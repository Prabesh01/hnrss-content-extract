<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-11T07:16:49.269578+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46203343</id><title>How Google Maps allocates survival across London's restaurants</title><updated>2025-12-11T07:16:57.676306+00:00</updated><content/><link href="https://laurenleek.substack.com/p/how-google-maps-quietly-allocates"/><published>2025-12-09T10:20:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46208348</id><title>Australia begins enforcing world-first teen social media ban</title><updated>2025-12-11T07:16:57.491775+00:00</updated><content>&lt;doc fingerprint="2d87985519e0dfd9"&gt;
  &lt;main&gt;
    &lt;p&gt;SYDNEY, Dec 10 (Reuters) - Australia on Wednesday became the first country to ban social media for children under 16, blocking access in a move welcomed by many parents and child advocates but criticised by major technology companies and free-speech advocates.&lt;/p&gt;
    &lt;p&gt;Starting at midnight (1300 GMT on Tuesday), 10 of the largest platforms including TikTok, Alphabet's (GOOGL.O) YouTube and Meta's (META.O) Instagram and Facebook were ordered to block children or face fines of up to A$49.5 million ($33 million) under the new law, which is being closely watched by regulators worldwide.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;Prime Minister Anthony Albanese called it "a proud day" for families and cast the law as proof that policymakers can curb online harms that have outpaced traditional safeguards.&lt;/p&gt;
    &lt;p&gt;"This will make an enormous difference. It is one of the biggest social and cultural changes that our nation has faced," Albanese told a news conference on Wednesday.&lt;/p&gt;
    &lt;p&gt;"It's a profound reform which will continue to reverberate around the world."&lt;/p&gt;
    &lt;head rend="h2"&gt;READ A BOOK INSTEAD, PM TELLS YOUNGSTERS&lt;/head&gt;
    &lt;p&gt;In a video message, Albanese urged children to "start a new sport, new instrument, or read that book that has been sitting there for some time on your shelf," ahead of Australia's summer school break starting later this month.&lt;/p&gt;
    &lt;p&gt;Some of those below the cut-off age of 16 were anxious about adjusting to life without social media, but others were less concerned.&lt;/p&gt;
    &lt;p&gt;"I'm not really that emotional about it," said 14-year-old Claire Ni. "I'm kind of just, like, neutral."&lt;/p&gt;
    &lt;p&gt;Luna Dizon, 15, said she still had access to her TikTok, Instagram and Snapchat accounts, but worried about "culture shock" once the ban took full effect.&lt;/p&gt;
    &lt;p&gt;"I think eventually, without (social media), we'll learn how to adapt to it," she added.&lt;/p&gt;
    &lt;head rend="h2"&gt;TEENAGER SIGNS OFF WITH 'SEE YOU WHEN I'M 16'&lt;/head&gt;
    &lt;p&gt;While the government has said the ban would not be perfect in its operation, about 200,000 accounts were deactivated by Wednesday on TikTok alone, with "hundreds of thousands" more to be blocked in the next few days.&lt;/p&gt;
    &lt;p&gt;Many of the estimated 1 million children affected by the legislation also posted goodbye messages on social media.&lt;/p&gt;
    &lt;p&gt;"No more social media ... no more contact with the rest of the world," one teen wrote on TikTok.&lt;/p&gt;
    &lt;p&gt;"#seeyouwhenim16," said another.&lt;/p&gt;
    &lt;p&gt;Others said they would learn how to get round the ban.&lt;/p&gt;
    &lt;p&gt;"It's just kind of pointless, we're just going to create new ways to get on these platforms, so what's the point," said 14-year-old Claire Ni.&lt;/p&gt;
    &lt;head rend="h2"&gt;BAN HAS GLOBAL IMPLICATIONS&lt;/head&gt;
    &lt;p&gt;The rollout caps a year of debate over whether any country could practically stop children from using platforms embedded in daily life, and begins a live test for governments frustrated that social media firms have been slow to implement harm-reduction measures.&lt;/p&gt;
    &lt;p&gt;"I'm happy that they want to protect kids, and I'm happy that we have a chance to see how they do it and see if we can learn from them," said European Union lawmaker Christel Schaldemose, who wants to see greater protection for the bloc's children.&lt;/p&gt;
    &lt;p&gt;Albanese's centre-left government proposed the landmark law citing research showing harms to mental health from the overuse of social media among young teens, including misinformation, bullying and harmful depictions of body image.&lt;/p&gt;
    &lt;p&gt;Several countries from Denmark to New Zealand to Malaysia have signalled they may study or emulate Australia's model.&lt;/p&gt;
    &lt;p&gt;At a school in the German city of Bonn, students spoke favourably of a ban.&lt;/p&gt;
    &lt;p&gt;"Social media is highly addictive and doesn't really have any real advantages. I mean, there are advantages, such as being able to spread your opinion, but I think the disadvantages, especially the addiction, are much worse," said 15-year-old pupil Arian Klaar.&lt;/p&gt;
    &lt;p&gt;Julie Inman Grant, the U.S.-born eSafety Commissioner who is overseeing the ban, told Reuters on Wednesday a groundswell of American parents wanted similar measures.&lt;/p&gt;
    &lt;p&gt;"I hear from the parents and the activists and everyday people in America, 'we wish we had an eSafety commissioner like you in America, we wish we had a government that was going to put tween and teen safety before technology profits,'" she said in an interview at her office in Sydney.&lt;/p&gt;
    &lt;p&gt;'NOT OUR CHOICE': X SAYS WILL COMPLY&lt;/p&gt;
    &lt;p&gt;Elon Musk's X became the last of the 10 major platforms to take measures to cut off access to underage teens after publicly acknowledging on Wednesday that it would comply.&lt;/p&gt;
    &lt;p&gt;"It's not our choice - it's what the Australian law requires," X said on its website.&lt;/p&gt;
    &lt;p&gt;Australia has said the initial list of covered platforms would change as new products emerge and young users migrate.&lt;/p&gt;
    &lt;p&gt;Companies have told Canberra they will deploy a mix of age inference - estimating a user's age from their behaviour - and age estimation based on a selfie, alongside checks that could include uploaded identification documents.&lt;/p&gt;
    &lt;p&gt;For social media businesses, the implementation marks a new era of structural stagnation as user numbers flatline and time spent on platforms shrinks, studies show.&lt;/p&gt;
    &lt;p&gt;Platforms say they earn little from advertising to under-16s, but warn the ban disrupts a pipeline of future users. Just before the ban took effect, 86% of Australians aged eight to 15 used social media, the government said.&lt;/p&gt;
    &lt;p&gt;($1 = 1.5097 Australian dollars)&lt;/p&gt;
    &lt;p&gt;Reporting by Byron Kaye and Renju Jose; Additional reporting by James Redmayne and Cordelia Hsu; Writing by Alasdair Pal, Alexandra Hudson and Christine Chen; Editing by Andrew Heavens, Mark Potter, Lincoln Feast and Deepa Babington&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/legal/litigation/australia-social-media-ban-takes-effect-world-first-2025-12-09/"/><published>2025-12-09T18:12:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46212438</id><title>Rubio stages font coup: Times New Roman ousts Calibri</title><updated>2025-12-11T07:16:57.358468+00:00</updated><content>&lt;doc fingerprint="f1be8f403c685bdb"&gt;
  &lt;main&gt;
    &lt;p&gt;WASHINGTON, Dec 9 (Reuters) - U.S. Secretary of State Marco Rubio on Tuesday ordered diplomats to return to using Times New Roman font in official communications, calling his predecessor Antony Blinken's decision to adopt Calibri a "wasteful" diversity move, according to an internal department cable seen by Reuters.&lt;/p&gt;
    &lt;p&gt;The department under Blinken in early January 2023 had switched to Calibri, a modern sans-serif font, saying this was a more accessible font for people with disabilities because it did not have the decorative angular features and was the default in Microsoft products.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;A cable dated December 9 sent to all U.S. diplomatic posts said that typography shapes the professionalism of an official document and Calibri is informal compared to serif typefaces.&lt;/p&gt;
    &lt;p&gt;"To restore decorum and professionalism to the Department‚Äôs written work products and abolish yet another wasteful DEIA program, the Department is returning to Times New Roman as its standard typeface," the cable said.&lt;/p&gt;
    &lt;p&gt;"This formatting standard aligns with the President‚Äôs One Voice for America‚Äôs Foreign Relations directive, underscoring the Department‚Äôs responsibility to present a unified, professional voice in all communications," it added.&lt;/p&gt;
    &lt;p&gt;The State Department did not immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Some studies suggest that sans-serif fonts, such as Calibri, are easier to read for those with certain visual disabilities.&lt;/p&gt;
    &lt;p&gt;Trump, a Republican, moved quickly after taking office in January to eradicate federal DEI programs and discourage them in the private sector and education, including by directing the firing of diversity officers at federal agencies and pulling grant funding for a wide range of programs.&lt;/p&gt;
    &lt;p&gt;DEI policies became more widespread after nationwide protests in 2020 against police killings of unarmed Black people, spurring a conservative backlash. Trump and other critics of diversity initiatives say they are discriminatory against white people and men and have eroded merit-based decision making.&lt;/p&gt;
    &lt;p&gt;Reporting by Humeyra Pamuk; Editing by Don Durfee and Lisa Shumaker&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/world/us/rubio-stages-font-coup-times-new-roman-ousts-calibri-2025-12-09/"/><published>2025-12-10T00:08:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46216446</id><title>Common Lisp, ASDF, and Quicklisp: packaging explained</title><updated>2025-12-11T07:16:56.838185+00:00</updated><content>&lt;doc fingerprint="b7209a1f8fa70f94"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Common Lisp, ASDF, and Quicklisp: packaging explained&lt;/head&gt;
    &lt;p&gt;If there is one thing that confuses newcomers to Common Lisp, it is the interplay of built-in CL functionality, add-ons like Quicklisp and ASDF, and what all the words mean.&lt;/p&gt;
    &lt;p&gt;Common Lisp is old, and its inspiration is even older. It was developed when there was zero consensus on how file systems worked, operating systems were more incompatible than you can probably imagine, and that age shows. It pinned down terminology way before other languages got to the same point, and, as it happens so often, the late arrivals decided that they needed different words and these words stuck.&lt;/p&gt;
    &lt;p&gt;So let√¢s do a bit of a deep dive and see how all the bits and pieces work and why they are there. All examples are using SBCL and might be SBCL-specific. Check your Lisp√¢s manual if you use something else. Also, I√¢m (still) linking to the old LispWorks-provided HyperSpec as I√¢m not sure that the newer versions are fully done yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Common Lisp&lt;/head&gt;
    &lt;p&gt;Common Lisp comes with just the bare essentials to work with files. It has to, as that single specification had to work on microcomputers, mainframes, and all sorts of minicomputers. Even today with essentially just two branches of the operating system family alive, the difference are big between Unix derivatives with a single hierarchy (and one of them, macOS, by default with a case-insensitive interpretation) and MS-DOS derivaties with drive letters and backslashes but also the option to have network-style paths with double backslashes. So Common Lisp has a somewhat odd system of √¢namestrings√¢ (plain strings) and √¢pathnames√¢ (weird strings). It is not super important and the spec has details, the tl&amp;amp;dr is that sometimes you will see a special reader macro &lt;code&gt;#P"/foo/bar"&lt;/code&gt; instead of just &lt;code&gt;"/foo/bar"&lt;/code&gt; and the docs will tell
you which of these two is acceptable as an argument for what function. I just wanted to get
that out of the way first. They HyperSpec has all the details, of course.&lt;/p&gt;
    &lt;head rend="h3"&gt;Loading code from files.&lt;/head&gt;
    &lt;p&gt;With files out of the way, next up is &lt;code&gt;LOAD&lt;/code&gt;. It loads a file √¢into the Lisp environment√¢ (which
means your running image), but exactly how the file is named and whether it will load a source
file or a compiled file is system-dependent. So&lt;/p&gt;
    &lt;code&gt;(load "foo")
&lt;/code&gt;
    &lt;p&gt;can load &lt;code&gt;foo.lisp&lt;/code&gt; or &lt;code&gt;foo.fasl&lt;/code&gt; or maybe even &lt;code&gt;foo.obj&lt;/code&gt; if a Lisp implementation compiles to
C object files. If it is a source file, it√¢ll evaluate all the forms and do some system-specific
thing with them. The end result is that, well, everything in the file will now be ready for you
to use. So if we have:&lt;/p&gt;
    &lt;code&gt;(defun hello ()
  (print "Hello, world!"))

(print "Done loading!")
&lt;/code&gt;
    &lt;p&gt;and we open SBCL:&lt;/p&gt;
    &lt;code&gt;CL-USER(1): (load "test")

"Done loading"
T
CL-USER(2): (hello)

"Hello, world!"
"Hello, world!"
&lt;/code&gt;
    &lt;p&gt;Nothing too surprising there. In case we want to speed up loading, we can compile the file:&lt;/p&gt;
    &lt;code&gt;CL-USER(7): (compile-file "test")

; compiling file "/home/cees/tmp/test.lisp" (written 26 NOV 2025 09:03:19 PM):

; wrote /home/cees/tmp/test.fasl
; compilation finished in 0:00:00.004
#P"/home/cees/tmp/test.fasl"
NIL
NIL
&lt;/code&gt;
    &lt;p&gt;and the next time we ask to load &lt;code&gt;"test"&lt;/code&gt;, the FASL (√¢fast load√¢) file should be loaded. It is purely a time-saver
as the FASL file has been pre-parsed into your Lisp√¢s in-memory format so can be loaded very
quickly (bypassing &lt;code&gt;READ&lt;/code&gt; with all its bells and whistles). FASL files are implementation dependent and more often than not even version dependent. This
is pretty much everything that the standard has to say about getting code into the system, and as you
can see, it√¢s not much.&lt;/p&gt;
    &lt;p&gt;There is also &lt;code&gt;PROVIDE&lt;/code&gt; and &lt;code&gt;REQUIRE&lt;/code&gt;, which operate on something
that the standard calls modules (and which are kept in a variable called &lt;code&gt;*modules*&lt;/code&gt;) but the
standard designates this as deprecated so let√¢s skip it. Just know it is still lingering there. Don√¢t
use it (not even when packages √¢helpfully√¢ wrap it).&lt;/p&gt;
    &lt;head rend="h3"&gt;Packages&lt;/head&gt;
    &lt;p&gt;That &lt;code&gt;CL-USER&lt;/code&gt; in the prompt is the name of the package that you are in. Here is a pretty
bad choice of naming, and an endless source of confusion. A package is a namespace, nothing else, and
the spec says so much:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A package establishes a mapping from names to symbols.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;These days, we associate the concept of √¢package√¢ probably with more than that. A bundle of software, with files and maybe some metadata, a thing you can download from somewhere, most likely. But in Common Lisp, it√¢s just a tool to map symbol names (strings in your source code) to symbols (internal addresses in memory). It√¢s a pretty versatile facility and you should read the docs on &lt;code&gt;DEFPACKAGE&lt;/code&gt;. It√¢s is quite powerful, as it can &lt;code&gt;:use&lt;/code&gt; other packages, it can shadow symbols,
and whatnot, but at the end of the day, all that happens is that when you type:&lt;/p&gt;
    &lt;code&gt;(hello)
&lt;/code&gt;
    &lt;p&gt;The REPL will use the current package (in &lt;code&gt;*package*&lt;/code&gt;) to translate &lt;code&gt;hello&lt;/code&gt; to whatever function
is in memory, which should exist in the current package (here &lt;code&gt;COMMON-LISP-USER&lt;/code&gt;, commonly aliased to
&lt;code&gt;CL-USER&lt;/code&gt;) or in any packages it inherits from (√¢uses√¢). You can explicitly tell Lisp to look into
another package (&lt;code&gt;my-package:hello&lt;/code&gt; is a different function) and even ignore
that package√¢s explicit list of exported symbols by using a double colon (but don√¢t make a habit
out of prying into other packages, it breaks modularity). There are a ton of details, but
what counts is that a Common Lisp package is just an in-memory namespace thing, a bunch of
connected lookup tables that help the parser map the strings in the files you load to the
correct items inside your running image.&lt;/p&gt;
    &lt;p&gt;Nothing more, nothing less.&lt;/p&gt;
    &lt;head rend="h3"&gt;Systems&lt;/head&gt;
    &lt;p&gt;Common Lisp documentation often talks about systems in a general way like it is an intrinsic part of the language. However, the standard is vague. In the chapter on √¢System construction√¢ it deals with loading√¢the little bit of functionality we already discussed√¢and √¢features√¢, which are essentially just flags that are used by the &lt;code&gt;#+&lt;/code&gt; and &lt;code&gt;#-&lt;/code&gt; reader macros to make bits of code that
is loaded conditional on the presence of features.&lt;/p&gt;
    &lt;p&gt;That is all the standard has to say about systems. You can load files and you can make compilation of these files conditional on feature flags.&lt;/p&gt;
    &lt;head rend="h3"&gt;So, where does that leave us?&lt;/head&gt;
    &lt;p&gt;In a sense, this is all you need. I mean, you can take someone else√¢s files and &lt;code&gt;LOAD&lt;/code&gt; them, and
they can be made somewhat portable by using features and saying &lt;code&gt;#+sbcl&lt;/code&gt; (this code only to be
compiled on SBCL) or &lt;code&gt;#-linux&lt;/code&gt; (do not compile this on Linux), and the files can organize themselves
by using &lt;code&gt;DEFPACKAGE&lt;/code&gt; and friends to separate the code into namespaces so everybody can write
code using names like &lt;code&gt;HELLO&lt;/code&gt; and not step on each other√¢s toes.&lt;/p&gt;
    &lt;p&gt;Still, that Common Lisp √¢system√¢ thing√¢¬¶ it√¢s a bit vague and maybe there√¢s a hook there to build something more?&lt;/p&gt;
    &lt;head rend="h2"&gt;Another System Definition Facility&lt;/head&gt;
    &lt;p&gt;Some Common Lisp implementations come with a &lt;code&gt;DEFSYSTEM&lt;/code&gt;, but that is not portable. There
were early (we√¢re in 1989-ish now) attempts to have a common version, &lt;code&gt;MK:DEFSYSTEM&lt;/code&gt;, which
still works and is used by some projects. At the turn of a century, another version of &lt;code&gt;DEFSYSTEM&lt;/code&gt;
was created under the name &lt;code&gt;ASDF&lt;/code&gt;, which modernized things and quickly turned into the de facto
standard. It can do a lot of things and has extensive docs on its website, but we√¢ll focus here on the essentials.&lt;/p&gt;
    &lt;p&gt;So, what is a system? Well, a library? A, err, package? Well, it should be named a package and if Common Lisp were born a couple of decades later it might have been called a package, but we have already seen that that name has been given to something closer to what we would probably call √¢module√¢ today. √¢System√¢ it is, then, and ASDF √¢defines√¢ them.&lt;/p&gt;
    &lt;p&gt;Still, the closest analogy of a system is a package or a library: a bunch of Lisp code that together defines some functionality. It√¢s not a perfect comparison, because a lot of Lisp libraries contain multiple systems: at the very least, it is customary to have your code define separate systems for regular code and for test code, and often more systems are defined for, say, optional or contributed code. In any case, it is not intrinsic to Common Lisp, though, so ASDF strictly adds functionality:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It allows you to define a system (&lt;code&gt;ASDF:DEFSYSTEM&lt;/code&gt;). That√¢s the core function: you tell it that you have a system with a certain name, and description, and all sorts of metadata; and most importantly, what source files are part of the system.&lt;/item&gt;
      &lt;item&gt;It allows you to define dependencies between systems in your &lt;code&gt;DEFSYSTEM&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;It allows you to load such systems wholesale. Instead of the individual files, or a developer√¢s homebrew loading script, you can now work on a higher level and load a system by name.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A system still is not a √¢real√¢ Common Lisp thing: all that it does with respect to the standard is a bunch of &lt;code&gt;LOAD&lt;/code&gt; and &lt;code&gt;COMPILE-FILE&lt;/code&gt; calls. It will keep metadata in memory
about systems that are loaded, but under the hood, loading code is all it does. It comes
with extensive documentation and can do a lot of things like additional compilation steps, manage
test runs, etcetera, but if you squint, it just loads code.&lt;/p&gt;
    &lt;p&gt;An ASDF file, with the extension &lt;code&gt;.asd&lt;/code&gt;, is also just a Lisp source. The only special thing about
it is that the extension signals to ASDF that it is the file to look for when ASDF is searching
for systems, the one that has the system
definition in a given constellation of source files and directories.&lt;/p&gt;
    &lt;p&gt;It is important to realize that a √¢system√¢ and a package are entirely different things: one is an entity in an add-on tool, the other is intrinsic to Common Lisp√¢s namespacing. They can have the same name and often enough, they have the same name (your ASDF system √¢foo√¢ will likely define a package √¢FOO√¢ and it is helpful if that lives in a Git repository called √¢foo√¢ which has a file named √¢foo.asd√¢) but they are different things living in, well, different namespaces and should not be confused with each other. One is intrinsic, the other an optional (but widely used) add-on and they are fully orthogonal things.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where does ASDF gets its systems from?&lt;/head&gt;
    &lt;p&gt;Well, we have a √¢standard√¢, albeit a de facto one, to bundle Lisp code and describe how to load it. But if you say √¢this system here is called FOO and is dependent on BAR√¢, how does ASDF find BAR? The answer is very simple: it looks in predefined locations on your local disk (and nowhere else!). There are two predefined locations, one older and one currently preferred:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;~/common-lisp&lt;/code&gt;, the old one;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;~/.local/share/common-lisp/source&lt;/code&gt;, the XDG-compliant currently preferred one. Use this.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That√¢s all. You can extend that list by a very flexible but somewhat complicated mechanism called √¢source registries√¢, extensively documented, but essentially, the process looks like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You refer to a system called &lt;code&gt;foo&lt;/code&gt;;&lt;/item&gt;
      &lt;item&gt;ASDF will look for &lt;code&gt;foo.asd&lt;/code&gt;under the configured directories;&lt;/item&gt;
      &lt;item&gt;If found, it will load that file, and the &lt;code&gt;DEFSYSTEM&lt;/code&gt;in there will do the rest.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This process recurses, so when system &lt;code&gt;foo&lt;/code&gt; depends on system &lt;code&gt;bar&lt;/code&gt; then the process will repeat, until
everything is loaded or an error occurs. All the systems will be found, defined (in your image/memory),
and loaded in the right order (depth-first so that dependencies are loaded, their packages defined and
functions and macros and variables ready for use, before dependents are).&lt;/p&gt;
    &lt;head rend="h3"&gt;So, where does that leave us?&lt;/head&gt;
    &lt;p&gt;We upgraded from √¢here are a couple of Lisp files, good luck!√¢ to √¢here is a library with dependencies√¢. Good progress. All you need to do now is download the library (as a Zip file or a tarball), unpack it under &lt;code&gt;~/.local/share/common-lisp/source&lt;/code&gt;, and load if with
&lt;code&gt;ASDF:LOAD-SYSTEM&lt;/code&gt;. Of course, the system may declare dependencies so you may get an error
message. Easy enough, hunt for the dependency on the Net, download and unpack that, try again, find the next one.&lt;/p&gt;
    &lt;p&gt;Not perfect, but, well, progress?&lt;/p&gt;
    &lt;head rend="h2"&gt;Quicklisp enters the stage&lt;/head&gt;
    &lt;p&gt;It√¢s still a bit primitive, though. I mean, when coders were sending each other QIC tapes this may have been sufficient, but then someone went and had to invent the Internet and now we just push data over the information superhighway. We should be able to do better, not? Like √¢Perl in 1995√¢ better, even?&lt;/p&gt;
    &lt;p&gt;Just ilke ASDF is an optional add-on to what Common Lisp provides, Quicklisp is an optional add-on to what ASDF offers. Essentially, it does two things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It adds a new directory to the places where ASDF can find systems;&lt;/item&gt;
      &lt;item&gt;It offers some functions to download a system from √¢wherever√¢, which includes √¢the Internet√¢.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It hook into ASDF√¢s dependency resolution so that if there are more dependencies needed, Quicklisp will go and fetch them as well.&lt;/p&gt;
    &lt;p&gt;Tadaa: problem solved! We can just open SBCL and say&lt;/p&gt;
    &lt;code&gt;(ql:quickload "foo")
&lt;/code&gt;
    &lt;p&gt;and admire a scrolling list of systems being downloaded, unpacked, loaded, analyzed for dependencies, dependencies being loaded, and so on.&lt;/p&gt;
    &lt;head rend="h3"&gt;So, where does that leave us?&lt;/head&gt;
    &lt;p&gt;We have all the functionality, but there√¢s one final issue: it is √¢always on√¢. In a lot of other languages, if you start your REPL (say, in Python or in Ruby or in Elixir) in a certain directory, that carries significance. The language runtime will look for a special project file, probably, and set up search paths so that they work for that project. Common Lisp has no such concept, not even after you load ASDF and Quicklisp. So if you have a directory &lt;code&gt;~/my-code/my-awesome-lisp-project&lt;/code&gt; with
a &lt;code&gt;my-awesome-lisp-project.asd&lt;/code&gt; in there√¢¬¶. Neither Quicklisp nor ASDF is going to bother
about the current directory and magically find your system.&lt;/p&gt;
    &lt;p&gt;You must play with their rules. Luckily, the rules are simple: go to &lt;code&gt;~/.local/share/common-lisp/source&lt;/code&gt; and drop symlinks in there to your projects so that ASDF
can find them. That also means that it
doesn√¢t matter where you start &lt;code&gt;sbcl&lt;/code&gt; or Sly or SLIME from, your code will always be found. And
when you then load your system with &lt;code&gt;QL:QUICKLOAD&lt;/code&gt;, its dependencies will automatically be pulled
in (&lt;code&gt;ASDF:LOAD-SYSTEM&lt;/code&gt; will still operate locally. It will, of course, use dependencies that
Quicklisp found and downloaded in previous runs).&lt;/p&gt;
    &lt;head rend="h2"&gt;Final tips&lt;/head&gt;
    &lt;head rend="h3"&gt;Read the source, Luke&lt;/head&gt;
    &lt;code&gt;$ git clone https://gitlab.common-lisp.net/asdf/asdf.git
$ git clone https://github.com/quicklisp/quicklisp-client
$ guix shell cloc -- cloc quicklisp-client asdf
     363 text files.
     264 unique files.
     104 files ignored.

github.com/AlDanial/cloc v 2.06  T=0.13 s (1984.8 files/s, 332115.5 lines/s)
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Lisp                           219           3981           3889          31548
Markdown                         3            305              0           1173
HTML                             1             11             50            767
Bourne Shell                    10             40            120            526
Text                            18            105              0            357
make                             4             88             61            312
CSS                              1             60              8            236
YAML                             3             28             51            202
Perl                             2             22              8            117
DOS Batch                        2             23             13             74
C                                1              0              0              1
-------------------------------------------------------------------------------
SUM:                           264           4663           4200          35313
-------------------------------------------------------------------------------
&lt;/code&gt;
    &lt;p&gt;It√¢s not that much code, and 7400 lines of that is the &lt;code&gt;UIOP&lt;/code&gt; package that ASDF
includes. UIOP is a package that is very useful in its own right as it is full of
utilities that help you make your code less implementation-dependent, but it won√¢t
teach you much about ASDF. So 25KLOC, tops. Without tests and contrib and whatnot, each
package is around 5000 lines of well-written Lisp and worth learning. It√¢s helped
me more than once to understand especially ASDF-VM to just open the code and figure
out what exactly is going on.&lt;/p&gt;
    &lt;head rend="h3"&gt;KISS: Use package-inferred-system and a single source tree.&lt;/head&gt;
    &lt;p&gt;Put your Lisp code in directories under, I dunno, say &lt;code&gt;~/Code/CL&lt;/code&gt;. Symlink that directory to
&lt;code&gt;~/.local/share/common-lisp/source&lt;/code&gt; and ASDF will be able to find all your
systems. I√¢ve done some magic using GUIX Home and Stow and whatnot and had to dig
around into how things worked, not recommended. If you have dependencies that are not
in Quicklisp (or Ultralisp, which is worth adding), then check
them out in a central spot (I use &lt;code&gt;~/OpenSource&lt;/code&gt;) and symlink it into &lt;code&gt;~/quicklisp/local-projects&lt;/code&gt;.
That way, all your dependency management is in one spot, the Quicklisp directory, whether you
download them or Quicklisp did the job.&lt;/p&gt;
    &lt;p&gt;Read about ASDF√¢s package-inferred-system and use it. It√¢ll keep you from having to spend much time writing &lt;code&gt;.asd&lt;/code&gt; files.
As the docs say, ASDF itself uses
it
and since switching to it, there√¢s no going back for me. In a nutshell, every file is
now expected to be a package and a system, same name, so that bit of confusion
goes away. One of my project repos (my main monorepo as of lately, I√¢m slowly
moving all my other code to it) has a very short ASDF definition:&lt;/p&gt;
    &lt;code&gt;#-asdf3.1 (error "CA.BERKSOFT requires ASDF 3.1 or later.")
(asdf:defsystem "ca.berksoft"
  :class :package-inferred-system)
&lt;/code&gt;
    &lt;p&gt;It also has some necessary &lt;code&gt;REGISTER-SYSTEM-PACKAGES&lt;/code&gt; calls to register Coalton packages. Sometimes you
have dependencies that don√¢t work well with this scheme and this is the work-around, a small drawback
that is dwarved by the advantages. But essentially, these three lines are it.&lt;/p&gt;
    &lt;p&gt;With that setup, a library to calculate the color temperature of an RGB color, say, lives in &lt;code&gt;l/gfx/color-temperature.lisp&lt;/code&gt; and starts with:&lt;/p&gt;
    &lt;code&gt;(uiop:define-package :ca.berksoft/l/gfx/color-temperature
  (:use :cl :infix-math :try)
  (:export :temp-&amp;gt;rgb))
&lt;/code&gt;
    &lt;p&gt;Note that I use the UIOP version of &lt;code&gt;defpackage&lt;/code&gt;. It√¢s a good habit to use the UIOP versions of
functions where possible; it√¢ll increase portability and more often than not, the UIOP functions
clean up confusion or shortcomings of the standard.&lt;/p&gt;
    &lt;p&gt;And that is all. ASDF, when I instruct it to load the system √¢ca.berksoft/l/gfx/color-temperature√¢, will stumble upon the top level &lt;code&gt;.asd&lt;/code&gt; file, and then will start interpreting the rest (√¢l/gfx/color-temperature√¢) as
a relative path under its package-inferred-system functionality. It finds that file, registers it as an ASDF system and loads it, which creates the Common Lisp package. Very simple, very clean. Give it
a try.&lt;/p&gt;
    &lt;p&gt;Questions? Jump on Libera IRC and join the &lt;code&gt;#commonlisp&lt;/code&gt; channel, I usually keep a close eye on
it. You can also DM me on Mastodon or drop me a mail.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cdegroot.com/programming/commonlisp/2025/11/26/cl-ql-asdf.html"/><published>2025-12-10T11:10:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218101</id><title>Show HN: Wirebrowser ‚Äì A JavaScript debugger with breakpoint-driven heap search</title><updated>2025-12-11T07:16:56.249423+00:00</updated><content>&lt;doc fingerprint="ac2b8e0449babf04"&gt;
  &lt;main&gt;
    &lt;p&gt;Wirebrowser is a debugging, interception, and memory-inspection toolkit powered by the Chrome DevTools Protocol (CDP). It unifies network manipulation, API testing, automation scripting, and deep JavaScript memory inspection into one interface.&lt;lb/&gt; With features like Breakpoint-Driven Heap Search and real-time Live Object Search, Wirebrowser provides researchers and engineers with precise, high-visibility tools for client-side analysis, reverse engineering, and complex application debugging.&lt;/p&gt;
    &lt;p&gt;Intercept, block, rewrite, and replay HTTP requests and responses in real time.&lt;/p&gt;
    &lt;p&gt;Inspect, search, and modify JavaScript memory using both live heap analysis and heap snapshots, with full support for object identity search, primitive search (via snapshots), structural matching, and runtime patching.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Live Object Search ‚Äî Search all live JavaScript objects using regex or structural matching, and patch matched objects at runtime to alter state or behavior dynamically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Static Heap Snapshot Search Capture a full V8 heap snapshot and search all objects and primitives, including strings and closure-captured values that are unreachable through the Runtime domain.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Origin Trace (BDHS) ‚Äî Performs automatic debugger pauses and captures a full heap snapshot at each stop. Every snapshot is searched to identify the user-land function responsible for creating or mutating the target value. Framework and vendor scripts are filtered out via heuristics.&lt;/p&gt;&lt;lb/&gt;BDHS also includes a tolerance window that samples snapshots before and after the first match, providing contextual insight into when and how a value is introduced or mutated.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A shared similarity engine used across Live Object Search, Heap Snapshots, and BDHS timelines. Enables shape-based searches, clustering, and origin tracing for objects that evolve over time.&lt;/p&gt;
    &lt;p&gt;Create, edit, and execute API requests with variable substitution and structured collections, integrating Postman-style workflows directly into the debugging environment.&lt;/p&gt;
    &lt;p&gt;A full technical deep-dive is available here: üëâ https://fcavallarin.github.io/wirebrowser/BDHS-Origin-Trace&lt;/p&gt;
    &lt;p&gt;Below is a quick visual tour of Wirebrowser‚Äôs most distinctive capabilities.&lt;/p&gt;
    &lt;p&gt;A short walkthrough of Wirebrowser‚Äôs advanced memory-analysis capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Live Object Search ‚Äî real-time search and runtime patching of live JS objects.&lt;/item&gt;
      &lt;item&gt;Origin Trace (BDHS) ‚Äî identify the user-land function responsible for creating or mutating the object during debugging.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Intercept, rewrite, block, and replay HTTP requests and responses.&lt;/p&gt;
    &lt;p&gt;Search and patch live JS objects using regex or structural matching.&lt;/p&gt;
    &lt;p&gt;Capture snapshots on each debugger pause to locate the user-land function responsible for object creation or mutation.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/fcavallarin/wirebrowser.git
cd wirebrowser
npm install
npm run build&lt;/code&gt;
    &lt;code&gt;npm run wirebrowser&lt;/code&gt;
    &lt;p&gt;On some Linux distributions, Electron may fail to start due to process sandboxing restrictions, showing errors such as:&lt;/p&gt;
    &lt;code&gt;The SUID sandbox helper binary was found, but is not configured correctly.
&lt;/code&gt;
    &lt;p&gt;This is a known issue in Electron ([electron/electron#42510]).&lt;lb/&gt; The most common solution is to disable AppArmor restrictions:&lt;/p&gt;
    &lt;code&gt;sudo sysctl -w kernel.apparmor_restrict_unprivileged_userns=0
&lt;/code&gt;
    &lt;p&gt;Beyond the core Network and Memory workflows, Wirebrowser offers several supporting modules that enhance debugging, testing, and automation workflows.&lt;/p&gt;
    &lt;p&gt;Create, edit, and execute API requests with variable substitution and organized collections.&lt;lb/&gt; Useful for testing endpoints, iterating on backend logic, or interacting with APIs directly from the same environment used for debugging the client.&lt;/p&gt;
    &lt;p&gt;Run browser-side or Node.js scripts, either manually or triggered by events such as page load.&lt;lb/&gt; Automation scripts have access to an &lt;code&gt;Utils&lt;/code&gt; object that exposes helpers for interacting with the browser, pages, variables, iterators, and HTTP utilities.&lt;/p&gt;
    &lt;code&gt;const userId = Utils.getVar("userId");
const page = Utils.getPage(1);
page.on("request", req =&amp;gt; req.continue());
await page.goto(`https://example.com/${userId}`);&lt;/code&gt;
    &lt;p&gt;A collection of small tools frequently needed during debugging and analysis, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Encode or decode strings in multiple formats:&lt;/item&gt;
      &lt;item&gt;Create, verify, and decode JSON Web Tokens (JWTs).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most Wirebrowser actions can be performed either globally (across all open tabs/pages) or targeted to a single tab. This lets you choose whether a rule or inspection should affect the whole browser session or only a specific page.&lt;lb/&gt; Every tab/page opened by Wirebrowser has a unique integer &lt;code&gt;tabId&lt;/code&gt;. Use this &lt;code&gt;tabId&lt;/code&gt; to scope actions.&lt;/p&gt;
    &lt;p&gt;UI Notes&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Many panels offer a scope selector (Global / Specific Tab ID) for quick changes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Wirebrowser is built with React and Node.js, using plain JavaScript to keep the codebase lightweight and hackable.&lt;lb/&gt; TypeScript or JSDoc-based typing may be introduced in the future for enhanced maintainability.&lt;/p&gt;
    &lt;p&gt;The following areas are being explored for future development:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SPA crawling ‚Äî automated crawling of single-page applications to map navigation flows and surface client-side behaviors.&lt;/item&gt;
      &lt;item&gt;DOM XSS scanning ‚Äî analysis of potential DOM-based XSS injection points during crawls or on-demand checks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Wirebrowser is being built in the open ‚Äî contributions and feedback are welcome!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üí¨ Chat coming soon (Discord or Matrix)&lt;/item&gt;
      &lt;item&gt;üê¶ Follow updates on X/Twitter: https://x.com/wirebrowser&lt;/item&gt;
      &lt;item&gt;üß† Issues &amp;amp; Ideas: https://github.com/fcavallarin/wirebrowser/issues&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions and pull requests are welcome!&lt;lb/&gt; Open an issue or pull request ‚Äî even small suggestions help improve Wirebrowser.&lt;/p&gt;
    &lt;p&gt;Wirebrowser‚Ñ¢ is distributed under the MIT License.&lt;lb/&gt; See the LICENSE file for more details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/fcavallarin/wirebrowser"/><published>2025-12-10T14:30:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218782</id><title>RoboCrop: Teaching robots how to pick tomatoes</title><updated>2025-12-11T07:16:55.990815+00:00</updated><content/><link href="https://phys.org/news/2025-12-robocrop-robots-tomatoes.html"/><published>2025-12-10T15:29:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219346</id><title>Size of Life</title><updated>2025-12-11T07:16:55.919029+00:00</updated><content/><link href="https://neal.fun/size-of-life/"/><published>2025-12-10T16:02:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219386</id><title>Launch HN: InspectMind (YC W24) ‚Äì AI agent for reviewing construction drawings</title><updated>2025-12-11T07:16:55.778612+00:00</updated><content>&lt;doc fingerprint="2d7bdbfc3354a606"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Aakash and Shuangling of InspectMind (&lt;/p&gt;https://www.inspectmind.ai/&lt;p&gt;), an AI ‚Äúplan checker‚Äù that finds issues in construction drawings, details, and specs.&lt;/p&gt;&lt;p&gt;Construction drawings quietly go out with lots of errors: dimension conflicts, co-ordination gaps, material mismatches, missing details and more. These errors turn into delays and hundreds of thousands of dollars of rework during construction. InspectMind reviews the full drawing set of a construction project in minutes. It cross-checks architecture, engineering, and specifications to catch issues that cause rework before building begins.&lt;/p&gt;&lt;p&gt;Here‚Äôs a video with some examples: https://www.youtube.com/watch?v=Mvn1FyHRlLQ.&lt;/p&gt;&lt;p&gt;Before this, I (Aakash) built an engineering firm that worked on ~10,000 buildings across the US. One thing that always frustrated us: a lot of design coordination issues don‚Äôt show up until construction starts. By then, the cost of a mistake can be 10‚Äì100x higher, and everyone is scrambling to fix problems that could have been caught earlier.&lt;/p&gt;&lt;p&gt;We tried everything including checklists, overlay reviews, peer checks but scrolling through 500‚Äì2000 PDF sheets and remembering how every detail connects to every other sheet is a brittle process. City reviewers and GC pre-con teams try to catch issues too, yet they still sneak through.&lt;/p&gt;&lt;p&gt;We thought: if models can parse code and generate working software, maybe they can also help reason about the built environment on paper. So we built something we wished we had!&lt;/p&gt;&lt;p&gt;You upload drawings and specs (PDFs). The system breaks them into disciplines and detail hierarchies, parses geometry and text, and looks for inconsistencies: - Dimensions that don‚Äôt reconcile across sheets; - Clearances blocked by mechanical/architectural elements; - Fire/safety details missing or mismatched; - Spec requirements that never made it into drawings; - Callouts referencing details that don‚Äôt exist.&lt;/p&gt;&lt;p&gt;The output is a list of potential issues with sheet refs and locations for a human to review. We don‚Äôt expect automation to replace design judgment, just to help ACE professionals not miss the obvious stuff. Current AIs are good at obvious stuff, plus can process data at quantities way beyond what humans can accurately do, so this is a good application for them.&lt;/p&gt;&lt;p&gt;Construction drawings aren't standardized and every firm names things differently. Earlier ‚Äúautomated checking‚Äù tools relied heavily on manually-written rules per customer, and break when naming conventions change. Instead, we‚Äôre using multimodal models for OCR + vector geometry, callout graphs across the entire set, constraint-based spatial checks, and retrieval-augmented code interpretation. No more hard-coded rules!&lt;/p&gt;&lt;p&gt;We‚Äôre processing residential, commercial, and industrial projects today. Latency ranges from minutes to a few hours depending on sheet count. There‚Äôs no onboarding required, simply upload PDFs. There are still lots of edge cases (PDF extraction weirdness, inconsistent layering, industry jargon), so we‚Äôre learning a lot from failures, maybe more than successes. But the tech is already delivering results that couldn‚Äôt be done with previous tools.&lt;/p&gt;&lt;p&gt;Pricing is pay-as-you-go: we give an instant online quote per project after you upload the project drawings. It‚Äôs hard to do regular SaaS pricing since one project may be a home remodel and another may be a highrise. We‚Äôre open to feedback on that too, we‚Äôre still figuring it out.&lt;/p&gt;&lt;p&gt;If you work with drawings as an architect, engineer, MEP, GC preconstruction, real estate developer, plan reviewer we‚Äôd love a chance to run a sample set and hear what breaks, what‚Äôs useful, and what‚Äôs missing!&lt;/p&gt;&lt;p&gt;We‚Äôll be here all day to go into technical details about geometry parsing, clustering failures, code reasoning attempts or real-world construction stories about how things go wrong. Thanks for reading! We‚Äôre happy to answer anything and look forward to your comments!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46219386"/><published>2025-12-10T16:05:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219538</id><title>Qwen3-Omni-Flash-2025-12-01Ôºöa next-generation native multimodal large model</title><updated>2025-12-11T07:16:55.226553+00:00</updated><link href="https://qwen.ai/blog?id=qwen3-omni-flash-20251201"/><published>2025-12-10T16:13:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220488</id><title>Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux</title><updated>2025-12-11T07:16:53.922295+00:00</updated><content>&lt;doc fingerprint="8cfd1d1d0995dc70"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux&lt;/head&gt;
    &lt;p&gt;Technically, the Steam Machine supports HDMI 2.1. However, Valve and AMD are not allowed to offer an open-source driver for it.&lt;/p&gt;
    &lt;p&gt;The HDMI Forum, responsible for the HDMI specification, continues to stonewall open source. Valve's Steam Machine theoretically supports HDMI 2.1, but the mini-PC is software-limited to HDMI 2.0. As a result, more than 60 frames per second at 4K resolution are only possible with limitations.&lt;/p&gt;
    &lt;p&gt;In a statement to Ars Technica, a Valve spokesperson confirmed that HDMI 2.1 support is "still a work-in-progress on the software side." "We‚Äôve been working on trying to unblock things there."&lt;/p&gt;
    &lt;p&gt;The Steam Machine uses an AMD Ryzen APU with a Radeon graphics unit. Valve strictly adheres to open-source drivers, but the HDMI Forum is unwilling to disclose the 2.1 specification. According to Valve, they have validated the HDMI 2.1 hardware under Windows to ensure basic functionality.&lt;/p&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;head rend="h3"&gt;No Change After Almost Two Years&lt;/head&gt;
    &lt;p&gt;The restriction imposed by the HDMI Forum was already criticized in early 2024 by an AMD employee responsible for Linux. Even then, according to AMD, they had submitted a functional, HDMI 2.1-compatible driver, which the HDMI Forum rejected.&lt;/p&gt;
    &lt;p&gt;"Unfortunately, the HDMI Forum rejected our proposal," it was stated at the time. "At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements."&lt;/p&gt;
    &lt;p&gt;Only HDMI 2.1 offers sufficient bandwidth for 120 or 144 Hertz at 3840 √ó 2160 pixels without compression. Furthermore, this version introduced manufacturer-independent variable refresh rates (HDMI VRR). Valve enables 4K and 120 Hertz using chroma subsampling, a compression technique that is particularly noticeable with text. VRR functions in the form of AMD's Freesync, which requires compatible displays.&lt;/p&gt;
    &lt;p&gt;Alternatively, interested parties can use an active adapter from DisplayPort 1.4 to HDMI 2.1 to increase the frame rate without compression. However, they do not officially support VRR. Popular variants from Club3D are no longer available; offers from less well-known providers (starting from 35,67 ‚Ç¨) are still available in price comparisons.&lt;/p&gt;
    &lt;p&gt;(mma)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html"/><published>2025-12-10T17:20:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220540</id><title>Auto-grading decade-old Hacker News discussions with hindsight</title><updated>2025-12-11T07:16:53.802846+00:00</updated><content>&lt;doc fingerprint="a207dbd71fe07fd4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Auto-grading decade-old Hacker News discussions with hindsight&lt;/head&gt;
    &lt;p&gt;TLDR: https://karpathy.ai/hncapsule/&lt;/p&gt;
    &lt;p&gt;Yesterday I stumbled on this HN thread Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now, where Gemini 3 was hallucinating the frontpage of 10 years from now. One of the comments struck me a bit more though - Bjartr linked to the HN frontpage from exactly 10 years ago, i.e. December 2015. I was reading through the discussions of 10 years ago and mentally grading them for prescience when I realized that an LLM might actually be a lot better at this task. I copy pasted one of the article+comment threads manually into ChatGPT 5.1 Thinking and it gave me a beautiful analysis of what people thought + what actually happened in retrospect, even better and significantly more detailed than what I was doing manually. I realized that this task is actually a really good fit for LLMs and I was looking for excuses to vibe code something with the newly released Opus 4.5, so I got to work. I'm going to get all the front pages of December (31 days, 30 articles per day), get ChatGPT 5.1 Thinking to do the analysis, and present everything in a nice way for historical reading.&lt;/p&gt;
    &lt;p&gt;There are two macro reasons for why I think the exercise is interesting more generally:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I believe it is quite possible and desirable to train your forward future predictor given training and effort.&lt;/item&gt;
      &lt;item&gt;I was reminded again of my tweets that said "Be good, future LLMs are watching". You can take that in many directions, but here I want to focus on the idea that future LLMs are watching. Everything we do today might be scrutinized in great detail in the future because doing so will be "free". A lot of the ways people behave currently I think make an implicit "security by obscurity" assumption. But if intelligence really does become too cheap to meter, it will become possible to do a perfect reconstruction and synthesis of everything. LLMs are watching (or humans using them might be). Best to be good.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Vibe coding the actual project was relatively painless and took about 3 hours with Opus 4.5, with a few hickups but overall very impressive. The repository is on GitHub here: karpathy/hn-time-capsule. Here is the progression of what the code does:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Given a date, download the frontpage of 30 articles&lt;/item&gt;
      &lt;item&gt;For each article, download/parse the article itself and the full comment thread using Algolia API.&lt;/item&gt;
      &lt;item&gt;Package up everything into a markdown prompt asking for the analysis. Here is the prompt prefix I used:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;The following is an article that appeared on Hacker News 10 years ago, and the discussion thread.

Let's use our benefit of hindsight now in 6 sections:

1. Give a brief summary of the article and the discussion thread.
2. What ended up happening to this topic? (research the topic briefly and write a summary)
3. Give out awards for "Most prescient" and "Most wrong" comments, considering what happened.
4. Mention any other fun or notable aspects of the article or discussion.
5. Give out grades to specific people for their comments, considering what happened.
6. At the end, give a final score (from 0-10) for how interesting this article and its retrospect analysis was.

As for the format of Section 5, use the header "Final grades" and follow it with simply an unordered list of people and their grades in the format of "name: grade (optional comment)". Here is an example:

Final grades
- speckx: A+ (excellent predictions on ...)
- tosh: A (correctly predicted this or that ...)
- keepamovin: A
- bgwalter: D
- fsflover: F (completely wrong on ...)

Your list may contain more people of course than just this toy example. Please follow the format exactly because I will be parsing it programmatically. The idea is that I will accumulate the grades for each account to identify the accounts that were over long periods of time the most prescient or the most wrong.

As for the format of Section 6, use the prefix "Article hindsight analysis interestingness score:" and then the score (0-10) as a number. Give high scores to articles/discussions that are prominent, notable, or interesting in retrospect. Give low scores in cases where few predictions are made, or the topic is very niche or obscure, or the discussion is not very interesting in retrospect.

Here is an example:
Article hindsight analysis interestingness score: 8
---
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Submit prompt to GPT 5.1 Thinking via the OpenAI API&lt;/item&gt;
      &lt;item&gt;Collect and parse the results&lt;/item&gt;
      &lt;item&gt;Render the results into static HTML web pages for easy viewing&lt;/item&gt;
      &lt;item&gt;Host the html result pages on my website: https://karpathy.ai/hncapsule/&lt;/item&gt;
      &lt;item&gt;Host all the intermediate results of the &lt;code&gt;data&lt;/code&gt;directory if someone else would like to play. It's the file&lt;code&gt;data.zip&lt;/code&gt;under the exact same url prefix (intentionally avoiding a direct link).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I spent a few hours browsing around and found it to be very interesting. A few example threads just for fun:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;December 3 2015 Swift went open source.&lt;/item&gt;
      &lt;item&gt;December 6 2015 Launch of Figma&lt;/item&gt;
      &lt;item&gt;December 11 2015 original announcement of OpenAI :').&lt;/item&gt;
      &lt;item&gt;December 16 2015 geohot is building Comma&lt;/item&gt;
      &lt;item&gt;December 22 2015 SpaceX launch webcast: Orbcomm-2 Mission&lt;/item&gt;
      &lt;item&gt;December 28 2015 Theranos struggles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And then when you navigate over to the Hall of Fame, you can find the top commenters of Hacker News in December 2015, sorted by imdb-style score of their grade point average. In particular, congratulations to pcwalton, tptacek, paulmd, cstross, greglindahl, moxie, hannob, 0xcde4c3db, Manishearth, johncolanduoni - GPT 5.1 Thinking found your comments very insightful and prescient. You can also scroll all the way down to find the noise of HN, which I think we're all familiar with too :)&lt;/p&gt;
    &lt;p&gt;My code (wait, Opus' code?) on GitHub can be used to reproduce or tweak the results. Running 31 days of 30 articles through GPT 5.1 Thinking meant &lt;code&gt;31 * 30 =&lt;/code&gt; 930 LLM queries and cost about $58 and somewhere around ~1 hour. The LLM megaminds of the future might find this kind of a thing a lot easier, a lot faster and a lot cheaper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://karpathy.bearblog.dev/auto-grade-hn/"/><published>2025-12-10T17:23:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220640</id><title>Is it a bubble?</title><updated>2025-12-11T07:16:53.541111+00:00</updated><content>&lt;doc fingerprint="3d81815945b785e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Is It a Bubble?&lt;/head&gt;
    &lt;p&gt;Ours is a remarkable moment in world history. A transformative technology is ascending, and its supporters claim it will forever change the world. To build it requires companies to invest a sum of money unlike anything in living memory. News reports are filled with widespread fears that America‚Äôs biggest corporations are propping up a bubble that will soon pop.&lt;/p&gt;
    &lt;p&gt;During my visits to clients in Asia and the Middle East last month, I was often asked about the possibility of a bubble surrounding artificial intelligence, and my discussions gave rise to this memo. I want to start off with my usual caveats: I‚Äôm not active in the stock market; I merely watch it as the best barometer of investor psychology. I‚Äôm also no techie, and I don‚Äôt know any more about AI than most generalist investors. But I‚Äôll do my best.&lt;/p&gt;
    &lt;p&gt;One of the most interesting aspects of bubbles is their regularity, not in terms of timing, but rather the progression they follow. Something new and seemingly revolutionary appears and worms its way into people‚Äôs minds. It captures their imagination, and the excitement is overwhelming. The early participants enjoy huge gains. Those who merely look on feel incredible envy and regret and ‚Äì motivated by the fear of continuing to miss out ‚Äì pile in. They do this without knowledge of what the future will bring or concern about whether the price they‚Äôre paying can possibly be expected to produce a reasonable return with a tolerable amount of risk. The end result for investors is inevitably painful in the short to medium term, although it‚Äôs possible to end up ahead after enough years have passed.&lt;/p&gt;
    &lt;p&gt;I‚Äôve lived through several bubbles and read about others, and they‚Äôve all hewed to this description. One might think the losses experienced when past bubbles popped would discourage the next one from forming. But that hasn‚Äôt happened yet, and I‚Äôm sure it never will. Memories are short, and prudence and natural risk aversion are no match for the dream of getting rich on the back of a revolutionary technology that ‚Äúeveryone knows‚Äù will change the world.&lt;/p&gt;
    &lt;p&gt;I took the quote that opens this memo from Derek Thompson‚Äôs November 4 newsletter entitled ‚ÄúAI Could Be the Railroad of the 21st Century. Brace Yourself,‚Äù about parallels between what‚Äôs going on today in AI and the railroad boom of the 1860s. Its word-for-word applicability to both shows clearly what‚Äôs meant by the phrase widely attributed to Mark Twain: ‚Äúhistory rhymes.‚Äù&lt;/p&gt;
    &lt;p&gt;Understanding Bubbles&lt;/p&gt;
    &lt;p&gt;Before diving into the subject at hand ‚Äì and having read a great deal about it in preparation ‚Äì I want to start with a point of clarification. Everyone asks, ‚ÄúIs there a bubble in AI?‚Äù I think there‚Äôs ambiguity even in the question. I‚Äôve concluded there are two different but interrelated bubble possibilities to think about: one in the behavior of companies within the industry, and the other in how investors are behaving with regard to the industry. I have absolutely no ability to judge whether the AI companies‚Äô aggressive behavior is justified, so I‚Äôll try to stick primarily to the question of whether there‚Äôs a bubble around AI in the financial world.&lt;/p&gt;
    &lt;p&gt;The main job of an investment analyst ‚Äì especially in the so-called ‚Äúvalue‚Äù school to which I subscribe ‚Äì is to (a) study companies and other assets and assess the level of and outlook for their intrinsic value and (b) make investment decisions on the basis of that value. Most of the change the analyst encounters in the short to medium term surrounds the asset‚Äôs price and its relationship to underlying value. That relationship, in turn, is essentially the result of investor psychology.&lt;/p&gt;
    &lt;p&gt;Market bubbles aren‚Äôt caused directly by technological or financial developments. Rather, they result from the application of excessive optimism to those developments. As I wrote in my January memo On Bubble Watch, bubbles are temporary manias in which developments in those areas become the subject of what former U.S. Federal Reserve Chairman Alan Greenspan called ‚Äúirrational exuberance.‚Äô‚Äô&lt;/p&gt;
    &lt;p&gt;Bubbles usually coalesce around new financial developments (e.g., the South Sea Company of the early 1700s or sub-prime residential mortgage-backed securities in 2005-06) or technological progress (optical fiber in the late 1990s and the internet in 1998-2000). Newness plays a huge part in this. Because there‚Äôs no history to restrain the imagination, the future can appear limitless for the new thing. And futures that are perceived to be limitless can justify valuations that go well beyond past norms ‚Äì leading to asset prices that aren‚Äôt justified on the basis of predictable earning power.&lt;/p&gt;
    &lt;p&gt;The role of newness is well described in my favorite passage from a book that greatly influenced me, A Short History of Financial Euphoria by John Kenneth Galbraith. Galbraith wrote about what he called ‚Äúthe extreme brevity of the financial memory‚Äù and pointed out that in the financial markets, ‚Äúpast experience, to the extent that it is part of memory at all, is dismissed as the primitive refuge of those who do not have the insight to appreciate the incredible wonders of the present.‚Äù In other words, history can impose limits on awe regarding the present and imagination regarding the future. In the absence of history, on the other hand, all things seem possible.&lt;/p&gt;
    &lt;p&gt;The key thing to note here is that the new thing understandably inspires great enthusiasm, but bubbles are what happen when the enthusiasm reaches irrational proportions. Who can identify the boundary of rationality? Who can say when an optimistic market has become a bubble? It‚Äôs just a matter of judgment.&lt;/p&gt;
    &lt;p&gt;Something that occurred to me this past month is that two of my best ‚Äúcalls‚Äù came in 2000, when I cautioned about what was going on in the market for tech and internet stocks, and in 2005-07, when I cited the dearth of risk aversion and the resulting ease of doing crazy deals in the pre-Global Financial Crisis world.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;First, in neither case did I possess any expertise regarding the things that turned out to be the subjects of the bubbles: the internet and sub-prime mortgage-backed securities. All I did was render observations regarding the behavior taking place around me.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;And second, the value in my calls consisted mostly of describing the folly in that behavior, not in insisting that it had brought on a bubble.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Struggling with whether to apply the ‚Äúbubble‚Äù label can bog you down and interfere with proper judgment; we can accomplish a great deal by merely assessing what‚Äôs going on around us and drawing inferences with regard to proper behavior.&lt;/p&gt;
    &lt;p&gt;What‚Äôs Good About Bubbles?&lt;/p&gt;
    &lt;p&gt;Before going on to discuss AI and whether it‚Äôs presently in a bubble, I want to spend a little time on a subject that may seem somewhat academic from the standpoint of investors: the upside of bubbles. You may find the attention I devote to this topic excessive, but I do so because I find it fascinating.&lt;/p&gt;
    &lt;p&gt;The November 5 Stratechery newsletter was entitled ‚ÄúThe Benefits of Bubbles.‚Äù In it, Ben Thompson (no relation to Derek) cites a book titled Boom: Bubbles and the End of Stagnation. It was written by Byrne Hobart and Tobias Huber, who propose that there are two kinds of bubbles:&lt;/p&gt;
    &lt;p&gt;. . . ‚ÄúInflection Bubbles‚Äù ‚Äì the good kind of bubbles, as opposed to the much more damaging ‚ÄúMean-reversion Bubbles‚Äù like the 2000‚Äôs subprime mortgage bubble.&lt;/p&gt;
    &lt;p&gt;I find this a useful dichotomy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The financial fads I‚Äôve read about or witnessed ‚Äì the South Sea Company, portfolio insurance, and sub-prime mortgage-backed securities ‚Äì stirred the imagination based on the promise of returns without risk, but there was no expectation that they would represent overall progress for mankind. There was, for example, no thought that housing would be revolutionized by the sub-prime mortgage movement, merely a feeling that there was money to be made from backing new buyers. Hobart and Huber call these ‚Äúmean-reverting bubbles,‚Äù presumably because there‚Äôs no expectation that the underlying developments would move the world forward. Fads merely rise and fall.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;On the other hand, Hobart and Huber call bubbles based on technological progress ‚Äì as in the case of the railroads and the internet ‚Äì ‚Äúinflection bubbles.‚Äù After an inflection-driven bubble, the world will not revert to its prior state. In such a bubble, ‚Äúinvestors decide that the future will be meaningfully different from the past and trade accordingly.‚Äù As Thompson tells us:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The definitive book on bubbles has long been Carlota Perez‚Äôs Technological Revolutions and Financial Capital. Bubbles were ‚Äì are ‚Äì thought to be something negative and to be avoided, particularly at the time Perez published her book. The year was 2002 and much of the world was in a recession coming off the puncturing of the dot-com bubble.&lt;/p&gt;
    &lt;p&gt;Perez didn‚Äôt deny the pain: in fact, she noted that similar crashes marked previous revolutions, including the Industrial Revolution, railways, electricity, and the automobile. In each case the bubbles were not regrettable, but necessary: the speculative mania enabled what Perez called the ‚ÄúInstallation Phase,‚Äù where necessary but not necessarily financially wise investments laid the groundwork for the ‚ÄúDeployment Period.‚Äù What marked the shift to the deployment period was the popping of the bubble; what enabled the deployment period were the money-losing investments. (All emphasis added)&lt;/p&gt;
    &lt;p&gt;This distinction is very meaningful for Hobart and Huber, and I agree. They say, ‚Äúnot all bubbles destroy wealth and value. Some can be understood as important catalysts for techno-scientific progress.‚Äù&lt;/p&gt;
    &lt;p&gt;But I would restate as follows: ‚ÄúMean-reversion bubbles‚Äù ‚Äì in which markets soar on the basis of some new financial miracle and then collapse ‚Äì destroy wealth. On the other hand, ‚Äúinflection bubbles‚Äù based on revolutionary developments accelerate technological progress and create the foundation for a more prosperous future, and they destroy wealth. The key is to not be one of the investors whose wealth is destroyed in the process of bringing on progress.&lt;/p&gt;
    &lt;p&gt;Hobart and Huber go on to describe in greater depth the process through which bubbles finance the building of the infrastructure required by the new technology and thus accelerate its adoption:&lt;/p&gt;
    &lt;p&gt;Most novel technology doesn‚Äôt just appear ex nihilo [i.e., from nothing], entering the world fully formed and all at once. Rather, it builds on previous false starts, failures, iterations, and historical path dependencies. Bubbles create opportunities to deploy the capital necessary to fund and speed up such large-scale experimentation ‚Äì which includes lots of trial and error done in parallel ‚Äì thereby accelerating the rate of potentially disruptive technologies and breakthroughs.&lt;/p&gt;
    &lt;p&gt;By generating positive feedback cycles of enthusiasm and investment, bubbles can be net beneficial. Optimism can be a self-fulfilling prophecy. Speculation provides the massive financing needed to fund highly risky and exploratory projects; what appears in the short term to be excessive enthusiasm or just bad investing turns out to be essential for bootstrapping social and technological innovations . . . A bubble can be a collective delusion, but it can also be an expression of collective vision. That vision becomes a site of coordination for people and capital and for the parallelization of innovation. Instead of happening over time, bursts of progress happen simultaneously across different domains. And with mounting enthusiasm . . . comes increased risk tolerance and strong network effects. The fear of missing out, or FOMO, attracts even more participants, entrepreneurs, and speculators, further reinforcing this positive feedback loop. Like bubbles, FOMO tends to have a bad reputation, but it‚Äôs sometimes a healthy instinct. After all, none of us wants to miss out on a once-in-a-lifetime chance to build the future.&lt;/p&gt;
    &lt;p&gt;In other words, bubbles based on technological progress are good because they excite investors into pouring in money ‚Äì a good bit of which is thrown away ‚Äì to carpet-bomb a new area of opportunity and thus jump-start its exploitation.&lt;/p&gt;
    &lt;p&gt;The key realization seems to be that if people remained patient, prudent, analytical, and value-insistent, novel technologies would take many years and perhaps decades to be built out. Instead, the hysteria of the bubble causes the process to be compressed into a very short period ‚Äì with some of the money going into life-changing investment in the winners but a lot of it being incinerated.&lt;/p&gt;
    &lt;p&gt;A bubble has aspects that are both technological and financial, but the above citations are from the standpoint of people who crave technological progress and are perfectly happy to see investors lose money in its interest. ‚ÄúWe,‚Äù on the other hand, would like to see technological progress but have no desire to throw away money to help bring it about.&lt;/p&gt;
    &lt;p&gt;Ben Thompson ends this discussion by saying, ‚ÄúThis is why I‚Äôm excited to talk about new technologies, the prospect for which I don‚Äôt know.‚Äù I love the fact that he‚Äôs excited by future possibilities and at the same time admits that the shape of the future is unknown (in our world, we might say ‚Äúvery risky‚Äù).&lt;/p&gt;
    &lt;p&gt;Assessing the Current Landscape&lt;/p&gt;
    &lt;p&gt;Now let‚Äôs get down to what we used to call ‚Äúbrass tacks.‚Äù What do we know? First, I haven‚Äôt met anyone who doesn‚Äôt believe artificial intelligence has the potential to be one of the biggest technological developments of all time, reshaping both daily life and the global economy.&lt;/p&gt;
    &lt;p&gt;We also know that in recent years, economies and markets have become increasingly dependent on AI:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;AI is responsible for a very large portion of companies‚Äô total capital expenditures.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Capital expenditures on AI capacity account for a large share of the growth in U.S. GDP.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AI stocks have been the source of the vast majority of the gains of the S&amp;amp;P 500.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As a Fortune headline put it on October 7:&lt;/p&gt;
    &lt;p&gt;75% of gains, 80% of profits, 90% of capex ‚Äì AI‚Äôs grip on the S&amp;amp;P is total and Morgan Stanley‚Äôs top analyst is ‚Äòvery concerned‚Äô&lt;/p&gt;
    &lt;p&gt;Further, I think it‚Äôs important to note that whereas the gains in AI-related stocks account for a disproportionate percentage of the total gains in all stocks, the excitement AI injects into the market must have added a lot to the appreciation of non-AI stocks as well.&lt;/p&gt;
    &lt;p&gt;AI-related stocks have shown astronomical performance, led by Nvidia, the leading developer of computer chips for AI. From its formation in 1993 and its initial public offering in 1999, when its estimated market value was $626 million, Nvidia briefly became the world‚Äôs first company worth $5 trillion. That‚Äôs appreciation of around 8,000x, or roughly 40% a year for 26+ years. No wonder imaginations have been fired.&lt;/p&gt;
    &lt;p&gt;What Are the Areas of Uncertainty?&lt;/p&gt;
    &lt;p&gt;I think it‚Äôs fair to say that while we know AI will be a source of incredible change, most of us have no idea exactly what it will be able to do, how it will be applied commercially, or what the timing will be.&lt;/p&gt;
    &lt;p&gt;Who will be the winners, and what will they be worth? If a new technology is assumed to be a world changer, it‚Äôs invariably assumed that the leading companies possessing that technology will be of great value. But how accurate will that assumption prove to be? As Warren Buffett pointed out in 1999, ‚Äú[The automobile was] the most important invention, probably, of the first half of the 20th century. . . . If you had seen at the time of the first cars how this country would develop in connection with autos, you would have said, ‚ÄòThis is the place I must be.‚Äô But of the 2,000 companies, as of a few years ago, only three car companies survived. So autos had an enormous impact on America but the opposite direction on investors.‚Äù (Time, January 23, 2012)&lt;/p&gt;
    &lt;p&gt;In AI, there are some very strong leaders at present, including some of the world‚Äôs strongest and richest companies. But new technology is notoriously disruptive. Will today‚Äôs leaders prevail or give way to upstarts? How much will the arms race cost, and who will win?&lt;/p&gt;
    &lt;p&gt;Similarly, what‚Äôs a share in an upstart worth? Unlike front runners worth trillions, it‚Äôs possible to invest in some would-be challengers at enterprise values in mere billions or even ‚Äì might I say? ‚Äì millions. On June 25, 2024, CNBC reported as follows:&lt;/p&gt;
    &lt;p&gt;A team founded by college dropouts has raised $120 million from investors led by Primary Venture Partners to build a new AI chip to take on Nvidia. Etched CEO Gavin Uberti said the startup is betting that as AI develops, most of the technology‚Äôs power-hungry computing requirements will be filled by customized, hard-wired chips called ASICs. ‚ÄúIf transformers go away, we‚Äôll die,‚Äù Uberti told CNBC. ‚ÄúBut if they stick around, we‚Äôre the biggest company of all time.‚Äù&lt;/p&gt;
    &lt;p&gt;Even granting the possibility that Etched won‚Äôt become the biggest company of all time, if success could give them a valuation just one-fifth of Nvidia‚Äôs peak ‚Äì a mere $1 trillion ‚Äì what probability of success would be required to justify an investment of $120 million? Assuming for simplicity‚Äôs sake that the investment was for a 100% ownership stake, all you need is a belief that achieving the trillion-dollar value has a probability of one-tenth of a percent for an expected return of over eight times your money. Who‚Äôs to say Etched doesn‚Äôt have that chance? And in that case, why would anyone not play? The foregoing is what I call ‚Äúlottery-ticket thinking,‚Äù in which the dream of an enormous payoff justifies ‚Äì no, compels ‚Äì participation in an endeavor with an overwhelming probability of failing.&lt;/p&gt;
    &lt;p&gt;There‚Äôs nothing wrong with calculating expected values this way. Leading venture capitalists engage in it every day to great effect. But assumptions regarding the possible payoffs and their probabilities must be reasonable. Thinking about a trillion-dollar payout will override reasonableness in any calculation.&lt;/p&gt;
    &lt;p&gt;Will AI produce profits, and for whom? Two things we know little or nothing about are the profits AI will produce for vendors and its impact on non-AI companies, primarily meaning those who employ it.&lt;/p&gt;
    &lt;p&gt;Will AI be a monopoly or duopoly, in which one or two leading companies are able to charge dearly for the capabilities? Or will it be a highly competitive free-for-all in which a number of firms compete on price for users‚Äô spending on AI services, making it a commodity? Or, perhaps most likely, will it be a mix of leading companies and specialized players, some of whom compete on price and others through proprietary advantages. It‚Äôs said that the services currently responding to AI queries, such as ChatGPT and Gemini, lose money on every query they answer (of course, it‚Äôs not unusual for participants in a new industry to offer ‚Äúloss leaders‚Äù for a while). Will the leading tech firms ‚Äì used to success in winner-take-all markets ‚Äì be content to experience losses in their AI businesses for years in order to gain share? Hundreds of billions of dollars are being committed to the race for AI leadership. Who will win, and what will be the result?&lt;/p&gt;
    &lt;p&gt;Likewise, what will be AI‚Äôs impact on the companies that use it? Clearly, AI will be a great tool for enhancing users‚Äô productivity by, among other things, replacing workers with computer-sourced labor and intelligence. But will this ability to cut costs add to the profit margins of the companies that employ it? Or will it simply enable price wars among those companies in the pursuit of customers? In that case, the savings might be passed on to the customers rather than garnered by the companies. In other words, is it possible AI will increase the efficiency of businesses without increasing their profitability?&lt;/p&gt;
    &lt;p&gt;Should we worry about so-called ‚Äúcircular deals‚Äù? In the telecom boom of the late 1990s, in which optical fiber became overbuilt, fiber-owning companies engaged in transactions with each other that permitted them to report profits. If two companies own fiber, they just have an asset on their books. But if each buys capacity from the other, they can both report profits . . . so they did. In other cases, manufacturers loaned network operators money to buy equipment from them, before the operators had customers to justify the buildout. All this resulted in profits that were illusory.&lt;/p&gt;
    &lt;p&gt;Nowadays, deals are being announced in which money appears to be round-tripped between AI players. People who believe there‚Äôs an AI bubble find it easy to view these transactions with suspicion. Is the purpose to achieve legitimate business goals or to exaggerate progress?&lt;/p&gt;
    &lt;p&gt;Adding to worries, critics say, some of the deals that OpenAI has made with chipmakers, cloud computing companies and others are oddly circular. OpenAI is set to receive billions from tech companies but also sends billions back to the same companies to pay for computing power and other services. . . .&lt;/p&gt;
    &lt;p&gt;Nvidia has also made some deals that have raised questions about whether the company is paying itself. It announced that it would invest $100 billion in OpenAI. The start-up receives that money as it buys or leases Nvidia‚Äôs chips. . . .&lt;/p&gt;
    &lt;p&gt;Goldman Sachs has estimated that Nvidia will make 15 percent of its sales next year from what critics also call circular deals. (The New York Times, November 20)&lt;/p&gt;
    &lt;p&gt;Noteworthily, OpenAI has made investment commitments to industry counterparties totaling $1.4 trillion, even though it has yet to turn a profit. The company makes clear that the investments are to be paid out of revenues received from the same parties and that it has ways to back out of these commitments. But all this raises the question of whether the AI industry has developed a perpetual motion machine.&lt;/p&gt;
    &lt;p&gt;(On this subject, I‚Äôve been enjoying articles questioning the ability of people to relate to the word ‚Äútrillion,‚Äù and I think this idea is spot on. A million dollars is a dollar a second for 11.6 days. A billion dollars is a dollar a second for 31.7 years. We get that. But a trillion dollars is a dollar a second for 31,700 years. Who can get their head around the significance of 31,700 years?)&lt;/p&gt;
    &lt;p&gt;What will be the useful life of AI assets? We have to wonder whether the topic of obsolescence is being handled correctly in AI-land. What will be the lifespan of AI chips? How many years of earnings growth should be counted on in assigning p/e ratios for AI-related stocks? Will chips and other aspects of AI infrastructure last long enough to repay the debt undertaken to buy them? Will artificial general intelligence (a machine capable of doing anything the human brain can do) be achieved? Will that be the end of progress, or might there be further revolutions, and what firms will win them? Will firms reach a position where technology is stable and they can extract economic value from it? Or will new technologies continually threaten to supplant older ones as the route to success?&lt;/p&gt;
    &lt;p&gt;In this connection, a single issue of an FT newsletter briefly mentioned two developments that suggest the fluid nature of the competitive landscape:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;A study by the Massachusetts Institute of Technology and open-source AI start-up Hugging Face found that the total share of downloads of new Chinese-made open models rose to 17 per cent in the past year. The figure surpasses the 15.8 per cent share of downloads from American developers such as Google, Meta and OpenAI ‚Äì the first time Chinese groups have beaten their American counterparts. . . .&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nvidia shares fell sharply yesterday on fears that Google is gaining ground in artificial intelligence, erasing $115bn in market value from the AI chipmaker. (FirstFT Americas, November 26)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Dynamic change creates the opportunity for incredible new technologies, but that same dynamism can threaten the leading companies‚Äô reign. Amid all these uncertainties, investors must ask whether the assumption of continued success incorporated in the prices they‚Äôre paying is fully warranted.&lt;/p&gt;
    &lt;p&gt;Is exuberance leading to speculative behavior? For an extreme example, I‚Äôll cite the trend toward venture capital investments in startups via $1 billion ‚Äúseed rounds.‚Äù Here‚Äôs one vignette:&lt;/p&gt;
    &lt;p&gt;Thinking Machines, an AI startup helmed by former Open AI executive Mira Murati, just raised the largest seed round in history: $2 billion in funding at a $10 billion valuation. The company has not released a product and has refused to tell investors what they‚Äôre even trying to build. ‚ÄúIt was the most absurd pitch meeting,‚Äù one investor who met with Murati said. ‚ÄúShe was like, ‚ÄòSo we're doing an AI company with the best AI people, but we can‚Äôt answer any questions.‚Äô ‚Äù (‚ÄúThe Is How the AI Bubble Will Pop,‚Äù Derek Thompson Substack, October 2)&lt;/p&gt;
    &lt;p&gt;But that‚Äôs ancient history. . . already two months old. Here‚Äôs an update:&lt;/p&gt;
    &lt;p&gt;Thinking Machines Lab, the artificial intelligence startup founded by former Open AI executive Mira Murati, is in early talks to raise a new funding round at a roughly $50 billion valuation, Bloomberg News reported on Thursday. The startup was last valued at $12 billion in July, after it raised about $2 billion. (Reuters, November 13)&lt;/p&gt;
    &lt;p&gt;And Thinking Machines Lab isn‚Äôt alone:&lt;/p&gt;
    &lt;p&gt;In one of the boldest bets yet in the AI arms race, Safe Superintelligence (SSI), the stealth startup founded by former OpenAI chief scientist Ilya Sutskever, has raised $2 billion in a round that values the company at $32 billion ‚Äì despite having no publicly released product or service. (CTech by Calcalist, April 13)&lt;/p&gt;
    &lt;p&gt;What‚Äôs the end state? Part of the issue with AI includes the unusual nature of this newest thing. This isn‚Äôt like a business that designs and sells a product, making money if the selling price exceeds the cost of the inputs. Rather, it‚Äôs companies building an airplane while it‚Äôs in flight, and once it‚Äôs built, they‚Äôll know what it can do and whether anyone will pay for its services.&lt;/p&gt;
    &lt;p&gt;Many companies justify their spending because they‚Äôre not just building a product, they‚Äôre creating something that will change the world: artificial general intelligence, or A.G.I. . . . The rub is that none of them quite know how to do it.&lt;/p&gt;
    &lt;p&gt;But Anton Korinek, an economist at the University of Virginia, said the spending would all be justified if Silicon Valley reached its goal. He is optimistic it can be done.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs a bet on A.G.I. or bust,‚Äù Dr. Korinek said. (The New York Times, November 20 ‚Äì emphasis added)&lt;/p&gt;
    &lt;p&gt;The yet-to-be-determined nature of the industry under construction is best captured in remarks from Sam Altman, the CEO of OpenAI, that have been paraphrased as follows: ‚Äúwe‚Äôll build this sort of generally intelligent system and then ask it to figure out a way to generate an investment return from it.‚Äù&lt;/p&gt;
    &lt;p&gt;This should be a source of pause for people who heretofore fully comprehended the nature of the businesses they invested in. Clearly, the value of a technology that equals or surpasses the human brain should be pretty big, but isn‚Äôt it well beyond calculation?&lt;/p&gt;
    &lt;p&gt;A Word About the Use of Debt&lt;/p&gt;
    &lt;p&gt;To date, much of the investment in AI and the supporting infrastructure has consisted of equity capital derived from operating cash flow. But now, companies are committing amounts that require debt financing, and for some of those companies, the investments and leverage have to be described as aggressive.&lt;/p&gt;
    &lt;p&gt;The AI data centre boom was never going to be financed with cash alone. The project is too big to be paid for out of pocket. JPMorgan analysts have done some sums on the back of a napkin, or possibly a tablecloth, and estimated the bill for the infrastructure build-out would come to $5tn (not including a tip). Who knows if that‚Äôs right, but we have good reason to expect close to half a trillion in spending next year. Meanwhile, the biggest spenders (Microsoft, Alphabet, Amazon, Meta and Oracle) had only about $350bn in the bank, collectively, as of the end of the third quarter. (‚ÄúUnhedged,‚Äù Financial Times, November 13)&lt;/p&gt;
    &lt;p&gt;The firms mentioned above derive healthy cash flows from their very strong non-AI businesses. But the massive, winner-take-all arms race in AI is requiring some to take on debt. In fact, it‚Äôs reasonable to think one of the reasons they‚Äôre spending vast sums is to make it hard for lesser firms to keep up.&lt;/p&gt;
    &lt;p&gt;Oracle, Meta, and Alphabet have issued 30-year bonds to finance AI investments. In the case of the latter two, the yields on the bonds exceed those on Treasurys of like maturity by 100 basis points or less. Is it prudent to accept 30 years of technological uncertainty to make a fixed-income investment that yields little more than riskless debt? And will the investments funded with debt ‚Äì in chips and data centers ‚Äì maintain their level of productivity long enough for these 30-year obligations to be repaid?&lt;/p&gt;
    &lt;p&gt;On November 14, Alex Kantrowitz‚Äôs Big Technology Podcast carried a conversation with Gil Luria, Head of Technology Research at financial services firm D.A. Davidson, primarily regarding the use of debt in the AI sector. Here‚Äôs some of what Luria had to say:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Healthy behavior is being practiced by ‚Äú. . . reasonable, thoughtful business leaders, like the ones at Microsoft, Amazon, and Google that are making sound investments in growing the capacity to deliver AI. And the reason they can make sound investments is that they have all the customers. . . And so, when they make investments, they‚Äôre using cash on their balance sheets; they have tremendous cash flow to back it up; they understand that it‚Äôs a risky investment; and they balance it out.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unhealthy behavior ‚Äì Here he describes ‚Äú. . . a startup that is borrowing money to build data centers for another startup. They‚Äôre both losing tremendous amounts of cash, and yet they‚Äôre somehow being able to raise this debt capital in order to fund this buildout, again without having the customers or the visibility into those investments paying off.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;‚ÄúSo there‚Äôs a whole range of behaviors between healthy and unhealthy, and we just need to sort that out so we don‚Äôt make the mistakes of the past.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;‚ÄúThere are certain things we finance through equity, through ownership, and there are certain things we finance through debt, through an obligation to pay down interest over time. And as a society, for the longest time, we‚Äôve had those two pieces in their right place. Debt is when I have a predictable cash flow and/or an asset that can back that loan, and then it makes sense for me to exchange capital now for future cash flows to the lender. . . . We use equity for investing in more speculative things, for when we want to grow and we want to own that growth, but we‚Äôre not sure about what the cash flow is going to be. That‚Äôs how a normal economy functions. When you start confusing the two you get yourself in trouble.‚Äù&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Among potentially worrisome factors, Luria cites these:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;‚ÄúA speculative asset . . . we don‚Äôt know how much of it we‚Äôre really going to need in two to five years.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lender personnel with incentives to make loans but no exposure to long-term consequences&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The possibility that the supply of AI capacity catches up with or surpasses the demand&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The chance that future generations of AI chips will be more powerful, obsoleting existing ones or reducing their value as backing for debt&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powerful competitors who vie for market share by cutting rental rates and running losses&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are some important paragraphs from Azeem Azhar‚Äôs Exponential View of October 18:&lt;/p&gt;
    &lt;p&gt;When does an AI boom tip into a bubble? [Investor and engineer] Paul Kedrosky points to the Minsky moment ‚Äì the inflection point when credit expansion exhausts its good projects and starts chasing bad ones, funding marginal deals with vendor financing and questionable coverage ratios. For AI infrastructure, that shift may already be underway; the telltale signs include hyperscalers‚Äô capex outpacing revenue momentum and lenders sweetening terms to keep the party alive.&lt;/p&gt;
    &lt;p&gt;Paul makes a compelling case. We‚Äôve entered speculative finance territory ‚Äì arguably past the tentative stage ‚Äì and recent deals will set dangerous precedents. As Paul warns, this financing will ‚Äúcreate templates for future such transactions,‚Äù spurring rapid expansion in junk issuance and SPV proliferation among hyperscalers chasing dominance at any cost. . . .&lt;/p&gt;
    &lt;p&gt;For AI infrastructure, the warning signs are flashing: vendor financing proliferates, coverage ratios thin, and hyperscalers leverage balance sheets to maintain capex velocity even as revenue momentum lags. We see both sides ‚Äì genuine infrastructure expansion alongside financing gymnastics that recall the 2000 telecom bust. The boom may yet prove productive, but only if revenue catches up before credit tightens. When does healthy strain become systemic risk? That‚Äôs the question we must answer before the market does. (Emphasis added)&lt;/p&gt;
    &lt;p&gt;Azhar references the use of off-balance sheet financing via special-purpose vehicles, or SPVs, which were among the biggest contributors to Enron‚Äôs precariousness and eventual collapse. A company and its partners set up an SPV for some specific purpose(s) and supply the equity capital. The parent company may have operating control, but because it doesn‚Äôt have majority ownership, it doesn‚Äôt consolidate the SPV on its financial statements. The SPV takes on debt, but that debt doesn‚Äôt appear on the parent‚Äôs books. The parent may be an investment grade borrower, but likewise, the debt isn‚Äôt an obligation of the parent or guaranteed by it. Today‚Äôs debt may be backed by promised rent from a data center tenant ‚Äì sometimes an equity partner ‚Äì but the debt isn‚Äôt a direct obligation of the equity partner either. Essentially, an SPV is a way to make it look like a company isn‚Äôt doing the things the SPV is doing and doesn‚Äôt have the debt the SPV does. (Private equity funds and private credit funds are highly likely to be found among the partners and lenders in these entities.)&lt;/p&gt;
    &lt;p&gt;As I quoted earlier, according to Perez (who wrote on the heels of the dot-com bubble), ‚Äúwhat enabled the deployment period were the money-losing investments.‚Äù Early investment is lost in the ‚ÄúMinsky moment,‚Äù in which unwise commitments made in an extended up-cycle encounters value destruction in a correction. And there are three things we know for sure about the use of debt:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;it magnifies losses if there are losses (just as it magnifies the hoped-for gains if they materialize),&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;it increases the probability of a venture failing if it encounters a difficult moment, and&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;despite the layer of equity beneath it, it puts lenders‚Äô capital at risk if the difficult moment is bad enough.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One key risk to consider is the possibility that the boom in data center construction will result in a glut. Some data centers may be rendered uneconomic, and some owners may go bankrupt. In that case, a new generation of owners might buy up centers at pennies on the dollar from lenders who foreclosed on them, reaping profits when the industry stabilizes. This is a process through which ‚Äúcreative destruction‚Äù brings markets into equilibrium and reduces costs to levels that make future business profitable.&lt;/p&gt;
    &lt;p&gt;Debt is neither a good thing nor a bad thing per se. Likewise, the use of leverage in the AI industry shouldn‚Äôt be applauded or feared. It all comes down to the proportion of debt in the capital structure; the quality of the assets or cash flows you‚Äôre lending against; the borrowers‚Äô alternative sources of liquidity for repayment; and the adequacy of the safety margin obtained by lenders. We‚Äôll see which lenders maintain discipline in today‚Äôs heady environment.&lt;/p&gt;
    &lt;p&gt;It‚Äôs worth noting in this connection that Oaktree has made a few investments in data centers, and our parent, Brookfield, is raising a $10 billion fund for investment in AI infrastructure. Brookfield is putting up its own money and has equity commitments from sovereign wealth funds and Nvidia, to which it intends to apply ‚Äúprudent‚Äù debt. Brookfield‚Äôs investments seem likely to go largely into geographies that are less saturated with data centers and for infrastructure to supply the vast amounts of electric power that data centers will require. Of course, we‚Äôre both doing these things on the basis of what we think are prudent decisions.&lt;/p&gt;
    &lt;p&gt;I know I don‚Äôt know enough to opine on AI. But I do know something about debt, and it‚Äôs this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;It‚Äôs okay to supply debt financing for a venture where the outcome is uncertain.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It‚Äôs not okay where the outcome is purely a matter of conjecture.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Those who understand the difference still have to make the distinction correctly.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The FT‚Äôs Unhedged quotes Chong Sin, lead analyst for CMBS research at JPMorgan, as saying, ‚Äú. . . in our conversations with investment grade ABS and CMBS investors, one often-cited concern is whether they want to take on the residual value risk of data centers when the bonds mature.‚Äù I‚Äôm glad potential lenders are asking the kind of questions they should.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how to think about the intersection of debt and AI according to Bob O‚ÄôLeary, Oaktree‚Äôs co-CEO and co-portfolio manager of our Opportunities Funds:&lt;/p&gt;
    &lt;p&gt;Most technological advances develop into winner-takes-all or winner-takes-most competitions. The ‚Äúright‚Äù way to play this dynamic is through equity, not debt. Assuming you can diversify your equity exposures so as to include the eventual winner, the massive gain from the winner will more than compensate for the capital impairment on the losers. That‚Äôs the venture capitalist‚Äôs time-honored formula for success.&lt;/p&gt;
    &lt;p&gt;The precise opposite is true of a diversified pool of debt exposures. You‚Äôll only make your coupon on the winner, and that will be grossly insufficient to compensate for the impairments you‚Äôll experience on the debt of the losers.&lt;/p&gt;
    &lt;p&gt;Of course, if you can‚Äôt identify the pool of companies from which the winner will emerge, the difference between debt and equity is irrelevant ‚Äì you‚Äôre a zero either way. I mention this because that‚Äôs precisely what happened in search and social media: early leaders (Lycos in search and MySpace in social media) lost out spectacularly to companies that emerged later (Google in search and Facebook in social media).&lt;/p&gt;
    &lt;p&gt;Trying to Get to a Conclusion&lt;/p&gt;
    &lt;p&gt;There can be no doubt that today‚Äôs behavior is ‚Äúspeculative,‚Äù defined as based on speculation regarding the future. There‚Äôs also no doubt that no one knows what the future holds, but investors are betting huge sums on that future.&lt;/p&gt;
    &lt;p&gt;In that connection, I want to say a little about the unique nature of AI. The AI revolution is different from the technological revolutions that preceded it in ways that are both wonderful and worrisome. It feels to me like a genie has been released from a bottle, and it isn‚Äôt going back in:&lt;/p&gt;
    &lt;p&gt;AI may not be a tool for mankind, but rather something of a replacement. It may be capable of taking over cognition, on which humans have thus far had a monopoly. Because of this, it‚Äôs likely to be different in kind from prior developments, not just in degree. (More on this in my postscript.)&lt;/p&gt;
    &lt;p&gt;AI technology is progressing at an incredibly rapid clip, possibly leaving scant time for mankind to adjust. I‚Äôll provide two examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Coding, which we called ‚Äúcomputer programming‚Äù 60 years ago, is the canary in the coal mine in terms of the impact of AI. In many advanced software teams, developers no longer write the code; they type in what they want, and AI systems generate the code for them. Coding performed by AI is at a world-class level, something that wasn‚Äôt so just a year ago. According to my guide here, ‚ÄúThere is no speculation about whether or not human replacement will take place in that vertical.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;In the field of digital advertising, when users log into an app, AI engages in ‚Äúad matching,‚Äù showing them ads tailored to the preferences displayed by their prior surfing. No humans need apply to do this job.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Perhaps most importantly, the growth of demand for AI seems totally unpredictable. As one of my younger advisers explained, ‚Äúthe speed and scale of improvement mean it‚Äôs incredibly hard to forecast demand for AI. Adoption today may have nothing to do with adoption tomorrow, because a year or two from now, AI may be able to do 10x or 100x what it can do today. Thus, how can anyone say how many data centers will be needed? And how can even successful companies know how much computing capacity to contract for?‚Äù&lt;/p&gt;
    &lt;p&gt;With differences like these, how can anyone correctly judge what AI implies for the future?&lt;/p&gt;
    &lt;p&gt;* * *&lt;/p&gt;
    &lt;p&gt;One of the things occupying many observers at this juncture ‚Äì including me ‚Äì is the search for parallels to past bubbles. Here‚Äôs some historical perspective from a recent article in Wired:&lt;/p&gt;
    &lt;p&gt;AI‚Äôs closest historical analogue here may be not electric lighting but radio. When RCA started broadcasting in 1919, it was immediately clear that it had a powerful information technology on its hands. But less clear was how that would translate into business. ‚ÄúWould radio be a loss-leading marketing for department stores? A public service for broadcasting Sunday sermons? An ad-supported medium for entertainment?‚Äù [Brent Goldfarb and David A. Kirsch of the University of Maryland] write. ‚ÄúAll were possible. All were subjects of technological narratives.‚Äù As a result, radio turned into one of the biggest bubbles in history ‚Äì peaking in 1929, before losing 97 percent of its value in the crash. This wasn‚Äôt an incidental sector; RCA was, along with Ford Motor Company, the most high-traded stock on the market. It was, as The New Yorker recently wrote, ‚Äúthe Nvidia of its day.‚Äù . . .&lt;/p&gt;
    &lt;p&gt;In 1927, Charles Lindbergh flew the first solo nonstop transatlantic flight from New York to Paris. . . . It was the biggest tech demo of the day, and it became an enormous, ChatGPT-launch-level coordinating event ‚Äì a signal to investors to pour money into the industry.&lt;/p&gt;
    &lt;p&gt;‚ÄúExpert investors appreciated correctly the importance of airplanes and air travel,‚Äù Goldfarb and Kirsch write, but ‚Äúthe narrative of inevitability largely drowned out their caution. Technological uncertainty was framed as opportunity, not risk. The market overestimated how quickly the industry would achieve technological viability and profitability.‚Äù&lt;/p&gt;
    &lt;p&gt;As a result, the bubble burst in 1929 ‚Äì from its peak in May, aviation stocks dropped 96 percent by May 1932. . . .&lt;/p&gt;
    &lt;p&gt;It‚Äôs worth reiterating that two of the closest analogs AI seems to have in tech bubble history are aviation and broadcast radio. Both were wrapped in high degrees of uncertainty and both were hyped with incredibly powerful coordinating narratives. Both were seized on by pure play companies seeking to capitalize on the new game-changing tech, and both were accessible to the retail investors of the day. Both helped inflate a bubble so big that when it burst, in 1929, it left us with the Great Depression. (‚ÄúAI Is the Bubble to Burst Them All,‚Äù Brian Merchant, Wired, October 27 ‚Äì emphasis added. N.b., the Depression had many causes beyond the bursting of the radio/aviation bubble.)&lt;/p&gt;
    &lt;p&gt;Derek Thompson, who supplied the quote with which I opened this memo, ended his newsletter with some terrific historical perspective:&lt;/p&gt;
    &lt;p&gt;The railroads were a bubble and they transformed America. Electricity was a bubble, and it transformed America. The broadband build-out of the late-1990s was a bubble that transformed America. I am not rooting for a bubble, and quite the contrary, I hope that the US economy doesn‚Äôt experience another recession for many years. But given the amount of debt now flowing into AI data center construction, I think it‚Äôs unlikely that AI will be the first transformative technology that isn‚Äôt overbuilt and doesn‚Äôt incur a brief painful correction. (‚ÄúAI Could Be the Railroad of the 21st Century. Brace Yourself.‚Äù November 4 ‚Äì emphasis added)&lt;/p&gt;
    &lt;p&gt;The skeptics readily cite ways in which today‚Äôs events are comparable to the internet bubble:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;A change-the-world technology&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Exuberant, speculative behavior&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The role of FOMO&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Suspect, circular deals&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The use of SPVs&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;$1 billion seed rounds&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The supporters have reasons why the comparison isn‚Äôt appropriate:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;An existing product for which there is strong demand&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;One billion users already (many times the number of internet users at the height of the bubble)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Well-established main players with revenues, profits, and cash flow&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The absence of an IPO craze with prices doubling in a day&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reasonable p/e ratios for the established participants&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I‚Äôll elaborate regarding the first of the proposed non-comparable factors. Unlike in the internet bubble, AI products already exist at scale, the demand for them is exploding, and they‚Äôre producing revenues in rapidly increasing amounts. For example, Anthropic, one of the two leaders in producing models for AI coding as described on page 12, is said to have ‚Äú10x-ed‚Äù its revenues in each of the last two years (for those who didn‚Äôt study higher math, that‚Äôs 100x in two years). Revenues from Claude Code, a program for coding that Anthropic introduced earlier this year, already are said to be running at an annual rate of $1 billion. Revenues for the other leader, Cursor, were $1 million in 2023 and $100 million in 2024, and they, too, are expected to reach $1 billion this year.&lt;/p&gt;
    &lt;p&gt;As to the final bullet point, see the table below, which comes from Goldman Sachs via Derek Thompson. You‚Äôll notice that during the internet bubble of 1998-2000, the p/e ratios were much higher for Microsoft, Cisco, and Oracle than they are today for the biggest AI players ‚Äì Nvidia, Microsoft, Alphabet, Amazon, and Meta (OpenAI doesn‚Äôt have earnings). In fact, Microsoft‚Äôs on a half-off sale relative to its p/e 26 years ago! In the first bubble I witnessed ‚Äì surrounding the Nifty-Fifty in 1969-72 ‚Äì the p/e ratios for the leading companies were even higher than those of 1998-2000.&lt;/p&gt;
    &lt;p&gt;In Conclusion&lt;/p&gt;
    &lt;p&gt;For my final citation, I‚Äôll look to Sam Altman of OpenAI. His comments seem to me to capture the essence of what‚Äôs going on:&lt;/p&gt;
    &lt;p&gt;‚ÄúWhen bubbles happen, smart people get overexcited about a kernel of truth,‚Äù Mr. Altman told reporters this year. ‚ÄúAre we in a phase where investors as a whole are overexcited about A.I.? My opinion is yes. Is A.I. the most important thing to happen in a very long time? My opinion is also yes.‚Äù (The New York Times, November 20)&lt;/p&gt;
    &lt;p&gt;But do I have a bottom line? Yes, I do. Alan Greenspan‚Äôs phrase, mentioned earlier, serves as an excellent way to sum up a stock market bubble: ‚Äúirrational exuberance.‚Äù There is no doubt that investors are applying exuberance with regard to AI. The question is whether it‚Äôs irrational. Given the vast potential of AI but also the large number of enormous unknowns, I think virtually no one can say for sure. We can theorize about whether the current enthusiasm is excessive, but we won‚Äôt know until years from now whether it was. Bubbles are best identified in retrospect.&lt;/p&gt;
    &lt;p&gt;While the parallels to past bubbles are inescapable, believers in the technology will argue that ‚Äúthis time it‚Äôs different.‚Äù Those four words are heard in virtually every bubble, explaining why the present situation isn‚Äôt a bubble, unlike the analogous prior ones. On the other hand, Sir John Templeton, who in 1987 drew my attention to those four words, was quick to point out that 20% of the time things really are different. But on the third hand, it must be borne in mind that behavior based on the belief that it‚Äôs different is what causes it to not be different!&lt;/p&gt;
    &lt;p&gt;Today‚Äôs situation calls to mind a comment attributed to American economist Stuart Chase about faith. I believe it‚Äôs also applicable to AI (as well as to gold and cryptocurrencies):&lt;/p&gt;
    &lt;p&gt;For those who believe, no proof is necessary. For those who don't believe, no proof is possible.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs my actual bottom line:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;There‚Äôs a consistent history of transformational technologies generating excessive enthusiasm and investment, resulting in more infrastructure than is needed and asset prices that prove to have been too high. The excesses accelerate the adoption of the technology in a way that wouldn‚Äôt occur in their absence. The common word for these excesses is ‚Äúbubbles.‚Äù&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;AI has the potential to be one of the greatest transformational technologies of all time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;As I wrote just above, AI is currently the subject of great enthusiasm. If that enthusiasm doesn‚Äôt produce a bubble conforming to the historical pattern, that will be a first.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bubbles created in this process usually end in losses for those who fuel them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The losses stem largely from the fact that the technology‚Äôs newness renders the extent and timing of its impact unpredictable. This in turn makes it easy to judge companies too positively amid all the enthusiasm and difficult to know which will emerge as winners when the dust settles.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There can be no way to participate fully in the potential benefits from the new technology without being exposed to the losses that will arise if the enthusiasm and thus investors‚Äô behavior prove to have been excessive.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The use of debt in this process ‚Äì which the high level of uncertainty usually precluded in past technological revolutions ‚Äì has the potential to magnify all of the above this time.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since no one can say definitively whether this is a bubble, I‚Äôd advise that no one should go all-in without acknowledging that they face the risk of ruin if things go badly. But by the same token, no one should stay all-out and risk missing out on one of the great technological steps forward. A moderate position, applied with selectivity and prudence, seems like the best approach.&lt;/p&gt;
    &lt;p&gt;Finally, it‚Äôs essential to bear in mind that there are no magic words in investing. These days, people promoting real estate funds say, ‚ÄúOffice buildings are so yesterday, but we‚Äôre investing in the future through data centers,‚Äù whereupon everyone nods in agreement. But data centers can be in shortage or in oversupply, and rental rates can surprise to the upside or the downside. As a result, they can be profitable . . . or not. Intelligent investment in data centers, and thus in AI ‚Äì like everything else ‚Äì requires sober, insightful judgment and skillful implementation.&lt;/p&gt;
    &lt;p&gt;December 9, 2025&lt;/p&gt;
    &lt;p&gt;P.S.: The following has nothing to do with the financial markets or the question of whether AI is the subject of a bubble. My topic is the impact of AI on society through joblessness and purposelessness. You needn‚Äôt read it ‚Äì that‚Äôs why it‚Äôs a postscript ‚Äì but it‚Äôs important to me, and I've been looking for a place to say a few words about it.&lt;/p&gt;
    &lt;p&gt;On November 18, a research note from Barclays described Fed Governor Christopher Waller as having ‚Äúhighlighted how recent stock market enthusiasm around AI has not yet translated into job creation.‚Äù This strikes me as paradoxical given my sense that one of AI‚Äôs main impacts will be to increase productivity and thus eliminate jobs. That is the source of my concern.&lt;/p&gt;
    &lt;p&gt;I view AI primarily as an incredible labor-saving device. Joe Davis, Global Chief Economist and Global Head of the Investment Strategy Group at Vanguard, says, ‚Äúfor most jobs ‚Äì likely four out of five ‚Äì AI‚Äôs impact will result in a mixture of innovation and automation, and could save about 43% of the time people currently spend on their work tasks.‚Äù (Exponential View, September 3)&lt;/p&gt;
    &lt;p&gt;I find the resulting outlook for employment terrifying. I am enormously concerned about what will happen to the people whose jobs AI renders unnecessary, or who can‚Äôt find jobs because of it. The optimists argue that ‚Äúnew jobs have always materialized after past technological advances.‚Äù I hope that‚Äôll hold true in the case of AI, but hope isn‚Äôt much to hang one‚Äôs hat on, and I have trouble figuring out where those jobs will come from. Of course, I‚Äôm not much of a futurist or a financial optimist, and that‚Äôs why it‚Äôs a good thing I shifted from equities to bonds in 1978.&lt;/p&gt;
    &lt;p&gt;The other thing the optimists say is that ‚Äúthe beneficial impact of AI on productivity will cause a huge acceleration in GDP growth.‚Äù Here I have specific quibbles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The change in GDP can be thought of as the change in hours worked times the change in output per hour (aka ‚Äúproductivity‚Äù). The role of AI in increasing productivity means it will take fewer hours worked ‚Äì meaning fewer workers ‚Äì to produce the goods we need.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Or, viewed from the other direction, maybe the boom in productivity will mean a lot more goods can be produced with the same amount of labor. But if a lot of jobs are lost to AI, how will people be able to afford the additional goods AI enables to be produced?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I find it hard to imagine a world in which AI works shoulder-to-shoulder with all the people who are employed today. How can employment not decline? AI is likely to replace large numbers of entry-level workers, people who process paper without applying judgment, and junior lawyers who scour the lawbooks for precedents. Maybe even junior investment analysts who create spreadsheets and compile presentation materials. It‚Äôs said that AI can read an MRI better than the average doctor. Driving is one of the most populous professions in America, and driverless vehicles are already arriving; where will all the people who currently drive taxis, limos, buses, and trucks find jobs?&lt;/p&gt;
    &lt;p&gt;I imagine government‚Äôs response will be something called ‚Äúuniversal basic income.‚Äù The government will simply mail checks to the millions for whom there are no jobs. But the worrier in me finds problems in this, too:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Where will the money come from for those checks? The job losses I foresee imply reduced income tax receipts and increased spending on entitlements. This puts a further burden on the declining segment of the population that is working and implies even greater deficits ahead. In this new world, will governments be able to fund ever-increasing deficits?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;And more importantly, people get a lot more from jobs than just a paycheck. A job gives them a reason to get up in the morning, imparts structure to their day, gives them a productive role in society and self-respect, and presents them with challenges, the overcoming of which provides satisfaction. How will these things be replaced? I worry about large numbers of people receiving subsistence checks and sitting around idle all day. I worry about the correlation between the loss of jobs in mining and manufacturing in recent decades and the incidence of opioid addiction and shortening of lifespans.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And by the way, if we eliminate large numbers of junior lawyers, analysts, and doctors, where will we get the experienced veterans capable of solving serious problems requiring judgment and pattern recognition honed over decades?&lt;/p&gt;
    &lt;p&gt;What jobs won‚Äôt be eliminated? What careers should our children and grandchildren prepare for? Think about the jobs that machines can‚Äôt perform. My list starts with plumbers, electricians, and masseurs ‚Äìphysical tasks. Maybe nurses will earn more than doctors because they deliver hands-on care. And what distinguishes the best artists, athletes, doctors, lawyers, and hopefully investors? I think it‚Äôs something called talent or insight, which AI might or might not be able to replicate. But how many people at the top of those professions are needed? A past presidential candidate said he would give laptops to everyone who lost their job to offshoring. How many laptop operators do we need?&lt;/p&gt;
    &lt;p&gt;Finally, I‚Äôm concerned that a small number of highly educated multi-billionaires living on the coasts will be viewed as having created technology that puts millions out of work. This promises even more social and political division than we have now, making the world ripe for populist demagoguery.&lt;/p&gt;
    &lt;p&gt;I‚Äôve seen incredible progress over the course of my lifetime, but in many ways I miss the simpler world I grew up in. I worry that this will be another big one. I get no pleasure from this recitation. Will the optimists please explain why I‚Äôm wrong?&lt;/p&gt;
    &lt;p&gt;Interestingly in this connection, Vanguard‚Äôs Joe Davis points out that more Americans are turning 65 in 2025 than in any preceding year, and that approximately 16 million baby boomers will retire between now and 2035. Could AI merely make up for that? There‚Äôs an optimistic take for you.&lt;/p&gt;
    &lt;p&gt;HM&lt;/p&gt;
    &lt;p&gt;Legal Information and Disclosures&lt;/p&gt;
    &lt;p&gt;This memorandum expresses the views of the author as of the date indicated and such views are subject to change without notice. Oaktree has no duty or obligation to update the information contained herein. Further, Oaktree makes no representation, and it should not be assumed, that past investment performance is an indication of future results. Moreover, wherever there is the potential for profit there is also the possibility of loss.&lt;/p&gt;
    &lt;p&gt;This memorandum is being made available for educational purposes only and should not be used for any other purpose. The information contained herein does not constitute and should not be construed as an offering of advisory services or an offer to sell or solicitation to buy any securities or related financial instruments in any jurisdiction. Certain information contained herein concerning economic trends and performance is based on or derived from information provided by independent third-party sources. Oaktree Capital Management, L.P. (‚ÄúOaktree‚Äù) believes that the sources from which such information has been obtained are reliable; however, it cannot guarantee the accuracy of such information and has not independently verified the accuracy or completeness of such information or the assumptions on which such information is based.&lt;/p&gt;
    &lt;p&gt;This memorandum, including the information contained herein, may not be copied, reproduced, republished, or posted in whole or in part, in any form without the prior written consent of Oaktree.&lt;/p&gt;
    &lt;p&gt;¬© 2025 Oaktree Capital Management, L.P.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.oaktreecapital.com/insights/memo/is-it-a-bubble"/><published>2025-12-10T17:30:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220794</id><title>Show HN: Automated license plate reader coverage in the USA</title><updated>2025-12-11T07:16:53.343179+00:00</updated><link href="https://alpranalysis.com"/><published>2025-12-10T17:42:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46221594</id><title>Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise</title><updated>2025-12-11T07:16:53.047240+00:00</updated><content>&lt;doc fingerprint="cd3e340a91d592ce"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computer Vision and Pattern Recognition&lt;/head&gt;&lt;p&gt; [Submitted on 9 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise in Infinite, Real-Time Terrain Generation&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:For decades, procedural worlds have been built on procedural noise functions such as Perlin noise, which are fast and infinite, yet fundamentally limited in realism and large-scale coherence. We introduce Terrain Diffusion, an AI-era successor to Perlin noise that bridges the fidelity of diffusion models with the properties that made procedural noise indispensable: seamless infinite extent, seed-consistency, and constant-time random access. At its core is InfiniteDiffusion, a novel algorithm for infinite generation, enabling seamless, real-time synthesis of boundless landscapes. A hierarchical stack of diffusion models couples planetary context with local detail, while a compact Laplacian encoding stabilizes outputs across Earth-scale dynamic ranges. An open-source infinite-tensor framework supports constant-memory manipulation of unbounded tensors, and few-step consistency distillation enables efficient generation. Together, these components establish diffusion models as a practical foundation for procedural world generation, capable of synthesizing entire planets coherently, controllably, and without limits.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Alexander Goslin [view email]&lt;p&gt;[v1] Tue, 9 Dec 2025 07:10:35 UTC (12,075 KB)&lt;/p&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.CV&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.08309"/><published>2025-12-10T18:37:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46221925</id><title>Super Mario 64 for the PS1</title><updated>2025-12-11T07:16:52.397284+00:00</updated><content>&lt;doc fingerprint="57cb9c197ca5b5c8"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a fork of the full decompilation of Super Mario 64 (J), (U), (E), and (SH).&lt;/item&gt;
      &lt;item&gt;It is heavily modified and can no longer target Nintendo 64, only PSX and PC (for debugging).&lt;/item&gt;
      &lt;item&gt;There are still many limitations.&lt;/item&gt;
      &lt;item&gt;For now, it can only build from the US version.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This repo does not include all assets necessary for compiling the game. An original copy of the game is required to extract the assets.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cool "DUAL SHOCK‚Ñ¢ Compatible" graphic mimicking the original "ÊåØÂãï„Éë„ÉÉ„ÇØÂØæÂøú" (Rumble Pak Compatible) graphic&lt;/item&gt;
      &lt;item&gt;An analog rumble signal is now produced for the DualShock's large motor, in addition to the original modulated digital signal for the small motor and for the SCPH-1150 Dual Analog Controller&lt;/item&gt;
      &lt;item&gt;Low-precision soft float implementation specially written for PSX to reduce the performance impact of floats&lt;/item&gt;
      &lt;item&gt;Large amounts of code have been adapted to use fixed point math, including the 16-bit integer vectors and matrices that are standard on PSX&lt;/item&gt;
      &lt;item&gt;Simplified rewritten render graph walker&lt;/item&gt;
      &lt;item&gt;Tessellation (up to 2x) to reduce issues with large polygons&lt;/item&gt;
      &lt;item&gt;RSP display lists are compiled just-in-time into a custom display list format that is more compact and faster to process&lt;/item&gt;
      &lt;item&gt;Display list preprocessor that removes commands we won't use and optimizes meshes (TODO: make it fix more things)&lt;/item&gt;
      &lt;item&gt;Mario's animations are compressed (from 580632 to 190324 bytes) and placed in a corner of VRAM rather than being loaded from storage (we don't have the luxury of a fast cartridge to read from in the middle of a frame)&lt;/item&gt;
      &lt;item&gt;Custom profiler&lt;/item&gt;
      &lt;item&gt;Custom texture encoder that quantizes all textures to 4 bits per pixel&lt;/item&gt;
      &lt;item&gt;Translucent circle-texture shadows replaced with subtractive hexagonal shadows, as the PSX doesn't support arbitrary translucency&lt;/item&gt;
      &lt;item&gt;(TODO) Camera system adapted to rotate with the right analog stick&lt;/item&gt;
      &lt;item&gt;(TODO) Simplified rewritten Goddard subsystem&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Floating trees (temporary issue due caused by a math rewrite)&lt;/item&gt;
      &lt;item&gt;Some of Mario's animations do not play, and may even crash the game&lt;/item&gt;
      &lt;item&gt;Music cannot be generated at build time without manually obtaining the tracks&lt;/item&gt;
      &lt;item&gt;Sound effects work but sometimes sound odd or are missing notes&lt;/item&gt;
      &lt;item&gt;The camera cannot be controlled in many levels due to the unfinished camera control implementation&lt;/item&gt;
      &lt;item&gt;Crashes when entering certain levels (due to insufficient memory?)&lt;/item&gt;
      &lt;item&gt;Ending sequence crashes on load&lt;/item&gt;
      &lt;item&gt;When reaching the bridge in the castle grounds, Mario looks up but Lakitu never comes over&lt;/item&gt;
      &lt;item&gt;Poles do not go down when pounded&lt;/item&gt;
      &lt;item&gt;Textures are loaded individually, causing long stutters and loading times&lt;/item&gt;
      &lt;item&gt;Stretched textures due to PSX limitations (the graphics preprocessor could help)&lt;/item&gt;
      &lt;item&gt;Tessellation is not good enough to fix all large polygons (the graphics preprocessor could help)&lt;/item&gt;
      &lt;item&gt;Some textures are rendered incorrectly (RSP JIT issues?)&lt;/item&gt;
      &lt;item&gt;Title screen is unfinished&lt;/item&gt;
      &lt;item&gt;Pause menu doesn't work&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build and install the mipsel-none-elf-gcc toolchain. For Arch users, it is available on AUR. (You can also install it on your system from https://github.com/malucard/poeng by running &lt;code&gt;make install-gcc&lt;/code&gt;from there. This may take a long time.)&lt;/item&gt;
      &lt;item&gt;Clone the repo: &lt;code&gt;git clone https://github.com/malucard/sm64-psx&lt;/code&gt;, which will create a directory&lt;code&gt;sm64-port&lt;/code&gt;and then enter it&lt;code&gt;cd sm64-port&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Place a Super Mario 64 ROM called &lt;code&gt;baserom.&amp;lt;VERSION&amp;gt;.z64&lt;/code&gt;into the repository's root directory for asset extraction,&lt;del rend="overstrike"&gt;where&lt;/del&gt;. (For now, only&lt;code&gt;VERSION&lt;/code&gt;can be&lt;code&gt;us&lt;/code&gt;,&lt;code&gt;jp&lt;/code&gt;, or&lt;code&gt;eu&lt;/code&gt;&lt;code&gt;us&lt;/code&gt;is supported.)&lt;/item&gt;
      &lt;item&gt;(Optional) Create a folder named &lt;code&gt;.local&lt;/code&gt;in the root of the repo and place every track of the soundtrack in it as a .wav file, numbered from 0 to 37 (0.wav, 1.wav, etc).&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make&lt;/code&gt;to build. To build the benchmark version without music, run&lt;code&gt;make BENCH=1&lt;/code&gt;. The disc image will be located at&lt;code&gt;build/&amp;lt;VERSION&amp;gt;_psx/sm64.&amp;lt;VERSION&amp;gt;.iso&lt;/code&gt;. The benchmark version will not generate an iso, only an elf and an exe, and it will require a PSX with 8MB of RAM (an emulator or a debug unit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install and update MSYS2, following all the directions listed on https://www.msys2.org/.&lt;/item&gt;
      &lt;item&gt;From the start menu, launch MSYS2 MinGW and install required packages depending on your machine (do NOT launch "MSYS2 MSYS"):&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;64-bit: Launch "MSYS2 MinGW 64-bit" and install: &lt;code&gt;pacman -S git make python3 mingw-w64-x86_64-gcc mingw-w64-x86_64-meson mingw-w64-x86_64-ffmpeg unzip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;32-bit (will also work on 64-bit machines): Launch "MSYS2 MinGW 32-bit" and install: &lt;code&gt;pacman -S git make python3 mingw-w64-i686-gcc mingw-w64-i686-meson mingw-w64-i686-ffmpeg unzip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Do NOT by mistake install the packages called simply &lt;code&gt;gcc&lt;/code&gt;and&lt;code&gt;meson&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install the mipsel-none-elf-gcc toolchain.&lt;/item&gt;
      &lt;item&gt;The MSYS2 terminal has a current working directory that initially is &lt;code&gt;C:\msys64\home\&amp;lt;username&amp;gt;&lt;/code&gt;(home directory). At the prompt, you will see the current working directory in yellow.&lt;code&gt;~&lt;/code&gt;is an alias for the home directory. You can change the current working directory to&lt;code&gt;My Documents&lt;/code&gt;by entering&lt;code&gt;cd /c/Users/&amp;lt;username&amp;gt;/Documents&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Clone the repo: &lt;code&gt;git clone https://github.com/malucard/sm64-psx&lt;/code&gt;, which will create a directory&lt;code&gt;sm64-psx&lt;/code&gt;and then enter it&lt;code&gt;cd sm64-psx&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Place a Super Mario 64 ROM called &lt;code&gt;baserom.&amp;lt;VERSION&amp;gt;.z64&lt;/code&gt;into the repository's root directory for asset extraction,&lt;del rend="overstrike"&gt;where&lt;/del&gt;. (For now, only&lt;code&gt;VERSION&lt;/code&gt;can be&lt;code&gt;us&lt;/code&gt;,&lt;code&gt;jp&lt;/code&gt;, or&lt;code&gt;eu&lt;/code&gt;&lt;code&gt;us&lt;/code&gt;is supported.)&lt;/item&gt;
      &lt;item&gt;(Optional) Create a folder named &lt;code&gt;.local&lt;/code&gt;in the root of the repo and place every track of the soundtrack in it as a .wav file, numbered from 0 to 37 (0.wav, 1.wav, etc).&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make&lt;/code&gt;to build. To build the benchmark version, run&lt;code&gt;make BENCH=1&lt;/code&gt;. The disc image will be located at&lt;code&gt;build/&amp;lt;VERSION&amp;gt;_psx/sm64.&amp;lt;VERSION&amp;gt;.iso&lt;/code&gt;. The benchmark version will not generate an iso, only an elf and an exe, and it will require a PSX with 8MB of RAM (an emulator or a debug unit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you get &lt;code&gt;make: gcc: no suitable C and C++ compiler found&lt;/code&gt;,&lt;code&gt;make: gcc: command not found&lt;/code&gt;,&lt;code&gt;make: gcc: No such file or directory&lt;/code&gt;although the packages did successfully install, you probably launched the wrong MSYS2. Read the instructions again. The terminal prompt should contain "MINGW32" or "MINGW64" in purple text, and NOT "MSYS".&lt;/item&gt;
      &lt;item&gt;If you get &lt;code&gt;Failed to open baserom.us.z64!&lt;/code&gt;you failed to place the baserom in the repository. You can write&lt;code&gt;ls&lt;/code&gt;to list the files in the current working directory. If you are in the&lt;code&gt;sm64-psx&lt;/code&gt;directory, make sure you see it here.&lt;/item&gt;
      &lt;item&gt;If you get &lt;code&gt;make: *** No targets specified and no makefile found. Stop.&lt;/code&gt;, you are not in the correct directory. Make sure the yellow text in the terminal ends with&lt;code&gt;sm64-psx&lt;/code&gt;. Use&lt;code&gt;cd &amp;lt;dir&amp;gt;&lt;/code&gt;to enter the correct directory. If you write&lt;code&gt;ls&lt;/code&gt;you should see all the project files, including&lt;code&gt;Makefile&lt;/code&gt;if everything is correct.&lt;/item&gt;
      &lt;item&gt;If you get any error, be sure MSYS2 packages are up to date by executing &lt;code&gt;pacman -Syu&lt;/code&gt;and&lt;code&gt;pacman -Su&lt;/code&gt;. If the MSYS2 window closes immediately after opening it, restart your computer.&lt;/item&gt;
      &lt;item&gt;Check if mipsel gcc is working by executing &lt;code&gt;mipsel-none-elf-gcc -v&lt;/code&gt;. If it doesn't work, you either opened the wrong MSYS start menu entry or installed the incorrect gcc package.&lt;/item&gt;
      &lt;item&gt;When switching between building on other platforms, run &lt;code&gt;make -C tools clean&lt;/code&gt;first to allow for the tools to recompile on the new platform. This also helps when switching between shells like WSL and MSYS2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sm64
‚îú‚îÄ‚îÄ actors: object behaviors, geo layout, and display lists
‚îú‚îÄ‚îÄ assets: animation and demo data
‚îÇ   ‚îú‚îÄ‚îÄ anims: animation data
‚îÇ   ‚îî‚îÄ‚îÄ demos: demo data
‚îú‚îÄ‚îÄ bin: C files for ordering display lists and textures
‚îú‚îÄ‚îÄ build: output directory
‚îú‚îÄ‚îÄ data: behavior scripts, misc. data
‚îú‚îÄ‚îÄ doxygen: documentation infrastructure
‚îú‚îÄ‚îÄ enhancements: example source modifications
‚îú‚îÄ‚îÄ include: header files
‚îú‚îÄ‚îÄ levels: level scripts, geo layout, and display lists
‚îú‚îÄ‚îÄ lib: N64 SDK code
‚îú‚îÄ‚îÄ sound: sequences, sound samples, and sound banks
‚îú‚îÄ‚îÄ src: C source code for game
‚îÇ   ‚îú‚îÄ‚îÄ audio: audio code
‚îÇ   ‚îú‚îÄ‚îÄ buffers: stacks, heaps, and task buffers
‚îÇ   ‚îú‚îÄ‚îÄ engine: script processing engines and utils
‚îÇ   ‚îú‚îÄ‚îÄ game: behaviors and rest of game source
‚îÇ   ‚îú‚îÄ‚îÄ goddard: rewritten Mario intro screen
‚îÇ   ‚îú‚îÄ‚îÄ goddard_og: backup of original Mario intro screen
‚îÇ   ‚îú‚îÄ‚îÄ menu: title screen and file, act, and debug level selection menus
‚îÇ   ‚îî‚îÄ‚îÄ port: port code, audio and video renderer
‚îú‚îÄ‚îÄ text: dialog, level names, act names
‚îú‚îÄ‚îÄ textures: skybox and generic texture data
‚îî‚îÄ‚îÄ tools: build tools
&lt;/code&gt;
    &lt;p&gt;Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/malucard/sm64-psx"/><published>2025-12-10T18:58:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46222165</id><title>The future of Terraform CDK</title><updated>2025-12-11T07:16:51.743699+00:00</updated><content>&lt;doc fingerprint="9510f5515e5f62fb"&gt;
  &lt;main&gt;
    &lt;p&gt;Terraform CDK (CDKTF) will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date. Unfortunately, Terraform CDK did not find product-market fit at scale. HashiCorp, an IBM Company, has chosen to focus its investments on Terraform core and its broader ecosystem.&lt;/p&gt;
    &lt;p&gt;As of December 10, 2025, Terraform CDK will be archived on GitHub, and the documentation will reflect its deprecated status. The archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements (including compatibility updates) will be made.&lt;/p&gt;
    &lt;p&gt;You will be able to continue to use Terraform CDK at your own risk. Terraform CDK is licensed under the Mozilla Public License (MPL). HashiCorp, an IBM Company, does not apply any additional restrictions. We encourage community forks if there‚Äôs interest in continuing development independently.&lt;/p&gt;
    &lt;p&gt;You can use the following command to generate Terraform-compatible .tf files directly from your Terraform CDK project:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;cdktf synth --hcl&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;This will produce readable HCL configuration files, making it easier to migrate away from Terraform CDK. After running the command, you can use standard Terraform CLI commands (&lt;code&gt;terraform init&lt;/code&gt;, &lt;code&gt;terraform plan&lt;/code&gt;, &lt;code&gt;terraform apply&lt;/code&gt;) to continue managing your infrastructure. Please note that while this helps bootstrap your configuration, you may still need to review and adjust the generated files for clarity, organization, or best practices.&lt;/p&gt;
    &lt;p&gt;If your infrastructure is defined in Terraform CDK but also tightly integrated with AWS CDK, you may find it more consistent to migrate directly to the AWS CDK ecosystem. If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment.&lt;/p&gt;
    &lt;p&gt;Q: Is CDKTF still being developed?&lt;/p&gt;
    &lt;p&gt;A: No. CDKTF will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date.&lt;/p&gt;
    &lt;p&gt;Q: Why is CDKTF being sunset?&lt;/p&gt;
    &lt;p&gt;A: CDKTF did not find product-market fit at scale. We‚Äôve chosen to focus our investments on Terraform core and its broader ecosystem.&lt;/p&gt;
    &lt;p&gt;Q: Will CDKTF be removed from GitHub?&lt;/p&gt;
    &lt;p&gt;A: CDKTF will be archived on GitHub, and documentation will reflect its deprecated status.&lt;/p&gt;
    &lt;p&gt;Q: Can I still use CDKTF after it's sunset?&lt;/p&gt;
    &lt;p&gt;A: Yes, the archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements will be made.&lt;/p&gt;
    &lt;p&gt;Q: Will CDKTF continue to support new versions of Terraform or providers?&lt;/p&gt;
    &lt;p&gt;A: No. Compatibility updates will not be made after the EOL date.&lt;/p&gt;
    &lt;p&gt;Q: Can I fork CDKTF and maintain it myself?&lt;/p&gt;
    &lt;p&gt;A: Yes. CDKTF is open source, and we encourage community forks if there‚Äôs interest in continuing development independently.&lt;/p&gt;
    &lt;p&gt;Q: Can I keep using CDKTF?&lt;/p&gt;
    &lt;p&gt;A: You may continue to use it at your own risk. HashiCorp, an IBM Company, will no longer be maintaining it.&lt;/p&gt;
    &lt;p&gt;Q: Is there a migration tool?&lt;/p&gt;
    &lt;p&gt;A: You can use the following command to generate Terraform-compatible .tf files directly from your CDKTF project:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;cdktf synth --hcl&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;This will produce readable HCL configuration files, making it easier to migrate away from CDKTF. After running the command, you can use standard Terraform CLI commands (terraform init, terraform plan, terraform apply) to continue managing your infrastructure. Please note that while this helps bootstrap your configuration, you may still need to review and adjust the generated files for clarity, organization, or best practices.&lt;/p&gt;
    &lt;p&gt;Q: What migration guidance can we provide to customers?&lt;/p&gt;
    &lt;p&gt;A: For users looking to migrate away from CDKTF:&lt;/p&gt;
    &lt;p&gt;If your infrastructure is defined in CDKTF but also tightly integrated with AWS CDK, you may find it more consistent to migrate directly to the AWS CDK ecosystem.&lt;/p&gt;
    &lt;p&gt;If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment.&lt;/p&gt;
    &lt;p&gt;Cloud Development Kit for Terraform (CDKTF) allows you to use familiar programming languages to define cloud infrastructure and provision it through HashiCorp Terraform. This gives you access to the entire Terraform ecosystem without learning HashiCorp Configuration Language (HCL) and lets you leverage the power of your existing toolchain for testing, dependency management, etc.&lt;/p&gt;
    &lt;p&gt;We currently support TypeScript, Python, Java, C#, and Go.&lt;/p&gt;
    &lt;p&gt;CDKTF includes two packages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;cdktf-cli - A CLI that allows users to run commands to initialize, import, and synthesize CDK for Terraform applications.&lt;/item&gt;
      &lt;item&gt;cdktf - A library for defining Terraform resources using programming constructs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Choose a language:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hands-on: Try the tutorials in the CDK for Terraform collection on HashiCorp Learn.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Refer to the CDKTF documentation for more detail about how to build and manage CDKTF applications, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Application Architecture: Learn the tools and processes that CDKTF uses to leverage the Terraform ecosystem and convert code into Terraform configuration files. It also explains the major components of a CDKTF application and how those pieces fit together.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Project Setup: Learn how to create a new CDKTF project from a pre-built or custom template. Also learn how to convert an existing HCL project into a CDKTF application.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unit Tests: Learn how to test your application in Typescript with jest.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Examples: Reference example projects in every supported language and review explanatory videos and other resources.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The development team would love your feedback to help guide the project.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Contribute using the CONTRIBUTING.md guide.&lt;/item&gt;
      &lt;item&gt;Ask a question on the HashiCorp Discuss using the terraform-cdk category.&lt;/item&gt;
      &lt;item&gt;Report a bug or request a new feature.&lt;/item&gt;
      &lt;item&gt;Browse all open issues.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For prerequisites, refer to the following.&lt;/p&gt;
    &lt;p&gt;Clone the project repository.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/hashicorp/terraform-cdk.git&lt;/code&gt;
    &lt;p&gt;Download dependencies.&lt;/p&gt;
    &lt;code&gt;cd terraform-cdk/
yarn install&lt;/code&gt;
    &lt;p&gt;Build the project and packages.&lt;/p&gt;
    &lt;code&gt;yarn build&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/hashicorp/terraform-cdk"/><published>2025-12-10T19:14:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46223311</id><title>Getting a Gemini API key is an exercise in frustration</title><updated>2025-12-11T07:16:51.652934+00:00</updated><content>&lt;doc fingerprint="3956b1cd9b3799d1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Getting a Gemini API key is an exercise in frustration&lt;/head&gt;
    &lt;p&gt;Last week, I started working on a new side-project. It‚Äôs a standard React app partly made up of run-of-the-mill CRUD views‚Äîa perfect fit for LLM-assisted programming. I reasoned that if I could get an LLM to quickly write the boring code for me, I‚Äôd have more time to focus on the interesting problems I wanted to solve.&lt;/p&gt;
    &lt;p&gt;I‚Äôve pretty much settled on Claude Code as my coding assistant of choice, but I‚Äôd been hearing great things about Google‚Äôs Gemini 3 Pro. Despite my aversion to Google products, I decided to try it out on my new codebase.&lt;/p&gt;
    &lt;p&gt;I already had Gemini CLI installed, but that only gave me access to Gemini 2.5 with rate limits. I wanted to try out Gemini 3 Pro, and I wanted to avoid being rate limited. I had some spare cash to burn on this experiment, so I went looking for ways to pay for a Gemini Pro plan, if such a thing existed.&lt;/p&gt;
    &lt;p&gt;Thus began my grand adventure in trying to give Google my money.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is a Gemini, really?&lt;/head&gt;
    &lt;p&gt;The name ‚ÄúGemini‚Äù is so overloaded that it barely means anything. Based on the context, Gemini could refer to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The chatbot available at gemini.google.com.&lt;/item&gt;
      &lt;item&gt;The mobile app that lets you use the same Gemini chatbot on your iPhone or Android.&lt;/item&gt;
      &lt;item&gt;The voice assistant on Android phones.&lt;/item&gt;
      &lt;item&gt;The AI features built into Google Workspace, Firebase, Colab, BigQuery, and other Google products.&lt;/item&gt;
      &lt;item&gt;Gemini CLI, an agentic coding tool for your terminal that works the same way as Claude Code or OpenAI Codex.&lt;/item&gt;
      &lt;item&gt;The Gemini Code Assist suite of products, which includes extensions for various IDEs, a GitHub app, and Gemini CLI.&lt;/item&gt;
      &lt;item&gt;The underlying LLM powering all these products.&lt;/item&gt;
      &lt;item&gt;Probably three more products by the time I finish writing this blog post.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To make things even more confusing, Google has at least three different products just for agentic coding: Gemini Code Assist (Gemini CLI is a part of this suite of products), Jules, and Antigravity.&lt;/p&gt;
    &lt;p&gt;And then there‚Äôs a bunch of other GenAI stuff that is powered by Gemini but doesn‚Äôt have the word Gemini in the name: Vertex AI Platform, Google AI Studio, NotebookLM, and who knows what else.&lt;/p&gt;
    &lt;p&gt;I just wanted to plug my credit card information into a form and get access to a coding assistant. Instead, I was dunked into an alphabet soup of products that all seemed to do similar things and, crucially, didn‚Äôt have any giant ‚ÄúBuy Now!‚Äù buttons for me to click.&lt;/p&gt;
    &lt;p&gt;In contrast, both Anthropic and OpenAI have two primary ways you can access their products: via their consumer offerings at claude.ai and chatgpt.com respectively, or via API credits that you can buy through their respective developer consoles. In each case, there is a form field where you can plug in your credit card details, and a big, friendly ‚ÄúBuy Now!‚Äù button to click.&lt;/p&gt;
    &lt;p&gt;After half an hour of searching the web, I did the obvious thing and asked the free version of Gemini (the chatbot, not one of those other Geminis) what to do:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;How do I pay for the pro version of Gemini so i can use it in the terminal for writing code? I specifically want to use the Gemini 3 Pro model.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It thought for a suspiciously long time and told me that Gemini 3 Pro required a developer API key to use. Since the new model is still in preview, it‚Äôs not yet available on any of the consumer plans. When I asked follow up questions about pricing, it told me that ‚ÄúSomething went wrong‚Äù. Which translates to: we broke something, but we won‚Äôt tell you how to fix it.&lt;/p&gt;
    &lt;p&gt;So I asked Claude for help. Between the two LLMs, I was able to figure out how to create an API key for the Gemini I wanted.&lt;/p&gt;
    &lt;head rend="h2"&gt;Creating an API key is easy&lt;/head&gt;
    &lt;p&gt;Google AI Studio is supposed to be the all-in-one dashboard for Google‚Äôs generative AI models. This is where you can experiment with model parameters, manage API keys, view logs, and manage billing for your projects.&lt;/p&gt;
    &lt;p&gt;I logged into Google AI Studio and created a new API key. This part was pretty straightforward: I followed the on-screen instructions and had a fresh new key housed under a project in a few seconds. I then verified that my key was working with Gemini CLI.&lt;/p&gt;
    &lt;p&gt;It worked! Now all that was left to do was to purchase some API credits. Back in Google AI Studio, I saw a link titled ‚ÄúSet up billing‚Äù next to my key. It looked promising, so I clicked it.&lt;/p&gt;
    &lt;p&gt;That‚Äôs where the fun really began.&lt;/p&gt;
    &lt;head rend="h2"&gt;Google doesn‚Äôt want my money&lt;/head&gt;
    &lt;p&gt;The ‚ÄúSet up billing‚Äù link kicked me out of Google AI Studio and into Google Cloud Console, and my heart sank. Every time I‚Äôve logged into Google Cloud Console or AWS, I‚Äôve wasted hours upon hours reading outdated documentation, gazing in despair at graphs that make no sense, going around in circles from dashboard to dashboard, and feeling a strong desire to attain freedom from this mortal coil.&lt;/p&gt;
    &lt;p&gt;Turns out I can‚Äôt just put $100 into my Gemini account. Instead, I must first create a Billing Account. After I‚Äôve done that, I must associate it with a project. Then I‚Äôm allowed to add a payment method to the Billing Account. And then, if I‚Äôm lucky, my API key will turn into a paid API key with Gemini Pro privileges.&lt;/p&gt;
    &lt;p&gt;So I did the thing. The whole song and dance. Including the mandatory two-factor OTP verification that every Indian credit card requires. At the end of the process, I was greeted with a popup telling me I had to verify my payment method before I‚Äôd be allowed to use it.&lt;/p&gt;
    &lt;p&gt;Wait. Didn‚Äôt I just verify my payment method? When I entered the OTP from my bank?&lt;/p&gt;
    &lt;p&gt;Nope, turns out Google hungers for more data. Who‚Äôd have thunk it?&lt;/p&gt;
    &lt;p&gt;To verify my payment method for reals, I had to send Google a picture of my government-issued ID and the credit card I‚Äôd just associated with my Billing Account. I had to ensure all the numbers on my credit card were redacted by manually placing black bars on top of them in an image editor, leaving only my name and the last four digits of the credit card number visible.&lt;/p&gt;
    &lt;p&gt;This felt unnecessarily intrusive. But by this point, I was too deep in the process to quit. I was invested. I needed my Gemini 3 Pro, and I was willing to pay any price.&lt;/p&gt;
    &lt;p&gt;The upload form for the government ID rejected my upload twice before it finally accepted it. It was the same exact ID every single time, just in different file formats. It wanted a PNG file. Not a JPG file, nor a PDF file, but a PNG file. Did the upload form mention that in the instructions? Of course not.&lt;/p&gt;
    &lt;p&gt;After jumping through all these hoops, I received an email from Google telling me that my verification will be completed in a few days.&lt;/p&gt;
    &lt;p&gt;A few days? Nothing to do but wait, I suppose.&lt;/p&gt;
    &lt;head rend="h2"&gt;403 Forbidden&lt;/head&gt;
    &lt;p&gt;At this point, I closed all my open Cloud Console tabs and went back to work. But when I was fifteen minutes into writing some code by hand like a Neanderthal, I received a second email from Google telling me that my verification was complete.&lt;/p&gt;
    &lt;p&gt;So for the tenth time that day, I navigated to AI Studio. For the tenth time I clicked ‚ÄúSet up billing‚Äù on the page listing my API keys. For the tenth time I was told that my project wasn‚Äôt associated with a billing account. For the tenth time I associated the project with my new billing account. And finally, after doing all of this, the ‚ÄúQuota tier‚Äù column on the page listing my API keys said ‚ÄúTier 1‚Äù instead of ‚ÄúSet up billing‚Äù.&lt;/p&gt;
    &lt;p&gt;Wait, Tier 1? Did that mean there were other tiers? What were tiers, anyway? Was I already on the best tier? Or maybe I was on the worst one? Not important. The important part was that I had my API key and I‚Äôd managed to convince Google to charge me for it.&lt;/p&gt;
    &lt;p&gt;I went back to the Gemini CLI, ran the &lt;code&gt;/settings&lt;/code&gt; command, and turned on the ‚ÄúEnable experimental features‚Äù option. I ran the &lt;code&gt;/models&lt;/code&gt; command, which told me that Gemini 3 Pro was now available.&lt;/p&gt;
    &lt;p&gt;Success? Not yet.&lt;/p&gt;
    &lt;p&gt;When I tried sending a message to the LLM, it failed with this 403 error:&lt;/p&gt;
    &lt;code&gt;{
  "error": {
    "message": "{\n  \"error\": {\n    \"code\": 403,\n    \"message\": \"The caller does not have permission\",\n    \"status\":\"PERMISSION_DENIED\"\n  }\n}\n",
    "code": 403,
    "status": "Forbidden"
  }
}&lt;/code&gt;
    &lt;p&gt;Is that JSON inside a string inside JSON? Yes. Yes it is.&lt;/p&gt;
    &lt;p&gt;To figure out if my key was even working, I tried calling the Gemini API from JavaScript, reproducing the basic example from Google‚Äôs own documentation.&lt;/p&gt;
    &lt;p&gt;No dice. I ran into the exact same error.&lt;/p&gt;
    &lt;p&gt;I then tried talking to Gemini 3 Pro using the Playground inside Google AI Studio. It showed me a toast message saying &lt;code&gt;Failed to generate content. Please try again.&lt;/code&gt; The chat transcript said &lt;code&gt;An internal error has occurred.&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;At this point I gave up and walked away from my computer. It was already 8pm. I‚Äôd been trying to get things to work since 5pm. I needed to eat dinner, play Clair Obscur, and go to bed. I had no more time to waste and no more fucks to give.&lt;/p&gt;
    &lt;head rend="h2"&gt;Your account is in good standing at this time&lt;/head&gt;
    &lt;p&gt;Just as I was getting into bed, I received an email from Google with this subject line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Your Google Cloud and APIs billing account XXXXXX-XXXXXX-XXXXXX is in good standing at this time.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;With the message inside saying:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Based on the information you provided and further analysis by Google, we have reinstated your billing account XXXXXX-XXXXXX-XXXXXX. Your account is in good standing, and you should now have full access to your account and related Project(s) and Service(s).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I have no idea what any of this means, but Gemini 3 Pro started working correctly after I received this email. It worked in the Playground, directly by calling the API from JavaScript, and with Gemini CLI.&lt;/p&gt;
    &lt;p&gt;Problem solved, I guess. Until Google mysteriously decides that my account is no longer in good standing.&lt;/p&gt;
    &lt;head rend="h2"&gt;This was a waste of time&lt;/head&gt;
    &lt;p&gt;This was such a frustrating experience that I still haven‚Äôt tried using Gemini with my new codebase, nearly a week after I made all those sacrifices to the Gods of Billing Account.&lt;/p&gt;
    &lt;p&gt;I understand why the process for getting a Gemini API key is so convoluted. It‚Äôs designed for large organizations, not an individual developers trying to get work done; it serves the bureaucracy, not the people doing the work; it‚Äôs designed for maximum compliance with government regulations, not for efficiency or productivity.&lt;/p&gt;
    &lt;p&gt;Google doesn‚Äôt want my money unless I‚Äôm an organization that employs ten thousand people.&lt;/p&gt;
    &lt;p&gt;In contrast to Google, Anthropic and OpenAI are much smaller and much more nimble. They‚Äôre able to make the process of setting up a developer account quick and easy for those of us who just want to get things done. Unlike Google, they haven‚Äôt yet become complacent. They need to compete for developer mindshare if they are to survive a decade into the future. Maybe they‚Äôll add the same level of bureaucracy to their processes as they become larger, but for now they‚Äôre fairly easy to deal with.&lt;/p&gt;
    &lt;p&gt;I‚Äôm still going to try using Gemini 3 Pro with Gemini CLI as my coding assistant, but I‚Äôll probably cap the experiment to a month. Unless Gemini 3 Pro is a massive improvement over its competitors, I‚Äôll stick to using tools built by organizations that want me as a customer.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ankursethi.com/blog/gemini-api-key-frustration/"/><published>2025-12-10T20:29:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46224311</id><title>When would you ever want bubblesort? (2023)</title><updated>2025-12-11T07:16:50.461186+00:00</updated><content>&lt;doc fingerprint="727c103438e80f1f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;When would you ever want bubblesort?&lt;/head&gt;
    &lt;p&gt;There are very few universal rules in software engineering, but there are are a lot of near-universal principles. Things like "prefer composition to inheritance" is near-universal. I love finding the rare situations where these principles don't hold, like where you do want inheritance over composition. A similar near-universal principle is "don't use bubblesort". Some would even say it's a universal rule, with Donald Knuth writing "bubble sort seems to have nothing to recommend it, except a catchy name and the fact that it leads to some interesting theoretical problems".1 But Knuth's been wrong before, so let's see if this universal rule is only near-universal.&lt;/p&gt;
    &lt;p&gt;Theoretically, bubblesort is faster than quick or mergesort for small arrays. This makes it useful as part of a larger sorting strategy: most of the fast-in-principle sorting algorithms work by recursively sorting subpartitions of an array, ie if you apply quicksort to 2^20 random integers, at some point you're sorting 2^17 8-integer subpartitions. Switching over to bubblesort for those subpartitions would be a nice optimization.&lt;/p&gt;
    &lt;p&gt;Many production sorting algorithms do use a hybrid approach, but they overwhelmingly use insertion sort instead. Insertion sort is very fast for small arrays and it's also better at using the hardware. On some very particular hardwares bubblesort stills ends up better, like in this NVIDIA study, but you probably don't have that hardware.&lt;/p&gt;
    &lt;p&gt;So that's one use-case, albeit one still dominated by a different algorithm. It's interesting that NVIDIA used it here because gamedev has a situation that's uniquely useful to bubblesort, based on two of its properties:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;While the algorithm is very slow overall, each individual step is very fast and easily suspendable.&lt;/item&gt;
      &lt;item&gt;Each swap leaves the array more ordered than it was before. Other sorts can move values away from their final positions in intermediate stages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This makes it really good when you want to do a fixed amount of sorting work per frame. Say you have a bunch of objects on a screen, where some objects can occlude others. You want to render the objects closest to the camera first because then you can determine which objects it hides, and then save time rendering those objects. There's no correctness cost for rendering objects out of order, just a potential performance cost. So while your array doesn't need to be ordered, the more ordered it is the happier you are. But you also can't spend too much time running a sorting algorithm, because you have a pretty strict realtime constraint. Bubble sort works pretty well here. You can run it a little bit of a time at each frame and get a better ordering than when you started.&lt;/p&gt;
    &lt;p&gt;That reminds me of one last use-case I've heard, apocryphally. Let's say you have a random collection of randomly-colored particles, and you want to animate them sorting into a rainbow spectrum. If you make each frame of the animation one pass of bubblesort, the particles will all move smoothly into the right positions. I couldn't find any examples in the wild, so with the help of GPT4 I hammered out a crappy visualization. Code is here, put it here.&lt;/p&gt;
    &lt;p&gt;(After doing that I suspect this isn't actually done in practice, in favor of running a better sort to calculate each particles final displacement and then animating each particles moving directly, instead of waiting to move for each bubblesort pass. I haven't mocked out an example but I think that'd look a lot smoother.)&lt;/p&gt;
    &lt;p&gt;So there you go, three niche use cases for bubblesort. You'll probably never need it.&lt;/p&gt;
    &lt;head rend="h3"&gt;New Quanta Article!&lt;/head&gt;
    &lt;p&gt;Okay so I didn't actually write this one, but I played a role in it happening! A while back a friend visited, and we were chatting about his job at quanta. At the time he was working on this mammoth article on metacomplexity theory, so naturally the topic of problems harder than NP-complete came up and I recommend he check out Petri net reachability. So he did, and then he wrote An Easy-Sounding Problem Yields Numbers Too Big for Our Universe. Gosh this is so exciting!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://buttondown.com/hillelwayne/archive/when-would-you-ever-want-bubblesort/"/><published>2025-12-10T21:45:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46226483</id><title>Patterns.dev</title><updated>2025-12-11T07:16:50.262000+00:00</updated><content>&lt;doc fingerprint="ed186110298694bb"&gt;
  &lt;main&gt;
    &lt;p&gt;Interested in our next book? Learn more about Building Large-scale JavaScript Web Apps with React&lt;/p&gt;
    &lt;p&gt;Patterns.dev is a free online resource on design, rendering, and performance patterns for building powerful web apps with vanilla JavaScript or modern frameworks.&lt;/p&gt;
    &lt;p&gt;We publish patterns, tips and tricks for improving how you architect apps for free. Keep in mind, design patterns are descriptive, not prescriptive . They can guide you when facing a problem other developers have encountered many times before, but are not a blunt tool for jamming into every scenario. Patterns.dev aims to be a catalog of patterns (for increasing awareness) rather than a checklist (what you must do).&lt;/p&gt;
    &lt;p&gt;Design patterns are a fundamental part of software development, as they provide typical solutions to commonly recurring problems in software design.&lt;/p&gt;
    &lt;p&gt;A common critique of design patterns is that they needlessly add complexity.&lt;/p&gt;
    &lt;p&gt;Our perspective is that patterns are valuable for solving specific problems, often helping to communicate comminalities in code problems for humans. If a project doesn't have those problems, there isn't a need to apply them. Patterns can also be very language or framework-specific (e.g. React), which can often mean thinking beyond the scope of just the original GoF design patterns.&lt;/p&gt;
    &lt;p&gt;Learn about web performance patterns for loading your code more efficiently. Unsure how to think about modern approaches to loading or rendering user-experiences? We've got you covered.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.patterns.dev/"/><published>2025-12-11T01:18:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46227619</id><title>Incomplete list of mistakes in the design of CSS</title><updated>2025-12-11T07:16:50.021072+00:00</updated><content>&lt;doc fingerprint="3f4ffa43dd2d5fa3"&gt;
  &lt;main&gt;&lt;p&gt;That should be corrected if anyone invents a time machine. :P&lt;/p&gt;&lt;code&gt;white-space: nowrap&lt;/code&gt; should be &lt;code&gt;white-space: no-wrap&lt;/code&gt;&lt;code&gt;white-space&lt;/code&gt;&lt;code&gt;animation-iteration-count&lt;/code&gt; should just have been &lt;code&gt;animation-count&lt;/code&gt; (like &lt;code&gt;column-count&lt;/code&gt;!)&lt;code&gt;vertical-align&lt;/code&gt; should not apply to table cells. Instead the CSS3 alignment properties should exist in Level 1.&lt;code&gt;vertical-align: middle&lt;/code&gt; should be &lt;code&gt;text-middle&lt;/code&gt; or &lt;code&gt;x-middle&lt;/code&gt; because it's not really in the middle, and such a name would better describes what it does.&lt;code&gt;fill-available&lt;/code&gt; rather than being undefined in auto situations.&lt;code&gt;border-box&lt;/code&gt; by default.&lt;code&gt;background-size&lt;/code&gt; with one value should duplicate its value, not default the second one to &lt;code&gt;auto&lt;/code&gt;. Ditto &lt;code&gt;translate()&lt;/code&gt;.&lt;code&gt;background-position&lt;/code&gt; and &lt;code&gt;border-spacing&lt;/code&gt; (all 2-axis properties) should take *vertical* first, to match with the 4-direction properties like &lt;code&gt;margin&lt;/code&gt;.&lt;code&gt;margin&lt;/code&gt; should go counter-clockwise (so that the inline-start value is before the block-end and inline-end values instead of after them).&lt;code&gt;z-index&lt;/code&gt; should be called &lt;code&gt;z-order&lt;/code&gt; or &lt;code&gt;depth&lt;/code&gt; and should Just Work on all elements (like it does on flex items).&lt;code&gt;word-wrap&lt;/code&gt;/&lt;code&gt;overflow-wrap&lt;/code&gt; should not exist. Instead, &lt;code&gt;overflow-wrap&lt;/code&gt; should be a keyword on 'white-space', like &lt;code&gt;nowrap&lt;/code&gt; (&lt;code&gt;no-wrap&lt;/code&gt;).&lt;code&gt;currentColor&lt;/code&gt; keyword should have retained the dash, &lt;code&gt;current-color&lt;/code&gt;, as originally specified. Likewise all other color multi-word keyword names.&lt;code&gt;border-radius&lt;/code&gt; should have been &lt;code&gt;corner-radius&lt;/code&gt;.&lt;code&gt;hyphens&lt;/code&gt; property should be called &lt;code&gt;hyphenate&lt;/code&gt;. (It's called &lt;code&gt;hyphens&lt;/code&gt; because the XSL:FO people objected to &lt;code&gt;hyphenate&lt;/code&gt;.)&lt;code&gt;rgba()&lt;/code&gt; and &lt;code&gt;hsla()&lt;/code&gt; should not exist, &lt;code&gt;rgb()&lt;/code&gt; and &lt;code&gt;hsl()&lt;/code&gt;  should have gotten an optional fourth parameter instead (and the alpha value should have used the same format as R, G, and B or S and L).&lt;code&gt;¬ª&lt;/code&gt; and indirect sibling combinator should have been &lt;code&gt;++&lt;/code&gt;, so there's some logical relationships among the selectors' ascii art&lt;code&gt;*-blend-mode&lt;/code&gt; properties should've just been &lt;code&gt;*-blend&lt;/code&gt;&lt;code&gt;u0001-u00c8&lt;/code&gt;.&lt;code&gt;font-family&lt;/code&gt; should have required the font name to be quoted (like all other values that come from ‚Äúoutside‚Äù CSS).  The rules for handling unquoted font names make parsing &lt;code&gt;font&lt;/code&gt; stupid, as it requires a &lt;code&gt;font-size&lt;/code&gt; value for disambiguation.&lt;code&gt;flex-basis&lt;/code&gt; vs &lt;code&gt;width&lt;/code&gt;/&lt;code&gt;height&lt;/code&gt;.  Perhaps: if &lt;code&gt;width&lt;/code&gt;/&lt;code&gt;height&lt;/code&gt; is &lt;code&gt;auto&lt;/code&gt;, use &lt;code&gt;flex-basis&lt;/code&gt;; otherwise, stick with &lt;code&gt;width&lt;/code&gt;/&lt;code&gt;height&lt;/code&gt; as an inflexible size.  (This also makes min/max width/height behavior fall out of the generic definition.)&lt;code&gt;:empty&lt;/code&gt; should have been &lt;code&gt;:void&lt;/code&gt;, and &lt;code&gt;:empty&lt;/code&gt; should select items that contain only white space&lt;code&gt;table-layout: fixed; width: auto&lt;/code&gt; should result in a fill-available table with fixed-layout columns.&lt;code&gt;text-orientation&lt;/code&gt; should have had &lt;code&gt;upright&lt;/code&gt; as the initial value (given the latest changes to 'writing-mode').&lt;code&gt;@import&lt;/code&gt; rule is required to (a) always hit the network unless you specify cache headers, and (b) construct fresh CSSStyleSheet objects for every import, even if they're identical. It should have had more aggressive URL-based deduping and allowed sharing of stylesheet objects.&lt;code&gt;:link&lt;/code&gt; should have had the &lt;code&gt;:any-link&lt;/code&gt; semantics all along.&lt;code&gt;flex&lt;/code&gt; shorthand (and &lt;code&gt;flex-shrink&lt;/code&gt; and &lt;code&gt;flex-grow&lt;/code&gt; longhands) should accept &lt;code&gt;fr&lt;/code&gt; units instead of bare numbers to represent flex fractions.&lt;code&gt;display&lt;/code&gt; property should be called &lt;code&gt;display-type&lt;/code&gt;.&lt;code&gt;list-style&lt;/code&gt; properties should be called &lt;code&gt;marker-style&lt;/code&gt;, and &lt;code&gt;list-item&lt;/code&gt; renamed to &lt;code&gt;marked-block&lt;/code&gt; or something.&lt;code&gt;text-overflow&lt;/code&gt; property should always apply, not be dependent on &lt;code&gt;overflow&lt;/code&gt;&lt;code&gt;line-height: &amp;lt;percentage&amp;gt;&lt;/code&gt; should compute to the equivalent &lt;code&gt;line-height: &amp;lt;number&amp;gt;&lt;/code&gt;, so that it effectively inherits as a percentage not a length&lt;code&gt;::placeholder&lt;/code&gt; should be &lt;code&gt;::placeholder-text&lt;/code&gt; and &lt;code&gt;:placeholder-shown&lt;/code&gt; should be &lt;code&gt;:placeholder&lt;/code&gt;&lt;code&gt;overflow: scroll&lt;/code&gt; should introduce a stacking context&lt;code&gt;size&lt;/code&gt; should have been a shorthand for &lt;code&gt;width&lt;/code&gt; and &lt;code&gt;height&lt;/code&gt; instead of an &lt;code&gt;@page&lt;/code&gt; property with a different definition&lt;code&gt;span&lt;/code&gt;) with idents in the grid properties, possibly by using functional notation (like &lt;code&gt;span(2)&lt;/code&gt;).&lt;code&gt;align-inline-*&lt;/code&gt; and &lt;code&gt;align-block-*&lt;/code&gt;.&lt;code&gt;shape-outside&lt;/code&gt; should have had &lt;code&gt;wrap-&lt;/code&gt; in the name somehow, as people assume the shape should also clip the content as in &lt;code&gt;clip-path&lt;/code&gt;.&lt;code&gt;!important&lt;/code&gt; ‚Äî¬†that reads to engineers as ‚Äúnot important‚Äù. We should have picked another way to write this.&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://wiki.csswg.org/ideas/mistakes"/><published>2025-12-11T04:20:52+00:00</published></entry></feed>