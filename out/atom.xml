<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-28T14:00:39.605247+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46779645</id><title>Xfwl4 – The Roadmap for a Xfce Wayland Compositor</title><updated>2026-01-28T14:00:46.940125+00:00</updated><content>&lt;doc fingerprint="9f1261d108f93af0"&gt;
  &lt;main&gt;
    &lt;p&gt;We, the Xfce team are excited to share some great news!&lt;/p&gt;
    &lt;p&gt;After careful consideration, we’ve decided on a meaningful way to use the generous donations from our community: funding longtime Xfce core developer Brian Tarricone to create xfwl4, a brand-new Wayland compositor for Xfce.&lt;/p&gt;
    &lt;p&gt;This initiative will utilize a significant portion of the project’s donated funds, but we believe it’s an important investment in Xfce’s future.&lt;/p&gt;
    &lt;p&gt;The goal is, that xfwl4 will offer the same functionality and behavior as xfwm4 does, or as much as possible considering the differences between X11 and Wayland. Using xfwl4 should feel just like using xfwm4 on X11. We even plan to reuse the existing xfwm4 configuration dialogs and xfconf settings to ensure a seamless transition.&lt;/p&gt;
    &lt;p&gt;Xfwl4 will not be based on the existing xfwm4 code. Instead, it will be written from scratch in rust, using smithay building blocks.&lt;/p&gt;
    &lt;p&gt;The first attempt at creating an Xfce Wayland compositor involved modifying the existing xfwm4 code to support both X11 and Wayland in parallel. However, this approach turned out to be the wrong path forward for several reasons:&lt;/p&gt;
    &lt;p&gt;Once the decision to write a compositor from scratch was done, the next major question was: Which Wayland support library to use as a base? In order to find an answer on that question Brian evaluated wlroots and smithay. The decision to use smithay as a base was done for the following reasons:&lt;/p&gt;
    &lt;p&gt;Besides getting feature parity with xfwm4, the xfwl4 project scope includes as well some other related tasks:&lt;/p&gt;
    &lt;p&gt;Brian has already started work on the project, so stay tuned for the first development release of xfwl4, which we hope to share around mid-year.&lt;/p&gt;
    &lt;p&gt;If you’re interested in the detailed reasoning behind the project or want to explore all the technical details, check out the issues and the work in progress source code.&lt;/p&gt;
    &lt;p&gt;For any questions related to xfwl4, please visit our Matrix channel #xfce-dev.&lt;/p&gt;
    &lt;p&gt;We’d like to extend our heartfelt thanks to our generous supporters on Open Collective US and Open Collective EU for making this project possible!&lt;/p&gt;
    &lt;p&gt;Best regards,&lt;/p&gt;
    &lt;p&gt;The Xfce development team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alexxcons.github.io/blogpost_15.html"/><published>2026-01-27T13:25:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46781444</id><title>Amazon closing its Fresh and Go stores</title><updated>2026-01-28T14:00:46.478049+00:00</updated><content>&lt;doc fingerprint="284bb94a339ea4ec"&gt;
  &lt;main&gt;
    &lt;p&gt;(Bloomberg) -- Amazon.com Inc. is shuttering its Amazon-branded grocery stores and automated grab-and-go markets, eliminating two centerpieces of its push into physical retail.&lt;/p&gt;
    &lt;p&gt;Amazon Fresh and Amazon Go stores will close, the company said in a blog post on Tuesday, with some locations converted into Whole Foods Market stores.&lt;/p&gt;
    &lt;p&gt;Most Read from Bloomberg&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;NYC’s Mamdani Crushes Snow Day Hopes, But He Yearns for It Too&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Boston’s 18-Inch Snow Deluge to Make Travel Hard to ‘Impossible’&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;London’s Vanishing Office Buildings Are Being Replaced by Hotels&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LA Council Sends Mansion Tax Changes Back, Dimming Prospects&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;“While we’ve seen encouraging signals in our Amazon-branded physical grocery stores, we haven’t yet created a truly distinctive customer experience with the right economic model needed for large-scale expansion,” Amazon said.&lt;/p&gt;
    &lt;p&gt;The moves mark the e-commerce giant’s latest retreat from its brick-and-mortar retail efforts. Since the surprise opening of a physical bookstore in 2015, Amazon has tried and failed to establish a foothold under its own brand in categories from groceries to fashion, often with technological flourishes such as digital price tags or novel checkout methods.&lt;/p&gt;
    &lt;p&gt;Over the last few years, the company has backed away from the bookstores, an eclectic kitchen goods, toys and electronics store called Amazon 4-Star, electronics kiosks in shopping malls and a short-lived clothing storefront.&lt;/p&gt;
    &lt;p&gt;Amazon on Tuesday said it would continue to invest in groceries sold both online and offline. That includes an ongoing effort to stock more produce and perishables in Amazon’s same-day delivery warehouses and at more Whole Foods stores, which comprise more than 550 locations.&lt;/p&gt;
    &lt;p&gt;Amazon currently operates 14 Go stores, which use cameras to track what people grab off the shelves, and 58 Amazon Fresh grocery stores, according to its website. The last day of operation for most of those stores will be Sunday, a spokesperson said, except in California, where they’ll stay open longer to comply with state requirements for advance notice of closures.&lt;/p&gt;
    &lt;p&gt;The moves mean thousands of hourly workers in the stores will lose their jobs. Cuts to Amazon’s corporate workforce will likely involve dozens of people, according to a person familiar with the matter, who asked for anonymity because the information was confidential. The company says it will work to help employees find other jobs at Amazon, including at Whole Foods stores or in its logistics network. Amazon’s corporate ranks were already bracing for a round of layoffs expected as soon as this week.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://finance.yahoo.com/news/amazon-closing-fresh-grocery-convenience-150437789.html"/><published>2026-01-27T15:41:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46781530</id><title>430k-year-old well-preserved wooden tools are the oldest ever found</title><updated>2026-01-28T14:00:46.373200+00:00</updated><content/><link href="https://www.nytimes.com/2026/01/26/science/archaeology-neanderthals-tools.html"/><published>2026-01-27T15:46:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46782763</id><title>Artie (YC S23) Is Hiring a Founding Recruiter</title><updated>2026-01-28T14:00:45.885552+00:00</updated><content>&lt;doc fingerprint="a189c0db27d96528"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;About Artie&lt;/head&gt;
      &lt;p&gt;Artie is a real-time streaming platform that moves production data across systems in real-time, with zero maintenance. We make high-volume data replication simple, reliable, and scalable for engineering teams.&lt;/p&gt;
      &lt;p&gt;Our platform powers mission-critical use cases including fraud and risk monitoring, inventory visibility, customer-facing analytics, and AI workloads. Artie is built for engineers who care about performance, reliability, and operational simplicity — and we’re growing fast.&lt;/p&gt;
      &lt;p&gt;We’re trusted by teams like ClickUp, Substack, and Alloy, and backed by top-tier investors including Y Combinator, General Catalyst, Pathlight Ventures, and the founders of Dropbox and Mode.&lt;/p&gt;
      &lt;p&gt;We’re hiring our first in-house recruiter to own and build talent at Artie. This role is your chance to build our team from first principles.&lt;/p&gt;
      &lt;head rend="h3"&gt;About the Role&lt;/head&gt;
      &lt;p&gt;This is not a coordination role and not a “run the ATS” job.&lt;/p&gt;
      &lt;p&gt;You will be responsible for end-to-end recruiting across the company, with a focus on Engineering, Product, Operations, and Design (EPOD). You’ll partner directly with founders and hiring managers, define what “great” looks like for each role, and build the recruiting foundation we scale on top of.&lt;/p&gt;
      &lt;p&gt;You will also be the internal owner for our external recruiting partners — setting strategy, calibrating quality, and ensuring agencies complement our in-house motion.&lt;/p&gt;
      &lt;p&gt;If you view recruiting as a mix of sales, systems thinking, storytelling, and judgment, this role is for you.&lt;/p&gt;
      &lt;p&gt;This is a high-trust, high-ownership role, and you’ll have real influence over the shape, culture, and trajectory of the company.&lt;/p&gt;
      &lt;head rend="h3"&gt;What you’ll do&lt;/head&gt;
      &lt;p&gt;Own full-cycle recruiting across the company&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Run end-to-end hiring for Engineering, Product, Operations, and Design roles, and support other roles in GTM as needed&lt;/item&gt;
        &lt;item&gt;Partner with founders and hiring managers to: &lt;list rend="ul"&gt;&lt;item&gt;Define role scope, seniority, and success criteria&lt;/item&gt;&lt;item&gt;Calibrate on candidate quality and tradeoffs&lt;/item&gt;&lt;item&gt;Continuously refine interview loops and hiring signals&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Manage candidates through sourcing, screening, interviews, offers, and closing&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Be the engine for technical hiring&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Proactively source and engage senior technical talent (engineers, product, design) in a competitive market&lt;/item&gt;
        &lt;item&gt;Run outbound recruiting with creativity and rigor — LinkedIn, referrals, networks, events, cold outreach, and non-obvious channels&lt;/item&gt;
        &lt;item&gt;Confidently engage technical candidates and speak credibly about: &lt;list rend="ul"&gt;&lt;item&gt;Engineering culture and technical challenges&lt;/item&gt;&lt;item&gt;Artie’s product, architecture, and roadmap (with support from founders)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Sell Artie to candidates&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Craft and deliver a compelling narrative around: &lt;list rend="ul"&gt;&lt;item&gt;Why Artie exists&lt;/item&gt;&lt;item&gt;Why this team is special&lt;/item&gt;&lt;item&gt;Why this is a rare career opportunity&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Own candidate experience end-to-end - build a world-class recruiting process that delights candidates&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Build recruiting infrastructure from scratch&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Own and evolve our recruiting process, tools, and operating rhythm&lt;/item&gt;
        &lt;item&gt;Manage and improve our ATS and sourcing tools&lt;/item&gt;
        &lt;item&gt;Track and report on hiring progress, pipeline health, and bottlenecks&lt;/item&gt;
        &lt;item&gt;Continuously improve speed, quality, and candidate experience as we scale&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Manage external recruiting partners&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Act as the primary point of contact for agencies we work with&lt;/item&gt;
        &lt;item&gt;Set expectations, role briefs, and quality bars&lt;/item&gt;
        &lt;item&gt;Ensure agencies augment our hiring motion rather than define it&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What we’re looking for&lt;/head&gt;
      &lt;p&gt;Recruiting mastery in early-stage environments&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;4+ years of recruiting experience, with meaningful exposure to: &lt;list rend="ul"&gt;&lt;item&gt;Technical recruiting (engineering, product, design)&lt;/item&gt;&lt;item&gt;Early-stage startups (Series A–C preferred)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Experience owning full-cycle recruiting without large support teams&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Strong technical intuition&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You don’t need to code, but you can recruit engineers&lt;/item&gt;
        &lt;item&gt;Able to build credibility quickly with senior technical candidates&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Sales mindset&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You view recruiting as a sales and persuasion problem&lt;/item&gt;
        &lt;item&gt;Comfortable with outbound, rejection, and ambiguity&lt;/item&gt;
        &lt;item&gt;Strong written and verbal communicator&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Extreme ownership&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You take responsibility for outcomes, not just inputs&lt;/item&gt;
        &lt;item&gt;You proactively identify problems and fix them&lt;/item&gt;
        &lt;item&gt;You care deeply about quality and long-term team health&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Taste, judgment, and integrity&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You have a strong internal bar for talent&lt;/item&gt;
        &lt;item&gt;You know when to push, when to pause, and when to say no&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Logistics&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Willing to work in-person, 5 days/week at our SF office&lt;/item&gt;
        &lt;item&gt;Comfortable operating with speed, ambiguity, and very little structure&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What you’ll get&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Foundational impact: You will shape the team, culture, and hiring bar at Artie&lt;/item&gt;
        &lt;item&gt;Direct founder partnership: Work closely with the CEO/CTO and leadership team&lt;/item&gt;
        &lt;item&gt;End-to-end ownership: Strategy, execution, iteration — all yours&lt;/item&gt;
        &lt;item&gt;Growth path: Opportunity to grow into a Head of Talent / recruiting leader as we scale&lt;/item&gt;
        &lt;item&gt;High trust environment: You’ll be treated as a core operator, not a support function&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Compensation &amp;amp; Benefits&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Competitive salary (commensurate with experience) - our philosophy is P75-90 for base salary and P90+ for equity compared to benchmarks&lt;/item&gt;
        &lt;item&gt;Healthcare, 401(k) matching, unlimited PTO&lt;/item&gt;
        &lt;item&gt;Lunch &amp;amp; dinner provided&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/artie/jobs/MX163y2-founding-recruiter"/><published>2026-01-27T17:01:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46782930</id><title>SoundCloud Data Breach Now on HaveIBeenPwned</title><updated>2026-01-28T14:00:45.632633+00:00</updated><content>&lt;doc fingerprint="8d73685d6bf0f787"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;SoundCloud Data Breach&lt;/head&gt;&lt;head rend="h2"&gt;What Happened&lt;/head&gt;&lt;p&gt;In December 2025, SoundCloud announced it had discovered unauthorised activity on its platform. The incident allowed an attacker to map publicly available SoundCloud profile data to email addresses for approximately 20% of its users. The impacted data included 30M unique email addresses, names, usernames, avatars, follower and following counts and, in some cases, the user’s country. The attackers later attempted to extort SoundCloud before publicly releasing the data the following month.&lt;/p&gt;&lt;head rend="h2"&gt;Compromised Data&lt;/head&gt;&lt;head rend="h2"&gt;Recommended Actions&lt;/head&gt;&lt;p&gt;Use a password manager to generate and store strong, unique passwords for all your accounts. 1Password helps protect your data with industry-leading security.&lt;/p&gt;Try 1Password&lt;p&gt;Get Aura for identity theft and credit protection. Keep your assets safe with fast fraud alerts, instant credit lock, and $1,000,000 identity theft insurance. Speak to a U.S. based fraud specialist 24/7.&lt;/p&gt;Try Aura&lt;p&gt;Get Guardio for real-time protection after a breach. Guardio blocks AI-generated scam sites, fake login pages, and malicious pages designed to exploit leaked information. Built by cybersecurity specialists who track new threats 24/7, Guardio gives you immediate, expert-level protection plus clear steps to help you secure your accounts instantly.&lt;/p&gt;Try Guardio&lt;head rend="h3"&gt;Breach Overview&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Affected Accounts:&lt;/p&gt;&lt;p&gt;29.8 million&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Breach Occurred:&lt;/p&gt;&lt;p&gt;December 2025&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Added to HIBP:&lt;/p&gt;&lt;p&gt;27 Jan 2026&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Recommended Actions&lt;/head&gt;&lt;head rend="h5"&gt;Change Your Password&lt;/head&gt;&lt;p&gt;If you haven’t already changed the password affected by this breach, do so immediately on every account where it was used.&lt;/p&gt;&lt;head rend="h5"&gt;Enable Two-Factor Authentication&lt;/head&gt;&lt;p&gt;Wherever 2FA is supported, add an extra layer of security to your account.&lt;/p&gt;&lt;p&gt;Get Guardio for real-time protection after a breach. Guardio blocks AI-generated scam sites, fake login pages, and malicious pages designed to exploit leaked information. Built by cybersecurity specialists who track new threats 24/7, Guardio gives you immediate, expert-level protection plus clear steps to help you secure your accounts instantly.&lt;/p&gt;Try Guardio&lt;p&gt;Use a password manager to generate and store strong, unique passwords for all your accounts. 1Password helps protect your data with industry-leading security.&lt;/p&gt;Try 1Password&lt;p&gt;Get Aura for identity theft and credit protection. Keep your assets safe with fast fraud alerts, instant credit lock, and $1,000,000 identity theft insurance. Speak to a U.S. based fraud specialist 24/7.&lt;/p&gt;Try Aura&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://haveibeenpwned.com/Breach/SoundCloud"/><published>2026-01-27T17:11:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46783017</id><title>AI2: Open Coding Agents</title><updated>2026-01-28T14:00:44.558662+00:00</updated><content>&lt;doc fingerprint="2d78817f1012d04a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Open Coding Agents: Fast, accessible coding agents that adapt to any repo&lt;/head&gt;
    &lt;p&gt;January 27, 2026&lt;/p&gt;
    &lt;p&gt;Ai2&lt;/p&gt;
    &lt;p&gt;Over the past year, coding agents have transformed how developers write, test, and maintain software. These systems can debug, refactor, and even submit pull requests—fundamentally changing what software development looks like. Yet despite this progress, most coding agents share the same constraints: they're closed, expensive to train, and difficult to study or adapt to private codebases.&lt;/p&gt;
    &lt;p&gt;Ai2 Open Coding Agents change that. Today we’re releasing not just a collection of strong open coding models, but a training method that makes building your own coding agent for any codebase – for example, your personal codebase or an internal codebase at your organization – remarkably accessible for tasks including code generation, code review, debugging, maintenance, and code explanation.&lt;/p&gt;
    &lt;p&gt;Closed models haven't seen your internal code, so they don't know it—custom data pipelines, internal APIs, specific org conventions, and so on. Training on your private data teaches them, but generating synthetic training data from private codebases that works for agents has been challenging and cost-prohibitive. Our method makes it easy—reproducing the performance of the previously best open-source model costs ~$400 of compute, or up to $12,000 for performance that rivals the best industry models of the same size. This puts the full recipe within reach for labs and small teams.&lt;/p&gt;
    &lt;p&gt;Resource constraints drove us to maximize efficiency at every stage, from data quality to inference costs to model selection. The result: we match SWE-smith, a synthetic data method, at 57× lower cost and SkyRL, an open-source reinforcement learning (RL) system, at 26× lower cost.&lt;/p&gt;
    &lt;p&gt;The first release in our Open Coding Agents family is SERA (Soft-verified Efficient Repository Agents). The strongest – SERA-32B – solves 54.2% of SWE-Bench Verified problems, surpassing prior open-source state-of-the-art coding models of comparable sizes and context lengths while requiring only 40 GPU days (or fewer) to train on a cluster of 2 NVIDIA Hopper GPUs or NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs. SERA models are optimized and compatible with Claude Code out of the box. With our fine-tuning method, you can specialize them to your own codebase including your full engineering stack and conventions quickly and at low cost.&lt;/p&gt;
    &lt;p&gt;We collaborated with NVIDIA to optimize SERA inference for their accelerated infrastructure, ensuring researchers and developers can get the most out of these models in production environments. Early benchmarks are promising: running in BF16 precision on 4xH100 GPUs, SERA achieves approximately 1,950 peak output tokens per second with a 16k context window. At FP8 precision, SERA reaches 3,700 peak output tokens per second—a higher throughput at almost negligible accuracy drop. On next-generation Blackwell 4xB200 systems running in NVFP4, SERA scales further to around 8,600 peak output tokens per second.&lt;/p&gt;
    &lt;p&gt;Every component of this release is open – models, Claude Code integration, and training recipes – and can be launched with a single line of code, making it easy to use even for those without LLM training experience. We're also releasing state-of-the-art training data so researchers can inspect what worked and push it further, and conduct deep science while avoiding the many stumbling blocks, dead ends, and other roadblocks typical of coding agents.&lt;/p&gt;
    &lt;p&gt;One result we're especially excited about: SERA uniquely enables adapting to private datasets like internal codebases, and we see evidence that a smaller, open model can replicate and possibly even exceed the performance of a more capable "teacher" coding agent in these setups. For example, SERA-32B can surpass its 110B parameter teacher (GLM-4.5-Air) on codebases like Django and Sympy after training on just 8,000 samples at a cost of $1,300.&lt;/p&gt;
    &lt;p&gt;Accessible open models can now inherit strong agentic behavior through a simple, reproducible pipeline—no large-scale RL infrastructure or engineering team required. Case in point, SERA was built largely by a single Ai2 researcher.&lt;/p&gt;
    &lt;head rend="h3"&gt;The challenge: specializing agents to your data&lt;/head&gt;
    &lt;p&gt;If you’re a small to mid-sized business or independent developer, you probably have code that works with customer data in ways no public model has ever seen. Training on that data would help, but generating agent-ready synthetic data from private codebases has been the hard part. The holy grail would be a method that yields state-of-the-art training data for any codebase, with minimal setup and clear evidence that the tuned model is actually learning agentic behavior versus fragile heuristics.&lt;/p&gt;
    &lt;p&gt;We tackle this challenge with our new post-training approach that achieves state-of-the-art open-source results on SWE-Bench at a fraction of the typical training costs. Two innovations make it both inexpensive and effective:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Soft-verified generation (SVG). Synthetic training data generation, which is key to training a strong coding agent, is usually done by generating pairs of code examples that have both incorrect and corrected code. From these examples, the coding agent can learn how to transform incorrect code into correct code by generating a patch with line-by-line code changes. Usually, these examples need to be carefully tested to ensure that they’re actually correct. In SVG, our main finding is that patches don’t need to be correct to be helpful for coding. Just like different code can lead to the same, correct solution, with SVG we generate synthetic training data by having patches that are only partially correct. This removes the need to thoroughly test for full correctness, which in turn alleviates the need for complex infrastructure for testing and costly generation of precise examples. We demonstrate that this soft-verified data scales exactly like "hard-verified" training data.&lt;/item&gt;
      &lt;item&gt;Scaling with a bug-type menu. To diversify data without becoming bottlenecked on finding real bugs, we draw from a taxonomy of 51 common bug patterns identified in prior analyses. For each function in a repository, we can generate multiple distinct bug-style prompts—so a repo with thousands of functions can yield tens of thousands of varied agentic trajectories at low cost.&lt;/item&gt;
      &lt;item&gt;High simulated workflow fidelity. A key finding is that high-quality synthetic training data should mirror the workflow of a developer rather than the precise details of correct code. This means correct coding data is less important than data that reflects how a developer works on a problem. Combined with SVG, this insight enables repository training: generating training data for any code repository, making it straightforward to scale synthetic data generation massively.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Together, these innovations mean that if you or your organization has a private codebase, you can use SERA to fine-tune a small model to strong performance on your data—easily and affordably. Instead of designing a complicated RL pipeline and test harness for every new task setting, you generate targeted synthetic data and run a straightforward supervised fine-tuning (SFT) job.&lt;/p&gt;
    &lt;head rend="h3"&gt;State-of-the-art performance, accessible hardware&lt;/head&gt;
    &lt;p&gt;Using SERA, we've developed a family of models ranging from 8B to 32B parameters, all built on Qwen3 and trained up to 32K context length with the help of various teacher models. We expect the same recipe to keep improving as we scale to larger backbones and context lengths, but the key point is that the current pipeline is already cheap and feasible for anyone to run, customize, and iterate on today—opening up wide access and endless possibilities for future research.&lt;/p&gt;
    &lt;p&gt;Our efficient technique enabled highly precise science. By keeping costs low, we could systematically disentangle the many factors that have made comparisons between agentic systems unreliable. This rigorous methodology drove rapid iteration, leading us from soft-verified generation to the full SERA approach.&lt;/p&gt;
    &lt;p&gt;When we align inference conditions for fair comparison, SERA performs competitively with leading open coding agents. At 32K context, SERA-32B achieves 49.5% ± 1.9% on SWE-Bench Verified, comparable to Devstral Small 2 (50.0% ± 1.3%) and GLM-4.5-Air (50.5% ± 1.3%). At 64K context, SERA-32B reaches 54.2% ± 1.4%—competitive with longer-context baselines.&lt;/p&gt;
    &lt;p&gt;Strong closed-weight coding agents like Devstral Small 2 are an important point of comparison. When we control for key variables, SERA-32B comes close: within ~0.5 points at 32K and ~4.9 points at 64K compared to Devstral Small 2 despite SERA being pure SFT and not trained beyond 32K tokens, both of which disadvantage longer-context evaluation.&lt;/p&gt;
    &lt;p&gt;We also explored how teacher strength affects results. GLM-4.6 yields our best numbers, but GLM-4.5-Air gets surprisingly close at lower cost. The gap between teachers becomes most meaningful in higher-compute regimes—suggesting that depending on your budget and target performance, a weaker (and cheaper) teacher can be the better overall choice, especially for early iterations.&lt;/p&gt;
    &lt;p&gt;To validate our synthetic data generation strategy, we tested repository-specific specialization on Django, SymPy, and Sphinx—the three largest repositories in SWE-Bench. Because these have actual test instances, we can quantify how well specialization works in practice. This serves as a proxy for the downstream use case we care most about: adapting to private codebases that may lack comprehensive tests or follow nonstandard structures.&lt;/p&gt;
    &lt;p&gt;The results are promising. Our specialized models – trained on 8,000 synthetic trajectories per repository – consistently match and often exceed the performance of the 100B+ parameter models we used as teachers. At 32K context, the specialized models achieve 52.23% on Django and 51.11% on SymPy, compared to GLM-4.5-Air's 51.20% and 48.89%. The gains are most pronounced on Django and SymPy, which together account for over 60% of all SWE-Bench problems.&lt;/p&gt;
    &lt;p&gt;These results highlight two crucial advantages of our method. First, specialization pays off: a 32B model fine-tuned to a specific codebase can match or surpass a 100B+ general-purpose teacher, delivering comparable performance at one-third the size with lower memory requirements, faster inference, and reduced operational costs. Second, simplicity scales: our SFT-only pipeline on an open base model is now competitive with heavily engineered, large-team efforts. Together, these findings lower the barrier to entry for researchers, make results easier to reproduce, and turn agentic coding progress into something the whole community can validate and build on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Built for developers and researchers&lt;/head&gt;
    &lt;p&gt;Our release package includes everything needed to reproduce, test, and build on SERA—a lightweight deployment requiring just two lines of code to launch an inference server. We've also developed a setup script and inference optimizations that make SERA directly compatible with Claude Code.&lt;/p&gt;
    &lt;p&gt;A key difference from closed-weight systems is our commitment to openness and reproducibility:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We release models, code, all generated agent data, and a full recipe to generate your own data so anyone can reproduce our results or customize them to new domains.&lt;/item&gt;
      &lt;item&gt;Our training pipeline is intentionally simple—standard SFT on trajectories with no custom RL infrastructure needed.&lt;/item&gt;
      &lt;item&gt;The total cost to reproduce performance levels of the best previous open-source result only is roughly $400 on commodity cloud GPUs, more than 25 times cheaper than many existing approaches that require complex distributed setups and still fall short on performance.&lt;/item&gt;
      &lt;item&gt;The total cost to reproduce top open-weight models in industry, such as Devstral Small 2, is only $12,000.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We believe bringing the cost of replicating strong coding agents down to a few hundred dollars will unlock research that simply wasn't possible before. Instead of being limited to a handful of well-funded labs, agentic coding can become a widely accessible practice.&lt;/p&gt;
    &lt;p&gt;Whether you're running locally on your hardware, deploying in the cloud, or fine-tuning on your own codebase, SERA delivers practical agentic coding within reach of developers, researchers, and small teams alike.&lt;/p&gt;
    &lt;p&gt;Models | Tech Report | SERA CLI | CLI on PyPi&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://allenai.org/blog/open-coding-agents"/><published>2026-01-27T17:17:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46783254</id><title>FBI is investigating Minnesota Signal chats tracking ICE</title><updated>2026-01-28T14:00:44.247294+00:00</updated><content>&lt;doc fingerprint="72bcc8104f07b317"&gt;
  &lt;main&gt;
    &lt;p&gt;FBI Director Kash Patel said Monday that he had opened an investigation into the Signal group text chats that Minnesota residents are using to share information about federal immigration agents’ movements, launching a new front in the Trump administration’s conflict there with potential free speech implications.&lt;/p&gt;
    &lt;p&gt;Patel said in an interview with conservative podcaster Benny Johnson that he wanted to know whether any Minnesota residents had put federal agents “in harm’s way” with activities such as sharing agents’ license plate numbers and locations.&lt;/p&gt;
    &lt;p&gt;“You cannot create a scenario that illegally entraps and puts law enforcement in harm’s way,” he said in the interview, which was posted to YouTube.&lt;/p&gt;
    &lt;p&gt;The investigation quickly drew skepticism from free speech advocates who said the First Amendment protects members of the public who share legally obtained information, such as the names of federal agents or where they are conducting enforcement operations.&lt;/p&gt;
    &lt;p&gt;“There are legitimate reasons to share such information, including enabling members of the public to observe and document law enforcement activity and to hold officials accountable for misconduct,” Aaron Terr, director of public advocacy at the Foundation for Individual Rights and Expression, said in an email.&lt;/p&gt;
    &lt;p&gt;“Given this administration’s poor track record of distinguishing protected speech from criminal conduct, any investigation like this deserves very close scrutiny,” he said.&lt;/p&gt;
    &lt;p&gt;For months, digital tools have been at the center of how people have pushed back against immigration enforcement efforts in Minnesota and across the country. The administration’s opponents have used group text chats to track Immigration and Customs Enforcement operations, share photos of suspected ICE vehicles and raise awareness for neighbors. In June, administration officials criticized ICEBlock, an app designed to share information about ICE sightings. Apple removed the app from its app store in October, prompting a lawsuit from the app’s developer alleging the administration unlawfully pressured Apple to remove it.&lt;/p&gt;
    &lt;p&gt;In the past few days, the group text chats — especially those on the encrypted messaging app Signal — have drawn attention from right-wing media. On Saturday, Cam Higby, a conservative journalist based near Seattle, said in a thread on X that he had “infiltrated” Signal groups from around Minneapolis that he alleged were obstructing law enforcement. His thread, which got 20 million views, focused on how the groups share such information as the license plate numbers of suspected federal vehicles. NBC News has not verified Higby’s claims.&lt;/p&gt;
    &lt;p&gt;Patel said he got the idea for the investigation from Higby.&lt;/p&gt;
    &lt;p&gt;“As soon as Higby put that post out, I opened an investigation on it,” he said. “We immediately opened up that investigation, because that sort of Signal chat — being coordinated with individuals not just locally in Minnesota, but maybe even around the country — if that leads to a break in the federal statute or a violation of some law, then we are going to arrest people.”&lt;/p&gt;
    &lt;p&gt;The Signal Foundation, the nonprofit organization that operates the Signal app, did not immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Signal, which is considered one of the most secure chat apps, is a go-to resource for people concerned about privacy. It is perhaps best known as the app Defense Secretary Pete Hegseth used to share sensitive military information last year in a group chat that accidentally included a journalist.&lt;/p&gt;
    &lt;p&gt;In the Twin Cities, Signal group chats have been a standard part of toolkits — along with walkie-talkies and whistles — used by activists, parents and neighborhood-watch members who have organized as volunteers to warn families about immigration enforcement activities by relaying real-time information, especially near schools. Patrol volunteers have said that, with more than 3,000 federal immigration agents in Minnesota, they are motivated by a desire to protect parents, children and school staff members who are not U.S. citizens.&lt;/p&gt;
    &lt;p&gt;Patel did not say which laws he thought Minnesota residents may have violated. An FBI spokesperson said the bureau had no further information to provide.&lt;/p&gt;
    &lt;p&gt;The announcement seemed likely to have implications for the First Amendment’s guarantee of free speech. Alex Abdo, litigation director at the Knight First Amendment Institute at Columbia University, said the First Amendment protects the right to record law enforcement officers as they carry out their official responsibilities.&lt;/p&gt;
    &lt;p&gt;“The ability of everyday citizens to hold government agents to account, by observing them and advocating for change, is what has distinguished the American experiment with democracy from authoritarian regimes around the world,” Abdo said in an email.&lt;/p&gt;
    &lt;p&gt;“Unless the FBI has evidence of a crime, and not just evidence of activity the Constitution protects, it should stand down,” he said.&lt;/p&gt;
    &lt;p&gt;Patel acknowledged in the interview with Johnson that an investigation into group text chats would raise free speech concerns and said the FBI would “balance” the rights guaranteed by the First and Second amendments with what he said were potential violations of federal law.&lt;/p&gt;
    &lt;p&gt;“Now, we will balance the First and Second amendment constantly, but we have to let the community know that we will not tolerate acts of violence and an escalation and a violation of the federal code,” he said. The Second Amendment could be at issue because Alex Pretti, the nurse shot and killed by a federal agent Saturday in Minneapolis, was permitted to carry a gun in public and had one with him.&lt;/p&gt;
    &lt;p&gt;Terr, of the Foundation for Individual Rights and Expression, said the government does not get to “balance” the First Amendment against its other interests.&lt;/p&gt;
    &lt;p&gt;“The Constitution takes precedence over any conflicting state or federal law, and over any official’s desire to suppress speech they dislike,” he said in his email.&lt;/p&gt;
    &lt;p&gt;He added: “There is a First Amendment exception for speech intended and likely to provoke imminent unlawful action, but that doesn’t apply to just any speech the government claims puts officials in harm’s way. By contrast, if individuals are threatening federal agents or conspiring to physically harm them, that is illegal. But conspiracy requires an agreement to commit a specific crime and a substantial step toward carrying it out.”&lt;/p&gt;
    &lt;p&gt;Patel also said the FBI had made “substantial progress” in an investigation into groups and people responsible for funding resistance to immigration enforcement. He alleged that the protests and neighborhood monitoring are “not happening organically” but did not immediately provide evidence.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nbcnews.com/tech/internet/fbi-investigating-minnesota-signal-minneapolis-group-ice-patel-kash-rcna256041"/><published>2026-01-27T17:32:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46783752</id><title>Prism</title><updated>2026-01-28T14:00:44.001097+00:00</updated><content>&lt;doc fingerprint="ab5a723abbf162df"&gt;
  &lt;main&gt;
    &lt;p&gt;Science shapes nearly every part of daily life—from the medicines we rely on, to the energy that powers our homes, to the systems that keep us safe. But the pace of scientific progress is still constrained by how research is done day to day. While AI has advanced rapidly, much of the everyday work of science still relies on tools that haven’t fundamentally changed in decades.&lt;/p&gt;
    &lt;p&gt;We’re introducing Prism, a free, AI-native workspace for scientists to write and collaborate on research, powered by GPT‑5.2. Prism offers unlimited projects and collaborators and is available today to anyone with a ChatGPT personal account.&lt;/p&gt;
    &lt;p&gt;Prism will be available soon to organizations using ChatGPT Business, Enterprise, and Education plans.&lt;/p&gt;
    &lt;p&gt;Over the past year, we’ve begun to see AI accelerate scientific work across domains. Advanced reasoning systems like GPT‑5 are helping push the frontiers of mathematics, accelerating the analysis of human immune-cell experiments, and speeding up experimental iteration in molecular biology.&lt;/p&gt;
    &lt;p&gt;We’re still early, but it’s clear that AI will play a meaningful role in how science advances.&lt;/p&gt;
    &lt;p&gt;At the same time, much of the everyday work of research—drafting papers, revising arguments, managing equations and citations, and coordinating with collaborators —remains fragmented across disconnected tools. Researchers often move between editors, PDFs, LaTeX compilers, reference managers, and separate chat interfaces, losing context and interrupting focus.&lt;/p&gt;
    &lt;p&gt;Prism is our first step toward addressing this fragmentation.&lt;/p&gt;
    &lt;p&gt;Prism is a free workspace for scientific writing and collaboration, with GPT‑5.2—our most advanced model for mathematical and scientific reasoning—integrated directly into the workflow.&lt;/p&gt;
    &lt;p&gt;It brings drafting, revision, collaboration, and preparation for publication into a single, cloud-based, LaTeX-native workspace. Rather than operating as a separate tool alongside the writing process, GPT‑5.2 works within the project itself—with access to the structure of the paper, equations, references, and surrounding context.&lt;/p&gt;
    &lt;p&gt;Prism builds on the foundation of Crixet, a cloud-based LaTeX platform that OpenAI acquired and has since evolved into Prism as a unified product. This allowed us to start with a strong base of a mature writing and collaboration environment, and integrate AI in a way that fits naturally into scientific workflows.&lt;/p&gt;
    &lt;p&gt;With Prism, researchers can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chat with GPT‑5.2 Thinking, to explore ideas, test hypotheses, and reason through complex scientific problems in context&lt;/item&gt;
      &lt;item&gt;Draft and revise papers with the full document as context, including surrounding text, equations, citations, figures, and overall structure&lt;/item&gt;
      &lt;item&gt;Search for and incorporate relevant literature (for example, from arXiv) in the context of the current manuscript, and revise text in light of newly identified related work&lt;/item&gt;
      &lt;item&gt;Create, refactor, and reason over equations, citations, and figures, with AI that understands how those elements relate across the paper&lt;/item&gt;
      &lt;item&gt;Turn whiteboard equations or diagrams directly into LaTeX, saving hours of time manipulating graphics pixel-by-pixel&lt;/item&gt;
      &lt;item&gt;Collaborate with co-authors, students, and advisors in real time, with edits, comments, and revisions reflected immediately&lt;/item&gt;
      &lt;item&gt;Make direct, in-place changes to the document when requested, without copying content between separate editors or chat tools&lt;/item&gt;
      &lt;item&gt;Use optional voice-based editing to make simple changes without interrupting writing or review&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Scientific research is inherently collaborative. Papers are shaped over time by co-authors, students, advisors, and reviewers, often across institutions and geographies.&lt;/p&gt;
    &lt;p&gt;Prism supports unlimited collaborators, allowing research teams to work together without seat limits or access barriers. Because it’s cloud-based, there’s no local LaTeX installation or environment management required, making it easier for teams to collaborate in a shared workspace.&lt;/p&gt;
    &lt;p&gt;By reducing version conflicts, manual merging, and mechanical overhead, Prism helps teams spend less time managing files and more time engaging with the substance of their work.&lt;/p&gt;
    &lt;p&gt;Just as importantly, Prism is designed to expand access.&lt;/p&gt;
    &lt;p&gt;Prism is free to use, and anyone with a ChatGPT account can start writing immediately. There are no subscriptions or seat limits. By making high-quality scientific tools easier to adopt and broadly available, we hope to enable more researchers—across institutions, disciplines, and career stages—to participate fully in the scientific process.&lt;/p&gt;
    &lt;p&gt;More powerful AI features will be made available through paid ChatGPT plans over time.&lt;/p&gt;
    &lt;p&gt;In 2025, AI changed software development forever. In 2026, we expect a comparable shift in science, as AI begins to meaningfully accelerate discovery in several ways, one of which is reducing friction in day-to-day research work. Prism is an early step toward that future.&lt;/p&gt;
    &lt;p&gt;We’re excited to learn from researchers using Prism today and to continue building toward tools that help science move faster—together. Try Prism for free today at prism.openai.com(opens in a new window).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/introducing-prism"/><published>2026-01-27T18:03:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46784491</id><title>Hypercubic (YC F25) Is Hiring a Founding SWE and COBOL Engineer</title><updated>2026-01-28T14:00:43.680678+00:00</updated><content>&lt;doc fingerprint="3564976ca045d865"&gt;
  &lt;main&gt;
    &lt;p&gt;AI to maintain and modernize COBOL.&lt;/p&gt;
    &lt;p&gt;Hypercubic is an AI-native maintenance and modernization platform for COBOL and mainframes.&lt;/p&gt;
    &lt;p&gt;We help enterprises understand and preserve their mission-critical legacy systems. About 70% of the Fortune 500 companies still rely on them to run their core business applications in banking, insurance, telecom, airlines, retail, and more.&lt;/p&gt;
    &lt;p&gt;These systems, originally built in the 1960s–90s, still power trillions in global infrastructure today but have become increasingly opaque as original developers retire or leave the workforce.&lt;/p&gt;
    &lt;p&gt;We're laying the foundation to autonomously maintain and modernize these legacy systems to future-proof the backbone of the global economy.&lt;/p&gt;
    &lt;p&gt;Learn more at hypercubic.ai&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/hypercubic/jobs"/><published>2026-01-27T18:50:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46784572</id><title>Lennart Poettering, Christian Brauner founded a new company</title><updated>2026-01-28T14:00:43.505969+00:00</updated><content>&lt;doc fingerprint="312f8243025a869"&gt;
  &lt;main&gt;&lt;p&gt;Our mission is to deliver verifiable integrity to Linux workloads everywhere&lt;/p&gt;Contact us&lt;p&gt;Our mission is to deliver verifiable integrity to Linux workloads everywhere&lt;/p&gt;&lt;p&gt;We are building cryptographically verifiable integrity into Linux systems. Every system starts in a verified state and stays trusted over time.&lt;/p&gt;&lt;p&gt;Delivering uncompromising integrity&lt;/p&gt;&lt;p&gt;Delivering uncompromising integrity&lt;/p&gt;&lt;p&gt;Executive team&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://amutable.com/about"/><published>2026-01-27T18:57:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46786183</id><title>Time Station Emulator</title><updated>2026-01-28T14:00:43.034578+00:00</updated><content>&lt;doc fingerprint="c61888ce72653253"&gt;
  &lt;main&gt;
    &lt;p&gt;Time Station Emulator turns almost any phone or tablet into a low-frequency radio transmitter broadcasting a time signal that can synchronize most radio-controlled (“atomic”) clocks and watches.&lt;/p&gt;
    &lt;p&gt;Real time signal broadcasts are limited in geographic range and notoriously prone to interference in urban areas, so many such clocks end up never actually using their self-setting functionality. Time Station Emulator may allow setting such clocks when/where a suitable signal is not otherwise available.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compatible with most radio-controlled clocks: Emulates the five operational radio time signal stations (🇨🇳 BPC, 🇩🇪 DCF77, 🇯🇵 JJY, 🇬🇧 MSF, and 🇺🇸 WWVB).&lt;/item&gt;
      &lt;item&gt;Network time: Derives the current time from the network using an NTP-like algorithm.&lt;/item&gt;
      &lt;item&gt;Location-agnostic: Supports applying an offset to the transmitted time of ±24 hours from the present.&lt;/item&gt;
      &lt;item&gt;BST/CEST/DST-aware: Transmits daylight saving time information for DCF77, MSF, and WWVB.&lt;/item&gt;
      &lt;item&gt;Leap second-aware: Transmits a DUT1 offset for MSF and WWVB.&lt;/item&gt;
      &lt;item&gt;Client-side, browser-based: Runs entirely in the browser; no installation, no signup, no data collection.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The hard requirements of note are browser WebAssembly support and DAC support for ≥44.1 KHz PCM. Almost any device running a browser from ≥2019 should work.&lt;/p&gt;
    &lt;p&gt;However, as of early 2024, Safari on iOS and Firefox on Android have multiple breaking issues and will not work.&lt;/p&gt;
    &lt;p&gt;For other devices, Time Station Emulator works best with a built-in speaker of a phone or tablet. See Technical Details for an explanation.&lt;/p&gt;
    &lt;p&gt;Time Station Emulator is hosted at https://timestation.pages.dev/.&lt;/p&gt;
    &lt;head&gt;click to expand/hide&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Choose emulator settings.&lt;/p&gt;
        &lt;p&gt;The most important setting is which time station to emulate. Certain settings are only available for certain stations.&lt;/p&gt;
        &lt;p&gt;Clocks (or watches) that support more than one station may prefer one of them over the others.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Choose any clock settings and place the clock into sync mode.&lt;/p&gt;
        &lt;p&gt;If your clock has them, try to choose station and/or time zone settings that make sense for your location.&lt;/p&gt;
        &lt;p&gt;Most clocks provide a way to force a synchronization attempt. You will probably have to navigate menus and/or press physical buttons.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Position the speaker as close as possible to the clock’s antenna.&lt;/p&gt;&lt;p&gt;The transmission range is quite short, so positioning is crucial. Some experimentation will probably be required, especially if you’re unsure where the antenna is.&lt;/p&gt;&lt;p&gt;The volume should be set so that the clock picks up the cleanest signal. Usually, this occurs at or near the maximum possible volume.&lt;/p&gt;&lt;th&gt;WARNING&lt;/th&gt;&lt;td&gt;DO NOT PLACE YOUR EARS NEAR THE SPEAKER TO DETERMINE VOLUME.&lt;/td&gt;&lt;lb/&gt;Use a visual volume indicator instead.&lt;lb/&gt;The generated waveform has full dynamic range, but is pitched high enough to be difficult to perceive.&lt;lb/&gt;Even if you “can’t hear anything”, many common devices are capable of playing it back loud enough to potentially cause permanent hearing damage!&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start transmitting and hold the speaker in position.&lt;/p&gt;
        &lt;p&gt;If all goes well, the clock will set itself within three minutes.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;click to expand/hide&lt;/head&gt;
    &lt;p&gt;Time Station Emulator generates an audio waveform intentionally crafted to create, when played back through consumer-grade audio hardware, the right kind of RF noise to be mistaken for a time station broadcast.&lt;/p&gt;
    &lt;p&gt;Specifically, given a fundamental carrier frequency used by a real time station, it generates and modulates the highest odd-numbered subharmonic that also falls below the Nyquist frequencies of common playback sample rates.&lt;/p&gt;
    &lt;p&gt;One of the higher-frequency harmonics inevitably created by any real-world DAC during playback will then be the original fundamental, which should leak to the environment as a short-range radio transmission via the ad-hoc antenna formed by the physical wires and circuit traces in the audio output path.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;NOTE&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Because it relies upon this leakage, Time Station Emulator works best with a built-in speaker of a phone or tablet.&lt;p&gt;In some cases, wired headphones or earbuds may also be suitable.&lt;/p&gt;&lt;p&gt;Higher-frequency harmonics are considered artifacts beyond the range of human hearing, so they are routinely suppressed by audio compression algorithms and better equipment.&lt;/p&gt;&lt;p&gt;Bluetooth devices and audiophile-grade equipment are therefore less likely to work.&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;&lt;code&gt;src/shared/casefoldingmap.ts&lt;/code&gt; derives from a
data file
published by the Unicode Consortium, and is
Unicode licensed.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;src/shared/icons.ts&lt;/code&gt; derives from SVG icons originally part of
ionicons v5.0.0 and
Flagpack, and is MIT licensed by way of those projects.&lt;/p&gt;
    &lt;p&gt;All other files are also MIT licensed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/kangtastic/timestation"/><published>2026-01-27T20:35:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46786196</id><title>Parametric CAD in Rust</title><updated>2026-01-28T14:00:42.825463+00:00</updated><content>&lt;doc fingerprint="2ac25944db1739fb"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Parametric CAD in Rust&lt;/head&gt;January 27, 2026&lt;p&gt;I keep designing physical parts for our robots. Motor mounts, sensor brackets, wheel hubs. Every time, the workflow is the same: open a GUI CAD program, click around for an hour, export an STL, realize the bolt pattern is 2mm off, repeat.&lt;/p&gt;&lt;p&gt;I wanted to write my parts the way I write firmware. In Rust. With types. With version control. With the ability to change one number and regenerate everything.&lt;/p&gt;&lt;p&gt;So I built vcad.&lt;/p&gt;&lt;code&gt;cargo add vcad
&lt;/code&gt;

&lt;head rend="h2"&gt;The idea&lt;/head&gt;&lt;p&gt;A part is just geometry with a name. You create primitives, combine them with boolean operations, and export. That's it.&lt;/p&gt;&lt;code&gt;use vcad::{centered_cube, centered_cylinder, bolt_pattern};

let plate = centered_cube("plate", 120.0, 80.0, 5.0);
let bore = centered_cylinder("bore", 15.0, 10.0, 64);
let bolts = bolt_pattern(6, 50.0, 4.5, 10.0, 32);

let part = plate - bore - bolts;
part.write_stl("plate.stl").unwrap();&lt;/code&gt;&lt;p&gt;That minus sign is a real boolean difference. &lt;code&gt;+&lt;/code&gt; is union. &lt;code&gt;&amp;amp;&lt;/code&gt; is intersection. Operator overloads make CSG feel like arithmetic.&lt;/p&gt;&lt;p&gt;The plate above has a center bore, four corner mounting holes, and a six-bolt circle pattern. Twelve lines of code. One STL file. Done.&lt;/p&gt;&lt;head rend="h2"&gt;What you can build&lt;/head&gt;&lt;p&gt;The API is small on purpose. Primitives, booleans, transforms, patterns. That's the whole language. But it composes well.&lt;/p&gt;&lt;p&gt;An L-bracket with mounting holes in both faces:&lt;/p&gt;&lt;code&gt;let base = centered_cube("base", 60.0, 40.0, 4.0);
let wall = centered_cube("wall", 60.0, 4.0, 36.0)
    .translate(0.0, -18.0, 20.0);
let bracket = base + wall - base_holes - wall_holes;&lt;/code&gt;&lt;p&gt;A flanged hub with a bolt circle:&lt;/p&gt;&lt;code&gt;let hub = centered_cylinder("hub", 15.0, 20.0, 64);
let flange = centered_cylinder("flange", 30.0, 4.0, 64)
    .translate(0.0, 0.0, -10.0);
let part = hub + flange - bore - bolt_pattern(6, 45.0, 3.0, 8.0, 32);&lt;/code&gt;&lt;p&gt;A radial vent pattern cut from a disc — one slot, repeated eight times:&lt;/p&gt;&lt;code&gt;let slot = centered_cube("slot", 15.0, 2.0, 10.0);
let vents = slot.circular_pattern(20.0, 8);
let panel = centered_cylinder("panel", 35.0, 3.0, 64) - vents;&lt;/code&gt;&lt;p&gt;Every part here is parametric. Change the bolt count, the radius, the wall thickness — one number changes and the whole part regenerates. No clicking. No undo. Just recompile.&lt;/p&gt;&lt;head rend="h2"&gt;Multi-material export&lt;/head&gt;&lt;p&gt;STL is fine for 3D printing, but it throws away all material information. For visualization, vcad exports glTF scenes with PBR materials defined in TOML:&lt;/p&gt;&lt;code&gt;let materials = Materials::parse(r#"
    [materials.body]
    color = [0.32, 0.72, 0.95]
    metallic = 0.1
    roughness = 0.5

    [materials.antenna]
    color = [0.95, 0.3, 0.35]
    metallic = 0.3
"#).unwrap();

let mut scene = Scene::new("mascot");
scene.add(body, "body");
scene.add(antenna_ball, "antenna");
export_scene_glb(&amp;amp;scene, &amp;amp;materials, "mascot.glb").unwrap();&lt;/code&gt;&lt;p&gt;That's our mascot. Entirely CSG. A rounded cube intersected with a sphere for the body, spheres for eyes, cylinders for arms. Eight materials, seventeen parts, one GLB file.&lt;/p&gt;&lt;head rend="h2"&gt;Why Rust&lt;/head&gt;&lt;p&gt;The geometry engine is manifold, which guarantees watertight meshes from boolean operations. The Rust bindings give us zero-cost abstractions over the C++ core — the operator overloads compile down to direct manifold calls. No garbage collection pauses. No floating point surprises from a scripting layer.&lt;/p&gt;&lt;p&gt;But honestly, the main reason is the toolchain. &lt;code&gt;cargo test&lt;/code&gt; runs 21 unit tests that verify volumes, surface areas, bounding boxes, and export round-trips. &lt;code&gt;cargo clippy&lt;/code&gt; catches issues before they become parts with holes in the wrong place. Types prevent you from passing a radius where a diameter was expected.&lt;/p&gt;&lt;p&gt;CAD files should be code. Code has tests, reviews, diffs, and CI. An STL file has... bytes.&lt;/p&gt;&lt;head rend="h2"&gt;Built for agents&lt;/head&gt;&lt;p&gt;One thing I care about that most CAD tools don't: vcad is designed to be used by AI coding agents.&lt;/p&gt;&lt;p&gt;The README has full API tables, a cookbook with copy-pasteable recipes, and a section on Blender MCP integration. An agent can read the docs, generate a part, export it, import it into Blender, position a camera, and render a preview — all in one conversation.&lt;/p&gt;&lt;p&gt;Every render in this post was made that way. Claude generated the geometry with vcad, imported each STL/GLB into Blender via MCP, set up studio lighting, and rendered to PNG. No human touched Blender.&lt;/p&gt;&lt;p&gt;The feedback loop is: describe a part → code generates → mesh exports → render previews → iterate. All in the terminal.&lt;/p&gt;&lt;head rend="h2"&gt;Try it&lt;/head&gt;&lt;code&gt;cargo add vcad
&lt;/code&gt;
&lt;list rend="ul"&gt;&lt;item&gt;Docs: docs.rs/vcad&lt;/item&gt;&lt;item&gt;Source: github.com/ecto/vcad&lt;/item&gt;&lt;item&gt;Site: vcad.io&lt;/item&gt;&lt;/list&gt;&lt;p&gt;It's MIT licensed. The first version is 0.1 — there's a lot more to build. Fillets, chamfers, threads, an interactive web GUI. But the core is solid: primitives, booleans, transforms, export. Everything you need to stop clicking and start typing.&lt;/p&gt;&lt;p&gt;Go make something.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://campedersen.com/vcad"/><published>2026-01-27T20:36:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46791742</id><title>Rust at Scale: An Added Layer of Security for WhatsApp</title><updated>2026-01-28T14:00:42.428893+00:00</updated><content>&lt;doc fingerprint="8e10dda3ac31549d"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WhatsApp has adopted and rolled out a new layer of security for users – built with Rust – as part of its effort to harden defenses against malware threats.&lt;/item&gt;
      &lt;item&gt;WhatsApp’s experience creating and distributing our media consistency library in Rust to billions of devices and browsers proves Rust is production ready at a global scale.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Our Media Handling Strategy&lt;/head&gt;
    &lt;p&gt;WhatsApp provides default end-to-end encryption for over 3 billion people to message securely each and every day. Online security is an adversarial space, and to continue ensuring users can keep messaging securely, we’re constantly adapting and evolving our strategy against cyber-security threats – all while supporting the WhatsApp infrastructure to help people connect.&lt;/p&gt;
    &lt;p&gt;For example, WhatsApp, like many other applications, allows users to share media and other types of documents. WhatsApp helps protect users by warning about dangerous attachments like APKs, yet rare and sophisticated malware could be hidden within a seemingly benign file like an image or video. These maliciously crafted files might target unpatched vulnerabilities in the operating system, libraries distributed by the operating system, or the application itself.&lt;/p&gt;
    &lt;p&gt;To help protect against such potential threads, WhatsApp is increasingly using the Rust programming language, including in our media sharing functionality. Rust is a memory safe language offering numerous security benefits. We believe that this is the largest rollout globally of any library written in Rust.&lt;/p&gt;
    &lt;p&gt;To help explain why and how we rolled this out, we should first look back at a key OS-level vulnerability that sent an important signal to WhatsApp around hardening media-sharing defenses.&lt;/p&gt;
    &lt;head rend="h2"&gt;2015 Android Vulnerability: A Wake-up Call for Media File Protections&lt;/head&gt;
    &lt;p&gt;In 2015, Android devices, and the applications that ran on them, became vulnerable to the “Stagefright” vulnerability. The bug lay in the processing of media files by operating system-provided libraries, so WhatsApp and other applications could not patch the underlying vulnerability. Because it could often take months for people to update to the latest version of their software, we set out to find solutions that would keep WhatsApp users safe, even in the event of an operating system vulnerability.&lt;/p&gt;
    &lt;p&gt;At that time, we realized that a cross-platform C++ library already developed by WhatsApp to send and consistently format MP4 files (called “wamedia”) could be modified to detect files which do not adhere to the MP4 standard and might trigger bugs in a vulnerable OS library on the receiver side – hence putting a target’s security at risk. We rolled out this check and were able to protect WhatsApp users from the Stagefright vulnerability much more rapidly than by depending on users to update the OS itself.&lt;/p&gt;
    &lt;p&gt;But because media checks run automatically on download and process untrusted inputs, we identified early on that wamedia was a prime candidate for using a memory safe language.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our Solution: Rust at Scale&lt;/head&gt;
    &lt;p&gt;Rather than an incremental rewrite, we developed the Rust version of wamedia in parallel with the original C++ version. We used differential fuzzing and extensive integration and unit tests to ensure compatibility between the two implementations.&lt;/p&gt;
    &lt;p&gt;Two major hurdles were the initial binary size increase due to bringing in the Rust standard library and the build system support required for the diverse platforms supported by WhatsApp. WhatsApp made a long-term bet to build that support. In the end, we replaced 160,000 lines of C++ (excluding tests) with 90,000 lines of Rust (including tests). The Rust version showed performance and runtime memory usage advantages over the C++. Given this success, Rust was fully rolled out to all WhatsApp users and many platforms: Android, iOS, Mac, Web, Wearables, and more. With this positive evidence in hand, memory safe languages will play an ever increasing part in WhatsApp’s overall approach to application and user security.&lt;/p&gt;
    &lt;p&gt;Over time, we’ve added more checks for non-conformant structures within certain file types to help protect downstream libraries from parser differential exploit attempts. Additionally, we check higher risk file types, even if structurally conformant, for risk indicators. For instance, PDFs are often a vehicle for malware, and more specifically, the presence of embedded files and scripting elements within a PDF further raise risks. We also detect when one file type masquerades as another, through a spoofed extension or MIME type. Finally, we uniformly flag known dangerous file types, such as executables or applications, for special handling in the application UX. Altogether, we call this ensemble of checks “Kaleidoscope.” This system protects people on WhatsApp from potentially malicious unofficial clients and attachments. Although format checks will not stop every attack, this layer of defense helps mitigate many of them.&lt;/p&gt;
    &lt;p&gt;Each month, these libraries are distributed to billions of phones, laptops, desktops, watches, and browsers running on multiple operating systems for people on WhatsApp, Messenger, and Instagram. This is the largest ever deployment of Rust code to a diverse set of end-user platforms and products that we are aware of. Our experience speaks to the production-readiness and unique value proposition of Rust on the client-side.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Rust Fits In To WhatsApp’s Approach to App Security&lt;/head&gt;
    &lt;p&gt;This is just one example of WhatsApp’s many investments in security. It’s why we built default end-to-end encryption for personal messages and calls, offer end-to-end encrypted backups, and use key transparency technology to verify a secure connection, provide additional calling protections, and more.&lt;/p&gt;
    &lt;p&gt;WhatsApp has a strong track record of being loud when we find issues and working to hold bad actors accountable. For example, WhatsApp reports CVEs for important issues we find in our applications, even if we do not find evidence of exploitation. We do this to give people on WhatsApp the best chance of protecting themselves by seeing a security advisory and updating quickly.&lt;/p&gt;
    &lt;p&gt;To ensure application security, we first must identify and quantify the sources of risk. We do this through internal and external audits like NCC Group’s public assessment of WhatsApp’s end-to-end encrypted backups, fuzzing, static analysis, supply chain management, and automated attack surface analysis. We also recently expanded our Bug Bounty program to introduce the WhatsApp Research Proxy – a tool that makes research into WhatsApp’s network protocol more effective.&lt;/p&gt;
    &lt;p&gt;Next, we reduce the identified risk. Like many others in the industry, we found that the majority of the high severity vulnerabilities we published were due to memory safety issues in code written in the C and C++ programming languages. To combat this we invest in three parallel strategies:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Design the product to minimize unnecessary attack surface exposure.&lt;/item&gt;
      &lt;item&gt;Invest in security assurance for the remaining C and C++ code.&lt;/item&gt;
      &lt;item&gt;Default the choice of memory safe languages, and not C and C++, for new code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;WhatsApp has added protections like CFI, hardened memory allocators, safer buffer handling APIs, and more. C and C++ developers have specialized security training, development guidelines, and automated security analysis on their changes. We also have strict SLAs for fixing issues uncovered by the risk identification process.&lt;/p&gt;
    &lt;head rend="h2"&gt;Accelerating Rust Adoption to Enhance Security&lt;/head&gt;
    &lt;p&gt;Rust enabled WhatsApp’s security team to develop a secure, high performance, cross-platform library to ensure media shared on the platform is consistent and safe across devices. This is an important step forward in adding additional security behind the scenes for users and part of our ongoing defense-in-depth approach. Security teams at WhatsApp and Meta are highlighting opportunities for high impact adoption of Rust to interested teams, and we anticipate accelerating adoption of Rust over the coming years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://engineering.fb.com/2026/01/27/security/rust-at-scale-security-whatsapp/"/><published>2026-01-28T06:21:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46792194</id><title>Make.ts</title><updated>2026-01-28T14:00:42.325741+00:00</updated><content>&lt;doc fingerprint="76c2d8f72f2572bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;make.ts&lt;/head&gt;
    &lt;p&gt;Up Enter Up Up Enter Up Up Up Enter&lt;/p&gt;
    &lt;p&gt; Sounds familiar? This is how I historically have been running benchmarks and other experiments requiring a repeated sequence of commands — type them manually once, then rely on shell history (and maybe some terminal splits) for reproduction. These past few years I’ve arrived at a much better workflow pattern — &lt;code&gt;make.ts&lt;/code&gt;.
          I was forced to adapt it once I started working with multiprocess
          applications, where manually entering commands is borderline
          infeasible. In retrospect, I should have adapted the workflow years
          earlier.
        &lt;/p&gt;
    &lt;head rend="h2"&gt;The Pattern&lt;/head&gt;
    &lt;p&gt; Use a (gitignored) file for interactive scripting. Instead of entering a command directly into the terminal, write it to a file first, and then run the file. For me, I type stuff into &lt;code&gt;make.ts&lt;/code&gt; and then run &lt;code&gt;./make.ts&lt;/code&gt; in my terminal
            (Ok, I need one Up Enter for that).
          &lt;/p&gt;
    &lt;p&gt;I want to be clear here, I am not advocating writing “proper” scripts, just capturing your interactive, ad-hoc command to a persistent file. Of course any command that you want to execute repeatedly belongs to the build system. The surprising thing is that even more complex one-off commands benefit from running through file, because it will take you several tries to get them right!&lt;/p&gt;
    &lt;p&gt;There are many benefits relative to Up Up Up workflow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real commands tend to get large, and it is so much nicer to use a real 2D text editor rather than shell’s line editor.&lt;/item&gt;
      &lt;item&gt; If you need more than one command, you can write several commands, and still run them all with a single key (before &lt;code&gt;make.ts&lt;/code&gt;, I was prone to constructing rather horrific &amp;amp;&amp;amp; conjuncts for this reason).&lt;/item&gt;
      &lt;item&gt;With a sequence of command outlined, you nudge yourself towards incrementally improving them, making them idempotent, and otherwise investing into your own workflow for the next few minutes, without falling into the YAGNI pit from the outset.&lt;/item&gt;
      &lt;item&gt;At some point you might realize after, say, running a series of ad-hoc benchmarks interactively, that you’d rather write a proper script which executes a collection of benchmarks with varying parameters. With the file approach, you already have the meat of the script implemented, and you only need to wrap in a couple of fors and ifs.&lt;/item&gt;
      &lt;item&gt;Finally, if you happen to work with multi-process projects, you’ll find it easier to manage concurrency declaratively, spawning a tree of processes from a single script, rather than switching between terminal splits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Details&lt;/head&gt;
    &lt;p&gt; Use a consistent filename for the script. I use &lt;code&gt;make.ts&lt;/code&gt;, and so there’s a &lt;code&gt;make.ts&lt;/code&gt; in the root
            of most projects I work on. Correspondingly, I have &lt;code&gt;make.ts&lt;/code&gt; line in project’s &lt;code&gt;.git/info/exclude&lt;/code&gt;
            — the &lt;code&gt;.gitignore&lt;/code&gt; file which is not shared. The fixed
            name reduces fixed costs — whenever I need complex interactivity I
            don’t need to come up with a name for a new file, I open my
            pre-existing &lt;code&gt;make.ts&lt;/code&gt;, wipe whatever was there and start
            hacking. Similarly, I have &lt;code&gt;./make.ts&lt;/code&gt; in my shell
            history, so
            fish autosuggestions
            work for me. At one point, I had a VS Code task to run &lt;code&gt;make.ts&lt;/code&gt;, though I now use
            terminal editor.
          &lt;/p&gt;
    &lt;p&gt; Start the script with hash bang, &lt;code&gt;#!/usr/bin/env -S deno run
                --allow-all&lt;/code&gt;
            in my case, and
            &lt;code&gt;chmod a+x make.ts&lt;/code&gt;
            the file, to make it easy to run.
          &lt;/p&gt;
    &lt;p&gt;Write the script in a language that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;you are comfortable with,&lt;/item&gt;
      &lt;item&gt;doesn’t require huge setup,&lt;/item&gt;
      &lt;item&gt;makes it easy to spawn subprocesses,&lt;/item&gt;
      &lt;item&gt;has good support for concurrency.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For me, that is TypeScript. Modern JavaScript is sufficiently ergonomic, and structural, gradual typing is a sweet spot that gives you reasonable code completion, but still allows brute-forcing any problem by throwing enough stringly dicts at it.&lt;/p&gt;
    &lt;p&gt;JavaScript’s tagged template syntax is brilliant for scripting use-cases:&lt;/p&gt;
    &lt;p&gt;prints&lt;/p&gt;
    &lt;p&gt; What happens here is that &lt;code&gt;$&lt;/code&gt; gets a list of literal
            string fragments inside the backticks, and then, separately, a list
            of values to be interpolated in-between. It could
            concatenate everything to just a single string, but it doesn’t have
            to. This is precisely what is required for process spawning, where
            you want to pass an array of strings to the &lt;code&gt;exec&lt;/code&gt;
            syscall.
          &lt;/p&gt;
    &lt;p&gt; Specifically, I use dax library with Deno, which is excellent as a single-binary batteries-included scripting environment (see &amp;lt;3 Deno). Bun has a dax-like library in the box and is a good alternative (though I personally stick with Deno because of &lt;code&gt;deno fmt&lt;/code&gt; and &lt;code&gt;deno lsp&lt;/code&gt;). You could also use
            famous zx, though be mindful that it
            uses your shell as a middleman, something I consider to be
            sloppy (explanation).
          &lt;/p&gt;
    &lt;p&gt; While &lt;code&gt;dax&lt;/code&gt; makes it convenient to spawn a single
            program, &lt;code&gt;async/await&lt;/code&gt; is excellent for herding a slither
            of processes:
          &lt;/p&gt;
    &lt;head rend="h2"&gt;Concrete Example&lt;/head&gt;
    &lt;p&gt;Here’s how I applied this pattern earlier today. I wanted to measure how TigerBeetle cluster recovers from the crash of the primary. The manual way to do that would be to create a bunch of ssh sessions for several cloud machines, format datafiles, start replicas, and then create some load. I almost started to split my terminal up, but then figured out I can do it the smart way.&lt;/p&gt;
    &lt;p&gt;The first step was cross-compiling the binary, uploading it to the cloud machines, and running the cluster (using my box from the other week):&lt;/p&gt;
    &lt;p&gt;Running the above the second time, I realized that I need to kill the old cluster first, so two new commands are “interactively” inserted:&lt;/p&gt;
    &lt;p&gt;At this point, my investment in writing this file and not just entering the commands one-by-one already paid off!&lt;/p&gt;
    &lt;p&gt;The next step is to run the benchmark load in parallel with the cluster:&lt;/p&gt;
    &lt;p&gt;I don’t need two terminals for two processes, and I get to copy-paste-edit the mostly same command.&lt;/p&gt;
    &lt;p&gt; For the next step, I actually want to kill one of the replicas, and I also want to capture live logs, to see in real-time how the cluster reacts. This is where &lt;code&gt;0-5&lt;/code&gt; multiplexing syntax
            of box falls short, but, given that this is JavaScript, I can just
            write a for loop:
          &lt;/p&gt;
    &lt;p&gt; At this point, I do need two terminals. One runs &lt;code&gt;./make.ts&lt;/code&gt; and shows the log from the benchmark itself, the
            other runs &lt;code&gt;tail -f logs/2.log&lt;/code&gt; to watch the next replica
            to become primary.
          &lt;/p&gt;
    &lt;p&gt;I have definitelly crossed the line where writing a script makes sense, but the neat thing is that the gradual evolution up to this point. There isn’t a discontinuity where I need to spend 15 minutes trying to shape various ad-hoc commands from five terminals into a single coherent script, it was in the file to begin with.&lt;/p&gt;
    &lt;p&gt; And then the script is easy to evolve. Once you realize that it’s a good idea to also run the same benchmark against a different, baseline version TigerBeetle, you replace &lt;code&gt;./tigerbeetle&lt;/code&gt;
            with
            &lt;code&gt;./${tigerbeetle}&lt;/code&gt; and wrap everything into
          &lt;/p&gt;
    &lt;p&gt;A bit more hacking, and you end up with a repeatable benchmark schedule for a matrix of parameters:&lt;/p&gt;
    &lt;p&gt;That’s the gist of it. Don’t let the shell history be your source, capture it into the file first!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://matklad.github.io/2026/01/27/make-ts.html"/><published>2026-01-28T07:35:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46792370</id><title>ASML staffing changes could result in a net reduction of around 1700 positions</title><updated>2026-01-28T14:00:42.053726+00:00</updated><content>&lt;doc fingerprint="af14c01700f8a5e0"&gt;
  &lt;main&gt;
    &lt;p&gt;Announcement - Veldhoven, the Netherlands, January 28, 2026&lt;/p&gt;
    &lt;p&gt;Earlier today, as referenced in our FY 2025 results release, the ASML Board of Management shared the following internal message with employees.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Dear ASML colleagues -- &lt;lb/&gt;Today we shared our full-year financial results for 2025, as well as our outlook for the year ahead. The semiconductor ecosystem is poised to experience significant growth in the coming years, and ASML is well positioned to leverage this positive development. On behalf of the Board of Management, I want to thank everyone for their contribution to this success. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;We can attribute our success to our customer dedication, engineering talent and collaborative approach to the ecosystem. Our ability to innovate and execute has generated substantial benefits for our customers and suppliers, our colleagues, and our investors. We intend to continue to grow our workforce and footprint, including at our planned second campus in Eindhoven, in line with customer demand. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;As with any company that grows rapidly, however, we need to be mindful that the way we have grown does not slow us down. The feedback from our colleagues, our suppliers and our customers shows that our ways of working have, in some cases, become less agile. Engineers in particular have expressed their desire to focus their time on engineering, without being hampered by slow process flows, and restore the fast-moving culture that has made us so successful. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;We believe it is important to address these issues so that we are well prepared for future growth and well positioned to continue to deliver for our customers. As a result, we are announcing today that we intend to strengthen our focus on engineering and innovation in critical areas of our company through the streamlining of the Technology and the IT organizations. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;In the Technology organization, we are proposing to shift from a project/matrix setup to one where most of our engineers will be dedicated to a specific product and module. This will allow us to simplify processes and decision-making. This need for simplification is something that we have heard consistently from all levels of the organization. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;We are safeguarding what makes us strong: a dedicated foundational team which will ensure that we continue to develop our deep technical competence, and drive fit-for-purpose commonality and standards across all engineering domains. &lt;lb/&gt;As a result of these proposed changes, some roles -- mainly at the leadership level -- may no longer be required. At the same time, to retain our engineering capability, we will create new engineering jobs to strengthen existing technology projects and embark on new ones to support our own and our customers’ growth plans. While this will allow some of our impacted colleagues to move to new roles, we have to acknowledge that some will leave ASML as a result. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;In addition to the Technology changes, we will also look at the setup of the IT &amp;amp; Data organization, similarly seeking ways to streamline its structure to optimize its delivery capabilities. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;In the coming weeks we will be working closely with our social partners in the Netherlands to discuss the intent and extent of these changes. At this stage, we believe the proposed changes could ultimately result in a net reduction of around 1,700 positions, mostly in the Netherlands, with some in the United States. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The focus of these changes is on the Technology and the IT organizations. ASML continues to grow and will need to create roles as required to meet customer demand for new machines and servicing, including in Manufacturing, Customer Support and Sales. &lt;lb/&gt;Of course, every colleague is someone that we value and appreciate: We are committed to acting responsibly - with care, speed, transparency, and fairness - and to supporting them through this change. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;We recognize that this news may create uncertainty and raise questions for many of you, but we believe strongly that it is important to be transparent in our approach. We will host all-employee meetings today to share more about the proposed changes. Further information sessions will be held for teams affected, and we commit to continuing to inform you all about what we can, when we can. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;As our FY 2025 financial results demonstrate, we are choosing to make these changes at a moment of strength for the company. Improving our processes and systems will allow us to innovate more and innovate better, generating further responsible growth for ASML and our stakeholders. &lt;lb/&gt;With best wishes &lt;lb/&gt;Christophe, on behalf of the ASML Board of Management &lt;/p&gt;
    &lt;p&gt;Forward Looking Statement&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.asml.com/en/news/press-releases/2026/strengthening-focus-on-engineering-and-innovation"/><published>2026-01-28T08:02:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46792572</id><title>Virtual Boy on TV with Intelligent Systems Video Boy</title><updated>2026-01-28T14:00:41.685094+00:00</updated><content>&lt;doc fingerprint="2d351f13193782d2"&gt;
  &lt;main&gt;
    &lt;p&gt;The Video Boy plays Nintendo Virtual Boy games on a TV or monitor. As with many of Nintendo's development tools, it was made by Intelligent Systems. These were used to record video or screenshots; it's said that this particular unit was used by the venerable Nintendo Power.&lt;/p&gt;
    &lt;p&gt;Contents:&lt;/p&gt;
    &lt;p&gt;The Virtual Boy inputs are on the top and front of the unit. From left to right: cartridge slot, link cable port, and controller port. There's also a red power LED. A cartridge goes in with the label facing down; it plugs directly into a Virtual Boy main board.&lt;/p&gt;
    &lt;p&gt;Note that the name shown here is "Video Adapter VUE". "Video Boy" appears nowhere on this device, but it is found in the instructions as "VIDEO-BOY (VUE)" and on the Intelligent Systems site as ãããªãã¼ã¤ or videoboy.html.&lt;/p&gt;
    &lt;p&gt;The AV multi-out is PAL, which is 50 FPS like the Virtual Boy; this avoids a more complicated and lossy scan conversion to ~60 FPS NTSC.&lt;/p&gt;
    &lt;p&gt;The unit came with a DB9 to 3xRCA cable for the RGB OUT; I haven't tested it, lacking a monitor that takes raw RGB. The SCANNER port connects to a development headset; I don't have one.&lt;/p&gt;
    &lt;p&gt;This row of switches, SW1, is exposed on the bottom of the unit. The initial setting was: 1 off, 2 on, 3 on, 4 on, 5 off, 6 off, 7 off, 8 on.&lt;/p&gt;
    &lt;p&gt;7 and 8 control which display is shown: 8 controls the left, rendered in Virtual Boy red, 7 is the right, rendered in green. With both 7 and 8 on, left and right are combined, this was intended as anaglyph 3D. See the video output below.&lt;/p&gt;
    &lt;p&gt;Switching 5 on prevents anything from working. I didn't notice any effect from switching the others.&lt;/p&gt;
    &lt;p&gt;There's an image of the instructions which describes the switches, unfortunately it's low resolution. I think it says "don't use" for 5 and 6, and 1-4 are for setting some integer, "1=MSB, 4=LSB, ON=0, OFF=1".&lt;/p&gt;
    &lt;p&gt;There are nearby unpopulated jumper pads, and a set of pads marked "CL" which seem to be cut traces. This may have been hardwired when the switch wasn't installed.&lt;/p&gt;
    &lt;p&gt;The top label says "ããã¸ã§å 12å·", approximately "Project No. 12".&lt;/p&gt;
    &lt;p&gt;The bottom label says "VUE TV MONITOR", identifying the board inside. "Ver. C" indicates the third or fourth version, and "+æ¹é " is "plus retrofit", perhaps indicating the various jumper wire patches. "MAI-VUE-X8" identifies the internal Virtual Boy main board.&lt;/p&gt;
    &lt;p&gt;The monitor board (left) has a Virtual Boy main board mounted on top of it (center top between the metal braces). The right side of the case is taken up by the power supply.&lt;/p&gt;
    &lt;p&gt;The Virtual Boy generates an image by sweeping a column of light horizontally. To convert this to the rows of a PAL TV signal, at least one frame must be buffered and rotated; the monitor board performs this conversion.&lt;/p&gt;
    &lt;p&gt;Note that the monitor board has unpopulated connector pads on the left (CN1, label not visible) and lower right (CN2). I think this same board can be configured to go into a VUE-DEBUGGER development unit (see PAL monitor), CN1 would be where it plugs into the debugger bus.&lt;/p&gt;
    &lt;p&gt;The main board is the heart of a Virtual Boy. This seems to be an early or development board, MAI-VUE-X8, (c) 1994. (A production board is VUE-MAI-01, (c) 1995.)&lt;/p&gt;
    &lt;p&gt;For info on Virtual Boy hardware:&lt;/p&gt;
    &lt;p&gt;Under the MAI-VUE-X8 board there are a few stray ICs and the ribbon cables that carry video to the monitor board (left and right). The board name was hiding under here: "VUE TV MONITOR(C)", which matches "Ver. C" on the label.&lt;/p&gt;
    &lt;p&gt;The workhorses are these two big Xilinx XC3064-70 FPGAs, which get their configuration from the 1765DPC PROMs between them. Perhaps one stores input while the other scans output.&lt;/p&gt;
    &lt;p&gt;The big NEC chip on the left (D27C1024A-15) is a 1Mbit EPROM, with an Intelligent Systems metal sticker to prevent UV erasure. I guess that at least one of the FPGAs is configured as a DSP, running a program from the EPROM.&lt;/p&gt;
    &lt;p&gt;There are eight 32KB SRAMs across the board, numbered in two groups: U12 &amp;amp; U13 (64KB), and U17-U22 (192KB). The 64KB might be DSP work RAM. 192KB would exactly fit two 384x256 frames with 8 bits per pixel (384x256 is the size of the Virtual Boy framebuffer, though only the top 224 rows are used). Virtual Boy graphics are only 2 bits per pixel, but each of the three non-black brightness levels can be configured by an independent 8 bit register, so 8 bits per pixel is plausible. This could be a double buffer (one taking input while the other scans output), or it could be one buffer per eye, or a double buffer for each eye at only 4 bits per pixel.&lt;/p&gt;
    &lt;p&gt;The oscillator Y1 (left, below the EPROM) seems to be associated with a VCLK test point, probably Video Clock; it's labeled D177J4, which suggests the 17.734475 MHz PAL color subcarrier. There's an unpopulated space for a second oscillator, Y2, and support components; it's grouped with the SCLK test point, maybe the Servo Clock. This may have be used when the board was configured to plug into the VUE-DEBUGGER.&lt;/p&gt;
    &lt;p&gt;Output is produced here by two MB40778 8-bit DACs (bottom center), an S-RGB video encoder (center right), and numerous discrete components. On the left are the output connectors: CN10 at top is RGB, CN8 at bottom is AV multi-out. I guess that each DAC handles one channel, connected to the red and green inputs of the S-RGB.&lt;/p&gt;
    &lt;p&gt;There are three jumpers on the bottom, and one that goes to (and through) the Virtual Boy board, strategically glued. Version C might have still needed a few fixes, or maybe these are used to retrofit a particular MAI-VUE board, or they could be specific to the standalone Video Boy configuration.&lt;/p&gt;
    &lt;p&gt;These images of Virtual Boy Wario Land come through an Elgato dongle, deinterlaced with ffmpeg filter yadif=send_field.&lt;/p&gt;
    &lt;p&gt;The composite video output is a bit blurry. DIP switches 7 and 8 control how the two Virtual Boy displays are combined: 8 enables the left display in red, 7 the right in green, and they can be combined (center).&lt;/p&gt;
    &lt;p&gt;Here's the stereo effect in action, note how the colors separate on the backswing.&lt;/p&gt;
    &lt;p&gt;S-Video has nice crisp pixels, thanks to a higher luma resolution than composite. The Elgato isn't picking up chroma for some reason; this may be a flaw in the multi-out to S-Video cable I'm using, or the VUE Monitor may not output a color PAL S-Video signal. I use the brighter "green" output on the right when I occasionally stream Virtual Boy games.&lt;/p&gt;
    &lt;p&gt;Intelligent Systems had a ï¼¶ï¼µï¼¥ï¼ï¼¤ï¼¥ï¼¢ï¼µï¼§ï¼§ï¼¥ï¼²ã·ãªã¼ãºã®ãæ¡å site, with a section on the ãããªãã¼ã¤ (Video Boy) VUE and a connection diagram.&lt;/p&gt;
    &lt;p&gt;Here's the text of the Video Boy page, based on Google Translate:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Simply connect a TV monitor that has PAL video input or RGB input to the Video Boy VUE, and a simulated stereoscopic Virtual Boy image will be displayed. By playing the Virtual Boy game cartridge on the Video Boy VUE, you can display the left-eye image and the right-eye image on the TV monitor in red and green, respectively. It is also possible to select and display an image for the left eye only or an image for the right eye only.&lt;/p&gt;
      &lt;p&gt;Since the same screen can be checked by multiple people, it is very useful during demonstrations, specification meetings, debugging, etc.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I think the PALä»æ§ã¢ãã¿åºåãã¼ãVUE (PAL monitor output board) was the same VUE TV Monitor board that's used in the Video Boy, configured as an expansion board for the VUE-DEBUGGER development unit. The notes on that page are similar to the Video Boy, with these two added points:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You can record your debugging work on video. This makes it easier to reproduce and check bugs that occur only occasionally, and improves debugging efficiency.&lt;/p&gt;
      &lt;p&gt;The need for programmers to look into the scanner during development is drastically reduced, reducing the strain on the eyes of the developer and improving work efficiency.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;lettuce, a developer who had worked with the Video Boy, has a page with an image of the instructions, along with a longer post about working with the Virtual Boy.&lt;/p&gt;
    &lt;p&gt;Initially published 2021-05-14.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hcs64.com/video-boy-vue/"/><published>2026-01-28T08:32:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46793693</id><title>Show HN: The HN Arcade</title><updated>2026-01-28T14:00:41.515295+00:00</updated><content>&lt;doc fingerprint="35d1c25da4e5eef"&gt;
  &lt;main&gt;
    &lt;p&gt;Skip to main content HN Arcade Games Tags How It Works GitHub HN Arcade Discover games from Hacker News Browse Games Submit a Game&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://andrewgy8.github.io/hnarcade/"/><published>2026-01-28T10:50:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46794231</id><title>Kyber (YC W23) Is Hiring a Staff Engineer</title><updated>2026-01-28T14:00:41.031900+00:00</updated><content>&lt;doc fingerprint="f15442ba0e572026"&gt;
  &lt;main&gt;
    &lt;p&gt;Instantly draft, review, and send complex regulatory notices.&lt;/p&gt;
    &lt;p&gt;At Kyber, we're building the next-generation document platform for enterprises. Today, our AI-native solution transforms regulatory document workflows, enabling insurance claims organizations to consolidate 80% of their templates, spend 65% less time drafting, and compress overall communication cycle times by 5x. Our vision is for every enterprise to seamlessly leverage AI templates to generate every document.&lt;/p&gt;
    &lt;p&gt;Over the past 18 months, we’ve:&lt;/p&gt;
    &lt;p&gt;Kyber is backed by top Silicon Valley VCs, including Y Combinator and Fellows Fund.&lt;/p&gt;
    &lt;p&gt;We're seeking a Staff Engineer with a clear line of sight to CTO. This role is ideal for someone who is already operating as a 10x engineer, thrives in early stage environments, and is excited to design and scale mission-critical AI systems from first principles.&lt;/p&gt;
    &lt;p&gt;Responsibilities:&lt;/p&gt;
    &lt;p&gt;What We’re Looking For in You:&lt;/p&gt;
    &lt;p&gt;Join us in building and scaling a game-changing enterprise product powered by state-of-the-art AI. At Kyber, your contributions will directly impact how businesses handle some of their most critical workflows and customer interactions.&lt;/p&gt;
    &lt;p&gt;If you’re obsessed with building, AI, and transforming enterprise workflows, we’d love to hear from you!&lt;/p&gt;
    &lt;p&gt;We want to hear from extraordinary individuals who are ready to shape the future of enterprise documents. To stand out, ask someone you’ve worked with to send your resume or LinkedIn profile, along with a brief 2-3 sentence endorsement, directly to arvind [at] askkyber.com.&lt;/p&gt;
    &lt;p&gt;Referrals matter. They help us understand the impact you’ve already had and the kind of teammate you’ll be. A strong referee can elevate your application, so choose someone who knows your skills and character well.&lt;/p&gt;
    &lt;p&gt;Apply today and help us bring enterprise documents into the AI-native age.&lt;/p&gt;
    &lt;p&gt;With Kyber, companies operating in regulated industries can quickly draft, review, and send complex regulatory notices. For example, when Branch Insurance's claims team has to settle a claim, instead of spending hours piecing together evidence to draft a complex notice, they can simply upload the details of the claim to Kyber, auto-generate multiple best in-class drafts, easily assign reviewers, collaborate on notices in real-time, and then send the letter to the individual the notice is for. Kyber not only saves these teams time, it also improves overall quality, accountability, and traceability.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/kyber/jobs/GPJkv5v-staff-engineer-tech-lead"/><published>2026-01-28T12:00:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46794258</id><title>SoftBank in Talks to Invest Up to $30B More in OpenAI</title><updated>2026-01-28T14:00:40.853441+00:00</updated><content/><link href="https://www.wsj.com/tech/ai/softbank-in-talks-to-invest-up-to-30-billion-more-in-openai-8585dea3"/><published>2026-01-28T12:03:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46794365</id><title>ICE and Palantir: US agents using health data to hunt illegal immigrants</title><updated>2026-01-28T14:00:39.832456+00:00</updated><content>&lt;doc fingerprint="ed98829a77ffe619"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;ICE and Palantir: US agents using health data to hunt illegal immigrants&lt;/head&gt;BMJ 2026; 392 doi: https://doi.org/10.1136/bmj.s168 (Published 27 January 2026) Cite this as: BMJ 2026;392:s168&lt;p&gt;US immigration agents are using an app developed by Palantir that draws on the health records of millions of Americans to find and detain illegal immigrants.&lt;/p&gt;&lt;p&gt;The revelation comes as the US’s Immigration and Customs Enforcement (ICE) comes under increased scrutiny after the shooting of Alex Pretti, a 37 year old intensive care nurse, by ICE agents in Minneapolis over the weekend.&lt;/p&gt;&lt;p&gt;It has now emerged that data from the Department of Health and Human Services (HHS) is being fed—along with other commercial and public datasets—into an analytics app developed by Palantir, according to an investigation by news outlet 404 Media.1&lt;/p&gt;&lt;p&gt;Testimony from an ICE official and internal documents obtained by 404 show the app, Enhanced Leads Identification and Targeting for Enforcement (Elite), maps areas to help agents decide where to conduct detention raids.&lt;/p&gt;&lt;p&gt;The tool was reportedly used in recent operations, including a raid in Oregon in October in which 30 people were arrested.&lt;/p&gt;&lt;p&gt;According to the 404 investigation, Elite pulls names, addresses, and photos from health records. It reportedly works like Google Maps, showing ICE agents which areas have higher densities of people who could be detained. It also generates dossiers on individuals, including their name, photo, and “confidence scores” that they are at home.&lt;/p&gt;&lt;p&gt;An HHS spokesperson contacted by The BMJ did not clarify what information was given to ICE but said the information sharing was permitted under national law.&lt;/p&gt;&lt;p&gt;“Several federal laws authorise the Centers for Medicare and Medicaid Services (CMS) to make certain information available to the Department of Homeland Security (DHS),” the spokesperson said. “Under the Immigration and Nationality Act, ‘any information in any records kept by any department or agency of the government as to the identity and location of aliens in the US shall be made available to’ immigration authorities.”&lt;/p&gt;&lt;p&gt;There is no data sharing agreement between CMS and DHS on “US citizens and lawful permanent residents,” they added.&lt;/p&gt;&lt;p&gt;In July 2025, it was revealed that a data sharing agreement between the US health department and ICE would see the personal data of 79 million Americans receiving Medicaid assistance handed over to the deportation agency.&lt;/p&gt;&lt;p&gt;This includes names, addresses, birth dates, and ethnic and racial information.2&lt;/p&gt;&lt;p&gt;Palantir, an American tech giant best known for its work with US defence and intelligence agencies, also works in the UK where it won a £330 million contract to develop data platforms that integrate information held across separate NHS trusts.&lt;/p&gt;&lt;p&gt;Doctors and patient advocacy and rights groups, as well as the BMA, have questioned if it is ethical for a US defence technology firm to handle sensitive health data and if the deal could undermine patient trust.3&lt;/p&gt;&lt;p&gt;Contacted by The BMJ, a Palantir spokesperson said it “cannot comment on specific data sources used by our customers in their confidential environments. However, Palantir expects data sharing among government agencies to be conducted in accordance with lawful authorities and compliant with applicable data sharing agreements.”&lt;/p&gt;&lt;head rend="h2"&gt;Indiscriminate and a violation of rights&lt;/head&gt;&lt;p&gt;Rights groups say the use of location based targeting is indiscriminate and violates due process, while some US states have challenged the move in court, leading to a temporary suspension of information sharing.4&lt;/p&gt;&lt;p&gt;John Howard, a specialist in healthcare data privacy at the University of Arizona, said that although the interagency sharing of data from health records is legal and likely covered under the Privacy Act rather than the Health Insurance Portability and Accountability Act, it could damage people’s trust in healthcare.&lt;/p&gt;&lt;p&gt;“If a population does not trust a health system to protect it and its information there could be a loss in trust of that system,” he told The BMJ.&lt;/p&gt;&lt;p&gt;This, he pointed out, was one of the purposes behind the Health Insurance Portability and Accountability Act, signed into law in 1996 to protect patient data. The act places limits on the disclosure of health information but does not cover all data held by health agencies and does not apply equally across all government departments.&lt;/p&gt;&lt;p&gt;Still, the act was put in place “to build trust in the US health system so people will seek care when they need it,” Howard said. “Eroding this trust can cause public health problems if we have sick or injured people that forgo seeking care.”&lt;/p&gt;&lt;p&gt;He urged the US Congress to act. “If circumstances arise where a law is applied in a manner that is counter to the public policy purpose intended by Congress, it is the responsibility of our lawmakers to step in and provide direction and corrections needed to account for the change,” he said. “If our leaders are not willing to do this an erosion in the trust of our entire legal system could result. I do not think this is something anyone wants.”&lt;/p&gt;&lt;p&gt;Dave Maass, director of investigations at the non-profit organisation Electronic Frontier Foundation, said, “In the wake of the Watergate and COINTELPRO scandals of the 1970s, US Congress enacted laws to protect private information from government misuse. Data grabs like the DHS’s reported use of healthcare data for immigration enforcement are exactly why.”&lt;/p&gt;&lt;p&gt;“Government agencies necessarily collect information to provide essential services, but when governments begin pooling data and using it for purposes unrelated to why it was originally collected, it provides them with enormous power that can be abused. The misuse of healthcare data is particularly insidious,” Maass told The BMJ.&lt;/p&gt;&lt;p&gt;“This information is not only extremely sensitive, but its misuse for law enforcement purposes could also deter people from seeking essential medical care—with grave individual and collective consequences.”&lt;/p&gt;&lt;p&gt;Do you have any additional information on this story?&lt;/p&gt;&lt;p&gt;Contact newsdesk@bmj.com&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bmj.com/content/392/bmj.s168"/><published>2026-01-28T12:18:12+00:00</published></entry></feed>