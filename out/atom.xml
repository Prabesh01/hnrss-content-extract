<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-24T10:42:26.227952+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46733624</id><title>The tech monoculture is finally breaking</title><updated>2026-01-24T10:42:32.601169+00:00</updated><content>&lt;doc fingerprint="afa5b35d9a6157f8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Tech is Fun Again: The Tech Monoculture is Finally Breaking&lt;/head&gt;
    &lt;p&gt;Growing up in the 90s and early 2000s, tech was a foundational part of my childhood.&lt;/p&gt;
    &lt;p&gt;I built more physical computers than I can remember. We went from paper maps to GPS (which itself evolved from DVDs with static maps to internet-connected real-time navigation). CD players became MP3 players, then streaming services. We had Palm Pilots and early attempts at “smart” phones, which were anything but. Our computers could search for extraterrestrial life through SETI. We emerged from the pager era to portable phones to the entire internet in our pocket (which evolved from charging per SMS or megabyte to unlimited data plans).&lt;/p&gt;
    &lt;p&gt;We went through what I still think of as a golden era of console gaming: the N64 &amp;amp; PlayStation, then PS2, Xbox, and GameCube. Meanwhile, our bulky CRT monitors became flat (with a misadventure toward “projection” TVs in between). We could buy gadgets for everything. Best Buy and RadioShack felt like amusement parks we’d visit without intention, ready to be drawn in by something new. A trip to Asia’s electronics stores felt like a genuine step into the future.&lt;/p&gt;
    &lt;p&gt;Today, we have everything we did back then, and much more. And yet it somehow feels like we’ve been left with less.&lt;/p&gt;
    &lt;p&gt;In the early 2000s, tech began a decades-long consolidation. Almost everything we used before became a function of a single device. Objectively, this was an improvement—old VCR interfaces were awful, early MP3 players were clunky, GPS lacked real-time traffic data, and nothing talked to each other. And yet, through that consolidation, something intangible was taken from us.&lt;/p&gt;
    &lt;p&gt;Our devices lost their unique personalities. Phones became our alarm clocks, flashlights, calendars, watches, cameras, GPS units, music players, radios, journals, and gaming devices—all at once. We betrayed our focus in the pursuit of convenience, and the personality of our devices for homogeneity.&lt;/p&gt;
    &lt;p&gt;The benefits were clear to us, but the costs weren’t.&lt;/p&gt;
    &lt;p&gt;This convergence created winner-take-all (and two-player) markets. Console gaming became PlayStation or Nintendo. Phones became Android or iOS. Computers became Mac or Windows. PC gaming became synonymous with Steam. Everything else became a feature inside one of those platforms, with globally synchronized updates making our experiences increasingly uniform, and bland.&lt;/p&gt;
    &lt;p&gt;For a long time, that felt inevitable. But it’s only become clear in retrospect that somewhere in the early 2020s, things started to change.&lt;/p&gt;
    &lt;p&gt;New paradigms are emerging for the first time since mobile. VR is no longer experimental. Early AR is starting to reach consumers. Meta shipped a wearable that normal people actually use, thanks to a clever Ray-Ban partnership (and associated equity stake). 3D printers have become real household products. Wearables are diversifying—smart rings, over-the-counter glucose monitors, connected beds.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Apple’s aggressive push for services revenue has alienated developers and users alike, creating space for alternatives. And nostalgia has revealed itself as massive, underserved economic demand.&lt;/p&gt;
    &lt;p&gt;Gen-Z is buying single-purpose iPods and wired headphones. Pokémon cards are trendy. My friends and I are amassing N64 game collections again. There is a revived appetite for film cameras and Polaroids. Companies are recreating old hardware in modern form—ModRetro’s upcoming FPGA-based M64 plays native N64 cartridges, following their successful Game Boy recreation. They’re now working to bring a “next-gen” CRT monitor to market. The Playdate proved there’s still room for third-party handhelds with their own unique philosophies. Even Nintendo couldn’t resist capitalizing with the re-release of their classic consoles.&lt;/p&gt;
    &lt;p&gt;Design matters again. In our devices, and in our lives. Art Deco is in vogue. Cyberpunk has never been more culturally mainstream. Color is back, and bold.&lt;/p&gt;
    &lt;p&gt;Canon, Sony, and Nikon may have replaced Kodak for professionals, but Leica is thriving again and Kodak Instamatic has gone viral. People want devices that feel personal—leather finishes, physical controls, intentional constraints. For years this expression was limited to phone cases. Now it’s showing up in hardware itself.&lt;/p&gt;
    &lt;p&gt;Tech is starting to resemble the wristwatch market: collaborations, limited editions, exclusivity. A market with many players—emerging companies, niche studios, design-forward brands, and even failing companies—is healthier than one dominated by a few giants.&lt;/p&gt;
    &lt;p&gt;Antitrust pressure has slowed consolidation, opened app distribution, killed the anti-competitive iMessage and AirDrop moats, and made big tech cautious about horizontal expansion. And yet market forces may matter even more. Subscriptions keep multiplying. Advertising creeps into everything. Consolidated platforms are becoming bloated, degrading experiences. Platforms extract value in ways that betray their original philosophies.&lt;/p&gt;
    &lt;p&gt;Apple’s push toward services has been financially successful but culturally damaging. Users are looking elsewhere. It was imperceptible at first, but that sentiment is spreading.&lt;/p&gt;
    &lt;p&gt;Barriers to entry are lower than they’ve been in decades. Software can be deployed in minutes. Hardware is still hard, but 3D printing has revolutionized prototyping and accessible manufacturing services have drastically lowered the cost and time to market. Even the consolidation on the USB-C standard has played a role, allowing switching devices without investing in a new ecosystem.&lt;/p&gt;
    &lt;p&gt;We’ve also grown tired of curation by algorithm. What we watch is shaped by recommendation engines. How we perceive it is influenced by aggregate ratings. I miss wandering through video stores, choosing based on nothing more than a cover. Discovery felt accidental and my opinions felt like my own.&lt;/p&gt;
    &lt;p&gt;Burnout plays a role too. A Timex ad went viral this year: “Know the time without seeing you have 1,249 unanswered emails.” People are gravitating toward rigid, single-purpose experiences that let them fully disengage.&lt;/p&gt;
    &lt;p&gt;Our appetite for alternatives has grown, while they’ve also become easier to create. LLMs and modern tools have lowered the effort required to build things. Side projects are easier to start and finish. Even when large companies offer better experiences on paper, individuals are building alternatives for the joy of it. Some go viral. Consumers end up with more choice.&lt;/p&gt;
    &lt;p&gt;Nothing would have been harder to project than the growth of Linux on the desktop. Integrated platforms seemingly made the Linux philosophy untenable, and yet it may now be growing as a direct result of this decoupling. This was a feature, not a bug.&lt;/p&gt;
    &lt;p&gt;Looking at my own purchases from 2025, the pattern becomes obvious:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;TRMNL (a no-distraction e-paper display)&lt;/item&gt;
      &lt;item&gt;Ray-Ban Meta glasses&lt;/item&gt;
      &lt;item&gt;Leica D-LUX&lt;/item&gt;
      &lt;item&gt;Wired headphones&lt;/item&gt;
      &lt;item&gt;Android Pixel Pro (alongside iPhone)&lt;/item&gt;
      &lt;item&gt;ASUS ROG laptop (for CUDA and gaming)&lt;/item&gt;
      &lt;item&gt;Matic AI vacuum&lt;/item&gt;
      &lt;item&gt;Govee programmable lights&lt;/item&gt;
      &lt;item&gt;28 TB Seagate hard drive&lt;/item&gt;
      &lt;item&gt;Bambu Labs P1S 3D printer&lt;/item&gt;
      &lt;item&gt;Kindle (finally retiring my last mini-USB device)&lt;/item&gt;
      &lt;item&gt;Oura Ring&lt;/item&gt;
      &lt;item&gt;Abbott Lingo glucose sensor&lt;/item&gt;
      &lt;item&gt;iPad (single-purpose: as a second MacBook display while traveling)&lt;/item&gt;
      &lt;item&gt;More mechanical watches than I can count (while not tech per se, it does reduce the breadth of the Apple ecosystem)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is more than I’ve bought in the last 5 years, and I’m already excited for 2026. While Meta, Apple, Amazon, and Google still appear in my list, their purposes are narrower for me than in the past, and their presence is often no longer part of a two-player market. To be clear, these companies often make great products that should exist, but they should be easy to use as standalone à la carte offerings, not forced omakase experiences.&lt;/p&gt;
    &lt;p&gt;We’ll never truly recreate the late 80s or mid-90s. SaaS, subscription pricing, and centralized platforms are here to stay. But this feels like the beginning of another golden era—one defined less by consolidation and more by variety, personality, and choice.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://www.jasonwillems.com/technology/2025/12/17/Tech-Is-Fun-Again/"/><published>2026-01-23T15:26:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46734302</id><title>Gas Town's agent patterns, design bottlenecks, and vibecoding at scale</title><updated>2026-01-24T10:42:32.170031+00:00</updated><content>&lt;doc fingerprint="3714585349c384a7"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Table of Contents&lt;/head&gt;
    &lt;head rend="h4"&gt;Table of Contents&lt;/head&gt;
    &lt;p&gt;A few weeks ago Steve Yegge published an elaborate manifesto and guide to Gas Town, his Mad-Max-Slow-Horses-Waterworld-etc-themed agent orchestrator that runs dozens of coding agents simultaneously in a metaphorical town of automated activity. Gas Town is entirely vibecoded, hastily designed with off-the-cuff solutions, and inefficiently burning through thousands of dollars a month in API costs.&lt;/p&gt;
    &lt;p&gt;This doesn’t sound promising, but it’s lit divisive debates and sparks of change across the software engineering community. A small hype machine has formed around it. It’s made the rounds through every engineering team’s Slack, probably twice. There’s somehow already a $GAS meme coin doing over $400k in earnings. This was not Yegge’s doing – someone else set it up on the crypto platform Bags which ties tokens to individual creators. The coin holds no legitimate relationship to Gas Town’s success or failure so this is the purest of pure speculative betting. I expect nothing less from the crypto bros. And the hype is justified. First, because it’s utterly unhinged, and second because it’s a serious indication of how agents will change the nature of software development from this point on.&lt;/p&gt;
    &lt;p&gt;You should at least skim through Yegge’s original article before continuing to read my reflections. First, because I’m not going to comprehensively summarise it. A challenging task given the sprawling, haphazard nature of the piece And second, because a even a one minute glance over Yegge’s style of writing will make the vibes clear.&lt;/p&gt;
    &lt;p&gt;We should take Yegge’s creation seriously not because it’s a serious, working tool for today’s developers (it isn’t). But because it’s a good piece of speculative design fiction that asks provocative questions and reveals the shape of constraints we’ll face as agentic coding systems mature and grow.&lt;/p&gt;
    &lt;p&gt;“Design fiction” or “speculative design” is a branch of design where you creating things (objects, prototypes, sketches) from a plausible near future. Not to predict what’s going to happen, but to provoke questions and start conversations about what could happen. Not in a bright-and-glorious-flying-cars way that futurism can sometimes fall into. But, most helpfully, in a way that thinks about banal details, overlooked everyday interactions, low status objects, imperfect implementations, knock-on effects, and inconveniences. See the Near Future Lab’s short explainer video and their Manual of Design Fiction if you want to learn more.&lt;/p&gt;
    &lt;p&gt;I also think Yegge deserves praise for exercising agency and taking a swing at a system like this, despite the inefficiencies and chaos of this iteration. And then running a public tour of his shitty, quarter-built plane while it’s mid-flight.&lt;/p&gt;
    &lt;p&gt;When I was taken to the Tate Modern as a child I’d point at Mark Rothko pieces and say to my mother “I could do that”, and she would say “yes, but you didn’t.” Many people have talked about what large-scale, automated agent orchestration systems could look like in a few years, and no one else attempted to sincerely build it.&lt;/p&gt;
    &lt;p&gt;I should be transparent and say that I have not used Gas Town in earnest on any serious work. I have only lightly poked at it, because I do not qualify as a serious user when I’m still hovering around stages 4-6 in Yegge’s 8 levels of automation:&lt;/p&gt;
    &lt;p&gt;I currently juggle a handful of consecutive Claude Code and OpenCode agents, but pay close attention to the diffs and regularly check code in an IDE. Which I guess puts me in the agentically conservative camp in this distressingly breakneck moment in history.&lt;/p&gt;
    &lt;p&gt;Gas Town is a full-on stage 8 piece of tooling: using an orchestrator that manages dozens+ of other coding agents for you. Yegge also warned me not to seriously use Gas Town multiple times, in increasingly threatening typography. I trust his guidance on his own slush pile.&lt;/p&gt;
    &lt;p&gt;But I have grokked the basic concepts and spent more time with this manifesto than is warranted. And here is what stood out to me from the parts I could comprehend:&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Design and planning becomes the bottleneck when agents write all the code&lt;/head&gt;
    &lt;p&gt;When you have a fat stack of agents churning through code tasks, development time is no longer the bottleneck. Yegge says “Gas Town churns through implementation plans so quickly that you have to do a LOT of design and planning to keep the engine fed.” Design becomes the limiting factor: imagining what you want to create and then figuring out all the gnarly little details required to make your imagination into reality.&lt;/p&gt;
    &lt;p&gt;I certainly feel this friction in both my own professional work and personal projects. My development velocity is far slower than Yegge since I only wrangle a few agents at a time and keep my eyes and hands on the code. But the build time is rarely what holds me up. It is always the design; how should we architect this? What should this feel like? How should this look? Is that transition subtle enough? How composable should this be? Is this the right metaphor?&lt;/p&gt;
    &lt;p&gt;When it’s not the design, it’s the product strategy and planning; What are the highest priority features to tackle? Which piece of this should we build first? When do we need to make that decision? What’s the next logical, incremental step we need to make progress here?&lt;/p&gt;
    &lt;p&gt;These are the kind of decisions that agents cannot make for you. They require your human context, taste, preferences, and vision.&lt;/p&gt;
    &lt;p&gt;With agents to hand, it’s easy to get ahead of yourself, stumbling forward into stacks of generated functions that should never have been prompted into existence, because they do not correctly render your intentions or achieve your goals.&lt;/p&gt;
    &lt;p&gt;Gas Town seems to be halfway into this pitfall. The biggest flaw in Yegge’s creation is that it is poorly designed. I mean this in the sense that he absolutely did not design the shape of this system ahead of time, thoughtfully considering which metaphors and primitives would make this effective, efficient, easy to use, and comprehensible.&lt;/p&gt;
    &lt;p&gt;He just made stuff up as he went. He says as much himself: “Gas Town is complicated. Not because I wanted it to be, but because I had to keep adding components until it was a self-sustaining machine.” Gas Town is composed of “especially difficult [theories] because it’s a bunch of bullshit I pulled out of my arse over the past 3 weeks, and I named it after badgers and stuff.” It was slapdashed together over “17 days, 75k lines of code, 2000 commits. It finally got off the ground (GUPP started working) just 2 days ago.” Do not ask what GUPP is; I cannot concisely explain without getting deep into it. Which we’ll do in a minute.&lt;/p&gt;
    &lt;p&gt;This Hacker News comment from qcnguy describes the problem well, and points out that Yegge’s previous Beads project, of which Gas Town is an extension, suffers the same issue:&lt;/p&gt;
    &lt;p&gt;“Beads is a good idea with a bad implementation. It’s not a designed product in the sense we are used to, it’s more like a stream of consciousness converted directly into code. It’s a program that isn’t only vibe coded, it was vibe designed too.”&lt;/p&gt;
    &lt;p&gt;“Gas Town is clearly the same thing multiplied by ten thousand. The number of overlapping and ad hoc concepts in this design is overwhelming. Steve is ahead of his time but we aren’t going to end up using this stuff. Instead a few of the core insights will get incorporated into other agents in a simpler but no less effective way.”&lt;/p&gt;
    &lt;p&gt;Or this review from astrra.space on Bluesky:&lt;/p&gt;
    &lt;p&gt;“gas town [is] such a nightmare to use i love it… the mayor is dumb as rocks the witness regularly forgets to look at stuff the deacon makes his own rules the crew have the object permanence of a tank full of goldfish and the polecats seem intent on wreaking as much chaos on the project as they can. this is peak entertainment i swear”&lt;/p&gt;
    &lt;p&gt;Friends and colleagues of mine who have been brave enough to try out Gas Town in more depth report the same thing; this thing fits the shape of Yegge’s brain and no one else’s. I’d categorise that as a moderate design fail, given this is a public product that I assume Yegge wants at least some people to try out. The onboarding is baptism by fire.&lt;/p&gt;
    &lt;p&gt;This feels like one of the most critical, emerging footguns of liberally hands-off agentic development. You can move so fast you never stop to think. It is so easy to prompt, you don’t fully consider what you’re building at each step of the process. It is only once you are hip-deep in poor architectural decisions, inscrutable bugs, and a fuzzy memory of what you set out to do, do you realise you have burned a billion tokens in exchange for a pile of hot trash.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Buried in the chaos are sketches of future agent orchestration patterns&lt;/head&gt;
    &lt;p&gt;Now that I’ve just critiqued the design of Gas Town, I will turn around and say that while the current amalgamation of polecats, convoys, deacons, molecules, protomolecules, mayors, seances, hooks, beads, witnesses, wisps, rigs, refineries, and dogs is a bunch of under cooked spaghetti, Yegge’s patterns roughly sketch out some useful conceptual shapes for future agentic systems.&lt;/p&gt;
    &lt;p&gt;If you step back and squint, this mishmash of concepts reveals a few underlying patterns that future agentic systems will likely follow:&lt;/p&gt;
    &lt;head rend="h3"&gt;Agents have specialised roles with hierarchical supervision&lt;/head&gt;
    &lt;p&gt;Every agent in Gas Town has a permanent, specialised role. When an agent spins up a new session, it knows who it is and what job it needs to do. Some examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Mayor is the human concierge: it’s the main agent you talk to. It talks to all the other agents for you, kicking off work, receiving notifications when things finish, and managing the flow of production.&lt;/item&gt;
      &lt;item&gt;Polecats are temporary grunt workers. They complete single, isolated tasks, then disappear after submitting their work to be merged.&lt;/item&gt;
      &lt;item&gt;The Witness supervises the Polecats and helps them get unstuck. Its job is to solve problems and nudge the proletariat workers along.&lt;/item&gt;
      &lt;item&gt;The Refinery manages the merge queue into the main branch. It evaluates each piece of work waiting to be merged, resolving conflicts in the process. It can creatively “re-imagine” implementations if merge conflicts get too hairy, while trying to keep the intent of the original work.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are many more characters in this town, but these give you a flavour of the system. Giving each agent a single job means you can prompt them more precisely, limit what they’re allowed to touch, and run lots of them at once without them stepping on each other’s toes.&lt;/p&gt;
    &lt;p&gt;There’s also a clear chain of command between these agents. You talk to the Mayor, who coordinates work across the system. The Mayor in Gas Town never writes code. It talks to you, then creates work tasks and assigns them to workers. A set of system supervisors called the Witness, the Deacon, and “Boot the Dog” intermittently nudge the grunt workers and each other to check everyone is doing their work. Oh and there’s also a crew of “dogs” who do maintenance and cleaning.&lt;/p&gt;
    &lt;p&gt;It’s easier if I try and show you. Here’s the basic relationship structure of Gas Town, as best I can make out:&lt;/p&gt;
    &lt;p&gt;Since I’m making my own visuals here, I should justify it by pointing out that while Yegge made lots of his own ornate, zoopmorphic diagrams of Gas Town’s architecture and workflows, they are unhelpful. Primarily because they were made entirely by Gemini’s Nano Banana . And while Nano Banana is state-of-the-art at making diagrams, generative AI systems are still really shit at making illustrative diagrams. They are very hard to decipher, filled with cluttered details, have arrows pointing the wrong direction, and are often missing key information. Case in point:&lt;/p&gt;
    &lt;p&gt;Does this help you understand how the system works? No? No.&lt;/p&gt;
    &lt;p&gt;Gas Town’s hierarchical approach solves both a coordination and attention problem. Without it, you are the one assigning tasks to dozens individual agents, checking who’s stuck, who’s idle, and who’s waiting on work from someone else. With the Mayor as your single interface, that overhead disappears. You can continuously talk to the Mayor without interrupting any agents or getting in the way, or having to think much about which one is doing what. This is less cognitive overhead than constantly switching tabs between Claudes.&lt;/p&gt;
    &lt;p&gt;I think there’s a lot of opportunity to diversify the cast of characters here and make more use of specialist subagents . The agents in Gas Town are all generalist workers in the software development pipeline. But we could add in any kind of specialist we want: a dev ops expert, a product manager, a front-end debugger, an accessibility checker, a documentation writer. These would be called in on-demand to apply their special skills and tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;Agent roles and tasks persist, sessions are ephemeral&lt;/head&gt;
    &lt;p&gt;One of the major limitations of current coding agents is running out of context. Before you even hit the limits of a context window, context rot degrades the output enough that it’s not worth keeping. We constantly have to compact or start fresh sessions.&lt;/p&gt;
    &lt;p&gt;Gas Town’s solution to this is make each agent session disposable by design. It stores the important information – agent identities and tasks – in Git, then liberally kills off sessions and spins up fresh ones when needed. New sessions are told their identity and currently assigned work, and continue on where the last one left off. Gas Town also lets new sessions ask their predecessors what happened through “seancing”: resuming the last session as a separate instance in order to let the new agent ask questions about unfinished work.&lt;/p&gt;
    &lt;p&gt;This saving and recalling is all done through Gas Town’s “Beads” system. Beads is also the name of the memory management system Yegge built before Gas Town; a precursor to this more ambitious civilisation. Beads are tiny, trackable units of work – like issues in an issue tracker – stored as JSON in Git alongside your code. Each bead has an ID, description, status, and assignee. Agent identities are also stored as beads, giving each worker a persistent address that survives session crashes.&lt;/p&gt;
    &lt;p&gt;Yegge didn’t invent this pattern of tracking atomic tasks outside agent memory in something structured like JSON. Anthropic described the same approach in their research on effective harnesses for long-running agents , just published in November 2025. I give it a hot minute before this type of task tracking lands in Claude Code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feeding agents continuous streams of work&lt;/head&gt;
    &lt;p&gt;The whole promise of an orchestration system like Gas Town is it’s a perpetual motion machine. You give high-level orders to the mayor, and then a zoo of agents kicks off to break it down into tasks, assign them, execute them, check for bugs, fix the bugs, review the code, and merge it in.&lt;/p&gt;
    &lt;p&gt;Each worker agent in Gas Town has its own queue of assigned work and a “hook” pointing to the current thing they should be doing. The minute they finish a task, the next one jumps to the front of the queue. The mayor is the one filling up these queues – it’s in charge of breaking down large features into atomic tasks and assigning them to available workers. In theory, the workers are never idle or lacking tasks, so long as you keep feeding the mayor your grand plans.&lt;/p&gt;
    &lt;p&gt;This principle of “workers always do their work” is better in theory than practice. It turns out to be slightly difficult to make happen because of the way current models are trained. They’re designed as helpful assistants who wait politely for human instructions. They’re not used to checking a task queue and independently getting on with things.&lt;/p&gt;
    &lt;p&gt;Gas Town’s patchwork solution to this is aggressive prompting and constant nudging. Supervisor agents spend their time poking workers to see if anyone’s stalled out or run dry on work. When one goes quiet, they send it a ping which jolts the agent into checking its queue and getting back to work. These periodic nudges move through the agent hierarchy like a heartbeat keeping everything moving. This is a decent band-aid for the first version, but more serious efforts at agent orchestration systems will need reliable ways to keep agents on task.&lt;/p&gt;
    &lt;head rend="h3"&gt;Merge queues and agent-managed conflicts&lt;/head&gt;
    &lt;p&gt;When you have a bunch of agents all working in parallel, you’re of course going to run into merge conflicts. Each agent is off on its own branch, and by the time it finishes its task, the main branch might look completely different – other changes have landed, the code has moved on. The later an agent finishes, the worse this gets. Normally you, the human, takes on the burden of sorting out the mess and deciding which changes to keep. But if agents are running on their own, something has to do that job for them.&lt;/p&gt;
    &lt;p&gt;So Gas Town has a dedicated merge agent – the Refinery – that works through the merge queue one change at a time. It looks at each merge request, resolves any conflicts, and gets it into main. When things get really tangled – when so much has changed that the original work doesn’t even make sense anymore – it can creatively “re-imagine” the changes: re-doing the work to fit the new codebase. Or escalate to a human if needed.&lt;/p&gt;
    &lt;p&gt;But there’s another way to sidestep merge conflict nightmares that Gas Town doesn’t have built in: ditch PRs for stacked diffs . The traditional git workflow puts each feature on its own branch for days or weeks, accumulating commits, then getting merged back as one chunky PR.&lt;/p&gt;
    &lt;p&gt;Stacked diffs avoid this conflict-prone approach by breaking work into small, atomic changes that each get reviewed and merged on their own, building on top of each other. Every change gets its own branch, forked off the previous change, forming a “stack” of changes dependent on one another. When a change earlier in the stack gets updated, all the changes below it automatically rebase on top of the new version.&lt;/p&gt;
    &lt;p&gt;This fits how agents naturally work. They’re already producing tiny, focused changes rather than sprawling multi-day branches. When conflicts do pop up, they’re easier to untangle because each diff touches less code. Cursor ’s recent acquisition of Graphite , a tool built specifically for stacked diff workflows, suggests I am not the only one who sees this opportunity. When you’ve got dozens of agents landing changes continuously, you need tools and interfaces specifically designed for these frequent, incremental merges.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. The price is extremely high, but so is the (potential) value&lt;/head&gt;
    &lt;p&gt;Yegge describes Gas Town as “expensive as hell… you won’t like Gas Town if you ever have to think, even for a moment, about where money comes from.” He’s on his second Claude account to get around Anthropic’s spending limits.&lt;/p&gt;
    &lt;p&gt;I can’t find any mention online of the per-account limits, but let’s conservatively assume he’s spending at least $2,000 USD per month, and liberally $5,000. Now covered by the $75,000 he’s earned in transaction fees from the $GAS cryptocoin, which gives him a good year to run this at scale&lt;/p&gt;
    &lt;p&gt;The current cost is almost certainly artificially inflated by system inefficiency. Work gets lost, bugs get fixed numerous times, designs go missing and need redoing. As models improve and orchestration patterns mature, the cost of orchestrators like this should drop while output quality rises.&lt;/p&gt;
    &lt;p&gt;I expect companies would happily pay around the $1-3k/month mark for a sane, understandable, higher quality, and lower waste version of Gas Town. Maybe that sounds absurd to you, given we’ve all become anchored to the artificially low rate of $100-200/month for unlimited usage by the major providers. But once the AI bubble pops, the VC funds dry up, and providers have to charge the true cost of inference at scale, we should expect that “unlimited” tier to look a lot pricier.&lt;/p&gt;
    &lt;p&gt;Even when that comes to pass, a few thousand is pretty reasonable when you compare it to an average US senior developer salary: $120,000 USD. Salary average from Indeed . Many people will pick bones over this because the market range is so broad. FAANG engineers in San Fransisco are paid closer to half a million, while developers in Europe are used to salaries in the $30-50k range. This seems like a sensible middle ground. If Gas Town could genuinely speed up the work of a senior developer by 2-3x or more, it would easily be worth 10-30% of their salary. The cost per unit of valuable work starts to look competitive with human labor.&lt;/p&gt;
    &lt;p&gt;The maths on paying for something like this is already defensible in wealthier places like the US and parts of Western Europe. In spots where developer salaries are lower, we would expect the budget for AI assisted tools adjusts accordingly. They’ll get less crazy scaled automation and more conversative useage with humans filling in the cognitive gaps.&lt;/p&gt;
    &lt;head rend="h2"&gt;4. Yegge never looks at code. When should we stop looking too?&lt;/head&gt;
    &lt;p&gt;Yegge is leaning into the true definition of vibecoding with this project: “It is 100% vibecoded. I’ve never seen the code, and I never care to.” Not looking at code at all is a very bold proposition, today, in January 2026.&lt;/p&gt;
    &lt;p&gt;Given the current state of models and the meagre safeguards we have in place around them, the vast majority of us would consider this blind coding approach irresponsible and daft to do on anything that isn’t a throwaway side project. Which, given the amount of effort and Claude tokens Yegge has sunk into building it, writing documentation, and publicly promoting it, Gas Town is not.&lt;/p&gt;
    &lt;p&gt;“Should developers still look at code?” will become one of the most divisive and heated debates over the coming years. You might be offended by the question, and find it absurd anyone is asking. But it’s a sincere question and the answer will change faster than you think.&lt;/p&gt;
    &lt;p&gt;I’m already seeing people divide along moralistic, personal identity lines as they try to answer it. Some declare themselves purist, AI skeptic, Real Developers who check every diff and hand-adjust specific lines, sneering at anyone reckless enough to let agents run free. While others lean into agentic maximalism, directing fleets from on high and pitying the mass of luddites still faffing about with manual edits like it’s 2019. Both camps mistake a contextual judgement for a personality trait and firm moral position.&lt;/p&gt;
    &lt;p&gt;A more conservative, easier to consider, debate is: how close should the code be in agentic software development tools? How easy should it be to access? How often do we expect developers to edit it by hand?&lt;/p&gt;
    &lt;p&gt;Interfaces like Claude Code , Cursor , and Conductor do not put code front and centre in the experience. The agent is your first and primary interface. You might be able to see diffs rolls by or display code files inline, but you can’t touch them. Trying to edit code yourself is a roundabout journey of opening your IDE and navigating to the correct files and lines.&lt;/p&gt;
    &lt;p&gt;This design choice assumes it is easier to ask an agent to make the change for you, than it is to type it out the syntax yourself. They clearly say “we don’t believe users need to touch code.”&lt;/p&gt;
    &lt;p&gt;Framing this debate as an either/or – either you look at code or don’t, either you edit code by hand or you exclusively direct agents, either you’re the anti-AI-purist or the agentic-maxxer – is unhelpful. Because nothing is a strict binary.&lt;/p&gt;
    &lt;p&gt;The right distance isn’t about what kind of person you are or what you believe about AI capabilities in the current moment. How far away you step from the syntax shifts based on what you’re building, who you’re building with, and what happens when things go wrong. The degree of freedom you hand over to agents depends on:&lt;/p&gt;
    &lt;head rend="h3"&gt;Domain and programming language&lt;/head&gt;
    &lt;p&gt;Front-end versus backend makes a huge difference. Language is a poor medium for designing easing curves and describing aesthetic feelings – I always need to touch the CSS, and it’s often faster to just tweak directly than try to explain what I want. Yegge’s CLI tooling is much easier to validate with pass/fail tests than evaluating whether a notification system “feels calm enough”. Model competence also varies wildly by language; prompting React and Tailwind gives you much better results than Rust or Haskell, where the models still regularly choke on borrow checkers and type systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Access to feedback loops and definitions of succes&lt;/head&gt;
    &lt;p&gt;The more agents can validate their own work, the better the results. If you let agents run tests and see the output, they quickly learn what’s broken and how to fix it. If you let them open browsers, take screenshots, and click around, they can spot their mistakes. Tools like the Ralph Wiggum plugin lean into this – it loops until tests pass or some specific condition is validated. This doesn’t work for less defined, clear cut work though. If you try to make an agent design a visual diagram for you, it’s going to struggle. It doesn’t know your aesthetic preferences and can’t really “see” what it’s making.&lt;/p&gt;
    &lt;head rend="h3"&gt;Risk tolerance for shit going wrong&lt;/head&gt;
    &lt;p&gt;Stakes matter. If an agent breaks some images on your personal blog, you’ll recover. But if you’re running a healthcare system where a bug could miscalculate drug dosages, or a banking app moving actual money around, you can’t just wave an agent at it and hope. Consequences scale up fast. Corporate software has people whose entire job is compliance and regulatory sign-off – they need to see the code, understand it, verify it meets requirements. Those people aren’t going to let you widly run Gas Town over projects without serious guardrails in place.&lt;/p&gt;
    &lt;p&gt;“Gas Town sounds fun if you are accountable to nobody: not for code quality, design coherence or inferencing costs. The rest of us are accountable for at least the first two and even in corporate scenarios where there is a blank check for tokens, that can’t last. So the bottleneck is going to be how fast humans can review code and agree to take responsibility for it.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Greenfield vs. brownfield projects&lt;/head&gt;
    &lt;p&gt;Starting fresh (greenfield), means you can let agents make architectural decisions and establish patterns – if you don’t like them, you can easily throw it out and restart. The cost of mistakes is low. But in an existing codebase (brownfield) with years of accumulated conventions, implicit patterns, and code that exists for reasons nobody remembers anymore, agents need much tighter supervision. They’ll happily introduce a new pattern that contradicts the three other ways this codebase already solves the same problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Number of collaborators&lt;/head&gt;
    &lt;p&gt;If you’re solo of course you can YOLO. If you’re working with more than a handful of people, you’ll have to agree on coding standards and agent rules. This creates its own overhead: updating the AGENTS.md file, picking MCPs, writing commands and skills and rules and whatever else we invent to constrain these things. The pace of change when you’re all using agents can be overwhelming and you need to figure out a sensible reviewing pipeline to manage it. Team coordination can fall apart when everyone’s agents start moving too fast. You might show up in the morning and discover someone’s agent renamed the database schema while another agent refactored the whole API layer, and neither of which jive with your giant, unmerged feature.&lt;/p&gt;
    &lt;head rend="h3"&gt;Your experience level&lt;/head&gt;
    &lt;p&gt;More senior developers can prompt better, debug better, and setup more stringent preferences earned through decades of seeing what can go wrong in scaled, production environments. They can recognize patterns: “oh, that’s a memory leak” or “that’s going to deadlock under load.” Newer developers don’t have that catalog of failures yet and are much more likely to prompt their own personal house of cards. The tests might pass and everything looks fine until you hit production traffic or someone enters a weird character. It is hard to defend against unknown unknowns.&lt;/p&gt;
    &lt;p&gt;Given all these “it depends” considerations, I’m currently in the code-must-be-close camp for most serious work done by professional developers. But I expect I’ll shift to the code-at-a-distance camp over the next year or two as the harnesses and tools we wrap around these agents mature. If we can ship them with essential safe guards and quality gates, the risks drop. Sure, the models will also improve, but the infrastructure matters far more: validation loops, tests, and specialised subagents who focus on security, debugging, and code quality are what will make code-at-a-distance feasible.&lt;/p&gt;
    &lt;p&gt;We have many, continuous versions of the code distance debate interally at Github Next . One of the projects within the team driving this is Agentic Workflows – autonomous agents run through GitHub Actions in response to events: new PRs, new issues, or specific times of day. Every commit can trigger a security review agent, an accessibility audit, and a documentation updater, all running in parallel alongside traditional CI/CD tests before anything lands in main. The team building it rarely touches code and do most of their work by directing agents from their phones. It’s these kinds of guardrails that makes a hands-off Sim-City-esque orchestrator system feel less terrifying to me.&lt;/p&gt;
    &lt;p&gt;I don’t believe Gas Town itself is “it”. It’s not going to evolve into the thing we all use, day in and day out, in 2027. As I said, it’s a provocative piece of speculative design, not a system many people will use in earnest. In the same way any poorly designed object or system gets abandoned, this manic creation is too poorly thought through to persist. But the problems it’s wrestling with and the patterns it has sketched out will unquestionably show up in the next generation of development tools.&lt;/p&gt;
    &lt;p&gt;As the pace of software development speeds up, we’ll feel the pressure intensify in other parts of the pipeline: thoughtful design, critical thinking, user research, planning and coordination within teams, deciding what to build, and whether it’s been built well. The most valuable tools in this new world won’t be the ones that generate the most code fastest. They’ll be the ones that help us think more clearly, plan more carefully, and keep the quality bar high while everything accelerates around us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maggieappleton.com/gastown"/><published>2026-01-23T16:19:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46735489</id><title>Route leak incident on January 22, 2026</title><updated>2026-01-24T10:42:31.934042+00:00</updated><content>&lt;doc fingerprint="f5aab1a1e428d1f3"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;On January 22, 2026, an automated routing policy configuration error caused us to leak some Border Gateway Protocol (BGP) prefixes unintentionally from a router at our data center in Miami, Florida. While the route leak caused some impact to Cloudflare customers, multiple external parties were also affected because their traffic was accidentally funnelled through our Miami data center location.&lt;/p&gt;
      &lt;p&gt;The route leak lasted 25 minutes, causing congestion on some of our backbone infrastructure in Miami, elevated loss for some Cloudflare customer traffic, and higher latency for traffic across these links. Additionally, some traffic was discarded by firewall filters on our routers that are designed to only accept traffic for Cloudflare services and our customers.&lt;/p&gt;
      &lt;p&gt;While weâve written about route leaks before, we rarely find ourselves causing them. This route leak was the result of an accidental misconfiguration on a router in Cloudflareâs network, and only affected IPv6 traffic. We sincerely apologize to the users, customers, and networks we impacted yesterday as a result of this BGP route leak.&lt;/p&gt;
      &lt;p&gt;We have written multiple times about BGP route leaks, and we even record route leak events on Cloudflare Radar for anyone to view and learn from. To get a fuller understanding of what route leaks are, you can refer to this detailed background section, or refer to the formal definition within RFC7908.Â &lt;/p&gt;
      &lt;p&gt;Essentially, a route leak occurs when a network tells the broader Internet to send it traffic that it's not supposed to forward. Technically, a route leak occurs when a network, or Autonomous System (AS), appears unexpectedly in an AS path. An AS path is what BGP uses to determine the path across the Internet to a final destination. An example of an anomalous AS path indicative of a route leak would be finding a network sending routes received from a peer to a provider.&lt;/p&gt;
      &lt;p&gt;During this type of route leak, the rules of valley-free routing are violated, as BGP updates are sent from AS64501 to their peer (AS64502), and then unexpectedly up to a provider (AS64503). Oftentimes the leaker, in this case AS64502, is not prepared to handle the amount of traffic they are going to receive and may not even have firewall filters configured to accept all of the traffic coming in their direction. In simple terms, once a route update is sent to a peer or provider, it should only be sent further to customers and not to another peer or provider AS.&lt;/p&gt;
      &lt;p&gt;During the incident on January 22, we caused a similar kind of route leak, in which we took routes from some of our peers and redistributed them in Miami to some of our peers and providers. According to the route leak definitions in RFC7908, we caused a mixture of Type 3 and Type 4 route leaks on the Internet.Â &lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Time (UTC)&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Event&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 19:52 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;A change that ultimately triggers the routing policy bug is merged in our network automation code repository&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 20:25 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Automation is run on single Miami edge-router resulting in unexpected advertisements to BGP transit providers and peers&lt;/p&gt;
            &lt;p&gt;IMPACT START&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 20:40 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Network team begins investigating unintended route advertisements from Miami&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 20:44 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Incident is raised to coordinate response&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 20:50 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The bad configuration change is manually reverted by a network operator, and automation is paused for the router, so it cannot run again&lt;/p&gt;
            &lt;p&gt;IMPACT STOP&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 21:47 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The change that triggered the leak is reverted from our code repository&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 22:07 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Automation is confirmed by operators to be healthy to run again on the Miami router, without the routing policy bug&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;2026-01-22 22:40 UTC&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Automation is unpaused on the single router in Miami&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;What happened: the configuration error&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;On January 22, 2026, at 20:25 UTC, we pushed a change via our policy automation platform to remove the BGP announcements from Miami for one of our data centers in BogotÃ¡, Colombia. This was purposeful, as we previously forwarded some IPv6 traffic through Miami toward the BogotÃ¡ data center, but recent infrastructure upgrades removed the need for us to do so.&lt;/p&gt;
      &lt;p&gt;This change generated the following diff (a program that compares configuration files in order to determine how or whether they differ):&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;[edit policy-options policy-statement 6-COGENT-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-COMCAST-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-GTT-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-LEVEL3-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-PRIVATE-PEER-ANYCAST-OUT term ADV-SITELOCAL from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-PUBLIC-PEER-ANYCAST-OUT term ADV-SITELOCAL from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-PUBLIC-PEER-OUT term ADV-SITELOCAL from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-TELEFONICA-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;
[edit policy-options policy-statement 6-TELIA-ACCEPT-EXPORT term ADV-SITELOCAL-GRE-RECEIVER from]
-      prefix-list 6-BOG04-SITE-LOCAL;&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;While this policy change looks innocent at a glance, only removing the prefix lists containing BOG04 unicast prefixes resulted in a policy that was too permissive:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;policy-options policy-statement 6-TELIA-ACCEPT-EXPORT {
    term ADV-SITELOCAL-GRE-RECEIVER {
        from route-type internal;
        then {
            community add STATIC-ROUTE;
            community add SITE-LOCAL-ROUTE;
            community add MIA01;
            community add NORTH-AMERICA;
            accept;
        }
    }
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The policy would now mark every prefix of type âinternalâ as acceptable, and proceed to add some informative communities to all matching prefixes. But more importantly, the policy also accepted the route through the policy filter, which resulted in the prefix â which was intended to be âinternalâ âÂ being advertised externally. This is an issue because the âroute-type internalâ match in JunOS or JunOS EVO (the operating systems used by HPE Juniper Networks devices) will match any non-external route type, such as Internal BGP (IBGP) routes, which is what happened here.&lt;/p&gt;
      &lt;p&gt;As a result, all IPv6 prefixes that Cloudflare redistributes internally across the backbone were accepted by this policy, and advertised to all our BGP neighbors in Miami. This is unfortunately very similar to the outage we experienced in 2020, on which you can read more on our blog.&lt;/p&gt;
      &lt;p&gt;When the policy misconfiguration was applied at 20:25 UTC, a series of unintended BGP updates were sent from AS13335 to peers and providers in Miami. These BGP updates are viewable historically by looking at MRT files with the monocle tool or using RIPE BGPlay.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;â  ~ monocle search --start-ts 2026-01-22T20:24:00Z --end-ts 2026-01-22T20:30:00Z --as-path ".*13335[ \d$]32934$*"
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f077::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f091::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f16f::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f17c::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f26f::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f27c::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113609.854028|2801:14:9000::6:4112:1|64112|2a03:2880:f33f::/48|64112 22850 174 3356 13335 32934|IGP|2801:14:9000::6:4112:1|0|0|22850:65151|false|||pit.scl
A|1769113583.095278|2001:504:d::4:9544:1|49544|2a03:2880:f17c::/48|49544 1299 3356 13335 32934|IGP|2001:504:d::4:9544:1|0|0|1299:25000 1299:25800 49544:16000 49544:16106|false|||route-views.isc
A|1769113583.095278|2001:504:d::4:9544:1|49544|2a03:2880:f27c::/48|49544 1299 3356 13335 32934|IGP|2001:504:d::4:9544:1|0|0|1299:25000 1299:25800 49544:16000 49544:16106|false|||route-views.isc
A|1769113583.095278|2001:504:d::4:9544:1|49544|2a03:2880:f091::/48|49544 1299 3356 13335 32934|IGP|2001:504:d::4:9544:1|0|0|1299:25000 1299:25800 49544:16000 49544:16106|false|||route-views.isc
A|1769113584.324483|2001:504:d::19:9524:1|199524|2a03:2880:f091::/48|199524 1299 3356 13335 32934|IGP|2001:2035:0:2bfd::1|0|0||false|||route-views.isc
A|1769113584.324483|2001:504:d::19:9524:1|199524|2a03:2880:f17c::/48|199524 1299 3356 13335 32934|IGP|2001:2035:0:2bfd::1|0|0||false|||route-views.isc
A|1769113584.324483|2001:504:d::19:9524:1|199524|2a03:2880:f27c::/48|199524 1299 3356 13335 32934|IGP|2001:2035:0:2bfd::1|0|0||false|||route-views.isc
{trimmed}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;In the monocle output seen above, we have the timestamp of our BGP update, followed by the next-hop in the announcement, the ASN of the network feeding a given route-collector, the prefix involved, and the AS path and BGP communities if any are found. At the end of the output per-line, we also find the route-collector instance.&lt;/p&gt;
      &lt;p&gt;Looking at the first update for prefix 2a03:2880:f077::/48, the AS path is 64112 22850 174 3356 13335 32934. This means we (AS13335) took the prefix received from Meta (AS32934), our peer, and then advertised it toward Lumen (AS3356), one of our upstream transit providers. We know this is a route leak as routes received from peers are only meant to be readvertised to downstream (customer) networks, not laterally to other peers or up to providers.&lt;/p&gt;
      &lt;p&gt;As a result of the leak and the forwarding of unintended traffic into our Miami router from providers and peers, we experienced congestion on our backbone between Miami and Atlanta, as you can see in the graph below.Â &lt;/p&gt;
      &lt;p&gt;This would have resulted in elevated loss for some Cloudflare customer traffic, and higher latency than usual for traffic traversing these links. In addition to this congestion, the networks whose prefixes we leaked would have had their traffic discarded by firewall filters on our routers that are designed to only accept traffic for Cloudflare services and our customers. At peak, we discarded around 12Gbps of traffic ingressing our router in Miami for these non-downstream prefixes.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Follow-ups and preventing route leaksÂ &lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We are big supporters and active contributors to efforts within the IETF and infrastructure community that strengthen routing security. We know firsthand how easy it is to cause a route leak accidentally, as evidenced by this incident.Â &lt;/p&gt;
      &lt;p&gt;Preventing route leaks will require a multi-faceted approach, but we have identified multiple areas in which we can improve, both short- and long-term.&lt;/p&gt;
      &lt;p&gt;In terms of our routing policy configurations and automation, we are:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Patching the failure in our routing policy automation that caused the route leak, and will mitigate this potential failure and others like it immediatelyÂ &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Implementing additional BGP community-based safeguards in our routing policies that explicitly reject routes that were received from providers and peers on external export policiesÂ &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Adding automatic routing policy evaluation into our CI/CD pipelines that looks specifically for empty or erroneous policy termsÂ &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Improve early detection of issues with network configurations and the negative effects of an automated change&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;To help prevent route leaks in general, we are:Â &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Validating routing equipment vendors' implementation of RFC9234 (BGP roles and the Only-to-Customer Attribute) in preparation for our rollout of the feature, which is the only way independent of routing policy to prevent route leaks caused at the local Autonomous System (AS)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Encouraging the long term adoption of RPKI Autonomous System Provider Authorization (ASPA), where networks could automatically reject routes that contain anomalous AS paths&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Most importantly, we would again like to apologize for the impact we caused users and customers of Cloudflare, as well as any impact felt by external networks.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/route-leak-incident-january-22-2026/"/><published>2026-01-23T17:54:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46735511</id><title>Proof of Corn</title><updated>2026-01-24T10:42:31.736655+00:00</updated><content>&lt;doc fingerprint="c284667a0d9646c2"&gt;
  &lt;main&gt;
    &lt;p&gt;A CASE STUDY&lt;/p&gt;
    &lt;p&gt;On January 21, 2026, @fredwilson challenged @seth: AI can write code, but it can't affect the physical world.&lt;/p&gt;
    &lt;p&gt;This is our response. Real corn, grown from seed to harvest, with every decision made by Claude Code.&lt;/p&gt;
    &lt;p&gt;AI doesn't need to drive a tractor. It needs to orchestrate the systems and people who do.&lt;/p&gt;
    &lt;p&gt;A farm manager doesn't personally plant every seed. They aggregate data, make decisions, coordinate contractors. Claude Code becomes that farm manager— 24/7, data-driven, fully documented.&lt;/p&gt;
    &lt;quote&gt;┌─────────────────────────────────────────────────┐ │ CLAUDE CODE (Brain) │ │ • Aggregates sensor data + weather forecasts │ │ • Makes planting, irrigation, harvest decisions│ │ • Coordinates human operators │ └─────────────────────────────────────────────────┘ │ ┌────────────────┼────────────────┐ ▼ ▼ ▼ DATA INPUTS ORCHESTRATION OUTPUTS • IoT sensors • Custom farmer • Decision log • Weather API • Seed supplier • Commands • Satellite • Equipment • Actual corn&lt;/quote&gt;
    &lt;p&gt;GitHub Repository — All code, documentation, decision logs&lt;/p&gt;
    &lt;p&gt;Decision Log — Every AI decision, timestamped&lt;/p&gt;
    &lt;p&gt;Budget — Every dollar, tracked&lt;/p&gt;
    &lt;p&gt;The Process — How this was built&lt;/p&gt;
    &lt;p&gt;Fred reads every message&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://proofofcorn.com/"/><published>2026-01-23T17:56:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46735545</id><title>Microsoft gave FBI set of BitLocker encryption keys to unlock suspects' laptops</title><updated>2026-01-24T10:42:31.639889+00:00</updated><content>&lt;doc fingerprint="3e12f8d9722ce9ee"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft provided the FBI with the recovery keys to unlock encrypted data on the hard drives of three laptops as part of a federal investigation, Forbes reported on Friday.&lt;/p&gt;
    &lt;p&gt;Many modern Windows computers rely on full-disk encryption, called BitLocker, which is enabled by default. This type of technology should prevent anyone except the device owner from accessing the data if the computer is locked and powered off.&lt;/p&gt;
    &lt;p&gt;But, by default, BitLocker recovery keys are uploaded to Microsoft’s cloud, allowing the tech giant — and by extension law enforcement — to access them and use them to decrypt drives encrypted with BitLocker, as with the case reported by Forbes.&lt;/p&gt;
    &lt;p&gt;The case involved several people suspected of fraud related to the Pandemic Unemployment Assistance program in Guam, a U.S. island in the Pacific. Local news outlet Pacific Daily News covered the case last year, reporting that a warrant had been served to Microsoft in relation to the suspects’ hard drives. Kandit News, another local Guam news outlet, also reported in October that the FBI requested the warrant six months after seizing the three laptops encrypted with BitLocker.&lt;/p&gt;
    &lt;p&gt;A spokesperson for Microsoft did not immediately respond to a request for comment by TechCrunch. Microsoft told Forbes that the company sometimes provides BitLocker recovery keys to authorities, having received an average of 20 such requests per year.&lt;/p&gt;
    &lt;p&gt;Apart from the privacy risks of handing recovery keys to a company, Johns Hopkins professor and cryptography expert Matthew Green raised the potential scenario where malicious hackers compromise Microsoft’s cloud infrastructure — something that has happened several times in recent years — and get access to these recovery keys. The hackers would still need physical access to the hard drives to use the stolen recovery keys.&lt;/p&gt;
    &lt;p&gt;“It’s 2026 and these concerns have been known for years,” Green wrote in a post on Bluesky. “Microsoft’s inability to secure critical customer keys is starting to make it an outlier from the rest of the industry.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://techcrunch.com/2026/01/23/microsoft-gave-fbi-a-set-of-bitlocker-encryption-keys-to-unlock-suspects-laptops-reports/"/><published>2026-01-23T17:58:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46735644</id><title>New YC homepage</title><updated>2026-01-24T10:42:31.453813+00:00</updated><link href="https://www.ycombinator.com/"/><published>2026-01-23T18:08:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46737447</id><title>Banned C++ features in Chromium</title><updated>2026-01-24T10:42:30.863768+00:00</updated><content>&lt;doc fingerprint="ced54b66c32c0c2a"&gt;
  &lt;main&gt;&lt;p&gt;This document is part of the more general Chromium C++ style guide. It summarizes the supported state of new and updated language and library features in recent C++ standards and the Abseil library. This guide applies to both Chromium and its subprojects, though subprojects can choose to be more restrictive if necessary for toolchain support.&lt;/p&gt;&lt;p&gt;The C++ language has in recent years received an updated standard every three years (C++11, C++14, etc.). For various reasons, Chromium does not immediately allow new features on the publication of such a standard. Instead, once Chromium supports the toolchain to a certain extent (e.g., build support is ready), a standard is declared “initially supported”, with new language/library features banned pending discussion but not yet allowed.&lt;/p&gt;&lt;p&gt;You can propose changing the status of a feature by sending an email to cxx@chromium.org. Include a short blurb on what the feature is and why you think it should or should not be allowed, along with links to any relevant previous discussion. If the list arrives at some consensus, send a codereview to change this file accordingly, linking to your discussion thread.&lt;/p&gt;&lt;p&gt;If an item remains on the TBD list two years after initial support is added, style arbiters should explicitly move it to an appropriate allowlist or blocklist, allowing it if there are no obvious reasons to ban.&lt;/p&gt;&lt;p&gt;The current status of existing standards and Abseil features is:&lt;/p&gt;&lt;p&gt;Third-party libraries may generally use banned features internally, although features with poor compiler support or poor security properties may make the library unsuitable to use with Chromium.&lt;/p&gt;&lt;p&gt;Chromium code that calls functions exported from a third-party library may use banned library types that are required by the interface, as long as:&lt;/p&gt;&lt;p&gt;The following C++11 language features are not allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;inline namespace foo { ... }&lt;/quote&gt;&lt;p&gt;Description: Allows better versioning of namespaces.&lt;/p&gt;&lt;p&gt;Documentation: Inline namespaces&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;long long var = value;&lt;/quote&gt;&lt;p&gt;Description: An integer of at least 64 bits.&lt;/p&gt;&lt;p&gt;Documentation: Fundamental types&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Use a &lt;code&gt;&amp;lt;stdint.h&amp;gt;&lt;/code&gt; type if you need a 64-bit number.&lt;/p&gt;&lt;quote&gt;DistanceType var = 12_km;&lt;/quote&gt;&lt;p&gt;Description: Allows user-defined literal expressions.&lt;/p&gt;&lt;p&gt;Documentation: User-defined literals&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;The following C++11 library features are not allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;#include &amp;lt;cctype&amp;gt; #include &amp;lt;cwctype&amp;gt; #include &amp;lt;ctype.h&amp;gt; #include &amp;lt;wctype.h&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Provides utilities for ASCII characters.&lt;/p&gt;&lt;p&gt;Documentation: Standard library header &lt;code&gt;&amp;lt;cctype&amp;gt;&lt;/code&gt;, Standard library header &lt;code&gt;&amp;lt;cwctype&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;unsigned char&lt;/code&gt;/&lt;code&gt;wchar_t&lt;/code&gt;. Use similarly-named replacements in third_party/abseil-cpp/absl/strings/ascii.h instead.&lt;quote&gt;#include &amp;lt;cfenv&amp;gt; #include &amp;lt;fenv.h&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Provides floating point status flags and control modes for C-compatible code.&lt;/p&gt;&lt;p&gt;Documentation: Standard library header &lt;code&gt;&amp;lt;cfenv&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#include &amp;lt;chrono&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: A standard date and time library.&lt;/p&gt;&lt;p&gt;Documentation: Date and time utilities&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/time&lt;/code&gt;.&lt;quote&gt;#include &amp;lt;exception&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Exception throwing and handling.&lt;/p&gt;&lt;p&gt;Documentation: Standard library header &lt;code&gt;&amp;lt;exception&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Exceptions are banned by the Google Style Guide and disabled in Chromium compiles. However, the &lt;code&gt;noexcept&lt;/code&gt; specifier is explicitly allowed.&lt;/p&gt;&lt;quote&gt;std::mt19937 generator;&lt;/quote&gt;&lt;p&gt;Description: Methods of generating random numbers.&lt;/p&gt;&lt;p&gt;Documentation: Pseudo-random number generation&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Do not use any random number engines or generators from &lt;code&gt;&amp;lt;random&amp;gt;&lt;/code&gt;. Instead, use &lt;code&gt;base::RandomBitGenerator&lt;/code&gt;. (You may use the distributions from &lt;code&gt;&amp;lt;random&amp;gt;&lt;/code&gt;.)&lt;/p&gt;&lt;quote&gt;#include &amp;lt;ratio&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Provides compile-time rational numbers.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::ratio&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#include &amp;lt;regex&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: A standard regular expressions library.&lt;/p&gt;&lt;p&gt;Documentation: Regular expressions library&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;third_party/re2&lt;/code&gt;.&lt;quote&gt;std::aligned_storage&amp;lt;sizeof(T), alignof&amp;lt;T&amp;gt;&amp;gt;::type buf;&lt;/quote&gt;&lt;p&gt;Description: Creates aligned, uninitialized storage to later hold one or more objects.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::aligned_storage&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;alignas(T) char buf[sizeof(T)];&lt;/code&gt;. Aligned unions can be handled similarly, using the max alignment and size of the union members, either passed via a pack or computed inline.&lt;quote&gt;auto x = std::bind(function, args, ...);&lt;/quote&gt;&lt;p&gt;Description: Declares a function object bound to certain arguments.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::bind&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Use &lt;code&gt;base::Bind&lt;/code&gt; instead. Compared to &lt;code&gt;std::bind&lt;/code&gt;, &lt;code&gt;base::Bind&lt;/code&gt; helps prevent lifetime issues by preventing binding of capturing lambdas and by forcing callers to declare raw pointers as &lt;code&gt;Unretained&lt;/code&gt;.&lt;/p&gt;&lt;quote&gt;std::function x = [] { return 10; }; std::function y = std::bind(foo, args);&lt;/quote&gt;&lt;p&gt;Description: Wraps a standard polymorphic function.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::function&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Use &lt;code&gt;base::{Once,Repeating}Callback&lt;/code&gt; or &lt;code&gt;base::FunctionRef&lt;/code&gt; instead. Compared to &lt;code&gt;std::function&lt;/code&gt;, &lt;code&gt;base::{Once,Repeating}Callback&lt;/code&gt; directly supports Chromium's refcounting classes and weak pointers and deals with additional thread safety concerns.&lt;/p&gt;&lt;quote&gt;std::shared_ptr&amp;lt;int&amp;gt; x = std::make_shared&amp;lt;int&amp;gt;(10);&lt;/quote&gt;&lt;p&gt;Description: Allows shared ownership of a pointer through reference counts.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::shared_ptr&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Unlike &lt;code&gt;base::RefCounted&lt;/code&gt;, uses extrinsic rather than intrinsic reference counting. Could plausibly be used in Chromium, but would require significant migration.&lt;/p&gt;&lt;quote&gt;int x = std::stoi("10");&lt;/quote&gt;&lt;p&gt;Description: Converts strings to/from numbers.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::stoi&lt;/code&gt;, &lt;code&gt;std::stol&lt;/code&gt;, &lt;code&gt;std::stoll&lt;/code&gt;, &lt;code&gt;std::stoul&lt;/code&gt;, &lt;code&gt;std::stoull&lt;/code&gt;, &lt;code&gt;std::stof&lt;/code&gt;, &lt;code&gt;std::stod&lt;/code&gt;, &lt;code&gt;std::stold&lt;/code&gt;, &lt;code&gt;std::to_string&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/strings/string_number_conversions.h&lt;/code&gt; instead.&lt;quote&gt;std::weak_ptr&amp;lt;int&amp;gt; x = my_shared_x;&lt;/quote&gt;&lt;p&gt;Description: Allows a weak reference to a &lt;code&gt;std::shared_ptr&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::weak_ptr&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::shared_ptr&lt;/code&gt; is banned.  Use &lt;code&gt;base::WeakPtr&lt;/code&gt; instead.&lt;quote&gt;#include &amp;lt;barrier&amp;gt; // C++20 #include &amp;lt;condition_variable&amp;gt; #include &amp;lt;future&amp;gt; #include &amp;lt;latch&amp;gt; // C++20 #include &amp;lt;mutex&amp;gt; #include &amp;lt;semaphore&amp;gt; // C++20 #include &amp;lt;stop_token&amp;gt; // C++20 #include &amp;lt;thread&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Provides a standard multithreading library using &lt;code&gt;std::thread&lt;/code&gt; and associates&lt;/p&gt;&lt;p&gt;Documentation: Thread support library&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/synchronization&lt;/code&gt;. &lt;code&gt;base::Thread&lt;/code&gt; is tightly coupled to &lt;code&gt;base::MessageLoop&lt;/code&gt; which would make it hard to replace. We should investigate using standard mutexes, or &lt;code&gt;std::unique_lock&lt;/code&gt;, etc. to replace our locking/synchronization classes.&lt;p&gt;The following C++17 language features are not allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;char x = u8'x'; // C++17 char8_t x = u8'x'; // C++20&lt;/quote&gt;&lt;p&gt;Description: A character literal that begins with &lt;code&gt;u8&lt;/code&gt; is a character literal of type &lt;code&gt;char&lt;/code&gt; (C++17) or &lt;code&gt;char8_t&lt;/code&gt; (C++20). The value of a UTF-8 character literal is equal to its ISO 10646 code point value.&lt;/p&gt;&lt;p&gt;Documentation: Character literal&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;char8_t&lt;/code&gt; is banned. Use an unprefixed character or string literal; it should be encoded in the binary as UTF-8 on all supported platforms.&lt;p&gt;The following C++17 library features are not allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;std::assoc_laguerre() std::assoc_legendre() std::beta() std::comp_ellint_1() std::comp_ellint_2() std::comp_ellint_3() std::cyl_bessel_i() std::cyl_bessel_j() std::cyl_bessel_k() std::cyl_neumann() std::ellint_1() std::ellint_2() std::ellint_3() std::expint() std::hermite() std::legendre() std::laguerre() std::riemann_zeta() std::sph_bessel() std::sph_legendre() std::sph_neumann()&lt;/quote&gt;&lt;p&gt;Description: A variety of mathematical functions.&lt;/p&gt;&lt;p&gt;Documentation: Mathematical special functions&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;auto it = std::find(std::execution::par, std::begin(vec), std::end(vec), 2);&lt;/quote&gt;&lt;p&gt;Description: Many of the STL algorithms, such as the &lt;code&gt;copy&lt;/code&gt;, &lt;code&gt;find&lt;/code&gt; and &lt;code&gt;sort&lt;/code&gt; methods, now support the parallel execution policies: &lt;code&gt;seq&lt;/code&gt;, &lt;code&gt;par&lt;/code&gt;, and &lt;code&gt;par_unseq&lt;/code&gt; which translate to “sequentially”, “parallel” and “parallel unsequenced”.&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;int* p2 = static_cast&amp;lt;int*&amp;gt;(std::aligned_alloc(1024, 1024));&lt;/quote&gt;&lt;p&gt;Description: Allocates uninitialized storage with the specified alignment.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::aligned_alloc&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::AlignedAlloc&lt;/code&gt;.&lt;quote&gt;std::any x = 5;&lt;/quote&gt;&lt;p&gt;Description: A type-safe container for single values of any type.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::any&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Banned since workaround for lack of RTTI isn't compatible with the component build. See also &lt;code&gt;absl::any&lt;/code&gt;.&lt;/p&gt;&lt;quote&gt;std::byte b = 0xFF; int i = std::to_integer&amp;lt;int&amp;gt;(b); // 0xFF&lt;/quote&gt;&lt;p&gt;Description: The contents of a single memory unit. &lt;code&gt;std::byte&lt;/code&gt; has the same size and aliasing rules as &lt;code&gt;unsigned char&lt;/code&gt;, but does not semantically represent a character or arithmetic value, and does not expose operators other than bitwise ops.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::byte&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Banned due to low marginal utility in practice, high conversion costs, and programmer confusion about “byte” vs. “octet”. Use &lt;code&gt;uint8_t&lt;/code&gt; for the common case of “8-bit unsigned value”, and &lt;code&gt;char&lt;/code&gt; for the atypical case of code that works with memory without regard to its contents' values or semantics (e.g allocator implementations).&lt;/p&gt;&lt;quote&gt;#include &amp;lt;filesystem&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: A standard way to manipulate files, directories, and paths in a filesystem.&lt;/p&gt;&lt;p&gt;Documentation: Filesystem library&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::from_chars(str.data(), str.data() + str.size(), result); std::to_chars(str.data(), str.data() + str.size(), 42);&lt;/quote&gt;&lt;p&gt;Description: Locale-independent, non-allocating, non-throwing functions to convert values from/to character strings, designed for use in high-throughput contexts.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::from_chars&lt;/code&gt; &lt;code&gt;std::to_chars&lt;/code&gt;,&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/strings/string_number_conversions.h&lt;/code&gt;, which are easier to use correctly.&lt;quote&gt;#include &amp;lt;memory_resource&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Manages memory allocations using runtime polymorphism.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::pmr::memory_resource&lt;/code&gt;, &lt;code&gt;std::pmr::polymorphic_allocator&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::timespec ts; std::timespec_get(&amp;amp;ts, TIME_UTC);&lt;/quote&gt;&lt;p&gt;Description: Gets the current calendar time in the given time base.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::timespec_get&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::TimeDelta::ToTimeSpec()&lt;/code&gt;; this could be supported on other platforms if desirable.&lt;quote&gt;int count = std::uncaught_exceptions();&lt;/quote&gt;&lt;p&gt;Description: Determines whether there are live exception objects.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::uncaught_exceptions&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::map&amp;lt;std::weak_ptr&amp;lt;T&amp;gt;, U, std::owner_less&amp;lt;&amp;gt;&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Function object providing mixed-type owner-based ordering of shared and weak pointers, regardless of the type of the pointee.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::owner_less&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::shared_ptr&lt;/code&gt; and &lt;code&gt;std::weak_ptr&lt;/code&gt; are banned.&lt;quote&gt;auto weak_ptr = weak_from_this();&lt;/quote&gt;&lt;p&gt;Description: Returns a &lt;code&gt;std::weak_ptr&amp;lt;T&amp;gt;&lt;/code&gt; that tracks ownership of &lt;code&gt;*this&lt;/code&gt; by all existing &lt;code&gt;std::shared_ptr&lt;/code&gt;s that refer to &lt;code&gt;*this&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::enable_shared_from_this&amp;lt;T&amp;gt;::weak_from_this&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::shared_ptr&lt;/code&gt; and &lt;code&gt;std::weak_ptr&lt;/code&gt; are banned.&lt;p&gt;The following C++20 language features are allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;// template &amp;lt;typename T&amp;gt; // void f1(T x); void f1(auto x); // template &amp;lt;C T&amp;gt; // `C` is a concept // void f2(T x); void f2(C auto x); // template &amp;lt;typename T, C U&amp;gt; // `C` is a concept // void f3(T x, U y); template &amp;lt;typename T&amp;gt; void f3(T x, C auto y); // template&amp;lt;typename... Ts&amp;gt; // void f4(Ts... xs); void f4(auto... xs);&lt;/quote&gt;&lt;p&gt;Description: Function params of type &lt;code&gt;auto&lt;/code&gt; become syntactic sugar for declaring a template type for each such parameter.&lt;/p&gt;&lt;p&gt;Documentation: Abbreviated function template&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;consteval int sqr(int n) { return n * n; } constexpr int kHundred = sqr(10); // OK constexpr int quad(int n) { return sqr(sqr(n)); } // ERROR, might be runtime&lt;/quote&gt;&lt;p&gt;Description: Specified that a function may only be used in a compile-time context.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;consteval&lt;/code&gt; specifier&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;// `Hashable` is a concept satisfied by any type `T` for which the expression // `std::hash&amp;lt;T&amp;gt;{}(a)` compiles and produces a value convertible to `size_t`. template&amp;lt;typename T&amp;gt; concept Hashable = requires(T a) { { std::hash&amp;lt;T&amp;gt;{}(a) } -&amp;gt; std::convertible_to&amp;lt;size_t&amp;gt;; }; template &amp;lt;Hashable T&amp;gt; // Only instantiable for `T`s that satisfy `Hashable`. void f(T) { ... }&lt;/quote&gt;&lt;p&gt;Description: Allows bundling sets of requirements together as named concepts, then enforcing them on template arguments.&lt;/p&gt;&lt;p&gt;Documentation: Constraints and concepts&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;class S : public T { // Non-member equality operator with access to private members. // Compares `T` bases, then `x`, then `y`, short-circuiting when // it finds inequality. friend bool operator==(const S&amp;amp;, const S&amp;amp;) = default; // Non-member ordering operator with access to private members. // Compares `T` bases, then `x`, then `y`, short-circuiting when // it finds an ordering difference. friend auto operator&amp;lt;=&amp;gt;(const S&amp;amp;, const S&amp;amp;) = default; int x; bool y; };&lt;/quote&gt;&lt;p&gt;Description: Requests that the compiler generate the implementation of any comparison operator, including &lt;code&gt;&amp;lt;=&amp;gt;&lt;/code&gt;. Prefer non-member comparison operators. When defaulting &lt;code&gt;&amp;lt;=&amp;gt;&lt;/code&gt;, also explicitly default &lt;code&gt;==&lt;/code&gt;. Together these are sufficient to allow any comparison as long as callers do not need to take the address of any non-declared operator.&lt;/p&gt;&lt;p&gt;Documentation: Default comparisons&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Unlike constructors/destructors, our compiler extensions do not require these to be written out-of-line in the .cc file. Feel free to write &lt;code&gt;= default&lt;/code&gt; directly in the header, as this is much simpler to write.&lt;/p&gt;&lt;quote&gt;struct S { int x = 1; int y = 2; } S s{ .y = 3 }; // OK, s.x == 1, s.y == 3&lt;/quote&gt;&lt;p&gt;Description: Allows explicit initialization of subsets of aggregate members at construction.&lt;/p&gt;&lt;p&gt;Documentation: Designated initializers&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#if __has_cpp_attribute(assume) // Toolchain supports C++23 `[[assume]]`. ... #endif&lt;/quote&gt;&lt;p&gt;Description: Checks whether the toolchain supports a particular standard attribute.&lt;/p&gt;&lt;p&gt;Documentation: Feature testing&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;constinit int x = 3; void foo() { ++x; }&lt;/quote&gt;&lt;p&gt;Description: Ensures that a variable can be compile-time initialized. This is like a milder form of &lt;code&gt;constexpr&lt;/code&gt; that does not force variables to be const or have constant destruction.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;constinit&lt;/code&gt; specifier&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;struct S { uint32_t x : 27 = 2; };&lt;/quote&gt;&lt;p&gt;Description: Allows specifying the default initial value of a bit-field member, as can already be done for other member types.&lt;/p&gt;&lt;p&gt;Documentation: Bit-field&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;template &amp;lt;typename... Args&amp;gt; void foo(Args... args) { const auto l = [...n = args] { (x(n), ...); }; }&lt;/quote&gt;&lt;p&gt;Description: Allows initializing a capture with a pack expansion.&lt;/p&gt;&lt;p&gt;Documentation: Lambda capture&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#if !defined(__cpp_modules) || (__cpp_modules &amp;lt; 201907L) ... // Toolchain does not support modules #endif&lt;/quote&gt;&lt;p&gt;Description: Provides a standardized way to test the toolchain's implementation of a particular language feature.&lt;/p&gt;&lt;p&gt;Documentation: Feature testing&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;if (n &amp;gt; 0) [[likely]] { return 1; }&lt;/quote&gt;&lt;p&gt;Description: Tells the optimizer that a particular codepath is more or less likely than an alternative.&lt;/p&gt;&lt;p&gt;Documentation: C++ attribute: &lt;code&gt;likely&lt;/code&gt;, &lt;code&gt;unlikely&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;T foo(); ... for (auto&amp;amp; x : foo().items()) { ... } // UAF before C++23! for (T thing = foo(); auto&amp;amp; x : thing.items()) { ... } // OK&lt;/quote&gt;&lt;p&gt;Description: Like C++17's selection statements with initializer. Particularly useful before C++23, since temporaries inside range-expressions are not lifetime-extended until the end of the loop before C++23.&lt;/p&gt;&lt;p&gt;Documentation: Range-based &lt;code&gt;for&lt;/code&gt; loop&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;// `ordering` is an instance of `std::strong_odering` or `std::partial_ordering` // that describes how `a` and `b` are related. const auto ordering = a &amp;lt;=&amp;gt; b; if (ordering &amp;lt; 0) { ... } // `a` &amp;lt; `b` else if (ordering &amp;gt; 0) { ... } // `a` &amp;gt; `b` else { ... } // `a` == `b`&lt;/quote&gt;&lt;p&gt;Description: Compares two objects in a fashion similar to &lt;code&gt;strcmp&lt;/code&gt;. Perhaps most useful when defined as an overload in a class, in which case it can replace definitions of other inequalities. See also “Default comparisons”.&lt;/p&gt;&lt;p&gt;Documentation: Three-way comparison&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;enum class E { kA = 1 }; void f() { using enum E; auto a = kA; }&lt;/quote&gt;&lt;p&gt;Description: Introduces enumerator element names into the current scope.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;using enum&lt;/code&gt; declaration&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Usage is subject to the Google Style guidelines on aliases.&lt;/p&gt;&lt;p&gt;The following C++20 library features are allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;#include &amp;lt;bit&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Provides various byte- and bit-twiddling functions, e.g. counting leading zeros.&lt;/p&gt;&lt;p&gt;Documentation: Standard library header &lt;code&gt;&amp;lt;bit&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#include &amp;lt;compare&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Concepts and classes used to implement three-way comparison (“spaceship”, &lt;code&gt;&amp;lt;=&amp;gt;&lt;/code&gt;) support.&lt;/p&gt;&lt;p&gt;Documentation: Standard library header &lt;code&gt;&amp;lt;compare&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#include &amp;lt;concepts&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Various useful concepts, many of which replace pre-concept machinery in &lt;code&gt;&amp;lt;type_traits&amp;gt;&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: Standard library header &lt;code&gt;&amp;lt;concepts&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;constexpr int kArr[] = {2, 4, 6, 8, 10, 12}; constexpr auto is_even = [] (auto x) { return x % 2 == 0; }; static_assert(std::ranges::all_of(kArr, is_even));&lt;/quote&gt;&lt;p&gt;Description: Provides versions of most algorithms that accept either an iterator-sentinel pair or a single range argument.&lt;/p&gt;&lt;p&gt;Documentation: Ranges algorithms&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;// Range access: constexpr int kArr[] = {2, 4, 6, 8, 10, 12}; static_assert(std::ranges::size(kArr) == 6); // Range primitives: static_assert( std::same_as&amp;lt;std::ranges::iterator_t&amp;lt;decltype(kArr)&amp;gt;, const int*&amp;gt;); // Range concepts: static_assert(std::ranges::contiguous_range&amp;lt;decltype(kArr)&amp;gt;);&lt;/quote&gt;&lt;p&gt;Description: Various helper functions and types for working with ranges.&lt;/p&gt;&lt;p&gt;Documentation: Ranges library&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Supersedes &lt;code&gt;//base&lt;/code&gt;'s backports in &lt;code&gt;//base//ranges/ranges.h&lt;/code&gt;.&lt;/p&gt;&lt;quote&gt;#if !defined(__cpp_lib_atomic_value_initialization) || \ (__cpp_lib_atomic_value_initialization &amp;lt; 201911L) ... // `std::atomic` is not value-initialized by default. #endif&lt;/quote&gt;&lt;p&gt;Description: Provides a standardized way to test the toolchain's implementation of a particular library feature.&lt;/p&gt;&lt;p&gt;Documentation: Feature testing&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#include &amp;lt;numbers&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Provides compile-time constants for many common mathematical values, e.g. pi and e.&lt;/p&gt;&lt;p&gt;Documentation: Mathematical constants&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;void f(int* p) { int* aligned = std::assume_aligned&amp;lt;256&amp;gt;(p); ...&lt;/quote&gt;&lt;p&gt;Description: Informs the compiler that a pointer points to an address aligned to at least some particular power of 2.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::assume_aligned&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::vector&amp;lt;int&amp;gt; numbers = ...; std::erase_if(numbers, [](int x) { return x % 2 == 0; });&lt;/quote&gt;&lt;p&gt;Description: Erases from a container by value comparison or predicate, avoiding the need to use the &lt;code&gt;erase(remove(...&lt;/code&gt; paradigm.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::erase&lt;/code&gt;, &lt;code&gt;std::erase_if&lt;/code&gt; (&lt;code&gt;std::vector&lt;/code&gt;)&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;struct SharedData { ReadOnlyFrequentlyUsed data; alignas(std::hardware_destructive_interference_size) std::atomic&amp;lt;size_t&amp;gt; counter; };&lt;/quote&gt;&lt;p&gt;Description: The &lt;code&gt;std::hardware_destructive_interference_size&lt;/code&gt; constant is useful to avoid false sharing (destructive interference) between variables that would otherwise occupy the same cacheline. In contrast, &lt;code&gt;std::hardware_constructive_interference_size&lt;/code&gt; is helpful to promote true sharing (constructive interference), e.g. to support better locality for non-contended data.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::hardware_destructive_interference_size&lt;/code&gt;, &lt;code&gt;std::hardware_constructive_interference_size&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;template &amp;lt;typename T&amp;gt; static constexpr bool kBoundedArray = std::is_bounded_array_v&amp;lt;T&amp;gt;;&lt;/quote&gt;&lt;p&gt;Description: Checks if a type is an array type with a known or unknown bound.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::is_bounded_array&lt;/code&gt;, &lt;code&gt;std::is_unbounded_array&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;double val = std::lerp(start, end, t);&lt;/quote&gt;&lt;p&gt;Description: Linearly interpolates (or extrapolates) between two values.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::lerp&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;auto obj = std::make_obj_using_allocator&amp;lt;Obj&amp;gt;(alloc, ...);&lt;/quote&gt;&lt;p&gt;Description: Constructs an object using uses-allocator construction.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::make_obj_using_allocator&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;auto ptr = std::make_unique_for_overwrite&amp;lt;int&amp;gt;(); // `*ptr` is uninitialized&lt;/quote&gt;&lt;p&gt;Description: Like calling &lt;code&gt;std::unique_ptr&amp;lt;T&amp;gt;(new T)&lt;/code&gt; instead of the more typical &lt;code&gt;std::unique_ptr&amp;lt;T&amp;gt;(new T(...))&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::make_unique&lt;/code&gt;, &lt;code&gt;std::make_unique_for_overwrite&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;int center = std::midpoint(top, bottom);&lt;/quote&gt;&lt;p&gt;Description: Finds the midpoint between its two arguments, avoiding any possible overflow. For integral inputs, rounds towards the first argument.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::midpoint&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;void transform(const std::multimap&amp;lt;int, char&amp;gt;&amp;amp; map, int key) { auto [first, last] = map.equal_range(key); for (const auto&amp;amp; [_, value] : std::ranges::subrange(first, last)) { ...&lt;/quote&gt;&lt;p&gt;Description: Creates a view from an iterator and a sentinel. Useful for treating non-contiguous storage (e.g. a &lt;code&gt;std::map&lt;/code&gt;) as a range.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::ranges::subrange&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Prefer &lt;code&gt;base::span&lt;/code&gt; if working with explicitly contiguous data, such as in a &lt;code&gt;std::vector&lt;/code&gt;. Use &lt;code&gt;std::ranges::subrange&lt;/code&gt; when data is non-contiguous, or when it's an implementation detail that the data is contiguous (e.g. &lt;code&gt;base::flat_map&lt;/code&gt;).&lt;/p&gt;&lt;quote&gt;template &amp;lt;typename T&amp;gt; requires (std::is_same_v&amp;lt;std::remove_cvref_t&amp;lt;T&amp;gt;, int&amp;gt;) void foo(T t);&lt;/quote&gt;&lt;p&gt;Description: Provides a way to remove const, volatile, and reference qualifiers from a type.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::remove_cvref&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;str.replace(it, it + std::ssize(substr), 1, 'x');&lt;/quote&gt;&lt;p&gt;Description: Returns the size of an object as a signed type.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::size&lt;/code&gt;, &lt;code&gt;std::ssize&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;const std::string str = "Foo bar"; const bool is_true = str.ends_with("bar");&lt;/quote&gt;&lt;p&gt;Description: Tests whether a string starts or ends with a particular character or string.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::basic_string&amp;lt;CharT,Traits,Allocator&amp;gt;::starts_with&lt;/code&gt;, &lt;code&gt;std::basic_string&amp;lt;CharT,Traits,Allocator&amp;gt;::ends_with&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;The following C++20 language features are not allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;char8_t c = u8'x';&lt;/quote&gt;&lt;p&gt;Description: A single UTF-8 code unit. Similar to &lt;code&gt;unsigned char&lt;/code&gt;, but considered a distinct type.&lt;/p&gt;&lt;p&gt;Documentation: Fundamental types&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;char&lt;/code&gt; and unprefixed character literals. Non-UTF-8 encodings are rare enough in Chromium that the value of distinguishing them at the type level is low, and &lt;code&gt;char8_t*&lt;/code&gt; is not interconvertible with &lt;code&gt;char*&lt;/code&gt; (what ~all Chromium, STL, and platform-specific APIs use), so using &lt;code&gt;u8&lt;/code&gt; prefixes would obligate us to insert casts everywhere. If you want to declare at a type level that a block of data is string-like and not an arbitrary binary blob, prefer &lt;code&gt;std::string[_view]&lt;/code&gt; over &lt;code&gt;char*&lt;/code&gt;.&lt;quote&gt;export module helloworld; // module declaration import &amp;lt;iostream&amp;gt;; // import declaration export void hello() { // export declaration std::cout &amp;lt;&amp;lt; "Hello world!\n"; }&lt;/quote&gt;&lt;p&gt;Description: Modules provide an alternative to many uses of headers which allows for faster compilation, better tooling support, and reduction of problems like “include what you use”.&lt;/p&gt;&lt;p&gt;Documentation: Modules&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;struct Empty {}; struct X { int i; [[no_unique_address]] Empty e; };&lt;/quote&gt;&lt;p&gt;Description: Allows a data member to be overlapped with other members.&lt;/p&gt;&lt;p&gt;Documentation: C++ attribute: &lt;code&gt;no_unique_address&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;NO_UNIQUE_ADDRESS&lt;/code&gt; from &lt;code&gt;base/compiler_specific.h&lt;/code&gt; instead. Do not use (either form) on members of unions due to potential memory safety problems.&lt;p&gt;The following C++20 library features are not allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;int minus(int a, int b); auto fifty_minus_x = std::bind_front(minus, 50); int forty = fifty_minus_x(10);&lt;/quote&gt;&lt;p&gt;Description: An updated version of &lt;code&gt;std::bind&lt;/code&gt; with fewer gotchas, similar to &lt;code&gt;absl::bind_front&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::bind_front&lt;/code&gt;, &lt;code&gt;std::bind_back&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::Bind&lt;/code&gt;.&lt;quote&gt;float quake_rsqrt(float number) { long i = std::bit_cast&amp;lt;long&amp;gt;(number); i = 0x5f3759df - (i &amp;gt;&amp;gt; 1); // wtf? float y = std::bit_cast&amp;lt;float&amp;gt;(i); return y * (1.5f - (0.5f * number * y * y)); }&lt;/quote&gt;&lt;p&gt;Description: Returns an value constructed with the same bits as an value of a different type.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::bit_cast&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::&lt;/code&gt; version of &lt;code&gt;bit_cast&lt;/code&gt; allows casting of pointer and reference types, which is both useless in that it doesn't avoid UB, and dangerous in that it allows arbitrary casting away of modifiers like &lt;code&gt;const&lt;/code&gt;. Instead of using &lt;code&gt;bit_cast&lt;/code&gt; on pointers, use standard C++ casts. For use on values, use &lt;code&gt;base::bit_cast&lt;/code&gt; which does not allow this unwanted usage.&lt;quote&gt;std::u8string_view strv = u8"zß水🍌"; std::mbstate_t state; char out[MB_LEN_MAX] = {0}; for (char8_t c : strv) { size_t rc = std::c8rtomb(out, c, &amp;amp;state); ...&lt;/quote&gt;&lt;p&gt;Description: Converts a code point between UTF-8 and a multibyte character encoded using the current C locale.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::c8rtomb&lt;/code&gt;, &lt;code&gt;std::mbrtoc8&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;// Prints 1, 2, 3, 4, 5, 6. for (auto i : std::ranges::iota_view(1, 7)) { std::cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; '\n'; } constexpr int kArr[] = {6, 2, 8, 4, 4, 2}; constexpr auto plus_one = std::views::transform([](int n){ return n + 1; }); static_assert(std::ranges::equal(kArr | plus_one, {7, 3, 9, 5, 5, 3}));&lt;/quote&gt;&lt;p&gt;Description: Lightweight objects that represent iterable sequences. Provides facilities for lazy operations on ranges, along with composition into pipelines.&lt;/p&gt;&lt;p&gt;Documentation: Ranges library&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Banned in Chrome due to questions about the design, impact on build time, and runtime performance.&lt;/p&gt;&lt;quote&gt;class MyView : public std::ranges::view_interface&amp;lt;MyView&amp;gt; { ... };&lt;/quote&gt;&lt;p&gt;Description: CRTP base class for implementing custom view objects.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::ranges::view_interface&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Banned in Chrome since range factories and adapters are banned, and this would primarily allow authors to create similar functionality.&lt;/p&gt;&lt;quote&gt;#include &amp;lt;span&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Utilities for non-owning views over a sequence of objects.&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::span&lt;/code&gt;, which has a richer functionality set.&lt;quote&gt;std::vector&amp;lt;int&amp;gt; numbers; int* i = std::to_address(numbers.begin());&lt;/quote&gt;&lt;p&gt;Description: Converts a pointer-like object to a pointer, even if the pointer does not refer to a constructed object (in which case an expression like &lt;code&gt;&amp;amp;*p&lt;/code&gt; is UB).&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::to_address&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#include &amp;lt;syncstream&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Facilities for multithreaded access to streams.&lt;/p&gt;&lt;p&gt;Documentation: Standard library header &lt;code&gt;&amp;lt;syncstream&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;The following C++20 language features are not allowed in the Chromium codebase. See the top of this page on how to propose moving a feature from this list into the allowed or banned sections.&lt;/p&gt;&lt;quote&gt;struct B { int a; int&amp;amp;&amp;amp; r; } b2(1, 1); // Warning: dangling reference&lt;/quote&gt;&lt;p&gt;Description: Allows initialization of aggregates using parentheses, not just braces.&lt;/p&gt;&lt;p&gt;Documentation: Aggregate initialization, Direct initialization&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;co_return 1;&lt;/quote&gt;&lt;p&gt;Description: Allows writing functions that logically block while physically returning control to a caller. This enables writing some kinds of async code in simple, straight-line ways without storing state in members or binding callbacks.&lt;/p&gt;&lt;p&gt;Documentation: Coroutines&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;The following C++20 library features are not allowed in the Chromium codebase. See the top of this page on how to propose moving a feature from this list into the allowed or banned sections.&lt;/p&gt;&lt;quote&gt;#include &amp;lt;coroutine&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Header which defines various core coroutine types.&lt;/p&gt;&lt;p&gt;Documentation: Coroutine support&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::cout &amp;lt;&amp;lt; std::format("Hello {}!\n", "world");&lt;/quote&gt;&lt;p&gt;Description: Utilities for producing formatted strings.&lt;/p&gt;&lt;p&gt;Documentation: Formatting library&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;absl::StrFormat&lt;/code&gt; (which we don't yet use). Migration would be nontrivial.&lt;quote&gt;#include &amp;lt;source_location&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: Provides a class that can hold source code details such as filenames, function names, and line numbers.&lt;/p&gt;&lt;p&gt;Documentation: Standard library header &lt;code&gt;&amp;lt;source_location&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::Location&lt;/code&gt;.&lt;quote&gt;std::u8string str = u8"Foo";&lt;/quote&gt;&lt;p&gt;Description: A string whose character type is &lt;code&gt;char8_t&lt;/code&gt;, intended to hold UTF-8-encoded text.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;std::basic_string&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;char8_t&lt;/code&gt; above.&lt;p&gt;The following C++23 language features are allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;#ifdef FOO ... #elifdef BAR // New. ... #elifndef BAZ // New. ... #endif&lt;/quote&gt;&lt;p&gt;Description: New conditional inclusion preprocessor directives.&lt;/p&gt;&lt;p&gt;Documentation: Conditional inclusion&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;if consteval { ... }&lt;/quote&gt;&lt;p&gt;Description: consteval if statement. This removes some gotchas with std::is_constant_evaluated(), which needs to be used with a runtime if (rather than constexpr if) to be meaningful.&lt;/p&gt;&lt;p&gt;Documentation: if statement&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;struct FooHash { // Does not take an implicit pointer to `this`, which would have been useless. static size_t operator()(const Foo&amp;amp; foo) { return ...; } };&lt;/quote&gt;&lt;p&gt;Description: Static operators () and []&lt;/p&gt;&lt;p&gt;Documentation: Operator overloading&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;this&lt;/code&gt; argument for functors, improving performance. Discussion thread.&lt;p&gt;The following C++23 library features are allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;if (str.contains("foo")) ...&lt;/quote&gt;&lt;p&gt;Description: More concise substring check.&lt;/p&gt;&lt;p&gt;Documentation: std::basic_string::contains&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;auto x = std::byteswap(y);&lt;/quote&gt;&lt;p&gt;Description: Reverses the bytes of an integer.&lt;/p&gt;&lt;p&gt;Documentation: std::byteswap&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::ranges::contains, std::ranges::contains_subrange std::ranges::starts_with std::ranges::ends_with std::ranges::find_last, std::ranges::find_last_if, std::ranges::find_last_if_not std::ranges::iota std::ranges::fold_left std::ranges::fold_left_with_iter // The ones below are pending libc++ implementation as of 01/2026. std::ranges::shift_left, std::ranges::shift_right std::ranges::fold_left_first std::ranges::fold_right std::ranges::fold_right_last std::ranges::fold_left_first_with_iter&lt;/quote&gt;&lt;p&gt;Description: Various new ranges algorithms&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;&amp;lt;algorithm&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Discussion thread. Migration of base::Contains() tracked here.&lt;/p&gt;&lt;quote&gt;std::set&amp;lt;int&amp;gt; a_very_long_container_name = {1, 2, 3}; std::vector&amp;lt;int&amp;gt; old_way( a_very_long_container_name.begin(), a_very_long_container_name.end()); std::vector&amp;lt;int&amp;gt; new_way(std::from_range, a_very_long_container_name);&lt;/quote&gt;&lt;p&gt;Description: More concise conversion from one container type to another.&lt;/p&gt;&lt;p&gt;Documentation: std::from_range&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;auto x = std::to_underlying(enum_val);&lt;/quote&gt;&lt;p&gt;Description: Converts an enumeration to its underlying type.&lt;/p&gt;&lt;p&gt;Documentation: std::to_underlying&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::to_underlying&lt;/code&gt; is tracked in https://crbug.com/470039537.&lt;p&gt;The following C++23 language features are not allowed in the Chromium codebase. See the top of this page on how to propose moving a feature from this list into the allowed or banned sections.&lt;/p&gt;&lt;quote&gt;struct S { void f(this S&amp;amp; self); };&lt;/quote&gt;&lt;p&gt;Description: Allows explicit specification of the object parameter (deducing &lt;code&gt;this&lt;/code&gt;) in member functions.&lt;/p&gt;&lt;p&gt;Documentation: Explicit object parameter&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;struct S { int operator[](int i, int j); };&lt;/quote&gt;&lt;p&gt;Description: Allows multiple arguments in the subscript operator.&lt;/p&gt;&lt;p&gt;Documentation: Operator overloading&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;void f(const int&amp;amp; i) { auto copy = auto(i); }&lt;/quote&gt;&lt;p&gt;Description: Prvalue copy (decay-copy).&lt;/p&gt;&lt;p&gt;Documentation: Functional cast&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;[[assume(n &amp;gt; 0)]];&lt;/quote&gt;&lt;p&gt;Description: Provides a hint to the optimizer.&lt;/p&gt;&lt;p&gt;Documentation: dcl.attr.assume&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#warning "This is a warning"&lt;/quote&gt;&lt;p&gt;Description: Standardized preprocessor warning directive.&lt;/p&gt;&lt;p&gt;Documentation: #warning&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;auto s = 10uz;&lt;/quote&gt;&lt;p&gt;Description: Literal suffix &lt;code&gt;z&lt;/code&gt; or &lt;code&gt;uz&lt;/code&gt; for &lt;code&gt;std::size_t&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: Integer literal&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;auto c = "\N{LATIN CAPITAL LETTER A}";&lt;/quote&gt;&lt;p&gt;Description: Universal character names using &lt;code&gt;\N{...}&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: Escape sequences&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;The following C++23 library features are not allowed in the Chromium codebase. See the top of this page on how to propose moving a feature from this list into the allowed or banned sections.&lt;/p&gt;&lt;quote&gt;opt.and_then(f).transform(g).or_else(h);&lt;/quote&gt;&lt;p&gt;Description: &lt;code&gt;and_then&lt;/code&gt;, &lt;code&gt;transform&lt;/code&gt;, &lt;code&gt;or_else&lt;/code&gt; member functions.&lt;/p&gt;&lt;p&gt;Documentation: std::optional&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::expected&amp;lt;int, std::string&amp;gt; e;&lt;/quote&gt;&lt;p&gt;Description: A vocabulary type that contains an expected value or an error.&lt;/p&gt;&lt;p&gt;Documentation: std::expected&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::expected&lt;/code&gt;.&lt;quote&gt;std::flat_map&amp;lt;int, std::string&amp;gt; map;&lt;/quote&gt;&lt;p&gt;Description: Container adaptors that provide the functionality of associative containers using sorted vectors.&lt;/p&gt;&lt;p&gt;Documentation: std::flat_map std::flat_multimap std::flat_set std::flat_multiset&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::flat_map&lt;/code&gt; and &lt;code&gt;base::flat_set&lt;/code&gt;.&lt;quote&gt;std::unique_ptr&amp;lt;T&amp;gt; p; void GetT(T** out); GetT(std::out_ptr(p));&lt;/quote&gt;&lt;p&gt;Description: Smart pointer adapters for functions that take raw pointers as out-parameters.&lt;/p&gt;&lt;p&gt;Documentation: std::out_ptr, std::inout_ptr&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::mdspan m(ptr, 10, 10);&lt;/quote&gt;&lt;p&gt;Description: Multidimensional array view.&lt;/p&gt;&lt;p&gt;Documentation: std::mdspan&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::set&amp;lt;int&amp;gt; s = {1, 2, 3}; auto u = std::ranges::to&amp;lt;std::vector&amp;gt;(s); auto v = s | std::ranges::to&amp;lt;std::vector&amp;gt;();&lt;/quote&gt;&lt;p&gt;Description: Converts a range to a container.&lt;/p&gt;&lt;p&gt;Documentation: std::ranges::to&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;LOG(INFO) &amp;lt;&amp;lt; std::format("Values: {}", my_vector);&lt;/quote&gt;&lt;p&gt;Description: Extends &lt;code&gt;&amp;lt;format&amp;gt;&lt;/code&gt; to support printing containers and ranges.&lt;/p&gt;&lt;p&gt;Documentation: &lt;code&gt;&amp;lt;format&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;&amp;lt;format&amp;gt;&lt;/code&gt; is still a TBD feature from C++20.&lt;quote&gt;std::print("Hello {}", "world");&lt;/quote&gt;&lt;p&gt;Description: Formatted output.&lt;/p&gt;&lt;p&gt;Documentation: Print functions&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;std::generator&amp;lt;int&amp;gt; gen() { co_yield 1; }&lt;/quote&gt;&lt;p&gt;Description: Coroutine generator.&lt;/p&gt;&lt;p&gt;Documentation: std::generator&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;auto trace = std::stacktrace::current();&lt;/quote&gt;&lt;p&gt;Description: Captures a stack trace.&lt;/p&gt;&lt;p&gt;Documentation: std::stacktrace&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::debug::StackTrace&lt;/code&gt;.&lt;quote&gt;std::move_only_function&amp;lt;void()&amp;gt; f = [x = std::make_unique&amp;lt;int&amp;gt;(1)] {};&lt;/quote&gt;&lt;p&gt;Description: Function wrapper for move-only objects.&lt;/p&gt;&lt;p&gt;Documentation: std::move_only_function&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::OnceCallback&lt;/code&gt;.&lt;quote&gt;std::unreachable();&lt;/quote&gt;&lt;p&gt;Description: Indicates a codepath that is unreachable and invokes undefined behavior if executed.&lt;/p&gt;&lt;p&gt;Documentation: std::unreachable&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;__builtin_unreachable()&lt;/code&gt;. Unlike &lt;code&gt;NOTREACHED()&lt;/code&gt;, which cleanly aborts, this hints the compiler to optimize assuming this point is unreachable, with no bounds on how the program behaves if the annotation was wrong. This and &lt;code&gt;__builtin_unreachable()&lt;/code&gt; should only be used in rare circumstances.&lt;quote&gt;std::spanstream s(buffer);&lt;/quote&gt;&lt;p&gt;Description: Input/output stream using a span as buffer.&lt;/p&gt;&lt;p&gt;Documentation: std::spanstream&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;#include &amp;lt;stdfloat&amp;gt; int main() { std::float64_t f = 0.1f64; }&lt;/quote&gt;&lt;p&gt;Description: Similar to int32_t and friends but for floats.&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;void* storage = std::malloc(sizeof(T)); T* p = std::start_lifetime_as&amp;lt;T&amp;gt;(storage);&lt;/quote&gt;&lt;p&gt;Description: Explicitly starts the lifetime of an object of type T in the given storage.&lt;/p&gt;&lt;p&gt;Documentation: std::start_lifetime_as&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;The following Abseil library features are not allowed in the Chromium codebase.&lt;/p&gt;&lt;quote&gt;absl::any a = int{5}; EXPECT_THAT(absl::any_cast&amp;lt;int&amp;gt;(&amp;amp;a), Pointee(5)); EXPECT_EQ(absl::any_cast&amp;lt;size_t&amp;gt;(&amp;amp;a), nullptr);&lt;/quote&gt;&lt;p&gt;Description: Early adaptation of C++17 &lt;code&gt;std::any&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: std::any&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::any&lt;/code&gt;.&lt;quote&gt;absl::AnyInvocable&lt;/quote&gt;&lt;p&gt;Description: An equivalent of the C++23 std::move_only_function.&lt;/p&gt;&lt;p&gt;Documentation:&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::RepeatingCallback&lt;/code&gt;, &lt;code&gt;base::OnceCallback&lt;/code&gt;.&lt;quote&gt;T* data() ABSL_ATTRIBUTE_LIFETIME_BOUND { return data_; } ABSL_ATTRIBUTE_NO_TAIL_CALL ReturnType Loop(); struct S { bool b; int32_t i; } ABSL_ATTRIBUTE_PACKED;&lt;/quote&gt;&lt;p&gt;Description: Cross-platform macros to expose compiler-specific functionality.&lt;/p&gt;&lt;p&gt;Documentation: attributes.h&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;Long names discourage use. Use standardized attributes over macros where possible, and otherwise prefer shorter alternatives in &lt;code&gt;base/compiler_specific.h&lt;/code&gt;.&lt;/p&gt;&lt;quote&gt;absl::btree_map absl::btree_set absl::btree_multimap absl::btree_multiset&lt;/quote&gt;&lt;p&gt;Description: Alternatives to the tree-based standard library containers designed to be more efficient in the general case.&lt;/p&gt;&lt;p&gt;Documentation: Containers&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::map&lt;/code&gt; and company. In practice they have been found to introduce a substantial code size increase. Until this problem can be resolved the use of these containers is banned. Use the standard library containers instead.&lt;quote&gt;absl::bind_front&lt;/quote&gt;&lt;p&gt;Description: Binds the first N arguments of an invocable object and stores them by value.&lt;/p&gt;&lt;p&gt;Documentation:&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::Bind&lt;/code&gt;.&lt;quote&gt;ABSL_FLAG(bool, logs, false, "print logs to stderr"); app --logs=true;&lt;/quote&gt;&lt;p&gt;Description: Allows programmatic access to flag values passed on the command-line to binaries.&lt;/p&gt;&lt;p&gt;Documentation: Flags Library&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::CommandLine&lt;/code&gt; instead.&lt;quote&gt;auto it = absl::c_find(container, value);&lt;/quote&gt;&lt;p&gt;Description: Container-based versions of algorithmic functions within C++ standard library.&lt;/p&gt;&lt;p&gt;Documentation: container.h&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::ranges::&lt;/code&gt;.&lt;quote&gt;absl::FixedArray&amp;lt;MyObj&amp;gt; objs_;&lt;/quote&gt;&lt;p&gt;Description: A fixed size array like &lt;code&gt;std::array&lt;/code&gt;, but with size determined at runtime instead of compile time.&lt;/p&gt;&lt;p&gt;Documentation: fixed_array.h&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/types/fixed_array.h&lt;/code&gt;, which is a light-weight wrapper that deletes the problematic constructor.&lt;quote&gt;absl::FunctionRef&lt;/quote&gt;&lt;p&gt;Description: Type for holding a non-owning reference to an object of any invocable type.&lt;/p&gt;&lt;p&gt;Documentation: function_ref.h&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;absl::FunctionRef&lt;/code&gt; is banned due to allowing implicit conversions between function signatures in potentially surprising ways. For example, a callable with the signature &lt;code&gt;int()&lt;/code&gt; will bind to &lt;code&gt;absl::FunctionRef&amp;lt;void()&amp;gt;&lt;/code&gt;: the return value from the callable will be silently discarded.&lt;code&gt;base::FunctionRef&lt;/code&gt; instead.&lt;code&gt;base::OnceCallback&lt;/code&gt; and &lt;code&gt;base::RepeatingCallback&lt;/code&gt;, &lt;code&gt;base::FunctionRef&lt;/code&gt; supports capturing lambdas.&lt;code&gt;ForEachFrame(base::FunctionRef&amp;lt;void(Frame&amp;amp;)&amp;gt;)&lt;/code&gt;. This can often result in clearer code than code that is templated to accept lambdas, e.g. with &lt;code&gt;template &amp;lt;typename Invocable&amp;gt; void ForEachFrame(Invocable invocable)&lt;/code&gt;, it is much less obvious what arguments will be passed to &lt;code&gt;invocable&lt;/code&gt;.&lt;code&gt;base::OnceCallback&lt;/code&gt; and &lt;code&gt;base::RepeatingCallback&lt;/code&gt; intentionally disallow conversions to &lt;code&gt;base::FunctionRef&lt;/code&gt;, under the theory that the callback should be a capturing lambda instead. Attempting to use this conversion will trigger a &lt;code&gt;static_assert&lt;/code&gt; requesting additional feedback for use cases where this conversion would be valuable.&lt;code&gt;base::FunctionRef&lt;/code&gt; must not outlive the function call. Like &lt;code&gt;std::string_view&lt;/code&gt;, &lt;code&gt;base::FunctionRef&lt;/code&gt; is a non-owning reference. Using a &lt;code&gt;base::FunctionRef&lt;/code&gt; as a return value or class field is dangerous and likely to result in lifetime bugs.&lt;quote&gt;LOG(INFO) &amp;lt;&amp;lt; message; CHECK(condition); absl::AddLogSink(&amp;amp;custom_sink_to_capture_absl_logs);&lt;/quote&gt;&lt;p&gt;Description: Macros and related classes to perform debug loggings&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/logging.h&lt;/code&gt;. We‘d like to drop Chromium’s version and replace with the Abseil one, but no one has looked into how to migrate and what impacts (e.g. build time) we‘d incur. If you’d like to do this work, please contact cxx@.&lt;quote&gt;// Global or namespace scope. ABSL_CONST_INIT absl::NoDestructor&amp;lt;MyRegistry&amp;gt; reg{"foo", "bar", 8008}; // Function scope. const std::string&amp;amp; MyString() { static const absl::NoDestructor&amp;lt;std::string&amp;gt; x("foo"); return *x; }&lt;/quote&gt;&lt;p&gt;Description: &lt;code&gt;absl::NoDestructor&amp;lt;T&amp;gt;&lt;/code&gt; is a wrapper around an object of type T that behaves as an object of type T but never calls T's destructor.&lt;/p&gt;&lt;p&gt;Documentation: no_destructor.h&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::NoDestructor&lt;/code&gt;. Banned pending rewriting friending of that class into a form usable with this (see crbug.com/392931072); at that point we can allow this and migrate to it.&lt;quote&gt;void PaySalary(Employee* absl_nonnull employee) { pay(*employee); // OK to dereference }&lt;/quote&gt;&lt;p&gt;Description: Annotations to more clearly specify contracts&lt;/p&gt;&lt;p&gt;Documentation: nullability.h&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;absl::optional&amp;lt;int&amp;gt; Func(bool b) { return b ? absl::make_optional(1) : absl::nullopt; }&lt;/quote&gt;&lt;p&gt;Description: Early adaptation of C++17 &lt;code&gt;std::optional&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: std::optional&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::optional&lt;/code&gt;. Use &lt;code&gt;std::optional&lt;/code&gt; instead.&lt;quote&gt;absl::BitGen bitgen; size_t index = absl::Uniform(bitgen, 0u, elems.size());&lt;/quote&gt;&lt;p&gt;Description: Functions and utilities for generating pseudorandom data.&lt;/p&gt;&lt;p&gt;Documentation: Random library&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/rand_util.h&lt;/code&gt; instead.&lt;quote&gt;absl::Span&lt;/quote&gt;&lt;p&gt;Description: Early adaptation of C++20 &lt;code&gt;std::span&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: Using absl::Span&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::span&lt;/code&gt;. Keep using &lt;code&gt;base::span&lt;/code&gt;.&lt;quote&gt;absl::StatusOr&amp;lt;T&amp;gt;&lt;/quote&gt;&lt;p&gt;Description: An object that is either a usable value, or an error Status explaining why such a value is not present.&lt;/p&gt;&lt;p&gt;Documentation: statusor.h&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base::expected&lt;/code&gt;.&lt;quote&gt;absl::string_view&lt;/quote&gt;&lt;p&gt;Description: Early adaptation of C++17 &lt;code&gt;std::string_view&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Documentation: absl::string_view&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;std::string_view&lt;/code&gt;. Please use &lt;code&gt;std::string_view&lt;/code&gt; instead.&lt;quote&gt;absl::StrSplit absl::StrJoin absl::StrCat absl::StrAppend absl::Substitute absl::StrContains&lt;/quote&gt;&lt;p&gt;Description: Classes and utility functions for manipulating and comparing strings.&lt;/p&gt;&lt;p&gt;Documentation: String Utilities&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/strings&lt;/code&gt;. We should re-evalute when we've migrated from &lt;code&gt;base::StringPiece&lt;/code&gt; to &lt;code&gt;std::string_view&lt;/code&gt;. Also note that &lt;code&gt;absl::StrFormat()&lt;/code&gt; is not considered part of this group, and is explicitly allowed.&lt;quote&gt;absl::Mutex&lt;/quote&gt;&lt;p&gt;Description: Primitives for managing tasks across different threads.&lt;/p&gt;&lt;p&gt;Documentation: Synchronization&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/synchronization/&lt;/code&gt;. We would love more testing on whether there are compelling reasons to prefer base, absl, or std synchronization primitives; for now, use &lt;code&gt;base/synchronization/&lt;/code&gt;.&lt;quote&gt;absl::Duration absl::Time absl::TimeZone absl::CivilDay&lt;/quote&gt;&lt;p&gt;Description: Abstractions for holding time values, both in terms of absolute time and civil time.&lt;/p&gt;&lt;p&gt;Documentation: Time&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;code&gt;base/time/&lt;/code&gt;.&lt;quote&gt;absl::bad_variant_access; absl::get; absl::get_if; absl::holds_alternative; absl::monostate; absl::variant; absl::variant_alternative; absl::variant_alternative_t; absl::variant_npos; absl::variant_size; absl::variant_size_v; absl::visit;&lt;/quote&gt;&lt;p&gt;Description: A backport of C++17's std::variant type-safe union and related utilities.&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;quote&gt;absl::apply; absl::exchange; absl::forward; absl::in_place; absl::in_place_index; absl::in_place_index_t; absl::in_place_t; absl::in_place_type; absl::in_place_type_t; absl::index_sequence; absl::index_sequence_for; absl::integer_sequence; absl::make_from_tuple; absl::make_index_sequence; absl::make_integer_sequence; absl::move;&lt;/quote&gt;&lt;p&gt;Description: Backports of various C++17 template utilities.&lt;/p&gt;&lt;p&gt;Notes:&lt;/p&gt;&lt;p&gt;The following Abseil library features are not allowed in the Chromium codebase. See the top of this page on how to propose moving a feature from this list into the allowed or banned sections.&lt;/p&gt;&lt;quote&gt;absl::linked_hash_set&amp;lt;int&amp;gt; m; m.insert(2); m.insert(1); m.insert(3); EXPECT_THAT(m, ElementsAre(2, 1, 3));&lt;/quote&gt;&lt;p&gt;Description: A simple insertion-ordered set or map. It provides O(1) amortized insertions and lookups, as well as iteration in the insertion order.&lt;/p&gt;&lt;p&gt;Documentation:&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chromium.googlesource.com/chromium/src/+/main/styleguide/c++/c++-features.md"/><published>2026-01-23T20:27:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46737630</id><title>Unrolling the Codex agent loop</title><updated>2026-01-24T10:42:30.638040+00:00</updated><content>&lt;doc fingerprint="f64eccd3469e8c9d"&gt;
  &lt;main&gt;
    &lt;p&gt;Codex CLI(opens in a new window) is our cross-platform local software agent, designed to produce high-quality, reliable software changes while operating safely and efficiently on your machine. We’ve learned a tremendous amount about how to build a world-class software agent since we first launched the CLI in April. To unpack those insights, this is the first post in an ongoing series where we’ll explore various aspects of how Codex works, as well as hard-earned lessons. (For an even more granular view on how the Codex CLI is built, check out our open source repository at https://github.com/openai/codex(opens in a new window). Many of the finer details of our design decisions are memorialized in GitHub issues and pull requests if you’d like to learn more.)&lt;/p&gt;
    &lt;p&gt;To kick off, we’ll focus on the agent loop, which is the core logic in Codex CLI that is responsible for orchestrating the interaction between the user, the model, and the tools the model invokes to perform meaningful software work. We hope this post gives you a good view into the role our agent (or “harness”) plays in making use of an LLM.&lt;/p&gt;
    &lt;p&gt;Before we dive in, a quick note on terminology: at OpenAI, “Codex” encompasses a suite of software agent offerings, including Codex CLI, Codex Cloud, and the Codex VS Code extension. This post focuses on the Codex harness, which provides the core agent loop and execution logic that underlies all Codex experiences and is surfaced through the Codex CLI. For ease here, we’ll use the terms “Codex” and “Codex CLI” interchangeably.&lt;/p&gt;
    &lt;p&gt;At the heart of every AI agent is something called “the agent loop.” A simplified illustration of the agent loop looks like this:&lt;/p&gt;
    &lt;p&gt;To start, the agent takes input from the user to include in the set of textual instructions it prepares for the model known as a prompt.&lt;/p&gt;
    &lt;p&gt;The next step is to query the model by sending it our instructions and asking it to generate a response, a process known as inference. During inference, the textual prompt is first translated into a sequence of input tokens(opens in a new window)—integers that index into the model’s vocabulary. These tokens are then used to sample the model, producing a new sequence of output tokens.&lt;/p&gt;
    &lt;p&gt;The output tokens are translated back into text, which becomes the model’s response. Because tokens are produced incrementally, this translation can happen as the model runs, which is why many LLM-based applications display streaming output. In practice, inference is usually encapsulated behind an API that operates on text, abstracting away the details of tokenization.&lt;/p&gt;
    &lt;p&gt;As the result of the inference step, the model either (1) produces a final response to the user’s original input, or (2) requests a tool call that the agent is expected to perform (e.g., “run &lt;code&gt;ls&lt;/code&gt; and report the output”). In the case of (2), the agent executes the tool call and appends its output to the original prompt. This output is used to generate a new input that’s used to re-query the model; the agent can then take this new information into account and try again.&lt;/p&gt;
    &lt;p&gt;This process repeats until the model stops emitting tool calls and instead produces a message for the user (referred to as an assistant message in OpenAI models). In many cases, this message directly answers the user’s original request, but it may also be a follow-up question for the user.&lt;/p&gt;
    &lt;p&gt;Because the agent can execute tool calls that modify the local environment, its “output” is not limited to the assistant message. In many cases, the primary output of a software agent is the code it writes or edits on your machine. Nevertheless, each turn always ends with an assistant message—such as “I added the &lt;code&gt;architecture.md&lt;/code&gt; you asked for”—which signals a termination state in the agent loop. From the agent’s perspective, its work is complete and control returns to the user.&lt;/p&gt;
    &lt;p&gt;The journey from user input to agent response shown in the diagram is referred to as one turn of a conversation (a thread in Codex). Though this conversation turn can include many iterations between the model inference and tool calls). Every time you send a new message to an existing conversation, the conversation history is included as part of the prompt for the new turn, which includes the messages and tool calls from previous turns:&lt;/p&gt;
    &lt;p&gt;This means that as the conversation grows, so does the length of the prompt used to sample the model. This length matters because every model has a context window, which is the maximum number of tokens it can use for one inference call. Note this window includes both input and output tokens. As you might imagine, an agent could decide to make hundreds of tool calls in a single turn, potentially exhausting the context window. For this reason, context window management is one of the agent’s many responsibilities. Now, let’s dive in to see how Codex runs the agent loop.&lt;/p&gt;
    &lt;p&gt;The Codex CLI sends HTTP requests to the Responses API(opens in a new window) to run model inference. We’ll examine how information flows through Codex, which uses the Responses API to drive the agent loop.&lt;/p&gt;
    &lt;p&gt;The Responses API endpoint that the Codex CLI uses is configurable(opens in a new window), so it can be used with any endpoint that implements the Responses API(opens in a new window):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;When using ChatGPT login(opens in a new window) with the Codex CLI, it uses &lt;code&gt;https://chatgpt.com/backend-api/codex/responses&lt;/code&gt;as the endpoint&lt;/item&gt;
      &lt;item&gt;When using API-key authentication(opens in a new window) with OpenAI hosted models, it uses &lt;code&gt;https://api.openai.com/v1/responses&lt;/code&gt;as the endpoint&lt;/item&gt;
      &lt;item&gt;When running Codex CLI with &lt;code&gt;--oss&lt;/code&gt;to use gpt-oss with ollama 0.13.4+(opens in a new window) or LM Studio 0.3.39+(opens in a new window), it defaults to&lt;code&gt;http://localhost:11434/v1/responses&lt;/code&gt;running locally on your computer&lt;/item&gt;
      &lt;item&gt;Codex CLI can be used with the Responses API hosted by a cloud provider such as Azure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let’s explore how Codex creates the prompt for the first inference call in a conversation.&lt;/p&gt;
    &lt;p&gt;As an end user, you don’t specify the prompt used to sample the model verbatim when you query the Responses API. Instead, you specify various input types as part of your query, and the Responses API server decides how to structure this information into a prompt that the model is designed to consume. You can think of the prompt as a “list of items”; this section will explain how your query gets transformed into that list.&lt;/p&gt;
    &lt;p&gt;In the initial prompt, every item in the list is associated with a role. The &lt;code&gt;role&lt;/code&gt; indicates how much weight the associated content should have and is one of the following values (in decreasing order of priority): &lt;code&gt;system&lt;/code&gt;, &lt;code&gt;developer&lt;/code&gt;, &lt;code&gt;user&lt;/code&gt;, &lt;code&gt;assistant&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The Responses API(opens in a new window) takes a JSON payload with many parameters. We’ll focus on these three:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;instructions&lt;/code&gt;(opens in a new window): system (or developer) message inserted into the model’s context&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tools&lt;/code&gt;(opens in a new window): a list of tools the model may call while generating a response&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;input&lt;/code&gt;(opens in a new window): a list of text, image, or file inputs to the model&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In Codex, the &lt;code&gt;instructions&lt;/code&gt; field is read from the &lt;code&gt;model_instructions_file&lt;/code&gt;(opens in a new window) in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;, if specified; otherwise, the &lt;code&gt;base_instructions&lt;/code&gt; associated with a model(opens in a new window) are used. Model-specific instructions live in the Codex repo and are bundled into the CLI (e.g., &lt;code&gt;gpt-5.2-codex_prompt.md&lt;/code&gt;(opens in a new window)).&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;tools&lt;/code&gt; field is a list of tool definitions that conform to a schema defined by the Responses API. For Codex, this includes tools that are provided by the Codex CLI, tools that are provided by the Responses API that should be made available to Codex, as well as tools provided by the user, usually via MCP servers:&lt;/p&gt;
    &lt;p&gt;Finally, the &lt;code&gt;input&lt;/code&gt; field of the JSON payload is a list of items. Codex inserts the following items(opens in a new window) into the &lt;code&gt;input&lt;/code&gt; before adding the user message:&lt;/p&gt;
    &lt;p&gt;1. A message with &lt;code&gt;role=developer&lt;/code&gt; that describes the sandbox that applies only to the Codex-provided &lt;code&gt;shell&lt;/code&gt; tool defined in the &lt;code&gt;tools&lt;/code&gt; section. That is, other tools, such as those provided from MCP servers, are not sandboxed by Codex and are responsible for enforcing their own guardrails.&lt;/p&gt;
    &lt;p&gt;The message is built from a template where the key pieces of content come from snippets of Markdown bundled into the Codex CLI, such as &lt;code&gt;workspace_write.md&lt;/code&gt;(opens in a new window) and &lt;code&gt;on_request.md&lt;/code&gt;(opens in a new window):&lt;/p&gt;
    &lt;p&gt;2. (Optional) A message with &lt;code&gt;role=developer&lt;/code&gt; whose contents are the &lt;code&gt;developer_instructions&lt;/code&gt; value read from the user’s &lt;code&gt;config.toml&lt;/code&gt; file.&lt;/p&gt;
    &lt;p&gt;3. (Optional) A message with &lt;code&gt;role=user&lt;/code&gt; whose contents are the “user instructions,” which are not sourced from a single file but are aggregated across multiple sources(opens in a new window). In general, more specific instructions appear later:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Contents of &lt;code&gt;AGENTS.override.md&lt;/code&gt;and&lt;code&gt;AGENTS.md&lt;/code&gt;in&lt;code&gt;$CODEX_HOME&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Subject to a limit (32 KiB, by default), look in each folder from the Git/project root of the &lt;code&gt;cwd&lt;/code&gt;(if it it exists) up to the&lt;code&gt;cwd&lt;/code&gt;itself: add the contents of any of&lt;code&gt;AGENTS.override.md&lt;/code&gt;,&lt;code&gt;AGENTS.md&lt;/code&gt;, or any filename specified by&lt;code&gt;project_doc_fallback_filenames in config.toml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;If any skills(opens in a new window) have been configured:&lt;list rend="ul"&gt;&lt;item&gt;a short preamble about skills&lt;/item&gt;&lt;item&gt;the skill metadata(opens in a new window) for each skill&lt;/item&gt;&lt;item&gt;a section on how to use skills(opens in a new window)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;4. A message with &lt;code&gt;role=user&lt;/code&gt; that describes the local environment in which the agent is currently operating. This specifies the current working directory and the user’s shell(opens in a new window):&lt;/p&gt;
    &lt;p&gt;Once Codex has done all of the above computation to initialize the &lt;code&gt;input&lt;/code&gt;, it appends the user message to start the conversation.&lt;/p&gt;
    &lt;p&gt;The previous examples focused on the content of each message, but note that each element of &lt;code&gt;input&lt;/code&gt; is a JSON object with &lt;code&gt;type&lt;/code&gt;, &lt;code&gt;role&lt;/code&gt;(opens in a new window), and &lt;code&gt;content&lt;/code&gt; as follows:&lt;/p&gt;
    &lt;p&gt;Once Codex builds up the full JSON payload to send to the Responses API, it then makes the HTTP POST request with an &lt;code&gt;Authorization&lt;/code&gt; header depending on how the Responses API endpoint is configured in &lt;code&gt;~/.codex/config.toml&lt;/code&gt; (additional HTTP headers and query parameters are added if specified).&lt;/p&gt;
    &lt;p&gt;When an OpenAI Responses API server receives the request, it uses the JSON to derive the prompt for the model as follows (to be sure, a custom implementation of the Responses API could make a different choice):&lt;/p&gt;
    &lt;p&gt;As you can see, the order of the first three items in the prompt is determined by the server, not the client. That said, of those three items, only the content of the system message is also controlled by the server, as the &lt;code&gt;tools&lt;/code&gt; and &lt;code&gt;instructions&lt;/code&gt; are determined by the client. These are followed by the &lt;code&gt;input&lt;/code&gt; from the JSON payload to complete the prompt.&lt;/p&gt;
    &lt;p&gt;Now that we have our prompt, we are ready to sample the model.&lt;/p&gt;
    &lt;p&gt;This HTTP request to the Responses API initiates the first “turn” of a conversation in Codex. The server replies with a Server-Sent Events (SSE(opens in a new window)) stream. The &lt;code&gt;data&lt;/code&gt; of each event is a JSON payload with a &lt;code&gt;"type"&lt;/code&gt; that starts with &lt;code&gt;"response"&lt;/code&gt;, which could be something like this (a full list of events can be found in our API docs(opens in a new window)):&lt;/p&gt;
    &lt;p&gt;Codex consumes the stream of events(opens in a new window) and republishes them as internal event objects that can be used by a client. Events like &lt;code&gt;response.output_text.delta&lt;/code&gt; are used to support streaming in the UI, whereas other events like &lt;code&gt;response.output_item.added&lt;/code&gt; are transformed into objects that are appended to the &lt;code&gt;input&lt;/code&gt; for subsequent Responses API calls.&lt;/p&gt;
    &lt;p&gt;Suppose the first request to the Responses API includes two &lt;code&gt;response.output_item.done&lt;/code&gt; events: one with &lt;code&gt;type=reasoning&lt;/code&gt; and one with &lt;code&gt;type=function_call&lt;/code&gt;. These events must be represented in the &lt;code&gt;input&lt;/code&gt; field of the JSON when we query the model again with the response to the tool call: &lt;/p&gt;
    &lt;p&gt;The resulting prompt used to sample the model as part of the subsequent query would look like this:&lt;/p&gt;
    &lt;p&gt;In particular, note how the old prompt is an exact prefix of the new prompt. This is intentional, as this makes subsequent requests much more efficient because it enables us to take advantage of prompt caching (which we’ll discuss in the next section on performance).&lt;/p&gt;
    &lt;p&gt;Looking back at our first diagram of the agent loop, we see that there could be many iterations between inference and tool calling. The prompt may continue to grow until we finally receive an assistant message, indicating the end of the turn:&lt;/p&gt;
    &lt;p&gt;In the Codex CLI, we present the assistant message to the user and focus the composer to indicate to the user that it’s their “turn” to continue the conversation. If the user responds, both the assistant message from the previous turn, as well as the user’s new message, must be appended to the &lt;code&gt;input&lt;/code&gt; in the Responses API request to start the new turn:&lt;/p&gt;
    &lt;p&gt;Once again, because we are continuing a conversation, the length of the &lt;code&gt;input&lt;/code&gt; we send to the Responses API keeps increasing:&lt;/p&gt;
    &lt;p&gt;Let’s examine what this ever-growing prompt means for performance.&lt;/p&gt;
    &lt;p&gt;You might be asking yourself, “Wait, isn’t the agent loop quadratic in terms of the amount of JSON sent to the Responses API over the course of the conversation?” And you would be right. While the Responses API does support an optional &lt;code&gt;previous_response_id&lt;/code&gt;(opens in a new window) parameter to mitigate this issue, Codex does not use it today, primarily to keep requests fully stateless and to support Zero Data Retention (ZDR) configurations.&lt;/p&gt;
    &lt;p&gt;Avoiding &lt;code&gt;previous_response_id&lt;/code&gt; simplifies things for the provider of the Responses API because it ensures that every request is stateless. This also makes it straightforward to support customers who have opted into Zero Data Retention (ZDR)(opens in a new window), as storing the data required to support &lt;code&gt;previous_response_id&lt;/code&gt; would be at odds with ZDR. Note that ZDR customers do not sacrifice the ability to benefit from proprietary reasoning messages from prior turns, as the associated &lt;code&gt;encrypted_content&lt;/code&gt; can be decrypted on the server. (OpenAI persists a ZDR customer’s decryption key, but not their data.) See PRs #642(opens in a new window) and #1641(opens in a new window) for the related changes to Codex to support ZDR.&lt;/p&gt;
    &lt;p&gt;Generally, the cost of sampling the model dominates the cost of network traffic, making sampling the primary target of our efficiency efforts. This is why prompt caching is so important, as it enables us to reuse computation from a previous inference call. When we get cache hits, sampling the model is linear rather than quadratic. Our prompt caching (opens in a new window)documentation explains this in more detail:&lt;/p&gt;
    &lt;p&gt;Cache hits are only possible for exact prefix matches within a prompt. To realize caching benefits, place static content like instructions and examples at the beginning of your prompt, and put variable content, such as user-specific information, at the end. This also applies to images and tools, which must be identical between requests.&lt;/p&gt;
    &lt;p&gt;With this in mind, let’s consider what types of operations could cause a “cache miss” in Codex:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Changing the &lt;code&gt;tools&lt;/code&gt;available to the model in the middle of the conversation.&lt;/item&gt;
      &lt;item&gt;Changing the &lt;code&gt;model&lt;/code&gt;that is the target of the Responses API request (in practice, this changes the third item in the original prompt, as it contains model-specific instructions).&lt;/item&gt;
      &lt;item&gt;Changing the sandbox configuration, approval mode, or current working directory.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Codex team must be diligent when introducing new features in the Codex CLI that could compromise prompt caching. As an example, our initial support for MCP tools introduced a bug where we failed to enumerate the tools in a consistent order(opens in a new window), causing cache misses. Note that MCP tools can be particularly tricky because MCP servers can change the list of tools they provide on the fly via a &lt;code&gt;notifications/tools/list_changed&lt;/code&gt;(opens in a new window) notification. Honoring this notification in the middle of a long conversation can cause an expensive cache miss.&lt;/p&gt;
    &lt;p&gt;When possible, we handle configuration changes that happen mid-conversation by appending a new message to &lt;code&gt;input&lt;/code&gt; to reflect the change rather than modifying an earlier message:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If the sandbox configuration or approval mode changes, we insert(opens in a new window) a new &lt;code&gt;role=developer&lt;/code&gt;message with the same format as the original&lt;code&gt;&amp;lt;permissions instructions&amp;gt;&lt;/code&gt;item.&lt;/item&gt;
      &lt;item&gt;If the current working directory changes, we insert(opens in a new window) a new &lt;code&gt;role=user&lt;/code&gt;message with the same format as the original&lt;code&gt;&amp;lt;environment_context&amp;gt;&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We go to great lengths to ensure cache hits for performance. There’s another key resource we have to manage: the context window.&lt;/p&gt;
    &lt;p&gt;Our general strategy to avoid running out of context window is to compact the conversation once the number of tokens exceeds some threshold. Specifically, we replace the &lt;code&gt;input&lt;/code&gt; with a new, smaller list of items that is representative of the conversation, enabling the agent to continue with an understanding of what has happened thus far. An early implementation of compaction(opens in a new window) required the user to manually invoke the &lt;code&gt;/compact&lt;/code&gt; command, which would query the Responses API using the existing conversation plus custom instructions for summarization(opens in a new window). Codex used the resulting assistant message containing the summary as the new &lt;code&gt;input&lt;/code&gt;(opens in a new window) for subsequent conversation turns.&lt;/p&gt;
    &lt;p&gt;Since then, the Responses API has evolved to support a special &lt;code&gt;/responses/compact&lt;/code&gt; endpoint(opens in a new window) that performs compaction more efficiently. It returns a list of items(opens in a new window) that can be used in place of the previous &lt;code&gt;input&lt;/code&gt; to continue the conversation while freeing up the context window. This list includes a special &lt;code&gt;type=compaction&lt;/code&gt; item with an opaque &lt;code&gt;encrypted_content&lt;/code&gt; item that preserves the model’s latent understanding of the original conversation. Now, Codex automatically uses this endpoint to compact the conversation when the &lt;code&gt;auto_compact_limit&lt;/code&gt;(opens in a new window) is exceeded.&lt;/p&gt;
    &lt;p&gt;We’ve introduced the Codex agent loop and walked through how Codex crafts and manages its context when querying a model. Along the way, we highlighted practical considerations and best practices that apply to anyone building an agent loop on top of the Responses API.&lt;/p&gt;
    &lt;p&gt;While the agent loop provides the foundation for Codex, it’s only the beginning. In upcoming posts, we’ll dig into the CLI’s architecture, explore how tool use is implemented, and take a closer look at Codex’s sandboxing model.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/unrolling-the-codex-agent-loop/"/><published>2026-01-23T20:42:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46737870</id><title>TrueVault (YC W14) is hiring a Growth Lead to test different growth channels</title><updated>2026-01-24T10:42:30.205937+00:00</updated><content>&lt;doc fingerprint="7d1cd05f220d14af"&gt;
  &lt;main&gt;
    &lt;p&gt;We make Privacy Software for SMBs.&lt;/p&gt;
    &lt;p&gt;At TrueVault, we build software that solves real problems for real customers, and we approach growth with the same discipline and curiosity we bring to product. We’re looking for a Growth Lead who wants to build from first principles: someone who enjoys experimenting, uncovering real signal, and turning insight into momentum.&lt;/p&gt;
    &lt;p&gt;This is a hands-on role for a builder. Someone who doesn’t want to inherit a playbook, but help write the first version of one.&lt;/p&gt;
    &lt;p&gt;Privacy is one of the most fundamental rights we have.&lt;/p&gt;
    &lt;p&gt;At TrueVault, we believe that when businesses are given practical, well-designed tools, respecting consumer privacy becomes the obvious choice. That belief drives everything we build.&lt;/p&gt;
    &lt;p&gt;We create software that helps brands comply with complex privacy laws without drowning in legal costs or operational overhead. No armies of lawyers. No brittle workflows. Just software that works.&lt;/p&gt;
    &lt;p&gt;TrueVault is a Y Combinator–backed company based in San Francisco. We’re obsessive about product quality, thoughtful about the problems we choose to solve, and relentless about making our customers successful.&lt;/p&gt;
    &lt;p&gt;As Growth Lead, your work will have immediate, visible impact on the company’s trajectory. This is not a role focused on incremental optimization. You will help establish how growth works at TrueVault.&lt;/p&gt;
    &lt;p&gt;The role reports directly to the CEO, ensuring you have the support, context, and access needed to move quickly and decisively. The experiments you run and the signals you uncover will directly influence how we reach customers, how we invest our time, and where the company goes next.&lt;/p&gt;
    &lt;p&gt;If you thrive on identifying what drives growth in early-stage startups, where the product is strong but the growth playbook is still being written, this is the role.&lt;/p&gt;
    &lt;p&gt;We’re looking for someone who thrives on experimentation. Someone who sees growth as a series of questions to answer, signals to uncover, and systems to build.&lt;/p&gt;
    &lt;p&gt;As TrueVault’s first Growth Lead, your initial mission is to identify viable acquisition channels that can reliably and repeatedly drive growth. You’ll explore a wide range of channels including paid, outbound, partnerships, co-marketing, SEO, and more, running structured experiments to determine what truly works.&lt;/p&gt;
    &lt;p&gt;Your early focus will be on Acquisition, but the role expands over time. As viable channels emerge and stabilize, you’ll help shape growth across the broader AAARRR framework, influencing awareness, activation, revenue, retention, and referral.&lt;/p&gt;
    &lt;p&gt;Experimentation is central to this role. Being genuinely data-driven is critical. You'll be expected to form clear hypotheses, measure outcomes rigorously, and let evidence guide decisions.&lt;/p&gt;
    &lt;p&gt;We believe in setting clear, concrete expectations. Success in this role will be measured by outcomes such as:&lt;/p&gt;
    &lt;p&gt;This role starts with hands-on ownership and grows with impact. Initially, you'll focus on discovery and execution: running experiments, identifying viable channels, and building repeatable growth motions. As those motions scale, your scope expands.&lt;/p&gt;
    &lt;p&gt;Strong performance typically leads to broader ownership across the funnel, strategic influence, and eventually leadership of the growth function—including hiring and managing a team. The trajectory depends on the impact you create and where your strengths emerge.&lt;/p&gt;
    &lt;p&gt;This is a fully remote role, but you must be based in the United States.&lt;/p&gt;
    &lt;p&gt;This role is leveled as a Principal Individual Contributor (Pave level: P6/Carta level: L7)&lt;/p&gt;
    &lt;p&gt;Final offers may vary slightly based on experience.&lt;/p&gt;
    &lt;p&gt;To apply, please submit your application through this form. Applications submitted outside of this form will not be reviewed.&lt;/p&gt;
    &lt;p&gt;We take applicant privacy seriously. Please review our Job Applicant Privacy Policy to understand how we collect and process your personal information in accordance with applicable laws, including the CCPA.&lt;/p&gt;
    &lt;p&gt;TrueVault builds software tools that help businesses comply with consumer data privacy laws. We believe if businesses have access to products that make getting and staying compliant simple, straightforward, and fully automated, respecting consumers' data privacy becomes the sensible default. And we all benefit from that.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/truevault/jobs/njvSGDj-growth-lead"/><published>2026-01-23T21:01:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46737957</id><title>Mental Models (2018)</title><updated>2026-01-24T10:42:29.843279+00:00</updated><content>&lt;doc fingerprint="7f42103f8de68718"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;What Are Mental Models?&lt;/head&gt;
    &lt;p&gt;A mental model is a simplified explanation of how something works.&lt;/p&gt;
    &lt;p&gt;Any idea, belief, or concept can be boiled down to its essence. Like a map, mental models highlight key information while ignoring irrelevant details. They’re tools for compressing complexity into manageable chunks.&lt;/p&gt;
    &lt;p&gt;Mental models help us understand the world. For example, velocity shows that both speed and direction matter. Reciprocity reveals how being positive and taking initiative gets the world to do most of the work for you. Margin of Safety reminds us that things don’t always go as planned. Relativity exposes our blind spots and shows how a different perspective can reveal new information. These are just a few examples.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Ideas From The Big Disciplines&lt;/head&gt;
    &lt;p&gt;This page summarizes the big ideas to help you make better decisions, avoid problems, and spot opportunities others miss.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;General Thinking Tools&lt;/item&gt;
      &lt;item&gt;Physics, Chemistry, and Biology&lt;/item&gt;
      &lt;item&gt;Systems&lt;/item&gt;
      &lt;item&gt;Numeracy&lt;/item&gt;
      &lt;item&gt;Microeconomics&lt;/item&gt;
      &lt;item&gt;Military and War&lt;/item&gt;
      &lt;item&gt;Human Nature and Judgment&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;General Thinking Tools&lt;/head&gt;
    &lt;p&gt;The map is not the territory reminds us that our mental models of the world are not the same as the world itself. It cautions against confusing our abstractions and representations with the complex, ever-shifting reality they aim to describe.&lt;/p&gt;
    &lt;p&gt;It is dangerous to mistake the map for the territory. Consider the person with an outstanding résumé who checks all the boxes on paper but can’t do the job.&lt;/p&gt;
    &lt;p&gt;Updating our maps is a difficult process of reconciling what we want to be true with what is true.&lt;/p&gt;
    &lt;p&gt;In many areas of life, we are offered maps by other people. We are reliant on the maps provided by experts, pundits, and teachers. In these cases, the best we can do is to choose our mapmakers wisely and to seek out those who are rigorous, transparent, and open to revision.&lt;/p&gt;
    &lt;p&gt;Ultimately, the map/territory distinction invites us to engage with the world as it is, not just as we imagine it. And remember, when you don’t make the map, choose your cartographer wisely.&lt;/p&gt;
    &lt;p&gt;The first rule of competition is that you are more likely to win if you play where you have an advantage. Playing to your advantage requires a firm understanding of what you know and don’t know.&lt;/p&gt;
    &lt;p&gt;Your circle of competence is your personal sphere of expertise, where your knowledge and skills are concentrated. It’s the domain where you have a deep understanding, where your judgments are reliable, and your decisions are sound.&lt;/p&gt;
    &lt;p&gt;The size of your circle isn’t as important as knowing the boundaries. The wise person knows the limits of their knowledge and can confidently say, “This falls within my circle,” or “This is outside my area of expertise.”&lt;/p&gt;
    &lt;p&gt;While operating within your circle of competence is a recipe for confidence and effectiveness, venturing outside your circle of competence is a recipe for trouble. You’re like a sailor navigating unfamiliar waters without a map, at the mercy of currents and storms you don’t fully understand. This isn’t to say that you should never venture outside your circle. Learning new things, gaining new skills, and mastering new domains is one of the most beautiful things about life.&lt;/p&gt;
    &lt;p&gt;Celebrate your expertise, but also acknowledge your limitations.&lt;/p&gt;
    &lt;p&gt;First principles thinking is the art of breaking down complex problems into their fundamental truths. It’s a way of thinking that goes beyond the surface and allows us to see things from a new perspective.&lt;/p&gt;
    &lt;p&gt;Thinking in first principles allows us to identify the root causes, strip away the layers of complexity, and focus on the most effective solutions. Reasoning from first principles allows us to step outside the way things have always been done and instead see what is possible.&lt;/p&gt;
    &lt;p&gt;First principles thinking is not easy. It requires a willingness to challenge the status quo. This is why it’s often the domain of rebels and disrupters who believe there must be a better way. It’s the thinking of those willing to start from scratch and build from the ground up.&lt;/p&gt;
    &lt;p&gt;In a world focused on incremental improvement, first principles thinking offers a competitive advantage because almost no one does it.&lt;/p&gt;
    &lt;p&gt;Thought experiments are the sandbox of the mind, the place where we can play with ideas without constraints. They’re a way of exploring the implications of our theories, of testing the boundaries of our understanding. They offer a powerful tool for clarifying our thinking, revealing hidden assumptions, and showing us unintended consequences.&lt;/p&gt;
    &lt;p&gt;The power of thought experiments lies in their ability to create a simplified model of reality where we can test our ideas. In the real world, confounding factors and messy details obscure the core principles at work. Thought experiments allow us to strip away the noise and focus on the essence of the problem.&lt;/p&gt;
    &lt;p&gt;Thought experiments remind us that some of the most profound insights and innovations start with a simple question: What if?&lt;/p&gt;
    &lt;p&gt;Second-order thinking is a method of thinking that goes beyond the surface level, beyond the knee-jerk reactions and short-term gains. It asks us to play the long game, to anticipate the ripple effects of our actions, and to make choices that will benefit us not just today but in the months and years to come.&lt;/p&gt;
    &lt;p&gt;Second-order thinking demands we ask: And then what?&lt;/p&gt;
    &lt;p&gt;Think of a chess master contemplating her next move. She doesn’t just consider how the move will affect the next turn but how it will shape the entire game. She’s thinking many steps ahead. She’s considering her own strategy and her opponent’s likely response.&lt;/p&gt;
    &lt;p&gt;In our daily lives, we’re often driven by first-order thinking. We make decisions based on what makes us happy now, what eases our current discomfort, or satisfies our immediate desires.&lt;/p&gt;
    &lt;p&gt;Second-order thinking asks us to consider the long-term implications of our choices to make decisions based not just on what feels good now but on what will lead to the best outcomes over time.&lt;/p&gt;
    &lt;p&gt;In the end, second-order thinking is about playing the long game. It’s about making choices for the next move and the entire journey.&lt;/p&gt;
    &lt;p&gt;Probabilistic thinking is the art of navigating uncertainty. Successfully thinking in shades of probability means roughly identifying what matters, calculating the odds, checking our assumptions, and then deciding.&lt;/p&gt;
    &lt;p&gt;The challenge of probabilistic thinking is that it requires constant updating. As new information emerges, the probabilities change. What seemed likely yesterday may seem unlikely today. This explains why probabilistic thinkers always revise their beliefs with new data and why it’s uncomfortable for many people.&lt;/p&gt;
    &lt;p&gt;It’s much easier to believe something false is accurate than to deal with the fact that we might be wrong. Being a probabilistic thinker means being willing to say, “I don’t know for sure, but based on the evidence, I think there’s a 63 percent chance of X.” The rewards of probabilistic thinking are immense.&lt;/p&gt;
    &lt;p&gt;By embracing uncertainty, we can make better decisions, avoid the pitfalls of overconfidence, and navigate complex situations with greater skill and flexibility. We can be more open- minded, more receptive to new ideas, and more resilient in the face of change.&lt;/p&gt;
    &lt;p&gt;Much of success comes from simply avoiding common paths to failure.&lt;/p&gt;
    &lt;p&gt;Inversion is not the way we are taught to think. We are taught to identify what we want and explore things that will move us closer to our objective. However, avoiding things that ensure we don’t get what we want dramatically increases our odds of success.&lt;/p&gt;
    &lt;p&gt;We can get fixated on solving problems one way, missing simpler solutions. Inversion breaks us out of this tunnel vision.&lt;/p&gt;
    &lt;p&gt;Instead of “How do I solve this?”, inversion asks, “What would guarantee failure?” Rather than “How can I achieve this?”, it asks “What’s preventing me from achieving it?” This flip reveals insights our usual thinking overlooks.&lt;/p&gt;
    &lt;p&gt;When facing a tricky problem or ambitious goal, try inverting. Ask how you’d guarantee failure. The answers may surprise you—and unlock new solutions.&lt;/p&gt;
    &lt;p&gt;Occam’s razor is the intellectual equivalent of “keep it simple.”&lt;/p&gt;
    &lt;p&gt;When faced with competing explanations or solutions, Occam’s razor suggests that the correct explanation is most likely the simplest one, the one that makes the fewest assumptions. This doesn’t mean the simplest theory is always true, only that it should be preferred until proven otherwise. Sometimes, the truth is complex, and the simplest explanation doesn’t account for all the facts. The key to wielding this model is understanding when it works for you and against you.&lt;/p&gt;
    &lt;p&gt;A theory that is too simple fails to capture reality, and one that is too complex collapses under its own weight.&lt;/p&gt;
    &lt;p&gt;Hanlon’s razor is a mental safeguard against the temptation to label behavior as malicious when incompetence is the most common response. It’s a reminder that people are not out to get you, and it’s best to assume good faith and resist the urge to assign sinister motives without overwhelming evidence.&lt;/p&gt;
    &lt;p&gt;This isn’t to say that genuine malice doesn’t exist. Of course, it does. But in most interactions, stupidity is a far more common explanation than malevolence. People make mistakes. They forget things. They speak without thinking. They prioritize short-term wins over long-term wins. They act on incomplete information. They fall prey to bias and prejudice. These actions might appear like deliberate attacks from the outside, but the reality is far more mundane.&lt;/p&gt;
    &lt;p&gt;Hanlon’s razor’s real power lies in how it shifts our perspective. When we assume stupidity rather than malice, we respond differently. Instead of getting defensive or lashing out, we approach the situation with empathy and clarity.&lt;/p&gt;
    &lt;p&gt;For most daily frustrations and confusion, Hanlon’s razor is a powerful reminder to approach problems with a spirit of generosity. It’s a way to reduce drama and stress and find practical solutions instead of descending into blame and escalation.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Mental Models of Physics, Chemistry, and Biology&lt;/head&gt;
    &lt;p&gt;Relativity is the idea that our perceptions and judgments are not absolute but are shaped by our unique vantage points and frames of reference. It’s the understanding that our experiences are subjective.&lt;/p&gt;
    &lt;p&gt;We each inhabit a particular web of experiences. This context shapes how we see the world, what we notice and overlook, and what we value and dismiss. Two people can look at the same event and come away with vastly different interpretations based on their unique frames of reference.&lt;/p&gt;
    &lt;p&gt;Consider two people standing in the same room: They each experience the same absolute temperature differently. One can feel hot while the other feels cold, even though the temperature is the same. Similarly, consider political debates: Our beliefs are shaped by our unique experiences and social contexts. A policy that seems like common sense to an urban progressive might feel like complete nonsense to a rural conservative, and vice versa. In this way, understanding relativity is key to fostering empathy and finding common ground. However, relativity is not the same as relativism— the idea that all perspectives are equally valid.&lt;/p&gt;
    &lt;p&gt;Recognizing the relativity of our perceptions doesn’t mean we don’t have to make judgments about validity. Instead, it’s a call to examine our assumptions, seek out diverse perspectives, and expand our frames of reference. We all have blind spots—things we cannot see. Understanding that our perceptions are relative allows us to open ourselves to other ways of seeing. If you’re wondering where to get started, try asking others what they see that you can’t. Apply your judgment to their responses and update your beliefs accordingly.&lt;/p&gt;
    &lt;p&gt;Reciprocity underlies everything from basic human kindness to the most complex systems of trade. At its core, reciprocity is the simple idea of treating others as they treat us—giving what we get. But from this simple principle grows a vast web of social interactions and expectations that shapes nearly every aspect of our lives.&lt;/p&gt;
    &lt;p&gt;Many people expect the world to just hand them things without effort. This is a poor strategy because it doesn’t align with the human behavior you can observe around you every day. Reciprocation teaches us that you are likely to receive the same if you give people cynicism and curtness or nothing at all. But if you give people an opportunity and the benefit of the doubt, you will, more often than not, be on the receiving end of the same behavior.&lt;/p&gt;
    &lt;p&gt;Become what you want to see in the world, and the world will return it to you. If you want an amazing relationship with your partner, be an amazing partner. If you want people to be thoughtful and kind to you, be thoughtful and kind to them. If you want people to listen to you, listen to them.&lt;/p&gt;
    &lt;p&gt;The best way to achieve success is to deserve success. Small changes in your actions change your entire world.&lt;/p&gt;
    &lt;p&gt;One of the biggest misperceptions about reciprocity is that people should sit around waiting for others to go first rather than unlocking the power of reciprocity in their favor by going positive and going first without expectation.&lt;/p&gt;
    &lt;p&gt;Reciprocity reminds us that our actions tend to come back on us. It’s an essential reminder that we are part of the world, and thus, our actions do not happen in isolation but are instead part of an interconnected web of effects.&lt;/p&gt;
    &lt;p&gt;Thermodynamics&lt;/p&gt;
    &lt;p&gt;Thermodynamics is the science of energy, heat, and work. It’s the set of physical laws that govern how energy moves and changes in the universe. Chances are, when you first came across the subject, it was dry, full of equations and abstract concepts. But the truth is thermodynamics is a useful intellectual framework for daily life. Not only can it reveal why your room gets messier over time, but it also explains why you should choose your friends wisely.&lt;/p&gt;
    &lt;p&gt;The first law of thermodynamics states that energy can neither be created nor destroyed, only transformed from one form to another. This means that every joule of energy in the universe, every bit of heat and work and motion is part of an unbroken chain stretching back to the Big Bang.&lt;/p&gt;
    &lt;p&gt;When you hop on a flight that burns jet fuel, you’re tapping into energy captured by plants millions of years ago and stored in chemical bonds until it was transformed into heat and motion.&lt;/p&gt;
    &lt;p&gt;But while energy is conserved, it’s not always useful. That’s where the second law of thermodynamics comes in. It states that entropy— a measure of disorder— increases over time in any closed system. In other words, left on its own, the universe tends toward chaos. Your bedroom doesn’t clean itself— it takes energy and effort to maintain order. Stars burn out, structures crumble, and ice melts into water.&lt;/p&gt;
    &lt;p&gt;Entropy is the universe’s tax on time. The constant battle against entropy is the driving force behind much of what we do. The constant struggle between order and disorder is the source of change and progress.&lt;/p&gt;
    &lt;p&gt;While engineers and scientists use thermodynamics to design engines or calculate the energy requirements of a system, we can use it as a framework for understanding the deep interconnectedness of everything. When you feel the sun’s warmth on your skin, you’re experiencing the result of a thermodynamic process that began in the heart of a star ninety-three million miles away. When you watch a campfire burn down to embers, you’re witnessing the inexorable march of entropy in real-time.&lt;/p&gt;
    &lt;p&gt;Thermodynamics is the story of energy across time. We’re part of an energy story that stretches back to the dawn of time and reaches the farthest pockets of space. We can marvel that in a universe ruled by disorder, pockets of temporary order can emerge, whether it’s a clean room, a planet, or a civilization.&lt;/p&gt;
    &lt;p&gt;By understanding thermodynamics, we gain not just a technical toolbox but an appreciation for the beauty, complexity, and fragility of our very existence.&lt;/p&gt;
    &lt;p&gt;Inertia&lt;/p&gt;
    &lt;p&gt;Inertia is the stubborn resistance of the universe to change. It’s why objects at rest tend to stay at rest, and objects in motion tend to stay in motion. You can think of inertia as the guardian of the status quo.&lt;/p&gt;
    &lt;p&gt;At its core, inertia is a property of mass. The more massive an object is, the more it resists changes to its state of motion. A feather, with its tiny mass, is easily blown about by the slightest breeze. A boulder, on the other hand, requires a powerful force to get it moving. This is why it takes more effort to push a heavy cart than a light one, more energy to launch a rocket than to toss a ball.&lt;/p&gt;
    &lt;p&gt;But inertia isn’t just a physical phenomenon. It’s an illuminating lens to see habits, beliefs, and our resistance to change. The longer we’ve held them, the larger the mass and the more force required to change them. The path of least resistance is always the status quo.&lt;/p&gt;
    &lt;p&gt;Getting started is the hardest part. Once something moves in a direction, keeping it in motion is much easier. But once something is in motion, it’s hard to stop. This is why most self-help books about positive habits break things down into very small steps—to reduce the force required to overcome the status quo. For example, if you want to get in the habit of doing push-ups daily, start with one rather than fifty. If you want to start a flossing habit, start with one tooth. After all, the bigger the mass—in this case, the gap between where you are and where you want to be— the more effort required.&lt;/p&gt;
    &lt;p&gt;Inertia is both a challenge and an opportunity. Successful companies struggle with the inertia of their success and the resistance to change that comes with size, complexity, and entrenched interests. On the other hand, startups can leverage their lack of inertia—their agility, their willingness to pivot and adapt—as a competitive advantage.&lt;/p&gt;
    &lt;p&gt;Momentum and inertia are closely related. While inertia is the tendency to resist change, momentum is the oomph an object has when it’s moving. The more momentum something has, the harder it is to stop or redirect. The key is to pick the right direction and build momentum so inertia works to your advantage and carries you forward. This is the essence of the “flywheel” concept in business—success breeds success, and small wins compound into big gains.&lt;/p&gt;
    &lt;p&gt;When you’re fighting the status quo, remember the physics at play. Resistance is natural. Understand that building momentum in a new direction takes a sustained force. While the universe resists change, it always rewards those who dare to overcome that resistance.&lt;/p&gt;
    &lt;p&gt;Friction and Viscosity&lt;/p&gt;
    &lt;p&gt;Friction and viscosity are the sand in the gears of the universe, the invisible hands that slow the motion of all things.&lt;/p&gt;
    &lt;p&gt;Friction is the grip between surfaces in contact, the roughness that resists sliding. Viscosity is the thickness of fluids, the internal friction that makes liquids sluggish and syrupy. Together, they are the great moderators of motion.&lt;/p&gt;
    &lt;p&gt;Think of the last time you tried to slide a heavy piece of furniture across the floor. The resistance you felt, the effort required to overcome the grip of the surface— that was friction at work. Or consider the slow, thick pour of honey from a jar, the way it clings and drips in slow threads. That’s the viscosity of the fluid resisting the force of gravity, the internal friction that makes the honey flow like molasses rather than water.&lt;/p&gt;
    &lt;p&gt;While friction is the enemy of efficiency, it’s also necessary for traction. We couldn’t walk, hold tools, or tie knots without it. Viscosity, too, is a double-edged sword. In pipelines and hydraulic systems, high viscosity means higher pumping costs, slower flows, and greater strain on equipment. But viscosity also makes oil a good lubricant, allowing paints and coatings to spread evenly and adhere to surfaces.&lt;/p&gt;
    &lt;p&gt;Friction and viscosity are powerful metaphors for the forces of resistance in every domain of life. In human relationships, friction is the conflict and tension that arises from differing goals, personalities, or beliefs. The interpersonal roughness can generate heat and wear, but also the traction that allows us to influence and connect with others.&lt;/p&gt;
    &lt;p&gt;While often hidden, friction and viscosity work against us whenever we try to do something. We often default to using more force to overcome resistance when simply reducing the friction or viscosity will do. However, doing both is more effective than either in isolation.&lt;/p&gt;
    &lt;p&gt;Friction and viscosity can also be wielded as weapons. Rather than try to catch up to the competition with more effort, you might want to explore slowing them down by adding resistance through increased regulation, bureaucracy, or other clever ideas. In the end, reducing resistance is often easier than adding force.&lt;/p&gt;
    &lt;p&gt;Velocity is the great differentiator, distinguishing the stagnant from the swift.&lt;/p&gt;
    &lt;p&gt;In physics, velocity is a fundamental quantity, a key variable in the equations that describe the behavior of everything from subatomic particles to galaxies. It’s the v in the formulas of motion, the arrow that points the way from here to there.&lt;/p&gt;
    &lt;p&gt;Velocity is also a metaphor for life. Consider it the rate at which we learn and grow, the speed at which we innovate and create, and the focus with which we pursue our goals.&lt;/p&gt;
    &lt;p&gt;Velocity challenges us to think about what we can do to put ourselves on the right trajectory and to find a balance between mass and speed to move toward our goals. The ability to set a direction, improve your tactics, and adjust to new information becomes paramount.&lt;/p&gt;
    &lt;p&gt;Velocity isn’t just about raw speed. Direction matters just as much (if not more). A car moving at high speed in circles goes nowhere, while a slow and steady walk in a straight line can cross continents.&lt;/p&gt;
    &lt;p&gt;Velocity is progress. Sometimes, progress comes from more force, and sometimes, progress comes from removing friction. Once you have a destination, you can improve your velocity by working harder and eliminating things that aren’t contributing toward reaching that goal.&lt;/p&gt;
    &lt;p&gt;Leverage is the force multiplier of the world, the principle that allows the small to move the large and the few to influence the many. It’s the idea that a little force, strategically applied, can yield outsize outputs.&lt;/p&gt;
    &lt;p&gt;At its core, leverage is amplification. Think of a crowbar prying two boards apart or a pulley system hoisting a heavy load. In each case, the appled force is multiplied. But leverage isn’t just useful in physics. Rather, it’s a principle that applies across our lives.&lt;/p&gt;
    &lt;p&gt;Leverage is often lurking in the background of nonlinear outcomes. Consider the author who took the ideas in their head, put them in a book, and sold millions of copies, or the Wall Street investor who made a single decision that resulted in billions. Or even the CEO who directs the people working for them. All of these examples are leverage in action.&lt;/p&gt;
    &lt;p&gt;In personal development, leverage is about identifying the key habits, skills, and relationships that will impact your life and work most. It’s about focusing your energy on the critical few rather than the trivial many, about finding the points of maximum leverage where small changes can cascade into massive results.&lt;/p&gt;
    &lt;p&gt;An example of personal leverage is an employee who learns to use AI to amplify their impact on the organization far beyond their experience or effort. While labor is still a form of leverage, it can often be done with silicon chips. In this sense, the person who can leverage technology can compete in a way never imaginable.&lt;/p&gt;
    &lt;p&gt;However, leverage is not without its risks and responsibilities. Just as a small action can have an outsized positive impact, so can it have negative consequences. If you borrow too much money against your house and it turns out to be less valuable than assumed or interest rates change, the downside of leverage can quickly wipe you out.&lt;/p&gt;
    &lt;p&gt;Good ideas taken too far often cause unanticipated consequences. Wielding leverage to maximum effect all the time, as the West Virginia mine owners did, sows the seeds of ongoing unrest that undermines one’s ability to be truly effective. No one wants to feel exploited, and those who are never give their loyalty or their best work.&lt;/p&gt;
    &lt;p&gt;The key is to use leverage wisely and judiciously by understanding the systems you want to influence and considering the second- and third- order effects of your actions.&lt;/p&gt;
    &lt;p&gt;Leverage is a tool, not a toy, and like any tool, it requires skill, judgment, and respect.&lt;/p&gt;
    &lt;p&gt;Activation energy is the spark that ignites the fire of change, the initial burst of effort required to kick- start a reaction or transformation. It’s the metaphorical push that gets the boulder rolling down the hill, the investment of energy needed to overcome inertia and set a process in motion.&lt;/p&gt;
    &lt;p&gt;In chemistry, activation energy is the minimum energy that must be input for a reaction. It’s the hurdle molecules must overcome to break their bonds and form new ones, the energetic barrier separating the reactants from the products.&lt;/p&gt;
    &lt;p&gt;But activation energy isn’t just a chemical concept. It’s a principle that applies to any system where change is possible but not automatic. In personal growth, activation energy is the effort required to break old habits and form new ones. In innovation, it’s the investment needed to turn an idea into reality.&lt;/p&gt;
    &lt;p&gt;The key is recognizing activation energy for what it is: a necessary upfront cost, not a permanent obstacle. Once things are moving, momentum takes over. Once the reaction starts, it becomes self- sustaining.&lt;/p&gt;
    &lt;p&gt;Catalysts&lt;/p&gt;
    &lt;p&gt;Catalysts are the unsung heroes of chemical reactions, the silent partners accelerating change. By decreasing the time required to cause change, they also make reactions possible that might not have occurred otherwise.&lt;/p&gt;
    &lt;p&gt;In chemistry, a catalyst is a substance that increases the reaction rate without permanently altering itself. But catalysts aren’t just chemical curiosities, they’re a powerful metaphor for the forces that drive change and growth.&lt;/p&gt;
    &lt;p&gt;In business, a catalyst might be a new technology that opens fresh possibilities or a visionary leader who inspires a team to new heights. In your personal life, a catalyst could be a life-changing book, a transformative experience, or a mentor who sees your potential and helps you realize it.&lt;/p&gt;
    &lt;p&gt;Of course, while we benefit from others acting as our catalysts, we can be catalysts ourselves—helping others find the activation energy they need to thrive.&lt;/p&gt;
    &lt;p&gt;Alloying&lt;/p&gt;
    &lt;p&gt;Alloying is the art of mixing elements to create something greater than the sum of its parts. While our intuition tells us that pure substances are best, alloying shows this is not always true. One plus one can equal ten. By blending ingredients in precise proportions, metallurgists can create materials with bespoke properties—the lightness of aluminum with the strength of steel, the corrosion resistance of chromium with the affordability of iron.&lt;/p&gt;
    &lt;p&gt;But alloying isn’t just about physical properties. It’s a metaphor for the power of diversity and combination in all walks of life. In teams, alloying is the mixing of different skills, perspectives, and personalities to create a more creative, adaptable, and resilient group than any individual could be alone. In ideas, it’s the blending of concepts from different fields to spark innovation and insight.&lt;/p&gt;
    &lt;p&gt;In people, alloying is the combination of skills that makes them unstoppable. Consider a person possessing deep engineering skills who can clearly explain ideas. They are more valuable than someone with just the engineering skills. Now add empathy, humility, resilience, and drive. This person becomes incredibly rare.&lt;/p&gt;
    &lt;p&gt;The key to successful alloying is knowing which elements to combine and in what proportions. Too little of one ingredient and you don’t get the desired effect; too much and you might end up with something brittle or unstable. The art lies in finding the sweet spot, the golden ratio where the whole becomes more than the sum of its parts.&lt;/p&gt;
    &lt;p&gt;Evolution Part One: Natural Selection and Extinction&lt;/p&gt;
    &lt;p&gt;Natural selection is the hidden hand that selects the fittest from a never-ending pile of genetic variation, while extinction is the hammer that shatters the unfit and clears the way for variations to arise.&lt;/p&gt;
    &lt;p&gt;In biology, natural selection is the process by which traits that enhance survival and reproduction become more common in successive generations of a population. The invisible hand of natural selection guides the adaptations of the living world, favoring creatures that are best suited to their environments and pruning back those that fall short.&lt;/p&gt;
    &lt;p&gt;But for every winner in the great game of natural selection, there are countless losers. Extinction is the fate awaiting those species that fail to adapt, that find themselves outpaced by changing circumstances or outcompeted by more successful forms. The evolutionary end. Without the possibility of extinction, there would be no imperative to evolve to our changing environment. And without the sculpting hand of natural selection, the unfit and ill- adapted would consume scarce resources. These principles apply far beyond the realm of biology.&lt;/p&gt;
    &lt;p&gt;In business, technology, and ideas, we see the same relentless winnowing of the unfit and the elevation of the adaptive. The companies that thrive navigate the shifting landscape of consumer demand and technological change, while those that stagnate are swept away by the tides of creative destruction.&lt;/p&gt;
    &lt;p&gt;On a personal level, we are all subject to the pressures of selection and the risk of extinction. Our skills, our knowledge, and our ways of thinking must constantly evolve to keep pace with an ever-changing world. Those who consistently adapt are the ones who thrive in the long run.&lt;/p&gt;
    &lt;p&gt;Above all, remember that there are no permanent victories in the great game of life— only the ceaseless striving to stay one step ahead.&lt;/p&gt;
    &lt;p&gt;Evolution Part Two: Adaptation and The Red Queen Effect&lt;/p&gt;
    &lt;p&gt;Complacency will kill you. There’s no such thing as a permanent lead. No matter how well a species adapts to its environment, it must keep running just to stay in place.&lt;/p&gt;
    &lt;p&gt;The Red Queen effect results from the never-ending arms race between predator and prey, parasite and host, and competitor and competitor. As one species evolves a new adaptation, others evolve countermeasures, leading to a constant escalation. The faster you adapt, the faster your rivals must respond, and vice versa. This has profound implications for the pace of evolution.&lt;/p&gt;
    &lt;p&gt;In a static environment, natural selection might favor a leisurely pace of change. But in a world of constant change, where your competitors are always nipping at your heels, the premium is on speed. The species that thrive adapt quickly and turn the evolutionary crank faster than their rivals. But the Red Queen effect isn’t just about biological evolution. The same principle applies in any competitive domain— business, technology, or even ideas.&lt;/p&gt;
    &lt;p&gt;Companies must continually innovate to stay ahead of their rivals. Technologies must evolve at a breakneck pace to avoid obsolescence. Ideas must adapt and grow to maintain their relevance.&lt;/p&gt;
    &lt;p&gt;The key is recognizing that adaptation isn’t a one-time event but a continuous process. It’s not about reaching a finish line but maintaining a lead in an endless race. Those who rest on their laurels, who become complacent in their success, are quickly overtaken by hungrier, more agile competitors. But there is a catch when it comes to people.&lt;/p&gt;
    &lt;p&gt;Once we gain an advantage, we want to hold on to it at all costs, and if we’re not careful, this can slow the pace of adaptation. Before long, our competitors catch up or find innovative ways to neutralize our strength. Sustained success comes from being flexible enough to change, letting go of what worked in the past, and focusing on what you need to thrive in the future.&lt;/p&gt;
    &lt;p&gt;Standing still is the quickest path to extinction in a world of constant change. Victory goes to those who can continuously adapt.&lt;/p&gt;
    &lt;p&gt;Ecosystems&lt;/p&gt;
    &lt;p&gt;Nothing exists in isolation. Everything is connected. The ecosystem lens reveals that each species plays its part in a delicate balance of competition and cooperation. The actions of any one species can have consequences for many others in the same environment.&lt;/p&gt;
    &lt;p&gt;In biology, an ecosystem is a community of living organisms interacting with each other and their physical environment. In an ecosystem, nothing exists in isolation—every creature is both predator and prey, both producer and consumer, locked in an intricate dance of energy and nutrients.&lt;/p&gt;
    &lt;p&gt;Yet the concept of an ecosystem extends far beyond biology. You can see it nearly everywhere you look. Businesses operate within a complex network of companies, customers, competitors, suppliers, and regulators. Each entity relies on and influences the others, creating a dynamic interplay that determines which businesses thrive and which do not. Economies are also vast ecosystems comprising various sectors (like agriculture, manufacturing, and services) and actors (like workers, consumers, and governments). These components interact under the rules set by economic policies and market forces. Economic theories often explore how changes in one part of the ecosystem can lead to significant outcomes in another, much like the ripple effects seen in biological ecosystems.&lt;/p&gt;
    &lt;p&gt;What all ecosystems have in common is their inherent complexity and their reductionist analysis. In an ecosystem, the whole is always more than the sum of its parts. The system’s behavior emerges from the countless interactions of its components, often in surprising and unpredictable ways. This suggests that to truly comprehend a complex system, we must look beyond the individual elements and consider the patterns of relationship and feedback that bind them together.&lt;/p&gt;
    &lt;p&gt;Left to their own devices, many systems can take care of themselves, possessing abilities to correct and compensate for changes and external pressures. No matter how well-intentioned our interventions are, they often lead to unintended consequences as the solution to one problem quickly causes another, more significant problem.&lt;/p&gt;
    &lt;p&gt;Be slow to intervene, and if you do, take the time to understand how actions in one part cascade into others. It pays to remember the motto of physicians, “First, do no harm.”&lt;/p&gt;
    &lt;p&gt;Niches&lt;/p&gt;
    &lt;p&gt;A niche is a special place where a particular species or idea can thrive. It’s the ecological equivalent of a custom-fitted suit tailored to its occupant’s unique needs and abilities. In a niche, you don’t have to be all things to all people— you just have to be the best at what you do.&lt;/p&gt;
    &lt;p&gt;In biology, a niche is a species’ specific role and position within its ecosystem. It’s the unique combination of resources it consumes, the habitat it lives in, the interactions it has with other species. A place where a species’ adaptations flourish.&lt;/p&gt;
    &lt;p&gt;But the concept of a niche extends far beyond the realm of ecology. In business, we talk about “market niches”— the specific segments of customers with particular needs or preferences. A company focusing on a niche can often out-compete larger, more general rivals by specializing, by becoming the best at serving that particular slice of the market, or by moving with velocity.&lt;/p&gt;
    &lt;p&gt;The same principle applies to careers. By specializing in something unique and valuable, you can create a space where you can excel and your combination of skills thrives. The key is finding the niche that fits you, rewards your strengths, and neutralizes your weaknesses.&lt;/p&gt;
    &lt;p&gt;This isn’t to say that occupying a niche is without risks. In fact, you become very fragile. If the environment changes, if consumer preferences shift, a once-cozy niche can quickly become a tight squeeze. That’s why successful niche occupants are often those who can adapt and evolve their niche as the world around them changes.&lt;/p&gt;
    &lt;p&gt;Specialists have less competition and stress, but only in times of stability. Generalists face more significant day‑to‑day challenges for resources and survival but have more flexibility to respond when times change.&lt;/p&gt;
    &lt;p&gt;Self-Preservation&lt;/p&gt;
    &lt;p&gt;Self- preservation is a core instinct that drives all living things to protect and sustain their own existence. It’s the biological imperative that makes a gazelle run from the lion, the roots of a tree seek water, and bacteria evolve resistance to antibiotics. In the game of life, self- preservation is the only rule: stay alive.&lt;/p&gt;
    &lt;p&gt;For humans, self- preservation goes beyond physical survival. It encompasses the protection of our psychological well-being, social status, and sense of identity. Anything that threatens how we see ourselves becomes a threat.&lt;/p&gt;
    &lt;p&gt;While self- preservation is a necessary instinct, it can also be limiting. When we’re too focused on avoiding threats, we can easily miss opportunities right before us. Left unchecked, self-preservation can lead to stagnation. The key is to find balance: to protect what’s essential and be willing to let go of what no longer serves us.&lt;/p&gt;
    &lt;p&gt;Listen to the voice that tells you when to be cautious, but don’t let it be the only voice you hear. Often, the most significant risk is not taking risks at all.&lt;/p&gt;
    &lt;p&gt;Replication&lt;/p&gt;
    &lt;p&gt;Replication is the molecular magic trick that allows organisms to make copies of themselves to pass their genetic blueprints from one generation to the next. In the grand ballet of evolution, replication is the music that keeps the dance going.&lt;/p&gt;
    &lt;p&gt;At its core, replication is about information transfer. It’s the process by which the instructions encoded in DNA are faithfully copied and transmitted. Whenever a cell divides or an organism reproduces, the replication machinery swings into action, ensuring the genetic message is preserved and propagated. However, replication is not a perfect process. Errors creep in, and mutations occur. And it’s these imperfections that fuel the engine of evolution. Without the variation introduced by replication errors, life would stagnate, unable to adapt to changing environments.&lt;/p&gt;
    &lt;p&gt;Replication is helpful outside of biology, too. As a mental model, it teaches us that we don’t always need to reinvent the wheel. When you’re just starting, the quickest way to make great leaps is to imitate what others are already doing. This establishes an average baseline of performance. Once you get a sense and a feel for the environment, you can innovate and adapt to set a new baseline.&lt;/p&gt;
    &lt;p&gt;The power of replication lies in its exponential nature. A single replicated entity can give rise to countless copies, each of which can replicate further. This is the power that viruses and viral ideas harness— the ability to spread explosively by exploiting the machinery of replication. Memes, beliefs, and practices also replicate, spreading from mind to mind and shaping the contours of our shared reality.&lt;/p&gt;
    &lt;p&gt;But replication also comes with risks. Unchecked replication can be cancerous, leading to uncontrolled growth that threatens the health of the larger system.&lt;/p&gt;
    &lt;p&gt;Effective replication requires enough structure and space to produce a copy and enough flexibility to adapt to environmental changes. Just because something has worked for a while doesn’t mean it will be effective in perpetuity. Maintaining a successful approach requires the ability to grow and modify that approach as required.&lt;/p&gt;
    &lt;p&gt;As we contemplate replication’s role in life and thought, we must recognize its creative and destructive potential. We must create conditions that favor replicating what is true, sound, and beneficial while resisting the spread of what is false, harmful, or malignant.&lt;/p&gt;
    &lt;p&gt;Cooperation&lt;/p&gt;
    &lt;p&gt;Cooperation is the surprising secret of success in the ruthless world of survival. If there is any one model that explains humanity, then this is it. Cooperation unleashed the potential of the human species.&lt;/p&gt;
    &lt;p&gt;At first glance, cooperation seems to defy the logic of natural selection. Why would an organism invest its hard- earned resources in helping another rather than focusing solely on its own survival and reproduction? The answer lies in the magic of reciprocity and shared interest. When organisms can benefit more by cooperating than by competing, cooperative strategies emerge and flourish. Collaboration with others gives us options and opportunities that are unavailable when we insist on going it alone.&lt;/p&gt;
    &lt;p&gt;But cooperation is not automatic. It requires specific conditions—repeated interactions, shared benefits, and mechanisms to prevent cheating.&lt;/p&gt;
    &lt;p&gt;Cooperation is the foundation of civilization. Our species’ success is built on our ability to cooperate flexibly and at scale— to share knowledge, coordinate efforts, and create institutions that incentivize cooperative behavior. Cooperation underlies our achievements, from the division of labor in the economy to the norms of reciprocity in society. But, as in nature, human cooperation is not guaranteed. It requires constant cultivation and protection from the forces of selfishness and short- term thinking. It requires norms that reward cooperation and punish defection.&lt;/p&gt;
    &lt;p&gt;Hierarchical Organization&lt;/p&gt;
    &lt;p&gt;Hierarchy is the invisible scaffolding that organizes the living world.&lt;/p&gt;
    &lt;p&gt;Hierarchies in biology aren’t just about structure but about function. They allow for specialization and division of labor, for the emergence of complex behaviors from simple rules. In the hierarchy of an ant colony, the queen, workers, and soldiers all play their roles, their interactions giving rise to the sophisticated operation of the colony as a whole.&lt;/p&gt;
    &lt;p&gt;But hierarchy isn’t rigid or fixed. It’s fluid and dynamic, with levels constantly interacting and influencing one another. A change at one level can ripple across the entire hierarchy, transforming the system unexpectedly.&lt;/p&gt;
    &lt;p&gt;While hierarchy is a way to manage complexity, it can also backfire. Too much hierarchy leads to unrest and instability. Too little leads to chaos.&lt;/p&gt;
    &lt;p&gt;Most organizations promote cultures that emphasize rather than de‑emphasize an individual’s status, power, and place, which is part of the reason they get torn apart, as the fight to get to the top of the hierarchy takes precedence over the organization’s success.&lt;/p&gt;
    &lt;p&gt;In the end, hierarchy is the organizing principle that allows scale from the microscopic to the magnificent.&lt;/p&gt;
    &lt;p&gt;Incentives are the hidden engines that drive behavior. They’re the unseen forces that shape our choices, the carrots and sticks that guide our actions.&lt;/p&gt;
    &lt;p&gt;Think of a business offering a bonus for hitting a sales target. The bonus is an incentive, the external reward that motivates the salesperson to excel. But incentives aren’t always so obvious. They can be subtle, even subconscious— the social approval we seek, the habits we form, the desires we pursue.&lt;/p&gt;
    &lt;p&gt;Incentives are powerful because they tap into the fundamental wiring of the human brain. We’re hardwired to seek reward and avoid punishment, to optimize for the outcomes that serve our interests. When the incentives align with our goals, we thrive. When they don’t, we struggle.&lt;/p&gt;
    &lt;p&gt;In a classroom, it’s easy to say that we’ll be motivated by doing the right thing; however, in reality, we’re driven mainly by rewards. We have difficulty turning down the pleasure of immediate gains, even if it takes us away from our ultimate goal.&lt;/p&gt;
    &lt;p&gt;Often, short-term and long-term incentives differ. You might not feel like going to the gym today but want to be healthy as you age. Making choices to maximize your satisfaction today often leads to less reward down the road.&lt;/p&gt;
    &lt;p&gt;Poorly designed incentives backfire, encouraging short- term thinking, unethical behavior, or unintended consequences. The key is to craft incentives that reward the behaviors that lead to long- term success.&lt;/p&gt;
    &lt;p&gt;Ultimately, if you understand the incentive, you can predict the outcome. By shaping the incentives, we shape the outcomes. By aligning the incentives, we unlock the power of human potential.&lt;/p&gt;
    &lt;p&gt;Tendency to Minimize Energy Output (Mental and physical)&lt;/p&gt;
    &lt;p&gt;The tendency to limit energy output is the universal inclination to follow the path of least resistance. From the flow of a river to the behavior of a market, this tendency is the invisible hand that guides the actions of the world.&lt;/p&gt;
    &lt;p&gt;Sometimes, our tendency to conserve energy helps us, and sometimes, it hurts us. While minimizing our output ensures we will have extra to draw on in times of increased need, it can also get in the way of learning. Experience doesn’t become learning without reflection, which is an energy expenditure.&lt;/p&gt;
    &lt;p&gt;If we want to develop our thinking and get the most out of our environments, then we have to be aware of the natural tendency to minimize energy output and correct for it where doing so creates value.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Mental Models of Systems Thinking&lt;/head&gt;
    &lt;p&gt;Feedback loops are the engines of growth and change. They’re the mechanisms by which the output of a system influences its input.&lt;/p&gt;
    &lt;p&gt;Complex systems often have many feedback loops, and it can be hard to appreciate how adjusting to feedback in one part of the system will affect the rest.&lt;/p&gt;
    &lt;p&gt;Using feedback loops as a mental model begins with noticing the feedback you give and respond to daily. The model also provides insight into the value of iterations in adjusting based on the feedback you receive. With this lens, you gain insight into where to direct system changes based on feedback and the pace you need to go to monitor the impacts.&lt;/p&gt;
    &lt;p&gt;Feedback loops are what make systems dynamic. Without feedback, a system does the same thing over and over. Understand them, respect them, and use them wisely.&lt;/p&gt;
    &lt;p&gt;Equilibrium&lt;/p&gt;
    &lt;p&gt;Equilibrium is the state of balance, where opposing forces cancel each other out. It’s the calm in the storm’s center, the stable point around which the chaos swirls. In a system at equilibrium, there’s no net change. Everything is in a steady state, humming along at a constant pace.&lt;/p&gt;
    &lt;p&gt;However, systems are rarely static. They continuously adjust toward equilibrium but rarely stay in balance for long.&lt;/p&gt;
    &lt;p&gt;Equilibrium is a double-edged sword, both stability and stagnation. In our lives, we often act like we can reach an equilibrium: once we get into a relationship, we’ll be happy; once we move, we’ll be productive; once X thing happens, we’ll be in Y state. But things are always in flux. We don’t reach a certain steady state and then stay there forever. The endless adjustments are our lives. The trick is to find the right balance, strive for equilibrium where it’s needed, and know when to break free and embrace the dis-equilibrium that drives progress.&lt;/p&gt;
    &lt;p&gt;Bottlenecks&lt;/p&gt;
    &lt;p&gt;Bottlenecks are the choke points, the narrow parts of the hourglass where everything slows down. They’re the constraints that limit the flow, the weakest links in the chain that determine the strength of the whole. In any system, the bottleneck is the part holding everything else back.&lt;/p&gt;
    &lt;p&gt;The tricky thing about bottlenecks is that they’re not always obvious. It’s easy to focus on the parts of the system that are moving quickly and assume everything is fine. But the real leverage is in finding and fixing the bottlenecks. Speed up the slowest part, and you speed up the whole system.&lt;/p&gt;
    &lt;p&gt;This is the theory of constraints in a nutshell. Figure out your bottleneck and focus all your efforts on alleviating it. Don’t waste time optimizing the parts that are already fast. They’re not the limiting factor.&lt;/p&gt;
    &lt;p&gt;However, bottlenecks aren’t always the villains we make them out to be. Sometimes, they’re a necessary part of the system. Think of a security checkpoint at an airport. It slows everything down, but it’s there for a reason. Remove it, and you might speed things up, but at the cost of safety.&lt;/p&gt;
    &lt;p&gt;The key is to be intentional about your bottlenecks. Choose them wisely, and make sure they’re serving a purpose. A deliberate bottleneck can be a powerful tool for focusing effort and maintaining quality. An accidental bottleneck is just a drag on the system.&lt;/p&gt;
    &lt;p&gt;Bottlenecks are leverage points where a little effort can go a long way.&lt;/p&gt;
    &lt;p&gt;Scale&lt;/p&gt;
    &lt;p&gt;Systems change as they scale up or down; neither is intrinsically better or worse. The right scale depends on your goals and the context. If you want to scale something up, you need to anticipate that new problems will keep arising— problems that didn’t exist on a smaller scale. Or you might need to keep solving the same problems in different ways.&lt;/p&gt;
    &lt;p&gt;Think about a recipe. If you’re making a cake for four people, you use a certain amount of ingredients. But if you want to make a cake for four hundred people, you don’t just multiply the ingredients by one hundred. That’s not how scale works. You need to change the process and use bigger mixers and bigger ovens. You need a system that can handle the increased volume without breaking down.&lt;/p&gt;
    &lt;p&gt;The challenge with scale is that it’s not always obvious how to achieve it. What works for a small system often breaks down at larger volumes. You have to anticipate the bottlenecks and the points where the system will strain under the increased load. And you have to be ready to re‑engineer your processes as you grow.&lt;/p&gt;
    &lt;p&gt;If you’re building something, always be thinking about scale. How will this work when you have ten times as many customers? One hundred times? One thousand times? Build with scale in mind from the start, and you’ll be ready for the growth when it comes.&lt;/p&gt;
    &lt;p&gt;Margin of safety is a secret weapon. It’s the buffer, the extra capacity, the redundancy that you build into a system to handle unexpected stress. It’s the difference between a bridge that can barely handle the expected load and one that can handle ten times that load without breaking a sweat.&lt;/p&gt;
    &lt;p&gt;You can apply a margin of safety to any area of life with uncertainty and risk. The key is always to ask yourself: What if I’m wrong? What if things don’t go as planned? How much extra capacity must I build to handle the unexpected?&lt;/p&gt;
    &lt;p&gt;But here’s the rub: margin of safety isn’t free. It means spending more upfront. In the short term, you’ll look overly cautious and leave immediate profits on the table. But in the long run, this apparent overcaution lets you survive when others break – and thrive when others merely survive.&lt;/p&gt;
    &lt;p&gt;Margin of safety is the unsung hero of long-term success. It’s not flashy. It’s not exciting, but it’s the foundation on which everything else is built. Master it, and you’ll be well on your way to navigating the uncertainties of life with confidence and stability.&lt;/p&gt;
    &lt;p&gt;Churn&lt;/p&gt;
    &lt;p&gt;Churn is the silent killer of businesses. It’s the slow leak, the constant drip of customers slipping away, of users drifting off to find something new. The attrition eats away at your growth, forcing you to keep running just to stay in place. The thing about churn is that it’s often hidden. It’s not like a sudden crisis that grabs your attention. It’s a slow, quiet process that happens in the background.&lt;/p&gt;
    &lt;p&gt;Churn can present opportunity. Like a snake shedding its skin, replacing components of a system is a natural part of keeping it healthy. New parts can improve functionality.&lt;/p&gt;
    &lt;p&gt;When we use this model as a lens, we see that new people bring new ideas, and counterintuitively, some turnover allows us to maintain stability. Replacing what is worn out also allows us to upgrade and expand our capabilities, creating new opportunities. Some churn is inevitable. Too much can kill you.&lt;/p&gt;
    &lt;p&gt;Algorithms&lt;/p&gt;
    &lt;p&gt;Algorithms are recipes. A list of crisp, unambiguous steps that tell you how to get from point A to point B. But they’re more than just directions. Algorithms are if‑then machines for tuning out the noise and zeroing in on the signal. Have the specs been met? Fol- low the algorithm and find out. Thinking algorithmically means searching for processes that reliably spit out the desired results, like a vending machine dispensing the same candy bar every time someone punches in E4.&lt;/p&gt;
    &lt;p&gt;Critical mass&lt;lb/&gt;Critical mass isn’t just a science term; it’s a guide for understanding that often things happen slowly and then all at once. It’s the moment when a system goes from sputtering along to explosive growth. Like a nuclear chain reaction, once you hit critical mass, the reaction becomes self-sustaining.&lt;/p&gt;
    &lt;p&gt;Through this lens we gain insight into the amount of material needed for a system to change from one state to another. Material can be anything from people and effort to raw material. When enough material builds up, systems reach their tipping point. When we keep going, we get sustainable change.&lt;/p&gt;
    &lt;p&gt;Using critical mass as a lens for situations where you want different outcomes helps you identify both the design elements you need to change and the work you need to put in.&lt;/p&gt;
    &lt;p&gt;Emergence&lt;/p&gt;
    &lt;p&gt;Nearly everything is an emergent effect—a table, a space shuttle, even us— combinations of ingredients that come together in a specific way to create something new. Emergence is the universe’s way of reminding us that when we combine different pieces in new ways, we get results that are more than the sum of their parts, often in the most unexpected and thrilling ways.&lt;/p&gt;
    &lt;p&gt;Using this mental model is not about predicting emergent properties but acknowledging they are possible. There is no need to stick with what you know; mix it up and see what happens. Learn new skills, interact with new people, read new things.&lt;/p&gt;
    &lt;p&gt;Irreducibility&lt;/p&gt;
    &lt;p&gt;Irreducibility is about essence. It’s the idea that some things can’t be broken down into smaller parts without losing what makes them tick. It’s the idea that not everything can be explained by looking at its components. Emergent properties arise from complex systems that can’t be predicted by studying the individual parts.&lt;/p&gt;
    &lt;p&gt;Grappling with irreducibility requires a shift in thinking. Instead of trying to break things down, sometimes you have to zoom out. Look at the big picture. Embrace the complexity. Because some problems don’t have neat, modular solutions. They’re irreducibly messy.&lt;/p&gt;
    &lt;p&gt;Using irreducibility as a lens helps you focus on what you can change by understanding what really matters&lt;/p&gt;
    &lt;p&gt;Law of Diminishing Returns&lt;/p&gt;
    &lt;p&gt;Diminishing returns is the idea that the easy wins usually come first. The more you optimize a system, the harder it gets to eke out additional improvements, like squeezing juice from a lemon. The first squeeze is easy. The second takes a bit more work. By the tenth squeeze, you’re fighting for every last drop.&lt;/p&gt;
    &lt;p&gt;Every bit of effort translates into significant gains when you’re a beginner. But as you level up, progress becomes more incremental. It takes more and more work to get better and better. That’s why going from good to great is much harder than going from bad to good.&lt;/p&gt;
    &lt;p&gt;Understanding diminishing returns is crucial for allocating resources efficiently. You want to focus on where you can get the biggest bang for your buck. Sometimes, that means knowing when to stop optimizing and move on to something else.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Mental Models of Mathematics&lt;/head&gt;
    &lt;p&gt;Sampling&lt;/p&gt;
    &lt;p&gt;Sample size is about how much of the world you’re looking at. It’s the number of data points you’re using to draw conclusions. Like trying to guess the average height of people in a city by measuring a few folks on the street. The more people you measure, the more confident you can estimate.&lt;/p&gt;
    &lt;p&gt;One of the biggest mistakes we can make is drawing conclusions from too small a sample size— like trying to guess a puzzle picture from only a few pieces. In most instances, increasing our sample size gives us valuable information that lets us see our situation in a new light. The catch is that large sample sizes are expensive. It takes time and money to collect all that data. So practitioners and researchers are always balancing the need for precision with the constraints of budget and deadline. They’ll often settle for the smallest sample size that can still give them a statistically significant result.&lt;/p&gt;
    &lt;p&gt;Using this model means exploring what isn’t obvious and knowing how easy it is to corrupt our samples with bias.&lt;/p&gt;
    &lt;p&gt;The next time you hear a statistic, think about the sample size. It’ll give you a clue about how seriously to take it. Remember: the larger the sample, the closer to the truth.&lt;/p&gt;
    &lt;p&gt;Randomness&lt;/p&gt;
    &lt;p&gt;Randomness is the chaos that underlies the cosmos. It’s the unpredictable, the uncontrollable, the stuff that doesn’t follow any discernible pattern.&lt;/p&gt;
    &lt;p&gt;Randomness is what makes life surprising. It’s why you can’t predict the future with certainty. You might make plans, but there’s always the possibility of a random event throwing a wrench in the works. A flat tire, a chance encounter, a sudden inspiration. Randomness is the spice that keeps things interesting.&lt;/p&gt;
    &lt;p&gt;The tricky thing about randomness is that humans are terrible at recognizing it. We see patterns where there are none. We attribute meaning to coincidence. We think we can beat the odds. But true randomness is immune to our predictions and superstitions. It doesn’t care about our theories or desires&lt;/p&gt;
    &lt;p&gt;Regression To The Mean&lt;/p&gt;
    &lt;p&gt;Regression to the mean is the universe’s way of saying “not so fast.” It’s the tendency for extreme outcomes to be followed by more average ones. Extreme results are rarely repeated.&lt;/p&gt;
    &lt;p&gt;The next time you see something extraordinary, enjoy it. But remember, it probably won’t last. Sooner or later, regression to the mean will come calling, pulling the exceptional back to the ordinary. That’s the way the universe keeps things in check.&lt;/p&gt;
    &lt;p&gt;Multiply by Zero&lt;/p&gt;
    &lt;p&gt;Multiplying by zero is the mathematical version of the Midas touch in reverse. Everything it touches turns to nothing. No matter how big or small a number is, when you multiply it by zero, you get zero. It’s the ultimate reset button.&lt;/p&gt;
    &lt;p&gt;Multiplying by zero shows that we must be mindful of the zeros that will negate our other efforts. Just as in engineering, where one faulty component can make an entire system fail, not being reliable can have the same effect in life.&lt;/p&gt;
    &lt;p&gt;When you multiply by zero, everything else becomes irrelevant.&lt;/p&gt;
    &lt;p&gt;Equivalence&lt;/p&gt;
    &lt;p&gt;Equivalence is the art of making things interchangeable. It’s the idea that two things can be swapped out without changing the essence of what they’re a part of. Like swapping a red Lego brick for a blue one. The color changes, but the structure remains the same.&lt;/p&gt;
    &lt;p&gt;Being equal doesn’t mean being the same. Different inputs can produce identical results, and there is more than one way to solve most problems.&lt;/p&gt;
    &lt;p&gt;Equivalence lets us simplify complex systems. We can focus on the essentials instead of getting bogged down in details. We can see the forest for the trees. And we can make changes without fear of breaking the fundamental structure.&lt;/p&gt;
    &lt;p&gt;Of course, equivalence has its limits. Not everything is interchangeable. You can’t swap out a car’s engine for a hamster wheel and expect the car to run. The art is in knowing where equivalence applies and where it doesn’t. It’s in recognizing the essential differences that matter, and the superficial differences that don’t.&lt;/p&gt;
    &lt;p&gt;The next time you face a complex problem, try thinking about equivalence. Look for the underlying patterns. See if there are components you can swap out or simplify. You might just find a solution that’s been hiding in plain sight all along.&lt;/p&gt;
    &lt;p&gt;Surface Area&lt;/p&gt;
    &lt;p&gt;Surface area is what determines how much an object interacts with its environment. The more surface area the more contact. Surface area can be good and bad. Sometimes, keeping it small is favorable, and sometimes, increasing our exposure is beneficial.&lt;/p&gt;
    &lt;p&gt;Surface area teaches us that increasing cognitive diversity can give us fresh ideas and help us innovate. However, the model also reminds us that in many ways, the more we expose ourselves, the more vulnerable we are. Different situations require different surface areas.&lt;/p&gt;
    &lt;p&gt;Global and Local Maxima&lt;/p&gt;
    &lt;p&gt;Global and local maxima as a model can be used differently to help us make the changes we need for success. It encourages us to see achieving our goals not as a steady upward trajectory but as a path full of peaks and valleys. Understanding that sometimes we have to go down to climb even higher helps us make short-term sacrifices to play the long game. In engineering, you might be trying to maximize efficiency. In life, you might be trying to maximize happiness. But in all these cases, getting stuck on a local maximum is easy. You find a pretty good solution, and you stop looking for a better one.&lt;/p&gt;
    &lt;p&gt;The next time you’re trying to optimize something, remember the concept of global and local maxima. Don’t just settle for the first peak you find. Keep exploring. Keep searching for that global maximum. It might be a tough climb, but the view from the top is worth it.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Mental Models of Economics&lt;/head&gt;
    &lt;p&gt;Scarcity&lt;/p&gt;
    &lt;p&gt;Scarcity shapes our choices and drives our actions. When something is scarce, it suddenly becomes valuable. We want it more because there is less. It’s the principle that underlies everything from the price of gold to the thrill of the hunt.&lt;/p&gt;
    &lt;p&gt;Scarcity isn’t just about material things. It applies to time, opportunities, and ideas. We’re drawn to the exclusive, the limited-edition, the one-of-a-kind.&lt;/p&gt;
    &lt;p&gt;In economics, scarcity is a foundational principle. There are infinite wants and desires but limited resources. We can’t have everything, so we must choose. Scarcity guides those choices.&lt;/p&gt;
    &lt;p&gt;Some businesses operate with a scarcity mentality, removing shock absorbers and operating lean, with just enough resources to produce the day’s goods. This model is prone to disruption with the slightest hiccup and signals to employees that they’re in a culture of scarcity, triggering our biological instinct toward self-preservation. We subconsciously hoard things of value to gain an individual advantage.&lt;/p&gt;
    &lt;p&gt;Scarcity can work to your advantage. Imagine you’ve got a rare combination of qualities: you’re honest, hardworking, and smart. People like that are scarce, and the world disproportionately rewards them. It’s not just about being good at one thing; it’s about having a mix of traits.&lt;/p&gt;
    &lt;p&gt;The key to navigating scarcity is understanding its power, recognizing when it’s driving our choices, and asking if those choices align with our true values and goals. Sometimes, scarcity creates real value. But sometimes, it’s just a mirage, a trick of the mind.&lt;/p&gt;
    &lt;p&gt;Supply and Demand&lt;/p&gt;
    &lt;p&gt;Supply and demand are the push and pull determining availability and price. Their dance is never-ending. A sudden shortage can send prices soaring; a new discovery can send them crashing.&lt;/p&gt;
    &lt;p&gt;But supply and demand aren’t just about price; they’re also about allocation. They determine who gets what, and how much of it. When supply is low and demand is high, resources flow to those willing and able to pay the most.&lt;/p&gt;
    &lt;p&gt;Markets react to supply and demand. When demand exceeds supply, it encourages investment by companies to create substitutes or more supply. On the other hand, when supply exceeds demand, it discourages investment until a profitable balance is restored.&lt;/p&gt;
    &lt;p&gt;Economic cycles are driven as much by human nature as by resources. When profits are flowing, it encourages overconfidence, greed, and complacency. When profits are nowhere to be found, it encourages fear, savings, and ruthless efficiency.&lt;/p&gt;
    &lt;p&gt;As individuals, we’re all part of this dance. Every choice we make as consumers and every decision we make as producers shapes the contours of supply and demand. We are the market, collectively determining what has value and what doesn’t.&lt;/p&gt;
    &lt;p&gt;Remember the forces at play the next time you’re at the store, negotiating a salary, or launching a product. You’re not just a passive participant but an active agent in supply and demand. Your choices matter. Make them wisely.&lt;/p&gt;
    &lt;p&gt;Optimization&lt;/p&gt;
    &lt;p&gt;Optimization is about making the most of what you have. It’s like cleverly solving a puzzle, finding a trick to skip steps and get to the answer faster.&lt;/p&gt;
    &lt;p&gt;In a world of scarcity, optimization is powerful. It allows us to maximize our limited resources, whether time, money, or energy. But like any tool, it’s only as good as the hand that wields it. Used wisely, optimization unlocks hidden potential and drives extraordinary results. Used poorly, it leads to wasted effort and missed opportunities.&lt;/p&gt;
    &lt;p&gt;Optimization often works for you until it doesn’t. It’s like the student who writes the answer but doesn’t show their work. Knowing when to use it, when to let it go, and when to avoid it can give you a key advantage.&lt;/p&gt;
    &lt;p&gt;Trade-offs&lt;/p&gt;
    &lt;p&gt;Life is full of trade-offs. Every choice has a cost. When you say yes to one thing, you say no to others. This is how the world works. It’s like gravity. You can’t escape it.&lt;/p&gt;
    &lt;p&gt;Opportunity cost is what you give up when you make a choice. It’s the thing you can’t have because you picked something else. Say you have a free evening. You can work on your startup or go to a movie. If you work, you miss the fun. If you go to the movie, you miss the chance to make progress.&lt;/p&gt;
    &lt;p&gt;Every choice has an opportunity cost because every time you say yes to something, you’re implicitly saying no to other things. You need to know your opportunity costs. This helps you make good trade-offs.&lt;/p&gt;
    &lt;p&gt;A trade-off is giving up one thing to get something else. It’s choosing between options. Each has good and bad points. Trade-offs are about priorities. When you make something, you face trade-offs. If you want it fast, you might lose some features. If you want it cheap, you might use lower-quality materials.&lt;/p&gt;
    &lt;p&gt;In life, we face trade- offs all the time. Do you take a high-paying job with long hours? Or the low-paying one with more free time? Do you spend money now or save for later?&lt;/p&gt;
    &lt;p&gt;Making good trade-offs is about weighing the opportunity costs and benefits of each option and choosing the one that aligns best with your goals and values. It’s not always easy, but being conscious of the trade- offs you’re making can help you make better decisions.&lt;/p&gt;
    &lt;p&gt;Wisdom is anticipating the consequences of your choices. In life and business, success is about making good trade-offs. It’s not about having it all. It’s about having what matters most. We all value different things. That’s what makes life rich.&lt;/p&gt;
    &lt;p&gt;Opportunity cost is what you give up when you make a choice; trade-offs are the balancing acts you perform when deciding between competing options. They’re two sides of the same coin— whenever you make a trade-off, you’re incurring an opportunity cost for the option you didn’t choose. The key in both cases is to be thoughtful and intentional about your choices.&lt;/p&gt;
    &lt;p&gt;Specialization&lt;/p&gt;
    &lt;p&gt;Specialization is a trade-off: pursuing one course means not pursuing another. It’s narrowing your focus to broaden your impact. In a world of infinite knowledge and finite time, specialization is the key to unlocking mastery. It’s about going deep, not wide.&lt;/p&gt;
    &lt;p&gt;Specialization has risks. If the world changes, what was once a valuable specialty can become obsolete. And yet, we need specialists. You wouldn’t want a generalist doing your brain surgery or a root canal.&lt;/p&gt;
    &lt;p&gt;Here’s the catch: the more you specialize, the more you see how much other fields can teach you. The most exciting finds often happen at the edges between areas of knowledge. The trick is to specialize without getting stuck. To go deep, but also reach out.&lt;/p&gt;
    &lt;p&gt;Ultimately, specialization is about where you spend your time and effort. It’s how you stand out. It’s choosing to be great at one thing instead of okay at many.&lt;/p&gt;
    &lt;p&gt;Interdependence&lt;/p&gt;
    &lt;p&gt;Interdependence is the web that ties us all together. It’s the recognition that no person, no company, no country is an island. We’re all connected, all reliant on one another in countless ways, big and small. Interdependence is the reality that underlies the illusion of self-sufficiency. No one is entirely self-made.&lt;/p&gt;
    &lt;p&gt;Interdependence can be both a vulnerability and a strength. When we recognize our interdependencies, we can leverage them for mutual benefit. We can form alliances, partnerships, and ecosystems. We can create value that no single entity could create alone.&lt;/p&gt;
    &lt;p&gt;Interdependence is the foundation of synergy, the alchemy of the whole being greater than the sum of its parts. On the other hand, if we depend on others for something critical, it can expose us if they fail to deliver or change their minds. It’s easy to be a good partner when things are going well. But you want to be careful with whom you depend in a crisis.&lt;/p&gt;
    &lt;p&gt;Interdependence isn’t just a macro concept. It’s deeply personal. We’re all interdependent with our families, our friends, our communities. We rely on one another for support, for love, for meaning. Interdependence is the fabric of our social lives.&lt;/p&gt;
    &lt;p&gt;Efficiency&lt;/p&gt;
    &lt;p&gt;Efficiency is about getting the most done with the least waste. It’s not always about finding the perfect answer but the one that works well enough without too much fuss. Efficiency matters because in real life, you never have all the time or resources you want. You have to make do with what you’ve got.&lt;/p&gt;
    &lt;p&gt;But efficiency isn’t just about speed. It’s also about effectiveness and doing the right things. There’s no point in doing something fast if it’s not worth doing. True efficiency is about focusing on what matters most. It’s about saying no to the small stuff so you can say yes to the big stuff.&lt;/p&gt;
    &lt;p&gt;Like everything, efficiency has its limits. There’s a point of diminishing returns, a threshold beyond which further optimization yields little gain. The key is finding the sweet spot, the point of maximum efficiency before the costs start outweighing the benefits.&lt;/p&gt;
    &lt;p&gt;Efficiency works until it doesn’t. The more perfectly efficient a system, the more vulnerable it becomes to any change. While the idea can be hard to appreciate, maximal efficiency in the short term rarely leads to maximum long- term efficiency. A common benefit eroded in the quest for efficiency is a margin of safety. Through the efficiency lens, the opportunity cost of holding something like extra cash, inventory, or even employees may be seen as too high. However, supply shocks or environmental changes can make excess cash, inventory, and employees more valuable.&lt;/p&gt;
    &lt;p&gt;Inefficiency in the short run is often very efficient in the long run when it leaves you better able to adapt to an uncertain world and increases the odds of survival.&lt;/p&gt;
    &lt;p&gt;In a world of trade-offs, efficiency is a balancing act. It’s about making the most of what you have and leaving room for what you might need. It’s about being prepared for the future, not just optimized for the present.&lt;/p&gt;
    &lt;p&gt;Debt&lt;/p&gt;
    &lt;p&gt;Debt is a double-edged sword. It’s a powerful tool to help you grow a business, buy a home, or seize an opportunity. But it’s also a chain that can bind your future or destroy you.&lt;/p&gt;
    &lt;p&gt;When debt spirals out of control, it quickly turns dreams into nightmares.&lt;/p&gt;
    &lt;p&gt;Debt isn’t just about money. It can be a favor you owe, a social obligation, or anything that creates a future obligation. We even have sleep debt.&lt;/p&gt;
    &lt;p&gt;It can be hard to appreciate just how fragile debt makes you. It’s like driving across a vast desert without a spare tire. If everything goes perfectly, you will reach the other side, but the smallest hiccup will leave you stranded and desperate.&lt;/p&gt;
    &lt;p&gt;Use debt wisely. Respect its power, but fear its edge. Remember, the more you borrow, the less room you have to weather life’s storms.&lt;/p&gt;
    &lt;p&gt;While debt might seem cheap in the moment, the future often proves it to be more expensive than we imagined. The more you borrow, the less room you have to deal with uncertainty.&lt;/p&gt;
    &lt;p&gt;Debt can give you leverage, but it can also take away your freedom. Respect its power but fear its edge.&lt;/p&gt;
    &lt;p&gt;Monopoly and Competition&lt;/p&gt;
    &lt;p&gt;Monopoly and competition are the yin and yang of the business world. They’re the opposing forces that shape the landscape of every market, the tides that lift and sink the fortunes of every firm. To understand business, you must understand the dance between these poles.&lt;/p&gt;
    &lt;p&gt;Competition is the default state of the market. It’s the Darwinian struggle where many firms vie for the same customers and resources. In a competitive market, no one firm has the power to set prices or dictate terms. They’re price takers, not price makers. They survive by being efficient, delivering value, and innovating.&lt;/p&gt;
    &lt;p&gt;If competition is the natural state, monopoly is the entrepreneur’s dream. A monopoly dominates a market so completely that it becomes the market. Think of the only bridge that crosses a river. But monopolies inevitably sow the seeds of their own destruction. The question is how long they will last.&lt;/p&gt;
    &lt;p&gt;We need both monopoly and competition. Competition keeps firms honest and drives innovation. But we also need monopolies’ deep pockets to fund big visions and moon shots. The ideal is a balance: enough competition to check monopolies but enough monopolies to reward innovation.&lt;/p&gt;
    &lt;p&gt;Creative Destruction&lt;/p&gt;
    &lt;p&gt;Creative destruction is the engine of progress in a capitalist economy. It’s the process by which new innovations replace old ones, the cycle of birth and death that keeps an economy vibrant. It embodies the old adage: The only constant is change.&lt;/p&gt;
    &lt;p&gt;In a dynamic economy, nothing is sacred. Newer, better ideas can disrupt every industry, company, and way of doing things. The smartphone replaced the flip phone, online streaming replaced movie rental stores, and cars replaced horses.&lt;/p&gt;
    &lt;p&gt;While creative destruction can be painful for individual companies, it’s essential for the overall economy’s health. It prevents stagnation and ensures resources are always put to their most productive use. Without creative destruction, we’d still ride horses and rent VHS tapes.&lt;/p&gt;
    &lt;p&gt;On one hand, creative destruction is the opportunity you’re looking for—the chance to disrupt an incumbent—to build something new and better. But on the other hand, it’s the threat you’re always guarding against—the possibility that you will be disrupted by the next big thing.&lt;/p&gt;
    &lt;p&gt;Creative destruction isn’t just about business; it’s a metaphor for life. We are all subject to change, to the constant cycle of endings and beginnings. The key is to not cling too tightly to the old, but to embrace the new possibilities.&lt;/p&gt;
    &lt;p&gt;Gresham’s Law&lt;/p&gt;
    &lt;p&gt;Gresham’s Law states that bad money drives out good. But it’s not just about currency. The principle applies anytime there are two competing versions of something, one perceived as high quality and the other as low quality.&lt;/p&gt;
    &lt;p&gt;In a sense, Gresham’s Law is the dark side of human nature. We’re wired to optimize for the short term, to get the most value for the least effort. If we can pass off the less valuable thing and keep the more valuable one, we will. Without consequences, bad behavior drives out good. Bad lending drives out good lending. Bad morals drive out good morals. Overcoming this requires constant effort.&lt;/p&gt;
    &lt;p&gt;In the short run, bad often drives out good. But in the long run, true value wins out.&lt;/p&gt;
    &lt;p&gt;Bubbles&lt;/p&gt;
    &lt;p&gt;Bubbles are a natural by-product of human nature. They happen when collective enthusiasm for an asset runs far ahead of its fundamental value. It’s the moment when the market becomes untethered from reality when prices are driven not by sober calculation but by mass delusion.&lt;/p&gt;
    &lt;p&gt;Bubbles are a fascinating study of human psychology. They’re driven by greed and FOMO (fear of missing out). No one wants to be the sucker who sits on the sidelines while everyone else gets rich. But there’s also an element of genuine belief, of conviction that this time is different, that the old rules no longer apply.&lt;/p&gt;
    &lt;p&gt;While ultimately destructive, bubbles also serve a function. They’re the market’s way of exploring new frontiers, of testing new possibilities. Many of the innovations we take for granted today— from cars to computers to the internet itself— were once the subject of speculative manias. Bubbles fund the infrastructure for future revolutions, even as they leave a trail of financial wreckage in their wake.&lt;/p&gt;
    &lt;p&gt;Bubbles remind us that markets are driven by human emotions and beliefs. They’re a mirror held up to our collective hopes, dreams, and delusions. The next time you catch yourself saying, “this time is different,” remember that all bubbles pop eventually.&lt;/p&gt;
    &lt;p&gt;Like a balloon that can only expand so far, bubbles eventually burst, and the game ends abruptly without warning. Keeping yourself grounded in value and economic reality, not in story or hype, is key to standing alone as a bubble expands.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Mental Models of Art&lt;/head&gt;
    &lt;p&gt;Audience&lt;/p&gt;
    &lt;p&gt;The audience is the invisible participant in every work of art. They are the eyes that see, the ears that hear, the minds that interpret. Without an audience, art is like a tree falling in an empty forest— it may make a sound, but does it matter? The audience is what gives art its meaning, its purpose, and its very existence.&lt;/p&gt;
    &lt;p&gt;Every observer infuses art with personal significance, transforming it into a co-creation. A painting of a sunset may evoke feelings of peace and beauty for one person and feelings of melancholy and loss for another. The artwork is the same, but the audience is different, so the meaning is different. In this sense, the audience is a cocreator of the art.&lt;/p&gt;
    &lt;p&gt;Great artists design their work for these silent judges, balancing authenticity with expectation without succumbing to pandering.The audience is their silent collaborator and their ultimate judge.&lt;/p&gt;
    &lt;p&gt;In a world where so much can be faked, the audience is something real. You can fake likes, followers, and reviews, but you can’t fake the genuine human experience of engaging with art. The spontaneous laughter, unexpected tears, and long, thoughtful silence are the honest reactions that both the audience and the artists live for.&lt;/p&gt;
    &lt;p&gt;Never forget your audience, but never let them dictate your creation.&lt;/p&gt;
    &lt;p&gt;Genre&lt;/p&gt;
    &lt;p&gt;Picture this: you’re browsing a bookstore, scanning the shelves for your next read. You pick up a book with a shadowy figure on the cover, a magnifying glass in hand. Instantly, you know what kind of story awaits you within those pages. This is the power of genre— the unspoken understanding between creator and audience that shapes how we experience art.&lt;/p&gt;
    &lt;p&gt;But genre is more than just a label; it’s a set of conventions, an understanding between the artist and the audience. When we pick up a mystery novel, we expect a crime, some clues, and a detective. When we go to a rock concert, we expect loud guitars, driving rhythms, and a rebellious attitude. Genre sets the parameters of our experience, even as it gives the artist a foundation to build upon or rebel against.&lt;/p&gt;
    &lt;p&gt;Think of genre as a game with rules. The rules provide structure, but they also create opportunities for creativity. A sonnet has a strict form— fourteen lines, a specific rhyme scheme— but within those constraints, poets have found endless ways to express love, loss, joy, and sorrow. The rules of the genre game inspire ingenuity, challenging artists to create something fresh within the familiar.&lt;/p&gt;
    &lt;p&gt;But genres are not static; they are constantly evolving. Look at the way rock music has transformed over the decades. What began as a rebellious offshoot of blues and country in the 1950s has splintered into countless subgenres, each with a distinct style and audience. From the psychedelic experimentation of the 1960s to the punk revolution of the ’70s to the grunge explosion of the ’90s, rock has reinvented itself time and again. What was once transgressive becomes mainstream, and new forms emerge to take its place.&lt;/p&gt;
    &lt;p&gt;Navigating genre is a delicate art. Sticking too closely to the conventions may cause your work to be dismissed as formulaic. On the other hand, if you stray too far you risk losing your audience. The key is to find the sweet spot— honoring the genre’s expectations while bringing something new and personal to the table.&lt;/p&gt;
    &lt;p&gt;Ultimately, genre is a tool—a way of framing the conversation between the artist and the audience. It provides common ground, a starting point for the journey together. But the true power of art lies in the way it can transcend genre, using convention as a springboard to take us places we’ve never been.&lt;/p&gt;
    &lt;p&gt;Contrast&lt;/p&gt;
    &lt;p&gt;Contrast is the spice of life and art. It’s the clash of opposites that energizes a work and jolts our senses. Without contrast, the world is bland. With it, the world dances with dark and light, loud and soft, rough and smooth. Contrast makes us notice.&lt;/p&gt;
    &lt;p&gt;Contrast isn’t just visual. In music, quiet moments make loud ones explosive. Gentle ballads set the stage for crashing anthems. In literature, calm before the storm makes extraordinary events remarkable. Contrast gives art emotional power.&lt;/p&gt;
    &lt;p&gt;Contrast creates interest and engagement. Our brains are wired to pay attention to changes and differences. We tune out the monotonous, but we snap to attention when something breaks the pattern. Artists use contrast to manipulate our attention, direct our focus, and shape our work experience.&lt;/p&gt;
    &lt;p&gt;Contrast is a universal principle. Light and dark, hot and cold, life and death— the world is defined by contrasts. Darkness helps us understand light. Winter makes us appreciate spring. Contrast gives meaning to existence.&lt;/p&gt;
    &lt;p&gt;Framing&lt;/p&gt;
    &lt;p&gt;Framing is the art of context, the craft of shaping perception. It’s how we present information, the lens through which we invite others to view the world. Like a photographer choosing what’s in the frame, we constantly decide what to emphasize, minimize, or leave out. These often unconscious choices profoundly influence how others understand and respond.&lt;/p&gt;
    &lt;p&gt;In psychology, framing is a key concept in understanding decision- making. Present the same options in different ways, and people’s choices change. Is it a muffin or a cake? The thing doesn’t change, but its packaging does.&lt;/p&gt;
    &lt;p&gt;For marketers and advertisers, framing is a potent tool. A car can be framed as a status symbol, an adventure machine, or a sensible family vehicle. A watch can be about punctuality, or it can be about luxury and prestige. The product stays the same, but the story changes. The right frame makes the ordinary extraordinary.&lt;/p&gt;
    &lt;p&gt;But framing isn’t just about persuasion. It’s also about understanding, about making sense of the complex world around us. We all carry frames in our minds— mental models of how things work, cultural narratives, and personal beliefs. These frames shape how we interpret information, how we explain events, and how we imagine possibilities.&lt;/p&gt;
    &lt;p&gt;Framing’s power lies in its subtlety. Unlike a logical argument, a frame doesn’t need to be explicitly stated to have an effect. It works on an emotional, often subconscious level. A well-crafted frame can make an idea feel intuitive, even inevitable, without the audience knowing why.&lt;/p&gt;
    &lt;p&gt;Framing is the silent partner in every communication, the hidden hand shaping understanding. Like any powerful tool, framing can be used for good or ill. It can illuminate truth, or it can obscure it. It can empower people to see new possibilities, or it can subtly limit their thinking to narrow predefined channels.&lt;/p&gt;
    &lt;p&gt;Rhythm&lt;/p&gt;
    &lt;p&gt;Rhythm is the universe’s heartbeat, the pulse animating life. From our steady heartbeats to the sun’s rise and fall, from crashing waves to swaying trees, rhythm is the pattern underlying existence. It’s the organizing principle bringing order to chaos, the recurring cycle shaping time.&lt;/p&gt;
    &lt;p&gt;In music, rhythm is the backbone supporting melody and harmony. Without rhythm, music would be a formless wash of sound, lacking structure and impact. The steady beat of the drum, the driving strum of the guitar, the pulsing throb of the bass— these rhythms grab us on a visceral level, moving our bodies and stirring our souls.&lt;/p&gt;
    &lt;p&gt;But rhythm isn’t just about regularity, the even spacing of beats. It’s also variation, the interplay of different rhythmic patterns. In jazz, the syncopated rhythms and the unexpected accents give the music an improvisational feel. In classical music, the shifting rhythms, from the stately march to the lively dance, convey the piece’s emotional arc.&lt;/p&gt;
    &lt;p&gt;Rhythm is also fundamental to language. The cadence of a phrase, the meter of a poem, the rise and fall of a great orator’s speech— these rhythms communicate meaning beyond the literal content of the words. They create their own music, a pattern resonating in the ear and lingering in the mind.&lt;/p&gt;
    &lt;p&gt;Even in our daily lives, rhythm plays a crucial role. The routines we establish, the habits we cultivate, the cycles of work and rest, of activity and reflection— these rhythms give structure and meaning to our existence. Without rhythm, life would be a formless blur, a ceaseless stream of unrelated moments. Rhythm allows us to make sense of time, to find our place in life’s larger patterns.&lt;/p&gt;
    &lt;p&gt;Melody&lt;/p&gt;
    &lt;p&gt;Melody is music’s soul, the ethereal thread weaving through sound’s tapestry. It’s the part of a song that we hum in the shower, the tune that gets stuck in our head and won’t let go. Melody is the musical expression of a fundamental human need: the need to tell a story, convey an emotion, and connect with others beyond words.&lt;/p&gt;
    &lt;p&gt;A melody is simply a sequence of notes, a pattern of pitches and rhythms. But melody’s magic transcends these basic building blocks. A great melody is more than the sum of its parts. It has a shape, a contour, an arc that carries us from one note to the next. It has a sense of inevitability, as if each note is the only possible choice, even as the melody surprises us with its freshness and novelty.&lt;/p&gt;
    &lt;p&gt;In this sense, melody is a lot like language. As we arrange words infinitely to express different ideas, we arrange notes to express emotions and experiences. A rising melody might convey a sense of hope and aspiration, while a falling melody might suggest sadness or resignation. A melody with large leaps might feel adventurous and daring, while one with small, stepwise motion might feel intimate and confiding.&lt;/p&gt;
    &lt;p&gt;But melody isn’t just about individual expressions. It’s also about communication and connection. When a melody resonates with us, it’s as if the composer is speaking directly to our hearts. We feel understood, validated, less alone. And when we sing or play a melody with others, we create a bond, a shared experience that transcends our individual differences.&lt;/p&gt;
    &lt;p&gt;This is why melody has such power across cultures and throughout history. From the chants of ancient rituals to the latest pop hits, melody has been a constant in human musical expression. It’s a universal language, requiring no translation or explanation. A beautiful melody can move us regardless of whether we understand the words or know the cultural context.&lt;/p&gt;
    &lt;p&gt;Of course, not all melodies are equal. Just as there are great works of literature and forgettable pulp novels, there are melodies that stand the test of time and others that quickly fade from memory. The best melodies balance the familiar and the new. They have a memorable shape, a satisfying resolution, a feeling of completeness.&lt;/p&gt;
    &lt;p&gt;In a world often fragmented and chaotic, melody is a source of unity and coherence, a way of finding beauty and meaning amid the noise.&lt;/p&gt;
    &lt;p&gt;Representation&lt;/p&gt;
    &lt;p&gt;Representation is the mental shorthand we use to navigate the complexities of reality, the symbols and images we use to communicate our thoughts and experiences. Representation is how we construct meaning and bridge the gap between the raw data of our senses and the narratives we tell about ourselves and our world.&lt;/p&gt;
    &lt;p&gt;At its core, representation is about standing in for something else. A word stands in for an object or concept, a map for a territory, a musical note for a sound. We use representations because we can’t hold the entirety of reality in our minds at once. We need abstractions, simplifications, and models that we can manipulate and reason about.&lt;/p&gt;
    &lt;p&gt;But representation is not neutral. Every representation is an interpretation, a way of framing reality that highlights some aspects and obscures others. An emoji might represent a feeling, but it doesn’t show the lived experience that causes that feeling. In this sense, representation is always a kind of distortion. It’s a lens that shapes how we see the world, for better or worse. A good representation can illuminate hidden truths, help us see patterns and connections we might otherwise miss. But a bad representation can mislead us, reinforce stereotypes and prejudices, limit our ability to imagine alternatives.&lt;/p&gt;
    &lt;p&gt;Representation is not just about mirroring reality; it’s also about shaping it. The representations we create and consume can influence how we think and act, to change the very world they purport to describe. A powerful piece of art can shift cultural attitudes, a persuasive political narrative can sway elections, a compelling scientific model can guide research and policy. In this way, representation is a kind of feedback loop. We create representations based on our understanding of reality, but those representations, in turn, shape our understanding, which influences the representations we create next. It’s a constant dance between map and territory, symbol and referent.&lt;/p&gt;
    &lt;p&gt;Plot&lt;/p&gt;
    &lt;p&gt;The plot is the story’s engine, propelling characters and events through time. It’s the sequence of causally connected events that leads from the beginning of a narrative to its resolution. Without a plot, a story is just disconnected moments and unrelated incidents. With a plot, a story becomes a journey, a transformative experience for characters and readers.&lt;/p&gt;
    &lt;p&gt;At its most basic level, a plot is a series of events connected by cause and effect. Event A leads to Event B, which leads to Event C, and so on, until the story reaches its resolution. But a good plot is more than just a linear chain of events. It’s a complex web of actions and reactions, of conflicts and resolutions, of setups and payoffs.&lt;/p&gt;
    &lt;p&gt;Conflict is the heart of any plot. Without conflict, characters have no story or reason to act or change. Conflict can take many forms— person versus person, person versus nature, person versus society, person versus self. But all conflicts share a fundamental structure: a character wants something but faces obstacles. The plot is the events that arise from the character’s attempts to overcome these obstacles and achieve their goal.&lt;/p&gt;
    &lt;p&gt;But plot is not just about external conflicts and goals. It’s also about the internal journey of the characters, the way they grow and change because of the events they experience. A good plot presents a character with external challenges and forces them to confront their own flaws, beliefs, and desires.&lt;/p&gt;
    &lt;p&gt;In this sense, the plot is a crucible for the character. It’s the fire that tests and transforms the protagonist, revealing their true nature and potential. A character who ends a story unchanged, unaffected by the plot’s events, is a character in a story that hasn’t really gone anywhere. The best plots leave characters fundamentally altered, through triumph or tragedy.&lt;/p&gt;
    &lt;p&gt;Plot is also personal. The most powerful story in the world is the one you tell yourself about the obstacles and challenges in front of you. A positive story doesn’t always ensure success, but a negative one almost guarantees failure.&lt;/p&gt;
    &lt;p&gt;Once a story takes root, no matter how false, it can be hard to change. This applies to both humanity in general and to each of us individually. Change the story to change the results.&lt;/p&gt;
    &lt;p&gt;Character&lt;/p&gt;
    &lt;p&gt;At their core, characters are bundles of traits and motivations, of habits and histories, of strengths and flaws. They are the total of their choices and actions, the product of genetics, choices, and circumstances. But a great character is more than just a list of attributes. A great character is a paradox, a contradiction, a mystery that unfolds over the course of a story.&lt;/p&gt;
    &lt;p&gt;In many ways, character is destiny. The choices a character makes, the actions they take, flow inevitably from who they are. A cautious, thoughtful character will approach a problem differently than an impulsive, emotional one. A character with a strong moral compass will make different decisions than one with a flexible relationship to the truth. Obstacles reveal character.&lt;/p&gt;
    &lt;p&gt;But character is not static; it is not a fixed point but a journey. The best characters are the ones who grow and change throughout a story and who are transformed by the events of the plot and the interactions with other characters. Think of Ebenezer Scrooge, the miserly old man who learns the true meaning of generosity.&lt;/p&gt;
    &lt;p&gt;Understanding a person’s character allows you to see someone for who they are at their core and step into their shoes. This helps you understand why they make their choices, predict their behavior, and empathize with their story. But remember, character is not set in stone. What happened yesterday is over. Today’s obstacles and challenges are nothing more than an opportunity to take a step toward or away from the person you want to be. No single choice satisfies the pursuit, only repeated steps in the right direction.&lt;/p&gt;
    &lt;p&gt;Setting&lt;/p&gt;
    &lt;p&gt;The setting is the stage upon which the drama of the story unfolds, the physical and temporal context that shapes and reflects the actions of characters. An active participant in the narrative, setting is a force that can enable or hinder, reveal or conceal, enlighten or deceive. The setting is not just where the story happens but why it happens.&lt;/p&gt;
    &lt;p&gt;Setting anchors a story in time and place, providing sensory details that make it real. But setting is more than just physical description. It’s also the social, cultural, and historical context that defines the parameters of what is possible and what is permissible for the characters.&lt;/p&gt;
    &lt;p&gt;A story set in medieval Europe will have different constraints and opportunities than one set in modern- day Tokyo. A character in a small, gossipy village will face different challenges than one in a large, anonymous city. Setting shapes the choices characters make, the conflicts they face, the resolutions they find.&lt;/p&gt;
    &lt;p&gt;But setting is not just a one-way street, not just the environment acting upon the characters. Characters also act upon and interact with their setting. They navigate its challenges, exploit its opportunities, and leave their mark on its landscape. Every story is a symbiotic relationship between character and setting, a reciprocal exchange of influence and transformation.&lt;/p&gt;
    &lt;p&gt;Setting is the silent force that influences our fate. What we think and do is greatly impacted by our environment. This leads to a powerful and profound point: to change your behavior, change your environment. If you don’t, it will change you.&lt;/p&gt;
    &lt;p&gt;Performance&lt;/p&gt;
    &lt;p&gt;Performance is the art of the ephemeral, the fleeting moment of creative expression existing only in the here and now. It’s where the boundaries between art and life blur, the artist’s body and actions become the medium, and the audience’s presence and participation become integral.&lt;/p&gt;
    &lt;p&gt;At its core, performance is about presence, about the immediacy and intimacy of live action. In a world increasingly mediated by screens, live performance asserts the primacy of embodied experience, of the direct encounter between performer and spectator. It’s a reminder that art is not just a thing to be consumed but an event to be lived.&lt;/p&gt;
    &lt;p&gt;But performance is also about absence, the gaps and spaces between action and interpretation, intention and reception. Unlike a painting or a sculpture, a performance can never be fully captured or contained. It exists only in the memories and testimonies of those who were there, in the ripples and reverberations it sends through the culture. Performance embraces the contingency and open- endedness of the live event, the sense that anything could happen, that meaning is always in the making.&lt;/p&gt;
    &lt;p&gt;This contingency is both the power and the challenge of performance. It allows for spontaneity and responsiveness, adapting to and incorporating the unpredictable elements of the moment. Yet, it makes performance resistant to the control and perfection other art forms aspire to. A performance is always a collaboration with chance, a dance with the unknown.&lt;/p&gt;
    &lt;p&gt;As audience members, we are not just passive observers but active participants in the performance. Our presence, reactions, and energy all become part of the work. Think of fans transmitting energy to a team to rally them from behind with a few minutes left in the game. Performance invites us to be cocreators, to complete the work through our own interpretations and responses. In so doing, we become part of something larger than ourselves.&lt;/p&gt;
    &lt;p&gt;When we are fully present in any performance where someone is making themselves vulnerable, we may just glimpse the raw, unedited, unpolished essence of what it means to be human.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Mental Models of Military and War&lt;/head&gt;
    &lt;p&gt;Seeing the Front&lt;/p&gt;
    &lt;p&gt;One of the most valuable military tactics is the habit of “personally seeing the front” before making decisions – not always relying on advisors, maps, and reports, all of which can be faulty or biased. The Map/Territory model, as does the incentive model, illustrates the problem of not seeing the front. Leaders of any organization can generally benefit from seeing the front, as it provides firsthand information and tends to improve the quality of secondhand information.&lt;/p&gt;
    &lt;p&gt;Asymmetric Warfare&lt;/p&gt;
    &lt;p&gt;The asymmetry model leads to an application in warfare whereby one side seemingly “plays by different rules” than the other side due to circumstance. Generally, this model is applied by an insurgency with limited resources. Unable to out-muscle their opponents, asymmetric fighters use other tactics, as with terrorism creating fear that’s disproportionate to their actual destructive ability.&lt;/p&gt;
    &lt;p&gt;Two-Front War&lt;/p&gt;
    &lt;p&gt;The Second World War was a good example of a two-front war. Once Russia and Germany became enemies, Germany was forced to split its troops and send them to separate fronts, weakening their impact on either front. Opening a two-front war can often be a useful tactic, as can solving a two-front war or avoiding one, as in the example of an organization tamping down internal discord to focus on its competitors.&lt;/p&gt;
    &lt;p&gt;Though asymmetric insurgent warfare can be extremely effective, competitors have developed counterinsurgency strategies over time. Recently and famously, General David Petraeus of the United States led the development of counterinsurgency plans involving no additional force but substantial gains. Tit-for-tat warfare or competition often leads to a feedback loop that demands insurgency and counterinsurgency.&lt;/p&gt;
    &lt;p&gt;Somewhat paradoxically, the stronger two opponents become, the less likely they may be to destroy one another. This process of mutually assured destruction occurs not just in warfare, as with the development of global nuclear warheads, but also in business, as with the avoidance of destructive price wars between competitors. However, in a fat-tailed world, it is also possible that mutually assured destruction scenarios simply make destruction more severe in the event of a mistake (pushing destruction into the “tails” of the distribution).&lt;/p&gt;
    &lt;head rend="h2"&gt;The Mental Models of Human Nature and Judgment&lt;/head&gt;
    &lt;p&gt;1. Trust&lt;lb/&gt;Fundamentally, the modern world operates on trust. Familial trust is generally a given (otherwise we’d have a hell of a time surviving), but we also choose to trust chefs, clerks, drivers, factory workers, executives, and many others. A trusting system is one that tends to work most efficiently; the rewards of trust are extremely high.&lt;/p&gt;
    &lt;p&gt;2. Bias from Incentives&lt;lb/&gt;Highly responsive to incentives, humans have perhaps the most varied and hardest to understand set of incentives in the animal kingdom. This causes us to distort our thinking when it is in our own interest to do so. A wonderful example is a salesman truly believing that his product will improve the lives of its users. It’s not merely convenient that he sells the product; the fact of his selling the product causes a very real bias in his own thinking.&lt;/p&gt;
    &lt;p&gt;3. Pavlovian Association&lt;lb/&gt;Ivan Pavlov very effectively demonstrated that animals can respond not just to direct incentives but also to associated objects; remember the famous dogs salivating at the ring of a bell. Human beings are much the same and can feel positive and negative emotion towards intangible objects, with the emotion coming from past associations rather than direct effects.&lt;/p&gt;
    &lt;p&gt;4. Tendency to Feel Envy &amp;amp; Jealousy&lt;lb/&gt;Humans have a tendency to feel envious of those receiving more than they are, and a desire “get what is theirs” in due course. The tendency towards envy is strong enough to drive otherwise irrational behavior, but is as old as humanity itself. Any system ignorant of envy effects will tend to self-immolate over time.&lt;/p&gt;
    &lt;p&gt;5. Tendency to Distort Due to Liking/Loving or Disliking/Hating&lt;lb/&gt;Based on past association, stereotyping, ideology, genetic influence, or direct experience, humans have a tendency to distort their thinking in favor of people or things that they like and against people or things they dislike. This tendency leads to overrating the things we like and underrating or broadly categorizing things we dislike, often missing crucial nuances in the process.&lt;/p&gt;
    &lt;p&gt;6. Denial &lt;lb/&gt;Anyone who has been alive long enough realizes that, as the saying goes, “denial is not just a river in Africa.” This is powerfully demonstrated in situations like war or drug abuse, where denial has powerful destructive effects but allows for behavioral inertia. Denying reality can be a coping mechanism, a survival mechanism, or a purposeful tactic.&lt;/p&gt;
    &lt;p&gt;7. Availability Heuristic&lt;lb/&gt;One of the most useful findings of modern psychology is what Daniel Kahneman calls the Availability Bias or Heuristic: We tend to most easily recall what is salient, important, frequent, and recent. The brain has its own energy-saving and inertial tendencies that we have little control over – the availability heuristic is likely one of them. Having a truly comprehensive memory would be debilitating. Some sub-examples of the availability heuristic include the Anchoring and Sunk Cost Tendencies.&lt;/p&gt;
    &lt;p&gt;8. Representativeness Heuristic&lt;lb/&gt;The three major psychological findings that fall under Representativeness, also defined by Kahneman and his partner Tversky, are:&lt;/p&gt;
    &lt;p&gt;a. Failure to Account for Base Rates&lt;lb/&gt;An unconscious failure to look at past odds in determining current or future behavior.&lt;/p&gt;
    &lt;p&gt;b. Tendency to Stereotype &lt;lb/&gt;The tendency to broadly generalize and categorize rather than look for specific nuance. Like availability, this is generally a necessary trait for energy-saving in the brain.&lt;/p&gt;
    &lt;p&gt;c. Failure to See False Conjunctions&lt;lb/&gt;Most famously demonstrated by the Linda Test, the same two psychologists showed that students chose more vividly described individuals as more likely to fit into a predefined category than individuals with broader, more inclusive, but less vivid descriptions, even if the vivid example was a mere subset of the more inclusive set. These specific examples are seen as more representative of the category than those with the broader but vaguer descriptions, in violation of logic and probability.&lt;/p&gt;
    &lt;p&gt;9. Social Proof (Safety in Numbers)&lt;lb/&gt;Human beings are one of many social species, along with bees, ants, and chimps, among many more. We have a DNA-level instinct to seek safety in numbers and will look for social guidance of our behavior. This instinct creates a cohesive sense of cooperation and culture which would not otherwise be possible but also leads us to do foolish things if our group is doing them as well.&lt;/p&gt;
    &lt;p&gt;10. Narrative Instinct&lt;lb/&gt;Human beings have been appropriately called “the storytelling animal” because of our instinct to construct and seek meaning in narrative. It’s likely that long before we developed the ability to write or to create objects, we were telling stories and thinking in stories. Nearly all social organizations, from religious institutions to corporations to nation-states, run on constructions of the narrative instinct.&lt;/p&gt;
    &lt;p&gt;11. Curiosity Instinct&lt;lb/&gt;We like to call other species curious, but we are the most curious of all, an instinct which led us out of the savanna and led us to learn a great deal about the world around us, using that information to create the world in our collective minds. The curiosity instinct leads to unique human behavior and forms of organization like the scientific enterprise. Even before there were direct incentives to innovate, humans innovated out of curiosity.&lt;/p&gt;
    &lt;p&gt;12. Language Instinct&lt;lb/&gt;The psychologist Steven Pinker calls our DNA-level instinct to learn grammatically constructed language the Language Instinct. The idea that grammatical language is not a simple cultural artifact was first popularized by the linguist Noam Chomsky. As we saw with the narrative instinct, we use these instincts to create shared stories, as well as to gossip, solve problems, and fight, among other things. Grammatically ordered language theoretically carries infinite varying meaning.&lt;/p&gt;
    &lt;p&gt;13. First-Conclusion Bias&lt;lb/&gt;As Charlie Munger famously pointed out, the mind works a bit like a sperm and egg: the first idea gets in and then the mind shuts. Like many other tendencies, this is probably an energy-saving device. Our tendency to settle on first conclusions leads us to accept many erroneous results and cease asking questions; it can be countered with some simple and useful mental routines.&lt;/p&gt;
    &lt;p&gt;14. Tendency to Overgeneralize from Small Samples&lt;lb/&gt;It’s important for human beings to generalize; we need not see every instance to understand the general rule, and this works to our advantage. With generalizing, however, comes a subset of errors when we forget about the Law of Large Numbers and act as if it does not exist. We take a small number of instances and create a general category, even if we have no statistically sound basis for the conclusion.&lt;/p&gt;
    &lt;p&gt;15. Relative Satisfaction/Misery Tendencies&lt;lb/&gt;The envy tendency is probably the most obvious manifestation of the relative satisfaction tendency, but nearly all studies of human happiness show that it is related to the state of the person relative to either their past or their peers, not absolute. These relative tendencies cause us great misery or happiness in a very wide variety of objectively different situations and make us poor predictors of our own behavior and feelings.&lt;/p&gt;
    &lt;p&gt;16. Commitment &amp;amp; Consistency Bias&lt;lb/&gt;As psychologists have frequently and famously demonstrated, humans are subject to a bias towards keeping their prior commitments and staying consistent with our prior selves when possible. This trait is necessary for social cohesion: people who often change their conclusions and habits are often distrusted. Yet our bias towards staying consistent can become, as one wag put it, a “hobgoblin of foolish minds” – when it is combined with the first-conclusion bias, we end up landing on poor answers and standing pat in the face of great evidence.&lt;/p&gt;
    &lt;p&gt;17. Hindsight Bias&lt;lb/&gt;Once we know the outcome, it’s nearly impossible to turn back the clock mentally. Our narrative instinct leads us to reason that we knew it all along (whatever “it” is), when in fact we are often simply reasoning post-hoc with information not available to us before the event. The hindsight bias explains why it’s wise to keep a journal of important decisions for an unaltered record and to re-examine our beliefs when we convince ourselves that we knew it all along.&lt;/p&gt;
    &lt;p&gt;18. Sensitivity to Fairness&lt;lb/&gt;Justice runs deep in our veins. In another illustration of our relative sense of well-being, we are careful arbiters of what is fair. Violations of fairness can be considered grounds for reciprocal action, or at least distrust. Yet fairness itself seems to be a moving target. What is seen as fair and just in one time and place may not be in another. Consider that slavery has been seen as perfectly natural and perfectly unnatural in alternating phases of human existence.&lt;/p&gt;
    &lt;p&gt;19. Tendency to Overestimate Consistency of Behavior (Fundamental Attribution Error)&lt;lb/&gt;We tend to over-ascribe the behavior of others to their innate traits rather than to situational factors, leading us to overestimate how consistent that behavior will be in the future. In such a situation, predicting behavior seems not very difficult. Of course, in practice this assumption is consistently demonstrated to be wrong, and we are consequently surprised when others do not act in accordance with the “innate” traits we’ve endowed them with.&lt;/p&gt;
    &lt;p&gt;20. Influence of Stress (Including Breaking Points)&lt;lb/&gt;Stress causes both mental and physiological responses and tends to amplify the other biases. Almost all human mental biases become worse in the face of stress as the body goes into a fight-or-flight response, relying purely on instinct without the emergency brake of Daniel Kahneman’s “System 2” type of reasoning. Stress causes hasty decisions, immediacy, and a fallback to habit, thus giving rise to the elite soldiers’ motto: “In the thick of battle, you will not rise to the level of your expectations, but fall to the level of your training.”&lt;/p&gt;
    &lt;p&gt;21. Survivorship Bias&lt;lb/&gt;A major problem with historiography – our interpretation of the past – is that history is famously written by the victors. We do not see what Nassim Taleb calls the “silent grave” – the lottery ticket holders who did not win. Thus, we over-attribute success to things done by the successful agent rather than to randomness or luck, and we often learn false lessons by exclusively studying victors without seeing all of the accompanying losers who acted in the same way but were not lucky enough to succeed.&lt;/p&gt;
    &lt;p&gt;22. Tendency to Want to Do Something (Fight/Flight, Intervention, Demonstration of Value, etc.)&lt;lb/&gt;We might term this Boredom Syndrome: Most humans have the tendency to need to act, even when their actions are not needed. We also tend to offer solutions even when we do not have knowledge to solve the problem.&lt;/p&gt;
    &lt;p&gt;23. Falsification / Confirmation Bias&lt;lb/&gt;What a man wishes, he also believes. Similarly, what we believe is what we choose to see. This is commonly referred to as the confirmation bias. It is a deeply ingrained mental habit, both energy-conserving and comfortable, to look for confirmations of long-held wisdom rather than violations. Yet the scientific process – including hypothesis generation, blind testing when needed, and objective statistical rigor – is designed to root out precisely the opposite, which is why it works so well when followed.&lt;/p&gt;
    &lt;p&gt;The modern scientific enterprise operates under the principle of falsification: A method is termed scientific if it can be stated so that a certain defined result would cause it to be proved false. Pseudo-knowledge and pseudo-science operate and propagate by being unfalsifiable. As with astrology, we cannot prove them either correct or incorrect because the conditions under which they would be shown false are never stated.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fs.blog/mental-models/"/><published>2026-01-23T21:08:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46738853</id><title>Wilson Lin on FastRender: a browser built by parallel agents</title><updated>2026-01-24T10:42:29.662435+00:00</updated><content>&lt;doc fingerprint="8f7050574dc8b14e"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Wilson Lin on FastRender: a browser built by thousands of parallel agents&lt;/head&gt;
    &lt;p&gt;23rd January 2026&lt;/p&gt;
    &lt;p&gt;Last week Cursor published Scaling long-running autonomous coding, an article describing their research efforts into coordinating large numbers of autonomous coding agents. One of the projects mentioned in the article was FastRender, a web browser they built from scratch using their agent swarms. I wanted to learn more so I asked Wilson Lin, the engineer behind FastRender, if we could record a conversation about the project. That 47 minute video is now available on YouTube. I’ve included some of the highlights below.&lt;/p&gt;
    &lt;p&gt;See my previous post for my notes and screenshots from trying out FastRender myself.&lt;/p&gt;
    &lt;head rend="h4"&gt;What FastRender can do right now&lt;/head&gt;
    &lt;p&gt;We started the conversation with a demo of FastRender loading different pages (03:15). The JavaScript engine isn’t working yet so we instead loaded github.com/wilsonzlin/fastrender, Wikipedia and CNN—all of which were usable, if a little slow to display.&lt;/p&gt;
    &lt;p&gt;JavaScript had been disabled by one of the agents, which decided to add a feature flag! 04:02&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;JavaScript is disabled right now. The agents made a decision as they were currently still implementing the engine and making progress towards other parts... they decided to turn it off or put it behind a feature flag, technically.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h4"&gt;From side-project to core research&lt;/head&gt;
    &lt;p&gt;Wilson started what become FastRender as a personal side-project to explore the capabilities of the latest generation of frontier models—Claude Opus 4.5, GPT-5.1, and GPT-5.2. 00:56&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;FastRender was a personal project of mine from, I’d say, November. It was an experiment to see how well frontier models like Opus 4.5 and back then GPT-5.1 could do with much more complex, difficult tasks.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A browser rendering engine was the ideal choice for this, because it’s both extremely ambitious and complex but also well specified. And you can visually see how well it’s working! 01:57&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;As that experiment progressed, I was seeing better and better results from single agents that were able to actually make good progress on this project. And at that point, I wanted to see, well, what’s the next level? How do I push this even further?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Once it became clear that this was an opportunity to try multiple agents working together it graduated to an official Cursor research project, and available resources were amplified.&lt;/p&gt;
    &lt;p&gt;The goal of FastRender was never to build a browser to compete with the likes of Chrome. 41:52&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We never intended for it to be a production software or usable, but we wanted to observe behaviors of this harness of multiple agents, to see how they could work at scale.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The great thing about a browser is that it has such a large scope that it can keep serving experiments in this space for many years to come. JavaScript, then WebAssembly, then WebGPU... it could take many years to run out of new challenges for the agents to tackle.&lt;/p&gt;
    &lt;head rend="h4"&gt;Running thousands of agents at once&lt;/head&gt;
    &lt;p&gt;The most interesting thing about FastRender is the way the project used multiple agents working in parallel to build different parts of the browser. I asked how many agents were running at once: 05:24&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;At the peak, when we had the stable system running for one week continuously, there were approximately 2,000 agents running concurrently at one time. And they were making, I believe, thousands of commits per hour.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The project has nearly 30,000 commits!&lt;/p&gt;
    &lt;p&gt;How do you run 2,000 agents at once? They used really big machines. 05:56&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The simple approach we took with the infrastructure was to have a large machine run one of these multi-agent harnesses. Each machine had ample resources, and it would run about 300 agents concurrently on each. This was able to scale and run reasonably well, as agents spend a lot of time thinking, and not just running tools.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;At this point we switched to a live demo of the harness running on one of those big machines (06:32). The agents are arranged in a tree structure, with planning agents firing up tasks and worker agents then carrying them out. 07:14&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This cluster of agents is working towards building out the CSS aspects of the browser, whether that’s parsing, selector engine, those features. We managed to push this even further by splitting out the browser project into multiple instructions or work streams and have each one run one of these harnesses on their own machine, so that was able to further parallelize and increase throughput.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But don’t all of these agents working on the same codebase result in a huge amount of merge conflicts? Apparently not: 08:21&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We’ve noticed that most commits do not have merge conflicts. The reason is the harness itself is able to quite effectively split out and divide the scope and tasks such that it tries to minimize the amount of overlap of work. That’s also reflected in the code structure—commits will be made at various times and they don’t tend to touch each other at the same time.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This appears to be the key trick for unlocking benefits from parallel agents: if planning agents do a good enough job of breaking up the work into non-overlapping chunks you can bring hundreds or even thousands of agents to bear on a problem at once.&lt;/p&gt;
    &lt;p&gt;Surprisingly, Wilson found that GPT-5.1 and GPT-5.2 were a better fit for this work than the coding specialist GPT-5.1-Codex: 17:28&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Some initial findings were that the instructions here were more expansive than merely coding. For example, how to operate and interact within a harness, or how to operate autonomously without interacting with the user or having a lot of user feedback. These kinds of instructions we found worked better with the general models.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I asked what the longest they’ve seen this system run without human intervention: 18:28&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;So this system, once you give an instruction, there’s actually no way to steer it, you can’t prompt it, you’re going to adjust how it goes. The only thing you can do is stop it. So our longest run, all the runs are basically autonomous. We don’t alter the trajectory while executing. [...]&lt;/p&gt;
      &lt;p&gt;And so the longest at the time of the post was about a week and that’s pretty close to the longest. Of course the research project itself was only about three weeks so you know we probably can go longer.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h4"&gt;Specifications and feedback loops&lt;/head&gt;
    &lt;p&gt;An interesting aspect of this project design is feedback loops. For agents to work autonomously for long periods of time they need as much useful context about the problem they are solving as possible, combined with effective feedback loops to help them make decisions.&lt;/p&gt;
    &lt;p&gt;The FastRender repo uses git submodules to include relevant specifications, including csswg-drafts, tc39-ecma262 for JavaScript, whatwg-dom, whatwg-html and more. 14:06&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Feedback loops to the system are very important. Agents are working for very long periods continuously, and without guardrails and feedback to know whether what they’re doing is right or wrong it can have a big impact over a long rollout. Specs are definitely an important part—you can see lots of comments in the code base that AI wrote referring specifically to specs that they found in the specs submodules.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;GPT-5.2 is a vision-capable model, and part of the feedback loop for FastRender included taking screenshots of the rendering results and feeding those back into the model: 16:23&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In the earlier evolution of this project, when it was just doing the static renderings of screenshots, this was definitely a very explicit thing we taught it to do. And these models are visual models, so they do have that ability. We have progress indicators to tell it to compare the diff against a golden sample.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The strictness of the Rust compiler helped provide a feedback loop as well: 15:52&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The nice thing about Rust is you can get a lot of verification just from compilation, and that is not as available in other languages.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h4"&gt;The agents chose the dependencies&lt;/head&gt;
    &lt;p&gt;We talked about the Cargo.toml dependencies that the project had accumulated, almost all of which had been selected by the agents themselves.&lt;/p&gt;
    &lt;p&gt;Some of these, like Skia for 2D graphics rendering or HarfBuzz for text shaping, were obvious choices. Others such as Taffy felt like they might go against the from-scratch goals of the project, since that library implements CSS flexbox and grid layout algorithms directly. This was not an intended outcome. 27:53&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Similarly these are dependencies that the agent picked to use for small parts of the engine and perhaps should have actually implemented itself. I think this reflects on the importance of the instructions, because I actually never encoded specifically the level of dependencies we should be implementing ourselves.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The agents vendored in Taffy and applied a stream of changes to that vendored copy. 31:18&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It’s currently vendored. And as the agents work on it, they do make changes to it. This was actually an artifact from the very early days of the project before it was a fully fledged browser... it’s implementing things like the flex and grid layers, but there are other layout methods like inline, block, and table, and in our new experiment, we’re removing that completely.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The inclusion of QuickJS despite the presence of a home-grown ecma-rs implementation has a fun origin story: 35:15&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I believe it mentioned that it pulled in the QuickJS because it knew that other agents were working on the JavaScript engine, and it needed to unblock itself quickly. [...]&lt;/p&gt;
      &lt;p&gt;It was like, eventually, once that’s finished, let’s remove it and replace with the proper engine.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I love how similar this is to the dynamics of a large-scale human engineering team, where you could absolutely see one engineer getting frustrated at another team not having delivered yet and unblocking themselves by pulling in a third-party library.&lt;/p&gt;
    &lt;head rend="h4"&gt;Intermittent errors are OK, actually&lt;/head&gt;
    &lt;p&gt;Here’s something I found really surprising: the agents were allowed to introduce small errors into the codebase as they worked! 39:42&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One of the trade-offs was: if you wanted every single commit to be a hundred percent perfect, make sure it can always compile every time, that might be a synchronization bottleneck. [...]&lt;/p&gt;
      &lt;p&gt;Especially as you break up the system into more modularized aspects, you can see that errors get introduced, but small errors, right? An API change or some syntax error, but then they get fixed really quickly after a few commits. So there’s a little bit of slack in the system to allow these temporary errors so that the overall system can continue to make progress at a really high throughput. [...]&lt;/p&gt;
      &lt;p&gt;People may say, well, that’s not correct code. But it’s not that the errors are accumulating. It’s a stable rate of errors. [...] That seems like a worthwhile trade-off.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If you’re going to have thousands of agents working in parallel optimizing for throughput over correctness turns out to be a strategy worth exploring.&lt;/p&gt;
    &lt;head rend="h4"&gt;A single engineer plus a swarm of agents in January 2026&lt;/head&gt;
    &lt;p&gt;The thing I find most interesting about FastRender is how it demonstrates the extreme edge of what a single engineer can achieve in early 2026 with the assistance of a swarm of agents.&lt;/p&gt;
    &lt;p&gt;FastRender may not be a production-ready browser, but it represents over a million lines of Rust code, written in a few weeks, that can already render real web pages to a usable degree.&lt;/p&gt;
    &lt;p&gt;A browser really is the ideal research project to experiment with this new, weirdly shaped form of software engineering.&lt;/p&gt;
    &lt;p&gt;I asked Wilson how much mental effort he had invested in browser rendering compared to agent co-ordination. 11:34&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The browser and this project were co-developed and very symbiotic, only because the browser was a very useful objective for us to measure and iterate the progress of the harness. The goal was to iterate on and research the multi-agent harness—the browser was just the research example or objective.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;FastRender is effectively using a full browser rendering engine as a “hello world” exercise for multi-agent coordination!&lt;/p&gt;
    &lt;head rend="h2"&gt;More recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First impressions of Claude Cowork, Anthropic's general agent - 12th January 2026&lt;/item&gt;
      &lt;item&gt;My answers to the questions I posed about porting open source code with LLMs - 11th January 2026&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://simonwillison.net/2026/Jan/23/fastrender/"/><published>2026-01-23T22:28:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46740028</id><title>Noora Health (YC W14) Is Hiring AI/ML Engineer</title><updated>2026-01-24T10:42:29.220824+00:00</updated><content>&lt;doc fingerprint="2e02a1e67629ad2b"&gt;
  &lt;main&gt;
    &lt;p&gt;Training patients and their families with health skills&lt;/p&gt;
    &lt;p&gt;WHO WE ARE&lt;/p&gt;
    &lt;p&gt;Noora Health India Private Limited is a key partner in Noora Health’s mission is to improve outcomes and strengthen health systems by equipping family caregivers with the skills they need to care for their loved ones. They develop content, technology platforms, new products, and strengthen other operational functions that support the scale and impact of Noora Health’s programs.&lt;/p&gt;
    &lt;p&gt;Founded in 2014, Noora Health turns hospital hallways and waiting rooms into classrooms by tapping into the most compassionate resources available for the patient’s care: their own family.&lt;/p&gt;
    &lt;p&gt;With support from governments and partners in India, Bangladesh, Indonesia, and Nepal, Noora Health has trained more than 43 million caregivers and patients across 12,800+ facilities using their flagship caregiver education and training curriculum, the Care Companion Program (CCP).&lt;/p&gt;
    &lt;p&gt;In a cohort of patients, the CCP reduced post-surgical cardiac complications by 71%, maternal complications by 12%, newborn complications by 16%, and newborn mortality by 18%.&lt;/p&gt;
    &lt;p&gt;Noora Health is an Audacious Project Grantee and received the Skoll Foundation Award for Social Innovation. To learn more, watch our TED Talk, Skoll feature, or read about our partnership with the World Health Organization.&lt;/p&gt;
    &lt;p&gt;WHAT YOU WILL DO&lt;/p&gt;
    &lt;p&gt;WHO WE ARE LOOKING FOR&lt;/p&gt;
    &lt;p&gt;WHAT WE VALUE&lt;/p&gt;
    &lt;p&gt;We value diversity, equity, and inclusion, and we understand the value of developing a team with different perspectives, educational backgrounds, and life experiences. We prioritize diversity within our team, and we welcome candidates from all gender identities, castes, religious practices, sexual orientations, and abilities — among many others.&lt;/p&gt;
    &lt;p&gt;We encourage people from all backgrounds to apply.&lt;/p&gt;
    &lt;p&gt;HOW TO APPLY&lt;/p&gt;
    &lt;p&gt;Please submit your application using this link.&lt;/p&gt;
    &lt;p&gt;Noora Health trains patient families with high-impact health skills that improve outcomes and save lives. Our model provides basic yet vital care knowledge through trusted providers by creating a scalable program for caregiving education and training within the established healthcare system. This model expands the care umbrella to include those closest to the patient — their family and community. Noora Health has trained over 30 million caregivers and patients across over 12,400 healthcare facilities in India, Bangladesh, Indonesia, and Nepal. The program reduces cardiac surgery complications by 71%, newborn readmissions by 56%, and neonatal mortality by 18%. By 2028, Noora Health will expand to reach over 70 million caregivers and patients.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/noora-health/jobs/2B4RxLG-ai-ml-engineer"/><published>2026-01-24T01:00:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46740029</id><title>Comma openpilot – Open source driver-assistance</title><updated>2026-01-24T10:42:28.968167+00:00</updated><content>&lt;doc fingerprint="c7717bc638b3d565"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;comma four&lt;/head&gt;
    &lt;head rend="h2"&gt;An AI upgrade for your car&lt;/head&gt;
    &lt;p&gt; Lane&lt;lb/&gt;centering&lt;/p&gt;
    &lt;p&gt;centering&lt;/p&gt;
    &lt;p&gt; Dashcam&lt;lb/&gt;recording&lt;/p&gt;
    &lt;p&gt;recording&lt;/p&gt;
    &lt;p&gt; Adaptive&lt;lb/&gt;cruise&lt;/p&gt;
    &lt;p&gt;cruise&lt;/p&gt;
    &lt;p&gt; OTA&lt;lb/&gt;updates&lt;/p&gt;
    &lt;p&gt;updates&lt;/p&gt;
    &lt;p&gt; Lane&lt;lb/&gt;changing&lt;/p&gt;
    &lt;p&gt;changing&lt;/p&gt;
    &lt;p&gt; 360° vision&lt;/p&gt;
    &lt;head rend="h1"&gt;Buy it, plug it in, and engage.&lt;/head&gt;
    &lt;head rend="h3"&gt;comma four works with the car you already drive. It's active driver assistance for your Toyota, Hyundai, Ford, and more.&lt;/head&gt;
    &lt;head rend="h1"&gt;openpilot can drive for hours without driver action.&lt;/head&gt;
    &lt;head rend="h1"&gt;It works on 325+ car models from 27 brands. Is your car supported?&lt;/head&gt;
    &lt;p&gt;Hyundai Sonata&lt;/p&gt;
    &lt;p&gt;2020-23&lt;/p&gt;
    &lt;p&gt;Hyundai Palisade&lt;/p&gt;
    &lt;p&gt;2020-22&lt;/p&gt;
    &lt;p&gt;Kia Niro EV&lt;/p&gt;
    &lt;p&gt;2019-23&lt;/p&gt;
    &lt;p&gt;Lexus ES&lt;/p&gt;
    &lt;p&gt;2019-22&lt;/p&gt;
    &lt;p&gt;Toyota Corolla&lt;/p&gt;
    &lt;p&gt;2020-22&lt;/p&gt;
    &lt;p&gt;Toyota Rav4&lt;/p&gt;
    &lt;p&gt;2019-22&lt;/p&gt;
    &lt;p&gt;Careers&lt;/p&gt;
    &lt;p&gt;We are hiring&lt;/p&gt;
    &lt;head rend="h1"&gt;Join us in building the future.&lt;/head&gt;
    &lt;p&gt;/01 product&lt;/p&gt;
    &lt;p&gt;/02 autonomy&lt;/p&gt;
    &lt;p&gt;/03 operations&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://comma.ai"/><published>2026-01-24T01:00:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46740748</id><title>"People are going to stop and ask you, 'How can I help?' Let them."</title><updated>2026-01-24T10:42:28.373130+00:00</updated><content>&lt;doc fingerprint="5776d1cd93b7c751"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;'Let them.' The small bit of advice that made a big difference to a grieving widow&lt;/head&gt;
    &lt;head rend="h4"&gt;'Let them.' The small bit of advice that made a big difference to a grieving widow&lt;/head&gt;
    &lt;p&gt;In 2020, Connie Sherburne's husband of 31 years, Peter, died in a crash while piloting their small plane.&lt;/p&gt;
    &lt;p&gt;Sherburne, a practical person, immediately focused on what needed to be done.&lt;/p&gt;
    &lt;p&gt;"I went home that evening, and the next morning, I got up and I thought, 'Hit the ground running. You've got all this to take care of.'"&lt;/p&gt;
    &lt;p&gt;She drove to their insurance company in Escondido, Calif., to transfer the insurance for Peter's truck into her name. Because of the pandemic, the office was staffed by just one person. The woman opened the door to let Sherburne inside, and they sat across from each other at a desk.&lt;/p&gt;
    &lt;p&gt;"It didn't take her but a few minutes to take care of why I was there," Sherburne recalled.&lt;/p&gt;
    &lt;p&gt;"When she got done, she stopped and she looked at me across her desk, and she made sure that I was looking at her — that she had my full attention."&lt;/p&gt;
    &lt;p&gt;"And she said, 'OK, so now that we've finished with that, people are going to stop and ask you, "How can I help?"' And then she gave this pregnant pause, and she said, 'Let them.'"&lt;/p&gt;
    &lt;p&gt;Sherburne took in the advice, absorbing the moment. She wasn't the kind of person to reach out to others for help.&lt;/p&gt;
    &lt;p&gt;"But because she said it with such force, it really, really made sense to me," Sherburne said.&lt;/p&gt;
    &lt;p&gt;As soon as she got home, she realized that she did need help. The firewood she used to heat her home was running low, and winter was around the corner. Chopping wood was something Peter had always done. But this time, she asked a friend to take care of it.&lt;/p&gt;
    &lt;p&gt;"So many, many people did little things and big things to help me," Sherburne said. "One of the neighbors actually cooked for me for four years — dinners — and her husband delivered the dinners to me."&lt;/p&gt;
    &lt;p&gt;Sherburne says she would have never reached out for support if not for the advice of the woman at the insurance company.&lt;/p&gt;
    &lt;p&gt;"In the back of my mind, I kept hearing her voice, you know, 'Let them.'"&lt;/p&gt;
    &lt;p&gt;A few years later, Sherburne went back to the insurance office to tell the woman how deeply her words had affected her. But the agent didn't work there anymore.&lt;/p&gt;
    &lt;p&gt;"So I just wanted to tell her how much that meant to me," Sherburne said.&lt;/p&gt;
    &lt;p&gt;"It was such a little thing for this woman just to say that to me. But she didn't realize what a huge thing it was going to be to help me through all this."&lt;/p&gt;
    &lt;p&gt;My Unsung Hero is also a podcast — new episodes are released every Tuesday. To share the story of your unsung hero with the Hidden Brain team, record a voice memo on your phone and send it to myunsunghero@hiddenbrain.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.npr.org/2026/01/20/nx-s1-5683170/let-them-the-small-bit-of-advice-that-made-a-big-difference-to-a-grieving-widow"/><published>2026-01-24T03:20:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46741482</id><title>80386 Multiplication and Division</title><updated>2026-01-24T10:42:28.277216+00:00</updated><content>&lt;doc fingerprint="877cd3abcb32029b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;80386 Multiplication and Division&lt;/head&gt;
    &lt;p&gt;When Intel released the 80386 in October 1985, it marked a watershed moment for personal computing. The 386 was the first 32-bit x86 processor, increasing the register width from 16 to 32 bits and vastly expanding the address space compared to its predecessors. This wasn't just an incremental upgrade—it was the foundation that would carry the PC architecture for decades to come.&lt;/p&gt;
    &lt;p&gt;The timing was significant. By the mid-1980s, the IBM PC had established x86 as the dominant PC architecture, but the 16-bit 8086/286 processors were hitting their limits. Memory was constrained to 1MB (or 16MB with the 286's limited protected mode). Competing 32-bit architectures like the Motorola 68020 threatened Intel's dominance. The 386 was Intel's answer: full 32-bit computing with backward compatibility for the massive library of existing DOS software.&lt;/p&gt;
    &lt;p&gt;The 386 introduced important and long-lasting x86 features: a flat 4GB address space, virtual memory with paging, and a protected mode that actually worked. It would go on to run Windows 3.0, Windows 95, early Linux, and countless other operating systems that shaped modern computing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Faster arithmetic&lt;/head&gt;
    &lt;p&gt;In addition to its architectural advances, the 386 delivered a major jump in arithmetic performance. On the earlier 8086, multiplication and division were slow — 16-bit multiplication typically required 120–130 cycles, with division taking even longer at over 150 cycles. The 286 significantly improved on this by introducing faster microcode routines and modest hardware enhancements.&lt;/p&gt;
    &lt;p&gt;The 386 pushed performance further with dedicated hardware that processes multiplication and division at the rate of one bit per cycle, combined with a native 32-bit datapath width. The microcode still orchestrates the operation, but the heavy lifting happens in specialized datapath logic that advances every cycle.&lt;/p&gt;
    &lt;p&gt;Here are the actual cycle counts from the Intel 386 Programmer's Reference Manual:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Instruction&lt;/cell&gt;
        &lt;cell role="head"&gt;8-bit&lt;/cell&gt;
        &lt;cell role="head"&gt;16-bit&lt;/cell&gt;
        &lt;cell role="head"&gt;32-bit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;MUL&lt;/cell&gt;
        &lt;cell&gt;9-14&lt;/cell&gt;
        &lt;cell&gt;9-22&lt;/cell&gt;
        &lt;cell&gt;9-38&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;IMUL&lt;/cell&gt;
        &lt;cell&gt;9-14&lt;/cell&gt;
        &lt;cell&gt;9-22&lt;/cell&gt;
        &lt;cell&gt;9-38&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DIV&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;38&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;IDIV&lt;/cell&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;27&lt;/cell&gt;
        &lt;cell&gt;43&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The ranges for MUL/IMUL reflect an "early-out" optimization—the loop exits early when the remaining multiplier bits are all zeros (or all ones for signed). Division has no early-out, so cycle counts are fixed at roughly &lt;code&gt;width + overhead&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;To save silicon, the 386 reuses the main ALU for the per-iteration add/subtract work rather than having a separate multiplier unit. The microcode controls the iteration, while dedicated datapath logic handles the shifting and loop termination. Let's look at how these algorithms work.&lt;/p&gt;
    &lt;head rend="h2"&gt;Add-and-shift multiplication&lt;/head&gt;
    &lt;p&gt;The classic multiplication algorithm in processors is the Booth algorithm. However, the 80386 does not use that. Instead, an "add-and-shift" multiplication algorithm is used. This is similar to grade-school long multiplication. The difference is that instead of moving from lower digits to higher, we shift to the right. Here's the data layout:&lt;/p&gt;
    &lt;p&gt;Three key internal registers participate in multiplication: MULTMP, TMPB, and SIGMA. A notable challenge is that x86 instructions support 8-bit, 16-bit, and 32-bit operands. Consistent with the design philosophy of the 8086, the 386 achieves this flexibility by reusing the same registers and microcode routines for all operand sizes. In most cases, the identical hardware and microcode sequence accommodate different widths seamlessly. The diagram above shows how, for example, the result of multiplying two 16-bit numbers is arranged within a 32-bit product: it occupies the lower half of the SIGMA register and the upper half of TMPB.&lt;/p&gt;
    &lt;p&gt;Here is the multiplication algorithm in pseudocode:&lt;/p&gt;
    &lt;code&gt;1: COUNTR = width-1
2: while (true):
3:   if (TMPB[0]) SIGMA &amp;lt;= SIGMA + MULTMP
4:   {SIGMA, TMPB} &amp;gt;&amp;gt;= 1      // arithmetic shift for signed
5:   if (--COUNTR==0) break
6:   if (remaining TMPB bits are all 0 or all 1 for signed) break
7: {SIGMA, TMPB} &amp;gt;&amp;gt;= COUNTR   // compensate for early exit
8: correction for signed multiplication
&lt;/code&gt;
    &lt;p&gt;Shifting to the right rather than the left simplifies the hardware circuits. Line 6 implements the important "early-out" optimization, which means the loop can terminate early if the remaining multiplier bits are all zeros—or all ones, in the case of signed multiplication. When this happens, line 7 adjusts for the early exit by shifting the accumulated result right by the number of remaining COUNTR bits.&lt;/p&gt;
    &lt;p&gt;Lines 1–7 fully describe unsigned multiplication. To extend this to signed multiplication, only a few tweaks are needed: use arithmetic (not logical) shifts on lines 4 and 7, and, as a final correction in line 8, subtract the multiplicand from the upper product register (SIGMA) if the multiplier was negative. For a deeper dive into the mathematics, see college-level computer organization resources such as this one.&lt;/p&gt;
    &lt;p&gt;The 80386 multiplication microcode closely mirrors the algorithm described above, and shows both the timing and the likely underlying hardware involved. The microcode routine shown here handles register-based multiplication—both unsigned and signed—and supports all three operand sizes: 8, 16, and 32 bits. Other forms, such as multiplying with a memory operand, are implemented similarly.&lt;/p&gt;
    &lt;p&gt;Before we examine the code, it’s helpful to quickly review the 80386’s microcode syntax and conventions. While the 8086 used 21-bit micro-operations, the 80386 expanded these to 37 bits, adding fields to control more complex hardware functionality. Moves are written as &lt;code&gt;src-&amp;gt;dest&lt;/code&gt;, which simply means copying data from one register to another. The &lt;code&gt;alujmp&lt;/code&gt; field directs either the ALU (using &lt;code&gt;src&lt;/code&gt; and &lt;code&gt;alu_src&lt;/code&gt; as inputs) or the microcode control flow, handling everything from arithmetic to jumps to indirect operations (&lt;code&gt;alu_src&lt;/code&gt; as the jump target). Pay special attention to the &lt;code&gt;RPT&lt;/code&gt; keyword found on the third line of the upcoming listing: this signals the microcode sequencer to repeatedly execute a micro-instruction, decrementing the COUNTR register each time, and continuing until COUNTR reaches zero, i.e. looping for COUNTR+1 iterations.&lt;/p&gt;
    &lt;code&gt;; MUL/IMUL r
; src     dest    alu_src        alujmp  uop sub busop
DSTREG -&amp;gt; MULTMP  BITS_V         LDCNTR          ; MULTMP=r (multiplicand), COUNTR=width-1
eAX_AL -&amp;gt; TMPB    0              PASS2           ; TMPB=multiplier (AL/AX/EAX)
SIGMA             TMPB           IMUL3   RPT DLY ; hardware mult loop with early-out 
SIGMA                            PASS            ; pass through SIGMA
COUNTR -&amp;gt; TMPD                                   ; save remaining COUNTR
RESULT -&amp;gt; TMPC    TMPD           LDBSR8          ; load shift count: right shift, COUNTR
SIGMA  -&amp;gt; TMPD    TMPC           SHIFT           ; shift {SIGMA,RESULT} to get low result
SIGMA  -&amp;gt; eAX_AL  TMPD           MULFIX          ; write low result, set flags, signed mult correction
SIGMA             TMPD           SHIFT   RNI     ; shift {0,ProdU} to get high result
SIGMA  -&amp;gt; eDX_AH                                 ; write high result
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;RESULT&lt;/code&gt; register is used by both multiplication and division. For multiplication, it accumulates the lower half of the product as bits shift right out of TMPB during the loop. &lt;code&gt;MULFIX&lt;/code&gt; is the correction for signed multiplication on pseudocode line 8.&lt;/p&gt;
    &lt;head rend="h3"&gt;Other variants&lt;/head&gt;
    &lt;p&gt;The 386 introduced two new forms of IMUL beyond the original single-operand form:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Two-operand: &lt;code&gt;IMUL reg, r/m&lt;/code&gt;- multiplies reg by r/m, stores in reg (single-width result)&lt;/item&gt;
      &lt;item&gt;Three-operand: &lt;code&gt;IMUL reg, r/m, imm&lt;/code&gt;- multiplies r/m by immediate, stores in reg (single-width result)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These variants are interesting because they only produce a single-width result (discarding the upper half), making them faster for common cases where overflow isn't expected. The microcode for these uses a slightly different entry point that skips writing the upper result to EDX/DX/AH.&lt;/p&gt;
    &lt;head rend="h2"&gt;Division&lt;/head&gt;
    &lt;p&gt;80386 uses the standard non-restoring division algorithm for division. Here's the data layout:&lt;/p&gt;
    &lt;p&gt;The dividend is {SIGMA, DIVTMP} (max 64 bits), while the divisor is TMPB (max 32 bits). Each iteration shifts the dividend left by one bit and either adds or subtracts the divisor, building up the quotient in RESULT one bit at a time.&lt;/p&gt;
    &lt;code&gt;1: do:                               // loop body is DIV7
2:     {SIGMA,DIVTMP} &amp;lt;&amp;lt;= 1;
3:     if (SIGMA &amp;lt; 0) SIGMA += TMPB;
4:     else           SIGMA -= TMPB;
5:     RESULT = (RESULT &amp;lt;&amp;lt; 1) | (SIGMA &amp;gt;= 0 ? 1 : 0)
6:     COUNTR--;
7: while (COUNTR &amp;gt; 0)
8: if (SIGMA &amp;lt; 0) SIGMA += TMPB;     // DIV5
&lt;/code&gt;
    &lt;p&gt;Let's look at the division routine (&lt;code&gt;DIV r&lt;/code&gt; at F6.6/F7.6) directly.&lt;/p&gt;
    &lt;code&gt;; DIV r
eAX_AL -&amp;gt; DIVTMP  BITS_V         LDCNTR          ; DIVTMP = lower half of dividend, COUNTR=width-1
eDX_AH                           PASS            ; SIGMA = upper half of dividend
DSTREG -&amp;gt; TMPB                                   ; TMPB = divisor
SIGMA             TMPB            DIV7   RPT DLY ; Loop: dividend={SIGMA,DIVTMP}, divisor=TMPB
SIGMA             TMPB            DIV5           ; Final correction
SIGMA                            PASS            ; Preserve remainder through ALU
RESULT -&amp;gt; eAX_AL                         RNI     ; accumulator = quotient 
SIGMA  -&amp;gt; eDX_AH                                 ; upper-half reg = remainder
&lt;/code&gt;
    &lt;p&gt;DIV7 and DIV5 are both single-cycle micro-operations. DIV7 implements the core of the division loop, corresponding to pseudocode lines 2–5 (excluding the COUNTR decrement). With each iteration, DIV7 updates SIGMA (the remainder) and RESULT (the quotient accumulator). The loop is controlled by the RPT instruction, which keeps the sequencer repeatedly executing DIV7 for COUNTR+1 iterations—there’s no early exit for division. After completing the main loop, DIV5 performs the final correction required by the non-restoring division algorithm (pseudocode line 8).&lt;/p&gt;
    &lt;head rend="h3"&gt;Signed division (IDIV)&lt;/head&gt;
    &lt;p&gt;IDIV is more complex than DIV because it must handle signs. The approach is:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Convert dividend and divisor to absolute values&lt;/item&gt;
      &lt;item&gt;Perform unsigned division&lt;/item&gt;
      &lt;item&gt;Adjust signs of quotient and remainder&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here's the IDIV microcode:&lt;/p&gt;
    &lt;code&gt;; IDIV r
-1                BITS_V         ADD             ; COUNTR=width-2
SIGMA  -&amp;gt; COUNTR
eDX_AH                           PASS            ; SIGMA=upper dividend
eAX_AL -&amp;gt; DIVTMP                                 ; DIVTMP=lower dividend
DSTREG -&amp;gt; TMPB                                   ; TMPB=divisor
SIGMA             TMPB           PREDIV          ; |dividend|divisor|, save signs, first iteration
SIGMA             TMPB            DIV7   RPT DLY ; main division loop
SIGMA             TMPB            DIV5           ; non-restoring correction
SIGMA             TMPB           IDIV1           ; correct remainder sign
SIGMA                            PASS
SIGMA  -&amp;gt; TMPB                                   ; save remainder
RESULT                           IDIV2           ; correct quotient sign -&amp;gt; SIGMA
TMPB   -&amp;gt; eDX_AH                         RNI     ; write remainder
SIGMA  -&amp;gt; eAX_AL                                 ; write quotient
&lt;/code&gt;
    &lt;p&gt;The key micro-ops are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PREDIV: Computes absolute values of dividend and divisor, saves their signs in internal flip-flops, and performs the first division iteration&lt;/item&gt;
      &lt;item&gt;IDIV1: Corrects the remainder's sign (remainder has same sign as dividend)&lt;/item&gt;
      &lt;item&gt;IDIV2: Corrects the quotient's sign (negative if operand signs differ)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This explains why IDIV takes 5 more cycles than DIV - the extra cycles handle sign computation and correction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Additional notes&lt;/head&gt;
    &lt;p&gt;One of the biggest hurdles in deciphering CPUs is interpreting the role and meaning of each micro-operation and constant. Their interdependence often makes the process both challenging and fascinating. Consider BITS_V: at first glance, seeing it used in LDCNTR and loop logic, you might assume it simply represents the instruction’s bit width—such as 8, 16, or 32—meaning the RPT instruction would run for that number of COUNTR cycles. This approach seems to suffice for MUL and DIV. However, when applied to IDIV and AAM, the microcode repeatedly failed to function as expected. After many hours spent troubleshooting, I finally came across a clue in a seemingly unrelated part of the microcode:&lt;/p&gt;
    &lt;code&gt;; PUSHAd
ESP               BITS_V         SUB         DLY      0    
SIGMA     INDSTK  -1             ADD             IN=+      
...
SIGMA  -&amp;gt; eSP                                DLY           
&lt;/code&gt;
    &lt;p&gt;This finally gave me the hint that BITS_V is &lt;code&gt;width-1&lt;/code&gt; instead of &lt;code&gt;width&lt;/code&gt;. Here PUSHA pushes 8 registers to the stack, so SP should be subtracted by &lt;code&gt;8*2=16&lt;/code&gt; or &lt;code&gt;8*4=32&lt;/code&gt; bytes. The existence of &lt;code&gt;SIGMA-1&lt;/code&gt; (SIGMA, -1, ADD) after &lt;code&gt;SIGMA=ESP-BITS_V&lt;/code&gt; (ESP, BITS_V, SUB) clearly indicates that BITS_V is one less than 16 or 32.&lt;/p&gt;
    &lt;head rend="h2"&gt;Comparison with modern CPUs&lt;/head&gt;
    &lt;p&gt;The 386's iterative approach to multiplication and division was state-of-the-art for its time, but modern x86 processors have moved far beyond it:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Era&lt;/cell&gt;
        &lt;cell role="head"&gt;Processor&lt;/cell&gt;
        &lt;cell role="head"&gt;32-bit MUL&lt;/cell&gt;
        &lt;cell role="head"&gt;32-bit DIV&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1985&lt;/cell&gt;
        &lt;cell&gt;80386&lt;/cell&gt;
        &lt;cell&gt;9-38 cycles&lt;/cell&gt;
        &lt;cell&gt;38 cycles&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1993&lt;/cell&gt;
        &lt;cell&gt;Pentium&lt;/cell&gt;
        &lt;cell&gt;10 cycles&lt;/cell&gt;
        &lt;cell&gt;41 cycles&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2000s&lt;/cell&gt;
        &lt;cell&gt;Core 2&lt;/cell&gt;
        &lt;cell&gt;3-4 cycles&lt;/cell&gt;
        &lt;cell&gt;17-41 cycles&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;2020s&lt;/cell&gt;
        &lt;cell&gt;Zen 3/Alder Lake&lt;/cell&gt;
        &lt;cell&gt;3-4 cycles&lt;/cell&gt;
        &lt;cell&gt;13-19 cycles&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Modern CPUs use dedicated multiplier arrays (often Booth-encoded Wallace trees) that can multiply 64-bit numbers in just a few cycles. Division remains slower because it's inherently sequential - each quotient bit depends on the previous remainder. However, modern CPUs use radix-4 or radix-16 division (computing 2-4 bits per cycle) and sophisticated prediction to speed things up.&lt;/p&gt;
    &lt;p&gt;The 386's "one bit per cycle" approach is elegant in its simplicity and its reuse of the main ALU. For an FPGA implementation, this microcode-driven design is actually quite practical - it minimizes hardware while still achieving reasonable performance.&lt;/p&gt;
    &lt;p&gt;Follows me on X (@nand2mario) for updates, or use RSS.&lt;/p&gt;
    &lt;p&gt;Credits: This analysis of the 80386 draws on the microcode disassembly and silicon reverse engineering work of reenigne, gloriouscow, smartest blob, and Ken Shirriff. For a detailed examination of the silicon itself, see Ken Shirriff’s silicon reverse engineering series on the 80386.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nand2mario.github.io/posts/2026/80386_multiplication_and_division/"/><published>2026-01-24T06:11:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46741643</id><title>Telli (YC F24) is hiring eng, design, growth [on-site, Berlin]</title><updated>2026-01-24T10:42:27.891131+00:00</updated><content>&lt;doc fingerprint="10f452a104a33a8"&gt;
  &lt;main&gt;
    &lt;p&gt;JavaScript must be enabled in order to use Notion. Please enable JavaScript to continue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://careers.telli.com/"/><published>2026-01-24T07:01:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46741711</id><title>Eloquent: Improving Text Editing on Mobile (2021)</title><updated>2026-01-24T10:42:27.703933+00:00</updated><content/><link href="https://dl.acm.org/doi/10.1145/3474349.3480178"/><published>2026-01-24T07:19:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46741929</id><title>Modetc: Move your dotfiles from kernel space</title><updated>2026-01-24T10:42:26.868490+00:00</updated><content>&lt;doc fingerprint="fa8d835ea7092b88"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;modetc&lt;/head&gt;
    &lt;head rend="h3"&gt;Move your dotfiles from kernel space&lt;/head&gt;
    &lt;p&gt;modetc is a Linux kernel module that rewrites paths in file operations: it allows you to move files wherever you like, while still having programs finding them where they expected them to be.&lt;/p&gt;
    &lt;p&gt;The main application is to move the dotfiles of those stubborn programs that refuse to adopt the XDG basedir standard, away from the home directory. For example, you can rewrite the path &lt;code&gt;~/.ssh&lt;/code&gt; to &lt;code&gt;~/var/lib/ssh&lt;/code&gt;.
Yes, this is the nuclear option.&lt;/p&gt;
    &lt;head rend="h2"&gt;Configuration&lt;/head&gt;
    &lt;p&gt;modetc is configured via module parameters that are set either when manually loading the module (eg. &lt;code&gt;modprobe modetc homedir=...&lt;/code&gt;) or by adding a line to
&lt;code&gt;/etc/modprobe.conf&lt;/code&gt;. The parameters are:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Default value&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;homedir&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;Home directory where to rewrite paths&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;default_rule&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;The default replacement for all dotfiles&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;rules_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;/etc/modetc.conf&lt;/cell&gt;
        &lt;cell&gt;File containing the rewriting rules&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;debug&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;Turn on debugging for rewriting rules&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Rewriting rules&lt;/head&gt;
    &lt;p&gt;modetc rules are pure text search and replace: single substitution per file path, no wildcards nor regular expresssions.&lt;/p&gt;
    &lt;p&gt;The rules are only applied to absolute path with the &lt;code&gt;homedir&lt;/code&gt; prefix followed
by &lt;code&gt;.&lt;/code&gt;, or to any relative path with a leading &lt;code&gt;.&lt;/code&gt; when the working directory
is &lt;code&gt;homedir&lt;/code&gt;.
Rules are tested in the order in which they appear in the rules file and the
first to match will be applied. If no specific rule matches, the leading &lt;code&gt;.&lt;/code&gt; of
the file path will be replaced with the value of &lt;code&gt;default_rule&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The rules file consists of one or more lines with one rule per line of the following format&lt;/p&gt;
    &lt;code&gt;&amp;lt;match&amp;gt;	&amp;lt;replacement&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Note: whitespace is significant and match and replacement are separate by a tab character. On a given line, anything after a &lt;code&gt;#&lt;/code&gt; character is treated as a
comment. Empty lines are also ignored.&lt;/p&gt;
    &lt;p&gt;Note: the maximum number of rules supported is 16.&lt;/p&gt;
    &lt;head rend="h3"&gt;Example rules file:&lt;/head&gt;
    &lt;code&gt;# Garbage found in XDG dirs
var/lib/recently-used.xbel	var/cache/recently-used
etc/Trolltech.conf	var/cache/qt/cache
etc/QtProject.conf	var/cache/qt/conf
etc/matplotlib/	var/cache/matplotlib/

# Generic rewrites
.compose-cache	var/cache/compose
.nix-	var/lib/nix/

# X.org files
.Xresources	etc/x/resources
.X	var/cache/x/
.x	var/cache/x/

# XDG "compliant" programs
.config/	etc/
.local/state/	var/lib/
.cache/	var/cache/
&lt;/code&gt;
    &lt;head rend="h2"&gt;Runtime commands&lt;/head&gt;
    &lt;p&gt;You can send modetc some commands like reloading the rules file or pausing the rewriting by writing them to &lt;code&gt;/proc/modetc&lt;/code&gt;. For example&lt;/p&gt;
    &lt;code&gt;echo pause | sudo tee /proc/modetc
&lt;/code&gt;
    &lt;p&gt;Use &lt;code&gt;cat /proc/modetc&lt;/code&gt; to get a list of commands and what they do.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building&lt;/head&gt;
    &lt;p&gt;If using Nix, to build the module simply run&lt;/p&gt;
    &lt;code&gt;nix-build -A module
&lt;/code&gt;
    &lt;p&gt;in the project directory. Before actually loading the module, it is a good idea to test that it works correctly in a virtual machine, so run:&lt;/p&gt;
    &lt;code&gt;nix-build -A test
&lt;/code&gt;
    &lt;p&gt;If the test passed, you can safely load the module with&lt;/p&gt;
    &lt;code&gt;sudo insmod result/lib/modules/*/misc/modetc.ko
&lt;/code&gt;
    &lt;p&gt;Note: when using a custom or older kernel, you may have to change the &lt;code&gt;linux&lt;/code&gt; argument in the Nix expression (&lt;code&gt;default.nix&lt;/code&gt;) to match yours.&lt;/p&gt;
    &lt;p&gt;Otherwise, install a basic toolchain and linux kernel module and run &lt;code&gt;make&lt;/code&gt; to build the module.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing&lt;/head&gt;
    &lt;p&gt;On NixOS, add the following to your configuration:&lt;/p&gt;
    &lt;code&gt;{ config, pkgs, lib, ...  }:

let
  modetc = import (pkgs.fetchzip {
    url = "https://maxwell.eurofusion.eu/git/rnhmjoj/modetc/archive/v0.1.2.zip";
    sha256 = lib.fakeHash;  # change this
  }) { inherit pkgs; linux = config.boot.kernelPackages; };
in
{
  boot.kernelModules = [ "modetc" ];
  boot.extraModulePackages = [ modetc.module ];
  boot.extraModprobeConfig = ''
    options modetc homedir=/home/alice default_rule=var/lib/
  '';

  environment.etc."modetc.conf".text = ''
    # add your rules here
  '';
}
&lt;/code&gt;
    &lt;p&gt;This installs modetc, loads it on boot and configures it.&lt;/p&gt;
    &lt;p&gt;On other distributions, after building the module run &lt;code&gt;make install&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;kprobes are a mechanism to insert breakpoints at arbitrary locations in the Linux kernel code; they are a performance or debugging tool, but can also be used to alter the kernel behaviour at runtime.&lt;/p&gt;
    &lt;p&gt;modetc inserts kprobes in a few functions of the Virtual File System (VFS) layer and system calls implementations (&lt;code&gt;do_symlinkat&lt;/code&gt;, &lt;code&gt;do_rmdir&lt;/code&gt;, etc.) that
handle file paths. When any of these functions is called, a breakpoint is hit
and a small piece of code is inserted that modifies in-place the file path
argument, so the file operation is carried out on the replacement file.&lt;/p&gt;
    &lt;p&gt;Note that only the cache containing the kernel space copy of a userspace file path (&lt;code&gt;names_cachep&lt;/code&gt;) is actually changed, so the process that invoked the
system call is completely oblivious to any of this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Comparison with alternatives&lt;/head&gt;
    &lt;p&gt;libetc was an earlier solution based on intercepting the libc wrapper functions of the system calls using the &lt;code&gt;LD_PRELOAD&lt;/code&gt; mechanism. Unlike libetc, modetc&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;works for statically linked programs&lt;/item&gt;
      &lt;item&gt;works for programs not using libc to invoke the system calls (e.g. sqlite)&lt;/item&gt;
      &lt;item&gt;can be quickly toggled without restarting programs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;rewritefs solves most of the issues of libetc by rewriting the paths at the filesystem level, using a special FUSE filesystem. However, it severely degrades the performance of any I/O operation under the home directory. In comparison, modetc&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;does not require to mount a file system&lt;/item&gt;
      &lt;item&gt;runs in the kernel, with very little overhead&lt;/item&gt;
      &lt;item&gt;does not support regular expressions&lt;/item&gt;
      &lt;item&gt;can be quickly toggled without logging out&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Similarly to both method, modetc is Linux-specific.&lt;/p&gt;
    &lt;head rend="h2"&gt;License&lt;/head&gt;
    &lt;p&gt;Copyright (C) 2025 Michele Guerini Rocco&lt;/p&gt;
    &lt;p&gt;This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.&lt;/p&gt;
    &lt;p&gt;This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.&lt;/p&gt;
    &lt;p&gt;You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maxwell.eurofusion.eu/git/rnhmjoj/modetc"/><published>2026-01-24T08:16:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46742250</id><title>Repatriate the gold': German economists advise withdrawal from US vaults</title><updated>2026-01-24T10:42:26.769845+00:00</updated><content>&lt;doc fingerprint="7b4dc957bc6d5f73"&gt;
  &lt;main&gt;
    &lt;p&gt;Germany is facing calls to withdraw its billions of euros’ worth of gold from US vaults, spurred on by the shift in transatlantic relations and the unpredictability of Donald Trump.&lt;/p&gt;
    &lt;p&gt;Germany holds the world’s second biggest national gold reserves after the US, of which approximately €164bn (£122bn) worth – 1,236 tonnes – is stored in New York.&lt;/p&gt;
    &lt;p&gt;Emanuel Mönch, a leading economist and former head of research at Germany’s federal bank, the Bundesbank, called for the gold to be brought home, saying it was too “risky” for it to be kept in the US under the current administration.&lt;/p&gt;
    &lt;p&gt;“Given the current geopolitical situation, it seems risky to store so much gold in the US,” he told the financial newspaper Handelsblatt. “In the interest of greater strategic independence from the US, the Bundesbank would therefore be well advised to consider repatriating the gold.”&lt;/p&gt;
    &lt;p&gt;Stefan Kornelius, the spokesperson for Friedrich Merz’s coalition government, said recently that withdrawal of the gold reserves was not currently under consideration.&lt;/p&gt;
    &lt;p&gt;But Mönch is only the latest in a string of economists and financial experts to argue that such a move would be in keeping with the greater strategic independence that Europe’s largest economy has been seeking from the US in recent months.&lt;/p&gt;
    &lt;p&gt;Michael Jäger, the head of the European Taxpayers Association (TAE) as well as the Association of German Taxpayers, has also said Berlin should make its move, arguing that the US’s stated desire to seize Greenland should concentrate minds.&lt;/p&gt;
    &lt;p&gt;“Trump is unpredictable and he does everything to generate revenue. That’s why our gold is no longer safe in the Fed’s vaults,” Jäger told the Rheinische Post. “What happens if the Greenland provocation continues? … The risk is increasing that the German Bundesbank will no longer be able to access its gold. Therefore, it should repatriate its reserves.”&lt;/p&gt;
    &lt;p&gt;Jäger said he had written last year to the Bundesbank and the finance ministry, urging them to “bring our gold home”.&lt;/p&gt;
    &lt;p&gt;Until recently the gold issue has been the preserve mainly of the far-right Alternative für Deutschland (AfD), which has repeatedly urged the return of the gold for patriotic reasons. But it has increasingly crept into the mainstream discourse.&lt;/p&gt;
    &lt;p&gt;Katharina Beck, the finance spokesperson for the opposition Greens in the Bundestag, has also spoken out in favour of relocating the gold bars, calling them an “important anchor of stability and trust”, which “must not become pawns in geopolitical disputes”.&lt;/p&gt;
    &lt;p&gt;However, Clemens Fuest, the president of the Institute for Economic Research (Ifo) and one of the country’s most prominent economists, warned against such a move, saying it could lead to unintended consequences and would “only pour oil on the fire of the current situation”, he told the Rheinische Post.&lt;/p&gt;
    &lt;p&gt;Germany’s total gold reserves are worth almost €450bn.&lt;/p&gt;
    &lt;p&gt;Just over half are held at the Bundesbank in Frankfurt am Main, 37% in the vaults of the US Federal Reserve in New York and 12% at the Bank of England in London, the global centre of gold trading. The Bundesbank says it regularly undertakes an audit of the supplies of gold it holds in storage.&lt;/p&gt;
    &lt;p&gt;Speaking last October at the International Monetary Fund’s (IMF) autumn meetings in Washington DC, the Bundesbank president, Joachim Nagel, assured attenders there was “no cause for concern” over the German gold held at the US Federal Reserve.&lt;/p&gt;
    &lt;p&gt;Frauke Heiligenstadt, the parliamentary group spokesperson on financial policy for the Social Democrats, junior partners in the government, said that while she understood concerns about the gold reserves, there was no need for panic.&lt;/p&gt;
    &lt;p&gt;“Germany’s gold reserves are well diversified,” she said. Because half of them are located in Frankfurt, “our ability to act is guaranteed”. Having gold in New York made sense, she added, because “Germany, Europe and the US are closely linked in terms of financial policy”.&lt;/p&gt;
    &lt;p&gt;But, amid Trump’s hardening rhetoric towards his western partners, an increasing number of Merz’s Christian Democrats have been speaking out in favour of relocation.&lt;/p&gt;
    &lt;p&gt;“Due to the Trump administration, the US is no longer a reliable partner,” Ulrike Neyer, a professor of economics at the University of Düsseldorf, told the Rheinische Post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/world/2026/jan/24/repatriate-the-gold-german-economists-advise-withdrawal-from-us-vaults"/><published>2026-01-24T09:44:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46742362</id><title>Doing Gigabit Ethernet over My British Phone Wires</title><updated>2026-01-24T10:42:26.588759+00:00</updated><content>&lt;doc fingerprint="e1c9085f6b475eff"&gt;
  &lt;main&gt;
    &lt;p&gt;Disclaimer: None of this is written by AI, I’m still a real person writing my own blog like its 1999&lt;/p&gt;
    &lt;p&gt;I finally figured out how to do Gigabit Ethernet over my existing phone wires.&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerline adapter and misery&lt;/head&gt;
    &lt;p&gt;I’ve mostly lived with powerline adapters over recent years. Some worked well, some did not (try few and return what doesn’t work in your home). One I had for a while gave me stable 30 Mbps, which was little but good enough for internet at the time. I care very much about having stable low latency for gaming, more than bandwidth.&lt;/p&gt;
    &lt;p&gt;Fast forward to my current situation, that powerline adapter regularly lost connection which was a major problem. I got some new ones with the latest and greatest G.hn 2400 standard. The final contender served around 180 Mbps to my office (with high variance 120 to 280 Mbps), or around 80 Mbps to the top floor. It’s good enough to watch YouTube/TV yet it’s far from impressive.&lt;/p&gt;
    &lt;p&gt;One peculiar thing from the UK: Internet providers don’t truly offer gigabit internet. They have a range of deals like 30 Mbps – 75 Mbps – 150 Mbps – 300 Mbps – 500 Mbps – 900 Mbps, each one costing a few more pounds per month than the last. This makes the UK simultaneously one of the cheapest and one of the most expensive countries to get Internet.&lt;/p&gt;
    &lt;p&gt;Long story short, new place, new hardware, new deals, the internet has been running at 500 Mbps for some time now.&lt;/p&gt;
    &lt;p&gt;Every 50 GB of Helldivers 2 update (because these idiots shipped the same content in duplicate 5 times) is a painful reminder that the setup is not operating at capacity.&lt;/p&gt;
    &lt;p&gt;Problem: How to get 500 Mbps to my room?&lt;/p&gt;
    &lt;head rend="h2"&gt;A Fetish for Phone Sockets&lt;/head&gt;
    &lt;p&gt;I’ve been looking for a way to reuse phone wires for a while, because British houses are full of phone sockets. There are 2 sockets in my office room.&lt;/p&gt;
    &lt;p&gt;I can’t stress enough how much we love our phone sockets. It’s not uncommon to have a one bed flat with 2 phone sockets in the living room and 2 phone sockets in the bedroom and a master socket in the technical room. It’s ridiculous.&lt;/p&gt;
    &lt;p&gt;A new house bought today could have 10 phone sockets and 0 Ethernet sockets. There is still no regulation that requires new build to get Ethernet wiring (as far as I know).&lt;/p&gt;
    &lt;p&gt;There’s got to be a way to use the existing phone infrastructure.&lt;/p&gt;
    &lt;p&gt;I know the technology exists. It’s one of the rare cases where the technology exists and is mature, but nobody can be bothered to make products for it.&lt;/p&gt;
    &lt;p&gt;The standards that run powerline adapters (HomePlug AV200, AV500, G.hn 2400) can work with any pair of wires. It should work ten times better on dedicated phone wires instead of noisy power wires, if only manufacturers could be bothered to pull their fingers out of their arse and make the products that are needed.&lt;/p&gt;
    &lt;p&gt;After countless years of research, I finally found one German manufacturer that’s making what needs to be made https://www.gigacopper.net/wp/en/home-networking/&lt;/p&gt;
    &lt;head rend="h2"&gt;Ordering&lt;/head&gt;
    &lt;p&gt;It’s made and shipped from Germany.&lt;/p&gt;
    &lt;p&gt;I was lazy so I ordered online in self-service (which is definitely the wrong way to go about it). It’s available on Ebay DE and Amazon DE, it’s possible to order from either with a UK account, make sure to enter a UK address for delivery (some items don’t allow it).&lt;/p&gt;
    &lt;p&gt;The better approach is almost certainly to speak to the seller to get a quote, with international shipping and the import invoice excluding VAT (to avoid paying VAT on VAT).&lt;/p&gt;
    &lt;head rend="h2"&gt;Delivery Hell&lt;/head&gt;
    &lt;p&gt;The package got the usual Royal Mail treatment:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The package was shipped by DHL Germany&lt;/item&gt;
      &lt;item&gt;The package was transferred to Royal Mail when entering the UK&lt;/item&gt;
      &lt;item&gt;After some days, the DHL website said they tried to deliver but nobody home, this is bullshit&lt;/item&gt;
      &lt;item&gt;Royal website said the package reached the depot and was awaiting delivery, this is bullshit&lt;/item&gt;
      &lt;item&gt;In reality, the package was stuck at the border, as usual&lt;/item&gt;
      &lt;item&gt;Google to find “website to pay import fee on parcel”&lt;/item&gt;
      &lt;item&gt;https://www.royalmail.com/receiving-mail/pay-a-fee&lt;/item&gt;
      &lt;item&gt;Entered the DHL tracking number into the Royal Mail form for a Royal Mail tracking number&lt;/item&gt;
      &lt;item&gt;The website said that the parcel had import fees to pay, this is correct&lt;/item&gt;
      &lt;item&gt;Paid the fee online, 20% VAT + a few pounds of handling fees&lt;/item&gt;
      &lt;item&gt;The package will be scheduled for delivery a few days later&lt;/item&gt;
      &lt;item&gt;Royal Mail and DHL updated their status another two or three times with false information&lt;/item&gt;
      &lt;item&gt;Royal Mail delivered a letter saying there was a package waiting on fees, though it was paid&lt;/item&gt;
      &lt;item&gt;The package finally arrived&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Basically, you need to follow the tracking regularly until the package is tagged as lost or failed delivery, which is the cue to pay import fees.&lt;/p&gt;
    &lt;p&gt;It’s the normal procedure to buy things from Europe since Brexit 2020. It’s actually quite shocking that Royal Mail still hasn’t updated their tracking system to be able to give a status “waiting on import fees to be paid online”. They had 6 years!&lt;/p&gt;
    &lt;head rend="h2"&gt;Items&lt;/head&gt;
    &lt;p&gt;This is the gigacopper G4201TM: 1 RJ11 phone line, 1 RJ45 gigabit Ethernet port, 1 power&lt;/p&gt;
    &lt;p&gt;Shopping list:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A pair of gigacopper G4201TM&lt;/item&gt;
      &lt;item&gt;The device has a German power socket (expected)&lt;/item&gt;
      &lt;item&gt;It came with a German to UK power adapter (unexpected and useful)&lt;/item&gt;
      &lt;item&gt;It came with a standard RJ11 cable (expected and useless)&lt;/item&gt;
      &lt;item&gt;Found BT631A to RJ11 cables online (the standard UK phone socket)&lt;/item&gt;
      &lt;item&gt;Found Ethernet cables in my toolbox&lt;/item&gt;
      &lt;item&gt;3M removable hanging strip to stick to the wall, the device is very light&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There is a gigacopper G4202TM: with an RJ45 to connect to the phone line instead of a RJ11 (not sure if it’s a newer model or just a variant, as that one has two gigabit Ethernet ports). Don’t be confused by having a RJ45 port that is not a RJ45 port.&lt;/p&gt;
    &lt;p&gt;There is a gigacopper G4201C (1 port) and G4204C (4 port) for Ethernet over coaxial. Some countries have coax in every room for TV/satellite. This may be of interest to some readers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Testing&lt;/head&gt;
    &lt;p&gt;Plugged it and it works!&lt;/p&gt;
    &lt;p&gt;Full speed achieved.&lt;/p&gt;
    &lt;p&gt;Reminder, this is a 500 Mbps internet connection.&lt;/p&gt;
    &lt;head rend="h2"&gt;InHome Variant&lt;/head&gt;
    &lt;p&gt;I discovered soon afterwards that I bought the wrong item. There is an InHome and a Client/Server variant of the product. Make sure to buy the InHome variant.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The InHome variant can have up to 16 devices, communicating to any peer on the medium, with sub millisecond latency.&lt;/item&gt;
      &lt;item&gt;The client-server variant is preconfigured as a pair, splitting the bandwidth 70% download / 30% upload, with few milliseconds latency. I think it’s a use case for ISP and long range connections.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thankfully the difference is only the firmware. I spoke to the vendor who was very helpful and responsive. They sent me the firmware and the tools to patch.&lt;/p&gt;
    &lt;p&gt;I have a fetish for low latency. This screenshot is oddly satisfying.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gigabit&lt;/head&gt;
    &lt;p&gt;The web interface says 1713 Mbps on the physical layer, the debugging tool says PHONE 200MHz – Connected 1385 Mbps.&lt;/p&gt;
    &lt;p&gt;I wanted to verify whether the device can do a full Gigabit. Unfortunately I realized I don’t have any device that can test that.&lt;/p&gt;
    &lt;p&gt;Phones are wireless, which is too slow to test anything. I checked out of curiosity, my phone did 100 Mbps to 400 Mbps right next to the router. Grabbed two laptops only to realize they didn’t have any Ethernet port. I dug up an old laptop from storage with an Ethernet port. The laptop couldn’t boot, the CPU fan didn’t start and the laptop refused to boot with a dead fan.&lt;/p&gt;
    &lt;p&gt;There is a hard lesson here: 1 Gbps ought to be enough for any home. Using the phone line is as good as having Ethernet wiring through the house if it can deliver a (shared) 1.7 Gbps link to multiple rooms.&lt;/p&gt;
    &lt;p&gt;Still, I really wanted to verify that the device can do a full Gbps, I procured an USB-C to Ethernet adapter.&lt;/p&gt;
    &lt;p&gt;It works!&lt;/p&gt;
    &lt;p&gt;Full speed achieved, testing from a phone to a computer with iperf3.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wiring&lt;/head&gt;
    &lt;p&gt;Some readers might wonder about the wiring.&lt;/p&gt;
    &lt;p&gt;I didn’t check the wiring before buying anything because it’s pointless. British sockets are always daisy chained in an incomprehensible maze.&lt;/p&gt;
    &lt;p&gt;Phone sockets need 2 wires and can be daisy chained. Ethernet sockets need 8 wires. They often use the same Cat5 cable because it’s the most widely available (8 wires cable, the 6 extra wires can remain unconnected).&lt;/p&gt;
    &lt;p&gt;It’s possible to swap the phone socket for an RJ45 socket, if you only have 2 sockets connected with the right cable. It’s not possible when sockets are daisy chained. (You could put a double or triple RJ45 socket with a switch to break a daisy chain, but it quickly becomes impractical in a British house with 5 to 10 sockets in an arbitrary layout.)&lt;/p&gt;
    &lt;p&gt;I opened one socket in the office room. There are two Cat5 cables daisy chained. There are 3 wires connected.&lt;/p&gt;
    &lt;p&gt;It’s probably daisy chained with the other socket in the room, or it’s daisy chained with the socket in the other room that’s closer. Who knows.&lt;/p&gt;
    &lt;p&gt;I opened the BT master socket in the technical room. It should have the cables coming from the other rooms. It should connect the internal phone wires with the external phone line.&lt;/p&gt;
    &lt;p&gt;There is one single Cat5 cable. There are 4 wires connected. It’s definitely not a master socket. WTF?!&lt;/p&gt;
    &lt;p&gt;It’s interesting that this socket has 4 wires connected but the socket in the office has 3 wires connected. The idiot who did the wiring was inconsistent. The gigacopper device can operate over 2 wires (200 MHz Phone SISO) or over 4 wires (100 MHz Phone MIMO). I can try the other modes if I finish the job.&lt;/p&gt;
    &lt;p&gt;The search for the master socket continues. The cables from the other floors should all be coming down somewhere around here. There is a blank plate next to it (right).&lt;/p&gt;
    &lt;p&gt;This might be the external phone line? A bunch of wires are crimped together, colours do not match. It’s the hell of a mess.&lt;/p&gt;
    &lt;p&gt;Only sure thing, they are different cables because they are different colours. They might be going to a junction box somewhere else. Probably behind a wall that’s impossible to access!&lt;/p&gt;
    &lt;p&gt;Conclusion: There is zero chance to get proper Ethernet wiring out of this mess.&lt;/p&gt;
    &lt;p&gt;The gigacopper device to do gigabit Ethernet over phone line is a miracle!&lt;/p&gt;
    &lt;p&gt;There is an enormous untapped market for gigabit Ethernet over phone sockets in the UK.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thehftguy.com/2026/01/22/doing-gigabit-ethernet-over-my-british-phone-wires/"/><published>2026-01-24T10:14:31+00:00</published></entry></feed>