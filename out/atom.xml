<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-27T13:33:57.545445+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45388021</id><title>Open Social</title><updated>2025-09-27T13:34:07.526484+00:00</updated><content>&lt;doc fingerprint="bd968b5388b80695"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Open Social&lt;/head&gt;
    &lt;p&gt;September 26, 2025&lt;/p&gt;
    &lt;p&gt;Open source has clearly won. Yes, there are plenty of closed source products and businesses. But the shared infrastructure—the commons—runs on open source.&lt;/p&gt;
    &lt;p&gt;We might take this for granted, but it wasn’t a foregone conclusion thirty five years ago. There were powerful forces that wanted open source to lose. Some believed in the open source model but didn’t think it could ever compete with closed source. Many categories of tools only existed as closed source. A Microsoft CEO called open source cancer—a decade before Microsoft has rebuilt its empire around it. The open source movement may not have lived up to the ideals of the “free software”, but it won in industry adoption. Nobody gets fired for choosing open source these days. For much crucial software, open source is now the default.&lt;/p&gt;
    &lt;p&gt;I believe we are at a similar juncture with social apps as we have been with open source thirty five years ago. There’s a new movement on the block. I like to call it “open social”. There are competing visions for what “open social” should be like. I think the AT Protocol created by Bluesky is the most convincing take on it so far. It’s not perfect, and it’s a work in progress, but there’s nothing I know quite like it.&lt;/p&gt;
    &lt;p&gt;(Disclosure: I used to work at Bluesky on the Bluesky client app. I wasn’t involved in the protocol design. I am a fan, and this post is my attempt to explain why.)&lt;/p&gt;
    &lt;p&gt;In this post, I’ll explain the ideas of the AT Protocol, lovingly called atproto, and how it changes the relationship between the user, the developer, and the product.&lt;/p&gt;
    &lt;p&gt;I don’t expect atproto and its ecosystem (known as the Atmosphere) to win hearts overnight. Like open source, it might take a few decades to become ubiquitous. By explaining these ideas here, I’m hoping to slightly nudge this timeline. Despite the grip of today’s social media companies, I believe open social will eventually seem inevitable in retrospect—just like open source does now. Good things can happen; all it takes is years of sustained effort by a community of stubborn enthusiasts.&lt;/p&gt;
    &lt;p&gt;So what is it all about?&lt;/p&gt;
    &lt;p&gt;What open source did for code, open social does for data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Before Social&lt;/head&gt;
    &lt;p&gt;The web is a beautiful invention.&lt;/p&gt;
    &lt;p&gt;You type &lt;code&gt;https://alice.com&lt;/code&gt; and you end up on Alice’s website.&lt;/p&gt;
    &lt;p&gt;Or you type &lt;code&gt;https://bob.com&lt;/code&gt; and you end up on Bob’s website.&lt;/p&gt;
    &lt;p&gt;In a sense, your browser is a portal to millions of different worlds, each with its own little jurisdiction. Only Alice decides what appears on Alice’s website. Only Bob decides what appears on Bob’s website. They meaningfully “own their data”.&lt;/p&gt;
    &lt;p&gt;This doesn’t mean that they’re isolated. On the contrary, Alice can embed Bob’s picture with an &lt;code&gt;&amp;lt;img src&amp;gt;&lt;/code&gt;, and Bob can link to Alice’s page with &lt;code&gt;&amp;lt;a href&amp;gt;&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Alice and Bob can link to each other, but they remain in charge of their sites.&lt;/p&gt;
    &lt;p&gt;What do I mean by saying Alice and Bob are in charge of their own sites? Even if they’re not physically hosting their content on their own computers, they could always change hosting. For example, if Alice’s hosting provider starts deleting her pages or injecting ads into them, Alice can take her content to another host, and point &lt;code&gt;https://alice.com&lt;/code&gt; at another computer. The visitors won’t need to know.&lt;/p&gt;
    &lt;p&gt;This is important. Hosting providers have no real leverage over Alice and Bob. If the hosting provider “turns evil” and starts messing with your site, you can just walk away and host it elsewhere (as long as you have a backup). You’re not going to lose your traffic. All existing links will seamlessly resolve to the new destination.&lt;/p&gt;
    &lt;p&gt;If Alice changes her hosting, Bob won’t need to update any links to Alice’s website. Alice’s site will keep working as if nothing had happened. At worst, a DNS change might make it inaccessible for a few hours, but then the web will be repaired:&lt;/p&gt;
    &lt;p&gt;Imagine how different the incentives would be if links were tied to physical hosts!&lt;/p&gt;
    &lt;p&gt;If changing a hosting provider caused Alice to lose her traffic, she would think many times before changing providers. Perhaps she’d stick with her existing provider even if it was messing with her site, as losing her connections is even worse. Luckily, web’s decentralized design avoids this. Because it’s easy to walk away, hosting providers are forced to compete, and hosting is now a commodity.&lt;/p&gt;
    &lt;p&gt;I think the web is a beautiful idea. It links decentralized islands controlled by different people and companies into one interconnected surface that anyone can index and navigate. Links describe a relationship between logical documents rather than between physical servers. As a result, you’re not a hostage to your hosting.&lt;/p&gt;
    &lt;p&gt;As a wise person said, in theory, there is no difference between theory and practice, but in practice there is. So what’s been happening with the web?&lt;/p&gt;
    &lt;head rend="h2"&gt;Closed Social&lt;/head&gt;
    &lt;p&gt;In the early 90’s, the main way to publish something on the web was to have your own website. Today, most people publish content by using a social media app.&lt;/p&gt;
    &lt;p&gt;Alice and Bob are still publishing things. But instead of publishing at domains like &lt;code&gt;alice.com&lt;/code&gt; and &lt;code&gt;bob.com&lt;/code&gt;, they publish at usernames like &lt;code&gt;@alice&lt;/code&gt; and &lt;code&gt;@bob&lt;/code&gt; allocated by a social media company. The things they publish are not HTML pages, but app-specific entities such as profiles, posts, comments, likes, and so on.&lt;/p&gt;
    &lt;p&gt;These entities are usually stored in a database on the social company’s servers. The most common way to visualize a database is as a sequence of rows, but you could also visualize it as a graph. This makes it look very similar to web itself:&lt;/p&gt;
    &lt;p&gt;What does this social graph enable that a web of personal sites doesn’t?&lt;/p&gt;
    &lt;p&gt;The advantage of storing structured app-specific entities, such as posts and likes, instead of HTML documents is obvious. App-specific entities such as posts and likes have a richer structure: you can always turn them into HTML documents later, but you can also aggregate them, filter them, query, sort, and recombine them in different ways before that. This allows you to create many projections of the same data—a profile page, a list of posts, an individual post with comments.&lt;/p&gt;
    &lt;p&gt;Where this really shines, though, is when many people use the same social app. Since everyone’s public content is now in a single database, it is easy to aggregate across content published by many people. This enables social features like global search, notifications, feeds, personalized algorithms, shared moderation, etc.&lt;/p&gt;
    &lt;p&gt;It’s specifically this social aggregation that blows the “personal sites” paradigm out of the water. People are social creatures, and we want to congregate in shared spaces. We don’t just want to visit each other’s sites—we want to hang out together, and social apps provide the shared infrastructure. Social aggregation features like notifications, feeds, and search are non-negotiable in modern social products.&lt;/p&gt;
    &lt;p&gt;Today, the most common way to implement these features is shaped like this:&lt;/p&gt;
    &lt;p&gt;There still exists a web-like logical model of our data—our profiles, our posts, our follows, our likes, all the things that we’ve created—but it lives within some social app’s database. What’s exposed to the web are only projections of that model—the Home screen, the Notifications screen, the HTML pages for individual posts.&lt;/p&gt;
    &lt;p&gt;This architecture makes sense. It is the easiest way to evolve the “personal sites” paradigm to support aggregation so it’s not surprising today’s apps have largely converged on it. People create accounts on social apps, which lets those apps build aggregated features, which entices more people to sign up for those apps.&lt;/p&gt;
    &lt;p&gt;However, something got lost in the process. The web we’re actually creating—our posts, our follows, our likes—is no longer meaningfully ours. Even though much of what we’re creating is public, it is not a part of the open web. We can’t change our “hosting provider” because we’re now one step removed from how the internet works. We, and the web we create, have become rows in somebody else’s database:&lt;/p&gt;
    &lt;p&gt;This creates an imbalance.&lt;/p&gt;
    &lt;p&gt;When Alice used to publish her stuff on &lt;code&gt;alice.com&lt;/code&gt;, she was not tied to any particular hosting provider. If she were unhappy with a hosting provider, she knew that she could swap it out without losing any traffic or breaking any links:&lt;/p&gt;
    &lt;p&gt;That kept the hosting providers in check.&lt;/p&gt;
    &lt;p&gt;But now that Alice publishes her stuff on a social media platform, she can no longer “walk away” without losing something. If she signs up to another social platform, she would be forced to start from scratch, even if she wants to retain her connections. There is no way for Alice to sever the relationship with a particular app without ripping herself, and anything she created there, out of its social graph:&lt;/p&gt;
    &lt;p&gt;The web Alice created—who she follows, what she likes, what she has posted—is trapped in a box that’s owned by somebody else. To leave it is to leave it behind.&lt;/p&gt;
    &lt;p&gt;On an individual level, it might not be a huge deal.&lt;/p&gt;
    &lt;p&gt;Alice can rebuild her social presence connection by connection somewhere else. Eventually she might even have the same reach as on the previous platform.&lt;/p&gt;
    &lt;p&gt;However, collectively, the net effect is that social platforms—at first, gradually, and then suddenly—turn their backs on their users. If you can’t leave without losing something important, the platform has no incentives to respect you as a user.&lt;/p&gt;
    &lt;p&gt;Maybe the app gets squeezed by investors, and every third post is an ad. Maybe it gets bought by a congolomerate that wanted to get rid of competition, and is now on life support. Maybe it runs out of funding, and your content goes down in two days. Maybe the founders get acquihired—an exciting new chapter. Maybe the app was bought by some guy, and now you’re slowly getting cooked by the algorithm.&lt;/p&gt;
    &lt;p&gt;If your next platform doesn’t respect you as a user, you might try to leave it, too.&lt;/p&gt;
    &lt;p&gt;But what are you going to do? Will you “export your data”? What will you do with that lonely shard of a social graph? You can upload it somewhere as an archive but it’s ripped out of its social context—a pitiful memento of your self-imposed exile.&lt;/p&gt;
    &lt;p&gt;Those megabytes of JSON you got on your way out are dead data. It’s like a branch torn apart from its tree. It doesn’t belong anywhere. To give a new life to our data, we’d have to collectively export it and then collectively import it into some next agreed-upon social app—a near-impossible feat of coordination. Even then, the network effects are so strong that most people would soon find their way back.&lt;/p&gt;
    &lt;p&gt;You can’t leave a social app without leaving behind the web you’ve created.&lt;/p&gt;
    &lt;p&gt;What if you could keep it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Social&lt;/head&gt;
    &lt;p&gt;Alice and Bob are still using social apps. Those apps don’t look much different from today’s social apps. You could hardly tell that something has changed.&lt;/p&gt;
    &lt;p&gt;Something has changed, though. (Can you spot it?)&lt;/p&gt;
    &lt;p&gt;Notice that Alice’s handle is now &lt;code&gt;@alice.com&lt;/code&gt;. It is not allocated by a social media company. Rather, her handle is the universal “internet handle”, i.e. a domain. Alice owns the &lt;code&gt;alice.com&lt;/code&gt; domain, so she can use it as a handle on any open social app. (On most open social apps, she goes by &lt;code&gt;@alice.com&lt;/code&gt;, but for others she wants a distinct disconnected identity, so she owns another handle she’d rather not share.)&lt;/p&gt;
    &lt;p&gt;Bob owns a domain too, even though he isn’t technical. He might not even know what a “domain” is. Bob just thinks of &lt;code&gt;@bob.com&lt;/code&gt; as his “internet handle”. Some open social apps will offer you a free subdomain on registration, just like Gmail gives you a free Gmail address, or may offer an extra flow for buying a domain. You’re not locked into your first choice, and can swap to a different domain later.&lt;/p&gt;
    &lt;p&gt;Your internet handle being something you actually own is the most user-visible aspect of open social apps. But the much bigger difference is invisible to the user.&lt;/p&gt;
    &lt;p&gt;When you previously saw the social graph above, it was trapped inside a social app’s database. There was a box around that graph—it wasn’t a part of the web. With open social, Alice’s data—her posts, likes, follows, etc—is hosted on the web itself. Alongside her personal site, Alice now has a personal repository of her data:&lt;/p&gt;
    &lt;p&gt;This “repository” is a regular web server that implements the AT Protocol spec. The only job of Alice’s personal repository is to store and serve data created by Alice in the form of signed JSON. Alice is technical, so she likes to sometimes inspect her repo using open source tools like pdsls, Taproot, or atproto-browser.&lt;/p&gt;
    &lt;p&gt;Bob, however, isn’t technical. He doesn’t even know that there is a “repository” with his “data”. He got a repository behind the scenes when he signed up for his first open social app. His repository stores his data (from all open social apps).&lt;/p&gt;
    &lt;p&gt;Have another look at this picture:&lt;/p&gt;
    &lt;p&gt;These aren’t rows in somebody’s database. This is a web of hyperlinked JSON. Just like every HTML page has an &lt;code&gt;https://&lt;/code&gt; URI so other pages can link to it, every JSON record has an &lt;code&gt;at://&lt;/code&gt; URI, so any other JSON record can link to it. (On this and other illustrations, &lt;code&gt;@alice.com&lt;/code&gt; is a shorthand for &lt;code&gt;at://alice.com&lt;/code&gt;.) The &lt;code&gt;at://&lt;/code&gt; protocol is a bunch of conventions on top of DNS, HTTP, and JSON.&lt;/p&gt;
    &lt;p&gt;Now have a look at the arrows between their records. Alice follows Bob, so she has a &lt;code&gt;follow&lt;/code&gt; record linking to Bob’s &lt;code&gt;profile&lt;/code&gt; record. Bob commented on Alice’s post, so he has a &lt;code&gt;comment&lt;/code&gt; record that links to Alice’s &lt;code&gt;post&lt;/code&gt; record. Alice liked his comment, so she has a &lt;code&gt;like&lt;/code&gt; record with a link to his &lt;code&gt;comment&lt;/code&gt; record. Everything Alice creates stays in her repo under her control, everything Bob creates stays in his repo under his control, and links express the connections—just like in HTML.&lt;/p&gt;
    &lt;p&gt;All of this happens behind the scenes and is invisibile to a non-technical user. The user doesn’t need to think about where their data is stored until it matters, just like the user doesn’t think about how servers work when navigating the web.&lt;/p&gt;
    &lt;p&gt;Alice’s and Bob’s repositories could be hosted on the same machine. Or they could be hosted by different companies or communities. Maybe Alice is self-hosting her repository, while Bob uses a free hosting service that came by default with his first open social app. They may even be running completely different implementations. If both servers follow the AT protocol, they can participate in this web of JSON.&lt;/p&gt;
    &lt;p&gt;Note that &lt;code&gt;https://alice.com&lt;/code&gt; and &lt;code&gt;at://alice.com&lt;/code&gt; do not need to resolve to the same server. This is intentional so that having a nice handle like &lt;code&gt;@alice.com&lt;/code&gt; doesn’t force Alice to host her own data, to mess with her website, or even to have a site at all. If she owns &lt;code&gt;alice.com&lt;/code&gt;, she can point &lt;code&gt;at://alice.com&lt;/code&gt; at any server.&lt;/p&gt;
    &lt;p&gt;If Alice is unhappy with her hosting, she can pack up and leave:&lt;/p&gt;
    &lt;p&gt;(This requires a modicum of technical skill today but it’s getting more accessible.)&lt;/p&gt;
    &lt;p&gt;Just like with moving a personal site, changing where her repo is being served from doesn’t require cooperation from the previous host. It also doesn’t disrupt her ability to log into apps and doesn’t break any links. The web repairs itself:&lt;/p&gt;
    &lt;p&gt;It is worth pausing for a moment to appreciate what we have here.&lt;/p&gt;
    &lt;p&gt;Every bit of public data that Alice and Bob created—their posts, their likes, their comments, their recipes, their scrobbles—is meaningfully owned by them. It’s not in a database subject to some CEO’s whims, but hosted directly on the open web, with ability to “walk away” without losing traffic or breaking any links.&lt;/p&gt;
    &lt;p&gt;Like the web of personal sites, this model is centered around the user.&lt;/p&gt;
    &lt;p&gt;What does it mean for apps?&lt;/p&gt;
    &lt;p&gt;Each open social app is like a CMS (content management system) for a subset of data that lives in its users’ repositories. In that sense, your personal repository serves a role akin to a Google account, a Dropbox folder, or a Git repository, with data from your different open social apps grouped under different “subfolders”.&lt;/p&gt;
    &lt;p&gt;When you make a post on Bluesky, Bluesky puts that post into your repo:&lt;/p&gt;
    &lt;p&gt;When you star a project on Tangled, Tangled puts that star into your repo:&lt;/p&gt;
    &lt;p&gt;When you create a publication on Leaflet, Leaflet puts it in your repo:&lt;/p&gt;
    &lt;p&gt;You get the idea.&lt;/p&gt;
    &lt;p&gt;Over time, your repo grows to be a collection of data from different open social apps. This data is open by default—if you wanted to look at my Bluesky posts, or Tangled stars, or Leaflet publications, you wouldn’t need to hit these applications’ APIs. You could just hit my personal repository and enumerate all of its records.&lt;/p&gt;
    &lt;p&gt;To avoid naming collisions, the data in the repository is grouped by the format:&lt;/p&gt;
    &lt;p&gt;In any user’s repo, Bluesky posts go with other Bluesky posts, Leaflet publications go with Leaflet publications, Tangled stars go with Tangled stars, and so on. Each data format is controlled and evolved by developers of the relevant application.&lt;/p&gt;
    &lt;p&gt;I’ve drawn a dotted line to separate them but perhaps this is misleading.&lt;/p&gt;
    &lt;p&gt;Since the data from different apps “lives together”, there’s a much lower barrier for open social apps to piggyback on each other’s data. In a way, it starts to feel like a connected multiverse of apps, with data from one app “bleeding into” other apps.&lt;/p&gt;
    &lt;p&gt;When I signed up for Tangled, I chose to use my existing &lt;code&gt;@danabra.mov&lt;/code&gt; handle. That makes sense since identity can be shared between open social apps. What’s more interesting is that Tangled prefilled my avatar based on my Bluesky profile. It didn’t need to hit the Bluesky API to do that; it just read the Bluesky profile record in my repository. Every app can choose to piggyback on data from other apps.&lt;/p&gt;
    &lt;p&gt;That might remind you of Gravatar, but it works for every piece of data. Every open social app can take advantage of data created by every other open social app:&lt;/p&gt;
    &lt;p&gt;There is no API to hit, no integrations to build, nothing to get locked out of. All the data is in the user’s repository, so you can parse it (as typed JSON), and use it.&lt;/p&gt;
    &lt;p&gt;The protocol is the API.&lt;/p&gt;
    &lt;p&gt;This has deep implications for the lifecycle of products. If a product gets shut down, the data doesn’t disappear. It’s still in its users’ repos. Someone can build a replacement that makes this data comes back to life. Someone can build a new product that incorporates some of that data, or lets users choose what to import. Someone can build an alternative projection of existing data—a forked product.&lt;/p&gt;
    &lt;p&gt;This also reduces the “cold start” problem for new apps. If some of the data you care about already exists on the network, you can bootstrap your product off of that. For example, if you’re launching a short video app, you can piggyback on the Bluesky &lt;code&gt;follow&lt;/code&gt; records so that people don’t have to find each other again. But if that doesn’t make sense for your app, you can have your own &lt;code&gt;follow&lt;/code&gt; records instead, or offer a one-time import. All existing data is up for reuse and remixing.&lt;/p&gt;
    &lt;p&gt;Some open social apps are explicitly based around this sort of remixing. Anisota is primarily a Bluesky client, but it natively supports showing Leaflet documents. Popfeed can cross-post reviews to both Bluesky and Leaflet. If Leaflet does get very popular, there’s nothing stopping Bluesky itself from supporting a Leaflet document as another type of post attachment. In fact, some third-party Bluesky client could decide to do that first, and the official one could eventually follow.&lt;/p&gt;
    &lt;p&gt;This is why I like “open social” as a term.&lt;/p&gt;
    &lt;p&gt;Open social frees up our data like open source freed up our code. Open social ensures that products can get a new life, that people can’t be locked out of what they have created, and that products can be forked and remixed. You don’t need an “everything app” when data from different apps circulates in the open web.&lt;/p&gt;
    &lt;p&gt;If you’re technical, by now you might have a burning question.&lt;/p&gt;
    &lt;p&gt;How the hell does aggregation work?!&lt;/p&gt;
    &lt;p&gt;Since every user’s records live in that user’s repository, there are millions (potentially billions?) repositories. How can an app efficiently query, sort, filter, and aggregate information from them? Surely it can’t search them on demand.&lt;/p&gt;
    &lt;p&gt;I’ve previously used a CMS as an analogy—for example, a blogging app could directly write posts to your repository and then read posts from it when someone visits your blog. This “singleplayer” use case would not require aggregation at all.&lt;/p&gt;
    &lt;p&gt;To avoid hitting the user’s repository every time you want to display their blog post, you can connect to the user’s repository by a websocket. Every time a record relevant to your app is created, updated, or deleted, you can update your database:&lt;/p&gt;
    &lt;p&gt;This database isn’t the source of truth for user’s data—it’s more like an app-specific cache that lets you avoid going to the user repo whenever you need some data.&lt;/p&gt;
    &lt;p&gt;Coincidentally, that’s the exact mechanism you would use for aggregation. You listen to events from all of your app users’ repositories, write them to a local database, and query that database as much as you like with zero extra latency.&lt;/p&gt;
    &lt;p&gt;This might remind you of how Google Reader crawls RSS (rip).&lt;/p&gt;
    &lt;p&gt;To avoid opening a million event socket connections, it makes sense to listen to a stream that retransmits events from all known repositories on the network:&lt;/p&gt;
    &lt;p&gt;You can then filter down such a stream to just the events you’re interested in, and then update your local database in response to the events your app cares about.&lt;/p&gt;
    &lt;p&gt;For example, Leaflet is only interested in events concerning &lt;code&gt;pub.leaflet.*&lt;/code&gt; records. However, Leaflet can also choose to listen to other events. If Leaflet wanted to add a feature that shows backlinks to Bluesky discussions of a Leaflet document, it would simply start tracking &lt;code&gt;bsky.app.feed.post&lt;/code&gt; records too.&lt;/p&gt;
    &lt;p&gt;You can try it yourself by clicking on this link:&lt;/p&gt;
    &lt;p&gt;This is a realtime stream of every single event on the network. It’s dominated by &lt;code&gt;app.bsky.*&lt;/code&gt; records because Bluesky is the most-used app, but you can filter it down to other record types. This retransmitter (called a “relay”) is operated by Bluesky, but you don’t have to depend on it. The Blacksky community runs their own relay implementation at &lt;code&gt;wss://atproto.africa&lt;/code&gt;, which you can try here.&lt;/p&gt;
    &lt;p&gt;Another important detail is that commits are cryptographically signed, which means that you don’t need to trust a relay or a cache of network data. You can verify that the records haven’t been tampered with, and each commit is legitimate.&lt;/p&gt;
    &lt;p&gt;As time goes by, we’ll see more infrastructure built around and for open social apps. Graze is letting users build their own algorithmic feeds, and Slices is an upcoming developer platform that does large-scale repository indexing for you.&lt;/p&gt;
    &lt;p&gt;These are all technical details, though.&lt;/p&gt;
    &lt;p&gt;What matters is the big picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Picture&lt;/head&gt;
    &lt;p&gt;The pre-social web of “personalized sites” got data ownership, hosting independence, and linking right. Alice and Bob fully participate in the web:&lt;/p&gt;
    &lt;p&gt;The closed social web innovated in scaling and in social aggregation features. Notifications, search, and feeds are non-negotiable in modern social products:&lt;/p&gt;
    &lt;p&gt;However, the closed social web has also excluded us from the web. The web we create is no longer meaningfully ours. We’re just rows in somebody else’s database.&lt;/p&gt;
    &lt;p&gt;Open social frees the web we’re creating from somebody else’s boxes. Our profiles, likes, follows, recipes, scrobbles, and other content meaningfully belong to us:&lt;/p&gt;
    &lt;p&gt;The data no longer lives inside the products; the products aggregate over our data:&lt;/p&gt;
    &lt;p&gt;This blurs the boundaries between apps. Every open social app can use, remix, link to, and riff on data from every other open social app.&lt;/p&gt;
    &lt;p&gt;The web we’ve created remains after the products we used to create it are gone. Developers can build new products to recontextualize it. No one can take it away.&lt;/p&gt;
    &lt;p&gt;As more products are built in the open social paradigm, there’s going to be a shift.&lt;/p&gt;
    &lt;p&gt;People might not ever start using technical concepts like “decentralization” but they do understand when data from one app can seamlessly flow into other apps.&lt;/p&gt;
    &lt;p&gt;People might not care about “federation” but they do notice when they log into a competing product, and their data is already there, and their reach is intact.&lt;/p&gt;
    &lt;p&gt;And people do understand when they’re being fucked with.&lt;/p&gt;
    &lt;p&gt;For a long time, open social will rely on a community of stubborn enthusiasts who see the promise of the approach and are willing to bear the pains of building (and failing) in a new ecosystem. But I don’t think that dooms the effort. That’s the history of every big community-driven change. Somebody has to work through the kinks. Like with open source, open social is a compounding effort. Every mildly successful open social app lifts all open social apps. Every piece of shared infrastructure can benefit somebody else. At some point, open is bound to win.&lt;/p&gt;
    &lt;p&gt;I just hope it doesn’t take thirty five years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://overreacted.io/open-social/"/><published>2025-09-26T16:01:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45388822</id><title>Suno Studio, a Generative AI DAW</title><updated>2025-09-27T13:34:07.151604+00:00</updated><content>&lt;doc fingerprint="536fd5a56c585c00"&gt;
  &lt;main&gt;
    &lt;p&gt;00:00 /&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://suno.com/studio-welcome"/><published>2025-09-26T17:17:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45389267</id><title>SimpleFold: Folding proteins is simpler than you think</title><updated>2025-09-27T13:34:06.553714+00:00</updated><content>&lt;doc fingerprint="dd791d51782a9c92"&gt;
  &lt;main&gt;
    &lt;p&gt;This github repository accompanies the research paper, SimpleFold: Folding Proteins is Simpler than You Think (Arxiv 2025).&lt;/p&gt;
    &lt;p&gt;Yuyang Wang, Jiarui Lu, Navdeep Jaitly, Joshua M. Susskind, Miguel Angel Bautista&lt;/p&gt;
    &lt;p&gt;We introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer layers. SimpleFold does not rely on expensive modules like triangle attention or pair representation biases, and is trained via a generative flow-matching objective. We scale SimpleFold to 3B parameters and train it on more than 8.6M distilled protein structures together with experimental PDB data. To the best of our knowledge, SimpleFold is the largest scale folding model ever developed. On standard folding benchmarks, SimpleFold-3B model achieves competitive performance compared to state-of-the-art baselines. Due to its generative training objective, SimpleFold also demonstrates strong performance in ensemble prediction. SimpleFold challenges the reliance on complex domain-specific architectures designs in folding, highlighting an alternative yet important avenue of progress in protein structure prediction.&lt;/p&gt;
    &lt;p&gt;To install &lt;code&gt;simplefold&lt;/code&gt; package from github repository, run&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/apple/ml-simplefold.git
cd ml-simplefold
conda create -n simplefold python=3.10
python -m pip install -U pip build; pip install -e .
&lt;/code&gt;
    &lt;p&gt;If you want to use MLX backend on Apple silicon:&lt;/p&gt;
    &lt;code&gt;pip install mlx==0.28.0
pip install git+https://github.com/facebookresearch/esm.git
&lt;/code&gt;
    &lt;p&gt;We provide a jupyter notebook &lt;code&gt;sample.ipynb&lt;/code&gt; to predict protein structures from example protein sequences.&lt;/p&gt;
    &lt;p&gt;Once you have &lt;code&gt;simplefold&lt;/code&gt; package installed, you can predict the protein structure from target fasta file(s) via the following command line. We provide support for both PyTorch and MLX (recommended for Apple hardware) backends in inference.&lt;/p&gt;
    &lt;code&gt;simplefold \
    --simplefold_model simplefold_100M \  # specify folding model in simplefold_100M/360M/700M/1.1B/1.6B/3B
    --num_steps 500 --tau 0.01 \        # specify inference setting
    --nsample_per_protein 1 \           # number of generated conformers per target
    --plddt \                           # output pLDDT
    --fasta_path [FASTA_PATH] \         # path to the target fasta directory or file
    --output_dir [OUTPUT_DIR] \         # path to the output directory
    --backend [mlx, torch]              # choose from MLX and PyTorch for inference backend 
&lt;/code&gt;
    &lt;p&gt;We provide predicted structures from SimpleFold of different model sizes:&lt;/p&gt;
    &lt;code&gt;https://ml-site.cdn-apple.com/models/simplefold/cameo22_predictions.zip # predicted structures of CAMEO22
https://ml-site.cdn-apple.com/models/simplefold/casp14_predictions.zip  # predicted structures of CASP14
https://ml-site.cdn-apple.com/models/simplefold/apo_predictions.zip     # predicted structures of Apo
https://ml-site.cdn-apple.com/models/simplefold/codnas_predictions.zip  # predicted structures of Fold-switch (CoDNaS)
&lt;/code&gt;
    &lt;p&gt;We use the docker image of openstructure 2.9.1 to evaluate generated structures for folding tasks (i.e., CASP14/CAMEO22). Once having the docker image enabled, you can run evaluation via:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/evaluation/analyze_folding.py \
    --data_dir [PATH_TO_TARGET_MMCIF] \
    --sample_dir [PATH_TO_PREDICTED_MMCIF] \
    --out_dir [PATH_TO_OUTPUT] \
    --max-workers [NUMBER_OF_WORKERS]
&lt;/code&gt;
    &lt;p&gt;To evaluate results of two-state prediction (i.e., Apo/CoDNaS), one need to compile the TMsore and then run evaluation via:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/evaluation/analyze_two_state.py \ 
    --data_dir [PATH_TO_TARGET_DATA_DIRECTORY] \
    --sample_dir [PATH_TO_PREDICTED_PDB] \
    --tm_bin [PATH_TO_TMscore_BINARY] \
    --task apo \ # choose from apo and codnas
    --nsample 5
&lt;/code&gt;
    &lt;p&gt;You can also train or tune SimpleFold on your end. Instructions below include details for SimpleFold training.&lt;/p&gt;
    &lt;p&gt;SimpleFold is trained on joint datasets including experimental structures from PDB, as well as distilled predictions from AFDB SwissProt and AFESM. Target lists of filtered SwissProt and AFESM targets thta are used in our training can be found:&lt;/p&gt;
    &lt;code&gt;https://ml-site.cdn-apple.com/models/simplefold/swissprot_list.csv # list of filted SwissProt (~270K targets)
https://ml-site.cdn-apple.com/models/simplefold/afesm_list.csv # list of filted AFESM targets (~1.9M targets)
https://ml-site.cdn-apple.com/models/simplefold/afesme_dict.json # list of filted extended AFESM (AFESM-E) (~8.6M targets)
&lt;/code&gt;
    &lt;p&gt;In &lt;code&gt;afesme_dict.json&lt;/code&gt;, the data is stored in the following structure:&lt;/p&gt;
    &lt;code&gt;{
    cluster 1 ID: {"members": [protein 1 ID, protein 2 ID, ...]},
    cluster 2 ID: {"members": [protein 1 ID, protein 2 ID, ...]},
    ...
}
&lt;/code&gt;
    &lt;p&gt;Of course, one can use own customized datasets to train or tune SimpleFold models. Instructions below list how to process the dataset for SimpleFold training.&lt;/p&gt;
    &lt;p&gt;To process downloaded mmcif files, you need Redis installed and launch the Redis server:&lt;/p&gt;
    &lt;code&gt;wget https://boltz1.s3.us-east-2.amazonaws.com/ccd.rdb
redis-server --dbfilename ccd.rdb --port 7777
&lt;/code&gt;
    &lt;p&gt;You can then process mmcif files to input format for SimpleFold:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/process_mmcif.py \
    --data_dir [MMCIF_DIR]   # directory of mmcif files
    --out_dir [OUTPUT_DIR]   # directory of processed targets
    --use-assembly
&lt;/code&gt;
    &lt;p&gt;The configuration of model is based on &lt;code&gt;Hydra&lt;/code&gt;. An example training configuration can be found in &lt;code&gt;configs/experiment/train&lt;/code&gt;. To change dataset and model settings, one can refer to config files in &lt;code&gt;configs/data&lt;/code&gt; and &lt;code&gt;configs/model&lt;/code&gt;. To initiate SimpleFold training:&lt;/p&gt;
    &lt;code&gt;python train experiment=train
&lt;/code&gt;
    &lt;p&gt;To train SimpleFold with FSDP strategy:&lt;/p&gt;
    &lt;code&gt;python train_fsdp.py experiment=train_fsdp
&lt;/code&gt;
    &lt;p&gt;If you found this code useful, please cite the following paper:&lt;/p&gt;
    &lt;code&gt;@article{simplefold,
  title={SimpleFold: Folding Proteins is Simpler than You Think},
  author={Wang, Yuyang and Lu, Jiarui and Jaitly, Navdeep and Susskind, Josh and Bautista, Miguel Angel},
  journal={arXiv preprint arXiv:2509.18480},
  year={2025}
}
&lt;/code&gt;
    &lt;p&gt;Our codebase is built using multiple opensource contributions, please see ACKNOWLEDGEMENTS for more details.&lt;/p&gt;
    &lt;p&gt;Please check out the repository LICENSE before using the provided code and LICENSE_MODEL for the released models.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/apple/ml-simplefold"/><published>2025-09-26T18:01:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45389293</id><title>Auth.js is now part of Better Auth</title><updated>2025-09-27T13:34:06.300537+00:00</updated><content>&lt;doc fingerprint="ea4da1989f2d5ce"&gt;
  &lt;main&gt;
    &lt;p&gt;We’re excited to announce that Auth.js, formerly known as NextAuth.js, is now being maintained and overseen by Better Auth team. If you haven't heard of Auth.js, it has long been one of the most widely used open source authentication libraries in the JavaScript ecosystem. Chances are, if you’ve used ChatGPT, Google Labs, Cal.com or a million other websites, you’ve already interacted with Auth.js.&lt;/p&gt;
    &lt;head rend="h2"&gt;Back Story about Better Auth and Auth.js&lt;/head&gt;
    &lt;p&gt;Before Better Auth, Auth.js gave developers like us the ability to own our auth without spending months wrestling with OAuth integrations or session management. But as applications became more complex and authentication needs evolved, some of its limitations became harder to ignore. We found ourselves rebuilding the same primitives over and over.&lt;/p&gt;
    &lt;p&gt;The Auth.js team recognized these challenges and had big ideas for the future, but for various reasons couldn’t execute them as fully as they hoped.&lt;/p&gt;
    &lt;p&gt;That shared frustration and the vision of empowering everyone to truly own their auth started the creation of Better Auth. Since our goals aligned with the Auth.js team, we were excited to help maintain Auth.js and make auth better across the web. As we talked more, we realized that Better Auth was the best home for Auth.js.&lt;/p&gt;
    &lt;head rend="h2"&gt;What does this mean for existing users?&lt;/head&gt;
    &lt;p&gt;We recognize how important this project is for countless applications, companies, and developers. If you’re using Auth.js/NextAuth.js today, you can continue doing so without disruption—we’ll keep addressing security patches and urgent issues as they come up.&lt;/p&gt;
    &lt;p&gt;But we strongly recommend new projects to start with Better Auth unless there are some very specific feature gaps (most notably stateless session management without a database). Our roadmap includes bringing those capabilities into Better Auth, so the ecosystem can converge rather than fragment.&lt;/p&gt;
    &lt;p&gt;For teams considering migration, we’ve prepared a guide and we’ll be adding more guides and documentation soon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;We are deeply grateful to the Auth.js community who have carried the project to this point. In particular, the core maintainers-Balázs, who served as lead maintainer, Thang Vu,Nico Domino, Lluis Agusti and Falco Winkler-pushed through difficult phases, brought in new primitives, and kept the project alive long enough for this transition to even be possible.&lt;/p&gt;
    &lt;p&gt;Better Auth beginning was inspired by Auth.js, and now, together, the two projects can carry the ecosystem further. The end goal remains unchanged: you should own your auth!&lt;/p&gt;
    &lt;p&gt;For the Auth.js team's announcement, see GitHub discussion.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.better-auth.com/blog/authjs-joins-better-auth"/><published>2025-09-26T18:04:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45389464</id><title>Oral Microbes Linked to 3-Fold Increased Risk of Pancreatic Cancer</title><updated>2025-09-27T13:34:05.964600+00:00</updated><content>&lt;doc fingerprint="f790e1a3620b8701"&gt;
  &lt;main&gt;
    &lt;p&gt;Among the hundreds of species of bacteria and fungi that live in people’s mouths, 27 have been collectively tied to a 3.5 times greater risk of developing pancreatic cancer, a study led by NYU Langone Health and its Perlmutter Cancer Center shows.&lt;/p&gt;
    &lt;p&gt;Experts have long observed that those with poor oral health are more vulnerable to pancreatic cancer than those with healthier mouths. More recently, scientists have uncovered a mechanism that could help explain this connection, finding that bacteria can travel through swallowed saliva into the pancreas, an organ that helps with digestion. However, precisely which species may contribute to the condition had until now remained unclear.&lt;/p&gt;
    &lt;p&gt;Published online September 18 in JAMA Oncology, the new analysis assessed the genetic makeup of microbes collected from the saliva of 122,000 healthy men and women.&lt;/p&gt;
    &lt;p&gt;“Our findings provide new insight into the relationship between the oral microbiome and pancreatic cancer,” said study lead author Yixuan Meng, PhD, a postdoctoral fellow in the Department of Population Health at NYU Grossman School of Medicine.&lt;/p&gt;
    &lt;p&gt;The oral microbiome, the diverse community of bacteria and fungi that inhabit the mouth, is increasingly being studied for its potential role in human health.&lt;/p&gt;
    &lt;p&gt;Last year, the same team of scientists uncovered a link between certain oral bacteria and a heightened risk of developing head and neck squamous cell carcinoma, a group of cancers that arise in the mouth and throat. The researchers had also conducted a small study in 2016 that tied microbes living in the mouth to pancreatic cancer, but could not identify precise bacterial species.&lt;/p&gt;
    &lt;p&gt;Their latest report is the largest and most detailed analysis of its kind to date, says Dr. Meng. It is also the first to show that oral fungi—namely a type of yeast in the genus Candida that naturally lives on the skin and throughout the body—may play a role in pancreatic cancer. The researchers also identified these oral Candida species in patients’ pancreatic tumors.&lt;/p&gt;
    &lt;p&gt;For the study, the team assessed data from two ongoing investigations tracking Americans from across the country to better understand how diet, lifestyle, medical history, and many other factors are involved in cancer. The data were gathered for the American Cancer Society Cancer Prevention Study II and the Prostate, Lung, Colorectal, and Ovarian Cancer Screening Trial.&lt;/p&gt;
    &lt;p&gt;Shortly after enrolling, participants rinsed with mouthwash, providing saliva samples that preserved the numbers and species of microbes for testing. Researchers then followed up for roughly nine years on average to record any presence of tumors.&lt;/p&gt;
    &lt;p&gt;In the current study, the investigators analyzed bacterial and fungal DNA from the spit samples. Then, they identified 445 patients who were diagnosed with pancreatic cancer and compared the DNA of their microbes with that of another 445 randomly selected study subjects who had remained cancer-free. The team made sure to account for factors known to play a role in developing the condition, such as age, race, and how often subjects smoked cigarettes.&lt;/p&gt;
    &lt;p&gt;The findings identified 24 species of bacteria and fungi that individually either raised or lowered pancreatic cancer risk. Another three kinds of bacteria tied to the cancer were already known to contribute to periodontal disease, a serious gum infection that can eat away at the jawbone and the soft tissues surrounding teeth.&lt;/p&gt;
    &lt;p&gt;Altogether, the entire group of microbes boosted participants’ chances of developing the cancer by more than threefold.&lt;/p&gt;
    &lt;p&gt;In addition, by assessing the makeup of each participant’s oral microbiome, the scientists for the first time developed a tool that could estimate their cancer risk.&lt;/p&gt;
    &lt;p&gt;“By profiling bacterial and fungal populations in the mouth, oncologists may be able to flag those most in need of pancreatic cancer screening,” said study co-senior author Jiyoung Ahn, PhD, a professor in the Departments of Population Health and Medicine at NYU Grossman School of Medicine.&lt;/p&gt;
    &lt;p&gt;Dr. Ahn, who is also the associate director for population sciences at Perlmutter Cancer Center, notes that there are currently few effective screening methods for the disease, which is among the deadliest forms of cancer.&lt;/p&gt;
    &lt;p&gt;“It is clearer than ever that brushing and flossing your teeth may not only help prevent periodontal disease but may also protect against cancer,” said study co-senior author Richard Hayes, DDS, MPH, PhD, a professor in the Department of Population Health.&lt;/p&gt;
    &lt;p&gt;Dr. Hayes, who is also a member of Perlmutter Cancer Center, emphasizes that the study was designed to identify correlations between disease risk and certain microbes in the mouth, but not to establish a direct cause-and-effect link. That will require further investigation.&lt;/p&gt;
    &lt;p&gt;The research team next plans to explore whether oral viruses could contribute to cancer and how the mouth’s microbiome may affect patients’ chances of survival, adds Hayes.&lt;/p&gt;
    &lt;p&gt;Funding for the study was provided by National Institutes of Health grants P30CA016087, P20CA252728, R01LM014085, R01CA159036, and U01CA250186.&lt;/p&gt;
    &lt;p&gt;Along with Dr. Meng, Dr. Hayes, and Dr. Ahn, other NYU Langone researchers involved in the study are Feng Wu, PhD; Soyoung Kwak, PhD; Chan Wang, PhD; Tamas A. Gonda, MD; Paul E. Oberstein, MD; and Huilin Li, PhD.&lt;/p&gt;
    &lt;p&gt;Other study co-investigators include Mykhaylo Usyk, PhD, at Albert Einstein College of Medicine in New York City; Neal Freedman, PhD, and Wen-Yi Huang, PhD, at the National Cancer Institute in Rockville, Maryland; and Caroline Um, PhD, at the American Cancer Society in Atlanta.&lt;/p&gt;
    &lt;head rend="h2"&gt;About NYU Langone Health&lt;/head&gt;
    &lt;p&gt;NYU Langone Health is a fully integrated health system that consistently achieves the best patient outcomes through a rigorous focus on quality that has resulted in some of the lowest mortality rates in the nation. Vizient Inc. has ranked NYU Langone number one out of 118 comprehensive academic medical centers across the nation for four years in a row, and U.S. News &amp;amp; World Report recently ranked four of its clinical specialties No. 1 in the nation. NYU Langone offers a comprehensive range of medical services with one high standard of care across seven inpatient locations, its Perlmutter Cancer Center, and more than 320 outpatient locations in the New York area and Florida. With $14.2 billion in revenue this year, the system also includes two tuition-free medical schools, in Manhattan and on Long Island, and a vast research enterprise.&lt;/p&gt;
    &lt;head rend="h3"&gt;Media Inquiries&lt;/head&gt;
    &lt;p&gt;Shira Polan&lt;lb/&gt; Phone: 212-404-4279&lt;lb/&gt; Shira.Polan@NYULangone.org&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nyulangone.org/news/oral-microbes-linked-increased-risk-pancreatic-cancer"/><published>2025-09-26T18:20:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45389965</id><title>If you are harassed by lasers</title><updated>2025-09-27T13:34:05.230701+00:00</updated><content>&lt;doc fingerprint="76c29116b4a1179f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Home&lt;/head&gt;
    &lt;head rend="h2"&gt;A comprehensive resource for safe and responsible laser use&lt;/head&gt;
    &lt;head rend="h1"&gt;If you are harassed by lasers&lt;/head&gt;
    &lt;head rend="h3"&gt;If the light is obviously coming from a laser&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple harassment -- a beam on your skin or clothes -- is probably not punishable unless it continues, or unless it occurs during a critical situation such as driving.&lt;/item&gt;
      &lt;item&gt;Deliberate aiming at your head or eyes is serious due to the unlikely but possible potential for causing eye damage. This could be considered as assault. For more on eye damage, see the information on when does a laser pointer get powerful enough to be dangerous.&lt;/item&gt;
      &lt;item&gt;If you have had laser light in your eyes, see the page If you are hit by a laser.&lt;/item&gt;
      &lt;item&gt;A partial list of laser harassment incidents is here.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, here is a case in 2018 of a visible green laser harassing a number of people at least five times over two weeks. The laser can easily be seen and photographed:&lt;/p&gt;
    &lt;head rend="h3"&gt;If you see laser beams or dots in a photo or video&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;The green and blue "laser" dots at lower left are actually lens flare caused by the bright sun at upper right. The sun is reflecting off elements inside the lens, causing dots or flare. The flare is almost always located diagonally mirrored from a bright light source.&lt;lb/&gt;Photo of a sunset, with upper and lower "beams" caused by blooming in the camera sensor.&lt;lb/&gt;This is a still frame from a video taken at night by the driver of a moving car, out their driver-side window. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The line on the left is a trail of a flying insect, not a laser beam. It is a curved, short line segment. If it was a laser beam it would be straight and it would not stop in mid-air like this. Plus note that the path is not aimed at the camera or the house. Even if it was a laser beam, it would not hit anyone in the house on the right where the camera is. &lt;/p&gt;
    &lt;p&gt;Click on the picture below to see video of a lens flare which looks remarkably like a laser. However, it is definitely a lens flare; there are many clues as to why it is actually the sun in the upper right reflecting off the inside of camera elements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Lens flare example video (click to start)Why this is not a laser: 1) The green dot does not illuminate or interact with the ground. 2) It looks like an overlay. 3) It moves diagonally opposite to the bright light source (sun), always perfectly tracking it. Example courtesy M.L., Sept. 2021. Taken with a Samsung A10 phone's rear camera.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a case described below (in "A few cases and emails we received"), a woman reported a uniform blue tint on her Blink security camera. The tint was not caused by a laser, but by a flaw in the camera or perhaps a lens effect.&lt;/p&gt;
    &lt;head rend="h3"&gt;If you see light or feel heat from an unknown source&lt;/head&gt;
    &lt;head rend="h4"&gt;Light&lt;/head&gt;
    &lt;p&gt;If you see light that is not from any obvious source, try blocking it. Visible laser light can be blocked by anything that also blocks conventional light, such as a solid curtain, a wall, or even a sheet of paper.&lt;/p&gt;
    &lt;p&gt;If you do see flashes when all external light paths are blocked, consult your doctor or do an internet search. There can be medical conditions that cause flashes.&lt;/p&gt;
    &lt;p&gt;The author of this page has seen "flocks of birds" in daytime and "falling stars" at night. It turned out to be minor retinal detachment that went away. This is one reason the author is sympathetic to people who experience sensations that are 100% real to them, even if the sensations come from inside their bodies.&lt;/p&gt;
    &lt;head rend="h4"&gt;Heat&lt;/head&gt;
    &lt;p&gt;If you feel heat spots, first try to block them, to see if they are coming from outside your body. Try using metal objects such as aluminum foil, a baking sheet or a cast-iron skillet. Hold the material over the area where you are having heat or pain, to see if it goes away.&lt;/p&gt;
    &lt;p&gt;If you continue to feel heat, consult your doctor or do an Internet search. There can be medical conditions that cause localized and/or intermittent feelings of being hot, such as fibromyalgia.&lt;/p&gt;
    &lt;head rend="h4"&gt;Get evidence and/or others to confirm&lt;/head&gt;
    &lt;p&gt;If you want to try and track down the beams, get photographic and/or video evidence if at all possible. Ideally this would be pictures of the beams or the laser "dot", and also pictures of any damage. Note the section above about how photos can have lens flare, sensor blooming or other things internal to the camera.&lt;/p&gt;
    &lt;p&gt;If you have family or friends who can help, ask them to stay with you or stay at your house. If others can confirm what you are seeing or feeling, then they can help you in finding the reasons why.&lt;/p&gt;
    &lt;p&gt;A number of people who contacted us, also contacted their local police. In all cases, the police either investigated but took no action, or declined to investigate. One person said their local police department no longer handled calls involving lasers.&lt;/p&gt;
    &lt;p&gt;It may be helpful to hire a private investigator. They can look into suspicious behavior and evidence, and can try to confirm reports of burn marks, burning sensations, etc. If police action is warranted, the police may take a licensed private investigator more seriously than an ordinary citizen. But beware of unscrupulous private investigators who may claim to help you, but who will only string you along to keep making money off you.&lt;/p&gt;
    &lt;head rend="h3"&gt;If the harassment seems mysterious, ongoing, or well-organized&lt;/head&gt;
    &lt;p&gt;These persons clearly feel effects. But their symptoms are often inexplicable by normal means. For example, they can feel heat on their skin which they believe is from beams going through solid walls. There are some types of electromagnetic radiation, such as terahertz waves and microwaves, which can go through objects. But visible laser light — which is also electromagnetic radiation — is stopped by any material or substance that would also stop conventional light such as from a flashlight.&lt;/p&gt;
    &lt;head rend="h4"&gt;You are not alone …&lt;/head&gt;
    &lt;p&gt;If you are a person plagued by mysterious, unknown causes, the good news is you are not alone. At LaserPointerSafety.com, we used to get calls every month or two from persons who say they are being continually harassed by light and energy beams. (We no longer take such calls, due to their frequency and our inability to solve such mysterious cases.)&lt;/p&gt;
    &lt;p&gt;Clearly these people and you are seeing and feeling something. We understand you are not imagining your sensations — they are real to you.&lt;/p&gt;
    &lt;head rend="h4"&gt;… but the cause is unknown&lt;/head&gt;
    &lt;p&gt;But the bad news is that what you are feeling usually does not have any plausible physical explanation. This means it is very unlikely that mysterious beams or exotic devices are able to cause your symptoms.&lt;/p&gt;
    &lt;p&gt;It is highly unlikely that ordinary persons can buy or otherwise obtain powerful directed energy beams that go through walls. Such devices are exotic and expensive. Even if someone works for the police or military, this would not be regular issue "take home" equipment.&lt;/p&gt;
    &lt;p&gt;Also, there is usually no reason that your neighbors would undertake a prolonged, continual, and expensive attack against you. (Frankly, if they did want to harass or harm you, there are easier and less costly ways to do so.)&lt;/p&gt;
    &lt;p&gt;If you are having such symptoms, the cause, in our view, is most likely something that has gone wrong in your body.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It may be your nerves are misfiring, leading you to see light or feel heat when there is no external source. [In experiments published in 2007, subjects had low-level laser light shined on a rubber hand that was positioned over their own hand. Sixty-six percent of subjects reported heat or tactile sensations from the laser light — even though 1) the light was on a rubber hand, not their own and 2) the laser power was low enough that it would not noticeably heat up even on a real hand.]&lt;/item&gt;
      &lt;item&gt;If you are seeing flashes of light at night, or dark swarms (like a flock of birds) during the daytime in your peripheral vision, this can be due to retinal detachment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It may be something in your brain that is manufacturing false symptoms and/or feelings of being stalked or harassed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are feeling harassed by inexplicable causes, we advise that you see one or more medical specialists such as neurologists. Describe your symptoms to the doctor without going into detail about the potential cause (beams) or reasons (angry neighbors). You can tell the doctor "it feels like this is coming from outside my body" but concentrate on describing the symptoms of what you are experiencing physically and mentally.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If a medical reason is found for your issues, this is reassuring that you are not a victim of organized harassment. Hopefully you can be treated and the sensations will go away.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If there is no medical reason initially found, keep in mind that does not mean that the alternative explanation (angry neighbors are getting exotic beam weapons and aiming them at you) is true. It may be there is a deeper or unknown medical reason. Again, other people have reported similar symptoms, so there must be some common underlying cause in the body or mind.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more information, see the section below "An example case - trying to help a friend".&lt;/p&gt;
    &lt;head rend="h3"&gt;Be careful not to escalate the situation&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In a 2018 case, a man in Arkansas shot and killed a neighbor who, among other harassments, had allegedly aimed red, blue and green lasers into his house. When the neighbor went to pick up a laser pointer, the man thought it was a gun and killed him in claimed self-defense. (The man was acquitted by a jury of first-degree murder charges.)&lt;/item&gt;
      &lt;item&gt;In the example case of "H" which is listed below, a woman who believes her neighbors are harassing her with light and heat beams is going around to their homes with a loaded gun, looking for the source. This may not end well.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whatever the level of harassment, let law enforcement look into it and (hopefully) solve the problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;A few cases and emails we received&lt;/head&gt;
    &lt;p&gt;NOTE: As of September 1 2023, we no longer take calls or reply to emails about heat lasers, strange dots or lines in photos &amp;amp; videos, or "mysterious, ongoing or well-organized" harassments as described above.&lt;lb/&gt; We do sympathize with those experiencing such issues. The most help we can give is to let people know that others have reported similar experiences, so they are not alone. The cases listed below occurred prior to Sept. 1 2023.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt; An example case - "H" is trying to help a friend&lt;/item&gt;
      &lt;item rend="dd-1"&gt;We were contacted by a person we'll call "H", who was trying to help her friend "F" of 30 years.&lt;lb/&gt;About two months before the call, H's friend suddenly (over a period of a few weeks) started seeing mysterious lights and feeling mysterious heat. This is an especially interesting case since:&lt;lb/&gt;1) F was "normal" for decades before this started.&lt;lb/&gt;2) The symptoms that F describes are very common among other people who have contacted us.&lt;lb/&gt;3) H has spent substantial time with F, looking for logical, rational explanations for what F said she was experiencing.&lt;lb/&gt;F at first thought harassing beams were coming from the cable company so the cable wiring was replaced. This did not help. F then thought it was coming from the home security company; that was not the cause. F replaced her ceiling fan since she thought she saw faces in it. Her windows are covered with heavy blankets yet light or heat beams still somehow get in, according to F.&lt;lb/&gt;There are numerous security cameras around F's house but so far she has not captured anyone coming up to the house. Unfortunately, she has started going to neighbors' homes — with a loaded gun — looking for the source. This of course could escalate into a dangerous situation.&lt;lb/&gt;H said there was no apparent cause for F to start seeing lights and feeling heat. F had some traumatic life events such as deaths of close family members, in the two years prior to onset. But there was no single event or physical trauma that corresponded with the start of F's symptoms.&lt;lb/&gt;H has tried to help her friend. For example, H and her husband went to F's home for 16 hours, staying awake through the night and going outside from time to time to look for any unusual activity. They saw and felt nothing abnormal. (F was asleep the entire time so she did not report any strange sightings or feelings during the time H and her husband were there.)&lt;lb/&gt;The police have been at F's home numerous times. But they have not found anything and cannot help further. The FBI was contacted but did not get involved.&lt;lb/&gt;We advised H to have her friend see medical specialists such as a neurologist. F should describe the symptoms (what she is seeing and feeling) without stating that it is coming from the outside.&lt;lb/&gt;We also said that the medical exams and tests may not turn up anything. This is based on our experience where we have never had a person call us back, saying "Oh, the doctor found I had ABC disease" or "It stopped when I started taking XYZ medication."&lt;/item&gt;
      &lt;item rend="dt-2"&gt; Email #1 - Laser harassment 24/7&lt;/item&gt;
      &lt;item rend="dd-2"&gt;&lt;code&gt;We live across the street from a neighbor who has her laser lights on 24 hrs/7days a week. She shines her laser lights in other neighbors faces, heads, at children, family pets, windows of houses, plants and trees (which are singed from being over exposed/burned by laser lights), aircraft, on our parked vehicles, &amp;amp; vehicles driving down the street. When I have been in the front yard my eyes and face start burning from the lasering. The police have been called several times, but state that they cannot do anything.&lt;/code&gt;&lt;code&gt;Here are pictures of the laser attacks:&lt;/code&gt;&lt;code&gt;Do you have any suggestions on how to go about getting this individual to stop harassing &amp;amp; terrorizing us?&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;You described your eyes and face burning when in your front yard. It would take a very powerful and expensive laser to do this. A simple laser pointer would not be able to create heat on your skin at a long distance such as across a yard. The most powerful handheld laser currently available [summer 2010] is the 1-watt Wicked Laser Arctic. It can burn skin but at a very close distance, and the burn is very small such as the size of a pea or less.&lt;lb/&gt;You also stated that various surfaces were singed. Again, it would take a very, very powerful and VERY expensive laser to do this. It is very hard to imagine any use outside of military or police (riot control), and even these are exceedingly rare.&lt;lb/&gt;One way to tell if a laser is being used against you is to see if it only happens when you are in line with a window or similar opening to the outdoors. This is because walls will stop laser beams, but windows can let light through. (Of course, windows also let through sunlight and heat (infrared), so just being warm next to a window can be caused by normal, non-laser reasons.)&lt;lb/&gt;Both photos that you sent have a vertical line that goes through a strong light in the photo. This straight line is NOT a laser. It is an artifact of how some digital cameras work. If there is a light source that is too strong for the camera's digital chip, then all pixels in the same vertical line will be overwhelmed. This is called blooming. You can read more about blooming here.&lt;lb/&gt;One question I have for you is whether you have seen laser beams with your own eyes (not from a camera's video). I am guessing the answer is "no".&lt;lb/&gt;I do not want to say absolutely, positively 100% that there is no laser activity from your neighbor's house. The world is very large, and every now and then there are strange things. However, I am 99.999% sure that there is no laser activity from your neighbor's house. Certainly the photos you have sent depict the blooming effect that is very common on some digital camera chips. There is no doubt that what is in the photos is NOT laser. The other effects you state, such as heating and singeing, are highly, extremely unlikely to be caused by any type of laser that a residential person would have access to or could afford.&lt;/item&gt;
      &lt;item rend="dt-3"&gt; Email #2 - Lasers cause pinpoint holes&lt;/item&gt;
      &lt;item rend="dd-3"&gt;&lt;code&gt;To whom it may concern:&lt;/code&gt;&lt;code&gt;I have been getting burned for now about a year. I have been finding burn holes in my mini-blinds. My dog I have found burn holes on her skin also, Is there anything I can do ? It is really painful and I think they did this so I had to sell my home because I felt that my life was in danger I would be walking in the house and then I would get this burning sensation in my eyes and then I would fell my arms would be burning didn't matter what side of the house I was at I would get burned, I would tell people and they would say that's weird.&lt;/code&gt;&lt;code&gt;So I sold my home because I feel they chased me out by hurting me and my dog. I think they even killed some kittens with this laser flashlight. I am writing to you cause no one help me or those kitten that didn't make or had a chance, I think there should be a law against this it is really scary and painful. Thank you for having this information on the internet and maybe it can help someone.&lt;/code&gt;&lt;code&gt;[Name withheld]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;It is very difficult to use a laser to create holes at long range (more than a few yards or meters). It also requires a very expensive laser, to have enough power to make holes at long range. I would not know why someone would go to this trouble.&lt;lb/&gt;If what you are seeing is small, pinpoint holes, it is highly unlikely that these are from a laser aimed at a distance. Laser beams do spread out, even a little bit. For example, the beam at the aperture (output opening) of a powerful laser might be very small. This might be a few millimeters or up to 1/4" in diameters, and the edge of the hole would be sharp. At a house-to-house distance, the hole might be the size of a quarter at least, and the edges might be more ragged, with burn or scorch marks around the hole.&lt;lb/&gt;If a person is walking around with a hand-held laser (laser pointer or battery-powered laser), then they could get close enough to make small holes or burn marks. For a laser pointer, this takes a LOT of power and is expensive. I do not know why someone would do this. (If they wanted to cause trouble, there are a lot of ways that are more effective, much less expensive, and also hard-to-trace.)&lt;lb/&gt;It is possible for the laser beam to be invisible to our eyes. Infrared lasers have beams which we can't normally see. However, you can use a camcorder to try to see these beams. To try this, point the camcorder at an infrared remote control, which are very common for TVs, etc. When you press a button on the remote control, you should see a light flash in the camcorder viewfinder (but not with your eyes). If your camcorder can see the infrared light, then you should be able to see infrared laser beams using the camcorder's viewfinder or fold-out monitor.&lt;lb/&gt;If someone is using a laser in the way you describe, this is illegal. It is damaging your property, cruelty to animals, and assault &amp;amp; battery. You could call the police -- but you should be sure that you really do have evidence.&lt;lb/&gt;For your own sensations of burning, you may also want to consult a doctor or do research on the Internet. There are some conditions where you may experience burning due to something internal in your body.&lt;/item&gt;
      &lt;item rend="dt-4"&gt; Email #3 - Some suggestions from a person saying they were harassed&lt;/item&gt;
      &lt;item rend="dd-4"&gt;&lt;code&gt;To whom it may concern:&lt;/code&gt;&lt;code&gt;When I read the two stories of people getting harassed by laser pointers, I thought I was reading about my own story.&lt;/code&gt;&lt;code&gt;I was also getting harassed by our neighbor. We complained to the police as well, but we got no help. Both me and my husband saw the green dots, still the authorities were not convinced. It's very difficult to film, since he changed locations from the window and could see us if we try to film or take picture. We finally moved from there and thought it would be over but to our dismay it continued in the second home. We moved in the same area, it was not far enough.&lt;/code&gt;&lt;code&gt;So, I started to do the research about laser pointers and their health risks on people. Here are a couple of suggestions: First, go to your Home Depot or Lowes and get a mirrored privacy film and stick it to your windows. Make sure your windows are completely covered. This will at least give you day time privacy and if they point the laser pointer at it they will get twice as much effect on themselves. Second, do not close your house completely. Leave your windows a crack open, because depending on the type of laser and its strength, all lasers emit radiation. The radiation further dries skin and increase the burning, and does not help in healing. Third, use coconut oil to moisturize skin. And, last, get as many humidifiers and run them until there is enough moisture in the house. This will negate the effects of radiation plus it will provide you with a relief from burning. I hope this helps. Good luck!&lt;/code&gt;&lt;code&gt;Finally, thank you for printing those articles, I thought I was alone. It is helpful to read what other people are going through.&lt;/code&gt;&lt;code&gt;[Name withheld]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;We have found a few people who, even if they moved to a different state, still said they had symptoms of being harassed by lasers. It is more likely that there is something about the person -- some medical or perhaps brain condition -- which is causing the symptoms. We urge such persons to get a medical exam and to stress to the doctor that you really are feeling these sensations (heat, etc.).&lt;lb/&gt;We are printing the information above because it may help others.&lt;list rend="ul"&gt;&lt;item&gt;The suggestion about privacy film is good. If a problem is being caused by visible light lasers, then light-blocking curtains, shades or films will eliminate the problem. You can also simply go into a room without windows or other openings to the outside, and see if the symptoms go away. Visible-light lasers, with a dot or beam that you can see, will be blocked by walls or other light-blocking material. It is theoretically possible that an infrared laser's energy might go through a lightweight material, but even here, putting a wall between you and a suspected laser source would block the infrared light. Note that reflective privacy film will NOT reflect the laser back to a perpetrator. This could only happen if the laser hits the film at an exact 90° angle, both side-to-side and up-and-down.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The point about radiation is not really accurate. Lasers do emit "radiation" -- electromagnetic radiation such as visible, infrared or ultraviolet light. Lasers available to the general public do not emit higher-energy nuclear radiation such as X-rays or gamma rays. Leaving windows open will not have any effect on light or radiation. For example, even a beam of X-rays will not somehow "build up" in a house. This is like saying leaving your oven on at 200 degrees will build up heat until an hour or two later it is 2000 degrees — not true.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The suggestions about coconut oil and humidifiers may help. If you do feel burning sensations, using a cream or having extra moisture in the air could be beneficial.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt; Telephone call - Blue light on Blink camera&lt;/item&gt;
      &lt;item rend="dd-5"&gt;In late 2020, a woman called saying that an unfriendly neighbor may be aiming a blue laser at persons in her driveway. The people did not see any blue light or blue flash, but a Blink security camera had blue images when the persons were in the driveway.&lt;lb/&gt;Before going to the police, she sent photos showing the normal security camera view, and the blue-tinted view. Here is a portion of the photos:&lt;lb/&gt;The normal camera view&lt;lb/&gt;When the "laser" was on — a uniform blue tint (it turned out not to be caused by a laser)The photos clearly show it was not a laser. The tint is uniform, whereas a laser hitting the camera would cause a bright spot or complete whiteout or blueout of the camera image. Also, the tint is steady. A handheld laser from across the street would flash in the camera, since the neighbor could not hold the laser completely steady. (Even most tripods would not be 100% steady from such a distance — there would be some brightness fluctuation.)&lt;lb/&gt;There were other indications as well that this was not a laser. The camera was the only evidence of unusual activity. No person saw laser dots or beams. The blue tint occurred only during the day; usually laser harassment is at dusk or night.&lt;lb/&gt;It turns out that Blink cameras can have a blue tint under certain circumstances as discussed here and here. None of these seemed to apply to the woman's situation — it was not cold, nor snowy. The tint occurred only at certain times or when there was a person in the view. And yet the cause had to be with the camera or perhaps the lens (e.g., angle to the sun at certain times).&lt;lb/&gt;We recommended that she swap out the driveway Blink camera for one of the other Blink cameras on her property. This could help decide if the blue tint was due to a problem in the camera or perhaps due to the sun being at a certain angle when looking at the driveway view.&lt;lb/&gt;Either way, the blue tint was not caused by a laser. This put her mind at ease and prevented an unnecessary trip to the police.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;More information about mysterious or ongoing attacks&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt; Why would ordinary citizens be targeted?&lt;/item&gt;
      &lt;item rend="dd-1"&gt;It seems unlikely that directed energy devices would be available or affordable to ordinary persons who want to harass other persons. Or whether such devices would be used by the government against ordinary citizens who don’t have vital state secrets.&lt;lb/&gt;We cannot help with issues about non-visible lasers or directed energy devices. However, below are links to resources which may be of interest to persons who feel they are deliberately targeted by mysterious devices.&lt;/item&gt;
      &lt;item rend="dt-2"&gt; Links about covert harassment and directed energy devices&lt;/item&gt;
      &lt;item rend="dd-2"&gt;The first two resources have links to other websites, organizations and videos of interest (too many links to list here). Thanks to Jeannie for her help with this list.&lt;list rend="ul"&gt;&lt;item&gt;People Against Covert Torture &amp;amp; Surveillance, International From their home page: “PACTS, International is a support network for those targeted with organized stalking and remote electronic assaults, also known as electronic harassment. Electronic harassment in this context refers to the use of radio frequencies and other methods to remotely access a person's mind and/or body to gain control of the individual or group of persons.” Much of the information at their site is in links to their newsletter, such as this newsletter page.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The "Stop Gangstalking Awareness Group", and especially this page about "Understanding Neuro Weapons." LaserPointerSafety has not evaluated the accuracy or usefulness of this group or their information. (Thanks to M.D. in July 2024 for bringing this to our attention.)&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The 2015 Covert Harassment Conference in Berlin. This contains videos and a list of the program; the material is in English. There was also a 2014 Covert Harassment Conference.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;A 2002 presentation by Dr. Reinhard Munzert, “Targeting the Human with Directed Energy Weapons”, here and here among other places.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The book "The E-Bomb: How America's New Directed Energy Weapons Will Change the Way Future Wars Will Be Fought" by Dr. Doug Beason, physicist, a Fellow of the American Physical Society, and former Chief Scientist for the USAF Space Command. From Amazon: "After more than two decades of research, the United States is on the verge of deploying a new generation of weapons that discharge light-wave energy, the same spectrum of energy found in your microwave, or in your TV remote control. It's called directed energy -- lasers, high-powered microwaves, and particle beams. And it's a revolution in weaponry, perhaps, more profound than the atomic bomb. The E-Bomb author Doug Beason, a leading expert in directed-energy research, describes in clear and jargon-free prose all of these exotic new weapons."&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;A July 19 2019 article in the Military Times entitled "Pentagon scientists are making talking plasma laser balls for use as non-lethal weapons" describes how lasers can be used for "heating up a target’s skin to extremely uncomfortable levels without burning them, blasting confusing noises or giving voice commands such as, 'Stop or we’ll be forced to fire upon you.'" As of the article date, the talking plasma ball distance involved is currently within "the short range of a laboratory setting", with a goal of 100 meters to multiple kilometers. (Note that it is unlikely that such lasers are being used outside of military applications; for example, by one neighbor upon another neighbor. Also, it is not known if such lasers could cause effects through solid walls.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-3"&gt; Mysterious Cuba attacks - microwaves or a "shared functional disorder"?&lt;/item&gt;
      &lt;item rend="dd-3"&gt;Persons who feel they have been targeted by mysterious enemies with directed energy devices may want to consider the case of the U.S. diplomats in Cuba afflicted by "Havana syndrome."&lt;lb/&gt;In August 2017, reports came out that numerous U.S. diplomats serving in Cuba had been affected by mysterious “acoustic attacks.” Symptoms included hearing a buzzing sound, having headaches, hearing loss, balance issues and nausea. CBS News reported “mild traumatic brain injuries and possible damage to the central nervous system as a result of the attacks.”&lt;lb/&gt;The question is whether Cuba targeted diplomats with an actual device, whether it was caused by pesticides or other untargeted source … or whether this may have been "mass hysteria." According to a report in Newsweek:&lt;lb/&gt;“Mass hysteria is the rapid spread of illness symptoms for which there is no organic cause,” [Robert] Bartholomew [author of a book on the topic] told Newsweek. “It happens in normal, healthy people—it’s not just ‘all in their heads’ because they do experience symptoms.”&lt;lb/&gt;Jon Stone, a neurologist from the University of Edinburgh first consulted for the Guardian article, agrees. “To consider this diagnostic possibility properly you have to strip away its negative connotations. The symptoms experienced in outbreaks of ‘mass hysteria’ are genuine and not faked or imaginary,” he told Newsweek.&lt;lb/&gt;Stone argues that the term "mass hysteria" itself sounds sensational and far-fetched. In reality, it is not as uncommon as you might think. He explains: “‘Mass hysteria’ is so laden with negativity, it badly distorts its own case. It suggests shrieking and raving individuals—not hard-working and normal people who mostly get functional disorders in everyday practice.”&lt;lb/&gt;A better, less stigmatizing term, says Stone, is “share functional disorder.” He defines the condition as a genuinely experienced illness, “in which there is some disturbance of bodily functioning which conventional diagnostic techniques fail to register.”&lt;lb/&gt;There are interesting parallels with Havana syndrome and persons reporting unexplained laser harassment.&lt;lb/&gt;Similarities&lt;lb/&gt;In the Cuba case, around 25 U.S. diplomats, and 14 Canadian diplomats — persons who would be considered reliable and rational — reported hearing mysterious sounds and began having unusual, unexplained health problems. There have been numerous studies conducted by the U.S., Canada, Cuba, that as of early 2020 have not definitively established any cause. Experts are even divided on whether there is any physical change in the brains of the affected persons.&lt;lb/&gt;In laser harassment cases, numerous persons — most of whom sound reliable and rational when we talk with them — report seeing lights and feeling heat from mysterious sources. Police, friends, family and medical experts trying to help them have been unable to find a cause. The only thing that is certain is the persons have genuine symptoms that are not faked or imaginary. To others, there may be no rational explanation — but the symptoms are genuinely experienced.&lt;lb/&gt;Differences&lt;lb/&gt;One difference between the Cuba case and persons reporting unexplained laser harassment is that the latter are widely scattered. In Cuba there is the possibility of all the diplomats being exposed to the same causal factor (still unknown but possibly sound or pesticides). But persons reporting laser harassment are widely scattered across the U.S. and Canada. Perhaps there is a common cause within the environment.&lt;lb/&gt;Also, the definition of mass psychogenic illness or "mass hysteria" almost always occurs in a relatively small group of people living or working together. This is true for the Cuba cases. But in the laser harassment cases, victims are again widely scattered and do not know, interact, or correspond (e.g. Internet) with each other.&lt;lb/&gt;December 2020 update — microwaves&lt;lb/&gt;A study by the National Academies of Science concluded that the cause was likely microwave energy that may not have been deliberately targeting the diplomats in Cuba. According to an NBC News story quoting the study, "The committee felt that many of the distinctive and acute signs, symptoms and observations reported by (government) employees are consistent with the effects of directed, pulsed radio frequency (RF) energy. Studies published in the open literature more than a half-century ago and over the subsequent decades by Western and Soviet sources provide circumstantial support for this possible mechanism.”&lt;lb/&gt;From the news story:&lt;lb/&gt;The study examined four possibilities to explain the symptoms: Infection, chemicals, psychological factors and microwave energy.&lt;lb/&gt;“Overall, directed pulsed RF energy … appears to be the most plausible mechanism in explaining these cases among those that the committee considered. ... The committee cannot rule out other possible mechanisms and considers it likely that a multiplicity of factors explains some cases and the differences between others.”&lt;lb/&gt;The report says more investigation is required.&lt;lb/&gt;Summary&lt;lb/&gt;LaserPointerSafety.com we are not aware of microwave directing devices that an ordinary citizen could purchase to cause problems for neighbors. It may be possible for a technically minded person to buy or modify devices and beam microwaves at other persons. But we are not experts in microwaves so we cannot give any more advice or opinion.&lt;/item&gt;
      &lt;item rend="dt-4"&gt; An email about directed energy weapons: Are we naive?&lt;/item&gt;
      &lt;item rend="dd-4"&gt;We received the following email in July 2019. It has been slightly edited for clarity and to avoid identifying information.&lt;code&gt;I just read your article on lasers and questions people emailed to you, all were very interesting.&lt;/code&gt;&lt;code&gt;In reading these it appeared to me most of these questions were based on Directed Energy Weapons - DEW (Microwave) rather than the laser beams per se. (i.e., laser beam in a pilots eyes).&lt;/code&gt;&lt;code&gt;I strongly disagree with you on the Cuban episode. First of all, I found your answer very naive, and I'm not trying to be mean, its just that you haven't done your homework on how those hell bent on hurting others obtain these military weapons! It's called Black Market, the Mexican Cartel (Sinanola or El Chapo) drug organization buy these DEW by the truck load from (hate to say this) crooked defense companies.&lt;/code&gt;&lt;code&gt;In turn these military weapons are given out like Hershey bars to Stalkers (MS-13) the large white van pulls up and delivers them right in your neighborhood purchased by the Cartel. Its big business. I'm assuming the Cuban government more than likely purchased these DEW weapons to threaten and hurt the Americans working in Cuba.&lt;/code&gt;&lt;code&gt;I keep reminding those that don't understand this Mexican Cartel they are extremely organized and extremely rich! They can and do buy anyone and anything! Most people don't even realize they have several submarines. This theory that everyone can get sick if enough people say they're sick, and blah blah blah, is just that, a theory. We're talking about the real world here. Unfortunately, it's the dark side, the hidden side that most don't even realize is out there.&lt;/code&gt;&lt;code&gt;So when these Americans complained about being hit and knocked down, believe them! My advice is do some studying on this weapon, yes its covert, silent and does shoot right thru walls,, it can hurt you and even kill you. Think of yourself as a potato, and what does it do if microwaved. My suggestion is get the book The E-Bomb: How America's New Directed Energy Weapons Will Change the Way Future Wars Will Be Fought. Unfortunately, you will NOT find any book in the library on this cartel, why? They're either stolen or lost.&lt;/code&gt;&lt;code&gt;You would not believe how many American citizens are now employed by this Mexican Cartel living right here in the good ole USA, and they ALL have this DEW weapon!&lt;/code&gt;&lt;code&gt;I would like to ask you if anything has been made to be able to catch a laser beam in motion and have it returned to the bad guy? I do not mean 'take' it to the bad guy (like a missile) I'm thinking perhaps a 'mirror-like' device.&lt;/code&gt;&lt;code&gt;[Name withheld; former employee at a defense contractor working on microwave devices]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;Thank you for your letter.&lt;lb/&gt;I haven't done a lot of homework on DEWs since my main interest is in visible lasers. I get calls about once every month or two from people who have experienced heat or light that I cannot explain. That's why my webpage includes links to other directed energy information sources.&lt;lb/&gt;I will say I'm not sure why Mexican cartels or human traffickers would target the people I hear from. They seem like normal people in residential neighborhoods. If the cartels wanted them gone, they certainly have other, much worse ways to do this.&lt;lb/&gt;I just downloaded the E-Bomb book in Kindle format. I will read it soon.&lt;lb/&gt;About your letter... I do want to bring forth other views. Would it be OK if I printed all or parts of it on the "If you are harassed by lasers" webpage at LaserPointerSafety.com? Without your name or identifying information, of course.&lt;lb/&gt;Finally, for visible lasers, you could use a retroreflector to return the light to the source. The beam may be degraded enough that if it could cause heat at the retroreflector, the returned beam (having gone twice as far and having bounced off possibly dirty or dusty surfaces) would be weaker and thus not able to harm anyone at the source area.&lt;lb/&gt;At a minimum, you would need a high-quality, industrial or research quality corner cube retroreflector like these. An inexpensive "cat's eye" bicycle retroreflector or similar would cause a bright glow to be seen at the source, but would not cause a coherent beam to be reflected back.&lt;lb/&gt;The original author's response:&lt;code&gt;Thanks for getting back to me so quickly, it's appreciated.&lt;/code&gt;&lt;code&gt;Yes, you can use what I wrote if it helps the targets. To help you to understand why good people end up targets is because more than likely they have interfered with something the Cartel is doing, like selling drugs, or human trafficking, they might have alerted the police, or see something say something. It could even be someone hired stalkers to hurt you because of some vendetta, or just pure revenge!&lt;/code&gt;&lt;code&gt;They could/can kill you. But, in most cases they just want to provoke you or harass you while hurting you with this DEW weapon. It's called a 'slow cooker' for a reason. It's nothing but pure evil.&lt;/code&gt;&lt;code&gt;I would like to see this hand held DEW put out of business and the defense companies fined big time for selling it, especially to the Cartels but, I'm reading where Directed Energy is being used even more than ever by other countries within the military sector. Lasers as well. I'm not against high technology but I am against something like this getting into the wrong hands.&lt;/code&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt; Another email with a detailed theory&lt;/item&gt;
      &lt;item rend="dd-5"&gt;In March 2020 we received an email from Anthony Arellano describing in great detail how sonic and heat attacks could theoretically be done.&lt;lb/&gt;We are providing the document as an example.&lt;lb/&gt;We have not reviewed and do not endorse this information. Please independently research this before taking any actions based on the information.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;We cannot help in mysterious or non-obvious cases&lt;/head&gt;
    &lt;p&gt;We do not have expertise about non-visible lasers or directed energy devices. Do not contact us, since we will no longer reply as of September 1 2023. If you are experiencing this, you should check the links above about covert harassment and directed energy devices.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.laserpointersafety.com/harassment.html"/><published>2025-09-26T19:12:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45390856</id><title>How insurance risk is transformed into investable assets</title><updated>2025-09-27T13:34:04.888439+00:00</updated><content>&lt;doc fingerprint="2954309d71ae7140"&gt;
  &lt;main&gt;
    &lt;p&gt;Insurance risk involves the sale of insurance policies to policyholders, the receipt of premium and the payment of claims. If claims &amp;amp; associated expenses are less than premium received, an Underwriting Profit is made. If claims are greater than premium, an Underwriting Loss occurs. In essence, investing in insurance risk is like partnering with an insurer — you share in the results of the portfolio, keeping a slice of the underwriting profit if claims come in below premiums, or sustaining a loss if they come in above.&lt;/p&gt;
    &lt;head rend="h2"&gt;Most Insurance Is Not Fully Collateralized&lt;/head&gt;
    &lt;p&gt;This brings us to the concept of collateralization. An everyday example of collateral involves your mortgage. When you take out a loan from the bank to buy a house, you're putting up the house itself as collateral for the loan to secure it - meaning, if you fail to pay back the loan, the bank can foreclose and sell the house to cover the loan.&lt;/p&gt;
    &lt;p&gt;The key observation about insurance risk is the possibility for insurers to pay out more money in claims than they take in via policy premiums. When you purchase a policy from an insurance company, you’re implicitly trusting that the insurance company will be able to pay you out in the event of a claim, even if it means they’re operating at a loss. Insurance companies have a balance sheet (basically, an amount of assets or money) which acts as collateral against the chance that they must pay out more than they take in.&lt;/p&gt;
    &lt;p&gt;The amount of money held by the insurance company for this purpose is known as insurance capital &amp;amp; surplus. Since this amount of capital is less than the total sum of all policy limits, we can say the policies are partially collateralized.&lt;/p&gt;
    &lt;head rend="h3"&gt;Visualizing How Insurance Losses Are Distributed&lt;/head&gt;
    &lt;p&gt;The chart below illustrates this concept with a probability distribution. The blue curve shows the likelihood of different loss levels. It peaks around 60-70% of premium but has a long tail extending to extreme scenarios.&lt;/p&gt;
    &lt;p&gt;The insurance company in this example holds capital equal to 175% of premium collected, giving them total resources of 275% of premium (100% premium + 175% capital) to pay claims in extreme years.&lt;/p&gt;
    &lt;p&gt;The green dashed line shows the return on capital from underwriting activities. When losses are less than premium collected (green zone), the insurer keeps the difference as profit. Once losses exceed the break-even point at 100%, the insurer must use their capital reserves to pay claims (red zone). Think of it like making an "investment" with the premium you collected, but getting such a negative return that you have to reach into your wallet to cover the losses (red line).&lt;/p&gt;
    &lt;head rend="h4"&gt;Chart Legend:&lt;/head&gt;
    &lt;head rend="h3"&gt;Key Insight&lt;/head&gt;
    &lt;head rend="h2"&gt;Some Retail Investments Are Partially Collateralized&lt;/head&gt;
    &lt;p&gt;Retail brokerages offer margin accounts to those customers that have sufficient assets to support it - much like the insurance company capital - and reserve the right to make a margin call if those trader’s reserves fall below minimum requirements. In extreme cases, it’s even possible for a trader to end up in a position where the brokerage could not sell collateral quickly enough and they’re left with a negative balance which must be filled with assets from elsewhere.&lt;/p&gt;
    &lt;p&gt;In the same way, insurers must maintain capital to meet extreme claims. Both systems rely on partial collateralization: enough to cover most outcomes, but not the absolute maximum.&lt;/p&gt;
    &lt;p&gt;Therein lies a critical implication: The entire balance sheet of the insurance company is available and backing each individual policy. This is similar to your margin account, as if your account balance (collateral) goes below zero, you'll have to pull from assets outside to cover the debt.&lt;/p&gt;
    &lt;p&gt;This is one of the fundamental reasons why regulators restrict retail investors from direct insurance risk investments. A strong knowledge base of how the risk works is needed to understand you're not just exposed to losing your investment, but other assets as well. For history buffs, I recommend reading Andrew Duguld's On the Brink: How a Crisis Transformed Lloyd's of London1for a fascinating first-hand account of the Names at Lloyd's. These individuals once pledged their entire personal wealth to back insurance syndicates, sometimes with catastrophic consequences.&lt;/p&gt;
    &lt;head rend="h2"&gt;Insurance Risk Investments For Retail Are Almost Always Fully Collateralized&lt;/head&gt;
    &lt;p&gt;So what have we learned from this comparison? Three points stand out:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;1Insurance risk is exposed to losses exceeding the premium received&lt;/item&gt;
      &lt;item&gt;2Collateral needs to be set aside in case of these outsized losses to ensure trust in the insurance product&lt;/item&gt;
      &lt;item&gt;3Outside (especially Retail) Investors would be best to limit their exposure to losses beyond their investment&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The challenge, then, is clear: how can retail investors access insurance risk without facing the danger of unlimited losses? The solution has been to design fully collateralized structures as vehicles that capture underwriting profits while capping potential losses at your invested amount. One of the most intuitive examples comes from adapting reinsurance structures into a format investors can access.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case Study: CAT Bonds&lt;/head&gt;
    &lt;p&gt;Catastrophe Bonds, or "CAT Bonds", are the most widely known form of investable insurance risk. If we ignore the insurance implications of it for a second, CAT Bonds are just like any other corporate bond: they are issued by a firm, pay a coupon, have a maturity date and have an associated risk of default (not being paid back principal).&lt;/p&gt;
    &lt;p&gt;The difference here is the risk of default of a CAT bond is tied in someway to insurance losses. If a qualifying insurance event happens, the principal is kept by the insurance company to pay those claims, effectively defaulting the bond. They are referred to as "Catastrophe" bonds simply because they are most often tied to large, catastrophic events such as Hurricanes, Earthquakes, or even Cyber events.&lt;/p&gt;
    &lt;p&gt;CAT Bonds can be thought of as an insurance policy bought by the insurance company itself. They are, in fact, usually a compliment to the insurance company's full reinsurance program. Here, however, the insurance company isn't buying a policy from another insurance company, but rather outside capital markets on a fully collateralized basis.&lt;/p&gt;
    &lt;p&gt;Let's form our own very basic CAT bond. We're Risksure - a Florida based insurance company - and we write a lot of homeowners policies in the sunshine state. We'd like to take out the following CAT bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sponsor: Risksure Re&lt;/item&gt;
      &lt;item&gt;Bond Size (Limit): $100M&lt;/item&gt;
      &lt;item&gt;Attachment Point (Deductible): $500M (Risksure covers the first $500M of losses)&lt;/item&gt;
      &lt;item&gt;Issuance Date: Jan 1, 2026&lt;/item&gt;
      &lt;item&gt;Maturity Date: Dec 31, 2026&lt;/item&gt;
      &lt;item&gt;Coupon (Premium): 9% annually, rate paid quarterly on current collateral balance&lt;/item&gt;
      &lt;item&gt;Terms: If a hurricane strikes Florida in 2026 and Risksure’s losses exceed $500M, investors’ principal is used to cover those excess losses, up to $100M. This is known as a per occurrence limit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h6"&gt;CAT Bond: Gator Re Ltd. 🐊&lt;/head&gt;
    &lt;p&gt;To issue this Bond, Risksure Re would collect $100M of principal from outside investors, thus fully collateralizing the insurance risk. In return, Risksure Re would pay $9M of premium for the bond, and should no hurricane event occur, pay back the $100M of principal at maturity.&lt;/p&gt;
    &lt;p&gt;This type of structure is common in reinsurance and known as an excess of loss structure. The layer of coverage can be visualized as follows:&lt;/p&gt;
    &lt;head rend="h3"&gt;How It Works&lt;/head&gt;
    &lt;head rend="h2"&gt;Investment Returns for Gator Re Ltd. 🐊&lt;/head&gt;
    &lt;p&gt;There are two components of return for the investors in our CAT Bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Risk Return: Compensation for taking on the insurance risk, paid for by the 9% coupon&lt;/item&gt;
      &lt;item&gt;Risk Free Return: Compensation for tying up capital, in the form of interest income on the collateral sitting in the bank, say by investing it in 4% T-bonds.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It's clear that with this structure, the investors are taking on insurance risk exposure. However, in this case, the "buyer" of the insurance policy (the insurance company itself) does not need to worry that the insurer (the outside investors) will not be able pay claims if the large event happens, because the entire value of the policy limit ($100M limit) is set aside and can't be touched.&lt;/p&gt;
    &lt;p&gt;We can now examine and visualize a few potential outcomes for the buyers of the CAT bond:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No Hurricane: Capital providers get back $9M Risk Income + $4M Risk-free Income = $13M along with their original $100M of investment, a 13% return.&lt;/item&gt;
      &lt;item&gt;A Partial Loss: Risksure suffers $525M of loss from a covered hurricane. Risksure pays the first $500M. They then use $25M of the paid in capital from the CAT bond to pay for the remaining claims. Assuming mid-year trigger, capital providers will receive back the remaining $75M, plus the $7.78M Risk Income (two coupons paid plus two partial coupons), plus reduced RF income due to the used capital, $3.5M, for a total of $86.28M. This is a negative 13.72% return.&lt;/item&gt;
      &lt;item&gt;A Full Loss: A massive hurricane hits Florida and Risksure pays out $1B in losses, far above the exhaustion point of $600M for this CAT bond. The entirety of the $100M principle and risk free income goes towards paying Risksure's policyholder claims. Investors received $4.5M in coupons before trigger and no principle, for a loss of 95.5%.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Keen observers will notice that we've successfully transformed the insurance risk into a limited liability product - you can no longer owe additional capital beyond your original investment. However, it's clear that investing in insurance risk in this manner should be treated as a compliment to other investment strategies. Bear markets for equities might return -30% to -50%, but crucially, they retain the potential to recover those losses over time. CAT bonds offer no such recovery potential - once triggered, that capital is permanently lost. That said, the stated probability of default for these bonds is typically 1-3%, meaning the 5-9% excess returns above risk-free rates are designed to compensate for this low-probability but high-severity risk.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Final Note: Why Isn't Insurance Fully Collateralized?&lt;/head&gt;
    &lt;p&gt;A natural question arises through this analysis: why aren't insurance companies forced to hold enough money to cover all potential loss scenarios? The short answer is efficiency. The less capital you have to hold, the larger your returns on capital will be. This can be illustrated with simple math. Say you hold $10M in capital and expect a profit of $500K on underwriting business. Expected return is $500K/$10M = 5%. But let's say now you only have to hold $5M in capital - your return on capital has now jumped to $500K/$5M = 10%. By holding fully collateralized layers, CAT bonds are trading capital efficiency for payment certainty.&lt;/p&gt;
    &lt;p&gt;Referring back to the chart at the beginning of the article, those extremely remote loss scenarios have exceedingly low likelihood of happening for a sufficiently large and diverse insurance company. Each insurance company has a team of actuaries and risk modelers dedicated to ensuring the ongoing solvency of the company. Regulators setup frameworks to validate and set guidelines for the amount of capital a company needs to hold. With all that said, insurance companies can and do fail, at which point regulators can swoop in to protect policyholders.&lt;/p&gt;
    &lt;p&gt;This is why under collateralized insurance "works" - there are many checks and balances along the way to align incentives. It's also why giving outside investors access to insurance risk is such a challenge; without those protections in place, guardrails (such as full collateralization) have to be setup such that insurance policies can be sure their claims will be paid.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://riskvest.io/riskvest-insights/transforming-insurance-risk"/><published>2025-09-26T20:46:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45391444</id><title>Moondream 3 Preview: Frontier-level reasoning at a blazing speed</title><updated>2025-09-27T13:34:04.736703+00:00</updated><content>&lt;doc fingerprint="ed439b79801b9f8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Moondream 3 Preview&lt;/head&gt;
    &lt;p&gt;We're excited to announce a preview release of Moondream 3. It's a new architecture of 9B MoE, with 2B active params. Moondream now achieves frontier-level visual reasoning while still retaining blazingly fast and efficient inference.&lt;/p&gt;
    &lt;p&gt;Why A New Architecture&lt;lb/&gt; The impact of AI today has largely been relegated to the digital realm. We have agents that can code, produce digital art, and so on - but very few cases of AI operating in our physical world. No robots to clean our houses, or act as receptionists, or inspect buildings, etc… For Moondream 3, we focused on 4 key areas.&lt;/p&gt;
    &lt;p&gt;Visual reasoning: despite our focus on smaller models, we don't want that to come at the cost of capability. We want Moondream to be the most capable VLM at real-world tasks.&lt;/p&gt;
    &lt;p&gt;Trainable: Many vision tasks require specialization. It's not enough for VLMs to be as good as humans. Even humans need training when it comes to complex tasks. Accurately interpreting an X-Ray image, or detecting struggling people in crowds. Moondream must be easily trainable.&lt;/p&gt;
    &lt;p&gt;Fast: Vision AI applications often need near-realtime performance. Sorting produce, or detecting missing herd animals from a drone, or recognizing security incidents - none of these tasks can be built without fast vision inference.&lt;/p&gt;
    &lt;p&gt;Inexpensive: Vision AI apps often deal with huge quantities of images, and cost can often be a blocker to adoption. Moondream must be cheap to run at scale.&lt;/p&gt;
    &lt;p&gt;Moondream 3 achieves these goals by adopting a 9B MoE model, yet still with 2B active parameters. This enables it to achieve, and in some cases beat, frontier-level models, yet still only require 2B active parameters (keeping it fast and inexpensive). We also improved its training dynamics, making Moondream 3 more efficient at learning, especially when using Reinforcement Learning (more on that in subsequent announcements). For more details on the architecture, head to the "Tech Notes" below. One final detail however: we grew the context length from 2k to 32k, making Moondream much better at understanding and producing more complex queries and answers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Moondream 3 in action&lt;/head&gt;
    &lt;p&gt;Here are some examples of Moondream 3.&lt;/p&gt;
    &lt;head rend="h3"&gt;Object Detection&lt;/head&gt;
    &lt;p&gt;Moondream 3 is astonishingly good at object detection. It goes beyond simple labels (.e.g., "car") and can understand more complex queries. We show results compared to frontier models alongside. These models don't support grounding skills like object detection and pointing natively, so we used a templated query for those (see footer).&lt;/p&gt;
    &lt;p&gt;Example 1&lt;lb/&gt; Prompt: "Runner with purple socks" &lt;/p&gt;
    &lt;p&gt;Example 2&lt;lb/&gt; Prompt: "Quantity input"&lt;/p&gt;
    &lt;head rend="h3"&gt;Pointing&lt;/head&gt;
    &lt;p&gt;Moondream supports pointing as a native skill.&lt;/p&gt;
    &lt;p&gt;Example 3&lt;lb/&gt; Prompt: "Bottle"&lt;/p&gt;
    &lt;p&gt;Example 4&lt;lb/&gt; Prompt: "Best utensil for pasta"&lt;/p&gt;
    &lt;head rend="h3"&gt;Structured output&lt;/head&gt;
    &lt;p&gt;With a longer context length, Moondream 3 generates intelligent structured outputs with minimal prompting.&lt;/p&gt;
    &lt;p&gt;Example 5: Sled dogs&lt;/p&gt;
    &lt;p&gt; Prompt&lt;lb/&gt; "A JSON array with keys: dog_id, fur_color, harness_color."&lt;/p&gt;
    &lt;p&gt;Result&lt;lb/&gt; [&lt;lb/&gt; { "dog_id": 1, "fur_color": "light brown", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 2, "fur_color": "dark brown", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 3, "fur_color": "gray", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 4, "fur_color": "white", "harness_color": "red" },&lt;lb/&gt; { "dog_id": 5, "fur_color": "dark brown", "harness_color": "green" },&lt;lb/&gt; { "dog_id": 6, "fur_color": "light brown", "harness_color": "green" },&lt;lb/&gt; { "dog_id": 7, "fur_color": "dark brown", "harness_color": "black" },&lt;lb/&gt; { "dog_id": 8, "fur_color": "white", "harness_color": "black" }&lt;lb/&gt; ]&lt;/p&gt;
    &lt;head rend="h3"&gt;OCR&lt;/head&gt;
    &lt;p&gt;Moondream 3 has drastically improved its OCR abilities. Our vision encoder can get tripped up on tiny fonts (working on it), but it's now useful in many real-world cases.&lt;/p&gt;
    &lt;p&gt;Example 6&lt;/p&gt;
    &lt;p&gt; Prompt&lt;lb/&gt; "Convert to markdown""&lt;/p&gt;
    &lt;p&gt;Result&lt;/p&gt;
    &lt;p&gt;| Metal | Reaction | Electrode Potential (V) |&lt;lb/&gt; |---|---|---|&lt;lb/&gt; | Gold | Au⁺ + e⁻ = Au | +1.692 |&lt;lb/&gt; | Silver | Ag⁺ + e⁻ = Ag | +0.7996 |&lt;lb/&gt; | Copper | Cu²⁺ + 2e⁻ = Cu | +0.342 |&lt;lb/&gt; | Iron | Fe³⁺ + 3e⁻ = Fe | -0.037 |&lt;lb/&gt; | Lead | Pb²⁺ + 2e⁻ = Pb | -0.126 |&lt;lb/&gt; | Nickel | Ni²⁺ + 2e⁻ = Ni | -0.257 |&lt;lb/&gt; | Cadmium | Cd²⁺ + 2e⁻ = Cd | -0.403 |&lt;lb/&gt; | Iron | Fe²⁺ + 2e⁻ = Fe | -0.447 |&lt;lb/&gt; | Zinc | Zn²⁺ + 2e⁻ = Zn | -0.762 |&lt;lb/&gt; | Aluminum | Al³⁺ + 3e⁻ = Al | -1.662 |&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;Here are some early benchmark results. We show it alongside some top frontier models for comparison. In practice, however, it's probably not a fair comparison for Moondream since, in practical terms, Moondream produces answers in fraction of the time of these bigger models. We'll publish more complete results later and include inference times to make this clearer.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Scores with a "*" next to them indicate that we used a 100 random question sample rather than evaluate the whole benchmark.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;MD3 Preview Technical Notes&lt;/head&gt;
    &lt;p&gt;Here are some details on our new model architecture. Moondeam 3 is a fine-grained sparse mixture-of-experts model with 64 experts, of which 8 are activated for each token. We initialized it from Moondream 2 (a 2B dense model) using drop upcycling. We also extended the usable context length to 32K tokens, which is critical for few-shot prompting and agentic workflows with tool-use. We don’t fully leverage this longer context in our post-training yet (part of why it's only a preview release). The full 32k context is available for you if you're interested in fine-tuning the model.&lt;/p&gt;
    &lt;p&gt;(Figure: Long-context perplexity evaluation on GovReport dataset. Each point shows the average cross-entropy loss (nats per token) for a 128-token sliding window at that position, measured across 100 documents truncated to 32,768 tokens.)&lt;/p&gt;
    &lt;p&gt;We do not use a separate context-length extension phase during training, instead opting to interleave long-context samples while pretraining with a default context length of 4096 tokens. Many context length extension methods like YaRN include an attention temperature scaling component. Inspired by this, we adjust the architecture to enable learned temperature scaling as a function of position, and find this helps with long context modeling.&lt;/p&gt;
    &lt;p&gt;Like our last 2B release, this is a hybrid reasoning model that supports both reasoning and non-reasoning mode. Unlike other reasoning models, however, Moondream focuses on visual reasoning with grounding. Here’s an example of what that means:&lt;/p&gt;
    &lt;p&gt;Each chunk of underlined text in the reasoning is grounded, meaning the model references a particular part of the image. In our playground, you can see what the model is focusing on by hovering over the text.&lt;/p&gt;
    &lt;p&gt;The model starts with only a small set of visual-reasoning examples, and gradually learns to rely on them more during our reinforcement learning (RL) post-training phase. RL proved so effective that, as we refined our training approach, post-training ended up using more compute than the initial pre-training itself.&lt;/p&gt;
    &lt;p&gt;It was trained with load-balancing and router orthogonality losses to help similar tokens specialize together early on, then had load balancing disabled in post-training to avoid catastrophic forgetting from distribution shift. Finally, attention tweaks like learnable temperature and LSE suppression sharpened focus and cut noise—boosting accuracy and clarity.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This preview release comes with some caveats. We haven't optimized the inference code yet, so inferences are much slower than anticipated (we're working on it!). We're also still actively training this model, and we expect the capabilities and benchmarks scores to improve. We also plan to produce variants of this model (e.g., quantized versions and distilled smaller versions).&lt;/p&gt;
    &lt;p&gt;The model is now available on the Moondream playground, and you can download it on HuggingFace (Moondream Station will be updated soon). Hit us up on our Discord if you have any questions.&lt;/p&gt;
    &lt;p&gt;(1) Frontier models don't support object detection natively, so this prompt was used instead:&lt;lb/&gt; Detect these objects in the image: [comma-separated list].&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://moondream.ai/blog/moondream-3-preview"/><published>2025-09-26T21:59:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45391566</id><title>Thoughts on Mechanical Keyboards and the ZSA Moonlander</title><updated>2025-09-27T13:34:04.056452+00:00</updated><content>&lt;doc fingerprint="4d545c11f59d8556"&gt;
  &lt;main&gt;
    &lt;p&gt;I don’t normally review things here, as I find that it’s outside the realm of the blog, but I want to talk about the ZSA Moonlander keyboard, a “mechanical” keyboard that I bought a couple of years ago. But, yeah, in case you’re wondering why I am writing a review: I mean, it’s a keyboard? You type on it. It goes clickety-clack — or maybe not, if you’re an obsessive and want your keyboard quiet. Or maybe you want it loud, like the flexor-destroying IBM model Ms from the days of yore, rat-tat-tatting like a Mac-10. People are into that now: they need to sound right, look right (boba tea colored keys are a thing) and type well. If they light up like a cheap vape stick, even better.&lt;/p&gt;
    &lt;p&gt;To me, it’s a tool; it’s there to minimize strain and injury. I bought the moonlander because it helps me do my job. It’s no different to me than a hammer is to a carpenter, and yet in using it I’ve realized it does expand on what I can do in ways that I feel compelled to talk about. It is a game changer to any keyboard warrior. ZSA’s moonlander is merely one well-crafted incarnation of millions.&lt;/p&gt;
    &lt;p&gt;Ricing your keyboard is a hobby. It’s nearly a religion to some folk: like crossfit and instant pots.&lt;/p&gt;
    &lt;p&gt;One major benefit of this movement is the wealth of opportunity afforded to people like me, and you, who care about finger ergonomy but do not find the old-fashioned options that have long existed on the periphery of peripherals.&lt;/p&gt;
    &lt;p&gt;The specifics of what makes, or doesn’t make, a mechanical keyboard is, I am sure, a tedious conversation that takes place all the time, so I’ll hide behind the phrase I’ll know it when I see it and move swiftly on. (But I’ll argue that quality key switches and firmware are two of the most important ones.)&lt;/p&gt;
    &lt;p&gt;It’s interesting how it’s a whole thing now for enthusiasts to solder, assemble, or buy ready-made mechanical keyboards made by other enthusiasts. It’s also a sign of how dire traditional, commercial keyboards are in quality and choice. With a mechanical keyboard you can pick the type of key switch you want your keys to have: quiet, loud, firm, soft. Linear or non-linear. You can mix and match so some keys are weightier than others: your thumbs are stronger, so you’ll want a weightier key for them.&lt;/p&gt;
    &lt;p&gt;I feel like this movement has sprung up out of nowhere in the last ten years, and it’s resulted in a lot of fun and interesting keyboards. There are novel firmware choices beyond the most manifestly basic idea that pressing a key yields exactly one outcome.&lt;/p&gt;
    &lt;p&gt;Clacky keys and boba tea colored key caps is not why I bought into the mechanical keyboard hype. I have long wanted to ditch the Microsoft Natural Ergonomic 4000 keyboards (who came up with that name?)&lt;/p&gt;
    &lt;p&gt;I had two at all times: one at home and another at work. They’d wear out from use after a couple of years. Total flim-flam. The typing experience was never great, either. But I loved the ergonomic design. I’ve owned around 10 in the last 20 years, as the ergonomics of the keyboard (and lack of serious alternatives) kept me from switching.&lt;/p&gt;
    &lt;p&gt;You see, mechanical keyboards offer hardware flexibility like switchable key caps and switches (the bit that goes click), true; but most of them also come with fancy, free software firmware that opens up a whole world of amazing possibilities. I’ve worked in some pretty weird work environments, and being able to rebind caps lock to control is one of the most important things I have to do on a traditional keyboard, like the aforementioned Microsoft keyboard. I once had to work at a client’s place that mandated I use a garbage-tier Citrix thin client computer that’d read your keyboard’s scan codes and make up its mind later, somewhere en-route to a data center in Paris, what key it should treat it as. I don’t have to tell you that rebinding caps lock to much of anything did not work at all.&lt;/p&gt;
    &lt;p&gt;But, with thoroughly customizable firmware, it’s a snap to deign a key to be what ever you choose; or even multiple things, at different times. Your customizations are in the keyboard’s firmware itself, so you take your changes with you. That’s perfect for someone like me that used to crash through the windows of many a client sites, Mary Poppins-style, keyboard in hand, ready to build software.&lt;/p&gt;
    &lt;p&gt;The value and flexibility of the firmware really is that useful and important. I now recommend that people consider this style of keyboard (or, at the very least, the programmable aspects of a mechanical keyboard) in my book, as it’s a good way to personalize your keyboard workflow to suit your style and needs. Forget binding caps lock to control: move your keys around to suit your physical needs. That is infinitely better than crudely remapping caps lock to control.&lt;/p&gt;
    &lt;p&gt;Back to the Moonlander. The product page did a reasonable (if overly flashy) job of explaining its key benefits over a regular keyboard. The cost? $365. Ouch. It’s not that much money for something that I myself use to make money, but it’s like… it’s just a keyboard. What’s it made out of!? Pressed myrrh and printer ink?&lt;/p&gt;
    &lt;p&gt;Still, it’s not a bad price if the finish and quality matches the price. So I bought it, and it took about 7-8 days to arrive at my house in London, all the way from Taiwan. Returns are apparently not possible, fair enough, as ZSA’s a small business, and Taiwan is a long way away. They recommend you try and sell it yourself if you dislike it. Spare a thought for the guy on eBay who was selling one with blank key caps, around the time I was buying mine, saying it was ‘barely used’…&lt;/p&gt;
    &lt;p&gt;The keyboard only has two years of warranty, though they claim it’s ‘built to last’. So fingers crossed as I’m coming up on 4 years of daily use.&lt;/p&gt;
    &lt;p&gt;What I like about it is that it ticked my main requirement of being touch typist friendly. Sounds dumb, but it has to feel right. Regular keyboards are too packed together. I’m a big guy: I don’t want to squash my shoulders and arms like I do when I type on a laptop keyboard. The keyboard is actually two keyboards. One half of a keyboard for each hand. The right-hand side has a removable cable that plugs into the left-hand side, so you could conceptually get by with just one side, which is a nice touch. The left-hand side has the USB cable, also removable, to connect to your computer. Because it’s in two pieces, I can move each half of the keyboard around to better fit my posture. I like that feature a lot.&lt;/p&gt;
    &lt;p&gt;It’s also surprisingly small, which is not always a benefit, as I’m wide-shouldered with big hands, but it works for me. The portability was not what I was looking for, but it’s come in handy for traveling, as it comes with a soft case pouch. You can put it in carry-on luggage quite easily and take it with you. That’s proven more useful than I thought it would. I’ve flown with the Microsoft keyboards too many times to count, and they’re bulky by comparison.&lt;/p&gt;
    &lt;p&gt;Much like so many keyboards of its type, it comes with “thumb clusters”, a set of four keys that are meant to be reachable primarily with your thumbs. I have large hands, so that works for me, but the red buttons they have on there are a stretch, even for me, to press without shifting my wrist. You can pivot the thumb cluster up or down (or lay it flat against your desk) which is finicky as all hell, as you have to lock it in place and somehow try to keep it from wobbling.&lt;/p&gt;
    &lt;p&gt;One, ah, novelty of the Moonlander is what they call tenting. It’s a pole that you can use to tilt each half of the keyboard to attain – they claim – a more ‘ergonomic’ position for your hands. The problem is, when you’re pitching your ‘tent’ (stop snickering), locking it into position (you’ll need a hex key to fasten the bolts on the thumb clusters and poles) so that your keyboard does not wobble is challenging to say the least. It works much like a table in a restaurant: no matter what, it’s going to wobble a bit. Maybe not today, but perhaps tomorrow; or when you type a bit more forcefully; or when you put more weight on one part of the keyboard because you pressed a button a bit more forcefully.&lt;/p&gt;
    &lt;p&gt;It’s poorly designed. I don’t want to overtighten the bolts for fear of shearing something, and even if you do want to throw a bit more torque into it, you’re most likely going to push the cluster or tent pole out of position when you try, resulting in a wobbly keyboard. One frustration I ran into is that you cannot pivot the thumb cluster up, so it juts into the air, and also use the tent poles. That leaves the keyboard unbalanced and you cannot type on it.&lt;/p&gt;
    &lt;p&gt;The keyboard also has two optional hand rests that pivot so you can fold them underneath the keyboard for portability. They’re made of the same flimsy plastic that train station lavatory seats are made of. Worse, they have a few unfinished edges — not at all sharp enough to hurt you, but still sharp enough that you’re reminded of how little attention was lavished on this part of an otherwise really well-made keyboard. The rests are attached to a bar to let them pivot, but unfortunately the manufacturing tolerances aren’t great, so they wobble a bit when I shift the weight of my hands around, which is also not good. I wish it had a nice leatherette foam cushion like the Microsoft keyboards did, as the plastic is hard to the touch.&lt;/p&gt;
    &lt;p&gt;I got one of those automated emails after a few months asking for feedback, and I asked about the wobbly rests and unfinished edges; and how you can’t tilt the keyboard and also raise the keyboard cluster. I got a polite email back explaining that the wobble had to be there to facilitate movement and give, and that I could buy their tenting kit to fix the keyboard cluster problem. No answers were forthcoming on the unfinished edges. Make of that what you will.&lt;/p&gt;
    &lt;p&gt;The keyboard is backlit with RGB LEDs, which are a bit frou-frou, though useful if you want to use the firmware’s layering functionality to add multi-modality to keys. Being able to tell layers apart by looking at the keyboard colors work well. The keyboard uses the QMK firmware, a polished and feature rich free software firmware that’s been extended with Moonlander-specific features. Their firmware changes are public and available on Github.&lt;/p&gt;
    &lt;p&gt;The main advantage of Moonlander (really, the QMK firmware) is the ability to program your keys to do more than just one thing. Yes, you can do keyboard macros, but that is not even the most interesting thing. For instance, you can make a key – say your space key – act as the control modifier if you hold it down and type another key at the same time. You can make it behave like a Space Cadet keyboard: tap left shift and it inserts &lt;code&gt;(&lt;/code&gt;; right, and it inserts &lt;code&gt;)&lt;/code&gt;. You can designate a key to toggle a new keyboard layer, letting you type accented characters, control your media player with media keys, and more. There are dozens of features and you have complete control over what each key will do.&lt;/p&gt;
    &lt;p&gt;I ordered the keyboard with the recommended Cherry Brown MX switches – those are the key switches the plastic key caps sit atop of, and you can choose which ones you want when you buy, or even replace them yourself after the fact – and they, much like the key caps and the main body of the keyboard, are of high quality and feel good to type on. I have zero complaints about this part of the build quality, and the main body of the keyboard is well made and sturdy. I can tell they spent a lot of engineering effort on that.&lt;/p&gt;
    &lt;p&gt;There’s a lot of dubious health advice on ergonomics out there that feels unfounded and speculative. And proponents of mechanical keyboards say you need fewer keys than a regular keyboard, for reasons, and to instead use the fancy firmware features to make up for the things they’ve taken away from you, in effect forcing you to use the layer functionality present in the firmware. By and large the mechanical keyboard community is friendly, but more than a little fad-driven and with that spicy melange of broscience and earnest helpfulness.&lt;/p&gt;
    &lt;p&gt;This keyboard, like many of its kind, is not a “full-sized” keyboard. There are fewer keys. No F-keys by default, though they’re behind a layered key in the default configuration; the dedicated column of navigation (arrows, page up/down, etc.) keys are missing, though scattered about. There is no dedicated section of numpad keys, either. The keys are all there, but hidden behind several layers that you access from certain trigger keys that activate when you press one of them.&lt;/p&gt;
    &lt;p&gt;I’m ambivalent about losing out on all the keys, especially as, well, I’m an Emacs user. I’ve adapted, and it’s fine, and I like the current setup I have now, but that part will take some getting used to. It took me a long time to get back up to speed, and there are still key combos that I could tap out with lightning speed on my old keyboard that I still struggle to type as fast: &lt;code&gt;C-M--&lt;/code&gt; (negative argument) followed by another key, such as &lt;code&gt;C-M-k&lt;/code&gt;, is one such example.&lt;/p&gt;
    &lt;p&gt;I wish I had more keys, yet ironically I have empty keys I do not use at all on the keyboard. That sounds like a contradictory statement, but it’s hard to fill out all the keys when you’re confined to the keyboard layout that you have, which necessitates the use of layers, which in some ways (and that is the point) renders the need for more keys unnecessary. A vexing paradox for sure.&lt;/p&gt;
    &lt;p&gt;One thing I think ZSA has done exceptionally well is their custom software stack. They’ve built a wonderful, interactive browser-based keyboard designer that makes it a breeze to not only change and experiment with your keyboard layout, but also view others’ layouts as well. I like their hardware well enough – but it’s just a keyboard to me – but I think they’ve done an outstanding piece of work with the software. When I first got it, I had to download the compiled keyboard ROM and use their easy-to-use tool to flash the keyboard ROM.&lt;/p&gt;
    &lt;p&gt;No more: their layout builder asks for permission to talk to your keyboard directly using WebUSB in the browser and, if you accept, it’ll flash your keyboard’s firmware for you automatically. Very nice. If you use Chrome that is. If you’re using Firefox like I do, then you have to download the firmware and flash it the normal way because the lumpenproletariat who run the security division at Mozilla have decided that WebUSB is… ‘insecure.’&lt;/p&gt;
    &lt;p&gt;The layout builder, the web flashing and the ease of use of it all speaks volumes. Someone’s actively working on improving the user experience which is honestly poor, if you just use the QMK firmware directly. Yes, there are interactive keyboard builders for QMK directly, but if you run into trouble, or if you want to do something esoteric, you’re going to have to start reading the C source code and fiddle with it.&lt;/p&gt;
    &lt;p&gt;So. Is it a good keyboard? Yes. It would be a great keyboard if they’d tweak the issues I have around fit and finish of the hand rests, and make it easier to balance the keyboard. The main reason you should look into a mechanical (QMK-based!) keyboard is that it objectively improves your primary interface with your computer. The QMK firmware’s value-adds – and I have only scratched the surface – is 80% of it. If you have a crappy OEM keyboard or if you’re plinking away on a laptop — get a mechanical keyboard! Your wrists and fingers will thank you in the long run.&lt;/p&gt;
    &lt;p&gt;The Moonlander keyboard is a safe buy and, aside from the issues I mentioned, it is worth the $365. That’s a dollar a day for a year — small potatoes. And if you’re strapped for cash, try searching AliExpress for mechanical keyboards. The Chinese have taken to it with gusto, and you can buy or build your own for not much money and experiment.&lt;/p&gt;
    &lt;p&gt;I program in Emacs for a living, so being able to move my modifier keys to the thumbs is a big improvement, for no other reason that they’re there and underused on most regular keyboards. Being able to multi-task keys to do more than one thing is also a massive win, and another reason to consider a programmable keyboard.&lt;/p&gt;
    &lt;p&gt;Get a mechanical keyboard. Make sure it has QMK firmware. Maybe a Moonlander if you can spare the cash. Go.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.masteringemacs.org/article/thoughts-on-mechanical-keyboards-zsa-moonlander"/><published>2025-09-26T22:17:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45391871</id><title>New math revives geometry's oldest problems</title><updated>2025-09-27T13:34:03.709596+00:00</updated><content>&lt;doc fingerprint="8f5c03150ab107f8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;New Math Revives Geometry’s Oldest Problems&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In the third century BCE, Apollonius of Perga asked how many circles one could draw that would touch three given circles at exactly one point each. It would take 1,800 years to prove the answer: eight.&lt;/p&gt;
    &lt;p&gt;Such questions, which ask for the number of solutions that satisfy a set of geometric conditions, were a favorite of the ancient Greeks. And they’ve continued to entrance mathematicians for millennia. How many lines lie on a cubic surface? How many quadratic curves lie on a quintic surface? (Twenty-seven and 609,250, respectively.) “These are really hard questions that are only easy to understand,” said Sheldon Katz, a mathematician at the University of Illinois, Urbana-Champaign.&lt;/p&gt;
    &lt;p&gt;As mathematics advanced, the objects that mathematicians wanted to count got more complicated. It became a field of study in its own right, known as enumerative geometry.&lt;/p&gt;
    &lt;p&gt;There seemed to be no end to the enumerative geometry problems that mathematicians could come up with. But by the middle of the 20th century, mathematicians had started to lose interest. Geometers moved beyond concrete problems about counting, and focused instead on more general abstractions and deeper truths. With the exception of a brief resurgence in the 1990s, enumerative geometry seemed to have been set aside for good.&lt;/p&gt;
    &lt;p&gt;That may now be starting to change. A small cadre of mathematicians has figured out how to apply a decades-old theory to enumerative questions. The researchers are providing solutions not just to the original problems, but to versions of those problems in infinitely many exotic number systems. “If you do something once, it’s impressive,” said Ravi Vakil, a mathematician at Stanford University. “If you do it again and again, it’s a theory.”&lt;/p&gt;
    &lt;p&gt;That theory has helped to revive the field of enumerative geometry and to connect it to several other areas of study, including algebra, topology and number theory — imbuing it with fresh depth and allure. The work has also given mathematicians new insights into all sorts of important number systems, far beyond the ones they’re most familiar with.&lt;/p&gt;
    &lt;p&gt;At the same time, these results are raising just as many questions as they answer. The theory spits out the numbers that mathematicians are seeking, but it also gives additional information that they’re struggling to interpret.&lt;/p&gt;
    &lt;p&gt;That mystery has inspired a new generation of talent to get involved. Together, they’re bringing counting into the 21st century.&lt;/p&gt;
    &lt;head rend="h2"&gt;Counting Forward&lt;/head&gt;
    &lt;p&gt;All enumerative geometry problems essentially come down to counting objects in space. But even the simplest examples can quickly get complicated.&lt;/p&gt;
    &lt;p&gt;Consider two circles some distance apart on a piece of paper. How many lines can you draw that touch each circle exactly once? The answer is four:&lt;/p&gt;
    &lt;p&gt;You can slide these circles further apart, or shrink one to half its size, and the answer won’t change. But move one circle so that it intersects the other like a Venn diagram, and suddenly the answer does change — from four to two. Slide whichever circle is smaller entirely inside the bigger one, and now the answer is zero: You can’t draw any lines that touch each circle only once.&lt;/p&gt;
    &lt;p&gt;Such inconsistencies are a real pain. In this example, there were only three different configurations to consider, but often the problem is too complicated for researchers to work through every possible case. You might find the answer for one case, but you’ll have no idea how it will change when you move things around.&lt;/p&gt;
    &lt;p&gt;In practice, mathematicians try to write the problem’s geometric constraints as a collection of equations, then figure out how many solutions satisfy all those equations simultaneously. But even though they know that the number of solutions won’t always stay consistent, there’s nothing in the nature of the equations they write down that indicates whether they’ve stumbled on a new configuration that will yield a different answer.&lt;/p&gt;
    &lt;p&gt;There’s one exception — when the problem is defined in terms of complex numbers. A complex number has two parts: a “real” part, which is an ordinary number, and an “imaginary” part, which is an ordinary number multiplied by the square root of −1 (what mathematicians call i).&lt;/p&gt;
    &lt;p&gt;In the example above with the circles and lines, if you ask for the number of complex solutions to your equations, you always get four as your answer, no matter what arrangement you look at.&lt;/p&gt;
    &lt;p&gt;By around 1900, mathematicians had developed techniques to solve any enumerative geometry problem in the complex realm. These techniques didn’t have to take different configurations into account: No matter what answer mathematicians got, they knew it had to be true for every configuration.&lt;/p&gt;
    &lt;p&gt;But the methods were no longer effective when mathematicians only wanted to find, say, the number of real solutions to the equations in an enumerative geometry problem, or the number of integer solutions. If they asked an enumerative geometry problem in any number system other than the complex one, inconsistencies cropped up again. In these other number systems, mathematicians couldn’t address enumerative questions systematically.&lt;/p&gt;
    &lt;p&gt;At the same time, the mysterious, shifting answers that mathematicians encountered when they limited themselves to the integers, or to the real numbers, made enumerative questions a great way to probe those other number systems — to better understand the differences between them, and the objects that live inside them. Mathematicians thought that developing methods to deal with these settings would open up new, deeper areas of mathematics.&lt;/p&gt;
    &lt;p&gt;Among them was the mathematical great David Hilbert. When he penned a list of what he considered the most important open problems of the 20th century, he included one about making the techniques for solving enumerative geometry questions more rigorous.&lt;/p&gt;
    &lt;p&gt;In the 1960s and ’70s, Alexander Grothendieck and his successors developed novel conceptual tools that helped resolve Hilbert’s problem and set the foundation for the field of modern algebraic geometry. As mathematicians pursued an understanding of those concepts, which are so abstract that they remain impenetrable to nonspecialists, they ended up leaving enumerative geometry behind. Meanwhile, when it came to enumerative geometry problems in other number systems, “our techniques hit a brick wall,” Katz said. Enumerative geometry never became the beacon that Hilbert had imagined; other threads of research illuminated mathematicians’ way instead.&lt;/p&gt;
    &lt;p&gt;Enumerative geometry no longer felt like a central, lively area of study. Katz recalled that as a young professor in the 1980s, he was warned away from the subject “because it was not going to be good for my career.”&lt;/p&gt;
    &lt;p&gt;But a few years later, the development of string theory temporarily gave enumerative geometry a second wind. Many problems in string theory could be framed in terms of counting: String theorists wanted to find the number of distinct curves of a certain type, which represented the motion of strings — one-dimensional objects in 10-dimensional space that they believe form the building blocks of the universe. Enumerative geometry “became very much in fashion again,” Katz said.&lt;/p&gt;
    &lt;p&gt;But it was short-lived. Once physicists answered their questions, they moved on. Mathematicians still lacked a general framework for enumerative geometry problems in other number systems and had little interest in pursuing one. Other fields seemed more approachable.&lt;/p&gt;
    &lt;p&gt;That was the case until the mathematicians Kirsten Wickelgren and Jesse Kass came to a sudden realization: that enumerative geometry might provide the exact kind of deep insights that Hilbert had hoped for.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Bird’s-Eye View&lt;/head&gt;
    &lt;p&gt;Kass and Wickelgren met in the late 2000s and soon became regular collaborators. In many ways their demeanors couldn’t be more different. Wickelgren is warm, but restrained and deliberate. Whenever I asked her to confirm that I’d understood a given statement correctly, she’d pause for a moment, then answer with a firm “Yes, please” — her way of saying “Exactly, you’ve got it!” Kass, on the other hand, is nervously enthusiastic. He’s easily excited and talks at a rapid-fire pace.&lt;/p&gt;
    &lt;p&gt;But Kass and Wickelgren worked well together and shared many interests — including a love for extending geometry’s reach into other fields.&lt;/p&gt;
    &lt;p&gt;In 2015, Kass was passing through Atlanta, where Wickelgren lived, and decided to approach her with his latest obsession: He wanted to revisit enumerative questions in restricted number systems, that long-abandoned endeavor.&lt;/p&gt;
    &lt;p&gt;He brought along a bunch of loose ideas and old papers that seemed relevant. “I realized this was a kind of pie-in-the-sky project,” Kass said. “She very politely explained to me that all my answers were nonsense.” Then he mentioned a result from 1977, and suddenly “a light bulb went off.”&lt;/p&gt;
    &lt;p&gt;In that 1977 paper, the mathematicians Harold Levine and David Eisenbud were working out a proof that involved counting. They ended up with a special type of expression called a quadratic form — a simple polynomial where each term’s exponents always add up to 2, such as x2 + y2, or z2 − x2 + 3yz.&lt;/p&gt;
    &lt;p&gt;Eisenbud and Levine realized that the count they were interested in was hidden in plain sight. The answer lay in the form’s “signature”: the number of positive terms minus the number of negative terms. (For example, the quadratic form z2 − x2 + 3yz has two positive terms, z2 and 3yz, and one negative term, x2, so its signature is 2 − 1, or 1.)&lt;/p&gt;
    &lt;p&gt;This was Wickelgren’s light bulb. In the decades since Eisenbud and Levine had published their proof, mathematicians had devised a seemingly unrelated framework called motivic homotopy theory. That framework, which treated solutions to equations as special mathematical spaces and studied the relationships between them, was both sophisticated and powerful. Among other things, it gave mathematicians a way to describe those relationships using particular kinds of quadratic forms.&lt;/p&gt;
    &lt;p&gt;Listening to Kass, Wickelgren immediately recognized that Eisenbud and Levine had come up with one of these forms. The mathematicians had been doing motivic homotopy theory without realizing it — and it had given them the answer they’d been seeking.&lt;/p&gt;
    &lt;p&gt;And while Eisenbud and Levine weren’t working on an enumerative geometry problem, it was similar enough in flavor — it involved counting, after all — that it got Kass and Wickelgren thinking. Perhaps they could solve their own counting problems using the framework of motivic homotopy theory, too. And since motivic homotopy theory could be broadly applied to any number system, perhaps it would unlock the enumerative geometry questions in those settings that had eluded mathematicians for so long.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Deeper View&lt;/head&gt;
    &lt;p&gt;Remember that typically, an enumerative geometry problem involves finding the number of solutions that satisfy a collection of equations. Kass and Wickelgren’s insight was not to try to solve those equations directly — it rarely worked in settings other than the complex numbers. Instead, the pair rewrote a given enumerative geometry question (set in a given number system) in terms of spaces of equations and functions that described the relationship between those spaces.&lt;/p&gt;
    &lt;p&gt;With the problem reformulated in this way, they could apply motivic homotopy theory to it. This allowed them to compute a quadratic form. Now they had to figure out what information that quadratic form contained about their original problem.&lt;/p&gt;
    &lt;p&gt;When they were working in the complex numbers, they realized, all they had to do was count up the number of different variables in the quadratic form they’d computed. That number gave them the number of solutions to their enumerative geometry problem. Of course, this wasn’t particularly interesting to them: Mathematicians already had good techniques for getting this answer.&lt;/p&gt;
    &lt;p&gt;So they moved on to other number systems. For the real numbers, it got a little trickier. Once they computed the quadratic form in this setting, they had to look at its signature instead. And the signature didn’t give the precise answer: It gave a minimum for what the answer could be. That is, for any enumerative geometry problem involving real numbers, they had a way to calculate a lower bound — a good starting place.&lt;/p&gt;
    &lt;p&gt;But most exciting of all was that when they computed a quadratic form for other, stranger number systems, they could also glean important information. Take a looping system of seven numbers that operates on what’s called clock arithmetic: In such a system, 7 + 1 equals 1 instead of 8. In this system, they rewrote their quadratic form as an array of numbers called a matrix. They then calculated a quantity called the determinant and proved that while it didn’t tell them the total number of solutions, it did tell them something about what proportions of those solutions had certain geometric properties.&lt;/p&gt;
    &lt;p&gt;In 2017, Kass and Wickelgren showcased this for one of enumerative geometry’s most famous theorems: that a cubic surface can contain at most 27 lines. Using their new methods, they showed that indeed, the answer is 27 in the complex numbers. They replicated a known lower bound for the real numbers — and provided new numerical information for every finite number system. It all came in one package.&lt;/p&gt;
    &lt;p&gt;It was one of the first times mathematicians had been able to say anything significant about enumerative geometry problems for systems outside the complex and real numbers. Moreover, while the problem’s answer might change depending on the number system and the configuration of shapes within it, for the first time mathematicians had found one theory that could encompass all those potential different answers.&lt;/p&gt;
    &lt;p&gt;“It’s not just about the real numbers or the complex numbers,” Wickelgren said. “They’re just special cases of a result that holds in any number system.”&lt;/p&gt;
    &lt;p&gt;And that was only the beginning.&lt;/p&gt;
    &lt;head rend="h2"&gt;A New Start&lt;/head&gt;
    &lt;p&gt;In the years since, Wickelgren, Kass and others have reframed a host of other enumerative problems using motivic homotopy theory, deriving the relevant quadratic forms in various number systems.&lt;/p&gt;
    &lt;p&gt;“All the geometric constructions used to give people integer answers,” said Marc Levine, a mathematician at the University of Duisburg-Essen who has been independently exploring the same ideas. “Now you can feed [the problem] in and get something which will give you a quadratic form as an answer.”&lt;/p&gt;
    &lt;p&gt;Mathematicians have made a lot of progress since Kass and Wickelgren’s original work when it comes to understanding what information a quadratic form can give them in different number systems. Sometimes, though, they’re not sure what to look for in the quadratic form. “We’re still kind of mystified about what exactly it tells you,” Levine said. There’s a lot left to interpret.&lt;/p&gt;
    &lt;p&gt;“At this point,” said Aravind Asok of the University of Southern California, trying to glean information about enumerative geometry problems from quadratic forms “is an entire industry.” It’s also concrete and accessible, which has attracted the attention of young mathematicians, he added. “It’s exciting because students can get into something with meat sort of quickly.”&lt;/p&gt;
    &lt;p&gt;Such concreteness is unusual in today’s abstract mathematical landscape. “The math keeps going one level higher in abstraction, and then sometimes I feel like I don’t know what I’m talking about anymore,” said Sabrina Pauli, who was Wickelgren’s first graduate student and is now a professor at the Technical University of Darmstadt in Germany. But this new area of research gives her a way to bring that high level of abstraction back down to earth.&lt;/p&gt;
    &lt;p&gt;Wickelgren, Kass, Levine and others have recently used their techniques to revisit enumerative questions related to string theory — but in new number systems and settings.&lt;/p&gt;
    &lt;p&gt;In all these cases, mathematicians have found a new way to explore how points, lines, circles and far more complicated objects act differently in different numerical contexts. Kass and Wickelgren’s revived version of enumerative geometry provides an unlikely window into the very structure of numbers. “It would be hard for me not to be drawn to the question that asks how many rational curves are there on a sheet of paper,” Wickelgren said. “That’s a fundamental part of the mathematical reality of a sheet of paper.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/new-math-revives-geometrys-oldest-problems-20250926/"/><published>2025-09-26T22:57:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45392164</id><title>The Obsessively Complete Infocom Catalog</title><updated>2025-09-27T13:34:03.083977+00:00</updated><content>&lt;doc fingerprint="27623a4966b10e92"&gt;
  &lt;main&gt;&lt;p&gt;This site is my attempt to collect every single version of each Infocom game, both source code and compiled game files. I have labelled each package with release and serial number information where possible. (Infocom serial numbers were a timestamp of the compilation date, which is very useful for reconstructing the development sequence.)&lt;/p&gt;&lt;p&gt;IF fans of the modern era have used this source code to recompile the Infocom games. Some have taken the opportunity to fix bugs or modify the games. This collection does not include these modern recompilations and updates. (I have no quarrel with them, but I'm not going to keep track.)&lt;/p&gt;&lt;p&gt;This collection does include a few fan-modified game files that date from the 1980s. (The modifications only extend to the serial and release numbers.) I include these because they were contemporary with Infocom and thus have some historical interest. Also, they were collected in the early 90s and wound up in the game file lists of the nascent Internet IF community.&lt;/p&gt;&lt;p&gt;Jason Scott began this process in April of 2019, when he posted a large collection of Infocom source code on GitHub. Source code and compiled files, in fact.&lt;/p&gt;&lt;p&gt;This was tremendously exciting to fans and scholars of old-school text adventures. This material was known to be out there in private collections, but it had never been publicly available in this form.&lt;/p&gt;&lt;p&gt;Jason's collections are excellent, but they are an edited extract from one source: the so-called "Infocom Drive". They omit some published variations, beta-tests, and so on. I figure it's good to have every Infocom game file variation in one place.&lt;/p&gt;&lt;p&gt;Nonetheless, let me be clear: this site would not exist without Jason Scott's efforts. Thank you, Jason! Also thanks to Beaux Hemmer for maintaining the patch collection. Thanks to TorbjÃ¶rn Andersson and Alessandro Giassi for enthusiastic help tracking down more versions and info on them. And, of course, thanks to the Implementors who created these games in the first place.&lt;/p&gt;&lt;p&gt;Update, December 2019: Another cleaned-up source collection has been posted by Adam Sommerfield.&lt;/p&gt;&lt;p&gt;You can download a catalog of the whole file collection (JSON format): catalog.json.&lt;/p&gt;&lt;p&gt;(Note that the "updated" field is when I added or last updated the file on this site.)&lt;/p&gt;&lt;p&gt;If you want to download everything in one go, grab allgamefiles.zip, allsources.zip, allinterpreters.zip, and allother.zip.&lt;/p&gt;&lt;p&gt;These are proprietary documents. The copyright rests with Activision. Mind you, Activision certainly doesn't have the development tools or the expertise to compile this source code any more. Quite likely they don't even have the source code any more. If it weren't for private collectors passing it around, this material would be entirely lost.&lt;/p&gt;&lt;p&gt;Like Jason, I believe that the historical value of these documents to the IF community outweighs the rights of the legal owner. As I wrote in April, copyright is a balance. Activision has not commented on the matter.&lt;/p&gt;&lt;p&gt;The GitHub repositories structure the source code as a sequence of commits, showing the development process. This site packages each source directory separately.&lt;/p&gt;&lt;p&gt;This site includes game files collected from original game releases. These have historically been collected as "patch files". This was a legal figleaf; it allowed a user to transform a legally-owned game file into a different version, without actually distributing copies of each version. I have used those transforms to recreate all known game file versions.&lt;/p&gt;&lt;p&gt;Several of the GitHub repositories contain a common error: an old source file is sometimes not deleted in newer commits. For example, the Zork 2 source contains "crufty.zil" in r22 and r48, but this file has been removed in r63. The GitHub zork2 repo fails to delete it. This site avoids that error.&lt;/p&gt;&lt;p&gt;The GitHub repos omit personal email and individual developers' comments found in the source collection. This site does too; I followed Jason's example in this matter. It is not my intent to expose private communication, even thirty years after the fact.&lt;/p&gt;&lt;p&gt;However, I have included a few files that Jason omitted, primarily "browsie/feelie" manuscripts intended for the game package.&lt;/p&gt;&lt;p&gt;The game files collected here are Z-code files, which may be played with any Z-code interpreter. The source packages contain ZIL source code and associated files.&lt;/p&gt;&lt;p&gt;Z-code files come in various versions. Infocom referred to these as "zip" (version 3), "ezip (version 4), "xzip" (version 5), and "yzip" (version 6). They used the ".zip" file suffix for all of these; the version is distinguished by the first byte of the game file. These days, ".zip" is a compression format, so we tag files as ".z3", ".z4", ".z5", ".z6".&lt;/p&gt;&lt;p&gt;This collection also includes a few ".z1" and ".z2" files recovered from very early releases of Zork 1. These have nonstandard serial numbers.&lt;/p&gt;&lt;p&gt;(In 1995, Graham Nelson proposed ".z7" and ".z8" as simple modifications to support larger game files. The Inform compiler and most modern interpreters support these versions. See the Z-code specification.)&lt;/p&gt;&lt;p&gt;Extracting the version, release, and serial number from a Z-code file is easy. I use this little Python script: zcanalyze.py.&lt;/p&gt;&lt;p&gt;Compiling ZIL source code into a game file requires more effort. Infocom's original ZIL compiler has been recovered, but only in a very early version (circa 1981; see below). However, ZILF is an open-source ZIL compiler which is under active development.&lt;/p&gt;&lt;p&gt;The Text Adventure Masterpieces of Infocom CD (1996) is the source of most modern releases and downloads. If you want to play the "official" version of a game, the Masterpieces version is usually the right choice.&lt;/p&gt;&lt;p&gt;However, there are some complications. In some cases, the Mac and PC directories on the CD had different versions. Also, Hitchhiker and Shogun were not included on Masterpieces.&lt;/p&gt;&lt;p&gt;The "official" version of Hitchhiker is the one that Douglas Adams posted on his web site in the mid-90s. The BBC later posted an illustrated version based on the same game file.&lt;/p&gt;&lt;p&gt;Lost Treasures of Infocom 1 and 2 (1992) were earlier Activision collections. These made slightly different game-file choices than Masterpieces, and they did include Hitchhiker and Shogun. To add to the confusion, LTOI1 was released for Amiga as well.&lt;/p&gt;&lt;p&gt;A few of Infocom's earlier games were re-released in "Solid Gold" editions, with built-in Invisiclues. These versions used ".z5" format in order to accomodate the additional text. The Activision collections were quite inconsistent about whether to use the "Solid Gold" versions.&lt;/p&gt;&lt;p&gt;I have noted the Masterpieces version of each game file, and (where different) the LTOI1/2 versions. For more information about game file versions, see Paul David Doherty's invaluable Infocom Fact Sheet.&lt;/p&gt;&lt;p&gt;Versions marked "final-dev" are unreleased final internal versions (according to the Fact Sheet). That is, they had changes in progress when development shut down. These may fix bugs, but they never went through QA, so they should not be considered release-quality.&lt;/p&gt;&lt;p&gt;Despite the title of this page, this is not a complete collection! We have what's been recovered. In particular, there's no guarantee that the "most current" source corresponds to a final release.&lt;/p&gt;&lt;p&gt;All of the source packages contain source (.zil) files. Some also contain temporary files in various stage of compilation (.zap, .zabstr). Some contain compilation reports, design documents, or other related files. It's just a question of what was found in the source archive.&lt;/p&gt;&lt;p&gt;Release numbers are not always sequential. Infocom tended to reset the release number sequence after beta/gamma testing was over, or at other major development milestones. The serial number dates are more reliable, except where they've been obviously zeroed out.&lt;/p&gt;&lt;p&gt;It is perhaps amusing to learn that the "Solid Gold" editions were labelled as the "cheap" releases during development.&lt;/p&gt;&lt;p&gt;Games with sound (Sherlock, Lurking Horror) and graphics (most z6 games) may or may not include the media files in the source directory. The game files never include media. Even if present in the source, these files are probably not in a form that a modern interpreter can understand. See this page for portable versions of these media files.&lt;/p&gt;&lt;p&gt;A few game files are modified for the Macintosh. According to the internal notes, the modifications are "special flags" on certain objects. This apparently refers to setting the fixed-width font for descriptions with ASCII art. Infocom's Mac interpreter required this; it was the only one of its kind that defaulted to variable-width font display. (Most modern interpreters do.)&lt;/p&gt;&lt;p&gt;Source comment on the Mac versions:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The following is a list of changeds specifically for the Mac version:&lt;/p&gt;&lt;p&gt;SEASTALKER -- Special flags set on Sonarscope, control panel in sub and control panel in Bly's office.&lt;/p&gt;&lt;p&gt;ZORK2 -- Special flags set on magic well etching (top and bottom), Label on candied insects and stone cube in bank vault.&lt;/p&gt;&lt;p&gt;ZORK3 -- Special flags set on Royal puzzle and bronze plaque in cage.&lt;/p&gt;&lt;p&gt;ENCHANTER -- Special flags set on Translucent maze map, sign on path to brook and on fireworks for Filfre scroll.&lt;/p&gt;&lt;p&gt;SUSPENDED -- Special flags set on all three monitors: 1) Weather, 2) Hydroponics 3) Transit.&lt;/p&gt;&lt;p&gt;INFIDEL -- Special flags set for Hieroglyphs: bottom of stairs, scarab, book of dead, page in book of dead, beam, scroll in forward cabin, opening in top of pyramid, stone cube, bricks, recessed panel, west end of passage, north antechamber, south antechamber, room of Nephthys, Isis, Selkis, Neith, narrow hallway, cube room, cube south part, silver room, gold room, skeleton in room.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Z-code game files are sometimes found with zeroes or garbage data padded on the end. This does not affect the game behavior. I have generally ignored these variations. I've also ignored variations in byte 1 of the game file; these represent interpreter variations from different platforms, not game differences.&lt;/p&gt;&lt;p&gt;The patches archive contains several game files whose serial numbers are blank or nonsensical. These are always minor modifications of other game files, typically with only the serial number (and checksum) altered. We assume these are "crack" versions modified by users. I have included them regardless.&lt;/p&gt;&lt;p&gt;The patches archive also includes a set of game files which have been modified to bypass Infocom's "feelie" copy protection. I have omitted these, as they definitely postdate Infocom (they were released circa 1999). The feelie data is of course well-archived in any case.&lt;/p&gt;&lt;p&gt;The "mainframe" version of Zork/Dungeon, created at MIT between 1977 and 1979. This package, unlike the others on this site, is written in MDL.&lt;/p&gt;&lt;p&gt;Zork-MDL has been available for some time. (It was posted on Bob Supnik's web site in 2003, perhaps earlier. Ports to Fortran and C are also easily findable.) I include it here because, well, it's Zork.&lt;/p&gt;&lt;p&gt;Four versions of the source, labelled according to the "US NEWS &amp;amp; DUNGEON REPORT" date (see &lt;code&gt;dung.mud&lt;/code&gt;; note that the 1979 version shows inconsistent dates). The 1981 version says "no longer being supported" and refers players to the commercial Infocom release.&lt;/p&gt;&lt;p&gt;Several runnable versions have been recovered from MIT tapes. These are available at the ITS project. I have not mirrored the executable files, because they're only executable inside ITS (running on an emulated PDP-10). See this post for a list of Zork versions found. Visit the project page for information on setting up ITS; or &lt;code&gt;telnet its.pdp10.se 10003&lt;/code&gt; to try it online.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;You can try the ITS environment online! Telnet to its.pdp10.se, port 10003 (&lt;/p&gt;&lt;code&gt;telnet its.pdp10.se 10003&lt;/code&gt;). When it says "Connected...", hit ctrl-Z. Then type&lt;code&gt;:login yourname&lt;/code&gt;. (Any name will work.) Then type&lt;code&gt;:zork&lt;/code&gt;to play.&lt;code&gt;:advent&lt;/code&gt;is also available; that's the original Crowther version. You can also try&lt;code&gt;:games;adv350&lt;/code&gt;and&lt;code&gt;:games;adv448&lt;/code&gt;.&lt;/quote&gt;&lt;p&gt;It is worth noting that the 1977-78 versions introduce themselves by saying "Welcome to Dungeon"; the 1979-81 versions say "Welcome to Zork". Of course the "Dungeon" versions still mention "Zork" in many places within the game.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;An early version of Infocom's ZIL compiler, written in MDL. The files are dated no later than early 1981; most are 1979-1980. This version includes both the compiler (ZILCH) and assembler (ZAP) stages.&lt;/p&gt;&lt;p&gt;This source was originally archived at https://github.com/PDP-10/its-vault (the &lt;code&gt;twenex/zork&lt;/code&gt; directory) by Lars Brinkhoff. See also the standalone repository at https://github.com/PDP-10/zil.&lt;/p&gt;&lt;p&gt;For a guide to using this source, see Roman Bartke's ZILCH How-to.&lt;/p&gt;&lt;p&gt;The documentation has been gathered from the Internet Archive, the collection at frobnitz.co.uk, and other sources. Note that &lt;code&gt;.rno&lt;/code&gt; is Runoff and &lt;code&gt;.fwf&lt;/code&gt; is Scribe, two venerable markup languages for document formatting. See Henrik Ãsman's repo for PDF versions.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Documentation:&lt;/p&gt;&lt;p&gt;We have two standalone versions of the ZAP assembler, one early and one late.&lt;/p&gt;&lt;p&gt;The first is written in the MIDAS assembly language for the PDP-10. This version is dated Jan 7 1982. It was found within the minizork-r2 source directory (see below).&lt;/p&gt;&lt;p&gt;The second is written in C and dated March 1988. The comments say "Zinn Computer Company, for Infocom", implying that the work was outsourced. The directory includes &lt;code&gt;.o&lt;/code&gt; and executable binaries, presumably in Sun architecture (the directory was labelled "sun"). From this historical repo. (A handful of other utilities are included, including &lt;code&gt;zsplit&lt;/code&gt;, &lt;code&gt;zglue&lt;/code&gt;, &lt;code&gt;zspix&lt;/code&gt;, and &lt;code&gt;zsymtest&lt;/code&gt;. These appear to have to do with packaging game files onto disk for specific platforms.)&lt;/p&gt;&lt;p&gt;A third, earlier version can be found as part of the ZIL source repository above. This is MDL code dated "Jan 18 1980". I'm not sure if it can be run independently of the rest of the ZIL toolset.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Documentation:&lt;/p&gt;&lt;p&gt;Most of Infocom's original ZIL interpreters were written in assembly for the various platforms of the 1980s. A few later versions were written in C, or (for the Mac) Pascal.&lt;/p&gt;&lt;p&gt;The TRS-80 (Tandy) CoCo interpreter was released in 2018, thanks to Brian Moriarty, Carlos Camacho, and John Linville. (First archived here.) The others became available to the public in 2023. (Archived here.)&lt;/p&gt;&lt;p&gt;These packages are presented by directory, as they were preserved. The contents are not consistently organized. Some of these packages contain more than one interpreter version; some contain additional documentation or serial-port transfer scripts. See this README for a detailed catalog of the contents.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Collector's note:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The Zork I Release 2 game file was extracted from a self-booting, copy-protected TRS-80 Model I disk. The disk itself was not an original and did not come with a label or packaging, but it seems to have been the early Personal Software release.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;We have two game files labelled r22, Mac and non-Mac. Neither of them seems to correspond to the most current source. (E.g.: the source mentions InvisiClues if you type &lt;code&gt;HELP&lt;/code&gt;, but none of the game files contain that line.) I've labelled the current source "infidel-rlater" for lack of better information.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;code&gt;$verify&lt;/code&gt; command therefore fails.
&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;We have two version of the r18 game file. They are identical except for an internal serial number (189 or 190), which is displayed if you type &lt;code&gt;$VERIFY 1949&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Many game file variations tagged with platform names ("tandy", "coco", etc). This is no doubt due to the difficulties of making the sonar display (status window) work across different screen sizes.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Note that many source files were deleted between r79 and the "rlater" version, so the GitHub repo error is particularly noticeable.&lt;/p&gt;&lt;p&gt;It appears that Infocom was still finalizing the V4 spec during AMFV's development. The development (alpha/gamma) versions have inconsistent header length fields, and must be updated to play in modern interpreters.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;The "Solid Gold" update has a serious bug with the delivery time limit.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;code&gt;hints.zil&lt;/code&gt;) but otherwise is nearly the same as the r69 source.
&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;The patch archive contains two further hacks are which are identical to r59 s000001 except for release and serial; I have omitted these.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Unusually, we have full source code for the beta (r63) and gamma (r87) versions.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;A conundrum, Watson. Four source directories appear. The base and -sound directories differ in only a few lines of zil. The -nosound directory has nosound.zil in place of gamesound.zil. The -ss directory is substantially different from the others; the header timestamps imply that it is an early development version. For what it's worth, the included version note says:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;The SOUND version is the Release version. The NOSOUND version is currently NOT the release version but contains the Bob Bates updates that are in the SOUND version (without the sound code, of course).&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Many alpha and beta game files. Also two demo versions, which could be considered "Mini-Zork Zero".&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;.z6&lt;/code&gt; game files do not include image assets. To play, you must combine the game file with the image data archived here. See IFWiki for more info.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Note the early z5 version whose release number (46) is out of sequence. We have two source directories which appear to match this version. Originally this was one source directory containing ".zil" and ".beta" files; the ".beta" files are earlier, so I have moved them to a separate beta directory.&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;.z6&lt;/code&gt; game files do not include image assets. To play, you must combine the game file with the image data archived here. See IFWiki for more info.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;.z6&lt;/code&gt; game files do not include image assets. To play, you must combine the game file with the image data archived here. See IFWiki for more info.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;.z6&lt;/code&gt; game files do not include image assets. To play, you must combine the game file with the image data archived here. See IFWiki for more info.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;TorbjÃ¶rn Andersson reports that this game file fails on modern interpreters when you exit the Carousel Room.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Links:&lt;/p&gt;&lt;p&gt;The sampler appears to have gone through several combinations of games. r26-r55 contained samples of Zork 1, Planetfall, Infidel, and The Witness. r97 contained Zork, Trinity, and LGOP; but we find a parallel r8 which contains only Zork and Trinity, plus partial work on adding Ballyhoo. Comment from the r8 source:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;This directory is for NSAMPLER stuff where all references to LGOP have been deleted. The XM4.* files are a stripped down Ballyhoo that could have possibly been inserted into XSAMPLER in place of LGOP, but wasn't. These files stand alone as a separate mini-game and would need to be integrated into XSAMPLER if ever used (when hell freezes over).&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;There's also a folder sampler-trinity, which appears to be a very partial tear-down (or build-up) of Trinity.&lt;/p&gt;&lt;p&gt;I have used the following labels:&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;An incomplete and unreleased game by Bob Bates, based on the James Cameron movie.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;An incomplete and unreleased game by Stu Galley. Curiously, the game file "spy.zip" originally found in this directory was not Checkpoint at all, but an early version of Journey.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Very incomplete and unreleased. Two versions found.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;An unfinished game by Tomas Bok. Bok worked for Infocom briefly before college (see this forum thread). Hypochondriac was a "fun project" he was working on in his own time.&lt;/p&gt;&lt;p&gt;The source package is Bok's work directory, and contains several fragments of source code unrelated to Hypochondriac. Some of them (&lt;code&gt;boot.zil&lt;/code&gt;, &lt;code&gt;circuit.zil&lt;/code&gt;, &lt;code&gt;maintenance.zil&lt;/code&gt;) are from an incomplete sci-fi game titled "Search 'n Rescue". Others are source files from Infocom games (Zork, LGOP, etc), modified while Bok was experimenting with ZIL.&lt;/p&gt;&lt;p&gt;The game files include both Hypochondriac and various experiments. The experiments aren't necessarily related to Hypochondriac; I've given them a common name simply to group them together.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;This is the "new parser" that Infocom developed around 1987, late in its history. Their earlier games were based on the ZIL parser developed for Zork 1, and then copied from game to game in an evolutionary sequence.&lt;/p&gt;&lt;p&gt;ZilLib was an attempt at a next-generation parser to go along with the next-generation (z6) Z-machine. See this article from Infocom's 1989 newsletter.&lt;/p&gt;&lt;p&gt;The source code for Zork Zero, Arthur, Shogun, Abyss, and Restaurant all refer to the zillib directory. (And the zillib/parser directory contains include files that refer back to them; e.g. "parser.shogun".)&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;A regression test suite for Infocom's Z-code interpreters. No source code found.&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;This appears to be a template for creating a new game. It includes a parser, a couple of rooms, and a couple of stub objects. Three game files were found with various dates and Z-code versions.&lt;/p&gt;&lt;p&gt;Sources:&lt;/p&gt;&lt;p&gt;Game files:&lt;/p&gt;&lt;p&gt;Cataloged by Andrew Plotkin from sources at GitHub and elsewhere.&lt;/p&gt;&lt;p&gt;Last updated January 14, 2025.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eblong.com/infocom/"/><published>2025-09-26T23:43:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45392744</id><title>GPT-OSS Reinforcement Learning</title><updated>2025-09-27T13:34:02.461280+00:00</updated><content>&lt;doc fingerprint="bd03a57f89323790"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;gpt-oss Reinforcement Learning&lt;/head&gt;
    &lt;p&gt;You can now train OpenAI gpt-oss with RL and GRPO via Unsloth. Unsloth now offers the fastest inference (3x faster), lowest VRAM (50% less) and most context (8x longer) for gpt-oss RL vs. any implementation - with no accuracy loss. Since RL on gpt-oss isn't yet vLLM compatible, we rewrote Transformers inference code to deliver 3x faster inference for gpt-oss at ~21 tokens/s. For BF16, Unsloth also achieves the fastest inference (~30 tokens/s), especially relative to VRAM usage, using 50% less VRAM vs. any implementation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Free notebook: gpt-oss-20b GSPO Colab notebook This notebook automatically creates faster matrix multiplication kernels and uses a new Unsloth reward function. We also show how to counteract reward-hacking which is one of RL's biggest challenges.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With Unsloth, you can train gpt-oss-20b with GRPO on 15GB VRAM and free on Colab. Unsloth's new inference runs faster on any GPU including A100, H100 and old T4's. gpt-oss-120b fits on 80GB VRAM.&lt;/p&gt;
    &lt;p&gt;Unsloth is the only framework to support 4-bit RL for gpt-oss. All performance gains are due to Unsloth's unique weight sharing, Flex Attention, Standby and custom kernels.&lt;/p&gt;
    &lt;p&gt;Reminder: Flash Attention 3 (FA3) is unsuitable for gpt-oss training since it currently doesn’t support backward passes for attention sinks, causing incorrect training loss. If you’re not using Unsloth, FA3 may be enabled by default, so please double-check it’s not in use!&lt;/p&gt;
    &lt;head rend="h2"&gt;⚡Making Inference Much Faster&lt;/head&gt;
    &lt;p&gt;Inference is crucial in RL training. To achieve the fastest inference speed for gpt-oss without vLLM, we rewrote Transformers inference and integrated many innovations including custom algorithms like Unsloth Flex Attention, torch.compile. The new inference was evaluated against an already optimized baseline (2x faster than native Transformers).&lt;/p&gt;
    &lt;p&gt;vLLM does not support RL for gpt-oss since it lacks bf16 training and LoRA support for gpt-oss. Without Unsloth, only training via bf16 works, making memory use even 800%+ higher. Most frameworks enable FA3 by default (which reduces VRAM use &amp;amp; increases speed) but this causes incorrect training loss. You must disable FA3, though that prevents long-context training, so instead, we implemented Unsloth Flex Attention.&lt;/p&gt;
    &lt;p&gt;We evaluated gpt-oss RL inference by benchmarking BitsandBytes 4-bit and also did separate tests for BF16. Unsloth’s 4-bit inference is ~4x faster, and BF16 is also more efficient, especially in VRAM use.&lt;/p&gt;
    &lt;p&gt;The best part about Unsloth's gpt-oss RL is that it can work on any GPU, even those that do not support bf16. Our free gpt-oss-20b Colab notebooks use older 15GB T4 GPUs, so the inference examples work well!&lt;/p&gt;
    &lt;head rend="h2"&gt;🛠️ gpt-oss Flex Attention Issues and Quirks&lt;/head&gt;
    &lt;p&gt;Masking was a tricky issue to deal with. We found that we had to, not only account for KV Cache prefill during generations of tokens (this is necessary for efficient inference as we need to know what KVCache corresponds to what token in what layer), but also account for a unique amount of pad tokens in each prompt for batch generations which would change the way we would need to store the block mask. Example of such can be seen below:&lt;/p&gt;
    &lt;p&gt;Normal Causal Mask:&lt;/p&gt;
    &lt;code&gt;   k0 k1 k2 k3 k4   &amp;lt;-- keys
q0 X
q1 X X
q2 X X X
q3 X X X X
q4 X X X X X &amp;lt;-- last query row (most important for decoding)&lt;/code&gt;
    &lt;p&gt;For inference in general case (decoding)&lt;/p&gt;
    &lt;code&gt;    k0 k1 k2 k3 k4
q0
q1
q2
q3
q4   X  X  X  X  X&lt;/code&gt;
    &lt;p&gt;If we naively use the same masking strategy&lt;/p&gt;
    &lt;code&gt;    k0 k1 k2 k3 k4
q0
q1
q2
q3
q4  X   (note that q4 is with q_idx 0 as this is the first query in current setup)&lt;/code&gt;
    &lt;p&gt;For generation (decoding phase), we usually only care about the last row of the attention matrix, since there’s just one query token attending to all previous key tokens. If we naïvely apply the causal mask (q_idx ≥ k_idx), it fails as our single query has index 0, while there are n_k key tokens. To fix this, we need an offset in mask creation to decide which tokens to attend. But a naïve approach is slow, since offsets change each step, forcing mask and kernel regeneration. We solved this with cache and compile optimizations.&lt;/p&gt;
    &lt;p&gt;The harder part is batch generation. Sequences differ in length, so padding complicates mask creation. Flex Attention had a lot of challenges and dynamic masks are tricky. Worse, if not compiled, it falls back to eager attention which is slow and memory-heavy (quadratic vs. linear in sequence length). Ultimately, the mask must dynamically handle prefill vs decode with KVCache, batch and padding tokens per sequence, remain torch.compile friendly, and support sliding windows.&lt;/p&gt;
    &lt;head rend="h3"&gt;🔍 FlashAttention Investigation&lt;/head&gt;
    &lt;p&gt;Another interesting direction we explored was integrating FlashAttention. Its advantages are widely recognized, but one limitation is that it does not support attention sinks during the backward pass for gpt-oss. To work around this, we restructured the attention mechanism so that it operates solely on the attention output and the log-sum-exp values that FlashAttention readily provides. Given these benefits, it seemed like an obvious choice to try.&lt;/p&gt;
    &lt;p&gt;However, we soon began noticing issues. While the first few layers behaved as expected, the later layers, particularly layers 18 through 24, produced outputs that diverged significantly from the eager-mode implementation in transformers. Importantly, this discrepancy cannot be attributed to error accumulation, since the inputs to each method are identical at every layer. For further validation, we also compared the results against Unsloth FlexAttention.&lt;/p&gt;
    &lt;p&gt;This needs further investigation into why only the last few layers show such a drastic difference between flash attention implementation vs. the others.&lt;/p&gt;
    &lt;head rend="h4"&gt;Flash Attention 3&lt;/head&gt;
    &lt;p&gt;FA3 is often enabled by default for most training packages (not Unsloth), but this is incorrect for gpt-oss. Using FA3 will make training loss completely wrong as FA3 doesn’t support gpt-oss backward passes for attention sinks. Many people are still unaware of this so please be cautious!&lt;/p&gt;
    &lt;head rend="h2"&gt;⚠️ Can We Counter Reward Hacking?&lt;/head&gt;
    &lt;p&gt;The ultimate goal of RL is to maximize some reward (say speed, revenue, some metric). But RL can cheat. When the RL algorithm learns a trick or exploits something to increase the reward, without actually doing the task at end, this is called "Reward Hacking". It's the reason models learn to modify unit tests to pass coding challenges, and these are critical blockers for real world deployment. Some other good examples are from Wikipedia.&lt;/p&gt;
    &lt;p&gt;In our notebook we explore how to counter reward hacking in a code generation setting and showcase tangible solutions to common error modes. We saw the model edit the timing function, outsource to other libraries, cache the results, and outright cheat. After countering, the result is our model generates genuinely optimized matrix multiplication kernels, not clever cheats.&lt;/p&gt;
    &lt;head rend="h2"&gt;💫 From OpenAI's Labs to Your Laptop&lt;/head&gt;
    &lt;p&gt;gpt-oss is a legitimate frontier-class architecture from OpenAI that could power breakthrough AI applications. Until now, training these models with RL was exclusively limited to well-funded labs with H100s to spare.&lt;/p&gt;
    &lt;p&gt;Today, that changes. You can train gpt-oss-20b with GRPO on a free Google Colab tier here. Free, Frontier Model, Training.&lt;/p&gt;
    &lt;p&gt;Last updated&lt;/p&gt;
    &lt;p&gt;Was this helpful?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning"/><published>2025-09-27T02:01:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45393501</id><title>Lifetime of social ties adds up to healthy aging at molecular level</title><updated>2025-09-27T13:34:02.325494+00:00</updated><content>&lt;doc fingerprint="7d92707705bd92c5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;A lifetime of social ties adds up to healthy aging&lt;/head&gt;&lt;head rend="h2"&gt;By Laura Reiley, Cornell Chronicle&lt;/head&gt;&lt;p&gt;The cumulative effect of social advantages across a lifetime – from parental warmth in childhood to friendship, community engagement and religious support in adulthood – may slow the biological processes of aging itself. These social advantages appear to set back “epigenetic clocks” such that a person’s biological age, as measured by analyzing DNA methylation patterns, is younger than their chronological age.&lt;/p&gt;&lt;p&gt;The research, which appeared in the October issue of the journal Brain, Behavior and Immunity - Health, drew on data from more than 2,100 adults in the long-running Midlife in the United States (MIDUS) study.&lt;/p&gt;&lt;p&gt;First author Anthony Ong, psychology professor and director of the Human Health Labs in the College of Human Ecology, and fellow researchers found that people with higher levels of what they called “cumulative social advantage” showed slower epigenetic aging and lower levels of chronic inflammation.&lt;/p&gt;&lt;p&gt;"This paper builds on a foundational study we published last year showing how cumulative social advantage relates to positive health outcomes," Ong said. "This new study digs deeper into the same data to understand the biological mechanisms - essentially, how social connections get under our skin to affect aging at the molecular level."&lt;/p&gt;&lt;p&gt;The study focused on so-called epigenetic clocks, molecular signatures that estimate the pace of biological aging. Two in particular – GrimAge and DunedinPACE – are considered especially predictive of morbidity and mortality. Adults with stronger, more sustained social networks showed significantly younger profiles on both clocks.&lt;/p&gt;&lt;p&gt;"Cumulative social advantage is really about the depth and breadth of your social connections over a lifetime,” Ong said. “We looked at four key areas: the warmth and support you received from your parents growing up, how connected you feel to your community and neighborhood, your involvement in religious or faith-based communities, and the ongoing emotional support from friends and family."&lt;/p&gt;&lt;p&gt;The researchers hypothesized that sustained social advantage becomes reflected in core regulatory systems linked to aging, including epigenetic, inflammatory and neuroendocrine pathways. And indeed, they found that higher social advantage was linked to lower levels of interleukin-6, a pro-inflammatory molecule implicated in heart disease, diabetes and neurodegeneration. But interestingly, there were no significant associations with short-term stress markers like cortisol or catecholamines.&lt;/p&gt;&lt;p&gt;Unlike many earlier studies that looked at social factors in isolation – whether a person is married, for example, or how many friends they have – this work conceptualized “cumulative social advantage” as a multidimensional construct. And by combining both early and later-life relational resources, the measure reflects the ways advantage clusters and compounds.&lt;/p&gt;&lt;p&gt;"What's striking is the cumulative effect - these social resources build on each other over time,” Ong said. “It's not just about having friends today; it's about how your social connections have grown and deepened throughout your life. That accumulation shapes your health trajectory in measurable ways."&lt;/p&gt;&lt;p&gt;This perspective draws on cumulative advantage theory, which holds that resources, whether economic or social, tend to accrue, widening disparities across the life course. This underscores a sobering reality: Access to these social resources is not evenly distributed. Race, class and educational attainment shape the likelihood of growing up with supportive parents, finding belonging in community institutions or having friends and partners who provide steady support.&lt;/p&gt;&lt;p&gt;That means those already disadvantaged in material ways may also be biologically disadvantaged by a relative lack of sustained social support, potentially accelerating the processes of aging and illness.&lt;/p&gt;&lt;p&gt;The findings dovetail with the “weathering hypothesis,” a framework developed by public health scholar Arline Geronimus, which suggests that chronic exposure to adversity and structural inequality leads to earlier health deterioration in marginalized groups. Here, researchers extend that framework to show how accumulated relational advantage, the other side of the coin, may confer resilience at the molecular level.&lt;/p&gt;&lt;p&gt;This doesn’t mean a single friendship or volunteer stint can turn back the biological clock. But the authors, including Frank Mann at Stony Brook University and Laura Kubzansky at Harvard University, suggest that the depth and consistency of social connection, built across decades and different spheres of life, matters profoundly. The study adds weight to the growing view that social life is not just a matter of happiness or stress relief but a core determinant of physiological health.&lt;/p&gt;&lt;p&gt;"Think of social connections like a retirement account," Ong said. “The earlier you start investing and the more consistently you contribute, the greater your returns. Our study shows those returns aren't just emotional; they're biological. People with richer, more sustained social connections literally age more slowly at the cellular level. Aging well means both staying healthy and staying connected - they're inseparable."&lt;/p&gt;&lt;head rend="h4"&gt;Media Contact&lt;/head&gt;&lt;p&gt;Get Cornell news delivered right to your inbox.&lt;/p&gt;Subscribe&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.cornell.edu/stories/2025/09/lifetime-social-ties-adds-healthy-aging"/><published>2025-09-27T06:00:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45393653</id><title>Property-Based Testing of OCaml 5's Runtime System [pdf]</title><updated>2025-09-27T13:34:01.069721+00:00</updated><content/><link href="https://janmidtgaard.dk/papers/Midtgaard%3AOLIVIERFEST25.pdf"/><published>2025-09-27T06:45:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45393842</id><title>Typst: A Possible LaTeX Replacement</title><updated>2025-09-27T13:34:00.515372+00:00</updated><content>&lt;doc fingerprint="2e5a531d3be77598"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Typst: a possible LaTeX replacement&lt;/head&gt;
    &lt;p&gt;Typst is a program for document typesetting. It is especially well-suited to technical material incorporating elements such as mathematics, tables, and floating figures. It produces high-quality results, comparable to the gold standard, LaTeX, with a simpler markup system and easier customization, all while compiling documents more quickly. Typst is free software, Apache-2.0 licensed, and is written in Rust.&lt;/p&gt;
    &lt;head rend="h4"&gt;Desire for a LaTeX replacement&lt;/head&gt;
    &lt;p&gt;LaTeX is a document typesetting system built on the foundation of Donald Knuth's TeX. LaTeX has become the standard tool for the preparation of scholarly papers and books in several fields, such as mathematics and computer science, and widely adopted in others, such as physics. TeX and LaTeX, which predate Linux, are early free software success stories. The quality of TeX's (and therefore LaTeX's) output rivals the work of skilled hand typesetters for both text and mathematics.&lt;/p&gt;
    &lt;quote&gt;$ sudo subscribe today&lt;p&gt;Subscribe today and elevate your LWN privileges. You’ll have access to all of LWN’s high-quality articles as soon as they’re published, and help support LWN in the process. Act now and you can start with a free trial subscription.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;Despite the acclaim earned by LaTeX, its community of users has been griping about it for years, and wondering aloud whether one day a replacement might arrive. There are several reasons for this dissatisfaction: the LaTeX installation is huge, compilation of large documents is not fast, and its error messages are riddles delivered by an infuriating oracle. In addition, any nontrivial customization or alteration to the program's behavior requires expertise in an arcane macro-expansion language.&lt;/p&gt;
    &lt;p&gt;Along with the griping came resignation: after decades of talk about a LaTeX replacement with nothing plausible on the horizon, and with the recognition that LaTeX's collection of specialized packages would take years to replace, it seemed impossible to dislodge the behemoth from its exalted position.&lt;/p&gt;
    &lt;head rend="h4"&gt;Introducing Typst&lt;/head&gt;
    &lt;p&gt;In 2019 two German developers, Laurenz Mädje and Martin Haug, decided to try to write a LaTeX replacement "just for fun". In 2022, Mädje wrote his computer science master's thesis about Typst. In March 2023, its first pre-release beta version was announced; a month later, semantic versioning was adopted with the release of v0.1.0. Typst is now at v.0.13.1 and shows 365 contributors on its GitHub repository.&lt;/p&gt;
    &lt;p&gt;I had been aware of this project for over a year but had not paid much attention, assuming it to be yet another attempt to supplant LaTeX that was doomed to fail. A rising chorus of enthusiasm among early adopters, and the beginnings of acceptance of Typst manuscripts by scholarly journals, made me curious enough to take the young project for a spin.&lt;/p&gt;
    &lt;p&gt;Typst is available as Rust source and as a compiled binary. To install, visit the releases page and download the appropriate archive. There are options for Linux, macOS and Windows; I used the precompiled Linux version for my testing.&lt;/p&gt;
    &lt;p&gt;The "typst" command accepts several subcommands. Entering "typst fonts" lists all of the usable fonts to be found in standard locations on the machine; nonstandard font directories can be added manually. In my case, Typst found all of my 476 fonts instantly; the only ones omitted were some ancient PostScript Type 1 fonts used by LaTeX. Users who have LaTeX installed will have a large collection of OpenType and TrueType math and text fonts on their machines; Typst can use all of these. But Typst will work fine without them, as the program has a small collection of fonts built in (try "typst fonts --ignore-system-fonts" to see them).&lt;/p&gt;
    &lt;p&gt;Two other subcommands to explore are "compile", which generates the output (PDF by default, with PDF/A, SVG, and PNG available, along with HTML under development) from a source file, and "watch" for interactive editing. The watch subcommand keeps a Typst process running that incrementally and automatically compiles the document to PDF in response to changes in the source. To use "typst watch" effectively, the screen should be divided into three windows: a small terminal window to monitor the typst output for error (or success) messages, the editing window, and an area for any PDF reader that automatically reloads the displayed document when it changes (many, such as my favorite, Sioyek, do this). The result is a responsive live preview, even of large documents, due to Typst's speed and incremental compilation. For example, Frans Skarman described his experience writing his doctoral thesis in Typst, and noted that he was able to enjoy nearly instant previews of content changes to the book-length document.&lt;/p&gt;
    &lt;head rend="h4"&gt;How Typst improves on LaTeX&lt;/head&gt;
    &lt;p&gt;Typst output is quite close to that of LaTeX. It uses the same line-breaking algorithm developed by Donald Knuth and Michael Plass for TeX, so it creates nicely balanced paragraphs of regular text. Its mathematical typesetting algorithms are based closely on the TeX algorithms, and indeed mathematical rendering is nearly indistinguishable between the two systems.&lt;/p&gt;
    &lt;p&gt;Getting started with LaTeX can be confusing for newcomers, because it comes with several alternative "engines" reflecting the long and complex history of the project. These are the various binaries such as "pdflatex", "tex", "xelatex", "luatex", "lualatex", and more, each with somewhat different capabilities. For Typst there is only "typst".&lt;/p&gt;
    &lt;p&gt;Markup in Typst is less verbose and easier to read than in LaTeX. It dispenses with the plethora of curly brackets and backslashes littering LaTeX documents by adopting, for prose, syntax in the style of Markdown, and, for equations, a set of conventions designed for easy input. The fact that curly brackets and backslashes are awkward to type on German keyboards may have provided a little extra impetus for the developers to create an alternative markup system that doesn't require a forest of these symbols.&lt;/p&gt;
    &lt;p&gt;When users make syntax errors in markup or programming, inevitable even in Typst, the system presents them with another dramatic improvement over LaTeX (and TeX): error messages using colored glyphs that clearly point out exactly where the problem is. I've even discovered that Typst will save me from trying to run a syntactically correct infinite loop.&lt;/p&gt;
    &lt;p&gt;Here is a bit of Typst markup for a shopping list, with the resulting rendering to the right:&lt;/p&gt;
    &lt;quote&gt;= Shopping List == Vegetables + Broccoli + Asparagus (*fresh only*) + Plantains (_ripe and green_) == Booze + Rum - White - Dark + #underline[Good] gin&lt;/quote&gt;
    &lt;p&gt;The example gives a flavor of Typst's terse markup syntax. Headings are indicated with leading = signs. Automatically numbered lists are created by prepending + signs to items, and bulleted lists with - signs; lists can be nested. Delimiters are shown for bold text and italics. These are shortcuts, or markup syntax sugar, for Typst functions for transforming text. Not every function has a corresponding shortcut; in those cases one needs to call the function explicitly, as in the final item.&lt;/p&gt;
    &lt;p&gt;Typst input is always within one of three modes. Markup (text) mode is the default. The # sign preceding the function call in the last line of the example places Typst in "code mode". The "underline()" function accepts a number of keyword arguments that affect its behavior, and one trailing argument, in square brackets, containing the text that it modifies. In the example, we've stuck with the default behavior, but if we wanted, for example, a red underline, we could use "#underline(stroke: red)[Good] gin". Following the square-bracketed text argument, Typst returns to interpreting input in text mode.&lt;/p&gt;
    &lt;p&gt;Other functions produce output directly, rather than modifying a text argument. This bit of Typst input:&lt;/p&gt;
    &lt;quote&gt;#let word = "Manhattan" There are #str.len(word) letters in #word.&lt;/quote&gt;
    &lt;p&gt;produces the output (in typeset form) "There are 9 letters in Manhattan.". The "len()" function is part of the "str" module, so it needs the namespace.&lt;/p&gt;
    &lt;p&gt;Let's take a look at the LaTeX equivalent for the first half of the shopping list for comparison:&lt;/p&gt;
    &lt;quote&gt;\documentclass[12pt]{article} \begin{document} \section*{Shopping List} \subsection*{Vegetables} \begin{enumerate} \item Broccoli \item Asparagus ({\bfseries fresh only}) \item Plantains (\emph{ripe and green}) \end{enumerate} \end{document}&lt;/quote&gt;
    &lt;p&gt;The first two and the last line are boilerplate that is not required in Typst. The difference in verbosity level and ease of reading the source is clear.&lt;/p&gt;
    &lt;p&gt;The third Typst mode, in addition to markup and code, is math mode, delimited by dollar signs. This is also best illustrated by an example:&lt;/p&gt;
    &lt;quote&gt;$ integral_0^1 (arcsin x)^2 (dif x)/(x^2 sqrt(1-x^2)) = π ln 2 $&lt;/quote&gt;
    &lt;p&gt;When this is compiled by Typst, it produces the result shown below:&lt;/p&gt;
    &lt;p&gt;Those who've used LaTeX will begin to see from this example how math in Typst source is less verbose and easier to read than in LaTeX. Greek letters and other Unicode symbols can be used directly, as in modern LaTeX engines such as lualatex, which we looked at back in 2017, but with no imports required.&lt;/p&gt;
    &lt;p&gt;The advent of the LuaTeX and LuaLaTeX projects provided users who wanted to incorporate programming into their documents a more pleasant alternative to the TeX macro language. As powerful as the embedded Lua system is, however, it betrays its bolted-on status, requiring users to negotiate the interface between Lua data structures and LaTeX or TeX internals. In Typst, programming is thoroughly integrated into the system, with no seams between the language used for calculation and the constructs that place characters in the final PDF. Typst programs are invariably simpler than their LuaLaTeX equivalents. All authors using Typst will make at least some simple use of its programming language, as such basic necessities as changing fonts, or customizations such as changing the style of section headings, are accomplished by calling Typst functions.&lt;/p&gt;
    &lt;p&gt;The Typst language is somewhat similar to Rust, perhaps unsurprisingly. Most Typst functions are pure: they have no side effects and always produce the same result given the same arguments (aside from certain functions that mutate their arguments, such as array.push()). This aspect reduces the probability of difficult-to-debug conflicts among packages that plague LaTeX, and makes it easier to debug Typst documents.&lt;/p&gt;
    &lt;p&gt;Although Typst uses the same line-breaking algorithm as LaTeX, its internal approach to overall page layout is distinct. Some consequences are that Typst does a better job at handling movable elements such as floating figures, and can, for example, easily split large tables across page breaks, something that LaTeX struggles with even with specialized packages.&lt;/p&gt;
    &lt;head rend="h4"&gt;Typst drawbacks&lt;/head&gt;
    &lt;p&gt;Typst's page layout algorithm doesn't always permit the refinements that LaTeX is capable of. For example, Typst is not as good as LaTeX at avoiding widows and orphans. Another salient deficiency is Typst's relative lack of specialized packages, compared with the vast ecosystem produced by LaTeX's decades of community involvement. However, the relative ease of programming in Typst (and the well-organized and extensively commented underlying Rust code) suggests that this drawback may be remedied before a comparable number of decades have elapsed. Indeed, there are already over 800 packages available. Typst still cannot do everything that LaTeX can, but the breadth of its package collection is encouraging.&lt;/p&gt;
    &lt;p&gt;Almost no journals that provide LaTeX templates for submissions offer a Typst option, so physicists and mathematicians adopting Typst will need to find a way to convert their manuscripts. This is made easier for those who use Pandoc, as that conversion program handles Typst.&lt;/p&gt;
    &lt;p&gt;Another drawback is the difficulty of learning Typst. The official documentation is confusingly organized, with information scattered unpredictably among "Tutorial", "Reference", and "Guides" sections. Concepts are not always clearly explained, and sometimes not presented in a logical order. The manual is not keeping up with the rapid development of the program, and contains some out-of-date information and errors. None of this is surprising considering how quickly the project is moving, its early stage, and its small core team. A work-in-progress called the Typst Examples Book has appeared, which may be a better starting point than the official documentation.&lt;/p&gt;
    &lt;p&gt;There are other minor deficiencies compared with LaTeX, such as the inability to include PDF documents. Typst provides no analogue to LaTeX's parshape command, which lets authors mold paragraphs to, for example, wrap around complex illustrations. The situation is likely to change, however, as something like parshape is being considered for the future.&lt;/p&gt;
    &lt;p&gt;More serious is the possibility of breaking changes as the system evolves, always a risk of early adoption. I suspect, however, that these will require only minor edits to documents in most cases. Progress seems to be steady, rational, and responsive to user requests.&lt;/p&gt;
    &lt;head rend="h4"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;I'm using Typst in real work right now to write a physics paper. I will need to submit my manuscript using the journal's LaTeX template, but I'm taking advantage of Typst to make the entry of the paper's many equations simpler, and I'll transform the result to LaTeX with Pandoc without needing any manual adjustment. The tooling is excellent, as my preferred editor, Neovim, has support for the Tree-sitter incremental parser for Markdown and Typst, which provides syntax-aware highlighting and navigation of the source files. I use Typst's fast incremental compilation to get live feedback as I fiddle with my math markup.&lt;/p&gt;
    &lt;p&gt;I was skeptical when I downloaded Typst to try it out, but became enthusiastic within minutes, as I saw the first (of many) of its lovely error messages, and remained sanguine as I saw the quality of its output. I predict that Typst will eventually take the place of LaTeX. But even if that never comes to pass, it is a useful tool right now.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GuestArticles&lt;/cell&gt;
        &lt;cell&gt;Phillips, Lee&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Sep 17, 2025 15:45 UTC (Wed) by spacefrogg (subscriber, #119608) [Link] (22 responses) There used to be the well-founded expectation from users that a typeset document did not change when processed by a future version of the processor, style or packages. In the long-run, this made learning and dealing with the languages intricacies and idiosyncrasies worthwhile. This has faded somewhat (looking at you, siunitx) in recent years since the first-generation contributors left the scene. I hope that the Typst maintainers and contributors understand this historic lesson as well. Also, TeX is a document processor able to document itself or at least its packages. And there is a reliable ecosystem for that as well (e.g. certain pressure on contributors to provide documentation along with code for acceptance). Posted Sep 17, 2025 17:07 UTC (Wed) by wtarreau (subscriber, #51152) [Link] (11 responses) Interesting because while that may be true in theory, it's precisely the opposite that made me abandon it over time. Trying to rebuild my old docs systematically resulted in cryptic errors. Looking on the net suggested that foobar.sty was replaced by somethingelse.sty which was close enough but required modifications etc. It happened to me several times to spend half a day updating a 5-year old manual to accommodate new packages. It might very well just be that some packages are less strict than the lower layers and that I hadn't been using state-of-the-art ones, but for the end user experience the problem is the same, a document you wrote doesn't build anymore spewing many errors. That happened to me with documents written between 1995 and 2000 roughly. Some packages were even related to how to deal with character encodings, which newer versions implemented more naturally but probably caused more difficulties to adapt to. I also remember some of article.sty no longer being compatible with the older one I used. I'm speaking about old memories, as it's been 20 years or so since I progressively stopped using it. It always made me sad because I loved the output quality which was super pleasant to read. Also I remember that newer versions were way simpler to install than the pre-2000 ones where you had to collect styles from everywhere and build your own packages from sources. Posted Sep 17, 2025 18:38 UTC (Wed) by ballombe (subscriber, #9523) [Link] (4 responses) Posted Sep 17, 2025 20:23 UTC (Wed) by NYKevin (subscriber, #129325) [Link] (3 responses) Posted Sep 18, 2025 12:35 UTC (Thu) by aragilar (subscriber, #122569) [Link] Posted Sep 19, 2025 18:05 UTC (Fri) by anton (subscriber, #25547) [Link] (1 responses) If I want to revise the paper (e.g., submit a revision of a rejected paper to a different conference), the original appearance is not desired, and usually I need to produce a different format, so it does not matter much if the original class and template no longer works. What matters is that I can easily copy my text to the new template. That is mostly easy, but recently I have had to deal with templates that want all kinds of meta-data, and place standard elements such as \title and \author in a non-standard location, which makes things somewhat time-consuming. But the main part of the paper can be reused and revised, with a formatting pass at the end. Concerning longevity, I have rarely had the need to process a really old work, but just to see how well it works, I have tried a thesis from 1990, and the main text works (graphics are separate, and I would have to invest more time to find out how they were built). I also tried papers from 1992 and 1993, and they compiled fine; the paper from 1992 contains Framemaker graphics, and I no longer have a way to convert that to Postscript, but fortunately I have the Postscript output; for one picture, the placement is slightly wrong, though. The 1993 paper looks fine. Maybe the advantage with these old papers is that there were no style/class files coming from the publication venue, so I just used article (or, for the thesis, report), and not many packages, either. Posted Sep 20, 2025 22:11 UTC (Sat) by NYKevin (subscriber, #129325) [Link] Posted Sep 19, 2025 0:03 UTC (Fri) by jschrod (subscriber, #1646) [Link] (4 responses) But you still bring this up, 31 years after the upgrade - which was 5 years in the making before. From a developer point of view, this is a complaint about a development that happened 35 years ago. Are you aware that this statement is similar to "I will not use Wayland because I had to write XFree86 modline configs back then"? (Because, as you surely remember, this was even before the days of the X.org server with better autoconfiguration that now is considered obsolete.) Disclaimer: I was part of the team that introduced LaTeX 2e back in 1994. I am still connected to that work and to the people working on it, though I'm not an active developer anymore. Posted Sep 19, 2025 5:20 UTC (Fri) by wtarreau (subscriber, #51152) [Link] (3 responses) The thing is that when you don't use LaTeX often enough and each time you do it's difficult, then what remains of the experience is frustration. The frustration of not being able to reproduce a previous report that you spent a lot of time arranging, etc. When I was using it on a daily basis 30 years ago, I *loved* it. Never having to think about what the output would look like and just typing was really awesome and I haven't found anything getting close to that experience. And I'm still pleased to read papers written using it, which are instantly recognizable. I'm also a bit suspicious about tools that try to imitate it, because, as you say, it has accumulated decades of expertise in what it's doing, so users risk losing great stuff. It's very possible that forward compatibility has improved a lot since these experience, but due to these problems I got used to no longer using it. The rare times I need to write something with different fonts and sizes, I just write HTML and let the browser of the moment render it. It's a bit more painful but relies on a standard that's not going to disappear any time soon. Posted Sep 19, 2025 8:34 UTC (Fri) by anselm (subscriber, #2796) [Link] (2 responses) LaTeX is great if you're largely happy with what it does. If you need to bend it to your will to obtain a specific effect, that can easily become an exercise in frustration – fortunately now there are extension packages which will let you, e.g., control how chapter and section headings look like, which was something that in the 1990s required fairly arcane knowledge of the insides of LaTeX to change in even minor ways. Similarly, LaTeX input is reasonably straightforward to write once you've got the hang of it, but it is an absolute bear to parse if you want to process it with a tool that isn't LaTeX itself. TeX input, if anything, is worse. The main problem of the TeX and LaTeX ecosystem is that it is, to a large extent, based on ideas which were innovative in the 1980s, but the publishing world has continued turning in the meantime, and TeX's stability guarantee in particular, while commendable in principle, has largely prevented it from evolving along. When TeX was new, PostScript hadn't really been invented yet, PDF wasn't even on the horizon, font technology looked a lot different from what it does today, and Unicode wasn't a thing at all, but now there is no way around these developments. The solutions that Knuth and his colleagues came up with (DVI, Metafont, and so on) didn't catch on outside the TeX community, so TeX has been chasing what the rest of the world was doing in these areas, through non-standard variants such as eTeX, PDFTeX, LuaTeX, etc. It is true that it is perfectly possible, in 2025, to use LaTeX to typeset a PDF document with OpenType fonts based on UTF-8 encoded input, but this means you have to run a version of TeX that has special code extensions not necessarily found in other versions of TeX, using special LaTeX packages which may come bundled in a “batteries included” distribution such as TeXLive but are not actually part of LaTeX itself. This fragmentation tends to make life with (La)TeX more difficult. Also, nowadays people expect to be able to write a document in a single source format and render it, without source changes, in wildly different output formats such as HTML and PDF, in a way that avails itself of the specific advantages of the format in question, and TeX/LaTeX doesn't really have a straightforward and obvious answer to that requirement like Markdown, Pandoc, or Sphinx (to name but a few examples) do. I've been a TeX and LaTeX user for 40 years now but I'm looking at Typst with considerable interest. Posted Sep 19, 2025 12:21 UTC (Fri) by dskoll (subscriber, #1630) [Link] I solved this problem (with a little bit of pain) for my 600-page set of manuals I mentioned earlier. I wanted PDF output as well as HTML output. There's a pretty nice program called Yes, it was a bit annoying to set up, but once I had my Makefile written, it worked beautifully. Posted Sep 27, 2025 9:26 UTC (Sat) by Delio (guest, #179554) [Link] Posted Sep 27, 2025 11:59 UTC (Sat) by simlo (guest, #10866) [Link] Posted Sep 17, 2025 20:51 UTC (Wed) by warrax (subscriber, #103205) [Link] (9 responses) I do think you're correct that backward[1] compatibility *is* important, but the LaTeX ecosystem as a whole isn't necessarily great at that... it very much depends on what packages you use. [1] Future versions being able to process old code/documents is usually referred to as 'backward' compatibility. Posted Sep 17, 2025 21:24 UTC (Wed) by dskoll (subscriber, #1630) [Link] (4 responses) Hmm... I have three manuals I started writing 20 years ago and continued writing through 2018; they total almost 600 pages and still build perfectly fine on whatever version of LaTeX ships with Debian 13. I don't go crazy with untested or new packages, though... all of the packages I use have been around for a long time and are very stable. Posted Sep 18, 2025 2:18 UTC (Thu) by Cyberax (✭ supporter ✭, #52523) [Link] (3 responses) Posted Sep 18, 2025 9:38 UTC (Thu) by paulj (subscriber, #341) [Link] (1 responses) Posted Sep 18, 2025 13:02 UTC (Thu) by pizza (subscriber, #46) [Link] ...Even on the *same* PC, with the *same* version of Word, "rendering the same" was not guaranteed. (Back in the day, I recall that merely changing the printer driver was sufficient to cause the document to paginate differently..) Posted Sep 18, 2025 17:12 UTC (Thu) by hholzgra (subscriber, #11737) [Link] WinWord could already no longer process it properly when WinWord 6.0; the version right after 2.0a, came out. The LaTeX version worked all the way until late 1999, when due to a series of mishaps the source was lost and I was left with only the PDF result, which I still have. (Generating PDF from Word documents on the other hand was basically unheard of back in the 1990s ...) I also still have a few smaller texts I've written after the 1999 backup disaster, and these I can still process using current LaTeX versions. Posted Sep 17, 2025 21:26 UTC (Wed) by iabervon (subscriber, #722) [Link] (2 responses) Posted Sep 18, 2025 20:54 UTC (Thu) by SLi (subscriber, #53131) [Link] If only the underlying language was something modern and somehow modular and encapsulated instead of a weird macro mess with not-really-scopes. Maybe I never got deep enough into it to really appreciate its cleverness (now I do appreciate that it's 50 years old), but in my experience it doesn't exactly take just "not thinking" to not break something by an unrelated change. Posted Sep 18, 2025 20:58 UTC (Thu) by ejr (subscriber, #51652) [Link] There was ConTeXt as well. I'm not sure of its status. And "worse is better" seems to have been a thing for me this week in many venues. Posted Sep 18, 2025 20:49 UTC (Thu) by SLi (subscriber, #53131) [Link] I think one big problem that I've seen in my field of CS is that people have become used to the output of LaTeX to the extent that everything else looks "unprofessional" to them merely by virtue of being different, even if it fixes some real annoyance in LaTeX output. So while I still do my maths and typesetting often in LaTeX, I'm actually happy that the modern practitioners are refusing to take that route, even if it means them using Word. We shouldn't teach people to rely on stuff built on MS-DOS and Cobol either, even if the best typesetting tool remains some obscure DOS executable. Posted Sep 17, 2025 18:25 UTC (Wed) by rogerwhittaker (subscriber, #39354) [Link] (5 responses) Posted Sep 17, 2025 19:35 UTC (Wed) by spacefrogg (subscriber, #119608) [Link] (4 responses) Additionally, Typst documents are closer in code style to plain TeX than LaTeX with its verbose Pascal'ish blocks. Anecdote: I had to write a letter, printed, on paper, just the other day. Had a go at using Typst and it was done in 20 minutes incl. downloading the letter package, initialising the document boilerplate and understanding what to change where. It looks like simple tasks are actually simple to do. Posted Sep 18, 2025 10:10 UTC (Thu) by epa (subscriber, #39769) [Link] (3 responses) Posted Sep 18, 2025 12:41 UTC (Thu) by smoogen (subscriber, #97) [Link] Posted Sep 19, 2025 9:19 UTC (Fri) by taladar (subscriber, #68407) [Link] Posted Sep 26, 2025 19:38 UTC (Fri) by bluss (guest, #47454) [Link] Posted Sep 18, 2025 9:21 UTC (Thu) by al4711 (subscriber, #57932) [Link] Posted Sep 18, 2025 11:36 UTC (Thu) by ceplm (subscriber, #41334) [Link] (2 responses) Posted Sep 19, 2025 18:22 UTC (Fri) by anton (subscriber, #25547) [Link] (1 responses) I looked up when Lout was released, and that was in 1991 (with work starting in 1994). The most recent release is from 2023, but apparently that just made it easier to build, so it's not sure if it is still being maintained. But then, if it works, do you really need any other maintenance? Posted Sep 19, 2025 20:15 UTC (Fri) by ceplm (subscriber, #41334) [Link] Posted Sep 18, 2025 17:02 UTC (Thu) by hholzgra (subscriber, #11737) [Link] (3 responses) Lower entry barrier for sure, but always having a taste of "Those who do not understand XXX have to reinvent it ... poorly" (CMake vs. Autotools rings a similar bell, although in a slightly different field) I'm afraid that once again we are forgetting about quite a few things that were already solved in the past by switching to such new solutions carrying less of a history with them ... Posted Sep 20, 2025 3:30 UTC (Sat) by mathstuf (subscriber, #69389) [Link] (2 responses) *sigh* Note that one of the "sparks" for CMake was Windows (as in MSVC, not MinGW-on-Cygwin or MSYS2) support. Something Autotools still does not have today. Posted Sep 20, 2025 10:44 UTC (Sat) by hholzgra (subscriber, #11737) [Link] (1 responses) That is not my issue with CMake, it is rather that it "forgot" about things like "make distcheck" and quite a few other things that autotools had solved just fine for ages. So while it supports other build systems besides good old Make, I'd say that at least on the Unixoid side Makefiles are still the predominant backend being used. And the Makefiles it generates are sub par compared to what automake generates. That's my "reinvent it ... badly" pain point with CMake. Posted Sep 20, 2025 23:49 UTC (Sat) by mathstuf (subscriber, #69389) [Link] I don't think `distcheck` is all that important for CMake because…the source tree *is* the tarball; there's no intermediate step which bundles everything that needs re-verified &amp;gt; I'd say that at least on the Unixoid side Makefiles are still the predominant backend being used I'd be very surprised if Ninja were not the most popular generator these days. I believe Fedora has switched its default generator at this point at least? I know Visual Studio's integration prefers it. &amp;gt; And the Makefiles it generates are sub par compared to what automake generates. Oh, I don't think anyone is going to argue that CMake's Unix Makefiles generator is anywhere near optimal. There are a number of reasons for it. The most important is that autotools and CMake are different build *systems* even though they do share support for a common build *tool* as an output. Because CMake also supports IDEs with…rather restrictive ideas on what is possible, CMake's model for the build is quite different than autotools'. The build tool is easy to define: it is a build graph executor. Make, ninja, msbuild, just, rake, build2, boost.build, bjam, scons, tup, etc. are all "build tools" that execute a build graph. The build *system* is where things get interesting (for me). Some build tools are also build systems: build2, boost.build, scons, tup. This is the layer which defines things like "what is a target" and "how do targets relate". autotools and CMake both execute at this level and "compile" their input language to something the target build tool understands. This does not mean that build systems expose everything that the build tool supports (e.g., CMake does not allow users to write their own ninja rule statements because…what does that even mean for its other outputs). Of course, some build tool support may have additional features as long as it doesn't conflict with the overall model of the build system itself. For example, CMake's Ninja generator can drop some dependencies other generators need to support the semantics CMake guarantees if it can prove to itself that they're satisfied in other ways. Now, there are ideas to rewrite CMake's Makefiles output to be more like Ninja: one global graph without per-directory entry points and without the per-target subgraph recursive instance. This would allow the Makefiles generator to do the same pruning of unnecessary dependencies that Ninja does. But because it was following the IDE model of "the build graph is a series of targets; each target's subgraph is an independent entity", we have the non-optimal behavior of "if A links to B, B must link before anything in A starts" because that is how CMake guarantees things like generated headers in B are available when A starts compiling[1]. So, in short, I think CMake tool a more general approach to build systems and its Makefiles output is suboptimal because of that. But because we now also support the Ninja generator which is, IMO, strictly better (unless one needs a job server for nested builds), restricting the scope to the Makefiles output of each is not a fair comparison. [1] The link dependency can be dropped if A's custom command dependencies are a superset of B's custom command dependencies: any header or whatever B ends up generating is already in A's graph. Posted Sep 19, 2025 0:28 UTC (Fri) by jschrod (subscriber, #1646) [Link] (9 responses) Just in the last few years, a major undertaking starts to produce tangible results: LaTeX Tagged PDF https://latex3.github.io/tagging-project/ With it, one can prepare barrier free PDFs with acceptable effort - *even for math*. I don't know if any other system that provides this level of capability. This is the stuff that gets developed in established FOSS ecosystems by people who work on typesetting systems since decades. Disclaimer: I'm personally involved in the LaTeX project, though I'm not a developer any more. Posted Sep 19, 2025 2:46 UTC (Fri) by intelfx (guest, #130118) [Link] (5 responses) How does this help with UX of *writing* in LaTeX, which seems to be the major issue driving the competing developments (and specifically the subject of the article)? &amp;lt;...&amp;gt; I understand that LaTeX is something you relate to, but your response reads somewhat like this: - Project A sucks at ABC, and I'm badly tired of it, so I don't wish to use project A anymore. I'm looking forward to possible replacements. Posted Sep 19, 2025 9:52 UTC (Fri) by Wol (subscriber, #4433) [Link] This seems to be a major blinker problem in FOSS. My brother's comments about his experience of Emacs at Uni 40 years ago are classic - when he first started he thought it was awful, impossible to use, way too complicated. Then after a year or two, once he'd mastered it, he couldn't imagine using anything else. The reason Word conquered the world (and the reason I hate it) is because it was aimed at people who COULDN'T TYPE - the managerial guys who had professional typists, the couch potatoes who didn't do much, etc etc. WordPerfect - which I took to like a duck to water because it (on the surface) mimicked a typewriter - which failed in large part due to MS's dirty tricks - couldn't compete in the battle for the minds of the people with the purse strings, even though it was a much better professional solution. FLOSS so often is such a super swiss army knife that anybody new approaching it is left thinking "but how does it fix MY problem ???". I use lilypond, and it's incredibly powerful, but the learning curve to access that power is almost impenetrable (it's driven by a variant of Lisp!). Cheers, Posted Sep 19, 2025 10:55 UTC (Fri) by smitty_one_each (subscriber, #28989) [Link] (3 responses) Posted Sep 19, 2025 11:21 UTC (Fri) by leephillips (subscriber, #100450) [Link] (2 responses) Posted Sep 19, 2025 12:41 UTC (Fri) by smitty_one_each (subscriber, #28989) [Link] &amp;gt; the learning curve to access that power is almost impenetrable One of my pet cliches is: "Everything is easy, when you know how to do it." Overleaf provides a gentle introduction to LaTeX. Posted Sep 19, 2025 13:17 UTC (Fri) by paulj (subscriber, #341) [Link] I'm a big fan of Lyx as a great accessible and fairly user-friendly UI for writing documents to eventually typeset with LaTeX. I've used it for my own dissertation and it made writing so much easier. It's also customisable. I ended up making a few of my own definitions for things, with their own menu entries - which was just a matter of adding some UI definition files. My father went to uni after retirement and (eventually) got a masters. He used to have endless issues with his masters dissertation in MS Word, with the format going screw and *especially* the required citations being very hard to manage and constantly getting messed up. I was constantly having to go over to him to try help him with his MS Word processing issues. In the end, I switched him over to Lyx. Showed him how to make chapters, sections and sub-sections, and insert citations. Told him just to write, and that the formatting would largely take care of itself. I helped with proofing at the end and help with inserting figures and illustrations, but it saved *both of us* a lot of hair-pulling and time. My dad generally does not get on with computers. He gets very frustrated with complex programmes, with states affecting things he can't see/understand. He became a big of fan Lyx however, for the way it just let him write and generally staying out of the way, while keeping track of all the citations and layout for him, and producing a beautiful doc at the end thanks to LaTeX. Lyx is a _great_ bit of software! Posted Sep 19, 2025 19:04 UTC (Fri) by notriddle (subscriber, #130608) [Link] (1 responses) And Typst does this: In TeX's defense, it's not the worst system I've ever dealt with, and a lot of that spew can be cleaned up by just putting it behind a --verbose flag, but the biggest, hardest-to-fix problem is here: Typest's equivalent has a line number. It also actually matches what was written. Is that fixable without breaking changes to the macro system? Posted Sep 22, 2025 18:49 UTC (Mon) by jschrod (subscriber, #1646) [Link] In all other error messages TeX's error messages consist of two lines. The first line has the line number and all characters that are read up to the error, the second line has the characters that are still to be processed. But that is actually a bynote. You wrote &amp;gt; tagged pdf or other niche features Since journals (especial scientific journals that Lee wrote about) and other publishers increasingly demand the production of barrier free PDFs for online publication, Tagged PDF is not a niche feature, IMNSHO. Customers of mine currently pour 6-digit numbers of Euro in creation of such files. For private production it doesn't matter -- but for publication, it will soon be a must-have. Posted Sep 27, 2025 9:11 UTC (Sat) by Delio (guest, #179554) [Link] Posted Sep 19, 2025 6:06 UTC (Fri) by yashi (subscriber, #4289) [Link] (2 responses) Meander seems to do it: https://github.com/typst/packages/pull/3065 Posted Sep 19, 2025 11:28 UTC (Fri) by leephillips (subscriber, #100450) [Link] (1 responses) This was first released while we were still working on the article. In other words, my prediction is coming true: that packages for Typst will emerge rapidly, because it’s easy (easier) to program in. Posted Sep 19, 2025 15:27 UTC (Fri) by adnl (subscriber, #179418) [Link] Posted Sep 27, 2025 12:04 UTC (Sat) by norbusan (guest, #10100) [Link] (1 responses) As wtih coreutils, as with several other places, first of all "I'm so shiny" (thanks Moana!), but reality is different. Posted Sep 27, 2025 13:26 UTC (Sat) by Delio (guest, #179554) [Link] &lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;head/&gt; Yes, you get a class file, and a template with \usepackage invocations (or they are in the class file), and if you want to produce the exact same output, then yes, you may need to keep the old packages around. But in that scenario I can just keep the resulting output (e.g., a PDF) around. &lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;quote&gt;When I was using it on a daily basis 30 years ago, I *loved* it. Never having to think about what the output would look like and just typing was really awesome and I haven't found anything getting close to that experience. And I'm still pleased to read papers written using it, which are instantly recognizable. I'm also a bit suspicious about tools that try to imitate it, because, as you say, it has accumulated decades of expertise in what it's doing, so users risk losing great stuff.&lt;/quote&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;quote&gt;Also, nowadays people expect to be able to write a document in a single source format and render it, without source changes, in wildly different output formats such as HTML and PDF, in a way that avails itself of the specific advantages of the format in question, and TeX/LaTeX doesn't really have a straightforward and obvious answer to that requirement[...]&lt;/quote&gt;&lt;code&gt;htlatex&lt;/code&gt; that does a creditable job of generating HTML, and then I post-processed it to (eg) replace the generated images with the original source images so figures were of higher quality.  I also defined a few conditional macros that inserted links to training videos in certain spots... something you can't really do with PDF.

&lt;head&gt;Inclusion of PDF files has been implemented&lt;/head&gt;&lt;head&gt;To become success story&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;About the compatibility story...&lt;/head&gt;&lt;head&gt;Another project with similar aims&lt;/head&gt;&lt;head&gt;Another project with similar aims&lt;/head&gt;&lt;head&gt;Another project with similar aims&lt;/head&gt;&lt;head&gt;Another project with similar aims&lt;/head&gt;&lt;head&gt;Another project with similar aims&lt;/head&gt;&lt;head&gt;Another project with similar aims&lt;/head&gt;&lt;head&gt;Very friendly and helpful Community&lt;/head&gt;&lt;head&gt;Lout&lt;/head&gt;&lt;head/&gt; Yes, when I read the article, I remembered Lout; a collegue advocated that in the 1990s. And already at that time it was obvious that TeX was a good typesetting engine, but a badly designed programming language, and LaTeX inherited this. Nevertheless, LaTeX has a big community behind it, and obviously Lout was unable to overcome the network effects coming from that. Will it be different for Typst or other contenders? Would it help if they built on each other rather than starting from scratch? &lt;head&gt;Lout&lt;/head&gt;&lt;head&gt;Lout&lt;/head&gt;&lt;head&gt;Bad feeling ...&lt;/head&gt;&lt;head&gt;Bad feeling ...&lt;/head&gt;&lt;head&gt;Bad feeling ...&lt;/head&gt;&lt;head&gt;Bad feeling ...&lt;/head&gt;&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;lb/&gt; This is bound to be incorporated into the next TeX-Live release and thus will appear in all major Linux distributions in due course.&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;lb/&gt; &amp;gt; This is bound to be incorporated into the next TeX-Live release and thus will appear in all major Linux distributions in due course.&lt;lb/&gt; - But project A is the best at XYZ, so this proves we are better than project B!&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;lb/&gt; Wol&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;head/&gt; If Typst manages to steal mindshare from LaTeX, I doubt it'll have much to do with tagged pdf or other niche features. It'll happen because, if I forget a closing brace, pdflatex does this: &lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;code&gt;This is pdfTeX, Version 3.141592653-2.6-1.40.24 (TeX Live 2022/Debian) (preloaded format=pdflatex)
 restricted \write18 enabled.
entering extended mode
(./t.latex
LaTeX2e &amp;lt;2022-11-01&amp;gt; patch level 1
L3 programming layer &amp;lt;2023-01-16&amp;gt;
(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls
Document Class: article 2022/07/02 v1.4n Standard LaTeX document class
(/usr/share/texlive/texmf-dist/tex/latex/base/size12.clo))
(/usr/share/texlive/texmf-dist/tex/latex/l3backend/l3backend-pdftex.def)
(./t.aux))
Runaway argument?
{ripe and green) \end {enumerate} \end {document} \par 
! File ended while scanning use of \emph .
&amp;lt;inserted text&amp;gt;
                \par 
&amp;lt;*&amp;gt; t.latex
           
? &lt;/code&gt;&lt;code&gt;error: unclosed delimiter
   ┌─ t.typst:14:12
   │
14 │ + #underline[Good gin  
   |             ^&lt;/code&gt;&lt;code&gt;{ripe and green) \end {enumerate} \end {document} \par &lt;/code&gt;&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;head&gt;Fully Tagged PDF (even for math) is in the works for LaTeX&lt;/head&gt;&lt;head&gt;Meander for parshape&lt;/head&gt;&lt;head&gt;Meander for parshape&lt;/head&gt;&lt;head&gt;Meander for parshape&lt;/head&gt;&lt;head&gt;Bad comparison&lt;/head&gt;&lt;head&gt;Bad comparison&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/Articles/1037577/"/><published>2025-09-27T07:31:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45394942</id><title>Cracker Barrel Outrage Was Almost Certainly Driven by Bots, Researchers Say</title><updated>2025-09-27T13:34:00.304901+00:00</updated><content>&lt;doc fingerprint="6ea788b311e82dc4"&gt;
  &lt;main&gt;
    &lt;p&gt;Did something feel…off about the whole Cracker Barrel debacle to you? Did you, in the midst of the endless stream of outrage directed at the Southern country-style restaurant, pause and think, “There’s just no way anyone cares about Cracker Barrel’s logo this much, right?” Well, you might have been onto something. According to data compiled by intelligence platform PeakMetrics, nearly half of the early posts about Cracker Barrel’s logo change appeared to be generated by bots.&lt;/p&gt;
    &lt;p&gt;PeakMetrics grabbed a sample of 52,000 posts made on X within the first 24 hours of Cracker Barrel’s announcement that it would be modernizing its logo to an admittedly very plain and generic design. In that timeframe, it found that 44.5% of all mentions of Cracker Barrel were flagged as likely or higher bot activity. Those numbers climb even higher when a boycott is mentioned. About 1,000 posts in that first 24-hour period called on people to stop eating at Cracker Barrel, and 49% of those posts got flagged as likely coming from bots. In its report, PeakMetrics states that the boycott was unlikely to be an organic grassroots response but a “bot-assisted amplification seeded by meme/activist accounts.”&lt;/p&gt;
    &lt;p&gt;The campaigns don’t seem as though they were limited to X, either. According to data collected by Open Measures, similar conversations were happening on the alt-tech platforms like Donald Trump’s Truth Social, Twitter knock-offs Gettr and Gab, 4chan, and Rumble. Over those platforms, posters regularly tied the Cracker Barrel logo change to terms like âwokeâ and “DEI,” because apparently, one of the demands of leftist extremists is conforming to sans-serif supremacy.&lt;/p&gt;
    &lt;p&gt;From August 19, when the logo change was announced, to September 5, a few days after the company not only rolled back the logo but also deleted LGBTQ and diversity and inclusion pages from its website, about 2,020,000 posts were made about the whole debacle on X. PeakMetrics estimates that nearly a quarter of those, 24% in total, were likely to be posted by bots. A little ironic, given the group outraged by the whole thing loves to call people who disagree with them NPCs.&lt;/p&gt;
    &lt;p&gt;Of course, that means 75% of those posts were from people. PeakMetrics notes that the earliest posts expressing dismay and frustration at Cracker Barrel’s decision to update its logo came from human-run accounts. Once the bot networks started to pick up on the trend, though, they blew the whole thing up. “Authentic voices articulated cultural dissatisfaction, which bots then amplified,” the report said.&lt;/p&gt;
    &lt;p&gt;PeakMetrics didn’t attribute the bot megaphone to any specific organization or state actor. Rather, it found, “The initiators are ideological activist accounts with prior culture-war posting histories, supported by botnets.” One read on that might be that the right-wing outrage farmers seem to have some inauthentic support that makes them seem more influential than they actually are.&lt;/p&gt;
    &lt;p&gt;Maybe knowing that these outrage cycles aren’t entirely authentic will be enough for corporations like Cracker Barrel to simply ignore the outrage cycle, knowing that most of the bluster won’t amount to anything. Bots don’t really eat biscuits and gravy, after all.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gizmodo.com/cracker-barrel-outrage-was-almost-certainly-driven-by-bots-researchers-say-2000664221"/><published>2025-09-27T11:44:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45395010</id><title>Trellis (YC W24) Is Hiring: Automate Healthcare Paperwork</title><updated>2025-09-27T13:33:59.292899+00:00</updated><content>&lt;doc fingerprint="bc7740d13adfadc6"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h1"&gt;Trellis helps healthcare providers treat more patients faster—while eliminating pre-service paperwork.&lt;/head&gt;
        &lt;p&gt;We do this by automating document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care.&lt;/p&gt;
        &lt;p&gt;Trellis is a spinout from Stanford AI lab and is backed by leading investors including YC, General Catalyst, Telesoft partners, and executives at Google and Salesforce.&lt;/p&gt;
        &lt;head rend="h3"&gt;The Role&lt;/head&gt;
        &lt;p&gt;Forward Deployed Engineers (FDEs) at Trellis work directly with healthcare providers, pharmaceutical companies, and diagnostic labs to understand their most pressing operational challenges and implement AI-powered solutions that transform patient care. Our customers trust Trellis for mission-critical healthcare operations, and projects often start with complex questions like "How do we reduce prior authorization denial rates while accelerating patient access to life-saving treatments?" or "How can we streamline our drug program enrollment process to get patients the medications they need faster?"&lt;/p&gt;
        &lt;head rend="h3"&gt;🧍🏻♂️Why work with us&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Be at the forefront of what's possible in AI and Healthcare data.&lt;/item&gt;
          &lt;item&gt;Work on the most important problem of our time—with direct, measurable impact.&lt;/item&gt;
          &lt;item&gt;You will work closely with the F500 customers and the founding team. You will get to wear multiple hats from sales and marketing to recruiting.&lt;/item&gt;
          &lt;item&gt;Extreme ownership: you will own key part of Trellis business operations and have the opportunities to start new initiatives.&lt;/item&gt;
          &lt;item&gt;Be a part of a world-class team (e.g., team members have previously won the international physics olympiad, published economics research, were a founding engineer at Unicorn Startup, and taught AI classes to hundreds of Stanford graduate students).&lt;/item&gt;
          &lt;item&gt;To apply, please complete this take home and email the Github link with your code to founders[at]runtrellis.com. We will only be looking at completed take homes emailed to the address, so please make sure all requirements are met before submitting.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h2"&gt;Requirements&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Core Responsibilities: As an FDE, your role combines the technical depth of a senior engineer with the strategic thinking of a healthcare consultant. You'll work in small, autonomous teams with direct access to leadership and own end-to-end delivery of high-impact projects. Your day might include: &lt;list rend="ul"&gt;&lt;item&gt;Technical Implementation: Architecting and building custom AI workflows, integrating with EHR systems, and developing healthcare-specific data pipelines&lt;/item&gt;&lt;item&gt;Customer Collaboration: Working directly with clinical teams, operations managers, and C-suite executives to understand workflows and optimize outcomes&lt;/item&gt;&lt;item&gt;Data Engineering: Processing and structuring complex healthcare data, from clinical notes to insurance guidelines to lab results&lt;/item&gt;&lt;item&gt;Product Development: Building custom interfaces and tools that seamlessly integrate into existing healthcare workflows&lt;/item&gt;&lt;item&gt;Strategic Planning: Establishing implementation roadmaps and success metrics for large-scale healthcare transformation projects&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;p&gt;Trellis helps healthcare providers treat more patients, faster—while eliminating pre-service paperwork.&lt;/p&gt;
      &lt;p&gt;We automate document intake, prior authorizations, and appeals at scale to streamline operations and accelerate care.&lt;/p&gt;
      &lt;p&gt;Our AI agent is trained on millions of clinical data points and converts messy, unstructured documents into clean, structured data directly in your EHR.&lt;/p&gt;
      &lt;p&gt;With Trellis, leading healthcare providers and pharmaceutical companies were able to:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Reduce time to treatment by over 90%&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Improve prior authorization approval and reimbursement rates&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Leverage structured data to enhance drug program performance and clinical decision-making&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Administrative costs account for over 20% of U.S. healthcare spending—delaying care, draining revenue, and driving staff burnout while having less visibility into patient care than ever before. We built Trellis to tackle this head on.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/trellis/jobs/C0VryYb-forward-deployed-engineers-intern-august-2025"/><published>2025-09-27T12:00:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45395396</id><title>Samsung now owns Denon, Bowers and Wilkins, Marantz, Polk, and more audio brands</title><updated>2025-09-27T13:33:59.137462+00:00</updated><content>&lt;doc fingerprint="618c34d31b447bf"&gt;
  &lt;main&gt;
    &lt;p&gt;Samsung subsidiary Harman has completed its acquisition of Sound United, Masimo’s former audio business, adding a sizable expansion to Samsung’s audio brand portfolio. The $350 million deal was first announced in May, and brings Bowers &amp;amp; Wilkins, Denon, Marantz, Definitive Technology, Polk Audio, HEOS, Classé, and Boston Acoustics under the same roof as JBL, Harman Kardon, and other audio brands that Samsung acquired when it purchased Harman for $8 billion in 2016.&lt;/p&gt;
    &lt;head rend="h1"&gt;Samsung now owns Denon, Bowers &amp;amp; Wilkins, Marantz, Polk, and more audio brands&lt;/head&gt;
    &lt;p&gt;The Sound United portfolio will operate as a standalone business under Samsung’s audio empire.&lt;/p&gt;
    &lt;p&gt;The Sound United portfolio will operate as a standalone business under Samsung’s audio empire.&lt;/p&gt;
    &lt;p&gt;”Sound United’s impressive roster of brands is rooted in a deep passion for sound, innovation, and commitment to quality that aligns with Harman’s own values,” Harman’s lifestyle lead, Dave Rogers, said in a statement. “This transaction unlocks meaningful growth opportunities for everyone. It bolsters Harman’s strategy to build on its unparalleled success story and scale to unprecedented heights as an audio leader.”&lt;/p&gt;
    &lt;p&gt;Sound United will operate as a standalone business under Harman’s lifestyle division to ensure that each audio brand preserves its identity and customer base. With the sale now completed, Masimo can focus its attention on the Apple Watch lawsuit it launched against US Customs and Border Protection in August.&lt;/p&gt;
    &lt;head rend="h2"&gt;Most Popular&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;X-ray scans reveal the hidden risks of cheap batteries&lt;/item&gt;
      &lt;item&gt;Costco is already selling piles of Lego Game Boys cheaper than the Lego company&lt;/item&gt;
      &lt;item&gt;OpenAI really, really wants you to start your day with ChatGPT Pulse&lt;/item&gt;
      &lt;item&gt;It costs $895 per year to get American Express’ premium app theme&lt;/item&gt;
      &lt;item&gt;A $1,000 Xbox Ally handheld tests the appetite for pricey next-gen consoles&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/784390/samsung-harman-masimo-audio-acquisition-complete"/><published>2025-09-27T13:05:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45395428</id><title>Show HN: I spent 4 months building Duolingo but for your life</title><updated>2025-09-27T13:33:58.603196+00:00</updated><content>&lt;doc fingerprint="26b05a1d1d4d2629"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Your days are slipping away. Take them back.&lt;/head&gt;
    &lt;head rend="h2"&gt;Daily journal, habits &amp;amp; tasks app that actually works&lt;/head&gt;
    &lt;p&gt;Built by someone who tried everything else first&lt;/p&gt;
    &lt;head rend="h2"&gt;One app. Three things. Actually stick to it.&lt;/head&gt;
    &lt;p&gt;The only productivity system you'll actually use every day&lt;/p&gt;
    &lt;head rend="h3"&gt;Journal&lt;/head&gt;
    &lt;p&gt;Two questions. One minute.&lt;lb/&gt;Finally understand what makes you tick.&lt;/p&gt;
    &lt;head rend="h3"&gt;Habits&lt;/head&gt;
    &lt;p&gt;One tap tracking. Addictive heatmaps.&lt;lb/&gt;Watch your streak grow.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tasks&lt;/head&gt;
    &lt;p&gt;Zero fluff. Just what matters.&lt;lb/&gt;Get stuff done, not organized.&lt;/p&gt;
    &lt;head rend="h2"&gt;What actual users say&lt;/head&gt;
    &lt;p&gt;"I've tried everything. Notion for journaling, Todoist for tasks, random habit apps. This is the first app that's minimal and has everything I need to build my dream life. I actually use it every day."&lt;/p&gt;
    &lt;p&gt;Mags, Software Engineer&lt;/p&gt;
    &lt;p&gt;"Finally. An app that doesn't try to do everything. Clean design, works perfectly, does exactly what it promises. I'm genuinely happy I found this."&lt;/p&gt;
    &lt;p&gt;Mabroor&lt;/p&gt;
    &lt;head rend="h2"&gt;Ready to get your life together?&lt;/head&gt;
    &lt;p&gt;stop app-hopping and started building better habits&lt;/p&gt;
    &lt;p&gt;Free to start â¢ Available on iPhone&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://three-cells.com"/><published>2025-09-27T13:10:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45395499</id><title>The Other Linux Logo</title><updated>2025-09-27T13:33:57.970359+00:00</updated><content>&lt;doc fingerprint="3d3b25dbd995bcab"&gt;
  &lt;main&gt;
    &lt;p&gt;Hi Linux lovers, feel free to share, use and edit this Linux logo we have designed for you.&lt;/p&gt;
    &lt;p&gt;After seeing to your reactions on Reddit and omg! ubuntu!, we added some new options for wider usecases.&lt;/p&gt;
    &lt;p&gt;Create and download your own version of Tux:&lt;/p&gt;
    &lt;p&gt;The good old Tux logo is really cool, we love and use it but a simple and efficient logo to identify Linux is missing. The Other Linux Logo is more icon-friendly and adapted to small sizes. Also, we want people to have the choice when it comes to picture the awesomeness of Linux!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ecogex.com/the-other-linux-logo/"/><published>2025-09-27T13:19:57+00:00</published></entry></feed>