<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-21T19:32:29.802161+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45319690</id><title>iFixit iPhone Air teardown</title><updated>2025-09-21T19:32:38.847513+00:00</updated><content>&lt;doc fingerprint="b569c1074bc717dd"&gt;
  &lt;main&gt;
    &lt;p&gt;To be honest, we were holding our breath for the iPhone Air. Thinner usually means flimsier, harder to fix, and more glued-down parts. But the iPhone Air proves otherwise. Apple has somehow built its thinnest iPhone ever without tanking repairability.&lt;/p&gt;
    &lt;p&gt;Just a few months ago, Samsung’s Galaxy S25 Edge pulled off a similar trick in an ultra-thin package. How’d they do it? And how’d Apple follow suit?&lt;/p&gt;
    &lt;p&gt;The secret: Thinner can actually be more repairable, with clever design.&lt;/p&gt;
    &lt;head rend="h2"&gt;Clever Use of Space&lt;/head&gt;
    &lt;p&gt;Apple made one huge design shift in the Air, which they teased in their keynote and we confirmed with our Lumafield Neptune CT scanner: The middle of this phone is basically just a battery with a frame around it. Apple popped the logic board up above the battery, a large part of how their design got thinner without compromising repair.&lt;/p&gt;
    &lt;p&gt;When we score repairability, 80% of our score is determined by the ease of replacing the parts that are most important and most likely to break. To figure this out, we build a model of the repair process. What’s the path you have to take to get to the battery, or to the screen? We call this the “disassembly tree.” The ideal (if unlikely) disassembly tree is flat. No parts in the way of other parts.&lt;/p&gt;
    &lt;p&gt;A thin device often means, advantageously, a flat disassembly tree. Stacked parts are thicker than parts side-by-side. Our friends over at Framework have been saying this for a long time: It’s totally possible to make a thin and light device that’s also built for repair. The Framework Laptop has done this from the start, with nearly all major components accessible when you remove the cover.&lt;/p&gt;
    &lt;p&gt;And that’s exactly what we’re seeing in the Air. The logic board shift freed up room for the battery and helped the phone stay thin without cramming parts on top of each other. It also conveniently puts less stress on the board if the phone flexes in your pocket. It’s a smart workaround for the “bendgate” problems that haunted earlier slim iPhone designs. Not that the Air’s really going to be bending much, as Zack’s test at Jerry Rig Everything suggests.&lt;/p&gt;
    &lt;p&gt;(By the way, did you see we’re teaming up with Zack to bring you a toolkit that’s made for on-the-go repairs and durability testing?)&lt;/p&gt;
    &lt;p&gt;The Air trims a few extras compared to the Plus line it succeeds, losing the lower speaker and a rear camera. Like the 16e, it’s got just a single rear camera.&lt;/p&gt;
    &lt;p&gt;Inside, though, it packs the upgraded C1X modem, a new N1 WiFi chip, and the A19 Pro system-on-chip, all tucked into the logic board sandwich. It’s a lean, efficient setup that makes the most of limited space. This reduced complexity also contributes to quicker disassembly—fewer features, fewer parts, and fewer points of failure.&lt;/p&gt;
    &lt;head rend="h2"&gt;Battery Life? Eh. Battery Swaps? No Big Deal&lt;/head&gt;
    &lt;p&gt;There’s been a lot of buzz about battery life on this phone. Apple said “all-day battery life,” and tech reviewers of the world, noting the lack of watt-hour specificity and immediate announcement of an add-on battery pack, said, “really now?” At 12.26 Wh, this battery is certainly smaller than recent iPhones (closest comparison being the 13 Pro’s 11.97 Wh), and that raises questions about longevity. More charging cycles usually means faster wear. Still, Apple’s efficiency tricks give it solid runtime, at least for now.&lt;/p&gt;
    &lt;p&gt;But no battery lasts forever, so how difficult will swaps be? We’re relieved to see that the Air has all the greatest hits of the last few iPhone battery designs.&lt;/p&gt;
    &lt;p&gt;The Air’s battery is easy to find and accessible through the back glass thanks to Apple’s dual entry design. Even better, it’s a metal-encased battery. This thin layer of armor makes it more bend resistant and safer to replace. Even better than that, it’s mounted with electrically debonding adhesive strips. Hook them up to a power source and the battery lifts right out, no dangerous prying required. We used our FixHub Portable Power Station for an easy 12 V, and each strip freed after about 70 seconds.&lt;/p&gt;
    &lt;p&gt;Even though it’s comparably a small battery, its heft accounts for 28% of the phone’s total weight, more than any other component.&lt;/p&gt;
    &lt;p&gt;And in a fun twist, we’ve confirmed that it’s the exact same cell found in Apple’s MagSafe battery pack. You can swap between them and the phone still boots up just fine. Like a rear-mounted spare tire on an SUV, an iPhone Air with a MagSafe battery pack is ready for an on-the-go swap, if you will. Granted it’ll take a bit more than a tire iron to make it happen.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular Port, but How About Parts to Back It Up?&lt;/head&gt;
    &lt;p&gt;How about other likely-to-fail parts? USB-C ports are among the most common failure points in modern phones. Ports tend to collect moisture, which can cause corrosion, and no one is immune to pocket lint. Not to mention the standard port problems caused by mechanical wear and tear.&lt;/p&gt;
    &lt;p&gt;Now, to be clear, if your phone stops charging consistently, you shouldn’t jump straight to replacing the port. Every time you stick a charge cable into the port, you’re jamming pocket lint against the back. Give your charge port a cleanout before you replace it.&lt;/p&gt;
    &lt;head rend="h3"&gt;How to Clean the Ports on your Electronic Device&lt;/head&gt;
    &lt;p&gt;Use this guide to clean the ports on your…&lt;/p&gt;
    &lt;p&gt;But when you do need to replace an Air charging port, you’ll be glad to know it’s decently modular, following the trend of the last few iPhone models. It’s a tedious process, with delicate flex cables, adhesive, and hard-to-reach screws, but it’s still feasible.&lt;/p&gt;
    &lt;p&gt;Interestingly, the modularity of the USB-C port doesn’t seem to be a serviceability choice. Apple won’t do USB-C repairs in-house and they don’t sell replacement ports for iPhones. Of course that won’t stop us from selling the parts as soon as we can get them—and regardless of intent, this modularity is nice to have.&lt;/p&gt;
    &lt;p&gt;Third-party parts manufacturers may take a bit to catch up, since this is a brand new architecture for the housing of the USB port. Apple reportedly used 3D printing to shrink the housing to fit the slim frame of the 6.5mm iPhone Air.&lt;/p&gt;
    &lt;p&gt;Apple says this process reduced material usage by 33% compared to conventional forging processes. Granted, the USB-C port is already tiny. But this isn’t the only place they’re using it: The Apple Watch Ultra 3 uses the same titanium-printing process in its case.&lt;/p&gt;
    &lt;p&gt;We took a close look at the titanium material in the USB-C port, with our Evident DSX2000 microscope.&lt;/p&gt;
    &lt;p&gt;What we saw was fascinating: these regular bubble-like structures.&lt;/p&gt;
    &lt;p&gt;We tapped in some friends in the additive manufacturing industry, who said it wasn’t quite like any metal 3D printing they’d seen before. Their best guess is that Apple’s using a binder or aerosol jet process in addition to some after-printing machining. This aligns with a binder jetting patent Apple inherited back in 2015 when they acquired Metaio. Whatever the exact process, the result is some truly impressive titanium manipulation.&lt;/p&gt;
    &lt;p&gt;(If you’re a metal 3D printing expert and want to give us your thoughts in the comments, we’d love to hear from you!)&lt;/p&gt;
    &lt;head rend="h2"&gt;How Strong Is Thin?&lt;/head&gt;
    &lt;p&gt;Titanium may have retired from the rest of the iPhone line (possibly for geopolitical more than technical reasons) but it’s back as the backbone of this slim smartphone. This tough metal is a good choice, but it’s only as strong as its weak points. Our empty-frame bend test snapped the Air at its plastic antenna passthroughs—a necessity if you want your phone to phone properly. CT scans make it clear: Apple reinforced the center section, but the top and bottom remain vulnerable.&lt;/p&gt;
    &lt;p&gt;Of course, the center is where the phone is most likely to bend, and so far testing hasn’t given any indication of undue flexibility. Will that design affect the durability of the phone? We doubt we’ll see instances of Airs snapping at the ends, but only time will tell.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Verdict: A 7 out of 10 Repairability Score&lt;/head&gt;
    &lt;p&gt;At 6.5 mm, the Air is a hair thinner than Samsung’s Galaxy S25 Edge, yet it manages to keep modular parts and early battery access. Apple’s dual entry design makes battery swaps simple and keeps the fancy OLED out of harm’s way. Electrically debonding adhesive makes battery replacements a lot more consistent than traditional or stretch-release adhesive, and most other major components are simple to access and remove. Apple also kept their best-in-class clipped- and screwed-in screen and back glass architecture, enabling quick reassembly without requiring special adhesive.&lt;/p&gt;
    &lt;p&gt;Combined with Apple’s continued commitment to day-one repair manuals, the iPhone Air earns a provisional 7 out of 10 repairability score. (We’re waiting on Apple to make good on their parts availability commitment as well as final results on our parts pairing tests. Their recent track record’s pretty good, though.)&lt;/p&gt;
    &lt;p&gt;Apple has proved that thin doesn’t have to mean unfixable. The iPhone Air is slimmer than any iPhone before it, but its layout and design tradeoffs make repairs more approachable, not less. It still has limits, but the design shows that good engineering can make even the slimmest devices last longer in the real world. Successful field test for your new foldable, Apple. We’re onto you!&lt;/p&gt;
    &lt;p&gt;More Apple 2025 lineup teardowns coming soon. Bonus round: Can TechWoven handle… hot sauce?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ifixit.com/News/113171/iphone-air-teardown"/><published>2025-09-21T03:09:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45319876</id><title>Spectral Labs releases SGS-1: the first generative model for structured CAD</title><updated>2025-09-21T19:32:38.551411+00:00</updated><content>&lt;doc fingerprint="a55b8b523846d2a2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing SGS-1&lt;/head&gt;
    &lt;p&gt;Spectral Labs releases SGS-1: the first generative model for structured CAD.&lt;/p&gt;
    &lt;p&gt;Today we are announcing SGS-1, a foundation model that can generate fully manufacturable and parametric 3D geometry. You can try a research preview of SGS-1 here.&lt;/p&gt;
    &lt;p&gt;Given an image or a 3D mesh, SGS-1 can generate CAD B-Rep parts in STEP format. Unlike all other existing generative models, SGS-1 outputs are accurate and can be edited easily in traditional CAD software.&lt;/p&gt;
    &lt;p&gt;Overview of SGS-1 - users can provide an image or “dumb” 3D file, and get back a parametric B-Rep file that can be easily edited to match specific dimensions&lt;/p&gt;
    &lt;p&gt;SGS-1 shows strong general results, producing much more complex and diverse CAD shapes than existing methods.&lt;/p&gt;
    &lt;p&gt;Illustrative results from SGS-1&lt;/p&gt;
    &lt;p&gt;SGS-1 can be used for real-world engineering tasks. In the below example, SGS-1 is used to design a bracket for a roller assembly from partial context and a text description (additional details below in Generating Parametric Geometry in Assembly Context section).&lt;/p&gt;
    &lt;head rend="h2"&gt;Results and comparing SGS-1 to prior models&lt;/head&gt;
    &lt;p&gt;We compare SGS-1 to SOTA multimodal reasoning LLMs and open-source image-to-CAD models: GPT-5 thinking, a large reasoning model by OpenAI that can produce CadQuery code to represent parametric geometry, and HoLa, a 205M parameter latent diffusion model with 181M parameter VAE that generate B-Rep geometry conditioned on a single input image. We develop a benchmark set of 75 images depicting medium to high complexity parametric geometry, sourced from CAD image renders of various styles, engineering sketches, and images generated by generative AI models. Model performance is evaluated by successful/failed creation of a single valid watertight solid that is an accurate representation of the input image using distance metrics (Success Ratio).&lt;/p&gt;
    &lt;p&gt;Quantitative evaluations&lt;/p&gt;
    &lt;p&gt;We run each model 10 times and show scores for all 10 runs, as well as for the best output of the 10. Although GPT-5 and HoLa BRep can attain non-zero performance on the easiest images, SGS-1 is the best performing model with at least one success for all but the most complex objects.&lt;/p&gt;
    &lt;p&gt;Outputs from the SOTA large reasoning model (GPT-5) demonstrate a clear lack of spatial understanding, producing outputs that are unusable or too simple to actually be useful. We use both SGS-1 and GPT-5 to generate the parametric geometry for the rail mount from the input image, in order to produce the desired target complete assembly.&lt;/p&gt;
    &lt;p&gt;SGS-1 accurately represents the geometry and can be plugged into an assembly context, while the output from the large reasoning model is missing core spatial features.&lt;/p&gt;
    &lt;head rend="h2"&gt;Generating Parametric Geometry in Assembly Context&lt;/head&gt;
    &lt;p&gt;With SGS-1, you can create new parametric geometry within your current assembly context. In this example, SGS-1 takes in a partial CAD assembly and a text description/image of a bracket, and produces a 3D design for a bracket that is feasible for the context.&lt;/p&gt;
    &lt;p&gt;First, render the partial assembly and come up with a text description of the parts you want to add. Next, run it through SGS-1, which will output a parametric B-Rep in the form of a downloadable STEP fileFinally, import the STEP file into your partial assembly and adjust dimensions until the part fits correctly into the assembly&lt;/p&gt;
    &lt;p&gt;SGS-1 is capable of generating diverse designs for tasks like this - several bracket designs created by SGS-1 are shown below:&lt;/p&gt;
    &lt;head rend="h2"&gt;Converting Sketches and Engineering Drawings to B-Rep&lt;/head&gt;
    &lt;p&gt;SGS-1 can be used to convert simple freehand sketches and engineering drawings into geometry that you can work in in your CAD editor. In this example, we run sketches and drawings through SGS-1 to create parametric geometry.&lt;/p&gt;
    &lt;p&gt;Use SGS-1 to transform sketches and drawings into 3D CAD files&lt;/p&gt;
    &lt;p&gt;This works well on simple hand sketches, enabling powerful design workflows.&lt;/p&gt;
    &lt;p&gt;This also works on structured engineering drawings.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automating Reverse Engineering and STL to STEP File Conversion&lt;/head&gt;
    &lt;p&gt;SGS-1 can be used to convert scans and standalone STL or other mesh files to parametric STEP files without any human input, automating reverse engineering of many shapes.&lt;/p&gt;
    &lt;p&gt;Use SGS-1 to convert dumb 3D representations to parametric geometry&lt;/p&gt;
    &lt;head rend="h2"&gt;Limitations&lt;/head&gt;
    &lt;p&gt;SGS-1 is designed to generate parametric 3D geometry for engineering use cases, and struggles when tasked with generating creative assets and organic shapes with complex curvature. In addition, SGS-1 has a limited 3D resolution and struggles with generating very thin structures. Finally, SGS-1 cannot create full assemblies in one shot. We plan to address these limitations with our next model generation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next Steps&lt;/head&gt;
    &lt;p&gt;SGS-1 represents a significant step forward for foundation models that can generate 3D geometry for engineering tasks. We plan to continue pushing forward the frontier, by training models that can engineer physical systems of increasing complexity. The next generation of models will be natively multimodal, support larger and more complex spatial context, and will be capable of performing more advanced physical reasoning through longer range planning. As we continue to scale up these models, we are excited about scaling up reinforcement learning using physical simulation feedback, which will unlock new physical reasoning capabilities for our models.&lt;/p&gt;
    &lt;p&gt;If you are interested in deploying SGS-1 or collaborating on research, please contact us through this form.&lt;/p&gt;
    &lt;p&gt;We are also hiring! Our team is composed of top AI researchers and engineers with previous experience at institutions such as Autodesk Research, Samsung Research, CMU, and Meta. If you're interested in our work and mission, please get in touch.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.spectrallabs.ai/research/SGS-1"/><published>2025-09-21T03:46:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45322050</id><title>Meta exposé author faces bankruptcy after ban on criticising company</title><updated>2025-09-21T19:32:38.408150+00:00</updated><content>&lt;doc fingerprint="2ea8491b1aa230fe"&gt;
  &lt;main&gt;
    &lt;p&gt;A former Meta executive who wrote an explosive exposé making allegations about the social media company’s dealings with China and its treatment of teenagers is said to be “on the verge of bankruptcy” after publishing the book.&lt;/p&gt;
    &lt;p&gt;An MP has claimed in parliament that Mark Zuckerberg’s company was trying to “silence and punish” Sarah Wynn-Williams, the former director of global public policy at Meta’s precursor, Facebook, after her decision to speak out about her time at the company.&lt;/p&gt;
    &lt;p&gt;Louise Haigh, the former Labour transport secretary, said Wynn-Williams was facing a fine of $50,000 (£37,000) every time she breached an order secured by Meta preventing her from talking disparagingly about the company.&lt;/p&gt;
    &lt;p&gt;Wynn-Williams made a series of claims about the social media company’s behaviour and culture in her book Careless People, published this year. It also contained allegations of sexual harassment denied by the company. It states she was fired for “poor performance and toxic behaviour”.&lt;/p&gt;
    &lt;p&gt;However, the former diplomat was barred from publicising the memoir after Meta, which owns Facebook and Instagram, secured a ruling preventing her from doing so. She subsequently appeared before a US Senate judiciary subcommittee, in which she said Meta worked “hand in glove” with Beijing over censorship tools – something the company has denied.&lt;/p&gt;
    &lt;p&gt;Pan Macmillan, which published the memoir, said it had sold more than 150,000 copies across all formats. The book was also named in The Sunday Times‘ bestselling hardbacks of 2025 so far. The paperback edition is due to be published early next year.&lt;/p&gt;
    &lt;p&gt;New York magazine has previously reported that Wynn-Williams was paid an advance for the book of more than $500,000 (£370,000).&lt;/p&gt;
    &lt;p&gt;Haigh highlighted Wynn-Williams’s case in the House of Commons during a debate about employment rights on Monday. She said Wynn-Williams’s decision to speak out had plunged her into financial peril.&lt;/p&gt;
    &lt;p&gt;“Despite previous public statements that Meta no longer uses NDAs [non-disclosure agreements] in cases of sexual harassment – which Sarah has repeatedly alleged – she is being pushed to financial ruin through the arbitration system in the UK, as Meta seeks to silence and punish her for speaking out,” she said.&lt;/p&gt;
    &lt;p&gt;“Meta has served a gagging order on Sarah and is attempting to fine her $50,000 for every breach of that order. She is on the verge of bankruptcy. I am sure that the whole house and the government will stand with Sarah as we pass this legislation to ensure that whistleblowers and those with the moral courage to speak out are always protected.”&lt;/p&gt;
    &lt;p&gt;It is understood that the $50,000 figure represents the damages Wynn-Williams has to pay for material breaches of the separation agreement she signed when she left Meta in 2017. Meta has emphasised that Wynn-Williams entered into the non-disparagement agreement voluntarily as part of her departure.&lt;/p&gt;
    &lt;p&gt;Meta said that to date, Wynn-Williams had not been forced to make any payments under the agreement.&lt;/p&gt;
    &lt;p&gt;The company did not wish to comment on Haigh’s intervention. It has previously said that Wynn-Williams’s Senate testimony was “divorced from reality and riddled with false claims” about China and the company’s treatment of teenagers.&lt;/p&gt;
    &lt;p&gt;Meta has described the book as a “mix of out-of-date and previously reported claims about the company and false accusations about our executives”. It has said she was fired for “poor performance and toxic behaviour” and that an investigation concluded she made misleading and unfounded allegations of harassment.&lt;/p&gt;
    &lt;p&gt;It said the ruling preventing her from publicising the memoir confirmed the “false and defamatory book should never have been published”.&lt;/p&gt;
    &lt;p&gt;The ruling stated Wynn-Williams should stop promoting the book and, to the extent she could, stop further publication. It did not order any action by Pan Macmillan.&lt;/p&gt;
    &lt;p&gt;Wynn-Williams has not spoken in public since appearing at the Senate hearing in April. In a written statement this month, she said she was grateful that the US Senate was continuing to investigate Meta’s behaviour.&lt;/p&gt;
    &lt;p&gt;“I wish I could say more,” she said. “I urge other tech employees and those who are thinking of whistleblowing to share what they know before more children are harmed.”&lt;/p&gt;
    &lt;p&gt;Her lawyer confirmed Wynn-Williams “remains silenced about the very matters Congress is investigating, despite clear and unanimous voices from Congress calling on Meta to end their arbitration proceedings which threaten to bankrupt her”.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/technology/2025/sep/21/meta-expose-author-sarah-wynn-williams-faces-bankruptcy-after-ban-on-criticising-company"/><published>2025-09-21T12:15:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45322623</id><title>Disk Utility still can't check and repair APFS volumes and containers (2021)</title><updated>2025-09-21T19:32:38.239286+00:00</updated><content>&lt;doc fingerprint="a711dd1523b6157c"&gt;
  &lt;main&gt;
    &lt;p&gt;Checking and repairing disks is one of the more important tasks performed by Disk Utility, but ever since the introduction of APFS, it has been more fraught than it should have been. One of its most persistent and pervasive problems has been complete failure because Disk Utility has been unable to unmount volumes or containers. To my shock, in Monterey 12.0.1 this problem appears worse than ever, and I now have one disk which Disk Utility is completely unable to check or repair. This article suggests ways around this, while we wait for Apple to fix this bug.&lt;/p&gt;
    &lt;p&gt;For much of this period, the First Aid tool in Disk Utility has relied on the command tool &lt;code&gt;fsck_apfs&lt;/code&gt; to do the work, calling it using two options, &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt;. The &lt;code&gt;y&lt;/code&gt; option simply agrees to make all the repairs suggested by the tool, but the &lt;code&gt;x&lt;/code&gt; option is private. I suspect that privacy isn’t sinister, merely allowing communication between the tool and app using XPC.&lt;/p&gt;
    &lt;p&gt;Best practice for performing disk checks and repairs like this isn’t with a live file system, and those options won’t work when the item being checked is still mounted. So to prepare for the call to &lt;code&gt;fsck_apfs&lt;/code&gt;, Disk Utility has to unmount the volume or container, and that’s the step which appears to go awry.&lt;/p&gt;
    &lt;p&gt;In Catalina and Big Sur, the error reported was confusing, and the recommendation to “back up the data on this volume” inappropriate. It would have been far better if Disk Utility had told us honestly that “this is a known bug, and some day we might get round to fixing it.”&lt;/p&gt;
    &lt;p&gt;That some day clearly hasn’t come in Monterey 12.0.1. When I was researching yesterday’s article about how to check Time Machine backup volumes, it hit me again and again, so I went back and had a closer look at what now goes wrong, and what to do about it.&lt;/p&gt;
    &lt;p&gt;This may happen persistently when you try to check and repair an APFS volume.&lt;/p&gt;
    &lt;p&gt;It can also happen every time with an APFS container.&lt;/p&gt;
    &lt;p&gt;Oddly, though, it doesn’t seem to affect HFS+ volumes.&lt;/p&gt;
    &lt;p&gt;One way around this is to cave in, start up in Recovery, and use Disk Utility there, where there’s no excuse for problems unmounting anything. If you’re intending to check and repair the boot volume group (System and/or Data) then this is the preferred way. macOS does now provide a good means of ‘freezing’ file system access if you do try that when running in normal user mode, but Recovery is always better.&lt;/p&gt;
    &lt;p&gt;The best news of all is that you can still use the command tool &lt;code&gt;fsck_apfs&lt;/code&gt; directly, and work around this bug in Disk Utility. The bizarre twist is that you can use Disk Utility’s Unmount tool to unmount volumes and containers which the app itself appears unable to unmount successfully. Here’s a summary of the process:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;In Disk Utility (or Terminal) obtain the device name of the APFS container or volume you want to check. In this case, I’ll use &lt;code&gt;disk7s2&lt;/code&gt;, which is the sort of volume name you’re looking for, or&lt;code&gt;disk7&lt;/code&gt;for a container.&lt;/item&gt;
      &lt;item&gt;In Disk Utility (or Terminal) unmount the container or volume, by selecting it and clicking on the Unmount tool. When you’re checking a container, it’s best to unmount each of its volumes before unmounting the container itself.&lt;/item&gt;
      &lt;item&gt;Open Terminal and type the chosen command with the correct device name. Then enter your admin user’s password at the prompt.&lt;/item&gt;
      &lt;item&gt;Watch as the volume or container is checked.&lt;/item&gt;
      &lt;item&gt;Once that has completed, consider whether the container or volume needs any repair using &lt;code&gt;fsck_apfs&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;In Disk Utility (or Terminal) mount the container or volume again, by selecting it and clicking on the Mount tool.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The command to use depends on whether you just want to check the item, or repair it as well. For the former, use the &lt;code&gt;-n&lt;/code&gt; option, and for the latter the &lt;code&gt;-y&lt;/code&gt; option will perform all repairs automatically. I advise you to include all snapshots, which are important, but if you want to exclude them all, use the &lt;code&gt;-S&lt;/code&gt; option.&lt;/p&gt;
    &lt;p&gt;If the volume is encrypted, you could keep it mounted and use the &lt;code&gt;-l&lt;/code&gt; option to check the live file system, or you can use a command like&lt;code&gt;diskutil apfs unlockVolume /dev/disk7s2 -nomount&lt;/code&gt;&lt;lb/&gt; to unlock the volume without mounting it (thanks to kapitainsky for suggesting that).&lt;/p&gt;
    &lt;p&gt;For example, choose between the commands:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;sudo fsck_apfs -n /dev/disk7s2&lt;/code&gt;just to check the volume disk7s2 but not repair it, and include snapshots.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sudo fsck_apfs -y /dev/disk7s2&lt;/code&gt;to check and repair all errors automatically, and include snapshots.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sudo fsck_apfs -n -S /dev/disk7s2&lt;/code&gt;to check but not repair, but excluding all snapshots.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sudo fsck_apfs -n -S /dev/disk7&lt;/code&gt;to check but not repair the container disk7, excluding all snapshots.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can find details of all available options in &lt;code&gt;man fsck_apfs&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Apple recommends that you first check and repair volumes within a container, then the container itself, and finally the disk (which you can do completely within Disk Utility). That is oddly the exact opposite order previously recommended by many, and duplicates checks on volumes which are normally repeated when you check their container.&lt;/p&gt;
    &lt;p&gt;The disk which I have such problems with is a little unusual in that it’s partitioned into two: a small HFS+ volume, and a much larger APFS container. The irony is that Disk Utility’s advice to back up the affect volume is being offered for my Time Machine backup, which is not only a backup volume itself, but can’t be backed up because its backup snapshots can’t be copied to another disk.&lt;/p&gt;
    &lt;p&gt;It will be so good when Apple finally sorts these problems we’ve suffered for the last four years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eclecticlight.co/2021/11/19/disk-utility-still-cant-check-and-repair-apfs-volumes-and-containers/"/><published>2025-09-21T13:37:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45322819</id><title>I forced myself to spend a week in Instagram instead of Xcode</title><updated>2025-09-21T19:32:37.897203+00:00</updated><content>&lt;doc fingerprint="3bcc78561ea6cefc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I forced myself to spend a week in Instagram instead of Xcode&lt;/head&gt;
    &lt;head rend="h3"&gt;This is what happens when you ban yourself from coding&lt;/head&gt;
    &lt;head rend="h4"&gt;Let’s set the stage:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The Lagree Buddy app has enough quality features that this is an actual, useful thing that I feel comfortable promoting &amp;amp; charging money for.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are more features I want to build, but they’re bigger features and are still weeks from releasing (because I need to QA them in the real world).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Since the hard paywall and overhauled onboarding (discussed here), there has been a noticeable increase in purchases (woohoo! see chart below)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Given the information above, I figured I should try an experiment.&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;What if I spent every business hour on marketing/distribution instead of coding and building more features?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That felt so uncomfortable to even say out loud because it meant spending a week on social media and talking to people about the app. But it also meant not hiding inside the code.&lt;/p&gt;
    &lt;p&gt;So here’s a detailed (but slightly stream of consciousness) recap of how that week went.&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 1 || Monday, August 25th&lt;/head&gt;
    &lt;p&gt;If any influencers out there want to give me some tips on how to IG correctly, please do. But my current thought process is to craft a story arc for one day. And then to break that arc into 4-6 posts, to be posted every 3 hours or so.&lt;/p&gt;
    &lt;p&gt;I do this because I don’t want it to feel salesy or spammy. So I at least inject some sort of narrative. So today’s story arc was:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Working on new feature at home, but oh no! it’s broken!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Thought I fixed it and took it to class, but oh no! still broken!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I found out why it was broken, explained it, and took it into another class …&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FIXED.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FIXED 2.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;FIXED 3.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also spent the day reaching out to new studios &amp;amp; trainers I saw wearing Apple Watches. Sent out 10 today and got 2 responses.&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 2 || Tuesday, August 26th&lt;/head&gt;
    &lt;p&gt;I bought a Microformer last week, so let’s use the thing for some content!&lt;/p&gt;
    &lt;p&gt;I signed up for Lagreeing at Home, found an instructor with an Apple Watch, snapped a lot of photos, and got busy creating and scheduling another story arc.&lt;/p&gt;
    &lt;p&gt;I almost immediately got a response from Lagreeing at Home about collabing, and I’d have to say… that’s a pretty big win. Lagreeing at Home was born out of the pandemic and has been an incredible presence in the Lagree community, so hearing some affirmation from them is a fantastic feeling.&lt;/p&gt;
    &lt;p&gt;I wanted to do more cold DM’s to studios and trainers today, too, but sometimes the Apple Gods say “try again tomorrow” (wheel of death! see below).&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 3 || Wednesday, August 27th&lt;/head&gt;
    &lt;p&gt;It’s only been two days, but I’ve been struggling with the actual creation of content itself. Struggling might be the wrong word… underestimate? I underestimated the amount of work it takes!&lt;/p&gt;
    &lt;p&gt;I planned everything out on Monday. But then you have to obviously create the stuff, and all of that takes so long! So today, today is going to be an FAQ series. But the question is how to create it creatively so it’s not just social media slop.&lt;/p&gt;
    &lt;p&gt;And after playing with a basic Q&amp;amp;A and not liking how it looked (aka ugly and sales-y) ... I went hunting on Reddit and found this incredible tool (Postfully) to create fake text messages and came up with this for my Q&amp;amp;A instead:&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 4 || Thursday, August 28th&lt;/head&gt;
    &lt;p&gt;I signed up for THE Sebastian Lagree’s class on Sunday. Three reasons why:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;I want to show him the app in person&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I’m running out of content and I need some photos of a new studio 😅&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I’m getting sick of social media and wanted to do something in real life loll&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I needed a break from creating content, so I cheated and repurposed my IG stories into TikTok videos. But I didn’t want to give up on my mission, so I fell back on cold messaging studios and trainers.&lt;/p&gt;
    &lt;p&gt;Getting any response is a nice feeling, but this message back from new studio Hold Fitness was incredible! She saw my original post on Reddit from 6 months ago!&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 5 || Friday, August 29th&lt;/head&gt;
    &lt;p&gt;I am absolutely ITCHING to get back to the code!!&lt;/p&gt;
    &lt;p&gt;But I am trying to stick to my mission for the week and am racking my brain on what content to come up without sounding repetitive or spammy. Thank goodness I went to class yesterday and took a bunch of b-roll footage because an idea quickly formed that felt different enough from everything before it this week.&lt;/p&gt;
    &lt;p&gt;This might have been the hardest day to stick to this challenge. Because everything inside of me was screaming:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“CAN WE FOR THE LOVE OF GOD GET OFF OF SOCIAL MEDIA AND DO SOMETHING PRODUCTIVE LIKE BUILD MORE FEATURES.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But the thing that I had to constantly remind myself of is that this is productive.&lt;/p&gt;
    &lt;p&gt;Build it and they will come is a fallacy.&lt;/p&gt;
    &lt;p&gt;You have to tell people about the damn thing. It just doesn’t feel productive because you’re over here churning and burning things that feel like they have a shelf-life of 24 hours (if even that). And sending out cold DM’s and hoping for 1 or 2 responses.&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 6 || Saturday, August 30th&lt;/head&gt;
    &lt;p&gt;Day of rest. &lt;lb/&gt;Sorry, not sorry.&lt;lb/&gt;But I did not code, so the challenge is still intact.&lt;/p&gt;
    &lt;head rend="h4"&gt;Day 7 || Sunday August 31th&lt;/head&gt;
    &lt;p&gt;Sebastian Lagree day!!&lt;/p&gt;
    &lt;p&gt;I drove to Brentwood to take a class from SEBASTIAN LAGREE himself. I was pretty nervous because I wasn’t sure if he was going to think my app was stupid or if it was weird, but he honestly couldn’t have been nicer.&lt;/p&gt;
    &lt;p&gt;He’s also an insanely good instructor, which seems obvious, but when you only see someone on IG as an “influencer”, you’re not entirely sure what to expect.&lt;/p&gt;
    &lt;p&gt;But his class was f-ing legit. But be warned, it may or may not be 60 minutes long 😂. Most classes I’ve taken are 45 minutes, but if you like to get there early (like I do), he will start the class early and end the class late and have you BURNING. My max HR hit 172, and I was sore for a week.&lt;/p&gt;
    &lt;p&gt;It was excellent.&lt;/p&gt;
    &lt;p&gt;I also had an entire plan of going home and editing/posting the content from this day, but like I said, I was sore for a week. So, the immediate aftermath of this class was me just lying down on the couch. No content was edited, posted, or thought about for the rest of the day loll.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Footnote: Because I’m always looking at people’s wrists for Apple Watches in class now, I couldn’t help but notice the lady next to me. Most people wear a fitness tracker in class or nothing at all. But this lady next to me was rocking this:&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;End of Week Results &amp;amp; Takeaways&lt;/head&gt;
    &lt;p&gt;Cold DMs actually work (sometimes). I sent maybe 30-40 messages total and got 4-5 meaningful responses. That's not amazing, but it's infinitely better than the zero responses you get when you never reach out at all.&lt;/p&gt;
    &lt;p&gt;Marketing opens doors that code never could. Sebastian seeing my app in person matters more than any feature I could have shipped that week. You can't build your way into someone's awareness - you have to actually show up.&lt;/p&gt;
    &lt;p&gt;You can't analytics your way to relationships. The numbers didn't move (see chart below), but the connections did. Having Lagreeing at Home and Sebastian Lagree be aware of the app and the person behind the app should pay dividends in the future.&lt;/p&gt;
    &lt;p&gt;Content creation is way harder than I thought. As an engineer, I assumed making an Instagram story would take 10 minutes. Turns out creating something that doesn't look like garbage takes a couple of hours. And doing it daily? Forget about it. I planned a whole week of content on Monday and ended up creating everything day-of because I completely underestimated the work involved.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.pixelpusher.club/p/i-forced-myself-to-spend-a-week-in"/><published>2025-09-21T14:00:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45322992</id><title>Extrachromosomal DNA–Driven Oncogene Evolution in Glioblastoma</title><updated>2025-09-21T19:32:37.636449+00:00</updated><content/><link href="https://aacrjournals.org/cancerdiscovery/article/doi/10.1158/2159-8290.CD-24-1555/764257/Extrachromosomal-DNA-Driven-Oncogene-Spatial"/><published>2025-09-21T14:22:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323008</id><title>UUIDv7 in Postgres 18. With time extraction</title><updated>2025-09-21T19:32:37.266923+00:00</updated><content>&lt;doc fingerprint="3d1d03952c8f26ac"&gt;
  &lt;main&gt;
    &lt;p&gt;PostgreSQL 18 is on the horizon, with beta testing now underway. Among the many improvements in this release is support for UUIDv7. A timestamp-based UUID variant that plays nicely with btree indexes. In this post, we'll discuss UUIDs in general, why UUIDv7 is so useful and how you'll want to use it in Postgres.&lt;/p&gt;
    &lt;head rend="h2"&gt;PostgreSQL 18&lt;/head&gt;
    &lt;p&gt;PostgreSQL 18 beta 1 was released few days ago. The release is packed with new features, improvements and bug fixes. As usual, the community is encouraged to try it out and report issues, with the goal of shipping a high quality release in September.&lt;/p&gt;
    &lt;p&gt;The highlights of the release include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Async I/O (with io_uring) — 2-3x speedups on seq scans, vacuums&lt;/item&gt;
      &lt;item&gt;Skip scan on multi-column btree indexes + smarter OR/IN optimizations&lt;/item&gt;
      &lt;item&gt;Keep planner stats during major upgrades&lt;/item&gt;
      &lt;item&gt;UUIDv7 functions&lt;/item&gt;
      &lt;item&gt;Virtual generated columns&lt;/item&gt;
      &lt;item&gt;OAuth login + md5 deprecation warning&lt;/item&gt;
      &lt;item&gt;EXPLAIN ANALYZE now shows I/O, CPU, WAL&lt;/item&gt;
      &lt;item&gt;Temporal constraints, LIKE on nondeterministic collation, casefolding&lt;/item&gt;
      &lt;item&gt;New wire protocol version: 3.2 (first since 2003!)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While &lt;code&gt;uuidv7()&lt;/code&gt; is not the most exciting feature (that would be async I/O), it's probably the most awaited one. It was close to being added in 17, and many users have been a bit disappointed that it didn't make the cut. I'm so excited about it, that I decided to take the beta for a spin and write a blog post about it.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is a UUID and why are they useful?&lt;/head&gt;
    &lt;p&gt;UUIDs are 128-bit values used as identifiers for various items - anything from transactions to companies. They are designed to be unique across space and time and can be generated efficiently at high rates without depending on centralized services.&lt;/p&gt;
    &lt;p&gt;Traditionally, relational databases used auto-incrementing types (like &lt;code&gt;SERIAL&lt;/code&gt; or &lt;code&gt;identity&lt;/code&gt;) to generate unique identifiers. This can be done efficiently on a single machine (although there are drawbacks even in this case), but once you need to scale out, you need a way to generate identifiers that are unique across all nodes. Instagram team wrote a short blog about their migration to UUIDs as they sharded their Postgres database.&lt;/p&gt;
    &lt;p&gt;UUIDs are useful as primary keys in databases in several common scenarios:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Generating unique IDs in a distributed database:&lt;lb/&gt;While many distributed databases can support auto-increment (identity) columns, they have limitations and performance issues.&lt;/item&gt;
      &lt;item&gt;Unguessable public identifiers:&lt;lb/&gt;Properly generated, UUIDs can't be guessed, predicted or used to infer information about the system. If you use auto-increment as a customer identifier, for instance, attackers can scan all existing identifiers and attempt to use them, they can guess the next identifier and estimate how many customers you have.&lt;/item&gt;
      &lt;item&gt;Allowing clients to generate identifiers:&lt;lb/&gt;Using UUIDs allows clients to generate identifiers that they can use without coordinating with the server. This is useful in mobile apps and serverless environments where you want to minimize communication to the server.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As a result of these benefits, UUIDs are used as primary keys in many databases. However, there are also 3 concerns with the use of UUIDs in databases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sorting: UUIDs are not meaningfully sortable by value.&lt;/item&gt;
      &lt;item&gt;Index locality: New UUIDs are not close to each other in the index, this means that inserts will be performed at random locations. This can cause index bloat and other performance issues, as you can see in the charts in this blog post.&lt;/item&gt;
      &lt;item&gt;Size: UUIDs are 128-bit values. Most developers default to using &lt;code&gt;INT&lt;/code&gt;(32-bit) or&lt;code&gt;BIGINT&lt;/code&gt;(64-bit) for their primary keys. For tables with large number of very small records, this can be meaningful overhead.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As I'll explain in the next section, UUIDv7 addresses 2 out of these 3 concerns.&lt;/p&gt;
    &lt;p&gt;The size of the UUID may be a problem when disk space or network bandwidth is limited, but it is worth noting that modern CPUs can compare 128-bit values in a single instruction (&lt;code&gt;CMEQ&lt;/code&gt;, part of SIMD instructions), so database operations on UUIDs are highly optimized. The key here is to make sure you use binary representation of UUIDs (proper UUID type) in both the database and the application, and not the string representation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why UUIDv7?&lt;/head&gt;
    &lt;p&gt;UUIDs were first standardized in RFC 4122 in 2005. This RFC defines 5 variants of UUIDs, of which variant 1 and 4 are the most common. The specification was later revised to add variants 6-8 in RFC 9562 which was published in May 2024 (although the first public working draft was published in 2020). Happy Birthday RFC 9562 and UUIDv7!&lt;/p&gt;
    &lt;p&gt;To motivate the specification update, RFC 9562 discusses the common use case of using UUIDs as primary keys in databases:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One area in which UUIDs have gained popularity is database keys ... but UUID versions 1-5, which were originally defined by [RFC4122], lack certain other desirable characteristics, such as:&lt;/p&gt;
      &lt;p&gt;UUID versions that are not time ordered, such as UUIDv4 (described in Section 5.4), have poor database-index locality. This means that new values created in succession are not close to each other in the index; thus, they require inserts to be performed at random locations. The resulting negative performance effects on the common structures used for this (B-tree and its variants) can be dramatic.&lt;/p&gt;
      &lt;p&gt;many widely distributed database applications and large application vendors have sought to solve the problem of creating a better time-based, sortable unique identifier for use as a database key. This has led to numerous implementations over the past 10+ years solving the same problem in slightly different ways.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The RFC proceeds to specify 16 (!) different implementations of non-standard UUIDs, each with their own trade-offs. This includes the popular &lt;code&gt;ULID&lt;/code&gt;, Twitter's &lt;code&gt;Snowflake&lt;/code&gt;, Instagram's &lt;code&gt;ShardId&lt;/code&gt; and many more.
All of these implementations were evaluated when designing the new specification.&lt;/p&gt;
    &lt;p&gt;While the new RFC specifies 3 new variants of UUIDs, the only interesting one is UUIDv7. UUIDv6 is introduced for backwards compatibility only - the RFC says "Systems that do not involve legacy UUIDv1 SHOULD use UUIDv7 instead". UUIDv8 provides a format for experimental and vendor-specific extensions.&lt;/p&gt;
    &lt;p&gt;UUIDv7 solves both the sorting and index locality concerns. It uses Unix Epoch timestamp as the most significant 48 bits, keeping the other 74 bits for random values (additional bits are used for version and variant). This makes UUIDs sortable by time sequence and unique. The standard also provides the option to include millisecond timestamp in the UUID and/or carefully seeded counter, to support ordering within a single second (if needed). As a result, UUIDv7 is a great fit for use as a primary key in databases - it is guaranteed to be unique, sortable and have good index locality.&lt;/p&gt;
    &lt;head rend="h2"&gt;UUIDv7 in PostgreSQL 18&lt;/head&gt;
    &lt;p&gt;Until PostgreSQL 18, UUIDv7 was not natively supported. The built-in &lt;code&gt;gen_random_uuid()&lt;/code&gt; function generated UUIDv4, and while the popular &lt;code&gt;uuid-ossp&lt;/code&gt; extension added
support for additional UUID variants, it was limited to the variants specified in RFC 4122.&lt;/p&gt;
    &lt;p&gt;PostgreSQL 18 adds a new function: &lt;code&gt;uuidv7()&lt;/code&gt;, which generates UUIDv7 values. The Postgres implementation includes a 12-bit sub-millisecond timestamp fraction immediately after the timestamp (as allowed but not required by the standard). This guarantees monotonicity for all UUIDv7 values generated by the same Postgres session (same backend process).&lt;/p&gt;
    &lt;p&gt;For consistency, PostgreSQL 18 added &lt;code&gt;uuidv4()&lt;/code&gt; as an alias for &lt;code&gt;gen_random_uuid()&lt;/code&gt;, to match the naming.&lt;/p&gt;
    &lt;p&gt;Calling &lt;code&gt;uuidv7()&lt;/code&gt; will generate a new UUIDv7 value where the timestamp is the current time. If you need to generate a UUIDv7 value for a different time, you can pass an optional &lt;code&gt;interval&lt;/code&gt; to the function.&lt;/p&gt;
    &lt;p&gt;Postgres' existing functions for extracting timestamp and version from a UUID are also updated to support UUIDv7. Here is an example of how to use the new functions:&lt;/p&gt;
    &lt;code&gt;postgres=# select uuidv7();
                uuidv7
--------------------------------------
 0196ea4a-6f32-7fd0-a9d9-9c815a0750cd
(1 row)

postgres=# select uuidv7(INTERVAL '1 day');
                uuidv7
--------------------------------------
 0196ef74-8d09-77b0-a84b-5301262f05ad
(1 row)

postgres=# SELECT uuid_extract_version(uuidv4());
 uuid_extract_version
----------------------
                    4
(1 row)

postgres=# SELECT uuid_extract_version(uuidv7());
 uuid_extract_version
----------------------
                    7
(1 row)

postgres=# SELECT uuid_extract_timestamp(uuidv7());
   uuid_extract_timestamp
----------------------------
 2025-05-19 20:50:40.381+00
(1 row)

postgres=# SELECT uuid_extract_timestamp(uuidv7(INTERVAL '1 hour'));
   uuid_extract_timestamp
----------------------------
 2025-05-19 21:50:59.388+00
(1 row)

postgres=# SELECT uuid_extract_timestamp(uuidv7(INTERVAL '-1 day'));
   uuid_extract_timestamp
----------------------------
 2025-05-18 20:51:15.774+00
(1 row)
&lt;/code&gt;
    &lt;p&gt;Using &lt;code&gt;uuidv7()&lt;/code&gt; as the primary key in a table is straightforward, and together with the ability to extract the timestamp, it makes it easy to use the UUID as a sortable key and even inspect the creation time of the record:&lt;/p&gt;
    &lt;code&gt;CREATE TABLE test (
    id uuid DEFAULT uuidv7() PRIMARY KEY,
    name text
);

INSERT INTO test (name) VALUES ('foo');
INSERT INTO test (name) VALUES ('bar');
-- this will be sorted to the beginning of the list since we are making it 1h older than the other two
INSERT INTO test (id, name) VALUES (uuidv7(INTERVAL '-1 hour'), 'oldest');

SELECT uuid_extract_timestamp(id), name FROM test ORDER BY id;

   uuid_extract_timestamp   |  name
----------------------------+--------
 2025-05-19 19:55:43.87+00  | oldest
 2025-05-19 20:55:01.304+00 | foo
 2025-05-19 20:55:01.305+00 | bar
(3 rows)
&lt;/code&gt;
    &lt;p&gt;All these functions are documented in the PostgreSQL documentation and if you are interested in the implementation details, you can review the patch.&lt;/p&gt;
    &lt;head rend="h2"&gt;Try it out!&lt;/head&gt;
    &lt;p&gt;Once PostgreSQL 18 is released, you will be able to use &lt;code&gt;uuidv7()&lt;/code&gt; and all the other new functionality by installing it as you normally do.
While the official release is planned for September, &lt;code&gt;Beta 1&lt;/code&gt; version is already available and the community encourages users to try it out and report issues.&lt;/p&gt;
    &lt;p&gt;The installations instructions for the beta versions and nightly snapshots are available here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;PostgreSQL 18 delivers practical improvements that experienced developers will really appreciate. Native support for UUIDv7 is a quiet but impactful addition that addresses long-standing pain points in database design.&lt;/p&gt;
    &lt;p&gt;UUIDs have always been a tradeoff: secure, guaranteed to be unique, efficient to generate in distributed systems. but with performance drawbacks for use with B-tree indexes. UUIDv7 brings the best of both worlds — globally unique, yet ordered in a way that plays nicely with B-tree indexes and write-heavy workloads. Postgres 18 makes them that much more convenient to use.&lt;/p&gt;
    &lt;p&gt;If you've ever hesitated to use UUIDs for primary keys, this is your chance to revisit that decision. Try the beta, test it in your schema, and see how it behaves. Whether you're building multi-tenant apps or just want more stable ID generation, UUIDv7 is worth a look.&lt;/p&gt;
    &lt;p&gt;The best way to shape the future of Postgres is to get involved early — so go ahead, spin up a test instance and let the community know what you find.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.thenile.dev/blog/uuidv7"/><published>2025-09-21T14:24:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323027</id><title>The Beginner's Textbook for Homomorphic Encryption</title><updated>2025-09-21T19:32:37.106498+00:00</updated><content>&lt;doc fingerprint="3d9db40ad4d580ca"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Cryptography and Security&lt;/head&gt;&lt;p&gt; [Submitted on 7 Mar 2025 (v1), last revised 8 Sep 2025 (this version, v15)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:The Beginner's Textbook for Fully Homomorphic Encryption&lt;/head&gt;View PDF&lt;quote&gt;Abstract:Fully Homomorphic Encryption (FHE) is a cryptographic scheme that enables computations to be performed directly on encrypted data, as if the data were in plaintext. After all computations are performed on the encrypted data, it can be decrypted to reveal the result. The decrypted value matches the result that would have been obtained if the same computations were applied to the plaintext data.&lt;lb/&gt;FHE supports basic operations such as addition and multiplication on encrypted numbers. Using these fundamental operations, more complex computations can be constructed, including subtraction, division, logic gates (e.g., AND, OR, XOR, NAND, MUX), and even advanced mathematical functions such as ReLU, sigmoid, and trigonometric functions (e.g., sin, cos). These functions can be implemented either as exact formulas or as approximations, depending on the trade-off between computational efficiency and accuracy.&lt;lb/&gt;FHE enables privacy-preserving machine learning by allowing a server to process the client's data in its encrypted form through an ML model. With FHE, the server learns neither the plaintext version of the input features nor the inference results. Only the client, using their secret key, can decrypt and access the results at the end of the service protocol. FHE can also be applied to confidential blockchain services, ensuring that sensitive data in smart contracts remains encrypted and confidential while maintaining the transparency and integrity of the execution process. Other applications of FHE include secure outsourcing of data analytics, encrypted database queries, privacy-preserving searches, efficient multi-party computation for digital signatures, and more.&lt;lb/&gt;As this book is an open project (this https URL), we welcome FHE experts to join us as collaborators to help expand the draft.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Ronny Ko [view email]&lt;p&gt;[v1] Fri, 7 Mar 2025 04:29:11 UTC (33 KB)&lt;/p&gt;&lt;p&gt;[v2] Thu, 13 Mar 2025 15:18:50 UTC (5,237 KB)&lt;/p&gt;&lt;p&gt;[v3] Fri, 14 Mar 2025 03:22:13 UTC (5,239 KB)&lt;/p&gt;&lt;p&gt;[v4] Sun, 13 Apr 2025 13:14:01 UTC (5,258 KB)&lt;/p&gt;&lt;p&gt;[v5] Sat, 26 Apr 2025 18:20:16 UTC (5,275 KB)&lt;/p&gt;&lt;p&gt;[v6] Sun, 4 May 2025 15:31:10 UTC (5,302 KB)&lt;/p&gt;&lt;p&gt;[v7] Mon, 12 May 2025 17:20:32 UTC (5,099 KB)&lt;/p&gt;&lt;p&gt;[v8] Tue, 20 May 2025 16:04:22 UTC (5,062 KB)&lt;/p&gt;&lt;p&gt;[v9] Mon, 26 May 2025 03:42:34 UTC (5,062 KB)&lt;/p&gt;&lt;p&gt;[v10] Sun, 1 Jun 2025 08:45:01 UTC (4,570 KB)&lt;/p&gt;&lt;p&gt;[v11] Sun, 8 Jun 2025 04:45:52 UTC (4,571 KB)&lt;/p&gt;&lt;p&gt;[v12] Mon, 30 Jun 2025 13:04:04 UTC (4,570 KB)&lt;/p&gt;&lt;p&gt;[v13] Mon, 7 Jul 2025 09:54:47 UTC (4,570 KB)&lt;/p&gt;&lt;p&gt;[v14] Wed, 13 Aug 2025 04:21:08 UTC (4,570 KB)&lt;/p&gt;&lt;p&gt;[v15] Mon, 8 Sep 2025 05:39:49 UTC (4,570 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2503.05136"/><published>2025-09-21T14:26:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323187</id><title>New thermoelectric cooling breakthrough nearly doubles efficiency</title><updated>2025-09-21T19:32:36.847978+00:00</updated><content>&lt;doc fingerprint="31bed7467a83e1fc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;New cooling breakthrough nearly doubles efficiency&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Date:&lt;/item&gt;
      &lt;item rend="dd-1"&gt;September 20, 2025&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Source:&lt;/item&gt;
      &lt;item rend="dd-2"&gt;Johns Hopkins University Applied Physics Laboratory&lt;/item&gt;
      &lt;item rend="dt-3"&gt;Summary:&lt;/item&gt;
      &lt;item rend="dd-3"&gt;CHESS thin-film materials nearly double refrigeration efficiency compared to traditional methods. Scalable and versatile, they promise applications from household cooling to space exploration.&lt;/item&gt;
      &lt;item rend="dt-4"&gt;Share:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Researchers at the Johns Hopkins Applied Physics Laboratory (APL) in Laurel, Maryland, have developed a new, easily manufacturable solid-state thermoelectric refrigeration technology with nano-engineered materials that is twice as efficient as devices made with commercially available bulk thermoelectric materials. As global demand grows for more energy-efficient, reliable and compact cooling solutions, this advancement offers a scalable alternative to traditional compressor-based refrigeration.&lt;/p&gt;
    &lt;p&gt;In a paper published in Nature Communications, a team of researchers from APL and refrigeration engineers from Samsung Research demonstrated improved heat-pumping efficiency and capacity in refrigeration systems attributable to high-performance nano-engineered thermoelectric materials invented at APL known as controlled hierarchically engineered superlattice structures (CHESS).&lt;/p&gt;
    &lt;p&gt;The CHESS technology is the result of 10 years of APL research in advanced nano-engineered thermoelectric materials and applications development. Initially developed for national security applications, the material has also been used for noninvasive cooling therapies for prosthetics and won an R&amp;amp;D 100 award in 2023.&lt;/p&gt;
    &lt;p&gt;"This real-world demonstration of refrigeration using new thermoelectric materials showcases the capabilities of nano-engineered CHESS thin films," said Rama Venkatasubramanian, principal investigator of the joint project and chief technologist for thermoelectrics at APL. "It marks a significant leap in cooling technology and sets the stage for translating advances in thermoelectric materials into practical, large-scale, energy-efficient refrigeration applications."&lt;/p&gt;
    &lt;p&gt;A New Benchmark for Solid-State Cooling&lt;/p&gt;
    &lt;p&gt;The push for more efficient and compact cooling technologies is fueled by a variety of factors, including population growth, urbanization and an increasing reliance on advanced electronics and data infrastructure. Conventional cooling systems, while effective, are often bulky, energy intensive and reliant on chemical refrigerants that can be harmful to the environment.&lt;/p&gt;
    &lt;p&gt;Thermoelectric refrigeration is widely regarded as a potential solution. This method cools by using electrons to move heat through specialized semiconductor materials, eliminating the need for moving parts or harmful chemicals, making these next-generation refrigerators quiet, compact, reliable and sustainable. Bulk thermoelectric materials are used in small devices like mini-fridges, but their limited efficiency, low heat-pumping capacity and incompatibility with scalable semiconductor chip fabrication have historically prevented their wider use in high-performance systems.&lt;/p&gt;
    &lt;p&gt;In the study, researchers compared refrigeration modules using traditional bulk thermoelectric materials with those using CHESS thin-film materials in standardized refrigeration tests, measuring and comparing the electrical power needed to achieve various cooling levels in the same commercial refrigerator test systems. Samsung Research's Life Solution Team, led by executive vice president Joonhyun Lee, collaborated with APL to validate the results through detailed thermal modeling, quantifying heat loads and thermal resistance parameters to ensure accurate performance evaluation under real-world conditions.&lt;/p&gt;
    &lt;p&gt;The results were striking: Using CHESS materials, the APL team achieved nearly 100% improvement in efficiency over traditional thermoelectric materials at room temperature (around 80 degrees Fahrenheit, or 25 C). They then translated these material-level gains into a near 75% improvement in efficiency at the device level in thermoelectric modules built with CHESS materials and a 70% improvement in efficiency in a fully integrated refrigeration system, each representing a significant improvement over state-of-the-art bulk thermoelectric devices. These tests were completed under conditions that involved significant amounts of heat pumping to replicate practical operation.&lt;/p&gt;
    &lt;p&gt;Built to Scale&lt;/p&gt;
    &lt;p&gt;Beyond improving efficiency, the CHESS thin-film technology uses remarkably less material -- just 0.003 cubic centimeters, or about the size of a grain of sand, per refrigeration unit. This reduction in material means APL's thermoelectric materials could be mass-produced using semiconductor chip production tools, driving cost efficiency and enabling widespread market adoption.&lt;/p&gt;
    &lt;p&gt;"This thin-film technology has the potential to grow from powering small-scale refrigeration systems to supporting large building HVAC applications, similar to the way that lithium-ion batteries have been scaled to power devices as small as mobile phones and as large as electric vehicles," Venkatasubramanian said.&lt;/p&gt;
    &lt;p&gt;Additionally, the CHESS materials were created using a well-established process commonly used to manufacture high-efficiency solar cells that power satellites and commercial LED lights.&lt;/p&gt;
    &lt;p&gt;"We used metal-organic chemical vapor deposition (MOCVD) to produce the CHESS materials, a method well known for its scalability, cost-effectiveness and ability to support large-volume manufacturing," said Jon Pierce, a senior research engineer who leads the MOCVD growth capability at APL. "MOCVD is already widely used commercially, making it ideal for scaling up CHESS thin-film thermoelectric materials production."&lt;/p&gt;
    &lt;p&gt;These materials and devices continue to show promise for a broad range of energy harvesting and electronics applications in addition to the recent advances in refrigeration. APL plans to continue to partner with organizations to refine the CHESS thermoelectric materials with a focus on boosting efficiency to approach that of conventional mechanical systems. Future efforts include demonstrating larger-scale refrigeration systems, including freezers, and integrating artificial intelligence-driven methods to optimize energy efficiency in compartmentalized or distributed cooling in refrigeration and HVAC equipment.&lt;/p&gt;
    &lt;p&gt;"Beyond refrigeration, CHESS materials are also able to convert temperature differences, like body heat, into usable power," said Jeff Maranchi, Exploration Program Area manager in APL's Research and Exploratory Development Mission Area. "In addition to advancing next-generation tactile systems, prosthetics and human-machine interfaces, this opens the door to scalable energy-harvesting technologies for applications ranging from computers to spacecraft -- capabilities that weren't feasible with older bulkier thermoelectric devices."&lt;/p&gt;
    &lt;p&gt;"The success of this collaborative effort demonstrates that high-efficiency solid-state refrigeration is not only scientifically viable but manufacturable at scale," said Susan Ehrlich, an APL technology commercialization manager. "We're looking forward to continued research and technology transfer opportunities with companies as we work toward translating these innovations into practical, real-world applications."&lt;/p&gt;
    &lt;p&gt;Story Source:&lt;/p&gt;
    &lt;p&gt;Materials provided by Johns Hopkins University Applied Physics Laboratory. Note: Content may be edited for style and length.&lt;/p&gt;
    &lt;p&gt;Journal Reference:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Jake Ballard, Matthew Hubbard, Sung-Jin Jung, Vanessa Rojas, Richard Ung, Junwoo Suh, MinSoo Kim, Joonhyun Lee, Jonathan M. Pierce, Rama Venkatasubramanian. Nano-engineered thin-film thermoelectric materials enable practical solid-state refrigeration. Nature Communications, 2025; 16 (1) DOI: 10.1038/s41467-025-59698-y&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cite This Page:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sciencedaily.com/releases/2025/09/250919085242.htm"/><published>2025-09-21T14:43:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323207</id><title>DXGI debugging: Microsoft put me on a list</title><updated>2025-09-21T19:32:36.311469+00:00</updated><content>&lt;doc fingerprint="260f8913c3239dc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;DXGI debugging: Microsoft put me on a list&lt;/head&gt;
    &lt;p&gt;Why does Space Station 14 crash with ANGLE on ARM64? 6 hours later…&lt;/p&gt;
    &lt;p&gt;So. I’ve been continuing work on getting ARM64 builds out for Space Station 14. The thing I was working on yesterday were launcher builds, specifically a single download that supports both ARM64 and x64. I’d already gotten the game client itself running natively on ARM64, and it worked perfectly fine in my dev environment. I wrote all the new launcher code, am pretty sure I got it right. Zip it up, test it on ARM64, aaand…&lt;/p&gt;
    &lt;p&gt;The game client crashes on Windows ARM64. Both in my VM and on Julian’s real Snapdragon X laptop.&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging: logs&lt;/head&gt;
    &lt;p&gt;The client logs are empty. They suspiciously cut out right after SDL is initialized.&lt;/p&gt;
    &lt;p&gt;Of course it isn’t that easy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging: pulling WinDbg out of the shed&lt;/head&gt;
    &lt;p&gt;Given that there’s no logs, this has to be a native crash. That means it’s WinDbg time.&lt;/p&gt;
    &lt;p&gt;So at first I decided to start &lt;code&gt;Space Station 14 Launcher.exe&lt;/code&gt; directly through WinDbg. This is annoying because I have to go into child processes (with &lt;code&gt;.childdbg 1&lt;/code&gt;) twice, and for some reason there’s a lot of waiting, but it does work…&lt;/p&gt;
    &lt;p&gt;The game crashes in &lt;code&gt;USER32!GetDC&lt;/code&gt; on an illegal instruction, somewhere after SDL does something. I barely glanced at the disassembly but it made no sense to me, so I just assumed there’s some UB happening and didn’t think much of it. After all, why would the implementation of &lt;code&gt;GetDC()&lt;/code&gt; have broken assembly?&lt;/p&gt;
    &lt;code&gt;(3148.35e4): Illegal instruction - code c000001d (first chance)
(3148.35e4): Unknown exception - code c000041d (!!! second chance !!!)
*** WARNING: Unable to verify checksum for C:\Users\Luna\Downloads\SS14.Launcher_Windows\bin_arm64\loader\SDL3.DLL
USER32!GetDC+0x8:
00007ff9`f7be9548 ee8e1db0 ???
&lt;/code&gt;
    &lt;p&gt;WinDbg was also unable to pull stack frames from C# code. It did, thankfully, clearly communicate why this was. Yep, it’s our friend &lt;code&gt;mscordaccore&lt;/code&gt; again!&lt;/p&gt;
    &lt;code&gt;CLRDLL: Consider using ".cordll -lp &amp;lt;path&amp;gt;" command to specify .NET runtime directory.
CLRDLL: Consider using ".cordll -lp &amp;lt;path&amp;gt;" command to specify .NET runtime directory.
&lt;/code&gt;
    &lt;p&gt;However, my attempts to actually follow said instructions were completely fruitless, giving this error:&lt;/p&gt;
    &lt;code&gt;0:027:ARM64EC&amp;gt; .cordll -lp C:\Users\Luna\Downloads\SS14.Launcher_Windows\dotnet_arm64\shared\Microsoft.NETCore.App\9.0.9
CLRDLL: Consider using ".cordll -lp &amp;lt;path&amp;gt;" command to specify .NET runtime directory.
CLR DLL status: ERROR: Unable to load DLL C:\Users\Luna\Downloads\SS14.Launcher_Windows\dotnet_arm64\shared\Microsoft.NETCore.App\9.0.9\mscordaccore_AMD64_arm64_9.0.925.41916.dll, Win32 error 0n87
&lt;/code&gt;
    &lt;p&gt;Why is it trying to run an &lt;code&gt;AMD64&lt;/code&gt; binary? Wait is WinDbg not natively compiled for ARM64? Sigh. Let’s just do it without C# debugging, I can probably manage based off the SDL stack trace. So I pull &lt;code&gt;SDL3.pdb&lt;/code&gt; from our server, drop it next to &lt;code&gt;SDL3.dll&lt;/code&gt;, and then use the UI to reload the symbols. And that gets us a bit further, we now have proper function names for SDL3!&lt;/p&gt;
    &lt;p&gt;So I double click one of the entries in the UI’s stack trace view. And the entire debugger breaks. Stack trace view goes empty. Every action I try to make causes more of these errors to be printed:&lt;/p&gt;
    &lt;code&gt;Machine is not a possible execution machine
Unable to get current machine context, HRESULT 0x8000FFFF
Machine is not a possible execution machine
Unable to get current machine context, HRESULT 0x8000FFFF
Machine is not a possible execution machine
Unable to get current machine context, HRESULT 0x8000FFFF
Machine is not a possible execution machine
Machine is not a possible execution machine
&lt;/code&gt;
    &lt;p&gt;Now even WinDbg is broken??&lt;/p&gt;
    &lt;p&gt;Googling these errors gave nothing useful. One of them gave not a single result. After just pondering the error for a moment, I thought “wait, why is the command prompt still saying &lt;code&gt;ARM64EC&amp;gt;&lt;/code&gt;? ARM64EC is for emulation, but the active debugger processes (&lt;code&gt;SS14.Launcher.exe&lt;/code&gt; and &lt;code&gt;SS14.Loader.exe&lt;/code&gt;) are both native ARM64.&lt;/p&gt;
    &lt;p&gt;Turns out that it’s because I started &lt;code&gt;Space Station 14 Launcher.exe&lt;/code&gt; directly. You see, that executable is x64 native, and its only job is to set up the .NET environment and launch the actual ARM64 executable. Something about starting the debugging session with that program causes WinDbg to get extremely confused when later looking at the child processes it spawns.&lt;/p&gt;
    &lt;p&gt;From this point on I just started launching &lt;code&gt;SS14.Launcher.exe&lt;/code&gt; directly1. This means I wasn’t setting up the same &lt;code&gt;DOTNET_ROOT&lt;/code&gt; (because WinDbg can’t set environment variables when launching things… yes really), but this didn’t really matter. This fixed both the “Machine is not a possible execution machine” errors and the issues with showing C# stack traces. I guess WinDbg is compiled for ARM64 after all, and it just decided to run an x64 debug host when you start debugging an x64 application. Fair enough I guess?&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging: what’s SDL doing?&lt;/head&gt;
    &lt;p&gt;After figuring out all of the above, we could really get started. I also opted to swap out &lt;code&gt;SDL3.dll&lt;/code&gt; with a locally-built copy, so that the debugger could locate source files2. What SDL is doing is pretty straight forward: the first time the window is shown, it clears the background with GDI commands:&lt;/p&gt;
    &lt;p&gt;I mean… this is like, fine, right? I mean I don’t know much about this code, but why would this crash on ARM but not x64??? The window is valid. &lt;code&gt;GetDC()&lt;/code&gt; is an extremely fundamental Win32 function call. If there was something broken with it, my OS would not be usable. What the fuck is going on?&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;if (ShouldClearWindowOnEraseBackground(data))&lt;/code&gt; allows it to be disabled via a hint, which can be specified by environment variable. This fixes the crash… until you open a second OS window, then SDL3 calls &lt;code&gt;GetDC()&lt;/code&gt; once again and that crashes. Not a solution.&lt;/p&gt;
    &lt;p&gt;So I checked the actual &lt;code&gt;USER32!GetDC&lt;/code&gt; again, and this time I actually paid attention to the disassembly code instead of glossing over it. What the fuck? &lt;code&gt;pacibsp&lt;/code&gt; is missing at the start. It’s loading an address for a jump that only jumps to the next instruction, which is invalid. In some runs, said instruction was instead a broken &lt;code&gt;x26&lt;/code&gt;-relative &lt;code&gt;str&lt;/code&gt; instruction that AV’d because the register was all zeroes.&lt;/p&gt;
    &lt;p&gt;At this point let’s introduce the villain. You might have noticed it in the call stack: &lt;code&gt;DXGI!My_GetDC&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For those who aren’t well-versed in DirectX stuff: DXGI is a fundamental part of DirectX ever since DirectX 10 (Vista). For those who have never modded a game before: a detour is a hack that injects instructions into other functions at runtime, to do evil shit. Why the hell is Microsoft using this in DXGI?&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging: DXGI despair&lt;/head&gt;
    &lt;p&gt;Through the debugging adventure, I ended up putting a breakpoint on every call to &lt;code&gt;USER32!GetDC&lt;/code&gt;. The first few calls are fine, but then the last one, the one that crashes, is not.&lt;/p&gt;
    &lt;p&gt;At this point I got really desperate. “Asking in low-level programming Discords”-level desperate. I ended up asking for help in the DirectX Discord (yes, there’s an official DirectX Discord, and there’s many MS employees in there).&lt;/p&gt;
    &lt;p&gt;I would like to thank Jesse Natalia from the DirectX Discord for responding swiftly to my messages in there.&lt;/p&gt;
    &lt;p&gt;After some back and forth there, I wanted to catch DXGI in the act. Maybe that would tell me something, I don’t know. So with a simple &lt;code&gt;ba w4 USER32!GetDC&lt;/code&gt;, I put a hardware breakpoint for whenever something would write to &lt;code&gt;USER32!GetDC&lt;/code&gt;. I did have to awkwardly “run the program for just a little bit” because &lt;code&gt;USER32.dll&lt;/code&gt; isn’t loaded immediately at program startup.3&lt;/p&gt;
    &lt;p&gt;While writing this blog post I realized there is an intelligent way to do this. It’s called &lt;code&gt;sxe ld USER32.dll&lt;/code&gt;. I’ve literally written about it in this blog before. Oops.&lt;/p&gt;
    &lt;p&gt;Now this is very interesting. The bottom of the stack trace is quite expected: SDL creates a window, uses ANGLE’s EGL implementation for this, that does a bunch of stuff, and eventually creates a DXGI swapchain. But then what is &lt;code&gt;UpgradeSwapEffect&lt;/code&gt;? And why is it installing a detour?&lt;/p&gt;
    &lt;p&gt;Ah, I already know what this is.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optimizing windowed games: flip model&lt;/head&gt;
    &lt;p&gt;Right. So. DirectX.&lt;/p&gt;
    &lt;p&gt;When you create a DirectX swapchain, you specify an “effect”, which falls into two categories: “bitblt” and “flip”. To make a long story short: bitblt is the “original” one, while flip is the much more modern one added in Windows 84. It’s more efficient and performant, and all software should be using it. Furthermore, on modern versions of Windows and with a GPU supporting “Multiplane Overlays”, flip model actually enables windowed games to be displayed with zero additional latency over “exclusive” fullscreen mode.&lt;/p&gt;
    &lt;p&gt;Of course, many games never get updated, or they’re stuck on an ancient version. And many of these games don’t care. So in Windows 11, Microsoft added “Optimizations for windowed games”, which forcibly enables flip model on games that are still using bitblt. Why does DXGI need to install detours for this? Probably some compatibility shit with the bitblt model. I don’t have any deep knowledge of how Win32 GDI stuff works, but it’s not hard for me to imagine there’s some interplay here they need to take care of. I can also confirm that disabling the feature in Windows’ settings menu fixes the crash!&lt;/p&gt;
    &lt;p&gt;If you’re wondering why SS14 isn’t using flip model: it’s because we can’t. We’re not creating the swapchain directly, ANGLE is. And ANGLE is continuing to use &lt;code&gt;SWAP_EFFECT_SEQUENTIAL&lt;/code&gt;. I actually once experimented with SS14 managing the swapchain, but this ran into some ANGLE limitations and I never got around to ironing out all the edge cases and crashes. I’d rather just spend the brain power on ditching OpenGL, rather than trying to continue working with this broken API.5.&lt;/p&gt;
    &lt;p&gt;So here we are. The entire debugging story so far, you’re like, “surely Microsoft didn’t break DXGI on ARM64, huh???” But now it’s becoming plausible. There’s barely any native ARM64 Windows games, and surely none that are using bitblt swapchains. And guess what, you don’t even need &lt;code&gt;GetDC()&lt;/code&gt; for modern DirectX games. SDL does it because it’s heavily designed for OpenGL. Most games run in x64 emulation, and that presumably works fine. Everything adds up to it being possible this just genuinely fell under the radar at Microsoft.&lt;/p&gt;
    &lt;p&gt;This should be pretty easy to verify in a minimal example. I cloned an old DirectX SDK sample, updated it to be compiled for ARM64, added some &lt;code&gt;GetDC()&lt;/code&gt; calls, aaand… nope, no crash. Then I spent quite a while trying various stuff: comparing the swapchain creation code with that of ANGLE, changing various parameters, verifying whether the detour was being installed (it wasn’t). But eventually, I did find it.&lt;/p&gt;
    &lt;p&gt;It’s the filename.&lt;/p&gt;
    &lt;p&gt;Of course it’s the goddamn filename.&lt;/p&gt;
    &lt;head rend="h2"&gt;I’m on a list&lt;/head&gt;
    &lt;p&gt;It only happens when the program is called &lt;code&gt;SS14.Loader.exe&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The final piece of the puzzle. It didn’t happen in a dev environment because then the exe isn’t named &lt;code&gt;SS14.Loader.exe&lt;/code&gt;. Microsoft only enables “Optimizations for windowed games” on a specific list of games. And guess what, none of those select games are on ARM64, at least until I was unfortunate enough to port mine. How did we get on the list? Who knows.&lt;/p&gt;
    &lt;p&gt;Microsoft put me on a list, that ships with every Windows install. And this list actually broke my game. Achievement unlocked!&lt;/p&gt;
    &lt;head rend="h2"&gt;Addendum: why ANGLE, and about OpenGL on Windows ARM64&lt;/head&gt;
    &lt;p&gt;Traditionally, OpenGL on Windows has been implemented by the 3 IHVs (Nvidia, AMD, Intel). If they didn’t explicitly go out of their way to add it to their drivers, you’d have no OpenGL beyond 1.0. Those new Snapdragon X devices, however, use Microsoft’s new-ish “OpenGL on D3D12” driver. It’s actually part of Mesa!&lt;/p&gt;
    &lt;p&gt;The problem with Space Station 14 is that said driver is broken for us, causing severe graphical artifacts and flickering. I had been aware of this for years, because the same driver is used for the GPU acceleration of WSL2, but I never bothered to report it 😬. So for the purpose of porting SS14 to ARM64 Windows, I decided to just immediately force on ANGLE on Qualcomm devices, and call it a day.&lt;/p&gt;
    &lt;p&gt;What I didn’t know until yesterday is that the OpenGL on D3D12 driver does not ship with Qualcomm’s drivers! It’s on the Microsoft store! I can even install it in my VM and get it to emulate OpenGL on top of DirectX’s software renderer (WARP), just like I had been doing with ANGLE. I’ve finally bothered to report the graphical issues, so hopefully it gets fixed eventually. If it does get fixed, Microsoft Store distribution means it shouldn’t take too long to trickle down to users, and then we can stop enforcing ANGLE on Qualcomm devices.&lt;/p&gt;
    &lt;p&gt;For Space Station 14, I will say that this means I’ll be postponing official Windows ARM64 support for now. At least until either bug (OpenGL on D3D12 or ARM64 DXGI detours) are fixed. Or when I finally rewrite the renderer to drop OpenGL, that’s also an option.&lt;/p&gt;
    &lt;head rend="h2"&gt;Addendum: clarifications&lt;/head&gt;
    &lt;p&gt;(This bit added a few hours after publishing)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“Why not just rename the &lt;code&gt;.exe&lt;/code&gt;on ARM”: what I didn’t mention is that Steamworks does not support ARM64 Linux or Windows, at the moment. That means ARM64 builds will not be on Steam regardless, and I didn’t feel like going through even more the effort to add a workaround, just to improve performance for that 0.001% of people playing the game on a Snapdragon X device while also downloading from our website. And God forbid Microsoft updates the list later based on a bulk import of some random filenames and catches the new name too. The game already works when emulated, so I’m leaving it there until Windows is fixed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Debugging&lt;/p&gt;&lt;code&gt;SS14.Loader.exe&lt;/code&gt;directly would be a pain in the ass because it needs like a dozen arguments and environment variables configured by the launcher. I’d rather not. ↩︎&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I assume there’s a way to configure WinDbg to load these if the paths don’t line up properly… but I wouldn’t know how. Lol. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;This is because, being a .NET app, most native libraries are dynamically loaded at runtime. Only libraries that are direct dependencies of the&lt;/p&gt;&lt;code&gt;.exe&lt;/code&gt;are available in the “initial debugger break” period before the program really starts. ↩︎&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you were one of those people that held onto Windows 7 for as long as possible, this is the kind of shit you were missing out on. Seriously, 8.1 was fine. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fuck EGL especially. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://slugcat.systems/post/25-09-21-dxgi-debugging-microsoft-put-me-on-a-list/"/><published>2025-09-21T14:45:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323297</id><title>How to stop functional programming (2016)</title><updated>2025-09-21T19:32:35.494409+00:00</updated><content>&lt;doc fingerprint="7ad3b18718b551b1"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;How to stop functional programming&lt;/head&gt;
    &lt;p&gt;The following has never happened to me but I often hear stories.&lt;/p&gt;
    &lt;p&gt;You go into work and discover that a coworker isn't happy with some code you wrote because they don't understand it. They go to your manager and tell them that you're being a problem by writing code they don't understand. Your manager, being very skilled in conflict resolution, makes a technical decision to avoid whatever tool you used which caused the problem. In your case it was functional programming.&lt;/p&gt;
    &lt;p&gt;That's it. You've been told. No more functional programming.&lt;/p&gt;
    &lt;p&gt;The manager has figured out what's good for the business and you figure that listening is what's good for your job.&lt;/p&gt;
    &lt;p&gt;You get back to your desk and take a ticket from JIRA. You've got to add a page listing a person's coworkers to your internal employee directory. First you write a function you need.&lt;/p&gt;
    &lt;code&gt;def userCoworkers(u: User): List[Employee] =
  u.departments.flatMap(_.employees)&lt;/code&gt;
    &lt;p&gt;But it's pure. You're doing functional programming! Stop&lt;/p&gt;
    &lt;code&gt;def userCoworkers(u: User): List[Employee] = {
  val coworkers = ListBuffer[Employee]()
  for { d &amp;lt;- departments }
    coworkers ++ d.employees
  coworkers.toList
}&lt;/code&gt;
    &lt;p&gt;Well, there's a side-effect involved, but the whole method is pure. You're still doing functional programming!&lt;/p&gt;
    &lt;code&gt;def userCoworkers(u: User): List[Employee] = {
  logger.info("Collecting coworkers")
  val coworkers = ListBuffer[Employee]()
  for { d &amp;lt;- departments }
    coworkers ++ d.employees
  coworkers.toList
}&lt;/code&gt;
    &lt;p&gt;Now the method has 1 external side-effect. Is that enough? With "no functional programming" you've been given a lower-bound of 1 side-effect per method but we don't really know what the ideal number is. Hopefully you can slip it through code review.&lt;/p&gt;
    &lt;p&gt;After this exercise you've learned how easy it is to not do functional programming.&lt;/p&gt;
    &lt;p&gt;You show it to your product manager. They didn't realise how many coworkers the average person had. The page is huge. They ask you to just change it to a number.&lt;/p&gt;
    &lt;p&gt;You're going to have to add numbers together. Without being pure. You're going to have to think about this one.&lt;/p&gt;
    &lt;p&gt;Maybe you should ask your manager how to do it. Good luck.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://brianmckenna.org/blog/howtostopfp"/><published>2025-09-21T14:55:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323793</id><title>The University of Oxford has fallen out of the top three universities in the UK</title><updated>2025-09-21T19:32:34.096247+00:00</updated><content>&lt;doc fingerprint="c0fc00182795c8d8"&gt;
  &lt;main&gt;
    &lt;p&gt;The University of Oxford has fallen out of the top three universities in the UK for the first time, according to The Times and The Sunday Times Good University Guide for 2026.&lt;/p&gt;
    &lt;p&gt;Both Oxford and Cambridge universities have been supplanted by Durham University, which now holds the third-place spot among the top universities in the UK.&lt;/p&gt;
    &lt;p&gt;Oxford and Cambridge are tied for fourth in the 2026 rankings, after falling due to their relatively poor performance in the latest National Student Survey.&lt;/p&gt;
    &lt;p&gt;Durham University was named The Times’s University of the Year, although the number-one ranked university in the UK remained the London School of Economics and Political Science (LSE) for the second year in a row.&lt;/p&gt;
    &lt;p&gt;Second place was held by the University of St Andrews, again for the second consecutive year.&lt;/p&gt;
    &lt;p&gt;While the University of St Andrews ranked very highly in student experience and teaching quality, it lost out to the LSE in graduate prospects and research quality.&lt;/p&gt;
    &lt;p&gt;Durham University improved by 30 places year-on-year in its students’ evaluation of teaching quality, which was the main driver in securing its third place in the overall university league table.&lt;/p&gt;
    &lt;p&gt;“Durham is an outstanding place to study. We ensure that every student can grow and thrive here,” said Durham University Vice-Chancellor Professor Karen O’Brien.&lt;/p&gt;
    &lt;p&gt;“Our loyal, engaged alumni are testament to the impressive career prospects that await our graduates.”&lt;/p&gt;
    &lt;p&gt;The table below shows the top 20 universities in the United Kingdom, according to The Times University Rankings 2026.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;University&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;London School of Economics and Political Science&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;University of St Andrews&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;Durham University&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4/5&lt;/cell&gt;
        &lt;cell&gt;University of Cambridge&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4/5&lt;/cell&gt;
        &lt;cell&gt;University of Oxford&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Imperial College London&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;University of Bath&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;University of Warwick&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;University College London&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;University of Bristol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;University of Strathclyde&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;Loughborough University&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;University of Sheffield&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;University of Exeter&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;Lancaster University&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;University of Birmingham&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;University of Southampton&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;University of Liverpool&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;King’s College London&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;University of York&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hotminute.co.uk/2025/09/19/oxford-loses-top-3-university-ranking-for-the-first-time/"/><published>2025-09-21T15:51:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323856</id><title>LaLiga's Anti-Piracy Crackdown Triggers Widespread Internet Disruptions in Spain</title><updated>2025-09-21T19:32:33.787080+00:00</updated><content/><link href="https://reclaimthenet.org/laligas-anti-piracy-crackdown-triggers-widespread-internet-disruptions"/><published>2025-09-21T15:57:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323875</id><title>Show HN: Freeing GPUs stuck by runaway jobs</title><updated>2025-09-21T19:32:32.539144+00:00</updated><content>&lt;doc fingerprint="3418e90b4c302a81"&gt;
  &lt;main&gt;
    &lt;p&gt;A CLI tool for managing GPUs across NVIDIA, AMD, Intel, and Apple Silicon systems. Monitor, control, and secure your GPU infrastructure with ease.&lt;/p&gt;
    &lt;p&gt;Join our Discord community for discussions, support, and updates:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Monitor GPUs: Real-time usage, memory, temperature, and processes&lt;/item&gt;
      &lt;item&gt;Kill Processes: Gracefully terminate stuck GPU processes&lt;/item&gt;
      &lt;item&gt;Security: Detect crypto miners and suspicious activity&lt;/item&gt;
      &lt;item&gt;Guard Mode: Policy enforcement to prevent resource abuse&lt;/item&gt;
      &lt;item&gt;Dashboard: Web interface for cluster monitoring&lt;/item&gt;
      &lt;item&gt;Remote: Manage GPUs across multiple servers&lt;/item&gt;
      &lt;item&gt;Multi-Vendor: Works with NVIDIA, AMD, Intel, and Apple Silicon&lt;/item&gt;
      &lt;item&gt;AI Integration: MCP server for AI assistant integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;NVIDIA: NVIDIA drivers installed&lt;/item&gt;
      &lt;item&gt;AMD: ROCm drivers installed&lt;/item&gt;
      &lt;item&gt;Intel: intel-gpu-tools package installed&lt;/item&gt;
      &lt;item&gt;Apple Silicon: macOS with Apple Silicon (M1/M2/M3/M4)&lt;/item&gt;
      &lt;item&gt;OS: Linux, macOS, or Windows&lt;/item&gt;
      &lt;item&gt;Rust: 1.70+ (for building from source)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Build from source
git clone https://github.com/kagehq/gpu-kill.git
cd gpu-kill
cargo build --release

# Or install via Cargo
cargo install gpukill

# List your GPUs
gpukill --list

# Watch GPU usage in real-time
gpukill --list --watch&lt;/code&gt;
    &lt;code&gt;# Kill a stuck process
gpukill --kill --pid 12345 --force

# Reset a crashed GPU
gpukill --reset --gpu 0 --force

# Start the web dashboard (backend only)
gpukill --server --server-port 8080&lt;/code&gt;
    &lt;p&gt;Start the web interface for cluster monitoring:&lt;/p&gt;
    &lt;code&gt;# 1. Start the backend API server
gpukill --server --server-port 8080

# 2. Start the dashboard UI (in a new terminal)
cd dashboard
npm install  # First time only
npm run dev

# 3. Access the dashboard
open http://localhost:3000&lt;/code&gt;
    &lt;p&gt;Note: You need both the backend server (port 8080) and frontend UI (port 3000) running for the dashboard to work.&lt;/p&gt;
    &lt;p&gt;The dashboard provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time monitoring of all GPUs&lt;/item&gt;
      &lt;item&gt;Security detection with threat analysis&lt;/item&gt;
      &lt;item&gt;Policy management for resource control&lt;/item&gt;
      &lt;item&gt;Cluster overview with Magic Moment insights&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;GPU Kill includes a MCP server that enables AI assistants to interact with GPU management functionality:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Resources: Read GPU status, processes, audit data, policies, and security scans&lt;/item&gt;
      &lt;item&gt;Tools: Kill processes, reset GPUs, scan for threats, create policies&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Start the MCP server
cargo run --release -p gpukill-mcp

# Server runs on http://localhost:3001/mcp&lt;/code&gt;
    &lt;p&gt;Ask your AI to use the tools.&lt;/p&gt;
    &lt;code&gt;What GPUs do I have and what's their current usage?
&lt;/code&gt;
    &lt;code&gt;Kill the Python process that's stuck on GPU 0
&lt;/code&gt;
    &lt;code&gt;Kill all training processes that are using too much GPU memory
&lt;/code&gt;
    &lt;code&gt;Show me GPU usage and kill any stuck processes
&lt;/code&gt;
    &lt;code&gt;Scan for crypto miners and suspicious activity
&lt;/code&gt;
    &lt;code&gt;Create a policy to limit user memory usage to 8GB
&lt;/code&gt;
    &lt;code&gt;Reset GPU 1 because it's not responding
&lt;/code&gt;
    &lt;code&gt;What processes are currently using my GPUs?
&lt;/code&gt;
    &lt;p&gt;See mcp/README.md for detailed MCP server documentation.&lt;/p&gt;
    &lt;code&gt;# Scan for crypto miners and suspicious activity
gpukill --audit --rogue

# Configure detection rules
gpukill --audit --rogue-config&lt;/code&gt;
    &lt;code&gt;# Enable Guard Mode
gpukill --guard --guard-enable

# Test policies safely
gpukill --guard --guard-test-policies&lt;/code&gt;
    &lt;p&gt;For detailed security and policy documentation, see DETAILED.md.&lt;/p&gt;
    &lt;p&gt;Manage GPUs across multiple servers via SSH:&lt;/p&gt;
    &lt;code&gt;# List GPUs on remote server
gpukill --remote staging-server --list

# Kill process on remote server
gpukill --remote prod-gpu-01 --kill --pid 1234

# Reset GPU on remote server
gpukill --remote gpu-cluster --reset --gpu 0&lt;/code&gt;
    &lt;code&gt;gpukill --help                    # Show all options
gpukill --version                 # Show version&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DETAILED.md - Complete documentation, API reference, and advanced features&lt;/item&gt;
      &lt;item&gt;Dashboard README - Web interface documentation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the FSL-1.1-MIT License. See the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/kagehq/gpu-kill"/><published>2025-09-21T16:00:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45323901</id><title>Review: Project Xanadu – The Internet That Might Have Been</title><updated>2025-09-21T19:32:31.944141+00:00</updated><content>&lt;doc fingerprint="3f9c91321ca38a88"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Your Review: Project Xanadu - The Internet That Might Have Been&lt;/head&gt;
    &lt;head rend="h3"&gt;Finalist #12 in the Review Contest&lt;/head&gt;
    &lt;p&gt;[This is one of the finalists in the 2025 review contest, written by an ACX reader who will remain anonymous until after voting is done. I’ll be posting about one of these a week for several months. When you’ve read them all, I’ll ask you to vote for a favorite, so remember which ones you liked]&lt;/p&gt;
    &lt;head rend="h1"&gt;1. The Internet That Would Be&lt;/head&gt;
    &lt;p&gt;In July 1945, Vannevar Bush was riding high.&lt;/p&gt;
    &lt;p&gt;As Director of the Office of Scientific Research and Development, he’d won World War II. His proximity fuse intercepted hundreds of V-1s and destroyed thousands of tanks, carving a path for Allied forces through the French countryside. Back in 1942, he’d advocated to President Roosevelt the merits of Oppenheimer’s atomic bomb. Roosevelt and his congressional allies snuck hundreds of millions in covert funding to the OSRD’s planned projects in Oak Ridge and Los Alamos. Writing directly and secretively to Bush, a one-line memo in June expressed Roosevelt’s total confidence in his Director: “Do you have the money?”&lt;/p&gt;
    &lt;p&gt;Indeed he did. The warheads it bought would fall on Hiroshima and Nagasaki in mere weeks. The Germans had already given up; Victory in the Pacific was nigh. So Bush was thinking ahead.&lt;/p&gt;
    &lt;p&gt;In The Atlantic, Bush returned to a pre-war obsession with communication and knowledge-exchange. His essay, “As We May Think,” imagined a new metascientifical endeavor (emphasis mine):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Science has provided the swiftest communication between individuals; it has provided a record of ideas and has enabled man to manipulate and to make extracts from that record so that knowledge evolves and endures throughout the life of a race rather than that of an individual.&lt;/p&gt;
      &lt;p&gt;There is a growing mountain of research. But there is increased evidence that we are being bogged down today as specialization extends. The investigator is staggered by the findings and conclusions of thousands of other workers—conclusions which he cannot find time to grasp, much less to remember, as they appear. Yet specialization becomes increasingly necessary for progress, and the effort to bridge between disciplines is correspondingly superficial.&lt;/p&gt;
      &lt;p&gt;…&lt;/p&gt;
      &lt;p&gt;The difficulty seems to be, not so much that we publish unduly in view of the extent and variety of present day interests, but rather that publication has been extended far beyond our present ability to make real use of the record. The summation of human experience is being expanded at a prodigious rate, and the means we use for threading through the consequent maze to the momentarily important item is the same as was used in the days of square-rigged ships.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Bush thought we were ripe for a paradigm shift. Some new method of spreading research, connecting it across fields and domains, and making new discoveries in the in-betweens. The most exciting Next Big Thing of the era was microfilm, and so when Bush let his imagination run a little wild,1 he envisioned a machine enabling us to do grand new things with long books shrunk into tidy rolls:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Consider a future device for individual use, which is a sort of mechanized private file and library. It needs a name, and, to coin one at random, “memex” will do. A memex is a device in which an individual stores all his books, records, and communications, and which is mechanized so that it may be consulted with exceeding speed and flexibility. It is an enlarged intimate supplement to his memory.&lt;/p&gt;
      &lt;p&gt;It consists of a desk, and while it can presumably be operated from a distance, it is primarily the piece of furniture at which he works. On the top are slanting translucent screens, on which material can be projected for convenient reading. There is a keyboard, and sets of buttons and levers. Otherwise it looks like an ordinary desk.&lt;/p&gt;
      &lt;p&gt;In one end is the stored material. The matter of bulk is well taken care of by improved microfilm. Only a small part of the interior of the memex is devoted to storage, the rest to mechanism. Yet if the user inserted 5000 pages of material a day it would take him hundreds of years to fill the repository, so he can be profligate and enter material freely.&lt;/p&gt;
      &lt;p&gt;Most of the memex contents are purchased on microfilm ready for insertion. Books of all sorts, pictures, current periodicals, newspapers, are thus obtained and dropped into place. Business correspondence takes the same path. And there is provision for direct entry. On the top of the memex is a transparent platen. On this are placed longhand notes, photographs, memoranda, all sorts of things. When one is in place, the depression of a lever causes it to be photographed onto the next blank space in a section of the memex film, dry photography being employed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Not only could you read and even add to the memex—you could recombine and link works between each other with ease. “This is the essential feature of the memex. The process of tying two items together is the important thing,” Bush wrote. As a memex user explored his vast library of human thought, he could leave a “trail” of connected articles and photos and his own commentaries. He could connect these trails to one another, split them into fractally expanding branches, save them, and access them over and over again. He could even share his trails with friends, allowing them to insert copies into their own memexes, where they could be expanded and branched and shared again.&lt;/p&gt;
    &lt;p&gt;I’ll remind you—the year was 1945.&lt;/p&gt;
    &lt;head rend="h1"&gt;2. First Experiments in Hyper-cyber-space&lt;/head&gt;
    &lt;p&gt;Bush never did much to make his memex a reality. He was too busy building the National Science Foundation and trying to prevent a nuclear arms race. He had no time to fiddle around with desk-sized personal libraries, fighting Truman’s hawkish hyperfocus on hydrogen warheads.&lt;/p&gt;
    &lt;p&gt;But Doug Engelbart didn’t have much else to do.&lt;/p&gt;
    &lt;p&gt;He was a Navy man, a radar technician, just 20 years old when he shipped out of San Francisco. As he tells it, the entire crew were very nervous, seeing as they were being sent off to invade Japan. But just as the ship sailed past the Bay Bridge, “the captain came out on the bridge and looked down on us. ‘Japan just surrendered!’ he shouts. And suddenly all propriety leaves us, and we all say, ‘well then, for Christ’s sake, turn around!’”&lt;/p&gt;
    &lt;p&gt;Of course, they didn’t, and so Engelbart spent two years faffing around in the Philippines. He lived on a remote island with nothing to do but read and read and read. He spent his first five days camping out by a little stilt hut with a sign reading “Red Cross Library”—and in the Red Cross Library, there was a copy of the September 1945 issue of LIFE magazine in which Vannevar Bush’s description of the memex had been reprinted.&lt;/p&gt;
    &lt;p&gt;Engelbart claimed that he found the idea “intriguing,” but had lots of radar-technician-ing to do or something, and so it didn’t really resurface for him until 15 years later, when he was writing his Augmenting Human Intellect: A Conceptual Framework. Engelbart quoted heavily from Bush’s article, and commented:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The associative trails whose establishment and use within the files he describes at some length provide a beautiful example of a new capability in symbol structuring that derives from new artifact-process capability, and that provides new ways to develop and portray concept structures. Any file is a symbol structure whose purpose is to represent a variety of concepts and concept structures in a way that makes them maximally available and useful to the needs of the human's mental-structure development—within the limits imposed by the capability of the artifacts and human for jointly executing processes of symbol-structure manipulation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;After his Framework was published in 1962, under the Stanford Research Institute, Engelbart founded the Augmentation Research Center to make, in essence, some version of the Memex a reality. The ARC received funding from NASA and ARPA, and after six years, Engelbart released his oN-Line System (NLS). It was a revelation.&lt;/p&gt;
    &lt;p&gt;Engelbart had invented a vast array of tools—including, according to his own Institute:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;the mouse&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;2-dimensional display editing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;in-file object addressing, linking&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;hypermedia&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;outline processing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;flexible view control&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;multiple windows&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;cross-file editing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;integrated hypermedia email&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;hypermedia publishing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;document version control&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;shared-screen teleconferencing&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;computer-aided meetings&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;formatting directives&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;context-sensitive help&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;distributed client-server architecture&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;uniform command syntax&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;universal "user interface" front-end module&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;multi-tool integration&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;grammar-driven command language interpreter&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;protocols for virtual terminals&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;remote procedure call protocols&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;compilable "Command Meta Language"&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Live on stage, in the year 1968, Engelbart started up the NLS, opened a document, and typed some words into it. The words, he said, constituted a statement. And statements made up a file. Engelbart copied, manipulated, saved, and loaded his words and statements and files, zipping around with his newly-invented mouse. He demonstrated his ability to embed documents in one another—images with links to statements, words nested and categorized by one another, files filled with metadata.&lt;/p&gt;
    &lt;p&gt;And then he paused, and the screen went blank. He explained that he and his colleagues at the ARC had been using this system to do their daily work for the last six months. He mentioned that they had, now, six consoles up and running. He showed the crowd a real document, then navigated to a statement within it. “This presentation is devoted to the AHIRC.”&lt;/p&gt;
    &lt;p&gt;“What is the AHIRC?” he asked.&lt;/p&gt;
    &lt;p&gt;Engelbart “froze” the initial statement, clicked on the acronym, and below the words “Augmented-Human-Intellect Research Center” appeared. He kept clicking and freezing, and a trail of nested and related information appeared—a list of funders, a graph of staffing over time, a mission statement. This was hypermedia. These were hyperlinks, he explained. NLS was a hypertext system.&lt;/p&gt;
    &lt;p&gt;The presentation went on for 90 minutes longer, and became known as The Mother of All Demos.2 At around the 75-minute mark, Engelbart shows that two different NLS users could edit a single document simultaneously. While this was extremely impressive functionality, it was achieved with time-sharing—computation was done on a single machine, switching rapidly between tasks—and became infeasible the very next year, when ARPANET was released and the number of machines you could connect to one system grew rapidly.&lt;/p&gt;
    &lt;p&gt;Engelbart’s hypertext system was impressive in its own right, even without collaborativity. And still, little came of it—Andy van Dam, an attendee and revolutionary computer scientist himself, would reflect decades later: “Everybody was blown away … and nothing else happened. There was almost no further impact.” Engelbart’s ideas were just a little too out there.&lt;/p&gt;
    &lt;p&gt;ARC quickly faded into obscurity. In 1972, Engelbart joined an organization called Erhard Seminars Training. EST, or “est” as it was marketed, offered a 60-hour self-improvement course for tech entrepreneurs modeled loosely on Zen Buddhism. Critics suggested that the est course was a mind-control method aimed at raising an authoritarian army. It was quite credibly branded a cult. The founder of est, Werner Erhard, was accused of tax fraud (he fought the claims and won $200,000 from the IRS) and incest (by his daughter, who later recanted).&lt;/p&gt;
    &lt;p&gt;Engelbart served, for many years, on est’s board of directors.&lt;/p&gt;
    &lt;p&gt;His researchers all left for greener, less cult-y pastures, and ARC died with hardly a whimper. No one really wanted to associate with Engelbart. His crackpot theories about an internet modeled after the memex fell into disrepute, and, if he was remembered at all, it was for the invention of the mouse. No one cared anymore about the memex, or hypertext.&lt;/p&gt;
    &lt;head rend="h1"&gt;3. Hyper-dreams of Hyper-everything&lt;/head&gt;
    &lt;p&gt;Well, one man cared.&lt;/p&gt;
    &lt;p&gt;Ted Nelson was born in 1937 to two twenty-year-olds, Ralph Nelson and Celeste Holm. His parents divorced in 1939, leaving him to be raised by his grandparents. Both Nelson (the elder) and Holm would go on to extremely-successful film careers: the former became an Emmy-winning director; the latter an Oscar-winning actress. And, at first, Ted seemed to be following in their footsteps.&lt;/p&gt;
    &lt;p&gt;As a philosophy major at Swarthmore College, he produced a film called The Epiphany of Slocum Furlow, which he described as “a short comedy about loneliness at college and the meaning of life.”3 Nelson also claims to have “[d]irected [and written] book and lyrics for what was apparently the first rock musical” in his junior year at Swarthmore.&lt;/p&gt;
    &lt;p&gt;Thankfully, his interest in a career as an entertainer soon waned, and Nelson went off to study sociology in grad school—first at the University of Chicago, then at Harvard. Nelson took a computer class at Harvard, in 1960, and “[his] world exploded.”4 He realized the incredible power of computing, quickly intuited that these new machines could be generally applied to everything, and founded Project Xanadu.5&lt;/p&gt;
    &lt;p&gt;Initially, Xanadu’s scope was pretty limited. Word processors weren’t around yet, but Nelson wanted to build something strikingly similar: he wanted to write a program that could store and display documents, with version histories and edits all stored and displayed at the same time too. Later, Nelson would call this version-history feature “intercomparison.” (Strange coinages will be a… theme; I’m just trying to get you ready.)&lt;/p&gt;
    &lt;p&gt;Nelson began working on an implementation, but his feature wishlist grew quickly, and he didn’t really know what he was doing, so in 1965, he sought help. He prepared a talk for the Association for Computing Machinery, and dropped, quite frankly, a bomb on the audience:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The kinds of file structures required if we are to use the computer for personal files and as an adjunct to creativity are wholly different in character from those customary in business and scientific data processing. They need to provide the capacity for intricate and idiosyncratic arrangements, total modifiability, undecided alternatives, and thorough internal documentation.&lt;/p&gt;
      &lt;p&gt;The original idea was to make a file for writers and scientists, much like the personal side of Bush's Memex, that would do the things such people need with the richness they would want. But there are so many possible specific functions that the mind reels. These uses and considerations become so complex that the only answer is a simple and generalized building-block structure, user-oriented and wholly general-purpose.&lt;/p&gt;
      &lt;p&gt;The resulting file structure is explained and examples of its use are given.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Ted Nelson was building the memex.&lt;/p&gt;
    &lt;p&gt;Of course, he wasn’t a very technical guy, and so his talk mostly focused on the philosophy of Xanadu, not its implementation. He commented (emphasis mine):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There are three false or inadequate theories of how writing is properly done. The first is that writing is a matter of inspiration. While inspiration is useful, it is rarely enough in itself. “Writing is 10% inspiration, 90% perspiration,” is a common saying. But this leads us to the second false theory, that “writing consists of applying the seat of the pants to the seat of the chair.” Insofar as sitting facilitates work, this view seems reasonable, but it also suggests that what is done while sitting is a matter of comparative indifference; probably not.&lt;/p&gt;
      &lt;p&gt;The third false theory is that all you really need is a good outline, created on prior consideration, and that if the outline is correctly followed the required text will be produced. For most good writers this theory is quite wrong. Rarely does the original outline predict well what headings and sequence will create the effects desired: the balance of emphasis, sequence of interrelating points, texture of insight, rhythm, etc. We may better call the outlining process inductive: certain interrelations appear to the author in the material itself, some at the outset and some as he works. He can only decide which to emphasize, which to use as unifying ideas and principles, and which to slight or delete, by trying. Outlines in general are spurious, made up after the fact by examining the segmentation of a finished work. If a finished work clearly follows an outline, that outline probably has been hammered out of many inspirations, comparisons and tests.&lt;/p&gt;
      &lt;p&gt;Between the inspirations, then, and during the sitting, the task of writing is one of rearrangement and reprocessing, and the real outline develops slowly. The original crude or fragmentary texts created at the outset generally undergo many revision processes before they are finished. Intellectually they are pondered, juxtaposed, compared, adapted, transposed, and judged; mechanically they are copied, overwritten with revision markings, rearranged and copied again. This cycle may be repeated many times. The whole grows by trial and error in the processes of arrangement, comparison and retrenchment.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Nelson recognized that the creation of knowledge is cyclical, recursive, self-referential. And he figured that our computer systems should accept and reflect that process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If a writer is really to be helped by an automated system, it ought to do more than retype and transpose: it should stand by him during the early periods of muddled confusion, when his ideas are scraps, fragments, phrases, and contradictory overall designs. And it must help him through to the final draft with every feasible mechanical aid—making the fragments easy to find, and making easier the tentative sequencing and juxtaposing and comparing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How do you design such a system? To navigate intuitively within complex file systems, between document versions, and across source materials—to access all the scraps and fragments writers need to write—you would need to establish what Vannevar Bush called “tracks.” You would need to connect and save different ideas, linking them together. That was it—you needed links.&lt;/p&gt;
    &lt;p&gt;Nelson went further, though—it wouldn’t do to simply have links to all the other files, a writer needed to see the other files before him, needed them to be brought up and displayed alongside his current work on demand. The links needed to contain their targets within themselves—so Nelson called them hyperlinks. And he called text embedded with hyperlinks hypertext, and movies embedded in his structure became hyperfilms, and so on. Nelson wanted us using computers to write and create self-referential, intricately-interconnected (“intertwingled,” as he’d later put it), eminently-accessible hypermedia.&lt;/p&gt;
    &lt;p&gt;And recall, in 1965, state-of-the-art computing looked like this.&lt;/p&gt;
    &lt;p&gt;Ted Nelson was thinking far, far ahead.&lt;/p&gt;
    &lt;p&gt;Maybe too far ahead. Conference attendees were initially excited about his idea, but when he revealed himself to know very little about the technical task of building Xanadu—or even whether it was possible at all—interest evaporated.&lt;/p&gt;
    &lt;head rend="h1"&gt;4. Failing to Develop Xanadu&lt;/head&gt;
    &lt;p&gt;But Nelson was all in. He would later write, “This is not a technical issue, but rather moral, aesthetic and conceptual.” Nelson loved knowledge and connection and abstraction—mere technical details wouldn’t stop him from building the best possible computer system for producing and consuming information.&lt;/p&gt;
    &lt;p&gt;He met Doug Engelbart in the mid 60s, forming a friendship with the only other man taking hypertext seriously at the time, and hopped around unhappily between various academic and scientific appointments. At one point, he and Andy van Dam worked together and produced the Hypertext Editing System—released in 1967, just before Engelbart’s NLS. It was the first computer application to ever have an “undo” button—Nelson claims to this day that he invented it (and the “back” button).&lt;/p&gt;
    &lt;p&gt;Shortly thereafter, Nelson’s wife left him. In his 2010 autobiography, he writes, “She, reasonably, wanted a Nice Life; women want that sort of thing.” They had a son, whom Nelson continued to visit regularly. “Debbie has been a friend and great support all these years,” Nelson adds. “[S]he believed in me.”&lt;/p&gt;
    &lt;p&gt;Nelson gave a talk at Union Theological Seminary in 1968 that included this slide, which Nelson considers “the first depiction of what the personal computer turned out to be.”&lt;/p&gt;
    &lt;p&gt;Around the same time, Nelson claims to have called Vannevar Bush and told him about Project Xanadu. Bush “wanted very much to discuss it with” Nelson, but Nelson “hated him instantly [because] he sounded like a sports coach” and never contacted him again. This, of course, proved to be extremely self-destructive (though I can’t honestly say I would’ve done otherwise).&lt;/p&gt;
    &lt;p&gt;Because Xanadu was as good as dead. No one would give him the money he needed to work on it, especially not after Doug Engelbart poisoned the idea of hypertext.&lt;/p&gt;
    &lt;p&gt;Nelson went where there was funding, working briefly on an early word processor called Juggler of Text (JOT). …And then he lost investment, stopped working on the project, and moved to Chicago, where he’d been offered a job teaching at the University of Illinois, to start work on a book. He would call it Computer Lib.&lt;/p&gt;
    &lt;p&gt;In fact, he started work on another book at the same time, called Dream Machines. By the time he completed each of them, in 1974, ARPANET had been released, and his vision for Project Xanadu had evolved. He published the two works together—Computer Lib was his lamentation over the industry’s disdain for hypertext, and Dream Machines was Xanadu’s manifesto.&lt;/p&gt;
    &lt;p&gt;Nelson designed and printed the book himself. Its pages mostly look like this:&lt;/p&gt;
    &lt;p&gt;Self-referential, multimedia, creative, and fun—they were a blueprint for the internet he was building. In the Dream Machines half, Nelson writes, “The real dream is for ‘everything’ to be in the hypertext. Everything you read, you read from the screen (and can always get back to right away; everything you write, you write at the screen (and can cross-link to whatever you read).”&lt;/p&gt;
    &lt;p&gt;In one section Nelson asks himself, “Can It Be Done?” His answer: “I dunno.”&lt;/p&gt;
    &lt;p&gt;Remember, Xanadu wouldn’t only involve links between works—it required hyperlinks, which as Nelson understood them, would need to contain the targets in themselves. (Eventually, Nelson would give these embeddings a new name—“transclusions”—and hyperlink came to simply mean “link between hypertext files.”) Every link would run both ways, each hypertext file would know exactly which other files were linked to it and how.&lt;/p&gt;
    &lt;p&gt;This introduced a few problems, in the new interconnected ARPANET age:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;How do you keep track? Where’s the metadata stored? Can you afford enough space for it all?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Who’s keeping track? Nelson was already, allegedly, approached by the CIA over this all—how do you make sure hypertext is a free, democratizing technology that doesn’t spread government propaganda?&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;What do you do about intellectual property? You don’t want everyone to be able to link everyone else’s work if each link contains the work itself—how do you ensure that people still get paid for their ideas?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Nelson answered (in 1974):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The docuverse keeps track! Xanadu wouldn’t simply be a platform for linkage—it would be the repository for all existing connections between human thought. It would be a universal library.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Storage of the docuverse will be distributed, people can use pseudonyms, and eventually we’ll figure out some good system for authenticating the texts everyone’s linking to.6&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Simply put a royalty on the links. If you want to reference a copyrighted New York Times article, then you’ve got to pay the author a little bit. And if someone else links to what you’ve written, then you get a small payout. Presumably, you could build in caveats for short excerpts and fair use kinds of things—“a universal flexible rule [still] has to be worked out.”&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;He helpfully diagrammed the whole idea, in case it was at all confusing:&lt;/p&gt;
    &lt;p&gt;A pay-per-click system like Nelson described would first be implemented in 1996.&lt;/p&gt;
    &lt;p&gt;Computer Lib/Dream Machines became a cult favorite, and Nelson began to gather a small following. In 1979, he moved back to Swarthmore with a group of disciples, and they got to work. The crack team included:7&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Roger Gregory, a University of Michigan graduate and Ann Arbor local who’d been corresponding over telephone with Nelson since reading Computer Lib in 1974. Gregory was a whiz with hardware, but suffered from regular bouts of depression, sometimes so strong they would render him “incapable of working.” Gregory paid for the house in Pennsylvania.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mark Miller, a mathematical wunderkind who’d read Computer Lib and grokked it so hard that Nelson invited him to give a lecture to his UIC class when Miller was just 19, and a sophomore at Yale. The students all thought Nelson was crazy, and so they thought Miller was crazy too. Nelson thought him a genius.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stuart Greene was a UIC student who thought Nelson and Miller might not be so crazy. He was invited to Pennsylvania too. Nelson, in his autobiography, describes Greene as “the mystic who’d taught holography at 14.”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Roland King, a linguist who, like Nelson, was super into an evangelical Christianity–associated theory of linguistics called “tagmemics.” I can’t make heads or tails of it, but Nelson describes it as a “romantic [extension] of the linguistic ideal.”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Eric Hill, a 15-year-old hacker and indicted felon, who “had been dismissed by the judge with admiration.”&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In Swarthmore, Nelson hoped his decades-old dream of Xanadu would finally materialize.&lt;/p&gt;
    &lt;head rend="h1"&gt;5. Developing Xanadu&lt;/head&gt;
    &lt;p&gt;Ted Nelson had built Project Xanadu into, for lack of better terminology, a cult.8 He writes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We all were deeply concerned about the Bad Guys, who we saw as a combination of IBM and the government. (The others were all Libertarians, I still called myself a Cynical Socialist.) The Bad Guys would spy on people, withhold and block information, and give us inferior hypertext. We had to Do It Right, to help prevent this.&lt;/p&gt;
      &lt;p&gt;This meant using the standard business defenses—especially non-disclosure agreements (I made all of them sign) and secret proprietary algorithms.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The Xanadians had a messiah—Ted Nelson—a gospel—Computer Lib—a persecution complex, a fearful dystopia—“inferior hypertext”—a hopeful utopia—Xanadu—and utter secrecy. Just six dudes in a rented house near Philly, building the internet, hiding from the Feds, signing NDAs, and saving the world.&lt;/p&gt;
    &lt;p&gt;Nelson spent a summer explaining the project to his team in its entirety. By the end, Gregory, Miller, and Greene were the only ones left. They told Nelson, “We’ll do it,” and moved to another suburb, where they finally began to work on an implementation of Xanadu. The three quickly figured out a new system that would allow users to reference and link to specific parts of a file—they called these links tumblers, and made them work with transfinite numbers. Suddenly, transclusions were really possible.&lt;/p&gt;
    &lt;p&gt;But after only a few early successes, the team’s progress stalled completely. Greene and Miller were young and left for jobs elsewhere, and so Gregory was left working on Xanadu alone.&lt;/p&gt;
    &lt;p&gt;Nelson, meanwhile, ran a magazine called Creative Computing for a while, then tried again to build his JOT word processor—this time for the Apple II—then spent a year in San Antonio pitching a watered-down version of Xanadu (rebranded as “Vortext”) to a tech company called Datapoint. Datapoint wasn’t buying, but kept Nelson on in some sort of fake, primitive email job anyway.&lt;/p&gt;
    &lt;p&gt;Gregory kept working on Xanadu in Philadelphia, slowly running out of money. Ted Nelson held an “Ecstasy party” in San Antonio: “A number of us floated down the river on inner tubes. It was quite lovely.”&lt;/p&gt;
    &lt;p&gt;In 1987, like he did every year, Roger Gregory went to The Hackers Conference in Saratoga to show off the latest unimpressive version of Xanadu. There, he met a man named John Walker—founder of the wildly successful Autodesk—and pitched the project to him. Incredibly, Walker was interested, and after tense negotiations with Nelson, agreed to fund Xanadu in earnest.&lt;/p&gt;
    &lt;p&gt;Beginning in 1988, Autodesk poured millions of dollars into the project, and a programming team led by Gregory finally started to make real progress. Walker said of Xanadu: “In 1980, it was the shared goal of a small group of brilliant technologists. By 1989, it will be a product. And by 1995, it will begin to change the world.”&lt;/p&gt;
    &lt;p&gt;Sweeping rhetoric—clear deadlines.&lt;/p&gt;
    &lt;p&gt;The team came nowhere close to meeting them. Infighting broke out between two factions—while Gregory simply wanted to patch together his old C code, insisting his product “was within six months of shipping,” the whiz-kid Mark Miller came back from his new job at Xerox PARC, alongside a half-dozen of his closest friends, and insisted on a perfectionistic rewrite in a more flexible language, Smalltalk.&lt;/p&gt;
    &lt;p&gt;The PARC faction began to drive Gregory up the wall. According to Nelson, it got to the point that he “was throwing things and acting crazy.” So Nelson called John Walker, the two “summoned Roger to meet [them] at John’s house at Muir Beach, and Walker told Roger he was no longer in charge.”&lt;/p&gt;
    &lt;p&gt;Miller took over and began the rewrite in Smalltalk. Walker’s deadline came and went, and the team delivered nothing. Xanadu’s offices descended into chaos—Miller anointed two PARC programmers to be “co-architects,” and the three of them increasingly left the rest of the team out of the loop. For four years, Miller dawdled about, adding features, giving them clever names (files were “berts,” after Bertrand Russell, and so, for symmetry’s sake, royalty-generating transclusions became “ernies”), and never building them.9&lt;/p&gt;
    &lt;p&gt;Meanwhile, Ted Nelson was living on a houseboat, attending sex retreats and Keristan orgies, and giving talks in Singapore. He recorded a new soundtrack for his student film, the one from 1959.&lt;/p&gt;
    &lt;p&gt;In 1992, Autodesk’s stock cratered, and they divested entirely from Xanadu. Miller lamented that his program was just six months from completion.&lt;/p&gt;
    &lt;p&gt;Ted Nelson started a film studio to make a movie with Doug Engelbart, then left for Japan to get a PhD.&lt;/p&gt;
    &lt;p&gt;Xanadu’s code was open-sourced in the late 90s.&lt;/p&gt;
    &lt;head rend="h1"&gt;6. The World Wide Web&lt;/head&gt;
    &lt;p&gt;In March 1989, a British computer scientist named Tim Berners-Lee, working at CERN, wrote a proposal for a system unifying hypertext and the internet. It was ignored.&lt;/p&gt;
    &lt;p&gt;In 1990, Berners-Lee resubmitted his proposal, it was accepted, and he began to work on the World Wide Web.&lt;/p&gt;
    &lt;p&gt;The WWW had a number of advantages over Xanadu:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;It was much simpler—Ted Nelson wrote of it disparagingly: “Where were annotation and marginal notes? Where was version management? Where was rights management? Where were multi-ended links? Where were third-party links? Where were transclusions? This ‘World Wide Web’ was just a lame text format and a lot of connected directories.” As it turns out, it’s much easier to build a lame text format and a lot of connected directories!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It had institutional buy-in from the start. CERN was huge, it saw promise in the WWW, and it gave Berners-Lee plenty of funding, latitude, and staffing.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tim Berners-Lee wasn’t a self-important lunatic. He didn’t join cults, nor did he start them. He didn’t attend sex workshops, nor did he intern at them. He was British and proper and serious, and so people took him and his work Britishly, properly, and seriously.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And so, despite Xanadu’s 30-year head start, the Web won the race.&lt;/p&gt;
    &lt;p&gt;By the occasion of Autodesk’s divestiture from Xanadu, everyone knew Berners-Lee’s creation was the Next Big Thing. It was released publicly in 1993—four years past John Walker’s deadline for Xanadu—and Netscape went public in 1995—Walker’s revolution came right on schedule.&lt;/p&gt;
    &lt;p&gt;But what kind of revolution was it, exactly?&lt;/p&gt;
    &lt;head rend="h1"&gt;7. This Is Hell.&lt;/head&gt;
    &lt;p&gt;Ted Nelson pulls no punches.&lt;/p&gt;
    &lt;p&gt;Think about the Web we have today. The 2.0 and 3.0 (however you choose to identify it) revolutions included.&lt;/p&gt;
    &lt;p&gt;What parts of Nelson’s wishlist have we checked off? What are we missing?&lt;/p&gt;
    &lt;p&gt;Ultimately the Web really is “just a lame text format and a lot of connected directories.” We’re reading and writing, publishing new kinds of media, calling up documents like crazy, democratizing publication to a fault, and… ah. Well, that’s all.&lt;/p&gt;
    &lt;p&gt;Vannevar Bush wrote, in 1945 (emphasis mine):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Our ineptitude in getting at the record is largely caused by the artificiality of systems of indexing. When data of any sort are placed in storage, they are filed alphabetically or numerically, and information is found (when it is) by tracing it down from subclass to subclass. It can be in only one place, unless duplicates are used; one has to have rules as to which path will locate it, and the rules are cumbersome. Having found one item, moreover, one has to emerge from the system and re-enter on a new path.&lt;/p&gt;
      &lt;p&gt;The human mind does not work that way. It operates by association. With one item in its grasp, it snaps instantly to the next that is suggested by the association of thoughts, in accordance with some intricate web of trails carried by the cells of the brain. It has other characteristics, of course; trails that are not frequently followed are prone to fade, items are not fully permanent, memory is transitory. Yet the speed of action, the intricacy of trails, the detail of mental pictures, is awe-inspiring beyond all else in nature.&lt;/p&gt;
      &lt;p&gt;Man cannot hope fully to duplicate this mental process artificially, but he certainly ought to be able to learn from it. In minor ways he may even improve, for his records have relative permanency. The first idea, however, to be drawn from the analogy concerns selection. Selection by association, rather than indexing, may yet be mechanized.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Unlike Doug Engelhart, and unlike Ted Nelson, Tim Berners-Lee never read about Bush’s memex. He built a system that connected people like never before—but made little effort to facilitate the connection of ideas. There are no trails on the World Wide Web—instead, there are misattributed quotes, dead one-way links, constant plagiarism scandals, and widespread misinformation and mutual distrust. It’s often said that we’re living in a ‘post-truth society’. The words we write and videos we share have become entirely unmoored from the ideas underlying them. Strangely, the Web has facilitated more disconnection than was ever possible before.&lt;/p&gt;
    &lt;p&gt;Ted Nelson, in his own oblique and dodgy way, predicted the failure mode we’re now seeing: “This is not a technical issue, but rather moral, aesthetic and conceptual.” We built our global information-sharing system quickly, efficiently, and technically, when we should’ve treated it as a philosophical and aesthetic puzzle as much as a computational one, and built carefully and precisely.&lt;/p&gt;
    &lt;p&gt;Tim Berners-Lee took inspiration from the artificial citation and index and reference paradigm of old—he simply scaled up the paper-based system that Vannevar Bush knew was getting out of hand in the 1940s. He gave us a Web shaped like a machine—not a memex shaped like a mind—and then let everyone in the world talk to everyone else on his alien, unwelcoming platform. He built a cold and inhuman Web—so why would we be shocked that the online world became a cold and inhuman one?&lt;/p&gt;
    &lt;head rend="h1"&gt;8. Whither Xanadu?&lt;/head&gt;
    &lt;p&gt;It’s extremely hard to like Ted Nelson once you’ve read his autobiography. For instance, in the space of just two pages, he writes about how incredibly virtuous he is for not selling out to Bill Gates, that “friends often tell [him], ‘Oh, you should get a MacArthur Genius Grant!’,” and that Robin Williams once “squatted down beside” him and said: “I think it’s wonderful what you’ve done for the world.”&lt;/p&gt;
    &lt;p&gt;I don’t think I want to be Ted Nelson’s friend. He very clearly believes that he’s the Internet Messiah.&lt;/p&gt;
    &lt;p&gt;The only thing that gives me pause is that he might be right.&lt;/p&gt;
    &lt;p&gt;In 2014, a primitive Xanadu demo was released on the Web. (If you have a Windows machine, another nicer-looking demo exists for you to download.) I mean it when I say “primitive.” This isn’t close to the full product Nelson has been promising since 1965.&lt;/p&gt;
    &lt;p&gt;But as you play with the demo, scrolling and clicking around, you might just catch a glimpse. It’s all right there. All of the underlying ideas—the scraps and fragments of our nonlinear, recursive thought—traced back to their source. If you squint, almost to the point of closing your eyes, but not quite—you can just make it out. A hypertext system with connection, accountability, verifiability. A mind-shaped system—a real memex.&lt;/p&gt;
    &lt;p&gt;Maybe it looks a little unnatural, what you see when you squint at Xanadu—what a pain it would be to write in a Xanadu editor, you think. How ugly is that design!&lt;/p&gt;
    &lt;p&gt;But give the sight a little charity—imagine billions of dollars, maybe trillions, poured into Xanadu. Making it more beautiful, more intuitive. Imagine you’d never seen the Web before—no habits built, no understanding of what a webpage could or should be. What’s so wrong with Xanadu?&lt;/p&gt;
    &lt;p&gt;Why shouldn’t the internet look (and work) a little more like this?&lt;/p&gt;
    &lt;p&gt;For that matter, why doesn’t it?&lt;/p&gt;
    &lt;p&gt;Xanadu had a huge head start. Ted Nelson coined the term “hypertext.” He was doing all of this way before anyone else. He had a mind for design, he was smart, he was charismatic. Why didn’t he become the Steve Jobs of the Web?&lt;/p&gt;
    &lt;p&gt;I think we can, in large part, trace it back to Doug Engelbart, who, by blind, dumb luck, found himself on a remote Philippine island for two years with nothing to do but hang out in a big hut full of magazines. And there he happened to read Vannevar Bush’s essay, and then, fifteen years later, the thought happened to pop back into his head, and he happened to be a little better positioned, a little better at technology than Ted Nelson, and so he happened to make comprehensive hypertext a highly-visible reality before anyone else.&lt;/p&gt;
    &lt;p&gt;And then Engelbart joined and helped lead a mind-control cult, and so everyone became very wary of hypertext projects—especially hypertext projects led by cult-y weirdos—and then when Ted Nelson spent decades trying to get anyone interested in Xanadu, anyone at all, they just wouldn’t fund him.&lt;/p&gt;
    &lt;p&gt;Of course, Nelson deserves plenty of blame too. In many ways, he really was a nutjob, and he certainly wasn’t capable of building Xanadu on his own—still, the concept itself was solid! If Nelson hadn’t turned down Vannevar Bush and Bill Gates and Robin Williams and the half-dozen other famous people he claims were kissing his ass at one point or another, maybe someone sometime could’ve figured out how to build it for him. But he couldn’t do it. Nelson was too busy play-acting as a great, tortured, persecuted genius. By the time he’d become pacified enough to let Autodesk help him build Xanadu, he was too pacified to exercise any sort of authority or discipline over his project anymore. He just went to his sex parties and watched it all burn.&lt;/p&gt;
    &lt;head rend="h1"&gt;9. Lo and Behold&lt;/head&gt;
    &lt;p&gt;In 2016, Werner Herzog made a documentary called Lo and Behold, Reveries of the Connected World. In an interview after the film was released, Herzog explained his motivation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I think we have to abandon this kind of false security that everything is settled now, that we have so much assistance by digital media and robots and artificial intelligence. At the same time, we overlook how vulnerable all this is, and how we are losing the essentials that make us human.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In Lo and Behold, between conversations with TCP/IP inventor Bob Kahn and a baby-faced non-insane Elon Musk, around the 11-minute mark, Herzog visits Ted Nelson on his houseboat.&lt;/p&gt;
    &lt;p&gt;His narration explains that Nelson has often been called insane. On screen, the near-octogenarian explains, as lucidly and self-importantly as ever: “There are two contradictory slogans: one is that continuing to do the same thing and expecting a different result is the definition of insanity. On the other hand, you say, ‘if at first you don’t succeed, try, try again.’ I prefer the latter. Because I don’t want to be remembered as the guy who didn’t.” Herzog replies: “To us, you appear to be the only one around who is clinically sane.”&lt;/p&gt;
    &lt;p&gt;The two shake hands, and Nelson produces a small camera from his pocket, taking a photo of Herzog and his crew. No doubt, he will file the picture somewhere in his vast, interlinked personal archives, where it will sit and wait, until the day that Xanadu is finally launched, to be uploaded to a true digital memex.&lt;/p&gt;
    &lt;p&gt;By all accounts, that day is only six months away.&lt;/p&gt;
    &lt;p&gt;Before getting onto the information-sharing mechanisms of the future, Vannevar Bush did a little imagining about information-recording too: he suggested that Bell Labs’ Vocoder (an early mechanical phoneme-to-text system) could be combined with a stenotype (a human operated, much more extensive, speaking speed–capable phoneme-to-text system) to produce a working speech-to-text machine. Then researchers would have no need to learn typing or to hire a secretary—they could simply speak their findings aloud, and have them automatically entered into the record! It’s interesting to me how this both absolutely came to be—lots of people use very impressively functional speech-to-text systems nowadays—and also largely didn’t—I typed the words you’re reading now with my own non-automated hands. This theme will recur—Bush having very good and important ideas that everyone claims inspiration from, but actually end up mostly perverting or ignoring.&lt;/p&gt;
    &lt;p&gt;Bush also wrote, presciently-though-not-quite-as-presciently-as-Turing-ly, that “[w]e may some day click off arguments on a machine with the same assurance that we now enter sales on a cash register.” He thought this would be a fairly deterministic process—eventually we’d find some way to encode our semantics perfectly into computer-readable symbols, and then we could use those new computer-readable symbols to construct logical arguments. This isn’t really what today’s arguing-machines do at all, but if you squint enough, it’s not a terribly inaccurate picture.&lt;/p&gt;
    &lt;p&gt;It’s on Youtube; I think you should watch it. When I was younger, my dad had me watch Steve Jobs’ iPhone presentation; held it up as a prime example of tech and sales, innovation and elegance all rolled up. I liked it at the time. Now, having watched Engelbart’s presentation, I recognize it for what it is: patronizing, mass-market garbage. It’s just nowhere near as cool.&lt;/p&gt;
    &lt;p&gt;This one’s on Youtube too. I don’t really recommend it. It’s pretty much what you’d expect upon hearing the description “late 1950s experimental student film about being a college student.” In some regard, it’s impressive for what it is, but it’s also very much what it is.&lt;/p&gt;
    &lt;p&gt;Here, I’m quoting Nelson’s autobiography, published in 2010. It’s called POSSIPLEX: Movies, Intellect, Creative Control, My Computer Life and the Fight for Civilization, and it’s even weirder than the title suggests.&lt;/p&gt;
    &lt;p&gt;Taking a page out of Jon Bois’ playbook, I’m gonna recommend you stop here for a moment, put on your headphones, turn the volume down to a not-so-misophonic level, and listen to twenty seconds or so of “Doomed Moon” from the 32-second mark, while staring unblinkingly at the words Project Xanadu. Your reading experience will be much enhanced.&lt;/p&gt;
    &lt;p&gt;In the 1987 edition of Computer Lib/Dream Machines, Nelson writes, “these are now called ‘authentication systems;’ very sophisticated ones exist, and the government is trying to suppress them.” He’s referring to public key cryptography, which wasn’t invented until 1976, and how an NSA official named Joseph A. Meyer had contacted three researchers—named Rivest, Shamir, and Adleman—just before they released a paper in 1977 that introduced a revolutionary new cryptosystem based on the public-key breakthrough.&lt;/p&gt;
    &lt;p&gt;My description of these men comes both from Nelson’s autobiography and from a classic article in the June 1995 edition of WIRED magazine called “The Curse of Xanadu.” The author, Gary Wolf, takes a somewhat less charitable view of Ted Nelson than I do: he describes Xanadu as “the longest-running vaporware project in the history of computing” and Nelson as “the king of unsuccessful software development.” In my view, the last 30 years of internet history have been extremely kind to Nelson’s legacy, and are reason to disregard much of Wolf’s snottiness in the article. (I do still recommend reading it, though, for a more detailed play-by-play of Xanadu’s history.)&lt;/p&gt;
    &lt;p&gt;What is it with hypertext pioneers and cults? I wonder if this simply has to do with the fact that these guys were so ahead of their time—the big guys like Tim Berners-Lee didn’t even start thinking about hypertext until 1980. Nelson had, at this point, been at it for 20 years—the kind of person who does that is also the kind of person who writes in his autobiography, “I knew ten times more fifty years ago, when I started in computers, than most people think I know now,” and also absolutely the kind of person who starts a cult.&lt;/p&gt;
    &lt;p&gt;Well, the team did manage one accomplishment during these years: in 1990, Robin Hanson showed up and ran the first ever corporate prediction market at Xanadu. Its employees assigned a 7% probability to verification of the cold fusion experiment in the next year, and a 70% probability to releasing Xanadu before Deng Xiaoping died. Cold fusion was debunked, and Deng died long before any version of Xanadu would be released. Bonus trivia: this story from Robin Hanson is how I first learned of Xanadu’s existence!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.astralcodexten.com/p/your-review-project-xanadu-the-internet"/><published>2025-09-21T16:03:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45324343</id><title>Google/timesketch: Collaborative forensic timeline analysis</title><updated>2025-09-21T19:32:31.444302+00:00</updated><content>&lt;doc fingerprint="f7201de7e5f62665"&gt;
  &lt;main&gt;
    &lt;p&gt;Timesketch is an open-source tool for collaborative forensic timeline analysis. Using sketches you and your collaborators can easily organize your timelines and analyze them all at the same time. Add meaning to your raw data with rich annotations, comments, tags and stars.&lt;/p&gt;
    &lt;p&gt;This is not an official Google product (experimental or otherwise), it is just code that happens to be owned by Google.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/google/timesketch"/><published>2025-09-21T16:43:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45324349</id><title>Sj.h: A tiny little JSON parsing library in ~150 lines of C99</title><updated>2025-09-21T19:32:30.903491+00:00</updated><content>&lt;doc fingerprint="afd877d9ee5a4e03"&gt;
  &lt;main&gt;
    &lt;p&gt;A tiny little JSON parsing library&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;~150 lines of C99&lt;/item&gt;
      &lt;item&gt;Zero-allocations with minimal state&lt;/item&gt;
      &lt;item&gt;Error messages with &lt;code&gt;line:column:&lt;/code&gt;location&lt;/item&gt;
      &lt;item&gt;No number parsing: &lt;code&gt;strtod&lt;/code&gt;,&lt;code&gt;atoi&lt;/code&gt;? Handle them how you want&lt;/item&gt;
      &lt;item&gt;No string parsing: bring your own unicode surrogate pair handling (or don't)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A small program to load a rectangle from a JSON string into a &lt;code&gt;Rect&lt;/code&gt; struct:&lt;/p&gt;
    &lt;code&gt;char *json_text = "{ \"x\": 10, \"y\": 20, \"w\": 30, \"h\": 40 }";

typedef struct { int x, y, w, h; } Rect;

bool eq(sj_Value val, char *s) {
    size_t len = val.end - val.start;
    return strlen(s) == len &amp;amp;&amp;amp; !memcmp(s, val.start, len);
}

int main(void) {
    Rect rect = {0};

    sj_Reader r = sj_reader(json_text, strlen(json_text));
    sj_Value obj = sj_read(&amp;amp;r);

    sj_Value key, val;
    while (sj_iter_object(&amp;amp;r, obj, &amp;amp;key, &amp;amp;val)) {
        if (eq(key, "x")) { rect.x = atoi(val.start); }
        if (eq(key, "y")) { rect.y = atoi(val.start); }
        if (eq(key, "w")) { rect.w = atoi(val.start); }
        if (eq(key, "h")) { rect.h = atoi(val.start); }
    }

    printf("rect: { %d, %d, %d, %d }\n", rect.x, rect.y, rect.w, rect.h);
    return 0;
}&lt;/code&gt;
    &lt;p&gt;See the demo folder for further usage examples.&lt;/p&gt;
    &lt;p&gt;This is free and unencumbered software released into the public domain. See LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/rxi/sj.h"/><published>2025-09-21T16:43:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45324350</id><title>Liberté, égalité, Radioactivité</title><updated>2025-09-21T19:32:30.558402+00:00</updated><content>&lt;doc fingerprint="3e088951c92ad684"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;France built 40 nuclear reactors in a decade. Here’s how they did it, and how the world can follow their lead today.&lt;/head&gt;
    &lt;p&gt;In the 1970s, the golden age of nuclear energy appeared to be coming to an end. Sharply escalating costs, regulatory upheaval, and public opposition had made industry boasts of electricity ‘too cheap to meter’ seem increasingly hubristic. After peaking in 1973, new US nuclear reactor orders would drop to zero in 1979, despite the oil shocks leading to a doubling of electricity prices in the intervening years. Meanwhile, poor design and planning resulted in the UK’s advanced gas reactor program running 50 percent over budget and years behind schedule.&lt;/p&gt;
    &lt;p&gt;France stands out as an exception. As much of the world was retrenching, France’s nuclear ambitions were accelerating. The construction of 37 of the 57 reactors currently operating in France began during the 1970s. Today, France has largely decarbonized its grid: 94 percent of French electricity is generated from low-carbon sources, with 70 percentage points of that coming from nuclear power.&lt;/p&gt;
    &lt;p&gt;Subscribe for $100 to receive six beautiful 120-page issues per year.&lt;/p&gt;
    &lt;p&gt;France’s success in civilian nuclear power was by no means preordained. Throughout the 1960s, France was a nuclear laggard. Its industry, hamstrung by poor technology choices and institutional infighting, was the subject of domestic and international derision. The program’s eventual success was contingent on a politically courageous about-turn, regulatory focus, and a tax system that made local communities enthusiastic about hosting nuclear power stations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Inauspicious beginnings&lt;/head&gt;
    &lt;p&gt;As France embarked on the daunting task of reconstruction after the Second World War, interim leader and Free French hero Charles de Gaulle was set on restoring his country to its preeminent position on the world stage. Before the newly restored French Republic had settled on a constitution, de Gaulle decided that it should have nuclear weapons.&lt;/p&gt;
    &lt;p&gt;France’s nuclear ambitions were split across two rival entities. The Commissariat à l’Énergie Atomique (CEA), established in 1945, focused on producing plutonium to support the country’s nascent nuclear weapons program. Meanwhile Électricité de France (EDF), created the next year, was in charge of operating France’s electricity grid.&lt;/p&gt;
    &lt;p&gt;In its early days, EDF was not focused on nuclear energy. It possessed little atomic expertise and had to focus its limited resources on rebuilding and rationalizing the devastated postwar electric grid at the same time as integrating 1,400 newly nationalized electricity companies. This left the CEA to pursue its own choice of reactor design. After some early experimentation, it settled on the gas-graphite design.&lt;/p&gt;
    &lt;p&gt;This design had two advantages from the CEA’s standpoint. First, it employed natural uranium (uranium-238) at a time when France didn’t have any domestic enrichment facilities. Second, the gas-graphite design didn’t rely on high-pressure systems or sealed fuel assemblies. This meant that individual fuel rods could be easily extracted while the reactor was still running, allowing the operator to harvest the weapons-grade plutonium that the fission reaction produced before it was contaminated with other isotopes.&lt;/p&gt;
    &lt;p&gt;The CEA finished Marcoule G1, its first full-scale reactor, in 1956. By this stage it had started to work with EDF. The director of EDF’s research division sat on the CEA’s steering committee and had persuaded them to add small power generating units to the Marcoule reactors to capture the heat produced by the reactor and use it to generate electricity. At the same time, this EDF director began to build support within his own organisation to pursue nuclear power.&lt;/p&gt;
    &lt;p&gt;The resulting reactor, finally completed in 1962, was an unhappy compromise. Deliberately throttled to optimize plutonium enrichment, it generated only about 40 percent of the electricity it was capable of producing (versus 60–70 percent for reactors in other countries at the time and 80–90 percent for reactors today). It provided 11 years of underwhelming performance before being decommissioned in 1973.&lt;/p&gt;
    &lt;p&gt;EDF1 did not mark the end of the early French nuclear program’s troubles. The unhappy marriage produced two more gas-graphite reactors on the same Chinon site: EDF2 (completed in 1965) and EDF3 (completed in 1966).&lt;/p&gt;
    &lt;p&gt;In 1965, American company Westinghouse, creator of the pressurized water reactor (PWR), embarked on a global public relations offensive. The Westinghouse sales pitch, which heavily emphasized lower capital costs, found favour with EDF. The company became convinced that the ‘sovereignty’ offered by the use of natural uranium was not worth the inefficiency of gas-graphite plants. A summer of negative press commentary, after the fueling of EDF3 was blighted by technical failures, only reinforced this.&lt;/p&gt;
    &lt;p&gt;For the next two years, a joint CEA-EDF study committee toured America, poring over designs and spreadsheets. EDF concluded that the pressurized water design would be 20–30 percent cheaper, even after paying for enrichment. The CEA contested these numbers and dug in their heels. EDF workers also went out on strike in 1969, in defence of the gas-graphite reactor, fearing that the switch to an American design would damage their employment prospects.&lt;/p&gt;
    &lt;p&gt;It was not until De Gaulle, who was set on an autonomous French design, left the presidency and was replaced by Georges Pompidou that change was possible. In 1970, after persuading the French cabinet and planning commission, EDF began building two pilot pressurized water reactors at Fessenheim, near the German and Swiss borders. EDF had successfully argued that supporting cheap, reliable electricity was more patriotic than building an inefficient all-French reactor. In 1972, after yet another round of technical failures, the government formally ended the gas-graphite program.&lt;/p&gt;
    &lt;p&gt;In 1973, global oil prices rocketed after a coalition of Arab countries implemented a total embargo against countries that had supported Israel during that year’s Yom Kippur War. Following Algerian independence, France had lost its major source of domestic natural gas production, so it was hit particularly hard. At this time, France met 70 percent of its energy needs through imported oil. By contrast, the UK and West Germany had access to abundant coal deposits, and the British knew that North Sea oil would come onstream from 1975. The US was the world’s biggest oil producer.&lt;/p&gt;
    &lt;p&gt;In response, France unveiled the Messmer Plan, named after then prime minister Pierre Messmer who was running the country while Pompidou battled with terminal illness. This committed France to a mass buildout of pressurized water reactors. EDF ordered 16 new reactors in 1974, doubling the country’s total reactor order book. Illustrating the improved efficiency, these new reactors had a total output of 14,400 megawatts versus 9,000 megawatts from the previous 16.&lt;/p&gt;
    &lt;p&gt;The Messmer Plan amounted to the fastest nuclear buildout ever, in both number of reactors built and capacity added. During the 1980s, France increased the number of reactors in commercial operation from 15 to 55. Even China, with the world’s most streamlined regulatory process and developed industrial base, has failed to match this record.&lt;/p&gt;
    &lt;p&gt;The most striking element of the buildout was speed, with new reactors consistently being built in approximately six years. EDF had a pre-screened list of suitable sites, and reactors were ordered in bulk with a standardized design. This removed the need for a convoluted site licensing process. Meanwhile, safety standards were set in near-total secrecy through a ‘technical dialog’ process between EDF, the CEA, and other government experts, dubbed ‘French cooking’ by Anglo-American observers. Before 1979, EDF was not even required to conduct an environmental impact assessment on individual construction sites.&lt;/p&gt;
    &lt;p&gt;Long-term planning gave suppliers the certainty they needed to build out teams and production lines. If engineers came up with potential improvements, they were noted and saved for a potential future reactor series, but EDF only made the smallest of changes to designs once they had been approved.&lt;/p&gt;
    &lt;p&gt;Framatome, a Franco-American consortium responsible for licensing Westinghouse’s technology, was responsible for much of the plant’s manufacture, but EDF wasn’t a passive customer. EDF maintained control of the engineering, much to Framatome’s irritation, and ran a rigorous cost control regime to compensate for the lack of traditional competition.&lt;/p&gt;
    &lt;p&gt;This rigorous standardization and long-term order book helped create a specialized supply chain, which introduced significant efficiencies into the manufacturing process. Framatome, for example, could invest in a specialized heavy component facility that could produce vessels, steam generators, pressurizers, and piping. The Saint-Marcel facility, opened in 1975, could use spare capacity for exports and has provided components for 106 reactors. They also built a 9,000-ton hydraulic forging press that produced four to five identical pressure-vessel shells per year.&lt;/p&gt;
    &lt;p&gt;In the 1970s, France was building nuclear reactors at one third to a half of the pre-interest costs that new reactors in the US had risen to amid toughening environmental and safety regulations.&lt;/p&gt;
    &lt;head rend="h3"&gt;The backlash that wasn’t&lt;/head&gt;
    &lt;p&gt;EDF was greatly aided by the weakness of its opposition. While the 1970s were a time of nuclear backlash in most major economies, French technocrats faced one of the world’s least potent anti-nuclear movements.&lt;/p&gt;
    &lt;p&gt;A big factor was structural. The constitution of the Fifth Republic, adopted in 1958, created a strong presidency and a weak legislature. France’s parliament had next to no legal oversight of nuclear policy and the key decisions sat in executive agencies that were indifferent to lobbying or public opinion. The early anti-nuclear movement in the US and UK successfully weaponized the legal and planning process, forcing lengthy public inquiries and court battles. This not only delayed projects, but forced an interminable public debate about nuclear energy that chipped away at popular support. The French system offered no such legal avenue.&lt;/p&gt;
    &lt;p&gt;There were a handful of prominent nuclear skeptics, like future president François Mitterand, but France’s lack of domestic fossil fuel production ensured there was a broad pro-nuclear consensus across the major political parties.&lt;/p&gt;
    &lt;p&gt;Communist parties and their affiliated unions were often a hot-bed of anti-nuclear sentiment. In many European countries with smaller nuclear workforces, communist movements aligned with environmentalists in the hope of winning over younger voters and opposed nuclear as part of a wider anti-NATO program. By contrast, France’s communist movement derived significant support from workers either directly employed by the nuclear industry or involved in its support infrastructure. This meant that the country’s powerful trade unions were either indifferent or actively hostile towards the nascent environmentalist movement. The French Communist Party’s daily newspaper derided anti-nuclear activists as opponents of progress who wanted to return to using candles.&lt;/p&gt;
    &lt;p&gt;While anti-nuclear sentiment was shut out of the French political system, the success of the buildout ensured that there less of it in France versus other western countries. In 1987, the year after the Chernobyl accident, France was the only major western country where more of the population supported nuclear energy than opposed it. In fact, support was greater than it had been a decade earlier.&lt;/p&gt;
    &lt;head rend="h3"&gt;Buying support&lt;/head&gt;
    &lt;p&gt;One of the biggest drivers of opposition to new infrastructure is the sense that communities bear the disruption of development while receiving little short-term benefit. For example, when a new power station is built in the UK, the local authority collects business rates, but most of the revenue is then sent back to the central government.&lt;/p&gt;
    &lt;p&gt;France’s business tax system has been effective at correcting this. Avoine, the commune that hosted the first EDF reactors, for example, saw annual revenue jump from tens of thousands of francs in the mid 1950s up to nine million a year by the time EDF2 and EDF3 were being brought online in 1964–1966. Locals dubbed their town ‘the Kuwait of Indre-et-Loire’.&lt;/p&gt;
    &lt;p&gt;The residents of Avoine were the beneficiaries of La Patente, a business tax based on location, activity type, and sometimes estimated turnover. La Patente was subsequently replaced in 1975 by the Taxe Professionnelle, which similarly directed industrial revenues towards the areas that hosted them. It taxed fixed industrial assets (i.e. reactors, cooling towers, machinery) along with wages (although this component was later dropped). This gave communities an economic stake in projects and, because it focussed on physical assets, provided predictable future revenue.&lt;/p&gt;
    &lt;p&gt;As a further sweetener, the French government began paying out a special class of subsidy from 1975 to municipalities that accepted nuclear power to cover the costs of any new infrastructure.&lt;/p&gt;
    &lt;p&gt;Avoine wasn’t the only mini-emirate. The northeastern town of Chooz has offered its residents free high-speed internet and a 120-channel TV subscription since 1999. In 2012, local councils in France paid an average of €35 in subsidies or benefits per local resident. In the 19 areas that hosted nuclear power, the average was €450.&lt;/p&gt;
    &lt;p&gt;Mayors who hosted reactors were able to pave roads and build schools, sports halls, ice rinks, and cultural centers without raising local rates. Until 2023, French communes charged a local residential tax on property. Nuclear municipalities were able to charge significantly less than their regional neighbors. Residents of Fessenheim paid nine percent a year, versus 13 percent for comparable neighbors. Residents of Avoine, near the Chinon nuclear power station, paid 0.1 percent versus a 12 percent regional average.&lt;/p&gt;
    &lt;p&gt;This transformed mayors into active lobbyists for new plants – rezoning land for industry, publicly praising EDF’s tax payments, and pushing the government to ensure that expansion schedules were kept on track. Meanwhile, EDF would also build new housing for workers and local infrastructure like schools, as well as sponsoring local cultural events.&lt;/p&gt;
    &lt;p&gt;Unlike Austria or Sweden, France never held a national referendum on nuclear power, but the town of Flamanville in Normandy held a local one in April 1975. Pro-nuclear councilors won the community over by campaigning on a platform of cutting local taxes and providing free electricity.&lt;/p&gt;
    &lt;p&gt;Two months later, Golfech in southwestern France held the country’s only other consultative referendum on nuclear power. This time, residents overwhelmingly voted against. EDF didn’t give up and signed an agreement with the regional authorities in February 1982. This committed EDF to paying 10 million francs per year during the construction phase and six million francs annually throughout the operational period of the power plant. EDF also promised to give priority to regional construction companies and local workers as well as commit to a number of environmental protection schemes. This significantly calmed local opposition, and construction began the same year.&lt;/p&gt;
    &lt;p&gt;To build popular support for the first nuclear reactors, EDF had also branded them as modern ‘chateaux’, suggesting that they were part of natural cultural revival. One historian who interviewed locals around the plant found that the reactors were a source of regional pride. According to one Chinon resident, the success of the area’s nuclear industry was explained by their superior temperament: ‘Brittany has not accepted [nuclear power]. But the Bretons are more chauvinistic, while we are more welcoming.’&lt;/p&gt;
    &lt;p&gt;This lobbying would continue even after plants were established. François Hollande, elected president in 2012, had pledged to shut down the two reactors in Fessenheim. While these reactors were reaching the end of their 40-year natural life, regulators had concluded that it was safe to extend their use for at least another decade after the completion of upgrades. The intended shutdown was fiercely, albeit unsuccessfully, opposed by a range of interests. Five trade unions joined forces, EDF engineers threatened to disobey instructions and not disconnect the reactor from the grid, and local officials warned of the damaging economic impact.&lt;/p&gt;
    &lt;head rend="h3"&gt;The end of French exceptionalism?&lt;/head&gt;
    &lt;p&gt;France’s nuclear program was not perfect. Construction costs doubled per kilowatt hour between the 1970s and late 1990s. But it still looked good by international standards, with costs rising by a factor of four in the US over the same period. And as time goes on, it looks better and better. New builds like Hinkley Point C in the UK, Vogtle 3 &amp;amp; 4 in the US, or Flamanville in France itself are many times more expensive per kilowatt hour of energy delivered than Civaux, the last reactor France built before freezing construction for a decade.&lt;/p&gt;
    &lt;p&gt;Rising costs in France were the result of a combination of bad luck and suboptimal planning. The original Messmer Plan envisaged as many as 170 reactors by 2000, which would have been able to meet electricity demand growing by seven percent a year. To take advantage of economies of scale, EDF embraced larger designs. New reactors moved from being 900 megawatts initially to 1,300 megawatts in 1975, and then eventually to 1,450 in 1984.&lt;/p&gt;
    &lt;p&gt;On the surface, it was reasonable to expect that bigger reactors would be cheaper per unit of electricity generated. For example, the control room and the security fencing should cost approximately the same for a 900 and a 1,300 megawatt reactor. EDF’s own estimates found that, for the same total output, a smaller series of 1,450 megawatt units would be 15 percent cheaper than a larger series of 600 megawatt reactors.&lt;/p&gt;
    &lt;p&gt;But these larger designs brought greater complexity. For example, the 1,300 and 1,450 megawatt reactors needed an extra coolant pump, steam generator, and piping circuit to remove heat safely from the larger reactor core. The engineering work required to integrate these systems did not scale linearly with increased output.&lt;/p&gt;
    &lt;p&gt;French nuclear power was then buffeted by two other forces.&lt;/p&gt;
    &lt;p&gt;First, the country had overbuilt compared to its electricity demand. By the mid-1980s, a sluggish economy meant that the steady growth in electricity demand that Messmer had forecast had evaporated. Many of France’s nuclear power stations were operating significantly below capacity. From 1984, the government limited new reactor buildout to one a year.&lt;/p&gt;
    &lt;p&gt;Second, France was not immune to the international context around nuclear regulation. The 1979 accident at the Three Mile Island nuclear power station in Pennsylvania accelerated a preexisting global move towards tighter safety regulations. This would intensify in 1986 after Chernobyl. New regulation forced EDF to retrofit reactors with new monitoring, ventilation, and containment systems. These changes built in more costs and disrupted standardization.&lt;/p&gt;
    &lt;p&gt;In 1991, the government froze new reactor orders until Flamanville-3 in 2004. Flamanville-3 was to be the flagship European Pressurized Reactor, a Franco-German collaboration between Framatome and Siemens. The two companies hoped that their modified version of the Westinghouse pressurized water reactor design could be an effective vehicle for driving up exports of nuclear technology and services.&lt;/p&gt;
    &lt;p&gt;Far from being a demonstration of French engineering prestige, Flamanville overran by €11 billion and 12 years. During the 13 year hiatus in France’s nuclear buildout, EDF and Framatome had licensed reactor designs to China and exported individual services like fuel fabrication, but along with their subcontractors, they essentially ‘forgot’ how to build new reactors. Supply chains were dismantled, industry didn’t keep up with new regulatory standards, and engineers were forced into early retirement or sought lucrative consulting contracts overseas.&lt;/p&gt;
    &lt;p&gt;As the Flamanville design was a collaboration, the reactor had been designed in accordance with stricter German nuclear standards, These, for example, required a fourth emergency safety and cooling system. In a world of tougher compliance and facing an emboldened post-Fukushima regulator, EDF struggled with a raft of compliance failures. The company lost years to paperwork, recertification, and work being redone at the regulator’s insistence. In the end, the European Pressurized Reactor wasn’t even an export success, with a slim order book of eight compared to 18 for the Westinghouse AP1000, 12 for KEPCO’s APR-1400, and 24 for Rosatom’s VVER-1200.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where France led, the rest of the world can follow&lt;/head&gt;
    &lt;p&gt;Thanks to its rapid buildout in the 1970s and 1980s, nuclear power still provides about 70 percent of France’s electricity. France is comfortably Europe’s largest electricity exporter, supporting other European countries that rely on intermittent renewables, and has some of the lowest carbon power in the world. French homes and businesses enjoy significantly cheaper electricity bills than their neighbors without the addition of hundreds of Euros in green levies.&lt;/p&gt;
    &lt;p&gt;France provides a template for others to follow: a single buyer, streamlined regulation, a localized supply chain, building in fleets, and providing visible benefits to local communities. Parts of the French model have been successfully copied, most notably by China. In technology transfer agreements signed in 1992 and 1995, Framatome provided China with the documentation, plans, and computer code for the original 900-megawatt reactor. Chinese state-owned enterprises and research institutes reduced the number of impurities in the steel, replaced the analogue control systems with digital ones, and then set about localizing the supply chain and building a fleet. China now operates 22 of these reactors, some licensed and built in as little as five years.&lt;/p&gt;
    &lt;p&gt;France’s nuclear buildout was one of the country’s most remarkable achievements in the past fifty years. Yet France’s political elite flirted with abandoning it. Under Hollande, France swung in an anti-nuclear direction, with plans to reduce nuclear power down to 50 percent of the energy mix, fuelled by the post-Fukushima panic. When Emmanuel Macron took power in 2017, he was still committed to this target and closed down Fessenheim in 2020, despite calls from pro-nuclear groups to extend its life.&lt;/p&gt;
    &lt;p&gt;Following the surge in energy prices triggered by the Ukraine War, France reversed course yet again, and the country is planning six new reactors and exploring a potential small modular reactor program. As France attempts to position itself as a sovereign power in AI, its grid positions it well to welcome data centers and foreign direct investment. UK-based AI cloud provider Fluidstack cited France’s ‘abundant, carbon-free, and predominantly nuclear energy’ when it announced its plans for a French supercomputer. With broad-based public support ahead of a major sovereignty-focused infrastructure buildout, Messmer and Pompidou would be smiling.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://worksinprogress.co/issue/liberte-egalite-radioactivite/"/><published>2025-09-21T16:43:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45324361</id><title>President Trump Signs Technology Prosperity Deal with United Kingdom</title><updated>2025-09-21T19:32:30.405027+00:00</updated><content>&lt;doc fingerprint="6e9ef0edf385c53a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;President Trump Signs Technology Prosperity Deal with United Kingdom&lt;/head&gt;
    &lt;p&gt;Today, President Donald J. Trump and Prime Minister Keir Starmer signed the Technology Prosperity Deal, a landmark science and technology agreement that will propel the U.S. – UK special relationship to new heights for the technological age, and deliver wins for the American people and American innovation globally.&lt;/p&gt;
    &lt;p&gt;“President Trump signed another game-changing deal that furthers American technology leadership and strengthens ties to one of our closest allies. With the TPD, the United States is exporting its world-class tech stack, accelerating scientific discovery, and advancing pro-innovation policies worldwide,” said Michael Kratsios, Assistant to the President and Director of the White House Office of Science and Technology Policy.&lt;/p&gt;
    &lt;p&gt;The Technology Prosperity Deal establishes joint initiatives between the two nations’ premiere research and standards institutions across artificial intelligence, nuclear energy, and quantum computing to bring transformative benefits to citizens – from accelerating breakthroughs in health care, to lowering energy costs, and supporting national security.&lt;/p&gt;
    &lt;p&gt;On Artificial Intelligence:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The TPD strengthens and refocuses the partnership between the U.S. Center for AI Standards and Innovation (CAISI) and the UK AI Security Institute (AISI) to exchange best practices in metrology and standards development for AI models, improve understanding of the most advanced models, and exchange talent between the institutes.&lt;/item&gt;
      &lt;item&gt;The TPD establishes a flagship AI for Science research program between the U.S. Departments of Energy, Health, and the National Science Foundation and its UK counterparts geared towards cutting-edge biotechnology research and precision medicine. As part of this, we’ll collaborate on automated labs and new scientific data sets,focusing especially on cancer and chronic disease research that will improve the lives of our peoples.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On Civil Nuclear Energy:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The TPD aligns the U.S. Nuclear Regulatory Commission, the UK Office for Nuclear Regulation, and the UK Environment Agency to streamline and accelerate licensing, targeting reactor design reviews within two years and site licensing within one year;&lt;/item&gt;
      &lt;item&gt;The TPD also commits the UK to achieve full independence from Russian nuclear fuel by the end of 2028 – bringing the UK in alignment with U.S. statutory commitments – ensuring a secure and reliable supply chain for advanced nuclear fuels in both countries.&lt;/item&gt;
      &lt;item&gt;The TPD facilitates coordination of fusion energy research and development, including through the use of artificial intelligence, with enhanced collaboration to develop harmonized, responsible, and pro-innovation policies to enable commercial development of fusion technologies.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On Quantum Computing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The TPD advances trusted, interoperable standards for quantum technologies and establishes a joint benchmarking taskforce that will cover across quantum computing hardware, software, and algorithms.&lt;/item&gt;
      &lt;item&gt;Additional partnerships between our top quantum institutions will lead to more a secure quantum supply chain and capability to accelerate breakthroughs in defense, finance, energy, and beyond.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.whitehouse.gov/articles/2025/09/president-trump-signs-technology-prosperity-deal-with-united-kingdom/"/><published>2025-09-21T16:44:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45324365</id><title>The link between trauma, drug use, and our search to feel better</title><updated>2025-09-21T19:32:30.172543+00:00</updated><content>&lt;doc fingerprint="3b3d98693963078a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Link Between Trauma, Drug Use, and Our Search to Feel Better&lt;/head&gt;
    &lt;head rend="h3"&gt;“As capitalism has invented ever more ways to be miserable, so too has it invented ever more specific ways to ease that misery.”&lt;/head&gt;
    &lt;p&gt;As long as humans have experienced emotional crisis (which is to say: for all of human history), they’ve attempted to ease their pain with drugs—plant-based psychoactives like marijuana in preindustrial societies, alcohol during the Industrial Revolution (quickly industrializing late nineteenth-century London, population 1 million, consumed an estimated 200 million quarts of beer, 50 million quarts of wine, and 10 million quarts of rum each year, for example). What’s new about our modern era isn’t drug consumption, it’s that drugs have become much more specifically formulated to ease each form of pain we experience in modern life. As capitalism has invented ever more ways to be miserable, so too has it invented ever more specific ways to ease that misery.&lt;/p&gt;
    &lt;p&gt;In an essay examining the origins of trauma and PTSD, the writer Will Self argues that mental trauma and the anxiety and despair it causes are inherent to the invention of modern, industrialized society. Self writes that technologies like the railway and the factory, and the very organization of life by a clock, were so destabilizing to our preindustrial rhythms that they caused a body-and mind-altering anxiety. In this understanding of modern capitalism, the PTSD caused by war, or, say, a neo-Nazi plowing an American muscle car into a crowd of protesters, is not unique; it is just the furthest node on a spectrum of the trauma that essentially everyone experiences under modern capitalism.&lt;/p&gt;
    &lt;p&gt;Which perhaps explains why it was at the height of industrial America that an industry dedicated to calming people down blossomed.&lt;/p&gt;
    &lt;p&gt;The 1950s saw the introduction of the first popular, industrially made anti-anxiety drugs. First with an antipsychotic called Thorazine, and then, most popularly at the time, with meprobamate, aka Miltown, a sedative with mysterious chemical properties (to this day no one really understands how it works) that immediately flooded American culture and bloodstreams. Newspapers called it a “wonder pill” and “emotional aspirin.” Pharmacies made signs that said “Miltown Available Tomorrow” to temporarily ward off the growing hordes of people coming in to get it.&lt;/p&gt;
    &lt;p&gt;By the late 1970s, Americans were consuming 2.3 billion Valium tablets a year. Billion. With a B.&lt;/p&gt;
    &lt;p&gt;“Fashionable ladies and hard-driving male executives alike kept their supplies close at hand,” historian of science Anne Harrington wrote in her book Mind Fixers. “Greeting card companies created cute Valentine’s Day designs that incorporated the drug, and bars introduced the Miltini—a martini with a Miltown tablet in place of the traditional olive.”&lt;/p&gt;
    &lt;p&gt;By the late fifties, one in three prescriptions in America was for meprobamate. Fifty tons were being produced a month, and a billion tablets had been sold within a few years.&lt;/p&gt;
    &lt;p&gt;And then, as fast as they took over America, the pills disappeared, not because people realized that consuming vast quantities of drugs was bad, or because the government regulated their use, but because a new class of drugs, promising even fewer side effects and less potential for addiction, took over. And those pills, developed fifty years ago as a replacement for Miltown, are what sit in my bathroom cabinet, and in a small pill case in my bag wherever I go in case I have a panic attack.&lt;/p&gt;
    &lt;p&gt;Klonopin is a benzodiazepine—a class of central nervous system depressants first synthesized by a man named Leo Sternbach at the drug company F. Hoffmann–La Roche in 1955. Sternbach was notoriously messy; his bosses did not like him. He was hardheaded, convinced he could find a new tranquilizer despite the company’s insistence he move on.&lt;/p&gt;
    &lt;p&gt;His research wasn’t going anywhere. Eventually, his bosses ordered him to clean up his disorganized lab, start from scratch, get it together. As he decluttered, his colleague Earl Reeder noticed a “nicely crystalline” compound, labeled RO-5-0690, sitting around that had gone untested for twenty years, so, on a lark, they decided to give it to some lab mice, just to see what it would do. Immediately they noticed that it relaxed the little animals; their muscles loosened, their movements slowed. By 1960, RO-5-0690 was on the market, branded as Librium.&lt;/p&gt;
    &lt;p&gt;And three years later, the company released diazepam, branded as Valium, named after the Latin word “valere,” which means “be strong.” The drug became so popular in such a short time that a few years later the Rolling Stones released a song about it called “Mother’s Little Helper.” By the late 1970s, Americans were consuming 2.3 billion Valium tablets a year. Billion. With a B. Somewhere between 10 and 15 percent of all Americans were on the drugs, as were somewhere between 4 and 8 percent of Europeans. By 1984, an estimated 500 million people worldwide had taken a benzo.&lt;/p&gt;
    &lt;p&gt;After Roche released its little miracle pill, drug companies, searching for their own patentable versions, began pushing out as many benzos as they could. In 1975, clonazepam, aka Klonopin, came to market.&lt;/p&gt;
    &lt;p&gt;As is more common than you’d probably like to think with psychoactive medication, no one, including the scientists who made them, really understood how benzos worked, even as doctors prescribed millions upon millions of the pills to patients. But in the late 1970s, researchers began to learn that the drugs helped flood the brain with gamma-aminobutyric acid, or GABA, which in essence blocks your nervous system from receiving too many activation signals.&lt;/p&gt;
    &lt;p&gt;There are dozens of different benzos, but they all work in basically the same way—forcing your nervous system into a kind of low-power mode. The main way they differ is in how long they last. One of the most popular, and notorious, alprazolam—more commonly known as Xanax—has a half-life of only twelve hours. You get high fast, you withdraw fast. That leads to more addiction. Klonopin, on the other hand, has a half-life of between twenty and eighty hours. The withdrawal is much slower. You’re not zapped back into your normal brain so quickly. And that’s why doctors prescribed it to me. The disadvantage is that it takes longer to work.&lt;/p&gt;
    &lt;p&gt;Which is why I would pace back and forth in my Philadelphia apartment, heart beating a thousand beats per minute, for ten, twenty, thirty, forty minutes, until I felt a heaviness overtake me. My eyelids would droop. My thoughts, instead of feeling like they were being released via machine gun, felt like they were launched from an old-timey pistol shot underwater, the propulsion forcibly slowed. I would drift off to sleep, wishing I could build a world out of Klonopin, like a gingerbread house—the walls and floors and tables and chairs a dusty blue; a Klonopin lamp, a Klonopin rug, a Klonopin dog. Peace on earth.&lt;/p&gt;
    &lt;p&gt;And then I’d wake up the next morning and, of course, the terror would be back.&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;Seeing my trauma and my drug use in this historical context—Charlottesville not as a one-off event but just a particularly nasty instance of an entire system set up to traumatize, and thus a system that encourages people to find relief in chemical cures—made me feel less alone.&lt;/p&gt;
    &lt;p&gt;But as repression killed these movements, and capitalism moved on, a new era emerged: the age of anxiety, which we’ve been stuck in since the 1970s.&lt;/p&gt;
    &lt;p&gt;In their 2014 manifesto, the European leftist collective Plan C wrote that each age of capitalism comes with an attendant affect. The Industrial Revolution brought widespread misery in the form of brutal factory working conditions. The early and mid-1900s brought crushing boredom, as lives became increasingly suburbanized, individualized, standardized—think of the prototypical depressed and stressed housewife and the businessman husband who cheated on her to add excitement to his life; stamp-size, pesticided grass yards, all cut to the same length, on which children would attempt to add any kind of spontaneity to their lives. The children of this era would go on to lead the next affective era in the form of the 1960s—which in many ways were a fight against this boredom, a call to reclaim the excitement of communalism, of revolution, of queerness and chaos.&lt;/p&gt;
    &lt;p&gt;But as repression killed these movements, and capitalism moved on, a new era emerged: the age of anxiety, which we’ve been stuck in since the 1970s. An age where as a society we have enough, even too much—food, housing, work, entertainment—but these things are precarious, always at risk of being stripped away. Homes sit empty as the homeless population grows. Wages flatline as productivity skyrockets. We never know what the next year will bring, when our rent will go up, when the next war will start, when inflation will take food off our tables.&lt;/p&gt;
    &lt;p&gt;After my mental breakdown, I began to see this internalized precarity everywhere I looked. I saw it in friends who lost jobs and then turned to drugs to ease the anxiety of their financial uncertainty; I saw it in the news, in statistics about suicide and addiction, and I saw it in myself—this feeling that the world and its violences had been placed into me, into my nervous system and psyche, an unwanted osmosis of energy.&lt;/p&gt;
    &lt;p&gt;For me, that osmosis was direct and obvious—the violence of fascism all represented by one man, James Alex Fields Jr., driving his car into a crowd and infecting me and so many others with his energetic sickness. For so many others the osmosis is slower and less conspicuous—the constant stress on one’s nerves from underpay and overwork and the rent being too high and our world, generally, being wholly unfair. But it is nonetheless damaging. We carry that stress in our nerve endings. We become bodies with constant excitation without release.&lt;/p&gt;
    &lt;p&gt;Klonopin does not permanently extinguish this excitation, but it tames it enough so that you can temporarily ignore it.&lt;/p&gt;
    &lt;p&gt;But the reason people use drugs is simple: it’s because they help. And the world, it’s bad. So we need help.&lt;/p&gt;
    &lt;p&gt;It’s not an exaggeration to say that drugs, both illicit and prescription, saved my life. They helped me when nothing else would. It’s hard to see through the haze of propaganda, the false divide that’s been placed between medications and illegal substances. But, to me, that divide is much less clear. People use illicit drugs for the same reason they use prescription ones—to quell pain, to help them focus or get through the day, to ease their depression and anxiety. What differentiates these drugs is less a matter of their purpose, and more a matter of how our laws and media treat these drugs. They’ve associated them with the ravages of poverty, they’ve criminalized them so that users of these drugs end up in a constant cycle of violence. We’ve been led to believe that drugs cause the breakdown, when in truth they are part and parcel of it. If our minds are constantly burdened, constantly being reshaped by the trauma of capitalism, of course we’re going to need ameliorants. Of course we’re going to need a break.&lt;/p&gt;
    &lt;p&gt;Drugs can be used in ways that end up breaking us, that end up keeping us closer to the trauma than we should be. The systems we have set up in this world often do not allow people to use drugs in healthy ways, and to stop using them when they want to. But the reason people use drugs is simple: it’s because they help. And the world, it’s bad. So we need help.&lt;/p&gt;
    &lt;p&gt;When I was at my worst, when drugs were the only thing that would help, I took a kind of sick solace in that: that so many others were in the same place.&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;There was one good night in my life that first year of breakdown. Like, one memory I actually look back on fondly.&lt;/p&gt;
    &lt;p&gt;It was perhaps a month in. And my friend Bobbi came over to my apartment. We watched a movie, but I do not remember which one. We ate dinner, but I do not remember what we ate. I just remember her, this butch lesbian with short hair and an aura of calm about her, sitting next to me, holding my hand as I stared at the TV in a daze, under the influence of a broken nervous system and 1 milligram of Klonopin. At some point I got sleepy from the downer in my bloodstream. I asked to go to bed.&lt;/p&gt;
    &lt;p&gt;Bobbi came with me. I lay on my side, curled up like a baby on top of the covers, and Bobbi pushed up behind me, her strong arms holding me tight to her stomach and big breasts. She smelled like lavender and sweat.&lt;/p&gt;
    &lt;p&gt;My eyes closed and then opened and then closed and then, when they opened again, it was two hours later and she was still there holding me.&lt;/p&gt;
    &lt;p&gt;That was the only moment of true comfort in my life for a year, maybe more; the only moment where my brain truly felt like it could turn off.&lt;/p&gt;
    &lt;p&gt;I would chase that feeling. Of ensconcement from everything evil in this world. And chasing it is what would keep me alive during my darkest moments. In some ways, it’s still what’s keeping me alive—the knowledge that with people to hold you close (and perhaps a chemical flowing through you that allows your brain to feel the comfort of that), the other side is visible, reachable, already here.&lt;/p&gt;
    &lt;p&gt;__________________________________&lt;/p&gt;
    &lt;p&gt;Breaking Awake: A Reporter’s Search for a New Life, and a New World, Through Drugs by P.E. Moskowitz is available from Atria Books, an imprint of Simon and Schuster.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lithub.com/the-link-between-trauma-drug-use-and-our-search-to-feel-better/"/><published>2025-09-21T16:45:06+00:00</published></entry></feed>