<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-08T22:09:09.911923+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45492977</id><title>Sora, AI Bicycles, and Meta Disruption</title><updated>2025-10-08T22:09:16.728217+00:00</updated><content>&lt;doc fingerprint="3493991100b12b9b"&gt;
  &lt;main&gt;
    &lt;p&gt;Listen to this post:&lt;/p&gt;
    &lt;p&gt;The App Store charts tell the story, at least for the first week of AI-generated video apps:&lt;/p&gt;
    &lt;p&gt;This doesn’t, somewhat embarrassingly, match my initial impressions: I liked the Vibes addition to the MetaAI app and was somewhat cool on Sora. I spent much of last week’s episode of Sharp Tech exploring why my initial impressions were so off base, and I think M.G. Siegler — who was sucked into Sora immediately — captures a few of them in Sora’s Slop Hits Different:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Anyway, what’s different, and what I underestimated about Sora, is that the AI content here is not just randomly generated things. It’s content that’s either loaded with “cameos” from your connections or it’s “real” world content that’s, well, hilarious. Not all of it, of course. But a lot of it! In this regard, it’s really not too dissimilar from TikTok — and back in the day, Vine! This is a lot more like those social networks but with the main difference being that it’s a lot easier to create such content thanks to AI.&lt;/p&gt;
      &lt;p&gt;I think that’s the real revelation here. It’s less about consumption and more about creation. I previously wrote about how I was an early investor in Vine in part because it felt like it could be analogous to Instagram. Thanks in large part to filters, that app made it easy for anyone to think they were good enough to be a photographer. It didn’t matter if they were or not, they thought they were — I was one of them — so everyone posted their photos. Vine felt like it could have been that for video thanks to its clever tap-to-record mechanism. But actually, it became a network for a lot of really talented amateurs to figure out a new format for funny videos on the internet. When Twitter acquired the company and dropped the ball, TikTok took that idea and scaled it (thanks to ByteDance paying um, Meta billions of dollars for distribution, and their own very smart algorithms).&lt;/p&gt;
      &lt;p&gt;In a way, Sora feels like enabling everyone to be a TikTok creator.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I feel blessed for a whole host of reasons, many of them related to the fact I’ve been able to carve out a career as a creator. Sure, I call myself an analyst, and I write about primarily big tech companies, but one thing I realized over the years is that the success of Stratechery is tied to it being a creative endeavor; there have been a lot of analysts over the years who have launched similar sites, but what was often missing was the narrative element. The best Articles on Stratechery tell a story, with a beginning, middle, and end, and the analysis is along for the ride; analysis alone doesn’t move the needle.&lt;/p&gt;
    &lt;p&gt;That I tell stories is itself a function of the way I think: I have a larger meta story in my head about how the world works, and I’m always adding and augmenting that story; that’s why, in various interviews, I’ve noted that being wrong is often the most inspiring (albeit painful) place to be. That means my story is incomplete, and I need to deepen my understanding of the world I’m seeking to chronicle. I certainly have that opportunity right now.&lt;/p&gt;
    &lt;head rend="h3"&gt;My Creativity Blindspot&lt;/head&gt;
    &lt;p&gt;This is what I wrote in my Update about Sora:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Indeed, it feels like each company has an entirely different target audience: YouTube is making tools for creators, Meta is building the ultimate lean back dream-like experience, and OpenAI is making an app that is, in my estimation, the easiest for normal people to use.&lt;/p&gt;
      &lt;p&gt;In this new competition, I prefer the Meta experience, by a significant margin, and the reason why goes back to one of the oldest axioms in technology: the 90/9/1 rule.&lt;/p&gt;
      &lt;item&gt;90% of users consume&lt;/item&gt;
      &lt;item&gt;9% of users edit/distribute&lt;/item&gt;
      &lt;item&gt;1% of users create&lt;/item&gt;
      &lt;p&gt;If you were to categorize the target market of these three AI video entrants, you might say that YouTube is focused on the 1% of creators; OpenAI is focused on the 9% of editors/distributors; Meta is focused on the 90% of users who consume. Speaking as someone who is, at least for now, more interested in consuming AI content than in distributing or creating it, I find Meta’s Vibes app genuinely compelling; the Sora app feels like a parlor trick, if I’m being honest, and I tired of my feed pretty quickly. I’m going to refrain on passing judgment on YouTube, given that my current primary YouTube use case is watching vocal coaches break down songs from KPop Demon Hunters.&lt;/p&gt;
      &lt;p&gt;I honestly have no idea if my evaluation of these apps is broadly applicable; as I’ve noted repeatedly, I’m hesitant to make any pronouncements about what resonates with society broadly given that I am the weirdo in the room. Still, I do think it’s striking how this target market evaluation tracks with the companies themselves: YouTube has always prioritized creators, while OpenAI’s business model is predicated on people actively using AI; it’s Meta that has stayed focused on the silent majority that simply consumes, and as a silent consumer, I still like Vibes!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As I noted at the beginning, the verdict is in, and my evaluation of these apps is not broadly applicable. Way more people like Sora than Vibes, and OpenAI has another viral hit. What I hear from people who love the app, however, is very much in line with what Siegler wrote: yes, they are browsing the feed, but the real lure is losing surprisingly large amounts of time making content — Sora lets them be a content creator.&lt;/p&gt;
    &lt;p&gt;This was a blind spot for me because I don’t have that itch! I’m creating content constantly — three Articles/Updates, an Interview, and three podcast episodes a week is enough for me, thank you very much. When I am vegging out on my phone, I want to passively consume, and I personally found the Vibes mix of fantastical environments and beautiful visages calming and inspiring; almost everyone else feels different:&lt;/p&gt;
    &lt;p&gt;I had to laugh at this because I’ve spent way too much time watching Apple’s Aerial Video screensavers; apparently my tastes are consistent! Beyond that, however, is a second blind spot: how much of the 90/9/1 rule is a law of the universe, versus a manifestation of barriers when it comes to creation? At the risk of sounding like a snob, have I become the sort of 1%-er who is totally out of touch?&lt;/p&gt;
    &lt;head rend="h3"&gt;The AI Bicycle&lt;/head&gt;
    &lt;p&gt;Back in 2022, when AI image generation was just starting to get good, I wrote about The AI Unbundling and the idea propagation chain:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The evolution of human communication has been about removing whatever bottleneck is in this value chain. Before humans could write, information could only be conveyed orally; that meant that the creation, vocalization, delivery, and consumption of an idea were all one-and-the-same. Writing, though, unbundled consumption, increasing the number of people who could consume an idea.&lt;/p&gt;
      &lt;p&gt;Now the new bottleneck was duplication: to reach more people whatever was written had to be painstakingly duplicated by hand, which dramatically limited what ideas were recorded and preserved. The printing press removed this bottleneck, dramatically increasing the number of ideas that could be economically distributed:&lt;/p&gt;
      &lt;p&gt;The new bottleneck was distribution, which is to say this was the new place to make money; thus the aforementioned profitability of newspapers. That bottleneck, though, was removed by the Internet, which made distribution free and available to anyone.&lt;/p&gt;
      &lt;p&gt;What remains is one final bundle: the creation and substantiation of an idea. To use myself as an example, I have plenty of ideas, and thanks to the Internet, the ability to distribute them around the globe; however, I still need to write them down, just as an artist needs to create an image, or a musician needs to write a song. What is becoming increasingly clear, though, is that this too is a bottleneck that is on the verge of being removed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is what was unlocked by Sora: all sorts of people without the time or inclination or skills or equipment to make videos could suddenly do just that — and they absolutely loved it. And why wouldn’t they? To be creative is to be truly human — to actually think of something yourself, instead of simply passively consuming — and AI makes creativity as accessible as a simple prompt.&lt;/p&gt;
    &lt;p&gt;I think this is pretty remarkable, so much so that I’ve done a complete 180 on Sora: this new app from OpenAI may be the single most exciting manifestation of AI yet, and the most encouraging in terms of AI’s impact on humans. Everyone — including lots of people in my Sora feed — are leaning into the concept of AI slop, which I get: we are looking at a world of infinite machine-generated content, and a lot of it is going to be terrible.&lt;/p&gt;
    &lt;p&gt;At the same time, how incredible is it to give everyone with an iPhone a creative outlet? It reminds me of one of my favorite Steve Jobs moments, just before he died, at the introduction of the iPad 2; I wrote about it in 2024’s The Great Flattening:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;My favorite moment in that keynote — one of my favorite Steve Jobs’ keynote moments ever, in fact — was the introduction of GarageBand. You can watch the entire introduction and demo, but the part that stands out in my memory is Jobs — clearly sick, in retrospect — moved by what the company had just produced:&lt;/p&gt;
      &lt;p&gt;I’m blown away with this stuff. Playing your own instruments, or using the smart instruments, anyone can make music now, in something that’s this thick and weighs 1.3 pounds. It’s unbelievable. GarageBand for iPad. Great set of features — again, this is no toy. This is something you can really use for real work. This is something that, I cannot tell you, how many hours teenagers are going to spend making music with this, and teaching themselves about music with this.&lt;/p&gt;
      &lt;p&gt;Jobs wasn’t wrong: global hits have originated on GarageBand, and undoubtedly many more hours of (mostly terrible, if my personal experience is any indication) amateur experimentation. Why I think this demo was so personally meaningful for Jobs, though, is that not only was GarageBand about music, one of his deepest passions, but it was also a manifestation of his life’s work: creating a bicycle for the mind.&lt;/p&gt;
      &lt;p&gt;I remember reading an Article when I was about 12 years old, I think it might have been in Scientific American, where they measured the efficiency of locomotion for all these species on planet earth. How many kilocalories did they expend to get from point A to point B, and the condor won: it came in at the top of the list, surpassed everything else. And humans came in about a third of the way down the list, which was not such a great showing for the crown of creation.&lt;/p&gt;
      &lt;p&gt;But somebody there had the imagination to test the efficiency of a human riding a bicycle. Human riding a bicycle blew away the condor, all the way off the top of the list. And it made a really big impression on me that we humans are tool builders, and that we can fashion tools that amplify these inherent abilities that we have to spectacular magnitudes, and so for me a computer has always been a bicycle of the mind, something that takes us far beyond our inherent abilities.&lt;/p&gt;
      &lt;p&gt;I think we’re just at the early stages of this tool, very early stages, and we’ve come only a very short distance, and it’s still in its formation, but already we’ve seen enormous changes, but I think that’s nothing compared to what’s coming in the next 100 years.&lt;/p&gt;
      &lt;p&gt;In Jobs’ view of the world, teenagers the world over are potential musicians, who might not be able to afford a piano or guitar or trumpet; if, though, they can get an iPad — now even thinner and lighter! — they can have access to everything they need. In this view “There’s an app for that” is profoundly empowering.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Well, now there’s an AI for that, and it’s accessible to everyone. And yes, I get the objections. I slave over these posts, thinking carefully about the structure and every word choice; it seems cheap to ask an LLM to generate the same. I’m certain that artists feel the same about AI images, or musicians about AI music, or YouTube and TikTok creators about Sora videos; what about the craft?&lt;/p&gt;
    &lt;p&gt;That, though, is an easy concern to have when you already have a creative outlet; it’s also easy to make the case that more content means more compelling content to consume, even if the percentage of what is great is very small.&lt;/p&gt;
    &lt;p&gt;What I didn’t fully appreciate, however, is what falls in the middle: the fact that so many more people get to be creators, and what a blessing that is. How many people have had ideas in their head, yet were incapable of substantiating them, and now can? I myself benefited greatly from the last unbundling — the ability for anyone to distribute content; why should I begrudge the latest unbundling, and the many more people who will benefit from AI substantiation of their creative impulses? Bicycles for all!&lt;/p&gt;
    &lt;head rend="h3"&gt;Instagram’s Social Umbrella&lt;/head&gt;
    &lt;p&gt;Siegler in his post discussed how he once thought Vine could be like Instagram, which made it easy to feel like a good photographer with its filters, but that was only step one; Chris Dixon described Instagram’s evolution as Come for the Tool, Stay for the Network:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A popular strategy for bootstrapping networks is what I like to call “come for the tool, stay for the network.” The idea is to initially attract users with a single-player tool and then, over time, get them to participate in a network. The tool helps get to initial critical mass. The network creates the long term value for users, and defensibility for the company.&lt;/p&gt;
      &lt;p&gt;Here are two historical examples: 1) Delicious. The single-player tool was a cloud service for your bookmarks. The multiplayer network was a tagging system for discovering and sharing links. 2) Instagram. Instagram’s initial hook was the innovative photo filters. At the time some other apps like Hipstamatic had filters but you had to pay for them. Instagram also made it easy to share your photos on other networks like Facebook and Twitter. But you could also share on Instagram’s network, which of course became the preferred way to use Instagram over time.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Dixon wrote that post in 2015, and Instagram has since gone much further than that, as I documented in 2021’s Instagram’s Evolution:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There was the tool to network evolution that Dixon talked about.&lt;/item&gt;
      &lt;item&gt;The second evolution was the addition of video.&lt;/item&gt;
      &lt;item&gt;The third evolution was the introduction of the algorithmic feed.&lt;/item&gt;
      &lt;item&gt;The fourth evolution was Stories, driven by competition with Snapchat.&lt;/item&gt;
      &lt;item&gt;The fifth evolution was what I was writing about in that Article: the commitment to short-form video, driven by competition with TikTok.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That last evolution is fully baked in at this point; late last month Instagram announced that it was changing Instagram’s navigation to focus on private messaging and Reels; I didn’t explicitly cover the 2013 addition of Instagram Direct, but it certainly is the case that messaging is where social networking happens today. What is public is pure entertainment, where the content you see is pulled from across the network and tailored for you specifically.&lt;/p&gt;
    &lt;p&gt;I think this evolution was both necessary and inevitable; I first wrote that Facebook needed to move in this direction in 2015’s Facebook and the Feed:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Consider Facebook’s smartest acquisition, Instagram. The photo-sharing service is valuable because it is a network, but it initially got traction because of filters. Sometimes what gets you started is only a lever to what makes you valuable. What, though, lies beyond the network? That was Facebook’s starting point, and I think the answer to what lies beyond is clear: the entire online experience of over a billion people. Will Facebook seek to protect its network — and Zuckerberg’s vision — or make a play to be the television of mobile?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It wasn’t until TikTok peeled off a huge amount of attention that Facebook finally realized that viewing itself as a social network was actually limiting its potential. If the goal was to monopolize user attention — the only scarce resource on the Internet — then artificially limiting what people saw to their social network was to fight with one hand tied behind your back; TikTok was taking share not just because of its format, but also because it wasn’t really a social network at all.&lt;/p&gt;
    &lt;p&gt;This is all interesting context for how OpenAI characterized Sora in their introductory post: it’s a social app.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Today, we’re launching a new social iOS app just called “Sora,” powered by Sora 2. Inside the app, you can create, remix each other’s generations, discover new videos in a customizable Sora feed, and bring yourself or your friends in via cameos. With cameos, you can drop yourself straight into any Sora scene with remarkable fidelity after a short one-time video-and-audio recording in the app to verify your identity and capture your likeness…&lt;/p&gt;
      &lt;p&gt;This app is made to be used with your friends. Overwhelming feedback from testers is that cameos are what make this feel different and fun to use — you have to try it to really get it, but it is a new and unique way to communicate with people. We’re rolling this out as an invite-based app to make sure you come in with your friends. At a time when all major platforms are moving away from the social graph, we think cameos will reinforce community.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;First, just because Meta needed to move beyond the social network doesn’t mean social networking isn’t still valuable, or appealing. As an analogy, consider the concept of a pricing umbrella: when something becomes more expensive, it opens up the market for a lower-priced competitor. In this case Instagram’s evolution has created a social umbrella: sure, Instagram content may be “better” by virtue of being pulled from anywhere, but that means there is now a space for a content app that is organized around friends.&lt;/p&gt;
    &lt;p&gt;Second, remember the creativity point above: one of the challenges of restricting Instagram content to just what your social network posted is that your social network may not post very many interesting things. That gap was initially filled by following influencers, but now Instagram simply goes out and finds what you are interested in without having to do anything. In Sora, however, your network is uniquely empowered to be creative, increasing the amount of interesting content in a network-mediated context (and, of course, Sora is also pulling from elsewhere as well to populate your feed).&lt;/p&gt;
    &lt;p&gt;What you’re seeing, if you squint, is disruption: Instagram has gone “up-market” in terms of content, leaving space for a new entrant; that new entrant, meanwhile, is not simply cheaper/smaller. Rather, it’s enabled by a new technological paradigm that lets it compete orthogonally with the incumbent. Granted, that new paradigm is very expensive, particularly compared to the content that Instagram gets for free, but the extent it restores value to your social network is notable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Meta Concerns&lt;/head&gt;
    &lt;p&gt;I am on the record as being very bullish about the impact of AI on Meta’s business:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It’s good for their ad business in the short, medium, and long-term (and YouTube’s as well).&lt;/item&gt;
      &lt;item&gt;More content benefits the company with the most popular distribution channels.&lt;/item&gt;
      &lt;item&gt;AI will be the key to unlocking both AR and VR.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The key to everything, however, is maintaining the hold Meta has on user attention, and the release of both Vibes and Sora has me seriously questioning point number two.&lt;/p&gt;
    &lt;p&gt;What I appreciate about both of these apps is the fact they are explicitly AI-content; I said in my Update about Vibes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One of the reasons why AI slop is so annoying is — paradoxically — the fact that a lot of it has gotten quite good. That means that when consuming content you have to continually be ascertaining if what you see is real or AI-generated; to put it in the terms of the Article I just quoted, you might want to lean back, but if you don’t want to be taken in or make a fool of yourself then you have to constantly be leaning forward to figure out what is or isn’t AI.&lt;/p&gt;
      &lt;p&gt;What this means for Vibes is the fact it is unapologetically and explicitly all AI is quite profound: it’s a true lean-back experience, where the fact none of it is real is a point of interest and — if Holz is right — inspiration and imagination. I find it quite relaxing to consume, in a way I don’t find almost any other feed on my phone.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The reason this is problematic for Meta (and YouTube) is that I’m not sure the company can counter Sora — or any other AI-generated content app that appears — in the same way they countered Snapchat and TikTok. Both challengers introduced new formats — Stories in the case of Instagram, and short-form video in the case of TikTok — but the content was still produced by humans; that made it much more palatable to stuff those formats into Instagram.&lt;/p&gt;
    &lt;p&gt;AI might be different: Meta certainly has data on this question, but I could imagine a scenario where users are actually annoyed and turned off by mixing AI-generated content with human content — and because Instagram isn’t really a social network anymore, the fact that that content might be made by or include your friends might not be enough. Implicit in this observation is the fact that I don’t think that human content is going anywhere; there just might be a smaller percentage of time devoted to it, and that’s a problem for a company predicated on marshaling attention.&lt;/p&gt;
    &lt;p&gt;The second issue for Meta is that their AI capabilities simply don’t match OpenAI, or Google’s for that matter. It’s clear that Meta knows this is the case — look no further than this summer’s hiring spree and total overhaul of their AI approach — but creating something like Sora is a lot more difficult than copying Stories or short-form video. I imagine this shortcoming will be rectified, but Sora is in the market now.&lt;/p&gt;
    &lt;p&gt;I also think that it is fair to raise some questions about point three. I have been a vocal proponent of AI being the key to the Metaverse, but my tastes in content may not be very broadly applicable! I loved Vibes because to me it felt like virtual reality, but if it was virtual reality, and no one liked it, maybe the concept actually isn’t that appealing? Time will tell, but I do keep coming back to the social aspects of Sora: people like the real world, and they like people they know, and virtual reality in particular just might not be that broadly popular.&lt;/p&gt;
    &lt;p&gt;And, while I’m here, I continue to think that Meta’s recent financial success is not entirely organic:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It turns out I was right last quarter that Meta had a lot of room to increase Reels monetization, but not just because they could target ads better (that was a part of it, as I noted above): rather, it turns out that short-form video is so addictive that Meta can simply drive more engagement — and thus more ad inventory — by pushing more of it. That’s impression driver number one — and the most important one. The second one is even more explicit: Meta simply started showing more ads to people (i.e. “ad load optimization”).&lt;/p&gt;
      &lt;p&gt;All of this ties back to where I started, about how Meta learned that you have to give investors short term results to get permission for long term investments. I don’t think it’s a coincidence that, in the same quarter where Meta decided to very publicly up its investment in the speculative “Superintelligence”, users got pushed more Reels and Facebook users in particular got shown more ads. The positive spin on this is that Meta has dials to turn; by the same token, investors who have flipped from intrinsically doubting Meta to intrinsically trusting them should realize that it was the pre-2022 Meta, the one that regularly voiced the importance of not pushing too many ads in order to preserve the user experience, that actually deserved the benefit of the doubt for growth that was purely organic. This last quarter is, to my mind, a bit more pre-determined.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;CEO Mark Zuckerberg framed the company’s new Personal Superintelligence like this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;As profound as the abundance produced by AI may one day be, an even more meaningful impact on our lives will likely come from everyone having a personal superintelligence that helps you achieve your goals, create what you want to see in the world, experience any adventure, be a better friend to those you care about, and grow to become the person you aspire to be.&lt;/p&gt;
      &lt;p&gt;Meta’s vision is to bring personal superintelligence to everyone. We believe in putting this power in people’s hands to direct it towards what they value in their own lives.&lt;/p&gt;
      &lt;p&gt;This is distinct from others in the industry who believe superintelligence should be directed centrally towards automating all valuable work, and then humanity will live on a dole of its output. At Meta, we believe that people pursuing their individual aspirations is how we have always made progress expanding prosperity, science, health, and culture. This will be increasingly important in the future as well.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I agree with the sentiment, but it’s worth being honest about today’s reality: Meta’s financial fortunes, at least for now, are in fact tied up in a centralized content engine that gives users “a dole of its output”; it’s nice from an investor perspective that Meta can turn the dials and get people to spend that much more time in Instagram. I for one can’t say that I feel particularly great when I’m done watching Reels for longer than I planned, and it’s certainly not a creative endeavor on my part — that’s for the content creators.&lt;/p&gt;
    &lt;p&gt;OpenAI, meanwhile, with both ChatGPT and Sora, is in fact placing easily accessible tools in people’s hands today, first with text and now with video. And, as I noted above, I actually find it exciting precisely because of the possibility that many more people are on the verge of discovering a creativity streak they didn’t even know they had, now that AI is available to substantiate it. So much Meta optimism is, paradoxically, pessimistic about the human condition; it may be the case that, to the extent that AI makes humans better, is the extent that Meta faces disruption.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://stratechery.com/2025/sora-ai-bicycles-and-meta-disruption/"/><published>2025-10-06T16:17:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45513485</id><title>Synology reverses policy banning third-party HDDs</title><updated>2025-10-08T22:09:16.296287+00:00</updated><content>&lt;doc fingerprint="7da303bb4dfe4cfc"&gt;
  &lt;main&gt;
    &lt;p&gt;Now, with the release of DSM 7.3, Synology has quietly walked the policy back. Third-party hard drives and 2.5-inch SATA SSDs can once again be used without triggering warning messages or reduced functionality. Drives from Seagate, WD, and others will work exactly as they did before—complete with full monitoring, alerts, and storage features.&lt;/p&gt;
    &lt;p&gt;For users, this means more choice and lower costs when building or upgrading a NAS. For Synology, it’s a much-needed course correction after months of backlash. While the company hasn’t publicly admitted fault, it’s clear that sales pressure and community outrage played a major role in reversing the decision.&lt;/p&gt;
    &lt;p&gt;Critics say the entire episode has damaged Synology’s reputation. The company seemed to believe that after QNAP’s well-known ransomware troubles, it could tighten control of the market without losing customers. Instead, the plan backfired—hard. Many loyal users have since turned to alternative brands or expressed hesitation about buying another Synology product.&lt;/p&gt;
    &lt;p&gt;Still, the return of open drive support is good news for anyone running a Synology NAS. It restores the flexibility that made the brand so popular in the first place. Whether this move is enough to win back frustrated users remains to be seen, but for now, DSM 7.3 brings a welcome dose of freedom back to the platform.&lt;/p&gt;
    &lt;p&gt;Source: Synology / nascompares&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.guru3d.com/story/synology-reverses-policy-banning-thirdparty-hdds-after-nas-sales-plummet/"/><published>2025-10-08T08:19:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45514164</id><title>Nobel Prize in Chemistry 2025</title><updated>2025-10-08T22:09:16.007355+00:00</updated><content>&lt;doc fingerprint="37d0923c8f250160"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Popular information&lt;/head&gt;
    &lt;p&gt;Popular science background: They have created new rooms for chemistry (pdf)&lt;lb/&gt;Populärvetenskaplig information: De har skapat nya rum för kemi (pdf)&lt;/p&gt;
    &lt;head rend="h2"&gt;They have created new rooms for chemistry&lt;/head&gt;
    &lt;p&gt;Susumu Kitagawa, Richard Robson and Omar M. Yaghi are awarded the Nobel Prize in Chemistry 2025 for the development of a new type of molecular architecture. The constructions they created – metal–organic frameworks – contain large cavities in which molecules can flow in and out. Researchers have used them to harvest water from desert air, extract pollutants from water, capture carbon dioxide and store hydrogen.&lt;/p&gt;
    &lt;p&gt;An attractive and very spacious studio apartment, specifically designed for your life as a water molecule – this is how an estate agent might describe one of all the metal–organic frameworks that laboratories around the world have developed in recent decades. Other constructions of this type are tailormade for capturing carbon dioxide, separating PFAS from water, delivering pharmaceuticals in the body or managing extremely toxic gases. Some can trap the ethylene gas from fruit – so they ripen more slowly – or encapsulate enzymes that break down traces of antibiotics in the environment.&lt;/p&gt;
    &lt;p&gt;Simply stated, metal–organic frameworks are exceptionally useful. Susumu Kitagawa, Richard Robson and Omar Yaghi are awarded the Nobel Prize in Chemistry 2025 because they created the first metal–organic frameworks (MOF) and demonstrated their potential. Thanks to the laureates’ work, chemists have been able to design tens of thousands of different MOFs, facilitating new chemical wonders.&lt;/p&gt;
    &lt;p&gt;As so often in the sciences, the story of the Nobel Prize in Chemistry 2025 begins with someone who thought outside the box. This time, inspiration came during preparations for a classic chemistry lesson, in which the students were to build molecules from rods and balls.&lt;/p&gt;
    &lt;head rend="h3"&gt;A simple wooden model of a molecule generates an idea&lt;/head&gt;
    &lt;p&gt;It was 1974. Richard Robson, who was teaching at the University of Melbourne, Australia, had been tasked with turning wooden balls into models of atoms, so students could create molecular structures. For this to work, he needed the university’s workshop to drill holes in them, so that wooden rods – the chemical bonds – could be attached to the atoms. However, the holes could not be randomly placed. Each atom – such as carbon, nitrogen or chlorine – forms chemical bonds in a specific way. Robson needed to mark out where the holes should be drilled.&lt;/p&gt;
    &lt;p&gt;When the workshop returned the wooden balls, he tested building some molecules. This was when he had a moment of insight: there was a vast amount of information baked into the holes’ positioning. The model molecules automatically had the correct form and structure, because of where the holes were situated. This insight led to his next idea: what would happen if he utilised the atoms’ inherent properties to link together different types of molecules, rather than individual atoms? Could he design new types of molecular constructions?&lt;/p&gt;
    &lt;head rend="h3"&gt;Robson builds innovative chemical creations&lt;/head&gt;
    &lt;p&gt;Every year, when Robson brought out the wooden models to teach new students, the same idea occurred to him. However, more than a decade passed before he decided to test it out. He started with a very simple model, inspired by the structure of a diamond, in which each carbon atom bonds to four others, forming a tiny pyramid (figure 2). Robson’s aim was to build a similar structure, but his would be based on positively charged copper ions, Cu+. Like carbon, they prefer to have four other atoms around them.&lt;/p&gt;
    &lt;p&gt;He combined the copper ions with a molecule that has four arms: 4′,4″,4”’,4””-tetracyanotetraphenylmethane. There’s no need to remember its complicated name, but it is important that the molecule at the end of each arm had a chemical group, nitrile, that was attracted to the positively charged copper ions (figure 2).&lt;/p&gt;
    &lt;p&gt;At that time, most chemists would have assumed that combining copper ions with the four-armed molecules would result in a bird’s nest of ions and molecules. But things went Robson’s way. As he had predicted, the ions and molecules inherent attraction to each other mattered, so they organised themselves into a large molecular construction. Just like carbon atoms in a diamond, they formed a regular crystalline structure. However, unlike diamond – which is a compact material – this crystal contained a vast number of large cavities (figure 2).&lt;/p&gt;
    &lt;p&gt;In 1989, Robson presented his innovative chemical creation in the Journal of the American Chemical Society. In his article, he speculates about the future and suggests that this could offer a new way to construct materials. These, he writes, could be given never previously seen properties, potentially beneficial ones.&lt;/p&gt;
    &lt;p&gt;As it turned out, he had foreseen the future.&lt;/p&gt;
    &lt;head rend="h3"&gt;Robson brings about a pioneering spirit in chemistry&lt;/head&gt;
    &lt;p&gt;As soon as the year after his pioneering work was published, Robson presented several new types of molecular constructions with cavities that were filled with various substances. He used one of them to exchange ions. He submerged the ion-filled construction in a fluid that contained a different type of ion. The result was that the ions changed places, demonstrating that substances could flow in and out of the construction.&lt;/p&gt;
    &lt;p&gt;In his experiments, Robson showed that rational design can be utilised for building crystals with spacious interiors that are optimised for specific chemicals. He suggested that this new form of molecular construction – when correctly designed – could be used to catalyse chemical reactions, for example.&lt;/p&gt;
    &lt;p&gt;However, Robson’s constructions were quite rickety and tended to fall apart. Many chemists thought they were useless, but some could see that he was onto something and, for them, his ideas about the future awakened a pioneering spirit. Those who would come to lay a stable foundation for his visions were Susumu Kitagawa and Omar Yaghi. Between 1992 and 2003 they made – separately – a series of groundbreaking discoveries. We will begin in the 1990s, with Kitagawa, who was working at Kindai University, Japan.&lt;/p&gt;
    &lt;head rend="h3"&gt;Kitagawa’s motto: even useless things can become useful&lt;/head&gt;
    &lt;p&gt;Throughout his research career, Susumu Kitagawa has followed an important principle: to try to see “the usefulness of useless.” As a young student, he read a book by the Nobel Prize laureate Hideki Yukawa. In it, Yukawa refers to an ancient Chinese philosopher, Zhuangzi, who says that we must question what we believe to be useful. Even if something does not bring immediate benefit, it may still turn out to be valuable.&lt;/p&gt;
    &lt;p&gt;Accordingly, when Kitagawa began to investigate the potential for creating porous molecular structures, he did not believe they had to have a specific purpose. When he presented his first molecular construction in 1992, it was indeed not particularly useful: a two-dimensional material with cavities in which acetone molecules could hide. However, it had resulted from a new way of thinking about the art of building with molecules. Like Robson, he used copper ions as cornerstones that were linked together by larger molecules.&lt;/p&gt;
    &lt;p&gt;Kitagawa wanted to continue experimenting with this new construction technology, but when he applied for grants, research funders did not think there was any particular point to his ambitions. The materials he created were unstable and had no purpose, so many of his proposals were rejected.&lt;/p&gt;
    &lt;p&gt;However, he did not give up and in 1997 he had his first major breakthrough. Using cobalt, nickel or zinc ions and a molecule called 4,4′-bipyridine, his research group created three-dimensional metal–organic frameworks that were intersected by open channels (figure 3). When they dried one of these materials – emptying it of water – it was stable and the spaces could even be filled with gases. The material could absorb and release methane, nitrogen and oxygen, without changing shape.&lt;/p&gt;
    &lt;head rend="h3"&gt;Kitagawa sees the uniqueness of his creations&lt;/head&gt;
    &lt;p&gt;Kitagawa’s constructions were both stable and had a function, but research funders were still unable to see their charm. One reason was that chemists already had zeolites, stable and porous materials, which they could build from silicon dioxide. These can absorb gases, so why would anyone develop a similar material that did not work as well?&lt;/p&gt;
    &lt;p&gt;Susumu Kitagawa understood that if he were to receive any major grants, he had to define what made metal–organic frameworks unique. So, in 1998, he described his vision in the Bulletin of the Chemical Society of Japan. He presented several advantages with MOFs. For example, they can be created from many types of molecules, so there is enormous potential for integrating different functions. Also – and this is important – he realised that MOFs can form soft materials. Unlike zeolites, which are usually hard materials, MOFs contain flexible molecular building blocks (figure 4) that can create a pliant material.&lt;/p&gt;
    &lt;p&gt;After this, all he had to do was to put his ideas into practice. Kitagawa, along with other researchers, started developing flexible MOFs. While they work on this, we will move our focus to the US, where Omar Yaghi was also occupied with taking molecular architecture to new heights.&lt;/p&gt;
    &lt;head rend="h3"&gt;A secret library visit opens Yaghi’s eyes to chemistry&lt;/head&gt;
    &lt;p&gt;Studying chemistry was not an obvious choice for Omar Yaghi. He and his many siblings were raised in a single room in Amman, Jordan, with no electricity or running water. School was a refuge from his otherwise challenging life. One day, when he was ten years old, he sneaked into the school library, which was usually locked, and picked a book at random from the shelf. On opening it, his eyes were drawn to unintelligible but captivating pictures – his first encounter with molecular structures.&lt;/p&gt;
    &lt;p&gt;At the age of 15 – and on his father’s stern instruction – Yaghi moved to the US to study. He was attracted by chemistry and eventually by the art of designing new materials, but found the traditional way of building new molecules too unpredictable. Normally, chemists combine substances that are to react with each other in a container. Then, to start the chemical reaction, they heat the container. The desired molecule forms, but is also often accompanied by a range of contaminating side products.&lt;/p&gt;
    &lt;p&gt;In 1992, when Yaghi started his first position as research group leader, at Arizona State University, he wanted to find more controlled ways in which to create materials. His aim was to use rational design to connect different chemical constituents, like pieces of Lego, to make large crystals. This turned out to be challenging, but they finally succeeded when the research group started combining metal ions with organic molecules. In 1995, Yaghi published the structure of two different two-dimensional materials; these were like nets and were held together by copper or cobalt. The latter could host guest molecules in its spaces and, when these were fully occupied, it was so stable that it could be heated to 350°C without collapsing. Yaghi describes this material in an article in Nature where he coins the name “metal–organic framework;” this term is now used to describe extended and ordered molecular structures that potentially contain cavities, and are built from metals and organic (carbon-based) molecules.&lt;/p&gt;
    &lt;head rend="h3"&gt;Just a few grams of Yaghi’s framework can contain a football pitch&lt;/head&gt;
    &lt;p&gt;Yaghi established the next milestone in the development of metal–organic frameworks in 1999, when he presented MOF-5 to the world. This material has become a classic in the field. It is an exceptionally spacious and stable molecular construction. Even when empty, it can be heated to 300°C without collapsing.&lt;/p&gt;
    &lt;p&gt;However, what caused many researchers to raise their eyebrows was the enormous area hiding inside the material’s cubic spaces. A couple of grams of MOF-5 holds an area as big as a football pitch, which means it can absorb much more gas than a zeolite could (figure 5).&lt;/p&gt;
    &lt;p&gt;Speaking of the differences between zeolites and MOFs, it took just a few years for researchers to succeed in developing soft MOFs. One of those who was able to present a flexible material was Susumu Kitagawa himself. When his material was filled with water or methane, it changed shape, and when it was emptied, it returned to its original form. The material behaved somewhat like a lung that can breathe gas in and out, changeable but stable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Yaghi’s research group conjures drinking water from desert air&lt;/head&gt;
    &lt;p&gt;Omar Yaghi laid the final bricks in the foundation of metal–organic frameworks in 2002 and 2003. In two articles, in Science and Nature, he shows that it is possible to modify and change MOFs in a rational manner, giving them different properties. One thing he did was to produce 16 variants of MOF-5, with cavities that were both larger and smaller than those in the original material (figure 6). One variant could store huge volumes of methane gas, which Yaghi suggested could be used in RNG-fuelled vehicles.&lt;/p&gt;
    &lt;p&gt;Subsequently, metal–organic frameworks have taken the world by storm. Researchers have developed a molecular kit with a wide range of different pieces that can be used to create new MOFs. These have different shapes and characters, providing incredible potential for the rational – or AI-based – design of MOFs for different purposes. Figure 7 provides examples of how MOFs can be utilised. For instance, Yaghi’s research group has harvested water from the desert air of Arizona. During the night, their MOF material captured water vapour from the air. When dawn came and the sun heated the material, they were able to collect the water.&lt;/p&gt;
    &lt;head rend="h3"&gt;MOF materials that capture carbon dioxide and toxic gases&lt;/head&gt;
    &lt;p&gt;Researchers have created numerous different and functional MOFs. So far, in most cases, the materials have only been used on a small scale. To harness the benefits of MOF materials for humanity, many companies are now investing in their mass production and commercialisation. Some have succeeded. For example, the electronics industry can now use MOF materials to contain some of the toxic gases required to produce semiconductors. Another MOF can instead break down harmful gases, including some that can be used as chemical weapons. Numerous companies are also testing materials that can capture carbon dioxide from factories and power stations, to reduce greenhouse gas emissions.&lt;/p&gt;
    &lt;p&gt;Some researchers believe that metal–organic frameworks have such huge potential that they will be the material of the twenty-first century. Time will tell, but through the development of metal–organic frameworks, Susumu Kitagawa, Richard Robson and Omar Yaghi have provided chemists with new opportunities for solving some of the challenges we face. They have thus – as Alfred Nobel’s will states – brought the greatest benefit to humankind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Further reading&lt;/head&gt;
    &lt;p&gt;Additional information on this year’s prizes, including a scientific background in English, is available on the website of the Royal Swedish Academy of Sciences, www.kva.se, and at www.nobelprize.org, where you can watch video from the press conferences, the Nobel Prize lectures and more. Information on exhibitions and activities related to the Nobel Prizes and the prize in economic sciences is available at www.nobelprizemuseum.se.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Royal Swedish Academy of Sciences has decided to award the Nobel Prize in Chemistry 2025 to&lt;/head&gt;
    &lt;p&gt;SUSUMU KITAGAWA&lt;lb/&gt;Born 1951 in Kyoto, Japan. PhD 1979 from Kyoto University, Japan. Professor at Kyoto University, Japan.&lt;/p&gt;
    &lt;p&gt;RICHARD ROBSON&lt;lb/&gt;Born 1937 in Glusburn, UK. PhD 1962 from University of Oxford, UK. Professor at University of Melbourne, Australia.&lt;/p&gt;
    &lt;p&gt;OMAR M. YAGHI&lt;lb/&gt;Born 1965 in Amman, Jordan. PhD 1990 from University of Illinois Urbana-Champaign, USA. Professor at University of California, Berkeley, USA.&lt;/p&gt;
    &lt;p&gt;“for the development of metal–organic frameworks”&lt;/p&gt;
    &lt;p&gt;Science Editors: Peter Brzezinski, Heiner Linke, Olof Ramström and Xiaodong Zou, the Nobel Committee for Chemistry&lt;lb/&gt;Text: Ann Fernholm&lt;lb/&gt;Translation: Clare Barnes&lt;lb/&gt;Illustrations: Johan Jarnestad&lt;lb/&gt;Editor: Alicia Hegner&lt;lb/&gt;© The Royal Swedish Academy of Sciences&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/chemistry/2025/popular-information/"/><published>2025-10-08T09:49:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45514433</id><title>One-man campaign ravages EU 'Chat Control' bill</title><updated>2025-10-08T22:09:15.508890+00:00</updated><content>&lt;doc fingerprint="7d9694e3ca051efe"&gt;
  &lt;main&gt;
    &lt;p&gt;BRUSSELS — A website set up by an unknown Dane over the course of one weekend in August is giving a massive headache to those trying to pass a European bill aimed at stopping child sexual abuse material from spreading online.&lt;/p&gt;
    &lt;p&gt;The website, called Fight Chat Control, was set up by Joachim, a 30-year-old software engineer living in Aalborg, Denmark. He made it after learning of a new attempt to approve a European Union proposal to fight child sexual abuse material (CSAM) — a bill seen by privacy activists as breaking encryption and leading to mass surveillance.&lt;/p&gt;
    &lt;p&gt;The site lets visitors compile a mass email warning about the bill and send it to national government officials, members of the European Parliament and others with ease. Since launching, it has broken the inboxes of MEPs and caused a stir in Brussels’ corridors of power.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.politico.eu/article/one-man-spam-campaign-ravages-eu-chat-control-bill-fight-chat-control/"/><published>2025-10-08T10:26:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516000</id><title>We found a bug in Go's ARM64 compiler</title><updated>2025-10-08T22:09:15.123289+00:00</updated><content>&lt;doc fingerprint="3b06c011ce263a54"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Every second, 84 million HTTP requests are hitting Cloudflare across our fleet of data centers in 330 cities. It means that even the rarest of bugs can show up frequently. In fact, it was our scale that recently led us to discover a bug in Go's arm64 compiler which causes a race condition in the generated code.&lt;/p&gt;
      &lt;p&gt;This post breaks down how we first encountered the bug, investigated it, and ultimately drove to the root cause.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Investigating a strange panic&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We run a service in our network which configures the kernel to handle traffic for some products like Magic Transit and Magic WAN. Our monitoring watches this closely, and it started to observe very sporadic panics on arm64 machines.&lt;/p&gt;
      &lt;p&gt;We first saw one with a fatal error stating that traceback did not unwind completely. That error suggests that invariants were violated when traversing the stack, likely because of stack corruption. After a brief investigation we decided that it was probably rare stack memory corruption. This was a largely idle control plane service where unplanned restarts have negligible impact, and so we felt that following up was not a priority unless it kept happening.&lt;/p&gt;
      &lt;p&gt;And then it kept happening.Â &lt;/p&gt;
      &lt;p&gt;When we first saw this bug we saw that the fatal errors correlated with recovered panics. These were caused by some old code which used panic/recover as error handling.Â &lt;/p&gt;
      &lt;p&gt;At this point, our theory was:Â &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;All of the fatal panics happen within stack unwinding.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;We correlated an increased volume of recovered panics with these fatal panics.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Recovering a panic unwinds goroutine stacks to call deferred functions.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;A related Go issue (#73259) reported an arm64 stack unwinding crash.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Letâs stop using panic/recover for error handling and wait out the upstream fix?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;So we did that and watched as fatal panics stopped occurring as the release rolled out. Fatal panics gone, our theoretical mitigation seemed to work, and this was no longer our problem. We subscribed to the upstream issue so we could update when it was resolved and put it out of our minds.&lt;/p&gt;
      &lt;p&gt;But, this turned out to be a much stranger bug than expected. Putting it out of our minds was premature as the same class of fatal panics came back at a much higher rate. A month later, we were seeing up to 30 daily fatal panics with no real discernible cause; while that might account for only one machine a day in less than 10% of our data centers, we found it concerning that we didnât understand the cause. The first thing we checked was the number of recovered panics, to match our previous pattern, but there were none. More interestingly, we could not correlate this increased rate of fatal panics with anything. A release? Infrastructure changes? The position of Mars? &lt;/p&gt;
      &lt;p&gt;At this point we felt like we needed to dive deeper to better understand the root cause. Pattern matching and hoping was clearly insufficient.Â &lt;/p&gt;
      &lt;p&gt;We saw two classes of this bug -- a crash while accessing invalid memory and an explicitly checked fatal error.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 153 gp=0x4000105340 m=324 mp=0x400639ea08 [GC worker (active)]:
/usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7ff97fffe870 sp=0x7ff97fffe860 pc=0x55558d4098fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1508 +0x68 fp=0x7ff97fffe860 sp=0x7ff97fffe810 pc=0x55558d3a9408
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1102
runtime.gcDrainMarkWorkerIdle(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7ff97fffe810 sp=0x7ff97fffe7a0 pc=0x55558d3ad514
runtime.gcDrain(0x400005bc50, 0x7)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7ff97fffe7a0 sp=0x7ff97fffe6f0 pc=0x55558d3ab248
runtime.markroot(0x400005bc50, 0x17e6, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7ff97fffe6f0 sp=0x7ff97fffe6a0 pc=0x55558d3ab578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7ff97fffe6a0 sp=0x7ff97fffe560 pc=0x55558d3acaa0
runtime.scanstack(0x4014494380, 0x400005bc50)
       /usr/local/go/src/runtime/traceback.go:447 +0x2ac fp=0x7ff97fffe560 sp=0x7ff97fffe4d0 pc=0x55558d3eeb7c
runtime.(*unwinder).next(0x7ff97fffe5b0?)
       /usr/local/go/src/runtime/traceback.go:566 +0x110 fp=0x7ff97fffe4d0 sp=0x7ff97fffe490 pc=0x55558d3eed40
runtime.(*unwinder).finishInternal(0x7ff97fffe4f8?)
       /usr/local/go/src/runtime/panic.go:1073 +0x38 fp=0x7ff97fffe490 sp=0x7ff97fffe460 pc=0x55558d403388
runtime.throw({0x55558de6aa27?, 0x7ff97fffe638?})
runtime stack:
fatal error: traceback did not unwind completely
       stack=[0x4015d6a000-0x4015d8a000
runtime: g8221077: frame.sp=0x4015d784c0 top=0x4015d89fd0&lt;/code&gt;
      &lt;/quote&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 187 gp=0x40003aea80 m=13 mp=0x40003ca008 [GC worker (active)]:
       /usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7fff2afde870 sp=0x7fff2afde860 pc=0x55557e2d98fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1489 +0x94 fp=0x7fff2afde860 sp=0x7fff2afde810 pc=0x55557e279434
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1112
runtime.gcDrainMarkWorkerDedicated(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7fff2afde810 sp=0x7fff2afde7a0 pc=0x55557e27d514
runtime.gcDrain(0x4000059750, 0x3)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7fff2afde7a0 sp=0x7fff2afde6f0 pc=0x55557e27b248
runtime.markroot(0x4000059750, 0xb8, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7fff2afde6f0 sp=0x7fff2afde6a0 pc=0x55557e27b578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7fff2afde6a0 sp=0x7fff2afde560 pc=0x55557e27caa0
runtime.scanstack(0x40042cc000, 0x4000059750)
       /usr/local/go/src/runtime/traceback.go:458 +0x188 fp=0x7fff2afde560 sp=0x7fff2afde4d0 pc=0x55557e2bea58
runtime.(*unwinder).next(0x7fff2afde5b0)
goroutine 0 gp=0x40003af880 m=13 mp=0x40003ca008 [idle]:
PC=0x55557e2bea58 m=13 sigcode=1 addr=0x118
SIGSEGV: segmentation violation&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Now we could observe some clear patterns. Both errors occur when unwinding the stack in &lt;code&gt;(*unwinder).next&lt;/code&gt;. In one case we saw an intentional fatal error as the runtime identified that unwinding could not complete and the stack was in a bad state. In the other case there was a direct memory access error that happened while trying to unwind the stack. The segfault was discussed in the GitHub issue and a Go engineer identified it as dereference of a go scheduler struct, m, when unwinding.Â   &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;A review of Go scheduler structs&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Go uses a lightweight userspace scheduler to manage concurrency. Many goroutines are scheduled on a smaller number of kernel threads â this is often referred to as M:N scheduling. Any individual goroutine can be scheduled on any kernel thread. The scheduler has three core types â &lt;code&gt;g&lt;/code&gt;Â  (the goroutine), &lt;code&gt;m&lt;/code&gt; (the kernel thread, or âmachineâ), and &lt;code&gt;p&lt;/code&gt; (the physical execution context, orÂ  âprocessorâ). For a goroutine to be scheduled a free &lt;code&gt;m&lt;/code&gt; must acquire a free &lt;code&gt;p&lt;/code&gt;, which will execute a g. Each &lt;code&gt;g&lt;/code&gt; contains a field for its m if it is currently running, otherwise it will be nil. This is all the context needed for this post but the go runtime docs explore this more comprehensively.Â &lt;/p&gt;
      &lt;p&gt;At this point we can start to make inferences on whatâs happening: the program crashes because we try to unwind a goroutine stack which is invalid. In the first backtrace, if a return address is null, we call &lt;code&gt;finishInternal&lt;/code&gt; and abort because the stack was not fully unwound. The segmentation fault case in the second backtrace is a bit more interesting: if instead the return address is non-zero but not a function then the unwinder code assumes that the goroutine is currently running. It'll then dereference m and fault by accessing &lt;code&gt;m.incgo&lt;/code&gt; (the offset of &lt;code&gt;incgo&lt;/code&gt; into &lt;code&gt;struct m&lt;/code&gt; is 0x118, the faulting memory access). &lt;/p&gt;
      &lt;p&gt;What, then, is causing this corruption? The traces were difficult to get anything useful from â our service has hundreds if not thousands of active goroutines. It was fairly clear from the beginning that the panic was remote from the actual bug. The crashes were all observed while unwinding the stack and if this were an issue any time the stack was unwound on arm64 we would be seeing it in many more services. We felt pretty confident that the stack unwinding was happening correctly but on an invalid stack.Â &lt;/p&gt;
      &lt;p&gt;Our investigation stalled for a while at this point â making guesses, testing guesses, trying to infer if the panic rate went up or down, or if nothing changed. There was a known issue on Goâs GitHub issue tracker which matched our symptoms almost exactly, but what they discussed was mostly what we already knew. At some point when looking through the linked stack traces we realized that their crash referenced an old version of a library that we were also using â Go Netlink.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 1267 gp=0x4002a8ea80 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /usr/local/go/src/runtime/preempt.go:308 +0x3c fp=0x4004cec4c0 sp=0x4004cec4a0 pc=0x46353c
runtime.asyncPreempt()
        /usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x4004cec6b0 sp=0x4004cec4c0 pc=0x4a6a8c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0x14360300000000?)
        /go/pkg/mod/github.com/!data!dog/[email protected]/nl/nl_linux.go:803 +0x130 fp=0x4004cfc710 sp=0x4004cec6c0 pc=0xf95de0
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;We spot-checked a few stack traces and confirmed the presence of this Netlink library. Querying our logs showed that not only did we share a library â every single segmentation fault we observed had happened while preempting &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt;.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Whatâs (async) preemption?&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;In the prehistoric era of Go (&amp;lt;=1.13) the runtime was cooperatively scheduled. A goroutine would run until it decided it was ready to yield to the scheduler â usually due to explicit calls to &lt;code&gt;runtime.Gosched()&lt;/code&gt; or injected yield points at function calls/IO operations. Since Go 1.14 the runtime instead does async preemption. The Go runtime has a thread &lt;code&gt;sysmon&lt;/code&gt; which tracks the runtime of goroutines and will preempt any that run for longer than 10ms (at time of writing). It does this by sending &lt;code&gt;SIGURG&lt;/code&gt; to the OS thread and in the signal handler will modify the program counter and stack to mimic a call to &lt;code&gt;asyncPreempt&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;At this point we had two broad theories:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go Netlink bug â likely due to &lt;code&gt;unsafe.Pointer&lt;/code&gt; usage which invoked undefined behavior but is only actually broken on arm64&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go runtime bug and we're only triggering it in &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt; for some reason&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;After finding the same bug publicly reported upstream, we were feeling confident this was caused by a Go runtime bug. However, upon seeing that both issues implicated the same function, we felt more skeptical â notably the Go Netlink library uses unsafe.Pointer so memory corruption was a plausible explanation even if we didn't understand why.&lt;/p&gt;
      &lt;p&gt;After an unsuccessful code audit we had hit a wall. The crashes were rare and remote from the root cause. Maybe these crashes were caused by a runtime bug, maybe they were caused by a Go Netlink bug. It seemed clear that there was something wrong with this area of the code, but code auditing wasnât going anywhere. &lt;/p&gt;
      &lt;p&gt;At this point we had a fairly good understanding of what was crashing but very little understanding of why it was happening. It was clear that the root cause of the stack unwinder crashing was remote from the actual crash, and that it had to do with &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;, but why? We were able to capture a coredump of a production crash and view it in a debugger. The backtrace confirmed what we already knew â that there was a segmentation fault when unwinding a stack. The crux of the issue revealed itself when we looked at the goroutine which had been preempted while calling &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;.Â     &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;(dlv) bt
0  0x0000555577579dec in runtime.asyncPreempt2
   at /usr/local/go/src/runtime/preempt.go:306
1  0x00005555775bc94c in runtime.asyncPreempt
   at /usr/local/go/src/runtime/preempt_arm64.s:47
2  0x0000555577cb2880 in github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive
   at
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779
3  0x0000555577cb19a8 in github.com/vishvananda/netlink/nl.(*NetlinkRequest).Execute
   at 
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:532
4  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
5  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
...
(dlv) disass -a 0x555577cb2878 0x555577cb2888
TEXT github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(SB) /vendor/github.com/vishvananda/netlink/nl/nl_linux.go
        nl_linux.go:779 0x555577cb2878  fdfb7fa9        LDP -8(RSP), (R29, R30)
        nl_linux.go:779 0x555577cb287c  ff430191        ADD $80, RSP, RSP
        nl_linux.go:779 0x555577cb2880  ff434091        ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
        nl_linux.go:779 0x555577cb2884  c0035fd6        RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The goroutine was paused between two opcodes in the function epilogue. Since the process of unwinding a stack relies on the stack frame being in a consistent state, it felt immediately suspicious that we preempted in the middle of adjusting the stack pointer. The goroutine had been paused at 0x555577cb2880, between&lt;code&gt; ADD $80, RSP, RSP and ADD $(16&amp;lt;&amp;lt;12), RSP, RSP&lt;/code&gt;.Â &lt;/p&gt;
      &lt;p&gt;We queried the service logs to confirm our theory. This wasnât isolated â the majority of stack traces showed that this same opcode was preempted. This was no longer a weird production crash we couldnât reproduce. A crash happened when the Go runtime preempted between these two stack pointer adjustments. We had our smoking gun.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Building a minimal reproducer&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;At this point we felt pretty confident that this was actually just a runtime bug and it should be reproducible in an isolated environment without any dependencies. The theory at this point was:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Stack unwinding is triggered by garbage collection&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption between a split stack pointer adjustment causes a crash&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;What if we make a function which splits the adjustment and then call it in a loop?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;quote&gt;
        &lt;code&gt;package main

import (
	"runtime"
)

//go:noinline
func big_stack(val int) int {
	var big_buffer = make([]byte, 1 &amp;lt;&amp;lt; 16)

	sum := 0
	// prevent the compiler from optimizing out the stack
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		big_buffer[i] = byte(val)
	}
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		sum ^= int(big_buffer[i])
	}
	return sum
}

func main() {
	go func() {
		for {
			runtime.GC()
		}
	}()
	for {
		_ = big_stack(1000)
	}
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This function ends up with a stack frame slightly larger than can be represented in 16 bits, and so on arm64 the Go compiler will split the stack pointer adjustment into two opcodes. If the runtime preempts between these opcodes then the stack unwinder will read an invalid stack pointer and crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; epilogue for main.big_stack
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
; preemption is problematic between these opcodes
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;After running this for a few minutes the program panicked as expected!&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;SIGSEGV: segmentation violation
PC=0x60598 m=8 sigcode=1 addr=0x118

goroutine 0 gp=0x400019c540 m=8 mp=0x4000198708 [idle]:
runtime.(*unwinder).next(0x400030fd10)
        /home/thea/sdk/go1.23.4/src/runtime/traceback.go:458 +0x188 fp=0x400030fcc0 sp=0x400030fc30 pc=0x60598
runtime.scanstack(0x40000021c0, 0x400002f750)
        /home/thea/sdk/go1.23.4/src/runtime/mgcmark.go:887 +0x290 

[...]

goroutine 1 gp=0x40000021c0 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /home/thea/sdk/go1.23.4/src/runtime/preempt.go:308 +0x3c fp=0x40003bfcf0 sp=0x40003bfcd0 pc=0x400cc
runtime.asyncPreempt()
        /home/thea/sdk/go1.23.4/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40003bfee0 sp=0x40003bfcf0 pc=0x75aec
main.big_stack(0x40003cff38?)
        /home/thea/dev/stack_corruption_reproducer/main.go:29 +0x94 fp=0x40003cff00 sp=0x40003bfef0 pc=0x77c04
Segmentation fault (core dumped)

real    1m29.165s
user    4m4.987s
sys     0m43.212s&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;A reproducible crash with standard library only? This felt like conclusive evidence that our problem was a runtime bug.&lt;/p&gt;
      &lt;p&gt;This was an extremely particular reproducer! Even now with a good understanding of the bug and its fix, some of the behavior is still puzzling. It's a one-instruction race condition, so itâs unsurprising that small changes could have large impact. For example, this reproducer was originally written and tested on Go 1.23.4, but did not crash when compiled with 1.23.9 (the version in production), even though we could objdump the binary and see the split ADD still present! We donât have a definite explanation for this behavior â even with the bug present there remain a few unknown variables which affect the likelihood of hitting the race condition.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;A single-instruction race condition window&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;arm64 is a fixed-length 4-byte instruction set architecture. This has a lot of implications on codegen but most relevant to this bug is the fact that immediate length is limited. &lt;code&gt;add&lt;/code&gt; gets a 12-bit immediate, &lt;code&gt;mov&lt;/code&gt; gets a 16-bit immediate, etc. How does the architecture handle this when the operands don't fit? It depends â &lt;code&gt;ADD&lt;/code&gt; in particular reserves a bit for "shift left by 12" so any 24 bit addition can be decomposed into two opcodes. Other instructions are decomposed similarly, or just require loading an immediate into a register first.Â &lt;/p&gt;
      &lt;p&gt;The very last step of the Go compiler before emitting machine code involves transforming the program into &lt;code&gt;obj.Prog&lt;/code&gt; structs. It's a very low level intermediate representation (IR) that mostly serves to be translated into machine code.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/fa2bb342d7b0024440d996c2d6d6778b7a5e0247/src/cmd/internal/obj/arm64/obj7.go#L856

// Pop stack frame.
// ADD $framesize, RSP, RSP
p = obj.Appendp(p, c.newprog)
p.As = AADD
p.From.Type = obj.TYPE_CONST
p.From.Offset = int64(c.autosize)
p.To.Type = obj.TYPE_REG
p.To.Reg = REGSP
p.Spadj = -c.autosize
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Notably, this IR is not aware of immediate length limitations. Instead, this happens in asm7.go when Go's internal intermediate representation is translated into arm64 machine code. The assembler will classify an immediate in conclass based on bit size and then use that when emitting instructions â extra if needed.&lt;/p&gt;
      &lt;p&gt;The Go assembler uses a combination of (&lt;code&gt;mov, add&lt;/code&gt;) opcodes for some adds that fit in 16-bit immediates, and prefers (&lt;code&gt;add, add + lsl 12&lt;/code&gt;) opcodes for 16-bit+ immediates.Â   &lt;/p&gt;
      &lt;p&gt;Compare a stack of (slightly larger than) &lt;code&gt;1&amp;lt;&amp;lt;15&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;15)
; 	return big_stack[0]
; }
MOVD $32776, R27
ADD R27, RSP, R29
MOVD $32784, R27
ADD R27, RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;With a stack of &lt;code&gt;1&amp;lt;&amp;lt;16&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;16)
; 	return big_stack[0]
; } 
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;In the larger stack case, there is a point between &lt;code&gt;ADD x, RSP, RSP&lt;/code&gt; opcodes where the stack pointer is not pointing to the tip of a stack frame. We thought at first that this was a matter of memory corruption â that in handling async preemption the runtime would push a function call on the stack and corrupt the middle of the stack. However, this goroutine is already in the function epilogue â any data we corrupt is actively in the process of being thrown away. What's the issue then?  &lt;/p&gt;
      &lt;p&gt;The Go runtime often needs to unwind the stack, which means walking backwards through the chain of function calls. For example: garbage collection uses it to find live references on the stack, panicking relies on it to evaluate &lt;code&gt;defer&lt;/code&gt; functions, and generating stack traces needs to print the call stack. For this to work the stack pointer must be accurate during unwinding because of how golang dereferences sp to determine the calling function. If the stack pointer is partially modified, the unwinder will look for the calling function in the middle of the stack. The underlying data is meaningless when interpreted as directions to a parent stack frame and then the runtime will likely crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/66536242fce34787230c42078a7bbd373ef8dcb0/src/runtime/traceback.go#L373

if innermost &amp;amp;&amp;amp; frame.sp &amp;lt; frame.fp || frame.lr == 0 {
    lrPtr = frame.sp
    frame.lr = *(*uintptr)(unsafe.Pointer(lrPtr))
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When async preemption happens it will push a function call onto the stack but the parent stack frame is no longer correct because sp was only partially adjusted when the preemption happened. The crash flow looks something like this: &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption happens between the two opcodes that &lt;code&gt;add x, rsp&lt;/code&gt; expands to&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Garbage collection triggers stack unwinding (to check for heap object liveness)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder starts traversing the stack of the problematic goroutine and correctly unwinds up to the problematic function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder dereferences &lt;code&gt;sp&lt;/code&gt; to determine the parent function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Almost certainly the data behind &lt;code&gt;sp&lt;/code&gt; is not a function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Crash&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;We saw earlier a faulting stack trace which ended in &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt; â in this case stack unwinding faulted while it was trying to determine the parent frame.Â    &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 90 gp=0x40042cc000 m=nil [preempted (scan)]:
runtime.asyncPreempt2()
/usr/local/go/src/runtime/preempt.go:306 +0x2c fp=0x40060a25d0 sp=0x40060a25b0 pc=0x55557e299dec
runtime.asyncPreempt()
/usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40060a27c0 sp=0x40060a25d0 pc=0x55557e2dc94c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0xff48ce6e060b2848?)
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779 +0x130 fp=0x40060b2820 sp=0x40060a27d0 pc=0x55557e9d2880
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Once we discovered the root cause we reported it with a reproducer and the bug was quickly fixed. This bug is fixed in go1.23.12, go1.24.6, and go1.25.0. Previously, the go compiler emitted a single &lt;code&gt;add x, rsp&lt;/code&gt; instruction and relied on the assembler to split immediates into multiple opcodes as necessary. After this change, stacks larger than 1&amp;lt;&amp;lt;12 will build the offset in a temporary register and then add that to &lt;code&gt;rsp&lt;/code&gt; in a single, indivisible opcode. A goroutine can be preempted before or after the stack pointer modification, but never during. This means that the stack pointer is always valid and there is no race condition.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;LDP -8(RSP), (R29, R30)
MOVD $32, R27
MOVK $(1&amp;lt;&amp;lt;16), R27
ADD R27, RSP, RSP
RET&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This was a very fun problem to debug. We donât often see bugs where you can accurately blame the compiler. Debugging it took weeks and we had to learn about areas of the Go runtime that people donât usually need to think about. Itâs a nice example of a rare race condition, the sort of bug that can only really be quantified at a large scale.&lt;/p&gt;
      &lt;p&gt;Weâre always looking for people who enjoy this kind of detective work. Our engineering teams are hiring. &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/how-we-found-a-bug-in-gos-arm64-compiler/"/><published>2025-10-08T13:33:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516426</id><title>Now open for building: Introducing Gemini CLI extensions</title><updated>2025-10-08T22:09:14.949863+00:00</updated><content>&lt;doc fingerprint="994b9cc09a2ba6b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Now open for building: Introducing Gemini CLI extensions&lt;/head&gt;
    &lt;p&gt;The best tools are the ones that adapt to you, not the other way around. For developers whose work is becoming more complex every day, the need for personalized, intelligent assistance has never been greater.&lt;/p&gt;
    &lt;p&gt;That’s why we’re announcing Gemini CLI extensions, a new framework that allows you to customize Gemini CLI and connect it to the tools you use most, all from the command line. Instead of context-switching between your terminal and other tools, you can now bring those tools directly into your workflow.&lt;/p&gt;
    &lt;p&gt;In just three months since our launch, more than one million developers are building with Gemini CLI. And they can now access a new ecosystem of extensions from Google, plus industry leaders like Dynatrace, Elastic, Figma, Harness, Postman, Shopify, Snyk and Stripe, and the broader open-source community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Personalize your command line with Gemini CLI extensions&lt;/head&gt;
    &lt;p&gt;Gemini CLI is an open-source, AI-powered agent for your terminal, and extensions are its power-ups — pre-packaged, easily installable integrations that connect it to external tools including everything from databases and design platforms to payment services.&lt;/p&gt;
    &lt;p&gt;Each extension contains a built-in “playbook” that instantly teaches the AI how to use the new tools effectively. This means you get meaningful results from the very first command, no complex setup required, allowing you to tailor your experience with the tools most valuable to you.&lt;/p&gt;
    &lt;p&gt;It’s easy to install an extension — simply type: “gemini extensions install &amp;lt;add your GitHub URL or local path&amp;gt;” from your command line.&lt;/p&gt;
    &lt;p&gt;Easily install extensions from Gemini CLI's open ecosystem&lt;/p&gt;
    &lt;head rend="h2"&gt;Access an open, growing ecosystem of partners and builders&lt;/head&gt;
    &lt;p&gt;Extensions put Gemini CLI at the center of an open ecosystem in which anyone can build integrations. That’s why in addition to our own set of Google-created extensions, we’re launching with a strong group of partners and open-source contributors.&lt;/p&gt;
    &lt;p&gt;To make extensions easy to find and use, we’re also launching a new Gemini CLI Extensions page. Here, you can discover a growing catalog of community, partner and Google-built extensions, ranked by popularity by GitHub stars.&lt;/p&gt;
    &lt;p&gt;You can get started with extensions from a wide range of launch partners and more coming soon. These include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dynatrace: Get real-time insights into application performance, availability and root-cause analysis directly from your CLI to accelerate debugging.&lt;/item&gt;
      &lt;item&gt;Elastic: Search, retrieve and analyze Elasticsearch data in developer and agentic workflows. Connects directly to an Elastic MCP server hosted in Elastic Cloud Serverless.&lt;/item&gt;
      &lt;item&gt;Figma: Generate code from frames, extract design context, retrieve resources and ensure design system consistency with your codebase.&lt;/item&gt;
      &lt;item&gt;Harness: Bring AI-powered intelligence to CI/CD by analyzing pipeline execution data, surfacing cost insights, detecting failure patterns and automatically remediating issues to accelerate software delivery.&lt;/item&gt;
      &lt;item&gt;Postman: Have AI agents access Postman workspaces, manage collections and environments, evaluate APIs and automate workflows through natural language interactions.&lt;/item&gt;
      &lt;item&gt;Shopify: Connect to Shopify's developer ecosystem with tools to search docs, explore API schemas, and build serverless Shopify functions.&lt;/item&gt;
      &lt;item&gt;Snyk: Seamlessly integrate Snyk's comprehensive security capabilities into your development process to ensure that code is secure at inception.&lt;/item&gt;
      &lt;item&gt;Stripe: Define a set of tools that AI agents can use to interact with the Stripe API and search the knowledge base.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;More than a connection: See how extensions add intelligence&lt;/head&gt;
    &lt;p&gt;Developers get more from Gemini CLI by integrating Model Context Protocol (MCP) tools, and extensions build on this by enabling even smarter interactions. While MCP provides the raw connection to a tool, a Gemini CLI extension takes the basic ability to use that tool and wraps it in a layer of intelligence and personalization. This makes the experience seamless for developers.&lt;/p&gt;
    &lt;p&gt;Gemini CLI extensions are easy to install and have a simple “playbook” — a set of tools it knows how to use, like a local script or a third-party API. When you run a command, Gemini CLI consults this playbook and uses the context from your environment (like your local files and git status) to execute the right tool for the job, exactly how you intended.&lt;/p&gt;
    &lt;p&gt;If you want to look under the hood, Gemini CLI extensions package instructions, MCP servers and custom commands into a familiar and user-friendly format. Extensions can bundle any combination of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One or more MCP servers: To connect with external tools and services.&lt;/item&gt;
      &lt;item&gt;Context files: Like GEMINI.md or bring your own context file type(s), to provide specific instructions and guidelines to the model.&lt;/item&gt;
      &lt;item&gt;Excluded tools: Useful for disabling built-in tools or offering alternative implementations.&lt;/item&gt;
      &lt;item&gt;Custom commands: To encapsulate complex prompts into simple slash commands.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use Gemini CLI to access all kinds of extensions, including one for image generation with Nano Banana&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover Google-created extensions&lt;/head&gt;
    &lt;p&gt;Googlers have also been building a suite of extensions for Gemini CLI. Give them a try; they just might help you solve some common developer pain points, deepen integration with other Google offerings or just have fun:&lt;/p&gt;
    &lt;p&gt;For cloud-native deployments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go from local code to a live public URL in a single step, with the Cloud Run extension.&lt;/item&gt;
      &lt;item&gt;Manage your Google Kubernetes Engine (GKE) clusters, from checking node health to deploying applications with our GKE extension.&lt;/item&gt;
      &lt;item&gt;Give Gemini CLI the ability to easily interact with your Google Cloud environment by using the gcloud extension.&lt;/item&gt;
      &lt;item&gt;Understand, manage and troubleshoot your Google Cloud environment with the Google Cloud Observability extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For app builders:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Perform code reviews on your codebase with the Code Review extension.&lt;/item&gt;
      &lt;item&gt;Perform AI-powered vulnerability detection on your code changes with the Security extension.&lt;/item&gt;
      &lt;item&gt;Retrieve place info from Google and embed Google Maps imagery into applications with the Google Maps Platform extension.&lt;/item&gt;
      &lt;item&gt;Create, build, refactor, debug and maintain Flutter applications with the Flutter extension.&lt;/item&gt;
      &lt;item&gt;Control and inspect a live Chrome browser for reliable automation, in-depth debugging and performance analysis with the Chrome DevTools extension.&lt;/item&gt;
      &lt;item&gt;Set up and manage your Firebase backend with the Firebase extension.&lt;/item&gt;
      &lt;item&gt;Enhance the user experience for building GenAI-powered apps with the Genkit extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For generative AI and data interaction:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For a bit of fun, generate and edit images with the Nano Banana extension 🍌.&lt;/item&gt;
      &lt;item&gt;Explore and visualize your business data with the Looker extension.&lt;/item&gt;
      &lt;item&gt;Build applications and analyze trends with services like Cloud SQL, AlloyDB BigQuery and more with our Data Cloud extensions.&lt;/item&gt;
      &lt;item&gt;Connect to enterprise data easily and securely using the MCP Toolbox for Databases extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Build the CLI of your dreams&lt;/head&gt;
    &lt;p&gt;Gemini CLI extensions put you in control. You can combine extensions, chain commands and build a personalized toolchain that perfectly fits the way you work.&lt;/p&gt;
    &lt;p&gt;Whether you want to streamline a personal workflow or integrate a company's internal tools, you now have the power to create the command-line experience you've always wanted.&lt;/p&gt;
    &lt;p&gt;Ready to get started? Visit the new Gemini CLI Extensions page to explore community tools, and check out our templates and a step-by-step guide to help you build your first extension and share it with the community.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/technology/developers/gemini-cli-extensions/"/><published>2025-10-08T14:13:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516584</id><title>Show HN: Recall: Give Claude memory with Redis-backed persistent context</title><updated>2025-10-08T22:09:14.850349+00:00</updated><content/><link href="https://www.npmjs.com/package/@joseairosa/recall"/><published>2025-10-08T14:28:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516690</id><title>Vectrex Mini</title><updated>2025-10-08T22:09:14.250747+00:00</updated><content>&lt;doc fingerprint="27d74f9593ed6a7c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Vectrex Mini Details&lt;/head&gt;
    &lt;p&gt;Experience the spirit of the original Vectrex in a modern, compact format. &lt;lb/&gt;After three years of development and refinement, the Vectrex Mini is ready for production.&lt;/p&gt;
    &lt;p&gt;The Kickstarter goes live on November 3rd 2025.&lt;/p&gt;
    &lt;head rend="h2"&gt;Console&lt;/head&gt;
    &lt;p&gt;The Vectrex Mini captures the full spirit of the original Vectrex in a case half the size. Its plastic shell is made using injection molding, just like the console of the time, and each unit will come in packaging inspired by the original box.&lt;/p&gt;
    &lt;p&gt;On the technical side, the console features a built-in 5-inch AMOLED display with a resolution of 800×600, delivering sharp and bright vector graphics. Power is supplied via USB-C, so it can run on a wall outlet as well as an external battery. The Vectrex Mini is powered by an ESP32, a modern and reliable microprocessor, powerful enough to run the entire Vectrex game library with performance beyond many arcade machines of the era.&lt;/p&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;p&gt;The console will include 12 built-in classic games, mostly from the General Consumer Electronics catalog (the final selection is still being completed, with the official list to be announced later). Each game will come with its own physical overlay to recreate the visual experience of the 1980s.&lt;/p&gt;
    &lt;p&gt;Sticker sheets will also be included, featuring different official logos (current, European, American, and Japanese), so players can customize their machine.&lt;/p&gt;
    &lt;p&gt;A Vector Clock mode will turn the console into a clock displaying the time, date, and weather thanks to Wi-Fi connectivity.&lt;/p&gt;
    &lt;p&gt;An alarm can also be set, allowing the Vectrex Mini to double as a stylish bedside clock or desk companion.&lt;/p&gt;
    &lt;p&gt;The Vectrex Mini offers several connection options. A micro-SD slot will allow the addition of games or homebrews (a card will likely not be included).&lt;/p&gt;
    &lt;p&gt;A Bluetooth controller with four action buttons and a self-centering analog joystick will be provided and can be stored in the console as with the original. A second controller can also be connected for multiplayer.&lt;/p&gt;
    &lt;p&gt;Finally, a video output will be integrated at the back of the unit (the final choice between HDMI or USB-C will be confirmed during production).&lt;/p&gt;
    &lt;head rend="h2"&gt;Special Edition&lt;/head&gt;
    &lt;p&gt;A limited run of 250 units will be produced. The White Edition has all the features of the standard version but stands out with a fully white finish, a unique serial number, and a certificate of authenticity. Aimed at collectors, it will come in its own box.&lt;/p&gt;
    &lt;head rend="h2"&gt;Merchandise&lt;/head&gt;
    &lt;p&gt;Several items will be available to accompany the release of the Vectrex Mini:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A second controller can be purchased separately and will include a dongle to connect it to the original console.&lt;/item&gt;
      &lt;item&gt;Four T-shirt designs will be released, featuring artwork of the console itself, a Vectrex-style Superman, Minestrom, and Spike.&lt;/item&gt;
      &lt;item&gt;A book written by Douglas Alves will also be part of the collection. A well-known French specialist in video game history, longtime journalist, MO5 association member, and teacher in the field, he retraces the story of the Vectrex in this work.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Kickstarter Campaign&lt;/head&gt;
    &lt;p&gt;After three years dedicated to prototyping and preparing for production, the project is now ready. We have set a clear timeline with defined milestones for testing, final adjustments, and assembly. Manufacturing will be carried out in partnership with teams based in Taiwan.&lt;/p&gt;
    &lt;p&gt;The Kickstarter campaign aims to finance this production phase. We waited until we had a fully functional prototype, strong partners, and a realistic schedule before launching. See you on November 3 on Kickstarter to discover all the details and join the adventure.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vectrex.com/vectrex-mini-details/"/><published>2025-10-08T14:38:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516968</id><title>After 2 decades of tinkering, MAME cracks the Hyper Neo Geo 64</title><updated>2025-10-08T22:09:13.964830+00:00</updated><content>&lt;doc fingerprint="372e9953cb024b11"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;After 2 decades of tinkering, MAME finally cracks the Hyper Neo Geo 64&lt;/head&gt;
    &lt;p&gt;How MAME devs finally got sound working for the 3D arcade system. Plus: PC Engine LaserActive support gets fast-tracked.&lt;/p&gt;
    &lt;p&gt;Let me test out a theory here: If you're into emulation, you're into older video games, ergo you're into old stuff of all kinds. That means you, savvy, good-taste-having reader, will love this spread of photos I took in Tokyo last week at the National Film Archive of Japan, which has a small but lovely set of exhibits from the history of Japanese film. Since you like playing Super Nintendo games this is absolutely your shit, right? Right??&lt;/p&gt;
    &lt;p&gt;Okay, I'll throw in a pic of some games to sweeten the deal.&lt;/p&gt;
    &lt;p&gt;This issue is coming a week late as I was off to Japan last week for my first-ever visit to the Tokyo Game Show, and too busy working (and working at eating sushi) to squeeze in a newsletter. And it's coming late in the day Sunday — apologies! But patience pays off!!&lt;/p&gt;
    &lt;p&gt;This issue's main story has been cookin' for a minute: last month the news landed that MAME had finally properly cracked Hyper Neo Geo 64 support, but the celebration was a little bit premature. The arcade system was playable in MAME, yes, but sound was in really shoddy shape — it wasn't yet a particularly good experience.&lt;/p&gt;
    &lt;p&gt;Over the last month or so that's been changing, and changing fast, with frequent improvements checked in by a pair of regular MAME contributors. So now is the time to talk about it, and soon (with the very next MAME release!) it will be time to actually play it. Considering there are only seven Hyper Neo Geo 64 games, well, that's a week's worth of evenings sorted.&lt;/p&gt;
    &lt;p&gt;As with every trip to Tokyo I took a few hours to stop by Akihabara this time, but its pull has certainly lessened over the years as retro prices have skyrocketed from where they were a decade ago and the selection has gotten thinner and thinner. Still, browsing the stores is a fun time and there are great finds to be found as long as you're not looking for anything too in-demand. I picked up one game: Kamiwaza, a PS2 "stealth" game where you play as a thief in feudal Japan stealing hella stuff.&lt;/p&gt;
    &lt;p&gt;As you might guess, it's more silly than stealthy.&lt;/p&gt;
    &lt;p&gt;Shout out to my shopping partner in crime, Paradise Killer's Oli Clarke Smith, for the recommendation. I've got a feature on the way in the coming weeks over at PC Gamer based on some of the games we picked up and how they speak to the "identity" of particular retro consoles. I'm hoping it'll be a fun read!&lt;/p&gt;
    &lt;p&gt;For now, let's hop into MAME; then stick around for an update on Pioneer LaserActive emulation!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Two&lt;/head&gt;
    &lt;head rend="h3"&gt;1. The Hyper Neo Geo comes to MAME: Now with working sound!&lt;/head&gt;
    &lt;p&gt;21 years ago, David "MameHaze" Haywood started looking into what it would take to add support for the Hyper Neo Geo 64 arcade system — then just five years past the end of its short lifespan — to MAME. "When I started looking at the system back in 2004 MAME didn't really do much 3D stuff at all, even things like the MIPS (main CPU) core were in a much rougher shape, there were no dumps of the I/O MCU at all (happened only a few years ago) and the PC I had at the time barely had enough memory to load and decode even the 2D graphics," he says.&lt;/p&gt;
    &lt;p&gt;"It was also pre-YouTube, and even in the early days of YouTube you didn't really get much in the way of good reference material. Kinda crazy to think that a lot of people who are probably interested in the emulation of the platform now as younger adults weren't even born when emulation work first started on it!"&lt;/p&gt;
    &lt;p&gt;A few weeks ago, two decades after he started looking into the system, Haywood finally promoted it to "working" status in MAME. But that move was a bit of a formality, or a bit sneaky, depending on how you look at it. Though the promotion got some buzz, it wasn't truly finished: proper sound emulation was still missing. Haywood actually hadn't worked on the core since 2023, and decided, well, people had been playing the games for long enough without sound, he might as well slap the "working" label on. It turned out to be the final push other MAME contributors needed to take a crack at tuning up the sound.&lt;/p&gt;
    &lt;p&gt;What's the Hyper Neo Geo's whole deal, anyway? Well, it makes some sense that the system would be more a curiosity for younger folks to discover than an object of intense nostalgia like some of MAME's more high-profile cores or the original Neo Geo; it was only active in arcades for two years from 1997 to 1999 during the awkward transitional period to 3D, with just seven games released for it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Road's Edge&lt;/item&gt;
      &lt;item&gt;Samurai Shodown 64&lt;/item&gt;
      &lt;item&gt;Xtreme Rally&lt;/item&gt;
      &lt;item&gt;Beat Busters: Second Nightmare&lt;/item&gt;
      &lt;item&gt;Samurai Shodown 64: Warriors Rage&lt;/item&gt;
      &lt;item&gt;Fatal Fury: Wild Ambition&lt;/item&gt;
      &lt;item&gt;Buriki One&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here's a nice write-up of the system from Nicole Express that delves into the hardware:&lt;/p&gt;
    &lt;p&gt;None of these games have the Bloodborne-style pull to individually inspire interest in emulation, but the MAME team's all-consuming drive to reverse-engineer and archive every arcade system in existence kept it on the radar. Haywood's initial investigation into it predated even MAME's high profile support of Capcom's CPS3 boards, for instance, but once that platform was decrypted support was added quite quickly because hell yeah people wanted to play Street Fighter III. By comparison, "Hyper64 has been a 21 year on-and-off slog," he says.&lt;/p&gt;
    &lt;p&gt;It's a perfect representation one of the eternal frustrations of emulation development: People often ask why no one's working on something when they actually are. Just invisibly.&lt;/p&gt;
    &lt;quote&gt;"The sheer number of times I picked up the Hyper64 driver and pumped weeks of work in it only to not be able to make any progress at all was frustrating at the best of times. Just trying to gain an understanding of it all, but ending up not making any headway at all. That's something I don't think people really appreciate when it comes to emulation, the amount of time that you have to put in which often yields no positive results at all, where all you can really conclude is it doesn't work the way you were hoping it would work."&lt;/quote&gt;
    &lt;p&gt;A few years ago, Haywood finally made substantial progress: Someone dumped the I/O microcontroller, and he was able to write a CPU core to emulate it. "The inputs finally started working in a bunch of the games, which allowed me to explore them further and make video improvements," he said.&lt;/p&gt;
    &lt;p&gt;"Other components improving in MAME over the years has really helped too. When I started MAME didn't have a CPU core for the V53 either (which is a V33 CPU with variolus peripherals) and is the CPU driving the sound DSP. At some point in MAME's history the V53 support got fleshed out (for other systems) which has really come in handy now, as proper sound emulation requires that to be running properly."&lt;/p&gt;
    &lt;p&gt;When Haywood marked the platform as working, it caught the attention of another longtime MAME contributor: R. Belmont. For the last month or so, Belmont, as well as two other devs, Happy and O. Galibert, have been chipping away at making the games sound like they're supposed to.&lt;/p&gt;
    &lt;p&gt;"Haze marking them working did provide a push, and Happy had done a detailed disassembly of the sound CPU program which was quite useful," Belmont recently posted on Reddit. Belmont and Galibert have both been working on synthesizer support in MAME, and the Hyper Neo Geo 64's sound chip happens to be used it one, providing them with some convenient overlap in interest/speciality.&lt;/p&gt;
    &lt;p&gt;The current MAME release, 0.281, includes a series of rapid-fire improvements as documented by Belmont in a few videos on YouTube:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Very early work in progress on better audio for the Hyper Neo Geo 64 system. There is a loooong way to go, this is just some very basic fixes so far."&lt;/item&gt;
      &lt;item&gt;"Since the first video we've got the basic sample starts and stops working the actual correct way they're supposed to and added a preliminary support for volume envelopes, which also helps the audio balance. Still a lot of work to go though."&lt;/item&gt;
      &lt;item&gt;"More progress today! I figured out how the volume envelopes really work, and that made Buriki One's intro mostly awesome."&lt;/item&gt;
      &lt;item&gt;"Barring any last minute adjustments, this is what HNG64 audio will sound like in MAME 0.281. Since the last video, the per-voice low pass filter was added, which cleans up some of the high frequency 'hash' audible previously and makes the sound a bit cleaner."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It was a ton of progress for a month, taking Hyper Neo Geo 64 sound support from messy and inaccurate to, at least, broadly playable without assaulting your ears. But the real refinements have been coming in just the last few days since 0.281's release in late September.&lt;/p&gt;
    &lt;p&gt;But the next build is gonna be the big one. October's upcoming MAME 0.282 release will notably fix up the audio issues in one of the the trickiest games, Xtreme Rally, while really polishing up the rest. Here's what Belmont's noted in update notes for 0.282 so far:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Olivier Galibert figured out how they squeezed 12 bits of dynamic range into 8 bits (presumably this is the format from Roger Linn's original MPC60 design) and replaced the biquad low-pass filter with a more likely Chamberlin one that fits the parameters better. Also there were some improvements to the filter envelope. All this results in much clearer and higher-fidelity sound."&lt;/item&gt;
      &lt;item&gt;"This time we've figured out how looping samples actually work, fixed the final mixdown to not introduce any distortion, and fixed the filter envelope. The result? A dramatic improvement to Beast Busters Second Nightmare's intro."&lt;/item&gt;
      &lt;item&gt;"So the previous fixes seem to have solved Samurai Shodown 64 and SS64 2, but Xtreme Rally (aka Off Beat Racer) was still extremely broken. The engine sound barely worked, sounds were missing, and some sounds would stick looping forever. This time the problem wasn't actually in the sound emulation itself; Xtreme Rally has unique code among the 7 HNG64 games that tries to push sound commands to the sound CPU as quickly as possible. This resulted in as many as 2/3rds of the commands getting dropped on the floor. I have fixed that issue so that all of the commands make it, and Xtreme Rally now sounds great."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since Belmont made that post he dialed in a few more improvements where the wrong sounds were playing in certain instances in the game. Here's a video from Haywood showing off the vastly improved audio (though he notes "some graphical issues, such as the fog in the tunnel still need addressing eventually.")&lt;/p&gt;
    &lt;p&gt;Once MAME 0.282 releases, the Hyper Neo Geo 64 will well and truly be worthy of the "working" label. Turns out it just needed that last little push.&lt;/p&gt;
    &lt;p&gt;In a perfect encapsulation of how these sorts of collaborative projects come together, Galibert noted on Reddit that despite their contributions to the core stemming from an interest in emulating synthesizers, "amusingly, the synth itself (MPC3000) is not working at all yet." Some parts of the synthesizer remain undumped and undocumented, just as parts of the Hyper Neo Geo once were; sometimes while you're waiting for all the pieces to fall into place, it turns out one of the pieces you do have happens to fit into another puzzle entirely.&lt;/p&gt;
    &lt;p&gt;"It's just been a long slow process," Haywood said. "Things have inched forward a little bit over the years, and the surrounding code in MAME has become better / more capable, allowing for more progress to be made, step by step."&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Can't stop Pioneering: NEC support and big LaserActive performance improvements arrive in the latest Ares nightlies&lt;/head&gt;
    &lt;p&gt;Often I end a big story, like the August issue's deep dive into the 16 years it took to emulate the Pioneer LaserActive, with the door open to a follow-up many months or years down the road. In this story, our hero — emudev Nemesis — finished work on one of two modules for the Laserdisc-based gaming console, making it possible to play Sega's Mega LD games via emulation for the first time.&lt;/p&gt;
    &lt;p&gt;As of publication time, Nemesis was juuuust starting to take a look at the work required to do the same for the other "pak" players could slot into the LaserActive to play NEC PC Engine games, but who knew how long that would take?&lt;/p&gt;
    &lt;p&gt;Maybe we'd come back to it before the end of 2026, or maybe next year, or maybe in half a deca-&lt;/p&gt;
    &lt;p&gt;Oh. He already did it.&lt;/p&gt;
    &lt;p&gt;"NEC LDROM2 support is functioning on nightly builds of the v147 prerelease, and will be included in the next official Ares release," Nemesis recently wrote on his website. It took less than three weeks. While you can grab the nightly build anytime, when the next stable build of Ares releases, it'll be all official-like.&lt;/p&gt;
    &lt;p&gt;Considering the bulky size of the LaserActive game rips — they can take up dozens of gigabytes — some performance optimizations Nemesis has implemented in the last few days are almost as exciting as the second console support. Because now you should be able to run the images off a decent HDD without performance issues. Here's the breakdown on Github:&lt;/p&gt;
    &lt;quote&gt;"This change brings speed enhancements to LaserActive games. The linear resampling coefficient precalculation reduces overall CPU overhead by approximately 30%, making slower CPUs much more likely to achieve full framerate. Additionally, frame prefetch using a background thread makes games much more tolerant of IO latency, making it possible to play games back from platter drives over SATA3.&lt;lb/&gt;This should be sufficient to make emulation performance acceptable on 95%+ of systems, and I don't have any further optimizations planned at this stage."&lt;/quote&gt;
    &lt;p&gt;So then — LaserActive support is more or less feature complete. What can you play? What should you play? Seeing as the system's deader than dead and nobody's likely to be playing copyright cop, the Laserdisc rips are being freely uploaded and shared here. Not every game is available yet, but here's where you should probably start:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vajra and Vajra 2 - A pair of LaserActive-exclusive rail shooters by Data West&lt;/item&gt;
      &lt;item&gt;Triad Stone - An FMV game in the Dragon's Lair game&lt;/item&gt;
      &lt;item&gt;J.B. Harold - Blue Chicago Blues - As described by Nemesis, an "FMV murder mystery detective game, with a surprising amount of freedom. You have control over where to go, what actions to take, and what questions to ask. This title came on a double-sided CLV disc, giving it four times the video content of a typical single-sided CAV LaserActive title. The game also used separate video streams per field, to squeeze a whopping 4 hours of footage into one disc."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are a couple other cool games and curiosities on the system, including more rail shooters, some prototypes of Myst, and a German TV movie that lets you swap between different perspectives — but the above should give you a taste for that sweet sweet (or fuzzy, fuzzy) '90s laser gaming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Patching In&lt;/head&gt;
    &lt;p&gt;MiSTer's Taito F2 core pulls off a Hat Trick – Taito's 1990 game Football Champ, aka Hat Trick Hero, is now playable on the MiSTer's arcade core, as is the baseball game Ah Eikou no Koshien. The latter's surprisingly expressive for its era and looks like a lot more fun than I expect from '90s baseball games.&lt;/p&gt;
    &lt;p&gt;MiSTer's CDi core once again threatens you by functioning – In the latest unstable nightly build of the CDi core, developer Andre Zeps has committed several crimes of CDi improvement, including: "Fix dual SDRAM mode," "Add support for chroma subcarrier for clean composite video from external RGB converters," and "- Add bob deinterlacing to ascal." Go on then, but don't blame me if you start bleeding from every orifice while playing Wind of Gamelon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core Report&lt;/head&gt;
    &lt;p&gt;Windows builds of RPCS3 are back in business – Due to a compiler issue, RPCS3's latest builds haven't been available on Windows since back in June, but they're back and working again now. Meanwhile, contributor Whatcookie has created a surprisingly detailed breakdown of how hard it is to do nothing, efficiently.&lt;/p&gt;
    &lt;p&gt;Eden is off the Play Store, for now – Well, so much for that. After launching on Android a few weeks ago, the Switch emulator has been taken down, though you can still find builds, including for Android, on the Github. Aren't DMCA takedowns lovely?&lt;/p&gt;
    &lt;p&gt;Speedrunning-focused emulator BizHawk gets hexed – But in a good way! The source port DSDA-Doom has been integrated into BizHawk, supporting Doom, Heretic and Hexen. It also now has an integrated DOSBox-X core, as well as Opera, for the 3DO.&lt;/p&gt;
    &lt;p&gt;ShadPS4 gets more Unreal – The latest build of ShadPS4 marks a significant milestone: some Unreal Engine games for the console are now playable, and even more are bootable. Look at all these games that work!&lt;/p&gt;
    &lt;head rend="h2"&gt;Translation Station&lt;/head&gt;
    &lt;p&gt;Tis the season for brains... Dead of the Brain (2) – It's spooky season, which means the crew behind the translation of PC-98 adventure game Dead of the Brain is back with the sequel two years after the first! "Like the original game, this is also a point-and-click adventure involving zombies, but this time the gameplay is much simpler, but there's still a degree of brute force required," translation crew WINE says. Playing this one might be a bit tedious, but the art is :chefskiss:&lt;/p&gt;
    &lt;p&gt;Virtual-On, on PS3 – The PS3 re-release of this mecha game had English dialogue etc., but its UI was in Japanese. This translation patch changes that.&lt;/p&gt;
    &lt;p&gt;Wizardy VI, on Saturn – There are at least nine platforms you can play Wizardry: Bane of the Cosmic Forge on, from the 1990 DOS original to the Amiga and FM Towns and modern ports, but the Japanese-only Saturn port is unique, incorporating features from Wizardry 7, and now playable with the original English script. This version has "more spells, more traps, and more skills (though most of the extra skills do nothing in 6, unfortunately), and the art style too is very reminiscent of 7 ... it’s also got a much easier early game, which a lot of new players have notoriously struggled with when playing the other versions," hacker and fan Remisse told Sega Saturn Shiro.&lt;/p&gt;
    &lt;p&gt;Undercover Cops play board games on the GB – Prolific translation group Stardust Crusaders is back with a Game Boy board/card game based on the arcade game. I'm not gonna say it's one of Irem's all-timers (find me playing Ninja Baseball Bat Man instead), but it's cute!&lt;/p&gt;
    &lt;head rend="h2"&gt;Good pixels&lt;/head&gt;
    &lt;p&gt;It's early October which means it's basically Halloween, right? Here's a load of screenshots from the first couple hours of Dead of the Brain 2. 👻&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.readonlymemo.com/mame-hyper-neo-geo-support-sound-emulation/"/><published>2025-10-08T15:01:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517134</id><title>The RSS feed reader landscape</title><updated>2025-10-08T22:09:13.493519+00:00</updated><content>&lt;doc fingerprint="be149c54c0323cec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A deep dive into the rss feed reader landscape&lt;/head&gt;
    &lt;p&gt;RSS feeds and, in one form or another, feed readers, have existed for more than 20 years. Their main purpose is enabling their users to consume content from various sources in one place. And especially in recent years, also helping users deal with content overload.&lt;/p&gt;
    &lt;p&gt;Back then there were only a handful of relevant products. Today it's different, there are products for many different situations and use-cases. When first getting into RSS and feed readers, it can be difficult to find out which of this wide range of products are the right ones to use.&lt;/p&gt;
    &lt;p&gt;This article describes the landscape so you can find out which product fits best for your use-case.&lt;/p&gt;
    &lt;p&gt;Side-note: I'm using RSS as a synonym for all web feed standards (Atom, JSON Feed)&lt;/p&gt;
    &lt;head rend="h2"&gt;Classification&lt;/head&gt;
    &lt;p&gt;I attempted a classification of feed readers based on 2 axes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deployment model: local (phone or PC), browser extension, self-hosted, hosted&lt;/item&gt;
      &lt;item&gt;Business model: free, one-time payment, SAAS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The deployment model is based on where data is stored and feed fetching happens. Some products have a web app and mobile apps, but feed fetching happens on the server. In this case it's classified as &lt;code&gt;hosted&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The business model categorization is based on the cheapest option that gives access to the full feature set of the product. A self-hostable product with a hosted option is categorized into &lt;code&gt;free&lt;/code&gt;. A freemium SAAS product is categorized as &lt;code&gt;paid (SAAS)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And here the image in table format, for easily clickable links:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Pricing&lt;/cell&gt;
        &lt;cell role="head"&gt;On-device (phone or PC)&lt;/cell&gt;
        &lt;cell role="head"&gt;Browser extension&lt;/cell&gt;
        &lt;cell role="head"&gt;Self-hosted&lt;/cell&gt;
        &lt;cell role="head"&gt;Hosted&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Free&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Paid (one-time)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hosting models&lt;/head&gt;
    &lt;head rend="h3"&gt;Browser extension&lt;/head&gt;
    &lt;p&gt;Feed readers deployed as browser extensions can be installed through the respective stores of the browsers, usually either the Chrome Web Store or the Firefox Add-ons.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup typically only requires installing the extension, not even an account is needed. There is no maintenance required beyond the occasional update, which usually happens automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally, with browser storage functionality (local storage or IndexedDB). How much data can be stored depends on the storage of the device. Browser extensions can only store as much data as the browser allows itself to use. But for most users this is easily enough.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device itself. Because the extension only runs if the browser runs, feeds are only fetched if the browser is open. This can lead to missed posts, depending on the publishing frequency of the feed and how often the browser is active.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Since all data is stored on the device, by default it's available only on the device where the extension is installed. If users enable it, the extension supports it, and the user is signed in, browsers can sync data to other devices that have the extension. Storing all data on the device also means that it is accessible offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Extensions can integrate deeply with the browser, and offer features like automatic feed finding of visited websites. Extensions can also provide a comprehensive feature set. Their only limitations are more compute-intensive features (e.g. requiring machine learning), or features that require special infrastructure to run (e.g. emails).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products (free)&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In this category I only found one product. Smart-RSS was another one, but was discontinued in February.&lt;/p&gt;
    &lt;head rend="h3"&gt;On-device&lt;/head&gt;
    &lt;p&gt;On-device products are separate applications and installed on the device you want to use them. Either on your iOS or Android phone or tablet, or on your Windows, Mac, or Linux computer. They fetch feeds and store data on that device.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: In general setup is done by installing the application. Some products may require an account, but that is not the norm. Maintenance is similar to browser extensions, the occasional updates. Some applications require manual update installations, others do that automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally on the device, which gives total control over the data. The maximum amount of feeds and articles stored only depend on the available storage of the device.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device. For that to happen the application must be running. Some products may implement a background fetching service, in that case only the device must be turned on. Similar to browser extensions, this limitation may lead to missed posts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Typically the data of on-device feed readers are only available on the device where it's installed. Data sync would need to be done manually or via operating system specific mechanisms (e.g. iCloud), which not all products support. Since data is stored on the device, it's also available offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On-device products can use the full computing power of the device. Combined with the comparatively small storage requirements of one user, it means that some features can be significantly faster than other categories. The exact features depend on the application, and mobile apps are typically less powerful than desktop apps. Limitations are only features that require multiple users (e.g. recommendations) or specific infrastructure (e.g. newsletter subscriptions).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Self-hosted&lt;/head&gt;
    &lt;p&gt;Self-hosted products all fall into the open-source and free category. They are designed to be installed on a server to run continuously, though it is possible to install them on a PC as well. They fetch feeds and store data on the server, and make it available through a web interface.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup requires a server, installing the application, and depending on how it should be accessible, possibly also domain and reverse proxy setup. This needs significantly more technical knowledge than the other options, but with ChatGPT (or others) it should be possible also for fairly non-technical people. This setup is generally more complex with more failure points than the other options, but with a correct setup failures happen rarely, if at all.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: The application stores data on the server it runs on. Since users control their server, they also have total control over the data stored on it. Applications typically use well-established databases, which allows users to inspect and change data with common tools. The amount of data that can be stored is only limited by the available storage on the server. Most servers start at 20 GB, which is enough for most feed reading use-cases. Often, storage can be dynamically extended if more space is needed.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the server. Since it runs continuously, there is no break in feed fetching, and even high frequency feeds are no problem.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: The application and all its data is accessible from any device with a web browser by navigating to the server's URL. Data is stored on the server, therefore automatically synced between all devices that use it, but also require internet access.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On average self-hosted products have a wider feature set than browser extension or on-device feed readers. There is no theoretical limit on the feature set, but typically they keep the infrastructure as simple as possible, to keep setup and maintenance straightforward. This makes them slightly less powerful than hosted alternatives.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;p&gt;Self-hosted products are all open-source and free. The only costs are for the server, and the cheapest VPS plans start at ~2$/month.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hosted&lt;/head&gt;
    &lt;p&gt;Hosted feed readers are managed services. It's required to create an account to get access to them. All of them are paid SAAS products, and most offer a free plan.&lt;/p&gt;
    &lt;p&gt;On average they have the most polished user experience and most comprehensive feature sets, since they're backed by companies that invest in continuous development.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Beyond creating an account, no setup is required. The same for maintenance. Service providers make sure the products work as intended, and deal with everything required to keep the service running, including infrastructure setup, monitoring, backups, etc.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Since data is stored on the servers and databases of the company running the product, users don't have direct control. But through laws like GDPR users have the right to export all their data, or request deletion. Storage is essentially unlimited, though most products have limits to avoid abuse. These limits are mentioned on their pricing page.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Similar to self-hosted products, feeds are fetched on the server, which runs continuously and ensures that even high-frequency feeds don't pose a problem. The fetching interval is usually dynamic, based on the popularity of a feed and the publishing frequency.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Hosted products are primarily available as web application, and some offer native apps as well. Since data is stored on the server, it's natively synced between devices. Some hosted feed readers also offer offline support.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Hosted feed readers serve many customers at the same time, which makes it necessary to have more complex infrastructure setups. This also enables features that other types of products cannot do, like email receiving, recommendations, or historic feed contents. Consequently hosted options are generally more powerful than other categories, though the specific feature set depends on the product.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All hosted products are SAAS products and charge monthly. &lt;code&gt;Folo&lt;/code&gt; is an outlier, they currently don't have any paid features, but the terms of service indicate that this will come in the future. At that point it will join the others in the &lt;code&gt;Paid (SAAS)&lt;/code&gt; category.&lt;/p&gt;
    &lt;head rend="h2"&gt;App support and offline access for products that don't offer it natively&lt;/head&gt;
    &lt;p&gt;Many of the self-hosted or hosted products don't provide apps or offline access by themselves. However, with the right setup, it's still possible to access the articles offline.&lt;/p&gt;
    &lt;p&gt;Most of these products provide APIs. This can be a proprietary API, or an API based on the old Google Reader API.&lt;/p&gt;
    &lt;p&gt;Mobile apps, for example ReadKit or Fiery Feeds, can not only subscribe to feeds, but also connect to other products through their APIs. They download contents, store them locally, and sync changes back to the connected products.&lt;/p&gt;
    &lt;p&gt;These apps make it possible to use a native mobile app for products that don't provide an app themselves, and get offline access at the same time.&lt;/p&gt;
    &lt;p&gt;FreshRSS, for example, has a list of native apps that support it.&lt;/p&gt;
    &lt;head rend="h2"&gt;A note on newsletters&lt;/head&gt;
    &lt;p&gt;Newsletters are a growing mechanism for delivering (blog) content. Some, but not all, hosted feed readers support newsletters out of the box. But on-device products can't do that at all because of their infrastructure limitations.&lt;/p&gt;
    &lt;p&gt;Even if a feed reader doesn't support newsletters by itself, it's still possible to get newsletters into the feed reader, through services that convert newsletters into RSS feeds.&lt;/p&gt;
    &lt;p&gt;These services generate an email address and give you a corresponding feed URL. Emails to the generated address are added to the feed as new entry. So after signing up to the newsletter and adding the feed URL, the newsletter is added to the feed reader even without native email support.&lt;/p&gt;
    &lt;p&gt;Services that do this are Kill the Newsletter and the Lighthouse Newsletter to RSS tool. Both are free.&lt;/p&gt;
    &lt;head rend="h2"&gt;Products&lt;/head&gt;
    &lt;p&gt;The descriptions highlight the defining and unique aspects of the products, for the full feature list please go to their respective websites. Where available I used the screenshots for their websites, to represent the products as best as possible (test account screenshots wouldn't be as good).&lt;/p&gt;
    &lt;head rend="h3"&gt;NetNewsWire (on-device, free)&lt;/head&gt;
    &lt;p&gt;NetNewsWire is a free, on-device feed reader for Mac and iOS. By default it stores data on the device itself, but can sync via iCloud and using other products as storage. And it provides a Safari extension for easy feed-adding. Notably, it supports AppleScript, which makes it possible to automate certain workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fiery Feeds (on device, paid SAAS)&lt;/head&gt;
    &lt;p&gt;Fiery feeds is a Mac and iOS app. The download is free, and to get the premium features it costs ~15$/year (varies by region). By default it stores data on the device itself, but can sync via iCloud and using the API of other products (e.g. FreshRSS). The main distinguishing features are the customization options of the app, like custom themes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reeder (on-device, SAAS)&lt;/head&gt;
    &lt;p&gt;The current version of Reeder is a Mac and iOS app. The download is free, and to get the premium features it costs ~10$/year. The previous version of Reeder, now called Reeder Classic, is still available as one-time purchase. It also stores data on-device, and can sync via iCloud.&lt;/p&gt;
    &lt;p&gt;The main distinguishing feature is the unified timeline, which includes RSS, podcasts, social media, and more.&lt;/p&gt;
    &lt;head rend="h3"&gt;FreshRSS (self-hosted, free)&lt;/head&gt;
    &lt;p&gt;FreshRSS is a self-hosted feed reader and once set up, it's available as a web app. It is quite powerful, and in addition to normal feed subscriptions offers WebSub as well. It's possible to customize it with themes and extensions, and it's translated into more than 15 languages.&lt;/p&gt;
    &lt;p&gt;Together with Miniflux they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Miniflux&lt;/head&gt;
    &lt;p&gt;Miniflux is a self-hosted feed reader as well, and available as web app after setup. It's focus is on staying simple and fast instead of adding fancy features. It also offers a hosted version, which is 15$/year and has a 15 day trial period.&lt;/p&gt;
    &lt;p&gt;Together with FreshRSS they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Folo (hosted, free)&lt;/head&gt;
    &lt;p&gt;Folo is a relatively new product developed by the creators of RSS Hub. It's a free hosted feed reader, with apps available for every major platform. Their terms of service suggest that at some point they will charge a monthly fee for some premium features, but at the time of writing there were no paid features.&lt;/p&gt;
    &lt;p&gt;Folo is also open-source and therefore theoretically self-hostable, but I haven't found documentation for it.&lt;/p&gt;
    &lt;p&gt;It has a huge feature set, including newsletter support, transforming websites into feeds, AI summaries, and much more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feedly (hosted, SAAS)&lt;/head&gt;
    &lt;p&gt;Feedly is the most widely-known product and has the most users of all feed readers. It has a comprehensive features set, and offers a free plan as well. For the past couple of years, it seems that Feedly has focused more on AI features and enterprise customers, but their core product remains solid.&lt;/p&gt;
    &lt;head rend="h3"&gt;Inoreader&lt;/head&gt;
    &lt;p&gt;Inoreader is the second most widely-known product, after Feedly. It too offers a free plan. Their feature list is impressive, with social media support for subscriptions, automation and AI features, public API and integrations. And of course much more.&lt;/p&gt;
    &lt;p&gt;What stands out on Reddit are complaints about price hikes. Though Inoreader probably has tens or hundreds of thousands of users who don't have issues and think the product is great.&lt;/p&gt;
    &lt;head rend="h3"&gt;Readwise Reader&lt;/head&gt;
    &lt;p&gt;Readwise Reader is a relatively new product, from the creators of the original Readwise. It's a great feed reader, though were it really shines is the reading experience. They also have reading views for PDFs, eBooks, and more.&lt;/p&gt;
    &lt;p&gt;The website mentions that it's in beta, but it has been in beta for years now and at this point is a stable product, and has been for awhile.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tiny Tiny RSS&lt;/head&gt;
    &lt;p&gt;Tiny Tiny RSS deserves an honorable mention in this list. It was, and still is, used by many, and has been for a long time, and was often recommended on the RSS subreddit.&lt;/p&gt;
    &lt;p&gt;On October 3rd the maintainer announced that he's going to stop working on it, and will remove all infrastructure on November 1st. Forks of the project with other maintainers may pop up, but at the moment it's too soon to tell what the future of Tiny Tiny RSS will be.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lighthouse&lt;/head&gt;
    &lt;p&gt;Lighthouse is also a relatively new product. It's in beta, which refers to the fact that it doesn't yet have all features necessary to fulfill its vision, which goes beyond simple feed reading.&lt;/p&gt;
    &lt;p&gt;The main differentiator is that it focuses on articles over feeds, and has a separate view for curating articles (the inbox). It's focused on finding high-value content.&lt;/p&gt;
    &lt;head rend="h2"&gt;Similar product categories&lt;/head&gt;
    &lt;p&gt;Feed readers are powerful products, which require manual setup to make them work well. Subscribing to feeds is mandatory, adding tags, filtered views, and rules can make them work even better. But for some use-cases, other product categories are simpler and might work better.&lt;/p&gt;
    &lt;head rend="h3"&gt;News aggregators&lt;/head&gt;
    &lt;p&gt;News aggregators automatically collect and curate news from a large variety of sources. They usually provide some customization options, but focus on news and don't allow arbitrary feed subscriptions like feed readers do.&lt;/p&gt;
    &lt;p&gt;They focus on providing an overview of the most relevant news stories.&lt;/p&gt;
    &lt;p&gt;Examples are Kagi News, Ground News, and SmartNews.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reading lists&lt;/head&gt;
    &lt;p&gt;Reading lists, also called read-it-later apps, are for saving and organizing links you found somewhere on the web. Many feed readers can do the same, but reading lists are optimized for that purpose.&lt;/p&gt;
    &lt;p&gt;Examples are Instapaper and Matter. Karakeep is a self-hosted option.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to choose&lt;/head&gt;
    &lt;p&gt;For most people, going with one of the hosted products is the best option. They're generally the most polished and most powerful products, owing to the fact that they have companies behind them with full-time engineers. They generally also offer a free plan, so if you stay within the limits of those, they will even be free to use.&lt;/p&gt;
    &lt;p&gt;For more specific requirements, products of the other categories can work better. They have different characteristics, and can work better in some situations. For example, if you want total control over your data, self-hosted options are the way to go.&lt;/p&gt;
    &lt;p&gt;It's probably easiest to first decide on the category, and then check out multiple products, or maybe even try them out. Virtually all products support OPML import and export, so moving feed subscriptions from one product to the next is almost zero effort.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lighthouseapp.io/blog/feed-reader-deep-dive"/><published>2025-10-08T15:17:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517674</id><title>Ortega hypothesis</title><updated>2025-10-08T22:09:13.176917+00:00</updated><content>&lt;doc fingerprint="efd8585d1ac4d390"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Ortega hypothesis&lt;/head&gt;&lt;p&gt;The Ortega hypothesis holds that average or mediocre scientists contribute substantially to the advancement of science.[1] According to this hypothesis, scientific progress occurs mainly by the accumulation of a mass of modest, narrowly specialized intellectual contributions. On this view, major breakthroughs draw heavily upon a large body of minor and little-known work, without which the major advances could not happen.[2]&lt;/p&gt;&lt;head rend="h2"&gt;Citation research&lt;/head&gt;[edit]&lt;p&gt;The Ortega hypothesis is widely held,[2] but a number of systematic studies of scientific citations have favored the opposing "Newton hypothesis", which says that scientific progress is mostly the work of a relatively small number of great scientists (after Isaac Newton's statement that he "stood on the shoulders of giants").[1] The most important papers mostly cite other important papers by a small number of outstanding scientists, suggesting that the breakthroughs do not actually draw heavily on a large body of minor work.[2] Rather, the pattern of citations suggests that most minor work draws heavily on a small number of outstanding papers and outstanding scientists. Even minor papers by the most eminent scientists are cited much more than papers by relatively unknown scientists; and these elite scientists are clustered mostly in a small group of elite departments and universities.[2] The same pattern of disproportionate citation of a small number of scholars appears in fields as diverse as physics and criminology.[3]&lt;/p&gt;&lt;p&gt;The matter is not settled. No research has established that citation counts reflect the real influence or worth of scientific work. So, the apparent disproof of the Ortega hypothesis may be an artifact of inappropriately chosen data.[4] Stratification within the social networks of scientists may skew the citation statistics.[5] Many authors cite research papers without actually reading them or being influenced by them.[6] Experimental results in physics make heavy use of techniques and devices that have been honed by many previous inventors and researchers, but these are seldom cited in reports on those results.[7][8] Theoretical papers have the broadest relevance to future research, while reports of experimental results have a narrower relevance but form the basis of the theories. This suggests that citation counts merely favor theoretical results.[7]&lt;/p&gt;&lt;head rend="h2"&gt;The name&lt;/head&gt;[edit]&lt;p&gt;The name of the hypothesis refers to José Ortega y Gasset, who wrote in The Revolt of the Masses that "astoundingly mediocre" men of narrow specialties do most of the work of experimental science.[9] Ortega most likely would have disagreed with the hypothesis that has been named after him, as he held not that scientific progress is driven mainly by the accumulation of small works by mediocrities, but that scientific geniuses create a framework within which intellectually commonplace people can work successfully. For example, Ortega thought that Albert Einstein drew upon the ideas of Immanuel Kant and Ernst Mach to form his own synthesis, and that Einstein did not draw upon masses of tiny results produced systematically by mediocrities. According to Ortega, science is mostly the work of geniuses, and geniuses mostly build on each other's work, but in some fields there is a real need for systematic laboratory work that could be done by almost anyone.[10]&lt;/p&gt;&lt;p&gt;The "Ortega hypothesis" derives only from this last element of Ortega's theory, not the main thrust of it. Ortega characterized this type of research as "mechanical work of the mind" that does not require special talent or even much understanding of the results, performed by people who specialize in one narrow corner of one science and hold no curiosity beyond it.[10]&lt;/p&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;[edit]&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ a b David J. Hess. Science Studies: An Advanced Introduction, p. 71. NYU Press, 1997.&lt;/item&gt;&lt;item&gt;^ a b c d Jonathan R. Cole and Cole, Stephen. "The Ortega hypothesis." Science, New Series, Vol. 178, No. 4059 (Oct. 27, 1972), pp. 368-375.&lt;/item&gt;&lt;item&gt;^ M. Oromaner. "The Ortega hypothesis and influential articles in American sociology." Scientometrics, Vol. 7, No. 1 (Jan. 26, 1985), pp. 3–10. doi:10.1007/BF02020136&lt;/item&gt;&lt;item&gt;^ M.H. MacRoberts and Barbara R. MacRoberts. "Testing the Ortega Hypothesis: Facts and Artifacts." Scientometrics, Vol. 12, Nos. 5–6 (1987) pp. 293–295.&lt;/item&gt;&lt;item&gt;^ Hildrun Kretschmer. "Measurement of social stratification. A contribution to the dispute on the ORTEGA hypothesis." Scientometrics, Vol. 26 No. 1 (1993), pp. 97–113. doi:10.1007/BF02016795&lt;/item&gt;&lt;item&gt;^ Heidi Lee Hoerman and Nowicke, Carole Elizabeth. "Secondary and Tertiary Citing: A Study of Referencing Behavior in the Literature of Citation Analysis Deriving from the Ortega Hypothesis of Cole and Cole." The Library Quarterly, Vol. 65, No. 4 (Oct., 1995), pp. 415-434.&lt;/item&gt;&lt;item&gt;^ a b S. A. Goudsmit, John D. McGervey, Robert J. Yaes, Jonathan R. Cole and Stephen Cole "Citation Analysis." Science, New Series, Vol. 183, No. 4120 (Jan. 11, 1974), pp. 28+30-33.&lt;/item&gt;&lt;item&gt;^ Endre Száva-Kováts. "Non-indexed eponymal citedness (NIEC): first fact-finding examination of a phenomenon of scientific literature." Journal of Information Science, 1994 20:55 doi:10.1177/016555159402000107&lt;/item&gt;&lt;item&gt;^ José Ortega y Gasset. The Revolt of the Masses, pp. 110-111. Norton, 1932.&lt;/item&gt;&lt;item&gt;^ a b Endre Száva-Kováts. "The false 'Ortega Hypothesis': a literature science case study." Journal of Information Science 2004 30: 496. doi:10.1177/0165551504047823&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://en.wikipedia.org/wiki/Ortega_hypothesis"/><published>2025-10-08T16:06:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518127</id><title>Show HN: I built a local-first podcast app</title><updated>2025-10-08T22:09:12.021893+00:00</updated><link href="https://wherever.audio"/><published>2025-10-08T16:46:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518813</id><title>WinBoat: Windows apps on Linux with seamless integration</title><updated>2025-10-08T22:09:11.806276+00:00</updated><content>&lt;doc fingerprint="b48fe95fd1b73cdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt; Run Windows apps on 🐧 Linux&lt;lb/&gt;with ✨ seamless integration &lt;/head&gt;
    &lt;head rend="h2"&gt;FFFFF/Features/sssss&lt;/head&gt;
    &lt;head rend="h2"&gt;Elegant Interface&lt;/head&gt;
    &lt;p&gt;WinBoat provides a sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automated Installs&lt;/head&gt;
    &lt;p&gt;Installing Windows via WinBoat is a delightfully simple process all done through our interface. Pick your preferences &amp;amp; specs and let us handle the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run Any App&lt;/head&gt;
    &lt;p&gt;If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications, from productivity tools to entertainment, all within your Linux environment as native OS-level windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filesystem Integration&lt;/head&gt;
    &lt;p&gt;Accessing your Linux filesystem from Windows is a breeze. Your home directory is mounted in Windows, allowing you to easily share files between the two systems without any hassle.&lt;/p&gt;
    &lt;head rend="h2"&gt;And many more...&lt;/head&gt;
    &lt;p&gt;There's tons more you can do with WinBoat, for example smartcard passthrough and resource monitoring. We're always looking to add more features, so stay tuned for updates!&lt;/p&gt;
    &lt;p&gt;Scroll for more!&lt;/p&gt;
    &lt;head rend="h2"&gt;Elegant Interface&lt;/head&gt;
    &lt;p&gt;WinBoat provides a sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automated Installs&lt;/head&gt;
    &lt;p&gt;Installing Windows via WinBoat is a delightfully simple process all done through our interface. Pick your preferences &amp;amp; specs and let us handle the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run Any App&lt;/head&gt;
    &lt;p&gt;If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications, from productivity tools to entertainment, all within your Linux environment as native OS-level windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filesystem Integration&lt;/head&gt;
    &lt;p&gt;Accessing your Linux filesystem from Windows is a breeze. Your home directory is mounted in Windows, allowing you to easily share files between the two systems without any hassle.&lt;/p&gt;
    &lt;head rend="h2"&gt;And many more...&lt;/head&gt;
    &lt;p&gt;There's tons more you can do with WinBoat, for example smartcard passthrough and resource monitoring. We're always looking to add more features, so stay tuned for updates!&lt;/p&gt;
    &lt;head rend="h2"&gt;DDDD/Download/ddddd&lt;/head&gt;
    &lt;p&gt;We're excited to have you onboard! Pick your platform below to get started with WinBoat within minutes, not hours.&lt;/p&gt;
    &lt;head rend="h2"&gt;CCCC/Contribute/eeeee&lt;/head&gt;
    &lt;p&gt;WinBoat is an open-source project licensed under MIT, and we welcome contributions from the community. Whether you're a developer, designer, or just someone who loves WinBoat, there are many ways you can help us improve and grow.&lt;/p&gt;
    &lt;head rend="h2"&gt;CCCC/Community/yyyyy&lt;/head&gt;
    &lt;p&gt;We usually hang out on Discord, come join and chat with us!&lt;/p&gt;
    &lt;head rend="h2"&gt;FFFFF/Frequently Asked Questions/sssss&lt;/head&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;How does it compare to WinApps?&lt;/head&gt;
    &lt;p&gt;With WinApps you do the bulk of the setup manually, and there's no cohesive interface to bring it all together. There's a basic TUI, a taskbar widget, and some CLI commands for you to play with.&lt;lb/&gt; WinBoat does all the setup once you have the pre-requisites installed, displays everything worth seeing in a neat interface for you, and acts like a complete experience. No need to mess with configuration files, no need to memorize a dozen CLI commands, it just works.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;What are the advantages of using this over CrossOver or WINE?&lt;/head&gt;
    &lt;p&gt;You can run stuff that doesn't play well with CrossOver or WINE, and have a full Windows desktop at the same time.&lt;lb/&gt; We've had numerous apps that weren't working nicely (or at all) in Wine, this is one of the reasons we've created WinBoat. Some examples would be Affinity Photo, Paint Tool Sai v1.0, the entire Adobe suite, AeroChat, Acrobat, and of course Office.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Will I be able to configure my peripherals / hardware using WinBoat?&lt;/head&gt;
    &lt;p&gt;If your peripheral / hardware uses USB to connect to your device. then yes! Starting from WinBoat 0.8.0 we support USB passthrough as an experimental feature and you can use any Windows software needed for configuration, it should work out of the box.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Is there USB passthrough?&lt;/head&gt;
    &lt;p&gt; Yes! Starting from WinBoat 0.8.0 we support USB passthrough as an experimental feature. Please give it a try and let us know what you think! 😄&lt;lb/&gt; If for whatever reason you're stuck with an older version of WinBoat, you can modify the docker-compose.yml file in ~/.winboat once you finished setting up WinBoat. You can add the appropriate USB devices like this, followed by executing docker-compose down and docker-compose up -d in the same folder. Please make sure to remove these changes before you upgrade to &amp;gt;=0.8.0 though, as they are incompatible with our implementation.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Is there GPU passthrough?&lt;/head&gt;
    &lt;p&gt;Not at the moment, but we plan on eventually implementing GPU acceleration through paravirtualized drivers.&lt;lb/&gt; We have looked at MVisor Win VGPU Driver for OpenGL, which seems promising from our tests, but it's for a different hypervisor (not compatible with QEMU). Some other folks are also working on DirectX drivers but nothing that we can try out yet.&lt;lb/&gt; We have also looked into Looking Glass extensively, specifically their Indirect Display Driver which does not need a second GPU, because it'd be absolutely amazing to have it. We got the driver to compile and start via some hacks, but couldn't get much more than a black screen. The developer says it is not ready for general use yet at all, however we plan to integrate it once it is ready.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Does it run games with anti-cheat that don't run on Linux?&lt;/head&gt;
    &lt;p&gt;Unfortunately running games with kernel anti-cheat is not possible, as they block virtualization.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Any possibility of adding Podman support as a Docker alternative?&lt;/head&gt;
    &lt;p&gt;Podman support is planned. We tried working on it, some contributors also tried working on it, but there's some issues with networking (specifically the guest server being unreachable) that prevent it from being functional for now.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Will you make it into a Flatpak?&lt;/head&gt;
    &lt;p&gt;This is on our to-do list, but it'll take some effort because Flatpak is pretty isolated from the rest of the system and apps, so we'd have to find a way to expose installed apps, the Docker binary, and the Docker socket, and many other utilities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.winboat.app/"/><published>2025-10-08T17:56:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518861</id><title>Show HN: FleetCode – Open-source UI for running multiple coding agents</title><updated>2025-10-08T22:09:11.362566+00:00</updated><content>&lt;doc fingerprint="57844e5f478d9a2f"&gt;
  &lt;main&gt;
    &lt;p&gt;A desktop terminal application for running multiple CLI coding agents simultaneously, each in isolated git worktrees.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multiple Sessions: Run multiple coding agent sessions (Claude, Codex) in parallel&lt;/item&gt;
      &lt;item&gt;Git Worktree Isolation: Each session runs in its own git worktree, keeping work isolated&lt;/item&gt;
      &lt;item&gt;Persistent Sessions: Sessions persist across app restarts with automatic resumption&lt;/item&gt;
      &lt;item&gt;Terminal Theming: Choose from preset themes (macOS Light/Dark, Solarized Dark, Dracula, One Dark, GitHub Dark)&lt;/item&gt;
      &lt;item&gt;Setup Commands: Configure shell commands to run before the coding agent starts&lt;/item&gt;
      &lt;item&gt;MCP Server Management: Add and configure Model Context Protocol (MCP) servers&lt;/item&gt;
      &lt;item&gt;Session Management: Rename, close, and delete sessions with automatic worktree cleanup&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js 16+&lt;/item&gt;
      &lt;item&gt;Git&lt;/item&gt;
      &lt;item&gt;Claude CLI (&lt;code&gt;npm install -g @anthropic-ai/claude-cli&lt;/code&gt;) or Codex&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;npm install&lt;/code&gt;
    &lt;code&gt;npm run dev&lt;/code&gt;
    &lt;code&gt;npm run build
npm start&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Select a project directory (must be a git repository)&lt;/item&gt;
      &lt;item&gt;Choose a parent branch for the worktree&lt;/item&gt;
      &lt;item&gt;Select your coding agent (Claude or Codex)&lt;/item&gt;
      &lt;item&gt;Optionally add setup commands (e.g., environment variables, source files)&lt;/item&gt;
      &lt;item&gt;FleetCode creates a new git worktree and spawns a terminal session&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New Sessions: Use &lt;code&gt;--session-id &amp;lt;uuid&amp;gt;&lt;/code&gt;for first-time Claude sessions&lt;/item&gt;
      &lt;item&gt;Reopened Sessions: Automatically resume with &lt;code&gt;--resume &amp;lt;uuid&amp;gt;&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Worktrees: Each session gets its own isolated git worktree&lt;/item&gt;
      &lt;item&gt;Persistence: Sessions are saved and can be reopened after closing the app&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Access settings via the gear icon (⚙️) in the sidebar:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Font Family: Choose from common monospace fonts&lt;/item&gt;
      &lt;item&gt;Font Size: Adjust terminal text size&lt;/item&gt;
      &lt;item&gt;Theme: Select from preset color themes&lt;/item&gt;
      &lt;item&gt;Cursor Blink: Toggle cursor blinking&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Configure Model Context Protocol servers for enhanced agent capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;stdio: Direct process communication&lt;/item&gt;
      &lt;item&gt;SSE: Server-sent events via HTTP&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you encounter a quarantine warning when trying to open the app on macOS, run:&lt;/p&gt;
    &lt;code&gt;xattr -cr /path/to/FleetCode.app&lt;/code&gt;
    &lt;p&gt;This removes the quarantine attribute that prevents the app from opening.&lt;/p&gt;
    &lt;p&gt;If you're using Claude Code and it's reading/writing files from the wrong directory instead of the worktree, disable "Auto connect to IDE" in your Claude Code settings:&lt;/p&gt;
    &lt;code&gt;claude config&lt;/code&gt;
    &lt;p&gt;Set &lt;code&gt;autoConnectToIde&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;. This ensures Claude Code operates within the correct worktree directory.&lt;/p&gt;
    &lt;p&gt;ISC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/built-by-as/FleetCode"/><published>2025-10-08T18:00:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519263</id><title>Julia 1.12 highlights</title><updated>2025-10-08T22:09:11.232668+00:00</updated><content>&lt;doc fingerprint="3cdcaa530be1dbe8"&gt;
  &lt;main&gt;&lt;p&gt;Julia version 1.12 has finally been released. We want to thank all the contributors to this release and all the testers who helped find regressions and issues in the pre-releases. Without you, this release would not have been possible.&lt;/p&gt;&lt;p&gt;The full list of changes can be found in the NEWS file, but here we'll give a more in-depth overview of some of the release highlights.&lt;/p&gt;&lt;code&gt;--trim&lt;/code&gt; feature&lt;code&gt;@atomic&lt;/code&gt; macro family now supports reference assignment syntax&lt;code&gt;--trim&lt;/code&gt; feature&lt;p&gt;Jeff Bezanson, Cody Tapscott, Gabriel Baraldi&lt;/p&gt;&lt;p&gt;&lt;code&gt;julia&lt;/code&gt; now has a new experimental&lt;code&gt;--trim&lt;/code&gt; feature, when compiling a system image with this mode julia will trim statically unreachable code leading to significantly better compile times and binary sizes. To use it you also need to pass the &lt;code&gt;--experimental&lt;/code&gt; flag when building the system image. &lt;/p&gt;&lt;p&gt;In order to use it, any code that is reachable from the entrypoints must not have any dynamic dispatches otherwise the trimming will be unsafe and it will error during compilation.&lt;/p&gt;&lt;p&gt;The expected way of using it is via the &lt;code&gt;JuliaC.jl&lt;/code&gt; package, which provides a CLI and a programmatic API. &lt;/p&gt;&lt;p&gt;For example a simple package with an &lt;code&gt;@main&lt;/code&gt; function:&lt;/p&gt;&lt;code&gt;module AppProject

function @main(ARGS)
    println(Core.stdout, "Hello World!")
    return 0
end

end&lt;/code&gt;
&lt;code&gt;juliac --output-exe app_test_exe --bundle build --trim=safe --experimental ./AppProject&lt;/code&gt;
&lt;code&gt;./build/bin/app_test_exe
Hello World!

ls -lh build/bin/app_test_exe
-rwxr-xr-x@ 1 gabrielbaraldi  staff   1.1M Oct  6 17:22 ./build/bin/app_test_exe*&lt;/code&gt;
&lt;p&gt;Keno Fischer, Tim Holy&lt;/p&gt;&lt;p&gt;Bindings now participate in the "world age" mechanism previously used for methods. This has the effect that constants and structs can be properly redefined. As an example:&lt;/p&gt;&lt;code&gt;# Define a struct and a method on that struct:
julia&amp;gt; struct Foo
          a::Int
       end

julia&amp;gt; g(f::Foo) = f.a^2
g (generic function with 1 method)

julia&amp;gt; g(Foo(2))
4

# Redefine the struct (julia pre-1.12 would error here)
julia&amp;gt; struct Foo
          a::Int
          b::Int
       end

# Note that functions need to be redefined to work on the new `Foo`
julia&amp;gt; g(Foo(1,2))
ERROR: MethodError: no method matching g(::Foo)
The function `g` exists, but no method is defined for this combination of argument types.

Closest candidates are:
  g(::@world(Foo, 39296:39300)) # &amp;lt;- This is syntax for accessing the binding in an older "world"
   @ Main REPL[2]:1

julia&amp;gt; g(f::Foo) = f.a^2 + f.b^2
g (generic function with 2 methods)

julia&amp;gt; g(Foo(2,3))
13&lt;/code&gt;
&lt;p&gt;There is also work in progress in Revise.jl to automatically redefine functions on replaced bindings. This should significantly reduce the number of times you have to restart Julia while iterating on some piece of code.&lt;/p&gt;&lt;p&gt;Ian Butterworth, Nathan Daly&lt;/p&gt;&lt;p&gt;&lt;code&gt;--trace-compile-timing&lt;/code&gt; is a new command-line flag that augments &lt;code&gt;--trace-compile&lt;/code&gt; by printing how long each compiled method took (in milliseconds) before the corresponding &lt;code&gt;precompile(...)&lt;/code&gt; line. This makes it easier to spot costly compilations.&lt;/p&gt;&lt;p&gt;In addition, two macros for ad-hoc tracing without restarting Julia have been added:&lt;/p&gt;&lt;p&gt;&lt;code&gt;@trace_compile expr&lt;/code&gt; runs &lt;code&gt;expr&lt;/code&gt; with &lt;code&gt;--trace-compile=stderr --trace-compile-timing&lt;/code&gt; enabled, emitting timed &lt;code&gt;precompile(...)&lt;/code&gt; entries only for that call.&lt;/p&gt;&lt;p&gt;&lt;code&gt;@trace_dispatch expr&lt;/code&gt; runs &lt;code&gt;expr&lt;/code&gt; with &lt;code&gt;--trace-dispatch=stderr&lt;/code&gt; enabled, reporting methods that are dynamically dispatched.&lt;/p&gt;&lt;p&gt;Examples&lt;/p&gt;&lt;code&gt;julia&amp;gt; @trace_compile @eval rand(2,2) * rand(2,2)
#=   79.9 ms =# precompile(Tuple{typeof(Base.rand), Int64, Int64})
#=    4.4 ms =# precompile(Tuple{typeof(Base.:(*)), Array{Float64, 2}, Array{Float64, 2}})
2×2 Matrix{Float64}:
 0.302276  0.14341
 0.738941  0.396414

julia&amp;gt; f(x) = x

julia&amp;gt; @trace_dispatch map(f, Any[1,2,3])
precompile(Tuple{Type{Array{Int64, 1}}, UndefInitializer, Tuple{Int64}})
precompile(Tuple{typeof(Base.collect_to_with_first!), Array{Int64, 1}, Int64, Base.Generator{Array{Any, 1}, typeof(Main.f)}, Int64})
3-element Vector{Int64}:
 1
 2
 3&lt;/code&gt;
&lt;p&gt;Gabriel Baraldi, Ian Butterworth&lt;/p&gt;&lt;p&gt;Julia now starts with one interactive thread by default (in addition to the default thread). This means that by default Julia runs with the threading configuration of 1 default thread, 1 interactive thread.&lt;/p&gt;&lt;p&gt;The interactive thread pool is where the REPL and other interactive operations run. By separating these from the default thread pool (where &lt;code&gt;@spawn&lt;/code&gt; and &lt;code&gt;@threads&lt;/code&gt; schedule work when no threadpool is specified), the REPL can perform operations like autocomplete queries in parallel with user code execution, leading to a more responsive interactive experience.&lt;/p&gt;&lt;p&gt;Key behaviors:&lt;/p&gt;&lt;p&gt;Default: Julia starts with &lt;code&gt;-t1,1&lt;/code&gt; (1 default + 1 interactive thread)&lt;/p&gt;&lt;p&gt;Explicit &lt;code&gt;-t1&lt;/code&gt;: If you explicitly request 1 thread with &lt;code&gt;-t1&lt;/code&gt;, Julia will give you exactly that—no additional interactive thread will be added (resulting in &lt;code&gt;-t1,0&lt;/code&gt;)&lt;/p&gt;&lt;p&gt;Multiple threads: &lt;code&gt;-t2&lt;/code&gt; or &lt;code&gt;-tauto&lt;/code&gt; will give you the requested default threads plus 1 interactive thread&lt;/p&gt;&lt;p&gt;Manual control: You can always specify both pools explicitly, e.g., &lt;code&gt;-t4,2&lt;/code&gt; for 4 default and 2 interactive threads&lt;/p&gt;&lt;p&gt;This change improves the out-of-the-box experience while maintaining backwards compatibility for users who explicitly request single-threaded execution.&lt;/p&gt;&lt;p&gt;Mosè Giordano&lt;/p&gt;&lt;p&gt;Julia now respects CPU affinity settings, such as those set via &lt;code&gt;cpuset&lt;/code&gt;/&lt;code&gt;taskset&lt;/code&gt;/&lt;code&gt;cgroups&lt;/code&gt;, etc. The same also applies to the default number of BLAS threads, which now follows the same logic. This can also be observed when running Julia inside Docker. Currently, you have&lt;/p&gt;&lt;code&gt;$ docker run --cpus=4 --rm -ti julia:1.11 julia --threads=auto -e '@show Threads.nthreads(); using LinearAlgebra; @show BLAS.get_num_threads()'
Threads.nthreads() = 22
BLAS.get_num_threads() = 11&lt;/code&gt;
&lt;p&gt;When starting Julia with &lt;code&gt;--threads=auto&lt;/code&gt;, &lt;code&gt;Threads.nthreads()&lt;/code&gt; is equal to the total number of CPUs on the system instead of the only 4 CPUs reserved by Docker. Likewise, the number of BLAS threads, which can be obtained with &lt;code&gt;BLAS.get_num_threads()&lt;/code&gt; and on x86-64 systems is by default half the number of available cores, is 11 instead of 2. With Julia v1.12 this is fixed, and the number of both Julia and BLAS threads will respect the number of CPUs reserved by Docker:&lt;/p&gt;&lt;code&gt;% docker run --cpus=4 --rm -ti julia:1.12 julia --threads=auto -e '@show Threads.nthreads(); using LinearAlgebra; @show BLAS.get_num_threads()'
Threads.nthreads() = 4
BLAS.get_num_threads() = 2&lt;/code&gt;
&lt;p&gt;The new behavior is also important to avoid oversubscription out-of-the-box when running Julia on HPC systems where schedulers set CPU affinity when using shared resources.&lt;/p&gt;&lt;code&gt;OncePerX&lt;/code&gt;&lt;p&gt;Jameson Nash&lt;/p&gt;&lt;p&gt;Certain initialization patterns need to run only once, depending on scope: per process, per thread, or per task. To make this easier and safer, Julia now provides three built-in types:&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerProcess{T}&lt;/code&gt;: runs an initializer exactly once per process, returning the same value for all future calls.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerThread{T}&lt;/code&gt;: runs an initializer once for each thread ID. Subsequent calls on the same thread return the same value.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerTask{T}&lt;/code&gt;: runs an initializer once per task, reusing the same value within that task.&lt;/p&gt;&lt;p&gt;These replace common hand-rolled solutions such as using &lt;code&gt;__init__&lt;/code&gt;, &lt;code&gt;nthreads()&lt;/code&gt;, or &lt;code&gt;task_local_storage()&lt;/code&gt; directly.&lt;/p&gt;&lt;p&gt;A simple example of &lt;code&gt;OncePerProcess&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;julia&amp;gt; const global_state = Base.OncePerProcess{Vector{UInt32}}() do
           println("Making lazy global value...done.")
           return [Libc.rand()]
       end;

julia&amp;gt; a = global_state();
Making lazy global value...done.

julia&amp;gt; a === global_state()
true&lt;/code&gt;
&lt;p&gt;Use cases:&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerProcess&lt;/code&gt;: caches, global constants, or initialization that should happen once per Julia process (even across precompilation).&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerThread&lt;/code&gt;: per-thread state needed for interoperability with C libraries or specialized threading models.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerTask&lt;/code&gt;: lightweight task-local state without manually managing &lt;code&gt;task_local_storage&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;These types provide a safer, composable way to express “initialize once” semantics in concurrent Julia code.&lt;/p&gt;&lt;p&gt;Zentrik&lt;/p&gt;&lt;p&gt;BOLT is a post-link optimizer from LLVM that improves runtime performance by reordering functions and basic blocks, splitting hot and cold code, and folding identical functions. Julia now supports building BOLT-optimized versions of libLLVM, libjulia-internal, and libjulia-codegen.&lt;/p&gt;&lt;p&gt;These optimizations reduce compilation and execution time in common workloads. For example, the all-inference benchmarks improve by about 10%, an LLVM-heavy workload shows a similar ~10% gain, and building &lt;code&gt;corecompiler.ji&lt;/code&gt; improves by 13–16% with BOLT. When combined with PGO and LTO, total improvements of up to ~23% have been observed.&lt;/p&gt;&lt;p&gt;To build a BOLT-optimized Julia, run the following commands from &lt;code&gt;contrib/bolt/&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;make stage1
make copy_originals
make bolt_instrument
make finish_stage1
make merge_data
make bolt&lt;/code&gt;
&lt;p&gt;The optimized binaries will be available in the &lt;code&gt;optimized.build&lt;/code&gt; directory. An analogous workflow exists in &lt;code&gt;contrib/pgo-lto-bolt/&lt;/code&gt; for combining BOLT with PGO+LTO.&lt;/p&gt;&lt;p&gt;BOLT currently works only on Linux x86_64 and aarch64, and the resulting &lt;code&gt;.so&lt;/code&gt; files must not be stripped. Some &lt;code&gt;readelf&lt;/code&gt; warnings may appear during testing but are considered harmless.&lt;/p&gt;&lt;code&gt;@atomic&lt;/code&gt; macro family now supports reference assignment syntax&lt;p&gt;Marek Kaluba&lt;/p&gt;&lt;p&gt;The &lt;code&gt;@atomic&lt;/code&gt; macro family now supports indexing (e.g. &lt;code&gt;m[i]&lt;/code&gt;, &lt;code&gt;m[i,j]&lt;/code&gt;) in addition to field access. This makes it possible to perform atomic fetch, set, modify, swap, compare-and-swap, and set-once directly on array-like references. The macros expand to new APIs: &lt;code&gt;getindex_atomic&lt;/code&gt;, &lt;code&gt;setindex_atomic!&lt;/code&gt;, &lt;code&gt;modifyindex_atomic!&lt;/code&gt;, &lt;code&gt;swapindex_atomic!&lt;/code&gt;, &lt;code&gt;replaceindex_atomic!&lt;/code&gt;, and &lt;code&gt;setindexonce_atomic!&lt;/code&gt;. Vararg and &lt;code&gt;CartesianIndex&lt;/code&gt; indexing are supported.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;code&gt;mem = AtomicMemory{Int}(undef, 2)

@atomic mem[1] = 2                 # atomic set
x = @atomic mem[1]                 # atomic fetch
@atomic :monotonic mem[1] += 1     # atomic modify with order
old = @atomicswap mem[1] = 4       # atomic swap (returns old)
res = @atomicreplace mem[1] 4 =&amp;gt; 10  # (old=4, success=true)
ok  = @atomiconce mem[2] = 7         # set once (Bool)&lt;/code&gt;
&lt;p&gt;Two new per-task metrics can be enabled by starting Julia with &lt;code&gt;--task-metrics=yes&lt;/code&gt; or by calling &lt;code&gt;Base.Experimental.task_metrics(true)&lt;/code&gt;. Enabling or disabling task metrics with &lt;code&gt;Base.Experimental.task_metrics&lt;/code&gt; only affects new tasks, not existing ones. The metrics are:&lt;/p&gt;&lt;p&gt;&lt;code&gt;Base.Experimental.task_running_time_ns(t::Task)&lt;/code&gt;: the time for which &lt;code&gt;t&lt;/code&gt; was actually running. This is currently inclusive of GC time, compilation time, and any spin time.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Base.Experimental.task_wall_time_ns(t::Task)&lt;/code&gt;: the time from the scheduler becoming aware of &lt;code&gt;t&lt;/code&gt; until &lt;code&gt;t&lt;/code&gt; is complete.&lt;/p&gt;&lt;p&gt;Kristoffer Carlsson&lt;/p&gt;&lt;p&gt;A workspace is a set of project files that all share the same manifest. Each project in a workspace can include its own dependencies, compatibility information, and even function as a full package.&lt;/p&gt;&lt;p&gt;When the package manager resolves dependencies, it considers the requirements and compatibility of all the projects in the workspace. The compatible versions identified during this process are recorded in a single manifest file.&lt;/p&gt;&lt;p&gt;A workspace is defined in the base project by giving a list of the projects in it:&lt;/p&gt;&lt;code&gt;[workspace]
projects = ["test", "docs", "benchmarks", "PrivatePackage"]&lt;/code&gt;
&lt;p&gt;This structure is particularly beneficial for developers using a monorepo approach, where a large number of unregistered packages may be involved. It is also useful for adding documentation or benchmarks to a package by including additional dependencies beyond those of the package itself. Test-specific dependencies are now recommended to be specified using the workspace approach (a project file in the &lt;code&gt;test&lt;/code&gt; directory that is part of the workspace defined by the package project file).&lt;/p&gt;&lt;p&gt;Workspaces can also be nested: a project that itself defines a workspace can also be part of another workspace. In this case, the workspaces are “merged,” with a single manifest being stored alongside the “root project” (the project that is not included in another workspace).&lt;/p&gt;&lt;p&gt;An app is a Julia package that can be run directly from the terminal, similar to a standalone program. Each app provides an entry point via &lt;code&gt;@main&lt;/code&gt; and can define its own default Julia flags and executable name.&lt;/p&gt;&lt;p&gt;When an app is installed, it gets put into &lt;code&gt;.julia/bin&lt;/code&gt; and by adding that to your &lt;code&gt;PATH&lt;/code&gt; it allows you to launch it by name together with any arguments or options.&lt;/p&gt;&lt;p&gt;A Julia app is defined in the &lt;code&gt;Project.toml&lt;/code&gt; file using an &lt;code&gt;[apps]&lt;/code&gt; section:&lt;/p&gt;&lt;code&gt;[apps]
reverse = {} # empty dictionary is for additional metadata&lt;/code&gt;
&lt;p&gt;with a corresponding entry point in the package module:&lt;/p&gt;&lt;code&gt;# src/MyReverseApp.jl
module MyReverseApp

function (@main)(ARGS)
    for arg in ARGS
        print(stdout, reverse(arg), " ")
    end
end

end # module&lt;/code&gt;
&lt;p&gt;After installation, the app can be run directly in the terminal:&lt;/p&gt;&lt;code&gt;$ reverse some input string
emos tupni gnirts&lt;/code&gt;
&lt;p&gt;This makes apps useful for building CLI tools or packaging Julia functionality as user-facing executables. Multiple apps can be defined per package by using submodules, and each app can specify default Julia flags (e.g. &lt;code&gt;--threads=4&lt;/code&gt;) for performance or debugging.&lt;/p&gt;&lt;p&gt;See the full documentation for more information: https://pkgdocs.julialang.org/dev/apps/&lt;/p&gt;&lt;p&gt;&lt;code&gt;Pkg.status()&lt;/code&gt; now highlights when a dependency's loaded version differs from what the current environment would load. This helps identify situations where you may be running code against an outdated or mismatched version of a package—particularly useful when switching between environments or after modifying dependencies.&lt;/p&gt;&lt;p&gt;When a package is already loaded from a different version or path than what the current environment specifies, Pkg will display a yellow &lt;code&gt;[loaded: vX.Y.Z]&lt;/code&gt; indicator next to the package name:&lt;/p&gt;&lt;p&gt;This visual cue makes it easier to spot when you need to restart Julia to pick up the correct package versions, reducing debugging time and confusion in iterative development workflows.&lt;/p&gt;&lt;p&gt;Tim Besard&lt;/p&gt;&lt;p&gt;&lt;code&gt;Ptr{T}&lt;/code&gt; now lowers to actual LLVM pointer types in generated IR (i.e. &lt;code&gt;ptr&lt;/code&gt; with opaque pointers, or &lt;code&gt;i8*&lt;/code&gt;), instead of integers like &lt;code&gt;i64&lt;/code&gt;. This simplifies low-level interop: &lt;code&gt;llvmcall&lt;/code&gt; no longer needs &lt;code&gt;ptrtoint&lt;/code&gt;/&lt;code&gt;inttoptr&lt;/code&gt; shims, and many intrinsics can be called via &lt;code&gt;ccall&lt;/code&gt; using &lt;code&gt;Ptr&lt;/code&gt; directly.&lt;/p&gt;&lt;p&gt;What changes for you&lt;/p&gt;&lt;p&gt;Inline LLVM (&lt;code&gt;llvmcall&lt;/code&gt;): update IR to use &lt;code&gt;ptr&lt;/code&gt;/&lt;code&gt;i8*&lt;/code&gt; for pointer arguments/returns, and remove redundant &lt;code&gt;ptrtoint&lt;/code&gt;/&lt;code&gt;inttoptr&lt;/code&gt; casts. Old IR that treats pointers as integers is still accepted but emits a deprecation warning.&lt;/p&gt;&lt;p&gt;Pointer arithmetic: &lt;code&gt;add_ptr&lt;/code&gt; / &lt;code&gt;sub_ptr&lt;/code&gt; now operate on real pointers: &lt;code&gt;add_ptr(::Ptr{T}, ::UInt)&lt;/code&gt; and &lt;code&gt;sub_ptr(::Ptr{T}, ::UInt)&lt;/code&gt; (lowered to GEP).&lt;/p&gt;&lt;p&gt;&lt;code&gt;ccall&lt;/code&gt; convenience: passing/returning &lt;code&gt;Ptr{T}&lt;/code&gt; maps to LLVM pointer types directly, enabling more intrinsic calls without custom &lt;code&gt;llvmcall&lt;/code&gt; glue.&lt;/p&gt;&lt;p&gt;Example (before → after)&lt;/p&gt;&lt;code&gt;; BEFORE (deprecated): integer pointer
define i64 @f(i64 %p) {
  %q = inttoptr i64 %p to i8*
  ; ...
  %r = ptrtoint i8* %q to i64
  ret i64 %r
}

; AFTER: real pointer
define ptr @f(ptr %p) {
  ; ...
  ret ptr %p
}&lt;/code&gt;
&lt;p&gt;This change also unlocks minor optimization opportunities in generated code since pointers no longer bounce through integer casts.&lt;/p&gt;&lt;p&gt;Mosè Giordano&lt;/p&gt;&lt;p&gt;Many developers may have experience with occasional failures when running tests of their packages which were observed only on remote machines, and wished to be able to reproduce the same run, for debugging purposes. The GitHub Actions workflow &lt;code&gt;julia-actions/julia-runtest&lt;/code&gt; recently started printing to the log the full options used to invoke the Julia process which runs the tests, which lets developers use the same compiler options (e.g. bounds checking, code coverage, deprecation warnings, etc.) as the CI runs. However there are occasional failures which don't depend on compiler options, but may depend on the state of the global random number generator (RNG), if for example the input data of the tests is generated with functions like &lt;code&gt;rand&lt;/code&gt; and &lt;code&gt;randn&lt;/code&gt;, without passing an explicit RNG object, instead relying on the global one. The &lt;code&gt;Test.@testset&lt;/code&gt; macro has had for a long time the feature of automatically controlling the global RNG, but until now its state was never displayed. Starting from Julia v1.12, a failure inside a &lt;code&gt;@testset&lt;/code&gt; causes the RNG of the outermost test set to be printed to screen, which then you can also set in a new test set to exactly reproduce the same run.&lt;/p&gt;&lt;p&gt;As an example, consider the following test which would fail with a 0.1% probability:&lt;/p&gt;&lt;code&gt;julia&amp;gt; using Test

julia&amp;gt; @testset begin
           @test rand() &amp;gt; 0.001
       end;
test set: Test Failed at REPL[2]:2
  Expression: rand() &amp;gt; 0.001
   Evaluated: 0.00036328334842516963 &amp;gt; 0.001

Stacktrace:
 [1] top-level scope
   @ REPL[2]:2
 [2] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:1776 [inlined]
 [3] macro expansion
   @ REPL[2]:2 [inlined]
 [4] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:680 [inlined]
Test Summary: | Fail  Total  Time
test set      |    1      1  1.5s
RNG of the outermost testset: Random.Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7)
ERROR: Some tests did not pass: 0 passed, 1 failed, 0 errored, 0 broken.&lt;/code&gt;
&lt;p&gt;Normally, it'd require several attempts to reproduce a similar failure, but now the RNG is printed to screen and you can reproduce the run in a new session by setting the &lt;code&gt;rng&lt;/code&gt; option of &lt;code&gt;@testset&lt;/code&gt; to the value printed in the failed test:&lt;/p&gt;&lt;code&gt;julia&amp;gt; using Test, Random

julia&amp;gt; @testset rng=Random.Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7) begin
           @test rand() &amp;gt; 0.001
       end;
test set: Test Failed at REPL[2]:2
  Expression: rand() &amp;gt; 0.001
   Evaluated: 0.00036328334842516963 &amp;gt; 0.001

Stacktrace:
 [1] top-level scope
   @ REPL[2]:2
 [2] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:1776 [inlined]
 [3] macro expansion
   @ REPL[2]:2 [inlined]
 [4] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:680 [inlined]
Test Summary: | Fail  Total  Time
test set      |    1      1  1.4s
RNG of the outermost testset: Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7)
ERROR: Some tests did not pass: 0 passed, 1 failed, 0 errored, 0 broken.&lt;/code&gt;
&lt;p&gt;While there are still many other classes of intermittent failures that aren't captured by the global RNG, being able to reproduce its state inside failing test sets should help debugging more issues during package development.&lt;/p&gt;&lt;p&gt;The preparation of this release was partially funded by NASA under award 80NSSC22K1740. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Aeronautics and Space Administration.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://julialang.org/blog/2025/10/julia-1.12-highlights/"/><published>2025-10-08T18:42:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519575</id><title>A few things to know before stealing my 914 (2022)</title><updated>2025-10-08T22:09:10.972960+00:00</updated><content>&lt;doc fingerprint="36419e95892d15df"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Media | Articles&lt;/head&gt;
    &lt;head rend="h1"&gt;A few things to know before stealing my 914&lt;/head&gt;
    &lt;p&gt;Dear Thief,&lt;/p&gt;
    &lt;p&gt;Welcome to my Porsche 914. I imagine that at this point (having found the door unlocked) your intention is to steal my car. Don’t be encouraged by this; the tumblers sheared off in 1978. I would have locked it up if I could, so don’t think you’re too clever or that I’m too lazy. However, now that you’re in the car, there are a few things you’re going to need to know. First, the battery is disconnected, so slide-hammering my ignition switch is not your first step. I leave the battery disconnected, not to foil hoodlums such as yourself, but because there is a mysterious current drain from the 40-year-old German wiring harness that I can’t locate and/or fix. So, connect the battery first. Good luck finding the engine cover release. Or the engine, for that matter.&lt;/p&gt;
    &lt;p&gt;Now, you can skip your slide hammer. The ignition switch’s tumblers are so worn that any flat-bladed screwdriver or pair of scissors will do. Don’t tell anyone.&lt;/p&gt;
    &lt;p&gt;Once you’ve figured that out and try to start the car, you’ll run into some trouble. The car is most likely in reverse gear, given that the parking brake cable froze up sometime during the Carter administration. Since there is not a clutch safety switch on the starting circuit, make sure to press the clutch down before you try to crank the engine. (I don’t want you running into my other car in the driveway.) This is doubly necessary because my starter is too weak to crank the clutch-transmission input shaft assembly with any success.&lt;/p&gt;
    &lt;p&gt;With the clutch pedal depressed, the engine should turn over fast enough to get things going. But first, you’ll need to press the gas pedal to the floor exactly four times. Not three. Not five. Four. The dual Webers don’t have chokes and you’ll be squirting fuel down the barrels with the accelerator pumps for the necessary priming regime. If you don’t do it right, the car won’t start before the battery gives up the ghost. Consider yourself forewarned.&lt;/p&gt;
    &lt;p&gt;If you’ve followed along so far, the engine should fire right up. Don’t be fooled—it will die in eight seconds when the priming fuel runs out. Repeat the gas pedal priming procedure, but only pump two times. Deviate from this routine at your own peril.&lt;/p&gt;
    &lt;p&gt;Now you have the engine running. Make sure the green oil light in the dash goes out. If it does not, you only have about 100 yards to drive before the engine locks up, so be attentive. If all goes well with the oil pressure, you may now attend to the gear shift lever. Some explanation follows.&lt;/p&gt;
    &lt;p&gt;This is a Porsche 914. It has a mid-engine layout. The transmission is in the far back of the car, and the shift linkage’s main component is a football-field-long steel rod formed loosely in the shape of your lower intestine. Manipulating the gear shift lever will deliver vague suggestions to this rod, which, in turn, will tickle small parts deep within the dark bowels of the transaxle case. It is akin to hitting a bag of gears with a stick, hopefully finding one that works.&lt;/p&gt;
    &lt;p&gt;If you are successful in finding first gear (there is a shift pattern printed on the knob; they say German engineers don’t have a sense of humor), congratulations. You may launch the vehicle into motion.&lt;/p&gt;
    &lt;p&gt;Do not become emboldened by your progress, as you will quickly need to shift to another gear. Ouija boards are more communicative than the shift knob you will be trusting to aid your efforts. Depress the clutch as you would in any car, and pull the knob from its secure location out of first gear. Now you will become adrift in the zone known to early Porsche owners as “Neverland” and your quest will be to find second gear. Prepare yourself for a ten-second-or-so adventure. Do not go straight forward with the shift knob, as you will only find Reverse waiting there to mock you with a shriek of high-speed gear teeth machining themselves into round cylinders. Should you hear this noise, retreat immediately to the only easy spot to find in this transmission: neutral. This is a safe place, no real damage can occur here, but alas, no forward motion will happen either. From this harbor of peace, you can re-attempt to find second, but you may just want to go for any “port in a storm”, given that the traffic behind you is now cheering you on in your quest with vigorous horn-honks of support and encouragement. Most 914 owners at this point pull over to the side of the road and feign answering a cell phone call to a) avoid further humiliation; b) allow traffic to pass; and c) gather the courage for another first gear start. You may choose to do likewise.&lt;/p&gt;
    &lt;p&gt;If you press onward without taking a break, you may re-enter first. This is how the car mocks you for your lack of skill, but sometimes it is the only path forward. Once you are ready to again try for second, I can offer some advice. One trick that works is to declutch the transmission, pull the lever from the first-gear position, enter into the aforementioned neutral zone, and then rapidly wig-wag the shift knob side-to-side along a lateral axis. If you move the knob quickly enough, the transmission will be out-smarted and cannot anticipate your next move. It is at this time that you should re-attempt to enter second, and most likely you will do so. Surprise is your best weapon against this transmission.&lt;/p&gt;
    &lt;p&gt;The move to third should be straightforward, as it’s the only easily-accessible gear in the set. You should now be out of my neighborhood and on the main four-lane road. Third gear will be good for 45 mph, so I would advise you just staying there. Trying to get to fourth gear will only frustrate you and your nearby drivers (see: first-to-second shift).&lt;/p&gt;
    &lt;p&gt;You don’t need to check for gasoline in the car. It will be full, even though the fuel gauge reads zero. The odometer reads “0”, not because it was reset when I filled the tank, but because it is just broken. Ignore it. If it is night, and it most likely will be, you will need to turn on the lights. I’ll leave it to you to find the switch since I’ve helped a lot so far. Suffice to say that once you get them active, you will find that the seven inch sealed beams from 1971 will only illuminate sufficient roadway for travel below 45 mph. Since you are still in third , this shouldn’t be a problem. Oh, and the lights only work on high beam, so ignore the flashing lights and vulgar gestures from opposing traffic.&lt;/p&gt;
    &lt;p&gt;By now you’ve certainly noticed the smell. That is the aroma of Mobil 1 oil being boiled off of long sections of horizontal exhaust pipes, which were cleverly encased by the factory with a second shroud of oil-holding chambers. They filled with oil during my last drive and you are now operating a small thermal refinery that is making light short-chained vaporous hydrocarbons from what was once $8-a-quart oil. They are being conveniently routed to the cabin through carefully formed channels in the heating system, plus the rust holes in the floor provided by Mother Nature herself over the past few decades.&lt;/p&gt;
    &lt;p&gt;You’ll feel less dizzy if you open a window. But mind that driver’s window does not work, so you’ll have to lean over and roll down the passenger window half-way. I say half-way in a manner that will become apparent once you try to get the window to go all the way down, which it will refuse to do. Instead, simply open the driver’s door slightly and drive along, as I do. Once the oil vapors are exhumed from the cabin, you should start to feel a little better. There is a rag behind the driver’s seat that you can use to wipe the oil film off of the inside of the windshield.&lt;/p&gt;
    &lt;p&gt;Knowing which road you’re probably on by now, you will be hitting stop lights. Try as hard as you can to not bring the 914 to a stop. The brake system is ideal for this situation, being known more as “scrubbers” than “brakes”. Since you can’t effectively stop the car, use this to your advantage and don’t try. Remember: You certainly don’t want to have to go back into first.&lt;/p&gt;
    &lt;p&gt;If you have made it within sight of to the highway entrance, don’t get any ideas. The front right wheel is severely bent and the vibration at velocities above 50 mph will crack the windshield and cause the doors to open by themselves. So stay on the surface streets, stoplights notwithstanding.&lt;/p&gt;
    &lt;p&gt;It may be at this point that you consider abandoning the car to avoid further calamity. There is an Exxon station right before the freeway entrance. The last guy who stole my 914 used this very spot and it was rather convenient for all concerned parties. I suggest you ditch the car there and scope out a nice, reliable Camry to heist.&lt;/p&gt;
    &lt;p&gt;Norman Garrett was the Concept Engineer for the original Miata back in his days at Mazda’s Southern California Design Studio. He currently teaches automotive engineering classes at UNC-C’s Motorsports Engineering Department in Charlotte, North Carolina and curates his small collection of dysfunctional automobiles and motorcycles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.hagerty.com/media/advice/a-few-things-to-know-before-you-steal-my-914/"/><published>2025-10-08T19:16:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519915</id><title>Svelte is that fast</title><updated>2025-10-08T22:09:10.680054+00:00</updated><content>&lt;doc fingerprint="e50d1701050b4dd2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Svelte really is that fast&lt;/head&gt;
    &lt;p&gt;If you search online, you’ll find countless benchmarks claiming to compare the performance of various JavaScript frameworks with each other. More often than not, the benchmarks are overly simplistic and fail to reflect real-world scenarios. In other cases, they compare apples and oranges, for instance by pitting a fully fledged framework against a lightweight library that cover only a small subset of the framework’s functionality.&lt;/p&gt;
    &lt;p&gt;Right now, I’m at that point in my career again where I am starting development on a new web application and need to choose the “right” JavaScript framework. This time, I decided to look for academic studies on the performance of JavaScript frameworks and sadly, didn’t find as many as I had hoped. I did come across one particular study that compares Angular, React, Vue, Svelte and Blazor with each other. Its main drawback is that the comparison was done in 2021 – a lifetime ago in tech terms – but I think it’s still worth reading.&lt;/p&gt;
    &lt;p&gt;Before I dive into the summary, I want to share something I found mildly amusing. The paper is published in the Journal of Web Engineering, and if you visit its website, you’ll notice it includes &lt;code&gt;/index.php/&lt;/code&gt; in the URL. I’m not sure why.
Is it a deliberate choice? Or is it a sign of questionable web engineering?&lt;/p&gt;
    &lt;p&gt;It is estimated that up to 97% of websites today use JavaScript, with more than 80% also relying on a library or framework. JavaScript is often used to manage UI state changes within single page applications, allowing users to interact without reloading the entire page. While this can be done manually via the DOM API, it’s often error prone.&lt;/p&gt;
    &lt;p&gt;Modern web frameworks wrap the DOM API and provide a custom declarative syntax. This means that application code can simply describe the desired UI state, and the framework automatically generates the necessary DOM API calls to reflect that state in the browser.&lt;/p&gt;
    &lt;p&gt;When using the DOM API directly, the amount of script execution required to update the UI scales linearly with the complexity of the change. However, when DOM API calls are generated dynamically by a framework, the framework must first determine exactly which updates are necessary, introducing additional overhead. Furthermore, the chosen rendering strategy can greatly affect the number of DOM API calls made. A bad strategy may result in noticeable delays even for small updates, which is why it makes sense to compare the strategies used by major JavaScript frameworks.&lt;/p&gt;
    &lt;p&gt;The study looks at five popular frameworks: Angular, React, Vue, Svelte, and Blazor. All are JavaScript-based except for Blazor, which uses WebAssembly. Blazor applications are written in C# and run in a .NET runtime compiled to WebAssembly. Because WebAssembly modules lack direct access to the DOM, they rely on an additional JavaScript interoperability layer, which can introduce extra overhead.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Framework&lt;/cell&gt;
        &lt;cell role="head"&gt;Version&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Angular&lt;/cell&gt;
        &lt;cell&gt;11.2.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;React&lt;/cell&gt;
        &lt;cell&gt;17.0.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Vue&lt;/cell&gt;
        &lt;cell&gt;3.0.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Svelte&lt;/cell&gt;
        &lt;cell&gt;3.35.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Blazor&lt;/cell&gt;
        &lt;cell&gt;5.0.3&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All five frameworks follow some variant of the Model-View-ViewModel (MVVM) pattern. In MVVM, developers define components that bind an application’s data sources to views, so that changes in the data are automatically reflected in the UI.&lt;/p&gt;
    &lt;p&gt;Each framework continuously tries to keep the state of the DOM tree synchronised with the state of the component tree defined in application code. This is done using two distinct methods.&lt;/p&gt;
    &lt;p&gt;The first method, known as virtual DOM (vDOM)-based rendering, is used in React, Vue, and Blazor. It works by comparing the two trees and calculating the minimum set of changes needed to transform one into the other. This generally has a time complexity of , but can often be simplified to by making assumptions that usually apply in browser applications.&lt;/p&gt;
    &lt;p&gt;The second method is used by Angular and Svelte. Here, there is no separate step for calculating all required changes to the DOM. Instead, each component directly updates its corresponding section of the DOM by tracking the values of its data bindings.&lt;/p&gt;
    &lt;p&gt;From a performance standpoint, using a virtual DOM can introduce overhead not present in a binding-based rendering strategy.&lt;/p&gt;
    &lt;p&gt;All of the reviewed frameworks perform DOM updates within a render loop that walks through the component tree. The cost of this render loop depends on the size of the input and fixed costs.&lt;/p&gt;
    &lt;p&gt;A render loop involves two types of work: creating new elements and updating existing ones. Creating elements is generally straightforward and costs the same for each framework, regardless of rendering strategy.&lt;/p&gt;
    &lt;p&gt;Updating existing elements is where the rendering strategy makes a noticeable difference. Angular, for example, always walks through the entire component tree, resulting in a lot of unnecessary work when only a small part of the tree needs updating. React and Blazor walk only through the subtree of the component that initiates the render loop, which is usually more efficient but may still require some unnecessary work for descendants whose output has not changed. Vue and Svelte, on the other hand, process only “dirty” components whose output has changed. This requires the framework to track which components are dirty. Vue does this at runtime, Svelte handles it at compile time.&lt;/p&gt;
    &lt;p&gt;Finally, component output can be classified as either static or dynamic content, with static content remaining unchanged after the component’s initial render. Frameworks that can optimise for static content may have a performance advantage over those that cannot.&lt;/p&gt;
    &lt;p&gt;Several benchmarks were conducted using Angular, React, Vue, Svelte and Blazor. The authors found significant differences in performance between the frameworks, especially as input size increased. , outperforming the others across literally every benchmark.&lt;/p&gt;
    &lt;p&gt;Svelte is the fastest framework when creating static elements, while React is generally among the slowest:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;500&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1000&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;13&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;5000&lt;/cell&gt;
        &lt;cell&gt;85&lt;/cell&gt;
        &lt;cell&gt;77&lt;/cell&gt;
        &lt;cell&gt;28&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;61&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;10000&lt;/cell&gt;
        &lt;cell&gt;177&lt;/cell&gt;
        &lt;cell&gt;200&lt;/cell&gt;
        &lt;cell&gt;47&lt;/cell&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;123&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;25000&lt;/cell&gt;
        &lt;cell&gt;844&lt;/cell&gt;
        &lt;cell&gt;956&lt;/cell&gt;
        &lt;cell&gt;95&lt;/cell&gt;
        &lt;cell&gt;63&lt;/cell&gt;
        &lt;cell&gt;371&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;50000&lt;/cell&gt;
        &lt;cell&gt;2520&lt;/cell&gt;
        &lt;cell&gt;3559&lt;/cell&gt;
        &lt;cell&gt;173&lt;/cell&gt;
        &lt;cell&gt;98&lt;/cell&gt;
        &lt;cell&gt;964&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Svelte is also the fastest when creating components arranged as a binary tree. However, in this case, Blazor is the slowest by a considerable margin:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;512&lt;/cell&gt;
        &lt;cell&gt;75&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;53&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1024&lt;/cell&gt;
        &lt;cell&gt;120&lt;/cell&gt;
        &lt;cell&gt;55&lt;/cell&gt;
        &lt;cell&gt;84&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;128&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4096&lt;/cell&gt;
        &lt;cell&gt;216&lt;/cell&gt;
        &lt;cell&gt;137&lt;/cell&gt;
        &lt;cell&gt;223&lt;/cell&gt;
        &lt;cell&gt;83&lt;/cell&gt;
        &lt;cell&gt;485&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8192&lt;/cell&gt;
        &lt;cell&gt;297&lt;/cell&gt;
        &lt;cell&gt;233&lt;/cell&gt;
        &lt;cell&gt;313&lt;/cell&gt;
        &lt;cell&gt;142&lt;/cell&gt;
        &lt;cell&gt;966&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16384&lt;/cell&gt;
        &lt;cell&gt;469&lt;/cell&gt;
        &lt;cell&gt;394&lt;/cell&gt;
        &lt;cell&gt;485&lt;/cell&gt;
        &lt;cell&gt;233&lt;/cell&gt;
        &lt;cell&gt;1870&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;32768&lt;/cell&gt;
        &lt;cell&gt;774&lt;/cell&gt;
        &lt;cell&gt;733&lt;/cell&gt;
        &lt;cell&gt;897&lt;/cell&gt;
        &lt;cell&gt;482&lt;/cell&gt;
        &lt;cell&gt;3644&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When updating the root component of a tree with components, :&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;512&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;23&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1024&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;42&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4096&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;92&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8192&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;92&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16384&lt;/cell&gt;
        &lt;cell&gt;43&lt;/cell&gt;
        &lt;cell&gt;211&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;32768&lt;/cell&gt;
        &lt;cell&gt;103&lt;/cell&gt;
        &lt;cell&gt;379&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When updating a leaf component in a component tree of components, Angular is the only framework that lags slightly behind. This is because it performs the same amount of work regardless of what has actually changed:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;512&lt;/cell&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1024&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4096&lt;/cell&gt;
        &lt;cell&gt;33&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8192&lt;/cell&gt;
        &lt;cell&gt;33&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16384&lt;/cell&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;32768&lt;/cell&gt;
        &lt;cell&gt;104&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Finally, the table below shows the script execution time when updating the entire component tree of components, where each component contains primarily static content:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;34&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;28&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;256&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;60&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;512&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;66&lt;/cell&gt;
        &lt;cell&gt;42&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;101&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1024&lt;/cell&gt;
        &lt;cell&gt;27&lt;/cell&gt;
        &lt;cell&gt;101&lt;/cell&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;250&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;2048&lt;/cell&gt;
        &lt;cell&gt;29&lt;/cell&gt;
        &lt;cell&gt;235&lt;/cell&gt;
        &lt;cell&gt;91&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;502&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4096&lt;/cell&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;289&lt;/cell&gt;
        &lt;cell&gt;149&lt;/cell&gt;
        &lt;cell&gt;54&lt;/cell&gt;
        &lt;cell&gt;1020&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;8192&lt;/cell&gt;
        &lt;cell&gt;238&lt;/cell&gt;
        &lt;cell&gt;841&lt;/cell&gt;
        &lt;cell&gt;311&lt;/cell&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;2013&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Overall, the results are in line with what would be expected given the characteristics of each rendering strategy.&lt;/p&gt;
    &lt;p&gt;The WebAssembly-based Blazor shows significantly worse performance than its JavaScript-based competitors. However, from these benchmarks alone it’s impossible to determine whether this is due to Blazor itself or a fundamental limitation of using WebAssembly for this purpose.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Svelte demonstrates three key characteristics that likely contribute most to improved performance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The use of a reactivity system to automatically detect dirty components&lt;/item&gt;
      &lt;item&gt;An optimising compiler that generates component update code which ignores static content&lt;/item&gt;
      &lt;item&gt;A binding-based rendering approach rather than a virtual DOM&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Svelte’s on fire, yo&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chuniversiteit.nl/papers/svelte-is-fast"/><published>2025-10-08T19:54:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519944</id><title>Expanding access to Opal, our no-code AI mini-app builder</title><updated>2025-10-08T22:09:10.474613+00:00</updated><content>&lt;doc fingerprint="f84bb61b56556dc9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Expanding access to Opal, our no-code AI mini-app builder&lt;/head&gt;
    &lt;p&gt;Two months ago, we introduced Opal as an early experiment within Google Labs. Our goal was simple: give users the ability to build AI-powered mini-apps, using just natural language — no coding required. When we opened up Opal to users in the U.S. we anticipated they might build simple, fun tools. We didn’t expect the surge of sophisticated, practical and highly creative Opal apps we got instead. The ingenuity of these early adopters made one thing clear: we need to get Opal into the hands of more creators globally.&lt;/p&gt;
    &lt;p&gt;Today, we’re starting to expand Opal to 15 more countries. Opal will begin rolling out in Canada, India, Japan, South Korea, Vietnam, Indonesia, Brazil, Singapore, Colombia, El Salvador, Costa Rica, Panamá, Honduras, Argentina and Pakistan.&lt;/p&gt;
    &lt;p&gt;We’re also sharing details about improvements we’re making to Opal. As more and more people begin to use it, they are finding new and more complex ways to build apps. One of the top requests we’ve received is for more transparency and reliability for Opal workflows. In response, we’re rolling out the following improvements:&lt;/p&gt;
    &lt;p&gt;Advanced debugging for workflows: We’ve fundamentally improved the debugging program but intentionally kept it no-code. You can now run your workflow step-by-step in the visual editor or iterate on a specific step in the console panel. Errors are displayed in real time and localized to the exact step where the failure occurred to provide immediate context and eliminate guesswork. We hope it helps you spend less time debugging and more time building.&lt;/p&gt;
    &lt;p&gt;A faster, more responsive foundation for your apps: We’ve also made significant under-the-hood improvements to Opal’s core performance. Previously, creating a new Opal could take up to five seconds or more. We’ve invested in improvements to speed that up dramatically to make it faster to get started. We’ve also enabled parallel runs, allowing complex workflows with multiple steps to execute simultaneously, helping to reduce overall wait times.&lt;/p&gt;
    &lt;p&gt;Whether you’re automating a complex business process, accelerating your marketing efforts or bringing a creative vision to life, Opal is here to help you build. Try Opal today at opal.withgoogle.com. And if you’re new to Opal, join our builder community through our Discord channel.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/technology/google-labs/opal-expansion/"/><published>2025-10-08T19:56:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45520154</id><title>I played 1k hands of online poker and built a web app with Cursor AI</title><updated>2025-10-08T22:09:10.266643+00:00</updated><content>&lt;doc fingerprint="3cc0aa516d242ab6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I played 1,000 hands of online poker and built a web app with Cursor AI&lt;/head&gt;
    &lt;p&gt;In the last two weeks I spent over a dozen hours playing poker, primarily online at pokerstarsmi.com, and live at a local casino.&lt;/p&gt;
    &lt;p&gt;You can view the last 1,000 hands I played here: https://poker.rchase.com&lt;/p&gt;
    &lt;p&gt;I spent at least as much time reviewing my hands with a desktop app called PokerTracker 4, I read 6 books, studied strategy, and journaled about it in my Apple Notes.&lt;/p&gt;
    &lt;p&gt;Then I started building my own Python script automations to export my hand history from PokerStars, import it into PokerTracker 4, check my balance, stuff like that.&lt;/p&gt;
    &lt;p&gt;That led me to getting help writing code from Grok, then Cursor, and then building a full blown Laravel MVP for a web app similar to the PokerTracker 4 desktop app.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why poker?&lt;/head&gt;
    &lt;p&gt;Without getting too philosophical, it's not about the money won or lost - I'm playing low stakes right now because I'm a beginner.&lt;/p&gt;
    &lt;p&gt;I just want to learn the game.&lt;/p&gt;
    &lt;p&gt;Maybe someday I'll play some tournaments or high stakes.&lt;/p&gt;
    &lt;p&gt;But right now, more importantly, I'm learning about myself.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Emotional intelligence becoming aware of emotions in myself and others&lt;/item&gt;
      &lt;item&gt;Self-regulation trying to control my emotions and not let them influence my actions&lt;/item&gt;
      &lt;item&gt;Resilience not giving up because of downswings&lt;/item&gt;
      &lt;item&gt;Humility learning to not get overconfident after a big win&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also have enjoyed the lessons from the bankroll side of the game:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Managing risk, taking profits, cutting losses&lt;/item&gt;
      &lt;item&gt;Developing the discipline to scale down my buy-ins when losing to keep a max of 10% of bankroll in play so I don't blow my entire bankroll on a bad day&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whether I won or lost money in a given day isn't important, what's important is whether I followed my plan or not.&lt;/p&gt;
    &lt;p&gt;If I let emotions guide my actions, or I maintained self-control.&lt;/p&gt;
    &lt;p&gt;Success is if I made good decisions given the information I had at the time, even if it didn't lead to a good outcome.&lt;/p&gt;
    &lt;p&gt;The analogies to life and business lessons are endless... but in this blog post I mainly wanted to write about my experience building this web app with AI which was completely mind blowing!&lt;/p&gt;
    &lt;head rend="h3"&gt;Building a poker stats web app with Laravel in Cursor&lt;/head&gt;
    &lt;p&gt;So after only 2 or 3 days of just chatting back and forth for hours and hours with the Cursor AI agent I built a fully functional web app at poker.rchase.com with an admin dashboard and dozens of features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Admin dashboard&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PokerStars and Gmail integrations&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complicated (over 700 lines of code) poker hand history text file parser&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complicated poker stats calculations like VPIP, PFR, and 3-Bet&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CRUD for journal entries, logging poker account deposits/withdrawals&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hand history file management with multi-file upload and "paste text" options&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Daily PokerStars balance checks&lt;/item&gt;
      &lt;item&gt;Auto export PokerStars hands every 15 minutes with enabled/disabled toggle&lt;/item&gt;
      &lt;item&gt;Auto import hands from email using Gmail IMAP integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hand history table and individual hand viewer&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Profit/loss chart&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Built locally using Herd for MacOS and deployed with the help of Cursor to a DigitalOcean Debian 13 server. Private git repo hosted by GitHub.&lt;/p&gt;
    &lt;p&gt;The insane part is I didn't write a single line of this code.&lt;/p&gt;
    &lt;p&gt;All of this was created through conversations with the Cursor AI agent.&lt;/p&gt;
    &lt;p&gt;I don't even know how we got here with AI.&lt;/p&gt;
    &lt;p&gt;Just a few years ago I remember chatting with ChatGPT asking it to write some basic Python script for me and it was completely useless, it hallucinated calling libraries that didn't exist, using functions it forgot to write... it was nuts.&lt;/p&gt;
    &lt;p&gt;It couldn't even do basic math not that long ago like 2+2=5 was a common thing that would happen in the course of a conversation.&lt;/p&gt;
    &lt;p&gt;I wrote off AI entirely for years after that brief experience - as clearly overhyped and with limited use case potential.&lt;/p&gt;
    &lt;p&gt;But then at some point, I subscribed to the Grok $30/month plan and began using it every single day.&lt;/p&gt;
    &lt;p&gt;It quickly replaced Google Search entirely for me.&lt;/p&gt;
    &lt;p&gt;And then I started to use it much more than I had previously used Google Search.&lt;/p&gt;
    &lt;p&gt;My team started to check with AI about hard problems we ran into whether it was networking or programming, usually the answers weren't great and of course we always reviewed carefully for security issues and didn't just trust implicitly the information it provided.&lt;/p&gt;
    &lt;p&gt;But we could see over time it was improving in the responses.&lt;/p&gt;
    &lt;p&gt;It became a thing when we were stuck "Did you check what Grok had to say about this?"&lt;/p&gt;
    &lt;p&gt;I remember earlier this year my feed being full of "vibe coding" on X and in particular Pieter Levels' fly.pieter.com, but I kind of just followed along for entertainment and I think even at that time it was much worse than it is now, I think you needed to keep the code in one file and implement various hacks to keep the AI aware of the context of that file.&lt;/p&gt;
    &lt;p&gt;But I had no idea it was this far along until last week I pasted my Python PokerStars hand exporter script into Grok and asked it to build the Gmail integration to retrieve the login PIN and with very few iterations it was able to do it successfully and without me writing any code.&lt;/p&gt;
    &lt;p&gt;Then I had it replace all my print statement debugging with proper logging and it did that too easily.&lt;/p&gt;
    &lt;p&gt;Then I had it turn the monolithic script into a class that could be used in other scripts and it did that as well.&lt;/p&gt;
    &lt;p&gt;I was so impressed that I decided to start looking into what the best AI tools were out there for programming... so of course I didn't Google that, I asked Grok. And I started to learn about Cursor, Claude, and Windsurf.&lt;/p&gt;
    &lt;head rend="h3"&gt;What it's like to build a web app with Cursor&lt;/head&gt;
    &lt;p&gt;For me, I've been primarily building apps through other people for the last 4 years now. I barely write any code. I'm not proficient enough to make commits to any of our production repos at HostiFi... sadly.&lt;/p&gt;
    &lt;p&gt;However, the skill I do have is I understand what I want to build, in what order, and what sacrifices need to be made in order to ship it.&lt;/p&gt;
    &lt;p&gt;I have knack for user experience and a small amount of design sense.&lt;/p&gt;
    &lt;p&gt;I also have empathy for the developers I work with, and the complexity of the work involved to build features. I have enough technical knowledge to debate with them the pros and cons of difference approaches when there are forks in the road.&lt;/p&gt;
    &lt;p&gt;All this to say - working with the Cursor Agent was eerily similar to working with a human developer on my team... but way, way faster because the feedback loop was real-time.&lt;/p&gt;
    &lt;p&gt;It was such an unusual experience to watch Cursor work that it's hard to put into words, you really just have to try it for yourself.&lt;/p&gt;
    &lt;p&gt;Basically you tell it to build something, it writes some code, I open the page and there's a 500 error. I tell it - hey there's a 500 error. It checks the logs, finds the bug, fixes the bug, ships the new code, I refresh the page and it's working... but it's not the color I wanted or whatever and I tell it to fix that and it goes and does it. On and on this goes for hours into the night.&lt;/p&gt;
    &lt;p&gt;With humans, normally I outline something I want built whether it's a feature or a new page for the website or a entire new app. Then the developer and I will kind of go back and forth over the details of the MVP version of it and what we should cut out considering the time/value trade off.&lt;/p&gt;
    &lt;p&gt;Then the developer will build it, but not the entire thing. We want to set milestones. That way I can see it as it gets built and give feedback which leads to many iterations, usually days or weeks apart, of each milestone until completion.&lt;/p&gt;
    &lt;p&gt;I learned how to build software like this the hard way...&lt;/p&gt;
    &lt;p&gt;By wasting a ton of time and money because I used to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Not work directly with the end developers&lt;/item&gt;
      &lt;item&gt;Not clearly communicate what I needed&lt;/item&gt;
      &lt;item&gt;Not consider time/value tradeoffs to cut the project or feature down to MVP&lt;/item&gt;
      &lt;item&gt;Wait until the entire project was completed before giving feedback and iterating&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I think these dev management skills I've built up along with the thin technical understanding of a lot of different programming topics over the years have made me uniquely capable of building things with the Cursor AI agent today.&lt;/p&gt;
    &lt;p&gt;I don't think just anyone can build anything right now.&lt;/p&gt;
    &lt;p&gt;I think I might have the contrarian take here - the bar to build is going to continue to get lowered but it will never be "easy" or "anyone can do it".&lt;/p&gt;
    &lt;p&gt;The code was actually never the hard part of most SaaS anyways.&lt;/p&gt;
    &lt;p&gt;If it was, every programmer would be a millionaire.&lt;/p&gt;
    &lt;p&gt;It's hard knowing what to build, in what order, and of course the most important part - getting customers.&lt;/p&gt;
    &lt;p&gt;But anyways back to Cursor.&lt;/p&gt;
    &lt;head rend="h3"&gt;Some of my more interesting conversations with Cursor&lt;/head&gt;
    &lt;p&gt;One of the biggest challenges was writing the hand history parser.&lt;/p&gt;
    &lt;p&gt;PokerStars exports hand history in text files like this:&lt;/p&gt;
    &lt;p&gt;It was very difficult to scrape all of this using regex into separate pieces of data to put into a database where hands can be sorted, summed, and analyzed.&lt;/p&gt;
    &lt;p&gt;Part of the problem was the AI's lack of understanding of the fundamentals of the game of poker.&lt;/p&gt;
    &lt;p&gt;Part of the problem was the amount of edge cases, or hands where something unusual or different happened of which only happened in a few hands.&lt;/p&gt;
    &lt;p&gt;My first goal was just to calculate the profit/loss total from all hands. This seemed fairly simple - find text like "reillychase collected $29.82 from pot" and add it up.&lt;/p&gt;
    &lt;p&gt;But actually wait, we need to also deduct the bets that I made from that pot.&lt;/p&gt;
    &lt;p&gt;But what is considered a bet?&lt;/p&gt;
    &lt;p&gt;If I'm the small or big blind there's different wording in the text file for that bet, there is also different language used for an all-in bet, a raise, a call. A bet was called many different things and they all needed to be added up so they could be deducted from the amount won in the pot.&lt;/p&gt;
    &lt;p&gt;There's also an edge case where I made a bet and someone went all-in so some of my bet was returned to me (the unmatched bet amount).&lt;/p&gt;
    &lt;p&gt;Or maybe there's an edge case where there were two winners and the pot was split.&lt;/p&gt;
    &lt;p&gt;As you can imagine the list goes on and on.&lt;/p&gt;
    &lt;p&gt;Instead of thinking through every edge case I told the AI "let's review some hands together - find me the biggest winners, the biggest losers, and some complicated hands and explain them to me"&lt;/p&gt;
    &lt;p&gt;It was able to find hands of those types, it showed me the text so I could add it up manually, and it showed me its own expected output along with the actual output.&lt;/p&gt;
    &lt;p&gt;Most of the time it was able to figure out on its own what had gone wrong because its expected output after reading the text file differed from the parsed output.&lt;/p&gt;
    &lt;p&gt;In other cases I had to explain to it something poker related to give it more context.&lt;/p&gt;
    &lt;p&gt;These are the kind of conversations we had over and over.&lt;/p&gt;
    &lt;p&gt;Again, this was just like working with a human programmer, although I will admit the AI was much dumber at times, but instead of days or weeks between iterations it was minutes.&lt;/p&gt;
    &lt;p&gt;One unlock I found, with the limited time I spent in actually exploring Cursor itself and not just plugging away at building with it, is changing from Auto to Claude 4.5 Sonnet Thinking as the agent.&lt;/p&gt;
    &lt;p&gt;The quality of the responses greatly improved in my experience and I plan on upgrading my subscription to pay on-demand to be able to continue to use it once my credits run out.&lt;/p&gt;
    &lt;head rend="h3"&gt;What it all means for the future&lt;/head&gt;
    &lt;p&gt;It's not really my thing to give too much thought about macro-trends that are out of my control or worry about what negative consequences they might have on my life.&lt;/p&gt;
    &lt;p&gt;The short answer, I really don't know what this means for the future of the career of programming, the business of software, or anything else.&lt;/p&gt;
    &lt;p&gt;Instead of worrying about that I'm going to try to focus on the here and now, the upside potential, and the unique set of advantages that I have available to me to build something valuable, have fun, and maybe profit.&lt;/p&gt;
    &lt;p&gt;I'm going to do what I enjoy doing, try to learn some new skills and create things.&lt;/p&gt;
    &lt;head rend="h3"&gt;Looking for input from you, the reader&lt;/head&gt;
    &lt;p&gt;If you play poker, let me know.&lt;/p&gt;
    &lt;p&gt;If you use Cursor or similar to build things, let me know.&lt;/p&gt;
    &lt;p&gt;I'm also looking for help on how to revamp the UX/design of poker.rchase.com using AI, it seems like Cursor is not strong in this area maybe there is an alternative I should be looking into?&lt;/p&gt;
    &lt;p&gt;Thank you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.rchase.com/i-played-1-000-hands-of-online-poker-and-built-a-web-app-with-cursor-ai/"/><published>2025-10-08T20:20:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45520615</id><title>Kurt Got Got</title><updated>2025-10-08T22:09:10.130713+00:00</updated><content>&lt;doc fingerprint="ee3b595b1b4777cd"&gt;
  &lt;main&gt;
    &lt;p&gt;The $FLY Airdrop is live! Claim your share of the token powering Fly.ioâs global network of 3M+ apps and (ð¤®) own a piece of the sky!&lt;/p&gt;
    &lt;p&gt;We know. Our Twitter got owned. We knew within moments of it happening. We know exactly how it happened. Nothing was at risk other than our Twitter account (and one Fly.io employee’s self-esteem). Also: for fuck’s sake.&lt;/p&gt;
    &lt;p&gt;Here’s what happened: Kurt Mackey, our intrepid CEO, got phished.&lt;/p&gt;
    &lt;p&gt;Had this been an impactful attack, we would not be this flippant about it. For this, though, any other tone on our part would be false.&lt;/p&gt;
    &lt;head rend="h2"&gt;How They Got Kurt&lt;/head&gt;
    &lt;p&gt;Two reasons: one, it was a pretty good phishing attack, and two, Twitter fell outside the “things we take seriously” boundary.&lt;/p&gt;
    &lt;p&gt;The phishing attack was effective because it exploited a deep psychological vulnerability in our management team: we are old and out of touch with the youths of today.&lt;/p&gt;
    &lt;p&gt;For many months now, we’ve had an contractor/intern-type-person Boosting Our Brand on Twitter by posting dank developer memes (I think that’s what they’re called). The thing about this dankery is that we don’t really understand it. I mean, hold on, we know what the memes mean technically. We just don’t get why they’re funny.&lt;/p&gt;
    &lt;p&gt;However, in pushing back on them, we’re up against two powerful forces:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The dank memes appear to perform better than the stuff we ourselves write on Twitter.&lt;/item&gt;
      &lt;item&gt;We are reliably informed by our zoomer children that we are too cringe to be trusted on these matters.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here’s the phish Kurt got:&lt;/p&gt;
    &lt;p&gt;Diabolical. Like a scalpel expertly wielded against Kurt’s deepest middle-aged-dude insecurity. Our ruthless attackers clinically designed this email to trigger an autonomic Kurt response: “oh, what the fuck is this, and why did we post it?”&lt;/p&gt;
    &lt;p&gt;ATO is cool-kid for âgot ownedâ&lt;/p&gt;
    &lt;p&gt;I’m getting a little ahead of the story here. We knew our X.com account had suffered an ATO because a bunch of us simultaneously got another email saying that the @flydotio account’s email address now pointed to &lt;code&gt;achilles19969@gmail.com&lt;/code&gt;. Our immediate response was to audit all accesses to the login information in 1Password, to cut all access for anybody who’d recently pulled it; your worst-case assumption in a situation like this is that someone’s endpoint has been owned up.&lt;/p&gt;
    &lt;p&gt;Fortunately, nobody lost access for very long. I called Kurt to let him know why he was being locked out, and 5 seconds later, he’d realized what had happened. Don’t click anything there.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why It Worked&lt;/head&gt;
    &lt;p&gt;That’s the right question to ask, isn’t it? How could this have been possible in the first place?&lt;/p&gt;
    &lt;p&gt;Contrary to one popular opinion, you don’t defeat phishing by training people not to click on things. I mean, tell them not to, sure! But eventually, under continued pressure, everybody clicks. There’s science on this. The cool kids haven’t done phishing simulation training in years.&lt;/p&gt;
    &lt;p&gt;What you’re supposed to do instead is use phishing-resistant authentication. This is almost the whole backstory for U2F, FIDO2 and Passkeys.&lt;/p&gt;
    &lt;p&gt;Phishing-resistant authentication works by mutual authentication (or, if you’re a stickler, by origin- and channel-binding). Phishes are malicious proxies for credentials. Modern MFA schemes like FIDO2 break that proxy flow; your browser won’t send real credentials to the fake site.&lt;/p&gt;
    &lt;p&gt;thereâs more to it than this, but, broad strokes.&lt;/p&gt;
    &lt;p&gt;This is, in fact, how all of our infrastructure is secured at Fly.io; specifically, we get everything behind an IdP (in our case: Google’s) and have it require phishing-proof MFA. You’re unlikely to phish your way to viewing logs here, or to refunding a customer bill at Stripe, or to viewing infra metrics, because all these things require an SSO login through Google.&lt;/p&gt;
    &lt;p&gt;Twitter, on the other hand. Yeah, so, about that. You may have heard that, a few years back, there were some goings-on involving Twitter. Many of us at Fly.io decamped for Mastodon, and later to Bluesky. There was a window of time in 2023-2024 where it looked as if Twitter might not be a long term thing for us at all.&lt;/p&gt;
    &lt;p&gt;â (to whom I sincerely apologize for having assumed they had been owned up and were the proximate cause of the hack)&lt;/p&gt;
    &lt;p&gt;As a result, Twitter had been a sort of legacy shared account for us, with credentials managed in 1Password and shared with our zoomer contractorâ .&lt;/p&gt;
    &lt;p&gt;Which is why Kurt was in a position to pull credentials from 1Password and log in to members-x.com in response to an email from alerts-x.com.&lt;/p&gt;
    &lt;p&gt;Still: we could have dodged this attack with hygiene: Kurt complains that âx.comâ is an extremely phishable domain, and, sure, but also: the 1Password browser plugin would have noticed that âmembers-x.comâ wasnât an âx.comâ host.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Took So Long&lt;/head&gt;
    &lt;p&gt;The attacker immediately revoked all tokens and set up new 2FA, so while we were quickly able to reset our password, we couldn’t lock them out of our account without an intervention from X.com, which took something like 1 5 hours to set up.&lt;/p&gt;
    &lt;p&gt;(That’s not a knock on X.com; 15 hours for a 2FA reset isn’t outside industry norms).&lt;/p&gt;
    &lt;p&gt;We’re obviously making a lot of noise about this now, but we were pretty quiet during the incident itself (beyond just “We know. We knew 45 seconds after it happened. We know exactly how it happened. It’s just a Twitter thing.”)&lt;/p&gt;
    &lt;p&gt;That’s because, in the grand scheme of things, the attack was pretty chill: a not-very-plausible crypto scam that presumably generated $0 for the attackers, 15+ hours of &lt;code&gt;brand damage&lt;/code&gt;, and extra security engineering cycles burnt on watchful waiting. Our users weren’t under attack, and the account wasn’t being used to further intercept customer accounts. At one point, the attackers apparently deleted our whole Twitter history, which, like, don’t threaten us with a good time. So we let it roll, until we got our account recovered the next morning.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Moral Of The Story Is&lt;/head&gt;
    &lt;p&gt;âReally the biggest takeaway for me is that Kurt reads his email.â&lt;/p&gt;
    &lt;p&gt;Obviously Kurt loses his commit access. The time comes in the life of every CEO, and now it comes for him.&lt;/p&gt;
    &lt;p&gt;Also, we’ll finally have a population sample for “incident response” in our next SOC2.&lt;/p&gt;
    &lt;p&gt;Maybe we’ll post more on Twitter. Or maybe we’ll double down on Zoomer memes. I don’t know. Social media is really weird right now. Either way: our Twitter access is Passkeys now.&lt;/p&gt;
    &lt;p&gt;seriously donât click anything on that page&lt;/p&gt;
    &lt;p&gt;If you were inclined to take us up on an “airdrop” to “claim a share” of the “token” powering Fly.io, the site is still up. You can connect your wallet it it! You’ll lose all your money. But if we’d actually done an ICO, you’d have lost all your money anyways.&lt;/p&gt;
    &lt;p&gt;Somebody involved in pulling this attack off had to come up with “own a piece of the sky!”, and I think that’s punishment enough for them.&lt;/p&gt;
    &lt;p&gt;Whatever you’re operating that isn’t behind phishing-resistant MFA, or, better yet, an SSO IdP that requires phishing-resistant MFA: that thing is eventually going to get phished. Dance around the clown-fire of our misfortune if you must, but let us be a lesson to you as well.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fly.io/blog/kurt-got-got/"/><published>2025-10-08T21:02:34+00:00</published></entry></feed>