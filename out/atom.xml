<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-19T12:20:28.463305+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45963780</id><title>Cloudflare Global Network experiencing issues</title><updated>2025-11-19T12:20:35.103442+00:00</updated><content>&lt;doc fingerprint="40d4ee565e054cd0"&gt;
  &lt;main&gt;
    &lt;p&gt;Cloudflare services are currently operating normally. We are no longer observing elevated errors or latency across the network.&lt;/p&gt;
    &lt;p&gt;Our engineering teams continue to closely monitor the platform and perform a deeper investigation into the earlier disruption, but no configuration changes are being made at this time.&lt;/p&gt;
    &lt;p&gt;At this point, it is considered safe to re-enable any Cloudflare services that were temporarily disabled during the incident. We will provide a final update once our investigation is complete.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 17:44 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We continue to monitor the system through recovery and we are seeing errors and latency return to normal levels. A full post-incident investigation and details about the incident will be made available asap.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 17:14 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We continue to see errors drop as we work through services globally and clearing remaining errors and latency.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 16:46 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We continue to see errors and latency improve but still have reports of intermittent errors. The team continues to monitor the situation as it improves, and looking for ways to accelerate full recovery.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 16:27 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Bot scores will be impacted intermittently while we undergo global recovery. We will update once we believe bot scores are fully recovered.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 16:04 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;The team is continuing to focus on restoring service post-fix. We are mitigating several issues that remain post-deployment.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 15:40 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are continuing to monitor for any further issues.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 15:23 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Some customers may be still experiencing issues logging into or using the Cloudflare dashboard. We are working on a fix to resolve this, and continuing to monitor for any further issues.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 14:57 UTC&lt;/p&gt;
    &lt;p&gt;Monitoring&lt;/p&gt;
    &lt;p&gt;A fix has been implemented and we believe the incident is now resolved. We are continuing to monitor for errors to ensure all services are back to normal.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 14:42 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We've deployed a change which has restored dashboard services. We are still working to remediate broad application services impact&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 14:34 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are continuing to work on a fix for this issue.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 14:22 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are continuing working on restoring service for application services customers.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 13:58 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are continuing working on restoring service for application services customers.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 13:35 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We have made changes that have allowed Cloudflare Access and WARP to recover. Error levels for Access and WARP users have returned to pre-incident rates. We have re-enabled WARP access in London.&lt;/p&gt;
    &lt;p&gt;We are continuing to work towards restoring other services.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 13:13 UTC&lt;/p&gt;
    &lt;p&gt;Identified&lt;/p&gt;
    &lt;p&gt;The issue has been identified and a fix is being implemented.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 13:09 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;During our attempts to remediate, we have disabled WARP access in London. Users in London trying to access the Internet via WARP will see a failure to connect.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 13:04 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are continuing to investigate this issue.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 12:53 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are continuing to investigate this issue.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 12:37 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are seeing services recover, but customers may continue to observe higher-than-normal error rates as we continue remediation efforts.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 12:21 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are continuing to investigate this issue.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 12:03 UTC&lt;/p&gt;
    &lt;p&gt;Investigating&lt;/p&gt;
    &lt;p&gt;Cloudflare is experiencing an internal service degradation. Some services may be intermittently impacted. We are focused on restoring service. We will update as we are able to remediate. More updates to follow shortly.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 11:48 UTC&lt;/p&gt;
    &lt;p&gt;This incident affected: Cloudflare Sites and Services (Access, Bot Management, CDN/Cache, Dashboard, Firewall, Network, WARP, Workers).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cloudflarestatus.com/incidents/8gmgl950y3h7"/><published>2025-11-18T11:35:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45966251</id><title>Nearly all UK drivers say headlights are too bright</title><updated>2025-11-19T12:20:34.938135+00:00</updated><content>&lt;doc fingerprint="24df8d635d03762d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nearly all drivers say headlights are too bright&lt;/head&gt;
    &lt;p&gt;Nearly all UK drivers said they thought headlights were too bright and that they have been dazzled by oncoming vehicles, according to a major study.&lt;/p&gt;
    &lt;p&gt;The government said last week that it will take a closer look at the design of cars and headlamps after concerns about lights dazzling drivers.&lt;/p&gt;
    &lt;p&gt;A study commissioned by the Department for Transport (DfT) found 97% of people surveyed found they were regularly or sometimes distracted by oncoming vehicles and 96% thought most or some headlights were too bright.&lt;/p&gt;
    &lt;p&gt;Dr Shaun Helman, who led the research for Berkshire-based Transport Research Laboratory (TRL), said it provides "compelling evidence" that lights' glare is a "genuine issue for UK drivers".&lt;/p&gt;
    &lt;p&gt;New measures will be included in the government's upcoming Road Safety Strategy, reflecting what is becoming an increasingly fraught issue for road users.&lt;/p&gt;
    &lt;p&gt;TRL's data suggests that LED and whiter headlamps may be linked to glare and that drivers might find their whiteness harder to cope with.&lt;/p&gt;
    &lt;p&gt;Of those surveyed, 33% said they had either stopped driving or are driving less at night because of lights, while another 22% said they would like to drive less at night but have no choice.&lt;/p&gt;
    &lt;p&gt;A total of 1,850 drivers, matched to the age and gender split of the country's licence holding population, were surveyed for their views.&lt;/p&gt;
    &lt;p&gt;TRL said LED lights used in vehicles are brighter, more concentrated and emit more blue light, which human eyes struggle with more at night.&lt;/p&gt;
    &lt;p&gt;The RAC's senior policy officer Rod Dennis said: "Having campaigned hard for this study, we welcome its findings which independently confirm what drivers have been telling us – that rather than being an imagined phenomenon, some bright headlights do cause a glare problem.&lt;/p&gt;
    &lt;p&gt;"While drivers clearly benefit from high-performing headlights, it's important this doesn't lead to others suffering the effects of dazzle, so a balance needs to be struck," he added.&lt;/p&gt;
    &lt;p&gt;Mr Dennis said that it is "vital" TRL's report is "reviewed carefully to put us on a path towards changes that ultimately benefit all road users."&lt;/p&gt;
    &lt;p&gt;Denise Voon, a clinical advisor at The College of Optometrists, said the DfT should "take immediate, actionable steps to support drivers and commission more detailed research, specifically into how headlight regulations need to change".&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/c1j8ewy1p86o"/><published>2025-11-18T14:11:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45966435</id><title>Short Little Difficult Books</title><updated>2025-11-19T12:20:34.844699+00:00</updated><content/><link href="https://countercraft.substack.com/p/short-little-difficult-books"/><published>2025-11-18T14:23:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45967079</id><title>Show HN: Browser-based interactive 3D Three-Body problem simulator</title><updated>2025-11-19T12:20:34.608867+00:00</updated><content>&lt;doc fingerprint="1b8cc1fe919783ba"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;About the N-Body Simulator&lt;/head&gt;
    &lt;head rend="h3"&gt;What is the Three-Body Problem?&lt;/head&gt;
    &lt;p&gt;The three-body problem is one of the most famous challenges in classical physics and celestial mechanics. It asks: given the initial positions, masses, and velocities of three bodies in space, can we predict their future motion under mutual gravitational attraction?&lt;/p&gt;
    &lt;p&gt;Unlike the two-body problem (which has an exact analytical solution), the three-body problem has no general closed-form solution. This makes numerical simulation the primary tool for studying these complex gravitational systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;N-Body Gravitational Simulation&lt;/head&gt;
    &lt;p&gt;This simulator uses Newton's law of universal gravitation to model the gravitational forces between every pair of bodies:&lt;/p&gt;
    &lt;p&gt;F = G × m₁ × m₂ / (r² + ε²)&lt;/p&gt;
    &lt;p&gt;Each body experiences the sum of all pairwise gravitational forces from every other body. For N bodies, this requires calculating N(N-1)/2 force pairs each timestep. The ε² term is a softening parameter that prevents numerical singularities when bodies pass very close together.&lt;/p&gt;
    &lt;p&gt;The simulation supports multiple integration methods. By default, it uses the Velocity Verlet integration method, a symplectic integrator that provides superior energy conservation compared to simpler methods like Euler integration. This makes it ideal for long-term orbital mechanics simulations.&lt;/p&gt;
    &lt;p&gt;Users can switch to the 4th-order Runge-Kutta (RK4) method in the Advanced Settings, which offers higher accuracy per timestep and typically shows lower energy drift in short simulations. However, RK4 is not symplectic and accumulates systematic phase errors over long simulation times, causing orbits to gradually decay or expand. This makes RK4 better suited for short to medium duration simulations where minimizing instantaneous error is the priority, while Verlet excels at maintaining correct orbital shapes over extended periods.&lt;/p&gt;
    &lt;head rend="h3"&gt;Preset Configurations&lt;/head&gt;
    &lt;p&gt;The simulator includes several famous periodic three-body orbits discovered through numerical searches:&lt;/p&gt;
    &lt;head rend="h4"&gt;2D Orbits&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Figure-8 choreography: Discovered by Cris Moore in 1993, where three equal masses chase each other along a figure-eight shaped path&lt;/item&gt;
      &lt;item&gt;Lagrange triangular configuration: Equilateral triangle configuration with circular orbits.&lt;/item&gt;
      &lt;item&gt;Butterfly, Broucke, Hénon, and Yarn: Periodic orbits from the Šuvakov-Dmitrašinović database of three-body choreographies, discovered through systematic numerical exploration of initial conditions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;3D Orbits&lt;/head&gt;
    &lt;p&gt;Three-dimensional periodic orbits from Li and Liao (2025), which discovered 10,059 new periodic solutions including 21 choreographic orbits and 273 "piano-trio" orbits (where two equal-mass bodies share one orbit while a third body follows another). Paper | GitHub&lt;/p&gt;
    &lt;head rend="h3"&gt;Features &amp;amp; Applications&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time Physics: Experience gravitational dynamics in 3D with interactive controls&lt;/item&gt;
      &lt;item&gt;Multiple Integration Methods: Choose between Velocity Verlet (energy-conserving) and RK4 (high accuracy).&lt;/item&gt;
      &lt;item&gt;Exploration Platform: Experiment with different initial conditions and masses&lt;/item&gt;
      &lt;item&gt;Timeline Playback: Scrub through simulation history to analyze orbital behavior&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;How to Use&lt;/head&gt;
    &lt;p&gt;Getting Started: Use the preset configurations (Figure-8 or Lagrange) to see stable three-body orbits, or generate random initial conditions to explore chaotic dynamics.&lt;/p&gt;
    &lt;p&gt;Controls: Adjust body masses, simulation speed, and physics parameters. Use the timeline to review and analyze orbital patterns. Drag bodies while paused to create custom configurations.&lt;/p&gt;
    &lt;p&gt;Sharing: Click "Share Configuration" to generate a URL that preserves your exact simulation initial state.&lt;/p&gt;
    &lt;head rend="h3"&gt;Energy Conservation &amp;amp; Simulation Accuracy&lt;/head&gt;
    &lt;p&gt;The simulator displays two important energy metrics in the Advanced Settings panel:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Total Energy: The sum of kinetic energy (½mv²) and gravitational potential energy (-Gm₁m₂/r) of all bodies. In an ideal gravitational system, this value should remain constant over time.&lt;/item&gt;
      &lt;item&gt;Energy Drift: The percentage change in total energy from the initial state. This measures the numerical accuracy of the simulation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In real physics, energy is conserved in isolated systems. However, numerical integration methods introduce small errors at each timestep. The energy drift indicator helps you evaluate simulation quality:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Green (&amp;lt;1%): Excellent energy conservation - the simulation is highly accurate&lt;/item&gt;
      &lt;item&gt;Yellow (1-5%): Moderate drift - acceptable for most purposes but consider reducing timestep&lt;/item&gt;
      &lt;item&gt;Red (&amp;gt;5%): Significant drift - simulation may be unreliable, reduce timestep or try other integration methods&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Velocity Verlet integration method is "symplectic," meaning it preserves the phase-space structure of Hamiltonian systems. While RK4 typically shows lower energy drift in short-term simulations (better local accuracy), Verlet prevents systematic phase errors that accumulate over extended simulations. This makes Verlet ideal for long-term orbital mechanics where maintaining orbital stability over thousands of periods is more important than minimizing instantaneous error.&lt;/p&gt;
    &lt;p&gt;Why is Total Energy Negative? In gravitational systems, total energy is often negative, and this is perfectly normal! Gravitational potential energy is defined as zero at infinite separation and becomes increasingly negative as bodies move closer together (PE = -Gm₁m₂/r). When total energy is negative, it means the system is gravitationally bound - the bodies don't have enough kinetic energy to escape to infinity, so they remain in orbit. This is exactly what you see in stable orbital systems like planets around stars or the choreographed orbits in this simulator. A negative total energy that remains constant indicates a stable, bound orbital system.&lt;/p&gt;
    &lt;head rend="h3"&gt;Technical Details&lt;/head&gt;
    &lt;p&gt;Built with Three.js for WebGL-accelerated 3D graphics and modern JavaScript. The physics engine implements N-body gravitational calculations with a configurable softening parameter to prevent numerical singularities during close encounters.&lt;/p&gt;
    &lt;p&gt;The simulator tracks up to 10,000 frames of history, allowing you to review and analyze the evolution of complex orbital systems. All simulations are deterministic and reproducible.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feedback&lt;/head&gt;
    &lt;p&gt;Have suggestions, found a bug, or want to share your thoughts? Give feedback and help improve this simulator!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://trisolarchaos.com/?pr=O_8(0.6)&amp;n=3&amp;s=5.0&amp;so=0.00&amp;im=rk4&amp;dt=1.00e-4&amp;rt=1.0e-6&amp;at=1.0e-8&amp;bs=0.15&amp;sf=0&amp;sv=0&amp;cm=free&amp;kt=1&amp;st=1&amp;tl=1500&amp;cp=2.5208,1.5125,2.5208&amp;ct=0.0000,0.0000,0.1670"/><published>2025-11-18T15:00:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45967211</id><title>Gemini 3</title><updated>2025-11-19T12:20:34.339738+00:00</updated><content>&lt;doc fingerprint="f9d7a1cf9b3f9a95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A new era of intelligence with Gemini 3&lt;/head&gt;
    &lt;head rend="h3"&gt;A note from Google and Alphabet CEO Sundar Pichai:&lt;/head&gt;
    &lt;p&gt;Nearly two years ago we kicked off the Gemini era, one of our biggest scientific and product endeavors ever undertaken as a company. Since then, it’s been incredible to see how much people love it. AI Overviews now have 2 billion users every month. The Gemini app surpasses 650 million users per month, more than 70% of our Cloud customers use our AI, 13 million developers have built with our generative models, and that is just a snippet of the impact we’re seeing.&lt;/p&gt;
    &lt;p&gt;And we’re able to get advanced capabilities to the world faster than ever, thanks to our differentiated full stack approach to AI innovation — from our leading infrastructure to our world-class research and models and tooling, to products that reach billions of people around the world.&lt;/p&gt;
    &lt;p&gt;Every generation of Gemini has built on the last, enabling you to do more. Gemini 1’s breakthroughs in native multimodality and long context window expanded the kinds of information that could be processed — and how much of it. Gemini 2 laid the foundation for agentic capabilities and pushed the frontiers on reasoning and thinking, helping with more complex tasks and ideas, leading to Gemini 2.5 Pro topping LMArena for over six months.&lt;/p&gt;
    &lt;p&gt;And now we’re introducing Gemini 3, our most intelligent model, that combines all of Gemini’s capabilities together so you can bring any idea to life.&lt;/p&gt;
    &lt;p&gt;It’s state-of-the-art in reasoning, built to grasp depth and nuance — whether it’s perceiving the subtle clues in a creative idea, or peeling apart the overlapping layers of a difficult problem. Gemini 3 is also much better at figuring out the context and intent behind your request, so you get what you need with less prompting. It’s amazing to think that in just two years, AI has evolved from simply reading text and images to reading the room.&lt;/p&gt;
    &lt;p&gt;And starting today, we’re shipping Gemini at the scale of Google. That includes Gemini 3 in AI Mode in Search with more complex reasoning and new dynamic experiences. This is the first time we are shipping Gemini in Search on day one. Gemini 3 is also coming today to the Gemini app, to developers in AI Studio and Vertex AI, and in our new agentic development platform, Google Antigravity — more below.&lt;/p&gt;
    &lt;p&gt;Like the generations before it, Gemini 3 is once again advancing the state of the art. In this new chapter, we’ll continue to push the frontiers of intelligence, agents, and personalization to make AI truly helpful for everyone.&lt;/p&gt;
    &lt;p&gt;We hope you like Gemini 3, we'll keep improving it, and look forward to seeing what you build with it. Much more to come!&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing Gemini 3: our most intelligent model that helps you bring any idea to life&lt;/head&gt;
    &lt;p&gt;Demis Hassabis, CEO of Google DeepMind and Koray Kavukcuoglu, CTO of Google DeepMind and Chief AI Architect, Google, on behalf of the Gemini team&lt;/p&gt;
    &lt;p&gt;Today we’re taking another big step on the path toward AGI and releasing Gemini 3.&lt;/p&gt;
    &lt;p&gt;It’s the best model in the world for multimodal understanding and our most powerful agentic and vibe coding model yet, delivering richer visualizations and deeper interactivity — all built on a foundation of state-of-the-art reasoning.&lt;/p&gt;
    &lt;p&gt;We’re beginning the Gemini 3 era by releasing Gemini 3 Pro in preview and making it available today across a suite of Google products so you can use it in your daily life to learn, build and plan anything. We’re also introducing Gemini 3 Deep Think — our enhanced reasoning mode that pushes Gemini 3 performance even further — and giving access to safety testers before making it available to Google AI Ultra subscribers.&lt;/p&gt;
    &lt;head rend="h2"&gt;State-of-the-art reasoning with unprecedented depth and nuance&lt;/head&gt;
    &lt;p&gt;Gemini 3 Pro can bring any idea to life with its state-of-the-art reasoning and multimodal capabilities. It significantly outperforms 2.5 Pro on every major AI benchmark.&lt;/p&gt;
    &lt;p&gt;It tops the LMArena Leaderboard with a breakthrough score of 1501 Elo. It demonstrates PhD-level reasoning with top scores on Humanity’s Last Exam (37.5% without the usage of any tools) and GPQA Diamond (91.9%). It also sets a new standard for frontier models in mathematics, achieving a new state-of-the-art of 23.4% on MathArena Apex.&lt;/p&gt;
    &lt;p&gt;Beyond text, Gemini 3 Pro redefines multimodal reasoning with 81% on MMMU-Pro and 87.6% on Video-MMMU. It also scores a state-of-the-art 72.1% on SimpleQA Verified, showing great progress on factual accuracy. This means Gemini 3 Pro is highly capable at solving complex problems across a vast array of topics like science and mathematics with a high degree of reliability.&lt;/p&gt;
    &lt;p&gt;Gemini 3 is state-of-the-art across a range of key AI benchmarks. See details on our evaluation methodology.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro also brings a new level of depth and nuance to every interaction. Its responses are smart, concise and direct, trading cliché and flattery for genuine insight — telling you what you need to hear, not just what you want to hear. It acts as a true thought partner that gives you new ways to understand information and express yourself, from translating dense scientific concepts by generating code for high-fidelity visualizations to creative brainstorming.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can code a visualization of plasma flow in a tokamak and write a poem capturing the physics of fusion.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gemini 3 Deep Think&lt;/head&gt;
    &lt;p&gt;Gemini 3 Deep Think mode pushes the boundaries of intelligence even further, delivering a step-change in Gemini 3’s reasoning and multimodal understanding capabilities to help you solve even more complex problems.&lt;/p&gt;
    &lt;p&gt;In testing, Gemini 3 Deep Think outperforms Gemini 3 Pro’s already impressive performance on Humanity’s Last Exam (41.0% without the use of tools) and GPQA Diamond (93.8%). It also achieves an unprecedented 45.1% on ARC-AGI-2 (with code execution, ARC Prize Verified), demonstrating its ability to solve novel challenges.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Deep Think mode excels on some of the most challenging AI benchmarks. See details on our evaluation methodology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gemini 3 helps you learn, build and plan anything&lt;/head&gt;
    &lt;head rend="h3"&gt;Learn anything&lt;/head&gt;
    &lt;p&gt;Gemini was built from the start to seamlessly synthesize information about any topic across multiple modalities, including text, images, video, audio and code. Gemini 3 pushes the frontier of multimodal reasoning to help you learn in ways that make sense for you by combining its state-of-the-art reasoning, vision and spatial understanding, leading multilingual performance, and 1 million-token context window.&lt;/p&gt;
    &lt;p&gt;For example, if you want to learn how to cook in your family tradition, Gemini 3 can decipher and translate handwritten recipes in different languages into a shareable family cookbook. Or if you want to learn about a new topic, you can give it academic papers, long video lectures or tutorials and it can generate code for interactive flashcards, visualizations or other formats that will help you master the material. It can even analyze videos of your pickleball match, identify areas where you can improve and generate a training plan for overall form improvements.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can help you learn and preserve family cooking traditions. Try it in Gemini Canvas.&lt;/p&gt;
    &lt;p&gt;Gemini 3 can help you analyze complex information like research papers and can generate code for an interactive guide.&lt;/p&gt;
    &lt;p&gt;Get expert-level sports analysis on your pickleball match to help improve your game.&lt;/p&gt;
    &lt;p&gt;To help you make better sense of information on the web, AI Mode in Search now uses Gemini 3 to enable new generative UI experiences like immersive visual layouts and interactive tools and simulations, all generated completely on the fly based on your query.&lt;/p&gt;
    &lt;p&gt;Learn a complex topic like how RNA polymerase works with generative UI in AI Mode in Search.&lt;/p&gt;
    &lt;head rend="h3"&gt;Build anything&lt;/head&gt;
    &lt;p&gt;Building on the success of 2.5 Pro, Gemini 3 delivers on the promise of bringing any idea to life for developers. It’s exceptional at zero-shot generation and handles complex prompts and instructions to render richer, more interactive web UI.&lt;/p&gt;
    &lt;p&gt;Gemini 3 is the best vibe coding and agentic coding model we’ve ever built – making our products more autonomous and boosting developer productivity. It tops the WebDev Arena leaderboard by scoring an impressive 1487 Elo. It also scores 54.2% on Terminal-Bench 2.0, which tests a model’s tool use ability to operate a computer via terminal and it greatly outperforms 2.5 Pro on SWE-bench Verified (76.2%), a benchmark that measures coding agents.&lt;/p&gt;
    &lt;p&gt;You can now build with Gemini 3 in Google AI Studio, Vertex AI, Gemini CLI and our new agentic development platform, Google Antigravity. It’s also available in third-party platforms like Cursor, GitHub, JetBrains, Manus, Replit and more.&lt;/p&gt;
    &lt;p&gt;Code a retro 3D spaceship game with richer visualizations and improved interactivity. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;Bring your imagination to life by building, deconstructing and remixing detailed 3D voxel art using code. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;Build a playable sci-fi world with shaders using Gemini 3. Try it in AI Studio.&lt;/p&gt;
    &lt;p&gt;You can vibe code richer, more interactive web UI and apps with Gemini 3.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introducing a new agent-first development experience&lt;/head&gt;
    &lt;p&gt;As model intelligence accelerates with Gemini 3, we have the opportunity to reimagine the entire developer experience. Today we’re releasing Google Antigravity, our new agentic development platform that enables developers to operate at a higher, task-oriented level.&lt;/p&gt;
    &lt;p&gt;Using Gemini 3’s advanced reasoning, tool use and agentic coding capabilities, Google Antigravity transforms AI assistance from a tool in a developer’s toolkit into an active partner. While the core of Google Antigravity is a familiar AI IDE experience, its agents have been elevated to a dedicated surface and given direct access to the editor, terminal and browser. Now, agents can autonomously plan and execute complex, end-to-end software tasks simultaneously on your behalf while validating their own code.&lt;/p&gt;
    &lt;p&gt;In addition to Gemini 3 Pro, Google Antigravity also comes tightly coupled with our latest Gemini 2.5 Computer Use model for browser control and our top-rated image editing model Nano Banana (Gemini 2.5 Image).&lt;/p&gt;
    &lt;p&gt;Google Antigravity uses Gemini 3 to drive an end-to-end agentic workflow for a flight tracker app. The agent independently plans, codes the application and validates its execution through browser-based computer use.&lt;/p&gt;
    &lt;head rend="h3"&gt;Plan anything&lt;/head&gt;
    &lt;p&gt;Since introducing the agentic era with Gemini 2, we’ve made a lot of progress, not only advancing Gemini’s coding agent abilities, but also improving its ability to reliably plan ahead over longer horizons. Gemini 3 demonstrates this by topping the leaderboard on Vending-Bench 2, which tests longer horizon planning by managing a simulated vending machine business. Gemini 3 Pro maintains consistent tool usage and decision-making for a full simulated year of operation, driving higher returns without drifting off task.&lt;/p&gt;
    &lt;p&gt;Gemini 3 Pro demonstrates better long-horizon planning to generate significantly higher returns compared to other frontier models.&lt;/p&gt;
    &lt;p&gt;This means Gemini 3 can better help you get things done in everyday life. By combining deeper reasoning with improved, more consistent tool use, Gemini 3 can take action on your behalf by navigating more complex, multi-step workflows from start to finish — like booking local services or organizing your inbox — all while under your control and guidance.&lt;/p&gt;
    &lt;p&gt;Google AI Ultra subscribers can try these agentic capabilities in the Gemini app with Gemini Agent today. We’ve learned a lot improving Gemini’s agentic capabilities, and we’re excited to see how you use it as we expand to more Google products soon.&lt;/p&gt;
    &lt;p&gt;Gemini Agent can help you organize your Gmail inbox. Try it now in the Gemini app for Google AI Ultra subscribers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building Gemini 3 responsibly&lt;/head&gt;
    &lt;p&gt;Gemini 3 is our most secure model yet, and has undergone the most comprehensive set of safety evaluations of any Google AI model to date. The model shows reduced sycophancy, increased resistance to prompt injections and improved protection against misuse via cyberattacks.&lt;/p&gt;
    &lt;p&gt;In addition to our in-house testing for the critical domains in our Frontier Safety Framework, we've also partnered on evaluations with world-leading subject matter experts, provided early access to bodies like the UK AISI, and obtained independent assessments from industry experts like Apollo, Vaultis, Dreadnode and more. For more information, see the Gemini 3 model card.&lt;/p&gt;
    &lt;head rend="h2"&gt;The next era of Gemini&lt;/head&gt;
    &lt;p&gt;This is just the start of the Gemini 3 era. As of today, Gemini 3 starts rolling out:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For everyone in the Gemini app and for Google AI Pro and Ultra subscribers in AI Mode in Search&lt;/item&gt;
      &lt;item&gt;For developers in the Gemini API in AI Studio, our new agentic development platform, Google Antigravity; and Gemini CLI&lt;/item&gt;
      &lt;item&gt;For enterprises in Vertex AI and Gemini Enterprise&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For Gemini 3 Deep Think mode, we’re taking extra time for safety evaluations and input from safety testers before making it available to Google AI Ultra subscribers in the coming weeks.&lt;/p&gt;
    &lt;p&gt;We plan to release additional models to the Gemini 3 series soon so you can do more with AI. We look forward to getting your feedback and seeing what you learn, build and plan with Gemini.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/products/gemini/gemini-3/"/><published>2025-11-18T15:09:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45967814</id><title>Google Antigravity</title><updated>2025-11-19T12:20:34.183011+00:00</updated><link href="https://antigravity.google/"/><published>2025-11-18T15:47:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45968121</id><title>The code and open-source tools I used to produce a science fiction anthology</title><updated>2025-11-19T12:20:33.958156+00:00</updated><content>&lt;doc fingerprint="2fc09a362ef7ad11"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;&lt;p&gt; Last month I published &lt;/p&gt;Think Weirder: The Year's Best Science Fiction Ideas&lt;p&gt;, a 16-story anthology featuring Greg Egan, Isabel J. Kim, Ray Nayler, Caroline M. Yoachim, and twelve other wonderful authors. The book ended up being the #1 New Release in the Short Stories Anthologies category for a short time on Amazon, outselling many other newly released short story anthologies published by the big NYC publishers with large marketing departments. &lt;/p&gt;&lt;/div&gt;
      &lt;p&gt; I'm not a professional publisher. I have a full-time job and two small kids, so all of this work happened after my kids went to sleep. I had to use my time judiciously, which meant creating an efficient process. Fortunately I'm a programmer, and it turns out that programming skills translate surprisingly well to book publishing. This post is about how I built a complete publishing pipeline using Python, YAML files, and LaTeX â and why you might want to do something similar if you're considering publishing a book. I know that by writing this I'll have my choices questioned by professional designers, but hopefully the software concepts will be helpful. &lt;/p&gt;
      &lt;p&gt; My initial thought: can I really do ALL of this? &lt;/p&gt;
      &lt;p&gt; When I started this project, I had some worries. Professional publishers have entire departments of specialists. How could I possibly handle all of that myself? &lt;/p&gt;
      &lt;p&gt; The answer turned out to be: build tools that automate the repetitive parts, and use simple file formats that make everything transparent and debuggable. &lt;/p&gt;
      &lt;p&gt; Step 1: Tracking stories with plain text files &lt;/p&gt;
      &lt;p&gt; The first challenge was tracking hundreds of candidate stories from different magazines. I read 391 stories published in 2024 before selecting the final 16. That's a lot of stories to keep organized. &lt;/p&gt;
      &lt;p&gt; I could have used a spreadsheet, but I went with plain YAML files instead. Here's why this worked well for me: &lt;/p&gt;
      &lt;div&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Git-friendly: Every decision I made was tracked in version control&lt;/item&gt;
          &lt;item&gt;Human-readable: I could open any file in a text editor and understand what I was looking at&lt;/item&gt;
          &lt;item&gt;Easy to build scripts around: I wrote several Python functions to do different kinds of metadata introspection that I'll go through&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
      &lt;p&gt; The structure looks like this: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;data/
  story-progress.yaml       # Central tracking file
  markets.yaml              # Magazine metadata
  themes.yaml               # Theme occurrence tracking
  subgenres.yaml            # Subgenre tallies
stories/
  clarkesworld-magazine/
    nelson_11_24.yaml       # Individual story files
    pak_06_24.yaml
  reactor-magazine/
    larson_breathing.yaml
  ...&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Each story file is pure YAML containing the full story text plus metadata: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;title: "Twenty-Four Hours"
author: H.H. Pak
market: clarkesworld-magazine
url: https://clarkesworldmagazine.com/pak_06_24/
word_count: 4540
year: 2024
slug: pak_06_24
summary: ...&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Not all stories have public URLs available, but that's OK because all of the fields are optional. The central &lt;code&gt;story-progress.yaml&lt;/code&gt; tracks editorial state:
&lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;clarkesworld-magazine-nelson_11_24:
  title: "LuvHomeâ¢"
  author: Resa Nelson
  market: clarkesworld-magazine
  status: accepted  # or: not_started/relevant/rejected
  date_added: '2024-09-08T08:22:47.033192'&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Step 2: A simple command-line tool &lt;/p&gt;
      &lt;p&gt; I built a small Python CLI tool (&lt;code&gt;se.py&lt;/code&gt;) to help me navigate all this data. Since I do all this work at night after my kids go to sleep, I wanted something fast that mirrored a lot of the other work I do on the command line. The tool is simple:
&lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;python se.py âhelp
usage: se.py [-h] {markets,stories,relevant,decide,accepted,compile} ...

Story Evaluator CLI

positional arguments:
  {markets,stories,relevant,decide,accepted,compile}
                        Available commands
    markets             List markets
    stories             Manage stories
    relevant            List URLs for stories marked as relevant
    decide              Make accept/reject decisions on relevant stories
    accepted            Manage accepted stories
    compile             Show anthology compilation statistics

optional arguments:
  -h, âhelp            show this help message and exit&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; The &lt;code&gt;compile&lt;/code&gt; command ended up being really useful â it gave me instant feedback on anthology size and composition:
&lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;ANTHOLOGY COMPILATION STATISTICS
============================================================
Total Stories: 16
Total Word Count: 115,093 words
Average Word Count: 7,193 words
Unique Authors: 16
Markets Represented: 4

STORIES BY MARKET:
  analog-magazine: 2 stories (12.5%)
  asimovs-magazine: 2 stories (12.5%)
  clarkesworld-magazine: 10 stories (62.5%)
  reactor-magazine: 2 stories (12.5%)&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; This was really helpful during the selection process. I could quickly check how far along I was toward my ~120k word goal, and make sure I hadn't accidentally included multiple stories by the same author. &lt;/p&gt;
      &lt;p&gt; Step 3: Typesetting the print book &lt;/p&gt;
      &lt;p&gt; This part surprised me the most. I initially thought I'd have to learn Adobe InDesign or pay someone to do the typesetting. But I decided to use LaTeX instead, since I had some previous experience with it (another publishing friend sent me some of his example files, and I had some academic experience). The process worked out better than expected. &lt;/p&gt;
      &lt;p&gt; I used XeLaTeX with the &lt;code&gt;memoir&lt;/code&gt; document class. Here's what I liked about this approach:
&lt;/p&gt;
      &lt;div&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Reproducible: I can rebuild the entire book from source in a few seconds, and I can use the same templates next year&lt;/item&gt;
          &lt;item&gt;Professional typography: LaTeX handles ligatures, kerning, and line breaking better than I could manually&lt;/item&gt;
          &lt;item&gt;Custom fonts: I used Crimson Pro for body text and Rajdhani for titles&lt;/item&gt;
          &lt;item&gt;Again, version control that I'm used to: The entire book is just text files in Git&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
      &lt;p&gt; The main parts of the master file for the book are really simple: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;\documentclass[final,11pt,twoside]{memoir}
\usepackage{compelling}

\begin{document}
\begin{frontmatter}
  \include{title}
  \tableofcontents
\end{frontmatter}

\begin{mainmatter}
  \include{introduction}
  \include{death-and-the-gorgon}
  \include{the-best-version-of-yourself}
  % ... 14 more stories
  \include{acknowledgements}
\end{mainmatter}
\end{document}&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;div&gt;&lt;p&gt; All the formatting rules live in &lt;/p&gt;&lt;code&gt;compelling.sty&lt;/code&gt;&lt;p&gt;, a custom style package. &lt;/p&gt;Here's a link to the full, messy file&lt;p&gt;. Some highlights: &lt;/p&gt;&lt;/div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;% 6x9 inch trade paperback size
\setstocksize{9in}{6in}
\settrimmedsize{9in}{6in}{*}

% Margins
\setlrmarginsandblock{1.00in}{0.75in}{*}
\setulmarginsandblock{0.75in}{0.75in}{*}

% Typography nerding
\usepackage[final,protrusion=true,factor=1125,
            stretch=70,shrink=70]{microtype}

% Custom fonts loaded from local files
\setromanfont[
  Ligatures=TeX,
  Path=./Crimson_Pro/static/,
  UprightFont=CrimsonPro-Regular,
  BoldFont=CrimsonPro-Bold,
  ItalicFont=CrimsonPro-Italic,
  BoldItalicFont=CrimsonPro-BoldItalic
]{Crimson Pro}


\setsansfont[
  Path=./Rajdhani/,
  UprightFont=Rajdhani-Bold,
  BoldFont=Rajdhani-Bold,
  ItalicFont=Rajdhani-Bold,
  BoldItalicFont=Rajdhani-Bold
]{Rajdhani}

% Chinese font family for CJK characters
\newfontfamily\chinesefont{PingFang SC}&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; The &lt;code&gt;microtype&lt;/code&gt; package does a lot of subtle work with character spacing and line breaking that makes the text look professionally typeset.
&lt;/p&gt;
      &lt;p&gt; I wanted story titles in bold sans-serif with author names underneath in a lighter gray. Here's how I set that up: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;\renewcommand{\chapter}[2]{
    \pagestyle{DefaultStyle}
    \stdchapter*{
        \sffamily
        \LARGE 
        \textbf{\MakeUppercase{#1}}
        \\ 
        \large 
        \color{dark-gray} 
        {\MakeUppercase{#2}}
    }
    \addcontentsline{toc}{chapter}{
        \protect\parbox[t]{\dimexpr\textwidth-3em}{
            \sffamily#1
            \\ 
            \protect\small
            \protect\color{gray}
            \protect\textit{#2}
        }
    }
    \def\leftmark{#1}
    \def\rightmark{#2}
}&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; This redefines the &lt;code&gt;chapter&lt;/code&gt; command to take two arguments, the title and byline, and sets up both the chapter formatting, TOC formatting, and makes sure that the title and byline are printed in the headers on alternating pages.
&lt;/p&gt;
      &lt;p&gt; Now every story file just says: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;\chapter{Death and the Gorgon}{by Greg Egan}
[story content]&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Most authors send me stories as HTML, PDF, or word, so I needed a way to convert them to LaTeX. I wrote a simple Python script to do this, which saved me a huge amount of manual formatting work. &lt;/p&gt;
      &lt;p&gt; Step 4: Creating the ebook &lt;/p&gt;
      &lt;p&gt; Print was one thing, but I also needed an ebook. This turned out to be easier than I expected because I could reuse all the LaTeX source I'd already created. &lt;/p&gt;
      &lt;p&gt; I used Pandoc to convert from LaTeX to EPUB: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;# Convert LaTeX to EPUB
pandoc 2025.tex -o Think_Weirder_2025.epub \
  âtoc \
  âepub-cover-image=cover_optimized.jpg \
  âcss=epub-style.css \
  âmetadata title="Think Weirder" \
  âmetadata author="Edited by Joe Stech"&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; Pandoc's default table of contents only showed story titles. But I wanted author names too, like you see in print anthologies. EPUBs are just zipped collections of XHTML files, so I wrote a small post-processing script: &lt;/p&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;def modify_toc(nav_content, authors):
    """Add author bylines to TOC entries."""
    pattern = r'&amp;lt;a href="([^"]+)"&amp;gt;([^&amp;lt;]+)&amp;lt;/a&amp;gt;'

    def add_author(match):
        href, title = match.group(1), match.group(2)
        chapter_id = extract_id_from_href(href)

        if chapter_id in authors:
            author = authors[chapter_id]
            return f'&amp;lt;a href="{href}"&amp;gt;{title}&amp;lt;br /&amp;gt;\n' \
                   f'&amp;lt;em&amp;gt;{author}&amp;lt;/em&amp;gt;&amp;lt;/a&amp;gt;'
        return match.group(0)

    return re.sub(pattern, add_author, nav_content)&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;p&gt; The script unzips the EPUB, finds the navigation file, adds author bylines, and rezips everything. Now the ebook table of contents matches the print version. &lt;/p&gt;
      &lt;p&gt; What I learned &lt;/p&gt;
      &lt;p&gt; The whole process took longer than I expected â many months of night work. The simple software I wrote really made it a feasible one-person project though, and motivates me to go through the whole process again next year. &lt;/p&gt;
      &lt;p&gt; Staying organized is crucial. When hundreds of stories are involved, it's easy to forget details, so using &lt;code&gt;se.py&lt;/code&gt; to save metadata in the moment that could be sliced and diced later was so important.
&lt;/p&gt;
      &lt;p&gt; Reproducible builds were a lifesaver. I made changes to the book layout right up until the week before publication. Because I could rebuild the entire book in seconds, and everything was backed up in git, I could experiment freely without worrying about breaking things. &lt;/p&gt;
      &lt;p&gt; Simple file formats made me comfortable. When something went wrong, I could always open a YAML file or look at the LaTeX source and understand what was happening. I never hit a point where the tools were a black box. &lt;/p&gt;
      &lt;p&gt; I didn't need to understand everything up front. I learned LaTeX details as I went (arguably I still don't really understand LaTeX). Same with Pandoc. I got something basic working first, then incrementally improved it. &lt;/p&gt;
      &lt;p&gt; Can you do this too? &lt;/p&gt;
      &lt;p&gt; If you're thinking about publishing a book â whether it's an anthology, a novel, or a collection of technical writing â I think this approach is worth considering. There's something motivating about having a detailed understanding of every step in the production process. If you have questions feel free to reach out, I love talking about this hobby! You can email me at joe@thinkweirder.com. &lt;/p&gt;
      &lt;div&gt;&lt;p&gt; And if you enjoy concept-driven science fiction that is heavy on novel ideas, check out &lt;/p&gt;Think Weirder! &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://compellingsciencefiction.com/posts/the-code-and-open-source-tools-i-used-to-produce-a-science-fiction-anthology.html"/><published>2025-11-18T16:10:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45968362</id><title>Solving a million-step LLM task with zero errors</title><updated>2025-11-19T12:20:33.702856+00:00</updated><content>&lt;doc fingerprint="189cb409d4d7b6cf"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 12 Nov 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Solving a Million-Step LLM Task with Zero Errors&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:LLMs have achieved remarkable breakthroughs in reasoning, insights, and tool use, but chaining these abilities into extended processes at the scale of those routinely executed by humans, organizations, and societies has remained out of reach. The models have a persistent error rate that prevents scale-up: for instance, recent experiments in the Towers of Hanoi benchmark domain showed that the process inevitably becomes derailed after at most a few hundred steps. Thus, although LLM research is often still benchmarked on tasks with relatively few dependent logical steps, there is increasing attention on the ability (or inability) of LLMs to perform long range tasks. This paper describes MAKER, the first system that successfully solves a task with over one million LLM steps with zero errors, and, in principle, scales far beyond this level. The approach relies on an extreme decomposition of a task into subtasks, each of which can be tackled by focused microagents. The high level of modularity resulting from the decomposition allows error correction to be applied at each step through an efficient multi-agent voting scheme. This combination of extreme decomposition and error correction makes scaling possible. Thus, the results suggest that instead of relying on continual improvement of current LLMs, massively decomposed agentic processes (MDAPs) may provide a way to efficiently solve problems at the level of organizations and societies.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.AI&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2511.09030"/><published>2025-11-18T16:26:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45969250</id><title>Pebble, Rebble, and a path forward</title><updated>2025-11-19T12:20:33.366434+00:00</updated><content>&lt;doc fingerprint="fc4b101b5b1408f0"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I believe the Pebble community, Core Devices, Rebble and I all want the same thing. We love our Pebbles and want them to keep working long into the future. We love the community that has sprung up around Pebble, and how it’s persevered - next year will be the 14th anniversary of the original Kickstarter campaign!&lt;/p&gt;
      &lt;p&gt;But I have to respond to claims made by Rebble posted on their blog yesterday. I will link to their post so you can read their side of the story, and I’ve asked them to link back to this blog post from theirs.&lt;/p&gt;
      &lt;p&gt;Look - I’m the first person to call myself out when I fail. I wrote a detailed blog post about Success and Failure at Pebble and often write in detail about learning from my mistakes. But in this specific case, you’ll find that I’ve done my utmost to respect the Pebble legacy and community. Rebble is misleading the community with false accusations.&lt;/p&gt;
      &lt;p&gt;For those just passing through, here’s the TLDR: &lt;/p&gt;
      &lt;p&gt;Core Devices is a small company I started in 2025 to relaunch Pebble and build new Pebble smartwatches. Rebble is a non-profit organization that has supported the Pebble community since 2017. Rebble has done a ton of great work over the years and deserves recognition and support for that.&lt;/p&gt;
      &lt;p&gt;Core Devices and Rebble negotiated an agreement where Core would pay $0.20/user/month to support Rebble services. But the agreement broke down after over the following disagreement. &lt;/p&gt;
      &lt;p&gt;Rebble believes that they ‘100%’ own the data of the Pebble Appstore. They’re attempting to create a walled garden around 13,000 apps and faces that individual Pebble developers created and uploaded to the Pebble Appstore between 2012 and 2016. Rebble later scraped this data in 2017. &lt;/p&gt;
      &lt;p&gt;I disagree. I’m working hard to keep the Pebble ecosystem open source. I believe the contents of the Pebble Appstore should be freely available and not controlled by one organization. &lt;/p&gt;
      &lt;p&gt;Rebble posted a blog post yesterday with a bunch of false accusations, and in this post I speak to each of them.&lt;/p&gt;
      &lt;p&gt;Sections&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Dec 2016 - Pebble shut down. Some IP was sold to Fitbit. I blogged about why I think we failed. Fitbit continued to run the Pebble Appstore and web services for 1.5 years. I really appreciated that.&lt;list rend="ul"&gt;&lt;item&gt;Rebble organization grew out of the official Pebble Developers Discord.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;July 2018, Fitbit shut down the Pebble appstore.&lt;list rend="ul"&gt;&lt;item&gt;Before it shut down, Rebble (and others) scraped all 13,000 apps and metadata from the Pebble Appstore. Rebble began hosting a copy of the appstore. They created a new Dev Portal where developers could upload new apps, roughly 500 have been uploaded since July 2018.&lt;/item&gt;&lt;item&gt;Rebble also reverse engineered many Pebble web services (weather, timeline and voice transcription) and provided them as a paid service for the Pebble community.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Jan 2025 - Google open sourced PebbleOS, breathing new life into the community.&lt;/item&gt;
        &lt;item&gt;March 2025 - I announced a new company (Core Devices) and 2 new watches - store.rePebble.com&lt;/item&gt;
        &lt;item&gt;November 2025 - we finished shipping out 5,000 Pebble 2 Duos. We’re working hard on Pebble Time 2. We’re aiming to start shipping in January.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 1: ‘Rebble paid for the work that [Eric] took as a base for his commercial watches’&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;I think they’re accusing me of ‘stealing’ open source contributions to PebbleOS that Rebble paid for. This is entirely false.&lt;/item&gt;
        &lt;item&gt;We did not take any PebbleOS work Rebble paid for ‘as a base for [our] commercial watches’. &lt;del rend="overstrike"&gt;To my best of my knowledge&lt;/del&gt;&lt;del rend="overstrike"&gt;,&lt;/del&gt;&lt;del rend="overstrike"&gt;Rebble never paid the&lt;/del&gt;&lt;del rend="overstrike"&gt;developer who ported NimBLE into PebbleOS.&lt;/del&gt;&lt;del rend="overstrike"&gt;My best guess is that they are referring to Rebble having paid CodeCoup, the company behind&lt;/del&gt;&lt;del rend="overstrike"&gt;NimBLE&lt;/del&gt;&lt;del rend="overstrike"&gt;, to fix some bugs that affected older non-Core Devices watches. Any Rebble-sponsored CodeCoup commits are not present in our repo. In fact, the opposite is true - we paid Codecoup $10,000 to fix multiple BLE stack issues, some of them on the host side that benefit all devices, including old Pebbles.&lt;/del&gt; Update: I’m told Rebble did pay him, months later. My point is valid - when we shifted development to our repo, Rebble had not paid anything. More broadly, I reject the premise that using open source software under the terms of the license, regardless of who funds development, is ‘stealing’.&lt;/item&gt;
        &lt;item&gt;We started using our own repo for PebbleOS development because PRs on the Rebble repo reviews were taking too long. We only had one firmware engineer at the time (now we have a whopping 2!) and he felt like he was being slowed down too much. All of our contributions to PebbleOS have been 100% open source.&lt;/item&gt;
        &lt;item&gt;Overall, the feedback that PebbleOS could benefit from open governance is well taken. Long term, PebbleOS would be a good fit for open source organization with experience in open governance, like Apache or Linux Foundation. I wrote about this last week.&lt;/item&gt;
        &lt;item&gt;With our small team and fairly quick development schedule, it's true that we haven't PRed our changes into Rebble’s repo. It’s tough to prioritize this while we are busy fixing bugs and getting ready for Pebble Time 2.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 2: ‘Core took Rebble’s work’ on &lt;code&gt;libpebblecommon&lt;/code&gt; to create &lt;code&gt;libpebble3&lt;/code&gt;&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;The majority (&amp;gt;90%) of our new open source&lt;code&gt;libpebble3&lt;/code&gt; library was written by Core Devices employees.  The remainder comes from &lt;code&gt;libpebblecommon&lt;/code&gt;, another open source library written by two people.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;In April 2025, Core purchased the copyright to the &lt;code&gt;libpebblecommon&lt;/code&gt; code from the two maintainers and incorporated it into &lt;code&gt;libpebble3&lt;/code&gt;**, which is also open source**.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;All our contributions to &lt;code&gt;libpebble3&lt;/code&gt; are GPL-3.0 licensed. Here’s the motivation behind that our licensing strategy for this repo. We use the same CLA agreement as Matrix, QT and MySQL. Our CLA explicitly includes a clause that requires to Core Devices to distribute all contributions under an OSI-compatible FOSS license (e.g. GPLv3).&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Note that neither Rebble &lt;code&gt;libpebblecommon&lt;/code&gt; maintainer signed the Rebble blog post.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Side note regarding Cobble, I don’t think Rebble even knows this but in 2024, I personally spent over $30,000 to support its development, way before PebbleOS was open source. It was my own way to support the community.&lt;/p&gt;
      &lt;p&gt;Accusation 3: ‘Core promised that they would let Rebble maintain and own the developer site’&lt;/p&gt;
      &lt;p&gt;Facts:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Nothing of the sort was agreed upon. See the full written agreement that Core Devices has with Rebble towards the bottom. Rebble agreed that Core would host the developer site.&lt;/item&gt;
        &lt;item&gt;I have been maintaining and updating the developer site personally - all open source. Having two sources of truth would be confusing for the community.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Accusation 4: ‘[Eric] scraped our app store, in violation of the agreement that we reached with him previously’&lt;/p&gt;
      &lt;p&gt;Note: ‘scraping’ usually means to automated extraction of data from a website.&lt;/p&gt;
      &lt;p&gt;Facts: &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Here’s what happened. I wanted to highlight some of my favourite watchfaces on the Pebble Appstore. Last Monday Nov 10, after I put my kids to sleep and between long calls with factories in Asia, I started building a webapp to help me quickly go through Pebble Appstore and decide which were my top picks.&lt;/item&gt;
        &lt;item&gt;Let me be crystal clear - my little webapp did not download apps or ‘scrape’ anything from Rebble. The webapp displayed the name of each watchface and screenshots and let me click on my favs. I used it to manually look through 6000 watchfaces with my own eyes. I still have 7,000 to go. Post your server logs, they will match up identically to the app I (well…Claude) wrote (source code here)&lt;/item&gt;
        &lt;item&gt;I integrated these picks into the Pebble Appstore on Saturday and posted about it on Sunday.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;All of four of these accusations could have been clarified simply by asking me. Instead, Rebble decided to post them on their blog and threaten a lawsuit. &lt;/p&gt;
      &lt;p&gt;How did we get here?&lt;/p&gt;
      &lt;p&gt;Why are there dueling blog posts in the Pebbleverse? &lt;/p&gt;
      &lt;p&gt;I think most of the people are behind Rebble are great and the community overall is awesome. I know they truly mean well, but there are many aspects of the org that are severely troubling. I am very close with one of the Rebble board members, who I consider a personal friend. Over the years, I learned a lot about the organization and helped coach him through some major disputes between board members. &lt;/p&gt;
      &lt;p&gt;I exchanged literally thousands of messages with my friend on this topic over the span of 3 years. I refrained from getting too involved, despite being asked several times to join Rebble as a board member or lead the organization. I demurred - I saw how painful it was for him and I had no interest in being part of that. &lt;/p&gt;
      &lt;p&gt;Core Devices + Rebble: 2025&lt;/p&gt;
      &lt;p&gt;PebbleOS is now open source! Yay. This is thanks to the work of many Googlers, ex-Pebblers and others - I called out (hopefully) all of them in my blog post in March. I really wanted Rebble to be a part of the Pebble revival going forward. I hired 3 people from Rebble to join Core Devices. I regularly brought up Rebble’s efforts over the years.&lt;/p&gt;
      &lt;p&gt;I engaged with Rebble folks in discussions in the spring on how we could formally work together, and then made some concrete proposals in the summer. One difficulty was that Core Devices is a business with customers and schedules. This didn’t always sync up with the timeframes of a non-profit. Things became very drawn out. It was very hard to pin people down, even on simple stuff like what the goals of Rebble as an organization were. &lt;/p&gt;
      &lt;p&gt;Regardless, I continued pushing to make Rebble a key part of the Pebble relaunch.&lt;/p&gt;
      &lt;p&gt;By August, we finally got close to an agreement.&lt;/p&gt;
      &lt;p&gt;On September 30 2025, we agreed to the following document and published respective blog posts (ours, theres). Core Devices would pay Rebble $0.20/user/month. I considered it a donation to a group that has done so much to support the community. But I purposely pushed for openness - no single group (Core Devices or Rebble) should be in control. &lt;/p&gt;
      &lt;p&gt;Notice the final bullet in the App store section: &lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;All binary/metadata (including historical apps) will be published as archive file (no scraping Rebble services) &lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;Looking back, we should have had more clear wording in this agreement. But this was after months of chat discussions and hours of Zoom calls. I honestly thought that we had reached an agreement to make the archive open, like in this message I received from a Rebble board member.&lt;/p&gt;
      &lt;p&gt;By the end of October, Rebble has changed their mind about providing an archive file.&lt;/p&gt;
      &lt;p&gt;Not withstanding their false accusations of theft, the crux of our disagreement is the archive of 13,000 Pebble apps and watchfaces that were uploaded to the Pebble Appstore in July 2018 before it was shut down. &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;I believe that these apps and watchfaces should be archived publicly and freely accessible by anyone. They should not held behind a walled garden by one organization. I repeatedly advocated for hosting this data on a neutral 3rd party like Archive.org.&lt;/item&gt;
        &lt;item&gt;Rebble believes ‘the data behind the Pebble App Store is 100% Rebble’ (this is a direct quote from their blog post). They repeatedly refer to all watchfaces and watchapps as ‘our data’.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;This is just plainly false. The apps and watchfaces were originally uploaded by individual developers to an appstore run by a company that no longer exists. These folks created beautiful work and shared them freely with the Pebble community. I’ve spoken with numerous Pebble app developers about this. After the fall of Pebble Tech Corp, none of them envisioned one single organization claiming ownership of their work and restricting access, or charging money for access.&lt;/p&gt;
      &lt;p&gt;Let’s do the right thing - honour the original developers and create a free publicly available archive of their beautiful watchfaces and watchapps. &lt;/p&gt;
      &lt;p&gt;It's easy to assume the worst in situations like this. But our plan for the appstore is pretty straightforward. We’re working on rewriting the appstore frontend to be native in the mobile app rather than a web view. Rebble’s appstore backend API will be the data source. Rebble’s dev portal is where developers upload apps. No subscription or Rebble account will not be required to download apps. We intend to curate how the appstore is displayed Pebble app.&lt;/p&gt;
      &lt;p&gt;We’re excited to see other Pebble-supporting mobile apps pop up - like MicroPebble and GadgetBridge, offering different features and experiences. We’d love to support these efforts with open source code or financially.&lt;/p&gt;
      &lt;p&gt;Reading things like ‘We’re happy to let them build whatever they want as long as it doesn’t hurt Rebble’ in their blog post worries me. Take our voice-to-text and weather features. Rebble currently offers these as part of their paid subscription. Our new Pebble mobile app includes a on-device speech-to-text feature. We’re planning to include weather for free in our app and make the data available to all watchfaces so you don’t need to configure each one separately. These features are better for users but would they ‘hurt’ Rebble? Will I need to ask permission from Rebble before building these features? It’s clear that the goals of a non-profit and device manufacturer will not always be in alignment.&lt;/p&gt;
      &lt;p&gt;Now consider the appstore. It’s a fundamental part of the Pebble experience. Even before yesterday’s accusations, I felt wary about relying too heavily on a 3rd party like Rebble to provide such a critical service. When people buy a watch from Core Devices, they expect to be able to download apps and watchfaces. If Rebble leadership changes their mind, how can I be certain I can deliver a good experience for our customers? This is one of the primary reasons I think it’s important for an archive of the Pebble Appstore to be freely available.&lt;/p&gt;
      &lt;p&gt;Rebble - prove that you believe in an open, unrestricted Pebble community. Tear down the walled garden you are trying to create. Publish your copy of the Pebble Appstore archive. Stop saying that you ‘100%’ own other developers data. Let’s move on from this ridiculous sideshow and focus on making Pebble awesome!&lt;/p&gt;
      &lt;p&gt;I’ve worked hard to structure everything that we’re doing to be sustainable for the long term, and to do right by the Pebble community. I think Rebble should do the same. &lt;/p&gt;
      &lt;p&gt;I earned almost nothing from Pebble Tech Corp. I paid myself a $65,000 salary each year. I did not get any payout through the asset sale. I fought to make sure that all Pebble employees were taken care of as best as possible, and that the Pebble community would live on. I believe that at every turn, I’ve done right by the community.&lt;/p&gt;
      &lt;p&gt;I didn’t relaunch Pebble to make a lot of money. My goal this time round is to make it sustainable. I want to continue making more watches and cool gadgets. There are no investors. I am taking huge risks doing this. I relaunched it because I love Pebble and want it to live on long into the future. Generally, I am excited and positive for the future, despite everything.&lt;/p&gt;
      &lt;p&gt;For everyone else, again, I apologize for the extreme amounts of inside baseball and the better things you could be doing with your time. I’ll leave the comments open here. Please refrain from any personal attacks or vicious comments (at myself or other people) - follow the HN guidelines.&lt;/p&gt;
      &lt;p&gt;Eric Migicovsky&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward/"/><published>2025-11-18T17:24:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45969909</id><title>I am stepping down as the CEO of Mastodon</title><updated>2025-11-19T12:20:33.043707+00:00</updated><content>&lt;doc fingerprint="6c92901d0c810af1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;My next chapter with Mastodon&lt;/head&gt;
    &lt;p&gt;Eugen Rochko&lt;/p&gt;
    &lt;p&gt;Strategy &amp;amp; Product Advisor, Founder&lt;/p&gt;
    &lt;p&gt;After nearly 10 years, I am stepping down as the CEO of Mastodon and transferring my ownership of the trademark and other assets to the Mastodon non-profit. Over the course of my time at Mastodon, I have centered myself less and less in our outward communications, and to some degree, this is the culmination of that trend. Mastodon is bigger than me, and though the technology we develop on is itself decentralized—with heaps of alternative fediverse projects demonstrating that participation in this ecosystem is possible without our involvement—it benefits our community to ensure that the project itself which so many people have come to love and depend on remains true to its values. There are too many examples of founder egos sabotaging thriving communities, and while I’d like to think myself an exception, I understand why people would prefer better guardrails.&lt;/p&gt;
    &lt;p&gt;But it would be uncouth for me to pretend that there isn’t some self-interest involved. Being in charge of a social media project is, turns out, quite the stressful endeavour, and I don’t have the right personality for it. I think I need not elaborate that the passion so many feel for social media does not always manifest in healthy ways. You are to be compared with tech billionaires, with their immense wealth and layered support systems, but with none of the money or resources. It manifests in what people expect of you, and how people talk about you. I remember somebody jokingly suggesting that I challenge Elon Musk to a fight (this was during his and Mark Zuckerberg’s martial arts feud), and quietly thinking to myself, I am literally not paid enough for that. I remember also, some Spanish newspaper article that for some reason, concluded that I don’t dress as fashionably as Jeff Bezos, based on the extremely sparse number of pictures of myself I have shared on the web. Over an entire decade, these tiny things chip away at you slowly. Some things chip faster. I steer clear of showing vulnerability online, but there was a particularly bad interaction with a user last summer that made me realise that I need to take a step back and find a healthier relationship with the project, ultimately serving as the impetus to begin this restructuring process.&lt;/p&gt;
    &lt;p&gt;As for what the legacy of my run will be, I find hard to answer. For one, I think it is not up for me to judge. On the other hand, it is as much about what didn’t happen as it is about what did. I’ve always thought that one of the most important responsibilities I had was to say “no”. It is not a popular thing to do, nor is it a fun thing to do, but being pulled into too many different directions at once can spell disaster for any project. I’d like to think I avoided some trouble by being careful. But I’m also aware that my aversion to public appearances cost Mastodon some opportunities in publicity. Ultimately, while I cannot take sole credit for it, I am nevertheless most proud of how far we’ve made it over these last 10 years. From the most barebones project written out of my childhood bedroom, to one of the last remaining and thriving pieces of the original, community-centred internet.&lt;/p&gt;
    &lt;p&gt;I have so much passion for Mastodon and the fediverse. The fediverse is an island within an increasingly dystopian capitalist hellscape. And from my perspective, Mastodon is our best shot at bringing this vision of a better future to the masses. This is why I’m sticking around, albeit in a more advisory, and less public, role.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.joinmastodon.org/2025/11/my-next-chapter-with-mastodon/"/><published>2025-11-18T18:13:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45970338</id><title>Show HN: RowboatX – open-source Claude Code for everyday automations</title><updated>2025-11-19T12:20:32.631328+00:00</updated><content>&lt;doc fingerprint="f5344fd3152ca8f9"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✨ Create background agents with full shell access &lt;list rend="ul"&gt;&lt;item&gt;E.g. "Generate a NotebookLM-style podcast from my saved articles every morning"&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;🔧 Connect any MCP server to add capabilities &lt;list rend="ul"&gt;&lt;item&gt;Add MCP servers and RowboatX handles the integration&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;🎯 Let RowboatX control and monitor your background agents &lt;list rend="ul"&gt;&lt;item&gt;Easily inspect state on the filesystem&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Inspired by Claude Code, RowboatX brings the same shell-native power to background automations.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install RowboatX &lt;quote&gt;npx @rowboatlabs/rowboatx&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Configure LLM (defaults to OpenAI) &lt;code&gt;edit ~/.rowboat/config/models.json&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then set your API key in your environment. Supports OpenAI, Ollama, Anthropic, Gemini, LMStudio, OpenRouter, LiteLLM&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;$ rowboatx&lt;/code&gt;
    &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add MCP: 'Add this MCP server config: &amp;lt;config&amp;gt; '&lt;/item&gt;
      &lt;item&gt;Explore tools: 'What tools are there in &amp;lt;server-name&amp;gt; '&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;
      &lt;code&gt;$ rowboatx&lt;/code&gt;
    &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;'Create agent to do X.'&lt;/item&gt;
      &lt;item&gt;'... Attach the correct tools from &amp;lt;mcp-server-name&amp;gt; to the agent'&lt;/item&gt;
      &lt;item&gt;'... Allow the agent to run shell commands including ffmpeg'&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;
      &lt;code&gt;$ rowboatx&lt;/code&gt;
    &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;'Make agent &amp;lt;background-agent-name&amp;gt; run every day at 10 AM'&lt;/item&gt;
      &lt;item&gt;'What agents do I have scheduled to run and at what times'&lt;/item&gt;
      &lt;item&gt;'When was &amp;lt;background-agent-name&amp;gt; last run'&lt;/item&gt;
      &lt;item&gt;'Are any agents waiting for my input or confirmation'&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;rowboatx --agent=&amp;lt;agent-name&amp;gt; --input="xyz" --no-interactive=true&lt;/code&gt;
    &lt;code&gt;rowboatx --agent=&amp;lt;agent-name&amp;gt; --run_id=&amp;lt;run_id&amp;gt; # resume from a previous run&lt;/code&gt;
    &lt;p&gt;You can configure your models in &lt;code&gt;~/.rowboat/config/models.json&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;{
  "providers": {
    "openai": {
      "flavor": "openai"
    },
    "openai-compatible-host": {
      "flavor": "openai",
      "baseURL": "http://localhost:2000/...",
      "apiKey": "...",
      "headers": {
        "foo": "bar"
      }
    },
    "anthropic": {
      "flavor": "anthropic"
    },
    "google": {
      "flavor": "google"
    },
    "ollama": {
      "flavor": "ollama"
    }
  },
  "defaults": {
    "provider": "openai",
    "model": "gpt-5"
  }
}&lt;/code&gt;
    &lt;p&gt;To use Rowboat Classic UI (not RowboatX), refer to Classic.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/rowboatlabs/rowboat"/><published>2025-11-18T18:50:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45970391</id><title>OrthoRoute – GPU-accelerated autorouting for KiCad</title><updated>2025-11-19T12:20:32.485265+00:00</updated><content>&lt;doc fingerprint="f2d15d492c15bffa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;OrthoRoute — GPU-Accelerated Autorouting for KiCad&lt;/head&gt;
    &lt;p&gt;OrthoRoute is a GPU-accelerated PCB autorouter that uses a Manhattan lattice and the PathFinder algorithm to route high-density boards. Built as a KiCad plugin using the IPC API, it handles complex designs with thousands of nets that make traditional push-and-shove routers give up.&lt;/p&gt;
    &lt;p&gt;Never trust the autorouter, but at least this one is fast.&lt;/p&gt;
    &lt;head rend="h4"&gt;This document is a complement to the README in the Github repository. The README provides information about performance, capabilities, and tests. This document reflects more on the why and how OrthoRoute was developed.&lt;/head&gt;
    &lt;head rend="h1"&gt;Why I Built This&lt;/head&gt;
    &lt;p&gt;This is a project born out of necessity. Another thing I was working on needed an enormous backplane. A PCB with sixteen connectors, with 1,100 pins on each connector. That’s 17,600 individual pads, and 8,192 airwires that need to be routed. Here, just take a look:&lt;/p&gt;
    &lt;p&gt;Look at that shit. Hand routing this would take months. For a laugh, I tried FreeRouting, the KiCad autorouter plugin, and it routed 4% of the traces in seven hours. If that trend held, which it wouldn’t, that would be a month of autorouting. And it probably wouldn’t work in the end. I had a few options, all of which would take far too long&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I could route the board by hand. This would be painful and take months, but I would get a good-looking board at the end.&lt;/item&gt;
      &lt;item&gt;I could YOLO everything and just let the FreeRouting autorouter handle it. It would take weeks, because the first traces are easy, the last traces take the longest. This would result in an ugly board.&lt;/item&gt;
      &lt;item&gt;I could spend a month or two building my own autorouter plugin for KiCad. I have a fairly powerful GPU and I thought routing a PCB is a very parallel problem. I could also implement my own routing algorithms to make the finished product look good.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When confronted with a task that will take months, always choose the more interesting path.&lt;/p&gt;
    &lt;head rend="h2"&gt;A New KiCad API, and a ‘Traditional’ Autorouter&lt;/head&gt;
    &lt;p&gt;KiCad, Pre-version 9.0, had a SWIG-based plugin system. There are serious deficits with this system compared to the new IPC plugin system released with KiCad 9. The SWIG-based system was locked to the Python environment bundled with KiCad. Process isolation, threading, and performance constraints were a problem. Doing GPU programming with CuPy or PyTorch, while not impossible, is difficult.&lt;/p&gt;
    &lt;p&gt;The new IPC plugin system for KiCad is a godsend. The basic structure of the OrthoRoute plugin looks something like this:&lt;/p&gt;
    &lt;p&gt;The OrthoRoute plugin communicates with KiCad via the IPC API over a UNIX-ey socket. This API is basically a bunch of C++ classes that gives me access to board data – nets, pads, copper pour geometry, airwires, and everything else. This allows me to build a second model of a PCB inside a Python script and model it however I want. With a second model of a board inside my plugin, all I have to do is draw the rest of the owl.&lt;/p&gt;
    &lt;head rend="h2"&gt;Development of the Manhattan Routing Engine&lt;/head&gt;
    &lt;p&gt;After wrapping my head around the the ability to read and write board information to and from KiCad, I had to figure out a way to route this stupidly complex backplane. A non-orthogonal autorouter is a good starting point, but I simply used that as an exercise to wrap my head around the KiCad IPC API. The real build is a ‘Manhattan Orthogonal Routing Engine’, the tool needed to route my mess of a backplane.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project PathFinder&lt;/head&gt;
    &lt;p&gt;The algorithm used for this autorouter is PathFinder: a negotiation-based performance-driven router for FPGAs. My implementation of PathFinder treats the PCB as a graph: nodes are intersections on an x–y grid where vias can go, and edges are the segments between intersections where copper traces can run. Each edge and node is treated as a shared resource.&lt;/p&gt;
    &lt;p&gt;PathFinder is iterative. In the first iteration, all nets (airwires) are routed greedily, without accounting for overuse of nodes or edges. Subsequent iterations account for congestion, increasing the “cost” of overused edges and ripping up the worst offenders to re-route them. Over time, the algorithm converges to a PCB layout where no edge or node is over-subscribed by multiple nets.&lt;/p&gt;
    &lt;p&gt;With this architecture – the PathFinder algorithm on a very large graph, within the same order of magnitude of the largest FPGAs – it makes sense to run the algorithm with GPU acceleration. There are a few factors that went into this decision:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Everyone who’s routing giant backplanes probably has a gaming PC. Or you can rent a GPU from whatever company is advertising on MUNI bus stops this month.&lt;/item&gt;
      &lt;item&gt;The PathFinder algorithm requires hundreds of billions of calculations for every iteration, making single-core CPU computation glacially slow.&lt;/item&gt;
      &lt;item&gt;With CUDA, I can implement a SSSP (parallel Dijkstra) to find a path through a weighted graph very fast.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Adapting FPGA Algorithms to PCBs&lt;/head&gt;
    &lt;p&gt;The original PathFinder paper was, “A Negotiation-Based Performance-Driven Router for FPGAs” and from 1995, this meant early FPGAs like the Xilinx 3000 series and others manufactured by Tryptych. These devices were simple, and to get a good idea of how they worked, check out Ken Shirriff’s blog. Here’s what the inside of a Xilinx XC2064 looks like:&lt;/p&gt;
    &lt;p&gt;That looks complicated, but it’s really exceptionally simple. All the LUTs, or logic elements, are connected to each other with wires. Where the wires cross over, there are fuzes. Burn the fuzes and you’ve connected the wires together. It’s a simple graph and all the complexity of the actual paths inside the chip are abstracted away. For a circuit board, I don’t have this luxury. I have to figure out how to get the signal from the pads on the top layer of the PCB and ‘drill down’ with vias into the grid. I need to come up with some way to account for both the edges of the graph and nodes of the graph, something that’s untread territory with the PathFinder algorithm.&lt;/p&gt;
    &lt;p&gt;The first step of that is the pad escape planner that pre-computes the escape routing of all the pads. Because the entire Manhattan Routing Engine is designed for a backplane, we can make some assumptions: All of the components are going to be SMD, because THT parts would kill the efficiency of a routing lattice. The components are going to be arranged on a grid, and just to be nice I’d like some ‘randomization’ in where it puts the vias punching down into the grid. Here’s what the escape planning looks like:&lt;/p&gt;
    &lt;head rend="h3"&gt;How PathFinder Almost Killed Me, and How I made PathFinder not suck&lt;/head&gt;
    &lt;p&gt;I found every bug imaginable while developing OrthoRoute. For one, congestion of nets would grow each iterations. The router would start fine with 9,495 edges with congestion in iteration 1. Then iteration 2: 18,636 edges. Iteration 3: 36,998 edges. The overuse was growing by 3× per iteration instead of converging. Something was fundamentally broken. The culprit? History costs were decaying instead of accumulating. The algorithm needs to remember which edges were problematic in past iterations, but my implementation had &lt;code&gt;history_decay=0.995&lt;/code&gt;, so it was forgetting 0.5% of the problem every iteration. By iteration 10, it had forgotten everything. No memory = no learning = explosion.&lt;/p&gt;
    &lt;p&gt;With the history fixed, I ran another test. I got oscillation. The algorithm would improve for 12 iterations (9,495 → 5,527, a 42% improvement!), then spike back to 11,817, then drop to 7,252, then spike to 14,000. The pattern repeated forever. The problem was “adaptive hotset sizing”—when progress slowed, the algorithm would enlarge the set of nets being rerouted from 150 to 225, causing massive disruption. Fixing the hotset at 100 nets eliminated the oscillation.&lt;/p&gt;
    &lt;p&gt;Even with fixed hotsets, late-stage oscillation returned after iteration 15. Why? The present cost factor escalates exponentially: &lt;code&gt;pres_fac = 1.15^iteration&lt;/code&gt;. By iteration 19, present cost was 12.4× stronger than iteration 1, completely overwhelming history (which grows linearly). The solution: cap &lt;code&gt;pres_fac_max=8.0&lt;/code&gt; to keep history competitive throughout convergence.&lt;/p&gt;
    &lt;p&gt;PathFinder is designed for FPGAs, and each and every Xilinx XC3000 chip is the same as every other XC3000 chip. Configuring the parameters for an old Xilinx chip means every routing problem will probably converge on that particular chip. PCBs are different; every single PCB is different from every other PCB. There is no single set of history, pressure, and decay parameters that will work on every single PCB.&lt;/p&gt;
    &lt;p&gt;What I had to do was figure out these paramaters on the fly. So that’s what I did. Right now I’m using Board-adaptive parameters for the Manhattan router. Before beginning the PathFinder algorithm it analyzes the board in KiCad for the number of signal layers, how many nets will be routed, and how dense the set of nets are. It’s clunky, but it kinda works.&lt;/p&gt;
    &lt;p&gt;Where PathFinder was tuned once for each family of FPGAs, I’m auto-tuning it for the entire class of circuit boards. A huge backplane gets careful routing and an Arduino clone gets fast, aggressive routing. The hope is that both will converge – produce a valid routing solution – and maybe that works. Maybe it doesn’t. There’s still more work to do.&lt;/p&gt;
    &lt;head rend="h2"&gt;Routing The Monster Board&lt;/head&gt;
    &lt;p&gt;After significant testing with “small” boards (actually 500+ net subsets of my large backplane, with 18 layers), I started work on the entire purpose of this project, the 8000+ net, 17000 pad monster board. There was one significant problem: it wouldn’t fit on my GPU. Admittedly, I only have a 16GB Nvidia 5080, but even this was far too small for the big backplane.&lt;/p&gt;
    &lt;p&gt;This led me to develop a ‘cloud routing solution’. It boils down to extracting a “OrthoRoute PCB file” from the OrthoRoute plugin. From there, I rent a Linux box with a GPU and run the autorouting algorithm with a headless mode. This produces an “OrthoRoute Solution file”. I import this back into KiCad by running the OrthoRoute plugin on my local machine, and importing the solution file, then pushing that to KiCad.&lt;/p&gt;
    &lt;p&gt;Here’s the result:&lt;/p&gt;
    &lt;p&gt;That’s it, that’s the finished board. A few specs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;44,233 blind and buried vias. 68,975 track segments.&lt;/item&gt;
      &lt;item&gt;Routed on an 80GB A100 GPU, rented on vast.io. The total VRAM required to route this board was 33.5 GB, so close to being under 32GB and allowing me to rent a cheaper GPU&lt;/item&gt;
      &lt;item&gt;Total time to route this board to completion was 41 hours. This is far better than the months it would have taken FreeRouting to route this board, but it’s still not fast.&lt;/item&gt;
      &lt;item&gt;The routing result is good but not great. A big problem is the DRC-awareness of the escape pad planning. There are traces that don’t quite overlap, but because of the geometry generated by the escape route planner they don’t pass a strict DRC. This could be fixed in future versions. There are also some overlapping traces in what PathFinder generated. Not many, but a few.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While the output from my autorouter isn’t perfect, no one would expect an autorouter to produce a perfect result, ready for production. It’s an autorouter, something you shouldn’t trust. Turning the result for OrthoRoute into a DRC-compliant board took a few days, but it was far easier than the intractable problem of eight thousand airwires I had at the beginning.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Future of OrthoRoute&lt;/head&gt;
    &lt;p&gt;I built this for one reason: to route my pathologically large backplane. Mission accomplished. And along the way, I accidentally built something more useful than I expected.&lt;/p&gt;
    &lt;p&gt;OrthoRoute proves that GPU-accelerated routing isn’t just theoretical, and that algorithms designed for routing FPGAs can be adapted to the more general class of circuit boards. It’s fast, too. The Manhattan lattice approach handles high-density designs that make traditional autorouters choke. And the PathFinder implementation converges in minutes on boards that would take hours or days with CPU-based approaches.&lt;/p&gt;
    &lt;p&gt;More importantly, the architecture is modular. The hard parts—KiCad IPC integration, GPU acceleration framework, DRC-aware routing space generation are done. Adding new routing strategies on top of this foundation is straightforward. Someone could implement different algorithms, optimize for specific board types, or extend it to handle flex PCBs.&lt;/p&gt;
    &lt;p&gt;The code is up on GitHub. I’m genuinely curious what other people will do with it. Want to add different routing strategies? Optimize for RF boards? Extend it to flex PCBs? PRs welcome, contributors welcome.&lt;/p&gt;
    &lt;p&gt;And yes, you should still manually route critical signals. But for dense digital boards with hundreds of mundane power and data nets? Let the GPU handle it while you grab coffee. That’s what autorouters are for.&lt;/p&gt;
    &lt;p&gt;Never trust the autorouter. But at least this one is fast.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bbenchoff.github.io/pages/OrthoRoute.html"/><published>2025-11-18T18:54:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45971726</id><title>GitHub: Git operation failures</title><updated>2025-11-19T12:20:32.193692+00:00</updated><content>&lt;doc fingerprint="7096aa564e934ff0"&gt;
  &lt;main&gt;
    &lt;p&gt;This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 21:59 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Git Operations is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 21:56 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are seeing full recovery after rolling out the fix and all services are operational.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 21:55 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Codespaces is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 21:55 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We have shipped a fix and are seeing recovery in some areas and will continue to provide updates.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 21:36 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We have identified the likely cause of the incident and are working on a fix. We will provide another update as we get closer to deploying the fix.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 21:27 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Codespaces is experiencing degraded availability. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 21:25 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are currently investigating failures on all Git operations, including both SSH and HTTP.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 21:11 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are seeing failures for some git http operations and are investigating&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 20:52 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Git Operations is experiencing degraded availability. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 20:39 UTC&lt;/p&gt;
    &lt;p&gt;Investigating&lt;/p&gt;
    &lt;p&gt;We are currently investigating this issue.&lt;/p&gt;
    &lt;p&gt;Posted Nov 18, 2025 - 20:39 UTC&lt;/p&gt;
    &lt;p&gt;This incident affected: Git Operations and Codespaces.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.githubstatus.com/incidents/5q7nmlxz30sk"/><published>2025-11-18T20:40:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45972390</id><title>Bild AI (YC W25) is hiring – Make housing affordable</title><updated>2025-11-19T12:20:31.400965+00:00</updated><content>&lt;doc fingerprint="19b82e91a7888e36"&gt;
  &lt;main&gt;
    &lt;p&gt;AI that understands construction blueprints&lt;/p&gt;
    &lt;p&gt;Puneet and I (Roop) founded Bild AI to tackle the mess that is blueprint reading, cost estimation, and permit applications in construction. It's a tough technical problem that requires the newest CV and AI approaches, and we’re impact-driven to make it more efficient to build more houses, hospitals, and schools. Featured on Business Insider.&lt;/p&gt;
    &lt;p&gt;Bild AI is an early-stage startup with a ton of really difficult technical challenges to solve. We're building blueprint understanding with a model-garden approach, so there is a lots of ground to break. We raised from the top VCs in the world before demo day and have a customer-obsessed approach to product development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/bild-ai/jobs/m2ilR5L-founding-engineer-applied-ai"/><published>2025-11-18T21:29:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45972519</id><title>Blender 5.0</title><updated>2025-11-19T12:20:31.136063+00:00</updated><content/><link href="https://www.blender.org/download/releases/5-0/"/><published>2025-11-18T21:39:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45973709</id><title>Cloudflare outage on November 18, 2025 post mortem</title><updated>2025-11-19T12:20:30.850875+00:00</updated><content>&lt;doc fingerprint="bc1b3b5b0cb0a8cb"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;On 18 November 2025 at 11:20 UTC (all times in this blog are UTC), Cloudflare's network began experiencing significant failures to deliver core network traffic. This showed up to Internet users trying to access our customers' sites as an error page indicating a failure within Cloudflare's network. &lt;/p&gt;
      &lt;p&gt;The issue was not caused, directly or indirectly, by a cyber attack or malicious activity of any kind. Instead, it was triggered by a change to one of our database systems' permissions which caused the database to output multiple entries into a âfeature fileâ used by our Bot Management system. That feature file, in turn, doubled in size. The larger-than-expected feature file was then propagated to all the machines that make up our network.&lt;/p&gt;
      &lt;p&gt;The software running on these machines to route traffic across our network reads this feature file to keep our Bot Management system up to date with ever changing threats. The software had a limit on the size of the feature file that was below its doubled size. That caused the software to fail.&lt;/p&gt;
      &lt;p&gt;After we initially wrongly suspected the symptoms we were seeing were caused by a hyper-scale DDoS attack, we correctly identified the core issue and were able to stop the propagation of the larger-than-expected feature file and replace it with an earlier version of the file. Core traffic was largely flowing as normal by 14:30. We worked over the next few hours to mitigate increased load on various parts of our network as traffic rushed back online. As of 17:06 all systems at Cloudflare were functioning as normal.&lt;/p&gt;
      &lt;p&gt;We are sorry for the impact to our customers and to the Internet in general. Given Cloudflare's importance in the Internet ecosystem any outage of any of our systems is unacceptable. That there was a period of time where our network was not able to route traffic is deeply painful to every member of our team. We know we let you down today.&lt;/p&gt;
      &lt;p&gt;This post is an in-depth recount of exactly what happened and what systems and processes failed. It is also the beginning, though not the end, of what we plan to do in order to make sure an outage like this will not happen again.&lt;/p&gt;
      &lt;p&gt;The chart below shows the volume of 5xx error HTTP status codes served by the Cloudflare network. Normally this should be very low, and it was right up until the start of the outage. &lt;/p&gt;
      &lt;p&gt;The volume prior to 11:20 is the expected baseline of 5xx errors observed across our network. The spike, and subsequent fluctuations, show our system failing due to loading the incorrect feature file. Whatâs notable is that our system would then recover for a period. This was very unusual behavior for an internal error.&lt;/p&gt;
      &lt;p&gt;The explanation was that the file was being generated every five minutes by a query running on a ClickHouse database cluster, which was being gradually updated to improve permissions management. Bad data was only generated if the query ran on a part of the cluster which had been updated. As a result, every five minutes there was a chance of either a good or a bad set of configuration files being generated and rapidly propagated across the network.&lt;/p&gt;
      &lt;p&gt;This fluctuation made it unclear what was happening as the entire system would recover and then fail again as sometimes good, sometimes bad configuration files were distributed to our network. Initially, this led us to believe this might be caused by an attack. Eventually, every ClickHouse node was generating the bad configuration file and the fluctuation stabilized in the failing state.&lt;/p&gt;
      &lt;p&gt;Errors continued until the underlying issue was identified and resolved starting at 14:30. We solved the problem by stopping the generation and propagation of the bad feature file and manually inserting a known good file into the feature file distribution queue. And then forcing a restart of our core proxy.&lt;/p&gt;
      &lt;p&gt;The remaining long tail in the chart above is our team restarting remaining services that had entered a bad state, with 5xx error code volume returning to normal at 17:06.&lt;/p&gt;
      &lt;p&gt;The following services were impacted:&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Service / Product&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Impact description&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Core CDN and security services&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;HTTP 5xx status codes. The screenshot at the top of this post shows a typical error page delivered to end users.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Turnstile&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Turnstile failed to load.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Workers KV&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Workers KV returned a significantly elevated level of HTTP 5xx errors as requests to KVâs âfront endâ gateway failed due to the core proxy failing.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Dashboard&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;While the dashboard was mostly operational, most users were unable to log in due to Turnstile being unavailable on the login page.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Email Security&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;While email processing and delivery were unaffected, we observed a temporary loss of access to an IP reputation source which reduced spam-detection accuracy and prevented some new-domain-age detections from triggering, with no critical customer impact observed. We also saw failures in some Auto Move actions; all affected messages have been reviewed and remediated.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;Access&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Authentication failures were widespread for most users, beginning at the start of the incident and continuing until the rollback was initiated at 13:05. Any existing Access sessions were unaffected.&lt;/p&gt;
            &lt;p&gt;All failed authentication attempts resulted in an error page, meaning none of these users ever reached the target application while authentication was failing. Successful logins during this period were correctly logged during this incident.Â &lt;/p&gt;
            &lt;p&gt;Any Access configuration updates attempted at that time would have either failed outright or propagated very slowly. All configuration updates are now recovered.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;As well as returning HTTP 5xx errors, we observed significant increases in latency of responses from our CDN during the impact period. This was due to large amounts of CPU being consumed by our debugging and observability systems, which automatically enhance uncaught errors with additional debugging information.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;How Cloudflare processes requests, and how this went wrong today&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Every request to Cloudflare takes a well-defined path through our network. It could be from a browser loading a webpage, a mobile app calling an API, or automated traffic from another service. These requests first terminate at our HTTP and TLS layer, then flow into our core proxy system (which we call FL for âFrontlineâ), and finally through Pingora, which performs cache lookups or fetches data from the origin if needed.&lt;/p&gt;
      &lt;p&gt;We previously shared more detail about how the core proxy works here.Â &lt;/p&gt;
      &lt;p&gt;As a request transits the core proxy, we run the various security and performance products available in our network. The proxy applies each customerâs unique configuration and settings, from enforcing WAF rules and DDoS protection to routing traffic to the Developer Platform and R2. It accomplishes this through a set of domain-specific modules that apply the configuration and policy rules to traffic transiting our proxy.&lt;/p&gt;
      &lt;p&gt;One of those modules, Bot Management, was the source of todayâs outage.Â &lt;/p&gt;
      &lt;p&gt;Cloudflareâs Bot Management includes, among other systems, a machine learning model that we use to generate bot scores for every request traversing our network. Our customers use bot scores to control which bots are allowed to access their sites â or not.&lt;/p&gt;
      &lt;p&gt;The model takes as input a âfeatureâ configuration file. A feature, in this context, is an individual trait used by the machine learning model to make a prediction about whether the request was automated or not. The feature configuration file is a collection of individual features.&lt;/p&gt;
      &lt;p&gt;This feature file is refreshed every few minutes and published to our entire network and allows us to react to variations in traffic flows across the Internet. It allows us to react to new types of bots and new bot attacks. So itâs critical that it is rolled out frequently and rapidly as bad actors change their tactics quickly.&lt;/p&gt;
      &lt;p&gt;A change in our underlying ClickHouse query behaviour (explained below) that generates this file caused it to have a large number of duplicate âfeatureâ rows. This changed the size of the previously fixed-size feature configuration file, causing the bots module to trigger an error.&lt;/p&gt;
      &lt;p&gt;As a result, HTTP 5xx error codes were returned by the core proxy system that handles traffic processing for our customers, for any traffic that depended on the bots module. This also affected Workers KV and Access, which rely on the core proxy.&lt;/p&gt;
      &lt;p&gt;Unrelated to this incident, we were and are currently migrating our customer traffic to a new version of our proxy service, internally known as FL2. Both versions were affected by the issue, although the impact observed was different.&lt;/p&gt;
      &lt;p&gt;Customers deployed on the new FL2 proxy engine, observed HTTP 5xx errors. Customers on our old proxy engine, known as FL, did not see errors, but bot scores were not generated correctly, resulting in all traffic receiving a bot score of zero. Customers that had rules deployed to block bots would have seen large numbers of false positives. Customers who were not using our bot score in their rules did not see any impact.&lt;/p&gt;
      &lt;p&gt;Throwing us off and making us believe this might have been an attack was another apparent symptom we observed: Cloudflareâs status page went down. The status page is hosted completely off Cloudflareâs infrastructure with no dependencies on Cloudflare. While it turned out to be a coincidence, it led some of the team diagnosing the issue to believe that an attacker may be targeting both our systems as well as our status page. Visitors to the status page at that time were greeted by an error message:&lt;/p&gt;
      &lt;p&gt;In the internal incident chat room, we were concerned that this might be the continuation of the recent spate of high volume Aisuru DDoS attacks:&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;The query behaviour change&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;I mentioned above that a change in the underlying query behaviour resulted in the feature file containing a large number of duplicate rows. The database system in question uses ClickHouseâs software.&lt;/p&gt;
      &lt;p&gt;For context, itâs helpful to know how ClickHouse distributed queries work. A ClickHouse cluster consists of many shards. To query data from all shards, we have so-called distributed tables (powered by the table engine &lt;code&gt;Distributed&lt;/code&gt;) in a database called &lt;code&gt;default&lt;/code&gt;. The Distributed engine queries underlying tables in a database &lt;code&gt;r0&lt;/code&gt;. The underlying tables are where data is stored on each shard of a ClickHouse cluster.&lt;/p&gt;
      &lt;p&gt;Queries to the distributed tables run through a shared system account. As part of efforts to improve our distributed queries security and reliability, thereâs work being done to make them run under the initial user accounts instead.&lt;/p&gt;
      &lt;p&gt;Before today, ClickHouse users would only see the tables in the &lt;code&gt;default&lt;/code&gt; database when querying table metadata from ClickHouse system tables such as &lt;code&gt;system.tables&lt;/code&gt; or &lt;code&gt;system.columns&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;Since users already have implicit access to underlying tables in &lt;code&gt;r0&lt;/code&gt;, we made a change at 11:05 to make this access explicit, so that users can see the metadata of these tables as well. By making sure that all distributed subqueries can run under the initial user, query limits and access grants can be evaluated in a more fine-grained manner, avoiding one bad subquery from a user affecting others.&lt;/p&gt;
      &lt;p&gt;The change explained above resulted in all users accessing accurate metadata about tables they have access to. Unfortunately, there were assumptions made in the past, that the list of columns returned by a query like this would only include the â&lt;code&gt;default&lt;/code&gt;â database:&lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;SELECT
  name,
  type
FROM system.columns
WHERE
  table = 'http_requests_features'
order by name;&lt;/code&gt;
      &lt;/p&gt;
      &lt;p&gt;Note how the query does not filter for the database name. With us gradually rolling out the explicit grants to users of a given ClickHouse cluster, after the change at 11:05 the query above started returning âduplicatesâ of columns because those were for underlying tables stored in the r0 database.&lt;/p&gt;
      &lt;p&gt;This, unfortunately, was the type of query that was performed by the Bot Management feature file generation logic to construct each input âfeatureâ for the file mentioned at the beginning of this section.Â &lt;/p&gt;
      &lt;p&gt;The query above would return a table of columns like the one displayed (simplified example):&lt;/p&gt;
      &lt;p&gt;However, as part of the additional permissions that were granted to the user, the response now contained all the metadata of the &lt;code&gt;r0&lt;/code&gt; schema effectively more than doubling the rows in the response ultimately affecting the number of rows (i.e. features) in the final file output.Â &lt;/p&gt;
      &lt;p&gt;Each module running on our proxy service has a number of limits in place to avoid unbounded memory consumption and to preallocate memory as a performance optimization. In this specific instance, the Bot Management system has a limit on the number of machine learning features that can be used at runtime. Currently that limit is set to 200, well above our current use of ~60 features. Again, the limit exists because for performance reasons we preallocate memory for the features.&lt;/p&gt;
      &lt;p&gt;When the bad file with more than 200 features was propagated to our servers, this limit was hit â resulting in the system panicking. The FL2 Rust code that makes the check and was the source of the unhandled error is shown below:&lt;/p&gt;
      &lt;p&gt;This resulted in the following panic which in turn resulted in a 5xx error:&lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;thread fl2_worker_thread panicked: called Result::unwrap() on an Err value&lt;/code&gt;
      &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Other impact during the incident&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Other systems that rely on our core proxy were impacted during the incident. This included Workers KV and Cloudflare Access. The team was able to reduce the impact to these systems at 13:04, when a patch was made to Workers KV to bypass the core proxy. Subsequently, all downstream systems that rely on Workers KV (such as Access itself) observed a reduced error rate.Â &lt;/p&gt;
      &lt;p&gt;The Cloudflare Dashboard was also impacted due to both Workers KV being used internally and Cloudflare Turnstile being deployed as part of our login flow.&lt;/p&gt;
      &lt;p&gt;Turnstile was impacted by this outage, resulting in customers who did not have an active dashboard session being unable to log in. This showed up as reduced availability during two time periods: from 11:30 to 13:10, and between 14:40 and 15:30, as seen in the graph below.&lt;/p&gt;
      &lt;p&gt;The first period, from 11:30 to 13:10, was due to the impact to Workers KV, which some control plane and dashboard functions rely upon. This was restored at 13:10, when Workers KV bypassed the core proxy system. The second period of impact to the dashboard occurred after restoring the feature configuration data. A backlog of login attempts began to overwhelm the dashboard. This backlog, in combination with retry attempts, resulted in elevated latency, reducing dashboard availability. Scaling control plane concurrency restored availability at approximately 15:30.&lt;/p&gt;
      &lt;p&gt;Now that our systems are back online and functioning normally, work has already begun on how we will harden them against failures like this in the future. In particular we are:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Hardening ingestion of Cloudflare-generated configuration files in the same way we would for user-generated input&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Enabling more global kill switches for features&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Eliminating the ability for core dumps or other error reports to overwhelm system resources&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Reviewing failure modes for error conditions across all core proxy modules&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Today was Cloudflare's worst outage since 2019. We've had outages that have made our dashboard unavailable. Some that have caused newer features to not be available for a period of time. But in the last 6+ years we've not had another outage that has caused the majority of core traffic to stop flowing through our network.&lt;/p&gt;
      &lt;p&gt;An outage like today is unacceptable. We've architected our systems to be highly resilient to failure to ensure traffic will always continue to flow. When we've had outages in the past it's always led to us building new, more resilient systems.&lt;/p&gt;
      &lt;p&gt;On behalf of the entire team at Cloudflare, I would like to apologize for the pain we caused the Internet today. &lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Time (UTC)&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Status&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell role="head"&gt;
            &lt;p&gt;Description&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;11:05&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Normal.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Database access control change deployed.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;11:28&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Impact starts.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Deployment reaches customer environments, first errors observed on customer HTTP traffic.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;11:32-13:05&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The team investigated elevated traffic levels and errors to Workers KV service.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;The initial symptom appeared to be degraded Workers KV response rate causing downstream impact on other Cloudflare services.&lt;/p&gt;
            &lt;p&gt;Mitigations such as traffic manipulation and account limiting were attempted to bring the Workers KV service back to normal operating levels.&lt;/p&gt;
            &lt;p&gt;The first automated test detected the issue at 11:31 and manual investigation started at 11:32. The incident call was created at 11:35.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;13:05&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Workers KV and Cloudflare Access bypass implemented â impact reduced.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;During investigation, we used internal system bypasses for Workers KV and Cloudflare Access so they fell back to a prior version of our core proxy. Although the issue was also present in prior versions of our proxy, the impact was smaller as described below.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;13:37&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Work focused on rollback of the Bot Management configuration file to a last-known-good version.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;We were confident that the Bot Management configuration file was the trigger for the incident. Teams worked on ways to repair the service in multiple workstreams, with the fastest workstream a restore of a previous version of the file.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;14:24&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Stopped creation and propagation of new Bot Management configuration files.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;We identified that the Bot Management module was the source of the 500 errors and that this was caused by a bad configuration file. We stopped automatic deployment of new Bot Management configuration files.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;14:24&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Test of new file complete.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;We observed successful recovery using the old version of the configuration file and then focused on accelerating the fix globally.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;14:30&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;Main impact resolved. Downstream impacted services started observing reduced errors.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;A correct Bot Management configuration file was deployed globally and most services started operating correctly.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;p&gt;17:06&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;All services resolved. Impact ends.&lt;/p&gt;
          &lt;/cell&gt;
          &lt;cell&gt;
            &lt;p&gt;All downstream services restarted and all operations fully restored.&lt;/p&gt;
          &lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/18-november-2025-outage/"/><published>2025-11-18T23:31:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45974012</id><title>I made a down detector for down detector</title><updated>2025-11-19T12:20:30.233612+00:00</updated><content>&lt;doc fingerprint="7e59a9a7de17484b"&gt;
  &lt;main&gt;
    &lt;p&gt;A tiny independent status checker.&lt;/p&gt;
    &lt;p&gt;Waiting for the latest checks from all regions.&lt;/p&gt;
    &lt;p&gt;Checks by region&lt;/p&gt;
    &lt;p&gt;â&lt;/p&gt;
    &lt;p&gt;Target: downdetector.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://downdetectorsdowndetector.com"/><published>2025-11-19T00:05:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45974681</id><title>Strace-macOS: A clone of the strace command for macOS</title><updated>2025-11-19T12:20:29.716031+00:00</updated><content>&lt;doc fingerprint="3a291a15e86658d0"&gt;
  &lt;main&gt;
    &lt;p&gt;A system call tracer for macOS using the LLDB debugger API.&lt;/p&gt;
    &lt;p&gt;Status: Beta - Core functionality works, but some features are still in development.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Works with SIP enabled - Unlike &lt;code&gt;dtruss&lt;/code&gt;, doesn't require disabling System Integrity Protection&lt;/item&gt;
      &lt;item&gt;Pure Python implementation - No kernel extensions or compiled components&lt;/item&gt;
      &lt;item&gt;Multiple output formats - JSON Lines and strace-compatible text output&lt;/item&gt;
      &lt;item&gt;Syscall filtering - Filter by syscall name or category (&lt;code&gt;-e trace=file&lt;/code&gt;,&lt;code&gt;-e trace=network&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Symbolic decoding - Automatically decodes flags, error codes, and struct fields&lt;/item&gt;
      &lt;item&gt;Color output - Syntax highlighting when output is a TTY&lt;/item&gt;
      &lt;item&gt;Summary statistics - Time/call/error counts with &lt;code&gt;-c&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Run directly
nix run github:Mic92/strace-macos -- ls

# Install to profile
nix profile install github:Mic92/strace-macos&lt;/code&gt;
    &lt;p&gt;strace-macos requires macOS system Python (has LLDB bindings):&lt;/p&gt;
    &lt;code&gt;# Install directly from GitHub
/usr/bin/python3 -m pip install --user git+https://github.com/Mic92/strace-macos

# Then run (if ~/Library/Python/3.x/bin is in PATH)
strace /usr/local/bin/git status  # or any homebrew-installed binary

# Or run directly from repository without installing
git clone https://github.com/Mic92/strace-macos
cd strace-macos
/usr/bin/python3 -m strace_macos /usr/local/bin/git status&lt;/code&gt;
    &lt;code&gt;# Basic usage (use non-system binaries like homebrew or nix-installed)
strace /usr/local/bin/git status

# Output to file
strace -o trace.txt /usr/local/bin/git status

# JSON output
strace --json /usr/local/bin/git status &amp;gt; trace.jsonl

# Filter syscalls by name
strace -e trace=open,close /usr/local/bin/git status

# Filter by category*
strace -e trace=file /usr/local/bin/git status    # All file operations
strace -e trace=network /usr/local/bin/curl https://example.com   # Network syscalls only
strace -e trace=process /usr/local/bin/git status # Process lifecycle syscalls&lt;/code&gt;
    &lt;p&gt;* See Syscall Filtering for all supported categories.&lt;/p&gt;
    &lt;code&gt;strace -p 1234&lt;/code&gt;
    &lt;code&gt;strace -c /usr/local/bin/git status
# % time     seconds  usecs/call     calls    errors syscall
# ------ ----------- ----------- --------- --------- ----------------
#  45.23    0.001234          12       103           read
#  32.10    0.000876           8       110           write
#  ...&lt;/code&gt;
    &lt;p&gt;strace-macos supports filtering syscalls by name or category using the &lt;code&gt;-e trace=&lt;/code&gt; option.&lt;/p&gt;
    &lt;p&gt;Specify one or more syscall names separated by commas:&lt;/p&gt;
    &lt;code&gt;strace -e trace=open,close,read,write /usr/local/bin/git status&lt;/code&gt;
    &lt;p&gt;Use predefined categories to trace groups of related syscalls:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Example Syscalls&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;File operations&lt;/cell&gt;
        &lt;cell&gt;open, close, read, write, stat, unlink&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;network&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Network operations&lt;/cell&gt;
        &lt;cell&gt;socket, connect, send, recv, bind&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;process&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Process lifecycle&lt;/cell&gt;
        &lt;cell&gt;fork, exec, wait, exit, kill&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;memory&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Memory management&lt;/cell&gt;
        &lt;cell&gt;mmap, munmap, brk, mprotect&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;signal&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Signal handling&lt;/cell&gt;
        &lt;cell&gt;signal, sigaction, sigprocmask, kill&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ipc&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Inter-process communication&lt;/cell&gt;
        &lt;cell&gt;pipe, shm_open, msgget, semop&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;thread&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Thread operations&lt;/cell&gt;
        &lt;cell&gt;pthread_create, bsdthread_register&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;time&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Time and timers&lt;/cell&gt;
        &lt;cell&gt;gettimeofday, setitimer, utimes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;sysinfo&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;System information&lt;/cell&gt;
        &lt;cell&gt;sysctl, getpid, getuid, uname&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;security&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Security/MAC operations&lt;/cell&gt;
        &lt;cell&gt;__mac_*, csops, csrctl&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;debug&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Debugging and tracing&lt;/cell&gt;
        &lt;cell&gt;ptrace, kdebug_trace, panic_with_data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;misc&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Miscellaneous syscalls&lt;/cell&gt;
        &lt;cell&gt;ioctl, fcntl, kqueue, connectx&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;# Trace only file operations
strace -e trace=file /usr/local/bin/git status

# Trace only network syscalls
strace -e trace=network /usr/local/bin/curl https://example.com

# Trace process management syscalls
strace -e trace=process /usr/local/bin/git status&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Linux strace&lt;/cell&gt;
        &lt;cell role="head"&gt;strace-macos&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Filter by syscall name&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=open,close&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=open,close&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Filter by category&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=file&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=file&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Negation (&lt;code&gt;!&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=!open&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Regex filtering&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace=/^open/&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Path filtering&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-P /etc/passwd&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FD filtering&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;-e trace-fd=3&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;&lt;code&gt;%desc&lt;/code&gt; category&lt;/cell&gt;
        &lt;cell&gt;✅ FD-related syscalls&lt;/cell&gt;
        &lt;cell&gt;❌ Not yet&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Percent prefix&lt;/cell&gt;
        &lt;cell&gt;✅ &lt;code&gt;%file&lt;/code&gt; or &lt;code&gt;file&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;file&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 12+ (Monterey or later)&lt;/item&gt;
      &lt;item&gt;Apple Silicon (ARM64) - primary platform&lt;/item&gt;
      &lt;item&gt;Intel (x86_64) - work in progress&lt;/item&gt;
      &lt;item&gt;Xcode Command Line Tools (for LLDB)&lt;/item&gt;
      &lt;item&gt;System Python (&lt;code&gt;/usr/bin/python3&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Important: Must use macOS system Python - LLDB bindings don't work with Homebrew/pyenv/Nix Python.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! See CONTRIBUTING.md for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Development environment setup&lt;/item&gt;
      &lt;item&gt;Code style guidelines&lt;/item&gt;
      &lt;item&gt;Testing instructions&lt;/item&gt;
      &lt;item&gt;How to add new syscalls&lt;/item&gt;
      &lt;item&gt;Pull request process&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Current Status: 3/13 tests passing (spawn functionality working)&lt;/p&gt;
    &lt;code&gt;strace-macos (Python CLI)
    ↓
LLDB Python API
    ↓
debugserver (macOS debugging APIs)
    ↓
Target Process
&lt;/code&gt;
    &lt;p&gt;The tracer uses LLDB's Python bindings to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set breakpoints at syscall entry/exit points&lt;/item&gt;
      &lt;item&gt;Read CPU registers to extract syscall arguments&lt;/item&gt;
      &lt;item&gt;Decode arguments symbolically (flags, errno, structs)&lt;/item&gt;
      &lt;item&gt;Format output in strace-compatible or JSON format&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Working:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Spawn and trace new processes ✅&lt;/item&gt;
      &lt;item&gt;Attach to running processes ✅&lt;/item&gt;
      &lt;item&gt;Basic syscall capture (entry/exit) ✅&lt;/item&gt;
      &lt;item&gt;Argument decoding (integers, strings, pointers, buffers, iovecs) ✅&lt;/item&gt;
      &lt;item&gt;Symbolic flag decoding (O_RDONLY, etc.) ✅&lt;/item&gt;
      &lt;item&gt;Error code decoding (ENOENT, etc.) ✅&lt;/item&gt;
      &lt;item&gt;Struct decoding (stat, sockaddr, msghdr, etc.) ✅&lt;/item&gt;
      &lt;item&gt;Syscall filtering by name and category ✅&lt;/item&gt;
      &lt;item&gt;Summary statistics (&lt;code&gt;-c&lt;/code&gt;) ✅&lt;/item&gt;
      &lt;item&gt;JSON and text output formats ✅&lt;/item&gt;
      &lt;item&gt;Color output with syntax highlighting ✅&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Planned:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multi-threaded process support&lt;/item&gt;
      &lt;item&gt;Follow forks (&lt;code&gt;-f&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Negation filtering (&lt;code&gt;-e trace=!open&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Regex filtering (&lt;code&gt;-e trace=/^open/&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Path-based filtering (&lt;code&gt;-P /path&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;FD-based filtering (&lt;code&gt;-e trace-fd=3&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;String truncation control (&lt;code&gt;-s&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Relative/absolute timestamps (&lt;code&gt;-t&lt;/code&gt;,&lt;code&gt;-tt&lt;/code&gt;,&lt;code&gt;-ttt&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;macOS ships with &lt;code&gt;dtruss&lt;/code&gt;, a DTrace-based syscall tracer. However:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Requires disabling System Integrity Protection (SIP)&lt;/item&gt;
      &lt;item&gt;Doesn't work on modern macOS versions without workarounds&lt;/item&gt;
      &lt;item&gt;Limited filtering capabilities&lt;/item&gt;
      &lt;item&gt;No symbolic decoding of arguments&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;strace-macos works with SIP enabled and provides richer output.&lt;/p&gt;
    &lt;p&gt;strace-macos aims for compatibility with Linux strace where possible:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Linux strace&lt;/cell&gt;
        &lt;cell role="head"&gt;strace-macos&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Basic tracing&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Attach to PID&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Syscall filtering*&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Summary stats&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Follow forks&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;⏳&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Symbolic decoding&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;JSON output&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Color output&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;* See Syscall Filtering for detailed feature comparison.&lt;/p&gt;
    &lt;p&gt;MIT License - see LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Jörg Thalheim joerg@thalheim.io&lt;/p&gt;
    &lt;p&gt;For commercial support, please contact Mic92 at joerg@thalheim.io or reach out to Numtide.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CONTRIBUTING.md - Development and contribution guide&lt;/item&gt;
      &lt;item&gt;tests/README.md - Test suite documentation&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Mic92/strace-macos"/><published>2025-11-19T01:18:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45976832</id><title>Exploring the Limits of Large Language Models as Quant Traders</title><updated>2025-11-19T12:20:29.422197+00:00</updated><content/><link href="https://nof1.ai/blog/TechPost1"/><published>2025-11-19T07:36:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45977542</id><title>Multimodal Diffusion Language Models for Thinking-Aware Editing and Generation</title><updated>2025-11-19T12:20:28.852787+00:00</updated><content>&lt;doc fingerprint="732fca743eb04b92"&gt;
  &lt;main&gt;
    &lt;p&gt;While thinking-aware generation aims to improve performance on complex tasks, we identify a critical failure mode where existing sequential, autoregressive approaches can paradoxically degrade performance due to error propagation. To systematically analyze this issue, we propose ParaBench, a new benchmark designed to evaluate both text and image output modalities. Our analysis using ParaBench reveals that this performance degradation is strongly correlated with poor alignment between the generated reasoning and the final image. To resolve this, we propose a parallel multimodal diffusion framework that enables continuous, bidirectional interaction between text and images throughout the entire denoising trajectory. This model, MMaDA-Parallel, is trained with supervised finetuning and then further optimized by Parallel Reinforcement Learning (ParaRL), a novel strategy that applies semantic rewards along the trajectory to enforce cross-modal consistency. Experiments validate that our approach significantly improves cross-modal alignment and semantic consistency, achieving a 6.9% improvement in Output Alignment on ParaBench compared to the state-of-the-art model, Bagel, establishing a more robust paradigm for thinking-aware image synthesis.&lt;/p&gt;
    &lt;p&gt;Architecture of MMaDA-Parallel. During Training, image and text responses are masked and predicted in parallel with a uniform mask predictor. During Sampling, the model performs parallel decoding to generate both image and text responses jointly, enabling continuous cross-modal interaction.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;[2025-11-11] We release our codes and models for MMaDA-Parallel, with two released 8B models MMaDA-Parallel-A and MMaDA-Parallel-M.&lt;/item&gt;
      &lt;item&gt;[2025-11-10] We release our research paper for Parallel Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Our model has been successfully validated on synthetic datasets focusing on environments, still life, architecture, and natural landscapes. Its performance on out-of-distribution inputs—such as human faces or real-world photographic imagery—has not yet been fully explored. We are actively expanding our training corpus to include more diverse datasets.&lt;/p&gt;
    &lt;p&gt;First, start with a torch environment with torch 2.3.1 or higher version, then install the following dependencies:&lt;/p&gt;
    &lt;code&gt;pip install -r requirements.txt
&lt;/code&gt;
    &lt;p&gt;We provide two varients of MMaDA-Parallel with different tokenizers. MMaDA-Parallel-A is trained with tokenizer Amused-VQ, and MMaDA-Parallel-M is trained with tokenizer Magvitv2.&lt;/p&gt;
    &lt;p&gt;You can directly use the local gradio app to experience the parallel generation with MMaDA-Parallel-A:&lt;/p&gt;
    &lt;code&gt;python app.py&lt;/code&gt;
    &lt;p&gt;Or you can use the inference script to generate the parallel generation results:&lt;/p&gt;
    &lt;code&gt;cd MMaDA-Parallel-A
python inference.py \
    --checkpoint tyfeld/MMaDA-Parallel-A \
    --vae_ckpt tyfeld/MMaDA-Parallel-A \
    --prompt "Replace the laptops with futuristic transparent tablets displaying holographic screens, and change the drink to a cup of glowing blue energy drink." \
    --image_path examples/image.png \
    --height 512 \
    --width 512 \
    --timesteps 64 \
    --text_steps 128 \
    --text_gen_length 256 \
    --text_block_length 32 \
    --cfg_scale 0 \
    --cfg_img 4.0 \
    --temperature 1.0 \
    --text_temperature 0 \
    --seed 42 \
    --output_dir output/results_interleave&lt;/code&gt;
    &lt;code&gt;cd MMaDA-Parallel-M
python inference.py interleave_root=./interleave_validation  &lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Release the MMaDA-Parallel code and paper.&lt;/item&gt;
      &lt;item&gt;Evaluation on ParaBench code.&lt;/item&gt;
      &lt;item&gt;Refine MMaDA-Parallel-M and update the corresponding checkpoint.&lt;/item&gt;
      &lt;item&gt;Training code for SFT and ParaRL.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;@article{tian2025mmadaparallel,
  title={MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation},
  author={Tian, Ye and Yang, Ling and Yang, Jiongfan and Wang, Anran and Tian, Yu and Zheng, Jiani and Wang, Haochen and Teng, Zhiyang and Wang, Zhuochen and Wang, Yinjie and Tong, Yunhai and Wang, Mengdi and Li, Xiangtai},
  journal={arXiv preprint arXiv:2511.09611},
  year={2025}
}
&lt;/code&gt;
    &lt;p&gt;This work is heavily based on MMaDA and Lumina-DiMOO. Thanks to all the authors for their great work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/tyfeld/MMaDA-Parallel"/><published>2025-11-19T09:27:17+00:00</published></entry></feed>