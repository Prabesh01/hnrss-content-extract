<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-30T03:56:11.336042+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46418415</id><title>You can't design software you don't work on</title><updated>2025-12-30T03:56:19.613178+00:00</updated><content>&lt;doc fingerprint="fd5fbb5368572389"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;You can't design software you don't work on&lt;/head&gt;
    &lt;p&gt;Only the engineers who work on a large software system can meaningfully participate in the design process. That’s because you cannot do good software design without an intimate understanding of the concrete details of the system. In other words, generic software design advice is typically useless for most practical software design problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Generic software design&lt;/head&gt;
    &lt;p&gt;What is generic software design? It’s “designing to the problem”: the kind of advice you give when you have a reasonable understanding of the domain, but very little knowledge of the existing codebase. Unfortunately, this is the only kind of advice you’ll read in software books and blog posts1. Engineers love giving generic software design advice for the same reason that all technical professionals love “talking shop”. However, you should be very careful about applying generic advice to your concrete day-to-day work problems2.&lt;/p&gt;
    &lt;p&gt;When you’re doing real work, concrete factors dominate generic factors. Having a clear understanding of what the code looks like right now is far, far more important than having a good grasp on general design patterns or principles. For instance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In large codebases, consistency is more important than “good design”. I won’t argue that point here, but I wrote about it at length in Mistakes engineers make in large established codebases.&lt;/item&gt;
      &lt;item&gt;Real codebases are typically full of complex, hard-to-predict consequences. If you want to make your change safely, that typically constrains your implementation choices down to a bare handful of possibilities.&lt;/item&gt;
      &lt;item&gt;Large shared codebases never reflect a single design, but are always in some intermediate state between different software designs. How the codebase will hang together after an individual change is thus way more important than what ideal “north star” you’re driving towards.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a world where you could rewrite the entire system at will, generic software design advice would be much more practical. Some projects are like this! But the majority of software engineering work is done on systems that cannot be safely rewritten. These systems cannot rely on “software design”, but must instead rely on internal consistency and the carefulness of their engineers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Concrete software design&lt;/head&gt;
    &lt;p&gt;What does good software design look like, then?&lt;/p&gt;
    &lt;p&gt;In my experience, the most useful software design happens in conversations between a small group of engineers who all have deep understanding of the system, because they’re the ones working on it every day. These design discussions are often really boring to outsiders, because they revolve around arcane concrete details of the system, not around general principles that any technical person can understand and have an opinion on.&lt;/p&gt;
    &lt;p&gt;The kinds of topic being discussed are not “is DRY better than WET”, but instead “could we put this new behavior in subsystem A? No, because it needs information B, which isn’t available to that subsystem in context C, and we can’t expose that without rewriting subsystem D, but if we split up subsystem E here and here…“.&lt;/p&gt;
    &lt;p&gt;Deep philosophical points about design are rarely important to the discussion. Instead, the most critical contributions point out small misunderstandings of concrete points, like: “oh, you thought B wasn’t available in context C, but we recently refactored C so now we could thread in B if we needed to”.&lt;/p&gt;
    &lt;head rend="h3"&gt;When generic software design is useful&lt;/head&gt;
    &lt;p&gt;Generic software design advice is not useful for practical software design problems, but that doesn’t mean it’s totally useless.&lt;/p&gt;
    &lt;p&gt;Generic software design advice is useful for building brand-new projects. As I argued above, when you’re designing a new feature in an existing system, concrete factors of the system dominate. But when you’re designing a new system, there are no concrete factors, so you can be entirely guided by generic advice.&lt;/p&gt;
    &lt;p&gt;Generic software design advice is useful for tie-breaking concrete design decisions. I don’t think you should start with a generic design, but if you have a few candidate concrete pathways that all seem acceptable, generic principles can help you decide between them.&lt;/p&gt;
    &lt;p&gt;This is particularly true at the level of the entire company. In other words, generic software design advice can help ensure consistency across different codebases. This is one of the most useful functions of an official “software architect” role: to provide a set of general principles so that individual engineers can all tie-break their concrete decisions in the same direction3.&lt;/p&gt;
    &lt;p&gt;Generic software design principles can also guide company-wide architectural decisions. Should we run our services in our own datacenter, or in the cloud? Should we use k8s? AWS or Azure? Once you get broad enough, the concrete details of individual services almost don’t matter, because it’s going to be a huge amount of work either way. Still, even for these decisions, concrete details matter a lot. There are certain things you just can’t do in the cloud (like rely on bespoke hardware setups), or that you can’t do in your own datacenter (like deploy your service to the edge in twelve different regions). If the concrete details of your codebase rely on one of those things, you’ll be in for a bad time if you ignore them when making company-wide architectural decisions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Architects and local minima&lt;/head&gt;
    &lt;p&gt;Those are all good reasons to do generic software design. One bad reason companies do generic software design is that it just sounds like a really good idea to people who aren’t working software engineers. Once you’re doing it, the incentives make it hard to stop. Many tech companies fall into this local minimum.&lt;/p&gt;
    &lt;p&gt;Why not have your highest-paid software engineers spend their time exclusively making the most abstract, highest-impact decisions? You want your structural engineers to be drawing, not laying bricks, after all. I don’t know if structural engineering works like this, but I do know that software engineering doesn’t. In practice, software architecture advice often has to be ignored by the people on the ground. There’s simply no way to actually translate it into something they can implement, in the context of the current system as it exists.&lt;/p&gt;
    &lt;p&gt;However, for a practice that doesn’t work, “have your top engineers just do generic design” is surprisingly robust. Architects don’t have any skin in the game4, because their designs are handed off to actual engineering teams to implement. Because those designs can never be implemented perfectly, architects can both claim credit for successes (after all, it was their design) and disclaim failures (if only those fools had followed my design!)&lt;/p&gt;
    &lt;head rend="h3"&gt;Summary&lt;/head&gt;
    &lt;p&gt;When working on large existing codebases, useful software design discussions are way, way more concrete than many people believe. They typically involve talking about individual files or even lines of code. You thus can’t do useful software design without being intimately familiar with the codebase (in practice, that almost always means being an active contributor).&lt;/p&gt;
    &lt;p&gt;Purely generic architecture is not useless, but its role should be restricted to (a) setting out paved paths for brand new systems, (b) tie-breaking decisions on existing systems, and (c) helping companies make broad technology choices.&lt;/p&gt;
    &lt;p&gt;In my opinion, formal “big-picture software architect” roles that spend all their time laying out the initial designs for projects are doomed to failure. They sound like a good idea (and they’re a good deal for the architect, who can claim credit without risking blame), but they provide very little value to the engineering teams that are tasked with actually writing the code.&lt;/p&gt;
    &lt;p&gt;Personally, I believe that if you come up with the design for a software project, you ought to be responsible for the project’s success or failure. That would rapidly ensure that the people designing software systems are the people who know how to ship software systems. It would also ensure that the real software designers - the ones that have to take into account all the rough edges and warts of the codebase - get credit for the difficult design work they do.&lt;/p&gt;
    &lt;p&gt;edit: this post got some comments on Hacker News. I was surprised to see some commenters disagreeing with my point about consistency. I remember the reception of Mistakes engineers make in large established codebases being quite positive. I was not surprised to see some commenters make the “haha, this is hypocritical because it is itself generic advice” point. I addressed this in the “when generic design is useful” section above.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;I admit I’ve given my own generic software design advice here, here, here, and probably a dozen other places.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;When I say “real work problems”, I’m talking here about impure software engineering: codebases which are intended to solve actual business needs and are thus (a) full of compromises and (b) constantly in a state of change. If you’re working on an elegant single-purpose library or the software for space probes, I suspect much of this advice does not apply.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Short of truly awful decisions, it almost doesn’t matter if those general principles are good or not - as with individual codebases, the benefits of consistency outweigh the benefits of having the “best” possible design.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The architects I’m talking about here, I mean. The job title “architect” covers a great many different kinds of job, including just “very senior engineer doing normal engineering work”. Many architects don’t have an “architect” title at all, and are just senior/staff/distinguished software engineers who have ascended above having to do any actual implementation.&lt;/p&gt;↩&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News. Here's a preview of a related post that shares tags with this one.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Pure and impure software engineering&lt;/p&gt;&lt;p&gt;Why do solo game developers tend to get into fights with big tech engineers? Why do high-profile external hires to large companies often fizzle out? Why is AI-assisted development amazing for some engineers and completely useless for others?&lt;/p&gt;&lt;p&gt;I think it’s because some engineers are doing very different kinds of work to other engineers. Those two types of engineers often assume their counterparts are simply incompetent, but they’re really just working in different fields.&lt;/p&gt;&lt;lb/&gt;Continue reading...&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.seangoedecke.com/you-cant-design-software-you-dont-work-on/"/><published>2025-12-29T07:54:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46419968</id><title>Linux DAW: Help Linux musicians to quickly and easily find the tools they need</title><updated>2025-12-30T03:56:19.073893+00:00</updated><link href="https://linuxdaw.org/"/><published>2025-12-29T12:23:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46419970</id><title>Kidnapped by Deutsche Bahn</title><updated>2025-12-30T03:56:18.858902+00:00</updated><content>&lt;doc fingerprint="5b8d1d547b2d05f1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I Was Kidnapped by Deutsche Bahn and All I Got Was 1.50 EUR&lt;/head&gt;
    &lt;p&gt;If you live in Germany, you have been treated like livestock by Deutsche Bahn (DB). Almost all of my friends have a story: they traveled with DB, got thrown out in the middle of the night in some cow village, and had to wait hours for the next train.&lt;/p&gt;
    &lt;p&gt;I have something better. I was kidnapped.&lt;/p&gt;
    &lt;p&gt;December 24th, 2025. 15:30. Cologne Main Station, Platform 9 D-G.&lt;/p&gt;
    &lt;p&gt;I am taking the RE5 (ID 28521) to my grandmother’s house in Meckenheim. Scheduled departure: 15:32. Scheduled arrival in Bonn: 15:54. From there, the S23 to Meckenheim. A journey of 35 kilometers, or, in DB units, somewhere between forty-five minutes and the heat death of the universe.&lt;/p&gt;
    &lt;p&gt;I wanted to arrive early to spend more time with her. My father, who lives near Troisdorf, was supposed to join us later.&lt;/p&gt;
    &lt;p&gt;I board the train. It is twenty minutes late. I consider this early. At least the train showed up. In DB’s official statistics, a train counts as “on time” if it’s less than six minutes late.1 Cancelled trains are not counted at all.2 If a train doesn’t exist, it cannot be late.&lt;/p&gt;
    &lt;p&gt;The train starts moving. The driver announces there are “issues around Bonn.” He does not specify what kind. No one asks. We have learned not to ask. He suggests we exit at Cologne South and take the subway, or continue to Troisdorf and catch a bus from there.&lt;/p&gt;
    &lt;p&gt;I decide to continue to Troisdorf. My father can just pick me up there and we drive together. The plan adapts.&lt;/p&gt;
    &lt;p&gt;The driver announces the full detour: from Cologne South to Troisdorf to Neuwied to Koblenz. The entire left bank of the Rhine is unavailable. Only then I notice: the driver has been speaking German only. If you were a tourist who got on in Cologne to visit Brühl, thirteen minutes away, you were about to have a very confusing Christmas in Troisdorf.&lt;/p&gt;
    &lt;p&gt;A woman near me is holding chocolates and flowers. She is on the phone with her mother. “Sorry Mama, I’ll be late.” Pause. “Deutsche Bahn.” Pause. Her mother understood.&lt;/p&gt;
    &lt;p&gt;Twenty minutes later. We are approaching Troisdorf. I stand up. I gather my things. My father texts me: he is at the station, waiting.&lt;/p&gt;
    &lt;p&gt;The driver comes back on: “Hello everyone. Apparently we were not registered at Troisdorf station, so we are on the wrong tracks. We cannot stop.”&lt;/p&gt;
    &lt;p&gt;He says this the way someone might say “the coffee machine is broken.”&lt;/p&gt;
    &lt;p&gt;Silence. Laughter. Silence.&lt;/p&gt;
    &lt;p&gt;I watch Troisdorf slide past the window. Somewhere in the parking lot outside the station, my father is sitting in his car, watching his son pass by as livestock.&lt;/p&gt;
    &lt;p&gt;My father calls.&lt;/p&gt;
    &lt;p&gt;“The train couldn’t stop.”&lt;/p&gt;
    &lt;p&gt;“What?”&lt;/p&gt;
    &lt;p&gt;“Next stop is Neuwied.”&lt;/p&gt;
    &lt;p&gt;“Neuwied?” Pause. “That’s in Rheinland-Pfalz.” Pause. “That’s a different federal state.”&lt;/p&gt;
    &lt;p&gt;“Yup.”&lt;/p&gt;
    &lt;p&gt;I was trying to travel 35 kilometers. I was now 63 kilometers from my grandmother’s house. Further away than when I started.&lt;/p&gt;
    &lt;p&gt;There are fifteen stations between Troisdorf and Neuwied. We pass all of them [^6].&lt;/p&gt;
    &lt;p&gt;At some point you stop being a passenger and start being cargo. A cow transporter. Mooohhhhh. A cow transporter going to a cow village. (Germany has a word for this: Kuhdorf. The cows are metaphorical. Usually.) I reached this point around Oberkassel.&lt;/p&gt;
    &lt;p&gt;DB once operated a bus to Llucalcari, a Mallorcan village of seventeen people.3 I wanted to take it home.&lt;/p&gt;
    &lt;p&gt;An English speaker near the doors is getting agitated. “What is happening? Why didn’t we stop?”&lt;/p&gt;
    &lt;p&gt;“We are not registered for this track.”&lt;/p&gt;
    &lt;p&gt;“But where will we stop?”&lt;/p&gt;
    &lt;p&gt;“Neuwied. Fifty-five minutes.”&lt;/p&gt;
    &lt;p&gt;“Fifty-five minutes.” He said it again, quieter. “I am being kidnapped.”&lt;/p&gt;
    &lt;p&gt;My seatmate, who had not looked up from his book in forty minutes, turned a page. “Deutsche Bahn.”&lt;/p&gt;
    &lt;p&gt;I looked up my compensation.4 1.50 EUR. Minimum payout threshold: 4.00 EUR.&lt;/p&gt;
    &lt;p&gt;I had been kidnapped at a loss.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Deutsche Bahn Annual Report 2022: Punctuality - “A stop is considered on time if the scheduled arrival time is exceeded by less than six minutes.” ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bundesrechnungshof Report 2022 - “Komplett ausgefallene Züge werden bei der Pünktlichkeit nicht berücksichtigt.” (Completely cancelled trains are not considered in the punctuality metric.) ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Llucalcari, Mallorca - Mallorca’s smallest village, population 17. Bus route 203 was operated by Autocares Mallorca, an Arriva company and Deutsche Bahn subsidiary, until 2021. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Deutsche Bahn: Deutschlandticket Verspätung Erstattung - Official compensation policy for Deutschlandticket delays. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/"/><published>2025-12-29T12:24:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46420672</id><title>Libgodc: Write Go Programs for Sega Dreamcast</title><updated>2025-12-30T03:56:18.473310+00:00</updated><content>&lt;doc fingerprint="3d8bf719eda53e81"&gt;
  &lt;main&gt;
    &lt;p&gt;Replaces the standard Go runtime with one designed for the Dreamcast's constraints: memory 16MB RAM, CPU single-core SH-4, no operating system. Provides garbage collection, goroutines, channels, and the core runtime functions.&lt;/p&gt;
    &lt;p&gt;Prerequisites: Go 1.25.3+, &lt;code&gt;make&lt;/code&gt;, and &lt;code&gt;git&lt;/code&gt; must be installed.&lt;/p&gt;
    &lt;code&gt;go install github.com/drpaneas/godc@latest
godc setup
godc doctor # to check (optional)&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Note: The&lt;/p&gt;&lt;code&gt;godc&lt;/code&gt;CLI tool is a separate project that handles toolchain setup and builds.&lt;/quote&gt;
    &lt;p&gt;Create and run a project:&lt;/p&gt;
    &lt;code&gt;mkdir myproject &amp;amp;&amp;amp; cd myproject
godc init
# write you main.go and other *.go files
godc build
godc run&lt;/code&gt;
    &lt;p&gt;See the Quick Start Guide for your first program.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Installation — Setup and configuration&lt;/item&gt;
      &lt;item&gt;Quick Start — First program walkthrough&lt;/item&gt;
      &lt;item&gt;Design — Runtime architecture&lt;/item&gt;
      &lt;item&gt;Effective Dreamcast Go — Best practices&lt;/item&gt;
      &lt;item&gt;KOS Wrappers — Calling C from Go&lt;/item&gt;
      &lt;item&gt;Limitations — What doesn't work&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Measured on real hardware (SH-4 @ 200MHz):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Operation&lt;/cell&gt;
        &lt;cell role="head"&gt;Time&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Gosched yield&lt;/cell&gt;
        &lt;cell&gt;~120 ns&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Allocation&lt;/cell&gt;
        &lt;cell&gt;~186 ns&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Buffered channel&lt;/cell&gt;
        &lt;cell&gt;~1.8 μs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Context switch&lt;/cell&gt;
        &lt;cell&gt;~6.4 μs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Unbuffered channel&lt;/cell&gt;
        &lt;cell&gt;~13 μs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Goroutine spawn&lt;/cell&gt;
        &lt;cell&gt;~31 μs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GC pause&lt;/cell&gt;
        &lt;cell&gt;72 μs - 6 ms&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains working programs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;hello&lt;/code&gt;— Minimal program (debug output)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;hello_screen&lt;/code&gt;— Hello World on screen using BIOS font&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;blue_screen&lt;/code&gt;— Minimal graphics&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;input&lt;/code&gt;— Controller input&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;goroutines&lt;/code&gt;— Concurrent bouncing balls&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;channels&lt;/code&gt;— Producer/consumer pattern&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;timer&lt;/code&gt;— Frame-rate independent animation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bfont&lt;/code&gt;— BIOS font rendering&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;filesystem&lt;/code&gt;— Directory browser&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;vmu&lt;/code&gt;— VMU LCD and buzzer&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;brkout&lt;/code&gt;— Breakout clone (GPL v2, port of Jim Ursetto's original)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pong&lt;/code&gt;— Pong clone with 1P/2P mode, particle effects, and AI&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;BSD 3-Clause License. See LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/drpaneas/libgodc"/><published>2025-12-29T13:43:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46422009</id><title>Static Allocation with Zig</title><updated>2025-12-30T03:56:18.165034+00:00</updated><content>&lt;doc fingerprint="3e59ba5f80a316c9"&gt;
  &lt;main&gt;
    &lt;p&gt;Over the past few months I've been chipping away at a small Redis-compatible key/value server called &lt;code&gt;kv&lt;/code&gt;. The goal is to have something (mostly) production-ready, while implementing
only a small subset of commands. The world doesn't necessarily need another key/value store, I'm just interested in
implementing it in Zig and learning about some new (to me) techniques for systems programming.&lt;/p&gt;
    &lt;p&gt;One of those techniques is static memory allocation during initialization. The idea here is that all memory is requested and allocated from the OS at startup, and held until termination. I first heard about this while learning about TigerBeetle, and they reference it explicitly in their development style guide dubbed "TigerStyle".&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;All memory must be statically allocated at startup. No memory may be dynamically allocated (or freed and reallocated) after initialization. This avoids unpredictable behavior that can significantly affect performance, and avoids use-after-free. As a second-order effect, it is our experience that this also makes for more efficient, simpler designs that are more performant and easier to maintain and reason about, compared to designs that do not consider all possible memory usage patterns upfront as part of the design.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Although, this isn't as straightforward as it might sound at first. The first question that comes to mind might be: "How much memory do I allocate?" Of course, the answer depends on the system. If we're writing a server, how many concurrent connections do we allow? How much space is each connection allowed to work with? How much data do we expect to process at any given time? Are there limits in response size? Do we need all the data at once, or can it streamed in some fashion?&lt;/p&gt;
    &lt;p&gt;These are all questions that depend on the nature of the system and the context in which it will operate. I believe that going through the exercise of answering these questions is ultimately a good thing, as it seems to have a strong possibility of resulting in more stable systems, and forces us to understand the nature of our program at a deeper level.1&lt;/p&gt;
    &lt;p&gt;On the language front, I feel like Zig is currently the best option out there for doing this with relative ease, considering its design choices around explicit memory allocation and the &lt;code&gt;std.mem.Allocator&lt;/code&gt; interface, which allows
the standard library to ship with a variety of different allocators.&lt;/p&gt;
    &lt;p&gt;Let's take a look at how we can manage static allocation in &lt;code&gt;kv&lt;/code&gt;, considering three areas of request handling in
sequence: connection handling, command parsing, and key/value storage.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A lot of this is pretty new to me, and I'm still wrestling with all these concepts. (And learning Zig!) I'm sure there are better ways of handling this stuff. I'm presenting this as one possible implementation completed as a learning exercise. I'll speak more about the trade-offs and where I think it can go further at the end of this post.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Connection Handling&lt;/head&gt;
    &lt;p&gt;The first thing we have to consider is how data comes into the system, which we'll maintain through the concept of a &lt;code&gt;Connection&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;A connection represents the communication to a particular client that wants to access the key/value store. Since we're using &lt;code&gt;io_uring&lt;/code&gt; for asynchronous I/O, we have to keep some information around through the life-cycle of
a request, so the kernel can use it. The space for that information is what we'll statically allocate and re-use across
different connections as they come and go.&lt;/p&gt;
    &lt;code&gt;const Connection = struct {
	completion: Completion = undefined,
	client: posix.socket_t = undefined,
	
	recv_buffer: *ByteArray,
	send_buffer: *ByteArray,
};
&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Connections also must maintain something called a "completion". This detail is related to integration with&lt;/p&gt;&lt;code&gt;io_uring&lt;/code&gt;, the full details of which are outside the scope of this post. There are some good resources here and here. I also took some inspiration from TigerBeetle's IO module.&lt;/quote&gt;
    &lt;p&gt;During initialization, we create three pools: one for the Connection structs themselves, one for receive buffers (requests), and one for send buffers (responses). When a request comes in to the server, a Connection is pulled from a &lt;code&gt;std.heap.MemoryPool&lt;/code&gt;, and then two buffers are associated with that &lt;code&gt;Connection&lt;/code&gt;. The buffers are
implemented as &lt;code&gt;ByteArray&lt;/code&gt; structs, which are in turn allocated as part of a &lt;code&gt;ByteArrayPool&lt;/code&gt;. The &lt;code&gt;ByteArrayPool&lt;/code&gt;
is custom and uses a free list to keep track of which buffers are available
to reserve for a new connection.&lt;/p&gt;
    &lt;code&gt;const ConnectionPool = struct {
    const Pool = std.heap.MemoryPoolExtra(Connection, .{ .growable = false });

    recv_buffers: ByteArrayPool,
    send_buffers: ByteArrayPool,

    connections: Pool,

    fn init(
        config: Config,
        gpa: std.mem.Allocator,
    ) !ConnectionPool {
        const allocation = config.allocation();
        const recv_size = allocation.connection_recv_size;
        const send_size = allocation.connection_send_size;

        const pool = try Pool.initPreheated(gpa, config.connections_max);
        const recv_buffers = try ByteArrayPool.init(gpa, config.connections_max, recv_size);
        const send_buffers = try ByteArrayPool.init(gpa, config.connections_max, send_size);

        return .{
            .recv_buffers = recv_buffers,
            .send_buffers = send_buffers,
            .connections = pool,
        };
    }
	
...
};
&lt;/code&gt;
    &lt;p&gt;At runtime, connections are created and destroyed (marked as available) using these pools and no actual allocation needs to happen. If no &lt;code&gt;Connection&lt;/code&gt; is available in the pool, the request is rejected and the client will have to try again.&lt;/p&gt;
    &lt;p&gt;This does mean that the server must be configured with an upper limit on the number of connections. Each connection must also have a limit on how much data it can receive and send.&lt;/p&gt;
    &lt;p&gt;At first this might seem limiting, but in practice, it creates a more robust system. Databases in particular will enforce a limit on the number of active connections for that exact reason! For a backend, networked system like &lt;code&gt;kv&lt;/code&gt;,
I would say something like 1000 active connections is a pretty reasonable limit. For a public facing system you'd
likely want more. Of course, this should all be configurable by the user.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;Config&lt;/code&gt; struct given to the &lt;code&gt;ConnectionPool&lt;/code&gt; represents these user-configured options. Note that the &lt;code&gt;Config&lt;/code&gt;
struct has a method &lt;code&gt;.allocation()&lt;/code&gt; which is computed after the options have been set. In this case,
the &lt;code&gt;connection_recv_size&lt;/code&gt; and &lt;code&gt;connection_send_size&lt;/code&gt; depend on other options, such as &lt;code&gt;config.key_count&lt;/code&gt; and
&lt;code&gt;config.key_size_max&lt;/code&gt;. We'll revisit those later.&lt;/p&gt;
    &lt;p&gt;Now that data can get into the system, the next step is to parse out Redis commands.&lt;/p&gt;
    &lt;head rend="h2"&gt;Command Parsing&lt;/head&gt;
    &lt;p&gt;In an attempt to be compatible with Redis (at least a very small subset of it), &lt;code&gt;kv&lt;/code&gt; has to parse incoming commands
following the Redis serialization protocol ("RESP") format.&lt;/p&gt;
    &lt;p&gt;Here's an example of an incoming &lt;code&gt;GET key&lt;/code&gt; command.&lt;/p&gt;
    &lt;code&gt;*2\r\n$3\r\nGET\r\n$3\r\nkey\r\n
&lt;/code&gt;
    &lt;p&gt;I won't go into detail on how these commands are structured, the RESP document will do a much better job there. Basically, what we're looking at is "Here's an array with 2 elements. The first element has 3 characters, with the content &lt;code&gt;GET&lt;/code&gt; and the second element has 3 characters, with the contenhttps://github.com/nickmonad/kvt &lt;code&gt;key&lt;/code&gt;."&lt;/p&gt;
    &lt;p&gt;In order to parse this command, we need to look at the buffer that contains the request data, create some kind of iterator over that buffer, and split each entry on the CRLF &lt;code&gt;\r\n&lt;/code&gt; byte sequence. Here's the signature for &lt;code&gt;parse&lt;/code&gt;,
the function that does just that.&lt;/p&gt;
    &lt;code&gt;pub fn parse(config: Config, alloc: std.mem.Allocator, buf: []const u8) !Command
&lt;/code&gt;
    &lt;p&gt;The allocator is used to create some book-keeping structure as we parse through the command. We need to create a list of &lt;code&gt;[]const u8&lt;/code&gt; slices that points into the whole buffer and then is given to a command's &lt;code&gt;parse()&lt;/code&gt; function, once
we know the command. This has the benefit of being a "zero copy" approach to parsing. No request data needs to be copied,
only pointed to.&lt;/p&gt;
    &lt;p&gt;Zig's &lt;code&gt;std.heap.FixedBufferAllocator&lt;/code&gt; is perfect for this kind of operation. During initialization, we ask for buffer
space from a general purpose allocator, and pass it to the &lt;code&gt;FixedBufferAllocator&lt;/code&gt;. This allocator works as "bump" allocator,
where each internal allocation happens in a linear fashion, up to the amount of available space. The trade-off here is
that memory allocated within the fixed buffer can't be free'd directly. Instead, the entire buffer is reset after use,
which simply resets an index back to &lt;code&gt;0&lt;/code&gt;. (Just about as cheap as an operation can get!)&lt;/p&gt;
    &lt;p&gt;Since our server is single-threaded2 and processes one request at a time, we can re-use this &lt;code&gt;FixedBufferAllocator&lt;/code&gt;
across every request. After the request is processed, the response is copied to a &lt;code&gt;Writer&lt;/code&gt; object backed by the
connection's &lt;code&gt;send&lt;/code&gt; buffer and the &lt;code&gt;FixedBufferAllocator&lt;/code&gt; is reset for the next request.&lt;/p&gt;
    &lt;p&gt;Knowing how much space to give the &lt;code&gt;FixedBufferAllocator&lt;/code&gt; depends again on our system configuration. We need space for
the &lt;code&gt;ArrayList&lt;/code&gt; of parsed command items, and space for any copied list items that are written back as a response during
command execution. Parsing must be able to support the largest possible command (a list &lt;code&gt;PUSH&lt;/code&gt; of maximum size/length) and
copying has to support the largest possible response (again, a maximally sized list).&lt;/p&gt;
    &lt;p&gt;Copying has the extra consideration that we have to actually store the copied list items, which are duplicated when read from the key/value store. During parsing, we just need to keep slices into the request buffer. For the copied items, we need to keep a list of slices that point to the items, and the items themselves. As long as we give the &lt;code&gt;FixedBufferAllocator&lt;/code&gt; space, we can use it for all these (sub-)allocations.&lt;/p&gt;
    &lt;code&gt;pub const Runner = struct {
    config: Config,
    fba: std.heap.FixedBufferAllocator,
    kv: *Store,

    pub fn init(config: Config, gpa: std.mem.Allocator, kv: *Store) !Runner {
        const L = config.list_length_max;
        const V = config.val_size_max;

        // ArrayList([]const u8) of largest possible command.
        // "[L/R]PUSH list item1 item2 ... itemL"
        const parse_cap = (1 + 1 + L);
        const parse_size: u64 = (parse_cap * @sizeOf([]const u8));

        // ArrayList([]const u8) pointing to duplicated values.
        const copy_size = (L * @sizeOf([]const u8));
        const copy_data = (L * V);

        const fba_size: u64 = parse_size + copy_size + copy_data;
        const buffer = try gpa.alloc(u8, fba_size);
        const fba = std.heap.FixedBufferAllocator.init(buffer);

        return .{
            .config = config,
            .fba = fba,
            .kv = kv,
        };
    }
...
};
&lt;/code&gt;
    &lt;p&gt;The underlying &lt;code&gt;Store&lt;/code&gt; will use the &lt;code&gt;FixedBufferAllocator&lt;/code&gt; to allocate an &lt;code&gt;ArrayList&lt;/code&gt; of fixed capacity
(determined by &lt;code&gt;config.list_length_max&lt;/code&gt;) and then use the remaining space in the allocator for the copied data.&lt;/p&gt;
    &lt;p&gt;Hopefully all is clear so far! Now we can move on to the core of the system: key/value storage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key/Value Storage&lt;/head&gt;
    &lt;p&gt;Perhaps obviously, the fundamental data structure in &lt;code&gt;kv&lt;/code&gt; is a hash map, used to associate user provided keys with
user provided values.&lt;/p&gt;
    &lt;p&gt;Without looking too closely at the standard library, if you grab one of the provided hash map implementations, it will accept a &lt;code&gt;std.mem.Allocator&lt;/code&gt; and hold onto the allocator for the lifetime of the map. When a key/value pair
is added to the map, it will use that same allocator and request the appropriate amount of memory to store that data.
This won't work for our case though, since we need to control allocation prior to adding any data to the map.&lt;/p&gt;
    &lt;p&gt;Fortunately, Zig also provides an "unmanaged" version of a hash map. Generally, these unmanaged versions of data structures in the standard library mean that an allocator is not held by the structure itself. It's up to us to provide that allocator when needed. A cool trick we can play with an unmanaged map is ask it to ensure it has enough capacity up front, and then "assume" that capacity during runtime when adding data to it. The hashing and internal details are still handled by the map.&lt;/p&gt;
    &lt;code&gt;var map: std.StringHashMapUnmanaged(Value) = .empty;
try map.ensureTotalCapacity(gpa, capacity);
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;ensure&lt;/code&gt; operation can fail with &lt;code&gt;error.OutOfMemory&lt;/code&gt;, which is OK during initialization. But, assuming this succeeds,
we no longer need to pass an allocator when we store data in the map.&lt;/p&gt;
    &lt;code&gt;store.map.putAssumeCapacity(key, value);
&lt;/code&gt;
    &lt;p&gt;This could in theory fail, in which case there would an assertion failure. It's ultimately up to us to check against the map's available capacity before calling this function. But, again, no allocation is required.&lt;/p&gt;
    &lt;p&gt;Since the map itself doesn't do any allocation at runtime, we have to provide space for incoming keys and values. We'll reuse the same &lt;code&gt;ByteArrayPool&lt;/code&gt; implementation that we used for connection buffers. Basically, we have a big space
allocated for keys and values and the hash map just maintains an association of pointers from keys to values.
The key/value data isn't literally stored "in the map." The allocation that happens in &lt;code&gt;ensureTotalCapacity&lt;/code&gt; is for
the internal book-keeping structure of the map, not for the user data.&lt;/p&gt;
    &lt;head rend="h3"&gt;Navigating the map&lt;/head&gt;
    &lt;p&gt;At the highest level, the primary challenge with storing keys and values in a statically allocated map is that we could get poor utilization of the allocated space, especially when we need to support keys pointed at lists as values.&lt;/p&gt;
    &lt;p&gt;To illustrate this, let's say our map is configured to allocate space for 5 keys and 5 values. If each key maps to one value, we get perfect utilization. At the other extreme, if one key maps to a value containing a list of 5 elements, we have to use all the allocated value space for this one key, preventing other keys from using any value space, causing the map to be "biased". The store wouldn't be able to hold any more key/value pairs, even though there is allocated memory "on the table."&lt;/p&gt;
    &lt;p&gt;Basically, the only way to mitigate this is to make sure there's enough allocated space for every key to hold a list of maximum size. This definitely inflates the amount of space we have to allocate, but the alternative is a system that doesn't support its configured properties. Every key must be able to store a list of maximum size, even if they don't during actual use.&lt;/p&gt;
    &lt;p&gt;Another issue with static allocation in the context of a map is dealing with map deletions. Our &lt;code&gt;std.StringHashMapUnmanaged&lt;/code&gt; structure uses open-addressing and linear probing to place keys in the map when hash
collisions occur. Deletions are tricky because they can break the map's ability to know if a key is actually present
in the map. To handle this, a "tombstone" technique is used to mark a space as logically (but not physically) deleted
in order to preserve accurate lookups.&lt;/p&gt;
    &lt;p&gt;There's a lot more to figure out here, but it's my understanding that a map will have to periodically rehash the keys in order to reclaim space if too many tombstones pile up. When this occurs is still a bit of mystery to me. If it occurs when the map needs to grow to accommodate more key/value pairs, we'll never actually trigger that condition in a static context. If it occurs at some other point, based on number of keys compared to capacity, perhaps that could work. Or maybe, it's up to us to call &lt;code&gt;rehash()&lt;/code&gt; whenever it appears there is no space left,
and try the operation again.&lt;/p&gt;
    &lt;p&gt;All of this considered, I think a custom map implementation is more appropriate for the context of static allocation. This current implementation proves the concept, but definitely leaves room for improvement!&lt;/p&gt;
    &lt;head rend="h2"&gt;Revisiting allocation size&lt;/head&gt;
    &lt;p&gt;Now that we have a method for statically allocating space for these three components (connections, parsing, and storage), we can finally answer the first question: How much space do we allocate?&lt;/p&gt;
    &lt;p&gt;In this current iteration of &lt;code&gt;kv&lt;/code&gt;, the answer can really only be determined after the fact, once configuration has
been set and all the allocations have been made. There are five options that can be configured by the user,
and two derived properties based on those options.&lt;/p&gt;
    &lt;code&gt;pub const Config = struct {
    /// Allocation is a calculated set of values (in bytes), based on the given configuration.
    /// This informs static allocation requested at initialization.
    pub const Allocation = struct {
        connection_recv_size: u64,
        connection_send_size: u64,
    };

    /// Maximum number of concurrent connections.
    connections_max: u32,

    /// Key count is the number of possible keys we can store.
    /// Internally, the store will allocate (key_count * list_length_max) number
    /// of values, such that each key could support the maximum number of list elements.
    key_count: u32,

    /// The maximum allowable key size in bytes.
    key_size_max: u32,
    /// The maximum allowable value size in bytes.
    val_size_max: u32,

    /// The maximum allowable length for a list as a value.
    list_length_max: u32,

    pub fn allocation(config: Config) Allocation {
		// ... calculate recv and send size ....
		
        return .{
            .connection_recv_size = connection_recv_size,
            .connection_send_size = connection_send_size,
        };
    }
};
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;connection_recv_size&lt;/code&gt; and &lt;code&gt;connection_send_size&lt;/code&gt; properties of &lt;code&gt;Allocation&lt;/code&gt; depend on some details of the
RESP protocol, but is mostly informed by our user configuration. In the interest of wrapping this post up,
I'll gloss over those details, and encourage you to check out &lt;code&gt;src/config.zig&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This &lt;code&gt;Config&lt;/code&gt; struct doesn't directly specify every aspect of allocation, but it does provide the basis for it.
Something not listed in the &lt;code&gt;Config&lt;/code&gt; struct directly is the "list item pool", part of the key/value &lt;code&gt;Store&lt;/code&gt; struct.
When keys point to lists as values, there is a linked list backing that value in the hash map, and we need a pool of
structs to assist in the construction and iteration of that linked list.&lt;/p&gt;
    &lt;p&gt;With some reasonable configuration options set, let's see just how much memory we allocate!&lt;/p&gt;
    &lt;code&gt;$ zig build run
config
  connections_max = 1000
  key_count       = 1000
  key_size_max    = 1024
  val_size_max    = 4096
  list_length_max = 50
allocation
  connection_recv_size = 206299
  connection_send_size = 205255
map capacity = 2048, map size = 0, available = 1638
total_requested_bytes = 748213015
ready!
&lt;/code&gt;
    &lt;p&gt;Everything here is measured in bytes, so we're looking at approximately &lt;code&gt;750 MB&lt;/code&gt; of memory for the given configuration.
&lt;code&gt;total_requested_bytes&lt;/code&gt; is a feature of Zig's &lt;code&gt;std.heap.DebugAllocator&lt;/code&gt;. The exact number of bytes will be different
on each run, although it will hover around that value. I think the reason for this is how Zig requests pages of
memory from the OS. It won't always be the same and the OS is very likely doing some fancy book-keeping of its own.&lt;/p&gt;
    &lt;p&gt;If you play around with the configuration options and see how &lt;code&gt;total_requested_bytes&lt;/code&gt; changes, it might be
surprising just how much memory is allocated up-front, before any of it is actually used! For example, if we
double &lt;code&gt;val_size_max&lt;/code&gt; to &lt;code&gt;8192&lt;/code&gt; and &lt;code&gt;list_length_max&lt;/code&gt; to &lt;code&gt;100&lt;/code&gt;, we're looking at about &lt;code&gt;2.8 GB&lt;/code&gt; of allocated memory.&lt;/p&gt;
    &lt;p&gt;In the context of modern servers, this isn't a lot, but it can quickly grow as we adjust these parameters. Should we be asking ourselves: Is this inefficient? What if we don't use all that memory?&lt;/p&gt;
    &lt;p&gt;Like all good engineering decisions, we have to consider them in the context of the problem we're trying to solve, and the guarantees we expect from our systems. With this design, ensuring that each request and each key/value pair can utilize the maximum configured space, seems like a worthy trade-off to make.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;Like most projects, this one took a lot longer than I expected! Trying to incorporate both &lt;code&gt;io_uring&lt;/code&gt; and
static allocation was something I had never done before, but I'm pretty happy with the result.&lt;/p&gt;
    &lt;p&gt;I'm looking forward to improving the internal hash map to better fit a static context, consider alternative allocator implementations to improve memory utilization, and incorporate fuzz testing to find the limits of the system.&lt;/p&gt;
    &lt;p&gt;Checkout the code on GitHub!&lt;/p&gt;
    &lt;head rend="h3"&gt;Notes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;At the risk of stating the obvious, these limits can (and likely should) be configured at runtime by the user. These aren't values that have to be set at compile time and enforced upon all users in every context, although some might be. Again, it depends on which part of the system is using the memory. The point is that once the program starts it will allocate memory, but after that, it does not. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Going with a single-threaded design simplifies a lot! Even though processing in&lt;/p&gt;&lt;code&gt;kv&lt;/code&gt;is single-threaded, it still enjoys the benefits of I/O concurrency via&lt;code&gt;io_uring&lt;/code&gt;. The kernel handles writing responses back out to clients and waiting for that operation to complete, so we don't have to worry (as much) about slow clients. ↩&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nickmonad.blog/2025/static-allocation-with-zig-kv/"/><published>2025-12-29T16:07:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46423521</id><title>A production bug that made me care about undefined behavior</title><updated>2025-12-30T03:56:18.062036+00:00</updated><content>&lt;doc fingerprint="9a79d8188a871a98"&gt;
  &lt;main&gt;&lt;p&gt;Published on 2025-12-27&lt;/p&gt;&lt;p&gt;Discussions: /r/programming, lobsters.&lt;/p&gt;&lt;p&gt;Years ago, I maintained a big C++ codebase at my day job. This product was the bread winner for the company and offered a public HTTP API for online payments. We are talking billions of euros of processed payments a year.&lt;/p&gt;&lt;p&gt;I was not a seasoned C++ developer yet. I knew about undefined behavior of course, but it was an abstract concept, something only beginners fall into. Oh boy was I wrong.&lt;/p&gt;&lt;p&gt;Please note that I am not and never was a C++ expert, and it's been a few years since I have been writing C++ for a living, so hopefully I got the wording and details right, but please tell me if I did not.&lt;/p&gt;&lt;p&gt;In this article I always say 'struct' when I mean 'struct or class'.&lt;/p&gt;&lt;p&gt;So, one day I receive a bug report. There is this HTTP endpoint that returns a simple response to inform the client that the operation either succeeded or had an error:&lt;/p&gt;&lt;code&gt;{
  "error": false,
  "succeeded": true,
}
&lt;/code&gt;&lt;p&gt;or&lt;/p&gt;&lt;code&gt;{
  "error": true,
  "succeeded": false,
}

&lt;/code&gt;&lt;p&gt;The actual format was probably not JSON, it was probably form encoded, I cannot exactly remember, but that does not matter for this bug.&lt;/p&gt;&lt;p&gt;This data model is not ideal but that's what the software did. Obviously, either &lt;code&gt;error&lt;/code&gt; or &lt;code&gt;succeeded&lt;/code&gt; is set but not both or neither (it's a XOR).&lt;/p&gt;&lt;p&gt;Anyway, the bug report says that the client received this reply:&lt;/p&gt;&lt;code&gt;{
  "error": true,
  "succeeded": true
}
&lt;/code&gt;&lt;p&gt;Hmm ok. That should not be possible, it's a bug indeed.&lt;/p&gt;&lt;p&gt;I now look at the code. It's all in one big function, and it's doing lots of database operations, but the shape of the code is very simple:&lt;/p&gt;&lt;code&gt;struct Response {
  bool error;
  bool succeeded;

  std::string data;
};

void handle() {
  Response response;
  
  try {
    // [..] Lots of database operations *not* touching `response`.

    response.succeeded = true;
  } catch(...) {
    response.error = true;
  }
  response.write();
}
&lt;/code&gt;&lt;p&gt;Here is a godbolt link with roughly this code.&lt;/p&gt;&lt;p&gt;There's only one place that sets the &lt;code&gt;succeeded&lt;/code&gt; field. And only one that sets the &lt;code&gt;error&lt;/code&gt; field. No other place in the code touches these two fields.&lt;/p&gt;&lt;p&gt;So now I am flabbergasted. How is that possible that both fields are true? The code is straightforward. Each field is only set once and exclusively. It should be impossible to have both fields with the value &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;At this point, my C developer spider senses are tingling: is &lt;code&gt;Response response;&lt;/code&gt; the culprit? It has to be, right? In C, that's clear undefined behavior to read fields from &lt;code&gt;response&lt;/code&gt;: The C struct is not initialized.&lt;/p&gt;&lt;p&gt;But right after, I stumble upon official C++ examples that use this syntax. So now I am confused. C++ initialization rules are different from C, after all.&lt;/p&gt;&lt;p&gt;Cue a training montage with 80's music of me reading the C++ standard for hours. The short answer is: yes, the rules are different (enough to fill a book, and also they vary by C++ version) and in some conditions, &lt;code&gt;Response response;&lt;/code&gt; is perfectly fine. In some other cases, this is undefined behavior.&lt;/p&gt;&lt;p&gt;In a nutshell: The default initialization rule applies when a variable is declared without an initializer. It's quite complex but I'll try to simplify it here.&lt;/p&gt;&lt;p&gt;Default initialization occurs under certain circumstances when using the syntax &lt;code&gt;T object;&lt;/code&gt; :&lt;/p&gt;&lt;code&gt;T&lt;/code&gt; is a non struct, non array type, e.g. &lt;code&gt;int a;&lt;/code&gt;, no initialization is performed at all. This is obvious undefined behavior.&lt;code&gt;T&lt;/code&gt; is an array, e.g. &lt;code&gt;std::string a[10];&lt;/code&gt;, this is fine: each element is default-initialized. But note that some types do not have default initialization, such as &lt;code&gt;int&lt;/code&gt;: &lt;code&gt;int a[10]&lt;/code&gt; would leave each element uninitialized.&lt;code&gt;T&lt;/code&gt; is a POD (Plain Old Data, pre C++11. The wording in the standard changed with C++11 but the idea remains under the term Trivially Default Constructible) struct, e.g. &lt;code&gt;Foo foo;&lt;/code&gt; no initialization is performed at all. This is akin to doing &lt;code&gt;int a;&lt;/code&gt; and then reading &lt;code&gt;a&lt;/code&gt;. This is obvious undefined behavior.&lt;code&gt;T&lt;/code&gt; is a non-POD struct, e.g. &lt;code&gt;Bar bar;&lt;/code&gt; the default constructor is called, and it is responsible for initializing all fields. It is easy to miss one, or even forget to implement a default constructor entirely, leading to undefined behavior.&lt;p&gt;It's important to distinguish the first and last case: in the first case, no call to the default constructor is emitted by the compiler. In the last case, the default constructor is called. If no default constructor is declared in the struct, the compiler generates one for us, and calls it. This can be confirmed by inspecting the generated assembly.&lt;/p&gt;&lt;p&gt;With this bug, we are in the last case: the &lt;code&gt;Response&lt;/code&gt; type is a non-POD struct (due to the &lt;code&gt;std::string data&lt;/code&gt; field), so the default constructor is called. &lt;code&gt;Response&lt;/code&gt; does not implement a default constructor. This means  that the compiler generates a default constructor for us, and in this generated code, each struct field is default initialized. So, the &lt;code&gt;std::string&lt;/code&gt; constructor is called for the &lt;code&gt;data&lt;/code&gt; field and all is well. Except, the other two fields are not initialized in any way. Oops.&lt;/p&gt;&lt;p&gt;Here is a quick summary:&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Type&lt;/cell&gt;&lt;cell role="head"&gt;Example&lt;/cell&gt;&lt;cell role="head"&gt;Result (Default Init)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Primitive (int, bool, etc)&lt;/cell&gt;&lt;cell&gt;int x;&lt;/cell&gt;&lt;cell&gt;Indeterminate (Garbage value)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;POD / Trivial Struct&lt;/cell&gt;&lt;cell&gt;Point p;&lt;/cell&gt;&lt;cell&gt;Indeterminate (All fields garbage)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Array of Objects&lt;/cell&gt;&lt;cell&gt;std::string x[10];&lt;/cell&gt;&lt;cell&gt;Safe (All strings initialized)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Array of Primitives&lt;/cell&gt;&lt;cell&gt;int x[10];&lt;/cell&gt;&lt;cell&gt;Indeterminate (All garbage)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Non-Trivial Struct&lt;/cell&gt;&lt;cell&gt;Response r;&lt;/cell&gt;&lt;cell&gt;Calls Default Constructor (Structs ok, primitives garbage)&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Any Type (Braces)&lt;/cell&gt;&lt;cell&gt;T obj{};&lt;/cell&gt;&lt;cell&gt;Value Initialized (Safe / Zeroed)&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Thus, the only way to fix the struct without having to fix all call sites is to implement a default constructor that properly initializes every field:&lt;/p&gt;&lt;code&gt;struct Response {
  bool error;
  bool succeeded;

  std::string data;

  Response(): error{false}, succeeded{false}, data{} 
  {
  }
};
&lt;/code&gt;
&lt;p&gt;Here is a godbolt link with this code.&lt;/p&gt;&lt;p&gt;Of course, due to the rule of 6 (when I started to learn C++ it was 3), we now have to implement the default destructor, the default move constructor etc etc etc.&lt;/p&gt;&lt;p&gt;Alternatively, we can define default values for the fields in the struct definition and avoid defining a default constructor:&lt;/p&gt;&lt;code&gt;struct Response {
  bool error = false;
  bool succeeded = false;

  std::string data;
}
&lt;/code&gt;
&lt;p&gt;This way, the default constructor generated by the compiler will initialize all the fields.&lt;/p&gt;&lt;p&gt;My fix at the time was to simply change the call site to:&lt;/p&gt;&lt;code&gt;  Response response{};
&lt;/code&gt;
&lt;p&gt;Here is a godbolt link with this code.&lt;/p&gt;&lt;p&gt;That forces zero initialization of the &lt;code&gt;error&lt;/code&gt; and &lt;code&gt;succeeded&lt;/code&gt; fields as well as default initialization of the &lt;code&gt;data&lt;/code&gt; field. And no need to change the struct definition.&lt;/p&gt;&lt;p&gt;This was my recommendation to my teammates at the time: do not tempt the devil, just always zero initialize when declaring a variable.&lt;/p&gt;&lt;p&gt;It is important to note that in some cases, the declaration syntax &lt;code&gt;Response response;&lt;/code&gt; is perfectly correct, provided that:&lt;/p&gt;&lt;p&gt;Then, the default constructor of the struct is invoked, which invokes the default constructor of each field.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;code&gt;struct Bar {
  std::string s;
  std::vector&amp;lt;std::string&amp;gt; vec;
};

int main() {
  Bar bar;

  // Prints: s=`` v.len=0
  // No undefined behavior.
  printf("s=%s v.len=%zu\n", bar.s.c_str(), bar.vec.size());
}
&lt;/code&gt;
&lt;p&gt;But to know that, you need to inspect each field (recursively) of the struct, or assume that every default constructor initializes each field.&lt;/p&gt;&lt;p&gt;Finally, it's also worth noting that it is only undefined behavior to read an uninitialized value. Simply having uninitialized fields is not undefined behavior. If the fields are never read, or written to with a known value, before being read, there is no undefined behavior.&lt;/p&gt;&lt;p&gt;The compiler (&lt;code&gt;clang&lt;/code&gt;) does not catch this issue even with all warnings enabled. This is frustrating because the compiler happily generates, and calls, a default constructor that does not initialize all the fields. So, the caller is expected to set all the uninitialized fields to some value manually? This is nonsense to me.&lt;/p&gt;&lt;p&gt;&lt;code&gt;clang-tidy&lt;/code&gt; catches the issue. However at the time it was imperfect, quoting my notes from back then:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;clang-tidy&lt;/code&gt;reports this issue when trying to pass such a variable as argument to a function, but that's all. We want to detect all problematic locations, even when the variable is not passed to a function. Also,&lt;code&gt;clang-tidy&lt;/code&gt;only reports one location and exits.&lt;/quote&gt;&lt;p&gt;But now, it seems it has improved, and reports all problematic locations, and not only in function calls, which is great.&lt;/p&gt;&lt;p&gt;I also wrote in my notes at the time that &lt;code&gt;cppcheck&lt;/code&gt; 'spots this without issues', but when I try it today, it does not spot anything even with &lt;code&gt;--enable=all&lt;/code&gt;. So, maybe it's a regression, or I am not using it correctly.&lt;/p&gt;&lt;p&gt;Most experienced C or C++ developers are probably screaming at their screen right now, thinking: just use Address Sanitizer (or ASan for short)!&lt;/p&gt;&lt;p&gt;Let's try it on the problematic code:&lt;/p&gt;&lt;code&gt;$ clang++ main.cpp -Weverything -std=c++11 -g -fsanitize=address,undefined -Wno-padded
$ ./a.out
a.out(46953,0x1f7f4a0c0) malloc: nano zone abandoned due to inability to reserve vm space.
main.cpp:21:41: runtime error: load of value 8, which is not a valid value for type 'bool'
SUMMARY: UndefinedBehaviorSanitizer: undefined-behavior main.cpp:21:41 
error=0 success=1
&lt;/code&gt;
&lt;p&gt;Great, the undefined behavior is spotted! Even if the error message is not super clear. This is ASan's way of saying: "I expected a 0 or 1 for this boolean, but I found a random 8 in that memory slot."&lt;/p&gt;&lt;p&gt;We alternatively could also have used Valgrind to the same effect.&lt;/p&gt;&lt;p&gt;But: it means that we now need to have 100% test coverage to be certain that our code does not have undefined behavior. That's a big ask.&lt;/p&gt;&lt;p&gt;Also, in my testing, Address Sanitizer did not always report the issue. That's the nature of the tool: it is meant to be conservative and avoid false positives, to avoid alerting fatigue, but that means it won't catch all issues.&lt;/p&gt;&lt;p&gt;Additionally, these tools have a performance cost and can make the build process a bit more complex.&lt;/p&gt;&lt;p&gt;I wrote a &lt;code&gt;libclang&lt;/code&gt; plugin at the time to catch other instances of this problem in the codebase at build time: https://github.com/gaultier/c/tree/master/libclang-plugin .&lt;/p&gt;&lt;p&gt;Amazingly, there was only one other case in the whole codebase, and it was a false positive because by chance, the caller set the uninitialized fields right after, like this:&lt;/p&gt;&lt;code&gt;Response response;
response.error = false;
response.success = true;
&lt;/code&gt;
&lt;p&gt;I have no idea if this &lt;code&gt;libclang&lt;/code&gt; plugin still works today because I have heard that the &lt;code&gt;libclang&lt;/code&gt; API often has breaking changes.&lt;/p&gt;&lt;p&gt;Remember all these rules we have just gone through? You want more? What if we added some sweet special cases to them?&lt;/p&gt;&lt;p&gt;Some types, when the value is not initialized, do not trigger undefined behavior, if they are used in certain ways:&lt;/p&gt;&lt;code&gt;std::byte&lt;/code&gt;&lt;code&gt;unsigned char&lt;/code&gt;&lt;code&gt;char&lt;/code&gt; if the underlying representation is &lt;code&gt;unsigned&lt;/code&gt;&lt;p&gt;For example, this code is perfectly valid and free of undefined behavior:&lt;/p&gt;&lt;code&gt;    unsigned char c;     // “c” has an indeterminate/erroneous value
 
    unsigned char d = c; // no undefined/erroneous behavior,
                         // but “d” has an indeterminate/erroneous value
 
    assert(c == d);  // holds, but both integral promotions have
                         // undefined/erroneous behavior
&lt;/code&gt;
&lt;p&gt;And this runs perfectly fine under ASan. Clang throws some warnings but compiles fine, and this is valid (in terms of the C++ standard) code.&lt;/p&gt;&lt;p&gt;Now, if we use &lt;code&gt;bool&lt;/code&gt; (for example) instead:&lt;/p&gt;&lt;code&gt;  bool c; 
  bool d = c;
  assert(c == d);
&lt;/code&gt;
&lt;p&gt;This is undefined behavior and immediately triggers ASan errors! Even if the code is the same in terms of type sizes and stack layout!&lt;/p&gt;&lt;p&gt;I do not know why the C++ standard felt the need to muddy the water even more, but they surely had a reason. Right?&lt;/p&gt;&lt;p&gt;Some quick research seems to indicate that these types are special cases to allow code to manipulate raw bytes like memcpy or buffer management without the compiler freaking out. Which...maybe makes sense?&lt;/p&gt;&lt;p&gt;In my opinion, this bug is C++ in a nutshell:&lt;/p&gt;&lt;code&gt;data&lt;/code&gt; field) makes the compiler generate completely different code at the call sites.&lt;p&gt;In contrast I really, really like the 'POD' approach that many languages have taken, from C, to Go, to Rust: a struct is just plain data. Either the compiler forces you to set each field in the struct when creating it, or it does not force you, and in this case, it zero-initializes all unmentioned fields. This is so simple it is obviously correct (but let's not talk about uninitialized padding between fields in C :/ ).&lt;/p&gt;&lt;p&gt;In the end I am thankful for this bug, because it made me aware for the first time that undefined behavior is real and dangerous, for one simple reason: it makes your program behave completely differently than the code. By reading the code, you cannot predict the behavior of the program in any way. The code stopped being the source of truth. Impossible values appear in the program, as if a cosmic ray hit your machine and flipped some bits. And you can very easily, and invisibly, trigger undefined behavior.&lt;/p&gt;&lt;p&gt;We programmers are only humans, and we only internalize that something (data corruption, undefined behavior, data races, etc) is a big real issue when we have been bitten by it and it ruined our day.&lt;/p&gt;&lt;p&gt;Post-Scriptum: This is not a hit piece on C++: C++ paid my bills for 10 years. I have been able to take a mortgage and build a house thanks to C++. But it is also a deeply flawed language, and I would not start a new professional project in C++ today without a very good reason. If you like C++, all the power to you. I just want to raise awareness on this (perhaps) little-known rule in the language that might trip you up.&lt;/p&gt;&lt;p&gt;A commenter posted this Forrest Gump gif that I had completely forgotten about, so thank you :)&lt;/p&gt;&lt;quote&gt;&lt;p&gt;If you enjoy what you're reading, you want to support me, and can afford it: Support me. That allows me to write more cool articles!&lt;/p&gt;&lt;p&gt;This blog is open-source! If you find a problem, please open a Github issue. The content of this blog as well as the code snippets are under the BSD-3 License which I also usually use for all my personal projects. It's basically free for every use but you have to mention me as the original author.&lt;/p&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gaultier.github.io/blog/the_production_bug_that_made_me_care_about_undefined_behavior.html"/><published>2025-12-29T18:17:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46423566</id><title>List of domains censored by German ISPs</title><updated>2025-12-30T03:56:17.844796+00:00</updated><content>&lt;doc fingerprint="1ce1d9ea58191f5"&gt;
  &lt;main&gt;
    &lt;p&gt;CUII Liste.de Home Home Gesperrte Domains Domain hinzufügen Domain hinzufügen Bin ich betroffen? Bin ich betroffen? Zensur umgehen Zensur umgehen Über uns Über uns Von der CUII gesperrte Domains Home Home Gesperrte Domains Domain hinzufügen Domain hinzufügen Bin ich betroffen? Bin ich betroffen? Zensur umgehen Zensur umgehen Über uns Über uns&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cuiiliste.de/domains"/><published>2025-12-29T18:21:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424262</id><title>All Delisted Steam Games</title><updated>2025-12-30T03:56:16.993648+00:00</updated><content>&lt;doc fingerprint="1f3d89cc94de127a"&gt;
  &lt;main&gt;
    &lt;p&gt;This page gives you direct access to all 1,038 delisted Steam titles on the site. Below each title are the companies it relates to. An * in the title denotes a placeholder page that contains basic details.&lt;/p&gt;
    &lt;p&gt;A&lt;/p&gt;
    &lt;p&gt;B&lt;/p&gt;
    &lt;p&gt;C&lt;/p&gt;
    &lt;p&gt;D&lt;/p&gt;
    &lt;p&gt;E&lt;/p&gt;
    &lt;p&gt;F&lt;/p&gt;
    &lt;p&gt;G&lt;/p&gt;
    &lt;p&gt;H&lt;/p&gt;
    &lt;p&gt;I&lt;/p&gt;
    &lt;p&gt;J&lt;/p&gt;
    &lt;p&gt;K&lt;/p&gt;
    &lt;p&gt;L&lt;/p&gt;
    &lt;p&gt;M&lt;/p&gt;
    &lt;p&gt;N&lt;/p&gt;
    &lt;p&gt;O&lt;/p&gt;
    &lt;p&gt;P&lt;/p&gt;
    &lt;p&gt;Q&lt;/p&gt;
    &lt;p&gt;R&lt;/p&gt;
    &lt;p&gt;S&lt;/p&gt;
    &lt;p&gt;T&lt;/p&gt;
    &lt;p&gt;U&lt;/p&gt;
    &lt;p&gt;V&lt;/p&gt;
    &lt;p&gt;W&lt;/p&gt;
    &lt;p&gt;Y&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://delistedgames.com/all-delisted-steam-games/"/><published>2025-12-29T19:16:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424460</id><title>When someone says they hate your product</title><updated>2025-12-30T03:56:16.659149+00:00</updated><content>&lt;doc fingerprint="2b1392cbba67bdad"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;When someone says they hate your product with a burning passion&lt;/head&gt;
    &lt;head rend="h3"&gt;What CodeRabbit did, and what to do instead&lt;/head&gt;
    &lt;p&gt;Let’s say you get negative feedback in public. It’s blunt, even abrasive. You instinctively bristle: they’re wrong, they don’t get it, they’re trolling. So naturally, you push back. But your rebuttal only makes the critic double down, and now others are piling on. You clarify your position, but it only gets worse.&lt;/p&gt;
    &lt;p&gt;Why does this happen, and what can you do about it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Feedback is a regulatory mechanism&lt;/head&gt;
    &lt;p&gt;Imagine a thermostat for your credibility. People form an opinion on what the correct setting should be, and they regulate if the reality seems off. If you’re above their setpoint, people feel you’re overrated and want to bring you down; if you’re below it, people feel you’re underrated and want to build you up. And the farther off you are, the more they’ll overcorrect.&lt;/p&gt;
    &lt;p&gt;When someone is frustrated with you (or your company, or your product), they have a view of how much you should be dinged for something. Venting in public is a way to regulate your reputation and achieve the proper homeostasis, like turning a thermostat toward the desired setting.&lt;/p&gt;
    &lt;p&gt;This means that the substance of someone’s feedback is totally separate from their frustration or desire to be heard. Complaints often seem unfair and you might want to jump to fact checking, but that won’t get anywhere unless you first resolve the frustration and make people feel that you actually listened. (It turns out facts do care about our feelings.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Resistance is escalation&lt;/head&gt;
    &lt;p&gt;When you reject someone’s feedback, you’re implying that (1) they’re wrong, (2) they’re possibly dumb, and (3) they don’t have the authority to judge you.&lt;/p&gt;
    &lt;p&gt;To be clear, sometimes that’s all true and you need to fight or ignore. But in this case, we’re focusing on substantive feedback from people who matter, like your customers.&lt;/p&gt;
    &lt;p&gt;By rebutting, you’re forcing them to justify and defend their initial statements. Either they were wrong to raise it or you were wrong to resist! Their choice is obvious.&lt;/p&gt;
    &lt;p&gt;Now their move is to escalate further, maybe with more examples or stronger language. As this plays out, onlookers will tend to take the critic’s side, as an angry customer is more relatable than an imperious founder.&lt;/p&gt;
    &lt;head rend="h2"&gt;Aiden v. CodeRabbit&lt;/head&gt;
    &lt;p&gt;Going back to the thermostat analogy, a stubborn dial only makes people twist harder.&lt;/p&gt;
    &lt;p&gt;Here’s a recent example.&lt;/p&gt;
    &lt;p&gt;Last week, Aiden Bai posted about grievances with CodeRabbit. Pretty normal so far; users complain about products all the time. A CodeRabbit engineer jumped in to ask for feedback, which was good, and Aiden followed up with details (full context here):&lt;/p&gt;
    &lt;p&gt;CodeRabbit’s CEO, Harjot, then entered the chat:&lt;/p&gt;
    &lt;p&gt;In one post, he&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;called his own customer clueless,&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;then implied CodeRabbit had enough users that this feedback didn’t matter,&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;then condescendingly speculated that, even if it were valid, it could probably be solved by “simpler controls and a lot of handholding,”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;then, to gild the lily, made sure to insult not only Aiden personally but indie developers as a category.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now, we should remember that writing a bad response isn’t the same as being a bad person. Harjot was frustrated by what he felt was a bad faith attack on his company, and I have a lot of sympathy for founders getting hater-fatigue.&lt;/p&gt;
    &lt;p&gt;Nonetheless, the response was objectively not good, and what came next was predictable:&lt;/p&gt;
    &lt;p&gt;The net upshot was bad vibes for CodeRabbit and a layup for its competitors:&lt;/p&gt;
    &lt;p&gt;The episode finally ended with an apologish from Harjot:&lt;/p&gt;
    &lt;p&gt;My advice for this kind of post is to pick a lane: if it’s an apology, make it a proper one and resist the urge to sprinkle in more veiled jabs. You could also take the other route and just not apologize. It’s best to try avoiding any uncanny valley situations. But it happens: bad interactions are unavoidable and this one wasn’t too damaging in the grand scheme.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to reset&lt;/head&gt;
    &lt;p&gt;As Tolstoy would’ve said, all positive mentions are alike; every negative mention is irksome in its own way. It varies based on who’s involved, what the feedback is, how much traction it’s getting, etc. etc. etc. — there isn’t a universal solution. As I’ve noted, sometimes it really is bad faith trolling, and that calls for a very different approach.&lt;/p&gt;
    &lt;p&gt;But in general, as a founder you should be your own hardest critic. You should have a higher standard for yourself than anyone else could possibly impose. You should be voracious for user feedback, even if it feels unfair.&lt;/p&gt;
    &lt;p&gt;And the magical thing is, when you sincerely feel that way and you demonstrate it, criticism tends to wilt.&lt;/p&gt;
    &lt;p&gt;Imagine a scenario where you get negative feedback, and you overrule the instinct to push back. Instead, you listen to the feedback, you embrace the responsibility to make the best product possible, you even thank them for caring enough to share their thoughts (remembering that your real enemy isn’t negativity but indifference).&lt;/p&gt;
    &lt;p&gt;With just this, you’ll have shown more curiosity, more ownership, more humility than they were even hoping to enforce. They’re surprised to find that the imbalance is now in the other direction. Instead of feeling snubbed or dismissed, they might consider whether their initial jab was excessive. They now risk overcorrecting and overshooting the setpoint they were aiming for.&lt;/p&gt;
    &lt;p&gt;And when people feel they’ve gone too far, they restore balance by pulling back. It’s common to see someone gearing up for a confrontation but, upon finding the other person gracious and receptive, pivot to, “Thanks for sharing the context,” “I shouldn’t have overreacted,” “I appreciate how you handled this, “I do like the product overall,” or some other form of deescalation — maybe even an apology or retraction.&lt;/p&gt;
    &lt;p&gt;Claude gets it!&lt;/p&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;When getting negative feedback:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Separate the information part from the emotion part. There’s the substance of the feedback, and there’s the customer’s frustration and expectation of being heard. Those are discrete, and you can’t address the former without resolving the latter.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start by aligning on principles, before rushing to defend yourself. Whatever the merits of the feedback, you agree that quality is important, that feedback is valuable, and that the feedback has found the person who’s responsible. Again, there’s no hope of aligning on facts if you can’t first align on principles.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Make a point of overindexing on accountability. Take more responsibility than what seems necessary. Take so much ownership that it surprises people. This obviates their need to hector you over it and removes a lot of surface area for attack, creating space for a calmer exchange. More importantly, if you’re the founder, the reality is that every detail of your product does fall on you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you need to clarify facts, explain instead of defending. You can share the exact same information in a way that’s either defensive and caustic, or earnest and transparent. The only difference is tone.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If self-critique or apology is warranted (it isn’t always), keep it straightforward. No need to grovel or self flagellate. Recap the problem plainly, explain the fix, say what you’re doing to prevent it in the future, and wrap it up. Then move on.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.getflack.com/p/responding-to-negative-feedback"/><published>2025-12-29T19:30:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424782</id><title>Which Humans? (2023)</title><updated>2025-12-30T03:56:16.566561+00:00</updated><link href="https://osf.io/preprints/psyarxiv/5b26t_v1"/><published>2025-12-29T19:57:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46424789</id><title>Obelisk 0.32: Cancellation, WebAPI, Postgres</title><updated>2025-12-30T03:56:16.475114+00:00</updated><content/><link href="https://obeli.sk/blog/announcing-obelisk-0-32/"/><published>2025-12-29T19:58:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46425198</id><title>Google is dead. Where do we go now?</title><updated>2025-12-30T03:56:16.321177+00:00</updated><content/><link href="https://www.circusscientist.com/2025/12/29/google-is-dead-where-do-we-go-now/"/><published>2025-12-29T20:29:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46426624</id><title>Show HN: Stop Claude Code from forgetting everything</title><updated>2025-12-30T03:56:16.216546+00:00</updated><content>&lt;doc fingerprint="aa6857fc6a9dbe21"&gt;
  &lt;main&gt;
    &lt;p&gt;Get smarter alongside your AI.&lt;/p&gt;
    &lt;p&gt;Your intelligence shouldn't reset every conversation. Ensue is a persistent knowledge tree that grows with you - what you learn today enriches tomorrow's reasoning.&lt;/p&gt;
    &lt;p&gt;Every conversation with an LLM starts from zero. You explain context, re-establish preferences, repeat decisions you've already made. Your knowledge doesn't compound.&lt;/p&gt;
    &lt;p&gt;Ensue changes that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Your knowledge persists - Build a tree of intelligence that spans conversations&lt;/item&gt;
      &lt;item&gt;Context carries forward - Prior research, decisions, and insights inform new work&lt;/item&gt;
      &lt;item&gt;You get smarter together - The LLM learns your thinking patterns, not just facts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Think of it as extended memory. When you ask about GPU inference, the LLM checks what you already know. When you make an architecture decision, it connects to past decisions in similar domains. Your accumulated knowledge becomes part of every conversation.&lt;/p&gt;
    &lt;code&gt;/plugin marketplace add https://github.com/mutable-state-inc/ensue-skill
&lt;/code&gt;
    &lt;code&gt;/plugin install ensue-memory
&lt;/code&gt;
    &lt;p&gt;Restart Claude Code. The skill will guide you through setup.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENSUE_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Required. Get one at dashboard&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;ENSUE_READONLY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set to &lt;code&gt;true&lt;/code&gt; to disable auto-logging (session tracking, tool capture). Manual &lt;code&gt;remember&lt;/code&gt;/&lt;code&gt;recall&lt;/code&gt; still works.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Disable auto-logging for a session
ENSUE_READONLY=true claude

# Or add to ~/.zshrc for permanent read-only mode
export ENSUE_READONLY=true&lt;/code&gt;
    &lt;code&gt;"remember my preferred stack is React + Postgres"
"what do I know about caching strategies?"
"check my research/distributed-systems/ notes"
&lt;/code&gt;
    &lt;p&gt;Docs · Dashboard · Homepage · API: &lt;code&gt;https://api.ensue-network.ai&lt;/code&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/mutable-state-inc/ensue-skill"/><published>2025-12-29T22:30:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46427181</id><title>Geology of the Gulf of the Farallones National Marine Sanctuary</title><updated>2025-12-30T03:56:15.056617+00:00</updated><content>&lt;doc fingerprint="fe5d5a9c58a2028f"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;Considerable public attention has focused on the environmental stress in and around the Gulf of the Farallones National Marine Sanctuary (NMS).&lt;/head&gt;
          &lt;p&gt;The U.S. Geological Survey (USGS) provides geological information in support of studies related to proposed siting of offshore areas for disposal of dredge spoils and to determining locations of barrels of radioactive waste. The potential for damage to the marine environment from disposal of dredge materials and from rupture of waste containers is difficult to assess without a detailed knowledge of geology, oceanography, and the movement and ultimate fate of transported sediments.&lt;/p&gt;
          &lt;head&gt;USGS studies perform a critical role in the preliminary study of potential disposal sites for dredge materials.&lt;/head&gt;
          &lt;p&gt;Cooperative work since 1990 with the Environmental Protection Agency (EPA), the Army Corps of Engineers, and the U.S. Navy has reduced the number of candidate disposal sites from six to three in an approximate 1,000 square mile area west of San Francisco. Sidescan sonar surveys were conducted in all areas in cooperation with the private sector and geological interpretations were derived from these images in preparation for site-specific studies conducted by EPA. A key set of geological characteristics for a proposed dredge-materials disposal site, among other logistical attributes, includes a featureless plain with gentle slopes, no evidence of mass movement of sediments or rock, a lack of strong currents that might redisperse dredge materials, and low-level biota. The ideal site would be geologically stable with net deposition rather than erosion or sediment instability.&lt;/p&gt;
          &lt;p&gt;The role of USGS scientists is simply to interpret the geological and geophysical data for regulatory agencies. USGS does not make judgments about the suitability of an area as a disposal site. Officials responsible for enforcing environmental regulations use these geologic interpretations along with other criteria to select appropriate disposal sites.&lt;/p&gt;
          &lt;head&gt;USGS scientists have mapped a small portion of the area known to contain hazardous wastes, and have made significant advances in interpreting sonar signals attributed to the containers.&lt;/head&gt;
          &lt;p&gt;Between 1946 and 1970, nearly 50,000 drums of hazardous and radioactive wastes were dumped over a 350 square nautical mile area that overlaps the Farallones NMS. The task facing environmental managers is to assess contamination of the environment around the 55-gallon drums. However, managers do not know the precise locations of these containers and therefore cannot put together an effective sediment and water sampling program that will provide clues to the extent of contamination, if any. USGS mapping, in cooperation with the National Oceanic and Atmospheric Administration (NOAA), to date covers just 15 percent of the potentially contaminated area. USGS scientists have determined that the sonar backscatter signal can be digitally enhanced to distinguish non-geologic targets such as waste containers, from geologic targets.&lt;/p&gt;
          &lt;head&gt;USGS scientists understanding of the geology in the marine environment is a key to selecting appropriate mapping technology.&lt;/head&gt;
          &lt;p&gt;Broad-beam sonar scanning used for reconnaissance mapping of the Exclusive Economic Zone (EEZ) yields insufficient detail. High-resolution scanning yields very fine detail but these surveys take much time and money to complete. USGS researchers use a mid-range frequency for this type of surveying in 3,000 feet of water to resolve features on the seafloor that, with correct interpretation, can lead to a generalized map showing geology as well as other targets of interest. The importance of such USGS maps is realized when the presence and location of specific targets such as hazardous waste containers is sought.&lt;/p&gt;
          &lt;head&gt;USGS scientists work towards finishing the mapping of the Marine Sanctuary.&lt;/head&gt;
          &lt;p&gt;Research in cooperation with NOAA and with the private sector continues to produce newer and better means for surveying the seafloor. As the remaining 85 percent of the area is mapped, techniques for resolving seafloor features and for detecting targets of interest are documented for application to other marine environments, such as those offshore from major metropolitan areas or in the vicinity of existing and proposed marine sanctuaries. A library of data combining near- and offshore surveys is available for use in applications requiring geological information.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pubs.usgs.gov/fs/farallones/"/><published>2025-12-29T23:12:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46427376</id><title>Parsing Advances</title><updated>2025-12-30T03:56:14.883427+00:00</updated><content>&lt;doc fingerprint="7fa4da19ee2f93dd"&gt;
  &lt;main&gt;
    &lt;p&gt;I find myself writing yet another toy parser, as one does during a Christmas break. It roughly follows Resilient LL Parsing Tutorial. Not because I need resilience, but mostly because I find producing a syntax tree and a collection of diagnostics a more natural fit for the problem than bailing out on the first error.&lt;/p&gt;
    &lt;p&gt;One practical pitfall with the approach is infinite loops/recursion. Resilience sometimes means not consuming a token, and, if you do that in a loop or a Pratt recursive call, you’ll get yourself an annoying to debug error:&lt;/p&gt;
    &lt;p&gt;For a concrete example, you might parse function argument list using code like this:&lt;/p&gt;
    &lt;p&gt;The implicit contract here is that expression consumes at least one token, even if there are errors in the source code. If there’s some token that makes expression bail without consuming anything, the code loops forever, and you’ll need a debugger to get at the stack trace!&lt;/p&gt;
    &lt;p&gt;The way I solved this issue traditionally is via a combination of two techniques:&lt;/p&gt;
    &lt;p&gt;Fuel: parser has a fuel: Cell&amp;lt;u32&amp;gt; field, which is decremented even by “readonly” lookahead methods, and topped up every time the parser consumes a token. Fuel is useful to make you parser crash somewhat cleanly, though the crash is typically still removed from problematic function by several stack frames.&lt;/p&gt;
    &lt;p&gt;The second technique is to maintain a mental map of functions which always consume at least one token of input, and functions which might bail without consuming anything. And, whenever you write a loop or a recursive call, consult this map to be sure to call at least one token-consuming function. Hard and error prone!&lt;/p&gt;
    &lt;p&gt;Well, I think I’ve figured something better today! You can assert that parser did advance when you expect it to. The smaller benefit here is that if parser didn’t advance, you get an immediate error. The bigger benefit is that these asserts materialize the mental map of advancing functions in the source code, so it doesn’t have to be mental anymore!&lt;/p&gt;
    &lt;p&gt;This seems like an obvious idea in retrospect, but, well, took me more than one parser to figure it out!&lt;/p&gt;
    &lt;p&gt;Concretely, I came up with the following base parser API:&lt;/p&gt;
    &lt;p&gt;And here is the buggy function that lead to the error at the start of the article:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://matklad.github.io/2025/12/28/parsing-advances.html"/><published>2025-12-29T23:29:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46427582</id><title>I migrated to an almost all-EU stack and saved 500€ per year</title><updated>2025-12-30T03:56:13.887117+00:00</updated><content>&lt;doc fingerprint="3d410656abb537ed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Bye Bye Big Tech: How I Migrated to an almost All-EU Stack (and saved 500€ per year)&lt;/head&gt;
    &lt;head rend="h3"&gt;“Bye bye bye.” It took some time, and a serious amount of research, but I have finally crossed the finish line. I have officially migrated my digital life to pure, EU-hosted solutions.&lt;/head&gt;
    &lt;p&gt;For a long time, the narrative has been that if you want privacy and data sovereignty, you have to sacrifice usability. But after settling into this new stack, I’ve realized that isn’t true anymore. In fact, most of these tools aren’t just more private; they are significantly better than the US-based giants I left behind.&lt;/p&gt;
    &lt;p&gt;Here is a breakdown of the tools I’m using, the money I’m saving, and the few hurdles I’m still trying to jump over.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;by the way, this post is for personal setups not for companies. Yet, I think most tools can be used for teams and companies too.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h1"&gt;The Backbone: The Proton Ecosystem&lt;/head&gt;
    &lt;p&gt;The biggest impact on this migration has come from Proton. They have matured from a simple encrypted email provider into a (almost) full-suite productivity powerhouse.&lt;/p&gt;
    &lt;p&gt;My subscription now covers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Mail &amp;amp; Calendar: Encrypted and clean.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Drive: Secure cloud storage, having docs for a while, and now also tables.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Proton Pass: A solid password manager with 2FA integration.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;VPN: Fast and reliable.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Standard Notes: My go-to for note-taking, now under the Proton umbrella.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lumo AI: A privacy-first GenAI, I’m not yet frequently using it, but we will talk about it later.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Everything is integrated and the user experience is superb. I’m also eagerly awaiting the release of Proton Meet to complete the suite.&lt;/p&gt;
    &lt;p&gt;This entire setup replaces for me my Google Drive and Gmail ecosystem. Plus NordVPN, Notion, 1Password and Authenticator.&lt;/p&gt;
    &lt;p&gt;Curious? I will drop you my referral link here.&lt;/p&gt;
    &lt;head rend="h1"&gt;My mixed AI Strategy&lt;/head&gt;
    &lt;p&gt;AI is the hardest thing to decouple from Big Tech, but improvements are happening fast here, too.&lt;/p&gt;
    &lt;p&gt;For privacy-first GenAI tasks within my workflow, I’m using Lumo AI. It’s great for quick, private queries.&lt;/p&gt;
    &lt;p&gt;However, sometimes you need raw power. For that, I started using Mammouth. I use this less for privacy reasons and more for the sheer value and flexibility. Getting access to every major AI model (including image generation) for just €10 is incredible value.&lt;/p&gt;
    &lt;p&gt;My default for Mammouth looks like this. You can sort them in your favourite order; whatever is leftmost is your default one.&lt;/p&gt;
    &lt;p&gt;The two models I use most are Mistral Medium 3.1 and Flux 2 Pro or Fast. For simple coding tasks, I also use Mistral, but when playing around with a larger codebase, I have to admit I’m using Claude Code.&lt;/p&gt;
    &lt;p&gt;For research, Mistral does its job. But if it becomes complex, I often find Gemini's results to be the best.&lt;/p&gt;
    &lt;p&gt;At last, Flux for images is fantastic. Yet, in my opinion, it comes with a major downside: You have to give a lot of good instructions. Where a Nano Banana seems more creative, even from short, simple inputs, Flux needs precise orders.&lt;/p&gt;
    &lt;head rend="h1"&gt;Browsing, Search, and Language&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Browser: I moved to Vivaldi Technologies. It’s highly customizable and respects user data.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Search: My default is Ecosia. It works well, and planting trees while searching adds a nice layer of purpose to mindless scrolling. Yet, every now and then I have to use Google :/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Translation: I’ve been using DeepL forever. In my opinion, it is still miles ahead of Google Translate in terms of nuance and quality.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Spell Check: … Haven’t found a good alternative, so I stay with Grammarly. Hoping for them to return to Europe with their Superhuman Platform.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Infrastructure: Hosting &amp;amp; Domains&lt;/head&gt;
    &lt;p&gt;For my website and domains, I moved everything to Scaleway.&lt;/p&gt;
    &lt;p&gt;If you are technical, you will appreciate this switch. It is lean, simple, and provides everything you need as a cloud provider without the bloat of AWS or Azure. Plus, it’s cheaper.&lt;/p&gt;
    &lt;head rend="h1"&gt;Creativity &amp;amp; Task Management&lt;/head&gt;
    &lt;p&gt;Canva… what shall I say.&lt;/p&gt;
    &lt;p&gt;Thanks to the initial discussion I had on LinkedIn (original post), I found Superlist, to which I transitioned from Todoist. I also had a mini stop at MeisterTask, but that was a complete waste of time.&lt;/p&gt;
    &lt;p&gt;MeisterTaks feels like a kindergarten playground, too much colorful design and too little actual functionality. It is 100% not user-intuitive for any workflow.&lt;/p&gt;
    &lt;p&gt;So, I’m now on Superlist, and very happy with it.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Economics: Privacy is Actually Cheaper&lt;/head&gt;
    &lt;p&gt;We often assume that “boutique” privacy tools cost a premium. Surprisingly, my migration proved the opposite. Initially, I wrote only about a small saving, but I missed the costs of Notion, Todoist, 1 Password, Claude and Canva as I focused on the “Office” suite.&lt;/p&gt;
    &lt;p&gt;My Old Stack cost ca. 83€ per month&lt;/p&gt;
    &lt;p&gt;My New EU Stack cost ca. 39€ per month&lt;/p&gt;
    &lt;p&gt;I’m saving over 528 € a year while owning most of my data.&lt;/p&gt;
    &lt;head rend="h1"&gt;Where There is Light, There is Shadow&lt;/head&gt;
    &lt;p&gt;I want to be transparent: you cannot escape everything, and some things are just harder to use.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The “Guilty Pleasure”: As a techie, I have too much fun playing with Claude Code. It’s a luxury I treat myself to, so I frequently turn the subscription on. Yet, if you don’t have that use case → Mistral, Lumo&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Social Web: You simply can’t get around LinkedIn, GitHub, YouTube, Medium, Substack and so on if you want to stay connected.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;del rend="overstrike"&gt;Convenience:&lt;/del&gt;&lt;del rend="overstrike"&gt;I miss a good Google SSO. It is everywhere, and losing that “one-click login” friction does make life slightly more annoying.&lt;/del&gt;I migrated every Login to Proton Pass using MFA and Passkey wherever possible.&lt;/item&gt;
      &lt;item&gt;&lt;del rend="overstrike"&gt;Office Suite:&lt;/del&gt;&lt;del rend="overstrike"&gt;I am struggling to get used to LibreOffice and Collabora Online. They feel similar to MS Office, but “not quite.” Since I don’t create documents or spreadsheets every day for personal use, the learning curve feels steeper than it should.&lt;/del&gt;Screw that → Proton Docs and Sheets are doing it. Worst case for slides, I’m going for Canva, I’m paying for it anyhow.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Blogging, Newsletter &amp;amp; Co.: Well, as you can see, I’m writing on Substack. There are no alternatives except to host it entirely yourself, but that doesn’t make sense to me right now.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;The Unexpected Gems I found&lt;/head&gt;
    &lt;p&gt;I also found a couple of positive side effects. The Proton platform itself has everything you need for your day-to-day life.&lt;/p&gt;
    &lt;p&gt;In addition, I migrated to a Duo plan with my wife. Together we have 2TB on storage for Mails, Files etc. Before we had 30GB on Gmail, which cost a little more.&lt;/p&gt;
    &lt;p&gt;Proton Pass creates anonymous email addresses in case you don’t want to use your real email address. This plays entirely on Proton's privacy aspect.&lt;/p&gt;
    &lt;p&gt;Superlist is free for the same features Todoist provided me for a little subscription.&lt;/p&gt;
    &lt;p&gt;Lastly, I’m always fighting with note-taking. I tested everything and started building something complex on Notion. I’m glad that I could delete it and just use Standard Notes from Proton. In simple terms, it is like notes from Apple, yet E2E encrypted and you can back them up offline. However, most helpful for me is that I finally found a way to work effectively with notes, keep it clean, lean and functional.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Takeaway&lt;/head&gt;
    &lt;p&gt;With Proton, Scaleway, Mammouth, Vivaldi, Superlist and DeepL, I have built a useful toolset that, in my opinion, surpasses what I used before.&lt;/p&gt;
    &lt;p&gt;The apps are cleaner, the UI is often more user-friendly, and the migration was surprisingly simple. Best of all, I can do more with my tech stack for less money.&lt;/p&gt;
    &lt;p&gt;If you’ve been on the fence about migrating to EU-hosted solutions, take the leap. It’s worth it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.zeitgeistofbytes.com/p/bye-bye-big-tech-how-i-migrated-to"/><published>2025-12-29T23:50:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46427920</id><title>MongoDB Server Security Update, December 2025</title><updated>2025-12-30T03:56:13.718533+00:00</updated><content>&lt;doc fingerprint="a4e75956e81f6bca"&gt;
  &lt;main&gt;
    &lt;p&gt;At MongoDB, protecting our customers’ data is our highest priority. On December 12, 2025, the MongoDB Security Engineering team identified a security vulnerability, described in CVE-2025-14847, which impacts MongoDB Server. Within the security community, this vulnerability is informally referred to as “Mongobleed.” This blog post outlines the situation, our immediate response, and the key insights we’ve gathered so far. Security is an ongoing responsibility in modern software development for both software producers and consumers, and maintaining trust depends on how issues are identified, addressed, and communicated.&lt;/p&gt;
    &lt;p&gt;This patched security vulnerability in the MongoDB Server products (Community and Enterprise) is not a breach or compromise of MongoDB, MongoDB Atlas (our managed MongoDB Server offering), or our systems. To maintain the highest levels of security, customers and users are advised to use the latest versions of MongoDB’s software that have been updated to address this vulnerability.&lt;/p&gt;
    &lt;p&gt;The vulnerability was discovered internally by MongoDB Security Engineering as part of our proactive and continuously evolving security program. Over the last several years, we have increased our investment in people, processes, and technology to analyse and improve our codebase continuously. This work is ongoing, and discoveries like this reinforce the importance of sustained focus in this area.&lt;/p&gt;
    &lt;p&gt;Because how and when we act matters as much as what we do, transparency around timing is important. The following timeline outlines our discovery, validation, remediation, and disclosure efforts from December 12 through December 23, 2025 (all times U.S. ET):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;December 12 at 19:00 – MongoDB Security Engineering detected the issue.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;December 12–14 – We worked continuously to validate the issue and develop and test a fix.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;December 15-17 – We developed and tested our rollout plans to enable rapid and safe deployment at scale, and commenced patching the Atlas fleet.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;December 17 at 12:10 – We completed patching the majority of the Atlas fleet.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;December 17 at 21:00 – Atlas provides an optional feature called “maintenance windows” that provides customers control over when MongoDB applies routine software updates to their Atlas instances. We proactively notified Atlas customers with maintenance windows configured that we would perform an urgent patch the following day, as part of our established policy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;December 18 – We patched the remainder of the Atlas fleet, including those with maintenance windows, and continued customer communications.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;December 19 – We published the vulnerability through the industry-standard CVE process as CVE-2025-14847.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;December 23 – We posted an update on MongoDB’s community forum, sharing the patch and details on how to update.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Protecting customers was our top priority throughout this process. Tens of thousands of MongoDB Atlas customers and hundreds of thousands of Atlas instances were proactively patched within days. Because MongoDB manages Atlas, we were able to deploy critical security patches quickly and safely on behalf of customers.&lt;/p&gt;
    &lt;p&gt;In parallel with our Atlas remediation, we published patch versions of MongoDB for customers running MongoDB Enterprise Advanced. We also made available patched community builds and proactively notified Community Edition users through our community forum. Our goal was to ensure that all MongoDB users, whether running Atlas, Enterprise Advanced, or Community, had access to patches and clear guidance as quickly as possible.&lt;/p&gt;
    &lt;p&gt;As with any operational event, this was another opportunity to learn, improve, and raise the bar. The software security space is rapidly evolving with new tools and techniques, and MongoDB will continue to evaluate and deploy new capabilities as part of our deep investment in security for our customers.&lt;/p&gt;
    &lt;p&gt;Operating software and services securely at high scale is complex. Our responsibility is to continuously improve our products, act with urgency and transparency, and strengthen how we protect our customers. We appreciate the trust our customers place in MongoDB and remain committed to earning that trust every day.&lt;/p&gt;
    &lt;p&gt;– Jim Scharf, Chief Technology Officer, MongoDB&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mongodb.com/company/blog/news/mongodb-server-security-update-december-2025"/><published>2025-12-30T00:23:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46428154</id><title>Outside, Dungeon, Town: Integrating the Three Places in Videogames (2024)</title><updated>2025-12-30T03:56:13.055364+00:00</updated><content>&lt;doc fingerprint="3c2214be1a840251"&gt;
  &lt;main&gt;
    &lt;p&gt;Videogames, at least the kind I’m talking about (RPGs, adventure kinds of somewhat narrative videogames, Zelda games, Elden Ring, etc), have essentially three “places”:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Outside – Hyrule field. Most of the game is Outside, just running around in a grassy area or a snowy mountain. It’s kind of the glue between all of the elements but there can be all manner of things Outside. Outside is the most flexible, but it typically has the lowest density of monsters, NPCs, shops, etc.&lt;/item&gt;
      &lt;item&gt;Dungeon – The sewers, the final boss’ castle, a factory full of monsters, or a literal dungeon. Dungeons have LOTS of monsters, treasure, and usually a boss. You go into a dungeon to kinda clear it, get the treasure, kill the boss. Dungeons rarely have NPCs or shops in them (Shiren the Wanderer is an exception that comes to mind).&lt;/item&gt;
      &lt;item&gt;Town – This is where most NPCs are, but also the highest concentration of “specific activities”. Towns are dense, there’s often shops, minigames, quests, etc. Kakariko Village from Ocarina of Time is one of my favorite towns. There are almost never fights in town – you are almost always entirely safe in town.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, any time you try to boil down reality into a nice neat little categorization system like this, you’re going to be missing a lot of details, but broadly speaking, I think this holds up pretty well. I’m playing through Final Fantasy VII Rebirth now (which I am loving) and it’s very clear in that game, whether you are in Outside, Dungeon or Town, pretty much at all times.&lt;/p&gt;
    &lt;p&gt;Videogames are a language, and this pattern is an important building block in that language. It is kind of good that you know you’re always safe in town. It is kind of good that you know what you’re in for when entering a big scary difficult dungeon, and so on. So, I am not saying that we get rid of these designations, at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;What I’m asking for&lt;/head&gt;
    &lt;p&gt;What I would love, though, is some more messiness in how they are implemented. Kakariko Village from Ocarina of Time is one of my favorite towns because there are some “grey area” parts, especially underground. It also has a dungeon, arguably inside it.&lt;/p&gt;
    &lt;p&gt;I would love a dungeon that connects to the back of someone’s house in a town. Or one part in town that is kind of more Outside-like, like a little forest in there. Or maybe something that’s like 50% dungeon, 50% town.&lt;/p&gt;
    &lt;p&gt;I want the borders of these places to be a little blurrier. It always bothers me in newer games when I enter a dungeon and text pops up on the screen saying “Gorbath’s Cove” or something. Developers do that so that players get a little “check box” feeling, that they have checked another Location off of the List Of Locations, and gotten that much closer to 100%-ing the game. There’s not nothing to that, but it has a cost. The cost of this kind of “instancing” is that the player is sort of robbed of the feeling of discovering a place for themselves. When I first see a cave, I’m like, whoa, there’s a little cave!! But then I walk in and get an announcement, telling me that this is a known site, that my discovery isn’t special, and also that there are many places just like this one in this game.&lt;/p&gt;
    &lt;p&gt;I am not really that impressed by the underworld of Tears of the Kingdom, specifically because it is so clearly “its own map”. I would much prefer that, throughout Hyrule, there was a network of messy underground areas. Maybe one cave system has a place where it connects to a dungeon, which connects also to a basement in some guy’s house in the middle of nowhere.&lt;/p&gt;
    &lt;p&gt;The existence of these “three places” is a good thing for videogames and I am not saying that we abandon it. However, I think we should “break the rules” a lot more frequently, because a world that breaks the rules is a world that invites and cultivates a sense of wonder.&lt;/p&gt;
    &lt;p&gt;I hope to do a lot of this with my own game, Free Tiya Bannet, which I’m working on now. I want the first town to be, yes, a town. It does have shops, and you are mostly safe in most of it. But maybe there’s one area where you aren’t safe. Maybe there’s an underground part of it that is kind of a dungeon. Maybe it even connects to a secret definitely-dungeon, etc.&lt;/p&gt;
    &lt;p&gt;Videogames, especially the higher budget games, have a tendency towards being conservative: making sure that everyone understands exactly what is happening at all times. I think this is a valid thing to care about, but I also think that, like all things, it’s a balancing act, and I think too many games have been falling on the too-conservative part of the spectrum.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://keithburgun.net/outside-dungeon-town-integrating-the-three-places-in-videogames/"/><published>2025-12-30T00:54:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46428206</id><title>100x (YC S22) Is Hiring a Front End Engineer</title><updated>2025-12-30T03:56:12.692954+00:00</updated><content>&lt;doc fingerprint="bdbb174c5dac2469"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Location: Bangalore, India (Koramangala) Compensation: Competitive Salary + Significant Equity (YC Standard) Founders: Shardul Lavekar (ex-Airtel AI, ex-Ola) &amp;amp; Parth Mudgal (ex-Flipkart, ex-Ola)&lt;/p&gt;
      &lt;p&gt;At 100x.bot, we are building the interface for this future. We are not just another "AI Wrapper." We are a deep-tech company backed by Y Combinator, Accel, and Inventus, solving the hardest problem in automation: making browser agents reliable, fast, and accessible to everyone.&lt;/p&gt;
      &lt;p&gt;Most AI agents today are slow, expensive, and hallucinate frequently because they "think too hard" about every click. We take a different approach: "Record once, Automate forever." We combine the deterministic speed of record-and-replay technology with the semantic intelligence of LLMs to create agents that utilize self-healing DOM maps to navigate the chaotic web with human-like resilience.&lt;/p&gt;
      &lt;p&gt;The Opportunity: More Than Just UI We are looking for a Frontend Craftsperson to join our core engineering team in Bangalore.&lt;/p&gt;
      &lt;p&gt;This is not a role for someone who just wants to center divs or convert Figma files into React components. We are looking for an engineer who can architect the client-side experience for autonomous agents. You will be building the "cockpit" from which users control their digital workforce.&lt;/p&gt;
      &lt;p&gt;What You Will Architect The Agent Visualization Engine: You will build complex, interactive graph-based interfaces that visualize agent workflows. Users need to see the logic flow—loops, conditionals, and "self-healing" events—in real-time.&lt;/p&gt;
      &lt;p&gt;Dynamic MCP Interfaces: You will build systems that dynamically generate UIs based on Model Context Protocol schemas. If an MCP server exposes a new tool, your UI should instantly adapt to support it, without a code deploy.&lt;/p&gt;
      &lt;p&gt;High-Performance Streaming UI: Our agents generate massive logs (DOM snapshots, network events, execution traces). You will use virtualization (e.g., react-window) and atomic state management (Zustand/Jotai) to render these streams at 60fps, ensuring the UI never lags behind the bot.&lt;/p&gt;
      &lt;p&gt;The "Recorder" Experience: You will refine our Chrome Extension overlay, ensuring it injects cleanly into any third-party website (using Shadow DOM encapsulation) to capture user intent without breaking the host page.&lt;/p&gt;
      &lt;p&gt;The Tech Stack We run a modern, type-safe stack designed for velocity and reliability.&lt;/p&gt;
      &lt;p&gt;Frontend: React, TypeScript, Next.js&lt;/p&gt;
      &lt;p&gt;Styling: Tailwind CSS (with Shadow DOM handling)&lt;/p&gt;
      &lt;p&gt;State: Zustand / TanStack Query (for high-frequency updates)&lt;/p&gt;
      &lt;p&gt;Protocol: Model Context Protocol (MCP), WebSockets, Chrome Extension APIs&lt;/p&gt;
      &lt;p&gt;Who You Are A React Expert (2+ Years): You understand the React reconciliation algorithm inside out. You know why useEffect is dangerous for high-frequency data and how to use useRef or useSyncExternalStore to optimize performance.&lt;/p&gt;
      &lt;p&gt;TypeScript Native: You don't just use any. You write robust, generic types that mirror complex backend schemas. You are comfortable sharing types between the extension background script and the UI.&lt;/p&gt;
      &lt;p&gt;A "Craftsperson": You care about micro-interactions. You understand that trust is built through UI feedback—a loading spinner, a hover state, a smooth transition. You take pride in building developer tools that feel like magic.&lt;/p&gt;
      &lt;p&gt;Systems Thinker: You can reason about asynchronous systems. You understand race conditions, websocket reconnections, and the complexity of communicating between a Content Script, a Background Worker, and a React UI.&lt;/p&gt;
      &lt;p&gt;High Agency: In a small YC team, nobody will hand you a ticket. You will identify problems, design solutions, and ship them.&lt;/p&gt;
      &lt;p&gt;Why Join 100x.bot? Work on the Bleeding Edge. You will be a pioneer in the space of AI Agents.&lt;/p&gt;
      &lt;p&gt;YC Culture: We move fast. We ship daily. We value product instincts over bureaucracy. You will have significant ownership and equity.&lt;/p&gt;
      &lt;p&gt;Complex Engineering: You won't be bored. You are building a browser automation engine, a recording studio, and an IDE—all in the browser.&lt;/p&gt;
      &lt;p&gt;Work directly with Shardul and Parth to shape the product roadmap.&lt;/p&gt;
      &lt;p&gt;How to Apply Email me your GitHub and a link to a complex UI you have built.&lt;/p&gt;
      &lt;p&gt;Note: We value actual build history over resumes/degress. Show us something that proves you are a craftsperson.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46428206"/><published>2025-12-30T01:00:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46428496</id><title>Hacking Washing Machines [video]</title><updated>2025-12-30T03:56:11.762689+00:00</updated><content>&lt;doc fingerprint="b41e325c1ac906ec"&gt;
  &lt;main&gt;
    &lt;p&gt;Severin von Wnuck-Lipinski and Hajo Noerenberg&lt;/p&gt;
    &lt;p&gt;Almost everyone has a household appliance at home, whether it's a washing machine, dishwasher, or dryer. Despite their ubiquity, little is publicly documented about how these devices actually work or how their internal components communicate. This talk takes a closer look at proprietary bus systems, hidden diagnostic interfaces, and approaches to cloud-less integration of appliances from two well-known manufacturers into modern home automation systems.&lt;/p&gt;
    &lt;p&gt;Modern home appliances may seem simple from the outside, but inside they contain complex electronic systems, proprietary communication protocols, and diagnostic interfaces rarely documented outside the manufacturer. In this talk, we'll explore the challenges of reverse-engineering these systems: from analyzing appliance control boards and internal communication buses to decompiling and modifying firmware to better understand device functionality.&lt;/p&gt;
    &lt;p&gt;We'll also look at the security mechanisms designed to protect diagnostic access and firmware readout, and how these protections can be bypassed to enable deeper insight into device operation. Finally, this talk will demonstrate how the results of this research can be used to integrate even legacy home appliances into popular home automation platforms.&lt;/p&gt;
    &lt;p&gt;This session combines examples and insights from the reverse-engineering of B/S/H/ and Miele household appliances.&lt;/p&gt;
    &lt;p&gt;Licensed to the public under http://creativecommons.org/licenses/by/4.0&lt;/p&gt;
    &lt;head rend="h3"&gt;Download&lt;/head&gt;
    &lt;head rend="h4"&gt;Video&lt;/head&gt;
    &lt;head rend="h4"&gt;These files contain multiple languages.&lt;/head&gt;
    &lt;p&gt;This Talk was translated into multiple languages. The files available for download contain all languages as separate audio-tracks. Most desktop video players allow you to choose between them.&lt;/p&gt;
    &lt;p&gt;Please look for "audio tracks" in your desktop video player.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://media.ccc.de/v/39c3-hacking-washing-machines"/><published>2025-12-30T01:40:49+00:00</published></entry></feed>