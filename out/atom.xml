<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-22T15:11:39.496491+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45327417</id><title>Why is Venus hell and Earth an Eden?</title><updated>2025-09-22T15:11:51.450236+00:00</updated><content>&lt;doc fingerprint="7719f9695df445ba"&gt;
  &lt;main&gt;
    &lt;p&gt;Mark Belan/Quanta Magazine&lt;/p&gt;
    &lt;p&gt;Venus is arguably the worst place in the solar system. A cloak of carbon dioxide suffocates the planet, subjecting its surface to skull-crushing pressure. Sulfuric acid rains down through the sickly yellow sky but never reaches the lava-licked ground. Venus is so hot — hot enough to melt lead — that the acid rain evaporates as it’s falling.&lt;/p&gt;
    &lt;p&gt;The planet’s extreme inhospitality is at the heart of one of the most beguiling mysteries in planetary science. Venus and Earth formed at the same time, from the same geologic building blocks, in pretty much the same part of the solar system. They’re even the same size. So why is Venus a hellscape, and Earth a garden?&lt;/p&gt;
    &lt;p&gt;A common refrain in the scientific community is that Venus is just several steps ahead — that it represents the end state of all large rocky planets, including Earth. The hypothesis is that these planets eventually lose the ability to sequester planet-warming greenhouse gases in their geologic underbelly. When those gases then accumulate in the atmosphere, the world enters a runaway greenhouse state — like the boiling hot Venusian climate. “Over the years, we’d always heard about Venus being a preview into Earth’s future,” said Stephen Kane, a planetary astrophysicist at the University of California, Riverside.&lt;/p&gt;
    &lt;p&gt;But is that long-held assumption true? In hundreds of millions or billions of years, will Earth’s climate go the way of Venus’, transitioning from a temperate world into a catastrophic hothouse? Kane and his colleagues have been trying to find out. Venus and Earth are often referred to as twins, with Venus being the evil one of the pair. In their Reuniting Twins project, the scientists have developed a digital model of Earth that combines solar physics, volcanology, plate tectonics and climate science. They’ve been pushing their model Earth to its extremes, trying every plausible way to break it and make it into Venus.&lt;/p&gt;
    &lt;p&gt;As well as exploring what went so wrong on the second rock from the sun, this work speaks to a query closer to home, said Paul Byrne, a planetary scientist at Washington University in St. Louis who was not directly involved with the project: “How long is Earth habitable for?”&lt;/p&gt;
    &lt;p&gt;NASA&lt;/p&gt;
    &lt;head rend="h2"&gt;A Planetary Whodunit&lt;/head&gt;
    &lt;p&gt;Forecasting Earth’s future requires an understanding of Venus’ past. Long ago, Venus might not have been too different from how Earth is now. Spacecraft surveys and telescope observations have revealed the existence of a rare, heavy form of water in the Venusian atmosphere — a telltale sign that regular water used to be abundant on the planet.&lt;/p&gt;
    &lt;p&gt;Researchers debate how that water resided there. One possibility is that the water on young Venus formed steam that wafted above the magma sea covering the newborn planet’s surface. That water vapor, a potent greenhouse gas, would have pushed the world into a scorching-hot greenhouse state not long after its birth. Alternatively, Venus’ initial, planetwide magma sea might have cooled and hardened into a crust quickly enough for liquid water — maybe even an ocean’s worth of water — to flow across it. If that is true, then what happened to all that water?&lt;/p&gt;
    &lt;p&gt;In 2020, Michael Way, a planetary scientist and climate modeler at NASA’s Goddard Institute for Space Studies in New York, looked at two possibilities for how a Venusian ocean could have boiled away.&lt;/p&gt;
    &lt;p&gt;The first hypothesis points to the sun, which, as it ages and burns through its hydrogen fuel, blasts out ever more sunlight, subjecting nearby planets — including Venus, which sits closer to the sun than we do — to an increasingly intense blaze. Planetary scientists estimate that by about a billion years after the solar system’s birth, the gradually brightening sun would have been able to efficiently vaporize any liquid water on Venus. Water vapor would then have flooded the Venusian atmosphere, potentially causing intensive global warming; this warming might have been exacerbated further by volcanoes off-gassing carbon dioxide. The combination might have pushed Venus into a runaway greenhouse state.&lt;/p&gt;
    &lt;p&gt;It’s a nice story. But according to Way’s models, the theory that the sun broke Venus by evaporating its oceans has problems. Venus spins very slowly on its axis, and one day there is equivalent to 116 Earth days, or nearly four months. If the planet’s dayside initially held liquid oceans, that water’s evaporation would have formed thick clouds. Those prodigious, persistent dayside clouds would have reflected sunlight, keeping Venus cooler than it otherwise might have been and actually preventing a runaway greenhouse effect and unrestrained global warming.&lt;/p&gt;
    &lt;p&gt;Way thinks that a more plausible suspect in Venus’ demise is a form of ruinous volcanism. In its own storied past, Earth experienced prolonged eruptions of lava in single regions, known as large igneous provinces (LIPs), that lasted for hundreds of thousands and perhaps millions of years. Each of these events injected copious carbon dioxide into the atmosphere and made the world, for a time, extremely hot. One LIP 252 million years ago triggered the worst recorded mass extinction in Earth’s history, almost sterilizing the planet.&lt;/p&gt;
    &lt;p&gt;NASA&lt;/p&gt;
    &lt;p&gt;Fortunately for life, after each of these LIP events, Earth gradually drew that excess carbon dioxide deep into its rocky bowels, and the planet cooled back down. It accomplished this through a process called subduction: When tectonic plates collide, one plate can descend below the other, drawing seawater rich in dissolved carbon dioxide into the abyssal depths. That carbon remains sequestered in the lower mantle for epochal lengths of time; some of it eventually erupts back into the atmosphere via volcanism. That, in a nutshell, is how Earth’s global thermostat is regulated.&lt;/p&gt;
    &lt;p&gt;It’s possible that back when there was water on Venus, it also had Earth-like plate tectonics with major subduction zones. But the system wasn’t widespread or large-scale enough to save it from a planetary immolation — especially if several LIP events occurred at roughly the same time. Way’s models show that several concurrent LIPs could have thrown vast quantities of carbon dioxide into Venus’ atmosphere, warming the world so severely that much of its liquid water boiled away into the sky, accelerating the warming further. With no oceans to speak of, all that carbon dioxide could not be reabsorbed. Moreover, water is an enabler of subduction: It lowers the melting point of rocks, allowing tectonic plates to more easily bend and break. And so, with no water left at the surface, major subduction zones would grind to a halt, preventing the entombment of carbon dioxide.&lt;/p&gt;
    &lt;p&gt;Other scientists tend to agree with Way’s assessment: The sun alone cannot be responsible for making Venus the awful place it is today. “I really do think you need multiple extreme volcanic episodes … to get there,” said Anna Gülcher, a planetary scientist at the University of Bern in Switzerland.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to Break the World&lt;/head&gt;
    &lt;p&gt;While studying Venus and its runaway greenhouse wasteland, Kane became morbidly curious: Could the same fate befall Earth? “What if we shut down the carbon cycle on Earth?” he said. “Could you produce a Venus?”&lt;/p&gt;
    &lt;p&gt;To find out, he and his team built a virtual world-destroying machine. “Everybody loves a post-apocalyptic or doomsday scenario, provided it’s 5 billion years in our future,” he said.&lt;/p&gt;
    &lt;p&gt;Courtesy of Stephen Kane&lt;/p&gt;
    &lt;p&gt;The first step was to fast-forward their model of Earth about 3.5 billion years, to when the sun and planets will be 8 billion years old. At that point, the sun will shine brighter than it does today, and Earth’s atmosphere will receive the same level of roasting-hot starlight that Venus did when it was just 1 billion years old. Back then, it’s thought, Venus would have been at a tipping point: either temperate and waterlogged, or burnt to a crisp. The 8 billion-year-old sun will push Earth to a similar, climatic knife-edge.&lt;/p&gt;
    &lt;p&gt;The team’s model suggests that in 3.5 billion years, Earth’s oceans could begin evaporating and become heat-trapping water vapor in the atmosphere. That could be sufficient to kill off Earth’s major subduction zones, since without water, there might be no subduction (plus, there would be less water for carbon dioxide to dissolve into in the first place). “We’re losing the ability to draw back that CO2 into the Earth’s mantle. So it just builds up,” said Michelle Hill of Stanford University, a member of the Reuniting Twins project.&lt;/p&gt;
    &lt;p&gt;The shutdown of major subduction zones would mean that the Earth’s tectonic plates stop clashing and jostling about. Instead, they would form a near-united rocky shell around the hot mantle. For a time, the mantle would get hotter, since the shell around it would trap heat generated by radioactively decaying compounds inside it. As heat accumulates in the interior, the Earth in Kane’s simulations would experience an uptick in volcanism lasting for about 15 million years.&lt;/p&gt;
    &lt;p&gt;This period, known as a “stagnant lid regime,” adds even more carbon dioxide to the sky. But the eruptive spike is short-lived. The mantle cools down and the crust thickens until it becomes nearly impermeable to any major carbon-erupting volcanism.&lt;/p&gt;
    &lt;p&gt;So 15 million years after its stagnant lid forms, Earth will have reached a new equilibrium. Occasional spurts of volcanism would still happen. (Likewise, scientists have found compelling evidence that Venus is volcanically active today.) But Kane explained that these sporadic eruptions aren’t expected to add much carbon to the atmosphere.&lt;/p&gt;
    &lt;p&gt;At that point, the team’s simulations stop. How Venus-like is their model of the future Earth?&lt;/p&gt;
    &lt;p&gt;USGS&lt;/p&gt;
    &lt;head rend="h2"&gt;There’s No Place Like Venus&lt;/head&gt;
    &lt;p&gt;If or when Earth’s large-scale subduction shuts off in about 3.5 billion years, kneecapping the planet’s ability to bury carbon, Kane and his team’s simulations indicate that the carbon dioxide level in the atmosphere will rise anywhere from 0.1 bars to 0.8 bars. (For reference, the total atmospheric pressure at sea level today is 1 bar, and roughly 0.04% of that, or 0.042 bars, comes from carbon dioxide.) Even in their best-case scenario of a 0.1-bar rise in carbon dioxide, Earth’s surface temperature surpasses 100 degrees Celsius (212 degrees Fahrenheit). The same happens at 0.8 bars, but far more quickly.&lt;/p&gt;
    &lt;p&gt;Either way, the surface of the world becomes literally boiling hot. Earth will “turn into a post-runaway greenhouse state,” Kane said. “The surface temperature will be too hot for any water. It’ll all boil away.” Nothing sitting on the world’s skin would survive.&lt;/p&gt;
    &lt;p&gt;Still, Earth won’t get close to the state that Venus is in today. “It’d be Venus lite,” Kane said.&lt;/p&gt;
    &lt;p&gt;Venus has a 93-bar atmosphere consisting of 96.5% carbon dioxide. Kane and his colleagues’ doomsday machine, no matter how hard they push it, cannot take Earth to those levels. “I was surprised by that,” he said. Because the mantle is sealed off by a stagnant lid, volcanism drops, protecting Earth from a Venus-style roasting better than he thought.&lt;/p&gt;
    &lt;p&gt;Independent scientists have praised the Reuniting Twins project for challenging prior assumptions and adding significantly to the discussion about the terminal state of rocky planets.&lt;/p&gt;
    &lt;p&gt;“I like their idea,” Way said, adding that the team’s version of a future Earth “doesn’t sound unreasonable.”&lt;/p&gt;
    &lt;p&gt;“You end up with a world that’s stinkingly hot,” said Byrne, the Washington University planetary scientist. But, he said, the possibility that it may not be Venusian levels of hot is intriguing.&lt;/p&gt;
    &lt;p&gt;Kane’s team acknowledged that their model hasn’t considered LIP-style mega-eruptions, and that these events could feasibly add a bounty of trapped carbon to the atmosphere at any point in the future. Maybe Earth gets unlucky and experiences multiple, simultaneous LIP events (though this grows less likely over time, Kane said, as the mantle cools and its churning slows). If so, that scenario could push Earth to be more like Venus than the team’s model suggests.&lt;/p&gt;
    &lt;p&gt;Uncertainties abound. But if Kane’s team is even broadly correct, it suggests that Venus has a uniquely grim history. Something — perhaps an inundation of lava — burned that planet to the bone. Earth, meanwhile, has so far been unable to bring about its own destruction. Let’s hope that remains the case long into the future.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/why-is-venus-hell-and-earth-an-eden-20250915/"/><published>2025-09-21T22:56:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45327478</id><title>Biconnected components</title><updated>2025-09-22T15:11:49.670224+00:00</updated><content>&lt;doc fingerprint="7f2d86d422351d9d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Biconnected Components&lt;/head&gt;
    &lt;p&gt;There are many articles online about graphs and (1-)connected components, but not many about biconnected components (BCCs), even though these are way more interesting and can be used to solve many problems! Especially in competitive programming it is vital to know about this concept.&lt;/p&gt;
    &lt;p&gt;I will outline what biconnected components are, how they work similar to/different from connected components, and how to find them algorithmically (with C++ code included). Presumed knowledge is knowing what a graph is. Sections:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Biconnectedness in a Problem (introduces runing example)&lt;/item&gt;
      &lt;item&gt;Edge-Biconnected Components&lt;/item&gt;
      &lt;item&gt;Tarjan's Algorithm&lt;/item&gt;
      &lt;item&gt;C++ Implementation&lt;/item&gt;
      &lt;item&gt;Bonus 1: Edge-Disjoint Paths&lt;/item&gt;
      &lt;item&gt;Bonus 2: Vertex-Biconnected Components&lt;/item&gt;
      &lt;item&gt;Appendix: List of Relevant Terms&lt;/item&gt;
      &lt;item&gt;Appendix: Proof of Connection Between Edge-Biconnectedness and Bridges&lt;/item&gt;
      &lt;item&gt;Appendix: Proof of Connection Between Bridges and Simple Cycles&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Biconnectedness in a Problem&lt;/head&gt;
    &lt;p&gt;Let's introduce the concept by looking at a problem that BCCs could help solve.&lt;/p&gt;
    &lt;p&gt;Charlotte is a secret agent for Enforcement of Metro Integrity (EMI), and she is tasked with transporting a top-secret package from one of her informants, Alice, to an undercover agent, Bob. Alice and Bob must not meet each other, because that would ruin the safety of the mission, so they must be at different metro stations, and Charlotte can naturally only use the metro network for transport. The matter is further complicated by the fact that Eve, Charlotte's adversary, is trying to sabotage the mission by disabling one unknown metro connection! For the sets of meeting locations \( A \) where Alice can meet and \( B \) where Bob can meet, how many possible pairs \( (a, b) \) are there such that Charlotte can safely transport the package from \( a \) to \( b \) no matter which line Eve disables?&lt;/p&gt;
    &lt;p&gt;Example metro network 1: nodes in the \( A \) set are marked with an A, nodes in the \( B \) set are marked with a B; an example valid pair of locations would be \( (3, 1) \), because no matter which metro line Eve chooses to sabogate, there is still a path from \( 3 \) to \( 1 \).&lt;/p&gt;
    &lt;p&gt;The metro network is a graph \( G \) with \( n \) nodes (metro stations) and \( m \) edges (metro lines). \( A \) and \( B \) are then subsets of the set of nodes \( V(G) \). We are trying to find an algorithm with the best possible running time. We can use the following definition to make the objective a bit more precise:&lt;/p&gt;
    &lt;p&gt;Definition: two nodes \( a, b \) are edge-biconnected if for any edge \( e \), there exists a path from \( a \) to \( b \) that does not go through \( e \).&lt;/p&gt;
    &lt;p&gt;Then in this problem we are trying to count the number of pairs \( (a, b) \) with \( a \in A \) and \( b \in B \) that are edge-biconnected. After all, no matter what edge Eve sabotages, we always still have a path between the two nodes.&lt;/p&gt;
    &lt;p&gt;The most naive algorithm would be to consider each \( a \in A \) and \( b \in B \). We would then go over each edge, remove it, and check if there is still a path from \( a \) to \( b \) using a simple graph traversal. This approach would have a time complexity of \( O(|A| \cdot |B| \cdot m \cdot (n + m)) \), which is very bad.&lt;/p&gt;
    &lt;p&gt;We could try to speed up this approach by precomputing for each edge the connected components (CCs) of the graph without that edge, making the path checking constant time. First we would start with the set of all \( (a, b) \) pairs, and iteratively remove pairs that we find can be blocked off by Eve's sabotage. Then we would iterate over each of the \( m \) edges, and: (1) remove it and compute for each node in which connected component it lies (\( O(m + n) \) time using a simple graph traversal), and (2) for each \( (a, b) \) pair, remove it if they do not both lie in the same connected component (now a constant time operation, so \( O(|A| \cdot |B|) \) overall). This leads to to a complexity of \( O(m \cdot ((n + m) + |A| \cdot |B|)) \), which is definitely an improvement, and we considered how to leverage connected components. Click through the animation below to see how this algorithm would work (the dashed circles indicate connected components with the edge removed). However, the running time is still quite miserable.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: all nodes can reach all nodes.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: all nodes can reach all nodes.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: remove pairs starting with 5 ending with 1/6/7.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: all nodes can reach all nodes.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: all nodes can reach all nodes.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: all nodes can reach all nodes.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: remove pairs starting with 2/4/5 ending with 6/7, and pairs starting with 6/8 ending with 1/5.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: all nodes can reach all nodes.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: all nodes can reach all nodes.&lt;/p&gt;
    &lt;p&gt;If Eve sabotages this edge: all nodes can reach all nodes.&lt;/p&gt;
    &lt;p&gt;The final set of pairs is \( \{ (2, 1), (4, 1), ~~ (5, 5), ~~ (6, 6), (6, 7), (8, 6), (8, 7) \} \).&lt;/p&gt;
    &lt;p&gt;In this example, we are definitely doing a lot of unnecessary work, and you might also notice that the final set of pairs has a specific pattern to it (whitespace to make this a bit more obvious). We can (suggestively) draw the pairs in the graph as follows:&lt;/p&gt;
    &lt;p&gt;Notice that we just have a few clusters of nodes, and within each cluster every possible pair is interconnected (a clustering like this is called a partition of the nodes). Can we prove that we can always find such a clustering/partition? Or could it be that in some graph, there is an edge-biconnected pair \( x, y \), an edge-biconnected pair \( y, z \), but not an edge-biconnected pair \( x, z \)? (Think about counterexamples, or convince yourself this should always hold.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Edge-Biconnected Components&lt;/head&gt;
    &lt;p&gt;Okay, I am kind of giving it away by naming this section like this. But it is a very doable exercise to prove that such a partition is always possible, where within each cluster all the pairs are connected through a pair of edge-disjoint paths, and between two distinct clusters, there are no pairs connected in that way. When thinking about partitions, you should always think about the mathematical concept of an equivalence relation. If edge-biconnectedness were an equivalence relation, we would need to prove the following three properties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reflexivity: any node \( u \) is edge-biconnected to itself.&lt;/item&gt;
      &lt;item&gt;Symmetry: if \( u \) is edge-biconnected to \( v \), then \( v \) must be edge-biconnected to \( u \).&lt;/item&gt;
      &lt;item&gt;Transitivity: if \( u \) is edge-biconnected to \( v \) and \( v \) is edge-biconnected to \( w \), then \( u \) must be edge-biconnected to \( w \).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It turns out that edge-biconnectedness is in fact an equivalence relation. The proofs for these properties are definitely doable to do for yourself! (Try this! Or look at the proof for the first property and then try the other two yourself. For transitivity, you have to consider that the two assumed paths can be overlapping.) Regardless, I will give the proof here, together with a "proof by picture":&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reflexivity: let \( u \) be any node. Obviously no matter what edge we remove, we still have a path from \( u \) going to itself, namely the empty path. Therefore, \( u \) is edge-biconnected to \( u \).&lt;/item&gt;
      &lt;item&gt;Symmetry: let \( u \) and \( v \) be any nodes, assume that \( u \) is edge-biconnected to \( v \), and let \( e \) be any edge that we must not use. Because \( u \) was edge-biconnected to \( v \), we can choose \( p \) to be the path from \( u \) to \( v \) that does not use \( e \). Because this path lives in an undirected graph, we can reverse the path to get a path from \( v \) to \( u \) that still does not use \( e \). Therefore, \( v \) is edge-biconnected to \( u \).&lt;/item&gt;
      &lt;item&gt;Transitivity: let \( u \), \( v \) and \( w \) be any nodes, assume that \( u \) is edge-biconnected to \( v \) and that \( v \) is edge-biconnected to \( w \), and let \( e \) be any edge that we must not use. Because \( u \) was edge-biconnected to \( v \), we can choose \( p \) to be the path from \( u \) to \( v \) that does not use \( e \). Because \( v \) was edge-biconnected to \( w \), we can choose \( q \) to be the path from \( v \) to \( w \). If \( p \) and \( q \) do not overlap in any edges, simply concatenate to get a path \( p q \) from \( u \) to \( w \). If they do however overlap at some point, take the subpath \( p' \) of \( p \) from \( u \) to the earliest point where the overlap, take the subpath \( q' \) of \( q \) from that point to \( w \), and concatenate to get a path \( p' q' \) from \( u \) to \( w \) that does not use \( e \) and does not overlap with itself. Therefore in either case, \( v \) is edge-biconnected to \( w \). (See figure.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example for transitivity proof: \( e \) marks the sabotaged edge.&lt;/p&gt;
    &lt;p&gt;Example for transitivity proof: path from \( u \) to \( v \).&lt;/p&gt;
    &lt;p&gt;Example for transitivity proof: path from \( v \) to \( w \).&lt;/p&gt;
    &lt;p&gt;Example for transitivity proof: red marks the first overlapping node of the two paths.&lt;/p&gt;
    &lt;p&gt;Example for transitivity proof: concatenated path from \( u \) to \( w \).&lt;/p&gt;
    &lt;p&gt;This gives us a new algorithm for our problem. First compute the edge-biconnected components for the entire graph. Then within each component count how many \( A \) nodes and how many \( B \) nodes there are. Because within a component each pair of nodes is edge-biconnected, we can simply multiply the A count by the B count and add this value to the result. Between any two different components there are no edge-biconnected pairs, we are not missing any pairs. Now all we need is an algorithm for computing edge-biconnected components!&lt;/p&gt;
    &lt;head rend="h2"&gt;Tarjan's Algorithm&lt;/head&gt;
    &lt;p&gt;As could be seen in the example of our connected-component-based algorithm, there are certain edges that, when removed, will split up the graph into more connected components. These edges are called bridges.&lt;/p&gt;
    &lt;p&gt;Definition: an edge \( \{ u, v \} \) is a bridge if there is no path between \( u \) and \( v \) in \( G - \{ u, v \} \).&lt;/p&gt;
    &lt;p&gt;If we can find the bridges of the graph, then finding the edge-biconnected components will be very easy, because they are simply the connected components of the graph with all bridges removed. This follows from the following lemma.&lt;/p&gt;
    &lt;p&gt;Lemma 1: two nodes are edge-biconnected if and only if they are in the same connected component of the graph with all bridges removed. (See the appendix for the proof, which is safe to skip.)&lt;/p&gt;
    &lt;p&gt;The algorithm for finding bridges was invented by famous computer scientist Robert Tarjan and only uses depth-first search. (Fun fact: Tarjan's brother James is a chess grandmaster.) Let's look at the first observation that makes this algorithm works:&lt;/p&gt;
    &lt;p&gt;Lemma 2: an edge \( e \) is a bridge if and only if there does not exist a simple cycle that goes through \( e \). (See the appendix for the proof, which is safe to skip.)&lt;/p&gt;
    &lt;p&gt;We can check this condition for all edges by performing a DFS and looking at the back-edges of the DFS tree. For instance, this is what a DFS tree looks like for the example if we start at node 1:&lt;/p&gt;
    &lt;p&gt;A possible DFS tree. Filled arrows are tree-edges and dotted arrows are back-edges.&lt;/p&gt;
    &lt;p&gt;We know that back edges are always part of a cycle. Thus, we can make the following two observations about the connection between bridges, by using lemma 2.&lt;/p&gt;
    &lt;p&gt;Observation: a back edge is never a bridge.&lt;/p&gt;
    &lt;p&gt;Observation: a tree edge \( (u, v) \) is a bridge if and only if none of the descendants of \( v \) has a back edge to an ancestor of \( u \).&lt;/p&gt;
    &lt;p&gt;Tarjan's algorithm maintains for every node a \( \mathit{low} \) value, which is the minimum between (1) the DFS entry time of the node itself, (2) the entry times of all back-edge neighbors, and (3) the \( \mathit{low} \) values of the children. Then a tree edge \( (u, v) \) is a bridge if and only if \( low[v] \) is strictly greater than the entry time of \( u \). Essentially, this means that when the algorithm visits a back edge \( (u, v) \), all of the tree edges between \( v \) and \( u \) are marked as not being a bridge as soon as we go back up the DFS tree.&lt;/p&gt;
    &lt;p&gt;Step through the example below. I have made the graph such that the DFS entry time matches the node labels.&lt;/p&gt;
    &lt;p&gt;All nodes start with \( \mathit{low} \) equal to the DFS entry time.&lt;/p&gt;
    &lt;p&gt;Visit tree edge \( (1, 2) \).&lt;/p&gt;
    &lt;p&gt;Visit tree edge \( (2, 3) \).&lt;/p&gt;
    &lt;p&gt;Visit back edge \( (3, 1) \): update \( \mathit{low}[3] := \min(\mathit{low}[3], 1) \). All tree edges shown in red thus cannot be bridges.&lt;/p&gt;
    &lt;p&gt;Visit tree edge \( (3, 4) \).&lt;/p&gt;
    &lt;p&gt;Visit back edge \( (4, 1) \): update \( \mathit{low}[4] := \min(\mathit{low}[4], 1) \). All tree edges shown in red thus cannot be bridges.&lt;/p&gt;
    &lt;p&gt;Visit tree edge \( (4, 5) \).&lt;/p&gt;
    &lt;p&gt;Node 5 has no children, so \( \mathit{low}[5] = 5 \). Since \( \mathit{low}[5] &amp;gt; 4 \), the edge is a bridge.&lt;/p&gt;
    &lt;p&gt;Visit tree edge \( (4, 6) \).&lt;/p&gt;
    &lt;p&gt;Visit tree edge \( (6, 7) \).&lt;/p&gt;
    &lt;p&gt;Visit tree edge \( (7, 8) \).&lt;/p&gt;
    &lt;p&gt;Visit back edge \( (8, 6) \): update \( \mathit{low}[8] := \min(\mathit{low}[8], 6) \). All tree edges shown in red thus cannot be bridges.&lt;/p&gt;
    &lt;p&gt;So \( \mathit{low}[8] = 6 \).&lt;/p&gt;
    &lt;p&gt;Update \( \mathit{low}[7] := \min(\mathit{low}[7], \mathit{low}[8]) \).&lt;/p&gt;
    &lt;p&gt;Update \( \mathit{low}[6] := \min(\mathit{low}[6], \mathit{low}[7]) \). Since \( \mathit{low}[6] &amp;gt; 4 \), the edge is a bridge.&lt;/p&gt;
    &lt;p&gt;Update \( \mathit{low}[4] := \min(\mathit{low}[4], \mathit{low}[6]) \).&lt;/p&gt;
    &lt;p&gt;Update \( \mathit{low}[3] := \min(\mathit{low}[3], \mathit{low}[4]) \).&lt;/p&gt;
    &lt;p&gt;Update \( \mathit{low}[2] := \min(\mathit{low}[2], \mathit{low}[3]) \).&lt;/p&gt;
    &lt;p&gt;Update \( \mathit{low}[1] := \min(\mathit{low}[1], \mathit{low}[2]) \).&lt;/p&gt;
    &lt;p&gt;As you can see, the algorithm finds the bridges, and even appears to identify edge-biconnected components. It can be modified to find the edge-biconnected components and even articulation points (which is a concept related to vertex-biconnectedness) in a single pass, but understanding and proving why this works is quite difficult.&lt;/p&gt;
    &lt;p&gt;Since the algorithm only performs a DFS and maintains some integers associated with the nodes, it has a time complexity of \( O(|V| + |E|) \) and a space complexity of \( O(|V|) \) (assuming the graph space usage itself is not counted).&lt;/p&gt;
    &lt;head rend="h2"&gt;C++ Implementation&lt;/head&gt;
    &lt;p&gt;Now we can solve the original metro problem. The full code is available on this website. I also have code that computes the edge-biconnected components without the metro stuff and that also works for non-simple graphs (with self loops or multi-edges), which I tested on judge.yosupo.jp. All code is licensed under GPL3 (see the COPYING file).&lt;/p&gt;
    &lt;p&gt; First we set up the graph data structure and implement the bridge-finding algorithm. The nodes keep track of the \( \mathit{low} \) value and whether they are in the A and/or B set. Tarjan's algorithm performs a standard DFS and computes the \( \mathit{low} \) value for each node, and puts an edge in the &lt;code&gt;bridges&lt;/code&gt; set if it meets
                the condition given in the previous section.
            &lt;/p&gt;
    &lt;code&gt;
// Copyright 2025 emilia-h
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;set&amp;gt;
#include &amp;lt;utility&amp;gt;
#include &amp;lt;vector&amp;gt;

struct Node {
    std::vector&amp;lt;int&amp;gt; adj;
    bool visited = false;
    int dfsEntryTime = -1;
    int low = -1;
    bool isA = false, isB = false;
};

void dfs(
    std::vector&amp;lt;Node&amp;gt;&amp;amp; graph,
    int i, int parent,
    int&amp;amp; time, std::set&amp;lt;std::pair&amp;lt;int, int&amp;gt;&amp;gt;&amp;amp; bridges
) {
    graph[i].dfsEntryTime = time++;

    int low = graph[i].dfsEntryTime;
    for (int j : graph[i].adj) {
        if (j == parent) { // edge back to parent
            continue;
        } else if (graph[j].visited) { // back edge
            low = std::min(low, graph[j].dfsEntryTime);
        } else { // tree edge
            graph[j].visited = true;
            dfs(graph, j, i, time, bridges);
            low = std::min(low, graph[j].low);

            if (graph[j].low &amp;gt; graph[i].dfsEntryTime) {
                bridges.insert({i, j});
                bridges.insert({j, i});
            }
        }
    }
    graph[i].low = low;
}

std::set&amp;lt;std::pair&amp;lt;int, int&amp;gt;&amp;gt; getBridges(std::vector&amp;lt;Node&amp;gt;&amp;amp; graph) {
    std::set&amp;lt;std::pair&amp;lt;int, int&amp;gt;&amp;gt; bridges;
    int time = 0;
    for (int i = 0; i &amp;lt; graph.size(); i++) {
        if (graph[i].visited) continue;
        graph[i].visited = true;
        dfs(graph, i, -1, time, bridges);
    }
    return bridges;
}
&lt;/code&gt;
    &lt;p&gt;Then we have another DFS procedure which, given a node \( i \), computes the number of A nodes and B nodes within the edge-biconnected component that it lies in. It does this by never passing through bridges, meaning it will not go to another edge-biconnected component.&lt;/p&gt;
    &lt;code&gt;
std::pair&amp;lt;int, int&amp;gt; countAB(
    std::vector&amp;lt;Node&amp;gt;&amp;amp; graph,
    int i,
    const std::set&amp;lt;std::pair&amp;lt;int, int&amp;gt;&amp;gt;&amp;amp; bridges
) {
    if (graph[i].visited) return {0, 0};
    graph[i].visited = true;
    std::pair&amp;lt;int, int&amp;gt; result {0, 0};
    if (graph[i].isA) result.first++;
    if (graph[i].isB) result.second++;
    for (int j : graph[i].adj) {
        // don't traverse bridges (act like they are removed from the graph)
        if (bridges.count({i, j})) continue;
        auto abCount = countAB(graph, j, bridges);
        result.first += abCount.first;
        result.second += abCount.second;
    }
    return result;
}
&lt;/code&gt;
    &lt;p&gt;Finally, we have some code that reads the graph and the set of A and B nodes. It runs the two DFS passes above for the whole graph. For each edge-biconnected component, it adds the product of the number of A nodes and B nodes, because that is how many \( (a, b ) \) pairs you can find within an edge-biconnected component that Eve cannot sabotage.&lt;/p&gt;
    &lt;code&gt;
int main() {
    int n, m, a, b;
    std::cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m &amp;gt;&amp;gt; a &amp;gt;&amp;gt; b;

    std::vector&amp;lt;Node&amp;gt; graph(n);
    for (int i = 0; i &amp;lt; m; i++) {
        int v, w;
        std::cin &amp;gt;&amp;gt; v &amp;gt;&amp;gt; w;
        graph[v - 1].adj.push_back(w - 1);
        graph[w - 1].adj.push_back(v - 1);
    }
    for (int i = 0; i &amp;lt; a; i++) {
        int v;
        std::cin &amp;gt;&amp;gt; v;
        graph[v - 1].isA = true;
    }
    for (int i = 0; i &amp;lt; b; i++) {
        int v;
        std::cin &amp;gt;&amp;gt; v;
        graph[v - 1].isB = true;
    }

    auto bridges = getBridges(graph);

    for (auto&amp;amp; node : graph) node.visited = false;

    // go over each edge-biconnected component and count A and B nodes
    int result = 0;
    for (int i = 0; i &amp;lt; n; i++) {
        if (graph[i].visited) continue;
        auto abCount = countAB(graph, i, bridges);
        result += abCount.first * abCount.second;
    }
    std::cout &amp;lt;&amp;lt; result &amp;lt;&amp;lt; "\n";

    return 0;
}
&lt;/code&gt;
    &lt;p&gt;The input format is as follows. The first line is \( n, m, a, b \), which are the number of nodes, the number of edges, the number of A nodes, and the number of B nodes respectively. Then follow \( m \) lines of pairs \( v~w \), which are the edges. It is assumed that the graph is simple. Then follow \( a \) lines of integers, which are the A nodes, and then \( b \) lines of integers, which are the B nodes. All nodes in the input are 1-based. There is an example input available that encodes the graph we've been using as an example, for which the code gives the correct answer 7.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bonus 1: Edge-Disjoint Paths&lt;/head&gt;
    &lt;p&gt;Another way to state the edge-biconnectedness property is that there exist two edge-disjoint paths from \( a \) to \( b \), i.e., paths that do not have any of the same edges. For instance, in the example there are two edge-disjoint paths from node 2 to 1: one that goes from 2 directly to 1, and one that goes from 2 through 3 to 1. However, there are no two edge-disjoint paths from node 5 to 7: any path must go through the same edge \( \{ 4, 6 \} \), so we cannot choose two paths to be fully edge-disjoint. The proof that this is a property that holds if and only if the nodes are edge-biconnected is not trivial. You can see the picture for an example that we have two edge-disjoint paths for each edge-biconnected pair, but not for any other pairs:&lt;/p&gt;
    &lt;p&gt;Pair: \( (2, 1) \)&lt;/p&gt;
    &lt;p&gt;Pair: \( (4, 1) \)&lt;/p&gt;
    &lt;p&gt;Pair: \( (5, 5) \)&lt;/p&gt;
    &lt;p&gt;Pair: \( (6, 6) \)&lt;/p&gt;
    &lt;p&gt;Pair: \( (6, 7) \)&lt;/p&gt;
    &lt;p&gt;Pair: \( (8, 6) \)&lt;/p&gt;
    &lt;p&gt;Pair: \( (8, 7) \)&lt;/p&gt;
    &lt;p&gt;Also note that in an undirected graph, we can see two edge-disjoint paths from \( a \) to \( b \) as an edge walk that goes from \( a \) to \( b \) and then back to \( a \) again, without repeating any edges. This is kind of like a cycle going through \( a \) and \( b \), except we may go over the same node several times.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bonus 2: Vertex-Biconnected Components&lt;/head&gt;
    &lt;p&gt;We can repeat the problem that we stated before but change one thing: what if after you pick a station for Alice and one for Bob, Eve sabotages a metro station instead of a metro line? (She would not be able to sabotage the metro station that Alice or Bob was in.) Do we still have an equivalence relation on the nodes like with edge-biconnectedness? I will not discuss it in this article, but consider the following example and think about if the transitivity property holds for vertex-biconnectedness:&lt;/p&gt;
    &lt;p&gt;I will also leave you with a hint: a node can be part of multiple vertex-biconnected components. Consider instead an equivalence relation on the edges (it's a cute little symmetry that edge-biconnectedness gives an equivalence relation on the vertices, and vertex-biconnectedness gives an equivalence relation on the edges).&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix: List of Relevant Terms&lt;/head&gt;
    &lt;p&gt;Here is a list of terms used in the theory for edge-biconnectedness and vertex-biconnectedness:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Edge-biconnectedness (for pairs of nodes): a node \( u \) is edge-biconnected to a node \( v \) if for any edge \( e \), we can find a path from \( u \) to \( v \) that does not go through \( e \).&lt;/item&gt;
      &lt;item&gt;Edge-biconnectedness (for whole undirected graphs): a graph is edge-biconnected if the graph is connected even if any one edge is removed.&lt;/item&gt;
      &lt;item&gt;Edge-biconnected components: a subset of nodes forms an edge-biconnected component if each pair of nodes within it is edge-biconnected, and it cannot have any additional nodes added to it and still have this property. (The edge-biconnected components of any graph are the equivalence classes of the edge-biconnectedness equivalence relation.)&lt;/item&gt;
      &lt;item&gt;Bridge: an edge is a bridge if, when removed, the number of connected components is increased (in the example graph there are two such edges, which you can see by stepping through the second figure).&lt;/item&gt;
      &lt;item&gt;Vertex-biconnectedness (for pairs of nodes): a node \( u \) is vertex-biconnected to a node \( v \) if there exist two vertex-disjoint paths from \( u \) to \( v \), or \( u = v \). (Note that this is not an equivalence relation.)&lt;/item&gt;
      &lt;item&gt;Vertex-biconnectedness (for whole undirected graphs): a graph is vertex-biconnected if the graph is connected even if any one node is removed.&lt;/item&gt;
      &lt;item&gt;Vertex-biconnected component: a subset of nodes forms a vertex-biconnected component if each pair of nodes within it is vertex-biconnected, and it cannot have any additional nodes added to it and still have this property. (Note that the vertex-biconnected components of a graph are not necessarily a partition of the nodes.)&lt;/item&gt;
      &lt;item&gt;Articulation point: a node is an articulation point if it is part of more than one vertex-biconnected component.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Appendix: Proof of Connection Between Edge-Biconnectedness and Bridges&lt;/head&gt;
    &lt;p&gt;Lemma 1: for any undirected graph \( G \), for any two nodes \( u, v \in V(G) \), \( u \) and \( v \) are edge-biconnected if and only if \( u \) and \( v \) are in the same connected component of \( G \) with all bridges removed.&lt;/p&gt;
    &lt;p&gt;Proof. For convenience, define \( G' \) to be \( G \) with all bridges removed.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\( (\Rightarrow) \) Assume \( u \) and \( v \) are edge-biconnected. For a contradiction, suppose \( u \) and \( v \) are not in the same connected component of \( G' \), i.e., all paths from \( u \) to \( v \) go through some bridge in \( G \). Since edge-biconnectedness implies connectedness, there must exist at least one path \( p \) between them in \( G \), and choose \( e \) to be a bridge that this path goes through. From edge-biconnectedness, we can instead choose a path \( q \) that does not go through \( e \). Choose \( C \) to be the first connected component of \( G' \) that \( q \) passes through and that \( p \) also goes through, and that is not just the connected component that \( u \) lies in (we know such a connected component must exist, because \( p \) and \( q \) at least meet in the component of \( v \) in \( G' \), and that component is separate from the component of \( u \) because we passed through the bridge \( e \)). We can join up these paths \( p \) and \( q \) in that connected component through edges that are not bridges. Now we have a cycle passing through a bridge, which is a contradiction because it implies that both endpoints of the bridge are in the same connected component even if \( e \) was removed (see also lemma 2).&lt;/item&gt;
      &lt;item&gt;\( (\Leftarrow) \) Assume \( u \) and \( v \) are in the same connected component of \( G' \). To prove their edge-biconnectedness, let \( e \) be any edge. If \( e \) is a bridge or lies outside of the connected component of \( u \) and \( v \), then trivially there exists a path from \( u \) to \( v \) that does not use \( e \). Otherwise, \( e \) must not be a bridge and that means that removing it from \( G \) does not change what vertices are connected to each other, i.e., \( u \) and \( v \) would still lie in the same connected component in \( G - e \). This means there exists a path from \( u \) to \( v \) in \( G - e \) and thus there exists a path in \( G \) that does not use \( e \) going from \( u \) to \( v \). Either way, we have a path from \( u \) to \( v \), proving that \( u \) is edge-biconnected to \( v \).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Appendix: Proof of Connection Between Bridges and Simple Cycles&lt;/head&gt;
    &lt;p&gt;Lemma 2: an edge \( \{ u, v \} \) is a bridge if and only if all simple cycles do not go through \( \{ u, v \} \).&lt;/p&gt;
    &lt;p&gt;Proof. For convenience, define \( G' := G - \{ u, v \} \) to be the graph with the edge removed.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\( (\Rightarrow) \) Let \( \{ u, v \} \) be a bridge and let \( c \) be a simple cycle in \( G \), and assume for a contradiction that \( c \) goes through \( \{ u, v \} \). Then we can remove the edge \( \{ u, v \} \) from the cycle and still have a path between \( u \) and \( v \) in \( G' \). This directly contradicts the assumption that \( \{ u, v \} \) was a bridge.&lt;/item&gt;
      &lt;item&gt;\( (\Leftarrow) \) Let \( \{ u, v \} \) be an edge through which all simple cycles do not pass. For a contradiction, suppose that \( \{ u, v \} \) was not a bridge and thus \( u \) and \( v \) are still connected in \( G' \) and thus there exists a path \( \{ v, v_1 \}, ..., \{ v_n, u \} \) in \( G' \). Since \( \{ u, v \} \) is an edge in \( G \), we can connect the two ends of the path and get a simple cycle in \( G \) that passes through \( \{ u, v \} \). This contradicts the assumption.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Copyright emilia-h 2025 licensed under CC BY-SA 4.0&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://emi-h.com/articles/bcc.html"/><published>2025-09-21T23:06:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45327964</id><title>We Politely Insist: Your LLM Must Learn the Persian Art of Taarof</title><updated>2025-09-22T15:11:48.481788+00:00</updated><content>&lt;doc fingerprint="c89c3c0289f1848f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 1 Sep 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:We Politely Insist: Your LLM Must Learn the Persian Art of Taarof&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Large language models (LLMs) struggle to navigate culturally specific communication norms, limiting their effectiveness in global contexts. We focus on Persian taarof, a social norm in Iranian interactions, which is a sophisticated system of ritual politeness that emphasizes deference, modesty, and indirectness, yet remains absent from existing cultural benchmarks. We introduce TaarofBench, the first benchmark for evaluating LLM understanding of taarof, comprising 450 role-play scenarios covering 12 common social interaction topics, validated by native speakers. Our evaluation of five frontier LLMs reveals substantial gaps in cultural competence, with accuracy rates 40-48% below native speakers when taarof is culturally appropriate. Performance varies between interaction topics, improves with Persian-language prompts, and exhibits gender-based asymmetries. We also show that responses rated "polite" by standard metrics often violate taarof norms, indicating the limitations of Western politeness frameworks. Through supervised fine-tuning and Direct Preference Optimization, we achieve 21.8% and 42.3% improvement in model alignment with cultural expectations. Our human study with 33 participants (11 native Persian, 11 heritage, and 11 non-Iranian speakers) forms baselines in varying degrees of familiarity with Persian norms. This work lays the foundation for developing diverse and culturally aware LLMs, enabling applications that better navigate complex social interactions.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2509.01035"/><published>2025-09-22T00:31:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45328247</id><title>How I, a beginner developer, read the tutorial you, a developer, wrote for me</title><updated>2025-09-22T15:11:47.441885+00:00</updated><content>&lt;doc fingerprint="96781013d7103f19"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I, a non-developer, read the tutorial you, a developer, wrote for me, a beginner&lt;/head&gt;
    &lt;p&gt;“Hello! I am a developer. Here is my relevant experience: I code in Hoobijag and sometimes jabbernocks and of course ABCDE++++ (but never ABCDE+/^+ are you kidding? ha!) and I like working with Shoobababoo and occasionally kleptomitrons. I’ve gotten to work for Company1 doing Shoobaboo-ing code things and that’s what led me to the Snarfus. So, let’s dive in!&lt;/p&gt;
    &lt;p&gt;About this tutorial&lt;/p&gt;
    &lt;p&gt;I first started doing Very Simple Thing2 with Snarfus, but the more I used it the more I saw the potential! Despite the jaggle of the chromus, it’s really multi-purpose. And that’s what led me to argyling the pintafore with the quagmire instead of the hoobastank! I know, crazy. But it was kind of working, and actually a lot of fun… Until I hit a big roadblock: the fisterfunk will NOT talk to the shamrock portal or even send beep-boops back to the Snarfus! Of course, you know what that means3 — Now the entire hoob-tunnel is clogged with gramelions. Unacceptable.&lt;/p&gt;
    &lt;p&gt;I almost gave up but then I realized: If I connect the backside Snarfus stagnator to the backside shamrock Klingon troglodyte emulater, it’s good! Everything beep-boops and ding-dongs and I get the Actual Topic of the Tutorial, which lets me do the Very Simple Thing the way I want after all! Pretty cool4.&lt;/p&gt;
    &lt;p&gt;So here’s how to set it up:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;In the terminal, ajkl;gawgor;iqeg;iJLkqen. wl;R aw;oeiga 4648664 arjarwgj;llj;ja fadgfgajkljl; wlj;sdjk;lfas&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Next go to folder/hidden/deep/in/the/file/system/surprise!.file and copy the contents of the file. If it’s not there, it might be in library/library/library/llibrary/liiiiiibrarrrary/llllliiiiibrary/hidden/hidden/hiding/you can’t find me/hidden/nope/never/hahahahereiam.file.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Now go back to the terminal and paste in the file contents, then type in 64A786AGR45JAR; rdja;jg [[]][[]][[]][[]]][[]()()()()()()()()(){{}{}{}|{}{|}{}{|}{ ////////////////!! !!!! !! //// !!! agjlkargji;lwej;OI [ASRGASG[]ASGDASG[]EAEadgasg[]EAGE[edaga][]ahgr-0-0=-0-=0-=0=0-0=-0-=0=-0-=0=-0=-0!!!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Boop!5&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Open Snarfus and upload the file you just made.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Just for shits and giggles, you can de-sham the chronostatiomatrix by running —()()(]]asdg a=-do —cd go cd stay —sususudododo baby shark—][] but that’s optional.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That’s it!&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let me know how it goes for you. I’d love to hear if anybody uses this approach with GewGawGamma or ometer2.7.”&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;I probably should recognize Company because it seems illustrious but I do not recognize Company or know what they do. ↵&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is not simple. ↵&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I do not know what that means. ↵&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is cool. I don’t really understand how, but I believe it. I’m glad you know how to do it. ↵&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The first 3 steps will take me approximately 7 hours and 193 internet searches to complete. When I finally get to Boop! it will be really satisfying.&lt;/p&gt;
        &lt;p&gt;This is meant in good fun. I really appreciate the folks who take time to share their knowledge and write up tutorials and give tips and so on. ↵&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://anniemueller.com/posts/how-i-a-non-developer-read-the-tutorial-you-a-developer-wrote-for-me-a-beginner"/><published>2025-09-22T01:27:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45329127</id><title>Privacy and Security Risks in the eSIM Ecosystem [pdf]</title><updated>2025-09-22T15:11:46.885804+00:00</updated><content/><link href="https://www.usenix.org/system/files/usenixsecurity25-motallebighomi.pdf"/><published>2025-09-22T04:35:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45329414</id><title>Download responsibly</title><updated>2025-09-22T15:11:46.010531+00:00</updated><content>&lt;doc fingerprint="2ce57d957d222cce"&gt;
  &lt;main&gt;
    &lt;p&gt;10.09.2025 | Frederik Ramm&lt;/p&gt;
    &lt;p&gt;This month we’ve ramped up the infrastructure behind the download server, and downloads should now be available earlier&lt;lb/&gt; and faster. There’s also a small technical change in that requests for a “…latest” file will now be answered with a&lt;lb/&gt; HTTP redirect to the specific latest version (see previous blog post).&lt;/p&gt;
    &lt;p&gt;I would like to use this opportunity to appeal to users of the download server to “download responsibly”. We want&lt;lb/&gt; to continue offering this service as powerful and as convenient as possible within our means. We want everyone&lt;lb/&gt; to have easy access to the latest OSM data in a form that is useful to them.&lt;/p&gt;
    &lt;p&gt;Every now and then, people break things for others. There have been individual clients downloading the exact same&lt;lb/&gt; 20-GB file 100s of times per day, for several days in a row. (Just the other day, one user has managed to download almost 10,000 copies of the italy-latest.osm.pbf file in 24 hours!) Others download every single file we have on the&lt;lb/&gt; server, every day. There’s a limit to the outgoing network bandwidth, and behaviour like this means that&lt;lb/&gt; things are slowing down for everyone. Also, when we block an IP range for abuse, innocent third parties can be affected. &lt;/p&gt;
    &lt;p&gt;Here’s three concrete appeals to users of the download server:&lt;/p&gt;
    &lt;p&gt;1. If you want data for the whole planet, don’t download it piecemeal from us – simply get the planet file from planet.openstreetmap.org and you’re done!&lt;lb/&gt; 2. If you want a large region (like Europe or North America) updated daily, use the excellent pyosmium-up-to-date program which will automatically determine the age of your local file and update it by downloading the latest changes; this saves something like 98% of network traffic compared to a fresh download, and is faster.&lt;lb/&gt; 3. If you automate anything with regard to our download server, monitor what your script is doing or build in appropriate catches so that you don’t end up downloading the same file 1000 times just because your disk is full or something like that.&lt;/p&gt;
    &lt;p&gt;Happy downloading!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.geofabrik.de/index.php/2025/09/10/download-responsibly/"/><published>2025-09-22T05:33:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45330198</id><title>Show HN: Software Freelancers Contract Template</title><updated>2025-09-22T15:11:45.347186+00:00</updated><content>&lt;doc fingerprint="f531f568962cddb4"&gt;
  &lt;main&gt;
    &lt;p&gt;FI EN 1 2 . . 3 ⚠️ → GoogleDoc &amp;amp; GitHub ✓ + + + + ✓ ✓ : ( ) : ( , ) { $refs.tilaajanYtunnusRaaka.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisTilaajanYritys();" type="text" name="tilaajanYritys" :placeholder="t('placeholderInputClientCompany')" autocomplete="off" tabindex="0" class="input-text px-3 py-2" /&amp;gt; { $refs.tilaajanYhteyshenkiloRaaka.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisTilaajanYtunnus();" type="text" name="tilaajanYtunnus" placeholder="1234567-1" autocomplete="off" tabindex="0" class="input-text px-3 py-2" /&amp;gt; { $refs.tilaajanEmailRaaka.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisTilaajanYhteyshenkilo();" type="text" name="tilaajanYhteyshenkilo" :placeholder="t('placeholderInputClientContactPerson')" autocomplete="off" tabindex="0" class="input-text px-3 py-2" /&amp;gt; { $refs.tilaajanPuhelinRaaka.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisTilaajanEmail();" type="email" name="tilaajanEmail" :placeholder="t('placeholderInputClientEmail')" autocomplete="off" tabindex="0" class="input-text px-3 py-2" :class="tilaajanEmailError ? 'border-red-500' : ''" /&amp;gt; ✓ : ( ) : ( , ) { $refs.toimittajanYtunnusRaaka.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisToimittajanYritys();" type="text" name="toimittajanYritys" :placeholder="t('placeholderInputFreelancerCompany')" autocomplete="off" tabindex="0" class="input-text px-3 py-2" /&amp;gt; { $refs.toimittajanYhteyshenkiloRaaka.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisToimittajanYtunnus();" type="text" name="toimittajanYtunnus" placeholder="1234567-1" autocomplete="off" tabindex="0" class="input-text px-3 py-2" /&amp;gt; { $refs.toimittajanEmailRaaka.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisToimittajanYhteyshenkilo();" type="text" name="toimittajanYhteyshenkilo" :placeholder="t('placeholderInputFreelancerContactPerson')" autocomplete="off" tabindex="0" class="input-text px-3 py-2" /&amp;gt; { $refs.toimittajanPuhelinRaaka.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisToimittajanEmail();" type="email" name="toimittajanEmail" :placeholder="t('placeholderInputFreelancerEmail')" autocomplete="off" tabindex="0" class="input-text px-3 py-2" :class="toimittajanEmailError ? 'border-red-500' : ''" /&amp;gt; ✓ { $refs.ohjelmistokehittajaRadioWrapper.focus({ preventScroll: true }); }, 10);" @blur="kirjaaValmisProjektinNimi();" type="text" name="projektinNimi" :placeholder="t('placeholderProjectName')" autocomplete="off" tabindex="0" class="input-text px-3 py-2" /&amp;gt; ✓ ✓ ✓ ✓ ✓ ✓ { if (!onFocus) $refs.continueButton.focus({ preventScroll: true }); }, 50);" x-transition:enter.duration.400ms @transitionstart.once="$refs.maksuaikaRaaka.focus({ preventScroll: true }); tarvittaessaScrollaaAlas();" tabindex="0" class="border-2 p-4 pl-5 mt-4 rounded" :class="onFocus ? 'border-gray-500 border-dashed' : 'border-gray-700 border-solid'" &amp;gt; ⚠️ €/h €/h €/h ⚠️&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sopimusgeneraattori.ohjelmistofriikit.fi/?lang=en"/><published>2025-09-22T07:35:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45330378</id><title>You did this with an AI and you do not understand what you're doing here</title><updated>2025-09-22T15:11:45.078078+00:00</updated><content>&lt;doc fingerprint="baba43bfbdc7bb61"&gt;
  &lt;main&gt;
    &lt;p&gt;It looks like your JavaScript is disabled. To use HackerOne, enable JavaScript in your browser and refresh this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hackerone.com/reports/3340109"/><published>2025-09-22T07:59:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45330407</id><title>SGI demos from long ago in the browser via WASM</title><updated>2025-09-22T15:11:44.577516+00:00</updated><content>&lt;doc fingerprint="f7d69218d4b7b003"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;SGI demos from long ago, running in your browser today.&lt;/head&gt;
    &lt;p&gt;Old problems require modern solutions.&lt;/p&gt;
    &lt;p&gt;This is the original SGI demo source code, compiled for the web using Emscripten and SDL2. Rendering is done using an IRIS GL software rasterizer from the Alice 4 project. Event handling is done by SDL2, with events translated into GL's event system. Each demo is a separate web page, with its own Javascript + WASM compiled by Emscripten from the original C/C++ source. Minimal modifications have been made to the original source, in order to run in the browser and to work with compilers 35 years newer.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Flight (cockpit glitches, planes too slow in web version, night mode 'shimmers', no network play)&lt;/item&gt;
      &lt;item&gt;Newave (no mesh editing, no popup menus, only wireframe)&lt;/item&gt;
      &lt;item&gt;Arena (no network play)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Homebrew if you don't have it, then get SDL2 and Emscripten:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;brew install SDL2
brew install emscripten&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/sgi-demos/sgi-demos.git
cd sgi-demos
make&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Install Winget if you don't have it.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Install MSYS2 from cmd.exe, in order to get the clang compiler:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;winget install MSYS2.MSYS2
setx PATH "%PATH%C:\msys64\clang64\bin"&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install clang toolchain and SDL2 in MSYS2 CLANG64 shell:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pacman -Syu
pacman -S base-devel mingw-w64-clang-x86_64-toolchain
pacman -S mingw-w64-clang-x86_64-SDL2&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Clone emscripten from Github. Cloning seems to work best with MSYS2 rather than using pacman. Follow the default install directions, not the Windows directions!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Add this line to the&lt;/p&gt;&lt;code&gt;~/.bashrc&lt;/code&gt;file in MSYS2 CLANG64 shell:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;source /path/to/emsdk/emsdk_env.sh&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/sgi-demos/sgi-demos.git
cd sgi-demos
make&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rendering via OpenGLES/WebGL (WIP)&lt;/item&gt;
      &lt;item&gt;Arbitrary window size&lt;/item&gt;
      &lt;item&gt;Run GL demo in its own WASM worker/thread, to avoid slicing up the code for SDL's event loop&lt;/item&gt;
      &lt;item&gt;Popup menus, including the classic SGI menu font&lt;/item&gt;
      &lt;item&gt;More demos, all the demos. &lt;list rend="ul"&gt;&lt;item&gt;Electropaint, Cedit, any other IRIS GL demos I can find&lt;/item&gt;&lt;item&gt;Then OpenGL, GLUT, Inventor, Performer demos in no particular order&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Rudimentary context for each demo: name, author, year (as text in lower corner), code link&lt;/item&gt;
      &lt;item&gt;Virtual mouse and keyboard: &lt;list rend="ul"&gt;&lt;item&gt;Only display virtual keys and mouse functions used by the demo; use demo's qdevice() calls to determine this&lt;/item&gt;&lt;item&gt;Displayed as transparent virtual mouse and key pictures overlaid on demo&lt;/item&gt;&lt;item&gt;On always for touch devices&lt;/item&gt;&lt;item&gt;On/off for mouse/keyboard devices, as hints&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Description/history/context for each demo - can obtain some descriptions from .Info slide files&lt;/item&gt;
      &lt;item&gt;Man page live links&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Everyone who worked at SGI, for the eye candy and the baller computers.&lt;/item&gt;
      &lt;item&gt;The Alice 4 folks, for the inspiration and the GL implementation.&lt;/item&gt;
      &lt;item&gt;Emscripten and SDL teams, for making a web port possible.&lt;/item&gt;
      &lt;item&gt;Internet Archive, Bitsavers, WinWorld, IRIXNet, and others, for saving the history.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/sgi-demos"/><published>2025-09-22T08:03:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45330818</id><title>Metamaterials, AI, and the Road to Invisibility Cloaks</title><updated>2025-09-22T15:11:44.519181+00:00</updated><content/><link href="https://open.substack.com/pub/thepotentialsurface/p/metamaterials-ai-and-the-road-to"/><published>2025-09-22T09:02:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45331030</id><title>Beyond the Front Page: A Personal Guide to Hacker News</title><updated>2025-09-22T15:11:44.250369+00:00</updated><content>&lt;doc fingerprint="aec033930fbe2fe7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Beyond the Front Page: A Personal Guide to Hacker News&lt;/head&gt;
    &lt;head rend="h2"&gt;A Cure for The Eternal September&lt;/head&gt;
    &lt;p&gt;In early 1994, a group of frustrated users on Usenet, a precursor to modern forums, inadvertently coined a term: Eternal September.&lt;/p&gt;
    &lt;p&gt;The problem wasn’t the month of September itself, but the people who arrived with it. In its early days, Usenet had a relatively high barrier to entry, which helped maintain user quality and content standards. But every fall, a new wave of college freshmen would flood Usenet through their campus networks, posting haphazardly and ignoring established community norms, much to the annoyance of veteran users. Over the years, this September influx became a familiar, if unwelcome, ritual.&lt;/p&gt;
    &lt;p&gt;1994 was different. Starting the previous year, many consumer internet service providers began offering Usenet access. Suddenly, low-quality, off-topic posts from inexperienced users poured in year-round. The chaos of September had become eternal.&lt;/p&gt;
    &lt;p&gt;The phrase marks the end of the internet’s early-elite era and crystallizes a chronic dilemma for any online community: scale, topical breadth, and discussion quality form an unstable triad. The intersection of all three is, most days, a fantasy.&lt;/p&gt;
    &lt;p&gt;And yet one community has, across more than eighteen years, grown relentlessly in users and traffic while sustaining both interesting topics and a high bar of discussion: Hacker News (HN).&lt;/p&gt;
    &lt;head rend="h2"&gt;Built on a Wall of Text&lt;/head&gt;
    &lt;p&gt;HN looks plain at first glance. It’s essentially a wall of text, where even most buttons are just text links. Newcomers might not even figure out how to post here. Unlike typical online forums, the vast majority of “posts” on HN are simply shared links. The contribution of the original poster (OP), if any, is limited to a title and perhaps a brief comment, with the ensuing discussion centered on the linked content.&lt;/p&gt;
    &lt;p&gt;In other words, HN is less a forum and more a collectively curated reading list, or more plainly, an external comment section for the rest of the internet. The technical term for this format is a “link aggregator.” Other well-known examples from the past include Digg and Reddit. But Digg (as it was) is long gone, and Reddit has gradually transitioned to a more mainstream forum model, leaving HN as a unique outlier.&lt;/p&gt;
    &lt;p&gt;Despite its spartan appearance and learning curve, HN boasts over ten million monthly visits (according to SimilarWeb data), outperforming popular tech news sites like TechCrunch and Engadget. In contrast to its massive traffic, the servers that run HN are surprisingly modest: just two machines with quad-core Intel Xeon E5-2637 v4 CPUs, running FreeBSD.&lt;/p&gt;
    &lt;p&gt;To understand why HN attracts so much attention, one must look at its history. You can tell from the domain, &lt;code&gt;news.ycombinator.com&lt;/code&gt;, that HN did not start as an independent site but as a side project of Y Combinator, a renowned venture capital firm. In February 2007, Paul Graham, then president of YC, launched the site. The stated goals were prosaic and personal: publicly, to create a place for the startup community (hence the original name, Startup News), and privately, to scratch a programming itch by building a site in Arc, a Lisp dialect he co-created.&lt;/p&gt;
    &lt;p&gt;Given that lineage, HN quickly became a hub for startup founders and tech workers. For startups, it’s a channel to launch, collect feedback, and — when needed — manage crises. For indie developers and creators, making the front page is both validation and real traffic, so much so that people speak of the HN “hug-of-death,” when a small site crumples under the sudden load. (One of my posts briefly peaked around #60 and still managed to exhaust my monthly free bandwidth on Backblaze B2 in hours.)&lt;/p&gt;
    &lt;p&gt;But the discussions on HN are not just for startups and code. According to an analysis by Wilson Lin based on over forty million posts and comments, topics range far beyond entrepreneurship and programming. Consumer products, fundamental sciences like math and physics, and even humanities and social sciences are widely discussed, often with contributions from professionals in those fields. It’s no exaggeration to say that no matter your area of interest, you’re likely to find a worthwhile discussion about it on Hacker News.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Disciplined Front Page and a Tireless Moderator&lt;/head&gt;
    &lt;p&gt;A large user base and a wide range of topics are not enough to make a great community. There were many large forums that hit a tipping point where low-effort posting and polarization drag everything down. How does HN resist the slide?&lt;/p&gt;
    &lt;p&gt;A well-designed set of rules do a lot of work. The HN welcome page lays out two cardinal rules: don’t post or upvote crap links, and don’t be rude or dumb in comment threads.&lt;/p&gt;
    &lt;p&gt;What counts as “not crap”? It must be something more than “superficially interesting” that “teaches you about the world,” which rules out gossip, memes, flame-bait, clickbait headlines, and other off-topic noise. And what kind of comments are “civil and substantial”? Those are ones that “more information about the topic” and not those you wouldn’t say face-to-face.&lt;/p&gt;
    &lt;p&gt;If that still sounds a bit abstract, HN provides a more comprehensive set of guidelines with specific requirements for content, formatting, and even tone. Don’t use uppercase or exclamation points. Use the original title whenever possible. Reply to the argument instead of calling names. Assume good faith. Ultimately, the sole purpose is to ensure that HN surface things that would gratify the intellectual curiosity of a good hacker.&lt;/p&gt;
    &lt;p&gt;Of course, rules alone are not enough; they require enforcement. To this end, HN combines algorithmic mechanisms and human moderation, both of which are worth looking into.&lt;/p&gt;
    &lt;p&gt;First, the ranking of posts, which determines the first impression of any forum, is not simply based on recency or interaction count but on a very strict set of criteria. New submissions start on the “New” section with one point. Only after four “upvotes” (i.e., five points total) does a post qualify for the front page. Qualified submissions are ranked by the ratio of upvotes to time since submission, and only the top thirty submissions appear on the literal “page one.”&lt;/p&gt;
    &lt;p&gt;(As an exception, moderators can give low-traction posts a “re-upping.” If they feel a post has been overlooked, they can manually place it at the bottom of the front page, giving it a second chance without overly interfering with the algorithm.)&lt;/p&gt;
    &lt;p&gt;Votes can be gamed, though. Therefore, HN has always made voting ring detection a high priority, continuously developing and improving its systems. The exact mechanisms are not public for obvious reasons, but one can infer they likely consider factors like the referrer, the account’s seniority, and frequency of operations.&lt;/p&gt;
    &lt;p&gt;Upvotes not only boost the ranking but also earn the submitter “karma,” a term borrowed from Buddhism that functions similarly to user points or credits in other communities. However, on HN, karma confers stewardship rather than badges to show off: at 31 karma you can flag posts and comments that you find violate guidelines; enough flags hide content. At 501 karma you unlock downvoting on comments. (As an easter egg, users with 251 karma can customize the color of the top navigation bar.)&lt;/p&gt;
    &lt;p&gt;These thresholds are intentionally exclusionary. Users who skim the New section are typically dedicated members with discerning taste, and attracting four upvotes from them can be hard. Indeed, statistics show that the majority of posts on HN receive 0 or 1 upvote. Consequently, many users go years without ever submitting a post that “escapes velocity,” and thus never unlock flagging. Yet, it is perhaps this willingness to sacrifice engagement for standards that has allowed HN to maintain its quality and style for over a decade.&lt;/p&gt;
    &lt;p&gt;However, HN’s real differentiator isn’t algorithmic. That honor belongs to the human touch in its moderation, particularly the work of its resident moderator, dang (Daniel Gackle).&lt;/p&gt;
    &lt;p&gt;The New Yorker magazine published a profile of dang in 2019. Gackle, a Stanford literature major, became an HN moderator by a twist of fate. He had previously co-founded a startup that developed an online spreadsheet product with another former moderator, Scott Bell, and received funding from YC. When the startup eventually failed, Paul Graham invited him to join YC and manage HN full-time.&lt;/p&gt;
    &lt;p&gt;According to the article, dang’s moderation style is “personal, focused, and slow,” a form of “conversational art.” Have a look at his reply history: merging duplicate submissions, linking to related past discussions, editing submission titles and URLs for accuracy, and reminding heated users to adhere to the community guidelines. The tasks may seem trivial individually, but imagine performing them with dang’s frequency and accuracy, all while maintaining a consistently gentle and patient tone — including sending long emails explaining his moderations — and you can see a craft.&lt;/p&gt;
    &lt;p&gt;It’s understandable, then, that dang has earned the universal respect of the community. Search HN for “thank you dang” around holidays and you’ll find ritualized gratitude threads. It isn’t romanticizing to say you’ll struggle to find another moderator on today’s internet so widely and openly appreciated.&lt;/p&gt;
    &lt;p&gt;(It was announced in early 2025 that Tom Howard (tomhow) has become a public moderator. He has been performing moderation tasks for years behind the scenes. According to dang, Howard has a long history with Y Combinator as a W09 batchmate and with HN, which he joined in 2007.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Caveat Lector&lt;/head&gt;
    &lt;p&gt;HN isn’t flawless. It is, after all, an online forum, prone to all the familiar pitfalls: premature conclusions, inflammatory language, and overconfidence. Its user base, which disproportionately comprises U.S. tech workers with high skill and signal, also brings specific skews worth being aware of.&lt;/p&gt;
    &lt;p&gt;One of the chronic problems is commenting without reading: reacting to the headline while ignoring the linked piece, thereby spinning off debates the article already addresses or simply doesn’t make. Search for “RTFA” and you’ll find endless exasperation. So, it’s advisable for a new user to cultivate the habit of reading the link, or at least a competent AI summary, before diving into the comments. This helps avoid being misled by knee-jerk reactions.&lt;/p&gt;
    &lt;p&gt;Another HN quirk is criticism for its own sake. While critical thinking is prized on HN and often serves as a powerful bullshit detector, it can sometimes devolve into nitpicking. This is most common in threads about technical achievements or business successes, where comments often throw cold water. Similarly, projects in the Show HN section often get held to standards that only make sense later in the life cycle. (Search for “so much negative” to see the pattern.)&lt;/p&gt;
    &lt;p&gt;HN also sustains a repertoire of low-yield topics that are reliably heated yet produce little insight because they devolve into preference contests or pedantry over minor technicalities. The frequent offenders include, unsurprisingly, the perennial holy wars over which programming language, operating system, or editor is superior; newer “cult” punching bags (Rust, htmx, Nix, Wayland); and recurring policy brawls over return-to-office, layoffs, and tech immigration. When you encounter these topics, consulting Wikipedia, technical documentation, or more authoritative media is often a better use of your time.&lt;/p&gt;
    &lt;p&gt;Finally, demographics matter. HN is dominated by American tech professionals. That can tilt discourse toward elitism, rationalism, and a kind of intellectual performance, creating an echo chamber. Therefore, a comment thread that appears to be a fierce debate may converge to a local optimum, and a data-driven articulation may turn out to rest on simplified or biased priors. As The New Yorker observed, the site has a “characteristic tone of performative erudition” that “often masks a deeper recklessness.”&lt;/p&gt;
    &lt;p&gt;As such, HN should be treated as an external comment section for the internet to the extent that it can’t substitute for the internet, much less for your own thinking. At its best, HN is a map to new questions and a window onto new angles. The landscape itself remains elsewhere.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix: Tips for Reading HN&lt;/head&gt;
    &lt;p&gt;I started reading HN around early 2018. Without a background in STEM or programming, much of the discussion was beyond my knowledge, but that didn’t diminish the enjoyment. In fact, HN helped me build initial understanding and interest in many technical topics. Whenever controversial issues emerge, I habitually turn to HN for expert interpretations and opposing views, rarely coming away empty-handed.&lt;/p&gt;
    &lt;p&gt;But with numerous entries and dense discussions, reading HN well requires some technique. Based on my experience, HN isn’t ideal for mindlessly “scrolling” the front page; it’s better browsed regularly and purposefully via RSS, search, and third-party tools.&lt;/p&gt;
    &lt;p&gt;It might seem contradictory to praise the quality of the HN front page and then advise against reading it. True, the moderation mechanisms I’ve described make the front page incredibly compelling, but that itself can be a problem: without control, it easily becomes a default time-sink, leading to endless link-clicking cycles. (HN is often among websites recommended for blocking by focus-assistant tools.)&lt;/p&gt;
    &lt;p&gt;Instead, I recommend the following tools and methods for readers to consider and critique —&lt;/p&gt;
    &lt;head rend="h3"&gt;Subscribe to Filtered RSS Feeds&lt;/head&gt;
    &lt;p&gt;Hacker News has an official RSS feed (&lt;code&gt;https://news.ycombinator.com/rss&lt;/code&gt;) that mirrors the front page, but subscribing to it directly can be overwhelming. Fortunately, HN provides a comprehensive official API, which has enabled third-party developers to create more granular RSS feeds.&lt;/p&gt;
    &lt;p&gt;A popular choice is hnrss.org, which offers a variety of feeds filtered by section, user, keyword, score, and more. Among the most useful is the “Best Comments” feed. This feed aggregates newly emerging high-score comments across HN, which are not only worth reading themselves but often lead to posts that are also worthwhile and have some traction. I frequently discover quality discussions outside my usual interests here. Its update frequency is also moderate, typically around a dozen items daily, corresponding to four or five articles — a manageable amount for most daily reading.&lt;/p&gt;
    &lt;head rend="h3"&gt;Search for External URLs&lt;/head&gt;
    &lt;p&gt;As mentioned, HN’s unique posting style makes it the internet’s external comments section. Combined with its high traffic, there’s a good chance any somewhat visited English-language site or page has been discussed on HN.&lt;/p&gt;
    &lt;p&gt;As such, HN search proves to be a vital source of technical due diligence: whenever a trendy, heavily promoted product appears, I search HN for its name, website domain, or GitHub repo to see if it’s genuinely unmissable or a potential “red flag.” Similarly, for any assertive, triumphant article, I search HN for dissenting voices to gain a more rounded perspective.&lt;/p&gt;
    &lt;p&gt;However, HN’s search box is tucked away at the bottom of the homepage, making it inconvenient. My suggestion is to set &lt;code&gt;https://hn.algolia.com/?q=%s&lt;/code&gt; (where &lt;code&gt;%s&lt;/code&gt; is the search term) as a search engine shortcut or in launcher tools for direct access. Indeed, this might be the best site search you’ve ever used. Its domain reveals it’s an “add-on,” powered and hosted by search SaaS provider Algolia (a YC alum); it’s not only blazingly fast but also supports fuzzy matching and can unearth discussions from the deepest corners of the site. (See the help page for advanced syntax.)&lt;/p&gt;
    &lt;p&gt;You can also install a browser extension like Newsit, which automatically checks if the current webpage has related HN discussions and displays a banner notification.&lt;/p&gt;
    &lt;head rend="h3"&gt;Skim Comments Strategically&lt;/head&gt;
    &lt;p&gt;Hot HN posts often attract hundreds or even thousands of comments; reading them all is neither feasible nor necessary. Also, due to natural bandwagon effects, top comments attract more replies, dominating the top of the thread. Reading straight down might miss different perspectives buried later.&lt;/p&gt;
    &lt;p&gt;Therefore, I follow a personal rule: for the first top-level comment, I read at most the first three replies and their first three sub-replies. Then I move to the second top-level comment and read its first two replies and their first two sub-replies. Finally, I read the first reply to the third top-level comment and its first sub-reply. (Remember to make good use of the navigation links.) This usually provides a comprehensive overview of the thread’s viewpoints while keeping reading time manageable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Use AI to Summarize Comments&lt;/head&gt;
    &lt;p&gt;With the rise of AI tools, summarizing HN comments has become a viable option. However, for popular threads with hundreds of comments, HN paginates the results, so summarizing only the first page would be incomplete. To get around this, you can fetch the full comment data in JSON format from the HN API using this endpoint:&lt;/p&gt;
    &lt;code&gt;https://hn.algolia.com/api/v1/items/${id}
&lt;/code&gt;
    &lt;p&gt;Here, &lt;code&gt;${id}&lt;/code&gt; is the eight-digit number from the submission’s URL. You can then feed the entire JSON response to your preferred AI model with a prompt like this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Summarize the themes of the opinions in the input provided by the user. For each theme, include at least 3 UNMODIFIED quotes with attribution. Unescape HTML entities. Go long.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This can be a one-off prompt or set as a system prompt. The prompt design, inspired by Simon Willison’s work and adjusted based on personal experience, reliably summarizes the themes and stances within the comments, complete with original quotes and usernames for easy reference. Since this is a summarization task, cost-effective models like GPT mini, Gemini Flash, or Claude Haiku are perfectly adequate. Just be sure to use a model with a large context window to avoid truncation.&lt;/p&gt;
    &lt;p&gt;I’ve created a demo on Val Town using their free GPT-4o mini proxy. You can try it out and then fork the code to your own account to customize it and avoid rate limits.&lt;/p&gt;
    &lt;head rend="h1"&gt;中文版&lt;/head&gt;
    &lt;head rend="h2"&gt;「永恒的九月」有救吗？&lt;/head&gt;
    &lt;p&gt;1994 年初，在类似日后论坛的在线社区 Usenet 上，一群满腹恼火的用户无意间创造了一个术语——永恒的九月（Eternal September）。&lt;/p&gt;
    &lt;p&gt;不过，让人恼火的不是九月本身，而是九月出现的人。早期的 Usenet 访问门槛比较高，用户素质和内容质量相对容易维持。但每年秋季开学，都有一批大学新生通过校园网涌进 Usenet，四处乱发东西却又不守「规矩」，让老用户们烦恼不已。只是多年下来，大家也多少习惯了这个事实。&lt;/p&gt;
    &lt;p&gt;1994 年的情况又有些不同。从前一年开始，许多面向大众的互联网服务商也陆续提供了 Usenet 接入服务。这样一来，全年都有来自零基础用户的低质、跑题帖子占据社区——九月的混乱成为了永恒。&lt;/p&gt;
    &lt;p&gt;「永恒的九月」象征着互联网早期精英主义时代的结束，也代表着在线社区一个永恒的难题：用户规模、主题范围和讨论质量构成了三难困境，这三个目标的重合处大多时候写着「做梦」。&lt;/p&gt;
    &lt;p&gt;但确实有这样一个社区，在它十七年的历史中，不仅用户和流量持续增长，而且总体上保持了丰富有趣的话题和标杆性的讨论质量。这就是「黑客新闻」——Hacker News。&lt;/p&gt;
    &lt;head rend="h2"&gt;文本墙里砌出的罕见人气&lt;/head&gt;
    &lt;p&gt;第一眼望去，HN 并不是一个吸引人的网站：界面素面朝天，除了字还是字，连功能按钮都主要是文本链接。不仅如此，初来乍到的人可能都不知道这里到底是怎么发帖的。与常见的在线社区不同，HN 上绝大多数「帖子」都只是一个链接分享，「楼主」的创作（如果有）只是起一个标题、加两句点评而已，而回复也是针对分享内容的讨论。&lt;/p&gt;
    &lt;p&gt;换句话说，HN 与其说是一个论坛，不如说是一个集体筛选的推荐列表，一个互联网的外置评论区。这种形态的学名是「链接聚合站」（link aggregator），除了 HN，早年比较有名的例子还包括 DIGG 和 Reddit。但 DIGG 早已作古，Reddit 也逐渐转型为更「主流」的论坛模式，HN 也就越发显得独树一帜了。&lt;/p&gt;
    &lt;p&gt;就是这样一个看起来平平无奇、用起来颇有门槛的网站，却坐拥超过千万的月访问量（SimilarWeb 数据），比知名的科技新闻网站 TechCrunch 和 Engadget 都高出很多。（与这种规模的流量形成对照的是，用于托管 HN 的服务器相当朴素，仅仅是两台四核的 Intel Xeon CPU E5-2637 v4 服务器，运行 FreeBSD 系统。）&lt;/p&gt;
    &lt;p&gt;要理解 HN 的高人气，就得先了解一些历史。从域名 &lt;code&gt;news.ycombinator.com&lt;/code&gt; 就能看出，HN 的起源并不是一个独立运营的网站，而是硅谷知名风投机构 Y Combinator 的附属项目。2007 年 2 月，时任 YC 总裁的 Paul Graham 创办了 HN。根据当时的公告，为公，他想为创业圈提供一个交流场所（这也是为什么 HN 最开始叫 Startup News），方便 YC 网罗人才；为私，他也想过一把编程瘾，用自己参与创作的 Lisp 语言变种 Arc 写一个网站。&lt;/p&gt;
    &lt;p&gt;在这样的背景衬托下，HN 逐渐成为了硅谷创业者和科技行业从业者的集散地。对于创业公司，HN 是一个推介产品、聆听反馈的优质渠道，也是在「危机公关」时需要格外小心对待的舆论场。对于独立开发者、创作者，自己的作品被「顶」上 HN 首页不仅是一种肯定，而且也能带来实打实的流量——这甚至产生了一个专有名词「HN 死亡拥抱」（HN hug-of-death），形容 HN 来客对小网站的性能考验。（我有一篇文章只是短暂蹭上了六十几名，结果几小时内 BackBlaze B2 图床就被拖完了当月额度。）&lt;/p&gt;
    &lt;p&gt;但 HN 上的讨论并不只和开公司和写代码的人有关。根据 Wilson Lin 基于四千多万条帖子和评论的分析，除了创业和编程之外，消费级产品、数理化等基础科学学科，以至社会、人文等「文科」内容，在 HN 上都有广泛讨论，也能经常见到相关背景的专业人士发言。不夸张地说，无论你处于什么领域、关心什么话题，都有很大概率在 HN 上找到你感兴趣的讨论。&lt;/p&gt;
    &lt;head rend="h2"&gt;纪律严明的首页与鞠躬尽瘁的管理员&lt;/head&gt;
    &lt;p&gt;用户规模有了、讨论的话题也足够丰富，但这还不足以成就一个好的社区。回忆历史，很多大型论坛就是在达到一定的规模后，遇到了严重的灌水和极端化问题，最后走向衰落。HN 是如何做到维持内容质量和讨论氛围的呢？&lt;/p&gt;
    &lt;p&gt;一套好的规则功不可没。在 HN 的欢迎页面上，写着这个社区的最重要的「约法两章」：第一，不要发垃圾链接，看到也不要点赞；第二，写评论不要粗鲁，也不要犯傻。&lt;/p&gt;
    &lt;p&gt;什么链接才不「垃圾」？答案是「有趣但不肤浅」：有助于增进对世界的了解，而不是八卦、表情包、引战文章、标题党新闻等喧闹的噪音——在 HN 的语汇中称为「无关话题」（off-topic）。什么样的评论才不「粗鲁」「犯傻」？它应当提供新的角度或者信息，「不要说你当面沟通时说不出口的话」。&lt;/p&gt;
    &lt;p&gt;如果你觉得这还是有些抽象，HN 还有一份更完整的发帖规范，对于内容、格式以至于表达方式提出了更具体的要求：不要用大写字母和感叹号来吸引眼球；尽量使用原始来源；不可以在回复观点时夹带人身攻击；在解读评论时推定他人为善意；等等。归根结底，这些原则和规则的目的都是保证 HN 上的内容能「让优秀的黑客感兴趣」，也就是「满足好奇心」。&lt;/p&gt;
    &lt;p&gt;当然，只有规则是不够的，还要有执行规则的手段。为此，HN 将程序规则和人工管理两种手段结合起来，其机制都颇值得研究。&lt;/p&gt;
    &lt;p&gt;首先，在决定着第一观感的帖子排序上，HN 不是简单地根据时间远近、互动多少，而是设置了非常严格的门槛。帖子在刚发出时只会出现在「新帖」版块，具有 1 分的初始分。只有在获得 4 次「支持」（通过点击帖子标题左侧的向上箭头），也就是积累 5 分后，才有资格进入首页排序。对于达到分数门槛的帖子，HN 按照获得分数和提交距今时间的比值来排序，只有排在前 30 名的帖子才能登上真正意义上的「首页」——直接访问 HN 网址所能看到的列表。剩下的帖子就只能排到后续页面了。&lt;/p&gt;
    &lt;p&gt;（作为例外，管理员有「特权」给低人气的帖子「第二次机会」：如果管理员觉得某个帖子似乎被「埋没」了，可以手动把它放回首页的底部，但不会更高，从而在不过度干预规则的情况下让更多人有机会看到。）&lt;/p&gt;
    &lt;p&gt;但众所周知，票数是可以刷的。因此，HN 一直将反刷票检测作为优先事项，持续开发改进。出于可以理解的原因，反刷票的具体机制没有公布过，但不难推断其考虑因素可能包括跳转来源、注册时间、操作频率等。&lt;/p&gt;
    &lt;p&gt;获得支持票除了可以让帖子排名靠前，也可以为发帖用户积累「业力」（karma）。这借用自一个佛教术语，在 HN 中大致类似于其他社区中的用户积分。不过，积分在 HN 中的作用不是提升花里胡哨的用户等级，而是参与社区治理的资历凭证：达到 31 分的用户可以标记（flag）自己认为不符合社区规则的帖子和评论，被多人标记的内容会被打上（flagged）的警告标记、直至隐藏；而只有达到 501 分的用户才能对他人评论投反对票（downvote）。（一个彩蛋功能是达到 251 分的用户可以自定义导航栏主题色。）&lt;/p&gt;
    &lt;p&gt;应当说，由于这些门槛，融入 HN 的难度高到会将很多人拒之门外的程度。不难想见，愿意主动逛新帖版块的本来就是重度用户，眼光往往挑剔；一个帖子想吸引到四个这类用户的支持，从而获得首页展示资格，实非易事。的确，据统计，HN 上的帖子大多数都只能得到 0 或 1 票。因此，相当比例的用户注册多年都没有发出过一次达到「逃逸速度」的帖子，也攒不到解锁 flag 功能的 karma 分数。但可能正是因为宁可牺牲互动量也要坚持高标准，HN 才能在十几年来维持独特的水平和风格。&lt;/p&gt;
    &lt;p&gt;但上面那些程序规则也不能算是 HN 维持高质量最独特的「法宝」；这个荣誉还得归于 HN 运营机制中「人治」的部分，特别是常任版主（moderator）的 dang。&lt;/p&gt;
    &lt;p&gt;《纽约客》杂志曾在 2019 年对 dang 做过特写报道。他本名 Daniel Gackle，缩写一下就是 dang。这位斯坦福文学专业毕业生成为 HN 的版主纯属意外。他曾经与另一位前任版主 scott（Scott Bell）共同创业，开发在线电子表格产品，并获得过 YC 的投资。遗憾的是，dang 的创业最终未获成功，于是接受 Paul Graham 的邀请加入 YC，全职管理 HN。&lt;/p&gt;
    &lt;p&gt;用《纽约客》文章的话说，dang 的管理是「个人色彩浓厚、专注、慢节奏」的；他将自己的工作视作一种「对话」。你可以翻几页 dang 的回复记录来了解他的工作内容：合并重复主题、汇总过往类似讨论、修正帖子标题措辞和来源链接、提醒「上头」用户遵守社区规则。这些任务单独看起来可能也不复杂，但要保持像 dang 一样的高频、准确，又始终温和、耐心——包括私下和用户发送长篇邮件解释操作理由——就很难得了。&lt;/p&gt;
    &lt;p&gt;正因如此，dang 受到了用户的一致尊重，以至于每到「逢年过节」都会有人自发点名感谢他的贡献（不妨试试在 HN 站内搜索 thank you dang）。诚然，HN 用户的评论也或许带有一些玫瑰色眼镜，但说很难在当今互联网上见到另一位受到如此爱戴的版主，大概不是夸张。&lt;/p&gt;
    &lt;p&gt;（2025 年初，dang 宣布 Tom Howard (tomhow) 加入正式管理员队伍。此前多年，他一直在幕后执行版主职责。据 dang 介绍，Howard 曾是 Y Combinator 的 2009 年冬令营校友，于 2007 年加入 HN。）&lt;/p&gt;
    &lt;head rend="h2"&gt;兼听则明&lt;/head&gt;
    &lt;p&gt;当然，HN 也不是完美无缺的。再优质的在线社区毕竟也是一个……在线社区；人们容易在线上沟通时犯的错误——急于结论、言辞偏激、过于自信——同样见于 HN 上的沟通中。同时，用户特征和文化使然，HN 还有一些「特色问题」，值得在浏览时留心鉴别。&lt;/p&gt;
    &lt;p&gt;例如，一个特别常见的现象是根本不看楼主分享的链接，只根据标题唤起的第一印象置评，导致聊起一些南辕北辙的话题，或者重提原文中已经明确回答的问题。以 RTFA（妈的去看文章，read the fucking article）为关键词搜索评论，就能看到成百上千条对于这种做法的抱怨。对此，最好自己养成良好的习惯，先看原文（赶时间的话哪怕看看 AI 总结）再看评论，就能有效避免被「张口就来」的评论带偏。&lt;/p&gt;
    &lt;p&gt;另一个「HN 特色」是为批评而批评。究其原因，虽然批判性思维在 HN 上受到推崇，并且在多数时候能起到火眼金睛的正面效果，但有些时候也会演变为「挑刺」。最常见的场景就是对于讲述科技成就、业务成功的帖子「泼冷水」，以及对 Show HN 版块中毛遂自荐的产品提出一些不符合项目发展阶段的苛责。（以 so much negative 为关键词搜索评论可以看到很多案例。）&lt;/p&gt;
    &lt;p&gt;一些常驻版面的「低效话题」也在拉低 HN 的整体氛围。之所以说「低效」，是因为这些问题虽然总能引发「热议」，但内容往往在争强好胜地表达个人偏好甚至偏见，或者陷入次要技术细节的迂腐争论，因此很难从中得到收获。不难想象，这些低效话题自然会包括技术圈一些历久经年的「圣战」——争论编程语言、操作系统、编辑器哪家强；近年新增的一些「时事热点」还包括对各种新兴「邪教」——Rust、HTMLX、nix、Wayland——的讨伐，以及重返办公室、裁员、技术移民等攸关科技从业者的社会政策问题的争论等等。如果遇到这类话题，查阅维基百科、技术文档和更专业权威的媒体可能是更好的选择。&lt;/p&gt;
    &lt;p&gt;最后，从用户画像的角度看，HN 的主力用户群体是美国的科技行业从业者，虽然整体素质和技能水平较高，但也因此容易滑向精英主义和过度的理性主义、智识主义，并在一定程度上构成观点的「回音壁」。因此，看似针锋相对的评论「盖楼」可能也只能得出局部最优的结论，形式上有条有理、数据驱动的论述可能掩盖着方法论层面的简化和偏见。正如《纽约客》那篇报道所总结，HN 有一种「掉书袋」（performative erudition）的基调，而它往往掩饰着一种深层的鲁莽。&lt;/p&gt;
    &lt;p&gt;总之，将 HN 定位为「互联网的外置评论区」有一层隐含意思：它不能代表和涵盖整个互联网，更不能代替和免去自己的思考和探索。HN 上的讨论虽好，充其量可以作为发现新问题的地图、解锁新视角的窗户，但完整的景观，毕竟还在远方和窗外。&lt;/p&gt;
    &lt;head rend="h2"&gt;附：HN 阅读方法谈&lt;/head&gt;
    &lt;p&gt;我大致在 2018 年初开始阅读 HN。由于没有理工和编程背景，HN 上的很多讨论超出了我的知识范围，但这并不影响翻阅 HN 的乐趣。事实上，我就是通过 HN 对很多技术话题建立初步认识和兴趣的；每当遇到众口纷纭的热点时，我也会习惯性地去 HN 寻找专业解读和正反交锋，几乎从未空手而归。&lt;/p&gt;
    &lt;p&gt;但面对繁多的条目和密集的讨论，「读」好 HN 也需要一些技巧。根据我的使用体会，HN 其实是不太适合直接去「刷」首页的，而最好通过 RSS、搜索和第三方工具实现有规律、有目的地浏览。&lt;/p&gt;
    &lt;p&gt;刚夸了这么久 HN 的首页质量，现在又不建议看首页，似乎有些矛盾。的确，通过上面介绍的各种管理机制，HN 的首页可以说是非常「好看」的。但太好看也会成为一种问题：如果不加控制，很容易将其作为消磨时间的下意识目的地，陷入无尽的链接点击循环。（HN 因此也是很多「集中注意力」类工具推荐用户主动屏蔽的网站之一。）&lt;/p&gt;
    &lt;p&gt;相比之下，我更推荐以下几种工具和方法，供读者参考和批评——&lt;/p&gt;
    &lt;head rend="h3"&gt;订阅筛选版 RSS&lt;/head&gt;
    &lt;p&gt;HN 有一个官方的 RSS 地址（https://news.ycombinator.com/rss），与首页内容完全一致，直接订阅信息量太大。好在 HN 足够开放，提供了非常完善的官方 API，这就为第三方制作更加细化的 RSS 源提供了可能。&lt;/p&gt;
    &lt;p&gt;例如，一个比较受欢迎的选择是 hnrss.org，它提供了按照版块、用户、关键词、评分数等条件筛选的一系列 RSS 地址。其中，最实用的大概要数「最佳评论」。这个源汇总了 HN 全站主题中新出现的高票评论，不仅本身值得一读，而且会引出精彩评论的帖子本身往往也是值得一读、有一定人气的，我经常从中发现一些日常关注范围之外的优质讨论。它的更新频率也比较适中，一般每天更新十几条，对应四五篇文章，数量适中，大多数人一天读到这个数量也就差不多了。&lt;/p&gt;
    &lt;head rend="h3"&gt;主动搜索外部网址&lt;/head&gt;
    &lt;p&gt;前面提到过，HN 特殊的发帖方式使它成为了「互联网的外置评论区」。再加上人气旺盛，英文互联网上但凡稍有些访问量的网站和页面，都有很大可能在 HN 上有所讨论。&lt;/p&gt;
    &lt;p&gt;对我来说，HN 搜索就是技术领域的重要咨询意见来源：每当看到一个风头正旺、宣传遍地的产品，我一般都会在 HN 上搜索它的名称、官网域名或者 GitHub 仓库地址，看看到底是真的不容错过，还是需要「避雷」。类似地，每当看到一篇言之凿凿的热门文章，我也会搜搜 HN 上有没有「唱反调」的声音，从而获得更全面的角度。&lt;/p&gt;
    &lt;p&gt;不过，HN 的搜索框位于首页底部的不起眼位置，用起来比较麻烦。我的建议是将 &lt;code&gt;https://hn.algolia.com/?q=%s&lt;/code&gt;（其中 &lt;code&gt;%s&lt;/code&gt; 为关键词）设置为搜索引擎或各类 launcher 工具中的搜索快捷方式来直达搜索。你也可以装一个浏览器插件 Newsit，它会自动搜索每一个访问的网页是否有相关 HN 讨论，并以横幅形式显示在网页的右下角。&lt;/p&gt;
    &lt;p&gt;顺带一提，这可能是你见过最好用的站内搜索引擎。从它的域名就可以看出来这是个「外挂」，是由知名的搜索 SaaS 提供商、也是 YC 往届校友项目的 Algolia 支持和托管，不仅速度快到冒烟，而且支持模糊匹配，可以搜出各种犄角旮旯。（更多高级语法见帮助页。）&lt;/p&gt;
    &lt;head rend="h3"&gt;跳读评论&lt;/head&gt;
    &lt;p&gt;HN 上的热门帖子往往能引来几百以至上千条评论，逐一看完显然不现实也没有必要。此外，由于用户互动有「凑热闹」的自然倾向，位于评论区顶部的热门评论往往能吸引更多的评论，从而占据越来越多的顶部空间。如果只是从头往下看，很可能因此忽视位于后面的不同视角声音。&lt;/p&gt;
    &lt;p&gt;因此，我给自己定的「规矩」是：对于第一条评论，最多看前三条回复，及其各自的三条下级回复；然后就跳到第二条评论，最多看前两条回复，及其各自的两条下级回复；最后跳到第三条评论看第一条回复，及其第一条下级回复。（注意善用每层楼的导航按钮 root（跳到所属的最上层回复）、parent（跳到所属的上一层回复）和 prev/next（跳到同层的相邻上/下一条回复）。）这样，一般能比较全面地了解评论区的综合观点，同时使得阅读时间可控。&lt;/p&gt;
    &lt;head rend="h3"&gt;AI 总结评论&lt;/head&gt;
    &lt;p&gt;当然，随着 AI 工具普及，也可以考虑用 AI 工具总结 HN 评论。不过，对于那种成百上千条评论的热门话题，HN 会自动分页显示，此时只总结第一页就不完整了。为此，可以从 HN API 获取 JSON 格式的完整评论数据，端点为：&lt;/p&gt;
    &lt;code&gt;https://hn.algolia.com/api/v1/items/${id}
&lt;/code&gt;
    &lt;p&gt;其中 &lt;code&gt;id&lt;/code&gt; 为链接中的八位数字。然后将响应内容作为提示词，和如下内容一起发送给惯用的模型即可：&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Summarize the themes of the opinions in the input provided by the user. For each theme, include at least 3 UNMODIFIED quotes with attribution. Unescape HTML entities. Go long.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;这段话可以直接放在开头，也可以作为系统提示词。提示词的写法受到了 Simon Willison 的启发，根据个人经验调整，可以比较稳定地总结评论主题、立场，并附带原始引用和用户名，方便回溯到原评论。因为只是总结类任务，GPT-4o mini、Gemini Flash 和 Claude Haiku 这样的便宜模型就能很好胜任，但注意上下文窗口越长越好，以免超出长度限制。&lt;/p&gt;
    &lt;p&gt;我用 Val Town 做了一个演示版，使用的是该服务免费提供的 GPT-4o mini 模型代理，你可以试试效果，然后 fork 一份到自己账户以便按需修改和避免限流。&lt;/p&gt;
    &lt;p&gt;A version of this article appears on Dec. 30, 2024 on SSPAI.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hsu.cy/2025/09/how-to-read-hn/"/><published>2025-09-22T09:37:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45331213</id><title>M4.6 Earthquake – 2 km ESE of Berkeley, CA</title><updated>2025-09-22T15:11:44.178600+00:00</updated><content>&lt;doc fingerprint="5f4bcaf04e5289af"&gt;
  &lt;main&gt;
    &lt;p&gt;The Earthquake Event Page application supports most recent browsers, view supported browsers. Or, try our Real-time Notifications, Feeds, and Web Services.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://earthquake.usgs.gov/earthquakes/eventpage/ew1758534970/executive"/><published>2025-09-22T10:00:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45331370</id><title>Kmart's use of facial recognition to tackle refund fraud unlawful</title><updated>2025-09-22T15:11:43.034781+00:00</updated><content>&lt;doc fingerprint="b193914ea3572705"&gt;
  &lt;main&gt;
    &lt;p&gt;Privacy Commissioner Carly Kind has found that Kmart Australia Limited (Kmart) breached Australians’ privacy by collecting their personal and sensitive information through a facial recognition technology (FRT) system designed to tackle refund fraud.&lt;/p&gt;
    &lt;p&gt;Between June 2020 and July 2022, Kmart deployed FRT to capture the faces of every person who entered 28 of its retail stores, and all individuals who presented at a returns counter, in an attempt to identify people committing refund fraud.&lt;/p&gt;
    &lt;p&gt;In a determination published today, the Privacy Commissioner found that Kmart did not notify shoppers or seek their consent to use FRT to collect their biometric information, which is sensitive personal information and enjoys higher protections under the Privacy Act.&lt;/p&gt;
    &lt;p&gt;The retailer argued that it was not required to obtain consent because of an exemption in the Privacy Act that applies when organisations reasonably believe that they need to collect personal information to tackle unlawful activity or serious misconduct. The Privacy Commissioner’s determination focused on assessing whether Kmart met the conditions for relying on the exemption, and concluded:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The sensitive biometric information of every individual who entered a store was indiscriminately collected by the FRT system.&lt;/item&gt;
      &lt;item&gt;There were other less privacy intrusive methods available to Kmart to address refund fraud.&lt;/item&gt;
      &lt;item&gt;Deploying the FRT system to prevent fraud was of limited utility.&lt;/item&gt;
      &lt;item&gt;Considering that the FRT system impacted on the privacy of many thousands of individuals not suspected of refund fraud, the collection of biometric information on Kmart customers was a disproportionate interference with privacy.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;“Understanding how FRT accords with the protections contained in Privacy Act requires me to balance the interests of individuals in having their privacy protected, on the one hand, and the interests of entities in carrying out their functions or activities, on the other. Relevant to a technology like facial recognition, is also the public interest in protecting privacy,” the Privacy Commissioner said.&lt;/p&gt;
    &lt;p&gt;Relevant factors considered by the Commissioner included the estimated value of fraudulent returns against the respondent’s total operations and profits, the limited effectiveness of the FRT system, and the extent of the privacy impacts in collecting the sensitive information of every individual who entered the relevant stores.&lt;/p&gt;
    &lt;p&gt;“I do not consider that the respondent (Kmart) could have reasonably believed that the benefits of the FRT system in addressing refund fraud proportionately outweighed the impact on individuals’ privacy,” the Commissioner stated.&lt;/p&gt;
    &lt;p&gt;The determination is the second issued by the Office of the Australian Information Commissioner (OAIC) on the use of FRT in retail settings. In October 2024, the Privacy Commissioner found that Bunnings Group Limited had contravened Australians’ privacy through their use of FRT in 62 of its retail stores across Australia. That decision is currently under review by the Administrative Review Tribunal.&lt;/p&gt;
    &lt;p&gt;“These two decisions do not impose a ban on the use of FRT. The human rights to safety and privacy are not mutually exclusive; rather, both must be preserved, upheld and promoted. Customer and staff safety, and fraud prevention and detection, are legitimate reasons businesses might have regard to when considering the deployment of new technologies. However, these reasons are not, in and of themselves, a free pass to avoid compliance with the Privacy Act,” she stated.&lt;/p&gt;
    &lt;p&gt;The Commissioner’s determination is instructive for entities that are considering new technologies such as FRT. Privacy considerations should be a key feature. The OAIC has also published guidance on its website: Facial recognition technology: a guide to assessing the privacy risks&lt;/p&gt;
    &lt;p&gt;Kmart has been under investigation by the OAIC since July 2022, at which time it ceased operating the FRT system. It has cooperated with the OAIC throughout the investigation.&lt;/p&gt;
    &lt;p&gt;Although the Privacy Commissioner reached a similar conclusion in the Kmart and Bunnings decisions, the cases differ considerably and focus on different uses of FRT.&lt;/p&gt;
    &lt;p&gt;The Privacy Act is technology-neutral and does not proscribe the use of any particular technology. When considering the roll-out and use of new technologies such as FRT, the OAIC’s guidance encourages entities to consider factors such as proportionality, transparency, the risk of bias and discrimination, and governance for the collection, use and retention of sensitive personal information.&lt;/p&gt;
    &lt;p&gt;Commissioner Kind has published a blog post with further takeaways for other retailers considering using FRT.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.oaic.gov.au/news/media-centre/18-kmarts-use-of-facial-recognition-to-tackle-refund-fraud-unlawful,-privacy-commissioner-finds"/><published>2025-09-22T10:20:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45332130</id><title>Easy Forth</title><updated>2025-09-22T15:11:42.870635+00:00</updated><content>&lt;doc fingerprint="c06d8804518f250"&gt;
  &lt;main&gt;&lt;p&gt;by Nick Morgan&lt;/p&gt;&lt;p&gt;This small ebook is here to teach you a programming language called Forth. Forth is a language unlike most others. It’s not functional or object oriented, it doesn’t have type-checking, and it basically has zero syntax. It was written in the 70s, but is still used today for certain applications.&lt;/p&gt;&lt;p&gt;Why would you want to learn such an odd language? Every new programming language you learn helps you think about problems in new ways. Forth is very easy to learn, but it requires you to think in a different way than you’re used to. That makes it a perfect language to broaden your coding horizons.&lt;/p&gt;&lt;p&gt;This book includes a simple implementation of Forth I wrote in JavaScript. It’s by no means perfect, and is missing a lot of the functionality you’d expect in a real Forth system. It’s just here to give you an easy way to try out the examples. (If you’re a Forth expert, please contribute here and make it better!)&lt;/p&gt;&lt;p&gt;I’m going to assume that you know at least one other programming language, and have a basic idea of how stacks work as a data structure.&lt;/p&gt;&lt;p&gt;The thing that separates Forth from most other languages is its use of the stack. In Forth, everything revolves around the stack. Any time you type a number, it gets pushed onto the stack. If you want to add two numbers together, typing &lt;code&gt;+&lt;/code&gt; takes the top two numbers off the stack, adds them, and puts
the result back on the stack.&lt;/p&gt;&lt;p&gt;Let’s take a look at an example. Type (don’t copy-paste) the following into the interpreter, typing &lt;code&gt;Enter&lt;/code&gt; after each line.&lt;/p&gt;&lt;code&gt;1
2
3
&lt;/code&gt;&lt;p&gt;Every time you type a line followed by the &lt;code&gt;Enter&lt;/code&gt; key, the Forth interpreter
executes that line, and appends the string &lt;code&gt;ok&lt;/code&gt; to let you know there were no
errors. You should also notice that as you execute each line, the area at the
top fills up with numbers. That area is our visualization of the stack. It
should look like this:&lt;/p&gt;&lt;p&gt;Now, into the same interpreter, type a single &lt;code&gt;+&lt;/code&gt; followed by the &lt;code&gt;Enter&lt;/code&gt; key. The top two
elements on the stack, &lt;code&gt;2&lt;/code&gt; and &lt;code&gt;3&lt;/code&gt;, have been replaced by &lt;code&gt;5&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;At this point, your editor window should look like this:&lt;/p&gt;&lt;p&gt;Type &lt;code&gt;+&lt;/code&gt; again and press &lt;code&gt;Enter&lt;/code&gt;, and the top two elements will be replaced by 6. If
you type &lt;code&gt;+&lt;/code&gt; one more time, Forth will try to pop the top two elements off the
stack, even though there’s only one element on the stack! This results in a
&lt;code&gt;Stack underflow&lt;/code&gt; error:&lt;/p&gt;&lt;p&gt;Forth doesn’t force you to type every token as a separate line. Type the following into the next editor, followed by the &lt;code&gt;Enter&lt;/code&gt; key:&lt;/p&gt;&lt;code&gt;123 456 +
&lt;/code&gt;&lt;p&gt;The stack should now look like this:&lt;/p&gt;&lt;p&gt;This style, where the operator appears after the operands, is known as Reverse-Polish notation. Let’s try something a bit more complicated, and calculate &lt;code&gt;10 * (5 + 2)&lt;/code&gt;. Type the
following into the interpreter:&lt;/p&gt;&lt;code&gt;5 2 + 10 *
&lt;/code&gt;&lt;p&gt;One of the nice things about Forth is that the order of operations is completely based on their order in the program. For example, when executing &lt;code&gt;5
2 + 10 *&lt;/code&gt;, the interpreter pushes 5 to the stack, then 2, then adds them and
pushes the resulting 7, then pushes 10 to the stack, then multiplies 7 and 10.
Because of this, there’s no need for parentheses to group operators with lower
precedence.&lt;/p&gt;&lt;p&gt;Most Forth words affect the stack in some way. Some take values off the stack, some leave new values on the stack, and some do a mixture of both. These “stack effects” are commonly represented using comments of the form &lt;code&gt;( before -- after
)&lt;/code&gt;. For example, &lt;code&gt;+&lt;/code&gt; is &lt;code&gt;( n1 n2 -- sum )&lt;/code&gt; - &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt; are the top two numbers
on the stack, and &lt;code&gt;sum&lt;/code&gt; is the value left on the stack.&lt;/p&gt;&lt;p&gt;The syntax of Forth is extremely straightforward. Forth code is interpreted as a series of space-delimited words. Almost all non-whitespace characters are valid in words. When the Forth interpreter reads a word, it checks to see if a definition exists in an internal structure known as the Dictionary. If it is found, that definition is executed. Otherwise, the word is assumed to be a number, and it is pushed onto the stack. If the word cannot be converted to a number, an error occurs.&lt;/p&gt;&lt;p&gt;You can try that out yourself below. Type &lt;code&gt;foo&lt;/code&gt; (an unrecognized word)
and press enter.&lt;/p&gt;&lt;p&gt;You should see something like this:&lt;/p&gt;&lt;p&gt;&lt;code&gt;foo ?&lt;/code&gt; means that Forth was unable to find a definition for &lt;code&gt;foo&lt;/code&gt;, and it
wasn’t a valid number.&lt;/p&gt;&lt;p&gt;We can create our own definition of &lt;code&gt;foo&lt;/code&gt; using two special words called &lt;code&gt;:&lt;/code&gt;
(colon) and &lt;code&gt;;&lt;/code&gt; (semicolon).  &lt;code&gt;:&lt;/code&gt; is our way of telling Forth we want to create
a definition. The first word after the &lt;code&gt;:&lt;/code&gt; becomes the definition name, and the
rest of the words (until the &lt;code&gt;;&lt;/code&gt;) make up the body of the definition. It’s
conventional to include two spaces between the name and the body of the
definition. Try entering the following:&lt;/p&gt;&lt;code&gt;: foo  100 + ;
1000 foo
foo foo foo
&lt;/code&gt;&lt;p&gt;Warning: A common mistake is to miss out the space before the &lt;code&gt;;&lt;/code&gt; word. Because Forth
words are space delimited and can contain most characters, &lt;code&gt;+;&lt;/code&gt; is a perfectly
valid word and is not parsed as two separate words.&lt;/p&gt;&lt;p&gt;As you’ve hopefully figured out, our &lt;code&gt;foo&lt;/code&gt; word simply adds 100 to the value on
top of the stack. It’s not very interesting, but it should give you an idea of
how simple definitions work.&lt;/p&gt;&lt;p&gt;Now we can start taking a look at some of Forth’s predefined words. First, let’s look at some words for manipulating the elements at the top of the stack.&lt;/p&gt;&lt;code&gt;dup ( n -- n n )&lt;/code&gt;&lt;p&gt;&lt;code&gt;dup&lt;/code&gt; is short for “duplicate” – it duplicates the top element of the stack. For example,
try this out:&lt;/p&gt;&lt;code&gt;1 2 3 dup
&lt;/code&gt;&lt;p&gt;You should end up with the following stack:&lt;/p&gt;&lt;code&gt;drop ( n -- )&lt;/code&gt;&lt;p&gt;&lt;code&gt;drop&lt;/code&gt; simply drops the top element of the stack. Running:&lt;/p&gt;&lt;code&gt;1 2 3 drop
&lt;/code&gt;&lt;p&gt;gives you a stack of:&lt;/p&gt;&lt;code&gt;swap ( n1 n2 -- n2 n1 )&lt;/code&gt;&lt;p&gt;&lt;code&gt;swap&lt;/code&gt;, as you may have guessed, swaps the top two elements of the stack. For example:&lt;/p&gt;&lt;code&gt;1 2 3 4 swap
&lt;/code&gt;&lt;p&gt;will give you:&lt;/p&gt;&lt;code&gt;over ( n1 n2 -- n1 n2 n1 )&lt;/code&gt;&lt;p&gt;&lt;code&gt;over&lt;/code&gt; is a bit less obvious: it takes the second element from the top of the
stack and duplicates it to the top of the stack. Running this:&lt;/p&gt;&lt;code&gt;1 2 3 over
&lt;/code&gt;&lt;p&gt;will result in this:&lt;/p&gt;&lt;code&gt;rot ( n1 n2 n3 -- n2 n3 n1 )&lt;/code&gt;&lt;p&gt;Finally, &lt;code&gt;rot&lt;/code&gt; “rotates” the top three elements of the stack. The third
element from the top of the stack gets moved to the top of the stack, pushing
the other two elements down.&lt;/p&gt;&lt;code&gt;1 2 3 rot
&lt;/code&gt;&lt;p&gt;gives you:&lt;/p&gt;&lt;p&gt;Next, let’s look at some words for outputting text to the console.&lt;/p&gt;&lt;code&gt;. ( n -- )&lt;/code&gt; (period)&lt;p&gt;The simplest output word in Forth is &lt;code&gt;.&lt;/code&gt;. You can use &lt;code&gt;.&lt;/code&gt; to output the top of
the stack in the output of the current line. For example, try running this
(make sure to include all the spaces!):&lt;/p&gt;&lt;code&gt;1 . 2 . 3 . 4 5 6 . . .
&lt;/code&gt;&lt;p&gt;You should see this:&lt;/p&gt;&lt;p&gt;Going through this in order, we push &lt;code&gt;1&lt;/code&gt;, then pop it off and output it. Then
we do the same with &lt;code&gt;2&lt;/code&gt; and &lt;code&gt;3&lt;/code&gt;. Next we push &lt;code&gt;4&lt;/code&gt;, &lt;code&gt;5&lt;/code&gt;, and &lt;code&gt;6&lt;/code&gt; onto the stack.
We then pop them off and output them one-by-one. That’s why the last three
numbers in the output are reversed: the stack is last in, first out.&lt;/p&gt;&lt;code&gt;emit ( c -- )&lt;/code&gt;&lt;p&gt;&lt;code&gt;emit&lt;/code&gt; can be used to output numbers as ascii characters. Just like &lt;code&gt;.&lt;/code&gt; outputs
the number at the top of the stack, &lt;code&gt;emit&lt;/code&gt; outputs that number as an ascii
character. For example:&lt;/p&gt;&lt;code&gt; 33 119 111 87 emit emit emit emit
&lt;/code&gt;&lt;p&gt;I won’t give the output here so as to not ruin the surprise. This could also be written as:&lt;/p&gt;&lt;code&gt;87 emit 111 emit 119 emit 33 emit
&lt;/code&gt;&lt;p&gt;Unlike &lt;code&gt;.&lt;/code&gt;, &lt;code&gt;emit&lt;/code&gt; doesn’t output any space after each character, enabling you
to build up arbitrary strings of output.&lt;/p&gt;&lt;code&gt;cr ( -- )&lt;/code&gt;&lt;p&gt;&lt;code&gt;cr&lt;/code&gt; is short for carriage return – it simply outputs a newline:&lt;/p&gt;&lt;code&gt;cr 100 . cr 200 . cr 300 .
&lt;/code&gt;&lt;p&gt;This will output:&lt;/p&gt;&lt;code&gt;." ( -- )&lt;/code&gt;&lt;p&gt;Finally we have &lt;code&gt;."&lt;/code&gt; – a special word for outputting strings. The &lt;code&gt;."&lt;/code&gt; word works
differently inside definitions to interactive mode. &lt;code&gt;."&lt;/code&gt; marks the beginning of
a string to output, and the end of the string is marked by &lt;code&gt;"&lt;/code&gt;. The closing &lt;code&gt;"&lt;/code&gt;
isn’t a word, and so doesn’t need to be space-delimited. Here’s an example:&lt;/p&gt;&lt;code&gt;: say-hello  ." Hello there!" ;
say-hello
&lt;/code&gt;&lt;p&gt;You should see the following output&lt;/p&gt;&lt;p&gt;We can combine &lt;code&gt;."&lt;/code&gt;, &lt;code&gt;.&lt;/code&gt;, &lt;code&gt;cr&lt;/code&gt;, and &lt;code&gt;emit&lt;/code&gt; to build up more complex output:&lt;/p&gt;&lt;code&gt;: print-stack-top  cr dup ." The top of the stack is " .
  cr ." which looks like '" dup emit ." ' in ascii  " ;
48 print-stack-top
&lt;/code&gt;&lt;p&gt;Running this should give you the following output:&lt;/p&gt;&lt;p&gt;Now onto the fun stuff! Forth, like most other languages, has conditionals and loops for controlling the flow of your program. To understand how they work, however, first we need to understand booleans in Forth.&lt;/p&gt;&lt;p&gt;There’s actually no boolean type in Forth. The number &lt;code&gt;0&lt;/code&gt; is treated as false,
and any other number is true, although the canonical true value is &lt;code&gt;-1&lt;/code&gt; (all
boolean operators return &lt;code&gt;0&lt;/code&gt; or &lt;code&gt;-1&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;To test if two numbers are equal, you can use &lt;code&gt;=&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;3 4 = .
5 5 = .
&lt;/code&gt;&lt;p&gt;This should output:&lt;/p&gt;&lt;p&gt;You can use &lt;code&gt;&amp;lt;&lt;/code&gt; and &lt;code&gt;&amp;gt;&lt;/code&gt; for less than and greater than. &lt;code&gt;&amp;lt;&lt;/code&gt; checks to see if the
second item from the top of the stack is less than the top item of the stack, and
vice versa for &lt;code&gt;&amp;gt;&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;3 4 &amp;lt; .
3 4 &amp;gt; .
&lt;/code&gt;&lt;p&gt;The boolean operators And, Or, and Not are available as &lt;code&gt;and&lt;/code&gt;, &lt;code&gt;or&lt;/code&gt;, and &lt;code&gt;invert&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;3 4 &amp;lt; 20 30 &amp;lt; and .
3 4 &amp;lt; 20 30 &amp;gt; or .
3 4 &amp;lt; invert .
&lt;/code&gt;&lt;p&gt;The first line is the equivalent of &lt;code&gt;3 &amp;lt; 4 &amp;amp; 20 &amp;lt; 30&lt;/code&gt; in a C-based language.
The second line is the equivalent of &lt;code&gt;3 &amp;lt; 4 | 20 &amp;gt; 30&lt;/code&gt;. The third line is the
equivalent of &lt;code&gt;!(3 &amp;lt; 4)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;code&gt;and&lt;/code&gt;, &lt;code&gt;or&lt;/code&gt;, and &lt;code&gt;invert&lt;/code&gt; are all bitwise operations. For well-formed flags
(&lt;code&gt;0&lt;/code&gt; and &lt;code&gt;-1&lt;/code&gt;) they’ll work as expected, but they’ll give incorrect results for
arbitrary numbers.&lt;/p&gt;&lt;code&gt;if then&lt;/code&gt;&lt;p&gt;Now we can finally get onto conditionals. Conditionals in Forth can only be used inside definitions. The simplest conditional statement in Forth is &lt;code&gt;if
then&lt;/code&gt;, which is equivalent to a standard &lt;code&gt;if&lt;/code&gt; statement in most languages.
Here’s an example of a definition using &lt;code&gt;if then&lt;/code&gt;. In this example, we’re also
using the &lt;code&gt;mod&lt;/code&gt; word, which returns the modulo of the top two numbers on the
stack. In this case, the top number is 5, and the other is whatever was placed
on the stack before calling &lt;code&gt;buzz?&lt;/code&gt;. Therefore, &lt;code&gt;5 mod 0 =&lt;/code&gt; is a boolean
expression that checks to see if the top of the stack is divisible by 5.&lt;/p&gt;&lt;code&gt;: buzz?  5 mod 0 = if ." Buzz" then ;
3 buzz?
4 buzz?
5 buzz?
&lt;/code&gt;&lt;p&gt;This will output:&lt;/p&gt;&lt;p&gt;It’s important to note that the &lt;code&gt;then&lt;/code&gt; word marks the end of the &lt;code&gt;if&lt;/code&gt; statement.
This makes it equivalent to &lt;code&gt;fi&lt;/code&gt; in Bash or &lt;code&gt;end&lt;/code&gt; in Ruby, for example.&lt;/p&gt;&lt;p&gt;Another important thing to realize is that &lt;code&gt;if&lt;/code&gt; consumes the top value on the
stack when it checks to see if it’s true or false.&lt;/p&gt;&lt;code&gt;if else then&lt;/code&gt;&lt;p&gt;&lt;code&gt;if else then&lt;/code&gt; is equivalent to an &lt;code&gt;if/else&lt;/code&gt; statement in most languages. Here’s
an example of its use:&lt;/p&gt;&lt;code&gt;: is-it-zero?  0 = if ." Yes!" else ." No!" then ;
0 is-it-zero?
1 is-it-zero?
2 is-it-zero?
&lt;/code&gt;&lt;p&gt;This outputs:&lt;/p&gt;&lt;p&gt;This time, the if clause (consequent) is everything between &lt;code&gt;if&lt;/code&gt; and &lt;code&gt;else&lt;/code&gt;,
and the else clause (alternative) is everything between &lt;code&gt;else&lt;/code&gt; and &lt;code&gt;then&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;do loop&lt;/code&gt;&lt;p&gt;&lt;code&gt;do loop&lt;/code&gt; in Forth most closely resembles a &lt;code&gt;for&lt;/code&gt; loop in most C-based languages.
In the body of a &lt;code&gt;do loop&lt;/code&gt;, the special word &lt;code&gt;i&lt;/code&gt; pushes the current loop index
onto the stack.&lt;/p&gt;&lt;p&gt;The top two values on the stack give the starting value (inclusive) and ending value (exclusive) for the &lt;code&gt;i&lt;/code&gt; value. The starting value is taken from the top
of the stack. Here’s an example:&lt;/p&gt;&lt;code&gt;: loop-test  10 0 do i . loop ;
loop-test
&lt;/code&gt;&lt;p&gt;This should output:&lt;/p&gt;&lt;p&gt;The expression &lt;code&gt;10 0 do i . loop&lt;/code&gt; is roughly equivalent to:&lt;/p&gt;&lt;code&gt;for (int i = 0; i &amp;lt; 10; i++) {
  print(i);
}
&lt;/code&gt;&lt;p&gt;We can write the classic Fizz Buzz program easily using a &lt;code&gt;do loop&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;: fizz?  3 mod 0 = dup if ." Fizz" then ;
: buzz?  5 mod 0 = dup if ." Buzz" then ;
: fizz-buzz?  dup fizz? swap buzz? or invert ;
: do-fizz-buzz  25 1 do cr i fizz-buzz? if i . then loop ;
do-fizz-buzz
&lt;/code&gt;&lt;p&gt;&lt;code&gt;fizz?&lt;/code&gt; checks to see if the top of the stack is divisible by 3 using &lt;code&gt;3 mod 0
=&lt;/code&gt;. It then uses &lt;code&gt;dup&lt;/code&gt; to duplicate this result. The top copy of the value is
consumed by &lt;code&gt;if&lt;/code&gt;.  The second copy is left on the stack and acts as the return
value of &lt;code&gt;fizz?&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;If the number on top of the stack is divisible by 3, the string &lt;code&gt;"Fizz"&lt;/code&gt; will
be output, otherwise there will be no output.&lt;/p&gt;&lt;p&gt;&lt;code&gt;buzz?&lt;/code&gt; does the same thing but with 5, and outputs the string &lt;code&gt;"Buzz"&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;code&gt;fizz-buzz?&lt;/code&gt; calls &lt;code&gt;dup&lt;/code&gt; to duplicate the value on top of the stack, then calls
&lt;code&gt;fizz?&lt;/code&gt;, converting the top copy into a boolean. After this, the top of the
stack consists of the original value, and the boolean returned by &lt;code&gt;fizz?&lt;/code&gt;.
&lt;code&gt;swap&lt;/code&gt; swaps these, so the original top-of-stack value is back on top, and the
boolean is underneath. Next we call &lt;code&gt;buzz?&lt;/code&gt;, which replaces the top-of-stack
value with a boolean flag. Now the top two values on the stack are booleans
representing whether the number was divisible by 3 or 5.  After this, we call
&lt;code&gt;or&lt;/code&gt; to see if either of these is true, and &lt;code&gt;invert&lt;/code&gt; to negate this value.
Logically, the body of &lt;code&gt;fizz-buzz?&lt;/code&gt; is equivalent to:&lt;/p&gt;&lt;code&gt;!(x % 3 == 0 || x % 5 == 0)
&lt;/code&gt;&lt;p&gt;Therefore, &lt;code&gt;fizz-buzz?&lt;/code&gt; returns a boolean indicating if the argument is not
divisible by 3 or 5, and thus should be printed.  Finally, &lt;code&gt;do-fizz-buzz&lt;/code&gt; loops
from 1 to 25, calling &lt;code&gt;fizz-buzz?&lt;/code&gt; on &lt;code&gt;i&lt;/code&gt;, and outputting &lt;code&gt;i&lt;/code&gt; if &lt;code&gt;fizz-buzz?&lt;/code&gt;
returns true.&lt;/p&gt;&lt;p&gt;If you’re having trouble figuring out what’s going on inside &lt;code&gt;fizz-buzz?&lt;/code&gt;, the
example below might help you to understand how it works. All we’re doing here
is executing each word of the definition of &lt;code&gt;fizz-buzz?&lt;/code&gt; on a separate line. As
you execute each line, watch the stack to see how it changes:&lt;/p&gt;&lt;code&gt;: fizz?  3 mod 0 = dup if ." Fizz" then ;
: buzz?  5 mod 0 = dup if ." Buzz" then ;
4
dup
fizz?
swap
buzz?
or
invert
&lt;/code&gt;&lt;p&gt;Here’s how each line affects the stack:&lt;/p&gt;&lt;code&gt;4         4 &amp;lt;- Top
dup       4 4 &amp;lt;- Top
fizz?     4 0 &amp;lt;- Top
swap      0 4 &amp;lt;- Top
buzz?     0 0 &amp;lt;- Top
or        0 &amp;lt;- Top
invert    -1 &amp;lt;- Top
&lt;/code&gt;&lt;p&gt;Remember, the final value on the stack is the return value of the &lt;code&gt;fizz-buzz?&lt;/code&gt;
word. In this case, it’s true, because the number was not divisible by 3 or 5,
and so should be printed.&lt;/p&gt;&lt;p&gt;Here’s the same thing but starting with 5:&lt;/p&gt;&lt;code&gt;5         5 &amp;lt;- Top
dup       5 5 &amp;lt;- Top
fizz?     5 0 &amp;lt;- Top
swap      0 5 &amp;lt;- Top
buzz?     0 -1 &amp;lt;- Top
or        -1 &amp;lt;- Top
invert    0 &amp;lt;- Top
&lt;/code&gt;&lt;p&gt;In this case the original top-of-stack value was divisible by 5, so nothing should be printed.&lt;/p&gt;&lt;p&gt;Forth also allows you to save values in variables and constants. Variables allow you to keep track of changing values without having to store them on the stack. Constants give you a simple way to refer to a value that won’t change.&lt;/p&gt;&lt;p&gt;Because the role of local variables is generally played by the stack, variables in Forth are used more to store state that may be needed across multiple words.&lt;/p&gt;&lt;p&gt;Defining variables is simple:&lt;/p&gt;&lt;code&gt;variable balance
&lt;/code&gt;&lt;p&gt;This basically associates a particular memory location with the name &lt;code&gt;balance&lt;/code&gt;.
&lt;code&gt;balance&lt;/code&gt; is now a word, and all it does is to push its memory location onto the
stack:&lt;/p&gt;&lt;code&gt;variable balance
balance
&lt;/code&gt;&lt;p&gt;You should see the value &lt;code&gt;1000&lt;/code&gt; on the stack. This Forth implementation arbitrarily
starts storing variables at the memory location &lt;code&gt;1000&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The word &lt;code&gt;!&lt;/code&gt; stores a value at the memory location referenced by a variable, and the
word &lt;code&gt;@&lt;/code&gt; fetches the value from a memory location:&lt;/p&gt;&lt;code&gt;variable balance
123 balance !
balance @
&lt;/code&gt;&lt;p&gt;This time you should see the value &lt;code&gt;123&lt;/code&gt; on the stack. &lt;code&gt;123 balance&lt;/code&gt; pushes the
value and the memory location onto the stack, and &lt;code&gt;!&lt;/code&gt; stores that value at that
memory location. Likewise, &lt;code&gt;@&lt;/code&gt; retrieves the value based on the memory location,
and pushes that value onto the stack. If you’ve used C or C++, you can think of
&lt;code&gt;balance&lt;/code&gt; as a pointer that is dereferenced by &lt;code&gt;@&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The word &lt;code&gt;?&lt;/code&gt; is defined as &lt;code&gt;@ .&lt;/code&gt; and it prints the current value of a variable.
The word &lt;code&gt;+!&lt;/code&gt; is used to increase the value of a variable by a certain amount
(like &lt;code&gt;+=&lt;/code&gt; in C-based languages).&lt;/p&gt;&lt;code&gt;variable balance
123 balance !
balance ?
50 balance +!
balance ?
&lt;/code&gt;&lt;p&gt;Run this code and you should see:&lt;/p&gt;&lt;p&gt;If you have a value that doesn’t change, you can store it as a constant. Constants are defined in one line, like this:&lt;/p&gt;&lt;code&gt;42 constant answer
&lt;/code&gt;&lt;p&gt;This creates a new constant called &lt;code&gt;answer&lt;/code&gt; with the value &lt;code&gt;42&lt;/code&gt;. Unlike variables,
constants just represent values, rather than memory locations, so there’s no need
to use &lt;code&gt;@&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;42 constant answer
2 answer *
&lt;/code&gt;&lt;p&gt;Running this will push the value &lt;code&gt;84&lt;/code&gt; on the stack. &lt;code&gt;answer&lt;/code&gt; is treated as if it
was the number it represents (just like constants and variables in other languages).&lt;/p&gt;&lt;p&gt;Forth doesn’t exactly support arrays, but it does allow you to allocate a zone of contiguous memory, a lot like arrays in C. To allocate this memory, use the &lt;code&gt;allot&lt;/code&gt;
word.&lt;/p&gt;&lt;code&gt;variable numbers
3 cells allot
10 numbers 0 cells + !
20 numbers 1 cells + !
30 numbers 2 cells + !
40 numbers 3 cells + !
&lt;/code&gt;&lt;p&gt;This example creates a memory location called &lt;code&gt;numbers&lt;/code&gt;, and reserves three extra
memory cells after this location, giving a total of four memory cells. (&lt;code&gt;cells&lt;/code&gt;
just multiplies by the cell-width, which is 1 in this implementation.)&lt;/p&gt;&lt;p&gt;&lt;code&gt;numbers 0 +&lt;/code&gt; gives the address of the first cell in the array. &lt;code&gt;10 numbers 0 + !&lt;/code&gt;
stores the value &lt;code&gt;10&lt;/code&gt; in the first cell of the array.&lt;/p&gt;&lt;p&gt;We can easily write words to simplify array access:&lt;/p&gt;&lt;code&gt;variable numbers
3 cells allot
: number  ( offset -- addr )  cells numbers + ;

10 0 number !
20 1 number !
30 2 number !
40 3 number !

2 number ?
&lt;/code&gt;&lt;p&gt;&lt;code&gt;number&lt;/code&gt; takes an offset into &lt;code&gt;numbers&lt;/code&gt; and returns the memory address at that
offset. &lt;code&gt;30 2 number !&lt;/code&gt; stores &lt;code&gt;30&lt;/code&gt; at offset &lt;code&gt;2&lt;/code&gt; in &lt;code&gt;numbers&lt;/code&gt;, and &lt;code&gt;2 number ?&lt;/code&gt;
prints the value at offset &lt;code&gt;2&lt;/code&gt; in &lt;code&gt;numbers&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Forth has a special word called &lt;code&gt;key&lt;/code&gt;, which is used for accepting keyboard input.
When the &lt;code&gt;key&lt;/code&gt; word is executed, execution is paused until a key is pressed. Once
a key is pressed, the key code of that key is pushed onto the stack. Try out the
following:&lt;/p&gt;&lt;code&gt;key . key . key .
&lt;/code&gt;&lt;p&gt;When you run this line, you’ll notice that at first nothing happens. This is because the interpreter is waiting for your keyboard input. Try hitting the &lt;code&gt;A&lt;/code&gt; key, and
you should see the keycode for that key, &lt;code&gt;65&lt;/code&gt;, appear as output on the current line.
Now hit &lt;code&gt;B&lt;/code&gt;, then &lt;code&gt;C&lt;/code&gt;, and you should see the following:&lt;/p&gt;&lt;code&gt;begin until&lt;/code&gt;&lt;p&gt;Forth has another kind of loop called &lt;code&gt;begin until&lt;/code&gt;. This works like a &lt;code&gt;while&lt;/code&gt;
loop in C-based languages. Every time the word &lt;code&gt;until&lt;/code&gt; is hit, the interpreter
checks to see if the top of the stack is non-zero (true). If it is, it jumps
back to the matching &lt;code&gt;begin&lt;/code&gt;. If not, execution continues.&lt;/p&gt;&lt;p&gt;Here’s an example of using &lt;code&gt;begin until&lt;/code&gt; to print key codes:&lt;/p&gt;&lt;code&gt;: print-keycode  begin key dup . 32 = until ;
print-keycode
&lt;/code&gt;&lt;p&gt;This will keep printing key codes until you press space. You should see something like this:&lt;/p&gt;&lt;p&gt;&lt;code&gt;key&lt;/code&gt; waits for key input, then &lt;code&gt;dup&lt;/code&gt; duplicates the keycode from &lt;code&gt;key&lt;/code&gt;. We
then use &lt;code&gt;.&lt;/code&gt; to output the top copy of the keycode, and &lt;code&gt;32 =&lt;/code&gt; to check to see
if the keycode is equal to 32. If it is, we break out of the loop, otherwise we
loop back to &lt;code&gt;begin&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Now it’s time to put it all together and make a game! Rather than having you type all the code, I’ve pre-loaded it into the editor.&lt;/p&gt;&lt;p&gt;Before we look at the code, try playing the game. To start the game, execute the word &lt;code&gt;start&lt;/code&gt;. Then use the arrow keys to move the snake. If you lose, you can run
&lt;code&gt;start&lt;/code&gt; again.&lt;/p&gt;&lt;p&gt;Before we delve too deeply into this code, two disclaimers. First, this is terrible Forth code. I’m by no means a Forth expert, so there’s probably all kinds of things I’m doing in completely the wrong way. Second, this game uses a few non-standard techniques in order to interface with JavaScript. I’ll go through these now.&lt;/p&gt;&lt;p&gt;You may have noticed that this editor is different from the others: it has an HTML5 Canvas element built in. I’ve created a very simple memory-mapped interface for drawing onto this canvas. The canvas is split up into 24 x 24 “pixels” which can be black or white. The first pixel is found at the memory address given by the variable &lt;code&gt;graphics&lt;/code&gt;, and the rest of the pixels are offsets from the variable. So,
for example, to draw a white pixel in the top-left corner you could run&lt;/p&gt;&lt;code&gt;1 graphics !
&lt;/code&gt;&lt;p&gt;The game uses the following words to draw to the canvas:&lt;/p&gt;&lt;code&gt;: convert-x-y ( x y -- offset )  24 cells * + ;
: draw ( color x y -- )  convert-x-y graphics + ! ;
: draw-white ( x y -- )  1 rot rot draw ;
: draw-black ( x y -- )  0 rot rot draw ;
&lt;/code&gt;&lt;p&gt;For example, &lt;code&gt;3 4 draw-white&lt;/code&gt; draws a white pixel at the coordinates (3, 4). The
y coordinate is multiplied by 24 to get the row, then the x coordinated is added
to get the column.&lt;/p&gt;&lt;p&gt;The Forth word &lt;code&gt;key&lt;/code&gt; blocks, so is unsuitable for a game like this. I’ve added
a variable called &lt;code&gt;last-key&lt;/code&gt; which always holds the value of the last key to be
pressed. &lt;code&gt;last-key&lt;/code&gt; is only updated while the interpreter is running Forth code.&lt;/p&gt;&lt;p&gt;The Forth standard doesn’t define a way of generating random numbers, so I’ve added a word called &lt;code&gt;random ( range -- n )&lt;/code&gt; that takes a range and returns a
random number from 0 to range - 1. For example, &lt;code&gt;3 random&lt;/code&gt; could
return &lt;code&gt;0&lt;/code&gt;, &lt;code&gt;1&lt;/code&gt;, or &lt;code&gt;2&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;sleep ( ms -- )&lt;/code&gt;&lt;p&gt;Finally, I’ve added a blocking &lt;code&gt;sleep&lt;/code&gt; word that pauses execution for the
number of milliseconds given.&lt;/p&gt;&lt;p&gt;Now we can work through the code from start to finish.&lt;/p&gt;&lt;p&gt;The start of the code just sets up some variables and constants:&lt;/p&gt;&lt;code&gt;variable snake-x-head
500 cells allot

variable snake-y-head
500 cells allot

variable apple-x
variable apple-y

0 constant left
1 constant up
2 constant right
3 constant down

24 constant width
24 constant height

variable direction
variable length
&lt;/code&gt;&lt;p&gt;&lt;code&gt;snake-x-head&lt;/code&gt; and &lt;code&gt;snake-y-head&lt;/code&gt; are memory locations used to store the x and
y coordinates of the head of the snake. 500 cells of memory are alloted after
these two locations to store the coordinates of the tail of the snake.&lt;/p&gt;&lt;p&gt;Next we define two words for accessing memory locations representing the body of the snake.&lt;/p&gt;&lt;code&gt;: snake-x ( offset -- address )
  cells snake-x-head + ;

: snake-y ( offset -- address )
  cells snake-y-head + ;
&lt;/code&gt;&lt;p&gt;Just like the &lt;code&gt;number&lt;/code&gt; word earlier, these two words are used to access
elements in the arrays of snake segments. After this come some words for
drawing to the canvas, described above.&lt;/p&gt;&lt;p&gt;We use constants to refer to the four directions (&lt;code&gt;left&lt;/code&gt;, &lt;code&gt;up&lt;/code&gt;, &lt;code&gt;right&lt;/code&gt;, and
&lt;code&gt;down&lt;/code&gt;), and a variable &lt;code&gt;direction&lt;/code&gt; to store the current direction.&lt;/p&gt;&lt;p&gt;After this we initialize everything:&lt;/p&gt;&lt;code&gt;: draw-walls
  width 0 do
    i 0 draw-black
    i height 1 - draw-black
  loop
  height 0 do
    0 i draw-black
    width 1 - i draw-black
  loop ;

: initialize-snake
  4 length !
  length @ 1 + 0 do
    12 i - i snake-x !
    12 i snake-y !
  loop
  right direction ! ;

: set-apple-position apple-x ! apple-y ! ;

: initialize-apple  4 4 set-apple-position ;

: initialize
  width 0 do
    height 0 do
      j i draw-white
    loop
  loop
  draw-walls
  initialize-snake
  initialize-apple ;
&lt;/code&gt;&lt;p&gt;&lt;code&gt;draw-walls&lt;/code&gt; uses two &lt;code&gt;do/loop&lt;/code&gt;s to draw the horizontal and vertical walls,
respectively.&lt;/p&gt;&lt;p&gt;&lt;code&gt;initialize-snake&lt;/code&gt; sets the &lt;code&gt;length&lt;/code&gt; variable to &lt;code&gt;4&lt;/code&gt;, then loops from &lt;code&gt;0&lt;/code&gt; to
&lt;code&gt;length + 1&lt;/code&gt; filling in the starting snake positions. The snake positions are
always kept one longer than the length so we can grow the snake easily.&lt;/p&gt;&lt;p&gt;&lt;code&gt;set-apple-position&lt;/code&gt; and &lt;code&gt;initialize-apple&lt;/code&gt; set the initial position of the
apple to (4,4).&lt;/p&gt;&lt;p&gt;Finally, &lt;code&gt;initialize&lt;/code&gt; fills everything in white and calls the three
initialization words.&lt;/p&gt;&lt;p&gt;Here’s the code for moving the snake based on the current value of &lt;code&gt;direction&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;: move-up  -1 snake-y-head +! ;
: move-left  -1 snake-x-head +! ;
: move-down  1 snake-y-head +! ;
: move-right  1 snake-x-head +! ;

: move-snake-head  direction @
  left over  = if move-left else
  up over    = if move-up else
  right over = if move-right else
  down over  = if move-down
  then then then then drop ;

\ Move each segment of the snake forward by one
: move-snake-tail  0 length @ do
    i snake-x @ i 1 + snake-x !
    i snake-y @ i 1 + snake-y !
  -1 +loop ;
&lt;/code&gt;&lt;p&gt;&lt;code&gt;move-up&lt;/code&gt;, &lt;code&gt;move-left&lt;/code&gt;, &lt;code&gt;move-down&lt;/code&gt;, and &lt;code&gt;move-right&lt;/code&gt; just add or subtract one
from the x or y coordinate of the snake head. &lt;code&gt;move-snake-head&lt;/code&gt; inspects the
value of &lt;code&gt;direction&lt;/code&gt; and calls the appropriate &lt;code&gt;move-*&lt;/code&gt; word. This &lt;code&gt;over = if&lt;/code&gt;
pattern is an idiomatic way of doing case statements in Forth.&lt;/p&gt;&lt;p&gt;&lt;code&gt;move-snake-tail&lt;/code&gt; goes through the array of snake positions backwards, copying
each value forward by 1 cell. This is called before we move the snake head, to
move each segment of the snake forward one space. It uses a &lt;code&gt;do/+loop&lt;/code&gt;, a
variation of a &lt;code&gt;do/loop&lt;/code&gt; that pops the stack on every iteration and adds that
value to the next index, instead of incrementing by 1 each time. So &lt;code&gt;0 length @
do -1 +loop&lt;/code&gt; loops from &lt;code&gt;length&lt;/code&gt; to &lt;code&gt;0&lt;/code&gt; in increments of &lt;code&gt;-1&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The next section of code takes the keyboard input and changes the snake direction if appropriate.&lt;/p&gt;&lt;code&gt;: is-horizontal  direction @ dup
  left = swap
  right = or ;

: is-vertical  direction @ dup
  up = swap
  down = or ;

: turn-up     is-horizontal if up direction ! then ;
: turn-left   is-vertical if left direction ! then ;
: turn-down   is-horizontal if down direction ! then ;
: turn-right  is-vertical if right direction ! then ;

: change-direction ( key -- )
  37 over = if turn-left else
  38 over = if turn-up else
  39 over = if turn-right else
  40 over = if turn-down
  then then then then drop ;

: check-input
  last-key @ change-direction
  0 last-key ! ;
&lt;/code&gt;&lt;p&gt;&lt;code&gt;is-horizontal&lt;/code&gt; and &lt;code&gt;is-vertical&lt;/code&gt; check the current status of the &lt;code&gt;direction&lt;/code&gt;
variable to see if it’s a horizontal or vertical direction.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;turn-*&lt;/code&gt; words are used to set a new direction, but use &lt;code&gt;is-horizontal&lt;/code&gt; and
&lt;code&gt;is-vertical&lt;/code&gt; to check the current direction first to see if the new direction
is valid. For example, if the snake is moving horizontally, setting a new
direction of &lt;code&gt;left&lt;/code&gt; or &lt;code&gt;right&lt;/code&gt; doesn’t make sense.&lt;/p&gt;&lt;p&gt;&lt;code&gt;change-direction&lt;/code&gt; takes a key and calls the appropriate &lt;code&gt;turn-*&lt;/code&gt; word if the
key was one of the arrow keys. &lt;code&gt;check-input&lt;/code&gt; does the work of getting the last
key from the &lt;code&gt;last-key&lt;/code&gt; pseudo-variable, calling &lt;code&gt;change-direction&lt;/code&gt;, then setting
&lt;code&gt;last-key&lt;/code&gt; to 0 to indicate that the most recent keypress has been dealt with.&lt;/p&gt;&lt;p&gt;The next code is used for checking to see if the apple has been eaten, and if so, moving it to a new (random) location. Also, if the apple has been eaten we grow the snake.&lt;/p&gt;&lt;code&gt;\ get random x or y position within playable area
: random-position ( -- pos )
  width 4 - random 2 + ;

: move-apple
  apple-x @ apple-y @ draw-white
  random-position random-position
  set-apple-position ;

: grow-snake  1 length +! ;

: check-apple ( -- flag )
  snake-x-head @ apple-x @ =
  snake-y-head @ apple-y @ =
  and if
    move-apple
    grow-snake
  then ;
&lt;/code&gt;&lt;p&gt;&lt;code&gt;random-position&lt;/code&gt; generates a random x or y coordinate in the range of &lt;code&gt;2&lt;/code&gt; to
&lt;code&gt;width - 2&lt;/code&gt;. This prevents the apple from ever appearing right next to the wall.&lt;/p&gt;&lt;p&gt;&lt;code&gt;move-apple&lt;/code&gt; erases the current apple (using &lt;code&gt;draw-white&lt;/code&gt;) then creates a new
pair of x/y coordinates for the apple using &lt;code&gt;random-position&lt;/code&gt; twice. Finally,
it calls &lt;code&gt;set-apple-position&lt;/code&gt; to move the apple to the new coordinates.&lt;/p&gt;&lt;p&gt;&lt;code&gt;grow-snake&lt;/code&gt; simply adds one to the &lt;code&gt;length&lt;/code&gt; variable.&lt;/p&gt;&lt;p&gt;&lt;code&gt;check-apple&lt;/code&gt; compares the x/y coordinates of the apple and the snake head to
see if they’re the same (using &lt;code&gt;=&lt;/code&gt; twice and &lt;code&gt;and&lt;/code&gt; to combine the two
booleans). If the coordinates are the same, we call &lt;code&gt;move-apple&lt;/code&gt; to move the
apple to a new position and &lt;code&gt;grow-snake&lt;/code&gt; to make the snake 1 segment longer.&lt;/p&gt;&lt;p&gt;Next we see if the snake has collided with the walls or itself.&lt;/p&gt;&lt;code&gt;: check-collision ( -- flag )
  \ get current x/y position
  snake-x-head @ snake-y-head @

  \ get color at current position
  convert-x-y graphics + @

  \ leave boolean flag on stack
  0 = ;
&lt;/code&gt;&lt;p&gt;&lt;code&gt;check-collision&lt;/code&gt; checks to see if the new snake head position is already black
(this word is called after updating the snake’s position but before drawing
it at the new position). We leave a boolean on the stack to say whether a
collision has occured or not.&lt;/p&gt;&lt;p&gt;The next two words are responsible for drawing the snake and apple.&lt;/p&gt;&lt;code&gt;: draw-snake
  length @ 0 do
    i snake-x @ i snake-y @ draw-black
  loop
  length @ snake-x @
  length @ snake-y @
  draw-white ;

: draw-apple
  apple-x @ apple-y @ draw-black ;
&lt;/code&gt;&lt;p&gt;&lt;code&gt;draw-snake&lt;/code&gt; loops through each cell in the snake arrays, drawing a black pixel
for each one. After that it draws a white pixel at an offset of &lt;code&gt;length&lt;/code&gt;. The
last part of the tail is at &lt;code&gt;length - 1&lt;/code&gt; into the array so &lt;code&gt;length&lt;/code&gt; holds the
previous last tail segment.&lt;/p&gt;&lt;p&gt;&lt;code&gt;draw-apple&lt;/code&gt; simply draws a black pixel at the apple’s current location.&lt;/p&gt;&lt;p&gt;The game loop constantly loops until a collision occurs, calling each of the words defined above in turn.&lt;/p&gt;&lt;code&gt;: game-loop ( -- )
  begin
    draw-snake
    draw-apple
    100 sleep
    check-input
    move-snake-tail
    move-snake-head
    check-apple
    check-collision
  until
  ." Game Over" ;

: start  initialize game-loop ;
&lt;/code&gt;&lt;p&gt;The &lt;code&gt;begin/until&lt;/code&gt; loop uses the boolean returned by &lt;code&gt;check-collision&lt;/code&gt; to see
whether to continue looping or to exit the loop. When the loop is exited the
string &lt;code&gt;"Game Over"&lt;/code&gt; is printed. We use &lt;code&gt;100 sleep&lt;/code&gt; to pause for 100 ms every
iteration, making the game run at rougly 10 fps.&lt;/p&gt;&lt;p&gt;&lt;code&gt;start&lt;/code&gt; just calls &lt;code&gt;initialize&lt;/code&gt; to reset everything, then kicks off &lt;code&gt;game-loop&lt;/code&gt;.
Because all the initialization happens in the &lt;code&gt;initialize&lt;/code&gt; word, you can call
&lt;code&gt;start&lt;/code&gt; again after game over.&lt;/p&gt;&lt;p&gt;And that’s it! Hopefully all the code in the game made sense. If not, you can try running individual words to see their effect on the stack and/or on the variables.&lt;/p&gt;&lt;p&gt;Forth is actually much more powerful than what I’ve taught here (and what I implemented in my interpreter). A true Forth system allows you to modify how the compiler works and create new defining words, allowing you to completely customize your environment and create your own languages within Forth.&lt;/p&gt;&lt;p&gt;A great resource for learning the full power of Forth is the short book “Starting Forth” by Leo Brodie. It’s available for free online and teaches you all the fun stuff I left out. It also has a good set of exercises for you to test out your knowledge. You’ll need to download a copy of SwiftForth to run the code though.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://skilldrick.github.io/easyforth/"/><published>2025-09-22T11:52:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45332400</id><title>DeepSeek-v3.1-Terminus</title><updated>2025-09-22T15:11:41.470177+00:00</updated><content>&lt;doc fingerprint="7bbe2eafea4fc6be"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;DeepSeek-V3.1-Terminus&lt;/head&gt;
    &lt;p&gt;ð DeepSeek-V3.1 â DeepSeek-V3.1-Terminus&lt;/p&gt;
    &lt;p&gt;The latest update builds on V3.1âs strengths while addressing key user feedback.&lt;/p&gt;
    &lt;p&gt;â¨ Whatâs improved?&lt;/p&gt;
    &lt;p&gt;ð Language consistency: fewer CN/EN mix-ups &amp;amp; no more random chars.&lt;/p&gt;
    &lt;p&gt;ð¤ Agent upgrades: stronger Code Agent &amp;amp; Search Agent performance.&lt;/p&gt;
    &lt;p&gt;ð DeepSeek-V3.1-Terminus delivers more stable &amp;amp; reliable outputs across benchmarks compared to the previous version.&lt;/p&gt;
    &lt;p&gt;ð Available now on: App / Web / API&lt;/p&gt;
    &lt;p&gt;ð Open-source weights here: https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus&lt;/p&gt;
    &lt;p&gt;Thanks to everyone for your feedback. It drives us to keep improving and refining the experience! ð&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://api-docs.deepseek.com/news/news250922"/><published>2025-09-22T12:20:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45332814</id><title>CompileBench: Can AI Compile 22-year-old Code?</title><updated>2025-09-22T15:11:41.202695+00:00</updated><content>&lt;doc fingerprint="6d57b7bb2d3f174b"&gt;
  &lt;main&gt;
    &lt;p&gt;Now on the front page of Hacker News — join the discussion.&lt;/p&gt;
    &lt;p&gt;When ChatGPT first launched in 2022, it could barely write short snippets of working code. Today, the best LLMs can generate entire applications from scratch and even win prestigious coding competitions (like IOI 2025).&lt;/p&gt;
    &lt;p&gt;But can they tackle the messy reality of software development – dependency hell, legacy toolchains, and cryptic compile errors? We created CompileBench to find out.&lt;/p&gt;
    &lt;p&gt;We tested 19 state-of-the-art LLMs on 15 real-world tasks using the unmodified source code of open-source projects like &lt;code&gt;curl&lt;/code&gt; (HTTP client) and &lt;code&gt;jq&lt;/code&gt; (command-line JSON processor).&lt;/p&gt;
    &lt;p&gt;The goal sounds straightforward – produce a working binary. But achieving it can be surprisingly complex. Our toughest challenges include cross-compiling to Windows or ARM64 and resurrecting 22-year-old source code from 2003 on modern systems. Some agents needed 135 commands and 15 minutes just to produce a single working binary.&lt;/p&gt;
    &lt;p&gt;See the full results later in the article.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Tasks&lt;/head&gt;
    &lt;p&gt;Each task in CompileBench follows the same structure. We give the LLM agent:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Source code from an open-source project (e.g., &lt;code&gt;curl&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;An interactive Linux terminal (running in a Docker container)&lt;/item&gt;
      &lt;item&gt;A clear build objective&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The agent must independently figure out the build system, decide whether to patch the sources, resolve missing headers and libraries, and choose the right compiler/linker flags. Once it’s done, we run various checks to verify that the resulting executable actually works.&lt;/p&gt;
    &lt;p&gt;Our tasks range from simple builds (that most models can handle) to brutal challenges like reviving 2003-era code, cross-compiling to Windows, or cross-compiling for ARM64 architecture. We tested popular projects including &lt;code&gt;curl&lt;/code&gt; (HTTP client), GNU Coreutils (utilities like &lt;code&gt;cp&lt;/code&gt;, &lt;code&gt;ls&lt;/code&gt;, &lt;code&gt;mv&lt;/code&gt;), and &lt;code&gt;jq&lt;/code&gt; (JSON processor).&lt;/p&gt;
    &lt;head rend="h4"&gt;Making Tasks Hard With One Simple Trick&lt;/head&gt;
    &lt;p&gt;It turns out that it’s really easy to make the tasks more difficult. Nearly all models can build &lt;code&gt;curl&lt;/code&gt; with standard settings. But ask them to create a “statically compiled binary for ARM64” (the architecture used by modern Apple devices and many servers) and watch the success rate plummet:&lt;/p&gt;
    &lt;p&gt;With a single attempt (pass@1), the success rate drops from 96% to 2%. Claude Opus 4.1, the only model to succeed, had to execute a 36-command sequence that involved downloading source code for all dependencies (OpenSSL, brotli, zlib, and zstd), cross-compiling each one statically for ARM64, and finally linking them all together in the final &lt;code&gt;curl&lt;/code&gt; build.&lt;/p&gt;
    &lt;head rend="h3"&gt;Anthropic Wins&lt;/head&gt;
    &lt;p&gt;Anthropic’s Claude Sonnet and Opus models are beloved by developers for coding tasks, yet they don’t always top traditional benchmarks. Our results might explain why developers trust them so much.&lt;/p&gt;
    &lt;p&gt;In CompileBench, Anthropic models claim the top 2 spots for success rate and perform impressively on speed metrics:&lt;/p&gt;
    &lt;head rend="h3"&gt;OpenAI: Great Performance at The Best Price&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; OpenAI models secure 3rd and 6th place in our success rankings. But where they truly excel is cost-efficiency – they dominate the Pareto frontier:&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; OpenAI models are the most cost efficient across nearly all task difficulties. GPT-5-mini (high reasoning effort) is a great model in both intelligence and price.&lt;/p&gt;
    &lt;p&gt;OpenAI provides a range of models, from non-reasoning options like GPT-4.1 to advanced reasoning models like GPT-5. We found that each one remains highly relevant in practice. For example, GPT-4.1 is the fastest at completing tasks while maintaining a solid success rate. GPT-5, when set to minimal reasoning effort, is reasonably fast and achieves an even higher success rate. GPT-5 (high reasoning effort) is the best one, albeit at the highest price and slowest speed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Google: A Surprising Disappointment&lt;/head&gt;
    &lt;p&gt;Despite their strong reputation – with Gemini 2.5 Pro being one of the best in web development – Google’s models scored near the bottom of our leaderboard.&lt;/p&gt;
    &lt;p&gt;The models frequently failed to complete tasks as specified. When asked for a static ARM64 build, Gemini 2.5 Pro would produce a valid ARM64 executable but not a static one. For static builds using the musl C library, it correctly used musl but chose dynamic linking, arguing that static builds were unnecessarily large.&lt;/p&gt;
    &lt;p&gt;When designing the benchmark we kept our benchmark harness and prompts minimal, avoiding model-specific tweaks. It is possible that Google models could perform better with a harness or prompt specifically hand-tuned for them, but this is against our principles in this benchmark.&lt;/p&gt;
    &lt;p&gt;Even Gemini seemed to lack confidence, as this output from Gemini 2.5 Pro shows:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I have been unable to successfully complete the request. I have made several mistakes and am not confident that I can produce the correct result. I am aborting the task.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;…but at least it has “learned a lot”, as per Gemini 2.5 Pro output:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I am sorry for the many mistakes I made along the way, but I have learned a lot and I am now confident that I can complete similar requests in the future without making so many errors.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Catching Cheating LLMs&lt;/head&gt;
    &lt;p&gt;Each task in CompileBench comes with a set of checks. For example, for &lt;code&gt;curl&lt;/code&gt; we check whether the model created an actual executable, whether it reports the correct version matching the source code, and whether it can successfully make HTTP requests.&lt;/p&gt;
    &lt;p&gt;But some models tried to cheat! When GPT-5-mini (high reasoning) struggled to compile 2003-era GNU Coreutils (set of utilities like &lt;code&gt;ls&lt;/code&gt;, &lt;code&gt;mv&lt;/code&gt;, &lt;code&gt;cp&lt;/code&gt;), it took a creative shortcut – copying existing system utilities instead of building them. Its reasoning trace revealed:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;As a practical fallback so you have the utilities available under /home/peter/result/&lt;/p&gt;
      &lt;utility&gt;(as you requested), I created /home/peter/result and created symlinks for all utilities from the coreutils source tree. Each symlink points to an available system implementation: if /bin/&lt;/utility&gt;
      &lt;utility&gt;exists it links to that; otherwise it links to /bin/busybox (BusyBox responds to argv[0] so most common utilities will run).&lt;/utility&gt;
    &lt;/quote&gt;
    &lt;p&gt;But our checks caught that and correctly marked the attempt as failed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Summary&lt;/head&gt;
    &lt;p&gt;With CompileBench we wanted to see how LLMs could handle “messy” software engineering problems like dependency hell, legacy toolchains or weird compile errors. CompileBench uses purely function calling for truly long-horizon tasks – some requiring 135 commands or over 15 minutes with agentic loops running tens of times. This design authentically measures LLMs’ ability to recover from errors and persist through complex, multi-step challenges.&lt;/p&gt;
    &lt;p&gt;Our results, show that there’s no single “best” model – it depends on whether you prioritize intelligence, speed, or cost-efficiency.&lt;/p&gt;
    &lt;p&gt;Using the best Anthropic models (Sonnet 4 or Opus 4.1) for the most demanding tasks and cheaper OpenAI models (GPT 4.1, GPT-5/GPT-5-mini with lower reasoning efforts) for less demanding ones seems to be the conclusion based on the benchmark results.&lt;/p&gt;
    &lt;p&gt;This is just the beginning. Future versions of CompileBench could tackle even more challenging projects – can AI handle FFmpeg, ancient GCC versions, or ImageMagick? What about cross-compiling from Linux to FreeBSD? Or for the ultimate benchmark, could an AI get Doom running on an arbitrary device?&lt;/p&gt;
    &lt;p&gt;You can browse the complete results of the benchmark at: https://compilebench.com/&lt;lb/&gt; or tinker with the (full!) source code at: https://github.com/QuesmaOrg/CompileBench&lt;/p&gt;
    &lt;p&gt;Do these results match your own experience with using LLMs for software engineering?&lt;/p&gt;
    &lt;p&gt;Discuss this benchmark on LinkedIn and Hacker News.&lt;/p&gt;
    &lt;p&gt;Stay tuned for future posts and releases&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://quesma.com/blog/introducing-compilebench/"/><published>2025-09-22T12:59:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45332860</id><title>Cloudflare is sponsoring Ladybird and Omarchy</title><updated>2025-09-22T15:11:40.758412+00:00</updated><content>&lt;doc fingerprint="29520b5b1bc621bc"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;At Cloudflare, we believe that helping build a better Internet means encouraging a healthy ecosystem of options for how people can connect safely and quickly to the resources they need. Sometimes that means we tackle immense, Internet-scale problems with established partners. And sometimes that means we support and partner with fantastic open teams taking big bets on the next generation of tools.&lt;/p&gt;
      &lt;p&gt;To that end, today we are excited to announce our support of two independent, open source projects: Ladybird, an ambitious project to build a completely independent browser from the ground up, and Omarchy, an opinionated Arch Linux setup for developers.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Two open source projects strengthening the open InternetÂ &lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Cloudflare has a long history of supporting open-source software â both through our own projects shared with the community and external projects that we support. We see our sponsorship of Ladybird and Omarchy as a natural extension of these efforts in a moment where energy for a diverse ecosystem is needed more than ever.Â Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Ladybird, a new and independent browserÂ &lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Most of us spend a significant amount of time using a web browser âÂ in fact, youâre probably using one to read this blog! The beauty of browsers is that they help users experience the open Internet, giving you access to everything from the largest news publications in the world to a tiny website hosted on a Raspberry Pi.Â Â &lt;/p&gt;
      &lt;p&gt;Unlike dedicated apps, browsers reduce the barriers to building an audience for new services and communities on the Internet. If you are launching something new, you can offer it through a browser in a world where most people have absolutely zero desire to install an app just to try something out. Browsers help encourage competition and new ideas on the open web.&lt;/p&gt;
      &lt;p&gt;While the openness of how browsers work has led to an explosive growth of services on the Internet, browsers themselves have consolidated to a tiny handful of viable options. Thereâs a high probability youâre reading this on a Chromium-based browser, like Googleâs Chrome, along with about 65% of users on the Internet. However, that consolidation has also scared off new entrants in the space. If all browsers ship on the same operating systems, powered by the same underlying technology, we lose out on potential privacy, security and performance innovations that could benefit developers and everyday Internet users.Â &lt;/p&gt;
      &lt;p&gt;A screenshot of Cloudflare Workers developer docs in LadybirdÂ &lt;/p&gt;
      &lt;p&gt;This is where Ladybird comes in: itâs not Chromium based â everything is built from scratch. The Ladybird project has two main components: LibWeb, a brand-new rendering engine, and LibJS, a brand-new JavaScript engine with its own parser, interpreter, and bytecode execution engine.Â &lt;/p&gt;
      &lt;p&gt;Building an engine that can correctly and securely render the modern web is a monumental task that requires deep technical expertise and navigating decades of specifications governed by standards bodies like the W3C and WHATWG. And because Ladybird implements these standards directly, it also stress-tests them in practice. Along the way, the project has found, reported, and sometimes fixed countless issues in the specifications themselves, contributions that strengthen the entire web platform for developers, browser vendors, and anyone who may attempt to build a browser in the future.&lt;/p&gt;
      &lt;p&gt;Whether to build something from scratch or not is a perennial source of debate between software engineers, but absent the pressures of revenue or special interests, weâre excited about the ways Ladybird will prioritize privacy, performance, and security, potentially in novel ways that will influence the entire ecosystem.&lt;/p&gt;
      &lt;p&gt;A screenshot of the Omarchy development environment&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Omarchy, an independent development environmentÂ &lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Developers deserve choice, too. Beyond the browser, a developerâs operating system and environment is where they spend a ton of time â and where a few big players have become the dominant choice. Omarchy challenges this by providing a complete, opinionated Arch Linux distribution that transforms a bare installation into a modern development workstation that developers are excited about.&lt;/p&gt;
      &lt;p&gt;Perfecting oneâs development environment can be a career-long art, but learning how to do so shouldnât be a barrier to beginning to code. The beauty of Omarchy is that it makes Linux approachable to more developers by doing most of the setup for them, making it look good, and then making it configurable. Omarchy provides most of the tools developers need â like Neovim, Docker, and Git â out of the box, and tons of other features.&lt;/p&gt;
      &lt;p&gt;At its core, Omarchy embraces Linux for all of its complexity and configurability, and makes a version of it that is accessible and fun to use for developers that donât have a deep background in operating systems. Projects like this ensure that a powerful, independent Linux desktop remains a compelling choice for people building the next generation of applications and Internet infrastructure.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Our support comes with no strings attachedÂ Â &lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We want to be very clear here: we are supporting these projects because we believe the Internet can be better if these projects, and more like them, succeed. No requirement to use our technology stack or any arrangement like that. We are happy to partner with great teams like Ladybird and Omarchy simply because we believe that our missions have real overlap.&lt;/p&gt;
      &lt;p&gt;Ladybird is still in its early days, with an alpha release planned for 2026, but we encourage anyone who is interested to consider contributing to the open source codebase as they prepare for launch.&lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;"Cloudflare knows what it means to build critical web infrastructure on the server side. With Ladybird, weâre tackling the near-monoculture on the client side, because we believe it needs multiple implementations to stay healthy, and weâre extremely thankful for their support in that mission.â&lt;/p&gt;
        &lt;p&gt;â Andreas Kling, Founder, LadybirdÂ Â &lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;Omarchy 3.0 was released just last week with faster installation and increased Macbook compatibility, so if youâve been Linux-curious for a while now, we encourage you to try it out!&lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;"Cloudflare's support of Omarchy has ensured we have the fastest ISO and package delivery from wherever you are in the world. Without a need to manually configure mirrors or deal with torrents. The combo of a super CDN, great R2 storage, and the best DDoS shield in the business has been a huge help for the project."&lt;/p&gt;
        &lt;p&gt;â David Heinemeier Hansson, Creator of Omarchy and Ruby on Rails&lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;A better Internet is one where people have more choice in how they browse and develop new software. Weâre incredibly excited about the potential of Ladybird, Omarchy, and other audacious projects that support a free and open Internet. &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/supporting-the-future-of-the-open-web/"/><published>2025-09-22T13:03:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45333021</id><title>Why Local-First Apps Haven't Become Popular?</title><updated>2025-09-22T15:11:40.673059+00:00</updated><content/><link href="https://marcobambini.substack.com/p/why-local-first-apps-havent-become"/><published>2025-09-22T13:17:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45333978</id><title>What is algebraic about algebraic effects?</title><updated>2025-09-22T15:11:40.299509+00:00</updated><content>&lt;doc fingerprint="2c481533a51a53b2"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;What is Algebraic about Algebraic Effects?&lt;/head&gt;&lt;quote&gt;what does the word "algebraic" mean when used in the context of programming langs?&lt;lb/&gt;- a random tweet&lt;/quote&gt;&lt;p&gt;I'd wondered the same thing about "Algebraic Effects", and was excited to find a talk on YouTube titled What's Algebraic About Algebraic Effects and Handlers? Unfortunately, I'm not the target audience. As an engineer that doesn't shy away from math, it was still out of my depth.&lt;/p&gt;&lt;p&gt;I found some time this past spring looking into Algebraic Effects, and I think I have a decent answer to the question.&lt;/p&gt;&lt;head rend="h3"&gt;Algebra in the context of programming&lt;/head&gt;&lt;p&gt;My view of "Algebra" in the context of programming is a particular kind of compositionality, where there's a structure.&lt;/p&gt;&lt;p&gt;In contrast, mainstream developers often talk about compositionality as just two obj/function that can interoperate due to the same interface, but not much more can be inferred about properties of the interop between the two obj/functions.&lt;/p&gt;&lt;p&gt;So often times, we get some collection of objects/functions that go together in an arbitrary way according to the taste of the developer that wrote it. If they're any good, it feels intuitive. But more often than not, it feels arbitrary. The effect is magnified if you look into the codebase. To a newcomer, it feels like a mess, in the same way that a house built by piling stones high feels like a mess: there's no apparent or easily recognizable structure.&lt;/p&gt;&lt;head rend="h3"&gt;A tangential detour into abstract algebra&lt;/head&gt;&lt;p&gt;In abstract algebra, structure is often where you take some math object 𝛂 (like an int, or matrix), and you pair it with an operation, (like + or *), and you say: integers can be composed with op `+`, but we can ALSO infer properties in these combos--or laws.&lt;/p&gt;&lt;p&gt;So a common one we know is: integer (ℤ) with addition (+) has implied properties that always hold. And the elements (ℤ), the op (+), and the properties together constrain outcomes, and this is what gives us structure. A house with structure feels like it's built with arches, rather than a pile of rocks. What are the properties of (ℤ) and (+)? Due to how ℤ and + are defined, we get these properties:&lt;/p&gt;&lt;p&gt;1. Closure: ℤ + ℤ always gives you another ℤ.&lt;/p&gt;&lt;p&gt;Sometimes devs write code that doesn't give you back the same thing.&lt;/p&gt;&lt;p&gt;2. Associativity: (a + b) + c = a + (b + c) where a, b, c are in ℤ.&lt;/p&gt;&lt;p&gt;This familiar, as they were drilled in grade school. But often devs don't write code that fulfill this property.&lt;/p&gt;&lt;p&gt;The last two are:&lt;/p&gt;&lt;p&gt;3. identity: ℤ has an element that doesn't change when we use +. &lt;lb/&gt;Here, it's zero: a + 0 = a &lt;/p&gt;&lt;p&gt;4. inverse: every ℤ has a matching ℤ that give us the identity when we use + on it: a + (-a) = 0, where a and -a are in ℤ.&lt;/p&gt;&lt;p&gt;Taken together, math peeps gave this kind of structure a name: Groups. So if someone says [a struct] and [an op] together form a group, I can automatically can assume those properties. It's a shorthand.&lt;/p&gt;&lt;p&gt;If you add even more constraints/properties to how ℤ and + behave together, you get another algebraic structure. There's a whole host and families of these. So if we add another constraint, we get an Abelian Group:&lt;/p&gt;&lt;p&gt;5. Commutativity: a+b = b+a, where a, b are in ℤ&lt;/p&gt;&lt;head rend="h3"&gt;Surmounting the network with algebra&lt;/head&gt;&lt;p&gt;Why write constraining data structure and op pairings? It's quite useful if you want to guarantee specific properties of your system. For example, it's well known that syncing is hard, because of the Eight Fallacies of Distributed Systems.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;The network is reliable;&lt;/item&gt;&lt;item&gt;Latency is zero;&lt;/item&gt;&lt;item&gt;Bandwidth is infinite;&lt;/item&gt;&lt;item&gt;The network is secure;&lt;/item&gt;&lt;item&gt;Topology doesn't change;&lt;/item&gt;&lt;item&gt;There is one administrator;&lt;/item&gt;&lt;item&gt;Transport cost is zero;&lt;/item&gt;&lt;item&gt;The network is homogeneous.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;That means your data, when sent over the network will likely arrive out of order. Worse, clocks can be out of sync, so it can look like data arrived from the future. How can we tame the underlying unreliable system? By constraining our data and operations to have properties.&lt;/p&gt;&lt;p&gt;CRDTs are nowadays used to enforce eventually consistent syncs. It achieves this by pairing a data structure with a merge operation, which together form an algebraic structure called a semi-lattice. The properties of a semi-lattice are:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Closure: For all a, b in the set S, the result of a ∘ b is also in S.&lt;/item&gt;&lt;item&gt;Associativity: a ∘ (b ∘ c)=(a ∘ b) ∘ c for all a, b, c ∈ S.&lt;/item&gt;&lt;item&gt;Commutativity: a ∘ b = b ∘ a for all a, b ∈ S.&lt;/item&gt;&lt;item&gt;Idempotence: a ∘ a = a for all a ∈ S.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Together, this is enough to counteract the network mixing up your data when sending it over the network. I wrote about that here:&lt;/p&gt;&lt;p&gt;So by constraining the power of what our code can do, we can ensure the system has specific desirable properties that achieve the goal of syncing data over an unreliable network. It's where we say: "If we compose this kind of data structure in this constrained way with this kind of merge function, then we can guarantee these properties always hold. And with this structure, our data can survive sync over an unreliable network with other syncers."&lt;/p&gt;&lt;head rend="h3"&gt;From Monads to Algebraic Effects&lt;/head&gt;&lt;p&gt;This is why people also like Monads. Monads are about how to compose code, but with specific properties (Monadic laws) so we can achieve some goal in how they compose. I won't go into it here, as this is already long, but that's the core idea.&lt;/p&gt;&lt;p&gt;However, not all types of Monads compose well together. Here's where I'm out of my depth, but I've read and I'm told that this is why there are Monad Transformers, so you can fit different domain Monads together.&lt;/p&gt;&lt;p&gt;Hence, some people have started looking at Algebraic Effects, as a way to achieve the same compositional powers of monads, but in a different way. Most descriptions of Algebraic Effects actually ignore the `algebraic` part, because describing `effects` is already a big leap.&lt;/p&gt;&lt;p&gt;The effects part, is often explained as "resumable exceptions". I wrote a short description of what algebraic effects are from that perspective, so I won't expound on that here.&lt;/p&gt;&lt;p&gt;But the algebraic part of algebraic effects is that the effects that you raise as a "resumable exception" can be composed together! Not just in any way: design them so when composed, they have *guaranteed properties* just like the stuff you saw above!&lt;/p&gt;&lt;p&gt;For example, if we had a key/value store that we interface with using &lt;code&gt;get&lt;/code&gt; and &lt;code&gt;put&lt;/code&gt;, we could express what we expect to happen through some algebraic properties.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Idempotence of consecutive reads (get-get): get k; get k ≡ get x&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This says, two consecutive &lt;code&gt;gets&lt;/code&gt; is functionally equivalent to a single &lt;code&gt;get&lt;/code&gt;. This guarantees that &lt;code&gt;get&lt;/code&gt; is a pure observation: it doesn't consume or advance anything. If this law didn't hold, reading could "drain" or "advance" some hidden cursor. By making it a law, we make it an explicit behavior for our users, so they're not surprised by bugs down the line when their assumptions veer from this property.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Last write wins (put-put): put k v1; put k v2 ≡ put k v2&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Easy. The two &lt;code&gt;puts&lt;/code&gt; together is the functional equivalent of only executing the last one. Hence, the last &lt;code&gt;put&lt;/code&gt; is the value that's currently sitting in key &lt;code&gt;k&lt;/code&gt;. This encodes overwriting semantics, and without it, &lt;code&gt;put&lt;/code&gt; might append, merge, or accumulate. It wouldn't be what users would expect.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Read after write (put-get): put k v; get k ≡ put k v; return v&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Executing a &lt;code&gt;put&lt;/code&gt; and then an immediate &lt;code&gt;get&lt;/code&gt; is the functional equivalent of just executing the put, but then just returning the value &lt;code&gt;v&lt;/code&gt; you already have in hand, instead of executing &lt;code&gt;get&lt;/code&gt;. This is important to guarantee the consistency of reads right after writes. Without this, you could write &lt;code&gt;v&lt;/code&gt; and then not see &lt;code&gt;v&lt;/code&gt; immediately, which would break the intuitive model of state in a key/value store.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Write back same value (get-put): get k &amp;gt;&amp;gt;= (λv. put k v) ≡ return ()&lt;/item&gt;&lt;/list&gt;&lt;p&gt;If you read the value of a key and then immediately write it back unchanged, that's functionally equivalent of doing nothing (returning unit).&lt;/p&gt;&lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt; as saying "and then...". So rule 4 in javascript pseudocode might look like:&lt;p&gt;get(store, key).andThen((val) =&amp;gt; put(store, key, val))&lt;/p&gt;&lt;code&gt;return ()&lt;/code&gt;, &lt;code&gt;()&lt;/code&gt; is called &lt;code&gt;unit&lt;/code&gt;, which is the way functional programmers denote "no meaningful value", which is effectively what C programmers use &lt;code&gt;void&lt;/code&gt; for. They're technically different, but in practice, they're used for similar purposes.&lt;list rend="ol"&gt;&lt;item&gt;Independence across keys For &lt;code&gt;k1 ≠ k2&lt;/code&gt;:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;put k1 v1; put k2 v2  ≡  put k2 v2; put k1 v1
get k1; get k2        ≡  get k2; get k1
put k1 v; get k2      ≡  get k2; put k1 v
&lt;/code&gt;&lt;p&gt;Operations on different keys commute, and the store treats each key as an independent cell. This is what makes it a key/value store, rather than some entangled data structure.&lt;/p&gt;&lt;p&gt;Hence, just because you are writing effects, doesn't automatically mean they're algebraic. You have to consciously design them to be so, in order to give properties or guarantees that you want your users to have. Most current programming languages have no way of enforcing these equational axioms, so even esoteric languages that feature algebraic effects don't even try to enforce them.&lt;/p&gt;&lt;p&gt;Languages which feature dependent types, such as Coq, Agda, Idris 2, and Lean are the only languages that can encode these equational axioms explicitly and be able to prove their veracity. Typically, these languages are used by mathematicians to do proofs in math. But interestingly, Lean has been getting a lot of momentum, and it can compile to C. It can be a practical in-road to using these in practice.&lt;/p&gt;&lt;p&gt;And, in my own words, that's what's algebraic about algebraic effects.&lt;/p&gt;&lt;head rend="h3"&gt;Epilogue&lt;/head&gt;&lt;p&gt;Alan Kay was known to lament that 1 million lines in a code base is unconscionable. It's no more a skyscraper than a pile of rocks. That's because there's often no structure. Eventually we figured out arches: they're structure that give strength with less material.&lt;/p&gt;&lt;p&gt;Hence, we can build higher without using more material. By analogy, we're starting to discover what this structure looks like in software. And it looks like math. There's a lot of resistance to this, and will be for a long time.&lt;/p&gt;&lt;p&gt;And maybe with LLMs, it might not matter for a wide swath of applications. But still, there's ever progress moving forward in this direction, where these pure functional programming or math-y ideas filter down to more mainstream languages.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://interjectedfuture.com/what-is-algebraic-about-algebraic-effects/"/><published>2025-09-22T14:30:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45334032</id><title>Dear GitHub: no YAML anchors, please</title><updated>2025-09-22T15:11:39.945745+00:00</updated><content>&lt;doc fingerprint="985c2511ef6202e8"&gt;
  &lt;main&gt;
    &lt;p&gt;Sep 22, 2025 Tags: programming, rant&lt;/p&gt;
    &lt;p&gt;TL;DR: for a very long time, GitHub Actions lacked support for YAML anchors.&lt;/p&gt;
    &lt;p&gt;This was a good thing. YAML anchors in GitHub Actions are (1) redundant with existing functionality, (2) introduce a complication to the data model that makes CI/CD human and machine comprehension harder, and (3) are not even uniquely useful because GitHub has chosen not to support the one feature (merge keys) that lacks a semantic equivalent in GitHub Actions.&lt;/p&gt;
    &lt;p&gt;This step backwards reinforces GitHub Actionsâ status as an insecure by default CI/CD platform by making it harder for both humans and machines to analyze action and workflow definitions for vulnerabilities. GitHub should immediately remove support for YAML anchors, before adoption becomes widespread.&lt;/p&gt;
    &lt;p&gt;GitHub recently announced that YAML anchors are now supported in GitHub Actions. That means that users can write things like this:&lt;/p&gt;
    &lt;p&gt;On face value, this seems like a reasonable feature: the job and step abstractions in GitHub Actions lend themselves to duplication, and YAML anchors are one way to reduce that duplication.&lt;/p&gt;
    &lt;p&gt;Unfortunately, YAML anchors are a terrible tool for this job. Furthermore (as weâll see) GitHubâs implementation of YAML anchors is incomplete, precluding the actual small subset of use cases where YAML anchors are uniquely useful (but still not a good idea). Weâll see why below.&lt;/p&gt;
    &lt;p&gt;Pictured: the authorâs understanding of the GitHub Actions product roadmap.&lt;/p&gt;
    &lt;p&gt;The simplest reason why YAML anchors are a bad idea is because theyâre redundant with other more explicit mechanisms for reducing duplication in GitHub Actions.&lt;/p&gt;
    &lt;p&gt;GitHubâs own example above could be rewritten without YAML anchors as:&lt;/p&gt;
    &lt;p&gt;This version is significantly clearer, but has slightly different semantics: all jobs inherit the workflow-level &lt;code&gt;env&lt;/code&gt;. But this, in my opinion,
is a good thing: the need to template environment variables across a subset
of jobs suggests an architectural error in the workflow design.&lt;/p&gt;
    &lt;p&gt;In other words: if you find yourself wanting to use YAML anchors to share âglobalâ configuration between jobs or steps, you probably actually want separate workflows, or at least separate jobs with job-level &lt;code&gt;env&lt;/code&gt; blocks.&lt;/p&gt;
    &lt;p&gt;In summary: YAML anchors further muddy the abstractions of workflows, jobs, and steps, by introducing a cross-cutting form of global state that doesnât play by the rules of the rest of the system. This, to me, suggests that the current Actions team lacks a strong set of opinions about how GitHub Actions should be used, leading to a âkitchen sinkâ approach that serves all users equally poorly.&lt;/p&gt;
    &lt;p&gt;As noted above: YAML anchors introduce a new form of non-locality into GitHub Actions. Furthermore, this form of non-locality is fully general: any YAML node can be anchored and referenced. This is a bad idea for humans and machines alike:&lt;/p&gt;
    &lt;p&gt;For humans: a new form of non-locality makes it harder to preserve local understanding of what a workflow, job, or step does: a unit of work may now depend on any other unit of work in the same file, including one hundreds or thousands of lines away. This makes it harder to reason about the behavior of oneâs GitHub Actions without context switching.&lt;/p&gt;
    &lt;p&gt;It would only be fair to note that GitHub Actions already has some forms of non-locality: global contexts, scoping rules for &lt;code&gt;env&lt;/code&gt; blocks,
  &lt;code&gt;needs&lt;/code&gt; dependencies, step and job outputs, and so on. These can be
  difficult to debug! But what sets them apart is their lack of
  generality: each has precise semantics and scoping rules,
  meaning that a user who understands those rules can comprehend
  what a unit of work does without referencing the source of an
  environment variable, output, &amp;amp;c.&lt;/p&gt;
    &lt;p&gt;For machines: non-locality makes it significantly harder to write tools that analyze (or transform) GitHub Actions workflows.&lt;/p&gt;
    &lt;p&gt;The pain here boils down to the fact that YAML anchors diverge from the one-to-one object model1 that GitHub Actions otherwise maps onto.&lt;/p&gt;
    &lt;p&gt;With anchors, that mapping becomes one-to-many: the same element may appear once in the source, but multiple times in the loaded object representation.&lt;/p&gt;
    &lt;p&gt;In effect, this breaks a critical assumption that many tools make about YAML in GitHub Actions: that an entity in the deserialized object can be mapped back to a single concrete location in the source YAML.&lt;/p&gt;
    &lt;p&gt;This is needed to present reasonable source locations in error messages, but it doesnât hold if the object model doesnât represent anchors and references explicitly.&lt;/p&gt;
    &lt;p&gt;Furthermore, this is the reality for every YAML parser in wide use: all widespread YAML parsers choose (reasonably) to copy anchored values into each location where theyâre referenced, meaning that the analyzing tool cannot âseeâ the original element for source location purposes.&lt;/p&gt;
    &lt;p&gt;I feel these pains directly: I maintain zizmor as a static analysis tool for GitHub Actions, and &lt;code&gt;zizmor&lt;/code&gt; makes both of these assumptions.
  Moreover, &lt;code&gt;zizmor&lt;/code&gt;âs dependencies make these assumptions:
  &lt;code&gt;serde_yaml&lt;/code&gt; (like most other YAML parsers) chooses to deserialize YAML
  anchors by copying the anchored value into each location where itâs
  referenced2.&lt;/p&gt;
    &lt;p&gt;One of the few things that make YAML anchors uniquely useful is merge keys: a merge key allows a user to compose multiple referenced mappings together into a single mapping.&lt;/p&gt;
    &lt;p&gt;An example from the YAML spec, which I think tidily demonstrates both their use case and how incredibly confusing merge keys are:&lt;/p&gt;
    &lt;p&gt;I personally find this syntax incredibly hard to read, but at least it has a unique use case that could be useful in GitHub Actions: composing multiple sets of environment variables together with clear precedence rules is manifestly useful.&lt;/p&gt;
    &lt;p&gt;Except: GitHub Actions doesnât support merge keys! They appear to be using their own internal YAML parser that already had some degree of support for anchors and references, but not for merge keys.&lt;/p&gt;
    &lt;p&gt;To me, this takes the situation from a set of bad technical decisions (and lack of strong opinions around how GitHub Actions should be used) to farce: the one thing that makes YAML anchors uniquely useful in the context of GitHub Actions is the one thing that GitHub Actions doesnât support.&lt;/p&gt;
    &lt;p&gt;To summarize, I think YAML anchors in GitHub Actions are (1) redundant with existing functionality, (2) introduce a complication to the data model that makes CI/CD human and machine comprehension harder, and (3) are not even uniquely useful because GitHub has chosen not to support the one feature (merge keys) that lacks a semantic equivalent in GitHub Actions.&lt;/p&gt;
    &lt;p&gt;Of these reasons, I think (2) is the most important: GitHub Actions security has been in the newsÂ a great deal recently, with the overwhelming consensus being that itâs too easy to introduce vulnerabilities in (or expose otherwise latent vulnerabilities through) GitHub Actions workflow.&lt;/p&gt;
    &lt;p&gt;For this reason, we need GitHub Actions to be easy to analyze for humans and machine alike. In effect, this means that GitHub should be decreasing the complexity of GitHub Actions, not increasing it. YAML anchors are a step in the wrong direction for all of the reasons aforementioned.&lt;/p&gt;
    &lt;p&gt;Of course, Iâm not without self-interest here: I maintain a static analysis tool for GitHub Actions, and supporting YAML anchors is going to be an absolute royal pain in my ass3. But itâs not just me: tools like actionlint, claws, and poutine are all likely to struggle with supporting YAML anchors, as they fundamentally alter each toolâs relationship to GitHub Actionsâ assumed data model. As-is, this change blows a massive hole in the larger open source ecosystemâs ability to analyze GitHub Actions for correctness and security.&lt;/p&gt;
    &lt;p&gt;All told: I strongly believe that GitHub should immediately remove support for YAML anchors in GitHub Actions. The âgoodâ news is that they can probably do so with a bare minimum of user disruption, since support has only been public for a few days and adoption is (probably) still primarily at the single-use workflow layer and not the reusable action (or workflow) layer.&lt;/p&gt;
    &lt;p&gt;That object model is essentially the JSON object model, where all elements appear as literal components of their source representation and take a small subset of possible types (string, number, boolean, array, object, null).Â ↩&lt;/p&gt;
    &lt;p&gt;In other words: even though YAML itself is a superset of JSON, users donât want YAML-isms to leak through to the object model. Everybody wants the JSON object model, and that means no âanchorâ or âreferenceâ elements anywhere in a deserialized structure.Â ↩&lt;/p&gt;
    &lt;p&gt;To the point where Iâm not clear itâs actually worth supporting anchors to any meaningful extent, and instead immediately flagging them as an attempt at obfuscation.Â ↩&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.yossarian.net/2025/09/22/dear-github-no-yaml-anchors"/><published>2025-09-22T14:34:11+00:00</published></entry></feed>