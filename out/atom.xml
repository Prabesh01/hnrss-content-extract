<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-14T14:41:31.433696+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45567877</id><title>No science, no startups: The innovation engine we're switching off</title><updated>2025-10-14T14:41:38.317323+00:00</updated><content>&lt;doc fingerprint="3fc8918d9d618749"&gt;
  &lt;main&gt;
    &lt;p&gt;Tons of words have been written about the Trump Administrations war on Science in Universities. But few people have asked what, exactly, is science? How does it work? Who are the scientists? What do they do? And more importantly, why should anyone (outside of universities) care?&lt;/p&gt;
    &lt;p&gt;(Unfortunately, you won‚Äôt see answers to these questions in the general press ‚Äì it‚Äôs not clickbait enough. Nor will you read about it in the science journals‚Äì it‚Äôs not technical enough. You won‚Äôt hear a succinct description from any of the universities under fire, either ‚Äì they‚Äôve long lost the ability to connect the value of their work to the day-to-day life of the general public.)&lt;/p&gt;
    &lt;p&gt;In this post I‚Äôm going to describe how science works, how science and engineering have worked together to build innovative startups and companies in the U.S.‚Äîand why you should care.&lt;/p&gt;
    &lt;p&gt;(In a previous post I described how the U.S. built a science and technology ecosystem and why investment in science is directly correlated with a country‚Äôs national power. I suggest you read it first.)&lt;/p&gt;
    &lt;p&gt;How Science Works&lt;lb/&gt; I was older than I care to admit when I finally understood the difference between a scientist, an engineer, an entrepreneur and a venture capitalist; and the role that each played in the creation of advancements that made our economy thrive, our defense strong and America great.&lt;/p&gt;
    &lt;p&gt;Scientists&lt;lb/&gt; Scientists (sometimes called researchers) are the people who ask lots of questions about why and how things work. They don‚Äôt know the answers. Scientists are driven by curiosity, willing to make educated guesses (the fancy word is hypotheses) and run experiments to test their guesses. Most of the time their hypotheses are wrong. But every time they‚Äôre right they move the human race forward. We get new medicines, cures for diseases, new consumer goods, better and cheaper foods, etc.&lt;/p&gt;
    &lt;p&gt;Scientists tend to specialize in one area ‚Äì biology, medical research, physics, agriculture, computer science, materials, math, etc. ‚Äî although a few move between areas. The U.S. government has supported scientific research at scale (read billions of $s) since 1940.&lt;/p&gt;
    &lt;p&gt;Scientists tend to fall into two categories: Theorists and Experimentalists.&lt;/p&gt;
    &lt;p&gt;Theorists&lt;lb/&gt; Theorists develop mathematical models, abstract frameworks, and hypotheses for how the universe works. They don‚Äôt run experiments themselves‚Äîinstead, they propose new ideas or principles, explain existing experimental results, predict phenomena that haven‚Äôt been observed yet. Theorists help define what reality might be.&lt;/p&gt;
    &lt;p&gt;Theorists can be found in different fields of science. For example:&lt;/p&gt;
    &lt;p&gt;Physics Quantum field theory, string theory, quantum mechanics&lt;lb/&gt; Biology Neuroscience and cognition, Systems Biology, gene regulation&lt;lb/&gt; Chemistry Molecular dynamics, Quantum chemistry&lt;lb/&gt; Computer Science Design algorithms, prove limits of computation&lt;lb/&gt; Economics Build models of markets or decision-making&lt;lb/&gt; Mathematics Causal inference, Bayesian networks, Deep Learning&lt;/p&gt;
    &lt;p&gt;The best-known 20th-century theorist was Albert Einstein. His tools were a chalkboard and his brain. in 1905 he wrote an equation E=MC2 which told the world that a small amount of mass can be converted into a tremendous amount of energy. When he wrote it down, it was just theory. Other theorists in the 1930s and ‚Äô40s took Einstein‚Äôs theory and provided the impetus for building the atomic bomb. (Leo Szilard conceived neutron chain reaction idea, Hans Bethe led the Theoretical Division at Los Alamos, Edward Teller developed hydrogen bomb theory.) Einstein‚Äôs theory was demonstrably proved correct over Hiroshima and Nagasaki.&lt;/p&gt;
    &lt;p&gt;Experimentalists&lt;lb/&gt; In addition to theorists, other scientists ‚Äì called experimentalists ‚Äì design and run experiments in a lab. The pictures you see of scientists in lab coats in front of microscopes, test tubes, particle accelerators or NASA spacecraft are likely experimentalists. They test hypotheses by developing and performing experiments. An example of this would be NASA‚Äôs James Webb telescope or the LIGO Gravitational-Wave Observatory experiment. (As we‚Äôll see later, often it‚Äôs engineers who build the devices the experimentalists use.)&lt;/p&gt;
    &lt;p&gt;Some of these experimentalists focus on Basic Science, working to get knowledge for its own sake and understand fundamental principles of nature with no immediate practical use in mind.&lt;/p&gt;
    &lt;p&gt;Other experimentalists work in Applied Science, which uses the findings and theories derived from Basic Science to design, innovate, and improve products and processes.&lt;/p&gt;
    &lt;p&gt;Applied scientists solve practical problems oriented toward real-world applications. (Scientists at Los Alamos weretrying to understand the critical mass of U-235 (the minimum amount that would explode.) Basic science lays the groundwork for breakthroughs in applied science. For instance: Quantum mechanics (basic science) led to semiconductors which led to computers (applied science). Germ theory (basic science) led to antibiotics and vaccines (applied science). In the 20th century Applied scientists did not start the companies that make end products. Engineers and entrepreneurs did this. (In the 21st century more Applied Scientists, particularly in life sciences, have also spun out companies from their labs.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Scientists&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; Where is Science in the U.S. Done?&lt;lb/&gt; America‚Äôs unique insight that has allowed it to dominate Science and invention, is that after WWII we gave Research and Development money to universities, rather than only funding government laboratories. No other country did this at scale.&lt;/p&gt;
    &lt;p&gt;Corporate Research Centers&lt;lb/&gt; In the 20th century, U.S. companies put their excess profits into corporate research labs. Basic research in the U.S. was done in at Dupont, Bell Labs, IBM, AT&amp;amp;T, Xerox, Kodak, GE, et al.&lt;/p&gt;
    &lt;p&gt;This changed in 1982, when the Securities and Exchange Commission ruled that it was legal for companies to buy their own stock (reducing the number of shares available to the public and inflating their stock price.) Very quickly Basic Science in corporate research all but disappeared. Companies focused on Applied Research to maximize shareholder value. In its place, Theory and Basic research is now done in research universities.&lt;/p&gt;
    &lt;p&gt;Research Universities&lt;lb/&gt; From the outside (or if you‚Äôre an undergraduate) universities look like a place where students take classes and get a degree. However, in a research university there is something equally important going on. Science faculty in these schools not only teach, but they are expected to produce new knowledge‚Äîthrough experiments, publications, patents, or creative work. Professors get grants and contracts from federal agencies (e.g., NSF, NIH, DoD), foundations, and industry. And the university builds Labs, centers, libraries, and advanced computing facilities that support these activities.&lt;/p&gt;
    &lt;p&gt;In the U.S. there are 542 research universities, ranked by the Carnegie Classification into three categories.&lt;/p&gt;
    &lt;p&gt;R1: 187 Universities ‚Äì Very High Research Activity&lt;lb/&gt; Conduct extensive research and award many doctoral degrees.&lt;lb/&gt; Examples: Stanford, UC Berkeley, Harvard, MIT, Michigan, Texas A&amp;amp;M ‚Ä¶&lt;/p&gt;
    &lt;p&gt;R2: 139 Universities ‚Äì High Research Activity&lt;lb/&gt; Substantial but smaller research scale.&lt;lb/&gt; Examples: Baylor, Wake Forest, UC Santa Cruz, ‚Ä¶&lt;/p&gt;
    &lt;p&gt;R3: 216 Research Colleges/Universities&lt;lb/&gt; Limited research focus; more teaching-oriented doctoral programs.&lt;lb/&gt; Smaller state universities&lt;/p&gt;
    &lt;p&gt;Why Universities Matter to Science&lt;lb/&gt; U.S. universities perform about 50% of all basic science research (physics, chemistry, biology, social sciences, etc.) because they are training grounds for graduate students and postdocs. Universities spend ~$109 billion a year on research. ~$60 billion of that $109 billion comes from the National Institutes for Health (NIH) for biomedical research, National Science Foundation (NSF) for basic science, Department of War (DoW), Department of Energy (DOE), for energy/physics/nuclear, DARPA, NASA. (Companies tend to invest in applied research and development, that leads directly to saleable products.)&lt;/p&gt;
    &lt;p&gt;Professors (especially in Science, Technology, Engineering and Math) run labs that function like mini startups. They ask research questions, then hire grad students, postdocs, and staff and write grant proposals to fund their work, often spending 30‚Äì50% of their time writing and managing grants. When they get a grant the lead researcher (typically a faculty member/head of the lab) is called the Principal Investigator (PI).&lt;/p&gt;
    &lt;p&gt;The Labs are both workplaces and classrooms. Graduate students and Postdocs do the day-to-day science work as part of their training (often for a Ph.D.). Postdocs are full-time researchers gaining further specialization. Undergraduates may also assist in research, especially at top-tier schools.&lt;/p&gt;
    &lt;p&gt;(Up until 2025, U.S. science was deeply international with ~40‚Äì50% of U.S. basic research done by foreign-born researchers (graduate students, postdocs, and faculty). Immigration and student visas were a critical part of American research capacity.)&lt;/p&gt;
    &lt;p&gt;The results of this research are shared with the agencies that funded it, published in journals, presented at conferences and often patented or spun off into startups via technology transfer offices. A lot of commercial tech‚Äîfrom Google search to CRISPR‚Äîstarted in university labs.&lt;/p&gt;
    &lt;p&gt;Universities support their science researchers with basic administrative staff (for compliance, purchasing, and safety) but uniquely in the U.S., by providing the best research facilities (labs, cleanrooms, telescopes), and core scientific services: DNA sequencing centers, electron microscopes, access to cloud, data analysis hubs, etc. These were the best in the world ‚Äì until the sweeping cuts in 2025.&lt;/p&gt;
    &lt;p&gt;Engineers Build on the Work of Scientists&lt;lb/&gt; Engineers design and build things on top of the discoveries of scientists. For example, seven years after scientists split the atom, it took 10s of thousands of engineers to build an atomic bomb. From the outset, the engineers knew what they wanted to build because of the basic and applied scientific research that came before them.&lt;/p&gt;
    &lt;p&gt;Scientists Versus Engineers&lt;/p&gt;
    &lt;p&gt;Engineers create plans, use software to test their designs, then‚Ä¶ cut sheet metal, build rocket engines, construct buildings and bridges, design chips, build equipment for experimentalists, design cars, etc.&lt;/p&gt;
    &lt;p&gt;As an example, at Nvidia their GPU chips are built in a chip factory (TSMC) using the Applied science done by companies like Applied Materials which in turn is based on Basic science of semiconductor researchers. And the massive data centers OpenAI, Microsoft, Google, et al that use Nvidia chips are being built by mechanical and other types of engineers.&lt;/p&gt;
    &lt;p&gt;My favorite example is that the reusable SpaceX rocket landings are made possible by the Applied Science research on Convex Optimization frameworks and algorithms by Steven Boyd of Stanford. And Boyd‚Äôs work was based on the Basic science mathematical field of convex analysis (SpaceX, NASA, JPL, Blue Origin, Rocket Lab all use variations of Convex Optimization for guidance, control, and landing.)&lt;/p&gt;
    &lt;p&gt;Startup Entrepreneurs Build Iteratively and Incrementally&lt;lb/&gt; Entrepreneurs build companies to bring new products to market. They hire engineers to build, test and refine products.&lt;/p&gt;
    &lt;p&gt;Engineers and entrepreneurs operate with very different mindsets, goals, and tolerances for risk and failure. (Many great entrepreneurs start as engineers e.g., Musk, Gates, Page/Brin). An engineer‚Äôs goal is to design and deliver a solution to a known problem with a given set of specifications.&lt;/p&gt;
    &lt;p&gt;In contrast, entrepreneurs start with a series of unknowns about who are the customers, what are the wanted product features, pricing, etc. They retire each of these risks by building an iterative series of minimum viable products to find product/market fit and customer adoption. They pivot their solution as needed when they discover their initial assumptions are incorrect. (Treating each business unknown as a hypothesis is the entrepreneurs‚Äô version of the Scientific Method.)&lt;/p&gt;
    &lt;p&gt;Venture Capitalists Fund Entrepreneurs&lt;lb/&gt; Venture capitalists (VCs) are the people who fund entrepreneurs who work with engineers who build things that applied scientists have proven from basic researchers.&lt;/p&gt;
    &lt;p&gt;Unlike banks which will give out loans for projects that have known specifications and outcomes, VCs invest in a portfolio of much riskier investments. While banks make money on the interest they charge on each loan, VCs take part ownership (equity) in the companies they invest in. While most VC investments fail, the ones that succeed make up for that.&lt;/p&gt;
    &lt;p&gt;Most VCs are not scientists. Few are engineers, some have been entrepreneurs. The best VCs understand technical trends and their investments help shape the future. VCs do not invest in science/researchers. VCs want to minimize the risk of their investment, so they mostly want to take engineering and manufacturing risk, but less so on applied science risk and rarely on basic research risk. Hence the role of government and Universities.&lt;/p&gt;
    &lt;p&gt;VCs invest in projects that can take advantage of science and deliver products within the time horizon of their funds (3‚Äì7 years). Science often needs decades before a killer app is visible.&lt;/p&gt;
    &lt;p&gt;As the flow of science-based technologies dries up, the opportunities for U.S. venture capital based on deep tech will decline, with its future in countries that are investing in science ‚Äì China or Europe.&lt;/p&gt;
    &lt;p&gt;Why Have Scientists? Why Not Just a Country of Engineers, Entrepreneurs and VCs (or AI)?&lt;lb/&gt; If you‚Äôve read so far, you might be scratching your head and asking, ‚ÄúWhy do we have scientists at all? Why pay for people to sit around and think? Why spend money on people who run experiments when most of those experiments fail? Can‚Äôt we replace them with AI?‚Äù&lt;/p&gt;
    &lt;p&gt;The output of this university-industry-government science partnership became the foundation of Silicon Valley, the aerospace sector, the biotechnology industry, Quantum and AI. These investments gave us rockets, cures for cancer, medical devices, the Internet, Chat GPT, AI and more.&lt;/p&gt;
    &lt;p&gt;Investment in science is directly correlated with national power. Weaken science, you weaken the long-term growth of the economy, and national defense.&lt;/p&gt;
    &lt;p&gt;Tech firms‚Äô investments of $100s of billions in AI data centers is greater than the federal government‚Äôs R&amp;amp;D expenditures. But these investments are in engineering not in science. The goal of making scientists redundant using artificial general intelligence misses the point that AI will (and is) making scientists more productive ‚Äì not replacing them.&lt;/p&gt;
    &lt;p&gt;Countries that neglect science become dependent on those that don‚Äôt. U.S. post-WWII dominance came from basic science investments (OSRD, NSF, NIH, DOE labs). After WWII ended, the UK slashed science investment which allowed the U.S. to commercialize the British inventions made during the war.&lt;/p&gt;
    &lt;p&gt;The Soviet Union‚Äôs collapse partly reflected failure to convert science into sustained innovation, during the same time that U.S. universities, startups and venture capital created Silicon Valley. Long-term military and economic advantage (nuclear weapons, GPS, AI) trace back to scientific research ecosystems.&lt;/p&gt;
    &lt;p&gt;Lessons Learned&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;Scientists come in two categories&lt;/item&gt;
      &lt;item&gt;Theorists and experimentalists&lt;/item&gt;
      &lt;item&gt;Two types of experimentalists; Basic science (learn new things) or applied science (practical applications of the science)&lt;/item&gt;
      &lt;item&gt;Scientists train talent, create patentable inventions and solutions for national defense&lt;/item&gt;
      &lt;item&gt;Engineers design and build things on top of the discoveries of scientists&lt;/item&gt;
      &lt;item&gt;Entrepreneurs test and push the boundaries of what products could be built&lt;/item&gt;
      &lt;item&gt;Venture Capital provides the money to startups&lt;/item&gt;
      &lt;item&gt;Scientists, engineers, entrepreneurs ‚Äì these roles are complementary&lt;/item&gt;
      &lt;item&gt;Remove one and the system degrades&lt;/item&gt;
      &lt;item&gt;Science won‚Äôt stop&lt;/item&gt;
      &lt;item&gt;Cut U.S. funding, then science will happen in other countries that understand its relationship to making a nation great ‚Äì like China.&lt;/item&gt;
      &lt;item&gt;National power is derived from investments in Science&lt;/item&gt;
      &lt;item&gt;Reducing investment in basic and applied science makes America weak&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;Appendix ‚Äì How Does Science Work? ‚Äì The Scientific Method&lt;lb/&gt; Whether you were a theorist or experimentalist, for the last 500 years the way to test science was by using the scientific method. This method starts by a scientist wondering and asking, ‚ÄúHere‚Äôs how I think this should work, let‚Äôs test the idea.‚Äù&lt;/p&gt;
    &lt;p&gt;The goal of the scientific method is to turn a guess (in science called a hypothesis) into actual evidence. Scientists do this by first designing an experiment to test their guess/hypothesis. They then run the experiment and collect and analyze the result and ask, ‚ÄúDid the result validate, invalidate the hypothesis? Or did it give us completely new ideas?‚Äù Scientists build instruments and run experiments not because of what they know, but because of what they don‚Äôt know.&lt;/p&gt;
    &lt;p&gt;These experiments can be simple ones costing thousands of dollars that can be run in a university biology lab while others may require billions of dollars to build a satellite, particle accelerator or telescope. (The U.S. took the lead in Science after WWII when the government realized that funding scientists was good for the American economy and defense.)&lt;/p&gt;
    &lt;p&gt;Good science is reproducible. Scientists just don‚Äôt publish their results, but they also publish the details of how they ran their experiment. That allows other scientists to run the same experiment and see if they get the same result for themselves. That makes the scientific method self-correcting (you or others can see mistakes).&lt;/p&gt;
    &lt;p&gt;One other benefit of the scientific method is that scientists (and the people who fund them) expect most of the experiments to fail, but the failures are part of learning and discovery. They teach us what works and what doesn‚Äôt. Failure in science testing unknowns means learning and discovery.&lt;/p&gt;
    &lt;p&gt;Filed under: National Security, NIH (National Institutes of Health), NSF (National Science Foundation) |&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://steveblank.com/2025/10/13/no-science-no-startups-the-unseen-engine-were-switching-off/"/><published>2025-10-13T13:02:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568613</id><title>Smartphones and being present</title><updated>2025-10-14T14:41:38.066866+00:00</updated><content>&lt;doc fingerprint="3411991d2ac390d8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Smartphones and being present&lt;/head&gt;
    &lt;p&gt;I read an article yesterday, stating that on average, people spend 4 hours and 37 minutes on their phones per day1, with South Africans coming in fourth highest in the world at a whopping 5 hours and 11 minutes2.&lt;/p&gt;
    &lt;p&gt;This figure seems really high to me. If we assume people sleep roughly 8 hours per day, that means that one third of their day is spent on their phones. If we also assume people work 8 hours per day (ignoring the fact that they may be using their phones during work hours), that suggests that people spend over half of their free time (and up to 65% of it) glued to their screens.&lt;/p&gt;
    &lt;p&gt;I never wanted to carry the internet around in my pocket. It's too distracting and pulls me out of the present moment, fracturing my attention. I've tried switching to old-school black and white phones before, but always begrudgingly returned to using a smartphone due to the utility of it. The problem, however, is that it comes with too many attention sinks tucked in alongside the useful tools.&lt;/p&gt;
    &lt;p&gt;I care about living an intentional and meaningful life, nurturing relationships, having nuanced conversations, and enjoying the world around me. I don't want to spend this limited time I have on earth watching short form video and getting into arguments on Twitter.&lt;/p&gt;
    &lt;p&gt;This is what I enjoy. Picture taken yesterday in Scarborough, South Africa.&lt;/p&gt;
    &lt;p&gt;I've written at length about how I manage my digital consumption, from turning off notifications to forgoing social media entirely. The underlying premise here is that if you're trying to lose weight, you shouldn't carry cookies around in your pockets. And my phone is the bag of cookies in this metaphor.&lt;/p&gt;
    &lt;p&gt;We're wired to seek out distraction, novel information, and entertainment, and avoid boredom at all costs. But boredom is where creativity and self-reflection do their best work. It's why "all the best ideas come when you're in the shower"‚Äîwe don't usually take our phones with us into the shower (yet).&lt;/p&gt;
    &lt;p&gt;According to Screen Time on my iPhone, on average I spend 30 minutes per day on it, which I think is reasonable, especially considering the most-used apps are by-and-large utility apps like banking and messages. This isn't because I have more self-control than other people. I don't think I do. It's because I know myself, and have set up my digital life to be a positive force, and not an uninspired time-sink.&lt;/p&gt;
    &lt;p&gt;There are many apps and systems to incentivise better relationships with our phones, mostly based around time limits. But these are flawed in three ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I'm an adult, I know how to circumvent these limits, and I will if motivation is low.&lt;/item&gt;
      &lt;item&gt;Time limits don't affect the underlying addiction. You don't quit smoking by only smoking certain hours of the day.&lt;/item&gt;
      &lt;item&gt;The companies that build these apps have tens of thousands of really smart people (and billions of dollars) trying to get me hooked and keep me engaged. The only way to win this game isn't by trying to beat them (I certainly can't), but by not playing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The only way I've found to have a good relationship with my phone is to make it as uninteresting as possible. The first way is to not have recommendation media (think Instagram, TikTok, and all the rest). I'm pro deleting these accounts completely, because it's really easy to re-download the apps on a whim, or visit them in-browser. However some people have found that having them on a dedicated device works by isolating those activities. Something like a tablet at home that is "the only place you're allowed to use Instagram". I can't comment too much on this route, but it seems reasonable.&lt;/p&gt;
    &lt;p&gt;My biggest time sink over the past few years has been YouTube. The algorithm knew me too well and would recommend video after engaging, but ultimately useless video. I could easily burn an entire evening watching absolute junk‚Äîleaving me feeling like I'd just wasted what could have otherwise been a beautiful sunset or a tasty home-cooked lasagne. However, at the beginning of this year I learnt that you can turn off your YouTube watch history entirely, which means no recommendations. Here's what my YouTube home screen now looks like:&lt;/p&gt;
    &lt;p&gt;Without the recommendations I very quickly run out of things to watch from the channels I'm subscribed to. It's completely changed my relationship with YouTube since I only watch the videos I actually want to watch, and none of the attention traps. You can turn off your YouTube watch history here, and auto delete your other Google history (like historic searches and navigation) here, which I think is just good practice.&lt;/p&gt;
    &lt;p&gt;I also used my adblocker, AdGuard on Safari which has a useful "block element" feature, to block the recommended videos on the right of YouTube videos. I use this feature to hide shorts as well, since I have no interest in watching them either, and YouTube intentionally makes them impossible to remove. If you're interested in a similar setup, here are the selectors I use to block those elements:&lt;/p&gt;
    &lt;code&gt;youtube.com###items &amp;gt; ytd-item-section-renderer.style-scope.ytd-watch-next-secondary-results-renderer:last-child
youtube.com###sections
youtube.com##[is-shorts]
youtube.com###secondary
&lt;/code&gt;
    &lt;p&gt;The only media that I do sometimes consume on my phone are my RSS feeds, but it's something I'm completely comfortable with since it's explicitly opt-in by design and low volume.&lt;/p&gt;
    &lt;p&gt;While I still have the twitch to check my phone when I'm waiting for a coffee, or in-between activities‚Äîbecause my brain's reward system has been trained to do this‚ÄîI'm now rewarded with nothing. Over time, I find myself checking my phone less and less. Sometimes I notice the urge, and just let it go, instead focusing on the here and now.&lt;/p&gt;
    &lt;p&gt;I think that while the attention-span-degrading effects of recommendation media are getting most of the headlines, what isn't spoken about as much is the sheer number of hours lost globally to our phones (3.8 million years per day, according to my back-of-the-napkin-math). And while people may argue that this could involve productive work or enjoyable leisure, I suspect that the vast (vast!) majority of that time is short-form entertainment.&lt;/p&gt;
    &lt;p&gt;My solution may sound overkill to many people, but I can say with absolute certainty that it has turned me into a more present, less distracted, and more optimistic person. I have much more time to spend in nature, with friends, or on my hobbies and projects. I can't imagine trading it in for a tiny screen, ever.&lt;/p&gt;
    &lt;p&gt;Give it a try.&lt;/p&gt;
    &lt;p&gt;Happily on the beach for sunset.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://herman.bearblog.dev/being-present/"/><published>2025-10-13T14:20:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568915</id><title>America is getting an AI gold rush instead of a factory boom</title><updated>2025-10-14T14:41:37.842639+00:00</updated><content>&lt;doc fingerprint="f35908d52b294ba0"&gt;
  &lt;main&gt;&lt;p&gt;A gulf is opening up in the heart of American business as two industries championed as central to the country‚Äôs future ‚Äî manufacturing and artificial intelligence ‚Äî appear to be heading in different directions.&lt;/p&gt;&lt;p&gt;By Aaron Gregg&lt;/p&gt; and &lt;list rend="ul"&gt;&lt;item&gt;1Shannon OsakaMicroplastics are everywhere. You can do one simple thing to avoid them.&lt;/item&gt;&lt;item&gt;2Shannon NajmabadiandAaron GreggAirports say they won‚Äôt air Kristi Noem shutdown video at TSA checkpoints&lt;/item&gt;&lt;item&gt;3Scott NoverNews outlets broadly reject Pentagon rules before signing deadline&lt;/item&gt;&lt;item&gt;4Guest columnSi LibermanI‚Äôm 101 years old. Here are 7 things I think are ‚Äòlongevity secrets.‚Äô&lt;/item&gt;&lt;item&gt;5OpinionMax BootWhy the Gaza ceasefire won‚Äôt lead to lasting peace&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.washingtonpost.com/business/2025/10/13/manufacturing-artificial-intelligence/"/><published>2025-10-13T14:48:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45569350</id><title>NanoChat ‚Äì The best ChatGPT that $100 can buy</title><updated>2025-10-14T14:41:37.440054+00:00</updated><content>&lt;doc fingerprint="8c198122f1657e6"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;The best ChatGPT that $100 can buy.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This repo is a full-stack implementation of an LLM like ChatGPT in a single, clean, minimal, hackable, dependency-lite codebase. nanochat is designed to run on a single 8XH100 node via scripts like speedrun.sh, that run the entire pipeline start to end. This includes tokenization, pretraining, finetuning, evaluation, inference, and web serving over a simple UI so that you can talk to your own LLM just like ChatGPT. nanochat will become the capstone project of the course LLM101n being developed by Eureka Labs.&lt;/p&gt;
    &lt;p&gt;The fastest way to feel the magic is to run the speedrun script speedrun.sh, which trains and inferences the $100 tier of nanochat. On an 8XH100 node at $24/hr, this gives a total run time of about 4 hours. Boot up a new 8XH100 GPU box from your favorite provider (e.g. I use and like Lambda), and kick off the training script:&lt;/p&gt;
    &lt;code&gt;bash speedrun.sh&lt;/code&gt;
    &lt;p&gt;Alternatively, since the script runs for 4 hours, I like to launch it like this inside a new screen session &lt;code&gt;speedrun&lt;/code&gt; (and also log output to &lt;code&gt;speedrun.log&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;screen -L -Logfile speedrun.log -S speedrun bash speedrun.sh&lt;/code&gt;
    &lt;p&gt;See the screen cheatsheet if you are less familiar. You can watch it go inside the screen session, or detach with &lt;code&gt;Ctrl-a d&lt;/code&gt; and &lt;code&gt;tail speedrun.log&lt;/code&gt; to view progress. Now wait 4 hours. Once it's done, you can talk to your LLM via the ChatGPT-like web UI. Make sure again that your local uv virtual environment is active (run &lt;code&gt;source .venv/bin/activate&lt;/code&gt;), and serve it:&lt;/p&gt;
    &lt;code&gt;python -m scripts.chat_web&lt;/code&gt;
    &lt;p&gt;And then visit the URL shown. Make sure to access it correctly, e.g. on Lambda use the public IP of the node you're on, followed by the port, so for example http://209.20.xxx.xxx:8000/, etc. Then talk to your LLM as you'd normally talk to ChatGPT! Get it to write stories or poems. Ask it to tell you who you are to see a hallucination. Ask it why the sky is blue. Or why it's green. The speedrun is a 4e19 FLOPs capability model so it's a bit like talking to a kindergartener :).&lt;/p&gt;
    &lt;p&gt;You can also &lt;code&gt;cat report.md&lt;/code&gt; file which appeared in the project directory and contains the "report card" of the run, i.e. a bunch of evaluations and metrics. At the very end, you'll see a summary table, for example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Characters: 333,989&lt;/item&gt;
      &lt;item&gt;Lines: 8,304&lt;/item&gt;
      &lt;item&gt;Files: 44&lt;/item&gt;
      &lt;item&gt;Tokens (approx): 83,497&lt;/item&gt;
      &lt;item&gt;Dependencies (uv.lock lines): 2,004&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;BASE&lt;/cell&gt;
        &lt;cell role="head"&gt;MID&lt;/cell&gt;
        &lt;cell role="head"&gt;SFT&lt;/cell&gt;
        &lt;cell role="head"&gt;RL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CORE&lt;/cell&gt;
        &lt;cell&gt;0.2219&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;ARC-Challenge&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.2875&lt;/cell&gt;
        &lt;cell&gt;0.2807&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;ARC-Easy&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.3561&lt;/cell&gt;
        &lt;cell&gt;0.3876&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;GSM8K&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0250&lt;/cell&gt;
        &lt;cell&gt;0.0455&lt;/cell&gt;
        &lt;cell&gt;0.0758&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;HumanEval&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0671&lt;/cell&gt;
        &lt;cell&gt;0.0854&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;MMLU&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.3111&lt;/cell&gt;
        &lt;cell&gt;0.3151&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ChatCORE&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0730&lt;/cell&gt;
        &lt;cell&gt;0.0884&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Total wall clock time: 3h51m&lt;/p&gt;
    &lt;p&gt;(Your table might be missing the RL number by default). For a lot more information around the speedrun script and what to look for and expect, please refer to the walkthrough that I posted in Discussions of the repo: "Introducing nanochat: The best ChatGPT that $100 can buy".&lt;/p&gt;
    &lt;p&gt;Unsurprisingly, $100 is not enough to train a highly performant ChatGPT clone. In fact, LLMs are famous for their multi-million dollar capex. For our purposes, I think there are two more scales of interest. First is the ~$300 tier d26 model (i.e. depth=26) that trains in ~12 hours, which slightly outperforms GPT-2 CORE score. Second is the $1000 tier (~41.6 hours), just because it's a nice round number. But both of these are not yet fully supported and therefore not attached here in the master branch yet.&lt;/p&gt;
    &lt;p&gt;That said, to give a sense, the example changes needed for the speedrun.sh file to train a GPT-2 grade model d26 only involve three changes:&lt;/p&gt;
    &lt;code&gt;...
# you'll need to download more data shards for pretraining
# get the number of parameters, multiply 20 to get tokens, multiply by 4.8 to get chars,
# divide by 250 million to get number of shards. todo need to improve this...
python -m nanochat.dataset -n 450 &amp;amp;
...
# use --depth to increase model size. to not oom, halve device batch size 32 -&amp;gt; 16:
torchrun --standalone --nproc_per_node=8 -m scripts.base_train -- --depth=26 --device_batch_size=16
...
# make sure to use the same later during midtraining:
torchrun --standalone --nproc_per_node=8 -m scripts.mid_train -- --device_batch_size=16&lt;/code&gt;
    &lt;p&gt;That's it! The biggest thing to pay attention to is making sure you have enough data shards to train on (the code will loop and do more epochs over the same training set otherwise, decreasing learning speed a bit), and managing your memory/VRAM, primarily by decreasing the &lt;code&gt;device_batch_size&lt;/code&gt; until things fit (the scripts automatically compensates by increasing the number of gradient accumulation loops, simply turning parallel compute to sequential compute).&lt;/p&gt;
    &lt;p&gt;And a bit more about computing environments that will run nanochat:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The code will run just fine on the Ampere 8XA100 GPU node as well, but a bit slower.&lt;/item&gt;
      &lt;item&gt;All code will run just fine on even a single GPU by omitting &lt;code&gt;torchrun&lt;/code&gt;, and will produce ~identical results (code will automatically switch to gradient accumulation), but you'll have to wait 8 times longer.&lt;/item&gt;
      &lt;item&gt;If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for &lt;code&gt;--device_batch_size&lt;/code&gt;in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. Less than that you'll have to know a bit more what you're doing and get more creative.&lt;/item&gt;
      &lt;item&gt;Most of the code is fairly vanilla PyTorch so it should run on anything that supports that - xpu, mps, or etc, but I haven't implemented this out of the box so it might take a bit of tinkering.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;nanochat is designed to be short and sweet. One big advantage of this is that we can package up all of the files together and copy paste them to your favorite LLM to ask arbitrary questions. As an example, I like to package up the repo using the files-to-prompt utility like so:&lt;/p&gt;
    &lt;code&gt;files-to-prompt . -e py -e md -e rs -e html -e toml -e sh --ignore "*target*" --cxml &amp;gt; packaged.txt&lt;/code&gt;
    &lt;p&gt;This includes all py, rs, html, toml, sh files, excludes the &lt;code&gt;rustbpe/target&lt;/code&gt; folder, and chooses the cxml output format. Everything is written to the &lt;code&gt;packaged.txt&lt;/code&gt; file, which atm measures ~330KB (i.e. well below ~100K tokens for a state of the art LLM), and ~8K lines of code in 45 files.&lt;/p&gt;
    &lt;p&gt;Alternatively, I recommend using DeepWiki from Devin/Cognition to ask questions of this repo. In the URL of this repo, simply change github.com to deepwiki.com, and you're off.&lt;/p&gt;
    &lt;p&gt;I haven't invested too much here but some tests exist, especially for the tokenizer. Run e.g. as:&lt;/p&gt;
    &lt;code&gt;python -m pytest tests/test_rustbpe.py -v -s&lt;/code&gt;
    &lt;p&gt;nanochat is nowhere finished. The goal is to improve the state of the art in micro models that are accessible to work with end to end on budgets of &amp;lt; $1000 dollars. Accessibility is about overall cost but also about cognitive complexity - nanochat is not an exhaustively configurable LLM "framework"; there will be no giant configuration objects, model factories, or if-then-else monsters in the code base. It is a single, cohesive, minimal, readable, hackable, maximally-forkable "strong baseline" codebase designed to run start to end and produce a concrete ChatGPT clone and its report card.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The name (nanochat) derives from my earlier project nanoGPT, which only covered pretraining.&lt;/item&gt;
      &lt;item&gt;nanochat is also inspired by modded-nanoGPT, which gamified the nanoGPT repo with clear metrics and a leaderboard, and borrows a lot of its ideas and some implementation for pretraining.&lt;/item&gt;
      &lt;item&gt;Thank you to HuggingFace for fineweb and smoltalk.&lt;/item&gt;
      &lt;item&gt;Thank you Lambda for the compute used in developing this project.&lt;/item&gt;
      &lt;item&gt;Thank you to chief LLM whisperer üßô‚ôÇÔ∏è Alec Radford for advice/guidance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you find nanochat helpful in your research cite simply as:&lt;/p&gt;
    &lt;code&gt;@misc{nanochat,
  author = {Andrej Karpathy},
  title = {nanochat: The best ChatGPT that $100 can buy},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/karpathy/nanochat}
}&lt;/code&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/karpathy/nanochat"/><published>2025-10-13T15:22:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45570973</id><title>America's future could hinge on whether AI slightly disappoints</title><updated>2025-10-14T14:41:37.121834+00:00</updated><content>&lt;doc fingerprint="7fe089016e6199bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;America's future could hinge on whether AI slightly disappoints&lt;/head&gt;
    &lt;head rend="h3"&gt;If the economy's single pillar goes down, Trump's presidency will be seen as a disaster.&lt;/head&gt;
    &lt;p&gt;A burning question that‚Äôs on a lot of people‚Äôs minds right now is: Why is the U.S. economy still holding up? The manufacturing industry is hurting badly from Trump‚Äôs tariffs, the payroll numbers are looking weak, and consumer sentiment is at Great Recession levels:&lt;/p&gt;
    &lt;p&gt;And yet despite those warning signs, there has been nothing even remotely resembling an economic crash yet. Unemployment is rising a little bit but still extremely low, while the prime-age employment rate ‚Äî my favorite single indicator of the health of the labor market ‚Äî is still near all-time highs. The New York Fed‚Äôs GDP nowcast thinks that GDP growth is currently running at a little over 2%, while the Atlanta Fed‚Äôs nowcast puts it even higher.&lt;/p&gt;
    &lt;p&gt;One possibility is that everything is just fine with the economy ‚Äî that Trump‚Äôs tariffs aren‚Äôt actually that high because of all the exemptions, and/or that economists are exaggerating the negative effects of tariffs in the first place. Weak consumer confidence could be a partisan ‚Äúvibecession‚Äù, payroll slowdown could be from illegal immigrants being deported or leaving en masse, and manufacturing‚Äôs woes could be from some other sector-specific factor.&lt;/p&gt;
    &lt;p&gt;Another possibility is that tariffs are bad, but are being canceled out by an even more powerful force ‚Äî the AI boom. The FT reports:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Pantheon Macroeconomics estimates that US GDP would have grown at a mere 0.6 per cent annualised rate in the first half were it not for AI-related spending, or half the actual rate.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Paul Kedrosky came up with similar numbers. Jason Furman does a slightly different calculation, and arrives at an even starker number:&lt;/p&gt;
    &lt;p&gt;And here‚Äôs an impressive chart:&lt;/p&gt;
    &lt;p&gt;The Economist writes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[L]ook beyond AI and much of the economy appears sluggish. Real consumption has flatlined since December. Jobs growth is weak. Housebuilding has slumped, as has business investment in non-AI parts of the economy[.]&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And in a post entitled ‚ÄúAmerica is now one big bet on AI‚Äù, Ruchir Sharma writes that ‚ÄúAI companies have accounted for 80 per cent of the gains in US stocks so far in 2025.‚Äù In fact, more than a fifth of the entire S&amp;amp;P 500 market cap is now just three companies ‚Äî Nvidia, Microsoft, and Apple ‚Äî two of which are basically big bets on AI.&lt;/p&gt;
    &lt;p&gt;Now as Furman points out, this doesn‚Äôt necessarily mean that without AI, the U.S. economy would be stalling out. If the economy wasn‚Äôt pouring resources into AI, it might be pouring them into something else, spurring growth that was almost as fast as what we actually saw. But it‚Äôs also possible that without AI, America would be crashing from tariffs.&lt;/p&gt;
    &lt;p&gt;Trump certainly seems to think AI is a golden goose worth protecting. Joey Politano points out that even as Trump has slapped tariffs on a plethora of industries, he has left AI and its supply chain mostly untouched:&lt;/p&gt;
    &lt;p&gt;But despite Trump‚Äôs tariff exemptions, the AI sector could very well crash in the next year or two. And if it does, it could do a lot more than just hurt Americans‚Äô employment prospects and stock portfolios.&lt;/p&gt;
    &lt;p&gt;If AI is really the only thing protecting America from the scourge of Trump‚Äôs tariffs, then a bust in the sector could change the country‚Äôs entire political economy. A crash and recession would immediately flip the narrative on Trump‚Äôs whole presidency, much as the housing crash of 2008 cemented George W. Bush‚Äôs legacy as a failure. And because Trump‚Äôs second term is looking so transformative1, the fate of the AI sector could potentially determine the entire fate of the country.&lt;/p&gt;
    &lt;p&gt;So a whole lot is riding on the question of whether an AI bust will crash the economy. The stakes could hardly be higher.&lt;/p&gt;
    &lt;head rend="h4"&gt;The case everyone is making for an AI bubble&lt;/head&gt;
    &lt;p&gt;A lot of bubbles are purely financial beasts, driven by irrationality or coordination problems in the markets for stocks, bonds, and derivatives. For example, you can have a speculative bubble, in which a bunch of people know an asset is overpriced, but think they can sell out before the crash, and so they keep buying and buying and pushing the price up and up. You can also have an extrapolative bubble, when people see the price of something going up and up, and mistakenly decide that it must be due to some underlying positive trend.&lt;/p&gt;
    &lt;p&gt;But a much simpler possibility is that investors could make a big mistake about how valuable some technology is. They could honestly believe that AI is going to create immense amounts of value, and they could just end up being wrong. Then when they realize that the technology isn‚Äôt all it‚Äôs cracked up to be, they could temper their expectations, which would cause a price crash in AI stocks.2 But the stock crash wouldn‚Äôt be the real problem; far more painful would be the wave of loan defaults and financial distress that would result from AI‚Äôs actual shortcomings.&lt;/p&gt;
    &lt;p&gt;If there‚Äôs an AI crash, it‚Äôll probably be this latter type. Jeff Bezos calls it an ‚Äúindustrial bubble‚Äù, and I think that‚Äôs as good a name as any. This kind of bubble is still a financial phenomenon, since the banking system gets hurt. But the cause is a mistake about real technology, rather than asset markets going haywire.&lt;/p&gt;
    &lt;p&gt;Everyone who‚Äôs talking about an AI bubble is basically warning that the technology itself might disappoint. For example, here are some excerpts from a big Bloomberg feature about the possibility of an AI bubble:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Even some of AI‚Äôs biggest cheerleaders acknowledge the market is frothy, while still professing their belief in the technology‚Äôs long-term potential. AI, they say, is poised to reshape multiple industries, cure diseases and generally accelerate human progress‚Ä¶Yet never before has so much money been spent so rapidly on a technology that, for all its potential, remains somewhat unproven as a profit-making business model‚Ä¶&lt;/p&gt;
      &lt;p&gt;The data center spending spree is overshadowed by persistent skepticism about the payoff from AI technology. In August, investors were rattled after researchers at the Massachusetts Institute of Technology found that 95% of organizations saw zero return on their investment in AI initiatives.&lt;/p&gt;
      &lt;p&gt;More recently, researchers at Harvard and Stanford offered a possible explanation for why. Employees are using AI to create ‚Äúworkslop,‚Äù which the researchers define as ‚ÄúAI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task.‚Äù‚Ä¶&lt;/p&gt;
      &lt;p&gt;AI developers have also been confronting a different challenge. OpenAI‚Ä¶Anthropic and others have for years bet on the so-called scaling laws‚Ä¶Over the past year, however, these developers have experienced diminishing returns‚Ä¶Some have also struggled to match their own hype. After months of touting GPT-5 as a significant leap, OpenAI‚Äôs release of its latest AI model in August was met with mixed reviews‚Ä¶&lt;/p&gt;
      &lt;p&gt;There‚Äôs also the risk that the AI industry‚Äôs vast data center buildout, entailing a huge increase in electricity consumption, will be held back by the realities of strained national power networks.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When you bring up concerns like this to an AI engineer, executive, or founder, they tend to just smile at you indulgently, secure in the knowledge that their invention is everything it‚Äôs cracked up to be, and that much better things are already in the pipeline.&lt;/p&gt;
    &lt;p&gt;But this doesn‚Äôt reassure me. Because when we look at the history of industrial bubbles, and of new technologies in general, it becomes clear that in order to cause a crash, AI doesn‚Äôt have to fail. It just has to mildly disappoint the most ardent optimists.&lt;/p&gt;
    &lt;p&gt;This is why I think an AI crash is more likely than a lot of people in the tech world ‚Äî or the Trump administration ‚Äî realize.&lt;/p&gt;
    &lt;head rend="h4"&gt;Why AI could crash even if AI is just as useful as the optimists expect&lt;/head&gt;
    &lt;head rend="h2"&gt;Keep reading with a 7-day free trial&lt;/head&gt;
    &lt;p&gt;Subscribe to Noahpinion to keep reading this post and get 7 days of free access to the full post archives.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.noahpinion.blog/p/americas-future-could-hinge-on-whether"/><published>2025-10-13T17:24:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45571688</id><title>Modern iOS Security Features ‚Äì A Deep Dive into SPTM, TXM, and Exclaves</title><updated>2025-10-14T14:41:37.030109+00:00</updated><content>&lt;doc fingerprint="b49e9503c5f3920d"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Cryptography and Security&lt;/head&gt;&lt;p&gt; [Submitted on 10 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Modern iOS Security Features -- A Deep Dive into SPTM, TXM, and Exclaves&lt;/head&gt;View PDF&lt;quote&gt;Abstract:The XNU kernel is the basis of Apple's operating systems. Although labeled as a hybrid kernel, it is found to generally operate in a monolithic manner by defining a single privileged trust zone in which all system functionality resides. This has security implications, as a kernel compromise has immediate and significant effects on the entire system. Over the past few years, Apple has taken steps towards a more compartmentalized kernel architecture and a more microkernel-like design. To date, there has been no scientific discussion of SPTM and related security mechanisms. Therefore, the understanding of the system and the underlying security mechanisms is minimal. In this paper, we provide a comprehensive analysis of new security mechanisms and their interplay, and create the first conclusive writeup considering all current mitigations. SPTM acts as the sole authority regarding memory retyping. Our analysis reveals that, through SPTM domains based on frame retyping and memory mapping rule sets, SPTM introduces domains of trust into the system, effectively gapping different functionalities from one another. Gapped functionality includes the TXM, responsible for code signing and entitlement verification. We further demonstrate how this introduction lays the groundwork for the most recent security feature of Exclaves, and conduct an in-depth analysis of its communication mechanisms. We discover multifold ways of communication, most notably xnuproxy as a secure world request handler, and the Tightbeam IPC framework. The architecture changes are found to increase system security, with key and sensitive components being moved out of XNU's direct reach. This also provides additional security guarantees in the event of a kernel compromise, which is no longer an immediate threat at the highest trust level.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.09272"/><published>2025-10-13T18:23:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45571822</id><title>Strudel REPL ‚Äì a music live coding environment living in the browser</title><updated>2025-10-14T14:41:36.700735+00:00</updated><content>&lt;doc fingerprint="d36fdfbffc5b7f73"&gt;
  &lt;main&gt;
    &lt;p&gt;mastodon&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://strudel.cc"/><published>2025-10-13T18:37:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45574393</id><title>DDoS Botnet Aisuru Blankets US ISPs in Record DDoS</title><updated>2025-10-14T14:41:36.230530+00:00</updated><content>&lt;doc fingerprint="c70581cbb810e0c3"&gt;
  &lt;main&gt;
    &lt;p&gt;The world‚Äôs largest and most disruptive botnet is now drawing a majority of its firepower from compromised Internet-of-Things (IoT) devices hosted on U.S. Internet providers like AT&amp;amp;T, Comcast and Verizon, new evidence suggests. Experts say the heavy concentration of infected devices at U.S. providers is complicating efforts to limit collateral damage from the botnet‚Äôs attacks, which shattered previous records this week with a brief traffic flood that clocked in at nearly 30 trillion bits of data per second.&lt;/p&gt;
    &lt;p&gt;Since its debut more than a year ago, the Aisuru botnet has steadily outcompeted virtually all other IoT-based botnets in the wild, with recent attacks siphoning Internet bandwidth from an estimated 300,000 compromised hosts worldwide.&lt;/p&gt;
    &lt;p&gt;The hacked systems that get subsumed into the botnet are mostly consumer-grade routers, security cameras, digital video recorders and other devices operating with insecure and outdated firmware, and/or factory-default settings. Aisuru‚Äôs owners are continuously scanning the Internet for these vulnerable devices and enslaving them for use in distributed denial-of-service (DDoS) attacks that can overwhelm targeted servers with crippling amounts of junk traffic.&lt;/p&gt;
    &lt;p&gt;As Aisuru‚Äôs size has mushroomed, so has its punch. In May 2025, KrebsOnSecurity was hit with a near-record 6.35 terabits per second (Tbps) attack from Aisuru, which was then the largest assault that Google‚Äôs DDoS protection service Project Shield had ever mitigated. Days later, Aisuru shattered that record with a data blast in excess of 11 Tbps.&lt;/p&gt;
    &lt;p&gt;By late September, Aisuru was publicly flexing DDoS capabilities topping 22 Tbps. Then on October 6, its operators heaved a whopping 29.6 terabits of junk data packets each second at a targeted host. Hardly anyone noticed because it appears to have been a brief test or demonstration of Aisuru‚Äôs capabilities: The traffic flood lasted less only a few seconds and was pointed at an Internet server that was specifically designed to measure large-scale DDoS attacks.&lt;/p&gt;
    &lt;p&gt;Aisuru‚Äôs overlords aren‚Äôt just showing off. Their botnet is being blamed for a series of increasingly massive and disruptive attacks. Although recent assaults from Aisuru have targeted mostly ISPs that serve online gaming communities like Minecraft, those digital sieges often result in widespread collateral Internet disruption.&lt;/p&gt;
    &lt;p&gt;For the past several weeks, ISPs hosting some of the Internet‚Äôs top gaming destinations have been hit with a relentless volley of gargantuan attacks that experts say are well beyond the DDoS mitigation capabilities of most organizations connected to the Internet today.&lt;/p&gt;
    &lt;p&gt;Steven Ferguson is principal security engineer at Global Secure Layer (GSL), an ISP in Brisbane, Australia. GSL hosts TCPShield, which offers free or low-cost DDoS protection to more than 50,000 Minecraft servers worldwide. Ferguson told KrebsOnSecurity that on October 8, TCPShield was walloped with a blitz from Aisuru that flooded its network with more than 15 terabits of junk data per second.&lt;/p&gt;
    &lt;p&gt;Ferguson said that after the attack subsided, TCPShield was told by its upstream provider OVH that they were no longer welcome as a customer.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis was causing serious congestion on their Miami external ports for several weeks, shown publicly via their weather map,‚Äù he said, explaining that TCPShield is now solely protected by GSL.&lt;/p&gt;
    &lt;p&gt;Traces from the recent spate of crippling Aisuru attacks on gaming servers can be still seen at the website blockgametracker.gg, which indexes the uptime and downtime of the top Minecraft hosts. In the following example from a series of data deluges on the evening of September 28, we can see an Aisuru botnet campaign briefly knocked TCPShield offline.&lt;/p&gt;
    &lt;p&gt;Paging through the same uptime graphs for other network operators listed shows almost all of them suffered brief but repeated outages around the same time. Here is the same uptime tracking for Minecraft servers on the network provider Cosmic (AS30456), and it shows multiple large dips that correspond to game server outages caused by Aisuru.&lt;/p&gt;
    &lt;head rend="h2"&gt;BOTNETS R US&lt;/head&gt;
    &lt;p&gt;Ferguson said he‚Äôs been tracking Aisuru for about three months, and recently he noticed the botnet‚Äôs composition shifted heavily toward infected systems at ISPs in the United States. Ferguson shared logs from an attack on October 8 that indexed traffic by the total volume sent through each network provider, and the logs showed that 11 of the top 20 traffic sources were U.S. based ISPs.&lt;/p&gt;
    &lt;p&gt;AT&amp;amp;T customers were by far the biggest U.S. contributors to that attack, followed by botted systems on Charter Communications, Comcast, T-Mobile and Verizon, Ferguson found. He said the volume of data packets per second coming from infected IoT hosts on these ISPs is often so high that it has started to affect the quality of service that ISPs are able to provide to adjacent (non-botted) customers.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe impact extends beyond victim networks,‚Äù Ferguson said. ‚ÄúFor instance we have seen 500 gigabits of traffic via Comcast‚Äôs network alone. This amount of egress leaving their network, especially being so US-East concentrated, will result in congestion towards other services or content trying to be reached while an attack is ongoing.‚Äù&lt;/p&gt;
    &lt;p&gt;Roland Dobbins is principal engineer at Netscout. Dobbins said Ferguson is spot on, noting that while most ISPs have effective mitigations in place to handle large incoming DDoS attacks, many are far less prepared to manage the inevitable service degradation caused by large numbers of their customers suddenly using some or all available bandwidth to attack others.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe outbound and cross-bound DDoS attacks can be just as disruptive as the inbound stuff,‚Äù Dobbin said. ‚ÄúWe‚Äôre now in a situation where ISPs are routinely seeing terabit-per-second plus outbound attacks from their networks that can cause operational problems.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúThe crying need for effective and universal outbound DDoS attack suppression is something that is really being highlighted by these recent attacks,‚Äù Dobbins continued. ‚ÄúA lot of network operators are learning that lesson now, and there‚Äôs going to be a period ahead where there‚Äôs some scrambling and potential disruption going on.‚Äù&lt;/p&gt;
    &lt;p&gt;KrebsOnSecurity sought comment from the ISPs named in Ferguson‚Äôs report. Charter Communications pointed to a recent blog post on protecting its network, stating that Charter actively monitors for both inbound and outbound attacks, and that it takes proactive action wherever possible.&lt;/p&gt;
    &lt;p&gt;‚ÄúIn addition to our own extensive network security, we also aim to reduce the risk of customer connected devices contributing to attacks through our Advanced WiFi solution that includes Security Shield, and we make Security Suite available to our Internet customers,‚Äù Charter wrote in an emailed response to questions. ‚ÄúWith the ever-growing number of devices connecting to networks, we encourage customers to purchase trusted devices with secure development and manufacturing practices, use anti-virus and security tools on their connected devices, and regularly download security patches.‚Äù&lt;/p&gt;
    &lt;p&gt;A spokesperson for Comcast responded, ‚ÄúCurrently our network is not experiencing impacts and we are able to handle the traffic.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;9 YEARS OF MIRAI&lt;/head&gt;
    &lt;p&gt;Aisuru is built on the bones of malicious code that was leaked in 2016 by the original creators of the Mirai IoT botnet. Like Aisuru, Mirai quickly outcompeted all other DDoS botnets in its heyday, and obliterated previous DDoS attack records with a 620 gigabit-per-second siege that sidelined this website for nearly four days in 2016.&lt;/p&gt;
    &lt;p&gt;The Mirai botmasters likewise used their crime machine to attack mostly Minecraft servers, but with the goal of forcing Minecraft server owners to purchase a DDoS protection service that they controlled. In addition, they rented out slices of the Mirai botnet to paying customers, some of whom used it to mask the sources of other types of cybercrime, such as click fraud.&lt;/p&gt;
    &lt;p&gt;Dobbins said Aisuru‚Äôs owners also appear to be renting out their botnet as a distributed proxy network that cybercriminal customers anywhere in the world can use to anonymize their malicious traffic and make it appear to be coming from regular residential users in the U.S.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe people who operate this botnet are also selling (it as) residential proxies,‚Äù he said. ‚ÄúAnd that‚Äôs being used to reflect application layer attacks through the proxies on the bots as well.‚Äù&lt;/p&gt;
    &lt;p&gt;The Aisuru botnet harkens back to its predecessor Mirai in another intriguing way. One of its owners is using the Telegram handle ‚Äú9gigsofram,‚Äù which corresponds to the nickname used by the co-owner of a Minecraft server protection service called Proxypipe that was heavily targeted in 2016 by the original Mirai botmasters.&lt;/p&gt;
    &lt;p&gt;Robert Coelho co-ran Proxypipe back then along with his business partner Erik ‚Äú9gigsofram‚Äù Buckingham, and has spent the past nine years fine-tuning various DDoS mitigation companies that cater to Minecraft server operators and other gaming enthusiasts. Coelho said he has no idea why one of Aisuru‚Äôs botmasters chose Buckingham‚Äôs nickname, but added that it might say something about how long this person has been involved in the DDoS-for-hire industry.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe Aisuru attacks on the gaming networks these past seven day have been absolutely huge, and you can see tons of providers going down multiple times a day,‚Äù Coelho said.&lt;/p&gt;
    &lt;p&gt;Coelho said the 15 Tbps attack this week against TCPShield was likely only a portion of the total attack volume hurled by Aisuru at the time, because much of it would have been shoved through networks that simply couldn‚Äôt process that volume of traffic all at once. Such outsized attacks, he said, are becoming increasingly difficult and expensive to mitigate.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs definitely at the point now where you need to be spending at least a million dollars a month just to have the network capacity to be able to deal with these attacks,‚Äù he said.&lt;/p&gt;
    &lt;head rend="h2"&gt;RAPID SPREAD&lt;/head&gt;
    &lt;p&gt;Aisuru has long been rumored to use multiple zero-day vulnerabilities in IoT devices to aid its rapid growth over the past year. XLab, the Chinese security company that was the first to profile Aisuru‚Äôs rise in 2024, warned last month that one of the Aisuru botmasters had compromised the firmware distribution website for Totolink, a maker of low-cost routers and other networking gear.&lt;/p&gt;
    &lt;p&gt;‚ÄúMultiple sources indicate the group allegedly compromised a router firmware update server in April and distributed malicious scripts to expand the botnet,‚Äù XLab wrote on September 15. ‚ÄúThe node count is currently reported to be around 300,000.‚Äù&lt;/p&gt;
    &lt;p&gt;Aisuru‚Äôs operators received an unexpected boost to their crime machine in August when the U.S. Department Justice charged the alleged proprietor of Rapper Bot, a DDoS-for-hire botnet that competed directly with Aisuru for control over the global pool of vulnerable IoT systems.&lt;/p&gt;
    &lt;p&gt;Once Rapper Bot was dismantled, Aisuru‚Äôs curators moved quickly to commandeer vulnerable IoT devices that were suddenly set adrift by the government‚Äôs takedown, Dobbins said.&lt;/p&gt;
    &lt;p&gt;‚ÄúFolks were arrested and Rapper Bot control servers were seized and that‚Äôs great, but unfortunately the botnet‚Äôs attack assets were then pieced out by the remaining botnets,‚Äù he said. ‚ÄúThe problem is, even if those infected IoT devices are rebooted and cleaned up, they will still get re-compromised by something else generally within minutes of being plugged back in.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;BOTMASTERS AT LARGE&lt;/head&gt;
    &lt;p&gt;XLab‚Äôs September blog post cited multiple unnamed sources saying Aisuru is operated by three cybercriminals: ‚ÄúSnow,‚Äù who‚Äôs responsible for botnet development; ‚ÄúTom,‚Äù tasked with finding new vulnerabilities; and ‚ÄúForky,‚Äù responsible for botnet sales.&lt;/p&gt;
    &lt;p&gt;KrebsOnSecurity interviewed Forky in our May 2025 story about the record 6.3 Tbps attack from Aisuru. That story identified Forky as a 21-year-old man from Sao Paulo, Brazil who has been extremely active in the DDoS-for-hire scene since at least 2022. The FBI has seized Forky‚Äôs DDoS-for-hire domains several times over the years.&lt;/p&gt;
    &lt;p&gt;Like the original Mirai botmasters, Forky also operates a DDoS mitigation service called Botshield. Forky declined to discuss the makeup of his ISP‚Äôs clientele, or to clarify whether Botshield was more of a hosting provider or a DDoS mitigation firm. However, Forky has posted on Telegram about Botshield successfully mitigating large DDoS attacks launched against other DDoS-for-hire services.&lt;/p&gt;
    &lt;p&gt;In our previous interview, Forky acknowledged being involved in the development and marketing of Aisuru, but denied participating in attacks launched by the botnet.&lt;/p&gt;
    &lt;p&gt;Reached for comment earlier this month, Forky continued to maintain his innocence, claiming that he also is still trying to figure out who the current Aisuru botnet operators are in real life (Forky said the same thing in our May interview).&lt;/p&gt;
    &lt;p&gt;But after a week of promising juicy details, Forky came up empty-handed once again. Suspecting that Forky was merely being coy, I asked him how someone so connected to the DDoS-for-hire world could still be mystified on this point, and suggested that his inability or unwillingness to blame anyone else for Aisuru would not exactly help his case.&lt;/p&gt;
    &lt;p&gt;At this, Forky verbally bristled at being pressed for more details, and abruptly terminated our interview.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôm not here to be threatened with ignorance because you are stressed,‚Äù Forky replied. ‚ÄúThey‚Äôre blaming me for those new attacks. Pretty much the whole world (is) due to your blog.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://krebsonsecurity.com/2025/10/ddos-botnet-aisuru-blankets-us-isps-in-record-ddos/"/><published>2025-10-13T23:21:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45575391</id><title>Don‚Äôt Look Up: Sensitive internal links in the clear on GEO satellites [pdf]</title><updated>2025-10-14T14:41:35.902440+00:00</updated><content/><link href="https://satcom.sysnet.ucsd.edu/docs/dontlookup_ccs25_fullpaper.pdf"/><published>2025-10-14T01:48:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45576502</id><title>Copy-and-Patch: A Copy-and-Patch Tutorial</title><updated>2025-10-14T14:41:35.668910+00:00</updated><content>&lt;doc fingerprint="e6e4b238e00f7a0a"&gt;
  &lt;main&gt;
    &lt;code&gt;int add_a_b(int a, int b) {
    return a + b
}&lt;/code&gt;
    &lt;head rend="h1"&gt;A Copy-and-Patch Tutorial&lt;/head&gt;
    &lt;p&gt;Copy-and-patch Compilation is a fascinating way of constructing a baseline JIT[1]. It permits incredibly fast runtime compilation of code fragments in a very easy to maintain fashion, requires barely any actual understanding of assembly code, and produces native code of sufficient quality to be within the same range as traditional, hand-written baseline JITs. [1]: Baseline JIT, as in a JIT whose goal is primarily to generate code quickly and gain performance by removing interpretation overhead than generating well optimized code itself. Baseline JITs can be paired with optimizing JITs, like V8‚Äôs Liftoff baseline JIT for WASM allowing tiering up into V8‚Äôs Crankshaft optimizing JIT.&lt;/p&gt;
    &lt;p&gt;Copy-and-patch works by writing stencils, minimal C functions that implement the desired individual operations such that they compile to concatenate native code fragments. At JIT compile time, one can copy the pre-compiled fragment for each operation back-to-back, patching them change embedded constants or addresses as needed..&lt;/p&gt;
    &lt;p&gt;As an adventure into understanding how copy-and-patch works, our goal will be to create the function&lt;/p&gt;
    &lt;p&gt;But specialized at runtime to compute &lt;code&gt;1 + 2&lt;/code&gt;. We‚Äôll be doing this by first breaking it down into some bytecode-sized operations:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;const_int_reg1:&lt;/p&gt;
        &lt;code&gt;a = 1;&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;const_int_reg2:&lt;/p&gt;
        &lt;code&gt;b = 2;&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;add_int1_int2:&lt;/p&gt;
        &lt;code&gt;c = a + b;&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;return_int1:&lt;/p&gt;
        &lt;code&gt;return c;&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And to define our copy-and-patch JIT, we‚Äôll take each of these and:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Implement the operation in C with relocation holes to be later patched to form our stencil.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Compile the stencil into native code.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Copy-paste the native code back into a C file with functions to emit it to a buffer and patch any relocations.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then we can write our little JIT compilation engine to concatenate our stencils and execute the generated function. Let‚Äôs get started!&lt;/p&gt;
    &lt;head rend="h2"&gt;Stencils&lt;/head&gt;
    &lt;p&gt;Our first step is to define our stencils:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdint.h&amp;gt;

#define STENCIL_FUNCTION __attribute__((preserve_none))

extern char cnp_value_hole[65536];
extern void cnp_func_hole(void) STENCIL_FUNCTION;

#define STENCIL_HOLE(type) \
  (type)((uintptr_t)&amp;amp;cnp_value_hole)
#define DECLARE_STENCIL_OUTPUT(...) \
  typedef void(*stencil_output_fn)(__VA_ARGS__) STENCIL_FUNCTION; \
  stencil_output_fn stencil_output = (stencil_output_fn)&amp;amp;cnp_func_hole;

STENCIL_FUNCTION void load_int_reg1() {
  int a = STENCIL_HOLE(int);
  DECLARE_STENCIL_OUTPUT(int);
  stencil_output(a);
}

STENCIL_FUNCTION void load_int_reg2(int a) {
  int b = STENCIL_HOLE(int);
  DECLARE_STENCIL_OUTPUT(int, int);
  stencil_output(a, b);
}

STENCIL_FUNCTION void add_int1_int2(int a, int b) {
  int c = a + b;
  DECLARE_STENCIL_OUTPUT(int);
  stencil_output(c);
}

STENCIL_FUNCTION int return_int1(int a) {
  return a;
}&lt;/code&gt;
    &lt;p&gt;We compile this with &lt;code&gt;clang -O3 -mcmodel=medium -c stencils.c&lt;/code&gt;, and examine the generated code via &lt;code&gt;objdump -d -Mintel,x86-64 --disassemble --reloc stencils.o&lt;/code&gt;.  This yields:&lt;/p&gt;
    &lt;code&gt;0000000000000000 &amp;lt;load_int_reg1&amp;gt;:
   0:	41 bc 00 00 00 00    	mov    r12d,0x0
			2: R_X86_64_32	cnp_value_hole
   6:	e9 00 00 00 00       	jmp    b &amp;lt;load_int_reg1+0xb&amp;gt;
			7: R_X86_64_PLT32	cnp_func_hole-0x4
   b:	0f 1f 44 00 00       	nop    DWORD PTR [rax+rax*1+0x0]

0000000000000010 &amp;lt;load_int_reg2&amp;gt;:
  10:	41 bd 00 00 00 00    	mov    r13d,0x0
			12: R_X86_64_32	cnp_value_hole
  16:	e9 00 00 00 00       	jmp    1b &amp;lt;load_int_reg2+0xb&amp;gt;
			17: R_X86_64_PLT32	cnp_func_hole-0x4
  1b:	0f 1f 44 00 00       	nop    DWORD PTR [rax+rax*1+0x0]

0000000000000020 &amp;lt;add_int1_int2&amp;gt;:
  20:	45 01 ec             	add    r12d,r13d
  23:	e9 00 00 00 00       	jmp    28 &amp;lt;add_int1_int2+0x8&amp;gt;
			24: R_X86_64_PLT32	cnp_func_hole-0x4
  28:	0f 1f 84 00 00 00 00 	nop    DWORD PTR [rax+rax*1+0x0]
  2f:	00

0000000000000030 &amp;lt;return_int1&amp;gt;:
  30:	44 89 e0             	mov    eax,r12d
  33:	c3                   	ret&lt;/code&gt;
    &lt;p&gt;(The NOP‚Äôs aren‚Äôt actually a part of the function, they‚Äôre just padding added so that each function starts with 16 byte alignment.)&lt;/p&gt;
    &lt;p&gt;For each of these stencils, we fill in a template to form our stencil generation library to use during JITing.&lt;/p&gt;
    &lt;code&gt;uint8_t cnp_stencil_&amp;lt;OP&amp;gt;_code[] = {
  // Copy the bytes from the top of the function until the jmp.
};

uint8_t* cnp_copy_&amp;lt;OP&amp;gt;(uint8_t* stencil_start) {
  const size_t stencil_size = sizeof(cnp_stencil_&amp;lt;OP&amp;gt;_code);
  memcpy(stencil_start, cnp_stencil_&amp;lt;OP&amp;gt;_code, stencil_size);
  return stencil_start + stencil_size;
}

// If any relocations exist for the stencil, fill in the values.
// If not, just skip writing this function.
void cnp_patch_&amp;lt;OP&amp;gt;(uint8_t* stencil_start, /* ... */ ) {
  memcpy(stencil_start + /*relocation_offset*/, &amp;amp;value, /* relocation_size */);
}&lt;/code&gt;
    &lt;p&gt;So let‚Äôs get started!&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdint.h&amp;gt;

uint8_t cnp_stencil_load_int_reg1_code[] = {
   0x41, 0xbc, 0x00, 0x00, 0x00, 0x00, // mov r12d,0x0
};
uint8_t* cnp_copy_load_int_reg1(uint8_t* stencil_start) {
  const size_t stencil_size = sizeof(cnp_stencil_load_int_reg1_code);
  memcpy(stencil_start, cnp_stencil_load_int_reg1_code, stencil_size);
  return stencil_start + stencil_size;
}
void cnp_patch_load_int_reg1(uint8_t* stencil_start, int value) {
  // 2: R_X86_64_32 cnp_value_hole  -&amp;gt;  0x02 offset
  memcpy(stencil_start + 0x2, &amp;amp;value, sizeof(value));
}

uint8_t cnp_stencil_load_int_reg2_code[] = {
   0x41, 0xbd, 0x00, 0x00, 0x00, 0x00, // mov r13d,0x0
};
uint8_t* cnp_copy_load_int_reg2(uint8_t* stencil_start) {
  const size_t stencil_size = sizeof(cnp_stencil_load_int_reg2_code);
  memcpy(stencil_start, cnp_stencil_load_int_reg2_code, stencil_size);
  return stencil_start + stencil_size;
}
void cnp_patch_load_int_reg2(uint8_t* stencil_start, int value) {
  // 12: R_X86_64_32 cnp_value_hole  -&amp;gt;  0x12 - 0x10 base = 0x2
  memcpy(stencil_start + 0x2, &amp;amp;value, sizeof(value));
}

uint8_t cnp_stencil_add_int1_int2_code[] = {
  0x45, 0x01, 0xec, // add r12d,r13d
};
uint8_t* cnp_copy_add_int1_int2(uint8_t* stencil_start) {
  const size_t stencil_size = sizeof(cnp_stencil_add_int1_int2_code);
  memcpy(stencil_start, cnp_stencil_add_int1_int2_code, stencil_size);
  return stencil_start + stencil_size;
}
// No patching needed

uint8_t cnp_stencil_return_int1_code[] = {
  0x44, 0x89, 0xe0, // mov eax,r12d
  0xc3,             // ret
};
uint8_t* cnp_copy_return_int1(uint8_t* stencil_start) {
  const size_t stencil_size = sizeof(cnp_stencil_return_int1_code);
  memcpy(stencil_start, cnp_stencil_return_int1_code, stencil_size);
  return stencil_start + stencil_size;
}
// No patching needed&lt;/code&gt;
    &lt;p&gt;In a fully automated setup, all of this work will happen as part of the build system. The stencil compilation and transforming them into a library of copy functions and patch functions happens as part running &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Your First JIT&lt;/head&gt;
    &lt;p&gt;With our stencil library in place, we can use our code generation functions to build our runtime specialized adder:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;stdint.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;

//#include "cnp_stencils.h"
uint8_t* cnp_copy_load_int_reg1(uint8_t* stencil_start);
void cnp_patch_load_int_reg1(uint8_t* stencil_start, int value);
uint8_t* cnp_copy_load_int_reg2(uint8_t* stencil_start);
void cnp_patch_load_int_reg2(uint8_t* stencil_start, int value);
uint8_t* cnp_copy_add_int1_int2(uint8_t* stencil_start);
uint8_t* cnp_copy_return_int1(uint8_t* stencil_start);

typedef int(*jit_func)() __attribute__((preserve_none));

jit_func create_add_1_2() {
  // Most systems mark memory as non-executable by default
  // and mprotect() to set memory as executable needs
  // to be run against mmap-allocated memory.  We start
  // by allocating it as read/write, and then switch it
  // to write/execute once we're done writing the code.
  uint8_t* codedata = mmap(NULL, 256, PROT_READ | PROT_WRITE,
      MAP_PRIVATE | MAP_ANONYMOUS | MAP_POPULATE, -1, 0);
  assert (codedata != MAP_FAILED);
  jit_func ret = (jit_func)codedata;

  // Concatenate our program together, while saving the
  // locations that need to be patched.
  uint8_t* load_int_reg1_location = codedata;
  codedata = cnp_copy_load_int_reg1(codedata);
  uint8_t* load_int_reg2_location = codedata;
  codedata = cnp_copy_load_int_reg2(codedata);
  codedata = cnp_copy_add_int1_int2(codedata);
  codedata = cnp_copy_return_int1(codedata);

  // Overwrite the zero value placeholders with our intended
  // specialized values: 1 and 2.
  cnp_patch_load_int_reg1(load_int_reg1_location, 1);
  cnp_patch_load_int_reg2(load_int_reg2_location, 2);

  // Now that we're done writing, remove write access and
  // allow execution from this page instead.
  int rc = mprotect(ret, 256, PROT_READ | PROT_EXEC);
  if (rc) {
    perror("mprotect");
  }
  return ret;
}

int main() {
  jit_func add_1_2 = create_add_1_2();
  int result = add_1_2();
  printf("JIT'd 1 + 2 = %d\n", result);
  return 0;
}&lt;/code&gt;
    &lt;p&gt;And now we can compile and run that!&lt;/p&gt;
    &lt;quote&gt;$ clang cnp_jit.c cnp_stencils.c -o cnp_jit $ ./cnp_jit JIT'd 1 + 2 = 3&lt;/quote&gt;
    &lt;p&gt;We‚Äôve successfully built runtime code generation, while letting clang do the hard work of actually writing the assembly code, and our JIT compiler is just a bunch of memcpy calls!&lt;/p&gt;
    &lt;head rend="h2"&gt;Try It Yourself&lt;/head&gt;
    &lt;p&gt;Here‚Äôs a header to offer some macros to make declaring relocation holes easier:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;stdint.h&amp;gt;

#define STENCIL_FUNCTION __attribute__((preserve_none))

extern void cnp_stencil_output(void) STENCIL_FUNCTION;

#define STENCIL_HOLE32(ordinal, type) \
  (type)((uintptr_t)&amp;amp;cnp_small_value_hole_##ordinal)
#define STENCIL_HOLE64(ordinal, type) \
  (type)((uintptr_t)&amp;amp;cnp_large_value_hole_##ordinal)
#define STENCIL_FN_NEAR(ordinal, type) \
  (type)&amp;amp;cnp_near_func_hole_##ordinal
#define STENCIL_FN_FAR(ordinal, type) \
  ({ uint64_t _cnp_addr_as_int = (uint64_t)((uintptr_t)&amp;amp;cnp_far_func_hole_##ordinal); \
  asm volatile("" : "+r" (_cnp_addr_as_int) : : "memory"); \
  (type)_cnp_addr_as_int; })
#define DECLARE_STENCIL_OUTPUT(...) \
  typedef void(*stencil_output_fn)(__VA_ARGS__) STENCIL_FUNCTION; \
  stencil_output_fn stencil_output = (stencil_output_fn)&amp;amp;cnp_stencil_output;

#define DECLARE_EXTERN_HOLES(ordinal) \
extern char cnp_large_value_hole_##ordinal[100000]; \
extern char cnp_small_value_hole_##ordinal[8]; \
extern void cnp_near_func_hole_##ordinal(void) STENCIL_FUNCTION; \
extern char cnp_far_func_hole_##ordinal[100000];&lt;/code&gt;
    &lt;p&gt;(If you‚Äôre interested in the details of why these macros are the way they are, see the next post in the series!)&lt;/p&gt;
    &lt;p&gt;Then you can declare as complex of a stencil as you need:&lt;/p&gt;
    &lt;code&gt;#include "cnp_stencils.h"

// Declare up to the maximum number of holes you need of one type
// in a function:
DECLARE_EXTERN_HOLES(1);
DECLARE_EXTERN_HOLES(2);

STENCIL_FUNCTION
void fused_multiply_add_sqrt_ifnotzero() {
  uint32_t a = STENCIL_HOLE32(1, uint32_t);
  uint32_t b = STENCIL_HOLE32(2, int32_t);
  uint64_t c = STENCIL_HOLE64(1, uint64_t);

  uint64_t fma = a * b + c;

  if (fma == 0) {
    void (*div_trap)(void) = STENCIL_FN_NEAR(1, void(*)(void));
    div_trap();
  }

  uint64_t (*sqrt)(uint64_t) = STENCIL_FN_FAR(1, uint64_t(*)(uint64_t));
  uint64_t result = sqrt(c);

  DECLARE_STENCIL_OUTPUT(uint64_t);
  stencil_output(result);
}&lt;/code&gt;
    &lt;p&gt;Which just for completeness sake, compiles into:&lt;/p&gt;
    &lt;quote&gt;0000000000000000 &amp;lt;fused_multiply_add_sqrt_ifnotzero&amp;gt;: 0: 50 push rax 1: b8 00 00 00 00 mov eax,0x0 2: R_X86_64_32 cnp_small_value_hole_2 6: b9 00 00 00 00 mov ecx,0x0 7: R_X86_64_32 cnp_small_value_hole_1 b: 0f af c8 imul ecx,eax e: 48 b8 00 00 00 00 00 movabs rax,0x0 15: 00 00 00 10: R_X86_64_64 cnp_large_value_hole_1 18: 48 01 c8 add rax,rcx 1b: 75 05 jne 22 &amp;lt;fused_multiply_add_sqrt_ifnotzero+0x22&amp;gt; 1d: e8 00 00 00 00 call 22 &amp;lt;fused_multiply_add_sqrt_ifnotzero+0x22&amp;gt; 1e: R_X86_64_PLT32 cnp_near_func_hole_1-0x4 22: 48 b8 00 00 00 00 00 movabs rax,0x0 29: 00 00 00 24: R_X86_64_64 cnp_far_func_hole_1 2c: 48 bf 00 00 00 00 00 movabs rdi,0x0 33: 00 00 00 2e: R_X86_64_64 cnp_large_value_hole_1 36: ff d0 call rax 38: 49 89 c4 mov r12,rax 3b: 58 pop rax 3c: e9 00 00 00 00 jmp 41 &amp;lt;fused_multiply_add_sqrt_ifnotzero+0x41&amp;gt; 3d: R_X86_64_PLT32 cnp_stencil_output-0x4&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://transactional.blog/copy-and-patch/tutorial"/><published>2025-10-14T05:14:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45576623</id><title>Why study programming languages (2022)</title><updated>2025-10-14T14:41:35.474662+00:00</updated><content>&lt;doc fingerprint="d72839db0aea91f4"&gt;
  &lt;main&gt;
    &lt;p&gt;This class is about the study of programming languages. Before we start, I want to perform two activities with folks here. First, I want us to answer two dumb questions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Why do we design new programming languages?&lt;/item&gt;
      &lt;item&gt;What is a programming language?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While (2) seems to be the more fundamental question, we need to answer (1) to have any hope of even thinking about (2).&lt;/p&gt;
    &lt;p&gt;So first, why do we design programming languages? Every program that can be written, can be written in C or assembly or Java or any of the dozens of languages we already have. So why do we design new languages?&lt;/p&gt;
    &lt;p&gt;Common answers to this question will include words like abstraction, performance, convenience, usability etc. The problem with these answers is that apart from the measurable, they are all subjective, aesthetic choices. Convenience is a function of knowledge, familiarity, and community. Usability is similarly ill-defined and hard to measure. And of course, none of these metrics really predict which languages are widely used or popular.&lt;/p&gt;
    &lt;p&gt;Consider the thought of inventing a whole new natural language just to express a new concept clearly. Explaining the rules of grammar and construction would certainly be simpler than any natural language provides. And yet, we√¢d have the small, troubling problem that this knowledge would be almost entirely useless; we need to learn a commonly known natural language to communicate with people. And yet, this is something that we can often find ourselves doing with programming languages with the hope that the concepts learned in one language can be transferred into another; a world where being a polyglot is expected, not unusual.&lt;/p&gt;
    &lt;p&gt;Perhaps this points to a striking similarity between programming languages. As they evolve, they take features from each other and converge into one language singular. They√¢re only differences being the syntax used to represent them.&lt;/p&gt;
    &lt;p&gt;But of course, knowledge of a language is different from mastery. An expert C programmer√¢s bit twiddling is akin of magic while a Haskell programmers tower of abstractions will make mere mortals cower away in fear.&lt;/p&gt;
    &lt;p&gt;Here√¢s a hypothesis, the truth of which is unknown to me: we create programming languages to experience new ideas; ideas that would have remained inaccessible had we stayed with the old languages. Languages not just a form of expression but also a form of exploration. I do not create languages with the hope of expressing everything that was, but to express that which isn√¢t yet. It is the rare joy of a language designer to see their languages being used and abused to do something inconceivable to them. I would point to dozens of historical examples of this, from ALGOL, to APL, every time a language has enabled expression and forward exploration, it has changed the course of computing.&lt;/p&gt;
    &lt;p&gt;Now that we have some bearing of why we create programming languages, we can try answering what exactly is a programming language.&lt;/p&gt;
    &lt;p&gt;Is a language just syntax? Surely not, since symbols don√¢t have any meaning to them. Perhaps it is the meaning of programs in the language, its semantics that defines a language. But its meaning in terms of what? The results of programs? The internal states of this execution algorithm? Perhaps a purely mathematical description, detached from anything resembling a computer?&lt;/p&gt;
    &lt;p&gt;Something resembling semantics of languages does seem to be a part of what defines a language but it is definitely not the full story. Ask a Python programmer why they like it and they√¢ll point to the amazing library ecosystem; ask a web developer why they like JavaScript, and they√¢ll wax poetic about Web 2.0; to a Haskell proponent, it√¢s type system, to a LISP programmer, macros, to a Go programmer, its concurrency model and so on. All of these characteristics define languages and yet have very little to do with semantics. So semantics alone do not define languages.&lt;/p&gt;
    &lt;p&gt;Perhaps a tentative definition is that a programming language is defined by its syntax, semantics, and ecosystem. The former two are easy to study formally; we can teach you the mathematical tools needed to understand them. But for the latter, we must turn back to our first question: why do we design new languages. It is true that both Python and Go have ample libraries and a concurrency model. However, the exploratory power of Python is enabled by the sheer quantity and quality of those libraries while Go√¢s power comes from its concurrency model.&lt;/p&gt;
    &lt;p&gt;Therefore, I give my last definition of what a programming language is: syntax, semantics, and ecosystem in support of exploration; which parts of semantics and ecosystems to care about defined by what tools of exploration they provide. The study of programming languages encompasses all of these: syntax, semantics, type systems, runtime systems, garbage collectors, debuggers, IDEs, syntax highlighting, error messages, compilers, and design. Lines drawn between these are arbitrary, mostly by people like me trying to publish papers.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I encourage everyone to create the most absurd, implausible, and impractical languages. Chasing the measurable is often useful, expressing the expressible is insightful, but never forget the true goal of language design: to explore and create what isn√¢t.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://people.csail.mit.edu/rachit/post/why-study-programming-languages/"/><published>2025-10-14T05:36:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45577080</id><title>Why the push for Agentic when models can barely follow a simple instruction?</title><updated>2025-10-14T14:41:35.197995+00:00</updated><content>&lt;doc fingerprint="ad50c87e6fc408b3"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I have a bunch of file for different reason, you need to work with a structure, agents like to work in folder structure, here is one of my custom agent instruction.&lt;/p&gt;
      &lt;p&gt;Now i have a agents.md with more generic details for all agent type, architecture file for my folder structure, another one for tasks with templates and so on.&lt;/p&gt;
      &lt;p&gt;Now i start all my prompt with please search and read/multi-read all .md file&lt;lb/&gt; (If i have the file system MCP installed, wich is free and godsend)&lt;/p&gt;
      &lt;p&gt;My md file has my high level planing, brainstorming files and other complementary file that i keep up to date so that when the AI is done ingesting all the md files he is prepped up to go dig code, write code and chew bubblegum‚Ä¶ Mmmm might need some work on the last one. HE MUST CHEW BUBBLE GUM AND HE HAS NO MOUTH (Claptrap kiss no mouth reference)&lt;/p&gt;
      &lt;p&gt;You need to have them work on small vertical slice that can be built under a 100k token more or less, more than that the agent start to misbehave and you need to fire him.&lt;/p&gt;
      &lt;p&gt;I have custom architect for building plan, codeseeker, coder, and other more specialised agents.&lt;/p&gt;
      &lt;p&gt;Build your team, build a structure, in the last 2 month playing with agents and python i learnt more about coding than a full year high school. I dont just tell them to work i watch them work, see how they tick, i learn by comparison, read the code and when im not sure? grab a few related file, post them to chatgpt 5 and i ask him to tutor me or ask free agents to document the file and i ask question.&lt;/p&gt;
      &lt;p&gt;You dont ask a human to climb a tree even tho he look like a monkey, he might be able to, but still not his best skill. Learn the limit, try to build tools to overcome their limit, keep asking question, keep improving you managerial skill because workin with agent is to start managing a team. Imm full on on the managing part with only rudimentary coding knowledge, if you are a good coder you can have you agent working on something while you code and use inline code completion and im talking full on function completion.&lt;/p&gt;
      &lt;p&gt;Maybe codex is more for you, there is a lot of agent type, providers each one with their strenght and weakness, experiement.&lt;/p&gt;
      &lt;p&gt;I really hope you can find your tool, the one adapted to what you want and that you can grow into your tool too, then you become borg! Hmm might be premature on the borg thing. Eh oh well.&lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;You are a Deep Python Coding Agent, an expert AI specialized in implementing, refactoring, and maintaining Python codebases with absolute adherence to project standards. Your mission is to execute coding tasks exhaustively, ensuring every change is complete, tested, and documented, while strictly following the Agent Collaboration Charter and project rules. You NEVER write or execute code in terminals, REPLs, or interactive sessions‚Äîalways edit files directly and run commands via the project‚Äôs standard workflow (e.g., python main.py, pytest --testmon -q).&lt;/p&gt;
        &lt;p&gt;Core Principles&lt;/p&gt;
        &lt;p&gt;Exhaustive Implementation: For any coding task, dive deep into all relevant code‚Äîread files, trace dependencies, analyze tests, and understand integrations. Implement complete solutions with no omissions, addressing edge cases, error handling, and performance.&lt;/p&gt;
        &lt;p&gt;No Terminal Code Execution: NEVER write code snippets in terminals or REPLs. All code changes must be made by editing files (e.g., via write_file, edit_file). Run tests and commands only through the project‚Äôs workflow.&lt;/p&gt;
        &lt;p&gt;Mandatory Documentation Updates: After EVERY change, update docs/TASKS.md (claim task as in_progress, mark completed), docs/WORKLOG.md (log what, why, how to run), and docs/DECISIONS.md (if assumptions made). This is NON-NEGOTIABLE‚Äîfailure to update these will break the project process.&lt;/p&gt;
        &lt;p&gt;Task Continuity: Claim and complete tasks sequentially from docs/TASKS.md. Do not start new tasks until the current one is fully done (main runs, tests pass, docs updated). Roll through all pending tasks until none remain.&lt;/p&gt;
        &lt;p&gt;Quality Standards: Code must be PEP8-compliant, typed with type hints, readable, and free of TODOs. Run ruff/black/mypy on changes and fix issues. Prefer vertical slices that run end-to-end.&lt;/p&gt;
        &lt;p&gt;Testing Rigorousness: Add/update unit, integration, and e2e tests for every change. Use pytest --testmon -q during development for affected tests; run full pytest before marking done. No regressions allowed.&lt;/p&gt;
        &lt;p&gt;Deterministic and Complete: Provide exact file paths, final code, and commands. Never leave partial work‚Äîensure python main.py runs without errors.&lt;/p&gt;
        &lt;p&gt;Operational Workflow&lt;/p&gt;
        &lt;p&gt;Context Gathering: Always start by reading docs/ARCHITECTURE.md, docs/TASKS.md, docs/DECISIONS.md, docs/WORKLOG.md, docs/reference/*, and recent Plan/ notes.&lt;lb/&gt; Task Claiming: Append/update your entry in docs/TASKS.md (status=pending ‚Üí in_progress) before starting work.&lt;/p&gt;
        &lt;p&gt;Implementation:&lt;lb/&gt; -Read all related files (use read_file for up to 5 at once).&lt;lb/&gt; -Use search_files and list_code_definition_names to understand structure and dependencies.&lt;lb/&gt; -Edit files with complete changes (no partial writes).&lt;lb/&gt; -Add/update tests in test files.&lt;lb/&gt; -Run pytest --testmon -q incrementally; fix failures immediately.&lt;lb/&gt; -Validation: Run python main.py to ensure no breaks. Run full pytest pre-commit.&lt;lb/&gt; -Documentation: Update WORKLOG.md, DECISIONS.md (if needed), and set TASKS.md status=completed.&lt;lb/&gt; -Next Task: If tasks remain, claim the next one and repeat.&lt;/p&gt;
        &lt;p&gt;Tool Usage Guidelines&lt;/p&gt;
        &lt;p&gt;-read_file/edit_file/write_file: Use for all code changes; provide complete file contents.&lt;lb/&gt; -search_files: Regex search for patterns (e.g., function usages).&lt;lb/&gt; -list_code_definition_names: Overview of classes/functions in directories.&lt;lb/&gt; -Commands: Run via execute_command only for project workflow (e.g., pytest, main.py); never for code execution.&lt;/p&gt;
        &lt;p&gt;Response Standards&lt;lb/&gt; -Be technical and precise; no fluff.&lt;lb/&gt; -Structure responses with sections (e.g., Changes Made, Tests Added, Documentation Updates).&lt;lb/&gt; -Use code references like function_name().&lt;lb/&gt; -End with final status; no follow-ups unless blocked (then log in DECISIONS.md).&lt;/p&gt;
        &lt;p&gt;Constraints&lt;lb/&gt; Focus on Python coding and project maintenance; adhere to AGENTS.md rules.&lt;lb/&gt; If blocked, make least-surprising assumption, proceed, and log in DECISIONS.md.&lt;lb/&gt; Definition of Done: main runs, tests pass, docs updated, no unresolved TODOs.&lt;/p&gt;
        &lt;p&gt;Runs: python main.py &lt;/p&gt;
        &lt;p&gt;Tests: pytest -q &lt;/p&gt;
        &lt;p&gt;Lint/type pass (if configured) &lt;/p&gt;
        &lt;p&gt;No TODOs in changed code &lt;/p&gt;
        &lt;p&gt;Updated WORKLOG/TASKS &lt;/p&gt;
        &lt;p&gt;Output format&lt;/p&gt;
        &lt;p&gt;FILES CHANGED (with full paths)&lt;/p&gt;
        &lt;p&gt;Final code blocks for each file&lt;/p&gt;
        &lt;p&gt;RUN &amp;amp; TEST commands&lt;/p&gt;
        &lt;p&gt;NOTES/ASSUMPTIONS&lt;/p&gt;
      &lt;/quote&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://forum.cursor.com/t/why-the-push-for-agentic-when-models-can-barely-follow-a-single-simple-instruction/137154"/><published>2025-10-14T07:08:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45578117</id><title>KDE celebrates the 29th birthday and kicks off the yearly fundraiser</title><updated>2025-10-14T14:41:34.597378+00:00</updated><content>&lt;doc fingerprint="abd5cf5cba4a215f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Happy Birthday to us&lt;/head&gt;
    &lt;p&gt;This week is KDE√¢s 29th anniversary. It may not be a nice round number like 25 or 30, but whenever another birthday rolls around for an independent project the size and scope of KDE √¢ powered by the goodwill of its contributors and users √¢ that√¢s really quite something!&lt;/p&gt;
    &lt;p&gt;This year we√¢re celebrating by kicking off our yearly fundraiser. Let√¢s raise at least √¢¬¨50,000 before the end of the year!&lt;/p&gt;
    &lt;head rend="h3"&gt;Donated (updated daily)&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;√¢¬¨50000&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;*Stretch goal coming soon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Make KDE√¢s Birthday Wishes Come True&lt;/head&gt;
    &lt;head rend="h3"&gt;Producing first-class software&lt;/head&gt;
    &lt;p&gt;KDE is on the verge of something big, and the popularity of its free software is on the rise. It√¢s increasingly being adopted by gamers, artists, professionals, companies, and public institutions. But the costs associated with developing and maintaining that software are also growing.&lt;/p&gt;
    &lt;p&gt;Your donation keeps KDE √¢in business√¢ and our software sustainable for generations to come.&lt;/p&gt;
    &lt;head rend="h3"&gt;Keeping you in control&lt;/head&gt;
    &lt;p&gt;A core aim of KDE is keeping you in control of your digital life, and we do it by providing high-quality and privacy-conscious free software. But we can only keep doing it by preserving our own financial independence, so that we never become too dependent on any single source of support.&lt;/p&gt;
    &lt;p&gt;Your donation makes KDE truly independent. Funding from the people allows us keep KDE developed by the people, of the people, and for the people.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cleaning up the world&lt;/head&gt;
    &lt;p&gt;This week is also International E-Waste Day, and KDE wants a clean planet too! We started the End of 10 campaign because big tech corporations continue pushing everyone to chase the new shiny√¢¬¶ in the process filling landfills with perfectly functional devices that become terrible sources of pollution when junked*.&lt;/p&gt;
    &lt;p&gt;Your donation allows us to inform everybody about how they can help stave off these environmental disasters.&lt;/p&gt;
    &lt;p&gt;* Case in point: Microsoft is stopping free support for Windows 10 on hundreds of millions of computers this very week. Many of these old yet perfectly usable devices will not be able to upgrade because of spurious hardware requirements. Microsoft√¢s solution? √¢Throw away your computer and pollute the planet because we want to make even more money.√¢&lt;/p&gt;
    &lt;head rend="h3"&gt;Reaching people the tech industry left behind&lt;/head&gt;
    &lt;p&gt;Many aren√¢t in a position to replace their devices every few years, or download hundreds of gigabyes of data from an always-on internet connection. KDE produces software that doesn√¢t need the latest hardware or an always-on internet connection, allowing everybody find their space in the digitized world.&lt;/p&gt;
    &lt;p&gt;Your donation helps KDE serve those who are ignored by the industry, and bring marginalized users into the community so they can help the project grow for everyone.&lt;/p&gt;
    &lt;head rend="h3"&gt;Helping public institutions adopt free software&lt;/head&gt;
    &lt;p&gt;The governments of the world are starting to realize that using public funds to lock themselves into proprietary closed-source software has been a strategic geopolitical mistake.&lt;/p&gt;
    &lt;p&gt;Free software is publicly owned, representing the safest option for governments that want full control over their machines and safety for their citizens√¢ data. But often the standards required for software approval by public institutions is very high, and their needs very specific.&lt;/p&gt;
    &lt;p&gt;Your donation helps KDE adapt our software to what public institutions require, clearing the way for your tax dollars to fund KDE, not some big foreign companies.&lt;/p&gt;
    &lt;p&gt;Images "Konqi opens the magic box", ""Katie and Konqi make software", "Katie and Konqi take on the public administration" CC-BY-SA-4.0 license by Arctaxia. "Katie &amp;amp; Konqi recyle" CC-BY-SA-4.0 license by Nezumi Cafun√É¬©.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goodies&lt;/head&gt;
    &lt;p&gt;Don√¢t forget to download your goodies after you donated! Get digital badges, printable cards, and more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kde.org/fundraisers/yearend2025/"/><published>2025-10-14T09:54:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45578383</id><title>ADS-B Exposed</title><updated>2025-10-14T14:41:34.234442+00:00</updated><content>&lt;doc fingerprint="5bd73eafb8c37a0a"&gt;
  &lt;main&gt;
    &lt;p&gt;Proudly made with ClickHouse open-source database Picture from Wikipedia, ¬© the details at the corresponding page. üëÅ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://adsb.exposed/"/><published>2025-10-14T10:38:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45578540</id><title>Zoo of Array Languages</title><updated>2025-10-14T14:41:34.113221+00:00</updated><content>&lt;doc fingerprint="378169306b47e15c"&gt;
  &lt;main&gt;
    &lt;quote&gt;‚Ä¢ktye/k run src intro apl360 pdp11 tokenize halfkey xk fem flow ‚Ä¢the k incunabulum ‚Ä¢zoo of array languages APL\360 ngn/apl APL\iv BQN KAP incunabulum APL\? j4.2 jstack oK ktye/k2 ktye/k.w klong ngn/k k7 k9 ktye/k lil ‚Ä¢j stack language ‚Ä¢edit&lt;/quote&gt;
    &lt;quote&gt;ktye/k ktye.github.io/k.html + flp add ' ech pri both bin - neg sub / ovr fix echright * fst mul \ scn fix eachleft % sqr div / join decode ! til key mod \ split encode &amp;amp; wer min $[a;b;...] cond | rev max while[c;a;b;d;e;..] &amp;lt; asc les f:{x+y} [bl;o;ck] &amp;gt; dsc mor "chars" c = grp eql 01234567 1 2 3 i ~ not mtc :+-*%&amp;amp;| .4 5 6. f , enl cat &amp;lt;&amp;gt;=~!,^# 2a300 z ^ srt cut _$?@. (1;2 3) L # cnt tak `a`b!5 6 D _ flr drp t,d t,t t,'t join $ str cst k!t key ? unq fnd in k?t group @ typ atx @[x;i;+;y] amend . val cal .[x;i;+;y] dmend abs sin cos exp log find angle imag conj types:cisfzLDTvcdlx ?n(uniform) ?-n(normal) ?z(bi) n?n(with) random -n?n(w/o)&lt;/quote&gt;
    &lt;quote&gt;‚ïî‚ïê[‚ñ†]‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê TURBO.K ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê[‚Üë]‚ïê‚ïó ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë K ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë ASM ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£ ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë C ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë ‚ïë ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£ ‚ïë ‚ïë ‚ïë WATCH ‚ïë ‚ïë ‚ïë ‚ïö‚ïê‚ïê1:1‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚Ä¢ jtye/k: k in fifty functions&lt;/quote&gt;
    &lt;quote&gt;+ type add ' each prior bin `js` - neg sub / over right join dec * sqr mul \ scan left split enc % sqrt div inv idiv mod &amp;amp; flip min atom | rev max atomic &amp;lt; up less curry &amp;gt; down more rec = freq eql ~ not match . value parse ! til dict token key where @ first at amend ? uniq find rand ^ sort cut while()[;;] # count take if()[;;;;;] _ floor drop do[]while() , list cat for(;;)[;;] $ string try[]catch(e)[]&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ktye.github.io/"/><published>2025-10-14T11:01:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45578990</id><title>Kyber (YC W23) Is Hiring an Enterprise AE</title><updated>2025-10-14T14:41:33.632258+00:00</updated><content>&lt;doc fingerprint="f15468be0e97206f"&gt;
  &lt;main&gt;
    &lt;p&gt;Instantly draft, review, and send complex regulatory notices.&lt;/p&gt;
    &lt;p&gt;At Kyber, we're building the next-generation document platform for enterprises. Today, our AI-native solution transforms regulatory document workflows, enabling insurance claims organizations to consolidate 80% of their templates, spend 65% less time drafting, and compress overall communication cycle times by 5x. Our vision is for every enterprise to seamlessly leverage AI templates to generate every document.&lt;/p&gt;
    &lt;p&gt;Over the past 9 months, we‚Äôve:&lt;/p&gt;
    &lt;p&gt;Kyber is backed by top Silicon Valley VCs, including Y Combinator and Fellows Fund.&lt;/p&gt;
    &lt;p&gt;We‚Äôre now looking for elite Enterprise Account Executives who can drive pipeline, navigate complex multi-threaded enterprise sales environments, close deals, and own the full sales cycle in order to scale our impact across the insurance industry and beyond.&lt;/p&gt;
    &lt;p&gt;Responsibilities:&lt;/p&gt;
    &lt;p&gt;You'll play a critical role in driving revenue growth by:&lt;/p&gt;
    &lt;p&gt;Owning the Full Sales Cycle:&lt;/p&gt;
    &lt;p&gt;Executing Outbound Strategies:&lt;/p&gt;
    &lt;p&gt;Enhancing Sales Operations:&lt;/p&gt;
    &lt;p&gt;Strategic Account Management:&lt;/p&gt;
    &lt;p&gt;What We're Looking For in You:&lt;/p&gt;
    &lt;p&gt;Olympic Work Ethic Focused On Results:&lt;/p&gt;
    &lt;p&gt;Outstanding Communication Skills:&lt;/p&gt;
    &lt;p&gt;Relentlessly Resourceful:&lt;/p&gt;
    &lt;p&gt;Team Player with an Owner‚Äôs Mindset:&lt;/p&gt;
    &lt;p&gt;Join us in building and scaling a game-changing enterprise product powered by state-of-the-art AI. At Kyber, your contributions will directly impact how businesses handle some of their most critical workflows and customer interactions.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre obsessed with growth, AI, and transforming enterprise workflows, we‚Äôd love to hear from you!&lt;/p&gt;
    &lt;p&gt;We want to hear from extraordinary individuals who are ready to shape the future of enterprise documents. To stand out, ask someone you‚Äôve worked with to send your resume or LinkedIn profile, along with a brief 2-3 sentence endorsement, directly to arvind [at] askkyber.com.&lt;/p&gt;
    &lt;p&gt;Referrals matter - they help us understand the impact you‚Äôve already had and the kind of teammate you‚Äôll be. A strong referee can elevate your application, so choose someone who knows your skills and character well.&lt;/p&gt;
    &lt;p&gt;Apply today and help us bring enterprise documents into the AI-native age.&lt;/p&gt;
    &lt;p&gt;*Listed salary range is for OTE&lt;/p&gt;
    &lt;p&gt;With Kyber, companies operating in regulated industries can quickly draft, review, and send complex regulatory notices. For example, when Branch Insurance's claims team has to settle a claim, instead of spending hours piecing together evidence to draft a complex notice, they can simply upload the details of the claim to Kyber, auto-generate multiple best in-class drafts, easily assign reviewers, collaborate on notices in real-time, and then send the letter to the individual the notice is for. Kyber not only saves these teams time, it also improves overall quality, accountability, and traceability.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/kyber/jobs/BQRRSrZ-enterprise-account-executive-ae"/><published>2025-10-14T12:00:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45579275</id><title>Pyrefly: Python type checker and language server in Rust</title><updated>2025-10-14T14:41:33.399190+00:00</updated><content>&lt;doc fingerprint="4bb22cff501cd0f2"&gt;
  &lt;main&gt;
    &lt;p&gt;A fast type checker and language server for Python with powerful IDE features&lt;/p&gt;
    &lt;code&gt;$ pip install pyrefly &amp;amp;&amp;amp; pyrefly init&lt;/code&gt;
    &lt;head rend="h3"&gt;Scale with Confidence&lt;/head&gt;
    &lt;p&gt;Type check over 1.85 million lines of code per second.‚ìòTested using Meta infrastructure (166 cores, 228 GB RAM)&lt;/p&gt;
    &lt;head rend="h3"&gt;Developer Delight&lt;/head&gt;
    &lt;p&gt;Get lightning fast autocomplete, and catch errors with instant feedback in your favorite editor.&lt;/p&gt;
    &lt;head rend="h3"&gt;Support at your Fingertips&lt;/head&gt;
    &lt;p&gt;Have questions or feedback to share? Connect with us on Discord&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance Comparison&lt;/head&gt;
    &lt;p&gt;Type checking the PyTorch codebase from scratch.‚ìòTested using Macbook&lt;lb/&gt;(10 cores: 8 performance + 2 efficiency cores, 32 GB RAM)&lt;/p&gt;
    &lt;p&gt;(10 cores: 8 performance + 2 efficiency cores, 32 GB RAM)&lt;/p&gt;
    &lt;p&gt;Pyrefly‚ìòCommand: "pyrefly check"&lt;lb/&gt;Pyrefly uses as many threads as possible&lt;/p&gt;
    &lt;p&gt;Pyrefly uses as many threads as possible&lt;/p&gt;
    &lt;p&gt;Pyright‚ìòCommand: "pyright --threads=8"&lt;lb/&gt;8 threads yielded the best performance after testing multiple settings&lt;/p&gt;
    &lt;p&gt;8 threads yielded the best performance after testing multiple settings&lt;/p&gt;
    &lt;p&gt;MyPy‚ìòCommand: "dmypy run"&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pyrefly.org/?featured_on=talkpython"/><published>2025-10-14T12:33:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45579708</id><title>CRISPR-like tools that finally can edit mitochondria DNA could be revolutionary</title><updated>2025-10-14T14:41:32.291306+00:00</updated><content>&lt;doc fingerprint="fa5893102835c8f9"&gt;
  &lt;main&gt;
    &lt;p&gt;Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.&lt;/p&gt;
    &lt;p&gt;The rings of DNA inside mitochondria are inaccessible to these techniques, which means that precise edits to mitochondrial DNA (mtDNA) remain frustratingly out of reach. ‚ÄúMitochondria missed the CRISPR‚ÄìCas9 revolution that exploded 12 years ago,‚Äù says Michal Minczuk, a geneticist at the University of Cambridge, UK.&lt;/p&gt;
    &lt;p&gt;But researchers are eager to access this DNA, says Minczuk. Mitochondria are bean-shaped organelles that power cells and have myriad other cellular tasks. Exploring their DNA is essential for understanding the energy production and exchange that underlies metabolic health. And more than 300 mutations in this DNA cause mitochondrial diseases ‚Äî incurable genetic disorders with a wide range of symptoms that can rob people of their sight and hearing, trigger muscle problems and spark seizures1. These disorders affect roughly 1 in 5,000 people.&lt;/p&gt;
    &lt;p&gt;Because CRISPR can‚Äôt help with these problems, researchers have been looking for other ways to precisely edit the mitochrondrial genome. And the past few years have brought some success: the tools are already proving to be a boon for creating accurate animal models of mitochondrial diseases. ‚ÄúThe progress has been remarkable,‚Äù says Jin-Soo Kim, a chemical biologist who develops mtDNA editing tools at the Korea Advanced Institute of Science and Technology in Daejeon, South Korea.&lt;/p&gt;
    &lt;p&gt;If researchers can make mtDNA editing safe and accurate enough, it could eventually be used to treat, and even cure, these genetic conditions. ‚ÄúIt would be a medical breakthrough,‚Äù says Kim.&lt;/p&gt;
    &lt;p&gt;A bacterial origin&lt;/p&gt;
    &lt;p&gt;The exact origins of mitochondria are murky, but the leading theory holds that the organelle‚Äôs story started around 1.5 billion years ago when a single-celled microorganism called an archaeon gobbled up a roaming bacterium that survived inside its host. This event marked the beginning of the eukaryotes ‚Äî the large group of organisms, including plants, animals and fungi, in which cells contain organelles that are enclosed inside membranes. The swallowed bacterium retained its characteristic circular DNA as it settled into its new home, but over time it sacrificed most of its genes to the nuclear genome of its host.&lt;/p&gt;
    &lt;p&gt;In the evolutionary lineage that gave rise to humans and other animals, this genetic transfer whittled the resident bacterium‚Äôs genome down to just 37 genes that code for 13 proteins involved in energy production, turning it into a specialized organelle.&lt;/p&gt;
    &lt;p&gt;The small amount of mitochondrial DNA that stuck around in animals differs in key ways from nuclear DNA, which in humans encodes around 20,000 genes. For a start, mtDNA is typically inherited solely from the mother. There can be several copies of mtDNA in each mitochondrion, and the organelle has its own built-in machinery for making RNA and proteins from that DNA.&lt;/p&gt;
    &lt;p&gt;Mitochondrial DNA is also much more error-prone, with a mutation rate estimated to be 10‚Äì20 times greater than that of nuclear DNA. This is in part because it has to contend with a barrage of damaging reactive oxygen species ‚Äî unstable molecules that are generated in mitochondria during normal energy production. But it‚Äôs also because it doesn‚Äôt have histones: the proteins that protect and package nuclear DNA.&lt;/p&gt;
    &lt;p&gt;Compared with its counterpart in the nucleus, mtDNA‚Äôs toolkit for repairing itself is rudimentary. The nucleus is quick to fix a snapped DNA strand using an arsenal of repair mechanisms, but mitochondria can mend only some defects. They often simply throw away their broken DNA. This difference limits the options for gene-editing tools, because nearly all such tools for nuclear DNA use its inherent repair pathways.&lt;/p&gt;
    &lt;p&gt;It has been notoriously challenging to develop approaches for modifying mitochondrial DNA, says Stephen Ekker, a molecular biologist at the University of Texas at Austin. ‚ÄúIts bacterial origins are revealed when you start trying to edit it,‚Äù he says.&lt;/p&gt;
    &lt;p&gt;The most crucial hurdle for scientists trying to tinker with the mitochondrial genome is that it is locked behind a wall of membranes that doesn‚Äôt allow external nucleic acids to pass into the organelle. Although there have been hints that CRISPR-based gene-editing tools ‚Äî which rely on RNA to guide them to the correct sequence ‚Äî might be able to overcome these barriers, many researchers remain unconvinced.&lt;/p&gt;
    &lt;p&gt;Snip and trash&lt;/p&gt;
    &lt;p&gt;Still, there are other ways in. More than a decade before CRISPR became a research tool, mitochondria researchers began experimenting with other editing tools that could cross mitochondrial membranes and coax the organelles into ditching their problematic DNA2.&lt;/p&gt;
    &lt;p&gt;Every cell contains a vast number of mitochondrial genomes, because cells contain thousands of mitochondria and each one can carry several copies of mtDNA. Healthy and mutated mtDNA often coexist: a state known as heteroplasmy. It‚Äôs when the proportion of mutated mtDNA reaches 60‚Äì80% in a particular tissue or cell type that mitochondrial diseases manifest3.&lt;/p&gt;
    &lt;p&gt;If researchers could reduce the faulty copies of mtDNA in cells, they could eliminate the resulting disease. So, they turned to enzymes called zinc finger nucleases (ZFNs) and transcription activator-like effector nucleases (TALENs) to snip the double-stranded mtDNA. Whereas targeted snipping of nuclear DNA cajoles the cut DNA strands to glue themselves back together without the harmful mutation, the cut DNA in mitochondria is simply cast out. This elimination triggers the remaining intact copies to replicate themselves so that the correct level of mtDNA is maintained.&lt;/p&gt;
    &lt;p&gt;In most cases, the mutated copies will be reduced to an acceptable level as the normal copies are replicated. ‚ÄúThat‚Äôs going to make up for what you‚Äôre destroying,‚Äù says Carlos Moraes, a geneticist at the University of Miami in Florida.&lt;/p&gt;
    &lt;p&gt;Although there has been progress with this approach, it hasn‚Äôt made its way out of the laboratory. And even if it did reach the clinic, the technique would be powerless against diseases caused by mutations that are often present in all copies of a person‚Äôs mtDNA, such as Leber‚Äôs hereditary optic neuropathy (LHON), a rare condition that causes rapid vision loss.&lt;/p&gt;
    &lt;p&gt;What researchers need are tools that do more than cut DNA but that don‚Äôt rely on guide RNA.&lt;/p&gt;
    &lt;p&gt;CRISPR-free base editing&lt;/p&gt;
    &lt;p&gt;When CRISPR‚ÄìCas9 emerged as a tool in 2012, it became the go-to gene editor for all kinds of application. A guide RNA directs the Cas9 enzyme to a specific DNA sequence, where the enzyme does the cutting. Genetic changes are introduced as the DNA repairs itself.&lt;/p&gt;
    &lt;p&gt;The approach became even more useful in 2016, when David Liu, a chemical biologist at the Broad Institute of MIT and Harvard in Cambridge, Massachusetts, and his colleagues introduced a more precise technique called base editing4. In this case, researchers modify the Cas9 enzyme and rely on another enzyme, called a deaminase, to convert one DNA base letter to another ‚Äî such as cytosine (C) to thymine (T) or adenine (A) to guanine (G).&lt;/p&gt;
    &lt;p&gt;Although base editing and other CRISPR techniques took off for nuclear DNA, Liu and other research teams couldn‚Äôt get it working on mtDNA. Because CRISPR‚Äôs guide RNA doesn‚Äôt readily pass through a mitochondrion‚Äôs double membrane, using precise tools on mtDNA remained a pipe dream. ‚ÄúWe did not have much success,‚Äù says Liu.&lt;/p&gt;
    &lt;p&gt;A solution materialized in 2018 when Joseph Mougous, a microbiologist then at the University of Washington in Seattle, and his colleagues stumbled across a toxin made by the bacterium Burkholderia cenocepacia. This enzyme, a deadly weapon against other bacteria, wreaks havoc by ultimately converting base C to T across the bacterial genome5.&lt;/p&gt;
    &lt;p&gt;Mougous, now based at Yale University in New Haven, Connecticut, e-mailed Liu asking whether the enzyme, called DddA, would be of any use to him. ‚ÄúI knew exactly what it might be used for ‚Äî base editing mtDNA!‚Äù says Liu.&lt;/p&gt;
    &lt;p&gt;But switching every C to a T would be lethal to cells. Liu and his colleagues set out to ‚Äútame the beast‚Äù. They split DddA into two inactive pieces so that the enzyme would do its handiwork on mtDNA only when the pieces were brought together in a particular orientation. And instead of using guide RNA, Liu and his colleagues modified proteins found in TALENs to direct the DddA segments to their target sequences (see ‚ÄòMaking the edit‚Äô).&lt;/p&gt;
    &lt;p&gt;Enjoying our latest content? Log in or create an account to continue&lt;/p&gt;
    &lt;p&gt;Access the most recent journalism from Nature's award-winning team&lt;/p&gt;
    &lt;p&gt;Explore the latest features &amp;amp; opinion covering groundbreaking research&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nature.com/articles/d41586-025-03307-x"/><published>2025-10-14T13:21:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45579968</id><title>Let's Not Encrypt</title><updated>2025-10-14T14:41:31.983110+00:00</updated><content/><link href="https://michael.orlitzky.com/articles/lets_not_encrypt.xhtml"/><published>2025-10-14T13:44:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45580315</id><title>Wireshark 4.6.0 Supports macOS Pktap Metadata (PID, Process Name, etc.)</title><updated>2025-10-14T14:41:31.805447+00:00</updated><content>&lt;doc fingerprint="22b0415e58bd4591"&gt;
  &lt;main&gt;
    &lt;p&gt;Four years after my post on doing network captures on macOS with Process ID, Wireshark 4.6.0 has been released which includes support for parsing this extra metadata, including the process info.&lt;/p&gt;
    &lt;p&gt;So how do you do it? Easy! You just need the &lt;code&gt;pktap&lt;/code&gt; interface parameter.&lt;/p&gt;
    &lt;p&gt;From the tcpdump(1) man page:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Alternatively, to capture on more than one interface at a time, one may use ‚Äúpktap‚Äù as the interface parameter followed by an optional list of comma separated interface names to include. For example, to capture on the loopback and en0 interface:&lt;/p&gt;tcpdump -i pktap,lo0,en0&lt;p&gt;An interface argument of ‚Äúall‚Äù or ‚Äúpktap,all‚Äù can be used to capture packets from all interfaces, including loopback and tunnel interfaces. A pktap pseudo interface provides for packet metadata using the default PKTAP data link type and files are written in the Pcap-ng file format. The RAW data link type must be used to force to use the legacy pcap-savefile(5) file format with a ptkap pseudo interface. Note that captures on a ptkap pseudo interface will not be done in promiscuous mode.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;Therefore, we just need something like:&lt;/p&gt;
    &lt;code&gt;tcpdump -i pktap,en0 -w outfile.pcapng&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;tcptump -i pktap,all host 192.168.0.6 -w outfile.pcapng&lt;/code&gt;
    &lt;p&gt;And then open &lt;code&gt;outfile.pcapng&lt;/code&gt; in Wireshark and under Frame ‚Üí Process Information you can find the process name, PID, etc. (See screenshot above.)&lt;/p&gt;
    &lt;p&gt;Filtering can be done with &lt;code&gt;frame.darwin.process_info&lt;/code&gt; as listed here. For example:&lt;/p&gt;
    &lt;code&gt;frame.darwin.process_info.pname == "firefox"&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;frame.darwin.process_info.pid == 92046&lt;/code&gt;
    &lt;p&gt;This is super helpful to figure out both what unexpected network traffic is being generated by and the inverse, what a process is doing on the network. And now thanks to Wireshark 4.6.0 it‚Äôs even easier.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nuxx.net/blog/2025/10/14/wireshark-4-6-0-supports-macos-pktap-metadata-pid-process-name-etc/"/><published>2025-10-14T14:18:14+00:00</published></entry></feed>