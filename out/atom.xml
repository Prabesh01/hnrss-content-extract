<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-09T19:32:16.232418+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45862802</id><title>Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican</title><updated>2025-11-09T19:32:25.352817+00:00</updated><content>&lt;doc fingerprint="bc0fcf3649af53d8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican&lt;/head&gt;
    &lt;p&gt;9th November 2025&lt;/p&gt;
    &lt;p&gt;OpenAI partially released a new model yesterday called GPT-5-Codex-Mini, which they describe as "a more compact and cost-efficient version of GPT-5-Codex". It’s currently only available via their Codex CLI tool and VS Code extension, with proper API access "coming soon". I decided to use Codex to reverse engineer the Codex CLI tool and give me the ability to prompt the new model directly.&lt;/p&gt;
    &lt;p&gt;I made a video talking through my progress and demonstrating the final results.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a little bit cheeky&lt;/item&gt;
      &lt;item&gt;Codex CLI is written in Rust&lt;/item&gt;
      &lt;item&gt;Iterating on the code&lt;/item&gt;
      &lt;item&gt;Let’s draw some pelicans&lt;/item&gt;
      &lt;item&gt;Bonus: the --debug option&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;This is a little bit cheeky&lt;/head&gt;
    &lt;p&gt;OpenAI clearly don’t intend for people to access this model directly just yet. It’s available exclusively through Codex CLI which is a privileged application—it gets to access a special backend API endpoint that’s not publicly documented, and it uses a special authentication mechanism that bills usage directly to the user’s existing ChatGPT account.&lt;/p&gt;
    &lt;p&gt;I figured reverse-engineering that API directly would be somewhat impolite. But... Codex CLI is an open source project released under an Apache 2.0 license. How about upgrading that to let me run my own prompts through its existing API mechanisms instead?&lt;/p&gt;
    &lt;p&gt;This felt like a somewhat absurd loophole, and I couldn’t resist trying it out and seeing what happened.&lt;/p&gt;
    &lt;head rend="h4"&gt;Codex CLI is written in Rust&lt;/head&gt;
    &lt;p&gt;The openai/codex repository contains the source code for the Codex CLI tool, which OpenAI rewrote in Rust just a few months ago.&lt;/p&gt;
    &lt;p&gt;I don’t know much Rust at all.&lt;/p&gt;
    &lt;p&gt;I made my own clone on GitHub and checked it out locally:&lt;/p&gt;
    &lt;code&gt;git clone git@github.com:simonw/codex
cd codex&lt;/code&gt;
    &lt;p&gt;Then I fired up Codex itself (in dangerous mode, because I like living dangerously):&lt;/p&gt;
    &lt;code&gt;codex --dangerously-bypass-approvals-and-sandbox&lt;/code&gt;
    &lt;p&gt;And ran this prompt:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Figure out how to build the rust version of this tool and then build it&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This worked. It churned away for a bit and figured out how to build itself. This is a useful starting point for a project like this—in figuring out the compile step the coding agent gets seeded with a little bit of relevant information about the project, and if it can compile that means it can later partially test the code it is writing while it works.&lt;/p&gt;
    &lt;p&gt;Once the compile had succeeded I fed it the design for the new feature I wanted:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a new sub-command to the Rust tool called “codex prompt”&lt;/p&gt;
      &lt;p&gt;codex prompt “prompt goes here”—this runs the given prompt directly against the OpenAI API that Codex uses, with the same code path and authentication credentials as the rest of Codex.&lt;/p&gt;
      &lt;p&gt;codex prompt -m &amp;lt;model_name&amp;gt; “prompt goes here”—same again but lets you set the model&lt;/p&gt;
      &lt;p&gt;codex prompt “prompt goes here” -s/--system “system prompt goes here”—runs with a custom system/developer message&lt;/p&gt;
      &lt;p&gt;codex prompt --models—this lists all available models that can be used with the “codex prompt” command&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My design for this new sub-command is lifted directly from my own llm command.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iterating on the code&lt;/head&gt;
    &lt;p&gt;Codex got to work. I’ve shared the full transcript here (using the tool I described here), but this TODO list it made itself is a useful summary of what it decided to do:&lt;/p&gt;
    &lt;code&gt;Updated Plan
└ ✔ Inspect CLI structure and relevant core utilities for sending prompts and listing models
  ✔ Implement new `codex prompt` subcommand (CLI plumbing + command handler)
  ✔ Format, lint, and test (`just fmt`, `just fix -p codex-cli`, `cargo test -p codex-cli`)
&lt;/code&gt;
    &lt;p&gt;I like that it figured out the justfile in the repo and decided to use it to run formatting and linting commands without me needing to tell it to. (Update: it turns out that was dictated by the AGENTS.md file.)&lt;/p&gt;
    &lt;p&gt;I tried running the first version of the code it wrote like this:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt 'Generate an SVG of a pelican riding a bicycle' -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;... and it didn’t quite work. I got this:&lt;/p&gt;
    &lt;code&gt;(reasoning summary) **Seeking
(reasoning summary)  instructions
(reasoning summary)  and
(reasoning summary)  sandbox
(reasoning summary)  info
(reasoning summary) **
(reasoning summary) **Dec
(reasoning summary) iding
(reasoning summary)  on
(reasoning summary)  SVG
(reasoning summary)  creation
(reasoning summary)  approach
(reasoning summary) **
(reasoning summary) **Checking
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
(reasoning summary) **Preparing
(reasoning summary)  to
(reasoning summary)  check
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
I�m ready to help�what would you like me to do next?I�m ready to help�what would you like me to do next?
Token usage: total=2459 input=2374 cached_input=0 output=85 reasoning_output=64
&lt;/code&gt;
    &lt;p&gt;Note that it DID think about SVG creation, but then decided it should look at the current directory. This isn’t what I want—it appeared to be running in Codex’s normal mode with a system prompt telling it to edit files on disk. I wanted it to respond to the prompt without acting as if it had a full workspace available to it.&lt;/p&gt;
    &lt;p&gt;I prompted it again, pasting in the broken output:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;this did not seem to work—here is what happened—note that the reasoning summary comes out on a lot of lines when I would rather it streams out to stderr on the same line (flushing constantly)—and then despite the reasoning summary thinking about pelican on SVG it did not actually act on that and display the result, which is very surprising. [pasted content]&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It churned for a bit more, but from the output it looked like it was still trying to include Codex-specific tools and workspace information. So I said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that this new ’codex prompt’ command should NOT be able to execute any tools at all, and should not have to think about the workspace or sandbox—it should send a single prompt with no tools and then stream and display a response and then stop.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This got me a new build, but when I ran it:&lt;/p&gt;
    &lt;code&gt;Error: unexpected status 400 Bad Request: {"detail":"Instructions are not valid"}
&lt;/code&gt;
    &lt;p&gt;My guess is that OpenAI’s custom backend API for Codex doesn’t like it if you attempt to call it without passing in the expected instructions. Fair enough!&lt;/p&gt;
    &lt;p&gt;Rather than paste that error in I got Codex to try the command itself, so it could see the error:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You try running this and see what happens: ./target/debug/codex prompt ’Generate an SVG of a pelican riding a bicycle’&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Codex switched back to the default instructions. From its reply:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;cli/src/prompt_cmd.rs#L1-L320&lt;/code&gt;now forces a tool-free request: we keep the workspace defaults, inject a lightweight system/developer message (“don’t run tools”), disable apply_patch/web search via config overrides, and build the outbound prompt as just that system span plus the user text.&lt;/quote&gt;
    &lt;p&gt;I guess that will have to do. I asked for one more feature:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a --debug option to the codex prompt command which causes the full JSON request and response to be printed to stderr, plus the URL that is being accessed and the HTTP verb&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;... and we’re ready to try this thing out!&lt;/p&gt;
    &lt;p&gt;Notably I haven’t written a single line of Rust myself here and paid almost no attention to what it was actually doing. My main contribution was to run the binary every now and then to see if it was doing what I needed yet.&lt;/p&gt;
    &lt;p&gt;I’ve pushed the working code to a prompt-subcommand branch in my repo if you want to take a look and see how it all works.&lt;/p&gt;
    &lt;head rend="h4"&gt;Let’s draw some pelicans&lt;/head&gt;
    &lt;p&gt;With the final version of the code built, I drew some pelicans. Here’s the full terminal transcript, but here are some highlights.&lt;/p&gt;
    &lt;p&gt;This is with the default GPT-5-Codex model:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle"&lt;/code&gt;
    &lt;p&gt;I pasted it into my tools.simonwillison.net/svg-render tool and got the following:&lt;/p&gt;
    &lt;p&gt;I ran it again for GPT-5:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5&lt;/code&gt;
    &lt;p&gt;And now the moment of truth... GPT-5 Codex Mini!&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;I don’t think I’ll be adding that one to my SVG drawing toolkit any time soon.&lt;/p&gt;
    &lt;head rend="h4"&gt;Bonus: the --debug option&lt;/head&gt;
    &lt;p&gt;I had Codex add a &lt;code&gt;--debug&lt;/code&gt; option to help me see exactly what was going on.&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt -m gpt-5-codex-mini "Generate an SVG of a pelican riding a bicycle" --debug&lt;/code&gt;
    &lt;p&gt;The output starts like this:&lt;/p&gt;
    &lt;code&gt;[codex prompt debug] POST https://chatgpt.com/backend-api/codex/responses
[codex prompt debug] Request JSON:
&lt;/code&gt;
    &lt;code&gt;{
  "model": "gpt-5-codex-mini",
  "instructions": "You are Codex, based on GPT-5. You are running as a coding agent ...",
  "input": [
    {
      "type": "message",
      "role": "developer",
      "content": [
        {
          "type": "input_text",
          "text": "You are a helpful assistant. Respond directly to the user request without running tools or shell commands."
        }
      ]
    },
    {
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "Generate an SVG of a pelican riding a bicycle"
        }
      ]
    }
  ],
  "tools": [],
  "tool_choice": "auto",
  "parallel_tool_calls": false,
  "reasoning": {
    "summary": "auto"
  },
  "store": false,
  "stream": true,
  "include": [
    "reasoning.encrypted_content"
  ],
  "prompt_cache_key": "019a66bf-3e2c-7412-b05e-db9b90bbad6e"
}&lt;/code&gt;
    &lt;p&gt;This reveals that OpenAI’s private API endpoint for Codex CLI is &lt;code&gt;https://chatgpt.com/backend-api/codex/responses&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Also interesting is how the &lt;code&gt;"instructions"&lt;/code&gt; key (truncated above, full copy here) contains the default instructions, without which the API appears not to work—but it also shows that you can send a message with &lt;code&gt;role="developer"&lt;/code&gt; in advance of your user prompt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/"/><published>2025-11-09T04:02:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45863024</id><title>Forth – Is it still relevant?</title><updated>2025-11-09T19:32:24.691722+00:00</updated><content>&lt;doc fingerprint="be229b0a630aca40"&gt;
  &lt;main&gt;
    &lt;p&gt;With all the advantages, it is unfortunate that Forth lost out to C language over the years and have been reduced to a niche. Per ChatGPT: due to C's broader appeal, standardization, and support ecosystem likely contributed to its greater adoption and use in mainstream computing.&lt;/p&gt;
    &lt;p&gt;So, the question is, how to encourage today's world of C programmers to take a look at Forth. How do we convince them that Forth can be 10 times more productive? Well, we do know that by keep saying how elegant Forth is or even bashing how bad C can be probably won't get us anywhere.&lt;/p&gt;
    &lt;p&gt;Bill Muench created eForth for simplicity and educational purpose. Dr. Ting, ported to many processors, described Forth in his well-written eForth genesis and overview. I like the idea and decided to pick it up.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;100% C/C++ with multi-platform support. Though classic implementation of primitives in assembly language and scripted high-level words gave the power to Forth, it also became the hurtle for newbies. Because they have to learn the assembly and Forth syntax before peeking into the internal beauty of Forth.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary is just an array. It's remodeled from linear memory linked-list to an array (or a vector in C++'s term) of words.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;To search for a word, simply scan the name string of dictionary entries. So, to define a new word during compile time is just to append those found word pointers to the its parameter array one by one.&lt;/item&gt;
          &lt;item&gt;To execute become just a walk of the word pointers in the array. This is our inner interpreter.&lt;/item&gt;
          &lt;item&gt;Hashtables might go even faster but we'll try that later.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data and Return Stacks are also arrays. With push, pop and [] methods to clarify intentions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Parameter fields are all arrays. Why not!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No vocabulary, or meta-compilation. Except CREATE..DOES&amp;gt;, and POSTPONE, these black-belt skills of Forth greatness are dropped to keep the focus on core concepts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multi-threading and message passing are available From v5.0 and on, multi-core platform can utilize Forth VMs running in parallel. see the multi-threading section below for details&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A thread pool is built-in. Size is defaults to number of cores.&lt;/item&gt;
          &lt;item&gt;Message Passing send/recv with pthread mutex waiting.&lt;/item&gt;
          &lt;item&gt;IO and memory update can be synchronized with lock/unlock.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are fluent in C/C++ and in the process of building your own Forth, skipping the verbage, the easiest path to gain understanding of how things work together is to download release v4.2 and work from there.&lt;/p&gt;
    &lt;p&gt;In the release, a heavily commented ceforth.cpp, the companion ceforth.h, and a config.h. Altogether, about 800 lines. Check them out!&lt;/p&gt;
    &lt;p&gt;The core of current implementation of eForth is the dictionary composed of an array of Code objects that represent each of Forth words.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Code - the heart of eForth, depends on the constructor called, the following fields are populated accordingly&lt;/p&gt;
        &lt;quote&gt;+ name - a string that holds primitive word's name, i.e. NFA in classic FORTH, can also holds branching mnemonic for compound words which classic FORTH keeps on parameter memory + xt - pointer to a lambda function for primitive words i.e. XT in classic FORTH + pf, p1, p2 - parameter arrays of Code objects for compound words, i.e. PFA in classic FORTH + q - holds the literal value which classic FORTH keep on parameter memory&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lit, Var, Str, Bran, Tmp - the polymorphic classes extended from the base class Code which serve the functionalities of primitive words of classic Forth.&lt;/p&gt;
        &lt;quote&gt;+ Lit - numeric literals + Var - variable or constant + Str - string for dostr or dotstr + Bran - Branching opcode + Tmp - temp storage for branching word&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary - an array of Code objects&lt;/p&gt;
        &lt;quote&gt;+ build-it words - constructed by initializer_list at start up, before main is called, degenerated lambdas become function pointers stored in Code.xt dict[0].xt ------&amp;gt; lambda[0] &amp;lt;== These function pointers can be converted dict[1].xt ------&amp;gt; lambda[1] into indices to a jump table ... which is exactly what WASM does dict[N-1].xt ----&amp;gt; lambda[N-1] &amp;lt;== N is number of built-in words + colon (user defined) words - collection of word pointers during compile time dict[N].pf = [ *Code, *Code, ... ] &amp;lt;== These are called the 'threads' in Forth's term dict[N+1].pf = [ *Code, *Code, ... ] So, instead of subroutine threading ... this is 'object' threading. dict[-1].pf = [ *Code, *Code, ... ] It can be further compacted into token (i.e. dict index) threading if desired&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Inner Interpreter - Code.exec() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;if (xt) { xt(this); return; } // run primitive word for (Code *w : pf) { // run colon word try { w-&amp;gt;exec(); } // execute recursively catch (...) { break; } // handle exception if any }&lt;/quote&gt;
        &lt;p&gt;i.e. either we call a built-in word's lambda function or walk the Code.pf array recursively like a depth-first tree search.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Outer Interpreter - forth_core() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;Code *c = find(idiom); // search dictionary if (c) { // word found? if (compile &amp;amp;&amp;amp; !c-&amp;gt;immd) // are we compiling a new word? dict[-1]-&amp;gt;add(c); // then append found code to it else c-&amp;gt;exec(); // or, execute the code return; } DU n = parse_number(idiom); // word not found, try as a number if (compile) // are we compiling a new word? dict[-1]-&amp;gt;add(new Lit(n)); // append numeric literal to it else PUSH(n); // push onto data stack&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the array implementation, the first difference is in array variable read/write.&lt;/p&gt;
    &lt;code&gt;&amp;gt; create narr 10 cells allot
&amp;gt; see narr
&amp;gt; : narr
    0 0 0 0 0 0 0 0 0 0 ;
\       ^----------------- narr 2 cells +&lt;/code&gt;
    &lt;p&gt;While traditional Forths uses &lt;code&gt;narr 2 cells +&lt;/code&gt; to get the memory address of &lt;code&gt;narr[2]&lt;/code&gt;, eforth &lt;code&gt;narr&lt;/code&gt; returns its index (or defining order) in the dictionary. So, &lt;code&gt;narr 2 cells +&lt;/code&gt; will actually get you the index of the second word defined after &lt;code&gt;narr&lt;/code&gt;. You'll be storing the value into that word's empty qf field.
To access the nth element of &lt;code&gt;narr&lt;/code&gt;, use &lt;code&gt;th&lt;/code&gt; instead&lt;/p&gt;
    &lt;code&gt;&amp;gt; : fill-arr
    10 0 do
      i 2* narr i th !
    loop ;
&amp;gt; fill-arr
&amp;gt; see narr
&amp;gt; : narr
    0 2 4 6 8 10 12 14 16 18 ;&lt;/code&gt;
    &lt;p&gt;With arrays, the doors are open. Dynamically expanding variables as well as storing objects instead of just integers. Parameter fields can be filled in compile time or changed on the fly in runtime i.e. self-morphing code. These can be the "scary" features for Forths to come.&lt;/p&gt;
    &lt;p&gt;Most classic Forth systems are build with a few low-level primitives in assembly language and bootstrap the high-level words in Forth itself. Over the years, Dr. Ting have implemented many Forth systems using the same model. See here for the detailed list. However, he eventually stated that it was silly trying to explain Forth in Forth to new comers. There are just not many people know Forth, period.&lt;/p&gt;
    &lt;p&gt;Utilizing modern OS and tool chains, a new generation of Forths implemented in just a few hundreds lines of C code can help someone who did not know Forth to gain the core understanding much quickly. He called the insight Forth without Forth.&lt;/p&gt;
    &lt;p&gt;In 2021-07-04, I got in touched with Dr. Ting mentioning that he taught at the university when I attended. He, as the usual kind and generous him, included me in his last projects all the way till his passing. I am honored that he considered me one of the frogs living in the bottom of the deep well with him looking up to the small opening of the sky together. With cross-platform portability as our guild-line, we built ooeForth in Java, jeForth in Javascript, wineForth for Windows, and esp32forth for ESP micro-controllers using the same code-base. With his last breath in the hospital, he attempted to build it onto an FPGA using Verilog. see ceForth_403 and eJsv32 for details.&lt;/p&gt;
    &lt;p&gt;We hope it can serve as a stepping stone for learning Forth to even building their own, one day.&lt;/p&gt;
    &lt;code&gt;    $ git clone https://github.com/chochain/eforth to your local machine
    $ cd eforth&lt;/code&gt;
    &lt;p&gt;There are two major versions current. eForth. v4 is single-threaded only and v5 default single-threaded but also supports multi-threaded.&lt;/p&gt;
    &lt;p&gt;Checkout the version you are interested in.&lt;/p&gt;
    &lt;code&gt;    $ git checkout v42           # for version 4.2 (latest), or
    $ git checkout master        # for version 5 and on&lt;/code&gt;
    &lt;p&gt;To enable multi-threading, of v5, update the followings in ~/src/config.h&lt;/p&gt;
    &lt;code&gt;    #define DO_MULTITASK   1
    #define E4_VM_POOL_SZ  8&lt;/code&gt;
    &lt;code&gt;    $ make
    $ ./tests/eforth             # to bring up the Forth interpreter&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words⏎               \ to see available Forth words
    &amp;gt; 1 2 +⏎               \ see Forth in action
    &amp;gt; bye⏎  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Once you get pass the above, try the lessons by Dr. Ting.
&lt;/code&gt;
    &lt;code&gt;    $ ./tests/eforth &amp;lt; ./tests/demo.fs&lt;/code&gt;
    &lt;p&gt;Pretty amazing stuffs! To grasp how they were done, study the individual files (*.fs) under ~/tests/demo.&lt;/p&gt;
    &lt;p&gt;Note: MacOS added, thanks to Kristopher Johnson's work.&lt;/p&gt;
    &lt;p&gt;I haven't develop anything useful on Windows for a long time. Just bearly got this compiled on an 2007 Windows7 box. So, take it with a grain of salt. I'm hoping someone can make it more streamlined.&lt;/p&gt;
    &lt;code&gt;* install and run Visual Studio on your box
* under the root directory, open the solution file eforth.sln (which points to project platform/eforth.vcxproj)
* Menu bar -&amp;gt; Build -&amp;gt; Build Solution   (default to Debug/64-bit)
* in a Command window, find and run eforth.exe under tests sub-directory
&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words⏎               \ to see available Forth words
    &amp;gt; 1 2 +⏎               \ see Forth in action
    &amp;gt; bye⏎  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Note: Windows multi-threading seems to work but 2x slower. 
    * I only have a 2-core Win box. Do let me know if it goes further. 8-)
    * No CPU affinity. The code might need to be namespaced to avoid conflicts with Windows include files.
&lt;/code&gt;
    &lt;code&gt;* ensure you have Emscripten (WASM compiler) installed and configured
* or, alternatively, you can utilize docker image from emscripten/emsdk
&lt;/code&gt;
    &lt;code&gt;    $ make wasm
    $ python3 tests/cors.py        # supports COOP&lt;/code&gt;
    &lt;code&gt;* from your browser, open http://localhost:8000/tests/eforth.html
&lt;/code&gt;
    &lt;p&gt;Note: For multi-threading to work, browser needs to receive Cross-Origin policies here for detail in the response header. A Python script ~/tests/cors.py is provided to solve the issue. The same needed to be provided if you use other web server.&lt;/p&gt;
    &lt;code&gt;* ensure your Arduino IDE have ESP32 libraries installed
* update ESP32 compiler.optimization flags in ~/hardware/platform.txt to -O3 (default -Os)
* open eforth.ino with Arduino IDE
* inside eforth.ino, modify WIFI_SSID and WIFI_PASS to point to your router
* open Arduino Serial Monitor, set baud 115200 and linefeed to 'Both NL &amp;amp; CR'
* compile and load
* if successful, web server IP address/port and eForth prompt shown in Serial Monitor
* from your browser, enter the IP address to access the ESP32 web server
&lt;/code&gt;
    &lt;p&gt;Note: Most ESP32 are dual-core. However core0 is dedicated to WiFi and FreeRTOS house keeping. Forth tasks will be tied to core1 only. So, multi-threading is possible but no performance gain. Actually, singled-threaded v4.2 does a bit better.&lt;/p&gt;
    &lt;p&gt;Forth has been supporting multi-tasking since the 70's. They are single-CPU round-robin/time-slicing systems mostly. Modern system has multiple cores and Forth can certainly take advantage of them. However, unlike most of the matured Forth word sets, multi-threading/processing words are yet to be standardized and there are many ways to do it.&lt;/p&gt;
    &lt;code&gt;* each VM has it's own private ss, rs, tos, ip, and state
* multi-threading, instead of multi-processing, with shared dictionary and parameter memory blocks.
* pthread.h is used. It is a common POSIXish library supported by most platforms. I have only tried the handful on hands, your mileage may vary.
* Message Passing interface for inter-task communication.
&lt;/code&gt;
    &lt;code&gt;1. We have the VM array, sized by E4_VM_POOL_SZ, which defines the max tasks you want to have. Typically, anything more than your CPU core count does not help completing the job faster.
2. Each VM is associated with a thread, i.e. our thread-pool.
3. The event_queue, a C++ queue takes in "ready to run" tasks.
4. Lastly, event_loop picks up "ready to run" tasks and kicks start them one by one.

The following VM states manage the life-cycle of a task

* QUERY - interpreter mode - only the main thread can do this
* HOLD  - ready to execute, or waiting for message to arrive
* NEST  - in execution
* STOP  - free for next task
&lt;/code&gt;
    &lt;p&gt;Before we go too far, make sure the following are updated before your build&lt;/p&gt;
    &lt;code&gt;* pthread.h is installed. 
* DO_MULTITASK, E4_VM_POOL_SZ are updated in ~/src/config.h
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;word&lt;/cell&gt;
        &lt;cell role="head"&gt;stack&lt;/cell&gt;
        &lt;cell role="head"&gt;desc&lt;/cell&gt;
        &lt;cell role="head"&gt;state&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;task&lt;/cell&gt;
        &lt;cell&gt;( xt -- t )&lt;/cell&gt;
        &lt;cell&gt;create a task (tid is index to thread pool entry)&lt;p&gt;a free VM from pool is chosen for the task&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;STOP=&amp;gt;HOLD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;rank&lt;/cell&gt;
        &lt;cell&gt;( -- t )&lt;/cell&gt;
        &lt;cell&gt;fetch current task id&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;start&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;start a task&lt;p&gt;The VM is added to event_queue and kick started when picked up by event_loop&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;join&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;wait until the given task is completed&lt;/cell&gt;
        &lt;cell&gt;NEST=&amp;gt;STOP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;lock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;lock (semaphore) IO or memory&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;unlock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;release IO or memory lock&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;send&lt;/cell&gt;
        &lt;cell&gt;( v1 v2 .. vn n t -- )&lt;/cell&gt;
        &lt;cell&gt;send n elements on current stack to designated task's stack (use stack as message queue)&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receiver HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;recv&lt;/cell&gt;
        &lt;cell&gt;( -- v1 v2 .. vn )&lt;/cell&gt;
        &lt;cell&gt;wait, until message to arrive&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;pull&lt;/cell&gt;
        &lt;cell&gt;( n t -- )&lt;/cell&gt;
        &lt;cell&gt;forced fetch stack elements from a completed task&lt;/cell&gt;
        &lt;cell&gt;current NEST&lt;p&gt;target STOP&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;bcast&lt;/cell&gt;
        &lt;cell&gt;( n -- )&lt;/cell&gt;
        &lt;cell&gt;not implemented yet, TODO&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receivers HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;clock&lt;/cell&gt;
        &lt;cell&gt;( -- n )&lt;/cell&gt;
        &lt;cell&gt;fetch microsecond since Epoch, useful for timing&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;    &amp;gt; : once 999999 for rank drop next ;            \ 1M cycles
    &amp;gt; : run clock negate once clock + . ." ms" cr ; \ benchmark
    &amp;gt; ' run constant xt                             \ keep the xt
    &amp;gt; : jobs 1- for xt task start next ;            \ tasks in parallel
    &amp;gt; 4 jobs&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T2 [05.1]&amp;gt;&amp;gt; started on T4 [04.1]&amp;gt;&amp;gt; started on T6 [07.1]&amp;gt;&amp;gt; started on T0 18 ms [06.3]&amp;gt;&amp;gt; finished on T2 18 ms [05.3]&amp;gt;&amp;gt; finished on T4 18 ms [04.3]&amp;gt;&amp;gt; finished on T6 18 ms [07.3]&amp;gt;&amp;gt; finished on T0&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; 0 constant pp                           \ producer task id
    &amp;gt; 0 constant cc                           \ consumer task id
    &amp;gt; : sndr
        1000 ms                               \ delay to simulate some processing
        1 2 3 4 4 cc send                     \ send 4 items from stack
        lock ." sent " cr unlock ;            \ locked IO before write
    &amp;gt; : rcvr
        recv                                  \ wait for sender
        + + +                                 \ sum received 4 items
        lock ." sum=" . cr unlock ;           \ locked IO before write
    &amp;gt; ' sndr task to pp
    &amp;gt; ' rcvr task to cc
    &amp;gt; cc start                                \ start receiver task
    &amp;gt; pp start                                \ start sender task
    &amp;gt; pp join cc join                         \ wait for completion&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T1 [06.1]&amp;gt;&amp;gt; waiting [07.1]&amp;gt;&amp;gt; started on T2 [06.1]&amp;gt;&amp;gt; sending 4 items to VM6.1 sent [07.3]&amp;gt;&amp;gt; finished on T2 [00.3]&amp;gt;&amp;gt; VM7 joint [06.3]&amp;gt;&amp;gt; received =&amp;gt; state=3 sum=10 [06.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM6 joint&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; : sum 0 1000000 for i + next ;          \ add 0 to 1M
    &amp;gt; ' sum task constant tt                  \ create the task
    &amp;gt; tt start tt join                        \ run and wait for completion
    &amp;gt; 1 tt pull ." total=" .                  \ pull the sum&lt;/code&gt;
    &lt;quote&gt;[00.3]&amp;gt;&amp;gt; joining VM7 [07.1]&amp;gt;&amp;gt; started on T1 [07.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM7 joint pulled 1 items from VM7.0 total= 1784293664 -1 -&amp;gt; ok&lt;/quote&gt;
    &lt;code&gt;+ ~/src       - multi-threaded, dynamic vector-based, object threading
+ ~/platform  - platform specific code for C++, ESP32, Windows, and WASM
+ ~/orig      - archive from Dr. Ting and my past works
+    /33b     - refactored ceForth_33, separate ASM from VM (used in eForth1 for Adruino UNO)
+    /ting    - ceForth source codes collaborated with Dr. Ting
+    /esp32   - esp32forth source codes collaborated with Dr. Ting
+    /40x     - my experiments, refactor _40 into vector-based subroutine-threaded, with 16-bit offset
+    /50x     - my experiments, add multi-threading to _40
&lt;/code&gt;
    &lt;code&gt;+ 4452ms: ~/orig/ting/ceforth_36b, linear memory, 32-bit, token threading
+ 1450ms: ~/orig/ting/ceForth_403, dict/pf array-based, subroutine threading
+ 1050ms: ~/orig/40x/ceforth, subroutine indirect threading, with 16-bit offset
+  890ms: ~/orig/40x/ceforth, inner interpreter with cached xt 16-bit offsets
+  780ms: ~/src/eforth, v4.2 dynamic vector, object threading (gcc -O2)
&lt;/code&gt;
    &lt;code&gt;+  812ms: v5.0, multi-threaded (gcc -O2)
+  732ms: v5.0, multi-threaded (gcc -O3)
+  731ms: v5.0, single-threaded (gcc -O3) =&amp;gt; not much overhead with MT
&lt;/code&gt;
    &lt;code&gt;+  843ms: v5.0 50x32 branch (gcc -O2)
   * program spent &amp;gt;50% in nest() - gprof/valgrind/cachegrind
   * 16-bit IU fetch + dispatch: Ir/Dr = 2.3M/0.5M (810ms)
   * 32-bit Param hardcopy     : Ir/Dr = 3.8M/1.1M (930ms)
   * 32-bit Param reference    : Ir/Dr = 3.1M/0.8M (843ms) &amp;lt;== 32-bit best
   * 32-bit Param pointer      : Ir/Dr = 3.2M/0.9M (899ms)
+  873ms: v5.0 50x32 branch (gcc -O3)
   * slower, due to inline find() into forth_core() which crowded cache.
     Note: this doesn't seem to bother WASM.
&lt;/code&gt;
    &lt;code&gt;+ 1440ms: Dr. Ting's ~/esp32forth/orig/esp32forth_82
+ 1045ms: ~/orig/esp32/ceforth802, array-based, token threading
+  990ms: ~/orig/40x/ceforth, linear-memory, subroutine threading, with 16-bit offset
+  930ms: ~/orig/40x/ceforth, inner interpreter with cached xt offsets
+  644ms: ~/src/eforth, v4.2 dynamic vector, token threading
+  534ms: ~/src/eforth, v5.0 multi-threaded, dynamic vector, object threading (with gcc -O3)
&lt;/code&gt;
    &lt;p&gt;What is the performance difference?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Code *dict[] - where words are dynamically allocated as a collection of pointers, or&lt;/item&gt;
      &lt;item&gt;Code dict[] - where words are statically created as an array of objects.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I have created a git branch 'static' to compare to the 'master. The static version is about 10% slower on 64-bit machine and about 5% slower on 32-bits. This hasn't been carefully analyzed but my guess is because Code is big at 144-bytes on 64-bit. They might get pushed off L1 cache too often.&lt;/p&gt;
    &lt;p&gt;An array of lambdas vs the classic switch statement, i.e.&lt;/p&gt;
    &lt;code&gt;const Code dict[] {               ///&amp;lt; Forth dictionary
    CODE("+",      TOS += SS.pop()),
    CODE("-",      TOS =  SS.pop() - TOS),
    CODE("*",      TOS *= SS.pop()),
    CODE("/",      TOS =  SS.pop() / TOS),
    ...
vs
    switch(opcode) {             ///&amp;lt; big switch statement
    case PLUS:     TOS += SS.pop();      break;
    case MINUS:    TOS = SS.pop() - TOS; break;
    case MULTIPLY: TOS *= SS.pop();      break;
    case DIVIDE:   TOS = SS.pop() / TOS; break;
    ...
&lt;/code&gt;
    &lt;p&gt;Though syntax clarity is pretty much the same, lambda being function pointers takes an extra jump and the cost of stack-frame setup/teardown. It takes more space and about 15% slower in tight loops. However, with the advance of compilers,&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It does not need a long enum definition, i.e. PLUS, MINUS, ..., which needs to be kept in-sync&lt;/item&gt;
      &lt;item&gt;It is possible to prebuild lambda array as a ROM image or static library that can be transported.&lt;/item&gt;
      &lt;item&gt;A tweak to CODE macro, i.g. adding NEXT, can potentially enable Tail Call Optimization (TCO) which eliminates the stack-frame overhead as did in many functional languages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Though the use of C++ standard libraries helps us understanding what Forth does but, even on machines with GBs, we still need to be mindful of the followings. It gets expensive especially on MCUs.&lt;/p&gt;
    &lt;code&gt;+ A pointer takes 8-byte on a 64-bit machine,
+ A C++ string, needs 3 to 4 pointers, will require 24-32 bytes,
+ A vector, takes 3 pointers, is 24 bytes
&lt;/code&gt;
    &lt;p&gt;The current implementation of ~/src/ceforth.h, a Code node takes 144 bytes on a 64-bit machine. On the other extreme, my ~/orig/40x experimental version, a vector linear-memory hybrid, takes only 16 bytes here. Go figure how the classic Forths needs only 2 or 4 bytes per node via linked-field and the final executable in a just a few KB. You might start to understand why the old Forth builders see C/C++ like plaque.&lt;/p&gt;
    &lt;p&gt;I try to release allocated blocks before exiting, however due to the dynamic alloc and resizing of std::vector, eForth dictionary hold on to many Code objects and the names string generated with them, valgrind (or similar tool) could reports lost (or leak). Though these memory blocks should all be reclaimed by the OS, it is something to be mindful of.&lt;/p&gt;
    &lt;p&gt;Current implementation utilize C++ vector as the core storage. Inside a Code object, there are pf, p1, p2 vectors to store branching words similar to that of an AST (Abstract Syntax Tree). The alternative is to stick all words into a single parameter field as done in classic Forth. I have created a branch one_pf doing exactly the same just to check it out. Also, tried polymorphic inner interpreter. So, are they better?&lt;/p&gt;
    &lt;code&gt;+ Branching microcode look cleaner. 2-bit **VM.stage** flag can be replaced by a 1-bit **VM.jmp** status. No big deal.
+ dump and see are easier to implement, but
+ Runs 4~8x slower using recursive nest() i.e. Forth inner interpreter,
+ Improved to 2x slower using iterative nest()
+ Also, polymorphic slows down additional 5%. Most likely due to extra vtable lookup.
&lt;/code&gt;
    &lt;p&gt;So, what cachegrind said for 100M loop tight loops and chacha.fs a CPU intensive?&lt;/p&gt;
    &lt;code&gt;| Op          | 100M loop | chacha.fs |
|-------------|-----------|-----------|
| Data Read   | +30%      | +32%      |
| Branches    | +25%      | +30%      |
| Mispred     | similar   | similar   |
| Instruction | +20%      | +40%      |
&lt;/code&gt;
    &lt;p&gt;Apparently, grown ~30% in all aspects. I think because having branching primitives, i.e. _if/_else/_then, for/next, in C++ prevent the extra fetch of VM branches. Sort of the difference between having hardware and software branchers. However, my gut feeling is the difference shouldn't be so dramatic especially with the recursive nest(). More research on this...&lt;/p&gt;
    &lt;p&gt;Instead of using vectors (i.e. pf, p1, p2) to keep codes and parameters, this implementation follows classic Forth's model using one big block of parameter memory with words laid down contiguoursly. With 32-bit data, subroutine threaded but hybrid with 16-bit xt offset (to reduce one lookup).&lt;/p&gt;
    &lt;p&gt;It works better with WASM's memory model. It is used as the foundation for weForth. So far, it is stable but tweaked from time to time and&lt;/p&gt;
    &lt;code&gt;&amp;gt; make 50x
&amp;gt; ./tests/eforth50x
&lt;/code&gt;
    &lt;p&gt;Hinted by Sean Pringle's Rethinking Forth and Travis Bemann's wornderful zeptoforth. Nested module (or sub-words), simplified control structures are attemped. Now, moved to eForthX&lt;/p&gt;
    &lt;code&gt;+ perf   - [multithreaded](https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps)
+ coding -
    [optimizing](http://www.agner.org/optimize/optimizing_cpp.pdf)
    [false-sharing](https://medium.com/distributed-knowledge/optimizations-for-c-multi-threaded-programs-33284dee5e9c)
    [affinity](https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/)
    [occlusion](https://fgiesen.wordpress.com/2013/02/17/optimizing-sw-occlusion-culling-index/)
    [perf c2c](https://coffeebeforearch.github.io/2020/03/27/perf-c2c.html)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Dr. Ting's work on eForth between 1995~2011 eForth references and their Source Code Repo&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210314: Initial&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Started with ~orig/33b code-base, refactor with enum and VA_ARGS macros targeting 100% C/C++.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210707: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Incorporated list-based dict, ss, rs (i.e. ~orig/ting/ceForth40 and ~orig/802) which I proposed to Dr. Ting in our email exchanges.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210816: Code Merge&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Targeting multi-platform. Common source by consolidating ceForth, wineForth, ESP32forth (kept in ~/orig/*). Officially version 8.0&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20220512: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Though the goal of Dr. Ting's is to demonstrate how a Forth can be easily understood and cleanly constructed. However, the token threading method used is costly (slow) because each call needs 2 indirect lookups (token-&amp;gt;dict, dict-&amp;gt;xt). On top of that, C/C++ call-frame needs to be setup/teardown. It is worsen by the branch prediction missing every call stalling the CPU pipeline. Bad stuffs!&lt;/item&gt;
          &lt;item&gt;Refactor to subroutine indirect threading. It's not portable but does speed up 25% (see benchmark above).&lt;/item&gt;
          &lt;item&gt;Using 16-bit offsets for pointer arithmetic which speed up another 5% while maintaining 16-bit parameter space consumption.&lt;/item&gt;
          &lt;item&gt;Since C++ code is at least 4-byte aligned and parameter is 2-byte aligned, the LSB of a given parameter is utilized for colon word identification.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20221118: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;WASM function pointer is U32 (index). Token-indirect worked but the two indirect look-up is even slower. Since WASM uses 64K linear memory block, 16-bit pointer offset is a better option. However, the xt "function pointer" in code space is simply an index to the shared _indirect_function_table. Since LSB is used, so we are forced to use MSB to differentiate primitive word from colon word. This left us 15-bit, i.e. 32K, parameter offset available.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20231011: Review&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Since the original intention of having a pre-compiled ROM dictionary still end up in C++ static initialization run before main(), moved dictionary compilation into dict_compile as function calls gives a little more debugging control and opportunity for fine tuning.&lt;/item&gt;
          &lt;item&gt;LAMBDA_OK option was originally intended for full VM implementation but 2x slower. Dropped to reduce source clutter.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20240308: Refactor for multi-platform, accept dynamic vectors&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Experiment various threading and memory pointer models, archive into ~/orig/40x&lt;/item&gt;
          &lt;item&gt;To support cross-platform, i.g. Linux/Cygwin, Arduino/ESP32, Win32, and WASM, there were many conditional compilation branches which make the code really messy. The following were done &lt;list rend="ul"&gt;&lt;item&gt;Separate cross-platform and configuration into ~/src/config.h&lt;/item&gt;&lt;item&gt;Separate platform specific code into ~/platform&lt;/item&gt;&lt;item&gt;add included opcode for Forth script loading&lt;/item&gt;&lt;item&gt;rename 'next_idiom' to 'word', per Forth standard&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20241001: Add multi-threading support&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Shared dictionary and code space amount threads.&lt;/item&gt;
          &lt;item&gt;Refactor source into ceforth, ceforth_sys, and ceforth_task for their specific functions.&lt;/item&gt;
          &lt;item&gt;Introduce VM, states &lt;list rend="ul"&gt;&lt;item&gt;local ss, rs, tos, and user area&lt;/item&gt;&lt;item&gt;align to cache-line width&lt;/item&gt;&lt;item&gt;pass VM&amp;amp; to all lambda and static functions&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add thread pool and event_loop with affinity to physical cores. &lt;list rend="ul"&gt;&lt;item&gt;task, start, stop, join for thread life-cycle management&lt;/item&gt;&lt;item&gt;add general multi-threading demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add Inter-task communication &lt;list rend="ul"&gt;&lt;item&gt;pthread mutex and condition variables are used for synchronization&lt;/item&gt;&lt;item&gt;rank for task id&lt;/item&gt;&lt;item&gt;send, recv, and pull. Use local stack, as queue, for message passing.&lt;/item&gt;&lt;item&gt;add producer/consumer demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add IO sequencing &lt;list rend="ul"&gt;&lt;item&gt;ANSI-Color trace/logging for different cores&lt;/item&gt;&lt;item&gt;mutex guard used&lt;/item&gt;&lt;item&gt;lock, unlock for output stream synchronization&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC: 20250610: maintenance and memory leak check&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Refactor &lt;list rend="ul"&gt;&lt;item&gt;Macros to reduce verbosity i.e. VM referenced TOS, SS, RS, BRAN, BTGT&lt;/item&gt;&lt;item&gt;Group IO functions to forth_sys module&lt;/item&gt;&lt;item&gt;Macros to clarify intention, i.e. NEST, BASE, ADD_W&lt;/item&gt;&lt;item&gt;Code references replace Code pointers&lt;/item&gt;&lt;item&gt;Rename ms=&amp;gt;clock, delay=&amp;gt;ms (adhere to Forth Standard)&lt;/item&gt;&lt;item&gt;Add destructors to deallocate (reduce valgrind's complaints)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance multi-threading &lt;list rend="ul"&gt;&lt;item&gt;Use std::thread instead of pthread (except device specific CPU affinity)&lt;/item&gt;&lt;item&gt;Handle recursive include - Save/Restore WP&lt;/item&gt;&lt;item&gt;Refined forth_vm state machine transition (QUERY, HOLD, NEST, STOP)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance debugging &lt;list rend="ul"&gt;&lt;item&gt;Add dict() to detail dictionary entries&lt;/item&gt;&lt;item&gt;Add dump() to show memory/parameter field's content&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Refactor &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/chochain/eforth"/><published>2025-11-09T04:59:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45863360</id><title>I Am Mark Zuckerberg</title><updated>2025-11-09T19:32:24.362211+00:00</updated><content>&lt;doc fingerprint="b609d0711019dfdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to iammarkzuckerg.com&lt;/head&gt;
    &lt;p&gt;No, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks.&lt;/p&gt;
    &lt;p&gt;Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money.&lt;/p&gt;
    &lt;p&gt;What I Really Do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Help people obtain a fresh financial start (no passwords required)&lt;/item&gt;
      &lt;item&gt;Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)&lt;/item&gt;
      &lt;item&gt;Answer local legal questions, not privacy scandals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real Zuckerberg Facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Shares a name, not fortune, with the Facebook founder&lt;/item&gt;
      &lt;item&gt; Gets mistaken daily for a tech billionaire &lt;/item&gt;
      &lt;item&gt; Has written zero social media apps, but plenty of court briefs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Fun Fact:&lt;lb/&gt; In Indiana, saying "I'm Mark Zuckerberg" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. &lt;/p&gt;
    &lt;head rend="h3"&gt; Click Here to See How Other &lt;lb/&gt;Websites Have Reacted to This &lt;/head&gt;
    &lt;head rend="h3"&gt;Interesting Things That Have Happened to Me Because My Name is Mark Zuckerberg&lt;/head&gt;
    &lt;p&gt;For a complete list of things that have happened to Mark Zuckerberg click here&lt;/p&gt;
    &lt;p&gt;Like I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for "Mark Zuckerberg bankruptcy". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://iammarkzuckerberg.com/"/><published>2025-11-09T06:13:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45864732</id><title>Ask HN: How would you set up a child’s first Linux computer?</title><updated>2025-11-09T19:32:24.062439+00:00</updated><content>&lt;doc fingerprint="d1e111d1f886a428"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;As a tech parent I think one of the best things I did for both my son and daughter was for their first computer to help them to build and setup their own Linux computer (It was Ubuntu back then but they’ve both moved themselves to Arch these days).&lt;/p&gt;
      &lt;p&gt;We went together and bought a second hand desktop (exciting the people selling to us also) and when I got home I pulled out the Ram, HD and CD drive and set them aside; and then together with a screwdriver we “built the computer” over a few days.&lt;/p&gt;
      &lt;p&gt;In windows when a child goes searching the web for a “movie maker for windows” they are going to be in a world of hurt either finding expensive commercial options or super scammy sites promising the world.&lt;/p&gt;
      &lt;p&gt;By comparison on Linux if they search the local “app store” they’ll find stacks and stacks of free, useful, open licensed software.&lt;/p&gt;
      &lt;p&gt;My kids loved the power, freedom and later unexpected community this bought them.&lt;/p&gt;
      &lt;p&gt;Now my friend wants the same for their daughter who is 8 years old.&lt;/p&gt;
      &lt;p&gt;I’m planning to do the same and go with her parents and her and buy a second hand desktop together and then put Linux on it.&lt;/p&gt;
      &lt;p&gt;My question is where would you go from there? What suggestions do you have? What to install? Any mini “curriculums” or ideas?&lt;/p&gt;
      &lt;p&gt;Would love to hear your ideas and experiences. Linux with free and open software is the goal and focus.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45864732"/><published>2025-11-09T11:12:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865049</id><title>Visualize FastAPI endpoints with FastAPI-Voyager</title><updated>2025-11-09T19:32:22.999987+00:00</updated><content>&lt;doc fingerprint="2d7d4c5aa849e7b4"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading… FastAPI Voyager {{ state.version }} scroll to zoom in/out double click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }} {{ tag.routes.length }} {{ route.name }} No routes {{ dumpJson }} Import core data JSON&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.newsyeah.fun/voyager/"/><published>2025-11-09T12:24:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865098</id><title>Alive internet theory</title><updated>2025-11-09T19:32:22.873507+00:00</updated><content/><link href="https://alivetheory.net/"/><published>2025-11-09T12:33:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865159</id><title>Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology</title><updated>2025-11-09T19:32:21.446394+00:00</updated><content>&lt;doc fingerprint="25357b3c1a218080"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt;How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Discovery: A Digital Time Capsule from 1987&lt;/head&gt;
    &lt;p&gt;Picture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to &lt;code&gt;comp.sources.games&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;“conquest – middle earth multi-player game, Part01/05”&lt;/p&gt;
    &lt;p&gt;That’s how Ed Barlow announced it at the time, before quickly changed the name to Conquer.&lt;/p&gt;
    &lt;p&gt;This was Conquer – a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn’t just the gameplay, but how it was built and distributed in an era when “open source” wasn’t even a term yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 0: University Days.&lt;/head&gt;
    &lt;p&gt;It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy.&lt;/p&gt;
    &lt;p&gt;But by 2006, this piece of computing history was trapped in legal limbo.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 1: The Quest Begins (2006)&lt;/head&gt;
    &lt;p&gt;As a university student in Spain in the early ’90s, I’d encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear – typical of the “post it and see what happens” era of early internet software distribution.&lt;/p&gt;
    &lt;p&gt;I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions.&lt;/p&gt;
    &lt;p&gt;Simple, right?&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 2: Digital Detective Work&lt;/head&gt;
    &lt;p&gt;Finding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums.&lt;/p&gt;
    &lt;p&gt;The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: “Yes i delegated it all to adam aeons ago. Im easy on it all…. copyleft didnt exist when i wrote it and it was all for fun so…”&lt;/p&gt;
    &lt;p&gt;But there was a catch – I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 3: The Long Wait (2006-2011)&lt;/head&gt;
    &lt;p&gt;I documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders.&lt;/p&gt;
    &lt;p&gt;Years passed. The project stalled.&lt;/p&gt;
    &lt;p&gt;Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:&lt;/p&gt;
    &lt;p&gt;“I heard news of the request to release the code. I grant permission to release the code under GPL.” – Adam Bryant&lt;/p&gt;
    &lt;p&gt;He had found one of my articles online and reached out on his own.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 4: The Plot Twist – Version 5 Emerges (2025)&lt;/head&gt;
    &lt;p&gt;Fast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 – a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn’t just an update; it was a complete reimagining of the game.&lt;/p&gt;
    &lt;p&gt;But V5 had a different legal history. In the ’90s, there had been commercial arrangements. Would Adam agree to GPL this version too?&lt;/p&gt;
    &lt;p&gt;His response: “I have no issues with applying a new GPL license to Version 5 as well.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 5: The Missing Piece – PostScript Magic&lt;/head&gt;
    &lt;p&gt;Just when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps – a crucial feature in the pre-GUI era when players needed physical printouts to strategize.&lt;/p&gt;
    &lt;p&gt;Tracking down MaF in 2025 led me to his company, where he’s now Director of Product Security. His response: “Oh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.”&lt;lb/&gt;Richard Caley: More Than Just a Legal Footnote&lt;/p&gt;
    &lt;p&gt;But not all searches end with an answer. Some end with silence.&lt;/p&gt;
    &lt;p&gt;My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.&lt;/p&gt;
    &lt;p&gt;Then I found him – not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org.&lt;/p&gt;
    &lt;p&gt;“Richard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.”&lt;/p&gt;
    &lt;p&gt;Reading those words felt different from finding a historical record. This wasn’t archival research – this was walking into someone’s house years after they’d gone and finding a note on the table.&lt;/p&gt;
    &lt;p&gt;The page continued:&lt;/p&gt;
    &lt;p&gt;“Over and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.”&lt;/p&gt;
    &lt;p&gt;The “Caleyisms” – The Man Behind the Code&lt;/p&gt;
    &lt;p&gt;And then I discovered his “Caleyisms” – a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:&lt;/p&gt;
    &lt;p&gt;What’s a shell suit?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Oil company executive.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;How do you prepare for a pyroclastic flow hitting Edinburgh?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Hang 1000 battered Mars bars on strings and stand back?”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;On his book addiction:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;His humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:&lt;/p&gt;
    &lt;p&gt;“Lack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn’t make it impossible to read what was written, just harder. But you probably write in green crayon anyway.”&lt;/p&gt;
    &lt;p&gt;A Digital Office Preserved&lt;/p&gt;
    &lt;p&gt;Exploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his “About” section:&lt;/p&gt;
    &lt;p&gt;“Thankfully I don’t have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I’m not.”&lt;/p&gt;
    &lt;p&gt;Here was a complete person – technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions.&lt;/p&gt;
    &lt;p&gt;The legal reality was harsh: Richard’s contributions to Conquer couldn’t be relicensed. The university couldn’t help contact heirs due to privacy laws.&lt;/p&gt;
    &lt;p&gt;His friends had preserved his memory with a simple ASCII tribute at the end of his page:&lt;/p&gt;
    &lt;quote&gt;^_^&lt;lb/&gt;(O O)&lt;lb/&gt;\_/@@\&lt;lb/&gt;\\~~/&lt;lb/&gt;~~&lt;lb/&gt;- RJC RIP&lt;/quote&gt;
    &lt;p&gt;In the Conquer project documentation, Richard Caley isn’t remembered as a “problem case” or “unlicensable code.” He’s honored as the vibrant person he was – the brilliant mind behind the “Caleyisms,” the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 6: Modern Renaissance – Enter GitHub, CICD and Modern Distributions&lt;/head&gt;
    &lt;p&gt;Here’s where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.&lt;/p&gt;
    &lt;p&gt;For APK packages, I used Melange – a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi “undistro”. The irony? I discovered this tool when some friend started to work for the company that created it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 7: The Technical Journey: From USENET to Modern CI/CD&lt;/head&gt;
    &lt;p&gt;The transformation has been remarkable:&lt;/p&gt;
    &lt;p&gt;1987 Original:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Distributed as split USENET posts&lt;/item&gt;
      &lt;item&gt;Manual compilation with system-specific Makefiles&lt;/item&gt;
      &lt;item&gt;No version control or automated testing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2025 Revival:&lt;/p&gt;
    &lt;code&gt;# Modern CI/CD with GitHub Actions
- name: Build APK package
  run: melange build conquer.yaml
- name: Build Debian package  
  run: dpkg-buildpackage -b
&lt;/code&gt;
    &lt;p&gt;Key Modern Additions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPLv3 relicensing&lt;/item&gt;
      &lt;item&gt;Make building system modernization&lt;/item&gt;
      &lt;item&gt;C Codebase partially updated to support modern ANSI C99 specification&lt;/item&gt;
      &lt;item&gt;Debian packaging&lt;/item&gt;
      &lt;item&gt;APK packaging with Melange&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can see the complete transformation in the repositories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Conquer v4 – The original classic&lt;/item&gt;
      &lt;item&gt;Conquer v5 – The advanced rewrite&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Original Conquer v4 code, by Ed Barlow and Adam Bryant&lt;/p&gt;
    &lt;p&gt;(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!)&lt;/p&gt;
    &lt;p&gt;Conquer Version 5 – The evolution of the classical Conquer, by Adam Bryant&lt;/p&gt;
    &lt;head rend="h2"&gt;Chapter 8: The Human Element: Why This Matters&lt;/head&gt;
    &lt;p&gt;This isn’t just about preserving old games – it’s about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that’s what you did – you shared cool things with the community.&lt;/p&gt;
    &lt;p&gt;Martin Forssen’s PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator!&lt;/p&gt;
    &lt;p&gt;The 20-year relicensing effort demonstrates something crucial about open source: it’s not just about code, it’s about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they’re weaving the threads that connect computing’s past to its future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons for Modern Developers&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Document everything: Those casual USENET posts became crucial legal evidence decades later&lt;/item&gt;
      &lt;item&gt;License clearly: Ed’s comment that “copyleft didnt exist when i wrote it” highlights how licensing landscapes evolve&lt;/item&gt;
      &lt;item&gt;Community matters: Adam found my articles because the community was talking about preservation&lt;/item&gt;
      &lt;item&gt;Technical debt is temporal: What seems like legacy tech today might be tomorrow’s archaeological treasure&lt;/item&gt;
      &lt;item&gt;Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Continuing Story&lt;/head&gt;
    &lt;p&gt;Both Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades.&lt;/p&gt;
    &lt;p&gt;The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life.&lt;/p&gt;
    &lt;p&gt;Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history.&lt;/p&gt;
    &lt;p&gt;What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?&lt;/p&gt;
    &lt;p&gt;#FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell&lt;/p&gt;
    &lt;p&gt;Read this article in Spanish / Lee este artículo en español: &lt;lb/&gt;https://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/&lt;/p&gt;
    &lt;p&gt;This article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/"/><published>2025-11-09T12:44:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865189</id><title>Zensical – A modern static site generator built by the Material for MkDocs team</title><updated>2025-11-09T19:32:21.321044+00:00</updated><content>&lt;doc fingerprint="9beaf6129f9c8fc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zensical – A modern static site generator built by the Material for MkDocs team¶&lt;/head&gt;
    &lt;p&gt;We are thrilled to announce Zensical, our next-gen static site generator designed to simplify the process of building documentation sites. Distilled from a decade of experience, Zensical is our effort to overcome the technical limitations of MkDocs, reaching far beyond its capabilities.&lt;/p&gt;
    &lt;p&gt;Zensical is the result of thousands of hours of work – built from the ground up for a modern and comfortable authoring experience, while making it easy for developers to extend and customize Zensical through its upcoming module system. Our goal is to support docs-as-code workflows with tens of thousands of pages, without compromising performance or usability.&lt;/p&gt;
    &lt;p&gt;To make the transition seamless, compatibility comes first. We're putting significant effort into ensuring a smooth migration from Material for MkDocs for all users. Zensical can natively read &lt;code&gt;mkdocs.yml&lt;/code&gt;, allowing you to build your existing project with minimal changes. As of now, a subset of plugins is supported, and we're working on feature parity in the coming months.&lt;/p&gt;
    &lt;p&gt;Zensical is fully Open Source, licensed under MIT, and can be used for any purpose, including for commercial use. We're also saying goodbye to our sponsorware model, replacing it with our new offering for professional users: Zensical Spark. This allows us to stay independent, maximizing user value, as we shape the future of Zensical together with you.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to stay in the loop.&lt;/p&gt;
    &lt;p&gt;This is the second article in a four-part series:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Transforming Material for MkDocs&lt;/item&gt;
      &lt;item&gt;Zensical – A modern static site generator built by the creators of Material for MkDocs.&lt;/item&gt;
      &lt;item&gt;What happens to the features in Insiders coming November 11, 2025&lt;/item&gt;
      &lt;item&gt;A path forward for our community coming November 18, 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why Zensical?¶&lt;/head&gt;
    &lt;p&gt;Since its initial release in 2016, Material for MkDocs has helped tens of thousands of teams to publish and maintain reliable documentation. However, in recent years, it has become apparent that we were running up against limitations of our core dependency, MkDocs. These limitations proved impossible to overcome as they are deeply rooted in its architecture.&lt;/p&gt;
    &lt;p&gt;We also mentioned in our update on our foundational work that MkDocs must be considered a supply chain risk, since it's unmaintained since August 2024. It has seen no releases in over a year and is accumulating unresolved issues and pull requests. These developments have forced us to cut our ties to MkDocs as a dependency.&lt;/p&gt;
    &lt;p&gt;In order to map out a path forward, we went back to the drawing board, talked to dozens of our professional users and thoroughly analyzed the MkDocs ecosystem. We didn't just want to create a fork or port of MkDocs, but decided to rethink static site generation from first principles.&lt;/p&gt;
    &lt;p&gt;With Zensical, we are creating a modern static site generator, which is compatible with your content and customizations, and addresses MkDocs' limitations. While Material for MkDocs is built on top of MkDocs, Zensical consolidates both projects into one coherent stack, covering static site generation, theming, and customization. What you can expect today:&lt;/p&gt;
    &lt;p&gt;Although we haven't reached full feature parity yet, you can already use Zensical to build your existing Material for MkDocs projects with minimal changes.&lt;/p&gt;
    &lt;p&gt;You can jump to the compatibility section to learn what is already supported.&lt;/p&gt;
    &lt;head rend="h2"&gt;What you can expect¶&lt;/head&gt;
    &lt;head rend="h3"&gt;Solid foundation¶&lt;/head&gt;
    &lt;p&gt;Our goal with Zensical is to create a coherent and modern stack, vertically integrating all parts of the authoring experience (AX), developer experience (DX), and user experience (UX). This gives us a significant competitive advantage over solutions that overly rely on third-party frameworks and dependencies, helping us to create much more robust Open Source software.&lt;/p&gt;
    &lt;p&gt;ZRX, our new differential build engine, creates a solid foundation for Zensical, and is an Open Source project of its own. It's a fresh take on making differential data flows easy to build and a joy to work with. Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster.&lt;/p&gt;
    &lt;p&gt;Following the principle of architectural hoisting, we moved essential, reusable functionality into ZRX, which allows us to keep Zensical's core simple and focused on static site generation. ZRX handles the heavy lifting – differential builds, caching, and data flow orchestration.&lt;/p&gt;
    &lt;p&gt;With the upcoming module system and component system, both of which are on our public roadmap, Zensical will gain more degrees of freedom in the coming months, allowing you to extend and customize Zensical in ways that were previously impossible with MkDocs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Modern design¶&lt;/head&gt;
    &lt;p&gt;Zensical brings a fresh, modern design that breaks out of the Materal Design aesthetic, creating a visual foundation that is more easily brandable and adaptable to different use cases. The new design prioritizes clarity, simplicity, and usability, while having a more professional finish:&lt;/p&gt;
    &lt;p&gt;Right now, the layout and site structure of Zensical match Material for MkDocs closely, as we're focusing on ensuring maximum compatibility. Once we finish work on our upcoming component system, we'll provide an alternative that is much more flexible and adaptable, and can be tailored to different use cases and branding requirements more easily.&lt;/p&gt;
    &lt;p&gt;You can also keep the Material for MkDocs look and feel with a single line of configuration.&lt;/p&gt;
    &lt;head rend="h3"&gt;Blazing-fast search¶&lt;/head&gt;
    &lt;p&gt;Client-side search isn't a compromise – for the vast majority of static sites, it's the best solution, since it's faster, involves zero maintenance, and doesn't require you to pay for a service.&lt;/p&gt;
    &lt;p&gt;As covered in depth in the first part of this series, the current search implementation in Material for MkDocs has severe limitations, and is based on a now unmaintained library, which is why we decided to build a new search engine from scratch. It's based on the same goals as Zensical itself: performance, flexibility, and extensibility.&lt;/p&gt;
    &lt;p&gt;Disco, our modular and blazing-fast client-side search engine, is exclusively available in Zensical. When you build your site with Zensical, your users will immediately benefit from Disco's improved ranking algorithm, as well as its filtering and aggregation capabilities:&lt;/p&gt;
    &lt;p&gt;In early 2026, we'll be releasing Disco as a standalone Open Source project. With the feedback of our professional users in Zensical Spark, we're going to evolve the search experience, turning Disco into a highly configurable and customizable search engine that adapts to your needs.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to receive news about Disco.&lt;/p&gt;
    &lt;head rend="h3"&gt;Authoring experience¶&lt;/head&gt;
    &lt;p&gt;Slow feedback loops can be a major pain point when writing documentation. Almost all of us know the feeling of waiting for the static site generator to finish building the site, just to see a small change reflected in the output. With Zensical, we're finally addressing this issue.&lt;/p&gt;
    &lt;p&gt;It's important to understand that we're not yet utilizing the differential capabilities of ZRX to the fullest extent, as we're forced to make several compromises to ensure maximum compatibility with Material for MkDocs at the moment. Markdown rendering needs to go through Python Markdown, which forces us to pay for extra marshalling costs.&lt;/p&gt;
    &lt;p&gt;While the initial build can sometimes be slower than with MkDocs, repeated builds – especially when serving the site – are already 4 to 5x faster, as only changed files need to be rebuilt.&lt;/p&gt;
    &lt;p&gt;We're also working on a new Markdown toolchain based on a CommonMark-compliant parser written in Rust, which will make Markdown processing significantly faster. We'll be tackling this as part of the upcoming component system, which we'll start working on in early 2026. Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content.&lt;/p&gt;
    &lt;head rend="h3"&gt;Maximum compatibility¶&lt;/head&gt;
    &lt;p&gt;Compatibility with Material for MkDocs is our top priority. We understand that switching to a new static site generator can be challenging, especially for large projects with many customizations. Therefore, we've put significant effort into ensuring that Zensical understands &lt;code&gt;mkdocs.yml&lt;/code&gt; configuration files, so that you can build your projects with minimal changes.&lt;/p&gt;
    &lt;p&gt;This means your existing Markdown files, template overrides, CSS and JavaScript extensions don't need to be touched, primarily because we did not change the generated HTML, and rely on Python Markdown for processing your content.&lt;/p&gt;
    &lt;p&gt;However, plugins are a different story. In MkDocs, practically all plugins have side effects, making it impossible to parallelize builds. We started from first principles and asked: what should extensibility look like in a modern static site generator? Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modules can inject, extend, and re-define functionality&lt;/item&gt;
      &lt;item&gt;Modules are deterministic through topological ordering&lt;/item&gt;
      &lt;item&gt;Modules foster reusability, with the possibility to remix them&lt;/item&gt;
      &lt;item&gt;Modules can cooperate through well-defined contracts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We're working on shipping essential functionality as provided by MkDocs plugins as built-in modules. In early 2026, we will open the module system to third-party developers, so they can start building their own modules, as we see Zensical as the heart of a thriving ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Zensical Spark¶&lt;/head&gt;
    &lt;p&gt;Zensical Spark, our offering for professionals, is the result of countless calls with professional users of Material for MkDocs. From startups to large enterprises, we enable organizations to realize complex projects in diverse environments. For this, we've created Zensical Spark as a collaborative space. If you're a professional user, Zensical Spark is for you, since:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;You can be confident that Zensical will continue to be developed and maintained in the long term as a set of interconnected and sustainable OSI-compliant Open Source projects.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You can receive the support you need to successfully use, configure and customize Zensical in your organization, receiving first-class support from the Zensical team.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You can influence the future development of Zensical by participating in our new approach to Open Source software development, helping us to build exactly what you need.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's talk! If you're working in a professional context, reach out to contact@zensical.org to schedule a call and learn how Zensical Spark enables your team to transition to Zensical smoothly and have a voice in its continued development.&lt;/p&gt;
    &lt;p&gt;You should also consider joining the waiting list, since seats are limited.&lt;/p&gt;
    &lt;head rend="h2"&gt;We're growing our team¶&lt;/head&gt;
    &lt;p&gt;We're also excited to announce that we're growing our team:&lt;/p&gt;
    &lt;p&gt;Timothée Mazzucotelli, also known as @pawamoy, is joining Zensical!&lt;/p&gt;
    &lt;p&gt;At Zensical, Tim is focusing on providing the same seamless experience for generating API reference documentation from source code (via docstrings) as he has done with mkdocstrings, the second biggest project in the MkDocs ecosystem. With his expertise, and Zensical's new stack, we'll be pushing the boundaries of what's possible with API reference documentation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goodbye, GitHub Sponsors¶&lt;/head&gt;
    &lt;p&gt;Thank you! To all of you who have supported us over the years through GitHub Sponsors – we are incredibly grateful for your support. It has been invaluable in helping us to build, maintain and evolve Material for MkDocs, and we couldn't have done it without you. Seriously, thank you!&lt;/p&gt;
    &lt;p&gt;Material for MkDocs gave us something invaluable: experience building for tens of thousands of users, and the opportunity to build a team around Open Source software. It showed us that making a living from Open Source isn't just possible – we grew it into one of the largest sponsorware projects on GitHub and inspired others to pursue similar paths.&lt;/p&gt;
    &lt;p&gt;Now we're breaking new ground. Zensical is our next chapter, and we're professionalizing how we approach Open Source development. Our vision is to make Zensical free for everyone to use while building a sustainable business around it through our new approach.&lt;/p&gt;
    &lt;p&gt;This transition means saying goodbye to GitHub Sponsors. It has served us exceptionally well, but as we professionalize and scale, we're making the leap from personal project to company – building a business and team that can meet the growing demands of professional users while staying true to our values.&lt;/p&gt;
    &lt;p&gt;We're doubling down on Open Source, developing software for everyone.&lt;/p&gt;
    &lt;p&gt;If you want to continue supporting our work, please subscribe to our newsletter. We'll be providing new methods to support us in the coming months, with the possibility of getting exclusive goodies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Ahead¶&lt;/head&gt;
    &lt;p&gt;Material for MkDocs grew organically in a pot that eventually became too small. With Zensical, we're building on solid foundations designed to grow with us – and with you.&lt;/p&gt;
    &lt;p&gt;Material for MkDocs is now in maintenance mode&lt;/p&gt;
    &lt;p&gt;We want to be transparent about the risks of staying on Material for MkDocs. With MkDocs unmaintained and facing fundamental supply chain concerns, we cannot guarantee Material for MkDocs will continue working reliably in the future. We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical.&lt;/p&gt;
    &lt;p&gt;If documentation plays a critical role in your organization, and you're worried how this might affect your business, consider joining Zensical Spark, or feel free to schedule a call by reaching out at contact@zensical.org.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where we'll be in 12 months¶&lt;/head&gt;
    &lt;p&gt;Over the next 12 months, following our phased transition strategy, we'll reach Phase 2 and 3 – introducing our module system and component system, as well as CommonMark support. By replacing Python Markdown with a Rust-based Markdown parser, we'll unlock performance improvements and the modularity needed for flexible templating. This is where Zensical truly starts to unfold its capabilities.&lt;/p&gt;
    &lt;p&gt;Zensical is already powering real projects due to extensive compatibility with Material for MkDocs. We're actively working on closing the gap to reach full feature parity.&lt;/p&gt;
    &lt;p&gt;You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue – we're here to help.&lt;/p&gt;
    &lt;head rend="h3"&gt;Connect with us¶&lt;/head&gt;
    &lt;p&gt;If you have questions we haven't addressed, please reach out to us at contact@zensical.org. We're currently collecting questions from the community about Zensical, and will address them in an FAQ section as part of our documentation in the coming weeks.&lt;/p&gt;
    &lt;p&gt;We're incredibly thankful that you have been part of our journey so far. With Zensical, we're embarking on a new chapter, and we couldn't be more excited to have you with us.&lt;/p&gt;
    &lt;p&gt;You can subscribe to our newsletter to stay in the loop.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/"/><published>2025-11-09T12:50:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865289</id><title>Montana Becomes First State to Enshrine 'Right to Compute' into Law</title><updated>2025-11-09T19:32:21.115645+00:00</updated><content>&lt;doc fingerprint="a971129b188e4438"&gt;
  &lt;main&gt;
    &lt;p&gt;Montana has made history as the first state in the U.S. to legally protect its citizens’ right to access and use computational tools and artificial intelligence technologies. Governor Greg Gianforte signed Senate Bill 212, officially known as the Montana Right to Compute Act (MRTCA), into law.&lt;/p&gt;
    &lt;p&gt;The groundbreaking legislation affirms Montanans’ fundamental right to own and operate computational resources — including hardware, software, and AI tools — under the state’s constitutional protections for property and free expression. Supporters of the bill say it represents a major step in securing digital freedoms in an increasingly AI-driven world.&lt;/p&gt;
    &lt;p&gt;“Montana is once again leading the way in defending individual liberty,” said Senator Daniel Zolnikov, the bill’s sponsor and a longtime advocate for digital privacy. “With the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.”&lt;/p&gt;
    &lt;p&gt;While the law allows state regulation of computation in the interest of public health and safety, it sets a high bar: any restrictions must be demonstrably necessary and narrowly tailored to serve a compelling interest. Legal experts note that this is one of the most protective standards available under Montana law.&lt;/p&gt;
    &lt;p&gt;The act also includes provisions for AI-controlled critical infrastructure, requiring both a “shutdown mechanism” to allow human control and annual safety reviews — a move aimed at balancing innovation with public safety concerns.&lt;/p&gt;
    &lt;p&gt;The bill has drawn praise from privacy advocates and tech policy groups. Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a “flag in the ground” for digital rights, adding: “Montana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.”&lt;/p&gt;
    &lt;p&gt;The MRTCA stands in stark contrast to recent regulatory efforts in other states, such as California, Virginia, and New York, where proposals to rein in AI technologies have either failed or been heavily revised. Montana’s approach leans toward empowering individual users rather than restricting access.&lt;/p&gt;
    &lt;p&gt;The law has already inspired similar efforts in New Hampshire, where lawmakers are pushing a constitutional amendment guaranteeing access to computation. Rep. Keith Ammon, the state’s Majority Floor Leader, praised Montana’s leadership: “This is the kind of bold move that sets the tone for the rest of the country.”&lt;/p&gt;
    &lt;p&gt;Nationally, the Right to Compute movement is gaining traction. Spearheaded by the grassroots group RightToCompute.ai, the campaign argues that computation — like speech and property — is a fundamental human right. “A computer is an extension of the human capacity to think,” the organization states.&lt;/p&gt;
    &lt;p&gt;The movement is supported by Haltia.AI, a Dubai-based AI startup, and the ASIMOV Protocol, a blockchain consortium advocating for decentralized AI infrastructure. Talal Thabet, Co-Founder of both groups, praised Montana’s law as “a monumental step forward in ensuring individuals retain control of their own data and digital tools.”&lt;/p&gt;
    &lt;p&gt;As debates over AI governance and digital rights continue to evolve, Montana’s bold new law could serve as a blueprint for other states seeking to safeguard freedom in the digital era.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/"/><published>2025-11-09T13:03:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865327</id><title>Using bubblewrap to add sandboxing to NetBSD</title><updated>2025-11-09T19:32:20.747258+00:00</updated><content>&lt;doc fingerprint="53c195e199d53b4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Google Summer of Code 2025 Reports: Using bubblewrap to add sandboxing to NetBSD&lt;/head&gt;
    &lt;p&gt;This report was written by Vasyl Lanko as part of Google Summer of Code 2025.&lt;/p&gt;
    &lt;head rend="h1"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;As of the time of writing, there is no real sandboxing technique available to NetBSD. There is chroot, which can be considered a weak sandbox because it modifies the root directory of the process, effectively restricting the process' view of the file system, but it doesn't isolate anything else, so all networking, IPC, and mounts inside this restricted file system are the same as of the system, and are accessible.&lt;/p&gt;
    &lt;p&gt;There has already been some research on implementing kernel-level isolation in NetBSD with tools like gaols, mult and netbsd-sandbox, but they haven't been merged to NetBSD. Other operating systems have their own ways to isolate programs, FreeBSD has jails, and Linux has namespaces.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Goals&lt;/head&gt;
    &lt;p&gt;The goal of this project is to bring a new way of sandboxing to NetBSD. More specifically, we want to implement a mechanism like Linux namespaces. These namespaces allow the isolation of parts of the system from a namespace, or, as the user sees it, from an application.&lt;/p&gt;
    &lt;p&gt;NetBSD has compat_linux to run Linux binaries on NetBSD systems, and the implementation of namespaces can also be utilized to emulate namespace-related functionality of Linux binaries.&lt;/p&gt;
    &lt;p&gt;A simple example to visualize our intended result is to consider an application running under an isolated UTS namespace that modifies the hostname. From the system's view, the hostname remains the same old hostname, but from the application's view it sees the modified hostname.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Implementation&lt;/head&gt;
    &lt;p&gt;Linux has 8 namespace types, in this project we will focus on only 2 of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details&lt;/item&gt;
      &lt;item&gt;mount namespace, it is a prerequisite to most other namespace types because UNIX follows the philosophy of "everything is a file", so we need a separate mount namespace to have different configuration files on the same location as the system.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Linux creates namespaces via the unshare or clone system calls, and it will also be our way of calling the namespace creation logic.&lt;/p&gt;
    &lt;p&gt;We setup the base for implementing Linux namespaces in the NetBSD kernel using kauth, the subsystem managing all authorization requests inside the kernel. It associates credentials with objects, and because the namespace lifecycle management is related to the credential lifecycle it handles all the credential inheritance and reference counting for us. (Thanks kauth devs!)&lt;/p&gt;
    &lt;p&gt;We separate the implementation of each namespace in a different secmodel, resulting in a similar framework to Linux which allows the isolation of a single namespace type. Our implementation also allows users to pick whether they want to have namespace support, and of what kind, via compilation flags, just like in Linux.&lt;/p&gt;
    &lt;head rend="h2"&gt;UTS namespace&lt;/head&gt;
    &lt;p&gt;UTS stands for UNIX Timesharing System, because it allows multiple users to share a single computer system. Isolating the &lt;code&gt;utsname&lt;/code&gt;  can be useful to give users the illusion that they have control over the system's hostname, and also, for example, to give different hostnames to virtual servers.&lt;/p&gt;
    &lt;p&gt;The UTS namespace stores the namespace's hostname, domain name, and their lengths. To isolate the &lt;code&gt;utsname&lt;/code&gt; we need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace.&lt;/p&gt;
    &lt;p&gt;This namespace specific information needs to be saved somewhere, and for that we use the credential's &lt;code&gt;private_data&lt;/code&gt; field, so we can use a &lt;code&gt;UTS_key&lt;/code&gt; to save and retrieve &lt;code&gt;UTS&lt;/code&gt; related information from the secmodel. The key specifies the type of information we want to retrieve from the &lt;code&gt;private_data&lt;/code&gt;, hence using a &lt;code&gt;UTS_key&lt;/code&gt; for the UTS namespace. The key for each namespace is a fixed value (we don't create a new key for every credential), but the retrieved value for that key from different credentials may be different.&lt;/p&gt;
    &lt;p&gt;We had to modify kernel code that was directly accessing the &lt;code&gt;hostname&lt;/code&gt; and &lt;code&gt;domainname&lt;/code&gt; variables, to instead call &lt;code&gt;get_uts()&lt;/code&gt;, which retrieves the UTS struct for the namespace of the calling process. We didn't modify occurrences in kernel drivers because drivers are not part of any namespace, so they should still access the system's resources directly.&lt;/p&gt;
    &lt;head rend="h2"&gt;MNT namespace&lt;/head&gt;
    &lt;p&gt;The MNT namespace isolates mounts across namespaces. It is used to have different versions of mounted filesystems across namespaces, meaning a user inside a mount namespace can mount and unmount whatever they want without affecting or even breaking the system.&lt;/p&gt;
    &lt;p&gt;The mount namespace structure in Linux is fairly complicated. To have something similar in NetBSD we need to be able to control the mounts accessed by each namespace, and for that we need to control what is each namespace's mountlist, this is also enough for unmounting file systems, because in practice we can just hide them.&lt;/p&gt;
    &lt;p&gt;For the mount_namespace, mountlist structure and the number of credentials using the mount namespace are stored in the credential's private data with the &lt;code&gt;MNT_key&lt;/code&gt;. Similarly to the UTS namespace, we had to modify kernel code to not directly access the &lt;code&gt;mountlist&lt;/code&gt;, but instead go through a wrapper called &lt;code&gt;get_mountlist()&lt;/code&gt; which returns the correct mountlist for the namespace the calling process resides in.&lt;/p&gt;
    &lt;p&gt;Implementation for the mount namespace is immensely more complex than for the UTS namespace, it involves having a good understanding of both Linux and NetBSD behaviour, and I would frequently find myself wondering how to implement something after reading the Linux man pages, which would lead to me looking for it in the Linux source code, understanding it, then going back to NetBSD source code, trying to implement it, and seeing it's too different to implement in the same way.&lt;/p&gt;
    &lt;head rend="h1"&gt;Project Status&lt;/head&gt;
    &lt;p&gt;You can find all code written during this project in GitHub at maksymlanko/netbsd-src &lt;code&gt;gsoc-bubblewrap&lt;/code&gt; branch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on &lt;code&gt;gsoc-bubblewrap&lt;/code&gt; branch and this was the last one for the &lt;code&gt;mnt_ns&lt;/code&gt; still WIP branch.&lt;/p&gt;
    &lt;p&gt;The link includes implementation of general namespace code via secmodels, implementation of the UTS namespace and related ATF-tests, and the work-in-progress implementation of mount namespaces.&lt;/p&gt;
    &lt;p&gt;The mount namespace functionality is not finished as it would require much more work than the time available for this project. To complete it, it would be required invasive and non-trivial changes to the original source code, and, of course, more time.&lt;/p&gt;
    &lt;head rend="h1"&gt;Future Work&lt;/head&gt;
    &lt;p&gt;As previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement.&lt;/p&gt;
    &lt;p&gt;I believe that after mount namespaces it would be interesting to implement PID namespaces as this in combination with mount namespaces would permit process isolation from this sandbox. Afterwards, implementing user namespaces would allow users to get capabilities similar to &lt;code&gt;root&lt;/code&gt; in the namespace, giving them &lt;code&gt;sudo&lt;/code&gt; permissions while still restricting system-wide actions like shutting down the machine.&lt;/p&gt;
    &lt;p&gt;A lower hanging fruit is to implement the namespace management functionality, which in Linux is lsns to list existing namespaces, and setns to move the current process to an already existing namespace.&lt;/p&gt;
    &lt;head rend="h1"&gt;Challenges&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Semantics. Did you know the unmount system call with MNT_FORCE flag in Linux (usually) returns EBUSY, and in NetBSD it forces the unmounting? One of them makes it easier to implement mount namespaces.&lt;/item&gt;
      &lt;item&gt;The behaviour of namespaces is not fully specified in the man pages. If something is not clear from the man pages you need to read the source code.&lt;/item&gt;
      &lt;item&gt;Unexpected need to learn a lot of VFS concepts and their differences in NetBSD and Linux.&lt;/item&gt;
      &lt;item&gt;There was a much bigger research component than I anticipated.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the end, Linux and NetBSD are different operating systems, implemented in different ways. Linux is complex and it is not trivial to port namespaces to NetBSD.&lt;/p&gt;
    &lt;head rend="h1"&gt;Notes&lt;/head&gt;
    &lt;p&gt;The project is called "Using bubblewrap to add sandboxing to NetBSD" and was initially projected to emulate the &lt;code&gt;unshare&lt;/code&gt; system call into &lt;code&gt;compat_linux&lt;/code&gt;, but, seeing that having namespaces could be useful for NetBSD, and that it would be easy to add to &lt;code&gt;compat_linux&lt;/code&gt; afterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the &lt;code&gt;bwrap&lt;/code&gt; linux binary work correctly also wouldn't be as satisfying as implementing namespaces directly into NetBSD, so this was why the project was initially called "Using bubblewrap to add sandboxing to NetBSD" but nowadays it would be more accurate to call it "Sandboxing in NetBSD with Linux-like namespaces".&lt;/p&gt;
    &lt;head rend="h1"&gt;Thanks&lt;/head&gt;
    &lt;p&gt;I am very grateful to Google for Google Summer of Code, because without it I wouldn't have learned so much this summer, wouldn't have met with smart and interesting people, and for sure wouldn't have tried to contribute to a project like NetBSD, even if I always wanted to write operating systems code... But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects.&lt;/p&gt;
    &lt;p&gt;I would also like to thank the members of the NetBSD organization for helping me throughout this project, and more specifically:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Taylor R. Campbell, Harold Gutch and Nia Alarie from IRC, for helping me fix a nasty &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt;bug I had on my system which wouldn't let me finish compiling NetBSD, and general GSoC recomendations.&lt;/item&gt;
      &lt;item&gt;Emmanuel Dreyfus from &lt;code&gt;tech-kern&lt;/code&gt;, with whom I discussed ideas for projects and proposal suggestions, and in the end inspired the namespaces project.&lt;/item&gt;
      &lt;item&gt;Christoph Badura and Leonardo Taccari who volunteered to be my mentors. They took time to research and answer my questions, anticipated possible problems in my approaches, and always pointed me in the right direction, daily, during all of GSoC's period. This project is from the 3 of us.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing"/><published>2025-11-09T13:09:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866165</id><title>Samsung Family Hub for 2025 Update Elevates the Smart Home Ecosystem</title><updated>2025-11-09T19:32:20.211005+00:00</updated><content>&lt;doc fingerprint="255dce4306b7f5ed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Samsung Family Hub™ for 2025 Update Elevates the Smart Home Ecosystem&lt;/head&gt;
    &lt;p&gt;The software update includes a more unified user experience across connected devices, enhancements to AI Vision Inside™, expanded Knox Security and more&lt;/p&gt;
    &lt;p&gt;10/27/2025&lt;/p&gt;
    &lt;p&gt;Samsung’s Family Hub™ for 2025 software enhancements will start rolling out in October for owners of Family Hub™ refrigerators. The update includes a more intuitive user interface, improved AI Vision Inside™ capabilities, Voice ID capabilities with Bixby[1] and upgraded security with Knox Matrix[2].&lt;/p&gt;
    &lt;head rend="h5"&gt;Unified Experience Across Screens&lt;/head&gt;
    &lt;p&gt;The refreshed One UI design that was first seen on Samsung’s 2025 Bespoke AI appliances will be coming to 2024 Family Hub™ models. This advances Samsung’s vision to bring a unified, seamless experience across the screens of its ecosystem of smart TVs, mobile devices and home appliances. In addition to enabling intuitive navigation and region-specific settings, users will get convenient access to features like Family Care, Pet Care and Home Care[3].&lt;/p&gt;
    &lt;p&gt;Family Hub’s™ Cover screen themes are also being updated with new features, including the addition of a Daily Board theme, that offers a new way to see useful information at a glance.&lt;/p&gt;
    &lt;head rend="h5"&gt;Smarter Food Tracking with AI Vision Inside Refrigerators&lt;/head&gt;
    &lt;p&gt;Family Hub™ refrigerators[4] with AI Vision Inside technology will receive upgrades to enable recognition of frequently used packaged foods and even more fresh fruits and vegetables to help families reduce food waste and save money. AI Vision Inside will now recognize 37 fresh food items, including apples, cherries, cucumbers, mangoes, kiwis and more. In addition, AI Vision can now identify and suggest labeling up to 50 packaged food items that are frequently placed in the fridge.[5]&lt;/p&gt;
    &lt;head rend="h5"&gt;Personalized Intelligence for Every User&lt;/head&gt;
    &lt;p&gt;Meanwhile, Bixby gets new Voice ID[6] capabilities, allowing it to recognize who is speaking and switches to their Samsung account. This makes it easy for users to access their calendar[7] and view their photos[8] or find a misplaced phone, even when it’s on silent[9].&lt;/p&gt;
    &lt;p&gt;Voice ID also enhances accessibility by syncing the refrigerator’s display with the visual settings on a user’s Samsung Galaxy phone, such as color inversion or grayscale[10]. And for quicker access, users can now activate Bixby with a simple double tap on the screen.&lt;/p&gt;
    &lt;head rend="h5"&gt;New Widget Pilot for Cover Screen Themes&lt;/head&gt;
    &lt;p&gt;As part of the Family Hub™ software update, we are piloting a new widget for select Cover screens themes of Family Hub™ refrigerators. The widget will display useful day-to-day information such as news, calendar and weather forecasts, along with curated advertisements.[11]&lt;/p&gt;
    &lt;p&gt;Family Hub™ owners will have the option to turn off Cover screen ads in the Advertisements tab of the Settings menu. Ads can also be dismissed on the Cover screen, meaning that specific ads will not appear again during the campaign period. Advertising will not appear when Cover screen displays Art or Album themes.&lt;/p&gt;
    &lt;head rend="h5"&gt;Advanced Security That Works Quietly in the Background&lt;/head&gt;
    &lt;p&gt;Samsung is also expanding the reach of Knox Matrix, its advanced security solution built on private blockchain technology, to more of its smart home lineup. The protection now extends beyond Family Hub™+ refrigerators to include compatible Wi-Fi–enabled[12] Samsung fridges, washers and dryers launched in 2024[13] — creating a safer, more connected home ecosystem.&lt;/p&gt;
    &lt;p&gt;With Knox Trust Chain, these appliances can now monitor each other’s security status, ensuring every connected device stays protected. The Bespoke AI Family Hub™+ will also receive enhanced security features, including encrypted Credential Sync, Passkey support and the new Knox Security Dashboard introduced on 2025 models, giving users an easy, real-time view of their connected devices’ security status.&lt;/p&gt;
    &lt;head rend="h5"&gt;How to Update Your Family Hub™&lt;/head&gt;
    &lt;p&gt;Once the update is available for your fridge, you will receive a notification on the fridge’s screen asking to opt in to the latest software update. Enhancements will become available as soon as you accept the terms and complete the update.&lt;/p&gt;
    &lt;p&gt;To learn more about Samsung’s innovative line of smart Family Hub™ refrigerators, visit Samsung.com.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.samsung.com/us/samsung-family-hub-2025-update-elevates-smart-home-ecosystem/"/><published>2025-11-09T15:18:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866224</id><title>The Manuscripts of Edsger W. Dijkstra</title><updated>2025-11-09T19:32:19.657262+00:00</updated><content>&lt;doc fingerprint="e615734b00f3a2b8"&gt;
  &lt;main&gt;
    &lt;p&gt;Edsger Wybe Dijkstra was one of the most influential members of computing science’s founding generation. Among the domains in which his scientific contributions are fundamental are&lt;/p&gt;
    &lt;p&gt;algorithm design&lt;/p&gt;
    &lt;p&gt;programming languages&lt;/p&gt;
    &lt;p&gt;program design&lt;/p&gt;
    &lt;p&gt;operating systems&lt;/p&gt;
    &lt;p&gt;distributed processing&lt;/p&gt;
    &lt;p&gt;formal specification and verification&lt;/p&gt;
    &lt;p&gt;design of mathematical arguments&lt;/p&gt;
    &lt;p&gt;In addition, Dijkstra was intensely interested in teaching, and in the relationships between academic computing science and the software industry.&lt;/p&gt;
    &lt;p&gt;During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra’s contributions brought him many prizes and awards, including computing science’s highest honor, the ACM Turing Award.&lt;/p&gt;
    &lt;p&gt;The Manuscripts&lt;/p&gt;
    &lt;p&gt;Like most of us, Dijkstra always believed it a scientist’s duty to maintain a lively correspondence with his scientific colleagues. To a greater extent than most of us, he put that conviction into practice. For over four decades, he mailed copies of his consecutively numbered technical notes, trip reports, insightful observations, and pungent commentaries, known collectively as “EWDs”, to several dozen recipients in academia and industry. Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra’s writings, the informal circulation of many of the EWDs eventually reached into the thousands.&lt;/p&gt;
    &lt;p&gt;Although most of Dijkstra’s publications began life as EWD manuscripts, the great majority of his manuscripts remain unpublished. They have been inaccessible to many potential readers, and those who have received copies have been unable to cite them in their own work. To alleviate both of these problems, the department has collected over a thousand of the manuscripts in this permanent web site, in the form of PDF bitmap documents (to read them, you’ll need a copy of Acrobat Reader). We hope you will find it convenient, useful, inspiring, and enjoyable.&lt;/p&gt;
    &lt;p&gt;The original manuscripts, along with diaries, correspondence, photographs, and other papers, are housed at The Center for American History of The University of Texas at Austin.&lt;/p&gt;
    &lt;p&gt;Indexes&lt;/p&gt;
    &lt;p&gt;Each manuscript file is accessible through either of two indexes:&lt;/p&gt;
    &lt;p&gt;0. BibTeX index. Each entry includes all the available bibliographic data.&lt;/p&gt;
    &lt;p&gt;1. Ad-hoc indexes. These contain titles only, but are faster if you know what you’re looking for.&lt;/p&gt;
    &lt;p&gt;EWD-numbered documents(This index gives an approximate correspondence between manuscripts’ EWD numbers and the year in which they appeared.)&lt;/p&gt;
    &lt;p&gt;Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica)&lt;/p&gt;
    &lt;p&gt;You can find a table relating EWD numbers to publication years here.&lt;/p&gt;
    &lt;p&gt;Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers.&lt;/p&gt;
    &lt;p&gt;Transcripts and translations&lt;/p&gt;
    &lt;p&gt;A growing number of the PDF bitmap documents have been transcribed to make them searchable and accessible to visitors who are visually impaired.&lt;/p&gt;
    &lt;p&gt;A few of the manuscripts written in Dutch have been translated into English, and one —EWD1036— has been translated into Spanish. EWD28 has been translated from English into Russian.&lt;/p&gt;
    &lt;p&gt;For these transcriptions and translations we are grateful to over sixty contributors. Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations).&lt;/p&gt;
    &lt;p&gt;Proofreading Each transcription gets a cursory scan as it’s prepared for uploading, but since a web page can always be updated, I don’t strive for (unattainable) perfection before installing it. On the web, proofreading is a game that can be played by every reader; if you spot an error, please&lt;/p&gt;
    &lt;p&gt;Links between EWDs&lt;/p&gt;
    &lt;p&gt;A compilation of cross-references has been contributed by Diethard Michaelis. As its author notes, the collection is incomplete, and all readers are invited to add to it.&lt;/p&gt;
    &lt;p&gt;Dijkstra often returned to topics about which he had already written, when he had something new to say or even just a better way of saying it. When Dijkstra himself didn’t provide the backward references, we indicate the relationship by "see also" links in the index, leaving the judgment of the extent to which the earlier EWD is superseded by the later one to the reader. Any reader who notices such a relationship is invited to&lt;/p&gt;
    &lt;p&gt;Summaries&lt;/p&gt;
    &lt;p&gt;We have begun adding summaries of the EWDs. This innovation was suggested by Günter Rote, who contributed the first dozen summaries. Additional contributions of summaries—especially summaries in English of EWDs in Dutch—are most welcome.&lt;/p&gt;
    &lt;p&gt;Copyrights&lt;/p&gt;
    &lt;p&gt;Copyrights in most EWDs are held by his children, one of whom — — handles requests for permission to publish reproductions. The exceptions are documents that were published, and whose copyrights are held by their publishers; those documents are listed here, and each one is provided with a cover page identifying the copyright holder.&lt;/p&gt;
    &lt;p&gt;Because the original manuscripts are in possession of the Briscoe Center for American History at The University of Texas, the Center’s policies are also applicable.&lt;/p&gt;
    &lt;p&gt;Video and audio&lt;/p&gt;
    &lt;p&gt;In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews.&lt;/p&gt;
    &lt;p&gt;About Dijkstra and his work&lt;/p&gt;
    &lt;p&gt;An interview with Dijkstra (Spanish translation here) was conducted in 1985 by Rogier F. van Vlissingen, who has also written a personal reflection on “Dijkstra’s sense of what computer science and programming are and what they aren’t.”&lt;/p&gt;
    &lt;p&gt;Another interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute.&lt;/p&gt;
    &lt;p&gt;To mark the occasion of Dijkstra’s retirement in November 1999 from the Schlumberger Centennial Chair in Computer Sciences, which he had occupied since 1984, and to celebrate his forty-plus years of seminal contributions to computing science, the Department of Computer Sciences organized a symposium, In Pursuit of Simplicity, which took place on his birthday in May 2000. The symposium’s program (10 MB) contains an outline of Dijkstra’s career, as well as a collection of quotes culled from his writings, from his blackboard, and from what others have said about him. Banquet speeches by David Gries, Fred Schneider, Krzysztof Apt, W.M. Turski, and H. Richards were recorded on a video.&lt;/p&gt;
    &lt;p&gt;Dijkstra’s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department’s memorial celebration.&lt;/p&gt;
    &lt;p&gt;A remembrance of Dijkstra was posted in May 2008 by Maarten van Emden (thanks to Tristram Brelstaff for noting it).&lt;/p&gt;
    &lt;p&gt;In 2021 Krzysztof R. Apt and Tony Hoare edited a commemoration of Edsger Dijkstra written by more than twenty computer scientists who knew him as a colleague, teacher, and friend.&lt;/p&gt;
    &lt;p&gt;A blog devoted to Dijkstra’s works and thoughts has been created, and is being maintained, by the historian of computing Edgar G. Daylight. An article by Daylight, “Dijkstra’s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,” appeared in The Computer Journal, March 2011.&lt;/p&gt;
    &lt;p&gt;In his blog A Programmer’s Place, Maarten van Emden has an entry entitled “Another scoop by Dijkstra?”. The entry describes Dijkstra’s “remarkable insight [in “Notes on Structured Programming” (EWD 249)] that resolves the stand-off between the Sieve of Eratosthenes (efficient in terms of time, but not memory) and the method of Trial Division (efficient in terms of memory, but not time)” by applying the Assembly-line Principle.&lt;/p&gt;
    &lt;p&gt;The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra’s “foundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.”&lt;/p&gt;
    &lt;p&gt;The Dijkstra Memorial Lectures&lt;/p&gt;
    &lt;p&gt;A series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010.&lt;/p&gt;
    &lt;p&gt;About this site&lt;/p&gt;
    &lt;p&gt;Recent significant changes in the site are listed here; the most recent change was posted on 30 March 2021.&lt;/p&gt;
    &lt;p&gt;The folks who contributed most significantly to the site’s creation are acknowledged here.&lt;/p&gt;
    &lt;p&gt;Comments and suggestions about the site are always welcome; please email them to the&lt;/p&gt;
    &lt;p&gt;Related site&lt;/p&gt;
    &lt;p&gt;If you find this site interesting, you may also be interested in another site:&lt;/p&gt;
    &lt;p&gt;Discipline in Thought which is a website dedicated to disciplined thinking, calculational mathematics, and mathematical methodology. The members of this site are markedly influenced by the works of EWD, and the material shared through the website continues in the traditions set by EWD (among others).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cs.utexas.edu/~EWD/"/><published>2025-11-09T15:27:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866243</id><title>AI isn't replacing jobs. AI spending is</title><updated>2025-11-09T19:32:19.493741+00:00</updated><content/><link href="https://www.fastcompany.com/91435192/chatgpt-llm-openai-jobs-amazon"/><published>2025-11-09T15:30:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866572</id><title>The Principles of Diffusion Models</title><updated>2025-11-09T19:32:19.205574+00:00</updated><content>&lt;doc fingerprint="ac0cac09d8b5828a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 24 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:The Principles of Diffusion Models&lt;/head&gt;View PDF&lt;quote&gt;Abstract:This monograph presents the core principles that have guided the development of diffusion models, tracing their origins and showing how diverse formulations arise from shared mathematical ideas. Diffusion modeling starts by defining a forward process that gradually corrupts data into noise, linking the data distribution to a simple prior through a continuum of intermediate distributions. The goal is to learn a reverse process that transforms noise back into data while recovering the same intermediates. We describe three complementary views. The variational view, inspired by variational autoencoders, sees diffusion as learning to remove noise step by step. The score-based view, rooted in energy-based modeling, learns the gradient of the evolving data distribution, indicating how to nudge samples toward more likely regions. The flow-based view, related to normalizing flows, treats generation as following a smooth path that moves samples from noise to data under a learned velocity field. These perspectives share a common backbone: a time-dependent velocity field whose flow transports a simple prior to the data. Sampling then amounts to solving a differential equation that evolves noise into data along a continuous trajectory. On this foundation, the monograph discusses guidance for controllable generation, efficient numerical solvers, and diffusion-motivated flow-map models that learn direct mappings between arbitrary times. It provides a conceptual and mathematically grounded understanding of diffusion models for readers with basic deep-learning knowledge.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.LG&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.21890"/><published>2025-11-09T16:10:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866688</id><title>Bull markets make you feel smarter than you are</title><updated>2025-11-09T19:32:19.076973+00:00</updated><content>&lt;doc fingerprint="798b513dafb3abc0"&gt;
  &lt;main&gt;
    &lt;p&gt;Bull markets make you feel smarter than you really are.&lt;/p&gt;
    &lt;p&gt;Bear markets make you feel dumber than you really are.&lt;/p&gt;
    &lt;p&gt;It’s almost impossible to avoid feeling like a know-it-all when things are going up and a know-nothing when things are going down.&lt;/p&gt;
    &lt;p&gt;That’s human nature.&lt;/p&gt;
    &lt;p&gt;Benjamin Graham started his investment partnership in the Roaring 20s with $400,000 of money from clients and his own capital. In just three years he turned $400k into $2.5 million. Much of it was Graham’s own money, derived from a combination of savings and the management fees he earned.&lt;/p&gt;
    &lt;p&gt;This magical run of performance just so happened to coincide with a melt-up in the stock market.&lt;/p&gt;
    &lt;p&gt;Alas, like most people, Graham didn’t see the Great Depression coming. He tried to pick the bottom on numerous occasions with disastrous results.&lt;/p&gt;
    &lt;p&gt;Michael wrote about what happened in Big Mistakes:&lt;/p&gt;
    &lt;p&gt;In 1930, thinking the worst was over, Graham went all in and then some. He used margin to leverage what he thought would be terrific returns. But the worst was not over, and when the Dow collapsed, Graham had his worst year ever, losing 50%. “He personally was wiped out in the crash. Having ducked the 1929 cataclysm, he was enticed back into the market before the final bottom.”&lt;/p&gt;
    &lt;p&gt;By 1932, the $2.5 million had dwindled to just $375k.&lt;/p&gt;
    &lt;p&gt;In his memoir Graham wrote about how his early successes impacted his mentality before the calamity:&lt;/p&gt;
    &lt;p&gt;At thirty-one I was convinced that I knew it all–or at least I knew all I needed to know about making money in stocks and bonds–that I had Wall Street by the tail, that my future was as unlimited as my ambitions, that I was destined to enjoy great wealth and all the material pleasures that wealth could buy. I thought of owning a large yacht, a villa at Newport, racehorses. I was too young to realize that I had caught a bad case of hubris.&lt;/p&gt;
    &lt;p&gt;The good news is Graham was able to turn it around. He didn’t take a paycheck until all of his investors were made whole. Despite his setbacks in the Great Depression, his long-term track record was impressive while his impact on investor education still lives on.&lt;/p&gt;
    &lt;p&gt;One of my all-time favorite investment books is What I Learned Losing a Million Dollars by Brendan Moynihan.&lt;/p&gt;
    &lt;p&gt;Moynihan tells the story of Jim Paul, a country boy from Kentucky who went from dirt-poor to millionaire trader on the Chicago Mercantile Exchange to broke in a matter of years.&lt;/p&gt;
    &lt;p&gt;This is how Moynihan describes the story in the introduction:&lt;/p&gt;
    &lt;p&gt;One of the premises of this book is that the rise sets up the fall; the winning sets up the losing. You can’t really be set up for disaster without having it preceded by success.&lt;/p&gt;
    &lt;p&gt;It’s extremely difficult to understand this dynamic as a young person who has experienced some level of success in the markets. Moynihan explains:&lt;/p&gt;
    &lt;p&gt;If you start from scratch and have a run of successes, you are setting yourself up for the coming failure because the successes lead to a variety of psychological distortions. This is particularly true if you have unknowingly broken the rules of the game and won anyway. Once that happens to you, you think that you are somehow special and exempt from following the rules.&lt;/p&gt;
    &lt;p&gt;There are a lot of people who have made a lot of money in this bull market.&lt;/p&gt;
    &lt;p&gt;So many investors have made life-altering amounts of money. This is a wonderful thing.&lt;/p&gt;
    &lt;p&gt;But it’s important to avoid letting success in the markets go to your head. This cycle will not last forever. Making money won’t always be this easy.&lt;/p&gt;
    &lt;p&gt;The market will make you feel dumb again at some point…even when it’s not true.&lt;/p&gt;
    &lt;p&gt;Further Reading:&lt;lb/&gt; The Curse of the Young Millionaire&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://awealthofcommonsense.com/2025/11/ben-graham-bull-market-brains/"/><published>2025-11-09T16:25:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866697</id><title>Marble Fountain</title><updated>2025-11-09T19:32:18.928450+00:00</updated><content>&lt;doc fingerprint="51808547f247bba"&gt;
  &lt;main&gt;
    &lt;p&gt;5 minutes&lt;/p&gt;
    &lt;head rend="h1"&gt;Marble Fountain&lt;/head&gt;
    &lt;p&gt;I really enjoy procedural generation, especially systems designed to work with hardware outputs. After starting work at Formlabs in September of 2023 and gaining access to much nicer printers than I was used to, I started wanting to tackle some large algorithmic structure projects. Complexity is free in 3d printing, the limit of design geometry is mostly how much time you’re willing to spend in CAD. I wanted to print the most complicated art piece I could think of. Marble Fountain is what I came up with.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tracks&lt;/head&gt;
    &lt;p&gt;My initial system came together quickly. Randomly placing spaced out points, drawing a spline through them, and setting a constant slope just works. My first draft was just subtracting a tube from the solid support structure which worked but was super limited. I wanted to add more parts and so I started working on a path solver. I wanted to fit as much motion into the volume of the printer as possible. This turned out to be extremely challenging.&lt;/p&gt;
    &lt;p&gt;The solver starts by making a random series of line segments connecting the top and bottom of the lift. There are several different algorithms to generate this guess, as the initial conditional has a noticeable impact on the shape of the structure for lower path counts. It’s interesting to play with different variants of the starting conditions and see how they change during generation.&lt;/p&gt;
    &lt;p&gt;A series of functions update the positions over time to “pull” the points into a followable path. The points making up each path:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stay in the bounding box&lt;/item&gt;
      &lt;item&gt;Evenly space themselves out&lt;/item&gt;
      &lt;item&gt;Pull towards a fixed height to enforce a constant slope&lt;/item&gt;
      &lt;item&gt;Enforce min and max turning radius of the path&lt;/item&gt;
      &lt;item&gt;Repel away from other tracks&lt;/item&gt;
      &lt;item&gt;Repel away from distant sections of our own track&lt;/item&gt;
      &lt;item&gt;Smooth out changes in slope to prevent jumps&lt;/item&gt;
      &lt;item&gt;Prevent slope from ever increasing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Velocity is a much harder problem than I anticipated. The tracks break a lot of the obvious assumptions if you act like the marble is a point mass, as changing the bank of the track moves the axis of rotation and can burn off rotational inertia to friction. Long straight sections would build up too much speed and bearings fly off on the turns, but balls taking sharp turns at slow speed will lose too much momentum and stop. I settled on setting a minimum turn radius for the track and banking much more aggressively than is technically necessary for any given speed, so it constantly snakes back and forth to burn off speed.&lt;/p&gt;
    &lt;p&gt;One of the most elegant designs of the whole structure is how the lift acts like a ball screw. The the screw is constrained by the balls on all sides which allows it to run with no bearing at the top. This also leads to a failure mode where if the screw ever only has balls on one side it will immediately start wobbling badly enough that all the balls currently rolling will fall off the tracks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supports&lt;/head&gt;
    &lt;p&gt;The support generation was surprisingly simple. Iterating from the top down and treating the support pillars as a particle system is quite robust. I spent more time tweaking the geometry for aesthetics than I did for actual structure and collision issues, although I did heavily lean on the overhang tolerance of the printer.&lt;/p&gt;
    &lt;p&gt;Each support:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pulls towards other supports, weighted by distance and similarity in size&lt;/item&gt;
      &lt;item&gt;Repels away from other supports&lt;/item&gt;
      &lt;item&gt;Pulls to stay in the bounding box&lt;/item&gt;
      &lt;item&gt;Pulls towards a fixed radius from the center of the structure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Supports also have inertia, which is where the arcs in the structure of the support columns come from.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;The final models take around 5-20 minutes to export. There’s a ton I could do to optimize the models, but at this point the geometry is simply beyond the scope of OpenSCAD. If I was rewriting this I would probably use a different tool more optimized for this type of organic geometry, likely an SDF library. I have vague ambitions to do a big rewrite eventually but figured sharing janky code is better than none. I started this just planning for the janky splines as a weekend project but it has gotten thoroughly out of hand.&lt;/p&gt;
    &lt;p&gt;I have a ton of other ideas to play with if I do that big rewrite. There is no realistic velocity estimation at any point in the whole system right now, just a pile of heuristics. I was originally trying to not overcomplicate but building a proper acceleration model by measuring velocity with a camera would have almost definitely saved time overall. Trying to maintain a fixed slope makes collision prevention much harder but is required to keep speed within bounds. At this point I’m also just curious about the response curve, there’s a knee somewhere where the surfaces start to slip that I want to track down.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking back&lt;/head&gt;
    &lt;p&gt;This was the most work I have ever put into a hobby project. I started in February 2024 and worked on it on and off until September. I applied to show it in a gallery (shoutout to New Alliance Gallery in Somerville) with two months of warning, which wound up leading to a large crunch trying to make the system reliable enough to show in person in the weeks before the show. I was able to get it working consistently, although it did lose 2-3 balls an hour and could only run for a few hours without the motor overheating. I got pretty burned out and dropped the project, which is why I shelved it for a full year before sharing anything.&lt;/p&gt;
    &lt;p&gt;Finally, a huge thanks to my friend Alex who listened to me ramble about marbles for several months every day while walking home from work, gave a ton of helpful input, and lived with the dozens of ball bearings scattered across our apartment.&lt;/p&gt;
    &lt;p&gt;ProceduralGeneration Art 3D Printed Python&lt;/p&gt;
    &lt;p&gt;983 Words&lt;/p&gt;
    &lt;p&gt;2025-11-01 00:00 (Last updated: 2025-11-03 01:40)&lt;/p&gt;
    &lt;p&gt;789ee9a @ 2025-11-03&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://willmorrison.net/posts/marble-fountain/"/><published>2025-11-09T16:26:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45866772</id><title>Bumble Berry Pi – A Cheap DIY Raspberry Pi Handheld Cyberdeck</title><updated>2025-11-09T19:32:18.182817+00:00</updated><content>&lt;doc fingerprint="d40f95070be1dc8"&gt;
  &lt;main&gt;
    &lt;p&gt;A cheap, easy-to-build Raspberry Pi Handheld Cyberdeck&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I wanted a Clockwork Pi uConsole, but didn’t want to wait 90 business days&lt;/item&gt;
      &lt;item&gt;I like the tactile feeling of a mini keyboard&lt;/item&gt;
      &lt;item&gt;I wanted something small enough to fit into a pants pocket, so I can easily take it anywhere, but with a large enough screen to do useful things like writing little programs, running scripts, etc&lt;/item&gt;
      &lt;item&gt;I wanted to build this quickly &amp;amp; cheaply, with as many off-the-shelf components as possible&lt;/item&gt;
      &lt;item&gt;I mostly boot to the terminal interface and use tmux to manage mutliple terminal windows, but I occasionally use the GUI&lt;/item&gt;
      &lt;item&gt;I wanted to use the Raspberry Pi's I already owned (i.e. an old 3b+), rather than having to buy a new compute module&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;4.3” Touch Screen Display&lt;/item&gt;
      &lt;item&gt;Nice sized QWERTY keypad&lt;/item&gt;
      &lt;item&gt;37 Watt-hour battery (all day battery life with Raspberry Pi 3b+)&lt;/item&gt;
      &lt;item&gt;Only 2 3D-Printed Parts&lt;/item&gt;
      &lt;item&gt;Minimal assembly required&lt;/item&gt;
      &lt;item&gt;All parts available on Amazon&lt;/item&gt;
      &lt;item&gt;Cost: ~$60 worth of Amazon parts, not including the raspberry pi&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Part&lt;/cell&gt;
        &lt;cell role="head"&gt;QTY&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Buy Link&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Raspberry Pi&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$50&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;Pick your favorite. I picked a 3b+ for low cost and low power usage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4.3” Touch Screen Display&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$38&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Mini Bluetooth keyboard&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$23&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;37 Watt-Hr USB Power Bank&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$19&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;Comes with short USB-C cable&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;USB-C to Micro-USB U-Shaped Adapter&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$10&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;USB-C Right Angle Adapter&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$9&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M3x10mm Countersunk Head Bolt&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M2.5x8mm Socket Head Bolt&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;M3 Threaded Inserts&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2" Kapton Tape&lt;/cell&gt;
        &lt;cell&gt;1 ft&lt;/cell&gt;
        &lt;cell&gt;Amazon&lt;/cell&gt;
        &lt;cell&gt;You could use another type of double-sided tape&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;bumble-berry-pi-enclosure-A-v3.STL&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Download from this repo an print on a 3D printer using PLA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;bumble-berry-pi-enclosure-B-v3.STL&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Download from this repo an print on a 3D printer using PLA&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Small phillips screw driver&lt;/item&gt;
      &lt;item&gt;M2.5mm hex driver&lt;/item&gt;
      &lt;item&gt;Soldering iron&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please note: Assembly instructions are a work in progress. Please let me know if you'd like additional instructions/videos, etc and I will do my best to provide them.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;3D print the two enclosure parts in PLA&lt;/item&gt;
      &lt;item&gt;Insert the 6 threaded inserts using a soldering iron (I always love this part)&lt;/item&gt;
      &lt;item&gt;Attach the raspberry pi to the screen using 4 phillips screws&lt;/item&gt;
      &lt;item&gt;Plug the ribbon cable into the rapsberry pi &amp;amp; display&lt;/item&gt;
      &lt;item&gt;Attach the screen to the front eclosure using 4 M2.5x6mm socket head bolts&lt;/item&gt;
      &lt;item&gt;Place the front enclosure face down on a table and insert the keyboard&lt;/item&gt;
      &lt;item&gt;Add a piece of double-sided kapton tape to the back of the keyboard&lt;/item&gt;
      &lt;item&gt;Place the USB power bank in the front enclosure&lt;/item&gt;
      &lt;item&gt;Add a piece of double-sided kapton tape to the back of the power bank&lt;/item&gt;
      &lt;item&gt;Route the USB cables &amp;amp; adapters as shown&lt;/item&gt;
      &lt;item&gt;Screw the enclosure back onto the enclosure front using 6 M3x10mm countersunk head bolts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I designed the 3D parts in Solidworks. Let me know if you're interested in the modifying the design and I can post the solidworks files.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/samcervantes/bumble-berry-pi"/><published>2025-11-09T16:34:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45867176</id><title>Ask HN: How do you get over the fear of sharing code?</title><updated>2025-11-09T19:32:18.011938+00:00</updated><content>&lt;doc fingerprint="4e6339913a219f53"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I'm a junior. Truth be told, I don't really care if professionals/adults see my code or pick it apart/mock it/fork it or whatever. All my repos are private just because I worry about other students being lazy and just ripping my hard work and claiming it as their own. That really pisses me off when I hear some horror stories like that.&lt;/p&gt;
      &lt;p&gt;Is this unfounded? Or do I have a right for some concern? It's obviously easier for viewers to just see public code repos and browse without ever requesting access so I know I'm losing some traffic (from my portfolio site)&lt;/p&gt;
      &lt;p&gt;I was thinking the alternative would be just linking my demo on my portfolio site as a proof of concept that yes I made it, yes it works, and if you're curious , here's a link to the code u can request independently of github.&lt;/p&gt;
      &lt;p&gt;Thank you in advance.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45867176"/><published>2025-11-09T17:17:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45867277</id><title>Python Software Foundation gets a donor surge after rejecting federal grant</title><updated>2025-11-09T19:32:17.633676+00:00</updated><content>&lt;doc fingerprint="3c0817bd488a0301"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;PSF Gets a Donor Surge After Rejecting Anti-DEI Federal Grant&lt;/head&gt;
    &lt;p&gt;“The support from the Python community in response has been overwhelming,” Seth Larson told me last week. As the Python Software Foundation‘s (PSF) principal investigator for a $1.5 million grant National Science Foundation application, Larson had a front-row seat for the multiround, months-long vetting process — and to everything that happened next.&lt;/p&gt;
    &lt;p&gt;In short, the PSF turned the grant down after discovering new federal “terms and conditions” that would require them to end any programs promoting Diversity, Equity, and Inclusion (DEI) “during the term of this financial assistance award.” But a flood of new donations followed, and the PSF vowed to explore other funding options while remaining steadfast to their organizational values.&lt;/p&gt;
    &lt;p&gt;“It was so maddening to have to turn down work that would benefit everyone,” posted Loren Crary, PSF deputy executive director, on Reddit, “because they insisted on dictating what we do outside of the security project.”&lt;/p&gt;
    &lt;p&gt;Yet rejecting the grant created a surge in news coverage, thousands of upvotes on social media and an upswell of donations. Together, maybe that show of support forms a kind of collective answer — an example of how a community responds to a forceful outside attempt to challenge their culture.&lt;/p&gt;
    &lt;p&gt;By coming together.&lt;/p&gt;
    &lt;head rend="h2"&gt;Support From Guido — and Thousands of Others&lt;/head&gt;
    &lt;p&gt;“I was one of the board members who voted to reject this funding — a unanimous but tough decision,” wrote Simon Willison on his blog. “I’m proud to serve on a board that can make difficult decisions like this.”&lt;/p&gt;
    &lt;p&gt;And Python’s original creator, Guido van Rossum, even made his own post of support on X, formerly known as Twitter. “If you haven’t heard about this, kudos to the PSF for standing for its values (which are also my values).”&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you haven’t heard about this, kudos to the PSF for standing for its values (which are also my values).&lt;/p&gt;
      &lt;p&gt;— Guido van Rossum (@gvanrossum), Oct. 29, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The day of the announcement, the PSF received about 300 new donations, Crary said — but then they’d kept coming. On Tuesday (Oct. 28), one Reddit user even complained their first try at donating was met with a timeout error — and Crary responded that apparently, “Our donation page got a little overwhelmed.”&lt;/p&gt;
    &lt;p&gt;Crary — who had also been the co-principal investigator on the withdrawn application — also acknowledged the supportive responses on Python’s official discussion forum, writing “We’re very grateful for the community’s support, which has been pouring in and has honestly been a little overwhelming.”&lt;/p&gt;
    &lt;p&gt;Throughout that week, Crary responded to several people who announced they were making donations to the PSF as a show of support. “I can’t tell you how much it has meant to see the community stand up with us today, after sitting with these tough circumstances for a while,” she said.&lt;/p&gt;
    &lt;p&gt;On Friday, less than two weeks after the announcement, the organization had seen some inspiring numbers, Deb Nicholson, PSF executive director, told TNS. “We’ve raised over $157,000,” including 295 new Supporting Members paying an annual $99 membership fee. And that’s just the beginning. “We know some donors are pursuing an employer match, and some community members have started their own matching campaign, which will also bump those numbers up.”&lt;/p&gt;
    &lt;p&gt;“It doesn’t quite bridge the gap of $1.5 million, but it’s incredibly impactful for us, both financially and in terms of feeling this strong groundswell of support from the community.”&lt;/p&gt;
    &lt;p&gt;“We zero percent expected a flood of support,” Crary added later, “and it’s been a huge deal for us.”&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We love the values of open source and @ThePSF‘s commitment to their community. Please read and share their story.&lt;/p&gt;
      &lt;p&gt;— Google Open Source (@GoogleOSS), Oct. 27, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Soon, the move had drawn news coverage from around the web. The conversation continued across several social media platforms. Their announcement also received 1,400 upvotes in Reddit’s Python subreddit and another 355 comments. It made the front page of Hacker News, drawing another 726 upvotes (along with 754 comments).&lt;/p&gt;
    &lt;p&gt;The PSF’s LinkedIn post about the decision began with this “TLDR” summary: “The PSF has made the decision to put our community and our shared diversity, equity, and inclusion values ahead of seeking $1.5M in new revenue.”&lt;/p&gt;
    &lt;p&gt;“In the end, it wasn’t a hard decision,” they wrote, saying they put their value (and community) first.&lt;/p&gt;
    &lt;p&gt;Within days, over 2,000 people clicked supportive “Reactions” on LinkedIn — with 361 reposts and 88 comments.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Happens Next?&lt;/head&gt;
    &lt;p&gt;Larson had another message. “I’m proud of what our little team has been able to accomplish, even if it’s not the result we imagined when Loren and I started this project almost a year ago.&lt;/p&gt;
    &lt;p&gt;“Everything we’ve seen since we announced our decision has only confirmed my feelings that Python is an amazing community to be serving. I couldn’t be happier about that.”&lt;/p&gt;
    &lt;p&gt;But will the work still go forward for what that grant was meant to cover? With an annual budget of roughly $5 million, according to a recent blog post, the $1.5 million grant would’ve represented a 30% boost in funding (spread across over two years) — “easily the largest grant we’d ever received.”&lt;/p&gt;
    &lt;p&gt;As the group’s security developer-in-residence, Larson had hoped to use the grant to improve screening for attempted supply chain attacks on the official PyPI registry of Python packages. The PSF blog post says the plan was to build tools for automating package reviews “rather than the current process of reactive-only review.”&lt;/p&gt;
    &lt;p&gt;Larson told me last week that the grant they’d applied for “included funding for multiple contracted positions over the two-year work period.” Sadly, he told me, “The automated package reviewing pipeline as proposed in the grant has no timeline to be implemented given current circumstances.”&lt;/p&gt;
    &lt;p&gt;The larger open source community would’ve also benefited from the work, their blog post noted, since “the outputs of this work could be transferable for all open source software package registries, such as NPM and Crates.io, improving security across multiple open source ecosystems.”&lt;/p&gt;
    &lt;p&gt;But Larson told me that moving forward without the grant also leaves far less room for that “additional work required to create artifacts that are adaptable to more than one software ecosystem — like documentation showing design, operation, results and performance.”&lt;/p&gt;
    &lt;p&gt;And, “We’ll now have to balance the roadmap of work and maintenance on the Python Package Index (PyPI) and CPython with only existing security staffing. This leaves far less room for new large-scale projects.”&lt;/p&gt;
    &lt;head rend="h2"&gt;A Future With Funding?&lt;/head&gt;
    &lt;p&gt;Could that same security project still happen if new funding materializes? The PSF hasn’t entirely given up. “The PSF is always looking for new opportunities to fund work benefiting the Python community,” Nicholson told me in an email last week, adding pointedly that “we have received some helpful suggestions in response to our announcement that we will be pursuing.”&lt;/p&gt;
    &lt;p&gt;And even as things stand, the PSF sees itself as “always developing or implementing the latest technologies for protecting PyPI project maintainers and users from current threats,” and it plans to continue with that commitment. For example, it notes, PyPI today implements Trusted Publishing (a tightly scoped alternative to publisher-verifying API tokens), digital provenance attestations and the ongoing malware-blocking efforts of Project Quarantine.&lt;/p&gt;
    &lt;p&gt;The PSF also has ideas for increasing its other funding going forward. (“We’re looking at European grants, revenue sources that are tied to corporate usage, and increasing our individual giving program,” Nicholson told me.) “Ultimately, we do need some of these new revenue channels to pick up in order to continue serving our mission and the Python community the way we have been: Python and PyPI usage has grown steadily, especially since Python is essential to the recent explosion of the AI sector, while our funding has stayed essentially flat.”&lt;/p&gt;
    &lt;p&gt;But this latest show of community support is especially heartening, arriving in a time of inflation, tech-sector economic pressures and “lower sponsorship,” the PSF’s blog pointed out (along with the general uncertainty and conflict). Writing that the PSF “needs financial support now more than ever,” they’d urged readers to show their support by buying PSF memberships or making a donation, or by encouraging their company to become a sponsor.&lt;/p&gt;
    &lt;p&gt;“If you’re already a PSF member or regular donor, you have our deep appreciation,” they wrote, “and we urge you to share your story about why you support the PSF.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thenewstack.io/psf-gets-a-donor-surge-after-rejecting-anti-dei-federal-grant/"/><published>2025-11-09T17:28:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45867717</id><title>Drilling Down on Uncle Sam's Proposed TP-Link Ban</title><updated>2025-11-09T19:32:16.912166+00:00</updated><content>&lt;doc fingerprint="b6ccb110c1301700"&gt;
  &lt;main&gt;
    &lt;p&gt;The U.S. government is reportedly preparing to ban the sale of wireless routers and other networking gear from TP-Link Systems, a tech company that currently enjoys an estimated 50% market share among home users and small businesses. Experts say while the proposed ban may have more to do with TP-Link’s ties to China than any specific technical threats, much of the rest of the industry serving this market also sources hardware from China and ships products that are insecure fresh out of the box.&lt;/p&gt;
    &lt;p&gt;The Washington Post recently reported that more than a half-dozen federal departments and agencies were backing a proposed ban on future sales of TP-Link devices in the United States. The story said U.S. Department of Commerce officials concluded TP-Link Systems products pose a risk because the U.S.-based company’s products handle sensitive American data and because the officials believe it remains subject to jurisdiction or influence by the Chinese government.&lt;/p&gt;
    &lt;p&gt;TP-Link Systems denies that, saying that it fully split from the Chinese TP-Link Technologies over the past three years, and that its critics have vastly overstated the company’s market share (TP-Link puts it at around 30 percent). TP-Link says it has headquarters in California, with a branch in Singapore, and that it manufactures in Vietnam. The company says it researches, designs, develops and manufactures everything except its chipsets in-house.&lt;/p&gt;
    &lt;p&gt;TP-Link Systems told The Post it has sole ownership of some engineering, design and manufacturing capabilities in China that were once part of China-based TP-Link Technologies, and that it operates them without Chinese government supervision.&lt;/p&gt;
    &lt;p&gt;“TP-Link vigorously disputes any allegation that its products present national security risks to the United States,” Ricca Silverio, a spokeswoman for TP-Link Systems, said in a statement. “TP-Link is a U.S. company committed to supplying high-quality and secure products to the U.S. market and beyond.”&lt;/p&gt;
    &lt;p&gt;Cost is a big reason TP-Link devices are so prevalent in the consumer and small business market: As this February 2025 story from Wired observed regarding the proposed ban, TP-Link has long had a reputation for flooding the market with devices that are considerably cheaper than comparable models from other vendors. That price point (and consistently excellent performance ratings) has made TP-Link a favorite among Internet service providers (ISPs) that provide routers to their customers.&lt;/p&gt;
    &lt;p&gt;In August 2024, the chairman and the ranking member of the House Select Committee on the Strategic Competition Between the United States and the Chinese Communist Party called for an investigation into TP-Link devices, which they said were found on U.S. military bases and for sale at exchanges that sell them to members of the military and their families.&lt;/p&gt;
    &lt;p&gt;“TP-Link’s unusual degree of vulnerabilities and required compliance with PRC law are in and of themselves disconcerting,” the House lawmakers warned in a letter (PDF) to the director of the Commerce Department. “When combined with the PRC government’s common use of SOHO [small office/home office] routers like TP-Link to perpetrate extensive cyberattacks in the United States, it becomes significantly alarming.”&lt;/p&gt;
    &lt;p&gt;The letter cited a May 2023 blog post by Check Point Research about a Chinese state-sponsored hacking group dubbed “Camaro Dragon” that used a malicious firmware implant for some TP-Link routers to carry out a sequence of targeted cyberattacks against European foreign affairs entities. Check Point said while it only found the malicious firmware on TP-Link devices, “the firmware-agnostic nature of the implanted components indicates that a wide range of devices and vendors may be at risk.”&lt;/p&gt;
    &lt;p&gt;In a report published in October 2024, Microsoft said it was tracking a network of compromised TP-Link small office and home office routers that has been abused by multiple distinct Chinese state-sponsored hacking groups since 2021. Microsoft found the hacker groups were leveraging the compromised TP-Link systems to conduct “password spraying” attacks against Microsoft accounts. Password spraying involves rapidly attempting to access a large number of accounts (usernames/email addresses) with a relatively small number of commonly used passwords.&lt;/p&gt;
    &lt;p&gt;TP-Link rightly points out that most of its competitors likewise source components from China. The company also correctly notes that advanced persistent threat (APT) groups from China and other nations have leveraged vulnerabilities in products from their competitors, such as Cisco and Netgear.&lt;/p&gt;
    &lt;p&gt;But that may be cold comfort for TP-Link customers who are now wondering if it’s smart to continue using these products, or whether it makes sense to buy more costly networking gear that might only be marginally less vulnerable to compromise.&lt;/p&gt;
    &lt;p&gt;Almost without exception, the hardware and software that ships with most consumer-grade routers includes a number of default settings that need to be changed before the devices can be safely connected to the Internet. For example, bring a new router online without changing the default username and password and chances are it will only take a few minutes before it is probed and possibly compromised by some type of Internet-of-Things botnet. Also, it is incredibly common for the firmware in a brand new router to be dangerously out of date by the time it is purchased and unboxed.&lt;/p&gt;
    &lt;p&gt;Until quite recently, the idea that router manufacturers should make it easier for their customers to use these products safely was something of anathema to this industry. Consumers were largely left to figure that out on their own, with predictably disastrous results.&lt;/p&gt;
    &lt;p&gt;But over the past few years, many manufacturers of popular consumer routers have begun forcing users to perform basic hygiene — such as changing the default password and updating the internal firmware — before the devices can be used as a router. For example, most brands of “mesh” wireless routers — like Amazon’s Eero, Netgear’s Orbi series, or Asus’s ZenWifi — require online registration that automates these critical steps going forward (or at least through their stated support lifecycle).&lt;/p&gt;
    &lt;p&gt;For better or worse, less expensive, traditional consumer routers like those from Belkin and Linksys also now automate this setup by heavily steering customers toward installing a mobile app to complete the installation (this often comes as a shock to people more accustomed to manually configuring a router). Still, these products tend to put the onus on users to check for and install available updates periodically. Also, they’re often powered by underwhelming or else bloated firmware, and a dearth of configurable options.&lt;/p&gt;
    &lt;p&gt;Of course, not everyone wants to fiddle with mobile apps or is comfortable with registering their router so that it can be managed or monitored remotely in the cloud. For those hands-on folks — and for power users seeking more advanced router features like VPNs, ad blockers and network monitoring — the best advice is to check if your router’s stock firmware can be replaced with open-source alternatives, such as OpenWrt or DD-WRT.&lt;/p&gt;
    &lt;p&gt;These open-source firmware options are compatible with a wide range of devices, and they generally offer more features and configurability. Open-source firmware can even help extend the life of routers years after the vendor stops supporting the underlying hardware, but it still requires users to manually check for and install any available updates.&lt;/p&gt;
    &lt;p&gt;Happily, TP-Link users spooked by the proposed ban may have an alternative to outright junking these devices, as many TP-Link routers also support open-source firmware options like OpenWRT. While this approach may not eliminate any potential hardware-specific security flaws, it could serve as an effective hedge against more common vendor-specific vulnerabilities, such as undocumented user accounts, hard-coded credentials, and weaknesses that allow attackers to bypass authentication.&lt;/p&gt;
    &lt;p&gt;Regardless of the brand, if your router is more than four or five years old it may be worth upgrading for performance reasons alone — particularly if your home or office is primarily accessing the Internet through WiFi.&lt;/p&gt;
    &lt;p&gt;NB: The Post’s story notes that a substantial portion of TP-Link routers and those of its competitors are purchased or leased through ISPs. In these cases, the devices are typically managed and updated remotely by your ISP, and equipped with custom profiles responsible for authenticating your device to the ISP’s network. If this describes your setup, please do not attempt to modify or replace these devices without first consulting with your Internet provider.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://krebsonsecurity.com/2025/11/drilling-down-on-uncle-sams-proposed-tp-link-ban/"/><published>2025-11-09T18:17:44+00:00</published></entry></feed>