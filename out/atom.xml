<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-09T19:12:34.817434+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46547740</id><title>Embassy: Modern embedded framework, using Rust and async</title><updated>2026-01-09T19:12:44.860415+00:00</updated><content>&lt;doc fingerprint="7b05f0bb442a83d4"&gt;
  &lt;main&gt;
    &lt;p&gt;Embassy is the next-generation framework for embedded applications. Write safe, correct, and energy-efficient embedded code faster, using the Rust programming language, its async facilities, and the Embassy libraries.&lt;/p&gt;
    &lt;p&gt;The Rust programming language is blazingly fast and memory-efficient, with no runtime, garbage collector, or OS. It catches a wide variety of bugs at compile time, thanks to its full memory- and thread-safety, and expressive type system.&lt;/p&gt;
    &lt;p&gt;Rust's async/await allows for unprecedentedly easy and efficient multitasking in embedded systems. Tasks get transformed at compile time into state machines that get run cooperatively. It requires no dynamic memory allocation and runs on a single stack, so no per-task stack size tuning is required. It obsoletes the need for a traditional RTOS with kernel context switching, and is faster and smaller than one!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Hardware Abstraction Layers&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;HALs implement safe, idiomatic Rust APIs to use the hardware capabilities, so raw register manipulation is not needed. The Embassy project maintains HALs for select hardware, but you can still use HALs from other projects with Embassy.&lt;/item&gt;
          &lt;item&gt;embassy-stm32, for all STM32 microcontroller families.&lt;/item&gt;
          &lt;item&gt;embassy-nrf, for the Nordic Semiconductor nRF52, nRF53, nRF54 and nRF91 series.&lt;/item&gt;
          &lt;item&gt;embassy-rp, for the Raspberry Pi RP2040 and RP23xx microcontrollers.&lt;/item&gt;
          &lt;item&gt;embassy-mspm0, for the Texas Instruments MSPM0 microcontrollers.&lt;/item&gt;
          &lt;item&gt;esp-rs, for the Espressif Systems ESP32 series of chips. &lt;list rend="ul"&gt;&lt;item&gt;Embassy HAL support for Espressif chips, as well as Async Wi-Fi, Bluetooth, and ESP-NOW, is being developed in the esp-rs/esp-hal repository.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;ch32-hal, for the WCH 32-bit RISC-V(CH32V) series of chips.&lt;/item&gt;
          &lt;item&gt;mpfs-hal, for the Microchip PolarFire SoC.&lt;/item&gt;
          &lt;item&gt;py32-hal, for the Puya Semiconductor PY32 series of microcontrollers.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Time that Just Works - No more messing with hardware timers. embassy_time provides Instant, Duration, and Timer types that are globally available and never overflow.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Real-time ready - Tasks on the same async executor run cooperatively, but you can create multiple executors with different priorities so that higher priority tasks preempt lower priority ones. See the example.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Low-power ready - Easily build devices with years of battery life. The async executor automatically puts the core to sleep when there's no work to do. Tasks are woken by interrupts, there is no busy-loop polling while waiting.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Networking - The embassy-net network stack implements extensive networking functionality, including Ethernet, IP, TCP, UDP, ICMP, and DHCP. Async drastically simplifies managing timeouts and serving multiple connections concurrently.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bluetooth&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;The trouble crate provides a Bluetooth Low Energy 4.x and 5.x Host that runs on any microcontroller implementing the bt-hci traits (currently &lt;code&gt;nRF52&lt;/code&gt;,&lt;code&gt;nrf54&lt;/code&gt;,&lt;code&gt;rp2040&lt;/code&gt;,&lt;code&gt;rp23xx&lt;/code&gt;and&lt;code&gt;esp32&lt;/code&gt;and&lt;code&gt;serial&lt;/code&gt;controllers are supported).&lt;/item&gt;
          &lt;item&gt;The nrf-softdevice crate provides Bluetooth Low Energy 4.x and 5.x support for nRF52 microcontrollers.&lt;/item&gt;
          &lt;item&gt;The embassy-stm32-wpan crate provides Bluetooth Low Energy 5.x support for stm32wb microcontrollers.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;The trouble crate provides a Bluetooth Low Energy 4.x and 5.x Host that runs on any microcontroller implementing the bt-hci traits (currently &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LoRa - The lora-rs project provides an async LoRa and LoRaWAN stack that works well on Embassy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;USB - embassy-usb implements a device-side USB stack. Implementations for common classes such as USB serial (CDC ACM) and USB HID are available, and a rich builder API allows building your own.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bootloader and DFU - embassy-boot is a lightweight bootloader supporting firmware application upgrades in a power-fail-safe way, with trial boots and rollbacks.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;use defmt::info;
use embassy_executor::Spawner;
use embassy_time::{Duration, Timer};
use embassy_nrf::gpio::{AnyPin, Input, Level, Output, OutputDrive, Pin, Pull};
use embassy_nrf::{Peri, Peripherals};

// Declare async tasks
#[embassy_executor::task]
async fn blink(pin: Peri&amp;lt;'static, AnyPin&amp;gt;) {
    let mut led = Output::new(pin, Level::Low, OutputDrive::Standard);

    loop {
        // Timekeeping is globally available, no need to mess with hardware timers.
        led.set_high();
        Timer::after_millis(150).await;
        led.set_low();
        Timer::after_millis(150).await;
    }
}

// Main is itself an async task as well.
#[embassy_executor::main]
async fn main(spawner: Spawner) {
    let p = embassy_nrf::init(Default::default());

    // Spawned tasks run in the background, concurrently.
    spawner.spawn(blink(p.P0_13.into()).unwrap());

    let mut button = Input::new(p.P0_11, Pull::Up);
    loop {
        // Asynchronously wait for GPIO events, allowing other tasks
        // to run, or the core to sleep.
        button.wait_for_low().await;
        info!("Button pressed!");
        button.wait_for_high().await;
        info!("Button released!");
    }
}&lt;/code&gt;
    &lt;p&gt;Examples are found in the &lt;code&gt;examples/&lt;/code&gt; folder separated by the chip manufacturer they are designed to run on. For example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;examples/nrf52840&lt;/code&gt;run on the&lt;code&gt;nrf52840-dk&lt;/code&gt;board (PCA10056) but should be easily adaptable to other nRF52 chips and boards.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;examples/nrf5340&lt;/code&gt;run on the&lt;code&gt;nrf5340-dk&lt;/code&gt;board (PCA10095).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;examples/stm32xx&lt;/code&gt;for the various STM32 families.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;examples/rp&lt;/code&gt;are for the RP2040 chip.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;examples/std&lt;/code&gt;are designed to run locally on your PC.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install &lt;code&gt;probe-rs&lt;/code&gt;following the instructions at https://probe.rs.&lt;/item&gt;
      &lt;item&gt;Change directory to the sample's base directory. For example:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cd examples/nrf52840&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Ensure&lt;/p&gt;&lt;code&gt;Cargo.toml&lt;/code&gt;sets the right feature for the name of the chip you are programming. If this name is incorrect, the example may fail to run or immediately crash after being programmed.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Ensure&lt;/p&gt;&lt;code&gt;.cargo/config.toml&lt;/code&gt;contains the name of the chip you are programming.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run the example&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;cargo run --release --bin blinky&lt;/code&gt;
    &lt;p&gt;For more help getting started, see Getting Started and Running the Examples.&lt;/p&gt;
    &lt;p&gt;The Rust Analyzer is used by Visual Studio Code and others. Given the multiple targets that Embassy serves, there is no Cargo workspace file. Instead, the Rust Analyzer must be told of the target project to work with. In the case of Visual Studio Code, please refer to the &lt;code&gt;.vscode/settings.json&lt;/code&gt; file's &lt;code&gt;rust-analyzer.linkedProjects&lt;/code&gt;setting.&lt;/p&gt;
    &lt;p&gt;Embassy is guaranteed to compile on stable Rust 1.75 and up. It might compile with older versions, but that may change in any new patch release.&lt;/p&gt;
    &lt;p&gt;EMBedded ASYnc! :)&lt;/p&gt;
    &lt;p&gt;Embassy is licensed under either of&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apache License, Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0)&lt;/item&gt;
      &lt;item&gt;MIT license (LICENSE-MIT or http://opensource.org/licenses/MIT)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;at your option.&lt;/p&gt;
    &lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/embassy-rs/embassy"/><published>2026-01-08T23:00:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46547962</id><title>Scientists discover oldest poison, on 60k-year-old arrows</title><updated>2026-01-09T19:12:44.803522+00:00</updated><content/><link href="https://www.nytimes.com/2026/01/07/science/poison-arrows-south-africa.html"/><published>2026-01-08T23:24:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46549333</id><title>Show HN: Various shape regularization algorithms</title><updated>2026-01-09T19:12:44.279615+00:00</updated><content>&lt;doc fingerprint="6cfc9320f7d44fe"&gt;
  &lt;main&gt;
    &lt;p&gt;A Python implementation of various shape regularization algorithms for regularizing line segments and closed contours.&lt;/p&gt;
    &lt;p&gt;Shape regularization is a technique used in computational geometry to clean up noisy or imprecise geometric data by aligning segments to common orientations and adjusting their positions to create cleaner, more regular shapes.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Segment Regularization: Align line segments to common angles and offsets using quadratic programming optimization&lt;/item&gt;
      &lt;item&gt;Snap Regularization: Connect nearby endpoints to create watertight polygons and meshes&lt;/item&gt;
      &lt;item&gt;Metric Regularization: Constrain segment dimensions - equal lengths, length quantization, and equal spacing&lt;/item&gt;
      &lt;item&gt;Contour Regularization: Simplify closed polygons by aligning edges to principal directions&lt;/item&gt;
      &lt;item&gt;T-Junction Detection: Snap endpoints onto segment interiors for proper connectivity&lt;/item&gt;
      &lt;item&gt;Flexible Configuration: Control maximum angle and offset tolerances&lt;/item&gt;
      &lt;item&gt;Visualization: Built-in plotting utilities for before/after comparisons&lt;/item&gt;
      &lt;item&gt;Pure Python: No dependencies required&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install shreg&lt;/code&gt;
    &lt;code&gt;uv pip install shreg&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/nickp/shreg.git
cd shreg
pip install -e .&lt;/code&gt;
    &lt;p&gt;Regularize a set of line segments by aligning their angles and offsets:&lt;/p&gt;
    &lt;code&gt;import numpy as np
from shreg import solve_line_segments, seg

# Create some segments (each segment is [x1, y1, x2, y2])
segments = [
    seg(0.0, 0.0, 1.0, 0.02),   # Nearly horizontal
    seg(0.0, 1.0, 1.0, 1.05),   # Nearly horizontal, slightly offset
    seg(1.0, 0.0, 1.02, 1.0),   # Nearly vertical
]

# Regularize: align angles within 25 degrees, offsets within 0.5 units
result = solve_line_segments(
    segments,
    angle=True,
    offset=True,
    maximum_angle=25,
    maximum_offset=0.5
)&lt;/code&gt;
    &lt;p&gt;Close gaps between nearby endpoints to create watertight polygons:&lt;/p&gt;
    &lt;code&gt;from shreg import snap_regularize_segments, seg

# Create segments with small gaps at corners
segments = [
    seg(0.0, 0.0, 1.0, 0.0),    # bottom edge
    seg(1.05, 0.02, 1.0, 1.0),  # right edge (gap at bottom-right)
    seg(1.0, 1.03, 0.0, 0.98),  # top edge (gap at corners)
    seg(-0.02, 1.0, 0.0, 0.0),  # left edge (gap at top-left)
]

# Snap endpoints within 0.1 units of each other
result = snap_regularize_segments(
    segments,
    epsilon=0.1,      # Distance threshold for snapping
    method="cluster"  # Fast centroid-based method
)
# Result: All corners are now perfectly connected&lt;/code&gt;
    &lt;p&gt;Constrain segment dimensions - force equal lengths, quantize to grid units, or equalize spacing:&lt;/p&gt;
    &lt;code&gt;from shreg import metric_regularize_segments, seg

# Segments with slightly different lengths and uneven spacing
segments = [
    seg(0.0, 0.0, 1.9, 0.0),   # length ~2
    seg(0.0, 0.9, 2.1, 0.9),   # length ~2, y=0.9 (should be 1.0)
    seg(0.0, 2.0, 1.95, 2.0),  # length ~2
]

# Regularize: equal lengths, snap to 1-unit grid, equalize spacing
result = metric_regularize_segments(
    segments,
    equal_length=True,         # Force similar lengths to be equal
    length_quantization=True,  # Snap lengths to multiples of base_unit
    equal_spacing=True,        # Equalize gaps between parallel lines
    base_unit=1.0,             # Grid unit for quantization
)
# Result: All segments have length 2.0 and are evenly spaced at y=0, 1, 2&lt;/code&gt;
    &lt;p&gt;Simplify a closed polygon by aligning edges to principal directions:&lt;/p&gt;
    &lt;code&gt;from shreg import regularize_contour

# Define a noisy polygon (list of [x, y] points)
points = [
    [45, 29], [65, 440], [44, 498], [446, 498], [429, 325],
    [499, 309], [448, 206], [479, 148], [479, 31], [247, 88],
]

# Regularize with axis alignment
result = regularize_contour(
    points,
    principle="axis",     # Align to horizontal/vertical
    max_offset=20,        # Maximum offset for merging
)

print(f"Simplified from {len(points)} to {len(result)} points")&lt;/code&gt;
    &lt;p&gt;The algorithm optimizes segment orientations and positions to create cleaner line arrangements:&lt;/p&gt;
    &lt;p&gt;Angle regularization aligns crossing lines to common orientations:&lt;/p&gt;
    &lt;p&gt;Combined angle and offset regularization on a hexagon:&lt;/p&gt;
    &lt;p&gt;This example from the CGAL documentation demonstrates sequential angle and offset regularization on 15 segments organized into three groups: outer boundary, top rhombus, and bottom rhombus.&lt;/p&gt;
    &lt;code&gt;from shreg import solve_line_segments, create_cgal_example

# Load the 15 segments from the CGAL example
segments, groups = create_cgal_example()

# Regularize with tight tolerances
result = solve_line_segments(
    segments,
    angle=True,
    offset=True,
    maximum_angle=10,    # 10 degrees max angle deviation
    maximum_offset=0.1   # 0.1 units max offset
)&lt;/code&gt;
    &lt;p&gt;Snap regularization connects nearby endpoints to create watertight geometry. This is essential for creating closed polygons suitable for 3D extrusion, mesh generation, or CAD operations.&lt;/p&gt;
    &lt;p&gt;The cluster method groups nearby endpoints and moves them to their centroid. This is the fastest approach and guarantees watertight results:&lt;/p&gt;
    &lt;code&gt;from shreg import snap_regularize_segments, seg

segments = [
    seg(0.0, 0.0, 1.0, 0.05),
    seg(1.08, 0.0, 1.05, 1.0),
    seg(1.0, 1.08, 0.0, 0.95),
    seg(-0.05, 1.0, 0.0, 0.0),
]
result = snap_regularize_segments(segments, epsilon=0.15, method="cluster")&lt;/code&gt;
    &lt;p&gt;Hard constraints use quadratic programming to find the optimal positions that exactly satisfy all snap constraints while minimizing total endpoint movement:&lt;/p&gt;
    &lt;code&gt;result = snap_regularize_segments(segments, epsilon=0.15, method="hard")&lt;/code&gt;
    &lt;p&gt;Soft constraints add "spring" forces between endpoints that should connect. This is useful when data is noisy and you're not certain endpoints should be exactly coincident:&lt;/p&gt;
    &lt;code&gt;result = snap_regularize_segments(
    segments,
    epsilon=0.25,
    method="soft",
    soft_weight=50.0  # Higher = stiffer springs
)&lt;/code&gt;
    &lt;p&gt;T-junctions occur when an endpoint should snap onto another segment's interior (not its endpoints). Enable T-junction detection for proper connectivity:&lt;/p&gt;
    &lt;code&gt;segments = [
    seg(0.0, 0.0, 2.0, 0.0),      # horizontal line
    seg(0.0, 1.0, 2.0, 1.0),      # horizontal line
    seg(0.95, -0.08, 1.05, 1.1),  # vertical line (forms T-junctions)
]
result = snap_regularize_segments(
    segments, epsilon=0.15, method="cluster", t_junctions=True
)&lt;/code&gt;
    &lt;p&gt;Snap regularization works on polygons of any complexity:&lt;/p&gt;
    &lt;p&gt;Metric regularization constrains the relative measurements of segments. This is useful for architectural drawings, CAD cleanup, and any domain where dimensions should follow regular patterns.&lt;/p&gt;
    &lt;p&gt;Forces segments with similar lengths to be exactly equal. Useful when objects (like windows or columns) should have identical dimensions:&lt;/p&gt;
    &lt;code&gt;from shreg import metric_regularize_segments, seg

segments = [
    seg(0.0, 0.0, 2.0, 0.0),    # length 2.0
    seg(0.0, 1.0, 2.15, 1.0),   # length 2.15
    seg(0.0, 2.0, 1.9, 2.0),    # length 1.9
    seg(0.0, 3.0, 2.05, 3.0),   # length 2.05
]

result = metric_regularize_segments(
    segments,
    equal_length=True,
    length_tolerance=0.15,  # 15% relative tolerance
)
# Result: All segments now have equal length (~2.0)&lt;/code&gt;
    &lt;p&gt;Snaps segment lengths to integer multiples of a base unit. Essential for architectural plans where walls must be multiples of a grid unit:&lt;/p&gt;
    &lt;code&gt;segments = [
    seg(0.0, 0.0, 1.85, 0.0),   # length 1.85 -&amp;gt; 2.0
    seg(0.0, 1.0, 3.15, 1.0),   # length 3.15 -&amp;gt; 3.0
    seg(0.0, 2.0, 0.9, 2.0),    # length 0.9 -&amp;gt; 1.0
    seg(0.0, 3.0, 2.2, 3.0),    # length 2.2 -&amp;gt; 2.0
]

result = metric_regularize_segments(
    segments,
    length_quantization=True,
    base_unit=1.0,              # Snap to 1-meter multiples
    quantization_tolerance=0.3, # Within 30% of base unit
)&lt;/code&gt;
    &lt;p&gt;Forces equal gaps between parallel lines. Perfect for regularizing staircases, window arrays, or any repeated elements:&lt;/p&gt;
    &lt;code&gt;segments = [
    seg(0.0, 0.0, 3.0, 0.0),    # y=0.0
    seg(0.0, 0.9, 3.0, 0.9),    # y=0.9 (uneven)
    seg(0.0, 2.0, 3.0, 2.0),    # y=2.0
    seg(0.0, 3.1, 3.0, 3.1),    # y=3.1 (uneven)
    seg(0.0, 4.0, 3.0, 4.0),    # y=4.0
]

result = metric_regularize_segments(
    segments,
    equal_spacing=True,
    angle_tolerance=5.0,  # Lines within 5° are considered parallel
)
# Result: Lines are now evenly spaced at y=0, 1, 2, 3, 4&lt;/code&gt;
    &lt;p&gt;Simplify complex polygons while preserving their essential shape:&lt;/p&gt;
    &lt;p&gt;Complex shapes are reduced to their essential vertices:&lt;/p&gt;
    &lt;p&gt;Regularize a list of line segments.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;segments&lt;/code&gt;: List of segments, where each segment is a numpy array&lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;offset&lt;/code&gt;: Whether to regularize offsets (default:&lt;code&gt;True&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;angle&lt;/code&gt;: Whether to regularize angles (default:&lt;code&gt;True&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;maximum_offset&lt;/code&gt;: Maximum offset tolerance in units (default:&lt;code&gt;0.5&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;maximum_angle&lt;/code&gt;: Maximum angle tolerance in degrees (default:&lt;code&gt;25&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: List of regularized segments&lt;/p&gt;
    &lt;p&gt;Helper function to create a segment array.&lt;/p&gt;
    &lt;code&gt;from shreg import seg
s = seg(0, 0, 1, 1)  # Creates np.array([0, 0, 1, 1])&lt;/code&gt;
    &lt;head rend="h4"&gt;
      &lt;code&gt;snap_regularize_segments(segments, epsilon=1.0, method="hard", soft_weight=100.0, t_junctions=False)&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;Connect nearby endpoints by snapping them together.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;segments&lt;/code&gt;: List of segments, where each segment is a numpy array&lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;epsilon&lt;/code&gt;: Maximum distance for endpoints to be considered "close" and snapped (default:&lt;code&gt;1.0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;method&lt;/code&gt;: Snapping method to use:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;"cluster"&lt;/code&gt;: Fast centroid-based method (recommended for most cases)&lt;/item&gt;&lt;item&gt;&lt;code&gt;"hard"&lt;/code&gt;: QP with exact equality constraints (perfectly watertight)&lt;/item&gt;&lt;item&gt;&lt;code&gt;"soft"&lt;/code&gt;: QP with spring penalty (elastic connections)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;soft_weight&lt;/code&gt;: Spring stiffness for soft constraints. Higher values = stiffer springs (default:&lt;code&gt;100.0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;t_junctions&lt;/code&gt;: Whether to detect and snap T-junctions (default:&lt;code&gt;False&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: List of segments with snapped endpoints&lt;/p&gt;
    &lt;p&gt;Find clusters of nearby endpoints using spatial indexing.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;segments&lt;/code&gt;: List of segments&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;epsilon&lt;/code&gt;: Maximum distance for clustering&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: List of clusters, where each cluster is a list of &lt;code&gt;(segment_idx, endpoint_idx)&lt;/code&gt; tuples&lt;/p&gt;
    &lt;p&gt;Find T-junctions where endpoints are close to segment interiors.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;segments&lt;/code&gt;: List of segments&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;epsilon&lt;/code&gt;: Maximum distance for T-junction detection&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;exclude_clusters&lt;/code&gt;: Endpoint clusters to exclude (already handled by endpoint-to-endpoint snapping)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: List of &lt;code&gt;((segment_idx, endpoint_idx), target_segment_idx)&lt;/code&gt; tuples&lt;/p&gt;
    &lt;head rend="h4"&gt;
      &lt;code&gt;metric_regularize_segments(segments, equal_length=True, length_quantization=False, equal_spacing=True, base_unit=1.0, length_tolerance=0.1, quantization_tolerance=0.3, angle_tolerance=5.0, max_iterations=3)&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;Regularize segments using metric and pattern constraints.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;segments&lt;/code&gt;: List of segments, where each segment is a numpy array&lt;code&gt;[x1, y1, x2, y2]&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;equal_length&lt;/code&gt;: Force segments with similar lengths to be exactly equal (default:&lt;code&gt;True&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;length_quantization&lt;/code&gt;: Snap lengths to multiples of&lt;code&gt;base_unit&lt;/code&gt;(default:&lt;code&gt;False&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;equal_spacing&lt;/code&gt;: Force equal gaps between parallel lines (default:&lt;code&gt;True&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;base_unit&lt;/code&gt;: Base unit for length quantization, e.g., 1.0 meter (default:&lt;code&gt;1.0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;length_tolerance&lt;/code&gt;: Relative tolerance for equal length detection (default:&lt;code&gt;0.1&lt;/code&gt;= 10%)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;quantization_tolerance&lt;/code&gt;: Tolerance for quantization as fraction of&lt;code&gt;base_unit&lt;/code&gt;(default:&lt;code&gt;0.3&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;angle_tolerance&lt;/code&gt;: Maximum angle difference in degrees to consider lines parallel (default:&lt;code&gt;5.0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;max_iterations&lt;/code&gt;: Maximum SQP iterations for iterative refinement (default:&lt;code&gt;3&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: List of regularized segments&lt;/p&gt;
    &lt;p&gt;Note: Uses linearization since length calculation is non-linear. The algorithm iteratively refines the solution using Sequential Quadratic Programming (SQP).&lt;/p&gt;
    &lt;p&gt;Find pairs of segments with similar lengths.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;segments&lt;/code&gt;: List of segments&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tolerance&lt;/code&gt;: Maximum relative length difference to consider "similar" (default:&lt;code&gt;0.1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;min_length&lt;/code&gt;: Minimum segment length to consider (default:&lt;code&gt;0.5&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: List of &lt;code&gt;(segment_idx_a, segment_idx_b)&lt;/code&gt; tuples&lt;/p&gt;
    &lt;p&gt;Find segments whose lengths should be quantized to multiples of &lt;code&gt;base_unit&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;segments&lt;/code&gt;: List of segments&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;base_unit&lt;/code&gt;: Base unit for quantization (default:&lt;code&gt;1.0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tolerance&lt;/code&gt;: Maximum distance from nearest multiple as fraction of&lt;code&gt;base_unit&lt;/code&gt;(default:&lt;code&gt;0.3&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;min_length&lt;/code&gt;: Minimum segment length to consider (default:&lt;code&gt;0.5&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: List of &lt;code&gt;(segment_idx, target_length)&lt;/code&gt; tuples&lt;/p&gt;
    &lt;p&gt;Find groups of parallel segments for equal spacing regularization.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;segments&lt;/code&gt;: List of segments&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;angle_tolerance&lt;/code&gt;: Maximum angle difference in degrees to consider parallel (default:&lt;code&gt;5.0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;min_group_size&lt;/code&gt;: Minimum number of segments to form a group (default:&lt;code&gt;3&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: List of groups, where each group is a list of segment indices&lt;/p&gt;
    &lt;p&gt;Regularize a closed contour.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;points&lt;/code&gt;: List of&lt;code&gt;[x, y]&lt;/code&gt;coordinates forming a closed polygon&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;principle&lt;/code&gt;: How to determine principal directions:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;"longest"&lt;/code&gt;: Use the longest edge as reference&lt;/item&gt;&lt;item&gt;&lt;code&gt;"axis"&lt;/code&gt;: Align to horizontal/vertical axes&lt;/item&gt;&lt;item&gt;&lt;code&gt;"cardinal"&lt;/code&gt;: Use 0, 45, 90, 135 degree directions&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;max_offset&lt;/code&gt;: Maximum offset for merging parallel segments (default:&lt;code&gt;20.0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;visualize&lt;/code&gt;: Whether to show intermediate plots (default:&lt;code&gt;False&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns: numpy array of regularized points&lt;/p&gt;
    &lt;p&gt;Load contour points from a polylines file.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;filename&lt;/code&gt;: Path to polylines file. If&lt;code&gt;None&lt;/code&gt;, loads bundled example data.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The package includes various geometry functions:&lt;/p&gt;
    &lt;code&gt;from shreg import (
    length,              # Segment length
    midpoint,            # Segment midpoint
    orientation,         # Segment orientation in degrees [0, 180)
    direction,           # Unit direction vector
    normal,              # Unit normal vector
    rotate,              # Rotate segment around midpoint
    translate_by_normal, # Translate along normal
    angle_difference,    # Angle difference modulo 90 degrees
)&lt;/code&gt;
    &lt;code&gt;from shreg import plotting

# Enable/disable all plotting
plotting.enable()
plotting.disable()

# Before/after comparison
plotting.comparison(before_segments, after_segments, title="My Title")

# Context manager for before/after
with plotting.BeforeAfter("My Title") as plot:
    plot.before(segments)
    segments = regularize(segments)
    plot.after(segments)

# Save plots to file
plotting.comparison(before, after, save_path="output.png")&lt;/code&gt;
    &lt;p&gt;Run the demo examples:&lt;/p&gt;
    &lt;code&gt;# Run all examples with visualization
shreg

# Run without visualization (batch mode)
shreg --no-plot

# Run only segment examples
shreg --segments

# Run only contour examples
shreg --contours&lt;/code&gt;
    &lt;p&gt;Or using Python module syntax:&lt;/p&gt;
    &lt;code&gt;python -m shreg --help&lt;/code&gt;
    &lt;p&gt;The regularization problem is formulated as an energy minimization problem. Given a set of segments, we seek small adjustments (rotations and translations) that minimize an energy function while respecting constraints on maximum deviations.&lt;/p&gt;
    &lt;p&gt;The energy function balances two objectives:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fidelity: Keep segments close to their original positions&lt;/item&gt;
      &lt;item&gt;Regularity: Encourage nearby segments to share common angles and offsets&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This leads to a quadratic program (QP) of the form:&lt;/p&gt;
    &lt;code&gt;minimize    (1/2) x'Px + q'x
subject to  l &amp;lt;= Ax &amp;lt;= u
&lt;/code&gt;
    &lt;p&gt;where &lt;code&gt;x&lt;/code&gt; contains the rotation and translation corrections for each segment, &lt;code&gt;P&lt;/code&gt; encodes the fidelity cost, and the constraints enforce that angle/offset differences between nearby segments are minimized.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Neighbor Detection: Use Delaunay triangulation on segment midpoints to identify nearby segment pairs efficiently&lt;/item&gt;
      &lt;item&gt;Constraint Graph: Build constraints for angle and offset differences between neighboring segments within tolerance bounds&lt;/item&gt;
      &lt;item&gt;QP Optimization: Solve the quadratic program using OSQP to find optimal corrections&lt;/item&gt;
      &lt;item&gt;Application: Apply computed rotations and translations to each segment&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Snap regularization is formulated as a Constrained Quadratic Programming problem that minimizes endpoint movement while enforcing connectivity constraints.&lt;/p&gt;
    &lt;p&gt;Variables: For N segments, the state vector contains all 4N endpoint coordinates:&lt;/p&gt;
    &lt;code&gt;x = [x₁₁, y₁₁, x₁₂, y₁₂, ..., xₙ₂, yₙ₂]ᵀ
&lt;/code&gt;
    &lt;p&gt;Objective (Fidelity): Minimize squared distance from original positions:&lt;/p&gt;
    &lt;code&gt;minimize (1/2) Σᵢ (||uᵢ - ûᵢ||² + ||vᵢ - v̂ᵢ||²)
&lt;/code&gt;
    &lt;p&gt;Methods:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
        &lt;cell role="head"&gt;Formulation&lt;/cell&gt;
        &lt;cell role="head"&gt;Use Case&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;cluster&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Replace clustered endpoints with centroid&lt;/cell&gt;
        &lt;cell&gt;Fast, guaranteed watertight&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;hard&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Equality constraints: vᵢ - uⱼ = 0&lt;/cell&gt;
        &lt;cell&gt;Exact connections required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;soft&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Penalty term: λ·Σ&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Pipeline:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Endpoint Detection: Build KD-Tree on all 2N endpoints&lt;/item&gt;
      &lt;item&gt;Clustering: Use Union-Find to group endpoints within ε distance&lt;/item&gt;
      &lt;item&gt;Variable Reduction (cluster): Replace clusters with single variables&lt;/item&gt;
      &lt;item&gt;QP Solve (hard/soft): Optimize using OSQP&lt;/item&gt;
      &lt;item&gt;T-Junction Handling: Project endpoints onto target segments&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Metric regularization constrains segment dimensions (length, distance). The challenge is that length calculation &lt;code&gt;√(Δx² + Δy²)&lt;/code&gt; is non-linear, but QP solvers require linear constraints.&lt;/p&gt;
    &lt;p&gt;Linearization: We approximate length using the segment's unit direction vector d = (dₓ, dᵧ):&lt;/p&gt;
    &lt;code&gt;L ≈ dₓ(xₑ - xₛ) + dᵧ(yₑ - yₛ)
&lt;/code&gt;
    &lt;p&gt;This is linear in the endpoint coordinates and can be directly inserted into the constraint matrix.&lt;/p&gt;
    &lt;p&gt;Constraint Formulations:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Constraint&lt;/cell&gt;
        &lt;cell role="head"&gt;Mathematical Form&lt;/cell&gt;
        &lt;cell role="head"&gt;Application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Equal Length&lt;/cell&gt;
        &lt;cell&gt;L_A - L_B = 0&lt;/cell&gt;
        &lt;cell&gt;Windows, columns&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Quantization&lt;/cell&gt;
        &lt;cell&gt;L = K (target)&lt;/cell&gt;
        &lt;cell&gt;Grid snapping&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Equal Spacing&lt;/cell&gt;
        &lt;cell&gt;2·Pos(L₂) - Pos(L₁) - Pos(L₃) = 0&lt;/cell&gt;
        &lt;cell&gt;Stairs, arrays&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Iterative Refinement (SQP): Because the unit vectors are computed from the current geometry, results are approximate if segments rotate significantly. The algorithm uses Sequential Quadratic Programming:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Compute unit vectors from current segment orientations&lt;/item&gt;
      &lt;item&gt;Build and solve the QP&lt;/item&gt;
      &lt;item&gt;Update segment coordinates&lt;/item&gt;
      &lt;item&gt;Repeat until convergence (or max iterations)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Pipeline:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Detection: Find candidate pairs/groups (similar lengths, parallel lines)&lt;/item&gt;
      &lt;item&gt;Linearization: Compute unit direction vectors for length approximation&lt;/item&gt;
      &lt;item&gt;Constraint Building: Build sparse constraint matrix A for detected patterns&lt;/item&gt;
      &lt;item&gt;QP Solve: Minimize ||x - x̂||² subject to Ax = b using OSQP&lt;/item&gt;
      &lt;item&gt;Iteration: Refine unit vectors and re-solve if needed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The contour regularization algorithm follows CGAL's approach for closed polygons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Angle Alignment: Rotate each edge to align with principal directions (modulo 90 degrees)&lt;/item&gt;
      &lt;item&gt;Parallel Merging: Merge consecutive parallel edges that are close together&lt;/item&gt;
      &lt;item&gt;Link Insertion: Insert connecting segments between remaining parallel edges&lt;/item&gt;
      &lt;item&gt;Intersection: Compute intersection points to form the final regularized polygon&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;numpy &amp;gt;= 1.20.0&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;scipy &amp;gt;= 1.7.0&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;osqp &amp;gt;= 0.6.0&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;matplotlib &amp;gt;= 3.5.0&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Install development dependencies:&lt;/p&gt;
    &lt;code&gt;pip install -e ".[dev]"&lt;/code&gt;
    &lt;p&gt;Run tests:&lt;/p&gt;
    &lt;code&gt;pytest tests/ -v&lt;/code&gt;
    &lt;p&gt;Run tests with coverage:&lt;/p&gt;
    &lt;code&gt;pytest tests/ -v --cov=shreg --cov-report=term-missing&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Jean-Philippe Bauchet and Florent Lafarge. KIPPI: KInetic Polygonal Partitioning of Images. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3146–3154, Salt Lake City, United States, June 2018. [PDF]&lt;/item&gt;
      &lt;item&gt;CGAL Shape Regularization Documentation&lt;/item&gt;
      &lt;item&gt;OSQP: Operator Splitting Quadratic Program Solver&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/nickponline/shreg"/><published>2026-01-09T02:13:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46550453</id><title>Agonist-Antagonist Myoneural Interface</title><updated>2026-01-09T19:12:44.058487+00:00</updated><content>&lt;doc fingerprint="f778dbc8b8e9c461"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Humans can accurately sense the position, speed, and torque of their limbs, even with their eyes shut. This sense, known as proprioception, allows humans to precisely control their body movements.&lt;/head&gt;
    &lt;p&gt;Today’s conventional prosthetic limbs do not provide feedback to the nervous system. Because of this, people with amputated limbs cannot feel the position, speed, and torque of their prosthetic joints without looking at them, making it difficult to control their movement. In order to create a more complete prosthetic control experience, researchers at the MIT Media Lab invented the agonist-antagonist myoneural interface (AMI). The AMI is a method to restore proprioception to persons with amputation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.media.mit.edu/projects/agonist-antagonist-myoneural-interface-ami/overview/"/><published>2026-01-09T05:44:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46550895</id><title>Mathematics for Computer Science (2018) [pdf]</title><updated>2026-01-09T19:12:43.625328+00:00</updated><content/><link href="https://courses.csail.mit.edu/6.042/spring18/mcs.pdf"/><published>2026-01-09T07:06:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46553343</id><title>Kagi releases alpha version of Orion for Linux</title><updated>2026-01-09T19:12:43.554071+00:00</updated><content>&lt;doc fingerprint="8923d81071c60f5d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Orion for Linux Status â&lt;/head&gt;
    &lt;p&gt;The alpha stage is an early, unstable version meant primarily for testing.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is ready to test â&lt;/head&gt;
    &lt;p&gt;All visual components, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Main menus, submenus, dialogs, buttons, and toolbars.&lt;/item&gt;
      &lt;item&gt;Right-click menus and other visual controls.&lt;/item&gt;
      &lt;item&gt;Window layouts and basic controls.&lt;/item&gt;
      &lt;item&gt;Demonstrated basic website navigation functionality, supporting essentials like the homepage, tabs, and simple searches&lt;/item&gt;
      &lt;item&gt;Advanced tab management is now complete, with the exception of the Tab Switcher UI, which is not supported yet.&lt;/item&gt;
      &lt;item&gt;Tabs now function independently and can be opened in parallel&lt;/item&gt;
      &lt;item&gt;Session persistence is implemented: previously opened tabs, along with their history, will reopen when the application is launched again.&lt;/item&gt;
      &lt;item&gt;Tabs currently appear in the main window and are supported in the left sidebar as well.&lt;/item&gt;
      &lt;item&gt;Bookmarks system a simple bookmark feature is now available.&lt;/item&gt;
      &lt;item&gt;Users can save pages, organize them into folders&lt;/item&gt;
      &lt;item&gt;Users can view them in the bookmarks dialog, sidebar, and bookmarks bar.&lt;/item&gt;
      &lt;item&gt;Bookmarking via the â´ï¸ icon.&lt;/item&gt;
      &lt;item&gt;Intuitive folder assignment when saving a new bookmark.&lt;/item&gt;
      &lt;item&gt;Advanced history management provides handling of browsing history&lt;/item&gt;
      &lt;item&gt;Password management framework establishes the core infrastructure needed for secure password handling and future improvements in this area.&lt;/item&gt;
      &lt;item&gt;Local export/import (via file)&lt;/item&gt;
      &lt;item&gt;Managing passwords&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Future improvements (not implemented in Alpha): â&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WebKit Extension support&lt;/item&gt;
      &lt;item&gt;Sync infrastructure&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://help.kagi.com/orion/misc/linux-status.html"/><published>2026-01-09T12:54:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46554462</id><title>London–Calcutta Bus Service</title><updated>2026-01-09T19:12:43.384738+00:00</updated><content>&lt;doc fingerprint="d36cd5cbf64c31a6"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;London–Calcutta bus service&lt;/head&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Overview&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Operator&lt;/cell&gt;&lt;cell&gt;Albert Travel&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Status&lt;/cell&gt;&lt;cell&gt;defunct&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Began service&lt;/cell&gt;&lt;cell&gt;c. 1957&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Ended service&lt;/cell&gt;&lt;cell&gt;c. 1976&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Route&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Start&lt;/cell&gt;&lt;cell&gt;London, United Kingdom&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Via&lt;/cell&gt;&lt;cell&gt;Belgium, West Germany, Austria, Yugoslavia, Bulgaria, Turkey, Iran, Afghanistan, Pakistan&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;End&lt;/cell&gt;&lt;cell&gt;Calcutta, India&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Other routes&lt;/cell&gt;&lt;cell&gt;London-Calcutta-Sydney&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Service&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Journey time&lt;/cell&gt;&lt;cell&gt;50+ days&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The London to Calcutta bus service was a long-distance international bus route that operated between London, England, and Calcutta, India. Launched in 1957, it was widely regarded as the longest bus route in the world at the time.[1][2][3] The journey spanned approximately 10,000 miles (16,000 km) one way, and over 20,000 miles (32,700 km) round trip, taking about 50 days to complete each leg.&lt;/p&gt;&lt;p&gt;The route passed through several countries, including Belgium, Yugoslavia, and parts of Northwest India,[4] and became famously associated with the overland Hippie Trail of the 1960s and 1970s.&lt;/p&gt;&lt;p&gt;The service offered an all-inclusive experience covering travel, food, and accommodation.[3] In 1957, a one-way ticket cost £85 (equivalent to £2,589 in 2023), rising to £145 by 1973 (equivalent to £2,215 in 2023).&lt;/p&gt;&lt;p&gt;The service was discontinued in 1976 due to growing geopolitical instability in the Middle East, which made the route increasingly dangerous.[5]&lt;/p&gt;&lt;head rend="h2"&gt;Route&lt;/head&gt;[edit]&lt;p&gt;The bus service was operated by Albert Travel.[6] The maiden journey set out from London on April 15, 1957.[7] The first service arrived in Calcutta on June 5, 50 days later. During its journey the bus traveled from England to Belgium, and from there to India via West Germany, Austria, Yugoslavia, Bulgaria, Turkey, Iran, Afghanistan, Pakistan and North Western India. After entering India, it eventually reached Calcutta via New Delhi, Agra, Allahabad and Banaras.[5]&lt;/p&gt;&lt;head rend="h2"&gt;Facilities on the bus&lt;/head&gt;[edit]&lt;p&gt;The bus was equipped with reading facilities, separate sleeping bunks for all passengers, fan-operated heaters, and a kitchen. There was a forward observation lounge on the upper deck of the bus. Radio and a music system for parties was provided.[1] It had time to spend at tourist destinations in India, including Banaras and the Taj Mahal on the banks of the Yamuna. Shopping was also allowed in Salzburg, Vienna, Istanbul, Tehran and Kabul.[3][8]&lt;/p&gt;&lt;head rend="h2"&gt;Later history&lt;/head&gt;[edit]&lt;p&gt;After some years the bus had an accident and became unusable. Later[specify] the bus was purchased by Andy Stewart, a British traveler. He rebuilt it to be a mobile home with two levels. The double-decker was renamed to Albert and was traveled from Sydney to London via India on October 8, 1968. It took about 132 days for the bus to reach London. Albert Tours was a company based in England and Australia and it operated on London–Calcutta–London and London–Calcutta–Sydney routes.[9]&lt;/p&gt;&lt;p&gt;The bus reached India through Iran and then it traveled to Singapore through Burma, Thailand and Malaysia. From Singapore, the bus was transported to Perth in Australia by ship, and from there it traveled by road to Sydney.[10][11] The charge for this service from London to Calcutta was £145. The service had all the modern facilities as before. The bus service was discontinued in 1976 due to political conditions leading up to the Iranian Revolution and the escalation of tensions between Pakistan and India.[12] The Albert Tours completed about 15 trips between Kolkata to London and again from London to Sydney, before the service ended permanently.[13]&lt;/p&gt;&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ a b "This Was 'World's Longest Bus Route' From Kolkata To London". Curly Tales. 2020-07-06. Retrieved 2020-07-24.&lt;/item&gt;&lt;item&gt;^ "A Bus Ride From London to Kolkata in 1950s? Yes, The Viral Photo is Real". News18. Retrieved 2020-07-24.&lt;/item&gt;&lt;item&gt;^ a b c Civic Affairs. Vol. 4. P. C. Kapoor at the Citizen Press. 1957 – via books.google.com.&lt;/item&gt;&lt;item&gt;^ "London Calcutta Bus Trip 1957 london India Editorial Stock Photo - Stock Image | Shutterstock". Shutterstock Editorial. Retrieved 2020-07-24.&lt;/item&gt;&lt;item&gt;^ a b "Samayam". malayalam.samayam.com. 2 July 2020. Retrieved 13 June 2023.&lt;/item&gt;&lt;item&gt;^ "London to Calcutta by Road? Picture of 1950s Albert Travel Bus Service is Going Viral, Know Details About This Fascinating Historic Journey". Unique News Online. 2020-07-02. Retrieved 2021-02-19.&lt;/item&gt;&lt;item&gt;^ Whispers of Yesterday, Rare Historical Photos, Old Photos, retrieved 2023-11-29&lt;/item&gt;&lt;item&gt;^ admin (2020-07-04). "ലണ്ടൻ – കൽക്കട്ട ബസ് റൂട്ട്". News Kerala online. Archived from the original on 2020-07-06. Retrieved 2020-07-24.&lt;/item&gt;&lt;item&gt;^ Eat, Tech Travel (2020-07-03). "ലണ്ടനിൽ നിന്നും ഇന്ത്യയിലെ കൽക്കട്ടയിലേക്ക് ഒരു ബസ് സർവ്വീസ്". Technology &amp;amp; Travel Blog from India. Retrieved 2020-07-31.&lt;/item&gt;&lt;item&gt;^ "ലണ്ടനിൽ നിന്നു കൽക്കട്ടയിലെത്തിയ ഇന്ത്യാ മാന്..." ManoramaOnline (in Malayalam). Retrieved 2020-07-31.&lt;/item&gt;&lt;item&gt;^ INGALIS, LEONARD (1957-08-08). "London-Calcutta Bus is back in London - Owner drove passengers 20,300 Miles". The New York Times.&lt;/item&gt;&lt;item&gt;^ K, Noushad K. "ലണ്ടൻ - കൽക്കട്ട ബസ്". Archived from the original on 2020-07-06. Retrieved 2020-07-31.&lt;/item&gt;&lt;item&gt;^ "Kolkata, Then Calcutta, Once Had The World's Longest Bus Route All The Way Till London!". Whats Hot. Retrieved 2020-07-31.&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://en.wikipedia.org/wiki/London%E2%80%93Calcutta_bus_service"/><published>2026-01-09T14:50:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46554652</id><title>How to store a chess position in 26 bytes</title><updated>2026-01-09T19:12:43.225187+00:00</updated><content>&lt;doc fingerprint="10f452a104a33a8"&gt;
  &lt;main&gt;
    &lt;p&gt;JavaScript must be enabled in order to use Notion. Please enable JavaScript to continue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ezzeriesa.notion.site/How-to-store-a-chess-position-in-26-bytes-using-bit-level-magic-df1fdb5364eb42fdac11eb23b25e9605"/><published>2026-01-09T15:07:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46555302</id><title>Developers Are Solving the Wrong Problem</title><updated>2026-01-09T19:12:43.067678+00:00</updated><content>&lt;doc fingerprint="37a0d05d2f7520b8"&gt;
  &lt;main&gt;
    &lt;p&gt;Everyone is either offended or excited about “vibe coding.” It’s all the rage and going to solve all your problems, or it’s the next great evil spewing crap code all over your systems. Those of us who love well structured clean code which is modular and concise seem to be a dying breed. For someone who’s early career was shaped by McConnell’s Code Complete, Brooks’ The Mythical Man Month, and Fowler’s Refactoring, this feels.. odd.&lt;/p&gt;
    &lt;p&gt;But when we dig into the WHY, something interesting happens:&lt;/p&gt;
    &lt;p&gt;Why do we want “well structured” code?&lt;/p&gt;
    &lt;p&gt;Well structured code is easier to understand to debug, extend, and maintain. But is there a single, shared definition of “well structured”?&lt;/p&gt;
    &lt;p&gt;Why do we want “clean” code?&lt;/p&gt;
    &lt;p&gt;Clean code is easier to understand to debug, extend, and maintain. But is there a single, shared definition of “clean”?&lt;/p&gt;
    &lt;p&gt;Why do we want “modular” code?&lt;/p&gt;
    &lt;p&gt;Modular code is easier to understand to debug, extend, and maintain. But is there a single, shared definition of “modular”? Actually, yes the Single Responsibility Principle addresses this one.&lt;/p&gt;
    &lt;p&gt;Why do we want “concise” code?&lt;/p&gt;
    &lt;p&gt;The less code there is, the easier it is to understand to debug, extend, and maintain. But too concise can make things harder to understand.&lt;/p&gt;
    &lt;p&gt;But when it gets down to it, all of these goals point at the problem.&lt;/p&gt;
    &lt;head rend="h2"&gt;It’s Not About You&lt;/head&gt;
    &lt;p&gt;Previously, we needed “well structured clean code which is modular and concise” because writing code was easy but reading code is hard. Really hard. Painfully hard. Making sense of someone else’s code is harder still. All of our practices are really just to decrease that pain. Anything we can do to make it easier for the next person – or ourselves six months from now – is worth it.&lt;/p&gt;
    &lt;p&gt;But what if the next “person” isn’t a person?&lt;/p&gt;
    &lt;p&gt;If we assume that the code will only be debugged, extended, and maintained by a computer, most of our reasoning for clean code goes out the window. We don’t care what a human can do with the resulting (output) code as long as they can consistently generate code and configuration to solve the business problem, which gets at the REAL problem.&lt;/p&gt;
    &lt;head rend="h2"&gt;It’s Not About Code&lt;/head&gt;
    &lt;p&gt;Somewhere along the line, we started treating the code as our goal. We worked hard to make sure it was structurally perfect on whatever framework we’re using today and didn’t realize that no one cares about our code. No one cares or even knows how “clean” our code is. They don’t even know what code is.&lt;/p&gt;
    &lt;p&gt;All our customers know is “does this solve my problem?” Enter vibe coding.&lt;/p&gt;
    &lt;head rend="h2"&gt;It’s About the Problem&lt;/head&gt;
    &lt;p&gt;When a savvy user can describe their problem in detail, they can skip over all the messy coding steps and get directly to a solution. It won’t be perfect, and it won’t have “clean code” but they’ll see it in hours instead of months. More importantly, the savviest users can make mistakes, improve their understanding, experiment with ideas, and iterate on the entire process while getting better at each step along the way at a fraction of the cost.&lt;/p&gt;
    &lt;p&gt;And that’s why vibe coding is popular and only going to get more popular.&lt;/p&gt;
    &lt;p&gt;Instead of seeing vibe coding as a threat, we need to consider it another tool.&lt;/p&gt;
    &lt;p&gt;If you see it exclusively as a threat, I’m shocked you read this far. Thanks. I hope I can nudge your thinking.&lt;/p&gt;
    &lt;p&gt;If you see it as a tool, there are a few things we can do.&lt;/p&gt;
    &lt;head rend="h2"&gt;Improving Vibe Coding&lt;/head&gt;
    &lt;p&gt;First, remember that any generative AI approach is only as good as the underlying model. If there’s a public model that suits your needs, use it. Though you can also give it context by adding code that fits your standards and expectations. To be clear, I don’t mean coding standards but patterns and practices which demonstrate good security and performant code.&lt;/p&gt;
    &lt;p&gt;Next, build out the rest of your tools. If you’re not writing the code directly, you need to be able to validate that the code works exactly the way you expect. At a minimum, that means testing business logic and validating interfaces, but you should include security and load or performance testing systems too.&lt;/p&gt;
    &lt;p&gt;Next, figure out how to describe your needs and capabilities effectively. We all know about requirements documents and Jiras but you’ll need to figure out how to translate that into actionable requests and steps for the generative AI. This will vary heavily on the system you’re using.&lt;/p&gt;
    &lt;p&gt;Finally, get used to throwing code away. Remember that your goal is solving the problem, and your code is merely the byproduct or the tool to get to that solution. The most important parts are the prompt and process used to generate the code, along with the understanding you gained and applied to get to that prompt. The more and faster you can learn, adapt, iterate, and ship, the better your solution will be.&lt;/p&gt;
    &lt;head rend="h2"&gt;But what happens After Vibe Coding?&lt;/head&gt;
    &lt;p&gt;It’s hard to predict things – especially the future – but I have a couple ideas.&lt;/p&gt;
    &lt;p&gt;First, more people are going to try more ideas faster. This is good. The people who were Excel wizards a generation ago are going to create “pretty good” things that solve their problems without involving a developer. My friends over at Dreambase are already doing that. We’ll have more automations and solutions than ever before.&lt;/p&gt;
    &lt;p&gt;Second, we may see the rise of “developer-less” companies. People will be able to imagine, describe, and ship a product with minimal developer input. Occasionally they may need an integration or similar and might contract with someone but maybe not even that. In my “Creating Better SDKs with Generative AI” course for LinkedIn, I realized that with well-defined interfaces, you don’t need much human interaction.&lt;/p&gt;
    &lt;p&gt;BUT – is this good or bad? Depends on who you are. If you job is to solve problems faster, this is a great time to be in the space. If your job is only to write beautiful code, you have a problem.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://caseysoftware.com/blog/developers-are-solving-the-wrong-problem"/><published>2026-01-09T16:05:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46555485</id><title>Cloudspecs: Cloud Hardware Evolution Through the Looking Glass</title><updated>2026-01-09T19:12:42.877322+00:00</updated><content>&lt;doc fingerprint="edc998f165b26ddb"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Cloudspecs: Cloud Hardware Evolution Through the Looking Glass&lt;/head&gt;
    &lt;p&gt;This paper (CIDR'26) presents a comprehensive analysis of cloud hardware trends from 2015 to 2025, focusing on AWS and comparing it with other clouds and on-premise hardware.&lt;/p&gt;
    &lt;p&gt;TL;DR: While network bandwidth per dollar improved by one order of magnitude (10x), CPU and DRAM gains (again in performance per dollar terms) have been much more modest. Most surprisingly, NVMe storage performance in the cloud has stagnated since 2016. Check out the NVMe SSD discussion below for data on this anomaly.&lt;/p&gt;
    &lt;head rend="h2"&gt;CPU Trends&lt;/head&gt;
    &lt;p&gt;Multi-core parallelism has skyrocketed in the cloud. Maximum core counts have increased by an order of magnitude over the last decade. The largest AWS instance u7in now boasts 448 cores. However, simply adding cores hasn't translated linearly into value. To measure real evolution, the authors normalized benchmarks (SPECint, TPC-H, TPC-C) by instance cost. SPECint benchmarking shows that cost-performance improved roughly 3x over ten years. A huge chunk of that gain comes from AWS Graviton. Without Graviton, the gain drops to roughly 2x. For in-memory database benchmarks, gains were even lower (2x–2.5x), likely due to memory and cache latency bottlenecks.&lt;/p&gt;
    &lt;p&gt;On-prem hardware comparison shows that this stagnation is not cloud price gouging. Historically, Moore's Law and Dennard scaling doubled cost-performance every two years (which would have sum up to 32x gain over a decade). However, an analysis of on-premise AMD server CPUs reveals a similar slump, only a 1.7x gain from 2017 to 2025.&lt;/p&gt;
    &lt;head rend="h2"&gt;Memory Trends&lt;/head&gt;
    &lt;p&gt;DRAM capacity per dollar has effectively flatlined. The only significant improvement was the 2016 introduction of memory-optimized x instances, which offered ~3.3x more GiB-hours/$ than compute-optimized peers. While absolute single-socket bandwidth jumped ~5x (93 GiB/s to 492 GiB/s) as servers moved from DDR3 to DDR5, the cost-normalized gain is only 2x.&lt;/p&gt;
    &lt;p&gt;Historical data suggests commodity DRAM prices dropped 3x over the decade. But in the last three months, due to AI-driven demand, DDR5 prices rose sharply, further limiting effective memory gains.&lt;/p&gt;
    &lt;head rend="h2"&gt;Network Trends&lt;/head&gt;
    &lt;p&gt;We have good news here, finally. Network bandwidth per dollar exploded by 10x. And absolute speeds went from 10 Gbit/s to 600 Gbit/s (60x).&lt;/p&gt;
    &lt;p&gt;These gains were not universal though. Generic instances saw little change. The gains were driven by network-optimized n instances (starting with the c5n in 2018) powered by proprietary Nitro cards.&lt;/p&gt;
    &lt;head rend="h2"&gt;NVMe Trends&lt;/head&gt;
    &lt;p&gt;NVMe SSDs are the biggest surprise. Unlike CPUs and memory, where cloud trends mirror on-prem hardware, NVMe performance in AWS has largely stagnated. The first NVMe-backed instance family, i3, appeared in 2016. As of 2025, AWS offers 36 NVMe instance families. Yet the i3 still delivers the best I/O performance per dollar by nearly 2x.&lt;/p&gt;
    &lt;p&gt;SSD capacity has stagnated since 2019 and I/O throughput since 2016. This sharply contrasts with on-prem hardware, where SSD performance doubled twice (PCIe 4 and PCIe 5) in the same timeframe. The gap between cloud and on-premise NVMe is widening rapidly.&lt;/p&gt;
    &lt;p&gt;This price/performance gap likely explains the accelerating push toward disaggregated storage. When local NVMe is expensive and underperforming, remote storage starts to look attractive. The paper speculates that with network speeds exploding and NVMe stagnating, architectures may shift further. For systems like Snowflake, using local NVMe for caching might no longer be worth the complexity compared to reading directly from S3 with fast networks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;I think the main takeaway is that uniform hardware scaling in the cloud is over. Moore's Law no longer lifts all boats. Performance gains now come from specialization, especially networking (e.g., Graviton, Nitro, Accelerators).&lt;/p&gt;
    &lt;p&gt;In my HPTS 2024 review, I noted that contrary to the deafening AI hype, the real excitement in the hallways was about hardware/software codesign. This paper validates that sentiment. With general-purpose CPU and memory cost-performance stagnating, future databases must be tightly integrated with specialized hardware and software capabilities to provide value. I think the findings here will refuel that trend.&lt;/p&gt;
    &lt;p&gt;A key open question is why massive core counts deliver so little value. Where is the performance lost? Possible explanations include memory bandwidth limits, poor core-to-memory balance, or configuration mismatches. But I think the most likely culprit is software. Parallel programming remains hard, synchronization is expensive, and many systems fail to scale beyond a modest number of cores. We may be leaving significant performance on the table simply because our software cannot effectively utilize the massive parallelism now available.&lt;/p&gt;
    &lt;p&gt;The paper comes with an interactive tool, Cloudspecs, built on DuckDB-WASM (yay!). This allows you to run SQL queries over the dataset directly in the browser to visualize these trends. The figures in the PDF actually contain clickable link symbols that take you to the specific query used to generate that chart. Awesome reproducibility!&lt;/p&gt;
    &lt;p&gt;Aleksey and I did a live-reading of the paper. As usual, we had a lot to argue about. I'll add a recording of our discussion on YouTube when it becomes available, and here is a link to my annotated paper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://muratbuffalo.blogspot.com/2026/01/cloudspecs-cloud-hardware-evolution.html"/><published>2026-01-09T16:23:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46555512</id><title>Latest SteamOS Beta Now Includes Ntsync Kernel Driver</title><updated>2026-01-09T19:12:42.574753+00:00</updated><content>&lt;doc fingerprint="4fa7b87e288b3d14"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Latest SteamOS Beta Now Includes NTSYNC Kernel Driver&lt;/head&gt;
    &lt;p&gt; Valve released the SteamOS 3.7.20 beta overnight and with it they are finally building the NTSYNC kernel driver for helping accelerate Windows NT synchronization primitives. &lt;lb/&gt;The NTSYNC kernel driver has been in good shape for about one year now after the implementation was finished up. From user-space Wine 10.16 added NTSYNC usage support as part of the upcoming Wine 11.0 stable release due out this month. In turn Proton 11.0 will see that support when it is re-based atop Wine 11.0. Albeit Proton (Steam Play) already has FSYNC for good performance but will be interesting to see how the NTSYNC path performs for SteamOS / Steam Play needs in comparison.&lt;lb/&gt;For gearing up for that future Proton NTSYNC support, SteamOS 3.7.20 enables the NTSYNC kernel driver and loads the module by default. Most Linux distributions are at least already building the NTSYNC kernel module though there's been different efforts on how to handle ensuring it's loaded when needed. The presence of the NTSYC kernel driver is the main highlight of the SteamOS 3.7.20 beta now available for testing.&lt;/p&gt;
    &lt;p&gt;The NTSYNC kernel driver has been in good shape for about one year now after the implementation was finished up. From user-space Wine 10.16 added NTSYNC usage support as part of the upcoming Wine 11.0 stable release due out this month. In turn Proton 11.0 will see that support when it is re-based atop Wine 11.0. Albeit Proton (Steam Play) already has FSYNC for good performance but will be interesting to see how the NTSYNC path performs for SteamOS / Steam Play needs in comparison.&lt;/p&gt;
    &lt;p&gt;For gearing up for that future Proton NTSYNC support, SteamOS 3.7.20 enables the NTSYNC kernel driver and loads the module by default. Most Linux distributions are at least already building the NTSYNC kernel module though there's been different efforts on how to handle ensuring it's loaded when needed. The presence of the NTSYC kernel driver is the main highlight of the SteamOS 3.7.20 beta now available for testing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.phoronix.com/news/Steam-OS-Beta-NTSYNC"/><published>2026-01-09T16:27:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46555760</id><title>Cloudflare CEO on the Italy Fines</title><updated>2026-01-09T19:12:42.287379+00:00</updated><content>&lt;doc fingerprint="d635e49f34142863"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2026 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://twitter.com/eastdakota/status/2009654937303896492"/><published>2026-01-09T16:46:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46555963</id><title>The Vietnam government has banned rooted phones from using any banking app</title><updated>2026-01-09T19:12:42.036320+00:00</updated><content>&lt;doc fingerprint="d77b9987e9f764cd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt; Regulated in Circular 77/2025/TT-NHNN amending Circular 50 on online service security in the banking industry, to be in affect from March 1st:&lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Thông tư số 77/2025/TT-NHNN của Ngân hàng Nhà nước Việt Nam: Sửa đổi, bổ sung một số điều của Thông tư số 50/2024/TT-NHNN của Thống đốc Ngân hàng Nhà nước Việt Nam quy định về an toàn, bảo mật cho việc cung cấp dịch vụ trực tuyến trong ngành Ngân hàng&lt;/p&gt;
            &lt;div&gt;
              &lt;p&gt; vanban.chinhphu.vn &lt;/p&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;p&gt; Clause 2, Article 5: Amend and supplement Clause 4 of Article 8 as follows: &lt;/p&gt;
      &lt;p&gt; 4. Implement solutions to prevent, combat, and detect unauthorized interference with the Mobile Banking application installed on customers' mobile devices. The Mobile Banking application must automatically exit or stop functioning and notify the customer of the reason if any of the following signs are detected: &lt;/p&gt;
      &lt;p&gt; a) A debugger is attached or the environment has a debugger running; or when the application is running in an emulator/virtual machine/emulator; or operating in a mode that allows the computer to communicate directly with the Android device (Android Debug Bridge); &lt;/p&gt;
      &lt;p&gt; b) The application software is injected with external code while running, performing actions such as monitoring executed functions, logging data transmitted through functions, APIs, etc. (hooks); or the application software is tampered with or repackaged. &lt;/p&gt;
      &lt;p&gt; c) The device has been rooted/jailbroken; or its bootloader has been unlocked." &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xdaforums.com/t/discussion-the-root-and-mod-hiding-fingerprint-spoofing-keybox-stealing-cat-and-mouse-game.4425939/page-118"/><published>2026-01-09T17:00:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46555977</id><title>IcePanel (YC W23) is hiring full-stack engineers in Vancouver</title><updated>2026-01-09T19:12:41.092915+00:00</updated><content>&lt;doc fingerprint="80b89e5ad2c4a6e0"&gt;
  &lt;main&gt;
    &lt;p&gt;$170,000 salary (CAD) + Profit-share quarterly bonus (last year averaged ~30k-40k each)&lt;/p&gt;
    &lt;p&gt;+ 1% equity + Unlimited holiday + Health benefits&lt;/p&gt;
    &lt;p&gt;We’re looking for someone with a high degree of agency, who can immediately take ownership of building new functionality from design &amp;gt; implementation &amp;gt; maintaining and refining current features based on our customers' needs.&lt;/p&gt;
    &lt;p&gt;You’ll be building end-to-end, including: - Frontend UI/UX design alongside a designer. - Backend API/data structure design. - Data migration and infrastructure changes. - Bug fixing and iterations.&lt;/p&gt;
    &lt;p&gt;We're simplifying how teams design for complex systems. We're building a collaborative diagramming and modelling tool that software architects think is cool.&lt;/p&gt;
    &lt;p&gt;We’re a small, energetic team that believes in building a lean and profitable business after being in the YCombinator W23 batch. We’ve grown the product to ~$4 million CAD in ARR and believe in continuing to build on profitability over funding. We’re looking for talented, driven people who love their craft to help achieve our vision of simplifying complexity.&lt;/p&gt;
    &lt;p&gt;🙋 Independence to build our way&lt;/p&gt;
    &lt;p&gt;🛠️ Build simple and exceptional experiences&lt;/p&gt;
    &lt;p&gt;🧊 Transparency and openness&lt;/p&gt;
    &lt;p&gt;💡 Stay humble and explore all ideas&lt;/p&gt;
    &lt;p&gt;💩 No bullshit, have fun&lt;/p&gt;
    &lt;p&gt;- In-person days every week (Tuesday, Wednesday, Thursday)&lt;/p&gt;
    &lt;p&gt;- North Vancouver, British Columbia, Canada&lt;/p&gt;
    &lt;p&gt;- Hybrid &amp;amp; flexible work environment&lt;/p&gt;
    &lt;p&gt;- This is not a fully remote job&lt;/p&gt;
    &lt;p&gt;🍰 Equity in the company 💰 Profit sharing&lt;/p&gt;
    &lt;p&gt;💻 Work setup provided&lt;/p&gt;
    &lt;p&gt;🎉 Flexible work culture&lt;/p&gt;
    &lt;p&gt;🏂 Unlimited holiday&lt;/p&gt;
    &lt;p&gt;🧑⚕️ Health, dental, vision&lt;/p&gt;
    &lt;p&gt;📚 Learning budget&lt;/p&gt;
    &lt;p&gt;✈️ Conference budget&lt;/p&gt;
    &lt;p&gt;🌴 Annual team retreat&lt;/p&gt;
    &lt;p&gt;🌭 Hot dog Wednesdays&lt;/p&gt;
    &lt;p&gt;🧊 Free ice cubes&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://forms.icepanel.io/careers/senior-product-engineer"/><published>2026-01-09T17:01:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46556210</id><title>Show HN: I made a memory game to teach you to play piano by ear</title><updated>2026-01-09T19:12:40.901854+00:00</updated><link href="https://lend-me-your-ears.specr.net"/><published>2026-01-09T17:17:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46556822</id><title>Replit (YC W18) Is Hiring</title><updated>2026-01-09T19:12:40.811407+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jobs.ashbyhq.com/replit"/><published>2026-01-09T18:00:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46556979</id><title>U.S. mandates more foreign travelers to pay $15,000 visa bond deposits</title><updated>2026-01-09T19:12:40.669320+00:00</updated><content>&lt;doc fingerprint="db2f51ae148dbf48"&gt;
  &lt;main&gt;
    &lt;p&gt;Foreign travelers from seven additional countries are now required to pay up to $15,000 for a reimbursable bond when applying for a U.S. visitor visa, as the Trump administration continues to tighten entry requirements to the country.&lt;/p&gt;
    &lt;p&gt;Democracy Dies in Darkness&lt;/p&gt;
    &lt;p&gt;Immigration&lt;/p&gt;
    &lt;head rend="h1"&gt;U.S. mandates more foreign travelers to pay $15,000 visa bond deposits&lt;/head&gt;
    &lt;p&gt;Visitors from 13 countries, mostly in Africa, will now be required to post the bonds. People from countries that are part of the visa waiver program are exempt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.washingtonpost.com/immigration/2026/01/06/visa-bonds-state-overstay-rates/"/><published>2026-01-09T18:11:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46556984</id><title>73% People Detained by ICE Have No Convictions</title><updated>2026-01-09T19:12:40.397606+00:00</updated><content>&lt;doc fingerprint="9d3880dd416fa00b"&gt;
  &lt;main&gt;
    &lt;p&gt;President Donald Trump premised his mass deportation agenda on the idea that he will be “returning millions and millions of criminal aliens.” Department of Homeland Security (DHS) Secretary Kristi Noem has repeatedly claimed that they are arresting the “worst of the worst.” New nonpublic data from Immigration and Customs Enforcement (ICE) leaked to the Cato Institute reveal a different story.&lt;/p&gt;
    &lt;p&gt;Of people booked into ICE custody this fiscal year (since October 1, 2025):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Nearly three in four (73 percent) had no criminal conviction.&lt;/item&gt;
      &lt;item&gt;Nearly half had no criminal conviction nor even any pending criminal charges.&lt;/item&gt;
      &lt;item&gt;Only 8 percent had a violent or property criminal conviction.&lt;/item&gt;
      &lt;item&gt;Only 5 percent had a violent criminal conviction.&lt;/item&gt;
      &lt;item&gt;A majority of criminal convicts had vice, immigration, or traffic convictions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The appendix table at the end of this report provides the detailed breakdown of the data by detailed type of crime.&lt;/p&gt;
    &lt;p&gt;The earliest data I obtained that was reported in this way comes from April 26, 2025. Compared with October 2024 to April 2025—before the White House shifted focus completely away from criminals—80 percent of the increase in daily ICE book-ins have come from individuals without criminal convictions.&lt;/p&gt;
    &lt;p&gt;Since October 1, only 8 percent of detained persons had either a violent or property crime. As many people were detained with an immigration conviction (e.g., illegal entry/reentry) as violent convicts.&lt;/p&gt;
    &lt;p&gt;In its posts on this subject, DHS and ICE often include people with pending criminal charges as “criminal arrests,” even though these people have never been found guilty, and the charges are often minor and regularly dismissed. ICE is depriving these people of due process by arresting them prior to a conviction. Nonetheless, ICE data show that nearly half (47 percent) of all ICE detainees this fiscal year&lt;/p&gt;
    &lt;p&gt;Other data sources support the conclusions from the number of ICE book-ins. The Deportation Data Project, which is run by UC Berkeley Law School in collaboration with the UCLA School of Law’s Center for Immigration Law and Policy, has obtained data on ICE arrests via the Freedom of Information Act. ICE arrests are individuals charged as removable by Immigration and Customs Enforcement, so it excludes people arrested by Border Patrol and referred to ICE for detention who are included in the data above.&lt;/p&gt;
    &lt;p&gt;This arrest dataset also does not disclose the type of crime committed. In any case, it similarly shows that by late July, 67 percent of ICE arrests were of people without criminal convictions. It also shows that by late July, nearly 40 percent of ICE arrests were of people without criminal convictions or criminal charges. This is a dramatic change from President Joseph Biden’s policies under which only one in 10 arrests were individuals without any criminal conviction or charge.&lt;/p&gt;
    &lt;p&gt;More important than the share of arrests is the absolute number of these arrests. Already by late July, ICE arrests of immigrants without criminal convictions had increased by 571 percent from the weekly average to start the calendar year. ICE arrests of immigrants without criminal convictions or criminal charges increased a staggering 1,500 percent since January 1.&lt;/p&gt;
    &lt;p&gt;Finally, the last data source comes from public data directly from the Immigration and Customs Enforcement website, showing that by mid-November, 69 percent of current ICE detainees who were arrested by ICE had no criminal conviction and 40 percent had no criminal charge. The number of people in detention who were convicted of a crime and had no pending charges increased a staggering 2,370 percent since January from fewer than 1,000 to over 21,000.&lt;/p&gt;
    &lt;p&gt;The ICE data show that the share of immigrants detained after an ICE arrest who had criminal convictions has fallen in half since January from 62 percent of detainees to 31 percent in November. At the same time, the share of detainees without a criminal conviction or criminal charge has exploded from 6 percent to 40 percent of detainees.&lt;/p&gt;
    &lt;p&gt;The same ICE dataset shows that in November 2025, 70 percent of those who ICE deported had no criminal conviction, and 43 percent had no criminal conviction or criminal charge. Across all available datasets, it is clear that the Trump administration is not living up to its promises to deport millions and millions of criminals or to prioritize the worst of the worse. So far, the administration has removed barely 90,000 individuals with criminal convictions and fewer than 150,000 individuals with convictions or pending charges.&lt;/p&gt;
    &lt;p&gt;President Trump’s deportation agenda does not match the campaign promises that he made nor the rhetoric from his officials. The president has already recognized that deportations are hurting the US economy in deporting good workers. But perhaps more importantly, the agenda is taking resources away from targeting true public safety threats, whether from immigrants or Americans. ICE should redirect its resources back toward serious public safety threats.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cato.org/blog/5-ice-detainees-have-violent-convictions-73-no-convictions"/><published>2026-01-09T18:11:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46557029</id><title>Show HN: Scroll Wikipedia like TikTok</title><updated>2026-01-09T19:12:39.837567+00:00</updated><content>&lt;doc fingerprint="434f9162ba198e26"&gt;
  &lt;main&gt;
    &lt;p&gt;Following Slop Ducks Storytime Home Friends Inbox Profile&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://quack.sdan.io"/><published>2026-01-09T18:15:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46557489</id><title>JavaScript Demos in 140 Characters</title><updated>2026-01-09T19:12:39.489049+00:00</updated><content>&lt;doc fingerprint="3325d7c3709c027d"&gt;
  &lt;main&gt;&lt;code&gt;function u(t) {&lt;/code&gt;&lt;code&gt;
    u(t) is called 60 times per second.
    t: Elapsed time in seconds.
    S: Shorthand for Math.sin.
    C: Shorthand for Math.cos.
    T: Shorthand for Math.tan.
    R: Function that generates rgba-strings, usage ex.: R(255, 255, 255, 0.5)
    c: A 1920x1080 canvas.
    x: A 2D context for that canvas.
  &lt;/code&gt;&lt;p&gt;Loading...&lt;/p&gt; Next page &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.dwitter.net/top"/><published>2026-01-09T18:48:30+00:00</published></entry></feed>