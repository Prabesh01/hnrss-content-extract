<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-10T18:15:23.552076+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45873904</id><title>Installing and using HP-UX 9</title><updated>2025-11-10T18:15:29.070538+00:00</updated><content>&lt;doc fingerprint="efb7711d2da00745"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt; JP's Website &lt;/head&gt;
    &lt;head rend="h1"&gt;Installing and using HP-UX 9&lt;/head&gt;
    &lt;p&gt;Posted on 2025-11-08&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Background&lt;/item&gt;
      &lt;item&gt;The HP 9000 Model 340&lt;/item&gt;
      &lt;item&gt;HP-UX 9 for Series 700 (PA-RISC)&lt;/item&gt;
      &lt;item&gt;An absolute Cluster ... Server&lt;/item&gt;
      &lt;item&gt;HP-UX 9 for Series 300 (68K)&lt;/item&gt;
      &lt;item&gt;Context Dependent Filesystems&lt;/item&gt;
      &lt;item&gt;Fixing X11R5&lt;/item&gt;
      &lt;item&gt;Wrapping up&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;A few weeks back I got a note on Bluesky, linking me to a website offering a free computer. The owner was in Cambridge, not far from me, and the computer was an HP 9000/300 Series - a Model 340, specifically.&lt;/p&gt;
    &lt;p&gt;The HP 9000 line of workstations and servers ran from the early 1980s through to the late 2000s (see this great history page at openpa.net for more details). It encompassed many processor architectures, including Itanium, HP's own Precision Architecture (aka PA-RISC), and their earlier FOCUS architecture. Alongside the early FOCUS machines, they also had a line of Motorola 68K based UNIX workstations - the 300 series. This is a machine from that series, and I thought a 68030 based UNIX workstation just sounded fascinating. Something of the same kind of processor and vintage as the Macintosh IIx, but part of the lineage that led to my beloved Visualize B132L+ and C3000 workstations.&lt;/p&gt;
    &lt;p&gt;E-mails were exchanged with the owner, Ben, and I was invited to pop over and collect the machine. And then, whilst I was there, it turns out Ben had a few more machines he'd be happy to move on to a new owner, to free up some space. And. Well. I went home with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;An HP 9000 Model 340 (68030)&lt;/item&gt;
      &lt;item&gt;An HP 9000 Model 715 (PA-7000)&lt;/item&gt;
      &lt;item&gt;A DEC microVAX 3100 (KA-41)&lt;/item&gt;
      &lt;item&gt;An IBM RS/6000 7012-320 (POWER 2)&lt;/item&gt;
      &lt;item&gt;A Sun SPARCstation 20 (HyperSPARC)&lt;/item&gt;
      &lt;item&gt;A Sun SPARCstation 4 (MicroSPARC)&lt;/item&gt;
      &lt;item&gt;A Sun SPARCstation 10 (SuperSPARC)&lt;/item&gt;
      &lt;item&gt;Some HP mice, some DDS tapes, and some SCSI terminators&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This haul was frankly ridiculous, and huge thanks to Ben for his generosity. It was also more machines that I literally had space for at home (thanks to a very large pile of SPARCstations I haven't yet moved on) and so I immediately called my friend Matt and arranged to drop off the SPARCstation 10 and the HP 9000 Model 715. I already have an HP 9000 Model 712 and they're similar enough I'm happy to let Matt hold on to the 715 for now. He also had his name down for the SPARCstation 10 I already had, so it made sense to let him have both in case one he needs spares.&lt;/p&gt;
    &lt;p&gt;Over at Matt's house we fired them up and were delighted to see the both booted up OK, which was very promising.&lt;/p&gt;
    &lt;p&gt;I've since donated the SPARCstation 4 (working) and the microVAX3100 (sadly dead) to new homes, free of charge. I've also tested the RS/6000, which was also dead, and the SPARCstation 20, which not only worked but turned out to contain two ROSS HyperSPARC CPU cards running at 150 MHz. As SPARCstations 20s go, it doesn't really get much better.&lt;/p&gt;
    &lt;p&gt;But, we're here to talk about HP-UX. And before I can do that, I need to explain that the Model 340 doesn't have a disk drive.&lt;/p&gt;
    &lt;head rend="h2"&gt;The HP 9000 Model 340&lt;/head&gt;
    &lt;p&gt;The system specs for this machine are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Motorola 68030 CPU at 16.7 MHz&lt;/item&gt;
      &lt;item&gt;Motorola 68882 FPU&lt;/item&gt;
      &lt;item&gt;16 MiB RAM&lt;/item&gt;
      &lt;item&gt;High Resolution Colour Graphics Board (1280x1024 in 256 colours at 75 Hz), with output via 3x BNC&lt;/item&gt;
      &lt;item&gt;HP-IB interface for disk drives and peripherals&lt;/item&gt;
      &lt;item&gt;HIL interface for keyboard and mouse&lt;/item&gt;
      &lt;item&gt;10base2 Ethernet interface&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sorry, you can't see the 68030 or the 68882 FPU - they are underneath the high-res graphics adapter, and I didn't want to take it apart.&lt;/p&gt;
    &lt;p&gt;What you also cannot see - because it does not have them - is a floppy controller or a SCSI controller, or any kind of disk controller. You're supposed to either network boot it, or use an HP-IB disk drive.&lt;/p&gt;
    &lt;p&gt;I do not (or rather, I did not) have any 10base2 networking gear, or a BNC to VGA adapter, or any HP-IB cables or devices, or an HIL keyboard (although I do have a bag of HIL mice). But, you know, eBay exists, and I was able to get the first three things in short order at fairly reasonable prices. The keyboards, however, are outrageously expensive, and being HIL interface, you can't just use a PC keyboard as a substitute.&lt;/p&gt;
    &lt;p&gt;Here Matt comes to the rescue because it turned out he had an HP 9000 Model 705 kicking around, and that also uses HIL, and he had the keyboard to go with it. Seeing as he now had my Model 715 (which supports both PS/2 and HIL), he was happy to let me borrow the 705 and its keyboard in exchange.&lt;/p&gt;
    &lt;p&gt;Amazingly, the Model 340 appears to be in great working order. When you turn it on, it does a self-test, and then fails to find any devices to boot from. I now do have an HP-IB card (well, a GPIB card) for my Windows XP PC, and a copy of HPDrive from hp9845.net. This is an emulator for HP HP-IB drive units - floppy drives, hard disk drives and CD-ROM drives. I have booted the machine with it, but I found it to be quite slow.&lt;/p&gt;
    &lt;p&gt;What's more fun though, is putting it into a cluster with the Model 705 and network booting it.&lt;/p&gt;
    &lt;p&gt;Yes, that a 68030 machine network booting from a PA-RISC machine ... and sharing the same root filesystem. But aren't PA-RISC binaries and 68K binaries quite different? Oh yes, they really are. So, how does that work?&lt;/p&gt;
    &lt;head rend="h2"&gt;HP-UX 9 for Series 700 (PA-RISC)&lt;/head&gt;
    &lt;p&gt;I believe there are several versions of HP-UX that support setting up a cluster, but HP-UX 9 is the last that supported mixed 68K and PA-RISC clusters (or, as HP would call it, mixed Series 300 and Series 700 suppport). HP-UX 10 dropped 68K support and was PA-RISC only.&lt;/p&gt;
    &lt;p&gt;So, let's install HP-UX 9 on the Model 705 I got from Matt. I found this guide quite helpful but I'll outline the basic steps here.&lt;/p&gt;
    &lt;p&gt;(Side note: look at that keyboard for more than a few seconds, and you'll realise it's really weird)&lt;/p&gt;
    &lt;p&gt;Step 1 is to boot the Install CD, which I do using a BlueSCSI. This formats the hard disk - but only if it recognises the make and model from its &lt;code&gt;disktab&lt;/code&gt; file. This is an annoyance that seems common to early UNIX systems - SunOS 4 has a similar problem - but I was able to swap some drives around and put a 2GB Seagate ST11200N into the machine, which it seems happy with. You'd certainly have no chance with a more modern 9.1GB drive. Once the format is done, it lays down a very basic root filesystem, and reboots into it.&lt;/p&gt;
    &lt;p&gt;Step 2 is the actual installation. I put the image onto the BlueSCSI (I'm using HP-UX 9.07 Core OS B2826-13716), and the installation picks it up and asks what packages I want to install. I pick Select All Filesets on the Source Media, because I've got plenty of disk space - I think a full install is only about 200 MiB. It takes about 20 minutes to copy the files over, and then we can set up the root password, hostname, IP address, DNS server, and so on.&lt;/p&gt;
    &lt;head rend="h2"&gt;An absolute Cluster ... Server&lt;/head&gt;
    &lt;p&gt;My first attempt at setting up HP-UX 9 on this machine was made difficult because the network card wasn't working. This was either because I had the switch on the rear of the machine in the Factory Setup position instead of the Normal position, or because I had the internal jumpers set to use the AUI port instead of the BNC, and it knew I didn't have an MAU attached to the AUI port. Either way, I resolved both issues at the same time and after that, the network started up on boot. If you cannot bring up a network interface on a Model 705, check both I guess.&lt;/p&gt;
    &lt;p&gt;We administer the system using SAM. It's a TUI tool, and easy enough to go in and set this machine up as a Cluster host.&lt;/p&gt;
    &lt;code&gt;âââââââââââSystem Administration Manager (hp705) (1)ââââââââââ  
â                                                            â  
â                                                            â  
â ââââââââââââââââââââââââââââââââââââââ                     â  
â â Printers and Plotters-&amp;gt;            ^  [[    Open      ]] â  
â â Disks and File Systems-&amp;gt;                                 â  
â â Peripheral Devices-&amp;gt;                                     â  
â â Backup and Recovery-&amp;gt;                 [ Previous Level ] â  
â â Users and Groups-&amp;gt;                                       â  
â â Routine Tasks-&amp;gt;                                          â  
â â Process Management-&amp;gt;                                     â  
â â Kernel Configuration-&amp;gt;                                   â  
â â Cluster Configuration                                    â  
â â Networking/Communications-&amp;gt;                              â  
â â Remote Administration                                    â  
â â Auditing and Security-&amp;gt;                                  â  
â â                                                          â  
â â                                    v                     â  
â ââââââââââââââââââââââââââââââââââââââ                     â  
â          Press CTRL-K any time for KEYBOARD HELP           â  
â                                                            â  
ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ  
â [   Exit SAM    ]   [  Options...   ]   [     Help      ]  â  
ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ  
&lt;/code&gt;
    &lt;code&gt;



               âââââââââââââCreate Cluster (hp705)ââââââââââââââ              
               â                                               â              
               â Create an HP-UX Cluster:                      â              
    ââââââââââââââââââââââââââConfirmation (hp705)ââââââââââââââââââââââââââ  
    â                                                                      â  
    â This system ("hp705") does not currently appear to be a cluster      â  
    â server (because "standalone" appears in the process context from the â  
    â kernel). Cluster configuration can only be done on a cluster server. â  
    â                                                                      â  
    â Would you like to create a cluster server?                           â  
    ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ  
    â [Yes  ]]                                                    [  No  ] â  
    ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ  
               âââââââââââââââââââââââââââââââââââââââââââââââââ              
               â [   OK   ]       [ Cancel ]       [  Help  ]  â  
               âââââââââââââââââââââââââââââââââââââââââââââââââ  






&lt;/code&gt;
    &lt;code&gt;
   ââââââââââââââââââââââââââConfirmation (hp705)âââââââââââââââââââââââââââ  
   â                                                                       â  
   â This system ("hp705") should be in single user state before being     â  
   â converted to a cluster server. Changes to the file system, and a      â  
   â following reboot, can negatively affect running processes. This       â  
   â system is not currently in single user state.                         â  
   â                                                                       â  
   â To view system status, start a new window (or press F7 on a terminal  â  
   â to escape to a shell), and type "who -r" (see the who(1) manual       â  
   â entry).                                                               â  
   â                                                                       â  
   â To bring the system to single user state, visit the Routine Tasks     â  
   â area of SAM, or exit SAM from the main menu and then type             â  
   â "/etc/shutdown" (see the shutdown(1M) manual entry). Once the system  â  
   â is in single user state, you can restart SAM to convert the system to â  
   â a cluster server.                                                     â  
   â                                                                       â  
   â Do you want to continue to convert your system to a cluster server    â  
   â without changing the system to single user state?                     â  
   âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ  
   â [ Yes  ]                                                     [[No  ]] â  
   âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ  

&lt;/code&gt;
    &lt;p&gt;Hmmm, OK, fine, I'll drop to single-user mode and do it on the console instead of over telnet. Sorry, no more copy-pastes of the cluster setup process, but you aren't missing much.&lt;/p&gt;
    &lt;p&gt;Once we're in single user mode, it lets us set up a cluster. And once we've accepted that it's an irreversible process (weird), actually setting up the cluster takes an age to complete. It's not immediately clear why it needs to thrash the disk for 20 minutes, but once that's done, we reboot and then we can go back in to SAM and add a new machine to the cluster. But, it's only letting us as S700 machines (i.e. PA-RISC machines), not S300 machines (that have the 68K architecture).&lt;/p&gt;
    &lt;p&gt;Another quick side-note here to shout-out to HP-UX for including a sensible &lt;code&gt;/etc/nsswitch.conf&lt;/code&gt; out of the box - one that looks at the &lt;code&gt;/etc/hosts&lt;/code&gt; file and then the DNS resolver configured in &lt;code&gt;/etc/resolv.conf&lt;/code&gt;. Most of you think this a weird thing to celebrate, but some of you have had the pain of installing old versions of SunOS and Solaris before, and you do not think this a weird thing to celebrate.&lt;/p&gt;
    &lt;head rend="h2"&gt;HP-UX 9 for Series 300 (68K)&lt;/head&gt;
    &lt;p&gt;HP-UX 9 for the Series 300 is a different set of install CDs, containg 68K binaries. It makes sense that we cannot add Series 300 machines to our cluster, because we have no 68K binaries for them to load over the network.&lt;/p&gt;
    &lt;p&gt;So how you do get Series 300 binaries on a Series 700 machine? You insert the Series 300 Core OS disk (not the bootable Install disk), and you install HP-UX 9 for Series 300. Over the top of the existing install.&lt;/p&gt;
    &lt;p&gt;This is profoundly weird and when I first tried this, I was sure I was doing something wrong and that I was about to trash my whole machine. You can imagine my surprise when, having done this second install (of an alien architecture), the Model 705 carried on working. I could even reboot it. Not only that, but now I was now able to add an S300 machine to my cluster too. I simply specifyied the Ethernet MAC address of my Model 340, along with a hostname (which it used to pick up the IP address from DNS, which was nice), and that was that. All configured.&lt;/p&gt;
    &lt;p&gt;You can further imagine my surprise when I connected the Model 340 to Model 705 with my new 10base2 cable (and T-pieces and terminators) and it boots right up, into HP-UX 9 for 68K, over the network. The root password is the same root password I have set up on the Model 705. In fact, it's the same root filesystem. I can make a file on the 340 and see it on the 705, like this:&lt;/p&gt;
    &lt;code&gt;$ uname -a
HP-UX hp340 B.09.10 A 9000/340 080009034425 two-user license
$ mount
/ on /dev+/localroot/dsk/c201d0s0 read/write on Tue May 23 19:48:13 1995 (hp705)
/UPDATE_CDROM on /dev+/localroot/dsk/c201d4s0 read only on Sun Nov  9 17:20:59 1997 (hp705)
$ echo "this is a test" &amp;gt; /tmp/test
$ cat /tmp/test
this is a test
&lt;/code&gt;
    &lt;p&gt;And on the other machine:&lt;/p&gt;
    &lt;code&gt;$ uname -a
HP-UX hp705 A.09.07 A 9000/705 2001450354 two-user license
$ mount
/ on /dev+/localroot/dsk/c201d0s0 read/write on Tue May 23 19:48:13 1995 (hp705)
/UPDATE_CDROM on /dev+/localroot/dsk/c201d4s0 read only on Sun Nov  9 17:20:59 1997 (hp705)
$ cat /tmp/test
this is a test
&lt;/code&gt;
    &lt;p&gt;But, binaries (like &lt;code&gt;/bin/ls&lt;/code&gt;) are PA-RISC code on the 705 and 68K code on the 340. I know this, because the binaries work on each machine, but I can see this using the &lt;code&gt;file&lt;/code&gt; command.&lt;/p&gt;
    &lt;p&gt;On the 705:&lt;/p&gt;
    &lt;code&gt;$ file /bin/ls
/bin/ls:        s800 shared executable
$ ls -l /bin/ls
-r-xr-xr-x   6 bin      bin       172032 Jun  9  1995 /bin/ls
&lt;/code&gt;
    &lt;p&gt;On the 340:&lt;/p&gt;
    &lt;code&gt;$ file /bin/ls
/bin/ls:        s200 demand-load executable -version 2
$ ls -l /bin/ls
-r-xr-xr-x   6 bin      bin       143360 Feb 27  1995 /bin/ls
&lt;/code&gt;
    &lt;p&gt;They are not the same file.&lt;/p&gt;
    &lt;p&gt;So ... they have mounted the same filesystem but the filesystem contents are different. What on earth is going on? How is one file both a 68K binary and a PA-RISC binary at the same time? But other files are just the same file?&lt;/p&gt;
    &lt;p&gt;You might think it's the NEXTSTEP trick of so-called fat binaries (as inherited by MacOS X and modern macOS). But look - the file sizes and timestamps don't match. So it's not one file with two binaries inside it.&lt;/p&gt;
    &lt;p&gt;I have bad news. That 20 minutes of thrashing when we set up cluster mode? We created ourselves a Context Dependent Filesystem. The contents of our filesystem are literally context-dependent. And the context comes from the machine you are logged in to.&lt;/p&gt;
    &lt;head rend="h2"&gt;Context Dependent Filesystems&lt;/head&gt;
    &lt;p&gt;Now we get to the point of the blog post. This filesystem is wild and I can totally see why HP ditched it in HP-UX 10.&lt;/p&gt;
    &lt;p&gt;When a file is a context-dependent file (or CDF), it in fact becomes a directory. Within this directory are files named after the various supported contexts. When you access the filename, you get the contents according to the context you are in. But when you access the filename including a &lt;code&gt;+&lt;/code&gt; character at the end, you can see the directory and the context-dependent files it contains.&lt;/p&gt;
    &lt;p&gt;Directories can also be context-dependent and when that happens, each entry it contains is a directory for a specific context.&lt;/p&gt;
    &lt;p&gt;Here's &lt;code&gt;/bin&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;$ ls -ld /bin
drwxr-xr-x   3 root     root        2048 May 23  1995 /bin
$ ls -ld /bin+
drwsr-xr-x   4 root     root        1024 May 23  1995 /bin+
$ ls -l /bin+
total 10
drwxr-xr-x   3 root     root        2060 Nov  9 17:44 HP-MC68020
drwxr-xr-x   3 root     root        2048 May 23  1995 HP-PA
$ ls -l /bin+/HP-PA/ls
-r-xr-xr-x   6 bin      bin       172032 Jun  9  1995 /bin+/HP-PA/ls
$ ls -l /bin+/HP-MC68020/ls
-r-xr-xr-x   6 bin      bin       143360 Feb 27  1995 /bin+/HP-MC68020/ls
&lt;/code&gt;
    &lt;p&gt;Oh look, our two copies of &lt;code&gt;ls&lt;/code&gt;! It appears the context for the Series 700 files is &lt;code&gt;HP-PA&lt;/code&gt; and the context for the Series 300 files is &lt;code&gt;HP-MC68020&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;(Side note: Don't worry about the dates - I moved the clock forward from the default of 1995 to 1997 before installing the 68K version because I got warnings on boot-up that files were newer than the current date/time)&lt;/p&gt;
    &lt;p&gt;They use this system even if you don't have a mixed-architecture cluster. There are some config files in &lt;code&gt;/etc&lt;/code&gt; where the context is the hostname of the machine that's accessing the file. That way each machine in the cluster can get a unique copy of the config file (like &lt;code&gt;/etc/checklist&lt;/code&gt;) whilst they can all share the same copy of some files (like &lt;code&gt;/etc/passwd&lt;/code&gt;, which is not a CDF).&lt;/p&gt;
    &lt;code&gt;$ ls -l /etc/checklist+
total 2
-rw-rw-rw-   1 root     sys            0 Nov  9 19:08 hp340
-r--r--r--   1 bin      bin          225 May 23  1995 hp705
$ cat /etc/checklist
# System /etc/checklist file.  Static information about the file systems
# See checklist(4) and sam(1M) for further details on configuring devices.
/dev/dsk/c201d0s0   /               hfs    defaults  0 1 # Root device entry
$ cat /etc/checklist+/hp705
# System /etc/checklist file.  Static information about the file systems
# See checklist(4) and sam(1M) for further details on configuring devices.
/dev/dsk/c201d0s0   /               hfs    defaults  0 1 # Root device entry
$ cat /etc/checklist+/hp340
$
&lt;/code&gt;
    &lt;p&gt;Files you create whilst using the system will just be regular files - if you want to create a CDF, you must use the &lt;code&gt;makecdf&lt;/code&gt; command. This turns out to be important because we need to fix a bug.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fixing X11R5&lt;/head&gt;
    &lt;p&gt;If you try and run the VUE desktop on the Model 340 on this version of HP-UX, when booted from a Series 700 server running that version of HP-UX, the X11 server will fail to start. This is due to a missing library called &lt;code&gt;libSXR5.sl&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;After a lot of poking around online and finding extremely little about this file, I worked out that this because the &lt;code&gt;X11-SERV&lt;/code&gt; package did not install correctly when we installed HP-UX for Series 300. Looking at &lt;code&gt;/tmp/update.log&lt;/code&gt; we see:&lt;/p&gt;
    &lt;code&gt;       * Beginning customize script for fileset "X11-SERV" (163 of 174) using 
         the command:  /system+/HP-MC68020/X11-SERV/customize HP-MC68020
cp: cannot create /usr/lib/X11/extensions/libSXR5.sl+/HP-MC68020: No such file or directory
NOTE:  couldn't copy /etc/newconfig+/HP-MC68020/X11R5/libSXR5.sl to 
       /usr/lib/X11/extensions/libSXR5.sl+/HP-MC68020
ERROR:   Customize script for fileset "X11-SERV" failed.  You might want to 
         re-invoke it manually later.
&lt;/code&gt;
    &lt;p&gt;That's interesting. It's trying to put the Series 300 file into a context called &lt;code&gt;HP-MC68020&lt;/code&gt; but it cannot. Does that CDF exist? No it does not. But there is a file called &lt;code&gt;libSXR5A.sl&lt;/code&gt;, which is not a CDF.&lt;/p&gt;
    &lt;p&gt;It turns out that this because in HP-UX 9.07 for Series 700, the library is called &lt;code&gt;libSXR5A.sl&lt;/code&gt;. My theory is that they updated it at some point and figured it needed a new name. However, when we installed HP-UX 9.10 for Series 300, it still thinks the library is called &lt;code&gt;libSXR5.sl&lt;/code&gt;, and it tries to install it to an existing CDF of that name, which does not exist. Therefore the installation of the &lt;code&gt;X11-SERV&lt;/code&gt; package fails and that file ends up missing.&lt;/p&gt;
    &lt;p&gt;The workaround is to create the CDF manually, and then retry the installation of that package.&lt;/p&gt;
    &lt;code&gt;$ makecdf /usr/lib/X11/extensions/libSXR5.sl
$ /system+/HP-MC68020/X11-SERV/customize HP-MC68020
NOTE: copying /etc/newconfig+/HP-MC68020/X11R5/libSXR5.sl to /usr/lib/X11/extensions/libSXR5.sl+/HP-MC68020
$ ls -l /usr/lib/X11/extensions/libSXR5.sl+
total 36
-r-xr-xr-x   1 root     sys        18262 Nov  9 18:22 HP-MC68020
&lt;/code&gt;
    &lt;p&gt;If you ever try to replicate this setup, I hope this helps.&lt;/p&gt;
    &lt;p&gt;Now we have the file, and we can run X11R5 and the VUE desktop on our 68K UNIX workstation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping up&lt;/head&gt;
    &lt;p&gt;You want to see the original version of the Sega classic Columns, running on a 68K UNIX workstation from 1989, in glorious 1280x1024 8-bit colour?&lt;/p&gt;
    &lt;p&gt;Turns out it was written by HP employee Jay Geertsen, and shipped as a game/demo in HP-UX. Sega later licensed it from the author, and you might remember playing it in the Arcade or on the Sega Mega Drive.&lt;/p&gt;
    &lt;p&gt;But do you want to play this game, on this hardware? Then come to the Retro Computer Festival, 15-16 November 2026 at the Centre for Computing History. I'll be there with these two monsters, along with a few more HPs, my SGI Power Indigo 2, and a few Sun workstations for good measure. Tickets are available from https://www.computinghistory.org.uk/ and are selling fast.&lt;/p&gt;
    &lt;p&gt;If you'd like more details about HP-UX in Cluster Mode, Bitsavers have a copy of Managing Clusters of HP 9000 Computers: Sharing the HP-UX Filesystem, along with many other interesting documents about HP-UX. Definitely worth taking a look.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thejpster.org.uk/blog/blog-2025-11-08/"/><published>2025-11-10T08:48:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45874659</id><title>Europe to decide if 6 GHz is shared between Wi-Fi and cellular networks</title><updated>2025-11-10T18:15:28.838654+00:00</updated><content>&lt;doc fingerprint="ed4c1d715eb01e87"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Europe to decide if 6 GHz is shared between Wi-Fi and cellular networks&lt;/head&gt;
    &lt;head rend="h2"&gt;Two different groups want this valuable spectrum, but can they share?&lt;/head&gt;
    &lt;p&gt;A row is brewing in Europe over the 6 GHz part of the wireless spectrum, between those who believe it should be licensed for use by cellular networks and others that want it reserved for Wi-Fi.&lt;/p&gt;
    &lt;p&gt;The Wi-Fi Alliance and the Dynamic Spectrum Alliance (DSA) have published open letters addressed to "EU digital ministers," expressing concerns that the upper 6 GHz band (6425 to 7125 MHz) may be rendered off-limits to Wi-Fi networks in European Union countries.&lt;/p&gt;
    &lt;p&gt;At the heart of the problem is that newer Wi-Fi standards such as Wi-Fi 6E and Wi-Fi 7 are capable of using frequencies in the entire 6 GHz band to provide greater performance. But mobile operators are also eyeing this band for 5G and 6G network services.&lt;/p&gt;
    &lt;p&gt;The Radio Spectrum Policy Group (RSPG) of the European Commission is currently exploring ways of sharing the upper 6 GHz band between license-exempt technologies such as Wi-Fi and mobile networks. The lower part of the band is already license-exempt. Britain's telco regulator Ofcom is following a similar policy, after a consultation process in 2023.&lt;/p&gt;
    &lt;p&gt;However, the Wi-Fi camp is worried that the German government may have changed its stance to favor exclusive mobile network use of the upper 6 GHz band, potentially influencing the RSPG's decision.&lt;/p&gt;
    &lt;p&gt;A spokesperson for the Federal Ministry for Digital and Transport told German news site Heise Online: "The frequency requirements of mobile network operators in the upper 6 GHz band are assessed as greater with a view to future 6G applications" than those of Wi-Fi applications.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Apartment living to get worse in 5 years as 6 GHz Wi-Fi nears 'exhaustion'&lt;/item&gt;
      &lt;item&gt;Trump's budget bill opens wide swath of spectrum for sale&lt;/item&gt;
      &lt;item&gt;EchoStar secures rights to spectrum it plans to sell to SpaceX&lt;/item&gt;
      &lt;item&gt;EchoStar sells off its spectrum for more than its total market cap&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In response, the Wi-Fi Alliance and the DSA are trying to stoke fears that such a move would severely dent Europe's digital development, claiming Wi-Fi is the primary way consumers access the internet and constraining it would impact progress.&lt;/p&gt;
    &lt;p&gt;"Blocking Wi-Fi access to the upper 6 GHz band would be devastating to the future of Wi-Fi technology in Europe. This spectrum is uniquely positioned to sustain the evolution of the Wi-Fi ecosystem and enable the next generation of digital innovation," said the DSA.&lt;/p&gt;
    &lt;p&gt;The DSA styles itself as a global body advocating for regulations that will deliver more efficient spectrum use, but its member list appears to consist chiefly of US tech giants – Amazon, Apple, Meta, Microsoft, Broadcom, and Cisco.&lt;/p&gt;
    &lt;p&gt;The Wi-Fi Alliance complained that its members were working with the RSPG's proposals to try and use the spectrum on a shared basis, in line with the European Commission's mandate.&lt;/p&gt;
    &lt;p&gt;"By contrast, the mobile industry is arguing against a compromise. It is now demanding exclusive use of the entire upper 6 GHz band for mobile services, arguing this would strengthen Europe's digital sovereignty," its letter states.&lt;/p&gt;
    &lt;p&gt;It claims that Wi-Fi has access to "significantly less spectrum than mobile. These traffic patterns show Wi-Fi's need for the upper 6 GHz band far exceeds that of mobile."&lt;/p&gt;
    &lt;p&gt;The mobile telecoms industry sees it differently, of course. Vodafone has previously conducted tests in the upper 6 GHz frequencies, achieving download speeds of up to 5 Gbps, and saying it should be made available to boost cellular capacity when current bandwidth becomes exhausted.&lt;/p&gt;
    &lt;p&gt;Nokia and Swedish telco Telia also carried out a pilot deployment using the upper 6 GHz spectrum last year, claiming it showed the ability to add "massive capacity" in built-up areas, while high throughput can be achieved in suburban or rural areas.&lt;/p&gt;
    &lt;p&gt;In this respect, the mobile industry has backing from the International Telecommunication Union (ITU), which earmarked the upper 6 GHz band for cellular services at the World Radio Conference (WRC) in 2023.&lt;/p&gt;
    &lt;p&gt;However, the US telco regulator the FCC reserved the entire 6 GHz band for Wi-Fi and other unlicensed operations back in 2020. Other countries are not prevented from following their own path.&lt;/p&gt;
    &lt;p&gt;All eyes will be on the RSPG's next Plenary Meeting on November 12, to see what decision (if any) it adopts.&lt;/p&gt;
    &lt;p&gt;A spokesperson at the European Commission sent a statement to The Register:&lt;/p&gt;
    &lt;p&gt;"The Commission envisages a technical harmonisation decision on the upper 6 GHz band.To this end, the Commission has tasked the European Conference of Postal and Telecommunications Administrations (CEPT) to develop EU-harmonised technical conditions for a preferred usage scenario of the band. The CEPT has to deliver its final report in July 2027." ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theregister.com/2025/11/09/europe_to_decide_if_6/"/><published>2025-11-10T10:53:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45874850</id><title>DNS Provider Quad9 Sees Piracy Blocking Orders as "Existential Threat"</title><updated>2025-11-10T18:15:28.596777+00:00</updated><content>&lt;doc fingerprint="391289e1110cdb80"&gt;
  &lt;main&gt;
    &lt;p&gt;In May 2024, the Paris Judicial Court ordered Google, Cloudflare, and Cisco to block access to several pirate sports streaming sites.&lt;/p&gt;
    &lt;p&gt;The move was a major enforcement escalation by French rightsholders, but in hindsight it was only the beginning.&lt;/p&gt;
    &lt;p&gt;In the months that followed, additional rightsholders such as DAZN and beIN joined in on the action with similar requests, while more DNS providers were added as targets, including Quad9 and Vercel. This pitted notably smaller players against these billion-dollar companies in court.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Existential Threat&lt;/head&gt;
    &lt;p&gt;Quad9 was no stranger to site blocking requests, having previously dealt with a similar legal battle in Germany. That said, for the small Swiss non-profit organization, these proceedings are more than a legal disagreement. They present an existential threat.&lt;/p&gt;
    &lt;p&gt;For billion-dollar tech companies Google and Cloudflare, dealing with these legal challenges is a nuisance, but they have the means to fight back. In a recent blog post, Quad9 explains that its foundation doesn’t have this luxury.&lt;/p&gt;
    &lt;p&gt;“For large commercial players such as Google, Cloudflare, or Cisco, these costs — legal, lobbying, or engineering — are absorbed as part of their business overhead.&lt;/p&gt;
    &lt;p&gt;“For small, mission-driven nonprofits like Quad9, they represent an existential threat,” the DNS provider adds.&lt;/p&gt;
    &lt;p&gt;Ideally Quad9 would like to defend itself in these blocking cases, as Google and Cloudflare have done. However, since it doesn’t have the financial resources to do so, it chose not to make an appearance in one of the recent site-blocking cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Breaking the Internet’s Plumbing&lt;/head&gt;
    &lt;p&gt;Quad9 argues that copyright holders are increasingly trying to hold neutral intermediaries liable for piracy. Instead of going after the infringers directly, ISPs, VPNs, and DNS providers have to take on the enforcement burden.&lt;/p&gt;
    &lt;p&gt;This is particularly problematic for smaller operations that, according to Quad9, simply don’t have the means to do so indefinitely. Not only that, by going after DNS providers, these orders also directly affect key internet infrastructure providers.&lt;/p&gt;
    &lt;p&gt;“Instead of targeting the platforms that profit from infringement, IP owners are increasingly going after the neutral infrastructure providers that simply make the internet work,” Quad9 writes.&lt;/p&gt;
    &lt;p&gt;In response to the French blocking efforts, Cisco decided to leave France, so the effects of these measures are already being felt.&lt;/p&gt;
    &lt;p&gt;Other companies, such as Google and Cloudflare, have the technical means to restrict the blockades to France, but not all providers can do so easily. That includes Quad9, which had no other choice than to apply the French blocking request worldwide.&lt;/p&gt;
    &lt;head rend="h2"&gt;Big Questions&lt;/head&gt;
    &lt;p&gt;In France, the courts have clearly decided that these blocking orders are warranted, and while some are under appeal, there’s no indication that they will be reversed anytime soon. That said, Quad9 believes that a broader discussion is warranted, and it poses several questions that go to the heart of how the internet should function.&lt;/p&gt;
    &lt;p&gt;In its blog post, the foundation asks, among other things:&lt;/p&gt;
    &lt;p&gt;“Should neutral, technical infrastructure be held responsible for the actions of others?”&lt;/p&gt;
    &lt;p&gt;“How far should courts reach across jurisdictions to impose national laws on global networks?”&lt;/p&gt;
    &lt;p&gt;“Can small nonprofits survive under legal obligations designed for global corporations?”&lt;/p&gt;
    &lt;p&gt;“What happens to privacy and resiliency when only a handful of corporations can afford to comply?”&lt;/p&gt;
    &lt;p&gt;“At what point does legal compliance become de facto censorship?”&lt;/p&gt;
    &lt;p&gt;These are not just rhetorical questions for the Swiss non-profit. After fighting and winning a multi-year, costly legal battle against Sony in Germany, Quad9’s “existential threat” has reemerged in France.&lt;/p&gt;
    &lt;p&gt;Ultimately, Quad9 warns that these blocking battles may lead to a less open, less private, and more centralized internet, leaving the “plumbing” in the hands of a few corporate giants who can afford to pay the legal bills.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://torrentfreak.com/dns-provider-quad9-sees-piracy-blocking-orders-as-existential-threat/"/><published>2025-11-10T11:21:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45875697</id><title>Refashion: Reconfigurable Garments via Modular Design</title><updated>2025-11-10T18:15:28.426121+00:00</updated><content>&lt;doc fingerprint="bd1cb823d0f436ef"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Human-Computer Interaction&lt;/head&gt;&lt;p&gt; [Submitted on 13 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Refashion: Reconfigurable Garments via Modular Design&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:While bodies change over time and trends vary, most store-bought clothing comes in fixed sizes and styles and fails to adapt to these changes. Alterations can enable small changes to otherwise static garments, but these changes often require sewing and are non-reversible. We propose a modular approach to garment design that considers resizing, restyling, and reuse earlier in the design process. Our contributions include a compact set of modules and connectors that form the building blocks of modular garments, a method to decompose a garment into modules via integer linear programming, and a digital design tool that supports modular garment design and simulation. Our user evaluation suggests that our approach to modular design can support the creation of a wide range of garments and can help users transform them across sizes and styles while reusing the same building blocks.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.11941"/><published>2025-11-10T13:19:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45875903</id><title>Steven Heller's Font of the Month: Archive Matrix</title><updated>2025-11-10T18:15:28.034483+00:00</updated><content/><link href="https://ilovetypography.com/2025/11/07/steven-hellers-font-of-the-month-archive-matrix/"/><published>2025-11-10T13:38:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45875918</id><title>Interesting SPI Routing with iCE40 FPGAs</title><updated>2025-11-10T18:15:27.918116+00:00</updated><content>&lt;doc fingerprint="3e62d395092b09e2"&gt;
  &lt;main&gt;
    &lt;p&gt;A few weeks ago I posted about how much fun I was having with the Fomu FPGA development board while travelling. This project from Tim ‘mithro’ Ansell and Sean ‘xobs’ Cross is not new, but remains a favorite of mine because of how portable it is — the entire board can fit in your USB port!&lt;/p&gt;
    &lt;p&gt;The Fomu includes a Lattice Semiconductor iCE40 UltraPlus 5K, which has been a popular FPGA option over the past few years due to the reverse engineered bitstream format and ability to program it with a fully open source toolchain (see updated repository here). One of the more recent production uses I have heard about is in the Oxide Computer, which I discussed with Nathanael Huffman on an episode of Microarch Club and has also come up on the Oxide &amp;amp; Friends podcast.&lt;/p&gt;
    &lt;p&gt;One of the most interesting attributes of the Fomu is that, despite the fact that it is programmed over USB, it doesn’t actually include any USB peripheral hardware. Instead, in order to make the board small enough to fit in the USB port, the USB core is implemented in RTL (Fomu uses ValentyUSB) and is included in the Foboot bootloader. Most FPGAs support writing bitstreams directly into SRAM, meaning that it will have to be reprogrammed after a power cycle, or storing a bistream in a separate flash IC that the FPGA will read from when powered on. iCE40 FPGAs are no different, but also include a Non-Volatile Configuration Memory (NVCM), which allows for one-time programming of a bitstream in high-volume applications. From the iCE40 Programming and Configuration Technical Note:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;iCE40 components are configured for a specific application by loading a binary configuration bitstream image, generated by the Lattice development system. For high-volume applications, the bitstream image is usually permanently programmed in the on-chip Non-volatile Configuration Memory. However, the bitstream image can also be stored externally in a standard, low-cost commodity SPI serial Flash PROM. The iCE40 component can automatically load the image using the SPI Master Configuration Interface. Similarly, the iCE40 configuration data can be downloaded from an external processor, microcontroller, or DSP using an SPI-like serial interface.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Given that the Fomu is primarily intended for prototyping and education, utilizing the NVCM is unnecessary. However, it does include a GD25Q16CEIGR flash chip for persistent bitstream storage. Despite the Fomu hardware also being open source, I hadn’t spent much time looking at the schematic when developing with it in the past. However, while on the plane ride back from my travels, I was reading some of the documentation for the device and became curious about how the device supported both loading bitstreams into SRAM on the iCE40 and into the external flash.&lt;/p&gt;
    &lt;p&gt;Other FPGA development boards, such as the Arty A7 I have previously written about, support configuring the FPGA’s SRAM by including a USB to Serial IC (the Arty A7 uses the FTDI FT2232HQ) that can be used to configure the FPGA directly, or configure the FPGA with a bitstream that allows it to talk to the SPI flash, which is subsequently used to store the user bitstream in flash. From the Arty A7 reference manual:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;When programming a nonvolatile flash device, a bitstream file is transferred to the flash in a two-step process. First, the FPGA is programmed with a circuit that can program flash devices, and then data is transferred to the flash device via the FPGA circuit (this complexity is hidden from the user by the Xilinx tools). This is called indirect programming. After the flash device has been programmed, it can automatically configure the FPGA at a subsequent power-on or reset event as determined by the mode jumper setting.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;However, as previously mentioned, the Fomu’s USB core is implemented in RTL, which presents a few challenges. Namely, the FPGA needs to be “bootstrapped” — we cannot configure the FPGA or the SPI flash via USB without the USB core already running on the FPGA. Fomu uses a bootloader, Foboot, which includes gateware for a RISC-V core (VexRiscv) and various peripherals, as well as software for USB and DFU suppport. If you buy a Fomu, Foboot will already be present on the device. You can update Foboot using the Booster program, but if you somehow perform a faulty update, you could find yourself with a bricked device that cannot be accesed over USB. In that case, you’ll need to be able to access the components by some other means. Or, if you’re like me, you might just be interested in loading alternative gateware and software onto the device.&lt;/p&gt;
    &lt;p&gt;The Fomu hardware repository has a nice image with some of the board’s test points labeled.&lt;/p&gt;
    &lt;p&gt;The first thing that I noticed was that there was only one “chip select” (&lt;code&gt;SPI_CS&lt;/code&gt;) test point. Both the FPGA and the flash IC can act as SPI
peripherals, and typically a &lt;code&gt;CS&lt;/code&gt; line is required from the controller to each
peripheral in a multidrop configuration, or peripherals can be
daisy-chained
if supported. The iCE40 is particularly interesting in this scenario because, as
previously mentioned, it can act as a controller when reading from the flash IC,
or as a peripheral when being configured directly. When supplying power, the
iCE40 will act as a SPI controller by default and attempt to load a bistream
from the flash IC. If we want to program the flash directly via the test points,
then we need to keep the iCE40 from attempting to control it. This is possible
because the &lt;code&gt;CRESET&lt;/code&gt; pin is also available on a test point.&lt;/p&gt;
    &lt;p&gt;As shown in the technical note, driving &lt;code&gt;CRESET&lt;/code&gt; low will reset the device, and
configuration will not begin until the next rising edge. At this point it is
clear how we can go about programming the flash IC: hold the iCE40 in reset
while we program the flash using the exposed SPI test points. One plausible
assumption is that only the flash IC can be accessed over SPI via the test
points. In fact, we really don’t need direct access to the iCE40 because if the
flash IC can be programmed, then the iCE40 will load the persistent bitstream
when powered on, and a bricked device could be recovered.&lt;/p&gt;
    &lt;p&gt;Interestingly, the iCEstick evaluation board made by Lattice Semiconductor, which uses an FTDI FT2232H in similar fashion to the Arty A7, takes this to heart. In the user guide, it states the following under “Known Issue”.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This board is designed for SPI flash programming only. This would prevent the iCE device from being accidentally NVCM programmed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;(This is also called out in the help output for &lt;code&gt;iceprog&lt;/code&gt;,
a programming tool included in Project IceStorm.)&lt;/p&gt;
    &lt;p&gt;As you would expect, this is reflected in the schematic from the same document. The SPI chip select pins on the iCE40 and the flash IC have a pull-up resistor, and the &lt;code&gt;iCE_SS_B&lt;/code&gt; net allows for pulling the &lt;code&gt;CS&lt;/code&gt; pin on the flash IC low for
programming, while the iCE40 &lt;code&gt;SPI_SS_B&lt;/code&gt; pin drives it after boot when the FPGA
is acting as the controller.&lt;/p&gt;
    &lt;p&gt;However, as you may have noticed in the first image in this post, the note on the Fomu schematic indicates that both the iCE40 and the flash IC can be programmed via the test points. This complicates things a bit because, up until now, each component only ever plays a single role:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The iCE40 FPGA is always a SPI controller.&lt;/item&gt;
      &lt;item&gt;The programmer (e.g. the machine connected to the test points) is always a SPI controller.&lt;/item&gt;
      &lt;item&gt;The flash IC is always a SPI peripheral, either accessed by the programmer or the FPGA.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If we are configuring the iCE40 directly, the iCE40 now needs to act as a peripheral, and the flash IC needs to no longer be driven by traffic on the SPI nets. Though not labeled in the device image, opening the design in the KiCad PCB viewer reveals the placement of the &lt;code&gt;SPI_IO2&lt;/code&gt; and &lt;code&gt;SPI_IO3&lt;/code&gt; (as well as the
&lt;code&gt;CDONE&lt;/code&gt;, &lt;code&gt;USB_P&lt;/code&gt;, and &lt;code&gt;USB_N&lt;/code&gt;) test points.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;SPI_IO3&lt;/code&gt; is connected to the flash IC &lt;code&gt;HOLD&lt;/code&gt; pin. This is in contrast to the
iCEstick, where the flash IC’s &lt;code&gt;HOLD&lt;/code&gt; pin has a pull-up resistor (i.e. the
active low pin is never asserted). Because we have access to the &lt;code&gt;HOLD&lt;/code&gt; pin on
the Fomu, we can drive it low to have the flash IC ignore all SPI traffic while
configuring the iCE40 directly. We also need to swap the pins used for the MOSI
and MISO signals, as &lt;code&gt;SPI_MOSI&lt;/code&gt; is connected to the iCE40’s &lt;code&gt;SPI_SO&lt;/code&gt; pin, and
&lt;code&gt;SPI_MISO&lt;/code&gt; is connected to &lt;code&gt;SPI_SI&lt;/code&gt;. When I looked at
&lt;code&gt;fomu-flash&lt;/code&gt;, a utility to program Fomu
boards using a Raspberry Pi, it appeared as though that was exactly what was
happening.&lt;/p&gt;
    &lt;code&gt;        spiHold(spi);
        spiSwapTxRx(spi);
        fpgaResetSlave(fpga);
&lt;/code&gt;
    &lt;p&gt;However, upon further inspection, &lt;code&gt;spiHold()&lt;/code&gt; is not actually asserting the
&lt;code&gt;HOLD&lt;/code&gt; pin, but rather issuing a
command.&lt;/p&gt;
    &lt;code&gt;void spiHold(struct ff_spi *spi) {
	spiBegin(spi);
	spiCommand(spi, 0xb9);
	spiEnd(spi);
}
void spiUnhold(struct ff_spi *spi) {
	spiBegin(spi);
	spiCommand(spi, 0xab);
	spiEnd(spi);
}
&lt;/code&gt;
    &lt;p&gt;In looking up the &lt;code&gt;spiHold()&lt;/code&gt; / &lt;code&gt;spiUnhold()&lt;/code&gt; commands in the GD25Q16CEIGR
datasheet,
I observed that they correspond to “Deep Power-Down (DP)” (&lt;code&gt;0xb9&lt;/code&gt;) and “Release
from Deep Power-Down and Read Device ID (RDI)” (&lt;code&gt;0xab&lt;/code&gt;).&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Executing the Deep Power-Down (DP) command is the only way to put the device in the lowest consumption mode (the Deep Power-Down Mode). It can also be used as an extra software protection mechanism, while the device is not in active use, since in this mode, the device ignores all Write, Program and Erase commands… Once the device has entered the Deep Power-Down Mode, all commands are ignored except the Release from Deep Power-Down and Read Device ID (RDI) command. These commands can release the device from this mode.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There are a few reasons why using the power down strategy rather than asserting &lt;code&gt;HOLD&lt;/code&gt; may be useful. First, the GD25Q16CEIGR supports Dual and Quad SPI, and in
the latter case the &lt;code&gt;HOLD&lt;/code&gt; pin is reassigned as the final I/O pin (&lt;code&gt;IO3&lt;/code&gt;). If
the goal is to configure the iCE40 directly, this may not be too much of a
problem, but the Quad Enable (QE) bit is set in a non-volatile status register,
so a previous interaction with the device where it was set could cause the
&lt;code&gt;HOLD&lt;/code&gt; strategy to fail (with the Fomu specifically, I suspect that would also
cause issues any time the iCE40 attempted to control the flash IC). Perhaps a
more likely motivator is that it reduces the number of test points that need to
be accessed to configure the iCE40 directly. Only the 7 labeled in the initial
image (&lt;code&gt;5V&lt;/code&gt;, &lt;code&gt;GND&lt;/code&gt;, &lt;code&gt;CRESET&lt;/code&gt;, &lt;code&gt;SPI_MOSI&lt;/code&gt;, &lt;code&gt;SPI_MISO&lt;/code&gt;, &lt;code&gt;SPI_CLK&lt;/code&gt;, &lt;code&gt;SPI_CS&lt;/code&gt;) are
necessary.&lt;/p&gt;
    &lt;p&gt;FPGAs are fascinating on many dimensions, but one of the most interesting is how they are configured. As we can see with the Fomu and other iCE40 based platforms, the capabilities of the FPGA can lead to some interesting board design decisions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://danielmangum.com/posts/spi-routing-ice40-fpga/"/><published>2025-11-10T13:40:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45876098</id><title>Multistable thin-shell metastructures for multiresponsive metabots</title><updated>2025-11-10T18:15:27.733015+00:00</updated><content/><link href="https://www.science.org/doi/10.1126/sciadv.adx4359"/><published>2025-11-10T14:01:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45876598</id><title>Time to start de-Appling</title><updated>2025-11-10T18:15:26.640937+00:00</updated><content>&lt;doc fingerprint="b049d1f1222217d5"&gt;
  &lt;main&gt;
    &lt;p&gt;I‘ve done such a thorough job of de-Googling that I forgot to show up for a meeting with someone, because I hadn’t checked my Google calendar in ages. (No, they were not amused.) In my defense, I proceeded to explain to them that having de-Googled, I was also in the process of de-Appling, which is a special bonus level that those of us in the UK have unlocked.&lt;/p&gt;
    &lt;p&gt;If you’re reading this in the sunlit uplands, you need to start that too.&lt;/p&gt;
    &lt;p&gt;You need to start that because, as we recently learned, at some point in the very near future Apple is withdrawing its Advanced Data Protection (ADP) feature from the UK altogether as a result of the Home Office TCN through the Investigatory Powers Act.&lt;/p&gt;
    &lt;p&gt;Users who already had ADP enabled when the first TCN became public in February will be required to manually switch it off or lose their iCloud account.&lt;/p&gt;
    &lt;p&gt;I am not going to explain the chapter and verse of the legal saga today, because I prefer to do that for people who pay me to explain them the chapter and verse.&lt;/p&gt;
    &lt;p&gt;But I will say that the shutdown of ADP is Apple being on the right side of the geopolitical fight, as inconvenient as that may be to you and me.&lt;/p&gt;
    &lt;p&gt;When the whole debacle blew up in February, Apple announced that ADP would no longer be available for new users, but would remain unaffected for those of us who already had it activated. That assurance was nothing to sleep on, and so we have been waiting for the inevitable. Apple’s September update confirmed that its days are numbered:&lt;/p&gt;
    &lt;p&gt;So what does that mean for you? Again, from their September update:&lt;/p&gt;
    &lt;p&gt;Our communication services, like iMessage and FaceTime, remain end-to-end encrypted globally, including in the UK.&lt;/p&gt;
    &lt;p&gt;Users in the UK who have not already enabled Advanced Data Protection will no longer have the option to do so. That means the 10 iCloud data categories covered by ADP will be protected by Standard Data Protection, and UK users will not have a choice to benefit from end-to-end encryption for these categories: iCloud Backup; iCloud Drive; Photos; Notes; Reminders; Safari Bookmarks; Siri Shortcuts; Voice Memos; Wallet Passes; and Freeform.&lt;/p&gt;
    &lt;p&gt;This means that if you already had ADP activated, and e2ee is critical to your personal or operational security, you need to get everything in that list – iCloud Backup, iCloud Drive, Photos, Notes, Reminders, Safari Bookmarks, Siri Shortcuts, Voice Memos, Wallet Passes, and Freeform – off of iCloud sooner rather than later.&lt;/p&gt;
    &lt;p&gt;Once you’ve done that, go into your iCloud settings, click on Manage, then click on each thing individually to purge it off iCloud.&lt;/p&gt;
    &lt;p&gt;I’m not going to tell you where to move your stuff other than to say that if you’re moving it from one big tech company to another, you’re just being daft. Likewise, if you’re moving your stuff to a non-e2ee service, don’t bother. If you need an e2ee service try Proton. They have a Black Friday sale on.&lt;/p&gt;
    &lt;p&gt;If you have a lot of Notes, first download the Exporter app from the app store. It does what it says on the tin. You’ll end up with a folder full of markdown files which you can upload elsewhere. E2EE being the dealbreaker, I chose Standard Notes. I know a lot of folk who prefer Obsidian or Joplin. Whatever you choose, do not use a non-E2EE note service.*&lt;/p&gt;
    &lt;p&gt;You know as well as I do that you need to be moving everything you can out of the American stack anyway so just stick this task on your to-do list, which should not be Reminders, and get it done.&lt;/p&gt;
    &lt;head rend="h2"&gt;What about the non-e2ee stuff in iCloud?&lt;/head&gt;
    &lt;p&gt;The full list of what lives in iCloud and how it is or is not encrypted is here.&lt;/p&gt;
    &lt;p&gt;We know from the tiny bits of the TCN saga which have been publicly disclosed, thanks to the only two media outlets that are bothering to cover it, that the first TCN was not just for the end-to-end encrypted data protected by ADP. It was for anything on iCloud, full stop, worldwide:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;…however, the new IPT filing states the TCN “is not limited to” data stored under ADP, suggesting the UK government sought bulk interception access to Apple’s standard iCloud service, which is much more widely used by the company’s customers. The TCN also included “obligations to provide and maintain a capability to disclose categories of data stored within a cloud-based backup service”, the filing states, which suggests the government sought to tap messages or passwords that were backed up in the cloud as well. “The obligations included in the TCN are not limited to the UK or users of the service in the UK; they apply globally in respect of the relevant data categories of all iCloud users,” the IPT filing adds. Tim Bradshaw and Anna Gross at the Financial Times (£)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This means that you have some serious thinking to do about what you intend to trust to the Apple stack altogether going forward, even things like passwords.&lt;/p&gt;
    &lt;p&gt;I can’t tell you what to do but once again, you have options. Educate yourself. Consider the opsec and persec needs not just of yourself, but for the people around you who could be adversely affected by insecure data going walkies out of your account.&lt;/p&gt;
    &lt;head rend="h2"&gt;What if I’m not in the UK?&lt;/head&gt;
    &lt;p&gt;This impacts the UK only: as their September update noted, Advanced Data Protection continues to be available everywhere else in the world.&lt;/p&gt;
    &lt;p&gt;It does mean that if you have someone in the UK on your team, you need to factor them in as part of your threat model. We are all liabilities to our own opsec now.&lt;/p&gt;
    &lt;p&gt;If you’re not in the UK, and you don’t have ADP activated, take 10 seconds to do it right now, you lucky sod.&lt;lb/&gt; Settings &amp;gt; Your name Apple Account &amp;gt; iCloud &amp;gt; Advanced Data Protection&lt;/p&gt;
    &lt;head rend="h2"&gt;What about that second TCN?&lt;/head&gt;
    &lt;p&gt;On the 1st of October, the Home Office issued a second TCN against Apple for the same as before, but only for British citizens’ data. World-leading!&lt;/p&gt;
    &lt;p&gt;Those who follow my work know that this phrase made me spew a double barrel of Glaswegian swearing. British citizens’ data, as opposed to British users’ data? The dividing line here is not e.g. being located in the UK or having registered an account here, but what it says on your passport? How is Apple going to know that, much less roll it out? (/s)&lt;/p&gt;
    &lt;p&gt;Did Apple just publicly state that they’re going to be removing a security layer and adding a nationality check layer?&lt;/p&gt;
    &lt;p&gt;We don’t know.&lt;/p&gt;
    &lt;p&gt;We don’t know because as with the first TCN, that information only became available in the public domain due to someone leaking it to the media. That’s all there is to know. Everything else is confidential and NCND. There is nothing else to say because nothing else is known. If someone who did know something was sitting across from me right now, and they told me, they would be committing a crime.&lt;/p&gt;
    &lt;p&gt;Those of us who care about these things enough to show up in difficult places are keeping tabs on both TCNs, and the wider legal and technical implications of both, as best we possibly can. Don’t expect to hear anything more until January, when the Liberty/PI challenge on the first TCN goes to the Investigatory Powers Tribunal. In the interim, if you want me to bore you about ECHR case law and how the UK’s review into Article 8 seems a little too coincidentally timed, pick a pub.&lt;/p&gt;
    &lt;p&gt;Otherwise, please make sure you de-Apple, de-Google, and de-American Stack yourself when you have time, clarity, and focus to do it. Start today.&lt;/p&gt;
    &lt;p&gt;In the meantime please follow and support the only media coverage being produced about the second TCN, which comes from Bill Goodwin at Computer Weekly and Tim Bradshaw and Anna Gross at the Financial Times (£).&lt;/p&gt;
    &lt;p&gt;Above all, please remember that this is the sunlit uplands. That’s the thing about Brexit Britain having decided to go it alone where tech regulation is concerned. It did not become the vanguard of a “world-leading” third way.&lt;/p&gt;
    &lt;p&gt;It became a small and inconsequential thing easily thrown under a bus.&lt;/p&gt;
    &lt;p&gt;Header image by me: Alan Turing memorial, Manchester, where he reminds you why keeping data private can be a matter of life and death.&lt;/p&gt;
    &lt;p&gt;*For the love of the wee man do not use a non-e2ee notetaking app which has been abandoned by an owner who has a track record of personally snooping through user data when he’s in a mood, i.e. if he’s breathing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://heatherburns.tech/2025/11/10/time-to-start-de-appling/"/><published>2025-11-10T14:57:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45876744</id><title>LLMs are steroids for your Dunning-Kruger</title><updated>2025-11-10T18:15:26.326427+00:00</updated><content>&lt;doc fingerprint="68b59b5b9a8709be"&gt;
  &lt;main&gt;
    &lt;p&gt;In his 1933 essay “The Triumph of Stupidity,” Bertrand Russell remarked that “the problem with the world is that the stupid are cocksure, while the intelligent are full of doubt.” This is something I often think about when ChatGPT hits me up with another “that’s a fantastic idea” when the idea is clearly anything but great.&lt;/p&gt;
    &lt;p&gt;How often do you think a ChatGPT user walks away not just misinformed, but misinformed with conviction? I would bet this happens all the time. And I can’t help but wonder what the effects are in the big picture.&lt;/p&gt;
    &lt;p&gt;I can relate to this on a personal level: As I ChatGPT user I notice that I’m often left with a sense of certainty. After discussing an issue with an LLM I feel like I know something — a lot, perhaps — but more often than not this information is either slightly incorrect or completely wrong. And you know what? I can’t help it. Even when I acknowledge this illusion, I can’t help chasing the wonderful feeling of conviction these models give. It’s great to feel like you know almost everything. Of course I come back for more. And it’s just not the feeling; I would be dishonest to claim these models wouldn’t have huge utility. Yet I’m a little worried about the psychological dimension of this whole ordeal.&lt;/p&gt;
    &lt;p&gt;They say AI is a mirror. This summarizes my experience. I feel LLMs “amplify” thinking. These models make your thoughts reverberate by taking them to multiple new directions. And sometimes these directions are really interesting. The thing is, though, that this goes both ways: A short ChatGPT session may help improve a good idea to a great idea. On the other hand, LLMs are amazing at supercharging self-delusion. These models will happily equip misguided thinking with a fluent, authoritative voice, which, in turn, sets up a psychological trap by delivering nonsense in a nice package.&lt;/p&gt;
    &lt;p&gt;And it’s so insanely habit-forming! I almost instinctively do a little back and forth with an LLM when I want to work on an idea. It hasn’t even been that long (these models have been around for, what, three years?) and I’m so used to them that I feel naked without. It’s getting even comical sometimes. When I lost my bag the other day and was going through the apartment looking for it, my first response to my growing frustration was that “I should ask ChatGPT where it is”.&lt;/p&gt;
    &lt;p&gt;I feel like LLMs are a fairly boring technology. They are stochastic black boxes. The training is essentially run-of-the-mill statistical inference. There are some more recent innovations on software/hardware-level, but these are not LLM-specific really. Is it too sardonic to say that the real “innovation” was throwing enough money at the problem to train the models at a huge scale? Maybe RLHF was a real innovation; I’m not sure. However, I don’t really feel like there is a lot to be interested in there. And yet, the current AI boom is extraordinarily interesting.&lt;/p&gt;
    &lt;p&gt;It’s the impact. The very real effect of all this in our lives. In hindsight, this will probably be one of the major shifts, and it will be reflected upon in terms of education, work and even society at large. Language cuts to the core of what and who we are. Speech is so natural to us that we even think in speech. And when a machine credibly stepped into that territory, something changed. I’m not sure what it is — I don’t think anyone really knows at this point — but I think there is a sense of shifting tides. I think it’s something most of us are trying to make sense of.&lt;/p&gt;
    &lt;p&gt;I think LLMs should not be seen as knowledge engines but as confidence engines. That, I feel, would better illustrate the potential near and medium-term futures we are dealing with.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bytesauna.com/post/dunning-kruger"/><published>2025-11-10T15:14:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45876990</id><title>Zig and the design choices within</title><updated>2025-11-10T18:15:26.071325+00:00</updated><content>&lt;doc fingerprint="a94a993ba8232dd0"&gt;
  &lt;main&gt;
    &lt;p&gt;2025-10-14&lt;/p&gt;
    &lt;p&gt;(From someone who has spent far too much time thinking about the designs of programming languages)&lt;/p&gt;
    &lt;p&gt;This post is split up into a few sections. I would also like to preface this post with:&lt;/p&gt;
    &lt;p&gt;First, and very much foremost, Zig is not memory safe. This is, in my opinion, the most egregious thing in this post, by a very large margin. Moreso, Zig does not make any attempt to be memory safe - it can catch some things at runtime, with specific allocators, but so can C these days. Indeed, there are some cases, like use-after-realloc, that &lt;code&gt;asan&lt;/code&gt; can catch and Zig cannot.&lt;/p&gt;
    &lt;p&gt;A language in the modern day that does not make an attempt at memory safety is, in my opinion, not reasonable. It has been shown that in some areas, up to 70% of security bugs are due to memory safety issues (Source).&lt;/p&gt;
    &lt;p&gt;I subscribe to the idea that the user must be constrained. It is perhaps harsh to say, but for large and complex programs, I believe that there are very few programmers who will write memory-correct code nine times out of ten. When writing code with others, that goes down. I personally do not believe I fit into that category.&lt;/p&gt;
    &lt;p&gt;The fact that Zig allows the user to write faulty software is supported by various somewhat informal, but still useful, statistics. Notably, the following statistic disregard duplicates, and unreported errors. However, general trends are still of note. &lt;head&gt;Here are some:&lt;/head&gt;&lt;/p&gt;
    &lt;p&gt;This means that, roughly:&lt;/p&gt;
    &lt;p&gt;Not ideal.&lt;/p&gt;
    &lt;p&gt;Again, this roughly means:&lt;/p&gt;
    &lt;p&gt;Also not great. Again, these statistics are slightly off at best simply due to the nature of their collection, but the trends do not lie.&lt;/p&gt;
    &lt;p&gt;If you're not reading the above: It can be summarized as "Not ideal."&lt;/p&gt;
    &lt;p&gt;At one point, this part of the article contained a runthrough of the &lt;code&gt;zig zen&lt;/code&gt;, and my opinions on each bullet point. I have decided that that is not a constructive discussion of Zig. It suffices for me to say that I do not believe Zig particularly embodies its own zen.&lt;/p&gt;
    &lt;p&gt;Zig does generics in an odd way. I believe this is the best way of putting it. This post is not meant to be, nor will it contain, a proper explanation of Zig's &lt;code&gt;comptime&lt;/code&gt;
capabilities, so I refer the reader to the wider internet there. However, doing generics
with "normal" code means that there are multiple ways to write the same generic function.
There is no standardization between different libraries, different styles of writing code, and
different users of Zig. Every person can do generics in their own special way.&lt;/p&gt;
    &lt;p&gt;This obviously has slightly dire effects on readability. In practice, most Zig users are reasonable enough to stick to some "common patterns" of doing generics and similar, but it is widely known that if the user is giving the ability to do something, it will be done. I believe that generics are important enough they should be first class.&lt;/p&gt;
    &lt;p&gt;Arguments can be made that Zig's comptime is also useful for other things, not just generics. Some examples I have been given are conditional compilation, and variadic functions. Beyond these, I am yet to see a convincing motivating example that requires the machinery that Zig provides. Every such example can, in my experience, be solved with less powerful (and hence, for the most part, less confusing) machinery.&lt;/p&gt;
    &lt;p&gt;As a result, I am inclined to believe that Zig's comptime is a very large and all-encompassing feature that ultimately brings very little to the table that smaller features cannot.&lt;/p&gt;
    &lt;p&gt;I am personally a proponent of a good macro system, but I will readily admit people can also go overboard with one of those.&lt;/p&gt;
    &lt;p&gt;Zig's casting is a bit cumbersome. To cast a float to a specific int width, for example, must be done with &lt;code&gt;@as(i32, @intFromFloat(flt))&lt;/code&gt;. Bit of a mouthful. Inference can help here (For example if a variable is already known to be a &lt;code&gt;i32&lt;/code&gt;, the outer cast is not needed), but I would think that with Zig's comptime abilities, this could be made a bit nicer. Luckily, it is common Zig practice to annotate everything if possible, so this does come up slightly less in practice. It is still a bit bulky however.&lt;/p&gt;
    &lt;p&gt;Float to int casting additionally can invoke undefined behavior if the float is outside the integer's range. I personally prefer truncating semantics, with perhaps a specialized method (&lt;code&gt;intFromFloatUnsafe&lt;/code&gt;?) for UB semantics. That's more of a personal preference though.&lt;/p&gt;
    &lt;p&gt;Result location semantics are in theory a quite nice idea. Knowing predictably where things are going to be placed in memory is, of course, good for any systems-adjacent language! In practice, there are several choices within RLS that I find counterintuitive. Take the following example, where we attempt to swap two struct members in place:&lt;/p&gt;
    &lt;code&gt;
const std = @import("std");
const What = struct {
    a: i32,
    b: i32,
};

pub fn main() void {
    var x: What = .{ .a = 1, .b = 2 };
    x = What { .a = x.b, .b = x.a };
    std.log.info("x: {}", .{x});

    var y: What = .{ .a = 1, .b = 2 };
    y = .{ .a = y.b, .b = y.a };
    std.log.info("y: {}", .{y});
}
&lt;/code&gt;
    &lt;p&gt;This outputs the following:&lt;/p&gt;
    &lt;code&gt;info: x: .{ .a = 2, .b = 1 }
info: y: .{ .a = 2, .b = 2 }
&lt;/code&gt;
    &lt;p&gt;I will note that the equivalent C can only be written in the former style, and it prints the former.&lt;/p&gt;
    &lt;p&gt;The only difference between the latter and the former is whether the type name is present. This is intended behavior! Indeed, this very example is given in the Zig reference, a fact that I find odd. Why give a warning against something when you could just fix it? Zig does not have move or copy constructors; I do not think there is very much reason for the latter to ever behave the way it does. One extra register is all you ever need, even for an arbitrary parallel move! (Source.)&lt;/p&gt;
    &lt;p&gt;In its previous form, PRO has been removed from Zig. There was a long period where this would print &lt;code&gt;5&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;const std = @import("std");

const AAAA = struct {
    foo: [100]u32,
};

fn kindabad(a: AAAA, b: *AAAA) void {
  b.*.foo[0] = 5;

  std.debug.print("unideal: {}", .{ a.foo[0] });
}

pub fn main() !void {
    var f: AAAA = undefined;

    f.foo[0] = 0;

    kindabad(f, &amp;amp;f);
}
&lt;/code&gt;
    &lt;p&gt;As Zig would correctly, per PRO at the time, but incorrectly per common sense, pass &lt;code&gt;a&lt;/code&gt; as a reference.&lt;/p&gt;
    &lt;p&gt;This is actually mildly unfortunate. It's a very interesting optimization, and being able to guarantee behavior around optimization of parameter passing would also be quite beneficial. Unfortunately, Zig simply does not have the level of control needed to do it. Aliasing is freely allowed, and in order to make PRO work, it cannot be. Rust can, and in many cases does, do this! It's a shame Zig has to miss out.&lt;/p&gt;
    &lt;p&gt;There is current work to make PRO work in the case of pure functions (Source), so I remain hopeful that it will return in some form eventually.&lt;/p&gt;
    &lt;p&gt;The Zig compiler is not particularly fast. The LLVM backend even more so; compared to Clang, (which has the home field advantage, but can still be quite slow), and by my measurements, Clang is consistently between 3-10x faster. A new Zig backend has been written to help fix this; by similar measurements, it is consistently faster than Clang by 1.5-2x, and much faster than the Zig LLVM backend. While these numbers are nothing to scoff at, I believe there is more room for improvement, and I would like to see where it goes. Zig is a simpler language than C when comptime is not involved, and I would be excited to see that reflected in the benchmarks. It is also possible that Zig could use LLVM more efficiently, but I cannot comment on this without digging into the internals of the compiler.&lt;/p&gt;
    &lt;p&gt;Of course, all of this is quite reasonable. The Zig compiler has had far, far fewer man-hours put into it, and this of course reflects in aspects of the compiler that simply take a lot of time, such as these. I look forward to seeing what can be done in the future.&lt;/p&gt;
    &lt;p&gt;The Zig build system is a little confusing. It is very neat to be able to write build system code in the language itself, and this is a feature I believe more languages should have. Unfortunately, it is as of current not well documented enough to justify its own complexity. This of course can be improved, and I hope it is.&lt;/p&gt;
    &lt;p&gt;Zig currently does not have a "first class" language server. The "Zig Language Server", or ZLS, is unofficial; It does not have real compiler integration, so it is unfortunately limited in some ways. The creator of Zig apparently does not use a language server while programming, so I do slightly understand why it is not a priority, but I personally believe tools like a good language server are quite essential to wider/popular usage. Here are some quotes I have heard from people who have used it far more than I:&lt;/p&gt;
    &lt;p&gt;Apparently it is very limited when &lt;code&gt;comptime&lt;/code&gt; comes into play, and cannot handle compound types like 2D arrays.&lt;/p&gt;
    &lt;p&gt;I cannot offer much firsthand experience however.&lt;/p&gt;
    &lt;p&gt;There are always more errors to be caught. I particularly recently noticed that Zig cannot currently catch use-after-realloc errors, like the following:&lt;/p&gt;
    &lt;code&gt;const std = @import("std");

pub fn main() !void {
    const allocator = std.heap.page_allocator;

    var buffer = try allocator.alloc(u8, 4);

    buffer[0] = 1;
    
    const new_buffer = try allocator.realloc(buffer, 8);
    
    // Should be caught!
    buffer[0] = 99; 

    allocator.free(new_buffer);
}
&lt;/code&gt;
    &lt;p&gt;Address sanitizer with Clang can catch this, so theoretically Zig should be able to catch it (perhaps with a similar system) too.&lt;/p&gt;
    &lt;code&gt;undefined&lt;/code&gt;
    &lt;p&gt;Apparently, it is desired that comparisons with &lt;code&gt;undefined&lt;/code&gt; panic. This seems reasonable to me. However, the issue for this has been open for almost ten years, which makes me worry that it might be a while still until it is finished.&lt;/p&gt;
    &lt;p&gt;This panics in &lt;code&gt;Debug&lt;/code&gt; and &lt;code&gt;ReleaseSafe&lt;/code&gt; modes, however, so it does at least work in some cases.&lt;/p&gt;
    &lt;code&gt;pub fn main() void {
    const x: u32 = undefined;
    if (x == 0) {
        return 1;
    } else {
        return 0;
    }
}
&lt;/code&gt;
    &lt;p&gt;According to this issue, it is "not a goal of the Zig compiler" to catch issues like the following:&lt;/p&gt;
    &lt;code&gt;pub fn main() void {
    var buf: []u8 = undefined;
    
    // Very not allowed!
    buf[0] = 1;
}
&lt;/code&gt;
    &lt;p&gt;This just seems silly to me. Catching something like this, in the simple case, should be just one pass over the AST; why not do it?&lt;/p&gt;
    &lt;p&gt;Zig simply doesn't allow tabs in comments and strings? This issue explains more, but the justification of "it (a tab) is ambiguous (in) how it should be rendered", I do not quite agree with.&lt;/p&gt;
    &lt;p&gt;Strings make some sense; you can still write &lt;code&gt;\t&lt;/code&gt; for a tab, and they do indeed make output ambiguous. However, they're still allowed in indentation! This means that in commenting out code, you can take a program from valid to invalid. &lt;code&gt;zig fmt&lt;/code&gt; does reify tabs into spaces, but if your editor is misconfigured and you're not running &lt;code&gt;zig fmt&lt;/code&gt; constantly?&lt;/p&gt;
    &lt;code&gt;tabs.zig:5:36: error: comment contains invalid byte: '\t'
//        const str: *const [1:0]u8 = "w";
  ^~~~~~~~~~~
&lt;/code&gt;
    &lt;p&gt;Very odd.&lt;/p&gt;
    &lt;p&gt;Zig does not have a way to iterate through a slice or similar in any way except one-at-a-time forwards. Anything else? You're using a &lt;code&gt;while&lt;/code&gt; loop, and you'll enjoy it. Zig blanket bans proposals to change the language, so despite issues like this one, I doubt this will happen any time soon.&lt;/p&gt;
    &lt;p&gt;Zig doesn't have 'em. Everything is an error. In practice, this mostly manifests through reasonably harmless things like "unused variable" notices becoming errors, which is reasonably annoying when just trying to spitball.&lt;/p&gt;
    &lt;p&gt;For the most part, the community is about par for the course for programming language communities; that is to say, quite nice. However, I have had some reasonably negative interactions that I feel are somewhat of a general trend. They usually proceed like the following:&lt;/p&gt;
    &lt;p&gt;This is unpleasant, and while it's not a particularly uncommon thing to see in programming language communities, Zig seems to have a bit of a bad case of it. I suspect it is due to Zig's fairly minimalistic nature; it lacks a lot of features that one would otherwise use to solve problems. Of course, this is the appeal for many, but still. It is made worse when said topic is something one is particularly knowledgeable about, and the people you are conversing with believe they can solve the issue without that knowledge.&lt;/p&gt;
    &lt;p&gt;I do not believe that a few bad apples necessarily spoil the whole barrel here, but they definitely sour it.&lt;/p&gt;
    &lt;p&gt;I find Zig interesting, with an unfortunately negative connotation. I believe the goal of a C-like memory unsafe language "for the modern day", while interesting at first glance, ignores many of the issues that make C a problem in said modern day. Much of Zig seems to me like "wishful thinking"; if every programmer was 150% smarter and more capable, perhaps it would work. Alas, they are not; myself included.&lt;/p&gt;
    &lt;p&gt;I believe that modern concerns of memory safety and correctness require modern solutions; not performing patchwork fixes over the core issue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blueberrywren.dev/blog/on-zig/"/><published>2025-11-10T15:42:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877027</id><title>Reminder to passengers ahead of move to 100% digital boarding passes</title><updated>2025-11-10T18:15:25.957456+00:00</updated><content>&lt;doc fingerprint="e13683748110f1dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Our News&lt;/head&gt;
    &lt;head rend="h1"&gt;Our News&lt;/head&gt;
    &lt;head rend="h2"&gt;RYANAIR ISSUES REMINDER TO PASSENGERS AHEAD OF MOVE TO 100% DIGITAL BOARDING PASSES FROM WEDNESDAY (12 NOV)&lt;/head&gt;
    &lt;p&gt;Ryanair, Europe’s No.1 airline, today (Thurs, 6 Nov) reminded passengers that from Wed (12 Nov) it will move to 100% digital boarding passes. This means that from Wed (12 Nov) passengers will no longer be able to download and print a physical paper boarding pass but will instead need to use the digital boarding pass generated in their “myRyanair” app during check-in to board their Ryanair flight.&lt;/p&gt;
    &lt;p&gt;This transition, already adopted by nearly 80% of Ryanair’s 207M+ annual passengers, will deliver a faster, smarter, and greener travel experience. It will also give passengers easier access to a range of innovative in-app features, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Order to Seat: Order food and drinks from your phone and get served first.&lt;/item&gt;
      &lt;item&gt;Live Flight Information: Real-time status updates on boarding, gates, and delays.&lt;/item&gt;
      &lt;item&gt;Direct Updates: Instant notifications from Ryanair’s operations centre during disruption.&lt;/item&gt;
      &lt;item&gt;Alternative Flight Options: Real-time alternative flight options during disruption.&lt;/item&gt;
      &lt;item&gt;Travel Documents: accessible in one convenient place.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ryanair CMO, Dara Brady, said:&lt;/p&gt;
    &lt;p&gt;“We are now just a little less than a week out from our move to 100% digital boarding passes, meaning that from Wednesday, 12 November, passengers will no longer be able to download and print a physical paper boarding pass but will instead need to use the digital boarding pass generated in their “myRyanair” app during check-in to board their Ryanair flight.&lt;/p&gt;
    &lt;p&gt;While over 80% of passengers already use digital boarding passes, and therefore won’t be affected by this progressive change, we remind the small number of passengers who still print boarding passes to download the myRyanair app ahead of the move to 100% digital boarding passes from Wednesday, 12 November.&lt;/p&gt;
    &lt;p&gt;Moving fully digital means a faster, smarter, and greener experience for passengers, whilst also providing easier access to a range of innovative in-app features, including ‘Order to Seat’, live flight information and direct updates during disruption. We look forward to delivering an enhanced travel experience for 100% of our customers, streamlined through our best-in-class myRyanair app.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Related News&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h2"&gt;RYANAIR LAUNCHES PRAGUE – PAPHOS &amp;amp; KOSICE ROUTES&lt;/head&gt;
        &lt;p&gt;Ryanair, Europe’s No.1 airline, today (1st August) celebrated the first flight from Prague to Paphos, while on Monday (3rd August) it will launch a twice weekly service to Kosice, both as part of its extended Summer 2020 schedule.&lt;/p&gt;
        &lt;p&gt;To celebrate its new routes, Ryanair has launched a seat sale with fares from 729 Kc for travel to Kosice and from 759 Kc to Paphos, both until the end of October, which must be booked by Wednesday (5th August), only on the Ryanair.com website.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h2"&gt;RYANAIR LAUNCHES PRAGUE – PAPHOS &amp;amp; KOSICE ROUTES&lt;/head&gt;
        &lt;p&gt;Ryanair, Europe’s No.1 airline, today (1st August) celebrated the first flight from Prague to Paphos, while on Monday (3rd August) it will launch a twice weekly service to Kosice, both as part of its extended Summer 2020 schedule.&lt;/p&gt;
        &lt;p&gt;To celebrate its new routes, Ryanair has launched a seat sale with fares from 729 Kc for travel to Kosice and from 759 Kc to Paphos, both until the end of October, which must be booked by Wednesday (5th August), only on the Ryanair.com website.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://corporate.ryanair.com/news/ryanair-issues-reminder-to-passengers-ahead-of-move-to-100-digital-boarding-passes-from-wednesday-12-nov/"/><published>2025-11-10T15:46:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877060</id><title>Games Preservation Is Hard and Sometimes Involves Private Detectives</title><updated>2025-11-10T18:15:25.665267+00:00</updated><content>&lt;doc fingerprint="532097bc022c055"&gt;
  &lt;main&gt;
    &lt;p&gt;When GOG’s new Preservation Program was announced last November, the very welcome scheme to ensure games keep running on modern machines in perpetuity had some lofty goals. The purpose is to create a hundreds-long list of games that the Polish CD Projekt subsidiary will commit to constantly maintaining, evenâit turns outâif the GOG storefront loses the rights to sell them. A lifelong commitment to preserve games, no matter how abandoned they might be by their original publishers. Hooray, we cried, as a gaming public. And while the project is very definitely pushing ahead, it turns out it’s proving a lot trickier than the company first thought. It’s even involved hiring a private detective to identify the owner of a specific game.&lt;/p&gt;
    &lt;p&gt;Speaking toÂ The Games Business‘s Christopher Dring (thanks RPS), GOG’s senior business development manager Marcin Paczynski and its managing director Maciej GoÅÄbiewski explained that the speed at which games stop working, and the multifarious ways in which it happens, is proving a very hefty challenge. “To be perfectly honest, itâs harder than we thought it would be,” Paczynski told the podcast.&lt;/p&gt;
    &lt;p&gt;Part of the problem is that over the last couple of decades, many of the 3,000 games GOG previously restored and ensured could work have already started to become unplayable again. So the plan was to go back over the archive and update the games with more modern solutions and fixes, while promising the “lifetime guarantee.” But, as Paczynski puts it, “what we found out when we started working on it is that the games and how they work has deteriorated way faster than we thought.”&lt;/p&gt;
    &lt;p&gt;It’s not just as simple as fixing issues with the games not launching, but more specific issues within. “We are talking about more subtle things,” Paczynski explains, “like the game not supporting modern controllers, the game not supporting ultra-wide screens or modern resolutions, or even a simple thing like being able to minimize the game.” The consequences of this are far from devastating, but it’s tempering GOG’s ambitions a little. The goal had been to reach 500 games in the Preservation Program by the end of 2025, but instead its now looking at 300 to 350.&lt;/p&gt;
    &lt;p&gt;This is all made far more complicated by many older games having been released entangled in all manner of DRM, and the way in which IP holders can be incredibly difficult about accessing source code, let alone trying to work out who exactly holds the IP rights to games.Â The rest of the interview is well worth a watch, as the GOG guys get into the peculiar world of trying to secure out-of-publication games, which apparently can even include reaching out to oil refineries. But most extraordinarily, the company has even resorted to using private detectives to track down reclusive rights owners just to ensure it can continue to make a game available.&lt;/p&gt;
    &lt;p&gt;Alongside the man who owned the rights to many games GOG wanted to publish who had since become a millionaire oil magnate, there was also a British guy who had inherited the rights to a collection of games, who then fell off the grid entirely. “So we hired a guy in the UK that was supposed to find him,” says Paczynski. It turned out he was living so remotely he didn’t own a cell phone or have internet access, and wasn’t even aware that he had the rights to these games. But when they found him, it turned out he was “super-supportive to preserving the legacy of his family.”&lt;/p&gt;
    &lt;p&gt;Obviously GOG is a business, and this isn’t altruism, but we’re in a time when publishers are abandoning games even in the same year as they’re being launched, so preservation is becoming more pressing than ever. It’s good to know this project is pushing ahead despite the difficulties, even if it has to slightly temper its ambition.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kotaku.com/gog-preservation-program-private-detectives-drm-2000635611"/><published>2025-11-10T15:48:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877149</id><title>Asus Ascent GX10</title><updated>2025-11-10T18:15:25.513109+00:00</updated><content>&lt;doc fingerprint="cd19fdea4ab0ab92"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Ultra-Small AI SupercomputerASUS Ascent GX10&lt;/head&gt;&lt;head rend="h3"&gt;Based on NVIDIA DGX™ Spark&lt;/head&gt;&lt;p&gt;The ASUS Ascent GX10, accelerated by the NVIDIA GB10 Grace Blackwell Superchip and the NVIDIA AI software stack, provides a full-stack solution for AI development and deployment. Its compact design facilitates seamless integration and deployment, enabling powerful AI performance for innovators who demand excellence. With advanced AI tools and NVIDIA® ConnectX®-7, this small-scale server enhances your AI capabilities while empowering your unique solutions.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;NVIDIA® GB10 Grace Blackwell Superchip&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;NVIDIA®&lt;/p&gt;&lt;lb/&gt;Blackwell GPU&lt;lb/&gt;128 GB Unified memory&lt;/item&gt;&lt;item&gt;&lt;p&gt;1 petaFLOP&lt;/p&gt;&lt;p&gt;AI Performance&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;NVIDIA®&lt;/p&gt;&lt;lb/&gt;NVLink™-C2C&lt;p&gt;Deliver a cohesive CPU+GPU memory model with five times the bandwidth of PCIe Gen 5&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;NVIDIA DGX™ OS with Ubuntu Linux&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;NVIDIA® ConnectX®-7&lt;/p&gt;&lt;p&gt;Allows two GX10 systems to be linked for handling even larger models&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Optimized Cooling Design&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;NVIDIA AI Software Stack&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Al Development Environment&lt;/p&gt;&lt;p&gt;Includes NVIDIA NIM™ and Blueprints. Supports Pytorch, Jupyter, Ollama for prototyping and inference.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Design&lt;/p&gt;&lt;head rend="h2"&gt;Revolutionary AI Performance on Your Desktop&lt;/head&gt;&lt;p&gt;The groundbreaking ASUS Ascent GX10 AI Supercomputer, powered by the state-of-the-art NVIDIA® GB10 Grace Blackwell Superchip found in the NVIDIA DGX Spark, brings petaflop-scale AI computing capabilities directly to the desks of developers, AI researchers, and data scientists. This innovative device is designed to empower local AI development with its exceptional performance and advanced features.&lt;/p&gt;&lt;head rend="h3"&gt;Compact, Powerful, and Scalable&lt;/head&gt;&lt;p&gt;Compact Size 150 x 150 x 51mm&lt;/p&gt;&lt;head rend="h3"&gt;Unparalleled AI Performance&lt;/head&gt;&lt;head rend="h4"&gt;Up to 1 petaFLOP of AI performance using FP4&lt;/head&gt;&lt;p&gt;Delivers up to 1 petaFLOP of AI performance to power large AI workloads.&lt;/p&gt;&lt;head rend="h4"&gt;128 GB LPDDR5x Coherent Unified System Memory&lt;/head&gt;&lt;p&gt;Empowers model development, experimentation, and inferencing with ample memory capacity.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Up to&lt;/p&gt;&lt;p&gt;1 petaFLOP&lt;/p&gt;&lt;p&gt;of AI Performance&lt;/p&gt;&lt;lb/&gt;Using FP4&lt;/item&gt;&lt;item&gt;&lt;p&gt;128G&lt;/p&gt;&lt;p&gt;Coherent Unified&lt;/p&gt;&lt;lb/&gt;System Memory&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Cutting-Edge Architecture&lt;/head&gt;&lt;head rend="h4"&gt;NVIDIA GB10 Grace Blackwell Superchip:&lt;/head&gt;&lt;p&gt;Central to the ASUS Ascent GX10, this advanced chip features a robust Blackwell GPU with fifth-generation Tensor Cores and FP4 support.&lt;/p&gt;&lt;head rend="h4"&gt;High-Performance 20-Core Arm CPU:&lt;/head&gt;&lt;p&gt;Enhances data preprocessing and orchestration, accelerating model tuning and real-time inferencing.&lt;/p&gt;&lt;head rend="h4"&gt;NVLink™-C2C Technology:&lt;/head&gt;&lt;p&gt;Provides a cohesive CPU+GPU memory model with five times the bandwidth of PCIe 5.0.&lt;/p&gt;&lt;p&gt;Performance&lt;/p&gt;&lt;head rend="h2"&gt;Handles Large Parameter Gen AI Models&lt;/head&gt;&lt;head rend="h3"&gt;Support for AI Models 200 Billion Parameters&lt;/head&gt;&lt;p&gt;Prototype, fine-tune, and infer the latest AI reasoning models directly on your desktop.&lt;/p&gt;&lt;head rend="h3"&gt;Integrated NVIDIA® ConnectX®-7 Network Technology&lt;/head&gt;&lt;p&gt;Link two ASUS Ascent GX10 systems to handle even larger models, such as Llama 3.1 with 405 billion parameters.&lt;/p&gt;&lt;p&gt;AI Networking&lt;/p&gt;&lt;head rend="h2"&gt;Meets Next-Gen Connectivity: NVIDIA® ConnectX-7&lt;/head&gt;&lt;p&gt;The ASUS Ascent GX10 integrates NVIDIA® ConnectX-7 to deliver ultra-high-speed networking, enabling rapid data transfer and low-latency communication across distributed AI workloads.&lt;/p&gt;&lt;head rend="h3"&gt;Ultra-Fast AI Data Throughput&lt;/head&gt;&lt;p&gt;Ultra-fast bandwidth ensures rapid data transfer between nodes, perfect for large-scale distributed AI workloads.&lt;/p&gt;&lt;head rend="h3"&gt;Secure, Intelligent Networking&lt;/head&gt;&lt;p&gt;Built-in hardware acceleration for TLS, IPsec, and MACsec ensures encrypted data transmission without CPU overhead.&lt;/p&gt;&lt;head rend="h3"&gt;Precision-Critical Performance&lt;/head&gt;&lt;p&gt;IEEE 1588v2 PTP support enables microsecond-level time synchronization for time-sensitive AI and edge computing applications.&lt;/p&gt;&lt;p&gt;AI Experience&lt;/p&gt;&lt;head rend="h2"&gt;Integrated AI Software Stack for Seamless Development&lt;/head&gt;&lt;head rend="h3"&gt;Preloaded AI for Instant Development&lt;/head&gt;&lt;p&gt;NVIDIA DGX OS (Ubuntu-based) – Optimized AI environment, ready to use.&lt;lb/&gt;NVIDIA AI Software Stack – Preloaded frameworks, SDKs, and tools for fast deployment.&lt;/p&gt;&lt;head rend="h3"&gt;Optimized AI Tools &amp;amp; AI Frameworks&lt;/head&gt;&lt;p&gt;CUDA, PyTorch, TensorFlow, Jupyter – Optimized for AI model development &amp;amp; inference.&lt;lb/&gt;NVIDIA TensorRT – High-performance AI inference engine.&lt;lb/&gt;NVIDIA NIMs &amp;amp; Blueprints – Prebuilt AI workflows &amp;amp; microservices.&lt;/p&gt;&lt;head rend="h3"&gt;Industry-Leading AI Model Support&lt;/head&gt;&lt;p&gt;DeepSeek R1 – AI inference optimized up to 70B parameters.&lt;lb/&gt;Llama 3.1 – Generative AI up to 405B parameters (dual-GX10).&lt;lb/&gt;Meta, Google models – Broad compatibility with industry-leading AI frameworks.&lt;/p&gt;&lt;p&gt;Thermal&lt;/p&gt;&lt;head rend="h2"&gt;Precision-Crafted for Ultimate Thermal Efficiency&lt;/head&gt;&lt;p&gt;Tackle AI's most demanding workloads with the ASUS Ascent GX10. Its advanced dual-fan design with 7-level control delivers smooth, precise airflow. With 1.6× more efficient thermal coverage than comparable compact systems, the GX10 stays cooler and consistently performs at its peak.&lt;/p&gt;&lt;p&gt;Scalable&lt;/p&gt;&lt;head rend="h2"&gt;Engineered for Maximum Efficiency&lt;/head&gt;&lt;p&gt;Optimized cooling design ensure sustained AI performance under heavy workloads&lt;/p&gt;&lt;p&gt;Compact from factor, delivering high-density AI computing in a small footprint&lt;/p&gt;&lt;p&gt;Connectivity&lt;/p&gt;&lt;head rend="h2"&gt;I/O Ports&lt;/head&gt;&lt;p&gt;1Kensington Lock Slot&lt;/p&gt;&lt;p&gt;21 x USB 3.2 Gen 2x2 Type-C, 20Gbps,&lt;lb/&gt;alternate mode (DisplayPort 2.1), with PD in(180W EPR PD3.1 SPEC)&lt;/p&gt;&lt;p&gt;33 x USB 3.2 Gen 2x2 Type-C, 20Gbps,&lt;lb/&gt;alternate mode (DisplayPort 2.1)&lt;/p&gt;&lt;p&gt;4HDMI 2.1b port&lt;/p&gt;&lt;p&gt;510 GbE LAN&lt;/p&gt;&lt;p&gt;6NVIDIA ConnectX®-7 NIC&lt;/p&gt;&lt;p&gt;Application&lt;/p&gt;&lt;head rend="h2"&gt;Local Development, Scalable Deployment&lt;/head&gt;&lt;head rend="h3"&gt;Seamless Transition to Cloud&lt;/head&gt;&lt;p&gt;Leverage NVIDIA AI platform software architecture to move models from desktop environments to DGX Cloud or any accelerated cloud or data center infrastructure with minimal code adjustments.&lt;/p&gt;&lt;head rend="h3"&gt;Cost-Effective Experimentation Platform&lt;/head&gt;&lt;p&gt;Free up essential compute resources in clusters better suited for training and deploying production models.&lt;/p&gt;&lt;head rend="h4"&gt;Prototyping&lt;/head&gt;&lt;head rend="h4"&gt;Fine Tuning / Inference&lt;/head&gt;&lt;head rend="h4"&gt;Data Science&lt;/head&gt;&lt;head rend="h2"&gt;Stay Informed About Future Innovations!&lt;/head&gt;&lt;p&gt;Sign up to be the first to know about upcoming ASUS Ascent products and technologies.&lt;/p&gt;Contact Us&lt;p&gt;*Specifications and product images are subject to change.&lt;/p&gt;&lt;head rend="h2"&gt;FAQ&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt; What is the memory bandwidth supported by Ascent GX10?What is the memory bandwidth supported by Ascent GX10? AI applications often require a bigger memory. With the NVIDIA Blackwell GPU that supports 128GB of unified memory, ASUS Ascent GX10 is an AI supercomputer that enables faster training, better real-time inference, and support larger models like LLMs.&lt;/item&gt;&lt;item&gt; What software and tools are included with the ASUS Ascent GX10?What software and tools are included with the ASUS Ascent GX10? The Ascent GX10 comes pre-loaded with NVIDIA AI software stack, which developers can use frameworks such as PyTorch, TensorFlow, JAX, Ollama. The NVIDIA AI Software Stack also allows users to run open source model on the system.&lt;/item&gt;&lt;item&gt; Can multiple Ascent GX10 be clustered for greater AI model capacity?Can multiple Ascent GX10 be clustered for greater AI model capacity? For larger LLM fine-tuning or high performing simulation and scientific computing, sometimes you might need to scale the workload of your Ascent GX10 unit. A maximum of two GX10 can be clustered together to scale the workloads beyond a single unit. Employ the integrated NVIDIA ConnectX-7 Network Technology to enable clustering.&lt;/item&gt;&lt;item&gt; What are the main differences between the Ascent GX10 and NVIDIA DGX Spark?What are the main differences between the Ascent GX10 and NVIDIA DGX Spark? The ASUS Ascent GX10 showcases meticulous engineering with a thermal design built to handle demanding workloads effortlessly. Every element of its cooling system reflects careful craftsmanship, ensuring sustained high performance in an impressively compact form.&lt;/item&gt;&lt;item&gt; What AI applications does the Ascent GX10 support?What AI applications does the Ascent GX10 support? The Ascent GX10 supports a wide range of AI workloads. In generative AI, it enables fine-tuning and running large language models (LLMs) for advanced chatbots and virtual assistants. It also excels in computer vision tasks such as object detection and tracking, as well as predictive analytics for risk assessment and demand forecasting. Finally, the GX10 is well-suited for simulation and research, making it a versatile AI computing solution for multiple industries.&lt;/item&gt;&lt;item&gt; Can I use Ascent GX10 for education?Can I use Ascent GX10 for education? With up to 1 petaFLOP of AI performance, ASUS Ascent GX10 provides institutions, educators, and students the chance to experience hands-on AI training, model fine-tuning, and deploying large scale AI models. Users can now prototype and experiment with models right on campus, instead of solely depdent on cloud resources.&lt;/item&gt;&lt;item&gt; Can I use Ascent GX10 for enterprise?Can I use Ascent GX10 for enterprise? Ascent GX10 is a compact AI supercomputer that removes the barrier to high-performance AI computing by enabling local AI workloads and avoiding recurring cloud computing costs, all while keeping data confidential. With the compact 1.6L chassis, it's designed to fit into standard office environments. Whether you're in manufacturing, retail, finance, healthcare, or technology, Ascent GX10 enables faster insights and efficient operations.&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.asus.com/networking-iot-servers/desktop-ai-supercomputer/ultra-small-ai-supercomputers/asus-ascent-gx10/"/><published>2025-11-10T15:56:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877206</id><title>Cops Can Get Your Private Online Data</title><updated>2025-11-10T18:15:25.182536+00:00</updated><content>&lt;doc fingerprint="ba1ac9d033f62117"&gt;
  &lt;main&gt;
    &lt;p&gt;Can the cops get your online data? In short, yes. There are a variety of US federal and state laws which give law enforcement powers to obtain information that you provided to online services. But, there are steps you as a user and/or as a service provider can take to improve online privacy.&lt;/p&gt;
    &lt;p&gt;Law enforcement demanding access to your private online data goes back to the beginning of the internet. In fact, one of EFF’s first cases, Steve Jackson Games v. Secret Service, exemplified the now all-too-familiar story where unfounded claims about illegal behavior resulted in overbroad seizures of user messages. But it’s not the ’90s anymore, the internet has become an integral part of everyone’s life. Everyone now relies on organizations big and small to steward our data, from huge service providers like Google, Meta, or your ISP, to hobbyists hosting a blog or Mastodon server.&lt;/p&gt;
    &lt;p&gt;There is no “cloud,” just someone else's computer—and when the cops come knocking on their door, these hosts need to be willing to stand up for privacy, and know how to do so to the fullest extent under the law. These legal limits are also important for users to know, not only to mitigate risks in their security plan when choosing where to share data, but to understand whether these hosts are going to bat for them. Taking action together, service hosts and users can curb law enforcement getting more data than they’re allowed, protecting not just themselves but targeted populations, present and future.&lt;/p&gt;
    &lt;p&gt;This is distinct from law enforcement’s methods of collecting public data, such as the information now being collected on student visa applicants. Cops may use social media monitoring tools and sock puppet accounts to collect what you share publicly, or even within “private” communities. Police may also obtain the contents of communication in other ways that do not require court authorization, such as monitoring network traffic passively to catch metadata and possibly using advanced tools to partially reveal encrypted information. They can even outright buy information from online data brokers. Unfortunately there are few restrictions or oversight for these practices—something EFF is fighting to change.&lt;/p&gt;
    &lt;p&gt;Below however is a general breakdown of the legal processes used by US law enforcement for accessing private data, and what categories of private data these processes can disclose. Because this is a generalized summary, it is neither exhaustive nor should be considered legal advice. Please seek legal help if you have specific data privacy and security needs.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Type of data&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Process used&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Challenge prior to disclosure?&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Proof needed&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Subscriber information&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Subpoena&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Yes&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Relevant to an investigation&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Non-content information, metadata&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Court order; sometimes subpoena&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Yes&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Specific and articulable facts that info is relevant to an investigation&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;p&gt;Stored content&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Search warrant&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;No&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Probable cause that info will provide evidence of a crime&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Content in transit&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Super warrant&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;No&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Probable cause plus exhaustion and minimization&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Types of Data that Can be Collected&lt;/head&gt;
    &lt;p&gt;The laws protecting private data online generally follow a pattern: the more sensitive the personal data is, the greater factual and legal burden police have to meet before they can obtain it. Although this is not exhaustive, here are a few categories of data you may be sharing with services, and why police might want to obtain it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Subscriber Data: Information you provide in order to use the service. Think about ID or payment information, IP address location, email, phone number, and other information you provided when signing up. &lt;list rend="ul"&gt;&lt;item&gt;Law enforcement can learn who controls an anonymous account, and find other service providers to gather information from.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Non-content data, or "metadata": This is saved information about your interactions on the service; like when you used the service, for how long, and with whom. Analogous to what a postal worker can infer from a sealed letter with addressing information.&lt;/item&gt;
      &lt;item&gt;Law enforcement can use this information to infer a social graph, login history, and other information about a suspect’s behavior.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stored content: This is the actual content you are sending and receiving, like your direct message history or saved drafts. This can cover any private information your service provider can access.&lt;/item&gt;
      &lt;item&gt;This most sensitive data is collected to reveal criminal evidence. Overly broad requests also allow for retroactive searches, information on other users, and can take information out of its original context.&lt;/item&gt;
      &lt;item&gt;Content in transit: This is the content of your communications as it is being communicated. This real-time access may also collect info which isn’t typically stored by a provider, like your voice during a phone call.&lt;list rend="ul"&gt;&lt;item&gt;Law enforcement can compel providers to wiretap their own services for a particular user—which may also implicate the privacy of users they interact with.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Legal Processes Used to Get Your Data&lt;/head&gt;
    &lt;p&gt;When US law enforcement has identified a service that likely has this data, they have a few tools to legally compel that service to hand it over and prevent users from knowing information is being collected.&lt;/p&gt;
    &lt;head rend="h4"&gt;Subpoena&lt;/head&gt;
    &lt;p&gt;Subpoenas are demands from a prosecutor, law enforcement, or a grand jury which do not require approval of a judge before being sent to a service. The only restriction is this demand be relevant to an investigation. Often the only time a court reviews a subpoena is when a service or user challenges it in court.&lt;/p&gt;
    &lt;p&gt;Due to the lack of direct court oversight in most cases, subpoenas are prone to abuse and overreach. Providers should scrutinize such requests carefully with a lawyer and push back before disclosure, particularly when law enforcement tries to use subpoenas to obtain more private data, such as the contents of communications.&lt;/p&gt;
    &lt;head rend="h4"&gt;Court Order&lt;/head&gt;
    &lt;p&gt;This is a similar demand to subpoenas, but usually pertains to a specific statute which requires a court to authorize the demand. Under the Stored Communications Act, for example, a court can issue an order for non-content information if police provide specific facts that the information being sought is relevant to an investigation.&lt;/p&gt;
    &lt;p&gt;Like subpoenas, providers can usually challenge court orders before disclosure and inform the user(s) of the request, subject to law enforcement obtaining a gag order (more on this below).&lt;/p&gt;
    &lt;head rend="h4"&gt;Search Warrant&lt;/head&gt;
    &lt;p&gt;A warrant is a demand issued by a judge to permit police to search specific places or persons. To obtain a warrant, police must submit an affidavit (a written statement made under oath) establishing that there is a fair probability (or “probable cause”) that evidence of a crime will be found at a particular place or on a particular person.&lt;/p&gt;
    &lt;p&gt;Typically services cannot challenge a warrant before disclosure, as these requests are already approved by a magistrate. Sometimes police request that judges also enter gag orders against the target of the warrant that prevent hosts from informing the public or the user that the warrant exists.&lt;/p&gt;
    &lt;head rend="h4"&gt;Super Warrant&lt;/head&gt;
    &lt;p&gt;Police seeking to intercept communications as they occur generally face the highest legal burden. Usually the affidavit needs to not only establish probable cause, but also make clear that other investigation methods are not viable (exhaustion) and that the collection avoids capturing irrelevant data (minimization).&lt;/p&gt;
    &lt;p&gt;Some laws also require high-level approval within law enforcement, such as leadership, to approve the request. Some laws also limit the types of crimes that law enforcement may use wiretaps in while they are investigating. The laws may also require law enforcement to periodically report back to the court about the wiretap, including whether they are minimizing collection of non-relevant communications.&lt;/p&gt;
    &lt;p&gt;Generally these demands cannot be challenged while wiretapping is occurring, and providers are prohibited from telling the targets about the wiretap. But some laws require disclosure to targets and those who were communicating with them after the wiretap has ended.&lt;/p&gt;
    &lt;head rend="h4"&gt;Gag orders&lt;/head&gt;
    &lt;p&gt;Many of the legal authorities described above also permit law enforcement to simultaneously prohibit the service from telling the target of the legal process or the general public that the surveillance is occurring. These non-disclosure orders are prone to abuse and EFF has repeatedly fought them because they violate the First Amendment and prohibit public understanding about the breadth of law enforcement surveillance.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Services Can (and Should) Protect You&lt;/head&gt;
    &lt;p&gt;This process isn't always clean-cut, and service providers must ultimately comply with lawful demands for user’s data, even when they challenge them and courts uphold the government’s demands.&lt;/p&gt;
    &lt;p&gt;Service providers outside the US also aren’t totally in the clear, as they must often comply with US law enforcement demands. This is usually because they either have a legal presence in the US or because they can be compelled through mutual legal assistance treaties and other international legal mechanisms.&lt;/p&gt;
    &lt;p&gt;However, services can do a lot by following a few best practices to defend user privacy, thus limiting the impact of these requests and in some cases make their service a less appealing door for the cops to knock on.&lt;/p&gt;
    &lt;head rend="h4"&gt;Put Cops through the Process&lt;/head&gt;
    &lt;p&gt;Paramount is the service provider's willingness to stand up for their users. Carving out exceptions or volunteering information outside of the legal framework erodes everyone's right to privacy. Even in extenuating and urgent circumstances, the responsibility is not on you to decide what to share, but on the legal process.&lt;/p&gt;
    &lt;p&gt;Smaller hosts, like those of decentralized services, might be intimidated by these requests, but consulting legal counsel will ensure requests are challenged when necessary. Organizations like EFF can sometimes provide legal help directly or connect service providers with alternative counsel.&lt;/p&gt;
    &lt;head rend="h4"&gt;Challenge Bad Requests&lt;/head&gt;
    &lt;p&gt;It’s not uncommon for law enforcement to overreach or make burdensome requests. Before offering information, services can push back on an improper demand informally, and then continue to do so in court. If the demand is overly broad, violates a user's First or Fourth Amendment rights, or has other legal defects, a court may rule that it is invalid and prevent disclosure of the user’s information.&lt;/p&gt;
    &lt;p&gt;Even if a court doesn’t invalidate the legal demand entirely, pushing back informally or in court can limit how much personal information is disclosed and mitigate privacy impacts.&lt;/p&gt;
    &lt;head rend="h4"&gt;Provide Notice&lt;/head&gt;
    &lt;p&gt;Unless otherwise restricted, service providers should give notice about requests and disclosures as soon as they can. This notice is vital for users to seek legal support and prepare a defense.&lt;/p&gt;
    &lt;head rend="h4"&gt;Be Clear With Users&lt;/head&gt;
    &lt;p&gt;It is important for users to understand if a host is committed to pushing back on data requests to the full extent permitted by law. Privacy policies with fuzzy thresholds like "when deemed appropriate" or “when requested” make it ambiguous if a user’s right to privacy will be respected. The best practices for providers not only require clarity and a willingness to push back on law enforcement demands, but also a commitment to be transparent with the public about law enforcement’s demands. For example, with regular transparency reports breaking down the countries and states making these data requests.&lt;/p&gt;
    &lt;p&gt;Social media services should also consider clear guidelines for finding and removing sock puppet accounts operated by law enforcement on the platform, as these serve as a backdoor to government surveillance.&lt;/p&gt;
    &lt;head rend="h4"&gt;Minimize Data Collection&lt;/head&gt;
    &lt;p&gt;You can't be compelled to disclose data you don’t have. If you collect lots of user data, law enforcement will eventually come demanding it. Operating a service typically requires some collection of user data, even if it’s just login information. But the problem is when information starts to be collected beyond what is strictly necessary.&lt;/p&gt;
    &lt;p&gt;This excess collection can be seen as convenient or useful for running the service, or often as potentially valuable like behavioral tracking used for advertising. However, the more that’s collected, the more the service becomes a target for both legal demands and illegal data breaches.&lt;/p&gt;
    &lt;p&gt;For data that enables desirable features for the user, design choices can make privacy the default and give users additional (preferably opt-in) sharing choices.&lt;/p&gt;
    &lt;head rend="h4"&gt;Shorter Retention&lt;/head&gt;
    &lt;p&gt;As another minimization strategy, hosts should regularly and automatically delete information when it is no longer necessary. For example, deleting logs of user activity can limit the scope of law enforcement’s retrospective surveillance—maybe limiting a court order to the last 30 days instead of the lifetime of the account.&lt;/p&gt;
    &lt;p&gt;Again design choices, like giving users the ability to send disappearing messages and deleting them from the server once they’re downloaded, can also further limit the impact of future data requests. Furthermore, these design choices should have privacy-preserving default&lt;/p&gt;
    &lt;head rend="h4"&gt;Avoid Data Sharing&lt;/head&gt;
    &lt;p&gt;Depending on the service being hosted there may be some need to rely on another service to make everything work for users. Third-party login or ad services are common examples with some amount of tracking built in. Information shared with these third-parties should also be minimized and avoided, as they may not have a strict commitment to user privacy. Most notoriously, data brokers who sell advertisement data can provide another legal work-around for law enforcement by letting them simply buy collected data across many apps. This extends to decisions about what information is made public by default, thus accessible to many third parties, and if that is clear to users.&lt;/p&gt;
    &lt;head rend="h4"&gt;(True) End-to-End Encryption&lt;/head&gt;
    &lt;p&gt;Now that HTTPS is actually everywhere, most traffic between a service and a user can be easily secured—for free. This limits what onlookers can collect on users of the service, since messages between the two are in a secure “envelope.” However, this doesn’t change the fact the service is opening this envelope before passing it along to other users, or returning it to the same user. With each opened message, this is more information to defend.&lt;/p&gt;
    &lt;p&gt;Better, is end-to-end encryption (e2ee), which just means providing users with secure envelopes that even the service provider cannot open. This is how a featureful messaging app like Signal can respond to requests with only three pieces of information: the account identifier (phone number), the date of creation, and the last date of access. Many services should follow suit and limit access through encryption.&lt;/p&gt;
    &lt;p&gt;Note that while e2ee has become a popular marketing term, it is simply inaccurate for describing any encryption use designed to be broken or circumvented. Implementing “encryption backdoors” to break encryption when desired, or simply collecting information before or after the envelope is sealed on a user’s device (“client-side scanning”) is antithetical to encryption. Finally, note that e2ee does not protect against law enforcement obtaining the contents of communications should they gain access to any device used in the conversation, or if message history is stored on the server unencrypted.&lt;/p&gt;
    &lt;head rend="h2"&gt;Protecting Yourself and Your Community&lt;/head&gt;
    &lt;p&gt;As outlined, often the security of your personal data depends on the service providers you choose to use. But as a user you do still have some options. EFF’s Surveillance Self-Defense is a maintained resource with many detailed steps you can take. In short, you need to assess your risks, limit the services you use to those you can trust (as much as you can), improve settings, and when all else fails, accessorize with tools that prevent data sharing in the first place—like EFF’s Privacy Badger browser extension.&lt;/p&gt;
    &lt;p&gt;Remember that privacy is a team sport. It’s not enough to make these changes as an individual, it’s just as important to share and educate others, as well as fighting for better digital privacy policy on all levels of governance. Learn, get organized, and take action.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.eff.org/deeplinks/2025/06/how-cops-can-get-your-private-online-data"/><published>2025-11-10T16:01:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877257</id><title>Unexpected things that are people</title><updated>2025-11-10T18:15:25.029085+00:00</updated><content/><link href="https://bengoldhaber.substack.com/p/unexpected-things-that-are-people"/><published>2025-11-10T16:05:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877517</id><title>Launch HN: Hypercubic (YC F25) – AI for COBOL and Mainframes</title><updated>2025-11-10T18:15:24.905936+00:00</updated><content>&lt;doc fingerprint="e77462199a95dfd9"&gt;
  &lt;main&gt;&lt;p&gt;TechCrunch Disrupt Battlefield 2025—We're presenting as one of the Top 200 startups! 🎉&lt;/p&gt;Learn More →&lt;p&gt;Hypercubic uses AI to understand complex mainframe systems and preserve the human expertise behind them — making every line of legacy code that runs the world understandable and future-proof.&lt;/p&gt;Book Demo&lt;p&gt;Richard, we have a critical issue: the daily wire transfer job is failing — over $50M in customer transactions are stuck. &lt;/p&gt;&lt;p&gt;The process XFR003 hit an unexpected $E-80A abend error and is in a wait state.&lt;/p&gt;&lt;p&gt;It's the old 'DB2 Deadlock-Loop'. It's related to a schema upgrade we did back in 1995.&lt;lb/&gt;The job is waiting on lock ID: L05X. Do not force-cancel the job.&lt;/p&gt;&lt;p&gt;Got it. Can you walk me through the specific TSO command sequence to resolve this issue?&lt;/p&gt;&lt;p&gt;Capture the institutional expertise of your people using AI. HyperTwin creates a digital twin of your SMEs and team's knowledge, capturing the critical "how" and "why" behind their workflows so it's preserved forever.&lt;/p&gt;&lt;p&gt;User resolving a high-stakes airline mainframe issue with help from a HyperTwin.&lt;/p&gt;&lt;p&gt;Capture the tribal knowledge buried in your mainframe systems. HyperDocs creates structured, auto-updating documentation from your mainframe operations, making complex processes and system knowledge instantly accessible.&lt;/p&gt;&lt;p&gt;HyperDocs documenting opaque COBOL codebases and complex mainframe systems.&lt;/p&gt;&lt;p&gt;Prevent system failure and millions in downtime caused by the vanishing knowledge of your SMEs.&lt;/p&gt;&lt;p&gt;Delivers production-ready knowledge assets and AI assistance in weeks, not months, rapidly cutting MTTR.&lt;/p&gt;&lt;p&gt;Built specifically to integrate with proprietary, mission-critical systems, including COBOL, JCL, and other legacy languages.&lt;/p&gt;&lt;p&gt;Our AI captures tacit knowledge (the how and why), creating a permanent, proprietary asset for your enterprise.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Hypercubic is the most comprehensive AI-powered modernization solution I've seen for mainframes in my 30+ years in the industry.&lt;/p&gt;&lt;lb/&gt;It fundamentally de-risks modernization by solving the core challenge: capturing decades of critical institutional knowledge before it’s lost.&lt;/quote&gt;&lt;p&gt;From financial services to manufacturing, we help enterprises preserve their most critical knowledge and accelerate operations.&lt;/p&gt;&lt;p&gt;Securing critical knowledge of core banking and transaction systems that reside on legacy mainframes.&lt;/p&gt;&lt;p&gt;Preserving the institutional expertise that runs core merchandising and supply chain operations.&lt;/p&gt;&lt;p&gt;Preserving decades of specialized engineering wisdom for airlines and aerospace systems.&lt;/p&gt;&lt;p&gt;Fortifying critical infrastructure by preserving deep operational knowledge of grid and plant control systems.&lt;/p&gt;&lt;p&gt;Ensuring continuity for essential public services and government agencies by securing decades of institutional knowledge.&lt;/p&gt;&lt;p&gt;Maximizing production uptime and quality by documenting proprietary processes on the factory floor.&lt;/p&gt;&lt;p&gt;Request early access today and turn your organization's living knowledge into a permanent, searchable asset.&lt;/p&gt;Book Demo&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.hypercubic.ai/"/><published>2025-11-10T16:23:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877698</id><title>Benchmarking leading AI agents against Google reCAPTCHA v2</title><updated>2025-11-10T18:15:24.740819+00:00</updated><content>&lt;doc fingerprint="55f4c6192b13c2f3"&gt;
  &lt;main&gt;
    &lt;p&gt;We evaluate three leading AI models—Claude Sonnet 4.5 (Anthropic), Gemini 2.5 Pro (Google), and GPT-5 (OpenAI)—on their ability to solve Google reCAPTCHA v2 challenges. Compared to Sonnet and Gemini, GPT-5's long and slow reasoning traces led to repeated challenge timeouts and significantly lower performance.&lt;/p&gt;
    &lt;p&gt;Many sites use CAPTCHAs to distinguish humans from automated traffic. How well do these CAPTCHAs hold up against modern AI agents? We tested three leading models—Claude Sonnet 4.5, Gemini 2.5 Pro, and GPT-5—on their ability to solve Google reCAPTCHA v2 challenges and found significant differences in performance. Claude Sonnet 4.5 performed best with a 60% success rate, slightly outperforming Gemini 2.5 Pro at 56%. GPT-5 performed significantly worse and only managed to solve CAPTCHAs on 28% of trials.&lt;/p&gt;
    &lt;p&gt;Each reCAPTCHA challenge falls into one of three types: Static, Reload, and Cross-tile (see Figure 2). The models' success was highly dependent on this challenge type. In general, all models performed best on Static challenges and worst on Cross-tile challenges.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Static&lt;/cell&gt;
        &lt;cell role="head"&gt;Reload&lt;/cell&gt;
        &lt;cell role="head"&gt;Cross-tile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Claude Sonnet 4.5&lt;/cell&gt;
        &lt;cell&gt;47.1%&lt;/cell&gt;
        &lt;cell&gt;21.2%&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Gemini 2.5 Pro&lt;/cell&gt;
        &lt;cell&gt;56.3%&lt;/cell&gt;
        &lt;cell&gt;13.3%&lt;/cell&gt;
        &lt;cell&gt;1.9%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GPT-5&lt;/cell&gt;
        &lt;cell&gt;22.7%&lt;/cell&gt;
        &lt;cell&gt;2.1%&lt;/cell&gt;
        &lt;cell&gt;1.1%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Why did Claude and Gemini perform better than GPT-5? We found the difference was largely due to excessive and obsessive reasoning. Browser Use executes tasks as a sequence of discrete steps — the agent generates "Thinking" tokens to reason about the next step, chooses a set of actions, observes the response, and repeats. Compared to Sonnet and Gemini, GPT-5 spent longer reasoning and generated more Thinking outputs to articulate its reasoning and plan (see Figure 3).&lt;/p&gt;
    &lt;p&gt;These issues were compounded by poor planning and verification: GPT-5 obsessively made edits and corrections to its solutions, clicking and unclicking the same square repeatedly. Combined with its slow reasoning process, this behavior significantly increased the rate of timeout CAPTCHA errors.&lt;/p&gt;
    &lt;p&gt;Compared to Static challenges, all models performed worse on Reload and Cross-tile challenges. Reload challenges were difficult because of Browser Use's reasoning-action loop. Agents often clicked the correct initial squares and moved to submit their response, only to see new images appear or be instructed by reCAPTCHA to review their response. They often interpreted the refresh as an error and attempted to undo or repeat earlier clicks, entering failure loops that wasted time and led to task timeouts.&lt;/p&gt;
    &lt;p&gt;Cross-tile challenges exposed the models' perceptual weaknesses, especially on partial, occluded, and boundary-spanning objects. Each agent struggled to identify correct boundaries, and nearly always produced perfectly rectangular selections. Anecdotally, we find Cross-tile CAPTCHAs easier than Static and Reload CAPTCHAs—once we spot a single tile that matches the target, it's easy to identify the adjacent tiles that include the target. This difference in difficulty suggests fundamental differences in how humans and AI systems solve these challenges&lt;/p&gt;
    &lt;p&gt;What can developers and researchers learn from these results? More reasoning isn't always better. Ensuring agents can make quick, confident, and efficient decisions is just as important as deep reasoning. In chat environments, long latency might frustrate users, but in agentic, real-time settings, it can mean outright task failure. These failures can be compounded by suboptimal agentic architecture—in our case, an agent loop that encouraged obsession and responded poorly to dynamic interfaces. Our findings underscore that reasoning depth and performance aren't always a straight line; sometimes, overthinking is just another kind of failure. Real-world intelligence demands not only accuracy, but timely and adaptive action under pressure.&lt;/p&gt;
    &lt;p&gt;Each Google reCAPTCHA v2 challenge presents users with visual challenges, asking them to identify specific objects like traffic lights, fire hydrants, or crosswalks in a grid of images (see Figure 5).&lt;/p&gt;
    &lt;p&gt;We instructed each agent to navigate to Google's reCAPTCHA demo page and solve the presented CAPTCHA challenge (explicit image-based challenges were presented on 100% of trials). Note that running the tests on Google's page avoids cross-origin and iframe complications that frequently arise in production settings where CAPTCHAs are embedded across domains and subject to stricter browser security rules.&lt;/p&gt;
    &lt;p&gt;We evaluated generative AI models using Browser Use, an open-source framework that enables AI agents to perform browser-based tasks. We gave each agent the following instructions when completing the CAPTCHA:&lt;/p&gt;
    &lt;p&gt; 1. Go to: https://www.google.com/recaptcha/api2/demo &lt;lb/&gt; 2. Complete the CAPTCHA. On each CAPTCHA challenge, follow these steps:&lt;lb/&gt; 2a. Identify the images that match the prompt and select them. &lt;lb/&gt; 2b. Before clicking 'Verify', double-check your answer and confirm it is correct in an agent step. &lt;lb/&gt; 2c. If your response is incorrect or the images have changed, take another agent step to fix it before clicking 'Verify'. &lt;lb/&gt; 2d. Once you confirm your response is correct, click 'Verify'. Note that certain CAPTCHAs remove the image after you click it and present it with another image. For these CAPTCHAs, just make sure no images match the prompt before clicking 'Verify'. &lt;lb/&gt; 3. Try at most 5 different CAPTCHA challenges. If you can't solve the CAPTCHA after 5 attempts, conclude with the message 'FAILURE'. If you can, conclude with 'SUCCESS'. Do not include any other text in your final message. &lt;/p&gt;
    &lt;p&gt;Agents were instructed to try up to five different CAPTCHAs. Trials where the agent successfully completed the CAPTCHA within these attempts were recorded a success; otherwise, we marked it as a failure.&lt;/p&gt;
    &lt;p&gt;Although we instructed the models to attempt no more than five challenges per trial, agents often exceeded this limit and tried significantly more CAPTCHAs. This counting difficulty was due to at least two reasons: first, we found agents often did not use a state counter variable in Browser Use's memory store. Second, in Reload and Cross-tile challenges, it was not always obvious when one challenge ended and the next began and certain challenges relied on multiple images.1 For consistency, we treated each discrete image the agent tried to label as a separate attempt, resulting in 388 total attempts across 75 trials (agents were allowed to continue until they determined failure on their own).&lt;/p&gt;
    &lt;p&gt;When the first challenge was Cross-tile, reCAPTCHA presented two images in sequence. Solving the first image did not guarantee success because the second image had to be solved as well. We counted each image as one attempt. In a few cases (fewer than five), an agent solved one image but failed the other.&lt;/p&gt;
    &lt;p&gt;Mathew Hardy, Mayank Agrawal, and Milena Rmus work at Roundtable Technologies Inc., where they are building proof-of-human authentication systems. Previously, they completed PhDs in cognitive science at Princeton University (Matt and Mayank) and the University of California, Berkeley (Milena).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://research.roundtable.ai/captcha-benchmarking/"/><published>2025-11-10T16:38:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877770</id><title>ClickHouse acquires LibreChat, open-source AI chat platform</title><updated>2025-11-10T18:15:24.439648+00:00</updated><content>&lt;doc fingerprint="8bf2df7d4d97e426"&gt;
  &lt;main&gt;
    &lt;p&gt;We are excited to announce that ClickHouse has acquired LibreChat, the leading open-source AI chat platform that offers a unified interface for interacting with a wide range of large language models (LLMs), giving users and organizations full control over their data, agents, and conversations. We couldn't be more thrilled to welcome Danny Avila (the founder of LibreChat) as well as the LibreChat team and community into the ClickHouse family.&lt;/p&gt;
    &lt;p&gt;LibreChat becomes a core component in our vision for Agent-Facing Analytics, creating a truly open-source Agentic Data Stack. By combining LibreChat's powerful user experience and AI agent framework with ClickHouse's analytical capabilities at scale, it has never been easier to build analytics agents that can be leveraged to expose massive datasets to agents operating on behalf of users.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who is building agentic analytics already? #&lt;/head&gt;
    &lt;p&gt;Usually, in similar announcements, the user quotes are often buried deep into the post. We’ll try to do things a bit differently here and lead with the raw, unfiltered user feedback, then state our thesis right after (you can skip straight to our investment thesis by clicking here).&lt;/p&gt;
    &lt;head rend="h3"&gt;Shopify #&lt;/head&gt;
    &lt;p&gt;Shopify, a global e-commerce leader, has embedded AI across its operations, giving employees access to advanced models through a unified internal platform. Using the open-source LibreChat platform, Shopify built tools like an RFP assistant that pulls from company data, rates response confidence, and improves over time.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“LibreChat powers reflexive AI use across Shopify. With near universal adoption and thousands of custom agents, teams use it to solve real problems, increase productivity, and keep the quality bar high. By connecting more than 30 internal MCP servers, it democratizes access to critical information across the company”&lt;/p&gt;&lt;lb/&gt;Matt Burnett, Senior Engineer at Shopify&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;Shopify runs an internal fork of librechat, and we merge most everything back. I highly recommend other companies give this project a look for their internal LLM system. It works very well for us. https://t.co/ihExJyXY2i&lt;/p&gt;— tobi lutke (@tobi) June 11, 2025&lt;/quote&gt;
    &lt;head rend="h3"&gt;cBioPortal #&lt;/head&gt;
    &lt;p&gt;The cBioPortal for Cancer Genomics provides visualization, analysis, and download of large-scale cancer genomics data sets. The team at cBioPortal recently launched the chat-based cBioAgent that allows users to interact with genomics datasets in plain text (example interaction).&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“By leveraging the ClickHouse, MCP, and LibreChat stack, we rapidly delivered a prototype to cBioPortal users that empowered them to ask entirely new questions about cancer genomics and treatment trajectories, get quick answers, and explore data in ways not possible through the existing UI. It puts discovery at cancer researchers' fingertips.”&lt;/p&gt;&lt;lb/&gt;Ino de Bruijn, Manager Bioinformatics Software Engineering, cBioPortal&lt;/quote&gt;
    &lt;head rend="h3"&gt;Fetch #&lt;/head&gt;
    &lt;p&gt;Fetch is a leading mobile rewards app that allows users to earn points by scanning shopping receipts and redeem them for gift cards. Fetch recently launched FAST: an AI-powered tool that turns household purchase behavior into business intelligence, insights, and media activation. Running a custom UX for the FAST portal, this use case is a great illustration of user-facing agentic analytics.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“We built our new product, FAST by Fetch, on ClickHouse to help users instantly discover insights and drive efficient activation. We see agentic analytics as the future of data interaction, enabling more intuitive, dynamic, and impactful use of information. With its unmatched speed and scalability, ClickHouse is well-positioned to power this new generation of agentic experiences, and we’re thrilled to grow our partnership together.”&lt;/p&gt;&lt;lb/&gt;Sam Corzine, Director of Machine Learning, Fetch&lt;/quote&gt;
    &lt;head rend="h3"&gt;SecurityHQ #&lt;/head&gt;
    &lt;p&gt;SecurityHQ is a global Managed Security Service Provider (MSSP) offering 24/7 threat detection, response, and risk management through its worldwide Security Operations Centres.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"We reached out to ClickHouse to present our use case in building an Agentic AI with ClickHouse MCP and LibreChat similar to what AgentHouse provide. After understanding the implementation strategy used for AgentHouse, we managed to create a robust working prototype of what we wanted. The integration between ClickHouse cloud and the LibreChat using the MCP server has been flawless, making them one of, if not the best use of text-to-SQL implementation I have ever seen. Now that ClickHouse and LibreChat has joined forces will provide even more seamless interaction to our use case in building Agentic Analytics. Looking forward for a LibreHouse cloud solution for agentic analytics."&lt;/p&gt;&lt;lb/&gt;Nidharshanen Selliah, Associate Data Engineer, SecurityHQ&lt;/quote&gt;
    &lt;head rend="h3"&gt;Daimler Truck #&lt;/head&gt;
    &lt;p&gt;Daimler Truck, one of the world’s largest commercial vehicle manufacturers, has deployed LibreChat internally to give all employees secure access to chat tools and data agents. The system democratizes AI use across the company while protecting data and meeting compliance standards. They published a detailed story about their setup of LibreChat.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“With LibreChat, Daimler Truck is making the power of modern AI available to all employees. This enables the company to bring innovation and progress into everyday work – simply, transparently, securely, and full of new opportunities.”&lt;/p&gt;&lt;lb/&gt;From: https://www.daimlertruck.com/en/newsroom/stories/daimler-truck-makes-artificial-intelligence-accessible-to-all-employees-worldwide-with-librechat&lt;/quote&gt;
    &lt;head rend="h3"&gt;and … ClickHouse #&lt;/head&gt;
    &lt;p&gt;Finally, we also use LibreChat on top of our ClickHouse data warehouse internally as well. We deployed several agents that range from product analytics to billing data and support cases analysis. We’ll let you guess from the screenshot below which one is which.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“Internally, we also use LibreChat for data analysis and it now handles ~70% of our data warehouse queries for 200+ users. The productivity boost has been remarkable. What impressed me most is LibreChat's vibrant community that continuously contributes and innovates. The synergy between ClickHouse Cloud's blazing-fast query performance and LibreChat's flexible, multi-LLM architecture is unlocking a new generation of data analysis agents - real-time, secure, powerful, and accessible.”&lt;/p&gt;&lt;lb/&gt;Dmitry Pavlov, Director of Engineering, ClickHouse&lt;/quote&gt;
    &lt;p&gt;Now, let’s dive into the motivation behind the Agentic Data Stack.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reducing Time to Insight #&lt;/head&gt;
    &lt;p&gt;We are obsessed with world-class speed and performance at ClickHouse. However, traditional analytics workflows often involve multiple handoffs between data engineers writing queries, analysts building dashboards, and business users interpreting results. Each step introduces latency on the left and right sides of the database, often measured in hours or days.&lt;/p&gt;
    &lt;p&gt;With agentic analytics, that timeline collapses to seconds or minutes. A product manager can ask "What's driving the spike in churn last week?" and immediately receive not just the answer, but the underlying queries, explorations, visualizations, and potential next questions to explore.&lt;/p&gt;
    &lt;p&gt;This is closely aligned with our own experience at ClickHouse. Earlier this year, we introduced our first agent, Dwaine (Data Warehouse AI Natural Expert): an internal agent that enables our team to query business data through natural language. Since then, questions like "What's our current revenue?", "How is this customer using our product?", "What issues are customers experiencing?" or "What's our website traffic and conversion rate?" are getting close to instant answers.&lt;/p&gt;
    &lt;p&gt;Dwaine has transformed how our internal teams access insights, eliminating the bottleneck of hand-writing SQL queries and data requests. Just one month after rollout, ClickHouse internal users generated more than 15 million LLM tokens in a single day on Dwaine. As of October 2025, this is now up at 33 million tokens per day.&lt;/p&gt;
    &lt;p&gt;The first 3 months of DWAINE - Token Counts per Day&lt;/p&gt;
    &lt;p&gt;If you want to experience the power of agentic analytics first-hand, try the public AgentHouse demo, which exposes publicly available datasets via the Agentic Data Stack.&lt;/p&gt;
    &lt;head rend="h2"&gt;The open-source advantage #&lt;/head&gt;
    &lt;p&gt;The agentic open-source landscape is currently centered around developer tooling and SDKs, which makes perfect sense given that developers are typically the earliest adopters of emerging technologies. The main open-source projects in this space aim to empower builders to create, extend, and customize agentic systems with SDKs, frameworks, orchestration layers, and integrations. This developer-first focus helps establish the foundational ecosystem and standards needed before broader consumer applications take off.&lt;/p&gt;
    &lt;p&gt;We see the Agentic Data Stack as one of the first proposals of a composable software stack that focuses on the higher-level integration story, allowing users to get started and deliver value in no time. Both ClickHouse and LibreChat share the same open-source software DNA, and joining forces strengthens our commitment to that vision:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LibreChat remains 100% open-source under its existing MIT license&lt;/item&gt;
      &lt;item&gt;Community-first development continues with the same transparency and openness&lt;/item&gt;
      &lt;item&gt;Expanded roadmap to bring an even more enterprise-ready analytics experience.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This proven playbook is the same one that we applied when joining forces with PeerDB to provide our ClickPipes CDC capabilities, and HyperDX, which became the UX of our observability product, ClickStack.&lt;/p&gt;
    &lt;p&gt;We believe that being good stewards of open-source means not just maintaining code, but actively investing in and growing the communities that depend on it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limitations #&lt;/head&gt;
    &lt;p&gt;Large Language Models can be tricky to use in production. While grounding responses in real-time data often helps, AI agents are not immune to hallucinations: situations where the model generates incorrect information with high confidence.&lt;/p&gt;
    &lt;p&gt;Our own experience running internal agents within ClickHouse taught us that the best remediation comes from providing the LLMs with the maximum and most accurate context possible. This can be achieved by commenting the tables using the SQL COMMENT syntax, for example, or by providing more context in-line, in the chat, or part of the system prompt of the LLM session.&lt;/p&gt;
    &lt;p&gt;Finally, robust evaluations are critical for agentic analytics in production because they turn qualitative agent behavior into quantifiable insights, enabling teams to measure effectiveness, detect regressions, and continuously improve system performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's next for LibreChat and ClickHouse users? #&lt;/head&gt;
    &lt;p&gt;For existing LibreChat deployments: nothing changes. LibreChat continues to work exactly as it does today, and we are committed to continuing to invest in it and make sure the community thrives.&lt;/p&gt;
    &lt;p&gt;For ClickHouse users, over the coming months, we'll be releasing tailored integration capabilities that make LibreChat a native part of the ClickHouse experience without sacrificing its generic integration capabilities. Think of it as a “happy path” for agentic analytics in LibreChat. This will include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seamless integration of the LibreChat experience alongside your ClickHouse Cloud instances&lt;/item&gt;
      &lt;item&gt;Extended support for data visualizations rendering in LibreChat&lt;/item&gt;
      &lt;item&gt;OAuth, end-to-end user identification, security, and governance schemes.&lt;/item&gt;
      &lt;item&gt;Tailored context providing (aka. semantic layer)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And many more. Please stay tuned for more updates by joining our communities in Slack and Discord.&lt;/p&gt;
    &lt;p&gt;Finally, for users of the LibreChat Code Interpreter API (a paid service offered by LibreChat that provides a sandboxed environment for executing code). We are planning to evolve this offering and discontinue this API in its current form. We understand that changes can take time to implement, and for this reason, we decided to set the timeline of this transition for the next 6 months (targeting May 1st, 2026). We will reach out to all code interpreter users directly to coordinate the transition.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get started #&lt;/head&gt;
    &lt;p&gt;For LibreChat users: Continue using LibreChat as you always have, and join our community on Discord if you haven’t already, to connect with other users building agents.&lt;/p&gt;
    &lt;p&gt;For ClickHouse users: You can already deploy the Agentic Data Stack by following our user guides in our public documentation and videos&lt;/p&gt;
    &lt;p&gt;For everyone else: Experience the power of the open-source Agentic Data Stack with AgentHouse, and let us know how we can help you succeed!&lt;/p&gt;
    &lt;p&gt;As always, the ClickHouse team would be honored to partner with you on your journey toward agentic analytics. Whether you're using LibreChat today or are interested in building analytical agents, please contact us!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://clickhouse.com/blog/librechat-open-source-agentic-data-stack"/><published>2025-11-10T16:44:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45877892</id><title>Canadian military will rely on army of public servants to grow its ranks by 300k</title><updated>2025-11-10T18:15:24.263084+00:00</updated><content>&lt;doc fingerprint="fbec9bb51c30df2b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Canadian military will rely on an army of public servants to boost its ranks by 300,000&lt;/head&gt;
    &lt;p&gt;Federal public servants would be trained to shoot guns, drive trucks and fly drones, according to a defence department directive.&lt;/p&gt;
    &lt;p&gt;The Canadian Forces is counting on public servants to volunteer for military service as it tries to ramp up an army of 300,000 as part of a mobilization plan, according to a defence department directive.&lt;/p&gt;
    &lt;p&gt;Federal and provincial employees would be given a one-week training course in how to handle firearms, drive trucks and fly drones, according to the directive, signed by Chief of the Defence Staff Gen. Jennie Carignan and defence deputy minister Stefanie Beck on May 30, 2025.&lt;/p&gt;
    &lt;p&gt;The public servants would be inducted into the Supplementary Reserve, which is currently made up of inactive or retired members of the Canadian Forces who are willing to return to duty if called. At this point, there are 4,384 personnel in the Supplementary Reserves, but in the case of an emergency, that would be boosted to 300,000, according to the directive from Beck and Carignan.&lt;/p&gt;
    &lt;p&gt;While the supplementary recruiting push will “prioritize volunteer public servants at the federal and provincial/territorial level” the entry standards wouldn’t be strict, according to the nine-page unclassified directive.&lt;/p&gt;
    &lt;p&gt;“The entry criteria for the Supplementary or other Reserve should be less restrictive than the Reserve Force for age limits as well as physical and fitness requirements,” the document noted.&lt;/p&gt;
    &lt;p&gt;After the initial entry into the ranks, the public servants would be required to do one week’s worth of military training each year but would not be issued uniforms. Medical coverage would be provided for their annual military service, but that time would not count towards their pensions, the directive pointed out.&lt;/p&gt;
    &lt;p&gt;The training focus would be on “basic skills (e.g. shoot, move, and communicate; drive a truck; fly a drone: etc.)”, Beck and Carignan wrote.&lt;/p&gt;
    &lt;p&gt;Their directive approved the creation of a “tiger team” which will work on setting the stage for a Defence Mobilization Plan or DMP. That team will examine what changes are needed to government legislation as well as examine other factors required to allow for such a massive influx of Canadians into the military.&lt;/p&gt;
    &lt;p&gt;Department of National Defence spokeswoman Andrée-Anne Poulin confirmed in an email that participation in the expanded reserve force would be voluntary. “Initial planning has begun to explore how the CAF (Canadian Armed Forces) could contribute to greater national resilience, including leveraging increased readiness from an expanded Reserve Force for defence purposes, in times of crisis, or for natural disasters for example,” she added.&lt;/p&gt;
    &lt;p&gt;Neither DND nor the military would provide comment on the timelines for the creation of the mobilization plan.&lt;/p&gt;
    &lt;p&gt;Work on the initiative by the tiger team located at DND’s Carling Campus in Ottawa began on June 4. DND would not comment on whether Carignan and Beck have been briefed on the initial work of the team.&lt;/p&gt;
    &lt;p&gt;The directive also points to a massive increase in the number of Canadian Forces reservists. The reserves are made up of volunteers who are in current military units. Although they are considered part-time, they are involved in training on a year-round basis.&lt;/p&gt;
    &lt;p&gt;The current reserve force would jump from 23,561 to 100,000 for the mobilization plan. There are no details on how that increase would be handled.&lt;/p&gt;
    &lt;p&gt;Beck and Carignan pointed out that the plan would require a Whole of Society (or WoS) effort, meaning that all Canadians would have to contribute to the initiative. That would require the Privy Council Office to lead a government “approach to population engagement to advance servant culture around sovereignty and public accountability,” according to their directive.&lt;/p&gt;
    &lt;p&gt;“Defence will not accomplish the outcome alone, rather it will necessitate shaping, facilitation and engagement with the Privy Council Office, other government departments and agencies as well as socialization with the Canadian public,” they added.&lt;/p&gt;
    &lt;p&gt;The tiger team will also consult with Canada’s allies, “including Finland which is a recognized leader in this area,” the document pointed out.&lt;/p&gt;
    &lt;p&gt;Finland has a conscription-based military. Every male Finnish citizen aged 18-60 is liable for military service, and women can apply for military service on a voluntary basis, according to the Finnish defence department website.&lt;/p&gt;
    &lt;p&gt;After Finnish citizens complete their compulsory full-time military service, they are transferred to the reserves. In May, the Finnish government proposed an initiative that would raise the age limit of conscript reservists to 65.&lt;/p&gt;
    &lt;p&gt;DND and the Canadian Forces also declined to comment on how ongoing recruitment problems might impact its mobilization plan.&lt;/p&gt;
    &lt;p&gt;A new report by Auditor General Karen Hogan revealed that the Canadian Forces is not currently recruiting enough individuals to meet its operational needs. “The Canadian Armed Forces continued to have challenges attracting and training enough highly skilled recruits to staff many occupations such as pilots and ammunition technicians,” Hogan said of the report, which was released Oct. 21.&lt;/p&gt;
    &lt;p&gt;In their document, Beck and Carignan noted the Canadian government has called for greater resiliency and autonomy on security matters. In order to achieve that goal, the Defence Mobilization Plan is needed, they added.&lt;/p&gt;
    &lt;p&gt;The document does not set out the specific criteria for the mobilization plan to be put into action. But it does mention that global security has been dramatically affected by the rise of strategic competition among states.&lt;/p&gt;
    &lt;p&gt;Some Canadian Forces leaders have claimed that a war between western nations and China or Russia could happen in the near future. In June 2025, Brig.-Gen. Brendan Cook, the Royal Canadian Air Force’s director general of air and space force development, warned that Canada needed to rearm for a potential war with China or Russia. That war could come between 2028 and 2030, Cook suggested.&lt;/p&gt;
    &lt;p&gt;In October 2023, the Ottawa Citizen reported on a document issued by then Chief of the Defence Staff Gen. Wayne Eyre pointed out that Canada is already at war with Russia and China.&lt;/p&gt;
    &lt;p&gt;David Pugliese is an award-winning journalist covering Canadian Forces and military issues in Canada. To support his work, including exclusive content for subscribers only, sign up here: ottawacitizen.com/subscribe&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ottawacitizen.com/public-service/defence-watch/canadian-military-public-servants"/><published>2025-11-10T16:55:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45878545</id><title>Hacker News Headlines (game)</title><updated>2025-11-10T18:15:24.011150+00:00</updated><content>&lt;doc fingerprint="efc1f1bdbf0a98e8"&gt;
  &lt;main&gt;
    &lt;p&gt;You'll see 5 headlines. Guess how many upvotes each received.&lt;/p&gt;
    &lt;p&gt;Fetching the top 500 stories from the past month...&lt;/p&gt;
    &lt;p&gt;Guess the upvotes for this story:&lt;/p&gt;
    &lt;p&gt;Your guess:&lt;/p&gt;
    &lt;p&gt;upvotes&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://projects.peercy.net/projects/hn-oracle/index.html"/><published>2025-11-10T17:47:49+00:00</published></entry></feed>