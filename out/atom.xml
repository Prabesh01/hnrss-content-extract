<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-11T03:08:28.370474+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46564116</id><title>Org Mode Syntax Is One of the Most Reasonable Markup Languages for Text (2017)</title><updated>2026-01-11T03:08:36.527089+00:00</updated><content>&lt;doc fingerprint="52849bffcb6479ed"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Updates &lt;list rend="ul"&gt;&lt;item&gt;2017-09-25: Simplified the table syntax even more&lt;/item&gt;&lt;item&gt;2018-04-06: Comments on the standardization argument&lt;/item&gt;&lt;item&gt;2019-04-12: Extended syntax examples, "Makes Sense Outside of Emacs", "Tool Support" and added more backlinks&lt;/item&gt;&lt;item&gt;2020-05-02: Comment by Ian Zimmerman&lt;/item&gt;&lt;item&gt;2021-05-24: more examples for AsciiDoc&lt;/item&gt;&lt;item&gt;2021-11-28: The birth of "Orgdown" - a new name for the Org mode syntax (see Summary)&lt;/item&gt;&lt;item&gt;2024-12-22: Part with the explanation on the Markdown flavor explosion&lt;/item&gt;&lt;item&gt;2025-03-09: extended the list of Markdown standards&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Disclaimer: this is a very nerdy blog entry. It is about lightweight markup languages and why I think that Org mode syntax is the best lightweight markup language for many use-cases. And with lightweight markup language, I do mean the syntax, the way you express headings, lists, font variations such as bold face or italic, and such things.&lt;/p&gt;
    &lt;p&gt;Disclaimer: I've written a very similar article on why Markdown is a bad idea in general.&lt;/p&gt;
    &lt;p&gt;Please do note that this is not about Emacs at all. This is about Org mode syntax and its advantages even when used outside of Emacs. You can type Org mode syntax in vim, notepad.exe, Atom, Notepad++, and all other text editors out there. And in my opinion it does have advantages compared to the other, common lightweight markup standards such as Markdown, AsciiDoc, Wikitext or reStructuredText.&lt;/p&gt;
    &lt;p&gt;Of course, Org mode syntax is my favorite syntax. Despite my personal choice you will see that I've got some pretty convincing arguments that underline my statement as well. So this is not just a matter of personal taste.&lt;/p&gt;
    &lt;p&gt;If you already have a grin on your face because you don't have any clue what this is all about: keep on reading. It makes an excellent example for making fun of nerds at your next dinner party. ;-)&lt;/p&gt;
    &lt;head rend="h2"&gt;Org Mode Syntax Is Intuitive, Easy to Learn and Remember&lt;/head&gt;
    &lt;p&gt;Here you are. This is almost anything you need to know about Org mode syntax:&lt;/p&gt;
    &lt;quote&gt;* This Is A Heading ** This Is A Sub-Heading *** And A Sub-Sub-Heading Paragraphs are separated by at least one empty line. *bold* /italic/ _underlined_ +strikethrough+ =monospaced= [[http://Karl-Voit.at][Link description]] http://Karl-Voit.at â link without description - list item - another item - sub-item 1. also enumerated 2. if you like - [ ] yet to be done - [X] item which is done : Simple pre-formatted text such as for source code. : This also respects the line breaks. *bold* is not bold here.&lt;/quote&gt;
    &lt;p&gt; And yes, for the people with advanced syntax in mind, this is not everything. Just the basics. A common objection is that source code needs a begin and an end marker instead of a string prefix like &lt;code&gt;: &lt;/code&gt; and Org mode syntax is providing this as well:

&lt;/p&gt;
    &lt;quote&gt;#+BEGIN_SRC python myresult = 42 * 23 print('Hello Europe! ' + str(myresult)) #+END_SRC&lt;/quote&gt;
    &lt;p&gt;I've seen many coworkers who typed Org mode markup when taking notes in their text editor. And they did not even know anything about it. So it is that intuitive I'd say.&lt;/p&gt;
    &lt;p&gt;While I was learning Org mode, I did not even use a cheat-sheet for the syntax as I normally do. It was very natural for me to type Org mode syntax right from the start.&lt;/p&gt;
    &lt;p&gt;Tables are a bit more complicated like in all other markup languages I know of:&lt;/p&gt;
    &lt;quote&gt;| My Column 1 | My Column 2 | Last Column | |-------------+-------------+-------------| | 42 | foo | bar | | 23 | baz | abcdefg | |-------------+-------------+-------------| | 65 | | |&lt;/quote&gt;
    &lt;p&gt;You most probably won't type a table like this outside of Emacs. The manual alignment without tool-support is very tedious. But even here you are able to deliver a perfectly fine Org mode table by simply ignoring the alignment altogether:&lt;/p&gt;
    &lt;quote&gt;| My Column 1|My Column 2 | Last Column | |- | 42 | foo | bar| | 23 | baz | abcdefg| |- | 65 |||&lt;/quote&gt;
    &lt;head rend="h2"&gt;Org Mode Syntax Is Standardized&lt;/head&gt;
    &lt;p&gt;This is an almost ridiculous argument because in my opinion a markup is of no use when it is not the same for tool A as for tool B.&lt;/p&gt;
    &lt;p&gt;However, there are markup languages that are different. For example the very widely used markup language named Markdown has many flavors to choose from (list far from complete):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the original writeup and implementation by John Gruber&lt;/item&gt;
      &lt;item&gt;Markdown Extra&lt;/item&gt;
      &lt;item&gt;MultiMarkdown&lt;/item&gt;
      &lt;item&gt;GitHub Flavored Markdown&lt;/item&gt;
      &lt;item&gt;CommonMark which tries to standardize the Markdown standard (again)&lt;/item&gt;
      &lt;item&gt;Djot (derived from CommonMark)&lt;/item&gt;
      &lt;item&gt;MyST (superset of CommonMark)&lt;/item&gt;
      &lt;item&gt;by the time you read this, there probably will be even much more!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Pandoc lists six different Markdown flavors as output formats. This is an absolutely bad situation which foils the original idea behind lightweight markup languages. When some web service tells me that I can use "Markdown" for a text field, I have to dig deeper to find out which of those many different Markdown standards the web page is talking about. After this I will have to continue and look for a cheat-sheet of this dialect because nothing is more difficult to differentiate than multiple standards that are almost the same but not really the same. A usability hell. I get furious every time I have to enter this hell.&lt;/p&gt;
    &lt;p&gt;With Markdown, the original (inconsistently designed) syntax format is a minimal set that made much sense when used when typing emails and so forth. Later-on, various tools needed more syntax elements for obvious reasons. For example, tools wanted to have footnotes or tables. Those syntax add-ons extended the original Markdown. However, they were not standardized.&lt;/p&gt;
    &lt;p&gt;This resulted in a zoo of very similar but incompatible set of Markdown flavors. Those differences cause information loss by moving from one "Markdown" tool to another "Markdown" tool because Markdown is not Markdown in most cases.&lt;/p&gt;
    &lt;p&gt;In contrast to that, the syntax of Emacs Org-mode as the one and only original form has - by far - the largest set of syntax elements and various extensions by modules. Any other adaptation of this syntax in other tools chose a real sub-set of the original syntax elements. This makes data transitions much smoother, is less error-prone and causes less data loss.&lt;/p&gt;
    &lt;p&gt;As of 2025-02, there is no formal Org-mode syntax definition. However, as described in the upper paragraphs, the Org-mode syntax is more standardized than any of the Markdown standards with respect to Markdown in general. All Org-mode syntax elements are part of the Emacs Org-mode implementation and all derivatives are sub-sets of this set of syntax elements. This is quite the opposite with Markdown.&lt;/p&gt;
    &lt;p&gt; An additional notion (which is not related to the syntax itself) is the lack of standardization of file extensions using Markdown syntax. I've seen &lt;code&gt;.md&lt;/code&gt;, &lt;code&gt;.mkdn&lt;/code&gt;, &lt;code&gt;.markdown&lt;/code&gt; and even &lt;code&gt;.txt&lt;/code&gt; (in Markdown).

&lt;/p&gt;
    &lt;p&gt; With Org mode syntax, life is easy. The snippet from the previous section explains all there is. Any tool that interprets Org mode syntax accepts this simple and easy to remember syntax. The file name extension is always &lt;code&gt;.org&lt;/code&gt;.

&lt;/p&gt;
    &lt;head rend="h2"&gt;Org Mode Syntax Is Consistent&lt;/head&gt;
    &lt;head rend="h3"&gt;Different Heading Approaches&lt;/head&gt;
    &lt;p&gt;Many lightweight markup languages do offer multiple ways of typing headings.&lt;/p&gt;
    &lt;p&gt;There are basically three ways of defining headings:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Prefix headings&lt;/item&gt;
      &lt;item&gt;Pre- and postfix headings&lt;/item&gt;
      &lt;item&gt;Underlined headings&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are some examples for each category:&lt;/p&gt;
    &lt;quote&gt;Prefix headings: # Heading 1 ## Heading 2 ### Heading 3 Pre- and postfix headings: = Heading 1 = == Heading 2 == === Heading 3 === Underlined headings: Heading 1 ========= Heading 2 ~~~~~~~~~ Heading 3 *********&lt;/quote&gt;
    &lt;p&gt; I prefer the prefix heading style. Org mode syntax use this as well with &lt;code&gt;*&lt;/code&gt; as prefix characters. The more asterisks, the deeper the level of the heading is.

&lt;/p&gt;
    &lt;p&gt; Pre- and postfix headings do offer bad usability. The user has manually synchronize the number of prefix character with the number of postfix characters. And it is totally unclear how something like &lt;code&gt;=&lt;/code&gt; with different numbers of pre/postfix characters is going to turn out when being interpreted.

&lt;code&gt; heading &lt;/code&gt;==&lt;/p&gt;
    &lt;p&gt;And in case the user already used a markup language with simple prefix headings, it is not logical why there is the need for the postfix characters at all.&lt;/p&gt;
    &lt;p&gt;Even worse than this is the underlined heading category. The user is completely irritated for multiple reasons. Besides the tedious manual work to align the stupid heading characters with the heading title, it is not clear what characters must be used for those heading lines. If you've got a bigger document with different levels of headings you get confused which heading character stands for which heading level.&lt;/p&gt;
    &lt;p&gt;Are the tilde characters level one? Or was it the equals characters? And how about asterisks? Without a cheat-sheet, the occasional markup user is completely lost.&lt;/p&gt;
    &lt;p&gt;This gets even more worse: some markup languages let you choose your "order" of heading characters. This results in weird situations. For example one author is starting to write a reStructuredText document using her favorite heading syntax. A second author is joining in and has to analyze the document in order to know what heading syntax he must use.&lt;/p&gt;
    &lt;head rend="h3"&gt;reStructuredText&lt;/head&gt;
    &lt;p&gt;In the reStructuredText mode of Emacs you can find following function:&lt;/p&gt;
    &lt;quote&gt;You can visualize the hierarchy of the section adornments in the current buffer by invoking&lt;code&gt;rst-display-adornments-hierarchy&lt;/code&gt;, bound on&lt;code&gt;C-c C-a C-d&lt;/code&gt;. A temporary buffer will appear with fake section titles rendered in the style of the current document. This can be useful when editing other people's documents to find out which section adornments correspond to which levels.&lt;/quote&gt;
    &lt;p&gt;Yes, you got it right, it is true: this function's only purpose is to generate a dummy-hierarchy of headings to visualize which markup has to be used for heading 1, which one for heading 2 and so forth just for this single document. What a bad design decision of the markup when you need such hacks just to know how a heading should look like in a markup even if you are familiar with in the first place.&lt;/p&gt;
    &lt;p&gt;Here is one more: some markup languages even allow mixed heading styles. You can use an underlined heading style for heading level 1, a prefix style for level 2, another underlining style for level 3 and so forth. Now the chaos is a perfect one.&lt;/p&gt;
    &lt;head rend="h3"&gt;AsciiDoc&lt;/head&gt;
    &lt;p&gt;I'm using this cheatsheet as reference for this section in AsciiDoc.&lt;/p&gt;
    &lt;quote&gt;Level 1 ------- Text. Level 2 ~~~~~~~ Text. Level 3 ^^^^^^^ Text. Level 4 +++++++ Text.&lt;/quote&gt;
    &lt;p&gt;There is no good way of memorizing the characters used for the various levels of headings. Within the text, you can't see clearly which heading has a higher level.&lt;/p&gt;
    &lt;p&gt;Do you have to manually align the characters below the heading text? Does it work when the heading text has a different length than the following line?&lt;/p&gt;
    &lt;quote&gt;== Level 1 Text. === Level 2 Text. ==== Level 3 Text. ===== Level 4 Text.&lt;/quote&gt;
    &lt;p&gt;Why are there two different options for the same very basic syntax element? What about mixing them? Does it work?&lt;/p&gt;
    &lt;p&gt;Why don't they start with one eual sign? Level one consists of two equal characters and so forth. Why this off-by-one mismatch?&lt;/p&gt;
    &lt;quote&gt;* bullet * bullet - bullet - bullet * bullet ** bullet ** bullet *** bullet *** bullet **** bullet&lt;/quote&gt;
    &lt;p&gt;and&lt;/p&gt;
    &lt;quote&gt;- bullet * bullet&lt;/quote&gt;
    &lt;p&gt;Again: why two different ways of writing a simple list?&lt;/p&gt;
    &lt;p&gt;First list version: Why do I have to use multiple asterisks but just one dash?&lt;/p&gt;
    &lt;quote&gt;a. letter b. letter .. letter2 .. letter2 . number . number 1. number2 2. number2 3. number2 4. number2 . number .. letter2 c. letter&lt;/quote&gt;
    &lt;p&gt;One letter, two dots, one dot â any logic seems to be gone.&lt;/p&gt;
    &lt;quote&gt;Term 1:: Definition 1 Term 2:: Definition 2 Term 2.1;; Definition 2.1 Term 2.2;; Definition 2.2 Term 3:: Definition 3 Term 4:: Definition 4 Term 4.1::: Definition 4.1 Term 4.2::: Definition 4.2 Term 4.2.1:::: Definition 4.2.1 Term 4.2.2:::: Definition 4.2.2 Term 4.3::: Definition 4.3 Term 5:: Definition 5&lt;/quote&gt;
    &lt;p&gt;Definition indented or not? The level after the definition text is hard to follow in the layout.&lt;/p&gt;
    &lt;quote&gt;.Multiline cells, row/col span |==== |Date |Duration |Avg HR |Notes |22-Aug-08 .2+^.^|10:24 | 157 | Worked out MSHR (max sustainable heart rate) by going hard for this interval. |22-Aug-08 | 152 | Back-to-back with previous interval. |24-Aug-08 3+^|none |====&lt;/quote&gt;
    &lt;p&gt;Please note that this has many table options that Org mode syntax does not provide such as multi-line cells. However, this comes with the price of a table syntax I would not be able to remember at least for occasional use.&lt;/p&gt;
    &lt;head rend="h3"&gt;Web Links and Simple Markup in Different Markup Languages&lt;/head&gt;
    &lt;p&gt;Let's have a look at a different markup element: external links. As you already remember in Org mode syntax, a link looks like this:&lt;/p&gt;
    &lt;quote&gt;[[http://Karl-Voit.at][my home page]]&lt;/quote&gt;
    &lt;p&gt;The only difficult thing here is to remember that the URL is at the beginning and the description follows after the URL. Many markup languages do add additional and unnecessary levels of difficulties.&lt;/p&gt;
    &lt;p&gt;Here are some examples from Wikipedia and comments by me where a user might be irritated.&lt;/p&gt;
    &lt;p&gt;AsciiDoc:&lt;/p&gt;
    &lt;quote&gt;http://example.com[Text]&lt;/quote&gt;
    &lt;p&gt; The form is simple but for complex URLs, the &lt;code&gt;[Text]&lt;/code&gt; might look like being part of the URL itself. Not beautiful but at least something I could live with.

&lt;/p&gt;
    &lt;p&gt;Markdown:&lt;/p&gt;
    &lt;quote&gt;[Text](http://example.com) [Text](http://example.com "Title")&lt;/quote&gt;
    &lt;p&gt; Brackets or parentheses first? Why using different kind of markup characters in the first place like only brackets? Is the &lt;code&gt;Title&lt;/code&gt; part of the URL? Why not part of &lt;code&gt;Text&lt;/code&gt;? Very confusing design decisions from my point of view.

&lt;/p&gt;
    &lt;p&gt;reStructuredText:&lt;/p&gt;
    &lt;quote&gt;`Text &amp;lt;http://example.com/&amp;gt;`_&lt;/quote&gt;
    &lt;p&gt; Holy moly. This is some weird stuff. First, you have to grave accents &lt;code&gt;`&lt;/code&gt; and not apostrophes &lt;code&gt;'&lt;/code&gt;. Then what about the underscore character at the end? This is as complicated as you can define a simple URL. I'd even prefer the hard to type HTML version of linking. A disaster for something which has "lightweight" in its class name.

&lt;/p&gt;
    &lt;p&gt;Even with the most basic formatting syntax, Markdown (I assume in all flavors of it) shows a high level of inconsistency:&lt;/p&gt;
    &lt;quote&gt;_italic_, **bold**, `monospace`, ~~strikethrough~~&lt;/quote&gt;
    &lt;p&gt;Why is it that italic and monospace require only one character before and after the string in-between and others require two? It's inconsistent and therefore hard to learn and error-prone.&lt;/p&gt;
    &lt;p&gt;Markdown has even different formatting for the very same thing:&lt;/p&gt;
    &lt;quote&gt;This is **bold text**. This is __bold text__. Text**is**bold NOT allowed: Text__is__bold&lt;/quote&gt;
    &lt;quote&gt;This is *italic*. This is _italic_. Text*is*italic NOT allowed: Text_is_italic&lt;/quote&gt;
    &lt;quote&gt;Horizontal Rules with three or more asterisks (***), dashes (---), or underscores (___) on a line by themselves&lt;/quote&gt;
    &lt;p&gt;And now compare the Org syntax for the same formats:&lt;/p&gt;
    &lt;quote&gt;/italic/, *bold*, ~monospace~, +strikethrough+ three or more dashes on one line for horizontal rules&lt;/quote&gt;
    &lt;p&gt;Org made different choices for the syntax. In my opinion with better mnemonics but you could disagree here. However, with one leading and one trailing syntax character, it's for sure easier to learn, type and recognize due to better consistency.&lt;/p&gt;
    &lt;head rend="h2"&gt;Org Mode Syntax Can Be Easily Typed&lt;/head&gt;
    &lt;p&gt;The simple syntax of Org mode does not imply typing unnecessary characters. You don't have to manually align something like underlined headings. Anybody using a simple text editor is very fast at adding markup for headings, font variations, and so forth. The previous section proved that other markup languages clearly fail in many cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Org Mode Syntax Makes Sense Outside of Emacs&lt;/head&gt;
    &lt;p&gt;You don't have to use the Emacs editor to write and work with Org mode markup text. As I mentioned above, many people already do so just because Org mode syntax is an intuitive and clean way of typing text characters.&lt;/p&gt;
    &lt;p&gt;When you've got text information in Org mode markup, you can process it with many tools. Most prominent and most important examples are files pushed within a GitHub repository and the swiss army knife named Pandoc which is able to convert Org mode syntax to dozens of formats like HTML, odt (LibreOffice), docx (Word), LaTeX, PDF, and so forth.&lt;/p&gt;
    &lt;p&gt;Many lightweight markups don't come with any decent tool support at all. When I'm using, e.g., markdown in any solution that doesn't do more than syntax highlighting, there is no real reason why this can not be written in Org mode syntax instead.&lt;/p&gt;
    &lt;p&gt;So, yes, Org mode syntax came with a perfect tool support in the first place. But my point is, that the syntax itself has that many advantages that is should be adapted for all the "tool-support is not the main focus"-applications as well.&lt;/p&gt;
    &lt;p&gt;You can write and render Org mode syntax in GitHub and GitLab. You can and should use it in any text editor like Notepad for your personal notes. Especially when there is no tool support because of the "easy to type manually"-syntax.&lt;/p&gt;
    &lt;head rend="h2"&gt;Org Mode Syntax Has Excellent Tool Support (If You Want)&lt;/head&gt;
    &lt;p&gt;As I mentioned in the beginning, this is not an article about Emacs. Nevertheless for anybody not familiar with Emacs I have to mention that with Emacs there is a tool that supports (not only) in writing Org mode syntax in a perfect way.&lt;/p&gt;
    &lt;p&gt;You might start with mouse-only usage. There are menu items with all important functions. For the users that want to get a minimum of efficiency, the menu items show you the keyboard shortcuts you might want to use.&lt;/p&gt;
    &lt;p&gt; For Org mode syntax it is really easy to learn. Basically you just have to use &lt;code&gt;TAB&lt;/code&gt; for toggle the collapsing and expanding of headings, lists, and blocks. It's &lt;code&gt;Alt&lt;/code&gt; and the arrow keys to move around headings, list items, and even table columns/rows. &lt;code&gt;Ctrl-Return&lt;/code&gt; creates a new heading or list item without the need of entering the markup characters and manually matching indentation levels at all.

&lt;/p&gt;
    &lt;p&gt;That's it. With those three things you're good to write Org mode syntax efficiently. The basic file open/save, finding help, exiting Emacs stuff is accessible with icons or the menu. No need to learn more keyboard shortcuts if you don't want to.&lt;/p&gt;
    &lt;p&gt;Having experienced this great tool-support, users typically are eager to learn more. You don't have to. You might be happy with Org mode for capturing minutes of meetings and your shopping list. However, others do master a few additional things and write whole eBooks within Org mode.&lt;/p&gt;
    &lt;p&gt;Since this article is not about Emacs, I want to explain why I mention the perfect Emacs support. My point is that Org mode deserves to be adopted for all kind of use-cases where a simple to read and simple to type lightweight markup is needed. However, if you want to have a decent tool support, there is no lightweight markup out there which has a better tool support compared to Org mode within Emacs. I did not find any tool support for Markdown, AsciiDoc, Wikitext or reStructuredText anywhere that could compete with the cozy Org mode syntax support within Emacs.&lt;/p&gt;
    &lt;p&gt;Yes, there could be more tool support outside of emacs but this is my point: change this. This syntax should support more people.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;Lightweight markup languages are designed to be used with a minimum effort compared to full-blown and therefore more complicated markup languages such as HTML or LaTeX.&lt;/p&gt;
    &lt;p&gt;Some are doing their job better than others. In my experience, many design decisions of widely adapted markups such as Markdown, AsciiDoc or reStructuredText (and others) are questionable from a usability point of view. At least I do have some issues when I have to use them in my daily life.&lt;/p&gt;
    &lt;p&gt;Unfortunately, I hardly see any people out there using Org mode syntax as a markup language outside of Emacs although there are very good reasons for it as an easy to learn and easy to use markup language.&lt;/p&gt;
    &lt;p&gt;With this blog article I wanted to point out the usefulness of Org mode even when you are not using Emacs as an writing tool. Of course, when you are using Emacs to type Org mode syntax, you get probably the most advanced tool-support for typing lightweight markup on top. But this was not the point of this article.&lt;/p&gt;
    &lt;p&gt;Update 2021-11-28: Due to the high demand and discussions of this article, the idea grew in me that we do have to address some issues of Org-mode mentioned here. Therefore, I came up with Orgdown. You should check out my Orgdown motivation article.&lt;/p&gt;
    &lt;p&gt;Backlinks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Large thread on Hacker News&lt;/item&gt;
      &lt;item&gt;Discussions on reddit: emacs, programming&lt;/item&gt;
      &lt;item&gt;Irreal: Karl Voit on the Superiority of Org Mode Markup&lt;/item&gt;
      &lt;item&gt;Another thread on hn.svelte.technology&lt;/item&gt;
      &lt;item&gt;Yet another reddit thread with a comment by me on the downsides of markdown in particular&lt;/item&gt;
      &lt;item&gt;2019-04-10: Another thread on Hacker News&lt;/item&gt;
      &lt;item&gt;2019-04-14: https://github.com/ngortheone/org-rs "More about Org Mode"&lt;/item&gt;
      &lt;item&gt;2020-06-29: Not a back-link to this article but also a discussion on the superiority of Org syntax&lt;/item&gt;
      &lt;item&gt;2020-7-31: Goodbye Markdown! | Org mode Tutorial | Switching to Emacs #5.1 - YouTube &lt;list rend="ul"&gt;&lt;item&gt;Tutorial video on the Org mode syntax. Please note: you don't need to use Emacs for writing Org mode texts.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Backlinks&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2017-09-23: Discussion on Hacker News&lt;/item&gt;
      &lt;item&gt;2019-04-10: Discussion on Hacker News&lt;/item&gt;
      &lt;item&gt;2021-11-18: Discussion on Hacker News&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Comments&lt;/head&gt;
    &lt;p&gt;"revocation" has a valid point related to the missing standardization of Org mode. Here is my comment on this:&lt;/p&gt;
    &lt;p&gt;The statements here refer to a lightweight markup, the basic things of Org mode syntax. I explicitly listed "headings, lists, font variations such as bold face or italic, and such things".&lt;/p&gt;
    &lt;p&gt;What I do not cover here is a full syntax statement or standard. In my opinion, currently this is not possible outside of Emacs for various reasons.&lt;/p&gt;
    &lt;p&gt;Of course, there are variations in interpreting Org mode files between Emacs and pandoc. Also, pandoc only supports a sub-set of Org mode. Otherwise, pandoc would have to re-implement or embed Emacs for parsing purposes.&lt;/p&gt;
    &lt;p&gt; In this specific case, pandoc seems to have a more strict parser related to leading spaces for #-lines, or keywords. I'm pretty sure that the pandoc project accepts this issue as a bug. In doubt, the interpretation of Emacs is the definition, or golden-standard, of Org mode syntax. Even this beta-version of a syntax definition does not mention optional spaces before keywords. The manual mentions &lt;code&gt;org-element-parse-buffer&lt;/code&gt; and &lt;code&gt;org-lint&lt;/code&gt; which would be most probably the best choice for defining the official standard if you would search for one.

&lt;/p&gt;
    &lt;p&gt;However, this does not relate at all with the intention of this article: the design of the (basic) Org mode syntax compared to other lightweight markup languages. All the issues mentioned where other markups show inconsistencies and usability issues where Org mode seems to have advantages still do apply here. Completely independent of the standardization argument. My personal believe is, that if there would be more use of Org mode syntax elements outside of Emacs, there would be a much higher pressure on formally defining Org mode as a syntax which pandoc and even Emacs could use as the golden standard.&lt;/p&gt;
    &lt;p&gt;So far, there is not even the necessity of defining this golden standard because nobody outside of the Emacs community knows or even is using Org mode. And this is what I tried to change a bit because other markup languages do tend to hurt my geeky soul when I do have to use them. ;-)&lt;/p&gt;
    &lt;head rend="h2"&gt;Comment by Ian Zimmerman&lt;/head&gt;
    &lt;p&gt;Ian wrote an email comment on reStructuredText (ReST):&lt;/p&gt;
    &lt;quote&gt;Most of your argument makes at least some sense, but you miss the point of the ReST link syntax: the URL doesn't have to be inline! The normal style (which I use for my blog) is like this:&lt;code&gt;blah blah blah follow the interesting link at `foo`_ blah blah blah&lt;/code&gt;&lt;code&gt;more blah bluh bleh&lt;/code&gt;&lt;code&gt;.. _foo: http ://www.foo.example.com&lt;/code&gt;&lt;lb/&gt;which among other things means that you can mention and link foo multiple times without repeating the URL.&lt;lb/&gt;Maybe there is a way of doing that in org - I don't know, I'm a total beginner. That's why I'm reading your post.&lt;/quote&gt;
    &lt;p&gt; (Note: I added an additional space character after &lt;code&gt;http&lt;/code&gt; in the example above to work around this lazyblorg issue.)

&lt;/p&gt;
    &lt;p&gt;First, about that question related to defining an URL once and referring to it multiple times. I'm not aware of an Org mode feature that is providing this functionality except footnotes, which is not specific to URLs only. An even more general approach could be the use of very powerful macro replacement. However, discussion those things, we're far away from the discussion of markup that is lightweight.&lt;/p&gt;
    &lt;p&gt;Second, I acknowledge that I did not cover this possibility to define URL references in REsT markup. In my opinion and when I try to look at it from a hypothetic user perspective, I do think that this still proves my point. There is no logical explanation for that underscore character. I already had to add those back-ticks as syntax element. Why combining those back-ticks with an additional underscore? This does not make sense to me. Furthermore, where should I place this block where the URLs are defined? After each paragraph? Visual clutter. At the end of the text? Too fragile IMHO. And don't get me started on those two dots and the underscore switching places. This is certainly not putting more weight in the thought that ReST syntax has a higher level of logic.&lt;/p&gt;
    &lt;p&gt;For somebody looking for a smooth, easy to remember lightweight markup language, I still think that nothing beats Org mode in general. Even when we totally neglect the Emacs integration and 99 percent of its feature-set which allows for the most complex requirements while still being consistent and lightweight in syntax.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://karl-voit.at/2017/09/23/orgmode-as-markup-only/"/><published>2026-01-10T09:15:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46564762</id><title>New information extracted from Snowden PDFs through metadata version analysis</title><updated>2026-01-11T03:08:35.129339+00:00</updated><content>&lt;doc fingerprint="22d661474f85de18"&gt;
  &lt;main&gt;&lt;p&gt;Previous parts:&lt;/p&gt;&lt;p&gt;We discovered that entire sections describing domestic U.S. intelligence facilities were deliberately removed from two published documents, while equivalent foreign facilities remained visible. The evidence exists in an unexpected place - the PDF metadata of documents published by The Intercept in 2016, and by The Intercept and the Australian Broadcasting Corporation in a 2017 collaborative investigation. To our knowledge, this is the first time this information has been revealed publicly. The removed sections reveal the operational designations and cover name structure for domestic U.S. NRO Mission Ground Stations.&lt;/p&gt;&lt;p&gt;Using PDF analysis tools, we found hidden text embedded in the metadata versioning of two documents published alongside investigative stories about NSA satellite surveillance facilities. These metadata artifacts prove that earlier versions of the documents contained detailed descriptions of domestic U.S. ground stations that were systematically scrubbed before publication (not just redacted with black boxes, but with text completely removed).&lt;/p&gt;What was published from the Snowden documents:&lt;list rend="ul"&gt;&lt;item&gt;Operational details for RAF Menwith Hill Station (UK)&lt;/item&gt;&lt;item&gt;Operational details for Pine Gap (Australia)&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;Potomac Mission Ground Station (PMGS) - Washington, DC. Public cover name: "Classic Wizard Reporting and Testing Center" (CWRTC).&lt;/item&gt;&lt;item&gt;Consolidated Denver Mission Ground Station (CDMGS) - Denver area. Public cover name: "Aerospace Data Facility" (ADF).&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The facilities themselves are not unknown. "Aerospace Data Facility" at Buckley Space Force Base is publicly acknowledged as a National Reconnaissance Office (NRO) Mission Ground Station. "Classic Wizard Reporting and Testing Center" at Naval Research Laboratory is publicly acknowledged, though its designation as a Mission Ground Station is less clear. What's NOT public (until now) is the specific operational designations used in classified networks: "Consolidated Denver Mission Ground Station (CDMGS)" and "Potomac Mission Ground Station (PMGS)." The Snowden documents prove these are deliberate cover names (not just alternative terminology) and show exactly what's classified and what's not.&lt;/p&gt;&lt;head rend="h2"&gt;Hidden PDF versions&lt;/head&gt;&lt;p&gt;The first PDF document titled "Menwith satellite classification guide" has two versions in the file metadata: an older one and a newer one. The removed information exists in the earlier version, and is completely removed in the second, published version. This is not standard redaction with black boxes - the text was completely deleted from the visible document while remaining embedded in the PDF's internal version history.&lt;/p&gt;&lt;p&gt;Screenshot from the first version of the document, containing the hidden text (sections 5.1.5.2 - 5.1.5.6).&lt;/p&gt;&lt;p&gt;Screenshot from the second version of the document, where the text is removed.&lt;/p&gt;&lt;p&gt;The removed text:&lt;/p&gt;&lt;quote&gt;5.1.5.2 (U) Facility Name: Formally identified as the ,Mission Support Facility(MSF) also re- ferred as the Classic Wizard Reporting and Testing Center (CWRTC). 5.1.5.3 (S//TK) Cover Story: The fact of a cover story is S//TK, the cover story itself is unclas- sified. 5.1.5.4 (U) Software development, maintenance, testing, and communications support to a world-wide Navy communications and reporting system. 5.1.5.5 (U) Associations: 1. The term Potomac Mission Ground Station (PMGS)=S//TK 2. The term Classic Wizard Reporting and Testing Center (CWRTC)=UNCLASSIFIED 3. The term Naval Research Laboratory=UNCLASSIFIED 4. The fact that CWRTC is the cover name for the PMGS=S//TK 5. The fact that CWRTC is a communications and data relay location for the US=UNCLASSIFIED (no association w/NRO) 6. The fact that PMGS is located on the NRL=S//TK 7. The fact that the NRO has a MGS located on the NRL=S//TK 8. The fact that the CWRTC is located on the NRL=UNCLASSIFIED (no association w/NRO) 9. CWRTC associated w/NRO=S//TK 10. Association of NRO, CIA, or NSA personnel with the CWRTC=S//TK 11. Association of CWRTC with other NRO MGS=S//TK 12. Association of MSF with the NRO=S//TK. 13. Association of CWRTC with the ADF=UNCLASSIFIED (no association w/NRO) 5.1.5.6 (U) Visitors: CWRTC is housed within buildings 259 and 260 on the Naval Research Laboratory in Southwest Washington, DC.&lt;/quote&gt;&lt;p&gt;The second document "NRO SIGINT Guide for Pine Gap" also has two versions in the file metadata: an older one and a newer one.&lt;/p&gt;&lt;p&gt;Screenshot from the first version of the document, containing the hidden text (section 5.1.2).&lt;/p&gt;&lt;p&gt;Screenshot from the second version of the document, where the text is removed.&lt;/p&gt;&lt;p&gt;The removed text:&lt;/p&gt;&lt;quote&gt;5.1.2 (S//TK) Consolidated Denver Mission Ground Station (CDMGS) 5.1.2.1 (U) Facility Name: Aerospace Data Facility (ADF) 5.1.2.2 (S//TK) Cover Story: The fact of a cover story is S/TK, the cover story itself is unclassi- fied.&lt;/quote&gt;&lt;head rend="h2"&gt;Potomac Mission Ground Station (PMGS)&lt;/head&gt;&lt;p&gt;In the "hidden version" of the document "Menwith satellite classification guide" section 5.1.5 describes a facility formally identified by its cover name "Mission Support Facility (MSF)," also referred to as the "Classic Wizard Reporting and Testing Center (CWRTC)." The classified operational designation is Potomac Mission Ground Station (PMGS).&lt;/p&gt;&lt;p&gt;Location: Buildings 259 and 260, Naval Research Laboratory, Southwest Washington, DC.&lt;/p&gt;&lt;p&gt;Public cover story: "Software development, maintenance, testing, and communications support to a world-wide Navy communications and reporting system."&lt;/p&gt;&lt;p&gt;Actual function: Mission Ground Station in the National Reconnaissance Office's satellite intelligence network.&lt;/p&gt;&lt;p&gt;The document explicitly states that "the fact of a cover story is S//TK" - meaning even acknowledging that CWRTC is a cover name (rather than the facility's real identity) is classified Secret/Talent Keyhole.&lt;/p&gt;&lt;p&gt;The classification guide provides a detailed breakdown of what's public and what's secret:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;"Classic Wizard Reporting and Testing Center (CWRTC)" = UNCLASSIFIED&lt;/item&gt;&lt;item&gt;"Potomac Mission Ground Station (PMGS)" = S//TK (SECRET)&lt;/item&gt;&lt;item&gt;The fact that CWRTC is a cover name for PMGS = S//TK (SECRET)&lt;/item&gt;&lt;item&gt;Association of NRO, CIA, or NSA personnel with CWRTC = S//TK (SECRET)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This layered classification allows the facility to operate under a public identity while keeping its actual intelligence designation and function secret.&lt;/p&gt;&lt;head rend="h2"&gt;Consolidated Denver Mission Ground Station (CDMGS)&lt;/head&gt;&lt;p&gt;In the "hidden version" of the document "NRO SIGINT Guide for Pine Gap" section 5.1.2 describes a facility identified by the cover name "Aerospace Data Facility (ADF)". The classified operational designation is "Consolidated Denver Mission Ground Station (CDMGS)."&lt;/p&gt;&lt;p&gt;Location: Buckley Space Force Base, Aurora, Colorado&lt;/p&gt;&lt;p&gt;Public acknowledgment: Publicly known as "Aerospace Data Facility-Colorado." For example ADF-C is openly described in Wikipedia as an NRO facility for "command and control of reconnaissance satellites."&lt;/p&gt;&lt;p&gt;What's NOT public: The operational designation "Consolidated Denver Mission Ground Station" and the fact that "Aerospace Data Facility" is a cover name for it.&lt;/p&gt;&lt;p&gt;As with PMGS, the classification guide shows "the fact of a cover story is S//TK" - the deception itself is classified.&lt;/p&gt;&lt;p&gt;Both hidden facilities appear in an organizational classification table in the Pine Gap guide. The table's visual structure reveals which names refer to the same facilities through deliberate formatting. Thicker borders separate distinct facility groups, while thinner borders separate columns within each group (this might be a bit hard to see from the screenshot/document). Each facility appears multiple times - once under its classified operational designation, and again under its unclassified cover name(s):&lt;/p&gt;&lt;p&gt;The groupings show:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Denver facility: CDMGS (real designation) + ADF (cover name) + FSD (Field Station Denver, cover name)&lt;/item&gt;&lt;item&gt;Potomac facility: PMGS (real designation) + MSF (cover name) + CWRTC (cover name)&lt;/item&gt;&lt;item&gt;Menwith Hill: HMGS (real designation) + RAF MHS (cover name)&lt;/item&gt;&lt;item&gt;Pine Gap: AMGS (real designation) + JDFPG (cover name)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;For each facility, the real operational designation (CDMGS, PMGS, HMGS, AMGS) has all agency associations classified S//TK (Secret). But the cover names have NSA and NGA associations marked as unclassified (U) or For Official Use Only (U//FOUO).&lt;/p&gt;&lt;p&gt;This creates a classification system where you can publicly acknowledge intelligence work using sanitized facility names, while the actual operational designations remain secret.&lt;/p&gt;&lt;p&gt;The domestic facilities use two cover names each (ADF + FSD for Denver; MSF + CWRTC for Potomac), while foreign facilities use only one. This suggests layered operational security for facilities on U.S. soil - possibly to navigate Congressional oversight, legal restrictions on domestic intelligence operations, or different audiences requiring different levels of plausible deniability.&lt;/p&gt;&lt;p&gt;There is a deliberate pattern in these two classification guides: detailed sections describing specific U.S. facilities were removed, while equivalent foreign facility sections were published intact. The 2016 Menwith Hill guide had its PMGS section (5.1.5) completely removed. The 2017 Pine Gap guide had its CDMGS section (5.1.2) completely removed. Both guides retained their detailed descriptions of foreign facilities, including operational designations, cover stories, and visitor protocols.&lt;/p&gt;&lt;p&gt;U.S. facilities weren't entirely absent from the published documents. The Pine Gap classification table shows CDMGS, PMGS, ADF, and other U.S. facility designations alongside foreign facilities, revealing the structure of the Mission Ground Station network. Other published documents from both investigations mention U.S. facilities. What was specifically removed were the detailed classification guide sections that would have explained these U.S. facilities the same way Menwith Hill and Pine Gap were explained.&lt;/p&gt;&lt;head rend="h2"&gt;Who edited the documents?&lt;/head&gt;&lt;p&gt;PDF metadata provides forensic evidence of the editing process. The Pine Gap classification guide shows timestamps from July 31, 2017, three weeks before publication. Two versions were created minutes apart using Nitro Pro 8, a commercial PDF editor: version 1 at 13:48:54 (containing the CDMGS section) and version 2 at 13:50:48 (with CDMGS removed). The Intercept and ABC published identical PDFs with the same metadata artifacts, indicating the editing was done once and the same file shared between organizations.&lt;/p&gt;&lt;p&gt;The Intercept, as holder of the Snowden archive, likely handled technical document preparation for publications. The Menwith Hill classification guide, published solely by The Intercept in 2016, shows more thorough metadata sanitization but the same editorial pattern - domestic facility sections removed while foreign equivalents remain.&lt;/p&gt;&lt;p&gt;We contacted Ryan Gallagher, the journalist who led both investigations, to ask about the editorial decision to remove these sections. After more than a week, we have not received a response.&lt;/p&gt;&lt;p&gt;The next part will be a technical deep-dive into PDF metadata across the published Snowden documents. We found that many documents contain multiple versions in their metadata, revealing the editorial redaction process: visible NSA agents' usernames that were later removed, screenshots that were later redacted, and surveillance data that went through multiple rounds of redaction. We'll also document cases of failed redactions - including one where redacted text remained fully copyable, previously reported only by a Polish cybersecurity blog.&lt;/p&gt;&lt;head rend="h2"&gt;Notes&lt;/head&gt;&lt;p&gt;You can extract versions from a PDF file for example with a pdfresurrect tool (pdfresurrect -w filename.pdf).&lt;/p&gt;&lt;p&gt;You can download the document versions directly here:&lt;/p&gt;Menwith satellite classification guide versions: NRO SIGINT Guide for Pine Gap versions:&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://libroot.org/posts/going-through-snowden-documents-part-4/"/><published>2026-01-10T11:23:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46565132</id><title>Eulogy for Dark Sky, a data visualization masterpiece (2023)</title><updated>2026-01-11T03:08:34.909738+00:00</updated><content>&lt;doc fingerprint="bf2e3a527d562d9d"&gt;
  &lt;main&gt;
    &lt;p&gt;On January 1, 2023, Apple sunsetted (pun intended) the Dark Sky mobile app on iOS. Apple purchased the company behind the popular weather application in early 2020, then announced that it would be shutting down the Dark Sky applications (first on Android, then on iOS and web), and finally stated in 2022 that the forecast technology would be integrated into the Apple Weather app with iOS 16.&lt;/p&gt;
    &lt;p&gt;But Dark Sky was much more than just an API or a set of “forecast technologies.” The design of the Dark Sky mobile application represented a hallmark of information design because the team clearly obsessed over how people would actually use the app on a daily basis.&lt;/p&gt;
    &lt;p&gt;Here’s a gallery of screenshots I personally took in the last year.&lt;/p&gt;
    &lt;p&gt;The design of Dark Sky was so wonderful that I could understand the shape of the weather at a glance, even from a zoomed out view of the app.&lt;/p&gt;
    &lt;head rend="h2"&gt;Common use cases for a weather app&lt;/head&gt;
    &lt;p&gt;Before we can dissect what makes the design of this app so special, let’s define the most common use cases for a weather app. A good weather app attempts to address a range of use cases in a person’s life. Here are some common use cases for a weather app, starting with the contextual goals first:&lt;/p&gt;
    &lt;p&gt;You’ll notice that the questions I want to answer vary based on the context and situation I’m in. This is the perfect situation for software that embraces good information design principles.&lt;/p&gt;
    &lt;p&gt;In Magic Ink, Bret Victor defined information design “as the design of context-sensitive information graphics.” Unlike static graphics, like a weather map in a newspaper, information graphics in software can be highly dynamic and can incorporate context from the user’s environment.&lt;/p&gt;
    &lt;p&gt;Dark Sky aggressively leaned into these ideas, and the team worked hard to turn nearly everything in the application into a context-sensitive information graphic. Let’s dive deeper into some examples where this notion is in full display.&lt;/p&gt;
    &lt;head rend="h2"&gt;Weather forecast for the day at a precise location&lt;/head&gt;
    &lt;p&gt;I’ll start by listing my goals when trying to understand the upcoming weather for the day:&lt;/p&gt;
    &lt;p&gt;The default experience for the Dark Sky application is to show weather for the next 12 hours at my precise location. Here are three screenshots from the app, from different days and locations. What do you notice?&lt;/p&gt;
    &lt;p&gt;The app contextualizes the information that’s presented based on what’s most relevant.&lt;/p&gt;
    &lt;p&gt;In the left-most screenshot, the context of the weather storm that’s passing by my location and some potential light rain is emphasized to the user. The wind advisory and dip in the “feels like” temperature also make honorable mentions. In combination with the clickable Wind Advisory warning, I can quickly understand that the storm has passed my specific location but I should still be mindful of the wind.&lt;/p&gt;
    &lt;p&gt;In the middle screenshot, the storm front heading my direction, the imminent rain starting within the hour, and the hours of rain later in the day are emphasized front and center. Based on my interest in the rain, I scrolled down (not shown in screenshot) to switch from temperature to rain probability for the main weather view.&lt;/p&gt;
    &lt;p&gt;In the right-most screenshot, the temperature distribution throughout the day is emphasized.&lt;/p&gt;
    &lt;p&gt;There are lots of little details that are easy to miss, as well. For example, all three screenshots above start showing weather information starting at the current moment (“now”) and onwards. This is brilliant, because I only occasionally care about weather from a few hours or days ago. (To accommodate those situations, the app did have a unique Time Machine view to explore past weather data.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Weather forecast for the week&lt;/head&gt;
    &lt;p&gt;Let’s revisit our goals when trying to understand the weather for the week:&lt;/p&gt;
    &lt;p&gt;While many other weather apps focus on helping me understand the weather at the city level, the Dark Sky app differentiates itself by enabling me to understand the weather with a hyperlocal view. I can view the weather at specific addresses and landmarks and understand how the weather might be different in a city center compared to the towns around it.&lt;/p&gt;
    &lt;p&gt;By default, the Dark Sky app shows the weekly weather summary at my current location (screenshot on the left). I can contextualize the weekly weather view by clicking the search icon and typing in the alternative location I’m interested in (screenshot on the right).&lt;/p&gt;
    &lt;p&gt;At a glance, I can quickly understand:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Which days are likely to rain.&lt;/item&gt;
      &lt;item&gt;Which days have wide temperature ranges (low lows and high highs).&lt;/item&gt;
      &lt;item&gt;The general shape of the weather (micro-trends).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Gallery of subtle design elements&lt;/head&gt;
    &lt;p&gt;In the first few sections, I laid the groundwork by diving a bit more deeply into specific aspects of Dark Sky. Now that I’ve hopefully engaged your critical design eye, I’d like to elevate other elements in the app’s design in a more rapid-fire fashion. I hope that this section will provide some ideas and inspiration for people designing their own data-rich applications.&lt;/p&gt;
    &lt;p&gt;Preserving temperature magnitudes in ranges&lt;/p&gt;
    &lt;p&gt;To represent data visually, the data needs to be mapped from “data space” to “pixel space”. In some domains and scenarios, you want to ensure the magnitudes are carried over, and in others you want to rescale the values to a fixed scale so the resulting charts are more consistent in the space and pixels they take up.&lt;/p&gt;
    &lt;p&gt;In the Dark Sky app, the “temperature pills” representing the forecasted temperatures for the upcoming week preserve their existing magnitude more effectively in the visualization. The temperature values are more tightly integrated with the visual representation, making the combined experience more amenable to quick comparison across multiple days.&lt;/p&gt;
    &lt;p&gt;Many weather apps opt for the design pattern on the right, where all temperature ranges are rescaled to take up the same amount of space in the app.&lt;/p&gt;
    &lt;p&gt;Replacing numbers with rough categories&lt;/p&gt;
    &lt;p&gt;Interpreting hourly distributions of rainfall or snowfall can be difficult. Is 0.25 inches of rain a lot over the next hour? What about 0.2 inches of snow per hour for the next hour, then 0.15 for the hour after that? How do I prepare for these circumstances?&lt;/p&gt;
    &lt;p&gt;To help users stay informed and take action, the app will often replace precise forecast distributions of rainfall and snowfall with rough categories instead. This design choice has two positive effects on users:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It contextualizes the forecast to simpler categories that can help us quickly make changes in our life if needed. &lt;list rend="ul"&gt;&lt;item&gt;Light snow that starts and stops means that my snow shoveling company won’t come out, but heavy snow means they likely will.&lt;/item&gt;&lt;item&gt;Heavy snow means I should probably make sure my outdoor furniture is better covered and ready to take the snow.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;It removes a sense of artificial precision that doesn’t really exist because weather forecasts fundamentally have very high uncertainty and error bands.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contextualized storm map&lt;/p&gt;
    &lt;p&gt;Simple color scales combined with arrows go a very long way to conveying relevant storm information.&lt;/p&gt;
    &lt;p&gt;Wind direction&lt;/p&gt;
    &lt;p&gt;Instead of conveying wind direction using text (“NW” or “Northwest”), the app uses arrows! If the wind shifts directions throughout the day, I can feel the wind direction changing using my body.&lt;/p&gt;
    &lt;head rend="h2"&gt;Complaints from former Dark Sky users&lt;/head&gt;
    &lt;p&gt;As you can tell, I could probably write an entire book about the design of Dark Sky.&lt;/p&gt;
    &lt;p&gt;Instead, I want to share some passionate comments from other Dark Sky fans. While most of them aren’t data viz or design nerds, they feel that the Apple Weather app is not a sufficient replacement. These people relied on Dark Sky to make decisions and grew very attached to an application that integrated deeply into their lives.&lt;/p&gt;
    &lt;p&gt;Here are some examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;0000GKP on Reddit: “I have already made the transition to the Weather app. The information is presented in a much less efficient manner than Dark Sky so it takes more effort to get it, but it is all there (except for cloud cover).”&lt;/item&gt;
      &lt;item&gt;TheGeckoDude on Reddit: “Is there anything that has the precipitation graph similar to dark sky? The biggest thing I will miss from dark sky is that graph. I’m outside a lot and it is super helpful for knowing when to take cover or when it might rain. I need to find a feature like that because the vague weather precipitation info will not cut it for me.”&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Let’s make data shine!&lt;/head&gt;
    &lt;p&gt;Dark Sky started with publicly available data, augmented it with contextualized predictions, rigorously iterated on data visualization design, and packaged all of this into a contextualized experience to make weather data useful for me in my daily life.&lt;/p&gt;
    &lt;p&gt;While the availability of data has never been higher, we’re still missing software experiences that contextualize that data to make our lives better. Data alone isn’t enough.&lt;/p&gt;
    &lt;p&gt;The world needs more Dark Sky-like experiences to help us improve our spending habits, help us sleep better, and more. If you’re working on information software, I hope you can be inspired by the body of design and engineering work that Dark Sky pioneered.&lt;/p&gt;
    &lt;head rend="h5"&gt;Srini Kadamati&lt;/head&gt;
    &lt;p&gt;Srini Kadamati currently helps build better data management tools for biomedical research at Manifold.ai. Previously, he taught data visualization and data skills at Dataquest.io and Preset.io.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nightingaledvs.com/dark-sky-weather-data-viz/"/><published>2026-01-10T12:23:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46566465</id><title>I replaced Windows with Linux and everything's going great</title><updated>2026-01-11T03:08:34.762762+00:00</updated><content>&lt;doc fingerprint="15a6595bd9b335ce"&gt;
  &lt;main&gt;
    &lt;p&gt;Greetings from the year of Linux on my desktop.&lt;/p&gt;
    &lt;head rend="h1"&gt;I replaced Windows with Linux and everything’s going great&lt;/head&gt;
    &lt;p&gt;Linux diary, chapter one: winging it.&lt;/p&gt;
    &lt;p&gt;Linux diary, chapter one: winging it.&lt;/p&gt;
    &lt;p&gt;In November, I got fed up and said screw it, I’m installing Linux. Since that article was published, I have dealt with one minor catastrophe after another. None of that has anything to do with Linux, mind you. It just meant I didn’t install it on my desktop until Sunday evening.&lt;/p&gt;
    &lt;p&gt;My goal here is to see how far I can get using Linux as my main OS without spending a ton of time futzing with it — or even much time researching beforehand. I am not looking for more high-maintenance hobbies at this stage. I want to see if Linux is a wingable alternative to Microsoft’s increasingly annoying OS.&lt;/p&gt;
    &lt;p&gt;Honestly? So far it’s been fine. Many things I expected to be difficult — like getting my Nvidia graphics card working properly — were perfectly straightforward. A few things I thought would be simple weren’t. And I’ve run into one very funny issue with a gaming mouse that only works in games. But I’ve been able to use my Linux setup for work this week, I played exactly one video game, and I even printed something from my accursed printer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Day one&lt;/head&gt;
    &lt;p&gt;I picked CachyOS rather than a better-known distro like Ubuntu because it’s optimized for modern hardware, and I had heard that it’s easy to install and set up for gaming, which is one of the reasons I’d stuck with Windows for this long. After backing up my Windows image sometime in December (close enough), I follow the installation instructions in the Cachy wiki and download the CachyOS live image to a Ventoy USB drive, plug it into my PC, reboot into the BIOS to disable Secure Boot, reboot again into the Ventoy bootloader, and launch the CachyOS disk image.&lt;/p&gt;
    &lt;p&gt;First challenge: My mouse buttons don’t work. I can move the cursor, but can’t click on anything. I try plugging in a mouse (without unplugging the first one), same deal. Not a major issue; I can get around fine with just the keyboard. Maybe this is just an issue with the live image.&lt;/p&gt;
    &lt;p&gt;I launch the installer and am thrust into analysis paralysis. An operating system needs lots of little pieces to work — stuff you don’t even think of as individual components if you use Mac or Windows. How do you boot into the OS? What runs the desktop environment? How are windows drawn? What’s the file system? Where do you get software updates? In Mac and Windows, all those decisions are made for you. But Linux is fundamentally different: The core of the OS is the kernel, and everything else is kind of up to you. A distro is just somebody’s idea of what pieces to use. Some, like Pop_OS! and Mint, aim for simplicity and make all those choices for you (though you can still change them if you want). But Cachy is based on Arch, a notoriously DIY distro, and before I do anything else, I have to pick one of four bootloaders. I pick Limine, for reasons I can’t recall.&lt;/p&gt;
    &lt;p&gt;Next, I need to figure out where to install it. On the recommendation of Will Smith from the Dual Boot Diaries podcast — from whom the “an operating system is a bunch of pieces” thing above is largely cribbed — I install Cachy on a different physical drive from Windows, since Windows updates tend not to care if they overwrite other bootloaders.&lt;/p&gt;
    &lt;p&gt;I have a 4TB storage drive with just over a terabyte of data on it, so I shrink that partition down to 2TB using the installer’s manual partitioning interface, then (following the guide) make a 2GB boot partition and a root partition using the btrfs file system. The guide says it needs at least 20GB, so I go big and make it 100GB. This will cause a minor problem later.&lt;/p&gt;
    &lt;p&gt;Next, I have to pick one of thirteen different desktop environments. This is too many options. KDE and Gnome seem to be the best-supported for gaming, so I pick KDE. I could rabbit-hole on this, but I don’t.&lt;/p&gt;
    &lt;p&gt;And then I just have to pick a username and password and name the computer. After some thought, I go with Maggie, after my in-laws’ cat, who half the family calls Linux. She doesn’t answer to either name.&lt;/p&gt;
    &lt;p&gt;Installation takes six minutes. I reboot the computer, and it loads into the Limine bootloader, which has also found my Windows install, so I can choose between Cachy and Windows.&lt;/p&gt;
    &lt;p&gt;Then I’m on the Cachy desktop, and my mouse buttons still aren’t working. Swapping USB ports doesn’t do anything. Plugging in my trackball doesn’t fix it either. I finally try unplugging the mouse, which makes the trackball work normally. My gaming mouse is an ancient Mad Catz Cyborg RAT 7; it turns out this is a known issue. I defer editing configuration files for now and just keep the mouse unplugged.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stuff that works&lt;/head&gt;
    &lt;p&gt;That weird mouse aside, all of the hardware I’ve tried so far has just worked. Cachy automatically installed the correct GPU drivers; my monitor, speakers, and Logitech webcam work fine with no effort. Even my printer prints, with only a tweak to my firewall settings.&lt;/p&gt;
    &lt;p&gt;There are lots of ways to install apps on Linux. Sometimes you can just download them from a company’s website, or you get them from your distro’s official repositories, or GitHub, or wherever. There’s no official app store for Linux, but there are at least three projects aiming to provide universal Linux apps: Flatpak, AppImage, and Snap. Neat! Commence hodgepodging.&lt;/p&gt;
    &lt;p&gt;I grab Chromium, Discord, Slack, and Audacity using the “Install Apps” button on Cachy’s welcome screen. Slack I get from the Arch User Repository. Twenty minutes later, I try to install 1Password from the same location, but the repository is down. I pick up my kid from a playdate and try again. It works.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s missing&lt;/head&gt;
    &lt;p&gt;I prefer the Arc browser, which doesn’t have a Linux build, but there are plenty of browsers. Firefox and Chromium will do. I can’t find official apps for Airtable (which I use for work), Spotify, or Apple Music, but they all work fine in the browser in the short term, and I’ll revisit this later.&lt;/p&gt;
    &lt;head rend="h2"&gt;Shall we play a game?&lt;/head&gt;
    &lt;p&gt;Cachy has a one-click gaming package install that includes the Proton compatibility layer, Steam, and Heroic (a launcher for Epic, GOG, and Amazon). I figure I ought to try one game. Then I remember that my root partition is only 100GB. I reboot back into the Cachy live image and use the Parted utility to increase it to 1TB, then make a second btrfs partition in the remaining space. I reboot, log into Epic and GOG, and start downloading The Outer Worlds, a game from 2019 I’ve been playing a bit lately. It runs fine with Proton, and I can even sync my saves from the cloud. I play it for a few minutes with my trackball, remember I hate gaming on a trackball, and plug my gaming mouse back in. It works fine as long as I’m in the game, but outside the game, mouse clicks stop working again. It makes sense — the bug is on the desktop, not in games — but it’s very funny to have a gaming mouse that only works for gaming.&lt;/p&gt;
    &lt;head rend="h2"&gt;The children yearn for the mines&lt;/head&gt;
    &lt;p&gt;The biggest issue I’ve had so far is Minecraft: Bedrock Edition. For some reason, Microsoft hasn’t prioritized making a Linux version of Bedrock. Java Edition works fine in Linux, but I play Minecraft with my kids, and they’re on Bedrock Edition on their iPads. There’s supposed to be a way to run the Android app with MCPE Launcher, but I couldn’t get it to work. There’s also a project to get the Windows version running on Proton, which will be my next step.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stuff I haven’t tried yet&lt;/head&gt;
    &lt;p&gt;I hear good things about howdy, a Linux equivalent to Windows Hello face authentication, but I haven’t installed it yet. I hear the Zen browser is a good Arc alternative. I also haven’t gotten my cloud storage synced, configured git so I can compile programs from scratch, figured out a backup strategy, or tried much other hardware beyond what’s currently plugged into my computer. There’s a command-line Spotify player I want to try. I’ve only scratched the surface.&lt;/p&gt;
    &lt;p&gt;I did take the time to install a KDE Plasma theme that makes it look like Windows XP, though. Just because.&lt;/p&gt;
    &lt;head rend="h2"&gt;Regret level: none&lt;/head&gt;
    &lt;p&gt;I’m well aware this is the honeymoon phase. And using Linux for less than a week isn’t exactly a flex. Many people use Linux. And I haven’t even tried doing anything particularly difficult, or playing a game that came out this decade. But so far it’s been a much easier transition than expected, and a quieter experience overall. My OS isn’t trying to change my browser or search engine to make some shareholder happy somewhere. It’s not nudging me to try some bullshit AI feature.&lt;/p&gt;
    &lt;p&gt;Will I go crawling back to macOS or Windows the first time I have to edit a batch of photos? Possibly! I’ll definitely boot back into Windows — or pull out a Chromebook — to play Minecraft with my kids, if I can’t get it running on Linux. And I don’t think I’ll ever be able to use Linux exclusively; my job as a reviews editor means I have to stay familiar with as many operating systems as possible. (This is a good way to drive yourself nuts.)&lt;/p&gt;
    &lt;p&gt;I’m sure I’ll run into plenty of fun problems soon enough. But the first few days have been great.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/tech/858910/linux-diary-gaming-desktop"/><published>2026-01-10T15:26:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46566812</id><title>Open Chaos: A self-evolving open-source project</title><updated>2026-01-11T03:08:34.627200+00:00</updated><content>&lt;doc fingerprint="ff96ee0e40fd76a0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;OPENCHAOS.DEV&lt;/head&gt;
    &lt;p&gt;--d --h --m --s&lt;/p&gt;
    &lt;p&gt;until next merge&lt;/p&gt;
    &lt;head rend="h2"&gt;Open PRs — Vote to merge&lt;/head&gt;
    &lt;p&gt;Loading PRs...&lt;/p&gt;
    &lt;p&gt;until next merge&lt;/p&gt;
    &lt;p&gt;Loading PRs...&lt;/p&gt;
    &lt;p&gt;by @yokeTH&lt;/p&gt;
    &lt;p&gt;by @wvanlit&lt;/p&gt;
    &lt;p&gt;by @BetonZM&lt;/p&gt;
    &lt;p&gt;by @bpottle&lt;/p&gt;
    &lt;p&gt;by @FelixLttks&lt;/p&gt;
    &lt;p&gt;by @matthewmayer&lt;/p&gt;
    &lt;p&gt;by @Mad182&lt;/p&gt;
    &lt;p&gt;by @addshore&lt;/p&gt;
    &lt;p&gt;by @Dart120&lt;/p&gt;
    &lt;p&gt;by @julian9499&lt;/p&gt;
    &lt;p&gt;by @fccview&lt;/p&gt;
    &lt;p&gt;by @amanbabuhemant&lt;/p&gt;
    &lt;p&gt;by @bigintersmind&lt;/p&gt;
    &lt;p&gt;by @antonmyrberg&lt;/p&gt;
    &lt;p&gt;by @Loeffeldude&lt;/p&gt;
    &lt;p&gt;by @ksurya&lt;/p&gt;
    &lt;p&gt;by @GoodPassiveMan&lt;/p&gt;
    &lt;p&gt;by @icco&lt;/p&gt;
    &lt;p&gt;by @ectucker1&lt;/p&gt;
    &lt;p&gt;by @addshore&lt;/p&gt;
    &lt;p&gt;by @henryivesjones&lt;/p&gt;
    &lt;p&gt;by @Kl0ven&lt;/p&gt;
    &lt;p&gt;by @prakashsellathurai&lt;/p&gt;
    &lt;p&gt;by @TheHamkerCat&lt;/p&gt;
    &lt;p&gt;by @kouta-kun&lt;/p&gt;
    &lt;p&gt;by @bigintersmind&lt;/p&gt;
    &lt;p&gt;by @bigintersmind&lt;/p&gt;
    &lt;p&gt;by @TheHamkerCat&lt;/p&gt;
    &lt;p&gt;by @hpinsley&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.openchaos.dev/"/><published>2026-01-10T16:03:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46567392</id><title>AI is a business model stress test</title><updated>2026-01-11T03:08:34.551992+00:00</updated><content>&lt;doc fingerprint="3e63d233e7760e68"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;AI is a business model stress test&lt;/head&gt;
    &lt;p&gt;AI commoditizes anything you can specify. It can't commoditize what you have to operate.&lt;/p&gt;
    &lt;p&gt;Tailwind Labs laid off 75% of its engineering team last week.&lt;/p&gt;
    &lt;p&gt;Adam Wathan, CEO of Tailwind Labs, spent the holidays running revenue forecasts. In a GitHub comment, he explained what happened:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The reality is that 75% of the people on our engineering team lost their jobs here yesterday because of the brutal impact AI has had on our business. Traffic to our docs is down about 40% from early 2023 despite Tailwind being more popular than ever.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The story circulating is that AI is killing Open Source businesses. I don't think that is quite right.&lt;/p&gt;
    &lt;p&gt;AI didn't kill Tailwind's business. It stress tested it. Their business model failed the test, but that is not an indictment of all Open Source business models.&lt;/p&gt;
    &lt;p&gt;Tailwind's business model worked for years. It relied on developers visiting their documentation, discovering Tailwind Plus while browsing, and buying it. Tailwind Plus is a $299 collection of pre-built UI components. Traffic led to discovery, and discovery drove sales. It was a reasonable business model, but always fragile.&lt;/p&gt;
    &lt;p&gt;In the last year, more and more developers started asking AI for code instead of reading documentation, and their sales and marketing funnel broke.&lt;/p&gt;
    &lt;p&gt;There is a fairness issue here that I don't want to skip past. AI companies trained their models on Tailwind's documentation and everything the community wrote about it. And now those models generate Tailwind code and answer Tailwind questions without sending anyone to Tailwind's website. The value got extracted, but compensation isn't flowing back. That bothers me, and it deserves a broader policy conversation.&lt;/p&gt;
    &lt;p&gt;What I keep coming back to is this: AI commoditizes anything you can fully specify. Documentation, pre-built card components, a CSS library, Open Source plugins. Tailwind's commercial offering was built on "specifications". AI made those things trivial to generate. AI can ship a specification but it can't run a business.&lt;/p&gt;
    &lt;p&gt;So where does value live now? In what requires showing up, not just specifying. Not what you can specify once, but what requires showing up again and again.&lt;/p&gt;
    &lt;p&gt;Value is shifting to operations: deployment, testing, rollbacks, observability. You can't prompt 99.95% uptime on Black Friday. Neither can you prompt your way to keeping a site secure, updated, and running.&lt;/p&gt;
    &lt;p&gt;That is why Vercel created Next.js and gives it away for free. The Open Source framework is the conduit; the hosting is the product. Same with Acquia, my own company. A big part of Acquia's business model is selling products around Drupal: hosting, search, CI/CD pipelines, digital asset management, and more. We don't sell describable things; we sell operations.&lt;/p&gt;
    &lt;p&gt;Open Source was never the commercial product. It's the conduit to something else.&lt;/p&gt;
    &lt;p&gt;When asked what to pivot to, Wathan was candid: "Still to this day, I don't know what we should be pivoting to". I've written about how digital agencies might evolve, but CSS frameworks and component libraries are a harder case. Some Open Source projects make for great features, but not great businesses.&lt;/p&gt;
    &lt;p&gt;Tailwind CSS powers millions of sites. The framework will survive. Whether the company does is a different question. I'm rooting for them. The world needs more successful Open Source businesses.&lt;/p&gt;
    &lt;p&gt;—&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dri.es/ai-is-a-business-model-stress-test"/><published>2026-01-10T16:56:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46567400</id><title>Show HN: I used Claude Code to discover connections between 100 books</title><updated>2026-01-11T03:08:34.409605+00:00</updated><content>&lt;doc fingerprint="f5f22681c15b4f4c"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Useful Lies&lt;/head&gt;
    &lt;p&gt;Self-deception as strategy: the best liars believe themselves.&lt;/p&gt;
    &lt;p&gt;Self-deception as strategy: the best liars believe themselves.&lt;/p&gt;
    &lt;p&gt;Microscopic defects propagate silently until catastrophic failure.&lt;/p&gt;
    &lt;p&gt;The hunt for words that stick&lt;/p&gt;
    &lt;p&gt;Weak IP accelerates innovation through collaborative copying.&lt;/p&gt;
    &lt;p&gt;Why isolated groups lose knowledge and capabilities.&lt;/p&gt;
    &lt;p&gt;Absent fathers forged titan ambition through unmet longing.&lt;/p&gt;
    &lt;p&gt;Mega-projects orchestrate unreliable elements into coherent wholes.&lt;/p&gt;
    &lt;p&gt;Desperation, not genius, drove transformative pivots.&lt;/p&gt;
    &lt;p&gt;Expertise defies formalization; conscious effort defeats itself.&lt;/p&gt;
    &lt;p&gt;Constraints in one part dictate the whole.&lt;/p&gt;
    &lt;p&gt;Protected spaces insulated from interference enable breakthroughs.&lt;/p&gt;
    &lt;p&gt;Practical knowledge defeats rationalized systems.&lt;/p&gt;
    &lt;p&gt;Rule-breaking as path to understanding.&lt;/p&gt;
    &lt;p&gt;Ego-dissolution enables both transcendence and manipulation.&lt;/p&gt;
    &lt;p&gt;Imitation powers both learning and conformity.&lt;/p&gt;
    &lt;p&gt;Winners eliminate competition; victory becomes permanent control.&lt;/p&gt;
    &lt;p&gt;Every treasure becomes tomorrow's ordinary commodity.&lt;/p&gt;
    &lt;p&gt;Metrics become mirages when optimized directly.&lt;/p&gt;
    &lt;p&gt;Rare signals drown in false positives.&lt;/p&gt;
    &lt;p&gt;Silent agreements to avoid uncomfortable truths.&lt;/p&gt;
    &lt;p&gt;Founders ousted through political power dynamics.&lt;/p&gt;
    &lt;p&gt;Mastery means bypassing conscious thought entirely.&lt;/p&gt;
    &lt;p&gt;Removing friction sometimes creates chaos.&lt;/p&gt;
    &lt;p&gt;Organizations minimize coalitions needed to maintain control.&lt;/p&gt;
    &lt;p&gt;Ripe ideas emerge independently across the world.&lt;/p&gt;
    &lt;p&gt;Copying forms without understanding structure guarantees failure.&lt;/p&gt;
    &lt;p&gt;Actions must be expensive to be believed.&lt;/p&gt;
    &lt;p&gt;Gifts, moral debts, and technical debt share logic.&lt;/p&gt;
    &lt;p&gt;Joy became more productive than efficiency optimization.&lt;/p&gt;
    &lt;p&gt;Getting worse precedes getting better in skill.&lt;/p&gt;
    &lt;p&gt;Large coordination emerges from small-scale trust.&lt;/p&gt;
    &lt;p&gt;Standardization enables scale but destroys local knowledge.&lt;/p&gt;
    &lt;p&gt;Method of creation shapes what is created.&lt;/p&gt;
    &lt;p&gt;Open systems consolidate into monopoly, then repeat.&lt;/p&gt;
    &lt;p&gt;Transforming vague concepts into testable frameworks.&lt;/p&gt;
    &lt;p&gt;Building observability changes what you see.&lt;/p&gt;
    &lt;p&gt;Decision-making speed determines conflict outcomes.&lt;/p&gt;
    &lt;p&gt;Simplification enables breakthroughs or destroys value.&lt;/p&gt;
    &lt;p&gt;Knowing what others don't creates competitive advantage.&lt;/p&gt;
    &lt;p&gt;Precise measurement creates infrastructure for distant trust.&lt;/p&gt;
    &lt;p&gt;Container shipping remade global supply chains.&lt;/p&gt;
    &lt;p&gt;Pursuit of perfection prevents completion.&lt;/p&gt;
    &lt;p&gt;Import order constantly or dissolve into disorder.&lt;/p&gt;
    &lt;p&gt;Simplified models systematically fail in complex reality.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://trails.pieterma.es/"/><published>2026-01-10T16:56:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46567458</id><title>UpCodes (YC S17) is hiring PMs, SWEs to automate construction compliance</title><updated>2026-01-11T03:08:34.035962+00:00</updated><content>&lt;doc fingerprint="f1efd1e76f34fe34"&gt;
  &lt;main&gt;
    &lt;p&gt;Try for Free&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://up.codes/careers?utm_source=HN"/><published>2026-01-10T17:01:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46568662</id><title>Rats caught on camera hunting flying bats</title><updated>2026-01-11T03:08:33.281522+00:00</updated><content>&lt;doc fingerprint="774931e969a21e9c"&gt;
  &lt;main&gt;
    &lt;p&gt;In northern Germany, researchers have filmed brown rats (Rattus norvegicus) leaping from cave ledges to catch bats mid-flight — the first evidence that rodents can intercept flying mammals. The finding, published in Global Ecology and Conservation, turns one of ecology’s everyday characters into an unexpectedly agile predator.&lt;/p&gt;
    &lt;p&gt;The behavior was recorded at Segeberg Kalkberg, a limestone cave that shelters around 30,000 hibernating bats each winter. Using infrared video over five weeks in autumn 2020 and thermal cameras from 2021 to 2024, a team led by Florian Gloza-Rausch in Bad Segeberg captured footage that’s unusual, for sure: a rat balancing on its hind legs at the cave entrance, sensing the movement of wings in the dark, then springing up to seize a bat from the air.&lt;/p&gt;
    &lt;p&gt;Across five weeks of monitoring, the researchers confirmed 13 kills and found a hidden cache of 52 bat carcasses — clear signs that the rats weren’t scavenging leftovers but hunting deliberately. At that rate, a small group of rats could wipe out about 7% of the bat population in a single season.&lt;/p&gt;
    &lt;p&gt;That’s remarkable for an animal not built for flight or pursuit. Brown rats are omnivores that typically scavenge or prey on slow-moving targets. Yet here, they appear to have developed two hunting strategies: aerial interception at the cave mouth and ground attacks on bats crawling to roost. How the rats locate their targets in near-darkness isn’t fully clear, but researchers suspect they use whisker and hearing cues rather than sight.&lt;/p&gt;
    &lt;p&gt;Similar: Brain-Wide Map Shows How Prior Knowledge Guides Mouse Decisions&lt;/p&gt;
    &lt;p&gt;The study describes this as unexpected behavioral plasticity in brown rats. The researchers believe the dense streams of bats and the narrow cave geometry created the perfect ambush zone — a place where a patient predator could learn a new trick.&lt;/p&gt;
    &lt;p&gt;The discovery also adds a new stressor to European bat populations, which are already under pressure from habitat loss and disease. Because brown rats are invasive across much of the continent, their access to major hibernation sites could have lasting ecological effects. The authors suggest managing rat presence near large roosts as a precaution.&lt;/p&gt;
    &lt;p&gt;Nevertheless, the most compelling part of the finding lies not in its numbers but in its image: a common city rat, usually seen raiding bins, now standing alert in a cave mouth, hunting with precision that blurs the line between scavenger and specialist. It’s a reminder that adaptation doesn’t always unfold in distant rainforests — sometimes it happens under our own streetlights, in ways no one thought to look for.&lt;/p&gt;
    &lt;p&gt;Story Source: Gloza-Rausch et al. (2025), published in Global Ecology and Conservation. Read the study here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scienceclock.com/rats-caught-on-camera-hunting-flying-bats-for-the-first-time/"/><published>2026-01-10T18:44:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46568794</id><title>Finding and fixing Ghostty's largest memory leak</title><updated>2026-01-11T03:08:33.149897+00:00</updated><content>&lt;doc fingerprint="36d8d949fca010a8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;Finding and Fixing Ghostty's Largest Memory Leak&lt;/head&gt;
    &lt;p&gt;A few months ago, users started reporting that Ghostty was consuming absurd amounts of memory, with one user reporting 37 GB after 10 days of uptime. Today, I'm happy to say the fix has been found and merged. This post is an overview of what caused the leak, a look at some of Ghostty's internals, and some brief descriptions of how we tracked it down.1&lt;/p&gt;
    &lt;p&gt;The leak was present since at least Ghostty 1.0, but it is only recently that popular CLI applications (particularly Claude Code) started producing the correct conditions to trigger it at scale. The limited conditions that triggered the leak are what made it particularly tricky to diagnose.&lt;/p&gt;
    &lt;p&gt;The fix is merged and is available in tip/nightly releases, and will be part of the tagged 1.3 release in March.&lt;/p&gt;
    &lt;head rend="h2"&gt;The PageList&lt;/head&gt;
    &lt;p&gt;To understand the bug, we first need to understand how Ghostty manages terminal memory. Ghostty uses a data structure called the &lt;code&gt;PageList&lt;/code&gt;
to store terminal content. PageList is a doubly-linked list of
memory pages that store the terminal content (characters, styles, hyperlinks,
etc.).&lt;/p&gt;
    &lt;p&gt;The underlying "pages" are not single virtual memory pages but they are a contiguous block of memory aligned to page boundaries and composed of an even multiple of system pages.2&lt;/p&gt;
    &lt;p&gt;These pages are allocated using &lt;code&gt;mmap&lt;/code&gt;. &lt;code&gt;mmap&lt;/code&gt; isn't particularly fast,
so to avoid constant syscalls, we use a memory pool. When we need
a new page, we pull from the pool. When we're done with a page, we return
it to the pool for reuse.&lt;/p&gt;
    &lt;p&gt;The pool uses a standard size for pages. Think of it like buying standard-sized shipping boxes: most things people ship fit in a standard box, and having a standard box comes with various efficiencies.&lt;/p&gt;
    &lt;p&gt;But sometimes terminals need more memory than a standard page provides. If a set of lines has many emoji, styles, or hyperlinks, we need a larger page. In these cases, we allocate a non-standard page directly with &lt;code&gt;mmap&lt;/code&gt;, bypassing the pool entirely. This is typically a
rare scenario.&lt;/p&gt;
    &lt;p&gt;When we "free" a page, we apply some simple logic:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If the page is &lt;code&gt;&amp;lt;= standard size&lt;/code&gt;: return it to the pool&lt;/item&gt;
      &lt;item&gt;If the page is &lt;code&gt;&amp;gt; standard size&lt;/code&gt;: call&lt;code&gt;munmap&lt;/code&gt;to free it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is the core background for terminal memory management in Ghostty, and the idea itself is sound. A logic bug around an optimization is what produced the leak, as we'll see next.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Scrollback Optimization&lt;/head&gt;
    &lt;p&gt;There's one more background detail we need to cover to understand the bug: scrollback pruning.&lt;/p&gt;
    &lt;p&gt;Ghostty has a &lt;code&gt;scrollback-limit&lt;/code&gt; configuration that caps how much history
is retained. When you hit this limit, we delete the oldest pages in
the scrollback buffer to free up memory.&lt;/p&gt;
    &lt;p&gt;But this often happens in a super hot path (e.g. when outputting large amounts of data quickly), and allocating and freeing memory pages is expensive, even with the pool. Therefore, we have an optimization: reuse the oldest page as the newest page when we reach the limit.&lt;/p&gt;
    &lt;p&gt;This optimization works great. It requires zero allocations and uses only some quick pointer manipulations to move the page from the front to the back of the list. We do some metadata cleanup to "clear" the page but otherwise leave the previous memory intact.&lt;/p&gt;
    &lt;p&gt;It's fast and empirically speeds up scrollback-heavy workloads significantly.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Bug&lt;/head&gt;
    &lt;p&gt;During the scrollback pruning optimization, we always resized our page back to standard size. But we didn't resize the underlying memory allocation itself, we only noted the resize in the metadata. The underlying memory was still the large non-standard &lt;code&gt;mmap&lt;/code&gt; allocation, but now the PageList thought it was standard
sized.&lt;/p&gt;
    &lt;p&gt;Eventually, we'd free the page under various circumstances (e.g. when the user closes the terminal, but also other times). At that point, we'd see the page memory was within the standard size, assume it was part of the pool, and we would never call &lt;code&gt;munmap&lt;/code&gt; on it.
A classic leak.&lt;/p&gt;
    &lt;p&gt;This all seems pretty obvious, but the issue is that non-standard pages are rare by design. The goal of our design and optimizations is that standard pages are the common case and provide a fast-path. Only very specific scenarios produce non-standard pages and they're usually not produced in large quantities.&lt;/p&gt;
    &lt;p&gt;But the rise of Claude Code changed this. For some reason, Claude Code's CLI produces a lot of multi-codepoint grapheme outputs which force Ghostty to regularly use non-standard pages. Additionally, Claude Code uses the primary screen and produces a significant amount of scrollback output. These things combined together created the perfect storm to trigger the leak in huge quantities.&lt;/p&gt;
    &lt;p&gt;I want to be explicit that this bug is not Claude Code's fault. Claude Code is simply exercising Ghostty in a way that exposes this long-standing bug.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Fix&lt;/head&gt;
    &lt;p&gt;The fix is conceptually simple: never reuse non-standard pages. If we encounter a non-standard page during scrollback pruning, we destroy it properly (calling &lt;code&gt;munmap&lt;/code&gt;) and allocate a fresh
standard-sized page from the pool.&lt;/p&gt;
    &lt;p&gt;The core of the fix is in the snippet below, but some extra work was needed to fix up some other bits of accounting we have:&lt;/p&gt;
    &lt;code&gt;if (first.data.memory.len &amp;gt; std_size) {
    self.destroyNode(first);
    break :prune;
}
&lt;/code&gt;
    &lt;p&gt;We could've also reused the non-standard page and just retained the large memory size, but until we have data that shows otherwise, we're still operating under the assumption that standard pages are the common case and it makes sense to reset back to a standard pooled page.&lt;/p&gt;
    &lt;p&gt;Other users have recommended more complex strategies (e.g. maintaining some metrics on how often non-standard pages are used and adjusting our assumptions accordingly), but more research is needed before making those changes. This change is simple, fixes the bug, and aligns with our current assumptions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finding the Leak with VM Tags&lt;/head&gt;
    &lt;p&gt;As part of the fix, I added support for virtual memory tags on macOS provided by the Mach kernel. This lets us tag our PageList memory allocations with a specific identifier that shows up in various tooling.&lt;/p&gt;
    &lt;code&gt;inline fn pageAllocator() Allocator {
    // In tests we use our testing allocator so we can detect leaks.
    if (builtin.is_test) return std.testing.allocator;

    // On non-macOS we use our standard Zig page allocator.
    if (!builtin.target.os.tag.isDarwin()) return std.heap.page_allocator;

    // On macOS we want to tag our memory so we can assign it to our
    // core terminal usage.
    const mach = @import("../os/mach.zig");
    return mach.taggedPageAllocator(.application_specific_1);
}
&lt;/code&gt;
    &lt;p&gt;Now when debugging memory on macOS, Ghostty's PageList memory shows up with a specific tag instead of being lumped in with everything else. This made it trivial to identify the leak, associate it with the PageList, and also verify that the fix worked by observing the tagged memory being properly freed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Preventing Leaks in Ghostty&lt;/head&gt;
    &lt;p&gt;We do a lot of work in the Ghostty project to find and prevent memory leaks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In debug builds and unit tests, we use leak-detecting Zig allocators.&lt;/item&gt;
      &lt;item&gt;The CI runs &lt;code&gt;valgrind&lt;/code&gt;on our full unit test suite on every commit to find more than just leaks, such as undefined memory usage.&lt;/item&gt;
      &lt;item&gt;We regularly run the macOS GUI via macOS Instruments to look for leaks particularly in the Swift codebase.&lt;/item&gt;
      &lt;item&gt;We run every GTK-related PR using Valgrind (the full GUI) to look for leaks in the GTK codepath that isn't unit tested.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This has worked really well to date, but unfortunately it didn't catch this particular leak because it only triggers under very specific conditions that our tests didn't reproduce. The merged PR includes a test that does reproduce the leak to prevent regressions in the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This was the largest known memory leak in Ghostty to date, and the only reported leak that has been confirmed by more than a single user. We'll continue to monitor and address memory reports as they come in, but remember that reproduction is the key to diagnosing and fixing memory leaks!&lt;/p&gt;
    &lt;p&gt;Big thanks to @grishy who finally got me a reliable reproduction so I could analyze the issue myself. Their own analysis reached the same conclusion as mine, and the reproduction let me verify both our understandings independently.&lt;/p&gt;
    &lt;p&gt;Thanks also to everyone who reported this issue with detailed diagnostics. The community's analysis, especially around the &lt;code&gt;footprint&lt;/code&gt; output and
VM region counting, gave me important clues that pointed toward the PageList
as the culprit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mitchellh.com/writing/ghostty-memory-leak-fix"/><published>2026-01-10T18:58:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46569061</id><title>Show HN: Play poker with LLMs, or watch them play against each other</title><updated>2026-01-11T03:08:32.725214+00:00</updated><link href="https://llmholdem.com/"/><published>2026-01-10T19:27:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46569225</id><title>Code Is Clay</title><updated>2026-01-11T03:08:32.665452+00:00</updated><content>&lt;doc fingerprint="af38810558e504dd"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Code is Clay&lt;/head&gt;January 10, 2026&lt;p&gt;Kerri and I took a ceramics class recently!&lt;/p&gt;&lt;p&gt;I made a hypercube.&lt;/p&gt;&lt;p&gt;My instructor was... disappointed. The class was supposed to make a mug, or a bowl, something functional. But I had this idea in my head and couldn't shake it. The glaze turned out amazing (this iridescent blue that shifts in the light). I've been wondering if it would look even cooler painted in Vantablack.&lt;/p&gt;&lt;p&gt;Anyway. I've been noticing parallels between code and clay. They're both mediums. Vessels for ideas. You weren't thinking about hypercubes until you saw one on the coffee table, and now you might be picturing what a ceramic tesseract would even look like.&lt;/p&gt;&lt;p&gt;Both are malleable. When you're centering the clay, it's constantly moving, constantly responding. You push a little too hard and the whole thing wobbles off center. Same with code. You add a feature, refactor something, introduce a bug, fix three more. It's never static. It's never done.&lt;/p&gt;&lt;p&gt;Clay breaks. A lot. My first few attempts collapsed on the wheel. One piece cracked in the kiln. I dropped another walking to my car. But nobody cries about it, you just start over. The clay doesn't care. It's just material waiting for the next idea.&lt;/p&gt;&lt;p&gt;You're gonna have a really bad time if you get too attached to it.&lt;/p&gt;&lt;p&gt;Code is the same way. We're so precious about it sometimes, like every line is sacred. But it's not. It's just text. Delete it. Rewrite it. Start fresh. The idea survives even when the implementation doesn't.&lt;/p&gt;&lt;p&gt;Before AI, we had to make every plate and coffee mug by hand. Every line of code, carefully typed. Every function, crafted manually.&lt;/p&gt;&lt;p&gt;Now? We've hit the industrial revolution of code.&lt;/p&gt;&lt;p&gt;When the industrial revolution came for pottery, factories started pumping out ceramics. Plates got cheap. Mugs became disposable. You'd think clay would have disappeared. Why bother with the slow, messy, manual process when machines could do it faster?&lt;/p&gt;&lt;p&gt;But clay didn't go away. Ceramics studios are everywhere now. People pay good money to throw pots on weekends. Kerri and I are proof. The craft got more valuable once it wasn't necessary anymore. When you don't have to make something by hand, choosing to makes it mean something.&lt;/p&gt;&lt;p&gt;Software engineers love to joke about automating themselves out of a job. Well, we're finally getting there. LLMs can write code. A lot of it, fast. The industrial revolution is here.&lt;/p&gt;&lt;p&gt;So what happens to us?&lt;/p&gt;&lt;p&gt;Maybe the same thing that happened to potters. The production work gets automated. The commodity code writes itself. But the craft remains. The weird ideas, the hypercubes, the things that don't fit in templates: that's still us. That's still human.&lt;/p&gt;&lt;p&gt;Honestly I think I'm going to like it more. I got into programming because I liked building things, not because I wanted to type boilerplate for the rest of my life. If AI handles the mugs, I can focus on the hypercubes.&lt;/p&gt;&lt;p&gt;The medium isn't going anywhere. It's just getting more interesting.&lt;/p&gt;&lt;p&gt;(i never said it was good)&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://campedersen.com/code-is-clay"/><published>2026-01-10T19:43:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46569799</id><title>Extracting books from production language models (2026)</title><updated>2026-01-11T03:08:32.431866+00:00</updated><content>&lt;doc fingerprint="2d3c36199db742cf"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 6 Jan 2026]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Extracting books from production language models&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Many unresolved legal questions over LLMs and copyright center on memorization: whether specific training data have been encoded in the model's weights during training, and whether those memorized data can be extracted in the model's outputs. While many believe that LLMs do not memorize much of their training data, recent work shows that substantial amounts of copyrighted text can be extracted from open-weight models. However, it remains an open question if similar extraction is feasible for production LLMs, given the safety measures these systems implement. We investigate this question using a two-phase procedure: (1) an initial probe to test for extraction feasibility, which sometimes uses a Best-of-N (BoN) jailbreak, followed by (2) iterative continuation prompts to attempt to extract the book. We evaluate our procedure on four production LLMs -- Claude 3.7 Sonnet, GPT-4.1, Gemini 2.5 Pro, and Grok 3 -- and we measure extraction success with a score computed from a block-based approximation of longest common substring (nv-recall). With different per-LLM experimental configurations, we were able to extract varying amounts of text. For the Phase 1 probe, it was unnecessary to jailbreak Gemini 2.5 Pro and Grok 3 to extract text (e.g, nv-recall of 76.8% and 70.3%, respectively, for Harry Potter and the Sorcerer's Stone), while it was necessary for Claude 3.7 Sonnet and GPT-4.1. In some cases, jailbroken Claude 3.7 Sonnet outputs entire books near-verbatim (e.g., nv-recall=95.8%). GPT-4.1 requires significantly more BoN attempts (e.g., 20X), and eventually refuses to continue (e.g., nv-recall=4.0%). Taken together, our work highlights that, even with model- and system-level safeguards, extraction of (in-copyright) training data remains a risk for production LLMs.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.CL&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2601.02671"/><published>2026-01-10T20:50:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46571095</id><title>Private equity firms acquired more than 500 autism centers in past decade: study</title><updated>2026-01-11T03:08:31.924333+00:00</updated><content>&lt;doc fingerprint="2c52d57576b86722"&gt;
  &lt;main&gt;
    &lt;p&gt;PROVIDENCE, R.I. [Brown University] — Private equity firms acquired more than 500 autism therapy centers across the U.S. over the past decade, with nearly 80% of acquisitions occurring over a four-year span.&lt;/p&gt;
    &lt;p&gt;That’s according to a new study from researchers at Brown University’s Center for Advancing Health Policy through Research.&lt;/p&gt;
    &lt;p&gt;Study author Yashaswini Singh, a health economist at Brown’s School of Public Health, said the work highlights how financial firms are rapidly moving into a sensitive area of health care with little public scrutiny or data on where this is happening or why.&lt;/p&gt;
    &lt;p&gt;“The big takeaway is that there is yet another segment of health care that has emerged as potentially profitable to private equity investors, and it is very distinct from where we have traditionally known investors to go, so the potential for harm can be a lot more serious,” Singh said. “We're also dealing with children who are largely insured by Medicaid programs, so if private equity increases the intensity of care, what we're looking at are impacts to state Medicaid budgets down the road.”&lt;/p&gt;
    &lt;p&gt;The findings were published in JAMA Pediatrics and offer one of the first national assessments of private equity’s growing role in autism therapies and services. Autism diagnoses among U.S. children have risen sharply in recent years, nearly tripling between 2011 and 2022, and autism has been in the national spotlight amid political debate claiming links between autism and childhood vaccines.&lt;/p&gt;
    &lt;p&gt;The findings suggest that investment has been concentrated in states with higher rates of autism diagnoses among children and states that have fewer limits on insurance coverage.&lt;/p&gt;
    &lt;p&gt;The researchers identified a total of 574 autism therapy centers owned by private equity firms as of 2024, spanning 42 states. Most of those centers were acquired between 2018 and 2022, the result of 142 separate deals. The largest concentrations of centers were in California (97), Texas (81), Colorado (38), Illinois (36) and Florida (36). Sixteen states had one or no private equity-owned clinics at the end of 2024.&lt;/p&gt;
    &lt;p&gt;States in the top third for childhood autism prevalence were 24% more likely to have private equity–owned clinics than others, according to the study.&lt;/p&gt;
    &lt;p&gt;The scale and speed of acquisitions underscore the growing trend of private equity’s entry into the market, the researchers say. According to Singh, the team was prompted to investigate that trend after hearing anecdotal reports from families and health providers about changes following private equity takeovers.&lt;/p&gt;
    &lt;p&gt;The primary concern is that private equity firms may prioritize financial gains over families, said Daniel Arnold, a senior research scientist at the School of Public Health.&lt;/p&gt;
    &lt;p&gt;“It's all about the financial incentives,” Arnold said. “I worry about the same types of revenue-generating strategies seen in other private equity-backed settings. I worry about children receiving more than the clinically appropriate amount of services and worsening disparities in terms of which children have access to services.”&lt;/p&gt;
    &lt;p&gt;To establish a baseline of where private equity firms are investing and why, the team used a mix of proprietary databases, public press releases and manual verification of archived websites to track changes in ownership. Unlike public companies, private equity firms and private practices are not required to disclose acquisitions, making data collection challenging and labor-intensive.&lt;/p&gt;
    &lt;p&gt;The team is now seeking federal funding to examine how private equity ownership affects outcomes, including changes in therapy intensity, medication use, diagnosis age or how long children stay in treatment. They seek to determine whether these investments are helping to meet real needs or are primarily a way to make money.&lt;/p&gt;
    &lt;p&gt;“Private investors making a little bit of money while expanding access is not a bad thing, per se,” Singh said. “But we need to understand how much of a bad thing this is and how much of a good thing this is. This is a first step in that direction.”&lt;/p&gt;
    &lt;p&gt;This study received funding from the National Institute on Aging (R01AG073286) and the National Institute on Mental Health (R01MH132128).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.brown.edu/news/2026-01-07/private-equity-autism-centers"/><published>2026-01-10T23:36:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46571149</id><title>Show HN: Librario, a book metadata API that aggregates G Books, ISBNDB, and more</title><updated>2026-01-11T03:08:31.588113+00:00</updated><content>&lt;doc fingerprint="a75d0845719503f8"&gt;
  &lt;main&gt;
    &lt;div&gt;TLDR:&lt;p&gt; Librario is a book metadata API that aggregates data from Google Books, ISBNDB, and Hardcover into a single response, solving the problem of no single source having complete book information. It's currently pre-alpha, AGPL-licensed, and available to try now[0].&lt;/p&gt;&lt;p&gt;My wife and I have a personal library with around 1,800 books. I started working on a library management tool for us, but I quickly realized I needed a source of data for book information, and none of the solutions available provided all the data I needed. One might provide the series, the other might provide genres, and another might provide a good cover, but none provided everything.&lt;/p&gt;&lt;p&gt;So I started working on Librario, a book metadata aggregation API written in Go. It fetches information about books from multiple sources (Google Books, ISBNDB, Hardcover. Working on Goodreads and Anna's Archive next.), merges everything, and saves it all to a PostgreSQL database for future lookups. The idea is that the database gets stronger over time as more books are queried.&lt;/p&gt;&lt;p&gt;You can see an example response here[1], or try it yourself:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;  curl -s -H 'Authorization: Bearer librario_ARbmrp1fjBpDywzhvrQcByA4sZ9pn7D5HEk0kmS34eqRcaujyt0enCZ' \
  'https://api.librario.dev/v1/book/9781328879943' | jq .
  &lt;/code&gt;&lt;/quote&gt;&lt;p&gt; This is pre-alpha and runs on a small VPS, so keep that in mind. I never hit the limits in the third-party services, so depending on how this post goes, I’ll or will not find out if the code handles that well.&lt;/p&gt;&lt;p&gt;The merger is the heart of the service, and figuring out how to combine conflicting data from different sources was the hardest part. In the end I decided to use field-specific strategies which are quite naive, but work for now.&lt;/p&gt;&lt;p&gt;Each extractor has a priority, and results are sorted by that priority before merging. But priority alone isn't enough, so different fields need different treatment.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;p&gt;- Titles use a scoring system. I penalize titles containing parentheses or brackets because sources sometimes shove subtitles into the main title field. Overly long titles (80+ chars) also get penalized since they often contain edition information or other metadata that belongs elsewhere.&lt;/p&gt;&lt;p&gt;- Covers collect all candidate URLs, then a separate fetcher downloads and scores them by dimensions and quality. The best one gets stored locally and served from the server.&lt;/p&gt;&lt;p&gt;For most other fields (publisher, language, page count), I just take the first non-empty value by priority. Simple, but it works.&lt;/p&gt;&lt;p&gt;Recently added a caching layer[2] which sped things up nicely. I considered migrating from net/http to fiber at some point[3], but decided against it. Going outside the standard library felt wrong, and the migration didn't provide much in the end.&lt;/p&gt;&lt;p&gt;The database layer is being rewritten before v1.0[4]. I'll be honest: the original schema was written by AI, and while I tried to guide it in the right direction with SQLC[5] and good documentation, database design isn't my strong suit and I couldn't confidently vouch for the code. Rather than ship something I don't fully understand, I hired the developers from SourceHut[6] to rewrite it properly.&lt;/p&gt;&lt;p&gt;I've got a 5-month-old and we're still adjusting to their schedule, so development is slow. I've mentioned this project in a few HN threads before[7], so I’m pretty happy to finally have something people can try.&lt;/p&gt;&lt;p&gt;Code is AGPL and on SourceHut[8].&lt;/p&gt;&lt;p&gt;Feedback and patches[9] are very welcome :)&lt;/p&gt;&lt;p&gt;[0]: https://sr.ht/~pagina394/librario/&lt;/p&gt;&lt;p&gt;[1]: https://paste.sr.ht/~jamesponddotco/a6c3b1130133f384cffd25b3...&lt;/p&gt;&lt;p&gt;[2]: https://todo.sr.ht/~pagina394/librario/16&lt;/p&gt;&lt;p&gt;[3]: https://todo.sr.ht/~pagina394/librario/13&lt;/p&gt;&lt;p&gt;[4]: https://todo.sr.ht/~pagina394/librario/14&lt;/p&gt;&lt;p&gt;[5]: https://sqlc.dev&lt;/p&gt;&lt;p&gt;[6]: https://sourcehut.org/consultancy/&lt;/p&gt;&lt;p&gt;[7]: https://news.ycombinator.com/item?id=45419234&lt;/p&gt;&lt;p&gt;[8]: https://sr.ht/~pagina394/librario/&lt;/p&gt;&lt;p&gt;[9]: https://git.sr.ht/~pagina394/librario/tree/trunk/item/CONTRI...&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46571149"/><published>2026-01-10T23:45:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46571166</id><title>Show HN: GlyphLang – An AI-first programming language</title><updated>2026-01-11T03:08:31.160319+00:00</updated><content>&lt;doc fingerprint="97081aa9b2cbc8de"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;While working on a proof of concept project, I kept hitting Claude's token limit 30-60 minutes into their 5-hour sessions. The accumulating context from the codebase was eating through tokens fast. So I built a language designed to be generated by AI rather than written by humans.&lt;/p&gt;
      &lt;p&gt;GlyphLang&lt;/p&gt;
      &lt;p&gt;GlyphLang replaces verbose keywords with symbols that tokenize more efficiently:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;  # Python
  @app.route('/users/&amp;lt;id&amp;gt;')
  def get_user(id):
      user = db.query("SELECT * FROM users WHERE id = ?", id)
      return jsonify(user)

  # GlyphLang
  @ GET /users/:id {
    $ user = db.query("SELECT * FROM users WHERE id = ?", id)
    &amp;gt; user
  }

  @ = route, $ = variable, &amp;gt; = return. Initial benchmarks show ~45% fewer tokens than Python, ~63% fewer than Java.
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt; In practice, that means more logic fits in context, and sessions stretch longer before hitting limits. The AI maintains a broader view of your codebase throughout.&lt;/p&gt;
      &lt;p&gt;Before anyone asks: no, this isn't APL with extra steps. APL, Perl, and Forth are symbol-heavy but optimized for mathematical notation, human terseness, or machine efficiency. GlyphLang is specifically optimized for how modern LLMs tokenize. It's designed to be generated by AI and reviewed by humans, not the other way around. That said, it's still readable enough to be written or tweaked if the occasion requires.&lt;/p&gt;
      &lt;p&gt;It's still a work in progress, but it's a usable language with a bytecode compiler, JIT, LSP, VS Code extension, PostgreSQL, WebSockets, async/await, generics.&lt;/p&gt;
      &lt;p&gt;Docs: https://glyphlang.dev/docs&lt;/p&gt;
      &lt;p&gt;GitHub: https://github.com/GlyphLang/GlyphLang&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46571166"/><published>2026-01-10T23:46:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46571707</id><title>Bob Weir has died</title><updated>2026-01-11T03:08:30.853495+00:00</updated><content>&lt;doc fingerprint="6624d531dbe206ff"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Bob Weir, Grateful Dead Co-Founder and Guitarist, Dead at 78&lt;/head&gt;
    &lt;p&gt; Bob Weir, the singer, songwriter, guitarist and co-founder of the Grateful Dead, whose songs about sunshine daydreams and truckin’ helped turn the jam band into a 60-year musical empire, has died at age 78.&lt;lb/&gt;“It is with profound sadness that we share the passing of Bobby Weir,” Weir’s family wrote in a statement; a date of death was not immediately available. “He transitioned peacefully, surrounded by loved ones, after courageously beating cancer as only Bobby could. Unfortunately, he succumbed to underlying lung issues.”&lt;/p&gt;
    &lt;p&gt;“Bobby will forever be a guiding force whose unique artistry reshaped American music,” the statement added. “His work did more than fill rooms with music; it was warm sunlight that filled the soul, building a community, a language, and a feeling of family that generations of fans carry with them. Every chord he played, every word he sang was an integral part of the stories he wove. There was an invitation: to feel, to question, to wander, and to belong.”&lt;/p&gt;
    &lt;p&gt;As the band’s co-lead singer, writer, and guitarist beside Jerry Garcia, his elliptical riffs, eccentric song structures and slightly off-kilter stage presence made him an intrinsic ingredient to the Dead, up to and beyond its demise following Garcia’s death in 1995. Weir often went under-recognized compared to the larger-than-life Garcia (one of the first songs he wrote in the Dead was called “The Other One”). Yet, the band’s bassist Phil Lesh characterized Weir’s contribution as that of “a stealth machine.”&lt;/p&gt;
    &lt;p&gt;Robert Hall Weir was born in San Francisco on October 16, 1947, to a college student who gave him up for adoption. He was raised in an affluent Bay Area suburb, where he managed to get kicked out of both preschool and the Cub Scouts, and suffered from undiagnosed dyslexia. At Fountain Valley, a Colorado school for boys with behavioral problems, he met John Perry Barlow, who would become his most frequent lyricist.&lt;/p&gt;
    &lt;p&gt;Weir began playing guitar at thirteen and was soon hanging out at the Tangent, a Palo Alto folk club, where he performed bluegrass numbers with the Uncalled Four and first saw Jerry Garcia playing banjo during a “hoot” night. Weir picked up his first guitar licks from David Nelson and future Jefferson Airplane member Jorma Kaukonen.&lt;/p&gt;
    &lt;p&gt;On New Year’s Eve, 1965, Weir and his friends heard banjo music emerging from Dana Morgan’s Music Store. He went in and found Garcia, and the two decided to form a band. The acoustic Mother McCree’s Uptown Jug Champions evolved into the electric Warlocks, who changed their name to the Grateful Dead.&lt;/p&gt;
    &lt;p&gt;As the youngest and best-looking member of the Dead, Weir had to pay some dues. Too much LSD during the group’s stint as house band for Ken Kesey’s Acid Tests made Weir somewhat withdrawn, as Garcia and bassist Phil Lesh were entwining more deeply on a musical level. “I was definitely low man on the totem pole,” he told Rolling Stone in 1989, “especially at the beginning. And for a long time I had to just shut up and take it.”&lt;/p&gt;
    &lt;p&gt;The lyrics to “The Other One” described Weir’s introduction to both LSD and Neal Cassady, the trickster hero of Jack Kerouac’s beat-generation masterpiece On the Road, with whom Weir shared a room in the Dead’s infamous 710 Ashbury Street house. In 1968, Weir and fellow founding member Ron “Pigpen” McKernan were booted from the band for their musical deficiencies, though both returned within months.&lt;/p&gt;
    &lt;p&gt;Throughout the Seventies, Weir thrived as a member of a band that could deliver music of nearly ineffable warmth and country-rock majesty – as on their pair of 1970 masterpieces, Workingman’s Dead and American Beauty – while also playing more freely improvised music to more listeners than any band in history. Weir sang the band’s country covers and his own original material, and played rhythm guitar in a brilliantly eccentric manner that belied the job’s second-string implications – even while soundman Dan Healy was turning him down in the mix. Lesh described Weir’s technique as “quirky, whimsical and goofy,” while Weir claimed jazz pianist McCoy Tyner’s left hand as his greatest influence.&lt;/p&gt;
    &lt;p&gt;With Pigpen’s death in 1972, Weir stepped into the second-vocalist role smoothly. Ace, his first solo album, established him as the band’s second most fruitful songwriting source with solo songs-turned-Dead standards like “Playing in the Band,” “One More Saturday Night,” and “Cassidy.”&lt;/p&gt;
    &lt;p&gt;Usually alternating lead vocals with Garcia, he developed a repertoire that ranged from country-rock originals and rhythmically unorthodox tunes to his ambitious and gorgeous “Weather Report Suite.” He also began gigging outside the Dead with a vatiety of acts: First with Kingfish in 1974, then the guitarist formed the Bob Weir Band with keyboardist Brent Mydland – who later joined the Dead – in the late Seventies and would release two albums with Bobby and the Midnites in the Eighties. His second solo album, 1978’s Heaven Help the Fool, proved he could sound as slick as any other California rocker.&lt;/p&gt;
    &lt;p&gt;Over the course of the Eighties, Weir would have to compensate onstage as Garcia sank into drug addiction – and later admitted that he also sometimes served as “bag man” for the guitarist’s drugs. Garcia temporarily recovered toward the end of the decade, an era Weir lauded as the Dead’s finest era. “For me, that was our peak,” he told Rolling Stone in 2013. “We could hear and feel each other thinking, and we could intuit each other’s moves. Jerry, Brent, and I reached new plateaus as singers. We packed a punch.”&lt;/p&gt;
    &lt;p&gt;Though hit hard by Garcia’s August 1995 death, Weir continued to perform; as he famously sang in one Dead classic, “The Music Never Stopped.” His band RatDog played his Dead material and originals, and Weir eventually began singing Garcia’s own material in various 21st-century configurations of former Grateful Dead members, including the Other Ones, the Dead, and Furthur. After collapsing onstage with Furthur in 2013 and canceling RatDog performances in 2014, Weir admitted that he struggled with his own addiction to painkillers.&lt;/p&gt;
    &lt;p&gt;As the remaining Grateful Dead members approached their golden anniversary in 2015, Weir was the first to support a reunion, telling Rolling Stone, “If there are issues we have to get past, I think that we owe it to ourselves to man up and get past them. If there are hatchets to be buried, then let’s get to work. Let’s start digging.”&lt;/p&gt;
    &lt;p&gt;Following the surviving members’ Fare Thee Well concerts celebrating the Grateful Dead’s 50th anniversary in 2015, Weir enlisted one of the gig’s guests, John Mayer, to join him, Mickey Hart, Bill Kreutzmann and other Dead associates in the new offshoot Dead &amp;amp; Company. That group would keep the spirit of the Dead alive for another decade, culminating in a 2023 “Final Tour” and two stints at Las Vegas’ Sphere.&lt;/p&gt;
    &lt;p&gt;“We speak a language that nobody else speaks,” Weir told Rolling Stone in March 2025. “We communicate, we kick stuff back and forth, and then make our little statement in a more universal language. For us, it’s a look or a motion with one shoulder, or the way you reflect a phrase or something that tips off the other guys where you’re going with this. And then they work on being where you’re headed, getting there with a little surprise for you. That’s a formula that’s worked real well for us over the years, and there just aren’t enough of us left now to do that anymore.”&lt;/p&gt;
    &lt;p&gt;Weir’s third and final solo studio album, Blue Mountain, arrived in 2016. Two years later, the guitarist embarked on yet another musical project as Bobby Weir and Wolf Bros, alongside bassist/producer Don Was and drummer Jay Lane.&lt;/p&gt;
    &lt;p&gt;In December 2024, shortly after the October 2024 death of Dead bassist Phil Lesh, the Grateful Dead’s surviving members were recipients of the Kennedy Center honors. Dead &amp;amp; Company marked the Grateful Dead’s 60th anniversary with a three-night stand at San Francisco’s Golden Gate Park in August. Those concerts marked Weir’s final performances, ending his “long strange trip” onstage.&lt;/p&gt;
    &lt;p&gt;“Bobby’s final months reflected the same spirit that defined his life. Diagnosed in July, he began treatment only weeks before returning to his hometown stage for a three-night celebration of 60 years of music at Golden Gate Park. Those performances, emotional, soulful, and full of light, were not farewells, but gifts. Another act of resilience,” Weir’s family added in their statement.&lt;/p&gt;
    &lt;p&gt;“There is no final curtain here, not really. Only the sense of someone setting off again. He often spoke of a 300-year legacy, determined to ensure the songbook would endure long after him. May that dream live on through future generations of Dead Heads. And so we send him off the way he sent so many of us on our way: with a farewell that isn’t an ending, but a blessing. A reward for a life worth livin’.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.rollingstone.com/music/music-news/bob-weir-grateful-dead-dead-obituary-1234810106/"/><published>2026-01-11T01:04:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46571760</id><title>Kodbox: Open-source cloud desktop with multi-storage fusion and web IDE</title><updated>2026-01-11T03:08:30.406579+00:00</updated><content>&lt;doc fingerprint="3e13a8480ba7bb84"&gt;
  &lt;main&gt;
    &lt;p&gt;Home • Download • Doc • Changelog&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;kodbox is a file manager for web. It is also a web code editor, which allows you to develop websites directly within the web browser. Self-hosted file management system with muilt-cloud support. You can run kodbox either online or locally,on Linux, Windows or Mac based platforms. The only requirement is to have PHP 5 available.&lt;/p&gt;
      &lt;head&gt;Demo [user: demo/demo]&lt;/head&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 Private cloud disk/enterprise network disk like Windows experience&lt;/item&gt;
      &lt;item&gt;🌟 Full support for private deployment, secure and controllable storage&lt;/item&gt;
      &lt;item&gt;👁️🗨️ Online preview, editing and playback of hundreds of file formats, both office and entertainment&lt;/item&gt;
      &lt;item&gt;🚀 Multi-storage fusion: support local disk, ftp, webdav, Alibaba Cloud OSS, Tencent Cloud COS, Qiniu, minio, S3 compatible protocol, etc.&lt;/item&gt;
      &lt;item&gt;🔗 Easy sharing, efficient collaboration, fine-grained permission control&lt;/item&gt;
      &lt;item&gt;💻 Full platform client coverage, access anytime, anywhere, easy synchronization mounting; web, H5, iOS, Android, PC, webdav mounting&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;File operation: highly consistent operation experience with Windows, including new creation, copy, move, paste, upload, download, delete, decompress, open mode, file sorting, view, etc.&lt;/item&gt;
      &lt;item&gt;Document selection: box selection, drag and drop, shortcut keys, cloud document management is as familiar and efficient as local operation; file check, ctrl click, shift continuous selection, shortcut key selection (ctrl/shift+a/up/down/left/right/home/end...), first letter quick positioning, pinyin fuzzy search quick filtering...&lt;/item&gt;
      &lt;item&gt;Global drag and drop: drag and drop files and folders to move and copy; drag and drop local files/folders to upload; drag and drop to the desktop to automatically download; drag and drop to the folder to automatically enter, drag and drop multiple file management windows to each other...&lt;/item&gt;
      &lt;item&gt;Efficient shortcut keys: ctrl+c to copy, ctrl+x to cut, ctrl+v to paste, ctrl+z to undo, f2 to rename, ctrl+shift+z to undo, file view switching...&lt;/item&gt;
      &lt;item&gt;Right-click menu: folders, files, and different types of files have fully adaptive right-click menus&lt;/item&gt;
      &lt;item&gt;File viewing mode: It combines the strengths of Windows and Mac, supports "icon mode/list mode/column mode" file management, icon mode supports custom icon size, and list mode folders support tree directory expansion; automatically records the viewing mode of each folder; uses virtual lists to quickly and efficiently manage a large number of file folders.&lt;/item&gt;
      &lt;item&gt;Multi-dimensional document management: Favorites; document tags; file classification; recent documents; albums; recycle bin; department document public tags; personal file private safe...;&lt;/item&gt;
      &lt;item&gt;Convenient property panel: All kinds of document attribute information, sharing status, picture exif information, music and video and other types of file information are clear at a glance; folders contain file folder quantity, size statistics, set notes, edit lock/top; can discuss file folders;&lt;/item&gt;
      &lt;item&gt;File history version: Files are edited and saved online, and history versions are automatically generated, so there is no need to worry about content loss;&lt;/item&gt;
      &lt;item&gt;File deduplication/second transfer: Using COW mechanism, file metadata records double hash authentication, automatic full deduplication, when uploading, files that already exist will be automatically transferred in seconds, saving storage space and improving upload efficiency; Folder movement and copying are completed quickly;&lt;/item&gt;
      &lt;item&gt;Advanced search: Supports filtering or searching by type, file size, last modified time and other dimensions, supports Chinese pinyin pinyin initial letter search, supports document tag, note search; supports batch search of multiple file names, and presents search results in the order of search&lt;/item&gt;
      &lt;item&gt;Document dynamics: All operation changes of file folders are clear at a glance, and the entire life cycle of the document is tracked;&lt;/item&gt;
      &lt;item&gt;Online decompression: Supports online decompression of zip, tar, gz, 7z, rar and other files, supports quick creation of compressed packages for folders, and supports online preview of compressed packages&lt;/item&gt;
      &lt;item&gt;File online preview: Anytime, anywhere, hundreds of common format documents can be easily viewed with a browser, without downloading to the local computer or installing software on the terminal; multimedia such as pictures, music, and videos; online preview and editing of Office documents; PDF, OFD, XPS and other version documents; online preview and editing of PhotoShop and Illustrator; AutoCAD engineering drawings&lt;/item&gt;
      &lt;item&gt;Text editor: Provide powerful online text file editing function; support 120 code language highlighting; adaptive text encoding, say goodbye to file garbled; multiple tags support; support js/json/php/css and other language methods for quick viewing and file formatting; html files support real-time and safe preview; support fragment loading, easy online opening of large files; support hex mode, convenient viewing of binary files;&lt;/item&gt;
      &lt;item&gt;markdown editing: The editor provides powerful and complete markdown editing function, supports real-time preview; shortcut key support; supports inserting formulas, flowcharts, sequence diagrams, uml diagrams, supports prompt references, supports html syntax; supports image relative path references; supports direct pasting of images copied from the clipboard; link jumps support other md files with relative paths;&lt;/item&gt;
      &lt;item&gt;Flowchart/Mind Map: Draw Visio flowcharts and mind maps online and quickly share them with others;&lt;/item&gt;
      &lt;item&gt;Fine-grained permission control: department files, folders, each file can set different permissions for different people or groups, thousands of faces;&lt;/item&gt;
      &lt;item&gt;External link sharing: Share files (folders) with customers or external partners with one click, support setting access passwords, validity periods and multiple permissions; recipients can easily preview documents in multiple formats through links; when editing is enabled, recipients can edit, upload and collaborate on office files online; folders support default settings for document mode, convenient publishing of user manuals, development documents, etc.;&lt;/item&gt;
      &lt;item&gt;Internal collaboration: You can initiate collaboration and grant different permissions to members, departments, or any combination within the system.&lt;/item&gt;
      &lt;item&gt;Collaboration Enhancement: Provides department labels, document discussions, file dynamics, historical versions, editing locks and other components to gather the work results of multiple people.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Login Control: Login device control, double verification, login IP filtering, login verification code, complex password policy, anti-brute force cracking; scan code login (App scan code to log in to the web terminal; scan the logged in web terminal to log in to the App)&lt;/item&gt;
      &lt;item&gt;Permission Control: Role permissions, department permissions, fine-grained document permissions, sharing control, content/authorization approval, multi-level administrators&lt;/item&gt;
      &lt;item&gt;Behavior Audit: Login log, operation log, sharing content control, dynamic security watermark, sensitive word filtering, file confidentiality management, system recycle bin&lt;/item&gt;
      &lt;item&gt;Data Security: Data backup, system restore, multi-cloud fusion storage, csrf protection, cluster deployment support&lt;/item&gt;
      &lt;item&gt;Multi-storage Fusion: Local disk, ftp, webdav, Alibaba Cloud OSS, Tencent Cloud COS, Qiniu, minio, S3 and other multi-cloud fusion mounting, easy to handle cross-cloud file management, backup transmission, elastic expansion&lt;/item&gt;
      &lt;item&gt;Plug-in Center: AD domain/enterprise WeChat/DingTalk and other 30+ enterprise-level application plug-ins can be freely expanded; file format editing and preview can be easily expanded; open plug-in development documents, enterprises can flexibly expand functions in the form of plug-ins according to needs; provide SDK to seamlessly embed the cloud file capabilities of enterprises into ERP, OA, mailbox and other IT systems&lt;/item&gt;
      &lt;item&gt;App: Android, iOS full-end support; automatic album backup;&lt;/item&gt;
      &lt;item&gt;PC client: Windows, Mac versions support; support folder backup to the cloud; automatically mount to local disk, no-feel operation, local experience; support calling PC software to preview and edit online files&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Install from source
git clone https://github.com/kalcaddle/kodbox.git
chmod -Rf 777 ./kodbox/*

# Install via download
wget https://github.com/kalcaddle/kodbox/archive/refs/heads/main.zip
unzip main.zip
chmod -Rf 777 ./*
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Suggest server: php8.1+mysql5.7+redis;&lt;/item&gt;
      &lt;item&gt;Upload speed and other configuration optimization: http://doc.kodcloud.com/v2/#/help/options&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;location / {
  if ( !-e $request_filename){
      rewrite ^[^index\.php](.*)$ /index.php?$1 last;
  }
}
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Server: &lt;list rend="ul"&gt;&lt;item&gt;Windows,Linux,Mac ...&lt;/item&gt;&lt;item&gt;PHP 5.3+&lt;/item&gt;&lt;item&gt;Database: sqlite;mysql;...&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Browser compatibility: &lt;list rend="ul"&gt;&lt;item&gt;Chrome&lt;/item&gt;&lt;item&gt;Firefox&lt;/item&gt;&lt;item&gt;Opera&lt;/item&gt;&lt;item&gt;IE9+&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;Tips: It can also run on a router, or your home NAS&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;kodcloud is issued under GPLv3. license.License&lt;lb/&gt; Contact: kalcaddle#qq.com&lt;lb/&gt; Copyright (C) 2013 kodcloud.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/kalcaddle/kodbox"/><published>2026-01-11T01:12:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46571980</id><title>Show HN: Ferrite – Markdown editor in Rust with native Mermaid diagram rendering</title><updated>2026-01-11T03:08:29.941803+00:00</updated><content>&lt;doc fingerprint="2704389f7bb0d98e"&gt;
  &lt;main&gt;
    &lt;p&gt;A fast, lightweight text editor for Markdown, JSON, YAML, and TOML files. Built with Rust and egui for a native, responsive experience.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Platform Note: Ferrite has been primarily developed and tested on Windows. While it should work on Linux and macOS, these platforms have not been extensively tested. If you encounter issues, please report them.&lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Raw Editor&lt;/cell&gt;
        &lt;cell role="head"&gt;Rendered View&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Split View&lt;/cell&gt;
        &lt;cell role="head"&gt;Zen Mode&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WYSIWYG Markdown Editing - Edit markdown with live preview, click-to-edit formatting, and syntax highlighting&lt;/item&gt;
      &lt;item&gt;Multi-Format Support - Native support for Markdown, JSON, YAML, and TOML files&lt;/item&gt;
      &lt;item&gt;Tree Viewer - Hierarchical view for JSON/YAML/TOML with inline editing, expand/collapse, and path copying&lt;/item&gt;
      &lt;item&gt;Find &amp;amp; Replace - Search with regex support and match highlighting&lt;/item&gt;
      &lt;item&gt;Undo/Redo - Full undo/redo support per tab&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Split View - Side-by-side raw editor and rendered preview with resizable divider&lt;/item&gt;
      &lt;item&gt;Zen Mode - Distraction-free writing with centered text column&lt;/item&gt;
      &lt;item&gt;Sync Scrolling - Bidirectional scroll sync between raw and rendered views&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syntax Highlighting - Full-file syntax highlighting for 40+ languages (Rust, Python, JavaScript, Go, etc.)&lt;/item&gt;
      &lt;item&gt;Code Folding - Fold detection with gutter indicators (▶/▼) for headings, code blocks, and lists (text hiding deferred to v0.3.0)&lt;/item&gt;
      &lt;item&gt;Minimap - VS Code-style navigation panel with click-to-jump and search highlights&lt;/item&gt;
      &lt;item&gt;Bracket Matching - Highlight matching brackets &lt;code&gt;()[]{}&amp;lt;&amp;gt;&lt;/code&gt;and emphasis pairs&lt;code&gt;**&lt;/code&gt;&lt;code&gt;__&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Auto-Save - Configurable auto-save with temp-file safety&lt;/item&gt;
      &lt;item&gt;Line Numbers - Optional line number gutter&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Native rendering of 11 diagram types directly in the preview:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Flowchart, Sequence, Pie, State, Mindmap&lt;/item&gt;
      &lt;item&gt;Class, ER, Git Graph, Gantt, Timeline, User Journey&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;p&gt;✨ v0.2.1 Released: Enhanced Mermaid support with sequence control-flow blocks (&lt;/p&gt;&lt;code&gt;loop&lt;/code&gt;,&lt;code&gt;alt&lt;/code&gt;,&lt;code&gt;opt&lt;/code&gt;,&lt;code&gt;par&lt;/code&gt;), activation boxes, notes, flowchart subgraphs with branching layout, and composite/nested states. See CHANGELOG.md for full details.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Workspace Mode - Open folders with file tree, quick switcher (Ctrl+P), and search-in-files (Ctrl+Shift+F)&lt;/item&gt;
      &lt;item&gt;Git Integration - Visual status indicators showing modified, added, untracked, and ignored files&lt;/item&gt;
      &lt;item&gt;Session Persistence - Restore open tabs, cursor positions, and scroll offsets on restart&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Light &amp;amp; Dark Themes - Beautiful themes with runtime switching&lt;/item&gt;
      &lt;item&gt;Document Outline - Navigate large documents with the outline panel&lt;/item&gt;
      &lt;item&gt;Export Options - Export to HTML with themed styling, or copy as HTML&lt;/item&gt;
      &lt;item&gt;Formatting Toolbar - Quick access to bold, italic, headings, lists, links, and more&lt;/item&gt;
      &lt;item&gt;Live Pipeline - Pipe JSON/YAML content through shell commands (for developers)&lt;/item&gt;
      &lt;item&gt;Custom Window - Borderless window with custom title bar and resize handles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Download the latest release for your platform from GitHub Releases.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Download&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ferrite-windows-x64.zip&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;ferrite-editor_amd64.deb&lt;/code&gt; (recommended) or &lt;code&gt;ferrite-linux-x64.tar.gz&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ferrite-macos-x64.tar.gz&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Using .deb package (Debian/Ubuntu/Mint - Recommended):&lt;/p&gt;
    &lt;code&gt;# Download the .deb file, then install with:
sudo apt install ./ferrite-editor_amd64.deb

# Or using dpkg:
sudo dpkg -i ferrite-editor_amd64.deb&lt;/code&gt;
    &lt;p&gt;This will:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install Ferrite to &lt;code&gt;/usr/bin/ferrite&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Add desktop entry (appears in your app menu)&lt;/item&gt;
      &lt;item&gt;Register file associations for &lt;code&gt;.md&lt;/code&gt;,&lt;code&gt;.json&lt;/code&gt;,&lt;code&gt;.yaml&lt;/code&gt;,&lt;code&gt;.toml&lt;/code&gt;files&lt;/item&gt;
      &lt;item&gt;Install icons for the system&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Using tar.gz (any Linux distro):&lt;/p&gt;
    &lt;code&gt;tar -xzf ferrite-linux-x64.tar.gz
./ferrite&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rust 1.70+ - Install from rustup.rs&lt;/item&gt;
      &lt;item&gt;Platform-specific dependencies:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Windows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Visual Studio Build Tools 2019+ with C++ workload&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Linux:&lt;/p&gt;
    &lt;code&gt;# Ubuntu/Debian
sudo apt install build-essential pkg-config libgtk-3-dev libxcb-shape0-dev libxcb-xfixes0-dev

# Fedora
sudo dnf install gcc pkg-config gtk3-devel libxcb-devel

# Arch
sudo pacman -S base-devel pkg-config gtk3 libxcb&lt;/code&gt;
    &lt;p&gt;macOS:&lt;/p&gt;
    &lt;code&gt;xcode-select --install&lt;/code&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/OlaProeis/Ferrite.git
cd Ferrite

# Build release version (optimized)
cargo build --release

# The binary will be at:
# Windows: target/release/ferrite.exe
# Linux/macOS: target/release/ferrite&lt;/code&gt;
    &lt;code&gt;# Run from source
cargo run --release

# Or run the binary directly
./target/release/ferrite

# Open a specific file
./target/release/ferrite path/to/file.md

# Open a folder as workspace
./target/release/ferrite path/to/folder/&lt;/code&gt;
    &lt;p&gt;Ferrite supports three view modes for Markdown files:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Raw - Plain text editing with syntax highlighting&lt;/item&gt;
      &lt;item&gt;Rendered - WYSIWYG editing with rendered markdown&lt;/item&gt;
      &lt;item&gt;Split - Side-by-side raw editor and live preview&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Toggle between modes using the toolbar buttons or keyboard shortcuts.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+N&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;New file&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+O&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open file&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+S&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Save file&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+S&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Save as&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+W&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Close tab&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Tab&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Next tab&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+Tab&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Previous tab&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Quick file switcher (workspace)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+F&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Search in files (workspace)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Z&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Undo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;Ctrl+Y&lt;/code&gt; / &lt;code&gt;Ctrl+Shift+Z&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Redo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+F&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+H&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find and replace&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+B&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bold&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+I&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Italic&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+K&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Insert link&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Shortcut&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;F11&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle fullscreen&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+,&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open settings&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+[&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fold all&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+Shift+]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Unfold all&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Settings are stored in platform-specific locations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Windows: &lt;code&gt;%APPDATA%\ferrite\&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Linux: &lt;code&gt;~/.config/ferrite/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;macOS: &lt;code&gt;~/Library/Application Support/ferrite/&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Workspace settings are stored in &lt;code&gt;.ferrite/&lt;/code&gt; within the workspace folder.&lt;/p&gt;
    &lt;p&gt;Access settings via &lt;code&gt;Ctrl+,&lt;/code&gt; or the gear icon. Configure:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Appearance: Theme, font family, font size&lt;/item&gt;
      &lt;item&gt;Editor: Word wrap, line numbers, minimap, bracket matching, code folding, syntax highlighting&lt;/item&gt;
      &lt;item&gt;Files: Auto-save, recent files history&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See ROADMAP.md for planned features and known issues.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Please see CONTRIBUTING.md for guidelines.&lt;/p&gt;
    &lt;code&gt;# Fork and clone
git clone https://github.com/YOUR_USERNAME/Ferrite.git
cd Ferrite

# Create a feature branch
git checkout -b feature/your-feature

# Make changes, then verify
cargo fmt
cargo clippy
cargo test
cargo build

# Commit and push
git commit -m "feat: your feature description"
git push origin feature/your-feature&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Technology&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Language&lt;/cell&gt;
        &lt;cell&gt;Rust 1.70+&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GUI Framework&lt;/cell&gt;
        &lt;cell&gt;egui 0.28 + eframe 0.28&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Markdown Parser&lt;/cell&gt;
        &lt;cell&gt;comrak 0.22&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Syntax Highlighting&lt;/cell&gt;
        &lt;cell&gt;syntect 5.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Git Integration&lt;/cell&gt;
        &lt;cell&gt;git2 0.19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;File Dialogs&lt;/cell&gt;
        &lt;cell&gt;rfd 0.14&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Clipboard&lt;/cell&gt;
        &lt;cell&gt;arboard 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;File Watching&lt;/cell&gt;
        &lt;cell&gt;notify 6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Fuzzy Matching&lt;/cell&gt;
        &lt;cell&gt;fuzzy-matcher 0.3&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/OlaProeis/Ferrite"/><published>2026-01-11T01:50:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46572060</id><title>A Year of Work on the Arch Linux Package Management (ALPM) Project</title><updated>2026-01-11T03:08:28.730783+00:00</updated><content>&lt;doc fingerprint="7c1005be86720b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A year of work on the ALPM project&lt;/head&gt;
    &lt;p&gt;In 2024 the Sovereign Tech Fund (STF) started funding work on the ALPM project, which provides a Rust-based framework for Arch Linux Package Management. Refer to the project's FAQ and mission statement to learn more about the relation to the tooling currently in use on Arch Linux.&lt;/p&gt;
    &lt;p&gt;The funding has now concluded, but over the time of 15 months allowed us to create various tools and integrations that we will highlight in the following sections.&lt;/p&gt;
    &lt;p&gt;We have worked on six milestones with focus on various aspects of the package management ecosystem, ranging from formalizing, parsing and writing of file formats, over cryptographic verification of distribution artifacts, to package file and system package management handling:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Formal specifications for packaging data formats"&lt;/item&gt;
      &lt;item&gt;"Basic OpenPGP verification of artifacts"&lt;/item&gt;
      &lt;item&gt;"Rust library for handling of individual packages"&lt;/item&gt;
      &lt;item&gt;"Python bindings for alpm-srcinfo"&lt;/item&gt;
      &lt;item&gt;"Distribution-agnostic OpenPGP stack for the verification of distribution artifacts"&lt;/item&gt;
      &lt;item&gt;"Rust library for system package management"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We are considering ourselves as part of a larger free software ecosystem. We believe that it makes sense to create value not only for our own niche, but for the greater good. As such, we focused on finding generic solutions to the technological problems we are facing as a distribution.&lt;/p&gt;
    &lt;p&gt;We are incredibly grateful for the support from STF without which this type of extensive ground work would not have been possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;ALPM stats 📊&lt;/head&gt;
    &lt;p&gt;A lot of work has been done over the time of the STF funding. Below are a few statistics about the work done on the ALPM project.&lt;/p&gt;
    &lt;code&gt;$ git shortlog --after="2024-10-01" --summary --numbered
   467  David Runge
   252  Arne Beer
   173  Orhun Parmaksız
   117  Jagoda Ślązak
    54  renovate
    16  Laura Demkowicz-Duffy
    14  David Schaefer
    10  Christian Heusel
     5  Heiko Schaefer
     4  Morgan Adamiec
     1  Adam Perkowski
     1  Daniel Maslowski
     1  Dominik Peteler
     1  Jakub Klinkovský
     1  Rafael Epplée
&lt;/code&gt;
    &lt;code&gt;$ tokei
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 Language          Files       Lines        Code    Comments      Blanks
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 BASH                  1          37          21          10           6
 C                     2           9           8           0           1
 C Header              1           2           1           0           1
 CSS                   4        2310        1704         175         431
 FreeMarker           22         922         557           0         365
 JavaScript           16         952         728         104         120
 JSON                  3        1108        1108           0           0
 Just                  3        1444        1072         153         219
 Meson                 1           4           4           0           0
 Python               31        6041        4871          70        1100
 Sass                  1          88          46          30          12
 SVG                  26          26          26           0           0
 Plain Text            4         770           0         615         155
 TOML                 32        1309        1089          81         139
 XML                   2          27          27           0           0
 YAML                  1        1053         798           0         255
─────────────────────────────────────────────────────────────────────────
 HTML                 35        1544        1459          34          51
 |- CSS                1           6           6           0           0
 |- JavaScript         5          41          36           2           3
 (Total)                        1591        1501          36          54
─────────────────────────────────────────────────────────────────────────
 Markdown             95       10253           0        7000        3253
 |- BASH              20        1052         929          40          83
 |- HTML               1          15          10           3           2
 |- INI               10         348         335           5           8
 |- JSON               1          34          34           0           0
 |- Rust              12         769         655          41          73
 |- Shell              2           5           5           0           0
 |- TOML               1         423         197         166          60
 |- YAML               1          17          17           0           0
 (Total)                       12916        2182        7255        3479
─────────────────────────────────────────────────────────────────────────
 Rust                271       46298       38583        1700        6015
 |- Markdown         235       15360         142       11744        3474
 (Total)                       61658       38725       13444        9489
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 Total               551       92267       54468       21973       15826
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
&lt;/code&gt;
    &lt;head rend="h2"&gt;Specifications 📝&lt;/head&gt;
    &lt;p&gt;Already in July we reported on the state of the specifications on the devblog and how they enable a deeper, shared view onto our current package management stack in Arch Linux.&lt;/p&gt;
    &lt;p&gt;A lot of custom file formats are in use in our ecosystem. Understanding how to use them is key to maintaining existing and envisioning new technology.&lt;/p&gt;
    &lt;p&gt;Interested developers and package maintainers are encouraged to browse them by file formats or concepts. Meanwhile, the alpm(7) specification provides a good high-level entry-point to the entire topic.&lt;/p&gt;
    &lt;p&gt;We hope this empowers a much larger group of contributors to participate in discussions about the concepts behind Arch Linux's package management. Additionally, we want to enable interested developers to participate in hacking both on the ALPM project itself, as well as make it much easier to experiment with new applications that are built on top of it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Foundational libraries 📚️&lt;/head&gt;
    &lt;p&gt;In the ALPM project we chose a bottom-up, library first approach, in which libraries for basic tasks have been created iteratively in a workspace. As more libraries for specific use-cases emerge, it becomes possible to build more elaborate or special purpose tools with them.&lt;/p&gt;
    &lt;p&gt;We invite interested Rust developers to have a look at the dedicated API documentation to gain a better understanding and overview of the available libraries and their dependencies.&lt;/p&gt;
    &lt;p&gt;The central alpm-types library provides shared low-level types, which are used in some or all file formats used by the Arch Linux package management stack. These common types make it easy to build other, interoperable libraries on top of it.&lt;/p&gt;
    &lt;p&gt;In alpm-common, central traits and utility functionality are made available to other libraries in the workspace.&lt;/p&gt;
    &lt;p&gt;After some consideration and research, we chose the winnow parser combinator library to create parsers for the various custom file formats. Shared functionality for parsers is made available in the alpm-parsers library.&lt;/p&gt;
    &lt;p&gt;Package management systems usually revolve around central dependency resolver functionality. With alpm-solve we have created a new approach to this for Arch Linux, which is based on the generic resolvo library.&lt;/p&gt;
    &lt;p&gt;Compression is an integral part of the packaging workflow. It ensures that an alpm-package(7) or alpm-repo-db(7) file can be transferred over the network as fast as possible by reducing its size. With the alpm-compress library we have implemented extensible (de)compression for these files.&lt;/p&gt;
    &lt;p&gt;To allow extraction of metadata and data files from an alpm-package(7) file, as well as (rudimentary) package creation, we have created the alpm-package crate. With it, it is possible to create package files from prepared input directories (which already contain relevant metadata and data files). In addition, it is possible to effortlessly iterate over the data files contained in a package file and to extract validated metadata.&lt;/p&gt;
    &lt;p&gt;The creation process of an alpm-package(7) file requires to add root-owned files to a directory (e.g. as part of the installation process of an upstream project's build system). However, one does not want to run the package build process as root, but as an unprivileged user. For this purpose we have created the rootless-run library, which generically abstracts running commands "as root" with the help of different backends (e.g. &lt;code&gt;fakeroot(1)&lt;/code&gt; and &lt;code&gt;rootlesskit&lt;/code&gt;).&lt;/p&gt;
    &lt;head rend="h2"&gt;Libraries and command line interfaces 💻️&lt;/head&gt;
    &lt;p&gt;Based on specifications of file formats currently used in Arch Linux, we have created libraries that allow their parsing, validation and writing.&lt;/p&gt;
    &lt;p&gt;Notably, we distinguish between:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;File formats used in an alpm-source-repo(7) (i.e. SRCINFO(5), PKGBUILD(5)),&lt;/item&gt;
      &lt;item&gt;those in an alpm-repo-db(7) (i.e. alpm-repo-desc(5) and alpm-repo-files(5)),&lt;/item&gt;
      &lt;item&gt;those in an alpm-db(7) (i.e. ALPM-MTREE(5), alpm-db-desc(5) and alpm-db-files(5)) and&lt;/item&gt;
      &lt;item&gt;those in an alpm-package(7) (i.e. ALPM-MTREE(5), BUILDINFO(5) and PKGINFO(5)).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The alpm-srcinfo crate provides a library and command line interface for the parsing, validation and creation of SRCINFO(5) files from PKGBUILD(5) scripts. Due to the dynamic nature of the PKGBUILD(5) scripts, the SRCINFO(5) format is surprisingly complex (both to create and to evaluate). The creation of SRCINFO(5) files from PKGBUILD(5) scripts is enabled via the alpm-pkgbuild-bridge project, the alpm-pkgbuild crate and a translation layer in alpm-srcinfo. We have created dedicated documentation for the aspects of parsing and providing its data from different contexts.&lt;/p&gt;
    &lt;p&gt;The alpm-buildinfo crate provides a library and command line interface for the parsing, validation and creation of BUILDINFO(5) files. This file format is contained in an alpm-package(7) and describes its build environment. In the context of reproducible builds it is used to recreate the build environment.&lt;/p&gt;
    &lt;p&gt;The alpm-mtree crate provides a library and command line interface that allows parsing, validation and creation of ALPM-MTREE(5) files. This file format is a subset of the mtree(5) file format, provided by libarchive. As it can be considered more of a meta language than a data format, we rely on &lt;code&gt;bsdtar(1)&lt;/code&gt; to write that file format.
An ALPM-MTREE(5) file is contained in an alpm-package(7), as well as an entry of an alpm-db(7) and represents a record of all files contained in the package during package creation time.
After installing a package to a system, this file can be used to verify ownership and mode of files installed by the package and detect any missing files.&lt;/p&gt;
    &lt;p&gt;The alpm-pkginfo crate offers a library and command line interface for the parsing, validation and creation of PKGINFO(5) files. This file format is contained in an alpm-package(7) and describes all relevant metadata of a package (e.g. alpm-package-relation(7), alpm-package-name(7), alpm-package-version(7)).&lt;/p&gt;
    &lt;p&gt;Each system based on alpm(7) maintains its state using an alpm-db(7). This state encompasses information on each package:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the contained files (see alpm-db-files(5))&lt;/item&gt;
      &lt;item&gt;general metadata (see alpm-db-desc(5))&lt;/item&gt;
      &lt;item&gt;a record that can be used to validate files of a package (see ALPM-MTREE(5))&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the alpm-db crate, it is possible to parse, validate and create the alpm-db-desc(5) and alpm-db-files(5) file formats. Additionally, we have worked on database access for the alpm-db(7) structure following the ACID characteristics.&lt;/p&gt;
    &lt;p&gt;Packages for compiled languages (e.g. C or C++) usually contain files in the Executable and Linkable Format (ELF). These files may expose soname information which may be used as alpm-package-relation(7) (see alpm-sonamev1(7) and alpm-sonamev2(7) for the two currently understood formats). With the alpm-soname crate we have focused on the handling and extraction of information for the more modern alpm-sonamev2(7) format as well as plain soname information. As a library and CLI, this crate offers easy access to this ELF data, which plays an important role in figuring out the run-time dependencies of packages.&lt;/p&gt;
    &lt;p&gt;Each alpm-repo(7) contains a set of alpm-package(7) files, digital signatures and a package repository database (see alpm-repo-db(7)). An alpm-repo-db(7) tracks information on particular, unique packages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;the contained files (see alpm-repo-files(5))&lt;/item&gt;
      &lt;item&gt;general metadata (see alpm-repo-desc(5))&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Using the alpm-repo-db crate, it is possible to parse, validate and write alpm-repo-desc(5) and alpm-repo-files(5) files. This crate provides both a library and CLI tool. In the future, it will be extended to allow the creation, reading and writing of alpm-repo-db(7) files.&lt;/p&gt;
    &lt;head rend="h2"&gt;Development integration 👷&lt;/head&gt;
    &lt;p&gt;To test integration of our libraries against real world data, we have created the dev-scripts crate. It lives in the context of the ALPM project, and is intended as development testbed for assumptions of the various libraries. As such, the crate does not get any releases.&lt;/p&gt;
    &lt;p&gt;The test integration makes it easy to download and prepare live data:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;package source repositories (official and all of the AUR)&lt;/item&gt;
      &lt;item&gt;official binary package repositories&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Currently, it is possible to verify&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SRCINFO(5) files in package source repositories of the official repositories and all of the AUR&lt;/item&gt;
      &lt;item&gt;ALPM-MTREE(5), BUILDINFO(5) and PKGINFO(5) files in binary packages in the official repositories&lt;/item&gt;
      &lt;item&gt;the OpenPGP signatures of all packages in the official repositories&lt;/item&gt;
      &lt;item&gt;alpm-db-desc(5) and alpm-db-files(5) files in the entries of a local alpm-db&lt;/item&gt;
      &lt;item&gt;alpm-repo-desc(5) and alpm-repo-files(5) files in the entries of the alpm-repo-db(7) files of the official repositories&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Python bindings 🐍&lt;/head&gt;
    &lt;p&gt;To make our modern Rust-based parsers and verified types available for use from in other languages used by the distribution, we provide Python bindings.&lt;/p&gt;
    &lt;p&gt;Arch Linux's largest Python-based project, with arguably also the largest user-base, is the AURweb, which powers the Arch User Repository (AUR). The web application deals with user input, e.g. via SRCINFO(5) files and currently relies on the native Python library python-srcinfo.&lt;/p&gt;
    &lt;p&gt;(As a sidenote: If you are a Python developer and interested in helping maintain a FastAPI based web application, please reach out to the project! We are always looking for further contributors and maintainers!)&lt;/p&gt;
    &lt;p&gt;The Python bindings for the ALPM project are available on PyPI as python-alpm. With them, we have focused on providing SRCINFO(5) support by relying on the alpm-srcinfo library and by proxy expose a lot of types from the alpm-types library as well.&lt;/p&gt;
    &lt;p&gt;The integration of the python-alpm library into the AURweb application is currently prepared (see aurweb!876).&lt;/p&gt;
    &lt;p&gt;If you are a Python developer and have specific needs for the integration of other libraries of the ALPM project, we would love to hear from you!&lt;/p&gt;
    &lt;head rend="h2"&gt;Linting 🧶&lt;/head&gt;
    &lt;p&gt;Linters are tools that shift some tedious responsibilities (e.g. quality control) from humans to automation. They are used to automatically detect common mistakes and deviations from established best practices. The goal of linting is to support humans in performing a task well, keeping them on a level with changes in best practices, and empowering them to produce better quality results with less manual effort.&lt;/p&gt;
    &lt;p&gt;The usability and robustness of a distribution like Arch Linux currently relies heavily on the diligence of its package maintainers. Only if package maintainers make an effort to stay up to date with recent developments in packaging (e.g. best practices for languages or PKGBUILD(5) scripts) can the resulting package files maintain a high quality standard.&lt;/p&gt;
    &lt;p&gt;Relying on the written specifications, foundational libraries, as well as libraries and command line interfaces we decided to create a framework for lints, that centrally exposes its knowledge database and allows to flexibly create new rules for various purposes. As such, another central goal of this framework is to provide a single, central tool that covers all aspects of Arch Linux package management.&lt;/p&gt;
    &lt;p&gt;With the alpm-lint crate, a central library and command line interface has been created, that thoroughly documents its architecture and how to add new lint rules. A custom, central website provides details about all currently existing lints, derived from the code documentation of the lint rules: https://alpm.archlinux.page/lints/&lt;/p&gt;
    &lt;p&gt;Using the &lt;code&gt;alpm-lint(1)&lt;/code&gt; CLI, package maintainers are enabled to validate various scopes relevant to packaging (e.g. contents of an alpm-source-repo(7) or an alpm-package(7) file).&lt;/p&gt;
    &lt;p&gt;The crate currently only offers a small set of lints and we encourage interested package maintainers with a background in Rust to write further lints.&lt;/p&gt;
    &lt;head rend="h2"&gt;Translations 🌐&lt;/head&gt;
    &lt;p&gt;We are targeting the English language as first language for the project, but many people that are exposed to its error handling and command line interfaces are not native English speakers, or do not speak the language at all. While writing libraries and command line interfaces for various purposes in the context of the ALPM project we realized that we needed to improve the translation (aka. internationalization or i18n) story of the project.&lt;/p&gt;
    &lt;p&gt;After some research on current technologies used for software translation, we have settled on the fluent framework and created a convenient integration for our purposes with the custom fluent-i18n crate.&lt;/p&gt;
    &lt;p&gt;Interested users can now start translating the project on weblate, following our dedicated contributing guidelines on localizations and translations: https://hosted.weblate.org/projects/alpm/&lt;/p&gt;
    &lt;head rend="h2"&gt;VOA 🔏&lt;/head&gt;
    &lt;p&gt;Arch Linux uses OpenPGP for the verification of its packages.&lt;/p&gt;
    &lt;p&gt;The current OpenPGP integration hinges on a central GnuPG-based keyring. This solution suffers from several shortcomings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The keyring is context-independent. It is not possible to represent different verification contexts with it, e.g. package repository metadata that is signed with a different set of keys than those used for signing packages, or packages in unofficial repositories are signed by a different set of keys than those used for the official repositories.&lt;/item&gt;
      &lt;item&gt;The keyring and its behavior is specific to the GnuPG tool, and in part unspecified. The setup cannot be reliably used with other OpenPGP implementations.&lt;/item&gt;
      &lt;item&gt;The keyring is stateful, and while its contents are populated by data from the package for archlinux-keyring, the entire mechanism requires a root-run agent service.&lt;/item&gt;
      &lt;item&gt;The GnuPG upstream has denounced the IETF-driven OpenPGP standardization process and has subsequently been removed from other major package management software such as &lt;code&gt;apt(8)&lt;/code&gt;and&lt;code&gt;rpm(8)&lt;/code&gt;over the last three years. Compatibility with other OpenPGP implementations is no longer guaranteed (see e.g. the ArchWiki article on GnuPG for details)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Already before 2024, the idea emerged to verify digital signatures not with a stateful keyring mechanism, but to instead use a stateless directory structure containing verifiers (see keyringctl#3).&lt;/p&gt;
    &lt;p&gt;This idea was discussed with a set of cross-distribution developers during Image-based Linux Summit 2024 and extended from the initial idea of a lookup directory only for OpenPGP to a more general, technology-agnostic mechanism.&lt;/p&gt;
    &lt;p&gt;In a nutshell, we set out to create a directory structure containing e.g. OpenPGP certificates, SSH pubkeys or X.509 certificates, which clearly describes in what context such verifiers are used when verifying artifacts of a distribution. A more in-depth discussion and rundown of the topic can be found in the talk "Verification of OS artifacts without stateful keyrings" from All Systems Go! 2025.&lt;/p&gt;
    &lt;head rend="h3"&gt;UAPI specification ✍️&lt;/head&gt;
    &lt;p&gt;In late 2024 we started work on a specification to describe this new, technology-agnostic signature verification mechanism and to collect input from relevant stakeholders in several of the more complex technologies that we wanted to cover.&lt;/p&gt;
    &lt;p&gt;The initial version of the specification "File Hierarchy for the Verification of OS Artifacts (VOA)" has been made available in June 2025 and covers the integration of OpenPGP as a first technology backend.&lt;/p&gt;
    &lt;p&gt;Further technology backend specifications are available as drafts, but need more work to iron out open questions. If you have expertise with the use of SSH, X.509, minisign or signify for the signing of artifacts and have an interest in working on a Rust codebase, please reach out and help stabilize these additional backends!&lt;/p&gt;
    &lt;head rend="h3"&gt;VOA reference implementation ⌨️&lt;/head&gt;
    &lt;p&gt;In July 2025 we started work on the VOA project, as a reference implementation of the UAPI specification.&lt;/p&gt;
    &lt;p&gt;Here are some statistics about the project:&lt;/p&gt;
    &lt;code&gt;$ git shortlog --summary --numbered
   190  David Runge
    17  Heiko Schaefer
     3  renovate
     2  David Schaefer
&lt;/code&gt;
    &lt;code&gt;$ tokei
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 Language          Files       Lines        Code    Comments      Blanks
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 JSON                  1          16          16           0           0
 Just                  1         849         580         109         160
 Plain Text            4         770           0         615         155
 TOML                 12         364         309          14          41
 YAML                  5         110         110           0           0
─────────────────────────────────────────────────────────────────────────
 Markdown             15        1340           0         847         493
 |- BASH               2         133          30         101           2
 |- Rust               4         200         156          18          26
 |- Shell              1           3           3           0           0
 |- YAML               1          94          94           0           0
 (Total)                        1770         283         966         521
─────────────────────────────────────────────────────────────────────────
 Rust                 70       13685       11301         478        1906
 |- Markdown          69        2832          29        2229         574
 (Total)                       16517       11330        2707        2480
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 Total               108       20396       12628        4411        3357
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
&lt;/code&gt;
    &lt;p&gt;Central handling of the VOA hierarchy is implemented in the technology-independent voa-core library. It serves as an abstraction to access verifiers from the filesystem.&lt;/p&gt;
    &lt;p&gt;The use of OpenPGP-specific verifiers has been implemented in the voa-openpgp library. It handles artifact verification based on several different methods:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"plain": Artifacts are verified directly with artifact verifiers, without additional trust anchors. Artifact verifiers can be filtered using OpenPGP fingerprints or domain name matches for OpenPGP User IDs.&lt;/item&gt;
      &lt;item&gt;simple "trust anchor": Artifacts are verified using artifact verifiers, which in turn must be certified by trust anchors. Artifact verifiers can be filtered using domain name matches for OpenPGP User IDs and trust anchors can be filtered using OpenPGP fingerprints. Additionally, the number of required individual certifications for User IDs on each artifact verifier can be specified.&lt;/item&gt;
      &lt;item&gt;"Web of Trust": Artifacts are verified using artifact verifiers, which must reach a sufficient level of trust according to an OpenPGP "Web of Trust" implementation. Artifact verifiers can be filtered using domain name matches for OpenPGP User IDs and trust anchors can be filtered using OpenPGP fingerprints. Additionally, the target trust amount, the trust amount of trusted introducers and the trust amount of filtered trust anchors can be set to a custom value.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Orthogonal to the trust models outlined above, it is possible to specify the required number of independent and valid OpenPGP data signatures per artifact.&lt;/p&gt;
    &lt;p&gt;On Arch Linux we are currently using the Web of Trust implementation that GnuPG offers, on the basis of a GnuPG-specific keyring. However, for all intents and purposes, we are not making use of the features that the full "Web of Trust" model provides. Apart from basic temporal OpenPGP semantics and cryptographic validity, the following rules apply in archlinux-keyring:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There is a set of three or more certificates that serve as trust anchors.&lt;/item&gt;
      &lt;item&gt;There is a set of packager certificates that each must have an OpenPGP User ID with an email that uses the "archlinux.org" domain and has three or more third-party certifications from trust anchors.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So in practice, Arch Linux relies on a "Web of Trust" with exactly one level of indirection, and manually curated sets of trust anchors and artifact verifiers. With voa-openpgp, Arch's verification requirements are best modeled with the simple “trust anchor” model.&lt;/p&gt;
    &lt;p&gt;As an additional feature, we have implemented the import of OpenPGP certificates as verifiers into VOA hierarchies from different sources. The import supports OpenPGP certificates split into OpenPGP packets and the custom directory structure used by archlinux-keyring.&lt;/p&gt;
    &lt;p&gt;With the voa-config library we have added support for a central configuration file format with which settings for VOA technology backends can be supplied. The file format (see voa(5)) allows flexible overrides that specify custom rules for any type of context in an OS.&lt;/p&gt;
    &lt;p&gt;The following configuration describes the current policy for the Arch Linux distribution (see arch.yaml):&lt;/p&gt;
    &lt;code&gt;default_technology_settings:
  openpgp:
    num_data_signatures: 1
    verification_method:
      trust_anchor:
        required_certifications: 3
        artifact_verifier_identity_domain_matches:
          - archlinux.org
        trust_anchor_fingerprint_matches:
          # Levente Polyak (Arch Linux Master Key) &amp;lt;anthraxx@master-key.archlinux.org&amp;gt;
          - d8afdda07a5b6edfa7d8ccdad6d055f927843f1c
          # Leonidas Spyropoulos (Arch Linux Master Key) &amp;lt;artafinde@master-key.archlinux.org&amp;gt;
          - 3572fa2a1b067f22c58af155f8b821b42a6fdcd7
          # Johannes Löthberg (Arch Linux Master Key) &amp;lt;demize@master-key.archlinux.org&amp;gt;
          - 69e6471e3ae065297529832e6ba0f5a2037f4f41
          # David Runge (Arch Linux Master Key) &amp;lt;dvzrv@master-key.archlinux.org&amp;gt;
          - 2ac0a42efb0b5cbc7a0402ed4dc95b6d7be9892e
          # Florian Pritz (Arch Linux Master Key) &amp;lt;florian@master-key.archlinux.org&amp;gt;
          - 91ffe0700e80619ceb73235ca88e23e377514e00
&lt;/code&gt;
    &lt;head rend="h3"&gt;VOA high-level API and CLI 🖥️&lt;/head&gt;
    &lt;p&gt;In the voa crate we provide a high-level API for consumers of VOA and a command line interface.&lt;/p&gt;
    &lt;p&gt;With &lt;code&gt;voa(1)&lt;/code&gt;, it is possible to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inspect technology backend configuration settings.&lt;/item&gt;
      &lt;item&gt;Import OpenPGP certificates as VOA verifiers.&lt;/item&gt;
      &lt;item&gt;List all VOA verifiers (by OS or specific context).&lt;/item&gt;
      &lt;item&gt;Verify a file using a detached OpenPGP signature and suitable VOA verifiers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All subcommands support JSON output.&lt;/p&gt;
    &lt;p&gt;The following example illustrates the semantics of the default VOA technology backend settings for Arch Linux as shown in the previous section:&lt;/p&gt;
    &lt;code&gt;$ voa config show arch
OpenPGP settings

🔏 Each artifact requires 1 valid data signature(s) from artifact verifiers to be successfully verified.

✅ Each artifact is verified using the "trust anchor" verification method.

📧 A valid certificate must have a valid User ID that uses one of the following domains and has 3 certification(s) from individual trust anchors on it for the certificate to be considered as artifact verifier:
⤷ archlinux.org

🐾 A valid certificate must match one of the following OpenPGP fingerprints to be considered as trust anchor:
⤷ 2ac0a42efb0b5cbc7a0402ed4dc95b6d7be9892e
⤷ 3572fa2a1b067f22c58af155f8b821b42a6fdcd7
⤷ 69e6471e3ae065297529832e6ba0f5a2037f4f41
⤷ 91ffe0700e80619ceb73235ca88e23e377514e00
⤷ d8afdda07a5b6edfa7d8ccdad6d055f927843f1c

📝 The following sources have been considered for the creation of the settings:
⤷ Config file: /usr/share/voa/arch.yaml
⤷ Built-in defaults
&lt;/code&gt;
    &lt;p&gt;After installing the voa-verifiers-arch package, which provides the VOA verifiers used by Arch Linux, it is possible to verify Arch Linux artifacts (e.g. package files) using &lt;code&gt;voa(1)&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;$ voa verify arch package default openpgp /var/cache/pacman/pkg/shadow-4.18.0-1-x86_64.pkg.tar.zst{,.sig}
✅ /var/cache/pacman/pkg/shadow-4.18.0-1-x86_64.pkg.tar.zst.sig 1751009927 991f6e3f0765cf6295888586139b09da5bf0d338 62cc73f884e52957b2fdd8839b7a287d9a2ec608
&lt;/code&gt;
    &lt;head rend="h3"&gt;Web of Trust and the Berblom algorithm 🕸️&lt;/head&gt;
    &lt;p&gt;The generalized "Web of Trust" model remains an interesting option in the OpenPGP domain. The "Web of Trust" enables more complex and more nuanced setups than the basic "trust anchor" mode. It also allows for fully decentralized management of trust, without relying on any single authority.&lt;/p&gt;
    &lt;p&gt;Over the course of 2024 and 2025, research has gone into comparing different "Web of Trust" implementations (see wot-observatory). The existing (legacy) implementations have surprising limitations and/or defects when it comes to the calculation of trust. This research led us to the conclusion that instead of relying on existing implementations and designs, a new approach was warranted to overcome the limitations of existing "Web of Trust" subsystems.&lt;/p&gt;
    &lt;p&gt;Our design is highly modular and centers around a pathfinding algorithm named "Berblom". Berblom is a novel and well-documented approach, which serves as a robust, general and efficient way of calculating the trust amount for an artifact verifier.&lt;/p&gt;
    &lt;p&gt;We are excited to integrate Berblom into the VOA reference implementation in 2026.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future work 🚀&lt;/head&gt;
    &lt;p&gt;We believe the ALPM project succeeded in the goals it set for itself in the funding period with Sovereign Tech Fund.&lt;/p&gt;
    &lt;p&gt;While a lot of foundational documentation and central libraries have been written, there is still more work ahead.&lt;/p&gt;
    &lt;head rend="h3"&gt;More lints 🧶🧶&lt;/head&gt;
    &lt;p&gt;The new lint framework provided by alpm-lint currently only features few lints.&lt;/p&gt;
    &lt;p&gt;Going forward, we want to extend this list in the dedicated "Lints" milestone and encourage anyone with Rust experience and an interest in packaging to help with this.&lt;/p&gt;
    &lt;p&gt;In addition to implementing lint rules, we want to explore the inclusion of the &lt;code&gt;alpm-lint(1)&lt;/code&gt; CLI in the canonical package build tooling for Arch Linux.&lt;/p&gt;
    &lt;head rend="h3"&gt;C-API 🇨&lt;/head&gt;
    &lt;p&gt;Our original project plan included potentially emulating the libalpm C-API in the scope of the contracting work. However, during the last months we realized, that for many consumers it would be more useful to rely on the finer grained libraries of the ALPM project directly instead. In addition, not all relevant database handling features are fully implemented yet, which would limit the usefulness of a C wrapper library.&lt;/p&gt;
    &lt;p&gt;In the medium term, it is certainly possible for interested developers to create an emulation of the libalpm C library based on ALPM. Reach out in case you are interested in something like this!&lt;/p&gt;
    &lt;head rend="h3"&gt;Repository database handling 📦️&lt;/head&gt;
    &lt;p&gt;In the alpm-repo-db crate we have added support for the data files in use in an alpm-repo-db(7).&lt;/p&gt;
    &lt;p&gt;Going forward, we want to add full handling of the database format: Creation, reading and compression of alpm-repo-db(7) files and the addition, update and removal of entries.&lt;/p&gt;
    &lt;head rend="h3"&gt;Add libkrun support to rootless-run 🏃➡️&lt;/head&gt;
    &lt;p&gt;Both &lt;code&gt;fakeroot(1)&lt;/code&gt; and &lt;code&gt;rootlesskit&lt;/code&gt; have their place in certain contexts, but they each also have their weaknesses (e.g. &lt;code&gt;fakeroot(1)&lt;/code&gt; does not provide isolation, &lt;code&gt;rootlesskit&lt;/code&gt; does not work in a containerized context).&lt;/p&gt;
    &lt;p&gt;Going forward, we want to explore adding libkrun support to rootless-run to accommodate stronger isolation on the basis of KVM.&lt;/p&gt;
    &lt;head rend="h3"&gt;Downloading of artifacts ⏬️&lt;/head&gt;
    &lt;p&gt;The alpm-package and alpm-repo-db crates provide integration for handling local package and repository database files.&lt;/p&gt;
    &lt;p&gt;In a package management workflow these are usually downloaded from an alpm-repo(7). We want to provide support for securely downloading these artifacts over the network.&lt;/p&gt;
    &lt;head rend="h3"&gt;Verification of artifacts 🔏&lt;/head&gt;
    &lt;p&gt;VOA provides a distribution- and technology-agnostic specification for artifact verification.&lt;/p&gt;
    &lt;p&gt;Using the voa project reference implementation, we want to add OpenPGP based verification for alpm-package(7) and alpm-repo-db(7) files.&lt;/p&gt;
    &lt;head rend="h3"&gt;More VOA technology backends 🔐&lt;/head&gt;
    &lt;p&gt;With the technology backend for OpenPGP in place, we have ironed out the generic handling of verifiers in the voa reference implementation.&lt;/p&gt;
    &lt;p&gt;Interested parties have already worked on a proof of concept for an x.509 technology backend and provided a ticket for the inclusion of signify as technology backend (see voa#24).&lt;/p&gt;
    &lt;p&gt;If you are interested in helping with the specification and implementation of more technology backends, please reach out!&lt;/p&gt;
    &lt;head rend="h3"&gt;Extend Python bindings 🐍🐍&lt;/head&gt;
    &lt;p&gt;We are very happy with the current feature set of python-alpm. Going forward, we want to extend the API for the Python bindings further to cover even more use-cases of interested projects, such as archinstall.&lt;/p&gt;
    &lt;p&gt;If you enjoy hacking on the intersection of Rust and Python, feel free to reach out! We would be excited to collaborate with any interested contributors.&lt;/p&gt;
    &lt;head rend="h3"&gt;More applications ⌨️&lt;/head&gt;
    &lt;p&gt;The new set of ALPM project libraries enables building robust tools. Users of the libraries can rely on a strongly typed, memory safe language 🦀&lt;/p&gt;
    &lt;p&gt;This empowers developers to build new special purpose package management applications with much greater ease. We look forward to building such applications ourselves, as well as seeing other parties building them.&lt;/p&gt;
    &lt;p&gt;Ultimately, user-facing improvements are our goal, and we think the foundation that we laid over the past year is fertile ground for innovation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://devblog.archlinux.page/2026/a-year-of-work-on-the-alpm-project/"/><published>2026-01-11T02:08:14+00:00</published></entry></feed>