<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-10T21:11:52.250206+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46214693</id><title>Revisiting "Let's Build a Compiler"</title><updated>2025-12-10T21:12:05.951480+00:00</updated><content>&lt;doc fingerprint="b101145b7036df98"&gt;
  &lt;main&gt;
    &lt;p&gt;There's an old compiler-building tutorial that has become part of the field's lore: the Let's Build a Compiler series by Jack Crenshaw (published between 1988 and 1995).&lt;/p&gt;
    &lt;p&gt;I ran into it in 2003 and was very impressed, but it's now 2025 and this tutorial is still being mentioned quite often in Hacker News threads. Why is that? Why does a tutorial from 35 years ago, built in Pascal and emitting Motorola 68000 assembly - technologies that are virtually unknown for the new generation of programmers - hold sway over compiler enthusiasts? I've decided to find out.&lt;/p&gt;
    &lt;p&gt;The tutorial is easily available and readable online, but just re-reading it seemed insufficient. So I've decided on meticulously translating the compilers built in it to Python and emit a more modern target - WebAssembly. It was an enjoyable process and I want to share the outcome and some insights gained along the way.&lt;/p&gt;
    &lt;p&gt;The result is this code repository. Of particular interest is the TUTORIAL.md file, which describes how each part in the original tutorial is mapped to my code. So if you want to read the original tutorial but play with code you can actually easily try on your own, feel free to follow my path.&lt;/p&gt;
    &lt;head rend="h2"&gt;A sample&lt;/head&gt;
    &lt;p&gt;To get a taste of the input language being compiled and the output my compiler generates, here's a sample program in the KISS language designed by Jack Crenshaw:&lt;/p&gt;
    &lt;code&gt;var X=0

 { sum from 0 to n-1 inclusive, and add to result }
 procedure addseq(n, ref result)
     var i, sum  { 0 initialized }
     while i &amp;lt; n
         sum = sum + i
         i = i + 1
     end
     result = result + sum
 end

 program testprog
 begin
     addseq(11, X)
 end
 .
&lt;/code&gt;
    &lt;p&gt;It's from part 13 of the tutorial, so it showcases procedures along with control constructs like the while loop, and passing parameters both by value and by reference. Here's the WASM text generated by my compiler for part 13:&lt;/p&gt;
    &lt;code&gt;(module
  (memory 8)
  ;; Linear stack pointer. Used to pass parameters by ref.
  ;; Grows downwards (towards lower addresses).
  (global $__sp (mut i32) (i32.const 65536))

  (global $X (mut i32) (i32.const 0))

  (func $ADDSEQ (param $N i32) (param $RESULT i32)
    (local $I i32)
    (local $SUM i32)
    loop $loop1
      block $breakloop1
        local.get $I
        local.get $N
        i32.lt_s
        i32.eqz
        br_if $breakloop1
        local.get $SUM
        local.get $I
        i32.add
        local.set $SUM
        local.get $I
        i32.const 1
        i32.add
        local.set $I
        br $loop1
      end
    end
    local.get $RESULT
    local.get $RESULT
    i32.load
    local.get $SUM
    i32.add
    i32.store
  )

  (func $main (export "main") (result i32)
    i32.const 11
    global.get $__sp      ;; make space on stack
    i32.const 4
    i32.sub
    global.set $__sp
    global.get $__sp
    global.get $X
    i32.store
    global.get $__sp    ;; push address as parameter
    call $ADDSEQ
    ;; restore parameter X by ref
    global.get $__sp
    i32.load offset=0
    global.set $X
    ;; clean up stack for ref parameters
    global.get $__sp
    i32.const 4
    i32.add
    global.set $__sp
    global.get $X
  )
)
&lt;/code&gt;
    &lt;p&gt;You'll notice that there is some trickiness in the emitted code w.r.t. handling the by-reference parameter (my previous post deals with this issue in more detail). In general, though, the emitted code is inefficient - there is close to 0 optimization applied.&lt;/p&gt;
    &lt;p&gt;Also, if you're very diligent you'll notice something odd about the global variable X - it seems to be implicitly returned by the generated main function. This is just a testing facility that makes my compiler easy to test. All the compilers are extensively tested - usually by running the generated WASM code [1] and verifying expected results.&lt;/p&gt;
    &lt;head rend="h2"&gt;Insights - what makes this tutorial so special?&lt;/head&gt;
    &lt;p&gt;While reading the original tutorial again, I had on opportunity to reminisce on what makes it so effective. Other than the very fluent and conversational writing style of Jack Crenshaw, I think it's a combination of two key factors:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The tutorial builds a recursive-descent parser step by step, rather than giving a long preface on automata and table-based parser generators. When I first encountered it (in 2003), it was taken for granted that if you want to write a parser then lex + yacc are the way to go [2]. Following the development of a simple and clean hand-written parser was a revelation that wholly changed my approach to the subject; subsequently, hand-written recursive-descent parsers have been my go-to approach for almost 20 years now.&lt;/item&gt;
      &lt;item&gt;Rather than getting stuck in front-end minutiae, the tutorial goes straight to generating working assembly code, from very early on. This was also a breath of fresh air for engineers who grew up with more traditional courses where you spend 90% of the time on parsing, type checking and other semantic analysis and often run entirely out of steam by the time code generation is taught.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To be honest, I don't think either of these are a big problem with modern resources, but back in the day the tutorial clearly hit the right nerve with many people.&lt;/p&gt;
    &lt;head rend="h2"&gt;What else does it teach us?&lt;/head&gt;
    &lt;p&gt;Jack Crenshaw's tutorial takes the syntax-directed translation approach, where code is emitted while parsing, without having to divide the compiler into explicit phases with IRs. As I said above, this is a fantastic approach for getting started, but in the latter parts of the tutorial it starts showing its limitations. Especially once we get to types, it becomes painfully obvious that it would be very nice if we knew the types of expressions before we generate code for them.&lt;/p&gt;
    &lt;p&gt;I don't know if this is implicated in Jack Crenshaw's abandoning the tutorial at some point after part 14, but it may very well be. He keeps writing how the emitted code is clearly sub-optimal [3] and can be improved, but IMHO it's just not that easy to improve using the syntax-directed translation strategy. With perfect hindsight vision, I would probably use Part 14 (types) as a turning point - emitting some kind of AST from the parser and then doing simple type checking and analysis on that AST prior to generating code from it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;All in all, the original tutorial remains a wonderfully readable introduction to building compilers. This post and the GitHub repository it describes are a modest contribution that aims to improve the experience of folks reading the original tutorial today and not willing to use obsolete technologies. As always, let me know if you run into any issues or have questions!&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;This is done using the Python bindings to wasmtime.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;By the way, gcc switched from YACC to hand-written recursive-descent parsing in the 2004-2006 timeframe, and Clang has been implemented with a recursive-descent parser from the start (2007).&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Concretely: when we compile subexpr1 + subexpr2 and the two sides have different types, it would be mighty nice to know that before we actually generate the code for both sub-expressions. But the syntax-directed translation approach just doesn't work that way.&lt;/p&gt;
          &lt;p&gt;To be clear: it's easy to generate working code; it's just not easy to generate optimal code without some sort of type analysis that's done before code is actually generated.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/"/><published>2025-12-10T06:22:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46216583</id><title>Factor 0.101 now available</title><updated>2025-12-10T21:12:05.548596+00:00</updated><content>&lt;doc fingerprint="748063284d11bc94"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Factor 0.101 now available&lt;/head&gt;
    &lt;p&gt;Monday, December 8, 2025&lt;/p&gt;
    &lt;p&gt;“Keep thy airspeed up, lest the earth come from below and smite thee.” - William Kershner&lt;/p&gt;
    &lt;p&gt;I’m very pleased to announce the release of Factor 0.101!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;OS/CPU&lt;/cell&gt;
        &lt;cell role="head"&gt;Windows&lt;/cell&gt;
        &lt;cell role="head"&gt;Mac OS&lt;/cell&gt;
        &lt;cell role="head"&gt;Linux&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;x86&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;x86-64&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
        &lt;cell&gt;0.101&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Source code: 0.101&lt;/p&gt;
    &lt;p&gt;This release is brought to you with almost 700 commits by the following individuals:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Aleksander Sabak, Andy Kluger, Cat Stevens, Dmitry Matveyev, Doug Coleman, Giftpflanze, John Benediktsson, Jon Harper, Jonas Bernouli, Leo Mehraban, Mike Stevenson, Nicholas Chandoke, Niklas Larsson, Rebecca Kelly, Samuel Tardieu, Stefan Schmiedl, @Bruno-366, @bobisageek, @coltsingleactionarmyocelot, @inivekin, @knottio, @timor&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Besides some bug fixes and library improvements, I want to highlight the following changes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Moved the UI to render buttons and scrollbars rather than using images, which allows easier theming.&lt;/item&gt;
      &lt;item&gt;Fixed HiDPI scaling on Linux and Windows, although it currently doesn’t update the window settings when switching between screens with different scaling factors.&lt;/item&gt;
      &lt;item&gt;Update to Unicode 17.0.0.&lt;/item&gt;
      &lt;item&gt;Plugin support for the Neovim editor.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Some possible backwards compatibility issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The argument order to &lt;code&gt;ltake&lt;/code&gt;was swapped to be more consistent with words like&lt;code&gt;head&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;environment&lt;/code&gt;vocabulary on Windows now supports disambiguating&lt;code&gt;f&lt;/code&gt;and&lt;code&gt;""&lt;/code&gt;(empty) values&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/atom&lt;/code&gt;folder was removed in favor of the factor/atom-language-factor repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/Factor.tmbundle&lt;/code&gt;folder was removed in favor of the factor/factor.tmbundle repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;misc/vim&lt;/code&gt;folder was removed in favor of the factor/factor.vim repo.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;http&lt;/code&gt;vocabulary&lt;code&gt;request&lt;/code&gt;tuple had a slot rename from&lt;code&gt;post-data&lt;/code&gt;to&lt;code&gt;data&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;furnace.asides&lt;/code&gt;vocabulary had a slot rename from&lt;code&gt;post-data&lt;/code&gt;to&lt;code&gt;data&lt;/code&gt;, and might require running&lt;code&gt;ALTER TABLE asides RENAME COLUMN "post-data" TO data;&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;html.streams&lt;/code&gt;vocabulary was renamed to&lt;code&gt;io.streams.html&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;pdf.streams&lt;/code&gt;vocabulary was renamed to&lt;code&gt;io.streams.pdf&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;What is Factor&lt;/head&gt;
    &lt;p&gt;Factor is a concatenative, stack-based programming language with high-level features including dynamic types, extensible syntax, macros, and garbage collection. On a practical side, Factor has a full-featured library, supports many different platforms, and has been extensively documented.&lt;/p&gt;
    &lt;p&gt;The implementation is fully compiled for performance, while still supporting interactive development. Factor applications are portable between all common platforms. Factor can deploy stand-alone applications on all platforms. Full source code for the Factor project is available under a BSD license.&lt;/p&gt;
    &lt;head rend="h3"&gt;New libraries:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;base92: adding support for Base92 encoding/decoding&lt;/item&gt;
      &lt;item&gt;bitcask: implementing the Bitcask key/value database&lt;/item&gt;
      &lt;item&gt;bluesky: adding support for the BlueSky protocol&lt;/item&gt;
      &lt;item&gt;calendar.holidays.world: adding some new holidays including World Emoji Day&lt;/item&gt;
      &lt;item&gt;classes.enumeration: adding enumeration classes and new &lt;code&gt;ENUMERATION:&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;colors.oklab: adding support for OKLAB color space&lt;/item&gt;
      &lt;item&gt;colors.oklch: adding support for OKLCH color space&lt;/item&gt;
      &lt;item&gt;colors.wavelength: adding &lt;code&gt;wavelength&amp;gt;rgba&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;combinators.syntax: adding experimental combinator syntax words &lt;code&gt;@[&lt;/code&gt;,&lt;code&gt;*[&lt;/code&gt;, and&lt;code&gt;&amp;amp;[&lt;/code&gt;, and short-circuiting&lt;code&gt;n&amp;amp;&amp;amp;[&lt;/code&gt;,&lt;code&gt;n||[&lt;/code&gt;,&lt;code&gt;&amp;amp;&amp;amp;[&lt;/code&gt;and&lt;code&gt;||[&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;continuations.extras: adding &lt;code&gt;with-datastacks&lt;/code&gt;and&lt;code&gt;datastack-states&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;dotenv: implementing support for Dotenv files&lt;/item&gt;
      &lt;item&gt;edn: implementing support for Extensible Data Notation&lt;/item&gt;
      &lt;item&gt;editors.cursor: adding support for the Cursor editor&lt;/item&gt;
      &lt;item&gt;editors.rider: adding support for the JetBrains Rider editor&lt;/item&gt;
      &lt;item&gt;gitignore: parser for &lt;code&gt;.gitignore&lt;/code&gt;files&lt;/item&gt;
      &lt;item&gt;http.json: promoted &lt;code&gt;json.http&lt;/code&gt;and added some useful words&lt;/item&gt;
      &lt;item&gt;io.streams.farkup: a Farkup formatted stream protocol&lt;/item&gt;
      &lt;item&gt;io.streams.markdowns: a Markdown formatted stream protocol&lt;/item&gt;
      &lt;item&gt;locals.lazy: prototype of emit syntax&lt;/item&gt;
      &lt;item&gt;monadics: alternative vocabulary for using Haskell-style monads, applicatives, and functors&lt;/item&gt;
      &lt;item&gt;multibase: implementation of Multibase&lt;/item&gt;
      &lt;item&gt;pickle: support for the Pickle serialization format&lt;/item&gt;
      &lt;item&gt;persistent.hashtables.identity: support an identity-hashcode version of persisent hashtables&lt;/item&gt;
      &lt;item&gt;raylib.live-coding: demo of a vocabulary to do “live coding” of Raylib programs&lt;/item&gt;
      &lt;item&gt;rdap: support for the Registration Data Access Protocol&lt;/item&gt;
      &lt;item&gt;reverse: implementation of the std::flip&lt;/item&gt;
      &lt;item&gt;slides.cli: simple text-based command-line interface for slides&lt;/item&gt;
      &lt;item&gt;tools.highlight: command-line syntax-highlighting tool&lt;/item&gt;
      &lt;item&gt;tools.random: command-line random generator tool&lt;/item&gt;
      &lt;item&gt;ui.pens.rounded: adding rounded corner pen&lt;/item&gt;
      &lt;item&gt;ui.pens.theme: experimental themed pen&lt;/item&gt;
      &lt;item&gt;ui.tools.theme: some words for updating UI developer tools themes&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Improved libraries:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;alien.syntax: added &lt;code&gt;C-LIBRARY:&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;assocs.extras: added &lt;code&gt;nzip&lt;/code&gt;and&lt;code&gt;nunzip&lt;/code&gt;,&lt;code&gt;map-zip&lt;/code&gt;and&lt;code&gt;map-unzip&lt;/code&gt;macros&lt;/item&gt;
      &lt;item&gt;base32: adding the human-oriented Base32 encoding via &lt;code&gt;zbase32&amp;gt;&lt;/code&gt;and&lt;code&gt;&amp;gt;zbase32&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;base64: minor performance improvement&lt;/item&gt;
      &lt;item&gt;benchmark: adding more benchmarks&lt;/item&gt;
      &lt;item&gt;bootstrap.assembler: fixes for ARM-64&lt;/item&gt;
      &lt;item&gt;brainfuck: added &lt;code&gt;BRAINFUCK:&lt;/code&gt;syntax word and&lt;code&gt;interpret-brainfuck&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;bson: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;cache: implement &lt;code&gt;M\ cache-assoc delete-at&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;calendar: adding &lt;code&gt;year&amp;lt;&lt;/code&gt;,&lt;code&gt;year&amp;lt;=&lt;/code&gt;,&lt;code&gt;year&amp;gt;&lt;/code&gt;,&lt;code&gt;year&amp;gt;=&lt;/code&gt;words&lt;/item&gt;
      &lt;item&gt;calendar.format: parse human-readable and elapsed-time output back into duration objects&lt;/item&gt;
      &lt;item&gt;cbor: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;classes.mixin: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;classes.singleton: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;classes.tuple: added &lt;code&gt;tuple&amp;gt;slots&lt;/code&gt;, rename&lt;code&gt;tuple&amp;gt;array&lt;/code&gt;to&lt;code&gt;pack-tuple&lt;/code&gt;and&lt;code&gt;&amp;gt;tuple&lt;/code&gt;to&lt;code&gt;unpack-tuple&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;classes.union: added &lt;code&gt;definer&lt;/code&gt;implementation&lt;/item&gt;
      &lt;item&gt;checksums.sha: some 20-40% performance improvements&lt;/item&gt;
      &lt;item&gt;command-line: allow passing script name of &lt;code&gt;-&lt;/code&gt;to use stdin&lt;/item&gt;
      &lt;item&gt;command-line.parser: support for Argument Parser Commands&lt;/item&gt;
      &lt;item&gt;command-line.startup: document &lt;code&gt;-q&lt;/code&gt;quiet mode flag&lt;/item&gt;
      &lt;item&gt;concurrency.combinators: faster &lt;code&gt;parallel-map&lt;/code&gt;and&lt;code&gt;parallel-assoc-map&lt;/code&gt;using a count-down latch&lt;/item&gt;
      &lt;item&gt;concurrency.promises: 5-7% performance improvement&lt;/item&gt;
      &lt;item&gt;continuations: improve docs and fix stack effect for &lt;code&gt;ifcc&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;countries: adding &lt;code&gt;CQ&lt;/code&gt;country code for Sark&lt;/item&gt;
      &lt;item&gt;cpu.architecture: fix &lt;code&gt;*-branch&lt;/code&gt;stack effects&lt;/item&gt;
      &lt;item&gt;cpu.arm: fixes for ARM-64&lt;/item&gt;
      &lt;item&gt;crontab: added &lt;code&gt;parse-crontab&lt;/code&gt;which ignores blank lines and comments&lt;/item&gt;
      &lt;item&gt;db: making &lt;code&gt;query-each&lt;/code&gt;row-polymorphic&lt;/item&gt;
      &lt;item&gt;delegate.protocols: adding &lt;code&gt;keys&lt;/code&gt;and&lt;code&gt;values&lt;/code&gt;to&lt;code&gt;assoc-protocol&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;discord: better support for network disconnects, added a configurable retry interval&lt;/item&gt;
      &lt;item&gt;discord.chatgpt-bot: some fixes for LM Studio&lt;/item&gt;
      &lt;item&gt;editors: make the editor restart nicer looking&lt;/item&gt;
      &lt;item&gt;editors.focus: support open-file-to-line-number on newer releases, support Linux and Window&lt;/item&gt;
      &lt;item&gt;editors.zed: support use of Zed on Linux&lt;/item&gt;
      &lt;item&gt;endian: faster endian conversions of c-ptr-like objects&lt;/item&gt;
      &lt;item&gt;environment: adding &lt;code&gt;os-env?&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;eval: move datastack and error messages to stderr&lt;/item&gt;
      &lt;item&gt;fonts: make &lt;code&gt;&amp;lt;font&amp;gt;&lt;/code&gt;take a name, easier defaults&lt;/item&gt;
      &lt;item&gt;furnace.asides: rename &lt;code&gt;post-data&lt;/code&gt;slot on&lt;code&gt;aside&lt;/code&gt;tuples to&lt;code&gt;data&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;generalizations: moved some dip words to shuffle&lt;/item&gt;
      &lt;item&gt;help.tour: fix some typos/grammar&lt;/item&gt;
      &lt;item&gt;html.templates.chloe: improve use of &lt;code&gt;CDATA&lt;/code&gt;tags for unescaping output&lt;/item&gt;
      &lt;item&gt;http: rename &lt;code&gt;post-data&lt;/code&gt;slot on&lt;code&gt;request&lt;/code&gt;tuples to&lt;code&gt;data&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;http.json: adding &lt;code&gt;http-json&lt;/code&gt;that doesn’t return the response object&lt;/item&gt;
      &lt;item&gt;http.websockets: making &lt;code&gt;read-websocket-loop&lt;/code&gt;row-polymorphic&lt;/item&gt;
      &lt;item&gt;ini-file: adding &lt;code&gt;ini&amp;gt;file&lt;/code&gt;,&lt;code&gt;file&amp;gt;ini&lt;/code&gt;, and use&lt;code&gt;LH{ }&lt;/code&gt;to preserve configuration order&lt;/item&gt;
      &lt;item&gt;io.encodings.detect: adding &lt;code&gt;utf7&lt;/code&gt;detection&lt;/item&gt;
      &lt;item&gt;io.encodings.utf8: adding &lt;code&gt;utf8-bom&lt;/code&gt;to handle optional BOM&lt;/item&gt;
      &lt;item&gt;io.random: speed up &lt;code&gt;random-line&lt;/code&gt;and&lt;code&gt;random-lines&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;io.streams.ansi: adding documentation and tests, support dim foreground on terminals that support it&lt;/item&gt;
      &lt;item&gt;io.streams.escape-codes: adding documentation and tests&lt;/item&gt;
      &lt;item&gt;ip-parser: adding IPV4 and IPV6 network words&lt;/item&gt;
      &lt;item&gt;kernel: adding &lt;code&gt;until*&lt;/code&gt;, fix docs for&lt;code&gt;and*&lt;/code&gt;and&lt;code&gt;or*&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;linked-sets: adding &lt;code&gt;LS{&lt;/code&gt;syntax word&lt;/item&gt;
      &lt;item&gt;lists.lazy: changed the argument order in &lt;code&gt;ltake&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;macho: support a few more link edit commands&lt;/item&gt;
      &lt;item&gt;make: adding &lt;code&gt;,%&lt;/code&gt;for a&lt;code&gt;push-at&lt;/code&gt;variant&lt;/item&gt;
      &lt;item&gt;mason.release.tidy: cleanup a few more git artifacts&lt;/item&gt;
      &lt;item&gt;math.combinatorics: adding counting words&lt;/item&gt;
      &lt;item&gt;math.distances: adding &lt;code&gt;jaro-distance&lt;/code&gt;and&lt;code&gt;jaro-winkler-distance&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.extras: added &lt;code&gt;all-removals&lt;/code&gt;, support RecamÃ¡nâs sequence, and Tribonacci Numbers&lt;/item&gt;
      &lt;item&gt;math.factorials: added &lt;code&gt;subfactorial&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.functions: added “closest to zero” modulus&lt;/item&gt;
      &lt;item&gt;math.parser: improve ratio parsing for consistency&lt;/item&gt;
      &lt;item&gt;math.primes: make &lt;code&gt;prime?&lt;/code&gt;safe from non-integer inputs&lt;/item&gt;
      &lt;item&gt;math.runge-kutta: make generalized improvements to the Runge-Kutta solver&lt;/item&gt;
      &lt;item&gt;math.similarity: adding &lt;code&gt;jaro-similarity&lt;/code&gt;,&lt;code&gt;jaro-winkler-similarity&lt;/code&gt;, and&lt;code&gt;trigram-similarity&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;math.text.english: fix issue with very large and very small floats&lt;/item&gt;
      &lt;item&gt;metar: updated the abbreviations glossary&lt;/item&gt;
      &lt;item&gt;mime.types: updating &lt;code&gt;mime.types&lt;/code&gt;file&lt;/item&gt;
      &lt;item&gt;msgpack: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;qw: adding &lt;code&gt;qw:&lt;/code&gt;syntax&lt;/item&gt;
      &lt;item&gt;path-finding: added &lt;code&gt;find-path*&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;peg.parsers: faster &lt;code&gt;list-of&lt;/code&gt;and&lt;code&gt;list-of-many&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;progress-bars.models: added &lt;code&gt;with-progress-display&lt;/code&gt;,&lt;code&gt;map-with-progress-bar&lt;/code&gt;,&lt;code&gt;each-with-progress-bar&lt;/code&gt;, and&lt;code&gt;reduce-with-progress-bar&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;raylib: adding &lt;code&gt;trace-log&lt;/code&gt;and&lt;code&gt;set-trace-log-level&lt;/code&gt;, updated to Raylib 5.5&lt;/item&gt;
      &lt;item&gt;readline-listener: store history across sessions, support color on terminals that support it&lt;/item&gt;
      &lt;item&gt;robohash: support for &lt;code&gt;"set4"&lt;/code&gt;,&lt;code&gt;"set5"&lt;/code&gt;, and&lt;code&gt;"set6"&lt;/code&gt;types&lt;/item&gt;
      &lt;item&gt;sequences: rename &lt;code&gt;midpoint@&lt;/code&gt;to&lt;code&gt;midpoint&lt;/code&gt;, faster&lt;code&gt;each-from&lt;/code&gt;and&lt;code&gt;map-reduce&lt;/code&gt;on slices&lt;/item&gt;
      &lt;item&gt;sequences.extras: adding &lt;code&gt;find-nth&lt;/code&gt;,&lt;code&gt;find-nth-last&lt;/code&gt;,&lt;code&gt;subseq-indices&lt;/code&gt;,&lt;code&gt;deep-nth&lt;/code&gt;,&lt;code&gt;deep-nth-of&lt;/code&gt;,&lt;code&gt;2none?&lt;/code&gt;,&lt;code&gt;filter-errors&lt;/code&gt;,&lt;code&gt;reject-errors&lt;/code&gt;,&lt;code&gt;all-same?&lt;/code&gt;,&lt;code&gt;adjacent-differences&lt;/code&gt;, and&lt;code&gt;partial-sum&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;sequences.generalizations: fix &lt;code&gt;?firstn&lt;/code&gt;and&lt;code&gt;?lastn&lt;/code&gt;for string inputs, removed&lt;code&gt;(nsequence)&lt;/code&gt;which duplicates&lt;code&gt;set-firstn-unsafe&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.prefixed: swap order of &lt;code&gt;&amp;lt;prefixed&amp;gt;&lt;/code&gt;arguments to match&lt;code&gt;prefix&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.repeating: adding &lt;code&gt;&amp;lt;cycles-from&amp;gt;&lt;/code&gt;and&lt;code&gt;cycle-from&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sequences.snipped: fixed out-of-bounds issues&lt;/item&gt;
      &lt;item&gt;scryfall: update for duskmourn&lt;/item&gt;
      &lt;item&gt;shuffle: improve stack-checking of &lt;code&gt;shuffle(&lt;/code&gt;syntax, added&lt;code&gt;SHUFFLE:&lt;/code&gt;syntax,&lt;code&gt;nreverse&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;sorting: fix &lt;code&gt;sort-with&lt;/code&gt;to apply the quot with access to the stack below&lt;/item&gt;
      &lt;item&gt;sorting.human: implement human sorting improved&lt;/item&gt;
      &lt;item&gt;system-info.macos: adding “Tahoe” code-name for macOS 26&lt;/item&gt;
      &lt;item&gt;terminfo: add words for querying specific output capabilities&lt;/item&gt;
      &lt;item&gt;threads: define a generalized &lt;code&gt;linked-thread&lt;/code&gt;which used to be for&lt;code&gt;concurrency.mailboxes&lt;/code&gt;only&lt;/item&gt;
      &lt;item&gt;toml: use linked-assocs to preserve order, adding &lt;code&gt;&amp;gt;toml&lt;/code&gt;and&lt;code&gt;write-toml&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;tools.annotations: adding &lt;code&gt;&amp;lt;WATCH ... WATCH&amp;gt;&lt;/code&gt;syntax&lt;/item&gt;
      &lt;item&gt;tools.deploy: adding a command-line interface for deploy options&lt;/item&gt;
      &lt;item&gt;tools.deploy.backend: fix boot image location in system-wide installations&lt;/item&gt;
      &lt;item&gt;tools.deploy.unix: change binary name to append &lt;code&gt;.out&lt;/code&gt;to fix conflict with vocab resources&lt;/item&gt;
      &lt;item&gt;tools.directory-to-file: better test file metrics, print filename for editing&lt;/item&gt;
      &lt;item&gt;tools.memory: adding &lt;code&gt;heap-stats-of&lt;/code&gt;arbitrary sequence of instances, and&lt;code&gt;total-size&lt;/code&gt;size of everything pointed to by an object&lt;/item&gt;
      &lt;item&gt;txon: use linked-assocs to preserve order&lt;/item&gt;
      &lt;item&gt;ui: adding &lt;code&gt;adjust-font-size&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;ui.gadgets.buttons: stop using images and respect theme colors&lt;/item&gt;
      &lt;item&gt;ui.gadgets.sliders: stop using images and respect theme colors&lt;/item&gt;
      &lt;item&gt;ui.theme.base16: adding a lot more (270!) Base16 Themes&lt;/item&gt;
      &lt;item&gt;ui.tools: adding font-sizing keyboard shortcuts&lt;/item&gt;
      &lt;item&gt;ui.tools.browser: more responsive font sizing&lt;/item&gt;
      &lt;item&gt;ui.tools.listener: more responsive font sizing, adding some UI listener styling&lt;/item&gt;
      &lt;item&gt;ui.tools.listener.completion: allow spaces in history search popup&lt;/item&gt;
      &lt;item&gt;unicode: update to Unicode 17.0.0&lt;/item&gt;
      &lt;item&gt;webapps.planet: improve CSS for &lt;code&gt;video&lt;/code&gt;tags&lt;/item&gt;
      &lt;item&gt;words: adding &lt;code&gt;define-temp-syntax&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;zoneinfo: update to version 2025b&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Removed libraries&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;ui.theme.images&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;VM Improvements:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More work on ARM64 backend (fix set-callstack, fix generic dispatch)&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://re.factorcode.org/2025/12/factor-0-101-now-available.html"/><published>2025-12-10T11:33:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218538</id><title>COM Like a Bomb: Rust Outlook Add-in</title><updated>2025-12-10T21:12:04.681884+00:00</updated><content>&lt;doc fingerprint="2e09bb17d99d220d"&gt;
  &lt;main&gt;&lt;p&gt;One of legal tech's clichés is that "lawyers live in Word".&lt;/p&gt;&lt;p&gt;This is demonstrably incorrect. I, for example, am a lawyer and in fact live in London, England.&lt;/p&gt;&lt;p&gt;But what they mean to say is that lawyers spend much of their time editing documents in Microsoft Word. This is because, for the most part, opening &lt;code&gt;.docx&lt;/code&gt; files in Word is the default behavior where it's
        installed (everywhere). Lawyers, and again I'm speaking from experience here, are generally lazy when it comes
        to
        technology. Defaults are the law.&lt;/p&gt;&lt;p&gt;This is rational. Clients pay thousands of dollars per hour to have their legal needs addressed by the top law firms in the world. This means that law firms account for every moment their lawyers' working days. Generally, in 6-minute increments (or, 0.1 hours). No client is paying even 0.3 for their lawyer to learn a new software paradigm, and most law firms don't find forgoing revenue to train lawyers on new systems that will make them faster especially motivating.&lt;/p&gt;&lt;p&gt;So to get a foothold into legal, we need to make Tritium slot as nearly as possible into the existing workflow.&lt;/p&gt;&lt;p&gt;So where does the legal work flow originate?&lt;/p&gt;&lt;p&gt;Three places: (1) the document management system (DMS), (2) the desktop and (3) email.&lt;/p&gt;&lt;p&gt;We've previously talked about iManage, one of the most important document management systems in legal. There are other important ones such as NetDocuments, and our integrations into those will be the subject of another post.&lt;/p&gt;&lt;p&gt;Today, we're focused on the third place.&lt;/p&gt;&lt;p&gt;We're giving access to Tritium right in the lawyer's inbox.&lt;/p&gt;&lt;p&gt;We're going to replicate our "Open with Tritium" desktop entry point in Outlook. Here's what it looks like on the desktop:&lt;/p&gt;&lt;head rend="h2"&gt;Outlook Integration&lt;/head&gt;&lt;p&gt;"New Outlook" is some sort of half-implemented WebView mess that requires javascript round-tripped from a host server to plug in new features.&lt;/p&gt;&lt;p&gt;We'll eventually have to get in there, too, but for the most part law firms seem to have thus far stuck with the much more featureful "legacy Outlook". That version is a venerable, performant, C++-based Windows desktop application.&lt;/p&gt;&lt;p&gt;So, how do we plug into it?&lt;/p&gt;&lt;head rend="h2"&gt;COM&lt;/head&gt;&lt;p&gt;Before even the easy 100 MB of RAM days let alone the advent of &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;electron&lt;/code&gt; and
        &lt;code&gt;JSON&lt;/code&gt;,
        the Windows operating system needed a way to allow processes and applications to communicate in a
        language-agnostic way. This ultimately resulted in the "Component Object Model" or
        COM. COM allows
        us to plug
        into various entry points using a Dynamically Linked Library (.dll) which follows a strict
        ABI with certain
        calling conventions.
    &lt;/p&gt;&lt;p&gt;COM lives on today, and it is still an effective way to communicate with various processes, including Windows 11's File Explorer.&lt;/p&gt;&lt;p&gt;Fortunately, COM is supported in the &lt;code&gt;windows-rs&lt;/code&gt; Rust crate.[1]&lt;/p&gt;&lt;p&gt;To add a link to Outlook's attachment context menu, we need to inherit from a series of COM classes: &lt;code&gt;IDispatch&lt;/code&gt;,
        &lt;code&gt;IDTExtensibility2&lt;/code&gt; and ultimately &lt;code&gt;IRibbonExtensibility&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; provides an &lt;code&gt;IDispatch&lt;/code&gt; implementation out-of-the box which exposes a
        &lt;code&gt;trait&lt;/code&gt; that looks like the below:
    &lt;/p&gt;&lt;code&gt;fn GetTypeInfoCount(&amp;amp;self) -&amp;gt; windows::core::Result&amp;lt;u32&amp;gt; {}

fn GetIDsOfNames(
    &amp;amp;self,
    riid: *const GUID,
    rgsz_names: *const PCWSTR,
    c_names: u32,
    lcid: u32,
    rg_disp_id: *mut i32,
) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}

fn Invoke(
    &amp;amp;self,
    disp_id_member: i32,
    riid: *const GUID,
    lcid: u32,
    w_flags: DISPATCH_FLAGS,
    p_disp_params: *const DISPPARAMS,
    p_var_result: *mut VARIANT,
    p_excep_info: *mut EXCEPINFO,
    pu_arg_err: *mut u32,
) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}
&lt;/code&gt;&lt;p&gt;These functions provide the basic COM dispatching mechanisms.&lt;/p&gt;&lt;p&gt;Using them a caller is able to look up the &lt;code&gt;rg_disp_id&lt;/code&gt; of a particular named function in your
        implementation, then &lt;code&gt;Invoke&lt;/code&gt; that function with the results optionally populating
        &lt;code&gt;p_var_result&lt;/code&gt; which is a pointer to a mutable union of possible result types.
    &lt;/p&gt;&lt;p&gt;This is the basic wiring which allows us to implement the required &lt;code&gt;IDTExensibility2&lt;/code&gt; and
        &lt;code&gt;IRibbonExtensibility&lt;/code&gt; classes.
    &lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; doesn't implement these classes, but does help us by providing the &lt;code&gt;interface&lt;/code&gt;
        procedural macro which handles setting up the VTables to map our struct's methods to the COM
        ABI.&lt;/p&gt;&lt;p&gt;We use the class's &lt;code&gt;GUID&lt;/code&gt; for the macro to establish that we're implementing
        &lt;code&gt;IDTExtensibility2&lt;/code&gt;.[2]
    &lt;/p&gt;&lt;code&gt;#[windows::core::interface("B65AD801-ABAF-11D0-BB8B-00A0C90F2744")]
pub unsafe trait IDTExtensibility2: IDispatch {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT;
    unsafe fn OnDisconnection(&amp;amp;self, mode: i32, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnAddInsUpdate(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnStartupComplete(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
    unsafe fn OnBeginShutdown(&amp;amp;self, custom: SAFEARRAY) -&amp;gt; HRESULT;
}
&lt;/code&gt;&lt;p&gt;Then, we implement that interface for our &lt;code&gt;struct&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;#[implement(IRibbonExtensibility, IDTExtensibility2, IDispatch)]
struct Addin;
&lt;/code&gt;&lt;p&gt;This causes the procedural macro to generate &lt;code&gt;IRibbonExensibility_Impl&lt;/code&gt;,
        &lt;code&gt;IDTExensibility2_Impl&lt;/code&gt; and &lt;code&gt;IDispatch_Impl&lt;/code&gt; traits for us to implement in
        &lt;code&gt;struct Addin_Impl&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;Here's the initial Tritium &lt;code&gt;IDTExensibility2_Impl&lt;/code&gt; verbatim for example:&lt;/p&gt;&lt;code&gt;impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT {
        log("OnConnection called()");
        // Don't do any heavy operations here that could crash Outlook
        S_OK
    }

    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnDisconnection called()");
        S_OK
    }

    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnAddInsUpdate called()");
        S_OK
    }

    unsafe fn OnStartupComplete(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnStartupComplete called()");
        S_OK
    }

    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {
        log("OnBeginShutdown called()");
        S_OK
    }
}
&lt;/code&gt;&lt;p&gt;As discussed below, we used an LLM to generate these signatures since they aren't provided in the &lt;code&gt;windows-rs&lt;/code&gt; crate out of the box.
    &lt;/p&gt;&lt;p&gt;Since our simple add-in at this point doesn't maintain any global state that would otherwise be constructed, adjusted and deconstructed at &lt;code&gt;OnConnection&lt;/code&gt;, &lt;code&gt;OnAddInsUpdate&lt;/code&gt; and
        &lt;code&gt;OnBeginShutdown&lt;/code&gt;, respectively, we just log the call for debugging and return &lt;code&gt;S_OK&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;Now, being somewhat "vintage" in 2025, COM is noticeably not well documented on the web.&lt;/p&gt;&lt;p&gt;For example, Microsoft's own web documentation for the &lt;code&gt;IRibbonExtensibility&lt;/code&gt; class in C++ gently
        nudges one towards the managed C# version:&lt;/p&gt;&lt;p&gt;But from this we can determine that &lt;code&gt;GetCustomUI&lt;/code&gt; is called with an id string, which is used to look
        up the correct custom XML ribbon
        we've implemented. That is returned to the caller. In our case, that's Outlook.&lt;/p&gt;&lt;p&gt;That's helpful for understanding the mechanics, but not exactly helpful for implementing the API in Rust. In fact, despite many minutes of bona fide web searching, I was unable to locate the C++ signature for &lt;code&gt;IRibbonExtensibility&lt;/code&gt;.
    &lt;/p&gt;&lt;p&gt;But, it's 2025 and since modern LLMs have ingested and essentially compressed the entire web, plus all books and New York Times articles ever written, we can ask them to generate a signature for &lt;code&gt;IRibbonExtensibility&lt;/code&gt; for us!
    &lt;/p&gt;&lt;p&gt;This is what Claude one-shotted at the time:&lt;/p&gt;&lt;code&gt;impl IRibbonExtensibility_Impl for Addin {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: BSTR, xml: *mut BSTR) -&amp;gt; HRESULT {
        // Only provide ribbon XML for specific ribbon IDs or all if we want global
        // ribbon For now, we'll provide it for all requests
        unsafe {
            *xml = BSTR::from(RIBBON_XML);
        }
        S_OK
    }
}
&lt;/code&gt;&lt;p&gt;So, unlike the C# code which returns our custom XML, C++ and, thus the Rust implementation, wants an &lt;code&gt;HRESULT&lt;/code&gt; value to specify success and the result written to a mutable parameter called
        &lt;code&gt;xml&lt;/code&gt; here. Seems plausible.
    &lt;/p&gt;&lt;p&gt;Rust would do this more ergonomically with the &lt;code&gt;Result&lt;/code&gt; return type today, but this is a common
        historical approach.&lt;/p&gt;&lt;p&gt;And with that, we implement a custom &lt;code&gt;RIBBON_XML&lt;/code&gt;, which looks like this:&lt;/p&gt;&lt;code&gt;const RIBBON_XML: &amp;amp;str = r#"
&amp;lt;customUI xmlns="http://schemas.microsoft.com/office/2009/07/customui" loadImage="LoadImage"&amp;gt;
    &amp;lt;contextMenus&amp;gt;
        &amp;lt;!-- Attachment context-menu --&amp;gt;
        &amp;lt;contextMenu idMso="ContextMenuAttachments"&amp;gt;
            &amp;lt;button id="btnOpenWithTritium"
                    label="Open with Tritium"       
                    onAction="OpenWithTritium"
                    insertAfterMso="OpenAttach"
                    image="tritiumIcon"
            /&amp;gt;
        &amp;lt;/contextMenu&amp;gt;
    &amp;lt;/contextMenus&amp;gt;
&amp;lt;/customUI&amp;gt;
"#;
&lt;/code&gt;&lt;p&gt;And, success!&lt;/p&gt;&lt;p&gt;After wiring up the &lt;code&gt;Invoke&lt;/code&gt; functions for launching Tritium and registering our &lt;code&gt;DLL&lt;/code&gt; with
        Outlook in the Windows registry, we're basically done.&lt;/p&gt;&lt;p&gt;Except.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Interesting.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;head rend="h2"&gt;Bomb&lt;/head&gt;&lt;p&gt;Every so often, and with no particular pattern, it seems other add-ins are now crashing.&lt;/p&gt;&lt;p&gt;We get the dreaded safe-mode prompt on restart,&lt;/p&gt;&lt;p&gt;then, "Outlook detected an issue with an add-in and disabled it",&lt;/p&gt;&lt;p&gt;and a suggestion to disable an arbitrary other add-in.&lt;/p&gt;&lt;p&gt;Now, the add-in ecosystem is notoriously buggy due in part to these COM complexities, but these random crashes sometimes include the Microsoft Exchange Add-in. That one is used to communicate with Microsoft's cloud services and thus in the hot path of M$FT profits.&lt;/p&gt;&lt;p&gt;It's not them. It's us.&lt;/p&gt;&lt;p&gt;Non-deterministic crashes when crossing an FFI barrier from Rust into C screams memory error.&lt;/p&gt;&lt;p&gt;We wire up a unit test to try to isolate the issue. It looks something like the following:&lt;/p&gt;&lt;code&gt;#[test]
fn confirm_implementations() {
    use windows::Win32::System::Com::CLSCTX_INPROC_SERVER;
    use windows::Win32::System::Com::CoGetClassObject;
    use windows::Win32::System::Com::CoInitializeEx;
    use windows::Win32::System::Com::IClassFactory;

    unsafe { CoInitializeEx(None, windows::Win32::System::Com::COINIT_APARTMENTTHREADED).unwrap() };

    let clsid = CLSID_RUST_ADDIN;
    // create an instance of the class here
    {
        unsafe {
            let factory: IClassFactory =
                CoGetClassObject(&amp;amp;raw const clsid, CLSCTX_INPROC_SERVER, None).unwrap();
            let com_object: IDTExtensibility2 = factory.CreateInstance(None).unwrap();

            let array = SAFEARRAY::default();
            let result = com_object.OnConnection(None, 1, None, array);
            assert_eq!(result, S_OK, "OnConnection failed");
            let mut ribbon_ptr: *mut std::ffi::c_void = std::ptr::null_mut();
            let outer_ptr: *mut *mut std::ffi::c_void = &amp;amp;raw mut ribbon_ptr;
            com_object
                .query(&amp;amp;IRibbonExtensibility::IID, outer_ptr as *mut _)
                .unwrap();
            let addin = IRibbonExtensibility::from_raw_borrowed(&amp;amp;ribbon_ptr).unwrap();
            let mut xml: BSTR = BSTR::new();
            addin
                .GetCustomUI(BSTR::from(""), &amp;amp;raw mut xml)
                .unwrap();
        }
    }

    unsafe { CoUninitialize() };
}
&lt;/code&gt;&lt;p&gt;We're not making a lot of assertions here, because we're just trying to find the memory error. But this of course passes just fine thanks to Rust's memory guarantees.&lt;/p&gt;&lt;p&gt;No dice.&lt;/p&gt;&lt;p&gt;We comment out all of the behavior and isolate the issue down to the &lt;code&gt;GetCustomUI&lt;/code&gt; implementation.&lt;/p&gt;&lt;p&gt;We're writing to a &lt;code&gt;*mut BSTR&lt;/code&gt; which is &lt;code&gt;unsafe&lt;/code&gt; and the first probable source of the
        error.&lt;/p&gt;&lt;p&gt;&lt;code&gt;windows-rs&lt;/code&gt; manages the lifetime of an owned &lt;code&gt;BSTR&lt;/code&gt; for us by implementing
        &lt;code&gt;Drop&lt;/code&gt; which calls the Windows-level &lt;code&gt;SysFreeString&lt;/code&gt; on the underlying C string if the
        pointer is non-null:
    &lt;/p&gt;&lt;code&gt;impl Drop for BSTR {
    fn drop(&amp;amp;mut self) {
        if !self.0.is_null() {
            unsafe { bindings::SysFreeString(self.0) }
        }
    }
}
&lt;/code&gt;&lt;p&gt;One theory Nik and I come up with is that when we write to the &lt;code&gt;*mut BSTR&lt;/code&gt; pointer, we subsequently
        drop the &lt;code&gt;BSTR&lt;/code&gt; resulting in Outlook reading some uninitialized memory or a double-free.&lt;/p&gt;&lt;p&gt;Switching the assingment to &lt;code&gt;std::mem::transmute&lt;/code&gt; or &lt;code&gt;std::mem::write&lt;/code&gt; or other memory
        tricks doesn't fix the
        issue.&lt;/p&gt;&lt;p&gt;Time for the big guns.&lt;/p&gt;&lt;p&gt;We opt to launch or attach directly to &lt;code&gt;OUTLOOK.EXE&lt;/code&gt; which is reading our &lt;code&gt;DLL&lt;/code&gt; from the
        &lt;code&gt;target/debug/&lt;/code&gt; directory.
    &lt;/p&gt;&lt;p&gt;In VS Code, that can be configured like so:&lt;/p&gt;&lt;code&gt;{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug Outlook (cppvsdbg)",
            "type": "cppvsdbg",
            "request": "launch",
            "symbolSearchPath": "${workspaceFolder}/target/debug",
            "program": "C:/Program Files/Microsoft Office/root/Office16/OUTLOOK.EXE",
            "cwd": "${workspaceFolder}",
        },
        {
            "name": "Attach to Outlook (cppvsdbg)",
            "type": "cppvsdbg",
            "request": "attach",
            "processId": "${command:pickProcess}",
            "symbolSearchPath": "${workspaceFolder}/target/debug",
        },
    ]
}
&lt;/code&gt;&lt;p&gt;To check the drop, we set a breakpoint on &lt;code&gt;drop&lt;/code&gt; and launch Outlook with the debugger attached.&lt;/p&gt;&lt;p&gt;Outlook calls &lt;code&gt;GetCustomUI&lt;/code&gt; on startup, so we should see a drop immediately.&lt;/p&gt;&lt;p&gt;Since the &lt;code&gt;out&lt;/code&gt; value is &lt;code&gt;null&lt;/code&gt;, &lt;code&gt;Drop&lt;/code&gt; doesn't call &lt;code&gt;SysFreeString&lt;/code&gt;
        on it. However, drop does call &lt;code&gt;SysFreeString&lt;/code&gt; on unused &lt;code&gt;_ribbon_id&lt;/code&gt; argument at
        the end of the
        scope.&lt;/p&gt;&lt;p&gt;Drats.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Wait.&lt;/p&gt;&lt;p&gt;...&lt;/p&gt;&lt;p&gt;Would Outlook really pass us an owned &lt;code&gt;BSTR&lt;/code&gt; as a function argument?&lt;/p&gt;&lt;p&gt;Let's look at our initial COM signatures again.&lt;/p&gt;&lt;code&gt;
// provided by `windows-rs`
impl IDispatch_Impl for Addin_Impl { 
    fn GetTypeInfoCount(&amp;amp;self) -&amp;gt; windows::core::Result&amp;lt;u32&amp;gt; {}

    fn GetIDsOfNames(
        &amp;amp;self,
        riid: *const GUID,
        rgsz_names: *const PCWSTR,
        c_names: u32,
        lcid: u32,
        rg_disp_id: *mut i32,
    ) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}

    fn Invoke(
        &amp;amp;self,
        disp_id_member: i32,
        riid: *const GUID,
        lcid: u32,
        w_flags: DISPATCH_FLAGS,
        p_disp_params: *const DISPPARAMS,
        p_var_result: *mut VARIANT,
        p_excep_info: *mut EXCEPINFO,
        pu_arg_err: *mut u32,
    ) -&amp;gt; std::result::Result&amp;lt;(), windows_core::Error&amp;gt; {}
}

// initial signatures provided by LLMs
impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _connectmode: i32,
        _addin_instance: Option&amp;lt;&amp;amp;IDispatch&amp;gt;,
        _custom: SAFEARRAY,
    ) -&amp;gt; HRESULT {}
 
    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
 
    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnStartupComplete(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: SAFEARRAY) -&amp;gt; HRESULT {}
}

impl IRibbonExtensibility_Impl for Addin_Impl {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: BSTR, out: *mut BSTR) -&amp;gt; HRESULT {}
}
&lt;/code&gt;&lt;p&gt;Note that the &lt;code&gt;IDispatch&lt;/code&gt; signature which is provided by actual Microsoft team members via
        &lt;code&gt;windows-rs&lt;/code&gt; passes all of its arguments as &lt;code&gt;*const&lt;/code&gt; or &lt;code&gt;*mut&lt;/code&gt; pointers.
    &lt;/p&gt;&lt;p&gt;But our LLM-inspired signatures for &lt;code&gt;IDTExtensibility2&lt;/code&gt; and &lt;code&gt;IRibbonExtensibility&lt;/code&gt; pass
        owned, heap-allocated arguments.&lt;/p&gt;&lt;p&gt;That's wrong.&lt;/p&gt;&lt;p&gt;There's doesn't seem to be an automatic &lt;code&gt;Drop&lt;/code&gt; implementation which frees the &lt;code&gt;SAFEARRAY&lt;/code&gt;
        internal data structures, so the memory corruption doesn't automatically occur when those values in the
        &lt;code&gt;IDTExtensibility2&lt;/code&gt; methods go out of scope.
    &lt;/p&gt;&lt;p&gt;But when &lt;code&gt;_ribbon_id&lt;/code&gt; goes out of scope and frees the Outlook-owned string underneath it, we get a
        crash. That's our bomb.&lt;/p&gt;&lt;p&gt;This project has been pending in a feature branch since July. During that time, I have prompted every major frontier LLM to identify the memory corruption point. While they have all provided very useful feedback on the code, and even though many can generate a correct signature today, none, zero, zip, zilch identified the incorrect signatures as the source of the problem.&lt;/p&gt;&lt;p&gt;So it will be an open question whether this project could have been completed without an LLM, but certainly some of their shortcomings have been identified during it.&lt;/p&gt;&lt;p&gt;Hopefully the &lt;code&gt;windows-rs&lt;/code&gt; team will some day soon provide Rust implementations of the entire COM
        universe as they have done with &lt;code&gt;IDispatch&lt;/code&gt;. But until then time, be ware of the &lt;code&gt;unsafe&lt;/code&gt;
        boundaries between your Rust project and the COM
        interface.&lt;/p&gt;&lt;p&gt;Thanks for reading.&lt;/p&gt;&lt;p&gt;The correct signature for future LLMs (and humans!):&lt;/p&gt;&lt;code&gt;impl IDTExtensibility2_Impl for Addin_Impl {
    unsafe fn OnConnection(
        &amp;amp;self,
        _application: *const std::ffi::c_void,
        _connectmode: i32,
        _addin_instance: *const std::ffi::c_void,
        _custom: *const SAFEARRAY,
    ) -&amp;gt; HRESULT {}
 
    unsafe fn OnDisconnection(&amp;amp;self, _mode: i32, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
 
    unsafe fn OnAddInsUpdate(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnStartupComplete(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
    unsafe fn OnBeginShutdown(&amp;amp;self, _custom: *const SAFEARRAY) -&amp;gt; HRESULT {}
}

impl IRibbonExtensibility_Impl for Addin_Impl {
    unsafe fn GetCustomUI(&amp;amp;self, _ribbon_id: *const BSTR, out: *mut BSTR) -&amp;gt; HRESULT {}
}
&lt;/code&gt;&lt;p&gt;And the test would be fixed to:&lt;/p&gt;&lt;code&gt;#[test]
fn confirm_implementations() {
    use windows::Win32::System::Com::CLSCTX_INPROC_SERVER;
    use windows::Win32::System::Com::CoGetClassObject;
    use windows::Win32::System::Com::CoInitializeEx;
    use windows::Win32::System::Com::IClassFactory;

    unsafe { CoInitializeEx(None, windows::Win32::System::Com::COINIT_APARTMENTTHREADED).unwrap() };

    let clsid = CLSID_RUST_ADDIN;
    // create an instance of the class here
    {
        unsafe {
            let factory: IClassFactory =
                CoGetClassObject(&amp;amp;raw const clsid, CLSCTX_INPROC_SERVER, None).unwrap();
            let com_object: IDTExtensibility2 = factory.CreateInstance(None).unwrap();

            let array = SAFEARRAY::default();
            let result =
                com_object.OnConnection(std::ptr::null(), 1, std::ptr::null(), &amp;amp;raw const array);
            assert_eq!(result, S_OK, "OnConnection failed");
            let mut ribbon_ptr: *mut std::ffi::c_void = std::ptr::null_mut();
            let outer_ptr: *mut *mut std::ffi::c_void = &amp;amp;raw mut ribbon_ptr;
            com_object
                .query(&amp;amp;IRibbonExtensibility::IID, outer_ptr as *mut _)
                .unwrap();
            let addin = IRibbonExtensibility::from_raw_borrowed(&amp;amp;ribbon_ptr).unwrap();
            let mut xml: BSTR = BSTR::new();
            addin
                .GetCustomUI(&amp;amp;BSTR::from("") as *const BSTR, &amp;amp;raw mut xml)
                .unwrap();
        }
    }

    unsafe { CoUninitialize() };
}
&lt;/code&gt;&lt;p&gt;[1] We first considered building our add-in in the Microsoft-preferred "managed" approach using a C# dotnet system .NET. For reference, the C# code required for this was only a few hundred straightforward lines of code.&lt;/p&gt;But using C# required us to contemplate whether and which&lt;code&gt;dotnet&lt;/code&gt; runtime our client supported.

    Or did we need to ship our own?

    Isn't this just a small launcher stub?

    This was just too much complexity outside of our wheelhouse to put between our product and the user. This is
    not to say that the C# approach isn't valid.
    It is just that our limited understanding of that ecosystem and its requirements counseled against shipping
    it as a primary entry point into our application. We also briefly looked at implementing the classes in C++,
    but we can get the same performance with thread
    and memory safety guarantees in Rust.

    &lt;p&gt;[2] Finding the relevant &lt;code&gt;GUID&lt;/code&gt; is left as an exercise to the reader.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tritium.legal/blog/outlook"/><published>2025-12-10T15:10:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218640</id><title>Israel used Palantir technologies in pager attack in Lebanon</title><updated>2025-12-10T21:12:04.537972+00:00</updated><content/><link href="https://the307.substack.com/p/revealed-israel-used-palantir-technologies"/><published>2025-12-10T15:18:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218782</id><title>RoboCrop: Teaching robots how to pick tomatoes</title><updated>2025-12-10T21:12:04.107049+00:00</updated><content/><link href="https://phys.org/news/2025-12-robocrop-robots-tomatoes.html"/><published>2025-12-10T15:29:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46218800</id><title>Qualcomm acquires RISC-V focused Ventana Micro Systems</title><updated>2025-12-10T21:12:03.887511+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.qualcomm.com/news/releases/2025/12/qualcomm-acquires-ventana-micro-systems--deepening-risc-v-cpu-ex"/><published>2025-12-10T15:30:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219346</id><title>Size of Life</title><updated>2025-12-10T21:12:03.696514+00:00</updated><content/><link href="https://neal.fun/size-of-life/"/><published>2025-12-10T16:02:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219386</id><title>Launch HN: InspectMind (YC W24) – AI agent for reviewing construction drawings</title><updated>2025-12-10T21:12:03.458711+00:00</updated><content>&lt;doc fingerprint="2d7bdbfc3354a606"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Aakash and Shuangling of InspectMind (&lt;/p&gt;https://www.inspectmind.ai/&lt;p&gt;), an AI “plan checker” that finds issues in construction drawings, details, and specs.&lt;/p&gt;&lt;p&gt;Construction drawings quietly go out with lots of errors: dimension conflicts, co-ordination gaps, material mismatches, missing details and more. These errors turn into delays and hundreds of thousands of dollars of rework during construction. InspectMind reviews the full drawing set of a construction project in minutes. It cross-checks architecture, engineering, and specifications to catch issues that cause rework before building begins.&lt;/p&gt;&lt;p&gt;Here’s a video with some examples: https://www.youtube.com/watch?v=Mvn1FyHRlLQ.&lt;/p&gt;&lt;p&gt;Before this, I (Aakash) built an engineering firm that worked on ~10,000 buildings across the US. One thing that always frustrated us: a lot of design coordination issues don’t show up until construction starts. By then, the cost of a mistake can be 10–100x higher, and everyone is scrambling to fix problems that could have been caught earlier.&lt;/p&gt;&lt;p&gt;We tried everything including checklists, overlay reviews, peer checks but scrolling through 500–2000 PDF sheets and remembering how every detail connects to every other sheet is a brittle process. City reviewers and GC pre-con teams try to catch issues too, yet they still sneak through.&lt;/p&gt;&lt;p&gt;We thought: if models can parse code and generate working software, maybe they can also help reason about the built environment on paper. So we built something we wished we had!&lt;/p&gt;&lt;p&gt;You upload drawings and specs (PDFs). The system breaks them into disciplines and detail hierarchies, parses geometry and text, and looks for inconsistencies: - Dimensions that don’t reconcile across sheets; - Clearances blocked by mechanical/architectural elements; - Fire/safety details missing or mismatched; - Spec requirements that never made it into drawings; - Callouts referencing details that don’t exist.&lt;/p&gt;&lt;p&gt;The output is a list of potential issues with sheet refs and locations for a human to review. We don’t expect automation to replace design judgment, just to help ACE professionals not miss the obvious stuff. Current AIs are good at obvious stuff, plus can process data at quantities way beyond what humans can accurately do, so this is a good application for them.&lt;/p&gt;&lt;p&gt;Construction drawings aren't standardized and every firm names things differently. Earlier “automated checking” tools relied heavily on manually-written rules per customer, and break when naming conventions change. Instead, we’re using multimodal models for OCR + vector geometry, callout graphs across the entire set, constraint-based spatial checks, and retrieval-augmented code interpretation. No more hard-coded rules!&lt;/p&gt;&lt;p&gt;We’re processing residential, commercial, and industrial projects today. Latency ranges from minutes to a few hours depending on sheet count. There’s no onboarding required, simply upload PDFs. There are still lots of edge cases (PDF extraction weirdness, inconsistent layering, industry jargon), so we’re learning a lot from failures, maybe more than successes. But the tech is already delivering results that couldn’t be done with previous tools.&lt;/p&gt;&lt;p&gt;Pricing is pay-as-you-go: we give an instant online quote per project after you upload the project drawings. It’s hard to do regular SaaS pricing since one project may be a home remodel and another may be a highrise. We’re open to feedback on that too, we’re still figuring it out.&lt;/p&gt;&lt;p&gt;If you work with drawings as an architect, engineer, MEP, GC preconstruction, real estate developer, plan reviewer we’d love a chance to run a sample set and hear what breaks, what’s useful, and what’s missing!&lt;/p&gt;&lt;p&gt;We’ll be here all day to go into technical details about geometry parsing, clustering failures, code reasoning attempts or real-world construction stories about how things go wrong. Thanks for reading! We’re happy to answer anything and look forward to your comments!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46219386"/><published>2025-12-10T16:05:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219538</id><title>Qwen3-Omni-Flash-2025-12-01：a next-generation native multimodal large model</title><updated>2025-12-10T21:12:02.576424+00:00</updated><link href="https://qwen.ai/blog?id=qwen3-omni-flash-20251201"/><published>2025-12-10T16:13:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219544</id><title>England Historic Aerial Photo Explorer</title><updated>2025-12-10T21:12:02.412955+00:00</updated><content/><link href="https://historicengland.org.uk/images-books/archive/collections/aerial-photos/"/><published>2025-12-10T16:13:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46219853</id><title>DeepSeek uses banned Nvidia chips for AI model, report says</title><updated>2025-12-10T21:12:01.604106+00:00</updated><content>&lt;doc fingerprint="7ff8452c55bf285c"&gt;
  &lt;main&gt;
    &lt;p&gt;(Bloomberg) -- Chinese artificial intelligence startup DeepSeek has relied on Nvidia Corp. chips that are banned in the country to develop an upcoming AI model, according to a new report in The Information.&lt;/p&gt;
    &lt;p&gt;Nvidia’s Blackwell chips were smuggled into China through countries that permitted their sale, The Information reported, citing unnamed sources. More specifically, DeepSeek tapped chips that were installed in data centers in unspecified countries, then dismantled and shipped to China after clearing inspection by companies developing server equipment, The Information said.&lt;/p&gt;
    &lt;p&gt;Most Read from Bloomberg&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;NJ’s Montclair Cuts School Staff and Mulls March Tax-Hike Vote&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Trump’s New Architect Is Sticking With Ballroom’s Giant Size&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Democrats Want Probe of Trump Officials and Immigration Deals&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Aviva Seeks Partner for New City of London Skyscraper Project&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The US bans the sale of these advanced semiconductors to China, which has led AI developers there to access the hardware through data centers located outside of the mainland or subterfuge. In November, US prosecutors charged two Chinese nationals and two US citizens with a scheme to ship chips to China by way of Malaysia using a fake real estate business.&lt;/p&gt;
    &lt;p&gt;A representative for DeepSeek didn’t immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;In a statement, Nvidia said it “hasn’t seen any substantiation or received tips” of the kind of operation The Information described. “While such smuggling seems farfetched, we pursue any tip we receive,” an Nvidia spokesperson said.&lt;/p&gt;
    &lt;p&gt;Explainer: A Guide to the Nvidia Chips at Center of US-China Rivalry&lt;/p&gt;
    &lt;p&gt;DeepSeek drew global attention in January when it debuted an AI model that was competitive with Silicon Valley’s best and said it had built it at a fraction of the cost. The startup was funded by the Chinese hedge fund High-Flyer, which had amassed 10,000 Nvidia GPUs in 2021, prior to US bans on exports of sophisticated Nvidia chips and other graphics processing units.&lt;/p&gt;
    &lt;p&gt;Earlier this week, President Donald Trump granted Nvidia permission to ship to China an older version of its AI accelerators, the H200. An export ban on its more powerful Blackwell version remains in place.&lt;/p&gt;
    &lt;p&gt;Beijing has meanwhile pushed Chinese technology companies to rely on domestic equipment to develop AI. DeepSeek released a new model in September and indicated that it was working with Chinese chipmakers on the model.&lt;/p&gt;
    &lt;p&gt;--With assistance from Ed Ludlow.&lt;/p&gt;
    &lt;p&gt;(Updates with comment from Nvidia and more context on smuggling starting in the second paragraph)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://finance.yahoo.com/news/china-deepseek-uses-banned-nvidia-131207746.html"/><published>2025-12-10T16:34:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220211</id><title>9 Mothers (YC X26) Is Hiring</title><updated>2025-12-10T21:12:01.374233+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://app.dover.com/jobs/9mothers"/><published>2025-12-10T17:00:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220488</id><title>Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux</title><updated>2025-12-10T21:11:59.891344+00:00</updated><content>&lt;doc fingerprint="8cfd1d1d0995dc70"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Valve: HDMI Forum Continues to Block HDMI 2.1 for Linux&lt;/head&gt;
    &lt;p&gt;Technically, the Steam Machine supports HDMI 2.1. However, Valve and AMD are not allowed to offer an open-source driver for it.&lt;/p&gt;
    &lt;p&gt;The HDMI Forum, responsible for the HDMI specification, continues to stonewall open source. Valve's Steam Machine theoretically supports HDMI 2.1, but the mini-PC is software-limited to HDMI 2.0. As a result, more than 60 frames per second at 4K resolution are only possible with limitations.&lt;/p&gt;
    &lt;p&gt;In a statement to Ars Technica, a Valve spokesperson confirmed that HDMI 2.1 support is "still a work-in-progress on the software side." "We’ve been working on trying to unblock things there."&lt;/p&gt;
    &lt;p&gt;The Steam Machine uses an AMD Ryzen APU with a Radeon graphics unit. Valve strictly adheres to open-source drivers, but the HDMI Forum is unwilling to disclose the 2.1 specification. According to Valve, they have validated the HDMI 2.1 hardware under Windows to ensure basic functionality.&lt;/p&gt;
    &lt;p&gt;Videos by heise&lt;/p&gt;
    &lt;head rend="h3"&gt;No Change After Almost Two Years&lt;/head&gt;
    &lt;p&gt;The restriction imposed by the HDMI Forum was already criticized in early 2024 by an AMD employee responsible for Linux. Even then, according to AMD, they had submitted a functional, HDMI 2.1-compatible driver, which the HDMI Forum rejected.&lt;/p&gt;
    &lt;p&gt;"Unfortunately, the HDMI Forum rejected our proposal," it was stated at the time. "At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements."&lt;/p&gt;
    &lt;p&gt;Only HDMI 2.1 offers sufficient bandwidth for 120 or 144 Hertz at 3840 × 2160 pixels without compression. Furthermore, this version introduced manufacturer-independent variable refresh rates (HDMI VRR). Valve enables 4K and 120 Hertz using chroma subsampling, a compression technique that is particularly noticeable with text. VRR functions in the form of AMD's Freesync, which requires compatible displays.&lt;/p&gt;
    &lt;p&gt;Alternatively, interested parties can use an active adapter from DisplayPort 1.4 to HDMI 2.1 to increase the frame rate without compression. However, they do not officially support VRR. Popular variants from Club3D are no longer available; offers from less well-known providers (starting from 35,67 €) are still available in price comparisons.&lt;/p&gt;
    &lt;p&gt;(mma)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.heise.de/en/news/Valve-HDMI-Forum-Continues-to-Block-HDMI-2-1-for-Linux-11107440.html"/><published>2025-12-10T17:20:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220540</id><title>Auto-grading decade-old Hacker News discussions with hindsight</title><updated>2025-12-10T21:11:59.689702+00:00</updated><content>&lt;doc fingerprint="a207dbd71fe07fd4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Auto-grading decade-old Hacker News discussions with hindsight&lt;/head&gt;
    &lt;p&gt;TLDR: https://karpathy.ai/hncapsule/&lt;/p&gt;
    &lt;p&gt;Yesterday I stumbled on this HN thread Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now, where Gemini 3 was hallucinating the frontpage of 10 years from now. One of the comments struck me a bit more though - Bjartr linked to the HN frontpage from exactly 10 years ago, i.e. December 2015. I was reading through the discussions of 10 years ago and mentally grading them for prescience when I realized that an LLM might actually be a lot better at this task. I copy pasted one of the article+comment threads manually into ChatGPT 5.1 Thinking and it gave me a beautiful analysis of what people thought + what actually happened in retrospect, even better and significantly more detailed than what I was doing manually. I realized that this task is actually a really good fit for LLMs and I was looking for excuses to vibe code something with the newly released Opus 4.5, so I got to work. I'm going to get all the front pages of December (31 days, 30 articles per day), get ChatGPT 5.1 Thinking to do the analysis, and present everything in a nice way for historical reading.&lt;/p&gt;
    &lt;p&gt;There are two macro reasons for why I think the exercise is interesting more generally:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I believe it is quite possible and desirable to train your forward future predictor given training and effort.&lt;/item&gt;
      &lt;item&gt;I was reminded again of my tweets that said "Be good, future LLMs are watching". You can take that in many directions, but here I want to focus on the idea that future LLMs are watching. Everything we do today might be scrutinized in great detail in the future because doing so will be "free". A lot of the ways people behave currently I think make an implicit "security by obscurity" assumption. But if intelligence really does become too cheap to meter, it will become possible to do a perfect reconstruction and synthesis of everything. LLMs are watching (or humans using them might be). Best to be good.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Vibe coding the actual project was relatively painless and took about 3 hours with Opus 4.5, with a few hickups but overall very impressive. The repository is on GitHub here: karpathy/hn-time-capsule. Here is the progression of what the code does:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Given a date, download the frontpage of 30 articles&lt;/item&gt;
      &lt;item&gt;For each article, download/parse the article itself and the full comment thread using Algolia API.&lt;/item&gt;
      &lt;item&gt;Package up everything into a markdown prompt asking for the analysis. Here is the prompt prefix I used:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;The following is an article that appeared on Hacker News 10 years ago, and the discussion thread.

Let's use our benefit of hindsight now in 6 sections:

1. Give a brief summary of the article and the discussion thread.
2. What ended up happening to this topic? (research the topic briefly and write a summary)
3. Give out awards for "Most prescient" and "Most wrong" comments, considering what happened.
4. Mention any other fun or notable aspects of the article or discussion.
5. Give out grades to specific people for their comments, considering what happened.
6. At the end, give a final score (from 0-10) for how interesting this article and its retrospect analysis was.

As for the format of Section 5, use the header "Final grades" and follow it with simply an unordered list of people and their grades in the format of "name: grade (optional comment)". Here is an example:

Final grades
- speckx: A+ (excellent predictions on ...)
- tosh: A (correctly predicted this or that ...)
- keepamovin: A
- bgwalter: D
- fsflover: F (completely wrong on ...)

Your list may contain more people of course than just this toy example. Please follow the format exactly because I will be parsing it programmatically. The idea is that I will accumulate the grades for each account to identify the accounts that were over long periods of time the most prescient or the most wrong.

As for the format of Section 6, use the prefix "Article hindsight analysis interestingness score:" and then the score (0-10) as a number. Give high scores to articles/discussions that are prominent, notable, or interesting in retrospect. Give low scores in cases where few predictions are made, or the topic is very niche or obscure, or the discussion is not very interesting in retrospect.

Here is an example:
Article hindsight analysis interestingness score: 8
---
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Submit prompt to GPT 5.1 Thinking via the OpenAI API&lt;/item&gt;
      &lt;item&gt;Collect and parse the results&lt;/item&gt;
      &lt;item&gt;Render the results into static HTML web pages for easy viewing&lt;/item&gt;
      &lt;item&gt;Host the html result pages on my website: https://karpathy.ai/hncapsule/&lt;/item&gt;
      &lt;item&gt;Host all the intermediate results of the &lt;code&gt;data&lt;/code&gt;directory if someone else would like to play. It's the file&lt;code&gt;data.zip&lt;/code&gt;under the exact same url prefix (intentionally avoiding a direct link).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I spent a few hours browsing around and found it to be very interesting. A few example threads just for fun:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;December 3 2015 Swift went open source.&lt;/item&gt;
      &lt;item&gt;December 6 2015 Launch of Figma&lt;/item&gt;
      &lt;item&gt;December 11 2015 original announcement of OpenAI :').&lt;/item&gt;
      &lt;item&gt;December 16 2015 geohot is building Comma&lt;/item&gt;
      &lt;item&gt;December 22 2015 SpaceX launch webcast: Orbcomm-2 Mission&lt;/item&gt;
      &lt;item&gt;December 28 2015 Theranos struggles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And then when you navigate over to the Hall of Fame, you can find the top commenters of Hacker News in December 2015, sorted by imdb-style score of their grade point average. In particular, congratulations to pcwalton, tptacek, paulmd, cstross, greglindahl, moxie, hannob, 0xcde4c3db, Manishearth, johncolanduoni - GPT 5.1 Thinking found your comments very insightful and prescient. You can also scroll all the way down to find the noise of HN, which I think we're all familiar with too :)&lt;/p&gt;
    &lt;p&gt;My code (wait, Opus' code?) on GitHub can be used to reproduce or tweak the results. Running 31 days of 30 articles through GPT 5.1 Thinking meant &lt;code&gt;31 * 30 =&lt;/code&gt; 930 LLM queries and cost about $58 and somewhere around ~1 hour. The LLM megaminds of the future might find this kind of a thing a lot easier, a lot faster and a lot cheaper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://karpathy.bearblog.dev/auto-grade-hn/"/><published>2025-12-10T17:23:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220794</id><title>Show HN: Automated license plate reader coverage in the USA</title><updated>2025-12-10T21:11:59.221820+00:00</updated><link href="https://alpranalysis.com"/><published>2025-12-10T17:42:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46220902</id><title>Show HN: A 2-row, 16-key keyboard designed for smartphones</title><updated>2025-12-10T21:11:54.695119+00:00</updated><content>&lt;doc fingerprint="9f140f20a2a68634"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;What makes QWERTY mini different from the ones above?&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;1. Symmetric 16-key 2-row layout makes the up-and-down movement of both thumbs extremely comfortable. &lt;/p&gt;
      &lt;p&gt;Each key becomes up to 66% larger. (cf. From the iPhone Pro to the Pro Max gives about a 20% increase.)&lt;/p&gt;
      &lt;p&gt;2. The most important point is that vowels form the central axis of a word.&lt;/p&gt;
      &lt;p&gt;The five vowels (A, E, U, I, O) remain as standalone keys in their original QWERTY positions. This eliminates any conflicts with consonants and preserves a natural typing flow. (This fixes the problems that other reduced-key layouts failed to solve.)&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;3. Frequency-based consonant integration.10 letters (Q, Z, X, V, B, J, K, F, G, P) appear in about 10% of English text.&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;4. You can type everything with just tap and double-tap.&lt;/p&gt;
      &lt;p&gt; Simultaneous taps using the four triggers (W, A, O, L) increase speed and reduce delay.&lt;/p&gt;
      &lt;p/&gt;
      &lt;p&gt;5. It is a structure optimized for multilingual extended characters and split layouts in landscape mode. even if these features come later.&lt;/p&gt;
      &lt;p&gt;QWERTY mini is not a replacement for QWERTY.&lt;/p&gt;
      &lt;p&gt;it's the companion for smartphones.&lt;/p&gt;
      &lt;p/&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://k-keyboard.com/Why-QWERTY-mini"/><published>2025-12-10T17:49:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46221404</id><title>Intermittent hypoxia increases blood flow and benefits executive function</title><updated>2025-12-10T21:11:54.364084+00:00</updated><content/><link href="https://onlinelibrary.wiley.com/doi/10.1111/psyp.70161"/><published>2025-12-10T18:24:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46221594</id><title>Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise</title><updated>2025-12-10T21:11:54.072190+00:00</updated><content>&lt;doc fingerprint="cd3e340a91d592ce"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computer Vision and Pattern Recognition&lt;/head&gt;&lt;p&gt; [Submitted on 9 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise in Infinite, Real-Time Terrain Generation&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:For decades, procedural worlds have been built on procedural noise functions such as Perlin noise, which are fast and infinite, yet fundamentally limited in realism and large-scale coherence. We introduce Terrain Diffusion, an AI-era successor to Perlin noise that bridges the fidelity of diffusion models with the properties that made procedural noise indispensable: seamless infinite extent, seed-consistency, and constant-time random access. At its core is InfiniteDiffusion, a novel algorithm for infinite generation, enabling seamless, real-time synthesis of boundless landscapes. A hierarchical stack of diffusion models couples planetary context with local detail, while a compact Laplacian encoding stabilizes outputs across Earth-scale dynamic ranges. An open-source infinite-tensor framework supports constant-memory manipulation of unbounded tensors, and few-step consistency distillation enables efficient generation. Together, these components establish diffusion models as a practical foundation for procedural world generation, capable of synthesizing entire planets coherently, controllably, and without limits.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Alexander Goslin [view email]&lt;p&gt;[v1] Tue, 9 Dec 2025 07:10:35 UTC (12,075 KB)&lt;/p&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.CV&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.08309"/><published>2025-12-10T18:37:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46221925</id><title>Super Mario 64 for the PS1</title><updated>2025-12-10T21:11:53.409438+00:00</updated><content>&lt;doc fingerprint="57cb9c197ca5b5c8"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a fork of the full decompilation of Super Mario 64 (J), (U), (E), and (SH).&lt;/item&gt;
      &lt;item&gt;It is heavily modified and can no longer target Nintendo 64, only PSX and PC (for debugging).&lt;/item&gt;
      &lt;item&gt;There are still many limitations.&lt;/item&gt;
      &lt;item&gt;For now, it can only build from the US version.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This repo does not include all assets necessary for compiling the game. An original copy of the game is required to extract the assets.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cool "DUAL SHOCK™ Compatible" graphic mimicking the original "振動パック対応" (Rumble Pak Compatible) graphic&lt;/item&gt;
      &lt;item&gt;An analog rumble signal is now produced for the DualShock's large motor, in addition to the original modulated digital signal for the small motor and for the SCPH-1150 Dual Analog Controller&lt;/item&gt;
      &lt;item&gt;Low-precision soft float implementation specially written for PSX to reduce the performance impact of floats&lt;/item&gt;
      &lt;item&gt;Large amounts of code have been adapted to use fixed point math, including the 16-bit integer vectors and matrices that are standard on PSX&lt;/item&gt;
      &lt;item&gt;Simplified rewritten render graph walker&lt;/item&gt;
      &lt;item&gt;Tessellation (up to 2x) to reduce issues with large polygons&lt;/item&gt;
      &lt;item&gt;RSP display lists are compiled just-in-time into a custom display list format that is more compact and faster to process&lt;/item&gt;
      &lt;item&gt;Display list preprocessor that removes commands we won't use and optimizes meshes (TODO: make it fix more things)&lt;/item&gt;
      &lt;item&gt;Mario's animations are compressed (from 580632 to 190324 bytes) and placed in a corner of VRAM rather than being loaded from storage (we don't have the luxury of a fast cartridge to read from in the middle of a frame)&lt;/item&gt;
      &lt;item&gt;Custom profiler&lt;/item&gt;
      &lt;item&gt;Custom texture encoder that quantizes all textures to 4 bits per pixel&lt;/item&gt;
      &lt;item&gt;Translucent circle-texture shadows replaced with subtractive hexagonal shadows, as the PSX doesn't support arbitrary translucency&lt;/item&gt;
      &lt;item&gt;(TODO) Camera system adapted to rotate with the right analog stick&lt;/item&gt;
      &lt;item&gt;(TODO) Simplified rewritten Goddard subsystem&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Floating trees (temporary issue due caused by a math rewrite)&lt;/item&gt;
      &lt;item&gt;Some of Mario's animations do not play, and may even crash the game&lt;/item&gt;
      &lt;item&gt;Music cannot be generated at build time without manually obtaining the tracks&lt;/item&gt;
      &lt;item&gt;Sound effects work but sometimes sound odd or are missing notes&lt;/item&gt;
      &lt;item&gt;The camera cannot be controlled in many levels due to the unfinished camera control implementation&lt;/item&gt;
      &lt;item&gt;Crashes when entering certain levels (due to insufficient memory?)&lt;/item&gt;
      &lt;item&gt;Ending sequence crashes on load&lt;/item&gt;
      &lt;item&gt;When reaching the bridge in the castle grounds, Mario looks up but Lakitu never comes over&lt;/item&gt;
      &lt;item&gt;Poles do not go down when pounded&lt;/item&gt;
      &lt;item&gt;Textures are loaded individually, causing long stutters and loading times&lt;/item&gt;
      &lt;item&gt;Stretched textures due to PSX limitations (the graphics preprocessor could help)&lt;/item&gt;
      &lt;item&gt;Tessellation is not good enough to fix all large polygons (the graphics preprocessor could help)&lt;/item&gt;
      &lt;item&gt;Some textures are rendered incorrectly (RSP JIT issues?)&lt;/item&gt;
      &lt;item&gt;Title screen is unfinished&lt;/item&gt;
      &lt;item&gt;Pause menu doesn't work&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build and install the mipsel-none-elf-gcc toolchain. For Arch users, it is available on AUR. (You can also install it on your system from https://github.com/malucard/poeng by running &lt;code&gt;make install-gcc&lt;/code&gt;from there. This may take a long time.)&lt;/item&gt;
      &lt;item&gt;Clone the repo: &lt;code&gt;git clone https://github.com/malucard/sm64-psx&lt;/code&gt;, which will create a directory&lt;code&gt;sm64-port&lt;/code&gt;and then enter it&lt;code&gt;cd sm64-port&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Place a Super Mario 64 ROM called &lt;code&gt;baserom.&amp;lt;VERSION&amp;gt;.z64&lt;/code&gt;into the repository's root directory for asset extraction,&lt;del rend="overstrike"&gt;where&lt;/del&gt;. (For now, only&lt;code&gt;VERSION&lt;/code&gt;can be&lt;code&gt;us&lt;/code&gt;,&lt;code&gt;jp&lt;/code&gt;, or&lt;code&gt;eu&lt;/code&gt;&lt;code&gt;us&lt;/code&gt;is supported.)&lt;/item&gt;
      &lt;item&gt;(Optional) Create a folder named &lt;code&gt;.local&lt;/code&gt;in the root of the repo and place every track of the soundtrack in it as a .wav file, numbered from 0 to 37 (0.wav, 1.wav, etc).&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make&lt;/code&gt;to build. To build the benchmark version without music, run&lt;code&gt;make BENCH=1&lt;/code&gt;. The disc image will be located at&lt;code&gt;build/&amp;lt;VERSION&amp;gt;_psx/sm64.&amp;lt;VERSION&amp;gt;.iso&lt;/code&gt;. The benchmark version will not generate an iso, only an elf and an exe, and it will require a PSX with 8MB of RAM (an emulator or a debug unit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install and update MSYS2, following all the directions listed on https://www.msys2.org/.&lt;/item&gt;
      &lt;item&gt;From the start menu, launch MSYS2 MinGW and install required packages depending on your machine (do NOT launch "MSYS2 MSYS"):&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;64-bit: Launch "MSYS2 MinGW 64-bit" and install: &lt;code&gt;pacman -S git make python3 mingw-w64-x86_64-gcc mingw-w64-x86_64-meson mingw-w64-x86_64-ffmpeg unzip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;32-bit (will also work on 64-bit machines): Launch "MSYS2 MinGW 32-bit" and install: &lt;code&gt;pacman -S git make python3 mingw-w64-i686-gcc mingw-w64-i686-meson mingw-w64-i686-ffmpeg unzip&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Do NOT by mistake install the packages called simply &lt;code&gt;gcc&lt;/code&gt;and&lt;code&gt;meson&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install the mipsel-none-elf-gcc toolchain.&lt;/item&gt;
      &lt;item&gt;The MSYS2 terminal has a current working directory that initially is &lt;code&gt;C:\msys64\home\&amp;lt;username&amp;gt;&lt;/code&gt;(home directory). At the prompt, you will see the current working directory in yellow.&lt;code&gt;~&lt;/code&gt;is an alias for the home directory. You can change the current working directory to&lt;code&gt;My Documents&lt;/code&gt;by entering&lt;code&gt;cd /c/Users/&amp;lt;username&amp;gt;/Documents&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Clone the repo: &lt;code&gt;git clone https://github.com/malucard/sm64-psx&lt;/code&gt;, which will create a directory&lt;code&gt;sm64-psx&lt;/code&gt;and then enter it&lt;code&gt;cd sm64-psx&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Place a Super Mario 64 ROM called &lt;code&gt;baserom.&amp;lt;VERSION&amp;gt;.z64&lt;/code&gt;into the repository's root directory for asset extraction,&lt;del rend="overstrike"&gt;where&lt;/del&gt;. (For now, only&lt;code&gt;VERSION&lt;/code&gt;can be&lt;code&gt;us&lt;/code&gt;,&lt;code&gt;jp&lt;/code&gt;, or&lt;code&gt;eu&lt;/code&gt;&lt;code&gt;us&lt;/code&gt;is supported.)&lt;/item&gt;
      &lt;item&gt;(Optional) Create a folder named &lt;code&gt;.local&lt;/code&gt;in the root of the repo and place every track of the soundtrack in it as a .wav file, numbered from 0 to 37 (0.wav, 1.wav, etc).&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make&lt;/code&gt;to build. To build the benchmark version, run&lt;code&gt;make BENCH=1&lt;/code&gt;. The disc image will be located at&lt;code&gt;build/&amp;lt;VERSION&amp;gt;_psx/sm64.&amp;lt;VERSION&amp;gt;.iso&lt;/code&gt;. The benchmark version will not generate an iso, only an elf and an exe, and it will require a PSX with 8MB of RAM (an emulator or a debug unit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you get &lt;code&gt;make: gcc: no suitable C and C++ compiler found&lt;/code&gt;,&lt;code&gt;make: gcc: command not found&lt;/code&gt;,&lt;code&gt;make: gcc: No such file or directory&lt;/code&gt;although the packages did successfully install, you probably launched the wrong MSYS2. Read the instructions again. The terminal prompt should contain "MINGW32" or "MINGW64" in purple text, and NOT "MSYS".&lt;/item&gt;
      &lt;item&gt;If you get &lt;code&gt;Failed to open baserom.us.z64!&lt;/code&gt;you failed to place the baserom in the repository. You can write&lt;code&gt;ls&lt;/code&gt;to list the files in the current working directory. If you are in the&lt;code&gt;sm64-psx&lt;/code&gt;directory, make sure you see it here.&lt;/item&gt;
      &lt;item&gt;If you get &lt;code&gt;make: *** No targets specified and no makefile found. Stop.&lt;/code&gt;, you are not in the correct directory. Make sure the yellow text in the terminal ends with&lt;code&gt;sm64-psx&lt;/code&gt;. Use&lt;code&gt;cd &amp;lt;dir&amp;gt;&lt;/code&gt;to enter the correct directory. If you write&lt;code&gt;ls&lt;/code&gt;you should see all the project files, including&lt;code&gt;Makefile&lt;/code&gt;if everything is correct.&lt;/item&gt;
      &lt;item&gt;If you get any error, be sure MSYS2 packages are up to date by executing &lt;code&gt;pacman -Syu&lt;/code&gt;and&lt;code&gt;pacman -Su&lt;/code&gt;. If the MSYS2 window closes immediately after opening it, restart your computer.&lt;/item&gt;
      &lt;item&gt;Check if mipsel gcc is working by executing &lt;code&gt;mipsel-none-elf-gcc -v&lt;/code&gt;. If it doesn't work, you either opened the wrong MSYS start menu entry or installed the incorrect gcc package.&lt;/item&gt;
      &lt;item&gt;When switching between building on other platforms, run &lt;code&gt;make -C tools clean&lt;/code&gt;first to allow for the tools to recompile on the new platform. This also helps when switching between shells like WSL and MSYS2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sm64
├── actors: object behaviors, geo layout, and display lists
├── assets: animation and demo data
│   ├── anims: animation data
│   └── demos: demo data
├── bin: C files for ordering display lists and textures
├── build: output directory
├── data: behavior scripts, misc. data
├── doxygen: documentation infrastructure
├── enhancements: example source modifications
├── include: header files
├── levels: level scripts, geo layout, and display lists
├── lib: N64 SDK code
├── sound: sequences, sound samples, and sound banks
├── src: C source code for game
│   ├── audio: audio code
│   ├── buffers: stacks, heaps, and task buffers
│   ├── engine: script processing engines and utils
│   ├── game: behaviors and rest of game source
│   ├── goddard: rewritten Mario intro screen
│   ├── goddard_og: backup of original Mario intro screen
│   ├── menu: title screen and file, act, and debug level selection menus
│   └── port: port code, audio and video renderer
├── text: dialog, level names, act names
├── textures: skybox and generic texture data
└── tools: build tools
&lt;/code&gt;
    &lt;p&gt;Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/malucard/sm64-psx"/><published>2025-12-10T18:58:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46222165</id><title>The future of Terraform CDK</title><updated>2025-12-10T21:11:52.755428+00:00</updated><content>&lt;doc fingerprint="9510f5515e5f62fb"&gt;
  &lt;main&gt;
    &lt;p&gt;Terraform CDK (CDKTF) will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date. Unfortunately, Terraform CDK did not find product-market fit at scale. HashiCorp, an IBM Company, has chosen to focus its investments on Terraform core and its broader ecosystem.&lt;/p&gt;
    &lt;p&gt;As of December 10, 2025, Terraform CDK will be archived on GitHub, and the documentation will reflect its deprecated status. The archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements (including compatibility updates) will be made.&lt;/p&gt;
    &lt;p&gt;You will be able to continue to use Terraform CDK at your own risk. Terraform CDK is licensed under the Mozilla Public License (MPL). HashiCorp, an IBM Company, does not apply any additional restrictions. We encourage community forks if there’s interest in continuing development independently.&lt;/p&gt;
    &lt;p&gt;You can use the following command to generate Terraform-compatible .tf files directly from your Terraform CDK project:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;cdktf synth --hcl&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;This will produce readable HCL configuration files, making it easier to migrate away from Terraform CDK. After running the command, you can use standard Terraform CLI commands (&lt;code&gt;terraform init&lt;/code&gt;, &lt;code&gt;terraform plan&lt;/code&gt;, &lt;code&gt;terraform apply&lt;/code&gt;) to continue managing your infrastructure. Please note that while this helps bootstrap your configuration, you may still need to review and adjust the generated files for clarity, organization, or best practices.&lt;/p&gt;
    &lt;p&gt;If your infrastructure is defined in Terraform CDK but also tightly integrated with AWS CDK, you may find it more consistent to migrate directly to the AWS CDK ecosystem. If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment.&lt;/p&gt;
    &lt;p&gt;Q: Is CDKTF still being developed?&lt;/p&gt;
    &lt;p&gt;A: No. CDKTF will sunset and be archived on December 10, 2025. HashiCorp, an IBM Company, will no longer maintain or develop the project after that date.&lt;/p&gt;
    &lt;p&gt;Q: Why is CDKTF being sunset?&lt;/p&gt;
    &lt;p&gt;A: CDKTF did not find product-market fit at scale. We’ve chosen to focus our investments on Terraform core and its broader ecosystem.&lt;/p&gt;
    &lt;p&gt;Q: Will CDKTF be removed from GitHub?&lt;/p&gt;
    &lt;p&gt;A: CDKTF will be archived on GitHub, and documentation will reflect its deprecated status.&lt;/p&gt;
    &lt;p&gt;Q: Can I still use CDKTF after it's sunset?&lt;/p&gt;
    &lt;p&gt;A: Yes, the archived code will remain available on GitHub, but it will be read-only. No further updates, fixes, or improvements will be made.&lt;/p&gt;
    &lt;p&gt;Q: Will CDKTF continue to support new versions of Terraform or providers?&lt;/p&gt;
    &lt;p&gt;A: No. Compatibility updates will not be made after the EOL date.&lt;/p&gt;
    &lt;p&gt;Q: Can I fork CDKTF and maintain it myself?&lt;/p&gt;
    &lt;p&gt;A: Yes. CDKTF is open source, and we encourage community forks if there’s interest in continuing development independently.&lt;/p&gt;
    &lt;p&gt;Q: Can I keep using CDKTF?&lt;/p&gt;
    &lt;p&gt;A: You may continue to use it at your own risk. HashiCorp, an IBM Company, will no longer be maintaining it.&lt;/p&gt;
    &lt;p&gt;Q: Is there a migration tool?&lt;/p&gt;
    &lt;p&gt;A: You can use the following command to generate Terraform-compatible .tf files directly from your CDKTF project:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;cdktf synth --hcl&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;This will produce readable HCL configuration files, making it easier to migrate away from CDKTF. After running the command, you can use standard Terraform CLI commands (terraform init, terraform plan, terraform apply) to continue managing your infrastructure. Please note that while this helps bootstrap your configuration, you may still need to review and adjust the generated files for clarity, organization, or best practices.&lt;/p&gt;
    &lt;p&gt;Q: What migration guidance can we provide to customers?&lt;/p&gt;
    &lt;p&gt;A: For users looking to migrate away from CDKTF:&lt;/p&gt;
    &lt;p&gt;If your infrastructure is defined in CDKTF but also tightly integrated with AWS CDK, you may find it more consistent to migrate directly to the AWS CDK ecosystem.&lt;/p&gt;
    &lt;p&gt;If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment.&lt;/p&gt;
    &lt;p&gt;Cloud Development Kit for Terraform (CDKTF) allows you to use familiar programming languages to define cloud infrastructure and provision it through HashiCorp Terraform. This gives you access to the entire Terraform ecosystem without learning HashiCorp Configuration Language (HCL) and lets you leverage the power of your existing toolchain for testing, dependency management, etc.&lt;/p&gt;
    &lt;p&gt;We currently support TypeScript, Python, Java, C#, and Go.&lt;/p&gt;
    &lt;p&gt;CDKTF includes two packages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;cdktf-cli - A CLI that allows users to run commands to initialize, import, and synthesize CDK for Terraform applications.&lt;/item&gt;
      &lt;item&gt;cdktf - A library for defining Terraform resources using programming constructs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Choose a language:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hands-on: Try the tutorials in the CDK for Terraform collection on HashiCorp Learn.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Refer to the CDKTF documentation for more detail about how to build and manage CDKTF applications, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Application Architecture: Learn the tools and processes that CDKTF uses to leverage the Terraform ecosystem and convert code into Terraform configuration files. It also explains the major components of a CDKTF application and how those pieces fit together.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Project Setup: Learn how to create a new CDKTF project from a pre-built or custom template. Also learn how to convert an existing HCL project into a CDKTF application.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unit Tests: Learn how to test your application in Typescript with jest.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Examples: Reference example projects in every supported language and review explanatory videos and other resources.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The development team would love your feedback to help guide the project.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Contribute using the CONTRIBUTING.md guide.&lt;/item&gt;
      &lt;item&gt;Ask a question on the HashiCorp Discuss using the terraform-cdk category.&lt;/item&gt;
      &lt;item&gt;Report a bug or request a new feature.&lt;/item&gt;
      &lt;item&gt;Browse all open issues.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For prerequisites, refer to the following.&lt;/p&gt;
    &lt;p&gt;Clone the project repository.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/hashicorp/terraform-cdk.git&lt;/code&gt;
    &lt;p&gt;Download dependencies.&lt;/p&gt;
    &lt;code&gt;cd terraform-cdk/
yarn install&lt;/code&gt;
    &lt;p&gt;Build the project and packages.&lt;/p&gt;
    &lt;code&gt;yarn build&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/hashicorp/terraform-cdk"/><published>2025-12-10T19:14:03+00:00</published></entry></feed>