<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-26T20:10:59.099576+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45382755</id><title>No reachable chess position with more than 218 moves</title><updated>2025-09-26T20:11:06.415683+00:00</updated><content>&lt;doc fingerprint="13011afe410486ef"&gt;
  &lt;main&gt;&lt;p&gt;Created by the author using GIMP and freely available images.&lt;/p&gt;&lt;head rend="h1"&gt;Why a position can't have more than 218 moves.&lt;/head&gt;Stop searching, we had it right for 60 years.&lt;p&gt;Ever since Nenad Petrović, grandmaster of chess composition, published his 218 move composition in 1964, people have tried to come up with a better one. I joined the hunt in May 2024 and, being a computer scientist, I decided to settle this question once and for all, using computers. You can give it a try yourself. Try to find a position with more moves than the one below.&lt;/p&gt;&lt;p&gt;Spoiler: You won't.&lt;/p&gt;&lt;p&gt;&lt;lb/&gt;Reachable chess position with 218 moves for White, published by Petrović in 1964.&lt;/p&gt;&lt;p&gt;...but how can we know for sure?&lt;/p&gt;&lt;p&gt;By checking all ~4.8x10^44 reachable chess positions?&lt;lb/&gt;Yeah that's not gonna happen...&lt;/p&gt;&lt;p&gt;That's 8.7 billion billion billion billion billion and it's enough to scare even the mightiest of supercomputers. In fact, cracking AES-128 encryption would be easier.&lt;/p&gt;&lt;p&gt;Fortunately, we can use the power of Math!&lt;/p&gt;&lt;p&gt;Follow me along and perhaps you can compute yourself a world record afterwards :)&lt;/p&gt;&lt;head rend="h2"&gt;Using the power of Math&lt;/head&gt;&lt;p&gt;&lt;lb/&gt;Red is the official color of Math, at least in my elementary school.&lt;/p&gt;&lt;p&gt;We're gonna tackle this problem from the white side, i.e., it is White to move. Except for rare exceptions regarding the reachability of positions, this is equivalent.&lt;/p&gt;&lt;p&gt;Since proving that a position is reachable is complicated, we're gonna search through all ways of placing pieces on the board and filter out the non-reachable ones later on, if needed.&lt;/p&gt;&lt;p&gt;Obviously, 99.9% of the positions suck at having lots of moves, they are not even close to 218. We just need a way to skip them and pray that there exists enough electricity to check the rest.&lt;/p&gt;&lt;p&gt;Let's begin with a couple of useful observations.&lt;/p&gt;&lt;head rend="h4"&gt;Useless pieces&lt;/head&gt;&lt;p&gt;A black piece does not improve the number of moves, most of the time. Its existence only benefits the number of moves if it increases White's number of moves, i.e., at least one of the following is true:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;It can be taken by a white pawn, giving said pawn more moves&lt;/item&gt;&lt;item&gt;It protects the black king from check, making an otherwise illegal position with lots of moves legal&lt;/item&gt;&lt;item&gt;It frees a white piece from being pinned to the white king, thus giving it more moves&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Otherwise, it is useless, at best, and thus can be removed.&lt;/p&gt;&lt;p&gt;&lt;lb/&gt;I inserted this picture for the sole purpose of making this article look less text-heavy.&lt;/p&gt;&lt;head rend="h4"&gt;Too powerful pieces&lt;/head&gt;&lt;p&gt;Next, we observe that, if piece counts permit, we can always replace a black piece, with the exception of the black king, with a strictly less powerful one. That is, a piece that has a subset of the moves of the original piece. For example, a queen with a pawn/bishop/rook or a bishop with a pawn. Except if a pawn is on the seventh rank, since in that case, each of its moves to the promotion square counts as 4 separata moves. The only way for Black's moves to affect White's number of moves is by pinning White's pieces or preventing the white king from stepping on a certain square. Both of these things can't get worse if the black piece has less moves than before.&lt;/p&gt;&lt;head rend="h4"&gt;Too weak pieces?&lt;/head&gt;&lt;p&gt;The other way around, it is not so easy, however. You'd think that you can just replace white rooks and white bishops with white queens if counts permit, but the problem is this: How do you ensure that you cannot capture the black king, making the position illegal? Maybe the optimal solution has a rook instead of a queen to avoid just that?&lt;/p&gt;&lt;p&gt;Well, you might say "Let's just place a black piece in between then".&lt;/p&gt;&lt;p&gt;And you would be wrong unless you can tell me why you haven't just blocked some other white piece and thus reduced the number of moves in total. Or what your plan is, if there is no space to put something in between. You just made the position illegal, duh!&lt;/p&gt;&lt;head rend="h4"&gt;No checks, thank you&lt;/head&gt;&lt;p&gt;Finally, we can get rid of checks. If the black king is in check, it means that the position is illegal, since it is White's turn to move and they could just capture the black king. Not okay! So that can't be it. On the other hand, if the white king is in check, then the number of White's moves is severely restricted and we can easily prove that we cannot reach 218 moves. There are three ways to get out of check:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Move the king&lt;/item&gt;&lt;item&gt;Capture the attacker&lt;/item&gt;&lt;item&gt;Block the attack&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Moving the king gives 8 moves at best. Since any square can be reached by at most 16 pieces at the same time (8 knights and 8 other pieces straight or diagonally), capturing gives 16 moves at best. We can have at most 6 squares to block an attack, so that's an additional 6 x 16 = 96 moves. So at best 8+16+96 = 120 moves, far less than 218, and thus we do not need to consider positions in which either king is in check.&lt;/p&gt;&lt;p&gt;So is this it Tobi? Can we now call NASA and ask for their supercomputer?&lt;/p&gt;&lt;p&gt;Nope, it's still absolutely hopeless, there are waaaaay too many positions left.&lt;lb/&gt;We have to skip even more positions.&lt;/p&gt;&lt;head rend="h2"&gt;Introducing Chess with Cheating: Partial Pieces and Moves&lt;/head&gt;&lt;p&gt;&lt;lb/&gt;Reminder: Replace rook pictures by something more interesting.&lt;/p&gt;&lt;p&gt;While searching through all possible piece configurations, we would ideally like to have some provably correct way of telling whether we can still reach 218 moves, so we can stop trying and save ourselves an astronomically large amount of work. The better the method is, the more work we save. But it also needs to be fast, since we need to run it millions and billions of times.&lt;/p&gt;&lt;p&gt;A common technique in optimization is to allow fractional decisions. Instead of a piece being either on e4 or not, it can be 27.3% there and 72.7% not there. This enables us to just "swim" through the solution space towards the optimal solution instead of trying all combinations. The drawback is that we usually end up with a way too good solution with most decisions being fractional. But if that doesn't get us beyond 218 moves, we know we can stop trying.&lt;/p&gt;&lt;p&gt;Obviously, these kinds of algorithms are already implemented in state-of-the-art solvers like Gurobi, so all we need to do is model our problem to its likings (as a so-called integer programming problem), tell it to maximize the number of moves and pray. Finally, after ~55 000 seconds, it crashed.&lt;lb/&gt;Not enough memory, but also hopelessly far away from completing the proof. Extrapolating the runtime led to an estimated runtime of ~6 years. Yeah, let's not go there. Going back to making more observations:&lt;/p&gt;&lt;head rend="h4"&gt;Checking more positions to make things less slow&lt;/head&gt;&lt;p&gt;To reduce the size of the model, I bent some chess rules, simplifying the search space:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;I allowed castling if king and rook were on the right squares, not requiring anything else&lt;/item&gt;&lt;item&gt;I stopped caring about pieces moving despite being pinned&lt;/item&gt;&lt;item&gt;I stopped caring whether the white king is in check or walks into check&lt;/item&gt;&lt;item&gt;I allowed white pawns to always capture when standing on the fifth rank so I'd not have to check en passant.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;All of these things are unlikely to happen in 218+ move positions and after a solution has been found, I can still check and discard it if it has less moves than it claims to have.&lt;/p&gt;&lt;p&gt;I started again and this time, memory wasn't a problem, but the progress was awfully slow with ~29 days remaining. The world could not wait this long and neither could I. I pressed cancel.&lt;/p&gt;&lt;head rend="h4"&gt;Preventing white magic&lt;/head&gt;&lt;p&gt;&lt;lb/&gt;The optimal fractional solution for the empty board. Most pieces are spread out over multiple squares and have fractional numbers of moves available that sum to ~305. This does prove that the real solution can't have more than 305 moves. Still quite a bit from proving 218 to be the optimum.&lt;/p&gt;&lt;p&gt;Our current way of cheating is too different from reality, causing the solver to have to search through way too many board configurations. In our case, the optimal solution to the easy problem flooded the center with half queens and half knights sharing the same squares, having half pieces move through other half pieces with half moves. Gurobi thinks that the above position has 305 moves in total, which is far away from 218 and a bad upper bound.&lt;/p&gt;&lt;p&gt;In order to cut off this crazy solution, I added a "redundant" constraint, saying that at most one piece in total can move from one direction onto a particular square. Which got us a new hallucination...&lt;/p&gt;&lt;p&gt;&lt;lb/&gt;The second try. This one has 271 2/3 moves which proves that there is no solution with more than 271 moves.&lt;/p&gt;&lt;p&gt;Now we have 271 2/3 moves, which is much better. It's a bit like having to try all passwords with 53 characters vs. all passwords with 87 characters, the latter being many magnitudes harder.&lt;/p&gt;&lt;p&gt;Wait a minute, White can't have 4 kings.&lt;/p&gt;&lt;p&gt;White does not have four kings. White has 3 times 24.6% kings and one 26.2% king. Also, the queen on g3 barely exists, it's 0.8% but apparently it somehow contributes to the total sum of moves :)&lt;/p&gt;&lt;p&gt;With this improved model, I tried again and after ~23 000 seconds, Gurobi solved it to optimality!&lt;/p&gt;&lt;head rend="h2"&gt;Results&lt;/head&gt;&lt;p&gt;Sadly, instead of finding me a fancy position with 219 moves and making my name immortal, Gurobi gave me the following 12 representative positions (of 40,000 in total) with 218 moves each:&lt;/p&gt;&lt;p&gt;All 12 positions seem trivially reachable. I only constructed a proof game for one of the positions, since that is sufficient for proving our claim. If you don't believe that this is possible, keep in mind that White's last or second last move might have been a capture. Or click on the link :)&lt;/p&gt;&lt;p&gt;Sadly not a world record, but at least we now know for certain that 218 is the limit.&lt;/p&gt;&lt;p&gt;And you smart chess move 3.7 bit compression people and chess engine developers, you can finally stop worrying. 256 moves will be enough. You're welcome :-)&lt;/p&gt;&lt;p&gt;Except if you allow non-reachable positions, in which case you might want to read on :P&lt;/p&gt;&lt;head rend="h2"&gt;Other stuff solved along the way&lt;/head&gt;&lt;p&gt;I also confirmed the optimality of the 144 move record without promotions. Since Gurobi did not find any position with more than 144 moves, that means that there also is no reachable position with more than 144 moves. Hence, 144 moves is the best we can do and "Jenő Bán", a chess composer from Hungary, found one in 1960 already:&lt;/p&gt;&lt;p&gt;&lt;lb/&gt;144 moves for White, no promotions. Created by Hungarian chess composer "Jenő Bán". Here is a proof game, demonstrating that the position is reachable.&lt;/p&gt;&lt;p&gt;Also, I confirmed the optimality of the following illegal position, which has 288 moves for White.&lt;/p&gt;&lt;p&gt;&lt;lb/&gt;Illegal position with 288 moves for White. Corner queens can be replaced with bishops.&lt;/p&gt;&lt;p&gt;Now have a guess at what the best non-reachable legal position looks like ;)&lt;lb/&gt;Yep, you're right, cramming the kings into the corners for 271 moves.&lt;/p&gt;&lt;p&gt;&lt;lb/&gt;Legal but non-reachable position with 271 moves for White. Corner queens can be replaced with bishops.&lt;/p&gt;&lt;head rend="h2"&gt;Future plans&lt;/head&gt;&lt;p&gt;My code snippet is freely available at Github. If you manage to do something cool based on it, please let the world know :)&lt;/p&gt;&lt;p&gt;Fun problems enthusiasts could try to tackle next using similar techniques:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Most captures&lt;/item&gt;&lt;item&gt;Most stalemates&lt;/item&gt;&lt;item&gt;Most checks&lt;/item&gt;&lt;item&gt;Most checkmates&lt;/item&gt;&lt;item&gt;Most mates in two&lt;/item&gt;&lt;item&gt;...&lt;/item&gt;&lt;item&gt;Most ... under &amp;lt;condition&amp;gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Some of these might be hard, extremely hard or practically impossible to solve with current technology. I don't think that integer linear programming is a suitable approach for all of them, one likely has to develop a custom algorithm for computing good upper bounds, based on creative mathematical insights.&lt;/p&gt;&lt;p&gt;Good luck to those who dare to try solving one of these ^^&lt;/p&gt;&lt;head rend="h2"&gt;FAQ (based on questions on Lichess and HackerNews)&lt;/head&gt;&lt;p&gt;A chess game can be longer than 218 move, duh&lt;lb/&gt;Yes, a chess game can have thousands of moves if people cooperate, but this article is about the number of options for the side to move.&lt;/p&gt;&lt;p&gt;I don't get what you are doing, this is magic to me, can you explain it simply?&lt;lb/&gt;Let me give an anology: We are trying to write the best possible short story with exactly 1000 letters using a keyboard. Out of ALL ways to arrange 1000 letters.&lt;lb/&gt;After choosing the next letter, we consult a magic oracle that tells us whether what we wrote so far is so terrible that it can't possibly become a good story (or rather one better than the currently best known story). Thanks to this magic oracle, we can actually work through the otherwise prohibitively large number of combinations!&lt;/p&gt;&lt;p&gt;Each letter represents a decision, such as, whether there is a queen on h5 or not, whether the piece on h5 can move to g3 or not, ...&lt;lb/&gt;The complete story represents a complete chess position. The goodness of a story is the number of legal moves to choose from.&lt;/p&gt;&lt;p&gt;The magic oracle thing is a bit heavier to explain, for that I'd recommend reading the article slowly and asking ChatGPT etc. interactively :)&lt;/p&gt;&lt;p&gt;Can I look at your code?&lt;lb/&gt;Yes, of course!&lt;lb/&gt;If Gurobi, your code and your thinking does not have a bug, is this mathematical proof?&lt;lb/&gt;Yes, this proves that among the set of all chess positions reachable from the starting position by a sequence of legal moves, there are positions with 218 legal moves to choose from for the side whose turn it is and there is no position with 219 or more legal moves. 218 is the maximum. Upper AND lower bound proven. The lower bound was known for ~60 years, of course. This work only supplied the (to the best of my knowledge) missing upper bound.&lt;/p&gt;&lt;head rend="h2"&gt;Feedback Hall of Fame&lt;/head&gt;&lt;p&gt;@tromp1234: For pointing to a better estimate for the number of legal chess positions and pointing out that my source is off by around one magnitude.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lichess.org/@/Tobs40/blog/there-is-no-reachable-chess-position-with-more-than-218-moves/a5xdxeqs"/><published>2025-09-26T04:47:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45383637</id><title>Translating a Fortran F-16 Simulator to Unity3D</title><updated>2025-09-26T20:11:05.981659+00:00</updated><content>&lt;doc fingerprint="3633da10e06c133a"&gt;
  &lt;main&gt;&lt;p&gt;I recently purchased the textbook “Aircraft Control and Simulation” by Brian L. Stevens, Frank L. Lewis, and Eric N. Johnson1. This book covers the control and simulation of aircraft. It’s really dense and frankly hard to understand. As far as aerodynamics texts go, it’s pretty typical.&lt;/p&gt;&lt;p&gt;One interesting item in the appendices of the book is the source code for the simulation of an F-16. It has a flight model, based on scale model wind tunnel data. The flight model consists of a dozen lookup tables and the math equations to make it fly.&lt;/p&gt;&lt;p&gt;The only problem: it’s written entirely in Fortran.&lt;/p&gt;&lt;p&gt;The source code is available on Github.&lt;/p&gt;&lt;p&gt;You can play the finished project right now on itch.io&lt;/p&gt;&lt;p&gt;Or watch the demo on Youtube:&lt;/p&gt;&lt;p&gt;While I am a professional software engineer and I have worked in the aerospace industry, that doesn’t mean that I understand what I’m doing.&lt;/p&gt;&lt;p&gt;Table of Contents&lt;/p&gt;&lt;head rend="h1"&gt;Introduction&lt;/head&gt;&lt;p&gt;In previous posts on this blog2 3 4, I covered the development of a flight simulator based on the lift equation and hand-tuned parameters. This gives the game designer direct control over a lot of flight parameters. For example, you can directly choose the turn rate and the G-limit of the aircraft, allowing the designer to easily tune the corner speed. This works well for game development, since the designer, and ultimately the player, care more about these high-level parameters.&lt;/p&gt;&lt;p&gt;But real aircraft are designed from the other direction, starting from low-level parameters such as the size, shape, and position of airfoils. Engineers tune every aspect of the aircraft in order to reach those high-level behaviors. But every design decision has trade offs and reaching the goal for one parameter means compromising another. An airliner is designed very differently from a fighter jet because of this.&lt;/p&gt;&lt;p&gt;Simulating all of the low-level parameters is difficult. It’s possible to simulate air flow over the vehicle using computational fluid dynamics (CFD), but this kind of software is difficult to write and even more difficult to verify.&lt;/p&gt;&lt;p&gt;The F-16 flight model from the textbook does not simulate the low-level parameters, but it also doesn’t simulate the high-level parameters either. It sits somewhere in between, so it serves as a useful stepping stone from my previous projects. This project will explore more advanced flight dynamics and explain the limitations of the old flight model as well as the new one.&lt;/p&gt;&lt;head rend="h1"&gt;Aerospace Conventions&lt;/head&gt;&lt;head rend="h2"&gt;Coordinate System&lt;/head&gt;&lt;p&gt;Before we can write any code, we need to understand the conventions used for mathematically modeling aircraft that are used in the aerospace industry. The textbook uses aerospace conventions and to use them in this project, we must convert them to Unity conventions.&lt;/p&gt;&lt;p&gt;The first convention is the coordinate system axes. If you’ve ever visited a graphics programming forum, you might have seen people arguing over how the X, Y, and Z axes should be arranged in their game. Especially whether to use a right handed or left handed, and Y-up or Z-up coordinate system.&lt;/p&gt;&lt;p&gt;This chart by Freya Holmer5 shows the axis choices made by a variety of 3D software tools.&lt;/p&gt;&lt;p&gt;The aerospace industry takes a different path. The most common coordinate system for aircraft is right handed, X forward, Y right, and Z down. This is completely different from every tool shown above. The textbook defines all of it’s math using this convention.&lt;/p&gt;&lt;p&gt;Luckily, translating between two coordinate systems is easy. You just swap the components around and then add or remove minus signs until it all works. Every calculation made by the textbook’s code can be easily translated into Unity’s coordinate system and vice versa.&lt;/p&gt;&lt;p&gt;Writing functions to do this is simple:&lt;/p&gt;&lt;quote&gt;public static Vector3 ConvertVectorToAerospace(Vector3 vector) { return new Vector3(vector.z, vector.x, -vector.y); } public static Vector3 ConvertVectorToUnity(Vector3 vector) { return new Vector3(vector.y, -vector.z, vector.x); }&lt;/quote&gt;&lt;p&gt;When translating euler angles, torque, or other angular values, one additional negation is needed:&lt;/p&gt;&lt;quote&gt;public static Vector3 ConvertAngleToAerospace(Vector3 angle) { // negate when switching handedness return -ConvertVectorToAerospace(angle); } public static Vector3 ConvertAngleToUnity(Vector3 angle) { // negate when switching handedness return -ConvertVectorToUnity(angle); }&lt;/quote&gt;&lt;head rend="h2"&gt;Units&lt;/head&gt;&lt;p&gt;For completely inscrutable reasons, American aerospace texts (and the industry!) insist on using US customary units for everything. All math is defined with these units. Distance is measured in feet. Mass is measured in slugs.&lt;/p&gt;&lt;p&gt;What the hell is a slug? A slug is the unit of mass in the US system. This is the equivalent unit of the kilogram in the metric system. Remember that weight and mass are not the same thing.&lt;/p&gt;\(1 \, \text{kg} * 9.81 \, \text{m/s}^2 = 9.81 \, \text{N}\) \(1 \, \text{slug} * 32.17 \, \text{ft/s}^2 = 32.17 \, \text{lb}\)&lt;p&gt;Mass is the measure of how much an object resists linear force. Moment of inertia is how much the object resists rotational force or torque. The unit for moment of inertia in metric is kg-m2. Thus, the equivalent unit in customary is slug-ft2.&lt;/p&gt;&lt;p&gt;You want to measure how much air mass is in a given volume? That’s gonna be slugs/ft3.&lt;/p&gt;&lt;p&gt;Speed is mostly measured in feet per second, unless you want to know the speed of the aircraft. Then you use knots, which means nautical miles per hour. Importantly, a nautical mile is not the same as a regular mile. A regular mile is 5,280 feet. A nautical mile is ~6,076 feet or exactly 1,852 meters (???).&lt;/p&gt;&lt;p&gt;Do you want to know how fast your ship is sailing? Just throw out this piece of wood tied to a spool of rope. The rope has knots tied at regular intervals. Count the number of knots that unspool in a given time frame. That’s how many knots your ship is making.&lt;/p&gt;&lt;p&gt;Finally, temperature is measured in degrees Rankine. You know how the Kelvin scale is just the Celsius scale adjusted so that 0 Kelvin equals absolute zero? Well Rankine is the same concept applied to Fahrenheit.&lt;/p&gt;\(0 \, \text{R} = \text{absolute zero} \\ 534 \, \text{R} = 75 \, \text{F} = \text{room temperature}\)&lt;p&gt;How the fuck did we ever build the SR-71? 💀&lt;/p&gt;&lt;p&gt;Unity by convention uses metric for all physics units. The flight model in the textbook uses US customary units, so every input and output of this system has to be converted. So we have to add functions to handle converting to and from US customary units. This is easy enough since conversion is just a multiplication or division operation.&lt;/p&gt;&lt;head rend="h2"&gt;Terminology&lt;/head&gt;&lt;p&gt;There are several terms used in aerospace that I need to define. I have used equivalent terms in the previous project, but I will clarify them here.&lt;/p&gt;&lt;p&gt;Alpha (α) refers to the angle of attack.&lt;/p&gt;&lt;p&gt;Beta (β) refers to the angle of side slip.&lt;/p&gt;&lt;p&gt;Longitudinal axis is the X-axis, from tail to nose.&lt;/p&gt;&lt;p&gt;Normal axis is the Z- axis, the vertical axis pointing downwards.&lt;/p&gt;&lt;p&gt;Lateral axis is the Y-axis, or side axis, pointing right.&lt;/p&gt;&lt;p&gt;Phi (φ) is the aircraft’s roll around the X axis.&lt;/p&gt;&lt;p&gt;Theta (θ) is the aircraft’s pitch around the Y axis.&lt;/p&gt;&lt;p&gt;Psi (ψ) is the aircraft’s yaw around the Z axis.&lt;/p&gt;&lt;p&gt;P, Q, and R refer to the angular velocity around the X, Y, and Z axes respectively.&lt;/p&gt;&lt;p&gt;In general you will find that aerodynamics texts are allergic to good variable names. I suspect this is a form of gatekeeping. Or perhaps the authors have to pay by the letter to publish.&lt;/p&gt;&lt;head rend="h1"&gt;Air Data&lt;/head&gt;&lt;p&gt;Airplanes need air to fly [citation needed]. Every behavior of a plane is determined by the movement of air. Therefore it is critically important, for real and simulated planes, to be able to measure the air flowing around it.&lt;/p&gt;&lt;p&gt;Real planes need to measure static and dynamic air pressure to determine how fast the plane is moving. Static pressure is measured by a static pressure port. It’s the pressure that you would measure if you just lifted a pressure meter to the same altitude as the plane. Static pressure decreases with altitude.&lt;/p&gt;&lt;p&gt;Dynamic pressure measures the pressure added by the plane’s forward motion. This requires a pitot tube to measure. As the plane moves forward it rams air into the pitot tube and increases the pressure above the static pressure. The pitot measures the total pressure of the air. By subtracting the static pressure, we can obtain the dynamic pressure.&lt;/p&gt;&lt;p&gt;The static and dynamic pressures can then be used to calculate many of the variables the pilot needs to fly. Most important are the airspeed and altitude of the aircraft. Specifically, these values can be used to calculate the indicated airspeed of the aircraft. Indicated airspeed is calculated directly from the dynamic pressure.&lt;/p&gt;&lt;p&gt;At most subsonic speeds, the dynamic pressure of air flowing over the wings is the most important variable in flight. A plane’s performance can be defined in terms of indicated airspeed. For example, a plane may have a stall speed of 100 knots indicated airspeed. This means that no matter what altitude the plane is at, the indicated airspeed will be 100 when the plane stalls.&lt;/p&gt;&lt;p&gt;This is important since it gives a consistent number for the stall speed regardless of atmospheric conditions. The pressure and density of the air can vary based on weather, temperature, and other factors. So the true airspeed when a stall occurs can be very inconsistent. But as long as the pilot knows the indicated airspeed, they know how their plane will behave.&lt;/p&gt;&lt;p&gt;For this simulator, the calculation has to work backwards. We know the true airspeed and altitude of the plane from the velocity and position of the rigidbody. From that, we can calculate the dynamic pressure. This dynamic pressure is then used for later calculations in the flight model. Additionally, the plane’s speed in mach is calculated here as well.&lt;/p&gt;&lt;p&gt;The original Fortran source code is given:&lt;/p&gt;&lt;quote&gt;SUBROUTINE ADC(VT,ALT,AMACH,QBAR) DATA R0/2.377E-3/ TFAC = 1.0 - 0.703E-5 * ALT T = 519.0 * TFAC IF (ALT .GE. 35000.0) T= 390.0 RHO = R0 * (TFAC**4.14) AMACH= VT/SQRT(1.4*1716.3*T) QBAR = 0.5*RHO*VT*VT C PS = 1715.0 * RHO * T RETURN END&lt;/quote&gt;&lt;p&gt;It turns out, Fortran is actually pretty good at translating formulas. So this code is not as difficult to read as I expected.&lt;/p&gt;&lt;p&gt;To translate this to Unity, we create a class AirDataComputer to perform these calculations. The output of the calculation is the AirData struct.&lt;/p&gt;&lt;quote&gt;public struct AirData { public float altitudeMach; public float qBar; } public class AirDataComputer { /// &amp;lt;summary&amp;gt; /// Density in slugs/ft^3 /// &amp;lt;/summary&amp;gt; public const float SeaLevelDensity = 2.377e-3f; public const float MaxAltitude = 35000.0f; /// &amp;lt;summary&amp;gt; /// Calculates air data based on velocity and altitude /// &amp;lt;/summary&amp;gt; /// &amp;lt;param name="velocity"&amp;gt;Velocity in ft/s&amp;lt;/param&amp;gt; /// &amp;lt;param name="altitude"&amp;gt;Altitude in ft&amp;lt;/param&amp;gt; /// &amp;lt;returns&amp;gt;Air data&amp;lt;/returns&amp;gt; public AirData CalculateAirData(float velocity, float altitude) { ... } }&lt;/quote&gt;&lt;p&gt;Here we can see where the US customary units are used. The density of air at sea level is defined in slugs/ft3. The altitude is defined in feet. Theoretically, these values could be defined using metric. But the implementation of the function depends on even more values defined in customary.&lt;/p&gt;&lt;quote&gt;const float baseTemperature = 519.0f; // sea level temp in R const float minTemperature = 390.0f; // minimum temp in R const float temperatureGradient = 0.703e-5f; // gradient in R / ft altitude = Mathf.Clamp(altitude, 0, MaxAltitude); // calculate temperature in Rankine float temperatureFactor = 1.0f - (temperatureGradient * altitude); float T = Mathf.Max(minTemperature, baseTemperature * temperatureFactor);&lt;/quote&gt;&lt;p&gt;These calculations simulate the change in atmospheric conditions at different altitudes. Particularly important is how the temperature drops at higher altitudes. The temperature gradient approximates the decreases in temperature (in Rankine) as altitude increases.&lt;/p&gt;&lt;p&gt;This flight model supports altitudes up to 35,000 ft. Altitudes above this are not supported. At any altitude above this, the plane will behave as if it were at 35,000 ft. This is because the temperatures at this altitude no longer consistently decrease, as it does in the lower atmosphere. A more advanced atmosphere model would need to be used.&lt;/p&gt;&lt;p&gt;Temperature factor does not drop below about 0.75 in this range, so the resulting temperature T does not fall below 390 R.&lt;/p&gt;&lt;quote&gt;const float gamma = 1.4f; // ratio of specific heats const float gasConstant = 1716.3f; float speedOfSound = Mathf.Sqrt(gamma * gasConstant * T); float altitudeMach = velocity / speedOfSound;&lt;/quote&gt;&lt;p&gt;Now we can calculate the speed of sound at the plane’s current altitude and use it to find the plane’s Mach number. The speed of sound varies with density, which varies with temperature. The speed of sound is equal to the square root of the ratio of specific heat, called gamma, times the gas constant, gasConstant, times the absolute temperature, T.7&lt;/p&gt;&lt;p&gt;Once the speed of sound is known, calculating the Mach number is just a simple division.&lt;/p&gt;&lt;quote&gt;const float densityPower = 4.14f; float rho = SeaLevelDensity * Mathf.Pow(temperatureFactor, densityPower); float qBar = 0.5f * rho * velocity * velocity;&lt;/quote&gt;&lt;p&gt;And finally the dynamic pressure is calculated from the temperature factor. I’ll admit, I don’t understand why exactly the formula is designed this way. It seems to calculate a density factor, called rho, based solely on the temperature factor, raised to an arbitrary value, densityPower.&lt;/p&gt;&lt;p&gt;The NASA reference provides a similar formula using metric units and using a different arbitrary power. I guess this value is just what results from using customary🤷♂️&lt;/p&gt;&lt;p&gt;In any case, this gives us the two air data values we need for the rest of the simulation, dynamic pressure and mach number.&lt;/p&gt;&lt;head rend="h1"&gt;Table Interpolation&lt;/head&gt;&lt;p&gt;Throughout this flight model, various forms of table lookups are used to determine the aircraft’s behavior. Lookup tables are commonly used in flight simulators to represent complex curves and functions. In fact, Unity’s AnimationCurve class in the previous project is used to define a few lookup tables, such as lift coefficient.&lt;/p&gt;&lt;p&gt;This animation curve serves as a 1 dimensional lookup table. The input dimension is AOA and the output value is lift coefficient.&lt;/p&gt;&lt;p&gt;Fortran code doesn’t have the luxury of using AnimationCurves, but a simple table of values with an interpolation function is almost as powerful.&lt;/p&gt;&lt;head rend="h2"&gt;1D Lookup Table&lt;/head&gt;&lt;p&gt;The interpolation functions provided by the textbook look something like this:&lt;/p&gt;&lt;quote&gt;FUNCTION LOOKUP(ALPHA, RESULT) REAL A(-2:9) C DATA A / .770,.241,-.100,-.416,-.731,-1.053, &amp;amp; -1.366,-1.646,-1.917,-2.120,-2.248,-2.229 / C S = 0.2*ALPHA K = INT(S) IF(K.LE.-2) K=-1 IF(K.GE.9) K=8 DA = S - FLOAT(K) L = K + INT(SIGN(1.1,DA)) RESULT = A(K) + ABS(DA)*(A(L)-A(K)) RETURN END&lt;/quote&gt;&lt;p&gt;This function takes alpha (AOA) and uses it to lookup a value from the table. Alpha is a float that can have any value from [-10, 45]. The table “A” represents values for every 5 degree increment of alpha. Note that Fortran supports arrays with an arbitrary starting index, in this case -2. So this table supports indices in the range [-2, 9].&lt;/p&gt;&lt;p&gt;This first step is multiplying alpha by a scaling value to create a float S, which maps alpha to the range [-2, 9]. An integer index K is created from S and then clamped to values one less than the table’s index range. The value DA is calculated as the difference between S and K.&lt;/p&gt;&lt;p&gt;The value L is calculated to be one index away from K, in the same direction as S. So now we have two indices to the table, K and L, which we use to read two values from the table, A(K) and A(L). DA is then used to blend between these table values and produce the final result.&lt;/p&gt;&lt;p&gt;This has two effects. The first is the simplest to understand. If alpha falls within the input range of the table, L and K are selected as the closest table values. For example, if alpha is 12, the two indices would be 2 and 3. The difference between S and K would be less than 1. The values A(2) and A(3) can be read from the table and then interpolated based on the value of DA. This is a fairly normal interpolation calculation.&lt;/p&gt;&lt;p&gt;The other effect is what happens when alpha is outside of the input range of the table. K is guaranteed to not be the first or last index, and L is allowed to be one index off of K. L and K are still valid indices, but the value of DA may be larger than 1. This means when we interpolate between A(L) and A(K), we can extrapolate values for inputs beyond the range of the table.&lt;/p&gt;&lt;p&gt;This means our lookup table can handle values outside of it’s input range. But there is still a limitation. As the input value gets further away from the input range, the extrapolated values will become more and more unrealistic. This allows our plane to fly slightly outside the flight envelope of the lookup tables.&lt;/p&gt;&lt;p&gt;I translated this function into C# like this:&lt;/p&gt;&lt;quote&gt;public static float ReadTable(float[] table, int i, int start) { return table[i - start]; } public static (int k0, int k1, float t) GetLookUpIndex(float value, float scale, int min, int max) { float scaled = value * scale; int K0 = Mathf.Clamp((int)scaled, min, max); float T = scaled - K0; int K1 = K0 + (int)Mathf.Sign(T); return (K0, K1, T); } public static float LinearLookup(float value, float scale, float[] table, int min, int max) { (int k0, int k1, float kT) = GetLookUpIndex(value, scale, min + 1, max - 1); float T = ReadTable(table, k0, min); float U = ReadTable(table, k1, min); float result = T + Math.Abs(kT) * (U - T); return result; }&lt;/quote&gt;&lt;p&gt;GetLookUpIndex calculates K, L, and DA. These variables are renamed to k0, k1, and kT respectively.&lt;/p&gt;&lt;p&gt;ReadTable is a function that maps array indices to a new range, to support arbitrary starting indices like Fortran. (C# surprisingly supports this feature natively, but who actually uses that?)&lt;/p&gt;&lt;p&gt;LinearLookup reads the k0 and k1 values from the array and performs the interpolation. This allows us to calculate values for any input to the lookup table.&lt;/p&gt;&lt;p&gt;Note that the expression “T + Math.Abs(kT) * (U – T)” is effectively equivalent to Mathf.LerpUnclamped.&lt;/p&gt;&lt;head rend="h2"&gt;2D Lookup Table&lt;/head&gt;&lt;p&gt;All of the above code is needed to perform a one dimensional table lookup. Performing this kind of table lookup with two input dimensions is called a bilinear interpolation. Extending this to two dimensions is not that much more complicated.&lt;/p&gt;&lt;p&gt;The two input values to the table form a two dimensional space. Our input values form a two dimensional point. Instead of selecting two array indices K and L, we need to select four array indices. These four indices form a box around our input point. We simply perform 2 one dimensional lookups, and then interpolate between them to produce the final value.&lt;/p&gt;&lt;p&gt;The 2 one dimensional lookups are marked in red. The final interpolation is marked in blue.&lt;/p&gt;&lt;p&gt;Implementing this in C# is a simple extension of the LinearLookup function:&lt;/p&gt;&lt;quote&gt;public static float BilinearLookup(float xValue, float xScale, float yValue, float yScale, float[,] table, int xMin, int xMax, int yMin, int yMax) { (int x0, int x1, float xT) = GetLookUpIndex(xValue, xScale, xMin + 1, xMax - 1); (int y0, int y1, float yT) = GetLookUpIndex(yValue, yScale, yMin + 1, yMax - 1); float T = ReadTable(table, x0, y0, xMin, yMin); float U = ReadTable(table, x0, y1, xMin, yMin); float V = T + Math.Abs(xT) * (ReadTable(table, x1, y0, xMin, yMin) - T); float W = U + Math.Abs(xT) * (ReadTable(table, x1, y1, xMin, yMin) - U); float result = V + (W - V) * Math.Abs(yT); return result; }&lt;/quote&gt;&lt;p&gt;A bilinear interpolation is a very common operation in computer graphics. This is how textures are sampled when placed on 3D geometry.&lt;/p&gt;&lt;p&gt;In the next section, we will see that the engine thrust calculation interpolates between the output of 2 two dimensional tables. Adding this third interpolation means this calculation is now a trilinear interpolation. Interpolating between two tables is how mipmaps are blended together in computer graphics. How neat is that?&lt;/p&gt;&lt;head rend="h1"&gt;Engine&lt;/head&gt;&lt;p&gt;The next system we’re going to add is the engine. In my previous project, the engine was dead simple. The player selected a throttle value from [0, 1], which is multiplied by the plane’s total thrust. This works fine for that simulation and even gives us the ability to reduce thrust to zero, so the plane becomes a glider.&lt;/p&gt;&lt;p&gt;However, it is not a realistic simulation of how a jet engine works. In reality, a jet engine still produces some thrust at idle throttle. And there are more factors that affect thrust output than just the throttle setting.&lt;/p&gt;&lt;p&gt;The thrust output of a jet engine decreases with altitude and increases with speed. As altitude increases, the air gets thinner and the jet engine becomes weaker. But as speed increases, dynamic pressure, and thus pressure in the engine, increases and the engine becomes stronger. These two effects need to be considered at the same time to find the thrust output at any given moment.&lt;/p&gt;&lt;p&gt;Additionally, we have to consider how jet engines behave in terms of RPM. Just like piston engines (like in a typical car), jet engines have rotating components whose speed increases with throttle. The max RPM of a jet is much higher than a piston engine, however the range of possible RPM is smaller.&lt;/p&gt;&lt;p&gt;The engine in an F-16 has a maximum RPM of about 14,000. This is at the maximum non-afterburner power, called military power. When throttle is reduced to the lowest setting, idle, the RPM falls to about 8,400 RPM or about 60% of the max. Planes of course do not have a transmission like a car does, so this range of RPM also covers the range of thrust needed at all stages of flight.&lt;/p&gt;&lt;p&gt;At idle throttle, the engine runs at 60% max RPM, but only produces 8% of max thrust. At military power, the engine runs at 100% RPM and produces 100% thrust.&lt;/p&gt;&lt;p&gt;Military power is selected when the pilot moves the throttle lever to 77% of it’s max setting. Pushing the throttle beyond that engages the afterburner and produces even more thrust. Setting the throttle lever to 100% is called max power. Max power provides about 57% more thrust than military power. Engine RPM does not increase when using afterburner.&lt;/p&gt;&lt;p&gt;A significant difference between a piston engine and a jet engine is how fast the engine can change RPM. In a car, you can put the transmission in neutral and rev the engine up and down very quickly. But a jet engine is much slower to respond to changes in throttle, regardless of how fast the pilot moves the throttle lever. Generally, it can take several seconds to go from idle to military power or vice versa.&lt;/p&gt;&lt;p&gt;The reasons why jet engines are slower to change RPM are complicated. The change in throttle is managed by a computer to avoid compressor stall, which can cause damage or shut down of the engine. This computer will change engine parameters slowly to avoid compressor stall or any other problems that might be caused by moving the throttle too quickly.&lt;/p&gt;&lt;head rend="h2"&gt;Power&lt;/head&gt;&lt;p&gt;The behavior of the jet engine is included in the textbook’s flight model. RPM is not explicitly modeled, but is abstracted as power. The pilot chooses a commanded power level and the engine’s current power setting will move towards this over time. This behavior is spring-like, thus a larger difference will cause the current power setting to change faster. It takes about 2 seconds to increase from idle to military power in this flight model.&lt;/p&gt;&lt;p&gt;The first step is to translate the player’s throttle setting into engine power. This is a fairly simple function that maps military power, or 77% throttle, to 50% power. Full afterburner, or 100%, is mapped to 100% power. This is called the “throttle gearing”, but don’t confuse that with a car’s gearing. It’s much simpler.&lt;/p&gt;&lt;quote&gt;FUNCTION TGEAR(THTL) ! Power command v. thtl. relationship IF(THTL.LE.0.77) THEN TGEAR = 64.94*THTL ELSE TGEAR = 217.38*THTL-117.38 END IF RETURN END&lt;/quote&gt;&lt;p&gt;In C#, this is translated as:&lt;/p&gt;&lt;quote&gt;public static float CalculateThrottleGear(float throttle) { // maps throttle 0 - 0.77 to power 0% - 50% // maps throttle 0.77 - 1.0 to power 50% - 100% float power; if (throttle &amp;lt;= militaryPowerThrottle) { power = 64.94f * throttle; } else { power = 217.38f * throttle - 117.38f; } return power; }&lt;/quote&gt;&lt;p&gt;Those constants might seem weird, but they just define two lines with different slopes. The two lines intersect when the throttle is 0.77.&lt;/p&gt;&lt;p&gt;The player’s throttle setting is used to calculate the commanded power level. The rate of change of engine power also depends on the current power level. This rate is calculated in the functions PDOT and RTAU:&lt;/p&gt;&lt;quote&gt;FUNCTION PDOT(P3,P1) ! PDOT= rate of change of power IF (P1.GE.50.0) THEN ! P3= actual power, P1= power command IF (P3.GE.50.0) THEN T=5.0 P2=P1 ELSE P2=60.0 T=RTAU(P2-P3) END IF ELSE IF (P3.GE.50.0) THEN T=5.0 P2=40.0 ELSE P2=P1 T=RTAU(P2-P3) END IF END IF PDOT=T*(P2-P3) RETURN END FUNCTION RTAU(DP) ! used by function PDOT IF (DP.LE.25.0) THEN RTAU=1.0 ! reciprocal time constant ELSE IF (DP.GE.50.0)THEN RTAU=0.1 ELSE RTAU=1.9-.036*DP END IF RETURN END&lt;/quote&gt;&lt;p&gt;PDOT means power rate of change. In C#, this is translated as:&lt;/p&gt;&lt;quote&gt;float CalculatePowerRateOfChange(float actualPower, float commandPower) { // calculates how fast power output should change based on commanded power float T; float p2; if (commandPower &amp;gt;= 50.0) { if (actualPower &amp;gt;= 50.0) { T = 5.0f; p2 = commandPower; } else { p2 = 60.0f; T = CalculateRTau(p2 - actualPower); } } else { if (actualPower &amp;gt;= 50.0) { T = 5.0f; p2 = 40.0f; } else { p2 = commandPower; T = CalculateRTau(p2 - actualPower); } } float pdot = T * (p2 - actualPower); return pdot; } float CalculateRTau(float deltaPower) { float rTau; if (dp &amp;lt;= 25.0) { rTau = 1.0f; } else if (dp &amp;gt;= 50.0) { rTau = 0.1f; } else { rTau = 1.9f - 0.036f * dp; } return rTau; }&lt;/quote&gt;&lt;p&gt;Power rate of change is the velocity of the power level. The most important line is this:&lt;/p&gt;&lt;quote&gt;float pdot = T * (p2 - actualPower);&lt;/quote&gt;&lt;p&gt;The velocity depends on the quantity (p2 – actualPower). Let’s call this value deltaPower. A larger deltaPower means a larger velocity. This is scaled by the factor T. The complexity comes from selecting the values for p2 and T. p2 is sometimes the commandPower value. T is sometimes the result of calling CalculateRTau.&lt;/p&gt;&lt;p&gt;These values are selected by the if statements above. These check for two conditions, the commandedPower being above 50%, and the actualPower being above 50%. This is checking whether the afterburner is being requested, and whether the afterburner is currently active. Remember that afterburner starts at 77% throttle, but 50% power.&lt;/p&gt;&lt;p&gt;If the afterburner is not active, then the T is given the value of CalculateRTau. If it is active, then T is given the constant value of 5.0. This matches with our expectation of how the engine’s RPM changes. When not in afterburner, the engine RPM should change slowly, thus power changes slowly. When in afterburner, fuel flow into the afterburner can change quickly, thus power changes quickly.&lt;/p&gt;&lt;p&gt;If we look at the function CalculateRTau, we can see that T can vary in the range [0.1, 1.0]. This depends on deltaPower. When the engine is not in afterburner, T can be at most 1.0. In afterburner, T is 5.0. That means power can change about 5 times faster when in afterburner. When multiplied with deltaPower, pdot can be as large as 250% per second.&lt;/p&gt;&lt;p&gt;The smallest value of T occurs when deltaPower is 50 or greater. This occurs when actualPower is 0 and commanded power is 50%, for example. This will cause the power rate of change to be quite small at only 6% per second. Note that this is simply the instantaneous rate of change. As the actual power rises, T will become larger and the rate of change will increase.&lt;/p&gt;&lt;p&gt;Now the reason why p2 is used instead of commandedPower is to handle the case where commandedPower is over 50% and actualPower is below 50%, or vice versa. The pilot is requesting afterburner, but the engine has not reached military power yet. In that case, deltaPower would become very large and the simulation would change power levels too quickly. To avoid this, an arbitrary constant is chosen that is on the opposite side of 50%, but not very far.&lt;/p&gt;&lt;p&gt;So if the actualPower is 0%, but commandedPower is 100%, p2 is set to the value of 60. This limits deltaPower to a maximum value of 60, instead of 100. And in the case where actualPower is 100% and commandedPower is 0%, deltaPower is limited to -60.&lt;/p&gt;&lt;p&gt;Another behavior of this code is that CalculateRTau does not handle cases where deltaPower is negative. In this case, the function returns 1, the highest value it can return. This means that the power can decrease 10 times faster than it can increase, in the most extreme case.&lt;/p&gt;&lt;p&gt;I don’t know if this is an intentional effect. This may match the behavior of real jet engines, or it may be an oversight by the authors. You can play with the behavior by adding a few calls to Mathf.Abs().&lt;/p&gt;&lt;p&gt;The practical effect of all this is that the plane’s power will lag behind the player’s throttle setting. The pilot needs to make sure that they provide enough time for the power level to change when moving the throttle.&lt;/p&gt;&lt;p&gt;The HUD for this project is mostly reused from the previous flight sim project. But the throttle indicator must be updated, since it can’t show the difference between commanded power and current power.&lt;/p&gt;&lt;p&gt;Previously, the red bar used to show the player’s throttle setting. This worked fine since power lag was not modeled. In this project, the red bar shows the engine’s current power level. I added a triangle marker to show the commanded power setting.&lt;/p&gt;&lt;p&gt;As you move the throttle, you’ll see that current power level changes quickly when there is a large difference from commanded power, and it slows down as it approaches. And when the engine enters afterburner, the power level changes very quickly.&lt;/p&gt;&lt;head rend="h2"&gt;Thrust&lt;/head&gt;&lt;p&gt;Engine power is a fairly abstract variable in this flight model. It doesn’t really correspond to any physical variable. Once we calculate the current power, we use it to find the thrust generated by the engine. Thrust in this flight model is defined in terms of pounds-force (lbf).&lt;/p&gt;&lt;p&gt;Thrust is defined by a group of look up tables. Each table has two dimensions as input, mach number and altitude, and the output is thrust. This gives us different thrust values in different flight conditions. Mach is input as 0.0 to 1.0 mach, in increments of 0.2 mach. Altitude is input as 0 to 50,000 ft, in increments of 10,000 ft. In other words, the table has dimensions 6×6.&lt;/p&gt;&lt;p&gt;The lookup tables in this flight model correspond to idle power, military power, and max power (full afterburner). The engine’s power value is used to perform a third interpolation between the output values of these tables. This makes the thrust calculation a trilinear interpolation.&lt;/p&gt;&lt;p&gt;At idle throttle, the thrust output has 100% influence from the idle table. When the throttle is halfway to military power, the output has 50% influence from the idle table and 50% influence from the military table. Above military power, the output will have some influence from the military power table and the max power table.&lt;/p&gt;&lt;p&gt;The code to read one table in Fortran is given:&lt;/p&gt;&lt;quote&gt;DATA A/ [IDLE TABLE OMITTED] DATA B/ [MIL TABLE OMITTED] DATA C/ [MAX TABLE OMITTED] H=0.0001*ALT I=INT(H) IF (I.GE.5) I=4 DH=H-FLOAT(I) RM=5.*RMACH M=INT(RM) IF (M.GE.5) M=4 DM=RM-FLOAT(M) CDH=1.0-DH&lt;/quote&gt;&lt;p&gt;These parameters are used to perform the table lookups:&lt;/p&gt;&lt;quote&gt;TMIL= S + (T-S)*DM IF (POW.LT.50.0) THEN S= A(I,M)*CDH + A(I+1,M)*DH T= A(I,M+1)*CDH + A(I+1,M+1)*DH TIDL= S + (T-S)*DM THRUST= TIDL + (TMIL-TIDL)*POW/50.0 ELSE S= C(I,M)*CDH + C(I+1,M)*DH T= C(I,M+1)*CDH + C(I+1,M+1)*DH TMAX= S + (T-S)*DM THRUST= TMIL + (TMAX-TMIL)*(POW-50.0)*0.02 END IF&lt;/quote&gt;&lt;p&gt;The output of the military power table, TMIL, is always calculated. If the power level is under 50, then the idle table is calculated as well, TIDL. Otherwise the max table is calculated, TMAX. The output of the two table lookups is then interpolated again to calculate the final thrust value, THRUST.&lt;/p&gt;&lt;p&gt;Altogether, this forms a trilinear lookup. To translate this to C#, we call BilinearLookup twice. Then those two results are interpolated based on the power level:&lt;/p&gt;&lt;quote&gt;float InterpolateThrust(float thrust1, float thrust2, float power) { float result = Mathf.LerpUnclamped(thrust1, thrust2, power * 0.02f); return result; } float CalculateThrust(float power, float altitude, float rMach) { float a = Mathf.Max(0, altitude); float m = Mathf.Max(0, rMach); float thrust; float thrustMilitary = Table.BilinearLookup(a, 0.0001f, m, 5, militaryPowerTable, 0, 6, 0, 6); // perform trilinear interpolation if (power &amp;lt; 50.0) { float thrustIdle = Table.BilinearLookup(a, 0.0001f, m, 5, idlePowerTable, 0, 6, 0, 6); thrust = InterpolateThrust(thrustIdle, thrustMilitary, power); } else { float thrustMax = Table.BilinearLookup(a, 0.0001f, m, 5, maxPowerTable, 0, 6, 0, 6); thrust = InterpolateThrust(thrustMilitary, thrustMax, power - 50.0f); } return thrust; }&lt;/quote&gt;&lt;p&gt;The output of this calculation is the plane’s thrust in pounds-force. A simple unit conversion allows us to apply it in newtons to a Unity rigidbody:&lt;/p&gt;&lt;quote&gt;void UpdateThrust(float dt) { engine.ThrottleCommand = Throttle; engine.Mach = Mach; engine.Altitude = AltitudeFeet; engine.Update(dt); Rigidbody.AddRelativeForce(new Vector3(0, 0, engine.Thrust * poundsForceToNewtons)); }&lt;/quote&gt;&lt;head rend="h1"&gt;Forces&lt;/head&gt;&lt;head rend="h2"&gt;Lift force vs Normal force&lt;/head&gt;&lt;p&gt;In the previous flight sim project, we calculated a plane’s lift force using the angle of attack and an AnimationCurve. This is the very core of the flight simulator and is what enables flight. The flight model from the textbook does not calculate lift force.&lt;/p&gt;&lt;p&gt;Instead what this flight model calculates is normal force. Recall that lift force is perpendicular to the aircraft’s velocity vector. Normal force is perpendicular to the aircraft’s nose. This distinction is subtle at a low angle of attack, but it becomes significant at a high angle of attack.&lt;/p&gt;&lt;p&gt;There are two more analogous forces to consider, drag and axial force. Drag is always exactly opposite to the aircraft’s velocity vector while axial force is opposite the aircraft’s nose. Lift and drag are perpendicular to each other and form one set of forces. Normal and axial form another perpendicular set. It’s important to understand that these two sets of forces are equally valid. In fact, they are simply the consequence of choosing different basis vectors for measuring force.&lt;/p&gt;&lt;p&gt;And of course there is the side force that points to the right. These forces are applied on the normal, side, and longitudinal (axial) axes, which are equivalent to the X, Y, and Z axes.&lt;/p&gt;&lt;p&gt;Imagine all of the forces being produced by the aircraft are summed into a single force vector. This vector would be strongly vertical, because the plane is generating enough lift to support it’s own weight, and somewhat backwards because of drag. When this vector is projected onto the lift vector, the result is the lift force. When it’s projected onto the normal vector, the result is the normal force.&lt;/p&gt;&lt;p&gt;Choosing to represent these forces as lift/drag or normal/axial is arbitrary. The textbook flight model only deals with normal/axial force. I suspect that’s because it’s easier to measure the physical forces when using normal/axial forces in a wind tunnel, since those are always aligned with the plane’s local axes.&lt;/p&gt;&lt;p&gt;The normal force is very similar to lift for low angles of attack. Lift force peaks at the stall AOA and then declines. Normal force similarly peaks at stall AOA, but it then increases again to peak at 90 AOA, with an even higher force. 90 degrees AOA means the plane is falling downwards belly first, so it’s no longer producing lift over the wings. Instead the normal vector and the drag vector are now aligned. All of the drag force projected onto the normal vector results in a large normal force.&lt;/p&gt;&lt;p&gt;We can calculate the lift force from the normal and axial force. Both normal and axial force may contribute to the lift force, so a complete projection needs to use both. This is the formula:&lt;/p&gt;\(\text{Lift} = \text{normal} * \cos{(\text{alpha})} – \text{axial} * \sin{(\text{alpha})}\)&lt;p&gt;When we apply this formula to the normal force from the textbook, this is the result:&lt;/p&gt;&lt;p&gt;Oh wait, that’s upside down. Recall that the Z axis points downward in this coordinate system. So a negative Z value is an upwards force. Still though, the chart is a little confusing. I inverted the values below to make it more intuitive.&lt;/p&gt;&lt;p&gt;We can see at 90 degrees AOA, the normal force stays relatively high while the lift force drops to zero. This roughly matches with the chart from aerospaceweb.org above.&lt;/p&gt;&lt;p&gt;Also note that the textbook only provides table values up to 45 degrees AOA. The extrapolation of the table lookup function is what allows us to have normal force values up to 90 degrees AOA. Additionally, the table only goes down to -10 degrees AOA. We can extrapolate further, but the data will be inaccurate by -30 degrees AOA. Large negative AOA values will quickly become inaccurate. So when you’re flying, don’t do that.&lt;/p&gt;&lt;p&gt;Anyways, adding these forces to our simulator is easy. The functions are fairly simple. They are called CZ, CY, and CX. These calculate the coefficients of force on the Z, Y, and X axes respectively. Note that these functions are the coefficients, not the force values themselves. They are used to calculate the force later on.&lt;/p&gt;&lt;p&gt;CZ or the normal coefficient is calculated like this:&lt;/p&gt;&lt;quote&gt;FUNCTION CZ(ALPHA,BETA,EL) REAL A(-2:9) C DATA A/ [TABLE OMITTED] C S = 0.2*ALPHA K = INT(S) IF(K.LE.-2) K=-1 IF(K.GE.9) K=8 DA = S - FLOAT(K) L = K + INT(SIGN(1.1,DA)) S = A(K) + ABS(DA)*(A(L)-A(K)) CZ = S*(1-(BETA/57.3)**2) - .19*(EL/25.0) C RETURN END&lt;/quote&gt;&lt;p&gt;The bulk of this code is just the table interpolation function. The table only depends on ALPHA and the output is S. The only new part here is the last line, where CZ is assigned a value. S is reduced based on the value of BETA and another term is subtracted based on EL, the elevator angle.&lt;/p&gt;&lt;p&gt;This is very easy to translate to C#:&lt;/p&gt;&lt;quote&gt;float GetZAxisForceCoefficient(float alpha, float beta, float elevator) { float S = Table.LinearLookup(alpha, 0.2f, zAxisTable, -2, 10); float CZ = S * (1 - Mathf.Pow(beta * Mathf.Deg2Rad, 2)) - 0.19f * (elevator / 25.0f); return CZ; }&lt;/quote&gt;&lt;p&gt;CY or the side coefficient is even simpler. It doesn’t even have a lookup table. Side force is perpendicular to both normal and axial force.&lt;/p&gt;&lt;quote&gt;FUNCTION CY(BETA,AIL,RDR) CY = -.02*BETA + .021*(AIL/20.0) + .086*(RDR/30.0) C RETURN END&lt;/quote&gt;&lt;p&gt;Side coefficient depends solely on beta, aileron angle, and rudder angle.&lt;/p&gt;&lt;p&gt;In C#:&lt;/p&gt;&lt;quote&gt;float GetYAxisForceCoefficient(float beta, float aileron, float rudder) { float CY = -0.02f * beta + 0.021f * (aileron / 20.0f) + 0.086f * (rudder / 30.0f); return CY; }&lt;/quote&gt;&lt;p&gt;CX or the axial coefficient is basically what creates drag on the aircraft. This function is a little more complicated since it performs a bilinear interpolation, with alpha and elevator angle as the inputs.&lt;/p&gt;&lt;quote&gt;FUNCTION CX(ALPHA,EL) REAL A(-2:9,-2:2) C DATA A/ [TABLE OMITTED] C S = 0.2*ALPHA K = INT(S) IF(K.LE.-2) K=-1 IF(K.GE.9) K=8 DA = S - FLOAT(K) L = K + INT(SIGN(1.1,DA)) S = EL/12.0 M = INT(S) IF(M.LE.-2) M=-1 IF(M.GE.2) M=1 DE = S - FLOAT(M) N = M + INT(SIGN(1.1,DE)) V = A(K,M) + ABS(DA)*(A(L,M)-A(K,M)) W = A(K,N) + ABS(DA)*(A(L,N)-A(K,N)) CX = V + (W-V)*ABS(DE) C RETURN END&lt;/quote&gt;&lt;p&gt;Thanks to the table lookup functions, this is easy to translate to C#:&lt;/p&gt;&lt;quote&gt;float GetXAxisForceCoefficient(float alpha, float elevator) { float result = Table.BilinearLookup(alpha, 0.2f, elevator, 1f / 12f, xAxisTable, -2, 9, -2, 2); return result; }&lt;/quote&gt;&lt;p&gt;These three functions define all of the linear force coefficients applied to the aircraft during flight. None of these will rotate the aircraft. That is handled by a different and more complicated set of calculations.&lt;/p&gt;&lt;head rend="h1"&gt;Moments&lt;/head&gt;&lt;p&gt;Moment is another word for torque. (There is a subtle difference, but who cares?🤓) The F-16 flight model uses another set of look up tables to compute the moment for the aircraft.&lt;/p&gt;&lt;p&gt;In the previous flight sim, torque was not actually calculated. Instead, the flight model calculates the angular acceleration directly. This ignores the mass of the plane when applying the torque. This is a simplification. A more realistic flight model would take into account the mass of the aircraft when applying torque.&lt;/p&gt;&lt;p&gt;Note that mass is not sufficient to model rotations. When it comes to rotation, the analogy to mass is called moment of inertia. Just like mass is the property that measures an object’s resistance to force, moment of inertia is the resistance to torque. But unlike mass, moment of inertia can differ on all 3 axes. This means a torque on the X axis will result in a different angular acceleration than the same torque on the Y axis, for example.&lt;/p&gt;&lt;p&gt;Moment of inertia is a four-dimensional value, called AXX, AYY, AZZ, and AXZ in the textbook code. This flight model contains it’s own calculations for angular velocity using these moment of inertia values.&lt;/p&gt;&lt;p&gt;The flight model contains several functions that calculate the moment of the aircraft. The three basic functions are called CM, CL, and CN. These calculate the moments around the Y, X, and Z axes, AKA pitch, roll, and yaw, respectively. (L stands for longitudinal, which is the X axis. N stands for normal, which is the Z axis. M stands for… something)&lt;/p&gt;&lt;p&gt;These functions are all simple look up tables. CM (pitch) uses alpha and elevator angle as the input. CL (roll) and CN (yaw) use alpha and beta as the input. CM is basically the same as the other lookup table functions. CL and CN are similar to each other since they both use a symmetric table. This is because the plane is symmetric on the lateral axis, so a single table can represent the left and right sides. Their final output is then multiplied by the sign of beta.&lt;/p&gt;&lt;quote&gt;FUNCTION CL(ALPHA,BETA) REAL A(-2:9,0:6) DATA A/ [DATA OMITTED] S = 0.2*ALPHA K = INT(S) IF(K.LE.-2) K=-1 IF(K.GE.9) K=8 DA = S - FLOAT(K) L = K + INT(SIGN(1.1,DA)) S = .2*ABS(BETA) M = INT(S) IF(M.EQ.0) M=1 IF(M.GE.6) M=5 DB = S - FLOAT(M) N = M + INT(SIGN(1.1,DB)) T = A(K,M) U = A(K,N) V = T + ABS(DA)*(A(L,M) - T) W = U + ABS(DA)*(A(L,N) - U) DUM = V + (W - V) * ABS(DB) CL = DUM + SIGN(1.0,BETA) RETURN END&lt;/quote&gt;&lt;p&gt;Note that there is an error in the textbook code. The final operation “CL = DUM + SIGN(…)” should use multiplication instead of addition. Otherwise this operation doesn’t make any sense.&lt;/p&gt;&lt;p&gt;When translated into C#:&lt;/p&gt;&lt;quote&gt;float GetYAxisMoment(float alpha, float elevator) { float result = Table.BilinearLookup(alpha, 0.2f, elevator, 1f / 12f, yMomentTable, -2, 9, -2, 2); return result; } float GetXAxisMoment(float alpha, float beta) { float DUM = Table.BilinearLookup(alpha, 0.2f, Mathf.Abs(beta), 0.2f, xMomentTable, -2, 9, 0, 7); float CL = DUM * Mathf.Sign(beta); return CL; } float GetZAxisMoment(float alpha, float beta) { float DUM = Table.BilinearLookup(alpha, 0.2f, Mathf.Abs(beta), 0.2f, zMomentTable, -2, 9, 0, 7); float CL = DUM * Mathf.Sign(beta); return CL; }&lt;/quote&gt;&lt;p&gt;Notice that CM takes “elevator” as an argument, so this is where the elevator’s turning effect is calculated. But CL and CN do not take any control surface as an argument. These functions only apply moment based on alpha and beta. For example, at high angles of sideslip, the plane tends to roll. On real planes, this is caused by wing sweep. In this flight model, it’s caused by the CL function.&lt;/p&gt;&lt;p&gt;Elevators are applied in CM, but rudder and ailerons are not. Those are actually handled by four more functions, called DLDA, DLDR, DNDA, and DNDR. The names are cryptic, but it just means which axis is affected from which control surface.&lt;/p&gt;&lt;p&gt;The “L” stands for longitudinal, so DLDA is the longitudinal moment from the ailerons, A. DLDR is the longitudinal moment from the rudder, R. The “N” stands for normal, so those functions are the normal axis moment from aileron and rudders.&lt;/p&gt;&lt;p&gt;These four functions are eventually summed with the CL and CN functions above. These functions mean that roll is affected by aileron and rudder, and yaw is affected by aileron and rudder.&lt;/p&gt;&lt;head rend="h2"&gt;Damping&lt;/head&gt;&lt;p&gt;There is one more set of coefficients that must be calculated. These are the damping coefficients and they depend solely on alpha. These values are stored in 9 distinct 1D lookup tables. The code for these lookups is the same as the other lookup code.&lt;/p&gt;&lt;p&gt;These values are stored in an array of length 9 called D.&lt;/p&gt;&lt;p&gt;Damping is the moment that opposes the angular velocity of an aircraft, essentially angular drag. They affect the other moment values in somewhat complex ways. For example, some of them are combined with the plane’s current bank value to affect the roll moment.&lt;/p&gt;&lt;p&gt;What isn’t clear is what the damping values actually represent. In the C# code, I added these comments explaining their meaning:&lt;/p&gt;&lt;quote&gt;// D[0] = CXq // D[1] = CYr // D[2] = CYp // D[3] = CZq // D[4] = Clr // D[5] = Clp // D[6] = Cmq // D[7] = Cnr // D[8] = Cnp&lt;/quote&gt;&lt;p&gt;Hope this helps!&lt;/p&gt;&lt;p&gt;The best I can tell is that “CXq” is the damping moment on the X axis relative to q, which is the angular velocity around the Y axis. The other damping values follow this naming scheme.&lt;/p&gt;&lt;p&gt;This is yet another example of aerodynamics texts with poor variable names.&lt;/p&gt;&lt;head rend="h1"&gt;Complete Flight Model&lt;/head&gt;&lt;p&gt;With all of the individual coefficients defined, we can now implement the complete flight model for the F-16. This flight model actually contains it’s own physics integrator. The text provides it’s own code for calculating velocity and angular velocity from the aerodynamic forces.&lt;/p&gt;&lt;p&gt;Strictly speaking, we don’t need to use this code since Unity allows us to provide those same forces and then performs the physics calculation for us. Setting the mass is easy enough, we just have to convert slugs to kilograms. The textbook code calculates acceleration by dividing the force by the aircraft mass. We simply omit this division, convert the forces to newtons, and apply it to the rigidbody.&lt;/p&gt;&lt;p&gt;However the moment of inertia is more complicated. The textbook provides the 4 dimensional MOI values, but Unity expects a 3 dimensional inertia tensor. That inertia tensor is then rotated by a quaternion called “inertiaTensorRotation”. I have no idea how to calculate this quaternion from the textbook’s provided value.&lt;/p&gt;&lt;p&gt;Therefore, we continue to use the textbook’s code for applying moment and simply apply the resulting angular acceleration to the rigidbody.&lt;/p&gt;&lt;p&gt;The Fortran code for the flight model is concise, yet scrutable. The first step is to read the plane’s current state from the input state vector X. This is simply an array that contains all of the relevant data for this frame.&lt;/p&gt;&lt;quote&gt;VT= X(1); ALPHA= X(2)*RTOD; BETA= X(3)*RTOD PHI=X(4); THETA= X(5); PSI= X(6) P= X(7); Q= X(8); R= X(9); ALT= X(12); POW= X(13)&lt;/quote&gt;&lt;p&gt;VT is the plane’s velocity in feet per second.&lt;/p&gt;&lt;p&gt;ALPHA and BETA are the plane’s AOA and AOS in degrees. RTOD is the constant to convert from radians to degrees.&lt;/p&gt;&lt;p&gt;PHI, THETA, and PSI are the plane’s roll, pitch, and yaw in radians.&lt;/p&gt;&lt;p&gt;P, Q, and R are the plane’s angular velocities (or roll rate, pitch rate, and yaw rate) in radians per second.&lt;/p&gt;&lt;p&gt;ALT is the altitude in feet.&lt;/p&gt;&lt;p&gt;POW is the current power level of the engine (0 – 100).&lt;/p&gt;&lt;p&gt;The air data computer (ADC) and engine model are then called using these variables:&lt;/p&gt;&lt;quote&gt;CALL ADC(VT,ALT,AMACH,QBAR); CPOW= TGEAR(THTL) XD(13) = PDOT(POW,CPOW); T= THRUST(POW,ALT,AMACH)&lt;/quote&gt;&lt;p&gt;The ADC function populates the variables AMACH and QBAR, which are the altitude mach and dynamic pressure.&lt;/p&gt;&lt;p&gt;CPOW is the pilot’s commanded power setting. That is, the power level returned by calling the throttle gear function, TGEAR, on the throttle lever position, THTL.&lt;/p&gt;&lt;p&gt;The array XD is the output state vector. Specifically, it holds the calculated derivative for every input value. XD(13) is set to the value calculated by PDOT, which is the velocity of the power level.&lt;/p&gt;&lt;p&gt;T is the thrust in pounds-force output by the engine, calculated using the power level, altitude, and altitude mach.&lt;/p&gt;&lt;p&gt;Then the aerodynamic coefficients are calculated using the force and moment functions:&lt;/p&gt;&lt;quote&gt;CXT = CX (ALPHA,EL) CYT = CY (BETA,AIL,RDR) CZT = CZ (ALPHA,BETA,EL) DAIL= AIL/20.0; DRDR= RDR/30.0 CLT = CL(ALPHA,BETA) + DLDA(ALPHA,BETA)*DAIL &amp;amp; + DLDR(ALPHA,BETA)*DRDR CMT = CM(ALPHA,EL) CNT = CN(ALPHA,BETA) + DNDA(ALPHA,BETA)*DAIL &amp;amp; + DNDR(ALPHA,BETA)*DRDR&lt;/quote&gt;&lt;p&gt;The values CXT, CYT, and CZT are the coefficients on the X, Y, and Z axes, calculated by calling their respective coefficient functions.&lt;/p&gt;&lt;p&gt;EL, AIL, and RDR are the current position of the elevators, ailerons, and rudder in degrees. DAIL and DRDR are simply the angle of these surfaces divided by the max angle. Their range is [-1, 1].&lt;/p&gt;&lt;p&gt;The values CLT, CMT, and CNT are the moment coefficients on the longitudinal, m’lateral, and normal axes. Note that CM calculates moment caused by the elevator position. The effects of the other control surfaces are calculated in the DLDA, DLDR, DNDA, and DNDR functions.&lt;/p&gt;&lt;p&gt;Then some other values are calculated and the damping coefficients are added to the above values:&lt;/p&gt;&lt;quote&gt;TVT= 0.5/VT; B2V= B*TVT; CQ= CBAR*Q*TVT CALL DAMP(ALPHA,D) CXT= CXT + CQ * D(1) CYT= CYT + B2V * ( D(2)*R + D(3)*P ) CZT= CZT + CQ * D(4) CLT= CLT + B2V * ( D(5)*R + D(6)*P ) CMT= CMT + CQ * D(7) + CZT * (XCGR-XCG) CNT= CNT + B2V*(D(8)*R + D(9)*P) - CYT*(XCGR-XCG) * CBAR/B&lt;/quote&gt;&lt;p&gt;I’ll be honest, I straight up don’t know what any of these values are or why they are being applied like this. The effect appears to be angular damping (AKA angular drag) which opposes the plane’s angular velocity.&lt;/p&gt;&lt;p&gt;The value (XCGR – XCG) is the center of gravity reference minus the current center of gravity. This allows us to alter the center of gravity of the aircraft and see how that affects stability.&lt;/p&gt;&lt;p&gt;XCGR is 0.35 for this flight model. XCG is 0.35 by default. XCG is the normalized position of the center of gravity, with a possible range of [0, 1]. This means that when XCG is 0.35, the term (XCGR – XCG) becomes zero and the aircraft is balanced around it’s center of gravity.&lt;/p&gt;&lt;p&gt;The center of gravity term affects CMT and CNT, which are the pitch and yaw axes. The roll axis is not affected.&lt;/p&gt;&lt;p&gt;The next block of code is fun:&lt;/p&gt;&lt;quote&gt;CBTA = COS(X(3)); U=VT*COS(X(2))*CBTA V= VT * SIN(X(3)); W=VT*SIN(X(2))*CBTA STH = SIN(THETA); CTH= COS(THETA); SPH= SIN(PHI) CPH = COS(PHI) ; SPSI= SIN(PSI); CPSI= COS(PSI) QS = QBAR * S ; QSB= QS * B; RMQS= QS/MASS GCTH = GD * CTH ; QSPH= Q * SPH AY = RMQS*CYT ; AZ= RMQS * CZT&lt;/quote&gt;&lt;p&gt;This writhing mass of arithmetic is simply pre-calculating a lot of the values that are used to calculate the aerodynamic forces. Some of these values are used in multiple places, so to avoid repeating them, they are pulled out of those equations and placed here.&lt;/p&gt;&lt;p&gt;This is essentially the “common subexpression” optimization pass of a compiler, but applied manually.&lt;/p&gt;&lt;p&gt;The important variables are U, V, and W, which is the plane’s velocity on the X, Y, and Z axes respectively.&lt;/p&gt;&lt;p&gt;QS is QBAR (dynamic pressure) times S (wing area).&lt;/p&gt;&lt;p&gt;Now the aerodynamic forces are calculated:&lt;/p&gt;&lt;quote&gt;UDOT = R*V - Q*W - GD*STH + (QS * CXT + T)/MASS VDOT = P*W - R*U + GCTH * SPH + AY WDOT = Q*U - P*V + GCTH * CPH + AZ DUM = (U*U + W*W) xd(1) = (U*UDOT + V*VDOT + W*WDOT)/VT xd(2) = (U*WDOT - W*UDOT) / DUM xd(3) = (VT*VDOT- V*XD(1)) * CBTA / DUM&lt;/quote&gt;&lt;p&gt;Once again, I don’t actually understand what I’m reading. UDOT etc are the accelerations on each axis. These values are then used to update the output state vector xd(1), xd(2), and xd(3), which are the VT, ALPHA, and BETA that will be used in the next frame.&lt;/p&gt;&lt;p&gt;It appears that this flight model is calculating the change in alpha and beta directly from the change in velocity. This is not necessary in C#, since we can calculate alpha and beta fresh in each frame.&lt;/p&gt;&lt;p&gt;But I don’t fully understand how UDOT is calculated. R and Q are angular velocities, so multiplying them with linear velocity doesn’t make any sense. Perhaps this is some physics equation that I’m not familiar with.&lt;/p&gt;&lt;p&gt;GD * STH is the gravity acceleration times sin(theta). This is simply how gravity is applied. When the plane is level (theta = 0), sin(theta) is 0. The plane experiences no gravity acceleration on the X axis (the forward axis). When the plane is pointed straight down, sin(theta) = 1, so the plane experiences the full force of gravity pulling on the X axis.&lt;/p&gt;&lt;p&gt;A similar calculation is made for every axis.&lt;/p&gt;&lt;p&gt;For UDOT, the final term is (QS * CXT + T) / MASS. This is the coefficient CXT plus the thrust from the engine, divided by mass. VDOT and WDOT have similar final terms, made more difficult to read by the common subexpression optimization.&lt;/p&gt;&lt;p&gt;Ignoring the other terms, the 3 accelerations can be written:&lt;/p&gt;&lt;quote&gt;UDOT = (QS * CXT + T)/MASS VDOT = AY WDOT = AZ&lt;/quote&gt;&lt;p&gt;Then the variables can be expanded and rewritten:&lt;/p&gt;&lt;quote&gt;UDOT = (QBAR * S * CXT + T) / MASS VDOT = (QBAR * S * CYT) / MASS WDOT = (QBAR * S * CZT) / MASS&lt;/quote&gt;&lt;p&gt;This is simply the force coefficient times QBAR (dynamic pressure) times S (wing area). Then thrust is added to the X axis. This is how all forces are applied to the aircraft.&lt;/p&gt;&lt;p&gt;Recall the lift equation from my previous project:&lt;/p&gt;\(L=\frac12\times A\times\rho\times C_L\times v^2\)&lt;list rend="ul"&gt;&lt;item&gt;L is the resulting lift force&lt;/item&gt;&lt;item&gt;A is the surface area&lt;/item&gt;&lt;item&gt;ρ (rho) is the air density&lt;/item&gt;&lt;item&gt;CL is the coefficient of lift&lt;/item&gt;&lt;item&gt;v is the velocity&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The surface area A is equivalent to the wing area S in the Fortran code. CL is equivalent to the variables CXT, CYT, or CZT. The factor ρ * v2 is equivalent to QBAR. Thus we are essentially calculating a lift force on all three axes. But remember that we are specifically calculating normal force, not lift force.&lt;/p&gt;&lt;p&gt;The roll, pitch, and yaw state vectors are then updated:&lt;/p&gt;&lt;quote&gt;xd(4) = P + (STH/CTH)*(QSPH + R*CPH) xd(5) = Q*CPH - R*SPH xd(6) = (QSPH + R*CPH)/CTH&lt;/quote&gt;&lt;p&gt;Once again, these equations make zero sense to me🤷♂️. It’s important for the Fortran code, but we will be calculating roll, pitch, and yaw differently in C#.&lt;/p&gt;&lt;p&gt;Aerodynamic moment is about to be calculated. However this depends on the moment of inertia values and some more values derived from those:&lt;/p&gt;&lt;quote&gt;PARAMETER (AXX=9496.0, AYY= 55814.0, AZZ=63100.0, AXZ= 982.0) PARAMETER (AXZS=AXZ**2, XPQ=AXZ*(AXX-AYY+AZZ),GAM=AXX*AZZ-AXZ**2) PARAMETER (XQR= AZZ*(AZZ-AYY)+AXZS, ZPQ=(AXX-AYY)*AXX+AXZS) PARAMETER ( YPR= AZZ - AXX )&lt;/quote&gt;&lt;p&gt;Now the aerodynamic moment is calculated:&lt;/p&gt;&lt;quote&gt;ROLL = QSB*CLT PITCH = QS *CBAR*CMT YAW = QSB*CNT PQ = p*Q QR = Q*R QHX = Q*HX xd(7) = ( XPQ*PQ - XQR*QR + AZZ*ROLL + AXZ*(YAW + QHX) )/GAM xd(8) = ( YPR*P*R - AXZ*(P**2 - R**2) + PITCH - R*HX )/AYY xd(9) = ( ZPQ*PQ - XPQ*QR + AXZ*ROLL + AXX*(YAW + QHX) )/GAM&lt;/quote&gt;&lt;p&gt;There’s a lot of stuff going on here. The output state vectors are updated using the moment of inertia values as well as HX, which is the angular momentum of the spinning engine mass. I don’t know enough about physics to fully understand why these equations are defined like this.&lt;/p&gt;&lt;p&gt;But we can at least see how the moment coefficients are used if we expand the ROLL, PITCH, and YAW variables:&lt;/p&gt;&lt;quote&gt;ROLL = QBAR * S * B * CLT PITCH = QBAR * S * CBAR * CMT YAW = QBAR * S * B * CNT&lt;/quote&gt;&lt;p&gt;ROLL and YAW depend on B, the wingspan of the plane. Pitch depends on CBAR, the mean aerodynamic chord.&lt;/p&gt;&lt;p&gt;The final step is to calculate the world space position of the aircraft. Since we are using Unity rigidbodies to implement the flight model, this step is not translated to C#. But for reference:&lt;/p&gt;&lt;quote&gt;T1= SPH * CPSI; T2= CPH * STH; T3= SPH * SPSI S1= CTH * CPSI; S2= CTH * SPSI; S3= T1 * STH - CPH * SPSI S4= T3 * STH + CPH * CPSI; S5= SPH * CTH; S6= T2*CPSI + T3 S7= T2 * SPSI - T1; S8= CPH * CTH xd(10) = U * S1 + V * S3 + W * S6 ! North speed xd(11) = U * S2 + V * S4 + W * S7 ! East speed xd(12) = U * STH -V * S5 - W * S8 ! Vertical speed AN = -AZ/GD; ALAT= AY/GD;&lt;/quote&gt;&lt;p&gt;Now we can start translating this into C# using Unity’s physics engine to replace some parts.&lt;/p&gt;&lt;p&gt;A lot of the code can be reused from the previous flight sim project. Using it for this new flight model only requires some conversion into customary units and back. The main class that controls everything is Plane. This class contains instances of the AirDataComputer, Engine, and Aerodynamics, which is where the translated Fortran code lives.&lt;/p&gt;&lt;p&gt;One simplification can be made since we are using Unity physics. We do not need to calculate the acceleration of the aircraft manually. That can be done automatically by the physics engine. However, the moment calculation needs to be copied more or less directly from the textbook.&lt;/p&gt;&lt;p&gt;The air data computer needs to be called:&lt;/p&gt;&lt;quote&gt;void UpdateAirData() { float speed = LocalVelocity.magnitude; // m/s float speedFeet = speed * metersToFeet; AltitudeFeet = Rigidbody.position.y * metersToFeet; airData = airDataComputer.CalculateAirData(speedFeet, AltitudeFeet); }&lt;/quote&gt;&lt;p&gt;Then the engine needs to be updated and the thrust force applied:&lt;/p&gt;&lt;quote&gt;void UpdateThrust(float dt) { engine.ThrottleCommand = Throttle; engine.Mach = Mach; engine.Altitude = AltitudeFeet; engine.Update(dt); Rigidbody.AddRelativeForce(new Vector3(0, 0, engine.Thrust * poundsForceToNewtons)); }&lt;/quote&gt;&lt;p&gt;For the aerodynamics class, a struct with all relevant aerodynamic state is passed, similar to the state vector in the Fortran code.&lt;/p&gt;&lt;quote&gt;public struct AerodynamicState { public Vector4 inertiaTensor; public Vector3 velocity; public Vector3 angularVelocity; public AirData airData; public float altitude; public float alpha; public float beta; public float xcg; public ControlSurfaces controlSurfaces; }&lt;/quote&gt;&lt;p&gt;This is populated by the Plane class, which also handles unit conversions:&lt;/p&gt;&lt;quote&gt;AerodynamicState currentState = new AerodynamicState { inertiaTensor = inertiaTensor, velocity = ConvertVectorToAerospace(LocalVelocity) * metersToFeet, angularVelocity = ConvertAngleToAerospace(LocalAngularVelocity), airData = airData, alpha = alpha, beta = beta, xcg = centerOfGravityPosition, controlSurfaces = ControlSurfaces }; var newState = aerodynamics.CalculateAerodynamics(currentState);&lt;/quote&gt;&lt;p&gt;All of the flight model code is located inside the Aerodynamics class.&lt;/p&gt;&lt;p&gt;First step is to call the aerodynamic coefficient functions from above:&lt;/p&gt;&lt;quote&gt;Vector3 GetForceCoefficient(float alpha, float beta, float aileron, float rudder, float elevator) { return new Vector3( GetXAxisForceCoefficient(alpha, elevator), GetYAxisForceCoefficient(beta, aileron, rudder), GetZAxisForceCoefficient(alpha, beta, elevator) ); } Vector3 GetMomentCoefficient(float alpha, float beta, float elevator) { return new Vector3( GetXAxisMomentCoefficient(alpha, beta), GetYAxisMomentCoefficient(alpha, elevator), GetZAxisMomentCoefficient(alpha, beta) ); } ... public AerodynamicForces CalculateAerodynamics(AerodynamicState currentState) { Vector3 forceCoefficient = GetForceCoefficient( currentState.alpha, currentState.beta, currentState.controlSurfaces.aileron, currentState.controlSurfaces.rudder, currentState.controlSurfaces.elevator ); Vector3 momentCoefficient = GetMomentCoefficient( currentState.alpha, currentState.beta, currentState.controlSurfaces.elevator ); }&lt;/quote&gt;&lt;p&gt;Then we calculate the damping values. This function simply performs the 9 table lookups.&lt;/p&gt;&lt;quote&gt;void CalculateDampingValues(float alpha) { float S = 0.2f * alpha; int K = Mathf.Clamp((int)S, -1, 8); float DA = S - K; int L = K + (int)Mathf.Sign(DA); for (int i = 0; i &amp;lt; 9; i++) { dampingTable[i] = ReadDampTable(dampTable, K, i) + Math.Abs(DA) * (ReadDampTable(dampTable, L, i) - ReadDampTable(dampTable, K, i)); } }&lt;/quote&gt;&lt;p&gt;Then the variables we need later are calculated:&lt;/p&gt;&lt;quote&gt;// calculate variables float P = currentState.angularVelocity.x; // roll rate float Q = currentState.angularVelocity.y; // pitch rate float R = currentState.angularVelocity.z; // yaw rate float airspeed = Mathf.Max(1, currentState.velocity.magnitude); float TVT = 0.5f / airspeed; float B2V = wingSpanFt * TVT; float CQ = CBAR * Q * TVT; float DAIL = currentState.controlSurfaces.aileron / 20.0f; float DRDR = currentState.controlSurfaces.rudder / 30.0f; float QS = currentState.airData.qBar * wingAreaFtSquared; float QSB = QS * wingSpanFt;&lt;/quote&gt;&lt;p&gt;Then damping is applied to the force and moment coefficients:&lt;/p&gt;&lt;quote&gt;// damping float CXT = forceCoefficient.x + CQ * dampingTable[0]; float CYT = forceCoefficient.y + B2V * (dampingTable[1] * R + dampingTable[2] * P); float CZT = forceCoefficient.z + CQ * dampingTable[3]; float CLT = momentCoefficient.x + B2V * (dampingTable[4] * R + dampingTable[5] * P); CLT += GetDLDA(currentState.alpha, currentState.beta) * DAIL; CLT += GetDLDR(currentState.alpha, currentState.beta) * DRDR; float CMT = momentCoefficient.y + CQ * dampingTable[6] + CZT * (XCGR - currentState.xcg); float CNT = momentCoefficient.z + B2V * (dampingTable[7] * R + dampingTable[8] * P) - CYT * (XCGR - currentState.xcg) * CBAR / wingSpanFt; CNT += GetDNDA(currentState.alpha, currentState.beta) * DAIL; CNT += GetDNDR(currentState.alpha, currentState.beta) * DRDR;&lt;/quote&gt;&lt;p&gt;Note that the damping array in Fortran is 1 based, while the same array in C# is 0 based.&lt;/p&gt;&lt;p&gt;Forces are calculated from the force coefficients. Since we are using Unity’s physics to apply gravity, the gravity terms are not included here. The force from engine thrust is applied outside of this class. And force is applied to a rigidbody, so acceleration does not need to be calculated manually. So the force calculations are now very simple:&lt;/p&gt;&lt;quote&gt;// forces // Acceleration in original text. Need to calculate force instead of acceleration float UDOT = QS * CXT; float VDOT = QS * CYT; float WDOT = QS * CZT;&lt;/quote&gt;&lt;p&gt;Moments are calculated using largely the same code as the textbook:&lt;/p&gt;&lt;quote&gt;// moments float ROLL = QSB * CLT; float PITCH = QS * CBAR * CMT; float YAW = QSB * CNT; float PQ = P * Q; float QR = Q * R; float QHX = Q * HX; // calculate inertia values float AXX = currentState.inertiaTensor.x; float AYY = currentState.inertiaTensor.y; float AZZ = currentState.inertiaTensor.z; float AXZ = currentState.inertiaTensor.w; float AXZS = AXZ * AXZ; float XPQ = AXZ * (AXX - AYY + AZZ); float GAM = AXX * AZZ - AXZS; float XQR = AZZ * (AZZ - AYY) + AXZS; float ZPQ = (AZZ - AYY) * AXX + AXZS; float YPR = AZZ - AXX; float rollAccel = ((XPQ * PQ) - (XQR * QR) + (AZZ * ROLL) + (AXZ * (YAW + QHX))) / GAM; float pitchAccel = ((YPR * P * R) - (AXZ * (P * P - R * R)) + PITCH - (R * HX)) / AYY; float yawAccel = ((ZPQ * PQ) - (XPQ * QR) + (AXZ * ROLL) + (AXX * (YAW + QHX))) / GAM;&lt;/quote&gt;&lt;p&gt;Finally, the force and angular acceleration is returned:&lt;/p&gt;&lt;quote&gt;public AerodynamicForces CalculateAerodynamics(AerodynamicState currentState) { ... result.force = new Vector3(UDOT, VDOT, WDOT); result.angularAcceleration = new Vector3(rollAccel, pitchAccel, yawAccel); return result; }&lt;/quote&gt;&lt;p&gt;Then in the Plane class, the force and angular acceleration can be applied to the rigidbody:&lt;/p&gt;&lt;quote&gt;// aeroForces in pounds var forces = ConvertVectorToUnity(aeroForces) * poundsForceToNewtons; Rigidbody.AddRelativeForce(forces); // aeroAngularAcceleration changes angular velocity directly Vector3 avCorrection = ConvertAngleToUnity(aeroAngularAcceleration); Rigidbody.AddRelativeTorque(avCorrection, ForceMode.Acceleration); lastAngularAcceleration = avCorrection;&lt;/quote&gt;&lt;p&gt;The plane is now able to fly. But if you try flying it right now, you will quickly find that it is impossible to fly by hand.&lt;/p&gt;&lt;head rend="h1"&gt;Stability&lt;/head&gt;&lt;p&gt;One important aerodynamic effect not modeled in my previous flight sim project is stability. Stability is the behavior of an aircraft when it’s disturbed from it’s flight path. More specifically, it’s how the aircraft behaves when it’s nose vector doesn’t match it’s velocity vector. Stability is the force that pulls the nose vector back towards the velocity vector.&lt;/p&gt;&lt;p&gt;For most aircraft, stability is created by the stabilizers in the tail. A stabilizer is simply a small airfoil (wing). Even without the pilot giving input, the stabilizers act like the fins of a dart. As the plane increases it’s Angle of Attack, the horizontal stabilizer will produce a lift force at the rear of the plane. This creates a torque that pulls the plane’s nose back towards the velocity vector, thus reducing the AOA. Likewise, the vertical stabilizers will create a torque that reduces Angle of Slip.&lt;/p&gt;&lt;p&gt;Keep in mind that stability depends on AOA, just as lift does. When the aircraft has a large AOA, the wings produce lift, which brings the velocity vector towards the nose vector. The stabilizers create torque which brings the nose vector towards the velocity vector. These two forces balance out somewhere and the aircraft will take a new attitude with a new velocity.&lt;/p&gt;&lt;p&gt;However, the aircraft needs to maintain a non-zero AOA to create enough lift to fly straight and level. How does it maintain this AOA when stability works to reduce AOA to zero? The stabilizers can be trimmed to hold a specific AOA. This means that the stabilizers produce zero torque at this particular non-zero AOA. In some planes this must be done manually by the pilot, but in the F-16 this is done automatically by the FCS.&lt;/p&gt;&lt;p&gt;The two forces of lift and stability combine to produce the “feel” of an aircraft’s controls. The tendency for the nose to be pulled towards the velocity vector is called positive stability. Most non-fighter aircraft are designed to have positive stability to maximize safety and ease of flying.&lt;/p&gt;&lt;p&gt;But fighter aircraft like the F-16 are different. These aircraft are often designed to have neutral or even negative stability. Neutral stability means that the aircraft will hold it’s current attitude. Negative stability means that the aircraft will rotate even further away from the velocity vector, at an increasing rate.&lt;/p&gt;&lt;p&gt;The previous flight sim does not model this at all. There is no torque that changes the plane’s attitude except for the steering force. So the behavior is best described as neutrally stable.&lt;/p&gt;&lt;p&gt;This F-16 flight model does include stability. But keep in mind that the real F-16 was designed to have relaxed static stability. This means that it is positively stable, but weakly so. This makes the aircraft more maneuverable and better at retaining energy while turning. But flying an aircraft like this is difficult or even impossible for a human pilot. The plane will depart from steady flight from the smallest stick input or wind gust. The only way a human can handle an aircraft like this during long and stressful missions is with a computerized flight control system.&lt;/p&gt;&lt;head rend="h1"&gt;Flight Control System&lt;/head&gt;&lt;p&gt;A flight control system (FCS) is a computer located between the flight stick and the control surfaces. This computer translates the pilot’s input on the flight stick into control surface movement. It can react to disturbances in the plane’s attitude more quickly and precisely than a human can.&lt;/p&gt;&lt;p&gt;In my previous flight sim project, the control surfaces were purely cosmetic. The actual method used to turn the vehicle was by applying torque directly to the center of mass. That torque was calculated to create a certain amount of angular acceleration without exceeding the plane’s turn rate limit.&lt;/p&gt;&lt;p&gt;For example, the plane had a turn rate on the pitch axis of 60 degrees per second and an acceleration of 120 degrees per second per second. The plane’s turn rate never leaves the range [-60, 60]. Actually, no torque is ever calculated. Unity provides a function to apply angular acceleration directly, ignoring moment of inertia. I chose this behavior to make it easy to both understand the code and to fly the plane.&lt;/p&gt;&lt;p&gt;But this F-16 simulator does depend on the position of the control surfaces. Instead of specifying the acceleration directly, this simulator specifies the torque (moment) and calculates the resulting acceleration. This is more accurate to how serious simulators work and how real planes fly, but this makes controlling the plane more difficult.&lt;/p&gt;&lt;p&gt;The steering system in the previous flight sim project was essentially a perfect FCS that could always achieve the turn rate chosen by the pilot. This is helped by the fact that that simulator does not model aerodynamic stability or instability at all. Spinning out of control was simply not possible.&lt;/p&gt;&lt;p&gt;This F-16 simulator is more difficult to control both because of the more accurate control surfaces and because of the modeled stability. You can actually try to fly this F-16 manually, by disabling the FCS in the config menu.&lt;/p&gt;&lt;p&gt;You will quickly find that the F-16 is almost impossible to fly manually. Every small disturbance from straight and level flight will create small torques that turn your plane unexpectedly. If you try to correct it with the control stick, you will almost certainly overcorrect and send the plane into a new and exciting attitude. This is called pilot induced oscillation.&lt;/p&gt;&lt;p&gt;It simply isn’t possible for a human to react quickly and precisely enough to fly this aircraft. You may be able to fly straight and level with some effort, but you will quickly lose control if you attempt any maneuver. This is indeed a property of the real F-16.&lt;/p&gt;&lt;p&gt;The textbook provides no Fortran code for the FCS. From here on out, it’s my own original code.&lt;/p&gt;&lt;head rend="h2"&gt;PID Controllers&lt;/head&gt;&lt;p&gt;The steering system from the previous project cannot be reused. The solution is to use PID controllers, a topic I’ve covered on this blog before.11&lt;/p&gt;&lt;p&gt;To be more specific, steering in the previous flight sim was easy because we could read the angular velocity of the aircraft and apply a torque that directly countered any undesired movement. This F-16 flight model does not allow us to apply torques directly. We can only set the angle of the control surfaces. This is the problem that PID controllers are good at solving.&lt;/p&gt;&lt;p&gt;Adding the PID controllers is simple. The pilot’s control input is used to select a target angular velocity for the plane, for the 3 axes of rotation. This is given to three independent PID controllers. The output of the PID controllers set the target position for the control surface.&lt;/p&gt;&lt;p&gt;The control surface positions are then passed into the flight model inside AerodynamicState.&lt;/p&gt;&lt;quote&gt;Vector3 targetAV = Vector3.Scale(controlInput, steeringSpeed * steeringSpeedFactor); var accel = lastAngularAcceleration * Mathf.Rad2Deg * dt; controlSurfaceTarget = new Vector3( pitchController.Calculate(dt, av.x, accel.x, targetAV.x), -yawController.Calculate(dt, av.y, accel.y, targetAV.y), rollController.Calculate(dt, av.z, accel.z, targetAV.z) ); var current = ControlSurfaces; ControlSurfaces = new ControlSurfaces( Utilities.MoveTo(current.elevator, controlSurfaceTarget.x, elevatorSpeed, dt, -elevatorRange, elevatorRange), Utilities.MoveTo(current.rudder, controlSurfaceTarget.y, rudderSpeed, dt, -rudderRange, rudderRange), Utilities.MoveTo(current.aileron, controlSurfaceTarget.z, aileronSpeed, dt, -aileronRange, aileronRange) ); ... AerodynamicState currentState = new AerodynamicState { controlSurfaces = ControlSurfaces }; var newState = aerodynamics.CalculateAerodynamics(currentState);&lt;/quote&gt;&lt;p&gt;Here the PIDs are named “pitchController”, “yawController”, and “rollController”. They are all tuned separately to handle a single axis.&lt;/p&gt;&lt;p&gt;When the player releases the stick, the PID controllers will attempt to hold an angular velocity of zero. This makes the aircraft feel like it’s neutrally stable. This also acts as a way to trim the aircraft, so that level flight can be maintained without needing to constantly pull the stick. The PID controller will detect an undesired rotation and move the elevators at a slight angle to counter it.&lt;/p&gt;&lt;p&gt;These PID controllers only add a small amount of complexity to the code, but they achieve similar results as the perfect FCS from the previous project. But there are still limitations that prevent it from being a perfect FCS.&lt;/p&gt;&lt;p&gt;First, the PID controllers must be tuned. The output has to be strong enough to quickly respond to pilot inputs, while avoiding oscillation. This is of course a limitation of any PID control system.&lt;/p&gt;&lt;p&gt;Second, the control surfaces move at a finite speed. This means that it will take some time for the control surface to match the FCS’s commands. So the commands will be imperfectly applied to the aircraft.&lt;/p&gt;&lt;p&gt;Third, unlike the previous flight sim, the three axes of rotation are not independent. For example, a large angle of slip will cause the plane to roll. This is due to the swept wings of the F-16. The roll controller will cancel this out somewhat, but a large enough AOS will result in an uncommanded roll.&lt;/p&gt;&lt;p&gt;Even with these limitations, the PID controllers work fairly well at keeping the plane in control.&lt;/p&gt;&lt;p&gt;Additionally, I use a technique called gain scheduling to change the gain parameters of the roll controller. Because roll performance increases with airspeed, we need a way to limit the amount of aileron movement at high speed. I add two animation curves, which take speed as input, and give the P and D gain of the roll controller as output.&lt;/p&gt;&lt;quote&gt;rollController.P = rollPSchedule.Evaluate(Mathf.Max(0, LocalVelocity.z)); rollController.D = rollDSchedule.Evaluate(Mathf.Max(0, LocalVelocity.z)); Vector3 fcsTarget = new Vector3( pitchController.Calculate(dt, av.x, accel.x, targetAV.x), -yawController.Calculate(dt, av.y, accel.y, targetAV.y), rollController.Calculate(dt, av.z, accel.z, targetAV.z) );&lt;/quote&gt;&lt;p&gt;This allows us to change the strength of the roll controller at different speeds. A more advanced FCS might have a gain schedule for each controller, possibly using more inputs than just airspeed. In fact, if there were multiple inputs, we would need a 2D lookup table to calculate the gain schedule.&lt;/p&gt;&lt;p&gt;Because the flight model is a complete description of how the aircraft will respond at different combinations of AOA, AOS, and control input, it is theoretically possible to design an FCS system that perfectly counters all of the unwanted tendencies. However, that is beyond my understanding of aerodynamics and control theory.&lt;/p&gt;&lt;head rend="h2"&gt;G and AOA Limiter&lt;/head&gt;&lt;p&gt;The weakness of PID controllers is that they only control the angular velocity of the plane. This is not sufficient to control the plane. The previous project has a G limiter, which is simple since steering torque is applied directly to the aircraft. Adding a G limiter is more complicated with this F-16 flight model.&lt;/p&gt;&lt;p&gt;Additionally, a critical part of the FCS on a real F-16 is the AOA limiter. Just like the G limiter prevents the pilot from creating excessive G-forces while maneuvering, the AOA limiter prevents excessive AOA. This is because the aircraft becomes so unstable at about 28 degrees AOA that even the FCS can not compensate. And importantly, our flight model only supports a limited range of AOA (up to 45 degrees), so if the pilot goes beyond that, the behavior of the simulator becomes nonsensical. So limiting the AOA to about 25 degrees is important for maintaining stable flight.&lt;/p&gt;&lt;p&gt;The previous flight sim project did not have anything like an AOA limiter. I simply tuned the steering strength so that AOA would not exceed about 15 degrees (unless stalling). And even then, there is no instability caused by high AOA, so nothing bad happens if the pilot exceeds that.&lt;/p&gt;&lt;p&gt;We need a system that prevents the pilot from exceeding 25 degrees AOA. This would be implemented as a multiplier on the pilot’s stick input, just like a G limiter. Since there are two limits, we simply select the more restrictive limit using min(). So if the G limiter says to limit input to 0.75 and the AOA limiter says to limit input to 0.5, the value 0.5 is chosen.&lt;/p&gt;&lt;p&gt;Because this flight model uses lookup tables, there is no simple formula for calculating either the G limiter or AOA limiter. The G limiter from the previous project won’t work here. Additionally, the relationship between steering input and AOA is not simple. There is a feedback loop between AOA and lift. As AOA increases, lift increases. But as lift increases, AOA decreases since lift pulls the plane onto a new velocity vector. Not to mention lift also depends on airspeed and altitude.&lt;/p&gt;&lt;p&gt;Luckily, the F-16 flight model is completely disconnected from Unity’s physics system. We can actually run the flight model as much as we want with any inputs, and use the outputs for any purpose. There is the “main” flight model that syncs with a Unity rigidbody. But we can create “side” flight models to predict future behavior of the plane.&lt;/p&gt;&lt;p&gt;I chose to implement the G and AOA limiters by running a side flight model. This side model takes the pilot’s inputs and simulates the aircraft in a simplified world state. In a single physics update, the main flight model runs once, but the side flight model runs multiple times to predict movement several seconds into the future. Because running the flight model is a few lookups and math operations, running multiple times per frame is dirt cheap.&lt;/p&gt;&lt;p&gt;By running this side model, we can determine how the plane would behave if it flew without any limiters. So if the plane is flying fast enough to pull 16 Gs, the side model will report that. We can use that information to calculate the G limiter for the main model.&lt;/p&gt;&lt;p&gt;The side model is contained in the class SimpleTrimmer. The main function Trim looks like this:&lt;/p&gt;&lt;quote&gt;public SimulatedState Trim(float dt, float timeMax, SimulatedState initialState) { float time = 0; while (time &amp;lt; timeMax) { AerodynamicState aeroState = new AerodynamicState() { ... }; var aeroForces = aerodynamics.CalculateAerodynamics(aeroState); … time += dt; } return state; }&lt;/quote&gt;&lt;p&gt;It just calls CalculateAerodynamics in a loop with it’s own time variable. The timestep can also be different from the main FixedUpdate loop time step. The variable timeMax controls how far into the future the prediction runs. For example, this side model can run at 0.1 second time steps for 5 seconds total.&lt;/p&gt;&lt;p&gt;After one step of the simulation is run, the state variables are updated and fed back into the next step. The maximum G force and AOA of the whole simulation is recorded.&lt;/p&gt;&lt;quote&gt;// rotate velocity by pitchDelta Quaternion newRotation = Quaternion.Euler(0, pitchDelta, 0); Vector3 newVelocity = newRotation * state.velocity; newVelocity.y = 0; newVelocity.z += gravity * dt; Vector3 velNormalized = newVelocity.normalized; // assume airspeed magnitude does not change (no drag, no thrust) state.velocity = velNormalized * airspeed; state.alpha = Mathf.Atan2(velNormalized.z, velNormalized.x) * Mathf.Rad2Deg; state.maxAlpha = Mathf.Max(state.maxAlpha, state.alpha); state.maxAccelerationZ = Mathf.Min(state.maxAccelerationZ, state.acceleration.z);&lt;/quote&gt;&lt;p&gt;This simulation is highly simplified compared to the main flight model. It ignores the pilot’s input except pitch. It ignores angular velocity except for pitch rate. It does not apply drag or any other force that changes airspeed or altitude. It ignores any change to the aircraft’s pitch. Note that the flight model does not care about the orientation of the aircraft to begin with.&lt;/p&gt;&lt;p&gt;The Trim function assumes the pilot is giving a full pitch up or pitch down input and takes the pitch PID controller as a parameter. So this side flight model uses the same PID values as the main model, to prevent the simulation from turning faster than the max turn rate. Since the I term is not used on the PID controller, we can use it without worrying about state.&lt;/p&gt;&lt;p&gt;Gravity as a single float value is also passed as a parameter. This allows the simulation to know how much gravity is affecting the turn on the pitch axis. If the plane is level, this value is 1. If the plane is rolled 90 degrees to the side, this value is 0. If upside down, this value is -1. Gravity on the other axes is ignored.&lt;/p&gt;&lt;p&gt;The larger time step and reduced complexity of simulation means that the side model is not completely accurate to how the plane will fly. But that’s acceptable since we are only using this to estimate the maximum G force and AOA that a turn might create.&lt;/p&gt;&lt;p&gt;After running through a few seconds of simulation on the flight model, the Trim function returns with the max G force and AOA. The FCS then uses these values to calculate the limiting factors for the pilot’s pitch input.&lt;/p&gt;&lt;quote&gt;SimpleTrimmer.SimulatedState state = simpleTrimmer.Trim( trimmerTimeStep, trimmerTime, initialState, maxAV.x * Mathf.Deg2Rad, gravityFactor * metersToFeet, pitchController, centerOfGravityPosition ); float predictedAlpha = state.maxAlpha; float predictedG = -state.maxAccelerationZ * feetToMeters; float aoaPitchMult = CalculateAOALimiter(predictedAlpha); float gLimit = gLimitPitch; // pitch up limit (ie 8G) if (controlInput.x &amp;gt; 0) { gLimit = this.gLimit; // pitch down limit (ie 4G) } float gPitchMult = CalculateGLimiter(predictedG, gLimit);&lt;/quote&gt;&lt;p&gt;The limiting factor for AOA and G force is calculated with a simple function:&lt;/p&gt;&lt;quote&gt;float ApplyLimiter(float value, float limit, float limitStrength) { if (limit &amp;lt;= 0) return 1; if (value &amp;lt; limit) return 1; float error = value - limit; error *= limitStrength; return limit / (limit + error); }&lt;/quote&gt;&lt;p&gt;ApplyLimiter returns a factor in the range [0, 1], which is eventually multiplied with the pilot’s control input. This function then used in the limiter functions:&lt;/p&gt;&lt;quote&gt;float CalculateGLimiter(float predictedG, float gLimit) { float gForce = predictedG / 9.81f; float gPitchMult = ApplyLimiter(gForce, gLimit, gLimitStrength); return gPitchMult; }&lt;/quote&gt;&lt;p&gt;The variable gForce is the predicted max G force from the side model. gLimit is the value chosen as the max G force, for example, 8. If the predicted value is 12, then the variable error will be 12 – 8 = 4. The returned factor would be 8 / (8 + 4) = 8 / 12 = 0.66. limitStrength is used to tune how strongly the error affects the returned limit factor.&lt;/p&gt;&lt;p&gt;If the value is below the limit, the returned factor is 1.&lt;/p&gt;&lt;p&gt;The AOA limiter uses the same function to calculate two limiting factors which are combined:&lt;/p&gt;&lt;quote&gt;float CalculateAOALimiter(float predictedAlpha) { float aoaPitchMult = 1.0f; aoaPitchMult *= ApplyLimiter(predictedAlpha, predictedAoaLimitMax, predictedAoaLimitStrength); float realAOA = AngleOfAttack * Mathf.Rad2Deg; aoaPitchMult *= ApplyLimiter(realAOA, feedbackAoaLimitMax, feedbackAoaLimitStrength); return aoaPitchMult; }&lt;/quote&gt;&lt;p&gt;One limit factor depends on the predicted alpha from the SimpleTrimmer class. The other factor depends on the actual alpha value the plane currently has. This can handle cases where the real alpha is much larger than the predicted value, such as when the plane is already stalling.&lt;/p&gt;&lt;p&gt;Then the AOA and G limiter factors are applied to the pilot’s input:&lt;/p&gt;&lt;quote&gt;float aoaPitchMult = CalculateAOALimiter(predictedAlpha); float gPitchMult = CalculateGLimiter(predictedG, gLimitPitch); float pitchMult = Mathf.Min(aoaPitchMult, gPitchMult); // select whichever limiter is stronger float rollMult = rollPitchFactor.Evaluate(Mathf.Abs(controlInput.x)) * rollAOAFactor.Evaluate(AngleOfAttack * Mathf.Rad2Deg); Vector3 limitedInput = Vector3.Scale(controlInput, new Vector3(pitchMult, 1, rollMult)); Vector3 targetAV = Vector3.Scale(limitedInput, steeringSpeed * steeringSpeedFactor);&lt;/quote&gt;&lt;p&gt;The min() function is used to select whichever limiter factor is strongest. Since I am designing these systems myself, I can tell you there is not a strong reason why I chose min() instead of another multiplication. This is just the formula that felt right when I was testing it.&lt;/p&gt;&lt;p&gt;In fact there are many different ways that the limiting factors could be calculated and combined. I designed the ApplyLimiter function primarily to be easy to tune. These allow me to have separate variables for tuning predicted G, predicted AOA, and feedback AOA limiters.&lt;/p&gt;&lt;p&gt;There is one final limiter above, rollMult. This is controlled by two AnimationCurves, rollPitchFactor and rollAOAFactor. These curves reduce the strength of roll input when the pilot is commanding a strong pitch rotation and when the plane has a high AOA. I added this because rolls felt too sensitive when in a high G or high AOA turn. Tune these to your own taste.&lt;/p&gt;&lt;head rend="h2"&gt;Stick Pusher&lt;/head&gt;&lt;p&gt;The final system to add is a stick pusher. A stick pusher is a device some aircraft have that physically pushes the stick forward to avoid a stall. This doesn’t exist in the real F-16, even digitally, but who cares? It was quick and easy to write.&lt;/p&gt;&lt;p&gt;If the AOA exceeds some threshold, a bias value is added to the pilot’s stick input to push the nose down. This is different from the AOA limiter above, which multiplies the input by a factor [0, 1]. If the pilot is giving an input of 0, then the AOA limiter has no effect. The stick pusher adds the bias value to the pilot’s input, so it will work even when the pilot gives no input.&lt;/p&gt;&lt;p&gt;The stick pusher will apply when the plane is stalling or if the AOA limiter fails to keep the AOA in the safe range.&lt;/p&gt;&lt;p&gt;The code for this is incredibly simple in concept and implementation:&lt;/p&gt;&lt;quote&gt;float CalculateAOAPusher() { float bias = 0.0f; float aoa = AngleOfAttack * Mathf.Rad2Deg; if (aoa &amp;gt; stickPusherThreshold) { float error = aoa - stickPusherThreshold; bias = stickPusherCurve.Evaluate(error); } return Mathf.Min(stickPusherMax, bias); }&lt;/quote&gt;&lt;p&gt;If the AOA is over the stickPushThreshold, add a bias to the player’s input. The more it exceeds the threshold, the stronger the bias. At max strength, the stick pusher can give a full nose down input that can’t be overridden by the pilot.&lt;/p&gt;&lt;p&gt;This value is summed with the pilot’s input before running the PID controllers.&lt;/p&gt;&lt;quote&gt;Vector3 stickPusher = new Vector3(CalculateAOAPusher(), 0, 0); Vector3 limitedInput = Vector3.Scale(controlInput, new Vector3(pitchMult, 1, rollMult)) + stickPusher; Vector3 targetAV = Vector3.Scale(limitedInput, steeringSpeed * steeringSpeedFactor);&lt;/quote&gt;&lt;p&gt;With all of these systems added to the FCS, the plane should be very stable to fly now. Since the side model simulation is simplified, the G and AOA limiters are not perfect. They will sometimes result in those parameters being limited at a value too high or too low. But these systems do work accurately enough to keep the plane stable.&lt;/p&gt;&lt;head rend="h1"&gt;Testing&lt;/head&gt;&lt;p&gt;Of course any implementation can have bugs. We need to test the flight model to make sure it works. This includes the translation of the Fortran flight model, and the code that implements all of this in Unity.&lt;/p&gt;&lt;head rend="h2"&gt;Unit Testing&lt;/head&gt;&lt;p&gt;Because the flight model is separate from Unity’s physics engine, we can actually test it using normal unit testing techniques. Unity provides a unit testing framework based on NUnit, so testing is pretty typical for C#.&lt;/p&gt;&lt;p&gt;The authors of the textbook also helpfully provide a test case to use. They give the inputs to the model (airspeed, control surface position, throttle, etc) and the expected output of the model (forces, moment, angular velocity, etc). This lets us validate that the model is implemented correctly by running a single step of simulation.&lt;/p&gt;&lt;quote&gt;// Textbook provides a table of input values and the expected output // Index Param Input State (X) Output (XD) // 1 0.4 (XCG) 0.9 (throttle) 500 (vt) -75.23724 // 2 20 (elevator) 0.5 (alpha) -0.8813419 // 3 -15 (aileron) -0.2 (beta) -0.4759990 // 4 -20 (rudder) -1 (phi) // 5 1 (theta) // 6 -1 (psi) // 7 0.7 (P) 12.62679 // 8 -0.8 (Q) 0.9649671 // 9 0.9 (R) 0.5809759 // 10 1000 (north) // 11 900 (east) // 12 10000 (alt) 248.1241 // 13 90 (power) -58.68999&lt;/quote&gt;&lt;p&gt;Note that the output values for roll, pitch, and yaw, and north, east, and altitude, are not checked in this test. We are using the Unity rigidbody to handle these, so these values are not even calculated in C#.&lt;/p&gt;&lt;p&gt;Additionally, the table lookup operations are fairly simple C# code, so these functions can also be unit tested. I caught a few bugs in the flight model by adding these tests.&lt;/p&gt;&lt;p&gt;All of the tests are in the ModelTestCase class.&lt;/p&gt;&lt;head rend="h2"&gt;Flight Testing&lt;/head&gt;&lt;p&gt;Of course unit testing can only cover so much. The whole point of this project is to create a flight simulator. The only way to know how the flight model really feels is to fly it. So get out there and start flying it!&lt;/p&gt;&lt;p&gt;I have caught a few bugs in the implementation just by flying it and realizing that some aspect felt weird.&lt;/p&gt;&lt;p&gt;In the aerospace industry, test flights are thoroughly instrumented to gather as much data as possible. Force on every axis, angular velocity, pilot input, GPS track, etc is all recorded and stored for future analysis. It’s possible to write automated tests that read this data and check that values stay within expected bounds.&lt;/p&gt;&lt;p&gt;I have done none of that here. Just have fun flying 🙂&lt;/p&gt;&lt;head rend="h1"&gt;Limitations&lt;/head&gt;&lt;p&gt;The flight model defined in the textbook has several limitations.&lt;/p&gt;&lt;p&gt;The effects of alpha on the flight model is only modeled for the range [-10, 45]. Beta is only modeled for the range [-30, 30]. The flight model supports extrapolating data tables beyond their defined ranges, but the returned values will quickly become nonsensical. This means that if you manage to fly the F-16 beyond the provided ranges for alpha and beta, the flight model will break down and begin behaving non-physically.&lt;/p&gt;&lt;p&gt;In some cases, the aircraft will eventually return to controlled flight. But in other cases, one bad data value used to query the tables will cause increasingly bad data to be stored to the plane’s state. These bad values will quickly grow until the plane is thrown to infinity.&lt;/p&gt;&lt;p&gt;Hopefully, this is not possible when using FCS that I’ve written. But I encourage any readers to try breaking it themselves.&lt;/p&gt;&lt;p&gt;You can also turn off parts of the FCS using the config menu in the top left corner. This allows you to fly the plane completely manually, turn the engine off, or alter the center of gravity.&lt;/p&gt;&lt;p&gt;If the flight model doesn’t bug out from extreme values, then you can actually perform a backflip or a “Kulbit” maneuver with the F-16. I recommend turning off only the pitch axis FCS if you want to try that.&lt;/p&gt;&lt;p&gt;Another limitation is that flaps and slats are not defined in the flight model. The real F-16 uses a single control surface called a “flaperon” that works as both a flap and an aileron. When more lift is needed at low speeds, both flaperons deflect downwards like traditional flaps. Leading edge slats also deflect downwards to increase lift.&lt;/p&gt;&lt;p&gt;The textbook flight model only considers these control surfaces to be ailerons. That is, they always deflect in opposite directions in order to create a roll moment. Only a single “aileron” value is used to represent both left and right, so they cannot be used as flaps. If they were to be used as flaps, then there would need to be a left aileron and right aileron value and the Z axis force coefficient would depend on flaperon position.&lt;/p&gt;&lt;p&gt;The effect of slat position is blended into the existing tables, so there is some effect of slats on Z axis force. But the slat position cannot be animated on the plane’s 3D model since no variable for it exists.&lt;/p&gt;&lt;p&gt;This means that there are reduced high lift devices on the aircraft. The extra lift from flaps cannot be modeled. So the plane’s takeoff speed is much higher than you might expect from the F-16. The textbook only defines a model for flight, not for taxiing or takeoff. Landings feel quite bad because of this.&lt;/p&gt;&lt;p&gt;Another limitation is the lack of landing gear simulation. The landing gear is implemented exactly the same as the previous project: three capsule colliders. There is no simulation of wheel, tire, or suspension behavior. Again, this makes takeoff and landing feel kind of weird. But I have no idea how to write a system like that and it’s out of scope for this project anyways.🤷♂️&lt;/p&gt;&lt;p&gt;Another limitation of the flight model is the inaccuracy when flying super sonic. With real planes, lift and drag forces change drastically as you approach Mach 1. Air accelerates as it passes over the wing. Even while the plane remains subsonic, some parts of the air flow are forced to accelerate above Mach 1. When this air reaches supersonic speeds, shockwaves form over the wing which alters the way air flows around it.&lt;/p&gt;&lt;p&gt;This region, where some air is supersonic and some is not, is called the transonic region. This has a drastic effect on the aircraft’s performance and handling. In particular, the coefficient of drag increases, creating the “sound barrier” effect. The position of lift force on the wing changes, which will change how the plane handles.&lt;/p&gt;&lt;p&gt;None of these effects are included in the textbook’s flight model. These could be modeled by adding another input dimension to the force and moment tables. I suspect these were omitted to keep the flight model simple.&lt;/p&gt;&lt;p&gt;The practical effect is that the flight model only works up to about Mach 0.7. Above that, all of the forces on the aircraft become unrealistic. The behavior of the plane continues to increase smoothly with airspeed as if supersonic effects don’t exist.&lt;/p&gt;&lt;head rend="h1"&gt;Conclusion&lt;/head&gt;&lt;p&gt;I started this project after I got a job in the aerospace industry. The textbook was recommended by my manager, since I was working on real flight control systems. In a way, this article is a summary of everything I’ve learned about flying and software engineering in that job.&lt;/p&gt;&lt;p&gt;The way this F-16 flight model is implemented is very different from my previous project. It is actually close to how professional level sims are written, though simplified to fit in a textbook. Even so, there are still plenty of limitations in the flight model which means the simulation will behave unrealistically beyond the intended flight envelope.&lt;/p&gt;&lt;p&gt;The authors of the textbook based their flight model on a NASA paper12 which measured the aerodynamic properties of a scale model in a wind tunnel. The Nasa paper provides 50 lookup tables. The textbook simplified, approximated, and combined these into only 13 lookup tables.&lt;/p&gt;&lt;p&gt;With only a little more effort, you could write a simulator that uses many more tables to cover a larger flight envelope with more detail. The only limit is the data you have access to and your understanding of aerodynamics.&lt;/p&gt;&lt;p&gt;The FCS I’ve written is much simpler than the real FCS. Theoretically, it would be possible to write code that models the real F-16 FCS and apply it to this flight simulator. But how could you even get that information and who would be crazy enough to try that?&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;“Aircraft Control and Simulation” by Brian L. Stevens, Frank L. Lewis, and Eric N. Johnson ↩︎&lt;/item&gt;&lt;item&gt;https://vazgriz.com/346/flight-simulator-in-unity3d-part-1/ ↩︎&lt;/item&gt;&lt;item&gt;https://vazgriz.com/467/flight-simulator-in-unity3d-part-2/ ↩︎&lt;/item&gt;&lt;item&gt;https://vazgriz.com/503/creating-a-flight-simulator-in-unity3d-part-3/ ↩︎&lt;/item&gt;&lt;item&gt;https://twitter.com/FreyaHolmer/status/1325556229410861056 ↩︎&lt;/item&gt;&lt;item&gt;https://commons.wikimedia.org/wiki/File:Speyer_Handlog.jpg ↩︎&lt;/item&gt;&lt;item&gt;https://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/airplane/sound.html ↩︎&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Bilinear_interpolation ↩︎&lt;/item&gt;&lt;item&gt;https://en.wikipedia.org/wiki/Trilinear_interpolation ↩︎&lt;/item&gt;&lt;item&gt;https://aerospaceweb.org/question/aerodynamics/q0194.shtml ↩︎&lt;/item&gt;&lt;item&gt;https://vazgriz.com/621/pid-controllers/ ↩︎&lt;/item&gt;&lt;item&gt;Simulator study of stall/post-stall characteristics of a fighter airplane with relaxed longitudinal static stability, Nyugen et al, 1979 (https://ntrs.nasa.gov/citations/19800005879) ↩︎&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vazgriz.com/762/f-16-flight-sim-in-unity-3d/"/><published>2025-09-26T07:06:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45384481</id><title>Pop OS 24.04 LTS Beta</title><updated>2025-09-26T20:11:05.506312+00:00</updated><content>&lt;doc fingerprint="d3f093e026c52dc0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Pop!_OS 24.04 LTS Beta Download&lt;/head&gt;
    &lt;head rend="h2"&gt;Pop!_OS is Getting Beta&lt;/head&gt;
    &lt;p&gt;Pop!_OS 24.04 LTS with the new COSMIC DE, developed by System76, is coming with many new features to explore and discover. Test out the beta as we fine-tune for release.&lt;/p&gt;
    &lt;head rend="h3"&gt;Upgrading from Pop!_OS 22.04 LTS to Pop!_OS 24.04 LTS Beta&lt;/head&gt;
    &lt;head rend="h3"&gt;Pop!_OS 24.04 LTS Beta&lt;/head&gt;
    &lt;p&gt;Filesize: GB&lt;/p&gt;
    &lt;head rend="h3"&gt;Pop!_OS 24.04 LTS Beta with NVIDIA&lt;/head&gt;
    &lt;p&gt;Filesize: GB&lt;/p&gt;
    &lt;head rend="h2"&gt;Release Notes&lt;/head&gt;
    &lt;p&gt;- Pop!_OS 24.04 LTS Beta includes the new COSMIC Desktop Environment designed and developed by System76. COSMIC DE is largely feature complete for the first release and development focus has turned to bug fixes for the final release. - This is a beta release and some bugs are expected. - On occasion, the installer does not start in a virtual machine. Press Super to activate the Launcher and search for "Installer". - Some GNOME apps are replaced by COSMIC apps - GNOME Files (Nautilus) &amp;gt; COSMIC Files - GNOME Terminal &amp;gt; COSMIC Terminal - GNOME Text Editor &amp;gt; COSMIC Text Editor - GNOME Media Player (Totem) &amp;gt; COSMIC Media Player - Pop!_Shop is replaced by COSMIC Store - Key components - COSMIC Epoch 1 Beta - Linux kernel 6.16.3 - Mesa 25.1.5-1 - NVIDIA Driver 580 - libwayland/libwayland-client 1.23.1-3 - libdrm 2.4.125-1 - Dragging and Dropping files from Wayland apps to X11 apps is not currently supported. For instance dragging files from COSMIC Files to Slack. Use the applications upload option as a work-around until the feature is added. - On distributions other than Pop!_OS, Firefox may need a configuration flag set to match COSMIC theming - Go to **```about:config```** and set **```widget.gtk.libadwaita-colors.enabled```** to **```false```** - Google Chrome based browsers - As of Google Chrome version 140, no configuration is necessary for Wayland - For versions prior to 140 and other Chrome based browsers that aren’t updated, setting the **```ozone-platform-hint```** is necessary. Go to chrome://flags in a tab, search for **```ozone-platform-hint```** and change the setting to “auto”. Restart the browser. - Gaming is working well but we expect to need more fixes in our xwayland implementation for the Release Candidate. - Some games may start partially off screen. Press F11 or Super+F11 to full screen the game (Goat Simulator is one example) - Display toggle hotkeys and an on-screen-display is not supported yet. - The “Accent hint” around windows doesn’t match the roundness style setting in Appearance. This is expected for at least COSMIC apps for the Release Candidate. - COSMIC has a built-in screenshot tool. If you require annotations, we recommend Flameshot which can be installed from Flathub via COSMIC Store. Version 13.1 or higher is required for COSMIC. - COSMIC Store doesn’t currently display Flatpak suggested addons for apps. This is planned for the Release Candidate. - Accessibility: The screen reader may not read all COSMIC apps widgets or may read them in an unintuitive direction. We’re working on screen reader flow and navigation for the Release Candidate. - Some application indicators do not appear in the Notification Tray applet. - Switching to an application using its application indicator does not currently work. - Printing support in COSMIC Text Editor is planned for the release candidate - Additional features and bugs expected to be fixed are triaged in the RC column on the [project board](https://github.com/orgs/pop-os/projects/23/views/1)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://system76.com/pop/pop-beta/"/><published>2025-09-26T09:20:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45386578</id><title>US cities pay too much for buses</title><updated>2025-09-26T20:11:05.064178+00:00</updated><content>&lt;doc fingerprint="acad56d595d09b7c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why US Cities Pay Too Much for Transit Buses&lt;/head&gt;
    &lt;p&gt;A new paper argues that lack of competition, demand for custom features and “Buy America” rules have driven up costs for transit agencies in the US.&lt;/p&gt;
    &lt;p&gt;In 2023, two transit agencies went shopping for new buses. Denver’s Regional Transportation District (RTD) and the Cincinnati area’s Southwest Ohio Regional Transit Authority (SORTA) both bought 40-foot, diesel-powered vehicles from the same manufacturer. Although the vehicles were similar, their prices were not: RTD’s 10 buses cost $432,028 each, while SORTA’s 17 cost a whopping $939,388 a pop.&lt;/p&gt;
    &lt;p&gt;That same year, Singapore’s Land Transport Authority also bought buses. Their order called for 240 fully electric vehicles — which are typically twice as expensive as diesel ones in the US. List price: Just $333,000 each.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bloomberg.com/news/articles/2025-09-26/us-cities-are-paying-too-much-for-new-transit-buses"/><published>2025-09-26T13:57:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45386690</id><title>Titanic's sister, Britannic, sank in 1916. Divers have recovered artifacts</title><updated>2025-09-26T20:11:04.884466+00:00</updated><content>&lt;doc fingerprint="3431279307b2c5f7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The Titanic’s Sister Ship, the Britannic, Sank in 1916. For the First Time, Divers Have Recovered Artifacts From Its Wreck&lt;/head&gt;&lt;head rend="h2"&gt;The luxury liner was requisitioned as a hospital ship during World War I. Thirty people died after the vessel struck a German naval mine and sank off the coast of Greece&lt;/head&gt;&lt;p&gt;In the early 20th century, the British White Star Line set out to make the largest and most luxurious ocean liners the world had ever seen. Between 1909 and 1914, the shipping line built a trio of upscale vessels: the Olympic, the Titanic and the Britannic.&lt;/p&gt;&lt;p&gt;Within a decade of the Olympic’s maiden voyage in June 1911, two of the three sister vessels had met tragic ends: the Titanic, which famously sank after striking an iceberg in April 1912, and the lesser-known Britannic, which sank in November 1916 after hitting a naval mine in the Aegean Sea during World War I.&lt;/p&gt;&lt;head rend="h4"&gt;Did you know? The long, strange journey of the Titanic’s dead&lt;/head&gt;Rescuers recovered the remains of only 337 of the roughly 1,500 men, women and children who died in the Titanic disaster. Some of the bodies were buried at sea, while others were brought back to land.&lt;p&gt;This week, Greece’s Ministry of Culture announced that deep-sea divers have recovered artifacts from the wreck of the Britannic for the very first time. The finds include the ship’s bell, a pair of binoculars and a navigation lamp.&lt;/p&gt;&lt;p&gt;In May, an 11-member team embarked on a weeklong expedition to the wreck site, which rests at a depth of nearly 400 feet, the Associated Press reports. The highly skilled group of divers used closed-circuit rebreather equipment to safely survey the ship. “Conditions at the wreck site were particularly challenging due to currents, depth and low visibility,” the ministry says in a statement, per a translation by Agence France-Presse.&lt;/p&gt;&lt;p&gt;British historian Simon Mills, who purchased the wreck in 1996, organized the recovery operation. Artifacts raised from the depths include both practical objects and luxury items, like silver-plated trays used in first class, ceramic tiles from a Turkish bath, and a porcelain sink from the ship’s second-class cabins.&lt;/p&gt;&lt;p&gt;The items are currently undergoing conservation in Athens. Afterward, they will be prominently displayed at the National Museum of Underwater Antiquities, which is slated to open in Greece’s largest port city, Piraeus, in 2026.&lt;/p&gt;&lt;p&gt;Unlike the Titanic and the Olympic, the Britannic was never actually deployed as a luxury cruise liner. Instead, the vessel was requisitioned in 1915, operating as the largest hospital ship in the world for almost a year. As Mills explains in an interview with Bloombsbury:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;By the time the Britannic’s keel was being laid, the Titanic was still several months from completion, and the Olympic had been in commercial service for almost six months, but the building and operational experience gained by observing the earlier vessels meant that even at this early stage, there would have been countless improvements incorporated into the Britannic’s designs.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;These safety measures weren’t enough to save the ship from the disaster. While traveling toward the Greek island of Lemnos, the Britannic hit a German naval mine and sank off the island of Kea on November 21, 1916. Of the 1,066 people on board, 30 lost their lives.&lt;/p&gt;&lt;p&gt;“Britannic was the largest vessel to sink during the Great War, [but] there was no catastrophic loss of life, unlike with the Lusitania, and no deliberate targeting of a hospital ship was evident,” notes the Western Front Association on its website. “As a result, the story of the Britannic is now largely forgotten.”&lt;/p&gt;&lt;p&gt;The Titanic’s sinking has long held immense cultural fascination. Last year, coal from the shipwreck sold for £1,500, while the controversial floating board from James Cameron’s 1997 film Titanic fetched $718,750 at auction.&lt;/p&gt;&lt;p&gt;The Olympic, the White Star Line’s lead ship, sailed for 24 years before its retirement in 1935. It served as a troopship during World War I, then returned to passenger service after the war.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.smithsonianmag.com/smart-news/the-titanics-sister-ship-the-britannic-sank-in-1916-for-the-first-time-ever-divers-have-recovered-artifacts-from-its-wreck-180987402/"/><published>2025-09-26T14:08:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45386872</id><title>DeepFabric – Generate high-quality synthetic datasets at scale</title><updated>2025-09-26T20:11:04.801937+00:00</updated><content>&lt;doc fingerprint="a39866c824b08fe8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Home&lt;/head&gt;
    &lt;p&gt;DeepFabric transforms the process of creating synthetic datasets for language model training, evaluation, and research. Built around the concept of topic-driven data generation, it provides both hierarchical topic trees and experimental graph-based topic modeling to create diverse, contextually rich training examples.&lt;/p&gt;
    &lt;p&gt;The library serves researchers, engineers, and practitioners who need high-quality synthetic data for model distillation, agent evaluation, or statistical research. Whether you're generating conversational datasets, creating domain-specific training examples, or building evaluation benchmarks, DeepFabric provides the tools to scale your data generation process while maintaining quality and diversity.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core Capabilities¶&lt;/head&gt;
    &lt;p&gt;DeepFabric operates through a three-stage pipeline that transforms a simple prompt into a comprehensive dataset. The process begins with topic generation, where the system creates either a hierarchical tree structure or a more complex graph representation of your domain. These topics then feed into the dataset generation engine, which produces contextually appropriate training examples. Finally, the system packages everything into standard formats ready for immediate use.&lt;/p&gt;
    &lt;p&gt;The topic modeling approach sets DeepFabric apart from simple prompt-based generation. Rather than creating isolated examples, the system builds a conceptual map of your domain and generates examples that explore different aspects systematically. This ensures broader coverage and more consistent quality across your dataset.&lt;/p&gt;
    &lt;head rend="h2"&gt;Topic Trees and Graphs¶&lt;/head&gt;
    &lt;p&gt;Traditional topic trees provide a hierarchical breakdown of subjects, ideal for domains with clear categorical structures. The experimental topic graph feature extends this concept by allowing cross-connections between topics, creating more realistic representations of complex domains where concepts naturally interconnect.&lt;/p&gt;
    &lt;p&gt;Both approaches leverage large language models to intelligently expand topics and generate relevant content, but they serve different use cases depending on your domain's structure and complexity requirements.&lt;/p&gt;
    &lt;head&gt;Choosing Between Trees and Graphs&lt;/head&gt;
    &lt;p&gt;Topic trees work well for domains with clear hierarchical relationships, such as academic subjects, product categories, or organizational structures. Topic graphs excel in interconnected domains like research areas, technical concepts, or social phenomena where relationships span multiple categories.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started¶&lt;/head&gt;
    &lt;p&gt;The fastest path to your first dataset involves three simple steps: installation, configuration, and generation. The Getting Started section walks through this process with practical examples that you can run immediately.&lt;/p&gt;
    &lt;p&gt;For those preferring configuration-driven workflows, DeepFabric's YAML format provides comprehensive control over every aspect of generation. Developers seeking programmatic integration can access the full API through Python classes that mirror the CLI functionality.&lt;/p&gt;
    &lt;head rend="h2"&gt;Integration Ecosystem¶&lt;/head&gt;
    &lt;p&gt;DeepFabric integrates seamlessly with the modern machine learning ecosystem, including OpenAI, Anthropic, local Ollama instances, and cloud-based solutions. Generated datasets export directly to Hugging Face Hub with automatic dataset cards and metadata.&lt;/p&gt;
    &lt;p&gt;The modular CLI design supports complex workflows through commands like &lt;code&gt;deepfabric validate&lt;/code&gt; for configuration checking, &lt;code&gt;deepfabric visualize&lt;/code&gt; for topic graph exploration, and &lt;code&gt;deepfabric upload&lt;/code&gt; for streamlined dataset publishing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next Steps¶&lt;/head&gt;
    &lt;p&gt;Begin with the Installation Guide to set up your environment, then follow the First Dataset tutorial to generate your initial synthetic dataset. The Configuration Guide provides comprehensive coverage of YAML options, while the API Reference documents programmatic usage patterns.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lukehinds.github.io/deepfabric/"/><published>2025-09-26T14:26:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45387155</id><title>How to stop AI's "lethal trifecta"</title><updated>2025-09-26T20:11:04.692173+00:00</updated><content/><link href="https://www.economist.com/leaders/2025/09/25/how-to-stop-ais-lethal-trifecta"/><published>2025-09-26T14:49:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45387337</id><title>A recent chess controversy</title><updated>2025-09-26T20:11:03.993716+00:00</updated><content>&lt;doc fingerprint="6956837f6123599f"&gt;
  &lt;main&gt;
    &lt;p&gt;The chess world is no stranger to scandals, from a 1960s fistfight between grand masters Bobby Fischer and Pal Benko to allegations of another grand master, Vladimir Kramnik, cheating in the 2006 world championship by accessing a phone during bathroom breaks. Just this fall, Kramnik expressed “concerns” on X about grand master Daniel Naroditsky and unspecified other players.&lt;/p&gt;
    &lt;p&gt;A prominent recent controversy erupted in November 2023, when Kramnik insinuated on his chess.com blog and in a YouTube video that Hikaru Nakamura cheated. Nakamura is a grand master and five-time US chess champion known for his aggressive style of play. Kramnik’s comments were a reaction to Nakamura’s almost flawless 45.5 out of 46 game winning streak in the high-speed chess.com online blitz tournament, where each player only has a total of three minutes of playing time per game. Kramnik pointed out the statistical improbability of Nakamura’s streak and stated that such a winning run would require the chess prodigy to play at a level higher than his current Elo rating (an estimate of a player’s skill level based on their historical play).&lt;/p&gt;
    &lt;p&gt;Was this just one of those rare streaks that occurs from time to time in sports, or was Nakamura relying on more than just his talent, as Kramnik believed?&lt;/p&gt;
    &lt;p&gt;The statistical elements of the criticism drew the attention of researchers including Shiva Maharaj of the chess school CHESS-ED, Chicago Booth’s Nicholas Polson, and George Mason University’s Vadim Sokolov. Using statistical analysis to investigate the cheating allegation, they find a 99.6 percent probability that Nakamura did not cheat. Moreover, their research highlights how the improper use of statistical evidence can distort or bias interpretations and lead to flawed conclusions.&lt;/p&gt;
    &lt;p&gt;For data, the researchers used Nakamura’s performance in more than 3,500 games he played on chess.com, including the 46 games in question. They also compared Nakamura’s Elo rating with those of his opponents, and find that Nakamura was a much stronger player than those whom he played.&lt;/p&gt;
    &lt;p&gt;This skill imbalance may have been an underestimated factor in the resulting winning streak, the researchers write. After calculating that there was a less than 3 percent chance of Nakamura’s demonstrated winning streak given his opponents’ ratings, the researchers used Bayesian analysis to reexamine the likelihood of it having occurred without cheating. This type of analysis refines an initial hypothesis by continuously incorporating new information to produce a more accurate assessment.&lt;/p&gt;
    &lt;p&gt;As a starting point, the researchers needed an estimate of the level of cheating that occurs in online chess games. Viswanathan Anand, deputy president of the World Chess Federation, stated in a 2022 discussion with the Hindustan Times that the number of online chess games in which cheating occurs “must be 1 in 10,000.” Using this estimated probability as an initial measure, they were able to calculate the high likelihood of Nakamura’s innocence.&lt;/p&gt;
    &lt;p&gt;But what if Anand’s estimate was off and cheating was more prevalent? After all, online games have less oversight than in-person tournaments. Maharaj, Polson, and Sokolov recalculated the probability of Nakamura’s innocence using a number of harsher estimations of online cheating. While the probability of his innocence was lower when it was assumed that cheating occurs in 1 out of every 500 games, the probability was high thereafter and sat in the 98 percent range once that estimate rose to 1 out of 1,500 games. This highlights how crucial the initial assumptions are in any analysis, especially when dealing with probabilities.&lt;/p&gt;
    &lt;head rend="h2"&gt;A real winning streak&lt;/head&gt;
    &lt;p&gt;Although the likelihood of any chess player winning 45.5 out of 46 online chess games is statistically low, the researchers estimate that the probability that grand master Nakamura won that many games without cheating—given his skill and the rarity of cheating among top players—is high.&lt;/p&gt;
    &lt;p&gt;Not only are initial assumptions important; improper use of statistical evidence can lead to misinterpretations. The researchers state that Kramnik’s claim—that the low probability of the streak was evidence of Nakamura’s guilt—falls into what statisticians call the prosecutor’s fallacy, a common misunderstanding in statistical reasoning that confuses the probability of evidence given innocence with the probability of innocence given evidence. Just because an event is unlikely does not mean the opposite of the situation must be true. For example, just because a low probability of a winning streak implies a high probability of cheating, that doesn’t mean Nakamura cheated, despite the streak’s unlikeliness.&lt;/p&gt;
    &lt;p&gt;Nakamura responded to Kramnik’s allegations by arguing that focusing on a particular streak while ignoring other games was cherry-picking. The researchers note that there’s a problem with this argument, too, as it violates the likelihood principle. This principle tells us the interpretation should only rely on the actual data observed, not the context in which it was collected.&lt;/p&gt;
    &lt;p&gt;The researchers also highlighted another statistical concept, Cromwell’s rule. This cautions against assigning 0 percent or 100 percent probability to an event. Even when things seem either impossible or certain, there may be factors that have not yet been considered or nuances in the data that could change our understanding of the probability.&lt;/p&gt;
    &lt;p&gt;Overall, the researchers issue a reminder to be critical consumers of information. No matter how rare or unusual an event may seem, before interpreting the data, consider the assumptions you’re making. Otherwise, the data’s framing can affect the conclusions you draw, even if you had no intention of manipulation. And that can damage reputations.&lt;/p&gt;
    &lt;p&gt;Shiva Maharaj, Nicholas Polson, and Vadim Sokolov, “Kramnik vs. Nakamura: A Chess Scandal,” preprint, arXiv, September 2024.&lt;/p&gt;
    &lt;p&gt;Your Privacy&lt;lb/&gt; We want to demonstrate our commitment to your privacy. Please review Chicago Booth's privacy notice, which provides information explaining how and why we collect particular information when you visit our website.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.chicagobooth.edu/review/did-us-chess-champion-cheat"/><published>2025-09-26T15:02:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45387374</id><title>Context is the bottleneck for coding agents now</title><updated>2025-09-26T20:11:03.841177+00:00</updated><content>&lt;doc fingerprint="6750dc7768fd1a4f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Context is the bottleneck for coding agents now&lt;/head&gt;
    &lt;p&gt;Intelligence is rapidly improving with each model release. Just last week it was announced that OpenAI got a perfect score on the 2025 ICPC programming contest, beating every single human contestant. They achieved this using a version (presumably a very high compute version, but still) of their publicly available GPT-5 model.&lt;/p&gt;
    &lt;p&gt;And yet, coding agents are nowhere near capable of replacing software developers. Why is that?&lt;/p&gt;
    &lt;p&gt;I’m going to argue that the limiting factor is no longer raw intelligence, but rather context. Existing coding agents simply do not have enough context about the problems they’re being asked to solve. This severely limits how long they can work effectively without human guidance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Intelligence and context&lt;/head&gt;
    &lt;p&gt;How autonomous are existing coding agents? Let’s think about autonomy as a spectrum and see how far along that spectrum we are.&lt;/p&gt;
    &lt;p&gt;Level 1 - A few lines of code&lt;lb/&gt;This is what autocomplete does, and it works very well.&lt;/p&gt;
    &lt;p&gt;Level 2 - One commit&lt;lb/&gt;Cursor and Claude Code work well for tasks in this size range.&lt;/p&gt;
    &lt;p&gt;Level 3 - One PR&lt;lb/&gt;Devin and other async agents are built to tackle tasks of this size. But do they work reliably? Only on relatively simple tasks.&lt;/p&gt;
    &lt;p&gt;Level 4 - Major feature or refactor&lt;lb/&gt;Doing this autonomously on an existing codebase is beyond the reach of current agents.&lt;/p&gt;
    &lt;p&gt;Level 5 - Entire codebase&lt;lb/&gt;This is what the vibe coding products like Lovable and Replit do now, but it only works because they can start from scratch. The problem is that they usually hit a wall well before they get to a production-ready application.&lt;/p&gt;
    &lt;p&gt;I’d say Level 2 is all we can reliably do on production codebases right now. And even that requires substantial human guidance and review. What will it take to move further along the autonomy spectrum, without sacrificing quality?&lt;/p&gt;
    &lt;p&gt;When an agent fails at a task, the cause is usually one of two things. It’s either an intelligence failure, or it’s a context failure. Either the model didn’t have the information it needed, or it didn’t have the mental horsepower to process that information properly. There are other aspects that can affect performance, such as taste, but if we’re just talking about whether the agent succeeds or fails at a task, it’s sufficient to just consider intelligence and context. Also note that I’m including general world knowledge as part of intelligence, both for simplicity and because I think it’s hard to fully separate those two out.&lt;/p&gt;
    &lt;p&gt;Programming competitions are competitions of intelligence. The entire context needed to solve a problem is provided in the problem statement itself. There’s no existing codebase to understand, no business requirements to consider, and no unwritten development processes you need to follow.&lt;/p&gt;
    &lt;p&gt;The superhuman ICPC performance we saw this week, as well as the IOI gold medal-level performances from last month, strongly suggest that the raw intelligence and general programming knowledge of frontier models is sufficient to automate most software engineering work.&lt;/p&gt;
    &lt;p&gt;Now these performances were achieved using models that are quite a bit stronger than the models used on a daily basis by developers, like Claude 4 and GPT-5. So we can’t quite say that lack of intelligence is never a cause of failure in current coding agents. They still do some pretty dumb stuff sometimes. But as models improve, more and more of the failures in agentic coding are failures of context, not failures of intelligence.&lt;/p&gt;
    &lt;head rend="h2"&gt;What context does a coding agent need?&lt;/head&gt;
    &lt;p&gt;Context isn’t just code. It’s also specs, dev practices, conversations, etc. When human developers write code, they’re drawing from a reservoir of implicit knowledge that goes far beyond what’s visible in the codebase itself. Current coding agents are operating with maybe 20% of this context, at best.&lt;/p&gt;
    &lt;p&gt;What context does an agent need to reliably operate autonomously and ship code that’s as good or better than human developers? It’s the same things a human developer needs.&lt;/p&gt;
    &lt;p&gt;There are the basics:&lt;/p&gt;
    &lt;p&gt;It needs to be able to access all code files&lt;lb/&gt;Most coding agents can already do this.&lt;/p&gt;
    &lt;p&gt;It needs to be able to access documentation&lt;lb/&gt;Most coding agents can do this if set up properly.&lt;/p&gt;
    &lt;p&gt;It needs to be able to run code and see the output&lt;lb/&gt;Most coding agents can already do this pretty well.&lt;/p&gt;
    &lt;p&gt;And then there are the more subtle forms of context:&lt;/p&gt;
    &lt;p&gt;It needs to have a high-level understanding of how the codebase is organized and where different code lives&lt;lb/&gt;This is important for efficient execution and also for making sure you don’t miss things. Most tool-based agents, like Cursor and Claude Code, do not have this. Some agents are provided with something along these lines.&lt;/p&gt;
    &lt;p&gt;It needs to understand all of the existing architectural patterns and conventions in the codebase&lt;lb/&gt;Every codebase has its own dialect. Maybe you always use dependency injection in a specific way. Perhaps there’s an unwritten rule about where business logic lives versus presentation logic. Maybe you have a specific pattern for handling async operations that evolved organically over three years.&lt;/p&gt;
    &lt;p&gt;Current agents struggle here because many of these patterns are emergent properties of the codebase that aren’t documented in any single place. They’re distributed across thousands of commits, pull requests, and code reviews.&lt;/p&gt;
    &lt;p&gt;It needs to understand why things were done the way they were&lt;lb/&gt;Why does the authentication system work the way it does? Because two years ago, there was a security incident that led to a complete redesign. Why don’t we use library X even though it seems perfect? Because it caused production issues in 2022.&lt;/p&gt;
    &lt;p&gt;This tribal knowledge lives in Slack threads, meeting notes, incident post-mortems, and developers’ heads.&lt;/p&gt;
    &lt;p&gt;It needs to understand development and deployment practices&lt;lb/&gt;Testing expectations, style and comment guidelines, etc.&lt;/p&gt;
    &lt;p&gt;Every team has unwritten rules about how code ships. Maybe you deploy to staging-east first because of a subtle dependency. Perhaps certain tests look weird because they’re working around a known race condition. The CI/CD pipeline has manual approval steps that seem redundant but prevent real disasters that happened in the past.&lt;/p&gt;
    &lt;p&gt;Current agents can read your test configs and deployment scripts, but they don’t understand the “why” behind them. They might remove a “redundant” check that’s actually preventing a production issue, or follow official docs that everyone knows are outdated.&lt;/p&gt;
    &lt;p&gt;It needs to understand product and business requirements&lt;lb/&gt;Code doesn’t exist in a vacuum. That seemingly arbitrary validation rule? It’s there because of a regulatory requirement in the EU market. That weird data transformation? It’s handling an edge case for your biggest enterprise customer.&lt;/p&gt;
    &lt;p&gt;I don’t know of any coding agents that are plugged into this kind of data right now.&lt;/p&gt;
    &lt;p&gt;Notice how all the basic forms of context use the word “access” while the more subtle forms of context use the word “understand.” This is important. Most of this context is not written down in a single document that the agent can just read. To the extent that it’s written down at all, it’s often scattered across many different files and apps. Some of that information will be conflicting and out of date. Giving the agent this context is not as simple as just giving it an MCP connector to your Google Drive and Linear accounts. The information needs to be processed and synthesized by the agent.&lt;/p&gt;
    &lt;p&gt;What does this mean for coding agents?&lt;/p&gt;
    &lt;p&gt;First, we need to give them access to way more context. Much of this new context will require sophisticated preprocessing to make it usable, so this is not an easy problem.&lt;/p&gt;
    &lt;p&gt;Second, not everything is written down. That means experienced human developers will still need to fill in the gaps for a very long time to come.&lt;/p&gt;
    &lt;p&gt;Third, agents need to learn to identify when they’re missing context so they can ask for human guidance. Right now they seem to be trained to just plow forward with what they have.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://runnercode.com/blog/context-is-the-bottleneck-for-coding-agents-now"/><published>2025-09-26T15:06:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45387421</id><title>Show HN: Dreamtap – Make your AI more creative</title><updated>2025-09-26T20:11:03.637036+00:00</updated><content>&lt;doc fingerprint="94095c1aadabbafb"&gt;
  &lt;main&gt;
    &lt;p&gt;⚡ Stop reading the same story 20 times ⚡ Explore different ideas ⚡ The AIs get bored too! ⚡&lt;/p&gt;
    &lt;p&gt;Dreamtap: Inspire your AI to be more creative&lt;/p&gt;
    &lt;p&gt;Dreamtap is a chatbot plugin that gives your AI wide-ranging sources of inspiration to do better at creative tasks - writing, design, etc.&lt;/p&gt;
    &lt;p&gt;Dreamtap works with Claude, ChatGPT (beta), and other tools that support MCP.&lt;/p&gt;
    &lt;p&gt;Dreamtap is free and doesn't see your chat content or know who you are.&lt;/p&gt;
    &lt;p&gt;Why?&lt;/p&gt;
    &lt;p&gt;When you ask AI to write stories, you've probably noticed they are frequently incredibly similar. Claude, for example, likes lighthouses and cartographers.&lt;/p&gt;
    &lt;p&gt;This is mode collapse – the AI defaulting to the safest, most average patterns in its training data. Every story becomes a slight variation of the same template.&lt;/p&gt;
    &lt;p&gt;How Dreamtap Fixes This&lt;/p&gt;
    &lt;p&gt;Dreamtap injects randomized sources of inspiration before your AI starts generating. Instead of letting the model slide into its default patterns, it inspires the model with some concepts unconnected to your prompt. Claude decides by itself when it needs more inspiration and uses Dreamtap. ChatGPT is a bit worse at this, and you'll need to use the tool manually.&lt;/p&gt;
    &lt;p&gt;The Difference in Practice&lt;/p&gt;
    &lt;p&gt;Below are stories written by Claude with the same prompt: "Write an inspired short story"&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dreamtap.xyz/"/><published>2025-09-26T15:11:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45387462</id><title>Fast UDP I/O for Firefox in Rust</title><updated>2025-09-26T20:11:03.191008+00:00</updated><content>&lt;doc fingerprint="9cacf1177618bfaa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Motivation&lt;/head&gt;
    &lt;p&gt;Around 20% of Firefox’s HTTP traffic today uses HTTP/3, which runs over QUIC, which in turn runs over UDP. This translates to substantial UDP I/O activity.&lt;/p&gt;
    &lt;p&gt;Firefox uses NSPR for most of its network I/O. When it comes to UDP I/O, NSPR only offers a limited set of dated APIs, most relevant here &lt;code&gt;PR_SendTo&lt;/code&gt; and &lt;code&gt;PR_RecvFrom&lt;/code&gt;, wrappers around POSIX’s &lt;code&gt;sendto&lt;/code&gt; and &lt;code&gt;recvfrom&lt;/code&gt;.
The N in NSPR stands for Netscape, giving you a hint of its age.&lt;/p&gt;
    &lt;p&gt;Operating systems have evolved since. Many offer multi-message APIs like &lt;code&gt;sendmmsg&lt;/code&gt; and &lt;code&gt;recvmmsg&lt;/code&gt;.
Some offer segmentation offloading like GSO (Generic Segmentation Offload) and GRO (Generic Receive Offload).
Each of these promise significant performance improvements for UDP I/O.&lt;/p&gt;
    &lt;p&gt;Can Firefox benefit from replacing its aging UDP I/O stack with modern system calls?&lt;/p&gt;
    &lt;head rend="h2"&gt;Overview&lt;/head&gt;
    &lt;p&gt;This project began in mid-2024 with the goal of rewriting Firefox’s QUIC UDP I/O stack using modern system calls across all supported operating systems. Beyond performance improvements, we wanted to increase security by using a memory-safe language to do UDP I/O. Firefox’s QUIC state machine itself is implemented in Rust already. We thereby chose Rust for this project as well, giving us both increased security and easy integration with the existing QUIC codebase.&lt;/p&gt;
    &lt;p&gt;Instead of starting from scratch, we built on top of &lt;code&gt;quinn-udp&lt;/code&gt;, the UDP I/O library of the Quinn project, a QUIC implementation in Rust.
This sped up our development efforts significantly.
Big thank you to the Quinn project.
Operating system calls are complex, with a myriad of idiosyncrasies, especially across versions.
Firefox is multi-platform, focusing on Windows, Android, MacOS and Linux as tier 1.
The main complexity though stems from Firefox supporting ancient versions of each of them, e.g.
Android 5.&lt;/p&gt;
    &lt;p&gt;One year later, i.e., mid 2025, this project is now rolling out to the majority of Firefox users. Performance benchmark results are promising. In extreme cases, on purely CPU bound benchmarks, we’re seeing a jump from &amp;lt; 1Gbit/s to 4 Gbit/s. Looking at CPU flamegraphs, the majority of CPU time is now spent in I/O system calls and cryptography code.&lt;/p&gt;
    &lt;p&gt;Below are the many improvements we were able to land, plus the ones we weren’t. I hope other projects in need of fast UDP I/O can benefit from our work. To make their lifes easier, below I am documenting the many learnings we made.&lt;/p&gt;
    &lt;head rend="h2"&gt;The basics&lt;/head&gt;
    &lt;p&gt;To understand the improvements, it’s helpful to first examine how UDP I/O traditionally works and how modern optimizations change this picture.&lt;/p&gt;
    &lt;head rend="h3"&gt;Single datagram&lt;/head&gt;
    &lt;p&gt;Previously Firefox would send (and receive) single UDP datagrams to (and from) the OS via &lt;code&gt;sendto&lt;/code&gt; (and &lt;code&gt;recvfrom&lt;/code&gt;) system call family.
The OS would send (and receive) that UDP datagram to (and from) the network interface card (NIC).
The NIC would send (and receive) it to (and from) the Internet.&lt;/p&gt;
    &lt;p&gt;Thus each datagram would require leaving user space which is cheap for one UDP datagram, but expensive when sending at say a 500 Mbit/s rate. In addition all user space and kernel space overhead independent of the number of bytes sent and received, is paid per datagram, i.e. per &amp;lt; 1500 bytes.&lt;/p&gt;
    &lt;code&gt;    +----------------------+
    |       Firefox        |
    |    +-----------+     |
    |    |   QUIC    |     |
    |    +-----------+     |
    +----------------------+
              |
         [ datagram ]
              |
    === User / Kernel ===
              |
         [ datagram ]
              |
    +----------------------+
    |         OS           |
    +----------------------+
              |
         [ datagram ]
              |
    +----------------------+
    |         NIC          |
    +----------------------+
              |
         [ datagram ]
              |
    +----------------------+
    |      Internet        |
    +----------------------+
&lt;/code&gt;
    &lt;head rend="h3"&gt;Batch of datagrams&lt;/head&gt;
    &lt;p&gt;Instead of sending a single datagram at a time, some operating systems nowadays offer multi-message system call families, e.g. on Linux &lt;code&gt;sendmmsg&lt;/code&gt; and &lt;code&gt;recvmmsg&lt;/code&gt;.
The idea is simple.
Send and receive multiple UDP datagrams at once, save on the costs that are independent of the number of bytes sent and received.&lt;/p&gt;
    &lt;code&gt;    +--------------------------+
    |         Firefox          |
    |      +-----------+       |
    |      |   QUIC    |       |
    |      +-----------+       |
    +--------------------------+
                  |
  [ datagram, datagram, datagram ]
                  |
    ===== User / Kernel =====
                  |
  [ datagram, datagram, datagram ]
                  |
    +--------------------------+
    |           OS             |
    +--------------------------+
                  |
  [ datagram, datagram, datagram ]
                  |
    +--------------------------+
    |           NIC            |
    +--------------------------+
                  |
  [ datagram, datagram, datagram ]
                  |
    +--------------------------+
    |        Internet          |
    +--------------------------+
&lt;/code&gt;
    &lt;head rend="h3"&gt;Single large segmented datagram&lt;/head&gt;
    &lt;p&gt;Some modern operating systems and network interface cards also support system call families with UDP segmentation offloading, e.g. &lt;code&gt;GSO&lt;/code&gt; and &lt;code&gt;GRO&lt;/code&gt; on Linux.
Instead of sending multiple UDP datagrams in a batch, it enables the application to send a single large UDP datagram, i.e. larger than the Maximum Transmission Unit, to the kernel.
Next, either the kernel, but really ideally the network interface card, will segment it into multiple smaller packets, add a header to each and calculates the UDP checksum.
The reverse happens on the receive path, where multiple incoming packets can be coalesced into a single large UDP datagram delivered to the application all at once.&lt;/p&gt;
    &lt;code&gt;    +------------------------------+
    |           Firefox            |
    |        +-----------+         |
    |        |   QUIC    |         |
    |        +-----------+         |
    +------------------------------+
                    |
      [ large segmented datagram ]
                    |
      ====== User / Kernel ======
                    |
      [ large segmented datagram ]
                    |
    +------------------------------+
    |             OS               |
    +------------------------------+
                    |
      [ large segmented datagram ]
                    |
    +------------------------------+
    |             NIC              |
    +------------------------------+
                    |
    [ datagram, datagram, datagram ]
                    |
    +------------------------------+
    |          Internet            |
    +------------------------------+
&lt;/code&gt;
    &lt;p&gt;Note: Unfortunately, Wireshark does not yet support GSO, making network-level debugging more challenging when these optimizations are active.&lt;/p&gt;
    &lt;p&gt;For performance analysis of these different approaches, Cloudflare’s comprehensive study provides excellent benchmarks and detailed explanations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replacing NSPR in Firefox&lt;/head&gt;
    &lt;p&gt;Batching and segmentation offloading aside for now, first step in the project was to replace usage of NSPR with quinn-udp, still sending and receiving one UDP datagram at a time. We updated the Mozilla QUIC client and server test implementation, then integrated quinn-udp into Firefox itself.&lt;/p&gt;
    &lt;p&gt;Next we rewrote the UDP datagram processing pipeline in the Mozilla QUIC implementation to send and receive batches of datagrams. This is done in a way, such that we can leverage both the multi-message style system calls, as well as the segmentation offloading style, if available. We added this along with various other I/O improvements, e.g. Lars added in-place en-/decryption. Going into detail here is better done in a separate blog post. Let’s focus on UDP I/O here.&lt;/p&gt;
    &lt;p&gt;So far so good. This was the easy part. Up next, the edge cases by platform.&lt;/p&gt;
    &lt;head rend="h2"&gt;Platform details&lt;/head&gt;
    &lt;head rend="h3"&gt;Windows&lt;/head&gt;
    &lt;p&gt;Windows offers &lt;code&gt;WSASendMsg&lt;/code&gt; and &lt;code&gt;WSARecvMsg&lt;/code&gt; to send and receive a single UDP datagram.
That UDP datagram can either be a classic MTU size datagram, or a large segmented datagram.
For the latter, what Linux calls &lt;code&gt;GSO&lt;/code&gt; and &lt;code&gt;GRO&lt;/code&gt;, Windows call &lt;code&gt;USO&lt;/code&gt; and &lt;code&gt;URO&lt;/code&gt;.
As described above, we started off rolling out quinn-udp using single-datagram system calls only.
This went without issues on Windows.&lt;/p&gt;
    &lt;p&gt;Next we tested &lt;code&gt;WSARecvMsg&lt;/code&gt; with &lt;code&gt;URO&lt;/code&gt;, i.e. receiving a batch of inbound datagrams as a single large segmented datagram, but got the following bug report:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;fosstodon.org doesn’t load with network.http.http3.use_nspr_for_io=false on ARM64 Windows&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;fosstodon is a Mastodon server. It is hosted behind the CDN provider Fastly. Fastly is a heavy user of Linux’s GSO, i.e. sends larger UDP datagram trains, perfect to be coalesced into a single large segmented UDP datagram when Firefox receives it. Why would Window’s &lt;code&gt;URO&lt;/code&gt; prevent Firefox from loading the site?&lt;/p&gt;
    &lt;p&gt;After many hours of back and forth with the reporter, luckily a Mozilla employee as well, I ended up buying the exact same laptop, same color, in a desperate attempt to reproduce the issue. Without much luck at first, I eventually needed a Linux command line tool, thus installed WSL, and to my surprise, that triggered the bug (reproducer). Turns out, on Windows on ARM, with WSL enabled, a &lt;code&gt;WSARecvMsg&lt;/code&gt; call with &lt;code&gt;URO&lt;/code&gt; would not return a segment size, thus Firefox was unable to differentiate a single datagram, from a single segmented datagram.
QUIC short header packets don’t carry a length, thus there is no way to tell where one QUIC packet ends and another starts, leading to the above page load failures.&lt;/p&gt;
    &lt;p&gt;We have been in touch with Microsoft since. No progress thus far. Thereby we are keeping &lt;code&gt;URO&lt;/code&gt; on Windows disabled in Firefox for now.&lt;/p&gt;
    &lt;p&gt;After &lt;code&gt;URO&lt;/code&gt; we started using &lt;code&gt;WSASendMsg&lt;/code&gt; &lt;code&gt;USO&lt;/code&gt;, i.e. sending a single large segmented datagram per system call.
But this too we rolled back quickly, seeing increased packet loss on Firefox Windows installations.
In addition, we have at least one report of a user, seeing their network driver crash due to Firefox’s usage of &lt;code&gt;USO&lt;/code&gt;.
More debugging needed.&lt;/p&gt;
    &lt;head rend="h3"&gt;MacOS&lt;/head&gt;
    &lt;p&gt;The transition on MacOS from NSPR to quinn-udp for HTTP/3 QUIC UDP I/O involved switching from the system calls &lt;code&gt;sendto&lt;/code&gt; and &lt;code&gt;recvfrom&lt;/code&gt; to the system calls &lt;code&gt;sendmsg&lt;/code&gt; and &lt;code&gt;recvmsg&lt;/code&gt;.
As with Windows, no issues on this first step, ignoring one report where MacOS 10.15 might be seeing IP packets other than v4 and v6 (fixed since).&lt;/p&gt;
    &lt;p&gt;Unfortunately MacOS does not offer UDP segmentation offloading, neither on the send, nor on the receive side. What it does offer though are two undocumented system calls, namely &lt;code&gt;sendmsg_x&lt;/code&gt; and &lt;code&gt;recvmsg_x&lt;/code&gt;, allowing a user to send and receive batches of UDP datagrams at once.
Lars from Mozilla added it to quinn-udp, exposed behind the &lt;code&gt;fast-apple-datapath&lt;/code&gt; feature flag, off by default.
After multiple iterations with smaller bugfixes (#2154, #2214, #2216 …) we decided to not ship it to users, not knowing how MacOS would behave, in case Apple ever decides to remove it, but with Firefox still calling it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Linux&lt;/head&gt;
    &lt;p&gt;Linux provides the most comprehensive and mature UDP optimization support, offering both multi-message APIs (&lt;code&gt;sendmmsg&lt;/code&gt;/&lt;code&gt;recvmmsg&lt;/code&gt;) and segmentation offloading (GSO/GRO).
The quinn-udp library makes a deliberate choice to prioritize GSO over &lt;code&gt;sendmmsg&lt;/code&gt; for transmission, as GSO typically provides superior performance with diminishing returns when both techniques are combined.
Thus far, this has proven the right choice for Firefox as well.&lt;/p&gt;
    &lt;p&gt;In addition to segmentation offloading being superior in the first place, Firefox uses one UDP socket per connection in order to improve privacy. As each socket gets its own source port it is harder to correlate connections. Why is this relevant here? &lt;code&gt;GSO&lt;/code&gt; (and &lt;code&gt;GRO&lt;/code&gt;) can only segment (and coalesce) datagrams from the same 4-tuple (src IP, src port, dst IP, dst port), &lt;code&gt;sendmmsg&lt;/code&gt; and &lt;code&gt;recvmmsg&lt;/code&gt; on the other hand can send and receive across 4-tuples.
Given that Firefox uses one socket per connection, it cannot make use of that distinct benefit of &lt;code&gt;sendmmsg&lt;/code&gt; (and &lt;code&gt;recvmmsg&lt;/code&gt;), making segmentation offloading yet again the obvious choice for Firefox.&lt;/p&gt;
    &lt;p&gt;Ignoring minor changes required to Firefox’s optional network sandboxing, and an additional at runtime GSO support check, replacing Firefox’s QUIC UDP I/O stack on Linux has been without issues, now enjoying all the benefits of segmentation offloading.&lt;/p&gt;
    &lt;head rend="h3"&gt;Android&lt;/head&gt;
    &lt;p&gt;During the time of this project I learned quickly that (a) Android is not Linux and (b) that Firefox still supports Android 5, …, on x86 (32 bit).&lt;/p&gt;
    &lt;p&gt;On x86, Android dispatches advanced socket calls through &lt;code&gt;socketcall&lt;/code&gt; system call instead of calling e.g. &lt;code&gt;sendmsg&lt;/code&gt; directly.
In addition Android has various default seccomp filters, crashing an app when e.g. not going through the required &lt;code&gt;socketcall&lt;/code&gt; system call.
The combination of the two did cost me a couple of days, resulting in this (basically single line) change in quinn-udp.&lt;/p&gt;
    &lt;p&gt;On Android API level 25 and below, calling &lt;code&gt;sendmsg&lt;/code&gt; with an ECN bit set results in an error &lt;code&gt;EINVAL&lt;/code&gt;.
quinn-udp will now simply retry on &lt;code&gt;EINVAL&lt;/code&gt; disabling various optional settings (e.g. ECN) on the second attempt.&lt;/p&gt;
    &lt;p&gt;Great benefit of the Quinn community is that Firefox will benefit from any improvements made to quinn-udp. For example this excellent find by Thomas where Android in some cases would complain if we did a &lt;code&gt;GSO&lt;/code&gt; with a single segment only.&lt;/p&gt;
    &lt;head rend="h2"&gt;Explicit congestion notifications (ECN)&lt;/head&gt;
    &lt;p&gt;With Firefox using modern system calls across all major operating systems, a nice additional benefit is the ability to send and receive ancillary data like IP ECN. This too came with some minor surprises, but QUIC ECN in Firefox is well on its way now. Firefox Nightly telemetry shows around 50% of all QUIC connections running on ECN outbound capable paths. With L4S and thus ECN becoming more and more relevant in today’s Internet, this is a great step forward.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;We successfully replaced Firefox’s QUIC UDP I/O stack with a modern memory-safe implementation using quinn-udp. Instead of limited and dated system calls like &lt;code&gt;sendto&lt;/code&gt; and &lt;code&gt;recvfrom&lt;/code&gt;, Firefox now uses modern OS specific system calls across all major platforms, resulting in HTTP/3 QUIC throughput improvements when CPU bound, and enabling QUIC ECN support across all major platforms.
Some OS specific optimizations still need more work, e.g. &lt;code&gt;USO&lt;/code&gt; and &lt;code&gt;URO&lt;/code&gt; on Windows.
That said, especially given QUIC’s growing adoption and thus increased UDP usage, I am optimistic that OS and driver support will continue to improve.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://max-inden.de/post/fast-udp-io-in-firefox/"/><published>2025-09-26T15:14:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45388021</id><title>Open Social</title><updated>2025-09-26T20:11:02.131649+00:00</updated><content>&lt;doc fingerprint="bd968b5388b80695"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Open Social&lt;/head&gt;
    &lt;p&gt;September 26, 2025&lt;/p&gt;
    &lt;p&gt;Open source has clearly won. Yes, there are plenty of closed source products and businesses. But the shared infrastructure—the commons—runs on open source.&lt;/p&gt;
    &lt;p&gt;We might take this for granted, but it wasn’t a foregone conclusion thirty five years ago. There were powerful forces that wanted open source to lose. Some believed in the open source model but didn’t think it could ever compete with closed source. Many categories of tools only existed as closed source. A Microsoft CEO called open source cancer—a decade before Microsoft has rebuilt its empire around it. The open source movement may not have lived up to the ideals of the “free software”, but it won in industry adoption. Nobody gets fired for choosing open source these days. For much crucial software, open source is now the default.&lt;/p&gt;
    &lt;p&gt;I believe we are at a similar juncture with social apps as we have been with open source thirty five years ago. There’s a new movement on the block. I like to call it “open social”. There are competing visions for what “open social” should be like. I think the AT Protocol created by Bluesky is the most convincing take on it so far. It’s not perfect, and it’s a work in progress, but there’s nothing I know quite like it.&lt;/p&gt;
    &lt;p&gt;(Disclosure: I used to work at Bluesky on the Bluesky client app. I wasn’t involved in the protocol design. I am a fan, and this post is my attempt to explain why.)&lt;/p&gt;
    &lt;p&gt;In this post, I’ll explain the ideas of the AT Protocol, lovingly called atproto, and how it changes the relationship between the user, the developer, and the product.&lt;/p&gt;
    &lt;p&gt;I don’t expect atproto and its ecosystem (known as the Atmosphere) to win hearts overnight. Like open source, it might take a few decades to become ubiquitous. By explaining these ideas here, I’m hoping to slightly nudge this timeline. Despite the grip of today’s social media companies, I believe open social will eventually seem inevitable in retrospect—just like open source does now. Good things can happen; all it takes is years of sustained effort by a community of stubborn enthusiasts.&lt;/p&gt;
    &lt;p&gt;So what is it all about?&lt;/p&gt;
    &lt;p&gt;What open source did for code, open social does for data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Before Social&lt;/head&gt;
    &lt;p&gt;The web is a beautiful invention.&lt;/p&gt;
    &lt;p&gt;You type &lt;code&gt;https://alice.com&lt;/code&gt; and you end up on Alice’s website.&lt;/p&gt;
    &lt;p&gt;Or you type &lt;code&gt;https://bob.com&lt;/code&gt; and you end up on Bob’s website.&lt;/p&gt;
    &lt;p&gt;In a sense, your browser is a portal to millions of different worlds, each with its own little jurisdiction. Only Alice decides what appears on Alice’s website. Only Bob decides what appears on Bob’s website. They meaningfully “own their data”.&lt;/p&gt;
    &lt;p&gt;This doesn’t mean that they’re isolated. On the contrary, Alice can embed Bob’s picture with an &lt;code&gt;&amp;lt;img src&amp;gt;&lt;/code&gt;, and Bob can link to Alice’s page with &lt;code&gt;&amp;lt;a href&amp;gt;&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Alice and Bob can link to each other, but they remain in charge of their sites.&lt;/p&gt;
    &lt;p&gt;What do I mean by saying Alice and Bob are in charge of their own sites? Even if they’re not physically hosting their content on their own computers, they could always change hosting. For example, if Alice’s hosting provider starts deleting her pages or injecting ads into them, Alice can take her content to another host, and point &lt;code&gt;https://alice.com&lt;/code&gt; at another computer. The visitors won’t need to know.&lt;/p&gt;
    &lt;p&gt;This is important. Hosting providers have no real leverage over Alice and Bob. If the hosting provider “turns evil” and starts messing with your site, you can just walk away and host it elsewhere (as long as you have a backup). You’re not going to lose your traffic. All existing links will seamlessly resolve to the new destination.&lt;/p&gt;
    &lt;p&gt;If Alice changes her hosting, Bob won’t need to update any links to Alice’s website. Alice’s site will keep working as if nothing had happened. At worst, a DNS change might make it inaccessible for a few hours, but then the web will be repaired:&lt;/p&gt;
    &lt;p&gt;Imagine how different the incentives would be if links were tied to physical hosts!&lt;/p&gt;
    &lt;p&gt;If changing a hosting provider caused Alice to lose her traffic, she would think many times before changing providers. Perhaps she’d stick with her existing provider even if it was messing with her site, as losing her connections is even worse. Luckily, web’s decentralized design avoids this. Because it’s easy to walk away, hosting providers are forced to compete, and hosting is now a commodity.&lt;/p&gt;
    &lt;p&gt;I think the web is a beautiful idea. It links decentralized islands controlled by different people and companies into one interconnected surface that anyone can index and navigate. Links describe a relationship between logical documents rather than between physical servers. As a result, you’re not a hostage to your hosting.&lt;/p&gt;
    &lt;p&gt;As a wise person said, in theory, there is no difference between theory and practice, but in practice there is. So what’s been happening with the web?&lt;/p&gt;
    &lt;head rend="h2"&gt;Closed Social&lt;/head&gt;
    &lt;p&gt;In the early 90’s, the main way to publish something on the web was to have your own website. Today, most people publish content by using a social media app.&lt;/p&gt;
    &lt;p&gt;Alice and Bob are still publishing things. But instead of publishing at domains like &lt;code&gt;alice.com&lt;/code&gt; and &lt;code&gt;bob.com&lt;/code&gt;, they publish at usernames like &lt;code&gt;@alice&lt;/code&gt; and &lt;code&gt;@bob&lt;/code&gt; allocated by a social media company. The things they publish are not HTML pages, but app-specific entities such as profiles, posts, comments, likes, and so on.&lt;/p&gt;
    &lt;p&gt;These entities are usually stored in a database on the social company’s servers. The most common way to visualize a database is as a sequence of rows, but you could also visualize it as a graph. This makes it look very similar to web itself:&lt;/p&gt;
    &lt;p&gt;What does this social graph enable that a web of personal sites doesn’t?&lt;/p&gt;
    &lt;p&gt;The advantage of storing structured app-specific entities, such as posts and likes, instead of HTML documents is obvious. App-specific entities such as posts and likes have a richer structure: you can always turn them into HTML documents later, but you can also aggregate them, filter them, query, sort, and recombine them in different ways before that. This allows you to create many projections of the same data—a profile page, a list of posts, an individual post with comments.&lt;/p&gt;
    &lt;p&gt;Where this really shines, though, is when many people use the same social app. Since everyone’s public content is now in a single database, it is easy to aggregate across content published by many people. This enables social features like global search, notifications, feeds, personalized algorithms, shared moderation, etc.&lt;/p&gt;
    &lt;p&gt;It’s specifically this social aggregation that blows the “personal sites” paradigm out of the water. People are social creatures, and we want to congregate in shared spaces. We don’t just want to visit each other’s sites—we want to hang out together, and social apps provide the shared infrastructure. Social aggregation features like notifications, feeds, and search are non-negotiable in modern social products.&lt;/p&gt;
    &lt;p&gt;Today, the most common way to implement these features is shaped like this:&lt;/p&gt;
    &lt;p&gt;There still exists a web-like logical model of our data—our profiles, our posts, our follows, our likes, all the things that we’ve created—but it lives within some social app’s database. What’s exposed to the web are only projections of that model—the Home screen, the Notifications screen, the HTML pages for individual posts.&lt;/p&gt;
    &lt;p&gt;This architecture makes sense. It is the easiest way to evolve the “personal sites” paradigm to support aggregation so it’s not surprising today’s apps have largely converged on it. People create accounts on social apps, which lets those apps build aggregated features, which entices more people to sign up for those apps.&lt;/p&gt;
    &lt;p&gt;However, something got lost in the process. The web we’re actually creating—our posts, our follows, our likes—is no longer meaningfully ours. Even though much of what we’re creating is public, it is not a part of the open web. We can’t change our “hosting provider” because we’re now one step removed from how the internet works. We, and the web we create, have become rows in somebody else’s database:&lt;/p&gt;
    &lt;p&gt;This creates an imbalance.&lt;/p&gt;
    &lt;p&gt;When Alice used to publish her stuff on &lt;code&gt;alice.com&lt;/code&gt;, she was not tied to any particular hosting provider. If she were unhappy with a hosting provider, she knew that she could swap it out without losing any traffic or breaking any links:&lt;/p&gt;
    &lt;p&gt;That kept the hosting providers in check.&lt;/p&gt;
    &lt;p&gt;But now that Alice publishes her stuff on a social media platform, she can no longer “walk away” without losing something. If she signs up to another social platform, she would be forced to start from scratch, even if she wants to retain her connections. There is no way for Alice to sever the relationship with a particular app without ripping herself, and anything she created there, out of its social graph:&lt;/p&gt;
    &lt;p&gt;The web Alice created—who she follows, what she likes, what she has posted—is trapped in a box that’s owned by somebody else. To leave it is to leave it behind.&lt;/p&gt;
    &lt;p&gt;On an individual level, it might not be a huge deal.&lt;/p&gt;
    &lt;p&gt;Alice can rebuild her social presence connection by connection somewhere else. Eventually she might even have the same reach as on the previous platform.&lt;/p&gt;
    &lt;p&gt;However, collectively, the net effect is that social platforms—at first, gradually, and then suddenly—turn their backs on their users. If you can’t leave without losing something important, the platform has no incentives to respect you as a user.&lt;/p&gt;
    &lt;p&gt;Maybe the app gets squeezed by investors, and every third post is an ad. Maybe it gets bought by a congolomerate that wanted to get rid of competition, and is now on life support. Maybe it runs out of funding, and your content goes down in two days. Maybe the founders get acquihired—an exciting new chapter. Maybe the app was bought by some guy, and now you’re slowly getting cooked by the algorithm.&lt;/p&gt;
    &lt;p&gt;If your next platform doesn’t respect you as a user, you might try to leave it, too.&lt;/p&gt;
    &lt;p&gt;But what are you going to do? Will you “export your data”? What will you do with that lonely shard of a social graph? You can upload it somewhere as an archive but it’s ripped out of its social context—a pitiful memento of your self-imposed exile.&lt;/p&gt;
    &lt;p&gt;Those megabytes of JSON you got on your way out are dead data. It’s like a branch torn apart from its tree. It doesn’t belong anywhere. To give a new life to our data, we’d have to collectively export it and then collectively import it into some next agreed-upon social app—a near-impossible feat of coordination. Even then, the network effects are so strong that most people would soon find their way back.&lt;/p&gt;
    &lt;p&gt;You can’t leave a social app without leaving behind the web you’ve created.&lt;/p&gt;
    &lt;p&gt;What if you could keep it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Social&lt;/head&gt;
    &lt;p&gt;Alice and Bob are still using social apps. Those apps don’t look much different from today’s social apps. You could hardly tell that something has changed.&lt;/p&gt;
    &lt;p&gt;Something has changed, though. (Can you spot it?)&lt;/p&gt;
    &lt;p&gt;Notice that Alice’s handle is now &lt;code&gt;@alice.com&lt;/code&gt;. It is not allocated by a social media company. Rather, her handle is the universal “internet handle”, i.e. a domain. Alice owns the &lt;code&gt;alice.com&lt;/code&gt; domain, so she can use it as a handle on any open social app. (On most open social apps, she goes by &lt;code&gt;@alice.com&lt;/code&gt;, but for others she wants a distinct disconnected identity, so she owns another handle she’d rather not share.)&lt;/p&gt;
    &lt;p&gt;Bob owns a domain too, even though he isn’t technical. He might not even know what a “domain” is. Bob just thinks of &lt;code&gt;@bob.com&lt;/code&gt; as his “internet handle”. Some open social apps will offer you a free subdomain on registration, just like Gmail gives you a free Gmail address, or may offer an extra flow for buying a domain. You’re not locked into your first choice, and can swap to a different domain later.&lt;/p&gt;
    &lt;p&gt;Your internet handle being something you actually own is the most user-visible aspect of open social apps. But the much bigger difference is invisible to the user.&lt;/p&gt;
    &lt;p&gt;When you previously saw the social graph above, it was trapped inside a social app’s database. There was a box around that graph—it wasn’t a part of the web. With open social, Alice’s data—her posts, likes, follows, etc—is hosted on the web itself. Alongside her personal site, Alice now has a personal repository of her data:&lt;/p&gt;
    &lt;p&gt;This “repository” is a regular web server that implements the AT Protocol spec. The only job of Alice’s personal repository is to store and serve data created by Alice in the form of signed JSON. Alice is technical, so she likes to sometimes inspect her repo using open source tools like pdsls, Taproot, or atproto-browser.&lt;/p&gt;
    &lt;p&gt;Bob, however, isn’t technical. He doesn’t even know that there is a “repository” with his “data”. He got a repository behind the scenes when he signed up for his first open social app. His repository stores his data (from all open social apps).&lt;/p&gt;
    &lt;p&gt;Have another look at this picture:&lt;/p&gt;
    &lt;p&gt;These aren’t rows in somebody’s database. This is a web of hyperlinked JSON. Just like every HTML page has an &lt;code&gt;https://&lt;/code&gt; URI so other pages can link to it, every JSON record has an &lt;code&gt;at://&lt;/code&gt; URI, so any other JSON record can link to it. (On this and other illustrations, &lt;code&gt;@alice.com&lt;/code&gt; is a shorthand for &lt;code&gt;at://alice.com&lt;/code&gt;.) The &lt;code&gt;at://&lt;/code&gt; protocol is a bunch of conventions on top of DNS, HTTP, and JSON.&lt;/p&gt;
    &lt;p&gt;Now have a look at the arrows between their records. Alice follows Bob, so she has a &lt;code&gt;follow&lt;/code&gt; record linking to Bob’s &lt;code&gt;profile&lt;/code&gt; record. Bob commented on Alice’s post, so he has a &lt;code&gt;comment&lt;/code&gt; record that links to Alice’s &lt;code&gt;post&lt;/code&gt; record. Alice liked his comment, so she has a &lt;code&gt;like&lt;/code&gt; record with a link to his &lt;code&gt;comment&lt;/code&gt; record. Everything Alice creates stays in her repo under her control, everything Bob creates stays in his repo under his control, and links express the connections—just like in HTML.&lt;/p&gt;
    &lt;p&gt;All of this happens behind the scenes and is invisibile to a non-technical user. The user doesn’t need to think about where their data is stored until it matters, just like the user doesn’t think about how servers work when navigating the web.&lt;/p&gt;
    &lt;p&gt;Alice’s and Bob’s repositories could be hosted on the same machine. Or they could be hosted by different companies or communities. Maybe Alice is self-hosting her repository, while Bob uses a free hosting service that came by default with his first open social app. They may even be running completely different implementations. If both servers follow the AT protocol, they can participate in this web of JSON.&lt;/p&gt;
    &lt;p&gt;Note that &lt;code&gt;https://alice.com&lt;/code&gt; and &lt;code&gt;at://alice.com&lt;/code&gt; do not need to resolve to the same server. This is intentional so that having a nice handle like &lt;code&gt;@alice.com&lt;/code&gt; doesn’t force Alice to host her own data, to mess with her website, or even to have a site at all. If she owns &lt;code&gt;alice.com&lt;/code&gt;, she can point &lt;code&gt;at://alice.com&lt;/code&gt; at any server.&lt;/p&gt;
    &lt;p&gt;If Alice is unhappy with her hosting, she can pack up and leave:&lt;/p&gt;
    &lt;p&gt;(This requires a modicum of technical skill today but it’s getting more accessible.)&lt;/p&gt;
    &lt;p&gt;Just like with moving a personal site, changing where her repo is being served from doesn’t require cooperation from the previous host. It also doesn’t disrupt her ability to log into apps and doesn’t break any links. The web repairs itself:&lt;/p&gt;
    &lt;p&gt;It is worth pausing for a moment to appreciate what we have here.&lt;/p&gt;
    &lt;p&gt;Every bit of public data that Alice and Bob created—their posts, their likes, their comments, their recipes, their scrobbles—is meaningfully owned by them. It’s not in a database subject to some CEO’s whims, but hosted directly on the open web, with ability to “walk away” without losing traffic or breaking any links.&lt;/p&gt;
    &lt;p&gt;Like the web of personal sites, this model is centered around the user.&lt;/p&gt;
    &lt;p&gt;What does it mean for apps?&lt;/p&gt;
    &lt;p&gt;Each open social app is like a CMS (content management system) for a subset of data that lives in its users’ repositories. In that sense, your personal repository serves a role akin to a Google account, a Dropbox folder, or a Git repository, with data from your different open social apps grouped under different “subfolders”.&lt;/p&gt;
    &lt;p&gt;When you make a post on Bluesky, Bluesky puts that post into your repo:&lt;/p&gt;
    &lt;p&gt;When you star a project on Tangled, Tangled puts that star into your repo:&lt;/p&gt;
    &lt;p&gt;When you create a publication on Leaflet, Leaflet puts it in your repo:&lt;/p&gt;
    &lt;p&gt;You get the idea.&lt;/p&gt;
    &lt;p&gt;Over time, your repo grows to be a collection of data from different open social apps. This data is open by default—if you wanted to look at my Bluesky posts, or Tangled stars, or Leaflet publications, you wouldn’t need to hit these applications’ APIs. You could just hit my personal repository and enumerate all of its records.&lt;/p&gt;
    &lt;p&gt;To avoid naming collisions, the data in the repository is grouped by the format:&lt;/p&gt;
    &lt;p&gt;In any user’s repo, Bluesky posts go with other Bluesky posts, Leaflet publications go with Leaflet publications, Tangled stars go with Tangled stars, and so on. Each data format is controlled and evolved by developers of the relevant application.&lt;/p&gt;
    &lt;p&gt;I’ve drawn a dotted line to separate them but perhaps this is misleading.&lt;/p&gt;
    &lt;p&gt;Since the data from different apps “lives together”, there’s a much lower barrier for open social apps to piggyback on each other’s data. In a way, it starts to feel like a connected multiverse of apps, with data from one app “bleeding into” other apps.&lt;/p&gt;
    &lt;p&gt;When I signed up for Tangled, I chose to use my existing &lt;code&gt;@danabra.mov&lt;/code&gt; handle. That makes sense since identity can be shared between open social apps. What’s more interesting is that Tangled prefilled my avatar based on my Bluesky profile. It didn’t need to hit the Bluesky API to do that; it just read the Bluesky profile record in my repository. Every app can choose to piggyback on data from other apps.&lt;/p&gt;
    &lt;p&gt;That might remind you of Gravatar, but it works for every piece of data. Every open social app can take advantage of data created by every other open social app:&lt;/p&gt;
    &lt;p&gt;There is no API to hit, no integrations to build, nothing to get locked out of. All the data is in the user’s repository, so you can parse it (as typed JSON), and use it.&lt;/p&gt;
    &lt;p&gt;The protocol is the API.&lt;/p&gt;
    &lt;p&gt;This has deep implications for the lifecycle of products. If a product gets shut down, the data doesn’t disappear. It’s still in its users’ repos. Someone can build a replacement that makes this data comes back to life. Someone can build a new product that incorporates some of that data, or lets users choose what to import. Someone can build an alternative projection of existing data—a forked product.&lt;/p&gt;
    &lt;p&gt;This also reduces the “cold start” problem for new apps. If some of the data you care about already exists on the network, you can bootstrap your product off of that. For example, if you’re launching a short video app, you can piggyback on the Bluesky &lt;code&gt;follow&lt;/code&gt; records so that people don’t have to find each other again. But if that doesn’t make sense for your app, you can have your own &lt;code&gt;follow&lt;/code&gt; records instead, or offer a one-time import. All existing data is up for reuse and remixing.&lt;/p&gt;
    &lt;p&gt;Some open social apps are explicitly based around this sort or remixing. Anisota is primarily a Bluesky client, but it natively supports showing Leaflet documents. Popfeed can cross-post reviews to both Bluesky and Leaflet. If Leaflet does gets very popular, there’s nothing stopping Bluesky itself from supporting a Leaflet document as another type of post attachment. In fact, some third-party Bluesky client could decide to do that first, and the official one could eventually follow.&lt;/p&gt;
    &lt;p&gt;This is why I like “open social” as a term.&lt;/p&gt;
    &lt;p&gt;Open social frees up our data like open source freed up our code. Open social ensures that products can get a new life, that people can’t be locked out of what they have created, and that products can be forked and remixed. You don’t need an “everything app” when data from different apps circulates in the open web.&lt;/p&gt;
    &lt;p&gt;If you’re technical, by now you might have a burning question.&lt;/p&gt;
    &lt;p&gt;How the hell does aggregation work?!&lt;/p&gt;
    &lt;p&gt;Since every user’s records live in that user’s repository, there are millions (potentially billions?) repositories. How can an app efficiently query, sort, filter, and aggregate information from them? Surely it can’t search them on demand.&lt;/p&gt;
    &lt;p&gt;I’ve previously used a CMS as an analogy—for example, a blogging app could directly write posts to your repository and then read posts from it when someone visits your blog. This “singleplayer” use case would not require aggregation at all.&lt;/p&gt;
    &lt;p&gt;To avoid hitting the user’s repository every time you want to display their blog post, you can connect to the user’s repository by a websocket. Every time a record relevant to your app is created, updated, or deleted, you can update your database:&lt;/p&gt;
    &lt;p&gt;This database isn’t the source of truth for user’s data—it’s more like an app-specific cache that lets you avoid going to the user repo whenever you need some data.&lt;/p&gt;
    &lt;p&gt;Coincidentally, that’s the exact mechanism you would use for aggregation. You listen to events from all of your app users’ repositories, write them to a local database, and query that database as much as you like with zero extra latency.&lt;/p&gt;
    &lt;p&gt;This might remind you of how Google Reader crawls RSS (rip).&lt;/p&gt;
    &lt;p&gt;To avoid opening a million event socket connections, it makes sense to listen to a stream that retransmits events from all known repositories on the network:&lt;/p&gt;
    &lt;p&gt;You can then filter down such a stream to just the events you’re interested in, and then update your local database in response to the events your app cares about.&lt;/p&gt;
    &lt;p&gt;For example, Leaflet is only interested in events concerning &lt;code&gt;pub.leaflet.*&lt;/code&gt; records. However, Leaflet can also choose to listen to other events. If Leaflet wanted to add a feature that shows backlinks to Bluesky discussions of a Leaflet document, it would simply start tracking &lt;code&gt;bsky.app.feed.post&lt;/code&gt; records too.&lt;/p&gt;
    &lt;p&gt;You can try it yourself by clicking on this link:&lt;/p&gt;
    &lt;p&gt;This is a realtime stream of every single event on the network. It’s dominated by &lt;code&gt;app.bsky.*&lt;/code&gt; records because Bluesky is the most-used app, but you can filter it down to other record types. This retransmitter (called a “relay”) is operated by Bluesky, but you don’t have to depend on it. The Blacksky community runs their own relay implementation at &lt;code&gt;wss://atproto.africa&lt;/code&gt;, which you can try here.&lt;/p&gt;
    &lt;p&gt;Another important detail is that commits are cryptographically signed, which means that you don’t need to trust a relay or a cache of network data. You can verify that the records haven’t been tampered with, and each commit is legitimate.&lt;/p&gt;
    &lt;p&gt;As time goes by, we’ll see more infrastructure built around and for open social apps. Graze is letting users build their own algorithmic feeds, and Slices is an upcoming developer platform that does large-scale repository indexing for you.&lt;/p&gt;
    &lt;p&gt;These are all technical details, though.&lt;/p&gt;
    &lt;p&gt;What matters is the big picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Picture&lt;/head&gt;
    &lt;p&gt;The pre-social web of “personalized sites” got data ownership, hosting independence, and linking right. Alice and Bob fully participate in the web:&lt;/p&gt;
    &lt;p&gt;The closed social web innovated in scaling and in social aggregation features. Notifications, search, and feeds are non-negotiable in modern social products:&lt;/p&gt;
    &lt;p&gt;However, the closed social web has also excluded us from the web. The web we create is no longer meaningfully ours. We’re just rows in somebody else’s database.&lt;/p&gt;
    &lt;p&gt;Open social frees the web we’re creating from somebody else’s boxes. Our profiles, likes, follows, recipes, scrobbles, and other content meaningfully belong to us:&lt;/p&gt;
    &lt;p&gt;The data no longer lives inside the products; the products aggregate over our data:&lt;/p&gt;
    &lt;p&gt;This blurs the boundaries between apps. Every open social app can use, remix, link to, and riff on data from every other open social app.&lt;/p&gt;
    &lt;p&gt;The web we’ve created remains after the products we used to create it are gone. Developers can build new products to recontextualize it. No one can take it away.&lt;/p&gt;
    &lt;p&gt;As more products are built in the open social paradigm, there’s going to be a shift.&lt;/p&gt;
    &lt;p&gt;People might not ever start using technical concepts like “decentralization” but they do understand when data from one app can seamlessly flow into other apps.&lt;/p&gt;
    &lt;p&gt;People might not care about “federation” but they do notice when they log into a competing product, and their data is already there, and their reach is intact.&lt;/p&gt;
    &lt;p&gt;And people do understand when they’re being fucked with.&lt;/p&gt;
    &lt;p&gt;For a long time, open social will rely on a community of stubborn enthusiasts who see the promise of the approach and are willing to bear the pains of building (and failing) in a new ecosystem. But I don’t think that dooms the effort. That’s the history of every big community-driven change. Somebody has to work through the kinks. Like with open source, open social is a compounding effort. Every mildly successful open social app lifts all open social apps. Every piece of shared infrastructure can benefit somebody else. At some point, open is bound to win.&lt;/p&gt;
    &lt;p&gt;I just hope it doesn’t take thirty five years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://overreacted.io/open-social/"/><published>2025-09-26T16:01:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45388675</id><title>Gauntlet AI (YC S17) is looking for engineers who want to master AI</title><updated>2025-09-26T20:11:01.875959+00:00</updated><link href="https://apply.gauntletai.com/"/><published>2025-09-26T17:00:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45388728</id><title>Modular Manifolds</title><updated>2025-09-26T20:11:01.621700+00:00</updated><content>&lt;doc fingerprint="3f8359d1081ca9b1"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Modular Manifolds&lt;/head&gt;&lt;p&gt;When we train large neural networks, we need to keep them healthy. We do not want the tensors in the network—either the weights, activations or gradients—to grow too large or too small. Very small and very large tensors cause a variety of problems not just limited to numerical underflow and overflow. For example, weight matrices changing size during training makes it harder to design training algorithms—since the relative size of updates to weights has a significant impact on the speed of learning.&lt;/p&gt;&lt;p&gt;The gold standard for keeping tensors healthy is to normalize them. Normalization is commonplace for activation vectors, where we use techniques like layer norm to put the activations on a good scale before passing them to the next layer. It is also commonplace to normalize gradient updates, where we can interpret fast training algorithms like the Muon optimizer as spectrally normalizing the updates. Normalization provides us with certainty about the sizes of tensors—without needing to check Wandb!—and when training large neural networks with many interacting components, having certainty about the network internals is valuable.&lt;/p&gt;&lt;p&gt;Normalization is less commonly applied to weight matrices, although it is not unheard of. For example, the EDM2 diffusion model codebase uses weight constraints and the authors report benefits in their paper. Various other techniques have been proposed but are not common practice in modern large-scale training.For some examples, see Salimans et al, 2016, Miyato et al, 2018 and our paper Liu et al, 2021. Normalizing the weight matrices might be a good idea for a few reasons. Weight constraints make understanding the relative size of optimization updates easier. They remove the problem of weight norms exploding. They allow us to focus hyperparameter tuning effort on tensors whose size matters most. They can force matrices to have a small condition number, making their behaviour more predictable. And relatedly, weight constraints facilitate Lipschitz guarantees for robustness to perturbations.&lt;/p&gt;&lt;p&gt;This post covers one appealing way to constrain the weight matrices of a neural network—by keeping the tensors constrained to submanifolds at each layer. This opens the door to re-thinking optimization, as we can co-design optimization algorithms with these manifold constraints. As an example, we proposeThis algorithm builds on work from Jianlin Su and Franz Louis Cesista, as discussed further below. a manifold version of the Muon optimizer whose weights are constrained to the Stiefel manifold: the manifold of matrices with unit condition number. We conclude the post by defining the idea of a modular manifold, which is a composable manifold that attempts to make it easier to scale up and train large networks.&lt;/p&gt;&lt;p&gt;Our goal in writing this post is to provide an introduction to a research area that we are excited about, and highlight many directions for future work. We would love to see more work from the community on the topics mentioned at the end of the post!&lt;/p&gt;&lt;head rend="h2"&gt;The shape of a manifold optimizer&lt;/head&gt;&lt;p&gt;This section works through the simplest example of learning on a manifold: a vector parameter constrained to a hypersphere in $\mathbb{R}^d$. The vector parameter is trained to minimize a loss function defined over the full space $\mathbb{R}^d$. This setup might be useful for, say, individual embedding vectors in a transformer model. This section will be a good warmup for the following section on manifold Muon that considers matrix parameters.&lt;/p&gt;&lt;p&gt;We will not be too formal about the definition of a manifold here: it is enough to understand that a manifold is a curved surface that looks flat when you zoom in close enough. The locally flat approximation at a point on the manifold is called the tangent space to the manifold, as visualized in Figure :&lt;/p&gt;&lt;p&gt;We can characterize the hypersphere in $d$ dimensions as the set of points $w \in \mathbb{R}^d$ of unit Euclidean norm. And the tangent space at a point $w$ on the hypersphere is the set of all vectors $a \in \mathbb{R}^d$ that are orthogonal to $w$.&lt;/p&gt;&lt;p&gt;To keep the weights constrained to the manifold, we could use a non-manifold optimizer and just project the weights back to the manifold after each step. Instead, we are interested in designing methods that take steps in the tangent space. The reason is that we would like to be able to equate the learning rate of our optimizer with the actual length of the optimization step. But if the optimization steps are pointing significantly off manifold and then being projected back, this nice property does not hold. Similar motivation is given in Section 2.3 of the EDM2 paper.&lt;/p&gt;&lt;p&gt;Before we can design a training algorithm for this manifold, something important we need to decide on is how to measure distanceFor a manifold to be “Riemannian”, the distance measure must be induced by an inner product. The Euclidean ($\ell_2$) norm is induced by an inner product, but the Manhattan ($\ell_1$) distance is not. in the tangent space. A common choice is the Euclidean distance, but we could also choose to measure distance in other ways, as visualized in Figure . In the next section, we will talk about choosing a distance measure based on the functionality of the module.&lt;/p&gt;&lt;p&gt;Crucially, the choice of distance measure changes the direction of the best optimization step. If the distance measure is non-Euclidean, then for a fixed length step, we may be able to move further in the direction of the gradientBy gradient, we mean the partial derivative of the loss with respect to the weights. Mathematicians reserve the term gradient for something else in Riemannian geometry. by not following the gradient direction exactly! This concept is visualized in Figure .&lt;/p&gt;&lt;p&gt;To see how this works out in math, we can formulate the optimal update direction given a manifold constraint and a distance measure as itself solving a constrained optimization problem. We will demonstrate this for the case of the hypersphere equipped with the Euclidean norm. Letting $g$ denote the gradient, $w$ the current point on the hypersphere, $a$ the update direction and $\eta$ the learning rate, we need to solve:&lt;/p&gt;$$\min_{a\in\mathbb{R}^d} \quad \underbrace{a^\top g\vphantom{\|a\|_2 = 1}}_{\mathclap{\text{linear change in loss}}} \quad \text{such that} \quad \underbrace{\|a\|_2 = \eta}_{\mathclap{\text{size constraint}}} \quad \text{and} \quad \underbrace{a^\top w = 0\vphantom{\|a\|_2 = 1}}_{\mathclap{\text{tangent constraint}}}.\tag{$\star$}$$&lt;p&gt;Mapping back to the visual language of Figures , and , this formula says that the green arrow (optimal value of $a$) must belong to the red tangent hyperplane ($a^\top w = 0$) and must also lie on a yellow circle of radius $\eta$ ($\|a\|_2 = \eta$). To solve $(\star)$, we can apply the method of Lagrange multipliers. The relevant Lagrangian function is given by:&lt;/p&gt;$$\mathcal{L}(a, \lambda, \mu) = a^\top g + \frac{\lambda}{2} \cdot (a^\top a - \eta) + \mu \cdot (a^\top w),$$&lt;p&gt;where $\lambda$ and $\mu$ are Lagrange multipliers. Setting the derivative of the Lagrangian with respect to $a$ to zero and applying the constraints to solve for $\lambda$ and $\mu$, the optimal update $a_\mathrm{opt}$ ends up being given by the following formula:&lt;/p&gt;$$a_\mathrm{opt} = - \eta \times \frac{g - ww^\top g}{\|g-ww^\top g\|_2}.$$&lt;p&gt;In words, the optimal update is given by subtracting out the radial component from the gradient, normalizing and multiplying by the learning rate. Since this update lies in the tangent space, actually a very smallFor a learning rate $\eta$, the effect of the retraction map is $\mathcal{O}(\eta^2)$ small, so the learning rate almost equals the length of the step. correction is needed to stay on the manifold. The correction is known as a “retraction map” and is visualized in Figure :&lt;/p&gt;&lt;p&gt;We can solve for the retraction map by applying Pythagoras’ theorem to Figure . For a unit hypersphere and a step of length $\eta$, the hypotenuse has length $\sqrt{1+\eta^2}$ and therefore the retraction map for the hypersphere equipped with the Euclidean norm is simply given by dividing the updated weights through by $\sqrt{1+\eta^2}$. Putting everything together, the full manifold optimization algorithm is then given by:&lt;/p&gt;$$w \gets \frac{1}{\sqrt{1+\eta^2}} \left[w - \eta \times \frac{g - ww^\top g}{\|g-ww^\top g\|_2}\right].$$&lt;p&gt;As an exercise for the reader: try calculating the Euclidean norm of the updated weight vector and check that the updated weight vector indeed lies on the hypersphere.&lt;/p&gt;&lt;p&gt;To summarize this section, a first-order manifold optimizer has three steps:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Find the tangent vector of unit length that goes furthest in the gradient direction.&lt;/item&gt;&lt;item&gt;Multiply this direction by the learning rate and subtract from the weights;&lt;/item&gt;&lt;item&gt;Retract the updated weights back to the manifold.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;There are two decisions to make in applying this procedure: what manifold constraint we should use and how we should measure length. By making different decisions, we can generate different optimization algorithms as shown in the following table.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Manifold&lt;/cell&gt;&lt;cell role="head"&gt;Norm&lt;/cell&gt;&lt;cell role="head"&gt;Optimizer&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Euclidean $\mathbb{R}^n$&lt;/cell&gt;&lt;cell&gt;Euclidean norm&lt;/cell&gt;&lt;cell&gt;vanilla gradient descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;Euclidean $\mathbb{R}^n$&lt;/cell&gt;&lt;cell&gt;infinity norm&lt;/cell&gt;&lt;cell&gt;sign gradient descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;hypersphere $S^n$&lt;/cell&gt;&lt;cell&gt;Euclidean norm&lt;/cell&gt;&lt;cell&gt;hyperspherical descent&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;matrix space $\mathbb{R}^{m\times n}$&lt;/cell&gt;&lt;cell&gt;spectral norm&lt;/cell&gt;&lt;cell&gt;Muon&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Stiefel manifold $\subset\mathbb{R}^{m\times n}$&lt;/cell&gt;&lt;cell&gt;spectral norm&lt;/cell&gt;&lt;cell&gt;manifold Muon&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;We will derive the final algorithm in the table, manifold Muon, in the next section. To design a manifold constraint and a distance function for a matrix parameter, we shall think carefully about the role that a weight matrix plays inside a neural network.&lt;/p&gt;&lt;head rend="h2"&gt;Manifold Muon&lt;/head&gt;&lt;p&gt;A typical weight matrix $W$ in a transformer is a “vector-multiplier”, meaning that it transforms an input vector $x$ into an output vector $y = Wx$. We will design a manifold constraint and a distance function so that the matrix acts in a good way on input vectors: the matrix should not produce excessively small or large outputs, and updates to the matrix should not cause the output vector to change too much or too little.&lt;/p&gt;&lt;p&gt;A good way to think about how a matrix acts on vectors is through the singular value decomposition, illustrated in Figure . The SVD decomposes a matrix in a way that tells us how the matrix stretches input vectors along different axes.&lt;/p&gt;&lt;p&gt;We would like the matrix to have a stretching effect close to one, so we will choose a matrix manifold where all the singular values are exactly one. This matrix manifold is known formally as the Stiefel manifold. We can assume without loss of generality that we are dealing with a tall matrix ($m \geq n$), and then the Stiefel manifold can be equivalently defined as the following set:&lt;/p&gt;$$\mathsf{Stiefel}(m,n) := \left\{ W \in \mathbb{R}^{m \times n} \mid W^T W = I_n \right\}.$$&lt;p&gt;Furthermore, one may show that a matrix $A \in \mathbb{R}^{m \times n}$ lies tangentNotice that the Stiefel constraint $W^T W = I_n$ directly generalizes the hyperspherical constraint $w^\top w = 1$ from the previous section. Similarly, the tangent space condition generalizes the hyperspherical one that $a^\top w = 0$. to the Stiefel manifold at matrix $W$ if and only if:&lt;/p&gt;$$A^\top W + W^\top A = 0.$$&lt;p&gt;To design a manifold optimizer for the Stiefel manifold, all that remains is to choose a distance function. To limit the maximum stretching effect the weight update can have on an input vector, we will choose the spectral norm, which measures the largest singular value of a matrix. Although this only limits the maximum effect the update can have, since the optimizer we derive will saturate this bound, it will turn out to prevent the minimum effect of the update from being too small.There are some exceptions to this statement, such as when a weight matrix has a fan-out less than its fan-in, in which case we cannot escape from the matrix and its updates having a null space and mapping some inputs to zero.&lt;/p&gt;&lt;p&gt;The idea of doing gradient descent under a spectral norm constraint is what led to the Muon optimizer and, when combined with the Stiefel manifold constraint, we obtain a problem that we shall call manifold Muon:&lt;/p&gt;$$\min_{A\in\mathbb{R}^{m\times n}} \quad \underbrace{\operatorname{trace}(G^T A)}_{\mathclap{\text{linear change in loss}}} \quad \text{such that} \quad \underbrace{\|A\|_{\text{spectral}} \leq \eta}_{\mathclap{\text{size constraint}}} \quad \text{and} \quad \underbrace{A^T W + W^T A = 0\vphantom{\|A\|_{\text{spectral}} = \eta}}_{\mathclap{\text{tangent constraint}}} \tag{$\dagger$}.$$&lt;p&gt;The manifold Muon problem $(\dagger)$ directly generalizes problem $(\star)$ from the previous section. Solving $(\dagger)$ is harder than solving $(\star)$, and here we will present a numerical solution inspiredI figured out how to solve manifold Muon in the square case late last year, but I was unable to solve the full rectangular case and thus posed the problem as an open problem on the Modula docs. Jianlin Su solved the problem this summer by taking a Lagrangian approach and working out a fixed point iteration on the optimality condition. I saw an early version of Jianlin’s work (which did not quite work yet) and also related work by Franz Louis Cesista, and I was able to work out the dual ascent algorithm presented here. by work done by Jianlin Su and Franz Louis Cesista.&lt;/p&gt;&lt;p&gt;Our key insight is that $(\dagger)$ is a convex optimization problem that may be solved via a standard method known as dual ascent. Here we will just sketch the main idea, but you can find a more detailed derivation on this page.&lt;/p&gt;&lt;p&gt;Similar to Jianlin’s approach, we introduce a matrix of Lagrange multipliers $\Lambda\in\mathbb{R}^{n\times n}$. We then apply a series of transformations to convert the problem $(\dagger)$ from a constrained minimization problem to an unconstrained maximization problem:&lt;/p&gt;$$ \begin{align} (\dagger) &amp;amp;= \min_{\|A\|_\mathrm{spectral} \leq \eta} \max_{\Lambda} \;\operatorname{trace} G^\top A + \operatorname{trace}\Lambda^\top (A^\top W + W^\top A) \\ &amp;amp;= \min_{\|A\|_\mathrm{spectral} \leq \eta} \max_{\Lambda}\; \operatorname{trace}A^\top (G + 2W(\Lambda+\Lambda^\top))\\ &amp;amp;= \max_{\Lambda} \min_{\|A\|_\mathrm{spectral} \leq \eta} \; \operatorname{trace}A^\top (G + 2W(\Lambda+\Lambda^\top))\\ &amp;amp;= \max_{\Lambda} \; - \eta \times \|G + 2W(\Lambda+\Lambda^\top)\|_\mathrm{nuclear}. \end{align} $$&lt;p&gt;Equation (1) reformulates the problem as a saddle point problem: the maximization over $\Lambda$ will send the objective to infinity whenever the tangent space condition is violated. Equation (2) follows by applying properties of the trace and equation (3) follows from Sion’s minimax theorem. The inner minimization in equation (3) is solved by setting $A_\mathrm{opt}(\Lambda) = - \eta \times \operatorname{msign}(G + 2W(\Lambda+\Lambda^\top))$ where $\operatorname{msign}$ is the matrix sign function.The matrix sign function snaps the singular values of a matrix to one. It may be computed efficiently on GPUs via Newton-Schulz iteration or the recent Polar Express algorithm. And we obtain equation (4) by substituting this expression for $A_\mathrm{opt}(\Lambda)$ into equation (3). Equation (4) is known as the “dual problem” to $(\dagger)$ and we can solve it by gradient ascent. After some work, the gradient of the dual function is given by:&lt;/p&gt;$$ \begin{align} H(\Lambda) &amp;amp;:= - \eta \times \nabla_\Lambda \|G + W (\Lambda+\Lambda^\top)\|_\mathrm{nuclear} \\ &amp;amp;= - \eta \times [W^\top\mathrm{msign}(G + 2W (\Lambda+\Lambda^\top)) + \operatorname{msign}(G + 2W (\Lambda+\Lambda^\top))^\top W], \end{align} $$&lt;p&gt;where the nuclear norm $\|\cdot\|_\mathrm{nuclear}$ measures the sum of the singular values of a matrix.&lt;/p&gt;&lt;p&gt;Finally, we can write down the manifold Muon algorithm:Note that this algorithm is closely related to Jianlin Su’s solution. Where we run dual ascent, Jianlin’s solution amounts to solving for the maximum of the dual function $H(\Lambda)=0$ via a fixed point iteration.&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Run gradient ascent on the dual variable $\Lambda \gets \Lambda + \alpha \times H(\Lambda)$ to solve for $\Lambda_\mathrm{opt}$.&lt;/item&gt;&lt;item&gt;Compute the update $A_\mathrm{opt} = - \eta \times \operatorname{msign}(G + 2W(\Lambda_{\mathrm{opt}}+\Lambda_\mathrm{opt}^\top))$.&lt;/item&gt;&lt;item&gt;Apply the update to the weights $W \gets W + A_\mathrm{opt}$.&lt;/item&gt;&lt;item&gt;Retract the weights back to the manifold $W \gets \operatorname{msign}(W)$.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We ran a very small experiment to sanity check the algorithm and provide a minimal implementation for students or researchers to play with. Each training run finishes in less than a minute. The code is here and see Figure for the setup and results.&lt;/p&gt;&lt;head rend="h2"&gt;Modular manifolds&lt;/head&gt;&lt;p&gt;So far in this post, we have discussed manifold constraints for individual parameter tensors and co-designed optimization logic for these constraints. A question we have not answered is: what happens when we combine layers to build networks? Can we think about individual layers in isolation—or do we need to be careful about interactions between layers and modify the optimization logic in response? The goal of this section is to point out that there is a way to extend the reasoning we introduced in the previous two sections to the case of whole networks, and we call this the theory of modular manifolds.The theory of modular manifolds builds on research I did with my friend Tim Large, my postdoc advisor Phillip Isola, my PhD advisor Yisong Yue and many other amazing collaborators. At the end of the section, we provide some links to learn more.&lt;/p&gt;&lt;p&gt;The idea of modular manifolds is to build an abstraction that tells us how to budget learning rates across layers. The actual optimization logic in each layer ends up being the same as what we already worked out, except that the learning rate for a layer is modified depending on where the layer appears in the network. The abstraction rests upon a key observation made in our paper on the modular norm, that budgeting learning rates—both across layers and when scaling up individual layers—is intimately tied to understanding the Lipschitz sensitivity of the network output with respect to the weights. The abstraction tracks this sensitivity as we build the network, and manifold constraints help us get a much tighter understanding of this sensitivity.&lt;/p&gt;&lt;p&gt;The starting point for the abstraction is to think of any neural network module—from a layer to a whole transformer—as a mathematical object with three attributes:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;A forward function $f:\mathcal{W} \times \mathcal{X} \to \mathcal{Y}$ that maps from a parameter space $\mathcal{W} = \mathbb{R}^d$ and an input space $\mathcal{X}$ to an output space $\mathcal{Y}$.&lt;/item&gt;&lt;item&gt;A submanifold of the weight space $\mathcal{M}\subset\mathcal{W}$ that the weights are constrained to.&lt;/item&gt;&lt;item&gt;A norm $\|\cdot\| : \mathcal{W} \to \mathbb{R}$ that acts as a measuring stick on weight space.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;For example, a linear module equipped with the spectral norm and constrained to the Stiefel manifold, for which we have already worked out an optimizer, would be written:&lt;/p&gt;$$ \mathsf{StiefelLinear} = \begin{cases}(W, x) \mapsto Wx, &amp;amp; \text{(forward function)}\\ \mathsf{Stiefel}(m,n), &amp;amp; \text{(manifold)}\\ \|\cdot\|_\mathrm{spectral}. &amp;amp; \text{(norm)}\end{cases}$$&lt;p&gt;Provided that an input $x$ to the $\mathsf{StiefelLinear}$ module has unit $\ell_2$ norm, then $\mathsf{StiefelLinear}$ is Lipschitz with respect to its weights in the module’s assigned norm with Lipschitz constant one:This argument can be extended to the RMS norm on the input and the RMS–RMS operator norm on the weights.&lt;/p&gt;$$\|(W + \Delta W) x - Wx\|_2 \leq \|\Delta W\|_\mathrm{spectral} \times \|x\|_2 = \|\Delta W\|_\mathrm{spectral}.$$&lt;p&gt;This type of Lipschitz statement helps us understand how to scale weight updates to this module since it gives us a bound on how much the output can change when we perturb the weights. But when we compose two modules, can we automatically compile a Lipschitz statement on the joint weight space of the new module? The answer turns out to be yes, if we follow special rules for building the new module:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;The new forward function $f_3$ is given by composing the two existing forward functions $f_1$ and $f_2$: $$f_3((w_1, w_2), x) := f_2(w_2, f_1(w_1, x)). \qquad$$&lt;/item&gt;&lt;item&gt;The new manifold constraint $\mathcal{M}_3$ is just the Cartesian product (see Figure for a fun example) of the two existing manifolds $\mathcal{M}_1$ and $\mathcal{M}_2$: $$\mathcal{M}_3 = \mathcal{M}_1 \times \mathcal{M}_2. \qquad$$&lt;/item&gt;&lt;item&gt;The new norm function is the max of the two existing norm functions weighted by special scalar coefficients $s_1$ and $s_2$. Letting $\|\cdot\|_1$ denote the first module’s norm and $\|\cdot\|_2$ denote the second module’s norm, the new norm $\|\cdot\|_3$ is given by: $$\|(w_1, w_2)\|_3 := \max(s_1\cdot \|w_1\|_1, s_2\cdot \|w_2\|_2). \qquad$$&lt;/item&gt;&lt;/list&gt;&lt;p&gt;When we use this composite norm to derive optimizers—following the same recipe we used in the first two sections of this post—we end up deriving separate optimizers for each layer, but the scalar coefficients $s_i$ budget the learning rates across layers.&lt;/p&gt;&lt;p&gt;We give much more detail on this construction, including extending it to other ways of combining modules, in our paper on the modular norm—although the paper does not cover manifold optimization. You can also check out our paper on modular duality for more on building optimizers in the modular norm. The Modula project builds toward a programmatic implementation of this construction.&lt;/p&gt;&lt;head rend="h2"&gt;Directions for future work&lt;/head&gt;&lt;p&gt;We are excited about any research that tries to make neural network training as principled and automatic as the forward pass. The ideas in this post benefitted strongly from interactions with external researchers like Jianlin Su and Franz Louis Cesista. We would love to see more work on these topics from the community.&lt;/p&gt;&lt;p&gt;Some possible directions for future work are:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Modularity. What manifolds should attention heads live on? Should embeddings be constrained differently than unembeddings? We can mix-and-match constraints in different parts of the network, or leave some tensors unconstrained.&lt;/item&gt;&lt;item&gt;Numerics. Manifold constraints also place constraints on the range of values that individual weight entries can take. Does this impact numerics, or make low-precision training easier?&lt;/item&gt;&lt;item&gt;Convex optimization. The manifold Muon algorithm involves running dual ascent. Can we apply more sophisticated convex optimization techniques to solve the dual problem faster or more reliably?&lt;/item&gt;&lt;item&gt;Convergence analysis. How fast do these algorithms converge? Does good conditioning of the weight matrices benefit convergence? Is there more that we can say theoretically?&lt;/item&gt;&lt;item&gt;Regularization. Manifold constraints implicitly regularize the model. Could we design constraints or tune their radii to improve generalization?&lt;/item&gt;&lt;item&gt;Architecture-optimizer co-design. While hard manifold constraints may not ultimately be the right way to constrain weight matrices, they exemplify the idea of tightly co-designing optimization algorithms with architecural components. Are there more opportunities here?&lt;/item&gt;&lt;item&gt;Non-Riemannian geometry. Most work on manifold optimization works in a Riemannian world where distances are induced by inner products and norm balls are ellipsoids. But neural networks are different: matrices act as operators, and operator norms like the spectral norm do not emerge from inner products. This implies, for example, that norm balls can have sharp corners and there is no unique gradient flow. Is there more to be discovered in this non-Riemannian world?&lt;/item&gt;&lt;item&gt;Practical implementation. Applying these techniques at scale requires efficient manifold operations on GPUs. The recent Polar Express paper shows promise for fast matrix sign computation. What other algorithmic innovations do we need?&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Further reading&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Manifold optimization. Absil, Mahony &amp;amp; Sepulchre’s textbook is a standard reference. For the Stiefel manifold specifically, see Edelman et al, 1998. These works live in a Riemannian world. Similarly most machine learning papers that consider optimization on the Stiefel manifold take a Riemannian point of view: see Li et al, 2020, Kong et al, 2022 and Park et al, 2025 for some examples.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Non-Riemannian geometry in machine learning. Thomas Flynn’s paper from 2017 on duality structure gradient descent characterizes the neural network weight space as a Finsler manifold, meaning a manifold equipped with a norm. It is well worth a read. Also see Jianlin Su’s recent blog post on Stiefel Muon as well as Franz Louis Cesista’s blog post on a heuristic solution to Muon on the Stiefel manifold. Franz also wrote a followup blog post generalizing the solution presented here. The Scion paper imposes weight constraints a different way via convex combinations and Carlson et al, 2015 wrote an early paper on (unconstrained) spectral descent.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The Modula project. The goal of the Modula project is to build a library that automatically compiles steepest descent optimizers along with Lipschitz statements for general architectures. Check out the project page at https://modula.systems as well as our paper on the modular norm and modular duality. Our optimization anthology also provides an accessible route into this space of ideas.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Lipschitz-constrained deep learning. There has been a lot of work on this topic. For example, check out Louis Béthune and Tsui-Wei Weng’s PhD theses. Usually work on this topic does not connect weight-Lipschitzness to optimizer design. See also Anil et al, 2018 and our paper Newhouse et al, 2025.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Citation&lt;/head&gt;&lt;p&gt;Please cite this work as:&lt;/p&gt;&lt;code&gt;Jeremy Bernstein, "Modular Manifolds",
Thinking Machines Lab: Connectionism, Sep 2025.
&lt;/code&gt;&lt;p&gt;Or use the BibTeX citation:&lt;/p&gt;&lt;code&gt;@article{bernstein2025manifolds,
  author = {Jeremy Bernstein},
  title = {Modular Manifolds},
  journal = {Thinking Machines Lab: Connectionism},
  year = {2025},
  note = {https://thinkingmachines.ai/blog/modular-manifolds/},
  doi = {10.64434/tml.20250926}
}
&lt;/code&gt;
    
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thinkingmachines.ai/blog/modular-manifolds/"/><published>2025-09-26T17:06:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45388770</id><title>Informed poll</title><updated>2025-09-26T20:11:01.048623+00:00</updated><content>&lt;doc fingerprint="3e4e5fc6cfaa138a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Informed poll#&lt;/head&gt;
    &lt;p&gt;pw_async2: Cooperative async tasks for embedded&lt;/p&gt;
    &lt;p&gt;The informed poll programming model is the core design philosophy behind &lt;code&gt;pw_async2&lt;/code&gt;. Informed poll provides an alternative to callback-based
asynchronous programming that is highly efficient, requires no dynamic memory
allocation, and simplifies state management for complex concurrent operations.
This model was popularized by Rustâs Future trait and was first proposed for
Pigweed in SEED 0112. We find that informed poll is very
well-suited for resource-constrained embedded systems. Itâs not yet a
common paradigm in embedded C++ codebases, though, so we strongly encourage all
&lt;code&gt;pw_async2&lt;/code&gt; users to read this page and internalize the informed poll
worldview before attempting to use &lt;code&gt;pw_async2&lt;/code&gt;!&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary#&lt;/head&gt;
    &lt;p&gt;The central idea is that asynchronous work is encapsulated in objects called Tasks. Instead of registering callbacks for different events, a central Dispatcher polls these tasks to see if they can make progress. The polling is informed because the task coordinates with its event source regarding when itâs ready to make more progress. The event source notifies the dispatcher when the task is ready to proceed and therefore should be polled again.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core components#&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;pw_async2&lt;/code&gt; is built upon a few fundamental concepts that work together to
provide a powerful asynchronous runtime.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tasks, the basic async primitive#&lt;/head&gt;
    &lt;p&gt;A Task is the basic unit of execution, analogous to a cooperatively scheduled thread. Itâs an object that represents a job to be done, like reading from a sensor or processing a network packet. Users implement a taskâs logic in its DoPend() method.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cooperative scheduling with Dispatchers#&lt;/head&gt;
    &lt;p&gt;The Dispatcher is the cooperative scheduler. It maintains a queue of tasks that are ready to be polled.&lt;/p&gt;
    &lt;head rend="h3"&gt;Running tasks and communicating task state#&lt;/head&gt;
    &lt;p&gt;The dispatcher runs a task by calling &lt;code&gt;Pend()&lt;/code&gt;, which is a non-virtual
wrapper around &lt;code&gt;DoPend()&lt;/code&gt;.  The task attempts to make progress and
communicates to the dispatcher what state itâs in by returning one of these
values:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Ready(): The task has finished its work. The&lt;/p&gt;&lt;code&gt;Dispatcher&lt;/code&gt;should not poll it again.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pending(): The task is not yet finished because it is waiting for an external event. E.g. itâs waiting for a timer to finish or for data to arrive. The dispatcher should put the task to sleep and then run it again later.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;A user writing a task implements &lt;code&gt;DoPend()&lt;/code&gt;, but they too call &lt;code&gt;Pend()&lt;/code&gt;
when calling other tasks. &lt;code&gt;Pend()&lt;/code&gt; is also the interface of âpendable
objectsâ used throughout &lt;code&gt;pw_async2&lt;/code&gt; such as Select, Join, and
coroutines.&lt;/p&gt;
    &lt;head rend="h3"&gt;âInformedâ polling with wakers#&lt;/head&gt;
    &lt;p&gt;When a taskâs &lt;code&gt;DoPend&lt;/code&gt; method returns &lt;code&gt;Pending()&lt;/code&gt;, the task must ensure
that something will eventually trigger it to be run again. This is the
âinformedâ part of the model: the task informs the &lt;code&gt;Dispatcher&lt;/code&gt; when itâs
ready to be polled again. This is achieved using a Waker.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Before returning&lt;/p&gt;&lt;code&gt;Pending()&lt;/code&gt;, the task must obtain its&lt;code&gt;Waker&lt;/code&gt;from the Context and store it somewhere thatâs accessible to the event source. Common event sources include interrupt handlers and timer managers.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;When the event occurs, the event source calls Waker::Wake() on the stored&lt;/p&gt;&lt;code&gt;Waker&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;Wake()&lt;/code&gt;call notifies the&lt;code&gt;Dispatcher&lt;/code&gt;that the task is ready to make progress.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;Dispatcher&lt;/code&gt;moves the task back into its run queue and polls it again in the future.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This mechanism prevents the &lt;code&gt;Dispatcher&lt;/code&gt; from having to wastefully poll tasks
that arenât ready, allowing it to sleep and save power when no work can be
done.&lt;/p&gt;
    &lt;p&gt;The following diagram illustrates the interaction between these components:&lt;/p&gt;
    &lt;head rend="h2"&gt;Comparison with Rustâs informed polling#&lt;/head&gt;
    &lt;p&gt;The basic idea of informed poll is the same: register a waker to be notified when to poll.&lt;/p&gt;
    &lt;p&gt;Async Rust is built around the Future trait, which &lt;code&gt;pw_async2&lt;/code&gt; doesnât
have. &lt;code&gt;pw_async2&lt;/code&gt; informally has âpendableâ objects, but unlike Rustâs
Future (or Stream), the semantics are unspecified. We plan to formalize
these concepts in &lt;code&gt;pw_async2&lt;/code&gt; and narrow the conceptual gap with Rust.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pigweed.dev/pw_async2/informed_poll.html"/><published>2025-09-26T17:11:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45389267</id><title>SimpleFold: Folding proteins is simpler than you think</title><updated>2025-09-26T20:11:00.534783+00:00</updated><content>&lt;doc fingerprint="dd791d51782a9c92"&gt;
  &lt;main&gt;
    &lt;p&gt;This github repository accompanies the research paper, SimpleFold: Folding Proteins is Simpler than You Think (Arxiv 2025).&lt;/p&gt;
    &lt;p&gt;Yuyang Wang, Jiarui Lu, Navdeep Jaitly, Joshua M. Susskind, Miguel Angel Bautista&lt;/p&gt;
    &lt;p&gt;We introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer layers. SimpleFold does not rely on expensive modules like triangle attention or pair representation biases, and is trained via a generative flow-matching objective. We scale SimpleFold to 3B parameters and train it on more than 8.6M distilled protein structures together with experimental PDB data. To the best of our knowledge, SimpleFold is the largest scale folding model ever developed. On standard folding benchmarks, SimpleFold-3B model achieves competitive performance compared to state-of-the-art baselines. Due to its generative training objective, SimpleFold also demonstrates strong performance in ensemble prediction. SimpleFold challenges the reliance on complex domain-specific architectures designs in folding, highlighting an alternative yet important avenue of progress in protein structure prediction.&lt;/p&gt;
    &lt;p&gt;To install &lt;code&gt;simplefold&lt;/code&gt; package from github repository, run&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/apple/ml-simplefold.git
cd ml-simplefold
python -m pip install -U pip build; pip install -e .
pip install git+https://github.com/facebookresearch/esm.git # Optional for MLX backend
&lt;/code&gt;
    &lt;p&gt;We provide a jupyter notebook &lt;code&gt;sample.ipynb&lt;/code&gt; to predict protein structures from example protein sequences.&lt;/p&gt;
    &lt;p&gt;Once you have &lt;code&gt;simplefold&lt;/code&gt; package installed, you can predict the protein structure from target fasta file(s) via the following command line. We provide support for both PyTorch and MLX (recommended for Apple hardware) backends in inference.&lt;/p&gt;
    &lt;code&gt;simplefold \
    --simplefold_model simplefold_100M \  # specify folding model in simplefold_100M/360M/700M/1.1B/1.6B/3B
    --num_steps 500 --tau 0.01 \        # specify inference setting
    --nsample_per_protein 1 \           # number of generated conformers per target
    --plddt \                           # output pLDDT
    --fasta_path [FASTA_PATH] \         # path to the target fasta directory or file
    --output_dir [OUTPUT_DIR] \         # path to the output directory
    --backend [mlx, torch]              # choose from MLX and PyTorch for inference backend 
&lt;/code&gt;
    &lt;p&gt;We provide predicted structures from SimpleFold of different model sizes:&lt;/p&gt;
    &lt;code&gt;https://ml-site.cdn-apple.com/models/simplefold/cameo22_predictions.zip # predicted structures of CAMEO22
https://ml-site.cdn-apple.com/models/simplefold/casp14_predictions.zip  # predicted structures of CASP14
https://ml-site.cdn-apple.com/models/simplefold/apo_predictions.zip     # predicted structures of Apo
https://ml-site.cdn-apple.com/models/simplefold/codnas_predictions.zip  # predicted structures of Fold-switch (CoDNaS)
&lt;/code&gt;
    &lt;p&gt;We use the docker image of openstructure 2.9.1 to evaluate generated structures for folding tasks (i.e., CASP14/CAMEO22). Once having the docker image enabled, you can run evaluation via:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/evaluation/analyze_folding.py \
    --data_dir [PATH_TO_TARGET_MMCIF] \
    --sample_dir [PATH_TO_PREDICTED_MMCIF] \
    --out_dir [PATH_TO_OUTPUT] \
    --max-workers [NUMBER_OF_WORKERS]
&lt;/code&gt;
    &lt;p&gt;To evaluate results of two-state prediction (i.e., Apo/CoDNaS), one need to compile the TMsore and then run evaluation via:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/evaluation/analyze_two_state.py \ 
    --data_dir [PATH_TO_TARGET_DATA_DIRECTORY] \
    --sample_dir [PATH_TO_PREDICTED_PDB] \
    --tm_bin [PATH_TO_TMscore_BINARY] \
    --task apo \ # choose from apo and codnas
    --nsample 5
&lt;/code&gt;
    &lt;p&gt;You can also train or tune SimpleFold on your end. Instructions below include details for SimpleFold training.&lt;/p&gt;
    &lt;p&gt;SimpleFold is trained on joint datasets including experimental structures from PDB, as well as distilled predictions from AFDB SwissProt and AFESM. Target lists of filtered SwissProt and AFESM targets thta are used in our training can be found:&lt;/p&gt;
    &lt;code&gt;https://ml-site.cdn-apple.com/models/simplefold/swissprot_list.csv # list of filted SwissProt (~270K targets)
https://ml-site.cdn-apple.com/models/simplefold/afesm_list.csv # list of filted AFESM targets (~1.9M targets)
https://ml-site.cdn-apple.com/models/simplefold/afesme_dict.json # list of filted extended AFESM (AFESM-E) (~8.6M targets)
&lt;/code&gt;
    &lt;p&gt;In &lt;code&gt;afesme_dict.json&lt;/code&gt;, the data is stored in the following structure:&lt;/p&gt;
    &lt;code&gt;{
    cluster 1 ID: {"members": [protein 1 ID, protein 2 ID, ...]},
    cluster 2 ID: {"members": [protein 1 ID, protein 2 ID, ...]},
    ...
}
&lt;/code&gt;
    &lt;p&gt;Of course, one can use own customized datasets to train or tune SimpleFold models. Instructions below list how to process the dataset for SimpleFold training.&lt;/p&gt;
    &lt;p&gt;To process downloaded mmcif files, you need Redis installed and launch the Redis server:&lt;/p&gt;
    &lt;code&gt;wget https://boltz1.s3.us-east-2.amazonaws.com/ccd.rdb
redis-server --dbfilename ccd.rdb --port 7777
&lt;/code&gt;
    &lt;p&gt;You can then process mmcif files to input format for SimpleFold:&lt;/p&gt;
    &lt;code&gt;python src/simplefold/process_mmcif.py \
    --data_dir [MMCIF_DIR]   # directory of mmcif files
    --out_dir [OUTPUT_DIR]   # directory of processed targets
    --use-assembly
&lt;/code&gt;
    &lt;p&gt;The configuration of model is based on &lt;code&gt;Hydra&lt;/code&gt;. An example training configuration can be found in &lt;code&gt;configs/experiment/train&lt;/code&gt;. To change dataset and model settings, one can refer to config files in &lt;code&gt;configs/data&lt;/code&gt; and &lt;code&gt;configs/model&lt;/code&gt;. To initiate SimpleFold training:&lt;/p&gt;
    &lt;code&gt;python train experiment=train
&lt;/code&gt;
    &lt;p&gt;To train SimpleFold with FSDP strategy:&lt;/p&gt;
    &lt;code&gt;python train_fsdp.py experiment=train_fsdp
&lt;/code&gt;
    &lt;p&gt;If you found this code useful, please cite the following paper:&lt;/p&gt;
    &lt;code&gt;@article{simplefold,
  title={SimpleFold: Folding Proteins is Simpler than You Think},
  author={Wang, Yuyang and Lu, Jiarui and Jaitly, Navdeep and Susskind, Josh and Bautista, Miguel Angel},
  journal={arXiv preprint arXiv:2509.18480},
  year={2025}
}
&lt;/code&gt;
    &lt;p&gt;Our codebase is built using multiple opensource contributions, please see ACKNOWLEDGEMENTS for more details.&lt;/p&gt;
    &lt;p&gt;Please check out the repository LICENSE before using the provided code and LICENSE_MODEL for the released models.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/apple/ml-simplefold"/><published>2025-09-26T18:01:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45389293</id><title>Auth.js Joining Better Auth</title><updated>2025-09-26T20:11:00.376379+00:00</updated><content>&lt;doc fingerprint="ea4da198952d5ce"&gt;
  &lt;main&gt;
    &lt;p&gt;We’re excited to announce that Auth.js, formerly known as NextAuth.js, is now being maintained and overseen by Better Auth team. If you haven't heard of Auth.js, it has long been one of the most widely used open source authentication libraries in the JavaScript ecosystem. Chances are, if you’ve used ChatGPT, Google Labs, Cal.com or a million other websites, you’ve already interacted with Auth.js.&lt;/p&gt;
    &lt;head rend="h2"&gt;Back Story about Better Auth and Auth.js&lt;/head&gt;
    &lt;p&gt;Before Better Auth, Auth.js gave developers like us the ability to own our auth without spending months wrestling with OAuth integrations or session management. But as applications became more complex and authentication needs evolved, some of its limitations became harder to ignore. We found ourselves rebuilding the same primitives over and over.&lt;/p&gt;
    &lt;p&gt;The Auth.js team recognized these challenges and had big ideas for the future, but for various reasons couldn’t execute them as fully as they hoped.&lt;/p&gt;
    &lt;p&gt;That shared frustration and the vision of empowering everyone to truly own their auth started the creation of Better Auth. Since our goals aligned with the Auth.js team, we were excited to help maintain Auth.js and make auth better across the web. As we talked more, we realized that Better Auth was the best home for Auth.js.&lt;/p&gt;
    &lt;head rend="h2"&gt;What does this mean for existing users?&lt;/head&gt;
    &lt;p&gt;We recognize how important this project is for countless applications, companies, and developers. If you’re using Auth.js/NextAuth.js today, you can continue doing so without disruption—we’ll keep addressing security patches and urgent issues as they come up.&lt;/p&gt;
    &lt;p&gt;But we strongly recommend new projects to start with Better Auth unless there are some very specific feature gaps (most notably stateless session management without a database). Our roadmap includes bringing those capabilities into Better Auth, so the ecosystem can converge rather than fragment.&lt;/p&gt;
    &lt;p&gt;For teams considering migration, we’ve prepared a guide and we’ll be adding more guides and documentation soon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;We are deeply grateful to the Auth.js community who have carried the project to this point. In particular, the core maintainers-Balázs, who served as lead maintainer, Thang Vu,Nico Domino, Lluis Agusti and Falco Winkler-pushed through difficult phases, brought in new primitives, and kept the project alive long enough for this transition to even be possible.&lt;/p&gt;
    &lt;p&gt;Better Auth beginning was inspired by Auth.js, and now, together, the two projects can carry the ecosystem further. The end goal remains unchanged: you should own your auth!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.better-auth.com/blog/authjs-joins-better-auth"/><published>2025-09-26T18:04:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45389889</id><title>When Bruce Lee trained with Kareem Abdul-Jabbar</title><updated>2025-09-26T20:11:00.151986+00:00</updated><content>&lt;doc fingerprint="be648895d3a52e5f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;When Bruce Lee Trained With Kareem Abdul-Jabbar&lt;/head&gt;
    &lt;head rend="h3"&gt;Jeff Chang on What Two Iconic Athletes Learned From Their Collaboration&lt;/head&gt;
    &lt;p&gt;When Bruce Lee met Kareem Abdul-Jabbar, a month after the 1968 national college basketball championship, he was still known as Lew Alcindor, the most hyped young basketball star in history.&lt;/p&gt;
    &lt;p&gt;Lew was seven feet two and, for his whole life, had been unable to hide. He disarmed reporters with a fierce intelligence masked by a laconic intensity. He was just completing his junior year at UCLA, and after indulging in two years of partying, drugs, and women, he wanted something different. “All sophomore and junior years I’d been looking for something to believe in,” he would later write.&lt;/p&gt;
    &lt;p&gt;During those two years, he had been in the eye of the storm. In the “Game of the Century,” witnessed by fifty-two thousand in the Houston Astrodome and millions more on television on January 20, 1968, he brought men’s college basketball to new heights. That night he played with blurred vision after having his cornea scratched. UCLA lost by a basket to the University of Houston, breaking their forty-seven- game winning streak, and the team melted down in its aftermath. Lew’s closest friend, a Black man from South Central Los Angeles, quit the team in a dispute with coach John Wooden, and racial tensions simmered in the locker room the rest of the season.&lt;/p&gt;
    &lt;p&gt;To him, Bruce was as effective a teacher as John Wooden. Both were focused on fundamentals, preparation, and what worked.&lt;/p&gt;
    &lt;p&gt;By the end of the season, Lew had led UCLA to its second consecutive national championship and was voted Most Outstanding Player for the second year in a row. It was the year that began the “March Madness” era. But after the season, he retreated.&lt;/p&gt;
    &lt;p&gt;Born Ferdinand Lewis Alcindor in 1947, the day after Jackie Robinson desegregated pro sports, he had grown up in an integrated housing project in uptown Manhattan. In third grade he stared at a Polaroid of his class: “There I was, freakishly towering over all the other kids, with skin much darker than everyone else’s.” When he was twelve, his white friends abandoned him. His former best friend picked a fight with him one day, calling him a “jungle bunny” and “big jungle n——r.”&lt;/p&gt;
    &lt;p&gt;At seventeen, Lew stepped out of the subway in Harlem and was caught in the first hours of six days of rioting that followed the police shooting of a Black teen. As bottles and bullets whizzed by and buildings went up in flames, he ran home. “Right then and there I knew who I was and who I was going to be. I was going to be Black rage personified, Black power in the flesh,” he later wrote. He led his team to a 79-2 record and two national high school championships. But once, to motivate him in a game, his coach had called him a “n——r,” and he never forgot it.&lt;/p&gt;
    &lt;p&gt;In his sophomore year at UCLA, in 1967, he was traveling with extra security because of death threats. He took comfort in listening to hard bop and reading about African and Asian history and religion. He was particularly captivated by The Autobiography of Malcolm X and the late Black leader’s journey into Sunni Islam, and sought out young Black Muslims in Los Angeles.&lt;/p&gt;
    &lt;p&gt;That summer he was the only college athlete among a group of prominent Black athletes invited by Jim Brown to meet with Muhammad Ali to try to change the boxer’s mind about his anti-war stance. Ali had asked, “Why should they ask me to put on a uniform and go ten thousand miles from home and drop bombs and bullets on brown people in Vietnam while so-called Negro people in Louisville are treated like dogs and denied simple human rights?” After declaring, “I don’t have no personal quarrel with those Vietcong,” he saw his heavyweight boxing title revoked, and faced a prison sentence for draft evasion. The men spent hours grilling Ali on his position, then emerged to face the press. Alcindor sat beside Brown, Ali, and Bill Russell as the athletes joined together in a historic show of solidarity for Ali.&lt;/p&gt;
    &lt;p&gt;Invited to a Black Youth conference by a young San Jose State College professor named Harry Edwards, who was organizing a Black athletes’ boycott of the 1968 Olympics, Alcindor spoke with conviction:&lt;/p&gt;
    &lt;p&gt;I’m the big basketball star, the weekend hero, everybody’s All American. Well, I was almost killed by a racist cop shooting at a black cat in Harlem. He was shooting on the street—where masses of people were standing around or just taking a walk. But he didn’t care. After all we were just n——rs. I found out that we don’t catch hell because we aren’t basketball stars or because we don’t have money. We catch hell because we are black. Somewhere each of us has got to make a stand against this kind of thing.&lt;/p&gt;
    &lt;p&gt;But in the media, an explosion of racist invective followed him and other Black athletes as they were accused by white writers of being ungrateful, unpatriotic, uppity “Black Hitlers.”&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;Weeks after the 1967 championship, the NCAA banned the dunk—in what became known as the “Alcindor rule”—an effort he believed was racist. Forced to improvise, he contemplated how to deal with triple-team defenses and worked on a new offensive weapon: the skyhook. One night after watching a Zatoichi flick, he was struck by the idea that the blind swordsman’s grace, control, and precision might be exactly what he needed. Instead of brute force, he thought, I will slide and roll and slip by them without fouling. In New York City, Alcindor started training in aikido.&lt;/p&gt;
    &lt;p&gt;“A victory [in martial arts] is your mind over someone else’s mind, as much as, if not more than, a simple physical mastery,” he later wrote. “The discipline also becomes a means of staying in shape mentally and keeping your entire inner self trained.”&lt;/p&gt;
    &lt;p&gt;That fall Alcindor visited the Black Belt offices to meet a fellow aikido adept, Mito Uyehara, and ask him if he knew someone with whom he could continue his martial arts training. Alcindor had become especially curious about tai chi. “This guy Bruce Lee—he’s really good at it,” Mito told him. “He knows more about those things than I do.”&lt;/p&gt;
    &lt;p&gt;“Who’s Bruce Lee?” Alcindor asked. “He was Kato in The Green Hornet.”&lt;/p&gt;
    &lt;p&gt;Alcindor was skeptical he could learn anything from an actor. “No, no! He’s the real deal.”&lt;/p&gt;
    &lt;p&gt;That night Mito drove to see Bruce and said he was sending Lew Alcindor over. “Who’s Lew Alcindor?” Bruce asked.&lt;/p&gt;
    &lt;p&gt;Mito explained that he was the tallest and most famous college basketball player in the country.&lt;/p&gt;
    &lt;p&gt;“I don’t watch basketball.”&lt;/p&gt;
    &lt;p&gt;Bruce asked Linda to bring a tape measure, stood on a chair, and dropped it down, to visualize Alcindor’s height. Then he thought aloud, “I wonder how fast he is.” Mito assured Bruce he was very fast, one of the best athletes in the world.&lt;/p&gt;
    &lt;p&gt;“He would have no chance with me,” Bruce said with a chuckle. “I would break his legs before he could do anything else.”&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;They met for the first time at Bruce and Linda’s house on a comfortable Los Angeles afternoon.&lt;/p&gt;
    &lt;p&gt;“He greeted me with a broad smile and friendly demeanor and right away I knew this was not a scowling teacher from Japanese films demanding bowing obedience,” Alcindor recalled. “We talked UCLA basketball for a while and then got down to business.”&lt;/p&gt;
    &lt;p&gt;Bruce first had Lew punch and kick the heavy bag, so he could gauge the big man’s power. Then he called Linda over, asked Lew to hold a pad to his chest, and told Linda to kick it. Linda grinned and got up from the patio seat where she had been watching.&lt;/p&gt;
    &lt;p&gt;“Bruce, I don’t think this will work,” Alcindor said. “I’m two feet taller and a hundred pounds heavier than Linda.”&lt;/p&gt;
    &lt;p&gt;“Just hold it up to your chest, Lew,” Linda said.&lt;/p&gt;
    &lt;p&gt;He lowered the pad so that it would be below her head.&lt;/p&gt;
    &lt;p&gt;“Your chest,” Linda said, frowning and pointing at the pad. “Do you want Bruce to show you where that is?”&lt;/p&gt;
    &lt;p&gt;He moved the pad up. Bruce nodded at Linda. Kareem would never forget what happened next.&lt;/p&gt;
    &lt;p&gt;“Suddenly Linda fired off a kick that not only reached the pad, but the impact rocked me backward a few feet, readjusted my spine, and possibly rearranged the order of my teeth,” he remembered. “They stood there smiling at the shocked expression on my face.”&lt;/p&gt;
    &lt;p&gt;Linda—Bruce’s longest-running student except for Taky—had just done what Bill Walton, Happy Hairston, Kent Benson, and Robert Parish never would.&lt;/p&gt;
    &lt;p&gt;“Okay,” Alcindor said, still sore where she had kicked him. “Teach me that.”&lt;/p&gt;
    &lt;p&gt;Bruce was just as intrigued. Not long afterward, he told Leo Fong, “You know why I’m getting him to train with me? I want to learn how to beat a tall guy!”&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;“Big Lew,” as Bruce called him, came to his backyard every Tuesday during the off-season, and sometimes Thursdays as well. Bruce taught him Jeet Kune Do footwork, the mook jong dummy, and punches and kicks on the bag. At first, Bruce told Mito that Big Lew was slow, his arms were weak, and he wasn’t good at chi sao. A reporter who witnessed one of their workouts was more impressed with Bruce than Big Lew. He wrote that Bruce could “leap and kick over Alcindor’s head, and says he can defeat him by taking advantage of his shin and thigh with a kick.”&lt;/p&gt;
    &lt;p&gt;But Bruce soon realized all that was irrelevant. Even if he could get inside Big Lew’s reach, it wasn’t easy. And with his front kick, Big Lew could rattle the rim of the basket. Bruce’s Wing Chun skills were all but useless. He joked with Doug Palmer, “Try doing chi sao with someone when you’re staring at his belly button.” Bruce called Taky and told him not to focus on chi sao in the school anymore.&lt;/p&gt;
    &lt;p&gt;“Bruce and I sparred regularly,” Kareem remembered. “But we didn’t compete; I was like a drawing board on which he could work out his theories and he was instructing me how to deal with people and attack him.”&lt;/p&gt;
    &lt;p&gt;Kareem came to appreciate Bruce’s approach. “Nothing was for art’s sake. Everything he taught was to achieve an end in doing damage to an opponent,” he recalled. “After studying for a little while, you learn a lot about how easy it is to hurt someone, and how easily you can get hurt. That makes you really respect what you’re involved in. With violence, you learn to respect it and see how easily you can become victimized by it.”&lt;/p&gt;
    &lt;p&gt;To him, Bruce was as effective a teacher as John Wooden. Both were focused on fundamentals, preparation, and what worked. “Bruce used to say, ‘I fear not the man who has practiced 10,000 kicks once, but I fear the man who has practiced one kick 10,000 times.’ In sports, we call this concept ‘muscle memory,’” he said. “For me, my hook shot was the one kick practiced 10,000 times.”&lt;/p&gt;
    &lt;p&gt;Bruce helped the young athlete understand his movements in a way that seemed to decelerate time. “Bruce showed me how to harness some of what was raging inside me and summon it completely at my will. The Chinese call it chi; the Japanese, ki; the Indians, prana—it is the life force,” he said. “I was quite amazed to find, after working with Bruce, that when I really had my presence of mind, when I did control my life force, that’s what I saw, things coming at me in slow motion with plenty of time to get out of the way.&lt;/p&gt;
    &lt;p&gt;Bruce helped the young athlete understand his movements in a way that seemed to decelerate time.&lt;/p&gt;
    &lt;p&gt;“It sounded mystical when he first told me, but I was becoming increasingly involved in matters of faith, and besides, Bruce grounded his philosophies in a good fight, which I could relate to.”&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;These sessions were a refuge from the media, who were painting Lew Alcindor as a coddled, ungrateful, unpatriotic athlete. In July 1968 he had agreed to an interview on the Today show to highlight the summer program for Black youths where he was working. But sports announcer Joe Garagiola ambushed him, asking Alcindor why he had declined to play in the Olympics. “You live here,” Garagiola said.&lt;/p&gt;
    &lt;p&gt;“Yeah, I live here, but it’s not really my country,” Alcindor answered. “Well then, there’s only one solution: maybe you should move.”&lt;/p&gt;
    &lt;p&gt;“Well, you see,” Alcindor responded, heating up, “that would be fine with me, you know, it all depends on where we are going to move?”&lt;/p&gt;
    &lt;p&gt;The producers cut away to a commercial.&lt;/p&gt;
    &lt;p&gt;“I felt no part of the country and had no desire to help it look good,” he later recalled. “I had better things to do.”&lt;/p&gt;
    &lt;p&gt;That summer he joined a mosque, declared shahada, became a Sunni Muslim, and received a new name: Abdul-Kareem, later Kareem Abdul-Jabbar, “noble, generous servant, powerful spirit.” He kept his name to himself and his closest friends until he asked the media two years later to call him by it. He recalled, “I was still Lew to almost everybody, as if I knew them but they didn’t know me….&lt;/p&gt;
    &lt;p&gt;“The heat I’d taken about the Olympics, and the absolute unwillingness I’d found in the press, and by extension the general public, to accept what to me seemed so obvious—that the country was run by white people for white people, and that even the most powerful Black men were still operating at a handicap—made me suspicious of strangers and even more jealous of my privacy.”&lt;/p&gt;
    &lt;p&gt;But with Bruce, everything was easy. The two talked philosophy and religion. They went to see Zatoichi flicks. Kareem even babysat sometimes, lifting Brandon up to give the five-year-old a view of the roof. They shared an understanding of fame and privacy. From youth, both of them had been under the spotlight.&lt;/p&gt;
    &lt;p&gt;In Chinatown they never paid for meals—everyone was a UCLA fan—and they often ate in the kitchen. Bruce joked to their companions that it would guarantee they weren’t getting the garbage served to the gweilo. But Bruce was also shielding the big man from the rabid autograph seekers.&lt;/p&gt;
    &lt;p&gt;“Bruce and I had something else in common,” Kareem recalled. “We both had experienced discrimination.”&lt;/p&gt;
    &lt;p&gt;Kareem talked about the Black liberation movement and his role in what Harry Edwards had come to call “the revolt of the Black athlete.” Bruce shared his frustrations with Hollywood, saying he sometimes felt like a “valet to the stars.” They swapped books. Bruce gave Kareem Miyamoto Musashi’s Book of Five Rings. Kareem gave him books to read on Islam and imperialism. He told a shocked Bruce that Europeans had barred Chinese from parks in their own cities.&lt;/p&gt;
    &lt;p&gt;“I recommended certain books about the British occupation of China,” Kareem said. “He didn’t know anything about that, and he’d gone to school in Hong Kong.”&lt;/p&gt;
    &lt;p&gt;__________________________________&lt;/p&gt;
    &lt;p&gt;Excerpted from the book Water Mirror Echo: Bruce Lee and the Making of Asian America by Jeff Chang. Copyright © 2025 by Jeff Chang. From Mariner Books, an imprint of HarperCollins Publishers. Reprinted by permission.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lithub.com/when-bruce-lee-trained-with-kareem-abdul-jabbar/"/><published>2025-09-26T19:04:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45389965</id><title>If you are harassed by lasers</title><updated>2025-09-26T20:10:59.543987+00:00</updated><content>&lt;doc fingerprint="76c29116b4a1179f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Home&lt;/head&gt;
    &lt;head rend="h2"&gt;A comprehensive resource for safe and responsible laser use&lt;/head&gt;
    &lt;head rend="h1"&gt;If you are harassed by lasers&lt;/head&gt;
    &lt;head rend="h3"&gt;If the light is obviously coming from a laser&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple harassment -- a beam on your skin or clothes -- is probably not punishable unless it continues, or unless it occurs during a critical situation such as driving.&lt;/item&gt;
      &lt;item&gt;Deliberate aiming at your head or eyes is serious due to the unlikely but possible potential for causing eye damage. This could be considered as assault. For more on eye damage, see the information on when does a laser pointer get powerful enough to be dangerous.&lt;/item&gt;
      &lt;item&gt;If you have had laser light in your eyes, see the page If you are hit by a laser.&lt;/item&gt;
      &lt;item&gt;A partial list of laser harassment incidents is here.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, here is a case in 2018 of a visible green laser harassing a number of people at least five times over two weeks. The laser can easily be seen and photographed:&lt;/p&gt;
    &lt;head rend="h3"&gt;If you see laser beams or dots in a photo or video&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;The green and blue "laser" dots at lower left are actually lens flare caused by the bright sun at upper right. The sun is reflecting off elements inside the lens, causing dots or flare. The flare is almost always located diagonally mirrored from a bright light source.&lt;lb/&gt;Photo of a sunset, with upper and lower "beams" caused by blooming in the camera sensor.&lt;lb/&gt;This is a still frame from a video taken at night by the driver of a moving car, out their driver-side window. &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The line on the left is a trail of a flying insect, not a laser beam. It is a curved, short line segment. If it was a laser beam it would be straight and it would not stop in mid-air like this. Plus note that the path is not aimed at the camera or the house. Even if it was a laser beam, it would not hit anyone in the house on the right where the camera is. &lt;/p&gt;
    &lt;p&gt;Click on the picture below to see video of a lens flare which looks remarkably like a laser. However, it is definitely a lens flare; there are many clues as to why it is actually the sun in the upper right reflecting off the inside of camera elements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Lens flare example video (click to start)Why this is not a laser: 1) The green dot does not illuminate or interact with the ground. 2) It looks like an overlay. 3) It moves diagonally opposite to the bright light source (sun), always perfectly tracking it. Example courtesy M.L., Sept. 2021. Taken with a Samsung A10 phone's rear camera.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a case described below (in "A few cases and emails we received"), a woman reported a uniform blue tint on her Blink security camera. The tint was not caused by a laser, but by a flaw in the camera or perhaps a lens effect.&lt;/p&gt;
    &lt;head rend="h3"&gt;If you see light or feel heat from an unknown source&lt;/head&gt;
    &lt;head rend="h4"&gt;Light&lt;/head&gt;
    &lt;p&gt;If you see light that is not from any obvious source, try blocking it. Visible laser light can be blocked by anything that also blocks conventional light, such as a solid curtain, a wall, or even a sheet of paper.&lt;/p&gt;
    &lt;p&gt;If you do see flashes when all external light paths are blocked, consult your doctor or do an internet search. There can be medical conditions that cause flashes.&lt;/p&gt;
    &lt;p&gt;The author of this page has seen "flocks of birds" in daytime and "falling stars" at night. It turned out to be minor retinal detachment that went away. This is one reason the author is sympathetic to people who experience sensations that are 100% real to them, even if the sensations come from inside their bodies.&lt;/p&gt;
    &lt;head rend="h4"&gt;Heat&lt;/head&gt;
    &lt;p&gt;If you feel heat spots, first try to block them, to see if they are coming from outside your body. Try using metal objects such as aluminum foil, a baking sheet or a cast-iron skillet. Hold the material over the area where you are having heat or pain, to see if it goes away.&lt;/p&gt;
    &lt;p&gt;If you continue to feel heat, consult your doctor or do an Internet search. There can be medical conditions that cause localized and/or intermittent feelings of being hot, such as fibromyalgia.&lt;/p&gt;
    &lt;head rend="h4"&gt;Get evidence and/or others to confirm&lt;/head&gt;
    &lt;p&gt;If you want to try and track down the beams, get photographic and/or video evidence if at all possible. Ideally this would be pictures of the beams or the laser "dot", and also pictures of any damage. Note the section above about how photos can have lens flare, sensor blooming or other things internal to the camera.&lt;/p&gt;
    &lt;p&gt;If you have family or friends who can help, ask them to stay with you or stay at your house. If others can confirm what you are seeing or feeling, then they can help you in finding the reasons why.&lt;/p&gt;
    &lt;p&gt;A number of people who contacted us, also contacted their local police. In all cases, the police either investigated but took no action, or declined to investigate. One person said their local police department no longer handled calls involving lasers.&lt;/p&gt;
    &lt;p&gt;It may be helpful to hire a private investigator. They can look into suspicious behavior and evidence, and can try to confirm reports of burn marks, burning sensations, etc. If police action is warranted, the police may take a licensed private investigator more seriously than an ordinary citizen. But beware of unscrupulous private investigators who may claim to help you, but who will only string you along to keep making money off you.&lt;/p&gt;
    &lt;head rend="h3"&gt;If the harassment seems mysterious, ongoing, or well-organized&lt;/head&gt;
    &lt;p&gt;These persons clearly feel effects. But their symptoms are often inexplicable by normal means. For example, they can feel heat on their skin which they believe is from beams going through solid walls. There are some types of electromagnetic radiation, such as terahertz waves and microwaves, which can go through objects. But visible laser light — which is also electromagnetic radiation — is stopped by any material or substance that would also stop conventional light such as from a flashlight.&lt;/p&gt;
    &lt;head rend="h4"&gt;You are not alone …&lt;/head&gt;
    &lt;p&gt;If you are a person plagued by mysterious, unknown causes, the good news is you are not alone. At LaserPointerSafety.com, we used to get calls every month or two from persons who say they are being continually harassed by light and energy beams. (We no longer take such calls, due to their frequency and our inability to solve such mysterious cases.)&lt;/p&gt;
    &lt;p&gt;Clearly these people and you are seeing and feeling something. We understand you are not imagining your sensations — they are real to you.&lt;/p&gt;
    &lt;head rend="h4"&gt;… but the cause is unknown&lt;/head&gt;
    &lt;p&gt;But the bad news is that what you are feeling usually does not have any plausible physical explanation. This means it is very unlikely that mysterious beams or exotic devices are able to cause your symptoms.&lt;/p&gt;
    &lt;p&gt;It is highly unlikely that ordinary persons can buy or otherwise obtain powerful directed energy beams that go through walls. Such devices are exotic and expensive. Even if someone works for the police or military, this would not be regular issue "take home" equipment.&lt;/p&gt;
    &lt;p&gt;Also, there is usually no reason that your neighbors would undertake a prolonged, continual, and expensive attack against you. (Frankly, if they did want to harass or harm you, there are easier and less costly ways to do so.)&lt;/p&gt;
    &lt;p&gt;If you are having such symptoms, the cause, in our view, is most likely something that has gone wrong in your body.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It may be your nerves are misfiring, leading you to see light or feel heat when there is no external source. [In experiments published in 2007, subjects had low-level laser light shined on a rubber hand that was positioned over their own hand. Sixty-six percent of subjects reported heat or tactile sensations from the laser light — even though 1) the light was on a rubber hand, not their own and 2) the laser power was low enough that it would not noticeably heat up even on a real hand.]&lt;/item&gt;
      &lt;item&gt;If you are seeing flashes of light at night, or dark swarms (like a flock of birds) during the daytime in your peripheral vision, this can be due to retinal detachment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It may be something in your brain that is manufacturing false symptoms and/or feelings of being stalked or harassed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are feeling harassed by inexplicable causes, we advise that you see one or more medical specialists such as neurologists. Describe your symptoms to the doctor without going into detail about the potential cause (beams) or reasons (angry neighbors). You can tell the doctor "it feels like this is coming from outside my body" but concentrate on describing the symptoms of what you are experiencing physically and mentally.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If a medical reason is found for your issues, this is reassuring that you are not a victim of organized harassment. Hopefully you can be treated and the sensations will go away.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If there is no medical reason initially found, keep in mind that does not mean that the alternative explanation (angry neighbors are getting exotic beam weapons and aiming them at you) is true. It may be there is a deeper or unknown medical reason. Again, other people have reported similar symptoms, so there must be some common underlying cause in the body or mind.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more information, see the section below "An example case - trying to help a friend".&lt;/p&gt;
    &lt;head rend="h3"&gt;Be careful not to escalate the situation&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In a 2018 case, a man in Arkansas shot and killed a neighbor who, among other harassments, had allegedly aimed red, blue and green lasers into his house. When the neighbor went to pick up a laser pointer, the man thought it was a gun and killed him in claimed self-defense. (The man was acquitted by a jury of first-degree murder charges.)&lt;/item&gt;
      &lt;item&gt;In the example case of "H" which is listed below, a woman who believes her neighbors are harassing her with light and heat beams is going around to their homes with a loaded gun, looking for the source. This may not end well.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whatever the level of harassment, let law enforcement look into it and (hopefully) solve the problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;A few cases and emails we received&lt;/head&gt;
    &lt;p&gt;NOTE: As of September 1 2023, we no longer take calls or reply to emails about heat lasers, strange dots or lines in photos &amp;amp; videos, or "mysterious, ongoing or well-organized" harassments as described above.&lt;lb/&gt; We do sympathize with those experiencing such issues. The most help we can give is to let people know that others have reported similar experiences, so they are not alone. The cases listed below occurred prior to Sept. 1 2023.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt; An example case - "H" is trying to help a friend&lt;/item&gt;
      &lt;item rend="dd-1"&gt;We were contacted by a person we'll call "H", who was trying to help her friend "F" of 30 years.&lt;lb/&gt;About two months before the call, H's friend suddenly (over a period of a few weeks) started seeing mysterious lights and feeling mysterious heat. This is an especially interesting case since:&lt;lb/&gt;1) F was "normal" for decades before this started.&lt;lb/&gt;2) The symptoms that F describes are very common among other people who have contacted us.&lt;lb/&gt;3) H has spent substantial time with F, looking for logical, rational explanations for what F said she was experiencing.&lt;lb/&gt;F at first thought harassing beams were coming from the cable company so the cable wiring was replaced. This did not help. F then thought it was coming from the home security company; that was not the cause. F replaced her ceiling fan since she thought she saw faces in it. Her windows are covered with heavy blankets yet light or heat beams still somehow get in, according to F.&lt;lb/&gt;There are numerous security cameras around F's house but so far she has not captured anyone coming up to the house. Unfortunately, she has started going to neighbors' homes — with a loaded gun — looking for the source. This of course could escalate into a dangerous situation.&lt;lb/&gt;H said there was no apparent cause for F to start seeing lights and feeling heat. F had some traumatic life events such as deaths of close family members, in the two years prior to onset. But there was no single event or physical trauma that corresponded with the start of F's symptoms.&lt;lb/&gt;H has tried to help her friend. For example, H and her husband went to F's home for 16 hours, staying awake through the night and going outside from time to time to look for any unusual activity. They saw and felt nothing abnormal. (F was asleep the entire time so she did not report any strange sightings or feelings during the time H and her husband were there.)&lt;lb/&gt;The police have been at F's home numerous times. But they have not found anything and cannot help further. The FBI was contacted but did not get involved.&lt;lb/&gt;We advised H to have her friend see medical specialists such as a neurologist. F should describe the symptoms (what she is seeing and feeling) without stating that it is coming from the outside.&lt;lb/&gt;We also said that the medical exams and tests may not turn up anything. This is based on our experience where we have never had a person call us back, saying "Oh, the doctor found I had ABC disease" or "It stopped when I started taking XYZ medication."&lt;/item&gt;
      &lt;item rend="dt-2"&gt; Email #1 - Laser harassment 24/7&lt;/item&gt;
      &lt;item rend="dd-2"&gt;&lt;code&gt;We live across the street from a neighbor who has her laser lights on 24 hrs/7days a week. She shines her laser lights in other neighbors faces, heads, at children, family pets, windows of houses, plants and trees (which are singed from being over exposed/burned by laser lights), aircraft, on our parked vehicles, &amp;amp; vehicles driving down the street. When I have been in the front yard my eyes and face start burning from the lasering. The police have been called several times, but state that they cannot do anything.&lt;/code&gt;&lt;code&gt;Here are pictures of the laser attacks:&lt;/code&gt;&lt;code&gt;Do you have any suggestions on how to go about getting this individual to stop harassing &amp;amp; terrorizing us?&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;You described your eyes and face burning when in your front yard. It would take a very powerful and expensive laser to do this. A simple laser pointer would not be able to create heat on your skin at a long distance such as across a yard. The most powerful handheld laser currently available [summer 2010] is the 1-watt Wicked Laser Arctic. It can burn skin but at a very close distance, and the burn is very small such as the size of a pea or less.&lt;lb/&gt;You also stated that various surfaces were singed. Again, it would take a very, very powerful and VERY expensive laser to do this. It is very hard to imagine any use outside of military or police (riot control), and even these are exceedingly rare.&lt;lb/&gt;One way to tell if a laser is being used against you is to see if it only happens when you are in line with a window or similar opening to the outdoors. This is because walls will stop laser beams, but windows can let light through. (Of course, windows also let through sunlight and heat (infrared), so just being warm next to a window can be caused by normal, non-laser reasons.)&lt;lb/&gt;Both photos that you sent have a vertical line that goes through a strong light in the photo. This straight line is NOT a laser. It is an artifact of how some digital cameras work. If there is a light source that is too strong for the camera's digital chip, then all pixels in the same vertical line will be overwhelmed. This is called blooming. You can read more about blooming here.&lt;lb/&gt;One question I have for you is whether you have seen laser beams with your own eyes (not from a camera's video). I am guessing the answer is "no".&lt;lb/&gt;I do not want to say absolutely, positively 100% that there is no laser activity from your neighbor's house. The world is very large, and every now and then there are strange things. However, I am 99.999% sure that there is no laser activity from your neighbor's house. Certainly the photos you have sent depict the blooming effect that is very common on some digital camera chips. There is no doubt that what is in the photos is NOT laser. The other effects you state, such as heating and singeing, are highly, extremely unlikely to be caused by any type of laser that a residential person would have access to or could afford.&lt;/item&gt;
      &lt;item rend="dt-3"&gt; Email #2 - Lasers cause pinpoint holes&lt;/item&gt;
      &lt;item rend="dd-3"&gt;&lt;code&gt;To whom it may concern:&lt;/code&gt;&lt;code&gt;I have been getting burned for now about a year. I have been finding burn holes in my mini-blinds. My dog I have found burn holes on her skin also, Is there anything I can do ? It is really painful and I think they did this so I had to sell my home because I felt that my life was in danger I would be walking in the house and then I would get this burning sensation in my eyes and then I would fell my arms would be burning didn't matter what side of the house I was at I would get burned, I would tell people and they would say that's weird.&lt;/code&gt;&lt;code&gt;So I sold my home because I feel they chased me out by hurting me and my dog. I think they even killed some kittens with this laser flashlight. I am writing to you cause no one help me or those kitten that didn't make or had a chance, I think there should be a law against this it is really scary and painful. Thank you for having this information on the internet and maybe it can help someone.&lt;/code&gt;&lt;code&gt;[Name withheld]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;It is very difficult to use a laser to create holes at long range (more than a few yards or meters). It also requires a very expensive laser, to have enough power to make holes at long range. I would not know why someone would go to this trouble.&lt;lb/&gt;If what you are seeing is small, pinpoint holes, it is highly unlikely that these are from a laser aimed at a distance. Laser beams do spread out, even a little bit. For example, the beam at the aperture (output opening) of a powerful laser might be very small. This might be a few millimeters or up to 1/4" in diameters, and the edge of the hole would be sharp. At a house-to-house distance, the hole might be the size of a quarter at least, and the edges might be more ragged, with burn or scorch marks around the hole.&lt;lb/&gt;If a person is walking around with a hand-held laser (laser pointer or battery-powered laser), then they could get close enough to make small holes or burn marks. For a laser pointer, this takes a LOT of power and is expensive. I do not know why someone would do this. (If they wanted to cause trouble, there are a lot of ways that are more effective, much less expensive, and also hard-to-trace.)&lt;lb/&gt;It is possible for the laser beam to be invisible to our eyes. Infrared lasers have beams which we can't normally see. However, you can use a camcorder to try to see these beams. To try this, point the camcorder at an infrared remote control, which are very common for TVs, etc. When you press a button on the remote control, you should see a light flash in the camcorder viewfinder (but not with your eyes). If your camcorder can see the infrared light, then you should be able to see infrared laser beams using the camcorder's viewfinder or fold-out monitor.&lt;lb/&gt;If someone is using a laser in the way you describe, this is illegal. It is damaging your property, cruelty to animals, and assault &amp;amp; battery. You could call the police -- but you should be sure that you really do have evidence.&lt;lb/&gt;For your own sensations of burning, you may also want to consult a doctor or do research on the Internet. There are some conditions where you may experience burning due to something internal in your body.&lt;/item&gt;
      &lt;item rend="dt-4"&gt; Email #3 - Some suggestions from a person saying they were harassed&lt;/item&gt;
      &lt;item rend="dd-4"&gt;&lt;code&gt;To whom it may concern:&lt;/code&gt;&lt;code&gt;When I read the two stories of people getting harassed by laser pointers, I thought I was reading about my own story.&lt;/code&gt;&lt;code&gt;I was also getting harassed by our neighbor. We complained to the police as well, but we got no help. Both me and my husband saw the green dots, still the authorities were not convinced. It's very difficult to film, since he changed locations from the window and could see us if we try to film or take picture. We finally moved from there and thought it would be over but to our dismay it continued in the second home. We moved in the same area, it was not far enough.&lt;/code&gt;&lt;code&gt;So, I started to do the research about laser pointers and their health risks on people. Here are a couple of suggestions: First, go to your Home Depot or Lowes and get a mirrored privacy film and stick it to your windows. Make sure your windows are completely covered. This will at least give you day time privacy and if they point the laser pointer at it they will get twice as much effect on themselves. Second, do not close your house completely. Leave your windows a crack open, because depending on the type of laser and its strength, all lasers emit radiation. The radiation further dries skin and increase the burning, and does not help in healing. Third, use coconut oil to moisturize skin. And, last, get as many humidifiers and run them until there is enough moisture in the house. This will negate the effects of radiation plus it will provide you with a relief from burning. I hope this helps. Good luck!&lt;/code&gt;&lt;code&gt;Finally, thank you for printing those articles, I thought I was alone. It is helpful to read what other people are going through.&lt;/code&gt;&lt;code&gt;[Name withheld]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;We have found a few people who, even if they moved to a different state, still said they had symptoms of being harassed by lasers. It is more likely that there is something about the person -- some medical or perhaps brain condition -- which is causing the symptoms. We urge such persons to get a medical exam and to stress to the doctor that you really are feeling these sensations (heat, etc.).&lt;lb/&gt;We are printing the information above because it may help others.&lt;list rend="ul"&gt;&lt;item&gt;The suggestion about privacy film is good. If a problem is being caused by visible light lasers, then light-blocking curtains, shades or films will eliminate the problem. You can also simply go into a room without windows or other openings to the outside, and see if the symptoms go away. Visible-light lasers, with a dot or beam that you can see, will be blocked by walls or other light-blocking material. It is theoretically possible that an infrared laser's energy might go through a lightweight material, but even here, putting a wall between you and a suspected laser source would block the infrared light. Note that reflective privacy film will NOT reflect the laser back to a perpetrator. This could only happen if the laser hits the film at an exact 90° angle, both side-to-side and up-and-down.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The point about radiation is not really accurate. Lasers do emit "radiation" -- electromagnetic radiation such as visible, infrared or ultraviolet light. Lasers available to the general public do not emit higher-energy nuclear radiation such as X-rays or gamma rays. Leaving windows open will not have any effect on light or radiation. For example, even a beam of X-rays will not somehow "build up" in a house. This is like saying leaving your oven on at 200 degrees will build up heat until an hour or two later it is 2000 degrees — not true.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The suggestions about coconut oil and humidifiers may help. If you do feel burning sensations, using a cream or having extra moisture in the air could be beneficial.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt; Telephone call - Blue light on Blink camera&lt;/item&gt;
      &lt;item rend="dd-5"&gt;In late 2020, a woman called saying that an unfriendly neighbor may be aiming a blue laser at persons in her driveway. The people did not see any blue light or blue flash, but a Blink security camera had blue images when the persons were in the driveway.&lt;lb/&gt;Before going to the police, she sent photos showing the normal security camera view, and the blue-tinted view. Here is a portion of the photos:&lt;lb/&gt;The normal camera view&lt;lb/&gt;When the "laser" was on — a uniform blue tint (it turned out not to be caused by a laser)The photos clearly show it was not a laser. The tint is uniform, whereas a laser hitting the camera would cause a bright spot or complete whiteout or blueout of the camera image. Also, the tint is steady. A handheld laser from across the street would flash in the camera, since the neighbor could not hold the laser completely steady. (Even most tripods would not be 100% steady from such a distance — there would be some brightness fluctuation.)&lt;lb/&gt;There were other indications as well that this was not a laser. The camera was the only evidence of unusual activity. No person saw laser dots or beams. The blue tint occurred only during the day; usually laser harassment is at dusk or night.&lt;lb/&gt;It turns out that Blink cameras can have a blue tint under certain circumstances as discussed here and here. None of these seemed to apply to the woman's situation — it was not cold, nor snowy. The tint occurred only at certain times or when there was a person in the view. And yet the cause had to be with the camera or perhaps the lens (e.g., angle to the sun at certain times).&lt;lb/&gt;We recommended that she swap out the driveway Blink camera for one of the other Blink cameras on her property. This could help decide if the blue tint was due to a problem in the camera or perhaps due to the sun being at a certain angle when looking at the driveway view.&lt;lb/&gt;Either way, the blue tint was not caused by a laser. This put her mind at ease and prevented an unnecessary trip to the police.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;More information about mysterious or ongoing attacks&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt; Why would ordinary citizens be targeted?&lt;/item&gt;
      &lt;item rend="dd-1"&gt;It seems unlikely that directed energy devices would be available or affordable to ordinary persons who want to harass other persons. Or whether such devices would be used by the government against ordinary citizens who don’t have vital state secrets.&lt;lb/&gt;We cannot help with issues about non-visible lasers or directed energy devices. However, below are links to resources which may be of interest to persons who feel they are deliberately targeted by mysterious devices.&lt;/item&gt;
      &lt;item rend="dt-2"&gt; Links about covert harassment and directed energy devices&lt;/item&gt;
      &lt;item rend="dd-2"&gt;The first two resources have links to other websites, organizations and videos of interest (too many links to list here). Thanks to Jeannie for her help with this list.&lt;list rend="ul"&gt;&lt;item&gt;People Against Covert Torture &amp;amp; Surveillance, International From their home page: “PACTS, International is a support network for those targeted with organized stalking and remote electronic assaults, also known as electronic harassment. Electronic harassment in this context refers to the use of radio frequencies and other methods to remotely access a person's mind and/or body to gain control of the individual or group of persons.” Much of the information at their site is in links to their newsletter, such as this newsletter page.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The "Stop Gangstalking Awareness Group", and especially this page about "Understanding Neuro Weapons." LaserPointerSafety has not evaluated the accuracy or usefulness of this group or their information. (Thanks to M.D. in July 2024 for bringing this to our attention.)&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The 2015 Covert Harassment Conference in Berlin. This contains videos and a list of the program; the material is in English. There was also a 2014 Covert Harassment Conference.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;A 2002 presentation by Dr. Reinhard Munzert, “Targeting the Human with Directed Energy Weapons”, here and here among other places.&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The book "The E-Bomb: How America's New Directed Energy Weapons Will Change the Way Future Wars Will Be Fought" by Dr. Doug Beason, physicist, a Fellow of the American Physical Society, and former Chief Scientist for the USAF Space Command. From Amazon: "After more than two decades of research, the United States is on the verge of deploying a new generation of weapons that discharge light-wave energy, the same spectrum of energy found in your microwave, or in your TV remote control. It's called directed energy -- lasers, high-powered microwaves, and particle beams. And it's a revolution in weaponry, perhaps, more profound than the atomic bomb. The E-Bomb author Doug Beason, a leading expert in directed-energy research, describes in clear and jargon-free prose all of these exotic new weapons."&lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;A July 19 2019 article in the Military Times entitled "Pentagon scientists are making talking plasma laser balls for use as non-lethal weapons" describes how lasers can be used for "heating up a target’s skin to extremely uncomfortable levels without burning them, blasting confusing noises or giving voice commands such as, 'Stop or we’ll be forced to fire upon you.'" As of the article date, the talking plasma ball distance involved is currently within "the short range of a laboratory setting", with a goal of 100 meters to multiple kilometers. (Note that it is unlikely that such lasers are being used outside of military applications; for example, by one neighbor upon another neighbor. Also, it is not known if such lasers could cause effects through solid walls.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-3"&gt; Mysterious Cuba attacks - microwaves or a "shared functional disorder"?&lt;/item&gt;
      &lt;item rend="dd-3"&gt;Persons who feel they have been targeted by mysterious enemies with directed energy devices may want to consider the case of the U.S. diplomats in Cuba afflicted by "Havana syndrome."&lt;lb/&gt;In August 2017, reports came out that numerous U.S. diplomats serving in Cuba had been affected by mysterious “acoustic attacks.” Symptoms included hearing a buzzing sound, having headaches, hearing loss, balance issues and nausea. CBS News reported “mild traumatic brain injuries and possible damage to the central nervous system as a result of the attacks.”&lt;lb/&gt;The question is whether Cuba targeted diplomats with an actual device, whether it was caused by pesticides or other untargeted source … or whether this may have been "mass hysteria." According to a report in Newsweek:&lt;lb/&gt;“Mass hysteria is the rapid spread of illness symptoms for which there is no organic cause,” [Robert] Bartholomew [author of a book on the topic] told Newsweek. “It happens in normal, healthy people—it’s not just ‘all in their heads’ because they do experience symptoms.”&lt;lb/&gt;Jon Stone, a neurologist from the University of Edinburgh first consulted for the Guardian article, agrees. “To consider this diagnostic possibility properly you have to strip away its negative connotations. The symptoms experienced in outbreaks of ‘mass hysteria’ are genuine and not faked or imaginary,” he told Newsweek.&lt;lb/&gt;Stone argues that the term "mass hysteria" itself sounds sensational and far-fetched. In reality, it is not as uncommon as you might think. He explains: “‘Mass hysteria’ is so laden with negativity, it badly distorts its own case. It suggests shrieking and raving individuals—not hard-working and normal people who mostly get functional disorders in everyday practice.”&lt;lb/&gt;A better, less stigmatizing term, says Stone, is “share functional disorder.” He defines the condition as a genuinely experienced illness, “in which there is some disturbance of bodily functioning which conventional diagnostic techniques fail to register.”&lt;lb/&gt;There are interesting parallels with Havana syndrome and persons reporting unexplained laser harassment.&lt;lb/&gt;Similarities&lt;lb/&gt;In the Cuba case, around 25 U.S. diplomats, and 14 Canadian diplomats — persons who would be considered reliable and rational — reported hearing mysterious sounds and began having unusual, unexplained health problems. There have been numerous studies conducted by the U.S., Canada, Cuba, that as of early 2020 have not definitively established any cause. Experts are even divided on whether there is any physical change in the brains of the affected persons.&lt;lb/&gt;In laser harassment cases, numerous persons — most of whom sound reliable and rational when we talk with them — report seeing lights and feeling heat from mysterious sources. Police, friends, family and medical experts trying to help them have been unable to find a cause. The only thing that is certain is the persons have genuine symptoms that are not faked or imaginary. To others, there may be no rational explanation — but the symptoms are genuinely experienced.&lt;lb/&gt;Differences&lt;lb/&gt;One difference between the Cuba case and persons reporting unexplained laser harassment is that the latter are widely scattered. In Cuba there is the possibility of all the diplomats being exposed to the same causal factor (still unknown but possibly sound or pesticides). But persons reporting laser harassment are widely scattered across the U.S. and Canada. Perhaps there is a common cause within the environment.&lt;lb/&gt;Also, the definition of mass psychogenic illness or "mass hysteria" almost always occurs in a relatively small group of people living or working together. This is true for the Cuba cases. But in the laser harassment cases, victims are again widely scattered and do not know, interact, or correspond (e.g. Internet) with each other.&lt;lb/&gt;December 2020 update — microwaves&lt;lb/&gt;A study by the National Academies of Science concluded that the cause was likely microwave energy that may not have been deliberately targeting the diplomats in Cuba. According to an NBC News story quoting the study, "The committee felt that many of the distinctive and acute signs, symptoms and observations reported by (government) employees are consistent with the effects of directed, pulsed radio frequency (RF) energy. Studies published in the open literature more than a half-century ago and over the subsequent decades by Western and Soviet sources provide circumstantial support for this possible mechanism.”&lt;lb/&gt;From the news story:&lt;lb/&gt;The study examined four possibilities to explain the symptoms: Infection, chemicals, psychological factors and microwave energy.&lt;lb/&gt;“Overall, directed pulsed RF energy … appears to be the most plausible mechanism in explaining these cases among those that the committee considered. ... The committee cannot rule out other possible mechanisms and considers it likely that a multiplicity of factors explains some cases and the differences between others.”&lt;lb/&gt;The report says more investigation is required.&lt;lb/&gt;Summary&lt;lb/&gt;LaserPointerSafety.com we are not aware of microwave directing devices that an ordinary citizen could purchase to cause problems for neighbors. It may be possible for a technically minded person to buy or modify devices and beam microwaves at other persons. But we are not experts in microwaves so we cannot give any more advice or opinion.&lt;/item&gt;
      &lt;item rend="dt-4"&gt; An email about directed energy weapons: Are we naive?&lt;/item&gt;
      &lt;item rend="dd-4"&gt;We received the following email in July 2019. It has been slightly edited for clarity and to avoid identifying information.&lt;code&gt;I just read your article on lasers and questions people emailed to you, all were very interesting.&lt;/code&gt;&lt;code&gt;In reading these it appeared to me most of these questions were based on Directed Energy Weapons - DEW (Microwave) rather than the laser beams per se. (i.e., laser beam in a pilots eyes).&lt;/code&gt;&lt;code&gt;I strongly disagree with you on the Cuban episode. First of all, I found your answer very naive, and I'm not trying to be mean, its just that you haven't done your homework on how those hell bent on hurting others obtain these military weapons! It's called Black Market, the Mexican Cartel (Sinanola or El Chapo) drug organization buy these DEW by the truck load from (hate to say this) crooked defense companies.&lt;/code&gt;&lt;code&gt;In turn these military weapons are given out like Hershey bars to Stalkers (MS-13) the large white van pulls up and delivers them right in your neighborhood purchased by the Cartel. Its big business. I'm assuming the Cuban government more than likely purchased these DEW weapons to threaten and hurt the Americans working in Cuba.&lt;/code&gt;&lt;code&gt;I keep reminding those that don't understand this Mexican Cartel they are extremely organized and extremely rich! They can and do buy anyone and anything! Most people don't even realize they have several submarines. This theory that everyone can get sick if enough people say they're sick, and blah blah blah, is just that, a theory. We're talking about the real world here. Unfortunately, it's the dark side, the hidden side that most don't even realize is out there.&lt;/code&gt;&lt;code&gt;So when these Americans complained about being hit and knocked down, believe them! My advice is do some studying on this weapon, yes its covert, silent and does shoot right thru walls,, it can hurt you and even kill you. Think of yourself as a potato, and what does it do if microwaved. My suggestion is get the book The E-Bomb: How America's New Directed Energy Weapons Will Change the Way Future Wars Will Be Fought. Unfortunately, you will NOT find any book in the library on this cartel, why? They're either stolen or lost.&lt;/code&gt;&lt;code&gt;You would not believe how many American citizens are now employed by this Mexican Cartel living right here in the good ole USA, and they ALL have this DEW weapon!&lt;/code&gt;&lt;code&gt;I would like to ask you if anything has been made to be able to catch a laser beam in motion and have it returned to the bad guy? I do not mean 'take' it to the bad guy (like a missile) I'm thinking perhaps a 'mirror-like' device.&lt;/code&gt;&lt;code&gt;[Name withheld; former employee at a defense contractor working on microwave devices]&lt;/code&gt;&lt;lb/&gt;Our response:&lt;lb/&gt;Thank you for your letter.&lt;lb/&gt;I haven't done a lot of homework on DEWs since my main interest is in visible lasers. I get calls about once every month or two from people who have experienced heat or light that I cannot explain. That's why my webpage includes links to other directed energy information sources.&lt;lb/&gt;I will say I'm not sure why Mexican cartels or human traffickers would target the people I hear from. They seem like normal people in residential neighborhoods. If the cartels wanted them gone, they certainly have other, much worse ways to do this.&lt;lb/&gt;I just downloaded the E-Bomb book in Kindle format. I will read it soon.&lt;lb/&gt;About your letter... I do want to bring forth other views. Would it be OK if I printed all or parts of it on the "If you are harassed by lasers" webpage at LaserPointerSafety.com? Without your name or identifying information, of course.&lt;lb/&gt;Finally, for visible lasers, you could use a retroreflector to return the light to the source. The beam may be degraded enough that if it could cause heat at the retroreflector, the returned beam (having gone twice as far and having bounced off possibly dirty or dusty surfaces) would be weaker and thus not able to harm anyone at the source area.&lt;lb/&gt;At a minimum, you would need a high-quality, industrial or research quality corner cube retroreflector like these. An inexpensive "cat's eye" bicycle retroreflector or similar would cause a bright glow to be seen at the source, but would not cause a coherent beam to be reflected back.&lt;lb/&gt;The original author's response:&lt;code&gt;Thanks for getting back to me so quickly, it's appreciated.&lt;/code&gt;&lt;code&gt;Yes, you can use what I wrote if it helps the targets. To help you to understand why good people end up targets is because more than likely they have interfered with something the Cartel is doing, like selling drugs, or human trafficking, they might have alerted the police, or see something say something. It could even be someone hired stalkers to hurt you because of some vendetta, or just pure revenge!&lt;/code&gt;&lt;code&gt;They could/can kill you. But, in most cases they just want to provoke you or harass you while hurting you with this DEW weapon. It's called a 'slow cooker' for a reason. It's nothing but pure evil.&lt;/code&gt;&lt;code&gt;I would like to see this hand held DEW put out of business and the defense companies fined big time for selling it, especially to the Cartels but, I'm reading where Directed Energy is being used even more than ever by other countries within the military sector. Lasers as well. I'm not against high technology but I am against something like this getting into the wrong hands.&lt;/code&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt; Another email with a detailed theory&lt;/item&gt;
      &lt;item rend="dd-5"&gt;In March 2020 we received an email from Anthony Arellano describing in great detail how sonic and heat attacks could theoretically be done.&lt;lb/&gt;We are providing the document as an example.&lt;lb/&gt;We have not reviewed and do not endorse this information. Please independently research this before taking any actions based on the information.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;We cannot help in mysterious or non-obvious cases&lt;/head&gt;
    &lt;p&gt;We do not have expertise about non-visible lasers or directed energy devices. Do not contact us, since we will no longer reply as of September 1 2023. If you are experiencing this, you should check the links above about covert harassment and directed energy devices.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.laserpointersafety.com/harassment.html"/><published>2025-09-26T19:12:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45390121</id><title>Why Use Mailing Lists?</title><updated>2025-09-26T20:10:59.422912+00:00</updated><content>&lt;doc fingerprint="e2dc9d93b25dbf8d"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Re: Fully functional email address&lt;/head&gt;
    &lt;p&gt;Rich Kulawiec &amp;lt;rsk@gsp.org&amp;gt; Thu, 19 June 2025 20:09 UTC&lt;/p&gt;
    &lt;p&gt; Return-Path: &amp;lt;rsk@gsp.org&amp;gt;&lt;lb/&gt; X-Original-To: ietf@mail2.ietf.org&lt;lb/&gt; Delivered-To: ietf@mail2.ietf.org&lt;lb/&gt; Received: from localhost (localhost [127.0.0.1]) by mail2.ietf.org (Postfix) with ESMTP id 0B126371B8C9 for &amp;lt;ietf@mail2.ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:46 -0700 (PDT)&lt;lb/&gt; X-Virus-Scanned: amavisd-new at ietf.org&lt;lb/&gt; X-Spam-Flag: NO&lt;lb/&gt; X-Spam-Score: -2.298&lt;lb/&gt; X-Spam-Level: &lt;lb/&gt; X-Spam-Status: No, score=-2.298 tagged_above=-999 required=5 tests=[BAYES_20=-0.001, RCVD_IN_DNSWL_MED=-2.3, RCVD_IN_MSPIKE_H3=0.001, RCVD_IN_MSPIKE_WL=0.001, RCVD_IN_VALIDITY_RPBL_BLOCKED=0.001, RCVD_IN_VALIDITY_SAFE_BLOCKED=0.001, SPF_PASS=-0.001] autolearn=ham autolearn_force=no&lt;lb/&gt; Received: from mail2.ietf.org ([166.84.6.31]) by localhost (mail2.ietf.org [127.0.0.1]) (amavisd-new, port 10024) with ESMTP id u4Vy4jVMA7Ej for &amp;lt;ietf@mail2.ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:45 -0700 (PDT)&lt;lb/&gt; Received: from taos.firemountain.net (taos.firemountain.net [207.114.3.54]) (using TLSv1.3 with cipher TLS_CHACHA20_POLY1305_SHA256 (256/256 bits) key-exchange X25519 server-signature ECDSA (P-256) server-digest SHA256) (No client certificate requested) by mail2.ietf.org (Postfix) with ESMTPS id 94448371B8C0 for &amp;lt;ietf@ietf.org&amp;gt;; Thu, 19 Jun 2025 13:09:45 -0700 (PDT)&lt;lb/&gt; Received: from gsp.org (localhost [127.0.0.1]) by taos.firemountain.net (8.17.2/8.17.2) with SMTP id 55JK9hDh065634 for &amp;lt;ietf@ietf.org&amp;gt;; Thu, 19 Jun 2025 16:09:44 -0400 (EDT)&lt;lb/&gt; Date: Thu, 19 Jun 2025 16:09:43 -0400&lt;lb/&gt; From: Rich Kulawiec &amp;lt;rsk@gsp.org&amp;gt;&lt;lb/&gt; To: IETF general list &amp;lt;ietf@ietf.org&amp;gt;&lt;lb/&gt; Subject: Re: Fully functional email address&lt;lb/&gt; Message-ID: &amp;lt;20250619200943.GB5995@gsp.org&amp;gt;&lt;lb/&gt; References: &amp;lt;18892.1750014795@obiwan.sandelman.ca&amp;gt; &amp;lt;50FFA5F1-6895-4C6C-A4C7-1DA2226CA07B@huitema.net&amp;gt; &amp;lt;9311a7d6-e935-fe48-d897-0011599aa5b0@iecc.com&amp;gt;&lt;lb/&gt; MIME-Version: 1.0&lt;lb/&gt; Content-Type: text/plain; charset="us-ascii"&lt;lb/&gt; Content-Disposition: inline&lt;lb/&gt; In-Reply-To: &amp;lt;9311a7d6-e935-fe48-d897-0011599aa5b0@iecc.com&amp;gt;&lt;lb/&gt; User-Agent: Mutt/1.5.23 (2014-03-12)&lt;lb/&gt; Message-ID-Hash: IAN7IQM56LHAQO7O4TZ6D2TKDYH5QLVT&lt;lb/&gt; X-Message-ID-Hash: IAN7IQM56LHAQO7O4TZ6D2TKDYH5QLVT&lt;lb/&gt; X-MailFrom: rsk@gsp.org&lt;lb/&gt; X-Mailman-Rule-Misses: dmarc-mitigation; no-senders; approved; emergency; loop; banned-address; member-moderation; header-match-ietf.ietf.org-0; nonmember-moderation; administrivia; implicit-dest; max-recipients; max-size; news-moderation; no-subject; digests; suspicious-header&lt;lb/&gt; X-Mailman-Version: 3.3.9rc6&lt;lb/&gt; Precedence: list&lt;lb/&gt; List-Id: "IETF-Discussion. This is the most general IETF mailing list, intended for discussion of technical, procedural, operational, and other topics for which no dedicated mailing lists exist." &amp;lt;ietf.ietf.org&amp;gt;&lt;lb/&gt; Archived-At: &amp;lt;https://mailarchive.ietf.org/arch/msg/ietf/q6A_anL1u-Y9iXe-vboiOYamsl0&amp;gt;&lt;lb/&gt; List-Archive: &amp;lt;https://mailarchive.ietf.org/arch/browse/ietf&amp;gt;&lt;lb/&gt; List-Help: &amp;lt;mailto:ietf-request@ietf.org?subject=help&amp;gt;&lt;lb/&gt; List-Owner: &amp;lt;mailto:ietf-owner@ietf.org&amp;gt;&lt;lb/&gt; List-Post: &amp;lt;mailto:ietf@ietf.org&amp;gt;&lt;lb/&gt; List-Subscribe: &amp;lt;mailto:ietf-join@ietf.org&amp;gt;&lt;lb/&gt; List-Unsubscribe: &amp;lt;mailto:ietf-leave@ietf.org&amp;gt;&lt;/p&gt;
    &lt;quote&gt;On Mon, Jun 16, 2025 at 12:31:09PM -0400, John R. Levine wrote: &amp;gt; Incidentally, the reason that mail will never go away is that it is fully &amp;gt; federated, doesn't require people to be online at the same time, and is easy &amp;gt; to archive and search. So far none of the replacements do that. +1, and let me augment this by (partially) quoting something that I wrote a few years ago about mail and mailing lists. Why use mailing lists? ---------------------- Mailing lists, which were sometimes called "reflectors" in their early days, are one of the older pieces of Internet technology. Despite that, they're still heavily used [...] That's not an accident. It's because mailing lists have enormous technical advantages over the alternatives. Here are some of those: 1. Mailing lists require no special software: anyone with a sensible mail client can participate. Thus they allow you to use *your* software with the user interface of *your* choosing rather than being compelled to learn 687 different web forums with 687 different user interfaces, all of which range from "merely bad" to "hideously bad". 2. Mailing lists are simple: learn a few basic rules of netiquette and a couple of Internet-wide conventions, and one's good to go. Web forums are complicated because all of them are different. In other words, participating in 20 different mailing lists is just about as easy as participating in one; but participating in 20 different web forums is really quite onerous. 3. They impose minimal security risk. 4. They impose minimal privacy risk. Points 3 and 4 stand in stark contrast to the security and privacy risks imposed on users of web forums and "social" media, especially the latter. 5. Mailing lists are bandwidth-friendly -- an increasing concern for people on mobile devices and thus on expensive data plans. Web forums are bandwidth-hungry. 6. Mailing lists interoperate. I can easily forward a message from one list to another one. Or to a person. I can send a message to multiple lists. I can forward a message from a person to this list. And so on. Try doing this with web forum software A on host B with destinations web forum software C and D on hosts E and F. Good luck with that. 7. They're asynchronous: you don't have to interact in real time. You can download messages when connected to the Internet, then read them and compose responses when offline. 8. As a result of 7, They work reasonably well even in the presence of multiple outages and severe congestion. Messages may be delayed, but once everything's up again, they'll go through. Web-based forums simply don't work at all. 9. They're push, not pull, so new content just shows up. Web forums require that you go fishing for it. 10. They scale beautifully. 11. (When properly run) they're relatively free of abuse vectors. Mailing lists are highly resistant to abuse and attacks. Web forums, because of their complexity, are highly vulnerable to software security issues as well as spam/phishing and other attacks. 12. They handle threading well. And provided users take a few seconds to edit properly, they handle quoting well. This is essential for anyone trying to follow a discussion. 13. They're portable: lists can be rehosted (different domain, different host) rather easily. 14. They can be freely interconverted -- that is, you can move a list hosted by A using software B on operating system C to host X using software Y on operating system Z. If you can do this at all with web forums, and you usually can't, it's really, really difficult. 15. They can be written to media and read from it. This is a VERY non-trivial task with web forums, and that's putting it mildly. 16. The computing resources require to support them are minimal -- CPU, memory, disk, bandwidth, etc. 17. Mailing lists can be uni- or bidirectionally gatewayed to Usenet. (The main Python language mailing list is an example of this.) They can also be gatewayed to web sites or to RSS feeds. All of these can be highly useful, because they provide alternative ways for people to receive the same content. 18. They're easily archivable in a format (Unix "mbox" format) that is simple and likely to be readable long into the future. Mail archives from 10, 20, even 30 or more years ago are still completely usable. And they take up very little space: I have hundreds of millions of mailing list messages archived, and the entire collection would fit on a USB stick. [...] 19. You can archive them locally... 20. ...which means you can search them locally with the software of *your* choice. Including when you're offline. And provided you make backups, you'll always have an archive -- even if the original goes away. Web forums don't facilitate this. [...] ---rsk&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address George Michaelson&lt;/item&gt;
      &lt;item&gt;Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Paul Wouters&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Michael Richardson&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Christian Huitema&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address George Michaelson&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John R. Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Salz, Rich&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Rob Sayre&lt;/item&gt;
      &lt;item&gt;Email usage (Was: Fully functional email address) Jay Daley&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Stephen Farrell&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Jay Daley&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Martin J. Dürst&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Christian Huitema&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Stephen Farrell&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John Levine&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Rich Kulawiec&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Phillip Hallam-Baker&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address Paul Wouters&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address John C Klensin&lt;/item&gt;
      &lt;item&gt;Re: Fully functional email address S Moonesamy&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mailarchive.ietf.org/arch/msg/ietf/q6A_anL1u-Y9iXe-vboiOYamsl0/"/><published>2025-09-26T19:27:23+00:00</published></entry></feed>