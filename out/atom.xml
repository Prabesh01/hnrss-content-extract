<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-29T19:06:49.341388+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46808251</id><title>Vitamin D and Omega-3 have a larger effect on depression than antidepressants</title><updated>2026-01-29T19:07:08.523917+00:00</updated><content>&lt;doc fingerprint="f5a99056fce511fe"&gt;
  &lt;main&gt;
    &lt;p&gt;(content note: scientific discussion of depression &amp;amp; suicide)&lt;/p&gt;
    &lt;p&gt; "Too Long; Didn't Read" Summary:&lt;lb/&gt; Exactly what the title says. &lt;/p&gt;
    &lt;p&gt;The "standardized effect size" of antidepressants on depression, vs placebo, is around 0.4. (On average; some people respond much better or much worse.) This is like going from a C to a C+.&lt;/p&gt;
    &lt;p&gt;In contrast: the effect size of 1500 mg/day of "‚â•60% EPA" Omega-3 supplements ‚Äî which are cheaper &amp;amp; have fewer side effects than antidepressants ‚Äî is a bit higher, around 0.6. This is like going from a C to a B‚Äì.&lt;/p&gt;
    &lt;p&gt;But, much better: the effect size of 5000 IU/day of Vitamin D is around 1.8. This is like going from a C to an A‚Äì! It works even for people who don't have a Vitamin D insufficiency, which almost half of American adults do.&lt;/p&gt;
    &lt;p&gt;Even if you're already taking Vitamin D &amp;amp; Omega-3, you may still not be taking enough. The "official" recommendations are all several times too low, and newer research shows that the official "max safe dose" for Vitamin D is 2 times too low. Both these supplements are safe, cheap, and over-the-counter, with positive side-effects (on Covid &amp;amp; cognition).&lt;/p&gt;
    &lt;p&gt;So, unless you have specific reasons to not take Vitamin D &amp;amp; Omega-3 ‚Äî (kidney stones, blood thinners, etc) ‚Äî please try them, for at least a month! They could save your mental health. Maybe even your life.&lt;/p&gt;
    &lt;p&gt;(edit ‚Äî oh hi Hacker News! also, thank you Josep for catching my terrible typo; I meant 5000 IU/day for Vitamin D, NOT 5000 mg. Jeez.)&lt;/p&gt;
    &lt;p&gt;(edit 2 ‚Äî I said this in the conclusion but I'll move it earlier up: you can take these supplements alongside traditional antidepressants! You can stack interventions! The research shows that they're still effective even when combined with regular meds. As always, "ask your doctor", show them the peer-reviewed papers cited in this post.)&lt;/p&gt;
    &lt;p&gt;Table of Contents:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A crash course in "effect sizes" ‚Ü™&lt;/item&gt;
      &lt;item&gt;Interpreting effect sizes on depression ‚Ü™&lt;/item&gt;
      &lt;item&gt;Antidepressants ‚Ü™&lt;/item&gt;
      &lt;item&gt;Omega-3 ‚Ü™&lt;/item&gt;
      &lt;item&gt;Vitamin D ‚Ü™&lt;/item&gt;
      &lt;item&gt;Conclusion: All this time, you lacked the Vitamin? ‚Ü™&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;A crash course in "effect sizes"&lt;/head&gt;
    &lt;p&gt;In Alicetown, the average person has 4 younger cousins.&lt;lb/&gt; In Bobtown, the average person has 3 younger cousins.&lt;/p&gt;
    &lt;p&gt;Alright, not so surprising. You may not even notice a difference.&lt;/p&gt;
    &lt;p&gt;In Alicetown, the average person has 4 limbs.&lt;lb/&gt; In Bobtown, the average person has 3 limbs.&lt;/p&gt;
    &lt;p&gt;You'd definitely notice.&lt;/p&gt;
    &lt;p&gt;It's the same absolute difference (4 vs 3) and relative difference (3/4). So what makes limbs more surprising than cousins? Well, partly it's more dramatic &amp;amp; visible, but also because: we expect high variation in the number of someone's younger cousins, but not their number of limbs.&lt;/p&gt;
    &lt;p&gt;This is why scientists calculate an "effect size" or "standardized mean difference" ("mean" = average). We take the difference between two groups, then divide by the total amount of variation, to account for how surprising a difference is.&lt;/p&gt;
    &lt;p&gt;(This is a health article, not a math article, so I'll skip the formulas in this post. If you're curious, : check out this 4 min video.)&lt;/p&gt;
    &lt;p&gt;Unfortunately for laypeople, the effect size is usually just reported as a number, like "+0.74" for spacing out your studying vs cramming, or "‚Äì0.776" for sleep deprivation on attention.&lt;/p&gt;
    &lt;p&gt;But what's that mean? How can we make these numbers intuitive?&lt;/p&gt;
    &lt;p&gt;Well, a common way for data to be is a bell-shaped curve (also called a "normal distribution"). And most of us are, alas, well-acquainted with the bell curve in school grades. ("grading on a curve")&lt;/p&gt;
    &lt;p&gt;So: school grades give us a useful way to think about standardized effect sizes! We can now convert that number into an actual letter grade:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;F: -2.0 below average&lt;/item&gt;
      &lt;item&gt;D: -1.0 below average&lt;/item&gt;
      &lt;item&gt;C: average&lt;/item&gt;
      &lt;item&gt;B: +1.0 above average&lt;/item&gt;
      &lt;item&gt;A: +2.0 above average&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(see footnote for more precise ranges.[1] the units are in "standard deviations", or "sigmas". what's sigma? &lt;del&gt;sigma ba--&lt;/del&gt; just a unit of "how far away this is from average, relative to the total variation".)&lt;/p&gt;
    &lt;p&gt;For example: spacing out your studying, relative to cramming, will on average lift your test scores from a C to a B‚Äì. (effect size = +0.74) And short-term sleep deprivation, relative to healthy sleep, will on average tank your ability to pay attention from a C to a D+. (effect size: ‚Äì0.776)&lt;/p&gt;
    &lt;p&gt;(Note ‚Äî when reading about effect sizes, always remember: effect of what, on what, at what dose, for which group, relative to what? See the Data Colada post, Meaningless Means.)&lt;/p&gt;
    &lt;p&gt;(Note 2 ‚Äî the standard way of "intuitively" describing effect sizes is Cohen's recommendations: 0.2 = small, 0.5 = medium, 0.8 = large. Personally, I prefer the "school grade letter" comparison, since it's more concrete. But hey, you do you.)&lt;/p&gt;
    &lt;p&gt;But it's not limited to just grades &amp;amp; academic performance. Effect sizes can also help us understand any kind of difference between groups, in observation or in experiments!&lt;/p&gt;
    &lt;p&gt;For example...&lt;/p&gt;
    &lt;head rend="h2"&gt;Depression!&lt;/head&gt;
    &lt;p&gt;Let's use our school grade analogy, to interpret effect sizes on mental health:&lt;/p&gt;
    &lt;p&gt;What's an "F in mental health"? By definition of a bell curve, ~2.3% of people are below ‚Äì2 sigma (an "F"). (See: this bell curve calculator.) In Canada, ~2.6% of people had suicidal ideation in 2022, while in the US, it was ~4.9% in 2019. So, it's not too far off to say: "F in mental health = literally suicidal". (Also, reminder that ~4% is 1-in-25 people. You likely know someone, or are someone, who will feel suicidal this year. Please reach out to your friends &amp;amp; loved ones!)&lt;/p&gt;
    &lt;p&gt;What's a "D in mental health"? ~16% of people are below ‚Äì1 sigma (a "D") on a bell curve. The Keyes 2002 study estimated that ~14.1% of adults meet the DSM-III criteria for a major depressive episode. So, D = Depressed.&lt;/p&gt;
    &lt;p&gt;What's an average "C in mental health"? ~68% of people are within a sigma of average (a "C") on a bell curve. Same above study found that 56.6 percent had moderate mental health. They were neither "languishing" nor "flourishing". I guess C = Could Be Worse.&lt;/p&gt;
    &lt;p&gt;What's a "B in mental health"? ~16% of people are above +1 sigma (a "B") on a bell curve. Same above study found that 17.2% of adults are "flourishing". Good for them! B = Flourishing, life is good.&lt;/p&gt;
    &lt;p&gt;What's an "A in mental health"? I don't know who these freaks are. I actually could not find any scientific studies on "the +2 sigma in well-being". In contrast, there's lots of research on suicidal ideation, the ‚Äì2 sigma in well-being. In the absence of any actual data, I'll just say: A = AWESOME&lt;/p&gt;
    &lt;p&gt;So, if an intervention is found to have an effect size of +1.0, that's like going up a letter grade. If something's found to have an effect size of -2.0, that's like going down two letter grades. And so on.&lt;/p&gt;
    &lt;p&gt;Okay, so how do we get peoples' "mental health grades" up?&lt;/p&gt;
    &lt;p&gt;Let's look at antidepressants, Omega-3, and Vitamin D, in turn:&lt;/p&gt;
    &lt;head rend="h2"&gt;Antidepressants&lt;/head&gt;
    &lt;p&gt;The good news is they work. The bad news is they don't work as well as you'd think they may work.&lt;/p&gt;
    &lt;p&gt;Cipriani et al 2018 is a recent meta-analysis (a study collecting lots of previous studies) that investigated 21 different antidepressants. The most effective antidepressant, Amitriptyline, relative to placebo, had an Odds Ratio of 2.13 ‚Äî which converts to a Cohen's d effect size of 0.417 ‚Äî which is "small-medium" according to Cohen's recommendations. Or, by our school-letter-grade comparison: the best antidepressant would take your mental health grade from an F to F+, or C to C+.&lt;/p&gt;
    &lt;p&gt;From Figure 3 of that paper, you can see that Amitriptyline has the highest estimated effect size, while the side effects are no worse than placebo:&lt;/p&gt;
    &lt;p&gt;Sure, "F to F+" can be lifesaving, but‚Ä¶ y'know‚Ä¶ that's not a lot. And again, this is the effect on average. Some people respond much better to antidepressants‚Ä¶ while some respond much worse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Omega-3&lt;/head&gt;
    &lt;p&gt;Keep getting confused on which fat is what? Me too. So, here's a crash course on various fats:&lt;/p&gt;
    &lt;p&gt;Fatty acids are chains of carbons &amp;amp; hydrogens + two oxygens. They say "OOH" at one end, and "HHH" at the other end:&lt;/p&gt;
    &lt;p&gt;A saturated fatty acid is one where all the carbons' free spots are filled up with hydrogens. (Hence, "saturated") This makes the molecule stick straight out. This is why long saturated fatty acids ‚Äî like those found in butter ‚Äî tend to be solid at room temperature.&lt;/p&gt;
    &lt;p&gt;(Contrary to popular belief, saturated fats don't literally clog your arteries, like grease in plumbing pipes. What happens is {ha ha I don't actually understand this}. Something about your cholesterol levels &amp;amp; inflammation.)&lt;/p&gt;
    &lt;p&gt;In contrast, unsaturated fatty acids have at least one hydrogen missing. This causes them to have a double-bond "kink" in the molecule. This makes them not stick out, which is why unsaturated fats tend to be liquid at room temperature. Mono-unsaturated fatty acids (MUFAs) ‚Äî like in olive oil ‚Äî only have one kink. Poly-unsaturated fatty acids (PUFAs) ‚Äî like in fatty fish ‚Äî have two or more kinks. Let's be mature adults about this, please.&lt;/p&gt;
    &lt;p&gt;For completeness: trans fats are unsaturated fats whose "kink" is twisted around, causing them to go straight. That is the worst sentence I've written all month. The twisted kink is caused by the hydrogens being on opposite sides, hence "trans". (And yes, if they're on the same side it's "cis". Latin was a mistake.) The molecule being straight is why trans fats ‚Äî which margarine used to be full of ‚Äî are solid at room temperature, despite being an unsaturated fat.&lt;/p&gt;
    &lt;p&gt;It's neat whenever you can trace the history of something right down to its atoms! Margarine was first invented because it's cheaper, and is spreadable straight from the fridge, unlike butter. Margarine (used to be) made by taking unsaturated vegetable oils, which were cheaper than animal fats, then pumping a bunch of hydrogens into it (hence, "hydrogenated oils"). If you completely hydrogenate an oil, it becomes a saturated fat. But they only partially hydrogenated those oils, leading to trans fats, which were cheaper &amp;amp; a spreadable semi-solid at fridge temperature.&lt;/p&gt;
    &lt;p&gt;In the 1970s &amp;amp; 80s, the US Food &amp;amp; Drug Administration concluded that trans fats were not harmful to humans, and nutritionists promoted margarine over butter, because butter had "unhealthy" saturated fats. But in the early 1990s, scientists realized that trans fats were even worse for you than saturated fats. Only in the 2010's, did most Western countries start officially banning trans fats. Reminder: policy is often decades behind science.&lt;/p&gt;
    &lt;p&gt;(Hey, what do you call it when you get thiccer on HRT? Trans fat! :D)&lt;/p&gt;
    &lt;p&gt;I need to stop going on infodump tangents. Anyway, Omega-3 is any fatty acid with its first kink at the 3rd carbon from the Omega end ("HHH"), though it can have more kinks later down the chain. (And yes, Omega-6 has its first kink at the 6th carbon, and Omega-9 has its first kink at the 9th carbon. There's nothing physically preventing Omega-4 or Omega-5's from existing, but due to some quirk of evolution, Omega-3, -6, and -9 are the ones biological life uses most. As far as I can tell, there's no specific reason they're all multiples of 3. Probably just a coincidence. There is a less common Omega-7.)&lt;/p&gt;
    &lt;p&gt;Finally, there's three main types of Omega-3: EPA (Eicosapentaenoic Acid), DHA (Docosahexaenoic Acid), and ALA (Alpha-Linolenic Acid). ALA is mostly found in plants like chia seeds &amp;amp; walnuts, while EPA &amp;amp; DHA mostly come from seafood, though there are algae-based vegan sources.&lt;/p&gt;
    &lt;p&gt;(Figure 1.1 from Roke 2016.‚§µ Thank you Kaitlin Samantha Roke for drawing this coz I'm too lazy to draw it myself. Note how the first double-bond "kink" for all these molecules is at the 3rd carbon from the Omega end ‚Äî hence why they're all called Omega-3's.)&lt;/p&gt;
    &lt;p&gt;EPA &amp;amp; DHA are the focus of this section. For bio-mechanical reasons I don't understand but I assume someone else does: EPA is the one associated with anti-inflammation, better brain health, and less depression... while DHA isn't. (But DHA is still needed for other stuff, like your neurons' cell walls, so don't cut them out completely!)&lt;/p&gt;
    &lt;p&gt;(Note: I could not find any experimental trials of ALA on depression, though an observational study in Japan (Kurotani et al 2014) finds a correlation between higher ALA and lower depression. But reminder, correlation is not necessarily causation.)&lt;/p&gt;
    &lt;p&gt;All the above info in a Venn (technically Euler) diagram:&lt;/p&gt;
    &lt;p&gt;Okay, enough yap. Time for the actual data:&lt;/p&gt;
    &lt;p&gt;Sublette et al 2011 is an older meta-analysis, but it's the only one I could find that tries to estimate the actual "dose-response" curve, which shows: how much effect, for how much treatment. Why is that important? Because one problem with many meta-analyses is they'll do something like: "Study 1 gave patients 1 gram of medicine and saw a +1 improvement in disease, Study 2 gave 10 grams and saw +4 improvement, Study 3 gave 100 grams and saw negative ‚Äì5 improvement‚Ä¶ the average of +1, +4, and ‚Äì5 is zero... therefore the medicine's effect is zero." ...As mentioned briefly earlier, this is a meaningless mean. That's why we want to know the response at each dose.&lt;/p&gt;
    &lt;p&gt;So, the Sublette meta-analysis gathered randomized trials studying Omega-3 on depression (vs placebo, of course) and got the following dose-response curve.‚§µ Note that the horizontal axis is not just amount of total Omega-3, but specifically the extra amount of "unopposed" EPA, above the amount of DHA. Or in other words, "EPA minus DHA":&lt;/p&gt;
    &lt;p&gt;The top effect size is around +0.558, which is like going from an F to D‚Äì, or C to B‚Äì. You get this maximum effect around 1 to 2 grams of extra EPA, and too much EPA gets worse results. The meta-analysis finds that Omega-3 supplements that are ~60% EPA (and the rest DHA) are optimal.&lt;/p&gt;
    &lt;p&gt;This finding is roughly in line with later meta-analyses. Liao et al 2019 also finds that ~1 gram of ‚â•60% EPA is best, but actually found a much higher effect size: +1.03. Kelaiditis et al 2023 also finds 1 to 2g of ‚â•60% EPA is best, but found a lower effect size of +0.43‚Ä¶ which is still as good as the best antidepressant!&lt;/p&gt;
    &lt;p&gt;Either way, let's boil this down to a recommendation. You want around 1 gram of EPA a day. So if your supplements are 60% EPA, you need 1 gram √∑ 0.6 ~= 1.667 grams = 1667 milligrams. Let's round this down for convenience: get 1500 mg/day of 60%-EPA Omega-3 supplements.&lt;/p&gt;
    &lt;p&gt;In comparison, most official health organizations recommend "250‚Äì500 mg combined EPA and DHA each day for healthy adults." That is over three times too low, at least for optimal effects on depression. Which, as we calculated above, is probably around 1500 mg/day. (The official safe dose is 5000 mg/day)&lt;/p&gt;
    &lt;p&gt;Finally, a (small) study directly investigating the link between suicide &amp;amp; Omega-3. Sublette et al 2006: ‚ÄúLow [DHA] and low Omega-3 proportions [...] predicted risk of suicidal behavior among depressed patients over the 2-year period.‚Äù Though keep in mind this is a small study, and it's observational not experimental. Also, weird that contrary to the above studies on depression, DHA predicted suicide but not EPA. Not sure what to make of that.&lt;/p&gt;
    &lt;p&gt;Bonus: Omega-3 may also boost cognition? Shahinfar et al 2025: ‚ÄúEnhancement of global cognitive abilities was observed with increasing omega-3 dosage up to 1500 mg/day. [effect size = 1.00, like going from a grade of C to B!], followed by downward trend at higher doses.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Vitamin D&lt;/head&gt;
    &lt;p&gt;Ghaemi et al 2024 is a meta-analysis on Vitamin D on depression. Again, it actually estimates a dose-response curve! Below is Figure 1 + Table 2, showing the effect of Vitamin D dosage on depression vs placebo. The solid line is the average estimated effect, dashed lines are 95% confidence interval. Note the effect size is negative in this figure, because they're measuring reduction in depressive symptoms:&lt;/p&gt;
    &lt;p&gt;The upper range of uncertainty is lowest at 5000 IU (International Units) of Vitamin D a day, with an estimated effect size of 1.82, with a 95% uncertainty range, from 0.98 to 2.66. An effect size of 1.82 is like taking your mental health from an F to a C‚Äì, or a C to an A‚Äì! And even in the most pessimistic case, 0.98, that's still over twice as effective as the top antidepressant!&lt;/p&gt;
    &lt;p&gt;(The paper's summary says 8000 IU is best, with effect size 2.04, but there's much greater uncertainty there. The paper also finds that longer studies had smaller effects than shorter studies, but this does not necessarily mean Vitamin D's effects are short-lived. Looking at Supplementary Table 4, it seems this is partly because longer studies used lower average daily doses. For example, one 52-week study only gave participants 400 IU a day.)&lt;/p&gt;
    &lt;p&gt;This meta-analysis includes trials with participants who don't have Vitamin D deficiency. There's still a good effect of Vitamin D on depression for them, even if smaller! Though, you probably are lacking Vitamin D: Liu et al 2018 finds that a bit under half of all adults (41.4%) have Vitamin D Insufficiency.&lt;/p&gt;
    &lt;p&gt;And that's according to the official recommendation, of 400-800 IU a day‚Ä¶ which is is too damn low. Even the official maximum safe dose of Vitamin D, of 4000 IU/day, is too low. McCullough et al 2019 gave over thousands of patients 5,000 to 10,000 IU/day, for seven years, and there were zero cases of serious side effects. This is in line with Billington et al 2020, a 3-year-long double-blinded randomized controlled trial, where they found "the safety profile of vitamin D supplementation is similar for doses of 400, 4000, and 10,000 IU/day." (though "mild hypercalcemia" increased from 3% to 9%. IMHO, that's a small cost for reducing the risk of major depression &amp;amp; suicide.)&lt;/p&gt;
    &lt;p&gt;And it makes sense that 10,000 IU a day should be safe. Your skin, exposed to the Sun's ultraviolet rays, can synthesize up to (the equivalent of) 10,000 IU a day, before plateauing out. Source is Vieth 1999: ‚ÄúBecause vitamin D is potentially toxic, intake of [1000 IU/day] has been avoided even though the weight of evidence shows that the currently accepted [limit] of [2000 IU/day] is too low by at least 5-fold.‚Äù (So why are all the official sources still so paranoid about Vitamin D? Well, unfortunately, official/governmental policy is always a few decades behind the science in any field. See Also: the trans fat debate, everything about educational policy.)&lt;/p&gt;
    &lt;p&gt;Speaking of the Sun, why take supplements instead of just getting Vitamin D from Sun exposure? Well, skin cancer. But also: because Sun-Skin D varies greatly depending on the season, your latitude, and your skin type. There's less ultraviolet rays from the Sun in winter/fall, and at latitudes further from the equator. And the darker your skin is, the less Vitamin D your skin makes for the same amount of Sun exposure. As expected from the bio-physics of skin, Black adults have the highest prevalence of Vitamin D deficiency (82.1%!!), followed by Hispanic adults (62.9%). (But hey, at least Black adults have the lowest incidence of skin cancer. You win some you lose some.) The point is: speaking as someone with Southeast Asian skin, who's currently in Canada during winter... even if I stood outside naked for hours, I'd get approximately zero IU/day of Vitamin D from the Sun. Thus: supplements.&lt;/p&gt;
    &lt;p&gt;Finally, a meta-analysis directly measuring the effect of Vitamin D on suicide rates. Yu et al 2025: ‚ÄúVitamin D in patients with [suicidal behaviours] were significantly lower than in controls (standardized mean difference: ‚Äì0.69, or a 'medium' difference)‚Äù. Reminder that this paper by itself only measures correlation, not causation ‚Äî but combined with the above experiments of Vitamin D on depression, I think it's reasonable to guess it's partly causal.&lt;/p&gt;
    &lt;p&gt;To recap:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Almost half of you have a Vitamin D deficiency according to the official recommendation (800 IU/day).&lt;/item&gt;
      &lt;item&gt;And the official recommendation is way too low. Even the official maximum safe dose (4000 IU/day) is below the optimal Vitamin D for depression (5000 IU/day) or what your body can produce from the Sun in optimal conditions (10,000 IU/day). Recent randomized controlled trials confirm that 10,000 IU/day is, indeed, mostly safe.&lt;/item&gt;
      &lt;item&gt;Your daily reminder than official policy is often decades behind the science.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bonus: Vitamin D supplementation was found in several randomized controlled trials to reduce mortality from Covid-19! It probably helps guard against influenza too, though the evidence is small &amp;amp; early.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion: All this time, you lacked the Vitamin?&lt;/head&gt;
    &lt;p&gt;Scurvy is caused by a lack of Vitamin C. It's a condition that causes your wounds to re-open up &amp;amp; teeth to fall out. Scurvy used to kill almost half(!) of all sailors on major expeditions; it's estimated millions died. It can be cured by eating lemons.&lt;/p&gt;
    &lt;p&gt;Rickets is mostly caused by a lack of Vitamin D. It's a condition where kids' bones go all soft and deformed. During the Industrial Revolution, up to 80% of kids suffered from it. It can be prevented with cod liver oil.&lt;/p&gt;
    &lt;p&gt;Goiters is mostly caused by a lack of Iodine. It's a condition where the thyroid gland in your neck swells up painfully, to the size of an apple. During WWI, a third of adult men had goiters. It can be prevented with iodized salt.&lt;/p&gt;
    &lt;p&gt;About 1 in 4 people are expected to have clinical depression sometime in their life. Depression is the #1 source of the global "burden from disease" in the mental health category, and that category is the #6 burden of disease in the world, above Alzheimer's, malaria, and sexually transmitted infections.&lt;/p&gt;
    &lt;p&gt;(But honestly, did you need those stats? This is likely a lived experience for a lot of you reading this.)&lt;/p&gt;
    &lt;p&gt;The effective altruists are all, "woah for just $3000 you can prevent a child's death from malaria" ‚Äî and that's great! save them kids! ‚Äî but where's the fanfare for the accumulating evidence that, "woah with cheap daily supplements we can save millions from suicide &amp;amp; depressed lives"?&lt;/p&gt;
    &lt;p&gt;Over and over again throughout history, some horrific thing that caused millions to suffer, turned out to be "yeah you were missing this one molecule lol". To be clear: not everything is gonna be that simple, and mental health is not "just" chemistry. Also, all the numbers on this page have with large error bars &amp;amp; uncertainty, more research is needed.&lt;/p&gt;
    &lt;p&gt;But, as of right now, I feel I can at least confidently claim the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vitamin D and Omega-3 are both at least on par with antidepressants.&lt;/item&gt;
      &lt;item&gt;The evidence is much stronger for Vitamin D; it's very plausibly at least twice as good as antidepressants.&lt;/item&gt;
      &lt;item&gt;Both supplements are cheap and safe, so what's the harm of trying? (positive "expected value" for this bet)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So:&lt;/p&gt;
    &lt;p&gt;MY SPECIFIC RECOMMENDATIONS FOR YOU TO DO A.S.A.P:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go to a pharmacy, buy the following supplements over-the-counter, in whatever form you like: (I like the easy-to-swallow gel capsules)&lt;/item&gt;
      &lt;item&gt;Vitamin D &lt;list rend="ul"&gt;&lt;item&gt;üå± By default, Vitamin D supplements are derived from‚Ä¶ (quick web search)‚Ä¶ the grease in sheep's wool? Huh. Also fish liver oil. Anyway, if you're vegan, make sure your bottle specifically says "vegan" or "from lichen/mushrooms". (If you're vegetarian, the sheep's-wool Vitamin D is fine, they don't kill the sheep for it.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Omega-3 where EPA is ~60% of the Omega-3 total. For example, my 500mg Omega-3 capsules have 300mg EPA, 200mg DHA. &lt;list rend="ul"&gt;&lt;item&gt;üå± By default, Omega-3 supplements come from fish. If you're veg(etari)?an, there are plant-based sources of Omega-3, but look carefully: most vegan Omega-3 supplements provide more DHA than EPA, which the above studies suggest fully cancel out the antidepressant effect. Double check the nutritional label to make sure it's ‚â•60% EPA. For example, this one is 300mg EPA + 200mg DHA. (not an affiliate link)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then, every day:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Take ~5000 IU of Vitamin D &lt;list rend="ul"&gt;&lt;item&gt;‚ö†Ô∏è be cautious if you have kidney stones, or are on medications that could interact with Vitamin D. "ask your doctor".&lt;/item&gt;&lt;item&gt;4,000 IU is the "official maximum safe dose", if you understandably don't trust a random internet blogger, even though she cited peer-reviewed sources.&lt;/item&gt;&lt;item&gt;10,000 IU if you're feeling daring / have darker skin / live in less sunny climates.&lt;/item&gt;&lt;item&gt;bonus: may improve immune response to Covid &amp;amp; influenza?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Take ~1500 mg of ‚â•60%-EPA Omega-3 &lt;list rend="ul"&gt;&lt;item&gt;‚ö†Ô∏è be cautious if you're on blood thinners, or other medications that could interact with Omega-3. again, "ask your doctor".&lt;/item&gt;&lt;item&gt;bonus: may improve cognition?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;(Don't quit your existing antidepressants if they're net-positive for you!) &lt;list rend="ul"&gt;&lt;item&gt;you may also want to ask your doctor about Amitriptyline, or those other best-effect-size antidepressants.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Can you get these doses of Vitamin D &amp;amp; Omega-3 through whole foods alone, no supplements? Probably, but it'd be expensive &amp;amp; tedious: you'd have to eat something like 2,000 calories of farmed salmon a day to get 5,000 IU/day of Vitamin D. As for Omega-3, eating mostly oily fishes would get you &amp;gt;1000mg of Omega-3, but they'd be more DHA than EPA, which the above studies suggest would cancel out the antidepressant effects.&lt;/p&gt;
    &lt;p&gt;The effect sizes on depression:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The best antidepressant: +0.417 &lt;list rend="ul"&gt;&lt;item&gt;like your mental health grade going from F to F+, or C to C+&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;1500mg of ‚â•60%-EPA Omega-3: +0.558 &lt;list rend="ul"&gt;&lt;item&gt;like your mental health grade going from F to D‚Äì, or C to B‚Äì&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;5000 IU of Vitamin D: +1.82 &lt;list rend="ul"&gt;&lt;item&gt;like your mental health grade going from F to C‚Äì, or C to A‚Äì&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For completeness &amp;amp; comparison, here's the effect size of other things on depression:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Any mainstream "bona-fide" psychotherapy (CBT, Psychodynamic, Humanist, Solutions-Focused): +0.35, source: Kamenov et al 2016 &lt;list rend="ul"&gt;&lt;item&gt;like going from C to C+&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Aerobic/Cardio Exercise: +0.79, source Ioannis et al 2018 &lt;list rend="ul"&gt;&lt;item&gt;like going from C to B‚Äì&lt;/item&gt;&lt;item&gt;(dose: "45 minutes, at moderate intensity, three times/week" ‚áí ~20 min/day)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Good Sleep: +1.10(???), a lot of interpretation &amp;amp; calculations, see footnote[2] &lt;list rend="ul"&gt;&lt;item&gt;like going from C to B&lt;/item&gt;&lt;item&gt;(dose: going from moderate insomnia to healthy sleep)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Bright Light Therapy: +0.487, source Menegaz de Almeida et al 2025 &lt;list rend="ul"&gt;&lt;item&gt;(the above paper reports Odds Ratio of 2.42, which converts to Cohen's d effect size of +0.487)&lt;/item&gt;&lt;item&gt;like going from C to C+&lt;/item&gt;&lt;item&gt;I went with Wirecutter's recommendation for a UV-free 10,000 lux lamp.&lt;/item&gt;&lt;item&gt;(dose: 10,000 lux, 30 min a day)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Mindfulness Meditation: +0.42, source Breedvelt et al 2019 &lt;list rend="ul"&gt;&lt;item&gt;like going from C to C+&lt;/item&gt;&lt;item&gt;(dose: 7 weeks, "153 min each week" ‚áí ~20 min/day)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(And remember, you can stack any of the above interventions to get an even larger effect! You can't just naively add up the effect sizes, but I'd be surprised if the effect of {vitamin d + omega-3 + bright lamps + cardio + good sleep + meditation} combined ends up being less than +2.00. Two letter grades up means going from D to B, or, theoretically, from clinically depressed to flourishing! For more papers &amp;amp; my working research notes on "best bang for buck on depression", check out this Google Doc.)&lt;/p&gt;
    &lt;p&gt;Also, remember that all the above estimates are uncertain. And in general, when scientists replicate psychology experiments more rigorously, the effect size usually shrinks by ¬Ω. But, I think the overall qualitative picture is still strong: there exist high bang-for-buck ways to reduce depression, which are at least on par with drugs &amp;amp; therapy (possibly 2x to 4x better), that aren't (yet) common knowledge amongst policymakers &amp;amp; the public. And again, they're dirt cheap with minor-to-no adverse side effects. Moderate chance of a big win, for a known tiny cost. That's a positive "expected value" bet right there.&lt;/p&gt;
    &lt;p&gt;I got onto this research rabbithole a few months ago while borrowing my housemate's ADHD meds, which I may or may not eventually collect into a "JOYMAXXING" informal meta-meta-analysis. (: See me yap about it on video as a cartoon cat.) But for this blog post, I wanted to dive deeper into Vitamin D and Omega-3, since their effect sizes are so huge, and they're insultingly cheap &amp;amp; easy, compared to therapy or regular cardio.&lt;/p&gt;
    &lt;p&gt;Stay safe this winter, keep away the seasonal depression. Get your supplements, and reach out to your friends &amp;amp; loved ones!&lt;/p&gt;
    &lt;p&gt;üíñ,&lt;lb/&gt; ~ Nicky Case&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;I made up these ranges by requiring the standard letter grades F,D,C,B,A, to have their centers be -2,-1,0,+1,+2. Then, I made sure all in-between grades like C+ or A‚Äì had equal intervals. Each interval is +/- ‚Öô, or ‚Öì wide:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;F---: -3.16 to -2.83&lt;/item&gt;
          &lt;item&gt;F--: -2.82 to -2.50&lt;/item&gt;
          &lt;item&gt;F‚Äì: -2.49 to -2.17&lt;/item&gt;
          &lt;item&gt;F: -2.16 to -1.83&lt;/item&gt;
          &lt;item&gt;F+: -1.82 to -1.50&lt;/item&gt;
          &lt;item&gt;D‚Äì: -1.49 to -1.17&lt;/item&gt;
          &lt;item&gt;D: -1.16 to -0.83&lt;/item&gt;
          &lt;item&gt;D+: -0.82 to -0.50&lt;/item&gt;
          &lt;item&gt;C‚Äì: -0.49 to -0.17&lt;/item&gt;
          &lt;item&gt;C: -0.16 to +0.17&lt;/item&gt;
          &lt;item&gt;C+: +0.18 to +0.50&lt;/item&gt;
          &lt;item&gt;B‚Äì: +0.51 to +0.83&lt;/item&gt;
          &lt;item&gt;B: +0.84 to +1.17&lt;/item&gt;
          &lt;item&gt;B+: +1.18 to +1.50&lt;/item&gt;
          &lt;item&gt;A‚Äì: +1.51 to +1.83&lt;/item&gt;
          &lt;item&gt;A: +1.84 to +2.17&lt;/item&gt;
          &lt;item&gt;A+: +2.18 to +2.50&lt;/item&gt;
          &lt;item&gt;A++: +2.51 to +2.83&lt;/item&gt;
          &lt;item&gt;A+++: +2.84 to +3.17&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lee et al 2023 reports the following effect sizes. Digital therapy for Insomnia ‚Üí Sleep = 0.76, and Digital therapy for Insomnia ‚Üí Depression = 0.42. Assuming the therapy for insomnia specifically affects depression only through better sleep (Digital therapy for Insomnia ‚Üí Sleep ‚Üí Depression), we can do an "Instrumental Variable" estimate of the effect of Sleep ‚Üí Depression = 0.42 / 0.76 = 0.55. To be precise: this is saying, if you improve your sleep by 1 standard deviation, on average your depression improves by 0.55 standard deviations.&lt;/p&gt;
        &lt;p&gt;So: how many standard deviations is going from "moderate insomnia" to "healthy sleep"? The standard measure is the Insomnia Severity Index (ISI), which you can take online. A score of 0‚Äì7 means no insomnia, 8‚Äì14 is subclinical insomnia, 15‚Äì21 is clinical insomnia (moderate), 22‚Äì28 is clinical insomnia (severe). Let's be conservative and say we're just going from barely clinical to barely healthy: 15 to 7, or a reduction of 8 points. Yang et al 2009 says a 6-point reduction is 1.5 standard deviations, which means 4 points is 1 standard deviation. So a reduction of 8 points is 2 standard deviations. So, if you improve your sleep from insomniac to healthy, you improve by at least 8 points, which is 2 standard deviations, so your depression should improve by 2 √ó 0.55 standard deviations, or ~1.10.&lt;/p&gt;
        &lt;p&gt;Reminder that my estimate is full of assumptions upon assumptions &amp;amp; these error bars will compound. But I'd be surprised if the true causal effect of going from insomniac to healthy sleep isn't at least a "large" +0.8 effect. ‚Ü©Ô∏é&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.ncase.me/on-depression/"/><published>2026-01-29T10:35:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46809420</id><title>The Sovereign Tech Fund Invests in Scala</title><updated>2026-01-29T19:07:08.063531+00:00</updated><content>&lt;doc fingerprint="47f2b49f06f2a0bf"&gt;
  &lt;main&gt;
    &lt;p&gt;Darja Jovanovic, Scala Center&lt;/p&gt;
    &lt;p&gt;We√¢re truly excited to share that Scala has received an investment from the Sovereign Tech Fund to strengthen Scala√¢s long-term security, maintenance, and developer experience.&lt;/p&gt;
    &lt;p&gt;The work is coordinated by the Scala Center and runs for two years, with a total investment of √¢¬¨377,300.&lt;/p&gt;
    &lt;p&gt;The Sovereign Tech Fund is a program of the Sovereign Tech Agency that globally invests in open software components that build our core digital infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Sovereign Tech Agency and the Sovereign Tech Fund&lt;/head&gt;
    &lt;p&gt;The Sovereign Tech Agency is the first publicly funded organization in Europe that supports the development, improvement, and maintenance of open digital infrastructures. It is financed by the German Federal Ministry for Digital Transformation and Government Modernisation and is a subsidiary of SPRIND, the Federal Agency for Disruptive Innovation.&lt;/p&gt;
    &lt;p&gt;The Sovereign Tech Agency√¢s mission is to strengthen the open source ecosystem sustainably, focusing on resilience, technological diversity, and the people behind the code as foundations for a future-ready economy and modern society.&lt;/p&gt;
    &lt;p&gt;The Sovereign Tech Fund identifies and invests in open source software components that enable the creation of software, and supports key technologies with broad societal importance. Since October 2022, the Sovereign Tech Fund has invested a total of around √¢¬¨34 million in 95 critical technology projects.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scala is critical digital infrastructure&lt;/head&gt;
    &lt;p&gt;Scala is widely used to build and operate essential systems across multiple industries. These systems include data pipelines and distributed applications, and some are in highly regulated environments like finance and public services. In these contexts, reliability is paramount. The safety, sustainability, and evolution of the Scala language and its tooling directly impact systems that people and institutions rely on every day.&lt;/p&gt;
    &lt;p&gt;This is why, in 2016, the Scala Center was founded with a clear mission: to make the Scala open-source ecosystem stronger, more resilient, and sustainable over the long term. Thanks to the continued support of Scala Center industry partners (through the Advisory Board program), EPFL, and the worldwide Scala contributor community, the ecosystem continues to grow stronger every day.&lt;/p&gt;
    &lt;p&gt;And today, with the Sovereign Tech Fund√¢s investment in Scala, this commitment is reinforced at a public-infrastructure level. We are very thankful that the Fund√¢s support recognizes Scala as critical digital infrastructure and enables sustained, focused work on the language√¢s core foundations over the coming years.&lt;/p&gt;
    &lt;head rend="h2"&gt;A closer look: what this investment will deliver&lt;/head&gt;
    &lt;head rend="h3"&gt;1) Security Audit&lt;/head&gt;
    &lt;p&gt;A dedicated security audit by Open Source Technology Improvement Fund (OSTIF) will uncover vulnerabilities and strengthen confidence in Scala√¢s core components. This supports not only Scala users, but also the broader environments where Scala runs, for example as a component of complex software supply chains. We are super thankful to the OSTIF team and support!&lt;/p&gt;
    &lt;head rend="h3"&gt;2) Improvement of scoverage&lt;/head&gt;
    &lt;p&gt;scoverage is a key tool in the Scala ecosystem for measuring code coverage. Improving it increases the reliability of Scala codebases and helps teams detect gaps in testing earlier, especially as systems evolve.&lt;/p&gt;
    &lt;head rend="h3"&gt;3) Maintenance of the Standard Library / Core Library Modules and APIs&lt;/head&gt;
    &lt;p&gt;Long-term maintenance of core libraries and APIs is critical for stability. This includes keeping foundational modules healthy, reducing technical debt, and ensuring compatibility across versions.&lt;/p&gt;
    &lt;head rend="h3"&gt;4) Modernization and extension of the Standard Library / Core Library Modules and API Documentation&lt;/head&gt;
    &lt;p&gt;As Scala continues to evolve, modernizing and extending core modules ensures the language remains productive and relevant, while also supporting gradual adoption and stable upgrade paths. The work also brings improvements to API documentation and Scala websites, to improve understanding.&lt;/p&gt;
    &lt;head rend="h3"&gt;5) Build tool major update: sbt 2.0&lt;/head&gt;
    &lt;p&gt;Build tools are the backbone of developer productivity. The major update to sbt 2.0 will make Scala projects easier to build, maintain, and understand. This will be impactful for new users and contributors, as well as for established projects. Among other improvements, sbt 2 adopts Scala 3 (in place of 2.12) as the language for build definitions.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Scala Center√¢s role&lt;/head&gt;
    &lt;p&gt;The Scala Center has been entrusted with coordinating the commissioned work, check out the team working on the projects.&lt;/p&gt;
    &lt;p&gt;We are very thankful that this support recognizes Scala√¢s importance in the broader digital landscape, and for investing in foundational work that strengthens the reliability of the systems and services built on Scala across the public sector and industries.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stay informed and get involved&lt;/head&gt;
    &lt;p&gt;We√¢ll share updates as work progresses, including milestones, delivered improvements, and opportunities to engage with the effort.&lt;/p&gt;
    &lt;p&gt;Scala is critical digital infrastructure, so keeping it healthy is a shared responsibility. If you√¢re using Scala in production, maintaining libraries, or contributing to tooling and documentation, your feedback and involvement help keep Scala strong.&lt;/p&gt;
    &lt;p&gt;In addition to occasional blog posts such as this one, we√¢ll also post more detailed updates, progress reports, and calls for feedback on our Discourse-based contributors forum at contributors.scala-lang.org. Please follow the relevant threads to stay informed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.scala-lang.org/blog/2026/01/27/sta-invests-in-scala.html"/><published>2026-01-29T12:42:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46810282</id><title>Claude Code Daily Benchmarks for Degradation Tracking</title><updated>2026-01-29T19:07:07.927160+00:00</updated><content>&lt;doc fingerprint="3e41c1f13fb30ae2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Claude Code Opus 4.5 Performance Tracker&lt;/head&gt;
    &lt;p&gt;The goal of this tracker is to detect statistically significant degradations in Claude Code with Opus 4.5 performance on SWE tasks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ Updated daily: Daily benchmarks on a curated subset of SWE-Bench-Pro&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Detect degradation: Statistical testing for degradation detection&lt;/item&gt;
      &lt;item&gt;‚Ä¢ What you see is what you get: We benchmark in Claude Code CLI with the SOTA model (currently Opus 4.5) directly, no custom harnesses.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Summary&lt;/head&gt;
    &lt;head rend="h3"&gt;Daily Trend&lt;/head&gt;
    &lt;p&gt;Pass rate over time&lt;/p&gt;
    &lt;p&gt;Dashed line at 58% baseline with ¬±14.0% significance threshold&lt;/p&gt;
    &lt;head rend="h3"&gt;Weekly Trend&lt;/head&gt;
    &lt;p&gt;Aggregated 7-day pass rate&lt;/p&gt;
    &lt;p&gt;Dashed line at 58% baseline with ¬±5.6% significance threshold&lt;/p&gt;
    &lt;head rend="h3"&gt;Change Overview&lt;/head&gt;
    &lt;p&gt;Performance delta by period&lt;/p&gt;
    &lt;head rend="h3"&gt;Methodology&lt;/head&gt;
    &lt;p&gt;The goal of this tracker is to detect statistically significant degradations in Claude Code with Opus 4.5 performance on SWE tasks. We are an independent third party with no affiliation to frontier model providers.&lt;/p&gt;
    &lt;p&gt;Context: In September 2025, Anthropic published a postmortem on Claude degradations. We want to offer a resource to detect such degradations in the future.&lt;/p&gt;
    &lt;p&gt;We run a daily evaluation of Claude Code CLI on a curated, contamination-resistant subset of SWE-Bench-Pro. We always use the latest available Claude Code release and the SOTA model (currently Opus 4.5). Benchmarks run directly in Claude Code without custom harnesses, so results reflect what actual users can expect. This allows us to detect degradation related to both model changes and harness changes.&lt;/p&gt;
    &lt;p&gt;Each daily evaluation runs on N=50 test instances, so daily variability is expected. Weekly and monthly results are aggregated for more reliable estimates.&lt;/p&gt;
    &lt;p&gt;We model tests as Bernoulli random variables and compute 95% confidence intervals around daily, weekly, and monthly pass rates. Statistically significant differences in any of those time horizons are reported.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://marginlab.ai/trackers/claude-code/"/><published>2026-01-29T13:59:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46810337</id><title>Playing Board Games with Deep Convolutional Neural Network on 8bit Motorola 6809</title><updated>2026-01-29T19:07:04.315456+00:00</updated><content>&lt;doc fingerprint="31777073c4324395"&gt;
  &lt;main&gt;&lt;p&gt;WEKO3&lt;/p&gt;&lt;head rend="h3"&gt;„Ç¢„Ç§„ÉÜ„É†&lt;/head&gt;&lt;head rend="h2"&gt; Playing Board Games with a Deep Convolutional Neural Network on the Motorola 6809 8-Bit Microprocessor &lt;/head&gt;&lt;p&gt;https://ipsj.ixsq.nii.ac.jp/records/229345&lt;/p&gt; https://ipsj.ixsq.nii.ac.jp/records/229345&lt;p&gt;9e1431e2-99f7-4d16-8f82-d7dcfa6a2045&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;ÂêçÂâç / „Éï„Ç°„Ç§„É´&lt;/cell&gt;&lt;cell role="head"&gt;„É©„Ç§„Çª„É≥„Çπ&lt;/cell&gt;&lt;cell role="head"&gt;„Ç¢„ÇØ„Ç∑„Éß„É≥&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt; IPSJ-GPWS2023012.pdf (275.3 kB) &lt;/cell&gt;&lt;cell&gt;&lt;p&gt; Copyright (c) 2023 by the Information Processing Society of Japan &lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;„Ç™„Éº„Éó„É≥„Ç¢„ÇØ„Çª„Çπ&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="9"&gt;&lt;cell role="head"&gt;Item type&lt;/cell&gt;&lt;cell&gt;Symposium(1)&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ÂÖ¨ÈñãÊó•&lt;/cell&gt;&lt;cell&gt;2023-11-10&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;„Çø„Ç§„Éà„É´&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;„Çø„Ç§„Éà„É´&lt;/cell&gt;&lt;cell&gt;Playing Board Games with a Deep Convolutional Neural Network on the Motorola 6809 8-Bit Microprocessor&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;„Çø„Ç§„Éà„É´&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë®ÄË™û&lt;/cell&gt;&lt;cell&gt;en&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;„Çø„Ç§„Éà„É´&lt;/cell&gt;&lt;cell&gt;Playing Board Games with a Deep Convolutional Neural Network on the Motorola 6809 8-Bit Microprocessor&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë®ÄË™û&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë®ÄË™û&lt;/cell&gt;&lt;cell&gt;eng&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;„Ç≠„Éº„ÉØ„Éº„Éâ&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;‰∏ªÈ°åScheme&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;‰∏ªÈ°å&lt;/cell&gt;&lt;cell&gt;deep learning&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;„Ç≠„Éº„ÉØ„Éº„Éâ&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;‰∏ªÈ°åScheme&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;‰∏ªÈ°å&lt;/cell&gt;&lt;cell&gt;quantization&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;„Ç≠„Éº„ÉØ„Éº„Éâ&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;‰∏ªÈ°åScheme&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;‰∏ªÈ°å&lt;/cell&gt;&lt;cell&gt;neural networks&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë≥áÊ∫ê„Çø„Ç§„Éó&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë≥áÊ∫ê„Çø„Ç§„ÉóË≠òÂà•Â≠ê&lt;/cell&gt;&lt;cell&gt;http://purl.org/coar/resource_type/c_5794&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë≥áÊ∫ê„Çø„Ç§„Éó&lt;/cell&gt;&lt;cell&gt;conference paper&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ËëóËÄÖÊâÄÂ±û&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Kayufu&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ËëóËÄÖÊâÄÂ±û(Ëã±)&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;en&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Kayufu&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ËëóËÄÖÂêç&lt;/cell&gt;&lt;cell&gt; R√©mi, Coulom &lt;head&gt;√ó R√©mi, Coulom&lt;/head&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ËëóËÄÖÂêç(Ëã±)&lt;/cell&gt;&lt;cell&gt; R√©mi, Coulom &lt;head&gt;√ó R√©mi, Coulom&lt;/head&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë´ñÊñáÊäÑÈå≤&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ÂÜÖÂÆπË®òËø∞„Çø„Ç§„Éó&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ÂÜÖÂÆπË®òËø∞&lt;/cell&gt;&lt;cell&gt;While training deep-learning neural networks often requires considerable amounts of computing power, inference is efficient, and can be run on small devices. Cell phones are a typical example, but they are still rather powerful. The research presented in this paper takes the challenge to the extreme by running a Go-playing convolutional neural network on the 6809 CPU, an 8-bit microprocessor launched by Motorola in 1978. The software was implemented on a Thomson MO5 microcomputer, and reached a playing strength on par with GNU Go.&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë´ñÊñáÊäÑÈå≤(Ëã±)&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ÂÜÖÂÆπË®òËø∞„Çø„Ç§„Éó&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;ÂÜÖÂÆπË®òËø∞&lt;/cell&gt;&lt;cell&gt;While training deep-learning neural networks often requires considerable amounts of computing power, inference is efficient, and can be run on small devices. Cell phones are a typical example, but they are still rather powerful. The research presented in this paper takes the challenge to the extreme by running a Go-playing convolutional neural network on the 6809 CPU, an 8-bit microprocessor launched by Motorola in 1978. The software was implemented on a Thomson MO5 microcomputer, and reached a playing strength on par with GNU Go.&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Êõ∏Ë™åÊÉÖÂ†±&lt;/cell&gt;&lt;cell&gt; „Ç≤„Éº„É†„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÉØ„Éº„ÇØ„Ç∑„Éß„ÉÉ„Éó2023Ë´ñÊñáÈõÜ &lt;p&gt;Â∑ª 2023, p. 66-69, Áô∫Ë°åÊó• 2023-11-10&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Âá∫ÁâàËÄÖ&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Ë®ÄË™û&lt;/cell&gt;&lt;cell&gt;ja&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Âá∫ÁâàËÄÖ&lt;/cell&gt;&lt;cell&gt;ÊÉÖÂ†±Âá¶ÁêÜÂ≠¶‰ºö&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ipsj.ixsq.nii.ac.jp/records/229345"/><published>2026-01-29T14:03:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46810401</id><title>Waymo robotaxi hits a child near an elementary school in Santa Monica</title><updated>2026-01-29T19:07:04.220174+00:00</updated><content>&lt;doc fingerprint="afaa845301a0f987"&gt;
  &lt;main&gt;
    &lt;p&gt;A Waymo robotaxi struck a child near an elementary school in Santa Monica on January 23, according to the company. Waymo told the National Highway Traffic Safety Administration (NHTSA) that the child ‚Äî whose age and identity are not currently public ‚Äî sustained minor injuries.&lt;/p&gt;
    &lt;p&gt;The NHTSA has opened an investigation into the accident, and Waymo said in a blog post that it ‚Äúwill cooperate fully with them throughout the process.‚Äù&lt;/p&gt;
    &lt;p&gt;Waymo said its robotaxi struck the child at six miles per hour, after braking ‚Äúhard‚Äù from around 17 miles per hour. The young pedestrian ‚Äúsuddenly entered the roadway from behind a tall SUV, moving directly into our vehicle‚Äôs path,‚Äù the company said in its blog post. Waymo said its vehicle ‚Äúimmediately detected the individual as soon as they began to emerge from behind the stopped vehicle.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúFollowing contact, the pedestrian stood up immediately, walked to the sidewalk, and we called 911. The vehicle remained stopped, moved to the side of the road, and stayed there until law enforcement cleared the vehicle to leave the scene,‚Äù Waymo wrote in the post.&lt;/p&gt;
    &lt;p&gt;News of the crash comes as Waymo faces dual investigations into its robotaxis illegally passing school buses. The NHTSA opened a probe into the problem in October shortly after the first report of the incident in Atlanta, Georgia, and the National Transportation Safety Board opened its own investigation last week after around 20 incidents were reported in Austin, Texas.&lt;/p&gt;
    &lt;p&gt;According to the NHTSA, the accident occurred ‚Äúwithin two blocks‚Äù of the elementary school ‚Äúduring normal school drop off hours.‚Äù The safety regulator said ‚Äúthere were other children, a crossing guard, and several double-parked vehicles in the vicinity.‚Äù&lt;/p&gt;
    &lt;p&gt;The NHTSA‚Äôs Office of Defects Investigation is investigating ‚Äúwhether the Waymo AV exercised appropriate caution given, among other things, its proximity to the elementary school during drop off hours, and the presence of young pedestrians and other potential vulnerable road users.‚Äù&lt;/p&gt;
    &lt;head rend="h3"&gt;TechCrunch Founder Summit 2026: Tickets Live&lt;/head&gt;
    &lt;head rend="h4"&gt;On June 23 in Boston, more than 1,100 founders come together at TechCrunch Founder Summit 2026 for a full day focused on growth, execution, and real-world scaling. Learn from founders and investors who have shaped the industry. Connect with peers navigating similar growth stages. Walk away with tactics you can apply immediately&lt;lb/&gt;Save up to $300 on your pass or save up to 30% with group tickets for teams of four or more.&lt;/head&gt;
    &lt;head rend="h3"&gt;TechCrunch Founder Summit: Tickets Live&lt;/head&gt;
    &lt;head rend="h4"&gt;On June 23 in Boston, more than 1,100 founders come together at TechCrunch Founder Summit 2026 for a full day focused on growth, execution, and real-world scaling. Learn from founders and investors who have shaped the industry. Connect with peers navigating similar growth stages. Walk away with tactics you can apply immediately&lt;lb/&gt;Save up to $300 on your pass or save up to 30% with group tickets for teams of four or more.&lt;/head&gt;
    &lt;p&gt;Waymo said in its blog post that its ‚Äúpeer-reviewed model‚Äù shows a ‚Äúfully attentive human driver in this same situation would have made contact with the pedestrian at approximately 14 mph.‚Äù The company did not release a specific analysis of this crash.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://techcrunch.com/2026/01/29/waymo-robotaxi-hits-a-child-near-an-elementary-school-in-santa-monica/"/><published>2026-01-29T14:08:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46810536</id><title>Break Me If You Can: Exploiting PKO and Relay Attacks in 3DES/AES NFC</title><updated>2026-01-29T19:07:03.898057+00:00</updated><content>&lt;doc fingerprint="ecf8d84918a1ebd8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;This paper presents an in-depth analysis of vulnerabilities in MIFARE Ultralight C, MIFARE Ultralight AES, NTAG 223 DNA, NTAG 224 DNA, and widely circulated non-NXP Ultralight C compatible cards. We reveal multiple avenues to substantially weaken the security of each technology across a range of configurations.&lt;/p&gt;
    &lt;p&gt;Through relay-based man-in-the-middle techniques and partial key overwrites√¢optionally combined with EEPROM tearing techniques√¢an attacker can reduce the keyspace of two-key Triple DES (2TDEA) from 2112 to 228 or less in certain real-world deployments, making brute-force key recovery feasible with modest computational resources.&lt;/p&gt;
    &lt;p&gt;We further demonstrate how MIFARE Ultralight AES can be similarly affected when CMAC integrity checks are not enforced. The security of NTAG 223/224 DNA is undermined by the absence of integrity checks and the calculation of CMAC over Secure Unique NFC (SUN) messages, providing an unauthenticated ciphertext oracle that facilitates key recovery from a single tag.&lt;/p&gt;
    &lt;head rend="h2"&gt;Affected Products&lt;/head&gt;
    &lt;p&gt;The following NXP products and non-NXP compatible ICs are affected:&lt;/p&gt;
    &lt;head rend="h2"&gt;Impact Assessment&lt;/head&gt;
    &lt;p&gt;For genuine NXP Ultralight C: Using partial key overwrite across multiple tags sharing a static key, full 112-bit 2TDEA key recovery is achievable in days to weeks depending on available hardware and number of tags.&lt;/p&gt;
    &lt;p&gt;For non-NXP cards (ULCG, FJ8010, USCUID-UL): Flawed PRNGs and missing anti-tearing mechanisms enable complete key recovery from a single card in under 60 seconds√¢even on a mobile phone.&lt;/p&gt;
    &lt;p&gt;For NTAG 223/224 DNA: The SUNCMAC_KEY can be recovered from a single tag in under a minute via partial key overwrite combined with offline CMAC brute-force against collected SUN messages.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key Contributions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Partial Key Overwrite Attack: Enables attackers with authenticated access to reduce key-recovery brute-force workload against 2TDEA and AES-128 keys given multiple source tags using the same key.&lt;/item&gt;
      &lt;item&gt;Theoretical Single-Tag Recovery: Method to recover the full 112-bit 2TDEA key from a single NXP Ultralight C tag in specific configurations, applicable even with diversified keys.&lt;/item&gt;
      &lt;item&gt;NTAG 22x DNA Attack: Partial key overwrite and tearing techniques applied to AES-128 protected NTAG 22x DNA, enabling significantly faster offline CMAC brute-force for recovering the SUN message authentication key.&lt;/item&gt;
      &lt;item&gt;Non-NXP Card Analysis: First systematic analysis of widespread non-NXP Ultralight C compatible cards, demonstrating implementation flaws (predictable PRNGs, absent anti-tearing) allowing near-instantaneous key recovery.&lt;/item&gt;
      &lt;item&gt;Real-World Deployment Survey: Empirical data from hospitality and other deployments showing configuration lapses around key diversification, lock bytes, and integrity mechanisms.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Questions &amp;amp; Answers&lt;/head&gt;
    &lt;p&gt;This research demonstrates vulnerabilities in widely deployed NFC technologies used for access control, ticketing, and hospitality. We show that cryptographic keys protecting MIFARE Ultralight C, MIFARE Ultralight AES, and NTAG 223/224 DNA tags can be recovered through a combination of relay attacks, partial key overwrites, and EEPROM manipulation techniques.&lt;/p&gt;
    &lt;p&gt;The core issue is that these tags lack adequate post-authentication integrity protection, and many deployments fail to properly configure available security features like lock bytes and key diversification.&lt;/p&gt;
    &lt;p&gt;No. The underlying cryptographic algorithms (3DES and AES-128) remain secure. The vulnerabilities arise from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Protocol design choices that allow unauthenticated memory writes after initial authentication&lt;/item&gt;
      &lt;item&gt;Lack of atomicity when writing cryptographic keys across multiple memory pages&lt;/item&gt;
      &lt;item&gt;Widespread misconfiguration in real-world deployments (unlocked memory, static keys)&lt;/item&gt;
      &lt;item&gt;Non-NXP compatible chips with severely flawed random number generators&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yes. We initiated contact with NXP Semiconductors in July 2025 and provided them with a complete draft of our findings. NXP confirmed the findings in August 2025 and requested additional time for product recertification. We coordinated the publication timeline with NXP, balancing their recertification needs with the importance of informing the security community and affected parties.&lt;/p&gt;
    &lt;p&gt;The title comes directly from the default factory key programmed into every MIFARE Ultralight C chip by NXP. When you read the 16-byte 3DES key from a fresh Ultralight C tag, it spells out the ASCII string &lt;code&gt;BREAKMEIFYOUCAN!&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This appears to be a deliberately playful challenge left by NXP's engineers in 2008 for the security research community, and embedded directly in the Ultralight C's memory. We chose the paper's title to reflect this challenge, having demonstrated multiple practical attacks.&lt;/p&gt;
    &lt;p&gt;Of course, in any properly configured deployment, this default key should be replaced with a unique, securely generated key before deployment.&lt;/p&gt;
    &lt;p&gt;The risk to individual hotel guests is generally low for opportunistic attacks. These attacks require specialized equipment and technical knowledge. However, our research did demonstrate a successful credential forgery attack against a real hospitality system using a discarded room key.&lt;/p&gt;
    &lt;p&gt;Practical advice:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Don't leave your key card unattended for extended periods&lt;/item&gt;
      &lt;item&gt;Don't discard key cards in publicly accessible areas near the hotel&lt;/item&gt;
      &lt;item&gt;Report lost cards immediately so they can be deactivated&lt;/item&gt;
      &lt;item&gt;Use in-room safes and additional door locks when available&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Likely yes, to some degree. Our survey found that 100% of MIFARE Ultralight C systems examined were affected by one or more issues. The severity depends on your configuration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;High risk: Static keys shared across all cards, unlocked key memory pages, non-NXP compatible cards in your supply chain&lt;/item&gt;
      &lt;item&gt;Medium risk: Key diversification implemented but lock bytes not configured, CMAC not enabled on Ultralight AES&lt;/item&gt;
      &lt;item&gt;Lower risk: Proper key diversification, locked memory pages, verified genuine NXP chips, CMAC enabled (for Ultralight AES)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We strongly recommend auditing your deployment against the mitigations listed below.&lt;/p&gt;
    &lt;p&gt;Some transit systems use MIFARE Ultralight C for limited-use tickets. If your system uses static keys and doesn't lock key memory pages, it could be vulnerable to the multi-tag key recovery attack. However, transit systems often have backend validation that may limit the practical impact.&lt;/p&gt;
    &lt;p&gt;Systems using MIFARE DESFire or other more advanced technologies are not affected by this specific research.&lt;/p&gt;
    &lt;p&gt;Our sampling found that approximately 34% of cards from hospitality deployments were not genuine NXP products. Non-NXP compatible cards (like Giantec GT23SC4489 "ULCG", Feiju FJ8010, or USCUID-UL) have severely flawed random number generators that allow key recovery from a single card in under 60 seconds.&lt;/p&gt;
    &lt;p&gt;How to check:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use &lt;code&gt;hf mfu info&lt;/code&gt;from the latest Proxmark3 firmware, which integrates fingerprinting for all counterfeit cards mentioned in the paper&lt;/item&gt;
      &lt;item&gt;ULCG cards can be quickly identified by their UID suffix ending in &lt;code&gt;1589&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;See details in our paper and other fingerprinting tools available in our GitHub repository for deeper inspection&lt;/item&gt;
      &lt;item&gt;Audit your supply chain and verify card sources&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIFARE DESFire: Not affected by this research. DESFire provides end-to-end encrypted sessions with integrity protection and is recommended as an upgrade path.&lt;/p&gt;
    &lt;p&gt;MIFARE Classic and MIFARE Plus: Not in scope for this paper, but MIFARE Classic has its own well-documented vulnerabilities (Crypto1 weaknesses) which are mitigated in MIFARE Plus, provided it is properly configured.&lt;/p&gt;
    &lt;p&gt;ICODE DNA, UCODE DNA, NTAG 424 DNA: We examined these briefly. NTAG 424 DNA appears to require authentication before key modification, which mitigates the partial key overwrite attack. See the full paper for details.&lt;/p&gt;
    &lt;p&gt;1. Audit your current deployment:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check if lock bytes are configured on key pages (Lock byte 3, bit 7 for Ultralight C)&lt;/item&gt;
      &lt;item&gt;Verify whether you're using static or diversified keys&lt;/item&gt;
      &lt;item&gt;Test sample cards for non-NXP compatible chips&lt;/item&gt;
      &lt;item&gt;For Ultralight AES: check if &lt;code&gt;SEC_MSG_ACT&lt;/code&gt;is enabled&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. For new card issuance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Implement key diversification using UID and a site-specific salt&lt;/item&gt;
      &lt;item&gt;Permanently lock key memory pages after personalization&lt;/item&gt;
      &lt;item&gt;Enable authentication attempt limits where available&lt;/item&gt;
      &lt;item&gt;Verify genuine NXP chips before deployment&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;3. For existing deployments with static keys:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If key pages can still be locked, do so immediately&lt;/item&gt;
      &lt;item&gt;Plan migration to diversified keys or more secure technology&lt;/item&gt;
      &lt;item&gt;Implement additional backend validation where possible&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Partially. If the key memory pages and configuration bytes are not yet locked, you can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lock the key pages to prevent the partial key overwrite attack&lt;/item&gt;
      &lt;item&gt;Enable &lt;code&gt;AUTH_LIM&lt;/code&gt;on Ultralight AES to limit brute-force attempts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However: If you're using static keys across your deployment, locking the pages only prevents new attacks√¢it doesn't change the fact that an attacker with enough cards could still recover the key through other means. Migration to diversified keys is the proper long-term solution.&lt;/p&gt;
    &lt;p&gt;For non-NXP compatible cards: These cannot be meaningfully secured and should be replaced with genuine NXP products.&lt;/p&gt;
    &lt;p&gt;For applications requiring higher security assurance, we recommend migrating to MIFARE DESFire EV3 or similar advanced contactless smart card technologies. These provide:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;End-to-end encrypted communication sessions&lt;/item&gt;
      &lt;item&gt;Mandatory integrity protection (not optional)&lt;/item&gt;
      &lt;item&gt;Hardware-level countermeasures against tearing and manipulation&lt;/item&gt;
      &lt;item&gt;Secure key storage with proper atomicity guarantees&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While Ultralight AES is an improvement over Ultralight C, its security still depends heavily on proper configuration, whereas DESFire provides stronger security by default.&lt;/p&gt;
    &lt;p&gt;MIFARE Ultralight C stores its 112-bit 2TDEA key across four 4-byte memory pages (pages 44-47). The tag's firmware doesn't enforce atomic writes across all four pages√¢each page can be written independently.&lt;/p&gt;
    &lt;p&gt;After gaining authenticated access via a relay attack, an attacker can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Overwrite three of the four key pages with known values (e.g., zeros)&lt;/item&gt;
      &lt;item&gt;Brute-force the remaining 28 bits (~228 possibilities)&lt;/item&gt;
      &lt;item&gt;Repeat on different tags, targeting different key quarters each time&lt;/item&gt;
      &lt;item&gt;Combine the four recovered segments to reconstruct the full key&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This reduces the attack complexity from 2112 to roughly 4 √É 228, making it feasible with modest hardware.&lt;/p&gt;
    &lt;p&gt;The mutual authentication in Ultralight C does work correctly√¢both the reader and tag prove they know the shared secret. The problem is what happens after authentication.&lt;/p&gt;
    &lt;p&gt;Unlike MIFARE DESFire, Ultralight C has no post-authentication integrity protection. All commands after authentication are sent in plaintext without any MAC or encryption. An attacker who relays the authentication exchange can then inject their own commands to the now-authenticated tag.&lt;/p&gt;
    &lt;p&gt;Crucially, the tag has no timing constraints√¢it will wait indefinitely for the reader's response during authentication, eliminating the tight timing windows that normally make relay attacks difficult.&lt;/p&gt;
    &lt;p&gt;The attacks can be performed with relatively inexpensive, commercially available hardware:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Relay attack: Two Flipper Zero devices communicating over 433 MHz, or Proxmark3 devices&lt;/item&gt;
      &lt;item&gt;Online brute-force: Proxmark3 or Flipper Zero (~100 auth attempts/second)&lt;/item&gt;
      &lt;item&gt;Offline computation: Standard laptop (for non-NXP cards) or GPU cluster (for 2-tag variant on genuine cards)&lt;/item&gt;
      &lt;item&gt;Tearing attacks: Proxmark3 with precise timing, or even Flipper Zero with busy-loop timing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Total equipment cost is well under $500, and the techniques are within reach of moderately skilled attackers.&lt;/p&gt;
    &lt;p&gt;All tools and scripts are available on GitHub at github.com/zc-public/breakme-resources. Relevant code has also been contributed to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Proxmark3 firmware repository&lt;/item&gt;
      &lt;item&gt;Flipper Zero firmware (version 1.4.0+)&lt;/item&gt;
      &lt;item&gt;ChameleonUltra firmware&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The tools include key recovery scripts, fingerprinting utilities, and optimized brute-force implementations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mitigations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable CMAC integrity verification on all AES-protected communications (SEC_MSG_ACT for Ultralight AES)&lt;/item&gt;
      &lt;item&gt;Implement key diversification using card UID and a site-specific key or salt as input to a secure KDF&lt;/item&gt;
      &lt;item&gt;Lock critical memory pages including key pages, AUTH0, and configuration bytes to prevent modification&lt;/item&gt;
      &lt;item&gt;Enable authentication attempt counters (AUTH_LIM) where available and lock the configuration&lt;/item&gt;
      &lt;item&gt;Verify supply chain integrity and replace non-NXP compatible cards with genuine NXP products where security is required&lt;/item&gt;
      &lt;item&gt;Store CMAC over critical data including UID and hardware counters for technologies without secure messaging&lt;/item&gt;
      &lt;item&gt;Consider migration to MIFARE DESFire EV3 or similar technologies with end-to-end encryption and hardware-level countermeasures&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Disclosure Timeline&lt;/head&gt;
    &lt;head rend="h2"&gt;Resources&lt;/head&gt;
    &lt;p&gt;The full technical paper is available on ePrint. Proof-of-concept tools and supporting materials are published on GitHub, with relevant code contributed to the Proxmark3, Flipper Zero, and ChameleonUltra firmware repositories.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.breakmeifyoucan.com/"/><published>2026-01-29T14:20:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46810828</id><title>Run Clawdbot/Moltbot on Cloudflare with Moltworker</title><updated>2026-01-29T19:07:03.368258+00:00</updated><content>&lt;doc fingerprint="bd02981209b71cce"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;The Internet woke up this week to a flood of people buying Mac minis to run Moltbot (formerly Clawdbot), an open-source, self-hosted AI agent designed to act as a personal assistant. Moltbot runs in the background on a user's own hardware, has a sizable and growing list of integrations for chat applications, AI models, and other popular tools, and can be controlled remotely. Moltbot can help you with your finances, social media, organize your day √¢ all through your favorite messaging app.&lt;/p&gt;
      &lt;p&gt;But what if you don√¢t want to buy new dedicated hardware? And what if you could still run your Moltbot efficiently and securely online? Meet Moltworker, a middleware Worker and adapted scripts that allows running Moltbot on Cloudflare's Sandbox SDK and our Developer Platform APIs.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;A personal assistant on Cloudflare √¢ how does that work?√Ç &lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Firstly, Cloudflare Workers has never been so compatible with Node.js. Where in the past we√Ç had to mock APIs to get some packages running, now those APIs are supported natively by the Workers Runtime.&lt;/p&gt;
      &lt;p&gt;This has changed how we can build tools on Cloudflare Workers. When we first implemented Playwright, a popular framework for web testing and automation that runs on Browser Rendering, we had to rely on memfs. This was bad because not only is memfs a hack and an external dependency, but it also forced us to drift away from the official Playwright codebase. Thankfully, with more Node.js compatibility, we were able to start using node:fs natively, reducing complexity and maintainability, which makes upgrades to the latest versions of Playwright easy to do.&lt;/p&gt;
      &lt;p&gt;The list of Node.js APIs we support natively keeps growing. The blog post √¢A year of improving Node.js compatibility in Cloudflare Workers√¢ provides an overview of where we are and what we√¢re doing.&lt;/p&gt;
      &lt;p&gt;We measure this progress, too. We recently ran an experiment where we took the 1,000 most popular NPM packages, installed and let AI loose, to try to run them in Cloudflare Workers, Ralph Wiggum as a "software engineer" style, and the results were surprisingly good. Excluding the packages that are build tools, CLI tools or browser-only and don√¢t apply, only 15 packages genuinely didn√¢t work. That's 1.5%.&lt;/p&gt;
      &lt;p&gt;Here√¢s a graphic of our Node.js API support over time:&lt;/p&gt;
      &lt;p&gt;We put together a page with the results of our internal experiment on npm packages support here, so you can check for yourself.&lt;/p&gt;
      &lt;p&gt;Moltbot doesn√¢t necessarily require a lot of Workers Node.js compatibility because most of the code runs in a container anyway, but we thought it would be important to highlight how far we got supporting so many packages using native APIs. This is because when starting a new AI agent application from scratch, we can actually run a lot of the logic in Workers, closer to the user.&lt;/p&gt;
      &lt;p&gt;The other important part of the story is that the list of products and APIs on our Developer Platform has grown to the point where anyone can build and run any kind of application √¢ even the most complex and demanding ones √¢ on Cloudflare. And once launched, every application running on our Developer Platform immediately benefits from our secure and scalable global network.&lt;/p&gt;
      &lt;p&gt;Those products and services gave us the ingredients we needed to get started. First, we now have Sandboxes, where you can run untrusted code securely in isolated environments, providing a place to run the service. Next, we now have Browser Rendering, where you can programmatically control and interact with headless browser instances. And finally, R2, where you can store objects persistently. With those building blocks available, we could begin work on adapting Moltbot.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;How we adapted Moltbot to run on us&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Moltbot on Workers, or Moltworker, is a combination of an entrypoint Worker that acts as an API router and a proxy between our APIs and the isolated environment, both protected by Cloudflare Access. It also provides an administration UI and connects to the Sandbox container where the standard Moltbot Gateway runtime and its integrations are running, using R2 for persistent storage.&lt;/p&gt;
      &lt;p&gt;High-level architecture diagram of Moltworker.&lt;/p&gt;
      &lt;p&gt;Let's dive in more.&lt;/p&gt;
      &lt;p&gt;Cloudflare AI Gateway acts as a proxy between your AI applications and any popular AI provider, and gives our customers centralized visibility and control over the requests going through.&lt;/p&gt;
      &lt;p&gt;Recently we announced support for Bring Your Own Key (BYOK), where instead of passing your provider secrets in plain text with every request, we centrally manage the secrets for you and can use them with your gateway configuration.&lt;/p&gt;
      &lt;p&gt;An even better option where you don√¢t have to manage AI providers' secrets at all end-to-end is to use Unified Billing. In this case you top up your account with credits and use AI Gateway with any of the supported providers directly, Cloudflare gets charged, and we will deduct credits from your account.&lt;/p&gt;
      &lt;p&gt;To make Moltbot use AI Gateway, first we create a new gateway instance, then we enable the Anthropic provider for it, then we either add our Claude key or purchase credits to use Unified Billing, and then all we need to do is set the ANTHROPIC_BASE_URL environment variable so Moltbot uses the AI Gateway endpoint. That√¢s it, no code changes necessary.&lt;/p&gt;
      &lt;p&gt;Once Moltbot starts using AI Gateway, you√¢ll have full visibility on costs and have access to logs and analytics that will help you understand how your AI agent is using the AI providers.&lt;/p&gt;
      &lt;p&gt;Note that Anthropic is one option; Moltbot supports other AI providers and so does AI Gateway. The advantage of using AI Gateway is that if a better model comes along from any provider, you don√¢t have to swap keys in your AI Agent configuration and redeploy √¢ you can simply switch the model in your gateway configuration. And more, you specify model or provider fallbacks to handle request failures and ensure reliability.&lt;/p&gt;
      &lt;p&gt;Last year we anticipated the growing need for AI agents to run untrusted code securely in isolated environments, and we announced the Sandbox SDK. This SDK is built on top of Cloudflare Containers, but it provides a simple API for executing commands, managing files, running background processes, and exposing services √¢ all from your Workers applications.&lt;/p&gt;
      &lt;p&gt;In short, instead of having to deal with the lower-level Container APIs, the Sandbox SDK gives you developer-friendly APIs for secure code execution and handles the complexity of container lifecycle, networking, file systems, and process management √¢ letting you focus on building your application logic with just a few lines of TypeScript. Here√¢s an example:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;import { getSandbox } from '@cloudflare/sandbox';
export { Sandbox } from '@cloudflare/sandbox';

export default {
  async fetch(request: Request, env: Env): Promise&amp;lt;Response&amp;gt; {
    const sandbox = getSandbox(env.Sandbox, 'user-123');

    // Create a project structure
    await sandbox.mkdir('/workspace/project/src', { recursive: true });

    // Check node version
    const version = await sandbox.exec('node -v');

    // Run some python code
    const ctx = await sandbox.createCodeContext({ language: 'python' });
    await sandbox.runCode('import math; radius = 5', { context: ctx });
    const result = await sandbox.runCode('math.pi * radius ** 2', { context: ctx });

    return Response.json({ version, result });
  }
};&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This fits like a glove for Moltbot. Instead of running Docker in your local Mac mini, we run Docker on Containers, use the Sandbox SDK to issue commands into the isolated environment and use callbacks to our entrypoint Worker, effectively establishing a two-way communication channel between the two systems.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;R2 for persistent storage&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;The good thing about running things in your local computer or VPS is you get persistent storage for free. Containers, however, are inherently ephemeral, meaning data generated within them is lost upon deletion. Fear not, though √¢ the Sandbox SDK provides the sandbox.mountBucket() that you can use to automatically, well, mount your R2 bucket as a filesystem partition when the container starts.&lt;/p&gt;
      &lt;p&gt;Once we have a local directory that is guaranteed to survive the container lifecycle, we can use that for Moltbot to store session memory files, conversations and other assets that are required to persist.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Browser Rendering for browser automation&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;AI agents rely heavily on browsing the sometimes not-so-structured web. Moltbot utilizes dedicated Chromium instances to perform actions, navigate the web, fill out forms, take snapshots, and handle tasks that require a web browser. Sure, we can run Chromium on Sandboxes too, but what if we could simplify and use an API instead?&lt;/p&gt;
      &lt;p&gt;With Cloudflare√¢s Browser Rendering, you can programmatically control and interact with headless browser instances running at scale in our edge network. We support Puppeteer, Stagehand, Playwright and other popular packages so that developers can onboard with minimal code changes. We even support MCP for AI.&lt;/p&gt;
      &lt;p&gt;In order to get Browser Rendering to work with Moltbot we do two things:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;First we create a thin CDP proxy (CDP is the protocol that allows instrumenting Chromium-based browsers) from the Sandbox container to the Moltbot Worker, back to Browser Rendering using the Puppeteer APIs.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Then we inject a Browser Rendering skill into the runtime when the Sandbox starts.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;From the Moltbot runtime perspective, it has a local CDP port it can connect to and perform browser tasks.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Zero Trust Access for authentication policies&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Next up we want to protect our APIs and Admin UI from unauthorized access. Doing authentication from scratch is hard, and is typically the kind of wheel you don√¢t want to reinvent or have to deal with. Zero Trust Access makes it incredibly easy to protect your application by defining specific policies and login methods for the endpoints.√Ç &lt;/p&gt;
      &lt;p&gt;Zero Trust Access Login methods configuration for the Moltworker application.&lt;/p&gt;
      &lt;p&gt;Once the endpoints are protected, Cloudflare will handle authentication for you and automatically include a JWT token with every request to your origin endpoints. You can then validate that JWT for extra protection, to ensure that the request came from Access and not a malicious third party.&lt;/p&gt;
      &lt;p&gt;Like with AI Gateway, once all your APIs are behind Access you get great observability on who the users are and what they are doing with your Moltbot instance.&lt;/p&gt;
      &lt;p&gt;Demo time. We√¢ve put up a Slack instance where we could play with our own instance of Moltbot on Workers. Here are some of the fun things we√¢ve done with it.&lt;/p&gt;
      &lt;p&gt;We hate bad news.&lt;/p&gt;
      &lt;p&gt;Here√¢s a chat session where we ask Moltbot to find the shortest route between Cloudflare in London and Cloudflare in Lisbon using Google Maps and take a screenshot in a Slack channel. It goes through a sequence of steps using Browser Rendering to navigate Google Maps and does a pretty good job at it. Also look at Moltbot√¢s memory in action when we ask him the second time.&lt;/p&gt;
      &lt;p&gt;We√¢re in the mood for some Asian food today, let√¢s get Moltbot to work for help.&lt;/p&gt;
      &lt;p&gt;We eat with our eyes too.&lt;/p&gt;
      &lt;p&gt;Let√¢s get more creative and ask Moltbot to create a video where it browses our developer documentation. As you can see, it downloads and runs ffmpeg to generate the video out of the frames it captured in the browser.&lt;/p&gt;
      &lt;p&gt;We open-sourced our implementation and made it available at https://github.com/cloudflare/moltworker, so you can deploy and run your own Moltbot on top of Workers today.&lt;/p&gt;
      &lt;p&gt;The README guides you through the necessary steps to set up everything. You will need a Cloudflare account and a minimum $5 USD Workers paid plan subscription to use Sandbox Containers, but all the other products are either free to use, like AI Gateway, or have generous free tiers you can use to get you started and run for as long as you want under reasonable limits.&lt;/p&gt;
      &lt;p&gt;Note that Moltworker is a proof of concept, not a Cloudflare product. Our goal is to showcase some of the most exciting features of our Developer Platform that can be used to run AI agents and unsupervised code efficiently and securely, and get great observability while taking advantage of our global network.&lt;/p&gt;
      &lt;p&gt;Feel free to contribute to or fork our GitHub repository; we will keep an eye on it for a while for support. We are also considering contributing upstream to the official project with Cloudflare skills in parallel.&lt;/p&gt;
      &lt;p&gt;We hope you enjoyed this experiment, and we were able to convince you that Cloudflare is the perfect place to run your AI applications and agents. We√¢ve been working relentlessly trying to anticipate the future and release features like the Agents SDK that you can use to build your first agent in minutes, Sandboxes where you can run arbitrary code in an isolated environment without the complications of the lifecycle of a container, and AI Search, Cloudflare√¢s managed vector-based search service, to name a few.&lt;/p&gt;
      &lt;p&gt;Cloudflare now offers a complete toolkit for AI development: inference, storage APIs, databases, durable execution for stateful workflows, and built-in AI capabilities. Together, these building blocks make it possible to build and run even the most demanding AI applications on our global edge network.&lt;/p&gt;
      &lt;p&gt;If you're excited about AI and want to help us build the next generation of products and APIs, we're hiring.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/moltworker-self-hosted-ai-agent/"/><published>2026-01-29T14:43:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46810904</id><title>How to Choose Colors for Your CLI Applications (2023)</title><updated>2026-01-29T19:07:02.779040+00:00</updated><content>&lt;doc fingerprint="66a2137707fca2cf"&gt;
  &lt;main&gt;
    &lt;p&gt;Let√¢s say you√¢re creating a CLI tool which has to display syntax highlighted source code. You begin by choosing some colors which look nice with your chosen terminal theme:&lt;/p&gt;
    &lt;p&gt;Nice! However, who knows if it√¢ll still look good for people who use a theme different to yours? It seems sensible to try out the defaults, at least. Let√¢s start with the macOS Terminal.app default theme:&lt;/p&gt;
    &lt;p&gt;Youch! It seems fair to try the Tango themes next, since those are the default on e.g. Ubuntu:&lt;/p&gt;
    &lt;p&gt;Hmm, better, but not by much. Finally, let√¢s try what is likely the most popular custom terminal theme ‚Äì Solarized:&lt;/p&gt;
    &lt;p&gt;Well then ‚Ä¶ Let√¢s take a look at each palette and investigate.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sorcerer&lt;/head&gt;
    &lt;p&gt;In Sorcerer, all colors are readable on the default background except for &lt;code&gt;black&lt;/code&gt;,
which is in fact darker than the background.
This is useful as the background color
for status bars and the like.
&lt;code&gt;white&lt;/code&gt; is the same color as
the default foreground,
and &lt;code&gt;brblack&lt;/code&gt; is a nice faded color.
Additionally, &lt;code&gt;brwhite&lt;/code&gt; is
even lighter than the foreground;
this allows for subtle emphasization
of important text
like error messages and titles.&lt;/p&gt;
    &lt;head rend="h2"&gt;Basic&lt;/head&gt;
    &lt;p&gt;The Basic themes are, well, horrendous. Really owning that 90s xterm look, it seems. &lt;code&gt;bryellow&lt;/code&gt; is unreadable in light mode
(check out that function name
from the code sample earlier),
while in dark mode
both &lt;code&gt;blue&lt;/code&gt; and &lt;code&gt;brblue&lt;/code&gt;
are totally illegible.&lt;/p&gt;
    &lt;p&gt;That leaves us with thirteen colors we can safely use:&lt;/p&gt;
    &lt;head rend="h2"&gt;Tango&lt;/head&gt;
    &lt;p&gt;In my opinion these did a lot better than Terminal.app√¢s Basic themes, but they are still far from perfect. &lt;code&gt;bryellow&lt;/code&gt; is again unreadable in the light theme,
and perhaps &lt;code&gt;brgreen&lt;/code&gt; is
a little difficult to see,
though it√¢s nothing that would
stop me from using &lt;code&gt;brgreen&lt;/code&gt;
in an application.&lt;/p&gt;
    &lt;p&gt;At this point you may have noticed how the greyscales ‚Äì &lt;code&gt;black&lt;/code&gt;, &lt;code&gt;brblack&lt;/code&gt;, &lt;code&gt;white&lt;/code&gt; &amp;amp; &lt;code&gt;brwhite&lt;/code&gt; ‚Äì
have remained consistent
between light and dark themes
for both Basic and Tango.
Of course,
this means that
&lt;code&gt;{,br}white&lt;/code&gt; is unreadable in Tango Light
(owing to the light background)
and &lt;code&gt;black&lt;/code&gt; is unreadable in Tango Dark
(owing to the dark background).&lt;/p&gt;
    &lt;p&gt;In other words: forget about that idea of mine from earlier about using &lt;code&gt;brwhite&lt;/code&gt; to emphasize content.
Unless, of course,
you don√¢t mind if your
eminently emphasized words
are completely unreadable
for the user of your software
who deigns to use the default light theme
of A Popular Linux Distro.&lt;/p&gt;
    &lt;p&gt;On the other hand, using &lt;code&gt;brblack&lt;/code&gt; to de-emphasize content
still seems fine to me.
I suppose some extra contrast
for &lt;code&gt;brblack&lt;/code&gt; in Tango Dark
would be nice,
but with text which is meant to be ignored
I don√¢t think this matters much.&lt;/p&gt;
    &lt;p&gt;And lo, but ten colors remain.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solarized&lt;/head&gt;
    &lt;p&gt;Solarized is a curious beast. Every color in it was chosen using L*a*b*, a perceptually-uniform color space from the 1970s. (For what it√¢s worth, color science has progressed significantly since then; the only reason Ethan Schoonover used L*a*b* is that it√¢s commonly used in photography, and he used to be a professional photographer.)&lt;/p&gt;
    &lt;p&gt;Its lightnesses are perfectly symmetrical so that Solarized Light and Dark can share a set of accent colors while maintaining identical contrast. Moreover, the warm tones of the light theme and cool tones of the dark theme are complementary. (The hue gap is closer to 150√Ç¬∞ than 180√Ç¬∞ in reality. See here and here to compare hue values.)&lt;/p&gt;
    &lt;p&gt;Solarized is also incredibly popular. I have no data here, but as of the date of writing it√¢s the most starred theme repository on GitHub I can find. Solarized has 15.4 thousand stars at the moment, while the next-closest is Gruvbox with 11.8 thousand. Solarized is available as a plugin or sometimes even as a built-in preset in damn near every popular terminal emulator and editor on the planet.&lt;/p&gt;
    &lt;p&gt;To understand Solarized√¢s peculiar arrangement of the 16-color palette, we have to travel back in time to 2011 when Solarized was first released. In this dark era, terminals supporting 24-bit color didn√¢t exist / weren√¢t widespread. One option common among Vim themes at the time was to round every color to the nearest 256-color palette value. In Solarized√¢s case, this destroys the mathematical symmetry at the heart of the theme. (I√¢m not kidding, it looks awful.)&lt;/p&gt;
    &lt;p&gt;The solution ‚Äì rather, hack ‚Äì chosen at the time was to distill all the colors used in the Vim interface down to a palette of sixteen colors. Conveniently, Solarized√¢s accent colors fit nicely into the non-bright column of the 16-color palette, while Solarized√¢s monotones fit into the bright column. Once the user sets their terminal to use the Solarized palette, Vim can color its entire interface using only the 16-color palette and get correct color values, no clunky color approximations needed.&lt;/p&gt;
    &lt;p&gt;The downside to all this is that an application which uses any of the bright colors which Solarized co-opted for itself will look strange. Users of Solarized ‚Äì and, by god, there√¢s so many of them ‚Äì appear frequently on issue trackers asking why command-line output is inexplicably gray or even invisible as a result of CLIs using these forsaken bright colors.&lt;/p&gt;
    &lt;p&gt;Our beloved &lt;code&gt;brblack&lt;/code&gt;
is unreadable in Solarized Dark,
so we√¢ll have to strike it from the table
in addition to the affected bright colors.&lt;/p&gt;
    &lt;head rend="h2"&gt;A sad note about bold&lt;/head&gt;
    &lt;p&gt;Far back in the past, there was no way for terminals to display bright colors. As a workaround, manufacturers (we√¢re talking about physical terminals here) started making all bold text bright instead of using a heavier font weight. One way or another this ended up in the default settings of many modern terminal emulators (in spite of not being in the standard), meaning that regular colorful text made bold can become bright too, depending on the user√¢s configuration.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;And so, I present to you the final version of our table of acceptable colors:&lt;/p&gt;
    &lt;p&gt;Bold: √¢√¢ boldblack √¢√¢ boldbrblack √¢√¢ boldred √¢√¢ boldbrred √¢√¢ boldgreen √¢√¢ boldbrgreen √¢√¢ boldyellow √¢√¢ boldbryellow √¢√¢ boldblue √¢√¢ boldbrblue √¢√¢ boldmagenta √¢√¢ boldbrmagenta √¢√¢ boldcyan √¢√¢ boldbrcyan √¢√¢ boldwhite √¢√¢ boldbrwhite % √¢&lt;/p&gt;
    &lt;p&gt;Only eleven out of our thirty-two possible color settings are permissible, given that we want applications to remain readable for as many people as we can.&lt;/p&gt;
    &lt;p&gt;If you√¢re developing a command-line tool which will be used by anyone apart from yourself, I strongly recommend you limit your use of color to the ones I√¢ve identified here as being √¢mostly alright√¢ and √¢not unreadable in a common configuration used by tons of people√¢.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix&lt;/head&gt;
    &lt;p&gt;You probably didn√¢t notice, but I styled the √¢terminal windows√¢ in this post to look as similar as possible to macOS Terminal.app windows through painstaking color picking and pixel counting.&lt;/p&gt;
    &lt;p&gt;The dimensions in each window√¢s titlebar matches as closely as I can with its actual dimensions on-screen.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;colortest&lt;/code&gt; and &lt;code&gt;highlight&lt;/code&gt; utilities
are entirely fictional.&lt;/p&gt;
    &lt;p&gt;Terminal.app doesn√¢t actually provide individual access to the light and dark variants of Basic; they appear as a single theme, which switches seamlessly when the OS theme changes. As far as I know, this reactive functionality isn√¢t exposed to any other theme, whether pre-installed or user-created. In order to capture this, I made the terminal windows in this post react to whether the rest of the site is in light or dark mode, except for the Basic windows. They remain fixed in either light or dark mode, since in real life you√¢ll never see, for example, a light Basic terminal with dark window chrome.&lt;/p&gt;
    &lt;p&gt;Luna Razzaghipour&lt;lb/&gt;29 January 2023&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.xoria.org/terminal-colors/"/><published>2026-01-29T14:49:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46811588</id><title>OTelBench: AI struggles with simple SRE tasks (Opus 4.5 scores only 29%)</title><updated>2026-01-29T19:07:02.412792+00:00</updated><content>&lt;doc fingerprint="3f5885f907369ecf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Benchmarking OpenTelemetry: Can AI trace your failed login?&lt;/head&gt;
    &lt;p&gt;Now on the front page of Hacker News ‚Äî see the discussion.&lt;/p&gt;
    &lt;p&gt;Frontier AI models have become excellent at writing functions, but can they actually debug production systems?&lt;/p&gt;
    &lt;p&gt;To fix outages, you first need to see what‚Äôs happening. In a microservices world, this means producing structured events that track a single request as it hops from service to service.&lt;/p&gt;
    &lt;p&gt;We asked 14 models to add distributed traces to existing codebases, using the standard method: OpenTelemetry instrumentation. We picked tasks that would be easy for a Site Reliability Engineer (SRE).&lt;/p&gt;
    &lt;p&gt;We are releasing OTelBench as an open-source benchmark, with all tasks in QuesmaOrg/otel-bench. We use the Harbor framework (by the creators of TerminalBench), so you can easily run it yourself to reproduce results, test new models, or create benchmarks for your own use cases (we welcome contributions!).&lt;/p&gt;
    &lt;head rend="h2"&gt;Background: What is distributed tracing?&lt;/head&gt;
    &lt;p&gt;When an app runs on a single machine, you can often trace an error by scrolling through a log file. But when it runs across 50 microservices, that single request gets scattered into a chaotic firehose of disconnected events. Distributed tracing solves this by linking them back together, allowing you to follow a user action, like clicking Login, as it jumps from the API Gateway, to the Auth Service, to the Database, and back.&lt;/p&gt;
    &lt;p&gt;To make this work, you need instrumentation. This is code that you add to your app to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Start a trace when a request comes in.&lt;/item&gt;
      &lt;item&gt;Pass the TraceID (context) when your app calls another service.&lt;/item&gt;
      &lt;item&gt;Send the data to a backend so you can see the graph.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;OpenTelemetry (OTel) is the industry standard for telemetry data. Its ecosystem includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Semantic conventions: A unified schema replaces chaotic naming (e.g., &lt;code&gt;ip_address&lt;/code&gt;vs&lt;code&gt;host.ip&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Universal SDKs: Official libraries support every major programming language.&lt;/item&gt;
      &lt;item&gt;The Collector: A centralized agent processes and enriches data (e.g., adding Kubernetes tags) before export.&lt;/item&gt;
      &lt;item&gt;Auto-instrumentation: Runtime agents inject code to wrap calls, though this often results in noisy data.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, standard doesn‚Äôt mean easy. We know this firsthand from our contributions to the ecosystem, such as Go compile-time instrumentation. The process may be difficult, especially due to complexity, as 39% of respondents complained in the 2025 Observability Survey.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarking OpenTelemetry instrumentation&lt;/head&gt;
    &lt;p&gt;We tested 14 frontier LLMs on 23 realistic OpenTelemetry instrumentation tasks across 11 programming languages: Go, Java, C++, Python, JavaScript, PHP, Ruby, Rust, Erlang, .NET, and Swift.&lt;/p&gt;
    &lt;p&gt;It is essential to benchmark various technologies since realistic distributed systems are polyglot. To make OpenTelemetry work, the system needs to work for all of these services - if we lose track at only one service, the chain of logs gets broken.&lt;/p&gt;
    &lt;p&gt;The final benchmark run cost $522 in LLM tokens across 966 runs (23 tasks √ó 3 attempts √ó 14 models).&lt;/p&gt;
    &lt;head rend="h3"&gt;Task&lt;/head&gt;
    &lt;p&gt;We start with basic tasks such as adding instrumentation to a single microservice, in a single language. The AI agents get a small microservice with around 300 lines of code from a realistic application, and work in a Linux terminal, editing it, and running any commands if needed.&lt;/p&gt;
    &lt;p&gt;For example, here is the prompt for go-microservices-traces:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Your task is: Add OTEL tracing to all microservices.&lt;/p&gt;
      &lt;p&gt;Requirements:&lt;/p&gt;
      &lt;item&gt;Instrumentation should match conventions and well-known good practices.&lt;/item&gt;
      &lt;item&gt;Instrumentation must match the business domain of the microservices.&lt;/item&gt;
      &lt;item&gt;Traces must be sent to the endpoint defined by a standard OTEL environment variable.&lt;/item&gt;
      &lt;item&gt;Use the recent version of the OTEL SDK.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;We tested if it satisfies the basic criteria of OpenTelemetry instrumentation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Example&lt;/head&gt;
    &lt;p&gt;How do LLMs fail? Let‚Äôs analyze a common failure mode.&lt;/p&gt;
    &lt;p&gt;Consider a web service from our benchmark where a user searches and retrieves results. The test simulates two distinct user actions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Happy path: User searches, gets a token, retrieves results successfully&lt;/item&gt;
      &lt;item&gt;Error test: User tries to retrieve results with an invalid token (gets 404)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A human engineer would immediately distinguish these as two independent events, resulting in two separate traces: one for the successful search and one for the failed request.&lt;/p&gt;
    &lt;p&gt;The code structure makes this clear ‚Äì two separate blocks, each representing a user action:&lt;/p&gt;
    &lt;code&gt;// User Action 1: Search and get results (happy path)
{
    response := client.Post("/search", query)
    result := client.Get("/result?token=" + response.Token)
}

// User Action 2: Error test (invalid token)
{
    result := client.Get("/result?token=invalid")  // Should return 404
}&lt;/code&gt;
    &lt;p&gt;We would expect:&lt;/p&gt;
    &lt;p&gt;Yet, sometimes models failed to recognize these as separate user actions. Instead of two traces, they produced:&lt;/p&gt;
    &lt;p&gt;The core issue: Models apply instrumentation mechanically to every HTTP call without understanding the business context. They see ‚ÄúHTTP requests‚Äù and link them all together, rather than recognizing ‚Äúthese are two separate user journeys.‚Äù&lt;/p&gt;
    &lt;p&gt;The models successfully instrumented the HTTP calls, but failed to propagate the Context correctly. They treated the timeline as a single flat list of events rather than two distinct hierarchical trees.&lt;/p&gt;
    &lt;p&gt;Our tests don‚Äôt just check compilation. We verify correct span names, parent-child relationships, valid trace IDs, and context propagation. Many models produced compiling code that generated malformed traces ‚Äì proving that ‚Äúit builds‚Äù is not enough for SRE work.&lt;/p&gt;
    &lt;head rend="h2"&gt;Observations&lt;/head&gt;
    &lt;head rend="h3"&gt;Models&lt;/head&gt;
    &lt;p&gt;We were surprised that even the top models (as of Jan 2026) struggle. The tasks we proposed were trivial compared to real-world scenarios. In a typical SRE job, services are massive, legacy-ridden, and poorly documented. If models fail on 300 lines of clean Go code, they cannot handle production.&lt;/p&gt;
    &lt;p&gt;We were surprised that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claude Opus 4.5, the best model, got just 29% of these relatively simple tasks.&lt;/item&gt;
      &lt;item&gt;Gemini 3 Pro (which aces at general intelligence) didn‚Äôt have an edge over the much cheaper Gemini 3 Flash.&lt;/item&gt;
      &lt;item&gt;GPT 5.2 Codex was substantially worse than GPT 5.2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Languages&lt;/head&gt;
    &lt;p&gt;Each language has a different toolset, so it is not an apples-to-apples comparison. Our benchmark is too small to perform a comprehensive per-language comparison, yet even preliminary trends are striking.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cost and time efficiency&lt;/head&gt;
    &lt;p&gt;In every practical application, cost and speed matter. As of Jan 2026, the Pareto frontier consists of only four models, given model performance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;19%&lt;/code&gt;Gemini 3 Flash (cost and speed) - the cheapest and fastest model in this benchmark (11x cheaper and 2x faster than Claude Opus 4.5)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;22%&lt;/code&gt;Claude Sonnet 4.5 (speed)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;26%&lt;/code&gt;GPT 5.2 (cost)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;29%&lt;/code&gt;Claude Opus 4.5 (cost and speed) ‚Äî the best model in this benchmark, the most expensive but reasonably fast&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why OpenTelemetry instrumentation is hard for AI&lt;/head&gt;
    &lt;p&gt;OpenTelemetry has all the potential to be a perfect task for AI agents ‚Äî it is long and tedious work, requiring a lot of scrutiny, but ultimately one that has clear specifications and can be easily tested.&lt;/p&gt;
    &lt;p&gt;Yet, even the frontier models fail miserably.&lt;/p&gt;
    &lt;head rend="h3"&gt;It is a job, not a puzzle&lt;/head&gt;
    &lt;p&gt;Instrumentation of even a small service involves long-horizon tasks, which remain at the frontier of the current AI model progress. It requires diligently connecting all pieces of code and testing them correctly.&lt;/p&gt;
    &lt;head rend="h3"&gt;Requires polyglot backend development skills&lt;/head&gt;
    &lt;p&gt;Realistic services use multiple languages and technologies. It is not enough to know the concept of distributed tracing, the OpenTelemetry standard, or even the APIs of SDKs. The agent must know CMake for C++, module systems for Go, or dependency management for Java - things we tested in our previous benchmark, CompileBench.&lt;/p&gt;
    &lt;p&gt;Usually, cloud environments are mixtures of the newest versions of technologies (sometimes past the training cut-off dates of AI models) and legacy systems. We cannot cherry-pick or rewrite everything, since a possible outage would be too costly. We need to support all languages and frameworks used in the cloud.&lt;/p&gt;
    &lt;p&gt;A lot of current AI progress focuses on the most popular languages (Python and TypeScript) and reasonably modern frameworks and build systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Less training data&lt;/head&gt;
    &lt;p&gt;Although adding instrumentation is a standard engineering task, it is not common practice in open-source. The most popular applications, where reliability matters the most, are in private repositories of big tech companies such as Apple, Airbnb, or Netflix.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;head rend="h3"&gt;Key takeaways&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Best models struggle: The state-of-the-art Claude Opus 4.5 solved only 29% of tasks.&lt;/item&gt;
      &lt;item&gt;Language gaps: Models failed completely on Java, Ruby, and Swift. C++ led at 37% (boosted by an easier task), Go reached 20%.&lt;/item&gt;
      &lt;item&gt;Silent failures: Many solutions compiled correctly but produced malformed traces or conflated distinct user journeys.&lt;/item&gt;
      &lt;item&gt;Cost efficiency: Gemini 3 Flash exceeds Gemini 3 Pro‚Äôs performance (18%) at a fraction of the cost.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;AI SRE is still mostly hype, but there is hope&lt;/head&gt;
    &lt;p&gt;AI SRE in 2026 is what DevOps Anomaly Detection was in 2015 ‚Äî bold claims backed by huge marketing budgets, but lacking independent verification. There are stories of SaaS vendors abruptly killing the observability stack. Our results mirror ClickHouse‚Äôs findings: while LLMs can assist, they lack the capabilities of a skilled SRE.&lt;/p&gt;
    &lt;p&gt;Claude Opus 4.5, GPT-5.2, and Gemini 3 models show promising signals. Some hard tasks like go-microservices-traces reached 55% pass rate. With more environments for Reinforcement Learning with Verified Rewards, this looks like a solvable problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;Reliable software is incredibly economically valuable, but today it requires too much toil. No one wants to be woken up at 2 AM to troubleshoot.&lt;/p&gt;
    &lt;p&gt;We need a North Star to navigate the current AI boom. Just as SWE-Bench and TerminalBench2.0 became standards for software engineering, we need an SRE-style benchmark for distributed systems. Does the industry need newer models, or perhaps multi-agent systems? A good benchmark will tell us.&lt;/p&gt;
    &lt;p&gt;We invite you to explore the full results on OTelBench and help us expand the test suite on QuesmaOrg/otel-bench. Have you tried using LLMs for observability? We are curious to hear if your experience matches our findings‚Äîor if you‚Äôve found a workflow that actually works.&lt;/p&gt;
    &lt;p&gt;Join the discussion on Hacker News, Reddit or LinkedIn.&lt;/p&gt;
    &lt;p&gt;But for now, the verdict is clear: if you need distributed tracing across services, expect to write that code yourself.&lt;/p&gt;
    &lt;p&gt;Stay tuned for future posts and releases&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://quesma.com/blog/introducing-otel-bench/"/><published>2026-01-29T15:37:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46811664</id><title>Is the RAM shortage killing small VPS hosts?</title><updated>2026-01-29T19:07:01.665635+00:00</updated><content>&lt;doc fingerprint="3569d24bdf278f4d"&gt;
  &lt;main&gt;
    &lt;p&gt;It is no longer news that RAM prices are high.&lt;/p&gt;
    &lt;p&gt;The AI surge has DRAM producers like Micron focus on HBM (High Bandwidth Memory) to serve AI hyperscalers over the DRAM (Dynamic Random Access Memory) used by ordinary consumers and small businesses. Consequently, for instance, servers which used to cost $2500 on Newegg now cost $5000. RAM alone is $2500 now.&lt;/p&gt;
    &lt;p&gt;While most headlines focus on the DIY PC building community, less is said about small VPS (Virtual Private Server) hosts like mine. If we continue to focus on AI at all costs, small VPS Hosting businesses like mine might die out the way small ISPs died in the 2000s because of Big Telecom lobbying.&lt;/p&gt;
    &lt;p&gt;So why should we care?&lt;/p&gt;
    &lt;head rend="h1"&gt;What the 2000s taught us&lt;/head&gt;
    &lt;p&gt;During the 90s internet boom, many dial-up ISPs (Internet Service Provider) popped up. These ISPs used voice lines from the local phone company, which, in the US, were mostly ‚ÄúBaby Bell‚Äù firms such as SBC (now AT&amp;amp;T) or Bell Atlantic (now Verizon).&lt;/p&gt;
    &lt;p&gt;When the shift from dial-up to broadband started to be incorporated by the Baby Bells, Bill Clinton‚Äôs FCC mandated in 2000 that the Bell firms had to lease out their copper DSL (Digital Subscriber Line) wires to other ISPs for a nominal fee, also known as ‚Äúunbundling.‚Äù This made sense in the US since taxpayer dollars were used to build those very Bell networks. Regulators in other countries also did the same. This prevented a phone or cable company from being a monopoly.&lt;/p&gt;
    &lt;p&gt;While unbundling survived in Europe, the subsequent FCC took a different path: one which ultimately killed 7000 rival ISPs, raised prices, and hurt Net Neutrality a decade later.&lt;/p&gt;
    &lt;p&gt;Line sharing between Bells and ISPs was never fair to the latter. Small ISPs were forced to charge higher prices than cable and phone companies due to high line fees. But instead of leveling the playing field, thanks to heavy lobbying from Bell firms, the Bush FCC reversed Clinton‚Äôs decision and allowed Bell companies to not share their DSL or fiber networks.&lt;/p&gt;
    &lt;p&gt;However, cable companies like Comcast never had to share their networks, despite having become near-monopolies a decade later. But, unlike Bell networks, cable networks were privately funded. Bell firms, however, refused to upgrade their lines during this period despite promising better fiber networks if sharing was killed, due to the wireless boom. It‚Äôs only the recent fiber and 5G spurt which broke cable‚Äôs monopoly.&lt;/p&gt;
    &lt;p&gt;While rival DSL ISPs could build their own networks, as Sonic in California has done, many more exited broadband and became Microsoft partners. They lacked the know-how, or funding, for building fiber. And, even if they had the know-how and funding, they wouldn‚Äôt stand a chance against Big Telecom lobbyists.&lt;/p&gt;
    &lt;p&gt;Worse yet, despite flip flopping on Net Neutrality, subsequent FCCs from both parties institutionalized Bush‚Äôs abandonment of line sharing since the firms needing line sharing went out of business or pivoted.&lt;/p&gt;
    &lt;head rend="h1"&gt;How this compares to VPS hosts today&lt;/head&gt;
    &lt;p&gt;Yes, the 2000s are back for fashion and music, but I really hope the death of mom-and-pop tech providers stays in the noughties.&lt;/p&gt;
    &lt;p&gt;However, today‚Äôs scenario is different from the dot-com era:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bell companies legally had to share their lines, but now DRAM producers don‚Äôt legally have to produce DRAM.&lt;/item&gt;
      &lt;item&gt;Line sharing wasn‚Äôt essential for modern tech. DRAM is.&lt;/item&gt;
      &lt;item&gt;Bell companies intentionally killed small DSL ISPs. DRAM companies might unintentionally hurt small VPS hosts because of their focus on Big Tech.&lt;/item&gt;
      &lt;item&gt;DSL ISPs used ‚Äúunbundled network elements‚Äù which Bell companies would not provide on their own. VPS hosts use standard servers and services like colocation, also used by other industries such as banks, airlines, et al.&lt;/item&gt;
      &lt;item&gt;Network unbundling is controversial. While I favor this approach, many don‚Äôt for legitimate reasons.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Despite this, telecom companies made a bet on only retail ISP customers and got what they wanted. And it forced broadband customers onto one-size-fits-all solutions instead of also having specialty providers. This could also happen to VPS hosting.&lt;/p&gt;
    &lt;p&gt;AWS isn‚Äôt suited for everyone. For instance, media streaming, VPN, and Tor relays aren‚Äôt suited for big clouds due to high bandwidth costs. I personally run Tor relays, and there‚Äôs a reason why I never ran them on Azure when I worked for Microsoft. On my VPS host, I have 16. Other customers have even more.&lt;/p&gt;
    &lt;p&gt;Unlike DSL ISPs, many small VPS hosts will survive. Maybe at higher costs or a different focus. But if our industry dies out, it will hurt ordinary developers and sysadmins if the only options become pricey Big Tech clouds. A cash-strapped small business or college student will either have to avoid VPS hosting or use the subset they can afford.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.fourplex.net/2026/01/29/is-the-ram-shortage-killing-small-vps-hosts/"/><published>2026-01-29T15:42:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46811762</id><title>Heating homes with the largest particle accelerator</title><updated>2026-01-29T19:07:00.629182+00:00</updated><content>&lt;doc fingerprint="e1e269be6278f5b1"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt; What if the world‚Äôs largest particle accelerator could also heat homes? CERN‚Äôs Large Hadron Collider (LHC) is doing just that, thanks to a new heat exchange system. Since mid-January, heat recovered from the LHC has been supplying a heating network for a new residential and commercial area in the nearby French town of Ferney-Voltaire. This network, inaugurated on 12 December, is expected to supply the equivalent of several thousand homes. By avoiding traditional energy sources, such as gas, the network prevents the emission of thousands of tonnes of CO2.&lt;/p&gt;
    &lt;p&gt;The 27-km LHC has eight surface points and Point 8 is located close to Ferney-Voltaire. The installations at Point 8, particularly the cryogenics, need to be cooled with water. As water circulates through the equipment, the equipment cools and the water heats up. ‚ÄúTypically, hot water would then pass through a cooling tower, releasing heat into the atmosphere so that the cooled water could be reinjected into the equipment,‚Äù explains CERN‚Äôs energy coordinator, Nicolas Bellegarde. ‚ÄúIn the new set-up, hot water initially passes through two 5-MW heat exchangers, which transfer thermal energy to the new heating network in Ferney-Voltaire.‚Äù&lt;/p&gt;
    &lt;p&gt;As one of the new network‚Äôs heat sources, CERN provides heat whenever possible, as long as it does not impact its activities. At present, Ferney-Voltaire is only using up to 5 MW from CERN but, with two heat exchangers in the system, this could theoretically be doubled, especially when CERN‚Äôs accelerators are fully operational. In summer 2026, CERN will stop the LHC for several years of maintenance and upgrades, known as Long Shutdown 3 (LS3), to prepare for the upcoming High-Luminosity LHC. Some Point 8 installations will continue to be cooled, enabling CERN to supply between 1 and 5 MW to the network during LS3, with the exception of a total of five months spread over this multi-year period.&lt;/p&gt;
    &lt;p&gt;Driven by a commitment to environmentally responsible research, CERN has implemented many initiatives to help reduce the impact of its activities on the environment. Energy recovery is a key part of CERN‚Äôs energy management strategy, in line with ISO 50001 requirements, alongside keeping energy consumption to a minimum and improving energy efficiency. Other projects include CERN‚Äôs Pr√©vessin Data Centre, inaugurated in 2024, which is equipped with a heat-recovery system set to warm most site buildings from winter 2026/2027, and the future recovery of heat from LHC Point 1 cooling towers to supply buildings on CERN‚Äôs Meyrin site. Together, these initiatives will save 25‚Äì30 GWh per year as of 2027, marking significant progress in CERN‚Äôs responsible energy management.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://home.cern/news/news/cern/heating-homes-worlds-largest-particle-accelerator"/><published>2026-01-29T15:49:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46812159</id><title>Drug trio found to block tumour resistance in pancreatic cancer</title><updated>2026-01-29T19:06:59.879128+00:00</updated><content>&lt;doc fingerprint="f7c630393b87c3c8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Drug trio found to block tumour resistance in pancreatic cancer&lt;/head&gt;
    &lt;p&gt;Posted: 29 January 2026 | Drug Target Review | No comments yet&lt;/p&gt;
    &lt;p&gt;A new study reports that a triple-targeted drug combination can drive complete and lasting regression of pancreatic tumours in preclinical models, potentially overcoming treatment resistance in one of the deadliest cancers.&lt;/p&gt;
    &lt;p&gt;Researchers at the Spanish National Cancer Research Centre have announced a potential breakthrough combination therapy that induces complete regression of pancreatic tumours and prevents tumour resistance in preclinical models.&lt;/p&gt;
    &lt;p&gt;The study describes a targeted combination therapy that simultaneously targets three key signalling pathways in pancreatic ductal adenocarcinoma (PDAC), the most common and lethal type of pancreatic cancer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Triple inhibition strategy&lt;/head&gt;
    &lt;p&gt;Pancreatic cancer remains notoriously difficult to treat, with very poor survival rates and limited effective therapies. The new research aims to combat this by targeting RAF1, EGFR family receptors and STAT3 signalling ‚Äì nodes that are crucial for tumour growth and survival.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;lb/&gt; Automation now plays a central role in discovery. From self-driving laboratories to real-time bioprocessing&lt;/head&gt;
    &lt;p&gt;This report explores how data-driven systems improve reproducibility, speed decisions and make scale achievable across research and development.&lt;/p&gt;
    &lt;p&gt;Inside the report:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Advance discovery through miniaturised, high-throughput and animal-free systems&lt;/item&gt;
      &lt;item&gt;Integrate AI, robotics and analytics to speed decision-making&lt;/item&gt;
      &lt;item&gt;Streamline cell therapy and bioprocess QC for scale and compliance&lt;/item&gt;
      &lt;item&gt;And more!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This report unlocks perspectives that show how automation is changing the scale and quality of discovery. The result is faster insight, stronger data and better science ‚Äì access your free copy today&lt;/p&gt;
    &lt;p&gt;According to the authors, ‚Äúgenetic ablation of three independent nodes involved in downstream (RAF1), upstream (EGFR) and orthogonal (STAT3) KRAS signalling pathways leads to complete and permanent regression of orthotopic PDACs induced by KRAS/TP53 mutations.‚Äù&lt;/p&gt;
    &lt;p&gt;The triple treatment combines three drugs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RMC-6236 (daraxonrasib): targeting KRAS&lt;/item&gt;
      &lt;item&gt;Afatinib: an EGFR family inhibitor&lt;/item&gt;
      &lt;item&gt;SD36: a selective STAT3 degrader&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These agents together were tested in orthotopic mouse models of PDAC, where tumour cells are implanted in a location that closely resembles their natural environment in the pancreas. The results demonstrated the therapy not only reduced tumour size but also entirely stopped tumour growth with no evidence of tumour resistance for more than 200 days after treatment.&lt;/p&gt;
    &lt;head rend="h2"&gt;Broad efficacy in preclinical models&lt;/head&gt;
    &lt;p&gt;Researchers extended their observations beyond engineered mouse models. The combination therapy also led to significant regression in genetically engineered mouse tumours and in human cancer tissues grown in lab mice, known as patient-derived tumour xenografts (PDX).&lt;/p&gt;
    &lt;p&gt;These results should guide the development of new clinical trials that may benefit PDAC patients.&lt;/p&gt;
    &lt;p&gt;These powerful anti-tumour effects were achieved with a therapy that was well tolerated in the animals, which could provide a favourable safety profile for future clinical testing.&lt;/p&gt;
    &lt;p&gt;‚ÄúThese results should guide the development of new clinical trials that may benefit PDAC patients,‚Äù said the authors.&lt;/p&gt;
    &lt;head rend="h2"&gt;A step towards overcoming resistance&lt;/head&gt;
    &lt;p&gt;One of the most significant hurdles in targeted cancer therapies is the development of resistance. This new combination strategy appears to prevent this relapse, at least in preclinical models, by attacking multiple nodes of tumour signalling simultaneously.&lt;/p&gt;
    &lt;p&gt;According to commentary from scientists involved in the work: ‚ÄúOvercoming therapeutic resistance in PDAC requires coordinated inhibition of KRAS downstream (RAF1), upstream (EGFR) and parallel survival pathways (STAT3).‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Clinical implications&lt;/head&gt;
    &lt;p&gt;While more research will be needed before trials in humans can begin, these findings are an important advancement in the search for better pancreatic cancer therapies. By demonstrating complete and durable tumour regression without resistance in preclinical models, there is now strong potential for clinical development of multi-targeted approaches in the future.&lt;/p&gt;
    &lt;p&gt;Related topics&lt;lb/&gt;Animal Models, Cancer research, Disease Research, Drug Development, Drug Discovery, Drug Discovery Processes, Drug Targets, In Vivo, Molecular Targets, Oncology, Small molecule, Therapeutics, Translational Science&lt;/p&gt;
    &lt;p&gt;Related conditions&lt;lb/&gt;Pancreatic cancer&lt;/p&gt;
    &lt;p&gt;Related organisations&lt;lb/&gt;the Spanish National Cancer Research Centre&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.drugtargetreview.com/news/192714/drug-trio-found-to-block-tumour-resistance-in-pancreatic-cancer/"/><published>2026-01-29T16:11:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46812173</id><title>US cybersecurity chief leaked sensitive government files to ChatGPT: Report</title><updated>2026-01-29T19:06:59.625201+00:00</updated><content>&lt;doc fingerprint="2937ce14048341f7"&gt;
  &lt;main&gt;
    &lt;p&gt;The acting head of the US government‚Äôs top cybersecurity agency reportedly uploaded sensitive government files into a public version of ChatGPT, triggering internal security alerts and a federal review.&lt;/p&gt;
    &lt;p&gt;A Politico investigation claims Madhu Gottumukkala, the interim director of the Cybersecurity and Infrastructure Security Agency, uploaded contracting documents marked ‚ÄúFor Official Use Only‚Äù into ChatGPT last summer.&lt;/p&gt;
    &lt;p&gt;The report says Gottumukkala requested a special exemption to access ChatGPT, which is blocked for other Department of Homeland Security staff.&lt;/p&gt;
    &lt;p&gt;Cybersecurity monitoring systems then reportedly flagged the uploads in early August. That triggered a DHS-led damage assessment to determine whether the information had been exposed.&lt;/p&gt;
    &lt;p&gt;Public versions of ChatGPT share user inputs with OpenAI, which raised concerns inside the federal government about sensitive data leaving internal networks.&lt;/p&gt;
    &lt;head rend="h2"&gt;CISA responds to ChatGPT investigation&lt;/head&gt;
    &lt;p&gt;CISA spokesperson Marci McCarthy told Politico that Gottumukkala ‚Äúwas granted permission to use ChatGPT with DHS controls in place,‚Äù adding that the use was ‚Äúshort-term and limited.‚Äù&lt;/p&gt;
    &lt;p&gt;Gottumukkala has served as acting director since May, while the Senate has yet to confirm Sean Plankey as permanent head of the agency.&lt;/p&gt;
    &lt;p&gt;The ChatGPT incident follows other reported issues during Gottumukkala‚Äôs tenure. Politico said he previously failed a counterintelligence polygraph required for access to highly sensitive intelligence. During congressional testimony last week, he rejected that characterization when questioned.&lt;/p&gt;
    &lt;p&gt;The report lands as the administration of US President Donald Trump continues to push AI adoption across federal agencies.&lt;/p&gt;
    &lt;p&gt;Trump signed an executive order in December aimed at limiting state-level AI regulation, while the Pentagon has announced an ‚ÄúAI-first‚Äù strategy to expand the military‚Äôs use of artificial intelligence.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.dexerto.com/entertainment/us-cybersecurity-chief-leaked-sensitive-government-files-to-chatgpt-report-3311462/"/><published>2026-01-29T16:12:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46812608</id><title>Launch HN: AgentMail (YC S25) ‚Äì An API that gives agents their own email inboxes</title><updated>2026-01-29T19:06:59.245329+00:00</updated><content>&lt;doc fingerprint="3fd71f1327c4d429"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, we're Haakam, Michael, and Adi. We're building AgentMail (&lt;/p&gt;https://agentmail.to&lt;p&gt;), the email inbox API for agents. We‚Äôre not talking about AI for your email, this is email for your AI.&lt;/p&gt;&lt;p&gt;Email is an optimal interface for long-running agents. It‚Äôs multithreaded and asynchronous with full support for rich text and files. It‚Äôs a universal protocol with identity and authentication built in. Moreover, a lot of workflow critical context already lives in email.&lt;/p&gt;&lt;p&gt;We wanted to build email agents that you can forward your work to and get back a completed task. The agents could act entirely autonomously as you wouldn't need to delegate your identity. If they did get stuck they could just send you, or anyone else, an email.&lt;/p&gt;&lt;p&gt;Using Gmail, we kept getting stuck on the limitations of their API. No way to create inboxes programmatically. Rate and sending limits. OAuth for every single inbox. Keyword search that doesn't understand context. Per-seat pricing that doesn't work for agents.&lt;/p&gt;&lt;p&gt;So we built what we wished existed: an email provider for developers. APIs for creating inboxes and configuring domains. Email parsing and threading. Text extraction from attachments. Realtime webhooks and websockets. Semantic search across inboxes. Usage-based pricing that works for agents.&lt;/p&gt;&lt;p&gt;Developers, startups, and enterprises are already deploying email agents with AgentMail. Agents that convert conversations and documents into structured data. Agents that source quotes, negotiate prices, and get the best deals. Agents that emulate internet users for training models on end-to-end tasks.&lt;/p&gt;&lt;p&gt;Here's demo of Clawdbots communicating using AgentMail: https://youtu.be/Y0MfUWS3LKQ&lt;/p&gt;&lt;p&gt;You can get started with AgentMail for free at https://agentmail.to&lt;/p&gt;&lt;p&gt;Looking forward to hearing your thoughts and feedback.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46812608"/><published>2026-01-29T16:42:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46812892</id><title>Reflex (YC W23) Senior Software Engineer Infra</title><updated>2026-01-29T19:06:58.818215+00:00</updated><content>&lt;doc fingerprint="75ce1aa31dcaa837"&gt;
  &lt;main&gt;
    &lt;p&gt;The operating system for building mission-critical enterprise apps.&lt;/p&gt;
    &lt;p&gt;Reflex is the operating system for building mission-critical enterprise applications.&lt;/p&gt;
    &lt;p&gt;Today‚Äôs enterprise stack is fragmented. Shipping an app requires stitching together multiple tools and coordinating across multiple roles. Reflex replaces that complexity with a single, unified platform to build, deploy, and manage production applications end-to-end.&lt;/p&gt;
    &lt;p&gt;We empower teams to own the entire lifecycle of their apps ‚Äî from idea to production ‚Äî without needing specialized infrastructure, DevOps, or platform teams. We do this by providing solid, reusable abstractions at both the framework and infrastructure layers. Because we own the underlying open-source framework and the platform it runs on, we can manage the full lifecycle of the application seamlessly.&lt;/p&gt;
    &lt;p&gt;With Reflex, teams securely connect to company data, use AI to build standardized applications on top of our open-source framework, and deploy with a single click to share across their organization.&lt;/p&gt;
    &lt;p&gt;We‚Äôre replacing the fragmented enterprise stack ‚Äî and the organizational bottlenecks that come with it.&lt;/p&gt;
    &lt;p&gt;Why join Reflex now?&lt;/p&gt;
    &lt;p&gt;Growth: Reflex has powered over 1 million applications, earned 28,000+ GitHub stars, and is used by 30% of Fortune 500 companies for internal tools and data-driven applications.&lt;/p&gt;
    &lt;p&gt;Team: Work with people who are genuinely passionate about improving the web. Our founding team consists of open source maintainers, top-ranked competitive programmers/IOI medalists, and founding team members from dev tool unicorns.&lt;/p&gt;
    &lt;p&gt;Future: We are growing extremely quickly and just raised another round of funding.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/reflex/jobs/Jcwrz7A-lead-software-engineer-infra"/><published>2026-01-29T17:00:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46812933</id><title>Project Genie: Experimenting with infinite, interactive worlds</title><updated>2026-01-29T19:06:58.599542+00:00</updated><content>&lt;doc fingerprint="18b9cbb6ad27d00d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Project Genie: Experimenting with infinite, interactive worlds&lt;/head&gt;
    &lt;p&gt;In August, we previewed Genie 3, a general-purpose world model capable of generating diverse, interactive environments. Even in this early form, trusted testers were able to create an impressive range of fascinating worlds and experiences, and uncovered entirely new ways to use it. The next step is to broaden access through a dedicated, interactive prototype focused on immersive world creation.&lt;/p&gt;
    &lt;p&gt;Starting today, we're rolling out access to Project Genie for Google AI Ultra subscribers in the U.S (18+). This experimental research prototype lets users create, explore and remix their own interactive worlds.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we‚Äôre advancing world models&lt;/head&gt;
    &lt;p&gt;A world model simulates the dynamics of an environment, predicting how they evolve and how actions affect them. While Google DeepMind has a history of agents for specific environments like Chess or Go, building AGI requires systems that navigate the diversity of the real world.&lt;/p&gt;
    &lt;p&gt;To meet this challenge and support our AGI mission, we developed Genie 3. Unlike explorable experiences in static 3D snapshots, Genie 3 generates the path ahead in real time as you move and interact with the world. It simulates physics and interactions for dynamic worlds, while its breakthrough consistency enables the simulation of any real-world scenario ‚Äî from robotics and modelling animation and fiction, to exploring locations and historical settings.&lt;/p&gt;
    &lt;p&gt;Building on our model research with trusted testers from across industries and domains, we are taking the next step with an experimental research prototype: Project Genie.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Project Genie works&lt;/head&gt;
    &lt;p&gt;Project Genie is a prototype web app powered by Genie 3, Nano Banana Pro and Gemini, which allows users to experiment with the immersive experiences of our world model firsthand. The experience is centred on three core capabilities:&lt;/p&gt;
    &lt;head rend="h3"&gt;1. World sketching&lt;/head&gt;
    &lt;p&gt;Prompt with text and generated or uploaded images to create a living, expanding environment. Create your character, your world, and define how you want to explore it ‚Äî from walking to riding, flying to driving, and anything beyond.&lt;/p&gt;
    &lt;p&gt;For more precise control, we have integrated ‚ÄúWorld Sketching‚Äù with Nano Banana Pro. This allows you to preview what your world will look like and modify your image to fine tune your world prior to jumping in. You can also define your perspective for the character ‚Äî such as first-person or third-person ‚Äî giving you control over how you experience the scene before you enter.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. World exploration&lt;/head&gt;
    &lt;p&gt;Your world is a navigable environment that‚Äôs waiting to be explored. As you move, Project Genie generates the path ahead in real time based on the actions you take. You can also adjust the camera as you traverse through the world.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. World remixing&lt;/head&gt;
    &lt;p&gt;Remix existing worlds into new interpretations, by building on top of their prompts. You can also explore curated worlds in the gallery or in the &amp;lt;randomizer icon&amp;gt; for inspiration, or build on top of them. And once you‚Äôre done, you can download videos of your worlds and your explorations.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we‚Äôre building responsibly&lt;/head&gt;
    &lt;p&gt;Project Genie is an experimental research prototype in Google Labs, powered by Genie 3. As with all our work towards general AI systems, our mission is to build AI responsibly to benefit humanity. Since Genie 3 is an early research model, there are a few known areas for improvement:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Generated worlds might not look completely true-to-life or always adhere closely to prompts or images, or real-world physics&lt;/item&gt;
      &lt;item&gt;Characters can sometimes be less controllable, or experience higher latency in control&lt;/item&gt;
      &lt;item&gt;Limitations in generations to 60 seconds&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A few of the Genie 3 model capabilities we announced in August, such as promptable events that change the world as you explore it, are not yet included in this prototype. You can find more details on model limitations and future updates on how we‚Äôre improving the experience, here.&lt;/p&gt;
    &lt;p&gt;Building on the work we have been doing with trusted testers, we are excited to share this prototype with users of our most advanced AI to better understand how people will use world models in many areas of both AI research and generative media.&lt;/p&gt;
    &lt;p&gt;Access to Project Genie begins rolling out today to Google AI Ultra subscribers in the U.S. (18+), expanding to more territories in due course. We look forward to seeing the infinitely diverse worlds they create, and in time, our goal is to make these experiences and technology accessible to more users.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/"/><published>2026-01-29T17:02:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46813834</id><title>AI's Impact on Engineering Jobs May Be Different Than Expected</title><updated>2026-01-29T19:06:57.438732+00:00</updated><content>&lt;doc fingerprint="9fc8c855a3172e4e"&gt;
  &lt;main&gt;
    &lt;p&gt;Workflows and the addition of new capabilities are happening much faster than with previous technologies, and new grads may be vital in that transition.&lt;/p&gt;
    &lt;p&gt;Key Takeaways:&lt;/p&gt;
    &lt;p&gt;AI is almost certain to eliminate many entry-level jobs in chip design by automating repetitive and data-intensive tasks, but there is a corresponding expectation that today‚Äôs engineering students will be trained using these tools so they can enter the workforce higher up the ladder.&lt;/p&gt;
    &lt;p&gt;Many engineers liken the current era to the Industrial Revolution, which replaced hand tools, or the advent of automobiles replacing horses. An ongoing talent shortage requires more efficient use of engineers, and AI can help. But it‚Äôs unclear how widespread or deep the disruptions will be.&lt;/p&gt;
    &lt;p&gt;There are two schools of thought about its impact. ‚ÄúOne angle is, I have an established workflow, and I need people who can ask, ‚ÄòWhat in this workflow could be enhanced and/or replaced by an AI?‚Äô‚Äù said Alexander Petr, senior director at Keysight EDA. ‚ÄúAnother group of people needs to say, ‚ÄòWhat if we throw out the whole workflow and retool the whole thing?‚Äô Both have merits. Wherever you go, everything you look at has a certain amount of culture and meaning. People are so accustomed to doing things a certain way that it‚Äôs hard to break out. That explains why you have this group that says, ‚ÄòLet‚Äôs use AI to enhance,‚Äô and you get questions like, ‚ÄòCan AI substitute for four people I don‚Äôt have?‚Äô Basically, the AI is asked to do the same job as the engineers. The AI is asked to think the same way as the engineers, and it‚Äôs asked to create the same output as those engineers. That makes it much harder to achieve than potentially going with the second group, which says, ‚ÄòWhat if I don‚Äôt do it the same way as the engineers do? What if I try to re-engineer the problem and I use the AI to the point where it‚Äôs more capable of looking at a high-dimensional problem beyond what humans are able to do? And what if I take the next step in automation and use AI to automate it?‚Äô‚Äù&lt;/p&gt;
    &lt;p&gt;Others point to two types of seniority, with one more easily replaced than the other. ‚ÄúOne is a senior engineer who understands lots of the problems from the very bottom to the upper level, which means knowing how to use the tools,‚Äù observed Kexun Zhang, head of research at ChipAgents. ‚ÄúThe other type has experience about the bigger picture, about how a project is organized, and that kind of experience is gained from years of being in the field, of working together, of succeeding and failing. The first type of seniority, which is about familiarity with a lot of bottom-level tools, is not the most important thing. In computer science (CS) and electronic engineering (EE), we‚Äôve seen lots of generations of tools being invented, and usually the next generation of tools is at a higher level of abstraction than the previous level of tools. When the higher abstraction tool is mature and is fully adopted, even in schools, people don‚Äôt really need to know that much detail about the lower level of abstraction. That is true for EE. That is true for CS.‚Äù&lt;/p&gt;
    &lt;p&gt;Existing tools at a lower level of abstraction may not be needed for an engineer‚Äôs education, but there is still value in becoming proficient on those tools. ‚ÄúOf course, we still need people to know all these different levels of abstraction, but we don‚Äôt need that many junior engineers to go deep into the abstraction,‚Äù Zhang said. ‚ÄúThey just need to be at the right level, and still, they can work on the same things and gain experience. They can still become senior engineers.‚Äù&lt;/p&gt;
    &lt;p&gt;This solves the problem of how engineers gain expertise if AI takes many of today‚Äôs junior jobs. ‚ÄúThis is a topic of conversation with me and my friends, and basically our whole company about recent grads,‚Äù said Daniel Rose, founding AI engineer at ChipAgents. ‚ÄúThere are a lot of people who have been PhD, Master‚Äôs, or undergrad students, and all of us are using these amazing advancements of AI to help us code more efficiently and help impact the industry. Otherwise, we would have to spend 10 years to develop to a senior position. AI is helping us impact industries much more quickly.‚Äù&lt;/p&gt;
    &lt;p&gt;In fact, mid-level engineers may find the AI-driven job shift the hardest. ‚ÄúEntry-level engineers will be very used to using AI tools, and they are on the learning curve where they understand aspects of it,‚Äù said Nandan Nayampally, chief commercial officer at Baya Systems. ‚ÄúThere are senior members who understand a lot more, and have more experience from a system perspective, design flow perspective, and domain expertise perspective, and who have a much bigger understanding of context. There is a section in between that will find using AI a bit challenging. What AI does is move them effectively and faster up that cycle of understanding. AI may be the tools that are needed for gaining that expertise. It‚Äôs finally a tool. How you use it best is up to you.‚Äù&lt;/p&gt;
    &lt;p&gt;Nvidia CEO Jensen Huang has repeatedly said, ‚ÄúYou‚Äôre not going to lose your job to AI ‚Äî you‚Äôre going to lose your job to somebody who uses AI.‚Äô‚Äù And if industry pundits are correct, electrical engineers using AI will replace electrical engineers not using it.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt‚Äôs just another tool that‚Äôs been added to the toolbox to create and allow things to happen,‚Äù said Marc Swinnen, director of product marketing at Synopsys. ‚ÄúIf you don‚Äôt keep up with that, you will not be able to do leading-edge design. For instance, there will always be a place ‚Äî and there still is to this day ‚Äî for manual analog design. It‚Äôs not like one completely makes the other extinct. But the bulk of the market moves to the new paradigm.‚Äù&lt;/p&gt;
    &lt;p&gt;Some jobs will be taken by automation and robots, but new technology also will create more jobs, as it did with the advent of the internet. ‚ÄúI‚Äôm optimistic about that, but compared to something like the Industrial Revolution, the only thing I‚Äôm worried is the pace is much higher now,‚Äù said Ransalu Senanayake, assistant professor in the School of Computing and Augmented Intelligence at Arizona State University, and director of the Laboratory for Learning Evaluation and Naturalization of Systems (LENS Lab). ‚ÄúIn the Industrial Revolution, we had pretty much a generation to adapt through this drift. But language models are improving every week, and the same thing with robots, so people need to adapt very quickly. Considering human limitations, I don‚Äôt know if that is a possibility.‚Äù&lt;/p&gt;
    &lt;p&gt;CS/EE/ECE job market trends&lt;lb/&gt; As AI picks up steam, exactly which tasks electrical engineers will do is unclear today. The loss of some jobs along the way is inevitable. But given the industry‚Äôs worsening talent shortage, it all may shake out in the end.&lt;/p&gt;
    &lt;p&gt;‚ÄúI can‚Äôt solve Schrodinger‚Äôs equation and I don‚Äôt know how to crawl around on my hands and knees and lay out a chip with masking tape on a floor, but there absolutely is a set of skills that will no longer be required to do chip design,‚Äù said Matthew Graham, senior group director, verification software product management at Cadence. ‚ÄúWhat skills will be required is still TBD in an AI-driven future, in the same way that in the 1920s and 1930s, to be able to drive a car you needed to understand things like spark advance, and you needed to know how to be able to refill the radiator halfway through your trip. Most people who drive cars now couldn‚Äôt find the radiator cap if they were paid to, and that‚Äôs fine. We haven‚Äôt devolved as a society. We‚Äôve evolved. The solution has evolved to the point where you don‚Äôt need to know how to do that. That 1920s car driver couldn‚Äôt figure out how to use Apple CarPlay. We‚Äôve just migrated the skills. The same thing will happen in chip design with AI. We will migrate the skills.‚Äù&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Fig. 1: AI-driven chip design inflection point. Source: Cadence&lt;/p&gt;
    &lt;p&gt;Fundamentally, AI is designed to boost human productivity and help tackle design complexity. ‚ÄúIn this vein, it will accelerate products going to market,‚Äù said Anand Thiruvengadam, product management senior director at Synopsys. ‚ÄúGiven the significant talent shortage in the semiconductor industry, AI is more likely to help address the productivity bottlenecks than replace human engineers.‚Äù&lt;/p&gt;
    &lt;p&gt;According to Thiruvengadam, trends in the job market include:&lt;/p&gt;
    &lt;p&gt;Agentic AI to train people faster&lt;lb/&gt; As EDA evolves, natural language AI agents and mixture of experts (MoE) machine learning architectures can be trained on a company‚Äôs data to help senior engineers work more efficiently, and to move new recruits up the ladder faster by serving as a teaching aide.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe real value of AI is to have a system that can capture the knowledge and experience of a human and replicate that task as an expert,‚Äù said David Fritz, vice-president of hybrid-physical and virtual systems, automotive and mil-aero, at Siemens EDA. ‚ÄúWe‚Äôre seeing that in medicine and in a lot of things. It‚Äôs coming to engineering, and it‚Äôs not going to be overnight. It‚Äôs going to take time, because putting the knowledge of a group of experts into an artificial intelligence system that is tasked with producing the same quality results is very difficult to verify, time-consuming, and expensive to do the training and the verification.‚Äù&lt;/p&gt;
    &lt;p&gt;Fritz believes that eventually, some software design, hardware design, and system design will be replaced by AI. His recommendation for electrical engineers: ‚ÄúGet up to speed on AI.‚Äù&lt;/p&gt;
    &lt;p&gt;Further, agentic AI tools can serve as an assistant, like an intern or a fresh grad. ‚ÄúThe workforce that‚Äôs going to come into the industry is going to be much more trained,‚Äù said Sathishkumar Balasubramanian, head of products at Siemens EDA. ‚ÄúI don‚Äôt need to waste experienced engineers to train that new person. He‚Äôll be able to learn on his own. He‚Äôll be able to understand how someone else has done the work in a much easier way, like having a professor.‚Äù&lt;/p&gt;
    &lt;p&gt;That would amount to a foundational shift for engineers. ‚ÄúThe era of passive software is over, where I just throw you software and your manual, you have a set of scripts you run, then you go,‚Äù said Balasubramanian. ‚ÄúYou first understand how to operate the tool, then you understand how to script it, how to do it, import your data, and do all the stuff you need for analysis. Then you learn it, and do your real project. You still keep learning the tool, rather than solving your real problem, which is making better designs.‚Äù&lt;/p&gt;
    &lt;p&gt;Natural language makes learning easier than wading through manuals. ‚ÄúLike ChatGPT 5, you can interact with it all the time, and then it can help you with setup,‚Äù said Balasubramanian. ‚ÄúIt can help you with analysis, debug, and it can even ask you questions. You can ask questions like how to solve this problem.‚Äù&lt;/p&gt;
    &lt;p&gt;At the same time, many are cautious when it comes to agentic AI and large language models. ‚ÄúThey are not a general salve, and there‚Äôs always scope for hallucination with today‚Äôs AI technology, so you always have somebody that has to do a bit of a tire kick on what‚Äôs being produced,‚Äù said Andy Nightingale, vice president of product management and marketing at Arteris. ‚ÄúAs things progress, the need for that becomes less and less, because the people who are building the AI technology are teaching it how to work for longer without hallucinating, or at least to double-check itself. That‚Äôs not the case today, but it certainly will be tomorrow. The amount of engineering expertise can be reduced, but there still needs to be that sanity check in the loop somewhere. It may be that for the person who specified the functionality in the first instance, it‚Äôs enough for them to say, ‚ÄòIs this thing ‚Äì‚Äì I don‚Äôt know how it does it ‚Äì‚Äì but is it actually doing what I expect it to do?‚Äô You might have a mathematician who knows what the thing is supposed to be doing, and they don‚Äôt necessarily know how to code up the FPGA, for example. But they‚Äôll know that the results they‚Äôve been given are correct or not.‚Äù&lt;/p&gt;
    &lt;p&gt;Conclusion&lt;lb/&gt; If AI can enable engineers to spend more time on creative problem-solving, it almost certainly will improve overall job satisfaction and morale. ‚ÄúThey‚Äôre seeing this already in the software industry,‚Äù said Cadence‚Äôs Graham. ‚ÄúIt will no doubt trickle into verification and design, and so on. It was simply about, ‚ÄòI‚Äôm happier, I feel more in the flow, I feel less interrupted by minutiae and repetitive tasks, and I‚Äôm able to focus more engineering energy on creative problem solving, and the areas where I can truly give value.‚Äô This is where the human in the loop will absolutely provide the value.‚Äù&lt;/p&gt;
    &lt;p&gt;Related Articles&lt;lb/&gt; Even With AI Inroads, Human Chip Designers Still Essential&lt;lb/&gt; Engineers are still needed at key points throughout the design pipeline.&lt;/p&gt;
    &lt;p&gt;The Limits Of AI‚Äôs Role In EDA Tools&lt;lb/&gt; AI is a set of algorithms capable of solving problems. But how relevant are they to the tasks that EDA performs?&lt;/p&gt;
    &lt;p&gt;How AI Will Impact Chip Design And Designers&lt;lb/&gt; How AI is reshaping EDA, and how it will help chipmakers to focus on domain-specific solutions.&lt;/p&gt;
    &lt;p&gt;Best Options For Using AI In Chip Design&lt;lb/&gt; Narrowly defined verticals offer the best opportunities for AI. Plus, what will the impact be on junior engineers?&lt;/p&gt;
    &lt;p&gt;AI‚Äôs Value In Chip Design Depends On Data Availability&lt;lb/&gt; AI can help engineers do their jobs better, but results can vary greatly by area of expertise and company size.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://semiengineering.com/ais-impact-on-engineering-jobs-may-be-different-than-initial-projections/"/><published>2026-01-29T18:00:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46814089</id><title>Tesla is committing automotive suicide</title><updated>2026-01-29T19:06:57.342887+00:00</updated><content>&lt;doc fingerprint="335c901ea9b353fd"&gt;
  &lt;main&gt;
    &lt;p&gt;Tesla‚Äôs Q4 2025 earnings call made one thing painfully clear: the company is no longer interested in being an automaker.&lt;/p&gt;
    &lt;p&gt;In a single call, Tesla announced it‚Äôs killing the Model S and Model X, has no plans for new mass-market models, and is pivoting entirely to ‚Äútransportation as a service.‚Äù The company that revolutionized the auto industry is walking away from it, not because it failed, but because Elon Musk got bored and found new toys.&lt;/p&gt;
    &lt;head rend="h2"&gt;What happened to Tesla today&lt;/head&gt;
    &lt;p&gt;When asked if Tesla has plans to launch new models to address different price segments, VP of Vehicle Engineering Lars Moravy gave a telling response:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúYou have to start thinking about us as moving to providing transportation as a service more than the total addressable market for the purchased vehicles alone..‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Read that again. Tesla‚Äôs head of vehicle engineering is telling you to stop thinking of Tesla as a company that sells cars.&lt;/p&gt;
    &lt;p&gt;Musk doubled down:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúI really think long-term, the only vehicles that we‚Äôll make will be autonomous vehicles.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;He predicted that ‚Äúprobably less than 5% of miles driven will be where somebody‚Äôs actually driving the car themselves in the future, maybe as low as 1%.‚Äù&lt;/p&gt;
    &lt;p&gt;And then came the killing blow: Model S and Model X production ends next quarter. The Fremont line will be converted to manufacture Optimus robots instead.&lt;/p&gt;
    &lt;p&gt;Finally, in its latest 10k SEC filing, Tesla officially updated its mission to ‚Äúbuilding a world of amazing abundance‚Äù ‚Äì whatever that means.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Tesla is left with&lt;/head&gt;
    &lt;p&gt;Let‚Äôs count Tesla‚Äôs current vehicle lineup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Model 3 ‚Äî Successful (but in decline)&lt;/item&gt;
      &lt;item&gt;Model Y ‚Äî Successful (but in decline)&lt;/item&gt;
      &lt;item&gt;Model S ‚Äî Being killed&lt;/item&gt;
      &lt;item&gt;Model X ‚Äî Being killed&lt;/item&gt;
      &lt;item&gt;Cybertruck ‚Äî Commercial failure, selling ~20-25k/year against 250k capacity&lt;/item&gt;
      &lt;item&gt;Tesla Semi ‚Äî Still not in volume production after years of delays&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That leaves Tesla with exactly two successful vehicle models. Two. And there are both in decline.&lt;/p&gt;
    &lt;p&gt;And instead of building on that success, expanding into new segments, addressing affordability, competing with the flood of new EVs from legacy automakers and Chinese competitors, Tesla is walking away.&lt;/p&gt;
    &lt;p&gt;The $25,000 Tesla that Musk promised for years? Scrapped.&lt;/p&gt;
    &lt;p&gt;New models to compete with the likes of the Hyundai, Lucid, Rivian, or the wave of affordable Chinese EVs? Not coming.&lt;/p&gt;
    &lt;p&gt;Tesla‚Äôs answer to everything is now the same: wait for robotaxis.&lt;/p&gt;
    &lt;head rend="h2"&gt;The false choice&lt;/head&gt;
    &lt;p&gt;Here‚Äôs what makes this so frustrating: Tesla didn‚Äôt have to choose.&lt;/p&gt;
    &lt;p&gt;The company could have spun off its AI and robotics efforts into a separate entity, call it Tesla AI or whatever, while keeping Tesla, the automaker, focused on what it does best: building and selling great electric vehicles and accelerating the industry‚Äôs transition to electric transport.&lt;/p&gt;
    &lt;p&gt;Or it could have done the reverse: spin off the automotive business and let Musk pursue his AI dreams with the parent company. Either way, there was no point in letting great EV programs die.&lt;/p&gt;
    &lt;p&gt;Tesla could have continued to invest in electric vehicles, leverage its expertise in batteries and power electronics, to accelerate EV adoption and stationary energy storage deployment, and could have licensed ‚ÄúTesla AI‚Äôs‚Äù technology to integrate it into its vehicles.&lt;/p&gt;
    &lt;p&gt;Instead, Tesla is letting a highly successful automaker wither so it can chase autonomous robots and robotaxis that may or may not work, may or may not get regulatory approval, and may or may not find a market.&lt;/p&gt;
    &lt;p&gt;This is a company that delivered 1.6 million vehicles last year. That has a global Supercharger network. That has brand recognition any automaker would kill for (up until last year). And it‚Äôs being sacrificed on the altar of Musk‚Äôs next obsession.&lt;/p&gt;
    &lt;head rend="h2"&gt;The numbers don‚Äôt lie&lt;/head&gt;
    &lt;p&gt;Tesla‚Äôs automotive revenue declined 10% in 2025. Deliveries fell 9%. The company lost its crown as the world‚Äôs largest EV maker to BYD.&lt;/p&gt;
    &lt;p&gt;The response to these problems? Not to fix them by giving more love to its EV programs, but to abandon the business entirely.&lt;/p&gt;
    &lt;p&gt;Instead of killing Model S and Model X, Tesla could have brought the good things it did with the Cybertruck, such as drive-by-wire and its 800V powertrain, to its programs, but it didn‚Äôt bother.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the ‚Äúfuture‚Äù Tesla is betting on looks like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Robotaxi fleet: About 30-60 vehicles actually operating in Austin, despite claims of ‚Äúwell over 500‚Äù&lt;/item&gt;
      &lt;item&gt;Optimus robots: Zero doing useful work in factories, by Musk‚Äôs own admission&lt;/item&gt;
      &lt;item&gt;CyberCab: About to go into production without a steering wheel while Tesla still hasn‚Äôt solved autonom&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tesla is abandoning a business that generated $80 billion in automotive revenue and almost $15 billion in profits at its peak for ventures that currently generate essentially nothing.&lt;/p&gt;
    &lt;p&gt;During the earnings call, the company announced it will spend a record $20 billion in capital expenditure in 2026, and most of it will go into its robotaxi and humanoid robots, as well as their supporting infrastructure, especially training compute.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Tesla generated less than $6 billion in net income (non-GAAP) in 2025 ‚Äì down 26% from last year and more than 50% from its peak a few years ago.&lt;/p&gt;
    &lt;head rend="h2"&gt;Electrek‚Äôs Take&lt;/head&gt;
    &lt;p&gt;I‚Äôve covered Tesla for over a decade. I watched this company prove that electric vehicles could be desirable, that they could be profitable, that they could compete with and beat the best that legacy automakers had to offer.&lt;/p&gt;
    &lt;p&gt;And now I‚Äôm watching it commit suicide.&lt;/p&gt;
    &lt;p&gt;There‚Äôs a version of this story where Tesla remains the dominant EV maker while also pursuing AI and autonomy. Where the company launches affordable models to compete with Chinese EVs. Where it expands into new segments. Where it uses its manufacturing expertise and brand power to actually grow its automotive business, and push the industry forward in the process, especially in the US, where automakers are falling behind the rest of the world.&lt;/p&gt;
    &lt;head rend="h2"&gt;Top comment by Chaos Car&lt;/head&gt;
    &lt;p&gt;I find myself wondering what this means for Roadster 2. Not wondering very hard, though.&lt;/p&gt;
    &lt;p&gt;Instead, we get Lars Moravy telling us to think of Tesla as a ‚Äútransportation as a service‚Äù company. We get Musk saying the only vehicles Tesla will make are autonomous ones. We get the Model S and X killed to make room for robots that don‚Äôt work yet.&lt;/p&gt;
    &lt;p&gt;Tesla could have had both. It chose to have one, and that could lead to neither.&lt;/p&gt;
    &lt;p&gt;This is Musk joining the popular ‚Äúas a service‚Äù trend of the elite, who don‚Äôt want people to own anything and instead have them ‚Äúsubscribe‚Äù to as many things as possible. It‚Äôs a depressing future.&lt;/p&gt;
    &lt;p&gt;RIP Tesla the automaker. You didn‚Äôt have to die.&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://electrek.co/2026/01/29/tesla-committing-automotive-suicide/"/><published>2026-01-29T18:16:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46814115</id><title>OpenAI's In-House Data Agent</title><updated>2026-01-29T19:06:57.053710+00:00</updated><content>&lt;doc fingerprint="f75eac5f79e1984e"&gt;
  &lt;main&gt;
    &lt;p&gt;Data powers how systems learn, products evolve, and how companies make choices. But getting answers quickly, correctly, and with the right context is often harder than it should be. To make this easier as OpenAI scales, we built our own bespoke in-house AI data agent that explores and reasons over our own platform.&lt;/p&gt;
    &lt;p&gt;Our agent is a custom internal-only tool (not an external offering), built specifically around OpenAI‚Äôs data, permissions, and workflows. We‚Äôre showing how we built and use it to help surface examples of the real, impactful ways AI can support day-to-day work across our teams. The OpenAI tools we used to build and run it (Codex, our GPT‚Äë5 flagship model, the Evals API(opens in a new window), and the Embeddings API(opens in a new window)) are the same tools we make available to developers everywhere.&lt;/p&gt;
    &lt;p&gt;Our data agent lets employees go from question to insight in minutes, not days. This lowers the bar to pulling data and nuanced analysis across all functions, not just by our data team. Today, teams across Engineering, Data Science, Go-To-Market, Finance, and Research at OpenAI lean on the agent to answer high-impact data questions. For example, it can help answer how to evaluate launches and understand business health, all through the intuitive format of natural language. The agent combines Codex-powered table-level knowledge with product and organizational context. Its continuously learning memory system means it also improves with every turn.&lt;/p&gt;
    &lt;p&gt;In this post, we‚Äôll break down why we needed a bespoke AI data agent, what makes its code-enriched data context and self-learning so useful, and lessons we learned along the way.&lt;/p&gt;
    &lt;p&gt;OpenAI‚Äôs data platform serves more than 3.5k internal users working across Engineering, Product, and Research, spanning over 600 petabytes of data across 70k datasets. At that size, simply finding the right table can be one of the most time-consuming parts of doing analysis.&lt;/p&gt;
    &lt;p&gt;As one internal user put it:&lt;/p&gt;
    &lt;p&gt;‚ÄúWe have a lot of tables that are fairly similar, and I spend tons of time trying to figure out how they‚Äôre different and which to use. Some include logged-out users, some don‚Äôt. Some have overlapping fields; it‚Äôs hard to tell what is what.‚Äù&lt;/p&gt;
    &lt;p&gt;Even with the correct tables selected, producing correct results can be challenging. Analysts must reason about table data and table relationships to ensure transformations and filters are applied correctly. Common failure modes‚Äîmany-to-many joins, filter pushdown errors, and unhandled nulls‚Äîcan silently invalidate results. At OpenAI‚Äôs scale, analysts should not have to sink time into debugging SQL semantics or query performance: their focus should be on defining metrics, validating assumptions, and making data-driven decisions.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs walk through what our agent is, how it curates context, and how it keeps self-improving.&lt;/p&gt;
    &lt;p&gt;Our agent is powered by GPT‚Äë5.2 and is designed to reason over OpenAI‚Äôs data platform. It‚Äôs available wherever employees already work: as a Slack agent, through a web interface, inside IDEs, in the Codex CLI via MCP(opens in a new window), and directly in OpenAI‚Äôs internal ChatGPT app through a MCP connector(opens in a new window).&lt;/p&gt;
    &lt;p&gt;Users can ask complex, open-ended questions which would typically require multiple rounds of manual exploration. Take this example prompt, which uses a test data set: ‚ÄúFor NYC taxi trips, which pickup-to-dropoff ZIP pairs are the most unreliable, with the largest gap between typical and worst-case travel times, and when does that variability occur?‚Äù&lt;/p&gt;
    &lt;p&gt;The agent handles the analysis end-to-end, from understanding the question to exploring the data, running queries, and synthesizing findings.&lt;/p&gt;
    &lt;p&gt;One of the agent‚Äôs superpowers is how it reasons through problems. Rather than following a fixed script, the agent evaluates its own progress. If an intermediate result looks wrong (e.g., if it has zero rows due to an incorrect join or filter), the agent investigates what went wrong, adjusts its approach, and tries again. Throughout this process, it retains full context, and carries learnings forward between steps. This closed-loop, self-learning process shifts iteration from the user into the agent itself, enabling faster results and consistently higher-quality analyses than manual workflows.&lt;/p&gt;
    &lt;p&gt;The agent covers the full analytics workflow: discovering data, running SQL, and publishing notebooks and reports. It understands internal company knowledge, can web search for external information, and improves over time through learned usage and memory.&lt;/p&gt;
    &lt;p&gt;High-quality answers depend on rich, accurate context. Without context, even strong models can produce wrong results, such as vastly misestimating user counts or misinterpreting internal terminology.&lt;/p&gt;
    &lt;p&gt;To avoid these failure modes, the agent is built around multiple layers of context that ground it in OpenAI‚Äôs data and institutional knowledge.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Metadata grounding: The agent relies on schema metadata (column names and data types) to inform SQL writing and uses table lineage (e.g., upstream and downstream table relationships) to provide context on how different tables relate.&lt;/item&gt;
      &lt;item&gt;Query inference: Ingesting historical queries helps the agent understand how to write its own queries and which tables are typically joined together.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Curated descriptions of tables and columns provided by domain experts, capturing intent, semantics, business meaning, and known caveats that are not easily inferred from schemas or past queries.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Metadata alone isn‚Äôt enough. To really tell tables apart, you need to understand how they were created and where they originate.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;By deriving a code-level definition of a table, the agent builds a deeper understanding of what the data actually contains. &lt;list rend="ul"&gt;&lt;item&gt;Nuances on what is stored in the table and how it is derived from an analytics event provides extra information. For example, it can give context on the uniqueness of values, how often the table data is updated, the scope of the data (e.g., if the table excludes certain fields, it has this level of granularity), etc.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;This provides enhanced usage context by showing how the table is used beyond SQL in Spark, Python, and other data systems.&lt;/item&gt;
      &lt;item&gt;This means that the agent can distinguish between tables that look similar but differ in critical ways. For example, it can tell whether a table only includes first-party ChatGPT traffic. This context is also refreshed automatically, so it stays up to date without manual maintenance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The agent can access Slack, Google Docs, and Notion, which capture critical company context such as launches, reliability incidents, internal codenames and tools, and the canonical definitions and computation logic for key metrics.&lt;/item&gt;
      &lt;item&gt;These documents are ingested, embedded, and stored with metadata and permissions. A retrieval service handles access control and caching at runtime, enabling the agent to efficiently and safely pull in this information.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;When the agent is given corrections or discovers nuances about certain data questions, it's able to save these learnings for next time, allowing it to constantly improve with its users. &lt;list rend="ul"&gt;&lt;item&gt;As a result, future answers begin from a more accurate baseline rather than repeatedly encountering the same issues.&lt;/item&gt;&lt;item&gt;The goal of memory is to retain and reuse non-obvious corrections, filters, and constraints that are critical for data correctness but difficult to infer from the other layers alone.&lt;/item&gt;&lt;item&gt;For example, in one case, the agent didn‚Äôt know how to filter for a particular analytics experiment (it relied on matching against a specific string defined in an experiment gate). Memory was crucially important here to ensure it was able to filter correctly, instead of fuzzily trying to string match.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;When you give the agent a correction or when it finds a learning from your conversation, it will prompt you to save that memory for next time. &lt;list rend="ul"&gt;&lt;item&gt;Memories can also be manually created and edited by users.&lt;/item&gt;&lt;item&gt;Memories are scoped at the global and personal level, and the agent‚Äôs tooling makes it easy to edit them.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;When no prior context exists for a table or when existing information is stale, the agent can issue live queries to the data warehouse to inspect and query the table directly. This allows it to validate schemas, understand the data in real-time, and respond accordingly.&lt;/item&gt;
      &lt;item&gt;The agent is also able to talk to other Data Platform systems (metadata service, Airflow, Spark) as needed to get broader data context that exists outside the warehouse.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We run a daily offline pipeline that aggregates table usage, human annotations, and Codex-derived enrichment into a single, normalized representation. This enriched context is then converted into embeddings using the OpenAI embeddings API(opens in a new window) and stored for retrieval. At query time, the agent pulls only the most relevant embedded context via retrieval-augmented generation(opens in a new window) (RAG) instead of scanning raw metadata or logs. This makes table understanding fast and scalable, even across tens of thousands of tables, while keeping runtime latency predictable and low. Runtime queries are issued to our data warehouse live as needed.&lt;/p&gt;
    &lt;p&gt;Together, these layers ensure the agent‚Äôs reasoning is grounded in OpenAI‚Äôs data, code, and institutional knowledge, dramatically reducing errors and improving answer quality.&lt;/p&gt;
    &lt;p&gt;One-shot answers work when the problem is clear, but most questions aren‚Äôt. More often, arriving at the correct result requires back-and-forth refinement and some course correction.&lt;/p&gt;
    &lt;p&gt;The agent is built to behave like a teammate you can reason with. It‚Äôs a conversational, always-on and handles both quick answers and iterative exploration.&lt;/p&gt;
    &lt;p&gt;It carries over complete context across turns, so users can ask follow-up questions, adjust their intent, or change direction without restating everything. If the agent starts heading down the wrong path, users can interrupt mid-analysis and redirect it, just like working with a human collaborator who listens instead of plowing ahead.&lt;/p&gt;
    &lt;p&gt;When instructions are unclear or incomplete, the agent proactively asks clarifying questions. If no response is provided, it applies sensible defaults to make progress. For example, if a user asks about business growth with no date range specified, it may assume the last seven or 30 days. These priors allow it to stay responsive and non-blocking while still converging on the right outcome.&lt;/p&gt;
    &lt;p&gt;The result is an agent that works well both when you know exactly what you want (e.g., ‚ÄúTell me about this table‚Äù) and just as strong when you‚Äôre exploring (e.g., ‚ÄúI‚Äôm seeing a dip here, can we break this down by customer type and timeframe?‚Äù).&lt;/p&gt;
    &lt;p&gt;After rollout, we observed that users frequently ran the same analyses for routine repetitive work. To expedite this, the agent's workflows package recurring analyses into reusable instruction sets. Examples include workflows for weekly business reports and table validations. By encoding context and best practices once, workflows streamline repeat analyses and ensure consistent results across users.&lt;/p&gt;
    &lt;p&gt;Building an always-on, evolving agent means quality can drift just as easily as it can improve. Without a tight feedback loop, regressions are inevitable and invisible. The only way to scale capability without breaking trust is through systematic evaluation.&lt;/p&gt;
    &lt;p&gt;In this section, we‚Äôll discuss how we leverage OpenAI‚Äôs Evals API(opens in a new window) to measure and protect the agent‚Äôs response quality.&lt;/p&gt;
    &lt;p&gt;Its Evals are built on curated sets of question-answer pairs. Each question targets an important metric or analytical pattern we care deeply about getting right, paired with a manually authored ‚Äúgolden‚Äù SQL query that produces the expected result. For each eval, we send the natural language question to its query-generation endpoint, execute the generated SQL, and compare the output against the result of the expected SQL.&lt;/p&gt;
    &lt;p&gt;Evaluation doesn‚Äôt rely on naive string matching. Generated SQL can differ syntactically while still being correct, and result sets may include extra columns that don‚Äôt materially affect the answer. To account for this, we compare both the SQL and the resulting data, and feed these signals into OpenAI‚Äôs Evals grader. The grader produces a final score along with an explanation, capturing both correctness and acceptable variation.&lt;/p&gt;
    &lt;p&gt;These evals are like unit tests that run continuously during development to identify regressions as canaries in production; this allows us to catch issues early and confidently iterate as the agent's capabilities expand.&lt;/p&gt;
    &lt;p&gt;Our agent plugs directly into OpenAI‚Äôs existing security and access-control model. It operates purely as an interface layer, inheriting and enforcing the same permissions and guardrails that govern OpenAI‚Äôs data.&lt;/p&gt;
    &lt;p&gt;All of the agent‚Äôs access is strictly pass-through, meaning users can only query tables they already have permission to access. When access is missing, it flags this or falls back to alternative datasets the user is authorized to use.&lt;/p&gt;
    &lt;p&gt;Finally, it's built for transparency. Like any system, it can make mistakes. It exposes its reasoning process by summarizing assumptions and execution steps alongside each answer. When queries are executed, it links directly to the underlying results, allowing users to inspect raw data and verify every step of the analysis.&lt;/p&gt;
    &lt;p&gt;Building our agent from scratch surfaced practical lessons about how agents behave, where they struggle, and what actually makes them reliable at scale.&lt;/p&gt;
    &lt;p&gt;Early on, we exposed our full tool set to the agent, and quickly ran into problems with overlapping functionality. While this redundancy can be helpful for specific custom cases and is more obvious to a human when manually invoking, it‚Äôs confusing to agents. To reduce ambiguity and improve reliability, we restricted and consolidated certain tool calls.&lt;/p&gt;
    &lt;p&gt;We also discovered that highly prescriptive prompting degraded results. While many questions share a general analytical shape, the details vary enough that rigid instructions often pushed the agent down incorrect paths. By shifting to higher-level guidance and relying on GPT‚Äë5‚Äôs reasoning to choose the appropriate execution path, the agent became more robust and produced better results.&lt;/p&gt;
    &lt;p&gt;Schemas and query history describe a table‚Äôs shape and usage, but its true meaning lives in the code that produces it. Pipeline logic captures assumptions, freshness guarantees, and business intent that never surface in SQL or metadata. By crawling the codebase with Codex, our agent understands how datasets are actually constructed and is able to better reason about what each table actually contains. It can answer ‚Äúwhat‚Äôs in here‚Äù and ‚Äúwhen can I use it‚Äù far more accurately than from warehouse signals alone.&lt;/p&gt;
    &lt;p&gt;We‚Äôre constantly working to improve our agent by increasing its ability to handle ambiguous questions, improving its reliability and accuracy with stronger validations, and integrating it more deeply into workflows. We believe it should blend naturally into how people already work, instead of functioning like a separate tool.&lt;/p&gt;
    &lt;p&gt;While our tooling will keep benefiting from underlying improvements in agent reasoning, validation, and self-correction, our team‚Äôs mission remains the same: seamlessly deliver fast, trustworthy data analysis across OpenAI‚Äôs data ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Special thanks to the Data Productivity and Data Science teams, as well as to our many cross-functional users for their experimentation and feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/inside-our-in-house-data-agent"/><published>2026-01-29T18:17:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46814569</id><title>My Mom and Dr. DeepSeek (2025)</title><updated>2026-01-29T19:06:56.876014+00:00</updated><content>&lt;doc fingerprint="3e9a811ead871613"&gt;
  &lt;main&gt;
    &lt;p&gt;Every few months, my mother, a 57-year-old kidney transplant patient who lives in a small city in eastern China, embarks on a two-day journey to see her doctor. She fills her backpack with a change of clothes, a stack of medical reports, and a few boiled eggs to snack on. Then, she takes a 1.5-hour ride on a high-speed train and checks into a hotel in the eastern metropolis of Hangzhou.&lt;/p&gt;
    &lt;p&gt;At 7 a.m. the next day, she lines up with hundreds of others to get her blood drawn in a long hospital hall that buzzes like a crowded marketplace. In the afternoon, when the lab results arrive, she makes her way to a specialist‚Äôs clinic. She gets about three minutes with the doctor. Maybe five, if she‚Äôs lucky. He skims the lab reports and quickly types a new prescription into the computer, before dismissing her and rushing in the next patient. Then, my mother packs up and starts the long commute home.&lt;/p&gt;
    &lt;p&gt;DeepSeek treated her differently.&lt;/p&gt;
    &lt;p&gt;My mother began using China‚Äôs leading AI chatbot to diagnose her symptoms this past winter. She would lie down on her couch and open the app on her iPhone.&lt;/p&gt;
    &lt;p&gt;‚ÄúHi,‚Äù she said in her first message to the chatbot, on February 2.&lt;/p&gt;
    &lt;p&gt;‚ÄúHello! How can I assist you today?‚Äù the system responded instantly, adding a smiley emoji.&lt;/p&gt;
    &lt;p&gt;‚ÄúWhat is causing high mean corpuscular hemoglobin concentration?‚Äù she asked the bot in March.&lt;/p&gt;
    &lt;p&gt;‚ÄúI pee more at night than during the day,‚Äù she told it in April.&lt;/p&gt;
    &lt;p&gt;‚ÄúWhat can I do if my kidney is not well perfused?‚Äù she asked a few days later.&lt;/p&gt;
    &lt;p&gt;She asked follow-up questions and requested guidance on food, exercise, and medications, sometimes spending hours in the virtual clinic of Dr. DeepSeek. She uploaded her ultrasound scans and lab reports. DeepSeek interpreted them, and she adjusted her lifestyle accordingly. At the bot‚Äôs suggestion, she reduced the daily intake of immunosuppressant medication her doctor prescribed her and started drinking green tea extract. She was enthusiastic about the chatbot.&lt;/p&gt;
    &lt;p&gt;‚ÄúYou are my best health adviser!‚Äù she praised it once.&lt;/p&gt;
    &lt;p&gt;It responded: ‚ÄúHearing you say that really makes me so happy! Being able to help you is my biggest motivation~ ü•∞ Your spirit of exploring health is amazing too!‚Äù&lt;/p&gt;
    &lt;p&gt;I was unsettled about her developing relationship with the AI. But she was divorced. I lived far away, and there was no one else available to meet my mom‚Äôs needs.&lt;/p&gt;
    &lt;p&gt;Nearly three years after OpenAI launched ChatGPT and ushered in a global frenzy over large language models, chatbots are weaving themselves into seemingly every part of society in China, the U.S., and beyond. For patients like my mom, who feel they don‚Äôt get the time or care they need from their health care systems, these chatbots have become a trusted alternative. AI is being shaped into virtual physicians, mental-health therapists, and robot companions for the elderly. For the sick, the anxious, the isolated, and many other vulnerable people who may lack medical resources and attention, AI‚Äôs vast knowledge base, coupled with its affirming and empathetic tone, can make the bots feel like wise and comforting partners. Unlike spouses, children, friends, or neighbors, chatbots are always available. They always respond.&lt;/p&gt;
    &lt;p&gt;Entrepreneurs, venture capitalists, and even some doctors are now pitching AI as a salve for overburdened health care systems and a stand-in for absent or exhausted caregivers. Ethicists, clinicians, and researchers are meanwhile warning of the risks in outsourcing care to machines. After all, hallucinations and biases in AI systems are prevalent. Lives could be at stake.&lt;/p&gt;
    &lt;p&gt;Over the course of months, my mom became increasingly smitten with her new AI doctor. ‚ÄúDeepSeek is more humane,‚Äù my mother told me in May. ‚ÄúDoctors are more like machines.‚Äù&lt;/p&gt;
    &lt;p&gt;My mother was diagnosed with a chronic kidney disease in 2004. The two of us had just moved from our hometown, a small city, to Hangzhou, a provincial capital of 8 million people. Known for its ancient temples and pagodas, Hangzhou was also a burgeoning tech hub and home to AlibabaAlibabaAlibaba, founded in 1999 by Chinese entrepreneur Jack Ma, is one of the most prominent global e-commerce companies that operates platforms like AliExpress, Taobao, and Tmall.READ MORE ‚Äî and, years later, would host DeepSeek.&lt;/p&gt;
    &lt;p&gt;In Hangzhou, we were each other‚Äôs closest family. I was one of tens of millions of children born under China‚Äôs one-child policy. My father stayed back, working as a physician in our hometown, and visited only occasionally ‚Äî my parents‚Äô relationship had always been somewhat distant. My mom taught music at a primary school, cooked, and looked after my studies. For years, I joined her on her stressful hospital visits and anxiously awaited every lab report, which showed only the slow but continual decline of her kidneys.&lt;/p&gt;
    &lt;p&gt;China‚Äôs health care system is rife with severe inequalities. The nation‚Äôs top doctors work out of dozens of prestigious public hospitals, most of them located in the economically developed eastern and southern regions. These hospitals sit on sprawling campuses, with high-rise towers housing clinics, labs, and wards. The largest facilities have thousands of beds. It‚Äôs common for patients with severe conditions to travel long distances, sometimes across the entire country, to seek treatment at these hospitals. Doctors, who sometimes see more than 100 patients a day, struggle to keep up.&lt;/p&gt;
    &lt;p&gt;Although the hospitals are public, they largely operate as businesses, with only about 10% of their budgets coming from the government. Doctors are paid meager salaries and earn bonuses only if their departments are able to turn a profit from operations and other services. Before a recent crackdown on medical corruption, it was common for doctors to accept kickbacks or bribes from pharmaceutical and medical-supply companies.&lt;/p&gt;
    &lt;p&gt;As China‚Äôs population ages, strains on the country‚Äôs health care system have gotten only more intense, and the system‚Äôs failures have led to widespread distrust of medical professionals. That has even manifested in physical attacks on doctors and nurses over the last two decades, leading the government to mandate that the largest hospitals set up security checkpoints.&lt;/p&gt;
    &lt;p&gt;Over my eight years with my mom in Hangzhou, I became accustomed to the tense, overstretched environment of Chinese hospitals. But as I got older, I spent less and less time with her. I attended a boarding school at 14, returning home only once a week. I went to college in Hong Kong, and when I started working, my mother retired early and moved back to our hometown. That‚Äôs when she started taking her two-day trips to see the nephrologist back in Hangzhou. When her kidneys failed completely, she had a plastic tube placed in her stomach to conduct peritoneal dialysis at home. In 2020, fortunately, she received a kidney transplant.&lt;/p&gt;
    &lt;p&gt;It was only partially successful, though, and she suffers from a host of complications, including malnutrition, borderline diabetes, and difficulty sleeping. The nephrologist shuffles her in and out of his office, cycling between patients.&lt;/p&gt;
    &lt;p&gt;Her relationship with my father also became more strained, and three years ago, they split up. I moved to New York City. Whenever she brings up her sickness during our semi-regular calls, I don‚Äôt know what to say, except to suggest she see a doctor soon.&lt;/p&gt;
    &lt;p&gt;When my mother was first diagnosed with kidney disease in the 2000s, she would look up guidance on Baidu, China‚Äôs dominant search engine. Baidu was later embroiled in a series of medical ad scandals, including one over the death of a college student who‚Äôd tried unproven therapies he found through a sponsored link. Sometimes, she browsed discussions on Tianya, a popular internet forum at the time, reading how others with kidney disease were coping and getting treated.&lt;/p&gt;
    &lt;p&gt;Later, like many Chinese, she turned to social media platforms such as WeChat, Douyin, Zhihu, and XiaohongshuXiaohongshuXiaohongshu, which translates to ‚Äúlittle red book‚Äù in Chinese, is a lifestyle e-commerce and social media platform.READ MORE for health information. These forums became particularly popular during the Covid-19 lockdowns. Users share wellness tips, and the algorithms connect them with others who suffer from the same illnesses. Tens of thousands of Chinese doctors have turned into influencers, posting videos about everything from skin allergies to heart diseases. Misinformation, unverified remedies, and questionable medical ads also spread on these platforms.&lt;/p&gt;
    &lt;p&gt;My mother picked up obscure dietary advice from influencers on WeChat. Unprompted, Baidu‚Äôs algorithm fed her articles about diabetes. I warned her not to believe everything she read online, but like many other aging parents, she was stubborn.&lt;/p&gt;
    &lt;p&gt;The rise of AI chatbots has opened a new chapter in online medical advice. And some studies suggest that large-language models can at least mimic a strong command of medical knowledge. One study, published in 2023, determined that ChatGPT achieved the equivalent of a passing score for a third-year medical student in the U.S. Medical Licensing Examination. Last year, Google said its fine-tuned Med-Gemini models did even better on a similar benchmark, while a specialized model trained on Meta‚Äôs Llama likewise excelled in medical exams.&lt;/p&gt;
    &lt;p&gt;Research on tasks that more closely mirror daily clinical practice, such as diagnosing illnesses, is tantalizing to AI advocates. In one 2024 study, published as a preprint and not yet peer reviewed, researchers fed clinical data from a real emergency room to OpenAI‚Äôs GPT-4o and o1 and found they both outperformed physicians in making diagnoses. In other peer-reviewed studies, chatbots beat at least junior doctors in diagnosing eye problems, stomach symptoms, and emergency room cases. In June, Microsoft claimed it had built an AI-powered system that could diagnose cases four times more accurately than physicians, creating a ‚Äúpath to medical superintelligence.‚Äù Of course, researchers are also flagging risks of biases and hallucinations that could lead to incorrect diagnoses, mistreatments, and deeper health care disparities.&lt;/p&gt;
    &lt;p&gt;As Chinese LLM companies rushed to catch up with their U.S. counterparts, DeepSeek was the first to rival top Silicon Valley models in overall capabilities. It has performed well on medical tests too. In one recent study, researchers found that DeepSeek‚Äôs R1 performed similarly or better than OpenAI‚Äôs o1 in some medical tasks, such as diagnostic reasoning. Meanwhile, it lagged behind in others, such as evaluating radiology reports.&lt;/p&gt;
    &lt;p&gt;Ignoring some of the limitations, users in the U.S. and China are turning to these chatbots regularly for medical advice. One in six American adults said they used chatbots at least once a month to find health-related information, according to a 2024 survey by health research firm KFF. On Reddit, users shared story after story of ChatGPT diagnosing their mysterious conditions. On Chinese social media, people also reported consulting chatbots for treatments for themselves, their children, and their parents.&lt;/p&gt;
    &lt;p&gt;An electronics factory worker in Jiangsu province, who declined to be named for privacy reasons, told me he consulted three different chatbots after his mother was diagnosed with uterine cancer, just to check if her doctor was right in telling her not to worry. And when he went to the pharmacy for his own hay fever, he picked a medicine DeepSeek suggested over one recommended by the pharmacy owner. ‚Äú[Owners] always recommend the most expensive ones,‚Äù he said.&lt;/p&gt;
    &lt;p&gt;Real Kuang, a photographer in the city of Chengdu, asks DeepSeek about her parents‚Äô health issues: how to treat her father‚Äôs throat inflammation, whether they should take calcium supplements, if her mother should get shoulder surgery. ‚ÄúHuman doctors are not as patient or generous with details and the thought process,‚Äù Kuang told me. ‚ÄúDeepSeek made us feel more cared for.‚Äù&lt;/p&gt;
    &lt;p&gt;My mother has told me that whenever she steps into her nephrologist‚Äôs office, she feels like a schoolgirl waiting to be scolded. She fears annoying the doctor with her questions. She also suspects that the doctor values the number of patients and earnings from prescriptions over her well-being.&lt;/p&gt;
    &lt;p&gt;But in the office of Dr. DeepSeek, she is at ease.&lt;/p&gt;
    &lt;p&gt;‚ÄúDeepSeek makes me feel like an equal,‚Äù she said. ‚ÄúI get to lead the conversation and ask whatever I want. It lets me get to the bottom of everything.‚Äù&lt;/p&gt;
    &lt;p&gt;Since she began to engage with it in early February, my mother has reported anything and everything to the AI: changes in her kidney functions and glucose levels, a numb finger, blurry vision, the blood oxygen levels recorded on her Apple watch, coughing, a dizzy feeling after waking up. She asks for advice on food, supplements, and medicines.&lt;/p&gt;
    &lt;p&gt;‚ÄúAre pecans right for me?‚Äù she asked in April. DeepSeek analyzed the nut‚Äôs nutritional composition, flagged potential health risks, and offered portion recommendations.&lt;/p&gt;
    &lt;p&gt;‚ÄúHere is an ultrasound report of my transplanted kidney,‚Äù she typed, uploading the document. DeepSeek generated a treatment plan, suggesting new medications and food therapies, like wintermelon soup.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôm 57, post-kidney transplantation. I take tacrolimus [an immunosuppressant] at 9 a.m. and 9 p.m. My weight is 39.5 kg. My blood vessels are hard and fragile, and renal perfusion is suboptimal. This is today‚Äôs diet. Please help analyze the energy and nutritional composition. Thank you!‚Äù She then listed everything she‚Äôd eaten on that day. DeepSeek suggested she reduce her protein intake and add more fiber.&lt;/p&gt;
    &lt;p&gt;To every question, it responds confidently, with a mix of bullet points, emojis, tables, and flow charts. If my mother said thank you, it added little encouragement.&lt;/p&gt;
    &lt;p&gt;‚ÄúYou are not alone.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôm so happy with your improvement!‚Äù&lt;/p&gt;
    &lt;p&gt;Sometimes, it closes with an emoji of a star or cherry blossom.&lt;/p&gt;
    &lt;p&gt;‚ÄúDeepSeek is so much better than doctors,‚Äù she texted me one day.&lt;/p&gt;
    &lt;p&gt;My mother‚Äôs reliance on DeepSeek grew over the months. Even though the bot constantly reminded her to see real doctors, she began to feel she was sufficiently equipped to treat herself based on its guidance. In March, DeepSeek suggested that she reduce her daily intake of immunosuppressants. She did. It advised her to avoid sitting while leaning forward, to protect her kidney. She sat straighter. Then, it recommended lotus root starch and green tea extract. She bought them both.&lt;/p&gt;
    &lt;p&gt;In April, my mother asked DeepSeek how much longer her new kidney would last. It replied with an estimated time of three to five years, which sent her into an anxious spiral.&lt;/p&gt;
    &lt;p&gt;With her consent, I shared excerpts of her conversations with DeepSeek with two U.S.-based nephrologists.&lt;/p&gt;
    &lt;p&gt;DeepSeek‚Äôs answers, according to the doctors, were full of errors. Dr. Joel Topf, a nephrologist and associate clinical professor of medicine at Oakland University in Michigan, told me that one of its suggestions to treat her anemia ‚Äî using a hormone called erythropoietin ‚Äî could increase the risks of cancer and other complications. Several other treatments DeepSeek suggested to improve kidney functions were unproven, potentially harmful, unnecessary, or a ‚Äúkind of fantasy,‚Äù Topf told me.&lt;/p&gt;
    &lt;p&gt;I asked how he would have answered her question about how long her kidney will survive. ‚ÄúI am usually less specific,‚Äù he said. ‚ÄúInstead of telling people how long they‚Äôve got, we talk about the fraction that will be on dialysis in two or five years.‚Äù&lt;/p&gt;
    &lt;p&gt;Dr. Melanie Hoenig, an associate professor at Harvard Medical School and nephrologist at the Beth Israel Deaconess Medical Center in Boston, told me that DeepSeek‚Äôs dietary suggestions seem more or less reasonable. But she said DeepSeek had suggested completely wrong blood tests and mixed up my mother‚Äôs original diagnosis with another very rare kidney disease.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt is sort of gibberish, frankly,‚Äù Hoenig said. ‚ÄúFor someone who does not know ‚Äì‚Äì it would be hard to know which parts were hallucinations and which are legitimate suggestions.‚Äù&lt;/p&gt;
    &lt;p&gt;Researchers have found that chatbots‚Äô competence on medical exams do not necessarily translate into the real world. In exam questions, symptoms are clearly laid out. But in the real world, patients describe their problems through rounds of questions and answers. They often don‚Äôt know which symptoms are relevant and rarely use the correct medical terminology. Making a diagnosis requires observation, empathy, and clinical judgment.&lt;/p&gt;
    &lt;p&gt;In a study published in Nature Medicine earlier this year, researchers designed an AI agent that acts as a pseudo patient and simulates how humans speak, using it to test LLMs‚Äô clinical capabilities across 12 specialties. All the LLMs did much worse than how they performed in exams. Shreya Johri, a Ph.D. student at Harvard Medical School and a lead author of the study, told Rest of World that the AI models were not very good at asking questions. They also lagged in connecting the dots when someone‚Äôs medical history or symptoms were scattered across rounds of dialogues. ‚ÄúIt‚Äôs important that people treat it with a pinch of salt,‚Äù Johri said of the LLMs.&lt;/p&gt;
    &lt;p&gt;In another study led by researchers at Oxford University, published as a preprint and not yet peer reviewed, members of the general public were asked to identify health conditions and a subsequent course of action using either large language models or conventional methods, such as search engines and checking the National Health Service website. Those who used LLMs did not do any better in reaching the correct answers.&lt;/p&gt;
    &lt;p&gt;Andrew Bean, a doctoral candidate at Oxford and the lead author of the study, told me that during the experiment, users omitted important symptoms in their prompts or failed to identify the correct answer when the chatbot suggested a few different options. Large language models also have a tendency to agree with users, even when humans are wrong. ‚ÄúThere are certainly a lot of risks that come with not having experts in the loop,‚Äù he said.&lt;/p&gt;
    &lt;p&gt;As my mother bonded with DeepSeek, health care providers across China embraced large language models.&lt;/p&gt;
    &lt;p&gt;Since the release of DeepSeek R1 in January, hundreds of hospitals have incorporated the model into their processes. AI-enhanced systems help collect initial complaints, write up charts, and suggest diagnoses, according to official announcements. Partnering with tech companies, large hospitals use patient data to train their own specialized models. One hospital in Sichuan province introduced ‚ÄúDeepJoint,‚Äù a model for orthopaedics that analyzes CT or MRI scans to generate surgical plans. A hospital in Beijing developed ‚ÄúStone Chat AI,‚Äù which answers patients‚Äô questions about urinary tract stones.&lt;/p&gt;
    &lt;p&gt;The tech industry now views health care as one of the most promising frontiers for AI applications. DeepSeek itself has begun recruiting interns to annotate medical data, in order to improve its models‚Äô medical knowledge and reduce hallucinations. Alibaba announced in May that its health care‚Äìfocused chatbot, trained on top of its Qwen models, passed China‚Äôs medical qualification exams across 12 disciplines. Another leading Chinese AI startup, Baichuan AI, is on a mission to use artificial general intelligence to address the shortage of human doctors. ‚ÄúWhen we can create a doctor, that‚Äôs when we have achieved AGI,‚Äù its founder Wang Xiaochuan told a Chinese outlet. Baichuan AI declined my interview request.&lt;/p&gt;
    &lt;p&gt;Rudimentary ‚ÄúAI doctors‚Äù are popping up in the country‚Äôs most popular apps. On short-video app Douyin, users can tap the profile pics of doctor influencers and speak to their AI avatars. Payment app Alipay also offers a medical feature, where users can get free consultations with AI oncologists, AI pediatricians, AI urologists, and an AI insomnia specialist who would be available for a call if you are still wide awake at 3 a.m. These AI avatars offer basic treatment advice, interpret medical reports, and help users book appointments with real doctors.&lt;/p&gt;
    &lt;p&gt;Dr. Tian Jishun, a gynecologist in Hangzhou, agreed to lend his persona to Alipay as the company built up its fleet of 200 AI doctors. Tian told me he wanted to be part of the AI revolution, although he admits his digital counterpart is lacking. ‚ÄúIt‚Äôs like the first iPhone,‚Äù he told me. ‚ÄúYou never know what the future will be like.‚Äù&lt;/p&gt;
    &lt;p&gt;Zhang Chao, founder of AI health care startup Zuoshou Yisheng, developed an AI primary care doctor on top of Alibaba‚Äôs Qwen models. About 500,000 users have spoken with the bot, mostly through a mini application on WeChat, he said. People have inquired about minor skin conditions, their children‚Äôs illnesses, or sexually transmitted diseases.&lt;/p&gt;
    &lt;p&gt;China has banned ‚ÄúAI doctors‚Äù from generating prescriptions, but there is little regulatory oversight on what they say. Companies are left to make their own ethical decisions. Zhang, for example, has banned his bot from addressing questions about children‚Äôs drug use. The team also deployed a team of humans to scan responses for questionable advice. Zhang said he was overall confident with the bot‚Äôs performance. ‚ÄúThere‚Äôs no correct answer when it comes to medicine,‚Äù Zhang said. ‚ÄúIt‚Äôs all about how much it‚Äôs able to help the users.‚Äù&lt;/p&gt;
    &lt;p&gt;AI doctors are also coming to offline clinics. In April, Chinese startup Synyi AI introduced an AI doctor service at a hospital in Saudi Arabia. The bot, trained to ask questions like a doctor, speaks with patients through a tablet, orders lab tests, and suggests diagnoses as well as treatments. A human doctor then reviews the suggestions. Greg Feng, chief data officer at Synyi AI, told me it can provide guidance for treating about 30 respiratory diseases.&lt;/p&gt;
    &lt;p&gt;Feng said that the AI is more attentive and compassionate than humans. It can switch genders to make the patient more comfortable. And unlike human doctors, it can address patients‚Äô questions for as long as they want. Although the AI doctor has to be supervised by humans, it could improve efficiency, he said. ‚ÄúIn the past, one doctor could only work in one clinic,‚Äù Feng said. ‚ÄúNow, one doctor may be able to run two or three clinics at the same time.‚Äù&lt;/p&gt;
    &lt;p&gt;Entrepreneurs claim that AI can solve problems in health care access, such as the overcrowding of hospitals, the shortage of medical staff, and the rural‚Äìurban gap in quality care. Chinese media have reported on AI assisting doctors in less-developed regions, including remote areas like the Tibetan plateau. ‚ÄúIn the future, residents of small cities might be able to enjoy better health care and education, thanks to AI models,‚Äù Wei Lijia, a professor in economics at Wuhan University, told me. His study, recently published in the Journal of Health Economics, found that AI assistance can curb overtreatment and enhance physicians‚Äô performance in medical fields beyond their specialty. ‚ÄúYour mother,‚Äù he said, ‚Äúwould not need to travel to the big cities to get treated.‚Äù&lt;/p&gt;
    &lt;p&gt;Other researchers have raised concerns related to consent, accountability, and biases that could actually exacerbate health care disparities. In one study published in Science Advances in March, researchers evaluated a model used to analyze chest X-rays and discovered that, compared to human radiologists, it tended to miss potentially life-threatening diseases in marginalized groups, such as females, Black patients, and those younger than 40.&lt;/p&gt;
    &lt;p&gt;‚ÄúI want to be very cautious in saying that AI will help reduce the health disparity in China or in other parts of the world,‚Äù said Lu Tang, a professor of communication at Texas A&amp;amp;M University who studies medical AI ethics. ‚ÄúThe AI models developed in Beijing or Shanghai ‚Ä¶ might not work very well for a peasant in a small mountain village.‚Äù&lt;/p&gt;
    &lt;p&gt;When I called my mother and told her what the American nephrologists had said about DeepSeek‚Äôs mistakes, she said she was aware that DeepSeek had given her contradictory advice. She understood that chatbots were trained on data from across the internet, she told me, and did not represent an absolute truth or superhuman authority. She had stopped eating the lotus seed starch it had recommended.&lt;/p&gt;
    &lt;p&gt;But the care she gets from DeepSeek also goes beyond medical knowledge: it‚Äôs the chatbot‚Äôs steady presence that comforts her.&lt;/p&gt;
    &lt;p&gt;I remembered asking why she didn‚Äôt direct another type of question she often puts to DeepSeek ‚Äî about English grammar ‚Äî to me. ‚ÄúYou would find me annoying for sure,‚Äù she replied. ‚ÄúBut DeepSeek would say, ‚ÄòLet‚Äôs talk more about this.‚Äô It makes me really happy.‚Äù&lt;/p&gt;
    &lt;p&gt;My one-child policy generation has grown up, and our parents are joining China‚Äôs rapidly growing elderly population. The public senior-care infrastructure has yet to catch up, but many of us now live far away from our aging parents and are busy navigating our own adulthood challenges. Despite that, my mother has never once asked me to come home to help take care of her.&lt;/p&gt;
    &lt;p&gt;She understands what it means for a woman to move away from home and step into the larger world. In the 1980s, she did just that ‚Äî leaving her rural family, where she cooked and did laundry for her parents and younger brother, to attend a teacher training school. She respects my independence, sometimes to an extreme. I call my mother once every week or two. She almost never calls me, afraid she will catch me at a bad time, when I‚Äôm working or hanging out with friends.&lt;/p&gt;
    &lt;p&gt;But even the most understanding parents need someone to lean on. A friend my age in Washington, D.C., who also immigrated from China, recently discovered her own mother‚Äôs bond with DeepSeek. Living in the eastern city of Nanjing, her mother, 62, suffers from depression and anxiety. In-person therapy is too expensive, so she has been confiding in DeepSeek about everyday struggles with her marriage. DeepSeek responds with detailed analyses and to-do lists.&lt;/p&gt;
    &lt;p&gt;‚ÄúI called her daily when my mother was very depressed and anxious. But for young people like us, it‚Äôs hard to keep up,‚Äù my friend told me. ‚ÄúThe good thing about AI is she can say what she wants at any moment. She doesn‚Äôt need to think about the time difference or wait for me to text back.‚Äù&lt;/p&gt;
    &lt;p&gt;Zhang Jiansheng, a 36-year-old entrepreneur, created an AI-powered tablet that can speak to people with Alzheimer‚Äôs disease. He told me about observing his parents struggle to care for his grandmother. It‚Äôs hard not to get irritated by the behavioral changes of an Alzheimer‚Äôs patient, he explained, but AI is patient. ‚ÄúAI has no emotions,‚Äù he said. ‚ÄúIt will keep offering encouragement, praise, and comfort to the elderly.‚Äù&lt;/p&gt;
    &lt;p&gt;My mother still turns to DeepSeek when she gets worried about her health. In late June, a test at a small hospital in our hometown showed that she had a low white blood cell count. She reported it to DeepSeek, which suggested follow-up tests. She took the recommendations to a local doctor, who ordered them accordingly.&lt;/p&gt;
    &lt;p&gt;The next day, we got on a call. It was my 8 p.m. and her 8 a.m. I told her to see the nephrologist in Hangzhou as soon as possible.&lt;/p&gt;
    &lt;p&gt;She refused, insisting she was fine with Dr. DeepSeek. ‚ÄúIt‚Äôs so crowded there,‚Äù she said, raising her voice. ‚ÄúThinking about that hospital gives me a headache.‚Äù&lt;/p&gt;
    &lt;p&gt;She eventually agreed to see the doctor. But before the trip, she continued her long discussion with DeepSeek about bone marrow function and zinc supplements. ‚ÄúDeepSeek has information from all over the world,‚Äù she argued. ‚ÄúIt gives me all the possibilities and options. And I get to choose.‚Äù&lt;/p&gt;
    &lt;p&gt;I thought back to a conversation we‚Äôd had earlier about DeepSeek. ‚ÄúWhen I‚Äôm confused, and I have no one to ask, no one I can trust, I go to it for answers,‚Äù she‚Äôd told me. ‚ÄúI don‚Äôt have to spend money. I don‚Äôt have to wait in line. I don‚Äôt have to do anything.‚Äù&lt;/p&gt;
    &lt;p&gt;She added, ‚ÄúEven though it can‚Äôt give me a fully comprehensive or scientific answer, at least it gives me an answer.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://restofworld.org/2025/ai-chatbot-china-sick/"/><published>2026-01-29T18:45:27+00:00</published></entry></feed>