<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-01T21:38:06.920049+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46454274</id><title>Joseph Campbell Meets George Lucas ‚Äì Part I (2015)</title><updated>2026-01-01T21:40:30.279068+00:00</updated><content>&lt;doc fingerprint="e7c8fdb190b0730a"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;A much friendlier meet-up than Obi-Wan and Vader.&lt;/head&gt;
    &lt;p&gt;Joseph Campbell (1904-1987) was a world-renowned mythologist who helped modern society understand the true power that storytelling has in our culture and within our personal lives. He studied and identified the universal themes and archetypes that are present in mythical storytelling across history and across the world. His seminal work, The Hero With a Thousand Faces, outlined what Campbell called the Hero‚Äôs Journey, a motif of adventure and personal transformation that is used in nearly every culture‚Äôs mythical framework. George Lucas was an avid admirer of Campbell‚Äôs writings, and used them as a direct reference in his creation of Star Wars. The two didn't meet face to face until after Lucas had already finished his original trilogy of films‚Ä¶&lt;/p&gt;
    &lt;p&gt;Part 1&lt;/p&gt;
    &lt;p&gt;We look to the stars and wonder. Light from infinite directions and distances meets our gaze. And within our ‚Äúmythic imagination,‚Äù as Joseph Campbell described it, we begin to tell stories. As Campbell points out, the visual beauties that inspire a saga like Star Wars are derived as much from within us as it is outside. ‚ÄúThe imagery is necessarily physical and thus apparently of outer space,‚Äù Campbell says, ‚ÄúThe inherent connotation is always, however, psychological and metaphysical, which is to say, of inner space.‚Äù As we look to the stars, we are inherently reflected. It is what Campbell calls the ‚Äúinner reaches of outer space.‚Äù&lt;/p&gt;
    &lt;p&gt;In 1984, Joseph Campbell came to the Palace of Fine Arts in San Francisco, an architectural beauty rebuilt from the Panama-Pacific International Exposition of 1915, and near the current location of Lucasfilm‚Äôs headquarters. The iconic dome had been constructed to reflect the classical styles of ancient Rome and Greece, and evokes emotion as if it could be an archetype of myth itself. It was an apt setting for Campbell to lead discussions on the inner reaches of outer space.&lt;/p&gt;
    &lt;p&gt;George Lucas was in the audience. Though he had long admired and studied Campbell back to the time of his early drafts of Star Wars, he had yet to meet the man who he would call, ‚Äúmy Yoda.‚Äù San Francisco certainly wasn‚Äôt the swampy planet of Dagobah. The meeting would in fact be the opposite of Master Yoda and young Luke Skywalker‚Äôs. This time it was the master who was to learn just how pivotal his teachings could be for the apprentice.&lt;/p&gt;
    &lt;p&gt;‚Äú[‚Ä¶] Outer space is within inasmuch as the laws of space are within us; outer and inner space are the same. We know, furthermore, that we have actually been born from space,‚Äù Campbell told audiences in San Francisco. He continued to describe the ‚Äúwonderland of myth,‚Äù where an almost circular path of inspiration moves between that which we see and that which we imagine. ‚ÄúFrom the outer world the senses carry images to mind, which do not become myth, however, until they‚Äôre transformed by fusion with accordant insights, awakened as imagination from the inner world of the body.‚Äù As Yoda tells Luke in The Empire Strikes Back, ‚ÄúLuminous beings are we, not this crude matter.‚Äù The light of the stars is fully within us.&lt;/p&gt;
    &lt;p&gt;After the mesmerizing discussions, Lucas was introduced to Campbell via their mutual friend, scientist and Nobel laureate Barbara McClintock. Though they did not connect at first words, as McClintock would remember to Campbell‚Äôs biographer, ‚ÄúI got them sitting together, but Joe was holding court like he would‚Ä¶There was a young man there, David Abrams, the only true magician I‚Äôve ever known in my life‚Ä¶ I called David over and said, ‚ÄòSee if you can get these two talking to each other.‚Äô David went over and did a trick‚Ä¶it involved putting George‚Äôs hand on Joe‚Äôs hand and that was it.‚Äù&lt;/p&gt;
    &lt;p&gt;The spark had been ignited and a friendship had begun. Campbell and Lucas took a liking to each other. They enjoyed discussing ideas of mythology, and in particular the influence of Campbell‚Äôs The Hero With a Thousand Faces on Lucas‚Äô filmmaking. Their relationship blossomed over the coming years, though surprisingly, Campbell had yet to see any of the Star Wars films.&lt;/p&gt;
    &lt;p&gt;A few years after their first meeting, the time finally came for Lucas to show Campbell his work. Lucas would tell Campbell‚Äôs biographers: ‚Äú[‚Ä¶] At one point I talked about Star Wars, and he‚Äôd heard about Star Wars. I said, ‚ÄòWould you be interested at all in seeing it?‚Äô At this point I‚Äôd finished all three of them. He said, ‚ÄòI‚Äôll see all three of them.‚Äô I said, ‚ÄòWould you like to see one a day?‚Äô because he was going to be here for around a week. ‚ÄòNo, no, I want to see them all at once.‚Äô‚Äù&lt;/p&gt;
    &lt;p&gt;And so Campbell, along with his wife Jean, came to Marin County north of San Francisco. It was on a Sunday when Lucas took the Campbells to the recently finished Skywalker Ranch. Lucas remembered, ‚ÄúI showed them one in the morning [A New Hope], and we had lunch. I showed another one in the afternoon [The Empire Strikes Back], then we had dinner. Then I showed another one in the evening [Return of the Jedi]. It was actually the first time anybody, I think, had ever seen all three of them together at one time!‚Äù&lt;/p&gt;
    &lt;p&gt;Their mutual friend, Barbara McClintock, joined in for the third film, and she remembered the moment after it had ended. ‚ÄúIt was just us and George. It was very quiet in the dark, and Joe said, ‚ÄòYou know, I thought real art had stopped with Picasso, Joyce, and Mann. Now I know it hasn‚Äôt.‚Äô‚Äù&lt;/p&gt;
    &lt;p&gt;Myth is often something experienced unconsciously by a collective. Most audience members in the summer of 1977 were not aware of the age-old archetypes at work in A New Hope. They simply enjoyed the film; the story had their attraction. Even the creators themselves can be part of this collective unconscious. Composer John Williams was in the audience for one of Campbell‚Äôs lectures at Skywalker Ranch and commented, ‚ÄúUntil Campbell told us what Star Wars meant [‚Ä¶] we regarded it as a Saturday morning space movie.‚Äù Nevertheless, the power resides in the experience equally as much as the understanding.&lt;/p&gt;
    &lt;p&gt;In his book, The Inner Reaches of Outer Space, Campbell meditates on the universe‚Äôs immensity, ‚Äú[‚Ä¶] twenty Milky Ways of billions of exploding nuclear furnaces, flying from each other through spaces not to be measured, the universe (of which we speak so easily) compromising, literally, quintillions of such self-consuming stars.‚Äù To contemplate a starry sky itself is to contemplate on a mythical level. And as scientific discovery continuously redefines our understanding of the cosmos, certainly our mythical perspective must change as well. Campbell himself states, ‚ÄúWhat does all this do to mythology?‚Äù George Lucas would help to redefine this mythical framework for the Space Age, and in effect prove that the discoveries and revelations of a storyteller could be as influential as those of an astronomer.&lt;/p&gt;
    &lt;p&gt;In the late 1980s, as Campbell entered the final years of his life, his friendship with Lucas continued. The apprentice would perform a fitting tribute to his mentor. Together with journalist Bill Moyers, they‚Äôd ensure Campbell‚Äôs teachings would remain as immortal as the very myths themselves‚Ä¶&lt;/p&gt;
    &lt;p&gt;The story continues in the second and final installment of this two-part article‚Ä¶&lt;/p&gt;
    &lt;p&gt;Sources &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Baxter, John. George Lucas: A Biography. Hammersmith, London: Harper Collins Entertainment, 1999. Print.&lt;/item&gt;
      &lt;item&gt;Campbell, Joseph. The Hero with a Thousand Faces. Novato, CA: New World Library, 2008. Print.&lt;/item&gt;
      &lt;item&gt;Campbell, Joseph. The Inner Reaches of Outer Space: Metaphor as Myth and as Religion. Novato, CA: New World Library, 2012. Print.&lt;/item&gt;
      &lt;item&gt;"Interview with Ron Suskind." Telephone interview. 18 Feb. 2015.&lt;/item&gt;
      &lt;item&gt;Larsen, Stephen, and Robin Larsen. A Fire in the Mind: The Life of Joseph Campbell. New York: Doubleday, 1991. Print.&lt;/item&gt;
      &lt;item&gt;Moyers, Bill, prod. The Power of Myth, The Hero's Journey. PBS. 1988. Television.&lt;/item&gt;
      &lt;item&gt;Seabrook, John. "Letter from Skywalker Ranch: Why Is the Force Still With Us?" George Lucas: Interviews. Ed. Sally Kline. Jackson: U of Mississippi, 1999. 190-215. Print.&lt;/item&gt;
      &lt;item&gt;Taylor, Chris. "Between the Wars." How Star Wars Conquered the Universe: The Past, Present, and Future of a Multibillion Dollar Franchise. New York: Basic, 2014. 277-79. Print.&lt;/item&gt;
      &lt;item&gt;The Mythology of Star Wars. Dir. Pamela Mason Wagner. Perf. George Lucas and Bill Moyers. PBS, 1999. DVD.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lucas O. Seastrom is a writer, historian, and filmmaker living in Marin County, CA. He grew up on a farm in California‚Äôs Central Valley, is a lifelong Star Wars fan, and volunteers at Rancho Obi Wan. Twitter: @losnorcal.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.starwars.com/news/mythic-discovery-within-the-inner-reaches-of-outer-space-joseph-campbell-meets-george-lucas-part-i"/><published>2026-01-01T14:12:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46454413</id><title>2025 Letter</title><updated>2026-01-01T21:38:15.467176+00:00</updated><content>&lt;doc fingerprint="24f9e010dc8092c8"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;There are numbers every Python programmer should know. For example, how fast or slow is it to add an item to a list in Python? What about opening a file? Is that less than a millisecond? Is there something that makes that slower than you might have guessed? If you have a performance sensitive algorithm, which data structure should you use? How much memory does a floating point number use? What about a single character or the empty string? How fast is FastAPI compared to Django?&lt;/p&gt;
      &lt;p&gt;I wanted to take a moment and write down performance numbers specifically focused on Python developers. Below you will find an extensive table of such values. They are grouped by category. And I provided a couple of graphs for the more significant analysis below the table.&lt;/p&gt;
      &lt;head rend="h3"&gt;Source code for the benchmarks&lt;/head&gt;
      &lt;p&gt;This article is posted without any code. I encourage you to dig into the benchmarks. The code is available on GitHub at:&lt;/p&gt;
      &lt;p&gt;https://github.com/mikeckennedy/python-numbers-everyone-should-know&lt;/p&gt;
      &lt;p&gt;The benchmarks were run on the sytem described in this table. While yours may be faster or slower, the most important thing to consider is relative comparisons.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Property&lt;/cell&gt;
          &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Python Version&lt;/cell&gt;
          &lt;cell&gt;CPython 3.14.2&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Hardware&lt;/cell&gt;
          &lt;cell&gt;Mac Mini M4 Pro&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Platform&lt;/cell&gt;
          &lt;cell&gt;macOS Tahoe (26.2)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Processor&lt;/cell&gt;
          &lt;cell&gt;ARM&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;CPU Cores&lt;/cell&gt;
          &lt;cell&gt;14 physical / 14 logical&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;RAM&lt;/cell&gt;
          &lt;cell&gt;24 GB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Timestamp&lt;/cell&gt;
          &lt;cell&gt;2025-12-30&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;
      &lt;p&gt;Inspired by Latency Numbers Every Programmer Should Know and similar resources.&lt;/p&gt;
      &lt;head rend="h2"&gt;Python numbers you should know&lt;/head&gt;
      &lt;p&gt;More analysis and graphs by category below the table.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Category&lt;/cell&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
          &lt;cell role="head"&gt;Memory&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üíæ Memory&lt;/cell&gt;
          &lt;cell&gt;Empty Python process&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;15.73 MB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty string&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;41 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;100-char string&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;141 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Small int (0-256)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;28 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Large int&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;28 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Float&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;24 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty list&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;56 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List with 1,000 ints&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;35.2 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List with 1,000 floats&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;32.1 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty dict&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;64 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Dict with 1,000 items&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;63.4 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty set&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;216 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set with 1,000 items&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;59.6 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Regular class instance (5 attrs)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;694 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;__slots__&lt;/code&gt; class instance (5 attrs)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;212 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List of 1,000 regular class instances&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;165.2 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List of 1,000 &lt;code&gt;__slots__&lt;/code&gt; class instances&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;79.1 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;dataclass instance&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;694 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;namedtuple instance&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;228 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;‚öôÔ∏è Basic Ops&lt;/cell&gt;
          &lt;cell&gt;Add two integers&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Add two floats&lt;/cell&gt;
          &lt;cell&gt;18.4 ns (54.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;String concatenation (small)&lt;/cell&gt;
          &lt;cell&gt;39.1 ns (25.6M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;f-string formatting&lt;/cell&gt;
          &lt;cell&gt;64.9 ns (15.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;.format()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;103 ns (9.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;%&lt;/code&gt; formatting&lt;/cell&gt;
          &lt;cell&gt;89.8 ns (11.1M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List append&lt;/cell&gt;
          &lt;cell&gt;28.7 ns (34.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List comprehension (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;9.45 Œºs (105.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Equivalent for-loop (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;11.9 Œºs (83.9k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üì¶ Collections&lt;/cell&gt;
          &lt;cell&gt;Dict lookup by key&lt;/cell&gt;
          &lt;cell&gt;21.9 ns (45.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set membership check&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List index access&lt;/cell&gt;
          &lt;cell&gt;17.6 ns (56.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List membership check (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;3.85 Œºs (259.6k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;len()&lt;/code&gt; on list&lt;/cell&gt;
          &lt;cell&gt;18.8 ns (53.3M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Iterate 1,000-item list&lt;/cell&gt;
          &lt;cell&gt;7.87 Œºs (127.0k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Iterate 1,000-item dict&lt;/cell&gt;
          &lt;cell&gt;8.74 Œºs (114.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;sum()&lt;/code&gt; of 1,000 ints&lt;/cell&gt;
          &lt;cell&gt;1.87 Œºs (534.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üè∑Ô∏è Attributes&lt;/cell&gt;
          &lt;cell&gt;Read from regular class&lt;/cell&gt;
          &lt;cell&gt;14.1 ns (70.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write to regular class&lt;/cell&gt;
          &lt;cell&gt;15.7 ns (63.6M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read from &lt;code&gt;__slots__&lt;/code&gt; class&lt;/cell&gt;
          &lt;cell&gt;14.1 ns (70.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write to &lt;code&gt;__slots__&lt;/code&gt; class&lt;/cell&gt;
          &lt;cell&gt;16.4 ns (60.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read from &lt;code&gt;@property&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;getattr()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;13.8 ns (72.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;hasattr()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;23.8 ns (41.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üìÑ JSON&lt;/cell&gt;
          &lt;cell&gt;&lt;code&gt;json.dumps()&lt;/code&gt; (simple)&lt;/cell&gt;
          &lt;cell&gt;708 ns (1.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.loads()&lt;/code&gt; (simple)&lt;/cell&gt;
          &lt;cell&gt;714 ns (1.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.dumps()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;2.65 Œºs (376.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.loads()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;2.22 Œºs (449.9k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;orjson.dumps()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;310 ns (3.2M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;orjson.loads()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;839 ns (1.2M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;ujson.dumps()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;1.64 Œºs (611.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;msgspec&lt;/code&gt; encode (complex)&lt;/cell&gt;
          &lt;cell&gt;445 ns (2.2M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Pydantic &lt;code&gt;model_dump_json()&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;1.54 Œºs (647.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Pydantic &lt;code&gt;model_validate_json()&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;2.99 Œºs (334.7k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üåê Web Frameworks&lt;/cell&gt;
          &lt;cell&gt;Flask (return JSON)&lt;/cell&gt;
          &lt;cell&gt;16.5 Œºs (60.7k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Django (return JSON)&lt;/cell&gt;
          &lt;cell&gt;18.1 Œºs (55.4k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;FastAPI (return JSON)&lt;/cell&gt;
          &lt;cell&gt;8.63 Œºs (115.9k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Starlette (return JSON)&lt;/cell&gt;
          &lt;cell&gt;8.01 Œºs (124.8k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Litestar (return JSON)&lt;/cell&gt;
          &lt;cell&gt;8.19 Œºs (122.1k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üìÅ File I/O&lt;/cell&gt;
          &lt;cell&gt;Open and close file&lt;/cell&gt;
          &lt;cell&gt;9.05 Œºs (110.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read 1KB file&lt;/cell&gt;
          &lt;cell&gt;10.0 Œºs (99.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write 1KB file&lt;/cell&gt;
          &lt;cell&gt;35.1 Œºs (28.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write 1MB file&lt;/cell&gt;
          &lt;cell&gt;207 Œºs (4.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;pickle.dumps()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;1.30 Œºs (769.6k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;pickle.loads()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;1.44 Œºs (695.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üóÑÔ∏è Database&lt;/cell&gt;
          &lt;cell&gt;SQLite insert (JSON blob)&lt;/cell&gt;
          &lt;cell&gt;192 Œºs (5.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;SQLite select by PK&lt;/cell&gt;
          &lt;cell&gt;3.57 Œºs (280.3k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;SQLite update one field&lt;/cell&gt;
          &lt;cell&gt;5.22 Œºs (191.7k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;diskcache set&lt;/cell&gt;
          &lt;cell&gt;23.9 Œºs (41.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;diskcache get&lt;/cell&gt;
          &lt;cell&gt;4.25 Œºs (235.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;MongoDB insert_one&lt;/cell&gt;
          &lt;cell&gt;119 Œºs (8.4k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;MongoDB find_one by _id&lt;/cell&gt;
          &lt;cell&gt;121 Œºs (8.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;MongoDB find_one by nested field&lt;/cell&gt;
          &lt;cell&gt;124 Œºs (8.1k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üìû Functions&lt;/cell&gt;
          &lt;cell&gt;Empty function call&lt;/cell&gt;
          &lt;cell&gt;22.4 ns (44.6M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Function with 5 args&lt;/cell&gt;
          &lt;cell&gt;24.0 ns (41.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Method call&lt;/cell&gt;
          &lt;cell&gt;23.3 ns (42.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Lambda call&lt;/cell&gt;
          &lt;cell&gt;19.7 ns (50.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;try/except (no exception)&lt;/cell&gt;
          &lt;cell&gt;21.5 ns (46.5M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;try/except (exception raised)&lt;/cell&gt;
          &lt;cell&gt;139 ns (7.2M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;isinstance()&lt;/code&gt; check&lt;/cell&gt;
          &lt;cell&gt;18.3 ns (54.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;‚è±Ô∏è Async&lt;/cell&gt;
          &lt;cell&gt;Create coroutine object&lt;/cell&gt;
          &lt;cell&gt;47.0 ns (21.3M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;run_until_complete(empty)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;27.6 Œºs (36.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;asyncio.sleep(0)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;39.4 Œºs (25.4k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;gather()&lt;/code&gt; 10 coroutines&lt;/cell&gt;
          &lt;cell&gt;55.0 Œºs (18.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;create_task()&lt;/code&gt; + await&lt;/cell&gt;
          &lt;cell&gt;52.8 Œºs (18.9k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;async with&lt;/code&gt; (context manager)&lt;/cell&gt;
          &lt;cell&gt;29.5 Œºs (33.9k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Memory Costs&lt;/head&gt;
      &lt;p&gt;Understanding how much memory different Python objects consume.&lt;/p&gt;
      &lt;head rend="h3"&gt;An empty Python process uses 15.73 MB&lt;/head&gt;
      &lt;head rend="h3"&gt;Strings&lt;/head&gt;
      &lt;p&gt;The rule of thumb for strings is the core string object takes 41 bytes. Each additional character is 1 byte.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;String&lt;/cell&gt;
          &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty string &lt;code&gt;""&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;41 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;1-char string &lt;code&gt;"a"&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;42 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;100-char string&lt;/cell&gt;
          &lt;cell&gt;141 bytes&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Numbers&lt;/head&gt;
      &lt;p&gt;Numbers are surprisingly large in Python. They have to derive from CPython‚Äôs &lt;code&gt;PyObject&lt;/code&gt; and are subject to reference counting for garabage collection, they exceed our typical mental model many of:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;2 bytes = short int&lt;/item&gt;
        &lt;item&gt;4 bytes = long int&lt;/item&gt;
        &lt;item&gt;etc.&lt;/item&gt;
      &lt;/list&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Type&lt;/cell&gt;
          &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Small int (0-256, cached)&lt;/cell&gt;
          &lt;cell&gt;28 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Large int (1000)&lt;/cell&gt;
          &lt;cell&gt;28 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Very large int (10**100)&lt;/cell&gt;
          &lt;cell&gt;72 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Float&lt;/cell&gt;
          &lt;cell&gt;24 bytes&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Collections&lt;/head&gt;
      &lt;p&gt;Collections are amazing in Python. Dynamically growing lists. Ultra high-perf dictionaries and sets. Here is the empty and ‚Äúfull‚Äù overhead of each.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Collection&lt;/cell&gt;
          &lt;cell role="head"&gt;Empty&lt;/cell&gt;
          &lt;cell role="head"&gt;1,000 items&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List (ints)&lt;/cell&gt;
          &lt;cell&gt;56 bytes&lt;/cell&gt;
          &lt;cell&gt;35.2 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List (floats)&lt;/cell&gt;
          &lt;cell&gt;56 bytes&lt;/cell&gt;
          &lt;cell&gt;32.1 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Dict&lt;/cell&gt;
          &lt;cell&gt;64 bytes&lt;/cell&gt;
          &lt;cell&gt;63.4 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set&lt;/cell&gt;
          &lt;cell&gt;216 bytes&lt;/cell&gt;
          &lt;cell&gt;59.6 KB&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Classes and Instances&lt;/head&gt;
      &lt;p&gt;Slots are an interesting addition to Python classes. They remove the entire concept of a &lt;code&gt;__dict__&lt;/code&gt; for tracking fields and other values. Even for a single instance, slots classes are significantly smaller (212 bytes vs 694 bytes for 5 attributes). If you are holding a large number of them in memory for a list or cache, the memory savings of a slots class becomes very dramatic - over 2x less memory usage. Luckily for most use-cases, just adding a slots entry saves a ton of memory with minimal effort.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Type&lt;/cell&gt;
          &lt;cell role="head"&gt;Empty&lt;/cell&gt;
          &lt;cell role="head"&gt;5 attributes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Regular class&lt;/cell&gt;
          &lt;cell&gt;344 bytes&lt;/cell&gt;
          &lt;cell&gt;694 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;__slots__&lt;/code&gt; class&lt;/cell&gt;
          &lt;cell&gt;32 bytes&lt;/cell&gt;
          &lt;cell&gt;212 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;dataclass&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;694 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;@dataclass(slots=True)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;212 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;namedtuple&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;228 bytes&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;Aggregate Memory Usage (1,000 instances):&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Type&lt;/cell&gt;
          &lt;cell role="head"&gt;Total Memory&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List of 1,000 regular class instances&lt;/cell&gt;
          &lt;cell&gt;165.2 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List of 1,000 &lt;code&gt;__slots__&lt;/code&gt; class instances&lt;/cell&gt;
          &lt;cell&gt;79.1 KB&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Basic Operations&lt;/head&gt;
      &lt;p&gt;The cost of fundamental Python operations: Way slower than C/C++/C# but still quite fast. I added a brief comparison to C# to the source repo.&lt;/p&gt;
      &lt;head rend="h3"&gt;Arithmetic&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Add two integers&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Add two floats&lt;/cell&gt;
          &lt;cell&gt;18.4 ns (54.4M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Multiply two integers&lt;/cell&gt;
          &lt;cell&gt;19.4 ns (51.6M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;String Operations&lt;/head&gt;
      &lt;p&gt;String operations in Python are fast as well. f-strings are the fastest formatting style, while even the slowest style is still measured in just nano-seconds.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Concatenation (&lt;code&gt;+&lt;/code&gt;)&lt;/cell&gt;
          &lt;cell&gt;39.1 ns (25.6M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;f-string&lt;/cell&gt;
          &lt;cell&gt;64.9 ns (15.4M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;.format()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;103 ns (9.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;%&lt;/code&gt; formatting&lt;/cell&gt;
          &lt;cell&gt;89.8 ns (11.1M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;List Operations&lt;/head&gt;
      &lt;p&gt;List operations are very fast in Python. Adding a single item usually requires 28ns. Said another way, you can do 35M appends per second. This is unless the list has to expand using something like a doubling algorithm. You can see this in the ops/sec for 1,000 items.&lt;/p&gt;
      &lt;p&gt;Surprisingly, list comprehensions are 26% faster than the equivalent for loops with append statements.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;list.append()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;28.7 ns (34.8M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List comprehension (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;9.45 Œºs (105.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Equivalent for-loop (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;11.9 Œºs (83.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Collection Access and Iteration&lt;/head&gt;
      &lt;p&gt;How fast can you get data out of Python‚Äôs built-in collections? Here is a dramatic example of how much faster the correct data structure is. &lt;code&gt;item in set&lt;/code&gt; or &lt;code&gt;item in dict&lt;/code&gt; is 200x faster than &lt;code&gt;item in list&lt;/code&gt; for just 1,000 items!&lt;/p&gt;
      &lt;p&gt;The graph below is non-linear in the x-axis.&lt;/p&gt;
      &lt;head rend="h3"&gt;Access by Key/Index&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Dict lookup by key&lt;/cell&gt;
          &lt;cell&gt;21.9 ns (45.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set membership (&lt;code&gt;in&lt;/code&gt;)&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List index access&lt;/cell&gt;
          &lt;cell&gt;17.6 ns (56.8M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List membership (&lt;code&gt;in&lt;/code&gt;, 1,000 items)&lt;/cell&gt;
          &lt;cell&gt;3.85 Œºs (259.6k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Length&lt;/head&gt;
      &lt;p&gt;&lt;code&gt;len()&lt;/code&gt; is very fast. Maybe we don‚Äôt have to optimize it out of the test condition on a while loop looping 100 times after all.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Collection&lt;/cell&gt;
          &lt;cell role="head"&gt;&lt;code&gt;len()&lt;/code&gt; time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;18.8 ns (53.3M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Dict (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;17.6 ns (56.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;18.0 ns (55.5M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Iteration&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Iterate 1,000-item list&lt;/cell&gt;
          &lt;cell&gt;7.87 Œºs (127.0k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Iterate 1,000-item dict (keys)&lt;/cell&gt;
          &lt;cell&gt;8.74 Œºs (114.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;sum()&lt;/code&gt; of 1,000 integers&lt;/cell&gt;
          &lt;cell&gt;1.87 Œºs (534.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Class and Object Attributes&lt;/head&gt;
      &lt;p&gt;The cost of reading and writing attributes, and how &lt;code&gt;__slots__&lt;/code&gt; changes things. Slots saves over 2x the memory usage on large collections, with virtually identical attribute access speed.&lt;/p&gt;
      &lt;head rend="h3"&gt;Attribute Access&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Regular Class&lt;/cell&gt;
          &lt;cell role="head"&gt;&lt;code&gt;__slots__&lt;/code&gt; Class&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read attribute&lt;/cell&gt;
          &lt;cell&gt;14.1 ns (70.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;14.1 ns (70.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write attribute&lt;/cell&gt;
          &lt;cell&gt;15.7 ns (63.6M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;16.4 ns (60.8M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Other Attribute Operations&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read &lt;code&gt;@property&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.8M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;getattr(obj, 'attr')&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;13.8 ns (72.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;hasattr(obj, 'attr')&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;23.8 ns (41.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;JSON and Serialization&lt;/head&gt;
      &lt;p&gt;Comparing standard library JSON with optimized alternatives. &lt;code&gt;orjson&lt;/code&gt; handles more data types and is over 8x faster than standard lib &lt;code&gt;json&lt;/code&gt; for complex objects. Impressive!&lt;/p&gt;
      &lt;head rend="h3"&gt;Serialization (dumps)&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Library&lt;/cell&gt;
          &lt;cell role="head"&gt;Simple Object&lt;/cell&gt;
          &lt;cell role="head"&gt;Complex Object&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json&lt;/code&gt; (stdlib)&lt;/cell&gt;
          &lt;cell&gt;708 ns (1.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;2.65 Œºs (376.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;orjson&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;60.9 ns (16.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;310 ns (3.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;ujson&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;264 ns (3.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;1.64 Œºs (611.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;msgspec&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;92.3 ns (10.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;445 ns (2.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Deserialization (loads)&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Library&lt;/cell&gt;
          &lt;cell role="head"&gt;Simple Object&lt;/cell&gt;
          &lt;cell role="head"&gt;Complex Object&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json&lt;/code&gt; (stdlib)&lt;/cell&gt;
          &lt;cell&gt;714 ns (1.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;2.22 Œºs (449.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;orjson&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;106 ns (9.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;839 ns (1.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;ujson&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;268 ns (3.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;1.46 Œºs (682.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;msgspec&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;101 ns (9.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;850 ns (1.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Pydantic&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;model_dump_json()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;1.54 Œºs (647.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;model_validate_json()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;2.99 Œºs (334.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;model_dump()&lt;/code&gt; (to dict)&lt;/cell&gt;
          &lt;cell&gt;1.71 Œºs (585.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;model_validate()&lt;/code&gt; (from dict)&lt;/cell&gt;
          &lt;cell&gt;2.30 Œºs (435.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Web Frameworks&lt;/head&gt;
      &lt;p&gt;Returning a simple JSON response. Benchmarked with &lt;code&gt;wrk&lt;/code&gt; against localhost running 4 works in Granian. Each framework returns the same JSON payload from a minimal endpoint. No database access or that sort of thing. This is just how much overhead/perf do we get from each framework itself. The code we write that runs within those view methods is largely the same.&lt;/p&gt;
      &lt;head rend="h3"&gt;Results&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Framework&lt;/cell&gt;
          &lt;cell role="head"&gt;Requests/sec&lt;/cell&gt;
          &lt;cell role="head"&gt;Latency (p99)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Flask&lt;/cell&gt;
          &lt;cell&gt;16.5 Œºs (60.7k req/sec)&lt;/cell&gt;
          &lt;cell&gt;20.85 ms (48.0 ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Django&lt;/cell&gt;
          &lt;cell&gt;18.1 Œºs (55.4k req/sec)&lt;/cell&gt;
          &lt;cell&gt;170.3 ms (5.9 ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;FastAPI&lt;/cell&gt;
          &lt;cell&gt;8.63 Œºs (115.9k req/sec)&lt;/cell&gt;
          &lt;cell&gt;1.530 ms (653.6 ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Starlette&lt;/cell&gt;
          &lt;cell&gt;8.01 Œºs (124.8k req/sec)&lt;/cell&gt;
          &lt;cell&gt;930 Œºs (1.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Litestar&lt;/cell&gt;
          &lt;cell&gt;8.19 Œºs (122.1k req/sec)&lt;/cell&gt;
          &lt;cell&gt;1.010 ms (990.1 ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;File I/O&lt;/head&gt;
      &lt;p&gt;Reading and writing files of various sizes. Note that the graph is non-linear in y-axis.&lt;/p&gt;
      &lt;head rend="h3"&gt;Basic Operations&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Open and close (no read)&lt;/cell&gt;
          &lt;cell&gt;9.05 Œºs (110.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read 1KB file&lt;/cell&gt;
          &lt;cell&gt;10.0 Œºs (99.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read 1MB file&lt;/cell&gt;
          &lt;cell&gt;33.6 Œºs (29.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write 1KB file&lt;/cell&gt;
          &lt;cell&gt;35.1 Œºs (28.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write 1MB file&lt;/cell&gt;
          &lt;cell&gt;207 Œºs (4.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Pickle vs JSON to Disk&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;pickle.dumps()&lt;/code&gt; (complex obj)&lt;/cell&gt;
          &lt;cell&gt;1.30 Œºs (769.6k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;pickle.loads()&lt;/code&gt; (complex obj)&lt;/cell&gt;
          &lt;cell&gt;1.44 Œºs (695.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.dumps()&lt;/code&gt; (complex obj)&lt;/cell&gt;
          &lt;cell&gt;2.72 Œºs (367.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.loads()&lt;/code&gt; (complex obj)&lt;/cell&gt;
          &lt;cell&gt;2.35 Œºs (425.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Database and Persistence&lt;/head&gt;
      &lt;p&gt;Comparing SQLite, diskcache, and MongoDB using the same complex object.&lt;/p&gt;
      &lt;head rend="h3"&gt;Test Object&lt;/head&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;user_data = {
    "id": 12345,
    "username": "alice_dev",
    "email": "alice@example.com",
    "profile": {
        "bio": "Software engineer who loves Python",
        "location": "Portland, OR",
        "website": "https://alice.dev",
        "joined": "2020-03-15T08:30:00Z"
    },
    "posts": [
        {"id": 1, "title": "First Post", "tags": ["python", "tutorial"], "views": 1520},
        {"id": 2, "title": "Second Post", "tags": ["rust", "wasm"], "views": 843},
        {"id": 3, "title": "Third Post", "tags": ["python", "async"], "views": 2341},
    ],
    "settings": {
        "theme": "dark",
        "notifications": True,
        "email_frequency": "weekly"
    }
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;head rend="h3"&gt;SQLite (JSON blob approach)&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Insert one object&lt;/cell&gt;
          &lt;cell&gt;192 Œºs (5.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Select by primary key&lt;/cell&gt;
          &lt;cell&gt;3.57 Œºs (280.3k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Update one field&lt;/cell&gt;
          &lt;cell&gt;5.22 Œºs (191.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Delete&lt;/cell&gt;
          &lt;cell&gt;191 Œºs (5.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Select with &lt;code&gt;json_extract()&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;4.27 Œºs (234.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;diskcache&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;cache.set(key, obj)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;23.9 Œºs (41.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;cache.get(key)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;4.25 Œºs (235.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;cache.delete(key)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;51.9 Œºs (19.3k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Check key exists&lt;/cell&gt;
          &lt;cell&gt;1.91 Œºs (523.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;MongoDB&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;insert_one()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;119 Œºs (8.4k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;find_one()&lt;/code&gt; by &lt;code&gt;_id&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;121 Œºs (8.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;find_one()&lt;/code&gt; by nested field&lt;/cell&gt;
          &lt;cell&gt;124 Œºs (8.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;update_one()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;115 Œºs (8.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;delete_one()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;30.4 ns (32.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Comparison Table&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;SQLite&lt;/cell&gt;
          &lt;cell role="head"&gt;diskcache&lt;/cell&gt;
          &lt;cell role="head"&gt;MongoDB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write one object&lt;/cell&gt;
          &lt;cell&gt;192 Œºs (5.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;23.9 Œºs (41.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;119 Œºs (8.4k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read by key/id&lt;/cell&gt;
          &lt;cell&gt;3.57 Œºs (280.3k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;4.25 Œºs (235.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;121 Œºs (8.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read by nested field&lt;/cell&gt;
          &lt;cell&gt;4.27 Œºs (234.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;N/A&lt;/cell&gt;
          &lt;cell&gt;124 Œºs (8.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Update one field&lt;/cell&gt;
          &lt;cell&gt;5.22 Œºs (191.7k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;23.9 Œºs (41.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;115 Œºs (8.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Delete&lt;/cell&gt;
          &lt;cell&gt;191 Œºs (5.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;51.9 Œºs (19.3k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;30.4 ns (32.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;Note: MongoDB is a victim of network access version in-process access.&lt;/p&gt;
      &lt;head rend="h2"&gt;Function and Call Overhead&lt;/head&gt;
      &lt;p&gt;The hidden cost of function calls, exceptions, and async.&lt;/p&gt;
      &lt;head rend="h3"&gt;Function Calls&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty function call&lt;/cell&gt;
          &lt;cell&gt;22.4 ns (44.6M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Function with 5 arguments&lt;/cell&gt;
          &lt;cell&gt;24.0 ns (41.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Method call on object&lt;/cell&gt;
          &lt;cell&gt;23.3 ns (42.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Lambda call&lt;/cell&gt;
          &lt;cell&gt;19.7 ns (50.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Built-in function (&lt;code&gt;len()&lt;/code&gt;)&lt;/cell&gt;
          &lt;cell&gt;17.1 ns (58.4M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Exceptions&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;try/except&lt;/code&gt; (no exception raised)&lt;/cell&gt;
          &lt;cell&gt;21.5 ns (46.5M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;try/except&lt;/code&gt; (exception raised)&lt;/cell&gt;
          &lt;cell&gt;139 ns (7.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Type Checking&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;isinstance()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;18.3 ns (54.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;type() == type&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;21.8 ns (46.0M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Async Overhead&lt;/head&gt;
      &lt;p&gt;The cost of async machinery.&lt;/p&gt;
      &lt;head rend="h3"&gt;Coroutine Creation&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Create coroutine object (no await)&lt;/cell&gt;
          &lt;cell&gt;47.0 ns (21.3M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Create coroutine (with return value)&lt;/cell&gt;
          &lt;cell&gt;45.3 ns (22.1M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Running Coroutines&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;run_until_complete(empty)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;27.6 Œºs (36.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;run_until_complete(return value)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;26.6 Œºs (37.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Run nested await&lt;/cell&gt;
          &lt;cell&gt;28.9 Œºs (34.6k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Run 3 sequential awaits&lt;/cell&gt;
          &lt;cell&gt;27.9 Œºs (35.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;asyncio.sleep()&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;asyncio.sleep(0)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;39.4 Œºs (25.4k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Coroutine with &lt;code&gt;sleep(0)&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;41.8 Œºs (23.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;asyncio.gather()&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;gather()&lt;/code&gt; 5 coroutines&lt;/cell&gt;
          &lt;cell&gt;49.7 Œºs (20.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;gather()&lt;/code&gt; 10 coroutines&lt;/cell&gt;
          &lt;cell&gt;55.0 Œºs (18.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;gather()&lt;/code&gt; 100 coroutines&lt;/cell&gt;
          &lt;cell&gt;155 Œºs (6.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Task Creation&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;create_task()&lt;/code&gt; + await&lt;/cell&gt;
          &lt;cell&gt;52.8 Œºs (18.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Create 10 tasks + gather&lt;/cell&gt;
          &lt;cell&gt;85.5 Œºs (11.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Async Context Managers &amp;amp; Iteration&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;async with&lt;/code&gt; (context manager)&lt;/cell&gt;
          &lt;cell&gt;29.5 Œºs (33.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;async for&lt;/code&gt; (5 items)&lt;/cell&gt;
          &lt;cell&gt;30.0 Œºs (33.3k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;async for&lt;/code&gt; (100 items)&lt;/cell&gt;
          &lt;cell&gt;36.4 Œºs (27.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Sync vs Async Comparison&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Sync function call&lt;/cell&gt;
          &lt;cell&gt;20.3 ns (49.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Async equivalent (&lt;code&gt;run_until_complete&lt;/code&gt;)&lt;/cell&gt;
          &lt;cell&gt;28.2 Œºs (35.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Methodology&lt;/head&gt;
      &lt;head rend="h3"&gt;Benchmarking Approach&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;All benchmarks run multiple times and with warmup not timed&lt;/item&gt;
        &lt;item&gt;Timing uses &lt;code&gt;timeit&lt;/code&gt; or &lt;code&gt;perf_counter_ns&lt;/code&gt; as appropriate&lt;/item&gt;
        &lt;item&gt;Memory measured with &lt;code&gt;sys.getsizeof()&lt;/code&gt; and &lt;code&gt;tracemalloc&lt;/code&gt;&lt;/item&gt;
        &lt;item&gt;Results are median of N runs&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Environment&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;OS: macOS 26.2&lt;/item&gt;
        &lt;item&gt;Python: 3.14.2 (CPython)&lt;/item&gt;
        &lt;item&gt;CPU: ARM - 14 cores (14 logical)&lt;/item&gt;
        &lt;item&gt;RAM: 24.0 GB&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Code Repository&lt;/head&gt;
      &lt;p&gt;All benchmark code available at: https://github.com/mkennedy/python-numbers-everyone-should-know&lt;/p&gt;
      &lt;head rend="h2"&gt;Key Takeaways&lt;/head&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;Memory overhead: Python objects have significant memory overhead - even an empty list is 56 bytes&lt;/item&gt;
        &lt;item&gt;Dict/set speed: Dictionary and set lookups are extremely fast (O(1) average case) compared to list membership checks (O(n))&lt;/item&gt;
        &lt;item&gt;JSON performance: Alternative JSON libraries like &lt;code&gt;orjson&lt;/code&gt; and &lt;code&gt;msgspec&lt;/code&gt; are 3-8x faster than stdlib &lt;code&gt;json&lt;/code&gt;&lt;/item&gt;
        &lt;item&gt;Async overhead: Creating and awaiting coroutines has measurable overhead - only use async when you need concurrency&lt;/item&gt;
        &lt;item&gt;&lt;code&gt;__slots__&lt;/code&gt; tradeoff: &lt;code&gt;__slots__&lt;/code&gt; saves significant memory (over 2x for collections) with virtually no performance impact&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Last updated: 2026-01-01&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://danwang.co/2025-letter/"/><published>2026-01-01T14:32:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46454470</id><title>Python numbers every programmer should know</title><updated>2026-01-01T21:38:14.997310+00:00</updated><content>&lt;doc fingerprint="24f9e010dc8092c8"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;There are numbers every Python programmer should know. For example, how fast or slow is it to add an item to a list in Python? What about opening a file? Is that less than a millisecond? Is there something that makes that slower than you might have guessed? If you have a performance sensitive algorithm, which data structure should you use? How much memory does a floating point number use? What about a single character or the empty string? How fast is FastAPI compared to Django?&lt;/p&gt;
      &lt;p&gt;I wanted to take a moment and write down performance numbers specifically focused on Python developers. Below you will find an extensive table of such values. They are grouped by category. And I provided a couple of graphs for the more significant analysis below the table.&lt;/p&gt;
      &lt;head rend="h3"&gt;Source code for the benchmarks&lt;/head&gt;
      &lt;p&gt;This article is posted without any code. I encourage you to dig into the benchmarks. The code is available on GitHub at:&lt;/p&gt;
      &lt;p&gt;https://github.com/mikeckennedy/python-numbers-everyone-should-know&lt;/p&gt;
      &lt;p&gt;The benchmarks were run on the sytem described in this table. While yours may be faster or slower, the most important thing to consider is relative comparisons.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Property&lt;/cell&gt;
          &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Python Version&lt;/cell&gt;
          &lt;cell&gt;CPython 3.14.2&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Hardware&lt;/cell&gt;
          &lt;cell&gt;Mac Mini M4 Pro&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Platform&lt;/cell&gt;
          &lt;cell&gt;macOS Tahoe (26.2)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Processor&lt;/cell&gt;
          &lt;cell&gt;ARM&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;CPU Cores&lt;/cell&gt;
          &lt;cell&gt;14 physical / 14 logical&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;RAM&lt;/cell&gt;
          &lt;cell&gt;24 GB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Timestamp&lt;/cell&gt;
          &lt;cell&gt;2025-12-30&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;
      &lt;p&gt;Inspired by Latency Numbers Every Programmer Should Know and similar resources.&lt;/p&gt;
      &lt;head rend="h2"&gt;Python numbers you should know&lt;/head&gt;
      &lt;p&gt;More analysis and graphs by category below the table.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Category&lt;/cell&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
          &lt;cell role="head"&gt;Memory&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üíæ Memory&lt;/cell&gt;
          &lt;cell&gt;Empty Python process&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;15.73 MB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty string&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;41 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;100-char string&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;141 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Small int (0-256)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;28 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Large int&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;28 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Float&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;24 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty list&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;56 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List with 1,000 ints&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;35.2 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List with 1,000 floats&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;32.1 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty dict&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;64 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Dict with 1,000 items&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;63.4 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty set&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;216 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set with 1,000 items&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;59.6 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Regular class instance (5 attrs)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;694 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;__slots__&lt;/code&gt; class instance (5 attrs)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;212 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List of 1,000 regular class instances&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;165.2 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List of 1,000 &lt;code&gt;__slots__&lt;/code&gt; class instances&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;79.1 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;dataclass instance&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;694 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;namedtuple instance&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;228 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;‚öôÔ∏è Basic Ops&lt;/cell&gt;
          &lt;cell&gt;Add two integers&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Add two floats&lt;/cell&gt;
          &lt;cell&gt;18.4 ns (54.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;String concatenation (small)&lt;/cell&gt;
          &lt;cell&gt;39.1 ns (25.6M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;f-string formatting&lt;/cell&gt;
          &lt;cell&gt;64.9 ns (15.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;.format()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;103 ns (9.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;%&lt;/code&gt; formatting&lt;/cell&gt;
          &lt;cell&gt;89.8 ns (11.1M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List append&lt;/cell&gt;
          &lt;cell&gt;28.7 ns (34.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List comprehension (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;9.45 Œºs (105.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Equivalent for-loop (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;11.9 Œºs (83.9k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üì¶ Collections&lt;/cell&gt;
          &lt;cell&gt;Dict lookup by key&lt;/cell&gt;
          &lt;cell&gt;21.9 ns (45.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set membership check&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List index access&lt;/cell&gt;
          &lt;cell&gt;17.6 ns (56.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List membership check (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;3.85 Œºs (259.6k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;len()&lt;/code&gt; on list&lt;/cell&gt;
          &lt;cell&gt;18.8 ns (53.3M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Iterate 1,000-item list&lt;/cell&gt;
          &lt;cell&gt;7.87 Œºs (127.0k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Iterate 1,000-item dict&lt;/cell&gt;
          &lt;cell&gt;8.74 Œºs (114.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;sum()&lt;/code&gt; of 1,000 ints&lt;/cell&gt;
          &lt;cell&gt;1.87 Œºs (534.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üè∑Ô∏è Attributes&lt;/cell&gt;
          &lt;cell&gt;Read from regular class&lt;/cell&gt;
          &lt;cell&gt;14.1 ns (70.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write to regular class&lt;/cell&gt;
          &lt;cell&gt;15.7 ns (63.6M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read from &lt;code&gt;__slots__&lt;/code&gt; class&lt;/cell&gt;
          &lt;cell&gt;14.1 ns (70.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write to &lt;code&gt;__slots__&lt;/code&gt; class&lt;/cell&gt;
          &lt;cell&gt;16.4 ns (60.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read from &lt;code&gt;@property&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;getattr()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;13.8 ns (72.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;hasattr()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;23.8 ns (41.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üìÑ JSON&lt;/cell&gt;
          &lt;cell&gt;&lt;code&gt;json.dumps()&lt;/code&gt; (simple)&lt;/cell&gt;
          &lt;cell&gt;708 ns (1.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.loads()&lt;/code&gt; (simple)&lt;/cell&gt;
          &lt;cell&gt;714 ns (1.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.dumps()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;2.65 Œºs (376.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.loads()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;2.22 Œºs (449.9k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;orjson.dumps()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;310 ns (3.2M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;orjson.loads()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;839 ns (1.2M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;ujson.dumps()&lt;/code&gt; (complex)&lt;/cell&gt;
          &lt;cell&gt;1.64 Œºs (611.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;msgspec&lt;/code&gt; encode (complex)&lt;/cell&gt;
          &lt;cell&gt;445 ns (2.2M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Pydantic &lt;code&gt;model_dump_json()&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;1.54 Œºs (647.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Pydantic &lt;code&gt;model_validate_json()&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;2.99 Œºs (334.7k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üåê Web Frameworks&lt;/cell&gt;
          &lt;cell&gt;Flask (return JSON)&lt;/cell&gt;
          &lt;cell&gt;16.5 Œºs (60.7k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Django (return JSON)&lt;/cell&gt;
          &lt;cell&gt;18.1 Œºs (55.4k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;FastAPI (return JSON)&lt;/cell&gt;
          &lt;cell&gt;8.63 Œºs (115.9k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Starlette (return JSON)&lt;/cell&gt;
          &lt;cell&gt;8.01 Œºs (124.8k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Litestar (return JSON)&lt;/cell&gt;
          &lt;cell&gt;8.19 Œºs (122.1k req/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üìÅ File I/O&lt;/cell&gt;
          &lt;cell&gt;Open and close file&lt;/cell&gt;
          &lt;cell&gt;9.05 Œºs (110.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read 1KB file&lt;/cell&gt;
          &lt;cell&gt;10.0 Œºs (99.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write 1KB file&lt;/cell&gt;
          &lt;cell&gt;35.1 Œºs (28.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write 1MB file&lt;/cell&gt;
          &lt;cell&gt;207 Œºs (4.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;pickle.dumps()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;1.30 Œºs (769.6k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;pickle.loads()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;1.44 Œºs (695.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üóÑÔ∏è Database&lt;/cell&gt;
          &lt;cell&gt;SQLite insert (JSON blob)&lt;/cell&gt;
          &lt;cell&gt;192 Œºs (5.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;SQLite select by PK&lt;/cell&gt;
          &lt;cell&gt;3.57 Œºs (280.3k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;SQLite update one field&lt;/cell&gt;
          &lt;cell&gt;5.22 Œºs (191.7k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;diskcache set&lt;/cell&gt;
          &lt;cell&gt;23.9 Œºs (41.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;diskcache get&lt;/cell&gt;
          &lt;cell&gt;4.25 Œºs (235.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;MongoDB insert_one&lt;/cell&gt;
          &lt;cell&gt;119 Œºs (8.4k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;MongoDB find_one by _id&lt;/cell&gt;
          &lt;cell&gt;121 Œºs (8.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;MongoDB find_one by nested field&lt;/cell&gt;
          &lt;cell&gt;124 Œºs (8.1k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;üìû Functions&lt;/cell&gt;
          &lt;cell&gt;Empty function call&lt;/cell&gt;
          &lt;cell&gt;22.4 ns (44.6M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Function with 5 args&lt;/cell&gt;
          &lt;cell&gt;24.0 ns (41.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Method call&lt;/cell&gt;
          &lt;cell&gt;23.3 ns (42.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Lambda call&lt;/cell&gt;
          &lt;cell&gt;19.7 ns (50.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;try/except (no exception)&lt;/cell&gt;
          &lt;cell&gt;21.5 ns (46.5M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;try/except (exception raised)&lt;/cell&gt;
          &lt;cell&gt;139 ns (7.2M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;isinstance()&lt;/code&gt; check&lt;/cell&gt;
          &lt;cell&gt;18.3 ns (54.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;‚è±Ô∏è Async&lt;/cell&gt;
          &lt;cell&gt;Create coroutine object&lt;/cell&gt;
          &lt;cell&gt;47.0 ns (21.3M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;run_until_complete(empty)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;27.6 Œºs (36.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;asyncio.sleep(0)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;39.4 Œºs (25.4k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;gather()&lt;/code&gt; 10 coroutines&lt;/cell&gt;
          &lt;cell&gt;55.0 Œºs (18.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;create_task()&lt;/code&gt; + await&lt;/cell&gt;
          &lt;cell&gt;52.8 Œºs (18.9k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;async with&lt;/code&gt; (context manager)&lt;/cell&gt;
          &lt;cell&gt;29.5 Œºs (33.9k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Memory Costs&lt;/head&gt;
      &lt;p&gt;Understanding how much memory different Python objects consume.&lt;/p&gt;
      &lt;head rend="h3"&gt;An empty Python process uses 15.73 MB&lt;/head&gt;
      &lt;head rend="h3"&gt;Strings&lt;/head&gt;
      &lt;p&gt;The rule of thumb for strings is the core string object takes 41 bytes. Each additional character is 1 byte.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;String&lt;/cell&gt;
          &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty string &lt;code&gt;""&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;41 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;1-char string &lt;code&gt;"a"&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;42 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;100-char string&lt;/cell&gt;
          &lt;cell&gt;141 bytes&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Numbers&lt;/head&gt;
      &lt;p&gt;Numbers are surprisingly large in Python. They have to derive from CPython‚Äôs &lt;code&gt;PyObject&lt;/code&gt; and are subject to reference counting for garabage collection, they exceed our typical mental model many of:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;2 bytes = short int&lt;/item&gt;
        &lt;item&gt;4 bytes = long int&lt;/item&gt;
        &lt;item&gt;etc.&lt;/item&gt;
      &lt;/list&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Type&lt;/cell&gt;
          &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Small int (0-256, cached)&lt;/cell&gt;
          &lt;cell&gt;28 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Large int (1000)&lt;/cell&gt;
          &lt;cell&gt;28 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Very large int (10**100)&lt;/cell&gt;
          &lt;cell&gt;72 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Float&lt;/cell&gt;
          &lt;cell&gt;24 bytes&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Collections&lt;/head&gt;
      &lt;p&gt;Collections are amazing in Python. Dynamically growing lists. Ultra high-perf dictionaries and sets. Here is the empty and ‚Äúfull‚Äù overhead of each.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Collection&lt;/cell&gt;
          &lt;cell role="head"&gt;Empty&lt;/cell&gt;
          &lt;cell role="head"&gt;1,000 items&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List (ints)&lt;/cell&gt;
          &lt;cell&gt;56 bytes&lt;/cell&gt;
          &lt;cell&gt;35.2 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List (floats)&lt;/cell&gt;
          &lt;cell&gt;56 bytes&lt;/cell&gt;
          &lt;cell&gt;32.1 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Dict&lt;/cell&gt;
          &lt;cell&gt;64 bytes&lt;/cell&gt;
          &lt;cell&gt;63.4 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set&lt;/cell&gt;
          &lt;cell&gt;216 bytes&lt;/cell&gt;
          &lt;cell&gt;59.6 KB&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Classes and Instances&lt;/head&gt;
      &lt;p&gt;Slots are an interesting addition to Python classes. They remove the entire concept of a &lt;code&gt;__dict__&lt;/code&gt; for tracking fields and other values. Even for a single instance, slots classes are significantly smaller (212 bytes vs 694 bytes for 5 attributes). If you are holding a large number of them in memory for a list or cache, the memory savings of a slots class becomes very dramatic - over 2x less memory usage. Luckily for most use-cases, just adding a slots entry saves a ton of memory with minimal effort.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Type&lt;/cell&gt;
          &lt;cell role="head"&gt;Empty&lt;/cell&gt;
          &lt;cell role="head"&gt;5 attributes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Regular class&lt;/cell&gt;
          &lt;cell&gt;344 bytes&lt;/cell&gt;
          &lt;cell&gt;694 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;__slots__&lt;/code&gt; class&lt;/cell&gt;
          &lt;cell&gt;32 bytes&lt;/cell&gt;
          &lt;cell&gt;212 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;dataclass&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;694 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;@dataclass(slots=True)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;212 bytes&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;namedtuple&lt;/cell&gt;
          &lt;cell&gt;‚Äî&lt;/cell&gt;
          &lt;cell&gt;228 bytes&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;Aggregate Memory Usage (1,000 instances):&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Type&lt;/cell&gt;
          &lt;cell role="head"&gt;Total Memory&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List of 1,000 regular class instances&lt;/cell&gt;
          &lt;cell&gt;165.2 KB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List of 1,000 &lt;code&gt;__slots__&lt;/code&gt; class instances&lt;/cell&gt;
          &lt;cell&gt;79.1 KB&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Basic Operations&lt;/head&gt;
      &lt;p&gt;The cost of fundamental Python operations: Way slower than C/C++/C# but still quite fast. I added a brief comparison to C# to the source repo.&lt;/p&gt;
      &lt;head rend="h3"&gt;Arithmetic&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Add two integers&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Add two floats&lt;/cell&gt;
          &lt;cell&gt;18.4 ns (54.4M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Multiply two integers&lt;/cell&gt;
          &lt;cell&gt;19.4 ns (51.6M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;String Operations&lt;/head&gt;
      &lt;p&gt;String operations in Python are fast as well. f-strings are the fastest formatting style, while even the slowest style is still measured in just nano-seconds.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Concatenation (&lt;code&gt;+&lt;/code&gt;)&lt;/cell&gt;
          &lt;cell&gt;39.1 ns (25.6M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;f-string&lt;/cell&gt;
          &lt;cell&gt;64.9 ns (15.4M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;.format()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;103 ns (9.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;%&lt;/code&gt; formatting&lt;/cell&gt;
          &lt;cell&gt;89.8 ns (11.1M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;List Operations&lt;/head&gt;
      &lt;p&gt;List operations are very fast in Python. Adding a single item usually requires 28ns. Said another way, you can do 35M appends per second. This is unless the list has to expand using something like a doubling algorithm. You can see this in the ops/sec for 1,000 items.&lt;/p&gt;
      &lt;p&gt;Surprisingly, list comprehensions are 26% faster than the equivalent for loops with append statements.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;list.append()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;28.7 ns (34.8M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List comprehension (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;9.45 Œºs (105.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Equivalent for-loop (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;11.9 Œºs (83.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Collection Access and Iteration&lt;/head&gt;
      &lt;p&gt;How fast can you get data out of Python‚Äôs built-in collections? Here is a dramatic example of how much faster the correct data structure is. &lt;code&gt;item in set&lt;/code&gt; or &lt;code&gt;item in dict&lt;/code&gt; is 200x faster than &lt;code&gt;item in list&lt;/code&gt; for just 1,000 items!&lt;/p&gt;
      &lt;p&gt;The graph below is non-linear in the x-axis.&lt;/p&gt;
      &lt;head rend="h3"&gt;Access by Key/Index&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Dict lookup by key&lt;/cell&gt;
          &lt;cell&gt;21.9 ns (45.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set membership (&lt;code&gt;in&lt;/code&gt;)&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List index access&lt;/cell&gt;
          &lt;cell&gt;17.6 ns (56.8M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List membership (&lt;code&gt;in&lt;/code&gt;, 1,000 items)&lt;/cell&gt;
          &lt;cell&gt;3.85 Œºs (259.6k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Length&lt;/head&gt;
      &lt;p&gt;&lt;code&gt;len()&lt;/code&gt; is very fast. Maybe we don‚Äôt have to optimize it out of the test condition on a while loop looping 100 times after all.&lt;/p&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Collection&lt;/cell&gt;
          &lt;cell role="head"&gt;&lt;code&gt;len()&lt;/code&gt; time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;List (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;18.8 ns (53.3M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Dict (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;17.6 ns (56.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Set (1,000 items)&lt;/cell&gt;
          &lt;cell&gt;18.0 ns (55.5M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Iteration&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Iterate 1,000-item list&lt;/cell&gt;
          &lt;cell&gt;7.87 Œºs (127.0k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Iterate 1,000-item dict (keys)&lt;/cell&gt;
          &lt;cell&gt;8.74 Œºs (114.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;sum()&lt;/code&gt; of 1,000 integers&lt;/cell&gt;
          &lt;cell&gt;1.87 Œºs (534.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Class and Object Attributes&lt;/head&gt;
      &lt;p&gt;The cost of reading and writing attributes, and how &lt;code&gt;__slots__&lt;/code&gt; changes things. Slots saves over 2x the memory usage on large collections, with virtually identical attribute access speed.&lt;/p&gt;
      &lt;head rend="h3"&gt;Attribute Access&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Regular Class&lt;/cell&gt;
          &lt;cell role="head"&gt;&lt;code&gt;__slots__&lt;/code&gt; Class&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read attribute&lt;/cell&gt;
          &lt;cell&gt;14.1 ns (70.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;14.1 ns (70.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write attribute&lt;/cell&gt;
          &lt;cell&gt;15.7 ns (63.6M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;16.4 ns (60.8M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Other Attribute Operations&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read &lt;code&gt;@property&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;19.0 ns (52.8M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;getattr(obj, 'attr')&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;13.8 ns (72.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;hasattr(obj, 'attr')&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;23.8 ns (41.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;JSON and Serialization&lt;/head&gt;
      &lt;p&gt;Comparing standard library JSON with optimized alternatives. &lt;code&gt;orjson&lt;/code&gt; handles more data types and is over 8x faster than standard lib &lt;code&gt;json&lt;/code&gt; for complex objects. Impressive!&lt;/p&gt;
      &lt;head rend="h3"&gt;Serialization (dumps)&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Library&lt;/cell&gt;
          &lt;cell role="head"&gt;Simple Object&lt;/cell&gt;
          &lt;cell role="head"&gt;Complex Object&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json&lt;/code&gt; (stdlib)&lt;/cell&gt;
          &lt;cell&gt;708 ns (1.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;2.65 Œºs (376.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;orjson&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;60.9 ns (16.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;310 ns (3.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;ujson&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;264 ns (3.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;1.64 Œºs (611.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;msgspec&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;92.3 ns (10.8M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;445 ns (2.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Deserialization (loads)&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Library&lt;/cell&gt;
          &lt;cell role="head"&gt;Simple Object&lt;/cell&gt;
          &lt;cell role="head"&gt;Complex Object&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json&lt;/code&gt; (stdlib)&lt;/cell&gt;
          &lt;cell&gt;714 ns (1.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;2.22 Œºs (449.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;orjson&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;106 ns (9.4M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;839 ns (1.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;ujson&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;268 ns (3.7M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;1.46 Œºs (682.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;msgspec&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;101 ns (9.9M ops/sec)&lt;/cell&gt;
          &lt;cell&gt;850 ns (1.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Pydantic&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;model_dump_json()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;1.54 Œºs (647.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;model_validate_json()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;2.99 Œºs (334.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;model_dump()&lt;/code&gt; (to dict)&lt;/cell&gt;
          &lt;cell&gt;1.71 Œºs (585.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;model_validate()&lt;/code&gt; (from dict)&lt;/cell&gt;
          &lt;cell&gt;2.30 Œºs (435.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Web Frameworks&lt;/head&gt;
      &lt;p&gt;Returning a simple JSON response. Benchmarked with &lt;code&gt;wrk&lt;/code&gt; against localhost running 4 works in Granian. Each framework returns the same JSON payload from a minimal endpoint. No database access or that sort of thing. This is just how much overhead/perf do we get from each framework itself. The code we write that runs within those view methods is largely the same.&lt;/p&gt;
      &lt;head rend="h3"&gt;Results&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Framework&lt;/cell&gt;
          &lt;cell role="head"&gt;Requests/sec&lt;/cell&gt;
          &lt;cell role="head"&gt;Latency (p99)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Flask&lt;/cell&gt;
          &lt;cell&gt;16.5 Œºs (60.7k req/sec)&lt;/cell&gt;
          &lt;cell&gt;20.85 ms (48.0 ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Django&lt;/cell&gt;
          &lt;cell&gt;18.1 Œºs (55.4k req/sec)&lt;/cell&gt;
          &lt;cell&gt;170.3 ms (5.9 ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;FastAPI&lt;/cell&gt;
          &lt;cell&gt;8.63 Œºs (115.9k req/sec)&lt;/cell&gt;
          &lt;cell&gt;1.530 ms (653.6 ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Starlette&lt;/cell&gt;
          &lt;cell&gt;8.01 Œºs (124.8k req/sec)&lt;/cell&gt;
          &lt;cell&gt;930 Œºs (1.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Litestar&lt;/cell&gt;
          &lt;cell&gt;8.19 Œºs (122.1k req/sec)&lt;/cell&gt;
          &lt;cell&gt;1.010 ms (990.1 ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;File I/O&lt;/head&gt;
      &lt;p&gt;Reading and writing files of various sizes. Note that the graph is non-linear in y-axis.&lt;/p&gt;
      &lt;head rend="h3"&gt;Basic Operations&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Open and close (no read)&lt;/cell&gt;
          &lt;cell&gt;9.05 Œºs (110.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read 1KB file&lt;/cell&gt;
          &lt;cell&gt;10.0 Œºs (99.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read 1MB file&lt;/cell&gt;
          &lt;cell&gt;33.6 Œºs (29.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write 1KB file&lt;/cell&gt;
          &lt;cell&gt;35.1 Œºs (28.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write 1MB file&lt;/cell&gt;
          &lt;cell&gt;207 Œºs (4.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Pickle vs JSON to Disk&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;pickle.dumps()&lt;/code&gt; (complex obj)&lt;/cell&gt;
          &lt;cell&gt;1.30 Œºs (769.6k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;pickle.loads()&lt;/code&gt; (complex obj)&lt;/cell&gt;
          &lt;cell&gt;1.44 Œºs (695.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.dumps()&lt;/code&gt; (complex obj)&lt;/cell&gt;
          &lt;cell&gt;2.72 Œºs (367.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;json.loads()&lt;/code&gt; (complex obj)&lt;/cell&gt;
          &lt;cell&gt;2.35 Œºs (425.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Database and Persistence&lt;/head&gt;
      &lt;p&gt;Comparing SQLite, diskcache, and MongoDB using the same complex object.&lt;/p&gt;
      &lt;head rend="h3"&gt;Test Object&lt;/head&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;user_data = {
    "id": 12345,
    "username": "alice_dev",
    "email": "alice@example.com",
    "profile": {
        "bio": "Software engineer who loves Python",
        "location": "Portland, OR",
        "website": "https://alice.dev",
        "joined": "2020-03-15T08:30:00Z"
    },
    "posts": [
        {"id": 1, "title": "First Post", "tags": ["python", "tutorial"], "views": 1520},
        {"id": 2, "title": "Second Post", "tags": ["rust", "wasm"], "views": 843},
        {"id": 3, "title": "Third Post", "tags": ["python", "async"], "views": 2341},
    ],
    "settings": {
        "theme": "dark",
        "notifications": True,
        "email_frequency": "weekly"
    }
}
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
      &lt;head rend="h3"&gt;SQLite (JSON blob approach)&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Insert one object&lt;/cell&gt;
          &lt;cell&gt;192 Œºs (5.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Select by primary key&lt;/cell&gt;
          &lt;cell&gt;3.57 Œºs (280.3k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Update one field&lt;/cell&gt;
          &lt;cell&gt;5.22 Œºs (191.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Delete&lt;/cell&gt;
          &lt;cell&gt;191 Œºs (5.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Select with &lt;code&gt;json_extract()&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;4.27 Œºs (234.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;diskcache&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;cache.set(key, obj)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;23.9 Œºs (41.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;cache.get(key)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;4.25 Œºs (235.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;cache.delete(key)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;51.9 Œºs (19.3k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Check key exists&lt;/cell&gt;
          &lt;cell&gt;1.91 Œºs (523.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;MongoDB&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;insert_one()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;119 Œºs (8.4k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;find_one()&lt;/code&gt; by &lt;code&gt;_id&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;121 Œºs (8.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;find_one()&lt;/code&gt; by nested field&lt;/cell&gt;
          &lt;cell&gt;124 Œºs (8.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;update_one()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;115 Œºs (8.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;delete_one()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;30.4 ns (32.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Comparison Table&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;SQLite&lt;/cell&gt;
          &lt;cell role="head"&gt;diskcache&lt;/cell&gt;
          &lt;cell role="head"&gt;MongoDB&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Write one object&lt;/cell&gt;
          &lt;cell&gt;192 Œºs (5.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;23.9 Œºs (41.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;119 Œºs (8.4k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read by key/id&lt;/cell&gt;
          &lt;cell&gt;3.57 Œºs (280.3k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;4.25 Œºs (235.5k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;121 Œºs (8.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Read by nested field&lt;/cell&gt;
          &lt;cell&gt;4.27 Œºs (234.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;N/A&lt;/cell&gt;
          &lt;cell&gt;124 Œºs (8.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Update one field&lt;/cell&gt;
          &lt;cell&gt;5.22 Œºs (191.7k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;23.9 Œºs (41.8k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;115 Œºs (8.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Delete&lt;/cell&gt;
          &lt;cell&gt;191 Œºs (5.2k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;51.9 Œºs (19.3k ops/sec)&lt;/cell&gt;
          &lt;cell&gt;30.4 ns (32.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;p&gt;Note: MongoDB is a victim of network access version in-process access.&lt;/p&gt;
      &lt;head rend="h2"&gt;Function and Call Overhead&lt;/head&gt;
      &lt;p&gt;The hidden cost of function calls, exceptions, and async.&lt;/p&gt;
      &lt;head rend="h3"&gt;Function Calls&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Empty function call&lt;/cell&gt;
          &lt;cell&gt;22.4 ns (44.6M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Function with 5 arguments&lt;/cell&gt;
          &lt;cell&gt;24.0 ns (41.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Method call on object&lt;/cell&gt;
          &lt;cell&gt;23.3 ns (42.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Lambda call&lt;/cell&gt;
          &lt;cell&gt;19.7 ns (50.9M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Built-in function (&lt;code&gt;len()&lt;/code&gt;)&lt;/cell&gt;
          &lt;cell&gt;17.1 ns (58.4M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Exceptions&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;try/except&lt;/code&gt; (no exception raised)&lt;/cell&gt;
          &lt;cell&gt;21.5 ns (46.5M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;try/except&lt;/code&gt; (exception raised)&lt;/cell&gt;
          &lt;cell&gt;139 ns (7.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Type Checking&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;isinstance()&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;18.3 ns (54.7M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;type() == type&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;21.8 ns (46.0M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Async Overhead&lt;/head&gt;
      &lt;p&gt;The cost of async machinery.&lt;/p&gt;
      &lt;head rend="h3"&gt;Coroutine Creation&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Create coroutine object (no await)&lt;/cell&gt;
          &lt;cell&gt;47.0 ns (21.3M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Create coroutine (with return value)&lt;/cell&gt;
          &lt;cell&gt;45.3 ns (22.1M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Running Coroutines&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;run_until_complete(empty)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;27.6 Œºs (36.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;run_until_complete(return value)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;26.6 Œºs (37.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Run nested await&lt;/cell&gt;
          &lt;cell&gt;28.9 Œºs (34.6k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Run 3 sequential awaits&lt;/cell&gt;
          &lt;cell&gt;27.9 Œºs (35.8k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;asyncio.sleep()&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;
            &lt;code&gt;asyncio.sleep(0)&lt;/code&gt;
          &lt;/cell&gt;
          &lt;cell&gt;39.4 Œºs (25.4k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Coroutine with &lt;code&gt;sleep(0)&lt;/code&gt;&lt;/cell&gt;
          &lt;cell&gt;41.8 Œºs (23.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;asyncio.gather()&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;gather()&lt;/code&gt; 5 coroutines&lt;/cell&gt;
          &lt;cell&gt;49.7 Œºs (20.1k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;gather()&lt;/code&gt; 10 coroutines&lt;/cell&gt;
          &lt;cell&gt;55.0 Œºs (18.2k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;gather()&lt;/code&gt; 100 coroutines&lt;/cell&gt;
          &lt;cell&gt;155 Œºs (6.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Task Creation&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;create_task()&lt;/code&gt; + await&lt;/cell&gt;
          &lt;cell&gt;52.8 Œºs (18.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Create 10 tasks + gather&lt;/cell&gt;
          &lt;cell&gt;85.5 Œºs (11.7k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Async Context Managers &amp;amp; Iteration&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;async with&lt;/code&gt; (context manager)&lt;/cell&gt;
          &lt;cell&gt;29.5 Œºs (33.9k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;async for&lt;/code&gt; (5 items)&lt;/cell&gt;
          &lt;cell&gt;30.0 Œºs (33.3k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;&lt;code&gt;async for&lt;/code&gt; (100 items)&lt;/cell&gt;
          &lt;cell&gt;36.4 Œºs (27.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h3"&gt;Sync vs Async Comparison&lt;/head&gt;
      &lt;table&gt;
        &lt;row&gt;
          &lt;cell role="head"&gt;Operation&lt;/cell&gt;
          &lt;cell role="head"&gt;Time&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Sync function call&lt;/cell&gt;
          &lt;cell&gt;20.3 ns (49.2M ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
        &lt;row&gt;
          &lt;cell&gt;Async equivalent (&lt;code&gt;run_until_complete&lt;/code&gt;)&lt;/cell&gt;
          &lt;cell&gt;28.2 Œºs (35.5k ops/sec)&lt;/cell&gt;
        &lt;/row&gt;
      &lt;/table&gt;
      &lt;head rend="h2"&gt;Methodology&lt;/head&gt;
      &lt;head rend="h3"&gt;Benchmarking Approach&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;All benchmarks run multiple times and with warmup not timed&lt;/item&gt;
        &lt;item&gt;Timing uses &lt;code&gt;timeit&lt;/code&gt; or &lt;code&gt;perf_counter_ns&lt;/code&gt; as appropriate&lt;/item&gt;
        &lt;item&gt;Memory measured with &lt;code&gt;sys.getsizeof()&lt;/code&gt; and &lt;code&gt;tracemalloc&lt;/code&gt;&lt;/item&gt;
        &lt;item&gt;Results are median of N runs&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Environment&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;OS: macOS 26.2&lt;/item&gt;
        &lt;item&gt;Python: 3.14.2 (CPython)&lt;/item&gt;
        &lt;item&gt;CPU: ARM - 14 cores (14 logical)&lt;/item&gt;
        &lt;item&gt;RAM: 24.0 GB&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Code Repository&lt;/head&gt;
      &lt;p&gt;All benchmark code available at: https://github.com/mkennedy/python-numbers-everyone-should-know&lt;/p&gt;
      &lt;head rend="h2"&gt;Key Takeaways&lt;/head&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;Memory overhead: Python objects have significant memory overhead - even an empty list is 56 bytes&lt;/item&gt;
        &lt;item&gt;Dict/set speed: Dictionary and set lookups are extremely fast (O(1) average case) compared to list membership checks (O(n))&lt;/item&gt;
        &lt;item&gt;JSON performance: Alternative JSON libraries like &lt;code&gt;orjson&lt;/code&gt; and &lt;code&gt;msgspec&lt;/code&gt; are 3-8x faster than stdlib &lt;code&gt;json&lt;/code&gt;&lt;/item&gt;
        &lt;item&gt;Async overhead: Creating and awaiting coroutines has measurable overhead - only use async when you need concurrency&lt;/item&gt;
        &lt;item&gt;&lt;code&gt;__slots__&lt;/code&gt; tradeoff: &lt;code&gt;__slots__&lt;/code&gt; saves significant memory (over 2x for collections) with virtually no performance impact&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Last updated: 2026-01-01&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mkennedy.codes/posts/python-numbers-every-programmer-should-know/"/><published>2026-01-01T14:39:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46454587</id><title>Build a Deep Learning Library</title><updated>2026-01-01T21:38:14.484659+00:00</updated><content>&lt;doc fingerprint="b759cf2f81cb5b8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Build a Simple Deep Learning Library&lt;/head&gt;
    &lt;head rend="h1"&gt;Preface&lt;/head&gt;
    &lt;p&gt;Instead of just learning how to use a deep learning library, we are going to learn how to create one.&lt;/p&gt;
    &lt;p&gt;We start with a blank file and NumPy, and we don‚Äôt stop until we have a functional autograd engine and a collection of layer modules. By the end, we will use it to train MNIST, simple CNN and simple ResNet.&lt;/p&gt;
    &lt;p&gt; NoteSupport This Project &lt;/p&gt;
    &lt;p&gt;This book is free to read online. If it helps you, consider paying what you want on Gumroad&lt;/p&gt;
    &lt;p&gt;Questions or feedback? zekcrates@proton.me&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://zekcrates.quarto.pub/deep-learning-library/"/><published>2026-01-01T14:53:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46454693</id><title>Show HN: OpenWorkers ‚Äì Self-hosted Cloudflare workers in Rust</title><updated>2026-01-01T21:38:14.369736+00:00</updated><content>&lt;doc fingerprint="ec56b9328dac36f2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing OpenWorkers&lt;/head&gt;
    &lt;p&gt;Self-hosted Cloudflare Workers in Rust&lt;/p&gt;
    &lt;p&gt;OpenWorkers is an open-source runtime for executing JavaScript in V8 isolates. It brings the power of edge computing to your own infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;What works today&lt;/head&gt;
    &lt;quote&gt;
      &lt;code&gt;export default { async fetch(request, env) { const data = await env.KV.get("key"); const rows = await env.DB.query( "SELECT * FROM users WHERE id = $1", [1] ); return Response.json({ data, rows }); } };&lt;/code&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;head rend="h3"&gt;Bindings&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ KV storage (get, put, delete, list)&lt;/item&gt;
      &lt;item&gt;‚Ä¢ PostgreSQL database&lt;/item&gt;
      &lt;item&gt;‚Ä¢ S3/R2-compatible storage&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Service bindings&lt;/item&gt;
      &lt;item&gt;‚Ä¢ Environment variables &amp;amp; secrets&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Web APIs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚Ä¢ fetch, Request, Response&lt;/item&gt;
      &lt;item&gt;‚Ä¢ ReadableStream&lt;/item&gt;
      &lt;item&gt;‚Ä¢ crypto.subtle&lt;/item&gt;
      &lt;item&gt;‚Ä¢ TextEncoder/Decoder, Blob&lt;/item&gt;
      &lt;item&gt;‚Ä¢ setTimeout, AbortController&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Architecture&lt;/head&gt;
    &lt;quote&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ nginx (proxy) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î∏‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î∏‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ dashboard ‚îÇ ‚îÇ api ‚îÇ ‚îÇ logs * ‚îÇ ‚îÇ runner (x3) * ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î∞‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ postgate * ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î• nats ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê * ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î• PostgreSQL ‚îÇ ‚îÇ scheduler * ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò&lt;/quote&gt;
    &lt;quote&gt;+-------------+ | nginx proxy | +------+------+ | +-------+-------+-------+--------+ | | | | +--+--+ +--+--+ +--+---+ +----------+-+ | dash| | api | |logs *| | runner * x3| +-----+ +--+--+ +--+---+ +-----+------+ | | | +-----+----+ | +------+-----+ |postgate *| +----+ nats | +-----+----+ +------+-----+ | | +-----+------+ +------+-----+ *-| PostgreSQL | | scheduler *| +------------+ +------------+&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;V8 Isolates: Sandboxing with CPU (100ms) and memory (128MB) limits per worker.&lt;/item&gt;
      &lt;item&gt;Cron Scheduling: Built-in support for 5 or 6-field cron syntax.&lt;/item&gt;
      &lt;item&gt;Compatibility: Cloudflare Workers syntax compatible.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Self-hosting&lt;/head&gt;
    &lt;p&gt;Deployment is designed to be simple. A single PostgreSQL database and a single Docker Compose file is all you need.&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;git clone https://github.com/openworkers/openworkers-infra cd openworkers-infra &amp;amp;&amp;amp; cp .env.example .env docker compose up -d postgres # Run migrations, generate token docker compose up -d&lt;/code&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Why I built this&lt;/head&gt;
    &lt;p&gt;This project has been evolving for about 7 years. I started experimenting with vm2 for sandboxing JS, then Cloudflare launched Workers and I got hooked on the model. When Deno came out, I switched to deno-core and ran on that for two years. Recently, with Claude's help, I rewrote everything on top of rusty_v8 directly.&lt;/p&gt;
    &lt;p&gt;The goal has always been the same: run JavaScript on your own servers, with the same DX as Cloudflare Workers but without vendor lock-in.&lt;/p&gt;
    &lt;p&gt;Next up: Execution recording &amp;amp; replay for deterministic debugging.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openworkers.com/introducing-openworkers"/><published>2026-01-01T15:09:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46454958</id><title>Common Lisp SDK for the Datastar Hypermedia Framework</title><updated>2026-01-01T21:38:13.676573+00:00</updated><content>&lt;doc fingerprint="9f8b980ffea5d2f4"&gt;
  &lt;main&gt;
    &lt;code&gt;================================================================

       |             
      / \            DATASTAR HYPERMEDIA FRAMEWORK
     /___\          
    |  D  |          
    | C*L |                '(DATASTAR-CL)    
    |     |                 
   /|  |  |\
  | |_ |__| |              COMMON LISP SDK
  |/  /.\  \|            

================================================================
&lt;/code&gt;
    &lt;p&gt;This is a Common Lisp implementation of the Datastar SDK, following the Datastar Architecture Decision Record (ADR) as closely as possible, making the necessary adjustments for Common Lisp.&lt;/p&gt;
    &lt;p&gt;Focus has been on implementing the core SDK functionality, with additional utilities planned.&lt;/p&gt;
    &lt;p&gt;Clone the repository somewhere ASDF2 can find it (~~/src/lisp~ is commonly already configured), and use Quicklisp to load it:&lt;/p&gt;
    &lt;code&gt;(ql:quickload "datastar-cl")
&lt;/code&gt;
    &lt;p&gt;The SDK uses CLOS and is based on a &lt;code&gt;sse-generator&lt;/code&gt; class, that currently has two subclasses:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;hunchentoot-sse-generator&lt;/code&gt;: used with the Hunchentoot web server.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;clack-sse-generator&lt;/code&gt;: used with the Clack web application environment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both approaches use a stream, although in different ways and initialized differently. For Clack, the work done is at the Lack level, and has been tested with both Hunchentoot and Woo.&lt;/p&gt;
    &lt;p&gt;We are currently using JZON as the JSON parser in two places: &lt;code&gt;read-signals&lt;/code&gt; and &lt;code&gt;patch-signals&lt;/code&gt;.
  This is not a hard requirement to remove, but for now it allows immediate use and testing of the
  library.&lt;/p&gt;
    &lt;p&gt;When using Clack with Woo, SSE connections are limited by Woo‚Äôs worker thread count. Each SSE connection blocks one worker for its entire duration. This is a fundamental architectural constraint - see &lt;code&gt;SSE-WOO-LIMITATIONS.org&lt;/code&gt; for details and practical solutions.&lt;/p&gt;
    &lt;p&gt;For applications with many SSE connections, Hunchentoot is recommended (no connection limit), or using a polling approach. By default, Hunchentoot (and Clack+Hunchentoot) uses a push approach, while Clack+Woo defaults to poll.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;test/&lt;/code&gt; directory has some basic examples. Additionally, the following projects use it&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Data SPICE: uses Datastar-CL for a 2D simulation of the solar system and Cassini-Huygens probe; written in parallel with the SDK to showcase it and also make sure it worked.&lt;/item&gt;
      &lt;item&gt;Horizons JPL API explorer: in the same theme, but a vastly simplified app that queries the Horizons API for solar system data.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Horizons JPL app is very simple ‚Äì one single file ‚Äì and should show the essentials. The Data SPICE application shows SSE streaming.&lt;/p&gt;
    &lt;p&gt;Support for compression was recently added, currently covering all backends but limited to &lt;code&gt;zstd&lt;/code&gt;:
  read &lt;code&gt;COMPRESSION.org&lt;/code&gt; for details.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;test/&lt;/code&gt; directory contains the code to setup and start the supported servers, Hunchentoot and
  Clack (with Woo and Hunchentoot backends, others can be added). It‚Äôs also a good place to use as an
  example of how the SDK can be used, especially since there are some differences depending on the
  backend (Hunchentoot or Clack). SSE has a specific test file that can also serve as an example, and
  some important edge cases (like what happens when connections are interrupted) are tested as well.&lt;/p&gt;
    &lt;p&gt;The code follows Datastar‚Äôs licence choice, the MIT license.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/fsmunoz/datastar-cl"/><published>2026-01-01T15:47:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46454968</id><title>Implementing HNSW (Hierarchical Navigable Small World) Vector Search in PHP</title><updated>2026-01-01T21:38:12.831753+00:00</updated><content>&lt;doc fingerprint="9ac1f3e5186c4fef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Hierarchical Navigable Small World (HNSW) in PHP&lt;/head&gt;
    &lt;p&gt;Or: How to find a needle in a haystack without checking all the hay&lt;/p&gt;
    &lt;p&gt;In the previous article we saw how vectors can help find the right information simply by describing the concept we want to find.&lt;/p&gt;
    &lt;p&gt;We used Cosine Similarity to compare our request with all available documents, scanning them one by one until we found those with the highest similarity. Does this approach work? Yes. Is it fast? Sort of....&lt;/p&gt;
    &lt;p&gt;Imagine if a librarian, to find your book, had to read the titles of all 10 million volumes in a National Library. Even if they spent one millisecond per book, it would take hours. This is the problem of linear search ($O(N)$).&lt;/p&gt;
    &lt;p&gt;To solve this problem, we introduce a concept that will transform that search from hours to milliseconds: HNSW (Hierarchical Navigable Small World).&lt;/p&gt;
    &lt;head rend="h2"&gt;Small worlds and highways&lt;/head&gt;
    &lt;p&gt;Let's use an analogy to better understand the solution HNSW proposes: How do we find a specific point in a huge city if we come from very far away and don't know the direction?&lt;/p&gt;
    &lt;p&gt;Simple: in real life, we use a hierarchy of roads. That is, we start from a "broad" view of the map and subsequently "zoom in" towards the point of interest. Expressing this with an algorithm, we would:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Take the highway to get close to the region.&lt;/item&gt;
      &lt;item&gt;Exit onto the state road to reach the city.&lt;/item&gt;
      &lt;item&gt;Take the main streets for the neighborhood.&lt;/item&gt;
      &lt;item&gt;Finally, use the side streets to find the house number.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;HNSW does exactly this with data. It builds a layered structure (Layers) where the higher levels are like highways (few points, long connections) and the lower levels are neighborhood streets (all points, short connections).&lt;/p&gt;
    &lt;head rend="h2"&gt;The Code&lt;/head&gt;
    &lt;p&gt;Let's analyze how to implement this logic in PHP. The code we will examine comes from the open source project Vektor, a small service I built that allows for native vector search in PHP.&lt;/p&gt;
    &lt;p&gt;Technical note: In addition to &lt;code&gt;$ef&lt;/code&gt;, there is a crucial parameter called &lt;code&gt;$M&lt;/code&gt;. Imagine it as the maximum number of roads that can start from an intersection. The higher &lt;code&gt;$M&lt;/code&gt; is, the more connected the city is, but the more memory our map will occupy.&lt;/p&gt;
    &lt;head rend="h3"&gt;The descent to Level 0&lt;/head&gt;
    &lt;p&gt;The main logic is in the &lt;code&gt;search&lt;/code&gt; method, which we see below. Imagine looking at a satellite map and progressively zooming in. We start from the global view (the nodes of the highest level).&lt;/p&gt;
    &lt;code&gt;public function search(array $queryVector, int $k, int $ef): array
{
    // Start from the highest level (e.g. Level 3)
    $entryPoint = $this-&amp;gt;readHeader();

    // Calculate the initial distance, i.e., compare the Level 3 object with the search target
    $currObj = $entryPoint;
    $currDist = Math::cosineSimilarity($queryVector, $this-&amp;gt;getVector($currObj));

    // Now progressively descend from high levels down to level 1
    // The for loop starts from the max level and repeats until we reach Level 1
    for ($lc = $maxLevel; $lc &amp;gt;= 1; $lc--) {

        // Navigate within the current level until we find the closest point
        while (true) {
            $changed = false;

            // Read the neighbors of the current node at this level
            $node = $this-&amp;gt;readNode($currObj);
            $neighbors = $node['connections'][$lc] ?? [];

            // Search if there is a neighbor that is CLOSER to our target
            foreach ($neighbors as $neighborId) {
                $dist = Math::cosineSimilarity($queryVector, $this-&amp;gt;getVector($neighborId));
                if ($dist &amp;gt; $currDist) {
                    $currDist = $dist;
                    $currObj = $neighborId;
                    $changed = true; // We found a better point!
                }
            }

            // If there were no changes in choosing the best node,
            // it means we are already at the closest possible point 
            // in this level, so we can "descend" to the lower level
            if (!$changed) break;
        }

        // Now $currObj is set with the starting point for the lower level ($lc - 1)
    }

    // At the end of the loop we will be at Level 0 and $currObj will contain the closest point!
}&lt;/code&gt;
    &lt;p&gt;This cycle is the equivalent of identifying the area of interest from above, moving towards the point closest to the destination, and then increasing the detail. Repeat until we are at the maximum detail level (Level 1).&lt;/p&gt;
    &lt;head rend="h3"&gt;Precision Search (Level 0)&lt;/head&gt;
    &lt;p&gt;Once we arrive at Level 0, where all the data resides, a single point is no longer enough. We want the K best results. This is where the &lt;code&gt;$ef&lt;/code&gt; (Construction/Search Size) parameter comes into play.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;$ef&lt;/code&gt; is the size of our "candidate list". The higher the number, the more nodes we evaluate, and the more precise (and slow) the search will be.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;searchLayer&lt;/code&gt; method adopts a Greedy approach: at each step, the algorithm makes the locally optimal choice, moving towards the neighbor that maximizes similarity with the query. Instead of exploring every possible path, the algorithm "follows the gradient" towards the target. The Priority Queue manages this process, allowing us to explore the most promising nodes first and stop the search as soon as new candidates stop improving our list of best results ($ef$).&lt;/p&gt;
    &lt;code&gt;public function searchLayer(int $entryPoint, array $queryVector, int $ef, int $level, ?int $k = null): array
{
    $visited = [$entryPoint =&amp;gt; true];
    $candidates = new SplPriorityQueue(); // Promising nodes to explore

    $winners = [$entryPoint =&amp;gt; $entrySim]; // Best results found so far (Winner list)

    while (!$candidates-&amp;gt;isEmpty()) {
        $c = $candidates-&amp;gt;extract(); // Take the best candidate

        // If the best candidate is worse than the worst of our current "winners"
        // and we have already filled the list ($ef), we can stop.
        // It's useless to explore further, we are moving away.
        if ($cSim &amp;lt; $worstSim &amp;amp;&amp;amp; count($winners) &amp;gt;= $ef) {
            break;
        }

        // Explore the candidate's neighbors
        $node = $this-&amp;gt;readNode($c);
        $neighbors = $node['connections'][$level] ?? [];

        foreach ($neighbors as $neighborId) {
            if (!isset($visited[$neighborId])) {
                $visited[$neighborId] = true;

                // For each neighbor, calculate its similarity with the target query
                $sim = Math::cosineSimilarity($queryVector, $this-&amp;gt;getVector($neighborId));

                // If this neighbor is promising, add it to candidates
                if ($sim &amp;gt; $worstSim || count($winners) &amp;lt; $ef) {
                    $candidates-&amp;gt;insert($neighborId, $sim);
                    $winners[$neighborId] = $sim;

                    // Keep the winner list W at a fixed size $ef
                    if (count($winners) &amp;gt; $ef) {
                        asort($winners);
                        $idToRemove = array_key_first($winners); // Remove the worst
                        unset($winners[$idToRemove]);

                        // Update the "worst acceptable" threshold
                        asort($winners);
                        $worstSim = $winners[array_key_first($winners)];
                    }
                }
            }
        }
    }

    // ... return the top K elements from the $winners list ...
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Why is it fast?&lt;/head&gt;
    &lt;p&gt;Let's go back to the library example.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In Linear Search, the librarian checks every book. $O(N)$ operations.&lt;/item&gt;
      &lt;item&gt;In HNSW, the librarian looks at the "Science" section (Level 2), then goes to the "Astronomy" shelf (Level 1), and finally checks only the 50 books on that shelf (Level 0). $O(\log N)$ operations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On a dataset of 1 million objects, instead of making 1,000,000 comparisons, we might make only 500 or 1,000. It's a difference of orders of magnitude.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building the map&lt;/head&gt;
    &lt;p&gt;So far we have taken for granted that these "highways" and "neighborhood streets" already exist. But how are they built? The genius of HNSW lies in the fact that the map is drawn dynamically, one point at a time.&lt;/p&gt;
    &lt;p&gt;When we need to insert a new piece of data (a vector) into our index, we have to decide two things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Which zone is it in? (Max level)&lt;/item&gt;
      &lt;item&gt;Who are its neighbors?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For the first question, HNSW relies on chance. It's like flipping a coin (or more technically, using an exponential probability distribution). Most points will end up at Level 0 (the residential neighborhood). Some lucky ones will win a "ticket" to Level 1 (the state roads). Very few "chosen ones" will reach the highest levels (the highways). This ensures that the upper levels remain uncluttered and fast to traverse.&lt;/p&gt;
    &lt;p&gt;For the second question, we use the search seen previously to also perform the insertion.&lt;/p&gt;
    &lt;p&gt;If our new point has been assigned to Level 1:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We start from the absolute highest level (e.g. Level 3).&lt;/item&gt;
      &lt;item&gt;We look for the closest point to our newcomer (using the logic of &lt;code&gt;searchLayer&lt;/code&gt;seen before).&lt;/item&gt;
      &lt;item&gt;We go down to the level below and repeat, until we reach the assigned level (Level 1).&lt;/item&gt;
      &lt;item&gt;Here we stop and connect the new point to its nearest neighbors (based on the parameter &lt;code&gt;$M&lt;/code&gt;, the maximum number of connections).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Basically, every new citizen who arrives in the city asks for directions to find their area, and once arrived, makes friends with the neighbors most similar to them. If a neighbor has too many friends, they cut ties with the least similar one to make room for the newcomer. It is this process of natural selection of connections that keeps the graph efficient and navigable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Implementing HNSW from scratch is a fundamental exercise to understand how modern vector databases like Qdrant or Pinecone work. We are not just "searching for data", we are navigating a multidimensional space using probabilistic shortcuts.&lt;/p&gt;
    &lt;p&gt;These algorithms are the basis of modern recommendation systems ("Users who bought this also saw....") and RAG (Retrieval Augmented Generation) systems for artificial intelligence, allowing relevant context to be found in fractions of a second.&lt;/p&gt;
    &lt;p&gt;If you want to dive deeper into the complete implementation, check out the Vektor https://github.com/centamiv/vektor repository on GitHub.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://centamori.com/index.php?slug=hierarchical-navigable-small-world-hnsw-php&amp;lang=en"/><published>2026-01-01T15:48:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46455053</id><title>Sony PS5 ROM keys leaked ‚Äì jailbreaking could be made easier with BootROM codes</title><updated>2026-01-01T21:38:12.504241+00:00</updated><content>&lt;doc fingerprint="a7c09b94082335b4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;PlayStation 5 ROM keys leaked ‚Äî jailbreaking could be made easier with BootROM codes&lt;/head&gt;
    &lt;p&gt;You still won't get a jailbroken PlayStation 5 with this leak, but it will make it easier for hackers to compromise the console's bootloader.&lt;/p&gt;
    &lt;p&gt;The PlayStation 5‚Äôs ROM keys have allegedly been leaked, meaning anyone who can get their hands on the hex strings now has the hardware code that will allow jailbreakers to try decrypting and analyzing the console‚Äôs bootloader. According to The Cybersec Guru, this is an unpatchable problem for Sony, because these keys cannot be changed and are burned directly in the APU. The only way that the company can invalidate the leaked codes is to replace the chips on yet-to-be-manufactured units, meaning consoles that are already in the wild could possibly take advantage of future jailbreaks stemming from the use of these leaked codes.&lt;/p&gt;
    &lt;p&gt;When you turn on the PS5, its CPU runs the BootROM code that‚Äôs baked in the chip and uses the ROM keys to ensure that Bootloader is valid. Now that the ROM keys have been leaked (and assuming they are valid), a hacker could then decrypt and study the official bootloader and potentially use that as a starting point to understand how the PS5‚Äôs boot system works. Since the issue is at a hardware level, Sony would not be able to release an update that will stop consoles with the compromised chip from loading kernel-level exploits in the future, should one become available.&lt;/p&gt;
    &lt;p&gt;Note that this leak does not automatically mean that we will see jailbroken PS5s on the market right now, especially as Sony has other security measures that hackers need to bypass. However, the appearance of these codes means that one of the biggest security features of the console has likely already been compromised, making it easier for those working on creating custom firmware to have a deeper understanding of how the console works and use that knowledge to maybe build a modified (or even a totally different) operating system for it.&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt the first time that Sony has had to deal with a security crisis with the popular PlayStation family. The PlayStation 3 was previously hit with a vulnerability when the company made a mistake with their cryptography on the console, allowing users to install homebrew software and allow piracy and cheating on popular titles. We also saw this with the Nintendo Switch, when a flaw in the Nvidia Tegra X1 chip that it used let tinkerers run Linux on the handheld.&lt;/p&gt;
    &lt;p&gt;Sony has yet to release a statement regarding the hack, but the company could release revised hardware in the near future to rectify the situation. Another solution is to issue a recall for all existing PlayStation 5 consoles on the market and replace their motherboard to change the hardware codes, but this is unlikely to happen as it‚Äôs either going to be too costly for the company or gamers would be unwilling to pay extra for a mistake that was ultimately not theirs.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;Jowi Morales is a tech enthusiast with years of experience working in the industry. He‚Äôs been writing with several tech publications since 2021, where he‚Äôs been interested in tech hardware and consumer electronics.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;ezst036&lt;/header&gt;Valve and the Steam Deck/incoming Steam Machine are giving Microsoft a lot of headaches for reasons that are not relevant here.Reply&lt;lb/&gt;On the other side,&lt;lb/&gt;I hope Valve's openness gives future (let's say PS6 and beyond) consoles from any company headaches as well. That these companies go through such trouble to lock the devices down against their own users is just pathetic. And don't even get me started on Nintendo's ridiculously litigious nature.&lt;lb/&gt;Valve's openness and respect for all of us is proving that there simply is not an either/or. We really can have it all and the world is ours: (1)Ease of use. (2)Lower prices. (3)Faster performance. (4)Unlimited configurability. (5)Total freedom.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tomshardware.com/video-games/playstation/playstation-5-rom-keys-leaked-jailbreaking-could-be-made-easier-with-bootrom-codes"/><published>2026-01-01T15:57:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46455872</id><title>Cameras and Lenses (2020)</title><updated>2026-01-01T21:38:11.846251+00:00</updated><content>&lt;doc fingerprint="368c0a750d314318"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Cameras and Lenses&lt;/head&gt;
    &lt;p&gt;Pictures have always been a meaningful part of the human experience. From the first cave drawings, to sketches and paintings, to modern photography, we‚Äôve mastered the art of recording what we see.&lt;/p&gt;
    &lt;p&gt;Cameras and the lenses inside them may seem a little mystifying. In this blog post I‚Äôd like to explain not only how they work, but also how adjusting a few tunable parameters can produce fairly different results:&lt;/p&gt;
    &lt;p&gt;Over the course of this article we‚Äôll build a simple camera from first principles. Our first steps will be very modest √¢ we‚Äôll simply try to take any picture. To do that we need to have a sensor capable of detecting and measuring light that shines onto it.&lt;/p&gt;
    &lt;head rend="h1"&gt;Recording Light&lt;/head&gt;
    &lt;p&gt;Before the dawn of the digital era, photographs were taken on a piece of film covered in crystals of silver halide. Those compounds are light-sensitive and when exposed to light they form a speck of metallic silver that can later be developed with further chemical processes.&lt;/p&gt;
    &lt;p&gt;For better or for worse, I‚Äôm not going to discuss analog devices √¢ these days most cameras are digital. Before we continue the discussion relating to light we‚Äôll use the classic trick of turning the illumination off. Don‚Äôt worry though, we‚Äôre not going to stay in darkness for too long.&lt;/p&gt;
    &lt;p&gt;The image sensor of a digital camera consists of a grid of photodetectors. A√Ç photodetector converts photons into electric current that can be measured √¢ the more photons hitting the detector the higher the signal.&lt;/p&gt;
    &lt;p&gt;In the demonstration below you can observe how photons fall onto the arrangement of detectors represented by small squares. After some processing, the value read by each detector is converted to the brightness of the resulting image pixels which you can see on the right side. I‚Äôm also symbolically showing which photosite was hit with a short highlight. The slider below controls the flow of time:&lt;/p&gt;
    &lt;p&gt;The longer the time of collection of photons the more of them are hitting the detectors and the brighter the resulting pixels in the image. When we don‚Äôt gather enough photons the image is underexposed, but if we allow the photon collection to run for too long the image will be overexposed.&lt;/p&gt;
    &lt;p&gt;While the photons have the ‚Äúcolor‚Äù of their wavelength, the photodetectors don‚Äôt see that hue √¢ they only measure the total intensity which results in a black and white image. To record the color information we need to separate the incoming photons into distinct groups. We can put tiny color filters on top of the detectors so that they will only accept, more or less, red, green, or blue light:&lt;/p&gt;
    &lt;p&gt;This color filter array can be arranged in many different formations. One of the simplest is a Bayer filter which uses one red, one blue, and two green filters arranged in a 2x2 grid:&lt;/p&gt;
    &lt;p&gt;A Bayer filter uses two green filters because light in green part of the spectrum heavily correlates with perceived brightness. If we now repeat this pattern across the entire sensor we‚Äôre able to collect color information. For the next demo we will also double the resolution to an astonishing 1 kilopixel arranged in a 32x32 grid:&lt;/p&gt;
    &lt;p&gt;Note that the individual sensors themselves still only see the intensity, and not the color, but knowing the arrangement of the filters we can recreate the colored intensity of each sensor, as shown on the right side of the simulation.&lt;/p&gt;
    &lt;p&gt;The final step of obtaining a normal image is called demosaicing. During demosaicing we want to reconstruct the full color information by filling in the gaps in the captured RGB values. One of the simplest way to do it is to just linearly interpolate the values between the existing neighbors. I‚Äôm not going to focus on the details of many other available demosaicing algorithms and I‚Äôll just present the resulting image created by the process:&lt;/p&gt;
    &lt;p&gt;Notice that yet again the overall brightness of the image depends on the length of time for which we let the photons through. That duration is known as shutter speed or exposure time. For most of this presentation I will ignore the time component and we will simply assume that the shutter speed has been set just right so that the image is well exposed.&lt;/p&gt;
    &lt;p&gt;The examples we‚Äôve discussed so far were very convenient √¢ we were surrounded by complete darkness with the photons neatly hitting the pixels to form a coherent image. Unfortunately, we can‚Äôt count on the photon paths to be as favorable in real environments, so let‚Äôs see how the sensor performs in more realistic scenarios.&lt;/p&gt;
    &lt;p&gt;Over the course of this article we will be taking pictures of this simple scene. The almost white background of this website is also a part of the scenery √¢ it represents a bright overcast sky. You can drag around the demo to see it from other directions:&lt;/p&gt;
    &lt;p&gt;Let‚Äôs try to see what sort of picture would be taken by a sensor that is placed near the objects without any enclosure. I‚Äôll also significantly increase the sensor‚Äôs resolution to make the pixels of the final image align with the pixels of your display. In the demonstration below the left side represents a view of the scene with the small greenish sensor present, while the right one shows the taken picture:&lt;/p&gt;
    &lt;p&gt;This is not a mistake. As you can see, the obtained image doesn‚Äôt really resemble anything. To understand why this happens let‚Äôs first look at the light radiated from the scene.&lt;/p&gt;
    &lt;p&gt;If you had a chance to explore how surfaces reflect light, you may recall that most matte surfaces scatter the incoming light in every direction. While I‚Äôm only showing a few examples, every point on every surface of this scene reflects the photons it receives from the whiteish background light source all around itself:&lt;/p&gt;
    &lt;p&gt;The red sphere ends up radiating red light, the green sphere radiates green light, and the gray checkerboard floor reflects white light of lesser intensity. Most importantly, however, the light emitted from the background is also visible to the sensor.&lt;/p&gt;
    &lt;p&gt;The problem with our current approach to taking pictures is that every pixel of the sensor is exposed to the entire environment. Light radiated from every point of the scene and the white background hits every point of the sensor. In the simulation below you can witness how light from different directions hits one point on the surface of the sensor:&lt;/p&gt;
    &lt;p&gt;Clearly, to obtain a discernible image we have to limit the range of directions that affect a given pixel on the sensor. With that in mind, let‚Äôs put the sensor in a box that has a small hole in it. The first slider controls the diameter of the hole, while the second one controls the distance between the opening and the sensor:&lt;/p&gt;
    &lt;p&gt;While not shown here, the inner sides of the walls are all black so that no light is reflected inside the box. I also put the sensor on the back wall so that the light from the hole shines onto it. We‚Äôve just built a pinhole camera, let‚Äôs see how it performs. Observe what happens to the taken image as we tweak the diameter of the hole with the first slider, or change the distance between the opening and the sensor with the second one:&lt;/p&gt;
    &lt;p&gt;There are so many interesting things happening here! The most pronounced effect is that the image is inverted. To understand why this happens let‚Äôs look at the schematic view of the scene that shows the light rays radiated from the objects, going through the hole, and hitting the sensor:&lt;/p&gt;
    &lt;p&gt;As you can see the rays cross over in the hole and the formed image is a horizontal and a vertical reflection of the actual scene. Those two flips end up forming a 180√Ç¬∞ rotation. Since rotated images aren‚Äôt convenient to look at, all cameras automatically rotate the image for presentation and for the rest of this article I will do so as well.&lt;/p&gt;
    &lt;p&gt;When we change the distance between the hole and the sensor the viewing angle changes drastically. If we trace the rays falling on the corner pixels of the sensor we can see that they define the extent of the visible section of the scene:&lt;/p&gt;
    &lt;p&gt;Rays of light coming from outside of that shape still go through the pinhole, but they land outside of the sensor and aren‚Äôt recorded. As the hole moves further away from the sensor, the angle, and thus the field of view visible to the sensor gets smaller. We can see this in a top-down view of the camera:&lt;/p&gt;
    &lt;p&gt;Coincidentally, this diagram also helps us explain two other effects. Firstly, in the photograph the red sphere looks almost as big as the green one, even though the scene view shows the latter is much larger. However, both spheres end up occupying roughly the same span on the sensor and their size in the picture is similar. It‚Äôs also worth noting that the spheres seem to grow when the field of view gets narrower because their light covers larger part of the sensor.&lt;/p&gt;
    &lt;p&gt;Secondly, notice that different pixels of the sensor have different distance and relative orientation to the hole. The pixels right in the center of the sensor see the pinhole straight on, but pixels positioned at an angle to the main axis see a distorted pinhole that is further away. The ellipse in the bottom right corner of the demonstration below shows how a pixel positioned at the blue point sees the pinhole:&lt;/p&gt;
    &lt;p&gt;This change in the visible area of the hole causes the darkening we see in the corners of the photograph. The value of the cosine of the angle I‚Äôve marked with a yellow color is quite important as it contributes to the reduction of visible light in four different ways:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Two cosine factors from the increased distance to the hole, it‚Äôs essentially the inverse square law&lt;/item&gt;
      &lt;item&gt;A cosine factor from the side squeeze of the circular hole seen at an angle&lt;/item&gt;
      &lt;item&gt;A cosine factor from the relative tilt of the receptor&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These four factors conspire together to reduce the illumination by a factor of cos4(√é¬±) in what is known as cosine-fourth-power law, also described as natural vignetting.&lt;/p&gt;
    &lt;p&gt;Since we know the relative geometry of the camera and the opening we can correct for this effect by simply dividing by the falloff factor and from this point on I will make sure that the images don‚Äôt have darkened corners.&lt;/p&gt;
    &lt;p&gt;The final effect we can observe is that when the hole gets smaller the image gets sharper. Let‚Äôs see how the light radiated from two points of the scene ends up going through the camera depending on the diameter of the pinhole:&lt;/p&gt;
    &lt;p&gt;We can already see that larger hole size ends up creating a bigger spread on the sensor. Let‚Äôs see this situation up close on a simple grid of detecting cells. Notice what happens to the size of the final circle hitting the sensor as that diameter of the hole changes:&lt;/p&gt;
    &lt;p&gt;When the hole is small enough rays from the source only manage to hit one pixel on the sensor. However, at larger radii the light spreads onto other pixels and a tiny point in the scene is no longer represented by a single pixel causing the image to no longer be sharp.&lt;/p&gt;
    &lt;p&gt;It‚Äôs worth pointing out that sharpness is ultimately arbitrary √¢ it depends on the size at which the final image is seen, viewing conditions, and visual acuity of the observer. The same photograph that looks sharp on a postage stamp may in fact be very blurry when seen on a big display.&lt;/p&gt;
    &lt;p&gt;By reducing the size of the cone of light we can make sure that the source light affects a limited number of pixels. Here, however, lays the problem. The sensor we‚Äôve been using so far has been an idealized detector capable of flawless adjustment of its sensitivity to the lighting conditions. If we instead were to fix the sensor sensitivity adjustment, the captured image would look more like this:&lt;/p&gt;
    &lt;p&gt;As the relative size of the hole visible to the pixels of the sensor gets smaller, be it due to reduced diameter or increased distance, fewer photons hit the surface and the image gets dimmer.&lt;/p&gt;
    &lt;p&gt;To increase the number of photons we capture we could extend the duration of collection, but increasing the exposure time comes with its own problems √¢ if the photographed object moves or the camera isn‚Äôt held steady we risk introducing some motion blur.&lt;/p&gt;
    &lt;p&gt;Alternatively, we could increase the sensitivity of the sensor which is described using the ISO rating. However, boosting the ISO may introduce a higher level of noise. Even with these problems solved an actual image obtained by smaller and smaller holes would actually start getting blurry again due to diffraction effects of light.&lt;/p&gt;
    &lt;p&gt;If you recall how diffuse surfaces reflect light you may also realize how incredibly inefficient a pinhole camera is. A single point on the surface of an object radiates light into its surrounding hemisphere, however, the pinhole captures only a tiny portion of that light.&lt;/p&gt;
    &lt;p&gt;More importantly, however, a pinhole camera gives us minimal artistic control over which parts of the picture are blurry. In the demonstration below you can witness how changing which object is in focus heavily affects what is the primary target of attention of the photograph:&lt;/p&gt;
    &lt;p&gt;Let‚Äôs try to build an optical device that would solve both of these problems: we want to find a way to harness a bigger part of the energy radiated by the objects and also control what is blurry and how blurry it is. For the objects in the scene that are supposed to be sharp we want to collect a big chunk of their light and make it converge to the smallest possible point. In essence, we‚Äôre looking for an instrument that will do something like this:&lt;/p&gt;
    &lt;p&gt;We could then put the sensor at the focus point and obtain a sharp image. Naturally, the contraption we‚Äôll try to create has to be transparent so that the light can pass through it and get to the sensor, so let‚Äôs begin the investigation by looking at a piece of glass.&lt;/p&gt;
    &lt;head rend="h1"&gt;Glass&lt;/head&gt;
    &lt;p&gt;In the demonstration below I put a red stick behind a pane of glass. You can adjust the thickness of this pane with the gray slider below:&lt;/p&gt;
    &lt;p&gt;When you look at the stick through the surface of a thick glass straight on, everything looks normal. However, as your viewing direction changes the stick seen through the glass seems out of place. The thicker the glass and the steeper the viewing angle the bigger the offset.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs focus on one point on the surface of the stick and see how the rays of light radiated from its surface propagate through the subsection of the glass. The red slider controls the position of the source and the gray slider controls the thickness. You can drag the demo around to see it from different viewpoints:&lt;/p&gt;
    &lt;p&gt;For some reason the rays passing through glass at an angle are deflected off their paths. The change of direction happens whenever the ray enters or leaves the glass.&lt;/p&gt;
    &lt;p&gt;To understand why the light changes direction we have to peek under the covers of classical electromagnetism and talk a bit more about waves.&lt;/p&gt;
    &lt;head rend="h1"&gt;Waves&lt;/head&gt;
    &lt;p&gt;It‚Äôs impossible to talk about wave propagation without involving the time component, so the simulations in this section are animated √¢ you can play and pause them by clickingtapping on the button in their bottom left corner.&lt;/p&gt;
    &lt;p&gt;By default all animations are enabled, but if you find them distracting, or if you want to save power, you can globally pause all the following demonstrations.disabled, but if you‚Äôd prefer to have things moving as you read you can globally unpause them and see all the waves oscillating.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs begin by introducing the simplest sinusoidal wave:&lt;/p&gt;
    &lt;p&gt;A wave like this can be characterized by two components. Wavelength √é¬ª is the distance over which the shape of the wave repeats. Period T defines how much time a full cycle takes.&lt;/p&gt;
    &lt;p&gt;Frequency f, is just a reciprocal of period and it‚Äôs more commonly used √¢ it defines how many waves per second have passed over some fixed point. Wavelength and frequency define phase velocity vp which describes how quickly a point on a wave, e.g. a peak, moves:&lt;/p&gt;
    &lt;p&gt;The sinusoidal wave is the building block of a polarized electromagnetic plane wave. As the name implies electromagnetic radiation is an interplay of oscillations of electric field E and magnetic field B:&lt;/p&gt;
    &lt;p&gt;In an electromagnetic wave the magnetic field is tied to the electric field so I‚Äôm going to hide the former and just visualize the latter. Observe what happens to the electric component of the field as it passes through a block of glass. I need to note that dimensions of wavelengths are not to scale:&lt;/p&gt;
    &lt;p&gt;Notice that the wave remains continuous at the boundary and inside the glass the frequency of the passing wave remains constant, However, the wavelength and thus the phase velocity are reduced √¢ you can see it clearly from the side.&lt;/p&gt;
    &lt;p&gt;The microscopic reason for the phase velocity change is quite complicated, but it can be quantified using the index of refraction n, which is the ratio of the speed of light c to the phase velocity vp of lightwave in that medium:&lt;/p&gt;
    &lt;p&gt;The higher the index of refraction the slower light propagates through the medium. In the table below I‚Äôve presented a few different indices of refraction for some materials:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vacuum&lt;/cell&gt;
        &lt;cell&gt;1.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;air&lt;/cell&gt;
        &lt;cell&gt;1.0003&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;water&lt;/cell&gt;
        &lt;cell&gt;1.33&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;glass&lt;/cell&gt;
        &lt;cell&gt;1.53&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;diamond&lt;/cell&gt;
        &lt;cell&gt;2.43&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Light traveling through air barely slows down, but in a diamond it‚Äôs over twice as slow. Now that we understand how index of refraction affects the wavelength in the glass, let‚Äôs see what happens when we change the direction of the incoming wave:&lt;/p&gt;
    &lt;p&gt;The wave in the glass has a shorter wavelength, but it still has to match the positions of its peaks and valleys across the boundary. As such, the direction of propagation must change to ensure that continuity.&lt;/p&gt;
    &lt;p&gt;I need to note that the previous two demonstrations presented a two dimensional wave since that allowed me to show the sinusoidal component oscillating into the third dimension. In real world the lightwaves are three dimensional and I can‚Äôt really visualize the sinusoidal component without using the fourth dimension which has its own set of complications.&lt;/p&gt;
    &lt;p&gt;The alternative way of presenting waves is to use wavefronts. Wavefronts connect the points of the same phase of the wave, e.g. all the peaks or valleys. In two dimensions wavefronts are represented by lines:&lt;/p&gt;
    &lt;p&gt;In three dimensions the wavefronts are represented by surfaces. In the demonstration below a single source emits a spherical wave, points of the same phase in the wave are represented by the moving shells:&lt;/p&gt;
    &lt;p&gt;By drawing lines that are perpendicular to the surface of the wavefront we create the familiar rays. In this interpretation rays simply show the local direction of wave propagation which can be seen in this example of a section of a spherical 3D wave:&lt;/p&gt;
    &lt;p&gt;I will continue to use the ray analogy to quantify the change in direction of light passing through materials. The relation between the angle of incidence √é¬∏1 and angle of refraction √é¬∏2 can be formalized with the equation known as Snell‚Äôs law:&lt;/p&gt;
    &lt;p&gt;It describes how a ray of light changes direction relative to the surface normal on the border between two different media. Let‚Äôs see it in action:&lt;/p&gt;
    &lt;p&gt;When traveling from a less to more refractive material the ray bends towards the normal, but when the ray exits the object with higher index of refraction it bends away from the normal.&lt;/p&gt;
    &lt;p&gt;Notice that in some configurations the refracted ray completely disappears, however, this doesn‚Äôt paint a full picture because we‚Äôre currently completely ignoring reflections.&lt;/p&gt;
    &lt;p&gt;All transparent objects reflect some amount of light. You may have noticed that reflection on a surface of a calm lake or even on the other side of the glass demonstration at the beginning of the previous section. The intensity of that reflection depends on the index of refraction of the material and the angle of the incident ray. Here‚Äôs a more realistic demonstration of how light would get refracted and reflected between two media:&lt;/p&gt;
    &lt;p&gt;The relation between transmittance and reflectance is determined by Fresnel equations. Observe that the curious case of missing light that we saw previously no longer occurs √¢ that light is actually reflected. The transition from partial reflection and refraction to the complete reflection is continuous, but near the end it‚Äôs very rapid and at some point the refraction completely disappears in the effect known as total internal reflection.&lt;/p&gt;
    &lt;p&gt;The critical angle at which the total internal reflection starts to happen depends on the indices of refraction of the boundary materials. Since that coefficient is low for air, but very high for diamond a proper cut of the faces makes diamonds very shiny.&lt;/p&gt;
    &lt;p&gt;While interesting on its own, reflection in glass isn‚Äôt very relevant to our discussion and for the rest of this article we‚Äôre not going to pay much attention to it. Instead, we‚Äôll simply assume that the materials we‚Äôre using are covered with high quality anti-reflective coating.&lt;/p&gt;
    &lt;head rend="h1"&gt;Manipulating Rays&lt;/head&gt;
    &lt;p&gt;Let‚Äôs go back to the example that started the discussion of light and glass. When both sides of a piece of glass are parallel, the ray is shifted, but it still travels in the same direction. Observe what happens to the ray when we change the relative angle of the surfaces of the glass.&lt;/p&gt;
    &lt;p&gt;When we make two surfaces of the glass not parallel we gain the ability to change the direction of the rays. Recall, that we‚Äôre trying to make the rays hitting the optical device converge at a certain point. To do that we have to bend the rays in the upper part down and, conversely, bend the rays in the lower part up.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see what happens if we shape the glass to have different angles between its walls at different height. In the demonstration below you can control how many distinct segments a piece of glass is shaped to:&lt;/p&gt;
    &lt;p&gt;As the number of segments approaches infinity we end up with a continuous surface without any edges. If we look at the crossover point from the side you may notice that we‚Äôve managed to converge the rays across one axis, but the top-down view reveals that we‚Äôre not done yet. To focus all the rays we need to replicate that smooth shape across all possible directions √¢ we need rotational symmetry:&lt;/p&gt;
    &lt;p&gt;We‚Äôve created a convex thin lens. This lens is idealized, in the later part of the article we‚Äôll discuss how real lenses aren‚Äôt as perfect, but for now it will serve us very well. Let‚Äôs see what happens to the focus point when we change the position of the red source:&lt;/p&gt;
    &lt;p&gt;When the source is positioned very far away the incoming rays become parallel and after passing through lens they converge at a certain distance away from the center. That distance is known as focal length.&lt;/p&gt;
    &lt;p&gt;The previous demonstration also shows two more general distances: so which is the distance between the object, or source, and the lens, as well as si which is the distance between the image and the lens. These two values and the focal length f are related by the thin lens equation:&lt;/p&gt;
    &lt;p&gt;Focal length of a lens depends on both the index of refraction of the material from which the lens is made and its shape:&lt;/p&gt;
    &lt;p&gt;Now that we understand how a simple convex lens works we‚Äôre ready to mount it into the hole of our camera. We will still control the distance between the sensor and the lens, but instead of controlling the diameter of the lens we‚Äôll instead control its focal length:&lt;/p&gt;
    &lt;p&gt;When you look at the lens from the side you may observe how the focal length change is tied to the shape of the lens. Let‚Äôs see how this new camera works in action:&lt;/p&gt;
    &lt;p&gt;Once again, a lot of things are going on here! Firstly, let‚Äôs try to understand how the image is formed in the first place. The demonstration below shows paths of rays from two separate points in the scene. After going through the lens they end up hitting the sensor:&lt;/p&gt;
    &lt;p&gt;Naturally, this process happens for every single point in the scene which creates the final image. Similarly to a pinhole a convex lens creates an inverted picture √¢ I‚Äôm still correcting for this by showing you a rotated photograph.&lt;/p&gt;
    &lt;p&gt;Secondly, notice that the distance between the lens and the sensor still controls the field of view. As a reminder, the focal length of a lens simply defines the distance from the lens at which the rays coming from infinity converge. To achieve a sharp image, the sensor has to be placed at the location where the rays focus and that‚Äôs what‚Äôs causing the field of view to change.&lt;/p&gt;
    &lt;p&gt;In the demonstration below I‚Äôve visualized how rays from a very far object focus through a lens of adjustable focal length, notice that to obtain a sharp image we must change the distance between the lens and the sensor which in turn causes the field of view to change:&lt;/p&gt;
    &lt;p&gt;If we want to change the object on which a camera with a lens of a fixed focal length is focused, we have to move the image plane closer or further away from the lens which affects the angle of view. This effect is called focus breathing:&lt;/p&gt;
    &lt;p&gt;A lens with a fixed focal length like the one above is often called a prime lens, while lenses with adjustable focal length are called zoom lenses. While the lenses in our eyes do dynamically adjust their focal lengths by changing their shape, rigid glass can‚Äôt do that so zoom lenses use a system of multiple glass elements that change their relative position to achieve this effect.&lt;/p&gt;
    &lt;p&gt;In the simulation above notice the difference in sharpness between the red and green spheres. To understand why this happens let‚Äôs analyze the rays emitted from two points on the surface of the spheres. In the demonstration below the right side shows the light seen by the sensor just from the two marked points on the spheres:&lt;/p&gt;
    &lt;p&gt;The light from the point in focus converges to a point, while the light from an out-of-focus point spreads onto a circle. For larger objects the multitude of overlapping out-of-focus circles creates a smooth blur called bokeh. With tiny and bright light sources that circle itself is often visible, you may have seen effects like the one in the demonstration below in some photographs captured in darker environments:&lt;/p&gt;
    &lt;p&gt;Notice that the circular shape is visible for lights both in front of and behind the focused distance. As the object is positioned closer or further away from the lens the image plane ‚Äúslices‚Äù the cone of light at different location:&lt;/p&gt;
    &lt;p&gt;That circular spot is called a circle of confusion. While in many circumstances the blurriness of the background or the foreground looks very appealing, it would be very useful to control how much blur there is.&lt;/p&gt;
    &lt;p&gt;Unfortunately, we don‚Äôt have total freedom here √¢ we still want the primary photographed object to remain in focus so its light has to converge to a point. We just want to change the size of the circle of out-of-focus objects without moving the central point. We can accomplish that by changing the angle of the cone of light:&lt;/p&gt;
    &lt;p&gt;There are two methods we can use to modify that angle. Firstly, we can change the focal length of the lens √¢ you may recall that with longer focal lengths the cone of light also gets longer. However, changing the focal length and keeping the primary object in focus requires moving the image plane which in turn changes how the picture is framed.&lt;/p&gt;
    &lt;p&gt;The alternative way of reducing the angle of the cone of light is to simply ignore some of the ‚Äúouter‚Äù rays. We can achieve that by introducing a stop with a hole in the path of light:&lt;/p&gt;
    &lt;p&gt;This hole is called an aperture. In fact, even the hole in which the lens is mounted is an aperture of some sort, but what we‚Äôre introducing is an adjustable aperture:&lt;/p&gt;
    &lt;p&gt;Let‚Äôs try to see how an aperture affects the photographs taken with our camera:&lt;/p&gt;
    &lt;p&gt;In real camera lenses an adjustable aperture is often constructed from a set of overlapping blades that constitute an iris. The movement of those blades changes the size of the aperture:&lt;/p&gt;
    &lt;p&gt;The shape of the aperture also defines the shape of bokeh. This is the reason why bokeh sometimes has a polygonal shape √¢ it‚Äôs simply the shape of the ‚Äúcone‚Äù of light after passing through the blades of the aperture. Next time you watch a movie pay a close attention to the shape of out-of-focus highlights, they‚Äôre often polygonal:&lt;/p&gt;
    &lt;p&gt;As the aperture diameter decreases, larger and larger areas of the photographed scene remain sharp. The term depth of field is used to define the length of the region over which the objects are acceptably sharp. When describing the depth of field we‚Äôre trying to conceptually demark those two boundary planes and see how far apart they are from each other.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs see the depth of field in action. The black slider controls the aperture, the blue slider controls the focal length, and the red slider changes the position of the object relative to the camera. The green dot shows the place of perfect focus, while the dark blue dots show the limits, or the depth, of positions between which the image of the red light source will be reasonably sharp, as shown by a single outlined pixel on the sensor:&lt;/p&gt;
    &lt;p&gt;Notice that the larger the diameter of aperture and the shorter the focal length the shorter the distance between the dark blue dots and thus the shallower the depth of field becomes. If you recall our discussion of sharpness this demonstration should make it easier to understand why reducing the angle of the cone increases the depth of field.&lt;/p&gt;
    &lt;p&gt;If you don‚Äôt have perfect vision you may have noticed that squinting your eyes make you see things a little better. Your eyelids covering some part of your iris simply act as an aperture that decreases the angle of the cone of light falling into your eyes making things sightly less blurry on your retina.&lt;/p&gt;
    &lt;p&gt;An interesting observation is that aperture defines the diameter of the base of the captured cone of light that is emitted from the object. Twice as large aperture diameter captures roughly four times more light due to increased solid angle. In practice, the actual size of the aperture as seen from the point of view of the scene, or the entrance pupil, depends on all the lenses in front of it as the shaped glass may scale the perceived size of the aperture.&lt;/p&gt;
    &lt;p&gt;On the other hand, when a lens is focused correctly, the focal length defines how large a source object is in the picture. By doubling the focal length we double the width and the height of the object on the sensor thus increasing the area by the factor of four. The light from the source is more spread out and each individual pixel receives less light.&lt;/p&gt;
    &lt;p&gt;The total amount of light hitting each pixel is proportional to the ratio between the focal length f and the diameter of the entrance pupil D. This ratio is known as the f-number:&lt;/p&gt;
    &lt;p&gt;A lens with a focal length of 50 mm and the entrance pupil of 25 mm would have N equal to 2 and the f-number would be known as f/2. Since the amount of light getting to each pixel of the sensor increases with the diameter of the aperture and decreases with the focal length, the f-number controls the brightness of the projected image.&lt;/p&gt;
    &lt;p&gt;The f-number with which commercial lenses are marked usually defines the maximum aperture a lens can achieve and the smaller the f-number the more light the lens passes through. Bigger amount of incoming light allows reduction of exposure time, so the smaller the f-number the faster the lens is. By reducing the size of the aperture we can modify the f-number with which a picture is taken.&lt;/p&gt;
    &lt;p&gt;The f-numbers are often multiples of 1.4 which is an approximation of 2. Scaling the diameter of an adjustable aperture by 2 scales its area by 2 which is a convenient factor to use. Increasing the f-number by a so-called stop halves the amount of received light. The demonstration below shows the relatives sizes of the aperture through which light is being seen:&lt;/p&gt;
    &lt;p&gt;To maintain the overall brightness of the image when stopping down we‚Äôd have to either increase the exposure time or the sensitivity of the sensor.&lt;/p&gt;
    &lt;p&gt;While aperture settings let us easily control the depth of field, that change comes at a cost. When the f-number increases and the aperture diameter gets smaller we effectively start approaching a pinhole camera with all its related complications.&lt;/p&gt;
    &lt;p&gt;In the final part of this article we will discuss the entire spectrum of another class of problems that we‚Äôve been conveniently avoiding all this time.&lt;/p&gt;
    &lt;head rend="h1"&gt;Aberrations&lt;/head&gt;
    &lt;p&gt;In our examples so far we‚Äôve been using a perfect idealized lens that did exactly what we want and in all the demonstrations I‚Äôve relied on a certain simplification known as the paraxial approximation. However, the physical world is a bit more complicated.&lt;/p&gt;
    &lt;p&gt;The most common types of lenses are spherical lenses √¢ their curved surfaces are sections of spheres of different radii. These types of lenses are easier to manufacture, however, they actually don‚Äôt perfectly converge the rays of incoming light. In the demonstration below you can observe how fuzzy the focus point is for various lens radii:&lt;/p&gt;
    &lt;p&gt;This imperfection is known as spherical aberration. This specific flaw can be corrected with aspheric lenses, but unfortunately there are other types of problems that may not be easily solved by a single lens. In general, for monochromatic light there are five primary types of aberrations: spherical aberration, coma, astigmatism, field curvature, and distortion.&lt;/p&gt;
    &lt;p&gt;We‚Äôre still not out of the woods even if we manage to minimize these problems. In normal environments light is very non-monochromatic and nature sets another hurdle into optical system design. Let‚Äôs quickly go back to the dark environment as we‚Äôll be discussing a single beam of white light.&lt;/p&gt;
    &lt;p&gt;Observe what happens to that beam when it hits a piece of glass. You can make the sides non-parallel by using the slider:&lt;/p&gt;
    &lt;p&gt;What we perceive as white light is a combination of lights of different wavelengths. In fact, the index of refraction of materials depends on the wavelength of the light. This phenomena called dispersion splits what seems to be a uniform beam of white light into a fan of color bands. The very same mechanism that we see here is also responsible for a rainbow.&lt;/p&gt;
    &lt;p&gt;In a lens this causes different wavelengths of light to focus at different offsets √¢ the effect known as chromatic aberration. We can easily visualize the axial chromatic aberration even on a lens with spherical aberration fixed. I‚Äôll only use red, green, and blue dispersed rays to make things less crowded, but remember that other colors of the spectrum are present in between. Using the slider you can control the amount of dispersion the lens material introduces:&lt;/p&gt;
    &lt;p&gt;Chromatic aberration may be corrected with an achromatic lens, usually in the form of a doublet with two different types of glass fused together.&lt;/p&gt;
    &lt;p&gt;To minimize the impact of the aberrations, camera lenses use more than one optical element on their pathways. In this article I‚Äôve only shown you simple lens systems, but a high-end camera lens may consist of a lot of elements that were carefully designed to balance the optical performance, weight, and cost.&lt;/p&gt;
    &lt;p&gt;While we, in our world of computer simulations on this website, can maintain the illusion of simple and perfect systems devoid of aberrations, vignetting, and lens flares, real cameras and lenses have to deal with all these problems to make the final pictures look good.&lt;/p&gt;
    &lt;head rend="h1"&gt;Further Watching and Reading&lt;/head&gt;
    &lt;p&gt;Over on YouTube Filmmaker IQ channel has a lot of great content related to lenses and movie making. Two videos especially fitting here are The History and Science of Lenses and Focusing on Depth of Field and Lens Equivalents.&lt;/p&gt;
    &lt;p&gt;What Makes Cinema Lenses So Special!? on Potato Jet channel is a great interview with Art Adams from ARRI. The video goes over many interesting details of high-end cinema lens design, for example, how the lenses compensate for focus breathing, or how much attention is paid to the quality of bokeh.&lt;/p&gt;
    &lt;p&gt;For a deeper dive on bokeh itself Jakub Tr√É¬°vn√Ék‚Äôs On Bokeh is a great article on the subject. The author explains how aberrations may cause bokeh of non uniform intensity and shows many photographs of real cameras and lenses.&lt;/p&gt;
    &lt;p&gt;In this article I‚Äôve mostly been using geometrical optics with some soft touches of electromagnetism. For a more modern look at the nature of light and its interaction with matter I recommend Richard Feynman‚Äôs QED: The Strange Theory of Light and Matter. The book is written in a very approachable style suited for general audience, but it still lets Feynman‚Äôs wits and brilliance shine right through.&lt;/p&gt;
    &lt;head rend="h1"&gt;Final Words&lt;/head&gt;
    &lt;p&gt;We√¢ve barely scratched the surface of optics and camera lens design, but even the most complex systems end up serving the same purpose: to tell light where to go. In some sense optical engineering is all about taming the nature of light.&lt;/p&gt;
    &lt;p&gt;The simple act of pressing the shutter button in a camera app on a smartphone or on the body of a high-end DSLR is effortless, but it√¢s at this moment when, through carefully guided rays hitting an array of photodetectors, we immortalize reality by painting with light.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ciechanow.ski/cameras-and-lenses/"/><published>2026-01-01T17:18:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46456215</id><title>Memory Subsystem Optimizations</title><updated>2026-01-01T21:38:10.850042+00:00</updated><content>&lt;doc fingerprint="ef7fd4586d6321ad"&gt;
  &lt;main&gt;
    &lt;p&gt;In this blog I wrote 18 blog posts about memory subsystem optimizations. By memory subsystem optimizations, I mean optimizations that aim at making software faster by better using the memory subsystem. Most of them are applicable to software that works with large datasets; but some of them are applicable to software that works with any data regardless of its size.&lt;/p&gt;
    &lt;p&gt;Do you need to discuss a performance problem in your project? Or maybe you want a vectorization training for yourself or your team? Contact us &lt;lb/&gt;Or follow us on LinkedIn , Twitter or Mastodon and get notified as soon as new content becomes available.&lt;/p&gt;
    &lt;p&gt;Here is a list of all posts that we covered on Johnny‚Äôs Software Lab:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Topic&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Link&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Decreasing Total Memory Accesses&lt;/cell&gt;
        &lt;cell&gt;We speed up software by keeping data in registers instead of reloading it from the memory subsystem several times.&lt;/cell&gt;
        &lt;cell&gt;Decreasing the Number of Memory Accesses 1/2&lt;p&gt;Decreasing the Number of Memory Accesses: The Compiler‚Äôs Secret Life 2/2&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Changing the Data Access Pattern to Increase Locality&lt;/cell&gt;
        &lt;cell&gt;By changing our data access pattern we increase the possibility our data is in the fastest level of data cache.&lt;/cell&gt;
        &lt;cell&gt;For Software Performance, the Way Data is Accessed Matters!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Changing the Data Layout: Classes&lt;/cell&gt;
        &lt;cell&gt;Selecting proper class data layout can improve software performance.&lt;/cell&gt;
        &lt;cell&gt;Software Performance and Class Layout&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Changing the Data Layout: Data Structures&lt;/cell&gt;
        &lt;cell&gt;By changing the data layout of common data structures, such as linked lists, trees or hash maps we can improve their performance.&lt;/cell&gt;
        &lt;cell&gt;Faster hash maps, binary trees etc. through data layout modification&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Decreasing the Dataset Size&lt;/cell&gt;
        &lt;cell&gt;Memory efficiency can be improved by decreasing the dataset size. This results in speed improvements as well.&lt;/cell&gt;
        &lt;cell&gt;Memory consumption, dataset size and performance: how does it all relate?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Changing the Memory Layout&lt;/cell&gt;
        &lt;cell&gt;Whereas data layout is determined at compile time, memory layout is determined by the system allocator at runtime. We examine how changing the memory layout using custom allocators influences software performance.&lt;/cell&gt;
        &lt;cell&gt;Performance Through Memory Layout&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Increasing instruction-level parallelism&lt;/cell&gt;
        &lt;cell&gt;Some codes cannot utilize the memory subsystem fully because of instruction dependencies. Here we investigate techniques that break dependencies and improve performance.&lt;/cell&gt;
        &lt;cell&gt;Instruction-level parallelism in practice: speeding up memory-bound programs with low ILP&lt;p&gt;Hiding Memory Latency With In-Order CPU Cores OR How Compilers Optimize Your Code&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Software prefetching for random data accesses&lt;/cell&gt;
        &lt;cell&gt;Explicit software prefetches tell hardware that you will be accessing a certain piece of data soon. When used smartly, they can improve software performance.&lt;/cell&gt;
        &lt;cell&gt;The pros and cons of explicit software prefetching&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Decreasing TLB cache misses&lt;/cell&gt;
        &lt;cell&gt;TLB cache is a small cache that speeds up translation of virtual to physical memory addresses. In some cases, it can be the reason for poor performance. We investigate techniques for decreasing TLB cache misses.&lt;/cell&gt;
        &lt;cell&gt;Speeding Up Translation of Virtual To Physical Memory Addresses: TLB and Huge Pages&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Saving the memory subsystem bandwidth&lt;/cell&gt;
        &lt;cell&gt;In some cases, we don‚Äôt care about software performance, but we do care about being a good neighbor. We investigate techniques that make our software consume least possible amount of memory subsystem resources.&lt;/cell&gt;
        &lt;cell&gt;Frugal Programming: Saving Memory Subsystem Bandwidth&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Branch prediction and data caches&lt;/cell&gt;
        &lt;cell&gt;We investigate the delicate interplay of the branch prediction and the memory subsystem.&lt;/cell&gt;
        &lt;cell&gt;Unexpected Ways Memory Subsystem Interacts with Branch Prediction&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Multithreading and the Memory Subsystem&lt;/cell&gt;
        &lt;cell&gt;Here we investigate how memory subsystem behaves in the presence of multithreading and how does that effect software speed.&lt;/cell&gt;
        &lt;cell&gt;Multithreading and the Memory Subsystem&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Low-latency applications&lt;/cell&gt;
        &lt;cell&gt;In some cases we are more interested in short latency than high throughput. We investigate the techniques aimed at improving latency, either by modifying our programs, or reconfiguring the system.&lt;/cell&gt;
        &lt;cell&gt;Latency-Sensitive Applications and the Memory Subsystem: Keeping the Data in the Cache&lt;p&gt;Latency-Sensitive Application and the Memory Subsystem Part 2: Memory Management Mechanisms&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Measuring Memory Subsystem Performance&lt;/cell&gt;
        &lt;cell&gt;We talk about tools and metrics you can use to understand what is going on with the memory subsystem.&lt;/cell&gt;
        &lt;cell&gt;Measuring Memory Subsystem Performance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Other topics&lt;/cell&gt;
        &lt;cell&gt;A few remaining topics related to memory subsystem optimizations that didn‚Äôt fit any of the other categories.&lt;/cell&gt;
        &lt;cell&gt;Memory Subsystem Optimizations ‚Äì The Remaining Topics&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Any feedback on the material covered in this posts will be highly appreciated.&lt;/p&gt;
    &lt;p&gt;Do you need to discuss a performance problem in your project? Or maybe you want a vectorization training for yourself or your team? Contact us &lt;lb/&gt;Or follow us on LinkedIn , Twitter or Mastodon and get notified as soon as new content becomes available.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://johnnysswlab.com/memory-subsystem-optimizations/"/><published>2026-01-01T17:52:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46456387</id><title>Gemini 3.0 Deciphered the Mystery of a Nuremberg Chronicle Leaf's</title><updated>2026-01-01T21:38:10.179823+00:00</updated><content>&lt;doc fingerprint="a513d9ddd5b38fa6"&gt;
  &lt;main&gt;
    &lt;p&gt;The 1493 Nuremberg Chronicle by Hartmann Schedel (printed by Anton Koberger) was one of the earliest illustrated printed encyclopedias and marked a major milestone in the history of printing, being "one of the most densely illustrated and technically advanced works of early printing, with woodcuts by Michael Wolgemut and Wilhelm Pleydenwurff, while a young Albrecht D√ºrer trained in Wolgemut's workshop. In one particularly lavishly colored copy of the Chronicle, seen below, a set of four handwritten circular margin annotations (roundels) are seen with Roman numerals. While it is clear that the roundels represent dates relating to the World and to Christ (they begin with "anno" and either "mdi" or "xpi"), several experts who reviewed the page were unable to discern their meaning and thus their purpose had remained elusive. Given Gemini 3 Pro's heavy investment in visual understanding, we wanted to explore what insights it could offer that could help bring greater clarity to this mystery. It ended up solving the mystery entirely, richly incorporating the page contents to disambiguate and contextualize the roundels and reason through ambiguities and different possibilities to arrive at what would appear to be a highly plausible and fascinating explanation that they represent a previous owner's attempt to work through the conflicting date systems of the Greek Old Testament and Hebrew Bible to clarify the chronology of Abraham's birth.&lt;/p&gt;
    &lt;p&gt;While Gemini 3 Pro doesn't get things perfectly right (it misreads a few of the dates in the text which affects its precise date answers), the arguments it makes below are highly persuasive and represent the first plausible explanation of these margin annotations to date. It is incredible to think that LMM visual understanding has advanced to the point that Gemini 3 Pro could read 500-year-old handwritten abbreviated shorthand marginalia, go back and read the entire printed page and use the contents of the page to work through and disambiguate the meaning of the shorthand, then put all of that information together to come up with a final understanding that fit all of the puzzle pieces , all without any human assistance of any kind.&lt;/p&gt;
    &lt;p&gt;Below you can see the full two-page spread (click to zoom):&lt;/p&gt;
    &lt;p&gt;Here are zooms of each of the four roundels (click to zoom):&lt;/p&gt;
    &lt;p&gt;We simply uploaded these five images into Gemini 3 Pro with High Media Resolution and gave it the following prompt:&lt;/p&gt;
    &lt;quote&gt;Attached are two pages from the Nuremberg Chronicle. At the bottom of the page a previous owner of the book drew four circles and wrote Latin text in them. It was probably written sometime from 1493 to 1600s for context. I've also attached zoomed up images of the four circles. For each of them, transcribe the Latin and translate into English and tell me its meaning and importance. They relate to the text in the page, so use the page text to decipher and contextualize them.&lt;/quote&gt;
    &lt;p&gt;Below you can see its final answer, which cost just $0.026008:&lt;/p&gt;
    &lt;p&gt;Based on the images provided from the Nuremberg Chronicle (Folio XXII), here is the transcription, translation, and analysis of the four handwritten circles.&lt;/p&gt;
    &lt;p&gt;The annotator has created a "conversion table" to clarify the chronology of Abraham's birth. The Nuremberg Chronicle presents two conflicting dates for this event based on different textual authorities: the Septuagint (the Greek Old Testament) and the Hebrew Bible (the Masoretic text). The annotator has extracted these "Year of the World" (Anno Mundi) dates from the printed text and calculated the corresponding "Before Christ" dates.&lt;/p&gt;
    &lt;p&gt;Here is the breakdown from Left to Right (based on the wide shot of the bottom of the page).&lt;/p&gt;
    &lt;head rend="h3"&gt;Circle 1 (Far Left)&lt;/head&gt;
    &lt;p&gt;Image: 3rd image provided&lt;/p&gt;
    &lt;p&gt;Latin Transcription:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Anno mdi [mundi]&lt;/p&gt;&lt;lb/&gt;iii^m c lxxx iiii&lt;/quote&gt;
    &lt;p&gt;English Translation:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Year of the World&lt;/p&gt;&lt;lb/&gt;3184&lt;/quote&gt;
    &lt;p&gt;Context &amp;amp; Meaning:&lt;lb/&gt; This number comes directly from the printed text at the top left of the page: "Incipit in Abrahe nativitate‚Ä¶ Anno mundi fm [secundum] lxx‚Ä¶ 3184" (The [Third Age] begins with the birth of Abraham‚Ä¶ Year of the world according to the 70 interpreters [Septuagint]‚Ä¶ 3184).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;The Numeral: It is written as iii (3) m (thousand) c (100) lxxx (80) iiii (4).&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Circle 2 (Middle Left)&lt;/head&gt;
    &lt;p&gt;Image: 2nd image provided&lt;/p&gt;
    &lt;p&gt;Latin Transcription:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Anno an [ante]&lt;/p&gt;&lt;lb/&gt;xpi [Christi] incarnat [incarnationem]&lt;lb/&gt;ii^m xv [or possibly ii^m &amp;amp; xv]&lt;/quote&gt;
    &lt;p&gt;English Translation:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Year before&lt;/p&gt;&lt;lb/&gt;the incarnation of Christ&lt;lb/&gt;2015&lt;/quote&gt;
    &lt;p&gt;Context &amp;amp; Meaning:&lt;lb/&gt; This circle is the pair to Circle 1. The annotator has calculated the date of Abraham's birth in "BC" (Before Christ) terms based on the Septuagint timeline.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;The Math: Medieval chronicles often placed the Creation of the World at 5199 BC (according to Eusebius). If you subtract the Year of the World (3184) from the date of Creation (5199), you get 2015.&lt;/item&gt;
              &lt;item&gt;Significance: The annotator is noting that, according to the Greek tradition, Abraham was born in 2015 BC.&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Circle 3 (Middle Right)&lt;/head&gt;
    &lt;p&gt;Image: 1st image provided&lt;/p&gt;
    &lt;p&gt;Latin Transcription:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Anno mdi [mundi]&lt;/p&gt;&lt;lb/&gt;ii^m xL&lt;/quote&gt;
    &lt;p&gt;English Translation:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Year of the World&lt;/p&gt;&lt;lb/&gt;2040&lt;/quote&gt;
    &lt;p&gt;Context &amp;amp; Meaning:&lt;lb/&gt; This number comes directly from the printed text in the first paragraph: "Anno mundi fm [secundum] heb. 2040" (Year of the world according to the Hebrews‚Ä¶ 2040).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;The Numeral: It is written as ii (2) m (thousand) xL (40).&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Circle 4 (Far Right)&lt;/head&gt;
    &lt;p&gt;Image: 4th image provided&lt;/p&gt;
    &lt;p&gt;Latin Transcription:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Anno an [ante]&lt;/p&gt;&lt;lb/&gt;xpi [Christi] na.te [nativitate]&lt;lb/&gt;i^m ix^c xv&lt;/quote&gt;
    &lt;p&gt;English Translation:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Year before&lt;/p&gt;&lt;lb/&gt;the birth of Christ&lt;lb/&gt;1915&lt;/quote&gt;
    &lt;p&gt;Context &amp;amp; Meaning:&lt;lb/&gt; This circle is the pair to Circle 3. The annotator has calculated the date of Abraham's birth in "BC" terms based on the Hebrew timeline.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;The Numeral: It appears to be written as i (1) m (thousand) ix (9) c (hundred) xv (15). Writing "nine hundreds" as ix c rather than cm or dcccc was a somewhat informal scribal shorthand.&lt;/item&gt;
              &lt;item&gt;The Math: If Abraham was born in AM 2040, and the date is 1915 BC, the annotator is working from a "Hebrew Verity" creation date of roughly 3955 BC (2040 + 1915). This differs from the Septuagint creation date (5199 BC) but aligns with the discrepancies medieval scholars faced when reconciling the two versions of the Bible.&lt;/item&gt;
              &lt;item&gt;Significance: The annotator is noting that, according to the Hebrew tradition, Abraham was born in 1915 BC‚Äîexactly 100 years later than the Greek calculation (2015 BC).&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Summary of Importance&lt;/head&gt;
    &lt;p&gt;These circles reveal a sophisticated reader from the 16th or 17th century engaging with the text. The Nuremberg Chronicle is a history of the world, and for a Christian reader of that era, understanding the exact timeline of the Patriarchs relative to Jesus was crucial for theology and history.&lt;/p&gt;
    &lt;p&gt;The annotator realized the printed text offered two contradictory dates (3184 AM vs. 2040 AM). To make this useful, they:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;
            &lt;list rend="ol"&gt;
              &lt;item&gt;Extracted the conflicting dates (Circles 1 and 3).&lt;/item&gt;
              &lt;item&gt;Converted them both into a unified "Before Christ" countdown (Circles 2 and 4).&lt;/item&gt;
              &lt;item&gt;Highlighted that regardless of which calculation used, the dates are exactly 100 years apart (2015 BC vs 1915 BC).&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In this case the Model Thoughts are quite informative, which you can see below:&lt;/p&gt;
    &lt;p&gt;Focusing on Nuremberg Chronicle&lt;/p&gt;
    &lt;p&gt;I've been analyzing the Nuremberg Chronicle pages, specifically Folio XXII. I'm zeroing in on the "Four" element within the Tercia etas mundi. The visual and textual interplay is fascinating and might yield interesting interpretations. The specific section on the "Four" is a potential goldmine for deeper insight.&lt;/p&gt;
    &lt;p&gt;Decoding Handwritten Circles&lt;/p&gt;
    &lt;p&gt;I've made progress on the handwritten circles on Folio XXII of the Nuremberg Chronicle. The gothic script is challenging, but I've managed a tentative transcription and translation of the Latin text within the circles. These dates and names seem to be adding additional context to the existing text, probably as annotations made at a later point in time. I'm carefully analyzing the relationship between the circles and the printed text, considering the impact of the added material.&lt;/p&gt;
    &lt;p&gt;Deciphering Numerals&lt;/p&gt;
    &lt;p&gt;I'm now focusing on the bottom-left circle's numerals. Initially, I read "2164", but the script is unconventional. Combining Arabic and Roman, it could be 2164, but the Nuremberg Chronicle text mentions a Year of the World of 2075 at a point of significance. This discrepancy demands closer scrutiny. The handwriting could be intentionally mixing methods or representing a variant dating system.&lt;/p&gt;
    &lt;p&gt;Revising Numerical Interpretations&lt;/p&gt;
    &lt;p&gt;I'm now re-examining the numerals within the second circle. The transcription seemed straightforward, but the resulting date of 2085 before Christ presents a chronological impossibility concerning Abraham's birth, placing it too far away in the future. The inscription should read "Anno ante Christi incarnationem". Perhaps there's an error in my initial transcription of "ii m lxxx v". I'm re-assessing each character and considering alternative interpretations, given the known timeline for Abraham.&lt;/p&gt;
    &lt;p&gt;Analyzing Circle Numerals&lt;/p&gt;
    &lt;p&gt;I'm now revising my interpretation of the numerals. It's not "ii m," it looks like "u m." However, let's explore this. The printed text indicates "2040 annis" from Adam to Abraham, which is an interesting point. I've re-examined the numerals, and they might represent a different, perhaps period-specific, system. Let's look at it like 1985. Abraham's traditional date helps confirm this. Are these specific calculations derived from the text, or a known system? Let's check against the style used at the time. Finally, I'm examining the first circle's numerals.&lt;/p&gt;
    &lt;p&gt;Clarifying Circle One Numerals&lt;/p&gt;
    &lt;p&gt;I'm now focusing on the first circle. After re-examining the handwriting, it's clear the numerals are iii m c lxxx iiii, which translates directly to 3184. The textual reference confirms this. I've successfully transcribed it as "Anno Mundi 3184," and I now move on. This confirms my ability to interpret these unique annotations. The next circle is now the focus.&lt;/p&gt;
    &lt;p&gt;Examining Circle Correlations&lt;/p&gt;
    &lt;p&gt;I'm now investigating the relationship between the "Year of the World" and "Year Before Christ" dates in the circles. Circle 4, labeled "Anno an xpi na.t / ii m xv", seems to indicate "2015" years before Christ's birth. This presents a direct contrast with the 2040 and 3184 dates of the other circles, which align to Year of the World calculations. The implications are significant for understanding the annotation's intended timeline. Perhaps this is a variant date-system, or an alternate calculation of the text. I'm focusing on the relationship between these numbers.&lt;/p&gt;
    &lt;p&gt;Correlating Date Systems&lt;/p&gt;
    &lt;p&gt;I'm now investigating how the various annotations relate to each other, considering the different dating systems they employ. Specifically, the annotations in the circles are using either the Septuagint's dating method or the Ussher's/Hebrew system. If the world was created in 5199 BC, the AM 3184 of circle 1 equals 2015 BC. It now appears that circle 2 agrees with this, but it is necessary to check the ink strokes for accuracy. So it does seem that circles 1 and 2 are a pair within the Septuagint system.&lt;/p&gt;
    &lt;p&gt;Examining Circle Four Numerals&lt;/p&gt;
    &lt;p&gt;I'm now focusing on Circle 4's numerals. I initially misinterpreted the inscription. With careful re-examination, the Latin inscription reads: "Anno ante christi nati / I m ix c xL," which translates to 1940. This is based on a Septuagint dating system and aligns with the expected timeline of the printed text's "Year of the World" values and matches the handwritten annotations. This confirms the circle's significance in establishing the timeline.&lt;/p&gt;
    &lt;p&gt;Revising Circle Interpretation&lt;/p&gt;
    &lt;p&gt;I'm now back at analyzing Circle 4. After revisiting the inscriptions, I can see that it reads: "i m ix c xlv". This should translate to 1945, using the Septuagint system. However, the Hebrew dating system would lead to 2040. This confirms that these annotations are using a more modern system of the time. The numerical relationship is now clearer, and all circles seem to employ dating that aligns with the Septuagint system.&lt;/p&gt;
    &lt;p&gt;Confirming Circle Calculations&lt;/p&gt;
    &lt;p&gt;I'm now cross-referencing the calculations across the circles. After examining the handwriting in circle four, I've confirmed that the numerals read "Anno an xpi nate / i m ix c xx", or 1920. However, using the Hebrew dating system, Abraham's birth in AM 2040 and Christ's birth in AM 3960 means the creation year is 3960. I need to verify if 3960 is a common creation date in the Nuremberg Chronicle.&lt;/p&gt;
    &lt;p&gt;Mapping Circle Calculations&lt;/p&gt;
    &lt;p&gt;I'm now drafting a concise interpretation of the circles, noting the annotator's calculations. After further analysis, the first circle yields 1920 BC, when employing the Septuagint system. Similarly, the second circle translates to 2015 BC. However, upon reviewing, the fourth circle inscription reads "i m ix c xx", or 1920. Therefore, the Annotator believed that the world was created in 5199 BC when applying Septuagint, but they understood the Hebrew at 3960.&lt;/p&gt;
    &lt;p&gt;Synthesizing Circle Data&lt;/p&gt;
    &lt;p&gt;I'm now pulling together the information from all circles to present a cohesive picture. It's clear that the annotator was engaging with the printed text's timelines, employing both "Year of the World" and "Anno ante Christum" calculations. The discrepancies between the Septuagint and Hebrew dating systems are now highlighted by these annotations, indicating a deliberate effort to align these differing timelines. The annotator seemed to be primarily following a Septuagint system, given the majority of calculations.&lt;/p&gt;
    &lt;p&gt;Finalizing Date Conversions&lt;/p&gt;
    &lt;p&gt;I've finally finished interpreting the annotations. The circles represent a fascinating interplay between different chronological systems. The annotator seemed focused on reconciling Hebrew and Septuagint dating, as the calculations demonstrate this. I am now refining the reasoning of why these annotations were created, which is a conversion guide to reconcile different timelines. All of these points will inform my broader understanding.&lt;/p&gt;
    &lt;p&gt;Synthesizing Circle Data&lt;/p&gt;
    &lt;p&gt;I'm now pulling together the information from all circles to present a cohesive picture. The annotator was attempting to provide translations of the BC dating used by the author of the Nuremberg Chronicle. The discrepancies between the Septuagint and Hebrew dating systems, as well as the newly-introduced BC system, are highlighted by these annotations, indicating a deliberate effort to align and translate differing timelines. The annotator seemed to be attempting to convert dates between systems, given the calculations and all the writing.&lt;/p&gt;
    &lt;p&gt;Summarizing Date Conversions&lt;/p&gt;
    &lt;p&gt;I'm now putting together the final structure to represent the key annotations. I've confirmed all date conversions, aligning with either the Eusebian or the Hebrew chronology system, depending on the annotator's preference. Using the Septuagint system, I now have a cohesive narrative about the numerical annotation system, but still not the reason for the annotations. The overall image will now be structured in a way that will be easy to understand.&lt;/p&gt;
    &lt;p&gt;Analyzing Annotated Dates&lt;/p&gt;
    &lt;p&gt;I'm now focusing on the circle three annotation. After review, it confirms to read "2040", directly aligning with the printed text's figure. Circle four, however, reads "1915," leading to a calculated creation date of 3955 BC, aligning with certain Hebraist calculations. This strengthens the argument that these annotations are a deliberate comparison of differing dating systems found in the book.&lt;/p&gt;
    &lt;p&gt;Let's see what Gemini 3 Pro thinks of the handwriting:&lt;/p&gt;
    &lt;quote&gt;analyze the handwriting of the four roundels and tell me about them. estimate the date range they were written and tell me about the writer. perform a detailed expert-level handwriting analysis.&lt;/quote&gt;
    &lt;p&gt;Based on a paleographic examination of the letterforms, ductus (flow), and abbreviations, here is an expert-level analysis of the handwriting found in these four roundels.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. General Characteristics &amp;amp; Script Classification&lt;/head&gt;
    &lt;p&gt;The script is a Cursiva Currens (running cursive) with heavy influence from Humanist Cursive.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;Hybrid Style: The handwriting sits at the intersection of late medieval Gothic traditions and the emerging Humanist style of the Renaissance. It retains the angularity and vertical compression of Gothic scripts (specifically Bastarda), but shows the spacing and legibility improvements of Humanist scripts.&lt;/item&gt;
              &lt;item&gt;Instrument: The writer used a quill pen with a relatively narrow, square-cut nib. You can see this in the variation between thick vertical strokes and thin horizontal connectors (hairlines), particularly in the Roman numerals.&lt;/item&gt;
              &lt;item&gt;Ink: The ink is a standard iron-gall ink which has oxidized to a warm brown/sepia tone over the centuries.&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;2. Detailed Paleographic Analysis of Letterforms&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;The Letter 'd' (Uncial style): In the word mundi (written as mdi or m^di), the writer uses a looped "uncial d." The ascender loops backward to the left. This is a very common feature in Germanic handwriting of the 15th and 16th centuries.&lt;/item&gt;
              &lt;item&gt;The Letter 'x' (in xpi and numerals): The 'x' is formed by two strokes. The second stroke (top right to bottom left) is often elongated and descends below the baseline, curving slightly. This "long x" is diagnostic of 16th-century cursive hands.&lt;/item&gt;
              &lt;item&gt;The Letter 'A' (in Anno): The capital 'A' is constructed almost like an enlarged lowercase 'a' or a simple tent. It lacks the elaborate flourishing of a professional scribe, indicating this was a personal note for utility, not display.&lt;/item&gt;
              &lt;item&gt;Minims (i, n, m): The "minims"‚Äîthe short vertical strokes used to make these letters‚Äîare unconnected at the baseline but connected at the topline (in 'n' and 'm'). This gives the script a "sawtooth" appearance common in Germanic Kurrent precursors.&lt;/item&gt;
              &lt;item&gt;Abbreviations: The writer uses standard medieval scribal abbreviations with ease: &lt;list rend="ul"&gt;&lt;item&gt;The tilde (macron) over vowels to indicate missing 'n' or 'm' (seen in an for ante).&lt;/item&gt;&lt;item&gt;The specialized contraction for Christi (xpi), using Greek Chi-Rho-Iota letters but written with Latin ductus.&lt;/item&gt;&lt;item&gt;The superscript letters (e.g., iii^m for tria milia / 3000), showing an understanding of algebraic notation conventions of the time.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;3. Dating the Handwriting&lt;/head&gt;
    &lt;p&gt;Estimated Range: 1500 ‚Äì 1550&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;Terminus Post Quem: The book was printed in 1493, so it cannot be earlier.&lt;/item&gt;
              &lt;item&gt;Style Evidence: The script is not the heavy, blocky Gothic of the 1400s, nor is it the flowing, looped Copperplate or developed Secretary hand of the 1600s.&lt;/item&gt;
              &lt;item&gt;The "Germanic" Flavor: The specific way the Roman numerals are formed‚Äîparticularly the use of ix connected almost like a y and the sharp angles of the L‚Äîstrongly suggests a German-speaking region in the first half of the 16th century. This aligns perfectly with the Nuremberg Chronicle's origins.&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;4. Profiling the Writer&lt;/head&gt;
    &lt;p&gt;We can deduce a significant amount about the person who wrote this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;Highly Educated: The writer is fluent in Latin abbreviations. More importantly, they possess mathematical literacy. They are not just copying numbers; they are converting "Anno Mundi" (Year of the World) to a "BC" count. This requires the ability to subtract Roman numerals and manage two different chronological epochs (Hebrew vs. Septuagint) simultaneously.&lt;/item&gt;
              &lt;item&gt;Theological/Historical Focus: The writer is concerned with the "chronological problem" of the Old Testament. In the Reformation era (early 1500s), establishing the exact timeline of Biblical events was a major scholarly obsession.&lt;/item&gt;
              &lt;item&gt;Provenance: Given the script style (the uncial 'd', the sharp 'r' rotunda shapes implied in abbreviations), the writer was likely German or Swiss.&lt;/item&gt;
              &lt;item&gt;Personality: The circles are drawn freehand, without a compass, yet they are fairly round. The handwriting is confident and rapid. This suggests a scholar working in a private study‚Äîperhaps a university student, a monk, or a protestant pastor‚Äîusing the book as a working tool rather than a precious object to be preserved.&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Conclusion:&lt;lb/&gt; The writer was likely a German scholar or cleric active in the early-to-mid 16th century. They possessed a "utilitarian scholarly hand"‚Äîefficient, legible to the initiated, and designed for marginalia. They were actively using the chronicle to reconcile conflicting biblical timelines, a common intellectual pursuit during the Renaissance and Reformation.&lt;/p&gt;
    &lt;p&gt;And Gemini's Model Thoughts:&lt;/p&gt;
    &lt;p&gt;Considering the Roundels&lt;/p&gt;
    &lt;p&gt;I'm currently focused on the four handwritten roundels and the Latin text, trying to understand the full context. My goal is to provide a comprehensive analysis of the handwriting. This includes a detailed breakdown of the letterforms, the pressure used, and any stylistic choices. The Nuremberg Chronicle provides helpful background.&lt;/p&gt;
    &lt;p&gt;Analyzing the Handwriting's Details&lt;/p&gt;
    &lt;p&gt;I'm starting to get a clear picture of the script's characteristics. I've noted the brown/sepia ink, hinting at iron-gall. It's a practiced yet informal hand, not a formal book hand but also not a frantic scrawl. My initial inspection reveals freehand circles drawn with a quill, indicating a casual annotation. Now, I'm focusing on a letter-by-letter analysis to define the script type as likely transitional, with Gothic Cursive influences merging into Humanist Cursive elements, pointing toward the 16th century.&lt;/p&gt;
    &lt;p&gt;Dissecting Key Letters&lt;/p&gt;
    &lt;p&gt;I am now focusing on the specific letterforms. The capital 'A' in "Anno" and the 'x' are particularly interesting; the 'A' has a high crossbar and spur, and the 'x' has a jagged, descending stroke. I've also examined the minim-based 'n' and 'm,' and the 'p' with its distinctive descender. The abbreviation above the 'p' confirms it signifies Christi. The 'y' or 'ii' in numerals is typical. These details support my ongoing analysis of the transitional script type.&lt;/p&gt;
    &lt;p&gt;Examining Roman Numerals&lt;/p&gt;
    &lt;p&gt;I'm now zeroing in on the numerals within the circles. The 'x's consistently represent tens, and I'm scrutinizing the variant 'y'-shape in Circle 4, possibly an 'ix'. The 'L' in Circle 2 is quite distinctive. The uncial 'd' in "mundi" confirms a strong Gothic influence. The tildes are consistent shorthand.&lt;/p&gt;
    &lt;p&gt;Establishing the Timeframe&lt;/p&gt;
    &lt;p&gt;I'm solidifying the date of the handwriting. Based on a terminus post quem of 1493 from the Nuremberg Chronicle and considering style, I've ruled out both Secretary and Bastarda hands. This points to a continental Humanist-influenced Cursive, likely from Germany or Italy. The Roman and Arabic numeral mixture confirms a 16th-century date. Notably, the writer's use of "ix^c" for 900 indicates an Arabic math influence, common in the mid-1500s. I also see a highly educated writer with mastery of Latin abbreviations, which will help with my profile of them.&lt;/p&gt;
    &lt;p&gt;Determining Writer's Identity&lt;/p&gt;
    &lt;p&gt;I'm now focusing on the writer's profession and origin. The knowledge of both "Year of the World" and "BC" dating systems suggests a cleric or scholar. The letter style reinforces a Central European origin, consistent with the Nuremberg Chronicle. This annotator was an active reader, likely clarifying the text for others.&lt;/p&gt;
    &lt;p&gt;Interpreting Cursive Nuances&lt;/p&gt;
    &lt;p&gt;I'm now integrating the handwriting analysis with the chronological context, seeking to understand the annotator's thought process. The ligatured "ix" within the Roman numerals, initially misread as a "y", highlights the cursive nature of the script, reinforcing that it's a quick, in-the-moment annotation. The hand-drawn circles also confirm this impression. It's becoming clear that this was not a formal record but a reader's engagement with the text.&lt;/p&gt;
    &lt;p&gt;Finally, for those interested in what the full page text says, we asked Gemini 3 Pro to do that too:&lt;/p&gt;
    &lt;quote&gt;give me a complete transcription (everything) of this page in its original latin and then a complete translation into english. make it as a table with each row as a sentence and the first column is the latin and the second is the english translation of that sentence so it can follow the text easily.&lt;/quote&gt;
    &lt;p&gt;Here is the complete transcription and translation of the two-page spread from the Nuremberg Chronicle (1493).&lt;/p&gt;
    &lt;p&gt;Notes on the Transcription:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The original text uses many scribal abbreviations (e.g., m≈´di for mundi, oƒ´m for omnium, ƒì for est). I have expanded these in the Latin column for readability.&lt;/item&gt;
      &lt;item&gt;The text is divided into the Left Page (Folio XXI Verso) and the Right Page (Folio XXII Recto).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Left Page (Folio XXI Verso)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Latin Transcription (Expanded)&lt;/cell&gt;
        &lt;cell&gt;English Translation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[Header] Tercia etas mundi&lt;/cell&gt;
        &lt;cell&gt;[Header] The Third Age of the World&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Tercia igitur etas incipit in Abrahe nativitate et durat usque ad David secundum hebreos .940. annis. secundum septuaginta interpretes .m.cccc.xl. Ubi etiam patriarcharum nostrorum quam verum coluerunt historia incipit.&lt;/cell&gt;
        &lt;cell&gt;The Third Age therefore begins with the birth of Abraham and lasts until David; according to the Hebrews, for 940 years, and according to the seventy interpreters [the Septuagint], for 1440 years. Here also begins the history of our patriarchs, which they cultivated as true.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Abraham itaque pater multitudinis genitus ex thare in hur caldeorum nascitur. anno mundi secundum hebreos .2043. secundum septuaginta interpretes .3184.&lt;/cell&gt;
        &lt;cell&gt;Abraham, therefore, the "father of a multitude," begotten of Terah, is born in Ur of the Chaldees in the year of the world 2043 according to the Hebrews, and 3184 according to the seventy interpreters.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Vir prudens et rerum divinarum humanarumque eruditissimus primus deum cunctarum creatorem punciaus. propter quod caldei in eum surgentes et caldea migrare coegerunt.&lt;/cell&gt;
        &lt;cell&gt;A prudent man and most learned in divine and human matters, he was the first to proclaim God as the creator of all things; because of this, the Chaldeans rose up against him and forced him to migrate from Chaldea.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Qui abraham eductus a patre suo thare de hur caldeorum venerat in aram. ibique habitatum precepit ei dominus dicens.&lt;/cell&gt;
        &lt;cell&gt;This Abraham, led out by his father Terah from Ur of the Chaldees, came into Haran. And while dwelling there, the Lord commanded him, saying:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Egredere de terra tua et de cognatione tua et de domo patris tui. et veni in terram quam monstravero tibi.&lt;/cell&gt;
        &lt;cell&gt;"Go forth from your land, and from your kindred, and from your father's house, and come into the land which I shall show you."&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Postquam Abraham redisset de occisione quattuor regum assiriorum que ceperat Loth. occurrit ei melchisedech rex salem qui erat sacerdos dei summi offerens pane et vinum. cui Abraham dedit decimas omnium spoliorum benedixit abrahe que subdiderat ei inimicos.&lt;/cell&gt;
        &lt;cell&gt;After Abraham had returned from the slaughter of the four Assyrian kings who had captured Lot, Melchizedek, king of Salem, who was a priest of the most high God, met him offering bread and wine. To him Abraham gave tithes of all the spoils, and [Melchizedek] blessed Abraham because He had subdued his enemies for him.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Hunc melchisedech dicunt hebrei fuisse Sem filium Noe primogenitum et vixisse usque ad tempora abrahe. tunc apparuit abrahe dominus promisit ei filium quem multiplicaret sicut stellas celi.&lt;/cell&gt;
        &lt;cell&gt;The Hebrews say that this Melchizedek was Shem, the firstborn son of Noah, and that he lived until the times of Abraham. Then the Lord appeared to Abraham and promised him a son whom He would multiply like the stars of heaven.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[Genealogy Labels ‚Äì Tree Branches] &amp;lt;br&amp;gt; Jesboth &amp;lt;br&amp;gt; Sue &amp;lt;br&amp;gt; Madian &amp;lt;br&amp;gt; Medan &amp;lt;br&amp;gt; Jectan &amp;lt;br&amp;gt; Zamran &amp;lt;br&amp;gt; Cetura 2a uxor abrahe &amp;lt;br&amp;gt; Ismahel filius ex egipcia genitus &amp;lt;br&amp;gt; Agar ancilla ab[ra]he&lt;/cell&gt;
        &lt;cell&gt;[Genealogy Labels] &amp;lt;br&amp;gt; Ishbak &amp;lt;br&amp;gt; Shuah &amp;lt;br&amp;gt; Midian &amp;lt;br&amp;gt; Medan &amp;lt;br&amp;gt; Jokshan &amp;lt;br&amp;gt; Zimran &amp;lt;br&amp;gt; Keturah, 2nd wife of Abraham &amp;lt;br&amp;gt; Ishmael, son born of the Egyptian woman &amp;lt;br&amp;gt; Hagar, maidservant of Abraham&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[Text block near bottom left] &amp;lt;br&amp;gt; Saray prima uxor abrahe diu sterilis tandem gratia divina fecundata parit ysaac nonagenaria mulier sancta.&lt;/cell&gt;
        &lt;cell&gt;[Text block near bottom left] &amp;lt;br&amp;gt; Sarah, the first wife of Abraham, sterile for a long time, finally made fertile by divine grace, gives birth to Isaac as a ninety-year-old holy woman.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Cetura secunda uxor abrahe et habuit .vi. filios sapientia ornatos et industria. hac duxit abraham post mortem sare. nomina filiorum. zamra. jectan. medan. madia. jesboth et Sue.&lt;/cell&gt;
        &lt;cell&gt;Keturah was the second wife of Abraham and she had six sons adorned with wisdom and industry. Abraham married her after the death of Sarah. The names of the sons: Zimran, Jokshan, Medan, Midian, Ishbak, and Shuah.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Agar concubina abrahe. Ysmahel mulier et egiptia genuit duos filios. Iste ysmahel filius abrahe quem peperit agar egiptia ancilla sare. a quo ysmahelitarum genus. qui postea agareni postremo saraceni dicti sunt: eiectus e deserto paran cum matre. quia ludebat cum ysaac. i. icitabat eum ad ydolatriam vel ad ocium ymaginum quas faciebat de luto. quod videns sara dicebat eijce ancillam et filium eius.&lt;/cell&gt;
        &lt;cell&gt;Hagar was the concubine of Abraham. The Egyptian woman bore [Abraham] a son. This is Ishmael, son of Abraham, whom Hagar the Egyptian, maidservant of Sarah, bore. From him comes the race of Ishmaelites, who were afterwards called Hagarenes and finally Saracens. He was cast out into the desert of Paran with his mother because he was playing with Isaac‚Äîthat is, inciting him to idolatry or to the idle making of images out of clay. Seeing this, Sarah said, "Cast out the bondwoman and her son."&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Right Page (Folio XXII Recto)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Latin Transcription (Expanded)&lt;/cell&gt;
        &lt;cell&gt;English Translation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[Header] Tercia etas mundi&lt;/cell&gt;
        &lt;cell&gt;[Header] The Third Age of the World&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[Header] Linea Christi&lt;/cell&gt;
        &lt;cell&gt;[Header] The Line of Christ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[Header] Folium XXII&lt;/cell&gt;
        &lt;cell&gt;[Header] Folio 22&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Abraham suffocato in hur caldeorum ara fratre suo in igne. quia ignem colere noluit. Cum et ipse piectus fuisset in ignem a deo liberatus est. Adoptavit autem loth filium fratris sui aram in filium. filia quoque eiusdem fratris sui nomine saray accepit uxorem.&lt;/cell&gt;
        &lt;cell&gt;Abraham, after his brother was suffocated in the fire on the altar of Ur of the Chaldees because he would not worship the fire, and when he himself was cast into the fire, was liberated by God. He adopted Lot, the son of his brother Haran, as a son. He also took the daughter of that same brother, named Sarai, as his wife.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Deinde cum thare patre suo nachorque fratre suo et familia aram peregrinatus est de chaldea in aram mesopotamie. demum mortuo patre suo thare. cum esset .75. annorum. cum loth et saray et omni familia et substantia sua precepto domini peregrinatus est in terram chanaam.&lt;/cell&gt;
        &lt;cell&gt;Then, with his father Terah and his brother Nahor and the family of Haran, he migrated from Chaldea to Haran in Mesopotamia. Finally, after his father Terah died, when he was 75 years old, with Lot and Sarai and all his family and substance, by the command of the Lord, he migrated into the land of Canaan.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Et habitavit in sichem ubi ei dominus apparuit dicens. Semini tuo dabo terram hanc. Et deinde venit penthapolim ubi nunc est mare mortuum. Inde veniens habitavit in damasco.&lt;/cell&gt;
        &lt;cell&gt;And he dwelt in Shechem, where the Lord appeared to him saying: "To your seed I will give this land." And from there he came to the Pentapolis [the five cities], where the Dead Sea is now. Coming from there, he dwelt in Damascus.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Facta autem fame recedens venit in egiptum a quo rediens habitavit in convalle mambre iuxta hebron. cui demum in somno dominus apparens dixit. quod semen suum peregrinum esset in terra egipti annis .430.&lt;/cell&gt;
        &lt;cell&gt;However, when a famine occurred, he withdrew and went into Egypt; returning from there, he dwelt in the valley of Mamre near Hebron. To him the Lord finally appeared in sleep, saying that his seed would be strangers in the land of Egypt for 430 years.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Et quod quarta generatione redire deberet in terra chanaan. cum autem esset .99. annorum facta fuit ei de terra chanaan repromissio. Et quod reges egressuri essent de eo suscepto circumcisionis etiam precepto circumcidit se et ysmahele filium suum. omnesque domum suam et familias. Anno mundi 3184.&lt;/cell&gt;
        &lt;cell&gt;And that in the fourth generation they should return to the land of Canaan. When he was 99 years old, the promise concerning the land of Canaan was made to him. And that kings would go forth from him; having received the commandment of circumcision, he circumcised himself and his son Ishmael, and all his house and families. Year of the World 3184.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[Title over Illustration] Memphis vel Chayrum&lt;/cell&gt;
        &lt;cell&gt;[Title over Illustration] Memphis or Cairo&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memphis nunc Chayrum dicta regia Egiptiorum quam teste diodoro siculo lib. i. histor. scdo Ogeous rex egipti condidit. Et a filia eius memphis denominata. Ambitus stadiorum centum et quinquaginta urbes olim egipti preclarissima opportuniori totius eius ore loco ubi nilus scissus in plures partes efficit formas delte.&lt;/cell&gt;
        &lt;cell&gt;Memphis, now called Cairo, the royal city of the Egyptians, which, as Diodorus Siculus witnesses in the second book of his history, King Ogiveus of Egypt founded. And it was named after his daughter Memphis. A circuit of one hundred and fifty stadia, once the most famous of the cities of Egypt, in the most opportune place of its whole mouth, where the Nile, split into many parts, forms the shape of a Delta.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Quo fit ut tanquam in nuli claustro posita aditum prebeat prohibeatque ad superiora loca navigantibus. Et ad cohibendam aquarum inundationem versus notum aggeres ingentes opposuit. Et a partibus ceteris undique effossa est lacus ingens ac profundus qui urbem efficit munitissimas. Unde et posteri reges fere omnes relictis thebis et regiam habitationem in ea edificarunt.&lt;/cell&gt;
        &lt;cell&gt;Whereby it happens that, situated as if in the enclosure of the Nile, it provides and prohibits access to those navigating to the upper places. And to hold back the inundation of the waters toward the south, he placed huge ramparts. And on the other sides everywhere a huge and deep lake was dug out, which makes the city most fortified. Whence also almost all later kings, having left Thebes, built a royal residence in it.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Et babilomam capti atque chayrum vocaverunt. Apud Memphim olim colebatur Osiris qui cus phrones avo in argivorum regno succederet Ipse maioris glorie cupidine captus ad egiptios transfretavit. Quos cum suo submisisset imperio Ibidem matrimonio sibi copulavit Is cum rudes eius loca homines multas res et hominum quam maxime convenientes edoceret. divinos ab illis est adeptus honores. et eum deum adorare ceperunt. et comutato nomine apim illam vocaverunt hoc est bovem. Sic enim bos eorum lingua apis vocatur. Nam teste Solino in collectaneis et Pli‚Ä¶ [text cuts off]&lt;/cell&gt;
        &lt;cell&gt;And the captives called it Babylon and Cairo. At Memphis, Osiris was once worshipped, who succeeded his grandfather Phoroneus in the kingdom of the Argives. He himself, seized by a desire for greater glory, crossed the sea to the Egyptians. When he had submitted them to his empire, he joined [Isis] to himself in marriage there. Since he taught the rude men of that place many things most suitable for humans, he obtained divine honors from them. And they began to worship him as a god; and changing his name, they called him Apis, that is, an ox. For thus an ox is called Apis in their tongue. For as Solinus witnesses in his Collectanea and Pli‚Ä¶ [Pliny]&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And Gemini's Model Thoughts:&lt;/p&gt;
    &lt;p&gt;Initiating Transcription &amp;amp; Translation&lt;/p&gt;
    &lt;p&gt;I've just begun analyzing the incoming request. My focus is on the essential information: it's a two-page spread from an incunabulum. The desired output is a thorough Latin transcription and English translation. This is the first step in the project, so I'm identifying the core challenge!&lt;/p&gt;
    &lt;p&gt;Formulating Transcription Strategy&lt;/p&gt;
    &lt;p&gt;I'm now formulating a transcription strategy. It will be a table, with Latin and English sentence pairs. The source is unequivocally the Nuremberg Chronicle. I've confirmed that the right page is Folio 22 Recto. I'll start with Folio 21 Verso. The first line is "Tercia." I will now proceed to transcribe the remainder of this side.&lt;/p&gt;
    &lt;p&gt;Deciphering Text &amp;amp; Structure&lt;/p&gt;
    &lt;p&gt;I'm now focusing on the textual details of Folio 21 Verso. I've decoded "Tertia etas mudi" as "Third age of the world". The main text begins with a large initial 'T', and I'm meticulously transcribing the lines about Abraham, Terah, and Melchizedek. I'm also carefully expanding scribal abbreviations as I go.&lt;/p&gt;
    &lt;p&gt;Focusing on Abraham &amp;amp; Memphis&lt;/p&gt;
    &lt;p&gt;I'm now diving into the specifics of Folio 22 Recto. I've got the line of Christ, Abraham's survival of the fire, adoption of Lot, and migration to Canaan down. Now I'm focusing on the city depiction: Memphis/Cairo. I'm making a mental note of the Nile, the pyramids (described as granaries), and the Egyptian religious beliefs. I need to remember to include the marginal handwritten notes, though they're a bit messy. They offer year details!&lt;/p&gt;
    &lt;p&gt;Deepening Textual Analysis&lt;/p&gt;
    &lt;p&gt;I've just concluded the transcription of the crucial section. I've now deciphered the complete line from the third age, starting with Abraham's birth and proceeding through David, noting Saray's role and the mention of Isaac. I also tackled the more challenging phrases relating to Abraham's experience in Ur and Memphis, now Cairo. The expanded abbreviations are complete, too.&lt;/p&gt;
    &lt;p&gt;Expanding Conceptual Understanding&lt;/p&gt;
    &lt;p&gt;I'm now integrating the finer details of the text, particularly the connection between Ur, fire, and the later city names. I'm focusing on "Memphis vel Chayrum" and "Turris" to prepare for the table structure. I'm making mental connections between the fire of the Chaldeans and the city's fortification. This requires deep understanding to connect historical context.&lt;/p&gt;
    &lt;p&gt;Analyzing Keturah &amp;amp; Lineage&lt;/p&gt;
    &lt;p&gt;I'm now examining the Keturah section, focusing on her sons and their lineage, as depicted in the tree and surrounding text. I've noted the sons' names and the details of their attributes. I'm cross-referencing these names within the Latin text and their visual placement within the graphical family tree, ensuring accuracy. I'm paying particular attention to variations between the transcription and the image, making sure that I am faithful to both sources.&lt;/p&gt;
    &lt;p&gt;Structuring Table for Clarity&lt;/p&gt;
    &lt;p&gt;I'm currently structuring the output table with expanded Latin text for readability, while maintaining the original abbreviations in the transcription. I'm focusing on ensuring the table accurately reflects the left-to-right flow of the original incunabulum. Recent additions like "Memphis nunc Chayru[m] dicta‚Ä¶" and the Ogiveus reference are now integrated, along with specific phrases like "Melchisedech rex salem" and descriptions of Osiris and Serapis. I have completed the final adjustments to the output format and am generating the table.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.gdeltproject.org/gemini-as-indiana-jones-how-gemini-3-0-deciphered-the-mystery-of-a-nuremberg-chronicle-leafs-500-year-old-roundels/"/><published>2026-01-01T18:08:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46456543</id><title>Street-Fighting Mathematics (2008)</title><updated>2026-01-01T21:38:10.054169+00:00</updated><content>&lt;doc fingerprint="f8f73fb885dfadb4"&gt;
  &lt;main&gt;
    &lt;p&gt;The readings for each session are designed to be read after attending that session. For a listing of the topics discussed in each session, see here: (PDF)&lt;/p&gt;
    &lt;head rend="h3"&gt;Published Textbook&lt;/head&gt;
    &lt;p&gt;Mahajan, Sanjoy. Street-Fighting Mathematics: The Art of Educated Guessing and Opportunistic Problem Solving. Cambridge, MA: MIT Press, 2010. ISBN: 9780262514293.&lt;/p&gt;
    &lt;p&gt;The book is available as a free download (PDF) from MIT Press.&lt;/p&gt;
    &lt;head rend="h3"&gt;Textbook (Earlier Edition)&lt;/head&gt;
    &lt;p&gt;An earlier version√Ç of the√Ç textbook as one file may be found here: (PDF - 1.3 MB)&lt;/p&gt;
    &lt;p&gt;Title page and table of contents (PDF)&lt;/p&gt;
    &lt;p&gt;References (PDF)&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;SES√Ç #&lt;/cell&gt;
        &lt;cell role="head"&gt;TOPICS&lt;/cell&gt;
        &lt;cell role="head"&gt;READINGS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Dimensions&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Chapter 1 - Dimensions, pp. 3-12 (PDF)&lt;/p&gt;
          &lt;p&gt;Questions from lecture 1 (PDF)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;Extreme cases&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Chapter 2 - Extreme cases, pp. 13-26 (PDF)&lt;/p&gt;
          &lt;p&gt;Questions and answers from lecture 2 (PDF)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;Application: drag&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Chapter 2 - Extreme cases, pp. 26-30 (PDF)&lt;/p&gt;
          &lt;p&gt;Questions from lecture 3 (PDF)&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;More on drag&lt;/cell&gt;
        &lt;cell&gt;√Ç&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;Discretization&lt;/cell&gt;
        &lt;cell&gt;Chapter 3 - Discretization, pp. 31-40 (PDF)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Application: pendulum period&lt;/cell&gt;
        &lt;cell&gt;Chapter 3 - Discretization, pp. 41-44 (PDF)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;Picture proofs&lt;/cell&gt;
        &lt;cell&gt;Chapter 4 - Picture proofs, pp. 45-56 (PDF)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;Taking out the big part&lt;/cell&gt;
        &lt;cell&gt;Chapter 5 - Taking out the big part, pp. 57-79 (PDF)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;Analogy&lt;/cell&gt;
        &lt;cell&gt;Chapter 6 - Analogy, pp. 80-85 (PDF)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;Application: operators&lt;/cell&gt;
        &lt;cell&gt;Chapter 7 - Operators, pp. 86-90 (PDF)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;Application: singing logarithms&lt;/cell&gt;
        &lt;cell&gt;Handout - approximating logarithms using musical intervals (PDF)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ocw.mit.edu/courses/18-098-street-fighting-mathematics-january-iap-2008/pages/readings/"/><published>2026-01-01T18:20:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46456682</id><title>Building an internal agent: Code-driven vs. LLM-driven workflows</title><updated>2026-01-01T21:38:09.953425+00:00</updated><content>&lt;doc fingerprint="b84e8d7920875ad9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building an internal agent: Code-driven vs LLM-driven workflows&lt;/head&gt;
    &lt;p&gt;When I started this project, I knew deep in my heart that we could get an LLM plus tool-usage to solve arbitrarily complex workflows. I still believe this is possible, but I‚Äôm no longer convinced this is actually a good solution. Some problems are just vastly simpler, cheaper, and faster to solve with software. This post talks about our approach to supporting both code and LLM-driven workflows, and why we decided it was necessary.&lt;/p&gt;
    &lt;p&gt;This is part of the Building an internal agent series.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why determinism matters&lt;/head&gt;
    &lt;p&gt;When I joined Imprint, we already had a channel where folks would share pull requests for review. It wasn‚Äôt required to add pull requests to that channel, but it was often the fastest way to get someone to review it, particularly for cross-team pull requests.&lt;/p&gt;
    &lt;p&gt;I often start my day by skimming for pull requests that need a review in that channel, and quickly realized that often a pull request would get reviewed and merged without someone adding the &lt;code&gt;:merged:&lt;/code&gt; reacji onto the chat. This felt inefficient, but also
extraordinarily minor, and not the kind of thing I want to complain about.
Instead, I pondered how I could solve it without requiring additional human labor.&lt;/p&gt;
    &lt;p&gt;So, I added an LLM-powered workflow to solve this. The prompt was straightforward:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Get the last 10 messages in the Slack channel&lt;/item&gt;
      &lt;item&gt;For each one, if there was exactly one Github pull request URL, extract that URL&lt;/item&gt;
      &lt;item&gt;Use the Github MCP to check the status of each of those URLs&lt;/item&gt;
      &lt;item&gt;Add the &lt;code&gt;:merged:&lt;/code&gt;reacji to messages where the associated pull request was merged or closed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This worked so well! So, so well. Except, ahh, except that it sometimes decided to add &lt;code&gt;:merged:&lt;/code&gt;
to pull requests that weren‚Äôt merged. Then no one would look at those pull requests.
So, it worked in concept‚Äìso much smart tool usage!‚Äìbut in practice it actually didn‚Äôt
solve the problem I was trying to solve: erroneous additions of the reacji meant
folks couldn‚Äôt evaluate whether to look at a given pull request in the channel based on the reacji‚Äôs presence.&lt;/p&gt;
    &lt;p&gt;(As an aside, some people really don‚Äôt like the term &lt;code&gt;reacji&lt;/code&gt;.
Don‚Äôt complain to me about it, this is what Slack calls them.)&lt;/p&gt;
    &lt;head rend="h2"&gt;How we implemented support for code-driven workflows&lt;/head&gt;
    &lt;p&gt;Our LLM-driven workflows are orchestrated by a software handler. That handler works something like:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Trigger comes in, and the handler selects which configuration corresponds with the trigger&lt;/item&gt;
      &lt;item&gt;Handler uses that configuration and trigger to pull the associated prompt, load the approved tools, and generate the available list of virtual files (e.g. files attached to a Jira issue or Slack message)&lt;/item&gt;
      &lt;item&gt;Handler sends the prompt and available tools to an LLM, then coordinates tool calls based on the LLM‚Äôs response, including e.g. making virtual files available to tools. The handler also has termination conditions where it prevents excessive tool usage, and so on&lt;/item&gt;
      &lt;item&gt;Eventually the LLM will stop recommending tools, and the final response from the LLM will be used or discarded depending on the configuration (e.g. configuration can determine whether the final response is sent to Slack)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We updated our configuration to allow running in one of two configurations:&lt;/p&gt;
    &lt;code&gt;# this is default behavior if omitted
coordinator: llm

# this is code-driven workflow
coordinator: script
coordinator_script: scripts/pr_merged.py
&lt;/code&gt;
    &lt;p&gt;When the &lt;code&gt;coordinator&lt;/code&gt; is set to &lt;code&gt;script&lt;/code&gt;, then instead of using the handler to determine which tools are called,
custom Python is used. That Python code has access to the same tools, trigger data, and virtual files
as the LLM-handling code. It can use the subagent tool to invoke an LLM where useful
(and that subagent can have full access to tools as well), but LLM control only occurs when explicitly desired.&lt;/p&gt;
    &lt;p&gt;This means that these scripts‚Äìwhich are being written and checked in by our software engineers, going through code review and so on‚Äìhave the same permission and capabilities as the LLM, although given it‚Äôs just code, any given commit could also introduce a new dependency, etc.&lt;/p&gt;
    &lt;head rend="h2"&gt;How‚Äôs it working? / Next steps?&lt;/head&gt;
    &lt;p&gt;Altogether, this has worked very well for complex workflows. I would describe it as a ‚Äúsolution of frequent resort‚Äù, where we use code-driven workflows as a progressive enhancement for workflows where LLM prompts and tools aren‚Äôt reliable or quick enough. We still start all workflows using the LLM, which works for many cases. When we do rewrite, Claude Code can almost always rewrite the prompt into the code workflow in one-shot.&lt;/p&gt;
    &lt;p&gt;Even as models get more powerful, relying on them narrowly in cases where we truly need intelligence, rather than for iterative workflows, seems like a long-term addition to our toolkit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lethain.com/agents-coordinators/"/><published>2026-01-01T18:34:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46456797</id><title>Finland detains ship and its crew after critical undersea cable damaged</title><updated>2026-01-01T21:38:09.692159+00:00</updated><content>&lt;doc fingerprint="e406048e7b88547e"&gt;
  &lt;main&gt;
    &lt;p&gt;Finland has detained a ship and its crew after a critical undersea telecommunication cable connecting the country to Estonia was damaged Wednesday, Finnish authorities said.&lt;/p&gt;
    &lt;p&gt;Finnish police said in a statement that the vessel suspected of causing the damage was found with its anchor chain lowered into the sea in Finland‚Äôs waters, while the damage site itself was in Estonia‚Äôs waters. The police later named the vessel as the Fitburg, a Saint Vincent and the Grenadines flagged cargo ship.&lt;/p&gt;
    &lt;p&gt;The Finnish National Police Commissioner Ilkka Koskim√§ki said at a news conference on Wednesday afternoon that all 14 members of the ship‚Äôs crew have been detained, adding that the crew are citizens of Russia, Georgia, Kazakhstan and Azerbaijan.&lt;/p&gt;
    &lt;p&gt;Incidents like this have become more frequent in recent years, raising suspicions they are the result of sabotage and prompting NATO to launch a project earlier this year specifically aimed at strengthening the protection of critical undersea infrastructure.&lt;/p&gt;
    &lt;p&gt;According to MarineTraffic, which tracks ship movements, the Fitburg departed the Russian port of St. Petersburg on Tuesday and was headed to Haifa in Israel.&lt;/p&gt;
    &lt;p&gt;After the damage was reported, Finnish authorities instructed the ship to stop and raise its anchor, and then took control of it, the police said.&lt;/p&gt;
    &lt;p&gt;Finnish media reported that the ship was seized by special forces police and the coast guard from helicopters.&lt;/p&gt;
    &lt;p&gt;Finland‚Äôs President Alexander Stubb said that the government was monitoring the situation closely and that Finland was ‚Äúprepared for security challenges of various kinds.‚Äù&lt;/p&gt;
    &lt;p&gt;The police said they were investigating the incident as aggravated criminal damage, attempted aggravated criminal damage, and aggravated interference with telecommunications.&lt;/p&gt;
    &lt;p&gt;The cable that was damaged runs between the Finnish capital Helsinki and the Estonian capital Talinn. While the extend of the damage was not immediately clear, the incident was serious enough to cause faults that were detected by the Finnish telecommunications provider Elisa, which operates the link.&lt;/p&gt;
    &lt;p&gt;Finnish Prime Minister Petteri Orpo said he spoke to his Estonian counterpart Kristen Michal about the situation, adding that the two countries were cooperating on the issue.&lt;/p&gt;
    &lt;p&gt;Estonia‚Äôs Ministry of Justice and Digital Affairs said in a statement that the country‚Äôs connections remained sufficiently backed up through other sea and land cables, ensuring the continuity of all services.&lt;/p&gt;
    &lt;p&gt;The ministry said that a second cable, owned by the Swedish company Arelion, was also damaged.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pattern of disruption&lt;/head&gt;
    &lt;p&gt;At least 10 undersea cables have been cut or damaged in the Baltic Sea since 2023. Some officials from Scandinavia, the Baltic states and the European Union have pointed the finger at Russia. They say the incidents appear to be part of what experts say is the Kremlin‚Äôs hybrid war on the West.&lt;/p&gt;
    &lt;p&gt;Russia has consistently denied involvement, but some of the ships that have caused damage to the undersea infrastructure in the past were found to have links to Russia.&lt;/p&gt;
    &lt;p&gt;Last year, a Baltic Sea power cable and several data cables were damaged after a Cook Islands-registered vessel dragged its anchor through the seabed for more than 50 miles.&lt;/p&gt;
    &lt;p&gt;Finnish and European officials said the ship, Eagle-S, was part of Russia‚Äôs shadow fleet of fuel tankers, and Finland later charged members of its crew. However, a court in Helsinki dismissed the case in October, saying Finland did not have jurisdiction over the issue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnn.com/2025/12/31/europe/finland-estonia-undersea-cable-ship-detained-intl"/><published>2026-01-01T18:46:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46457027</id><title>Dell's version of the DGX Spark fixes pain points</title><updated>2026-01-01T21:38:09.438365+00:00</updated><content>&lt;doc fingerprint="bdb351577a83619d"&gt;
  &lt;main&gt;
    &lt;p&gt;Dell sent me two of their GB10 mini workstations to test:&lt;/p&gt;
    &lt;p&gt;In this blog post, I'll cover the base system, just one of the two nodes. Cluster testing is ongoing, and I'll cover things like AI model training and networking more in depth next year, likely with comparisons to the Framework Desktop cluster and Mac Studio cluster I've also been testing.&lt;/p&gt;
    &lt;p&gt;But many of the same caveats of the DGX Spark (namely, price to performance is not great if you just want to run LLMs on a small desktop) apply to Dell's GB10 box as well.&lt;/p&gt;
    &lt;p&gt;It costs a little more than the DGX Spark, but does solve a couple pain points people experienced on the DGX Spark:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It has a power LED (seriously, why does the DGX Spark not have one?!)&lt;/item&gt;
      &lt;item&gt;The included power supply is 280W instead of 240W for a little more headroom&lt;/item&gt;
      &lt;item&gt;The thermal design (front-to-back airflow) seems less restricted, so is quieter and capable of keeping the GB10 'AI Superchip' from thermal throttling&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But if this isn't a mini PC to compete with a Mac mini, nor a good value for huge LLMs like a Mac Studio, or AMD's Ryzen AI Max+ 395 machines, what is it and who is it for?&lt;/p&gt;
    &lt;p&gt;Well, it's a $4,000+ box built specifically for developers in Nvidia's ecosystem, deploying code to Nvidia servers that cost half a million dollars each. A major part of the selling point are these built-in 200 gigabit QSFP ports, which would cost $1,500 or so to add on to another system, assuming you have the available PCIe bandwidth:&lt;/p&gt;
    &lt;p&gt;Those ports can't achieve 400 Gbps, but they do hit over 200 Gbps in the right conditions, configured for Infiniband / RDMA. And they hit over 100 Gbps for Ethernet (though only when running multiple TCP streams).&lt;/p&gt;
    &lt;p&gt;So it may seem a little bit of an odd duck for me, since I'm not an 'Nvidia developer' and I don't deploy code to Nvidia's 'AI factories'.&lt;/p&gt;
    &lt;p&gt;If I'm being honest, I'm more interested in the 'Grace' part of the GB10 (or 'Grace Blackwell 10') 'AI Superchip. It's a big.LITTLE Arm CPU co-designed by Mediatek, with 10 Cortex-X925 cores and 10 Cortex-A725 cores.&lt;/p&gt;
    &lt;p&gt;The chip is united to the Blackwell GPU, and shares the same 128 GB pool of LPDDR5X memory. And it's a pretty snappy Arm CPU‚Äîjust stuck in a $4,000+ system.&lt;/p&gt;
    &lt;p&gt;But like I said, Dell sent me these boxes to test. They aren't paying for this blog post and have no control over what I say.&lt;/p&gt;
    &lt;p&gt;In fact, one of the main things they said was "this is isn't a gaming machine, so don't focus on that."&lt;/p&gt;
    &lt;p&gt;But that got me thinking. What if... I did.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gaming on Arm Linux&lt;/head&gt;
    &lt;p&gt;Valve just announced the Steam Frame, and it runs on Arm.&lt;/p&gt;
    &lt;p&gt;Steam Frame will use FEX for its x86-Arm translation layer, and CodeWeavers' Crossover Preview for Arm64 was just released, so I thought I'd give that a try on DGX OS (Nvidia's Linux OS, currently based on Ubuntu 24.04).&lt;/p&gt;
    &lt;p&gt;I was able to quickly install Steam, and through that, games like Cyberpunk 2077, Doom Eternal, and Ultimate Epic Battle Simulator II.&lt;/p&gt;
    &lt;p&gt;I'll leave the full experience and test results for you to see in this video:&lt;/p&gt;
    &lt;p&gt;But bottom line, the Windows games I typically test on Arm systems through Steam/Proton played very well here, with no stuttering, and decent frame rates (100 fps in Cyberpunk 2077 at 1080p with low settings).&lt;/p&gt;
    &lt;p&gt;But no, I agree with Dell, this box should not be evaluated as a gaming machine. While it performs admirably for an Arm linux box, you could do a lot better with half the budget if you just wanted to build a dedicated gaming rig. Even with RAM prices as they are today.&lt;/p&gt;
    &lt;head rend="h2"&gt;General Purpose Arm Workstation (with tons of VRAM)&lt;/head&gt;
    &lt;p&gt;This machine is built for AI development, but it just so happens to have a very good Arm CPU and tons of RAM, so I wanted to test it for both running LLMs, and as a general Arm Linux workstation.&lt;/p&gt;
    &lt;p&gt;The video above has more depth, and you can find all my benchmark data here, but I wanted to focus on a few things in particular.&lt;/p&gt;
    &lt;head rend="h2"&gt;Software&lt;/head&gt;
    &lt;p&gt;Before we get to benchmarks, I wanted to mention Nvidia's DGX OS. Based on Ubuntu Linux, it's the only supported Linux distribution for GB10 systems. Regular Ubuntu LTS versions are supported for 5 years, with optional Pro support extending that out to 10 or even 15 years. But DGX OS only guarantees updates for two years, though Nvidia doesn't really offer guarantees for its hardware support.&lt;/p&gt;
    &lt;p&gt;Their track record for ongoing support for their hardware is decidedly mixed, and in the absence of any guarantees, I wouldn't expect them to continue supporting the Spark or other GB10 systems beyond a few years.&lt;/p&gt;
    &lt;p&gt;Some people have had luck getting other distros running, but they're still running Nvidia's kernel. So if you buy one of these, know there's no guarantees for ongoing support.&lt;/p&gt;
    &lt;p&gt;Running things on DGX OS, I've found most server/headless software runs great, but there are still desktop tools that are more of a hassle. Like Blender doesn't have a stable release that uses GPU acceleration on Arm. But if you compile it from sourcelike GitHub user CoconutMacaroon did, you can get full acceleration.&lt;/p&gt;
    &lt;p&gt;Just using this box as a little workstation, it is plenty fast for all the things I do, from coding, to browsing the web, to media editing. (Though media workflows are still rough on Linux in general, even on x86.)&lt;/p&gt;
    &lt;head rend="h2"&gt;CPU benchmarks&lt;/head&gt;
    &lt;p&gt;The Grace CPU is a 20-core Arm chip co-designed by Mediatek, fused together with the Blackwell GPU.&lt;/p&gt;
    &lt;p&gt;There must be some inefficiency there, though, because the system's idle power draw is a bit higher than I'm used to for Arm, coming in around 30 watts. A lot higher than Apple's M3 Ultra with 512GB of RAM, or even AMD's Ryzen AI Max+ 395 (these names just roll right off the tongue, don't they?).&lt;/p&gt;
    &lt;p&gt;In my testing, it seems the CPU itself maxes out around 140 watts, leaving another 140 watts of headroom for the GPU, network, and USB-C ports with PD.&lt;/p&gt;
    &lt;p&gt;Geekbench 6 was a little unstable, which was weird, but when I did get it to run, it was about on par with the AMD Ryzen AI Max+ 395 system I tested earlier this year, the Framework Desktop.&lt;/p&gt;
    &lt;p&gt;Apple's 2-generation-old M3 Ultra Mac studio beats both, but it does cost quite a bit more, so that's to be expected.&lt;/p&gt;
    &lt;p&gt;And testing with High Performance Linpack, the Dell Pro Max gets about 675 Gflops:&lt;/p&gt;
    &lt;p&gt;NVIDIA's marketing said the GB10 "offers a petaflop of AI computing performance"‚Äîa thousand teraflops! This thing can't even hit one...&lt;/p&gt;
    &lt;p&gt;But in the fine print, NVIDIA says it's a petaflop at FP4 precision. HPL tests FP64, aka double precision, which is more used in scientific computing. A FLOP is not always a FLOP, and even the 'petaflop' claim seems disputed, at least if I'm reading John Carmack's tweets correctly.&lt;/p&gt;
    &lt;p&gt;But at least for FP64 on the CPU, the GB10 is fairly efficient, at least compared to x86 systems I've tested:&lt;/p&gt;
    &lt;head rend="h2"&gt;Networking Performance&lt;/head&gt;
    &lt;p&gt;A huge part of the value is the built-in ConnectX-7 networking. I tested that, and it's fast. But also a bit odd. Here's the maximum TCP performance I was able to get through the fastest interface on each of the three systems I've been comparing:&lt;/p&gt;
    &lt;p&gt;But 106 Gigabits isn't 200, is NVIDIA lying?&lt;/p&gt;
    &lt;p&gt;Well, no... it's a little complicated. For full details, I'll refer you to the ServeTheHome article The NVIDIA GB10 ConnectX-7 200GbE Networking is Really Different.&lt;/p&gt;
    &lt;p&gt;Because the ports are each connected to a x4 PCIe Gen 5 link‚Äîwhich isn't enough bandwidth for 200 Gbps per port. To get a full 200 Gbps, you have to use Infiniband/RDMA and carefully configure the network topology. You won't get more than about 206 Gbps, maximum, in real world throughput, no matter how you set it up.&lt;/p&gt;
    &lt;p&gt;That's still honestly pretty good, but it's not the same as getting 400 Gbps of networking for AI clustering, like I think some of us expected reading the initial press releases in early 2025...&lt;/p&gt;
    &lt;p&gt;From the perspective of someone replicating NVIDIA's networking stack locally, though, having ConnectX ports built in is a boon. If you want replicate this kind of developer setup on AMD, you'd have to spend around the same amount of money, for the Max+ 395 plus a Connect-X 7 card.&lt;/p&gt;
    &lt;p&gt;Many people don't care about clustering use cases, or RDMA or Infiniband, but that doesn't mean it's not extremely useful for the people who do. This stuff's expensive, but to some people, it's not a bad value.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI Performance&lt;/head&gt;
    &lt;p&gt;For now I'm just running two models, both of them with llama.cpp, optimized for each architecture.&lt;/p&gt;
    &lt;p&gt;And for a small model that requires a decent amount of CPU to keep up with the GPU, the GB10 does pretty well, almost hitting 100 tokens/s for inference, which is second to the M3 Ultra:&lt;/p&gt;
    &lt;p&gt;But for prompt processing, which is important for how quickly you start seeing a response from AI models, the GB10 chip is the winner, despite costing less than half the M3 Ultra.&lt;/p&gt;
    &lt;p&gt;And it's a similar story for a huge 'dense' model, Llama 3.1 70B, except here, it gets beat just a little by AMD's Strix Halo in the Framework Desktop:&lt;/p&gt;
    &lt;p&gt;Prompt processing is a strong selling point for these boxes. That's the reason Exo teased running a DGX Spark as the compute node for a Mac Studio cluster.&lt;/p&gt;
    &lt;p&gt;You can have the Spark, or one of these Dell's, handle the thing it's best at, prompt processing, while the Mac Studios handle the thing they're best at, memory bandwidth for token generation.&lt;/p&gt;
    &lt;p&gt;Anyway, these are just two quick AI benchmarks, and I have a lot more in the Dell Pro Max with GB10 issue in my ai-benchmarks repository. I'm doing a lot more testing, including model training and how I clustered two of these things in a tiny mini rack, but you'll have to wait until next year for that.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jeffgeerling.com/blog/2025/dells-version-dgx-spark-fixes-pain-points"/><published>2026-01-01T19:11:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46457240</id><title>Prompting People</title><updated>2026-01-01T21:38:09.347714+00:00</updated><content>&lt;doc fingerprint="891e43764647d9be"&gt;
  &lt;main&gt;
    &lt;p&gt;I just gave my final end semester exam a couple days ago when I bumped into an old friend and we got into talking and discussing some important topics for the test.&lt;/p&gt;
    &lt;p&gt;I was midway through explaining a concept he hadn‚Äôt covered when he stopped me. He pointed out that my way of speaking had completely changed and how it was unusually structured and didn‚Äôt give him the opportunity to ask follow up questions.&lt;/p&gt;
    &lt;p&gt;and that‚Äôs when it hit me - I think the more often I use AI, the more I start talking to people like how I engineer prompts for LLMs and not just over messages or text - even in person.&lt;/p&gt;
    &lt;p&gt;even the concept I was explaining - definition, descriptions, potential follow up questions and edge cases in that order.&lt;/p&gt;
    &lt;p&gt;What‚Äôs funny is that this isn‚Äôt even intentional - it‚Äôs what I believe in my head is the more ‚Äúefficient‚Äù way to express my thoughts and ideas than entirely separate, broken up conversations.&lt;/p&gt;
    &lt;p&gt;The more surprising part is the unusual reactions of the other people getting a better picture and context of what I‚Äôm explaining without the usual back and forth - which has landed me my fair share of complaints of having to hear mini lectures, but not more than people appreciative of the fuller picture.&lt;/p&gt;
    &lt;p&gt;It made me realize that while we‚Äôre training AI to be more human, the conversations might be training us to be more structured and honestly I‚Äôm not sure if this makes me a better communicator or just a better prompt engineer, but it‚Äôs a hard habit to break.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kuber.studio/blog/Reflections/Prompting-People"/><published>2026-01-01T19:33:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46457770</id><title>Linux is good now; to feel like you actually own your PC, put Linux on it</title><updated>2026-01-01T21:38:09.035548+00:00</updated><content>&lt;doc fingerprint="13f391b9904a4bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I'm brave enough to say it: Linux is good now, and if you want to feel like you actually own your PC, make 2026 the year of Linux on (your) desktop&lt;/head&gt;
    &lt;p&gt;Now if you don't mind I'm going to delete the root folder and see what happens.&lt;/p&gt;
    &lt;p&gt;I'm all-in, baby. I'm committed. If upgrading any distinct component of my PC didn't require me taking out a loan right now, I'd be seriously considering switching my GPU over to some kind of AMD thing just to make my life slightly, slightly easier.&lt;/p&gt;
    &lt;p&gt;I've had it with Windows and ascended to the sunlit uplands of Linux, where the trees heave with open-source fruits and men with large beards grep things with their minds.&lt;/p&gt;
    &lt;p&gt;I'm not alone. In last month's Steam hardware survey, the number of Linux users hit a new all-time high for the second month running, reaching the heady summit of a whopping, ah, 3.2% of overall Steam users. Hey, we're beating Mac players.&lt;/p&gt;
    &lt;p&gt;I think that number will only grow as the new year goes by. More and more of us are getting sick of Windows, sure‚Äîthe AI guff, the constant upselling on Office subs, the middle taskbar*‚Äîbut also, all my experience goofing about with Linux this year has dispelled a lot of the, frankly, erroneous ideas I had about it. It's really not hard! Really! I know Linux guys have been saying this for three decades, but it's true now!&lt;/p&gt;
    &lt;head rend="h2"&gt;Goated with the open source (sorry)&lt;/head&gt;
    &lt;p&gt;As I've already written about, the bulk of my Linux-futzing time this year has been spent in Bazzite, a distro tailor-made for gaming and also tailor-made to stop idiots (me) from doing something likely to detonate their boot drive.&lt;/p&gt;
    &lt;p&gt;I grew up thinking of Linux as 'the command-line OS that lets you delete your bootloader' and, well, I suppose that's not untrue, but I've been consistently impressed at how simple Bazzite has been to run on my PC, even with my persnickety Nvidia GPU.&lt;/p&gt;
    &lt;p&gt;Everything I've played this year has been as easy‚Äîif not easier‚Äîto run on a free OS put together by a gaggle of passionate nerds as it is on Windows, the OS made by one of the most valuable corporations on planet Earth. I've never had to dip into the command line (which is, to be frank, a shame, as the command line is objectively cool).&lt;/p&gt;
    &lt;p&gt;Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.&lt;/p&gt;
    &lt;p&gt;But to be honest, it's not as if the Bazzite team has miraculously made Linux pleasant to use after decades of it seeming difficult and esoteric to normie computer users. I think mainstream Linux distros are just, well, sort of good now. Apart from my gaming PC, I also have an old laptop converted into a media server that lives underneath my television. It runs Debian 13 (which I updated to from Debian 12 earlier in the year) and requires essentially zero input from me at all.&lt;/p&gt;
    &lt;p&gt;What's more, the only software I have on there is software I actually want on there. Oh for a version of Windows that let me do something as zany as, I don't know, uninstall Edge.&lt;/p&gt;
    &lt;p&gt;That's the true nub of it, I think. The stats can say what they like (and they do! We've all heard tales of Windows games actually running better on Linux via Valve's Proton compatibility layer), but the heart of my fatigue with Windows is that, for every new worthless AI gadget Microsoft crams into it and for every time the OS inexplicably boots to a white screen and implores me to "finish setting up" my PC with an Office 365 subscription, the real problem is a feeling that my computer isn't mine, that I am somehow renting this thing I put together with my own two hands from an AI corporation in Redmond.&lt;/p&gt;
    &lt;p&gt;That's fine for consoles. Indeed, part of the whole pitch of an Xbox or PlayStation is the notion that you are handing off a lot of responsibility for your device to Sony and Microsoft's teams of techs, but my PC? That I built? Get your grubby mitts off it.&lt;/p&gt;
    &lt;p&gt;Are there issues? Sure. HDR's still a crapshoot (plus √ßa change) and, as you've no doubt heard, a lot of live-service games have anticheat software that won't play with Linux. But I think both of these issues are gradually ticking toward their solutions, particularly with Valve making its own push into the living room.&lt;/p&gt;
    &lt;p&gt;So I say make 2026 the year you give Linux a try, if you haven't already. At the very least, you can stick it on a separate boot drive and have a noodle about with it. I suspect you'll find the open (source) water is a lot more hospitable than you might think.&lt;/p&gt;
    &lt;p&gt;*I'm actually fine with the middle taskbar. I'm sorry.&lt;/p&gt;
    &lt;p&gt;2026 Games: This year's upcoming games&lt;lb/&gt;Best PC games: Our all-time favorites&lt;lb/&gt;Free PC games: Freebie fest&lt;lb/&gt;Best FPS games: Finest gunplay&lt;lb/&gt;Best RPGs: Grand adventures&lt;lb/&gt;Best co-op games: Better together&lt;/p&gt;
    &lt;p&gt;One of Josh's first memories is of playing Quake 2 on the family computer when he was much too young to be doing that, and he's been irreparably game-brained ever since. His writing has been featured in Vice, Fanbyte, and the Financial Times. He'll play pretty much anything, and has written far too much on everything from visual novels to Assassin's Creed. His most profound loves are for CRPGs, immersive sims, and any game whose ambition outstrips its budget. He thinks you're all far too mean about Deus Ex: Invisible War.&lt;/p&gt;
    &lt;p&gt;You must confirm your public display name before commenting&lt;/p&gt;
    &lt;p&gt;Please logout and then login again, you will then be prompted to enter your display name.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.pcgamer.com/software/linux/im-brave-enough-to-say-it-linux-is-good-now-and-if-you-want-to-feel-like-you-actually-own-your-pc-make-2026-the-year-of-linux-on-your-desktop/"/><published>2026-01-01T20:35:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46457784</id><title>A website to destroy all websites</title><updated>2026-01-01T21:38:08.728655+00:00</updated><content>&lt;doc fingerprint="3cc011532966ad7d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A website to destroy all websites.&lt;/head&gt;
    &lt;head rend="h2"&gt;table of contents, of course&lt;/head&gt;
    &lt;head rend="h2"&gt;The internet is bad.&lt;/head&gt;
    &lt;p&gt;Well, the Internet mostly feels bad these days.&lt;/p&gt;
    &lt;p&gt;We were given this vast, holy realm of self-discovery and joy and philosophy and community; a thousand thousand acres of digital landscape, on which to grow our forests and grasslands of imagination, plant our gardens of learning, explore the caves of our making. We were given the chance to know anything about anything, to be our own Prometheus, to make wishes and to grant them.&lt;/p&gt;
    &lt;p&gt;But that‚Äôs not what we use the Internet for anymore. These days, instead of using it to make ourselves, most of us are using it to waste ourselves: we‚Äôre doom-scrolling brain-rot on the attention-farm, we‚Äôre getting slop from the feed.&lt;/p&gt;
    &lt;p&gt;Instead of turning freely in the HTTP meadows we grow for each other, we go to work: we break our backs at the foundry of algorithmic content as this earnest, na√Øve, human endeavoring to connect our lives with others is corrupted. Our powerful drive to learn about ourselves, each other, and our world, is broken into scant remnants ‚Äî hollow, clutching phantasms of Content Creation, speed-cut vertical video, listicle thought-leadership, ragebait and the thread emoji.&lt;/p&gt;
    &lt;head rend="h3"&gt;it wasn‚Äôt always like this.&lt;/head&gt;
    &lt;p&gt;It used to feel way better to Go Online, and some of us will remember.&lt;/p&gt;
    &lt;p&gt;We used to be able to learn about our hobbies and interests from hundreds of experts on a wealth of websites whose only shared motivation was their passion. Some of those venerable old educational blogs, forums, and wikis still stand, though most have been bulldozed.&lt;/p&gt;
    &lt;p&gt;Now, Learning On The Internet often means fighting ads and endless assaults on one‚Äôs attention ‚Äî it means watching part-1-part-2-part-3 short-form video clips, taped together by action movie psychology hacks, narrated gracelessly by TTS AI voices. We‚Äôre down from a thousand and one websites to three, and each of those remaining monolith websites is just a soullessly-regurgitated, compression-down-scaled, AI-up-scaled version of the next.&lt;/p&gt;
    &lt;p&gt;¬∂&lt;/p&gt;
    &lt;p&gt;We used to make lasting friendships with folks all over the world on shared interest and good humor.&lt;/p&gt;
    &lt;p&gt;But now those social networks, once hand-built and hand-tended, vibrant and organic, are unceremoniously swallowed by social media networks, pens built for trapping us and our little piggy attentions, turning us all into clout-chasers &amp;amp; content-creators, and removing us from what meaningful intimacy &amp;amp; community felt like.&lt;/p&gt;
    &lt;p&gt;¬∂&lt;/p&gt;
    &lt;p&gt;Even coding for the web used to be different: One could Learn To Code‚Ñ¢ to express oneself creatively, imbue one‚Äôs online presence with passion and meaning, and for some of us, build a real career.&lt;/p&gt;
    &lt;p&gt;These days, however, we write increasing amounts of complicated, unsecure code to express less and less meaning, in order to infinitely generate shareholder value. We don‚Äôt think about the art of our craft and the discipline of its application, we think about throughput and scale.&lt;/p&gt;
    &lt;p&gt;To be very clear: I‚Äôm not trying to Good Old Days the internet. None of this is meant to make you feel nostalgic ‚Äî the Internet used to be slow and less populated and less diverse, and its access was limited to those of a certain class. The Web For All is a marked improvement, widespread global internet access is a marked improvement, and what I‚Äôm asking you to consider is what it used to feel like to use these tools, and what we‚Äôve lost in the Big Tech, Web 2.0 and web3 devouring of the ‚ÄôNet.&lt;/p&gt;
    &lt;head rend="h2"&gt;The invention of the automobile&lt;/head&gt;
    &lt;p&gt;The onset of the automobile was a revelation for access and personal liberty. With the advent of cars, members of society could travel farther, get more done in their day, and bend their limited time more to their creative will!&lt;/p&gt;
    &lt;p&gt;But as time wore on and the industrialization &amp;amp; proliferation of the automobile progressed, its marginal utility diminished ‚Äî the industry started to society fewer &amp;amp; fewer benefits, and take more &amp;amp; more in exchange1.&lt;/p&gt;
    &lt;p&gt;In American cities, for example: though at first the automobile enabled humans to travel further distances, it now demanded that humans travel those distances, and demanded infrastructure be created &amp;amp; maintained to enable it.2 Many now must use an automobile to get everything done in their town in a day, and must pay &amp;amp; take time for that automobile‚Äôs fueling &amp;amp; maintenance.3&lt;/p&gt;
    &lt;p&gt;Further than that, the automobile asks all of us to chip in tax revenue to protect its infrastructure, but only certain classes can afford an automobile with which to use that infrastructure, and those classes who can‚Äôt afford to do so are relegated to underfunded public transit systems.4&lt;/p&gt;
    &lt;p&gt;No longer a tool to serve our societies, our societies now serve the automobile.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tools for Conviviality, &amp;amp; the industrialization of the Web.&lt;/head&gt;
    &lt;p&gt;In his book Tools For Conviviality, technology philosopher and social critic Ivan Illich identifies these two critical moments, the optimistic arrival &amp;amp; the deadening industrialization, as watersheds of technological advent. Tools are first created to enhance our capacities to spend our energy more freely and in turn spend our days more freely, but as their industrialization increases, their manipulation &amp;amp; usurpation of society increases in tow5.&lt;/p&gt;
    &lt;p&gt;Illich also describes the concept of radical monopoly, which is that point where a technological tool is so dominant that people are excluded from society unless they become its users. We saw this with the automobile, we saw it with the internet, and we even see it with social media.&lt;/p&gt;
    &lt;p&gt;&lt;del&gt;No longer a tool to serve our societies, our societies now serve the automobile.&lt;/del&gt; Instead of designing and using tools to build a society, our society changes to adapt to the demands of our tools.&lt;/p&gt;
    &lt;p&gt;¬∂&lt;/p&gt;
    &lt;p&gt;Illich‚Äôs thesis allows us to reframe our adoption and use of the technologies in our life. We can map fairly directly most technological developments in the last 100 (or even 200) years to this framework: a net lift, followed by a push to extract value and subsequent insistence upon the technology‚Äôs ubiquity:&lt;/p&gt;
    &lt;head rend="h3"&gt;the textile revolution&lt;/head&gt;
    &lt;p&gt;The preferred imagery used to mythologize the Industrial Revolution is the woodetchings of textile manufacturers, transformed in the early 19th century by the arrival of automated fabric machinery. Its proponents laud the shift of an agricultural society to a technological one, creating new sectors for labor, and raising up the middle class (we will say nothing of this period‚Äôs new punishing conditions for labor in this essay6). But the ultimate ecological and human costs engendered by the increasing availability of cheap fabric production are well-documented: In 2022, the fashion and textile industries employed around 60 million factory workers worldwide7, and less than 2% of those workers earn a living wage. Those workers also endure the full suite of labor exploitation practices, including gender-based harassment, wage theft, and unsafe conditions. On the material side, the induced consumption resulting from ever-cheaper products means the world consumed 400% more textile products globally as 20 years ago8, and bins most of it (the average American generates 82 pounds of textile waste each year).&lt;/p&gt;
    &lt;head rend="h3"&gt;antibiotic technology&lt;/head&gt;
    &lt;p&gt;The arrival of antibiotics in 19289 allowed for revolutionary leaps in fighting bacterial infections like strep throat, pneumonia, and meningitis, but an over-dependence and over-prescription of penicillin and its siblings through the 1950s-70s resulted in the proliferation of antibiotic resistance, which subsequently led to longer hospital stays, higher medical costs, and increased mortality.10&lt;/p&gt;
    &lt;head rend="h3"&gt;space exploration&lt;/head&gt;
    &lt;p&gt;Since the beginning of the space exploration era in the late 1950s, humanity has made leaps and bounds in learning about our own world and its physical systems, telecommunications, imaging, etc. The increasing frequency of commercialization missions in space for satellite systems (and lately tourism) has resulted in immense amounts of space debris being generated ‚Äî both from active satellites and from jettisoned/destroyed components of previous missions, the debris threatens future missions and has even been destructive to the field of astronomy, making it impossible to use earth-based sensors and photography devices to learn about space.11 So desperate to extract Shareholder Value from the starry sky, we‚Äôre blinding our own ability to look at it.&lt;/p&gt;
    &lt;p&gt;The web is no exception to this pattern. A vision of interoperability, accessibility, and usability, the World Wide Web was first conceived in 1989 as a way to universally link documents and other media content in a flexibly-organized system that could make information easily accessed at CERN, and be easily shared with collaborators beyond.12 But the proliferation of access and ultimate social requirement of access has spawned countless troubles for human society, including cyberstalking and bullying, the instantaneous circulation of CSAM, violent images, and misinformation, identity theft, addiction, etcetera.&lt;/p&gt;
    &lt;p&gt;The rampant industrialization and commercialization of the Web predictably develops flashy, insidious patterns of extracting capital from its users: new surfaces for information means new surfaces for advertisement, and new formats of media beget new mechanisms for divorcing you from their ownership.&lt;/p&gt;
    &lt;head rend="h3"&gt;convivial life &amp;amp; convivial tooling&lt;/head&gt;
    &lt;p&gt;Illich poses convivial tools as directly opposed to this industrialized, radically-monopolized set of social systems. Similar to E.F. Schumacher‚Äôs concept of ‚Äúintermediate technology‚Äù introduced in his 1973 book Small Is Beautiful: A Study of Economics As If People Mattered, convivial tools are sustainable, energy-efficient (though often labor intensive), local-first, and designed primarily to enhance the autonomy and creativity of their users.13 Illich cites specifically hand tools, bicycles, and telephones as examples, but with its enormous capacity for interoperability and extensibility, the Internet is the perfect workshed in which to design our own Tools For Conviviality.&lt;/p&gt;
    &lt;head rend="h2"&gt;the Web we want&lt;/head&gt;
    &lt;p&gt;let‚Äôs reconsider&lt;/p&gt;
    &lt;p&gt;the markers of a decaying 'Net I mentioned before, with convivial tooling in mind:&lt;/p&gt;
    &lt;head rend="h3"&gt;Teaching &amp;amp; learning on the Web&lt;/head&gt;
    &lt;p&gt;Monolithic platforms like YouTube, TikTok, Medium, and Substack draw a ton of creators and educators because of the promise of monetization and large audiences, but they‚Äôve shown time and time again how the lack of ownership creates a problem. When those platforms fail, when they change their rules, when they demand creators move or create a particular way to maintain their access to those audiences, they pit creators or their audiences against the loss of the other. Without adhering to the algorithm‚Äôs requirements, writers may not write an impactful document, and without bypassing a paywall, readers can‚Äôt read it.&lt;/p&gt;
    &lt;p&gt;¬∂&lt;/p&gt;
    &lt;p&gt;When those promises of exorbitant wealth and a life of decadence through per-click monetization ultimately dry up (or come with a steep moral or creative cost), creators and learners must look for new solutions for how educational content is shared on the Internet. The most self-evident, convivial answer is an old one: blogs. HTML is free to access by default, RSS has worked for about 130 years[citation needed], and combined with webmentions, it‚Äôs never been easier to read new ideas, experiment with ideas, and build upon &amp;amp; grow those ideas with other strong thinkers on the web, owning that content all along.14&lt;/p&gt;
    &lt;head rend="h3"&gt;Connecting with friends on the Web&lt;/head&gt;
    &lt;p&gt;Social media apps have imprisoned us all in this weird content prison ‚Äî in order to connect with friends we‚Äôre sort of forced to create or be vanished by capricious black box algorithms, and all that we do create is, as we‚Äôve already alluded to, subsequently owned by whatever platform we‚Äôve created it on. If Instagram goes away overnight, or decides to pivot catastrophically, your stories and your network of friends goes with it.&lt;/p&gt;
    &lt;p&gt;¬∂&lt;/p&gt;
    &lt;p&gt;The advent and development of tools &amp;amp; methodologies like POSSE (Publish On your Own Site, Syndicate Elsewhere), ActivityPub, microformats, and ATProto, it‚Äôs becoming quite achievable to generate your own social network, interoperable with other networks like Bluesky or Mastodon. That network, designed for ownership and decentralization, is durable, designed around storytelling instead of engagement, and free of the whims of weird tech billionaires.&lt;/p&gt;
    &lt;p&gt;With some basic HTML knowledge and getting-stuff-online knowledge, a handful of scrappy protocols, and a free afternoon or two, one can build their own home to post bangers for the tight homies, make friends, and snipe those new friends with those hits of dopamine they so fiendishly rely on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Coding for the web&lt;/head&gt;
    &lt;p&gt;Lastly, consider the discipline of web engineering:&lt;/p&gt;
    &lt;p&gt;We have been asked to build the same B2B SaaS website with the same featureset n^‚àû times, and our answers for the optimal way to do that are increasingly limited. We‚Äôve penned all of our markup into JavaScript templates just in case a product manager needs the wrapper component to post JSON somewhere down the line, and we‚Äôve whittled away at style code until it‚Äôs just a mechanism for deploying one of two border-radius-drop-shadow combos to divs. It‚Äôs an industrial, production-minded way of approaching a discipline that has all the hallmarks of being a great craft, and that‚Äôs understandably uninspiring to many of us.&lt;/p&gt;
    &lt;p&gt;¬∂&lt;/p&gt;
    &lt;p&gt;Yet our young React shepherds have no need to fear: there are countless more colors than blurple out there, and countless more fonts than Inter. HTML and CSS are better and more generative technologies than they‚Äôve ever been: Thanks to the tireless work of the CSS working groups and browser implementers, etc, there is an unbelievable amount of creative expression possible with basic web tools in a text editor. Even JavaScript is more progressively-ehanceable than ever, and enables interfacing with a rapidly-growing number of exciting browser APIs (still fuck Brendan Eich though). &lt;code&gt;${new Date.getCurrentYear()}&lt;/code&gt; is a veritable renaissance of web code, and it asks of authors only curiosity and a drive to experiment.&lt;/p&gt;
    &lt;head rend="h2"&gt;so where do we go from here?&lt;/head&gt;
    &lt;p&gt;Illich‚Äôs thesis is that technology and its derived tools should serve people in a way that enhances their freedom, creativity, independence, and will.&lt;/p&gt;
    &lt;p&gt;The distillation of those principles on the web through manual code, hand-built social networks, and blogs, points luminously to one answer to the question of how the Internet can best serve humans:&lt;/p&gt;
    &lt;head rend="h3"&gt;it‚Äôs personal websites.&lt;/head&gt;
    &lt;p&gt;Hand-coded, syndicated, and above all personal websites are exemplary: They let users of the internet to be autonomous, experiment, have ownership, learn, share, find god, find love, find purpose. Bespoke, endlessly tweaked, eternally redesigned, built-in-public, surprising UI and delightful UX. The personal website is a staunch undying answer to everything the corporate and industrial web has taken from us.&lt;/p&gt;
    &lt;p&gt;And how might one claim this ultimate toolchain of conviviality, and build a place on the web that enhances their autonomy and creativity?&lt;/p&gt;
    &lt;p&gt;How might one build a personal website?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Start small&lt;/head&gt;
        &lt;p&gt;Let yourself start small, have fun trying shit that doesn‚Äôt work, document your growth, publish failed ideas &amp;amp; successful ones. Some of the best websites in the world are just HTML, and they belong to their authors. Make friends, let yourself be inspired by others, send friendly emails asking to learn new things, and do not demand of yourself masterpieces.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;head rend="h3"&gt;Reduce friction to publishing&lt;/head&gt;&lt;p&gt;Get the resistance to ship out of your way. Don‚Äôt get caught up in tooling and frameworks, just write HTML and get something online. If you‚Äôre an engineer, delight that you‚Äôre not beholden to the same standards of quality and rigorous testing that you are at work ‚Äî draft some ideas, hit the&lt;/p&gt;&lt;code&gt;h1&lt;/code&gt;to&lt;code&gt;p&lt;/code&gt;tag combo, and publish. Update and update again; let your ideas grow like gardens, the way they do in your mind. The mutability of the web, often its great weakness, is also one of its great strengths.&lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Don‚Äôt worry about design (unless you want to)&lt;/head&gt;
        &lt;p&gt;Don‚Äôt worry about design unless that‚Äôs the part that brings you joy. Make friends with designers and trade your work for theirs, or trade tips, trade advice. Get comfortable with being joyfully bad at something ‚Äî from that soil of humility grows a million questions for those who have learned and are excited to share. Iterate until you‚Äôve something you‚Äôre proud of, or iterate so much you‚Äôve ruined it and have to go back to bald.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Use the IndieWeb&lt;/head&gt;
        &lt;p&gt;Leverage the IndieWeb and its wonderfully thought-out protocols, tools like brid.gy to syndicate your ideas out to the wider web, and then use Webmentions to bring the ensuing conversations back where the content is. That way, you can publish work where you prefer to, folks on Bluesky can enjoy and discuss it, in the same stroke as folks on Mastodon may, or folks directly on the canonical URL.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Join us in sharing what you‚Äôve made&lt;/head&gt;
        &lt;p&gt;I encourage you to join us in our auspicious website adventure, and if you do, I hope you‚Äôll further join us on personalsit.es, our happy little home for everyone building something humble or thrilling or joyful or deeply accursed, but personal.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;(denouement)&lt;/head&gt;
    &lt;p&gt;You‚Äôre not crazy. The internet does feel genuinely so awful right now, and for about a thousand and one reasons. But the path back to feeling like you have some control is to un-spin yourself from the Five Apps of the Apocalypse and reclaim the Internet as a set of tools you use to build something you can own &amp;amp; be proud of ‚Äî or in most of our cases, be deeply ashamed of. Godspeed and good luck.&lt;/p&gt;
    &lt;p&gt;‚ù¶&lt;/p&gt;
    &lt;p&gt;That‚Äôs all for me. If you find any issues with this post, please reach out to me by email. Thanks eternally for your time and patience, and thanks for reading. Find me here online at one of my personal websites like henry.codes or strange.website or stillness.digital or strangersbyspring.com, or sometimes on Bluesky and Mastodon.&lt;/p&gt;
    &lt;p&gt;As ever, unionize, free Palestine, trans rights are human rights, fix your heart or die.&lt;/p&gt;
    &lt;p&gt;fin.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://henry.codes/writing/a-website-to-destroy-all-websites/"/><published>2026-01-01T20:36:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46457912</id><title>Show HN: Tasker ‚Äì An open-source desktop agent for browser and OS automation</title><updated>2026-01-01T21:38:08.594163+00:00</updated><content>&lt;doc fingerprint="cce229404a2136aa"&gt;
  &lt;main&gt;
    &lt;p&gt;Free and open-source. Record workflows or describe what you want in plain English. AI handles the rest. Save hours on repetitive web tasks.&lt;/p&gt;
    &lt;p&gt;Detecting your system...&lt;/p&gt;
    &lt;p&gt;Works with any website&lt;/p&gt;
    &lt;p&gt;Everything you need to automate your browser workflows. Free and open-source forever.&lt;/p&gt;
    &lt;p&gt;Click record to capture your actions, or just describe what you want in plain English. Your choice.&lt;/p&gt;
    &lt;p&gt;Our AI understands page changes and adapts. Even when websites update, your workflows keep running.&lt;/p&gt;
    &lt;p&gt;Use dynamic variables and loop through data. Process hundreds of items with a single workflow.&lt;/p&gt;
    &lt;p&gt;Watch your workflows run in real-time. See exactly what Tasker sees with built-in screenshots.&lt;/p&gt;
    &lt;p&gt;Your data never leaves your computer. Tasker runs entirely on your machine for maximum privacy.&lt;/p&gt;
    &lt;p&gt;Tasker is completely free and open source under the MIT license. Inspect the code, contribute, or customize it for your needs.&lt;/p&gt;
    &lt;p&gt;Three simple steps to automate any website&lt;/p&gt;
    &lt;p&gt;Record your workflow by doing it once, or describe what you want in plain English. Either way works.&lt;/p&gt;
    &lt;p&gt;Add variables, set conditions, and configure how your workflow handles different scenarios.&lt;/p&gt;
    &lt;p&gt;Hit play and watch AI execute your workflow. It adapts to page changes automatically.&lt;/p&gt;
    &lt;p&gt;100% free and open-source. No account required. Download and start automating today.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://automatewithtasker.com/"/><published>2026-01-01T20:53:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46458029</id><title>Cycling Game (Mini Neural Net Demo)</title><updated>2026-01-01T21:38:07.602976+00:00</updated><content>&lt;doc fingerprint="f6635ed161d8bc7a"&gt;
  &lt;main&gt;
    &lt;p&gt;Click or use up/down arrow keys to select a rider and see their neural controller. Press 'r' or wait to return to default race view which shows the top 5 riders. Space to force evolution before race distance. Reload (Ctrl+R or Cmd+R) to reset with new riders and randomly generated terrain (try this if nothing interesting is happening!).&lt;/p&gt;
    &lt;p&gt;All the riders have the same physical characteristics, but different brains, which evolve over multiple races. Each rider is controlled by a small neural network whose inputs are percepts (speed, power, battery level, average gradient over the next 100m, average gradient over the next 1000m, distance to the rider ahead, fraction of race completed) and whose output determines how the rider's power output will change per timestep (scaled by Power Multiplier). The network weights are randomly initialised. The red/blue colouring of the input nodes shows the current positive/negative contribution of each input to the output change. After each race we select the 5 leading riders, and generate a new generation of some exact copies and some with small weight mutations, which will lead to different behaviour. Watch the population of riders hopefully slowly improve their average speed over a few generations. Basic good strategy is to try hard going uphill and recover going down (because the air resistance force is proportional to velocity squared). You may also sometimes see dedicated drafters or sprinters emerge...&lt;/p&gt;
    &lt;p&gt;The cycling physics is based on rider + bike weighing 87kg, and simulates slope and air resistance effects with a drag area CwA of 0.32 and a coefficient of rolling resistance Cr of 0.004. Drafting reduces air resistance by up to nearly 40% when a rider is close behind another. Physiologically, the riders have aerobic threshold power of 250W, and a "Wprime" anaerobic battery of 15000J which discharges above that threshold and recovers beneath it. The riders have a maximum sprint power of 750W, but this decreases linearly with battery level.&lt;/p&gt;
    &lt;p&gt;Andrew Davison, Imperial College London, 2025. @ajddavison on x.com for suggestions! Partly inspired by this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.doc.ic.ac.uk/~ajd/Cycling/"/><published>2026-01-01T21:10:31+00:00</published></entry></feed>