<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 07 Oct 2025 17:36:39 +0000</lastBuildDate><item><title>The Mondrian introduction to functional optics</title><link>http://marcosh.github.io/post/2025/10/07/the-mondrian-introduction-to-functional-optics.html</link><description>&lt;doc fingerprint="13dc85e44d4ba5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Mondrian introduction to functional optics&lt;/head&gt;
    &lt;p&gt;In this post I’d like to try to discuss what functional optics are, without going too much into why they are so cool, and you should use them, or how they are implemented1 and should be used with a specific language and library.&lt;/p&gt;
    &lt;p&gt;I personally think that functional optics should be a really easy concept to grasp, but currently learning them is harder than it should be mostly due to library implementation details, quite obscure documentation and an exotic usage of weird symbols.&lt;/p&gt;
    &lt;p&gt;Since a picture is worth a thousand words, I will introduce and use a graphical notation to illustrate the concepts we will discuss.&lt;/p&gt;
    &lt;head rend="h2"&gt;Types and values&lt;/head&gt;
    &lt;p&gt;Let’s start introducing our graphical notation from its basic building blocks.&lt;/p&gt;
    &lt;p&gt;We can represent a type with a simple coloured rectangle&lt;/p&gt;
    &lt;p&gt;A value for a given type will be represented as a horizontal line spanning the width of the rectangle&lt;/p&gt;
    &lt;head rend="h2"&gt;Sums and products&lt;/head&gt;
    &lt;p&gt;When considering algebraic data types, we have two ways of combining types, using products and sums.&lt;/p&gt;
    &lt;p&gt;The product of two types &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;B&lt;/code&gt; is a new type, which we will denote by &lt;code&gt;A*B&lt;/code&gt;, whose values are composed of a value of type &lt;code&gt;A&lt;/code&gt; and a value of type &lt;code&gt;B&lt;/code&gt;. An example of a product type is a tuple like &lt;code&gt;(Int, String)&lt;/code&gt; where each value is pair composed of an integer and a string.&lt;/p&gt;
    &lt;p&gt;Graphically we can represent a product type as two side by side rectangles&lt;/p&gt;
    &lt;p&gt;When it comes to values, we need to upgrade a little bit our graphical interpretation. Since a value in a product type is composed of values of its components, we will just represent it as piecewise horizontal line, composed by horizontal lines (possible at different heights) spanning its horizontal sub-rectangles.&lt;/p&gt;
    &lt;p&gt;On the other hand, the sum of two types is represented by two rectangles one on top of the other&lt;/p&gt;
    &lt;p&gt;A value of a sum type is a horizontal line spanning the width of the whole rectangle. If it is a horizontal line in the top rectangle, it means that we are selecting the first type, and we’re using one of its values.&lt;/p&gt;
    &lt;p&gt;If it is a horizontal line in the bottom rectangle, it means that we are selecting the second type and one of its values.&lt;/p&gt;
    &lt;p&gt;More generally, for any algebraic data type, we can represent it as a sum of products by stacking a series of rectangles one on top of the other, each one potentially divided horizontally in multiple sub-rectangles.&lt;/p&gt;
    &lt;p&gt;In general, we can continue to split any sub-rectangle horizontally or vertically (if you prefer a top-down point of view) or you can place two rectangles side by side or top to bottom.&lt;/p&gt;
    &lt;p&gt;A value of such a type is a piecewise horizontal line which can not cross a horizontal division.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optics&lt;/head&gt;
    &lt;p&gt;Now that we have this graphical representation to represent data types, we can use it to discuss various kinds of optics.&lt;/p&gt;
    &lt;p&gt;In general, we can think of an optic as a way to select, given our graphical representation of a type, one (or more) rectangle inside a given rectangle representing a type. For example in the following picture we are selecting the rectangle with the red boundary inside the main rectangle representing a complex type.&lt;/p&gt;
    &lt;p&gt;If call the main type &lt;code&gt;A&lt;/code&gt; and the selected type &lt;code&gt;B&lt;/code&gt;, we will denote the optic selecting &lt;code&gt;B&lt;/code&gt; inside &lt;code&gt;A&lt;/code&gt; with &lt;code&gt;Optic A B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Before going into inspecting the various kinds of optics, let’s try to see if can can already derive some properties of optics just by looking at their graphical representation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Compositionality&lt;/head&gt;
    &lt;p&gt;One thing that we can notice is that optics compose really well. Suppose we have a type &lt;code&gt;A&lt;/code&gt; represented by the following diagram&lt;/p&gt;
    &lt;p&gt;We can first select a sub-rectangle identifying a type &lt;code&gt;B&lt;/code&gt; with an &lt;code&gt;Optic A B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Starting now with the type &lt;code&gt;B&lt;/code&gt; we can use an &lt;code&gt;Optic B C&lt;/code&gt; to select a type &lt;code&gt;C&lt;/code&gt; inside &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Using now the &lt;code&gt;Optic A B&lt;/code&gt; and the &lt;code&gt;Optic B C&lt;/code&gt; we just chose, we can compose them to obtain an &lt;code&gt;Optic A C&lt;/code&gt; which directly selects &lt;code&gt;C&lt;/code&gt; inside &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This optic composition operation is actually associative and has an identity element, turning optics into a Category.&lt;/p&gt;
    &lt;p&gt;Let’s now start to have a look at some specific families of optics.&lt;/p&gt;
    &lt;head rend="h2"&gt;Iso&lt;/head&gt;
    &lt;p&gt;The simplest optic we can define for any type &lt;code&gt;A&lt;/code&gt; is the one that we can obtain by selecting the whole rectangle.&lt;/p&gt;
    &lt;p&gt;With such a selection we can see that for any value of the outer type &lt;code&gt;A&lt;/code&gt;, we actually have a value of the type identified by the red rectangle, which we will call &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This means that, given an &lt;code&gt;Iso A B&lt;/code&gt;, we can actually define a function &lt;code&gt;view :: A -&amp;gt; B&lt;/code&gt; that for any value of &lt;code&gt;A&lt;/code&gt; gives us a value of &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;But in this special case also the converse holds! For any value of &lt;code&gt;B&lt;/code&gt;, since &lt;code&gt;B&lt;/code&gt; is actually &lt;code&gt;A&lt;/code&gt; itself, we have in fact a value of &lt;code&gt;A&lt;/code&gt;. This gives rise to a function &lt;code&gt;review :: B -&amp;gt; A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In fact &lt;code&gt;review . view = id_A&lt;/code&gt; and &lt;code&gt;view . review = id_B&lt;/code&gt; giving rise to a proper isomorphism.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lens&lt;/head&gt;
    &lt;p&gt;In our graphical representation, a &lt;code&gt;Lens&lt;/code&gt; is a vertical slice of the main rectangle.&lt;/p&gt;
    &lt;p&gt;Any vertical slice cuts out a piece out of any horizontal line. In other terms, given a value of the type &lt;code&gt;A&lt;/code&gt; represented by the main rectangle, we have a way to obtain a value of type &lt;code&gt;B&lt;/code&gt; represented by our vertical slice. This means that also in this case we are able to define a function &lt;code&gt;view :: A -&amp;gt; B&lt;/code&gt; which allows us to focus from the main type to one of its component.&lt;/p&gt;
    &lt;p&gt;On the other hand, it’s not possible with &lt;code&gt;Lens&lt;/code&gt;es as it was with &lt;code&gt;Iso&lt;/code&gt;s to build back a value of type &lt;code&gt;A&lt;/code&gt; from a value of type &lt;code&gt;B&lt;/code&gt;, since a value of type &lt;code&gt;B&lt;/code&gt; is only a part of value of type &lt;code&gt;A&lt;/code&gt;. What is actually possible, though, is to update only the part included in the red rectangle of a value of type &lt;code&gt;A&lt;/code&gt;. In other terms, given a &lt;code&gt;Lens A B&lt;/code&gt;, we can define a function &lt;code&gt;set :: B -&amp;gt; A -&amp;gt; A&lt;/code&gt; which takes a value of type &lt;code&gt;B&lt;/code&gt; and a value of type &lt;code&gt;A&lt;/code&gt; and updates the section of the latter identified by the &lt;code&gt;Lens&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Having a look at the graphical representations of the &lt;code&gt;view&lt;/code&gt; and &lt;code&gt;set&lt;/code&gt; functions, we can convince ourselves that the following properties hold:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If we &lt;code&gt;set&lt;/code&gt;a value and then we&lt;code&gt;view&lt;/code&gt;it, we must get back what we put in:&lt;code&gt;view (set b a) == b&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If we &lt;code&gt;set&lt;/code&gt;what we get out of a&lt;code&gt;view&lt;/code&gt;, nothing changes:&lt;code&gt;set (view a) a == a&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Setting a value twice is the same thing as setting it once: &lt;code&gt;set b (set b a) == set b a&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Moreover, we can notice that composing two lenses with the operation described in the Compositionality section gives us back another lens. A vertical slice of a vertical slice is in fact still a vertical slice of the original rectangle. In other terms this means that &lt;code&gt;Lens&lt;/code&gt;es form a subcategory of the bigger category of &lt;code&gt;Optic&lt;/code&gt;s.&lt;/p&gt;
    &lt;p&gt;Composing adequately &lt;code&gt;set&lt;/code&gt; and &lt;code&gt;view&lt;/code&gt; we can also define a function &lt;code&gt;over :: (B -&amp;gt; B) -&amp;gt; A -&amp;gt; A&lt;/code&gt; as &lt;code&gt;over f a = set (f $ view a) a&lt;/code&gt;. This means that if we have a function &lt;code&gt;f :: B -&amp;gt; B&lt;/code&gt; which can transform values of type &lt;code&gt;B&lt;/code&gt;, we can use our lens to extract a &lt;code&gt;B&lt;/code&gt; from an &lt;code&gt;A&lt;/code&gt; via &lt;code&gt;view&lt;/code&gt;, use &lt;code&gt;f&lt;/code&gt; to transform the result, and eventually use &lt;code&gt;set&lt;/code&gt; to update the &lt;code&gt;B&lt;/code&gt; part inside the original &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Prism&lt;/head&gt;
    &lt;p&gt;If vertical slices are &lt;code&gt;Lens&lt;/code&gt;es, it is only natural to wonder what are horizontal slices. They correspond to &lt;code&gt;Prism&lt;/code&gt;s, and they are the dual concept of &lt;code&gt;Lens&lt;/code&gt;es. Where a &lt;code&gt;Lens&lt;/code&gt; represents a component in a product type, a &lt;code&gt;Prism&lt;/code&gt; represents a component in a sum type.&lt;/p&gt;
    &lt;p&gt;Looking at values, we can notice that a value in the main type could either be a value of the inner type or it could be completely outside of it. This implies that, given a &lt;code&gt;Prism A B&lt;/code&gt;, we can define a function &lt;code&gt;preview :: A -&amp;gt; Maybe B&lt;/code&gt; which, given a value &lt;code&gt;a :: A&lt;/code&gt; returns a &lt;code&gt;Just b&lt;/code&gt; if &lt;code&gt;a&lt;/code&gt; was inside the sub-rectangle identified by &lt;code&gt;B&lt;/code&gt; and &lt;code&gt;Nothing&lt;/code&gt; otherwise.&lt;/p&gt;
    &lt;p&gt;On the other hard, since a &lt;code&gt;Prism&lt;/code&gt; constitutes a horizontal slice of the main rectangle, if we have a value of the sub-rectangle, we can always interpret it a value of the main rectangle. In other words, this means that for a &lt;code&gt;Prism A B&lt;/code&gt; we can always define a function &lt;code&gt;review :: B -&amp;gt; A&lt;/code&gt; constructing a value of type &lt;code&gt;A&lt;/code&gt; from a value of type &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Again, having a look at the graphical representation we can convince ourselves that the following properties hold for &lt;code&gt;Prism&lt;/code&gt;s:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If we preview through a &lt;code&gt;Prism&lt;/code&gt;what we just built using the same&lt;code&gt;Prism&lt;/code&gt;, we will get a value back:&lt;code&gt;preview (review b) == Just b&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If when we preview we get a &lt;code&gt;Just&lt;/code&gt;, then reviewing the result through the same&lt;code&gt;Prism&lt;/code&gt;will get us to the initial value:&lt;code&gt;preview s == Just a =&amp;gt; review a == s&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a &lt;code&gt;Prism A B&lt;/code&gt; it is also possible to define a function &lt;code&gt;set :: B -&amp;gt; A -&amp;gt; A&lt;/code&gt; as &lt;code&gt;set = flip $ const review&lt;/code&gt;. This means that, being able to construct an &lt;code&gt;A&lt;/code&gt; from a &lt;code&gt;B&lt;/code&gt;, we are able to substitute a &lt;code&gt;B&lt;/code&gt; inside an &lt;code&gt;A&lt;/code&gt; just by discarding the initial &lt;code&gt;A&lt;/code&gt; and building a new one from &lt;code&gt;B&lt;/code&gt;. Graphically, we can interpret this as using the &lt;code&gt;B&lt;/code&gt; value in the inner rectangle to build an &lt;code&gt;A&lt;/code&gt; value, forgetting about the initial &lt;code&gt;A&lt;/code&gt; value.&lt;/p&gt;
    &lt;p&gt;At this point we can also define another function &lt;code&gt;over :: (B -&amp;gt; B) -&amp;gt; A -&amp;gt; A&lt;/code&gt; which allows us to update the &lt;code&gt;B&lt;/code&gt; part inside an &lt;code&gt;A&lt;/code&gt;. We can define it as &lt;code&gt;over f a = maybe a review (f &amp;lt;$&amp;gt; preview a)&lt;/code&gt;. In words, we use &lt;code&gt;preview&lt;/code&gt; to get a &lt;code&gt;Maybe B&lt;/code&gt; and we map &lt;code&gt;f&lt;/code&gt; over it to get another &lt;code&gt;Maybe B&lt;/code&gt;; if we have a value &lt;code&gt;Just b&lt;/code&gt;, then we can use it to construct an &lt;code&gt;A&lt;/code&gt; using &lt;code&gt;review&lt;/code&gt;; on the other hand, if we ended up with a &lt;code&gt;Nothing&lt;/code&gt;, we just keep the initial &lt;code&gt;A&lt;/code&gt;. Graphically, we can interpret this as follows: if the &lt;code&gt;A&lt;/code&gt; value is inside the &lt;code&gt;B&lt;/code&gt; sub-rectangle, we apply &lt;code&gt;f&lt;/code&gt; and then we use the result to build a new &lt;code&gt;A&lt;/code&gt; value; if the value is not in &lt;code&gt;B&lt;/code&gt;, we just leave it alone.&lt;/p&gt;
    &lt;p&gt;Looking at the graphical interpretation, it’s easy to convince ourselves that the composition of two &lt;code&gt;Prism&lt;/code&gt;s is still a &lt;code&gt;Prism&lt;/code&gt;, given that a horizontal slice of a horizontal slice is still a horizontal slice of the main rectangle. In other terms, also &lt;code&gt;Prism&lt;/code&gt;s form a subcategory of the category of &lt;code&gt;Optic&lt;/code&gt;s.&lt;/p&gt;
    &lt;head rend="h2"&gt;Affine traversals&lt;/head&gt;
    &lt;p&gt;Now that we discussed &lt;code&gt;Lens&lt;/code&gt;es and &lt;code&gt;Prism&lt;/code&gt;s, one natural question which might arise is what happens when we try to compose a &lt;code&gt;Lens&lt;/code&gt; and a &lt;code&gt;Prism&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In the picture above we see a &lt;code&gt;Lens&lt;/code&gt; (the blue rectangle) composed with a &lt;code&gt;Prism&lt;/code&gt; (the red rectangle). What we get out of the composition is the lower right rectangle, which is neither a &lt;code&gt;Lens&lt;/code&gt;, nor a &lt;code&gt;Prism&lt;/code&gt;, with respect to the main rectangle. It’s just a single inner rectangle.&lt;/p&gt;
    &lt;p&gt;On the other hand, if you think about it, every inner rectangle of the main rectangle could be obtained by composing &lt;code&gt;Lens&lt;/code&gt;es and &lt;code&gt;Prism&lt;/code&gt;s.&lt;/p&gt;
    &lt;p&gt;An &lt;code&gt;Optic&lt;/code&gt; identifying an inner rectangle is called an &lt;code&gt;AffineTraversal&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Combining the intuitions we had for &lt;code&gt;Lens&lt;/code&gt;es and &lt;code&gt;Prism&lt;/code&gt;s, it’s actually possible to define functions &lt;code&gt;set :: B -&amp;gt; A -&amp;gt; A&lt;/code&gt; and &lt;code&gt;over :: (B -&amp;gt; B) -&amp;gt; A -&amp;gt; A&lt;/code&gt; also for &lt;code&gt;AffineTraversal&lt;/code&gt;s.&lt;/p&gt;
    &lt;p&gt;Moreover, the graphical representation suggests us that also &lt;code&gt;AffineTraversal&lt;/code&gt;s for a subcategory of &lt;code&gt;Optic&lt;/code&gt;s, since a sub-rectangle of a sub-rectangle is actually a sub-rectangle of the initial one.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why stop at one?&lt;/head&gt;
    &lt;p&gt;All the &lt;code&gt;Optic&lt;/code&gt;s that we discussed so far focus on a single sub-rectangle. But, if we want, we can consider also &lt;code&gt;Optic&lt;/code&gt;s which focus on multiple sub-rectangles at the same time.&lt;/p&gt;
    &lt;p&gt;We will denote by &lt;code&gt;Traversal A B&lt;/code&gt; the &lt;code&gt;Optic&lt;/code&gt;s which focus on multiple sub-rectangles of type &lt;code&gt;B&lt;/code&gt; inside a main rectangle of type &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;Traversal&lt;/code&gt;s we can still define &lt;code&gt;set :: B -&amp;gt; A -&amp;gt; A&lt;/code&gt; which replaces all the selected sub-rectangles of type &lt;code&gt;B&lt;/code&gt;, inside the main rectangle of type &lt;code&gt;A&lt;/code&gt;, with the same vale &lt;code&gt;b&lt;/code&gt; of type &lt;code&gt;B&lt;/code&gt;, to produce a new &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Similarly, we can define &lt;code&gt;over :: (B -&amp;gt; B) -&amp;gt; A -&amp;gt; A&lt;/code&gt; which applies a function to all the selected sub-rectangles of type &lt;code&gt;B&lt;/code&gt;, inside the main rectangle of type &lt;code&gt;A&lt;/code&gt;, to produce a new &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Another relevant function which makes sense to consider for &lt;code&gt;Traversal&lt;/code&gt;s is &lt;code&gt;toListOf :: A -&amp;gt; [B]&lt;/code&gt;, which extracts all the values of the selected sub-rectangles of type &lt;code&gt;B&lt;/code&gt; from the main rectangle of type &lt;code&gt;A&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;As usual, we can notice that &lt;code&gt;Traversal A B&lt;/code&gt; form a subcategory of &lt;code&gt;Optic A B&lt;/code&gt;, since a selection of sub-rectangles inside a selection 0f sub-rectangles is still a selection of sub-rectangles of the main rectangle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The graphical representation we just introduced in this post provides us with a tool to navigate various kinds of &lt;code&gt;Optic&lt;/code&gt;s and their operations. I hope it can provide a concrete way to understand the basic ideas behind &lt;code&gt;Lens&lt;/code&gt;es, &lt;code&gt;Prism&lt;/code&gt;s and other &lt;code&gt;Optic&lt;/code&gt;s and make it easier to use them.&lt;/p&gt;
    &lt;p&gt;Such a representation could also help to explore and shed some light on the mysterious world of &lt;code&gt;Optic&lt;/code&gt;s. One could try to search for other sub-categories in a graphical fashion and then ask what do they correspond to in other &lt;code&gt;Optic&lt;/code&gt; representation. For example, what is the sub-category of &lt;code&gt;Optics&lt;/code&gt; made by multiple horizontal slices? Or the one made by multiple vertical slices?&lt;/p&gt;
    &lt;p&gt;I need also to mention that such a representation is not able, as far as I can see, to fully represent the whole universe of &lt;code&gt;Optic&lt;/code&gt;s. For example, it’s hard to distinguish a &lt;code&gt;Traversal&lt;/code&gt; from a &lt;code&gt;Fold&lt;/code&gt;, or describe what &lt;code&gt;Grate&lt;/code&gt;s are.&lt;/p&gt;
    &lt;p&gt;All in all, I’m confident that describing and explaining optics in this graphical fashion could help people understand their beauty and usefulness! Thanks for reading up to here!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45501114</guid><pubDate>Tue, 07 Oct 2025 09:35:53 +0000</pubDate></item><item><title>Nobel Prize in Physics 2025</title><link>https://www.nobelprize.org/prizes/physics/2025/popular-information/</link><description>&lt;doc fingerprint="715db15f2195d5ea"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Popular information&lt;/head&gt;
    &lt;p&gt;Popular science background: Quantum properties on a human scale (pdf)&lt;lb/&gt;Populärvetenskaplig information: Kvantegenskaper på mänsklig skala (pdf)&lt;/p&gt;
    &lt;head rend="h2"&gt;Quantum properties on a human scale&lt;/head&gt;
    &lt;p&gt;The Nobel Prize laureates in physics for 2025, John Clarke, Michel H. Devoret and John M. Martinis, used a series of experiments to demonstrate that the bizarre properties of the quantum world can be made concrete in a system big enough to be held in the hand. Their superconducting electrical system could tunnel from one state to another, as if it were passing straight through a wall. They also showed that the system absorbed and emitted energy in doses of specific sizes, just as predicted by quantum mechanics.&lt;/p&gt;
    &lt;head rend="h3"&gt;A series of groundbreaking experiments&lt;/head&gt;
    &lt;p&gt;Quantum mechanics describes properties that are significant on a scale that involves single particles. In quantum physics, these phenomena are called microscopic, even when they are much smaller than can be seen using an optical microscope. This contrasts with macroscopic phenomena, which consist of a large number of particles. For example, an everyday ball is built up of an astronomical amount of molecules and displays no quantum mechanical effects. We know that the ball will bounce back every time it is thrown at a wall. A single particle, however, will sometimes pass straight through an equivalent barrier in its microscopic world and appear on the other side. This quantum mechanical phenomenon is called tunnelling.&lt;/p&gt;
    &lt;p&gt;This year’s Nobel Prize in Physics recognises experiments that demonstrated how quantum tunnelling can be observed on a macroscopic scale, involving many particles. In 1984 and 1985, John Clarke, Michel Devoret and John Martinis conducted a series of experiments at the University of California, Berkeley. They built an electrical circuit with two superconductors, components that can conduct a current without any electrical resistance. They separated these with a thin layer of material that did not conduct any current at all. In this experiment, they showed that they could control and investigate a phenomenon in which all the charged particles in the superconductor behave in unison, as if they are a single particle that fills the entire circuit.&lt;/p&gt;
    &lt;p&gt;This particle-like system is trapped in a state in which current flows without any voltage – a state from which it does not have enough energy to escape. In the experiment, the system shows its quantum character by using tunnelling to escape the zero-voltage state, generating an electrical voltage. The laureates were also able to show that the system is quantised, which means it only absorbs or emits energy in specific amounts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tunnels and crossings&lt;/head&gt;
    &lt;p&gt;To help them, the laureates had concepts and experimental tools that had been developed over decades. Together with the theory of relativity, quantum physics is the foundation of what has come to be called modern physics, and researchers have spent the last century exploring what it entails.&lt;/p&gt;
    &lt;p&gt;Individual particles’ ability to tunnel is well known. In 1928, the physicist George Gamow realised that tunnelling is the reason why some heavy atomic nuclei tend to decay in a particular manner. The interaction between the forces in the nucleus creates a barrier around it, holding in the particles it contains. However, despite this, a small piece of the atomic nucleus can sometimes split off, move outside the barrier and escape – leaving behind a nucleus that has been transformed into another element. Without tunnelling, this type of nuclear decay could not occur.&lt;/p&gt;
    &lt;p&gt;Tunnelling is a quantum mechanical process, which entails that chance plays a role. Some types of atomic nuclei have a tall, wide barrier, so it can take a long while for a piece of the nucleus to appear outside it, while other types decay more easily. If we only look at a single atom, we cannot predict when this will happen, but by watching the decay of a large number of nuclei of the same type, we can measure an expected time before tunnelling occurs. The most common way of describing this is through the concept of half-life, which is how long it takes for half the nuclei in a sample to decay.&lt;/p&gt;
    &lt;p&gt;Physicists were quick to wonder whether it would be possible to investigate a type of tunnelling that involves more than one particle at a time. One approach to new types of experiments originated in a phenomenon that arises when some materials get extremely cold.&lt;/p&gt;
    &lt;p&gt;In an ordinary conductive material, current flows because there are electrons that are free to move through the entire material. In some materials, the individual electrons that push their way through the conductor may become organised, forming a synchronised dance that flows without any resistance. The material has become a superconductor and the electrons are joined together as pairs. These are called Cooper pairs, after Leon Cooper who, along with John Bardeen and Robert Schrieffer, provided a detailed description of how superconductors work (Nobel Prize in Physics 1972).&lt;/p&gt;
    &lt;p&gt;Cooper pairs behave completely differently to ordinary electrons. Electrons have a great deal of integrity and like to stay at a distance from each other – two electrons cannot be in the same place if they have the same properties. We can see this in an atom, for example, where the electrons divide themselves into different energy levels, called shells. However, when the electrons in a superconductor join up as pairs, they lose a bit of their individuality; while two separate electrons are always distinct, two Cooper pairs can be exactly the same. This means the Cooper pairs in a superconductor can be described as a single unit, one quantum mechanical system. In the language of quantum mechanics, they are then described as a single wave function. This wave function describes the probability of observing the system in a given state and with given properties.&lt;/p&gt;
    &lt;p&gt;If two superconductors are joined together with a thin insulating barrier between them, it creates a Josephson junction. This component is named after Brian Josephson, who performed quantum mechanical calculations for the junction. He discovered that interesting phenomena arise when the wave functions on each side of the junction are considered (Nobel Prize in Physics 1973). The Josephson junction rapidly found areas of application, including in precise measurements of fundamental physical constants and magnetic fields.&lt;/p&gt;
    &lt;p&gt;The construction also provided tools for exploring the fundamentals of quantum physics in a new way. One person who did so was Anthony Leggett (Nobel Prize in Physics 2003), whose theoretical work on macroscopic quantum tunnelling at a Josephson junction inspired new types of experiments.&lt;/p&gt;
    &lt;head rend="h3"&gt;The research group starts its work&lt;/head&gt;
    &lt;p&gt;These subjects were a perfect match for John Clarke’s research interests. He was a professor at the University of California, Berkeley, in the US, where he had moved after completing his doctoral degree at the University of Cambridge, UK, in 1968. At UC Berkeley he built up his research group and specialised in exploring a range of phenomena using superconductors and the Josephson junction.&lt;/p&gt;
    &lt;p&gt;By the mid-1980s, Michel Devoret had joined John Clarke’s research group as a postdoc, after receiving his doctorate in Paris. This group also included the doctoral student John Martinis. Together, they took on the challenge of demonstrating macroscopic quantum tunnelling. Vast amounts of care and precision were necessary to screen the experimental setup from all the interference that could affect it. They succeeded in refining and measuring all the properties of their electrical circuit, allowing them to understand it in detail.&lt;/p&gt;
    &lt;p&gt;To measure the quantum phenomena, they fed a weak current into the Josephson junction and measured the voltage, which is related to the electrical resistance in the circuit. The voltage over the Josephson junction was initially zero, as expected. This is because the wave function for the system is enclosed in a state that does not allow a voltage to arise. Then they studied how long it took for the system to tunnel out of this state, causing a voltage. Because quantum mechanics entails an element of chance, they took numerous measurements and plotted their results as graphs, from which they could read the duration of the zero-voltage state. This is similar to how measurements of the half-lives of atomic nuclei are based on statistics of numerous instances of decay.&lt;/p&gt;
    &lt;p&gt;The tunnelling demonstrates how the experimental setup’s Cooper pairs, in their synchronised dance, behave like a single giant particle. The researchers obtained further confirmation of this when they saw that the system had quantised energy levels. Quantum mechanics was named after the observation that the energy in microscopic processes is divided into separate packages, quanta. The laureates introduced microwaves of varying wavelengths into the zero-voltage state. Some of these were absorbed, and the system then moved to a higher energy level. This showed that the zero-voltage state had a shorter duration when the system contained more energy – which is exactly what quantum mechanics predicts. A microscopic particle shut behind a barrier functions in the same way.&lt;/p&gt;
    &lt;head rend="h3"&gt;Practical and theoretical benefit&lt;/head&gt;
    &lt;p&gt;This experiment has consequences for the understanding of quantum mechanics. Other types of quantum mechanical effects that are demonstrated on the macroscopic scale are composed of many tiny individual pieces and their separate quantum properties. The microscopic components are then combined to cause macroscopic phenomena such as lasers, superconductors and superfluid liquids. However, this experiment instead created a macroscopic effect – a measurable voltage – from a state that is in itself macroscopic, in the form of a common wave function for vast numbers of particles.&lt;/p&gt;
    &lt;p&gt;Theorists like Anthony Leggett have compared the laureates’ macroscopic quantum system with Erwin Schrödinger’s famous thought experiment featuring a cat in a box, where the cat would be both alive and dead if we did not look inside. (Erwin Schrödinger received the Nobel Prize in Physics 1933.) The intention of his thought experiment was to show the absurdity of this situation, because the special properties of quantum mechanics are often erased at a macroscopic scale. The quantum properties of an entire cat cannot be demonstrated in a laboratory experiment.&lt;/p&gt;
    &lt;p&gt;However, Legget has argued that the series of experiments conducted by John Clarke, Michel Devoret and John Martinis showed that there are phenomena that involve vast numbers of particles which together behave just as quantum mechanics predicts. The macroscopic system that consists of many Cooper pairs is still many orders of magnitude smaller than a kitten – but because the experiment measures the quantum mechanical properties that apply to the system as a whole, for a quantum physicist it is fairly similar to Schrödinger’s imaginary cat.&lt;/p&gt;
    &lt;p&gt;This type of macroscopic quantum state offers new potential for experiments using the phenomena that govern the microscopic world of particles. It can be regarded as a form of artificial atom on a large scale – an atom with cables and sockets that can be connected into new test set-ups or utilised in new quantum technology. For example, artificial atoms are used to simulate other quantum systems and aid in understanding them.&lt;/p&gt;
    &lt;p&gt;Another example is the quantum computer experiment subsequently performed by Martinis, in which he utilised exactly the energy quantisation that he and the other two laureates had demonstrated. He used a circuit with quantised states as information-bearing units – a quantum bit. The lowest energy state and the first step upward functioned as zero and one, respectively. Superconducting circuits are one of the techniques being explored in attempts to construct a future quantum computer.&lt;/p&gt;
    &lt;p&gt;This year’s laureates have thus contributed to both practical benefit in physics laboratories and to providing new information for the theoretical understanding of our physical world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Further reading&lt;/head&gt;
    &lt;p&gt;Additional information on this year’s prizes, including a scientific background in English, is available on the website of the Royal Swedish Academy of Sciences, www.kva.se, and at www.nobelprize.org, where you can watch video from the press conferences, the Nobel Prize lectures and more. Information on exhibitions and activities related to the Nobel Prizes and the prize in economic sciences is available at www.nobelprizemuseum.se.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Royal Swedish Academy of Sciences has decided to award the Nobel Prize in Physics 2025 to&lt;/head&gt;
    &lt;p&gt;JOHN CLARKE&lt;lb/&gt;Born 1942 in Cambridge, UK. PhD 1968 from University of Cambridge, UK. Professor at University of California, Berkeley, USA.&lt;/p&gt;
    &lt;p&gt;MICHEL H. DEVORET&lt;lb/&gt;Born 1953 in Paris, France. PhD 1982 from Paris-Sud University, France. Professor at Yale University, New Haven, CT and University of California, Santa Barbara, USA.&lt;/p&gt;
    &lt;p&gt;JOHN M. MARTINIS&lt;lb/&gt;Born 1958. PhD 1987 from University of Californa, Berkeley, USA. Professor at University of California, Santa Barbara, USA.&lt;/p&gt;
    &lt;p&gt;“for the discovery of macroscopic quantum mechanical tunnelling and energy quantisation in an electric circuit”&lt;/p&gt;
    &lt;p&gt;Science Editors: Ulf Danielsson, Göran Johansson and Eva Lindroth, the Nobel Committee for Physics&lt;lb/&gt;Text: Anna Davour&lt;lb/&gt;Translation: Clare Barnes&lt;lb/&gt;Illustrations: Johan Jarnestad&lt;lb/&gt;Editor: Sara Gustavsson&lt;lb/&gt;© The Royal Swedish Academy of Sciences&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45501189</guid><pubDate>Tue, 07 Oct 2025 09:50:49 +0000</pubDate></item><item><title>Devpush – Open-source and self-hostable alternative to Vercel, Render, Netlify</title><link>https://github.com/hunvreus/devpush</link><description>&lt;doc fingerprint="c1875194e4671d1"&gt;
  &lt;main&gt;
    &lt;p&gt;An open-source and self-hostable alternative to Vercel, Render, Netlify and the likes. It allows you to build and deploy any app (Python, Node.js, PHP, ...) with zero-downtime updates, real-time logs, team management, customizable environments and domains, etc.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Git-based deployments: Push to deploy from GitHub with zero-downtime rollouts and instant rollback.&lt;/item&gt;
      &lt;item&gt;Multi-language support: Python, Node.js, PHP... basically anything that can run on Docker.&lt;/item&gt;
      &lt;item&gt;Environment management: Multiple environments with branch mapping and encrypted environment variables.&lt;/item&gt;
      &lt;item&gt;Real-time monitoring: Live and searchable build and runtime logs.&lt;/item&gt;
      &lt;item&gt;Team collaboration: Role-based access control with team invitations and permissions.&lt;/item&gt;
      &lt;item&gt;Custom domains: Support for custom domain and automatic Let's Encrypt SSL certificates.&lt;/item&gt;
      &lt;item&gt;Self-hosted and open source: Run on your own servers, MIT licensed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;User documentation: devpu.sh/docs&lt;/item&gt;
      &lt;item&gt;Technical documentation: ARCHITECTURE&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Supported on Ubuntu/Debian. Other distros may work but aren't officially supported (yet).&lt;/quote&gt;
    &lt;p&gt;Log in your server, run the following command and follow instructions:&lt;/p&gt;
    &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/install.sh | sudo bash&lt;/code&gt;
    &lt;p&gt;You user must have sudo privileges.&lt;/p&gt;
    &lt;p&gt;You will need a fresh Ubuntu/Debian server you can SSH into with sudo privileges. We recommend a CPX31 from Hetzner.&lt;/p&gt;
    &lt;p&gt;You can use the provisioning script to get a server up and running:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Sign in or sign up for a Hetzner account: Hetzner Cloud Console&lt;/item&gt;
      &lt;item&gt;Generate an API token: Creating an API token&lt;/item&gt;
      &lt;item&gt;Provision a server (requires &lt;code&gt;--token&lt;/code&gt;; optional:&lt;code&gt;--user&lt;/code&gt;,&lt;code&gt;--name&lt;/code&gt;,&lt;code&gt;--region&lt;/code&gt;,&lt;code&gt;--type&lt;/code&gt;):Tip: run&lt;quote&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/provision-hetzner.sh | bash -s -- --token &amp;lt;hetzner_api_key&amp;gt; [--user &amp;lt;login_user&amp;gt;] [--name &amp;lt;hostname&amp;gt;] [--region &amp;lt;fsn1|nbg1|hel1|ash|hil|sin&amp;gt;] [--type &amp;lt;cpx11|cpx21|cpx31|cpx41|cpx51&amp;gt;]&lt;/quote&gt;&lt;code&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/provision-hetzner.sh | bash -s -- --help&lt;/code&gt;to list regions and types (with specs). Defaults: region&lt;code&gt;hil&lt;/code&gt;, type&lt;code&gt;cpx31&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Configure DNS Records: Go to your DNS provider and create two A records pointing at the server IP for &lt;code&gt;APP_HOSTNAME&lt;/code&gt;(e.g.&lt;code&gt;app.devpu.sh&lt;/code&gt;) and a wildcard on subdomains of&lt;code&gt;DEPLOY_DOMAIN&lt;/code&gt;(e.g.&lt;code&gt;*.devpush.app&lt;/code&gt;). If you're using Cloudflare, set SSL/TLS to "Full (strict)" and keep the records proxied.&lt;/item&gt;
      &lt;item&gt;SSH into your new server: The provision script will have created a user for you. &lt;quote&gt;ssh &amp;lt;login_user&amp;gt;@&amp;lt;server_ip&amp;gt;&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Run hardening for system and SSH:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/harden.sh | sudo bash -s -- --ssh&lt;/code&gt;
    &lt;p&gt;Even if you already have a server, we recommend you harden security (ufw, fail2ban, disabled root SSH, etc). You can do that using &lt;code&gt;scripts/prod/harden.sh&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;SSH into the server: &lt;quote&gt;ssh &amp;lt;login_user&amp;gt;@&amp;lt;server_ip&amp;gt;&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Install /dev/push: &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/hunvreus/devpush/main/scripts/prod/install.sh | sudo bash&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Switch to &lt;code&gt;devpush&lt;/code&gt;user:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sudo -iu devpush&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Edit &lt;code&gt;.env&lt;/code&gt;:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cd devpush &amp;amp;&amp;amp; vi .env&lt;/code&gt;
    &lt;p&gt;Tip: you will need to fill in at least the following: &lt;code&gt;LE_EMAIL&lt;/code&gt;, &lt;code&gt;APP_HOSTNAME&lt;/code&gt;, &lt;code&gt;DEPLOY_DOMAIN&lt;/code&gt;, &lt;code&gt;EMAIL_SENDER_ADDRESS&lt;/code&gt;, &lt;code&gt;RESEND_API_KEY&lt;/code&gt; and your GitHub app settings (see [environment-variables] for details). &lt;code&gt;SERVER_IP&lt;/code&gt;, &lt;code&gt;SECRET_KEY&lt;/code&gt;, &lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;, &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt; should be pre-filled. You can ignore all commented out environment variables.
5. Start services:&lt;/p&gt;
    &lt;code&gt;scripts/prod/start.sh --migrate&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Visit your URL: &lt;code&gt;https://&amp;lt;APP_HOSTNAME&amp;gt;&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The follwing commands must be run as &lt;code&gt;devpush&lt;/code&gt; user (&lt;code&gt;su - devpush&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;In most cases, you can run an update with:&lt;/p&gt;
    &lt;code&gt;scripts/prod/update.sh --all&lt;/code&gt;
    &lt;p&gt;Alternatively, you can force a full upgrade (with downtime) using:&lt;/p&gt;
    &lt;code&gt;scripts/prod/update.sh --full -y&lt;/code&gt;
    &lt;p&gt;You can update specific components:&lt;/p&gt;
    &lt;code&gt;scripts/prod/update.sh --components &amp;lt;component_name&amp;gt;&lt;/code&gt;
    &lt;quote&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;Development scripts target macOS for now.&lt;/quote&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Colima and the Loki Docker plugin: &lt;quote&gt;scripts/dev/install.sh&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Set up environment variables: &lt;quote&gt;cp .env.dev.example .env&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Start the stack (streams logs): &lt;quote&gt;scripts/dev/start.sh&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Add &lt;code&gt;--prune&lt;/code&gt;to prune dangling images before build&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;--cache&lt;/code&gt;to use the build cache (default is no cache)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Add &lt;/item&gt;
      &lt;item&gt;Initialize your database once containers are up: &lt;quote&gt;scripts/dev/db-migrate.sh&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the scripts section for more dev utilities.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The app is mounted inside containers, so code changes reflect immediately. Some SSE endpoints may require closing browser tabs to trigger a reload.&lt;/item&gt;
      &lt;item&gt;The workers require a restart: &lt;quote&gt;docker-compose restart worker-arq&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;To apply migrations: &lt;quote&gt;scripts/dev/db-migrate.sh&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Area&lt;/cell&gt;
        &lt;cell role="head"&gt;Script&lt;/cell&gt;
        &lt;cell role="head"&gt;What it does&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/install.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Setup Colima and install Loki Docker plugin&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/start.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start stack with logs (foreground); supports &lt;code&gt;--prune&lt;/code&gt;, &lt;code&gt;--cache&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/build-runners.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Build runner images (default no cache; &lt;code&gt;--cache&lt;/code&gt; to enable)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/db-generate.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Generate Alembic migration (prompts for message)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/db-migrate.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Apply Alembic migrations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/db-reset.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Drop and recreate &lt;code&gt;public&lt;/code&gt; schema in DB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Dev&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/dev/clean.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stop stack and clean dev data (&lt;code&gt;--hard&lt;/code&gt; for global)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/provision-hetzner.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Provision a Hetzner server (API token, regions from API, fixed sizes)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/install.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Server setup: Docker, Loki plugin, user, clone repo, create &lt;code&gt;.env&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/harden.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;System hardening (UFW, fail2ban, unattended-upgrades); add &lt;code&gt;--ssh&lt;/code&gt; to harden SSH&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/start.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start services; optional &lt;code&gt;--migrate&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/stop.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stop services (&lt;code&gt;--down&lt;/code&gt; for hard stop)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/restart.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Restart services; optional &lt;code&gt;--migrate&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/update.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Update by tag; &lt;code&gt;--all&lt;/code&gt; (app+workers), &lt;code&gt;--full&lt;/code&gt; (downtime), or &lt;code&gt;--components&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/db-migrate.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Apply DB migrations in production&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/check-env.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Validate required keys exist in &lt;code&gt;.env&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/update/app.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Blue‑green update for app&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/update/worker-arq.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Drain‑aware blue‑green update for &lt;code&gt;worker-arq&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Prod&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;scripts/prod/update/worker-monitor.sh&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Blue‑green update for &lt;code&gt;worker-monitor&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Comments&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;APP_NAME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;App name.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/dev/push&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;APP_DESCRIPTION&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;App description.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Deploy your Python app without touching a server.&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;URL_SCHEME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;http&lt;/code&gt; (development) or &lt;code&gt;https&lt;/code&gt; (production).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;https&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;LE_EMAIL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Email used to register the Let's Encrypt (ACME) account in Traefik; receives certificate issuance/renewal/expiry notifications.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;APP_HOSTNAME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Domain for the app (e.g. &lt;code&gt;app.devpu.sh&lt;/code&gt;).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DEPLOY_DOMAIN&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Domain used for deployments (e.g. &lt;code&gt;devpush.app&lt;/code&gt; if you want your deployments available at &lt;code&gt;*.devpush.app&lt;/code&gt;).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;APP_HOSTNAME&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;SERVER_IP&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Public IP of the server&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;SECRET_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;App secret for sessions/CSRF. Generate: &lt;code&gt;openssl rand -hex 32&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fernet key (urlsafe base64, 32 bytes). Generate: `openssl rand -base64 32&lt;/cell&gt;
        &lt;cell&gt;tr '+/' '-_'&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;EMAIL_LOGO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;URL for email logo image. Only helpful for testing, as the app will use &lt;code&gt;app/logo-email.png&lt;/code&gt; if left empty.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;EMAIL_SENDER_NAME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Name displayed as email sender for invites/login.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;EMAIL_SENDER_ADDRESS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Email sender used for invites/login.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;RESEND_API_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;API key for Resend.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_ID&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub App ID.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_NAME&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub App name.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_PRIVATE_KEY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub App private key (PEM format).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_WEBHOOK_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub webhook secret for verifying webhook payloads.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_CLIENT_ID&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub OAuth app client ID.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GITHUB_APP_CLIENT_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;GitHub OAuth app client secret.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GOOGLE_CLIENT_ID&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Google OAuth client ID.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;GOOGLE_CLIENT_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Google OAuth client secret.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;POSTGRES_DB&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;PostgreSQL database name.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;devpush&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;POSTGRES_USER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;PostgreSQL username.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;devpush-app&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;PostgreSQL password. Generate: `openssl rand -base64 24&lt;/cell&gt;
        &lt;cell&gt;tr -d '\n'`&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;REDIS_URL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Redis connection URL.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;redis://redis:6379&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DOCKER_HOST&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Docker daemon host address.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;tcp://docker-proxy:2375&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;UPLOAD_DIR&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Directory for file uploads.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/app/upload&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;TRAEFIK_CONFIG_DIR&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Traefik configuration directory.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/data/traefik&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DEFAULT_CPU_QUOTA&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Default CPU quota for containers (microseconds).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;100000&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DEFAULT_MEMORY_MB&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Default memory limit for containers (MB).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;4096&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;JOB_TIMEOUT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Job timeout in seconds.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;320&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;JOB_COMPLETION_WAIT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Job completion wait time in seconds.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;300&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DEPLOYMENT_TIMEOUT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Deployment timeout in seconds.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;300&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;LOG_LEVEL&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Logging level.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WARNING&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;DB_ECHO&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable SQL query logging.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ENV&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Environment (development/production).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;development&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ACCESS_DENIED_MESSAGE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Message shown to users who are denied access based on sign-in access control.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Sign-in not allowed for this email.&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ACCESS_DENIED_WEBHOOK&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Optional webhook to receive denied events (read more about Sign-in access control).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;LOGIN_HEADER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;HTML snippet displayed above the login form.&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;TOASTER_HEADER&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;HTML snippet displayed at the top of the toaster (useful to display a permanent toast on all pages).&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;""&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;You will need to configure a GitHub App with the following settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Identifying and authorizing users: &lt;list rend="ul"&gt;&lt;item&gt;Callback URL: add two callback URLs with your domain:&lt;/item&gt;&lt;item&gt;Expire user authorization tokens: No&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Post installation: &lt;list rend="ul"&gt;&lt;item&gt;Setup URL: https://example.com/api/github/install/callback&lt;/item&gt;&lt;item&gt;Redirect on update: Yes&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Webhook: &lt;list rend="ul"&gt;&lt;item&gt;Active: Yes&lt;/item&gt;&lt;item&gt;Webhook URL: https://example.com/api/github/webhook&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Permissions: &lt;list rend="ul"&gt;&lt;item&gt;Repository permissions &lt;list rend="ul"&gt;&lt;item&gt;Administration: Read and write&lt;/item&gt;&lt;item&gt;Checks: Read and write&lt;/item&gt;&lt;item&gt;Commit statuses: Read and write&lt;/item&gt;&lt;item&gt;Contents: Read and write&lt;/item&gt;&lt;item&gt;Deployments: Read and write&lt;/item&gt;&lt;item&gt;Issues: Read and write&lt;/item&gt;&lt;item&gt;Metadata: Read-only&lt;/item&gt;&lt;item&gt;Pull requests: Read and write&lt;/item&gt;&lt;item&gt;Webhook: Read and write&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Account permissions: &lt;list rend="ul"&gt;&lt;item&gt;Email addresses: Read-only&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Repository permissions &lt;/item&gt;
      &lt;item&gt;Subscribe to events: &lt;list rend="ul"&gt;&lt;item&gt;Installation target&lt;/item&gt;&lt;item&gt;Push&lt;/item&gt;&lt;item&gt;Repository&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Provide an access rules file to restrict who can sign up/sign in.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Development: edit &lt;code&gt;./access.json&lt;/code&gt;. If missing, running&lt;code&gt;scripts/dev/start.sh&lt;/code&gt;will sed an allow‑all file.&lt;/item&gt;
      &lt;item&gt;Production: edit &lt;code&gt;/srv/devpush/access.json&lt;/code&gt;on the server.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Rules format (any/all may be used):&lt;/p&gt;
    &lt;code&gt;{
  "emails": ["alice@example.com"],
  "domains": ["example.com"],
  "globs": ["*@corp.local", "*.dept.example.com"],
  "regex": ["^[^@]+@(eng|research)\\.example\\.com$"]
}&lt;/code&gt;
    &lt;p&gt;Globs use shell-style wildcards; regex are Python patterns. If the file is missing or empty, all valid emails are allowed.&lt;/p&gt;
    &lt;p&gt;Additionally, if you set the &lt;code&gt;ACCESS_DENIED_WEBHOOK&lt;/code&gt; environment variable, denied sign-in attempts will be posted to the provided URL with the following payload:&lt;/p&gt;
    &lt;code&gt;{
  "email": "user@example.com",
  "provider": "google",
  "ip": "203.0.113.10",
  "user_agent": "Mozilla/5.0"
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45501279</guid><pubDate>Tue, 07 Oct 2025 10:07:50 +0000</pubDate></item><item><title>The evolution of Lua, continued [pdf]</title><link>https://www.lua.org/doc/cola.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45502502</guid><pubDate>Tue, 07 Oct 2025 12:54:14 +0000</pubDate></item><item><title>Qualcomm to Acquire Arduino</title><link>https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45502541</guid><pubDate>Tue, 07 Oct 2025 13:00:08 +0000</pubDate></item><item><title>Erlang ARM32 JIT is born</title><link>https://www.grisp.org/blog/posts/2025-10-07-jit-arm32.3</link><description>&lt;doc fingerprint="ea279a502acd05f8"&gt;
  &lt;main&gt;
    &lt;p&gt;A blog series recounting our adventures in the quest to port the BEAM JIT to the ARM32-bit architecture.&lt;/p&gt;
    &lt;p&gt;This work is made possible thanks to funding from the Erlang Ecosystem Foundation and the ongoing support of its Embedded Working Group.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Erlang ARM32 JIT is born!&lt;/head&gt;
    &lt;p&gt;This week we finally achieved our first milestone in developing the ARM32 JIT. We executed our first Erlang function through JITted ARM32 machine code!&lt;/p&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/arm32-jit/otp/RELEASE -progname erl -home /home
    ~/arm32-jit$ echo $?
    42&lt;/code&gt;
    &lt;p&gt;The BEAM successfully runs and terminates with error code 42! That 42 comes from an Erlang function, just-in-time compiled by our ARM32 JIT!&lt;/p&gt;
    &lt;p&gt;Announcement is done! All code is available at https://github.com/stritzinger/otp/tree/arm32-jit&lt;/p&gt;
    &lt;p&gt;Keep reading for a lot of interesting details!&lt;/p&gt;
    &lt;head rend="h2"&gt;The first piece of Erlang code&lt;/head&gt;
    &lt;code&gt;-module(hello).
-export([start/2]).

start(_BootMod, _BootArgs) -&amp;gt;
    halt(42, [{flush, false}]).&lt;/code&gt;
    &lt;p&gt;This is &lt;code&gt;hello.erl&lt;/code&gt; that contains a &lt;code&gt;start/2&lt;/code&gt; function. The function head mimics the &lt;code&gt;erl_init:start/2&lt;/code&gt; function, which is the entry point of the first Erlang process. We replaced &lt;code&gt;erl_init:start/2&lt;/code&gt; with &lt;code&gt;hello:start/2&lt;/code&gt; in the &lt;code&gt;erl_init.c&lt;/code&gt; module of the BEAM VM. This way, we forced the runtime to execute this Erlang function.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;hello:start/2&lt;/code&gt; is very simple as it just calls the &lt;code&gt;erlang:halt/2&lt;/code&gt;. This function is a BIF (Built-in Function) that executes C code, part of the BEAM VM. This code executes an ordered shutdown of the BEAM and allows us to customize the error code, in this case: &lt;code&gt;42&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;(Why &lt;code&gt;{flush, false}&lt;/code&gt;? At the time I am writing this, letting it be true causes a segmentation fault EHEH)&lt;/p&gt;
    &lt;p&gt;Obviously, we need to compile this Erlang module, but I will also generate the BEAM assembly so we can have a look at what we will have to deal with.&lt;/p&gt;
    &lt;code&gt;{module, hello}.  %% version = 0
{exports, [{module_info,0},{module_info,1},{start,2}]}.
{attributes, []}.
{labels, 7}.

{function, start, 2, 2}.
  {label,1}.
    {line,[{location,"erts/preloaded/src/hello.erl",74}]}.
    {func_info,{atom,hello},{atom,start},2}.
  {label,2}.
    {move,{literal,[{flush,false}]},{x,1}}.
    {move,{integer,42},{x,0}}.
    {line,[{location,"erts/preloaded/src/hello.erl",76}]}.
    {call_ext_only,2,{extfunc,erlang,halt,2}}.

{function, module_info, 0, 4}.
  {label,3}.
    {line,[]}.
    {func_info,{atom,hello},{atom,module_info},0}.
  {label,4}.
    {move,{atom,hello},{x,0}}.
    {call_ext_only,1,{extfunc,erlang,get_module_info,1}}.

{function, module_info, 1, 6}.
  {label,5}.
    {line,[]}.
    {func_info,{atom,hello},{atom,module_info},1}.
  {label,6}.
    {move,{x,0},{x,1}}.
    {move,{atom,hello},{x,0}}.
    {call_ext_only,2,{extfunc,erlang,get_module_info,2}}.&lt;/code&gt;
    &lt;p&gt;You can spot the start function and the two standard module_info functions that all Erlang modules have. We do not care much about those right now as we discovered that they are not executed and are not required to work, for now.&lt;/p&gt;
    &lt;p&gt;We can see that the core of the start function is just two &lt;code&gt;move&lt;/code&gt; operations and one &lt;code&gt;call_ext_only&lt;/code&gt;. But bear in mind that the BEAM loader will transmute these Generic BEAM Operations into Specific operations. More complexity will pop up!&lt;/p&gt;
    &lt;head rend="h2"&gt;Execution&lt;/head&gt;
    &lt;p&gt;We are using &lt;code&gt;qemu-arm&lt;/code&gt; to emulate &lt;code&gt;Arm32&lt;/code&gt; and we are directly using &lt;code&gt;beam.smp&lt;/code&gt; to run the BEAM.&lt;/p&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/vagrant/arm32-jit/otp/RELEASE -progname erl -home /home/vagrant&lt;/code&gt;
    &lt;head rend="h3"&gt;JIT initialization&lt;/head&gt;
    &lt;p&gt;At boot, the BEAM initializes the JIT if enabled. The JIT leverages the AsmJit library to emit all machine code instructions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Emission of all global shared fragments&lt;/head&gt;
    &lt;p&gt;There are 90+ code snippets that are shared among all modules. The JIT loads them one single time and sets up jumps to them in every other module. It is like a global library for all modules.&lt;/p&gt;
    &lt;p&gt;We skipped most of these because just the shared fragments involved in the &lt;code&gt;hello:start/2&lt;/code&gt; execution were needed.&lt;/p&gt;
    &lt;head rend="h4"&gt;Emission of the erts_beamasm module&lt;/head&gt;
    &lt;p&gt;As part of the JIT initialization, &lt;code&gt;erts_beamasm&lt;/code&gt; is emitted. This module is an internal hardcoded module that exists only when BEAM is using the JIT. It holds 7 fundamental instructions used to manage the Erlang process executions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;run_process - The main process execution entry point&lt;/item&gt;
      &lt;item&gt;normal_exit - Normal process termination&lt;/item&gt;
      &lt;item&gt;continue_exit - Continue after exit handling&lt;/item&gt;
      &lt;item&gt;exception_trace - Exception tracing functionality&lt;/item&gt;
      &lt;item&gt;return_trace - Return value tracing&lt;/item&gt;
      &lt;item&gt;return_to_trace - Return to tracing state&lt;/item&gt;
      &lt;item&gt;call_trace_return - Call tracing return handling&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Preloaded modules&lt;/head&gt;
    &lt;p&gt;The &lt;code&gt;hello.erl&lt;/code&gt; module has been compiled and put as first and single Erlang module in the list of preloaded modules. Preloaded modules are Erlang fundamental modules that are always loaded by the BEAM before the first Erlang process can start. They implement, in Erlang, the core features of the Erlang Runtime System (ERTS). The OTP build scripts group all &lt;code&gt;ebin&lt;/code&gt; files into a single C header that is then linked into the executable. This makes the Erlang binaries available as a static C array in the BEAM source code. These are then loaded one by one after the BEAM VM is initialized.&lt;/p&gt;
    &lt;p&gt;Cool, let's nuke all these modules and leave just our &lt;code&gt;hello.erl&lt;/code&gt;. It does not need many BEAM instructions and we can easily verify that it executes. To do the substitution we just need to change this build variable in otp/erts/emulator/Makefile.in&lt;/p&gt;
    &lt;p&gt;We are running BEAMASM with &lt;code&gt;-JDdump true&lt;/code&gt; so &lt;code&gt;asmjit&lt;/code&gt; will dump all ARM32 assembly for each module! This is incredibly useful if monitored while executing with a debugger, as we can see the assembler being printed line by line by our code.&lt;/p&gt;
    &lt;code&gt;~/arm32-jit$ cat hello.asm 
L6:
.byte 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_1:
# i_func_info_IaaI
# hello:start/2
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x0B, 0xA4, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00
# aligned_label_Lt
start/2:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L9
    bl L11
L9:
# i_test_yield
    adr r2, start/2
    subs r9, r9, 1
    b.le L13
# i_move_sd
    ldr r12, [L14]
    str r12, [r4, 68]
# i_move_sd
    movw r12, 687
    str r12, [r4, 64]
# line_I
# allocate_tt
# call_light_bif_be
L15:
    ldr r3, [L16]
    movw r1, 10188
    movt r1, 16432
    adr r2, L15
# BIF: erlang:halt/2
    sub r12, r7, 4
    cmp r10, r12
    b.ls L17
    udf 48879
L17:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L18
    udf 57005
L18:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_3:
# i_func_info_IaaI
# hello:module_info/0
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x4B, 0x6B, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
# aligned_label_Lt
module_info/0:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L23
    bl L11
L23:
# i_test_yield
    adr r2, module_info/0
    subs r9, r9, 1
    b.le L13
# i_move_sd
    movw r12, 20235
    str r12, [r4, 64]
# allocate_tt
# call_light_bif_be
L24:
    ldr r3, [L25]
    movw r1, 4772
    movt r1, 16425
    adr r2, L24
# BIF: erlang:get_module_info/1
    sub r12, r7, 4
    cmp r10, r12
    b.ls L26
    udf 48879
L26:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L27
    udf 57005
L27:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# i_flush_stubs
# func_line_I
# aligned_label_Lt
label_5:
# i_func_info_IaaI
# hello:module_info/1
    blx L8
.byte 0x00, 0x00, 0x00, 0x00
.byte 0x0B, 0x4F, 0x00, 0x00, 0x4B, 0x6B, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00
# aligned_label_Lt
module_info/1:
# i_breakpoint_trampoline
    str lr, [r7, -4]!
    b L28
    bl L11
L28:
# i_test_yield
    adr r2, module_info/1
    subs r9, r9, 1
    b.le L13
# i_move_sd
    ldr r12, [r4, 64]
    str r12, [r4, 68]
# i_move_sd
    movw r12, 20235
    str r12, [r4, 64]
# allocate_tt
# call_light_bif_be
L29:
    ldr r3, [L30]
    movw r1, 4868
    movt r1, 16425
    adr r2, L29
# BIF: erlang:get_module_info/2
    sub r12, r7, 4
    cmp r10, r12
    b.ls L31
    udf 48879
L31:
    movw r12, 12424
    add r12, r4, r12
    ldr r12, [r12]
    cmp sp, r12
    b.eq L32
    udf 57005
L32:
    bl L20
# deallocate_t
    movw r0, 64676
    movt r0, 16480
    blx L22
# return
    movw r0, 61636
    movt r0, 16480
    blx L22
# int_code_end
L33:
    movw r0, 18576
    movt r0, 16480
    blx L22
L13:
L12:
    movw r12, 1968
    movt r12, 14656
    blx r12
L22:
L21:
    movw r12, 29192
    movt r12, 16399
    blx r12
L11:
L10:
    movw r12, 1752
    movt r12, 14656
    blx r12
L20:
L19:
    movw r12, 680
    movt r12, 14656
    blx r12
L8:
L7:
    movw r12, 1824
    movt r12, 14656
    blx r12
# Begin stub section
L14:
.xword 0x000000007FFFFFFF
L16:
.xword 0x000000007FFFFFFF
L25:
.xword 0x000000007FFFFFFF
L30:
.xword 0x000000007FFFFFFF
# End stub section
L34:
.section .rodata {#1}
md5:
.byte 0x6D, 0xC4, 0x1E, 0xF1, 0x13, 0x1E, 0xBF, 0xF2, 0x4B, 0xF5, 0xC0, 0x41, 0x57, 0x86, 0xDF, 0xD5
.section .text {#0}
; CODE_SIZE: 632&lt;/code&gt;
    &lt;p&gt;Bear in mind, this assembler is not what hello should look like. We are missing a lot of things.&lt;/p&gt;
    &lt;p&gt;You can spot many sequences like:&lt;/p&gt;
    &lt;code&gt;    movw r0, 64676
    movt r0, 16480
    blx L22 # &amp;lt;---- branch to NYI&lt;/code&gt;
    &lt;p&gt;This is a call to &lt;code&gt;nyi&lt;/code&gt; (Not Yet Implemented) function and the argument loaded to R0 is the pointer to a string that contains the name of the BEAM instruction that should have been emitted instead. You can spot many of these since we are only emitting the code to reach halt. Everything after that is not important now as halt will never return!&lt;/p&gt;
    &lt;p&gt;There are many more comments we could make around all the details in this assembler dump, but let's move on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Jumping into Jitted code!&lt;/head&gt;
    &lt;p&gt;Later in the BEAM initialization the first Erlang process will be allocated and started.&lt;/p&gt;
    &lt;p&gt;We swap the module and function with hello in erts/emulator/beam/erl_init.c&lt;/p&gt;
    &lt;code&gt;    erl_spawn_system_process(&amp;amp;parent, am_hello, am_start, args, &amp;amp;so);&lt;/code&gt;
    &lt;p&gt;One BEAM scheduler thread will jump to the &lt;code&gt;process_main&lt;/code&gt; function. You can find it here in the source code. This is emitted by our JIT and is the first emitted code that will run.&lt;/p&gt;
    &lt;p&gt;Here we need to handle the Erlang processes scheduling by calling BEAM routines that implement the algorithms of Erlang concurrency, like &lt;code&gt;erts_schedule&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;erts_schedule&lt;/code&gt; will return the pointer to the &lt;code&gt;Process&lt;/code&gt; C structure that holds all information about the process that is going to execute. We then load all necessary data inside registers and then we branch to the exact point where the program execution stopped.&lt;/p&gt;
    &lt;head rend="h3"&gt;The first Erlang function call&lt;/head&gt;
    &lt;p&gt;In this case we are calling &lt;code&gt;hello:start/2&lt;/code&gt; so the first instruction to execute is &lt;code&gt;apply_only&lt;/code&gt; that does a few things but ends up calling the C &lt;code&gt;apply&lt;/code&gt; routine.&lt;/p&gt;
    &lt;p&gt;The routine processes the Module-Function-Arity information to get the address where the function code resides in memory.&lt;/p&gt;
    &lt;p&gt;What follows is the Erlang function prologue. You can see it in the assembler code section above. For example, all functions have these instructions in their prologue:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;i_breakpoint_trampoline: handle breakpoints for the &lt;code&gt;debugger&lt;/code&gt;app&lt;/item&gt;
      &lt;item&gt;i_test_yield: checks if the function should yield and go back to the scheduler&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We have minimal or partial implementations of these since we do not really need them. We have to emit them though, as the C++ generated loader functions from the BEAM are expanding the Erlang function call Operation into a more specific and complex function prologue sequence.&lt;/p&gt;
    &lt;p&gt;After that, we added support for the &lt;code&gt;call_light_bif&lt;/code&gt; operation that precedes the call to the halt_2 BIF routine. This implementation is also minimal.&lt;/p&gt;
    &lt;p&gt;Question for later: did you notice that we put a &lt;code&gt;42&lt;/code&gt; as a number in the code? Numeric constants are printed as decimals in the dump, but we cannot spot any 42!?&lt;/p&gt;
    &lt;p&gt;After the call, we see two other operations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;dealloc&lt;/item&gt;
      &lt;item&gt;return&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are just calls to NYI as we will never reach this code! So for now, we can skip them...&lt;/p&gt;
    &lt;head rend="h3"&gt;Let's roll the JIT!&lt;/head&gt;
    &lt;code&gt;    ~/arm32-jit$ qemu-arm -L /usr/arm-linux-gnueabihf ./otp/RELEASE/erts-15.0/bin/beam.smp -S 1:1 -SDcpu 1:1 -SDio 1 -JDdump true -JMsingle     true -- -root /home/arm32-jit/otp/RELEASE -progname erl -home /home
    ~/arm32-jit$&lt;/code&gt;
    &lt;p&gt;Impressive, the program returns immediately without even saying "Hi" ... and without Segmentation Fault!!&lt;/p&gt;
    &lt;p&gt;But let's check the program return code!&lt;/p&gt;
    &lt;code&gt;~/arm32-jit$ echo $?
42
&lt;/code&gt;
    &lt;p&gt;We can safely say that number is not there by accident! This is a great achievement as from now on we will be able to incrementally add Erlang instructions.&lt;/p&gt;
    &lt;p&gt;Every Erlang line we add will trigger new Opcodes. By emitting them and running the code we will have immediate feedback on everything.&lt;/p&gt;
    &lt;p&gt;The next goal now is to complete the &lt;code&gt;hello&lt;/code&gt; module to host all possible beam instructions!&lt;/p&gt;
    &lt;head rend="h4"&gt;Hey where is 42???&lt;/head&gt;
    &lt;p&gt;One interesting thing I spotted looking at the assembly: You cannot find the number &lt;code&gt;42&lt;/code&gt; in there. Or actually, you can, it is just hidden in plain sight. To understand you need to know how we are using ARM32 registers.&lt;/p&gt;
    &lt;p&gt;In particular the register &lt;code&gt;r4&lt;/code&gt;, a callee-saved register. We are using it to store the pointer to the &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt; struct. The &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt; contains the X register array. When a function is called, X registers are used to store the arguments of the call.&lt;/p&gt;
    &lt;p&gt;This becomes more obvious if we compare the Erlang assembly to the Arm32 assembly.&lt;/p&gt;
    &lt;code&gt;# i_move_sd                       &amp;lt;---- {move,{literal,[{flush,false}]},{x,1}}. % List at X[1]
    ldr r12, [L14]
    str r12, [r4, 68]
# i_move_sd                       &amp;lt;---- {move,{integer,42},{x,0}}. % 42 at X[0]
    movw r12, 687 
    str r12, [r4, 64]
# line_I
# allocate_tt
# call_light_bif_be
L15:
    ldr r3, [L16]
    movw r1, 10188
    movt r1, 16432
    adr r2, L15
# BIF: erlang:halt/2
# ...&lt;/code&gt;
    &lt;p&gt;42 is stored at &lt;code&gt;r4&lt;/code&gt;+64.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;r4: pointer to the &lt;code&gt;ErtsSchedulerRegisters&lt;/code&gt;struct&lt;/item&gt;
      &lt;item&gt;64: base offset from the beginning of the struct to the beginning of the &lt;code&gt;x_reg_array&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The list is stored at &lt;code&gt;r4&lt;/code&gt;+68.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;68: is the base offset + the size of one &lt;code&gt;Eterm&lt;/code&gt;(4 bytes on ARM32)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But why in assembly do we see 687 and not 42?&lt;/p&gt;
    &lt;p&gt;Converting both numbers to hex we get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;42 -&amp;gt; 2A&lt;/item&gt;
      &lt;item&gt;687 -&amp;gt; 2AF !!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yep, this is an example of a Tagged Value. If we consult the BEAM book we can learn about the Tagging Scheme:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;00 11 Pid&lt;/item&gt;
      &lt;item&gt;01 11 Port&lt;/item&gt;
      &lt;item&gt;10 11 Immediate 2&lt;/item&gt;
      &lt;item&gt;11 11 Small integer&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;42 is tagged with &lt;code&gt;1111&lt;/code&gt; at the low end. So the BEAM can quickly recognize during a pattern match that this Erlang Term is a Small Integer!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45502543</guid><pubDate>Tue, 07 Oct 2025 13:00:25 +0000</pubDate></item><item><title>3M May Escape Toxic Chemical, PFAS Manufacturing Legacy</title><link>https://www.bloomberg.com/features/2025-3m-pfas-toxic-legacy-turnaround/</link><description>&lt;doc fingerprint="2e10915d0a385ff3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;3M Might Just Escape Its Toxic Chemical Legacy&lt;/head&gt;
    &lt;p&gt;Decades of selling PFAS left the iconic American manufacturer mired in legal liabilities. A new CEO is hoping to spark a turnaround.&lt;/p&gt;
    &lt;p&gt;The Command strip is one of those quintessential 3M products. Released in 1996, it was simple yet revolutionary, strong enough to hold items without stripping paint when removed. Soon it was fastening framed photos, bathroom towels and outdoor decorations around the world.&lt;/p&gt;
    &lt;p&gt;The adhesive that made the strip possible was invented by a 3M scientist in the late 1980s. The exact science is a closely guarded secret, but it can resist gravity while somehow pulling away clean when tugged as instructed. In hindsight the market for such an invention is obvious, and yet it was almost lost to corporate bureaucracy. 3M shelved the project at one point in the ’90s and revived it only after impassioned pleas from a determined product development executive. His persistence paid off: Within three years of its debut, the Command strip was turning a $10 million profit. 3M Co. now sells more than 200 varieties, bringing in $500 million a year.&lt;/p&gt;
    &lt;p&gt;As Command strips turned into a product empire, though, they also became captive to 3M’s unique form of industrial sprawl. Historically the company has organized its factories by material science and manufacturing processes, rather than by product—think chemicals in one facility, adhesives in another and packaging somewhere else, for example, regardless of their ultimate end use. This way, the thinking went, with each innovation, 3M could wring more value from existing machinery and underlying technologies. But every new product and geographic market also brought with it new costs and complexities, resulting in a labyrinthine factory network. This approach meant that Command strip production took place at multiple sites, sometimes hundreds of miles apart. Add in more steps for distribution, and the journey to Walmart shelves of what is, at base, just a particularly good sticky plastic hook looks pretty convoluted.&lt;/p&gt;
    &lt;p&gt;3M is one of the most sparkling brand names in US business history, known for advancing material science to the point that the first astronauts who walked on the moon were equipped with boots made from its synthetic rubber. If America wanted it, 3M could invent and produce it, building its fortunes on products as innocuous as Post-it notes and as dangerous as chemicals lining nonstick pans. From its headquarters in St. Paul, the company also became known in the business world for its Minnesota-nice corporate culture, a contrast to the ruthlessness championed by the likes of longtime General Electric Co. Chief Executive Officer Jack Welch. 3M’s executives were unfailingly polite, its senior scientists were allowed to devote 15% of their time to research projects of their choosing, and many employees worked at 3M for their entire careers, long after staying in one job forever ceased to be fashionable.&lt;/p&gt;
    &lt;p&gt;But problems were bubbling under the surface, ones that went well beyond struggles with successful lines like the Command strip. First and foremost, those pan-lining chemicals—specifically certain types of perfluoroalkyl and polyfluoroalkyl substances, or PFAS, which were also used in products such as Scotchgard fabric protector and firefighting foam—have been found to increase the risk of cancer, decrease fertility and suppress the immune system, including weakening response to vaccines. Those findings have fueled a vast array of lawsuits that analysts estimate could end up costing 3M in the neighborhood of $20 billion, including ones it has already settled. Adding to those legal woes, the company spent years facing down major multidistrict litigation claiming it knowingly sold defective earplugs that left US military service members with hearing loss and tinnitus. (In agreements to resolve both of those lawsuits, 3M hasn’t admitted to any liability or wrongdoing.)&lt;/p&gt;
    &lt;p&gt;As 3M dealt with these issues, its traditional strengths were atrophying. New product introductions slowed to a trickle, and sales growth was lackluster. If America wanted it, 3M grew less and less likely to be making it. By late 2021, as most businesses were regaining their footing after the pandemic, it appeared to many observers almost as if 3M had forgotten how to be a manufacturing company. Investors stopped treating it like one, viewing it more through the lens of liability and risk than of factory output and projected revenue.&lt;/p&gt;
    &lt;p&gt;Even 3M’s Minnesota-nice reputation has taken some hits. Senior executives privately complain that in recent years, beneath all the Midwestern cheer, the working environment has been marked by tone deafness, overbearing bureaucracy and resistance to change. Decisions were slow, fixes pushed by management felt blunt and grating, and accountability was hard to come by. Worker-safety protocols also lapsed, with the incident rate at its factories becoming significantly higher than at North American peers such as Corteva, Dow and GE.&lt;/p&gt;
    &lt;p&gt;Effectively, 3M became “a case study of everything not to do over a very long period of time,” says Scott Davis, an analyst at Melius Research LLC. It became a “broken company.” And when that happens, Davis says, “you want change, you crave change.”&lt;/p&gt;
    &lt;p&gt;With almost $100 billion of market value wiped out from the peak in 2018 to the start of 2024, 3M last year tapped Bill Brown, an outsider who’d spent much of his career in the defense industry, to turn things around. He hosted his first earnings call about three months into the job. Analysts and investors expected him to offer the usual platitudes about hosting listening sessions and considering all options. Instead he talked about the Command strip—how it demonstrated perfectly that the company had gotten too big, too slow, too convoluted. Brown said he had a plan to tackle all that. 3M’s stock price shot up more than 20% by close, its best one-day rally in more than four decades on the public markets.&lt;/p&gt;
    &lt;p&gt;The company declined to comment on the reporting in this story, instead saying in a statement that it’s “focused on creating shareholder value and positioning 3M for success by driving profitable growth, embedding a culture of operational excellence across the enterprise.”&lt;/p&gt;
    &lt;p&gt;It will help Brown’s turnaround plan that 3M’s liabilities have become less open-ended: A major settlement with water utilities over PFAS pollution and a deal to resolve the earplugs litigation, both agreed to in 2023, have reset investor expectations for the overall bill. The Trump administration also appears set to take a lighter touch to environmental regulation, providing relief to companies like 3M.&lt;/p&gt;
    &lt;p&gt;But even the optimists concede that this is no easy fix. In the months since Brown took the reins, he’s been relying on the same playbook that Dave Cote used to restore Honeywell International Inc. in the early 2000s, when it faced a raft of asbestos lawsuits and the aftereffects of several dubious megamergers, and that Larry Culp deployed this decade to resuscitate GE when it was overwhelmed by debt and a $15 billion mess in a legacy insurance business. Brown’s plan starts with running 3M better. Get that right, and the really big problems—the amorphous liabilities, the cultural corrosion, the public-image crisis—won’t seem quite as insurmountable.&lt;/p&gt;
    &lt;p&gt;Minnesota Mining &amp;amp; Manufacturing started in 1902 as a venture to mine corundum, which is harder than all other minerals save for diamonds and an ideal ingredient in sandpaper. But when its founders discovered they were in fact extracting a different low-grade material, they decided to get out of mining and into making the sandpaper instead, using raw materials sourced elsewhere.&lt;/p&gt;
    &lt;p&gt;Similarly, 3M didn’t discover PFAS. These synthetic chemicals trace back to the Manhattan Project, which required scientists to invent a way to extract uranium to make an atomic bomb. A chemical engineering professor at Pennsylvania State College named Joseph H. Simons developed a process to create almost unbreakable carbon fluorine bonds by passing raw fluorine, a highly volatile gas, through a carbon arc. He later developed a method for practical production of fluorocarbons, a process 3M employed to pioneer the use of PFAS in consumer and industrial products starting in the 1950s. The company eventually became a major producer both for its own products and for customers such as DuPont de Nemours Inc., which used it in Teflon.&lt;/p&gt;
    &lt;p&gt;Near-indestructibility is useful for everything from developing nuclear weapons to repelling grease and water. But these chemicals take years to break down, making them highly problematic in the environment and the human body. For a long time, 3M billed manufactured PFAS and its PFAS-infused products as perfectly safe, even as internal documents and studies unearthed through lawsuits showed the company was aware of the chemicals’ toxicity at least as far back as the 1970s.&lt;/p&gt;
    &lt;p&gt;In 1998, Richard Purdy, an ecological toxicologist at 3M, conducted a study that found PFAS even in the blood of bald eagle nestlings, which primarily eat fish and inhabit remote areas. He quit the next year and sent a copy of his resignation letter to the US Environmental Protection Agency, saying the company had failed to properly communicate to customers and regulators the results of research showing how prevalent the chemicals had become in people and the environment. In 2000, 3M announced it would voluntarily stop making the forms of the chemicals that had the most research documenting their hazards, even as it maintained the chemicals were safe and didn’t pose a long-term health issue. In 2006, the company reached a $1.5 million settlement with the EPA over reporting violations related to PFAS.&lt;/p&gt;
    &lt;p&gt;More research about the health consequences of PFAS followed, including an influential 2012 study of children born in the remote Faroe Islands that found the chemicals in bloodstreams at levels comparable to the US population and indicated a resulting weakened immune response to vaccines. As the production of certain kinds of PFAS declined, the concentration of the chemicals in people’s bloodstreams fell sharply, according to research from the US Centers for Disease Control and Prevention and others. But after decades of use, the legal challenges, and the public fallout, were just beginning.&lt;/p&gt;
    &lt;p&gt;The tipping point came in 2018. That January, The Devil We Know—an investigative documentary examining a West Virginia community’s fight against a plant, then owned by DuPont, that made Teflon—premiered at the Sundance Film Festival. A few weeks after that, 3M agreed, without admitting wrongdoing, to pay $850 million to settle a lawsuit brought by Minnesota over claims the company had poisoned drinking water in its own backyard. And in June the CDC, drawing on scientific advances that allowed PFAS detection at much lower levels, published a draft report warning that the chemicals can cause health problems at significantly lower exposure thresholds than what the EPA had claimed at the time was safe.&lt;/p&gt;
    &lt;p&gt;The following month, Michael Roman took over as 3M’s CEO. A 30-year company veteran, Roman had overseen businesses in the US, Europe and Asia and had served as 3M’s chief operating officer. He was the embodiment of its culture of politesse, but this ultimately wouldn’t help him much with the storm that was brewing. PFAS claims came to span challenges from state attorneys general, water utilities, people with personal injury and property complaints, and foreign governments such as those of Belgium and the Netherlands.&lt;/p&gt;
    &lt;p&gt;Adding to the pile, 3M was also being sued over an earplug business it had acquired through the 2008 purchase of Aearo Technologies. In July 2018, the same month Roman took over, 3M had agreed, without admitting wrongdoing, to a $9.1 million settlement with the US Department of Justice to resolve allegations that it had sold earplugs to the US military without disclosing defects. Cases brought by veterans claiming hearing damage mushroomed after the settlement and dragged on for years.&lt;/p&gt;
    &lt;p&gt;With potential liabilities stewing outside its factories, 3M was simultaneously dealing with issues inside them. Having long prided itself on being a desirable and safe place to work, the company was seeing an uptick in the number of safety violations at its factories. From 2019 to 2024, 3M received at least 27 “serious” initial citations, which are based on worksite investigations, from the Occupational Safety and Health Administration—more than any other company among a group of its North American industrial and health-care technology peers, according to a Bloomberg Businessweek analysis.&lt;/p&gt;
    &lt;p&gt;3M also got one repeat admonishment and notice of three willful violations, meaning it knowingly failed to comply with a legal requirement or acted with “plain indifference to employee safety.” (3M and other companies in the dataset have contested many of the citations, and have in some cases succeeded in getting them downgraded or dismissed as part of settlements. In response to requests for comment from Businessweek, Carlisle said that its injury rate is “very low” compared with the industry average and that it seeks to “continuously improve” its safety standards, and GE said it took immediate action to report the incident that led to its citations and to prevent a reoccurrence.)&lt;/p&gt;
    &lt;p&gt;Two of 3M’s willful violations were linked to inadequate safeguards for a plastic extrusion machine that required employees to thread material through by hand. Trisha Jones, who operated the machine at the company’s plant in Prairie du Chien, Wisconsin, died in May 2023 after getting caught in the large rollers and suffering traumatic head injuries. “They’re not managing these facilities well,” says David Michaels, who ran OSHA from 2009 to 2017 and is now a professor of public health at George Washington University. “That’s a sign of safety management not being implemented.”&lt;/p&gt;
    &lt;p&gt;The safety incidents jarred with the benevolent culture workers had come to expect. Peter Gibbons, formerly in charge of overseeing supply chains across the company, would regularly contend that the biggest cause of injuries at factories was employees falling down stairs while using their phones, so much so that “Use the Handrail” became a running joke among staff, according to people with the company who, like others interviewed for this piece, asked not to be named discussing private interactions or information. (Gibbons didn’t respond to requests for comment.)&lt;/p&gt;
    &lt;p&gt;People close to 3M say the rise in safety incidents reflected years of underinvestment in factories to save costs, as well as a decision by Roman in 2020 to make oversight of manufacturing operations the responsibility of managers in charge of the business lines, rather than ones who were on-site at plants. The shift was part of a 2020 reorganization, dubbed “Advanced 3M,” that was intended to make the company more responsive to customer needs.&lt;/p&gt;
    &lt;p&gt;It was one of many sweeping gestures Roman undertook during his six years at the helm. Another was Polaris, a suite of digital tools introduced in 2021 to give customers a more Amazon-like experience when placing and tracking orders; the initiative ended up costing more than planned and hasn’t been fully implemented since going online, the people close to the company say. Roman also pursued several cost-cutting efforts that cost hundreds of workers their jobs while barely denting 3M’s financial results. In fact its profit margins went sideways, in contrast to peers that were improving manufacturing processes, raising prices and adding market share.&lt;/p&gt;
    &lt;p&gt;During his tenure, Roman developed a reputation internally for being thin-skinned. In 2020, at the height of the pandemic, he hosted virtual town halls as part of a planned series. But, according to the people close to the company, the series was abruptly canceled after he learned that anonymous commenters had criticized his presentations for reasons that included a lack of detail and transparency about Covid-19 strategy and protocols. (Roman didn’t respond to requests for comment.)&lt;/p&gt;
    &lt;p&gt;Roman’s biggest challenge may have been that an outsize amount of his time, rather than being spent running an industrial company, was spent managing the PFAS problem, even though manufactured PFAS represented a fraction of 3M’s business. In 2022 the Biden administration proposed to designate certain PFAS as hazardous materials under the federal Superfund law, and the EPA declared that virtually no amount of the chemicals is safe in drinking water. Not long after, Roman announced 3M would cease all remaining production of PFAS and work to discontinue their use in its products by the end of 2025. In internal deliberations, people familiar with the conversations say, executives had pointed out to Roman that PFAS are integral to the production of semiconductors, electric-vehicle batteries and weapons systems—the very types of goods the US government under President Joe Biden was seeking to make more of at home. At the very least, some argued, 3M should sell its PFAS manufacturing facilities rather than simply shutting them down. Roman didn’t want to hear it: 3M was done with PFAS, and that was that.&lt;/p&gt;
    &lt;p&gt;Getting all the PFAS out of its products has proved complicated, though. In a testament to how prevalent the chemicals have become, 3M has cautioned investors that they may continue to be present beyond 2025 in certain products that contain components manufactured by third parties, including lithium-ion batteries, printed circuit boards and some seals and gaskets. 3M said this is because approved substitutes that meet regulatory and industry standards may not be available.&lt;/p&gt;
    &lt;p&gt;In the year after Roman’s announcement, 3M finally started putting some of its legal challenges behind it. The company announced a deal in June 2023 to pay as much as $12.5 billion over 13 years to test and treat city water supplies for PFAS, resolving current and future claims by municipal utilities over pollution. A few months later it announced it had reached a separate $6 billion agreement to resolve claims in the earplug litigation.&lt;/p&gt;
    &lt;p&gt;3M continued to chip away at its PFAS lawsuits after Brown replaced Roman in 2024. This May it agreed to pay New Jersey as much as $450 million to resolve claims related to PFAS pollution at the 3M-supplied Chambers Works plant, as well as general complaints about natural resource damage from the chemicals.&lt;/p&gt;
    &lt;p&gt;As settlements have accrued, estimates for how much the company might ultimately have to pay have gone down. Andrew Obin, an analyst at Bank of America Corp., says 3M might be on the hook for $11.5 billion in settlements related to US suits over damages to natural resources alone. But he says the settlement math in New Jersey—which has particularly acute levels of PFAS pollution—implies his estimate for this category of claims should be materially lower, closer to $6 billion.&lt;/p&gt;
    &lt;p&gt;The regulatory landscape is also changing in ways that might help 3M. The shift began with the US Supreme Court’s decision, handed down last June 28, to overturn the Chevron doctrine, the legal principle that empowered executive branch agencies to interpret and enforce regulations. The ruling gave momentum to lawsuits filed by chemical industry and manufacturing groups as well as water utility associations, challenging the Biden administration’s limits on PFAS in drinking water as arbitrary and financially impossible. This May, President Donald Trump’s EPA announced it was delaying its compliance deadline for removal of the two best-known types of PFAS and was rescinding and reconsidering the limits on four other categories. And earlier this month, in a major shift, the EPA asked the court to vacate the drinking water rule for the four other categories of PFAS, concurring with the water utility plaintiffs that aspects of the process by which the standards had been established were unlawful. The agency has delayed a rule, too, that would have required PFAS manufacturers to file reports about environmental and health effects from 2011 to 2022. (The EPA said in a statement that it’s “committed to protecting public health by addressing PFAS in drinking water while following the law and ensuring that regulatory compliance is achievable for drinking water systems.”)&lt;/p&gt;
    &lt;p&gt;The US Chamber of Commerce is also leading a lawsuit against the EPA over the designation of certain types of PFAS as hazardous materials under the Superfund law—which it contends could force companies to collectively pay as much as $17.4 billion in cleanup costs just for nonfederal sites that have been identified as a priority. After repeatedly getting the proceedings postponed, the Trump administration announced this month that it would retain the Superfund designation for the two best-known kinds of PFAS, while calling upon Congress to address concerns about entities getting stuck with cleanup bills for chemicals they didn’t themselves manufacture. The litigation itself continues.&lt;/p&gt;
    &lt;p&gt;Obin, the Bank of America analyst, pegs 3M’s liability for cleaning up Superfund sites at as much as $9 billion but says that bill could also end up being lower as legal challenges drag out the policy’s implementation. And he points out that the company could recover as much as 25% of its total PFAS liabilities through insurance payouts. “In conversations with investors, the narrative has changed,” Obin says. “Maybe three years ago, people would say, ‘Why are your estimates so low?’”&lt;/p&gt;
    &lt;p&gt;3M’s other big remaining undefined PFAS liability is personal injury lawsuits. These, too, may turn out to be less financially crippling than analysts previously feared. In major multidistrict litigation, plaintiffs are arguing that they got cancer by being exposed to water contaminated with PFAS from firefighting foam and are seeking damages from 3M and other companies. The defendants’ lawyers have sought to exclude expert testimony for the plaintiffs on the link between PFAS and cancer, contending that they relied on research findings that aren’t statistically significant at the relevant exposure levels for the claimants. A bellwether trial had been set to come before a federal district court in South Carolina in October. It’s since been postponed “until such a time as the court deems appropriate,” to allow both sides to sift through a large number of unfiled claims and determine which of these should be included in the proceeding. The judge overseeing the case has urged the two sides to settle, and this latest development may make such an agreement more likely, according to Barclays Plc analyst Julian Mitchell. As it stands, Mitchell estimates that all of 3M’s outstanding PFAS liabilities, including personal injury and natural resources claims, could be as much as $11 billion, down from his $16 billion calculation immediately after an agreement to settle the water lawsuits was announced in 2023.&lt;/p&gt;
    &lt;p&gt;Companies have recovered from liability disasters before. Davis, the Melius Research analyst, recalls a peer predicting in the early 2000s that Honeywell would go bankrupt because of asbestos claims, as well as a short seller who infamously claimed GE was on a path to financial collapse because of festering liabilities in a legacy insurance business. Neither forecast came true. The critical thing for 3M, Davis says, is improving cash flow so its liabilities seem less like an existential wrecking ball than an expense. It needs to improve to the point that “cash-flow growth is so strong that people say, ‘You know what? They’ve got the liabilities, and they can do buybacks and M&amp;amp;A, and operate as a real entity.’” The key for Honeywell and GE, he points out, was finding the right CEO to clean up their operations.&lt;/p&gt;
    &lt;p&gt;3M’s choice for that was Brown. Before signing on, he had a successful career overseeing defense contractor Harris Corp., now known as L3Harris Technologies Inc. after he shepherded a merger with L3 Technologies in 2019. Former colleagues say they thought that, after Brown stepped down in 2022, he might land a cushy private equity gig, not join a struggling conglomerate facing giant legal liabilities. Asked earlier this year at a JPMorgan Chase &amp;amp; Co. conference why he took the 3M job given the PFAS baggage, Brown joked that it wasn’t the -15F winter weather at headquarters in Minnesota. Rather, he said, PFAS had been so all-consuming for 3M that it had an opportunity to simply pay more attention to everything else—as long as the liabilities didn’t end up being worse than investors’ downtrodden expectations, then 3M’s stock price could climb much higher. It was, he added, “a great opportunity to engage with this great iconic company called 3M and try to help make it great again.”&lt;/p&gt;
    &lt;p&gt;Filings show that Brown is either 62 or 63 (the company declined to specify which). Known as an exercise fanatic, he’s trying to bring a comparable rigor of routine to 3M. The plan he’s revealed for fixing it isn’t all that complex. For starters, he cleared out much of the upper management under his predecessor, including replacing the chief financial officer, the head of investor relations and the top supply chain manager. Brown also lured in Amazon.com Inc. executive Wendy Bauer to take over 3M’s transportation and electronics division.&lt;/p&gt;
    &lt;p&gt;He’s vowed, too, to reboot 3M’s vaunted “innovation machine,” to cut costs and to drag the company’s manufacturing operations into the modern era, including making factories safer. “Our performance in safety has not been where we should be,” he said at the conference. “Our focus is around zero injuries, zero spills, zero incidents.”&lt;/p&gt;
    &lt;p&gt;Brown has also been pushing to improve how the company satisfies orders—when he took over, more than 10% of 3M deliveries were showing up late or incomplete—and how it makes each product in its sprawling portfolio. He’s suggested the company might reduce its 25,000-strong network of suppliers and eventually its empire of 110 factories, with its manufacturing equipment currently being used at only about 60% of capacity. Every week he and his top lieutenants review 3M’s business lines and factories, hunting for logjams and inefficiencies that cause deliveries to fall short of expectations.&lt;/p&gt;
    &lt;p&gt;Those who worked with Brown at L3Harris praise his leadership style. An engineer by training, he’s obsessed with pursuing excellence in all facets of a company’s operations, according to Jay Malave, a former L3Harris executive who was recently named Boeing Co.’s CFO. Rahul Ghai, CFO of GE Aerospace and a former Brown deputy himself, says, “What makes him successful is his tremendous attention to detail.” He adds: “This is the right guy for the job.” Both say that even though Brown can be demanding, he delivers marching orders with positivity.&lt;/p&gt;
    &lt;p&gt;At a Bank of America conference in May, Brown said 3M’s culture needs to encourage more individual accountability if his other improvements are to stick. When he joined the company, only about 10 people had performance-based stock compensation agreements. Now 1,500 people are paid this way. And everyone is being encouraged to act with urgency. The mantra, he said, is “Get it done tonight, not tomorrow. If it can be done in the next minute, do it in the next minute.”&lt;/p&gt;
    &lt;p&gt;Despite recent market volatility related to the global trade war started by Trump’s tariffs, 3M shares are still worth about 60% more than they were when Brown started last May. That’s more than double the gains for a broader group of industrial companies on the S&amp;amp;P 500 over that time period. But the stock is still down about 30% from its peak in early 2018, before the PFAS challenges came to a head.&lt;/p&gt;
    &lt;p&gt;Brown has been at pains to emphasize to investors that this turnaround isn’t going to be quick. Success would be resolving 3M’s legal cases without any jarring surprises, revving its innovation apparatus back up to the point that investors are convinced it can increase revenue, and improving the efficiency of its supply chain and manufacturing network.&lt;/p&gt;
    &lt;p&gt;In a testament to how hard that last challenge will be, Brown isn’t the first 3M CEO to cite the Command strip as an example of what needs to be fixed: George Buckley, who ran the company from 2005 to 2012, used to describe 3M’s disjointed assembly processes for the strip and other products as “hairballs.” At the time he started trying to untangle these knots, one part of the production process for Command hooks began with adhesives made at a 3M plant in Missouri, which were then shipped to Indiana to be applied to polyethylene foam. The foam then went to Minnesota, where the 3M logo was added and the strips were cut to size. Finally the tabs went to Wisconsin to be packaged along with a plastic hook. According to company executives interviewed by the Wall Street Journal in 2012, under Buckley’s oversight, 3M consolidated these particular steps in the Command strip production at one plant.&lt;/p&gt;
    &lt;p&gt;It was an improvement, sure, though it didn’t resolve the problem. Today, the end-to-end process still spans a handful of factories.&lt;/p&gt;
    &lt;p&gt;“You will never fix it, because that was how the company was built,” Obin says of 3M’s manufacturing labyrinth. But perhaps that’s OK. He points out that it wasn’t an issue during periods in the company’s history when revenue and profits were growing. “It just needs to be run properly.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45502748</guid><pubDate>Tue, 07 Oct 2025 13:22:04 +0000</pubDate></item><item><title>Tcl-Lang Showcase</title><link>https://wiki.tcl-lang.org/page/Showcase</link><description>&lt;doc fingerprint="598b77957e6a418d"&gt;
  &lt;main&gt;&lt;p&gt;Canvas3d&lt;/p&gt;Canvas3d wiki page&lt;p&gt;HP-15 Simulation&lt;/p&gt;HP-15 Simulation wiki page&lt;p&gt;By clicking on the image, an interactive demonstration of the Tcl/Tk application is launched using CloudTk. Over 100 Tcl/Tk applications listed from this wiki are demonstrated here . To view the Tcl/Tk Widget Demonstration, go to the "Playground" from the menu above and then select "Demos" in the "Tcl-Playground" - Console menu.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45502784</guid><pubDate>Tue, 07 Oct 2025 13:25:33 +0000</pubDate></item><item><title>No account? No Windows 11, Microsoft says as another loophole snaps shut</title><link>https://www.theregister.com/2025/10/07/windows_11_local_account_loophole/</link><description>&lt;doc fingerprint="3f986a36e76660d6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;No account? No Windows 11, Microsoft says as another loophole snaps shut&lt;/head&gt;
    &lt;head rend="h2"&gt;Workaround sent to the big OOBE in the sky with latest Insider builds&lt;/head&gt;
    &lt;p&gt;Microsoft is closing a popular loophole that allowed users to install Windows 11 without a Microsoft account.&lt;/p&gt;
    &lt;p&gt;The change has appeared in recent Insider builds of Windows 11, indicating it is likely to be included in the production version soon.&lt;/p&gt;
    &lt;p&gt;Microsoft refers to these loopholes as "known mechanisms" and is talking about local commands in this instance. You can learn all about these in our piece for getting Windows 11 installed with a local account, but suffice to say &lt;code&gt;start ms-cxh:localonly&lt;/code&gt; is no more.&lt;/p&gt;
    &lt;p&gt;"While these mechanisms were often used to bypass Microsoft account setup, they also inadvertently skip critical setup screens, potentially causing users to exit OOBE with a device that is not fully configured for use," Microsoft said.&lt;/p&gt;
    &lt;p&gt;"Users will need to complete OOBE with internet and a Microsoft account, to ensure [the] device is set up correctly."&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Windows 10 refuses to go gentle into that good night&lt;/item&gt;
      &lt;item&gt;Hundreds of orgs urge Microsoft: don't kill off free Windows 10 updates&lt;/item&gt;
      &lt;item&gt;Windows 11 25H2 is mostly 24H2 with bits bolted on or ripped out&lt;/item&gt;
      &lt;item&gt;Healthcare lags in Windows 11 upgrades – and lives may depend on it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As far as Redmond is concerned, this is all for the user's own good. It is also important to note that managed devices are not directly affected, just hardware that users want to get running with Windows 11 without having to deal with a Microsoft Account during setup.&lt;/p&gt;
    &lt;p&gt;The change is part of Microsoft's ongoing game of Whac-A-Mole with users trying to find ways of avoiding its online services. In March, it removed the &lt;code&gt;bypassnro.cmd&lt;/code&gt; script that allowed users to get through the Windows 11 setup without needing an internet connection. That time, Microsoft said the change was to "enhance security and user experience of Windows 11."&lt;/p&gt;
    &lt;p&gt;There remain a number of ways to avoid the Microsoft account requirement during setup, including setting up an unattended installation, but these are more complicated. It is also clear that Microsoft is determined to continue closing loopholes where it can.&lt;/p&gt;
    &lt;p&gt;It is getting increasingly difficult to use Windows 11 on an unmanaged device without a Microsoft account. Users who don't want to sign up should perhaps consider whether it's time to look at an alternative operating system instead. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45503726</guid><pubDate>Tue, 07 Oct 2025 14:45:54 +0000</pubDate></item><item><title>Swiss glaciers have shrunk by a quarter since 2015, study says</title><link>https://www.france24.com/en/live-news/20251001-swiss-glaciers-shrank-by-a-quarter-in-past-decade-study</link><description>&lt;doc fingerprint="3e43618bca203f15"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Swiss glaciers have shrunk by a quarter since 2015, study says&lt;/head&gt;
    &lt;p&gt;Switzerland’s glaciers have lost 24 percent of their volume over the past decade, researchers said Wednesday, warning that accelerated melting in 2025 brought ice loss close to record levels. Scientists warn that Switzerland’s glaciers could nearly vanish by the end of this century without stronger actions to counter global warming.&lt;/p&gt;
    &lt;p&gt;Switzerland's glaciers, which are disproportionately impacted by climate change, have lost a quarter of their volume in the past decade alone, a study warned Wednesday, heightening concerns over accelerating melting.&lt;/p&gt;
    &lt;p&gt;In 2025, glacial melting in the Alpine nation was once again "enormous", the Glacier Monitoring in Switzerland (GLAMOS) network said, adding that it was close to the record set in 2022.&lt;/p&gt;
    &lt;p&gt;A winter with little snow combined with summer heatwaves in June and August saw Switzerland's glaciers lose three percent of their volume.&lt;/p&gt;
    &lt;p&gt;That marks the fourth-largest level of shrinkage since measurements began, trailing only 2022, 2023 and 2003, according to GLAMOS's annual report.&lt;/p&gt;
    &lt;p&gt;Glaciers across the Alps have been retreating for more than a century.&lt;/p&gt;
    &lt;p&gt;But in recent decades, the process has sped up as the climate warms, driven by humanity's burning of fossil fuels.&lt;/p&gt;
    &lt;p&gt;"Since about 20 years, all glaciers in Switzerland are losing ice, and the rate of this loss is accelerating," GLAMOS chief Matthias Huss told AFP.&lt;/p&gt;
    &lt;p&gt;Between 2015 and 2025 alone, the glaciers shed 24 percent of their volume, Wednesday's report said, compared to 10 percent between 1990 and 2000.&lt;/p&gt;
    &lt;head rend="h2"&gt;Melting away&lt;/head&gt;
    &lt;p&gt;GLAMOS researchers did extensive measurements at around 20 reference glaciers in September, and extrapolated the findings to Switzerland's 1,400 glaciers.&lt;/p&gt;
    &lt;p&gt;Europe's Alpine region has been hard-hit by climate change, with warming in Switzerland progressing at twice the pace of the global average, according to the Swiss Federal Office of Meteorology and Climatology.&lt;/p&gt;
    &lt;p&gt;Other Alpine countries are also seeing glaciers retreat, and researchers highlight that those in Switzerland -- whose mountain peaks are higher than in neighbouring Austria -- may have a better chance of surviving the increasingly hot summers.&lt;/p&gt;
    &lt;p&gt;Even so, scientists warn that Switzerland's glaciers could all but disappear by the end of this century without more action to rein in global warming.&lt;/p&gt;
    &lt;p&gt;"We can't avoid the glacier melting overall," GLAMOS head Huss said, but "we can slow it down... with globally coordinated climate action".&lt;/p&gt;
    &lt;p&gt;If carbon dioxide emissions "are brought to zero within 30 years... we could still save about one-third of the Swiss glaciers", Huss added.&lt;/p&gt;
    &lt;p&gt;Since the early 1970s, more than 1,100 Swiss glaciers have disappeared completely, according to GLAMOS.&lt;/p&gt;
    &lt;head rend="h2"&gt;'Destabilising' mountains&lt;/head&gt;
    &lt;p&gt;Overlooking the Rhone Glacier, near Gletsch village, Huss said the giant ice mass had lost more than 100 metres (330 feet) in height in the last 20 years.&lt;/p&gt;
    &lt;p&gt;"It's really a devastation of the ice," he said.&lt;/p&gt;
    &lt;p&gt;Argentine tourist Wincho Ponte, 29, agreed.&lt;/p&gt;
    &lt;p&gt;It was "really sad that it's melting so quickly", Pointe said.&lt;/p&gt;
    &lt;p&gt;Water reserves have meanwhile been dwindling as the glaciers retreat, causing increasing problems in the summer months.&lt;/p&gt;
    &lt;p&gt;Huss cautioned that this could hit "water availability not only up here in the mountains but also all the way down to the Mediterranean Sea".&lt;/p&gt;
    &lt;p&gt;"The continuous diminishing of glaciers also contributes to the destabilising of mountains", he warned, pointing to the Swiss village of Blatten, which was wiped out by a dramatic glacier collapse in May.&lt;/p&gt;
    &lt;p&gt;GLAMOS determined that Swiss glacier volume will total 45.1 cubic kilometres (10.8 cubic miles) at the end of this year -- or 30 km3 less than in 2000.&lt;/p&gt;
    &lt;p&gt;At present, the surface area of Swiss glaciers covers 755 square kilometres -- a decline of 30 percent over the past 25 years.&lt;/p&gt;
    &lt;p&gt;This year, Switzerland's second-hottest June on record contributed to snow melting rapidly, even at the highest altitudes.&lt;/p&gt;
    &lt;p&gt;August brought a fresh heatwave, pushing the freezing line as high as 5,000 metres above sea level -- well above the peak of western Europe's highest mountain, Mont Blanc.&lt;/p&gt;
    &lt;p&gt;Only a rather cool and damp July "provided some relief and prevented an even worse outcome", GLAMOS said, with a few cold fronts resulting in individual days with fresh snow at higher altitudes.&lt;/p&gt;
    &lt;p&gt;The overall summer melt this year was therefore only 15 percent above the 2010-2020 average -- its lowest level in the past four years.&lt;/p&gt;
    &lt;p&gt;(FRANCE 24 with AFP)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45503882</guid><pubDate>Tue, 07 Oct 2025 14:56:09 +0000</pubDate></item><item><title>Launch HN: LlamaFarm (YC W22) – Open-source framework for distributed AI</title><link>https://github.com/llama-farm/llamafarm</link><description>&lt;doc fingerprint="ed1fa4511bbd11f2"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Build powerful AI locally, extend anywhere.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;LlamaFarm is an open-source framework for building retrieval-augmented and agentic AI applications. It ships with opinionated defaults (Ollama for local models, Chroma for vector storage) while staying 100% extendable—swap in vLLM, remote OpenAI-compatible hosts, new parsers, or custom stores without rewriting your app.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local-first developer experience with a single CLI (&lt;code&gt;lf&lt;/code&gt;) that manages projects, datasets, and chat sessions.&lt;/item&gt;
      &lt;item&gt;Production-ready architecture that mirrors server endpoints and enforces schema-based configuration.&lt;/item&gt;
      &lt;item&gt;Composable RAG pipelines you can tailor through YAML, not bespoke code.&lt;/item&gt;
      &lt;item&gt;Extendable everything: runtimes, embedders, databases, extractors, and CLI tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;📺 Video demo (90 seconds): https://youtu.be/W7MHGyN0MdQ&lt;/p&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Install the CLI&lt;/p&gt;
        &lt;p&gt;macOS / Linux&lt;/p&gt;
        &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/llama-farm/llamafarm/main/install.sh | bash&lt;/code&gt;
        &lt;p&gt;Windows (via winget)&lt;/p&gt;
        &lt;code&gt;winget install LlamaFarm.CLI&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Adjust Ollama context window&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Open the Ollama app, go to Settings → Advanced, and set the context window to match production (e.g., 100K tokens).&lt;/item&gt;
          &lt;item&gt;Larger context windows improve RAG answers when long documents are ingested.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create and run a project&lt;/p&gt;
        &lt;quote&gt;lf init my-project # Generates llamafarm.yaml using the server template lf start # Spins up Docker services &amp;amp; opens the dev chat UI&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start an interactive project chat or send a one-off message&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Interactive project chat (auto-detects namespace/project from llamafarm.yaml)
lf chat

# One-off message
lf chat "Hello, LlamaFarm!"&lt;/code&gt;
    &lt;p&gt;Need the full walkthrough with dataset ingestion and troubleshooting tips? Jump to the Quickstart guide.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Prefer building from source? Clone the repo and follow the steps in Development &amp;amp; Testing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Run services manually (without Docker auto-start):&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/llama-farm/llamafarm.git
cd llamafarm

# Install Nx globally and bootstrap the workspace
npm install -g nx
nx init --useDotNxInstallation --interactive=false

# Option 1: start both server and RAG worker with one command
nx dev

# Option 2: start services in separate terminals
# Terminal 1
nx start rag
# Terminal 2
nx start server&lt;/code&gt;
    &lt;p&gt;Open another terminal to run &lt;code&gt;lf&lt;/code&gt; commands (installed or built from source). This is equivalent to what &lt;code&gt;lf start&lt;/code&gt; orchestrates automatically.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Own your stack – Run small local models today and swap to hosted vLLM, Together, or custom APIs tomorrow by changing &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Battle-tested RAG – Configure parsers, extractors, embedding strategies, and databases without touching orchestration code.&lt;/item&gt;
      &lt;item&gt;Config over code – Every project is defined by YAML schemas that are validated at runtime and easy to version control.&lt;/item&gt;
      &lt;item&gt;Friendly CLI – &lt;code&gt;lf&lt;/code&gt;handles project bootstrapping, dataset lifecycle, RAG queries, and non-interactive chats.&lt;/item&gt;
      &lt;item&gt;Built to extend – Add a new provider or vector store by registering a backend and regenerating schema types.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Task&lt;/cell&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Initialize a project&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf init my-project&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Creates &lt;code&gt;llamafarm.yaml&lt;/code&gt; from server template.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Start dev stack + chat TUI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf start&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Spins up server, rag worker, monitors Ollama/vLLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Interactive project chat&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Opens TUI using project from &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Send single prompt&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat "Explain retrieval augmented generation"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Uses RAG by default; add &lt;code&gt;--no-rag&lt;/code&gt; for pure LLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Preview REST call&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat --curl "What models are configured?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Prints sanitized &lt;code&gt;curl&lt;/code&gt; command.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Create dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets create -s pdf_ingest -b main_db research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Validates strategy/database against project config.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Upload files&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets upload research-notes ./docs/*.pdf&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Supports globs and directories.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Process dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets process research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Streams heartbeat dots during long processing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Semantic query&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf rag query --database main_db "What did the 2024 FDA letters require?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Use &lt;code&gt;--filter&lt;/code&gt;, &lt;code&gt;--include-metadata&lt;/code&gt;, etc.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See the CLI reference for full command details and troubleshooting advice.&lt;/p&gt;
    &lt;p&gt;LlamaFarm provides a comprehensive REST API (compatible with OpenAI's format) for integrating with your applications. The API runs at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Chat Completions (OpenAI-compatible)&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "What are the FDA requirements?"}
    ],
    "stream": false,
    "rag_enabled": true,
    "database": "main_db"
  }'&lt;/code&gt;
    &lt;p&gt;RAG Query&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "clinical trial requirements",
    "database": "main_db",
    "top_k": 5
  }'&lt;/code&gt;
    &lt;p&gt;Dataset Management&lt;/p&gt;
    &lt;code&gt;# Upload file
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/data \
  -F "file=@document.pdf"

# Process dataset
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/process&lt;/code&gt;
    &lt;p&gt;Check your &lt;code&gt;llamafarm.yaml&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;name: my-project        # Your project name
namespace: my-org       # Your namespace&lt;/code&gt;
    &lt;p&gt;Or inspect the file system: &lt;code&gt;~/.llamafarm/projects/{namespace}/{project}/&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;See the complete API Reference for all endpoints, request/response formats, Python/TypeScript clients, and examples.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;llamafarm.yaml&lt;/code&gt; is the source of truth for each project. The schema enforces required fields and documents every extension point.&lt;/p&gt;
    &lt;code&gt;version: v1
name: fda-assistant
namespace: default

runtime:
  provider: openai                   # "openai" for any OpenAI-compatible host, "ollama" for local Ollama
  model: qwen2.5:7b
  base_url: http://localhost:8000/v1 # Point to vLLM, Together, etc.
  api_key: sk-local-placeholder
  instructor_mode: tools             # Optional: json, md_json, tools, etc.

prompts:
  - role: system
    content: &amp;gt;-
      You are an FDA specialist. Answer using short paragraphs and cite document titles when available.

rag:
  databases:
    - name: main_db
      type: ChromaStore
      default_embedding_strategy: default_embeddings
      default_retrieval_strategy: filtered_search
      embedding_strategies:
        - name: default_embeddings
          type: OllamaEmbedder
          config:
            model: nomic-embed-text:latest
      retrieval_strategies:
        - name: filtered_search
          type: MetadataFilteredStrategy
          config:
            top_k: 5
  data_processing_strategies:
    - name: pdf_ingest
      parsers:
        - type: PDFParser_LlamaIndex
          config:
            chunk_size: 1500
            chunk_overlap: 200
      extractors:
        - type: HeadingExtractor
        - type: ContentStatisticsExtractor

datasets:
  - name: research-notes
    data_processing_strategy: pdf_ingest
    database: main_db&lt;/code&gt;
    &lt;p&gt;Configuration reference: Configuration Guide • Extending LlamaFarm&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swap runtimes by pointing to any OpenAI-compatible endpoint (vLLM, Mistral, Anyscale). Update &lt;code&gt;runtime.provider&lt;/code&gt;,&lt;code&gt;base_url&lt;/code&gt;, and&lt;code&gt;api_key&lt;/code&gt;; regenerate schema types if you add a new provider enum.&lt;/item&gt;
      &lt;item&gt;Bring your own vector store by implementing a store backend, adding it to &lt;code&gt;rag/schema.yaml&lt;/code&gt;, and updating the server service registry.&lt;/item&gt;
      &lt;item&gt;Add parsers/extractors to support new file formats or metadata pipelines. Register implementations and extend the schema definitions.&lt;/item&gt;
      &lt;item&gt;Extend the CLI with new Cobra commands under &lt;code&gt;cli/cmd&lt;/code&gt;; the docs include guidance on adding dataset utilities or project tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check the Extending guide for step-by-step instructions.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
        &lt;cell role="head"&gt;What it Shows&lt;/cell&gt;
        &lt;cell role="head"&gt;Location&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FDA Letters Assistant&lt;/cell&gt;
        &lt;cell&gt;Multi-document PDF ingestion, RAG queries, reference-style prompts&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/fda_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Raleigh UDO Planning Helper&lt;/cell&gt;
        &lt;cell&gt;Large ordinance ingestion, long-running processing tips, geospatial queries&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/gov_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;lf datasets&lt;/code&gt; and &lt;code&gt;lf rag query&lt;/code&gt; commands from each example folder to reproduce the flows demonstrated in the docs.&lt;/p&gt;
    &lt;code&gt;# Python server + RAG tests
cd server
uv sync
uv run --group test python -m pytest

# CLI tests
cd ../cli
go test ./...

# RAG tooling smoke tests
cd ../rag
uv sync
uv run python cli.py test

# Docs build (ensures navigation/link integrity)
cd ..
nx build docs&lt;/code&gt;
    &lt;p&gt;Linting: &lt;code&gt;uv run ruff check --fix .&lt;/code&gt; (Python), &lt;code&gt;go fmt ./...&lt;/code&gt; and &lt;code&gt;go vet ./...&lt;/code&gt; (Go).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord – chat with the team, share feedback, find collaborators.&lt;/item&gt;
      &lt;item&gt;GitHub Issues – bug reports and feature requests.&lt;/item&gt;
      &lt;item&gt;Discussions – ideas, RFCs, roadmap proposals.&lt;/item&gt;
      &lt;item&gt;Contributing Guide – code style, testing expectations, doc updates, schema regeneration steps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Want to add a new provider, parser, or example? Start a discussion or open a draft PR—we love extensions!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Licensed under the Apache 2.0 License.&lt;/item&gt;
      &lt;item&gt;Built by the LlamaFarm community and inspired by the broader open-source AI ecosystem. See CREDITS for detailed acknowledgments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build locally. Deploy anywhere. Own your AI.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504388</guid><pubDate>Tue, 07 Oct 2025 15:30:20 +0000</pubDate></item><item><title>IKEA Catalogs 1951-2021</title><link>https://ikeamuseum.com/en/explore/ikea-catalogue/</link><description>&lt;doc fingerprint="71c3125f48ed4455"&gt;
  &lt;main&gt;
    &lt;p&gt;Good question! We know that a lot of people are curious about what the IKEA catalogue has looked like through the ages. The catalogue has always reflected the age and its views on interior design and everyday living, especially in Sweden, but in recent decades also internationally. The catalogue was in print for 70 years, and by digitising all the catalogues we could make them available to everybody. Making the story of IKEA available to as many people as possible is our main task at IKEA Museum. So we hope that the catalogues will bring some joy and nostalgia, and maybe even a few surprises.&lt;/p&gt;
    &lt;head rend="h1"&gt;IKEA catalogue&lt;/head&gt;
    &lt;p&gt;For over 70 years, the IKEA catalogue was produced in Ãlmhult, constantly growing in number, scope and distribution. From the 1950s when Ingvar Kamprad wrote most of the texts himself, via the poppy, somewhat radical 1970s and all the way into the scaled-down 2000s â the IKEA catalogue always captured the spirit of the time. The 2021 IKEA catalogue was the very last one printed on paper.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1950s&lt;/item&gt;
      &lt;item&gt;1960s&lt;/item&gt;
      &lt;item&gt;1970s&lt;/item&gt;
      &lt;item&gt;1980s&lt;/item&gt;
      &lt;item&gt;1990s&lt;/item&gt;
      &lt;item&gt;2000s&lt;/item&gt;
      &lt;item&gt;2010s&lt;/item&gt;
      &lt;item&gt;2020s&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Just like the perception of the home, the catalogue has changed dramatically since 1951, when it was first published. Look in the older catalogues and youâll be amazed at what you find. In fact, youâll probably even have a giggle or two. In the 1950s and 1960s, there are rarely any people in the pictures, and never any children. But in the 1970s there are children playing all over the home, you can see adults smoking and even the occasional political poster on the wall. Browse on to the 1980s IKEA catalogues and the trends have changed again, with shiny fabrics and other fancy materials. In the 1990s homes become more scaled-down and clearly inspired by a Scandinavian tradition. In this way, the IKEA catalogues are a kind of time capsule for you to travel in. And who knows? When we look back at the most recent catalogues in 10 or 20 yearsâ time, weâll probably shake our heads and give a sigh.&lt;/p&gt;
    &lt;p&gt;IKEA Museum decided to start with the Swedish catalogue as it has been around the longest. In the future, we hope to be able to digitise catalogues from more countries in more languages.&lt;/p&gt;
    &lt;p&gt;No. The IKEA catalogue has always only shown a selection of whatâs available in the stores. The catalogues from the 1970s and onwards show around 30â50 per cent of the entire range. The products that are not featured are generally smaller ones in textiles, decorations and lighting. Temporary collections are rarely included either. But the farther back you go, the higher a percentage of the range can be found in the catalogue.&lt;/p&gt;
    &lt;p&gt;Yes, but the older a product is, the harder it may be to find information about it. If you have a specific question about a product, weâre happy to help you out if we can. But 70 years is a long time, so we canât promise anything. While youâre waiting for our response you can always browse through the catalogues â the product texts that are there are quite detailed. You can search in the catalogues by product name and product type. There are also various stories about different products on our site, and more are constantly being added.&lt;lb/&gt; Browse through stories about IKEA products from 7 decades. &lt;/p&gt;
    &lt;p&gt;IKEA was founded in the 1940s, so why are you showing no catalogues from before 1951?&lt;lb/&gt; The first catalogue did not come out until 1951. Before that, IKEA was a mail order company that didnât sell furniture, but pens, clocks, electric razors, wallets and bags. At that time, the range was only presented in a small mail order brochure called ikÃ©a-nytt (literally ikÃ©a news). Sometimes it was distributed as a supplement in farming paper Jordbrukarnas FÃ¶reningsblad, which reached hundreds of thousands of people in the Swedish countryside. From autumn 1948 Ingvar Kamprad started including furniture in the range, and things quickly grew from there. In the 1950 ikÃ©a-nytt, as many as six of the 18 pages featured furniture. And when you look at the 1951 catalogue, youâll see that there are no more pens and wallets. Ingvar Kamprad was now truly focusing on home furnishing, and shelving the rest.&lt;lb/&gt; Browse through all issues of ikÃ©a-nytt.&lt;/p&gt;
    &lt;p&gt;Not really. We do have a few copies of each yearâs IKEA catalogue in our archives, which weâre saving for posterity. They should be handled as little as possible to keep them in good condition, so weâve made the catalogues available digitally, both online and on monitors at IKEA Museum. You can browse through those as much as you like!&lt;/p&gt;
    &lt;p&gt;Yes you can. The easiest way to share the catalogues is to click on the arrow at the bottom left corner for each catalogue, or in the left-hand menu once youâve started browsing through. This will copy a link which you can share on a website or social media. If you would like to download and publish on your own digital platform, you can share a maximum of three complete digital catalogues. Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more. You may not publish the digital catalogues for commercial purposes.&lt;/p&gt;
    &lt;p&gt;Absolutely! You can share up to 30 images from the catalogues on your own digital platform, such as a blog, on Instagram or similar (as long as itâs not for commercial purposes). Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more.&lt;/p&gt;
    &lt;p&gt;Yes! You can find all press material, including images, information about current exhibitions and much more, in the IKEA Museum press room.&lt;/p&gt;
    &lt;p&gt;At the moment we have a good amount of catalogues in all languages at the museum, and do not need any more. Having said that, please contact us anyway if youâve been collecting catalogues for several decades, or if you have any other material you think might be of interest to IKEA Museum.&lt;/p&gt;
    &lt;p&gt;Unfortunately not. We sometimes wish we did, as we handle quite a lot of old products that may need putting together and taking apart.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504470</guid><pubDate>Tue, 07 Oct 2025 15:35:48 +0000</pubDate></item><item><title>Show HN: Timelinize – Privately organize your own data from everywhere, locally</title><link>https://timelinize.com</link><description>&lt;doc fingerprint="e64842e6eda1dcc1"&gt;
  &lt;main&gt;
    &lt;p&gt;Timelinize ("time-lynn-eyes") is an open source personal archival suite, designed for modern family history. It organizes all your data onto a single, unified timeline on your own computer.&lt;/p&gt;
    &lt;p&gt;Photos, videos, text messages, locations, chats, social media, and more. Timelinize unifies it all.&lt;/p&gt;
    &lt;p&gt;By adding all your data, Timelinize documents your family's life with more detail and privacy, and gives you a more complete view of your story, than standard photo library and journaling apps.&lt;/p&gt;
    &lt;p&gt;Most apps store your data "in the cloud" and out of your control. What if you lost access to your Google/Apple/Facebook accounts, or your phone? By bringing that data home to your own computer, Timelinize preserves a richer story than any one app or service can do alone.&lt;/p&gt;
    &lt;p&gt;Timelinize isn't a replacement for the apps and services you already use, so you don't need to disrupt your way of life. Instead, it "sits behind" what you already use to become the permanent private archive of your working copy from:&lt;/p&gt;
    &lt;p&gt;With several projections for your data, it's easy to keep moments alive that would otherwise be forgotten, rotting on a hard drive in your closet... or in a bigcorp's cloud.&lt;/p&gt;
    &lt;p&gt;The timeline view semantically groups all your data into a single linear layout. Easily see what occurred on a specific day in the order it happened.&lt;/p&gt;
    &lt;p&gt;Visualize your data on a huge, beautiful map of the world that plots points when and where they happened, even for data that doesn't have coordinates (like text messages and emails).&lt;/p&gt;
    &lt;p&gt;Follow connections with people across all kinds of chats and messages. Combine conversations with people across platforms into one view.&lt;/p&gt;
    &lt;p&gt;Browse through a rich display of photos and videos from photo libraries, messages sent and received, and other sources.&lt;/p&gt;
    &lt;p&gt;Add millions of data points to your timeline in a matter of minutes. You get full control over background jobs like imports, thumbnails, and embeddings.&lt;/p&gt;
    &lt;p&gt;Timelinize supports playing "live photos" (or "motion photos") for photos taken on Apple, Google, and Samsung devices.&lt;/p&gt;
    &lt;p&gt;Timelinize specializes in combining data from multiple sets and sources. It can identify people and other entities across data sources by their attributes. If a person or contact appears in multiple data sets, it will automatically merge them if possible. If not, you can easily merge entities with the click of a button.&lt;/p&gt;
    &lt;p&gt;Because Timelinize is entity-aware, it can project data points onto a map even without coordinate data. If a geolocated point is known for an entity around the same time of others of that entity's data points, it will appear on the map.&lt;/p&gt;
    &lt;p&gt;Customize the map to change its theme, layers, and even make it 3D.&lt;/p&gt;
    &lt;p&gt;The heatmap shows where your data is concentrated. It smoothly blends as you zoom in and out.&lt;/p&gt;
    &lt;p&gt;Customize what defines a duplicate item, and how to handle that, with a fine degree of control—perfect for merging separate, disparate data sets.&lt;/p&gt;
    &lt;p&gt;An implicit conversation is discovered when a data source links items and entities with a "sent to" relation. You can easily view conversations between entities across modalities in a single scroll: chats, emails, messages, texts, and more.&lt;/p&gt;
    &lt;p&gt;Since I need this to function well for my own family, I have tried to give special attention to less-visible aspects of this application, such as:&lt;/p&gt;
    &lt;p&gt;Timelinize deduplicates, denoises, clusters, and simplifies location data for optimal preservation, with an algorithm that subjectively performs better than Google Maps Timeline.&lt;/p&gt;
    &lt;p&gt;For nerds like me: you can use Timelinize through its CLI, which mirrors all the functions of the HTTP API used by the frontend.&lt;/p&gt;
    &lt;p&gt;Search for pictures and messages by describing them, or find similar items to what you're viewing.&lt;/p&gt;
    &lt;p&gt;All items are stored verbatim, then thumbnails are generated for all images and video media, which are stored separately. Your original data is not modified.&lt;/p&gt;
    &lt;p&gt;The database schema has been meticulously designed and refined to be as adaptable as possible.&lt;/p&gt;
    &lt;p&gt;Timelinize will continue to develop and evolve. In the future, I anticipate the following capabilities:&lt;/p&gt;
    &lt;p&gt;Annotate your timeline, write rich stories with live embeddings from your timeline data, or make physical media like photo books (but with more than just photos!).&lt;/p&gt;
    &lt;p&gt;Add context to your timeline with additional public timelines which have weather, local/regional news, and global events.&lt;/p&gt;
    &lt;p&gt;Securely and privately share parts of your timeline with trusted friends and family members, directly from your computer to theirs.&lt;/p&gt;
    &lt;p&gt;Right now, Timelinize sits "behind" the apps and platforms you already use. But in the future, you could sync data directly to your timeline as it is originated.&lt;/p&gt;
    &lt;p&gt;Collect your data from various sources. Import it with a few clicks. Within minutes, explore millions of your data points in several intuitive ways.&lt;/p&gt;
    &lt;p&gt;Imported data is copied into your timeline folder, ensuring long-term stability and integrity. Timelines are portable—you can copy them or move them to other devices and computers.&lt;/p&gt;
    &lt;p&gt;Your timeline is simply a folder on disk containing a SQLite database alongside your data files. You can freely explore it with other tooling, so you're not locked into Timelinize.&lt;/p&gt;
    &lt;p&gt;Unlike writing a journal, you don't have to take extra time to create content. You're already making the data your timeline can display! And it doesn't replace your current workflow or apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45504973</guid><pubDate>Tue, 07 Oct 2025 16:10:22 +0000</pubDate></item><item><title>Police Said They Surveilled Woman Who Had an Abortion for Her 'Safety.'</title><link>https://www.404media.co/police-said-they-surveilled-woman-who-had-an-abortion-for-her-safety-court-records-show-they-considered-charging-her-with-a-crime/</link><description>&lt;doc fingerprint="3de23113b1ea22e1"&gt;
  &lt;main&gt;&lt;p&gt;In May, 404 Media reported that the Johnson County Sheriff’s Office in Texas searched a nationwide network of Flock cameras, a powerful AI-enabled license plate surveillance tool, to look for a woman who self-administered an abortion. At the time, the sheriff told us that the search had nothing to do with criminality and that they were concerned solely about the woman’s safety, specifically the idea that she could be bleeding to death from the abortion. Flock itself said “she was never under criminal investigation by Johnson County. She was being searched for as a missing person, not as a suspect of a crime.”&lt;/p&gt;&lt;head rend="h2"&gt;This post is for paid members only&lt;/head&gt;&lt;p&gt;Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.&lt;/p&gt; Subscribe &lt;head rend="h2"&gt;Sign up for free access to this post&lt;/head&gt;&lt;p&gt;Free members get access to posts like this one along with an email round-up of our week's stories.&lt;/p&gt; Subscribe &lt;p&gt;Already have an account? Sign in&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505103</guid><pubDate>Tue, 07 Oct 2025 16:18:48 +0000</pubDate></item><item><title>Cache-Friendly B+Tree Nodes with Dynamic Fanout</title><link>https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/</link><description>&lt;doc fingerprint="eafbc81bf4b08ea8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Cache-Friendly B+Tree Nodes With Dynamic Fanout&lt;/head&gt;&lt;p&gt;For a high-performance B+Tree, the memory layout of each node must be a single contiguous block. This improves locality of reference, increasing the likelihood that the node's contents reside in the CPU cache.&lt;/p&gt;&lt;p&gt;In C++, achieving this means forgoing the use of &lt;code&gt;std::vector&lt;/code&gt;, as it introduces a layer of indirection through a separate memory allocation. The solution to this problem though inevitably increases the implementation complexity and is mired with hidden drawbacks. Nevertheless, this is still a necessary trade-off for unlocking high performance.&lt;/p&gt;&lt;code&gt;  +----------------------+&lt;/code&gt;&lt;head rend="h2"&gt;Challenges&lt;/head&gt;&lt;p&gt;Using &lt;code&gt;std::vector&lt;/code&gt; for a B+Tree node's entries is a non-starter. A &lt;code&gt;std::vector&lt;/code&gt; object holds a pointer to its entries which are stored in a separate block of memory on the heap. This indirection fragments the memory layout, forcing us to fall back on C-style arrays for a contiguous layout when storing variable-length node entries.&lt;/p&gt;&lt;p&gt;This leads to a dilemma. The size of the array must be known at compilation time, yet we need to allow users to configure the fanout (the array's size) at runtime. Furthermore, the implementation should allow inner nodes and leaf nodes to have different fanouts.&lt;/p&gt;&lt;p&gt;This isn't just a B+Tree problem. It is a common challenge in systems programming whenever an object needs to contain a variable-length payload whose size is only known at runtime. How can you define a class that occupies a single block of memory when a part of the block has a dynamic size?&lt;/p&gt;&lt;p&gt;The solution isn't obvious, but it's a well-known trick that systems programmers have used for decades, a technique so common it has eventually been standardized in C99.&lt;/p&gt;&lt;head rend="h2"&gt;The Struct Hack&lt;/head&gt;&lt;p&gt;The solution to this problem is a technique originating in C programming known as the struct hack. The variable-length member (array) is placed at the last position in the struct. To satisfy the compiler an array size of one is hard-coded, ensuring the array size is known at compilation time.&lt;/p&gt;&lt;code&gt;struct Payload {&lt;/code&gt;&lt;p&gt;At runtime, when the required size &lt;code&gt;N&lt;/code&gt; is known, you allocate a single block of memory for the struct and the &lt;code&gt;N&lt;/code&gt; elements combined. The compiler treats this as an opaque block, and provides no safety guarantees. However, accessing the extra allocated space is safe because the variable-length member is the final field in the struct.&lt;/p&gt;&lt;code&gt;// The (N - 1) adjusts for the 1-element array in Payload struct&lt;/code&gt;&lt;p&gt;This pattern was officially standardized in C99, where it is known as a flexible array member.&lt;/p&gt;&lt;p&gt;The C++11 standard formally incorporates the flexible array member, referring to it as an array of unknown bound when it is the last member of a struct.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Arrays of unknown bound&lt;/p&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;expr&lt;/code&gt;is omitted in the declaration of an array, the type declared is "array of unknown bound of T", which is a kind of incomplete type, ...&lt;code&gt;extern int x[]; // the type of x is "array of unknown bound of int"&lt;/code&gt;&lt;lb/&gt;int a[] = {1, 2, 3}; // the type of a is "array of 3 int"&lt;/quote&gt;&lt;p&gt;This means that in C++, the size can be omitted from the final array declaration (e.g. &lt;code&gt;entries_[]&lt;/code&gt;), and the code will compile, enabling the same pattern.&lt;/p&gt;&lt;head rend="h2"&gt;B+Tree Node Declaration&lt;/head&gt;&lt;p&gt;Using the flexible array member syntax, we can now declare a B+Tree node with a memory layout which is a contiguous single block in the heap.&lt;/p&gt;&lt;code&gt;template &amp;lt;typename KeyType, typename ValueType&amp;gt;&lt;/code&gt;&lt;p&gt;Using a &lt;code&gt;std::vector&amp;lt;KeyValuePair&amp;gt;&lt;/code&gt; for the node's entries would result in an indirection. This immediately fragments the memory layout. Accessing an entry within a node is slower, and has higher latency because of the pointer indirection. Chasing the pointer increases the probability of a cache miss, which will force the CPU to stall while it waits for the cache line to be fetched from a different region in main memory.&lt;/p&gt;&lt;p&gt;A cache miss will cost hundreds of CPU cycles compared to just a few cycles for a cache hit. This cumulative latency is unacceptable for any high-performance data structure.&lt;/p&gt;&lt;p&gt;This technique avoids the pointer indirection and provides fine-grained control over memory layout. The node header and data are co-located in one continuous memory block. This layout is cache-friendly and will result in fewer cache misses.&lt;/p&gt;&lt;head rend="h2"&gt;Raw Memory Buffer&lt;/head&gt;&lt;p&gt;This is the key step. The construction of the object has to be separate from its memory allocation. We cannot therefore use the standard &lt;code&gt;new&lt;/code&gt; syntax which will attempt to allocate storage, and then initialize the object in the same storage.&lt;/p&gt;&lt;p&gt;Instead, we use the placement new syntax which only constructs an object in a preallocated memory buffer provided by us. We know exactly how much space to allocate, which is information the standard &lt;code&gt;new&lt;/code&gt; operator does not have in this scenario because of the flexible array member.&lt;/p&gt;&lt;code&gt;// A static helper to allocate storage for a B+Tree node.&lt;/code&gt;&lt;p&gt;The result is a cache-friendly B+Tree node with a fanout that can be configured at runtime.&lt;/p&gt;&lt;head rend="h2"&gt;The Price Of Fine-Grained Control&lt;/head&gt;&lt;p&gt;To create an instance of a B+Tree node with a fanout of &lt;code&gt;256&lt;/code&gt;, it is not possible to write simple idiomatic code like this: &lt;code&gt;new BPlusTreeNode(256)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Instead we use the custom &lt;code&gt;BPlusTreeNode::Get&lt;/code&gt; helper which knows how much raw memory to allocate for the object including the data section.&lt;/p&gt;&lt;code&gt;BPlusTreeNode *root = BPlusTreeNode&amp;lt;KeyValuePair&amp;gt;::Get(256);&lt;/code&gt;&lt;head rend="h3"&gt;Manual Handling Of Deallocation&lt;/head&gt;&lt;p&gt;The destructor code is also not idiomatic anymore. When the lifetime of the B+Tree node ends, the deallocation code has to be carefully crafted to avoid resource or memory leaks.&lt;/p&gt;&lt;code&gt;class BPlusTreeNode {&lt;/code&gt;&lt;p&gt;This carefully ordered cleanup is necessary because we took manual control of memory. The process is the mirror opposite of our &lt;code&gt;Get&lt;/code&gt; function. We constructed the object outside in: raw memory buffer -&amp;gt; node object -&amp;gt; individual elements. So we teardown in the opposite direction, from the inside out: individual elements -&amp;gt; node object -&amp;gt; raw memory buffer.&lt;/p&gt;&lt;head rend="h3"&gt;Adding New Members In A Derived Class&lt;/head&gt;&lt;p&gt;Adding a new member to a derived class will result in data corruption. It is not possible to add new fields to a specialized &lt;code&gt;InnerNode&lt;/code&gt; or &lt;code&gt;LeafNode&lt;/code&gt; class.&lt;/p&gt;&lt;code&gt;+----------------------+&lt;/code&gt;&lt;code&gt;entries_&lt;/code&gt; array in memory.&lt;p&gt;The raw memory we manually allocated is opaque to the compiler and it cannot safely reason about where the newly added members to the derived class are physically located. The end result is it will overwrite the data buffer and cause data corruption.&lt;/p&gt;&lt;p&gt;The workaround is to break encapsulation and add derived members to the base class so that the flexible array member is always in the last position. This is a significant drawback when we begin using flexible array members.&lt;/p&gt;&lt;code&gt;+----------------------+&lt;/code&gt;
&lt;code&gt;InnerNode&lt;/code&gt; and &lt;code&gt;LeafNode&lt;/code&gt; implementations.&lt;head rend="h3"&gt;Reinventing The Wheel&lt;/head&gt;&lt;p&gt;By using a raw C-style array, we effectively reinvent parts of &lt;code&gt;std::vector&lt;/code&gt;, implementing our own utilities for insertion, deletion and iteration. This not only raises the complexity and maintenance burden but also means we are responsible for ensuring our custom implementation is as performant as the highly-optimized standard library version.&lt;/p&gt;&lt;p&gt;The engineering cost to make this implementation production-grade is significant.&lt;/p&gt;&lt;head rend="h3"&gt;Hidden Data Type Assumptions&lt;/head&gt;&lt;p&gt;The &lt;code&gt;BPlusTreeNode&lt;/code&gt;'s generic signature implies it will work for any &lt;code&gt;KeyType&lt;/code&gt; or &lt;code&gt;ValueType&lt;/code&gt;, but this is dangerously misleading. Using a non-trivial type like &lt;code&gt;std::string&lt;/code&gt; will cause undefined behavior.&lt;/p&gt;&lt;code&gt;template &amp;lt;typename KeyType, typename ValueType&amp;gt;&lt;/code&gt;
&lt;p&gt;To understand why, let's look at how entries are inserted. To make space for a new element, existing entries must be shifted to the right. With our low-level memory layout, this is done using bitwise copy, as the following implementation shows.&lt;/p&gt;&lt;code&gt;bool Insert(const KeyValuePair &amp;amp;element, KeyValuePair *pos) {&lt;/code&gt;
&lt;p&gt;The use of &lt;code&gt;std::memmove&lt;/code&gt; introduces a hidden constraint: &lt;code&gt;KeyValuePair&lt;/code&gt; must be trivially copyable. This means the implementation only works correctly for simple, C-style data structures despite its generic-looking interface.&lt;/p&gt;&lt;p&gt;Using &lt;code&gt;std::memmove&lt;/code&gt; on a &lt;code&gt;std::string&lt;/code&gt; object creates a shallow copy. We now have two &lt;code&gt;std::string&lt;/code&gt; objects whose internal pointers both point to the same character buffer on the heap. When the destructor of the original string is eventually called, it deallocates that buffer. The copied string is now left with a dangling pointer to freed memory, leading to use-after-free errors or a double-free crash when its own destructor runs.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;The initial hurdle when implementing a B+Tree implementation is solving the contiguous memory layout puzzle avoiding heap indirection. The solution is flexible array members, which makes it possible to compile the program when the number of entries in the B+Tree node is dynamic, and a runtime value.&lt;/p&gt;&lt;p&gt;However, the implementation complexity goes up because of manual memory management, lack of inheritance, and hidden data type constraints. This is unavoidable for high performance.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505398</guid><pubDate>Tue, 07 Oct 2025 16:39:13 +0000</pubDate></item><item><title>Robin Williams' daughter pleads for people to stop sending AI videos of her dad</title><link>https://www.bbc.co.uk/news/articles/c0r0erqk18jo</link><description>&lt;doc fingerprint="97d23aa93261cd6d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Robin Williams' daughter pleads for people to stop sending AI videos of her dad&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Published&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Zelda Williams, the daughter of Robin Williams, has asked people to stop sending her AI-generated videos of her father, the celebrated US actor and comic who died in 2014.&lt;/p&gt;
    &lt;p&gt;"Please, just stop sending me AI videos of Dad," Zelda Williams posted on her Instagram stories.&lt;/p&gt;
    &lt;p&gt;"Stop believing I wanna see it or that I'll understand, I don't and I won't. If you're just trying to troll me, I've seen way worse, I'll restrict and move on.&lt;/p&gt;
    &lt;p&gt;"But please, if you've got any decency, just stop doing this to him and to me, to everyone even, full stop. It's dumb, it's a waste of time and energy, and believe me, it's NOT what he'd want."&lt;/p&gt;
    &lt;p&gt;This is not the first time Zelda Williams, a film director, has criticised AI versions of her father, who took his own life in 2014 at his Californian home at the age of 63.&lt;/p&gt;
    &lt;p&gt;Williams, who was famous for films such as Good Morning Vietnam, Dead Poets Society and Mrs Doubtfire, was understood to have been battling depression at the time of his death.&lt;/p&gt;
    &lt;p&gt;In 2023, in an Instagram post supporting a campaign against AI by US media union SAG-Aftra, she described attempts at recreating his voice as "personally disturbing", while also pointing to the wider implications.&lt;/p&gt;
    &lt;p&gt;Her post on Tuesday reflects a trend on social media, where images of people who have died are animated, featuring captions like "bring your loved ones back to life".&lt;/p&gt;
    &lt;p&gt;Williams continued: "To watch the legacies of real people be condensed down to 'this vaguely looks and sounds like them so that's enough', just so other people can churn out horrible TikTok slop puppeteering them is maddening," she continued.&lt;/p&gt;
    &lt;p&gt;"You're not making art, you're making disgusting, over-processed hotdogs out of the lives of human beings, out of the history of art and music, and then shoving them down someone else's throat hoping they'll give you a little thumbs up and like it. Gross."&lt;/p&gt;
    &lt;p&gt;She concluded: "And for the love of EVERY THING, stop calling it 'the future,' AI is just badly recycling and regurgitating the past to be re-consumed. You are taking in the Human Centipede of content, and from the very very end of the line, all while the folks at the front laugh and laugh, consume and consume."&lt;/p&gt;
    &lt;p&gt;The Human Centipede is a reference to the 2009 body horror film.&lt;/p&gt;
    &lt;head rend="h2"&gt;'She sparks conversation'&lt;/head&gt;
    &lt;p&gt;Her latest comments come in the wake of unease following the unveiling of "AI actor", Tilly Norwood.&lt;/p&gt;
    &lt;p&gt;Norwood was created by Dutch actor and comedian Eline Van der Velden, who reportedly said she wanted Norwood to become the "next Scarlett Johansson".&lt;/p&gt;
    &lt;p&gt;In a statement, SAG-Aftra said Norwood "is not an actor, it's a character generated by a computer program that was trained on the work of countless professional performers.&lt;/p&gt;
    &lt;p&gt;"It has no life experience to draw from, no emotion and, from what we've seen, audiences aren't interested in watching computer-generated content untethered from the human experience," the union added.&lt;/p&gt;
    &lt;p&gt;Actress Emily Blunt also recently said she found the idea of Norwood terrifying.&lt;/p&gt;
    &lt;p&gt;"That is really, really scary, Come on, agencies, don't do that. Please stop. Please stop taking away our human connection," she said on a podcast with Variety.&lt;/p&gt;
    &lt;p&gt;Van der Velden later said in a statement, external: "To those who have expressed anger over the creation of my AI character, Tilly Norwood, she is not a replacement for a human being, but a creative work â a piece of art.&lt;/p&gt;
    &lt;p&gt;"Like many forms of art before her, she sparks conversation, and that in itself shows the power of creativity."&lt;/p&gt;
    &lt;head rend="h2"&gt;Related topics&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published6 days ago&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published25 September 2023&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published27 February 2015&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published13 August 2014&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505626</guid><pubDate>Tue, 07 Oct 2025 16:56:40 +0000</pubDate></item><item><title>Pigeon (YC W23) is hiring a lead full stack engineer</title><link>https://www.ycombinator.com/companies/pigeon/jobs/sjuJOg3-lead-full-stack-software-engineer-remote-us</link><description>&lt;doc fingerprint="aa9be2aaf687b428"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h1"&gt;Lead Full Stack Software Engineer at Pigeon (YC W23)&lt;/head&gt;
        &lt;p&gt;Pigeon (YC W23) is looking for a motivated Lead Full Stack Software Engineer to join our engineering team. You can work from our NYC office or remotely if you’re not local.&lt;/p&gt;
        &lt;p&gt;As a Lead Full Stack Software Engineer at Pigeon, you will help lead a small and fast-paced engineering team and spearhead the development of new features and systems from the ground up. You will be given a unique opportunity to shape our stack, processes, and culture while making a tangible impact on our technology and our customers.&lt;/p&gt;
        &lt;head rend="h3"&gt;Why Join Pigeon&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Impact: You will own high-value features for Pigeon’s entire customer base that will help shape their everyday business processes.&lt;/item&gt;
          &lt;item&gt;Culture: You will help shape how we work on a day-to-day basis and inform core values as we grow.&lt;/item&gt;
          &lt;item&gt;Leadership: You will be placed in a key leadership position with the opportunity to contribute to our direction, goals, and vision.&lt;/item&gt;
          &lt;item&gt;Learning: You will be encouraged to experiment with new methods and technologies to enable innovative experiences for customers.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;What You’ll Do&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Own core services, APIs, and integrations with third-party systems&lt;/item&gt;
          &lt;item&gt;Build and scale our AI-powered document processing system&lt;/item&gt;
          &lt;item&gt;Ship new features end-to-end - from conception to implementation to deployment&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;What We’re Looking For&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;5+ years experience as a full-stack software engineer&lt;/item&gt;
          &lt;item&gt;Comfortable with fast-paced development environment and early-stage ambiguity&lt;/item&gt;
          &lt;item&gt;Ability to take full ownership of projects (scoping, system design, implementation, QA, deployment, and maintenance)&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;Our Stack&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;AWS, Kubernetes, Vercel&lt;/item&gt;
          &lt;item&gt;Python, Flask, FastAPI, SqlAlchemy&lt;/item&gt;
          &lt;item&gt;NextJS, Javascript/Typescript, React, CSS, Tailwind&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;Benefits:&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Healthcare (Medical, Vision, and Dental)&lt;/item&gt;
          &lt;item&gt;OneMedical&lt;/item&gt;
          &lt;item&gt;401(k)&lt;/item&gt;
          &lt;item&gt;Unlimited PTO&lt;/item&gt;
          &lt;item&gt;16” Macbook Pro (M2 Chip)&lt;/item&gt;
          &lt;item&gt;Free Pigeon Merchandise (shop.pigeondocuments.com)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;p&gt;Pigeon automates the entire document lifecycle: collecting documents from clients, reviewing and extracting data with AI, and syncing with CRMs or storage systems. Pigeon eliminates the manual back-and-forth of document handling and eliminates thousands of hours of manual tasks.&lt;/p&gt;
      &lt;p&gt;We're growing fast, and want someone who can help join our team as we prepare for the next stage of growth.&lt;/p&gt;
      &lt;head rend="h3"&gt;Team&lt;/head&gt;
      &lt;p&gt;We are a team of 4 who previously worked at Google, Squarespace, Deloitte, and HonorLock.&lt;/p&gt;
      &lt;head rend="h3"&gt;Funding Status&lt;/head&gt;
      &lt;p&gt;We closed a $3.5M Seed round post-YC.&lt;/p&gt;
      &lt;head rend="h3"&gt;About our Technology:&lt;/head&gt;
      &lt;p&gt;Our Stack:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;AWS, Kubernetes, Vercel&lt;/item&gt;
        &lt;item&gt;Python, Flask, SqlAlchemy&lt;/item&gt;
        &lt;item&gt;NextJS, Javascript/Typescript, React, CSS, Tailwind&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505666</guid><pubDate>Tue, 07 Oct 2025 17:00:09 +0000</pubDate></item><item><title>You're Doing Rails Wrong</title><link>https://www.bananacurvingmachine.com/articles/you-re-doing-rails-wrong</link><description>&lt;doc fingerprint="2cd7f1377fc53f68"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt; You're doing Rails wrong. copy link &lt;/head&gt;
    &lt;head rend="h6"&gt;Tuesday, 07 October 2025&lt;/head&gt;
    &lt;p&gt; Kevin: Hey, have you tried Vite for Rails 8? It’s insanely fast.&lt;/p&gt;
    &lt;p&gt; John: I’ve heard of it. Isn’t that a build tool? Didn’t Rails already come with one?&lt;/p&gt;
    &lt;p&gt; K: Well, it did, but Vite is like… modern. You’ll need to install Node, npm, and configure a few scripts, but it’s totally worth it.&lt;/p&gt;
    &lt;p&gt; J: Wait, Rails needs Node now?&lt;/p&gt;
    &lt;p&gt; K: Well, yeah — if you want to use React. Everyone’s using React.&lt;/p&gt;
    &lt;p&gt; J: Didn’t Rails have something for that?&lt;/p&gt;
    &lt;p&gt; K: It did, but now you’ll want to use Vite with React Refresh so you get instant component reloads. And if you want TypeScript support, you’ll have to configure that too.&lt;/p&gt;
    &lt;p&gt; J: Sounds… like a lot.&lt;/p&gt;
    &lt;p&gt; K: Oh, not really. Just install Babel, configure your .babelrc, add vite-plugin-ruby, then you’ll want PostCSS for your styles.&lt;/p&gt;
    &lt;p&gt; J: PostCSS?&lt;/p&gt;
    &lt;p&gt; K: Yeah, and then Tailwind, obviously — you don’t want to write CSS like a peasant.&lt;/p&gt;
    &lt;p&gt; J: Of course not.&lt;/p&gt;
    &lt;p&gt; K: Then you’ll probably want to add ESLint and Prettier to make sure your code looks clean, and maybe Husky for pre-commit hooks.&lt;/p&gt;
    &lt;p&gt; J: So... Vite, React, Babel, PostCSS, Tailwind, ESLint, Prettier, Husky. That’s it?&lt;/p&gt;
    &lt;p&gt; K: Pretty much. Oh, unless you want server-side rendering — then you’ll need Next.js or Remix.&lt;/p&gt;
    &lt;p&gt; J: Wait, we’re still talking about a Rails app, right?&lt;/p&gt;
    &lt;p&gt; K: Yeah, but hybrid stacks are the way to go! You could also use StimulusReflex or Hotwire if you want reactive components without JS frameworks.&lt;/p&gt;
    &lt;p&gt; J: StimulusReflex sounds like a Marvel character.&lt;/p&gt;
    &lt;p&gt; K: Ha! No, it’s for real-time updates. But you’ll need ActionCable configured, Redis running, and—&lt;/p&gt;
    &lt;p&gt; J: Redis?&lt;/p&gt;
    &lt;p&gt; K: Yeah, you need a pub/sub layer. Don’t worry, it’s just another Docker container.&lt;/p&gt;
    &lt;p&gt; J: Docker too?&lt;/p&gt;
    &lt;p&gt; K: Yeah, to isolate your dependencies. And if you want everything reproducible, you’ll need Docker Compose, maybe Fly.io for deployment, and a build pipeline with GitHub Actions.&lt;/p&gt;
    &lt;p&gt; J: That’s... quite a setup.&lt;/p&gt;
    &lt;p&gt; K: It’s just modern web development, man. Keeps things simple. What are you doing?&lt;/p&gt;
    &lt;p&gt; J: Just tinkering.&lt;/p&gt;
    &lt;p&gt;(John runs a single command. The app boots instantly, working forms, instant loading times, blazing fast navigation.)&lt;/p&gt;
    &lt;p&gt; K: Wow, that looks like a pretty complex setup. What stack’s that?&lt;/p&gt;
    &lt;p&gt; J: Vanilla Rails.&lt;/p&gt;
    &lt;p&gt;Just F#$%^&amp;amp; use Rails.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505692</guid><pubDate>Tue, 07 Oct 2025 17:01:32 +0000</pubDate></item><item><title>Building a Browser for Reverse Engineers</title><link>https://nullpt.rs/reverse-engineering-browser</link><description>&lt;doc fingerprint="62009220a90d26e8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Preamble&lt;/head&gt;
    &lt;p&gt;In the expanding world of AI my heart still lies in AST transforms, browser fingerprinting, and anti-bot circumvention. In fact, that's the majority of this blog's content. But my workflow always felt... primitive. I was still manually sifting through page scripts, pasting suspicious snippets into an editor, and writing bespoke deobfuscators by hand. Tools like Webcrack and deobfuscate.io help, but the end-to-end loop still felt slow and manual. I wanted to build a tool that would be my web reverse-engineering Swiss Army knife&lt;/p&gt;
    &lt;p&gt;If you're just curious about what it looks like and don't care about how it works then here's a quick showcase:&lt;/p&gt;
    &lt;head rend="h2"&gt;Humble Beginnings&lt;/head&gt;
    &lt;p&gt;My first idea was simple: make a browser extension. For an MVP I wanted to hook an arbitrary function like &lt;code&gt;Array.prototype.push&lt;/code&gt; as early as possible and log every call to it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hooking functions in JavaScript&lt;/head&gt;
    &lt;p&gt;In JavaScript, it's trivial to hook into and override existing functions because you can reassign references at runtime. A common pattern is to stash the original function, replace it with a wrapper that does whatever instrumentation you want, and then call the original so the page keeps behaving normally:&lt;/p&gt;
    &lt;code&gt;const _origPush = Array.prototype.push;
Array.prototype.push = function (...args) {
  console.log('Array.push called on', this, 'with', args);
  return _origPush.apply(this, args);
};
&lt;/code&gt;
    &lt;p&gt;Here's what that looks like in Chrome's devtools:&lt;/p&gt;
    &lt;p&gt;This technique should make it pretty straightforward to build a Chrome extension that hooks arbitrary global functions on page load and surfaces calls in a small UI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Content Scripts&lt;/head&gt;
    &lt;p&gt;Chrome's content scripts aree files that run in the context of web pages, which we can use to install our hooks early.&lt;/p&gt;
    &lt;p&gt;The idea is simple, we create a content script that runs at document_start that injects a tiny bit of code that replaces &lt;code&gt;Array.prototype.push&lt;/code&gt; with a wrapper that logs and then calls the original.&lt;/p&gt;
    &lt;code&gt;{
 "name": "My extension",
 "content_scripts": [
   {
     "run_at": "document_start", // Script is injected after any files from css, but before any other DOM is constructed or any other script is run.
     "matches": ["&amp;lt;all_urls&amp;gt;"],
     "js": ["content-script.js"]
   }
 ]
}
&lt;/code&gt;
    &lt;code&gt;const _origPush = Array.prototype.push;
Array.prototype.push = function (...args) {
  console.log('Array.push called on', this, 'with', args);
  return _origPush.apply(this, args);
};
&lt;/code&gt;
    &lt;p&gt;Running this on a page that clearly used Array.push gave me... absolutely nothing. At first, I thought it had to be an execution order issue. Maybe my hook was loading too late? But after another read through the docs, I found this painfully obvious note staring me right in the face:&lt;/p&gt;
    &lt;p&gt;âContent scripts live in an isolated world, allowing a content script to make changes to its JavaScript environment without conflicting with the page or other extensionsâ content scripts.â&lt;/p&gt;
    &lt;p&gt;In hindsight, of course that makes sense. Still, it sucked. I wasnât ready to give up yet, though. I had a potentially clever workaround: injecting a &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag directly into the page with my hook inside. But, naturally, it could never be that easy.&lt;/p&gt;
    &lt;p&gt;I knew if I wanted to get this done, I would have to go down a layer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chrome Devtools Protocol&lt;/head&gt;
    &lt;p&gt;The Chrome DevTools Protocol (CDP) is the low-level bridge for instrumenting, inspecting, and debugging Chromium-based browsers. Itâs what automation tools like Selenium and Playwright use under the hood. CDP exposes a large set of methods and events split across domains. The docs publish a convenient, comprehensive list of them.&lt;/p&gt;
    &lt;p&gt;While reading the domains, one method jumped out: &lt;code&gt;Page.addScriptToEvaluateOnNewDocument&lt;/code&gt;. Its description "Evaluates given script in every frame upon creation (before loading frame's scripts)" sounded like exactly the hook we needed: run code before the pageâs own scripts so we can win the prototype race.&lt;/p&gt;
    &lt;p&gt;To prove the idea I built a tiny test: a page with a script that pushes a secret value into an array, and a CDP-injected hook that tries to observe that push. If the hook sees the secret, the technique works. I chose to prototype this using Electron. I could have spoken directly to the browser over raw CDP, but Electron made wiring up a UI, IPC, and a quick demo app way faster for a weekend PoC.&lt;/p&gt;
    &lt;code&gt;const { app, BrowserWindow } = require("electron/main");

function createWindow() {
  const win = new BrowserWindow({
    width: 800,
    height: 600,
  });

  const dbg = win.webContents.debugger;
  dbg.attach("1.3");
  // Enables the Page domain so we can run the script on new document command after
  dbg.sendCommand("Page.enable");
  dbg.sendCommand("Page.addScriptToEvaluateOnNewDocument", {
    source: `(() =&amp;gt; {
        const _origPush = Array.prototype.push;
        Array.prototype.push = function (...args) {
            console.log('Array.push called on', this, 'with', args);
            return _origPush.apply(this, args);
        };
})();`,
  });
  win.webContents.openDevTools();
  win.loadURL("file:///Users/veritas/demo/index.html");
}

app.whenReady().then(() =&amp;gt; {
  createWindow();
});
&lt;/code&gt;
    &lt;p&gt;The result?:&lt;/p&gt;
    &lt;p&gt;It worked! I knew this PoC could take me far. I could hook any arbitrary global function or property and log (or spoof!) arguments and return values. The next step was building a user interface around it.&lt;/p&gt;
    &lt;p&gt;Since this started as a fun weekend project, I wanted the fastest path to a working demo. In true open-source fashion I searched for âelectron web browserâ and stumbled across electron-browser-shell by Samuel Maddock.&lt;/p&gt;
    &lt;p&gt;That project gave me an address bar, tabs, and a basic IPC-ready shell bridging the webview environment and my browser UI.&lt;/p&gt;
    &lt;p&gt;From there I added a sidebar that would display hooked function events as they fired.&lt;/p&gt;
    &lt;p&gt;To make things more interesting I needed to hook more than Array.push. A favorite target of fingerprinting scripts is the Canvas API. Sites can draw a static image to a &lt;code&gt;&amp;lt;canvas&amp;gt;&lt;/code&gt;, call &lt;code&gt;toDataURL()&lt;/code&gt; (or read pixel data), and use the resulting hash to fingerprint your GPU using subtle rendering differences. By correlating canvas hashes with other signals (user agent, installed fonts, etc.), trackers can build a surprisingly robust fingerprint. Watching and optionally spoofing these kind of calls is extremely useful for this kind of RE work.&lt;/p&gt;
    &lt;p&gt;The result looked as follows:&lt;/p&gt;
    &lt;p&gt;I was pretty happy with the direction the project was taking. The PoC actually felt useful. Remembering my previous work reverse-engineering TikTokâs web collector and how aggressively those collectors scrape client-side signals, I couldnât resist testing the hook there. I fired up the demo, pointed it at TikTok, and watched the UI for activity.&lt;/p&gt;
    &lt;p&gt;The site was pulling a decent amount of telemetry. Canvas calls (like &lt;code&gt;toDataURL&lt;/code&gt;), WebGL stats, font and plugin probes, and other subtle signals that, when combined, paint a detailed fingerprint. Seeing those calls appear in my sidebar made this project feel immediately worthwhile.&lt;/p&gt;
    &lt;p&gt;I even made sure to include all canvas operations in a secrion of the detail pane to be able to recreate a canvas if necessary.&lt;/p&gt;
    &lt;p&gt;I wanted to run this against more anti-bots. Out of curiosity I pointed the demo at a site using Cloudflareâs Turnstile. I knew Turnstile was collecting various browser signals, but to my surprise, my sidebar showed nothing. Why was I seeing zero logs?&lt;/p&gt;
    &lt;head rend="h2"&gt;OOPif(S) I did it again&lt;/head&gt;
    &lt;p&gt;Cloudflare renders the Turnstile widget inside a sandboxed iframe tucked into a closed shadow root. This iframe is an OOPIF (out-of-process iframe). It lives in a different renderer process so page-level scripts (and our injected hooks) simply wonât run there, thus, no logs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hopping the Turnstile&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;In 2024, the M.T.A. reports to have lost a combined $568 million in unpaid bus fares and $350 million in unpaid subway fares, wait, wrong turnstile.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We needed a way to run our hooks inside those out-of-process frames. While scanning CDP I noticed the &lt;code&gt;Target.attachedToTarget&lt;/code&gt; event. It fires when the debugger auto-attaches to a new target or when you explicitly call &lt;code&gt;attachToTarget&lt;/code&gt;. This was the key: if we tell CDP to auto-attach to targets, it will notify us (and give us a &lt;code&gt;sessionId&lt;/code&gt;) for every new frame/process as it appears. With that target/session info we can evaluate code in the correct context so our hook actually runs inside OOPIFs as they spawn.&lt;/p&gt;
    &lt;code&gt;const dbg = view.webContents.debugger
dbg.on('message', async (_, method, params) =&amp;gt; {
    if (method === 'Target.attachedToTarget') {
        const { sessionId, targetInfo } = params
        // Prepare child session
        dbg.sendCommand('Runtime.enable', {}, sessionId).catch(() =&amp;gt; {})
        dbg.sendCommand('Page.enable', {}, sessionId).catch(() =&amp;gt; {})
        // Inject hook script into child frames (iframes)
        dbg.sendCommand('Page.addScriptToEvaluateOnNewDocument', { source: hook }, sessionId)
    }
})
&lt;/code&gt;
    &lt;p&gt;Tada, we have events!&lt;/p&gt;
    &lt;p&gt;Iâm not the first to hook common globals and dynamically analyze page scripts. Anti-bots are well aware of this trick and will use a variety of techniques to detect runtime JS patches, so you canât assume your wrappers will stay hidden.&lt;/p&gt;
    &lt;p&gt;How is this possible?&lt;/p&gt;
    &lt;head rend="h2"&gt;toString theory&lt;/head&gt;
    &lt;p&gt;In JavaScript, functions contain a &lt;code&gt;toString&lt;/code&gt; instance method. Let's try calling this on a native function:&lt;/p&gt;
    &lt;code&gt;const mapToString = Array.prototype.map.toString()
// returns 'function map() { [native code] }'
&lt;/code&gt;
    &lt;p&gt;This means that the implementation of this function is provided by the browser's native code. How does this look like with our hook applied?:&lt;/p&gt;
    &lt;code&gt;const _origPush = Array.prototype.push;
Array.prototype.push = function (...args) {
  console.log('Array.push called on', this, 'with', args);
  return _origPush.apply(this, args);
};
const pushToString = Array.prototype.push.toString(); // Returns "function (...args) {\n  console.log('Array.push called on', this, 'with', args);\n  return _origPush.apply(this, args);\n}"
&lt;/code&gt;
    &lt;p&gt;Oh no, our hook has been discovered! Luckily for us, this is easily patched&lt;/p&gt;
    &lt;code&gt;Array.prototype.push.toString = () =&amp;gt; "function push() { [native code] }";
&lt;/code&gt;
    &lt;p&gt;Phew, that was close.&lt;/p&gt;
    &lt;code&gt;const haha = Array.prototype.push.toString.toString(); // '() =&amp;gt; "function push() { [native code] }"'
&lt;/code&gt;
    &lt;p&gt;Oh no, another leak!&lt;/p&gt;
    &lt;code&gt;Array.prototype.push.toString.toString = () =&amp;gt; "function toString() { [native code] }"; // Yay it's fixed
&lt;/code&gt;
    &lt;p&gt;Ahhh! Another one!&lt;/p&gt;
    &lt;code&gt;const haha = Array.prototype.push.toString.toString.toString.toString.toString.toString();
&lt;/code&gt;
    &lt;p&gt;Wait, you can do what now!?&lt;/p&gt;
    &lt;code&gt;const youCantEscape = Function.toString.call(Array.prototype.push); // Returns "function (...args) {\n  console.log('Array.push called on', this, 'with', args);\n  return _origPush.apply(this, args);\n}"
&lt;/code&gt;
    &lt;p&gt;These JS runtime patches turned out to be frustratingly leaky. Patch one hole and another opens. Fixes were possible, but every patch felt like a bandaid that introduced new detection vectors. see:&lt;/p&gt;
    &lt;code&gt;const _origPush = Array.prototype.push;
Array.prototype.push = function (...args) {
  console.log('Array.push called on', this, 'with', args);
  return _origPush.apply(this, args);
};

// Yay, we patched this
Array.prototype.push.toString = () =&amp;gt; "function push() { [native code] }";
Array.prototype.push.toString.toString = () =&amp;gt; "function toString() { [native code] }";

// *facepalm*
const anotherLeak = Array.prototype.push.name; // returns "" instead of "push"
&lt;/code&gt;
    &lt;p&gt;Those runtime patches were very brittle. Targets we were analyzing could detect the instrumentation and change behavior or even self destruct if they noticed they were being watched. Fixing each leak felt like an endless game of whack-a-mole, so I decided to go a layer deeper.&lt;/p&gt;
    &lt;head rend="h2"&gt;Forking Chromium&lt;/head&gt;
    &lt;p&gt;At this point I knew I wanted to fork Chromium. I still planned to use Electron, at least for now, since Iâd already built a decent UI and didnât feel like rewriting it all in native C++. The idea was simple: fork Electron (and by extension Chromium), patch into the Blink layer where these API calls happen, and expose them somehow.&lt;/p&gt;
    &lt;p&gt;I didnât spend too long figuring out how Iâd surface those events. I was already using CDP, so why not create my own custom CDP domain and emit events from there? That way my existing Electron app could just subscribe to them like any other CDP event.&lt;/p&gt;
    &lt;p&gt;Luckily, Electron has a well-documented guide for building from source. Unluckily, building it took more than three hours on my M2 Pro Mac Mini. To make things worse, macOS 26 had broken parts of the build chain. The Metal toolchain wasnât being detected no matter what I had tried. Eventually, I hardcoded the path into the build script just to move forward. After several hours of C++ compilation errors and boredom, I finally had a locally built Electron binary running from source.&lt;/p&gt;
    &lt;p&gt;Now came the hard part: creating a custom CDP domain. The &lt;code&gt;devtools-frontend&lt;/code&gt; repository actually provides documentation on defining new protocol domains.&lt;/p&gt;
    &lt;p&gt;The gist is that protocols are defined in a &lt;code&gt;.pdl&lt;/code&gt; (Protocol Definition Language) file, specifically &lt;code&gt;browser_protocol.pdl&lt;/code&gt;. To add your own domain, you simply declare it there alongside the existing ones.&lt;/p&gt;
    &lt;p&gt;I decided to name my new domain &lt;code&gt;Snitch&lt;/code&gt;, and defined it like this:&lt;/p&gt;
    &lt;code&gt;experimental domain Snitch
  command disable
  command enable
  event toDataURLCalled
    parameters
      string dataURL
      optional string frameId
      optional string contextId
&lt;/code&gt;
    &lt;p&gt;Next, you include your new protocol files in Blinkâs build configuration, found in &lt;code&gt;third_party/blink/renderer/core/inspector/BUILD.gn&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;From there, you define an agent, the bridge that connects Blinkâs internals to the DevTools Protocol so your new CDP domain can send and receive events.&lt;/p&gt;
    &lt;p&gt;Iâll be honest, the documentation for this part was pretty lacking. The only promising link in the documentation pointed to a locked Google Doc presumably restricted to Chrome team members. They say there's no better documentation than the source code itself! By dissecting existing domains like &lt;code&gt;DOMStorage&lt;/code&gt;, &lt;code&gt;Network&lt;/code&gt;, and others, I reverse-engineered how they registered and dispatched events, then adapted that pattern for my own &lt;code&gt;Snitch&lt;/code&gt; domain.&lt;/p&gt;
    &lt;p&gt;I eventually landed on this:&lt;/p&gt;
    &lt;p&gt;snitch_agent.h&lt;/p&gt;
    &lt;code&gt;#ifndef THIRD_PARTY_BLINK_RENDERER_CORE_INSPECTOR_SNITCH_AGENT_H_
#define THIRD_PARTY_BLINK_RENDERER_CORE_INSPECTOR_SNITCH_AGENT_H_
#include &amp;lt;optional&amp;gt;

#include "third_party/blink/renderer/core/core_export.h"
#include "third_party/blink/renderer/core/inspector/inspector_base_agent.h"
#include "third_party/blink/renderer/core/inspector/protocol/snitch.h"

namespace blink {

class InspectedFrames;

class CORE_EXPORT SnitchAgent final
    : public InspectorBaseAgent&amp;lt;protocol::Snitch::Metainfo&amp;gt; {
 public:
  SnitchAgent(InspectedFrames*);
  SnitchAgent(const SnitchAgent&amp;amp;) = delete;
  SnitchAgent&amp;amp; operator=(const SnitchAgent&amp;amp;) = delete;
  ~SnitchAgent() override;

  void Trace(Visitor*) const override;
  protocol::Response enable() override;
  protocol::Response disable() override;

  void DidCanvasToDataURL(ExecutionContext*, const String&amp;amp; data_url,
                          const String&amp;amp; frame_id,
                          const String&amp;amp; context_id);

 private:
  Member&amp;lt;InspectedFrames&amp;gt; inspected_frames_;
  InspectorAgentState::Boolean enabled_;
};

}  // namespace blink

#endif  // THIRD_PARTY_BLINK_RENDERER_CORE_INSPECTOR_SNITCH_AGENT_H_

&lt;/code&gt;
    &lt;p&gt;snitch_agent.cpp&lt;/p&gt;
    &lt;code&gt;#include "third_party/blink/renderer/core/inspector/snitch_agent.h"
#include "third_party/blink/renderer/core/inspector/inspected_frames.h"

namespace blink {

SnitchAgent::SnitchAgent(
  InspectedFrames* inspected_frames)
  : inspected_frames_(inspected_frames),
    enabled_(&amp;amp;agent_state_, /*default_value=*/false) {}


SnitchAgent::~SnitchAgent() = default;

void SnitchAgent::Trace(Visitor* visitor) const {
  visitor-&amp;gt;Trace(inspected_frames_);
  InspectorBaseAgent::Trace(visitor);
}

protocol::Response SnitchAgent::enable() {
  enabled_.Set(true);
  instrumenting_agents_-&amp;gt;AddSnitchAgent(this);
  return protocol::Response::Success();
}

protocol::Response SnitchAgent::disable() {
  enabled_.Clear();
  instrumenting_agents_-&amp;gt;RemoveSnitchAgent(this);
  return protocol::Response::Success();
}

void SnitchAgent::DidCanvasToDataURL(ExecutionContext* context, const String&amp;amp; data_url,
                                     const String&amp;amp; frame_id,
                                     const String&amp;amp; context_id) {

  if (!enabled_.Get()) {
    return;
  }

  std::optional&amp;lt;String&amp;gt; maybe_frame;
  if (!frame_id.empty()) {
    maybe_frame = frame_id;
  }

  std::optional&amp;lt;String&amp;gt; maybe_ctx;
  if (!context_id.empty()) {
    maybe_ctx = context_id;
  }

  GetFrontend()-&amp;gt;toDataURLCalled(data_url, maybe_frame, maybe_ctx);
}

}  // namespace blink

&lt;/code&gt;
    &lt;p&gt;Now I needed a way to trigger my new event from the native C++ implementation of &lt;code&gt;toDataURL&lt;/code&gt;. The implementation for that function lives in &lt;code&gt;src/third_party/blink/renderer/core/html/canvas/html_canvas_element.cc&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;While digging through how other events were dispatched, I noticed something interesting. The agents werenât called directly. Instead, events were emitted through probes. These probes act as intermediary hooks that Blink uses to fire instrumentation events into the DevTools pipeline.&lt;/p&gt;
    &lt;p&gt;Hereâs a comment from that same class showing how a probe fires when a canvas element is created:&lt;/p&gt;
    &lt;code&gt;CanvasRenderingContext* HTMLCanvasElement::GetCanvasRenderingContextInternal(
    ExecutionContext* execution_context,
    const String&amp;amp; type,
    const CanvasContextCreationAttributesCore&amp;amp; attributes) {
  CanvasRenderingContext::CanvasRenderingAPI rendering_api =
      CanvasRenderingContext::RenderingAPIFromId(type);

  // ...

  CanvasRenderingContextFactory* factory =
      GetRenderingContextFactory(static_cast&amp;lt;int&amp;gt;(rendering_api));

  // Tell the debugger about the attempt to create a canvas context
  // even if it will fail, to ease debugging.
  probe::DidCreateCanvasContext(&amp;amp;GetDocument());
  // ...
}  
&lt;/code&gt;
    &lt;p&gt;These probes are defined in a file called &lt;code&gt;core_probes.pidl&lt;/code&gt;. The comment at the top of this file states:&lt;/p&gt;
    &lt;code&gt;/*
 * make_instrumenting_probes.py uses this file as a source to generate
 * core_probes_inl.h, core_probes_impl.cc and core_probe_sink.h.
 *
 * The code below is not a correct IDL but a mix of IDL and C++.
 *
 * The syntax for an instrumentation method is as follows:
 *
 *    returnValue methodName([paramAttr1] param1, [paramAttr2] param2, ...)
&lt;/code&gt;
    &lt;p&gt;Following this syntax, I added my custom probe:&lt;/p&gt;
    &lt;code&gt;void DidCanvasToDataURL([Keep] ExecutionContext*, String&amp;amp; data_url, String&amp;amp; frame_id, String&amp;amp; context_id);
&lt;/code&gt;
    &lt;p&gt;A similarly named &lt;code&gt;core_probes.json5&lt;/code&gt; holds the mappings of which agents are responsible for which probes. We can add our entry as such:&lt;/p&gt;
    &lt;code&gt;{
    observers: {
        // ...,
        SnitchAgent: {
            probes: ["DidCanvasToDataURL"]
        }
        // ...
    }
}
&lt;/code&gt;
    &lt;p&gt;The final step in adding our custom domain is to register the agent in &lt;code&gt;WebDevToolsAgentImpl::AttachSession&lt;/code&gt; like so:&lt;/p&gt;
    &lt;code&gt;session-&amp;gt;CreateAndAppend&amp;lt;SnitchAgent&amp;gt;(inspected_frames);
&lt;/code&gt;
    &lt;p&gt;and actually calling it in the implementation of &lt;code&gt;toDataURL&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;String HTMLCanvasElement::toDataURL(const String&amp;amp; mime_type,
                                    const ScriptValue&amp;amp; quality_argument,
                                    ExceptionState&amp;amp; exception_state) const {
  // ...
  String data_url = ToDataURLInternal(mime_type, quality, kBackBuffer,
                                      ReadbackType::kWebExposed);

  // // Hook up call to our new CDP event (Snitch.toDataURLCalled)
  probe::DidCanvasToDataURL(GetExecutionContext(), data_url, frame_id, context_id);

  return data_url;
}
&lt;/code&gt;
    &lt;p&gt;After accidentally nuking my local repository and having to restart the entire process, including sitting through another 3 hour compilation ð¥², it was ready to test!&lt;/p&gt;
    &lt;p&gt;We can create a simple Electron test application:&lt;/p&gt;
    &lt;code&gt;const { app, BrowserWindow } = require("electron/main");

function createWindow() {
  const win = new BrowserWindow({
    width: 800,
    height: 600,
  });

  const dbg = win.webContents.debugger;
  dbg.attach("1.3");
  dbg.sendCommand("Snitch.enable");
  dbg.on("message", (_, method, { dataURL }) =&amp;gt; {
    if (method === "Snitch.toDataURLCalled") {
      console.log("toDataURL called", dataURL);
    }
  });
  win.loadURL("https://demo.fingerprint.com/playground");
}

app.whenReady().then(() =&amp;gt; {
  createWindow();
});
&lt;/code&gt;
    &lt;p&gt;and run it pointing to our custom Electron build:&lt;/p&gt;
    &lt;code&gt;$ /Users/veritas/electron/src/out/Testing/Electron.app/Contents/MacOS/Electron demo.js
&lt;/code&gt;
    &lt;p&gt;Drumroll, please!&lt;/p&gt;
    &lt;p&gt;It worked! We can see our custom CDP event firing and returning to us the result of a toDataURL call on FingerprintJS' playground. We can now use these stealthy CDP events and not leak the fact that we're instrumenting these functions.&lt;/p&gt;
    &lt;p&gt;Note: Depending on what we do in these hooks, it may still be possible to detect us through any side-effects we introduce or potentially through timing checks (Is the function slower than it would usually be?).&lt;/p&gt;
    &lt;head rend="h2"&gt;Extras&lt;/head&gt;
    &lt;p&gt;This was powerful, but I wanted more. I needed a few extra tools to make this thing a real web reverse-engineering Swiss Army knife.&lt;/p&gt;
    &lt;head rend="h3"&gt;Deobfuscation&lt;/head&gt;
    &lt;p&gt;One of the biggest time sinks in this kind of work is dealing with obfuscated scripts. I wanted a built-in tool that could automatically detect and attempt to deobfuscate scripts as they load. Using CDPâs &lt;code&gt;Network&lt;/code&gt; domain, I intercept incoming JavaScript files and run a few lightweight heuristics to score their likelihood of being obfuscated. Suspicious ones are displayed in a separate tab, where I integrate tools like bensbâs deobfuscate.io to automatically try recovering a more readable version. The plan is to add more tools such as Webcrack and even custom deobfuscators of my own.&lt;/p&gt;
    &lt;p&gt;I also added a section that extracts and displays recovered string literals from the processed script for added speed.&lt;/p&gt;
    &lt;head rend="h3"&gt;Overwriting properties and functions&lt;/head&gt;
    &lt;p&gt;Hooking and reading is fun, but sometimes you want to change behavior. You now know that doing so in a browser environment, across OOPIFs and with anti-tamper checks is non-trivial. I built an Overrides tab where you can define custom JavaScript snippets that overwrite functions or properties across all frames. These execute without triggering common integrity checks, giving a clean way to spoof or alter these values.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fingerprint payload decryption&lt;/head&gt;
    &lt;p&gt;My bread and butter is dissecting anti-bot and fingerprinting scripts. These scripts often encrypt or encode their payloads before sending them to backend validators, which makes analysis painful. To make life easier, I added a feature that detects known collectors and automatically intercepts their outbound requests. It decrypts (or decodes) the payloads and displays both the plaintext and structured data in a neat table view.&lt;/p&gt;
    &lt;p&gt;Of course, each collector still needs to be reverse-engineered beforehand. Maybe this is where AI-assisted payload analysis could step in someday? Maybe, but for now I will continue to hand-roll my own parsers :-)&lt;/p&gt;
    &lt;head rend="h2"&gt;Next steps&lt;/head&gt;
    &lt;p&gt;Iâm really happy with how this project has evolved. Itâs gone from my quick weekend curiosity to a genuinely useful research tool. Still, I have a few major goals remain before I can say I'm truly proud:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Abandon Electron&lt;/p&gt;&lt;lb/&gt;Electron was great for rapid prototyping, but it is heavy and adds its own leaks. Theyâre fixable, sure, but the cleaner path is to embed the UI directly inside Chromium. Iâm looking into how other Chromium forks (like Brave) integrate their native UIs and exploring whether I can do the same.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Hook all the things&lt;/p&gt;&lt;lb/&gt;Iâve already implemented a broad set of hooks. Canvas, WebGL, audio fingerprinting,&lt;code&gt;navigator&lt;/code&gt;accessors, document and window properties, and more. But can we hook everything?&lt;lb/&gt;Iâve experimented with injecting hooks deeper in V8 where function calls are dispatched, however, V8âs optimizations quickly complicate things. Disabling those optimizations would work but at the cost of performance (and thus introducing timing leaks). Another idea is to modify the IDL code generator to automatically insert hooks during buildtime. This is likely the approach I will take.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Release?&lt;/p&gt;&lt;lb/&gt;I havenât decided what to do once itâs ready. Maybe open source it? Would others find it useful? Was this all built into Chromium this entire time under some obscure setting that I missed? Who knows.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And with that, I present to you a gallery of canvas fingerprint images that I've collected during this project.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fingerprint Gallery&lt;/head&gt;
    &lt;head rend="h3"&gt;Tiktok&lt;/head&gt;
    &lt;head&gt;Canvas operations:&lt;/head&gt;
    &lt;code&gt;const canvas = document.createElement('canvas')
const context = canvas.getContext("2d")
const gradient0 = context.createLinearGradient(10, 0, 180, 1)
gradient0.addColorStop(0, "red")
gradient0.addColorStop(0.1, "white")
gradient0.addColorStop(0.2, "blue")
gradient0.addColorStop(0.3, "yellow")
gradient0.addColorStop(0.4, "purple")
gradient0.addColorStop(0.7, "orange")
gradient0.addColorStop(1, "magenta")
context.fillStyle = gradient0
context.fillRect(0, 10, 100, 6)
const gradient1 = context.createLinearGradient(0, 0, 100, 100)
gradient1.addColorStop(0, "green")
gradient1.addColorStop(0.5, "yellow")
gradient1.addColorStop(0.7, "orange")
gradient1.addColorStop(1, "magenta")
context.beginPath()
context.fillStyle = gradient1
context.arc(50, 10, 25, 0, 6.283185307179586)
context.stroke()
context.fillStyle = "rgba(150, 32, 170, .97)"
context.font = "12px Sans"
context.textBaseline = "top"
context.fillText("*+(}#?ð¼ ð", 18, 18)
context.shadowBlur = 1
context.fillStyle = "rgba(47, 211, 69, .99)"
context.font = "14px Sans"
context.textBaseline = "top"
context.fillText("ð¼OynG@%tp$", 3, 3)
context.beginPath()
context.arc(30, 10, 20, 0, 6.283185307179586)
context.strokeStyle = "rgba(255, 12, 220, 1)"
context.stroke()
&lt;/code&gt;
    &lt;head rend="h3"&gt;FingerprintJS&lt;/head&gt;
    &lt;head&gt;Canvas operations:&lt;/head&gt;
    &lt;code&gt;const canvas = document.createElement('canvas')
const context = canvas.getContext("2d")
context.rect(0, 0, 10, 10)
context.rect(2, 2, 6, 6)
context.isPointInPath(5, 5, "evenodd")
context.textBaseline = "alphabetic"
context.fillStyle = "#f60"
context.fillRect(100, 1, 62, 20)
context.fillStyle = "#069"
context.font = "11pt \"Times New Roman\""
context.fillText("Cwm fjordbank gly ð", 2, 15)
context.fillStyle = "rgba(102, 204, 0, 0.2)"
context.font = "18pt Arial"
context.fillText("Cwm fjordbank gly ð", 4, 45)
&lt;/code&gt;
    &lt;head&gt;Canvas operations:&lt;/head&gt;
    &lt;code&gt;const canvas = document.createElement('canvas')
const context = canvas.getContext("2d")
context.globalCompositeOperation = "multiply"
context.fillStyle = "#f2f"
context.beginPath()
context.arc(40, 40, 40, 0, 6.283185307179586, true)
context.closePath()
context.fill()
context.fillStyle = "#2ff"
context.beginPath()
context.arc(80, 40, 40, 0, 6.283185307179586, true)
context.closePath()
context.fill()
context.fillStyle = "#ff2"
context.beginPath()
context.arc(60, 80, 40, 0, 6.283185307179586, true)
context.closePath()
context.fill()
context.fillStyle = "#f9c"
context.arc(60, 60, 60, 0, 6.283185307179586, true)
context.arc(60, 60, 20, 0, 6.283185307179586, true)
context.fill("evenodd")
&lt;/code&gt;
    &lt;head rend="h3"&gt;Cloudflare&lt;/head&gt;
    &lt;head&gt;Canvas operations:&lt;/head&gt;
    &lt;code&gt;const canvas = document.createElement('canvas')
const context = canvas.getContext("2d")
const gradient0 = context.createRadialGradient(33, 18, 8, 42, 10, 226)
gradient0.addColorStop(0, "#809900")
gradient0.addColorStop(1, "#404041")
context.fillStyle = gradient0
context.shadowBlur = 11
context.shadowColor = "#F38020"
context.beginPath()
context.moveTo(9, 14)
context.quadraticCurveTo(93, 48, 116, 111)
context.stroke()
context.fill()
context.shadowBlur = 0
const gradient1 = context.createRadialGradient(77, 98, 2, 27, 30, 206)
gradient1.addColorStop(0, "#809900")
gradient1.addColorStop(1, "#404041")
context.fillStyle = gradient1
context.beginPath()
context.ellipse(58, 55, 31, 28, 1.4441705959829747, 0.5401125108618993, 4.052233984744969)
context.stroke()
context.fill()
context.shadowBlur = 0
const gradient2 = context.createRadialGradient(108, 12, 10, 65, 118, 169)
gradient2.addColorStop(0, "#1AB399")
gradient2.addColorStop(1, "#E666B3")
context.fillStyle = gradient2
context.shadowBlur = 16
context.shadowColor = "#809980"
context.font = "27.77777777777778px aanotafontaa"
context.fillText("Ry", 13, 67)
context.shadowBlur = 0
const gradient3 = context.createRadialGradient(46, 47, 0, 101, 108, 207)
gradient3.addColorStop(0, "#4DB380")
gradient3.addColorStop(1, "#FF4D4D")
context.fillStyle = gradient3
context.shadowBlur = 3
context.shadowColor = "#FF6633"
context.beginPath()
context.moveTo(54, 5)
context.bezierCurveTo(54, 90, 32, 74, 71, 120)
context.stroke()
context.fill()
context.shadowBlur = 0
const gradient4 = context.createRadialGradient(119, 123, 3, 109, 90, 137)
gradient4.addColorStop(0, "#E6B333")
gradient4.addColorStop(1, "#3366E6")
context.fillStyle = gradient4
context.shadowBlur = 4
context.shadowColor = "#B3B31A"
context.beginPath()
context.moveTo(76, 0)
context.bezierCurveTo(1, 49, 103, 67, 49, 125)
context.stroke()
context.fill()
context.shadowBlur = 0
const gradient5 = context.createRadialGradient(34, 47, 1, 37, 59, 245)
gradient5.addColorStop(0, "#809900")
gradient5.addColorStop(1, "#404041")
context.fillStyle = gradient5
context.beginPath()
context.ellipse(56, 57, 14, 8, 1.2273132071162383, 4.1926143018618225, 2.8853539230051624)
context.stroke()
context.fill()
context.shadowBlur = 0
context.shadowBlur = 14
context.shadowColor = "#809900"
context.font = "11.904761904761905px aanotafontaa"
context.strokeText("@H1", 30, 73)
context.shadowBlur = 0;
&lt;/code&gt;
    &lt;head rend="h2"&gt;Until next time&lt;/head&gt;
    &lt;p&gt;I'd love to know if you found this even remotely interesting or think it's just a giant waste of time :-) I certainly had fun building it and had even more fun using it&lt;/p&gt;
    &lt;head rend="h2"&gt;Credits&lt;/head&gt;
    &lt;p&gt;pimothyxd: Helped with the design of the UI! Always someone I can depend on.&lt;/p&gt;
    &lt;p&gt;bensb: Used his deobfuscator for the scripts tab. Also very knowledgable and a great person to chat ideas with.&lt;/p&gt;
    &lt;p&gt;samuelmaddock: Your electron-browser-shell project made it very easy to get this spun up.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505713</guid><pubDate>Tue, 07 Oct 2025 17:03:15 +0000</pubDate></item><item><title>Saul Zabar, Smoked Fish Czar of Upper West Side, Dies at 97</title><link>https://www.nytimes.com/2025/10/07/dining/saul-zabar-dead.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45505793</guid><pubDate>Tue, 07 Oct 2025 17:07:52 +0000</pubDate></item></channel></rss>