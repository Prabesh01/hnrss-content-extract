<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 26 Sep 2025 03:44:38 +0000</lastBuildDate><item><title>Launch HN: Webhound (YC S23) â€“ Research agent that builds datasets from the web</title><link>https://news.ycombinator.com/item?id=45373008</link><description>&lt;doc fingerprint="354a104b23ad844a"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;We're the team behind Webhound (&lt;/p&gt;https://webhound.ai&lt;p&gt;), an AI agent that builds datasets from the web based on natural language prompts. You describe what you're trying to find. The agent figures out how to structure the data and where to look, then searches, extracts the results, and outputs everything in a CSV you can export.&lt;/p&gt;&lt;p&gt;We've set up a special no-signup version for the HN community at https://hn.webhound.ai - just click "Continue as Guest" to try it without signing up.&lt;/p&gt;&lt;p&gt;Here's a demo: https://youtu.be/fGaRfPdK1Sk&lt;/p&gt;&lt;p&gt;We started building it after getting tired of doing this kind of research manually. Open 50 tabs, copy everything into a spreadsheet, realize it's inconsistent, start over. It felt like something an LLM should be able to handle.&lt;/p&gt;&lt;p&gt;Some examples of how people have used it in the past month:&lt;/p&gt;&lt;p&gt;Competitor analysis: "Create a comparison table of internal tooling platforms (Retool, Appsmith, Superblocks, UI Bakery, BudiBase, etc) with their free plan limits, pricing tiers, onboarding experience, integrations, and how they position themselves on their landing pages." (https://www.webhound.ai/dataset/c67c96a6-9d17-4c91-b9a0-ff69...)&lt;/p&gt;&lt;p&gt;Lead generation: "Find Shopify stores launched recently that sell skincare products. I want the store URLs, founder names, emails, Instagram handles, and product categories." (https://www.webhound.ai/dataset/b63d148a-8895-4aab-ac34-455e...)&lt;/p&gt;&lt;p&gt;Pricing tracking: "Track how the free and paid plans of note-taking apps have changed over the past 6 months using official sites and changelogs. List each app with a timeline of changes and the source for each." (https://www.webhound.ai/dataset/c17e6033-5d00-4e54-baf6-8dea...)&lt;/p&gt;&lt;p&gt;Investor mapping: "Find VCs who led or participated in pre-seed or seed rounds for browser-based devtools startups in the past year. Include the VC name, relevant partners, contact info, and portfolio links for context." (https://www.webhound.ai/dataset/1480c053-d86b-40ce-a620-37fd...)&lt;/p&gt;&lt;p&gt;Research collection: "Get a list of recent arXiv papers on weak supervision in NLP. For each, include the abstract, citation count, publication date, and a GitHub repo if available." (https://www.webhound.ai/dataset/e274ca26-0513-4296-85a5-2b7b...)&lt;/p&gt;&lt;p&gt;Hypothesis testing: "Check if user complaints about Figma's performance on large files have increased in the last 3 months. Search forums like Hacker News, Reddit, and Figma's community site and show the most relevant posts with timestamps and engagement metrics." (https://www.webhound.ai/dataset/42b2de49-acbf-4851-bbb7-080b...)&lt;/p&gt;&lt;p&gt;The first version of Webhound was a single agent running on Claude 4 Sonnet. It worked, but sessions routinely cost over $1100 and it would often get lost in infinite loops. We knew that wasn't sustainable, so we started building around smaller models.&lt;/p&gt;&lt;p&gt;That meant adding more structure. We introduced a multi-agent system to keep it reliable and accurate. There's a main agent, a set of search agents that run subtasks in parallel, a critic agent that keeps things on track, and a validator that double-checks extracted data before saving it. We also gave it a notepad for long-term memory, which helps avoid duplicates and keeps track of what it's already seen.&lt;/p&gt;&lt;p&gt;After switching to Gemini 2.5 Flash and layering in the agent system, we were able to cut costs by more than 30x while also improving speed and output quality.&lt;/p&gt;&lt;p&gt;The system runs in two phases. First is planning, where it decides the schema, how to search, what sources to use, and how to know when it's done. Then comes extraction, where it executes the plan and gathers the data.&lt;/p&gt;&lt;p&gt;It uses a text-based browser we built that renders pages as markdown and extracts content directly. We tried full browser use but it was slower and less reliable. Plain text still works better for this kind of task.&lt;/p&gt;&lt;p&gt;We also built scheduled refreshes to keep datasets up to date and an API so you can integrate the data directly into your workflows.&lt;/p&gt;&lt;p&gt;Right now, everything stays in the agent's context during a run. It starts to break down around 1000-5000 rows depending on the number of attributes. We're working on a better architecture for scaling past that.&lt;/p&gt;&lt;p&gt;We'd love feedback, especially from anyone who's tried solving this problem or built similar tools. Happy to answer anything in the thread.&lt;/p&gt;&lt;p&gt;Thanks! Moe&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45373008</guid><pubDate>Thu, 25 Sep 2025 14:28:24 +0000</pubDate></item><item><title>Cloudflare Email Service: private beta</title><link>https://blog.cloudflare.com/email-service/</link><description>&lt;doc fingerprint="ee97ad5b3f10bcad"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;If you are building an application, you rely on email to communicate with your users. You validate their signup, notify them about events, and send them invoices through email. The service continues to find new purpose with agentic workflows and other AI-powered tools that rely on a simple email as an input or output.&lt;/p&gt;
      &lt;p&gt;And it is a pain for developers to manage. ItÃ¢s frequently the most annoying burden for most teams. Developers deserve a solution that is simple, reliable, and deeply integrated into their workflow.Ã‚ &lt;/p&gt;
      &lt;p&gt;Today, we're excited to announce just that: the private beta of Email Sending, a new capability that allows you to send transactional emails directly from Cloudflare Workers. Email Sending joins and expands our popular Email Routing product, and together they form the new Cloudflare Email Service Ã¢ a single, unified developer experience for all your email needs.&lt;/p&gt;
      &lt;p&gt;With Cloudflare Email Service, weÃ¢re distilling our years of experience securing and routing emails, and combining it with the power of the developer platform. Now, sending an email is as easy as adding a binding to a Worker and calling &lt;code&gt;send&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;export default {
  async fetch(request, env, ctx) {

    await env.SEND_EMAIL.send({
      to: [{ email: "[emailÂ protected]" }],
      from: { email: "[emailÂ protected]", name: "Your App" },
      subject: "Hello World",
      text: "Hello World!"
    });

    return new Response(`Successfully sent email!`);
  },
};&lt;/code&gt;
      &lt;/quote&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Email experience is user experience&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Email is a core tenet of your user experience. ItÃ¢s how you stay in touch with your users when they are outside your applications. Users rely on email to inform them when they need to take actions such as password resets, purchase receipts, magic login links, and onboarding flows. When they fail, your application fails.&lt;/p&gt;
      &lt;p&gt;That means itÃ¢s crucial that emails need to land in your usersÃ¢ inboxes, both reliably and quickly. A magic link that arrives ten minutes late is a lost user. An email delivered to a spam folder breaks user flows and can erode trust in your product. ThatÃ¢s why weÃ¢re focusing on deliverability and time-to-inbox with Cloudflare Email Service.Ã‚ &lt;/p&gt;
      &lt;p&gt;To do this, weÃ¢re tightly integrating with DNS to automatically configure the necessary DNS records Ã¢ like SPF, DKIM and DMARC Ã¢ such that email providers can verify your sending domain and trust your emails. Plus, in true Cloudflare fashion, Email Service is a global service. That means that we can deliver your emails with low latency anywhere in the world, without the complexity of managing servers across regions.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Simple and flexible for developers&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Treating email as a core piece of your application also means building for every touchpoint in your development workflow. WeÃ¢re building Email Service as part of the Cloudflare stack to make developing with email feels as natural as writing a Worker.Ã‚ &lt;/p&gt;
      &lt;p&gt;In practice, that means solving for every part of the transactional email workflow:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Starting with Email Service is easy. Instead of managing API keys and secrets, you can use the &lt;code&gt;Email&lt;/code&gt; binding to your &lt;code&gt;wrangler.jsonc&lt;/code&gt; and send emails securely and with no risk of leaked credentials.Ã‚Â &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;You can use Workers to process incoming mail, store attachments in R2, and add tasks to Queues to get email sending off the hot path of your application. And you can use &lt;code&gt;wrangler&lt;/code&gt; to emulate Email Sending locally, allowing you to test your user journeys without jumping between tools and environments.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;In production, you have clear observability over your emails with bounce rates and delivery events. And, when a user reports a missing email, you can quickly dive into the delivery status to debug issues quickly and help get your user back on track.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;WeÃ¢re also making sure Email Service seamlessly fits into your existing applications. If you need to send emails from external services, you can do so using either REST APIs or SMTP. Likewise, if youÃ¢ve been leaning on existing email frameworks (like React Email) to send rich, HTML-rendered emails to users, you can continue to use them with Email Service. Import the library, render your template, and pass it to the `send` method just as you would elsewhere.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;import { render, pretty, toPlainText } from '@react-email/render';
import { SignupConfirmation } from './templates';

export default {
  async fetch(request, env, ctx) {

    // Convert React Email template to html
    const html = await pretty(await render(&amp;lt;SignupConfirmation url="https://your-domain.com/confirmation-id"/&amp;gt;));

    // Use the Email Sending binding to send emails
    await env.SEND_EMAIL.send({
      to: [{ email: "[emailÂ protected]" }],
      from: { email: "[emailÂ protected]", name: "Welcome" },
      subject: "Signup Confirmation",
      html,
      text: toPlainText(html)
    });

    return new Response(`Successfully sent email!`);
  }
};&lt;/code&gt;
      &lt;/quote&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Email Routing and Email Sending: Better together&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Sending email is only half the story. Applications often need to receive and parse emails to create powerful workflows. By combining Email Sending with our existing Email Routing capabilities, we're providing a complete, end-to-end solution for all your application's email needs.&lt;/p&gt;
      &lt;p&gt;Email Routing allows you to create custom email addresses on your domain and handle incoming messages programmatically with a Worker, which can enable powerful application flows such as:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Using Workers AI to parse, summarize and even label incoming emails: flagging security events from customers, early signs of a bug or incident, and/or generating automatic responses based on those incoming emails.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Creating support tickets in systems like JIRA or Linear from emails sent to &lt;code&gt;[emailÂ protected]&lt;/code&gt;.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Processing invoices sent to &lt;code&gt;[emailÂ protected]&lt;/code&gt; and storing attachments in R2.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;To use Email Routing, add the &lt;code&gt;email&lt;/code&gt; handler to your Worker application and process it as needed:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;export default {
  // Create an email handler to process emails delivered to your Worker
  async email(message, env, ctx) {

    // Classify incoming emails using Workers AI
    const { score, label } = env.AI.run("@cf/huggingface/distilbert-sst-2-int8", { text: message.raw" })

    env.PROCESSED_EMAILS.send({score, label, message});
  },
};  &lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When you combine inbound routing with outbound sending, you can close the loop entirely within Cloudflare. Imagine a user emails your support address. A Worker can receive the email, parse its content, call a third-party API to create a ticket, and then use the Email Sending binding to send an immediate confirmation back to the user with their ticket number. ThatÃ¢s the power of a unified Email Service.&lt;/p&gt;
      &lt;p&gt;Email Sending will require a paid Workers subscription, and we'll be charging based on messages sent. We're still finalizing the packaging, and we'll update our documentation, changelog, and notify users as soon as we have final pricing and long before we start charging. Email Routing limits will remain unchanged.&lt;/p&gt;
      &lt;p&gt;Email is core to your application today, and it's becoming essential for the next generation of AI agents, background tasks, and automated workflows. We built the Cloudflare Email Service to be the engine for this new era of applications, weÃ¢ll be making it available in private beta this November.&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Interested in Email Sending? Sign up to the waitlist here.Ã‚ &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Want to start processing inbound emails? Get started with Email Routing, which is available now, remains free and will be folded into the new email sending APIs coming.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;WeÃ¢re excited to be adding Email Service to our Developer Platform, and weÃ¢re looking forward to seeing how you reimagine user experiences that increasingly rely on emails!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45373081</guid><pubDate>Thu, 25 Sep 2025 14:33:50 +0000</pubDate></item><item><title>ChatControl: EU wants to scan all private messages, even in encrypted apps</title><link>https://metalhearf.fr/posts/chatcontrol-wants-your-private-messages/</link><description>&lt;doc fingerprint="b516b17038a1bfe5"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction #&lt;/head&gt;
    &lt;p&gt;The ğŸ‡ªğŸ‡º European Union is advancing legislation that could fundamentally change how we communicate online. ChatControl would require all messaging platforms to automatically scan their usersâ€™ private messages and images.&lt;/p&gt;
    &lt;p&gt;Yes, even encrypted ones like Signal, WhatsApp and Telegram. No, you canâ€™t opt out.&lt;/p&gt;
    &lt;p&gt;This isnâ€™t just another privacy policy update you can ignore. If passed, this EU regulation (strongest and most binding legal instrument in EU law) would automatically apply to all member states without any wiggle room for national interpretation. It would even override constitutional protections for communication privacy and establish unprecedented mass surveillance of private communications.&lt;/p&gt;
    &lt;p&gt;The official justification? Fighting child sexual abuse material (CSAM). Protecting children is undeniably crucial, but the proposed methods would eliminate digital privacy for 450 million Europeans and set a global precedent for mass surveillance.&lt;/p&gt;
    &lt;p&gt;This surveillance trend extends beyond Europe: ğŸ‡¨ğŸ‡­ Switzerland is advancing metadata retention requirements, the ğŸ‡¬ğŸ‡§ UK is implementing comprehensive age verification systems and now the ğŸ‡ªğŸ‡º EU proposes to scan every private message. Each initiative is positioned as child protection policy, but the implications reach far beyond their stated goals.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is ChatControl #&lt;/head&gt;
    &lt;p&gt;ChatControl is what critics call the EUâ€™s proposed Regulation to Prevent and Combat Child Sexual Abuse, also known as CSAR (Child Sexual Abuse Regulation).&lt;/p&gt;
    &lt;p&gt;The proposal builds on surveillance techniques already deployed by major tech companies. Meta analyzes all Facebook Messenger conversations and unencrypted WhatsApp data (profile photos, group descriptions). Apple announced similar scanning for iCloud content in 2021, though they later suspended the program.&lt;/p&gt;
    &lt;p&gt;This turns voluntary corporate surveillance into mandatory government-ordered scanning. A temporary 2021 EU regulation allowed platforms to scan content voluntarily for three years. That authorization expired in 2024, which is why CSAR was proposed. The temporary regulation merely permitted scanning; CSAR would make detection obligatory under certain conditions.&lt;/p&gt;
    &lt;p&gt;Thereâ€™s also the Roadmap for Lawful Access to Data which has an even bigger goal: making all our digital data readable by authorities upon request. Weâ€™ll dive deeper into this broader surveillance agenda later.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scope and Coverage #&lt;/head&gt;
    &lt;p&gt;CSAR casts an extremely wide net. The regulation would apply to all interpersonal communication service providers, not just obvious targets like Signal, WhatsApp, or Telegram, but also:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Email providers&lt;/item&gt;
      &lt;item&gt;Dating apps&lt;/item&gt;
      &lt;item&gt;Gaming platforms with chat features&lt;/item&gt;
      &lt;item&gt;Social media platforms&lt;/item&gt;
      &lt;item&gt;File hosting services (Google Drive, iCloud, DropBoxâ€¦)&lt;/item&gt;
      &lt;item&gt;App stores&lt;/item&gt;
      &lt;item&gt;Even small community hosting services run by associations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This means virtually any digital service that allows people to communicate or share content would fall under surveillance requirements. The scope extends far beyond what most people imagine when they hear messaging apps.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it Works #&lt;/head&gt;
    &lt;p&gt;ChatControl relies on Client-Side Scanning. Your device becomes a monitoring station that analyzes your content before encryption happens.&lt;/p&gt;
    &lt;p&gt;This represents a fundamental shift away from traditional surveillance that intercepts messages during transmission. With ChatControl, every message gets automatically checked, assuming everyone is guilty until proven innocent and effectively reversing the presumption of innocence.&lt;/p&gt;
    &lt;head rend="h3"&gt;Technical Implementation #&lt;/head&gt;
    &lt;p&gt;The system would automatically scan for three categories of content before encryption:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Known illegal content: Images or videos already catalogued by authorities as CSAM. Your device creates hash fingerprints of your content and compares them against databases of known illegal material.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unknown potential content: Photos or videos that might constitute CSAM but havenâ€™t been previously identified. AI algorithms analyze visual elements (like exposed skin) to flag potentially problematic content based on statistical models.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Grooming behavior: Text analysis using AI to identify communication patterns that match predefined indicators of adults soliciting children. This involves scanning the actual content of your private conversations.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If something gets flagged, it automatically gets reported to authorities. No human checks it first, that would be impossible given the billions of daily messages. This would be mandatory for all messaging platforms in ğŸ‡ªğŸ‡º Europe.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why This Breaks Encryption #&lt;/head&gt;
    &lt;p&gt;ChatControl doesnâ€™t break encryption, it bypasses it entirely. While your messages still get encrypted during transmission, the system defeats the purpose of end-to-end encryption by examining your content before it gets encrypted. True E2EE means only you and your recipient can read messages: no government, no company, no algorithm should peek inside. This surveillance violates that principle by inserting monitoring at the source.&lt;/p&gt;
    &lt;p&gt;Privacy-focused companies like Proton point out this approach might be worse than encryption backdoors. Backdoors give authorities access to communications you share with others. This system examines everything on your device, whether you share it or not.&lt;/p&gt;
    &lt;p&gt;Your encrypted messaging app becomes spyware. Supporters claim this protects privacy because scanning happens locally, but surveillance built into your device makes it impossible to escape.&lt;/p&gt;
    &lt;head rend="h3"&gt;Governance Structure #&lt;/head&gt;
    &lt;p&gt;The proposal would create a centralized EU Centre on Child Sexual Abuse to receive all reports, but EU institutions wouldnâ€™t control the scanning technology itself.&lt;/p&gt;
    &lt;p&gt;Service providers would face additional obligations beyond scanning. They would need to conduct risk assessments to evaluate and minimize the potential for illegal content sharing on their platforms. This requires collecting detailed information about their users (age groups, content types) that many privacy-focused services deliberately avoid gathering.&lt;/p&gt;
    &lt;p&gt;The regulation also pushes for mandatory age verification systems. No viable, privacy-respecting age verification technology currently exists. These systems would eliminate online anonymity, requiring users to prove their identity to access digital services.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-World Impact #&lt;/head&gt;
    &lt;head rend="h3"&gt;Encryption Concerns #&lt;/head&gt;
    &lt;p&gt;ChatControl fits into a broader political strategy. Since the 1990s crypto wars, certain states have argued that privacy-protecting technologies, especially encryption, obstruct police investigations. These technologies are designed to do exactly that, protect everyoneâ€™s ability to control their expression and communication.&lt;/p&gt;
    &lt;p&gt;The European Commissionâ€™s Roadmap for Lawful Access to Data wants to make all digital data accessible to authorities by 2030. This involves systematically weakening encryption rather than simply bypassing it.&lt;/p&gt;
    &lt;p&gt;Edward Snowdenâ€™s revelations ten years ago led to widespread adoption of encryption and institutional consensus supporting the right to encrypted communication. But governments remain frustrated by their inability to access private communications. Weâ€™re seeing a return to authoritarian positions using terrorism, organized crime and child exploitation as justifications for undermining encryption.&lt;/p&gt;
    &lt;p&gt;ğŸ‡©ğŸ‡° Danish Minister of Justice Peter Hummelgaard, chief architect of the current ChatControl proposal, recently stated: â€œWe must break with the totally erroneous perception that it is everyoneâ€™s civil liberty to communicate on encrypted messaging services.â€ Well, there you have it folks: encrypted communication isnâ€™t a civil liberty anymore. You cypherpunks were wrong all along. /s&lt;/p&gt;
    &lt;p&gt;Similarly in ğŸ‡«ğŸ‡· France, both Bernard Cazeneuve and Emmanuel Macron have explicitly stated their desire to control encrypted messaging, seeking to pierce the privacy of millions who use these services.&lt;/p&gt;
    &lt;p&gt;CSAR provides the perfect opportunity for member states to finally design and implement a generalized surveillance tool for monitoring population communications. Crossing this threshold means eliminating all confidentiality from communications using digital infrastructure.&lt;/p&gt;
    &lt;head rend="h3"&gt;False Positives #&lt;/head&gt;
    &lt;p&gt;These scanning systems get it wrong most of the time. Studies show approximately 80% of algorithmic reports are false positives: innocent content incorrectly flagged as illegal. ğŸ‡®ğŸ‡ª Irish law enforcement confirms this: only 20.3% of 4,192 automated reports actually contained illegal material.&lt;/p&gt;
    &lt;p&gt;Even with hypothetical 99% accuracy (which current systems donâ€™t achieve), scanning billions of daily messages would generate millions of false accusations. Police resources would be overwhelmed investigating innocent families sharing vacation photos while real crimes go uninvestigated.&lt;/p&gt;
    &lt;p&gt;Innocent content regularly triggers these systems: family photos, teenage conversations, educational materials and medical communications. Consider this real case: a father was automatically reported to police after sending photos of his childâ€™s medical condition to their doctor. Googleâ€™s algorithms flagged this legitimate medical consultation as potential abuse, permanently closed his account and refused all appeals. His digital life was destroyed by an algorithm that couldnâ€™t distinguish between medical care and criminal activity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scientific Opposition #&lt;/head&gt;
    &lt;p&gt;For the third time in three years, over 600 cryptographers, security researchers and scientists across 35 countries have co-signed an open letter explaining why this mass scanning project is â€œtechnically unfeasibleâ€, constitutes a â€œdanger to democracyâ€ and would â€œcompletely compromiseâ€ the security and privacy of all European citizens.&lt;/p&gt;
    &lt;p&gt;The letter emphasizes that client-side scanning cannot distinguish between legal and illegal content without fundamentally breaking encryption and creating vulnerabilities that malicious actors can exploit.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the Commission has provided no serious studies demonstrating the effectiveness, reliability or appropriateness of these intrusive measures for actually protecting children. Industry claims appear to have taken precedence over evidence-based policy-making.&lt;/p&gt;
    &lt;p&gt;Genuine security emerges through thoughtful design where security measures and civil liberties function as complementary forces, not opposing ones.&lt;/p&gt;
    &lt;head rend="h3"&gt;Easily Defeated #&lt;/head&gt;
    &lt;p&gt;The fundamental flaw in ChatControl becomes clear when examining how easily determined actors can circumvent these scanning systems. Criminals donâ€™t need sophisticated techniques to bypass client-side scanning; they use well-documented public knowledge already employed by malicious actors.&lt;/p&gt;
    &lt;p&gt;Layered Encryption&lt;lb/&gt; Encrypt files with standard tools like GPG before messaging. Hell, even a basic Caesar cipher would be sufficient to bypass detection. Since client-side scanning occurs after user encryption but before transport encryption, pre-encrypted content looks like random data to detection algorithms. Recipients decrypt locally with shared keys.&lt;/p&gt;
    &lt;p&gt;External Platform Bypass&lt;lb/&gt; Upload content to any third-party platform (Dropbox, OneDrive, anonymous file hosts, or obscure hosting services) and share links instead of files. The scanner sees innocent text containing a URL while the actual content sits untouched on external servers.&lt;/p&gt;
    &lt;p&gt;Custom Messaging Clients&lt;lb/&gt; Open-source protocols like XMPP and Matrix allow custom client development. Modified clients can automatically implement cloud storage and encryption workflows transparently. Users experience normal messaging while completely evading surveillance infrastructure.&lt;/p&gt;
    &lt;p&gt;Digital Steganography&lt;lb/&gt; Steganographic techniques embed data within innocent images. Family photos can carry hidden payloads invisible to both human operators and AI systems. Tools like OpenStego make this accessible to average users.&lt;/p&gt;
    &lt;p&gt;Platform Migration&lt;lb/&gt; Criminal networks can shift to decentralized platforms, peer-to-peer networks or services outside EU jurisdiction. Tor-based messaging, blockchain communications or servers in non-compliant countries remain beyond ChatControlâ€™s reach.&lt;/p&gt;
    &lt;p&gt;ChatControl catches only amateur criminals who directly attach problematic content to messages. Professional networks already employ these evasion techniques as standard practice. EU legislation wonâ€™t make them forget how computers work.&lt;/p&gt;
    &lt;p&gt;The system fails at protecting children while succeeding at mass civilian monitoring. Itâ€™s not a bug, itâ€™s a feature.&lt;/p&gt;
    &lt;head rend="h2"&gt;Business Interests #&lt;/head&gt;
    &lt;head rend="h3"&gt;Industry Players #&lt;/head&gt;
    &lt;p&gt;The child protection narrative masks concerning business interests. The European Commission based its CSAR proposal primarily on claims from industry players rather than independent research.&lt;/p&gt;
    &lt;p&gt;Commercial surveillance companies would manage the technology with guaranteed access to the European market. Organizations like Thorn (co-founded by actor Ashton Kutcher), Microsoftâ€™s PhotoDNA and other tech companies develop these detection systems while simultaneously lobbying for regulations that would require their adoption across Europe.&lt;/p&gt;
    &lt;p&gt;These companies develop the detection technologies and lobby for laws mandating their adoption, creating a profitable feedback loop. The proposal would secure privileged market positions for surveillance companies across hundreds of millions of European users. Pretty nice, isnâ€™t it?&lt;/p&gt;
    &lt;p&gt;These systems would be:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Proprietary: Built on closed-source code with methods hidden from public view&lt;/item&gt;
      &lt;item&gt;Unverifiable: Operating without meaningful external examination or accountability&lt;/item&gt;
      &lt;item&gt;Legally powerful: Capable of starting criminal proceedings through algorithmic decisions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Rhetorical Tactics #&lt;/head&gt;
    &lt;p&gt;Commissioner Ylva Johansson consistently emphasizes this narrative in her communications:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;â€œ[Privacy defenders make a lot of noise], but someone has to speak for the children.â€&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;â€œThink of the childrenâ€ is a well-documented political rhetoric technique that appeals to emotion rather than evidence. While child protection is genuinely important, this approach frames any opposition as being against child welfare, making nuanced discussion more difficult.&lt;/p&gt;
    &lt;p&gt;This creates a false choice. Privacy isnâ€™t a luxury for troublemakers, itâ€™s a fundamental right that protects journalists, whistleblowers, activists and ordinary people from unwarranted intrusion.&lt;/p&gt;
    &lt;p&gt;Critics arenâ€™t opposing child protection. Weâ€™re questioning whether undermining privacy rights for 450 million ğŸ‡ªğŸ‡º Europeans is the most effective approach when targeted alternatives exist that preserve rights.&lt;/p&gt;
    &lt;head rend="h2"&gt;EU Country Positions #&lt;/head&gt;
    &lt;p&gt;Understanding how ğŸ‡ªğŸ‡º EU member states position themselves on this legislation is crucial, as their votes will determine whether ChatControl becomes reality.&lt;/p&gt;
    &lt;head rend="h3"&gt;Vote Breakdown #&lt;/head&gt;
    &lt;p&gt;Countries that support ChatControl (12): ğŸ‡§ğŸ‡¬ Bulgaria â€¢ ğŸ‡­ğŸ‡· Croatia â€¢ ğŸ‡¨ğŸ‡¾ Cyprus â€¢ ğŸ‡©ğŸ‡° Denmark â€¢ ğŸ‡«ğŸ‡· France â€¢ ğŸ‡­ğŸ‡º Hungary â€¢ ğŸ‡®ğŸ‡ª Ireland â€¢ ğŸ‡±ğŸ‡¹ Lithuania â€¢ ğŸ‡²ğŸ‡¹ Malta â€¢ ğŸ‡µğŸ‡¹ Portugal â€¢ ğŸ‡·ğŸ‡´ Romania â€¢ ğŸ‡ªğŸ‡¸ Spain&lt;/p&gt;
    &lt;p&gt;Countries that oppose ChatControl (7): ğŸ‡¦ğŸ‡¹ Austria â€¢ ğŸ‡¨ğŸ‡¿ Czech Republic â€¢ ğŸ‡ªğŸ‡ª Estonia â€¢ ğŸ‡«ğŸ‡® Finland â€¢ ğŸ‡±ğŸ‡º Luxembourg â€¢ ğŸ‡³ğŸ‡± Netherlands â€¢ ğŸ‡µğŸ‡± Poland&lt;/p&gt;
    &lt;p&gt;Countries still undecided (8): ğŸ‡§ğŸ‡ª Belgium â€¢ ğŸ‡©ğŸ‡ª Germany â€¢ ğŸ‡¬ğŸ‡· Greece â€¢ ğŸ‡®ğŸ‡¹ Italy â€¢ ğŸ‡±ğŸ‡» Latvia â€¢ ğŸ‡¸ğŸ‡° Slovakia â€¢ ğŸ‡¸ğŸ‡® Slovenia â€¢ ğŸ‡¸ğŸ‡ª Sweden&lt;/p&gt;
    &lt;head rend="h3"&gt;National Stances #&lt;/head&gt;
    &lt;head&gt;ğŸ’ª Strong opposition (the good guys) (click to expand)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;ğŸ‡¦ğŸ‡¹ Austria: Constitutional and privacy concerns.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ğŸ‡¨ğŸ‡¿ Czech Republic: Prime Minister explicitly rejects proposals that would allow widespread monitoring of citizensâ€™ private digital communications.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ğŸ‡ªğŸ‡ª Estonia: Acknowledges sincere concerns about child exploitation, but opposes undermining end-to-end encryption and forcing mass surveillance.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ğŸ‡«ğŸ‡® Finland: Cannot support the latest compromise proposal because it contains a constitutionally problematic identification order.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ğŸ‡±ğŸ‡º Luxembourg: Rejects broad surveillance measures like client-side scanning and insists that EU regulation must ensure proportional, targeted detection to protect citizensâ€™ fundamental rights.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ğŸ‡³ğŸ‡± Netherlands: Strong privacy protection stance.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ğŸ‡µğŸ‡± Poland: Opposition to mass surveillance measures.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;ğŸ¤· Undecided positions (click to expand)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ‡§ğŸ‡ª Belgium: The N-VA party calls ChatControl a â€œmonster that invades your privacy and cannot be tamedâ€. Despite this, Belgium backed Denmarkâ€™s compromise during September meetings. Mixed signals from Brussels.&lt;/item&gt;
      &lt;item&gt;ğŸ‡©ğŸ‡ª Germany: Wonâ€™t break encryption but wants to find middle ground. Theyâ€™re trying to craft their own compromise instead of rejecting ChatControl outright. Germanyâ€™s fence-sitting could be decisive.&lt;/item&gt;
      &lt;item&gt;ğŸ‡¬ğŸ‡· Greece: Still figuring out the technical details. No clear stance yet.&lt;/item&gt;
      &lt;item&gt;ğŸ‡®ğŸ‡¹ Italy: Has concerns about expanding the scope to cover new CSAM detection. Rome seems hesitant about how far this thing could reach.&lt;/item&gt;
      &lt;item&gt;ğŸ‡±ğŸ‡» Latvia: The government likes what they see on paper but worries about political backlash after summer attention. Classic politicians hedging their bets.&lt;/item&gt;
      &lt;item&gt;ğŸ‡¸ğŸ‡° Slovakia: Playing the wait-and-see game. No commitment either way.&lt;/item&gt;
      &lt;item&gt;ğŸ‡¸ğŸ‡® Slovenia: Dealing with constitutional headaches around privacy. Another country wrestling with legal implications.&lt;/item&gt;
      &lt;item&gt;ğŸ‡¸ğŸ‡ª Sweden: Stockholm is still reading the fine print. Taking their time to decide.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Current Status #&lt;/head&gt;
    &lt;p&gt;Current situation: Country positions continue shifting regularly since September 12. With 12 countries supporting, 7 opposing, and 8 undecided, ChatControl supporters still fall short of the 65% EU population threshold needed for a qualified majority. The opposition maintains enough demographic weight to block the proposal for now, but the situation remains fluid as the interim regulation approaches expiration.&lt;/p&gt;
    &lt;head&gt;ğŸ“… Timeline of Events (click to expand)&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;ChatControl Proposal Introduced&lt;/head&gt;&lt;head rend="h3"&gt;May 11, 2022&lt;/head&gt;&lt;head rend="h4"&gt;European Commission&lt;/head&gt;The European Commission unveils the original ChatControl proposal, requiring all email and messaging providers to scan communications for child sexual abuse material.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Danish Presidency Takes Charge&lt;/head&gt;&lt;head rend="h3"&gt;Jul 1, 2025&lt;/head&gt;&lt;head rend="h4"&gt;EU Council Presidency&lt;/head&gt;ğŸ‡©ğŸ‡° Denmark assumes the EU Council Presidency and immediately reintroduces ChatControl as a top legislative priority, targeting October 14, 2025 for adoption.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Support Momentum Builds&lt;/head&gt;&lt;head rend="h3"&gt;Jul 28, 2025&lt;/head&gt;&lt;head rend="h4"&gt;15 Member States&lt;/head&gt;Fifteen EU member states back the ChatControl proposal, reversing earlier resistance. ğŸ‡«ğŸ‡· France has shifted its position and now supports the proposal. ğŸ‡©ğŸ‡ª Germany remains the crucial undecided vote.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Opposition Wave Begins&lt;/head&gt;&lt;head rend="h3"&gt;Aug 26, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Czech Republic&lt;/head&gt;ğŸ‡¨ğŸ‡¿ Czech Prime Minister Petr Fiala announces total opposition on behalf of the entire coalition government.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Constitutional Concerns&lt;/head&gt;&lt;head rend="h3"&gt;Aug 29, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Finland&lt;/head&gt;ğŸ‡«ğŸ‡® Finland rejects the compromise proposal due to constitutionally problematic detection requirements.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Blocking Minority Secured&lt;/head&gt;&lt;head rend="h3"&gt;Sep 10, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Germany, Luxembourg, Slovakia&lt;/head&gt;ğŸ‡©ğŸ‡ª Germany, ğŸ‡±ğŸ‡º Luxembourg, and ğŸ‡¸ğŸ‡° Slovakia officially oppose breaking encryption. This creates the blocking minority needed to stop the proposal.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Estonia Joins Opposition&lt;/head&gt;&lt;head rend="h3"&gt;Sep 14, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Privacy Protection&lt;/head&gt;ğŸ‡ªğŸ‡ª Estonia acknowledges child exploitation concerns but opposes undermining end-to-end encryption and mass surveillance.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Germany Wavers&lt;/head&gt;&lt;head rend="h3"&gt;Sep 16, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Position Unclear&lt;/head&gt;ğŸ‡©ğŸ‡ª Germany refrains from taking a definitive stance during the LEWP meeting, despite previous encryption concerns. Position becomes uncertain.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Three Countries Flip&lt;/head&gt;&lt;head rend="h3"&gt;Sep 23, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Belgium, Latvia, Italy&lt;/head&gt;ğŸ‡§ğŸ‡ª Belgium, ğŸ‡±ğŸ‡» Latvia, and ğŸ‡®ğŸ‡¹ Italy have moved away from supporting the proposal and are now undecided. Country positions continue changing regularly since September 12.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Consequences #&lt;/head&gt;
    &lt;p&gt;The effects of these proposals go beyond individual privacy concerns.&lt;/p&gt;
    &lt;p&gt;Cybersecurity gets compromised&lt;lb/&gt; Adding deliberate vulnerabilities to encryption creates weaknesses that everyone can exploit. Any backdoor for authorized access becomes a potential entry point for criminals and foreign intelligence services. In February 2024, the ğŸ‡ªğŸ‡º European Court of Human Rights already determined that mandating weakened encryption â€œcannot be regarded as necessary in a democratic societyâ€.&lt;/p&gt;
    &lt;p&gt;Innovation suffers&lt;lb/&gt; ğŸ‡ªğŸ‡º European cybersecurity companies would face an impossible situation in global markets. How could they credibly sell security solutions when regulations require them to build in access mechanisms that undermine those very protections?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;â€œBuy our ultra-secure encrypted stuff!â€ (Terms and conditions apply, government backdoors included)."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Tech companies will leave Europe&lt;lb/&gt; Privacy-focused services that moved to ğŸ‡ªğŸ‡º Europe after the Snowden revelations are already signaling they might leave. Signal has explicitly said it would stop operating in ğŸ‡ªğŸ‡º Europe rather than compromise its security.&lt;/p&gt;
    &lt;p&gt;Even ğŸ‡¨ğŸ‡­ Switzerland, traditionally seen as a privacy haven, is facing severe legislative pressures that are forcing tech companies to relocate. Proton has confirmed it has begun moving some of its physical infrastructure out of Switzerland due to â€œlegal uncertaintyâ€ over the proposed surveillance law amendments. Lumo, their AI chatbot, became the first product to relocate, moving to Germany instead of Switzerland specifically because of these legislative concerns.&lt;/p&gt;
    &lt;p&gt;The Swiss OSCPT (Ordinance on the Surveillance of Correspondence by Post and Telecommunications) revision would require VPNs and messaging apps to identify users and retain data for up to six months, plus decrypt communications upon authority request. As Protonâ€™s CEO Andy Yen explained, these are proposals that â€œhave been outlawed in the EUâ€ but could soon become reality in Switzerland.&lt;/p&gt;
    &lt;p&gt;Other privacy-focused providers like Tuta have expressed similar concerns and contingency plans to leave ğŸ‡¨ğŸ‡­ Switzerland if the surveillance laws pass.&lt;/p&gt;
    &lt;p&gt;Europe might become dependent on US surveillance&lt;lb/&gt; Iâ€™m not so sure on this one, but by outsourcing surveillance technology to American companies, ğŸ‡ªğŸ‡º Europe may create dangerous dependencies. These companies operate under ğŸ‡ºğŸ‡¸ US jurisdiction and the CLOUD Act, potentially allowing ğŸ‡ºğŸ‡¸ Washington to access data collected on ğŸ‡ªğŸ‡º European citizens. Under the pretense of child protection, the ğŸ‡ªğŸ‡º EU risks handing surveillance keys to foreign powers.&lt;/p&gt;
    &lt;p&gt;Social behavior changes&lt;lb/&gt; When people know theyâ€™re being watched, they change how they communicate. People start self-censoring, avoiding certain topics and carefully choosing their words even in private conversations.&lt;/p&gt;
    &lt;p&gt;This is called the chilling effect. Rights donâ€™t disappear overnight: they erode gradually as people change their behavior to avoid potential problems.&lt;/p&gt;
    &lt;head rend="h2"&gt;Take Action #&lt;/head&gt;
    &lt;p&gt;Hereâ€™s how you can contribute to defending our digital freedoms:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Share this article and educate your network: Use hashtags like &lt;code&gt;#ChatControl&lt;/code&gt;or&lt;code&gt;#StopScanningMe&lt;/code&gt;. Forward resources to friends, family and colleagues.&lt;/item&gt;
      &lt;item&gt;Sign the petition: against ChatControl at change.org.&lt;/item&gt;
      &lt;item&gt;Stay informed and follow updates: @[email protected], x.com/nonchatcontrol, patrick-breyer.de and fightchatcontrol.eu.&lt;/item&gt;
      &lt;item&gt;Contact your national representatives to convince your country to oppose ChatControl, if itâ€™s not already the case.&lt;/item&gt;
      &lt;item&gt;Join campaigns and support organizations: stopscanningme.eu for local actions, EFF and EDRi for digital rights advocacy.&lt;/item&gt;
      &lt;item&gt;Adopt privacy tools and infrastructure: Use Signal and other privacy-respecting alternatives. Host your own services or support privacy-focused providers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusion #&lt;/head&gt;
    &lt;p&gt;The irony is kinda painful: the continent that built GDPR to protect digital privacy now designs ChatControl to dismantle it systematically. What was once a fundamental right could become mandatory surveillance.&lt;/p&gt;
    &lt;p&gt;ChatControl represents a historic choice for ğŸ‡ªğŸ‡º Europe. Either we become the first democracy to normalize mass surveillance of private communications or we defend the digital rights that made Europe a global privacy leader.&lt;/p&gt;
    &lt;p&gt;This decision deserves close attention: authoritarian regimes worldwide are watching, ready to justify their own programs with: â€œEh, if Europe does it, why shouldnâ€™t we?â€&lt;/p&gt;
    &lt;p&gt;The next chapter unfolds on October 14, 2025. ğŸ˜‰&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45374500</guid><pubDate>Thu, 25 Sep 2025 16:01:41 +0000</pubDate></item><item><title>ChatGPT Pulse</title><link>https://openai.com/index/introducing-chatgpt-pulse/</link><description>&lt;doc fingerprint="9a26a651bae7d2f3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing ChatGPT Pulse&lt;/head&gt;
    &lt;p&gt;Now ChatGPT can start the conversation&lt;/p&gt;
    &lt;p&gt;We're building ChatGPT to help you reach your goals. Since ChatGPT launched, that's always meant coming to ask a question. There's magic in being able to simply ask and get answers to help you learn, create or solve problems. However that's limited by what you know to ask for and always puts the burden on you for the next step.&lt;/p&gt;
    &lt;p&gt;Today we're releasing a preview of ChatGPT Pulse to Pro users on mobile. Pulse is a new experience where ChatGPT proactively does research to deliver personalized updates based on your chats, feedback, and connected apps like your calendar. You can curate what ChatGPT researches by letting it know whatâ€™s useful and what isnâ€™t. The research appears in Pulse as topical visual cards you can scan quickly or open for more detail, so each day starts with a new, focused set of updates.&lt;/p&gt;
    &lt;p&gt;This is the first step toward a more useful ChatGPT that proactively brings you what you need, helping you make more progress so you can get back to your life. Weâ€™ll learn and improve from early use before rolling it out to Plus, with the goal of making it available to everyone.&lt;/p&gt;
    &lt;p&gt;ChatGPT can now do asynchronous research on your behalf. Each night, it synthesizes information from your memory, chat history, and direct feedback to learn whatâ€™s most relevant to you, then delivers personalized, focused updates the next day. These could look like follow-ups on topics you discuss often, ideas for quick, healthy dinner to make at home that evening, or next steps toward a longer-term goal such as training for a triathlon.&lt;/p&gt;
    &lt;p&gt;You can also connect Gmail and Google Calendar to provide additional context for more relevant suggestions. When Calendar is connected, ChatGPT might draft a sample meeting agenda, remind you to buy a birthday gift, or surface restaurant recommendations for an upcoming trip. These integrations are off by default and can be turned on or off anytime in settings.&lt;/p&gt;
    &lt;p&gt;Topics shown in Pulse also pass through safety checks to avoid showing harmful content that violates our policies.&lt;/p&gt;
    &lt;p&gt;You can ask for what youâ€™d like ChatGPT to research for you each day. Tap "curate" to request what you want to see in future editionsâ€”ask for a Friday roundup of local events, tips for learning a new skill, or something specific like "focus on professional tennis updates tomorrow." You can also give quick feedback with a thumbs up or thumbs down, and easily view or delete your feedback history. Over time, your guidance makes Pulse more personal and useful.&lt;/p&gt;
    &lt;p&gt;Every morning, ChatGPT delivers a curated set of the most relevant updates, giving you the information you need so you can get back to what matters most. Each update is available for that day only unless you save it as a chat or ask a follow-up question, which adds it to your conversation history. Expand any update to dive deeper, request next steps, or save it for later so you can move forward on goals with clear, timely information.&lt;/p&gt;
    &lt;p&gt;We partnered with college students in the ChatGPT Lab to gather early feedback and improve Pulse. One insight in particular we had was that many started to feel its utility once they started telling ChatGPT what they wanted to see. That insight underscored the importance of simple feedback, so we added more ways to share reactions and guide what appears. Here are a few of the studentsâ€™ favorite personalized updates.&lt;/p&gt;
    &lt;head rend="h3"&gt;Student use cases&lt;/head&gt;
    &lt;head rend="h3"&gt;Actionable recommendations&lt;/head&gt;
    &lt;p&gt;"Received this based on a conversation that I had yesterday that focused on calendar management/structuring PTO for my grant period in Taiwan. What it produced was several logical steps ahead of where I was at in the conversation. The update was incredibly helpful and exposed me to train and commute information I would have never come across or looked for otherwise."&lt;/p&gt;
    &lt;p&gt;Pulse is a preview and wonâ€™t always get things right. It aims to show you whatâ€™s most relevant and useful but you may still see suggestions that miss the mark. For example, you may get tips for a project you already completed. You can guide what shows up by telling ChatGPT directly. It remembers your feedback for next time and improves as it learns from real use.&lt;/p&gt;
    &lt;p&gt;Pulse is the first step toward a new paradigm for interacting with AI.&lt;/p&gt;
    &lt;p&gt;By combining conversation, memory, and connected apps, ChatGPT is moving from answering questions to a proactive assistant that works on your behalf. Over time, we envision AI systems that can research, plan, and take helpful actions for youâ€”based on your directionâ€”so that progress happens even when you are not asking.&lt;/p&gt;
    &lt;p&gt;Pulse introduces this future in its simplest form: personalized research and timely updates that appear regularly to keep you informed. Soon, Pulse will be able to connect with more of the apps you use so updates capture a more complete picture of your context. Weâ€™re also exploring ways for Pulse to deliver relevant work at the right moments throughout the day, whether itâ€™s a quick check before a meeting, a reminder to revisit a draft, or a resource that appears right when you need it.&lt;/p&gt;
    &lt;p&gt;As we expand to more apps and richer actions, ChatGPT will evolve from something you consult into something that quietly accelerates the work and ideas that matter to you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45375477</guid><pubDate>Thu, 25 Sep 2025 16:59:55 +0000</pubDate></item><item><title>Improved Gemini 2.5 Flash and Flash-Lite</title><link>https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/</link><description>&lt;doc fingerprint="bf7738879939489d"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, we are releasing updated versions of Gemini 2.5 Flash and 2.5 Flash-Lite, available on Google AI Studio and Vertex AI, aimed at continuing to deliver better quality while also improving the efficiency.&lt;/p&gt;
    &lt;p&gt;The latest version of Gemini 2.5 Flash-Lite was trained and built based on three key themes:&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;You can start testing this version today using the following model string: &lt;code&gt;gemini-2.5-flash-lite-preview-09-2025&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This latest 2.5 Flash model comes with improvements in two key areas we heard consistent feedback on:&lt;/p&gt;
    &lt;p&gt;Weâ€™re already seeing positive feedback from early testers. As Yichao â€˜Peakâ€™ Ji, Co-Founder &amp;amp; Chief Scientist at Manus, an autonomous AI agent, noted: â€œThe new Gemini 2.5 Flash model offers a remarkable blend of speed and intelligence. Our evaluation on internal benchmarks revealed a 15% leap in performance for long-horizon agentic tasks. Its outstanding cost-efficiency enables Manus to scale to unprecedented levelsâ€”advancing our mission to Extend Human Reach.â€&lt;/p&gt;
    &lt;p&gt;You can start testing this preview version today by using the following model string: &lt;code&gt;gemini-2.5-flash-preview-09-2025&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Over the last year, weâ€™ve learned that shipping preview versions of our models allows you to test our latest improvements and innovations, provide feedback, and build production-ready experiences with the best of Gemini. Todayâ€™s releases are not intended to graduate to a new, stable version but will help us shape our future stable releases, and allow us to continue iterating and bring you the best of Gemini.&lt;/p&gt;
    &lt;p&gt;To make it even easier to access our latest models while also reducing the need to keep track of long model string names, we are also introducing a &lt;code&gt;-latest&lt;/code&gt; alias for each model family. This alias always points to our most recent model versions, allowing you to experiment with new features without needing to update your code for each release. You can access the new previews using:&lt;/p&gt;
    &lt;code&gt;gemini-flash-latest&lt;/code&gt;
    &lt;code&gt;gemini-flash-lite-latest&lt;/code&gt;
    &lt;p&gt;&lt;lb/&gt;To ensure you have time to test new models, we will always provide a 2-week notice (via email) before we make updates or deprecate a specific version behind &lt;code&gt;-latest&lt;/code&gt;. These are just model aliases so the rate limits, cost, and features available may fluctuate between releases.&lt;/p&gt;
    &lt;p&gt;For applications that require more stability, continue to use &lt;code&gt;gemini-2.5-flash&lt;/code&gt; and &lt;code&gt;gemini-2.5-flash-lite&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We continue to push the frontier of what is possible with Gemini and this release is just another step in that direction. We will have more to share soon, but in the meantime, happy building!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45375845</guid><pubDate>Thu, 25 Sep 2025 17:20:56 +0000</pubDate></item><item><title>Athlon 64: How AMD turned the tables on Intel</title><link>https://dfarq.homeip.net/athlon-64-how-amd-turned-the-tables-on-intel/</link><description>&lt;doc fingerprint="e70d5115fd2265ff"&gt;
  &lt;main&gt;
    &lt;p&gt;22 years ago, on September 23, 2003, AMD changed the game for x86 once and for all. They released the Athlon 64 CPU, a chip that did something Intel didnâ€™t want. Intel didnâ€™t want to extend x86 to 64 bits. But when AMD did it, it forced Intel to clone AMD, rather than the other way around.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Intel didnâ€™t want to go 64-bit&lt;/head&gt;
    &lt;p&gt;Even in 2001, x86 had decades of baggage attached to it. It was a 32-bit architecture that had been extended from a 16-bit architecture. But that in turn had been extended from an 8-bit CPU design from 1972 that, believe it or not, originated at Datapoint, not Intel.&lt;/p&gt;
    &lt;p&gt;This was great for backward compatibility. 8-bit applications were very easy to port to x86 in the early 1980s, and those early DOS applications still ran flawlessly on modern systems 30 years later. For that matter, itâ€™s not impossible to get them running even today.&lt;/p&gt;
    &lt;p&gt;Removal of the ability to run 16-bit applications in 64-bit Windows was a design decision, not a technical limitation.&lt;/p&gt;
    &lt;p&gt;Intel wanted to start over to go 64-bit. Without having to worry about backward compatibility, they could design something that would be faster and more efficient. In theory at least, it would be able to scale higher in clock speed. And there was no question a new design would outperform a theoretical 64-bit x86 when running at the same speed because of efficiency.&lt;/p&gt;
    &lt;p&gt;And if you are cynical, there was one more motivation. If Intel could start over, they wouldnâ€™t have to worry about competing CPU designs, at least not for a very long time. The new design would be encumbered with so many patents, it might be 20 years before someone could clone it.&lt;/p&gt;
    &lt;p&gt;Keep in mind that in 2003, not only was AMD in the picture, but Transmeta was still in the picture, and Cyrix was fading but not completely gone.&lt;/p&gt;
    &lt;p&gt;Starting over with a new CPU architecture outright was massively attractive to Intel.&lt;/p&gt;
    &lt;p&gt;This new 64-bit architecture wasnâ€™t theoretical, either. Intel was producing it. It was called Itanium, and Intel first released it in June 2001.&lt;/p&gt;
    &lt;head rend="h2"&gt;AMDâ€™s risky bet and why they made it&lt;/head&gt;
    &lt;p&gt;AMD was well aware of the shortcomings of extending x86 to 64 bits. And they did it anyway. For them, the stakes were completely different.&lt;/p&gt;
    &lt;p&gt;AMD knew that if Itanium caught on, that would be the end for them as a CPU company, unless maybe they wanted to become just another ARM licensee. Being just another ARM licensee is more attractive in 2025 than it was in 2003.&lt;/p&gt;
    &lt;p&gt;But they could see Itanium wasnâ€™t catching on. It had its uses, and it was doing well enough in those niches, but Windows on Itanium was a non-starter. So much so, The Register called it â€œItanic.â€&lt;/p&gt;
    &lt;p&gt;AMD bet that there would be appeal in a 64-bit architecture that was fully backward compatible with x86 and natively ran 32-bit applications at full speed. People would be able to run 32-bit Windows and 32-bit applications on it if they needed to, and then when they were ready for 64-bit software, the hardware was there and ready to go. And they could continue to run 32-bit apps in 64-bit operating systems as long as needed to ease the transition.&lt;/p&gt;
    &lt;p&gt;The transition to 32 bits took a decade. AMD reasoned more people would be willing to upgrade to 64 bits if they made that transition as similar as the transition from the 286 to the 386 as possible.&lt;/p&gt;
    &lt;p&gt;They believed the market would willingly trade lower 64-bit performance in the long term for better 32-bit performance right away. They also believed that if Microsoft was willing to build Windows on Itanium, they would be willing to take a chance on 64-bit x86 as well.&lt;/p&gt;
    &lt;p&gt;So on September 23, 2003, AMD launched its Athlon 64, the first 64-bit x86 CPU.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why the Athlon 64 was a hit&lt;/head&gt;
    &lt;p&gt;AMD64 was everything AMD hoped it would be. It was backward compatible with 32-bit x86. The 64-bit builds of Windows werenâ€™t available immediately, and they didnâ€™t catch on immediately, but you cannot say nobody used them. People did, in fact, use them. In late 2005, I was in charge of administering the complimentary antivirus software that Charter Communications provided to its subscribers. Iâ€™m not going to say say someone called me every day wanting 64-bit antivirus for 64-bit Windows. But it did happen once a week.&lt;/p&gt;
    &lt;p&gt;The transition took at least as long as AMD expected. When I finally bought an Athlon 64 in 2011, I found native 64-bit software was still scarce. Iâ€™m an outspoken Firefox fan; the reason I briefly switched to Google Chrome was to get a 64-bit web browser.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Athlon 64 in the enterprise&lt;/head&gt;
    &lt;p&gt;A few months later, I got a better job with more pay and better growth potential. I canâ€™t talk a lot about the job, but I was administering a mission critical system that ran on Windows, mostly on Dell hardware. I mention Dell because they were exclusively an Intel vendor for years. Cofounder and longtime AMD CEO Jerry Sanders once said of Michael Dell, â€œI canâ€™t sell him a[n AMD] K6 no matter what I do.â€&lt;/p&gt;
    &lt;p&gt;It was the Athlon 64 that made Dell relent and finally start using AMD CPUs. Not only were they using them on desktop systems, but they were putting AMD CPUs in servers, an idea that would have been extremely controversial 5 years before. At least in the circles I ran in.&lt;/p&gt;
    &lt;p&gt;The Athlon 64 caught on because, in spite of its name, it was an outstanding 32-bit CPU. It was faster than an Intel CPU running at the same clock rate, and it used less power as well. The power consumption was the key to getting into the data center. The Intel name was a security blanket, even though AMD had been making x86 CPUs exactly as long as Intel. But certain decision makers bought Intel marketing and saw AMD as a second tier brand.&lt;/p&gt;
    &lt;p&gt;The thing is, when you have a data center with hundreds of systems in it, the money you save on a more efficient CPU really talks.&lt;/p&gt;
    &lt;p&gt;Replacing Intel Prescott-based servers with AMD64 servers was not a universally popular idea. But you could tell a difference when you were standing behind a rack full of Intel-based servers versus a rack full of AMD based servers. The Intels ran hotter.&lt;/p&gt;
    &lt;p&gt;From an uptime perspective, we couldnâ€™t see a difference. The performance metrics I collected showed there was a slight difference, and that difference was in AMDâ€™s favor. So the AMD critics quickly ate their words.&lt;/p&gt;
    &lt;head rend="h3"&gt;Intel giving in and cloning AMD64&lt;/head&gt;
    &lt;p&gt;In 2004, Intel wrote off the Itanium and cloned AMD64. They called it Intel64, but it was a blatant copy of the AMD implementation. A quirk in the agreements that allowed AMD to use the x86 instruction set also gave Intel the rights to use the AMD64 instructions. So there was nothing illegal about what Intel did. Itanium continued to see use in specialized applications, but Intel quietly discontinued it in 2020.&lt;/p&gt;
    &lt;p&gt;AMD and Intel have been chasing and catching each other ever since. One of them will pass the other for a CPU generation or two, and then they will change positions. Itâ€™s not terribly different from the situation in 1999 with the original Athlon, when AMD outperformed Intel for the first time. The question in everyoneâ€™s mind was whether they would do it a second time. The Athlon 64 was the second time.&lt;/p&gt;
    &lt;p&gt;It was a big step forward. Eight years before, AMD was trying to pass off a high-clocked 486 as a Pentium equivalent. With the Athlon 64, AMD was innovating.&lt;/p&gt;
    &lt;p&gt;David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45376605</guid><pubDate>Thu, 25 Sep 2025 18:09:47 +0000</pubDate></item><item><title>Redox OS Development Priorities for 2025/26</title><link>https://www.redox-os.org/news/development-priorities-2025-09/</link><description>&lt;doc fingerprint="3691901340131be1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Development Priorities for 2025/26&lt;/head&gt;
    &lt;head rend="h5"&gt;By Ron Williams on&lt;/head&gt;
    &lt;p&gt;Redox has made great strides over the past year, with notable improvements in stability, performance, and compatibility.&lt;/p&gt;
    &lt;p&gt;To give a big-picture perspective for where Redox development is headed, here is our view of priorities as of September, 2025. Obviously, we canâ€™t finish everything on this list in the next 15 months, but it would be nice to have people working on as many of these things as possible.&lt;/p&gt;
    &lt;head rend="h3"&gt;Redox Variants&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;â€œHosted Redoxâ€ as a Web Services Runtime, in a Virtual Machine&lt;/item&gt;
      &lt;item&gt;â€œRedox Serverâ€ for Edge and Cloud&lt;/item&gt;
      &lt;item&gt;â€œRedox Desktopâ€ for your daily driver&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Development Priorities&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Building Redox on Redox&lt;/item&gt;
      &lt;item&gt;Compliance and Compatibility&lt;/item&gt;
      &lt;item&gt;Programming Language and Build System Support&lt;/item&gt;
      &lt;item&gt;Performance&lt;/item&gt;
      &lt;item&gt;Security&lt;/item&gt;
      &lt;item&gt;Hardware Support&lt;/item&gt;
      &lt;item&gt;COSMIC, Wayland, and GPU Acceleration&lt;/item&gt;
      &lt;item&gt;Accessibility&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How can you help?&lt;/head&gt;
    &lt;p&gt;Here are some ways you can help us move Redox closer to our goals.&lt;/p&gt;
    &lt;head rend="h3"&gt;Donating&lt;/head&gt;
    &lt;p&gt;If you would like to support Redox development, please consider donating or buying some merch! We are currently funding a community support/researcher/documentation person, a part-time build engineer, and our Redox Summer of Code program for students, all from donations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Contributing&lt;/head&gt;
    &lt;p&gt;If you would like to help with Redox development or documentation, please read the CONTRIBUTING page and join us on Redox Chat. Try to connect with others who are interested in one of the major areas, create a tracking issue for the work to be done, and start checking things off.&lt;/p&gt;
    &lt;head rend="h3"&gt;Redox is Hiring!&lt;/head&gt;
    &lt;p&gt;Redox is looking for an experienced kernel/core developer. Check out the job description in the July report. Please contact us if you think you are the right person.&lt;/p&gt;
    &lt;p&gt;As well, we are frequently applying for grants. We currently have three students working on grants from NGI Zero and NLnet.&lt;/p&gt;
    &lt;p&gt;If you are a talented Rust developer interested in obtaining a grant to work on Redox, get in touch with us and we will do our best to help. You can also apply for grants for â€œRedox-adjacentâ€ work on your own.&lt;/p&gt;
    &lt;p&gt;Send an email to president@redox-os.org, cc info@redox-os.org, with a resume/CV or links to your open source work, and let us know what you are interested in doing.&lt;/p&gt;
    &lt;head rend="h1"&gt;Redox Variants&lt;/head&gt;
    &lt;head rend="h2"&gt;Hosted Redox as a Web Services Runtime, in a Virtual Machine&lt;/head&gt;
    &lt;p&gt;One of the opportunities we would like to pursue is to use Redox as a hosted runtime environment for web services. The goal is to run your web services in a secure Redox environment, but to have the hardware compatibility and management tools delegated to a Linux host. We believe that this is one of the quickest paths to getting Redox into real-world use, and to help us validate it as a secure platform.&lt;/p&gt;
    &lt;p&gt;The set up would be something like the following.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A Linux server&lt;/item&gt;
      &lt;item&gt;A QEMU Virtual Machine, with KVM, VirtioFS and a virtualized compute acceleration interface like virglrenderer&lt;/item&gt;
      &lt;item&gt;Redox running in QEMU, with some combination of these applications &lt;list rend="ul"&gt;&lt;item&gt;A web server and content manager&lt;/item&gt;&lt;item&gt;A database&lt;/item&gt;&lt;item&gt;WASM/WASI microservices&lt;/item&gt;&lt;item&gt;Custom web services applications of your choice&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We will need the following improvements to Redox to make this work.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A faster network stack, including Ring Buffer I/O&lt;/item&gt;
      &lt;item&gt;virtiofs&lt;/item&gt;
      &lt;item&gt;virglrenderer&lt;/item&gt;
      &lt;item&gt;Improvements to our shared memory and IPC&lt;/item&gt;
      &lt;item&gt;General compatibility, performance, security and stability testing&lt;/item&gt;
      &lt;item&gt;Management tools to simplify the use of the system&lt;/item&gt;
      &lt;item&gt;Repeatable builds&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It would be nice to experiment with making virtualized devices like the GPU or VirtioFS available as a relibc/Redox-RT service, although that is not a major goal for 2026. This would be a configurable option, where the web service has exclusive use of the virtualized device. To the extent possible, the API should be the same whether the virtualized device is available as a library service or as a scheme-type service.&lt;/p&gt;
    &lt;head rend="h2"&gt;Redox Server for Edge and Cloud&lt;/head&gt;
    &lt;p&gt;The most valuable application for Redox is as a secure host for web services, initially as a private server or edge server, and eventually as a multi-tenant cloud server. Redox can provide lightweight but secure sandboxing of web servers, databases and web service applications. We plan to provide heavyweight containerization in the longer-term future, with complete isolation between each tenant in a multi-tenant environment.&lt;/p&gt;
    &lt;p&gt;This represents a substantial effort, but we plan to tackle it in phases to demonstrate value.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Phase 1 - Redox running on bare metal in a single tenant server/edge scenario&lt;/item&gt;
      &lt;item&gt;Phase 2 - Multi-tenant Redox with lightweight containers for WASM microservices and other supported applications&lt;/item&gt;
      &lt;item&gt;Phase 3 - Multi-tenant Redox with heavyweight containers and support for arbitrary applications&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Redox Desktop for your daily driver&lt;/head&gt;
    &lt;p&gt;Redox Desktop will benefit from all the features of Redox Server, but it also needs to be usable for everyone. And Redox security must work in a natural way for the average user.&lt;/p&gt;
    &lt;p&gt;The COSMIC Desktop is being developed at System76, with Jeremy Soller as principal engineer. ItÃ¢s an open source Linux desktop environment that is written almost entirely in Rust.&lt;/p&gt;
    &lt;p&gt;Redox currently supports several key applications, including COSMIC Terminal, COSMIC Files, COSMIC Editor, COSMIC Reader, and COSMIC Store. However, a few important parts of the COSMIC environment are missing due to our lack of Wayland support.&lt;/p&gt;
    &lt;p&gt;Once Wayland is supported, we will be able to support almost the entire COSMIC Desktop. We will also be able to add features for accessibility, i18n/l10n, and other improvements to the desktop experience.&lt;/p&gt;
    &lt;p&gt;We then plan to experiment with â€œsandboxing by defaultâ€, restricting the access of applications to only the resources that they should normally require. We would like to create a consistent experience for sandboxed applications, requesting greater access, and being aware of when you are more-privileged or less-privileged. There are several initiatives in this area, and if we can partner with someone to build a sandboxed desktop, it would be a valuable opportunity for us.&lt;/p&gt;
    &lt;head rend="h1"&gt;Development Priorities&lt;/head&gt;
    &lt;head rend="h2"&gt;Building Redox on Redox&lt;/head&gt;
    &lt;p&gt;Although this has been an important goal for a long time, we are getting closer to supporting development for Redox, on Redox. Having the ability to edit, compile and run your code without having to cross-compile and generate bootable images will make development much faster and more pleasant.&lt;/p&gt;
    &lt;p&gt;I have done some small-scale development on Redox, debugging test suites in C and making one-off changes. Itâ€™s quite pleasant, although itâ€™s currently easier to mirror the changes manually in a host editor than to move the files back and forth between Redox and the host file system.&lt;/p&gt;
    &lt;head rend="h3"&gt;How it will work&lt;/head&gt;
    &lt;p&gt;In the short/medium-term, Redox developers will be running Redox in QEMU or VirtualBox on their Linux, Windows or MacOS laptops or desktops.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Initially, developers will need to use the GitLab server as their trusted storage, as work in progress might be lost if there is a Redox failure of some sort.&lt;/item&gt;
      &lt;item&gt;We hope to add a VirtioFS file system service so Redox can access the host files. This will greatly improve the developer experience.&lt;/item&gt;
      &lt;item&gt;And, hopefully after a few months of use as a â€œdaily driverâ€ for developers, we will have the confidence that the Redox file system can be used for persistent storage, and you can push to GitLab when you reach a good stopping point.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a small number of systems, we will be able to support Redox development on real hardware. The system will need to have hardware that works well with Redox, including a wired Ethernet connection. But we hope to have at least a few people doing development on real hardware before the end of 2026.&lt;/p&gt;
    &lt;head rend="h3"&gt;Things to do&lt;/head&gt;
    &lt;p&gt;Here are some of the challenges we need to address to make Self-Hosting a reality.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Network performance needs to improve - we have an NGI Zero &amp;amp; NLnet funded project to implement Ring Buffers for disk I/O. We need to implement ring buffers in our network stack as well, once the disk I/O work stabilizes.&lt;/item&gt;
      &lt;item&gt;Move to the upstream Rust compiler - we have mostly solved this, and just need to finish up.&lt;/item&gt;
      &lt;item&gt;Rustc and Cargo reliability - due to past performance issues and a few challenging bugs, we have not had Cargo and the Rust compiler working consistently on Redox. We could use help fighting through the bugs while we wait for the networking improvements.&lt;/item&gt;
      &lt;item&gt;Build system improvements - we have removed a lot of legacy build system code and scripts, and now we are in a position to optimize our custom build tools.&lt;/item&gt;
      &lt;item&gt;Workflow improvements - self-hosting is a different experience from cross-compiling, and we will need to tweak our package manager and some build tools to make the development cycle more straightforward.&lt;/item&gt;
      &lt;item&gt;Redox improvements - self-hosting will be our first opportunity to use Redox as a daily driver, and we expect to find a few bugs or incomplete features that need polishing, and probably one or two unexpected performance bottlenecks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Compilers and build systems are a real torture test for operating systems, with many processes spawned and lots of files being opened and closed, and lots of small-file reads and writes. Getting Redox working smoothly for development will also greatly improve its general stability.&lt;/p&gt;
    &lt;head rend="h3"&gt;Debugging&lt;/head&gt;
    &lt;p&gt;Currently, Redox supports limited debugging with &lt;code&gt;gdb&lt;/code&gt; running on the Linux host.
This works well for debugging the kernel,
but it is more challenging when debugging applications.&lt;/p&gt;
    &lt;p&gt;We donâ€™t have a reasonable self-hosted debugger setup yet, as Redoxâ€™s &lt;code&gt;ptrace&lt;/code&gt; implementation needs to be reworked.
Thatâ€™s a complex enough project that we consider it a secondary goal for 2026.
If someone is up for a real challenge, please let us know.
Or, if you have ideas on how to improve debugging of user space applications and services
using &lt;code&gt;gdb&lt;/code&gt; on the Linux host, please get in touch.&lt;/p&gt;
    &lt;head rend="h2"&gt;Compliance and Compatibility&lt;/head&gt;
    &lt;p&gt;Redox is not intended to be 100% POSIX compliant, or 100% source compatible with Linux, but we want to come close where itâ€™s practical. Porting Linux applications to Redox has been the main driver for compatibility, but we have recently set up some compliance tests. Using a test-driven approach, rather than just focusing on porting, will speed up porting, with fewer non-compliance bugs to track down. There are also some chunks of functionality that are medium-high priority that we would love to have help fixing.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Controlling Terminal needs a proper implementation&lt;/item&gt;
      &lt;item&gt;There are several functions related to timers and alarms that need both POSIX and Linux functionality&lt;/item&gt;
      &lt;item&gt;Many other examples will crop up as we do more compliance testing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We would also like to polish our Rust compatibility. If you would like to set up tests for the Rust &lt;code&gt;std::&lt;/code&gt; library or other popular crates,
please join us and we can work together to add the tests to our Redox test suites.&lt;/p&gt;
    &lt;head rend="h2"&gt;Programming Language and Build Systems Support&lt;/head&gt;
    &lt;p&gt;Redox intends to support applications developed in any language. However, there are some tricky bits. Rust and C/C++ are well-supported, but we have trouble with languages that come with their own runtime. We need to add some fairly complex hooks in &lt;code&gt;relibc&lt;/code&gt; (our &lt;code&gt;libc&lt;/code&gt; implementation),
or provide a Redox-compatible implementation to support those runtimes,
and then we need to port and test the languages.&lt;/p&gt;
    &lt;p&gt;We can currently run Python programs using RustPython, but it would be nice if we could support the official implementation. We have started porting a couple of JavaScript engines, and we have work underway to support Go.&lt;/p&gt;
    &lt;p&gt;If you have some expertise in x86, ARM and RISC-V assembly, as well as language runtimes, and would like to get into the details of relibc and Redoxâ€™s runtime support for applications, please give us a hand.&lt;/p&gt;
    &lt;p&gt;We also need to port the build tools, scripting languages, and utilities used in build systems. We have decent support for shell scripts, GNU Make, and the most common utilities. But we can use help figuring out if we can get build systems for various libraries and applications working, and what additional utilities are required.&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance&lt;/head&gt;
    &lt;p&gt;Last year, we made really substantial improvements to Redoxâ€™s file system performance, thanks to James Matlik (RedoxFS), Jacob Lorentzon (Kernel) and Jeremy Soller (Disk I/O), which got us to the point where Redox can be usable in realistic scenarios. We are continuing to improve performance, as described above, so much so that by the end of next year, performance should not be a roadblock for using Redox.&lt;/p&gt;
    &lt;p&gt;We do want to continue to make Redox go faster, but that work will be incremental going forward. Hereâ€™s a summary of our upcoming performance work (including things mentioned elsewhere).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ring Buffers for the disk and file system&lt;/item&gt;
      &lt;item&gt;Direct process switching (context switching to the target driver with no scheduler intervention) as part of the Ring Buffers work&lt;/item&gt;
      &lt;item&gt;Ring Buffers for the network stack&lt;/item&gt;
      &lt;item&gt;Scheduler improvements (EEVDF, and maybe others)&lt;/item&gt;
      &lt;item&gt;Ongoing improvements to RedoxFS&lt;/item&gt;
      &lt;item&gt;Hardware-accelerated graphics&lt;/item&gt;
      &lt;item&gt;Performance benchmarking - we would like someone to help curate and improve our benchmarking&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Security&lt;/head&gt;
    &lt;p&gt;Redox is implementing Capability Based Security as a fundamental part of how files and resources are accessed. Over the next 12 months, the underlying representation of file descriptors will be replaced by capabilities.&lt;/p&gt;
    &lt;p&gt;The first stage of this work is&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;to implement the machinery to create capabilities and transfer them between processes&lt;/item&gt;
      &lt;item&gt;to have file references be relative to some capability (see openat(2))&lt;/item&gt;
      &lt;item&gt;to have every program running in a resource namespace that can be restricted as appropriate&lt;/item&gt;
      &lt;item&gt;to provide POSIX-style paths and file descriptors as a layer on top of capabilities&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There will be lots of followup work, to implement Capsicum-style security and mechanisms for requesting additional privileges, and to make security easy to use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hardware Support&lt;/head&gt;
    &lt;p&gt;To run Redox on real hardware, we need compatible drivers for the full range of system functionality. Linux has literally hundreds of people working on device drivers of all kinds, and we donâ€™t have that luxury. So we will be focusing on â€œrecommendedâ€ hardware.&lt;/p&gt;
    &lt;p&gt;For Redox Server, we will have to partner with a small number of server vendors, and develop drivers for that particular hardware. Whether itâ€™s x86_64/amd64, Aarch64/ARM64, or RISC-V 64, we will have to find a vendor that will provide either funding or developers (or both) to create optimized drivers for disk, network, compute acceleration, as well as for system management and other functions.&lt;/p&gt;
    &lt;p&gt;For Redox Desktop, we will support a very small number of desktop and laptop systems for our own development purposes, focusing on drivers that are likely to be compatible with the maximum number of real-world systems. For emerging standards and less common devices, we will look for help from the community to build out a more complete set of drivers.&lt;/p&gt;
    &lt;p&gt;Here are some of the key efforts that we are hoping to complete by the end of 2026.&lt;/p&gt;
    &lt;head rend="h3"&gt;Firmware Support and Hardware Management&lt;/head&gt;
    &lt;p&gt;We need to rework our ACPI support, as the implementation we have needs better integration with the drivers and driver management. As well, Isaac Woods and the Rust-OSDev team have developed an entirely new AML parser, and improved the design of their acpi crate. We hope to take full advantage of their implementation.&lt;/p&gt;
    &lt;p&gt;The goal for 2026 is to ensure we can configure and run the system correctly, with full system management as stretch goals and future work.&lt;/p&gt;
    &lt;p&gt;We are designing our boot/init to handle non-APCI firmware, and we could use help developing drivers for IEEE-1275 and other standards, as well as getting access to hardware that we can use for testing.&lt;/p&gt;
    &lt;head rend="h3"&gt;WiFi&lt;/head&gt;
    &lt;p&gt;WiFi support is a whole collection of functionality, and it is not something we have tackled yet. We would appreciate some help porting an existing written-in-Rust WiFi driver stack, if an appropriate one can be found. Itâ€™s a pretty big project.&lt;/p&gt;
    &lt;head rend="h3"&gt;USB and I2C Support&lt;/head&gt;
    &lt;p&gt;Redox has USB drivers for keyboard, mouse, disk, and hub, but full support for USB on all the varied hardware out there remains a challenge. We could use help with improving our USB implementation, seeing if we can collaborate with other written-in-Rust implementations, adding new devices, and testing on real hardware.&lt;/p&gt;
    &lt;p&gt;We donâ€™t have an I2C driver, and would love to collaborate with someone on creating one.&lt;/p&gt;
    &lt;head rend="h3"&gt;IOMMU and Virtualization&lt;/head&gt;
    &lt;p&gt;It is our intent that Redox will use IOMMU and hardware virtualization features wherever they are available, to protect against rogue hardware and drivers. However, we have not implemented support for IOMMU yet. We would like to at least get started on this in 2026.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hosted Linux for Driver Support&lt;/head&gt;
    &lt;p&gt;In order to avoid porting thousands of device drivers, we would like to port QEMU to Redox, then run a stripped-down Linux to provide device drivers for less common and older devices. The interface between Redox and Linux-in-QEMU will be designed to be secure, so this approach should give us reasonable safety.&lt;/p&gt;
    &lt;p&gt;This is an experimental approach, and our goal for 2026 is to determine if it is feasible and useful. We want to be able to run QEMU on Redox regardless, so please join us if you want to help out.&lt;/p&gt;
    &lt;head rend="h2"&gt;COSMIC, Wayland, and GPU Acceleration&lt;/head&gt;
    &lt;p&gt;Redox uses the COSMIC Desktop, although we donâ€™t currently support the COSMIC Compositor, so we are unable to use a lot of the COSMIC features. Porting Wayland will be a big step towards supporting the COSMIC Compositor, so thatâ€™s very high on our list of things to do.&lt;/p&gt;
    &lt;p&gt;The ability to send file descriptors over our Unix Domain Sockets was implemented in one of our Summer of Code projects (thanks Ibuki!), which represents a big step forward.&lt;/p&gt;
    &lt;p&gt;We are still missing some functionality in &lt;code&gt;relibc&lt;/code&gt;,
including timerfds and a few other things,
although most of the underlying machinery exists,
so if you want to help, please join our chat and let us know.&lt;/p&gt;
    &lt;p&gt;We are also looking for a full D-Bus implementation in Rust that can be ported to Redox.&lt;/p&gt;
    &lt;p&gt;For GPU acceleration, our first goal is to support Virtio graphics acceleration, probably using virglrenderer. Then Intel graphics will probably be the easiest next step, with drivers for AMD and NVIDIA graphics dependent on having access to the right information.&lt;/p&gt;
    &lt;head rend="h2"&gt;Accessibility and Internationalization&lt;/head&gt;
    &lt;p&gt;So far, Redox has not accomplished as much as we would like with either Internalization or Accessibility. We have gotten a start in the last few months but thereâ€™s lots to do.&lt;/p&gt;
    &lt;head rend="h3"&gt;Internationalization&lt;/head&gt;
    &lt;p&gt;Our goal with Internationalization (â€œi18nâ€) is to align with POSIX where possible, and we encourage ideas that go beyond the POSIX standard. Redox is UTF-8 natively, but we allow for opening non-UTF-8 file names on non-RedoxFS file systems.&lt;/p&gt;
    &lt;p&gt;Some of the areas that need work are&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Localization APIs and settings storage&lt;/item&gt;
      &lt;item&gt;Non-US keyboard support (started but not complete)&lt;/item&gt;
      &lt;item&gt;Non-Latin text display (COSMIC supports this, but Redox does not use it yet)&lt;/item&gt;
      &lt;item&gt;Timezones, numeric and currency display, other LC_* types&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Having team members with expertise in i18n/l10n support is would be a great boost to Redox.&lt;/p&gt;
    &lt;head rend="h3"&gt;Accessibility&lt;/head&gt;
    &lt;p&gt;We have started a discussion group for Accessibility. One of our contributors, Bendeguz Pisch, has been working on a screen reader solution for Redox. More help would be appreciated. We would ideally like a written-in-Rust solution with an MIT or other permissive license, but a good screen reader is not a small undertaking, and requires expertise in meeting the expectations of users.&lt;/p&gt;
    &lt;p&gt;There are many other areas of accessibility to address, and we would like to find contributors that can help us ensure that Redox meets the needs of as many users as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Join Us!&lt;/head&gt;
    &lt;p&gt;Thereâ€™s lots of exciting work ahead, and a great team already working on it. If you would like to be part of the team, or just listen in to the conversation, please join us on Redox Chat.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45376895</guid><pubDate>Thu, 25 Sep 2025 18:29:50 +0000</pubDate></item><item><title>Tracing JITs in the Real World CPython Core Dev Sprint</title><link>https://antocuni.eu/2025/09/24/tracing-jits-in-the-real-world--cpython-core-dev-sprint/</link><description>&lt;doc fingerprint="23330e932cf522d9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Tracing JITs in the real world @ CPython Core Dev SprintÂ¶&lt;/head&gt;
    &lt;p&gt;Last week I got to take part in the CPython Core Developer Sprint in Cambridge, hosted by ARM and brilliantly organized by Diego Russo -- about ~50 core devs and guests were there, and I was excited to join as one of the guests.&lt;/p&gt;
    &lt;p&gt;I had three main areas of focus:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;C API: this was a follow up of what we discussed at the C API summit at EuroPython. The current C API is problematic, so we are exploring ideas for the development of PyNI (Python Native Interface), whose design will likely be heavily inspired by HPy. It's important to underline that this is just the beginning and the entire process will require multiple PEPs.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;fancycompleter This is a small PR which I started months ago, to enable colorful tab completions within the Python REPL. I wrote the original version of fancycompleter 15 years ago, but colorful completions work only in combination with PyREPL. Now PyREPL is part of the standard library and enabled by default, so we can finally upstream it. I hope to see it merged soon.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"JIT stuff": I spent a considerable amount of time talking to the people who are working on the CPython JIT (in particular Mark, Brandt, Savannah, Ken Jin and Diego). Knowledge transfer worked in both ways: I learned a lot about the internal details of CPython's JIT, and conversely I shared with them some of the experience, pain points and gut feelings which I got by working many years on PyPy.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In particular, on the first day I presented a talk titled Tracing JIT and real world Python (slides and source code).&lt;/p&gt;
    &lt;p&gt;What follows is an annotated version of the slides.&lt;/p&gt;
    &lt;p&gt;CPython's new JIT and PyPy's JIT share fundamental similarities, as they're both tracing JITs.&lt;/p&gt;
    &lt;p&gt;I spent ~7 years of my career optimizing existing code for PyPy at a high-frequency trading firm, and I realized that I'm probably one of the few people in the world with actual experience in optimizing real world Python code for a tracing JIT.&lt;/p&gt;
    &lt;p&gt;I expect that some of the challenges which I faced will still be valid also for CPython, and I wanted to share my experience to make sure that CPython core devs are aware of them.&lt;/p&gt;
    &lt;p&gt;One lesson which I learned is that the set of benchmarks in &lt;code&gt;pyperformance&lt;/code&gt; are
a good starting point, but they are not entirely representative of what you
find in the wild.&lt;/p&gt;
    &lt;p&gt;The main goal of the talk is not to present solutions to these problems, but to raise awareness that they exist.&lt;/p&gt;
    &lt;p&gt;Until now CPython's performance has been particularly predictable, there are well established "performance tricks" to make code faster, and generally speaking you can mostly reason about the speed of a given piece of code "locally".&lt;/p&gt;
    &lt;p&gt;Adding a JIT completely changes how we reason about performance of a given program, for two reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;JITted code can be very fast if your code conforms to the heuristics applied by the JIT compiler, but unexpectedly slow(-ish) otherwise;&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;the speed of a given piece of code might depend heavily on what happens elsewhere in the program, making it much harder to reason about performance locally.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The end result is that modifying a line of code can significantly impact seemingly unrelated code. This effect becomes more pronounced as the JIT becomes more sophisticated.&lt;/p&gt;
    &lt;p&gt;The CPython JIT is still pretty new and doesnâ€™t give huge speedups yet. I expect that as it gets faster, its performance will start looking more and more like PyPyâ€™s.&lt;/p&gt;
    &lt;p&gt;I delivered this talk at the Core Dev Sprint: I expected my audience to be familiar with CPython's JIT, and wanted to draw parallels with PyPy's one.&lt;/p&gt;
    &lt;p&gt;Since the audience of this blog is different, let me briefly explain CPython's JIT first.&lt;/p&gt;
    &lt;p&gt;The explanations of both JITs are necessarily short, incomplete and highly simplified.&lt;/p&gt;
    &lt;head rend="h4"&gt;CPython JIT 101Â¶&lt;/head&gt;
    &lt;p&gt;Python source code is turned into bytecode. Bytecode is a sequence of "opcodes" (&lt;code&gt;LOAD_FAST&lt;/code&gt;, &lt;code&gt;BINARY_OP&lt;/code&gt;, etc.), and the CPython VM is an
interpreter for those opcodes. Historically the VM was written by hand, and the
main loop consisted of a big &lt;code&gt;switch&lt;/code&gt; statement which executed the code
corresponding to each opcode.&lt;/p&gt;
    &lt;p&gt;Nowadays things are different: the opcodes are written in a special DSL and the main interpreter loop is generated from this DSL. Additionally, the DSL describes how each opcode can be decomposed into multiple "microops".&lt;/p&gt;
    &lt;p&gt;When the interpreter detects a "hot loop", it starts the JIT. The JIT retroactively looks at the opcodes which were executed in the last iteration of the loop, and creates a "linear trace" which contains the equivalent microops. This process is called trace projection and the result is an unoptimized trace of microops.&lt;/p&gt;
    &lt;p&gt;Then, the JIT can produce an optimized trace, by reordering and removing redundant microops. Finally, the optimized trace is turned into executable code using the "copy &amp;amp; patch" technique.&lt;/p&gt;
    &lt;head rend="h4"&gt;PyPy JIT 101Â¶&lt;/head&gt;
    &lt;p&gt;CPython's Python interpreter is written in C, and then compiled into an executable by &lt;code&gt;gcc&lt;/code&gt; (or any other C compiler).&lt;/p&gt;
    &lt;p&gt;Similarly, PyPy's Python interpreter is written in RPython, and then compiled into an executable by &lt;code&gt;rpython&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Under the hood, &lt;code&gt;rpython&lt;/code&gt; applies two separate transformations to the source
code:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;it turns each function into C code, which is then fed to&lt;/p&gt;&lt;code&gt;gcc&lt;/code&gt;to get the final executable;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;it turns each function into "jitcodes", which is a way to represent RPython's IR (internal representation). For each RPython function, the final&lt;/p&gt;&lt;code&gt;./pypy&lt;/code&gt;executable contains its compiled representation (generated by GCC) and its jitcode representation (embedded as static data into the executable).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In a way, RPython's jitcodes are equivalent to CPython's microops, as they are a low-level representation of the logic of each opcode.&lt;/p&gt;
    &lt;p&gt;When the interpreter detects a hot loop, it enters trace recording mode, which is essentially an interpreter which executes the jitcodes: the result is a linear unoptimized trace of all the jitcodes which were actually executed.&lt;/p&gt;
    &lt;p&gt;Similarly to CPython, PyPy then produces an optimized trace, which is then sent to the JIT backend for actual native code generation.&lt;/p&gt;
    &lt;p&gt;Tracing JITs work by recording a trace of all microops which are executed. The optimizer can then reason about what happens in the trace and remove unneeded operations.&lt;/p&gt;
    &lt;p&gt;However, sometimes we encounter some operation which is a black box from the point of view of the tracer: we call them "trace blocker", because the tracing JIT cannot see through them. In the case of CPython, this happens for example, whenever we call any function implemented in C (because it doesn't have any correspondent "microop").&lt;/p&gt;
    &lt;p&gt;This is a simple function that computes &lt;code&gt;pi&lt;/code&gt;, generated by ChatGPT.  Its
precise content is not important: what matters is that it's a nice purely
numerical loop that the PyPy JIT can optimize very well.&lt;/p&gt;
    &lt;p&gt;Same function as above, with a call to &lt;code&gt;hic_sunt_leones()&lt;/code&gt;. This is actually
an empty function which does absolutely nothing, but annotated in a
special way so that the PyPy JIT cannot "enter" it, so it effectively behaves
as trace blocker.&lt;/p&gt;
    &lt;p&gt;In this example we use the special &lt;code&gt;pypyjit.residual_call&lt;/code&gt; to simulate a trace
blocker, but in real life we get it whenever we have a call to any
non-traceable function, in particular C extensions.&lt;/p&gt;
    &lt;p&gt;The clean version runs 42x faster on PyPy than CPython - that's the JIT working perfectly. But with just one untraceable function call added to the loop, PyPy slows down to only 1.8x faster than CPython. That single line destroyed most of the JIT's effectiveness!&lt;/p&gt;
    &lt;p&gt;This happens because after the call the optimizer no longer knows whether its assumptions about the world are still true, and thus must be much more conservative.&lt;/p&gt;
    &lt;p&gt;I fear that for CPython, this will turn out to be a much bigger problem than for PyPy, for two reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;nowadays it's virtually impossible to run Python code without using any C extension, either directly or indirectly.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;by construction, PyPy's JIT can see much more than CPython's JIT. Remember the slide about "jitcodes": any RPython function gets a "jitcodes" equivalent, which means that the JIT can automatially trace inside builtins and internals of the interpreter, whereas CPython can trace only inside pure python code.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, PyPy's JIT can trace through &lt;code&gt;range()&lt;/code&gt;, &lt;code&gt;zip&lt;/code&gt;, and &lt;code&gt;enumerate()&lt;/code&gt;
automatically. CPython's JIT currently cannot because they are implemented in
C. CPython could add special cases for these common functions, but the
general approach doesn't scale.&lt;/p&gt;
    &lt;p&gt;The second big problem is what I call "data driven control flow". This example has been autogenerated by ChatGPT and it's completely silly, but it's a good representation of what happens in real life code.&lt;/p&gt;
    &lt;p&gt;In this example, &lt;code&gt;fn&lt;/code&gt; takes 9 variables, each of them can be &lt;code&gt;None&lt;/code&gt; or a
number. The function starts with a sequence of &lt;code&gt;if &amp;lt;var&amp;gt; is None: ...&lt;/code&gt;. The
function is then called repeatedly in a loop.&lt;/p&gt;
    &lt;p&gt;One of the assumption of tracing JITs is that control flow tends to stay on the "hot path", and that it's enough to optimize that to get good performance.&lt;/p&gt;
    &lt;p&gt;But in a case like this, each combination of &lt;code&gt;None&lt;/code&gt;ness selects a different
path, and if we assume the data is evenly distributed, we find out that
there is no hot path.&lt;/p&gt;
    &lt;p&gt;Let's see what happens when we execute on CPython and PyPy:&lt;/p&gt;
    &lt;p&gt;PyPy without JIT is "only" 2.3x slower than CPython, but when we enable the JIT, it becomes much worse. This happens because of an exponential explosion of code paths seen by the JIT.&lt;/p&gt;
    &lt;p&gt;In a normal compiler, an &lt;code&gt;if&lt;/code&gt; statement is compiled as a diamond, and the
control flow merges after each &lt;code&gt;if&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;A tracing JIT by definition follows what's happening during a concrete execution, so it sees only a concrete path in the control flow, with "guards" to ensure correctness:&lt;/p&gt;
    &lt;p&gt;When &lt;code&gt;guard(a is None)&lt;/code&gt; fails enough times, we create a "bridge" and record
another linear trace, following again the concrete control flow that happens
now:&lt;/p&gt;
    &lt;code&gt;          guard(a is None) ----&amp;gt; FAIL (side exit)
            /                         \
           /                           \
        a = 0                          pass
           \                             \
            \                             \
    guard(b not None)              guard(b not None)
            /                             /
           /                             /
        b = 0                         b = 0
           \                             \
            \                             \
           ...                           ...
&lt;/code&gt;
    &lt;p&gt;Note how &lt;code&gt;b = 0&lt;/code&gt; is effectively duplicated now. By design, PyPy's JIT never
merges execution flow.&lt;/p&gt;
    &lt;p&gt;Looking inside &lt;code&gt;PYPYLOG&lt;/code&gt; confirms our theory: we get "exponential
tracing". The JIT has to compile separate optimized code for every unique
combination of which parameters are None and which aren't. With 9 parameters,
that could be up to 512 different combinations!&lt;/p&gt;
    &lt;p&gt;One possible mitigation is to rewrite conditional code to be "branchless" - using arithmetic tricks instead of if statements. But this makes code ugly and unreadable, and it's not always possible.&lt;/p&gt;
    &lt;p&gt;Despite years of working on this, I never found a really good solution. There were cases in which we had to continue running some piece of code on CPython because I never managed to make the PyPy version faster.&lt;/p&gt;
    &lt;p&gt;This pattern happens quite a lot, although often is more subtle: in this silly example all the &lt;code&gt;if&lt;/code&gt;s are nicely grouped together at the start, but in a long
trace they can be scattered in multiple places, and any kind of control flow
contributes to the problem, not only &lt;code&gt;if&lt;/code&gt;s. In Python, this includes any kind
of dynamic dispatch, exceptions, etc.&lt;/p&gt;
    &lt;p&gt;One possible solution for CPython's JIT is to try to merge (some) traces to avoid or limit the exponential explosion. However, it is worth underlining that tracing JITs shine precisely when they can optimize a long linear trace: if you try to compile shorter traces, you might quickly end up in a situation which is equivalent to the "trace blocker" problem described earlier.&lt;/p&gt;
    &lt;p&gt;I suspect this might be a fundamental limitation of tracing JITs.&lt;/p&gt;
    &lt;p&gt;Compared to the other two problems, this is less serious, but it's worth mentioning because of prevalence of &lt;code&gt;async&lt;/code&gt; (and thus implicitly generators)
in modern Python.&lt;/p&gt;
    &lt;p&gt;Here's another silly function that counts Pythagorean triples using nested loops. This is our baseline version using plain loops.&lt;/p&gt;
    &lt;p&gt;Here's the same algorithm refactored to use a generator function for the nested iteration. The "state of iteration" is implicitly stored inside the local variables of frame object associated to the &lt;code&gt;range_product&lt;/code&gt; generator.&lt;/p&gt;
    &lt;p&gt;Here's the same functionality implemented as a traditional iterator class. The "state of iteration" is explicitly stored as attributes of &lt;code&gt;RangeProductIter&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;On CPython, the generator version is ~29% slower than the explicit loops. The iterator class is much slower, as one would intuitively expect.&lt;/p&gt;
    &lt;p&gt;However, on PyPy we see different results: &lt;code&gt;RangeProductIter&lt;/code&gt; is basically
same speed as the baseline, while the generator version is slower. This
happens because in the case of &lt;code&gt;RangeProductIter&lt;/code&gt; the JIT is able to see the whole
lifetime of the object and optimize it away entirely: instance variables
become local variables, the call to &lt;code&gt;__next__&lt;/code&gt; is inlined and we get the
equivalent of explicit nested loops.&lt;/p&gt;
    &lt;p&gt;However, generators are required to create a frame object and represent a fundamental case in which the JIT cannot trace through them effectively. In more complex real-world scenarios, we saw much worse slowdowns than these examples show.&lt;/p&gt;
    &lt;p&gt;This is a collection of other miscellaneous problems that I had to deal with. Generally speaking, we lack good support for tooling and profilers. CPython needs to have a good story to explain people how to understand what's happening when the JIT is enabled.&lt;/p&gt;
    &lt;p&gt;Warmup is another big problem: in PyPy, very short programs tend to be slower than CPython because JITting costs. Moreover warmup is not an easily definable phase, as the linked paper shows. This is an area where currently CPython shines, as its JIT is very fast. I think that it will become slightly slower when it tries to optimize more aggressively, but hopefully warmup will overall be a lesser problem than on PyPy.&lt;/p&gt;
    &lt;p&gt;Moreover, it's very easy to accidentally make your code 2x, 5x or even 10x slower by changing seemingly innocent pieces of code. This is another reason why good tooling is essential.&lt;/p&gt;
    &lt;p&gt;Finally, the "long tail of JITting": every loop and every guard gets a counter, and we start JITting when it reaches a threshold. Given a sufficiently long running program, all counters reach the threshold eventually and we end up JITting much more than necessary, using too much memory and/or thrashing the cache. In many cases I found beneficial to just disable the JIT "after a while", with manually tuned heuristics.&lt;/p&gt;
    &lt;p&gt;These are slides which I didn't show during the live presentation, and show a case where a tracing JIT can shine: since the JIT sees a complete trace of an entire loop (including nested calls) it can easily removes a lot of temporary objects which usually penalize Python performance.&lt;/p&gt;
    &lt;p&gt;In many cases, we can get the famous "zero-cost abstractions".&lt;/p&gt;
    &lt;p&gt;Let's look at a concrete example. We need to compute the barycenter of triangles that are serialized in a binary format. Each triangle has three points, each point has x and y coordinates. This simulates real world protocols such as protobuf, capnproto, etc.&lt;/p&gt;
    &lt;p&gt;This is what we use a a baseline: a bare loop, using &lt;code&gt;struct.unpack_from&lt;/code&gt; to read 6 floats at a time.&lt;/p&gt;
    &lt;p&gt;Here's the "proper" object-oriented approach, similar to how modern serialization libraries work. We create &lt;code&gt;Triangle&lt;/code&gt; and &lt;code&gt;Point&lt;/code&gt; classes that
provide a nice API for accessing the binary data. Each property access creates
new objects and calls struct.unpack_from. This is much more readable and
reusable, but creates many temporary objects.&lt;/p&gt;
    &lt;p&gt;Here's how you'd use the object-oriented API. The code is much cleaner and more readable than the bare loop version. But notice how many object creations are happening: one &lt;code&gt;Triangle&lt;/code&gt; object, six &lt;code&gt;Point&lt;/code&gt; objects, plus all the
intermediate tuples from &lt;code&gt;struct.unpack_from&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;As expected, on CPython &lt;code&gt;read_proto&lt;/code&gt; is much slower than the bare one,
roughly 6x slower. However, PyPy can fully optimize away all the
abstraction overhead introduced by &lt;code&gt;Triangle&lt;/code&gt; and &lt;code&gt;Point&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In PyPy jargon we call this form of allocation removal "virtuals" (because we create "virtual objects" whose fields are represented as local variables) and it's probably the single most important optimization that PyPy does.&lt;/p&gt;
    &lt;p&gt;During my week in Cambridge I talked extensively with the CPython JIT devs about this and I hope I convinced them that this is what they should aim for ğŸ˜Š.&lt;/p&gt;
    &lt;p&gt;Note also that &lt;code&gt;read_proto&lt;/code&gt; is actually faster than &lt;code&gt;read_loop&lt;/code&gt;. This
happens because in &lt;code&gt;read_loop&lt;/code&gt; we do a single &lt;code&gt;struct.unpack_from('dddddd', ...)&lt;/code&gt;,
while in &lt;code&gt;read_proto&lt;/code&gt; we do a succession of six individual
&lt;code&gt;struct.unpack_from('d', ...)&lt;/code&gt;. It turns out that the JIT is able to trace
into the second form but not into the first, which means that in &lt;code&gt;read_loop&lt;/code&gt;
we actually need to allocate a pseudo-tuple at each iteration.&lt;/p&gt;
    &lt;p&gt;The funny part is that I did not expect to get this result. I had to take the time to analyze the JIT traces of both versions to understand why &lt;code&gt;read_loop&lt;/code&gt; was slower.  This is probably the best explanation of how
counterintuitive it is to reason about performance in a JITted world.&lt;/p&gt;
    &lt;head rend="h2"&gt;AcknowledgmentsÂ¶&lt;/head&gt;
    &lt;p&gt;Thanks to Carl Friedrich Bolz-Tereick and Hood Chatham for feedback on the slides and the post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45377030</guid><pubDate>Thu, 25 Sep 2025 18:40:22 +0000</pubDate></item><item><title>Ollama Web Search</title><link>https://ollama.com/blog/web-search</link><description>&lt;doc fingerprint="2d52dc131ca4ae0e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Web search&lt;/head&gt;
    &lt;head rend="h2"&gt;September 24, 2025&lt;/head&gt;
    &lt;p&gt;A new web search API is now available in Ollama. Ollama provides a generous free tier of web searches for individuals to use, and higher rate limits are available via Ollamaâ€™s cloud.&lt;/p&gt;
    &lt;p&gt;This web search capability can augment models with the latest information from the web to reduce hallucinations and improve accuracy.&lt;/p&gt;
    &lt;p&gt;Web search is provided as a REST API with deeper tool integrations in Ollamaâ€™s Python and JavaScript libraries. This also enables models such as OpenAIâ€™s &lt;code&gt;gpt-oss&lt;/code&gt; models to conduct long-running research tasks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Get started&lt;/head&gt;
    &lt;p&gt;Create an API key from your Ollama account.&lt;/p&gt;
    &lt;code&gt;export OLLAMA_API_KEY="your_api_key"
&lt;/code&gt;
    &lt;head rend="h4"&gt;cURL&lt;/head&gt;
    &lt;code&gt;curl https://ollama.com/api/web_search \
  --header "Authorization: Bearer $OLLAMA_API_KEY" \
  -d '{
    "query": "what is ollama?"
  }'
&lt;/code&gt;
    &lt;p&gt;Example output&lt;/p&gt;
    &lt;code&gt;{
  "results": [
    {
      "title": "Ollama",
      "url": "https://ollama.com/",
      "content": "Cloud models are now available..."
    },
    {
      "title": "What is Ollama? Introduction to the AI model management tool",
      "url": "https://www.hostinger.com/tutorials/what-is-ollama",
      "content": "Ariffud M. 6min Read..."
    },
    {
      "title": "Ollama Explained: Transforming AI Accessibility and Language ...",
      "url": "https://www.geeksforgeeks.org/artificial-intelligence/ollama-explained-transforming-ai-accessibility-and-language-processing/",
      "content": "Data Science Data Science Projects Data Analysis..."
    }
  ]
}
&lt;/code&gt;
    &lt;head rend="h4"&gt;Python&lt;/head&gt;
    &lt;p&gt;Install and run Ollamaâ€™s Python library&lt;/p&gt;
    &lt;code&gt;pip install 'ollama&amp;gt;=0.6.0'
&lt;/code&gt;
    &lt;p&gt;Then make a request using &lt;code&gt;ollama.web_search&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;import ollama
response = ollama.web_search("What is Ollama?")
print(response)
&lt;/code&gt;
    &lt;p&gt;Example output&lt;/p&gt;
    &lt;code&gt;results = [
    {
        "title": "Ollama",
        "url": "https://ollama.com/",
        "content": "Cloud models are now available in Ollama..."
    },
    {
        "title": "What is Ollama? Features, Pricing, and Use Cases - Walturn",
        "url": "https://www.walturn.com/insights/what-is-ollama-features-pricing-and-use-cases",
        "content": "Our services..."
    },
    {
        "title": "Complete Ollama Guide: Installation, Usage &amp;amp; Code Examples",
        "url": "https://collabnix.com/complete-ollama-guide-installation-usage-code-examples",
        "content": "Join our Discord Server..."
    }
]
&lt;/code&gt;
    &lt;head rend="h4"&gt;JavaScript&lt;/head&gt;
    &lt;p&gt;Install and run Ollamaâ€™s JavaScript library&lt;/p&gt;
    &lt;code&gt;npm install 'ollama@&amp;gt;=0.6.0'
&lt;/code&gt;
    &lt;code&gt;import { Ollama } from "ollama";

const client = new Ollama();
const results = await client.webSearch({ query: "what is ollama?" });
console.log(JSON.stringify(results, null, 2));
&lt;/code&gt;
    &lt;p&gt;Example output&lt;/p&gt;
    &lt;code&gt;{
  "results": [
    {
      "title": "Ollama",
      "url": "https://ollama.com/",
      "content": "Cloud models are now available..."
    },
    {
      "title": "What is Ollama? Introduction to the AI model management tool",
      "url": "https://www.hostinger.com/tutorials/what-is-ollama",
      "content": "Ollama is an open-source tool..."
    },
    {
      "title": "Ollama Explained: Transforming AI Accessibility and Language Processing",
      "url": "https://www.geeksforgeeks.org/artificial-intelligence/ollama-explained-transforming-ai-accessibility-and-language-processing/",
      "content": "Ollama is a groundbreaking..."
    }
  ]
}

&lt;/code&gt;
    &lt;head rend="h3"&gt;Building a search agent&lt;/head&gt;
    &lt;p&gt;Use Ollamaâ€™s web search as a tool to build a mini search agent.&lt;/p&gt;
    &lt;p&gt;The example uses Alibabaâ€™s Qwen 3 model with 4B parameters.&lt;/p&gt;
    &lt;code&gt;ollama pull qwen3:4b
&lt;/code&gt;
    &lt;code&gt;from ollama import chat, web_fetch, web_search

available_tools = {'web_search': web_search, 'web_fetch': web_fetch}

messages = [{'role': 'user', 'content': "what is ollama's new engine"}]

while True:
  response = chat(
    model='qwen3:4b',
    messages=messages,
    tools=[web_search, web_fetch],
    think=True
    )
  if response.message.thinking:
    print('Thinking: ', response.message.thinking)
  if response.message.content:
    print('Content: ', response.message.content)
  messages.append(response.message)
  if response.message.tool_calls:
    print('Tool calls: ', response.message.tool_calls)
    for tool_call in response.message.tool_calls:
      function_to_call = available_tools.get(tool_call.function.name)
      if function_to_call:
        args = tool_call.function.arguments
        result = function_to_call(**args)
        print('Result: ', str(result)[:200]+'...')
        # Result is truncated for limited context lengths
        messages.append({'role': 'tool', 'content': str(result)[:2000 * 4], 'tool_name': tool_call.function.name})
      else:
        messages.append({'role': 'tool', 'content': f'Tool {tool_call.function.name} not found', 'tool_name': tool_call.function.name})
  else:
    break
&lt;/code&gt;
    &lt;p&gt;Result&lt;/p&gt;
    &lt;code&gt;Thinking:  Okay, the user is asking about Ollama's new engine. I need to figure out what they're referring to. Ollama is a company that develops large language models, so maybe they've released a new model or an updated version of their existing engine...

Tool calls:  [ToolCall(function=Function(name='web_search', arguments={'max_results': 3, 'query': 'Ollama new engine'}))]
Result:  results=[WebSearchResult(content='# New model scheduling\n\n## September 23, 2025\n\nOllama now includes a significantly improved model scheduling system. Ahead of running a model, Ollamaâ€™s new engine...

Thinking:  Okay, the user asked about Ollama's new engine. Let me look at the search results.

First result is from September 23, 2025, talking about new model scheduling. It mentions improved memory management, reduced crashes, better GPU utilization, and multi-GPU performance. Examples show speed improvements and accurate memory reporting. Supported models include gemma3, llama4, qwen3, etc...

Content:  Ollama has introduced two key updates to its engine, both released in 2025:

1. **Enhanced Model Scheduling (September 23, 2025)**
   - **Precision Memory Management**: Exact memory allocation reduces out-of-memory crashes and optimizes GPU utilization.
   - **Performance Gains**: Examples show significant speed improvements (e.g., 85.54 tokens/s vs 52.02 tokens/s) and full GPU layer utilization.
   - **Multi-GPU Support**: Improved efficiency across multiple GPUs, with accurate memory reporting via tools like `nvidia-smi`.
   - **Supported Models**: Includes `gemma3`, `llama4`, `qwen3`, `mistral-small3.2`, and more.

2. **Multimodal Engine (May 15, 2025)**
   - **Vision Support**: First-class support for vision models, including `llama4:scout` (109B parameters), `gemma3`, `qwen2.5vl`, and `mistral-small3.1`.
   - **Multimodal Tasks**: Examples include identifying animals in multiple images, answering location-based questions from videos, and document scanning.

These updates highlight Ollama's focus on efficiency, performance, and expanded capabilities for both text and vision tasks.
&lt;/code&gt;
    &lt;p&gt;Recommended models:&lt;/p&gt;
    &lt;p&gt;These models have great tool-use capabilities and are able to have multi-turn interactions with the user and tools to get to a final result.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;qwen3&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;gpt-oss&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recommended cloud models:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;qwen3:480b-cloud&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;gpt-oss:120b-cloud&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;deepseek-v3.1-cloud&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;web_search&lt;/code&gt; and &lt;code&gt;web_fetch&lt;/code&gt; tools can return thousands of tokens. It is recommended to increase the context length of the model to ~32000 tokens for reasonable performance. Search agents work best with full context length.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fetching page results&lt;/head&gt;
    &lt;p&gt;To fetch individual pages (e.g. when a user provides a url in the prompt), use the new web fetch API.&lt;/p&gt;
    &lt;head rend="h4"&gt;Python library&lt;/head&gt;
    &lt;code&gt;from ollama import web_fetch

result = web_fetch('https://ollama.com')
print(result)
&lt;/code&gt;
    &lt;p&gt;Result&lt;/p&gt;
    &lt;code&gt;WebFetchResponse(
    title='Ollama',
    content='[Cloud models](https://ollama.com/blog/cloud-models) are now available in Ollama\n\n**Chat &amp;amp; build
with open models**\n\n[Download](https://ollama.com/download) [Explore
models](https://ollama.com/models)\n\nAvailable for macOS, Windows, and Linux',
    links=['https://ollama.com/', 'https://ollama.com/models', 'https://github.com/ollama/ollama']
)
&lt;/code&gt;
    &lt;p&gt;Example Python code is available on GitHub.&lt;/p&gt;
    &lt;head rend="h4"&gt;JavaScript library&lt;/head&gt;
    &lt;code&gt;import { Ollama } from "ollama";

const client = new Ollama();
const fetchResult = await client.webFetch({ url: "https://ollama.com" });
console.log(JSON.stringify(fetchResult, null, 2));
&lt;/code&gt;
    &lt;p&gt;Result&lt;/p&gt;
    &lt;code&gt;{
  "title": "Ollama",
  "content": "[Cloud models](https://ollama.com/blog/cloud-models) are now available in Ollama...",
  "links": [
    "https://ollama.com/",
    "https://ollama.com/models",
    "https://github.com/ollama/ollama"
  ]
}
&lt;/code&gt;
    &lt;p&gt;Example JavaScript code is available on GitHub.&lt;/p&gt;
    &lt;head rend="h4"&gt;cURL&lt;/head&gt;
    &lt;code&gt;curl --request POST \
  --url https://ollama.com/api/web_fetch \
  --header "Authorization: Bearer $OLLAMA_API_KEY" \
  --header 'Content-Type: application/json' \
  --data '{
      "url": "ollama.com"
}'
&lt;/code&gt;
    &lt;p&gt;Result&lt;/p&gt;
    &lt;code&gt;{
  "title": "Ollama",
  "content": "[Cloud models](https://ollama.com/blog/cloud-models) are now available in Ollama...",
  "links": [
    "http://ollama.com/",
    "http://ollama.com/models",
    "https://github.com/ollama/ollama"
  ]
}
&lt;/code&gt;
    &lt;head rend="h3"&gt;Integrations&lt;/head&gt;
    &lt;head rend="h3"&gt;MCP Server (Model Context Protocol server)&lt;/head&gt;
    &lt;p&gt;You can enable web search in any MCP client through the Python MCP server.&lt;/p&gt;
    &lt;head rend="h4"&gt;Cline&lt;/head&gt;
    &lt;p&gt;To integrate with Cline, configure MCP servers in its settings.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Manage MCP Servers &amp;gt; Configure MCP Servers &amp;gt; Add the configuration below&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  "mcpServers": {
    "web_search_and_fetch": {
      "type": "stdio",
      "command": "uv",
      "args": ["run", "path/to/web-search-mcp.py"],
      "env": { "OLLAMA_API_KEY": "your_api_key_here" }
    }
  }
}
&lt;/code&gt;
    &lt;head rend="h4"&gt;Codex&lt;/head&gt;
    &lt;p&gt;Add the following configuration to &lt;code&gt;~/.codex/config.toml&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;[mcp_servers.web_search]
command = "uv"
args = ["run", "path/to/web-search-mcp.py"]
env = { "OLLAMA_API_KEY" = "your_api_key_here" }
&lt;/code&gt;
    &lt;head rend="h4"&gt;Goose&lt;/head&gt;
    &lt;p&gt;You can integrate with Ollama via Gooseâ€™s extensions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Get started&lt;/head&gt;
    &lt;p&gt;Web search is included with a free Ollama account, with much higher rate limits available by upgrading your Ollama subscription.&lt;/p&gt;
    &lt;p&gt;To get started, sign up for an Ollama account!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45377641</guid><pubDate>Thu, 25 Sep 2025 19:21:52 +0000</pubDate></item><item><title>Can a model trained on satellite data really find brambles on the ground?</title><link>https://toao.com/blog/can-we-really-see-brambles-from-space</link><description>&lt;doc fingerprint="3d09f083bdbd4a9a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Can a model trained on satellite data really find brambles on the ground?&lt;/head&gt;
    &lt;p&gt;Over the summer Gabriel Mahler has been conducting research on hedgehog habitat mapping using Agent Based Models (ABMs) and remote sensing. Hedgehogs seem to like brambles and so as part of his work he has produced a bramble map. He did this by combining the TESSERA earth representation embeddings (using the geotessera library) with data from iNaturalist. The current model is an ensemble of logistic regression and a knn classifier.&lt;/p&gt;
    &lt;p&gt;Can we really see brambles from space? What better way to test the model than a quick field trip around Cambridge. Gabriel, Anil, Shane and I did just that today.&lt;/p&gt;
    &lt;p&gt;We started at Milton Community Centre, as the model was relatively confident there were brambles near the car park and along the path to Milton Park. It took us about 20 seconds to find the first one in an area indicated by the model.&lt;/p&gt;
    &lt;p&gt;So it turns out that there's a lot of bramble between the community center and entrance to Milton Country Park. We stopped six or seven times before reaching the park entrance. While the model predicted we'd find brambles all over the park, we went for the few areas of very high confidence near the entrance. In every place we checked, we found pretty significant amounts of bramble.&lt;/p&gt;
    &lt;p&gt;We collected photos of all the places we stopped, as well as recording our GPS location. One thought while out exploring is that the model did a great job predicting where we would find very large quantities of bramble without any cover. It didn't have high confidence in other areas where we found smaller brambles under partial cover. Since TESSERA is learned representation from remote sensing data (Sentinel 1 and 2), it would make sense that bramble partially obscured from above might be harder to spot. This is something we can potentially tease apart when we have more validation data.&lt;/p&gt;
    &lt;p&gt;Finally, we were satisfied the model was doing a good job in the park area and decided to pick a hotspot the model was predicting in part of a residential street. We drove over to find an empty plot that did indeed have a lot of bramble!&lt;/p&gt;
    &lt;p&gt;Another hotspot was on Fen Road and we stopped by to find this absolute unit:&lt;/p&gt;
    &lt;p&gt;Finally, we headed back in to Cambridge to see what one of the big hotspots in North Cambridge was like. To our amusement we ended up at the local nature reserve Bramblefields, which, true to its name, has a lot of bramble.&lt;/p&gt;
    &lt;p&gt;I was pleasantly surprised by how good Gabriel's model was for its simplicity. Great work!&lt;/p&gt;
    &lt;p&gt;We had hoped to actually re-run the model based on the data we were gathering but that proved tricky on a laptop, in a park. Given the richness of the TESSERA embeddings and the simplicity of the classifiers being used, a mobile phone-based human-in-the-loop active learning setup could be practical..&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45377748</guid><pubDate>Thu, 25 Sep 2025 19:28:16 +0000</pubDate></item><item><title>New Quasi-Moon Discovered Orbiting Earth, but It's Been Around for Decades</title><link>https://explorersweb.com/new-quasi-moon-discovered-orbiting-earth-but-its-been-around-for-decades/</link><description>&lt;doc fingerprint="7777217bfc065bf0"&gt;
  &lt;main&gt;
    &lt;p&gt;Astronomers have found a space rock that has been quietly hanging around Earth for decades: a tiny asteroid named 2025 PN7. This so-called â€œquasi-moonâ€ isnâ€™t a true moon or a mini-moon, because it orbits the Sun rather than our planet. But its orbit is so similar to Earthâ€™s that it will be our companion for around another 60 years.&lt;/p&gt;
    &lt;p&gt;Though the quasi-moon orbits the Sun, it occasionally looks from our vantage point like it is looping around us. However, our orbits are slightly different, so sometimes it lags behind us and sometimes it seems to lead us. But since the little asteroidâ€™s orbit around the Sun is very close to one Earth year, it is always pretty close.&lt;/p&gt;
    &lt;p&gt;2025 PN7 is just 19 meters across and might be the smallest quasi-moon ever found. Its minuscule size means that it can be quite tricky to spot. As astronomers put it, its â€œvisibility windowsâ€ are very narrow. We can only see it through very large telescopes when its position and the lighting are favorable. Thatâ€™s partly why it evaded detection for so long.&lt;/p&gt;
    &lt;head rend="h2"&gt;Entered orbit in 1957&lt;/head&gt;
    &lt;p&gt;Although the Pan-STARRS1 telescope in Hawaii discovered it in August 2025, the quasi-moon has been in this orbit for far longer. When researchers later trawled through archived images, they found that 2025 PN7 had shown up decades earlier. They think it likely entered its current orbit in 1957.&lt;/p&gt;
    &lt;p&gt;It wonâ€™t stay with us in this dance forever. Simulations suggest that it will keep up company for another 60 years before it wanders off in another direction. In that time, its distance from Earth will change quite a bit. So far, it has varied between 4 million kilometers at its closest and 18 million kilometers at its furthest.&lt;/p&gt;
    &lt;p&gt;2025 PN7 is one of seven quasi-moons in Earth-like orbits, and seems to be the smallest and least stable. Astronomers arenâ€™t exactly sure where it came from. It does not pose any threat to us.&lt;/p&gt;
    &lt;p&gt;â€œThese asteroids are relatively easy to access for unmanned missions and can be used to test planetary exploration technologies [relatively cheaply],â€ said Carlos de la Fuente Marcos, lead author of the study.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45378871</guid><pubDate>Thu, 25 Sep 2025 20:50:05 +0000</pubDate></item><item><title>RedoxFS is the default filesystem of Redox OS, inspired by ZFS</title><link>https://doc.redox-os.org/book/redoxfs.html</link><description>&lt;doc fingerprint="1c99101b8162c9f1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;RedoxFS&lt;/head&gt;
    &lt;p&gt;This is the default filesystem of Redox OS, inspired by ZFS and adapted to a microkernel architecture.&lt;/p&gt;
    &lt;p&gt;Redox had a read-only ZFS driver but it was abandoned because of the monolithic nature of ZFS that created problems with the Redox microkernel design.&lt;/p&gt;
    &lt;p&gt;(It's a replacement for TFS)&lt;/p&gt;
    &lt;p&gt;Current features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compatible with Redox and Linux (FUSE)&lt;/item&gt;
      &lt;item&gt;Copy-on-write&lt;/item&gt;
      &lt;item&gt;Data/metadata checksums&lt;/item&gt;
      &lt;item&gt;Transparent encryption&lt;/item&gt;
      &lt;item&gt;Standard Unix file attributes&lt;/item&gt;
      &lt;item&gt;File/directory size limit up to 193TiB (212TB)&lt;/item&gt;
      &lt;item&gt;File/directory quantity limit up to 4 billion per 193TiB (2^32 - 1 = 4294967295)&lt;/item&gt;
      &lt;item&gt;Disk encryption fully supported by the Redox bootloader, letting it load the kernel off an encrypted partition.&lt;/item&gt;
      &lt;item&gt;MIT licensed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Being MIT licensed, RedoxFS can be bundled on GPL-licensed operating systems (Linux, for example).&lt;/p&gt;
    &lt;head rend="h2"&gt;Tooling&lt;/head&gt;
    &lt;p&gt;RedoxFS tooling can be used to create, mount and edit contents of an &lt;code&gt;.img&lt;/code&gt; file containing RedoxFS. It can be installed with:&lt;/p&gt;
    &lt;code&gt;cargo install redoxfs
&lt;/code&gt;
    &lt;p&gt;If you found errors while installing it, make sure to install &lt;code&gt;fuse3&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Create a disk&lt;/head&gt;
    &lt;p&gt;You can create an empty, non bootable RedoxFS by allocating an empty file with &lt;code&gt;fallocate&lt;/code&gt; then run &lt;code&gt;redoxfs-mkfs&lt;/code&gt; to initialize the whole image as &lt;code&gt;RedoxFS&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;fallocate -l 1G redox.img
&lt;/code&gt;
    &lt;code&gt;redoxfs-mkfs redox.img
&lt;/code&gt;
    &lt;head rend="h3"&gt;Mount a disk&lt;/head&gt;
    &lt;p&gt;To mount the disk, run &lt;code&gt;redoxfs [image] [directory]&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;mkdir ./redox-img
&lt;/code&gt;
    &lt;code&gt;redoxfs redox.img ./redox-img
&lt;/code&gt;
    &lt;p&gt;It will mount the disk using FUSE underneath.&lt;/p&gt;
    &lt;head rend="h3"&gt;Unmount&lt;/head&gt;
    &lt;p&gt;Unmount the disk using FUSE unmount binary:&lt;/p&gt;
    &lt;code&gt;fusermount3 ./redox-img
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45379325</guid><pubDate>Thu, 25 Sep 2025 21:25:51 +0000</pubDate></item><item><title>Redis is fast â€“ I'll cache in Postgres</title><link>https://dizzy.zone/2025/09/24/Redis-is-fast-Ill-cache-in-Postgres/</link><description>&lt;doc fingerprint="6770f5d56a0059d1"&gt;
  &lt;main&gt;
    &lt;p&gt;There are books &amp;amp; many articles online, like this one arguing for using Postgres for everything. I thought Iâ€™d take a look at one use case - using Postgres instead of Redis for caching. I work with APIs quite a bit, so Iâ€™d build a super simple HTTP server that responds with data from that cache. Iâ€™d start from Redis as this is something I frequently encounter at work, switch it out to Postgres using unlogged tables and see if thereâ€™s a difference.&lt;/p&gt;
    &lt;head rend="h2"&gt;The setup&lt;/head&gt;
    &lt;p&gt;Iâ€™ll run the experiment on my homelabâ€™s k8s cluster. The idea is to run Postgres or Redis on one node, limiting it to 2CPUs via k8s limits, as well as 8GiB of memory. On another node, Iâ€™ll run the web server itself and then spin a pod for the benchmark executed via k6 on the third.&lt;/p&gt;
    &lt;p&gt;Both postgres and redis are used with the out of the box settings for the following images:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Postgres - &lt;code&gt;postgres:17.6&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Redis - &lt;code&gt;redis:8.2&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I wrote a simple webserver, with 2 endpoints, a cache and a â€œSessionâ€ struct which weâ€™ll store in the cache:&lt;/p&gt;
    &lt;code&gt;var ErrCacheMiss = errors.New("cache miss")

type Cache interface {
	Get(ctx context.Context, key string) (string, error)
	Set(ctx context.Context, key string, value string) error
}

type Session struct {
	ID string
}


func serveHTTP(c Cache) {
	http.HandleFunc("/get", getHandler(c))
	http.HandleFunc("/set", setHandler(c))

	port := os.Getenv("PORT")
	if port == "" {
		port = "8080"
	}

	fmt.Println("Server starting on http://0.0.0.0:" + port)

	server := &amp;amp;http.Server{Addr: "0.0.0.0:" + port}

	go func() {
		if err := server.ListenAndServe(); err != nil &amp;amp;&amp;amp; err != http.ErrServerClosed {
			fmt.Println("Error starting server:", err)
		}
	}()

	quit := make(chan os.Signal, 1)
	signal.Notify(quit, os.Interrupt)
	&amp;lt;-quit

	fmt.Println("Shutting down server...")

	if err := server.Close(); err != nil {
		fmt.Println("Error shutting down server:", err)
	}
}&lt;/code&gt;
    &lt;p&gt;For redis, Iâ€™ve implemented the cache using &lt;code&gt;github.com/redis/go-redis/v9&lt;/code&gt; as follows:&lt;/p&gt;
    &lt;code&gt;type RedisCache struct {
	client *redis.Client
}

func NewRedisCache() *RedisCache {
	redisURL := os.Getenv("REDIS_URL")
	if redisURL == "" {
		redisURL = "localhost:6379"
	}

	fmt.Println("Connecting to Redis at", redisURL)

	client := redis.NewClient(&amp;amp;redis.Options{
		Addr:     redisURL,
		Password: "",
		DB:       0,
	})

	return &amp;amp;RedisCache{
		client: client,
	}
}

func (r *RedisCache) Get(ctx context.Context, key string) (string, error) {
	val, err := r.client.Get(ctx, key).Result()
	if err == redis.Nil {
		return "", ErrCacheMiss
	}
	if err != nil {
		return "", err
	}
	return val, nil
}

func (r *RedisCache) Set(ctx context.Context, key string, value string) error {
	return r.client.Set(ctx, key, value, 0).Err()
}&lt;/code&gt;
    &lt;p&gt;The postgres cache is implemented using the &lt;code&gt;github.com/jackc/pgx/v5&lt;/code&gt; library:
&lt;/p&gt;
    &lt;code&gt;type PostgresCache struct {
	db *pgxpool.Pool
}

func NewPostgresCache() (*PostgresCache, error) {
	pgDSN := os.Getenv("POSTGRES_DSN")
	if pgDSN == "" {
		pgDSN = "postgres://user:password@localhost:5432/mydb"
	}

	cfg, err := pgxpool.ParseConfig(pgDSN)
	if err != nil {
		return nil, err
	}

	cfg.MaxConns = 50
	cfg.MinConns = 10

	pool, err := pgxpool.NewWithConfig(context.Background(), cfg)
	if err != nil {
		return nil, err
	}

	_, err = pool.Exec(context.Background(), `
		CREATE UNLOGGED TABLE IF NOT EXISTS cache (
			key VARCHAR(255) PRIMARY KEY,
			value TEXT
		);
	`)
	if err != nil {
		return nil, err
	}

	return &amp;amp;PostgresCache{
		db: pool,
	}, nil
}

func (p *PostgresCache) Get(ctx context.Context, key string) (string, error) {
	var content string
	err := p.db.QueryRow(ctx, `SELECT value FROM cache WHERE key = $1`, key).Scan(&amp;amp;content)
	if err == pgx.ErrNoRows {
		return "", ErrCacheMiss
	}
	if err != nil {
		return "", err
	}
	return content, nil
}

func (p *PostgresCache) Set(ctx context.Context, key string, value string) error {
	_, err := p.db.Exec(ctx, `INSERT INTO cache (key, value) VALUES ($1, $2) ON CONFLICT (key) DO UPDATE SET value = $2`, key, value)
	return err
}&lt;/code&gt;
    &lt;p&gt;Iâ€™ll seed the redis and postgres with 30 million entries each, keeping record of the inserted uuids. From there, Iâ€™ll generate a subset of existing uuids to use while benchmarking. This allows for simulating both hits and misses.&lt;/p&gt;
    &lt;p&gt;Iâ€™ll do a few runs of benchmarks for gets first, then sets and then a mixed run. Each run will execute for 2 minutes. Iâ€™ll look at the number of operations per second, latencies as well as memory and CPU usage during those times.&lt;/p&gt;
    &lt;p&gt;To simulate a somewhat real scenario where only a subset of keys exist in the cache the set benchmark will have a 10% chance to update an existing key, whereas the get will have an 80% chance of picking an existing key. The mixed workload will have a 20% chance to execute a set scenario and 80% for the get scenario.&lt;/p&gt;
    &lt;head rend="h2"&gt;The results&lt;/head&gt;
    &lt;head rend="h3"&gt;Getting values from cache&lt;/head&gt;
    &lt;p&gt;Redis performed better than Postgres, which did not surprise me at all. The bottleneck was actually the HTTP server. The machine running the http server maxed out on CPU, with redis running comfortably with ~1280mCPU - short of the 2000mCPU limit imposed. Redis used ~3800MiB of RAM, which stayed flat across the runs.&lt;/p&gt;
    &lt;p&gt;For postgres, the bottleneck was the CPU on postgres side. It consistently maxed out the 2 cores dedicated to it, while also using ~5000MiB of RAM.&lt;/p&gt;
    &lt;p&gt;Redis also did better when it comes to latencies of the HTTP responses:&lt;/p&gt;
    &lt;head rend="h3"&gt;Setting values in cache&lt;/head&gt;
    &lt;p&gt;Once again Redis performed better. The CPU usage stayed roughly the same as in the case of the GET experiment, with the RAM usage growing to ~4300MiB due to the new keys being inserted. The bottleneck stayed on the HTTP server side, with Redis using ~1280mCPU once again.&lt;/p&gt;
    &lt;p&gt;Postgres once again was bottlenecked by the CPU, constantly using 100% of the 2 cores it was limited to. During the course of the run, the memory usage grew to ~5500MiB.&lt;/p&gt;
    &lt;p&gt;During the test, the endpoints with the Redis cache implementation also had better latencies:&lt;/p&gt;
    &lt;head rend="h3"&gt;Read/write performance&lt;/head&gt;
    &lt;p&gt;The mixed benchmark also returned the predictable result of Redis reigning superior. As has been the story so far, the CPU stayed put at ~1280mCPU, RAM usage grew a bit due to the new keys being inserted.&lt;/p&gt;
    &lt;p&gt;Postgres maxed out the two cores and reached around 6GiB of memory used.&lt;/p&gt;
    &lt;p&gt;Latencies once again were better when using redis:&lt;/p&gt;
    &lt;head rend="h3"&gt;Unlogged tables&lt;/head&gt;
    &lt;p&gt;In the benchmark, Iâ€™ve used an unlogged table for postgres but this has not seemed to help, or has it? If I rerun the same benchmark with a normal(logged) table we can look at the numbers.&lt;/p&gt;
    &lt;p&gt;The unlogged table makes a huge difference for the write benchmark and a somewhat smaller but still significant one for the mixed workload. This is because the unlogged tables skip the write ahead log making them a lot faster for writes. Thereâ€™s very little difference for the read performance though and I expect more runs would show the two test cases converging.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Redis is faster than postgres when it comes to caching, thereâ€™s no doubt about it. It conveniently comes with a bunch of other useful functionality that one would expect from a cache, such as TTLs. It was also bottlenecked by the hardware, my service or a combination of both and could definitely show better numbers. Surely, we should all use Redis for our caching needs then, right? Well, I think Iâ€™ll still use postgres. Almost always, my projects need a database. Not having to add another dependency comes with its own benefits. If I need my keys to expire, Iâ€™ll add a column for it, and a cron job to remove those keys from the table. As far as speed goes - 7425 requests per second is still a lot. Thatâ€™s more than half a billion requests per day. All on hardware thatâ€™s 10 years old and using laptop CPUs. Not many projects will reach this scale and if they do I can just upgrade the postgres instance or if need be spin up a redis then. Having an interface for your cache so you can easily switch out the underlying store is definitely something Iâ€™ll keep doing exactly for this purpose.&lt;/p&gt;
    &lt;p&gt;Thanks for reading!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45380699</guid><pubDate>Thu, 25 Sep 2025 23:34:46 +0000</pubDate></item><item><title>Bluesky Alt Text Stream</title><link>https://bobbiec.github.io/bluesky-alt-text.html</link><description>&lt;doc fingerprint="6972460eaef3f6a4"&gt;
  &lt;main&gt;
    &lt;p&gt;This demo is part of Image descriptions on Bluesky: not bad, could be better - see the blog post for more details!&lt;/p&gt;
    &lt;p&gt;The streaming tool itself is a fork of Simon Willison's Bluesky WebSocket Firehose (code here), with the following changes:&lt;/p&gt;
    &lt;quote&gt;Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License. "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution." "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a "NOTICE" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets "[]" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same "printed page" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45380726</guid><pubDate>Thu, 25 Sep 2025 23:36:59 +0000</pubDate></item><item><title>Investigating a Forged PDF</title><link>https://mjg59.dreamwidth.org/73317.html</link><description>&lt;doc fingerprint="7096a97f0e007743"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Investigating a forged PDF&lt;/head&gt;Sep. 24th, 2025 12:24 pm&lt;p&gt; mjg59&lt;/p&gt;&lt;p&gt;I had to rent a house for a couple of months recently, which is long enough in California that it pushes you into proper tenant protection law. As landlords tend to do, they failed to return my security deposit within the 21 days required by law, having already failed to provide the required notification that I was entitled to an inspection before moving out. Cue some tedious argumentation with the letting agency, and eventually me threatening to take them to small claims court.&lt;lb/&gt;This post is not about that.&lt;lb/&gt;Now, under Californian law, the onus is on the landlord to hold and return the security deposit - the agency has no role in this. The only reason I was talking to them is that my lease didn't mention the name or address of the landlord (another legal violation, but the outcome is just that you get to serve the landlord via the agency). So it was a bit surprising when I received an email from the owner of the agency informing me that they did not hold the deposit and so were not liable - I already knew this.&lt;lb/&gt;The odd bit about this, though, is that they sent me another copy of the contract, asserting that it made it clear that the landlord held the deposit. I read it, and instead found a clause reading&lt;lb/&gt;Ok, fair enough, there's an addendum that says the landlord has it (I've removed the landlord's name, it's present in the original).&lt;lb/&gt;Except. I had no recollection of that addendum. I went back to the copy of the contract I had and discovered:&lt;lb/&gt;Huh! But obviously I could just have edited that to remove it (there's no obvious reason for me to, but whatever), and then it'd be my word against theirs. However, I'd been sent the document via RightSignature, an online document signing platform, and they'd added a certification page that looked like this:&lt;lb/&gt;Interestingly, the certificate page was identical in both documents, including the checksums, despite the content being different. So, how do I show which one is legitimate? You'd think given this certificate page this would be trivial, but RightSignature provides no documented mechanism whatsoever for anyone to verify any of the fields in the certificate, which is annoying but let's see what we can do anyway.&lt;lb/&gt;First up, let's look at the PDF metadata. pdftk has a dump_data command that dumps the metadata in the document, including the creation date and the modification date. My file had both set to identical timestamps in June, both listed in UTC, corresponding to the time I'd signed the document. The file containing the addendum? The same creation time, but a modification time of this Monday, shortly before it was sent to me. This time, the modification timestamp was in Pacific Daylight Time, the timezone currently observed in California. In addition, the data included two ID fields, ID0 and ID1. In my document both were identical, in the one with the addendum ID0 matched mine but ID1 was different.&lt;lb/&gt;These ID tags are intended to be some form of representation (such as a hash) of the document. ID0 is set when the document is created and should not be modified afterwards - ID1 initially identical to ID0, but changes when the document is modified. This is intended to allow tooling to identify whether two documents are modified versions of the same document. The identical ID0 indicated that the document with the addendum was originally identical to mine, and the different ID1 that it had been modified.&lt;lb/&gt;Well, ok, that seems like a pretty strong demonstration. I had the "I have a very particular set of skills" conversation with the agency and pointed these facts out, that they were an extremely strong indication that my copy was authentic and their one wasn't, and they responded that the document was "re-sealed" every time it was downloaded from RightSignature and that would explain the modifications. This doesn't seem plausible, but it's an argument. Let's go further.&lt;lb/&gt;My next move was pdfalyzer, which allows you to pull a PDF apart into its component pieces. This revealed that the documents were identical, other than page 3, the one with the addendum. This page included tags entitled "touchUp_TextEdit", evidence that the page had been modified using Acrobat. But in itself, that doesn't prove anything - obviously it had been edited at some point to insert the landlord's name, it doesn't prove whether it happened before or after the signing.&lt;lb/&gt;But in the process of editing, Acrobat appeared to have renamed all the font references on that page into a different format. Every other page had a consistent naming scheme for the fonts, and they matched the scheme in the page 3 I had. Again, that doesn't tell us whether the renaming happened before or after the signing. Or does it?&lt;lb/&gt;You see, when I completed my signing, RightSignature inserted my name into the document, and did so using a font that wasn't otherwise present in the document (Courier, in this case). That font was named identically throughout the document, except on page 3, where it was named in the same manner as every other font that Acrobat had renamed. Given the font wasn't present in the document until after I'd signed it, this is proof that the page was edited after signing.&lt;lb/&gt;But eh this is all very convoluted. Surely there's an easier way? Thankfully yes, although I hate it. RightSignature had sent me a link to view my signed copy of the document. When I went there it presented it to me as the original PDF with my signature overlaid on top. Hitting F12 gave me the network tab, and I could see a reference to a base.pdf. Downloading that gave me the original PDF, pre-signature. Running sha256sum on it gave me an identical hash to the "Original checksum" field. Needless to say, it did not contain the addendum.&lt;lb/&gt;Why do this? The only explanation I can come up with (and I am obviously guessing here, I may be incorrect!) is that International Executive Rentals realised that they'd sent me a contract which could mean that they were liable for the return of my deposit, even though they'd already given it to my landlord, and after realising this added the addendum, sent it to me, and assumed that I just wouldn't notice (or that, if I did, I wouldn't be able to prove anything). In the process they went from an extremely unlikely possibility of having civil liability for a few thousand dollars (even if they were holding the deposit it's still the landlord's legal duty to return it, as far as I can tell) to doing something that looks extremely like forgery.&lt;lb/&gt;There's a hilarious followup. After this happened, the agency offered to do a screenshare with me showing them logging into RightSignature and showing the signed file with the addendum, and then proceeded to do so. One minor problem - the "Send for signature" button was still there, just below a field saying "Uploaded: 09/22/25". I asked them to search for my name, and it popped up two hits - one marked draft, one marked completed. The one marked completed? Didn't contain the addendum.&lt;/p&gt;&lt;p&gt;This post is not about that.&lt;/p&gt;&lt;p&gt;Now, under Californian law, the onus is on the landlord to hold and return the security deposit - the agency has no role in this. The only reason I was talking to them is that my lease didn't mention the name or address of the landlord (another legal violation, but the outcome is just that you get to serve the landlord via the agency). So it was a bit surprising when I received an email from the owner of the agency informing me that they did not hold the deposit and so were not liable - I already knew this.&lt;/p&gt;&lt;p&gt;The odd bit about this, though, is that they sent me another copy of the contract, asserting that it made it clear that the landlord held the deposit. I read it, and instead found a clause reading&lt;/p&gt;&lt;quote&gt;SECURITY: The security deposit will secure the performance of Tenantâ€™s obligations. IER may, but will not be obligated to, apply all portions of said deposit on account of Tenantâ€™s obligations. Any balance remaining upon termination will be returned to Tenant. Tenant will not have the right to apply the security deposit in payment of the last monthâ€™s rent. Security deposit held at IER Trust Account., where IER is International Executive Rentals, the agency in question. Why send me a contract that says you hold the money while you're telling me you don't? And then I read further down and found this:&lt;/quote&gt;&lt;p&gt;Ok, fair enough, there's an addendum that says the landlord has it (I've removed the landlord's name, it's present in the original).&lt;/p&gt;&lt;p&gt;Except. I had no recollection of that addendum. I went back to the copy of the contract I had and discovered:&lt;/p&gt;&lt;p&gt;Huh! But obviously I could just have edited that to remove it (there's no obvious reason for me to, but whatever), and then it'd be my word against theirs. However, I'd been sent the document via RightSignature, an online document signing platform, and they'd added a certification page that looked like this:&lt;/p&gt;&lt;p&gt;Interestingly, the certificate page was identical in both documents, including the checksums, despite the content being different. So, how do I show which one is legitimate? You'd think given this certificate page this would be trivial, but RightSignature provides no documented mechanism whatsoever for anyone to verify any of the fields in the certificate, which is annoying but let's see what we can do anyway.&lt;/p&gt;&lt;p&gt;First up, let's look at the PDF metadata. pdftk has a dump_data command that dumps the metadata in the document, including the creation date and the modification date. My file had both set to identical timestamps in June, both listed in UTC, corresponding to the time I'd signed the document. The file containing the addendum? The same creation time, but a modification time of this Monday, shortly before it was sent to me. This time, the modification timestamp was in Pacific Daylight Time, the timezone currently observed in California. In addition, the data included two ID fields, ID0 and ID1. In my document both were identical, in the one with the addendum ID0 matched mine but ID1 was different.&lt;/p&gt;&lt;p&gt;These ID tags are intended to be some form of representation (such as a hash) of the document. ID0 is set when the document is created and should not be modified afterwards - ID1 initially identical to ID0, but changes when the document is modified. This is intended to allow tooling to identify whether two documents are modified versions of the same document. The identical ID0 indicated that the document with the addendum was originally identical to mine, and the different ID1 that it had been modified.&lt;/p&gt;&lt;p&gt;Well, ok, that seems like a pretty strong demonstration. I had the "I have a very particular set of skills" conversation with the agency and pointed these facts out, that they were an extremely strong indication that my copy was authentic and their one wasn't, and they responded that the document was "re-sealed" every time it was downloaded from RightSignature and that would explain the modifications. This doesn't seem plausible, but it's an argument. Let's go further.&lt;/p&gt;&lt;p&gt;My next move was pdfalyzer, which allows you to pull a PDF apart into its component pieces. This revealed that the documents were identical, other than page 3, the one with the addendum. This page included tags entitled "touchUp_TextEdit", evidence that the page had been modified using Acrobat. But in itself, that doesn't prove anything - obviously it had been edited at some point to insert the landlord's name, it doesn't prove whether it happened before or after the signing.&lt;/p&gt;&lt;p&gt;But in the process of editing, Acrobat appeared to have renamed all the font references on that page into a different format. Every other page had a consistent naming scheme for the fonts, and they matched the scheme in the page 3 I had. Again, that doesn't tell us whether the renaming happened before or after the signing. Or does it?&lt;/p&gt;&lt;p&gt;You see, when I completed my signing, RightSignature inserted my name into the document, and did so using a font that wasn't otherwise present in the document (Courier, in this case). That font was named identically throughout the document, except on page 3, where it was named in the same manner as every other font that Acrobat had renamed. Given the font wasn't present in the document until after I'd signed it, this is proof that the page was edited after signing.&lt;/p&gt;&lt;p&gt;But eh this is all very convoluted. Surely there's an easier way? Thankfully yes, although I hate it. RightSignature had sent me a link to view my signed copy of the document. When I went there it presented it to me as the original PDF with my signature overlaid on top. Hitting F12 gave me the network tab, and I could see a reference to a base.pdf. Downloading that gave me the original PDF, pre-signature. Running sha256sum on it gave me an identical hash to the "Original checksum" field. Needless to say, it did not contain the addendum.&lt;/p&gt;&lt;p&gt;Why do this? The only explanation I can come up with (and I am obviously guessing here, I may be incorrect!) is that International Executive Rentals realised that they'd sent me a contract which could mean that they were liable for the return of my deposit, even though they'd already given it to my landlord, and after realising this added the addendum, sent it to me, and assumed that I just wouldn't notice (or that, if I did, I wouldn't be able to prove anything). In the process they went from an extremely unlikely possibility of having civil liability for a few thousand dollars (even if they were holding the deposit it's still the landlord's legal duty to return it, as far as I can tell) to doing something that looks extremely like forgery.&lt;/p&gt;&lt;p&gt;There's a hilarious followup. After this happened, the agency offered to do a screenshare with me showing them logging into RightSignature and showing the signed file with the addendum, and then proceeded to do so. One minor problem - the "Send for signature" button was still there, just below a field saying "Uploaded: 09/22/25". I asked them to search for my name, and it popped up two hits - one marked draft, one marked completed. The one marked completed? Didn't contain the addendum.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45381010</guid><pubDate>Fri, 26 Sep 2025 00:14:11 +0000</pubDate></item><item><title>The Digital Markets Act: time for a reset</title><link>https://blog.google/around-the-globe/google-europe/the-digital-markets-act-time-for-a-reset/</link><description>&lt;doc fingerprint="9f9e5832aabb324f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Digital Markets Act: time for a reset&lt;/head&gt;
    &lt;p&gt;The Digital Markets Act (DMA), intended to create a more level playing field, is causing significant and unintended harm to European users and many of the small businesses it was meant to protect. This week we detailed these impacts in our response to the European Commissionâ€™s consultation on this new law and provided our thoughts on how to improve it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unintended consequences&lt;/head&gt;
    &lt;p&gt;Consider the DMAâ€™s impact on Europeâ€™s tourism industry. The DMA requires Google Search to stop showing useful travel results that link directly to airline and hotel sites, and instead show links to intermediary websites that charge for inclusion. This raises prices for consumers, reduces traffic to businesses, and makes it harder for people to quickly find reliable, direct booking information.&lt;/p&gt;
    &lt;p&gt;Key parts of the European tourism industry have already seen free, direct booking traffic from Google Search plummet by up to 30%. A recent study on the economic impact of the DMA estimates that European businesses across sectors could face revenue losses of up to â‚¬114 billion.&lt;/p&gt;
    &lt;head rend="h2"&gt;Favoring the few&lt;/head&gt;
    &lt;p&gt;We remain concerned that these changes to Search are a result of the DMA prioritizing the commercial interests of a small set of intermediary sites â€” who often shout the loudest in these debates â€” over the ability of most businesses to sell directly to their customers.&lt;/p&gt;
    &lt;p&gt;Beyond Search, the DMA is making it difficult to protect users from scams and malicious links on Android by forcing us to remove our legitimate safeguards that protect usersâ€™ security and safety. Unlike iOS, Android is open by design, meaning that users can download apps from other sources (known as â€œsideloadingâ€). Plus, most devices come with multiple app stores pre-installed. This openness has benefited innovation and choice across Europe but is now under threat.&lt;/p&gt;
    &lt;head rend="h2"&gt;Competitiveness needs clarity&lt;/head&gt;
    &lt;p&gt;The DMAâ€™s biggest challenge remains: How do we boost innovation and deliver cutting-edge products to Europe while navigating complex and untested new rules?&lt;/p&gt;
    &lt;p&gt;Regulatory burdens and uncertainty are delaying our launch of new products, like our latest AI features, by up to a year after they launch in the rest of the world. This delay hurts European consumers and businesses who deserve access to the latest and greatest technology.&lt;/p&gt;
    &lt;head rend="h2"&gt;Time for a reset&lt;/head&gt;
    &lt;p&gt;We have proactively made many changes to our products to comply with the DMA, including offering new opportunities like data portability tools for European businesses and developers. But we and other companies still face considerable uncertainty and unpredictability. This is compounded by overlapping rules from national regulators and cases before national courts that are increasingly undermining the DMAâ€™s goal of creating harmonized, consistent rules across the EU.&lt;/p&gt;
    &lt;p&gt;We call on the Commission to ensure that future enforcement is user-driven, fact-based, consistent and clear. We should have a single-minded focus on benefitting European businesses and consumers and ensuring that they benefit from high-quality products and services. DMA compliance should improve digital markets, not come at the expense of security, integrity, quality or usefulness.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45381013</guid><pubDate>Fri, 26 Sep 2025 00:14:44 +0000</pubDate></item><item><title>Exploit Allows for Takeover of Fleets of Unitree Robots</title><link>https://spectrum.ieee.org/unitree-robot-exploit</link><description>&lt;doc fingerprint="b4089113aaa71981"&gt;
  &lt;main&gt;
    &lt;p&gt;A critical vulnerability in the Bluetooth Low Energy (BLE) Wi-Fi configuration interface used by several different Unitree robots can result in a root level takeover by an attacker, security researchers disclosed on 20 September. The exploit impacts Unitreeâ€™s Go2 and B2 quadrupeds and G1 and H1 humanoids. Because the vulnerability is wireless, and the resulting access to the affected platform is complete, the vulnerability becomes wormable, say the researchers, meaning â€œan infected robot can simply scan for other Unitree robots in BLE range and automatically compromise them, creating a robot botnet that spreads without user intervention.â€&lt;/p&gt;
    &lt;p&gt;Initially discovered by security researchers Andreas Makris and Kevin Finisterre, UniPwn takes advantage of several security lapses that are still present in the firmware of Unitree robots as of 20 September, 2025. As far as IEEE Spectrum is aware, this is the first major public exploit of a commercial humanoid platform.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unitree Robotsâ€™ BLE Security Flaw Exposed&lt;/head&gt;
    &lt;p&gt;Like many robots, Unitreeâ€™s robots use an initial BLE connection to make it easier for a user to set up a Wi-Fi network connection. The BLE packets that the robot accepts are encrypted, but those encryption keys are hardcoded and were published on X (formerly Twitter) by Makris in July. Although the robot does validate the contents of the BLE packets to make sure that the user is authenticated, the researchers say that all it takes to become an authenticated user is to encrypt the string â€˜unitreeâ€™ with the hardcoded keys and the robot will let someone in. From there, an attacker can inject arbitrary code masquerading as the Wi-Fi SSID and password, and when the robot attempts to connect to Wi-Fi, it will execute that code without any validation and with root privileges.&lt;/p&gt;
    &lt;p&gt;â€œA simple attack might be just to reboot the robot, which we published as a proof-of-concept,â€ explains Makris. â€œBut an attacker could do much more sophisticated things: It would be possible to have a trojan implanted into your robotâ€™s startup routine to exfiltrate data while disabling the ability to install new firmware without the user knowing. And as the vulnerability uses BLE, the robots can easily infect each other, and from there the attacker might have access to an army of robots.â€&lt;/p&gt;
    &lt;p&gt;Makris and Finisterre first contacted Unitree in May in an attempt to responsibly disclose this vulnerability. After some back and forth with little progress, Unitree stopped responding to the researchers in July, and the decision was made to make the vulnerability public. â€œWe have had some bad experiences communicating with them,â€ Makris tells us, citing an earlier backdoor vulnerability he discovered with the Unitree Go1. â€œSo we need to ask ourselvesâ€”are they introducing vulnerabilities like this on purpose, or is it sloppy development? Both answers are equally bad.â€ Unitree has not responded to a request for comment from IEEE Spectrum as of press time.&lt;/p&gt;
    &lt;p&gt;â€œUnitree, as other manufacturers do, has simply ignored prior security disclosures and repeated outreach attempts,â€ says VÃ­ctor Mayoral-Vilches, the founder of robotics cybersecurity company Alias Robotics. â€œThis is not the right way to cooperate with security researchers.â€ Mayoral-Vilches was not involved in publishing the UniPwn exploit, but he has found other security issues with Unitree robots, including undisclosed streaming of telemetry data to servers in China which could potentially include audio, visual, and spatial data.&lt;/p&gt;
    &lt;p&gt;Mayoral-Vilches explains that security researchers are focusing on Unitree primarily because the robots are available and affordable. This makes them not just more accessible for the researchers, but also more relevant, since Unitreeâ€™s robots are already being deployed by users around the world who are likely not aware of the security risks. For example, Makris is concerned that the Nottinghamshire Police in the UK have begun testing a Unitree Go2, which can be exploited by UniPwn. â€œWe tried contacting them and would have disclosed the vulnerability upfront to them before going public, but they ignored us. What would happen if an attacker implanted themselves into one of these police dogs?â€&lt;/p&gt;
    &lt;head rend="h2"&gt;How to Secure Unitree Robots&lt;/head&gt;
    &lt;p&gt;In the short term, Mayoral-Vilches suggests that people using Unitree robots can protect themselves by only connecting the robots to isolated Wi-Fi networks and disabling their Bluetooth connectivity. â€œYou need to hack the robot to secure it for real,â€ he says. â€œThis is not uncommon and why security research in robotics is so important.â€&lt;/p&gt;
    &lt;p&gt;Both Mayoral-Vilches and Makris believe that fundamentally itâ€™s up to Unitree to make their robots secure in the long term, and that the company needs to be much more responsive to users and security researchers. But Makris says: â€œThere will never be a 100 percent secure system.â€&lt;/p&gt;
    &lt;p&gt;Mayoral-Vilches agrees. â€œRobots are very complex systems, with wide attack surfaces to protect, and a state-of-the-art humanoid exemplifies that complexity.â€&lt;/p&gt;
    &lt;p&gt;Unitree, of course, is not the only company offering complex state-of-the-art quadrupeds and humanoids, and it seems likely (if not inevitable) that similar exploits will be discovered in other platforms. The potential consequences here canâ€™t be overstatedâ€”the idea that robots can be taken over and used for nefarious purposes is already a science fiction trope, but the impact of a high-profile robot hack on the reputation of the commercial robotics industry is unclear. Robots companies are barely talking about security in public, despite how damaging even the perception of an unsecured robot might be. A robot that is not under control has the potential to be a real physical danger.&lt;/p&gt;
    &lt;p&gt;At the IEEE Humanoids Conference in Seoul from 30 September to 2 October, Mayoral-Vilches has organized a workshop on Cybersecurity for Humanoids, where he will present a brief (co-authored with Makris and Finisterre) titled Humanoid Robots as Attack Vectors. Despite the title, their intent is not to overhype the problem but instead to encourage roboticists (and robotics companies) to take security seriously, and not treat it as an afterthought. As Mayoral-Vilches points out, â€œrobots are only safe if secure.â€&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This Robotics Startup Wants to Be the Boston Dynamics of China â€º&lt;/item&gt;
      &lt;item&gt;Unitreeâ€™s New Go2 Is One Dynamic Quadruped â€º&lt;/item&gt;
      &lt;item&gt;Unitreeâ€™s Go1 Robot Dog Looks Pretty Great, Costs Just USD $2700 â€º&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Evan Ackerman is a senior editor at IEEE Spectrum. Since 2007, he has written over 6,000 articles on robotics and technology. He has a degree in Martian geology and is excellent at playing bagpipes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45381590</guid><pubDate>Fri, 26 Sep 2025 01:38:19 +0000</pubDate></item><item><title>Bit is all we need: binary normalized neural networks</title><link>https://arxiv.org/abs/2509.07025</link><description>&lt;doc fingerprint="853f05b8443e96ce"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 7 Sep 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:1 bit is all we need: binary normalized neural networks&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The increasing size of large neural network models, specifically language models and foundational image models, poses deployment challenges, prompting efforts to reduce memory requirements and enhance computational efficiency. These efforts are critical to ensure practical deployment and effective utilization of these models across various applications. In this work, a novel type of neural network layers and models is developed that uses only single-bit parameters. In this novel type of models all parameters of all layers, including kernel weights and biases, only have values equal to zero or one. This novel type of models uses layers named as binary normalized layer. These binary normalized layers can be of any type, such as fully connected, convolutional, attention, etc., and they consist of slight variations of the corresponding conventional layers. To show the effectiveness of the binary normalized layers, two different models are configured to solve a multiclass image classification problem and a language decoder to predict the next token of a sequence. The model to solve the image classification has convolutional and fully connected layers, and the language model is composed of transformer blocks with multi-head attention. The results show that models with binary normalized layers present almost the same results obtained by equivalent models with real 32-bit parameters. The binary normalized layers allow to develop models that use 32 times less memory than current models and have equivalent performance. Besides, the binary normalized layers can be easily implemented on current computers using 1-bit arrays, and do not require the development of dedicated electronic hardware. This novel type of layers opens a new era for large neural network models with reduced memory requirements that can be deployed using simple and cheap hardware, such as mobile devices or only cpus.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45381631</guid><pubDate>Fri, 26 Sep 2025 01:43:57 +0000</pubDate></item><item><title>All British adults to require a digital ID 'Brit Card'</title><link>https://news.sky.com/video/all-british-adults-to-require-a-digital-id-brit-card-13438041</link><description>&lt;doc fingerprint="5fe9bbf5a091b27f"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;All British adults to require a digital ID 'Brit Card'&lt;/head&gt;&lt;p&gt;The proposals are the government's latest bid to tackle illegal immigration, with the new ID being a form of proof of a citizen's right to live and work in the UK.&lt;/p&gt;&lt;p&gt;Thursday 25 September 2025 16:22, UK&lt;/p&gt;&lt;p&gt;Please use Chrome browser for a more accessible video player&lt;/p&gt;3:01&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45381810</guid><pubDate>Fri, 26 Sep 2025 02:09:47 +0000</pubDate></item><item><title>Writing Memory Safe JIT Compilers</title><link>https://medium.com/graalvm/writing-truly-memory-safe-jit-compilers-f79ad44558dd</link><description>&lt;doc fingerprint="8e229c19fc33becc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Writing Truly Memory Safe JIT Compilers&lt;/head&gt;
    &lt;head rend="h2"&gt;How to kill off a top source of browser exploits&lt;/head&gt;
    &lt;p&gt;Last month the V8 team published an excellent blog post on what they call the V8 Sandbox. This isnâ€™t a sandbox for your JavaScript code â€” itâ€™s intended to mitigate browser exploits caused by bugs in the JIT compiler itself. Thatâ€™s important work because they report that most Chrome exploits start with a V8 memory safety bug.&lt;/p&gt;
    &lt;p&gt;V8 is written in C++, so it may seem like these are the sort of bugs youâ€™d expect from working in a memory-unsafe language. Unfortunately the situation is more complex. Why? The team explain:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There is a catch: V8 vulnerabilities are rarely â€œclassicâ€ memory corruption bugs (use-after-frees, out-of-bounds accesses, etc.) but instead subtle logic issues which can in turn be exploited to corrupt memory. As such, existing memory safety solutions are, for the most part, not applicable to V8. In particular, neither switching to a memory safe language, such as Rust, nor using current or future hardware memory safety features, such as memory tagging, can help with the security challenges faced by V8 today.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;They give an example bug that can cause memory corruption without the engine itself containing any normal memory safety problems, as VM intrinsics or JIT compiled machine code itself may accidentally rely on invalid assumptions about memory.&lt;/p&gt;
    &lt;p&gt;It would be nice if there was a rigorous approach to writing language runtimes that eliminated such bugs by design.&lt;/p&gt;
    &lt;p&gt;GraalVM has a JavaScript engine called GraalJS. Itâ€™s written in Java using the Truffle language framework. Its peak performance is competitive with V8 and on a few benchmarks (such as ray tracing) is actually faster!&lt;/p&gt;
    &lt;p&gt;Although being written in Java does improve memory safety, we just saw that rewriting V8 in a safe language wouldnâ€™t help with the types of bugs V8 is trying to solve and so we would intuitively expect that GraalJS must suffer from the same classes of bugs. Yet, it doesnâ€™t. Letâ€™s take a look at why not. Along the way weâ€™ll explore the first Futamura projection, the core theoretical idea underpinning Truffle.&lt;/p&gt;
    &lt;p&gt;All fast language VMs work the same way. A program is loaded from disk into in-memory data structures representing the program, either an abstract syntax tree or byte code. The program starts running in an interpreter. Parts are soon discovered to be hot spots, i.e. the program spends much more time there than in other parts. Those hot spots are passed to a just-in-time compiler that converts them to optimized machine code, and execution then jumps back and forth between the interpreter and the collection of compiled program fragments. This gives a big performance boost.&lt;/p&gt;
    &lt;p&gt;This architecture is standard â€” both the JVM and V8 use it â€” but viewed from a security perspective the design has a flaw: itâ€™s error prone. The language semantics are implemented twice, once for the interpreter and again for the JIT compiler. Itâ€™s critical not only that both places are fully correct but also that they exactly match. Otherwise, the VM becomes exploitable.&lt;/p&gt;
    &lt;p&gt;Truffle is a Java library that helps you build advanced, high performance language runtimes. VMs built using the Truffle framework operate in a fundamentally different way to conventional VMs, one that not only makes them much easier to write but which also eliminates memory safety bugs by design. It all starts with you writing an interpreter for your language in Java. This doesnâ€™t mean compiling your target language to JVM bytecode â€” in fact bytecode wonâ€™t feature anywhere in this story. You just write an ordinary interpreter. Because the interpreterâ€™s code is garbage collected and bounds-checked, malicious user code canâ€™t use memory safety bugs to exploit it.&lt;/p&gt;
    &lt;p&gt;If you think about conventional Java then this may sound quite slow â€” isnâ€™t Java itself interpreted until it gets JIT compiled? Are we â€¦ interpreting an interpreter? Fortunately not because you can ship your Truffle-based language runtime as a native executable, meaning itâ€™s compiled ahead of time to fully native code using the Graal compiler (from which the wider umbrella project takes its name).&lt;/p&gt;
    &lt;p&gt;So at the start of the userâ€™s program their JavaScript is running in a regular interpreter shipped as a normal executable binary or DLL, but which still benefits from the safety properties of a Java program. Soon some methods get hot. At this point something unconventional happens. The Truffle framework is keeping track of which functions are hot for you and will decide to schedule JIT compilations. But unlike in a conventional VM design, you donâ€™t write your own JIT compiler. Instead your userâ€™s code is automatically compiled by the same general-purpose Graal compiler that was used to convert your interpreter to native code, and execution will start automatically switching back and forth between the interpreter and compiled functions. This is possible thanks to an unusual technique called partial evaluation (or the first Futamura projection).&lt;/p&gt;
    &lt;p&gt;You might not have encountered Futamura projections or partial evaluation before, so what is this strange sounding thing?&lt;/p&gt;
    &lt;p&gt;The core idea is to automatically transform the code of your interpreter to create individual JIT compiled user methods. Instead of needing to carefully implement the language semantics in two places (interpreter and hand-crafted JIT), itâ€™s sufficient to implement it just once. As the interpreter is memory safe and the transform preserves interpreter semantics, the compiled version of the userâ€™s code is guaranteed to match the interpreterâ€™s behavior and is therefore also automatically memory safe. This makes it much harder to slip up and write an exploitable VM.&lt;/p&gt;
    &lt;p&gt;There are several tricks that make this possible. The most important is a new form of constant-ness, added to Java using annotations. In normal programming a variable is either mutable or immutable. An immutable variable is marked with a special keyword such as&lt;code&gt;final&lt;/code&gt; or &lt;code&gt;const&lt;/code&gt; and must be set only once, at the declaration site. Constants are great for compilers because they can be folded, meaning that references to them can be replaced with their value. Consider the following bit of code:&lt;/p&gt;
    &lt;code&gt;class Example {&lt;lb/&gt;    private static final int A = 1;&lt;lb/&gt;    private static final int B = 2;&lt;lb/&gt;&lt;lb/&gt;    static int answer() {&lt;lb/&gt;        return A - B;&lt;lb/&gt;    }&lt;lb/&gt;&lt;lb/&gt;    static String doSomething() {&lt;lb/&gt;        if (answer() &amp;lt; 0) &lt;lb/&gt;            return "OK" &lt;lb/&gt;        else &lt;lb/&gt;            throw new IllegalStateException();&lt;lb/&gt;    }&lt;lb/&gt;}&lt;/code&gt;
    &lt;p&gt;Itâ€™s easy to see the &lt;code&gt;answer()&lt;/code&gt; method will always return the same number. A good compiler will substitute 1 and 2 into the expression yielding &lt;code&gt;return 1 â€” 2&lt;/code&gt; and pre-compute the answer. Then it will inline any calls to answer (i.e. copy/paste the implementation into the call site), substituting those with -1 and thus removing the call overhead as well. That in turn may trigger even more constant folding, such as in the &lt;code&gt;doSomething&lt;/code&gt; method where the compiler will prove that the exception can never be thrown and delete it entirely. Having done that, &lt;code&gt;doSomething&lt;/code&gt; can also be optimized out by simply replacing it with â€œOKâ€, and so on.&lt;/p&gt;
    &lt;p&gt;Thatâ€™s neat, but every compiler can do that â€¦ as long as the constant values are known at compile time. Truffle changes that by introducing a third kind of const-ness called compilation final. If in your interpreter implementation you declare a variable like this:&lt;/p&gt;
    &lt;code&gt;@CompilationFinal private int a = 1;&lt;/code&gt;
    &lt;p&gt;then it will change its const-ness depending on when itâ€™s being accessed. From inside your interpreter, itâ€™s mutable. You will use such variables to implement your interpreter. Theyâ€™ll be set when you load your userâ€™s program and maybe also whilst it runs. Once a function in the userâ€™s script becomes hot, Truffle will work together with the Graal compiler to recompile the parts of the interpreter corresponding to the userâ€™s code, and this time &lt;code&gt;a&lt;/code&gt;will be treated as if it was a constant, i.e. the same as the literal value &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This works for any kind of data, including complex objects. Consider the following highly simplified pseudocode:&lt;/p&gt;
    &lt;code&gt;import com.oracle.truffle.api.nodes.Node;&lt;lb/&gt;&lt;lb/&gt;class JavaScriptFunction extends Node {&lt;lb/&gt;    @CompilationFinal Node[] statements;&lt;lb/&gt;&lt;lb/&gt;    Object execute() {&lt;lb/&gt;        for (var statement : statements) statement.execute();&lt;lb/&gt;    } &lt;lb/&gt;}&lt;/code&gt;
    &lt;p&gt;This is the sort of class you might find in a typical abstract syntax tree interpreter. The &lt;code&gt;statements&lt;/code&gt; array is marked compilation-final. When the program is first loaded we can initialize the array with objects representing the different things a userâ€™s JavaScript function is doing, because itâ€™s mutable. Now imagine that the function represented by this object gets hot. Truffle will start a special compilation of the &lt;code&gt;execute()&lt;/code&gt; method in which Graal is told that the &lt;code&gt;this&lt;/code&gt; pointer should be treated implicitly as compilation-final. Because the object is treated as constant, so can &lt;code&gt;this.statements&lt;/code&gt; also be treated as constant. Itâ€™ll be substituted with the exact contents of a specific &lt;code&gt;JavaScriptFunction&lt;/code&gt; object on the interpreter heap enabling the compiler to unroll the loop inside &lt;code&gt;execute&lt;/code&gt;, transforming it to look like this:&lt;/p&gt;
    &lt;code&gt;Object execute() {&lt;lb/&gt;    this.statements[0].execute();&lt;lb/&gt;    this.statements[1].execute();&lt;lb/&gt;    this.statements[2].execute();&lt;lb/&gt;}&lt;/code&gt;
    &lt;p&gt;Here &lt;code&gt;Node&lt;/code&gt; is a superclass and &lt;code&gt;execute()&lt;/code&gt; is virtual, but that doesnâ€™t matter. Because the list is compilation-final the individual objects in the list are also constant folded, so the &lt;code&gt;execute&lt;/code&gt; method can be de-virtualized (resolved to whatever concrete type it really is) and then inlined as well.&lt;/p&gt;
    &lt;p&gt;And on and on we go. At the end the compiler generates a native function which matches the semantics of the userâ€™s JavaScript (or Python or C++ or whatever language weâ€™re implementing). Invocations of the specific &lt;code&gt;JavaScriptFunction.execute()&lt;/code&gt; method that were compiled are diverted, so when the interpreter invokes it, there will be a transition from interpreter to native code and back. If your interpreter realizes it needs to change a &lt;code&gt;@CompilationFinal&lt;/code&gt; field, for example because the program changes its behavior and invalidates an optimistic assumption you made, that's absolutely fine. Truffle will let you do that and "deoptimizes" the program back to the interpreter for you. Deoptimization (tech talk) is an advanced technique that's normally very hard to implement securely, as it means mapping the optimized CPU state back to the interpreter state and once again, any mistakes can be exploitable (you may be seeing a theme here). But you donâ€™t have to write any of this. Itâ€™s all done for you by Truffle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why does this work?&lt;/head&gt;
    &lt;p&gt;It might not be obvious why partial evaluation actually makes things faster.&lt;/p&gt;
    &lt;p&gt;Interpreters are slow because they have to make a lot of decisions. The userâ€™s program could do anything, so interpreters must constantly check for many possibilities to find out what the program is trying to do at that exact moment. Because branches and memory loads are difficult for the CPU to execute quickly, the whole program ends up being slow. This technique of compiling an interpreter with enhanced constant folding eliminates branches and loads. On top of this, Truffle builds an API that makes it easy to implement advanced optimizations and features for JavaScript or indeed, for any other language you have an interpreter for. For example, it offers a simple API for using assumptions â€” a way to JIT compile code that executes faster by not including code for handling edge cases. If such an edge case is hit then the compiled code can be thrown away and regenerated to take into account that the edge case was observed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recompilation&lt;/head&gt;
    &lt;p&gt;Above we briefly mentioned â€œrecompilationâ€, but glossed over how thatâ€™s possible. We said the interpreter is just native code, right?&lt;/p&gt;
    &lt;p&gt;When the interpreter was compiled ahead of time with the &lt;code&gt;native-image&lt;/code&gt; in preparation for shipping to the userâ€™s computer, the Graal compiler recognized that it was compiling a Truffle-using program. Graal and Truffle are co-developed, so although they can be used independently, when used together they recognize each other and collaborate.&lt;/p&gt;
    &lt;p&gt;Graal changes its behavior in a couple of ways when it notices itâ€™s compiling a Truffle language ahead-of-time. Firstly, it adds a copy of itself to the output program. Interpreter methods are then discovered by doing a static analysis of the program and then stored in the resulting executable, but with a twist: theyâ€™re stored more than once. One version is directly executable machine code. Thatâ€™s your regular generic interpreter. Another is a carefully encoded form of Graalâ€™s intermediate representation (or IR). An IR is sort of half way between the source code you write and the machine code that eventually executes (Graalâ€™s IR is an object graph). Graal also compiles in a garbage collector, either the advanced and mature G1 collector (if you use Oracle GraalVM) or a simpler GC written in pure Java (if you use the GraalVM Community Edition).&lt;/p&gt;
    &lt;p&gt;When a user function gets hot, Truffle looks up the embedded IR for the â€œexecute a user functionâ€ node and partially evaluates it. The evaluation is interleaved with the parsing of the graph IR to ensure that the process is as efficient as possible â€” if something wonâ€™t be executed because constant folding already proved it canâ€™t be reached it wonâ€™t even be decoded or seen by the compiler. This also ensures that memory usage during the compile is kept low.&lt;/p&gt;
    &lt;head rend="h2"&gt;My only friend, the end&lt;/head&gt;
    &lt;p&gt;And thatâ€™s it! Thatâ€™s how an entire class of subtle safety bugs is eliminated in GraalJS: because the semantics of the language are defined by the memory-safe interpreter and then partially evaluated, the generated machine code is also memory safe by construction.&lt;/p&gt;
    &lt;p&gt;What about the V8 sandbox that the original blog post is about? Expressing pointers as offsets from a heap base is a great idea thatâ€™s already used in GraalVM natively compiled binaries. However this is done for performance, as the other memory safety mechanisms mean thereâ€™s no need for mitigating heap overwrites.&lt;/p&gt;
    &lt;p&gt;None of the above is in any way specific to JavaScript, and nor are Truffleâ€™s benefits limited to security and performance. In fact Truffle automatically adds many other features to your language, such as debugging (through Chrome Debuggerâ€™s wire protocol), language interop with both Java/Kotlin/etc and any other Truffle language, a fast regular expression engine, a fast foreign function interface, profiling tools, heap snapshotting and much more. Truffle has been used to build over 30 language VMs for dozens of languages, including languages you wouldnâ€™t expect to have such features such as the recent Pkl configuration language from Apple.&lt;/p&gt;
    &lt;p&gt;If this article has whetted your appetite to learn more, take a look at the documentation or this tech talk on how it all works.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45381813</guid><pubDate>Fri, 26 Sep 2025 02:10:31 +0000</pubDate></item></channel></rss>