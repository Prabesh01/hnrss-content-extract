<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 15 Sep 2025 06:16:43 +0000</lastBuildDate><item><title>Repetitive negative thinking associated with cognitive decline in older adults</title><link>https://bmcpsychiatry.biomedcentral.com/articles/10.1186/s12888-025-06815-2</link><description>&lt;doc fingerprint="7f1fa9232da10d63"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Research&lt;/item&gt;
      &lt;item&gt;Open access&lt;/item&gt;
      &lt;item&gt;Published:&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Repetitive negative thinking is associated with cognitive function decline in older adults: a cross-sectional study&lt;/head&gt;
    &lt;p&gt;BMC Psychiatry volume 25, Article number: 562 (2025)&lt;/p&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;head rend="h3"&gt;Background&lt;/head&gt;
    &lt;p&gt;Psychological problems such as depression and anxiety increase the risk of cognitive impairment in older adults. But mechanisms on the effect of psychological disorder on cognitive function is inconclusive. Repetitive negative thinking (RNT) is a core symptom of a number of common psychological disorders and may be a modifiable process shared by many psychological risk factors that contribute to the development of cognitive impairment. RNT may increase the risk of cognitive impairment. However, there are fewer studies related to RNT and cognitive function, and there is a lack of epidemiological studies to explore the relationship between RNT and cognitive function.&lt;/p&gt;
    &lt;head rend="h3"&gt;Methods&lt;/head&gt;
    &lt;p&gt;A cross-sectional study of 424 older adults aged 60 years or over was performed form May to November 2023 in hospital. To investigate the RNT level by using the Perseverative Thinking Questionnaire (PTQ), and investigate the cognitive function level by using the Montreal Cognitive Assessment Scale (MoCA). Multivariable linear regression and subgroup analyses were used to explore the relationship between RNT and cognitive function.&lt;/p&gt;
    &lt;head rend="h3"&gt;Results&lt;/head&gt;
    &lt;p&gt;We categorized the total RNT scores into quartiles. The multivariable linear regression analysis showed that after adjusting for all covariates, the participants in the Q3 and Q4 groups exhibited lower cognition scores (Q3:β = -0.180, 95%CI -2.849~-0.860; Q4:β = -0.164, 95% -2.611~-0.666) compared to the Q1 group. The results of the subgroup analyses showed that individuals aged 60 ~ 79 years, junior high school and above are more prone to suffer from cognitive impairment with a high RNT score.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The study reveals a negative association between RNT and cognitive function in community-dwelling older adults. However, multi-center and a longer time span cohort studies on the relationship between RNT and cognitive function should be carried out to further explore the mechanisms involved.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In the context of a grim situation of population aging and a prominent trend of advanced aging in China, cognitive impairment has become one of the major diseases that seriously endanger the health of the older adults and affect the sustainable development of the society, which has a negative impact on the physical and psychological health as well as the quality of life of the older adults. The onset of cognitive impairment begins with the age-related declines in cognitive function, progresses to mild cognitive impairment (MCI), and ends with dementia [1]. The patients unable to live independently in the later stages of the disease. Around 55 million people worldwide currently suffer from dementia, with the figure expected to reach 139 million by 2050 [2]. The prevalence of dementia in China aged 60 years and over is 6.0%, and the prevalence of MCI is 15.5% [3]. The prevalence of cognitive disorders is increasing year by year, placing a heavy burden on patients, families, and society. It is estimated that the total annual cost of dementia disease in China will reach $1.89 trillion in 2050 [4]. However, there is no drug that can stop or reverse the progression of dementia. Cognitive decline can be effectively prevented or delayed by controlling risk factors at an early stage, so it is important to identify, prevent, and treat risk factors associated with cognitive impairment [5].&lt;/p&gt;
    &lt;p&gt;With the rapid development of society, the transformation of family structures, and the decline of physiological functions brought about by aging, the psychological health problems of the older adults have become increasingly prominent [6, 7]. Anxiety and depression are the most common psychological health problems among the older adults, and the probability of suffering from depressive symptoms is currently 22.6% and that of suffering from anxiety symptoms is 22.11% in China [8, 9]. Various physical illnesses caused by psychological problems in older adults threaten their physical and psychological health and the quality of existence. Psychological problems such as depression and anxiety have been found to increase the risk of cognitive impairment in older adults [10, 11]. But mechanisms on the effect of psychological disorder on cognitive function is inconclusive [12, 13].&lt;/p&gt;
    &lt;p&gt;RNT includes rumination and worry. Rumination refers to a maladaptive response style, which is characterised by repeated and unconscious passive thinking about the causes, consequences and effects of negative life events, and a persistent preoccupation with negative experiences rather than taking positive practical action [14]. Worry describes repetitive thoughts about potential threats, uncertain events, and risky events in the future [15]. The main difference between rumination and worry is in time and content [16]. It has been found that heightened levels of rumination and/or worry are present in the most Axis I disorder, including 13 categories of psychological disorders such as depression, anxiety disorders, sleep disorders, and post-traumatic stress disorder [17,18,19]. Based on the widespread presence of rumination and worry across disorders, is has been suggested that RNT is a transdiagnostic process that shows the same characteristics across disorders, whereby only the content is disorder-specific [20]. RNT is the repetitive thinking about one or more negative issues that are difficult to control [21]. Research has shown that RNT is a core symptom of depression, anxiety, and many other common psychological illnesses. The higher levels of RNT lead to increased susceptibility to a wide range of mood disorders [22]. RNT as a common process in Axis I disorder may be a common pathway for psychological disorder leading to an increased risk of dementia. Therefore, we propose that RNT may be a modifiable process for many of the psychological risk factors that contribute to cognitive decline and it increase the risk of cognitive decline.&lt;/p&gt;
    &lt;p&gt;RNT has been found to correlate with dementia biomarkers, global cognition, and subjective cognitive decline in older adults [23, 24]. Although these studies provide evidence of a relationship between RNT and poorer objective and subjective cognition. Since differences in the study populations and assessment methods of different studies may have an impact on the results, we aimed to explore the association between RNT and cognitive function in community-dwelling older adults in China to provide evidence for the prevention of cognitive decline.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methods&lt;/head&gt;
    &lt;head rend="h3"&gt;Population&lt;/head&gt;
    &lt;p&gt;In this study, a cross-sectional study method was used to select participants from community in Wuhan. The sample size was calculated using the formula of [Z2P(1-P)]/d2, at level of significance at 0.05 and CI of 95% [25]. The prevalence of cognitive disorder in the Wuhan was taken at a level of 0.878 with a relative precision of 0.05 [26]. A sample size of 190 participant was estimated to assess its correlation with RNT with a potential a dropout rate of 15%. The questionnaire survey was conducted from May 2023 to November 2023 among 424 participants in the community of Wuhan. The inclusion criteria for participants included: (1) age over 60 years; (2) a local residence time ≥ 6 months; (3) ability to communicate normal and complete the questionnaire; and (4) signed informed consent. Considering the impact of selected diseases on the cognitive function, the exclusion criteria included: (1) presence dementia such as Alzheimer’s disease, vascular dementia, and other neurological diseases that can cause brain dysfunction, which diagnosed by a medical institution; (2) presence of severe heart, liver, and kidney diseases and malignant tumours; (3) alcohol, drug abuse or dependence within the previous 2 years; (4) have psychological disease diagnosed by a medical institution. Prior to both the interviews and examinations, all participants provided informed consent. The study was approved by the Ethics Committee of Hubei University of Chinese Medicine (Approved No. of ethic committee: 2019-IEC-003).&lt;/p&gt;
    &lt;head rend="h3"&gt;Repetitive negative thinking assessment&lt;/head&gt;
    &lt;p&gt;RNT was assessed using the perseverative thinking questionnaire (PTQ). The scale consists of 15 items covering three domains: core characteristics of RNT, unproductiveness, and psychological capacity captured. Each item is rated on a 5-point Likert scale from 0 “never” to 4 “almost always”, with a total score ranging from 0 to 60. The higher score of PTQ represents higher levels of RNT. The Cronbach’s α of PTQ is 0.95 [20]. The questionnaire is currently available in Chinese, German, English, Polish and French. Good reliability and validity when applied to the older adults, young people, children and women [27, 28].&lt;/p&gt;
    &lt;head rend="h3"&gt;Cognitive function assessment&lt;/head&gt;
    &lt;p&gt;Montreal Cognitive Assessment (MoCA) Test is a widely used screening assessment tool for cognitive function of older adults. Studies have shown that the MoCA test has high sensitivity (80-100%) and specificity (50-76%) in identifying MCI, and it is more accurate than the Mini-Mental State Examination Scale in distinguishing between normal and MCI (Grade A recommendation) [29]. The MoCA test measures a wider range of cognitive domains, including visuospatial abilities, executive functions, attention, memory, concentration, language, verbal abstraction, and orientation. There are a total of 11 test entries with a total score of 30, with higher scores indicating better cognitive function. One additional point was given to patients having &amp;lt; 12 years of education for the MoCA scale. Cognitive function was assessed with MoCA (Beijing version). The Cronbach’s α of MoCA is 0.818, which has a good measurement characteristic [30].&lt;/p&gt;
    &lt;head rend="h3"&gt;Covariates&lt;/head&gt;
    &lt;p&gt;In our study, covariates were used to mitigate potential confounding influences on the relationship between RNT and cognitive function, grounded on insights from prior research literature. These covariates included gender, age, occupation, marital status, living arrangement, education level, monthly income, and number of chronic disease, family history of Alzheimer’s disease, and number of hobbies.&lt;/p&gt;
    &lt;head rend="h3"&gt;Statistical analysis&lt;/head&gt;
    &lt;p&gt;Quantitative data are presented as mean ± standard deviation, while qualitative data are expressed as numbers (percentages). Data were tested for independence, normality, and homogeneity of the variances before statistical analyses. Independent samples t-test was used to compare the measurement data between the two groups. Multi-group comparison was determined by the one‐way ANOVA or Welch’s test as appropriate. If p &amp;lt; 0.05, the data of the two groups were considered to have statistical differences. Associations between normally distributed variables were analyzed using Pearson correlation. To examine the association between RNT and cognitive function, a linear regression model was conducted. In order to enrich the findings and provide clearer clinical implications, total RNT score was categorized based on quartiles (Q1: &amp;lt; 25th percentile, Q2: 25 to 50th percentile, Q3: 50 to 75th percentile, Q4: ≥ 75th percentile) with Q1 as the reference category. Furthermore, subgroup analyses were conducted based on factors such as age and educational level to investigate whether these factors influenced the relationship between RNT and cognitive function. A P-value &amp;lt; 0.05 was considered statistically significant. SPSS 25.0 was used for statistical analysis in this study. This was an exploratory analysis; thus, adjustment for multiple comparisons was not made.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;head rend="h3"&gt;Participants characteristics&lt;/head&gt;
    &lt;p&gt;Table 1 presents participant characteristics. This analysis included 424 participants from Wuhan in Hubei Province. Of these participants, 161 (37.97%) were male and 263 (62.03%) were female, and the weighted mean age was 68.93 ± 0.26 years. Different age, occupation, marital status, living arrangement, education level, monthly income, and number of hobbies were significantly different across the cognitive function.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cognitive function scores for comparison among the RNT quartiles&lt;/head&gt;
    &lt;p&gt;Table 2 presents the relationship between RNT and cognitive function. The results of the Pearson correlation analyses showed that RNT is associated with global cognition and cognitive domains except language skills.&lt;/p&gt;
    &lt;p&gt;Table 3 presents the comparison of the cognitive function in RNT quartiles. The interquartile ranges of RNT scores were 0 to 5, 6 to 12, 13 to 21.75, and 21.75 to 47, respectively. After stratifying the RNT, MoCA scores and cognitive domains score revealed differences in RNT quartiles. Participants in the Q3 and Q4 groups exhibited lower MoCA scores, visuospatial function score, naming score, abstracting score, memory score (P &amp;lt; 0.05).&lt;/p&gt;
    &lt;head rend="h3"&gt;Association between the RNT and cognitive function: results of regression analysis&lt;/head&gt;
    &lt;p&gt;Table 4 presents the findings of multivariable linear regression analysis on the association between RNT and cognitive function. All regressions passed independence, normality test, and homogeneity of variances. Our research indicated that RNT was negatively associated with cognitive scores. The association remained statistically significant across all multivariate linear regression models, even after controlling for various covariates such as age, occupation, marital status, living arrangement, education level, monthly income, and number of hobbies. Age, education level, and RNT retained their statistical significance when entered into the final regression model. In Model 2, the participants in the Q3 and Q4 groups exhibited lower cognition scores (Q3:β = -0.180, 95%CI -2.849~-0.860; Q4:β = -0.164, 95% -2.611~-0.666) compared to the Q1 group.&lt;/p&gt;
    &lt;head rend="h3"&gt;Subgroup analysis&lt;/head&gt;
    &lt;p&gt;The final variables included in Model 2 included the variables age and education level in addition to RNT. Therefore, we want to further explore whether there is a correlation between RNT and cognition within different subgroups, including age (60 ~ 69 vs. 70 ~ 79 vs. ≥ 80 ~ 90) and education level (Illiteracy vs. Primary school vs. Junior high school vs. High school and above). The covariates included were those that were meaningful in the univariate analysis (age, occupation, marital status, living arrangement, education level, monthly income, and number of hobbies). The outcomes are displayed in Table 5. After adjusting for potential confounders, it was observed that RNT was negatively associated with cognitive function in the 60 ~ 79, middle school, and high school/technical school/secondary school groups. Within these subgroups, higher RNT scores were related to lower cognitive function scores. In contrast, RNT was not associated with cognitive function in the 80 ~ 90, primary school, and illiteracy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;The present study suggested that the risk of cognitive impairment increased with higher RNT scores among older adults, and the robustness of the finding was confirmed through adjustment for various potential confounding variables. Additionally, individuals aged 60 ~ 79 years, junior high school and above were more prone to suffer from cognitive impairment with a high RNT score. However, the correlation between RNT and cognitive function was not significant in older adults aged 80 to 90 years, or those in elementary school and below.&lt;/p&gt;
    &lt;p&gt;To date, there have been limited endeavors to explore the correlation between RNT and cognitive function in older adults. Marchant et al. conducted a cohort study in 2016 to find that RNT was associated with decline in cognition, including global cognition, immediate and delayed memory [23]. In addition, the study found that increased level of RNT was associated with cognitive decline and neuroimaging biomarkers of Alzheimer’s disease (i.e., amyloid, tau). Another cross-sectional study found that increased level of RNT was associated with worse subjective cognition and increased memory complaints. Consistent with previous studies, our data demonstrates that higher level of RNT is related to worsecognitive function. In addition to this, this study found RNT was associated with cognitive domains except language skills. When participants were stratified by age and education level, a notable negative correlation was observed between RNT and cognitive function among older adults aged 60~69 years or junior high school and above. There are reasons why RNT does not correlate with cognitive function in older adults who are 80 to 90 years of age or have elementary school or below as follows. Increased brain aging in this age group may have altered the relationship between cognition and mood, or it may have weakened the association. The limited ability of older adults with low education level to perceive and express RNT resulted in a non-significant correlation between RNT and cognitive function.&lt;/p&gt;
    &lt;p&gt;The underlying mechanisms linking psychological disorder to cognitive function remain vague. One study found that increased level of RNT was closely related to gray and white matter structures in the brain, particularly in the dorso-lateral prefrontal cortex, anterior cingulate cortex, the arcuate fasciculus, and superior longitudinal fasciculus [31]. These regions are related to cognitive control, emotion processing and regulation [32]. Increased level of RNT may lead to changes in the brain’s structural functions related to cognitive control, leading to further cognitive decline. Cognitive debt theory suggests that psychology disorder can lead to damage to the hippocampus by increasing glucocorticoid levels and inducing inflammation and vascular disease in the brain, which impairs cognitive function [33]. RNT as a common trait of many types of psychology disorder, can be initiated and maintained without external triggers or awareness and narrows the scope of attention to repeatedly activated negative thoughts, thus provoking the individual to repeatedly experience physical and psychological distress, leading to the onset of psychology disorders, which in turn may increase the risk of cognitive impairment. As a person adopts the habits of negative thinking for a long-term, it constantly depletes the brain’s limited resources, leading to a decline in the brain’s ability to attention, executive functions, and memory [34, 35]. Older adulthood is a special stage with more pressure and stressful events. Along with the aging process, older adults will face physiological changes such as reduced self-care, frailty and the development of physical illnesses [36,37,38]. At the same time, they will experience negative stressful events such as a reduction in financial income, a decline in social status, and the death of friends and partners [39, 40]. These make older adults vulnerable to RNT, which further can have a range of negative effects on them.&lt;/p&gt;
    &lt;p&gt;Age is the biggest and uncontrollable risk factor for cognitive decline [41]. Literature has indicated that MCI incidence in China was 11.9% for older adults ages 60 to 69, 19.3% for 70 to 79, 24.4% for 80 to 89, 33.1% for 90 and above [3]. People over 80 are the fastest growing demographic around the world and they are at higher risk of developing cognitive impairment [42]. With the aging process, the physiological of the older adults gradually decline with the structure and function of the brain tissue gradual decline and the function of neural cell loss [43]. In addition, the continued accumulation of health risk factors increases the risk of chronic diseases such as hypertension, diabetes and coronary heart disease [44]. This disease led to amyloid plaque deposition through several mechanisms, such as increased oxidative stress, promoting inflammatory reaction, caused metabolic disorders. These mechanisms increase the risk of cognitive decline.&lt;/p&gt;
    &lt;p&gt;Education level is a more consistent influence on cognitive function in most studies. Older adults with lower levels of education generally have limited nutritional conditions in early childhood or limited educational resources, which may have an impact on cognitive function [45]. They are more likely to be engaged in manual occupation and lack of exercise for brain, which leads to premature degeneration of neurons in the brain, thus reducing cognitive function [46]. In addition, older adults with lower levels of education may lack such knowledge, further increasing the risk of cognitive impairment [47].&lt;/p&gt;
    &lt;p&gt;This study offered multiple strengths. Firstly, in examining the association between RNT and cognitive function, the study eliminated as many bias-inducing factors as possible to ensure more reliable results through previous research and by conducting in-depth analyses that took into account a variety of possible potential confounders. Secondly, the study investigated the relationship between RNT and cognitive function through regression and subgroup analysis suggesting a negative association between RNT and cognitive function in community-dwelling older adults. In the future, the assessment of mental health can be incorporated into the health screening of older adults to comprehensively evaluate their health status. Health professionals and carers can enhance the assessment of RNT in older adults and identify problems promptly. By developing interventions to avoid further exacerbation of psychological problems in the elderly and increased risk of other diseases such as cognitive impairment.&lt;/p&gt;
    &lt;p&gt;However, there were limitations in the present study. First, a definitive causal relationship between RNT and cognitive function could not determine in this study since this study was a cross-sectional design. Secondly, since convenience sampling method was used in this study and all the participants in our study were selected only from Wuchan District and Hongshan District in Wuhan city, which suffered short time span, small sample size, and bad representativeness. In the future, multi-center and a longer time span cohort studies on the relationship between RNT and cognitive function should be carried out to further explore the mechanisms involved. Nonetheless, these findings have implications that are crucial to interventions that promote cognitive function in older adults.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;In conclusion, this is the first study to investigate the relationship between RNT and cognitive function in Chinese older adults. After adjusting for a range of confounders, RNT is associated with cognitive function decline in older adults. The assessment of RNT levels in older adults can be enhanced, and psychological interventions and other measures can be taken to reduce RNT levels and further prevent cognitive decline.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data availability&lt;/head&gt;
    &lt;p&gt;The datasets used and/or analysed during the current study are available from the corresponding author on reasonable request.&lt;/p&gt;
    &lt;head rend="h2"&gt;Change history&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;23 July 2025&lt;/head&gt;
        &lt;p&gt;In the original publication, the affiliations 1 and 2 were incorrect. The article has been updated to rectify the errors.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Abbreviations&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;RNT:&lt;/item&gt;
      &lt;item rend="dd-1"&gt;
        &lt;p&gt;Repetitive negative thinking&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-2"&gt;PTQ:&lt;/item&gt;
      &lt;item rend="dd-2"&gt;
        &lt;p&gt;Perseverative Thinking Questionnaire&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-3"&gt;MCI:&lt;/item&gt;
      &lt;item rend="dd-3"&gt;
        &lt;p&gt;Mild cognitive impairment&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-4"&gt;MoCA:&lt;/item&gt;
      &lt;item rend="dd-4"&gt;
        &lt;p&gt;Montreal Cognitive Assessment&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Canadian Task Force on Preventive Health Care, Pottie K, Rahal R, Jaramillo A, Birtwhistle R, Thombs BD, et al. Recommendations on screening for cognitive impairment in older adults. CMAJ. 2016;188(1):37–46. https://doi.org/10.1503/cmaj.141165.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;GBD 2019 Dementia Forecasting Collaborators. Estimation of the global prevalence of dementia in 2019 and forecasted prevalence in 2050: an analysis for the global burden of disease study 2019. Lancet Public Health. 2022;7(2):e105–25. https://doi.org/10.1016/S2468-2667(21)00249-8.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jia L, Du Y, Chu L, Zhang Z, Li F, Lyu D, et al. Prevalence, risk factors, and management of dementia and mild cognitive impairment in adults aged 60 years or older in China: a cross-sectional study. Lancet Public Health. 2020;5(12):e661–71. https://doi.org/10.1016/S2468-2667(20)30185-7.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jia J, Wei C, Chen S, Li F, Tang Y, Qin W, et al. The cost of Alzheimer’s disease in China and re-estimation of costs worldwide. Alzheimer’s Dement J Alzheimer’s Assoc. 2018;14(4):483–91. https://doi.org/10.1016/j.jalz.2017.12.006.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Livingston G, Sommerlad A, Orgeta V, Costafreda SG, Huntley J, Ames D, et al. Dementia prevention, intervention, and care. Lancet. 2017;390(10113):2673–734. https://doi.org/10.1016/S0140-6736(17)31363-6.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Zhou D, Zhan Q, Li L. The impact of self-employment on mental health of the younger elderly in China. BMC Geriatr. 2023;23(1):280. https://doi.org/10.1186/s12877-023-03948-5.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sivakumar PT, Mukku SSR, Antony S, Harbishettar V, Kumar CN, Math SB. Implications of mental healthcare act 2017 for geriatric mental health care delivery: A critical appraisal. Indian J Psychiatry. 2019;61(Suppl 4):S763–7. https://doi.org/10.4103/psychiatry.IndianJPsychiatry_100_19.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Wang H, Hou Y, Zhang L, Yang M, Deng R, Yao J. Chinese elderly migrants’ loneliness, anxiety and depressive symptoms: the mediation effect of perceived stress and resilience. Front Public Health. 2022;10:998532. https://doi.org/10.3389/fpubh.2022.998532.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Li CWY, Yao YT, Hu YD. Mental health status of the elderly in China and intervention suggestions. China Med Herald. 2021;18(15):192–6.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Boyle LL, Porsteinsson AP, Cui X, King DA, Lyness JM. Depression predicts cognitive disorders in older primary care patients. J Clin Psychiatry. 2010;71(1):74–9. https://doi.org/10.4088/JCP.08m04724gry.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gulpers BJA, Verhey FRJ, Eussen SJPM, Schram MT, de Galan BE, van Boxtel MPJ, et al. Anxiety and cognitive functioning in the Maastricht study: A cross-sectional population study. J Affect Disord. 2022;319:570–9. https://doi.org/10.1016/j.jad.2022.09.072.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Botto R, Callai N, Cermelli A, Causarano L, Rainero I. Anxiety and depression in Alzheimer’s disease: a systematic review of pathogenetic mechanisms and relation to cognitive decline. Neurol Sci. 2022;43(7):4107–24. https://doi.org/10.1007/s10072-022-06068-x.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hou P, Xue H, Zhang Y, Ping Y, Zheng Y, Wang Y, et al. Mediating effect of loneliness in the relationship between depressive symptoms and cognitive frailty in Community-Dwelling older adults. Brain Sci. 2022;12(10):1341. https://doi.org/10.3390/brainsci12101341.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nolen-Hoeksema S. Sex differences in unipolar depression: evidence and theory. Psychol Bull. 1987;101(2):259–82.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Borkovec TD, Robinson E, Pruzinsky T, DePree JA. Preliminary exploration of worry: some characteristics and processes. Behav Res Ther. 1983;21(1):9–16. https://doi.org/10.1016/0005-7967(83)90121-3.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mahoney AE, McEvoy PM, Moulds ML. Psychometric properties of the repetitive thinking questionnaire in a clinical sample. J Anxiety Disord. 2012;26(2):359–67. https://doi.org/10.1016/j.janxdis.2011.12.003.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ehring T, Watkins ER. Repetitive negative thinking as a transdiagnostic process. Int J Cogn Therapy. 2008.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nota JA, Coles ME. Shorter sleep duration and longer sleep onset latency are related to difficulty disengaging attention from negative emotional images in individuals with elevated transdiagnostic repetitive negative thinking. J Behav Ther Exp Psychiatry. 2018;58:114–22. https://doi.org/10.1016/j.jbtep.2017.10.003.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Spinhoven P, van Hemert AM, Penninx BW. Repetitive negative thinking as a predictor of depression and anxiety: a longitudinal cohort study. J Affect Disord. 2018;241:216–25. https://doi.org/10.1016/j.jad.2018.08.037.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ehring T, Zetsche U, Weidacker K, Wahl K, Schönfeld S, Ehlers A. The perseverative thinking questionnaire (PTQ): validation of a content-independent measure of repetitive negative thinking. J Behav Ther Exp Psychiatry. 2011;42(2):225–32. https://doi.org/10.1016/j.jbtep.2010.12.003.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nolen-Hoeksema S, Wisco BE, Lyubomirsky S. Rethinking rumination. Perspect Psychol Sci. 2008;3(5):400–24. https://doi.org/10.1111/j.1745-6924.2008.00088.x.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;McEvoy PM, Watson H, Watkins ER, Nathan P. The relationship between worry, rumination, and comorbidity: evidence for repetitive negative thinking as a transdiagnostic construct. J Affect Disord. 2013;151(1):313–20. https://doi.org/10.1016/j.jad.2013.06.014.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Marchant NL, Lovland LR, Jones R, et al. Repetitive negative thinking is associated with amyloid, Tau, and cognitive decline. Alzheimers Dement. 2020;16(7):1054–64. https://doi.org/10.1002/alz.12116.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Schlosser M, Demnitz-King H, Whitfield T, Wirth M, Marchant NL. Repetitive negative thinking is associated with subjective cognitive decline in older adults: a cross-sectional study. BMC Psychiatry. 2020;20(1):500. https://doi.org/10.1186/s12888-020-02884-7.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kelsey J, Whittemore A, Evans A, Thompson W. Methods of sampling and Estimation of sample size. Methods Observational Epidemiol. 1996;311:340.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ai YT, Hu H, Wang L, Gao XL, Wang ZC, Ren HR et al. Current status of cognitive function and risk factors of the older adults in Wuhan. Chinese Journal of Gerontology. 2019;39(10):2507–2510. doi: 10. 3969/j. issn. 1005–9202. 2019. 10. 065.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kornacka M, Buczny J, Layton RL. Assessing repetitive negative thinking using categorical and transdiagnostic approaches: a comparison and validation of three Polish Language adaptations of Self-Report questionnaires. Front Psychol. 2016;7:322. https://doi.org/10.3389/fpsyg.2016.00322.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Devynck F, Kornacka M, Baeyens C, Serra É, Neves JFD, Gaudrat B, et al. Perseverative thinking questionnaire (PTQ): French validation of a transdiagnostic measure of repetitive negative thinking. Front Psychol. 2017;8:2159. https://doi.org/10.3389/fpsyg.2017.02159.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;China Dementia and Cognitive Disorders Guidelines Writing Group, Professional Committee of Cognitive Impairment Diseases of Chinese Medical Doctor Association Neurosurgery Branch. 2018 China dementia and cognitive disorders diagnosis and treatment guidelines (V): diagnosis and treatment of mild cognitive impairment. Nat. Med. J. China. 2018,98(17):1294–1301. https://doi.org/10.3760/cma.j.issn.0376-2491.2018.17.00&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Zhang LX, Liu XQ. A study on reliability and validity of MOCA scale of Chinese version. Chin Nurs Res. 2007;31:2906–7.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Demnitz-King H, Göehre I, Marchant NL. The neuroanatomical correlates of repetitive negative thinking: A systematic review. Psychiatry Res Neuroimaging. 2021;316:111353. https://doi.org/10.1016/j.pscychresns.2021.111353.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Liu S, Abdellaoui A, Verweij KJH, van Wingen GA. Gene expression has distinct associations with brain structure and function in major depressive disorder. Adv Sci (Weinh). 2023;10(7):e2205486. https://doi.org/10.1002/advs.202205486.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Wu JJ, Wang HX, Yao W, Yan Z, Pei JJ. Late-life depression and the risk of dementia in 14 countries: a 10-year follow-up study from the survey of health, ageing and retirement in Europe. J Affect Disord. 2020;274:671–7. https://doi.org/10.1016/j.jad.2020.05.059.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lewis EJ, Blanco I, Raila H, Joormann J. Does repetitive negative thinking affect attention? Differential effects of worry and rumination on attention to emotional stimuli. Emotion. 2019;19(8):1450–62. https://doi.org/10.1037/emo0000535.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mennies RJ, Stewart LC, Olino TM. The relationship between executive functioning and repetitive negative thinking in youth: A systematic review of the literature. Clin Psychol Rev. 2021;88:102050. https://doi.org/10.1016/j.cpr.2021.102050.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Alavijeh MS, Zandiyeh Z, Moeini M. The effect of self-care self-efficacy program on life satisfaction of the Iranian elderly. J Educ Health Promot. 2021;10(1):167. https://doi.org/10.4103/jehp.jehp_928_20.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dent E, Lien C, Lim WS, Wong WC, Wong CH, Ng TP, et al. The Asia-Pacific clinical practice guidelines for the management of frailty. J Am Med Dir Assoc. 2017;18(7):564–75. https://doi.org/10.1016/j.jamda.2017.04.018.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Wen W, Zhang Y, Shi W, Li J. Association between internet use and physical health, mental health, and subjective health in Middle-aged and older adults: nationally representative Cross-sectional survey in China. J Med Internet Res. 2023;25:e40956. https://doi.org/10.2196/40956.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Friebe J, Schmidt-Hertha B. Activities and barriers to education for elderly people. J Contemp Educ Stud. 2013;64:1.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Azizi A, Sepahvandi MA, Peyda N, Mohamadi J. Effective approach to the study of aging: grounded theory study. Iran J Ageing. 2016;10(4):88–101.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Prince M, Bryce R, Albanese E, Wimo A, Ribeiro W, Ferri CP. The global prevalence of dementia: a systematic review and metaanalysis. Alzheimers Dement. 2013;9:63–75. https://doi.org/10.1016/j.jalz.2012.11.00.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Zhang PD, Lv YB, Li ZH, Yin ZX, Li FR, Wang JN, et al. Age, period, and cohort effects on activities of daily living, physical performance, and cognitive functioning impairment among the Oldest-Old in China. J Gerontol Biol Sci Med Sci. 2020;75(6):1214–21. https://doi.org/10.1093/gerona/glz196.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Wang L, Cao M, Pu T, Huang H, Marshall C, Xiao M. Enriched physical environment attenuates Spatial and social memory impairments of aged socially isolated mice. Int J Neuropsychopharmacol. 2018;21(12):1114–27. https://doi.org/10.1093/ijnp/pyy084.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Matyjaszek-Matuszek B, Lenart-Lipińska M, Woźniakowska E. Clinical implications of vitamin D deficiency. Prz Menopauzalny. 2015;14(2):75–81. https://doi.org/10.5114/pm.2015.52149.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Aihemaitijiang S, Ye C, Halimulati M, Huang X, Wang R, Zhang Z. Development and validation of nutrition literacy questionnaire for the Chinese elderly. Nutrients. 2022;14(5):1005. https://doi.org/10.3390/nu14051005.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hämmig O, Bauer GF. The social gradient in work and health: a cross-sectional study exploring the relationship between working conditions and health inequalities. BMC Public Health. 2013;13:1170. https://doi.org/10.1186/1471-2458-13-1170.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Zhang D, Wu S, Zhang Y, Yang P, MacIntyre CR, Seale H, et al. Health literacy in Beijing: an assessment of adults’ knowledge and skills regarding communicable diseases. BMC Public Health. 2015;15:799. https://doi.org/10.1186/s12889-015-2151-1.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;The authors thank all the study participants.&lt;/p&gt;
    &lt;head rend="h2"&gt;Funding&lt;/head&gt;
    &lt;p&gt;This study was funded by a National Natural Science Foundation of China in 2019(81973921). The authors appreciate the staff and residents of the institutions who participated in the study.&lt;/p&gt;
    &lt;head rend="h2"&gt;Author information&lt;/head&gt;
    &lt;head rend="h3"&gt;Authors and Affiliations&lt;/head&gt;
    &lt;head rend="h3"&gt;Contributions&lt;/head&gt;
    &lt;p&gt;NSY involved in conception of study, acquisition of data, data entry, interpretation of results and drafting manuscript. LP and BD involved in acquisition of data and finalization of manuscript. HH involved in conception of study, acquisition of data, interpretation of results and finalization of manuscript. YCW, TYZ, and YTA involved in finalization of manuscript. XTL, SZ, and YCL involved in acquisition of data and data entry.&lt;/p&gt;
    &lt;head rend="h3"&gt;Corresponding author&lt;/head&gt;
    &lt;head rend="h2"&gt;Ethics declarations&lt;/head&gt;
    &lt;head rend="h3"&gt;Ethics approval and consent to participate&lt;/head&gt;
    &lt;p&gt;The study was reviewed and approved by the Medical Ethics Committee of Hubei University of Chinese Medicine (Approved No. of ethic committee: [2019]IEC(003)). All methods were carried out in accordance with the relevant guidelines and regulations, following the principles of the Declaration of Helsinki. Informed consent was obtained, with subjects advised that participation was voluntary with information kept confidential.&lt;/p&gt;
    &lt;head rend="h3"&gt;Consent for publication&lt;/head&gt;
    &lt;p&gt;Not applicable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Competing interests&lt;/head&gt;
    &lt;p&gt;The authors declare no competing interests.&lt;/p&gt;
    &lt;head rend="h3"&gt;Clinical trial number&lt;/head&gt;
    &lt;p&gt;Not applicable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Additional information&lt;/head&gt;
    &lt;head rend="h3"&gt;Publisher’s note&lt;/head&gt;
    &lt;p&gt;Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Electronic supplementary material&lt;/head&gt;
    &lt;p&gt;Below is the link to the electronic supplementary material.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rights and permissions&lt;/head&gt;
    &lt;p&gt;Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.&lt;/p&gt;
    &lt;head rend="h2"&gt;About this article&lt;/head&gt;
    &lt;head rend="h3"&gt;Cite this article&lt;/head&gt;
    &lt;p&gt;Ye, N., Peng, L., Deng, B. et al. Repetitive negative thinking is associated with cognitive function decline in older adults: a cross-sectional study. BMC Psychiatry 25, 562 (2025). https://doi.org/10.1186/s12888-025-06815-2&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Received:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Accepted:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Published:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DOI: https://doi.org/10.1186/s12888-025-06815-2&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45239085</guid><pubDate>Sun, 14 Sep 2025 11:37:33 +0000</pubDate></item><item><title>Read to forget</title><link>https://mo42.bearblog.dev/read-to-forget/</link><description>&lt;doc fingerprint="b4f9f8e6259a1b04"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Read to Forget&lt;/head&gt;
    &lt;p&gt;I read to forget. Even when studying or working on papers for a PhD, I approach texts with the same mindset: I'm not a storage device that needs to save all bits of information. I am more of a system of Bayesian beliefs, constantly evolving and updating in small, incremental steps.&lt;/p&gt;
    &lt;p&gt;I remember co-workers highlighting large chunks of text, sometimes 40%. That doesn't make sense to me. We can only read a text once, given the number of compelling works and the limited time available to us. So, I read to forget. When I start reading, I'm prepared to lose 98% of what's in front of me. From most texts, I only want two things: First, I want it to subtly alter my thinking, an incremental update that moves me towards a refined world model. Second, I want to pull out a few key pieces of information that I might use later in my writing. For instance, if I come across a well-written methodology section in a paper, I’ll save that. Reading should stimulate my thinking and produce new ideas. I've found myself reading a paper, pausing midway, and immediately experimenting with some variation of the algorithm described, leading to new ideas or even a new paper.&lt;/p&gt;
    &lt;p&gt;If a non-fiction text doesn't spark new thoughts or actions, it may not even be worthwhile reading. Anything beyond that clutters my note-taking system. You can't possibly keep track of everything, nor can you work with hoarded pieces of information.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45239601</guid><pubDate>Sun, 14 Sep 2025 13:23:12 +0000</pubDate></item><item><title>Why We Spiral</title><link>https://behavioralscientist.org/why-we-spiral/</link><description>&lt;doc fingerprint="5d0a0a15efb30cdb"&gt;
  &lt;main&gt;
    &lt;p&gt;Say you’re a senior member of your team at work. You’re 12 minutes late to the weekly staff Zoom. Once you’ve “joined audio,” the first thing you hear is your old friend’s voice. “There you are! So glad you could fit us in.” You laugh and explain the disastrous traffic, difficult drop-off at your kids’ school, or whatever it was that messed up your morning. The moment passes and the conversation moves on. You turn to the job at hand, focused and ready to go.&lt;/p&gt;
    &lt;p&gt;But what if you’re a junior staffer, still feeling your way. Same thing happens: You’re 12 minutes late to the weekly staff Zoom. Once you’ve “joined audio,” the first thing you hear is the boss’s voice. “There you are! So glad you could fit us in.” A few colleagues chuckle. You consider making excuses—about traffic, drop-off, whatever it was—but the moment passes, and the conversation moves on.&lt;/p&gt;
    &lt;p&gt;Your mind doesn’t, though. It’s still ruminating. Was that snark in my boss’s voice? Were they talking about me before I logged on? Do I fit in here? Am I any good at this job? You might not be fully aware of these questions. Your mind works quickly on multiple tracks at the same time. And those questions are nasty; they threaten your sense of belonging, your worth, and your value, at least at work. So you try to push them away, to suppress them. But they’re still there. And once they’ve been triggered, it might feel like the evidence keeps pouring in.&lt;/p&gt;
    &lt;p&gt;Someone makes an inside joke in the chat. You don’t get it. I don’t belong here. Someone rolls their eyes while you’re talking. They don’t respect me. The boss ignores you for the rest of the meeting. No one sees me. Again, these thoughts may not be fully conscious. But there’s no mistaking the fact that your motivation to get back to work has waned by the time you log off. What was it you were supposed to look into?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Was that snark in my boss’s voice? Were they talking about me before I logged on? Do I fit in here? Am I any good at this job?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Next thing you know, you’re idly messing around online when a text comes in from the person who rolled their eyes. “You okay? You seemed out of it at the meeting.” You ignore it. But your mind doesn’t. It’s busy composing possible replies. The full spectrum from passive-aggressive to career imperiling. Eventually you pick up your phone. What will you text back?&lt;/p&gt;
    &lt;p&gt;This is how self-defeating spirals start and how they gather speed. Let’s break down the moving parts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A circumstance places a big question on the table—about identity, belonging, or adequacy: You’re new at work. You want to succeed and belong, but you wonder . . . That question looms, latent and inactive, but present.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A “bad” thing happens: Your boss is a little snarky.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;That question gets triggered: You read the room for answers, drawing negative inferences from ambiguous evidence. You’re distracted from the task at hand. Your pessimistic hypothesis becomes more entrenched.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;You act on that pessimistic hypothesis, making matters worse.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Maybe you send that colleague a snarky text back. And what do you know: When you see them a few days later, they’re cold to you.&lt;/p&gt;
    &lt;p&gt;Now you aren’t talking. Maybe you flub that assignment your boss gave you, and they lose confidence in you. Fast-forward a year and you’re at a new job. Tensions are emerging with the new coworkers. Or are they? How will this story end? Do you have any control over it?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;When a core question is unsettled, it functions like a lens through which you see the world.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yes, you do. We all do. Negative spirals or feedback loops like these aren’t inevitable. In fact, there are small things we can do both for ourselves and for others to nip them in the bud—and prevent catastrophic outcomes months and years into the future. Better yet, there are ways we can launch positive spirals—dramatically increasing our chances of future happiness, success, and flourishing. The very same processes can either propel us upward or pull us down.&lt;/p&gt;
    &lt;p&gt;To understand how all this is possible, let’s get more precise about sequences like 1–4 above. There are three key concepts at play: “core questions” (number 1), meaning making or “construal” (numbers 2 and 3), and “calcification” (number 4). Think of these as “the three Cs” of spirals—whether positive or negative.&lt;/p&gt;
    &lt;p&gt;Core questions. There are the fundamental questions all of us face, at one time or another. For example: Who am I? Do I belong? Am I enough? I think of these questions as “defining” because they help define you and your life: your sense of self, what relationships you’ll have, and whether you’ll be able to do and be the things you aspire to. There might be long stretches when you don’t think about a given question much because it’s settled for you then. But at critical junctures specific questions flare up, unsettle and preoccupy you. Then they begin to shape what you see and how you act.&lt;/p&gt;
    &lt;p&gt;Construal. It’s natural to think that we have an unfiltered view of the world. That light hits your eyes and you just see what’s out there. But it’s more that we read the world, interpret it, drawing inferences based on what’s already in our heads. We pick up on themes that seem relevant or important to us, not noticing or screening out other details.&lt;/p&gt;
    &lt;p&gt;A friend once told me of an ingenious class demonstration that helped her begin to understand this process. A professor split the class in two and then spoke to the first half alone, telling them of his love for travel and a recent trip to Libya. Next, he spoke to the second half about shopping and how hard it was to find the right size shoe. Last, he brought the class together and said a single word. He asked the students to write it down. Students in the first group wrote, “Tripoli.” Those in the second wrote, “Triple E.”&lt;/p&gt;
    &lt;p&gt;Construal is like a kind of focus. As you look out at the social scene, what snaps to attention? If you’re anything like me, one of the most powerful guides is whatever could pose a risk to you, could threaten you. If you’re walking through a forest where a tiger is said to prowl, you might hear that tiger in every rustle of leaves, see it in every sway of reeds. But in the social world, we don’t all face the same threats. That’s why when you’re new at work and nervous about your place you might hear snark in your boss’s voice, but not if it’s your old friend.&lt;/p&gt;
    &lt;p&gt;When a core question is unsettled for a person, it functions like a lens through which you see the world. We seek answers that can help us resolve that question. Is it true? we ask. Are my doubts and fears well founded? Then, if a “bad” thing happens, it can seem like proof of your negative hypothesis. We aren’t neutral observers on the lookout for evidence one way or the other. We’re in the grip of confirmation bias, attuned to evidence that corroborates our preconceived theory, even if it’s the tiniest thing.&lt;/p&gt;
    &lt;p&gt;Calcification. Calcification happens when our negative thoughts and feelings get entrenched—often as a consequence of our own actions. You have a bad date and think, Am I unlovable? Will I be alone forever? Pretty soon your next date isn’t going well either. Rinse and repeat long enough, and you’re stuck in a romantic rut.&lt;/p&gt;
    &lt;p&gt;When you start to look, you can see spirals everywhere. You fail an important math test. You think you can’t succeed, and stop going to class. You feel sick from a treatment designed to help you overcome an illness. You think it means your illness is especially strong and resistant and so avoid treatment. You have a fight with your kids. You think you’re a “bad parent,” and then yell at them even more the next time. This is self-sabotage, and one step at a time it costs us our achievements, our health, our relationships, and our well-being.&lt;/p&gt;
    &lt;p&gt;Spiraling up&lt;/p&gt;
    &lt;p&gt;Yet if our struggles arise, in part, from the inferences we draw, we have an opportunity. In my work, my colleagues and I identify early moments where people could go one way or the other. By understanding the questions that come up at critical junctures, we can offer people better ways to think through challenges—ways that can help them spiral up, instead of down.&lt;/p&gt;
    &lt;p&gt;That’s what we call “wise” interventions: graceful ways to offer people good answers to the questions that define our lives. It sure can seem like magic that 21 minutes could improve marriage a year later; that a one-page letter could keep kids out of jail; that a string of postcards could cut suicide rates by half over two years; or that an hour-long reflection on belonging in the first year of college could improve life satisfaction and career success a decade later. But this—this is ordinary magic.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Negative spirals or feedback loops aren’t inevitable. There are things we can do both for ourselves and for others to nip them in the bud.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In my first year of college, I was biking back through campus one lovely fall day when I saw a large group of fellow students gathered enthusiastically around a truck from the California burger chain In-N-Out. Maybe they craved a taste of home. But in Michigan, where I was from, there are no In-N-Outs. I’d never heard of it. Feeling excluded from the burger party, I biked off in a huff to eat my lunch in the dining hall alone. I remember thinking, I’m not standing in line for a burger!&lt;/p&gt;
    &lt;p&gt;What was my problem?&lt;/p&gt;
    &lt;p&gt;As an 18-year-old, I certainly didn’t want to think of myself as feeling that I did not belong in college. And I definitely didn’t want to think that an In-N-Out truck could trigger that feeling. How ridiculous that would be. Who thinks they don’t belong because of a burger truck?&lt;/p&gt;
    &lt;p&gt;It was ridiculous. After my brother experienced a particularly mysterious romantic disaster, it’s something we christened a “tifbit”—tiny fact, big theory. Of course not knowing about In-N-Out didn’t mean I didn’t belong in college. But that’s the point. For looking back now, I know the truth is I was homesick. I felt so far from home and all the people I knew and loved. So I wondered, Will I make friends in California? Will I fit in? Seeing all those classmates crowded together, eager to get lunch from a place I’d never even heard of, just triggered those anxieties.&lt;/p&gt;
    &lt;p&gt;With wisdom and kindness and a little distance, we can laugh at ourselves in situations like these. But we should pay attention. For beneath every tifbit is a real question, and it’s almost always a reasonable one. Big responses to small experiences can help us see what lies beneath the surface. For a tifbit is never just a tiny fact. It’s a clue to the bigger questions that define our lives.&lt;/p&gt;
    &lt;p&gt;With a little prompt, I could have known that almost everyone feels homesick at first in college, that we’re all in some sense far from home, even the kids from California, that everyone was trying to find new communities. Maybe then I would have joined the line at the In-N-Out truck. I could have asked someone to tell me what In-N-Out was. Why do they love it? What is “animal style”?&lt;/p&gt;
    &lt;p&gt;I’m sure they would have been glad to share. I know I would have had a better lunch. And maybe I would have made a friend, too.&lt;/p&gt;
    &lt;p&gt;Excerpted from Ordinary Magic copyright © 2025 by Gregory M. Walton. Used by permission of Harmony Books, an imprint of Random House, a division of Penguin Random House LLC, New York. All rights reserved. No part of this excerpt may be reproduced or reprinted without permission in writing from the publisher.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45240146</guid><pubDate>Sun, 14 Sep 2025 14:46:58 +0000</pubDate></item><item><title>Nicu's test website made with SVG (2007)</title><link>https://svg.nicubunu.ro/</link><description>&lt;doc fingerprint="d70295d149350397"&gt;
  &lt;main&gt;Nicu's test website made with SVG
Navigation Menu
Experiment by:
nicubunu.ro
/
nicubunu.blogspot.com
This is a test page made to test Google's indexing abilities for SVG files.I am primarily interested in the following:- full text indexing - does Google index the text or will threat the file as an image?- links - will Google follow the links present in this SVG and index the linked files?There are more other things o test, but for the time being these two are blockers.The purpose of the test is to determine the effectiveness of using solely Inkscapefor authoring web sites.If you, as a reader of this page have more information on the subject and are willing to give me some more info, a contact address should be available in the About page linked in the right menu.This test website was made entirely with Inkscape.Notes: - I am fully aware about how the improper use of SVG could get a lot of bloat andinstatisfaction for the users;- SVG is a standard of the World Wide Web consortium;- This page use a few advanced SVG fatures (like Gaussian Blur) which are notfully supported by the current browsers (but will fall-back decently) and for the best experience you will need a browser powered by Geck 1.9 or later (like Firefox 3.0or later).Text to be found by search engines: lmtbk4mh.
Home
Home
Stuf
About
lmtbk4mh&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45240391</guid><pubDate>Sun, 14 Sep 2025 15:13:42 +0000</pubDate></item><item><title>Writing an operating system kernel from scratch</title><link>https://popovicu.com/posts/writing-an-operating-system-kernel-from-scratch/</link><description>&lt;doc fingerprint="b60e921211a1b64c"&gt;
  &lt;main&gt;
    &lt;p&gt;I recently implemented a minimal proof of concept time-sharing operating system kernel on RISC-V. In this post, I’ll share the details of how this prototype works. The target audience is anyone looking to understand low-level system software, drivers, system calls, etc., and I hope this will be especially useful to students of system software and computer architecture.&lt;/p&gt;
    &lt;p&gt;This is a redo of an exercise I did for my undergraduate course in operating systems, and functionally it should resemble a typical operating systems project. However, this experiment focuses on modern tooling, as well as the modern architecture of RISC-V. RISC-V is an amazing technology that is easy to understand more quickly than other CPU architectures, while remaining a popular choice for many new systems, not just an educational architecture.&lt;/p&gt;
    &lt;p&gt;Finally, to do things differently here, I implemented this exercise in Zig, rather than traditional C. In addition to being an interesting experiment, I believe Zig makes this experiment much more easily reproducible on your machine, as it’s very easy to set up and does not require any installation (which could otherwise be slightly messy when cross-compiling to RISC-V).&lt;/p&gt;
    &lt;head rend="h2"&gt;Table of contents&lt;/head&gt;
    &lt;head&gt;Open Table of contents&lt;/head&gt;
    &lt;head rend="h2"&gt;GitHub repo&lt;/head&gt;
    &lt;p&gt;The final code for this experiment is on GitHub here. We’ll be referencing the code from it as we go.&lt;/p&gt;
    &lt;p&gt;GitHub should be the source of truth and may be slightly out of sync with the code below.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recommended reading&lt;/head&gt;
    &lt;p&gt;The basic fundamentals of computer engineering and specifically computer architecture are assumed. Specifically, knowledge of registers, how the CPU addresses memory, and interrupts is all necessary.&lt;/p&gt;
    &lt;p&gt;Before diving deep into this experiment, it’s recommended to also review the following background texts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Bare metal programming on RISC-V&lt;/item&gt;
      &lt;item&gt;RISC-V boot process with SBI&lt;/item&gt;
      &lt;item&gt;RISC-V interrupts with a timer example&lt;/item&gt;
      &lt;item&gt;Optional - Making a micro Linux distro - mainly for the brief philosophy on the kernel / user space split&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Unikernel&lt;/head&gt;
    &lt;p&gt;We’ll be developing a type of unikernel. Simply put, this setup links the application code directly with the OS kernel it depends on. Essentially, everything is bundled into a single binary executable, and the user code is loaded into memory alongside the kernel.&lt;/p&gt;
    &lt;p&gt;This bypasses the need to separately load the user code at runtime, which is a complex field in itself (involving linkers, loaders, etc.).&lt;/p&gt;
    &lt;head rend="h2"&gt;SBI layer&lt;/head&gt;
    &lt;p&gt;RISC-V supports a layered permissions model. The system boots into machine mode (M), which is completely bare-metal, and then supports a couple of other less privileged modes. Please check the background texts for more details; below is a quick summary:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;M-mode can do pretty much anything; it is fully bare-metal.&lt;/item&gt;
      &lt;item&gt;In the middle is S-mode, supervisor, which typically hosts the operating system kernel.&lt;/item&gt;
      &lt;item&gt;At the bottom is U-mode, user, where application code runs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lower privilege levels can send requests to higher privilege levels.&lt;/p&gt;
    &lt;p&gt;We’ll assume that at the bottom of our software stack is an SBI layer, specifically OpenSBI. Please study this text for the necessary background, as we’ll use the SBI layer to manage console printing and control the timer hardware. While manual implementation is possible, I wanted to add more value to this text by demonstrating a more portable approach with OpenSBI.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goal for the kernel&lt;/head&gt;
    &lt;p&gt;We want to support a few key features for simplicity:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Statically define threads ahead of execution; i.e., dynamic thread creation is not supported. Additionally, for simplicity, threads are implemented as never-ending functions.&lt;/item&gt;
      &lt;item&gt;Threads operate in user mode and are able to send system calls to the kernel operating in S-mode.&lt;/item&gt;
      &lt;item&gt;Time is sliced and allocated among different threads. The system timer will be set to tick every couple of milliseconds, at which point a thread may be switched out.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Finally, development is targeted for a single-core machine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Virtualization and what exactly is a thread&lt;/head&gt;
    &lt;p&gt;Before implementing threads, we should decide what they really are. The concept of threads in a time-sharing environment enables multiple workloads to run on a single core (as noted above, we’re focusing on single-core machines), while the programming model for each thread remains largely the same as if it were the sole software on the machine. This is a loose definition, which we will refine.&lt;/p&gt;
    &lt;p&gt;To understand time-sharing, let’s briefly consider its contrast: cooperative scheduling/threading. In cooperative scheduling/threading, a thread voluntarily yields CPU time to another workload. Eventually, the expectation is that another thread will yield control back to the first.&lt;/p&gt;
    &lt;code&gt;function thread():
  operation_1();
  operation_2();
  YIELD();
  operation_3();
  YIELD();
  ...&lt;/code&gt;
    &lt;p&gt;To be clear, this isn’t an “outdated” technique, despite being older. In fact, it’s alive and well in many modern programming languages and their runtimes (often abstracted from programmers). One good example is Go, which uses Goroutines to run multiple workloads on top of one operating system thread. While programmers don’t necessarily add explicit yield operations, the compiler and runtime can inject them into the workload.&lt;/p&gt;
    &lt;p&gt;Now, it should be clearer what it means for the programming model to remain largely the same in a time-sharing context. The thread would naturally look like this:&lt;/p&gt;
    &lt;code&gt;function thread():
  operation_1();
  operation_2();
  operation_3();
  ...&lt;/code&gt;
    &lt;p&gt;There are simply no explicit yield operations; instead, the kernel utilizes timers and interrupts to seamlessly switch between threads on the same core. This is precisely what we’ll implement in this experiment.&lt;/p&gt;
    &lt;p&gt;When multiple workloads run on the same resource, and each retains the same programming model as if it were the only workload, we can say the resource is virtualized. In other words, if we’re running 5 threads on the same core, each thread “feels” like it has its own core, effectively running on 5 little cores instead of 1 big core. More formally, each thread retains its own view of the core’s architectural registers (in RISC-V, &lt;code&gt;x0-x31&lt;/code&gt; and some CSRs, more on this below) and… some memory! Let’s look deeper into that.&lt;/p&gt;
    &lt;head rend="h3"&gt;The stack and memory virtualization&lt;/head&gt;
    &lt;p&gt;To begin, a thread has its own stack for reasons we’ll analyze shortly. The rest of the memory is “shared” with other threads, but this requires further investigation.&lt;/p&gt;
    &lt;p&gt;It’s important to understand that hardware virtualization exists on a spectrum, rather than as a few rigid options. Here are some of the options for virtualization:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Threads: virtualizes architectural registers and stacks, but not much else; i.e., different threads can share data elsewhere in memory.&lt;/item&gt;
      &lt;item&gt;Process: more heavyweight than threads, memory is virtualized such that each process “feels” like it has a dedicated CPU core and its own memory untouchable by other processes; additionally, a process houses multiple threads.&lt;/item&gt;
      &lt;item&gt;Container: virtualizes even more - each container has its own filesystem and potentially its own set of network interfaces; containers share the same kernel and underlying hardware.&lt;/item&gt;
      &lt;item&gt;VM: virtualizes everything.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are many more shades in between, and each of these options likely has different subtypes. The point here is that all these approaches enable running different workloads with varying isolations, or more intuitively, different views of the machine and their environment.&lt;/p&gt;
    &lt;p&gt;Interestingly, if you examine the Linux kernel source code, you won’t find a construct explicitly called a container. What we popularly call containers isn’t a mechanism baked into the kernel, but rather a set of kernel mechanisms used together to form a specific view of the environment for our workload. For example, the &lt;code&gt;chroot&lt;/code&gt; mechanism restricts filesystem visibility, while &lt;code&gt;cgroups&lt;/code&gt; impose limits on workloads; together, these form what we call a container.&lt;/p&gt;
    &lt;p&gt;Furthermore, I believe (though don’t quote me on this) that the boundaries between threads and processes in Linux are somewhat blurred. To the best of my knowledge, both are implemented on top of tasks in the kernel, but when creating a task, the API allows different restrictions to be specified.&lt;/p&gt;
    &lt;p&gt;Ultimately, this is all to say that we’re always defining a workload with varying restrictions on what it can see and access. When and why to apply different restrictions is a topic for another day. Many questions arise when writing an application, ranging from the difficulty of an approach to its security.&lt;/p&gt;
    &lt;head rend="h3"&gt;Virtualizing a thread&lt;/head&gt;
    &lt;p&gt;In this experiment, we’ll implement minimal virtualization with very basic, time-sharing threads. Therefore, the goals are the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The programming model for a thread should remain mostly untouched. As long as a thread doesn’t interact with memory contents used by other threads, its programming model should remain consistent, powered by time-sharing.&lt;/item&gt;
      &lt;item&gt;A thread should have its own protected view of architectural registers, including some RISC-V CSRs.&lt;/item&gt;
      &lt;item&gt;A thread should be assigned its own stack.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It should be obvious why a thread needs its own view of the registers. If other threads could freely touch a thread’s registers, the thread wouldn’t be able to do any meaningful work. All (I believe) RISC-V instructions work with at least one register, so protecting a thread’s register view is essential.&lt;/p&gt;
    &lt;p&gt;Furthermore, assigning a private stack to a thread is necessary, though slightly less obvious. The answer is that different stacks are needed to manage different execution contexts. Namely, when a function is invoked, by convention, the stack is used to allocate function-private variables. Additionally, registers like &lt;code&gt;ra&lt;/code&gt; can be pushed to the stack to retain the correct return address from a function (in case another function is invoked within it). In short, there are various reasons, per RISC-V convention, why the stack is needed to maintain the execution context. The details of RISC-V calling conventions will not be described here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Interrupt context&lt;/head&gt;
    &lt;p&gt;It’s crucial to understand how interrupt code runs and what it should consist of, as this mechanism will be heavily exploited to achieve seamless time-sharing between threads. For a detailed, practical example, please check out this past text.&lt;/p&gt;
    &lt;p&gt;I’ll briefly include the assembly for the timer interrupt routine from that text:&lt;/p&gt;
    &lt;code&gt;s_mode_interrupt_handler:
        addi    sp,sp,-144
        sd      ra,136(sp)
        sd      t0,128(sp)
        sd      t1,120(sp)
        sd      t2,112(sp)
        sd      s0,104(sp)
        sd      a0,96(sp)
        sd      a1,88(sp)
        sd      a2,80(sp)
        sd      a3,72(sp)
        sd      a4,64(sp)
        sd      a5,56(sp)
        sd      a6,48(sp)
        sd      a7,40(sp)
        sd      t3,32(sp)
        sd      t4,24(sp)
        sd      t5,16(sp)
        sd      t6,8(sp)
        addi    s0,sp,144
        call    clear_timer_pending_bit
        call    set_timer_in_near_future
        li      a1,33
        lla     a0,.LC0
        call    debug_print
        nop
        ld      ra,136(sp)
        ld      t0,128(sp)
        ld      t1,120(sp)
        ld      t2,112(sp)
        ld      s0,104(sp)
        ld      a0,96(sp)
        ld      a1,88(sp)
        ld      a2,80(sp)
        ld      a3,72(sp)
        ld      a4,64(sp)
        ld      a5,56(sp)
        ld      a6,48(sp)
        ld      a7,40(sp)
        ld      t3,32(sp)
        ld      t4,24(sp)
        ld      t5,16(sp)
        ld      t6,8(sp)
        addi    sp,sp,144
        sret&lt;/code&gt;
    &lt;p&gt;This assembly was obtained by writing a C function tagged as an S-level interrupt in RISC-V. With this tag, the GCC compiler knew how to generate the prologue and epilogue of the interrupt routine. The prologue preserves architectural registers on the stack, and the epilogue recovers them (in addition to specifically returning from S-mode). All of this was generated by correctly tagging the C function’s invoking convention.&lt;/p&gt;
    &lt;p&gt;This somewhat resembles function calling, and that’s essentially what it is. Interrupts can be thought of (in a very simplified sense) as functions invoked by some system effect. Consequently, utilized registers must be carefully preserved on the stack and then restored at the routine’s exit; otherwise, asynchronous interrupts like timer interrupts would randomly corrupt architectural register values, completely blocking any practical software from running!&lt;/p&gt;
    &lt;head rend="h2"&gt;Implementation (high-level)&lt;/head&gt;
    &lt;p&gt;We’ll explore the implementation by first describing the high-level idea and then digging into the code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Leveraging the interrupt stack convention&lt;/head&gt;
    &lt;p&gt;Adding an interrupt is, in a way, already introducing a form of threading to your application code. In a system with a timer interrupt, the main application code runs, which can occasionally be interleaved with instances of timer interrupt invocations. The core jumps to this interrupt routine when the timer signals, and it carefully restores the architectural state before control flow returns to the “main thread”. There are two control flows running concurrently here:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Main application code.&lt;/item&gt;
      &lt;item&gt;Repetitions of the interrupt routine.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This interleaving of the timer interrupt can be leveraged to implement additional control flows, and the main idea is outlined below.&lt;/p&gt;
    &lt;p&gt;The core of the interrupt routine is sandwiched between the prologue and the epilogue. That’s where the interrupt is serviced before control returns to the main application thread by restoring registers from the stack.&lt;/p&gt;
    &lt;p&gt;However, why must we restore the registers from the same stack location? If our interrupt logic swaps the stack pointer to some other piece of memory, we’ll end up with a different set of architectural register values recovered, thus entering a whole different flow. In other words, we achieve a context switch, and this is precisely how it’s implemented in this experiment. We’ll see the code for it shortly.&lt;/p&gt;
    &lt;head rend="h3"&gt;Kernel/user space separation&lt;/head&gt;
    &lt;p&gt;We can now delineate the kernel space and user space. With RISC-V, this naturally translates to kernel code running in supervisor (S) mode and user space code running in U-mode.&lt;/p&gt;
    &lt;p&gt;The machine boots into machine (M) mode, and since we want to leverage the SBI layer, we’ll allow OpenSBI to run there. Then, the kernel will perform some initial setup in S-mode before starting the U-mode execution of user space threads. Periodic timer interrupts will enable context switches, and the interrupt code will execute in S-mode. Finally, user threads will be able to make system calls to the kernel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Implementation (code)&lt;/head&gt;
    &lt;p&gt;Please refer to the GitHub repository for the full code; we will only cover core excerpts below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Assembly startup&lt;/head&gt;
    &lt;p&gt;As usual, a short assembly snippet is needed to start our S-mode code and enter the “main program” in Zig. This is in &lt;code&gt;startup.S&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;...
done_bss:

    # Jump to Zig main
    call main
...&lt;/code&gt;
    &lt;p&gt;The rest of the assembly startup primarily involves cleaning up the BSS section and setting up the stack pointer for the initial kernel code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Main kernel file and I/O drivers&lt;/head&gt;
    &lt;p&gt;We’ll now examine &lt;code&gt;kernel.zig&lt;/code&gt;, which contains the &lt;code&gt;main&lt;/code&gt; function.&lt;/p&gt;
    &lt;p&gt;First, we probe the OpenSBI layer for console capabilities. We’ll only consider running on a relatively recent version of OpenSBI (from the last few years) that includes console capability. Otherwise, the kernel will halt and report an error.&lt;/p&gt;
    &lt;code&gt;export fn main() void {
    const initial_print_status = sbi.debug_print(BOOT_MSG);

    if (initial_print_status.sbi_error != 0) {
        // SBI debug console not available, fall back to direct UART
        const error_msg = "ERROR: OpenSBI debug console not available! You need the latest OpenSBI.\n";
        const fallback_msg = "Falling back to direct UART at 0x10000000...\n";

        uart.uart_write_string(error_msg);
        uart.uart_write_string(fallback_msg);
        uart.uart_write_string("Stopping... We rely on OpenSBI, cannot continue.\n");

        while (true) {
            asm volatile ("wfi");
        }

        unreachable;
    }&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;main&lt;/code&gt; is marked as &lt;code&gt;export&lt;/code&gt; to conform to the C ABI.&lt;/p&gt;
    &lt;p&gt;Here, we have a lightweight implementation of a couple of I/O drivers. As you can see, writing can occur in one of two ways: either we go through the SBI layer (&lt;code&gt;sbi.zig&lt;/code&gt;) or, if that fails, we use direct MMIO (&lt;code&gt;uart_mmio.zig&lt;/code&gt;). The SBI method should theoretically be more portable, as it delegates output management details to the M-level layer (essentially what we do with MMIO), freeing us from concerns about exact memory space addresses.&lt;/p&gt;
    &lt;p&gt;Let’s quickly look at &lt;code&gt;sbi.zig&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;// Struct containing the return status of OpenSBI
pub const SbiRet = struct {
    sbi_error: isize,
    value: isize,
};

pub fn debug_print(message: []const u8) SbiRet {
    var err: isize = undefined;
    var val: isize = undefined;

    const msg_ptr = @intFromPtr(message.ptr);
    const msg_len = message.len;

    asm volatile (
        \\mv a0, %[len]
        \\mv a1, %[msg]
        \\li a2, 0
        \\li a6, 0x00
        \\li a7, 0x4442434E
        \\ecall
        \\mv %[err], a0
        \\mv %[val], a1
        : [err] "=r" (err),
          [val] "=r" (val),
        : [msg] "r" (msg_ptr),
          [len] "r" (msg_len),
        : .{ .x10 = true, .x11 = true, .x12 = true, .x16 = true, .x17 = true, .memory = true });

    return SbiRet{
        .sbi_error = err,
        .value = val,
    };
}&lt;/code&gt;
    &lt;p&gt;This is very straightforward; we’re simply performing the system call exactly as described in the OpenSBI documentation. Note that when I first wrote this code, I wasn’t fully familiar with Zig’s error handling capabilities, hence the somewhat non-idiomatic error handling.&lt;/p&gt;
    &lt;p&gt;However, this can be considered a first driver in this kernel, as it directly manages output to the device.&lt;/p&gt;
    &lt;p&gt;Next is &lt;code&gt;uart_mmio.zig&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;// UART MMIO address (standard for QEMU virt machine)
pub const UART_BASE: usize = 0x10000000;
pub const UART_TX: *volatile u8 = @ptrFromInt(UART_BASE);

// Direct UART write function (fallback when SBI is not available)
pub fn uart_write_string(message: []const u8) void {
    for (message) |byte| {
        UART_TX.* = byte;
    }
}&lt;/code&gt;
    &lt;p&gt;This is straightforward and self-explanatory.&lt;/p&gt;
    &lt;p&gt;Returning to &lt;code&gt;kernel.zig&lt;/code&gt; and the &lt;code&gt;main&lt;/code&gt; function, we create 3 user threads, each printing a slightly different message (the thread ID is the varying bit). At this point, the kernel setup is almost complete.&lt;/p&gt;
    &lt;p&gt;The final steps involve setting up and running the timer interrupt. Once that is done, kernel code will only run when the timer interrupts the system or when user space code requests a system call.&lt;/p&gt;
    &lt;code&gt;interrupts.setup_s_mode_interrupt(&amp;amp;s_mode_interrupt_handler);
_ = timer.set_timer_in_near_future();
timer.enable_s_mode_timer_interrupt();&lt;/code&gt;
    &lt;p&gt;We could request a context switch immediately, but for simplicity, we’ll wait until the timer activates and begins the actual work in the system.&lt;/p&gt;
    &lt;head rend="h3"&gt;S-mode handler and the context switch&lt;/head&gt;
    &lt;p&gt;While the Zig compiler could generate the adequate prologue and epilogue for our S-mode handler, we will do it manually. The reason is that we also want to capture some CSRs in the context that otherwise wouldn’t have been captured by the generated routine.&lt;/p&gt;
    &lt;p&gt;That’s why we use the &lt;code&gt;naked&lt;/code&gt; calling convention in Zig. This forces us to write the entire function in assembly, though a quick escape hatch to this limitation is to call a Zig function whenever Zig logic is needed.&lt;/p&gt;
    &lt;p&gt;I won’t copy paste the whole prologue and epilogue here because they are very similar to what was done in the previous C experiment with RISC-V interrupts. Instead, I’ll just focus on the bit that is different:&lt;/p&gt;
    &lt;code&gt;...
        // Save S-level CSRs (using x5 as a temporary register)
        \\csrr x5, sstatus
        \\sd x5, 240(sp)
        \\csrr x5, sepc
        \\sd x5, 248(sp)
        \\csrr x5, scause
        \\sd x5, 256(sp)
        \\csrr x5, stval
        \\sd x5, 264(sp)

        // Call handle_kernel
        \\mv a0, sp
        \\call handle_kernel
        \\mv sp, a0

        // Epilogue: Restore context
        // Restore S-level CSRs (using x5 as a temporary register)
        \\ld x5, 264(sp)
        \\csrw stval, x5
        \\ld x5, 256(sp)
        \\csrw scause, x5
        \\ld x5, 248(sp)
        \\csrw sepc, x5
        \\ld x5, 240(sp)
        \\csrw sstatus, x5
...&lt;/code&gt;
    &lt;p&gt;As you can see, a couple more registers were added to the prologue and epilogue in addition to the core architectural registers.&lt;/p&gt;
    &lt;p&gt;Next, within this prologue/epilogue sandwich, we invoke the &lt;code&gt;handle_kernel&lt;/code&gt; Zig function. This routes to the correct logic based on whether the interrupt source is a synchronous system call from user space or an asynchronous timer interrupt. The reason is that we land in the same S-level interrupt routine regardless of the interrupt source, and then we inspect the &lt;code&gt;scause&lt;/code&gt; CSR for details.&lt;/p&gt;
    &lt;p&gt;To successfully work with the &lt;code&gt;handle_kernel&lt;/code&gt; function, we need to be aware of the assembly-level calling conventions. This function takes a single integer parameter and returns a single integer parameter. Since the function signature is small, it works as simply as this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The sole function parameter is passed through the &lt;code&gt;a0&lt;/code&gt;architectural register.&lt;/item&gt;
      &lt;item&gt;The same register also holds the function’s result upon return.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is pretty easy. Let’s quickly look at the signature of this function:&lt;/p&gt;
    &lt;code&gt;export fn handle_kernel(current_stack: usize) usize {
...&lt;/code&gt;
    &lt;p&gt;It is slightly awkward but gets the job done. The input to this Zig logic is the stack top before invoking the Zig logic (which inevitably leads to some data added to the stack). The function’s output is where the stack top should be after the Zig logic is done. If it differs from the input, then we’re performing a context switch. If it’s the same, the same workload thread will continue running after the interrupt.&lt;/p&gt;
    &lt;p&gt;The rest of the logic is very simple. It inspects the interrupt source (system call from user space or timer interrupt) and performs accordingly.&lt;/p&gt;
    &lt;p&gt;In the case of a timer interrupt, a context switch is performed. The &lt;code&gt;schedule&lt;/code&gt; function from &lt;code&gt;scheduling.zig&lt;/code&gt; is invoked, and it potentially returns the other stack we should switch to:&lt;/p&gt;
    &lt;code&gt;const build_options = @import("build_options");
const sbi = @import("sbi");
const std = @import("std");
const thread = @import("thread");

pub fn schedule(current_stack: usize) usize {
    const maybe_current_thread = thread.getCurrentThread();

    if (maybe_current_thread) |current_thread| {
        current_thread.sp_save = current_stack;

        if (comptime build_options.enable_debug_logs) {
            _ = sbi.debug_print("[I] Enqueueing the current thread\n");
        }
        thread.enqueueReady(current_thread);
    } else {
        if (comptime build_options.enable_debug_logs) {
            _ = sbi.debug_print("[W] NO CURRENT THREAD AVAILABLE!\n");
        }
    }

    const maybe_new_thread = thread.dequeueReady();

    if (maybe_new_thread) |new_thread| {
        // TODO: software interrupt to yield to the user thread

        if (comptime build_options.enable_debug_logs) {
            _ = sbi.debug_print("Yielding to the new thread\n");
        }

        thread.setCurrentThread(new_thread);

        if (comptime build_options.enable_debug_logs) {
            var buffer: [256]u8 = undefined;
            const content = std.fmt.bufPrint(&amp;amp;buffer, "New thread ID: {d}, stack top: {x}\n", .{ new_thread.id, new_thread.sp_save }) catch {
                return 0; // Return bogus stack, should be more robust in reality
            };
            _ = sbi.debug_print(content);
        }

        return new_thread.sp_save;
    }

    _ = sbi.debug_print("NO NEW THREAD AVAILABLE!\n");

    while (true) {
        asm volatile ("wfi");
    }
    unreachable;
}&lt;/code&gt;
    &lt;p&gt;The code from the &lt;code&gt;thread&lt;/code&gt; module is very simple, serving as boilerplate for a basic queue that manages structs representing threads. I won’t copy it here, as it’s mostly AI-generated. It is important to note, however, that the stacks are statically allocated in memory, and the maximum number of running threads is hardcoded.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;thread&lt;/code&gt; module also includes logic for setting up a new thread. This is where data is pushed onto the stack before the thread even runs. If you wonder why, it’s because when returning from the S-level trap handler, we need something on the stack to indicate where to go. The initial data does precisely that. We can seed the initial register values here as desired. In fact, in this experiment, we demonstrate passing a single integer parameter to the thread function by seeding the &lt;code&gt;a0&lt;/code&gt; register value (per calling convention) on the stack, which the thread function can then use immediately.&lt;/p&gt;
    &lt;head rend="h3"&gt;The user space threads&lt;/head&gt;
    &lt;p&gt;As mentioned in the introduction, we’ll bundle the user space and kernel space code into a single binary blob to avoid dynamic loading, linking, and other complexities. Hence, our user space code consists of regular functions:&lt;/p&gt;
    &lt;code&gt;/// Example: Create a simple idle thread
pub fn createPrintingThread(thread_number: usize) !*Thread {
    const thread = allocThread() orelse return error.NoFreeThreads;

    // Idle thread just spins
    const print_fn = struct {
        fn print(thread_arg: usize) noreturn {
            while (true) {
                var buffer: [256]u8 = undefined;
                const content = std.fmt.bufPrint(&amp;amp;buffer, "Printing from thread ID: {d}\n", .{thread_arg}) catch {
                    continue;
                };

                syscall.debug_print(content);

                // Simulate a delay
                var i: u32 = 0;
                while (i &amp;lt; 300000000) : (i += 1) {
                    asm volatile ("" ::: .{ .memory = true }); // Memory barrier to prevent optimization
                }
            }
            unreachable;
        }
    }.print;

    initThread(thread, @intFromPtr(&amp;amp;print_fn), thread_number);
    return thread;
}&lt;/code&gt;
    &lt;p&gt;Additionally, as mentioned above, we pre-seeded the stack such that when &lt;code&gt;a0&lt;/code&gt; is recovered from the stack upon the first interrupt return for a given thread, the function argument will be picked up. That’s how the &lt;code&gt;print&lt;/code&gt; function accesses the &lt;code&gt;thread_arg&lt;/code&gt; value and uses it in its logic.&lt;/p&gt;
    &lt;p&gt;To demonstrate the user/kernel boundary, we have &lt;code&gt;syscall.debug_print(content);&lt;/code&gt;. This conceptually behaves more or less as &lt;code&gt;printf&lt;/code&gt; from &lt;code&gt;stdio.h&lt;/code&gt; in C. It performs prepares the arguments to the kernel and runs a system call with these arguments which should lead to some content getting printed on the output device. Here’s what the printing library looks like (from &lt;code&gt;syscall.zig&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;// User-level debug_print function
pub fn debug_print(message: []const u8) void {
    const msg_ptr = @intFromPtr(message.ptr);
    const msg_len = message.len;

    // Let's say syscall number 64
    // a7 = syscall number
    // a0 = message pointer
    // a1 = message length
    asm volatile (
        \\mv a0, %[msg]
        \\mv a1, %[len]
        \\li a7, 64
        \\ecall
        :
        : [msg] "r" (msg_ptr),
          [len] "r" (msg_len),
        : .{ .x10 = true, .x11 = true, .x17 = true, .memory = true });

    // Ignore return value for simplicity
}&lt;/code&gt;
    &lt;p&gt;System call 64 is served from the S-mode handler in &lt;code&gt;kernel.zig&lt;/code&gt;. This is self-explanatory, and we won’t go into further details here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Running the kernel&lt;/head&gt;
    &lt;p&gt;We will deploy the kernel on bare-metal, specifically on a virtual machine. In theory, this should also work on a real machine, provided an SBI layer is present when the kernel starts, and the linker script, I/O “drivers,” and other machine-specific constants are adapted.&lt;/p&gt;
    &lt;p&gt;To build, we simply run&lt;/p&gt;
    &lt;code&gt;zig build&lt;/code&gt;
    &lt;p&gt;To now run the kernel, we run:&lt;/p&gt;
    &lt;code&gt;qemu-system-riscv64 -machine virt -nographic -bios /tmp/opensbi/build/platform/generic/firmware/fw_dynamic.bin -kernel zig-out/bin/kernel&lt;/code&gt;
    &lt;p&gt;Refer to the previous text on OpenSBI for details on building OpenSBI. It is strongly recommended to use a freshly built OpenSBI, as QEMU may use an outdated version if no &lt;code&gt;-bios&lt;/code&gt; flag is passed.&lt;/p&gt;
    &lt;p&gt;The output should begin with a big OpenSBI splash along with some OpenSBI data:&lt;/p&gt;
    &lt;code&gt;OpenSBI v1.7
   ____                    _____ ____ _____
  / __ \                  / ____|  _ \_   _|
 | |  | |_ __   ___ _ __ | (___ | |_) || |
 | |  | | '_ \ / _ \ '_ \ \___ \|  _ &amp;lt; | |
 | |__| | |_) |  __/ | | |____) | |_) || |_
  \____/| .__/ \___|_| |_|_____/|____/_____|
        | |
        |_|

Platform Name               : riscv-virtio,qemu
Platform Features           : medeleg
Platform HART Count         : 1
Platform IPI Device         : aclint-mswi
Platform Timer Device       : aclint-mtimer @ 10000000Hz
Platform Console Device     : uart8250
Platform HSM Device         : ---
Platform PMU Device         : ---
Platform Reboot Device      : syscon-reboot
Platform Shutdown Device    : syscon-poweroff
Platform Suspend Device     : ---
Platform CPPC Device        : ---
Firmware Base               : 0x80000000
Firmware Size               : 317 KB
Firmware RW Offset          : 0x40000
Firmware RW Size            : 61 KB
Firmware Heap Offset        : 0x46000
Firmware Heap Size          : 37 KB (total), 2 KB (reserved), 11 KB (used), 23 KB (free)
Firmware Scratch Size       : 4096 B (total), 400 B (used), 3696 B (free)
Runtime SBI Version         : 3.0
Standard SBI Extensions     : time,rfnc,ipi,base,hsm,srst,pmu,dbcn,fwft,legacy,dbtr,sse
Experimental SBI Extensions : none

Domain0 Name                : root
....&lt;/code&gt;
    &lt;p&gt;Following the OpenSBI splash, we’ll see the kernel output:&lt;/p&gt;
    &lt;code&gt;Booting the kernel...
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 2
Printing from thread ID: 2
Printing from thread ID: 2
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 2
Printing from thread ID: 2
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 2
Printing from thread ID: 2
Printing from thread ID: 2&lt;/code&gt;
    &lt;p&gt;The prints will continue running until QEMU is terminated.&lt;/p&gt;
    &lt;p&gt;If you want to build the kernel in an extremely verbose mode for debugging and experimentation, use the following command:&lt;/p&gt;
    &lt;code&gt;zig build -Ddebug-logs=true&lt;/code&gt;
    &lt;p&gt;After running the kernel with the same QEMU command, the output will appear as follows:&lt;/p&gt;
    &lt;code&gt;Booting the kernel...
DEBUG mode on
Interrupt source: Timer, Current stack: 87cffe70
[W] NO CURRENT THREAD AVAILABLE!
Yielding to the new thread
New thread ID: 0, stack top: 80203030
Interrupt source: Ecall from User mode, Current stack: 80202ec0
Printing from thread ID: 0
Interrupt source: Ecall from User mode, Current stack: 80202ec0
Printing from thread ID: 0
Interrupt source: Ecall from User mode, Current stack: 80202ec0
Printing from thread ID: 0
Interrupt source: Timer, Current stack: 80202ec0
[I] Enqueueing the current thread
Yielding to the new thread
New thread ID: 1, stack top: 80205030
Interrupt source: Ecall from User mode, Current stack: 80204ec0
Printing from thread ID: 1
Interrupt source: Ecall from User mode, Current stack: 80204ec0
Printing from thread ID: 1
Interrupt source: Ecall from User mode, Current stack: 80204ec0
Printing from thread ID: 1
Interrupt source: Timer, Current stack: 80204ec0
[I] Enqueueing the current thread
Yielding to the new thread
New thread ID: 2, stack top: 80207030
Interrupt source: Ecall from User mode, Current stack: 80206ec0
Printing from thread ID: 2
Interrupt source: Ecall from User mode, Current stack: 80206ec0
Printing from thread ID: 2
Interrupt source: Ecall from User mode, Current stack: 80206ec0
Printing from thread ID: 2
Interrupt source: Timer, Current stack: 80206ec0
...&lt;/code&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Many educational OS kernels exist, but this experiment combines RISC-V, OpenSBI, and Zig, offering a fresh perspective compared to traditional C implementations.&lt;/p&gt;
    &lt;p&gt;The resulting code runs on a QEMU virtual machine, which can be easily set up, even by building QEMU from source.&lt;/p&gt;
    &lt;p&gt;To keep the explanation concise, error reporting was kept minimal. Should you modify the code and require debugging, sufficient clues are provided, despite some areas where the code is simplified (e.g., anonymous results after SBI print invocations like &lt;code&gt;_ = ...&lt;/code&gt;). Much of the code in this example was AI-generated by Claude to save time, and it should function as intended. While some parts of the code are simplified, such as stack space over-allocation, these do not detract from the experiment’s educational value.&lt;/p&gt;
    &lt;p&gt;Overall, this experiment serves as a starting point for studying operating systems, assuming a foundational understanding of computer engineering and computer architecture. It likely has plenty of flaws for a practical application, but for now, we’re just hacking here!&lt;/p&gt;
    &lt;p&gt;I hope this was a useful exploration.&lt;/p&gt;
    &lt;p&gt;Please consider following on Twitter/X and LinkedIn to stay updated.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45240682</guid><pubDate>Sun, 14 Sep 2025 15:44:44 +0000</pubDate></item><item><title>OCSP Service Has Reached End of Life</title><link>https://letsencrypt.org/2025/08/06/ocsp-service-has-reached-end-of-life</link><description>&lt;doc fingerprint="e337cfd427579385"&gt;
  &lt;main&gt;
    &lt;p&gt;Today we turned off our Online Certificate Status Protocol (OCSP) service, as announced in December of last year. We stopped including OCSP URLs in our certificates more than 90 days ago, so all Let’s Encrypt certificates that contained OCSP URLs have now expired. Going forward, we will publish revocation information exclusively via Certificate Revocation Lists (CRLs).&lt;/p&gt;
    &lt;p&gt;We ended support for OCSP primarily because it represents a considerable risk to privacy on the Internet. When someone visits a website using a browser or other software that checks for certificate revocation via OCSP, the Certificate Authority (CA) operating the OCSP responder immediately becomes aware of which website is being visited from that visitor’s particular IP address. Even when a CA intentionally does not retain this information, as is the case with Let’s Encrypt, it could accidentally be retained or CAs could be legally compelled to collect it. CRLs do not have this issue.&lt;/p&gt;
    &lt;p&gt;We are also taking this step because keeping our CA infrastructure as simple as possible is critical for the continuity of compliance, reliability, and efficiency at Let’s Encrypt. For every year that we have existed, operating OCSP services has taken up considerable resources that can soon be better spent on other aspects of our operations. Now that we support CRLs, our OCSP service has become unnecessary.&lt;/p&gt;
    &lt;p&gt;At the height of our OCSP service’s traffic earlier this year, we handled approximately 340 billion OCSP requests per month. That’s more than 140,000 requests per second handled by our CDN, with 15,000 requests per second handled by our origin. We’d like to thank Akamai for generously donating CDN services for OCSP to Let’s Encrypt for the past ten years.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45242591</guid><pubDate>Sun, 14 Sep 2025 19:34:48 +0000</pubDate></item><item><title>AMD Turin PSP binaries analysis from open-source firmware perspective</title><link>https://blog.3mdeb.com/2025/2025-09-11-gigabyte-mz33-ar1-blob-analysis/</link><description>&lt;doc fingerprint="bc4ac671c73409c5"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In the previous post, we showed coreboot running on Gigabyte MZ33-AR1 with Turin CPU, the current, newest family of AMD server processors. However, we faced various obstacles and problems. Despite AMD publishing a set of blobs required for the Turin system initialization, they turned out to be not enough to release the CPU from reset by PSP. We were forced to do a workaround by injecting coreboot into the vendor firmware image and flashing it back. The whole process is far from ideal; thus, it forced us to perform an analysis, where we demystify and explain the problems and solutions we came up with.&lt;/p&gt;
    &lt;head rend="h2"&gt;AMD PSP firmware structure&lt;/head&gt;
    &lt;p&gt;Nowadays, the x86 CPUs are not the first entities that begin code execution after pressing the power button. The design of the processors and silicon overall drifted towards adding many co-processors, which perform a specialized subset of actions and have a very specific role in the system. For example: Intel Management Engine (ME) on Intel platforms and AMD Platform Security Processor (PSP), also known as AMD Security Processor (ASP). These co-processors run their own firmware, which is usually stored in the same flash memory as the BIOS for an x86 CPU. Often these firmwares contain other firmwares for yet another co-processors or IP blocks. This is true for both Intel and AMD. We will not dive into Intel specifics, but if you are curious, just open an Intel firmware image in UEFITool and expand the Intel ME region. You will see how many various applications or firmwares reside there.&lt;/p&gt;
    &lt;p&gt;The situation is no different on an AMD system, although the separation of x86 BIOS and PSP firmware/blobs is not as clean as on Intel systems. AMD PSP does not have any separate flash region for its own use. Instead, the PSP blobs are packed into specific directory structures, which you can read a bit about here.&lt;/p&gt;
    &lt;p&gt;To understand how it is supposed to work on the Turin system, we have to go through each structure of the PSP firmware and analyze it, starting with Embedded Firmware Structure (EFS), through PSP directories up to the BIOS directories.&lt;/p&gt;
    &lt;head rend="h2"&gt;Embedded Firmware Structure&lt;/head&gt;
    &lt;p&gt;Embedded Firmware Structure is like a header that indicates the location of PSP and BIOS directories. It is used by PSP during power-on to locate the blobs and configure certain properties of the system, e.g., SPI interface speeds, eSPI bus configuration, etc. The tool responsible for creating EFS, PSP and BIOS directories in coreboot are amdfwtool. The coreboot build system uses this utility during the build process to stitch all blobs together into a bootable image.&lt;/p&gt;
    &lt;p&gt;There has been some activity around this tool recently, which has enhanced its debugging and analysis capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;util/amdfwtool/amdfwread: add initial parsing for EFW structure&lt;/item&gt;
      &lt;item&gt;util/amdfwtool/amdfwread: fix offset decision for PSP/BIOS directory lookup&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Seeing this opportunity, I have reviewed and tested the patches, even added more information to be dumped, and fixed parsing of the images for Turin processors, to serve the purpose of my analysis:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;util/amdfwtool: Extend parsing of embedded firmware structures and dirs&lt;/item&gt;
      &lt;item&gt;util/amdfwtool: Handle address mode properly for Turin&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With those improvements in place, I was able to dump information about coreboot images as well as vendor images. When something does not work, one of the best and easiest ways is to compare a faulty case with a known good reference. And so by dumping the information on both images, we could spot some major differences, which potentially could cause the image to be unbootable.&lt;/p&gt;
    &lt;p&gt;Since the outputs from amdfwtool are quite long, I have added them as a paste:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;./util/amdfwtool/amdfwread -d --ro-list build/coreboot.rom&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;./util/amdfwtool/amdfwread -d --ro-list MZ33-AR1_R11_F08/SPI_UPD/image.bin&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The second dump comes from the latest BIOS update package &lt;code&gt;R11_F08&lt;/code&gt; for the
Gigabyte MZ33-AR1 which can be downloaded from the vendor’s site.&lt;/p&gt;
    &lt;p&gt;Right now, we are interested in everything that comes before &lt;code&gt;Table: FW Offset Size&lt;/code&gt; line, since it represents the EFS. We can see that many fields are
different. Also, we have to remember that vendor image is a dual BIOS for
Genoa and Turin platforms. &lt;code&gt;amdfwread&lt;/code&gt; prints only the contents of the first
BIOS image (first 16MB). So the &lt;code&gt;image.bin&lt;/code&gt; has to be split into two 16MB
files, and the dump should be taken from the second file:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;./util/amdfwtool/amdfwread -d --ro-list xab&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now we can start comparing the output. Pointers to directories or firmwares that are either 00000000 or ffffffff can be omitted, since both should indicate an invalid pointer. Most notable differences are SPI speeds, eSPI config and Multi Gen EFS value.&lt;/p&gt;
    &lt;p&gt;Fixing SPI speeds is pretty much straightforward. The board code should supply the following Kconfig values to match vendor firmware:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Having a correct SPI speed may be crucial for the proper operation of the system components and flawless communication on the SPI bus interface.&lt;/p&gt;
    &lt;p&gt;The eSPI configuration fields are configuration values that the PSP will use to configure the eSPI bus before the reset vector. The eSPI bus is important because the Baseboard Management Controller is connected to it. With BMC, we can use the serial port to debug problems, so we have to match the configuration. Support for setting the eSPI configuration has been implemented in the patch that adds Turin support to amdfwtool. With these modifications in place, I could define the Kconfig values again in board code (only one value is enough, because the rest is 0xff - default):&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The only difference left to cover is the Multi Gen EFS value. The usage of this field is described in the AMD documentation only. For the purpose of the analysis and explaining its importance, let’s say this value is specific to the processor family, and PSP uses it to match whether the given EFS is appropriate for the given CPU. These values are fixed for a given CPU family, and for Turin it has to be 0xffffffe3.&lt;/p&gt;
    &lt;p&gt;Covering these differences was not enough to allow the CPU to be released from reset using the public blobs. So we have to proceed further with the analysis, that is, to the PSP and BIOS directories.&lt;/p&gt;
    &lt;head rend="h2"&gt;PSP and BIOS directories&lt;/head&gt;
    &lt;p&gt;In the coreboot paste, we can see that PSP and BIOS directories have the same attributes as in the vendor image, but there are fewer entries in them than in the vendor image. For comparison:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vendor BIOS: &lt;list rend="ul"&gt;&lt;item&gt;PSPL1: 53 entries&lt;/item&gt;&lt;item&gt;PSPL2: 48 entries&lt;/item&gt;&lt;item&gt;BIOSL1: 25 entries&lt;/item&gt;&lt;item&gt;BIOSL2: 34 entries&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;coreboot: &lt;list rend="ul"&gt;&lt;item&gt;PSPL1: 30 entries&lt;/item&gt;&lt;item&gt;PSPL2: 41 entries&lt;/item&gt;&lt;item&gt;BIOSL1: 17 entries&lt;/item&gt;&lt;item&gt;BIOSL2: 19 entries&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The difference is, of course, dictated by the number of blobs AMD published here. Also, a subset of entries is duplicated between level 1 (L1) and level 2 (L2) directories of the same type. Level 1 directory is typically considered a recovery, and the level 2 is the main directory. However, for some reason, Gigabyte puts more blobs into the level 1 PSP directory than the level 2. To proceed further, we had no other choice but to eliminate the differences by extracting the blobs from the vendor image and integrating the missing ones. Extracting the blobs is possible with PSPTool:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;We have to take the extra &lt;code&gt;-r 1&lt;/code&gt; parameter because we want to extract the
Turin blobs, which live in the second 16MB half of the image, due to the dual
BIOS nature of the firmware images for this platform. When the blobs are
extracted, they have to be put into
&lt;code&gt;coreboot/3rdparty/amd_firmwares/Firmwares/Turin/&lt;/code&gt; directory to replace the
public blobs. Also, the &lt;code&gt;coreboot/src/soc/amd/turin_poc/fw.cfg&lt;/code&gt; file had to be
modified to point to the missing files. On top of that, the &lt;code&gt;amdfwtool&lt;/code&gt; had to
be extended with the new blob types. It has also been done as part of the
patch with Turin support.
However, to obtain full information on how these missing blobs should be
included, I needed the subprogram and instance numbers. These numbers are used
by PSP to distinguish the same type of program/blob, but for a different CPU
variant. For example, we may have multiple SMU firmwares, but only one will be
loaded on a given processor family, based on the subprogram and instance
numbers.&lt;/p&gt;
    &lt;p&gt;However, I had no tooling to dump these numbers. So again, I had to implement something myself. Thankfully, the PSPTool was very close to what I needed, and I simply extended it to print the subprogram and instance numbers for each blob:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;psptool -E MZ33-AR1_R11_F08/SPI_UPD/image.bin&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Based on the dump from the vendor image, I have modified &lt;code&gt;coreboot/src/soc/amd/turin_poc/fw.cfg&lt;/code&gt; and &lt;code&gt;amdfwtool&lt;/code&gt; to stitch the
components extracted from the vendor image. Only then was I able to obtain a
bootable coreboot image (CPU has been released from reset by PSP). Now having
the known good reference and a working tool, I could go back to the public
blobs.&lt;/p&gt;
    &lt;p&gt;I haven’t yet published the patches with PSPTool modifications. They will follow very soon, so stay tuned.&lt;/p&gt;
    &lt;head rend="h2"&gt;Running coreboot with public PSP blobs&lt;/head&gt;
    &lt;p&gt;Before proceeding with reverting to public PSP blobs, I have made one additional safety measure. I flashed back the vendor BIOS and enabled PSP verbose debug output. This can be done with the &lt;code&gt;ABL Console Out&lt;/code&gt; options in
the &lt;code&gt;SOC Miscellaneous Control&lt;/code&gt; described in the board
manual
(section 2-3-6). Booted the platform with debug options enabled, and on the
serial console port, I could see verbose debugging messages almost immediately
after pressing the power button. This debug output will help me quickly
determine if the public blobs are even consumed by PSP or not. If I don’t see
anything on the serial port, it will mean they are not consumed. The debug
switches are stored inside APCB blobs, so I dumped the BIOS image, extracted
the APCBs with PSPTool and copied them in place on the old ones in the board
code. First, I confirmed whether they are working with the blobs extracted
from the vendor image, to avoid any mistakes later. And fortunately, it also
gave me debug output with the coreboot image. Then I proceeded with replacing
the vendor image blobs with the public ones, stitched the image again, and
flashed it on the board. But nothing happened on the serial console,
unfortunately. This was very unexpected and left me at a loss. After many
hours of analysis and comparisons, what else might be wrong or different, I
noticed something strange in the PSPTool output made from the current coreboot
image:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;psptool -E build/coreboot.rom&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The most worrying is the first entry of PSPL1, which corresponds to AMD Root Key. This Root Key is the main key used to sign PSP blobs and derive other keys to sign other components:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Here we can see that the AMD Root Key has an ID &lt;code&gt;9F9D&lt;/code&gt;. The very same key is
used to verify PSP FW bootloader and PSP FW recovery bootloader
(&lt;code&gt;veri-failed(9F9D)&lt;/code&gt;, not sure why the verification fails, but it could be one
of the reasons why it is not working). When I looked closer at the output of
PSPTool from the vendor image, the verification of the PSP FW recovery boot
loader passed with the AMD Root Key:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The second significant difference is the key ID. The key ID in the vendor image was different (&lt;code&gt;D05C&lt;/code&gt;)! At first, I suspected that Gigabyte could have
created their own key to sign PSP blobs and got it signed by the AMD Root Key.
But is that really possible?&lt;/p&gt;
    &lt;p&gt;To be 100% sure, I have attempted to build the coreboot image with the latest AMD PSP blobs available in the Turin PI package (available to AMD partners). This is the package with the silicon initialization source code and the set of PSP blobs required to build a bootable image. So I updated &lt;code&gt;coreboot/src/soc/amd/turin_poc/fw.cfg&lt;/code&gt; again for the blobs from the Turin PI
package and dumped the directories with PSPTool. To my surprise, the AMD Root
Key was the same as in Gigabyte vendor firmware (full paste
here):&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;This means my hypothesis about the custom root key was incorrect. AMD simply published a different set of blobs, or blobs that are signed with pre-production key (that would make sense, since the PoC code was proven on the AMD CRB platform, which most likely uses a pre-production CPU). I have filed an issue on the repository requesting to update the blobs to the newest ones from the Turin PI package. A separate &lt;code&gt;fw.cfg&lt;/code&gt; file for the use with official Turin PI package blobs has been
prepared in this
patch,
for future use.&lt;/p&gt;
    &lt;p&gt;While using public blobs proved to be impossible for now, I still decided to prove that blobs from official sources are working properly and can eventually replaced the incorrect blobs from the repo. So I flashed the freshly produced image with blobs from the Turin PI package, and thankfully, the CPU was released from reset, and I saw debug messages from coreboot’s bootblock!&lt;/p&gt;
    &lt;p&gt;With these results, we have fulfilled the goals of the following milestones in the project:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Task 2. Public blobs integration &lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Milestone a. Analysis of vendor’s image&lt;/p&gt;&lt;p&gt;We have thoroughly analyzed the vendor image and eliminated any differences in the integrated PSP blobs that could have hindered the boot process with coreboot. We also learned about the inappropriate blobs published by AMD. The usage of publicly available blobs is currently impossible, until the correct blobs are published by AMD. However, when that happens, we are already prepared to build functional images. So building based on public components is possible but produces unbootable image. People with access to Turin PI package are able to build bootable image. Regardless of what will happen to the public blobs, 3mdeb will ship hardware and firmware with the correct blobs. The relevant patch adding support for the blob integration can be found here.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Milestone b. Update coreboot’s amdfwtool&lt;/p&gt;&lt;p&gt;Thanks to the extensive analysis of the vendor image, the amdfwtool is now successfully creating a bootable image for the Turin system. A patch has been uploaded and the “work in progress” state got removed, indicating the change is ready to review and functional.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;The journey of porting Gigabyte MZ33-AR1 seems to be still quite long. Lots of surprises probably still await us. Stay tuned for more blog posts where further porting efforts will be shown and explained.&lt;/p&gt;
    &lt;p&gt;Huge kudos to NLnet Foundation for sponsoring the project.&lt;/p&gt;
    &lt;p&gt;Unlock the full potential of your hardware and secure your firmware with the experts at 3mdeb! If you’re looking to boost your product’s performance and protect it from potential security threats, our team is here to help. Schedule a call with us or drop us an email at &lt;code&gt;contact&amp;lt;at&amp;gt;3mdeb&amp;lt;dot&amp;gt;com&lt;/code&gt; to start unlocking the
hidden benefits of your hardware. And if you want to stay up-to-date on all
things firmware security and optimization, be sure to sign up for our
newsletter:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45243439</guid><pubDate>Sun, 14 Sep 2025 21:35:42 +0000</pubDate></item><item><title>Betty Crocker broke recipes by shrinking boxes</title><link>https://www.cubbyathome.com/boxed-cake-mix-sizes-have-shrunk-80045058</link><description>&lt;doc fingerprint="800a557659315311"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The 70-Year-Old Beloved Boxed Mix Grandmas Won’t Be Buying Anymore&lt;/head&gt;
    &lt;p&gt;There’s a problem with boxed mixes, and it’s impacting grandmas’ most beloved recipes. At some point last year, shoppers noticed Betty Crocker cake mixes shrank (again), this time from 15.25 ounces down to 13.25 ounces. And while few people would ever argue for less cake, the 2-ounce decrease is weighing particularly heavy on grandmas.&lt;/p&gt;
    &lt;p&gt;Take my neighbor Judith (and grandma to two). Her chocolate crinkle cookies have been practically synonymous with our community potlucks for the past 15 years — and that’s only how long I’ve known her! It wasn’t until she suddenly stopped bringing them that I knew something was terribly wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Grandmas Aren’t Buying Boxed Cake Mixes&lt;/head&gt;
    &lt;p&gt;Her cookie recipe — a box of Betty Crocker chocolate cake mix, two eggs, and ⅓ cup neutral oil — no longer works now that the box is a full 5 ounces smaller than its original 18.25-ounce size (a 27% decrease and textbook example of shrinkflation). What once yielded 24 consistently light, fluffy cookies now makes 20 goopy, lackluster blobs. The only thing that has changed? The box mix.&lt;/p&gt;
    &lt;p&gt;“It’s just so upsetting,” says Judith, whose cookie recipe was passed down by her mother. These “perfect little cookies” once made the rounds at bake sales, Christmas cookie exchanges, and birthdays. She now calls them “unusable.” She could buy an additional box to make up the difference, she acknowledges, “but out of principle, I just can’t.”&lt;/p&gt;
    &lt;p&gt;Judith isn’t the only one. She says that her other (grandma) friends are feeling the changes, too, and they’re not happy about it. Betty Crocker has empowered home cooks to make delicious desserts for over a century now. So it’s no surprise just how many cherished family recipes — involving that once familiar box of cake mix — have been passed down from generation to generation.&lt;/p&gt;
    &lt;p&gt;It’s not just cookies that are affected; beloved family dump cakes, crumbles, pancakes, and more all fall short because the cake mix is no longer the same.&lt;/p&gt;
    &lt;p&gt;To add to the frustration, one Redditor pointed out that the brand may have “tinkered with the amount of leaveners in the mix itself. … When [the cake] first comes out of the oven, it looks like a more substantial amount of cake but then shrinks as it cools down.” (We reached out to Betty Crocker to verify any ingredient changes and have yet to receive a response.)&lt;/p&gt;
    &lt;p&gt;Baking is indeed a science that needs precise measurements and consistency. Many home bakers, like Judith, find it disheartening to see decades-old cherished recipes forever changed by corporate decisions. I did, though, share our Chocolate Crinkle Cookie recipe with her so she can try to make new traditions. &lt;lb/&gt;This article originally published on The Kitchn. See it there: The 70-Year-Old Beloved Boxed Mix Grandmas Won’t Be Buying This Holiday Season&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45243635</guid><pubDate>Sun, 14 Sep 2025 21:54:07 +0000</pubDate></item><item><title>Trigger Crossbar</title><link>https://serd.es/2025/09/14/Trigger-crossbar.html</link><description>&lt;doc fingerprint="2e1b921501a716a4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Trigger crossbar&lt;/head&gt;
    &lt;p&gt;If you have a large, well-equipped electronics lab youâre going to have a lot of instrumentation with trigger input and output ports.&lt;/p&gt;
    &lt;p&gt;In my case all three oscilloscopes, the vector signal generator, and even my VNAs have trigger sync capability, and thereâs probably more things Iâm missing. And that doesnât even count the ThunderScope or the two Siglent AWGs I have on loan for ThunderScope R&amp;amp;D.&lt;/p&gt;
    &lt;p&gt;Very often, itâs handy to cascade these in order to enable complex multi-instrument setups (for example, having a scope trigger when an AWG creates a pulse of some sort, without burning a scope channel to look at the AWG output, or to have two scopes trigger simultaneously to capture more channels of data in a complex system).&lt;/p&gt;
    &lt;p&gt;Thereâs just one obvious problem: All of my equipment is rack mounted, thereâs a LOT of it, and thereâs already a ton of cable spaghetti in a fairly confined space. The last thing I want to be doing is reaching around behind the racks and crawling under the bench to untangle coax and route trigger signals from one instrument to another every time I want to set up a multi-instrument experiment.&lt;/p&gt;
    &lt;p&gt;The second, slightly less obvious, problem is that not all of these signals are compatible voltage levels. For example, the trigger output on my Teledyne LeCroy oscilloscopes is 1V into high-Z or 500 mV into a 50Î© load. The Siglent vector signal generator has a 5V TTL trigger input. So you canât just directly connect these without a level shifter or buffer.&lt;/p&gt;
    &lt;p&gt;What if there was a better way?&lt;/p&gt;
    &lt;head rend="h2"&gt;The concept&lt;/head&gt;
    &lt;p&gt;Pretty quickly I came up with a high level concept for what I wanted to build: a 1U device with an Ethernet SCPI interface plus a ton of coaxial trigger inputs and outputs, connected to a buffered FPGA-based switch fabric.&lt;/p&gt;
    &lt;p&gt;Some outputs would be buffered by external level shifters to enable interfacing with different voltage levels, while others would be directly connected to FPGA GPIOs for the lowest possible jitter but with a fixed voltage range. Inputs would be routed to comparators to allow arbitrary switching thresholds.&lt;/p&gt;
    &lt;p&gt;A handful of these channels would be bidirectional, with latching relays to swap between input and output modes. This is important because a few of my instruments, most notably the PicoScope and Siglent vector signal generator, use the same BNC as both trigger input and output.&lt;/p&gt;
    &lt;p&gt;The whole thing would be powered by 48V DC using my existing intermediate bus converter and controlled over IP via ngscopeclient, using the filter graph to create virtual connections between crossbar ports..&lt;/p&gt;
    &lt;head rend="h2"&gt;High level design&lt;/head&gt;
    &lt;p&gt;I selected the Xilinx XC7K70T-2FBG484C as the FPGA for a few reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I had a lot of 7 series parts in inventory, so no need to buy anything new.&lt;/item&gt;
      &lt;item&gt;Kintex-7 has high-performance (HP) I/O banks which have faster slew and lower jitter than the high-range (HR) I/Os found in Spartan/Artix parts. I didnât want to increase cross-trigger jitter more than necessary so this was important.&lt;/item&gt;
      &lt;item&gt;The 70T in FBG484 is the lowest cost part in the Kintex-7 line, we donât need a ton of stuff in the FPGA so no reason to go bigger.&lt;/item&gt;
      &lt;item&gt;The -2 speed has 10.3125 Gbps capable SERDES (weâll get to why this is important in a bit).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This then got paired with the STM32H735 MCU as the controller.&lt;/p&gt;
    &lt;p&gt;I started this project all the way back in October 2023, long before I realized how cursed the OCTOSPI on the H735 was. In fact, many of the things I discuss in that post were learned on the crossbar project, it just took me this long to get to the point of having time to write about the crossbar as a whole.&lt;/p&gt;
    &lt;p&gt;So (foreshadowing a bit), I made the mistake of connecting it via the OCTOSPI thinking that I wouldnât need the bandwidth of the FMC to control a few muxes and it would save pins. I also hadnât tried the FMC yet and thought (famous last words) that the OCTOSPI would be simpler and easier to set up. This ultimately turned out to be a massive annoyance and cost me a lot of time, but I did get it working in the end.&lt;/p&gt;
    &lt;p&gt;The final concept I came up with was logically a 12x12 crossbar: eight inputs, eight outputs, and four bidirectional ports.&lt;/p&gt;
    &lt;p&gt;The input ports were all 50Î© impedance, with a 6 dB (2:1) attenuator and ESD diode prior to the input termination. The input then entered a MAX40026 high-speed LVDS comparator, with the positive input fed by the trigger signal and the negative by a reference voltage generated by a DAC. This design provides runtime-variable thresholding and 5V tolerance while operating from a 3.3V supply.&lt;/p&gt;
    &lt;p&gt;Output channels 0-3 were driven directly by HP I/Os on the FPGA, providing a fixed 1.8V swing but the highest possible jitter performance. The remaining 8 outputs were driven by TI 74LVC1T45 level shifters. Each level shifter had its own independent VCCIO power domain supplied by an ISL24021 power op-amp buffering a reference voltage generated by one output from an 8-channel DAC, allowing runtime adjustment of VCCIO for each port. The buffered output then passes a final ESD diode before reaching the connector.&lt;/p&gt;
    &lt;p&gt;You can see the whole schematic (and firmware) on my GitHub.&lt;/p&gt;
    &lt;p&gt;The rest of the logic board was fairly straightforward: a KSZ9031 gigabit Ethernet PHY for management (routed to the FPGA in case I wanted to add any kind of hardware offload), a bunch of Murata DC-DC modules to generate all of the necessary supply rails from the 12V intermediate bus, a serial port for initial IP configuration and debug, an EEPROM to store the MAC address, and a connector supplying power and SPI to the front panel board.&lt;/p&gt;
    &lt;p&gt;The FPGA has four GTX SERDES lanes in a single quad. I hooked them all up (it always seems like a shame to not pin out transceivers to something):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Two lanes to front panel TX/RX differential SMA ports for use as a 2-lane BERT or serial pattern generator/receiver. Iâve wanted to build a proper BERT for a while and this was a good opportunity to play with it.&lt;/item&gt;
      &lt;item&gt;One lane to a back panel 10G SFP+ (because why not, 10GbE is always handy to have)&lt;/item&gt;
      &lt;item&gt;One lane TX to a front panel differential SMA port for use as a deskew reference&lt;/item&gt;
      &lt;item&gt;The RX of the split channel went to a comparator and single-ended coaxial input for a potential future CDR trigger feature.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unfortunately, having all of the transceivers in a single quad was a bit limiting due to the 7 series clocking architecture: they share the same QPLL, which has to be at 10.3125 Gbps for 10Gbase-R operation. While the CPLLs can be configured freely, they have a lower Fmax which meant that the BERT / CDR trigger channels cannot operate at arbitrary frequencies above 6 Gbps (most notably, 8 Gbps operation for PCIe gen3 mode is not available).&lt;/p&gt;
    &lt;p&gt;In theory it would be possible to reconfigure the QPLL for PCIe gen3 at the cost of temporarily disabling the SFP+ but current firmware/gateware doesnât support this. Using an UltraScale+ FPGA (which has a much higher CPLL frequency range, plus two QPLLs per quad) would also have provided a lot more clocking flexibility, but would also increase the cost since I didnât have a suitable FPGA on the shelf at the time and this board started out as a âjunk box buildâ from parts I mostly had on the shelf already.&lt;/p&gt;
    &lt;head rend="h2"&gt;The PCB&lt;/head&gt;
    &lt;p&gt;The board was fabricated at Multech on the 10-layer stackup Iâve used for my last few high-end designs: SGS GPPG SGS, with TU872SLK between the signal and reference layers and S1000-2M between the power and ground layers since thereâs no reason to use an expensive low-loss laminate on a power layer.&lt;/p&gt;
    &lt;p&gt;All of the trigger I/Os were placed in the northwest corner, with what ultimately turned out to be perhaps a bit too much packing density in retropect. The other rear-panel connectors were RJ45s for RS232 (Cisco pinout) and 1000baseT and the SFP+ for high speed I/O.&lt;/p&gt;
    &lt;p&gt;The 12V power input and I2C interface to the IBC were placed in the southwest corner, with the front panel SERDES ports along the south edge and the FPGA roughly centered in the board for easy access to everything. All of the high speed I/Os used SMPM connectors, my go-to for high speed high density these days because theyâre much smaller than SMA and have higher bandwidth. But this many of them was perhaps a bit excessive; if I were doing it again Iâd likely have used some kind of multi-lane board to board or board-to-cable connector and then broken out elsewhere.&lt;/p&gt;
    &lt;p&gt;The MCU was jammed into the 3 oâclock position just south of the SFP+; since it was mostly a âbrain on a stickâ hanging off the quad SPI link to the FPGA and not needing much IO of its own it could be placed almost anywhere.&lt;/p&gt;
    &lt;p&gt;I also provided a PMOD for debug GPIO, a couple of LEDs, and two 12V 4-pin fan connectors (only one of which ended up being used).&lt;/p&gt;
    &lt;p&gt;The final board size was 165 x 121 mm with 633 components, one of my larger designs to date. Mounting holes were 4-40, 5mm in from each corner plus one in the center of each of the long edges.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bringup woes&lt;/head&gt;
    &lt;p&gt;Once I assembled the board (most of a weekend worth of tweezering components) and started trying to write firmware and gateware, I ran into problems. Well, actually I found one even before finishing populating the board (the SFP+ was recessed too far, and the EMI fingers on the bottom were bumping into the PCB surface and tilting it up slightly). I was able to fix this by cutting the EMI fingers off.&lt;/p&gt;
    &lt;head rend="h3"&gt;Power connection&lt;/head&gt;
    &lt;p&gt;Then I tried to actually turn it on, and nothing happened. The 48V IBC connects to the logic board via two connections - an 8-pin Molex Mini-Fit Jr carrying 12V power and ground, and a 5-pin Molex PicoBlade carrying a 3.3V standby power rail, an I2C management bus, and an enable line for the main 12V rail.&lt;/p&gt;
    &lt;p&gt;After a bit of probing, I discovered that I had wired the connector as if it were 1:1 pinout (i.e. pin 1 of IBC connector to pin 1 of logic board connector). But standard PicoBlade cables are wired straight through (a strip of parallel wires with one connector on each end, pin 1 wired to pin N-1).&lt;/p&gt;
    &lt;p&gt;I briefly considered reworking the IBC or logic board before realizing that bodging the cable was a much simpler solution. All I had to do was gently push in the latching pin on each crimp terminal to remove it from the plastic housing, then reinsert them in the correct order and add a bright orange stick-on warning label âmirrored pinoutâ so I didnât mix up this special cable with a standard-pinout one.&lt;/p&gt;
    &lt;p&gt;With that fixed, I was at least able to get power to the board. There was no magic smoke, always a good sign.&lt;/p&gt;
    &lt;head rend="h3"&gt;More power issues&lt;/head&gt;
    &lt;p&gt;I normally have the majority of power rails on my boards default to the off state, then turn them on one at a time under control of a supervisor MCU which functions as a PMIC (in this case a STM32L031). This is great for prototypes and small-run boards because it lets me change rail sequencing dynamically with a software patch, as well as automating bringup one rail at a time with instant panic-shutdown within milliseconds if a rail doesnât stabilize when and where it should. This minimizes the chance of hardware damage in case of solder defects or PCB design bugs on a hand soldered prototype.&lt;/p&gt;
    &lt;p&gt;Right out of the gate, things werenât too happy: 1V8 was reporting no-good on PGOOD. 3V0_N and GTX_1V8 werenât coming up, GTX_1V0 was unstable, and 1V2 was a dead short to ground.&lt;/p&gt;
    &lt;p&gt;Scoping the 1.8V rail gave a somewhat surprising result: the rail came up fine, stabilized at 1.7903V, but PGOOD never went high and after a few ms the supervisor assumed the rail was shorted (it wasnât monitoring the actual rail voltage with an ADC, just PGOOD reported by the regulator) and entered panic-shutdown mode to protect the board.&lt;/p&gt;
    &lt;p&gt;I decided to ignore the PGOOD fault since it looked like it would be a pain to rework due to the thermal mass of the board, and just patch the supervisor firmware to continue bringing up other rails a fixed delay after turning on 1V8. This isnât something I would do in a ârealâ system of course, but for a one-off it was a risk I was willing to take after having confirmed the rail wasnât in fact shorted (I had plenty of other fusing and protection mechanisms, the software timeouts were deliberately paranoid for bringup).&lt;/p&gt;
    &lt;p&gt;Most of the other rail issues turned out to be bad solder joints on the LGA Murata DC-DC modules I was usingâ¦ my solder paste print in this area was decidedly subpar (the board was larger than I was used to and flexed in the printing fixture due to insufficient back-side support while only fixturing it from the edges). In retrospect I should have just wiped the board off and re-printed but I had faith in my solder paste. A bit too much faith.&lt;/p&gt;
    &lt;p&gt;Anyway, I pulled and resoldered the 1V2 and GTX_1V8 DC-DC Modules, and added more capacitance to the 3V0_N regulator input which was causing instability during startup. I had ferrites on the output of GTX_1V0 and a few other rails as secondary filters but these were hurting stability so I removed them and replaced them with 0Râs.&lt;/p&gt;
    &lt;p&gt;At some point I noticed that decoupling capacitor C6, one of two 22 uF MLCCs as the input of the 3.3V DC-DC module, was not actually placed within the 12V power zone fill on layer 6. The 12V terminal on the capacitor was only connected by a very thin trace coming off the vias, which significantly reduced its effectiveness. This was easily bodged with a surface jumper connecting it to C3, the other 22 uF capacitor.&lt;/p&gt;
    &lt;head rend="h3"&gt;Comparator Vcm issues&lt;/head&gt;
    &lt;p&gt;With the power reasonably stable, the next step was to actually hook up some signal sources and bring up the I/O buffers.&lt;/p&gt;
    &lt;p&gt;They worked fine with large-swing inputs like 3.3V, but when I tried to use low-amplitude signals the LVDS outputs of the comparators werenât toggling.&lt;/p&gt;
    &lt;p&gt;After a while, I realized that I had missed the 1.5V minimum Vcm spec on the MAX40026 comparators when designing the input stage. And since I had a 2x attenuator on the input to provide 5V tolerance, this really came out to 3V at the input. Experimentally, if the DAC for setting the comparator threshold was set below about 800 mV, I stopped getting useful results out of the comparator. This was a major problem, since these inputs were key to the functionality of the device and my LeCroy scopes had 1V full-scale output on the trigger sync ports.&lt;/p&gt;
    &lt;p&gt;A switchable attenuator is the ârightâ solution here - with the 2x switched in it would perform well for ~3V to 5V inputs, and with no attenuation it would accept inputs from 3.3V down to ~1V logic levels. But retrofitting eight SPDT relays and drive circuitry around the attenuators, plus figuring out how to power and control them, seemed a bit beyond the scope of reasonable rework. I didnât want to respin the board and since this was mostly a project to scratch my own itch and not something I planned to mass produce, I wanted to avoid scrapping the board (now worth well over $2K between PCB and components, plus several days of hand assembly time).&lt;/p&gt;
    &lt;p&gt;After giving it some thought I decided that since I planned to have any given trigger input permanently connected to a specific instrument for the lifetime of the device, I didnât actually need a runtime-switchable attenuator. So I reworked most of the inputs to have a 0 dB passthrough instead of the original 6 dB attenuator (limiting them to 3.3V input levels), keeping attenuators only on the inputs that I planned to connect to instruments which had 5V trigger outputs. This seemed to work fine.&lt;/p&gt;
    &lt;head rend="h3"&gt;SPI/QSPI bus issues&lt;/head&gt;
    &lt;p&gt;As I started writing firmware, I couldnât get the main MCU (STM32H735) to talk to the supervisor (STM32L031) over their shared SPI bus. I pretty quickly discovered that this was due to a MOSI/MISO crossover that shouldnât have been there (STM32 SPI block wants them connected 1:1, changing pin directions based on host/device mode rather than having fixed in/out pins). This was easily reworked with a few trace cuts and a surface jumper right next to the MCU.&lt;/p&gt;
    &lt;p&gt;Around this time I also discovered how cursed the OCTOSPI was. I have a whole post about this so I wonât repeat all of the details here.&lt;/p&gt;
    &lt;p&gt;Finally, I started trying to bring up the front panel MCU and lost connectivity to the debugger as soon as I tried to send SPI traffic to it. This puzzled me to no end until I realized I was being hit by STM32L431 errata 2.2.6. Basically, the pin muxing logic is broken and if you try to use PB4 as anything but NJTRST, it doesnât actually disconnect the signal from the JTAG TAP and any logic low on the pin will reset the TAP.&lt;/p&gt;
    &lt;p&gt;I ended up working around this issue in two different ways:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First: Patch the firmware to keep PB4 alt mode as JTRST unless actively sending SPI data back to the main processor (which will cause a momentary debugger disconnection, but allow the debugger to reconnect as soon as the SPI burst ends).&lt;/item&gt;
      &lt;item&gt;Second: Switch from debugging over JTAG to SWD, which bypasses the issue entirely. This also frees up the JTDO/SWO pin for use as serial trace output, which I wasnât using at the time but have since began to take advantage of.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Single ended CDR trigger input not working&lt;/head&gt;
    &lt;p&gt;I never solved this one. There was a HMC675 comparator feeding a GTX lane that I had intended to use as a CDR trigger input, but I wasnât getting toggles on the LVDS/CML output no matter what I did. I had so many other issues on the board and the CDR trigger was mostly a stretch goal, so I just shelved it. Could be anything from a soldering issue to a bad pinout to something borked in the power supply / circuit design.&lt;/p&gt;
    &lt;p&gt;I can always add CDR trigger input functionality in gateware via the BERT lanes, it will just require a 100 ohm differential input (or terminating one of the inputs to provide a single ended input?) rather than using the 50 ohm single ended input I had originally planned.&lt;/p&gt;
    &lt;head rend="h3"&gt;FPGA flash pinout bug&lt;/head&gt;
    &lt;p&gt;At this point, I had all of the major issues fixed (so I thought) and I started writing firmware and gateware. I had things working pretty well, until I tried to burn a bitstream to FPGA flash so I could boot the board from a cold state without having to JTAG it.&lt;/p&gt;
    &lt;p&gt;And nothing happened.&lt;/p&gt;
    &lt;p&gt;So I dug deeper, and was very upset with what I found: I had hooked CS# of the QSPI flash to CSO_B (daisy chain configuration chip select output), not FCS_B (flash chip select). Iâm still not sure how I made this mistake and didnât catch it during design review: if this was my first 7 series FPGA design it would be somewhat understandable, but itâs not. Iâve done probably 10+ 7 series designs in the past, and always got this connection right. Until now.&lt;/p&gt;
    &lt;p&gt;The actual FLASH_CS_N signal connected to pin M22 of the FBG484 package, while it should have gone to L16.&lt;/p&gt;
    &lt;p&gt;Disconnecting it from M22 was trivial, there was a via in the M22 BGA land (at the outer perimeter of the BGA) going straight into a 33Î© series terminator footprint on the back side of the board. Desoldering the terminator trivially disconnected the incorrect connection.&lt;/p&gt;
    &lt;p&gt;Adding the new connection at L16? Less trivial. In this area, there were:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;JTAG TMS and TCK in the routing channels immediately east/west of the L16 land on layer 3&lt;/item&gt;
      &lt;item&gt;Ground planes on layers 2, 4, 7, and 9&lt;/item&gt;
      &lt;item&gt;3.3V VCCO power plane on layer 5, connecting to a via in L17 immediately south of the L16 land&lt;/item&gt;
      &lt;item&gt;1.0V VCCINT power plane on layer 5, connecting to a via in L15 immediately north of the L16 land&lt;/item&gt;
      &lt;item&gt;1.8V VCCO/VCCAUX power plane on layer 6, but with no vias in the immediate area&lt;/item&gt;
      &lt;item&gt;4.7 Î¼F 0603 decoupling capacitor on layer 10 partially overlapping the L16 land&lt;/item&gt;
      &lt;item&gt;The remote sense line for VCCINT on layer 10&lt;/item&gt;
      &lt;item&gt;And of course the FPGA already soldered to layer 1&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Given how far into the BGA footprint the missing connection was, trying to reach in from the edge wasnât viable.&lt;/p&gt;
    &lt;p&gt;This really left only three options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Give up. Accept that SPI boot isnât going to be available, then bodge up some board with a little MCU that acts as a JTAG controller, hooks up to the FPGA JTAG, and squirts a bitstream into the FPGA on powerup. This would require no hardware modification at all (although Iâd have to design the MCU board) but would block FPGA JTAG access for debug and just be ugly. The lack of debug access alone was enough of a reason to reject this,&lt;/item&gt;
      &lt;item&gt;Remove the FPGA, drill out a via from the top, figure out how to plate/fill it so it wouldnât suck the solder down, reball the FPGA, put it back. I donât have great gear for BGA desoldering, had a bunch of heat sensitive non-reflowable components on the board at this point, and didnât feel like tweezering 484 solder balls or scrapping a several hundred dollar FPGA. So this was a non-starter as well.&lt;/item&gt;
      &lt;item&gt;Root canal approach: add the via from the back side. This really seemed like the only way forward.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So basically I had to drill a ~1.6mm deep flat-bottomed hole, exposing but not perforating the 35 Î¼m thick copper foil on L1 attached to the BGA land, and solder a jumper wire to it without shorting to any of the six power/ground plane layers in close proximity, damaging the VCCINT/VCCO vias 1mm centered north/south of the target, or cutting either of the layer 3 JTAG lines centered 500 Î¼m east/west of the target. No big deal /s.&lt;/p&gt;
    &lt;p&gt;I started out by removing two capacitors and a resistor in close proximity to the work area, that were getting in the way.&lt;/p&gt;
    &lt;p&gt;Then I fixtured the board on my Sherline 5400 mini mill and loaded up a 250 Î¼m carbide endmill. The mill is set up with a cheap Amscope stereo microscope (Iâm not going to risk my nice Leica getting hit by flying debris etc) and a 1/8â collet for mounting fine-pitch drills and endmills. At the time of this project I didnât have a proper gooseneck LED illuminator so I just used a random headlamp, although Iâve since fixed that.&lt;/p&gt;
    &lt;p&gt;At this point there was nothing left to do but start drilling.&lt;/p&gt;
    &lt;p&gt;The overall setup was very similar to a dual-beam SEM/FIB scaled up by a few orders of magnitude and rotated: milling column coming in from the top, and imaging column at a ~45 degree angle for in-process inspection. And using a vacuum system (aka a shopvac) for removing debris from the milled cavity. No fancy secondary ion mass spectrometer is needed for endpoint detection though, you can just see the swarf change from white fiberglass to shiny red copper when you hit a metal layer.&lt;/p&gt;
    &lt;p&gt;Just like with a dual-beam, this sort of work requires making an angled cut to allow the angled imaging path to see the work area of the mill. I decided to orient the board in the canonical CAD orientation and come in from the south side, parallel to the JTAG traces. As long as I kept the cavity centered and not more than around 750 Î¼m wide, there was no real danger of hitting the JTAG lines. The angled cut was more tricky as I had a VCCO via 1mm south of the work area that I needed to keep intact from L1 to L5 (but back-drilling it from L6 to L10 wouldnât hurt anything), so I had to pay careful attention to depth as I approached this area.&lt;/p&gt;
    &lt;p&gt;It worked perfectly. After about an hour of very careful machining, periodically stopping to unmount the board and look at it from different angles under the nice microscope, I saw the back side of the target BGA land coming into view, still under around 50 Î¼m of laminate but clearly visible after adding a drop of IPA (a little trick Iâve learned when doing rework: it soaks into the resin and fills the gaps between the glass strands, acting to match the refractive index better and making it more transparent with less scatter)&lt;/p&gt;
    &lt;p&gt;The only thing left to do was a final plunge cut to expose a 250 Î¼m circle of bare copper to solder to. In this view you can clearly see how the milled cavity gets smaller and smaller as the target area approaches. This is rotated 180 degrees from canonical (south in CAD view is up in this image). Note the VCCO via barrel terminating at L5, then L4 ground plane visible slightly below it. The L2 ground plane is barely visible at the 7 oâclock position of the final hole.&lt;/p&gt;
    &lt;p&gt;I did a final check for shorts and everything looked good. The only thing left to do was solder it up (not trivial, given that Iâm trying to hit a 250 Î¼m diameter target at the bottom of a 1.6mm deep hole).&lt;/p&gt;
    &lt;p&gt;After a few minutes of contorting myself trying to get a 100 Î¼m conical soldering tip and a 125 Î¼m bare copper wire positioned at the bottom of the hole while also angling the board enough that I could see under a microscope, I managed to get the wire securely attached.&lt;/p&gt;
    &lt;p&gt;Once that was done, I reconnected the VCCINT remote sense input, added a new series terminator to the CS# signal, put the removed decoupling capacitor back on its new slightly-smaller footprint, and tacked down all the wires with UV glue so they wouldnât move around.&lt;/p&gt;
    &lt;p&gt;After verifying the board was electrically functional and I could program the flash and boot from it, I went back and flooded the whole area with UV cured conformal coating to lock everything in place permanently.&lt;/p&gt;
    &lt;head rend="h2"&gt;Chassis design and assembly problems&lt;/head&gt;
    &lt;p&gt;I went with a custom 1U enclosure from ProtoCase, designed using their free ProtoCase Designer software.&lt;/p&gt;
    &lt;p&gt;I have very mixed feelings about it: it has a lot of convenient templates and integrations with their standard pems and printing processes, and runs on Linux (a rarity in the proprietary CAD world). But itâs also a custom file format to lock you into their service, and if you import a couple of moderately complex STEP models of PCBs it slows to a crawl. Iâll probably keep using it for now, as the free tools donât seem to be up to the task for complex sheet metal work and I donât want to buy SolidWorks or something and set up a Windows VM for it.&lt;/p&gt;
    &lt;p&gt;My original plan had been to use their standard 1U folded sheet metal design, but I discovered too late, after boards were ordered, that it wasnât going to work due to the 5mm corner mounting holes being inside the keepout area for the rear bend. I went with an extruded aluminum design, which let me salvage the design but had several significant problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The stock template has no rack ears (although itâs 1U high) and thereâs no way to add them within their software. I had to pay an hourly fee for one of their engineering technicians to create a new template with ears and extruded sides.&lt;/item&gt;
      &lt;item&gt;The top and bottom panels slide into the extrusions and are held in place by the front and back. This means you cannot take the top panel off, e.g. to access JTAG ports for debug, without also removing the front panel (wearing out the self-tapping screwsâ holes and putting shear forces on any attached cables)&lt;/item&gt;
      &lt;item&gt;The front panel is only attached at the edges, and can flex relative to the top/bottom panels by quite a bit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Iâm definitely not going to use this case design again, although I made it work for a one-off. All of my future projects will do chassis-PCB codesign and not order boards until the enclosure is finished enough that Iâm confident everything will mate properly.&lt;/p&gt;
    &lt;p&gt;All of the front/rear panel coaxial ports connect to the logic board using custom sized SMA-to-SMPM semirigid cables. I went with semirigid to ensure the best possible repeatability of the trigger path delays, but it was likely overkill. It also made chassis assembly an absolute nightmare even with the custom 3D printed bending jigs I madeâ¦ Iâm never doing this again. Either flexible cables, hand-formable cables, or a much lower density design with semirigid that I have more space to route.&lt;/p&gt;
    &lt;p&gt;The biggest problem was that the SMAs bolted to the outside of the chassis, meaning that I had to pre-bend the cables, then thread the SMPM end in through the hole in the chassis, then try to snake the SMPM in through all of the previously installed cables. Lesson very painfully learned: I did get it fully assembled in the end, but I would never build a second unit like this.&lt;/p&gt;
    &lt;p&gt;I also had slightly oversized some of the cables thinking that this would be better than undersizing, but in many cases this led to extra slack that I had to remove by U-bends and such, adding to the tangle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Front panel&lt;/head&gt;
    &lt;p&gt;The front panel has a STM32L431 and an I2C I/O expander to drive two rows of LEDs, showing pulse-stretched trigger input and output state. Four additional pairs of LEDs show the direction of the bidirectional ports, and a small e-paper display shows system health and status information.&lt;/p&gt;
    &lt;p&gt;I may have gone slightly overkill with the stitching vias on the board, but Iâm so used to high speed designs that itâs a hard habit to break. I used an 0.5mm BGA package for the STM32 as a test to see if I could make it work on OSHPark, but probably would have just gone with the 48-QFN if this was a ârealâ product since there was absolutely no point in using a fine pitch BGA here.&lt;/p&gt;
    &lt;p&gt;This was my first time using e-paper and I initially had specced a white/black/red panel thinking I could use the red to denote error states or something, but quickly realized the error of my ways: the tricolor panels have a very very slow refresh rate and are really only suitable for signage, not user interface type stuff. Luckily Pervasive Displays made a pin- and mechanically-compatible B&amp;amp;W fast refresh display, so I swapped that in.&lt;/p&gt;
    &lt;p&gt;After spending a little while figuring out the not-great documentation for the panel controller and baking a few bitmap fonts into the STM32 firmware, I got it displaying some pretty system health stats: Ethernet link speed, IPv4/6 addresses, unit serial number, firmware timestamps for the FPGA and MCUs, input and output voltage/current/power for the IBC, temperatures at four points in the system, and fan speed.&lt;/p&gt;
    &lt;p&gt;I also swapped the original first-generation IBC shown in the build photos with my second-generation MYC0409 based version to improve power efficiency, at which point the hardware was essentially done.&lt;/p&gt;
    &lt;p&gt;The unit is now mounted on one of my 19â benchtop racks and cabled to most of my instrumentation (I have a few more cables to run still but the main oscilloscopes and such are connected). I left the top off because I still have some firmware tweaks to do, so I need to be able to get JTAG/SWD dongles in to debug it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Operation&lt;/head&gt;
    &lt;p&gt;The crossbar has two remoting interfaces: SSH and SCPI.&lt;/p&gt;
    &lt;head rend="h3"&gt;SSH&lt;/head&gt;
    &lt;p&gt;The SSH interface is mostly used for low level configuration and setup - managing keys for administrative access, forcing refreshes of the front panel LCD, displaying hardware sensor values, setting the NTP server IP address, etc.&lt;/p&gt;
    &lt;p&gt;Itâs also used for firmware updates via SFTP. This is a somewhat unconventional DFU flow but I quite liked it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;To flash the FPGA, SFTP a .bit file to /dev/fpga and it will be directly written to QSPI flash on the FPGA&lt;/item&gt;
      &lt;item&gt;To flash the front panel or logic board MCU, SFTP an ELF binary to /dev/mcu or /dev/frontpanel. The ELF will be parsed live by the SFTP server and any PT_LOAD program headers in the flash address range are then written to flash. This is implemented in a single-pass streaming flow which requires a specific construction of the ELF (ELF header then program header table then program headers in linear address order) however all sane ELF generators like the GNU linker produce binaries that follow this. If you try to flash with a pathological ELF hand crafted in a hex editor and brick things, thatâs on you :P&lt;/item&gt;
      &lt;item&gt;Supervisor and IBC MCUs are not field updateable because they were (at the time) STM32L031 based and lacked the flash for a bootloader. IBC is now STM32L431 based so adding a bootloader is possible, but I canât see any reason Iâd want to OTA the power supply so Iâll probably just JTAG it if I ever need to patch.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Code signing support could be added to this flow easily (basically just mark the image as non-bootable in some way until youâve checked the signature, then clear the flag once youâve verified it). For the near term though, I trust that anyone with a valid administrative SSH key on the device is an authorized admin and can flash arbitrary code. Since thatâs only me, itâs fine for now.&lt;/p&gt;
    &lt;p&gt;But since I have a curve25519 acceleration block in the FPGA already Iâll probably prototype a signing flow at some point just to have it available for future projects; I can always turn it off. The basic concept is to add an extra .signature section in the linker script that will be filled with 0x00 padding at link time, then a signing tool run post-link will hash the contents and headers of all data to be written to flash, sign with the curve25519 key, and overwrite .signature with that.&lt;/p&gt;
    &lt;p&gt;Signing the FPGA bitstream would be even simpler, just sign the entire .bit and append 32 bytes of signature to the end. The bitstream can be made unbootable by writing a dummy bitstream to the first flash sector containing an invalid CRC and a DESYNC command until the verification is done, then erasing this and writing the actual first sector bitstream content at the very end. This will require one flash erase block (typically 4 kB) of scratchpad buffer in the bootloader but not an entire bitstream worth of RAM, enabling a fly-by update flow at the cost of a second program/erase cycle on that one flash sector which is probably OK.&lt;/p&gt;
    &lt;head rend="h3"&gt;SCPI&lt;/head&gt;
    &lt;p&gt;The SCPI interface is the primary remote control interface for application layer access to the crossbar. It provides a standard SCPI-compliant *IDN? command a well as custom commands for controlling the actual crossbar matrix, setting input thresholds and output levels, and accessing the BERT.&lt;/p&gt;
    &lt;p&gt;Crossbar paths can be configured in ngscopeclient by drawing connections in the filter graph from source port to sink port.&lt;/p&gt;
    &lt;p&gt;The BERT works pretty much like any other BERT supported by ngscopeclient. You can configure TX/RX bit rate, inversion, PRBS pattern or custom arbitrary pattern, NRZ baud rates from 625 Mbps to 10.3125 Gbps, etc. TX-side swing and pre/postcursor equalizer taps are also easily controlled from the channel properties dialog.&lt;/p&gt;
    &lt;p&gt;Thereâs still a few things I want to tweak. RX side equalization is currently fixed until I figure out how to properly tune the 7 series GTX receiver via the DRP. I havenât implemented long-duration single point BER measurements, oversampling density plot mode, or offset sampling single-point scans.&lt;/p&gt;
    &lt;p&gt;The BERT inputs also contain an incomplete âCDR-based logic analyzerâ feature. Essentially the raw GTX output is fed through 8b/10b or 64b/66b decoders and into a pattern matching block; once the requested trigger event is seen the LA will trigger and capture about a megapoint of raw line coded serial bits into block RAM then output to ngscopeclient as a waveform.&lt;/p&gt;
    &lt;p&gt;Eventually I want to finish building out various pattern triggers as well as integrating the CDR block with the trigger crossbar proper, such that a CDR pattern match can trigger an oscilloscope or other instrument.&lt;/p&gt;
    &lt;p&gt;The current gateware also provides a fixed 10.3125 Gbps PRBS-31 on the front panel âsyncâ port although I will likely make the baud rate and polynomial configurable at some point (basically a third output-only BERT channel). The intended use here is a deskew reference signal for use with ngscopeclientâs multi instrument sync feature, allowing the cross-trigger delay between multiple instruments to be automatically calibrated out.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;This was my first large, standalone, rackmountable, network connected project that Iâve taken to something resembling completion in a long time (although Iâm sure Iâll be continuing to poke at firmware for some time since the feature set isnât quite where I want it). I learned a lot of things not to do, ranging from PCB design to mounting hole positionining to the awful OCTOSPI.&lt;/p&gt;
    &lt;p&gt;But itâs a useful tool I work with in my lab on a regular basis, and proved out a lot of software and hardware building blocks and techniques that I plan to use in many of my future projects, such as the Ethernet switch.&lt;/p&gt;
    &lt;p&gt;Like this post? Drop me a comment on Mastodon&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45243740</guid><pubDate>Sun, 14 Sep 2025 22:08:13 +0000</pubDate></item><item><title>Grapevine canes can be converted into plastic-like material that will decompose</title><link>https://www.sdstate.edu/news/2025/08/can-grapevines-help-slow-plastic-waste-problem</link><description>&lt;doc fingerprint="f488c5b0bf730735"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Can grapevines help slow the plastic waste problem?&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;A new study from South Dakota State University reveals how grapevine canes can be converted into plastic-like material that is stronger than traditional plastic and will decompose in the environment in a relatively short amount of time.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The need for biodegradable packaging material has never been higher.&lt;/p&gt;
    &lt;p&gt;Currently, most packaging is "single use" and is made with plastic materials, derived from nonrenewable sources like crude oil that take hundreds of years to decompose in the environment. On top of this, only 9% of plastic is recycled. This has resulted in the formation of floating piles of plastic garbage in the ocean, called the "Great Pacific Garbage Patch."&lt;/p&gt;
    &lt;p&gt;But maybe even more concerning is the discovery of micro- and nano-plastics in the environment. Research has found that plastic breaks down into tiny particles, which are being ingested or inhaled by both humans and animals, and are found literally everywhere, including in the human body — according to recent research studies. Worse, little is known about the long-term health effects of microplastics.&lt;/p&gt;
    &lt;p&gt;Srinivas Janaswamy is an associate professor in South Dakota State University's Department of Dairy and Food Science. His research has focused on developing value-added products through biowaste and agricultural byproducts. One of the overarching goals of Janaswamy's research is to tackle the plastic waste crisis.&lt;/p&gt;
    &lt;p&gt;Perhaps the biggest contributor to plastic waste, at least in the United States, is plastic bags, the kind found at most retail stores. These bags, while sometimes recycled, are often only used once and can be found littered throughout the environment.&lt;/p&gt;
    &lt;p&gt;To address this problem, Janaswamy is working toward developing a plastic-like bag that will decompose in the environment.&lt;/p&gt;
    &lt;p&gt;"That is my dream," Janaswamy said.&lt;/p&gt;
    &lt;p&gt;The key ingredient to Janaswamy's work? Cellulose. This biopolymer is the most abundant organic substance on Earth and is found, primarily, in the cell walls of plants. Cellulose, thanks to strong hydrogen bonds and a chain of glucose molecules, gives plants structural strength and rigidity along with other biopolymers such as mannan, xylose, hemicellulose and lignin.&lt;/p&gt;
    &lt;p&gt;Humans have long used cellulose to create products. Cotton, the material used to make a majority of the world’s clothing, is primarily composed of cellulose. Wood is rich in cellulose as well.&lt;/p&gt;
    &lt;p&gt;In previous research, Janaswamy has extracted cellulose from agricultural products like avocado peels, soyhulls, alfalfa, switchgrass, spent coffee grounds, corncob and banana peels. He uses the extracted cellulose to develop films — materials that look and feel similar to traditional plastic wrapping.&lt;/p&gt;
    &lt;p&gt;"By extracting cellulose from agricultural products, value-added products can be created," Janaswamy said.&lt;/p&gt;
    &lt;p&gt;Each of Janaswamy's films has different characteristics and properties. Some are more transparent than others. Some are stronger. But thanks to a unique collaboration with a fellow SDSU faculty member, Janaswamy may have created his best value-added product yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Grapevine canes&lt;/head&gt;
    &lt;p&gt;Janaswamy had just finished presenting “Ag Biomass – A Holy Grail to Clean up the Plastic Mess” at SDSU's Celebration of Faculty Excellence when he was approached by Anne Fennell, a Distinguished Professor in the Department of Agronomy, Horticulture and Plant Science.&lt;/p&gt;
    &lt;p&gt;After listening to Janaswamy's presentation, Fennell became interested in the research and had an idea. A leading researcher in the study of grapevines, she knew that grapevine canes — the woody plant material that grapes grow on — were rich in cellulose. She also knew that grapevine canes were abundant and had limited use after harvest.&lt;/p&gt;
    &lt;p&gt;"Every year we prune the majority of yearly biomass off the vine," Fennell said. "The pruned canes are either mowed over, composted and reapplied to the soil, or burned in some areas. Research in Australia showed that prunings could be removed from the field in alternate years without effecting soil health. My thought was why not use this for value added films. Several of the materials that Janaswamy previously used had a high-water content, in contrast the winter pruning yields a cellulose-dense material with low water content, making them an abundant ideal material to work with."&lt;/p&gt;
    &lt;p&gt;Fennell's idea led to a collaboration, and soon Janaswamy was extracting cellulose — which looks almost like cotton — from the canes of grapevines. The resulting films were eye-opening.&lt;/p&gt;
    &lt;p&gt;According to a recent study published in the academic journal Sustainable Food Technology, Janaswamy's grapevine cane films are transparent and strong and biodegrade within 17 days in the soil — leaving behind no harmful residue.&lt;/p&gt;
    &lt;p&gt;"High transmittance in packaging films enhances product visibility, making them more attractive to consumers and facilitating easy quality inspection without the need for unsealing," Janaswamy said. "These films demonstrate outstanding potential for food packaging applications."&lt;/p&gt;
    &lt;p&gt;The grapevine canes were harvested from SDSU's research vineyard. The research team, which includes doctoral candidates Sandeep Paudel and Sumi Regmi, and Sajal Bhattarai, an SDSU graduate and a doctoral candidate at Purdue University, followed a published protocol in developing the films, which includes drying and grinding the canes and extracting the cellulosic residue. The residue was then solubilized and cast onto glass plates to create the films.&lt;/p&gt;
    &lt;p&gt;Testing revealed the grapevine cane-derived films were actually stronger than traditional plastic bags — in terms of tensile strength.&lt;/p&gt;
    &lt;p&gt;"Using underutilized grapevine prunings as a cellulose source for packaging films enhances waste management in the field and addresses the global issue of plastic pollution," Janaswamy said. "Developing eco-friendly films from grapevine cellulose represents a practical approach to sustainability, helping to conserve the environment and its resources and contributing to the circular bioeconomy."&lt;/p&gt;
    &lt;p&gt;The results of this work move Janaswamy one step closer to his dream of developing a bag made from a plastic-like material that will quickly decompose in the environment.&lt;/p&gt;
    &lt;p&gt;Funding for this research was provided by the U.S. Department of Agriculture's National Institute of Food and Agriculture and the National Science Foundation.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;Republishing&lt;/p&gt;
    &lt;p&gt;You may republish SDSU News Center articles for free, online or in print. Questions? Contact us at sdsu.news@sdstate.edu or 605-688-6161.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45243803</guid><pubDate>Sun, 14 Sep 2025 22:15:33 +0000</pubDate></item><item><title>Titania Programming Language</title><link>https://github.com/gingerBill/titania</link><description>&lt;doc fingerprint="cc9bde28ba1db0de"&gt;
  &lt;main&gt;
    &lt;p&gt;Based on the Oberon-07 programming language designed by the late Niklaus Wirth.&lt;/p&gt;
    &lt;p&gt;This is designed to be a language to teach compiler development with.&lt;/p&gt;
    &lt;p&gt;Meaning behind the name:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Titania is the wife of Oberon (Fairy King) in Shakespeare's A Midsummer Night's Dream&lt;/item&gt;
      &lt;item&gt;https://en.wikipedia.org/wiki/Titania_(A_Midsummer_Night%27s_Dream)&lt;/item&gt;
      &lt;item&gt;This is just a codename, and probably not final for this teaching language&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;module = "module" ident ";" [import_list] decl_sequence
         ["begin" stmt_sequence] "end" [";"].

import_list = "import" import_decl {"," import_decl} ";".
decl_sequence = ["const" {const_decl ";"}]
                ["type"  {type_decl  ";"}]
                ["var"   {var_decl   ";"}]
                [{proc_decl          ";"}].

const_decl = ident "=" const_expr.
type_decl = ident "="" struct_type.
var_decl = ident_list ":" type.

proc_decl = "proc" ident [formal_parameters] ";" proc_body.
proc_body = decl_sequence ["begin" stmt_sequence] ["return" expr] "end".


const_expr = expr.
expr = simple_expr {relation simple_expr}.

simple_expr = ["+" | "-"] unary_expr {add_operator unary_expr}.
unary_expr = ["+" | "-"] term.
term = factor {mul_operator factor}.

factor = integer | real | string | nil | true | false | set |
         "(" expr ")" | "not" expr | designator.

element = expr [".." expr].

ident_list = ident {"," ident}.
qual_ident = [ident "."] ident.

struct_type = array_type | record_type | pointer_type | proc_type.
array_type = "["" const_expr {"," const_expr} "]" type.
record_type = "record" ["(" qual_ident ")"] [field_list_sequence] "end".
pointer_type = "^" type.
proc_type = "proc" formal_parameters.
field_list = ident_list ":" type.
formal_parmeters = "(" [fp_section {";" fp_section}] [";"] ")".
formal_type = "[" "]" qual_ident.

stmt_sequence = stmt {";" stmt} [";"].
stmt = [assignment | proc_call | if_stmt | case_stmt | while_stmt | repeat_stmt | for_stmt ].

assignment = designator ":=" expr

if_stmt = "if" expr "then" stmt_sequence
          {"elseif" expr "then" stmt_sequence}
          ["else" stmt_sequence]
          "end".

case_stmt = "case" expr "of" case {"|" case} "end".
case = [case_label_list ":" stmt_sequence].
case_list = label_range {"," label_range}.
label_range = label [".." label].
label = integer | string | qual_ident.

while_stmt = "while" expr "do" stmt_sequence
             {"elseif" expr "then" stmt_sequence}
             "end".
repeat_stmt = "repeat" stmt_sequence "until" expr.
for_stmt = "for" ident ":=" expr "to" expr ["by" const_expr] "do" stmt_sequence "end".


designator = qual_ident {selector}.
selector = "." ident | "[" expr_list "]" | "^" | "(" qual_ident ")".
expr_list = expr {"," expr}.


add_operator = "+" | "-" | "xor" | "or".
mul_operator = "*" | "/" | "%"   | "and".
relation     = "=" | "&amp;lt;&amp;gt;" | "&amp;lt;" | "&amp;lt;=" | "&amp;gt;" | "&amp;gt;=" | "in" | "is".
&lt;/code&gt;
    &lt;code&gt;and    else    import  of      then   while
begin  elseif  in      or      to     xor
by     end     is      proc    true
case   false   module  record  type
const  for     nil     repeat  until
do     if      not     return  var
&lt;/code&gt;
    &lt;code&gt;+    .   (   )   =  &amp;lt;&amp;gt;
-    ,   [   ]   &amp;lt;  &amp;lt;=
*    ;   {   }   &amp;gt;  &amp;gt;=
/    |   :=  :   ..
%    ^
&lt;/code&gt;
    &lt;p&gt;Note: These will be added to as the compiler develops&lt;/p&gt;
    &lt;code&gt;abs(x)            - absolute value of
lsh(x, y)         - logical shift left
ash(x, y)         - arithmetic shift right
ror(x, y)         - rotate right
chr(i)            - convert int to char
ord(c)            - convert char to int
inc(x)            - x := x + 1
inc(x, y)         - x := x + y
dec(x)            - x := x - 1
dec(x, y)         - x := x - y
incl(x, y)        - include y in set x
excl(x, y)        - exclude y in set x
odd(x)            - x % 2 = 0
floor(x)          - round-down for real
ceil(x)           - round-up   for real
assert(cond)      - assert when cond is false
new(ptr)          - allocate memory
delete(ptr)       - free memory
addr(x)           - address of addressable memory
size_of(x)        - size of the type of 'x'
align_of(x)       - alignment of the type of 'x'
copy(dst, src, n) - non-overlapping memory copying from `src` to `dst` of `n` bytes
print(...)        - variadic print without newline
println(...)      - variadic print with newline
len(x)            - length of an array 'x'
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45243925</guid><pubDate>Sun, 14 Sep 2025 22:29:49 +0000</pubDate></item><item><title>Gentoo AI Policy</title><link>https://wiki.gentoo.org/wiki/Project:Council/AI_policy</link><description>&lt;doc fingerprint="5113f350feb360da"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Project:Council/AI policy&lt;/head&gt;&lt;p&gt;From Gentoo Wiki&lt;/p&gt; Jump to:navigation Jump to:search &lt;head rend="h2"&gt;The policy&lt;/head&gt;&lt;p&gt;Gentoo Council has voted on 2024-04-14 on the following policy:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;It is expressly forbidden to contribute to Gentoo any content that has been created with the assistance of Natural Language Processing artificial intelligence tools. This motion can be revisited, should a case been made over such a tool that does not pose copyright, ethical and quality concerns.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;This policy affects Gentoo contributions and the official Gentoo projects. It does not prohibit adding packages for AI-related software or software that is being developed with the help of such tools upstream.&lt;/p&gt;&lt;head rend="h2"&gt;Rationale&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;Copyright concerns. At this point, the regulations concerning copyright of generated contents are still emerging worldwide. Using such material could pose a danger of copyright violations, but it could also weaken Gentoo claims to copyright and void the guarantees given by copyleft licensing.&lt;/item&gt;&lt;item&gt;Quality concerns. Popular LLMs are really great at generating plausibly looking, but meaningless content. They are capable of providing good assistance if you are careful enough, but we can't really rely on that. At this point, they pose both the risk of lowering the quality of Gentoo projects, and of requiring an unfair human effort from developers and users to review contributions and detect the mistakes resulting from the use of AI.&lt;/item&gt;&lt;item&gt;Ethical concerns. The business side of AI boom is creating serious ethical concerns. Among them: &lt;list rend="ul"&gt;&lt;item&gt;Commercial AI projects are frequently indulging in blatant copyright violations to train their models.&lt;/item&gt;&lt;item&gt;Their operations are causing concerns about the huge use of energy and water.&lt;/item&gt;&lt;item&gt;The advertising and use of AI models has caused a significant harm to employees and reduction of service quality.&lt;/item&gt;&lt;item&gt;LLMs have been empowering all kinds of spam and scam efforts.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45244295</guid><pubDate>Sun, 14 Sep 2025 23:20:01 +0000</pubDate></item><item><title>Show HN: Dagger.js – A buildless, runtime-only JavaScript micro-framework</title><link>https://daggerjs.org</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245138</guid><pubDate>Mon, 15 Sep 2025 01:28:52 +0000</pubDate></item><item><title>For Good First Issue – A repository of social impact and open source projects</title><link>https://forgoodfirstissue.github.com/</link><description>&lt;doc fingerprint="7bd122672bfb268d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Committing to a better future&lt;/head&gt;
    &lt;p&gt;Lend your skills to an open source project focused on the Digital Public Goods (DPGs). From fighting climate change, to solving world hunger, your efforts will contribute to creating a better future for everyone. Together, we can drive positive and lasting contributions to the world, one commit at a time.&lt;lb/&gt;Explore a DPG repo below to get started.&lt;/p&gt;
    &lt;head rend="h2"&gt;Find a project&lt;/head&gt;
    &lt;p&gt;Augmentative and Alternative Communication (AAC) system with text-to-speech for the browser&lt;/p&gt;
    &lt;p&gt;A collection of tools for extracting FHIR resources and analytics services on top of that data.&lt;/p&gt;
    &lt;p&gt;The CHT Core Framework makes it faster to build responsive, offline-first digital health apps that equip health workers to provide better care in their communities. It is a central resource of the Community Health Toolkit.&lt;/p&gt;
    &lt;p&gt;The participatory democracy framework. A generator and multiple gems made with Ruby on Rails&lt;/p&gt;
    &lt;p&gt;Web application for management and data entry&lt;/p&gt;
    &lt;p&gt;Documents added by volunteer contributors and historically imported from TOSBack.org. Maintenance is collaborative and volunteer-based.&lt;/p&gt;
    &lt;p&gt;PolicyEngine's free web app for computing the impact of public policy.&lt;/p&gt;
    &lt;p&gt;Graphical Java application for managing BibTeX and BibLaTeX (.bib) databases&lt;/p&gt;
    &lt;p&gt;The CYF Curriculum&lt;/p&gt;
    &lt;p&gt;ODK Collect is an Android app for filling out forms. It's been used to collect billions of data points in challenging environments around the world. Contribute and make the world a better place! ✨📋✨&lt;/p&gt;
    &lt;p&gt;OpenFn/Lightning ⚡️ is the newest version of the OpenFn DPG and provides a web UI to visually manage complex workflow automation projects.&lt;/p&gt;
    &lt;p&gt;Mautic: Open Source Marketing Automation Software.&lt;/p&gt;
    &lt;p&gt;Volunteer management system for nonprofit CASA, which serves foster youth in counties across America.&lt;/p&gt;
    &lt;p&gt;Source code of the X-Road® data exchange layer software&lt;/p&gt;
    &lt;p&gt;ODK Central is a server that is easy to use, very fast, and stuffed with features that make data collection easier. Contribute and make the world a better place! ✨🗄✨&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245313</guid><pubDate>Mon, 15 Sep 2025 02:02:39 +0000</pubDate></item><item><title>Which NPM package has the largest version number?</title><link>https://adamhl.dev/blog/largest-number-in-npm-package/</link><description>&lt;doc fingerprint="2b5d6a0d8d70ae19"&gt;
  &lt;main&gt;
    &lt;p&gt;I was recently working on a project that uses the AWS SDK for JavaScript. When updating the dependencies in said project, I noticed that the version of that dependency was &lt;code&gt;v3.888.0&lt;/code&gt;. Eight hundred eighty eight. That’s a big number as far as versions go.&lt;/p&gt;
    &lt;p&gt;That got me thinking: I wonder what package in the npm registry has the largest number in its version. It could be a major, minor, or patch version, and it doesn’t have to be the latest version of the package. In other words, out of the three numbers in &lt;code&gt;&amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;.&amp;lt;patch&amp;gt;&lt;/code&gt; for each version for each package, what is the largest number I can find?&lt;/p&gt;
    &lt;p&gt;TL;DR? Jump to the results to see the answer.&lt;/p&gt;
    &lt;head rend="h2"&gt;The npm API&lt;/head&gt;
    &lt;p&gt;Obviously npm has some kind of API, so it shouldn’t be too hard to get a list of all… 3,639,812 packages. Oh. That’s a lot of packages. Well, considering npm had 374 billion package downloads in the past month, I’m sure they wouldn’t mind me making a few million HTTP requests.&lt;/p&gt;
    &lt;p&gt;Doing a quick search for “npm api” leads me to a readme in the npm/registry repo on GitHub. There’s a &lt;code&gt;/-/all&lt;/code&gt; endpoint listed in the table of contents which seems promising. That section doesn’t actually exist in the readme, but maybe it still works?&lt;/p&gt;
    &lt;p&gt;Whelp, maybe npm packages have an ID and I can just start at 1 and count up? It looks like packages have an &lt;code&gt;_id&lt;/code&gt; field… never mind, the &lt;code&gt;_id&lt;/code&gt; field is the package name. Okay, let’s try to find something else.&lt;/p&gt;
    &lt;p&gt;A little more digging brings me to this GitHub discussion about the npm replication API. So npm replicates package info in CouchDB at &lt;code&gt;https://replicate.npmjs.com&lt;/code&gt;, and conveniently, they support the &lt;code&gt;_all_docs&lt;/code&gt; endpoint. Let’s give that a try:&lt;/p&gt;
    &lt;p&gt;Those are some interesting package names. Looks like this data is paginated and by default I get 1,000 packages at a time. When I write the final script, I can set the &lt;code&gt;limit&lt;/code&gt; query parameter to the max of 10,000 to make pagination a little less painful.&lt;/p&gt;
    &lt;p&gt;Fortunately, the CouchDB docs have a guide for pagination, and it looks like it’s as simple as using the &lt;code&gt;skip&lt;/code&gt; query parameter.&lt;/p&gt;
    &lt;p&gt;Never mind. According to the GitHub discussion linked above, &lt;code&gt;skip&lt;/code&gt; is no longer supported. The “Paging (Alternate Method)” section of the same page says that I can use &lt;code&gt;startkey_docid&lt;/code&gt; instead. If I grab the &lt;code&gt;id&lt;/code&gt; of the last row, I should be able to use that to return the next set of rows. Fun fact: The 1000th package (alphabetically) on npm is &lt;code&gt;03-webpack-number-test&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Nice. Also, another &lt;code&gt;3628102 - 3628088 = 14&lt;/code&gt; packages have been published in the ~15 minutes since I ran the last query.&lt;/p&gt;
    &lt;p&gt;Now, there’s one more piece of the puzzle to figure out. How do I get all the versions for a given package? Unfortunately, it doesn’t seem like I can get package version information along with the base info returned by &lt;code&gt;_all_docs&lt;/code&gt;. I have to separately fetch each package’s metadata from &lt;code&gt;https://registry.npmjs.org/&amp;lt;package_id&amp;gt;&lt;/code&gt;. Let’s see what good ol’ trusty &lt;code&gt;03-webpack-number-test&lt;/code&gt; looks like:&lt;/p&gt;
    &lt;p&gt;Alright, I have everything I need. Now I just need to write a bash script that— just kidding. A wise programmer once said, “if your shell script is more than 10 lines, it shouldn’t be a shell script” (that was me, I said that). I like TypeScript, so let’s use that.&lt;/p&gt;
    &lt;p&gt;The biggest bottleneck is going to be waiting on the &lt;code&gt;GET&lt;/code&gt;s for each package’s metadata. My plan is this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Grab all the package IDs from the replication API and save that data to a file (I don’t want to have to refetch everything if the something goes wrong later in the script)&lt;/item&gt;
      &lt;item&gt;Fetch package data in batches so we’re not just doing 1 HTTP request at a time&lt;/item&gt;
      &lt;item&gt;Save the package data to a file (again, hopefully I only have to fetch everything once)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once I have all the package data, I can answer the original question of “largest number in version” and look at a few other interesting things.&lt;/p&gt;
    &lt;p&gt;(A few hours and many iterations later…)&lt;/p&gt;
    &lt;p&gt;See the script section at the end if you want to see what it looks like.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;Some stats:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Time to fetch all ~3.6 million package IDs: A few minutes&lt;/item&gt;
      &lt;item&gt;Time to fetch version data for each one of those packages: ~12 hours (yikes)&lt;/item&gt;
      &lt;item&gt;Packages fetched per second: ~84 packages/s&lt;/item&gt;
      &lt;item&gt;Size of &lt;code&gt;package-ids.json&lt;/code&gt;: ~78MB&lt;/item&gt;
      &lt;item&gt;Size of &lt;code&gt;package-data.json&lt;/code&gt;: ~886MB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And the winner is… (not really) latentflip-test at version &lt;code&gt;1000000000000000000.1000000000000000000.1000000000000000000&lt;/code&gt;. And no, there haven’t actually been one quintillion major versions of this package published. Disappointing, I know.&lt;/p&gt;
    &lt;p&gt;Well, I feel like that shouldn’t count. I think we can do better and find a “real” package that actually follows semantic versioning. I think a better question to ask is this:&lt;/p&gt;
    &lt;p&gt;For packages that follow semantic versioning, which package has the largest number from &lt;code&gt;&amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;.&amp;lt;patch&amp;gt;&lt;/code&gt; in any of its versions?&lt;/p&gt;
    &lt;p&gt;So, what does it mean to “follow semantic versioning”? Should we “disqualify” a package for skipping a version number? In this case, I think we’ll just say that a package has to have more versions published than the largest number we find for that package. For example, a package with a version of &lt;code&gt;1.888.0&lt;/code&gt; will have had at least 888 versions published if it actually followed semver.&lt;/p&gt;
    &lt;p&gt;Before we get to the real winner, here are the top 10 packages by total number of versions published:&lt;/p&gt;
    &lt;p&gt;Top 10 packages that (probably) follow semver by largest number in one of its versions:&lt;/p&gt;
    &lt;p&gt;So it seems like the winner is electron-remote-control, right? Unfortunately, I’m not going to count that either. It only has so many versions because of a misconfigured GitHub action that ran every hour… for a while.&lt;/p&gt;
    &lt;p&gt;I manually went down the above list, disqualifying any packages that had similar issues. I also checked that “new” versions actually differed from previous versions in terms of content. Overall, I looked for a package that was actually publishing new versions on purpose with some kind of change to the package content.&lt;/p&gt;
    &lt;p&gt;The real winner (#20 on the list) is: @wppconnect/wa-version at version &lt;code&gt;1.5.2219&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;What you do with this extremely important and useful information is up to you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245678</guid><pubDate>Mon, 15 Sep 2025 03:03:18 +0000</pubDate></item><item><title>Decentralized YouTube alternative adds livestream scheduling in new release</title><link>https://news.itsfoss.com/peertube-7-3/</link><description>&lt;doc fingerprint="f9c2fa0dd99ffe84"&gt;
  &lt;main&gt;
    &lt;p&gt;PeerTube is a decentralized alternative to YouTube that doesn't believe in harvesting user data and pushing people into echo chambers via a proprietary algorithm. Built on open standards and federation, it lets communities host and share video without depending on a central server.&lt;/p&gt;
    &lt;p&gt;Earlier this year, the project asked for donations to improve its mobile app and help them reach certain funding goals. The developers made it clear that improving the mobile experience was a key priority, and community backing has helped fund ongoing development.&lt;/p&gt;
    &lt;p&gt;Now, PeerTube has shipped a fresh release.&lt;/p&gt;
    &lt;head rend="h2"&gt;🆕 PeerTube 7.3: What's New?&lt;/head&gt;
    &lt;p&gt;Admins of PeerTube instances will be glad to learn that the cluttered horizontal menu has been replaced with a clean, easy-to-navigate side panel. This redesign makes accessing settings, customization, and user management much faster, with a new "Logo" page for configuring icons and logos displayed on the platform.&lt;/p&gt;
    &lt;p&gt;Similarly, the new admin onboarding wizard (shown above) guides instance owners through setup, making it easy to configure colors, platform type, logos, favicons, and banners. Basically, the left-hand panel keeps everything organized, while the wizard ensures nothing important is missed during initial setup.&lt;/p&gt;
    &lt;p&gt;Email notifications have also received a major upgrade. PeerTube now supports multilingual emails, with French and Chinese available right now. Volunteers are invited to help translate both the platform and its emails via Weblate.&lt;/p&gt;
    &lt;p&gt;Live streaming gets a boost too. Users can now schedule live streams in advance, allowing viewers to see upcoming events on the channel and live stream pages. This is a surefire way to improve community engagement and gives creators a clear way to plan broadcasts.&lt;/p&gt;
    &lt;p&gt;Playlist management has also been improved. Admins can reorder public playlists, set default video licenses, visibility, and comment policies, making it easier to organize content and maintain consistent settings across a channel.&lt;/p&gt;
    &lt;head rend="h2"&gt;📥 Get PeerTube&lt;/head&gt;
    &lt;p&gt;The latest release and full changelog are available on GitHub. Detailed upgrade instructions and installation guides can be found in the official documentation.&lt;/p&gt;
    &lt;p&gt;- Even the biggest players in the Linux world don't care about desktop Linux users. We do.&lt;/p&gt;
    &lt;p&gt;- We don't put informational content behind paywall. Your support keeps it open for everyone. Think of it like 'pay it forward'.&lt;/p&gt;
    &lt;p&gt;- Don't like ads? With the Plus membership, you get an ad-free reading experience.&lt;/p&gt;
    &lt;p&gt;- When millions of AI-generated content is being published daily, you read and learn from real human Linux users.&lt;/p&gt;
    &lt;p&gt;- It costs just $2 a month, less than the cost of your favorite burger.&lt;/p&gt;
    &lt;p&gt;Become a Plus Member today and join over 300 people in supporting our work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245802</guid><pubDate>Mon, 15 Sep 2025 03:27:34 +0000</pubDate></item><item><title>Language Models Pack Billions of Concepts into 12,000 Dimensions</title><link>https://nickyoder.com/johnson-lindenstrauss/</link><description>&lt;doc fingerprint="150b027d080f93db"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Beyond Orthogonality: How Language Models Pack Billions of Concepts into 12,000 Dimensions&lt;/head&gt;
    &lt;p&gt;In a recent 3Blue1Brown video series on transformer models, Grant Sanderson posed a fascinating question: How can a relatively modest embedding space of 12,288 dimensions (GPT-3) accommodate millions of distinct real-world concepts?&lt;/p&gt;
    &lt;p&gt;The answer lies at the intersection of high-dimensional geometry and a remarkable mathematical result known as the Johnson-Lindenstrauss lemma. While exploring this question, I discovered something unexpected that led to an interesting collaboration with Grant and a deeper understanding of vector space geometry.&lt;/p&gt;
    &lt;p&gt;The key insight begins with a simple observation: while an N-dimensional space can only hold N perfectly orthogonal vectors, relaxing this constraint to allow for "quasi-orthogonal" relationships (vectors at angles of, say, 85-95 degrees) dramatically increases the space's capacity. This property is crucial for understanding how language models can efficiently encode semantic meaning in relatively compact embedding spaces.&lt;/p&gt;
    &lt;p&gt;In Grant's video, he demonstrated this principle with an experiment attempting to fit 10,000 unit vectors into a 100-dimensional space while maintaining near-orthogonal relationships. The visualization suggested success, showing angles clustered between 89-91 degrees. However, when I implemented the code myself, I noticed something interesting about the optimization process.&lt;/p&gt;
    &lt;p&gt;The original loss function was elegantly simple:&lt;/p&gt;
    &lt;p&gt; loss = (dot_products.abs()).relu().sum()&lt;lb/&gt;While this loss function appears perfect for an unbounded ℝᴺ space, it encounters two subtle but critical issues when applied to vectors constrained to a high-dimensional unit sphere:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The Gradient Trap: The dot product between vectors is the cosine of the angle between them, and the gradient is the sine of this angle. This creates a perverse incentive structure: when vectors approach the desired 90-degree relationship, the gradient (sin(90°) = 1.0) strongly pushes toward improvement. However, when vectors drift far from the goal (near 0° or 180°), the gradient (sin(0°) ≈ 0) vanishes—effectively trapping these badly aligned vectors in their poor configuration.&lt;/item&gt;
      &lt;item&gt;The 99% Solution: The optimizer discovered a statistically favorable but geometrically perverse solution. For each vector, it would be properly orthogonal to 9,900 out of 9,999 other vectors while being nearly parallel to just 99. This configuration, while clearly not the intended outcome, actually represented a global minimum for the loss function—mathematically similar to taking 100 orthogonal basis vectors and replicating each one roughly 100 times.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This stable configuration was particularly insidious because it satisfied 99% of the constraints while being fundamentally different from the desired constellation of evenly spaced, quasi-orthogonal vectors. To address this, I modified the loss function to use an exponential penalty that increases aggressively as dot products grow:&lt;/p&gt;
    &lt;p&gt;loss = exp(20*dot_products.abs()**2).sum() (Full code here)&lt;/p&gt;
    &lt;p&gt;This change produced the desired behavior, though with a revealing result: the maximum achievable pairwise angle was around 76.5 degrees, not 89 degrees.&lt;/p&gt;
    &lt;p&gt;This discovery led me down a fascinating path exploring the fundamental limits of vector packing in high-dimensional spaces, and how these limits relate to the Johnson-Lindenstrauss lemma.&lt;/p&gt;
    &lt;p&gt;When I shared these findings with Grant, his response exemplified the collaborative spirit that makes the mathematics community so rewarding. He not only appreciated the technical correction but invited me to share these insights with the 3Blue1Brown audience. This article is that response, expanded to explore the broader implications of these geometric properties for machine learning and dimensionality reduction.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Johnson-Lindenstrauss Lemma: A Geometric Guarantee&lt;/head&gt;
    &lt;p&gt;At its core, the Johnson-Lindenstrauss (JL) lemma makes a remarkable promise: you can project points from an arbitrarily high-dimensional space into a surprisingly low-dimensional space while preserving their relative distances with high probability. What makes this result particularly striking is that the required dimensionality of the low-dimensional space grows only logarithmically with the number of points you want to project.&lt;/p&gt;
    &lt;p&gt;Formally, the lemma states that for an error factor ε (between 0 and 1), and any set of N points in a high-dimensional space, there exists a projection into k dimensions where for any two points u and v in the original space, their projections f(u) and f(v) in the lower dimensional space satisfy:&lt;/p&gt;
    &lt;p&gt;(1 - ε)||u - v||² ≤ ||f(u) - f(v)||² ≤ (1 + ε)||u - v||²&lt;/p&gt;
    &lt;p&gt;The number of dimensions (k) required to guarantee these error bounds is given by:&lt;/p&gt;
    &lt;p&gt;k ≥ O(log(N)/ε²)&lt;/p&gt;
    &lt;p&gt;The "Big O" notation can be replaced with a concrete constant C:&lt;/p&gt;
    &lt;p&gt;k ≥ (C/ε²) * log(N)&lt;/p&gt;
    &lt;p&gt;Where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;k is the target dimension&lt;/item&gt;
      &lt;item&gt;N is the number of points&lt;/item&gt;
      &lt;item&gt;ε is the maximum allowed distortion&lt;/item&gt;
      &lt;item&gt;C is a constant that determines the probability of success&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While most practitioners use values between 4 and 8 as a conservative choice for random projections, the optimal value of C remains an open question. As we'll see in the experimental section, engineered projections can achieve much lower values of C, with profound implications for embedding space capacity.&lt;/p&gt;
    &lt;p&gt;The fascinating history of this result speaks to the interconnected nature of mathematical discovery. Johnson and Lindenstrauss weren't actually trying to solve a dimensionality reduction problem – they stumbled upon this property while working on extending Lipschitz functions in Banach spaces. Their 1984 paper turned out to be far more influential in computer science than in their original domain.&lt;/p&gt;
    &lt;head rend="h1"&gt;From Theory to Practice: Two Domains of Application&lt;/head&gt;
    &lt;p&gt;The JL lemma finds practical application in two distinct but equally important domains:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Dimensionality Reduction: Consider an e-commerce platform like Amazon, where each customer's preferences might be represented by a vector with millions of dimensions (one for each product). Direct computation with such vectors would be prohibitively expensive. The JL lemma tells us we can project this data into a much lower-dimensional space – perhaps just a thousand dimensions – while preserving the essential relationships between customers. This makes previously intractable computations feasible on a single GPU, enabling real-time customer relationship management and inventory planning.&lt;/item&gt;
      &lt;item&gt;Embedding Space Capacity: This application is more subtle but equally powerful. Rather than actively projecting vectors, we're interested in understanding how many distinct concepts can naturally coexist in a fixed-dimensional space. This is where our experiments provide valuable insight into the practical limits of embedding space capacity.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's consider what we mean by "concepts" in an embedding space. Language models don't deal with perfectly orthogonal relationships – real-world concepts exhibit varying degrees of similarity and difference. Consider these examples of words chosen at random:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Archery" shares some semantic space with "precision" and "sport"&lt;/item&gt;
      &lt;item&gt;"Fire" overlaps with both "heat" and "passion"&lt;/item&gt;
      &lt;item&gt;"Gelatinous" relates to physical properties and food textures&lt;/item&gt;
      &lt;item&gt;"Southern-ness" encompasses culture, geography, and dialect&lt;/item&gt;
      &lt;item&gt;"Basketball" connects to both athletics and geometry&lt;/item&gt;
      &lt;item&gt;"Green" spans color perception and environmental consciousness&lt;/item&gt;
      &lt;item&gt;"Altruistic" links moral philosophy with behavioral patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The beauty of high-dimensional spaces is that they can accommodate these nuanced, partial relationships while maintaining useful geometric properties for computation and inference.&lt;/p&gt;
    &lt;head rend="h1"&gt;Empirical Investigation of Embedding Capacity&lt;/head&gt;
    &lt;p&gt;When we move from random projections to engineered solutions, the theoretical bounds for C of the JL lemma become surprisingly conservative. While a Hadamard matrix transformation with random elements can reliably achieve a C value between 2.5 and 4 in a single pass, our GPU experiments suggest even more efficient arrangements are possible through optimization.&lt;/p&gt;
    &lt;p&gt;To explore these limits, I implemented a series of experiments projecting standard basis vectors into spaces of varying dimensionality. Using GPU acceleration, I tested combinations of N (number of vectors) up to 30,000 and k (embedding dimensions) up to 10,000, running each optimization for 50,000 iterations. The results reveal some fascinating patterns:&lt;/p&gt;
    &lt;p&gt;Several key observations emerge from this data:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The value of C initially rises with N, reaching a maximum around ~0.9 (notably always below 1.0)&lt;/item&gt;
      &lt;item&gt;After peaking, C begins a consistent downward trend&lt;/item&gt;
      &lt;item&gt;At high ratios of N to K, we observe C values trend below 0.2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This behavior likely relates to an interesting property of high-dimensional geometry: as dimensionality increases, sphere packing becomes more efficient when the spheres are small relative to the unit sphere. This suggests that our observed upper bounds on C might still be conservative for very large numbers of concepts.&lt;/p&gt;
    &lt;head rend="h1"&gt;Practical Implications for Language Models&lt;/head&gt;
    &lt;p&gt;Let's consider three scenarios for the constant C:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;C = 4: A conservative choice for random projections with Hadamard matrices&lt;/item&gt;
      &lt;item&gt;C = 1: A likely upper bound for optimized or emergent embeddings&lt;/item&gt;
      &lt;item&gt;C = 0.2: A value suggested by our experiments for very large spaces&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The implications of these geometric properties are staggering. Let's consider a simple way to estimate how many quasi-orthogonal vectors can fit in a k-dimensional space. If we define F as the degrees of freedom from orthogonality (90° - desired angle), we can approximate the number of vectors as:&lt;/p&gt;
    &lt;p&gt;Vectors ≈ 10^(k * F² / 1500)&lt;/p&gt;
    &lt;p&gt;where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;k is the embedding dimension&lt;/item&gt;
      &lt;item&gt;F is the degrees of "freedom" from orthogonality (e.g., F = 3 for 87° angles)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Applying this to GPT-3's 12,288-dimensional embedding space reveals its extraordinary capacity:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;At 89° (F = 1): approximately 10^8 vectors&lt;/item&gt;
      &lt;item&gt;At 88° (F = 2): approximately 10^32 vectors&lt;/item&gt;
      &lt;item&gt;At 87° (F = 3): approximately 10^73 vectors&lt;/item&gt;
      &lt;item&gt;At 85° (F = 5): more than 10^200 vectors&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To put this in perspective, even the conservative case of 86° angles provides capacity far exceeding the estimated number of atoms in the observable universe (~10^80). This helps explain how language models can maintain rich, nuanced relationships between millions of concepts while working in relatively modest embedding dimensions.&lt;/p&gt;
    &lt;head rend="h1"&gt;Practical Applications and Future Directions&lt;/head&gt;
    &lt;p&gt;The insights from this investigation have two major practical implications:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Efficient Dimensionality Reduction: The robustness of random projections, particularly when combined with Hadamard transformations (or BCH coding), provides a computationally efficient way to work with high-dimensional data. No complex optimization required – the mathematics of high-dimensional spaces does the heavy lifting for us.&lt;/item&gt;
      &lt;item&gt;Embedding Space Design: Understanding the true capacity of high-dimensional spaces helps explain how transformer models can maintain rich, nuanced representations of language in relatively compact embeddings. Concepts like "Canadian," "morose," "Hitchcockian," "handsome," "whimsical," and "Muppet-like" can all find their place in the geometry while preserving their subtle relationships to each other.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This research suggests that current embedding dimensions (1,000-20,000) provide more than adequate capacity for representing human knowledge and reasoning. The challenge lies not in the capacity of these spaces but in learning the optimal arrangement of concepts within them.&lt;/p&gt;
    &lt;p&gt;My code for Hadamard and optimized projections.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;What began as an investigation into a subtle optimization issue has led us to a deeper appreciation of high-dimensional geometry and its role in modern machine learning. The Johnson-Lindenstrauss lemma, discovered in a different context nearly four decades ago, continues to provide insight into the foundations of how we can represent meaning in mathematical spaces.&lt;/p&gt;
    &lt;p&gt;I want to express my sincere gratitude to Grant Sanderson and the 3Blue1Brown channel. His work consistently inspires deeper exploration of mathematical concepts, and his openness to collaboration exemplifies the best aspects of the mathematical community. The opportunity to contribute to this discussion has been both an honor and a genuine pleasure.&lt;/p&gt;
    &lt;p&gt;I would also like to thank Suman Dev for his help in optimizing the GPU code.&lt;/p&gt;
    &lt;p&gt;This was enormously fun to research and write.&lt;/p&gt;
    &lt;p&gt;Nick Yoder&lt;/p&gt;
    &lt;head rend="h3"&gt;&lt;lb/&gt;Further Reading&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Sphere Packings, Lattices and Groups by Conway and Sloane&lt;/item&gt;
      &lt;item&gt;Database-friendly random projections: Johnson-Lindenstrauss with binary coins by Achlioptas&lt;/item&gt;
      &lt;item&gt;Hadamard Matrices, Sequences, and Block Designs by Seberry and Yamada&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245948</guid><pubDate>Mon, 15 Sep 2025 03:54:20 +0000</pubDate></item><item><title>A qualitative analysis of pig-butchering scams</title><link>https://arxiv.org/abs/2503.20821</link><description>&lt;doc fingerprint="7c9cd00988b1068b"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Cryptography and Security&lt;/head&gt;&lt;p&gt; [Submitted on 25 Mar 2025 (v1), last revised 24 May 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:"Hello, is this Anna?": Unpacking the Lifecycle of Pig-Butchering Scams&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Pig-butchering scams have emerged as a complex form of fraud that combines elements of romance, investment fraud, and advanced social engineering tactics to systematically exploit victims. In this paper, we present the first qualitative analysis of pig-butchering scams, informed by in-depth semi-structured interviews with $N=26$ victims. We capture nuanced, first-hand accounts from victims, providing insight into the lifecycle of pig-butchering scams and the complex emotional and financial manipulation involved. We systematically analyze each phase of the scam, revealing that perpetrators employ tactics such as staged trust-building, fraudulent financial platforms, fabricated investment returns, and repeated high-pressure tactics, all designed to exploit victims' trust and financial resources over extended periods. Our findings reveal an organized scam lifecycle characterized by emotional manipulation, staged financial exploitation, and persistent re-engagement efforts that amplify victim losses. We also find complex psychological and financial impacts on victims, including heightened vulnerability to secondary scams. Finally, we propose actionable intervention points for social media and financial platforms to curb the prevalence of these scams and highlight the need for non-stigmatizing terminology to encourage victims to report and seek assistance.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Rajvardhan Oak [view email]&lt;p&gt;[v1] Tue, 25 Mar 2025 23:15:48 UTC (342 KB)&lt;/p&gt;&lt;p&gt;[v2] Sat, 24 May 2025 07:36:41 UTC (343 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245962</guid><pubDate>Mon, 15 Sep 2025 03:58:23 +0000</pubDate></item><item><title>Starlink is currently experiencing a service outage</title><link>https://www.starlink.com/</link><description>&lt;doc fingerprint="b09b35d0b115a941"&gt;
  &lt;main&gt;
    &lt;p&gt;Residential&lt;/p&gt;
    &lt;p&gt;Connect at home&lt;/p&gt;
    &lt;p&gt;Starting at $80/mo for service&lt;/p&gt;
    &lt;p&gt;Roam&lt;/p&gt;
    &lt;p&gt;Connect while traveling anywhere in over 100 markets&lt;/p&gt;
    &lt;p&gt;Starting at $50/mo for service&lt;/p&gt;
    &lt;p&gt;Streaming, video calls, online gaming, remote working and more are now possible in even the most remote locations thanks to the world’s most advanced internet system.&lt;/p&gt;
    &lt;p&gt;Starlink Mini is a compact, portable kit that can easily fit in a backpack, designed to provide high-speed, low-latency internet on the go. It includes a built-in WiFi router, lower power consumption, DC power input, and max download speeds over 100 Mbps.&lt;/p&gt;
    &lt;p&gt;1 PLUG IT IN&lt;/p&gt;
    &lt;p&gt;2 POINT AT SKY&lt;/p&gt;
    &lt;p&gt;Starlink requires an unobstructed view of the sky. Download the Starlink app to determine your best install location.&lt;/p&gt;
    &lt;p&gt;Download for android&lt;/p&gt;
    &lt;p&gt;Starlink offers flexible service plans everywhere. Check availability by entering your address here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45246229</guid><pubDate>Mon, 15 Sep 2025 04:51:29 +0000</pubDate></item><item><title>Americans Crushed by Auto Loans as Defaults and Repossessions Surge</title><link>https://www.carscoops.com/2025/09/auto-loan-delinquencies-are-off-the-dial-and-even-prime-borrowers-are-struggling/</link><description>&lt;doc fingerprint="63cea99f4fe3e6b1"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Auto loan debt in America now sits at a shocking $1.66 trillion.&lt;/item&gt;
      &lt;item&gt;Delinquencies, defaults, and repossessions are skyrocketing.&lt;/item&gt;
      &lt;item&gt;Subprime delinquency is worse than in the 2008 financial crisis.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Many Americans love the feeling of driving a new car, but the price of that thrill is pushing household budgets to the edge. Auto loan delinquencies are spiraling, the nation now owes a staggering $1.66 trillion in auto loans, and some figures show scary similarities to the period right before the 2008 financial crash.&lt;/p&gt;
    &lt;p&gt;Also: One In Four Trade-Ins Are Now Underwater And It’s Getting Worse&lt;/p&gt;
    &lt;p&gt;That’s according to a new report titled “Driven to Default: The Economy-Wide Risks of Rising Auto Loan Delinquencies” from the Consumer Federation of America (CFA). It describes auto finance in the US as being “at breaking point,” and criticizes Congress and the country’s federal watchdogs for stepping back, despite evidence showing they’re needed more than ever to protect buyers from unscrupulous dealers.&lt;/p&gt;
    &lt;p&gt;Crushing Monthly Bills&lt;/p&gt;
    &lt;p&gt;One of the reasons owners are struggling to keep their heads above water is the high cost of monthly car payments, caused in part by high interest rates. Figures show the typical monthly payment is $745 and 20 percent of buyers are saddled with monthly bills of at least $1,000. Things could get worse quickly because the $7,500 EV tax credit is due to disappear imminently.&lt;/p&gt;
    &lt;p&gt;And this time it’s not just subprime borrowers who are feeling the heat. Car buyers with above-average credit scores are twice as likely to fall behind on payments as they were before the pandemic. Younger buyers are hitting the payment skids in high numbers and the repossession rate across all age groups jumped by 43 percent between 2022 and 2024, according to Cox data.&lt;/p&gt;
    &lt;p&gt;A Wider Warning Sign&lt;/p&gt;
    &lt;p&gt;Moreover, the CFA warns that we should be concerned about more than a few cars getting repossessed because people haven’t kept up with payments. It says Americans have a tendency to prioritize their car bills over other household and living expenses, meaning the delinquency rates could be pointing to much more widespread and significant problems across the US economy.&lt;/p&gt;
    &lt;p&gt;“Now is the time for policymakers to take a hard look at the auto lending market to call out exploitative practices that raise prices and require our federal regulators to stop sleepwalking their way through this crisis while Americans suffer,” the organization suggests.&lt;/p&gt;
    &lt;p&gt;Personal Choices, Public Consequences&lt;/p&gt;
    &lt;p&gt;Still, there’s a question hanging over this: do drivers really need lawmakers to intervene, or is part of the solution simply about making different choices? To us, there’s an obvious way to avoid this mess, and it’s to be honest with yourself about your financial situation and buy an older car that’s been looked after. I broke my lease car habit five years ago and haven’t looked back since. But hey, whatever rocks your boat, right?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45246247</guid><pubDate>Mon, 15 Sep 2025 04:56:24 +0000</pubDate></item></channel></rss>