<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 17 Jan 2026 21:35:53 +0000</lastBuildDate><item><title>East Germany balloon escape</title><link>https://en.wikipedia.org/wiki/East_Germany_balloon_escape</link><description>&lt;doc fingerprint="be46c17b47664bf8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;East Germany balloon escape&lt;/head&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Native name&lt;/cell&gt;&lt;cell&gt;Die Ballonflucht&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Date&lt;/cell&gt;&lt;cell&gt;16 September 1979&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Time&lt;/cell&gt;&lt;cell&gt;02:00 am (approximate)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Duration&lt;/cell&gt;&lt;cell&gt;25 minutes&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Location&lt;/cell&gt;&lt;cell&gt;Oberlemnitz, East Germany&lt;p&gt;(takeoff)&lt;/p&gt;&lt;p&gt;Naila, West Germany&lt;/p&gt;&lt;p&gt;(landing)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Coordinates&lt;/cell&gt;&lt;cell&gt;50°28′59″N 11°35′29″E / 50.48306°N 11.59139°E[1]&lt;p&gt;(takeoff)&lt;/p&gt;&lt;p&gt;50°19′52.7″N 11°40′13.1″E / 50.331306°N 11.670306°E[1]&lt;/p&gt;&lt;p&gt;(landing)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Organised by&lt;/cell&gt;&lt;cell&gt;Peter Strelzyk &amp;amp; family&lt;p&gt;Günter Wetzel &amp;amp; family&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Participants&lt;/cell&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Outcome&lt;/cell&gt;&lt;cell&gt;Successful escape to West Germany&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Non-fatal injuries&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;On 16 September 1979, eight people from two families escaped from East Germany by crossing the border into West Germany at night in a homemade hot air balloon. The unique feat was the result of over a year and a half of preparations involving three different balloons, various modifications, and a first, unsuccessful attempt. The failed attempt alerted the East German authorities to the plot, but the police were unable to identify the escapees before their second, successful flight two months later.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;[edit]&lt;p&gt;East Germany, then part of the Eastern Bloc, was separated from West Germany in the Western Bloc by the inner German border and the Berlin Wall, which were heavily fortified with watchtowers, land mines, armed soldiers, and various other measures to prevent illegal crossings. East German border troops were instructed to prevent defection to West Germany by all means, including lethal force (Schießbefehl; "order to fire").[2]&lt;/p&gt;&lt;p&gt;Peter Strelzyk (1942–2017), an electrician and former East German Air Force mechanic, and Günter Wetzel (born 1955), a bricklayer by trade,[3] were colleagues at a local plastics factory.[4] Friends for four years, they shared a desire to flee the country and began discussing ways to get across the border. On 7 March 1978, they agreed to plan an escape.[5] They considered building a helicopter but quickly realized they would be unable to acquire an engine capable of powering such a craft. They then decided to explore the idea of constructing a hot air balloon,[6] having been inspired by a television program about ballooning.[3] An alternate account is that a relative shared a magazine article about the International Balloon Festival in Albuquerque, New Mexico.[5]&lt;/p&gt;&lt;head rend="h2"&gt;Construction&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel began research into balloons. Their plan was to escape with their wives and a total of four children (aged 2 to 15). They calculated the weight of the eight passengers and the craft itself to be around 750 kilograms (1,650 lb). Subsequent calculations determined a balloon capable of lifting this weight would need to hold 2,000 cubic metres (71,000 cu ft) of air heated to 100 °C (212 °F). The next calculation was the amount of material needed for the balloon, estimated to be 800 square metres (8,600 sq ft).[6]&lt;/p&gt;&lt;p&gt;The pair lived in Pößneck, a small town of about 20,000 where large quantities of cloth could not be obtained without raising attention. They tried neighbouring towns of Rudolstadt, Saalfeld, and Jena without success.[7] They travelled 50 km (31 mi) to Gera, where they purchased 1-metre-wide (3 ft 3 in) rolls of cotton cloth totalling 850 metres (2,790 ft) in length at a department store after telling the astonished clerk that they needed the large quantity of material to use as tent lining for their camping club.[6][7]&lt;/p&gt;&lt;p&gt;Wetzel spent two weeks sewing the cloth into a balloon-shaped bag, 15 metres (49 ft) wide by 20 metres (66 ft) long, on a 40-year-old manually operated sewing machine. Strelzyk spent the time building the gondola and burner assembly. The gondola was made from an iron frame, sheet metal floor, and clothesline run around the perimeter every 150 millimetres (5.9 in) for the sides. The burner was made using two 11-kilogram (24 lb) bottles of liquid propane household gas, hoses, water pipe, a nozzle, and a piece of stove pipe.[6]&lt;/p&gt;&lt;head rend="h2"&gt;First test&lt;/head&gt;[edit]&lt;p&gt;The team was ready to test the craft in April 1978. After days of searching, they found a suitable secluded forest clearing near Ziegenrück, 10 km (6.2 mi) from the border and 30 km (19 mi) from Pößneck. After lighting the burner one night, they failed to inflate the balloon. They thought the problem might stem from the fact that they had laid the balloon on the ground. After weeks of additional searching, they found a 25-metre (82 ft) cliff at a rock quarry where they could suspend the balloon vertically before inflation, but that also proved unsuccessful.[6]&lt;/p&gt;&lt;p&gt;The pair then decided to fill the bag with ambient-temperature air before using the burner to raise the air temperature and provide lift. They constructed a blower with a 14 hp (10 kW) 250 cc (15 cu in) motorcycle engine taken from Wetzel's old MZ, started with a Trabant automobile starter powered by jumper cables from Strelzyk's Moskvitch sedan.[8] This engine, silenced by a Trabant muffler, turned 1-metre-long (3.3 ft) fan blades to inflate the balloon. They also used a home-made flamethrower, similar to the gondola's burner, to pre-heat the air faster. With these modifications in place, they returned to the secluded clearing to try again but still could not inflate the balloon. But using the blower did allow them to discover that the cotton material with which they fashioned the balloon was too porous and leaked excessively.[6]&lt;/p&gt;&lt;p&gt;Their unsuccessful effort had cost them 2,400 DDM (US$360). Strelzyk disposed of the cloth by burning it in his furnace over several weeks.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Second test&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel purchased samples of different fabrics in local stores, including umbrella material and various samples of taffeta and nylon. They used an oven to test the material for heat resistance. In addition, they created a test rig from a vacuum cleaner and a water-filled glass tube to determine which material would allow the vacuum to exert the most suction on the water, and consequently which was the most impervious to air. The umbrella covering performed the best but was also the most expensive. They instead selected a synthetic kind of taffeta.[6]&lt;/p&gt;&lt;p&gt;To purchase a large quantity of fabric without arousing too much suspicion, the pair again drove to a distant city. This time they travelled over 160 kilometres (100 mi) to a department store in Leipzig. Their new cover story was that they belonged to a sailing club and needed the material to make sails. The quantity they needed had to be ordered, and although they feared the purchase might be reported to East Germany's State Security Service (Stasi), they returned the next day and picked up the material without incident. They paid 4,800 DDM (US$720) for 800 metres (2,600 ft) of 1-metre-wide (3 ft 3 in) fabric.[6] On the way home, they also purchased an electric motor to speed up the pedal-operated sewing machine they had been using to sew the material into the desired balloon shape.[7]&lt;/p&gt;&lt;p&gt;Wetzel spent the next week sewing the material into another balloon, accomplishing the task faster the second time with the now-electric sewing machine. Soon afterwards, the two men returned to the forest clearing and inflated the bag in about five minutes using the blower and flame thrower. The bag rose and held air, but the burner on the gondola was not powerful enough to create the heat needed for lift. The pair continued experimenting for months, doubling the number of propane tanks and trying different fuel mixtures. Disappointed with the result, Wetzel decided to abandon the project and instead started to pursue the idea of building a small gasoline engine-powered light aeroplane[6] or a glider.[5]&lt;/p&gt;&lt;p&gt;Strelzyk continued trying to improve the burner. In June 1979, he discovered that with the propane tank inverted, additional pressure caused the liquid propane to evaporate, which produced a bigger flame. He modified the gondola to mount the propane tanks upside down, and returned to the test site where he found the new configuration produced a 12-metre (39 ft) long flame. Strelzyk was ready to attempt an escape.[6]&lt;/p&gt;&lt;head rend="h2"&gt;First escape attempt&lt;/head&gt;[edit]&lt;p&gt;On 3 July 1979, the weather and wind conditions were favourable. The entire Strelzyk family lifted from a forest clearing at 1:30 am and climbed at a rate of 4 metres (13 ft) per second. They reached an altitude of 2,000 metres (6,600 ft) according to an altimeter Strelzyk had made by modifying a barometer. A light wind was blowing them towards the border. The balloon then entered clouds, and atmospheric water vapour condensed on the balloon, adding weight which caused it to descend prematurely. The family landed safely approximately 180 metres (590 ft) short of the border, at the edge of the heavily mined border zone. Unsure of where they were, Strelzyk explored until he found a piece of litter – a bread bag from a bakery in Wernigerode, an East German town. The group spent nine hours carefully extricating themselves from the 500-metre (1,600 ft) wide border zone to avoid detection. They also had to travel unnoticed through a 5 km (3.1 mi) restricted zone before hiking back a total of 14 km (8.7 mi) to their car and the launch paraphernalia they had left behind.[6] They made it home just in time to report their absence from work and school was due to sickness.[7]&lt;/p&gt;&lt;p&gt;The abandoned balloon was discovered by the authorities later that morning. Strelzyk destroyed all compromising evidence and sold his car, fearing that it could link him to the escape attempt.[6] On 14 August, the Stasi launched an appeal to find the "perpetrator of a serious offence", listing in detail all the items recovered at the landing site.[9] Strelzyk felt that the Stasi would eventually trace the balloon to him and the Wetzels. He agreed with Wetzel that their best chance was to quickly build another balloon and get out as soon as possible.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Successful escape&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel decided to double the balloon's size to 4,000 cubic metres (140,000 cu ft) in volume, 20 metres (66 ft) in diameter, and 25 metres (82 ft) in height. They needed 1,250 square metres (13,500 sq ft) of taffeta, and purchased the material, in various colours and patterns, all over the country in order to escape suspicion. Wetzel sewed a third balloon, using over 6 kilometres (3.7 mi) of thread, and Strelzyk rebuilt everything else as before. In six weeks, they had prepared the 180-kilogram (400 lb) balloon and a payload of 550 kilograms (1,210 lb), including the gondola, equipment, and cargo (the two families). Confident in their calculations, they found the weather conditions right on 15 September, when a violent thunderstorm created the correct winds. The two families set off for the launch site in Strelzyk's replacement car (a Wartburg) and a moped. Arriving at 1:30 am, they needed just ten minutes to inflate the balloon and an additional three minutes to heat the air.[6]&lt;/p&gt;&lt;p&gt;Lifting off just after 2:00 am, the group failed to cut the tethers holding the gondola to the ground at the same time, tilting the balloon and sending the flame towards the fabric, which caught fire. After putting out the fire with an extinguisher brought along for just such an emergency, they climbed to 2,000 metres (6,600 ft) in nine minutes, drifting towards West Germany at 30 kilometres per hour (19 mph). The balloon flew for 28 minutes, with the temperature plummeting to −8 °C (18 °F) in the unsheltered gondola, which consisted solely of clothesline railing.&lt;/p&gt;&lt;p&gt;A design miscalculation resulted in the burner stovepipe being too long, causing the flame to be too high in the balloon, creating excessive pressure which caused the balloon to split. The air rushing out of the split extinguished the burner flame. Wetzel was able to re-light the flame with a match, and had to do so several more times before the group landed. At one point, they increased the flame to the maximum possible extent and rose to 2,500 metres (8,200 ft). They later learned they had been high enough to be detected, but not identified, on radar by West German air traffic controllers.[6] They had also been detected on the East German side by a night watchman at the district culture house in Bad Lobenstein. The report of an unidentified flying object heading toward the border caused guards to activate search lights, but the balloon was too high and out of reach of the lights.[10]&lt;/p&gt;&lt;p&gt;The tear in the balloon meant the group had to use the burner much more often, greatly limiting the distance it could travel. Wetzel later said he thought they could have travelled another 50 kilometres (31 mi) had the balloon remained intact. They made out the border crossing at Rudolphstein on the A9 and saw the search lights. When the propane ran out, they descended quickly, landing near the town of Naila, in the West German state of Bavaria and only 10 km (6 mi) from the border. The only injury was suffered by Wetzel, who broke his leg upon landing.[6] Various clues indicated to the families that the balloon had made it across the border. These included spotting red and yellow coloured lights, not common in East Germany,[3] and small farms, in contrast to the large state-run operations in the east. Another clue was modern farm equipment, unlike the older equipment used in East Germany.[11] Two Bavarian State Police officers saw the balloon's flickering light and headed to where they thought it would land. There they found Strelzyk and Wetzel, who first asked if they had made it to the West, although they noticed the police car was an Audi – another sign they were in West Germany. Upon learning they had, the escapees happily called for their families to join them.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Aftermath&lt;/head&gt;[edit]&lt;p&gt;East Germany immediately increased border security, closed all small airports close to the border, and ordered the planes kept farther inland.[6] Propane gas tanks became registered products, and large quantities of fabric suitable for balloon construction could no longer be purchased. Mail from East Germany to the two escaped families was prohibited.[12]&lt;/p&gt;&lt;p&gt;Erich Strelzyk learned of his brother's escape on the ZDF news and was arrested in his Potsdam apartment three hours after the landing. The arrest of family members was standard procedure to deter others from attempting escape. He was charged with "aiding and abetting escape", as were Strelzyk's sister Maria and her husband, who were sentenced to 2½ years. The three were eventually released with the help of Amnesty International.[12]&lt;/p&gt;&lt;p&gt;The families decided to initially settle in Naila where they had landed. Wetzel worked as an automobile mechanic and Strelzyk opened a TV repair shop in Bad Kissingen. Due to pressure from Stasi spies, the Strelzyks moved to Switzerland in 1985.[10] After German reunification in 1990, they returned to their old home in their hometown of Pößneck.[13] The Wetzels remained in Bavaria.[7]&lt;/p&gt;&lt;p&gt;West German weekly magazine Stern paid Strelzyk and Wetzel for exclusive rights to the story.[3]&lt;/p&gt;&lt;p&gt;The escape has been portrayed in two films: Night Crossing (1982) and Balloon (2018). The former, also called With the Wind to the West – the English translation of the German title – was an English-language film produced by Disney. The latter was a German-language production which "both families welcomed [Director] Herbig’s desire to, as he put it, 'make a German film for an international audience.'" The Strelzyks were reportedly "moved to tears" at the screening of Balloon at Rockefeller Center in New York City.[12] Herbig claimed in 2018 that both the Strelzyk and Wetzel families had been dissatisfied with the Disney film.[14]&lt;/p&gt;&lt;p&gt;Peter Strelzyk died in 2017 at age 74 after a long illness.[13]&lt;/p&gt;&lt;p&gt;In 2017, the balloon was put on permanent display at the Haus der Bayerischen Geschichte: Museum in Regensburg.[10]&lt;/p&gt;&lt;head rend="h2"&gt;Escapees&lt;/head&gt;[edit]&lt;p&gt;The family members included:[3]&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Peter Strelzyk, aged 37&lt;/item&gt;&lt;item&gt;Doris Strelzyk&lt;/item&gt;&lt;item&gt;Frank Strelzyk, aged 15&lt;/item&gt;&lt;item&gt;Andreas Strelzyk, aged 11&lt;/item&gt;&lt;item&gt;Günter Wetzel, aged 24&lt;/item&gt;&lt;item&gt;Petra Wetzel&lt;/item&gt;&lt;item&gt;Peter Wetzel, aged 5&lt;/item&gt;&lt;item&gt;Andreas Wetzel, aged 2&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Media&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;The Disney film Night Crossing (1982) is an adaptation of the story[13]&lt;/item&gt;&lt;item&gt;Michael Herbig's film Balloon (2018) is a German-language adaptation of the story[15]&lt;/item&gt;&lt;item&gt;BBC program Outlook, "Fleeing Communism in a Hot Air Balloon"[16]&lt;/item&gt;&lt;item&gt;PBS Nova program, "History's Great Escapes" (2004)[17]&lt;/item&gt;&lt;item&gt;Doris Strelzyk, Peter Strelzyk, Gudrun Giese: Destiny Balloon Escape. Quadriga, Berlin 1999, ISBN 3-88679-330-3&lt;/item&gt;&lt;item&gt;Jürgen Petschull, With the Wind to the West. The Adventurous Flight from Germany to Germany. Goldmann, Munich 1980, ISBN 3-442-11501-9&lt;/item&gt;&lt;item&gt;Kristen Fulton (Author), Torben Kuhlmann (Illustrator), Flight for Freedom: The Wetzel Family’s Daring Escape from East Germany. March 3, 2020, ISBN 978-1452149608&lt;/item&gt;&lt;item&gt;The Netflix series White Rabbit Project, episode 2, "Jailbreak"&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;[edit]&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ a b Wetzel, Günter. "Die Nacht der Flucht". Ballonflucht.de. Archived from the original on 19 September 2020. Retrieved 16 September 2019.&lt;/item&gt;&lt;item&gt;^ Hertle, Hans-Hermann; Nooke, Maria (2009). Die Todesopfer an der Berliner Mauer 1961–1989. Ein biographisches Handbuch. Ch. Links Verlag. ISBN 978-3-86153-517-1.&lt;/item&gt;&lt;item&gt;^ a b c d e Getler, Michael (28 September 1979). "Harrowing Flight From East Germany". The Washington Post. Archived from the original on 26 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ Snow, Philipp (16 September 2009). "Balloon escape from the GDR With hot air to freedom". Spiegel Online (in German). Archived from the original on 7 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c Simpson, Paul (2013). The Mammoth Book of Prison Breaks. Little, Brown Book Group. p. 216. ISBN 978-1-4721-0024-5. Archived from the original on 16 September 2023. Retrieved 1 April 2018.&lt;/item&gt;&lt;item&gt;^ a b c d e f g h i j k l m n o p q r s Dornberg, John (February 1980). "The Freedom Balloon". Popular Mechanics. pp. 100–103. Retrieved 22 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c d e Overbye, Stine (13 April 2017). "Fathers wanted to escape GDR in a hot air balloon". Historia (in Dutch). Archived from the original on 1 April 2018. Retrieved 30 March 2018.&lt;/item&gt;&lt;item&gt;^ Petschull, Jürgen (27 September 1979). "Das Himmelfahrtskommando" [High-flying mission] (PDF). Stern (in German). No. 40. p. 34. Archived from the original (PDF) on 12 July 2024 – via Museum Naila.&lt;/item&gt;&lt;item&gt;^ Souerbry, Rachel. "How Two Families Escaped East Germany In A Homemade Hot Air Balloon". ranker.com. Archived from the original on 1 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "Wetzel und Peter Strelzyk Ballonhülle der Strelzyks". museum.bayern (in German). Archived from the original on 8 April 2019. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ "East-West: The Great Balloon Escape". Time. 1 October 1979. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "The Balloon Escape of Peter Strelzyk". goethe-rutheneum.de (in German). Archived from the original on 11 February 2013. Retrieved 30 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "Man who fled East Germany in a homemade balloon and whose story was made into a film dies". The Express. 15 March 2017. Archived from the original on 1 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ Connolly, Kate (17 October 2018). "Film of daring balloon escape from East revives German identity debate". Archived from the original on 8 February 2021. Retrieved 10 May 2019.&lt;/item&gt;&lt;item&gt;^ Ballon at IMDb&lt;/item&gt;&lt;item&gt;^ "Fleeing Communism in a Hot Air Balloon". bbc. Archived from the original on 12 December 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ "Great Escapes". pbs.org. Archived from the original on 16 April 2019. Retrieved 16 April 2019.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;External links&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;Escape by balloon by Günter Wetzel (participant website)&lt;/item&gt;&lt;item&gt;Video of balloon on museum display&lt;/item&gt;&lt;item&gt;BBC Outlook program&lt;/item&gt;&lt;item&gt;Photograph of Güenter Wetzel, Peter and Doris Strelzyk Archived 1 April 2018 at the Wayback Machine&lt;/item&gt;&lt;item&gt;Photograph of the actual balloon, inflated in 1985 at a festival in Hof, Bavaria&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46648916</guid><pubDate>Fri, 16 Jan 2026 17:16:33 +0000</pubDate></item><item><title>Counterfactual evaluation for recommendation systems</title><link>https://eugeneyan.com/writing/counterfactual-evaluation/</link><description>&lt;doc fingerprint="b472dbf60d6b017c"&gt;
  &lt;main&gt;
    &lt;p&gt;When I first started working on recommendation systems, I thought there was something weird about the way we did offline evaluation. First, we split customer interaction data into training and validation sets. Then, we train our recommenders on the training set before evaluating them on the validation set, usually on metrics such as recall, precision, and NDCG. This is similar to how we evaluate supervised machine learning models and doesn’t seem unusual at first glance.&lt;/p&gt;
    &lt;p&gt;But don’t our recommendations change how customers click or purchase? If customers can only interact with items shown to them, why do we perform offline evaluation on static historical data?&lt;/p&gt;
    &lt;p&gt;It took me a while to put a finger on it but I think this is why it felt weird: We’re treating recommendations as an observational problem when it really is an interventional problem.&lt;/p&gt;
    &lt;p&gt;Problems solved via supervised machine learning are usually observational problems. Given an observation such as product title, description, and image, we try to predict the product category. Our model learns P(category=phone|title=“…”, description=“…”, image=image01.jpeg).&lt;/p&gt;
    &lt;p&gt;On the other hand, recommendations are an interventional problem. We want to learn how different interventions (i.e., item recommendations) lead to different outcomes (i.e., clicks, purchases). By using logged customer interaction data as labels, the observational offline evaluation approach ignores the interventional nature of recommendations.&lt;/p&gt;
    &lt;p&gt;As a result, we’re not evaluating if users would click or purchase more due to our new recommendations; we’re evaluating how well the new recommendations fit logged data. Thus, what our model learns is P(view3=iphone|view1=pixel, view2=galaxy) when what we really want is P(click=True|recommend=iphone, view1=pixel, view2=galaxy).&lt;/p&gt;
    &lt;p&gt;The straightforward way to evaluate recommendations as an interventional problem is via A/B testing. Our interventions (i.e., new recommendations) are shown to users, we log their behavior attributed to our new recommendations, and then measure how metrics such as click-thru-rate and conversion change. However, it requires more effort relative to offline evaluation, experiment cycles may be long as we need enough data to make a judgement, and there’s the risk of deploying terrible experiments. Also, we may not have easy access to A/B testing we’re working on the research side of things.&lt;/p&gt;
    &lt;p&gt;The less direct approach is counterfactual evaluation. Counterfactual evaluation tries to answer “what would have happened if we show users our new recommendations instead of the existing recommendations?” This allows us to estimate the outcomes of potential A/B tests without actually running them.&lt;/p&gt;
    &lt;p&gt;The most widely known technique for counterfactual evaluation is Inverse Propensity Scoring (IPS). It’s sometimes also referred to as inverse probability weighting/sampling. The intuition behind it is that we can estimate how customer interactions will change—by reweighting how often each interaction will occur—based on how much more (or less) each item is shown by our new recommendation model. Here’s the IPS equation.&lt;/p&gt;
    &lt;p&gt;Let’s try to understand it by starting from the right. In section 1, &lt;code&gt;r&lt;/code&gt; represents the reward for an observation. This is the number of clicks or purchases or whatever metric is important to you in the logged data.&lt;/p&gt;
    &lt;p&gt;Next is the importance weight. The denominator (section 2a) represents our existing production recommender’s (&lt;code&gt;π0&lt;/code&gt;) probability of making a recommendation (aka action &lt;code&gt;a&lt;/code&gt;) given the context &lt;code&gt;x&lt;/code&gt;; the numerator (section 2b) represents the same probability but for our new recommender (&lt;code&gt;πe&lt;/code&gt;). (&lt;code&gt;π&lt;/code&gt; stands for recommendation policy.) For a user-to-item recommender, &lt;code&gt;x&lt;/code&gt; is the user; for an item-to-item recommender, &lt;code&gt;x&lt;/code&gt; is an item.&lt;/p&gt;
    &lt;p&gt;With the importance weight, we can compute how often a recommendation is made via the new model relative to the existing model. We can then use the ratio to update our logged rewards. For example, we have an old model (&lt;code&gt;π0&lt;/code&gt;) and new model (&lt;code&gt;πe&lt;/code&gt;) that recommend iPhone on the Pixel detail page, but with different probabilities:&lt;/p&gt;
    &lt;p&gt;In this scenario, the new model will recommend iPhone 0.6/0.4 = 1.5x as often as the old model. Thus, assuming a non-zero reward (i.e., the user clicked or purchased), we can reweight the logged reward to be worth 1.5x as much.&lt;/p&gt;
    &lt;p&gt;Finally, we average over our data (section 3) to get the IPS estimate (section 4) for our new recommender. This IPS estimate suggests how much reward (i.e., clicks, purchases) the new recommender would get relative to the production recommender if the new recommender was shown to users.&lt;/p&gt;
    &lt;p&gt;But how do we get the probability of making a recommendation (&lt;code&gt;a&lt;/code&gt;) given the context (&lt;code&gt;x&lt;/code&gt;)? Well, we can normalize the raw scores for each recommendation (via Plackett-Luce) to get each recommendation’s probability. Alternatively, if our recommendations are pre-computed, we can count the frequency of each recommendation in our recommendation store. My preferred approach is to use the impression count for each recommendation—I believe this is the most direct measure of the probability of making a recommendation and best adjusts for the presentation bias.&lt;/p&gt;
    &lt;p&gt;This dependence on recommendation probabilities or impressions likely explains why counterfactual evaluation isn’t more widely adopted in academic papers—most public datasets don’t include them. One exception is the Open Bandit Dataset which includes the recommendation probability (&lt;code&gt;action_prob&lt;/code&gt;) for each recommendation observation.&lt;/p&gt;
    &lt;p&gt;However, IPS has its pitfalls. One challenge is insufficient support. This happens when our new recommender being evaluated (&lt;code&gt;πe&lt;/code&gt;) makes a recommendation (&lt;code&gt;a&lt;/code&gt;) that our existing production recommender (&lt;code&gt;π0&lt;/code&gt;) didn’t make. Thus, &lt;code&gt;π0&lt;/code&gt;’s probability of &lt;code&gt;a&lt;/code&gt; is zero and we can’t compute the importance weight. We can mitigate this by deliberately showing random samples of non-recommended items on a sliver of traffic to log interactions for potential recommendations. (Spoiler: PMs might not like this.) A more palatable approach is ensure that all eligible items have a non-zero recommendation probability and then sample based on that probability. This gives all items a chance to be recommended.&lt;/p&gt;
    &lt;p&gt;IPS can also suffer from high variance when the new model (&lt;code&gt;πe&lt;/code&gt;) recommends very differently from the old model (&lt;code&gt;π0&lt;/code&gt;). Suppose &lt;code&gt;π0&lt;/code&gt; makes a recommendation (&lt;code&gt;a&lt;/code&gt;) with a probability of 0.001 and we logged a single click. If &lt;code&gt;πe&lt;/code&gt; makes the same recommendation (&lt;code&gt;a&lt;/code&gt;) with a probability of 0.1, we would reweight that single click by 100x—this is likely a severe overestimation. One solution is to ensure that the new recommenders being evaluated don’t differ too much from the production recommender, thus preventing the importance weight from exploding.&lt;/p&gt;
    &lt;p&gt;Another solution is Clipped IPS (CIPS). CIPS lets us set a maximum threshold for the importance weight. For example, if our threshold is 10, an importance weight greater than 10 is clipped to it. However, tuning the clipping parameter can be tricky.&lt;/p&gt;
    &lt;p&gt;Another approach is Self-Normalized IPS (SNIPS). SNIPS divides the IPS estimate by the importance weight. This rescaling prevents overinflated IPS estimates. Relative to CIPS, SNIPS is simpler and doesn’t require setting a parameter.&lt;/p&gt;
    &lt;p&gt;Which works better? At a recent RecSys 2021 tutorial, Yuta Saito compared various methods via experiments on synthetic data generated via Open Bandit Pipeline with 10 possible actions. He also assessed the direct method (DM) which we didn’t discuss. In a nutshell, DM trains a model to impute missing rewards. Think of it as similar to building an environment model for reinforcement learning, such as OpenAI gym or Criteo reco-gym, which we can then use to train and evaluate our RL models.&lt;/p&gt;
    &lt;p&gt;He found that IPS outperformed DM as the amount of logged data increases, and that CIPS didn’t perform much better than IPS. Overall, SNIPS performed the best (i.e., had the least error) and without the need for any parameter tuning. The tutorial goes on to discuss other estimators such as Doubly Robust (combining DM and SNIPS) as well as counterfactual learning—highly recommend checking it out.&lt;/p&gt;
    &lt;p&gt;Nonetheless, one downside of SNIPS is that it requires computing the importance weight for all observations; in IPS, we only need the importance weight for observations with non-zero reward. If we consider how most recommendations have zero reward (&amp;lt;10% CTR or conversion), SNIPS increases storage requirements of recommendation probabilities and computation of importance weights by 10x or more. That said, the authors of SNIPS found that the increase in computation is made up for via faster convergence.&lt;/p&gt;
    &lt;p&gt;Let me conclude by clarifying that I’m not suggesting for us to stop training and evaluating recsys models via the observational paradigm. Despite its limitations, it has several benefits. First, it’s an established evaluation framework with many public datasets and standard metrics. This makes it easier to compare various techniques. Second, we can collect training and evaluation data even before deploying our first recommender. Customer interaction data is generated organically when customers use our platforms. Thus, the conventional offline evaluation approach is a good place to start.&lt;/p&gt;
    &lt;p&gt;Nonetheless, if you’re keen to try a new evaluation approach, or find your offline metrics diverging from online A/B testing outcomes, consider counterfactual evaluation via SNIPS. In addition, though I’ve been discussing counterfactual evaluation in the context of recsys, it’s also applicable to other use cases where you want to simulate A/B tests offline.&lt;/p&gt;
    &lt;p&gt;Thanks to Arnab Bhadury, Vicki Boykis, and Yuta Saito for reading drafts of this.&lt;/p&gt;
    &lt;p&gt;If you found this useful, please cite this write-up as:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Yan, Ziyou. (Apr 2022). Counterfactual Evaluation for Recommendation Systems. eugeneyan.com. https://eugeneyan.com/writing/counterfactual-evaluation/.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;@article{yan2022counterfactual,
  title   = {Counterfactual Evaluation for Recommendation Systems},
  author  = {Yan, Ziyou},
  journal = {eugeneyan.com},
  year    = {2022},
  month   = {Apr},
  url     = {https://eugeneyan.com/writing/counterfactual-evaluation/}
}&lt;/code&gt;
    &lt;p&gt;Join 11,800+ readers getting updates on machine learning, RecSys, LLMs, and engineering.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46655524</guid><pubDate>Sat, 17 Jan 2026 05:20:20 +0000</pubDate></item><item><title>The 'untouchable hacker god' behind Finland's biggest crime</title><link>https://www.theguardian.com/technology/2026/jan/17/vastaamo-hack-finland-therapy-notes</link><description>&lt;doc fingerprint="260593d10eb24786"&gt;
  &lt;main&gt;
    &lt;p&gt;Tiina Parikka was half-naked when she read the email. It was a Saturday in late October 2020, and Parikka had spent the morning sorting out plans for distance learning after a Covid outbreak at the school where she was headteacher. She had taken a sauna at her flat in Vantaa, just outside Finland’s capital, Helsinki, and when she came into her bedroom to get dressed, she idly checked her phone. There was a message that began with Parikka’s name and her social security number – the unique code used to identify Finnish people when they access healthcare, education and banking. “I knew then that this is not a game,” she says.&lt;/p&gt;
    &lt;p&gt;The email was in Finnish. It was jarringly polite. “We are contacting you because you have used Vastaamo’s therapy and/or psychiatric services,” it read. “Unfortunately, we have to ask you to pay to keep your personal information safe.” The sender demanded €200 in bitcoin within 24 hours, otherwise the price would go up to €500 within 48 hours. “If we still do not receive our money after this, your information will be published for everyone to see, including your name, address, phone number, social security number and detailed records containing transcripts of your conversations with Vastaamo’s therapists or psychiatrists.”&lt;/p&gt;
    &lt;p&gt;Parikka swallows hard as she relives this memory. “My heart was pounding. It was really difficult to breathe. I remember lying down on the bed and telling my spouse, ‘I think I’m going to have a heart attack.’”&lt;/p&gt;
    &lt;p&gt;Someone had hacked into Vastaamo, the company through which Parikka had accessed psychotherapy. They’d got hold of therapy notes containing her most private, intimate feelings and darkest thoughts – and they were holding them to ransom. Parikka’s mind raced as she tried to recall everything she’d confided during three years of weekly therapy sessions. How would her family react if they knew what she’d been saying? What would her students say? The sense of exposure and violation was unfathomable: “It felt like a public rape.”&lt;/p&gt;
    &lt;p&gt;Therapy had been Parikka’s lifeline. Now 62, she’d had three children by the time she was 25, including twins who had been born extremely prematurely in the 1980s, weighing only a few hundred grams each. One grew up with cerebral palsy; the other is blind. Parikka spent years juggling medical emergencies, surgeries and hospital stays with a demanding job and a crumbling marriage. “During those years, nobody ever asked me, the mother, ‘How are you?’”&lt;/p&gt;
    &lt;p&gt;She divorced in 2014 and met her current partner a year later. By then, her children were adults with independent lives. After decades of putting everyone’s else’s needs before her own, she should have been finally able to exhale. Instead, she had a breakdown. “I had full-scale anxiety running through my body all the time. I couldn’t sleep. I had panic attacks. I couldn’t eat.” Driving at high speed on the highway one day, dark thoughts descended. “I was thinking, I wouldn’t mind if this car crashed.”&lt;/p&gt;
    &lt;p&gt;In search of urgent help, she went to Google, which led her to Vastaamo, Finland’s one-stop digital shop for people in search of psychotherapy. No doctor referral was necessary. She managed to book a session for the very next day. “It was that easy.”&lt;/p&gt;
    &lt;p&gt;Being able to confide in a total stranger felt liberating. She told her therapist things she had never told another soul. “Trauma in relationships. The disappointment and tragedy of having disabled children, and the influence it had on my life,” she says. “Silly things, childish things. It’s very human to feel hate, anger, rage.”&lt;/p&gt;
    &lt;p&gt;After Parikka read the email that left her struggling to breathe, she had no idea where to turn for help. She rang the emergency services, but the police told her to get off the line; they needed to keep it free for real emergencies. In her bathrobe, her phone still in her hand, she felt utterly alone.&lt;/p&gt;
    &lt;p&gt;But Parikka was far from alone. Across Finland, 33,000 people who had used Vastaamo were discovering that a hacker had got hold of their therapy notes and was holding them to ransom. These were people who, by definition, were likely to be vulnerable, in need of help. Each was experiencing a very personal, individual terror. In a country of only 5.6 million people, everyone knows someone who was hacked.&lt;/p&gt;
    &lt;p&gt;Some victims’ notes had already been cherrypicked for the world to see. Three days before the extortion emails were sent, someone using the handle ransom_man had left posts on the dark web, on r/Suomi, the Finnish-language subreddit, and on Ylilauta, Finland’s equivalent to 4chan. This time, the post was in English. “Hello Finnish Colleagues,” it began. “We have hacked the psychotherapy clinic vastaamo.fi and taken tens of thousands of patient records including extremely sensitive session notes and social security numbers. We requested a small payment of 40 bitcoins (nothing for a company with yearly revenues close to 20 million euros) but the CEO has stopped responding to our emails. We are now starting to gradually release their patient records, 100 entries every day.”&lt;/p&gt;
    &lt;p&gt;There was a link to the dark web, where 100 records were already on display. Directly below it, ransom_man had signed off the post with a single word: “Enjoy!”&lt;/p&gt;
    &lt;p&gt;The 100 records included those of politicians, police officers and prominent public figures. Their names appeared alongside therapy notes that contained details of adultery, suicide attempts, paedophilia and sexual violence. Some of the records belonged to children. And whoever was behind the hack was true to their word: the next day, 100 more patient records were uploaded.&lt;/p&gt;
    &lt;p&gt;Some victims went searching on the dark web in a desperate attempt to see if their records were out there. Some paid the ransom, scrabbling to get hold of bitcoin while the clock ticked down. Lawyers representing the victims have told me they know of at least two cases where people took their own lives after they discovered their therapy notes had been hacked.&lt;/p&gt;
    &lt;p&gt;But for all of them, it was already too late. At 2am on 23 October 2020 – the day before the emails began to arrive in tens of thousands of inboxes – ransom_man had uploaded a much larger file. It contained every record of every single patient on Vastaamo’s database. Everyone’s therapy notes had already been published, for free, for everyone in the world to see.&lt;/p&gt;
    &lt;p&gt;Who was behind the biggest crime Finland had ever known? And might they have been motivated by something other than money? I have spent 18 months trying to answer these questions, following threads across Europe and the US. They culminated in a visit to a prison, and one of the most chilling conversations I have ever had.&lt;/p&gt;
    &lt;p&gt;Finland has been ranked the happiest country on Earth by the UN for the last eight years in a row. A world leader in childcare and education, Finland is also famously hi-tech: it’s the most digitalised country in Europe, renowned for its communications sector (as the home of Nokia) and leading the way when it comes to cybersecurity and AI innovation. But Finland is also a place of extremes. It has more heavy metal bands per capita than any other nation. In the far north, for the few days around the winter solstice, the sun does not rise.&lt;/p&gt;
    &lt;p&gt;Vastaamo had long been considered an example of how Finland was getting it right when it came to digital tech. Founded in 2008 by entrepreneur Ville Tapio and his mother, Nina, a psychotherapist, the aim was to open up therapy to the masses, removing the stigma of asking for help. The platform made it easy for people to see who was free, where, and what therapeutic approach they specialised in. The logo had the colour palette of a first-aid kit, with white lettering in a green speech bubble. Vastaamo means “a place for answers”.&lt;/p&gt;
    &lt;p&gt;It was an attractive platform for therapists, too: they didn’t have to worry about marketing or billing – Vastaamo would take care of all of that. The company even provided a behind-the-scenes digital interface where therapists could make and store their notes. This formula, combined with the increasing demand for therapy services, meant Vastaamo grew fast. It opened its own network of around 20 clinics across Finland, employing more than 220 psychotherapists by 2018, leading some in Finland to refer to it as “the McDonald’s of therapy”. In the years before Zoom and Teams were part of our daily lives, the remote therapy also offered by Vastaamo was groundbreaking. In 2019, a private equity firm bought a majority stake in the company, earning the Tapio family a payout of more than €5m.&lt;/p&gt;
    &lt;p&gt;Meri-Tuuli Auer, 30, describes using Vastaamo as “like Uber for therapy – convenient, accessible, relatively cheap”. She picked her therapist because he offered cognitive psychotherapy – and she liked his photo. “He looked nice. He looked approachable.”&lt;/p&gt;
    &lt;p&gt;Auer’s home, on the outskirts of Helsinki, is a riot of pink. There are Barbie dolls, Barbie books and Barbie-themed handbags on her shelves, as well as a glittery open-top Barbie sports car. A pole-dancing pole takes pride of place in the centre of her living room.&lt;/p&gt;
    &lt;p&gt;“I’m a mixed personality,” she tells me over tea in Moomin mugs. “I love being around people, but I get that inkling, that doubt: maybe they all think I’m full of shit and stupid and ugly and I have no idea what I’m doing.” Auer has struggled with depression for much of her life. When she was 18, she was in a secretive, difficult relationship with a man 29 years her senior, which made her self-esteem plummet further. She was drinking heavily. “If I hadn’t gone to therapy, I don’t know what would have become of me. Maybe there is another universe where I didn’t make it to 30.”&lt;/p&gt;
    &lt;p&gt;Most of the cost of Auer’s treatment was covered by the Finnish healthcare system; she paid only about €25 for each weekly session. She was making great strides. “After going to therapy in 2018 and 2019, I had gained a basic sense of security. That was lost in 2020.”&lt;/p&gt;
    &lt;p&gt;Vastaamo’s CEO knew the company’s patient registry was being held to ransom weeks before his customers found out. On 28 September 2020, Ville Tapio received an email demanding the bitcoin equivalent of €450,000 to keep it safe. Sample patient records attached to the email proved the extortionist wasn’t bluffing. Tapio called in a cybersecurity firm to investigate.&lt;/p&gt;
    &lt;p&gt;Medical information is an obvious target for would-be extortionists, says Antti Kurittu, the security specialist Tapio hired. But this was something else: “Whatever I tell a therapist is, by its very nature, a lot more private than what my blood pressure is,” he says, drily.&lt;/p&gt;
    &lt;p&gt;Kurittu used to be a detective, investigating cybercrimes for the Finnish police; he says he insisted they be told about the ransom attempt so they could begin a parallel investigation. Meanwhile, he began inspecting Vastaamo’s server, looking for clues as to who might be behind the hack – and one of the first things he noticed was how lax security had been. “It was definitely unfit for purpose for storing this kind of information,” he says. He tells me that the patient records database was accessible via the internet; there was no firewall and, perhaps most egregiously, it was secured with a blank password, so anyone could just press enter and open it. Kurittu determined that whoever had hacked Vastaamo had probably just been scanning the internet in search of any badly secured databases that could be monetised. “They tried a bunch of bank vaults to see which ones were open, and just happened to stumble on this one.”&lt;/p&gt;
    &lt;p&gt;For a few weeks, the hacker and Vastaamo exchanged emails, but there was no question that Vastaamo would pay the ransom. If they did, they’d have to trust a criminal’s word that the records had been destroyed – plus, Kurittu says, it goes against the national character. “Finns are a bit of a belligerent bunch. We’re not known for paying ransom quietly or easily, which I take great national pride in.”&lt;/p&gt;
    &lt;p&gt;After ransom_man started leaking patient records to put pressure on the company, Kurittu kept a close eye on the server being used to publish them. He had a hunch whoever was behind this was either Finnish, or had lived in Finland for a long time: they knew which famous names to flaunt from the patient records.&lt;/p&gt;
    &lt;p&gt;When Auer learned about the hack, she downloaded a browser that would enable her to access the dark web, for the first time in her life. “I was thinking to myself, I just have to see if my records are there.” She found her name wasn’t among the first batch posted, and closed the file without reading anyone’s records. But she saw other people discussing what they’d seen. “People had already picked – in their opinion – the funniest parts from the patient records. They were laughing at these people’s misery. A 10-year-old child had gone to therapy, and people found it funny.”&lt;/p&gt;
    &lt;p&gt;Auer began to spiral. “I closed myself in at home, I didn’t want to leave, I didn’t want anyone to see me,” she tells me. She had no hope that the hacker would ever be found. “It’s not that I don’t trust the police in Finland – it’s just that it seemed like an impossible task.”&lt;/p&gt;
    &lt;p&gt;But the much larger file ransom_man had uploaded to the dark web – the one that contained every single one of Vastaamo’s patient records – also included vital clues to his identity. The first three batches of therapy notes had been posted manually, but when the hacker had tried to automate the process, he had not only accidentally uploaded all of the therapy notes, but also his entire home folder. It had appeared only briefly before it was taken down, along with a post that read “whoopsie :D”, but ransom_man had screwed up.&lt;/p&gt;
    &lt;p&gt;“After spending several evenings with the file, I had the feeling I’d seen this kind of thing before,” Kurittu says. The data on the hacker’s home drive wasn’t systematically organised and arranged in folders, as you would expect from someone for whom extortion was a business. “It had that sort of chaotic, passionate hobby feeling to it.” And there was something about the childish way ransom_man had named some of the files that was eerily familiar (the one containing all the patient data was entitled “therapissed”).&lt;/p&gt;
    &lt;p&gt;Kurittu’s mind went back to 2013 when he was a senior detective constable for the Helsinki police, and the file names he’d seen on a computer he’d seized from a 16-year-old boy. “It made me think of Julius Kivimäki.”&lt;/p&gt;
    &lt;p&gt;Aleksanteri Kivimäki – who used to go by his middle name, Julius, or the online handle zeekill – had long been notorious among cybersecurity investigators. Not because of any particular talent as a hacker, but because he seemed prepared to go further than most who spend their time in the darkest parts of the internet.&lt;/p&gt;
    &lt;p&gt;Aged 14, Kivimäki was involved with a group called Hack the Planet (named after the tagline of the 1995 movie Hackers). They would break into big companies and show off what they had managed to steal online. “It was for the LOLs,” says Blair Strater, a former hacker from Illinois who hung out with Kivimäki in internet relay chat forums at that time. “You notice that something is open and you just take it. It’s not targeted.”&lt;/p&gt;
    &lt;p&gt;This kind of hacking was about impressing others – winning online clout, not extorting money. But some of those involved may have felt they were also serving a noble purpose: exposing security vulnerabilities in major corporations, or the hypocrisy of cybersecurity firms who claimed to be qualified to advise businesses while being unable to secure their own network.&lt;/p&gt;
    &lt;p&gt;Strater found Kivimäki amusing, at first. “A lot of the things he did early on were objectively funny,” he tells me over Zoom from his home in Illinois. When I ask Strater whether I would find them funny, he clarifies that his humour was an acquired taste best suited to 4chan. But in 2010, when Strater was 17 and Kivimäki was 14, they fell out over which one of them was going to publish a report of a recent hack.&lt;/p&gt;
    &lt;p&gt;Orders of pizzas and Chinese takeaway began arriving at the home Strater shared with his parents and younger sister on the outskirts of Chicago; when they opened the door, the delivery driver would ask for Julius Kivimäki. “Taxis were ordered. Hookers were ordered,” Strater says. “My father had to send away a big dump truck filled with gravel.” Strater received a blizzard of letters from credit card and insurance companies, and government agencies, including one from the department of social security confirming that an appointment with the welfare office had been created for him and his spouse – Julius Kivimäki.&lt;/p&gt;
    &lt;p&gt;Then, at 2am one morning, police in body armour carrying guns with laser sights turned up outside the Straters’ home, responding to reports that Blair had beaten his mother to death in a drug-fuelled rage. When she answered the door, they took her blood pressure to verify that she was, in fact, alive. It was the first of dozens of so-called swatting attacks the family would endure. After a lull of a couple of months, Strater learned that someone using his name had emailed a bomb threat to a local police officer; it led to Strater spending three weeks over Christmas in a juvenile detention centre.&lt;/p&gt;
    &lt;p&gt;Several years into their feud, in 2015, someone hacked Elon Musk and Tesla’s Twitter accounts, and tweeted that anyone who rang the Straters’ landline or showed up at their home would get a free car; their phone rang off the hook for days, and Blair’s father had to turn several disappointed people away from their porch. Someone using Blair’s mother’s name posted a threat to shoot up the elementary school where his 10-year-old sister was a pupil. His mother’s LinkedIn and Twitter accounts were hacked and filled with juvenile, racist posts, as well as antisemitic insults directed at the company where she worked as a healthcare statistician. Within months, she had lost her job.&lt;/p&gt;
    &lt;p&gt;The campaign of terror lasted for many more years. Strater says it’s never going to be fully over. “It’s like having cancer: it’s never really cured, it goes into remission,” he says. “Every so often, someone would hit me up and say, ‘Hey, I was one of the people that helped Julius do these things.’ Sometimes they would say, ‘He made me do them. He was blackmailing me,’ which is something he does to an awful lot of people. I want to make this very clear: I am not the person zeekill fucked with the most.”&lt;/p&gt;
    &lt;p&gt;Indeed, Kivimäki set his sights far beyond the Strater family. In August 2014 – days after his 17th birthday – he rang in a fake bomb threat that grounded a flight carrying John Smedley, president of Sony Online Entertainment, who oversaw PlayStation’s multiplayer network. A group calling themselves Lizard Squad claimed responsibility, posting almost nonsensically on Twitter that the attack was in sympathy with Islamic State. Lizard Squad struck again, on 25 December 2014, with a cyber-attack that shut down Xbox and PlayStation, and ruined Christmas morning for millions. Brazenly, Kivimäki gave interviews to BBC 5 Live and Sky News as a Lizard Squad spokesperson, claiming they did the hack both to amuse themselves and to expose Microsoft and Sony’s poor cybersecurity. He seemed to revel in the chaos and drama. He appeared on camera on Sky News; he used a fake name, but his boyish face – blond hair, blue eyes, plump cheeks – was visible for all to see.&lt;/p&gt;
    &lt;p&gt;In July 2015, following Kurittu’s investigation with the Finnish police, Kivimäki was convicted of hacking into servers at MIT and Harvard universities, as well as money laundering and fraud. He was found guilty of more than 50,000 data breaches, and received a two-year suspended sentence; he had his computer confiscated and was forced to pay back more than €6,000 obtained through his crimes. He never faced justice for any of the offences he perpetrated against Blair Strater and his family.&lt;/p&gt;
    &lt;p&gt;Shortly after he received his suspended sentence, Kivimäki updated his Twitter bio to read “untouchable hacker god”.&lt;/p&gt;
    &lt;p&gt;Kivimäki spent the next few years travelling the world. During lockdown, he lived in an air-conditioned apartment in Westminster, 20 metres away from the central London headquarters of MI5. There were trips to Dubai, Hong Kong, Barcelona and Paris. According to the images of himself he liked to post online, he was living the life of an international jetsetter. But he was not, in the end, untouchable.&lt;/p&gt;
    &lt;p&gt;Police made a micropayment of 0.1 bitcoins to ransom_man. They were able to determine that, when it was laundered into real-world currency, it was transferred into Kivimäki’s bank account. The home folder ransom_man had accidentally uploaded had led the police to some servers, one of which had been paid for using a credit card linked to him – the same one he’d been using to pay for Apple services and an OnlyFans subscription.&lt;/p&gt;
    &lt;p&gt;As investigators traced the history on ransom_man’s home folder, they were able to determine that, as well as looking for keywords such as rape, abuse and child molestation in the database of patient records, the hacker had also searched for Kivimäki’s home address, and the names of his family members. “Before publication, he ensured there was no harmful information about him, or people close to him,” Pasi Vainio, the lead prosecutor on the case, tells me. Those searches took place using an IP address linked to Kivimäki’s Westminster apartment. “He was in London when the crimes were committed.”&lt;/p&gt;
    &lt;p&gt;But it was a drawn-out, arduous investigation. There were terabytes of data to comb through. The crime had so many victims that the police had to create an online portal for everyone to register and give their statements. That generated more than 21,000 criminal reports, all of which needed to be looked at individually. So it was October 2022 – two years after Parikka, Auer and the other victims had received their ransom demands – before Vainio signed an arrest warrant for Kivimäki. His face – chubby-cheeked and floppy-haired – was added to Europol’s list of most-wanted fugitives, alongside murderers and drug traffickers.&lt;/p&gt;
    &lt;p&gt;On 3 February 2023, French police were alerted to a report of domestic violence taking place in a flat in a Paris suburb. Officers used a battering ram to enter the property and found a man and a woman inside. The man was pale and white-blond, but when asked to identify himself he handed over a Romanian passport that gave his name as Asan Amet. “We have a Scandinavian-looking guy, 195cm tall,” Vainio tells me with a smile. “I think the French police just thought something’s off.” They searched their databases and discovered Amet was one of Kivimäki’s known aliases. He was handed over to the Finnish authorities a few weeks later.&lt;/p&gt;
    &lt;p&gt;“I don’t know what I had expected, but I was surprised to see that he looked so normal,” Auer says. “He looks like a regular Finnish young man. It did make me feel like it could have been anyone.”&lt;/p&gt;
    &lt;p&gt;“I had heard that he was in a court hearing,” Parikka says. “We have a habit – every night at 8.30pm, I’ll lie here on the couch with my spouse and watch the main news. Without warning, Kivimäki was there on the screen. Kivimäki came to my living room.” She glances over to her couch, metres away from where we sit, and is overcome with tears. “I didn’t sleep the next night.”&lt;/p&gt;
    &lt;p&gt;But when the trial began, in November 2023, Parikka was determined to watch Kivimäki face justice. The logistics of inviting more than 21,000 registered victims to court were impossible; instead, proceedings were relayed to public spaces such as cinemas so that the plaintiffs could watch in real time. In a case that was all about the right to privacy and anonymity, it sounds a profoundly awkward setup. “We were all sitting far away from each other,” Auer says. “It was dead silent.” Parikka had a similar experience. “We pretty much kept to ourselves.”&lt;/p&gt;
    &lt;p&gt;On 30 April 2024, Kivimäki was found guilty of all charges – including 9,600 counts of aggravated invasion of privacy and more than 21,300 counts of attempted aggravated extortion – and sentenced to six years and three months in prison: a long stretch by Finnish standards, but shy of the seven-year maximum he could have received. His appeal against his sentence is currently under way.&lt;/p&gt;
    &lt;p&gt;Even if his conviction is upheld, he will be a free man by the end of this year.&lt;/p&gt;
    &lt;p&gt;“The sentencing scale is too low, in my opinion. But that’s the framework we have in Finland,” Vainio says. He tells me a colleague has tried to quantify the harm caused, using the conservative estimate that each person had endured a week of agony as a result of the hack. “When you multiply it with the number of victims of this case, you would have 635 years of suffering.”&lt;/p&gt;
    &lt;p&gt;Now 28, Kivimäki has served much of his sentence in a spotless, bright but suitably austere facility in Turku, south-west Finland, a two-hour train ride from Helsinki. For months, he had refused to grant me an interview, but while I am in Finland reporting this story, he changes his mind. As I sit in silence in the prison’s visitor room for what feels like hours, watching the clock tick down behind a panel of reinforced glass, I wonder if Kivimäki is trolling me; if he has dragged me over here simply to derail the other interviews I already had scheduled, with no intention of ever leaving his cell. But after 40 minutes he appears. With his white-blond hair, ice-blue eyes and razor burn, and dressed in a black T-shirt and shorts, he looks like an overgrown teenage boy.&lt;/p&gt;
    &lt;p&gt;He didn’t do it, he says; he’s simply a victim of his own notoriety. “They had to find somebody. They just chose somebody who was convenient for the story.” When I point out that there’s an enormous amount of circumstantial evidence linking him to the hack, Kivimäki is defiant. “The obvious answer is that it’s just somebody close to me.” He has an idea who it is, he continues, but he isn’t prepared to name names.&lt;/p&gt;
    &lt;p&gt;It seems very selfless to do time for someone else’s crime, I say. I tell him Parikka says having her therapy notes held to ransom felt like a public rape. “I’m sure that’s how she felt,” he replies, blankly. “It’s quite remote to me. I’m involved, in that I was in court over this stuff, but I didn’t do it. It’s another story in the news.”&lt;/p&gt;
    &lt;p&gt;As a fellow human being rather than the person convicted of the crime, I ask, what’s your response to people taking their lives after having their therapy notes stolen? “There’s a lot of terrible things going on in the world. I don’t really feel any differently about this. I turn on the news and there’s people dying in Gaza or wherever. It’s like, how do you feel about that? I think the honest answer for most people is that they just … don’t.” You don’t have anything to say to the victims? “Not really,” he replies. “These are nameless, faceless people.”&lt;/p&gt;
    &lt;p&gt;“There’s been just one question that I would ask Kivimäki,” Parikka says. “That would be: ‘Was there ever such a moment that you felt empathy?’ I don’t think he’s able to put himself into anybody else’s situation.” She pauses. “I think that he really needs therapy.”&lt;/p&gt;
    &lt;p&gt;Vastaamo was declared bankrupt in February 2021. Days after patients received the ransom emails, the board announced that it had let the CEO, Ville Tapio, go. In April 2023, Tapio was found guilty of criminal negligence in his handling of patient data. His conviction was overturned on appeal in December 2025. (He declined my requests to interview him.)&lt;/p&gt;
    &lt;p&gt;“I have actually been more angry towards Ville Tapio than I have been towards Kivimäki,” Auer says. “As CEO of the company, he had the responsibility to make sure that it was prepared for all kinds of risks, and that they had sufficient information security. It seems like it was never a priority to him.” What was his priority? “Making money. He ran a very successful business.”&lt;/p&gt;
    &lt;p&gt;“I believe that originally the Tapios were wanting to help people and make therapy available,” Parikka says. “There are now maybe thousands of people who will never use therapy again, because they can never trust. And that’s really bad.”&lt;/p&gt;
    &lt;p&gt;Alongside more than 6,000 other plaintiffs, Auer and Parikka are part of a civil case suing Kivimäki for damages. Despite the lifestyle he projects online, he claims not to have the funds to pay damages; so far, no one has been able to find his assets. The government has agreed to pay compensation to victims – anything from a few hundred euros to a few thousand, depending on how many pages of their therapy notes Vastaamo had in its database, and how sensitive the information contained in those pages was – but the sum is likely to be symbolic. How can you ever repay the damage of being exposed in this way?&lt;/p&gt;
    &lt;p&gt;Copies of the patient files have been circulating ever since they were first released in October 2020. At one point, someone created a special search engine for browsing the database. This doesn’t surprise Parikka. “Kivimäki isn’t just one of a kind,” she says. “I know human curiosity. People want to know.”&lt;/p&gt;
    &lt;p&gt;Other people are as prepared as Kivimäki was to break moral and legal boundaries – for money, for online clout, out of ghoulish curiosity or simply for the LOLs. In May, Finnish police announced that there was a second suspect in the Vastaamo case, a US citizen living in Estonia – suspected of aiding and abetting Kivimäki, helping prepare the files. He has been charged with assisting in the attempted extortion.&lt;/p&gt;
    &lt;p&gt;In an era when AI models are trained on our Zoom conversations, emails and status updates, it is naive to believe that anything can ever be fully secure. The human need to confide in others can be met in an extraordinary range of ways in the digital age. In a world of unparalleled connectivity, can our innermost secrets ever be truly safe?&lt;/p&gt;
    &lt;p&gt;Kivimäki thinks we are all clinging on to analogue expectations about privacy in a digital world. “So many of our worst secrets – I mean worst of worst, things we might really, really not want to share with the entire world – they exist online. They’ll exist in the database of some company you used,” he tells me. “Everybody’s photos, everybody’s text-messaging histories.” He fixes me with his eyes. “You fundamentally want to believe in this privacy. But, on the other hand, I don’t know how you’re going to get there.”&lt;/p&gt;
    &lt;p&gt;Intrigue: Ransom Man, Jenny Kleeman’s six-part series for BBC Radio 4, is available now on BBC Sounds.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46656045</guid><pubDate>Sat, 17 Jan 2026 07:29:18 +0000</pubDate></item><item><title>Show HN: Streaming gigabyte medical images from S3 without downloading them</title><link>https://github.com/PABannier/WSIStreamer</link><description>&lt;doc fingerprint="286db0183daf5dc5"&gt;
  &lt;main&gt;
    &lt;p&gt;A modern, cloud-native tile server for Whole Slide Images. One command to start serving tiles directly from S3.&lt;/p&gt;
    &lt;code&gt;# Installation (requires Rust, see alternatives below)
cargo install wsi-streamer

# On your local machine
wsi-streamer s3://my-slides-bucket --s3-region eu-west-3&lt;/code&gt;
    &lt;p&gt;That's it. No configuration files, no local storage, no complex setup. Open &lt;code&gt;http://localhost:3000/view/sample.svs&lt;/code&gt; in your browser to view a slide.&lt;/p&gt;
    &lt;p&gt;Whole Slide Images are large (1-3GB+) and typically live in object storage. Traditional viewers require downloading entire files before serving a single tile. WSIStreamer takes a different approach: it understands slide formats natively, fetches only the bytes needed via HTTP range requests, and returns JPEG tiles immediately.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Range-based streaming — fetches only the bytes needed for each tile, no local files&lt;/item&gt;
      &lt;item&gt;Built-in viewer — OpenSeadragon-based web viewer with pan, zoom, and dark theme&lt;/item&gt;
      &lt;item&gt;Native format support — Rust parsers for Aperio SVS and pyramidal TIFF&lt;/item&gt;
      &lt;item&gt;Production-ready — HMAC-SHA256 signed URL authentication&lt;/item&gt;
      &lt;item&gt;Multi-level caching — slides, blocks, and encoded tiles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Install from crates.io:&lt;/p&gt;
    &lt;code&gt;cargo install wsi-streamer&lt;/code&gt;
    &lt;p&gt;Or build from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/PABannier/WSIStreamer.git
cd WSIStreamer
cargo build --release&lt;/code&gt;
    &lt;p&gt;Or run with Docker:&lt;/p&gt;
    &lt;code&gt;# Pull from GitHub Container Registry
docker run -p 3000:3000 -e WSI_S3_BUCKET=my-bucket ghcr.io/pabannier/wsistreamer:latest

# Or use Docker Compose for local development with MinIO
docker compose up --build&lt;/code&gt;
    &lt;code&gt;# Serve slides from S3
wsi-streamer s3://my-slides

# Custom port
wsi-streamer s3://my-slides --port 8080

# S3-compatible storage (MinIO, etc.)
wsi-streamer s3://slides --s3-endpoint http://localhost:9000&lt;/code&gt;
    &lt;code&gt;# List slides
curl http://localhost:3000/slides

# Get slide metadata
curl http://localhost:3000/slides/sample.svs

# Fetch a tile (level 0, position 0,0)
curl http://localhost:3000/tiles/sample.svs/0/0/0.jpg -o tile.jpg

# Get thumbnail
curl "http://localhost:3000/slides/sample.svs/thumbnail?max_size=256" -o thumb.jpg&lt;/code&gt;
    &lt;code&gt;# Enable HMAC-SHA256 authentication
wsi-streamer s3://my-slides --auth-enabled --auth-secret "$SECRET"

# Generate signed URLs
wsi-streamer sign --path /tiles/slide.svs/0/0/0.jpg --secret "$SECRET" --base-url http://localhost:3000&lt;/code&gt;
    &lt;p&gt;The web viewer handles authentication automatically when enabled.&lt;/p&gt;
    &lt;code&gt;# Check S3 connectivity
wsi-streamer check s3://my-slides

# List available slides
wsi-streamer check s3://my-slides --list-slides

# Test a specific slide
wsi-streamer check s3://my-slides --test-slide sample.svs&lt;/code&gt;
    &lt;p&gt;All options can be set via CLI flags or environment variables:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Env Var&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_HOST&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0.0.0.0&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bind address&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_PORT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3000&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;HTTP port&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-bucket&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_BUCKET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;S3 bucket name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-endpoint&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_ENDPOINT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;Custom S3 endpoint&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-region&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_REGION&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;us-east-1&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;AWS region&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--auth-enabled&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_AUTH_ENABLED&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable authentication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--auth-secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_AUTH_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;HMAC secret key&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--cache-slides&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CACHE_SLIDES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;100&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Max slides in cache&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--cache-tiles&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CACHE_TILES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;100MB&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Tile cache size&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--jpeg-quality&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_JPEG_QUALITY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;80&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JPEG quality (1-100)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--cors-origins&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CORS_ORIGINS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;any&lt;/cell&gt;
        &lt;cell&gt;Allowed CORS origins&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;wsi-streamer --help&lt;/code&gt; for full details.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Endpoint&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /health&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Health check&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /view/{slide_id}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Web viewer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /tiles/{slide_id}/{level}/{x}/{y}.jpg&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fetch tile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List slides&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Slide metadata&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}/thumbnail&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Thumbnail&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}/dzi&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;DZI descriptor&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See API_SPECIFICATIONS.md for complete documentation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Format&lt;/cell&gt;
        &lt;cell role="head"&gt;Extensions&lt;/cell&gt;
        &lt;cell role="head"&gt;Compression&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Aperio SVS&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.svs&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JPEG, JPEG 2000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Pyramidal TIFF&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;.tif&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;JPEG, JPEG 2000&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Files must be tiled (not stripped) and pyramidal.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;January 17th, 2026: front page of Hacker News and Rust subreddit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIT. See LICENSE.&lt;/p&gt;
    &lt;p&gt;Issues and pull requests welcome. See CONTRIBUTING.md.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46656358</guid><pubDate>Sat, 17 Jan 2026 08:46:08 +0000</pubDate></item><item><title>ClickHouse acquires Langfuse</title><link>https://langfuse.com/blog/joining-clickhouse</link><description>&lt;doc fingerprint="2bee90517ddf277e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Langfuse joins ClickHouse&lt;/head&gt;
    &lt;p&gt;Our goal continues to be building the best LLM engineering platform&lt;/p&gt;
    &lt;p&gt;ClickHouse has acquired Langfuse.&lt;/p&gt;
    &lt;p&gt;If you’re reading this as a Langfuse user, your first question is probably: What does this mean for me?&lt;/p&gt;
    &lt;p&gt;Our roadmap stays the same, our goal continues to be building the best LLM engineering platform, and we remain committed to open source and self-hosting. There are no immediate changes to how you use Langfuse and how you can reach out to us.&lt;/p&gt;
    &lt;p&gt;What does change is our ability to move faster. With ClickHouse behind us, we can invest more deeply into performance, reliability, and our roadmap that helps teams build and improve AI applications in production.&lt;/p&gt;
    &lt;head rend="h2"&gt;What stays the same&lt;/head&gt;
    &lt;p&gt;This is the section we would want to read first, too.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Langfuse stays open source and self‑hostable. There are no planned changes to licensing. As you know, we leaned heavily into OSS over the last years.&lt;/item&gt;
      &lt;item&gt;Langfuse Cloud keeps running as‑is. Same product, same endpoints, same experience.&lt;/item&gt;
      &lt;item&gt;Support stays the same. Same channels, same SLAs for existing customers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What gets better now&lt;/head&gt;
    &lt;p&gt;Joining Clickhouse compresses years of operational learning into immediate, real customer benefits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More engineering leverage on the hardest parts. Langfuse is a data‑intensive product. Working closely with the ClickHouse engineering team helps us push performance and reliability.&lt;/item&gt;
      &lt;item&gt;Faster progress on enhanced enterprise-grade compliance and security, with the help of Clickhouse’s resources.&lt;/item&gt;
      &lt;item&gt;Learning from Clickhouse’s customer success and support playbook. This puts us years ahead and allows us to spend more time on what we really care about: our users.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;A quick look back&lt;/head&gt;
    &lt;p&gt;The longer version of how we got here is in our handbook.&lt;/p&gt;
    &lt;p&gt;Langfuse started the same way many LLM products start: we were building agents ourselves. And we constantly ran into the same problems.&lt;/p&gt;
    &lt;p&gt;Building LLM apps is easy to demo and hard to run in production. Debugging is different, quality is non‑deterministic, and the iteration loop is messy. When we did Y Combinator in early 2023, we saw this every week, both in our own projects and in what other founders in our cohort were working on.&lt;/p&gt;
    &lt;p&gt;So we built a duct tape version of what we wished existed: tracing and evaluation primitives that are easy to add, easy to self‑host, and actually useful for iterating.&lt;/p&gt;
    &lt;p&gt;The very first version was intentionally simple. It ran on Postgres, because speed of shipping mattered more than theoretical scaling. That got us to a real product and a real community fast.&lt;/p&gt;
    &lt;p&gt;Then people actually started to use the product more than we could have imagined.&lt;/p&gt;
    &lt;p&gt;As adoption grew, Postgres became the bottleneck for the workloads Langfuse needed to support (high‑throughput ingestion + fast analytical reads). With Langfuse v3, we switched the core data layer to ClickHouse to make Langfuse scale for production workloads, both in Cloud and self‑hosted deployments.&lt;/p&gt;
    &lt;p&gt;And if you like infrastructure deep dives, here’s the v3 migration write‑up.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why join ClickHouse&lt;/head&gt;
    &lt;p&gt;There are a lot of ways this could have gone. We didn’t plan to sell the company. Actually, we had Term Sheets for a great Series A and were looking forward to some days off over Christmas after an intense year.&lt;/p&gt;
    &lt;p&gt;What changed wasn’t our conviction in Langfuse, it was realizing how much faster we can go together with ClickHouse, while staying true to what makes Langfuse work: open source, self-hosting, and a product that’s built for real production workloads.&lt;/p&gt;
    &lt;head rend="h3"&gt;A shared history (before the acquisition)&lt;/head&gt;
    &lt;p&gt;This dialogue didn’t start with a term sheet. Because Langfuse runs on ClickHouse, we naturally ended up collaborating early and often.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We’ve always been closely in touch with many teams at ClickHouse: sharing feedback with the database team, and using new features to make Langfuse more reliable. For example, compute-compute separation helps us to reduce the risk of noisy-neighbours on Langfuse Cloud.&lt;/item&gt;
      &lt;item&gt;Langfuse Cloud is a large customer of ClickHouse Cloud.&lt;/item&gt;
      &lt;item&gt;Teams at ClickHouse use Langfuse to improve their agentic applications.&lt;/item&gt;
      &lt;item&gt;We invested heavily in ClickHouse-backed self-hosting: documentation, templates, and deployment patterns, and collaborated closely with ClickHouse on improving that experience.&lt;/item&gt;
      &lt;item&gt;As a result, Langfuse introduced thousands of teams to ClickHouse when upgrading from Langfuse v2 to v3.&lt;/item&gt;
      &lt;item&gt;We’ve done community meetups together: a ClickHouse meetup at our Berlin office, another one in San Francisco, and an OpenHouse talk in Amsterdam.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Langfuse runs on ClickHouse, ClickHouse uses Langfuse to optimize its agentic products, we share lots of customers and OSS deployments; that gives ClickHouse every incentive to keep Langfuse fast, reliable, and boringly dependable at scale.&lt;/p&gt;
    &lt;p&gt;So in many ways, we operated like long-term partners. This acquisition is a way to make that partnership permanent — and invest aggressively together.&lt;/p&gt;
    &lt;p&gt;Max shared on how we use ClickHouse to keep product performance ahead of demand at ClickHouse Open House (recording) in Amsterdam.&lt;/p&gt;
    &lt;head rend="h3"&gt;Culture and engineering fit&lt;/head&gt;
    &lt;p&gt;The first time we met Aaron, Yury, Alexey, Tanya, Ryadh, and Pete in-person ended up in a long lunch in Amsterdam. It became obvious we share a similar view on building great developer tooling, how that drives everything within our companies, and how fast analytics is increasingly foundational for building and optimizing agentic products.&lt;/p&gt;
    &lt;p&gt;We already knew that ClickHouse is one of the best infrastructure engineering teams in the world. More importantly, the engineering culture feels like an instant match:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;open-source identity and stewardship&lt;/item&gt;
      &lt;item&gt;developer-first product instincts&lt;/item&gt;
      &lt;item&gt;performance and reliability as product features (not afterthoughts)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The whole Langfuse team will join ClickHouse to continue building Langfuse. All of these aspects were important to us and we couldn’t be more excited.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we’re focused on next&lt;/head&gt;
    &lt;p&gt;Our north star doesn’t change: help teams ship useful, reliable agents by closing the loop from production data to better prompts, evaluations, and product decisions.&lt;/p&gt;
    &lt;p&gt;Concretely, we’re investing in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Production monitoring and analytics for real agent systems (not just offline evals).&lt;/item&gt;
      &lt;item&gt;Workflows across tracing, labeling, and experiments so iteration loops get shorter.&lt;/item&gt;
      &lt;item&gt;More performance and scale—especially for large self‑hosted and enterprise deployments.&lt;/item&gt;
      &lt;item&gt;More polish (UI/UX, developer experience, and docs) so the product stays simple even as the space gets more complex.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can always follow along on the public roadmap.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you&lt;/head&gt;
    &lt;p&gt;Langfuse exists because the community pushed it forward, through GitHub issues, PRs, feedback, and lots of Slack messages and spontaneous calls to dig into a product feature together.&lt;/p&gt;
    &lt;p&gt;We’re grateful for the trust you’ve put in us. Joining ClickHouse is our way of honoring that trust by putting more resources behind the thing we care about most: building a product you can rely on.&lt;/p&gt;
    &lt;p&gt;We’re excited for what’s next!&lt;lb/&gt; Max, Clemens, and Marc&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQ&lt;/head&gt;
    &lt;p&gt;Is Langfuse still open source?&lt;lb/&gt;Yes. No licensing changes planned.&lt;/p&gt;
    &lt;p&gt;Can I still self‑host Langfuse?&lt;lb/&gt;Yes. Self‑hosting is a first‑class path.&lt;/p&gt;
    &lt;p&gt;Does anything change for Langfuse Cloud customers today?&lt;lb/&gt;No. Same product, same endpoints, same contracts.&lt;/p&gt;
    &lt;p&gt;Where do I go for support?&lt;lb/&gt;No changes: https://langfuse.com/support&lt;/p&gt;
    &lt;p&gt;Will the Langfuse team stay on Langfuse?&lt;lb/&gt;Yes. The team is joining ClickHouse and will keep building Langfuse. Also, we continue hiring in Berlin and SF.&lt;/p&gt;
    &lt;head rend="h2"&gt;Join the discussion&lt;/head&gt;
    &lt;p&gt;If you have any other questions, let’s discuss together on GitHub Discussions.&lt;/p&gt;
    &lt;p&gt;If you’re an enterprise customer and have additional questions, feel free to reach out to enterprise@langfuse.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46656552</guid><pubDate>Sat, 17 Jan 2026 09:15:45 +0000</pubDate></item><item><title>Show HN: I built a tool to assist AI agents to know when a PR is good to go</title><link>https://dsifry.github.io/goodtogo/</link><description>&lt;doc fingerprint="2764e65f5d9246b2"&gt;
  &lt;main&gt;
    &lt;p&gt;Deterministic PR readiness detection for AI coding agents&lt;/p&gt;
    &lt;p&gt;The missing piece in AI-assisted development: knowing when you’re actually done.&lt;/p&gt;
    &lt;p&gt;AI coding agents are transforming software development. They can write code, fix bugs, respond to review comments, and create pull requests. But they all share one fundamental problem:&lt;/p&gt;
    &lt;p&gt;They can’t reliably know when a PR is ready to merge.&lt;/p&gt;
    &lt;p&gt;Think about it. When you ask an AI agent to “fix the CI and address the review comments,” how does it know when it’s finished?&lt;/p&gt;
    &lt;p&gt;Without deterministic answers, agents either:&lt;/p&gt;
    &lt;p&gt;Good To Go provides a single command that answers the question definitively:&lt;/p&gt;
    &lt;code&gt;gtg 123
&lt;/code&gt;
    &lt;p&gt;That’s it. One command. One answer.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
        &lt;cell role="head"&gt;Meaning&lt;/cell&gt;
        &lt;cell role="head"&gt;What to Do&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;READY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;All clear&lt;/cell&gt;
        &lt;cell&gt;Merge it&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ACTION_REQUIRED&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Comments need fixes&lt;/cell&gt;
        &lt;cell&gt;Address them&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;UNRESOLVED_THREADS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open discussions&lt;/cell&gt;
        &lt;cell&gt;Resolve them&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;CI_FAILING&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Checks not passing&lt;/cell&gt;
        &lt;cell&gt;Fix the build&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;No ambiguity. No guessing. No infinite loops.&lt;/p&gt;
    &lt;p&gt;Good To Go analyzes your PR across three dimensions:&lt;/p&gt;
    &lt;p&gt;Combines all GitHub check runs and commit statuses into a single pass/fail/pending state. Handles the complexity of multiple CI systems, required vs optional checks, and in-progress runs.&lt;/p&gt;
    &lt;p&gt;Not all review comments are created equal. Good To Go classifies each comment as:&lt;/p&gt;
    &lt;p&gt;Built-in parsers understand the patterns of popular automated reviewers:&lt;/p&gt;
    &lt;p&gt;Distinguishes between truly unresolved discussions and threads that are technically “unresolved” but already addressed in subsequent commits.&lt;/p&gt;
    &lt;p&gt;Good To Go is built specifically for how AI agents work:&lt;/p&gt;
    &lt;p&gt;Default mode returns &lt;code&gt;0&lt;/code&gt; for any analyzable state—because AI agents should parse the JSON output, not interpret exit codes as errors.&lt;/p&gt;
    &lt;code&gt;# AI-friendly (default): exit 0 + parse JSON
gtg 123 --format json

# Shell-script friendly: semantic exit codes
gtg 123 -q  # quiet mode, exit code only
&lt;/code&gt;
    &lt;p&gt;Every response includes exactly what an agent needs to take action:&lt;/p&gt;
    &lt;code&gt;{
  "status": "ACTION_REQUIRED",
  "action_items": [
    "Fix CRITICAL comment from coderabbit in src/db.py:42",
    "Resolve thread started by @reviewer in api.py"
  ],
  "actionable_comments": [...],
  "ci_status": {...},
  "threads": {...}
}
&lt;/code&gt;
    &lt;p&gt;Track what’s already been handled across agent sessions:&lt;/p&gt;
    &lt;code&gt;gtg 123 --state-path .goodtogo/state.db  # Remember dismissed comments
gtg 123 --refresh                         # Force fresh analysis
&lt;/code&gt;
    &lt;p&gt;Make &lt;code&gt;gtg&lt;/code&gt; a required status check. PRs can’t merge until they’re truly ready—not just “CI passed.”&lt;/p&gt;
    &lt;code&gt;# .github/workflows/pr-check.yml
- name: Check PR readiness
  run: gtg $ --semantic-codes
&lt;/code&gt;
    &lt;p&gt;Give your AI agent a definitive answer instead of endless polling:&lt;/p&gt;
    &lt;code&gt;result = subprocess.run(["gtg", pr_number, "--format", "json"], ...)
data = json.loads(result.stdout)

if data["status"] == "READY":
    merge_pr()
elif data["status"] == "ACTION_REQUIRED":
    for item in data["action_items"]:
        address_feedback(item)
&lt;/code&gt;
    &lt;p&gt;Monitor a PR through its entire lifecycle:&lt;/p&gt;
    &lt;code&gt;while true; do
  gtg 123 -q
  case $? in
    0) echo "Ready to merge!"; break ;;
    1) handle_comments ;;
    2) resolve_threads ;;
    3) wait_for_ci ;;
  esac
  sleep 60
done
&lt;/code&gt;
    &lt;code&gt;# Install
pip install gtg

# Set your GitHub token
export GITHUB_TOKEN=ghp_...

# Check a PR (auto-detects repo from git origin)
gtg 123

# Explicit repo
gtg 123 --repo owner/repo

# Human-readable output
gtg 123 --format text
&lt;/code&gt;
    &lt;p&gt;Good To Go embeds several opinions about PR workflows:&lt;/p&gt;
    &lt;p&gt; Made with Claude Code&lt;lb/&gt; by David Sifry &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46656759</guid><pubDate>Sat, 17 Jan 2026 09:55:56 +0000</pubDate></item><item><title>Map To Poster – Create Art of your favourite city</title><link>https://github.com/originalankur/maptoposter</link><description>&lt;doc fingerprint="a8f7d87e9ce1dad8"&gt;
  &lt;main&gt;
    &lt;p&gt;Generate beautiful, minimalist map posters for any city in the world.&lt;/p&gt;
    &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;
    &lt;code&gt;python create_map_poster.py --city &amp;lt;city&amp;gt; --country &amp;lt;country&amp;gt; [options]&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Short&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--city&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;-c&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;City name&lt;/cell&gt;
        &lt;cell&gt;required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--country&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;-C&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Country name&lt;/cell&gt;
        &lt;cell&gt;required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--theme&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;-t&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Theme name&lt;/cell&gt;
        &lt;cell&gt;feature_based&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--distance&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;-d&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Map radius in meters&lt;/cell&gt;
        &lt;cell&gt;29000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--list-themes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List all available themes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Iconic grid patterns
python create_map_poster.py -c "New York" -C "USA" -t noir -d 12000           # Manhattan grid
python create_map_poster.py -c "Barcelona" -C "Spain" -t warm_beige -d 8000   # Eixample district

# Waterfront &amp;amp; canals
python create_map_poster.py -c "Venice" -C "Italy" -t blueprint -d 4000       # Canal network
python create_map_poster.py -c "Amsterdam" -C "Netherlands" -t ocean -d 6000  # Concentric canals
python create_map_poster.py -c "Dubai" -C "UAE" -t midnight_blue -d 15000     # Palm &amp;amp; coastline

# Radial patterns
python create_map_poster.py -c "Paris" -C "France" -t pastel_dream -d 10000   # Haussmann boulevards
python create_map_poster.py -c "Moscow" -C "Russia" -t noir -d 12000          # Ring roads

# Organic old cities
python create_map_poster.py -c "Tokyo" -C "Japan" -t japanese_ink -d 15000    # Dense organic streets
python create_map_poster.py -c "Marrakech" -C "Morocco" -t terracotta -d 5000 # Medina maze
python create_map_poster.py -c "Rome" -C "Italy" -t warm_beige -d 8000        # Ancient layout

# Coastal cities
python create_map_poster.py -c "San Francisco" -C "USA" -t sunset -d 10000    # Peninsula grid
python create_map_poster.py -c "Sydney" -C "Australia" -t ocean -d 12000      # Harbor city
python create_map_poster.py -c "Mumbai" -C "India" -t contrast_zones -d 18000 # Coastal peninsula

# River cities
python create_map_poster.py -c "London" -C "UK" -t noir -d 15000              # Thames curves
python create_map_poster.py -c "Budapest" -C "Hungary" -t copper_patina -d 8000  # Danube split

# List available themes
python create_map_poster.py --list-themes&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Distance&lt;/cell&gt;
        &lt;cell role="head"&gt;Best for&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4000-6000m&lt;/cell&gt;
        &lt;cell&gt;Small/dense cities (Venice, Amsterdam center)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;8000-12000m&lt;/cell&gt;
        &lt;cell&gt;Medium cities, focused downtown (Paris, Barcelona)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;15000-20000m&lt;/cell&gt;
        &lt;cell&gt;Large metros, full city view (Tokyo, Mumbai)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;17 themes available in &lt;code&gt;themes/&lt;/code&gt; directory:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Theme&lt;/cell&gt;
        &lt;cell role="head"&gt;Style&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;feature_based&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Classic black &amp;amp; white with road hierarchy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gradient_roads&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Smooth gradient shading&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;contrast_zones&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;High contrast urban density&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;noir&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Pure black background, white roads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;midnight_blue&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Navy background with gold roads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;blueprint&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Architectural blueprint aesthetic&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;neon_cyberpunk&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark with electric pink/cyan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;warm_beige&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Vintage sepia tones&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;pastel_dream&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Soft muted pastels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;japanese_ink&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Minimalist ink wash style&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;forest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Deep greens and sage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ocean&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Blues and teals for coastal cities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;terracotta&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Mediterranean warmth&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;sunset&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Warm oranges and pinks&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;autumn&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Seasonal burnt oranges and reds&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;copper_patina&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Oxidized copper aesthetic&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;monochrome_blue&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Single blue color family&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Posters are saved to &lt;code&gt;posters/&lt;/code&gt; directory with format:&lt;/p&gt;
    &lt;code&gt;{city}_{theme}_{YYYYMMDD_HHMMSS}.png
&lt;/code&gt;
    &lt;p&gt;Create a JSON file in &lt;code&gt;themes/&lt;/code&gt; directory:&lt;/p&gt;
    &lt;code&gt;{
  "name": "My Theme",
  "description": "Description of the theme",
  "bg": "#FFFFFF",
  "text": "#000000",
  "gradient_color": "#FFFFFF",
  "water": "#C0C0C0",
  "parks": "#F0F0F0",
  "road_motorway": "#0A0A0A",
  "road_primary": "#1A1A1A",
  "road_secondary": "#2A2A2A",
  "road_tertiary": "#3A3A3A",
  "road_residential": "#4A4A4A",
  "road_default": "#3A3A3A"
}&lt;/code&gt;
    &lt;code&gt;map_poster/
├── create_map_poster.py          # Main script
├── themes/               # Theme JSON files
├── fonts/                # Roboto font files
├── posters/              # Generated posters
└── README.md
&lt;/code&gt;
    &lt;p&gt;Quick reference for contributors who want to extend or modify the script.&lt;/p&gt;
    &lt;code&gt;┌─────────────────┐     ┌──────────────┐     ┌─────────────────┐
│   CLI Parser    │────▶│  Geocoding   │────▶│  Data Fetching  │
│   (argparse)    │     │  (Nominatim) │     │    (OSMnx)      │
└─────────────────┘     └──────────────┘     └─────────────────┘
                                                     │
                        ┌──────────────┐             ▼
                        │    Output    │◀────┌─────────────────┐
                        │  (matplotlib)│     │   Rendering     │
                        └──────────────┘     │  (matplotlib)   │
                                             └─────────────────┘
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Function&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Modify when...&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;get_coordinates()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;City → lat/lon via Nominatim&lt;/cell&gt;
        &lt;cell&gt;Switching geocoding provider&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;create_poster()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Main rendering pipeline&lt;/cell&gt;
        &lt;cell&gt;Adding new map layers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;get_edge_colors_by_type()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Road color by OSM highway tag&lt;/cell&gt;
        &lt;cell&gt;Changing road styling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;get_edge_widths_by_type()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Road width by importance&lt;/cell&gt;
        &lt;cell&gt;Adjusting line weights&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;create_gradient_fade()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Top/bottom fade effect&lt;/cell&gt;
        &lt;cell&gt;Modifying gradient overlay&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;load_theme()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JSON theme → dict&lt;/cell&gt;
        &lt;cell&gt;Adding new theme properties&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;z=11  Text labels (city, country, coords)
z=10  Gradient fades (top &amp;amp; bottom)
z=3   Roads (via ox.plot_graph)
z=2   Parks (green polygons)
z=1   Water (blue polygons)
z=0   Background color
&lt;/code&gt;
    &lt;code&gt;# In get_edge_colors_by_type() and get_edge_widths_by_type()
motorway, motorway_link     → Thickest (1.2), darkest
trunk, primary              → Thick (1.0)
secondary                   → Medium (0.8)
tertiary                    → Thin (0.6)
residential, living_street  → Thinnest (0.4), lightest&lt;/code&gt;
    &lt;p&gt;New map layer (e.g., railways):&lt;/p&gt;
    &lt;code&gt;# In create_poster(), after parks fetch:
try:
    railways = ox.features_from_point(point, tags={'railway': 'rail'}, dist=dist)
except:
    railways = None

# Then plot before roads:
if railways is not None and not railways.empty:
    railways.plot(ax=ax, color=THEME['railway'], linewidth=0.5, zorder=2.5)&lt;/code&gt;
    &lt;p&gt;New theme property:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Add to theme JSON: &lt;code&gt;"railway": "#FF0000"&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Use in code: &lt;code&gt;THEME['railway']&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Add fallback in &lt;code&gt;load_theme()&lt;/code&gt;default dict&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All text uses &lt;code&gt;transform=ax.transAxes&lt;/code&gt; (0-1 normalized coordinates):&lt;/p&gt;
    &lt;code&gt;y=0.14  City name (spaced letters)
y=0.125 Decorative line
y=0.10  Country name
y=0.07  Coordinates
y=0.02  Attribution (bottom-right)
&lt;/code&gt;
    &lt;code&gt;# Get all buildings
buildings = ox.features_from_point(point, tags={'building': True}, dist=dist)

# Get specific amenities
cafes = ox.features_from_point(point, tags={'amenity': 'cafe'}, dist=dist)

# Different network types
G = ox.graph_from_point(point, dist=dist, network_type='drive')  # roads only
G = ox.graph_from_point(point, dist=dist, network_type='bike')   # bike paths
G = ox.graph_from_point(point, dist=dist, network_type='walk')   # pedestrian&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Large &lt;code&gt;dist&lt;/code&gt;values (&amp;gt;20km) = slow downloads + memory heavy&lt;/item&gt;
      &lt;item&gt;Cache coordinates locally to avoid Nominatim rate limits&lt;/item&gt;
      &lt;item&gt;Use &lt;code&gt;network_type='drive'&lt;/code&gt;instead of&lt;code&gt;'all'&lt;/code&gt;for faster renders&lt;/item&gt;
      &lt;item&gt;Reduce &lt;code&gt;dpi&lt;/code&gt;from 300 to 150 for quick previews&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46656834</guid><pubDate>Sat, 17 Jan 2026 10:13:57 +0000</pubDate></item><item><title>US electricity demand surged in 2025 – solar handled 61% of it</title><link>https://electrek.co/2026/01/16/us-electricity-demand-surged-in-2025-solar-handled-61-percent/</link><description>&lt;doc fingerprint="a910b07712b4d594"&gt;
  &lt;main&gt;
    &lt;p&gt;Solar didn’t just show up in 2025 – it carried the grid. A new analysis from global energy think tank Ember shows that solar power accounted for 61% of the growth in US electricity demand last year, highlighting how central solar has become as power demand accelerates.&lt;/p&gt;
    &lt;p&gt;US electricity demand jumped by 135 terawatt-hours (TWh) in 2025, a 3.1% increase, the fourth‑largest annual rise of the past decade. Over that same period, solar generation grew by a record 83 TWh – a 27% increase from 2024 and the biggest absolute gain of any power source. That single jump in solar output covered 61% of all new electricity demand nationwide.&lt;/p&gt;
    &lt;p&gt;“Solar growth was essential in helping to meet fast‑rising US electricity demand in 2025,” said Dave Jones, chief analyst at Ember. “It generated where it was needed, and – with the surge in batteries – increasingly when it was needed.”&lt;/p&gt;
    &lt;p&gt;Texas, the Midwest, and the Mid‑Atlantic saw the largest increases in solar generation last year, and they were also the regions where electricity demand rose the fastest. Solar met 81% of demand growth in both Texas and the Midwest, and 33% in the Mid‑Atlantic.&lt;/p&gt;
    &lt;p&gt;Timing mattered, too. In aggregate, the increase in solar generation met the entire rise in US electricity demand during daytime hours between 10 am and 6 pm Eastern. And as a result of the rapid buildout of battery storage, solar also helped cover some of the demand growth during the evening hours, from 6 pm to 2 am.&lt;/p&gt;
    &lt;p&gt;The adoption of battery storage is turning solar from cheap daytime power into something far more flexible. Over the past six years, California’s utility‑scale solar and battery generation has climbed 58%. Yet, output at the sunniest hour of the day has increased by just 8%, a sign that more energy is being stored and used later, rather than dumped onto the grid all at once.&lt;/p&gt;
    &lt;p&gt;Most of the new solar generation in 2025 was absorbed by rising electricity demand, allowing solar to scale alongside overall grid growth.&lt;/p&gt;
    &lt;p&gt;“Solar has the potential to meet all the rise in electricity demand and much more. With electricity demand surging, the case to build solar has never been stronger,” said Jones.&lt;/p&gt;
    &lt;p&gt;Read more: EIA: All net new generating capacity in 2026 may be renewables&lt;/p&gt;
    &lt;p&gt;If you’re looking to replace your old HVAC equipment, it’s always a good idea to get quotes from a few installers. To make sure you’re finding a trusted, reliable HVAC installer near you that offers competitive pricing on heat pumps, check out EnergySage. EnergySage is a free service that makes it easy for you to get a heat pump. They have pre-vetted heat pump installers competing for your business, ensuring you get high quality solutions. Plus, it’s free to use!&lt;/p&gt;
    &lt;p&gt;Your personalized heat pump quotes are easy to compare online and you’ll get access to unbiased Energy Advisors to help you every step of the way. Get started here. – *ad&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46656903</guid><pubDate>Sat, 17 Jan 2026 10:28:06 +0000</pubDate></item><item><title>ASCII characters are not pixels: a deep dive into ASCII rendering</title><link>https://alexharri.com/blog/ascii-rendering</link><description>&lt;doc fingerprint="74d7db3c780d01ad"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;ASCII characters are not pixels: a deep dive into ASCII rendering&lt;/head&gt;
    &lt;p&gt;Recently, I’ve been spending my time building an image-to-ASCII renderer. Below is the result — try dragging it around, the demo is interactive!&lt;/p&gt;
    &lt;p&gt;One thing I spent a lot of effort on is getting edges looking sharp. Take a look at this rotating cube example:&lt;/p&gt;
    &lt;p&gt;Try opening the “split” view. Notice how well the characters follow the contour of the square.&lt;/p&gt;
    &lt;p&gt;This renderer works well for animated scenes, like the ones above, but we can also use it to render static images:&lt;/p&gt;
    &lt;p&gt;The image of Saturn was generated with ChatGPT.&lt;/p&gt;
    &lt;p&gt;Then, to get better separation between different colored regions, I also implemented a cel shading-like effect to enhance contrast between edges. Try dragging the contrast slider below:&lt;/p&gt;
    &lt;p&gt;The contrast enhancement makes the separation between different colored regions far clearer. That was key to making the 3D scene above look as good as it does.&lt;/p&gt;
    &lt;p&gt;I put so much focus on sharp edges because they’re an aspect of ASCII rendering that is often overlooked when programmatically rendering images as ASCII. Consider this animated 3D scene from Cognition’s landing page that is rendered via ASCII characters:&lt;/p&gt;
    &lt;p&gt;Source: cognition.ai&lt;/p&gt;
    &lt;p&gt;It’s a cool effect, especially while in motion, but take a look at those blurry edges! The characters follow the cube contours very poorly, and as a result, the edges look blurry and jagged in places:&lt;/p&gt;
    &lt;p&gt;This blurriness happens because the ASCII characters are being treated like pixels — their shape is ignored. It’s disappointing to see because ASCII art looks so much better when shape is utilized. I don’t believe I’ve ever seen shape utilized in generated ASCII art, and I think that’s because it’s not really obvious how to consider shape when building an ASCII renderer.&lt;/p&gt;
    &lt;p&gt;I started building my ASCII renderer to prove to myself that it’s possible to utilize shape in ASCII rendering. In this post, I’ll cover the techniques and ideas I used to capture shape and build this ASCII renderer in detail.&lt;/p&gt;
    &lt;p&gt;We’ll start with the basics of image-to-ASCII conversion and see where the common issue of blurry edges comes from. After that, I’ll show you the approach I used to fix that and achieve sharp, high-quality ASCII rendering. At the end, we’ll improve on that by implementing the contrast enhancement effect I showed above.&lt;/p&gt;
    &lt;p&gt;Let’s get to it!&lt;/p&gt;
    &lt;head rend="h2"&gt;Image to ASCII conversion&lt;/head&gt;
    &lt;p&gt;ASCII contains 95 printable characters that we can use. Let’s start off by rendering the following image containing a white circle using those ASCII characters:&lt;/p&gt;
    &lt;p&gt;ASCII art is (almost) always rendered using a monospace font. Since every character in a monospace font is equally wide and tall, we can split the image into a grid. Each grid cell will contain a single ASCII character.&lt;/p&gt;
    &lt;p&gt;The image with the circle is &lt;/p&gt;
    &lt;p&gt;Monospace characters are typically taller than they are wide, so I made each grid cell a bit taller than it is wide.&lt;/p&gt;
    &lt;p&gt;Our task is now to pick which character to place in each cell. The simplest approach is to calculate a lightness value for each cell and pick a character based on that.&lt;/p&gt;
    &lt;p&gt;We can get a lightness value for each cell by sampling the lightness of the pixel at the cell’s center:&lt;/p&gt;
    &lt;p&gt;We want each pixel’s lightness as a numeric value between &lt;/p&gt;
    &lt;p&gt;We can use the following formula to convert an RGB color (with component values between &lt;/p&gt;
    &lt;p&gt;See relative luminance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mapping lightness values to ASCII characters&lt;/head&gt;
    &lt;p&gt;Now that we have a lightness value for each cell, we want to use those values to pick ASCII characters. As mentioned before, ASCII has 95 printable characters, but let’s start simple with just these characters:&lt;/p&gt;
    &lt;quote&gt;: - # = + @ * % .&lt;/quote&gt;
    &lt;p&gt;We can sort them in approximate density order like so, with lower-density characters to the left, and high-density characters to the right:&lt;/p&gt;
    &lt;quote&gt;. : - = + * # % @&lt;/quote&gt;
    &lt;p&gt;We’ll put these characters in a &lt;code&gt;CHARS&lt;/code&gt; array:&lt;/p&gt;
    &lt;quote&gt;const CHARS = [" ", ".", ":", "-", "=", "+", "*", "#", "%", "@"]&lt;/quote&gt;
    &lt;p&gt;I added space as the first (least dense) character.&lt;/p&gt;
    &lt;p&gt;We can then map lightness values between &lt;/p&gt;
    &lt;quote&gt;function getCharacterFromLightness(lightness: number) {const index = Math.floor(lightness * (CHARS.length - 1));return CHARS[index];}&lt;/quote&gt;
    &lt;p&gt;This maps low lightness values to low-density characters and high lightness values to high-density characters.&lt;/p&gt;
    &lt;p&gt;Rendering the circle from above with this method gives us:&lt;/p&gt;
    &lt;p&gt;That works... but the result is pretty ugly. We seem to always get &lt;code&gt;@&lt;/code&gt; for cells that fall within the circle and a space for cells that fall outside.&lt;/p&gt;
    &lt;p&gt;That is happening because we’ve pretty much just implemented nearest-neighbor downsampling. Let’s see what that means.&lt;/p&gt;
    &lt;head rend="h2"&gt;Nearest neighbor downsampling&lt;/head&gt;
    &lt;p&gt;Downsampling, in the context of image processing, is taking a larger image (in our case, the &lt;/p&gt;
    &lt;p&gt;The simplest and fastest method of sampling is nearest-neighbor interpolation, where, for each cell (pixel), we only take a single sample from the higher resolution image.&lt;/p&gt;
    &lt;p&gt;Consider the circle example again. Using nearest-neighbor interpolation, every sample either falls inside or outside of the shape, resulting in either &lt;/p&gt;
    &lt;p&gt;If, instead of picking an ASCII character for each grid cell, we color each grid cell (pixel) according to the sampled value, we get the following pixelated rendering:&lt;/p&gt;
    &lt;p&gt;This pixelated rendering is pretty much equivalent to the ASCII rendering from before. The only difference is that instead of &lt;code&gt;@&lt;/code&gt;s we have white pixels, and instead of spaces we have black pixels.&lt;/p&gt;
    &lt;p&gt;These square, jagged looking edges are aliasing artifacts, commonly called jaggies. They’re a common result of using nearest-neighbor interpolation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Supersampling&lt;/head&gt;
    &lt;p&gt;To get rid of jaggies, we can collect more samples for each cell. Consider this line:&lt;/p&gt;
    &lt;p&gt;The line’s slope on the &lt;/p&gt;
    &lt;p&gt;Let’s try to get rid of the jagginess by taking multiple samples within each cell and using the average sampled lightness value as the cell’s lightness. The example below lets you vary the number of samples using the slider:&lt;/p&gt;
    &lt;p&gt;With multiple samples, cells that lie on the edge of a shape will have some of their samples fall within the shape, and some outside of it. Averaging those, we get gray in-between colors that smooth the downsampled image. Below is the same example, but with an overlay showing where the samples are taken:&lt;/p&gt;
    &lt;p&gt;This method of collecting multiple samples from the larger image is called supersampling. It’s a common method of spatial anti-aliasing (avoiding jaggies at edges). Here’s what the rotating square looks like with supersampling (using &lt;/p&gt;
    &lt;p&gt;Let’s look at what supersampling does for the circle example from earlier. Try dragging the sample quality slider:&lt;/p&gt;
    &lt;p&gt;The circle becomes less jagged, but the edges feel blurry. Why’s that?&lt;/p&gt;
    &lt;p&gt;Well, they feel blurry because we’re pretty much just rendering a low-resolution, pixelated image of a circle. Take a look at the pixelated view:&lt;/p&gt;
    &lt;p&gt;The ASCII and pixelated views are mirror images of each other. Both are just low-resolution versions of the original high-resolution image, scaled up to the original’s size — it’s no wonder they both look blurry.&lt;/p&gt;
    &lt;p&gt;Increasing the number of samples is insufficient. No matter how many samples we take per cell, the samples will be averaged into a single lightness value, used to render a single pixel.&lt;/p&gt;
    &lt;p&gt;And that’s the core problem: treating each grid cell as a pixel in an image. It’s an obvious and simple method, but it disregards that ASCII characters have shape.&lt;/p&gt;
    &lt;p&gt;We can make our ASCII renderings far more crisp by picking characters based on their shape. Here’s the circle rendered that way:&lt;/p&gt;
    &lt;p&gt;The characters follow the contour of the circle very well. By picking characters based on shape, we get a far higher effective resolution. The result is also more visually interesting.&lt;/p&gt;
    &lt;p&gt;Let’s see how we can implement this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Shape&lt;/head&gt;
    &lt;p&gt;So what do I mean by shape? Well, consider the characters &lt;code&gt;T&lt;/code&gt;, &lt;code&gt;L&lt;/code&gt;, and &lt;code&gt;O&lt;/code&gt; placed within grid cells:&lt;/p&gt;
    &lt;p&gt;The character &lt;code&gt;T&lt;/code&gt; is top-heavy. Its visual density in the upper half of the grid cell is higher than in the lower half. The opposite can be said for &lt;code&gt;L&lt;/code&gt; — it’s bottom-heavy. &lt;code&gt;O&lt;/code&gt; is pretty much equally dense in the upper and lower halves of the cell.&lt;/p&gt;
    &lt;p&gt;We might also compare characters like &lt;code&gt;L&lt;/code&gt; and &lt;code&gt;J&lt;/code&gt;. The character &lt;code&gt;L&lt;/code&gt; is heavier within the left half of the cell, while &lt;code&gt;J&lt;/code&gt; is heavier in the right half:&lt;/p&gt;
    &lt;p&gt;We also have more “extreme” characters, such as &lt;code&gt;_&lt;/code&gt; and &lt;code&gt;^&lt;/code&gt;, that only occupy the lower or upper portion of the cell, respectively:&lt;/p&gt;
    &lt;p&gt;This is, roughly, what I mean by “shape” in the context of ASCII rendering. Shape refers to which regions of a cell a given character visually occupies.&lt;/p&gt;
    &lt;head rend="h3"&gt;Quantifying shape&lt;/head&gt;
    &lt;p&gt;To pick characters based on their shape, we’ll somehow need to quantify (put numbers to) the shape of each character.&lt;/p&gt;
    &lt;p&gt;Let’s start by only considering how much characters occupy the upper and lower regions of our cell. To do that, we’ll define two “sampling circles” for each grid cell — one placed in the upper half and one in the lower half:&lt;/p&gt;
    &lt;p&gt;It may seem odd or arbitrary to use circles instead of just splitting the cell into two rectangles, but using circles will give us more flexibility later on.&lt;/p&gt;
    &lt;p&gt;A character placed within a cell will overlap each of the cell’s sampling circles to some extent.&lt;/p&gt;
    &lt;p&gt;One can compute that overlap by taking a bunch of samples within the circle (for example, at every pixel). The fraction of samples that land inside the character gives us the overlap as a numeric value between &lt;/p&gt;
    &lt;p&gt;For T, we get an overlap of approximately &lt;/p&gt;
    &lt;p&gt;We can generate such a &lt;/p&gt;
    &lt;p&gt;Below are some ASCII characters and their shape vectors. I’m coloring the sampling circles using the component values of the shape vectors:&lt;/p&gt;
    &lt;p&gt;We can use the shape vectors as 2D coordinates — here’s every ASCII character on a 2D plot:&lt;/p&gt;
    &lt;head rend="h3"&gt;Shape-based lookup&lt;/head&gt;
    &lt;p&gt;Let’s say that we have our ASCII characters and their associated shape vectors in a &lt;code&gt;CHARACTERS&lt;/code&gt; array:&lt;/p&gt;
    &lt;quote&gt;const CHARACTERS: Array&amp;lt;{character: string,shapeVector: number[],}&amp;gt; = [...];&lt;/quote&gt;
    &lt;p&gt;We can then perform a nearest neighbor search like so:&lt;/p&gt;
    &lt;quote&gt;function findBestCharacter(inputVector: number[]) {let bestCharacter = "";let bestDistance = Infinity;for (const { character, shapeVector } of CHARACTERS) {const dist = getDistance(shapeVector, inputVector);if (dist &amp;lt; bestDistance) {bestDistance = dist;bestCharacter = character;}}return bestCharacter;}&lt;/quote&gt;
    &lt;p&gt;The &lt;code&gt;findBestCharacter&lt;/code&gt; function gives us the ASCII character whose shape best matches the input lookup vector.&lt;/p&gt;
    &lt;p&gt;Note: this brute force search is not very performant. This becomes a bottleneck when we start rendering thousands of ASCII characters at &lt;/p&gt;
    &lt;p&gt;To make use of this in our ASCII renderer, we’ll calculate a lookup vector for each cell in the ASCII grid and pass it to &lt;code&gt;findBestCharacter&lt;/code&gt; to determine the character to display.&lt;/p&gt;
    &lt;p&gt;Let’s try it out. Consider the following zoomed-in circle as an example. It is split into three grid cells:&lt;/p&gt;
    &lt;p&gt;Overlaying our sampling circles, we see varying degrees of overlap:&lt;/p&gt;
    &lt;p&gt;When calculating the shape vector of each ASCII character, we took a huge number of samples. We could afford to do that because we only need to calculate those shape vectors once up front. After they’re calculated, we can use them again and again.&lt;/p&gt;
    &lt;p&gt;However, if we’re converting an animated image (e.g. canvas or video) to ASCII, we need to be mindful of performance when calculating the lookup vectors. An ASCII rendering might have hundreds or thousands of cells. Multiplying that by tens or hundreds of samples would be incredibly costly in terms of performance.&lt;/p&gt;
    &lt;p&gt;With that being said, let’s pick a sampling quality of &lt;/p&gt;
    &lt;p&gt;For the top sampling circle of the leftmost cell, we get one white sample and two black, giving us an average lightness of &lt;/p&gt;
    &lt;p&gt;From now on, instead of using the term “lookup vectors”, I’ll call these vectors, sampled from the image that we’re rendering as ASCII, sampling vectors. One sampling vector is calculated for each cell in the grid.&lt;/p&gt;
    &lt;p&gt;Anyway, we can use these sampling vectors to find the best-matching ASCII character. Let’s see what that looks like on our 2D plot — I’ll label the sampling vectors (from left to right) C0, C1, and C2:&lt;/p&gt;
    &lt;p&gt;Hmm... this is not what we want. Since none of the ASCII shape vector components exceed &lt;/p&gt;
    &lt;p&gt;We can fix this by normalizing the shape vectors. We’ll do that by taking the maximum value of each component across all shape vectors, and dividing the components of each shape vector by the maximum. Expressed in code, that looks like so:&lt;/p&gt;
    &lt;quote&gt;const max = [0, 0]for (const vector of characterVectors) {for (const [i, value] of Object.entries(vector)) {if (value &amp;gt; max[i]) {max[i] = value;}}}const normalizedCharacterVectors = characterVectors.map(vector =&amp;gt; vector.map((value, i) =&amp;gt; value / max[i]))&lt;/quote&gt;
    &lt;p&gt;Here’s what the plot looks like with the shape vectors normalized:&lt;/p&gt;
    &lt;p&gt;If we now map the sampling vectors to their nearest neighbors, we get a much more sensible result:&lt;/p&gt;
    &lt;p&gt;We get &lt;code&gt;'&lt;/code&gt;, &lt;code&gt;M&lt;/code&gt; and &lt;code&gt;$&lt;/code&gt;.  Let’s see how well those characters match the circle:&lt;/p&gt;
    &lt;p&gt;Nice! They match very well.&lt;/p&gt;
    &lt;p&gt;Let’s try rendering the full circle from before with the same method:&lt;/p&gt;
    &lt;p&gt;Much better than before! The picked characters follow the contour of the circle very well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limits of a 2D shape vector&lt;/head&gt;
    &lt;p&gt;Using two sampling circles — one upper and one lower — produces a much better result than the &lt;/p&gt;
    &lt;p&gt;For example, two circles don’t capture the shape of characters that fall in the middle of the cell. Consider &lt;code&gt;-&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;-&lt;/code&gt;, we get a shape vector of &lt;/p&gt;
    &lt;p&gt;The two upper-lower sampling circles also don’t capture left-right differences, such as the difference between &lt;code&gt;p&lt;/code&gt; and &lt;code&gt;q&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;We could use such differences to get better character picks, but our two sampling circles don’t capture them. Let’s add more dimensions to our shape to fix that.&lt;/p&gt;
    &lt;head rend="h2"&gt;Increasing to 6 dimensions&lt;/head&gt;
    &lt;p&gt;Since cells are taller than they are wide (at least with the monospace font I’m using), we can use &lt;/p&gt;
    &lt;p&gt;&lt;code&gt;p&lt;/code&gt; and &lt;code&gt;q&lt;/code&gt;, while also capturing differences across the top, bottom, and middle regions of the cell, differentiating &lt;code&gt;^&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, and &lt;code&gt;_&lt;/code&gt;. They also capture the shape of “diagonal” characters like &lt;code&gt;/&lt;/code&gt; to a reasonable degree.&lt;/p&gt;
    &lt;p&gt;One problem with this grid-like configuration for the sampling circles is that there are gaps. For example, &lt;code&gt;.&lt;/code&gt; falls between the sampling circles:&lt;/p&gt;
    &lt;p&gt;To compensate for this, we can stagger the sampling circles vertically (e.g. lowering the left sampling circles and raising the right ones) and make them a bit larger. This causes the cell to be almost fully covered while not causing excessive overlap across the sampling circles:&lt;/p&gt;
    &lt;p&gt;We can use the same procedure as before to generate character vectors using these sampling circles, this time yielding a &lt;code&gt;L&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;L&lt;/code&gt;, we get the vector:&lt;/p&gt;
    &lt;p&gt;I’m presenting &lt;/p&gt;
    &lt;p&gt;The lightness values certainly look L-shaped! The 6D shape vector captures &lt;code&gt;L&lt;/code&gt;’s shape very well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nearest neighbor lookups in a 6D space&lt;/head&gt;
    &lt;p&gt;Now we have a 6D shape vector for every ASCII character. Does that affect character lookups (how we find the best matching character)?&lt;/p&gt;
    &lt;p&gt;Earlier, in the &lt;code&gt;findBestCharacter&lt;/code&gt; function, I referenced a &lt;code&gt;getDistance&lt;/code&gt; function. That function returns the Euclidean distance between the input points. Given two 2D points &lt;/p&gt;
    &lt;p&gt;This generalizes to higher dimensions:&lt;/p&gt;
    &lt;p&gt;Put into code, this looks like so:&lt;/p&gt;
    &lt;quote&gt;function getDistance(a: number[], b: number[]): number {let sum = 0;for (let i = 0; i &amp;lt; a.length; i++) {sum += (a[i] - b[i]) ** 2;}return Math.sqrt(sum);}&lt;/quote&gt;
    &lt;p&gt;Note: since we’re just using this for the purposes of finding the closest point, we can skip the expensive &lt;code&gt;Math.sqrt()&lt;/code&gt; call and just return the squared distance. It does not affect the result.&lt;/p&gt;
    &lt;p&gt;So, no, the dimensionality of our shape vector does not change lookups at all. We can use the same &lt;code&gt;getDistance&lt;/code&gt; function for both 2D and 6D.&lt;/p&gt;
    &lt;p&gt;With that out of the way, let’s see what the 6D approach yields!&lt;/p&gt;
    &lt;head rend="h3"&gt;Trying out the 6D approach&lt;/head&gt;
    &lt;p&gt;Our new 6D approach works really well for flat shapes, like the circle example we’ve been using:&lt;/p&gt;
    &lt;p&gt;Now let’s see how this approach works when we render a 3D scene with more shades of gray:&lt;/p&gt;
    &lt;p&gt;Firstly, the outer contours look nice and sharp. I also like how well the gradients across the sphere and cone look.&lt;/p&gt;
    &lt;p&gt;However, internally, the objects all kind of blend together. The edges between surfaces with different lightnesses aren’t sharp enough. For example, the lighter faces of the cubes all kind of blend into one solid color. When there is a change in color — like when two faces of a cube meet — I’d like to see more sharpness in the ASCII rendering.&lt;/p&gt;
    &lt;p&gt;To demonstrate what I mean, consider the following split:&lt;/p&gt;
    &lt;p&gt;It’s currently rendered like so:&lt;/p&gt;
    &lt;p&gt;The different shades result in &lt;code&gt;i&lt;/code&gt;s on the left and &lt;code&gt;B&lt;/code&gt;s on the right, but the boundary is not very sharp.&lt;/p&gt;
    &lt;p&gt;By applying some effects to the sampling vector, we can enhance the contrast at the boundary so that it appears sharper:&lt;/p&gt;
    &lt;p&gt;The added contrast makes a big difference in readability for the 3D scene. Let’s look at how we can implement this contrast enhancement effect.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contrast enhancement&lt;/head&gt;
    &lt;p&gt;Consider cells overlapping a color boundary like so:&lt;/p&gt;
    &lt;p&gt;For the cells on the boundary, we get a 6D sampling vector that looks like so:&lt;/p&gt;
    &lt;p&gt;To make future examples easier to visualize, I’ll start drawing the sampling vector using &lt;/p&gt;
    &lt;p&gt;Currently, this sampling vector resolves to the character &lt;code&gt;T&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;That’s a sensible choice. The character &lt;code&gt;T&lt;/code&gt; is visually dense in the top half and less so in the bottom half, so it matches the image fairly well.&lt;/p&gt;
    &lt;p&gt;Still, I want the picked character to emphasize the shape of the boundary better. We can achieve that by enhancing the contrast of the sampling vector.&lt;/p&gt;
    &lt;p&gt;To increase the contrast of our sampling vector, we might raise each component of the vector to the power of some exponent.&lt;/p&gt;
    &lt;p&gt;Consider how an exponent affects values between &lt;/p&gt;
    &lt;p&gt;The level of pull depends on the exponent. Here’s a chart of &lt;/p&gt;
    &lt;p&gt;This effect becomes more pronounced with higher exponents:&lt;/p&gt;
    &lt;p&gt;A higher exponent translates to a stronger pull towards zero.&lt;/p&gt;
    &lt;p&gt;Applying an exponent should make dark values darker more quickly than light ones. The example below allows you to vary the exponent applied to the sampling vector:&lt;/p&gt;
    &lt;p&gt;As the exponent is increased to &lt;/p&gt;
    &lt;p&gt;I don’t want that. I want to increase the contrast between the lighter and darker components of the sampling vector, not the vector in its entirety.&lt;/p&gt;
    &lt;p&gt;To achieve that, we can normalize the sampling vector to the range &lt;/p&gt;
    &lt;p&gt;The normalization to &lt;/p&gt;
    &lt;quote&gt;const maxValue = Math.max(...samplingVector)samplingVector = samplingVector.map((value) =&amp;gt; {value = x / maxValue; // Normalizevalue = Math.pow(x, exponent);value = x * maxValue; // Denormalizereturn value;})&lt;/quote&gt;
    &lt;p&gt;Here’s the same example, but with this normalization applied:&lt;/p&gt;
    &lt;p&gt;Very nice! The lightest component values are retained, and the contrast between the lighter and darker components is increased by “crunching” the lower values.&lt;/p&gt;
    &lt;p&gt;This affects which character is picked. The following example shows how the selected character changes as the contrast is increased:&lt;/p&gt;
    &lt;p&gt;Awesome! The pick of &lt;code&gt;"&lt;/code&gt; over &lt;code&gt;T&lt;/code&gt; emphasizes the separation between the lighter region above and the darker region below!&lt;/p&gt;
    &lt;p&gt;By enhancing the contrast of the sampling vector, we exaggerate its shape. This gives us a character that less faithfully represents the underlying image, but improves readability as a whole by enhancing the separation between different colored regions.&lt;/p&gt;
    &lt;p&gt;Let’s look at another example. Observe how the L-shape of the sampling vector below becomes more pronounced as the exponent increases, and how that affects the picked character:&lt;/p&gt;
    &lt;p&gt;Works really nicely! I love the transition from &lt;code&gt;&amp;amp; -&amp;gt; b -&amp;gt; L&lt;/code&gt; as the L-shape of the vector becomes clearer.&lt;/p&gt;
    &lt;p&gt;What’s nice about applying exponents to normalized sampling vectors is that it barely affects vectors that are uniform in value. If all component values are similar, applying an exponent has a minimal effect:&lt;/p&gt;
    &lt;p&gt;Because the vector is fairly uniform, the exponent only has a slight effect and doesn’t change the picked character.&lt;/p&gt;
    &lt;p&gt;This is a good thing! If we have a smooth gradient in our image, we want to retain it. We very much do not want to introduce unnecessary choppiness.&lt;/p&gt;
    &lt;p&gt;Compare the 3D scene ASCII rendering with and without this contrast enhancement:&lt;/p&gt;
    &lt;p&gt;We do see more contrast at boundaries, but this is not quite there yet. Some edges are still not sharp enough, and we also observe a “staircasing” effect happening at some boundaries.&lt;/p&gt;
    &lt;p&gt;Let’s look at the staircasing effect first. We can reproduce it with a boundary like so:&lt;/p&gt;
    &lt;p&gt;Below is the ASCII rendering of that boundary. Notice how the lower edge (the &lt;code&gt;!&lt;/code&gt;s) becomes “staircase-y” as you increase the exponent:&lt;/p&gt;
    &lt;p&gt;We see a staircase pattern like so:&lt;/p&gt;
    &lt;quote&gt;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&lt;/quote&gt;
    &lt;p&gt;To understand why that’s happening, let’s consider the row in the middle of the canvas, progressing from left to right. As we start off, every sample is equally light, giving us &lt;code&gt;U&lt;/code&gt;s:&lt;/p&gt;
    &lt;quote&gt;UUUUUUUU -&amp;gt;&lt;/quote&gt;
    &lt;p&gt;As we reach the boundary, the lower right samples become a bit darker. Those darker components are crunched by contrast enhancement, giving us some &lt;code&gt;Y&lt;/code&gt;s:&lt;/p&gt;
    &lt;p&gt;So we get:&lt;/p&gt;
    &lt;quote&gt;UUUUUUUUYY -&amp;gt;&lt;/quote&gt;
    &lt;p&gt;As we progress further right, the middle and lower samples get darker, so we get some &lt;code&gt;f&lt;/code&gt;s:&lt;/p&gt;
    &lt;p&gt;This trend continues towards &lt;code&gt;"&lt;/code&gt;, &lt;code&gt;'&lt;/code&gt;, and finally, &lt;code&gt;`&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Giving us a sequence like so:&lt;/p&gt;
    &lt;quote&gt;UUUUUUUUYYf""''` -&amp;gt;&lt;/quote&gt;
    &lt;p&gt;That looks good, but at some point we get no light samples. Once we get no light samples, our contrast enhancement has no effect because every component is equally light. This causes us to always get &lt;code&gt;!&lt;/code&gt;s:&lt;/p&gt;
    &lt;p&gt;Making our sequence look like so:&lt;/p&gt;
    &lt;quote&gt;UUUUUUUUYYf""''`!!!!!!!!!! -&amp;gt;&lt;/quote&gt;
    &lt;p&gt;This sudden stop in contrast enhancement having an effect is what causes the staircasing effect:&lt;/p&gt;
    &lt;quote&gt;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&lt;/quote&gt;
    &lt;p&gt;Let’s see how we can counteract this staircasing effect with another layer of contrast enhancement, this time looking outside of the boundary of each cell.&lt;/p&gt;
    &lt;head rend="h3"&gt;Directional contrast enhancement&lt;/head&gt;
    &lt;p&gt;We currently have sampling circles arranged like so:&lt;/p&gt;
    &lt;p&gt;For each of those sampling circles, we’ll specify an “external sampling circle”, placed outside of the cell’s boundary, like so:&lt;/p&gt;
    &lt;p&gt;Each of those external sampling circles is “reaching” into the region of a neighboring cell. Together, the samples that are collected by the external sampling circles constitute an “external sampling vector”.&lt;/p&gt;
    &lt;p&gt;Let’s simplify the visualization and consider a single example. Imagine that we collected a sampling vector and an external sampling vector that look like so:&lt;/p&gt;
    &lt;p&gt;The circles colored red are the external sampling vector components. Currently, they have no effect.&lt;/p&gt;
    &lt;p&gt;The “internal” sampling vector itself is fairly uniform, with values ranging from &lt;/p&gt;
    &lt;p&gt;To enhance this apparent boundary, we’ll darken the top-left and middle-left components of the sampling vector. We can do that by applying component-wise contrast enhancement using the values from the external vector.&lt;/p&gt;
    &lt;p&gt;In the previous contrast enhancement, we calculated the maximum component value across the sampling vector and normalized the vector using that value:&lt;/p&gt;
    &lt;quote&gt;const maxValue = Math.max(...samplingVector)samplingVector = samplingVector.map((value) =&amp;gt; {value = x / maxValue; // Normalizevalue = Math.pow(x, exponent);value = x * maxValue; // Denormalizereturn value;})&lt;/quote&gt;
    &lt;p&gt;But the new component-wise contrast enhancement will take the maximum value between each component of the sampling vector and the corresponding component in the external sampling vector:&lt;/p&gt;
    &lt;quote&gt;samplingVector = samplingVector.map((value, i) =&amp;gt; {const maxValue = Math.max(value, externalSamplingVector[i])// ...});&lt;/quote&gt;
    &lt;p&gt;Aside from that, the contrast enhancement is performed in the same way:&lt;/p&gt;
    &lt;quote&gt;samplingVector = samplingVector.map((value, i) =&amp;gt; {const maxValue = Math.max(value, externalSamplingVector[i]);value = value / maxValue;value = Math.pow(value, exponent);value = value * maxValue;return value;});&lt;/quote&gt;
    &lt;p&gt;The example below shows how light values in the external sampling vector push values in the sampling vector down:&lt;/p&gt;
    &lt;p&gt;I call this “directional contrast enhancement”, since each of the external sampling circles reaches outside of the cell in the direction of the sampling vector component that it is enhancing the contrast of. I describe the other effect as “global contrast enhancement” since it acts on all of the sampling vector’s components together.&lt;/p&gt;
    &lt;p&gt;Let’s see what this directional contrast enhancement does to get rid of the staircasing effect:&lt;/p&gt;
    &lt;p&gt;Hmm, that’s not doing what I wanted. I wanted to see a sequence like so:&lt;/p&gt;
    &lt;quote&gt;..::!!..::!!!!!!!!..::!!!!!!!!!!!!!!&lt;/quote&gt;
    &lt;p&gt;But we just see &lt;code&gt;!&lt;/code&gt; changing to &lt;code&gt;:&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;This happens because the directional contrast enhancement doesn’t reach far enough into our sampling vector. The light upper values in the external vector do push the upper values of the sampling vector down, but because the lightness of the four bottom components is retained, we don’t get to &lt;code&gt;.&lt;/code&gt;, just &lt;code&gt;:&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Widening the directional contrast enhancement&lt;/head&gt;
    &lt;p&gt;I’d like to “widen” the directional contrast enhancement so that, for example, light external values at the top spread to the middle components of the sampling vector.&lt;/p&gt;
    &lt;p&gt;To do that, I’ll introduce a few more external sampling circles, arranged like so:&lt;/p&gt;
    &lt;p&gt;These are a total of &lt;/p&gt;
    &lt;p&gt;For each component of the internal sampling vector, we’ll calculate the maximum value across the external sampling vector components that affect it, and use that maximum to perform the contrast enhancement.&lt;/p&gt;
    &lt;p&gt;Let’s implement that. I’ll order the internal and external sampling circles like so:&lt;/p&gt;
    &lt;p&gt;We can then define a mapping from the internal circles to the external sampling circles that affect them:&lt;/p&gt;
    &lt;quote&gt;const AFFECTING_EXTERNAL_INDICES = [[0, 1, 2, 4],[0, 1, 3, 5],[2, 4, 6],[3, 5, 7],[4, 6, 8, 9],[5, 7, 8, 9],];&lt;/quote&gt;
    &lt;p&gt;With this, we can change the calculation of &lt;code&gt;maxValue&lt;/code&gt; to take the maximum affecting external value:&lt;/p&gt;
    &lt;quote&gt;// Beforeconst maxValue = Math.max(value, externalSamplingVector[i]);// Afterlet maxValue = value;for (const externalIndex of AFFECTING_EXTERNAL_INDICES[i]) {maxValue = Math.max(value, externalSamplingVector[externalIndex]);}&lt;/quote&gt;
    &lt;p&gt;Now look what happens if the top four external sampling circles are light: it causes the contrast enhancement to reach into the middle of the sampling vector, giving us the desired effect:&lt;/p&gt;
    &lt;p&gt;We now smoothly transition from &lt;code&gt;! -&amp;gt; : -&amp;gt; .&lt;/code&gt; — beautiful stuff!&lt;/p&gt;
    &lt;p&gt;Let’s see if this change resolves the staircasing effect:&lt;/p&gt;
    &lt;p&gt;Oh yeah, looks awesome! We get the desired effect. The boundary is nice and sharp while not being too jagged.&lt;/p&gt;
    &lt;p&gt;Here’s the 3D scene again. The contrast slider now applies both types of contrast enhancement at the same time — try it out:&lt;/p&gt;
    &lt;p&gt;This really enhances the contrast at boundaries, making the image far more readable!&lt;/p&gt;
    &lt;p&gt;Together, the 6D shape vector approach and contrast enhancement techniques have given us a really nice final ASCII rendering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final words&lt;/head&gt;
    &lt;p&gt;This post was really fun to build and write! I hope you enjoyed reading it.&lt;/p&gt;
    &lt;p&gt;ASCII rendering is perhaps not the most useful topic to write about, but I think the idea of using a high-dimensional vector to capture shape is interesting and could easily be applied to many other problems. There are parallels to be drawn to word embeddings.&lt;/p&gt;
    &lt;p&gt;I started writing this ASCII renderer to see if the idea of using a vector to capture the shape of characters would work at all. That approach turned out to work very well, but the initial prototype was terribly slow — I only got single-digit FPS on my iPhone. To get the ASCII renderer running at a smooth &lt;/p&gt;
    &lt;p&gt;My colleagues, after reading a draft of this post, suggested many alternatives to the approaches I described in this post. For example, why not make the sampling vector &lt;code&gt;T&lt;/code&gt; far better — just look how &lt;code&gt;T&lt;/code&gt;’s stem falls between the two sampling circles in each row:&lt;/p&gt;
    &lt;p&gt;And yeah, he’s right! A &lt;/p&gt;
    &lt;p&gt;It’s really fun how large the solution space to the problem of ASCII rendering is. There are so, so many approaches and trade-offs to explore. I imagine you probably thought of a few yourself while reading this post!&lt;/p&gt;
    &lt;p&gt;One dimension I intentionally did not explore was using different colors or lightnesses for the ASCII characters themselves. This is for many reasons, but the two primary ones are that 1) it would have expanded the scope of this post too much, and 2) it’s just a different effect, and I personally don’t like the look.&lt;/p&gt;
    &lt;p&gt;At the time of writing these final words, around &lt;/p&gt;
    &lt;p&gt;Thanks for reading! And huge thanks to Gunnlaugur Þór Briem and Eiríkur Fannar Torfason for reading and providing feedback on a draft of this post.&lt;/p&gt;
    &lt;p&gt;— Alex Harri&lt;/p&gt;
    &lt;p&gt;To be notified of new posts, subscribe to my mailing list.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix I: Character lookup performance&lt;/head&gt;
    &lt;p&gt;Earlier in this post, I showed how can find the best character by finding the character with the shortest Euclidean distance to our sampling vector.&lt;/p&gt;
    &lt;quote&gt;function findBestCharacter(inputVector: number[]) {let bestCharacter = "";let bestDistance = Infinity;for (const { character, shapeVector } of CHARACTERS) {const dist = getDistance(shapeVector, inputVector);if (dist &amp;lt; bestDistance) {bestDistance = dist;bestCharacter = character;}}return bestCharacter;}&lt;/quote&gt;
    &lt;p&gt;I tried benchmarking this for &lt;/p&gt;
    &lt;p&gt;If we allow ourselves &lt;/p&gt;
    &lt;head rend="h3"&gt;k-d trees&lt;/head&gt;
    &lt;p&gt;Internally, &lt;/p&gt;
    &lt;p&gt;I won’t go into much detail on &lt;/p&gt;
    &lt;p&gt;One could also look at the hierarchical navigable small worlds (HNSW) algorithm, which Eiríkur pointed me to. It is used for approximate nearest neighbor lookups in vector databases, so definitely relevant.&lt;/p&gt;
    &lt;p&gt;Let’s see how it performs! We’ll construct a &lt;/p&gt;
    &lt;quote&gt;const kdTree = new KdTree(CHARACTERS.map(({ character, shapeVector }) =&amp;gt; ({point: shapeVector,data: character,})));&lt;/quote&gt;
    &lt;p&gt;We can now perform nearest-neighbor lookups on the &lt;/p&gt;
    &lt;quote&gt;const result = kdTree.findNearest(samplingVector);&lt;/quote&gt;
    &lt;p&gt;Running &lt;/p&gt;
    &lt;p&gt;That’s a lot of lookups per frame, but again, we’re benchmarking on a powerful machine. This is still not good enough.&lt;/p&gt;
    &lt;p&gt;Let’s see how we can eke out even more performance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Caching&lt;/head&gt;
    &lt;p&gt;An obvious avenue for speeding up lookups is to cache the result:&lt;/p&gt;
    &lt;quote&gt;function searchCached(samplingVector: number[]) {const key = generateCacheKey(samplingVector)if (cache.has(key)) {return cache.get(key)!;}const result = search(samplingVector);cache.set(key, result);return result;}&lt;/quote&gt;
    &lt;p&gt;But how does one generate a cache key for a &lt;/p&gt;
    &lt;p&gt;Well, one way is to quantize each vector component so that it fits into a set number of bits and packing those bits into a single number. JavaScript numbers give us &lt;/p&gt;
    &lt;p&gt;We can quantize a numeric value between &lt;/p&gt;
    &lt;quote&gt;const BITS = 5;const RANGE = 2 ** BITS;function quantizeTo5Bits(value: number) {return Math.min(RANGE - 1, Math.floor(value * RANGE));}&lt;/quote&gt;
    &lt;p&gt;Applying a max of &lt;code&gt;RANGE - 1&lt;/code&gt; is done so that a &lt;code&gt;value&lt;/code&gt; of exactly &lt;/p&gt;
    &lt;p&gt;We can quantize each of the sampling vector components in this manner and use bit shifting to pack all of the quantized values into a single number like so:&lt;/p&gt;
    &lt;quote&gt;const BITS = 5;const RANGE = 2 ** BITS;function generateCacheKey(vector: number[]): number {let key = 0;for (let i = 0; i &amp;lt; vector.length; i++) {const quantized = Math.min(RANGE - 1, Math.floor(vector[i] * RANGE));key = (key &amp;lt;&amp;lt; BITS) | quantized;}return key;}&lt;/quote&gt;
    &lt;p&gt;The &lt;code&gt;RANGE&lt;/code&gt; is current set to &lt;code&gt;2 ** 5&lt;/code&gt;, but consider how large that makes our key space. Each vector component is one of &lt;/p&gt;
    &lt;p&gt;Alright, &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
        &lt;cell role="head"&gt;Number of keys&lt;/cell&gt;
        &lt;cell role="head"&gt;Memory needed to store keys&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;46,656&lt;/cell&gt;
        &lt;cell&gt;364 KB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;117,649&lt;/cell&gt;
        &lt;cell&gt;919 KB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;262,144&lt;/cell&gt;
        &lt;cell&gt;2.00 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;531,441&lt;/cell&gt;
        &lt;cell&gt;4.05 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;1,000,000&lt;/cell&gt;
        &lt;cell&gt;7.63 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;1,771,561&lt;/cell&gt;
        &lt;cell&gt;13.52 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;2,985,984&lt;/cell&gt;
        &lt;cell&gt;22.78 MB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There are trade-offs to consider here. As the range gets smaller, the quality of the results drops. If we pick a range of &lt;/p&gt;
    &lt;p&gt;At the same time, if we increase the possible number of keys, we need more memory to store them. Additionally, the cache hit rate might be very low, especially when the cache is relatively empty.&lt;/p&gt;
    &lt;p&gt;I ended up picking a range of &lt;/p&gt;
    &lt;p&gt;Cached lookups are incredibly fast — fast enough that lookup performance just isn’t a concern anymore (&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix II: GPU acceleration&lt;/head&gt;
    &lt;p&gt;Lookups were not the only performance concern. Just collecting the sampling vectors (internal and external) turned out to be terribly expensive.&lt;/p&gt;
    &lt;p&gt;Just consider the sheer amount of samples that need to be collected. The 3D scene I’ve been using as an example uses a &lt;/p&gt;
    &lt;p&gt;And that’s if we use a sampling quality of &lt;/p&gt;
    &lt;p&gt;Collecting these samples absolutely crushed performance on my iPhone, so I needed to either collect fewer samples or speed up the collection of samples. Collecting fewer samples would have meant rendering fewer ASCII characters or removing the directional contrast enhancement, neither of which was an appealing solution.&lt;/p&gt;
    &lt;p&gt;My initial implementation ran on the CPU, which could only collect one sample at a time. To speed this up, I moved the work of sampling collection and applying the contrast enhancement to the GPU. The pipeline for that looks like so (each of the steps listed is a single shader pass):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Collect the raw internal sampling vectors into a &lt;mjx-container/&gt;texture, using the canvas (image) as the input texture.&lt;/item&gt;
      &lt;item&gt;Do the same for the external sampling vectors.&lt;/item&gt;
      &lt;item&gt;Calculate the maximum external value affecting each internal vector component into a &lt;mjx-container/&gt;texture.&lt;/item&gt;
      &lt;item&gt;Apply directional contrast enhancement to each sampling vector component, using the maximum external values texture.&lt;/item&gt;
      &lt;item&gt;Calculate the maximum value for each internal sampling vector into a &lt;mjx-container/&gt;texture.&lt;/item&gt;
      &lt;item&gt;Apply global contrast enhancement to each sampling vector component, using the maximum internal values texture.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m glossing over the details because I could spend a whole other post covering them, but moving work to the GPU made the renderer many times more performant than it was when everything ran on the CPU.&lt;/p&gt;
    &lt;p&gt;To be notified of new posts, subscribe to my mailing list.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46657122</guid><pubDate>Sat, 17 Jan 2026 11:15:26 +0000</pubDate></item><item><title>The 600-year-old origins of the word 'hello'</title><link>https://www.bbc.com/culture/article/20260113-hello-hiya-aloha-what-our-greetings-reveal</link><description>&lt;doc fingerprint="b2309d8d8fa112dc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;'Hullo, hillo, holla': The 600-year-old origins of the word 'hello'&lt;/head&gt;
    &lt;p&gt;It's been 200 years since the word "hello" was first used in print – though its beginnings date back to the 15th Century. How has the language of greetings evolved around the world - and what does it tell us about ourselves?&lt;/p&gt;
    &lt;p&gt;We use "hello" dozens of times a day without thinking – during phone calls, emails and face-to-face encounters. We sing it along with Adele and Lionel Richie, and we have watched it spun into moments of screen gold in Jerry Maguire ("You had me at hello"), and Scarface ("Say hello to my little friend!"). It's been used to sell everything from mobile phones (Motorola's "Hello, Moto") to lingerie (Wonderbra's iconic "Hello boys"), and it has been borrowed to name computer programs and celebrity magazines.&lt;/p&gt;
    &lt;p&gt;In print, this ubiquitous, friendly greeting has a surprisingly short history. Two centuries ago, on 18 January 1826, "hello" made what is thought to be its earliest recorded appearance on the page, in a Connecticut newspaper called The Norwich Courier. Hidden among the column inches, it was a modest in-ink debut for a word that would go on to greet much of the modern world.&lt;/p&gt;
    &lt;p&gt;By the 1850s, it had crossed the Atlantic to Britain – appearing in publications such as the London Literary Gazette – and became increasingly common in print. Like the go-to greetings in other languages, "hello" also says something about the English-speaking world – depending on which variation, abbreviation or inflection of the word we choose to use.&lt;/p&gt;
    &lt;p&gt;There are plenty of such forms. Whether due to dialect or accent influences, or the brevity demanded by online communication, which "hello" you choose says a lot about you, and can indicate age, nationality, or even mood. According to linguists, elongated variations such as "heyyy" could be construed as flirtatious, "hellaw" might suggest you're from the southern US, "howdy" from western US, and the clipped "hi" may indicate a curt disposition.&lt;/p&gt;
    &lt;p&gt;"It can be pronounced and inflected in many different ways, and these subtle intonational contours can change its meaning," says Alessandro Duranti, professor of linguistic anthropology at the University of California, Los Angeles. "For example, when someone says 'hello' with a stretched final vowel, it can question what the other person just said, as in 'Hello, are you paying attention?' or 'Hello, you must be kidding.'"&lt;/p&gt;
    &lt;p&gt;This capacity to convey nuance through tone and form is no modern invention; even in its first printed appearances, "hello" was a patchwork of influences, derivations and applications drawn from several languages.&lt;/p&gt;
    &lt;head rend="h2"&gt;The origins of hello&lt;/head&gt;
    &lt;p&gt;The pre-printed origins of the word "hello" are disputed. The most commonly cited etymology is the Old High German "halâ" – a cry historically used to hail a ferryman. The Oxford English Dictionary also points to "halloo" (a hunting call that urged hounds to run faster) as a possible linguistic root. It notes several early spellings, including "hullo", "hillo" and "holla" – the latter thought to have derived from the 15th-Century French "hol", an exclamation meaning "whoa!" or "stop!". In English sources, the OED lists the earliest form as the late-16th-Century "hollo".&lt;/p&gt;
    &lt;p&gt;Simon Horobin, professor of English language and literature at Magdelen College, Oxford, notes that such semantic shifts and spelling changes may also be explained by regional accents and differences in pronunciation. "Especially in the example of 'ello' which shows the prevalent – though now stigmatised – feature of h-dropping," he tells the BBC, referring to the classist English stereotype of a dropped 'h' indicating a lack of education.&lt;/p&gt;
    &lt;p&gt;"But for origins and early history," he adds, "we are dependent upon written evidence, which is patchy at the best of times. For a colloquial word like this, which would have appeared much earlier and more frequently in speech than in writing, it is especially tricky to establish a definite timeline."&lt;/p&gt;
    &lt;p&gt;More like this:&lt;/p&gt;
    &lt;p&gt;• The most powerful word in the English language&lt;/p&gt;
    &lt;p&gt;• The surprising history of the word 'dude'&lt;/p&gt;
    &lt;p&gt;• The subtle way language shapes us&lt;/p&gt;
    &lt;p&gt;The selection of a standardised word form, Horobin explains, usually falls to lexicographers – those who compile dictionaries. "They base their choice on the relative prevalence of a particular spelling, though it's necessarily somewhat provisional and arbitrary."&lt;/p&gt;
    &lt;p&gt;By the time the Oxford English Dictionary first went to press in 1884, "hello" was emerging as the dominant form of the greeting. Charles Dickens, however, spent the 19th Century using "hullo" in his writings, and Alexander Graham Bell (who once argued that "ahoy!" would make a superior telephone greeting) stuck with "halloo". Bell's rival, Thomas Edison, championed "hello", believing it would carry clearly over even the worst phone lines. Like that of The Norwich Courier before him, Edison's backing helped – and "hello" was established as the English-language greeting to beat.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hello around the world&lt;/head&gt;
    &lt;p&gt;While the English language settled on "hello" as its customary greeting, other languages forged their own. Some were influenced by English, others developed independently – yet each carries a distinct cultural flavour, hinting at the social norms and stereotypes we have of the people who use it.&lt;/p&gt;
    &lt;p&gt;In Germanic and Scandinavian languages, for example, "hallo" and "hallå" are phonetically harder and feel more efficient and no-nonsense than the lyrical, almost poetic quality of "hola" and "olá", favoured by the Romance languages that are associated with more effusive stereotypes. Elsewhere, some greetings carry traces of national history: from the Dutch-derived "hallo" of Afrikaans to "óla" in Tetum, a reminder of Portuguese influence in Timor-Leste. Many such words appear to function as both introduction and identity marker. But, says Professor Duranti, it's not quite that simple.&lt;/p&gt;
    &lt;p&gt;"It's hard to go straight from the use of a particular greeting to a national character, even though it is tempting," he tells the BBC. Alternative or secondary greetings, Duranti suggests, may offer better clues. "In English, given the common use of 'how are you?', there is an apparent interest in people's wellbeing." In some Polynesian societies, he adds, greetings are less about a word-for-word "hello" than about checking in on someone's plans or movements – literally asking "where are you going?". Greek, meanwhile, uses "Γειά σου" (pronounced "yah-soo") as a typical informal greeting, offering a wish for health rather than a simple salutation. It is also usable for "goodbye".&lt;/p&gt;
    &lt;p&gt;Other languages also turn abstract concepts into multipurpose greetings that serve as both "hi" and "bye". "Ciao" comes from a Venetian dialect phrase meaning "at your service", and the French "salut" is an informal expression used for both greeting and parting company. Similarly, the Hawaiian "aloha" can express affection or compassion, and the Hebrew "shalom" peace or wholeness. Yet, as Duranti cautions, even these evocative examples shouldn't be viewed as cut-and-dry indicators of national character.&lt;/p&gt;
    &lt;p&gt;"I would be careful making that kind of correlation," he explains. "Especially about the semantics of it – health versus sympathy versus whereabouts. But there is one aspect of greetings that is sensitive to the social structure of a society, which is that equals greet each other in different ways from people of different statuses. In fact, greetings can be seen to define levels of intimacy or social distance." In this sense, he adds, greetings are like magnets – confidently announcing who we are, and drawing in those we want to be associated with.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hello in the digital age&lt;/head&gt;
    &lt;p&gt;If greetings act as social magnets, then technology has quietly altered their pull. Over the past few decades, the rise of email, texting and social media has reshaped not just how often we say "hello", but what we might replace it with – and whether we say it at all.&lt;/p&gt;
    &lt;p&gt;"If you think about WhatsApp, we're basically always in conversation – we're always online," says Christian Ilbury, senior lecturer in linguistics and English language at the University of Edinburgh. "When someone asks you how your day is or whether you're going to be on time for the meal, you don't always have to say 'hello' first, because it's unlikely the last message concluded with 'bye'."&lt;/p&gt;
    &lt;p&gt;In a text-led, always-on world, greetings have proved especially susceptible to change and, as they are used so often, their evolution has accelerated dramatically. Ilbury has identified many non-standard and creative spellings of "hello" in his studies of digital language, from "hellooooo" and "hiiiiiii" to "heyyyyy". Yet, while tech has made it easier for us to elongate words in this way, Ilbury points out that most modern-day greetings are short, sharp and driven by brevity.&lt;/p&gt;
    &lt;p&gt;"The most obvious thing to say is that people now sometimes use an emoji – the wave – in place of the word 'hello'," says Ilbury. "But technology has always contributed to language change. We now 'Google' stuff and 'unfriend' people. Like any major invention – AI, for instance – we're bound to get some new vocabulary from that source."&lt;/p&gt;
    &lt;p&gt;In many ways, this mirrors the instability of "hello" in the early 19th Century, when the greeting may have sounded vaguely the same whenever spoken, but varied widely in spelling when written down. By shortening the established greeting, or replacing it with icons and abbreviations, it's made clear that such salutations remain as fluid as they were before The Norwich Couriermade its landmark linguistic choice in 1826.&lt;/p&gt;
    &lt;p&gt;But for all its so-called standardisation, "hello" has never really stood still. It began as a shout, a summons, a way to hail attention, before settling – briefly – into an accepted spelling and usage. Two centuries on from its print debut, the greeting is once again being stretched, clipped, replaced or ignored altogether. Yet whether it's spoken aloud, typed hastily, or reduced to a small waving hand on a screen, the impulse behind it remains the same: an act of recognition, the announcing of one's presence and just asking – however casually – to be acknowledged in return.&lt;/p&gt;
    &lt;p&gt;--&lt;/p&gt;
    &lt;p&gt;If you liked this story, sign up for The Essential List newsletter – a handpicked selection of features, videos and can't-miss news, delivered to your inbox twice a week.&lt;/p&gt;
    &lt;p&gt;For more Culture stories from the BBC, follow us on Facebook and Instagram.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46657296</guid><pubDate>Sat, 17 Jan 2026 11:51:44 +0000</pubDate></item><item><title>The recurring dream of replacing developers</title><link>https://www.caimito.net/en/blog/2025/12/07/the-recurring-dream-of-replacing-developers.html</link><description>&lt;doc fingerprint="d5de5d392af7abd9"&gt;
  &lt;main&gt;
    &lt;p&gt;07.12.2025, By Stephan Schwab&lt;/p&gt;
    &lt;p&gt;Every decade brings new promises: this time, we'll finally make software development simple enough that we won't need so many developers. From COBOL to AI, the pattern repeats. Business leaders grow frustrated with slow delivery and high costs. Developers feel misunderstood and undervalued. Understanding why this cycle persists for fifty years reveals what both sides need to know about the nature of software work.&lt;/p&gt;
    &lt;p&gt;When Neil Armstrong stepped onto the lunar surface in 1969, the world witnessed what organized human ingenuity could accomplish. Behind that achievement stood Margaret Hamilton and her team, writing Apollo’s guidance software by hand, catching critical errors through careful review, and proving that software could be mission-critical.&lt;/p&gt;
    &lt;p&gt;The Apollo program demonstrated that software development was essential to achieving the impossible. Yet it also revealed something that would frustrate business leaders for decades to come: writing software required specialized knowledge, intense focus, and significant time investment. The dream of making it easier—of needing fewer of these expensive specialists—began almost immediately.&lt;/p&gt;
    &lt;p&gt;The late 1960s and 1970s saw COBOL emerge with an explicit goal stated in its name: Common Business-Oriented Language. The vision was clear: make the language read like English sentences, and business analysts would write their own programs. No need for specialized programmers.&lt;/p&gt;
    &lt;p&gt;This vision had genuine appeal. Software was becoming essential to business operations, yet programmers remained a scarce, expensive resource. COBOL promised to democratize software creation.&lt;/p&gt;
    &lt;p&gt;What happened instead? COBOL became another programming language requiring specialized training. Business analysts who tried to write COBOL quickly discovered that readable syntax didn’t eliminate the complexity of logic, data structures, or system design. A new class of COBOL programmers emerged, and the dream of eliminating specialized developers remained unfulfilled.&lt;/p&gt;
    &lt;p&gt;Yet the dream didn’t die. It simply waited for the next technological wave.&lt;/p&gt;
    &lt;p&gt;Computer-Aided Software Engineering tools arrived in the 1980s with tremendous promise. Draw flowcharts and entity-relationship diagrams, and the tool would generate working code. The marketing message resonated: visual design was more intuitive than typing cryptic commands. Business experts could model their processes, and software would materialize.&lt;/p&gt;
    &lt;p&gt;Organizations invested heavily. Vendors promised productivity increases of 10x or more. Yet most CASE tool initiatives struggled or failed outright.&lt;/p&gt;
    &lt;p&gt;The generated code often required substantial manual intervention. Performance problems emerged. Maintenance became a nightmare when generated code diverged from the visual models. Most critically, drawing accurate diagrams required understanding the same logical complexity that programming demanded. The tool changed the interface but not the fundamental challenge.&lt;/p&gt;
    &lt;p&gt;Once again, the problem proved more stubborn than the solution.&lt;/p&gt;
    &lt;p&gt;The 1990s brought a different approach. Microsoft’s Visual Basic and Borland’s Delphi made building user interfaces dramatically easier. Drag components onto a form, set properties, write event handlers. Suddenly, creating a Windows application felt achievable for developers with modest experience.&lt;/p&gt;
    &lt;p&gt;This wave succeeded differently than COBOL or CASE tools. These environments acknowledged that programming knowledge was still necessary, but they reduced the barrier to entry. A broader range of people could create useful applications.&lt;/p&gt;
    &lt;p&gt;Yet the dream of eliminating developers persisted. “Power users” and “citizen developers” would build departmental applications. IT departments could focus on infrastructure while business units solved their own software needs.&lt;/p&gt;
    &lt;p&gt;Reality proved more nuanced. Simple applications were indeed accessible to more people. But as requirements grew in complexity—integration with existing systems, security considerations, performance under load, long-term maintenance—the need for experienced developers became evident. The tools expanded who could write software, but they didn’t eliminate the expertise required for substantial systems.&lt;/p&gt;
    &lt;p&gt;And so the cycle continued into the new millennium.&lt;/p&gt;
    &lt;p&gt;Each subsequent decade introduced new variations. Ruby on Rails promised convention over configuration. Low-code platforms offered visual development with minimal coding. No-code platforms claimed to eliminate programming entirely for common business applications.&lt;/p&gt;
    &lt;p&gt;Each wave delivered real value. Development genuinely became faster in specific contexts. More people could participate in creating software solutions. Yet professional software developers remained essential, and demand for their skills continued growing rather than shrinking.&lt;/p&gt;
    &lt;p&gt;Which brings us to the question: why does this pattern repeat?&lt;/p&gt;
    &lt;p&gt;The recurring pattern reveals something important about how we think about complexity. Software development looks like it should be simple because we can describe what we want in plain language. “When a customer places an order, check inventory, calculate shipping, process payment, and send a confirmation email.” That description sounds straightforward.&lt;/p&gt;
    &lt;p&gt;The complexity emerges in the details. What happens when inventory is temporarily reserved by another order? How do you handle partial payments? What if the email service is temporarily unavailable? Should you retry? How many times? What if the customer’s session expires during checkout? How do you prevent duplicate orders?&lt;/p&gt;
    &lt;p&gt;Each answer leads to more questions. The accumulated decisions, edge cases, and interactions create genuine complexity that no tool or language can eliminate. Someone must think through these scenarios. That thinking is software development, regardless of whether it’s expressed in COBOL, a CASE tool diagram, Visual Basic, or an AI prompt.&lt;/p&gt;
    &lt;p&gt;Which brings us to today’s excitement.&lt;/p&gt;
    &lt;p&gt;Today’s AI coding assistants represent the most capable attempt yet to assist with software creation. They can generate substantial amounts of working code from natural language descriptions. They can explain existing code, suggest improvements, and help debug problems.&lt;/p&gt;
    &lt;p&gt;This represents genuine progress. The assistance is real and valuable. Experienced developers use these tools to work more efficiently. People learning to code find the interactive guidance helpful.&lt;/p&gt;
    &lt;p&gt;Yet we’re already seeing the familiar pattern emerge. Initial excitement about AI replacing developers is giving way to a more nuanced understanding: AI changes how developers work rather than eliminating the need for their judgment. The complexity remains. Someone must understand the business problem, evaluate whether the generated code solves it correctly, consider security implications, ensure it integrates properly with existing systems, and maintain it as requirements evolve.&lt;/p&gt;
    &lt;p&gt;AI amplifies developer capability. It doesn’t replace the need for people who understand both the problem domain and the technical landscape.&lt;/p&gt;
    &lt;p&gt;Here’s the paradox that makes this pattern particularly poignant. We’ve made extraordinary progress in software capabilities. The Apollo guidance computer had 4KB of RAM. Your smartphone has millions of times more computing power. We’ve built tools and frameworks that genuinely make many aspects of development easier.&lt;/p&gt;
    &lt;p&gt;Yet demand for software far exceeds our ability to create it. Every organization needs more software than it can build. The backlog of desired features and new initiatives grows faster than development teams can address it.&lt;/p&gt;
    &lt;p&gt;This tension—powerful tools yet insufficient capacity—keeps the dream alive. Business leaders look at the backlog and think, “There must be a way to go faster, to enable more people to contribute.” That’s a reasonable thought. It leads naturally to enthusiasm for any tool or approach that promises to democratize software creation.&lt;/p&gt;
    &lt;p&gt;The challenge is that software development isn’t primarily constrained by typing speed or syntax knowledge. It’s constrained by the thinking required to handle complexity well. Faster typing doesn’t help when you’re thinking through how to handle concurrent database updates. Simpler syntax doesn’t help when you’re reasoning about security implications.&lt;/p&gt;
    &lt;p&gt;So what should leaders do with this understanding?&lt;/p&gt;
    &lt;p&gt;Understanding this pattern changes how you evaluate new tools and approaches. When someone promises that their platform will let business users build applications without developers, you can appreciate the aspiration while maintaining realistic expectations.&lt;/p&gt;
    &lt;p&gt;The right question isn’t “Will this eliminate our need for developers?” The right questions are:&lt;/p&gt;
    &lt;p&gt;These questions acknowledge that development involves irreducible complexity while remaining open to tools that provide genuine leverage.&lt;/p&gt;
    &lt;p&gt;And they point to something deeper about the nature of software work.&lt;/p&gt;
    &lt;p&gt;This fifty-year pattern teaches us something fundamental about software development itself. If the problem were primarily mechanical—too much typing, too complex syntax, too many steps—we would have solved it by now. COBOL made syntax readable. CASE tools eliminated typing. Visual tools eliminated syntax. AI can now generate entire functions from descriptions.&lt;/p&gt;
    &lt;p&gt;Each advancement addressed a real friction point. Yet the fundamental challenge persists because it’s not mechanical. It’s intellectual. Software development is thinking made tangible. The artifacts we create—whether COBOL programs, Delphi forms, or Python scripts—are the visible outcome of invisible reasoning about complexity.&lt;/p&gt;
    &lt;p&gt;You can’t shortcut that reasoning any more than you can shortcut the reasoning required to design a building or diagnose a medical condition. Better tools help. Experience helps. But someone must still think it through.&lt;/p&gt;
    &lt;p&gt;So how should we move forward, knowing all this?&lt;/p&gt;
    &lt;p&gt;The next wave of development tools will arrive. Some will provide genuine value. Some will repeat familiar promises with new technology. Having perspective on this recurring pattern helps you engage with new tools productively.&lt;/p&gt;
    &lt;p&gt;Use AI assistants. Evaluate low-code platforms. Experiment with new frameworks. But invest primarily in your people’s ability to think clearly about complexity. That capability remains the constraining factor, just as it was during the Apollo program.&lt;/p&gt;
    &lt;p&gt;The moon landing happened because brilliant people thought carefully about every detail of an extraordinarily complex challenge. They wrote software by hand because that was the available tool. If they’d had better tools, they would have used them gladly. But the tools wouldn’t have eliminated their need to think through the complexity.&lt;/p&gt;
    &lt;p&gt;We’re still in that same fundamental situation. We have better tools—vastly better tools—but the thinking remains essential.&lt;/p&gt;
    &lt;p&gt;Perhaps the recurring dream of replacing developers isn’t a mistake. Perhaps it’s a necessary optimism that drives tool creation. Each attempt to make development more accessible produces tools that genuinely help. The dream doesn’t come true as imagined, but pursuing it creates value.&lt;/p&gt;
    &lt;p&gt;COBOL didn’t let business analysts write programs, but it did enable a generation of developers to build business systems effectively. CASE tools didn’t generate complete applications, but they advanced our thinking about visual modeling. Visual Basic didn’t eliminate professional developers, but it brought application development to more people. AI won’t replace developers, but it will change how we work in meaningful ways.&lt;/p&gt;
    &lt;p&gt;The pattern continues because the dream reflects a legitimate need. We genuinely require faster, more efficient ways to create software. We just keep discovering that the constraint isn’t the tool—it’s the complexity of the problems we’re trying to solve.&lt;/p&gt;
    &lt;p&gt;Understanding this doesn’t mean rejecting new tools. It means using them with clear expectations about what they can provide and what will always require human judgment.&lt;/p&gt;
    &lt;p&gt;Let's talk about your real situation. Want to accelerate delivery, remove technical blockers, or validate whether an idea deserves more investment? Book a short conversation (20 min): I listen to your context and give 1–2 practical recommendations—no pitch, no obligation. If it fits, we continue; if not, you leave with clarity. Confidential and direct.&lt;/p&gt;
    &lt;p&gt;Prefer email? Write me: sns@caimito.net&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46658345</guid><pubDate>Sat, 17 Jan 2026 14:31:33 +0000</pubDate></item><item><title>There's no single best way to store information</title><link>https://www.quantamagazine.org/why-theres-no-single-best-way-to-store-information-20260116/</link><description>&lt;doc fingerprint="7721186709e90e89"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why There’s No Single Best Way To Store Information&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Just as there’s no single best way to organize your bookshelf, there’s no one-size-fits-all solution to storing information.&lt;/p&gt;
    &lt;p&gt;Consider the simple situation where you create a new digital file. Your computer needs to rapidly find a place to put it. If you later want to delete it, the machine must quickly find the right bits to erase. Researchers aim to design storage systems, called data structures, that balance the amount of time it takes to add data, the time it takes to later remove it, and the total amount of memory the system needs.&lt;/p&gt;
    &lt;p&gt;To get a feel for these challenges, imagine you keep all your books in a row on one long shelf. If they’re organized alphabetically, you can quickly pick out any book. But whenever you acquire a new book, it’ll take time to find its proper spot. Conversely, if you place books wherever there’s space, you’ll save time now, but they’ll be hard to find later. This trade-off between insertion time and retrieval time might not be a problem for a single-shelf library, but you can see how it could get cumbersome with thousands of books.&lt;/p&gt;
    &lt;p&gt;Instead of a shelf, you could set up 26 alphabetically labeled bins and assign books to bins based on the first letter of the author’s last name. Whenever you get a new book, you can instantly tell which bin it goes in, and whenever you want to retrieve a book, you will immediately know where to look. In certain situations, both insertion and removal can be a lot faster than they would be if you stored items on one long shelf.&lt;/p&gt;
    &lt;p&gt;Of course, this bin system comes with its own problems. Retrieving books is only instantaneous if you have one book per bin; otherwise, you’ll have to root around to find the right one. In an extreme scenario where all your books are by Asimov, Atwood, and Austen, you’re back to the problem of one long shelf, plus you’ll have a bunch of empty bins cluttering up your living room.&lt;/p&gt;
    &lt;p&gt;Computer scientists often study data structures called hash tables that resemble more sophisticated versions of this simple bin system. Hash tables calculate a storage address for each item from a known property of that item, called the key. In our example, the key for each book is the first letter of the author’s last name. But that simple key makes it likely that some bins will be much fuller than others. (Few authors writing in English have a last name that starts with X, for example.) A better approach is to start with the author’s full name, replace each letter in the name with the number corresponding to its position in the alphabet, add up all these numbers, and divide the sum by 26. The remainder is some number between zero and 25. Use that number to assign the book to a bin.&lt;/p&gt;
    &lt;p&gt;This kind of mathematical rule for transforming a key into a storage address is called a hash function. A cleverly designed hash function ensures that items will usually end up distributed relatively evenly across bins, so you won’t need to spend as much time searching in each bin.&lt;/p&gt;
    &lt;p&gt;If you want to reduce retrieval time further, you can use more bins. But that leads to another trade-off: Those bins will take up space even if they end up empty.&lt;/p&gt;
    &lt;p&gt;This trade-off between space and time is an inherent feature of hash tables — it’s the price you pay for avoiding the tension between insertion and retrieval time that plagues simpler data structures. More than 70 years after hash tables were invented, computer scientists are still discovering new things about their fundamental properties. Recently, they finally devised a version that strikes an ideal balance between space and time. And last year, an undergraduate student disproved a long-standing conjecture about the minimum amount of time needed to find a specific item in a hash table that’s almost full.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Heap of Priorities&lt;/head&gt;
    &lt;p&gt;Hash tables work well when you can’t anticipate which piece of data you’ll need to retrieve next. But that’s not always the case. Imagine you’re trying to complete tasks on a to-do list, but you’re constantly being assigned new tasks with different deadlines. You want to be able to quickly add new items to the to-do list, but you don’t care about retrieving items until they become your top priority.&lt;/p&gt;
    &lt;p&gt;In this case, your best bet is a type of data structure called a heap. As the name suggests, a heap is a somewhat haphazard approach to data storage. It’s basically a mathematical version of a pile of stuff: Some items are stored above others, and these higher items are easier to access. The highest-priority item is always at the top of the heap, where you can instantly pluck it off. Lower layers will be more disorganized, but you don’t need to worry about the relative positions of these low-priority items.&lt;/p&gt;
    &lt;p&gt;The simplest implementation of this basic idea uses a mathematical object called a binary tree, which is a network of nodes with a special shape: There’s a single node at the top, and each node is connected to two nodes directly below it.&lt;/p&gt;
    &lt;p&gt;Let’s imagine a binary tree that contains the items in a to-do list. Each node can store a single item, and each item is labeled with a number that represents its due date. High-priority items get smaller numbers.&lt;/p&gt;
    &lt;p&gt;Each new item is put into an empty slot in the current lowest layer.&lt;/p&gt;
    &lt;p&gt;Once the new item goes in, compare its due date to that of the item in the node directly above it. If the new task is due sooner, swap the items. Keep swapping until the new item ends up directly below an item that’s more urgent.&lt;/p&gt;
    &lt;p&gt;This procedure ensures that the highest-priority item will always rise to the top. What’s more, the procedure is extremely fast. Even in a nightmare scenario where you have 1,000 tasks on your to-do list and keep getting new assignments, storing them in a heap ensures that it takes no more than nine swaps to move each new item up to the appropriate position. Whenever you complete the most urgent task and remove it from the heap, you can quickly pull up your new top priority from the layer below.&lt;/p&gt;
    &lt;p&gt;Within computer science, heaps are widely used in algorithms for finding the shortest path from a given starting point in a network to every other point. In 2024, a team of researchers used an ingenious new heap design to transform a classic shortest-paths algorithm into one that is theoretically optimal for any network layout.&lt;/p&gt;
    &lt;p&gt;There’s no shortage of self-help books filled with contradictory advice about the best way to organize your belongings. If computer science offers any lesson, it’s that there is no perfect solution — every approach comes with trade-offs. But if some items are more important to you than others, don’t be afraid to leave a bit of a mess.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46659219</guid><pubDate>Sat, 17 Jan 2026 16:17:58 +0000</pubDate></item><item><title>The Resonant Computing Manifesto</title><link>https://resonantcomputing.org/</link><description>&lt;doc fingerprint="9a11f37a94f0aa69"&gt;
  &lt;main&gt;
    &lt;p&gt; There's a feeling you get&lt;lb/&gt; in the presence of&lt;lb/&gt; beautiful buildings and bustling courtyards.&lt;lb/&gt; A sense that these spaces&lt;lb/&gt; are inviting you to slow down,&lt;lb/&gt; deepen your attention, and be&lt;lb/&gt; a bit more human.&lt;lb/&gt; What if our software could do the same? &lt;/p&gt;
    &lt;p&gt;We shape our environments, and thereafter they shape us.&lt;/p&gt;
    &lt;p&gt;Great technology does more than solve problems. It weaves itself into the world we inhabit. At its best, it can expand our capacity, our connectedness, our sense of what's possible. Technology can bring out the best in us.&lt;/p&gt;
    &lt;p&gt;Our current technological landscape, however, does the opposite. Feeds engineered to hijack attention and keep us scrolling, leaving a trail of anxiety and atomization in their wake. Digital platforms that increasingly mediate our access to transportation, work, food, dating, commerce, entertainment—while routinely draining the depth and warmth from everything they touch. For all its grandiose promises, modern tech often leaves us feeling alienated, ever more distant from who we want to be.&lt;/p&gt;
    &lt;p&gt;The people who build these products aren't bad or evil. Most of us got into tech with an earnest desire to leave the world better than we found it. But the incentives and cultural norms of the tech industry have coalesced around the logic of hyper-scale. It's become monolithic, magnetic, all-encompassing—an environment that shapes all who step foot there. While the business results are undeniable, so too are the downstream effects on humanity.&lt;/p&gt;
    &lt;p&gt;With the emergence of artificial intelligence, we stand at a crossroads. This technology holds genuine promise. It could just as easily pour gasoline on existing problems. If we continue to sleepwalk down the path of hyper-scale and centralization, future generations are sure to inherit a world far more dystopian than our own.&lt;/p&gt;
    &lt;p&gt;But there is another path opening before us.&lt;/p&gt;
    &lt;p&gt;Christopher Alexander spent his career exploring why some built environments deaden us, while others leave us feeling more human, more at home in the world. His work centered around the "quality without a name," this intuitive knowing that a place or an architectural element is in tune with life. By learning to recognize this quality, he argued, and constructing a building in dialogue with it, we could reliably create environments that enliven us.&lt;/p&gt;
    &lt;p&gt;We call this quality resonance. It's the experience of encountering something that speaks to our deeper values. It's a spark of recognition, a sense that we're being invited to lean in, to participate. Unlike the digital junk food of the day, the more we engage with what resonates, the more we're left feeling nourished, grateful, alive. As individuals, following the breadcrumbs of resonance helps us build meaningful lives. As communities, companies, and societies, cultivating shared resonance helps us break away from perverse incentives, and play positive-sum infinite games together.&lt;/p&gt;
    &lt;p&gt;For decades, technology has required standardized solutions to complex human problems. In order to scale software, you had to build for the average user, sanding away the edge cases. In many ways, this is why our digital world has come to resemble the sterile, deadening architecture that Alexander spent his career pushing back against.&lt;/p&gt;
    &lt;p&gt;This is where AI provides a missing puzzle piece. Software can now respond fluidly to the context and particularity of each human—at scale. One-size-fits-all is no longer a technological or economic necessity. Where once our digital environments inevitably shaped us against our will, we can now build technology that adaptively shapes itself in service of our individual and collective aspirations. We can build resonant environments that bring out the best in every human who inhabits them.&lt;/p&gt;
    &lt;p&gt;And so, we find ourselves at this crossroads. Regardless of which path we choose, the future of computing will be hyper-personalized. The question is whether that personalization will be in service of keeping us passively glued to screens—wading around in the shallows, stripped of agency—or whether it will enable us to direct more attention to what matters.&lt;/p&gt;
    &lt;p&gt;In order to build the resonant technological future we want for ourselves, we will have to resist the seductive logic of hyper-scale, and challenge the business and cultural assumptions that hold it in place. We will have to make deliberate decisions that stand in the face of accepted best practices—rethinking the system architectures, design patterns, and business models that have undergirded the tech industry for decades.&lt;/p&gt;
    &lt;p&gt;We suggest these five principles as a starting place:&lt;/p&gt;
    &lt;p&gt;We, the signatories of this manifesto, are committed to building, funding, and championing products and companies that embed these principles at their core. For us, this isn't a theoretical treatise. We're already building tooling and infrastructure that will enable resonant products and ecosystems.&lt;/p&gt;
    &lt;p&gt;But we cannot do it alone. None of us holds all the answers, and this movement cannot succeed in isolation. That's why, alongside this manifesto, we're sharing an evolving list of principles and theses. These are specific assertions about the implementation details and tradeoffs required to make resonant computing a reality. Some of these stem from our experiences, while others will be crowdsourced from practitioners across the industry. This conversation is only just beginning.&lt;/p&gt;
    &lt;p&gt;If this vision resonates, we invite you to join us. Not just as a signatory, but as a contributor. Add your expertise, your critiques, your own theses. By harnessing the collective intelligence of people who earnestly care, we can chart a path towards technology that enables individual growth and collective flourishing.&lt;/p&gt;
    &lt;p&gt;Explore &amp;amp; contribute to the theses of resonant computing&lt;/p&gt;
    &lt;p&gt;The following individuals drafted and released this manifesto:&lt;/p&gt;
    &lt;p&gt;Maggie Appleton&lt;lb/&gt; Samuel Arbesman&lt;lb/&gt; Daniel Barcay&lt;lb/&gt; Rob Hardy&lt;lb/&gt; Aishwarya Khanduja&lt;lb/&gt; Alex Komoroske&lt;lb/&gt; Geoffrey Litt&lt;lb/&gt; Michael Masnick&lt;lb/&gt; Brendan McCord&lt;/p&gt;
    &lt;p&gt;Bernhard Seefeld&lt;lb/&gt; Ivan Vendrov&lt;lb/&gt; Amelia Wattenberger&lt;lb/&gt; Zoe Weinberg&lt;lb/&gt; Simon Willison&lt;/p&gt;
    &lt;p&gt;with illustrations by&lt;lb/&gt; Forest Stearns&lt;/p&gt;
    &lt;p&gt;The following individuals have signed in support:&lt;/p&gt;
    &lt;p&gt;Tim O'Reilly&lt;/p&gt;
    &lt;p&gt;Kevin Kelly&lt;/p&gt;
    &lt;p&gt;Bruce Schneier&lt;/p&gt;
    &lt;p&gt;Alan Kay&lt;/p&gt;
    &lt;p&gt;Hank Green&lt;/p&gt;
    &lt;p&gt;Hiten Shah&lt;/p&gt;
    &lt;p&gt;Eric Ries&lt;/p&gt;
    &lt;p&gt;Joel Lehman&lt;/p&gt;
    &lt;p&gt;Packy McCormick&lt;/p&gt;
    &lt;p&gt;Danielle Perszyk&lt;/p&gt;
    &lt;p&gt;Jim Rutt&lt;/p&gt;
    &lt;p&gt;Peter Wang&lt;/p&gt;
    &lt;p&gt;Brad Burnham&lt;/p&gt;
    &lt;p&gt;Kent Beck&lt;/p&gt;
    &lt;p&gt;Eugene Wei&lt;/p&gt;
    &lt;p&gt;Gary William Flake&lt;/p&gt;
    &lt;p&gt;Lenny Rachitsky&lt;/p&gt;
    &lt;p&gt;John Seely Brown&lt;/p&gt;
    &lt;p&gt;Roy Bahat&lt;/p&gt;
    &lt;p&gt;Jonathan Zittrain&lt;/p&gt;
    &lt;p&gt;Max Read&lt;/p&gt;
    &lt;p&gt;Harper Reed&lt;/p&gt;
    &lt;p&gt;Lawrence Lessig&lt;/p&gt;
    &lt;p&gt;Evan Henshaw-Plath&lt;/p&gt;
    &lt;p&gt;Anjan Katta&lt;/p&gt;
    &lt;p&gt;Yancey Strickler&lt;/p&gt;
    &lt;p&gt;Uri Bram&lt;/p&gt;
    &lt;p&gt;Rohit Krishnan&lt;/p&gt;
    &lt;p&gt;Simon Taylor&lt;/p&gt;
    &lt;p&gt;David A Smith&lt;/p&gt;
    &lt;p&gt;Peter van Hardenberg&lt;/p&gt;
    &lt;p&gt;E. Glen Weyl&lt;/p&gt;
    &lt;p&gt;Linda Liukas&lt;/p&gt;
    &lt;p&gt;Adam Davidson&lt;/p&gt;
    &lt;p&gt;Mark A. Lemley&lt;/p&gt;
    &lt;p&gt;Matt Beane&lt;/p&gt;
    &lt;p&gt;Anil Dash&lt;/p&gt;
    &lt;p&gt;Brooklyn Zelenka&lt;/p&gt;
    &lt;p&gt;Karen Wickre&lt;/p&gt;
    &lt;p&gt;Alex Russell&lt;/p&gt;
    &lt;p&gt;Rebecca MacKinnon&lt;/p&gt;
    &lt;p&gt;Audrey Tang&lt;/p&gt;
    &lt;p&gt;Ryan Carson&lt;/p&gt;
    &lt;p&gt;Ben Guo&lt;/p&gt;
    &lt;p&gt;Kim Scott&lt;/p&gt;
    &lt;p&gt;Scott Jenson&lt;/p&gt;
    &lt;p&gt;Esther Dyson&lt;/p&gt;
    &lt;p&gt;Richard Sambrook&lt;/p&gt;
    &lt;p&gt;Gilad Bracha&lt;/p&gt;
    &lt;p&gt;Matt Mullenweg&lt;/p&gt;
    &lt;p&gt;David P. Reed&lt;/p&gt;
    &lt;p&gt;Andrew Stone&lt;/p&gt;
    &lt;p&gt;Eric Migicovsky&lt;/p&gt;
    &lt;p&gt;Chris Messina&lt;/p&gt;
    &lt;p&gt;Vaughn Tan&lt;/p&gt;
    &lt;p&gt;Daphne Keller&lt;/p&gt;
    &lt;p&gt;Chad Kohalyk&lt;/p&gt;
    &lt;p&gt;James Edward Dillard&lt;/p&gt;
    &lt;p&gt;Ben mathes&lt;/p&gt;
    &lt;p&gt;Goblin Oats&lt;/p&gt;
    &lt;p&gt;Chris Lunt&lt;/p&gt;
    &lt;p&gt;Curran Dwyer&lt;/p&gt;
    &lt;p&gt;Ben Follington&lt;/p&gt;
    &lt;p&gt;Stuart Buck&lt;/p&gt;
    &lt;p&gt;Bridget Harris&lt;/p&gt;
    &lt;p&gt;Chad Fowler&lt;/p&gt;
    &lt;p&gt;Kyle Morris&lt;/p&gt;
    &lt;p&gt;Sean Thielen-Esparza&lt;/p&gt;
    &lt;p&gt;Janfj&lt;/p&gt;
    &lt;p&gt;Yatú Espinosa&lt;/p&gt;
    &lt;p&gt;Alex Zhang&lt;/p&gt;
    &lt;p&gt;Anna Mitchell&lt;/p&gt;
    &lt;p&gt;`Steve Kirkham&lt;/p&gt;
    &lt;p&gt;Scott Moore&lt;/p&gt;
    &lt;p&gt;Jason Zhao&lt;/p&gt;
    &lt;p&gt;Jad Esber&lt;/p&gt;
    &lt;p&gt;Joel Dietz&lt;/p&gt;
    &lt;p&gt;Lola Agabalogun&lt;/p&gt;
    &lt;p&gt;Tony Espinoza&lt;/p&gt;
    &lt;p&gt;Arjun Khoosal&lt;/p&gt;
    &lt;p&gt;Tony Curzon Price&lt;/p&gt;
    &lt;p&gt;Maximilian Eusterbrock&lt;/p&gt;
    &lt;p&gt;Beth Anderson&lt;/p&gt;
    &lt;p&gt;Anastasia Uglova&lt;/p&gt;
    &lt;p&gt;Jordan Erlends&lt;/p&gt;
    &lt;p&gt;Samuel Robson&lt;/p&gt;
    &lt;p&gt;Andrew Conner&lt;/p&gt;
    &lt;p&gt;Menno Schaap&lt;/p&gt;
    &lt;p&gt;Philipp Banhardt&lt;/p&gt;
    &lt;p&gt;Berlynn Bai&lt;/p&gt;
    &lt;p&gt;Arun&lt;/p&gt;
    &lt;p&gt;Louis Barclay&lt;/p&gt;
    &lt;p&gt;Gabriel Raubenheimer&lt;/p&gt;
    &lt;p&gt;Roman Leventov&lt;/p&gt;
    &lt;p&gt;Corey James&lt;/p&gt;
    &lt;p&gt;Ben Mayhew&lt;/p&gt;
    &lt;p&gt;Kyle Cox&lt;/p&gt;
    &lt;p&gt;Pierre Chuzeville&lt;/p&gt;
    &lt;p&gt;Lucabrando Sanfilippo&lt;/p&gt;
    &lt;p&gt;Jai Gandhi&lt;/p&gt;
    &lt;p&gt;Carsten Peters&lt;/p&gt;
    &lt;p&gt;Raghuvir Kasturi&lt;/p&gt;
    &lt;p&gt;B. Scot Rousse&lt;/p&gt;
    &lt;p&gt;Ilan Strauss&lt;/p&gt;
    &lt;p&gt;Yash Sharma&lt;/p&gt;
    &lt;p&gt;Sean McKeon&lt;/p&gt;
    &lt;p&gt;Gurupanguji&lt;/p&gt;
    &lt;p&gt;Zoë Chazen&lt;/p&gt;
    &lt;p&gt;John Luther&lt;/p&gt;
    &lt;p&gt;Blain Smith&lt;/p&gt;
    &lt;p&gt;Menelaos Mazarakis&lt;/p&gt;
    &lt;p&gt;Konstantinos Komaitis&lt;/p&gt;
    &lt;p&gt;Eddy Abraham&lt;/p&gt;
    &lt;p&gt;Justin Mares&lt;/p&gt;
    &lt;p&gt;Aastha JS&lt;/p&gt;
    &lt;p&gt;Marisa Rama&lt;/p&gt;
    &lt;p&gt;Seb Agertoft&lt;/p&gt;
    &lt;p&gt;Christina Kirsch&lt;/p&gt;
    &lt;p&gt;Peter Voss&lt;/p&gt;
    &lt;p&gt;Shoumik Dabir&lt;/p&gt;
    &lt;p&gt;Mike McCormick&lt;/p&gt;
    &lt;p&gt;Riley Wong&lt;/p&gt;
    &lt;p&gt;Matt Hawes&lt;/p&gt;
    &lt;p&gt;Michele Canzi&lt;/p&gt;
    &lt;p&gt;Matt Jones&lt;/p&gt;
    &lt;p&gt;Jonathan Lebensold&lt;/p&gt;
    &lt;p&gt;Francisco Javier Arceo&lt;/p&gt;
    &lt;p&gt;Noah Ringler&lt;/p&gt;
    &lt;p&gt;Simone Cicero&lt;/p&gt;
    &lt;p&gt;Lex Sokolin&lt;/p&gt;
    &lt;p&gt;Erika Rice Scherpelz&lt;/p&gt;
    &lt;p&gt;Sahar Mor&lt;/p&gt;
    &lt;p&gt;max bittker&lt;/p&gt;
    &lt;p&gt;Avni Patel Thompson&lt;/p&gt;
    &lt;p&gt;Chaim Gingold&lt;/p&gt;
    &lt;p&gt;Matt Ziegler&lt;/p&gt;
    &lt;p&gt;Daniel Hatkoff&lt;/p&gt;
    &lt;p&gt;Kamran Hakima&lt;/p&gt;
    &lt;p&gt;Rupert Manfredi&lt;/p&gt;
    &lt;p&gt;Mark Moriarty&lt;/p&gt;
    &lt;p&gt;Jordan Rubin&lt;/p&gt;
    &lt;p&gt;Rebecca Mqamelo&lt;/p&gt;
    &lt;p&gt;Chenoe Hart&lt;/p&gt;
    &lt;p&gt;Rob Flickenger&lt;/p&gt;
    &lt;p&gt;Michael Lapadula&lt;/p&gt;
    &lt;p&gt;Dan Garon&lt;/p&gt;
    &lt;p&gt;Sean Lynch&lt;/p&gt;
    &lt;p&gt;Michael Tanzillo&lt;/p&gt;
    &lt;p&gt;Reggie James&lt;/p&gt;
    &lt;p&gt;Sam Barton&lt;/p&gt;
    &lt;p&gt;Anthea Roberts&lt;/p&gt;
    &lt;p&gt;Andrew Rose&lt;/p&gt;
    &lt;p&gt;Kevin Roark&lt;/p&gt;
    &lt;p&gt;Matt Holden&lt;/p&gt;
    &lt;p&gt;Leon Markham&lt;/p&gt;
    &lt;p&gt;Sam Weston&lt;/p&gt;
    &lt;p&gt;Rudolf Laine&lt;/p&gt;
    &lt;p&gt;Mark Whiting&lt;/p&gt;
    &lt;p&gt;Christine Gibson&lt;/p&gt;
    &lt;p&gt;Vivian Chong&lt;/p&gt;
    &lt;p&gt;Florian Weber&lt;/p&gt;
    &lt;p&gt;Luke Chatelain&lt;/p&gt;
    &lt;p&gt;Dan Bornstein (@danfuzz)&lt;/p&gt;
    &lt;p&gt;Marcus Estes&lt;/p&gt;
    &lt;p&gt;Kasra Kyanzadeh&lt;/p&gt;
    &lt;p&gt;Rishi Ishairzay&lt;/p&gt;
    &lt;p&gt;Nicholas Chirls&lt;/p&gt;
    &lt;p&gt;Lola Wajskop&lt;/p&gt;
    &lt;p&gt;William Kelly&lt;/p&gt;
    &lt;p&gt;Michael Greig&lt;/p&gt;
    &lt;p&gt;Jasnam Sidhu&lt;/p&gt;
    &lt;p&gt;dougfort&lt;/p&gt;
    &lt;p&gt;Lev Eliezer Israel&lt;/p&gt;
    &lt;p&gt;Mathilde Grant&lt;/p&gt;
    &lt;p&gt;Nathaniel Evans&lt;/p&gt;
    &lt;p&gt;Jessica Johnston&lt;/p&gt;
    &lt;p&gt;Benoit Pimpaud&lt;/p&gt;
    &lt;p&gt;Ross Matican&lt;/p&gt;
    &lt;p&gt;Natalie Breitkopf&lt;/p&gt;
    &lt;p&gt;Nirit Weiss-Blatt&lt;/p&gt;
    &lt;p&gt;James Sinka&lt;/p&gt;
    &lt;p&gt;Grace Kantrow&lt;/p&gt;
    &lt;p&gt;Robinson Eaton&lt;/p&gt;
    &lt;p&gt;Tom Rielly&lt;/p&gt;
    &lt;p&gt;Jason Shellen&lt;/p&gt;
    &lt;p&gt;EdZ&lt;/p&gt;
    &lt;p&gt;Juan Suarez&lt;/p&gt;
    &lt;p&gt;Selipso&lt;/p&gt;
    &lt;p&gt;Toto Tvalavadze&lt;/p&gt;
    &lt;p&gt;Brian "Beej Jorgensen" Hall&lt;/p&gt;
    &lt;p&gt;Hiraeth Wax&lt;/p&gt;
    &lt;p&gt;Dave Sanford&lt;/p&gt;
    &lt;p&gt;Rida Al Barazi&lt;/p&gt;
    &lt;p&gt;Baba Buehler&lt;/p&gt;
    &lt;p&gt;Will Henderson&lt;/p&gt;
    &lt;p&gt;Johannes Ernst&lt;/p&gt;
    &lt;p&gt;Gernot Poetsch&lt;/p&gt;
    &lt;p&gt;Ian Mulvany&lt;/p&gt;
    &lt;p&gt;Xavi Duran&lt;/p&gt;
    &lt;p&gt;Steve Della Valentina&lt;/p&gt;
    &lt;p&gt;Gabriel Cubbage&lt;/p&gt;
    &lt;p&gt;Marcel Goethals&lt;/p&gt;
    &lt;p&gt;Ashish Uppala&lt;/p&gt;
    &lt;p&gt;Ted Wood&lt;/p&gt;
    &lt;p&gt;Al Mithani&lt;/p&gt;
    &lt;p&gt;Carlos Pinto&lt;/p&gt;
    &lt;p&gt;Joël Gombin&lt;/p&gt;
    &lt;p&gt;Jassi Singh&lt;/p&gt;
    &lt;p&gt;Patrick Farrell&lt;/p&gt;
    &lt;p&gt;Steven Feuerstein&lt;/p&gt;
    &lt;p&gt;Alexia Petrakos&lt;/p&gt;
    &lt;p&gt;Quentin Hardy&lt;/p&gt;
    &lt;p&gt;Daniel Müller&lt;/p&gt;
    &lt;p&gt;Jorge Arango&lt;/p&gt;
    &lt;p&gt;Tom Usher&lt;/p&gt;
    &lt;p&gt;Jake Simonds&lt;/p&gt;
    &lt;p&gt;Luke Hubbard&lt;/p&gt;
    &lt;p&gt;Oren Maximov&lt;/p&gt;
    &lt;p&gt;Arun krishnasamy&lt;/p&gt;
    &lt;p&gt;Kingsley Uyi Idehen&lt;/p&gt;
    &lt;p&gt;Christopher David&lt;/p&gt;
    &lt;p&gt;mig&lt;/p&gt;
    &lt;p&gt;Giedrius Jaloveckas&lt;/p&gt;
    &lt;p&gt;Yuval Yeret&lt;/p&gt;
    &lt;p&gt;Mario Zechner&lt;/p&gt;
    &lt;p&gt;Alex Reynish&lt;/p&gt;
    &lt;p&gt;William Philpott&lt;/p&gt;
    &lt;p&gt;Sireesh Gururaja&lt;/p&gt;
    &lt;p&gt;Stephen Band&lt;/p&gt;
    &lt;p&gt;Peergos&lt;/p&gt;
    &lt;p&gt;Joey Tyson&lt;/p&gt;
    &lt;p&gt;Ankesh Bharti&lt;/p&gt;
    &lt;p&gt;Tommy Falkowski&lt;/p&gt;
    &lt;p&gt;Ruthvik Reddy SL&lt;/p&gt;
    &lt;p&gt;Raymond Zhong&lt;/p&gt;
    &lt;p&gt;Ramin Firoozye&lt;/p&gt;
    &lt;p&gt;Jeff Smith&lt;/p&gt;
    &lt;p&gt;David M. Schulman&lt;/p&gt;
    &lt;p&gt;Scott Rosenberg&lt;/p&gt;
    &lt;p&gt;Ted Underwood&lt;/p&gt;
    &lt;p&gt;David Brittain&lt;/p&gt;
    &lt;p&gt;Dumi Konovenski&lt;/p&gt;
    &lt;p&gt;Mark Appleby&lt;/p&gt;
    &lt;p&gt;Kasey Klimes&lt;/p&gt;
    &lt;p&gt;Jacob Carlson&lt;/p&gt;
    &lt;p&gt;Jeremiah Lee&lt;/p&gt;
    &lt;p&gt;Shawn Simister&lt;/p&gt;
    &lt;p&gt;Rev. Koushi Sherrill&lt;/p&gt;
    &lt;p&gt;Courtney Hohne&lt;/p&gt;
    &lt;p&gt;Glenn&lt;/p&gt;
    &lt;p&gt;Redowan Delowar&lt;/p&gt;
    &lt;p&gt;Thomas J. Tobin&lt;/p&gt;
    &lt;p&gt;Devin Gaffney&lt;/p&gt;
    &lt;p&gt;John Bergmayer&lt;/p&gt;
    &lt;p&gt;David W.&lt;/p&gt;
    &lt;p&gt;Jeremy Miller&lt;/p&gt;
    &lt;p&gt;Darren Munk&lt;/p&gt;
    &lt;p&gt;Julian Hicks&lt;/p&gt;
    &lt;p&gt;Fred.&lt;/p&gt;
    &lt;p&gt;Morgan Dalton&lt;/p&gt;
    &lt;p&gt;Mia&lt;/p&gt;
    &lt;p&gt;Adi Pradhan&lt;/p&gt;
    &lt;p&gt;Matt Boulos&lt;/p&gt;
    &lt;p&gt;John Patrick Pullen&lt;/p&gt;
    &lt;p&gt;Dominik Rabiej&lt;/p&gt;
    &lt;p&gt;Renee Frank&lt;/p&gt;
    &lt;p&gt;Charles F Leonard&lt;/p&gt;
    &lt;p&gt;Kate Edgar&lt;/p&gt;
    &lt;p&gt;Andreas Gerold&lt;/p&gt;
    &lt;p&gt;Andy Sellars&lt;/p&gt;
    &lt;p&gt;Davi Arruda&lt;/p&gt;
    &lt;p&gt;Benjamin Smith&lt;/p&gt;
    &lt;p&gt;Marco Bello&lt;/p&gt;
    &lt;p&gt;Randy Lubin&lt;/p&gt;
    &lt;p&gt;Allen Wirfs-Brock&lt;/p&gt;
    &lt;p&gt;Ilja Panić&lt;/p&gt;
    &lt;p&gt;kousha&lt;/p&gt;
    &lt;p&gt;Phil Kilner&lt;/p&gt;
    &lt;p&gt;Eric Hu&lt;/p&gt;
    &lt;p&gt;John Jakubowski&lt;/p&gt;
    &lt;p&gt;JD Pirtle&lt;/p&gt;
    &lt;p&gt;James Tauber&lt;/p&gt;
    &lt;p&gt;Vatsav&lt;/p&gt;
    &lt;p&gt;Joop Snijder&lt;/p&gt;
    &lt;p&gt;Frank B&lt;/p&gt;
    &lt;p&gt;Björn Jarisch&lt;/p&gt;
    &lt;p&gt;Jonathan Simcoe&lt;/p&gt;
    &lt;p&gt;David Cabo&lt;/p&gt;
    &lt;p&gt;Mark Zweifel&lt;/p&gt;
    &lt;p&gt;Glenn Poppe&lt;/p&gt;
    &lt;p&gt;Roy Atkinson&lt;/p&gt;
    &lt;p&gt;dat-ecosystem&lt;/p&gt;
    &lt;p&gt;Keith Kurson&lt;/p&gt;
    &lt;p&gt;Jeremy Littau&lt;/p&gt;
    &lt;p&gt;Joe Gaffey&lt;/p&gt;
    &lt;p&gt;James Cruz-Youll&lt;/p&gt;
    &lt;p&gt;Evan Kaufman&lt;/p&gt;
    &lt;p&gt;Rex Roof&lt;/p&gt;
    &lt;p&gt;kato gk&lt;/p&gt;
    &lt;p&gt;Peter Petrash&lt;/p&gt;
    &lt;p&gt;Oliver Dawkins&lt;/p&gt;
    &lt;p&gt;Diana Dely&lt;/p&gt;
    &lt;p&gt;Steve Whitney&lt;/p&gt;
    &lt;p&gt;Olabode Adedoyin&lt;/p&gt;
    &lt;p&gt;Simon Berlin&lt;/p&gt;
    &lt;p&gt;Brent Eubanks&lt;/p&gt;
    &lt;p&gt;John Brooks&lt;/p&gt;
    &lt;p&gt;John Chandy&lt;/p&gt;
    &lt;p&gt;Dmitry Alexeenko&lt;/p&gt;
    &lt;p&gt;Brian Cowles&lt;/p&gt;
    &lt;p&gt;Austin Parker&lt;/p&gt;
    &lt;p&gt;Joe W&lt;/p&gt;
    &lt;p&gt;Niana Dela Cruz&lt;/p&gt;
    &lt;p&gt;Holly Tavel&lt;/p&gt;
    &lt;p&gt;Michael Taggart&lt;/p&gt;
    &lt;p&gt;cassidy cypress&lt;/p&gt;
    &lt;p&gt;Damien Tournoud&lt;/p&gt;
    &lt;p&gt;Gavin Chait&lt;/p&gt;
    &lt;p&gt;Bryan Watts&lt;/p&gt;
    &lt;p&gt;Pilar Rodríguez&lt;/p&gt;
    &lt;p&gt;Kris Wilcox&lt;/p&gt;
    &lt;p&gt;Thomas A. Powell&lt;/p&gt;
    &lt;p&gt;Eliot Kristan&lt;/p&gt;
    &lt;p&gt;J. M. Johnson&lt;/p&gt;
    &lt;p&gt;Laura Alonso Alemany&lt;/p&gt;
    &lt;p&gt;Arun Bahl&lt;/p&gt;
    &lt;p&gt;Quinn Underwood&lt;/p&gt;
    &lt;p&gt;Robin Strom&lt;/p&gt;
    &lt;p&gt;Matt Kanninen&lt;/p&gt;
    &lt;p&gt;R. Brent Adams&lt;/p&gt;
    &lt;p&gt;Nicholas Chen&lt;/p&gt;
    &lt;p&gt;Andrew Przybylski&lt;/p&gt;
    &lt;p&gt;@bumblefudge&lt;/p&gt;
    &lt;p&gt;Manuel Aráoz&lt;/p&gt;
    &lt;p&gt;Jim Diamond&lt;/p&gt;
    &lt;p&gt;Jimmie Munyi&lt;/p&gt;
    &lt;p&gt;Kevin Sagle&lt;/p&gt;
    &lt;p&gt;Paul Gowder&lt;/p&gt;
    &lt;p&gt;Diego Veras&lt;/p&gt;
    &lt;p&gt;Taylor Sizemore&lt;/p&gt;
    &lt;p&gt;Pete Harbeson&lt;/p&gt;
    &lt;p&gt;Tom O'Leary&lt;/p&gt;
    &lt;p&gt;Nils Lundquist&lt;/p&gt;
    &lt;p&gt;Leanna Garfield&lt;/p&gt;
    &lt;p&gt;Mitch Morton&lt;/p&gt;
    &lt;p&gt;EBertsch&lt;/p&gt;
    &lt;p&gt;Darryl Rubarth&lt;/p&gt;
    &lt;p&gt;Laurence Favrot&lt;/p&gt;
    &lt;p&gt;Dakota Sillyman&lt;/p&gt;
    &lt;p&gt;Soren Larson&lt;/p&gt;
    &lt;p&gt;Andres Palau&lt;/p&gt;
    &lt;p&gt;Steve Duggan&lt;/p&gt;
    &lt;p&gt;Phil Wolff&lt;/p&gt;
    &lt;p&gt;Zach Jordan&lt;/p&gt;
    &lt;p&gt;Asher Wolf&lt;/p&gt;
    &lt;p&gt;Rainey Reitman&lt;/p&gt;
    &lt;p&gt;David Grimm&lt;/p&gt;
    &lt;p&gt;Belmer Negrillo&lt;/p&gt;
    &lt;p&gt;Courtney Harrness&lt;/p&gt;
    &lt;p&gt;Anuj Ahooja&lt;/p&gt;
    &lt;p&gt;Kiran Scott de Martinville&lt;/p&gt;
    &lt;p&gt;Greg Breidenbach&lt;/p&gt;
    &lt;p&gt;Deji Akomolafe&lt;/p&gt;
    &lt;p&gt;Wayne Westerman&lt;/p&gt;
    &lt;p&gt;Vamp Hallow&lt;/p&gt;
    &lt;p&gt;Ivan Leon&lt;/p&gt;
    &lt;p&gt;Nuno André&lt;/p&gt;
    &lt;p&gt;Sunny G&lt;/p&gt;
    &lt;p&gt;Gabriela Andrade&lt;/p&gt;
    &lt;p&gt;Scott Frankum&lt;/p&gt;
    &lt;p&gt;Benoît Mayaux&lt;/p&gt;
    &lt;p&gt;Les Horne&lt;/p&gt;
    &lt;p&gt;Patricio J. Garcia&lt;/p&gt;
    &lt;p&gt;Kir Peñalber&lt;/p&gt;
    &lt;p&gt;Pradeep Das&lt;/p&gt;
    &lt;p&gt;Oliver Segovia&lt;/p&gt;
    &lt;p&gt;Matt Abrams&lt;/p&gt;
    &lt;p&gt;Sean Horgan&lt;/p&gt;
    &lt;p&gt;viv shaw&lt;/p&gt;
    &lt;p&gt;Aaron Wright&lt;/p&gt;
    &lt;p&gt;Mark Fletcher&lt;/p&gt;
    &lt;p&gt;Hansatanu Roy&lt;/p&gt;
    &lt;p&gt;Dr. Astrid J. Scholz&lt;/p&gt;
    &lt;p&gt;Michael X Crowe&lt;/p&gt;
    &lt;p&gt;Joshua Landau&lt;/p&gt;
    &lt;p&gt;Awab Khan&lt;/p&gt;
    &lt;p&gt;Beth Goldberg&lt;/p&gt;
    &lt;p&gt;Adam Lake&lt;/p&gt;
    &lt;p&gt;Andreas Liebschner&lt;/p&gt;
    &lt;p&gt;Britt Lewis&lt;/p&gt;
    &lt;p&gt;Yong Cheng Toh&lt;/p&gt;
    &lt;p&gt;paolo cardullo&lt;/p&gt;
    &lt;p&gt;Filip Zrůst&lt;/p&gt;
    &lt;p&gt;Annie Vella&lt;/p&gt;
    &lt;p&gt;Dan Pelichowski&lt;/p&gt;
    &lt;p&gt;Mike Young&lt;/p&gt;
    &lt;p&gt;Matthias Urlichs&lt;/p&gt;
    &lt;p&gt;Kilian Merrins&lt;/p&gt;
    &lt;p&gt;Friedemann Bürgel&lt;/p&gt;
    &lt;p&gt;Roy Osherove&lt;/p&gt;
    &lt;p&gt;Colin Constable&lt;/p&gt;
    &lt;p&gt;Maxime Fazilleau&lt;/p&gt;
    &lt;p&gt;Ive Verstappen&lt;/p&gt;
    &lt;p&gt;Helen Simmons&lt;/p&gt;
    &lt;p&gt;Chris Swan&lt;/p&gt;
    &lt;p&gt;Ben Shaw&lt;/p&gt;
    &lt;p&gt;Christian Bewernitz&lt;/p&gt;
    &lt;p&gt;Haustraliaer&lt;/p&gt;
    &lt;p&gt;Salvo Vaccarino&lt;/p&gt;
    &lt;p&gt;Alex Wrottesley&lt;/p&gt;
    &lt;p&gt;Lorelei Kelly&lt;/p&gt;
    &lt;p&gt;Johan Trip&lt;/p&gt;
    &lt;p&gt;Giles Copp&lt;/p&gt;
    &lt;p&gt;Mark Little&lt;/p&gt;
    &lt;p&gt;Duma Ron&lt;/p&gt;
    &lt;p&gt;Tarek Elghawaby&lt;/p&gt;
    &lt;p&gt;Krishna Kumar&lt;/p&gt;
    &lt;p&gt;Steve Moraco&lt;/p&gt;
    &lt;p&gt;Ezra Mechaber&lt;/p&gt;
    &lt;p&gt;Jamey Greenwood&lt;/p&gt;
    &lt;p&gt;Ben Reinhardt&lt;/p&gt;
    &lt;p&gt;Iris Stammberger&lt;/p&gt;
    &lt;p&gt;Michael LeRoy&lt;/p&gt;
    &lt;p&gt;Walter Viguiliouk&lt;/p&gt;
    &lt;p&gt;AHM Bazlur Rahman&lt;/p&gt;
    &lt;p&gt;Vlad Iliescu&lt;/p&gt;
    &lt;p&gt;Jeff Rivett&lt;/p&gt;
    &lt;p&gt;Russell Ong&lt;/p&gt;
    &lt;p&gt;Scott Schaffter&lt;/p&gt;
    &lt;p&gt;Chris McAvoy&lt;/p&gt;
    &lt;p&gt;Nishant Shah&lt;/p&gt;
    &lt;p&gt;Tavis Rudd&lt;/p&gt;
    &lt;p&gt;Tomas Taylor&lt;/p&gt;
    &lt;p&gt;Paolo Scanferla&lt;/p&gt;
    &lt;p&gt;Tiago Ferreira&lt;/p&gt;
    &lt;p&gt;Martha Nichols&lt;/p&gt;
    &lt;p&gt;Tom Cross&lt;/p&gt;
    &lt;p&gt;Peter Suber&lt;/p&gt;
    &lt;p&gt;Adam Coates&lt;/p&gt;
    &lt;p&gt;Maxwell Fritz&lt;/p&gt;
    &lt;p&gt;Amy Tabor&lt;/p&gt;
    &lt;p&gt;Steyn Viljoen&lt;/p&gt;
    &lt;p&gt;Danny Zuckerman&lt;/p&gt;
    &lt;p&gt;Dov Lev Drory-Lehrer&lt;/p&gt;
    &lt;p&gt;Brent Lutz&lt;/p&gt;
    &lt;p&gt;Sarah-Jane Morris&lt;/p&gt;
    &lt;p&gt;Cristian R.&lt;/p&gt;
    &lt;p&gt;Peter Dedene&lt;/p&gt;
    &lt;p&gt;Jack Marsh&lt;/p&gt;
    &lt;p&gt;huck bales&lt;/p&gt;
    &lt;p&gt;Jon Redeker&lt;/p&gt;
    &lt;p&gt;Adam Crabtree&lt;/p&gt;
    &lt;p&gt;Al Duncanson&lt;/p&gt;
    &lt;p&gt;robzinn&lt;/p&gt;
    &lt;p&gt;Michael Verdusco&lt;/p&gt;
    &lt;p&gt;Keith Delgado&lt;/p&gt;
    &lt;p&gt;Ariel Barmat&lt;/p&gt;
    &lt;p&gt;Dean Riddick&lt;/p&gt;
    &lt;p&gt;Josiah Witt&lt;/p&gt;
    &lt;p&gt;Juliette Brown&lt;/p&gt;
    &lt;p&gt;Matt Silverstein&lt;/p&gt;
    &lt;p&gt;Chris Parsons&lt;/p&gt;
    &lt;p&gt;Paul Bakaus&lt;/p&gt;
    &lt;p&gt;Ari Dyckovsky&lt;/p&gt;
    &lt;p&gt;John Naughton&lt;/p&gt;
    &lt;p&gt;Duncan Cragg&lt;/p&gt;
    &lt;p&gt;Tom larkworthy&lt;/p&gt;
    &lt;p&gt;Jason Vella&lt;/p&gt;
    &lt;p&gt;Barbara Tallent&lt;/p&gt;
    &lt;p&gt;Griffith Awuah&lt;/p&gt;
    &lt;p&gt;noumena a. hundimägi-mei&lt;/p&gt;
    &lt;p&gt;Jan Johannesson&lt;/p&gt;
    &lt;p&gt;Julia Cheung&lt;/p&gt;
    &lt;p&gt;Christian Vuye&lt;/p&gt;
    &lt;p&gt;Dan Gauger&lt;/p&gt;
    &lt;p&gt;Joel Chan&lt;/p&gt;
    &lt;p&gt;Carissa Karban&lt;/p&gt;
    &lt;p&gt;Mark Selleck&lt;/p&gt;
    &lt;p&gt;Rahul Dave&lt;/p&gt;
    &lt;p&gt;Dragon Messmer&lt;/p&gt;
    &lt;p&gt;Carmelyne Thompson&lt;/p&gt;
    &lt;p&gt;Luke Stanley&lt;/p&gt;
    &lt;p&gt;Evan Chan&lt;/p&gt;
    &lt;p&gt;Ann Poletti&lt;/p&gt;
    &lt;p&gt;David Karger&lt;/p&gt;
    &lt;p&gt;Scott Woods&lt;/p&gt;
    &lt;p&gt;Garrett Williams&lt;/p&gt;
    &lt;p&gt;Avantika Mehra&lt;/p&gt;
    &lt;p&gt;Chrisjit Xavier&lt;/p&gt;
    &lt;p&gt;Jaack65&lt;/p&gt;
    &lt;p&gt;Zach G&lt;/p&gt;
    &lt;p&gt;Mari Adkins&lt;/p&gt;
    &lt;p&gt;Firecrow Silvernight&lt;/p&gt;
    &lt;p&gt;Jediah Katz&lt;/p&gt;
    &lt;p&gt;Andy Braren&lt;/p&gt;
    &lt;p&gt;Joe Flynn&lt;/p&gt;
    &lt;p&gt;Anoop Menon&lt;/p&gt;
    &lt;p&gt;Alessio 'dottorblaster' Biancalana&lt;/p&gt;
    &lt;p&gt;Steven Vandevelde&lt;/p&gt;
    &lt;p&gt;Julian Leiss&lt;/p&gt;
    &lt;p&gt;Averill Campion&lt;/p&gt;
    &lt;p&gt;Iglika Ivanova&lt;/p&gt;
    &lt;p&gt;Stefan Lesser&lt;/p&gt;
    &lt;p&gt;Paul Hastings&lt;/p&gt;
    &lt;p&gt;Jean Jordaan&lt;/p&gt;
    &lt;p&gt;Pandi Lin&lt;/p&gt;
    &lt;p&gt;Robin Dhanwani&lt;/p&gt;
    &lt;p&gt;Torsten Goerke&lt;/p&gt;
    &lt;p&gt;Davis Keene&lt;/p&gt;
    &lt;p&gt;Stephane Raynaud&lt;/p&gt;
    &lt;p&gt;Burt Herman&lt;/p&gt;
    &lt;p&gt;Iain Henderson&lt;/p&gt;
    &lt;p&gt;C3&lt;/p&gt;
    &lt;p&gt;Frank Hajek&lt;/p&gt;
    &lt;p&gt;David de Siebenthal&lt;/p&gt;
    &lt;p&gt;William Nardi&lt;/p&gt;
    &lt;p&gt;Edson Fregni&lt;/p&gt;
    &lt;p&gt;Amy Bruckman&lt;/p&gt;
    &lt;p&gt;Mike Tarpey&lt;/p&gt;
    &lt;p&gt;Stephen Reid&lt;/p&gt;
    &lt;p&gt;Shirley Grose&lt;/p&gt;
    &lt;p&gt;Sam Caldwell&lt;/p&gt;
    &lt;p&gt;Troy S&lt;/p&gt;
    &lt;p&gt;Jeff Loney&lt;/p&gt;
    &lt;p&gt;Gene Levinson&lt;/p&gt;
    &lt;p&gt;Martin Kaufmann&lt;/p&gt;
    &lt;p&gt;Naomi Richman&lt;/p&gt;
    &lt;p&gt;Beth Bailey&lt;/p&gt;
    &lt;p&gt;Markku Pätynen&lt;/p&gt;
    &lt;p&gt;Robert Bourdeau&lt;/p&gt;
    &lt;p&gt;Art Scott&lt;/p&gt;
    &lt;p&gt;Steve Makofsky&lt;/p&gt;
    &lt;p&gt;Mark Shust&lt;/p&gt;
    &lt;p&gt;Pam Boney&lt;/p&gt;
    &lt;p&gt;Ken Norton&lt;/p&gt;
    &lt;p&gt;Circé - Marie Drouvin&lt;/p&gt;
    &lt;p&gt;Jack Baty&lt;/p&gt;
    &lt;p&gt;Angela McGuire&lt;/p&gt;
    &lt;p&gt;Sarah Drinkwater&lt;/p&gt;
    &lt;p&gt;Kate Sieck&lt;/p&gt;
    &lt;p&gt;Martín Aguilar Tello&lt;/p&gt;
    &lt;p&gt;Alex Hillman&lt;/p&gt;
    &lt;p&gt;Jon Mertz&lt;/p&gt;
    &lt;p&gt;Hamza Essahbaoui&lt;/p&gt;
    &lt;p&gt;Matt Miller&lt;/p&gt;
    &lt;p&gt;When Leggett&lt;/p&gt;
    &lt;p&gt;Hari M&lt;/p&gt;
    &lt;p&gt;David H. Collins&lt;/p&gt;
    &lt;p&gt;Christopher Sperandio&lt;/p&gt;
    &lt;p&gt;Miguel A Villarreal&lt;/p&gt;
    &lt;p&gt;McKenzie Dunlap&lt;/p&gt;
    &lt;p&gt;Andrea Borruso&lt;/p&gt;
    &lt;p&gt;Aditya Narayana K&lt;/p&gt;
    &lt;p&gt;Dave Anderson&lt;/p&gt;
    &lt;p&gt;Tony Santos&lt;/p&gt;
    &lt;p&gt;Vince Taylor&lt;/p&gt;
    &lt;p&gt;Berkley Rothmeier&lt;/p&gt;
    &lt;p&gt;Yuval Adam&lt;/p&gt;
    &lt;p&gt;Barry Parr&lt;/p&gt;
    &lt;p&gt;John Dale&lt;/p&gt;
    &lt;p&gt;Héctor Jaime&lt;/p&gt;
    &lt;p&gt;Ryan Yeske&lt;/p&gt;
    &lt;p&gt;Peter Rojas&lt;/p&gt;
    &lt;p&gt;John Allsopp&lt;/p&gt;
    &lt;p&gt;Aftab Khan&lt;/p&gt;
    &lt;p&gt;Sanders&lt;/p&gt;
    &lt;p&gt;Ned Hayes&lt;/p&gt;
    &lt;p&gt;Nate Angell&lt;/p&gt;
    &lt;p&gt;Magnús Smárason&lt;/p&gt;
    &lt;p&gt;Dave Kong&lt;/p&gt;
    &lt;p&gt;Bobby Schweizer&lt;/p&gt;
    &lt;p&gt;Tereza Bizkova&lt;/p&gt;
    &lt;p&gt;Tony Smith&lt;/p&gt;
    &lt;p&gt;Patrick Berry&lt;/p&gt;
    &lt;p&gt;Adri&lt;/p&gt;
    &lt;p&gt;Brian Brewington&lt;/p&gt;
    &lt;p&gt;Jeremy Hunsinger&lt;/p&gt;
    &lt;p&gt;Anand Iyer&lt;/p&gt;
    &lt;p&gt;Greg Sprague&lt;/p&gt;
    &lt;p&gt;Breno Colom&lt;/p&gt;
    &lt;p&gt;Mira Vogel&lt;/p&gt;
    &lt;p&gt;TJ Kolleh&lt;/p&gt;
    &lt;p&gt;Ardeshir Sepahsalar&lt;/p&gt;
    &lt;p&gt;Dawn Nunziato&lt;/p&gt;
    &lt;p&gt;Vedang Manerikar&lt;/p&gt;
    &lt;p&gt;Jk Jenzen&lt;/p&gt;
    &lt;p&gt;Paulo Peres&lt;/p&gt;
    &lt;p&gt;Anwesh Roy&lt;/p&gt;
    &lt;p&gt;Andrew Knott&lt;/p&gt;
    &lt;p&gt;Jay Patel&lt;/p&gt;
    &lt;p&gt;Autumn Gray&lt;/p&gt;
    &lt;p&gt;Patsy Wood&lt;/p&gt;
    &lt;p&gt;Jon Festinger&lt;/p&gt;
    &lt;p&gt;Guy Kerem&lt;/p&gt;
    &lt;p&gt;Adithya Nair&lt;/p&gt;
    &lt;p&gt;Gio Pandone&lt;/p&gt;
    &lt;p&gt;Shalev NessAiver&lt;/p&gt;
    &lt;p&gt;Eileen Wagner&lt;/p&gt;
    &lt;p&gt;Dan McGreal&lt;/p&gt;
    &lt;p&gt;Karen M. Olsen&lt;/p&gt;
    &lt;p&gt;Andrea Rossi&lt;/p&gt;
    &lt;p&gt;David Gasquez&lt;/p&gt;
    &lt;p&gt;willtonkin&lt;/p&gt;
    &lt;p&gt;Johan Jacobs&lt;/p&gt;
    &lt;p&gt;Iwo Piętak&lt;/p&gt;
    &lt;p&gt;Alan Shimel&lt;/p&gt;
    &lt;p&gt;Manuel Vielma&lt;/p&gt;
    &lt;p&gt;Kamil Sobkowicz&lt;/p&gt;
    &lt;p&gt;Eric Sydell&lt;/p&gt;
    &lt;p&gt;Estrella Núñez (León)&lt;/p&gt;
    &lt;p&gt;Ruthvik Peddawandla&lt;/p&gt;
    &lt;p&gt;Sam Clemente&lt;/p&gt;
    &lt;p&gt;Tero Parviainen&lt;/p&gt;
    &lt;p&gt;Moebius&lt;/p&gt;
    &lt;p&gt;Matt McCormick&lt;/p&gt;
    &lt;p&gt;Sean Simpson&lt;/p&gt;
    &lt;p&gt;Maria Michalis&lt;/p&gt;
    &lt;p&gt;Eran Sandler&lt;/p&gt;
    &lt;p&gt;Ryan Lucht&lt;/p&gt;
    &lt;p&gt;Davey M. Kim&lt;/p&gt;
    &lt;p&gt;Koven J. Smith&lt;/p&gt;
    &lt;p&gt;Jonny Burch&lt;/p&gt;
    &lt;p&gt;Jessica Roache&lt;/p&gt;
    &lt;p&gt;Todd Youngblood&lt;/p&gt;
    &lt;p&gt;Fahrio&lt;/p&gt;
    &lt;p&gt;lyel resner&lt;/p&gt;
    &lt;p&gt;David Waksberg&lt;/p&gt;
    &lt;p&gt;Chris Wessels&lt;/p&gt;
    &lt;p&gt;Uday Ramesh Phalak&lt;/p&gt;
    &lt;p&gt;Amy Jean Studdart&lt;/p&gt;
    &lt;p&gt;Blaine Garst&lt;/p&gt;
    &lt;p&gt;Martijn Verpaalen&lt;/p&gt;
    &lt;p&gt;Andrew Matthews&lt;/p&gt;
    &lt;p&gt;Kevin Nothnagel&lt;/p&gt;
    &lt;p&gt;Melissa Turner&lt;/p&gt;
    &lt;p&gt;Kurt Schrader&lt;/p&gt;
    &lt;p&gt;Abbie Morris&lt;/p&gt;
    &lt;p&gt;Colin McMillen&lt;/p&gt;
    &lt;p&gt;Nikhil Kunapuli&lt;/p&gt;
    &lt;p&gt;Dorota Moravčíková&lt;/p&gt;
    &lt;p&gt;Vivek Bhupatiraju&lt;/p&gt;
    &lt;p&gt;Tyler Griffin&lt;/p&gt;
    &lt;p&gt;Greg Petroff&lt;/p&gt;
    &lt;p&gt;Bradley Clark Royes&lt;/p&gt;
    &lt;p&gt;Chase McCoy&lt;/p&gt;
    &lt;p&gt;Federico Jarach&lt;/p&gt;
    &lt;p&gt;Mr. Cairo&lt;/p&gt;
    &lt;p&gt;Charles AW Anaman&lt;/p&gt;
    &lt;p&gt;Gabriel Salkin&lt;/p&gt;
    &lt;p&gt;alsunseri&lt;/p&gt;
    &lt;p&gt;Alan Lewis&lt;/p&gt;
    &lt;p&gt;Vlad Georgescu&lt;/p&gt;
    &lt;p&gt;Daryl vines&lt;/p&gt;
    &lt;p&gt;Alun Machin&lt;/p&gt;
    &lt;p&gt;Clay Devlin&lt;/p&gt;
    &lt;p&gt;Drew Whitehouse&lt;/p&gt;
    &lt;p&gt;John Masson&lt;/p&gt;
    &lt;p&gt;Sage Hunter Bornstein&lt;/p&gt;
    &lt;p&gt;Campbell Macdonald&lt;/p&gt;
    &lt;p&gt;Kelly Lucas&lt;/p&gt;
    &lt;p&gt;Martin Compton&lt;/p&gt;
    &lt;p&gt;Daniel Waterhouse&lt;/p&gt;
    &lt;p&gt;Graham Mitchell&lt;/p&gt;
    &lt;p&gt;Fábio Corrêa&lt;/p&gt;
    &lt;p&gt;Alexa Chirnoaga&lt;/p&gt;
    &lt;p&gt;Priya bhunia&lt;/p&gt;
    &lt;p&gt;Rand Arete&lt;/p&gt;
    &lt;p&gt;Nicholas Underwood&lt;/p&gt;
    &lt;p&gt;Ingrid (kaslkaos) Schmelter&lt;/p&gt;
    &lt;p&gt;Florent Michel&lt;/p&gt;
    &lt;p&gt;Michael Saltzman&lt;/p&gt;
    &lt;p&gt;Jayson Margalus&lt;/p&gt;
    &lt;p&gt;Aaron Careaga&lt;/p&gt;
    &lt;p&gt;Safak Gezer&lt;/p&gt;
    &lt;p&gt;Paa Yaw&lt;/p&gt;
    &lt;p&gt;Matt Daily&lt;/p&gt;
    &lt;p&gt;Bill Dybas&lt;/p&gt;
    &lt;p&gt;Dave Karpf&lt;/p&gt;
    &lt;p&gt;Jesse Brown&lt;/p&gt;
    &lt;p&gt;Carolina Capetillo&lt;/p&gt;
    &lt;p&gt;Drew Marshall&lt;/p&gt;
    &lt;p&gt;Paul Weisser&lt;/p&gt;
    &lt;p&gt;Carlson Cheng&lt;/p&gt;
    &lt;p&gt;Christopher Davis&lt;/p&gt;
    &lt;p&gt;Tracy Leung&lt;/p&gt;
    &lt;p&gt;Sina Khanifar&lt;/p&gt;
    &lt;p&gt;Tom c Phillips&lt;/p&gt;
    &lt;p&gt;Nabiha Syed&lt;/p&gt;
    &lt;p&gt;Scott C. Anderson&lt;/p&gt;
    &lt;p&gt;David Smooke&lt;/p&gt;
    &lt;p&gt;Carissa Bilinski&lt;/p&gt;
    &lt;p&gt;Keith Phelan&lt;/p&gt;
    &lt;p&gt;Evan Blonien&lt;/p&gt;
    &lt;p&gt;Jim Santo&lt;/p&gt;
    &lt;p&gt;Dave Edwards&lt;/p&gt;
    &lt;p&gt;Masayuki Hatta&lt;/p&gt;
    &lt;p&gt;Kyle Allebach&lt;/p&gt;
    &lt;p&gt;Kyle Monson&lt;/p&gt;
    &lt;p&gt;Jenny Zhang&lt;/p&gt;
    &lt;p&gt;Lalit Merani&lt;/p&gt;
    &lt;p&gt;Javier Pallero&lt;/p&gt;
    &lt;p&gt;Matt Knight&lt;/p&gt;
    &lt;p&gt;Danilo Maurizio&lt;/p&gt;
    &lt;p&gt;John Panzer&lt;/p&gt;
    &lt;p&gt;Jill Metcalfe&lt;/p&gt;
    &lt;p&gt;Khoa Nguyen&lt;/p&gt;
    &lt;p&gt;Violet Harris&lt;/p&gt;
    &lt;p&gt;Jason Prunty&lt;/p&gt;
    &lt;p&gt;Evelyn Osman&lt;/p&gt;
    &lt;p&gt;Christoph Ono&lt;/p&gt;
    &lt;p&gt;Mark Mosedale&lt;/p&gt;
    &lt;p&gt;dane&lt;/p&gt;
    &lt;p&gt;Benjamin Taghavi-Awal&lt;/p&gt;
    &lt;p&gt;Charlie Vayas&lt;/p&gt;
    &lt;p&gt;Vlad Nicolescu&lt;/p&gt;
    &lt;p&gt;Peter Keating&lt;/p&gt;
    &lt;p&gt;Bas Grasmayer&lt;/p&gt;
    &lt;p&gt;Eugen Dunlap&lt;/p&gt;
    &lt;p&gt;Dan Schmidt&lt;/p&gt;
    &lt;p&gt;Wesley Faulkner&lt;/p&gt;
    &lt;p&gt;Don Goodspeed&lt;/p&gt;
    &lt;p&gt;Kris Decoodt&lt;/p&gt;
    &lt;p&gt;JdF&lt;/p&gt;
    &lt;p&gt;Tyler Sellhorn&lt;/p&gt;
    &lt;p&gt;Brita Shor&lt;/p&gt;
    &lt;p&gt;Corey Hayes&lt;/p&gt;
    &lt;p&gt;craig ts&lt;/p&gt;
    &lt;p&gt;Antoine Bérubé&lt;/p&gt;
    &lt;p&gt;Collin DePaemelere&lt;/p&gt;
    &lt;p&gt;Sean Dwyer&lt;/p&gt;
    &lt;p&gt;Casey Wahl&lt;/p&gt;
    &lt;p&gt;Jacob Seiler&lt;/p&gt;
    &lt;p&gt;CJ Wunsch&lt;/p&gt;
    &lt;p&gt;Julien Silland&lt;/p&gt;
    &lt;p&gt;Jess Holbrook&lt;/p&gt;
    &lt;p&gt;Ashleigh Broadfoot&lt;/p&gt;
    &lt;p&gt;David Worrell&lt;/p&gt;
    &lt;p&gt;Thibaud Teil&lt;/p&gt;
    &lt;p&gt;Haley Teil&lt;/p&gt;
    &lt;p&gt;Azalea Holder&lt;/p&gt;
    &lt;p&gt;rodrigo arcaya&lt;/p&gt;
    &lt;p&gt;Om Sonone&lt;/p&gt;
    &lt;p&gt;Isaac&lt;/p&gt;
    &lt;p&gt;Sam Klein&lt;/p&gt;
    &lt;p&gt;Fabian Morón Zirfas&lt;/p&gt;
    &lt;p&gt;Madhu Sriram&lt;/p&gt;
    &lt;p&gt;Eric John Olson&lt;/p&gt;
    &lt;p&gt;Eltons Kūns&lt;/p&gt;
    &lt;p&gt;Laura Christianson&lt;/p&gt;
    &lt;p&gt;Ondřej Konečný&lt;/p&gt;
    &lt;p&gt;Josh Woods&lt;/p&gt;
    &lt;p&gt;Etienne Amaral&lt;/p&gt;
    &lt;p&gt;Paweł Pasikowski&lt;/p&gt;
    &lt;p&gt;Brett Witty&lt;/p&gt;
    &lt;p&gt;Ben Mayberry&lt;/p&gt;
    &lt;p&gt;Brenda Lucena&lt;/p&gt;
    &lt;p&gt;Martina Pugliese&lt;/p&gt;
    &lt;p&gt;Bader Abdulwaseem&lt;/p&gt;
    &lt;p&gt;Josiah Evans&lt;/p&gt;
    &lt;p&gt;Andreas Gabor&lt;/p&gt;
    &lt;p&gt;Neil Winterburn&lt;/p&gt;
    &lt;p&gt;Marcel R. Bülles&lt;/p&gt;
    &lt;p&gt;Damiano Sabuzi Giuliani&lt;/p&gt;
    &lt;p&gt;Marcello Seri&lt;/p&gt;
    &lt;p&gt;Alejandra Cruz García&lt;/p&gt;
    &lt;p&gt;Bastien Giraud&lt;/p&gt;
    &lt;p&gt;Justin Lieb&lt;/p&gt;
    &lt;p&gt;Stefan Munz&lt;/p&gt;
    &lt;p&gt;Sari Azout&lt;/p&gt;
    &lt;p&gt;Annafi Wahed&lt;/p&gt;
    &lt;p&gt;Gil Friend&lt;/p&gt;
    &lt;p&gt;Craig Trim&lt;/p&gt;
    &lt;p&gt;Dana E. Barnard&lt;/p&gt;
    &lt;p&gt;Alyssa Panetta&lt;/p&gt;
    &lt;p&gt;J. Rodier&lt;/p&gt;
    &lt;p&gt;Austin Jackson&lt;/p&gt;
    &lt;p&gt;Kram&lt;/p&gt;
    &lt;p&gt;Charlie Rolph-Kevlahan&lt;/p&gt;
    &lt;p&gt;Paul Swail&lt;/p&gt;
    &lt;p&gt;Duncan Cox&lt;/p&gt;
    &lt;p&gt;Bryant Macy&lt;/p&gt;
    &lt;p&gt;Paul Hoffman&lt;/p&gt;
    &lt;p&gt;Venessa Paech&lt;/p&gt;
    &lt;p&gt;Charlie Ortiz&lt;/p&gt;
    &lt;p&gt;Neil Traft&lt;/p&gt;
    &lt;p&gt;Aran Lunzer&lt;/p&gt;
    &lt;p&gt;Sarah Schmidt&lt;/p&gt;
    &lt;p&gt;Carl Flippin&lt;/p&gt;
    &lt;p&gt;DaveGeer&lt;/p&gt;
    &lt;p&gt;omoju miller&lt;/p&gt;
    &lt;p&gt;Jort Hessel&lt;/p&gt;
    &lt;p&gt;Fabrizio Poltronieri&lt;/p&gt;
    &lt;p&gt;V3L&lt;/p&gt;
    &lt;p&gt;Vianney Vaute&lt;/p&gt;
    &lt;p&gt;Jakub Mirovsky&lt;/p&gt;
    &lt;p&gt;Nick Sng&lt;/p&gt;
    &lt;p&gt;John Lemme&lt;/p&gt;
    &lt;p&gt;Eric Darley&lt;/p&gt;
    &lt;p&gt;Alexander Melville&lt;/p&gt;
    &lt;p&gt;Phillip Shreves&lt;/p&gt;
    &lt;p&gt;Ingo Boltz&lt;/p&gt;
    &lt;p&gt;Anjon Roy&lt;/p&gt;
    &lt;p&gt;Jenny&lt;/p&gt;
    &lt;p&gt;Matthew Kreiling&lt;/p&gt;
    &lt;p&gt;Izanogi&lt;/p&gt;
    &lt;p&gt;Jonathan Garbee&lt;/p&gt;
    &lt;p&gt;Greg Fong&lt;/p&gt;
    &lt;p&gt;Anjali Bhide&lt;/p&gt;
    &lt;p&gt;Mimi Reyburn&lt;/p&gt;
    &lt;p&gt;Dart Lindsley&lt;/p&gt;
    &lt;p&gt;Nithilan Rameshkumar&lt;/p&gt;
    &lt;p&gt;Esteban Ordano&lt;/p&gt;
    &lt;p&gt;Dozie Anyaegbunam&lt;/p&gt;
    &lt;p&gt;Gerard Fox&lt;/p&gt;
    &lt;p&gt;Pete Mandas&lt;/p&gt;
    &lt;p&gt;Sebastian Gold&lt;/p&gt;
    &lt;p&gt;Alistair Knock&lt;/p&gt;
    &lt;p&gt;Máximo Gavete&lt;/p&gt;
    &lt;p&gt;Ruairi Laughlin-McCann&lt;/p&gt;
    &lt;p&gt;Kim Peiter Jorgensen&lt;/p&gt;
    &lt;p&gt;Roland Pascoe&lt;/p&gt;
    &lt;p&gt;Sungho Yoo&lt;/p&gt;
    &lt;p&gt;Theo Foley&lt;/p&gt;
    &lt;p&gt;danijel&lt;/p&gt;
    &lt;p&gt;Diana Mas&lt;/p&gt;
    &lt;p&gt;Jacob Sandlund&lt;/p&gt;
    &lt;p&gt;Uli Paulin&lt;/p&gt;
    &lt;p&gt;Chris M&lt;/p&gt;
    &lt;p&gt;John Seeley&lt;/p&gt;
    &lt;p&gt;Aaron G Neyer&lt;/p&gt;
    &lt;p&gt;Finn Markham&lt;/p&gt;
    &lt;p&gt;Daniel Barter&lt;/p&gt;
    &lt;p&gt;Will Abramson&lt;/p&gt;
    &lt;p&gt;Anir Nair&lt;/p&gt;
    &lt;p&gt;Utkarsh Gupta&lt;/p&gt;
    &lt;p&gt;Philipp Markolin&lt;/p&gt;
    &lt;p&gt;Ron Welch&lt;/p&gt;
    &lt;p&gt;Gustavo Moreira&lt;/p&gt;
    &lt;p&gt;Toni Aittoniemi&lt;/p&gt;
    &lt;p&gt;Andrew Dunn&lt;/p&gt;
    &lt;p&gt;Akhil Puri&lt;/p&gt;
    &lt;p&gt;Jay Rivera&lt;/p&gt;
    &lt;p&gt;Patricia Cartes&lt;/p&gt;
    &lt;p&gt;Joshua Stübner&lt;/p&gt;
    &lt;p&gt;Jae Yoon&lt;/p&gt;
    &lt;p&gt;Alfredo Serafini&lt;/p&gt;
    &lt;p&gt;Gabriel Melian&lt;/p&gt;
    &lt;p&gt;Nalin Kapoor&lt;/p&gt;
    &lt;p&gt;Dave Roselle&lt;/p&gt;
    &lt;p&gt;Farzin Nasiri&lt;/p&gt;
    &lt;p&gt;Andrew Lyjak&lt;/p&gt;
    &lt;p&gt;A. Galvan&lt;/p&gt;
    &lt;p&gt;Vicki Tan&lt;/p&gt;
    &lt;p&gt;M. Z. Mitchell Zheng&lt;/p&gt;
    &lt;p&gt;Madison Hsieh&lt;/p&gt;
    &lt;p&gt;Kyle Welch&lt;/p&gt;
    &lt;p&gt;Max Weese&lt;/p&gt;
    &lt;p&gt;Elisa Beshero-Bondar&lt;/p&gt;
    &lt;p&gt;Damashe Thomas&lt;/p&gt;
    &lt;p&gt;Alex Morisse&lt;/p&gt;
    &lt;p&gt;Greg Witt&lt;/p&gt;
    &lt;p&gt;Brian Karlak&lt;/p&gt;
    &lt;p&gt;Gabriel Krieshok&lt;/p&gt;
    &lt;p&gt;David Fox&lt;/p&gt;
    &lt;p&gt;Brian Hill&lt;/p&gt;
    &lt;p&gt;Randy Vane&lt;/p&gt;
    &lt;p&gt;Nick Sedlet&lt;/p&gt;
    &lt;p&gt;Manuviraj Godara&lt;/p&gt;
    &lt;p&gt;Gimena del Rio Riande&lt;/p&gt;
    &lt;p&gt;Brendan O'Brien&lt;/p&gt;
    &lt;p&gt;Kory Kilpatrick&lt;/p&gt;
    &lt;p&gt;Ben Munat&lt;/p&gt;
    &lt;p&gt;Melanie Kahl&lt;/p&gt;
    &lt;p&gt;Jimmy Lindsey&lt;/p&gt;
    &lt;p&gt;Clay Shentrup&lt;/p&gt;
    &lt;p&gt;Dongyuan Liu&lt;/p&gt;
    &lt;p&gt;Gaurav Ramesh&lt;/p&gt;
    &lt;p&gt;İrem Küçükali&lt;/p&gt;
    &lt;p&gt;Ankur Kumar&lt;/p&gt;
    &lt;p&gt;paul dariye&lt;/p&gt;
    &lt;p&gt;Sara Lindey&lt;/p&gt;
    &lt;p&gt;svitlana midianko&lt;/p&gt;
    &lt;p&gt;Denis Sosnovtsev&lt;/p&gt;
    &lt;p&gt;Jaxx Brown&lt;/p&gt;
    &lt;p&gt;Dr Aaron Breidenbach&lt;/p&gt;
    &lt;p&gt;James Uther&lt;/p&gt;
    &lt;p&gt;Damir Kombikov&lt;/p&gt;
    &lt;p&gt;Jahed Momand&lt;/p&gt;
    &lt;p&gt;Dai Griffiths&lt;/p&gt;
    &lt;p&gt;John Carosella Gardner&lt;/p&gt;
    &lt;p&gt;Mike McCue&lt;/p&gt;
    &lt;p&gt;Seyed Danesh&lt;/p&gt;
    &lt;p&gt;Daveed Benjamin&lt;/p&gt;
    &lt;p&gt;Andreas Ringman Uggla&lt;/p&gt;
    &lt;p&gt;Tor Guttorm&lt;/p&gt;
    &lt;p&gt;Simon H.&lt;/p&gt;
    &lt;p&gt;Balázs Búzás&lt;/p&gt;
    &lt;p&gt;Lamine BARRO&lt;/p&gt;
    &lt;p&gt;Trung Nguyen&lt;/p&gt;
    &lt;p&gt;Howard Stearns&lt;/p&gt;
    &lt;p&gt;Sean Leow&lt;/p&gt;
    &lt;p&gt;Vlad Cealicu&lt;/p&gt;
    &lt;p&gt;Cole Bittel&lt;/p&gt;
    &lt;p&gt;Brian Rinaldi&lt;/p&gt;
    &lt;p&gt;Rosalma Zubizarreta-Ada&lt;/p&gt;
    &lt;p&gt;Marcel Neuhausler&lt;/p&gt;
    &lt;p&gt;Thanh-Mai Phan&lt;/p&gt;
    &lt;p&gt;Pavle Matic&lt;/p&gt;
    &lt;p&gt;David Kunin&lt;/p&gt;
    &lt;p&gt;Jack Crawford&lt;/p&gt;
    &lt;p&gt;Jonathan Chomko&lt;/p&gt;
    &lt;p&gt;Nick Hagar&lt;/p&gt;
    &lt;p&gt;Craig Mod&lt;/p&gt;
    &lt;p&gt;Mike Elgan&lt;/p&gt;
    &lt;p&gt;Bartus Csongor&lt;/p&gt;
    &lt;p&gt;Shreyan Jain&lt;/p&gt;
    &lt;p&gt;David Critics&lt;/p&gt;
    &lt;p&gt;Seth Etter&lt;/p&gt;
    &lt;p&gt;Tim Jarratt&lt;/p&gt;
    &lt;p&gt;D. Ben Knoble&lt;/p&gt;
    &lt;p&gt;Edan Krolewicz&lt;/p&gt;
    &lt;p&gt;Laura S&lt;/p&gt;
    &lt;p&gt;Justin Manley&lt;/p&gt;
    &lt;p&gt;Brandon Lee&lt;/p&gt;
    &lt;p&gt;Egor Andreevich&lt;/p&gt;
    &lt;p&gt;Matt Baxter&lt;/p&gt;
    &lt;p&gt;Noah Van Loen&lt;/p&gt;
    &lt;p&gt;Chad O&lt;/p&gt;
    &lt;p&gt;Abhinav Ramachandran&lt;/p&gt;
    &lt;p&gt;Enrique Dans&lt;/p&gt;
    &lt;p&gt;mukesh agrawal&lt;/p&gt;
    &lt;p&gt;ConanXin&lt;/p&gt;
    &lt;p&gt;Varun Shijo&lt;/p&gt;
    &lt;p&gt;Phillip Traulsen&lt;/p&gt;
    &lt;p&gt;Juan Calero&lt;/p&gt;
    &lt;p&gt;Ashley Rolfmore&lt;/p&gt;
    &lt;p&gt;Pasquale Di Maria&lt;/p&gt;
    &lt;p&gt;ed Ropple&lt;/p&gt;
    &lt;p&gt;Thomas Moll&lt;/p&gt;
    &lt;p&gt;Last NPC Alex&lt;/p&gt;
    &lt;p&gt;Eric Boersma&lt;/p&gt;
    &lt;p&gt;Bronte Sihan Li&lt;/p&gt;
    &lt;p&gt;Moto Ishizawa&lt;/p&gt;
    &lt;p&gt;David Schmudde&lt;/p&gt;
    &lt;p&gt;John Lardee&lt;/p&gt;
    &lt;p&gt;Sarah Hack&lt;/p&gt;
    &lt;p&gt;Sipho Langa&lt;/p&gt;
    &lt;p&gt;Rob Reagan&lt;/p&gt;
    &lt;p&gt;Shreenath Regunathan&lt;/p&gt;
    &lt;p&gt;David Stern&lt;/p&gt;
    &lt;p&gt;Alex Márquez Pérez&lt;/p&gt;
    &lt;p&gt;Saskia Keskpaik&lt;/p&gt;
    &lt;p&gt;Chuck Donaldson&lt;/p&gt;
    &lt;p&gt;Vasilis Giannoulis&lt;/p&gt;
    &lt;p&gt;Marco Cesati&lt;/p&gt;
    &lt;p&gt;Rikard Linde&lt;/p&gt;
    &lt;p&gt;José David Carbajo&lt;/p&gt;
    &lt;p&gt;Wolfgang Miller&lt;/p&gt;
    &lt;p&gt;Peter Bartr Reiner&lt;/p&gt;
    &lt;p&gt;Joel Hall&lt;/p&gt;
    &lt;p&gt;Helene Goldberg&lt;/p&gt;
    &lt;p&gt;glhein&lt;/p&gt;
    &lt;p&gt;Anupam Goel&lt;/p&gt;
    &lt;p&gt;Erica Schumacher&lt;/p&gt;
    &lt;p&gt;Gabrielle Pelletier&lt;/p&gt;
    &lt;p&gt;Sander McComiskey&lt;/p&gt;
    &lt;p&gt;Ishan Ghorela&lt;/p&gt;
    &lt;p&gt;Michael Garfield&lt;/p&gt;
    &lt;p&gt;Bodhi Hill&lt;/p&gt;
    &lt;p&gt;Sarah Andrabi&lt;/p&gt;
    &lt;p&gt;Ben Meneses-Sosa&lt;/p&gt;
    &lt;p&gt;Jonathan Masters&lt;/p&gt;
    &lt;p&gt;Steve Arvedson&lt;/p&gt;
    &lt;p&gt;Chad Walker&lt;/p&gt;
    &lt;p&gt;Georgia Pears&lt;/p&gt;
    &lt;p&gt;Stefan Werner&lt;/p&gt;
    &lt;p&gt;Nick Brody&lt;/p&gt;
    &lt;p&gt;David P.&lt;/p&gt;
    &lt;p&gt;Oscar Smith&lt;/p&gt;
    &lt;p&gt;Paul Bauer&lt;/p&gt;
    &lt;p&gt;Paul Tibbits&lt;/p&gt;
    &lt;p&gt;Jürgen Höhe&lt;/p&gt;
    &lt;p&gt;Andrew Sorcini&lt;/p&gt;
    &lt;p&gt;Sreedhar K&lt;/p&gt;
    &lt;p&gt;Warren Stringer&lt;/p&gt;
    &lt;p&gt;Katie braund&lt;/p&gt;
    &lt;p&gt;Ryan Hodgman&lt;/p&gt;
    &lt;p&gt;Ernst Hafen&lt;/p&gt;
    &lt;p&gt;John Knox&lt;/p&gt;
    &lt;p&gt;Alberto Medina&lt;/p&gt;
    &lt;p&gt;Wei Zhou&lt;/p&gt;
    &lt;p&gt;Samuel Ratnam&lt;/p&gt;
    &lt;p&gt;Vivek Dhami&lt;/p&gt;
    &lt;p&gt;Daniel Gillis&lt;/p&gt;
    &lt;p&gt;Richard Newman&lt;/p&gt;
    &lt;p&gt;Nico Ward&lt;/p&gt;
    &lt;p&gt;Osarumen Osamuyi&lt;/p&gt;
    &lt;p&gt;Ovidiu Mățan&lt;/p&gt;
    &lt;p&gt;David Congour&lt;/p&gt;
    &lt;p&gt;Andie Bandie&lt;/p&gt;
    &lt;p&gt;Justin Irabor&lt;/p&gt;
    &lt;p&gt;Eddy Lee&lt;/p&gt;
    &lt;p&gt;Sandeep M&lt;/p&gt;
    &lt;p&gt;Sergey Votyagov&lt;/p&gt;
    &lt;p&gt;Gina Biernacki&lt;/p&gt;
    &lt;p&gt;Felipe Chor&lt;/p&gt;
    &lt;p&gt;Kevin George&lt;/p&gt;
    &lt;p&gt;Dan Cayer&lt;/p&gt;
    &lt;p&gt;Substantive changes that have been made to this manifesto:&lt;/p&gt;
    &lt;p&gt;11/18/25 - Changed several instances of the word "user," to "people" or other humanistic alternatives. The word user carries heavy connotations of addiction.&lt;/p&gt;
    &lt;p&gt;10/28/25 - Updated the first principle (private) to include more nuanced language around the ownership of data. People must be the primary stewards of their context, but every system has multiple stakeholders.&lt;/p&gt;
    &lt;p&gt;10/28/25 - Updated the second principle (dedicated) to include the "contextual integrity" privacy model.&lt;/p&gt;
    &lt;p&gt;10/27/25 - Added header artwork and poetic introduction.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46659456</guid><pubDate>Sat, 17 Jan 2026 16:43:59 +0000</pubDate></item><item><title>Apples, Trees, and Quasimodes</title><link>https://systemstack.dev/2025/09/humane-computing/</link><description>&lt;doc fingerprint="fd9b9b1c22e783ab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Apples, Trees, and Quasimodes&lt;/head&gt;
    &lt;p&gt;A while back, Ars Technica published a thoughtful piece about Jef Raskin, tracing his long pursuit of the “humane computer” and the cul-de-sacs where that pursuit ended. It’s a generous, well-told account of the designer who wanted to make machines simpler, kinder, and more aligned with the way people actually think.&lt;/p&gt;
    &lt;p&gt;But part of what makes Raskin interesting is that his story isn’t just Apple’s story. He came out of the same cultural current John Markoff chronicled in What the Dormouse Said—the Bay Area tradition that treated computers not as office appliances but as tools for thought, instruments of liberation. Read that way, the Canon Cat and Raskin’s other projects aren’t just an eccentric side quest from a frustrated Apple veteran. It’s evidence of how far the humane ideal could stretch, and how quickly it ran up against the limits of commercial computing.&lt;/p&gt;
    &lt;p&gt;Apple couldn’t deliver Raskin’s vision then, and it can’t deliver it now. Neither can any other big platform company. If we want to understand why, and what Raskin still tells us about humane computing, we have to put him back in the longer lineage he belonged to, and look at how his version of the dream carried that vision but also narrowed it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Prophets and participants&lt;/head&gt;
    &lt;p&gt;What the Dormouse Said documents how the Bay Area counterculture shaped early personal computing. LSD, communes, systems theory, amorphous defense research contracts, and Engelbart’s “augmentation” experiments all swirled together in a weird scene that accidentally (or maybe not so accidentally) created much of the modern world.&lt;/p&gt;
    &lt;p&gt;The story usually gets told with a neat list: Engelbart’s demo, Nelson’s Xanadu hypertext, Kay’s Dynabook, Brand’s Whole Earth. Xerox PARC, Steve Jobs, the World Wide Web. The familiar pantheon. But that version turns a messy, improvisational moment into a plaque. Engelbart’s system needed a whole research staff just to operate; Nelson’s Xanadu was (and is) more sermon than software; Kay’s Dynabook lived mostly on paper; Brand mostly supplied vocabulary and vibe. What bound them together wasn’t working code so much as the conviction that computers could be more than appliances and calculators, even if no one agreed on what “more” meant.&lt;/p&gt;
    &lt;p&gt;Ultimately all these weird white guys had a futurist vision: computers could be liberation machines. They weren’t just for business automation or scientific number-crunching; they could be deployed to expand consciousness and reshape how people thought and worked.&lt;/p&gt;
    &lt;p&gt;Raskin belonged to this current. Before Apple, he was an artist and a musician. He brought a humanist’s suspicion of machine logic into the design lab. He argued for humane interfaces: modeless, predictable, low-friction, focused on the human first. He wasn’t a prophet on his own crying in the wilderness so much as another strand of the same weave.&lt;/p&gt;
    &lt;p&gt;That said, his role was different than that of some of these other figures. He tried to pull those ideals out of the lab and into machines ordinary people might actually use. The Macintosh began under his hand, though what shipped was less a tool for thought than a polished derivative—what you might call a “popular religion” of computing, stripped of the harder doctrines.&lt;/p&gt;
    &lt;p&gt;The Canon Cat and its predecessors were Raskin’s counterargument: humane, text-first systems that tried to carry the spirit of the Dormouse tradition into the commercial world without sanding off everything that made it strange. It sort of worked, but only sort of.&lt;/p&gt;
    &lt;head rend="h2"&gt;Raskin’s Humane vision&lt;/head&gt;
    &lt;p&gt;Raskin’s principles are laid out most clearly in 2000’s The Humane Interface, but he’d been developing them since the late 1970s:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modelessness: eliminate modes generally, and especially when they confuse users or are hard to reason about.&lt;/item&gt;
      &lt;item&gt;Quasimodes: short-lived states (like holding a key down) that don’t trap the user.&lt;/item&gt;
      &lt;item&gt;Humane defaults: undo everywhere, consistent commands, predictable behavior.&lt;/item&gt;
      &lt;item&gt;Low cognitive load: interfaces designed around human memory and perception limits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These ideas are recognizably part of the “Tools for Thought” tradition. Like Engelbart and the others, he wanted to reduce friction between thought and machine. Like Nelson, he believed in fluidity and extension.&lt;/p&gt;
    &lt;p&gt;But there’s a subtle difference. For Engelbart, augmentation meant complexity: bootstrapping a system so wild it demanded co-evolution between user and tool. For Nelson, it meant endless layers of possibility. For Raskin, it often meant protection or constraint. Humane computing wasn’t only about empowerment… often it was about shielding users from mistakes, overload, and confusion.&lt;/p&gt;
    &lt;p&gt;That protective impulse would shape the systems he built.&lt;/p&gt;
    &lt;p&gt;Raskin’s first clear articulation of his humane ideals wasn’t hardware at all but The Macintosh Papers, his internal proposal at Apple for a low-cost, appliance-like computer that would boot straight into a simple, modeless interface. The Mac project that followed eventually diverged—under Steve Jobs it became a graphical machine aimed at competing with the Lisa, for the reasons we’ve all read about—but Raskin’s vision was considerably more radical. He imagined a computer that behaved less like a business workstation and more like a humane, everyday tool.&lt;/p&gt;
    &lt;p&gt;In tone, the Macintosh Papers have more in common with Ted Nelson’s Computer Lib than with any corporate white paper. They read like a manifesto: plainspoken, insistent, arguing that ordinary people deserved machines that bent to them rather than the other way around. Where Nelson declared that “you can and must understand computers now,” Raskin’s papers laid out what such a computer should look like if you started from human needs instead of technical conventions. Both belong to that peculiar genre of the 1970s and early ’80s: the computing manifesto as cultural text, half engineering and half tract.1&lt;/p&gt;
    &lt;p&gt;You could argue that the Swyft, built a few years later by his company Information Appliance Inc., was “the real Macintosh” in that sense. Compact and text-first, it booted instantly, eliminated modes, and introduced the Leap keys for fluid navigation. It was Raskin’s manifesto rendered in hardware. But the Swyft never made it to market; without a manufacturer to back it, Information Appliance pivoted to the SwyftCard, a fallback product that brought the same interface into the Apple II while IA waited to find a dance partner.&lt;/p&gt;
    &lt;p&gt;That partner came briefly in 1987, when Canon released the Canon Cat, the only mass-produced computer to carry Raskin’s humane vision into the world. The Cat retained the Swyft’s defining ideas: instant boot into a blank page, consistent commands, Leap-based navigation. Marketed as a word processor, it was framed as an appliance for the office rather than an exploratory tool for thought.&lt;/p&gt;
    &lt;p&gt;After its failure, Raskin returned to the same design principles in the 1990s with Archy, an unfinished software environment that tried once again to realize his humane interface on contemporary hardware. Archy never reached a finished state, but it shows how Raskin’s ideas kept circling back to the same point: computing stripped down to words, presented as simply and predictably as possible.&lt;/p&gt;
    &lt;p&gt;I’ve always had a real fondness for the Swyft/Cat lineage, and it’s certainly influenced what I think a computer can be. Each one of these attempts embodied humane design: a blank screen for writing, consistent commands, no modes to trip over. The Cat in particular was radical in its way—a computer designed to feel less like a computer and more like a natural extension of the mind. It truly could have changed everything about how we use our computers had it succeeded.&lt;/p&gt;
    &lt;p&gt;Unfortunately for all of us, by 1987, the market for dedicated word processors was already fading. Canon didn’t seem to know what to do with the Cat—whether to sell it as an office appliance, a PC competitor, or something stranger—and the result was that it fit nowhere. Raskin’s design pushed toward humane simplicity, but Canon’s marketing treated it like just another machine for typing memos.&lt;/p&gt;
    &lt;p&gt;It isn’t surprising that it failed, though it’s hard not to wonder how it might have landed a few years earlier, when the ground was more open. As it is, the Cat survives less as a commercial product than as an idea in hardware—a glimpse of what a computer could look like if the whole thing were rebuilt around text, consistency, and genuine care for the user.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Paradox of Openness&lt;/head&gt;
    &lt;p&gt;The Cat also embodies why Raskin’s philosophy was not necessarily on the same wavelength as some of those other visionary systems. On the surface, the Canon Cat looked open. It booted to a blank screen. Everything was text. You could jump anywhere, edit fluidly, undo anything. Compared to the modal labyrinth of DOS or early Mac software, it felt like freedom.&lt;/p&gt;
    &lt;p&gt;But look closer and you see the narrowing. The Cat gave you fewer ways to improvise. Its humane design was also constraining design. It reduced your options in order to keep you safe.&lt;/p&gt;
    &lt;p&gt;The real irony is that the Cat wasn’t even truly closed in the way a smartphone or Chromebook might be considered so today. Underneath, it ran on a Forth environment. You could, if you knew how, drop into Forth and even program directly in 68k assembler. In principle, it was as open as any hacker could want, at least from a software perspective.&lt;/p&gt;
    &lt;p&gt;The catch was cultural, not technical. From the Ars piece:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;IAI’s back door to Forth quietly shipped in every Cat, and the clue was a curious omission in the online help: USE FRONT-ANSWER. This otherwise unexplained and unused key combination was the gateway. If you entered the string&lt;/p&gt;&lt;code&gt;Enable Forth Language&lt;/code&gt;, highlighted it, and evaluated it with USE FRONT-ANSWER (not CALC; usually Control-Backspace in MAME), you’d get a Forth&lt;code&gt;ok&lt;/code&gt;prompt, and the system was now yours. Reset the Cat or type&lt;code&gt;re&lt;/code&gt;to return to the editor.&lt;/quote&gt;
    &lt;p&gt;Canon didn’t provide documentation that would have made that power accessible, and Raskin’s design philosophy treated it as outside the normal use case. Extensibility was there if you knew where to look for it, but it wasn’t encouraged. The humane interface was meant to keep most users away from the hood, even though what was under the hood was remarkably open.&lt;/p&gt;
    &lt;p&gt;That makes the Cat’s paradox sharper: it was a genuinely extensible software environment (up to a point) presented as a sealed appliance. The hardware mostly was a sealed appliance. Contrast this with Emacs or Smalltalk, where openness is the posture of the environment itself. You are expected to extend and reshape as you go, building your tools out of themselves. The Cat offered the same possibility–Forth is a remarkably flexible language, especially for microcomputers–but it discouraged you from taking it.&lt;/p&gt;
    &lt;p&gt;Humane computing, in Raskin’s hands, edged toward hermetic computing. He built openness in, but sealed it away behind an interface designed to keep it out of sight.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cul-de-sacs vs. Branches&lt;/head&gt;
    &lt;p&gt;All of this, to me, is why calling Raskin’s systems thinking a “cul-de-sac” misses the point, and is the wrong way to think about his legacy.&lt;/p&gt;
    &lt;p&gt;If “cul-de-sac” means “product that didn’t sell,” then sure, the Cat and SwyftCard qualify. They were total dead-ends. But by that same measure, Engelbart’s NLS, Nelson’s Xanadu, Kay’s Smalltalk, or even Lotus Agenda are dead-ends, too. By that measure, most of the “Tools for Thought” tradition didn’t lead anywhere.&lt;/p&gt;
    &lt;p&gt;The reality is different. These systems were branches. They were rhizomes, in the Deleuze and Guattari sense. They didn’t reach the mainstream, but they seeded ideas that echoed elsewhere, connecting threads that run throughout the history of computing. Hypertext, graphical interfaces, undo, modeless editing—all of these survived in one form or another.&lt;/p&gt;
    &lt;p&gt;Raskin’s branch is no exception. His machines exposed a fundamental tension inside the tradition: how far do you go in protecting the user from complexity? At what point does “humane” become “hermetic”? Those questions didn’t vanish with the Cat. They’re still with us every time a productivity app promises “simplicity” at the cost of agency.&lt;/p&gt;
    &lt;p&gt;Raskin’s humane ideals live on in obvious ways, to the benefit of anyone using a graphical computer today—undo everywhere, discoverability, and consistent commands and shortcuts are now interface common sense. But the deeper thread, the ethos that inspired him and others in the tradition of computers as tools for thought, survived mostly outside the mainstream. It persists in systems that never had to sell millions of units or satisfy quarterly targets, that never had to justify their existence to the mass of people using PCs—tools that could afford to remain strange, open, and humane on their own terms. Emacs, Oberon, and Smalltalk belong here, but so do newer experiments like Uxn and 9front.&lt;/p&gt;
    &lt;p&gt;The Cat failed partly because it tried to straddle two worlds: commercial appliance and humane machine, whereas something like Emacs survives precisely because it never had to. It’s as complex as you want it to be.&lt;/p&gt;
    &lt;p&gt;This is the sharper point: radical, humane, exploratory computing never survives in the mainstream. The mainstream is built for profit and predictability. Even Engelbart’s work was DARPA-funded, not venture-backed. When you put humane ideals through commercial constraints, they collapse into simplistic appliances, the “For Dummies” version of the original intent. That doesn’t mean the tradition is dead. But it does mean you have to look off to the side, away from the market’s center, to see it alive.&lt;/p&gt;
    &lt;head rend="h2"&gt;The dilemma(s)&lt;/head&gt;
    &lt;p&gt;Raskin’s story sharpens two dilemmas that haven’t gone away.&lt;/p&gt;
    &lt;p&gt;The first is practical: make a system too open, and it risks being overwhelming. Make it too humane, and it risks narrowing into something sealed and hermetic, and not useful enough. The Cat, while also a victim of other factors, tried to balance the two and ended up fitting nowhere.&lt;/p&gt;
    &lt;p&gt;The lesson isn’t that humane computing is impossible. It’s that humane computing can’t just mean protective computing. It has to mean trusting users with both simplicity and openness. That’s why Org mode and even Mac System 7 endure and the Cat does not.&lt;/p&gt;
    &lt;p&gt;The deeper implication is harder, but maybe truer: the true Tools for Thought we still wish existed will never come from Apple, Microsoft, Google, OpenAI, or any other large player in the software or hardware space. They can’t. These companies’ scale and incentives point elsewhere—toward lock-in, surveillance, and products that are safe enough to sell but never open enough to empower. The logic of scale makes them constitutionally incapable of building systems that are truly humane and open. The next humane systems, if they arrive, will have to come from outside those walls, as they always have: from margins, from hobbyists, from research labs, and from stubborn communities of practice. But as those platform companies make it more and more difficult to experiment, how do we keep pushing these philosophies forward?&lt;/p&gt;
    &lt;p&gt;Jef Raskin’s philosophy isn’t a cul-de-sac in computing history. He’s responsible for a branch of the “Tools for Thought” tradition—a branch that shows both the promise and the peril of humane design. His machines make clear how far you can go when you put the human first, and how easily that ideal can collapse into constraint once it’s pushed through commercial channels and turned into walled gardens.&lt;/p&gt;
    &lt;p&gt;The humane thread survives, but only outside the center—in the tools that don’t have to answer to quarterly earnings, in projects that refuse to die just because they don’t fit the market. The Dormouse lineage isn’t gone. It just doesn’t live where the money is, because it can’t. If you want your computer to be humane in the deeper sense—not an appliance, but an instrument for thought—you have to look to the margins. That’s where it has always been, and where it still is today. If it survives, that’s where it’ll still be.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;That genre, “photocopied computer manifesto,” is very much the reason this blog exists. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Published September 18, 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46659465</guid><pubDate>Sat, 17 Jan 2026 16:44:45 +0000</pubDate></item><item><title>An Elizabethan mansion's secrets for staying warm</title><link>https://www.bbc.com/future/article/20260116-an-elizabethan-mansions-secrets-for-staying-warm</link><description>&lt;doc fingerprint="b42e10265ba205d0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;'The past is an underused tool': An Elizabethan mansion's secrets for staying warm&lt;/head&gt;
    &lt;p&gt;In a bleak, deadly period of cold weather known as the Little Ice Age, clever Elizabethan designs helped keep a magnificent stately home unusually warm. The house has lessons for how we can heat our homes more efficiently today.&lt;/p&gt;
    &lt;p&gt;England's longest river was usually flowing freely. But on New Year's Eve in 1564, the River Thames was frozen solid, from bank to bank. Bonfires crackled on the stuck-fast surface, oxen roasted on spits, and people danced on the ice. Some accounts say that Queen Elizabeth I even practised archery on the glacial river. This sort of thing wasn't a one off. It had happened before: King Henry VIII and his queen had dashed downriver in a sleigh nearly three decades previously in 1537.&lt;/p&gt;
    &lt;p&gt;These frosty conditions were the result of a climatic plot twist roughly between the 14th and 19th centuries, known today as the Little Ice Age. As well as festivals on the ice, this prolonged cold period brought periods of famine, and frightening unseasonable frosts. Soldiers froze to death in the middle of the European summer.&lt;/p&gt;
    &lt;p&gt;The cold forced Europeans to develop new ways of coping with extreme weather. One of the best-studied examples of architectural adaptation is Hardwick Hall in Derbyshire, England – a building whose design is a carefully choreographed effort to keep as warm as possible.&lt;/p&gt;
    &lt;p&gt;The same tricks for more efficient heating can be used in modern designs, helping reduce our reliance on fossil fuels today. And they can even inspire small changes in our existing homes to keep temperatures cosier through the winter without turning up the thermostat.&lt;/p&gt;
    &lt;head rend="h2"&gt;An 'exceptional' house&lt;/head&gt;
    &lt;p&gt;I drive the long, meandering driveway uphill to the house, confronted by the occasional long-horn cattle grazing between leafless oak trees. At the crest of the hill, I'm met with a striking sight: not one hall, but two.&lt;/p&gt;
    &lt;p&gt;Hardwick "old" Hall is massive, despite its ruinous state. I can tell it's been repeatedly extended over the years, as the bricks are misaligned at the joins of each extension and the windows are mismatched in style and size across the facade.&lt;/p&gt;
    &lt;p&gt;What caused the Little Ice Age?&lt;/p&gt;
    &lt;p&gt;It appears there's no single cause of the Little Ice Age, but a deadly and complex combination. Scientists have found evidence for reduced solar activity, increased volcanic eruptions, changes in ocean circulation and the natural fluctuations within the global climate system. In addition, the arrival of the Europeans in North America in the late 15th Century led to an estimated 56 million deaths of indigenous peoples, resulting in widespread abandonment of farming and regrowth of forests. More trees mean less planet-warming gases were circulating in the atmosphere, reducing the global average temperature.&lt;/p&gt;
    &lt;p&gt;Hardwick "new" Hall is a few dozen metres away. This pale yellow manor was built in the 1590s and is eye-pleasingly symmetrical, complete with three-story turrets and huge expanses of glass. Whoever quipped at the time of its construction that it was "more window than wall" was right. It is a magnificent display of wealth, built in a time when glass was extremely expensive.&lt;/p&gt;
    &lt;p&gt;Elizabeth (Bess), Countess of Shrewsbury, was the woman who had deep enough pockets to build it. She was mid-way through extending the massive, rambling Hardwick "old" Hall, but for some reason or another, stopped midway through and began afresh. The experts I spoke to say we don't know why she did that, but theories range from coming into money when her husband died and feeling the need to have a house in keeping with her elevated status, to using what she'd learnt in previous builds to design a house warm and cosy for a lady approaching her seventies and living through the Little Ice Age.&lt;/p&gt;
    &lt;p&gt;"The late 16th Century is really one of the coldest stretches of the Little Ice Age, and it's bitterly cold in England," says Dagomar Degroot, professor of environmental history at Georgetown University in Washington, DC, and author of The Frigid Golden Age.&lt;/p&gt;
    &lt;p&gt;Global average temperatures during the Little Ice Age dipped "at most" by 0.5C (less than 0.9F), with impacts mostly documented in the northern hemisphere. That figure is an average over about five centuries, so temperatures would have swung more dramatically year to year and region to region.&lt;/p&gt;
    &lt;head rend="h2"&gt;Turning to the Sun&lt;/head&gt;
    &lt;p&gt;A key difference between the old hall and the new hall is their orientation in relation to the Sun. The old hall is just off east-west. The new hall has been rotated by about 90 degrees, which means it can soak up much more sunshine and, therefore, heat.&lt;/p&gt;
    &lt;p&gt;"The incredible thing about Hardwick [new Hall] is… when you set it on the compass, it's almost exactly north-south," says Ranald Lawrence, a lecturer in architecture at the University of Liverpool in the UK. He's also published papers on Hardwick's design and thermal comfort. "And," he adds, "the whole internal planning of the [new] house is then based around that geometry."&lt;/p&gt;
    &lt;p&gt;Bess moved around the rooms, following the Sun's path. Her mornings were spent walking the 63m (200ft) east-facing Long Gallery, where the bright morning light hits. The afternoon and evening Sun illuminates the south-western flank of the building, where Bess' bed chambers were. And the darkest, coldest corner of the house in the north-west was where the kitchens were placed, which would have been handy in keeping food cool and fresh.&lt;/p&gt;
    &lt;p&gt;I experience this first hand as I walk around – the kitchens are much colder. Elena Williams, the senior house and collections manager at The National Trust, a UK charity which preserves historic sites, notices too. "It's a well-designed building that is also designed around comfort and that uses the natural environment to do that," she says.&lt;/p&gt;
    &lt;head rend="h2"&gt;Windows, walls and fireplaces&lt;/head&gt;
    &lt;p&gt;It's not just the orientation that helps keep the house warm. As Williams shows me around, she points out that some of the windows on the north of the building are actually "blind" or fake. She explains that on the outside, there is a window, but on the inside, it's lined with lead and blocked up. Unlike south-facing windows, north-facing windows bring little thermal benefit, even in summer, Lawrence says.&lt;/p&gt;
    &lt;p&gt;Pretty much all the fireplaces I see are also built on the central spine of the building, meaning not much heat would be lost to the windows or exterior wall. It's not until we take a door through this spine that I realise that the girth of it is staggering – 1.37m (4.5ft) thick. This is yet another trick to keep its inhabitants warm.&lt;/p&gt;
    &lt;p&gt;"You have thermal mass, effectively," Lawrence says. "So something heavy like brick or stone, like you have at Hardwick, stores the heat from the fire and gives it out 12 hours later."&lt;/p&gt;
    &lt;p&gt;All these construction techniques appear to have made a difference. Lawrence has measured the temperature difference between inside and outside in modern times and depending on the season and weather, he told me it can feel around 10C (18F) warmer inside on a cold winter's day. Other, typical Elizabethan houses, he estimates, would have only feel 2-3C (3.6-5.4F) warmer.&lt;/p&gt;
    &lt;p&gt;The Tudors had other coping mechanisms, Williams says – like lining the walls with thick tapestries – adding further thermal mass and keeping out the drafts. Curtains were hung around the beds and over some of the windows too. And Elizabethan fashion of giant neck ruffs and layers and layers of linens, thick velvet and fur all helped people like Bess keep warm.&lt;/p&gt;
    &lt;p&gt;Other large and flashy manors at the time were using some of the same solar strategies. But Lawrence believes Hardwick is "exceptional" in the way these elements are carefully integrated and brought together.&lt;/p&gt;
    &lt;p&gt;Though Lawrence says there is no written evidence to suggest that the architectural designs were purposeful, he thinks that "it can't be coincidence". Williams agrees. "I think they definitely thought about using the Sun in the design of Hardwick," she says.&lt;/p&gt;
    &lt;p&gt;All this despite the fact that the Elizabethans may have been unaware that they were living through what is now known as the Little Ice Age, says Degroot. "Why would I expect somebody living 400 years ago would realise that their climate was 0.5C colder than the climate had been in their mother's or father's lifetime?"&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons for modern times&lt;/head&gt;
    &lt;p&gt;There are still lessons we can learn today when we build new homes and in the way we use the ones we've already got – especially with the need to heat and cool our homes more efficiently in order to save money and tackle climate change.&lt;/p&gt;
    &lt;p&gt;"The past is an underused tool," Degroot says. "I think by trying to identify the complex and diverse ways in which people responded to history's climate changes, we can come up with new tools for understanding how we might respond in the future and for identifying responses that are constructive versus destructive."&lt;/p&gt;
    &lt;p&gt;Brutalist architects Peter and Alison Smithson knew of and even admired Hardwick Hall. Some academics claim that it likely inspired their own designs, like the Solar Pavillion, in south-west England, which is only has glass on its east, west and south-facing walls. Sun-soaking designs aren't just the preserve of the rich, though. One of London's most striking council estates is on Alexandria Road in Camden, in the north of the city, and Lawrence says it too features south facing terraces with lots of concrete to store the Sun's heat.&lt;/p&gt;
    &lt;p&gt;But on the whole, he tells me, we generally don't use these Elizabethan building secrets. Instead, we use air conditioning and heating in an attempt to override building designs that are poorly suited to their climate.&lt;/p&gt;
    &lt;p&gt;"Our assumption that the solution to all of our problems is technological," Lawrence says. Glass box skyscrapers, now common in both cold and hot climates, are a good example of this. In winter, heat escapes through the glass, and require a lot of heating. Conversely in summer, the glass traps the heat – like a greenhouse – and require massive amounts of energy for cooling.&lt;/p&gt;
    &lt;p&gt;But without taking apart our existing housing and building it again from scratch, there are also micro-adjustments we can make.&lt;/p&gt;
    &lt;p&gt;More like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hacks to keep your home warmer&lt;/item&gt;
      &lt;item&gt;The homes heated without fossil fuels&lt;/item&gt;
      &lt;item&gt;How living in a cold home affects your health&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I get a compass out at my house – for the first time – and begin to think about how I could follow the Sun's path throughout the day. Since it's winter, and cold, I move my desk to a south-eastern window. It brightens the mornings and if I wear another layer, I find I can lower the thermostat by 2C (3.6F). Longer term, I've been thinking about planting a tree just outside. In a couple of decades, it would shade my house from scorching heatwaves that are predicted to be much more common because of climate change.&lt;/p&gt;
    &lt;p&gt;These are modest changes, imperceptible to most, and they won't enable us to forgo active heating and cooling entirely. But they do echo a way of thinking which, today, is oft ignored. Hardwick Hall was designed with Sun, season and temperature in mind. It paid attention to the world outside its walls. As the climate becomes more volatile, architecture that works with its environment feels more urgent than ever.&lt;/p&gt;
    &lt;p&gt;--&lt;/p&gt;
    &lt;p&gt;For essential climate news and hopeful developments to your inbox, sign up to the Future Earth newsletter, while The Essential List delivers a handpicked selection of features and insights twice a week.&lt;/p&gt;
    &lt;p&gt;For more science, technology, environment and health stories from the BBC, follow us on Facebook and Instagram.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46659550</guid><pubDate>Sat, 17 Jan 2026 16:53:24 +0000</pubDate></item><item><title>Show HN: What if your menu bar was a keyboard-controlled command center?</title><link>https://extrabar.app/</link><description>&lt;doc fingerprint="21dcd83b7d1977a9"&gt;
  &lt;main&gt;&lt;p&gt;ExtraBar brings Mac users a customizable menu bar with instant access to apps, deep links, and custom actions. Requiring zero permissions to work.&lt;/p&gt;&lt;p&gt;Create custom actions for any app or file. Use Deep Links, trigger macOS Shortcuts, and so much more, tailored to your workflow.&lt;/p&gt;&lt;p&gt;Launch any app screen, setting, or feature directly. No menu clicking required. Get instant access to exactly where you want to be.&lt;/p&gt;&lt;p&gt;Switch between inline and floating bar mode. Choose inline mode for native menu bar integration, or floating mode for a customizable separate bar.&lt;/p&gt;&lt;p&gt;Assign one global hotkey to interact with ExtraBar. Use numbers or arrows to navigate easily between apps and menus.&lt;/p&gt;&lt;p&gt;Designers, developers, founders, everyone gets the same bar with the same limitations. Each one has different needs,&lt;/p&gt;&lt;p&gt;but the menu bar stays the same.&lt;/p&gt;&lt;p&gt; The macOS menu bar was designed to show system info and app icons.&lt;lb/&gt; It wasn't built to help you do things quickly. You get: &lt;/p&gt;&lt;p&gt;Designers, developers, founders, everyone gets the same bar with the same limitations. Each one has different needs,&lt;/p&gt;&lt;p&gt;but the menu bar stays the same.&lt;/p&gt;&lt;p&gt; The macOS menu bar was designed to show system info and app icons.&lt;lb/&gt; It wasn't built to help you do things quickly. You get: &lt;/p&gt;&lt;p&gt;ExtraBar is made for...&lt;/p&gt;&lt;p&gt;Designers&lt;/p&gt;&lt;p&gt;Developers&lt;/p&gt;&lt;p&gt;Managers&lt;/p&gt;&lt;p&gt;Power Users&lt;/p&gt;&lt;p&gt; Access your daily design tools instantly. Open specific Figma files, frames, and prototypes! &lt;lb/&gt; You can also open assets and folders straight from your menu bar. &lt;/p&gt;&lt;p&gt;Part of a team? Open your Slack channel directly from the menu.&lt;/p&gt;&lt;p&gt; Jump straight into your code project.&lt;lb/&gt; Open specific projects in your IDE, terminal sessions, and anything else with a deep link! &lt;/p&gt;&lt;p&gt;Client call? Hit a hotkey and jump straight into your Zoom call.&lt;/p&gt;&lt;p&gt;Stay on top of your team. Open specific dashboards, reports, and Slack channels! Effortlessly jump into WhatsApp chats with your most used contacts.&lt;/p&gt;&lt;p&gt;Running late? Join your Zoom or Google Meet directly from the menu bar.&lt;/p&gt;&lt;p&gt;Build your perfect workflow. Create custom actions, keyboard shortcuts, and deep links! Leverage tools like Raycast to unlock a new level of productivity with deep links.&lt;/p&gt;&lt;p&gt;One hotkey to rule them all, One hotkey to find them, One hotkey to launch them all, and in the menu bind them.&lt;/p&gt;&lt;p&gt;A glimpse into your future workflow. Clean, powerful, and always a single hotkey away.&lt;/p&gt;&lt;p&gt;Your Command Center — Organize apps, folders and files in one intuitive management screen.&lt;/p&gt;&lt;p&gt;Total Control — Define custom labels, choose action types, and configure every detail your way.&lt;/p&gt;&lt;p&gt;Deep Links — Skip the clicks. Land exactly where you need to be.&lt;/p&gt;&lt;p&gt;Full Control — Browse through action presets designed for your favorite apps.&lt;/p&gt;&lt;p&gt;Make It Yours — Personalize colors, layouts, and behaviors to match your setup.&lt;/p&gt;&lt;p&gt;The difference between&lt;/p&gt;&lt;p&gt;Apps like Bartender, Ice and Barbee are built to hide, organize, and manage menu bar icons. To achieve that, they require system-level permissions that allow them to record your screen, and manage accessibility.&lt;/p&gt;&lt;p&gt;ExtraBar is built for action, not icon management. It requires zero permissions to work. Simply download, add your apps and you're set. Optionally enable accessibility for enhanced keyboard navigation.&lt;/p&gt;&lt;p&gt;The difference between&lt;/p&gt;&lt;p&gt;Apps like Bartender, Ice and Barbee are built to hide, organize, and manage menu bar icons. To achieve that, they require system-level permissions that allow them to record your screen, and manage accessibility.&lt;/p&gt;&lt;p&gt;ExtraBar is built for action, not icon management. It requires zero permissions to work. Simply download, add your apps and you're set. Optionally enable accessibility for enhanced keyboard navigation.&lt;/p&gt;&lt;p&gt;We're excited to finally launch ExtraBar! During launch month, you can get lifetime access with one time payment.&lt;/p&gt;&lt;p&gt;After January 31, the price will be €24.99&lt;/p&gt;&lt;p&gt;Taxes might apply&lt;/p&gt;&lt;p&gt;We're excited to finally launch ExtraBar! During launch month, you can get lifetime access with one time payment.&lt;/p&gt;&lt;p&gt;After January 31, the price will be €24.99&lt;/p&gt;&lt;p&gt;Taxes might apply&lt;/p&gt;&lt;p&gt;One-time payment · Lifetime updates · 14-day money-back guarantee&lt;/p&gt;Start using ExtraBar&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46659943</guid><pubDate>Sat, 17 Jan 2026 17:31:21 +0000</pubDate></item><item><title>Raising money fucked me up</title><link>https://blog.yakkomajuri.com/blog/raising-money-fucked-me-up</link><description>&lt;doc fingerprint="7d4e111769e460bd"&gt;
  &lt;main&gt;
    &lt;p&gt;About four months ago I quit my job at Doublepoint and decided to start my own thing.&lt;/p&gt;
    &lt;p&gt;I'd been working on a little project with Pedrique (who would become my co-founder) for a bit over half-a-year and decided I had enough signal to determine he was someone I wanted to start a business with.&lt;/p&gt;
    &lt;p&gt;I was excited about the idea we were working on at the time, but being truly honest about my motivations, I mostly wanted to run my own thing. In a dream world I'd have had the "idea of my life" while working at PostHog or Doublepoint and have gone on to build that with maximum conviction but this wasn't the case, so I got tired of waiting for a spark and decided to go out and make it happen, with the idea we were working on being our best bet at the time.&lt;/p&gt;
    &lt;p&gt;Since I'd just quit my job, I had my finances well in order. Thus, my ideal scenario would have been to work on the idea we had the MVP for, try to get it off the ground, and if that didn't work, try something else, then something else, until something did indeed get off the ground, and only at that point we would consider whether or not to raise VC funding, depending on whether it made sense or not.&lt;/p&gt;
    &lt;p&gt;My ideal scenario wasn't going to work for Pedrique, though. He had told me for a while that the money he had saved up for trying to build his own thing was running out and that soon he'd need to start freelancing or something to make some income in order to sustain the search for a little longer. Prior to us working together, he had a bit of success with his MicroSaaS products but only just enough to increase his personal runway, which was now reasonably short.&lt;/p&gt;
    &lt;p&gt;We had spoken about this before, but with me now being 110% in, we had to do something about it. I had just come in full-time so we weren't about to go back to a dynamic where one person was full-time and the other part-time because they needed to make ends meet. The decision then became clear: we're gonna raise.&lt;/p&gt;
    &lt;p&gt;At that point, it was an easy decision to make. Again, we have two co-founders who have a lot of confidence in each other, and we don't want to let the opportunity pass us by. So while this wasn't my ideal choice, we were a business now and this was the best decision for the company. "Just don't die" goes the advice I think, and Skald had just then been born.&lt;/p&gt;
    &lt;p&gt;And so raise we did. We brought in four phenomenal angels, including, and this is relevant, my last few bosses (PostHog co-founders James and Tim and Doublepoint co-founder Ohto), and then decided to look for an early-stage fund. We eventually landed with Broom Ventures and passed up on a few other opportunities to limit dilution.&lt;/p&gt;
    &lt;p&gt;Great, right? I didn't need a salary yet, but for equality purposes, I now had one. Our investors are amazing. James and Ohto have been particularly helpful as angels (thank you!), and our investors are all founders of successful companies, including Jeff and Dan, the Broom GPs. We're super early, but Broom has been massively helpful and all-around just a great hands-off VC to deal with.&lt;/p&gt;
    &lt;p&gt;Most importantly, none of them put any pressure on us. All understand the nature of pre-seed investing well, and that can't be said about all the potential investors we took meetings with.&lt;/p&gt;
    &lt;p&gt;So some time passes and we decide to pivot. We're really excited about the new idea. We launch and get a bit of early traction. The open source project is doing well, but we're struggling to monetize. We fail to close a few customers and the traction wanes a bit.&lt;/p&gt;
    &lt;p&gt;Then I find myself fucked in the head.&lt;/p&gt;
    &lt;p&gt;And here's where we get to the point that I'm not sure I should be talking publicly about. Does this hurt my image a bit? Maybe. Do I look like I'm not cut for this? Potentially. But I've always appreciated when people share about the process rather than just talking about things in hindsight, and reflecting while things are happening + being super transparent publicly is how I am. You're witnessing my growth, live, as I type these words.&lt;/p&gt;
    &lt;p&gt;Anyway, so what happened is I found myself spending days with my head spinning, searching for ideas. I'm angry, I'm annoyed, and I'm not being super productive.&lt;/p&gt;
    &lt;p&gt;As I dug deeper into these feelings, I realized I was feeling pressured. We weren't making that much money, we weren't growing super fast. Then you look around and see "startup X gets to $1M ARR a month after launch" and shit like that and I'm feeling terrible about how we're barely growing. I'm thinking people that I really respect and admire have placed a bet on me and I'm letting them down.&lt;/p&gt;
    &lt;p&gt;Except they're not saying this, I am.&lt;/p&gt;
    &lt;p&gt;There's an interesting reflection that came up in a discussion between me and my girlfriend a few months prior that I realized applied to me, but in reverse. It's much more comfortable to be the person that "could be X" than to be the person that tries to actually do it. We were speaking about this regarding people who have a clear innate talent for something like music or sports but don't practice at all. Everyone says things like "you'd be the best at this if you just practiced more" but then they never do.&lt;/p&gt;
    &lt;p&gt;The thing is: it's a lot easier to live your life thinking you could have done X if you wanted to, than to "disappoint" these people that believed in you by trying and failing. You can always lean on this idea in your head of what you could have been, and how everyone believed in you so it must be true, but you just chose not to follow that path.&lt;/p&gt;
    &lt;p&gt;In my case, I found myself on the other side of that coin. Throughout my career, I've always had really high ownership roles, and have been actively involved in a couple 0 to 1 journeys. This led me throughout my career to get many comments about how great of a founder I'd be or how I have the "founder profile". I led teams, I wore a bunch of different hats, I worked hard as fuck, and I always thought about the big picture.&lt;/p&gt;
    &lt;p&gt;Those traits led my former bosses to then invest in me, and now suddenly I have to, in my head, live up to all of this. I can no longer take solace in some excuse like "I could have been a founder but working full-time was the best financial decision (it almost always is) so I never started my own thing". I set foot down a path from which there's no return. I've begun my attempt. I can of course stop and try again later. But from now on, I'm either gonna be a successful founder, or I'm not. And if I'm not, I'll have to deal with having broken with the expectations that people had of me.&lt;/p&gt;
    &lt;p&gt;There's a lot to unpack here, including what "success" means, and how most of what I say are other people's expectations are actually my own projected onto them (I've learned this about my relationship with my father too), but this post is already a bit too long so I'll save those for another time.&lt;/p&gt;
    &lt;p&gt;But the whole point here is not just that having raised this money from friends my head got a bit messy, but that I started to actually operate in a way that is counterproductive for my startup, while thinking I was actually doing what was best.&lt;/p&gt;
    &lt;p&gt;Ideas we considered when pivoting were looked more through a lens of "how big does this feel" rather than "what problem does this solve and for who". The slow growth was eating me, and while slow growth is terrible and can be a sign that you're on the wrong path it needs to be looked at from an objectively strategic lens. Didn't we say we were going to build an open source community and only later focus on monetization? Is that a viable strategy? Do we actually have a sound plan? Those were the things I should have been thinking about, rather than looping on "we need something that grows faster".&lt;/p&gt;
    &lt;p&gt;The people who invested in us, invested in us, not whatever idea we pitched them. And the best thing we can do is to follow our own process for building a great business based on what we believe and know, rather than focusing on making numbers look good so I can feel more relieved the next time I send over an investor update.&lt;/p&gt;
    &lt;p&gt;We have a ton to learn, particularly about sales (since we're both engineers), so we can't just be building shit for the sake of building shit because that's our comfort zone. But if our process is slower than company X on TechCrunch, that's fine. It's a marathon after all.&lt;/p&gt;
    &lt;p&gt;So after probably breaking many rules about what a founder should talk about publicly, what was my whole goal here? I mean, the main thing for me with posts like this is to get things off my chest. I've always said that the reason I publish writing that includes poems about my breakup, stories about falling in love, posts about my insecurities, and reflections about my dreams is that by there being the possibility of someone reading them (because technically it could be the case that nobody does) I can truly be who I really am in my day-to-day life. If I'm ok with there being the possibility of a friend I'll meet later today having read about how I felt during my last breakup, I can be myself with them without reservations, because I've made myself available to be seen. That's always been really freeing to me.&lt;/p&gt;
    &lt;p&gt;As a side effect, I'd hope that if this does get read by some people, particularly those starting or looking to start a business, that they can reflect about themselves, their lives, and their companies through listening to my story. I thought about writing a short bullet list about lessons I learned from raising money and dealing with its aftermath here, but honestly, that's best left to the reader to figure out. We're all different, and how one person reacts to a set of circumstances will differ from someone else. Some people don't feel pressure at all, or at least not from friends or investors. Or they only respond positively to pressure (because it certainly has benefits too). Maybe they're better off than me. Maybe they're not.&lt;/p&gt;
    &lt;p&gt;This is my story, after all. I wish you the best of luck with yours.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46660543</guid><pubDate>Sat, 17 Jan 2026 18:29:00 +0000</pubDate></item><item><title>The thing that brought me joy</title><link>https://www.stephenlewis.me/blog/the-thing-that-brought-me-joy/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46660663</guid><pubDate>Sat, 17 Jan 2026 18:42:39 +0000</pubDate></item><item><title>Why Twenty Years of DevOps Has Failed to Do It</title><link>https://www.honeycomb.io/blog/you-had-one-job-why-twenty-years-of-devops-has-failed-to-do-it</link><description>&lt;doc fingerprint="255053116fc506bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;“You Had One Job”: Why Twenty Years of DevOps Has Failed to Do it&lt;/head&gt;
    &lt;p&gt;I think the entire DevOps movement was a mighty, twenty year battle to achieve one thing: a single feedback loop connecting devs with prod. On those grounds, it failed.&lt;/p&gt;
    &lt;p&gt;By: Charity Majors&lt;/p&gt;
    &lt;p&gt;Let’s start with a question. What is DevOps all about?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Empathy!&lt;/item&gt;
      &lt;item&gt;Breaking down silos!&lt;/item&gt;
      &lt;item&gt;Forcing operations engineers to write more software!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’ll tell you my answer. In retrospect, I think the entire DevOps movement was a mighty, twenty year battle to achieve one thing: a single feedback loop connecting devs with prod.&lt;/p&gt;
    &lt;p&gt;On those grounds, it failed.&lt;/p&gt;
    &lt;p&gt;Not because software engineers weren’t good at their jobs, or didn’t care enough. It failed because the technology wasn’t good enough. The tools we gave them weren’t designed for this, so using them could easily double, triple, or quadruple the time it took to do their job: writing business logic.&lt;/p&gt;
    &lt;p&gt;This isn’t true everywhere. Please keep in mind that all data tools are effectively fungible if you can assume an infinite amount of time, money, and engineering skill. You can run production off an Excel spreadsheet if you have to, and some SREs have done so. That doesn’t make it a great solution, the right use of resources, or accessible to the median engineering org.&lt;/p&gt;
    &lt;head rend="h2"&gt;Good news and bad news&lt;/head&gt;
    &lt;p&gt;The good news is that AI has changed this. The technology we have now is good enough to create a feedback loop between developers and production systems for the median engineering team, for the first time ever.&lt;/p&gt;
    &lt;p&gt;The bad news is also that AI has changed this. Our existing feedback loops are unprepared to deal with the current amount of code slop. And I think we all know what the volume of code slop is about to do:&lt;/p&gt;
    &lt;p&gt;(Oh yeah, guess what I learned to do over the break? STICK ART, baby doll.)&lt;/p&gt;
    &lt;p&gt;I know this is a big, spicy claim. And since I got as pissed off as anyone when vendors were posting clickbait about “DEVOPS IS DEAD,” I’m going to back up and show you my argument from scratch. I’m not saying this in an accusatory, inflammatory kind of way. The truth is, we were all sensing and circling around the same problem, and it was the right one. We did the best we could with the tools that we had.&lt;/p&gt;
    &lt;head rend="h2"&gt;Value-generating feedback loops&lt;/head&gt;
    &lt;p&gt;If your business makes money by building products with software, this is what progress looks like: you build something new, ship it to users, and see what happens.&lt;/p&gt;
    &lt;p&gt;This is the theoretical feedback loop of generating business value with software. As our friends at Intercom like to say, “shipping is your company’s heartbeat.” The value-generating loop gets kicked off every time you deploy a new diff. In stick art, it looks like this: deploy -&amp;gt; observe -&amp;gt; learn.&lt;/p&gt;
    &lt;p&gt;“Build” isn’t shown because it doesn’t count. Value does not get captured until the code has been deployed. That’s one of the reasons why software experts are always haranguing us to ship frequently. Like this:&lt;/p&gt;
    &lt;p&gt;Or even…&lt;/p&gt;
    &lt;p&gt;(Look at all that learning! 😍)&lt;/p&gt;
    &lt;p&gt;Every deploy is a chance to learn something new about your product, your system, your users, your feature, etc. But what if you deploy new code and don’t observe?&lt;/p&gt;
    &lt;p&gt;If you don’t observe, you don’t learn anything. Your deploy becomes an open loop. You are shipping blind.&lt;/p&gt;
    &lt;p&gt;This is what observability does, by the way. It’s the sense mechanism that enables all your other feedback loops to function. It’s the information channel that connects the dots and closes the loops.&lt;/p&gt;
    &lt;p&gt;Now, let’s move from the theoretical loops of value generation to the actual feedback loops people are using today to develop new software and operate the software they already have.&lt;/p&gt;
    &lt;head rend="h2"&gt;Actual developer feedback loops&lt;/head&gt;
    &lt;p&gt;Software developers typically spend most of the day in their development environment. They build stuff, they run tests, they build more stuff, they run more tests. (Or they conduct lengthy, increasingly intimate conversations with Cursor or Claude about how agents should do these things on their behalf, but for simplicity’s sake, let’s use the classical terms.)&lt;/p&gt;
    &lt;p&gt;Build-&amp;gt; test -&amp;gt; learn, build -&amp;gt; test -&amp;gt; learn. These are the actual feedback loops that drive a developer’s daily labor. When we’re ready to merge, we may get code review first.&lt;/p&gt;
    &lt;p&gt;If all tests pass, and our buddy approves, we merge! Joyous day. On to the next unit of work.&lt;/p&gt;
    &lt;p&gt;What did we “learn” by running tests? We learned that our tests pass. That’s all.&lt;/p&gt;
    &lt;p&gt;Tests are great, but from the business perspective, we don’t learn anything new by running tests. All of this work is important, but you don’t learn anything. You can’t learn anything until you deploy to production. Hold that thought.&lt;/p&gt;
    &lt;p&gt;Next, let’s look at the feedback loops involving production.&lt;/p&gt;
    &lt;head rend="h2"&gt;Actual production feedback loops&lt;/head&gt;
    &lt;p&gt;Most developers don’t interact with production on a daily basis, unless they’re hunting down a bug or something. Guess who does? Your operations crew—or as they are more likely to be called, cloud engineering, infrastructure, SREs, DevOps, or platform engineering.&lt;/p&gt;
    &lt;p&gt;Whatever you call them, somebody has to deal with operational feedback loops. They are the last line of defense for your system in the face of perpetual threats. In soccer terms, they are the goalie.&lt;/p&gt;
    &lt;p&gt;Operational feedback loops get kicked off any time someone gets paged (or a customer complains loudly enough to trigger an escalation). Day or night, rain or shine, someone hops on to production to investigate, triage, and fix the problem.&lt;/p&gt;
    &lt;p&gt;Operational feedback loops are always reactive. Sometimes you can tell what just changed (deploy? migration?), but often, you cannot. An unusual traffic pattern, a new client version, a database bug, a bug from two years ago just reached a tipping point… the possibilities are endless.&lt;/p&gt;
    &lt;p&gt;It might look more like this:&lt;/p&gt;
    &lt;p&gt;Or this:&lt;/p&gt;
    &lt;p&gt;The dirty little secret of infrastructure is how often things happen that we just don’t understand. Some of it can perhaps be handwaved away as emergent properties of complex systems, but a great deal more of it is due to how long, laggy, and lossy these feedback loops are.&lt;/p&gt;
    &lt;head rend="h2"&gt;Both of these feedback loops are vital&lt;/head&gt;
    &lt;p&gt;This might be a good time for me to pause and underline that both feedback loops are necessary. One is not better than the other one. We need both. As Stephen Jay Gould might say, these are non-overlapping magisteria. (Uh, except actually they do overlap, a lot.)&lt;/p&gt;
    &lt;p&gt;I want to be super clear on this point, because in this industry we have a tendency to throw rocks at each other and be like, “why are you stupid?”&lt;/p&gt;
    &lt;p&gt;“Stupid ops people, why don’t you just alert any time something changes in production, so we can learn from it?”&lt;/p&gt;
    &lt;p&gt;“Stupid developers, why don’t you just LOOK at your graphs after every deploy?”&lt;/p&gt;
    &lt;p&gt;I actually feel pretty bad about this, because I think I’ve been a key driver of the latter narrative. I’ve lost track of how many times I’ve told people to “put your developers on call!” to make them pay more attention to production. Mind you, I’m not necessarily saying this is a bad idea, nor is it necessarily a good idea. I’m saying that it doesn’t solve the problem.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ops and dev have different perspectives&lt;/head&gt;
    &lt;p&gt;The problem is that these are different domains, and they have fundamentally different perspectives. This doesn’t necessarily mean they need different tools (recall what I said about all data tools being fungible), but they are worth considering with equal weight.&lt;/p&gt;
    &lt;head rend="h3"&gt;The ops perspective&lt;/head&gt;
    &lt;p&gt;Here we have the basic ops/dev contract, in its simplest form. Ops (or platform, or whatever) provides a place for devs to run their code, their queries, etc. Devs write the code that runs on it.&lt;/p&gt;
    &lt;p&gt;If we zoom out a little and simplify by a factor of ten million or so, it looks like this. The ops/platform/SRE mandate is to provide a stable, reliable place for lines of code to execute.&lt;/p&gt;
    &lt;p&gt;To do this, they collect a lot of telemetry from the perspective of the system and each of its constituent parts: disks, pods, network devices, databases, and so on. Most of this is third-party code, so you can’t change it; you just have to swallow whatever metrics or logs they sent you.&lt;/p&gt;
    &lt;head rend="h3"&gt;The dev perspective&lt;/head&gt;
    &lt;p&gt;What the devs care about is the ability to understand the product experience from the perspective of each customer. In practice, this can mean any combination or permutation of agent, user, mobile device type, laptop, desktop, point of sale device, and so on.&lt;/p&gt;
    &lt;p&gt;They also need to be able to slice and dice and combine this with any combination of build IDs, commit tags, feature flags, container pods, and anything else being collected by the application telemetry.&lt;/p&gt;
    &lt;p&gt;Devs can’t physically access every phone, laptop, and point of sale device in the world. But if they use the right tools, they can stream that telemetry back to the application in a format that preserves their ability to explore and ask open-ended, exploratory questions from the system side.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ops and dev have different concerns&lt;/head&gt;
    &lt;p&gt;Ops and dev also have different concerns.&lt;/p&gt;
    &lt;p&gt;Operational feedback loops exist to guard the system and its components against catastrophic threats. If it isn’t failing, broken, buggy, slow, etc., ops mostly don’t care; not their domain.&lt;/p&gt;
    &lt;p&gt;Devs, on the other hand, very much do care about things beyond bugs and catastrophes. The developer’s job is to create new value for the business. Build products, implement features, run experiments. Try something new, see if users run with it.&lt;/p&gt;
    &lt;p&gt;Think of it this way. Ops is the building inspector, dev is the architect. The inspector only shows up to look for code violations, structural problems, safety hazards. The architect spends most of their time imagining what could be built, how people might use the space, what will delight them. They both care about safety, but the inspector’s entire job is about managing risk while the architect’s job is possibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;“How do I get my developers to go look at it?”&lt;/head&gt;
    &lt;p&gt;I spent some time chatting with folks at LDX Berlin last November. It struck me afterwards that over half of the questions I heard—from staff+ engineers, directors, and execs—were some variation on a single theme: “But how do I get my developers to go look at it?” [their dashboards].&lt;/p&gt;
    &lt;p&gt;This might be the first time I ever truly thought through just how frustrating and confusing this has been for developers, from start to finish.&lt;/p&gt;
    &lt;head rend="h3"&gt;Instrumenting your code using ops tools: not easy&lt;/head&gt;
    &lt;p&gt;Think about it. You and your buddy Claude are building a new checkout feature together, and you want to capture a few valuable bits of telemetry, let’s say &lt;code&gt;user_name&lt;/code&gt; and &lt;code&gt;order_total&lt;/code&gt;. Where do they go?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Should these go in metrics?&lt;/item&gt;
      &lt;item&gt;Should they go in logs?&lt;/item&gt;
      &lt;item&gt;Should they be part of a trace? A span?&lt;/item&gt;
      &lt;item&gt;What if you want to see it alongside errors when checkout fails?&lt;/item&gt;
      &lt;item&gt;What about profiling data when checkout is slow?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Buckle in, we are just getting started. If it’s a metric, should it be a:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Counter?&lt;/item&gt;
      &lt;item&gt;Gauge?&lt;/item&gt;
      &lt;item&gt;Histogram?&lt;/item&gt;
      &lt;item&gt;Summary?&lt;/item&gt;
      &lt;item&gt;Rate?&lt;/item&gt;
      &lt;item&gt;Distribution?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If it’s a counter, when does it reset? If it’s a histogram or a summary, what are the bucket boundaries? Do I need to tag anything? Does cardinality matter, for the data and/or the tags? Am I supposed to worry about cost? Is there a naming convention?&lt;/p&gt;
    &lt;p&gt;Let’s say you figure out the metric part. Now, do they also need to go into logs or traces? All of the signal types? Should I append them to an existing log line (which one?), or make a new one? Do they need indexes? Can I index them? Is there a schema?&lt;/p&gt;
    &lt;p&gt;We could keep asking questions for another five pages or so. I don’t know that I ever truly considered just how much domain knowledge we presume when we tell developers to do this. All that time, fear and decision fatigue… it adds up.&lt;/p&gt;
    &lt;p&gt;At least it’s a one time expense and then you have it, right? In the end, it’s all worth it?&lt;/p&gt;
    &lt;p&gt;Ah. Right. About that…&lt;/p&gt;
    &lt;head rend="h3"&gt;Finding your telemetry using ops tools: also not easy&lt;/head&gt;
    &lt;p&gt;To look at your new instrumentation, you probably just need to wait for your code to get deployed, then find the right tool (or tools) for the telemetry you added, and create a new dashboard using those attributes. I’m going to fast forward through all this because it’s extremely vendor-specific and the specifics don’t matter much.&lt;/p&gt;
    &lt;p&gt;I want to get back to the question people were asking me in Berlin: how do you get your developers to go look at their telemetry?&lt;/p&gt;
    &lt;p&gt;The answer is: you don’t.&lt;/p&gt;
    &lt;p&gt;We have the technology now. We bring the telemetry to them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bring the telemetry to developers&lt;/head&gt;
    &lt;p&gt;No matter how much time we have spent yelling at them over the years, most developers really don’t want to leave their development environment (for anything other than Slack).&lt;/p&gt;
    &lt;p&gt;What if they were right all along?&lt;/p&gt;
    &lt;p&gt;Here, watch this demo. It’s only 3:37 long, and it shows Jessitron demoing some of the AI capabilities we released last September. Jump ahead to 2:21 if you’re impatient and want to see it in your development environment.&lt;/p&gt;
    &lt;p&gt;As it turns out, chat is kind of the perfect interface for interrogating your software and finding out how it’s doing in production.&lt;/p&gt;
    &lt;head rend="h2"&gt;Bring them telemetry they can use&lt;/head&gt;
    &lt;p&gt;The cognitive overhead of three pillars instrumentation is one reason we historically struggled to get developers to use ops tools. The other is simpler: the tools weren’t worth it.&lt;/p&gt;
    &lt;p&gt;Imagine you did everything ops was asking you to do—you doubled, tripled the time it took you to ship your business logic in order to get the right instrumentation included. You shipped your changes, then went to explore what impact your changes were having on how users experienced the product. And finally, after all the wrestling, and waiting, and clicking around, you got…aggregates? Histograms? Fucking buckets?&lt;/p&gt;
    &lt;p&gt;If you’re trying to use tools to ask exploratory, open-ended questions about the quality of your product as experienced by your users, you are squarely in “running production off an Excel spreadsheet” territory.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI has changed the instrumentation game&lt;/head&gt;
    &lt;p&gt;In the past, instrumentation was laborious and required expertise in multiple domains, while auto-instrumentation generally alternated between sucking by doing too much and sucking by doing too little.&lt;/p&gt;
    &lt;p&gt;OpenTelemetry changed things by standardizing the way we instrument code, making instrumentation patterns consistent and well-documented, with a massive corpus of examples. LLMs have been trained on these, so they can follow instructions on how to implement it or add it to software projects.&lt;/p&gt;
    &lt;p&gt;The cost of instrumentation has effectively fallen to zero, and AI models and agents are able to understand important patterns in your code and generalize from the patterns they know how to instrument.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI has changed the analysis game&lt;/head&gt;
    &lt;p&gt;And if your agentic harness can run your code in dev, inspect the output, verify that it’s working as expected, etc., then by the time you’re ready to merge your changes to production, you’ve already validated that the instrumentation can explain itself back to you from production.&lt;/p&gt;
    &lt;p&gt;Automatic, end-to-end feedback loops are the key. Instead of spending hours poring through traces, looking for outliers and suspicious symptoms… let your little buddy do that. Instead of putting your IDE on the left side of the screen, and a long, detailed trace on the right side of the screen, and stepping line by line, span by span through the trace… let your buddy do that, too.&lt;/p&gt;
    &lt;p&gt;It is not impossible to get what you need out of ops tools and legacy models. Plenty of engineers and teams have done so. That doesn’t make it a great solution, the right use of resources, or accessible to the median engineering org.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI has changed the need for validation&lt;/head&gt;
    &lt;p&gt;The shape of the future is becoming clear. Developers will spend less time writing lines of code, and more time writing specs, thinking about the problem space, running experiments, and validating what they’ve built.&lt;/p&gt;
    &lt;p&gt;Instead of: write code -&amp;gt; test -&amp;gt; code review -&amp;gt; merge -&amp;gt; “hope it works!”&lt;/p&gt;
    &lt;p&gt;It becomes: write code (with AI) -&amp;gt; deploy -&amp;gt; observe and validate -&amp;gt; learn -&amp;gt; iterate.&lt;/p&gt;
    &lt;p&gt;See what happens? You are literally feeding what you learned from each change right back into the product in your next change. Shipping swiftly, with confidence, at the speed of AI.&lt;/p&gt;
    &lt;p&gt;The bottleneck shifts from, “How fast can I write code?” to, “How fast can I understand what’s happening and make good decisions about it?”&lt;/p&gt;
    &lt;p&gt;If AI makes code writing nearly free, then the ability to understand and validate what that code does in production becomes the primary constraint.&lt;/p&gt;
    &lt;p&gt;Engineers become more like scientists running experiments and interpreting results, less like typists translating specifications into syntax.&lt;/p&gt;
    &lt;head rend="h2"&gt;The freight train barrelling down the tracks at us&lt;/head&gt;
    &lt;p&gt;All this is tremendously exciting and great fun.&lt;/p&gt;
    &lt;p&gt;What’s mildly terrifying is that most companies, to this day, do all of their learning and observing about production via long, lossy, laggy operational feedback loops.&lt;/p&gt;
    &lt;p&gt;And most orgs are used to responding to a daytime alert by calling out, “Who just shipped that change?” assuming that whoever merged the diff surely understands how it works and can fix it post-haste.&lt;/p&gt;
    &lt;p&gt;What happens when nobody wrote the code you just deployed, and nobody really understands it?&lt;/p&gt;
    &lt;p&gt;I guess we’ll (all) find out. 😉&lt;/p&gt;
    &lt;head rend="h2"&gt;DevOps isn’t dead&lt;/head&gt;
    &lt;p&gt;The DevOps movement isn’t “dead.” It did an enormous amount of good in the world. It broke down silos, preached the value of empathy and collaboration, and reduced a ton of toil.&lt;/p&gt;
    &lt;p&gt;In retrospect, I’ve come to think that the entire effort was about trying to connect developers with the consequences of their code in production. We did not succeed, but it was hardly for lack of trying. We did the best we could with the tools we had.&lt;/p&gt;
    &lt;p&gt;And now we can do better.&lt;/p&gt;
    &lt;head rend="h1"&gt;A decade of observability hot takes and learning the hard way&lt;/head&gt;
    &lt;p&gt;Join the webinar, The Next Era of Observability: Founders' Reflections,&lt;/p&gt;
    &lt;p&gt;with Christine and Charity.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46661132</guid><pubDate>Sat, 17 Jan 2026 19:21:38 +0000</pubDate></item><item><title>A programming language based on grammatical cases of Turkish</title><link>https://github.com/kip-dili/kip</link><description>&lt;doc fingerprint="4a813f1d0f75a8ca"&gt;
  &lt;main&gt;
    &lt;p&gt;Kip (meaning "grammatical mood" in Turkish) is an experimental programming language that uses Turkish grammatical cases as part of its type system. It demonstrates how natural language morphology—specifically Turkish noun cases and vowel harmony—can be integrated into programming language design.&lt;/p&gt;
    &lt;p&gt;This is a research/educational project exploring the intersection of linguistics and type theory, not a production programming language.&lt;/p&gt;
    &lt;p&gt;There is also a tutorial in Turkish and a tutorial in English that explains how to write Kip programs.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Kip is experimental. Expect changes in syntax and behavior over time.&lt;/p&gt;
    &lt;p&gt;For you to get a taste of what Kip looks like, here is an example program that prompts the user to enter a number and then prints that many of the Fibonacci numbers:&lt;/p&gt;
    &lt;code&gt;(* İlk n Fibonacci sayısını yazdırır. *)
(bu tam-sayıyı) (şu tam-sayıyı) (o tam-sayıyı) işlemek,
  (onla 0'ın eşitliği) doğruysa,
    durmaktır,
  yanlışsa,
    bunu yazıp,
    şunu (bunla şunun toplamını) (onla 1'in farkını) işlemektir.

çalıştırmak,
  "Bir sayı girin:" yazıp,
  isim olarak okuyup,
  ((ismin tam-sayı-hali)
    yokluksa,
      "Geçersiz sayı." yazmaktır,
    n'nin varlığıysa,
      0'ı 1'i n'yi işlemektir).

çalıştır.
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language Features&lt;/item&gt;
      &lt;item&gt;Installation&lt;/item&gt;
      &lt;item&gt;Example Program&lt;/item&gt;
      &lt;item&gt;WASM Playground&lt;/item&gt;
      &lt;item&gt;Bytecode Cache&lt;/item&gt;
      &lt;item&gt;Project Structure&lt;/item&gt;
      &lt;item&gt;Testing&lt;/item&gt;
      &lt;item&gt;Morphological Analysis&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Kip uses Turkish noun cases (ismin halleri) to determine argument relationships in function calls:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Case&lt;/cell&gt;
        &lt;cell role="head"&gt;Turkish Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Suffix&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Nominative&lt;/cell&gt;
        &lt;cell&gt;Yalın hal&lt;/cell&gt;
        &lt;cell&gt;(none)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;sıfır&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Accusative&lt;/cell&gt;
        &lt;cell&gt;-i hali&lt;/cell&gt;
        &lt;cell&gt;-i, -ı, -u, -ü&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;sayıyı&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Dative&lt;/cell&gt;
        &lt;cell&gt;-e hali&lt;/cell&gt;
        &lt;cell&gt;-e, -a&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;sayıya&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Locative&lt;/cell&gt;
        &lt;cell&gt;-de hali&lt;/cell&gt;
        &lt;cell&gt;-de, -da, -te, -ta&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;listede&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Ablative&lt;/cell&gt;
        &lt;cell&gt;-den hali&lt;/cell&gt;
        &lt;cell&gt;-den, -dan, -ten, -tan&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;listeden&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Genitive&lt;/cell&gt;
        &lt;cell&gt;Tamlayan eki&lt;/cell&gt;
        &lt;cell&gt;-in, -ın, -un, -ün&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;sayının&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Instrumental&lt;/cell&gt;
        &lt;cell&gt;-le eki&lt;/cell&gt;
        &lt;cell&gt;-le, -la, ile&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;sayıyla&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Possessive (3s)&lt;/cell&gt;
        &lt;cell&gt;Tamlanan eki&lt;/cell&gt;
        &lt;cell&gt;-i, -ı, -u, -ü, -si, -sı&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;ardılı&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Because Turkish cases mark grammatical relationships explicitly, Kip allows flexible argument ordering. These two calls are equivalent:&lt;/p&gt;
    &lt;code&gt;(5'le 3'ün farkını) yaz.
(3'ün 5'le farkını) yaz.
&lt;/code&gt;
    &lt;p&gt;As long as arguments have different case suffixes or different types, Kip can determine which argument is which.&lt;/p&gt;
    &lt;p&gt;Define algebraic data types with Turkish syntax:&lt;/p&gt;
    &lt;code&gt;Bir doğruluk ya doğru ya da yanlış olabilir.

Bir doğal-sayı
ya sıfır
ya da bir doğal-sayının ardılı
olabilir.
&lt;/code&gt;
    &lt;p&gt;Type variables are supported for generic data structures:&lt;/p&gt;
    &lt;code&gt;Bir (öğe listesi)
ya boş
ya da bir öğenin bir öğe listesine eki
olabilir.
&lt;/code&gt;
    &lt;p&gt;Pattern match using the conditional suffix &lt;code&gt;-sa/-se&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;(bu doğruluğun) tersi,
  bu doğruysa, yanlış,
  yanlışsa, doğrudur.
&lt;/code&gt;
    &lt;p&gt;Supports nested pattern matching, binders, and wildcard patterns (&lt;code&gt;değilse&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;(bu doğal-sayının) kopyası,
  bu sıfırsa, sıfır,
  öncülün ardılıysa, öncülün ardılıdır.
&lt;/code&gt;
    &lt;p&gt;Define named constants with &lt;code&gt;diyelim&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;sıfırın ardılına bir diyelim.
birin ardılına iki diyelim.
&lt;/code&gt;
    &lt;p&gt;Sequencing with &lt;code&gt;-ip/-ıp/-up/-üp&lt;/code&gt; suffixes and binding with &lt;code&gt;olarak&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;selamlamak,
  isim olarak okuyup,
  ("Merhaba "yla ismin birleşimini) yazmaktır.
&lt;/code&gt;
    &lt;p&gt;Integers (&lt;code&gt;tam-sayı&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Arithmetic: &lt;code&gt;toplamı&lt;/code&gt;,&lt;code&gt;farkı&lt;/code&gt;,&lt;code&gt;çarpımı&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Comparison: &lt;code&gt;eşitliği&lt;/code&gt;,&lt;code&gt;küçüklüğü&lt;/code&gt;,&lt;code&gt;büyüklüğü&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Other: &lt;code&gt;öncülü&lt;/code&gt;,&lt;code&gt;sıfırlığı&lt;/code&gt;,&lt;code&gt;faktöriyeli&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Strings (&lt;code&gt;dizge&lt;/code&gt;):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;uzunluğu&lt;/code&gt;- length&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;birleşimi&lt;/code&gt;- concatenation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tam-sayı-hali&lt;/code&gt;- parse as integer&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I/O:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;yazmak&lt;/code&gt;/&lt;code&gt;yaz&lt;/code&gt;- print to stdout&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;okumak&lt;/code&gt;/&lt;code&gt;oku&lt;/code&gt;- read from stdin&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;(* This is a comment *)
&lt;/code&gt;
    &lt;code&gt;5'i yaz.              (* Integer literal with case suffix *)
"merhaba"'yı yaz.     (* String literal with case suffix *)
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Foma - finite-state morphology toolkit&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;macOS: &lt;code&gt;brew install foma&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Debian/Ubuntu: &lt;code&gt;apt install foma libfoma-dev&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Fedora: &lt;code&gt;dnf install foma foma-devel&lt;/code&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;macOS: &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Stack - Haskell build tool&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;See haskellstack.org&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;If you only want to explore the language, you can start with &lt;code&gt;stack exec kip&lt;/code&gt; after a successful build.&lt;/p&gt;
    &lt;p&gt;Clone this repository, then:&lt;/p&gt;
    &lt;code&gt;# Quick install (macOS/Linux)
chmod +x install.sh
./install.sh

# Or manual build
stack build&lt;/code&gt;
    &lt;p&gt;The TRmorph transducer is bundled at &lt;code&gt;vendor/trmorph.fst&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;# Start REPL
stack exec kip

# Execute a file
stack exec kip -- --exec path/to/file.kip

# Install to PATH
stack install&lt;/code&gt;
    &lt;p&gt;A browser playground build is available under &lt;code&gt;playground/&lt;/code&gt;. It compiles the
non-interactive runner (&lt;code&gt;kip-playground&lt;/code&gt;) to &lt;code&gt;wasm32-wasi&lt;/code&gt; and ships a small
HTML/JS harness that runs Kip in the browser.&lt;/p&gt;
    &lt;p&gt;See &lt;code&gt;playground/README.md&lt;/code&gt; for prerequisites, toolchain setup, and build steps.&lt;/p&gt;
    &lt;p&gt;Kip stores a cached, type-checked version of each &lt;code&gt;.kip&lt;/code&gt; file in a sibling &lt;code&gt;.iz&lt;/code&gt; file. When you run a file again, Kip will reuse the &lt;code&gt;.iz&lt;/code&gt; cache if both the source and its loaded dependencies are unchanged.&lt;/p&gt;
    &lt;p&gt;If you want to force a fresh parse and type-check, delete the &lt;code&gt;.iz&lt;/code&gt; file next to the source.&lt;/p&gt;
    &lt;p&gt;Important&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;.iz&lt;/code&gt; files include a compiler hash. If the compiler changes, the cache is invalidated automatically.&lt;/p&gt;
    &lt;code&gt;(* Natural numbers *)
Bir doğal-sayı
ya sıfır
ya da bir doğal-sayının ardılı
olabilir.

(* Define some constants *)
sıfırın ardılına bir diyelim.
birin ardılına iki diyelim.
ikinin ardılına üç diyelim.

(* Addition function *)
(bu doğal-sayıyla) (şu doğal-sayının) toplamı,
  bu sıfırsa,
    şu,
  öncülün ardılıysa,
    (öncülle) (şunun ardılının) toplamıdır.

(* Print result *)
(ikiyle üçün toplamını) yaz.
&lt;/code&gt;
    &lt;code&gt;app/
└── Main.hs            - CLI entry point

src/
├── Kip/
│   ├── AST.hs         - Abstract syntax tree
│   ├── Cache.hs       - .iz cache handling
│   ├── Eval.hs        - Interpreter
│   ├── Parser.hs      - Parser
│   ├── Render.hs      - Pretty-printing with morphological inflection
│   └── TypeCheck.hs   - Type checker validating grammatical case usage
└── Language/
    └── Foma.hs        - Haskell bindings to Foma via FFI

lib/
├── giriş.kip          - Prelude module loaded by default
├── temel.kip           - Core types
├── temel-doğruluk.kip  - Boolean functions
├── temel-dizge.kip     - String functions
├── temel-etki.kip      - I/O primitives
├── temel-liste.kip     - List functions
└── temel-tam-sayı.kip  - Integer functions

tests/
├── succeed/            - Passing golden tests (.kip + .out + optional .in)
└── fail/               - Failing golden tests (.kip + .err)

vendor/
└── trmorph.fst        - TRmorph transducer
&lt;/code&gt;
    &lt;code&gt;stack test&lt;/code&gt;
    &lt;p&gt;Tests are in &lt;code&gt;tests/succeed/&lt;/code&gt; (expected to pass) and &lt;code&gt;tests/fail/&lt;/code&gt; (expected to fail).&lt;/p&gt;
    &lt;p&gt;Kip uses TRmorph for Turkish morphological analysis. When a word has multiple possible parses (e.g., "takası" could be "taka + possessive" or "takas + accusative"), Kip carries all candidates through parsing and resolves ambiguity during type checking.&lt;/p&gt;
    &lt;p&gt;For intentionally ambiguous words, use an apostrophe to force a specific parse: &lt;code&gt;taka'sı&lt;/code&gt; vs &lt;code&gt;takas'ı&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;See LICENSE file.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46661897</guid><pubDate>Sat, 17 Jan 2026 20:44:52 +0000</pubDate></item></channel></rss>