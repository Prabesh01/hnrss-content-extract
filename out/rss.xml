<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 07 Feb 2026 07:07:13 +0000</lastBuildDate><item><title>I now assume that all ads on Apple news are scams</title><link>https://kirkville.com/i-now-assume-that-all-ads-on-apple-news-are-scams/</link><description>&lt;doc fingerprint="7b885158dca214d7"&gt;
  &lt;main&gt;
    &lt;p&gt;In 2024, Apple signed a deal with Taboola to serve ads in its app, notably Apple News. John Gruber, writing in Daring Fireball said at the time:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you told me that the ads in Apple News have been sold by Taboola for the last few years, I‚Äôd have said, ‚ÄúOh, that makes sense.‚Äù Because the ads in Apple News ‚Äî at least the ones I see1 ‚Äî already look like chumbox Taboola ads. Even worse, they‚Äôre incredibly repetitious.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I use Apple News to keep up on topics that I don‚Äôt find in sources I pay for (The Guardian and The New York Times). But there‚Äôs no way I‚Äôm going to pay the exorbitant price Apple wants for Apple News+ ‚Äì ¬£13 ‚Äì because, while you get more publications, you still get ads.&lt;/p&gt;
    &lt;p&gt;And those ads have gotten worse recently. Many if not most of them look like and probably are scams. Here are a few examples from Apple News today.&lt;/p&gt;
    &lt;p&gt;Here are three ads that are scammy; the first two were clearly generated by AI, and the third may have been created by AI.&lt;/p&gt;
    &lt;p&gt;Why are they scams? When I searched domain information for the domains, I found that they were registered very recently.&lt;/p&gt;
    &lt;p&gt;Domain Name: MUSTYLEVO.COM&lt;lb/&gt; Registry Domain ID: 3059688301_DOMAIN_COM-VRSN&lt;lb/&gt; Registrar WHOIS Server: whois.gname.com&lt;lb/&gt; Registrar URL: http://www.gname.com&lt;lb/&gt; Updated Date: 2026-02-04T07:23:58Z&lt;lb/&gt; Creation Date: 2026-01-21T07:23:43Z&lt;/p&gt;
    &lt;p&gt;Domain Name: SOLVERACO.COM&lt;lb/&gt; Registry Domain ID: 3045027870_DOMAIN_COM-VRSN&lt;lb/&gt; Registrar WHOIS Server: grs-whois.hichina.com&lt;lb/&gt; Registrar URL: http://wanwang.aliyun.com&lt;lb/&gt; Updated Date: 2025-12-05T06:10:51Z&lt;lb/&gt; Creation Date: 2025-12-05T06:07:40Z&lt;/p&gt;
    &lt;p&gt;Domain Name: SHIYAATELIER.COM&lt;lb/&gt; Registry Domain ID: 3037972202_DOMAIN_COM-VRSN&lt;lb/&gt; Registrar WHOIS Server: whois.name.com&lt;lb/&gt; Registrar URL: http://www.name.com&lt;lb/&gt; Updated Date: 2025-11-12T06:47:14Z&lt;lb/&gt; Creation Date: 2025-11-12T06:47:13Z&lt;/p&gt;
    &lt;p&gt;This recent registration doesn‚Äôt necessarily mean they are scams, but they don‚Äôt inspire much confidence.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs one example. This ad from Tidenox, whose website says I am retiring, showing a photo of an elderly woman, who says, ‚ÄúFor 26 years, Tidenox has been port of your journey in creating earth and comfort at home.‚Äù The image of the retiring owner is probably made by AI. (Update: someone on Hacker News pointed out the partly masked Google Gemini logo on the bottom right. I hadn‚Äôt spotted that, in part because I don‚Äôt use any AI image generation tools.)&lt;/p&gt;
    &lt;p&gt;These fake ‚Äúgoing out of business ads‚Äù have been around for a few years, and even the US Better Business Bureau warns about them, as they take peoples‚Äô money then shut down. Does Apple care? Does Taboola care? Does Apple care that Taboola serves ads like this? My guess: no, no, and no.&lt;/p&gt;
    &lt;p&gt;Note the registration date for the tidenox.com domain. It‚Äôs nowhere near 26 years old, and it‚Äôs registered in China:&lt;/p&gt;
    &lt;p&gt;Domain Name: TIDENOX.COM&lt;lb/&gt; Registry Domain ID: 2987356919_DOMAIN_COM-VRSN&lt;lb/&gt; Registrar WHOIS Server: grs-whois.hichina.com&lt;lb/&gt; Registrar URL: http://wanwang.aliyun.com&lt;lb/&gt; Updated Date: 2025-05-29T09:17:31Z&lt;lb/&gt; Creation Date: 2025-05-29T09:14:35Z&lt;/p&gt;
    &lt;p&gt;Shame on Apple for creating a honeypot for scam ads in what they consider to be a premium news service. This company cannot be trusted with ads in its products any more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Discover more from Kirkville&lt;/head&gt;
    &lt;p&gt;Subscribe to get the latest posts sent to your email.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46911901</guid><pubDate>Fri, 06 Feb 2026 12:16:43 +0000</pubDate></item><item><title>Hackers (1995) Animated Experience</title><link>https://hackers-1995.vercel.app/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46912800</guid><pubDate>Fri, 06 Feb 2026 13:49:55 +0000</pubDate></item><item><title>FORTH?¬†Really!?</title><link>https://rescrv.net/w/2026/02/06/associative</link><description>&lt;doc fingerprint="c7a8e21a28609e3c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FORTH? Really!?&lt;/head&gt;
    &lt;p&gt;Imagine you have to generate the word that succeeds this colon: ___&lt;/p&gt;
    &lt;p&gt;What would you put in that blank space?&lt;/p&gt;
    &lt;p&gt;It‚Äôs easier when the question comes first.&lt;/p&gt;
    &lt;p&gt;But what if we structured things such that the blank had to be generated before its constituent parts. LLMs are wonderful, but I see too many people try to break down recursively to solve problems like top-down humans do. Instead, I posit that FORTH and associative/applicative languages may be better for transformer architectures. Concatenate, not integrate. Agree on the stack state.&lt;/p&gt;
    &lt;p&gt;I set out to question if this could be true.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sideways Passing Join.&lt;/head&gt;
    &lt;p&gt;Imagine you had this program:&lt;/p&gt;
    &lt;code&gt;A SCAN [foo &amp;gt; 5] FILTER
B SCAN [foo &amp;lt; 5] FILTER
BUILD
PROBE
&lt;/code&gt;
    &lt;p&gt;that performs a natural join on A and B‚Äôs shared identifiers.&lt;/p&gt;
    &lt;p&gt;Because of the properties of associative languages you can always make local edits. For example, if you made a sed-like transformation, you could replace &lt;code&gt;BUILD PROBE&lt;/code&gt; with the following anywhere
there‚Äôs¬†a &lt;code&gt;BUILD PROBE&lt;/code&gt; sequence to do a sideways-information-passing¬†join:&lt;/p&gt;
    &lt;code&gt;DUP STATS SWAP BUILD
[PUSHDOWN] DIP PROBE
&lt;/code&gt;
    &lt;p&gt;This same associative property allows us to divide a program into, ‚ÄúWhat‚Äôs been generated in-context,‚Äù and, ‚ÄúWhat remains to be generated.‚Äù We shuffle one token at a time to extend the context and consume our desire to generate tokens.&lt;/p&gt;
    &lt;p&gt;I have a hunch that transformations of finite automatons over subsequences of the text can be used to write optimization passes for the database layer.&lt;/p&gt;
    &lt;p&gt;A phrase from Manfred von Thun goes, ‚Äúsyntactic concatenation is semantic composition.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;A Benchmark&lt;/head&gt;
    &lt;p&gt;I set out to benchmark what models can do in this regard. Would the order of terms matter to an attention transformer? The experiment is simple: I want to construct a tree over numbers and measure when the tree conforms to instructions. In my experiment I used parity to assess whether the sum of a sub-tree‚Äôs children were even or odd. Thus, prefix notation needs to know the overall answer before it generates the sub-answers. Postfix notation generates bottom-up, generating sub-answers before answering further.&lt;/p&gt;
    &lt;p&gt;If you think about how you answer, ‚ÄúWhat is the next token,‚Äù you‚Äôll see where I‚Äôm going.&lt;/p&gt;
    &lt;head rend="h3"&gt;Setup&lt;/head&gt;
    &lt;p&gt;Given: A sequence of numbers. Construct: A prefix or postfix parity tree.&lt;/p&gt;
    &lt;p&gt;What is a parity tree? An unbalanced, left- or right-skewed binary tree whose leaves are numbers and whose interior nodes represent the parity of their transitive children.&lt;/p&gt;
    &lt;head rend="h3"&gt;Results&lt;/head&gt;
    &lt;p&gt;I ran four trials across Opus and Haiku (sonnet gave results I need to better understand before I‚Äôll publish). Thinking consistently outperforms non-thinking. Opus consistently outperforms Haiku. And postfix consistently outperforms prefix.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Thinking&lt;/cell&gt;
        &lt;cell role="head"&gt;Postfix Acc&lt;/cell&gt;
        &lt;cell role="head"&gt;Prefix Acc&lt;/cell&gt;
        &lt;cell role="head"&gt;Both Correct&lt;/cell&gt;
        &lt;cell role="head"&gt;Postfix Only&lt;/cell&gt;
        &lt;cell role="head"&gt;Prefix Only&lt;/cell&gt;
        &lt;cell role="head"&gt;Both Wrong&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Haiku&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;88.3%&lt;/cell&gt;
        &lt;cell&gt;36.7%&lt;/cell&gt;
        &lt;cell&gt;110&lt;/cell&gt;
        &lt;cell&gt;155&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;35&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Haiku&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;6.7%&lt;/cell&gt;
        &lt;cell&gt;4.3%&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;276&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Opus&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;98.3%&lt;/cell&gt;
        &lt;cell&gt;81.3%&lt;/cell&gt;
        &lt;cell&gt;243&lt;/cell&gt;
        &lt;cell&gt;52&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Opus&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;50.0%&lt;/cell&gt;
        &lt;cell&gt;9.7%&lt;/cell&gt;
        &lt;cell&gt;28&lt;/cell&gt;
        &lt;cell&gt;122&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;149&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All makes sense in the world.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46912843</guid><pubDate>Fri, 06 Feb 2026 13:54:09 +0000</pubDate></item><item><title>Microsoft open-sources LiteBox, a security-focused library OS</title><link>https://github.com/microsoft/litebox</link><description>&lt;doc fingerprint="272b985dd8c3e751"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;A security-focused library OS&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;This project is currently actively evolving and improving. While we are working toward a stable release, some APIs and interfaces may change as the design continues to mature. You are welcome to explore and experiment, but if you need long-term stability, it may be best to wait for a stable release, or be prepared to adapt to updates along the way.&lt;/p&gt;
    &lt;p&gt;LiteBox is a sandboxing library OS that drastically cuts down the interface to the host, thereby reducing attack surface. It focuses on easy interop of various "North" shims and "South" platforms. LiteBox is designed for usage in both kernel and non-kernel scenarios.&lt;/p&gt;
    &lt;p&gt;LiteBox exposes a Rust-y &lt;code&gt;nix&lt;/code&gt;/&lt;code&gt;rustix&lt;/code&gt;-inspired "North" interface when it is provided a &lt;code&gt;Platform&lt;/code&gt; interface at its "South".  These interfaces allow for a wide variety of use-cases, easily allowing for connection between any of the North--South pairs.&lt;/p&gt;
    &lt;p&gt;Example use cases include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Running unmodified Linux programs on Windows&lt;/item&gt;
      &lt;item&gt;Sandboxing Linux applications on Linux&lt;/item&gt;
      &lt;item&gt;Run programs on top of SEV SNP&lt;/item&gt;
      &lt;item&gt;Running OP-TEE programs on Linux&lt;/item&gt;
      &lt;item&gt;Running on LVBS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the following files for details:&lt;/p&gt;
    &lt;p&gt;MIT License. See ./LICENSE for details.&lt;/p&gt;
    &lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark &amp;amp; Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46913793</guid><pubDate>Fri, 06 Feb 2026 15:13:04 +0000</pubDate></item><item><title>An Update on Heroku</title><link>https://www.heroku.com/blog/an-update-on-heroku/</link><description>&lt;doc fingerprint="e57d8508db6b75e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;An Update on Heroku&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Last Updated: February 06, 2026&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Today, Heroku is transitioning to a sustaining engineering model focused on stability, security, reliability, and support. Heroku remains an actively supported, production-ready platform, with an emphasis on maintaining quality and operational excellence rather than introducing new features. We know changes like this can raise questions, and we want to be clear about what this means for customers.&lt;/p&gt;
    &lt;p&gt;There is no change for customers using Heroku today. Customers who pay via credit card in the Heroku dashboard‚Äîboth existing and new‚Äîcan continue to use Heroku with no changes to pricing, billing, service, or day-to-day usage. Core platform functionality, including applications, pipelines, teams, and add-ons, is unaffected, and customers can continue to rely on Heroku for their production, business-critical workloads.&lt;/p&gt;
    &lt;p&gt;Enterprise Account contracts will no longer be offered to new customers. Existing Enterprise subscriptions and support contracts will continue to be fully honored and may renew as usual.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why this change&lt;/head&gt;
    &lt;p&gt;We‚Äôre focusing our product and engineering investments on areas where we can deliver the greatest long-term customer value, including helping organizations build and deploy enterprise-grade AI in a secure and trusted way.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Originally Published:&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46913903</guid><pubDate>Fri, 06 Feb 2026 15:20:23 +0000</pubDate></item><item><title>Sheldon Brown's Bicycle Technical Info</title><link>https://www.sheldonbrown.com/</link><description>&lt;doc fingerprint="b6f35e572bce892"&gt;
  &lt;main&gt;
    &lt;p&gt;Sheldon Brown's Bicycle Technical Info Articles by Sheldon Brown and Others What's New Beginners Bicycle Glossary Brakes Commuting Cyclecomputers Do-It-Yourself Essays and Fiction Family Cycling Fixed-Gear Frames Gears and Drivetrains Humor Old Bikes Repair Tips Singlespeed Tandems Touring Video Wheels Translations Sheldon - the man Sheldon Brown's Bicycle Glossary: A - B - C - D - EF - G - H - IJKL - M - NO - PQ - R - S - T - UVWXYZ What's New at sheldonbrown.com Our Paris-Brest-Paris page Sheldon Brown's Personal Pages Books Boston My Bicycles France My Hotlists My Journal Miscellaneous Music Photography Qu√©bec Plus √áa Change Radio Mailing lists My Father My Mother My Great-grandfather If you would like to make a link or bookmark to this page, the URL is: https://www.sheldonbrown.com/index.html Last Updated: by John Allen&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46914159</guid><pubDate>Fri, 06 Feb 2026 15:40:42 +0000</pubDate></item><item><title>The Waymo World Model</title><link>https://waymo.com/blog/2026/02/the-waymo-world-model-a-new-frontier-for-autonomous-driving-simulation</link><description>&lt;doc fingerprint="75b5e4f8bda0980d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Waymo World Model: A New Frontier For Autonomous Driving Simulation&lt;/head&gt;
    &lt;p&gt;The Waymo Driver has traveled nearly 200 million fully autonomous miles, becoming a vital part of the urban fabric in major U.S. cities and improving road safety. What riders and local communities don‚Äôt see is our Driver navigating billions of miles in virtual worlds, mastering complex scenarios long before it encounters them on public roads. Today, we are excited to introduce the Waymo World Model, a frontier generative model that sets a new bar for large-scale, hyper-realistic autonomous driving simulation.&lt;/p&gt;
    &lt;p&gt;Simulation is a critical component of Waymo‚Äôs AI ecosystem and one of the three key pillars of our approach to demonstrably safe AI. The Waymo World Model, which we detail below, is the component that is responsible for generating hyper-realistic simulated environments.&lt;/p&gt;
    &lt;p&gt;The Waymo World Model is built upon Genie 3‚ÄîGoogle DeepMind's most advanced general-purpose world model that generates photorealistic and interactive 3D environments‚Äîand is adapted for the rigors of the driving domain. By leveraging Genie‚Äôs immense world knowledge, it can simulate exceedingly rare events‚Äîfrom a tornado to a casual encounter with an elephant‚Äîthat are almost impossible to capture at scale in reality. The model‚Äôs architecture offers high controllability, allowing our engineers to modify simulations with simple language prompts, driving inputs, and scene layouts. Notably, the Waymo World Model generates high-fidelity, multi-sensor outputs that include both camera and lidar data.&lt;/p&gt;
    &lt;p&gt;This combination of broad world knowledge, fine-grained controllability, and multi-modal realism enhances Waymo‚Äôs ability to safely scale our service across more places and new driving environments. In the following sections we showcase the Waymo World Model in action, featuring simulations of the Waymo Driver navigating diverse rare edge-case scenarios.&lt;/p&gt;
    &lt;head rend="h3"&gt;üåé Emergent Multimodal World Knowledge&lt;/head&gt;
    &lt;p&gt;Most simulation models in the autonomous driving industry are trained from scratch based on only the on-road data they collect. That approach means the system only learns from limited experience. Genie 3‚Äôs strong world knowledge, gained from its pre-training on an extremely large and diverse set of videos, allows us to explore situations that were never directly observed by our fleet.&lt;/p&gt;
    &lt;p&gt;Through our specialized post-training, we are transferring that vast world knowledge from 2D video into 3D lidar outputs unique to Waymo‚Äôs hardware suite. While cameras excel at depicting visual details, lidar sensors provide valuable complementary signals like precise depth. The Waymo World Model can generate virtually any scene‚Äîfrom regular, day-to-day driving to rare, long-tail scenarios‚Äîacross multiple sensor modalities.&lt;/p&gt;
    &lt;head rend="h5"&gt;üå™Ô∏è Extreme weather conditions and natural disasters&lt;/head&gt;
    &lt;head rend="h5"&gt;üí• Rare and safety-critical events&lt;/head&gt;
    &lt;head rend="h5"&gt;üêò Long-tail (pun intended!) objects and more&lt;/head&gt;
    &lt;p&gt;In the interactive viewers below, you can immersively view the realistic 4D point clouds generated by the Waymo World Model.&lt;/p&gt;
    &lt;head rend="h3"&gt;üïπÔ∏è Strong Simulation Controllability&lt;/head&gt;
    &lt;p&gt;The Waymo World Model offers strong simulation controllability through three main mechanisms: driving action control, scene layout control, and language control.&lt;/p&gt;
    &lt;p&gt;Driving action control allows us to have a responsive simulator that adheres to specific driving inputs. This enables us to simulate ‚Äúwhat if‚Äù counterfactual events such as whether the Waymo Driver could have safely driven more confidently instead of yielding in a particular situation.&lt;/p&gt;
    &lt;p&gt;Counterfactual driving. We demonstrate simulations both under the original route in a past recorded drive, or a completely new route. While purely reconstructive simulation methods (e.g., 3D Gaussian Splats, or 3DGS) suffer from visual breakdowns due to missing observations when the simulated route is too different from the original driving, the fully learned Waymo World Model maintains good realism and consistency thanks to its strong generative capabilities.&lt;/p&gt;
    &lt;p&gt;Scene layout control allows for customization of the road layouts, traffic signal states, and the behavior of other road users. This way, we can create custom scenarios via selective placement of other road users, or applying custom mutations to road layouts.&lt;/p&gt;
    &lt;p&gt;Scene layout conditioning following&lt;/p&gt;
    &lt;p&gt;Language control is our most flexible tool that allows us to adjust time-of-day, weather conditions, or even generate an entirely synthetic scene (such as the long-tail scenarios shown previously).&lt;/p&gt;
    &lt;p&gt;World Mutation - Time of Day&lt;/p&gt;
    &lt;p&gt;World Mutation - Weather&lt;/p&gt;
    &lt;head rend="h3"&gt;üéûÔ∏è Converting Dashcam Videos&lt;/head&gt;
    &lt;p&gt;During a scenic drive, it is common to record videos of the journey on mobile devices or dashcams, perhaps capturing piled up snow banks or a highway at sunset. The Waymo World Model can convert those kinds of videos, or any taken with a regular camera, into a multimodal simulation‚Äîshowing how the Waymo Driver would see that exact scene. This process enables the highest degree of realism and factuality, since simulations are derived from actual footage.&lt;/p&gt;
    &lt;head rend="h3"&gt;‚öôÔ∏è Scalable Inference&lt;/head&gt;
    &lt;p&gt;Some scenes we want to simulate may take longer to play out, for example, negotiating passage in a narrow lane. That‚Äôs harder to do because the longer the simulation, the tougher it is to compute and maintain stable quality. However, through a more efficient variant of the Waymo World Model, we can simulate longer scenes with dramatic reduction in compute while maintaining high realism and fidelity to enable large-scale simulations.&lt;/p&gt;
    &lt;head rend="h5"&gt;üöÄ Long rollout (4x speed playback) on an efficient variant of the Waymo World Model&lt;/head&gt;
    &lt;p&gt;By simulating the ‚Äúimpossible‚Äù, we proactively prepare the Waymo Driver for some of the most rare and complex scenarios. This creates a more rigorous safety benchmark, ensuring the Waymo Driver can navigate long-tail challenges long before it encounters them in the real world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;The Waymo World Model is enabled by the key research, engineering and evaluation contributions from James Gunn, Kanaad Parvate, Lu Liu, Lucas Deecke, Luca Bergamini, Zehao Zhu, Raajay Viswanathan, Jiahao Wang, Sakshum Kulshrestha, Titas Anciukeviƒçius, Luna Yue Huang, Yury Bychenkov, Yijing Bai, Yichen Shen, Stefanos Nikolaidis, Tiancheng Ge, Shih-Yang Su and Vincent Casser.&lt;/p&gt;
    &lt;p&gt;We thank Chulong Chen, Mingxing Tan, Tom Walters, Harish Chandran, David Wong, Jieying Chen, Smitha Shyam, Vincent Vanhoucke and Drago Anguelov for their support in defining the vision for this project, and for their strong leadership and guidance throughout.&lt;/p&gt;
    &lt;p&gt;We would like to additionally thank Jon Pedersen, Michael Dreibelbis, Larry Lansing, Sasho Gabrovski, Alan Kimball, Dave Richardson, Evan Birenbaum, Harrison McKenzie Chapter and Pratyush Chakraborty, Khoa Vo, Todd Hester, Yuliang Zou, Artur Filipowicz, Sophie Wang and Linn Bieske for their invaluable partnership in facilitating and enabling this project.&lt;/p&gt;
    &lt;p&gt;We thank our partners from Google DeepMind: Jack Parker-Holder, Shlomi Fruchter, Philip Ball, Ruiqi Gao, Songyou Peng, Ben Poole, Fei Xia, Allan Zhou, Sean Kirmani, Christos Kaplanis, Matt McGill, Tim Salimans, Ruben Villegas, Xinchen Yan, Emma Wang, Woohyun Han, Shan Han, Rundi Wu, Shuang Li, Philipp Henzler, Yulia Rubanova, and Thomas Kipf for helpful discussions and for sharing invaluable insights for this project.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46914785</guid><pubDate>Fri, 06 Feb 2026 16:20:42 +0000</pubDate></item><item><title>I spent 5 years in DevOps ‚Äì Solutions engineering gave me what I was missing</title><link>https://infisical.com/blog/devops-to-solutions-engineering</link><description>&lt;doc fingerprint="2cd13b40d7e4344e"&gt;
  &lt;main&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Blog post ‚Ä¢ 7 min read&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;I Spent 5 Years in DevOps. Solutions Engineering Gave Me What I Was Missing.&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Published on&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I was good at DevOps. This isn't a story about escaping a job I hated. I spent five years as a DevSecOps engineer at two large financial services companies. I built things I was proud of. I learned a ton. I was respected by my team.&lt;/p&gt;
    &lt;p&gt;But somewhere around year four, something shifted. The work didn't change. I did. After five years, I made a change that surprised everyone who knew me: I left for a sales-adjacent role. Today, I'm one year into working as a Solutions Engineer at Infisical, and I want to share what I've learned. I think there are other DevOps engineers out there who might be feeling the same thing I felt, even if they can't quite name it yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;What I Was Actually Missing&lt;/head&gt;
    &lt;p&gt;For a long time, I couldn't pinpoint what was wrong. The job was fine. I was good at it. But I started dreading the monotony of it all.&lt;/p&gt;
    &lt;p&gt;Part of it was repetition. My days had become predictable: check the dashboards, respond to tickets, debug whatever broke overnight, push some Terraform, go home. Maintain the HashiCorp Vault clusters, manage the secrets pipelines, answer the same support questions. Repeat. The work that used to feel engaging had become routine.&lt;/p&gt;
    &lt;p&gt;Part of it was stagnation. When I first started, I was learning constantly. Vault architecture, PKI fundamentals, secrets rotation, the politics of platform adoption in a large enterprise. But once I'd mastered the core toolset and codebase, the learning curve flattened. I wasn't being challenged anymore. I was just keeping things running.&lt;/p&gt;
    &lt;p&gt;And part of it was isolation. Most days, it was just me and my pipelines. My primary relationships were with CI/CD tools and YAML files. The humans I did interact with were usually frustrated. They needed something from me, or something I owned was blocking them. I missed working with people, not just unblocking them from behind a ticket queue.&lt;/p&gt;
    &lt;p&gt;I didn't have a word for what I was looking for. I just knew that what I was doing wasn't it anymore.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discovering a Role I Didn't Know Existed&lt;/head&gt;
    &lt;p&gt;I had no idea Solutions Engineering was a real career path.&lt;/p&gt;
    &lt;p&gt;I knew sales existed. I vaguely knew there were "technical sales" people. But I assumed those were salespeople who'd learned enough technical vocabulary to get by, not engineers who actually stayed technical while working with customers.&lt;/p&gt;
    &lt;p&gt;Some friends in sales pointed it out to me. They'd watched me get animated whenever someone asked how something worked, and one of them eventually said: "You know there's a job where you explain technical stuff to people all day and help them solve problems, right?"&lt;/p&gt;
    &lt;p&gt;I'd never considered anything sales-adjacent because I assumed it meant leaving the technical world. But the more I learned about SE, the more I realized it might solve everything I was missing. New problems to solve every day. Constant learning. And more people.&lt;/p&gt;
    &lt;p&gt;I ended up joining Infisical. There's some irony there: I spent years managing HashiCorp Vault, and now I work for a Vault competitor. But that background is exactly why the role made sense. I knew the space. I knew the pain points. I knew what it felt like to be the engineer on the other side, evaluating these tools.&lt;/p&gt;
    &lt;head rend="h2"&gt;One Year In: What Actually Changed&lt;/head&gt;
    &lt;p&gt;The biggest change is the simplest one: I talk to people now. A lot of people. Every day.&lt;/p&gt;
    &lt;p&gt;In a single week, I might have a discovery call with a fintech startup, demo to a platform team at an aerospace company, help a healthcare organization troubleshoot their Kubernetes deployment, and run a workshop for a manufacturing company's security team. Fintech to aerospace to healthcare to manufacturing, all with completely different stacks and problems.&lt;/p&gt;
    &lt;p&gt;And it's not all over Zoom. I get to visit customers on-site, sit down with their teams face to face, and actually understand how they work. Over time, you build real relationships with these people. You become their trusted technical advisor, not just a vendor they talk to once. That's something I never experienced in DevOps, where my "customers" were internal teams who mostly just wanted me to unblock them.&lt;/p&gt;
    &lt;p&gt;The contrast with my DevOps days is stark. Monday morning used to mean checking dashboards, then the ticket queue, then the same Slack questions I'd answered last week. Now Monday morning might mean prepping for a demo with a company I've never spoken to, or helping a long-time customer work through a new challenge. I genuinely don't know what most days will look like until they start.&lt;/p&gt;
    &lt;p&gt;One thing I didn't expect: I'm not just talking to customers. I've become a bridge between the people using our product and the people building it. Every customer conversation surfaces pain points, feature gaps, edge cases our docs don't cover. I take that back to engineering and product. I'm actually influencing what we build next, which is something I never had in DevOps. I was always downstream of decisions, not shaping them.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Superpower I Didn't Know I Had&lt;/head&gt;
    &lt;p&gt;My biggest fear going in was that I'd lose my technical edge. That I'd become "the sales guy" and slowly forget how things actually worked.&lt;/p&gt;
    &lt;p&gt;That didn't happen. As an SE, I'm exposed to everything. Customers running Kubernetes, ECS, Lambda, bare metal, air-gapped environments. AWS, Azure, GCP, hybrid setups. CI/CD in Jenkins, GitHub Actions, GitLab, CircleCI. I have to understand their environment well enough to actually help them, so the learning is constant. The stagnation I felt in DevOps? Gone.&lt;/p&gt;
    &lt;p&gt;But all those years in DevOps weren't just background. They're the reason I'm useful in this role.&lt;/p&gt;
    &lt;p&gt;I get on calls and prospects describe problems I've literally lived. They talk about the pain of managing secrets at scale, and I can say "yeah, I've been there" and actually mean it. That shared experience changes the dynamic completely. I'm not a salesperson trying to manufacture urgency. I'm an engineer who dealt with the same problems and found something that helped.&lt;/p&gt;
    &lt;p&gt;Is it all upside? No. Demoing is a skill I had to build from scratch. The context-switching is intense. The stress is different, more human, more ambiguous. But it's the kind of challenge that makes me better, not the kind that grinds me down.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who This Might Be For&lt;/head&gt;
    &lt;p&gt;This path isn't for everyone. If you love going deep on a single system and optimizing it over years, SE might feel too scattered. If you genuinely prefer working alone with your tools, the constant human interaction might drain you.&lt;/p&gt;
    &lt;p&gt;But if any of this resonates, if you're good at DevOps but feel stuck, if the work has become repetitive, if you miss collaborating with people, if you find yourself energized when explaining technical concepts or helping someone work through a problem, Solutions Engineering might be worth exploring.&lt;/p&gt;
    &lt;p&gt;I didn't know this role existed until someone pointed it out to me. Now, one year in, I can't imagine going back. Not because DevOps is bad. It's critical work, and the people who do it well deserve more credit than they get.&lt;/p&gt;
    &lt;p&gt;But for me, it was missing something I didn't know how to name until I found it: the chance to be technical and connected. To keep learning, to solve new problems every day, and to do it alongside people instead of behind a queue.&lt;/p&gt;
    &lt;p&gt;If you're a DevOps engineer feeling something similar, even if you can't quite articulate it, maybe this is what you're looking for too.&lt;/p&gt;
    &lt;p&gt;I didn't know this role existed until someone pointed it out to me. Consider this me pointing it out to you. We're hiring at Infisical.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46915102</guid><pubDate>Fri, 06 Feb 2026 16:45:47 +0000</pubDate></item><item><title>How to effectively write quality code with AI</title><link>https://heidenstedt.org/posts/2026/how-to-effectively-write-quality-code-with-ai/</link><description>&lt;doc fingerprint="bed09edf20d5daed"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;1 Establish a Clear Vision&lt;/head&gt;
    &lt;p&gt;You are a human, you know how this world behaves, how your team and colleagues behave, and what your users expect. You have experienced the world, and you want to work together with a system that has no experience in this world you live in. Every decision in your project that you don‚Äôt take and document will be taken for you by the AI.&lt;/p&gt;
    &lt;p&gt;Your responsibility of delivering quality code cannot be met if not even you know where long-lasting and difficult-to-change decisions are taken.&lt;lb/&gt;You must know what parts of your code need to be thought through and what must be vigorously tested.&lt;/p&gt;
    &lt;p&gt;Think about and discuss the architecture, interfaces, data structures, and algorithms you want to use. Think about how to test and validate your code to these specifications.&lt;/p&gt;
    &lt;head rend="h2"&gt;2 Maintain Precise documentation&lt;/head&gt;
    &lt;p&gt;You need to communicate to the AI in detail what you want to achieve, otherwise it will result in code that is unusable for your purpose.&lt;/p&gt;
    &lt;p&gt;Other developers also need to communicate this information to the AI. That makes it efficient to write as much documentation as practical in a standardized format and into the code repository itself.&lt;/p&gt;
    &lt;p&gt;Document the requirements, specifications, constraints, and architecture of your project in detail.&lt;lb/&gt;Document your coding standards, best practices, and design patterns.&lt;lb/&gt;Use flowcharts, UML diagrams, and other visual aids to communicate complex structures and workflows.&lt;lb/&gt;Write pseudocode for complex algorithms and logic to guide the AI in understanding your intentions.&lt;/p&gt;
    &lt;head rend="h2"&gt;3 Build debug systems that aid the AI&lt;/head&gt;
    &lt;p&gt;Develop efficient debug systems for the AI to use, reducing the need for multiple expensive CLI commands or browsers to verify code functionality. This will save time and resources while simplifying the process for the AI to identify and resolve code issues.&lt;/p&gt;
    &lt;p&gt;For example: Build a system that collects logs from all nodes in a distributed system and provides abstracted information like ‚ÄúThe Data was send to all nodes‚Äù, ‚ÄúThe Data X is saved on Node 1 but not on Node 2‚Äù.&lt;/p&gt;
    &lt;head rend="h2"&gt;4 Mark code review levels&lt;/head&gt;
    &lt;p&gt;Not all code is equally important. Some parts of your codebase are critical and need to be reviewed with extra care. Other parts are less important and can be generated with less oversight.&lt;/p&gt;
    &lt;p&gt;Use a system that allows you to mark how thoroughly each function has been reviewed.&lt;/p&gt;
    &lt;p&gt;For example you can use a prompt that will let the AI put the comment &lt;code&gt;//A&lt;/code&gt; behind functions it wrote to indicate that the function has been written by an AI and is not yet reviewed by a human.&lt;/p&gt;
    &lt;head rend="h2"&gt;5 Write high level specifications and test by yourself&lt;/head&gt;
    &lt;p&gt;AIs will cheat and use shortcuts eventually. They will write mocks, stubs, and hard coded values to make the code tests succeed while the code itself is not working and most of the time dangerous. Often AIs will adapt or outright delete test code to let the code pass tests.&lt;/p&gt;
    &lt;p&gt;You must discourage this behavior by writing property based high level specification tests yourself. Build them in a way that makes it hard for the AI to cheat without having big code segments dedicated to it.&lt;lb/&gt;For example, use property based testing, restart the server and check in between if the database has the correct values.&lt;/p&gt;
    &lt;p&gt;Separate these test so the AI cannot edit them and prompt the AI not to change them.&lt;/p&gt;
    &lt;head rend="h2"&gt;6 Write interface tests in a separate context&lt;/head&gt;
    &lt;p&gt;Let an AI write property based interface tests for the expected behavior with as little context of the rest of the code as possible.&lt;lb/&gt;This will generate tests that are uninfluenced by the ‚Äúimplementation AI‚Äù which will prevent the tests from being adapted to the implementation in a way that makes them useless or less effective.&lt;/p&gt;
    &lt;p&gt;Separate these tests so the AI cannot edit them without approval and prompt the AI not to change them.&lt;/p&gt;
    &lt;head rend="h2"&gt;7 Use strict linting and formatting rules&lt;/head&gt;
    &lt;p&gt;Use strict linting and formatting rules to ensure code quality and consistency. This will help you and your AI to find issues early.&lt;/p&gt;
    &lt;head rend="h2"&gt;8 Use context specific coding agent prompts&lt;/head&gt;
    &lt;p&gt;Save time and money by utilizing path specific coding agent prompts like CLAUDE.md.&lt;/p&gt;
    &lt;p&gt;You can generate them automatically which will give your AI information it would otherwise as to create from scratch every time.&lt;/p&gt;
    &lt;p&gt;Try to provide as much high level information as practical, such as coding standards, best practices, design patterns, and specific requirements for the project. This will help the AI to generate code that is more aligned with your expectations and will reduce lookup time and cost.&lt;/p&gt;
    &lt;head rend="h2"&gt;9 Find and mark functions that have a high security risk&lt;/head&gt;
    &lt;p&gt;Identify and mark functions that have a high security risk, such as authentication, authorization, and data handling. These functions should be reviewed and tested with extra care and in such a way that a human has comprehended the logic of the function in all its dimensions and is confident about its correctness and safety.&lt;/p&gt;
    &lt;p&gt;Make this explicit with a comment like &lt;code&gt;//HIGH-RISK-UNREVIEWED&lt;/code&gt; and &lt;code&gt;//HIGH-RISK-REVIEWED&lt;/code&gt; to make sure that other developers are aware of the importance of these functions and will review them with extra care.&lt;/p&gt;
    &lt;p&gt;Make sure that the AI is instructed to change the review state of these functions as soon as it changes a single character in the function.&lt;lb/&gt;Developers must make sure that the status of these functions is always correct.&lt;/p&gt;
    &lt;head rend="h2"&gt;10 Reduce code complexity where possible&lt;/head&gt;
    &lt;p&gt;Aim to reduce the complexity of the generated code where possible. Each single line of code will eat up your context window and make it harder for the AI and You to keep track of the overall logic of your code.&lt;lb/&gt;Each avoidable line of code is costing energy, money and probability of future unsuccessful AI tasks.&lt;/p&gt;
    &lt;head rend="h2"&gt;11 Explore problems with experiments and prototypes&lt;/head&gt;
    &lt;p&gt;AI written code is cheap, use this to your advantage by exploring different solutions to a problem with experiments and prototypes with minimal specifications. This will allow you to find the best solution to a problem without investing too much time and resources in a single solution.&lt;/p&gt;
    &lt;head rend="h2"&gt;12 Do not generate blindly or to much complexity at once&lt;/head&gt;
    &lt;p&gt;Break down complex tasks into smaller, manageable tasks for the AI. Instead of asking the AI to generate the complete project or component at once, break it down into smaller tasks, such as generating individual functions or classes. This will help you to maintain control over the code and it‚Äôs logic.&lt;/p&gt;
    &lt;p&gt;You have to check each component or module for its adherence to the specifications and requirements.&lt;lb/&gt;If you have lost the overview of the complexity and inner workings of the code, you have lost control over your code and must restart from a state where you were in control of your code.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46916586</guid><pubDate>Fri, 06 Feb 2026 18:49:59 +0000</pubDate></item><item><title>Show HN: If you lose your memory, how to regain access to your computer?</title><link>https://eljojo.github.io/rememory/</link><description>&lt;doc fingerprint="69b580f4f137d2e5"&gt;
  &lt;main&gt;&lt;p&gt;This is a tool that encrypts files and splits the decryption key among trusted friends using Shamir's Secret Sharing. For example, you can give pieces to 5 friends and require any 3 of them to cooperate to recover the key. No single friend can access your data alone.&lt;/p&gt;&lt;p&gt; Each friend receives a self-contained bundle with &lt;code&gt;recover.html&lt;/code&gt;‚Äîa browser-based tool that works
        offline, with no servers or internet required. If this website disappears, recovery still works.
      &lt;/p&gt;&lt;p&gt;Your file is encrypted, the key is split into shares, and friends combine shares to recover it.&lt;/p&gt;&lt;p&gt; Your File ‚Üí Encrypt ‚Üí Split key into 5 shares ‚Üí Distribute to friends&lt;lb/&gt; ‚Üì&lt;lb/&gt; Any 3 friends ‚Üí Combine shares ‚Üí Decrypt ‚Üí File recovered &lt;/p&gt;&lt;code&gt;bundle-alice/recover.html&lt;/code&gt; in your browser&lt;p&gt;This is the best way to understand what your friends would experience during a real recovery.&lt;/p&gt;&lt;p&gt;I wanted a way to ensure trusted friends could access important files if something happened to me‚Äîwithout trusting any single person or service with everything. Shamir's Secret Sharing seemed like the right approach, but I couldn't find a tool that gave friends a simple, self-contained way to recover files together. So I built one. I'm sharing it in case it's useful to others.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46916609</guid><pubDate>Fri, 06 Feb 2026 18:51:58 +0000</pubDate></item><item><title>Show HN: I spent 4 years building a UI design tool with only the features I use</title><link>https://vecti.com</link><description>&lt;doc fingerprint="3d7ab04bf9563c9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Design better user experiences, faster.&lt;/head&gt;
    &lt;p&gt;Vecti is the collaborative UX design tool that turns complex workflows into intuitive visual solutions.&lt;/p&gt;
    &lt;head rend="h5"&gt;Build Together&lt;/head&gt;
    &lt;head rend="h2"&gt;Collaborate in real-time, from anywhere&lt;/head&gt;
    &lt;p&gt;Multiple team members can simultaneously edit and review designs, with all assets and artifacts shared seamlessly across the team.&lt;/p&gt;
    &lt;head rend="h5"&gt;Build at Speed&lt;/head&gt;
    &lt;head rend="h2"&gt;High-fidelity, powerful rendering engine&lt;/head&gt;
    &lt;p&gt;Use our high-performance rendering engine to build your pixel-perfect designs. Handle unlimited-scale projects without compromise.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why designers choose Vecti&lt;/head&gt;
    &lt;p&gt;Professional power. Intuitive simplicity. Built specifically for modern UX workflows&lt;/p&gt;
    &lt;head rend="h2"&gt;Intuitive Interface&lt;/head&gt;
    &lt;p&gt;Our intuitive interface will help you quickly bring your ideas to life so you can spend more time to be creative.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reusable Componentscoming soon&lt;/head&gt;
    &lt;p&gt;Create once, use everywhere. Simply drag and drop or click to re-use your previously created UI elements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Shared Asset Library&lt;/head&gt;
    &lt;p&gt;Centralize all your design resources in one collaborative library where team members can upload, access, and reuse assets instantly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Share &amp;amp; Present&lt;/head&gt;
    &lt;p&gt;Set viewer and editor permissions at the team or project level. When it's time to present, switch to full-screen mode and let your work shine.&lt;/p&gt;
    &lt;head rend="h5"&gt;Pricing&lt;/head&gt;
    &lt;head rend="h1"&gt;Choose the plan that best fits you&lt;/head&gt;
    &lt;p&gt;Pay only for what you need with our pay-per-editor model, it's easy to scale your team and manage your budget.&lt;/p&gt;
    &lt;head rend="h2"&gt;Starter $0 / mo&lt;/head&gt;
    &lt;p&gt;Create 5 projects &amp;amp; invite 1 more editor&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Up to 5 projects&lt;/item&gt;
      &lt;item&gt;Up to 2 editors&lt;/item&gt;
      &lt;item&gt;Unlimited viewers&lt;/item&gt;
      &lt;item&gt;Sharing via link&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Professional $12 / mo&lt;/head&gt;
    &lt;p&gt;Billed annually, or $15/mo billed monthly&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unlimited projects&lt;/item&gt;
      &lt;item&gt;Pay per editor&lt;/item&gt;
      &lt;item&gt;Unlimited viewers&lt;/item&gt;
      &lt;item&gt;Sharing via link&lt;/item&gt;
      &lt;item&gt;Sharing permissions&lt;/item&gt;
      &lt;item&gt;Priority support&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Not sure which plan is right for you?&lt;/head&gt;
    &lt;p&gt;Our support team is ready to help you choose the best option for you.&lt;lb/&gt;Send us an email and we'll get back to you in no time.&lt;/p&gt;
    &lt;p&gt;Educational and open-source discounts are available on request. Contact us.&lt;/p&gt;
    &lt;head rend="h5"&gt;F.A.Q.&lt;/head&gt;
    &lt;head rend="h1"&gt;Have a question or need help?&lt;/head&gt;
    &lt;p&gt;We provide email support from 8:00 AM - 6:00 PM (GMT), Monday to Friday. We do our best to respond to each request with a personalized reply within 24-48 business hours.&lt;/p&gt;
    &lt;p&gt;No, you can get started with Vecti for free and use Vecti for as long as you want without needing a card on file. You're only asked to provide a card when you want to upgrade your plan.&lt;/p&gt;
    &lt;p&gt; You can choose between a monthly or annual billing cycle.&lt;lb/&gt; Annual pricing gives you the ability to pay for a plan upfront at a discounted rate. Paying for a plan upfront can save up to 20% compared to paying monthly. &lt;/p&gt;
    &lt;p&gt;Your plan automatically renews at the end of each billing cycle, but you can stop it from renewing by cancelling at any time. You will still pay the remainder of the term for the professional plan.&lt;/p&gt;
    &lt;p&gt;You will not lose any of your work if you downgrade. The projects and workspaces will still be available, yet with some limitations. You will not be able to create more projects (if you have more than 5 already). You will also lose the professional features.&lt;/p&gt;
    &lt;p&gt;Yes, we provide free plans for students and teachers! Please contact us.&lt;/p&gt;
    &lt;p&gt;We do not have any discounts for non-profit organisations. Anyone is welcome to use Vecti's free plan.&lt;/p&gt;
    &lt;head rend="h5"&gt;User Stories&lt;/head&gt;
    &lt;head rend="h1"&gt;What designers and product managers like you have to say&lt;/head&gt;
    &lt;head rend="h1"&gt;√¢As someone who often jumps into design work, Vecti is a game-changer. I can quickly mock up interfaces, share them with my team for feedback, and export clean assets, all without leaving my flow.√¢&lt;/head&gt;
    &lt;head rend="h1"&gt;√¢I finally found a design tool where I can collaborate seamlessly with developers and stakeholders. No more endless email threads. The permission controls and presentation mode have completely transformed how I run design reviews.√¢&lt;/head&gt;
    &lt;head rend="h1"&gt;√¢Vecti's interface felt instantly familiar, but the performance with my massive design system? Night and day difference. I'm never going back.√¢&lt;/head&gt;
    &lt;head rend="h5"&gt;About&lt;/head&gt;
    &lt;head rend="h1"&gt;Our Story&lt;/head&gt;
    &lt;head rend="h1"&gt;After nearly two decades in UI and design, I saw an opportunity to build something different, a design tool with a better philosophy. So I built it. Vecti is a browser-based UI design tool built from the ground up with one core belief, that creators deserve tools built specifically for them. Better performance, better privacy, and better alignment with their actual needs. A tool that just works, built by someone who genuinely cares about the people using it.&lt;/head&gt;
    &lt;p&gt;Serge @ Vecti&lt;/p&gt;
    &lt;p&gt;Founder&lt;/p&gt;
    &lt;head rend="h2"&gt;Our Mission&lt;/head&gt;
    &lt;p&gt;To give designers and developers a design tool they can trust. We prioritize performance, privacy, and creative freedom. Vecti is built and based in the EU, following European privacy standards. We're transparent about how we operate. Design software should serve creators first - that's our commitment.&lt;/p&gt;
    &lt;head rend="h2"&gt;Our Vision&lt;/head&gt;
    &lt;p&gt;A world where design tools are built with the community, not imposed on them. Where solo creators and small teams have access to professional-grade software that respects them. We're building Vecti to be that tool-performant, transparent, and genuinely aligned with the people who use it every day. This is just the beginning.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46917033</guid><pubDate>Fri, 06 Feb 2026 19:27:37 +0000</pubDate></item><item><title>Monty: A minimal, secure Python interpreter written in Rust for use by AI</title><link>https://github.com/pydantic/monty</link><description>&lt;doc fingerprint="b5ba06337cac1e92"&gt;
  &lt;main&gt;
    &lt;p&gt;Experimental - This project is still in development, and not ready for the prime time.&lt;/p&gt;
    &lt;p&gt;A minimal, secure Python interpreter written in Rust for use by AI.&lt;/p&gt;
    &lt;p&gt;Monty avoids the cost, latency, complexity and general faff of using full container based sandbox for running LLM generated code.&lt;/p&gt;
    &lt;p&gt;Instead, it let's you safely run Python code written by an LLM embedded in your agent, with startup times measured in single digit microseconds not hundreds of milliseconds.&lt;/p&gt;
    &lt;p&gt;What Monty can do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run a reasonable subset of Python code - enough for your agent to express what it wants to do&lt;/item&gt;
      &lt;item&gt;Completely block access to the host environment: filesystem, env variables and network access are all implemented via external function calls the developer can control&lt;/item&gt;
      &lt;item&gt;Call functions on the host - only functions you give it access to&lt;/item&gt;
      &lt;item&gt;Run typechecking - monty supports full modern python type hints and comes with ty included in a single binary to run typechecking&lt;/item&gt;
      &lt;item&gt;Be snapshotted to bytes at external function calls, meaning you can store the interpreter state in a file or database, and resume later&lt;/item&gt;
      &lt;item&gt;Startup extremely fast (&amp;lt;1Œºs to go from code to execution result), and has runtime performance that is similar to CPython (generally between 5x faster and 5x slower)&lt;/item&gt;
      &lt;item&gt;Be called from Rust, Python, or Javascript - because Monty has no dependencies on cpython, you can use it anywhere you can run Rust&lt;/item&gt;
      &lt;item&gt;Control resource usage - Monty can track memory usage, allocations, stack depth, and execution time and cancel execution if it exceeds preset limits&lt;/item&gt;
      &lt;item&gt;Collect stdout and stderr and return it to the caller&lt;/item&gt;
      &lt;item&gt;Run async or sync code on the host via async or sync code on the host&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What Monty cannot do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use the standard library (except a few select modules: &lt;code&gt;sys&lt;/code&gt;,&lt;code&gt;typing&lt;/code&gt;,&lt;code&gt;asyncio&lt;/code&gt;,&lt;code&gt;dataclasses&lt;/code&gt;(soon),&lt;code&gt;json&lt;/code&gt;(soon))&lt;/item&gt;
      &lt;item&gt;Use third party libraries (like Pydantic), support for external python library is not a goal&lt;/item&gt;
      &lt;item&gt;define classes (support should come soon)&lt;/item&gt;
      &lt;item&gt;use match statements (again, support should come soon)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In short, Monty is extremely limited and designed for one use case:&lt;/p&gt;
    &lt;p&gt;To run code written by agents.&lt;/p&gt;
    &lt;p&gt;For motivation on why you might want to do this, see:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Codemode from Cloudflare&lt;/item&gt;
      &lt;item&gt;Programmatic Tool Calling from Anthropic&lt;/item&gt;
      &lt;item&gt;Code Execution with MCP from Anthropic&lt;/item&gt;
      &lt;item&gt;Smol Agents from Hugging Face&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In very simple terms, the idea of all the above is that LLMs can be work faster, cheaper and more reliably if they're asked to write Python (or Javascript) code, instead of relying on traditional tool calling. Monty makes that possible without the complexity of a sandbox or risk of running code directly on the host.&lt;/p&gt;
    &lt;p&gt;Note: Monty will (soon) be used to implement &lt;code&gt;codemode&lt;/code&gt; in Pydantic AI&lt;/p&gt;
    &lt;p&gt;Monty can be called from Python, JavaScript/TypeScript or Rust.&lt;/p&gt;
    &lt;p&gt;To install:&lt;/p&gt;
    &lt;code&gt;uv add pydantic-monty&lt;/code&gt;
    &lt;p&gt;(Or &lt;code&gt;pip install pydantic-monty&lt;/code&gt; for the boomers)&lt;/p&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;from typing import Any

import pydantic_monty

code = """
async def agent(prompt: str, messages: Messages):
    while True:
        print(f'messages so far: {messages}')
        output = await call_llm(prompt, messages)
        if isinstance(output, str):
            return output
        messages.extend(output)

await agent(prompt, [])
"""

type_definitions = """
from typing import Any

Messages = list[dict[str, Any]]

async def call_llm(prompt: str, messages: Messages) -&amp;gt; str | Messages:
    raise NotImplementedError()

prompt: str = ''
"""

m = pydantic_monty.Monty(
    code,
    inputs=['prompt'],
    external_functions=['call_llm'],
    script_name='agent.py',
    type_check=True,
    type_check_stubs=type_definitions,
)


Messages = list[dict[str, Any]]


async def call_llm(prompt: str, messages: Messages) -&amp;gt; str | Messages:
    if len(messages) &amp;lt; 2:
        return [{'role': 'system', 'content': 'example response'}]
    else:
        return f'example output, message count {len(messages)}'


async def main():
    output = await pydantic_monty.run_monty_async(
        m,
        inputs={'prompt': 'testing'},
        external_functions={'call_llm': call_llm},
    )
    print(output)
    #&amp;gt; example output, message count 2


if __name__ == '__main__':
    import asyncio

    asyncio.run(main())&lt;/code&gt;
    &lt;p&gt;Use &lt;code&gt;start()&lt;/code&gt; and &lt;code&gt;resume()&lt;/code&gt; to handle external function calls iteratively,
giving you control over each call:&lt;/p&gt;
    &lt;code&gt;import pydantic_monty

code = """
data = fetch(url)
len(data)
"""

m = pydantic_monty.Monty(code, inputs=['url'], external_functions=['fetch'])

# Start execution - pauses when fetch() is called
result = m.start(inputs={'url': 'https://example.com'})

print(type(result))
#&amp;gt; &amp;lt;class 'pydantic_monty.MontySnapshot'&amp;gt;
print(result.function_name)  # fetch
#&amp;gt; fetch
print(result.args)
#&amp;gt; ('https://example.com',)

# Perform the actual fetch, then resume with the result
result = result.resume(return_value='hello world')

print(type(result))
#&amp;gt; &amp;lt;class 'pydantic_monty.MontyComplete'&amp;gt;
print(result.output)
#&amp;gt; 11&lt;/code&gt;
    &lt;p&gt;Both &lt;code&gt;Monty&lt;/code&gt; and &lt;code&gt;MontySnapshot&lt;/code&gt; can be serialized to bytes and restored later.
This allows caching parsed code or suspending execution across process boundaries:&lt;/p&gt;
    &lt;code&gt;import pydantic_monty

# Serialize parsed code to avoid re-parsing
m = pydantic_monty.Monty('x + 1', inputs=['x'])
data = m.dump()

# Later, restore and run
m2 = pydantic_monty.Monty.load(data)
print(m2.run(inputs={'x': 41}))
#&amp;gt; 42

# Serialize execution state mid-flight
m = pydantic_monty.Monty('fetch(url)', inputs=['url'], external_functions=['fetch'])
progress = m.start(inputs={'url': 'https://example.com'})
state = progress.dump()

# Later, restore and resume (e.g., in a different process)
progress2 = pydantic_monty.MontySnapshot.load(state)
result = progress2.resume(return_value='response data')
print(result.output)
#&amp;gt; response data&lt;/code&gt;
    &lt;code&gt;use monty::{MontyRun, MontyObject, NoLimitTracker, StdPrint};

let code = r#"
def fib(n):
    if n &amp;lt;= 1:
        return n
    return fib(n - 1) + fib(n - 2)

fib(x)
"#;

let runner = MontyRun::new(code.to_owned(), "fib.py", vec!["x".to_owned()], vec![]).unwrap();
let result = runner.run(vec![MontyObject::Int(10)], NoLimitTracker, &amp;amp;mut StdPrint).unwrap();
assert_eq!(result, MontyObject::Int(55));&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;MontyRun&lt;/code&gt; and &lt;code&gt;RunProgress&lt;/code&gt; can be serialized using the &lt;code&gt;dump()&lt;/code&gt; and &lt;code&gt;load()&lt;/code&gt; methods:&lt;/p&gt;
    &lt;code&gt;use monty::{MontyRun, MontyObject, NoLimitTracker, StdPrint};

// Serialize parsed code
let runner = MontyRun::new("x + 1".to_owned(), "main.py", vec!["x".to_owned()], vec![]).unwrap();
let bytes = runner.dump().unwrap();

// Later, restore and run
let runner2 = MontyRun::load(&amp;amp;bytes).unwrap();
let result = runner2.run(vec![MontyObject::Int(41)], NoLimitTracker, &amp;amp;mut StdPrint).unwrap();
assert_eq!(result, MontyObject::Int(42));&lt;/code&gt;
    &lt;p&gt;Monty will power code-mode in Pydantic AI. Instead of making sequential tool calls, the LLM writes Python code that calls your tools as functions and Monty executes it safely.&lt;/p&gt;
    &lt;code&gt;from pydantic_ai import Agent
from pydantic_ai.toolsets.code_mode import CodeModeToolset
from pydantic_ai.toolsets.function import FunctionToolset
from typing_extensions import TypedDict


class WeatherResult(TypedDict):
    city: str
    temp_c: float
    conditions: str


toolset = FunctionToolset()


@toolset.tool
def get_weather(city: str) -&amp;gt; WeatherResult:
    """Get current weather for a city."""
    # your real implementation here
    return {'city': city, 'temp_c': 18, 'conditions': 'partly cloudy'}


@toolset.tool
def get_population(city: str) -&amp;gt; int:
    """Get the population of a city."""
    return {'london': 9_000_000, 'paris': 2_100_000, 'tokyo': 14_000_000}.get(
        city.lower(), 0
    )


toolset = CodeModeToolset(toolset)

agent = Agent(
    'anthropic:claude-sonnet-4-5',
    toolsets=[toolset],
)

result = agent.run_sync(
    'Compare the weather and population of London, Paris, and Tokyo.'
)
print(result.output)&lt;/code&gt;
    &lt;p&gt;There are generally two responses when you show people Monty:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Oh my god, this solves so many problems, I want it.&lt;/item&gt;
      &lt;item&gt;Why not X?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Where X is some alternative technology. Oddly often these responses are combined, suggesting people have not yet found an alternative that works for them, but are incredulous that there's really no good alternative to creating an entire Python implementation from scratch.&lt;/p&gt;
    &lt;p&gt;I'll try to run through the most obvious alternatives, and why there aren't right for what we wanted.&lt;/p&gt;
    &lt;p&gt;NOTE: all these technologies are impressive and have widespread uses, this commentary on their limitations for our use case should not be seen as a criticism. Most of these solutions were not conceived with the goal of providing an LLM sandbox, which is why they're not necessary great at it.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;Tech&lt;/cell&gt;
        &lt;cell role="head"&gt;Language completeness&lt;/cell&gt;
        &lt;cell role="head"&gt;Security&lt;/cell&gt;
        &lt;cell role="head"&gt;Start latency&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Setup complexity&lt;/cell&gt;
        &lt;cell role="head"&gt;File mounting&lt;/cell&gt;
        &lt;cell role="head"&gt;Snapshotting&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Monty&lt;/cell&gt;
        &lt;cell&gt;partial&lt;/cell&gt;
        &lt;cell&gt;strict&lt;/cell&gt;
        &lt;cell&gt;0.06ms&lt;/cell&gt;
        &lt;cell&gt;free&lt;/cell&gt;
        &lt;cell&gt;easy&lt;/cell&gt;
        &lt;cell&gt;easy&lt;/cell&gt;
        &lt;cell&gt;easy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Docker&lt;/cell&gt;
        &lt;cell&gt;full&lt;/cell&gt;
        &lt;cell&gt;good&lt;/cell&gt;
        &lt;cell&gt;195ms&lt;/cell&gt;
        &lt;cell&gt;free&lt;/cell&gt;
        &lt;cell&gt;intermediate&lt;/cell&gt;
        &lt;cell&gt;easy&lt;/cell&gt;
        &lt;cell&gt;intermediate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Pyodide&lt;/cell&gt;
        &lt;cell&gt;full&lt;/cell&gt;
        &lt;cell&gt;poor&lt;/cell&gt;
        &lt;cell&gt;2800ms&lt;/cell&gt;
        &lt;cell&gt;free&lt;/cell&gt;
        &lt;cell&gt;intermediate&lt;/cell&gt;
        &lt;cell&gt;easy&lt;/cell&gt;
        &lt;cell&gt;hard&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;starlark-rust&lt;/cell&gt;
        &lt;cell&gt;very limited&lt;/cell&gt;
        &lt;cell&gt;good&lt;/cell&gt;
        &lt;cell&gt;1.7ms&lt;/cell&gt;
        &lt;cell&gt;free&lt;/cell&gt;
        &lt;cell&gt;easy&lt;/cell&gt;
        &lt;cell&gt;not available?&lt;/cell&gt;
        &lt;cell&gt;impossible?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;sandboxing service&lt;/cell&gt;
        &lt;cell&gt;full&lt;/cell&gt;
        &lt;cell&gt;strict&lt;/cell&gt;
        &lt;cell&gt;1033ms&lt;/cell&gt;
        &lt;cell&gt;not free&lt;/cell&gt;
        &lt;cell&gt;intermediate&lt;/cell&gt;
        &lt;cell&gt;hard&lt;/cell&gt;
        &lt;cell&gt;intermediate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;YOLO Python&lt;/cell&gt;
        &lt;cell&gt;full&lt;/cell&gt;
        &lt;cell&gt;non-existent&lt;/cell&gt;
        &lt;cell&gt;0.1ms / 30ms&lt;/cell&gt;
        &lt;cell&gt;free&lt;/cell&gt;
        &lt;cell&gt;easy&lt;/cell&gt;
        &lt;cell&gt;easy / scary&lt;/cell&gt;
        &lt;cell&gt;hard&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See ./scripts/startup_performance.py for the script used to calculate the startup performance numbers.&lt;/p&gt;
    &lt;p&gt;Details on each row below:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language completeness: No classes (yet), limited stdlib, no third-party libraries&lt;/item&gt;
      &lt;item&gt;Security: Explicitly controlled filesystem, network, and env access, strict limits on execution time and memory usage&lt;/item&gt;
      &lt;item&gt;Start latency: Starts in microseconds&lt;/item&gt;
      &lt;item&gt;Setup complexity: just &lt;code&gt;pip install pydantic-monty&lt;/code&gt;or&lt;code&gt;npm install @pydantic/monty&lt;/code&gt;, ~4.5MB download&lt;/item&gt;
      &lt;item&gt;File mounting: Strictly controlled, see #85&lt;/item&gt;
      &lt;item&gt;Snapshotting: Monty's pause and resume functionality with &lt;code&gt;dump()&lt;/code&gt;and&lt;code&gt;load()&lt;/code&gt;makes it trivial to pause, resume and fork execution&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language completeness: Full CPython with any library&lt;/item&gt;
      &lt;item&gt;Security: Process and filesystem isolation, network policies, but container escapes exist, memory limitation is possible&lt;/item&gt;
      &lt;item&gt;Start latency: Container startup overhead (~195ms measured)&lt;/item&gt;
      &lt;item&gt;Setup complexity: Requires Docker daemon, container images, orchestration, &lt;code&gt;python:3.14-alpine&lt;/code&gt;is 50MB - docker can't be installed from PyPI&lt;/item&gt;
      &lt;item&gt;File mounting: Volume mounts work well&lt;/item&gt;
      &lt;item&gt;Snapshotting: Possible with durable execution solutions like Temporal, or snapshotting an image and saving it as a Docker image.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language completeness: Full CPython compiled to WASM, almost all libraries available&lt;/item&gt;
      &lt;item&gt;Security: Relies on browser/WASM sandbox - not designed for server-side isolation, python code can run arbitrary code in the JS runtime, only deno allows isolation, memory limits are hard/impossible to enforce with deno&lt;/item&gt;
      &lt;item&gt;Start latency: WASM runtime loading is slow (~2800ms cold start)&lt;/item&gt;
      &lt;item&gt;Setup complexity: Need to load WASM runtime, handle async initialization, pyodide NPM package is ~12MB, deno is ~50MB - Pyodide can't be called with just PyPI packages&lt;/item&gt;
      &lt;item&gt;File mounting: Virtual filesystem via browser APIs&lt;/item&gt;
      &lt;item&gt;Snapshotting: Possible with durable execution solutions like Temporal presumably, but hard&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See starlark-rust.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language completeness: Configuration language, not Python - no classes, exceptions, async&lt;/item&gt;
      &lt;item&gt;Security: Deterministic and hermetic by design&lt;/item&gt;
      &lt;item&gt;Start latency: runs embedded in the process like Monty, hence impressive startup time&lt;/item&gt;
      &lt;item&gt;Setup complexity: Usable in python via starlark-pyo3&lt;/item&gt;
      &lt;item&gt;File mounting: No file handling by design AFAIK?&lt;/item&gt;
      &lt;item&gt;Snapshotting: Impossible AFAIK?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Services like Daytona, E2B, Modal.&lt;/p&gt;
    &lt;p&gt;There are similar challenges, more setup complexity but lower network latency for setting up your own sandbox setup with k8s.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language completeness: Full CPython with any library&lt;/item&gt;
      &lt;item&gt;Security: Professionally managed container isolation&lt;/item&gt;
      &lt;item&gt;Start latency: Network round-trip and container startup time. I got ~1s cold start time with Daytona EU from London, Daytona advertise sub 90ms latency, presumably that's for an existing container, not clear if it includes network latency&lt;/item&gt;
      &lt;item&gt;Cost: Pay per execution or compute time&lt;/item&gt;
      &lt;item&gt;Setup complexity: API integration, auth tokens - fine for startups but generally a non-start for enterprises&lt;/item&gt;
      &lt;item&gt;File mounting: Upload/download via API calls&lt;/item&gt;
      &lt;item&gt;Snapshotting: Possible with durable execution solutions like Temporal, also the services offer some solutions for this, I think based con docker containers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Running Python directly via &lt;code&gt;exec()&lt;/code&gt; (~0.1ms) or subprocess (~30ms).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language completeness: Full CPython with any library&lt;/item&gt;
      &lt;item&gt;Security: None - full filesystem, network, env vars, system commands&lt;/item&gt;
      &lt;item&gt;Start latency: Near-zero for &lt;code&gt;exec()&lt;/code&gt;, ~30ms for subprocess&lt;/item&gt;
      &lt;item&gt;Setup complexity: None&lt;/item&gt;
      &lt;item&gt;File mounting: Direct filesystem access (that's the problem)&lt;/item&gt;
      &lt;item&gt;Snapshotting: Possible with durable execution solutions like Temporal&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46918254</guid><pubDate>Fri, 06 Feb 2026 21:16:36 +0000</pubDate></item><item><title>Show HN: Look Ma, No Linux: Shell, App Installer, Vi, Cc on ESP32-S3 / BreezyBox</title><link>https://github.com/valdanylchuk/breezydemo</link><description>&lt;doc fingerprint="23f693d834a59b94"&gt;
  &lt;main&gt;
    &lt;p&gt;This is a demo for how you can turn an ESP32-S3 microcontroller into a tiny instant-on PC with its own shell, editor, compiler, and online apps installer. Something like Raspberry Pi, minus the overhead of a full server/desktop grade OS. I think ESP32 is underrated in hobby maker community for this PC-like use case. This demo uses BreezyBox, my mini-shell ESP-IDF component.&lt;/p&gt;
    &lt;p&gt;First of all, seeing is believing (click to watch the video):&lt;/p&gt;
    &lt;p&gt;It started as a "cyberdeck" style crafting project. Then I got carried away with the software part. I chose ESP32-S3 for the base platform. It has the nostalgic appeal of the DOS era PCs, with similar resources, and elbow-deep-in-bytes coding experience, plus modern wireless comms.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;ESP32-S3 can do everything those PCs did and more, but that is inconvenient out of the box, because that is not the commercial use case it is positioned for. It also forces away the code bloat. If you are like me, and love small elegant things, and technology that punches way above its weight, you ought to try it!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So anyway, I decided to try and package some key missing parts: a basic vterm, the current working directory (CWD) tracking, a few familiar UNIX-like commands, and an app installer. Believe it or not, the rest is already there in ESP-IDF components, including the elf_loader with dynamic linking.&lt;/p&gt;
    &lt;p&gt;The result is called "BreezyBox", by analogy with the BusyBox commands suite. The name is just a light joke, it is not meant to be a full clone. You can import it with one command in your ESP-IDF project, and if you have some stdio going, even at "Hello World" level, it should mostly just work. I call it a "mini shell", a na√Øve user might call it an OS (it is not, it runs on FreeRTOS), and you can also call it the userland layer.&lt;/p&gt;
    &lt;p&gt;The BreezyBox component leaves the display and other board configuration details to the user's firmware project, providing mainly the vterm/vfs features, and some shell commands. This particular example/demo project supports only one specific dev board: Waveshare ESP32-S3-Touch-LCD-7B (no affiliation). But you can see how all the parts connect, and adapt it to your display/board, or just copy some code snippets from here.&lt;/p&gt;
    &lt;p&gt;I suggest just fork it, clone it, and try to make it work on your board. Mine was about 40‚Ç¨; you can start with some random $10 two inch LCD S3 dev board if you like. Hint: LVGL text label control is the easiest path to stdout on LCD that works almost everywhere. You can also start with a headless board over USB console, that takes zero code, and gives you free ANSI codes in standard IDF Monitor in VSCode (or in Tabby).&lt;/p&gt;
    &lt;p&gt;You do not have to write your own font renderer like I did here; that was just to push past 30 FPS on a display slightly too large for this chip.&lt;/p&gt;
    &lt;p&gt;This is free software under MIT License.&lt;/p&gt;
    &lt;p&gt;The best help is currently more testing beyond "works on my computer", more shared examples and fun use cases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;More ELF apps ‚Äì see the examples at my breezyapps repo, they are super easy to follow. Even a carefully written stdlib C program with no platform-specific bits may work sometimes, also with some ANSI codes. But be sure to verify on the actual ESP32-S3: the memory is tight, the larger PSRAM requires alignment, and there are other limits and quirks. You can publish and install the apps using your own repo.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;More full example firmware repositories: for different boards, with different styles. Maybe you provide the basic LVGL text label example on some popular board. Maybe you prefer C++ to plain C. Maybe you embrace the GUI. Maybe you port some retro games. Maybe you even make it work on P4, or C6 (RISC-V, a completely different CPU). Maybe you attach some cool gadgets to it. Maybe you build an extra cool cyberdeck case. Or maybe you reproduce the exact same thing, and just share your setup experience and hands-on impressions.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It would be so cool to see more people using BreezyBox, and to have more ready-to-clone examples for everyone!&lt;/p&gt;
    &lt;p&gt;Have fun!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46918429</guid><pubDate>Fri, 06 Feb 2026 21:33:11 +0000</pubDate></item><item><title>OpenCiv3: Open-source, cross-platform reimagining of Civilization III</title><link>https://openciv3.org/</link><description>&lt;doc fingerprint="9c8fd0b95eb34b4b"&gt;
  &lt;main&gt;&lt;p&gt;OpenCiv3 (formerly known by the codename ‚ÄúC7‚Äù) is an open-source, cross-platform, mod-oriented, modernized reimagining of Civilization III by the fan community built with the Godot Engine and C#, with capabilities inspired by the best of the 4X genre and lessons learned from modding Civ3. Our vision is to make Civ3 as it could have been, rebuilt for today‚Äôs modders and players: removing arbitary limits, fixing broken features, expanding mod capabilities, and supporting modern graphics and platforms. A game that can go beyond C3C but retain all of its gameplay and content.&lt;/p&gt;&lt;p&gt;OpenCiv3 is under active development and currently in an early pre-alpha state. It is a rudimentary playable game but lacking many mechanics and late-game content, and errors are likely. Keep up with our development for the latest updates and opportunities to contribute!&lt;/p&gt;&lt;quote&gt;&lt;p&gt;NOTE: OpenCiv3 is not affiliated with civfanatics.com, Firaxis Games, BreakAway Games, Hasbro Interactive, Infogrames Interactive, Atari Interactive, or Take-Two Interactive Software. All trademarks are property of their respective owners.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;The OpenCiv3 team is pleased to announce the first preview release of the v0.3 ‚ÄúDutch‚Äù milestone. This is a major enhancement over the ‚ÄúCarthage‚Äù release, and our debut with standalone mode featuring placeholder graphics without the need for Civ3 media files. A local installation of Civ3 is still recommended for a more polished experience. See the release notes for a full list of new features in each version.&lt;/p&gt;&lt;p&gt;OpenCiv3 Dutch Preview 1 with the same game in Standalone mode (top) and with imported Civ3 graphics (bottom)&lt;/p&gt;&lt;p&gt;Download the appropriate zip file for your OS from the Dutch Preview 1 release&lt;/p&gt;&lt;p&gt;All official releases of OpenCiv3 along with more detailed release notes can be found on the GitHub releases page.&lt;/p&gt;&lt;p&gt;This is a Windows 64-bit executable. OpenCiv3 will look for a local installation of Civilization III in the Windows registry automatically, or you may use an environment variable to point to the files.&lt;/p&gt;&lt;code&gt;OpenCiv3.exe&lt;/code&gt;&lt;code&gt;CIV3_HOME&lt;/code&gt; pointing to it and restart OpenCiv3&lt;p&gt;This is an x86-64 Linux executable. You may use an environment variable to point to the files from a Civilization III installation. You can just copy or mount the top-level ‚ÄúSid Meier‚Äôs Civilization III Complete‚Äù (Sans ‚ÄúComplete‚Äù if your install was from pre-Complete CDs) folder and its contents to your Linux system, or install the game via Steam or GOG.&lt;/p&gt;&lt;code&gt;CIV3_HOME&lt;/code&gt; environment variable to point to the Civ3 files, e.g. &lt;code&gt;export CIV3_HOME="/path/to/civ3"&lt;/code&gt;&lt;code&gt;CIV3_HOME&lt;/code&gt;, run &lt;code&gt;OpenCiv3.x86_64&lt;/code&gt;&lt;code&gt;.profile&lt;/code&gt; or equivalent.&lt;p&gt;This is a universal 64-bit executable, so it should run on both Intel and M1 Macs. You may use an environment variable to point to the files from a Civilization III installation. You can just copy or mount the top-level ‚ÄúSid Meier‚Äôs Civilization III Complete‚Äù (Sans ‚ÄúComplete‚Äù if your install was from pre-Complete CDs) folder and its contents to your Mac system, or install the game via Steam or GOG.&lt;/p&gt;&lt;code&gt;OpenCiv3.app&lt;/code&gt; and a json file will appear&lt;code&gt;OpenCiv3.app&lt;/code&gt; it will tell you it‚Äôs damaged and try to trash it; it is not damaged&lt;code&gt;xattr -cr /path/to/OpenCiv3.app&lt;/code&gt;; you can avoid typing the path out by typing &lt;code&gt;xattr -cr &lt;/code&gt; and then dragging the &lt;code&gt;OpenCiv3.app&lt;/code&gt; icon onto the terminal window&lt;code&gt;CIV3_HOME&lt;/code&gt; environment variable to point to the Civ3 files, e.g. &lt;code&gt;export CIV3_HOME="/path/to/civ3"&lt;/code&gt;&lt;code&gt;CIV3_HOME&lt;/code&gt;, run &lt;code&gt;OpenCiv3.app&lt;/code&gt; with &lt;code&gt;open /path/to/OpenCiv3.app&lt;/code&gt;, or again just type &lt;code&gt;open &lt;/code&gt; and drag the OpenCiv3 icon onto the terminal window and press enter&lt;code&gt;xattr -cr /path/to/OpenCiv3.app&lt;/code&gt; to enable running it.&lt;code&gt;c7-static-map-save.json&lt;/code&gt; or open a Civ3 SAV file to open that map&lt;quote&gt;&lt;p&gt;¬© OpenCiv3 contributors. OpenCiv3 is free and open source software released under the MIT License.&lt;/p&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46918612</guid><pubDate>Fri, 06 Feb 2026 21:51:23 +0000</pubDate></item><item><title>Show HN: R3forth, a ColorForth-inspired language with a tiny VM</title><link>https://github.com/phreda4/r3</link><description>&lt;doc fingerprint="8dc25b38833a72d0"&gt;
  &lt;main&gt;
    &lt;p&gt;A Minimalist, Self-Hosted Stack Machine Environment&lt;/p&gt;
    &lt;p&gt;r3forth is a programming language and environment inspired by ColorForth and the Forth philosophy. It‚Äôs designed to be a complete, self-contained system that balances extreme minimalism with practical creative power.&lt;/p&gt;
    &lt;p&gt;R3 can load and call procedures from any dynamic library (.DLL in windows) or (.SO in linux) the distro use SDL2 library for make games.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ultra-Minimalist VM: A highly portable, lightweight core (~40kb) written in C. It‚Äôs designed for simplicity and speed, currently supporting Windows and Linux: r3evm.&lt;/item&gt;
      &lt;item&gt;Zero Bloat Philosophy: No massive standard libraries or complex toolchains. It‚Äôs just the core VM, the stack, and your code.&lt;/item&gt;
      &lt;item&gt;High Performance &amp;amp; Native Ambitions: Despite running on a VM, r3 is architected for speed. It features a self-hosted compiler (currently for Windows) written entirely in r3forth, laying the groundwork for future direct-to-metal implementations.&lt;/item&gt;
      &lt;item&gt;Rich Ecosystem: On top of this minimal core, r3 provides a powerful suite of libraries for:&lt;/item&gt;
      &lt;item&gt;Graphics &amp;amp; 2D: Sprites, tilemaps, fonts, animations, and stack-based sprites.&lt;/item&gt;
      &lt;item&gt;Advanced Logic: 3D engine, collision hash, and TUI/Immediate Mode GUI (immgui).&lt;/item&gt;
      &lt;item&gt;Tooling: Integrated editors and a growing collection of games and demos.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;r3 requires SDL2 development libraries.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install dependencies:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;sudo apt install libsdl2-dev libsdl2-ttf-dev libsdl2-image-dev libsdl2-mixer-dev
&lt;/code&gt;
    &lt;p&gt;2a. Run the precompiled binary:&lt;/p&gt;
    &lt;p&gt;Donwload the latest release(.zip)&lt;/p&gt;
    &lt;code&gt;chmod +x r3lin
./r3lin&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;p&gt;2b. Build and Run: If you want to build the VM from source (recommended for compatibility):&lt;/p&gt;
    &lt;code&gt;# Clone the VM core
git clone https://github.com/phreda4/r3evm
cd r3evm &amp;amp;&amp;amp; make
# Move the binary back to the main folder
mv r3lin ../ &amp;amp;&amp;amp; cd ..
./r3lin
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Donwload the latest release(.zip)&lt;/item&gt;
      &lt;item&gt;Extract and run &lt;code&gt;r3.exe&lt;/code&gt;. No installation required.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;r3 is flexible. You can use the built-in environment or stay in your favorite terminal/editor.&lt;/p&gt;
    &lt;p&gt;By default, running the binary without arguments loads the internal system.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Execution: Run &lt;code&gt;./r3lin&lt;/code&gt;(Linux) or&lt;code&gt;r3.exe&lt;/code&gt;(Windows).&lt;/item&gt;
      &lt;item&gt;Bootstrap: The system automatically loads &lt;code&gt;main.r3&lt;/code&gt;. This script acts as the entry point, scanning the&lt;code&gt;/r3&lt;/code&gt;folder to build the internal menu and tools.&lt;/item&gt;
      &lt;item&gt;The Environment: Inside, you have access to the built-in code editor, dictionary browser, and live-coding tools.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you prefer using Emacs, Vim or Notepad++, you can use r3 as a traditional compiler/interpreter.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create your script: Save your code with the &lt;code&gt;.r3&lt;/code&gt;extension (e.g.,&lt;code&gt;hello.r3&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Run it directly: Pass the filename as an argument:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;| linux
./r3lin hello.r3

| windows
r3 hello.r3
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Development Loop: r3 is designed for instant feedback. The VM starts, compiles, and executes your script in milliseconds.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;r3forth1.mp4&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;r3forth2.mp4&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Red box in the corner program&lt;/p&gt;
    &lt;code&gt;^r3/lib/sdl2gfx.r3

:main
	0 sdlcls
	$ff0000 sdlcolor
	10 10 100 100 sdlfrect
	sdlredraw
	sdlkey
	&amp;gt;esc&amp;lt; =? ( exit )
	drop ;
	
:
	"red box in the corner" 800 600 SDLinit
	'main SDLShow
	SDLquit 
	;
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;main.r3&lt;/code&gt;: The core startup script.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/r3&lt;/code&gt;: Contains all the code, the system libraries, the IDE code, and core tools, etc.. all in .r3 code&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/asm&lt;/code&gt;: Compiler folder, not used if you not invoke it.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/dll&lt;/code&gt;: In WIN you not install anything, the dll is here.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/doc&lt;/code&gt;: Documentation.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/media&lt;/code&gt;: graphics, sounds, models, font..etc&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/mem&lt;/code&gt;: use like static memory (for keep info when exit r3)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;main.xml&lt;/code&gt;: syntax coloring for notepad++&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;r3 is not just a language; it's a creative suite. Here is what you can find:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;head&gt;develop.mov&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;games.mov&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;demo.mov&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;opengl.mov&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In the /doc folder.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46918824</guid><pubDate>Fri, 06 Feb 2026 22:10:13 +0000</pubDate></item><item><title>Introducing the Developer Knowledge API and MCP Server</title><link>https://developers.googleblog.com/introducing-the-developer-knowledge-api-and-mcp-server/</link><description>&lt;doc fingerprint="b4629309983a5cc2"&gt;
  &lt;main&gt;&lt;p&gt;As the ecosystem of AI-powered developer tools‚Äîfrom agentic platforms like Antigravity to command-line interfaces like Gemini CLI‚Äîcontinues to expand, a critical challenge has emerged: how do we ensure these models have access to the most accurate, up-to-date documentation?&lt;/p&gt;&lt;p&gt;Large Language Models (LLMs) are only as good as the context they are given. When building with Google technology, developers need their AI assistants to know the latest Firebase features, the most recent Android API changes, and the current best practices for Google Cloud.&lt;/p&gt;&lt;p&gt;Today, we are excited to announce the public preview of the Developer Knowledge API and its associated Model Context Protocol (MCP) server. Together, these tools provide a canonical, machine-readable gateway to Google‚Äôs official developer documentation.&lt;/p&gt;&lt;p&gt;The Developer Knowledge API is designed to be the programmatic source of truth for Google‚Äôs public documentation. Instead of relying on potentially outdated training data or fragile web-scraping, developers can now search and retrieve Google developer documentation pages as Markdown.&lt;/p&gt;&lt;p&gt;Key features include:&lt;/p&gt;&lt;p&gt;Alongside the API, we are releasing an official Model Context Protocol (MCP) server. MCP is an open standard that enables AI assistants to safely and easily access external data sources.&lt;/p&gt;&lt;p&gt;By connecting the Developer Knowledge MCP server to your IDE or AI assistant, you give it the ability to "read" Google‚Äôs developer documentation. This enables more reliable features, such as:&lt;/p&gt;&lt;p&gt;The server is compatible with a wide range of popular assistants and tools, as described in the documentation.&lt;/p&gt;&lt;p&gt;You can begin using the Developer Knowledge API and MCP server today in public preview.&lt;/p&gt;&lt;code&gt;&lt;lb/&gt;gcloud beta services mcp enable developerknowledge.googleapis.com --project=PROJECT_ID&lt;lb/&gt;&lt;lb/&gt;&lt;/code&gt;&lt;code&gt;mcp_config.json&lt;/code&gt; or &lt;code&gt;settings.json&lt;/code&gt;). Detailed configuration steps for various AI assistants can be found in the documentation.&lt;p&gt;This preview release focuses on providing high-quality, unstructured Markdown. As we move toward general availability, we plan to add support for structured content such as specific code sample objects and API reference entities. We will expand the corpus to include more of Google's developer documentation and reduce re-indexing latency.&lt;/p&gt;&lt;p&gt;We can‚Äôt wait to see how you integrate official Google knowledge into your agentic workflows and developer tools. Check out the full documentation to dive deeper, and let us know what you build!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46919824</guid><pubDate>Fri, 06 Feb 2026 23:58:53 +0000</pubDate></item><item><title>I'm going to cure my girlfriend's brain tumor</title><link>https://andrewjrod.substack.com/p/im-going-to-cure-my-girlfriends-brain</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46920248</guid><pubDate>Sat, 07 Feb 2026 01:05:59 +0000</pubDate></item><item><title>WebView performance significantly slower than PWA</title><link>https://issues.chromium.org/issues/40817676</link><description>&lt;doc fingerprint="732bc1ae2d485202"&gt;
  &lt;main&gt;
    &lt;p&gt;Sign in&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46920273</guid><pubDate>Sat, 07 Feb 2026 01:10:00 +0000</pubDate></item><item><title>Why I Joined OpenAI</title><link>https://www.brendangregg.com/blog/2026-02-07/why-i-joined-openai.html</link><description>&lt;doc fingerprint="3503545d39a5069f"&gt;
  &lt;main&gt;
    &lt;p&gt;The staggering and fast-growing cost of AI datacenters is a call for performance engineering like no other in history; it's not just about saving costs ‚Äì it's about saving the planet. I have joined OpenAI to work on this challenge directly, with an initial focus on ChatGPT performance. The scale is extreme and the growth is mind-boggling. As a leader in datacenter performance, I've realized that performance engineering as we know it may not be enough ‚Äì I'm thinking of new engineering methods so that we can find bigger optimizations than we have before, and find them faster. It's the opportunity of a lifetime and, unlike in mature environments of scale, it feels as if there are no obstacles ‚Äì no areas considered too difficult to change. Do anything, do it at scale, and do it today.&lt;/p&gt;
    &lt;p&gt;Why OpenAI exactly? I had talked to industry experts and friends who recommended several companies, especially OpenAI. However, I was still a bit cynical about AI adoption. Like everyone, I was being bombarded with ads by various companies to use AI, but I wondered: was anyone actually using it? Everyday people with everyday uses? One day during a busy period of interviewing, I realized I needed a haircut (as it happened, it was the day before I was due to speak with Sam Altman).&lt;/p&gt;
    &lt;p&gt;Mia the hairstylist got to work, and casually asked what I do for a living. "I'm an Intel fellow, I work on datacenter performance." Silence. Maybe she didn't know what datacenters were or who Intel was. I followed up: "I'm interviewing for a new job to work on AI datacenters." Mia lit up: "Oh, I use ChatGPT all the time!" While she was cutting my hair √¢ which takes a while √¢ she told me about her many uses of ChatGPT. (I, of course, was a captive audience.) She described uses I hadn't thought of, and I realized how ChatGPT was becoming an essential tool for everyone. Just one example: She was worried about a friend who was travelling in a far-away city, with little timezone overlap when they could chat, but she could talk to ChatGPT anytime about what the city was like and what tourist activities her friend might be doing, which helped her feel connected. She liked the memory feature too, saying it was like talking to a person who was living there.&lt;/p&gt;
    &lt;p&gt;I had previously chatted to other random people about AI, including a realtor, a tax accountant, and a part-time beekeeper. All told me enthusiastically about their uses of ChatGPT; the beekeeper, for example, uses it to help with small business paperwork. My wife was already a big user, and I was using it more and more, e.g. to sanity-check quotes from tradespeople. Now my hairstylist, who recognized ChatGPT as a brand more readily than she did Intel, was praising the technology and teaching me about it. I stood on the street after my haircut and let sink in how big this was, how this technology has become an essential aide for so many, how I could lead performance efforts and help save the planet. Joining OpenAI might be the biggest opportunity of my lifetime.&lt;/p&gt;
    &lt;p&gt;It's nice to work on something big that many people recognize and appreciate. I felt this when working at Netflix, and I'd been missing that human connection when I changed jobs. But there are other factors to consider beyond a well-known product: what's my role, who am I doing it with, and what is the compensation?&lt;/p&gt;
    &lt;p&gt;I ended up having 26 interviews and meetings (of course I kept a log) with various AI tech giants, so I learned a lot about the engineering work they are doing and the engineers who do it. The work itself reminds me of Netflix cloud engineering: huge scale, cloud computing challenges, fast-paced code changes, and freedom for engineers to make an impact. Lots of very interesting engineering problems across the stack. It's not just GPUs, it's everything.&lt;/p&gt;
    &lt;p&gt;The engineers I met were impressive: the AI giants have been very selective, to the point that I wasn't totally sure I'd pass the interviews myself. Of the companies I talked to, OpenAI had the largest number of talented engineers I already knew, including former Netflix colleagues such as Vadim who was encouraging me to join. At Netflix, Vadim would bring me performance issues and watch over my shoulder as I debugged and fixed them. It's a big plus to have someone at a company who knows you well, knows the work, and thinks you'll be good at the work.&lt;/p&gt;
    &lt;p&gt;Some people may be excited by what it means for OpenAI to hire me, a well known figure in computer performance, and of course I'd like to do great things. But to be fair on my fellow staff, there are many performance engineers already at OpenAI, including veterans I know from the industry, and they have been busy finding important wins. I'm not the first, I'm just the latest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building Orac&lt;/head&gt;
    &lt;p&gt;AI was also an early dream of mine. As a child I was a fan of British SciFi, including Blake's 7 (1978-1981) which featured a sarcastic, opinionated supercomputer named Orac. Characters could talk to Orac and ask it to do research tasks. Orac could communicate with all other computers in the universe, delegate work to them, and control them (this was very futuristic in 1978, pre-Internet as we know it).&lt;/p&gt;
    &lt;p&gt;Orac was considered the most valuable thing in the Blake's 7 universe, and by the time I was a university engineering student I wanted to build Orac. So I started developing my own natural language processing software. I didn't get very far, though: main memory at the time wasn't large enough to store an entire dictionary plus metadata. I visited a PC vendor with my requirements and they laughed, telling me to buy a mainframe instead. I realized I needed it to distinguish hot versus cold data and leave cold data on disk, and maybe I should be using a database√¢¬¶ and that was about where I left that project.&lt;/p&gt;
    &lt;p&gt;Last year I started using ChatGPT, and wondered if it knew about Blake's 7 and Orac. So I asked:&lt;/p&gt;
    &lt;p&gt;ChatGPT's response nails the character. I added it to Settings-&amp;gt;Personalization-&amp;gt;Custom Instructions, and now it always answers as Orac. I love it. (There's also surprising news for Blake's 7 fans: A reboot was just announced!)&lt;/p&gt;
    &lt;head rend="h2"&gt;What's next for me&lt;/head&gt;
    &lt;p&gt;I am now a Member of Technical Staff for OpenAI, working remotely from Sydney, Australia, and reporting to Justin Becker. The team I've joined is ChatGPT performance engineering, and I'll be working with the other performance engineering teams at the company. One of my first projects is a multi-org strategy for improving performance and reducing costs.&lt;/p&gt;
    &lt;p&gt;There's so many interesting things to work on, things I have done before and things I haven't. I'm already using Codex for more than just coding. Will I be doing more eBPF, Ftrace, PMCs? I'm starting with OpenAI's needs and seeing where that takes me; but given those technologies are proven for finding datacenter performance wins, it seems likely -- I can lead the way. (And if everything I've described here sounds interesting to you, OpenAI is hiring.)&lt;/p&gt;
    &lt;p&gt;I was at Linux Plumber's Conference in Toyko in December, just after I announced leaving Intel, and dozens of people wanted to know where I was going next and why. I thought I'd write this blog post to answer everyone at once. I also need to finish part 2 of hiring a performance engineering team (it was already drafted before I joined OpenAI). I haven't forgotten.&lt;/p&gt;
    &lt;p&gt;It took months to wrap up my prior job and start at OpenAI, so I was due for another haircut. I thought it'd be neat to ask Mia about ChatGPT now that I work on it, then realized it had been months and she could have changed her mind. I asked nervously: "Still using ChatGPT?". Mia responded confidently: "twenty-four seven!"&lt;/p&gt;
    &lt;p&gt;I checked with Mia, she was thrilled to be mentioned in my post. This is also a personal post: no one asked me to write this.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46920487</guid><pubDate>Sat, 07 Feb 2026 01:45:04 +0000</pubDate></item><item><title>Female Asian Elephant Calf Born at the Smithsonian National Zoo</title><link>https://www.si.edu/newsdesk/releases/female-asian-elephant-calf-born-smithsonians-national-zoo-and-conservation?user_id=66c4bf745d78644b3aa57b08&amp;utm_medium=email&amp;utm_placement=newsletter&amp;utm_source=join1440</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46920773</guid><pubDate>Sat, 07 Feb 2026 02:35:49 +0000</pubDate></item></channel></rss>