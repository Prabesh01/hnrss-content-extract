<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 29 Oct 2025 18:47:23 +0000</lastBuildDate><item><title>From VS Code to Helix</title><link>https://ergaster.org/posts/2025/10/29-vscode-to-helix/</link><description>&lt;doc fingerprint="7708325733a03a9d"&gt;
  &lt;main&gt;
    &lt;p&gt;I created the website you’re reading with VS Code. Behind the scenes I use Astro, a static site generator that gets out of the way while providing nice conveniences.&lt;/p&gt;
    &lt;p&gt;Using VS Code was a no-brainer: everyone in the industry seems to at least be familiar with it, every project can be opened with it, and most projects can get enhancements and syntactic helpers in a few clicks. In short: VS Code is free, easy to use, and widely adopted.&lt;/p&gt;
    &lt;p&gt;A Rustacean colleague kept singing Helix’s praises. I discarded it because he’s much smarter than I am, and I only ever use vim when I need to fiddle with files on a server. I like when things “Just Work” and didn’t want to bother learning how to use Helix nor how to configure it.&lt;/p&gt;
    &lt;p&gt;Today it has become my daily driver. Why did I change my mind? What was preventing me from using it before? And how difficult was it to get there?&lt;/p&gt;
    &lt;head rend="h2"&gt;Automation is a double-edged sword&lt;/head&gt;
    &lt;p&gt;Automation and technology make work easier, this is why we produce technology in the first place. But it also means you grow more dependent on the tech you use. If the tech is produced transparently by an international team or a team you trust, it’s fine. But if it’s produced by a single large entity that can screw you over, it’s dangerous.&lt;/p&gt;
    &lt;p&gt;VS Code might be open source, but in practice it’s produced by Microsoft. Microsoft has a problematic relationship to consent and is shoving AI products down everyone’s throat. I’d rather use tools that respect me and my decisions, and I’d rather not get my tools produced by already monopolistic organizations.&lt;/p&gt;
    &lt;p&gt;Microsoft is also based in the USA, and the political climate over there makes me want to depend as little as possible on American tools. I know that’s a long, uphill battle, but we have to start somewhere.&lt;/p&gt;
    &lt;p&gt;I’m not advocating for a ban against American tech in general, but for more balance in our supply chain. I’m also not advocating for European tech either: I’d rather get open source tools from international teams competing in a race to the top, rather than from teams in a single jurisdiction. What is happening in the USA could happen in Europe too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why I feared using Helix&lt;/head&gt;
    &lt;p&gt;I’ve never found vim particularly pleasant to use but it’s everywhere, so I figured I might just get used to it. But one of the things I never liked about vim is the number of moving pieces. By default, vim and neovim are very bare bones. They can be extended and completely modified with plugins, but I really don’t like the idea of having extremely customize tools.&lt;/p&gt;
    &lt;p&gt;I’d rather have the same editor as everyone else, with a few knobs for minor preferences. I am subject to choice paralysis, so making me configure an editor before I’ve even started editing is the best way to tank my productivity.&lt;/p&gt;
    &lt;p&gt;When my colleague told me about Helix, two things struck me as improvements over vim.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Helix’s philosophy is that everything should work out of the box. There are a few configs and themes, but everything should work similarly from one Helix to another. All the language-specific logic is handled in Language Servers that implement the Language Server Protocol standard.&lt;/item&gt;
      &lt;item&gt;In Helix, first you select text, and then you perform operations onto it. So you can visually tell what is going to be changed before you apply the change. It fits my mental model much better.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But there are major drawbacks to Helix too:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;After decades of vim, I was scared to re-learn everything. In practice this wasn’t a problem at all because of the very visual way Helix works.&lt;/item&gt;
      &lt;item&gt;VS Code “Just Works”, and Helix sounded like more work than the few clicks from VS Code’s extension store. This is true, but not as bad as I had anticipated.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After a single week of usage, Helix was already very comfortable to navigate. After a few weeks, most of the wrinkles have been ironed out and I use it as my primary editor. So how did I overcome those fears?&lt;/p&gt;
    &lt;head rend="h2"&gt;What Helped&lt;/head&gt;
    &lt;head rend="h3"&gt;Just Do It&lt;/head&gt;
    &lt;p&gt;I tried Helix. It can sound silly, but the very first step to get into Helix was not to overthink it. I just installed it on my mac with &lt;code&gt;brew install helix&lt;/code&gt; and gave it a go. I was not too familiar with it, so I looked up the official documentation and noticed there was a tutorial.&lt;/p&gt;
    &lt;p&gt;This tutorial alone is what convinced me to try harder. It’s an interactive and well written way to learn how to move and perform basic operations in Helix. I quickly learned how to move around, select things, surround them with braces or parenthesis. I could see what I was about to do before doing it. This has been epiphany. Helix just worked the way I wanted.&lt;/p&gt;
    &lt;p&gt;Better: I could get things done faster than in VS Code after a few minutes of learning. Being a lazy person, I never bothered looking up VS Code shortcuts. Because the learning curve for Helix is slightly steeper, you have to learn those shortcuts that make moving around feel so easy.&lt;/p&gt;
    &lt;p&gt;Not only did I quickly get used to Helix key bindings: my vim muscle-memory didn’t get in the way at all!&lt;/p&gt;
    &lt;head rend="h3"&gt;Better docs&lt;/head&gt;
    &lt;p&gt;The built-in tutorial is a very pragmatic way to get started. You get results fast, you learn hands on, and it’s not that long. But if you want to go further, you have to look for docs. Helix has officials docs. They seem to be fairly complete, but they’re also impenetrable as a new user. They focus on what the editor supports and not on what I will want to do with it.&lt;/p&gt;
    &lt;p&gt;After a bit of browsing online, I’ve stumbled upon this third-party documentation website. The domain didn’t inspire me a lot of confidence, but the docs are really good. They are clearly laid out, use-case oriented, and they make the most of Astro Starlight to provide a great reading experience. The author tried to upstream these docs, but that won’t happen. It looks like they are upstreaming their docs to the current website. I hope this will improve the quality of upstream docs eventually.&lt;/p&gt;
    &lt;p&gt;After learning the basics and finding my way through the docs, it was time to ensure Helix was set up to help me where I needed it most.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting the most of Markdown and Astro in Helix&lt;/head&gt;
    &lt;p&gt;In my free time, I mostly use my editor for three things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Write notes in markdown&lt;/item&gt;
      &lt;item&gt;Tweak my website with Astro&lt;/item&gt;
      &lt;item&gt;Edit yaml to faff around my Kubernetes cluster&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Helix is a “stupid” text editor. It doesn’t know much about what you’re typing. But it supports Language Servers that implement the Language Server Protocol. Language Servers understand the document you’re editing. They explain to Helix what you’re editing, whether you’re in a TypeScript function, typing a markdown link, etc. With that information, Helix and the Language Server can provide code completion hints, errors &amp;amp; warnings, and easier navigation in your code.&lt;/p&gt;
    &lt;p&gt;In addition to Language Servers, Helix also supports plugging code formatters. Those are pieces of software that will read the document and ensure that it is consistently formatted. It will check that all indentations use spaces and not tabs, that there is a consistent number of space when indenting, that brackets are on the same line as the function, etc. In short: it will make the code pretty.&lt;/p&gt;
    &lt;head rend="h3"&gt;Markdown&lt;/head&gt;
    &lt;p&gt;Markdown is not really a programming language, so it might seem surprising to configure a Language Server for it. But if you remember what we said earlier, Language Servers can provide code completion, which is useful when creating links for example. Marksman does exactly that!&lt;/p&gt;
    &lt;p&gt;Since Helix is pre-configured to use marksman for markdown files we only need to install marksman and make sure it’s in our &lt;code&gt;PATH&lt;/code&gt;. Installing it with homebrew is enough.&lt;/p&gt;
    &lt;p&gt;We can check that Helix is happy with it with the following command&lt;/p&gt;
    &lt;p&gt;But Language Servers can also help Helix display errors and warnings, and “code suggestions” to help fix the issues. It means Language Servers are a perfect fit for… grammar checkers! Several grammar checkers exist. The most notable are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LTEX+, the Language Server used by Language Tool. It supports several languages must is quite resource hungry.&lt;/item&gt;
      &lt;item&gt;Harper, a grammar checker Language Server developed by Automattic, the people behind WordPress, Tumblr, WooCommerce, Beeper and more. Harper only support English and its variants, but they intend to support more languages in the future.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I mostly write in English and want to keep a minimalistic setup. Automattic is well funded, and I’m confident they will keep working on Harper to improve it. Since grammar checker LSPs can easily be changed, I’ve decided to go with Harper for now.&lt;/p&gt;
    &lt;p&gt;To install it, homebrew does the job as always:&lt;/p&gt;
    &lt;p&gt;Then I edited my &lt;code&gt;~/.config/helix/languages.toml&lt;/code&gt; to add Harper as a secondary Language Server in addition to marksman&lt;/p&gt;
    &lt;p&gt;Finally I can add a markdown linter to ensure my markdown is formatted properly. Several options exist, and markdownlint is one of the most popular. My colleagues recommended the new kid on the block, a Blazing Fast equivalent: rumdl.&lt;/p&gt;
    &lt;p&gt;Installing rumdl was pretty simple on my mac. I only had to add the repository of the maintainer, and install rumdl from it.&lt;/p&gt;
    &lt;p&gt;After that I added a new &lt;code&gt;language-server&lt;/code&gt; to my &lt;code&gt;~/.config/helix/languages.toml&lt;/code&gt; and added it to the language servers to use for the markdown &lt;code&gt;language&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Since my website already contained a &lt;code&gt;.markdownlint.yaml&lt;/code&gt; I could import it to the rumdl format with&lt;/p&gt;
    &lt;p&gt;You might have noticed that I’ve added a little quality of life improvement: soft-wrap at 80 characters.&lt;/p&gt;
    &lt;p&gt;Now if you add this to your own &lt;code&gt;config.toml&lt;/code&gt; you will notice that the text is completely left aligned. This is not a problem on small screens, but it rapidly gets annoying on wider screens.&lt;/p&gt;
    &lt;p&gt;Helix doesn’t support centering the editor. There is a PR tackling the problem but it has been stale for most of the year. The maintainers are overwhelmed by the number of PRs making it their way, and it’s not clear if or when this PR will be merged.&lt;/p&gt;
    &lt;p&gt;In the meantime, a workaround exists, with a few caveats. It is possible to add spaces to the left gutter (the column with the line numbers) so it pushes the content towards the center of the screen.&lt;/p&gt;
    &lt;p&gt;To figure out how many spaces are needed, you need to get your terminal width with &lt;code&gt;stty&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;In my case, when in full screen, my terminal is 243 characters wide. I need to remove the content column with from it, and divide everything by 2 to get the space needed on each side. In my case for a 243 character wide terminal with a text width of 80 characters:&lt;/p&gt;
    &lt;p&gt;As is, I would add 203 spaces to my left gutter to push the rest of the gutter and the content to the right. But the gutter itself has a width of 4 characters, that I need to remove from the total. So I need to subtract them from the total, which leaves me with &lt;code&gt;76&lt;/code&gt; characters to add.&lt;/p&gt;
    &lt;p&gt;I can open my &lt;code&gt;~/.config/helix/config.toml&lt;/code&gt; to add a new key binding that will automatically add or remove those spaces from the left gutter when needed, to shift the content towards the center.&lt;/p&gt;
    &lt;p&gt;Now when in normal mode, pressing Space then t then z will add/remove the spaces. Of course this workaround only works when the terminal runs in full screen mode.&lt;/p&gt;
    &lt;head rend="h3"&gt;Astro&lt;/head&gt;
    &lt;p&gt;Astro works like a charm in VS Code. The team behind it provides a Language Server and a TypeScript plugin to enable code completion and syntax highlighting.&lt;/p&gt;
    &lt;p&gt;I only had to install those globally with&lt;/p&gt;
    &lt;p&gt;Now we need to add a few lines to our &lt;code&gt;~/.config/helix/languages.toml&lt;/code&gt; to tell it how to use the language server&lt;/p&gt;
    &lt;p&gt;We can check that the Astro Language Server can be used by helix with&lt;/p&gt;
    &lt;p&gt;I also like to get a formatter to automatically make my code consistent and pretty for me when I save a file. One of the most popular code formaters out there is Prettier. I’ve decided to go with the fast and easy formatter dprint instead.&lt;/p&gt;
    &lt;p&gt;I installed it with&lt;/p&gt;
    &lt;p&gt;Then in the projects I want to use dprint in, I do&lt;/p&gt;
    &lt;p&gt;I might edit the &lt;code&gt;dprint.json&lt;/code&gt; file to my liking. Finally, I configure Helix to use dprint globally for all Astro projects by appending a few lines in my &lt;code&gt;~/.config/helix/languages.toml&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;One final check, and I can see that Helix is ready to use the formatter as well&lt;/p&gt;
    &lt;head rend="h3"&gt;YAML&lt;/head&gt;
    &lt;p&gt;For yaml, it’s simple and straightforward: Helix is preconfigured to use &lt;code&gt;yaml-language-server&lt;/code&gt; as soon as it’s in the PATH. I just need to install it with&lt;/p&gt;
    &lt;head rend="h2"&gt;Is it worth it?&lt;/head&gt;
    &lt;p&gt;Helix really grew on me. I find it particularly easy and fast to edit code with it. It takes a tiny bit more work to get the language support than it does in VS Code, but it’s nothing insurmountable. There is a slightly steeper learning curve than for VS Code, but I consider it to be a good thing. It forced me to learn how to move around and edit efficiently, because there is no way to do it inefficiently. Helix remains intuitive once you’ve learned the basics.&lt;/p&gt;
    &lt;p&gt;I am a GNOME enthusiast, and I adhere to the same principles: I like when my apps work out of the box, and when I have little to do to configure them. This is a strong stance that often attracts a vocal opposition. I like products that follow those principles better than those who don’t.&lt;/p&gt;
    &lt;p&gt;With that said, Helix sometimes feels like it is maintained by one or two people who have a strong vision, but who struggle to onboard more maintainers. As of writing, Helix has more than 350 PRs open. Quite a few bring interesting features, but the maintainers don’t have enough time to review them.&lt;/p&gt;
    &lt;p&gt;Those 350 PRs mean there is a lot of energy and goodwill around the project. People are willing to contribute. Right now, all that energy is gated, resulting in frustration both from the contributors who feel like they’re working in the void, and the maintainers who feel like there at the receiving end of a fire hose.&lt;/p&gt;
    &lt;p&gt;A solution to make everyone happier without sacrificing the quality of the project would be to work on a Contributor Ladder. CHAOSS’ Dr Dawn Foster published a blog post about it, listing interesting resources at the end.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45746478</guid><pubDate>Wed, 29 Oct 2025 13:19:30 +0000</pubDate></item><item><title>Recreating a Homebrew Game System from 1987</title><link>https://alex-j-lowry.github.io/z80tvg.html</link><description>&lt;doc fingerprint="345a297f4904c8c5"&gt;
  &lt;main&gt;
    &lt;p&gt;The specifications are as follows:&lt;/p&gt;
    &lt;p&gt;Controller input and audio output are handled by either an Intel 8255 or Zilog Z80PIO I/O controller. There are two sockets on the PCB for either controller, depending on which is easier for you to obtain. These two ICs have to be controlled slightly differently by software, but it's possible to write games that are compatible with both, as demonstrated by the games written by Inufuto.&lt;/p&gt;
    &lt;p&gt;The controller interface is designed for two-button Sega Master System controllers and will also work with Mega Drive/Genesis controllers. Standard one-button joysticks will also work, aside from the lack of a second button.&lt;/p&gt;
    &lt;p&gt;The composite sync signal is generated with an EPROM, an unconventional method of simplifying the circuitry. Different ROMs have different data access times, so you may need to experiment with one or two models of ROM before you'll find one that produces a glitchless video signal, due to the high speed at which the raster generator steps through the ROM's address bus.&lt;/p&gt;
    &lt;p&gt;Fortunately, any size of ROM between 4KB (2732) and 64KB (27512) can be used, so long as the 4KB binary data file (available for download further down this page) is written to the upper 4KB of higher capacity ROMs. During testing, I found that a 150ns ROM worked well, while a 450ns ROM was too slow.&lt;/p&gt;
    &lt;p&gt;If the prospect of making a lot of cartridges doesn't appeal to you, I've designed a multi-cartridge that holds sixteen 32KB games on one 27C040 ROM. Game selection on the multi-cartridge is performed with DIP switches.&lt;/p&gt;
    &lt;p&gt;The maximum file size for games is 32KB, but I've designed an experimental bank-switching cartridge PCB (not tested yet!) that should allow games of up to 256KB to be accessed through two configurable 16KB page registers on the cartridge.&lt;/p&gt;
    &lt;p&gt;8255:&lt;/p&gt;
    &lt;p&gt;There's a selection of tools available for programming the Z80 TV Game in C:&lt;/p&gt;
    &lt;p&gt; Schematic - Console &lt;lb/&gt; PDF document, 941 KB &lt;/p&gt;
    &lt;p&gt; PCB Gerbers - Console &lt;lb/&gt; ZIP archive, 744 KB &lt;/p&gt;
    &lt;p&gt; KiCad Files - Console &lt;lb/&gt; ZIP archive, 1.33 MB - Useful if you want to make modifications to the PCB. Made with KiCad 9. &lt;/p&gt;
    &lt;p&gt; Interactive Bill of Materials - 32KB ROM Cartridge &lt;lb/&gt; HTML document, 338 KB &lt;/p&gt;
    &lt;p&gt; Schematic - 32KB ROM Cartridge &lt;lb/&gt; PDF document, 127 KB &lt;/p&gt;
    &lt;p&gt; PCB Gerbers - 32KB ROM Cartridge &lt;lb/&gt; ZIP archive, 170 KB &lt;/p&gt;
    &lt;p&gt; KiCad Files - 32KB ROM Cartridge &lt;lb/&gt; ZIP archive, 532 KB - Useful if you want to make modifications to the PCB. Made with KiCad 9. &lt;/p&gt;
    &lt;p&gt; Interactive Bill of Materials - 32KB x 16 Multi-Cartridge &lt;lb/&gt; HTML document, 350 KB &lt;/p&gt;
    &lt;p&gt; Schematic - 32KB x 16 Multi-Cartridge &lt;lb/&gt; PDF document, 151 KB &lt;/p&gt;
    &lt;p&gt; PCB Gerbers - 32KB x 16 Multi-Cartridge &lt;lb/&gt; ZIP archive, 191 KB &lt;/p&gt;
    &lt;p&gt; KiCad Files - 32KB x 16 Multi-Cartridge &lt;lb/&gt; ZIP archive, 564 KB - Useful if you want to make modifications to the PCB. Made with KiCad 9. &lt;/p&gt;
    &lt;p&gt; Interactive Bill of Materials - Experimental 256KB ROM Cartridge &lt;lb/&gt; HTML document, 316 KB &lt;/p&gt;
    &lt;p&gt; Schematic - Experimental 256KB ROM Cartridge &lt;lb/&gt; PDF document, 221 KB &lt;/p&gt;
    &lt;p&gt; PCB Gerbers - Experimental 256KB ROM Cartridge &lt;lb/&gt; ZIP archive, 209 KB - Please note that the 256KB cartridge hasn't yet been tested! &lt;/p&gt;
    &lt;p&gt; KiCad Files - Experimental 256KB ROM Cartridge &lt;lb/&gt; ZIP archive, 603 KB - Useful if you want to make modifications to the PCB. Made with KiCad 9. &lt;/p&gt;
    &lt;p&gt; Custom Fonts &lt;lb/&gt; ZIP archive, 8.90 MB - Custom fonts used for the KiCad files. Only needed if you want to modify these files. &lt;/p&gt;
    &lt;p&gt; Original Schematics &lt;lb/&gt; ZIP archive, 1.14 MB - Mr. Isizu's original schematics for the Z80 TV Game, with the 74LS122 timing circuit corrected. Includes the 1980's hand-drawn schematic, which has a different memory map to the 2000's CAD schematic that this PCB, emulators, C devtools, etc. are based on. &lt;/p&gt;
    &lt;p&gt; Game ROMs &lt;lb/&gt; ZIP archive, 922 KB - All the games I know to exist for the Z80 TV Game thus far. Includes two combined ROMs for those who would rather have all 26 games on 2 multi-cartridges. If you know of any games that aren't mentioned on this page (or you've written a new game), please let me know! My email address is on the home page. &lt;/p&gt;
    &lt;p&gt; 32KB Cartridge Dimensions &lt;lb/&gt; PDF document, 61.3 KB - Useful for designing a 3D printed cartridge enclosure. Note that the standard PCB thickness used by most manufacturers is 1.6mm. &lt;/p&gt;
    &lt;p&gt; 32KB x 16 Multi-Cartridge Dimensions &lt;lb/&gt; PDF document, 67.1 KB - Useful for designing a 3D printed cartridge enclosure. Note that the standard PCB thickness used by most manufacturers is 1.6mm. &lt;/p&gt;
    &lt;p&gt; Z80 TV Game Logo (1920 x 846) (Variant 1) &lt;lb/&gt; PNG image, 1.21 MB - The logo seen at the top of the page in full resolution. &lt;/p&gt;
    &lt;p&gt; Z80 TV Game Logo (1920 x 846) (Variant 2) &lt;lb/&gt; PNG image, 1.08 MB - The logo seen at the top of the page in full resolution. &lt;/p&gt;
    &lt;p&gt;Inufuto: Developer of Cate, a multi-platform compiler that can generate software for the Z80 TV Game. All 20 of the games he has created with it thus far have Z80 TV Game versions. Inufuto has also designed a PCB version of the Z80 TV Game that outputs VGA video via a Raspberry Pi Pico.&lt;/p&gt;
    &lt;p&gt;Takeda Toshiya: Developer of eZ80TVGAME, a Z80 TV Game emulator for Windows.&lt;/p&gt;
    &lt;p&gt;lsluk: Developer of vdmgr, a multi-platform emulator for Windows that supports the Z80 TV Game.&lt;/p&gt;
    &lt;p&gt;Last updated on Oct 26, 2025. &lt;lb/&gt;This page was first uploaded on Oct 26, 2025. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45746726</guid><pubDate>Wed, 29 Oct 2025 13:42:05 +0000</pubDate></item><item><title>Character.ai to bar children under 18 from using its chatbots</title><link>https://www.nytimes.com/2025/10/29/technology/characterai-underage-users.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45746844</guid><pubDate>Wed, 29 Oct 2025 13:52:31 +0000</pubDate></item><item><title>I made a 10¢ MCU Talk</title><link>https://www.atomic14.com/2025/10/29/CH32V003-talking</link><description>&lt;doc fingerprint="a50cd3b339220607"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;TLDR: Yes, you can fit about 7 seconds of audio into 16K of flash and still have room for code. And you can even play LPC encoded audio on a 10 cent MCU.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There’s quite a lot more detail in this video (and of course you can hear the audio!).&lt;/p&gt;
    &lt;p&gt;In the previous project, I had this ultra-cheap CH32V003 microcontroller playing simple tunes on a tiny SMD buzzer. It was just toggling a GPIO pin at musical note frequencies – 1-bit audio output – and it sounded surprisingly decent. That was a fun start, but now it’s time to push this little $0.10 MCU even further: can we make it actually talk?&lt;/p&gt;
    &lt;p&gt;Spoiler: Yes, we can! (well, there wouldn’t be much of a blog post if we couldn’t) This 8-pin RISC-V chip is now producing sampled audio data and spoken words. We’re really stretching the limits of what you can fit in 16 KB of flash.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Beeps to Actual Audio&lt;/head&gt;
    &lt;p&gt;Moving from simple beeps to real audio meant using the microcontroller’s PWM output as a rudimentary DAC. Instead of just on/off beeping, I’m driving a waveform at an 8 kHz sample rate using a high-frequency PWM on the output pin. The hardware is the same tiny board as before – but I’ve swapped the small SMD buzzer for a small speaker. The buzer works too, but it’s quieter and very tinny.&lt;/p&gt;
    &lt;p&gt;The sample I wanted to test with is just over 6 seconds in length - it’s the iconic “Open the pod bay doors HAL…” sequence from 2001.&lt;/p&gt;
    &lt;p&gt;If we keep this audio at 16-bit PCM, 8kHZ, we’d need about 96KB – way beyond our 16 KB flash! And remember, that 16 KB has to hold both the audio data and our playback code. Clearly some aggressive compression is required.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Format&lt;/cell&gt;
        &lt;cell role="head"&gt;Sample Rate&lt;/cell&gt;
        &lt;cell role="head"&gt;Bits/Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Fits in 16KB?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CD Quality&lt;/cell&gt;
        &lt;cell&gt;44.1 kHz&lt;/cell&gt;
        &lt;cell&gt;16-bit&lt;/cell&gt;
        &lt;cell&gt;529 KB&lt;/cell&gt;
        &lt;cell&gt;❌ 33× too big!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Phone Quality&lt;/cell&gt;
        &lt;cell&gt;16 kHz&lt;/cell&gt;
        &lt;cell&gt;16-bit&lt;/cell&gt;
        &lt;cell&gt;192 KB&lt;/cell&gt;
        &lt;cell&gt;❌ 12× too big!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Basic PCM&lt;/cell&gt;
        &lt;cell&gt;8 kHz&lt;/cell&gt;
        &lt;cell&gt;8-bit&lt;/cell&gt;
        &lt;cell&gt;48 KB&lt;/cell&gt;
        &lt;cell&gt;❌ 3× too big!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4-bit ADPCM (IMA)&lt;/cell&gt;
        &lt;cell&gt;8 kHz&lt;/cell&gt;
        &lt;cell&gt;4-bit&lt;/cell&gt;
        &lt;cell&gt;24 KB&lt;/cell&gt;
        &lt;cell&gt;❌ 1.5× too big&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;QOA (Quite OK Audio)&lt;/cell&gt;
        &lt;cell&gt;8 kHz&lt;/cell&gt;
        &lt;cell&gt;3.2-bit&lt;/cell&gt;
        &lt;cell&gt;19 KB&lt;/cell&gt;
        &lt;cell&gt;❌ Still too big!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;2-bit ADPCM&lt;/cell&gt;
        &lt;cell&gt;8 kHz&lt;/cell&gt;
        &lt;cell&gt;2-bit&lt;/cell&gt;
        &lt;cell&gt;12 KB&lt;/cell&gt;
        &lt;cell&gt;✅ Fits!&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;I considered a few encoding options for compressing the audio.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;8-bit PCM: Simply using 8-bit samples at 8 kHz cuts size in half (to ~47 KB for 6s), but that’s still about 3× too large for our flash.&lt;/item&gt;
      &lt;item&gt;4-bit ADPCM: Adaptive Differential PCM is a simple lossy compression that could quarter the size. In theory 6 seconds would be ~24 KB – much closer to fitting,&lt;/item&gt;
      &lt;item&gt;“Quite OK Audio” (QOA): This is nice codec that packs audio into about 3.2 bits per sample (roughly 1/5 the size of 16-bit PCM)&lt;/item&gt;
      &lt;item&gt;2-bit ADPCM: Going even further with ADPCM, using only 2 bits per sample gives a 4:1 compression relative to 8-bit audio – that’s 75% storage savings.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2-bit ADPCM is definitely the winner here. Our 6-second clip shrinks to under 12 KB, which comfortably fits in flash with room for code. This looked like the winner, provided the audio quality was acceptable. The decoder for 2-bit ADPCM is also very lightweight (my implementation compiled to under just over 1K of code - 1340 bytes!). It’s definitely low quality - but it actually sounds surprisingly ok.&lt;/p&gt;
    &lt;head rend="h2"&gt;How does 2-bit ADPCM work?&lt;/head&gt;
    &lt;p&gt;It’s actually a very simple algorithm. Both the encoder and decoder maintain a predicted signal value and a step size index into a predefined table. Each 2-bit code tells the decoder how to adjust the current prediction and the step size index. In essence, we’re coding the difference between the real audio and our prediction, with only four possible levels (since 2 bits gives 4 values). After each sample, the algorithm adapts: if the prediction error was large, we move to a bigger step size (to allow larger changes); if the error was small, we use a smaller step size for finer resolution. This adaptive step is what makes it ADPCM (Adaptive Differential PCM).&lt;/p&gt;
    &lt;p&gt;Our codes are as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;00&lt;/code&gt;(0): Go down by 1 step - subtract the step size from our current prediction&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;01&lt;/code&gt;(1): Go up by 1 step - add the step size to our current prediction&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;10&lt;/code&gt;(2): Go down by 2 steps - subtract the 2 x step size from our current prediction&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;11&lt;/code&gt;(3): Go up by 2 steps - add the 2 x step size to our current prediction&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even with this very high level of compression, the predicted waveform manages to track the original audio surprisingly well. The above graph shows a small snippet of the audio: the blue line is the original waveform and the yellow line is the ADPCM decoder’s output.&lt;/p&gt;
    &lt;p&gt;They’re not identical (and we wouldn’t expect them to be), but the general shape is preserved. When you play it back through the little speaker, it’s recognizable and surprisingly good.&lt;/p&gt;
    &lt;p&gt;To make my life easier, I built a quick conversion tool to encode WAV files into this 2-bit ADPCM format. The tool lets me drag-and-drop a WAV, and it gives you the files with the data that can ve dropped into the firmware code.&lt;/p&gt;
    &lt;head rend="h2"&gt;LPC Speech Synthesis&lt;/head&gt;
    &lt;p&gt;Six seconds of audio is cool, but what about longer phrases or even arbitrary speech? Storing anything much longer with raw or ADPCM audio would quickly fill the 16K of flash.&lt;/p&gt;
    &lt;p&gt;For my second experiment, I tried something different: instead of recorded waveform audio, I used an old-school speech synthesis approach. This leverages the fact that spoken language can be encoded very compactly by modeling the human voice, rather than storing the raw sound. Specifically, I integrated a library called Talkie.&lt;/p&gt;
    &lt;p&gt;Talkie is a software implementation of the Texas Instruments LPC speech synthesis architecture from the late 1970s. This was implemented in a variety of chips, most commonly the TMS5220 and TMS5100 speech chips.&lt;/p&gt;
    &lt;p&gt;These were used in things like the original Speak &amp;amp; Spell, arcade games like early Star Wars, and speech add-ons for home computers (e.g. the BBC Micro).&lt;/p&gt;
    &lt;p&gt;The Talkie library (originally by Peter Knight, later added to by Adafruit) comes with a big set of examples and vocabulary. It’s also possible to extract examples from old ROMs from arcade games.&lt;/p&gt;
    &lt;p&gt;Each phrase or word only takes a few hundred bytes or even less, so you can fit quite a lot of speech into a few kilobytes of flash. The trade-off is that the voice has a very computer-esque timbre – think of the Speak &amp;amp; Spell’s voice. It’s clearly synthetic, but still understandable.&lt;/p&gt;
    &lt;p&gt;To say custom sentences not in the library, you either concatenate the available words/phonemes (which can be clunky), or you need to generate new LPC data. The original tools for this are a bit obscure – there’s BlueWizard (a classic Mac app) and PythonWizard (a command-line tool with TK GUI) which can analyze WAV files and produce LPC data.&lt;/p&gt;
    &lt;p&gt;I gave both a try with some success (and a few headaches setting them up). In the end, I cheated a bit and used an AI coding assistant to help me create a streamlined online tool for this.&lt;/p&gt;
    &lt;p&gt;The result is a little web app where I can upload a recording of, say, my own voice, and it outputs the LPC data. It even lets me play back the synthesized voice in-browser to check it.&lt;/p&gt;
    &lt;p&gt;So there we have it – our 10¢ microcontroller now has a voice! By using 2-bit ADPCM compression, we can store short audio clips (up to around 8 seconds) even in 16 KB of flash, and play them back via PWM with decent fidelity.&lt;/p&gt;
    &lt;p&gt;And with the Talkie LPC speech synthesis, we can make the device “speak” lots of words and phrases with only a tiny memory footprint.&lt;/p&gt;
    &lt;p&gt;If you want to hear it for yourself, check out the video demo linked at the top of this post. In the video, you’ll see (and hear) the WarGames clip and the Star Wars quotes running on the hardware. It’s honestly amazing what these cheap little MCUs can do. We’re really pushing the boundaries of cheap hardware here.&lt;/p&gt;
    &lt;p&gt;You can find all my code on GitHub in this repository.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45747112</guid><pubDate>Wed, 29 Oct 2025 14:12:50 +0000</pubDate></item><item><title>Show HN: HUD-like live annotation and sketching app for macOS</title><link>https://draw.wrobele.com/</link><description>&lt;doc fingerprint="354456b7533f15ed"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Annotate, explain, create - anywhere on your screen&lt;/head&gt;&lt;p&gt;Draw Over It gives presenters, trainers, and any professional an always-ready overlay for live markups. Open it with a hotkey, sketch directly on top of any app, and jump back to work without leaving a trace.&lt;/p&gt;Mac App Store&lt;head rend="h2"&gt;Always-on overlay for live sessions&lt;/head&gt;&lt;p&gt;Stay in flow while you mark up anything on screen. Draw Over It floats above your desktop and hides with a single hotkey.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Overlay the canvas on any app instantly with the menu bar controls or just ââ¥âD combination.&lt;/item&gt;&lt;item&gt;Access the HUD toolkit easily with a right-click.&lt;/item&gt;&lt;item&gt;With just a click, blur everything else to keep attention on your key points.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Tools built for clear annotations&lt;/head&gt;&lt;p&gt;Summon the SwiftUI HUD with a right-click and reach pens, highlighters, shapes, blur, and session controls without leaving the overlay.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Swap between pens, highlighters, rectangles, and circles with one click.&lt;/item&gt;&lt;item&gt;Configure pen widths from 1â64 pt, opacity, fill modes, and color presets.&lt;/item&gt;&lt;item&gt;Use quick presets for Pen sizes, highlight box, and highlighter to stay in rhythm.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Capture your ideas close to the source&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Save the canvas at any time so you can get back to that state quickly.&lt;/item&gt;&lt;item&gt;Export the canvas state as transparent PNGs ready for sharing.&lt;/item&gt;&lt;item&gt;The entire application is available in 14 languages.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Switch tools, tweak width or opacity, and pick presets in one floating palette.&lt;/p&gt;&lt;p&gt;Easily annotate any document, presentation or codebase&lt;/p&gt;&lt;p&gt;Export your canvas to a PNG with a single click&lt;/p&gt;&lt;p&gt;Visualise your ideas close to the source&lt;/p&gt;&lt;p&gt;Easy to use tooling always at your fingertips&lt;/p&gt;&lt;head rend="h2"&gt;Frequently asked questions&lt;/head&gt;&lt;head rend="h3"&gt;How do I toggle the overlay?&lt;/head&gt;&lt;p&gt;Use ââ¥âD or the status bar menu. The overlay floats above every window until you hide it.&lt;/p&gt;&lt;head rend="h3"&gt;How do I open the tool HUD?&lt;/head&gt;&lt;p&gt;Right-click the overlay or press ââ¥âH. The HUD appears near your pointer for quick adjustments.&lt;/p&gt;&lt;head rend="h3"&gt;Can I erase or undo mistakes?&lt;/head&gt;&lt;p&gt;Hold Option to switch to the eraser or press ââ¥âZ to undo. Redo lives in the HUD and app menus.&lt;/p&gt;&lt;head rend="h3"&gt;Where are exports saved?&lt;/head&gt;&lt;p&gt;Transparent PNG exports live in ~/Library/Application Support/DrawOverIt/Exports inside the app sandbox.&lt;/p&gt;&lt;head rend="h3"&gt;Does the app remember my annotations?&lt;/head&gt;&lt;p&gt;Yes. Sessions persist between launches, and you can save or restore snapshots manually. Enable Ephemeral Canvas if you prefer a fresh slate every time.&lt;/p&gt;&lt;head rend="h3"&gt;Which macOS versions are supported?&lt;/head&gt;&lt;p&gt;Draw Over It targets macOS 13.5 or later with universal binaries for Apple Silicon and Intel.&lt;/p&gt;&lt;head rend="h2"&gt;Ready to draw over anything?&lt;/head&gt;&lt;p&gt;Try it yourself and see how easy visualising your ideas becomes!&lt;/p&gt;Mac App Store&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45747402</guid><pubDate>Wed, 29 Oct 2025 14:36:36 +0000</pubDate></item><item><title>Collins Aerospace: Sending text messages to the cockpit with test:test</title><link>https://www.ccc.de/en/disclosure/collins-aerospace-mit-test-test-textnachrichten-bis-ins-cockpit-senden</link><description>&lt;doc fingerprint="ef98aafde223bee7"&gt;
  &lt;main&gt;
    &lt;p&gt;Informed parties: RTX Corporation and Department of Defense Cyber Crime Center (on September 21, 2025)&lt;/p&gt;
    &lt;p&gt;Using the credentials test:test, it was possible to log in at the ARINC OpCenter Message Browser (Screenshot) as U.S. Navy Fleet Logistics Support Wing.&lt;/p&gt;
    &lt;p&gt;Via this web service, text messages can be sent to the cockpit. For obvious reasons, we did not try that. Sent messages could be viewed.&lt;/p&gt;
    &lt;p&gt;Unfortunately, RTX did not respond to our vulnerability report. The account was disabled.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45747804</guid><pubDate>Wed, 29 Oct 2025 15:07:20 +0000</pubDate></item><item><title>Hosting SQLite Databases on GitHub Pages (2021)</title><link>https://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/</link><description>&lt;doc fingerprint="3d0f8f5e6fa86b83"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Hosting SQLite databases on Github Pages&lt;/head&gt;&lt;p&gt;(or IPFS or any static file hoster)&lt;/p&gt;• Last Update&lt;p&gt;I was writing a tiny website to display statistics of how much sponsored content a Youtube creator has over time when I noticed that I often write a small tool as a website that queries some data from a database and then displays it in a graph, a table, or similar. But if you want to use a database, you either need to write a backend (which you then need to host and maintain forever) or download the whole dataset into the browser (which is not so great when the dataset is more than 10MB).&lt;/p&gt;&lt;p&gt;In the past when I’ve used a backend server for these small side projects at some point some external API goes down or a key expires or I forget about the backend and stop paying for whatever VPS it was on. Then when I revisit it years later, I’m annoyed that it’s gone and curse myself for relying on an external service - or on myself caring over a longer period of time.&lt;/p&gt;&lt;p&gt;Hosting a static website is much easier than a "real" server - there’s many free and reliable options (like GitHub, GitLab Pages, Netlify, etc), and it scales to basically infinity without any effort.&lt;/p&gt;&lt;p&gt;So I wrote a tool to be able to use a real SQL database in a statically hosted website!&lt;/p&gt;&lt;p&gt;Here’s a demo using the World Development Indicators dataset - a dataset with 6 tables and over 8 million rows (670 MiByte total).&lt;/p&gt;&lt;code&gt;select country_code, long_name from wdi_country limit 3;&lt;/code&gt;&lt;p&gt;As you can see, we can query the &lt;code&gt;wdi_country&lt;/code&gt; table while fetching only 1kB of data!&lt;/p&gt;&lt;p&gt;This is a full SQLite query engine. As such, we can use e.g. the SQLite JSON functions:&lt;/p&gt;&lt;code&gt;select json_extract(arr.value, '$.foo.bar') as bar
  from json_each('[{"foo": {"bar": 123}}, {"foo": {"bar": "baz"}}]') as arr&lt;/code&gt;&lt;p&gt;We can also register JS functions so they can be called from within a query. Here’s an example with a &lt;code&gt;getFlag&lt;/code&gt; function that gets the flag emoji for a country:&lt;/p&gt;&lt;code&gt;function getFlag(country_code) {
  // just some unicode magic
  return String.fromCodePoint(...Array.from(country_code||"")
    .map(c =&amp;gt; 127397 + c.codePointAt()));
}

await db.create_function("get_flag", getFlag)
return await db.query(`
  select long_name, get_flag("2-alpha_code") as flag from wdi_country
    where region is not null and currency_unit = 'Euro';
`)&lt;/code&gt;&lt;p&gt;Press the Run button to run the following demos. You can change the code in any way you like, though if you make a query too broad it will fetch large amounts of data ;)&lt;/p&gt;&lt;p&gt;Note that this website is 100% hosted on a static file hoster (GitHub Pages).&lt;/p&gt;&lt;p&gt;So how do you use a database on a static file hoster? Firstly, SQLite (written in C) is compiled to WebAssembly. SQLite can be compiled with emscripten without any modifications, and the sql.js library is a thin JS wrapper around the wasm code.&lt;/p&gt;&lt;p&gt;sql.js only allows you to create and read from databases that are fully in memory though - so I implemented a virtual file system that fetches chunks of the database with HTTP Range requests when SQLite tries to read from the filesystem: sql.js-httpvfs. From SQLite’s perspective, it just looks like it’s living on a normal computer with an empty filesystem except for a file called &lt;code&gt;/wdi.sqlite3&lt;/code&gt; that it can read from. Of course it can’t write to this file, but a read-only database is still very useful.&lt;/p&gt;&lt;p&gt;Since fetching data via HTTP has a pretty large overhead, we need to fetch data in chunks and find some balance between the number of requests and the used bandwidth. Thankfully, SQLite already organizes its database in "pages" with a user-defined page size (4 KiB by default). I’ve set the page size to 1 KiB for this database.&lt;/p&gt;&lt;p&gt;Here’s an example of a simple index lookup query:&lt;/p&gt;&lt;code&gt;select indicator_code, long_definition from wdi_series where indicator_name
    = 'Literacy rate, youth total (% of people ages 15-24)'&lt;/code&gt;&lt;p&gt;Run the above query and look at the page read log. SQLite does 7 page reads for that query.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Three page reads are just some to get some schema information (these are already cached)&lt;/item&gt;&lt;item&gt;Two page reads are the index lookup in the index &lt;code&gt;on wdi_series (indicator_name)&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Two page reads are on the &lt;code&gt;wdi_series&lt;/code&gt;table data (the first to find the row value by primary key, the second to get the text data from an overflow page)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Both the index as well as the table reads are B-Tree lookups.&lt;/p&gt;&lt;p&gt;A more complex query: What are the countries with the lowest youth literacy rate, based on the newest data from after 2010?&lt;/p&gt;&lt;code&gt;with newest_datapoints as (
  select country_code, indicator_code, max(year) as year from wdi_data
  join wdi_series using (indicator_code)
  where
    indicator_name = 'Literacy rate, youth total (% of people ages 15-24)'
    and year &amp;gt; 2010
  group by country_code
)
select c.short_name as country, printf('%.1f %%', value) as "Youth Literacy Rate"
from wdi_data
  join wdi_country c using (country_code)
  join newest_datapoints using (indicator_code, country_code, year)
order by value asc limit 10&lt;/code&gt;&lt;p&gt;The above query should do 10-20 GET requests, fetching a total of 130 - 270KiB, depending on if you ran the above demos as well. Note that it only has to do 20 requests and not 270 (as would be expected when fetching 270 KiB with 1 KiB at a time). That’s because I implemented a pre-fetching system that tries to detect access patterns through three separate virtual read heads and exponentially increases the request size for sequential reads. This means that index scans or table scans reading more than a few KiB of data will only cause a number of requests that is logarithmic in the total byte length of the scan. You can see the effect of this by looking at the "Access pattern" column in the page read log above.&lt;/p&gt;&lt;p&gt;All of this only works well when we have indices in the database that match the queries well. For example, the index used in the above query is a &lt;code&gt;INDEX ON wdi_data (indicator_code, country_code, year, value)&lt;/code&gt;. If that index did not include the value column, the SQLite engine would have to do another random access (unpredictable) read and thus HTTP request to retrieve the actual value for every data point. If the index was ordered &lt;code&gt;country_code, indicator_code, ...&lt;/code&gt;, then we would be able to quickly get all indicators for a single country, but not all country values of a single indicator.&lt;/p&gt;&lt;p&gt;We can also make use of the SQLite FTS module so we can do a full-text search on the more text-heavy information in the database - in this case there are over 1000 human development indicators in the database with longer descriptions.&lt;/p&gt;&lt;code&gt;select * from indicator_search
where indicator_search match 'educatio* femal*'
order by rank limit 10&lt;/code&gt;&lt;p&gt;The total amount of data in the &lt;code&gt;indicator_search&lt;/code&gt; FTS table is around 8 MByte. The above query should only fetch around 70 KiB. You can see how it is constructed here.&lt;/p&gt;&lt;p&gt;And finally, here’s a more complete demonstration of the usefulness of this system - here’s an interactive graph showing the development of a few countries over time, for any countries you want using any indicator from the dataset:&lt;/p&gt;&lt;head&gt;Extra information about this indicator&lt;/head&gt;&lt;list rend="dl"&gt;&lt;item rend="dt-1"&gt;Indicator Code&lt;/item&gt;&lt;item rend="dd-1"&gt;IT.NET.USER.ZS&lt;/item&gt;&lt;item rend="dt-2"&gt;Long definition&lt;/item&gt;&lt;item rend="dd-2"&gt;Internet users are individuals who have used the Internet (from any location) in the last 3 months. The Internet can be used via a computer, mobile phone, personal digital assistant, games machine, digital TV etc.&lt;/item&gt;&lt;item rend="dt-3"&gt;Statistical concept and methodology&lt;/item&gt;&lt;item rend="dd-3"&gt;The Internet is a world-wide public computer network. It provides access to a number of communication services including the World Wide Web and carries email, news, entertainment and data files, irrespective of the device used (not assumed to be only via a computer - it may also be by mobile phone, PDA, games machine, digital TV etc.). Access can be via a fixed or mobile network. For additional/latest information on sources and country notes, please also refer to: https://www.itu.int/en/ITU-D/Statistics/Pages/stat/default.aspx&lt;/item&gt;&lt;item rend="dt-4"&gt;Development relevance&lt;/item&gt;&lt;item rend="dd-4"&gt;The digital and information revolution has changed the way the world learns, communicates, does business, and treats illnesses. New information and communications technologies (ICT) offer vast opportunities for progress in all walks of life in all countries - opportunities for economic growth, improved health, better service delivery, learning through distance education, and social and cultural advances. Today's smartphones and tablets have computer power equivalent to that of yesterday's computers and provide a similar range of functions. Device convergence is thus rendering the conventional definition obsolete. Comparable statistics on access, use, quality, and affordability of ICT are needed to formulate growth-enabling policies for the sector and to monitor and evaluate the sector's impact on development. Although basic access data are available for many countries, in most developing countries little is known about who uses ICT; what they are used for (school, work, business, research, government); and how they affect people and businesses. The global Partnership on Measuring ICT for Development is helping to set standards, harmonize information and communications technology statistics, and build statistical capacity in developing countries. However, despite significant improvements in the developing world, the gap between the ICT haves and have-nots remains.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Note that many indicators are only available for some countries, for example the indicator "Women who believe a husband is justified in beating his wife when she burns the food" is based on surveys only conducted in lower-developed countries.&lt;/p&gt;&lt;head rend="h2"&gt;Bonus: DOM as a database&lt;/head&gt;&lt;p&gt;Since we’re already running a database in our browser, why not use our browser as a database using a virtual table called &lt;code&gt;dom&lt;/code&gt;?&lt;/p&gt;&lt;code&gt;select count(*) as number_of_demos from dom
  where selector match '.content div.sqlite-httpvfs-demo';
select count(*) as sqlite_mentions from dom
  where selector match '.content p' and textContent like '%SQLite%';&lt;/code&gt;&lt;p&gt;We can even insert elements directly into the DOM:&lt;/p&gt;&lt;code&gt;insert into dom (parent, tagName, textContent)
    select 'ul#outtable1', 'li', short_name
    from wdi_country where currency_unit = 'Euro'&lt;/code&gt;&lt;p&gt;Output:&lt;/p&gt;&lt;p&gt;And update elements in the DOM:&lt;/p&gt;&lt;code&gt;update dom set textContent =
  get_flag("2-alpha_code") || ' ' || textContent
from wdi_country
where selector match 'ul#outtable1 &amp;gt; li'
  and textContent = wdi_country.short_name&lt;/code&gt;&lt;p&gt;Of course, everything here is open source. The main implementation of the sqlite wrapper is in sql.js-httpvfs. The source code of this blog post is a pandoc markdown file, with the demos being a custom "fenced code block" React component.&lt;/p&gt;&lt;head rend="h2"&gt;Update 2023: Future Work&lt;/head&gt;&lt;p&gt;Since I wrote this article in 2021, a lot of interesting things have happened in this space, many inspired by this proof of concept! Here’s some highlights:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;libgen-ipfs: implements a search engine for the Library Genesis based on IPFS and sql.js-httpvfs.&lt;/item&gt;&lt;item&gt;absurd-sql: implements a backend for sql.js (sqlite3 compiled for the web) that treats IndexedDB like a disk and stores data in blocks there. Inspired by this article.&lt;/item&gt;&lt;item&gt;sqlite itself has now added official support for wasm, citing absurd-sql as related work!&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45748186</guid><pubDate>Wed, 29 Oct 2025 15:32:11 +0000</pubDate></item><item><title>Tell HN: Twilio support replies with hallucinated features</title><link>https://news.ycombinator.com/item?id=45748570</link><description>&lt;doc fingerprint="fe03d1565042ad40"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I was investigating some bug with our voice system and asked support where I can find some debugging information and event logs.&lt;/p&gt;
      &lt;p&gt;They told me where I should go in the interface to see that and reassured that they checked logs and this event exist.&lt;/p&gt;
      &lt;p&gt;It turned out these features and information doesn't exist anywhere in the interface and impossible to retrieve in any way. The support message with hallucinated features is mostly AI written.&lt;/p&gt;
      &lt;p&gt;CEOs tell us AGI is around the corner but in reality it just unreliable information and AI can't even restock the vending machine.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45748570</guid><pubDate>Wed, 29 Oct 2025 15:54:36 +0000</pubDate></item><item><title>AirTips – Alternative to Bento.me/Linktree</title><link>https://a.coffee/</link><description>&lt;doc fingerprint="7b1933f95ea4aa9d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;acoffee&lt;/head&gt;
    &lt;p&gt;NO.0002Pro&lt;/p&gt;
    &lt;p&gt;Links and projects by acoffee — compact, restrained, and a bit playful.&lt;/p&gt;
    &lt;p&gt;TIPS&lt;/p&gt;
    &lt;p&gt;12&lt;/p&gt;
    &lt;p&gt;tips received&lt;/p&gt;
    &lt;p&gt; Compact Customizable API‑ready &lt;/p&gt;
    &lt;p&gt; Invite‑only &lt;/p&gt;
    &lt;head rend="h2"&gt;Gallery&lt;/head&gt;
    &lt;p&gt;A.coffee/becool&lt;/p&gt;
    &lt;p&gt;Maker&lt;/p&gt;
    &lt;head rend="h2"&gt;Modules&lt;/head&gt;
    &lt;p&gt;TEXT&lt;/p&gt;
    &lt;head rend="h3"&gt;New note&lt;/head&gt;
    &lt;p&gt;This is a text module.&lt;/p&gt;
    &lt;p&gt;Number&lt;/p&gt;
    &lt;p&gt;1024&lt;/p&gt;
    &lt;head rend="h3"&gt;Custom HTML&lt;/head&gt;
    &lt;p&gt;Build playful, precise UI with pure HTML.&lt;/p&gt;
    &lt;p&gt; ⚡ Compact 🎛️ Customizable 🔗 API‑ready &lt;/p&gt;
    &lt;p&gt;LAYOUT&lt;/p&gt;
    &lt;p&gt;Responsive grids, badges, cards.&lt;/p&gt;
    &lt;p&gt;CONTENT&lt;/p&gt;
    &lt;p&gt;Headings, lists, emojis, inline SVG.&lt;/p&gt;
    &lt;p&gt;SAFE&lt;/p&gt;
    &lt;p&gt;No scripts. Pure, secure markup.&lt;/p&gt;
    &lt;head class="cursor-pointer text-sm font-medium text-slate-800"&gt;See a tiny JSON payload&lt;/head&gt;
    &lt;code&gt;{
    "items": [
      { "kind": "module", "type": "text", "id": "mod-1" },
      { "kind": "module", "type": "image", "id": "mod-2" }
    ]
  }&lt;/code&gt;
    &lt;p&gt;PROJECTS&lt;/p&gt;
    &lt;p&gt;IMAGE&lt;/p&gt;
    &lt;p&gt;Metric1&lt;/p&gt;
    &lt;p&gt;9383&lt;/p&gt;
    &lt;p&gt;Metric2&lt;/p&gt;
    &lt;p&gt;2.6k&lt;/p&gt;
    &lt;p&gt;Metri3&lt;/p&gt;
    &lt;p&gt;1234.5&lt;/p&gt;
    &lt;p&gt;This is a link&lt;/p&gt;
    &lt;p&gt;x.com/becool_me&lt;/p&gt;
    &lt;p&gt;LINKS&lt;/p&gt;
    &lt;p&gt;Custom HTML with Tailwind classes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45748608</guid><pubDate>Wed, 29 Oct 2025 15:57:17 +0000</pubDate></item><item><title>Tell HN: Azure outage</title><link>https://news.ycombinator.com/item?id=45748661</link><description>&lt;doc fingerprint="767891154f3225d5"&gt;
  &lt;main&gt;
    &lt;p&gt;For some reason an Azure outage does not faze me in the same way that an AWS outage does.&lt;/p&gt;
    &lt;p&gt;I have never had much confidence in Azure as a cloud provider. The vertical integration of all the things for a Microsoft shop was initially very compelling. I was ready to fight that battle. But, this fantasy was quickly ruined by poor execution on Microsoft's part. They were able to convince me to move back to AWS by simply making it difficult to provision compute resources. Their quota system &amp;amp; availability issues are a nightmare to deal with compared to EC2.&lt;/p&gt;
    &lt;p&gt;At this point I'd rather use GCP over Azure and I have zero seconds of experience with it. The number of things Microsoft gets right in 2025 can be counted single-handedly. The things they do get right are quite good, but everything else tends to be extremely awful.&lt;/p&gt;
    &lt;p&gt;The "Blades" experience [0] where instead of navigating between pages it just kept opening things to the side and expanding horizontally?&lt;/p&gt;
    &lt;p&gt;Yeah, that had some fun ideas but was way more confusing than it needed to be. But also that was quite a few years back now. The Portal ditched that experience relatively quickly. Just long enough to leave a lot of awful first impressions, but not long enough for it to be much more than a distant memory at this point, several redesigns later.&lt;/p&gt;
    &lt;p&gt;[0] The name "Blades" for that came from the early years of the Xbox 360, maybe not the best UX to emulate for a complex control panel/portal.&lt;/p&gt;
    &lt;p&gt;The problem is that in some industries, Microsoft is the only option. Many of these regulated industries are just now transitioning from the data center to the cloud, and they've barely managed to get approval for that with all of the Microsoft history in their organization. AWS or GCloud are complete non-starters.&lt;/p&gt;
    &lt;p&gt;Starting at approximately 16:00 UTC, we began experiencing Azure Front Door issues resulting in a loss of availability of some services. In addition. customers may experience issues accessing the Azure Portal. Customers can attempt to use programmatic methods (PowerShell, CLI, etc.) to access/utilize resources if they are unable to access the portal directly. We have failed the portal away from Azure Front Door (AFD) to attempt to mitigate the portal access issues and are continuing to assess the situation.&lt;/p&gt;
    &lt;p&gt;We are actively assessing failover options of internal services from our AFD infrastructure. Our investigation into the contributing factors and additional recovery workstreams continues. More information will be provided within 60 minutes or sooner.&lt;/p&gt;
    &lt;p&gt;This message was last updated at 16:57 UTC on 29 October 2025&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;Update: 16:35 UTC:&lt;/p&gt;
    &lt;p&gt;Azure Portal Access Issues&lt;/p&gt;
    &lt;p&gt;Starting at approximately 16:00 UTC, we began experiencing DNS issues resulting in availability degradation of some services. Customers may experience issues accessing the Azure Portal. We have taken action that is expected to address the portal access issues here shortly. We are actively investigating the underlying issue and additional mitigation actions. More information will be provided within 60 minutes or sooner.&lt;/p&gt;
    &lt;p&gt;This message was last updated at 16:35 UTC on 29 October 2025&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;Azure Portal Access Issues&lt;/p&gt;
    &lt;p&gt;We are investigating an issue with the Azure Portal where customers may be experiencing issues accessing the portal. More information will be provided shortly.&lt;/p&gt;
    &lt;p&gt;This message was last updated at 16:18 UTC on 29 October 2025&lt;/p&gt;
    &lt;p&gt;Starting at approximately 16:00 UTC, we began experiencing Azure Front Door issues resulting in a loss of availability of some services. We suspect that an inadvertent configuration change as the trigger event for this issue. We are taking two concurrent actions where we are blocking all changes to the AFD services and at the same time rolling back to our last known good state.&lt;/p&gt;
    &lt;p&gt;We have failed the portal away from Azure Front Door (AFD) to mitigate the portal access issues. Customers should be able to access the Azure management portal directly.&lt;/p&gt;
    &lt;p&gt;We do not have an ETA for when the rollback will be completed, but we will update this communication within 30 minutes or when we have an update.&lt;/p&gt;
    &lt;p&gt;This message was last updated at 17:17 UTC on 29 October 2025&lt;/p&gt;
    &lt;p&gt;"We have initiated the deployment of our 'last known good' configuration. This is expected to be fully deployed in about 30 minutes from which point customers will start to see initial signs of recovery. Once this is completed, the next stage is to start to recover nodes while we route traffic through these healthy nodes."&lt;/p&gt;
    &lt;p&gt;"This message was last updated at 18:11 UTC on 29 October 2025"&lt;/p&gt;
    &lt;p&gt;in many cases: no service health alerts, no status page updates and no confirmations from the support team in tickets. still we can confirm these issues from different customers accross europe. Mostly the issues are regional dependent.&lt;/p&gt;
    &lt;p&gt;It's pretty unlikely. AWS published a public 'RCA' https://aws.amazon.com/message/101925/. A race condition in a DNS 'record allocator' causing all DNS records for DDB to be wiped out.&lt;/p&gt;
    &lt;p&gt;I'm simplifying a bit, but I don't think it's likely that Azure has a similar race condition wiping out DNS records on _one_ system than then propagates to all others. The similarity might just end at "it was DNS".&lt;/p&gt;
    &lt;p&gt;That RCA was fun. A distributed system with members that don't know about each other, don't bother with leader elections, and basically all stomp all over each other updating the records. It "worked fine" until one of the members had slightly increased latency and everything cascade-failed down from there. I'm sure there was missing (internal) context but it did not sound like a well-architected system at all.&lt;/p&gt;
    &lt;p&gt;Whilst the status message acknowledge's the issue with Front Door (AFD), it seems as though the rest of the actions are about how to get Portal/internal services working without relying on AFD. For those of us using Front Door does that mean we're in for a long haul?&lt;/p&gt;
    &lt;p&gt;yea I saw that, but im not sure on how accurate that is. a few large apps/companies I know to be 100% on AWS in us-east-1 are cranking along just fine.&lt;/p&gt;
    &lt;p&gt;Yeah, I am guessing it's just a placeholder till they get more info. I thought I saw somewhere that internally within Microsoft it's seen as a "Sev 1" with "all hands on deck" - Annoyingly I can't remember where I saw it, so if someone spots it before I do, please credit that person :D&lt;/p&gt;
    &lt;p&gt;They briefly had a statement about using Traffic Manager to work with your AFD to work around this issue, with a link to learn.microsoft.com/...traffic-manager, and the link didn't work. Due to the same issue affecting everyone right now.&lt;/p&gt;
    &lt;p&gt;They quickly updated the message to REMOVE the link. Comical at this point.&lt;/p&gt;
    &lt;p&gt;We already had to do it for large files served from Blob Storage since they would cap out at 2MB/s when not in cache of the nearest PoP. If you’ve ever experienced slow Windows Store or Xbox downloads it’s probably the same problem.&lt;/p&gt;
    &lt;p&gt;I had a support ticket open for months about this and in the end the agent said “this is to be expected and we don’t plan on doing anything about it”.&lt;/p&gt;
    &lt;p&gt;We’ve moved to Cloudflare and not only is the performance great, but it costs less.&lt;/p&gt;
    &lt;p&gt;Only thing I need to move off Front Door is a static website for our docs served from Blob Storage, this incident will make us do it sooner rather than later.&lt;/p&gt;
    &lt;p&gt;we are considering the same but because our website uses APEX domain we would need to move all DNS resolver to cloudfront right ? Does it have as a nice "rule set builder" as azure ?&lt;/p&gt;
    &lt;p&gt;Unless you pay for CloudFlare’s Enterpise plan, you’re required to have them host your DNS zone, you can use a different registrar as long as you just point your NS records to Cloudflare.&lt;/p&gt;
    &lt;p&gt;Be aware that if you’re using Azure as your registrar, it’s (probably still) impossible to change your NS records to point to CloudFlare’s DNS server, at least it was for me about 6 months ago.&lt;/p&gt;
    &lt;p&gt;This also makes it impossible to transfer your domain to them either, as CloudFlare’s domain transfer flow requires you set your NS records to point to them before their interface shows a transfer option.&lt;/p&gt;
    &lt;p&gt;In our case we had to transfer to a different registrar, we used Namecheap.&lt;/p&gt;
    &lt;p&gt;However, transferring a domain from Azure was also a nightmare. Their UI doesn’t have any kind of transfer option, I eventually found an obscure document (not on their Learn website) which had an az command which would let you get a transfer code which I could give to Namecheap.&lt;/p&gt;
    &lt;p&gt;Then I had to wait over a week for the transfer timeout to occur because there is no way on Azure side that I could find to accept the transfer immediately.&lt;/p&gt;
    &lt;p&gt;I found CloudFlare’s way of building rules quite easy to use, different from Front Door but I’m not doing anything more complex than some redirects and reverse proxying.&lt;/p&gt;
    &lt;p&gt;I will say that Cloudflare’s UI is super fast, with Front Door I always found it painfully slow when trying to do any kind of configuration.&lt;/p&gt;
    &lt;p&gt;Cloudflare also doesn’t have the problem that Front Door has where it requires a manual process every 6 months or so to renew the APEX certificate.&lt;/p&gt;
    &lt;p&gt;Thanks :). We don't use Azure as our registrar. It seems I'll have to plan for this then, we also had another issue, AFD has a hard 500ms tls handshake timeout (doesn't matter how much you put on the origin timeout settings) which means if our server was slow for some reason we would get 504 origin timeout.&lt;/p&gt;
    &lt;p&gt;I noticed that Starbucks mobile ordering was down and thought “welp, I guess I’ll order a bagel and coffee on Grubhub”, then GrubHub was down. My next stop was HN to find the common denominator, and y’all did not disappoint.&lt;/p&gt;
    &lt;p&gt;The paradox of cloud provider crashes is that if the provider goes down and takes the whole world with it, it's actually good advertisement. Because, that means so many things rely on it, it's critically important, and has so many big customers. That might be why Amazon stock went up after AWS crash.&lt;/p&gt;
    &lt;p&gt;If Azure goes down and nobody feels it, does Azure really matter?&lt;/p&gt;
    &lt;p&gt;Personally I am thinking more and more about hetzner, yes I know its not an apples to orange comparison. But its honestly so good&lt;/p&gt;
    &lt;p&gt;Someone had created a video where they showed the underlying hardware etc., I am wondering if there is something like https://vpspricetracker.com/ but with geek-benchmarks as well.&lt;/p&gt;
    &lt;p&gt;We’re 100% on Azure but so far there’s no impact for us.&lt;/p&gt;
    &lt;p&gt;Luckily, we moved off Azure Front Door about a year ago. We’d had three major incidents tied to Front Door and stopped treating it as a reliable CDN.&lt;/p&gt;
    &lt;p&gt;They weren’t global outages, more like issues triggered by new deployments. In one case, our homepage suddenly showed a huge Microsoft banner about a “post-quantum encryption algorithm” or something along those lines.&lt;/p&gt;
    &lt;p&gt;Kinda wild that a company that big can be so shaky on a CDN, which should be rock solid.&lt;/p&gt;
    &lt;p&gt;The sad thing is - $MSFT isn't even down by 1%. And IIRC, $AMZN actually went up during their previous outage.&lt;/p&gt;
    &lt;p&gt;So if we look at these companies' bottom lines, all those big wigs are actually doing something right. Sales and lobbying capacity is way more effective than reliability or good engineering (at least in the short term).&lt;/p&gt;
    &lt;p&gt;There's a Family Dollar by my house that is down at least 2 full days per month because of bad inet connectivity. I live close enough that with a small tower on my roof i can get line of sight to theirs. I've thought about offering them a backup link off my home inet if they give me 50% of sales whenever its in use. It would be a pretty good deal for them, better some sales when their inet is down vs none.&lt;/p&gt;
    &lt;p&gt;2-3%, bit higher on perishables. Though i'd just ask lump sum payments in cash since it likely has to no go through corporate (as in, avoid the corporation).&lt;/p&gt;
    &lt;p&gt;You'd think any SeriousBusiness would have a backup way to take customers' money. This is the one thing you always want to be able to do: accept payment. If they made it so they can't do that, they deserve the hit to their revenue. People should just walk out of the store with the goods if they're not being charged.&lt;/p&gt;
    &lt;p&gt;Why doesn't someone in the store at least have one of those manual kachunk-kachunk carbon copy card readers in the back that they can resuscitate for a few days until the technology is turned back on? Did they throw them all away?&lt;/p&gt;
    &lt;p&gt;If they used standalone merchant terminals, then those typically use the local LAN which can rollover to cellular or PoT in the event of a network outage. The store can process a card transaction with the merchant terminal and then reconcile with the end of day chit. This article from 2008 describes their PoS https://www.retailtouchpoints.com/topics/store-operations/ca...&lt;/p&gt;
    &lt;p&gt;I think a lot of payment terminals have an option to record transactions offline and upload them later, but apparently it's not enabled by default - probably because it increases your risk that someone pays with a bad card.&lt;/p&gt;
    &lt;p&gt;The kachunk-kachunk credit card machines need raised digits on the cards, and I don't think most banks have been issuing those for years at this point. Mine have been smooth for at least 10 years.&lt;/p&gt;
    &lt;p&gt;IIRC, the grocery chain I worked for used to have an offline mode to move customers out the door. But it meant that when the system came back online, if the customers card was denied, the customer got free groceries.&lt;/p&gt;
    &lt;p&gt;I remember that banks will try to honor the transactions, even if the customer's balance/credit limit is exhausted. It doesn't apply only to some gift cards.&lt;/p&gt;
    &lt;p&gt;And querying https://www.microsoft.com/ results in HTTP 200 on the root document, but the page elements return errors (a 504 on the .css/.js documents, a 404 on some fonts, Name Not Resolved on scripts.clarity.ms, Connection Timed Out on wcpstatic.microsoft.com and mem.gfx.ms). That many different kinds of errors is actually kind of impressive.&lt;/p&gt;
    &lt;p&gt;I'm gonna say this was a networking/routing issue. The CDN stayed up, but everything else non-CDN became unroutable, and different requests traveled through different paths/services, but each eventually hit the bad network path, and that's what created all the different responses. Could also have been a bad deploy or a service stopped running and there's different things trying to access that service in different ways, leading to the weird responses... but that wouldn't explain the failed DNS propagation.&lt;/p&gt;
    &lt;p&gt;We are very dependent on Azure and Microsoft Authentication and Microsoft 365 and haven’t had weekly or even monthly issues. I can think of maybe three issues this year.&lt;/p&gt;
    &lt;p&gt;I’ve been migrating our services off of Azure slowly for the past couple of years. The last internet facing things remaining are a static assets bucket and an analytics VM running Matomo. Working with Front Door has been an abysmal experience, and today was the push I needed to finally migrate our assets to Cloudflare.&lt;/p&gt;
    &lt;p&gt;I feel pretty justified in my previous decisions to move away from Azure. Using it feels like building on quicksand…&lt;/p&gt;
    &lt;p&gt;Yeah just took down the prod site for one of our clients since we host the front-end out of their CDN. Just got wrapped up panic hosting it somewhere else for the past hour, very quickly reminds you about the pain of cookies...&lt;/p&gt;
    &lt;p&gt;They added a message at the same time as your comment:&lt;/p&gt;
    &lt;p&gt;"We are investigating an issue with the Azure Portal where customers may be experiencing issues accessing the portal. More information will be provided shortly."&lt;/p&gt;
    &lt;p&gt;I've been doing it since 1998 in my bedroom with a dual T1 (and on to real DCs later). While I've had some outages for sure it makes me feel better I am not that divergent in uptime in the long run vs big clouds.&lt;/p&gt;
    &lt;p&gt;The Internet is supposed to be decentralized. The big three seem to have all the power now (Amazon, Microsoft, and Google) plus Cloudflare/Oracle.&lt;/p&gt;
    &lt;p&gt;How did we get here? Is it because of scale? Going to market in minutes by using someone else's computers instead of building out your own, like co-location or dedicated servers, like back in the day.&lt;/p&gt;
    &lt;p&gt;&amp;gt; Big Tech lobbying is riding the EU’s deregulation wave by spending more, hiring more, and pushing more, according to a new report by NGO’s Corporate Europe Observatory and LobbyControl on Wednesday (29 October).&lt;/p&gt;
    &lt;p&gt;&amp;gt; Based on data from the EU’s transparency register, the NGOs found that tech companies spend the most on lobbying of any sector, spending €151m a year on lobbying — a 33 percent increase from €113m in 2023.&lt;/p&gt;
    &lt;p&gt;Gee whizz, I really do wonder how they end up having all the power!&lt;/p&gt;
    &lt;p&gt;A lot of money and years of marketing the cloud as the responsible business decision led us here. Now that the cloud providers have vendor lock-in, few will leave, and customers will continue to wildly overpay for cloud services.&lt;/p&gt;
    &lt;p&gt;Not sure how the current situation is better. Being stranded with no way whatsoever to access most/all of your services sounds way more terrifying than regular issues limited to a couple of services at a time&lt;/p&gt;
    &lt;p&gt;&amp;gt; no way whatsoever to access most/all of your services&lt;/p&gt;
    &lt;p&gt;I work on a product hosted on Azure. That's not the case. Except for front door, everything else is running fine. (Front door is a reverse proxy for static web sites.)&lt;/p&gt;
    &lt;p&gt;The product itself (an iot stormwater management system) is running, but our customers just can't access the website. If they need to do something, they can go out to the sites or call us and we can "rub two sticks together" and bypass the website. (We could also bypass front door if someone twisted our arms.)&lt;/p&gt;
    &lt;p&gt;Most customers only look at the website a few times a year.&lt;/p&gt;
    &lt;p&gt;---&lt;/p&gt;
    &lt;p&gt;That being said, our biggest point of failure is a completely different iot vendor who you probably won't hear about on Hacker News when they, or their data networks, have downtime.&lt;/p&gt;
    &lt;p&gt;I think the response lies in the surrounding ecosystem.&lt;/p&gt;
    &lt;p&gt;If you have a company it's easier to scale your team if you use AWS (or any other established ecosystem). It's way easier to hire 10 engineers that are competent with AWS tools than it is to hire 10 engineers that are competent with the IBM tools.&lt;/p&gt;
    &lt;p&gt;And from the individuals perspective it also make sense to bet on larger platforms. If you want to increase your odds of getting a new job, learning the AWS tools gives you a better ROI than learning the IBM tools.&lt;/p&gt;
    &lt;p&gt;A natural monopoly is a monopoly in an industry in which high infrastructure costs and other barriers to entry relative to the size of the market give the largest supplier in an industry, often the first supplier in a market, an overwhelming advantage over potential competitors. Specifically, an industry is a natural monopoly if a single firm can supply the entire market at a lower long-run average cost than if multiple firms were to operate within it. In that case, it is very probable that a company (monopoly) or a minimal number of companies (oligopoly) will form, providing all or most of the relevant products and/or services.&lt;/p&gt;
    &lt;p&gt;Consolidation is the inevitable outcome of free unregulated markets.&lt;/p&gt;
    &lt;p&gt;In our highly interconnected world, decentralization paradoxically requires a central authority to enforce decentralization by restricting M&amp;amp;A, cartels, etc.&lt;/p&gt;
    &lt;p&gt;Thank you. I was wondering what was going on at a company whose web app I need to access. I just checked with BuiltWith and it seems they are on Azure.&lt;/p&gt;
    &lt;p&gt;For us, it looks like most services are still working (eastus and eastus2). Our AKS cluster is still running and taking requests. Failures seem limited to management portal.&lt;/p&gt;
    &lt;p&gt;Pretty much all Azure services seem to be down. Their status page says it's only the portal since 16:00. It would be nice if these mega-companies could update their status page when they take down a large fraction of the Internet and thousands of services that use them.&lt;/p&gt;
    &lt;p&gt;Same playbook for AWS. When they admitted that Dynamo was inaccessible, they failed to provide context that their internal services are heavily dependent on Dynamo&lt;/p&gt;
    &lt;p&gt;It's only after the fact they are transparent about the impact&lt;/p&gt;
    &lt;p&gt;High availability is touted as a reason for their high prices, but I swear I read about major cloud outages far more than I experience any outages at Hetzner.&lt;/p&gt;
    &lt;p&gt;I think the biggest features of the big cloud vendors is that when they are down, not only you but your customers and your competitors usually have issues at the same time so everybody just shrug and have a lazy/off day at the same time. Even on call teams reall just have to wait and stay on standby because there is very little they can do. Doing a failover can be slower than waiting for the recovery, not help at all if outage is spanned accross several region, or bring aditional risks.&lt;/p&gt;
    &lt;p&gt;And more importantly nobody lose any reputation except AWS/Azure/Google.&lt;/p&gt;
    &lt;p&gt;The real reason is that outages are not your fault. Its the new version of "nobody ever got fired for buying IBM" - later it became MS, and now its any big cloud provider.&lt;/p&gt;
    &lt;p&gt;For one it’s statistics - Hetzner simply runs far fewer major services than hyperscalers. And the services they run are also more affluent, with larger customer bases, so downtimes are systemically critical. Therefore it’s louder.&lt;/p&gt;
    &lt;p&gt;On the merits though, I agree, haven’t had any serious issues with Hetzner.&lt;/p&gt;
    &lt;p&gt;DO has been shockingly reliable for me. I shut down a neglected box almost 900 days uptime the other day. In that time AWS has randomly dropped many of my boxes with no warning requiring a manual stop/start action to recover them... But everybody keeps telling me that DO isn't "as reliable" as the big three are.&lt;/p&gt;
    &lt;p&gt;Nope, more than the portal. For instance, I just searched for "Azure Front Door" because I hadn't heard of it before (I now know it's a CDN), and neither the product page itself [1] nor the technical docs [2] are coming up for me.&lt;/p&gt;
    &lt;p&gt;we use front door (as does miccrosoft.com) and our website was down, I was able to change the DNS records to point directly to our server and will leave it like that for a few hours until everything is green&lt;/p&gt;
    &lt;p&gt;Do Microsoft still say "If the government has a broader voluntary national security program to gather customer data, we don't participate in it" today (which PRISM proved very false), or are they at least acknowledging they're participating in whatever NSA has deployed today?&lt;/p&gt;
    &lt;p&gt;PRISM wasn't voluntary. Also there are 3 levels here:&lt;/p&gt;
    &lt;p&gt;1. Mandatory&lt;/p&gt;
    &lt;p&gt;2. "Voluntary"&lt;/p&gt;
    &lt;p&gt;3. Voluntary&lt;/p&gt;
    &lt;p&gt;And I suspect that very little of what the NSA does falls into category 3. As Sen Chuck Schumer put it "you take on the intelligence community, they have six ways from Sunday at getting back at you"&lt;/p&gt;
    &lt;p&gt;This is funny but also possibly true because: business/MBA types see these outages as a way to prove how critical some services are, leading to investors deciding to load up on the vendor's stock.&lt;/p&gt;
    &lt;p&gt;I may or may not have been known to temporarily take a database down in the past to make a point to management about how unreliable some old software is.&lt;/p&gt;
    &lt;p&gt;Starting at approximately 16:00 UTC, we began experiencing DNS issues resulting in availability degradation of some services. Customers may experience issues accessing the Azure Portal. We have taken action that is expected to address the portal access issues here shortly. We are actively investigating the underlying issue and additional mitigation actions. More information will be provided within 60 minutes or sooner.&lt;/p&gt;
    &lt;p&gt;This message was last updated at 16:35 UTC on 29 October 2025&lt;/p&gt;
    &lt;p&gt;----&lt;/p&gt;
    &lt;p&gt;Azure Portal Access Issues&lt;/p&gt;
    &lt;p&gt;We are investigating an issue with the Azure Portal where customers may be experiencing issues accessing the portal. More information will be provided shortly.&lt;/p&gt;
    &lt;p&gt;This message was last updated at 16:18 UTC on 29 October 2025&lt;/p&gt;
    &lt;p&gt;"We’re investigating an issue impacting Azure Front Door services. Customers may experience intermittent request failures or latency. Updates will be provided shortly."&lt;/p&gt;
    &lt;p&gt;They admit in their update blurb azure front door is having issues but still report azure front door as having no issues on their status page.&lt;/p&gt;
    &lt;p&gt;And it's very clear from these updates that they're more focused on the portal than the product, their updates haven't even mentioned fixing it yet, just moving off of it, as if it's some third party service that's down.&lt;/p&gt;
    &lt;p&gt;Unsubstantiated idea: So the support contract likely says there is a window between each reporting step and the status page is the last one and the one in the legal documents giving them several more hours before the clauses trigger.&lt;/p&gt;
    &lt;p&gt;On our end, our VMs are still working, so our gitlab instance is still up. Our services using Azure App Services are available through their provided url. However, Front Door is failing to resolve any domains that it was responsible for.&lt;/p&gt;
    &lt;p&gt;Portal and Azure CDN are down here in the SF Bay Area. Tenant azureedge.net DNS A queries are taking 2-6 seconds and most often return nothing. I got a couple successful A response in the last 10 minutes.&lt;/p&gt;
    &lt;p&gt;Edit: As of 9:19 AM Pacific time, I'm now getting successful A responses but they can take several seconds. The web server at that address is not responding.&lt;/p&gt;
    &lt;p&gt;I'd say DNS/Front Door (or some carrier interconnect) is the thing affected, since I can auth just fine in a few places. (I'm at MS, but not looped into anything operational these days, so I'm checking my personal subscription).&lt;/p&gt;
    &lt;p&gt;SSO is down, Azure Portal Down and more, seems like a major outage. Already a lot of services seem to be affected: banks, airlines, consumer apps, etc.&lt;/p&gt;
    &lt;p&gt;The portal is up for me and their status page confirms they did a failover for it. Definitely not disputing that its reach is wide, but a lot of smaller setups probably aren't using Front Door.&lt;/p&gt;
    &lt;p&gt;Azure goes down all the time. On Friday we had an entire regional service down all day. Two weeks ago same thing different region. You only hear about it when it's something everyone uses like the portal, because in general nobody uses Azure unless they're held hostage.&lt;/p&gt;
    &lt;p&gt;“ Starting at approximately 16:00 UTC, we began experiencing DNS issues resulting in availability degradation of some services. Customers may experience issues accessing the Azure Portal. We have taken action that is expected to address the portal access issues here shortly. We are actively investigating the underlying issue and additional mitigation actions. More information will be provided within 60 minutes or sooner.&lt;/p&gt;
    &lt;p&gt;This message was last updated at 16:35 UTC on 29 October 2025”&lt;/p&gt;
    &lt;p&gt;Looks like MyGet is impacted too. Seems like they use Azure:&lt;/p&gt;
    &lt;p&gt;&amp;gt;What is required to be able to use MyGet? ... MyGet runs its operations from the Microsoft Azure in the West Europe region, near Amsterdam, the Netherlands.&lt;/p&gt;
    &lt;p&gt;It begs the question from a noob like me... Where should they host the status page? Surely it shouldn't be on the same infra that it's supposed to be monitoring. Am I correct in thinking that?&lt;/p&gt;
    &lt;p&gt;I absolutely love the utility aspect of LLMs but part of me is curious if moving faster by using AI is going to make these sorts of failure more and more often.&lt;/p&gt;
    &lt;p&gt;It is much more than azure. One of my kids needs a key for their laptop and can't reach that either. Great excuse though, 'Azure ate my homework'. What a ridiculous world we are building. Fuck MS and their account requirements for windows.&lt;/p&gt;
    &lt;p&gt;Does (should, could) DownDetector also say what customer-facing services are down, when some infrastructure is unworking? Or is that the info that the malefactors are seeking?&lt;/p&gt;
    &lt;p&gt;Unable to access the portal and any hit to SSO for other corporate accesses is also broken. Seems like there's something wrong in their Identity services.&lt;/p&gt;
    &lt;p&gt;Apologies, but this just reads like a low effort critique of big things.&lt;/p&gt;
    &lt;p&gt;To be clear, they should get criticism. They should be held liable for any damage they cause.&lt;/p&gt;
    &lt;p&gt;But that they remain the biggest cloud offering out there isn't something you'd expect to change from a few outages that, by most all evidence, potential replacements have, as well? More, a lot of the outages potential replacements have are often more global in nature.&lt;/p&gt;
    &lt;p&gt;That said, I don't hear about GCP outages all that often. I do think AWS might be leading in outages, but that's a gut feeling, I didn't look up numbers.&lt;/p&gt;
    &lt;p&gt;I don't think it's meant to be serious. It's a comment on Microsoft laying off their staff and stuffing their Azure and Dotnet teams with AI product managers.&lt;/p&gt;
    &lt;p&gt;downdetector reports coincident cloudflare outage. is microsoft using cloudflare for management plane, or is there common infra? data center problem somewhere, maybe fiber backbone? BGP?&lt;/p&gt;
    &lt;p&gt;Yeah, I have non prod environments that don't use FD that are functioning. Routing through FD does not work. And a different app, nonprod doesn't use FD (and is working) but loads assets from the CDN (which is not working).&lt;/p&gt;
    &lt;p&gt;FD and CDN are global resources and are experiencing issues. Probably some other global resources as well.&lt;/p&gt;
    &lt;p&gt;Hate to say it, but DNS is looking like it's still the undisputed champ.&lt;/p&gt;
    &lt;p&gt;downdetector reports coincident cloudflare outage. is microsoft using cloudflare for management plane, or is there common infra? data center problem somewhere, maybe fiber backbone? BGP?&lt;/p&gt;
    &lt;p&gt;When you look at the scale of the reports, you find they are much lower than Azure's. seeing a bunch of 24-hour sparkline type graphs next to each other can make it look like they are equally impacted, but AWS has 500 reports and Azure has 20,000. The scale is hidden by the choice of graph.&lt;/p&gt;
    &lt;p&gt;In other words, people reporting outages at AWS are probably having trouble with microsoft-run DNS services or caching proxies. It's not that the issues aren't there, it's that the internet is full of intermingled complexity. Just that amount of organic false-positives can make it look like an unrelated major service is impacted.&lt;/p&gt;
    &lt;p&gt;Yeah the graph for that one looks exactly the same shape. I wonder if they were depending on some azure component somehow, or maybe there were things hosted on both and the azure failure made enough things failover to AWS that AWS couldn't cope? If that was the case I'd expect to see something similar with GCP too though.&lt;/p&gt;
    &lt;p&gt;Edit: nope looks like there's actually a spike on GCP as well&lt;/p&gt;
    &lt;p&gt;Definitely also a strong possibility. I wish I had paid more attention during the AWS one earlier to see what other things looked like on there at the time.&lt;/p&gt;
    &lt;p&gt;I noticed issues on Azure so I went to the status page. It said everything was fine even though the Azure Portal was down. It took more than 10 minutes for that status page to update.&lt;/p&gt;
    &lt;p&gt;How can one of the richest companies in the world not offer a better service?&lt;/p&gt;
    &lt;p&gt;As of now Azure Status page still shows no incident. It must be manually updated, someone has to actively decide to acknowledge an issue, and they're just... not. It undermines confidence in that status page.&lt;/p&gt;
    &lt;p&gt;My best guess at the moment is something global like the CDN is having problems affecting things everywhere. I'm able to use a legacy application we have that goes directly to resources in uswest3, but I'm not able to use our more modern application which uses APIM/CDN networks at all.&lt;/p&gt;
    &lt;p&gt;From Azure status page: "Customers can consider implementing failover strategies with Azure Traffic Manager, to fail over from Azure Front Door to your origins".&lt;/p&gt;
    &lt;p&gt;I especially like how Nadella speaks of layoffs as some kind of uncontrollable natural disaster, like a hurricane, caused by no-one in particular. A kind of "God works in mysterious ways".&lt;/p&gt;
    &lt;p&gt;&amp;gt; “Microsoft is being recognized and rewarded at levels never seen before,” Nadella wrote. “And yet, at the same time, we’ve undergone layoffs. This is the enigma of success in an industry that has no franchise value.” &amp;gt; Nadella explained the disconnect between thriving financials and layoffs by stating that “progress isn’t linear” and that it is “sometimes dissonant, and always demanding.”&lt;/p&gt;
    &lt;p&gt;I've read the whole memo and it's actually worse than those excerpts. Nadella doesn't even claim these were low performers:&lt;/p&gt;
    &lt;p&gt;&amp;gt; These decisions are among the most difficult we have to make. They affect people we’ve worked alongside, learned from, and shared countless moments with—our colleagues, teammates, and friends.&lt;/p&gt;
    &lt;p&gt;Ok, so Microsoft is thriving, these were friends and people "we've learned from", but they must go because... uh... "progress isn't linear". Well, thanks Nadella! That explains so much!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45748661</guid><pubDate>Wed, 29 Oct 2025 16:01:18 +0000</pubDate></item><item><title>Cursor Composer: Building a fast frontier model with RL</title><link>https://cursor.com/blog/composer</link><description>&lt;doc fingerprint="3d5aedd9e03a0a1a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Composer: Building a fast frontier model with RL&lt;/head&gt;
    &lt;p&gt;Composer is our new agent model designed for software engineering intelligence and speed. On our benchmarks, the model achieves frontier coding results with generation speed four times faster than similar models.&lt;/p&gt;
    &lt;p&gt;We achieve these results by training the model to complete real-world software engineering challenges in large codebases. During training, Composer is given access to a set of production search and editing tools and tasked with efficiently solving a diverse range of difficult problems. The final result is a large-scale model optimized for high-speed use as an agent in Cursor.&lt;/p&gt;
    &lt;p&gt;Our motivation comes from our experience developing Cursor Tab, our custom completion model. We found that often developers want the smartest model that can support interactive use, keeping them in the flow of coding. In our development process, we experimented with a prototype agent model, codenamed Cheetah, to better understand the impact of faster agent models. Composer is a smarter version of this model that keeps coding delightful by being fast enough for an interactive experience.&lt;/p&gt;
    &lt;p&gt;Composer is a mixture-of-experts (MoE) language model supporting long-context generation and understanding. It is specialized for software engineering through reinforcement learning (RL) in a diverse range of development environments. At each iteration of training, the model is given a problem description and instructed to produce the best response, be it a code edit, a plan, or an informative answer. The model has access to simple tools, like reading and editing files, and also more powerful ones like terminal commands and codebase-wide semantic search.&lt;/p&gt;
    &lt;p&gt;To measure progress, we constructed an evaluation that measures a model's usefulness to a software developer as faithfully as possible. Our benchmark, Cursor Bench, consists of real agent requests from engineers and researchers at Cursor, along with hand-curated optimal solutions to these requests. The resulting evaluation measures not just the agent’s correctness, but also its adherence to a codebase's existing abstractions and software engineering practices.&lt;/p&gt;
    &lt;p&gt;Reinforcement learning allows us to actively specialize the model for effective software engineering. Since response speed is a critical component for interactive development, we incentivize the model to make efficient choices in tool use and to maximize parallelism whenever possible. In addition, we train the model to be a helpful assistant by minimizing unnecessary responses and claims made without evidence. We also find that during RL, the model learns useful behaviors on its own like performing complex searches, fixing linter errors, and writing and executing unit tests.&lt;/p&gt;
    &lt;p&gt;Efficient training of large MoE models requires significant investment into building infrastructure and systems research. We built custom training infrastructure leveraging PyTorch and Ray to power asynchronous reinforcement learning at scale. We natively train our models at low precision by combining our MXFP8 MoE kernels with expert parallelism and hybrid sharded data parallelism, allowing us to scale training to thousands of NVIDIA GPUs with minimal communication cost. Additionally, training with MXFP8 allows us to deliver faster inference speeds without requiring post-training quantization.&lt;/p&gt;
    &lt;p&gt;During RL, we want our model to be able to call any tool in the Cursor Agent harness. These tools allow editing code, using semantic search, grepping strings, and running terminal commands. At our scale, teaching the model to effectively call these tools requires running hundreds of thousands of concurrent sandboxed coding environments in the cloud. To support this workload, we adapted existing infrastructure we built for Background Agents, rewriting our virtual machine scheduler to support the bursty nature and scale of training runs. This enabled seamless unification of RL environments with production environments.&lt;/p&gt;
    &lt;p&gt;Cursor builds tools for software engineering, and we make heavy use of the tools we develop. A motivation of Composer development has been developing an agent we would reach for in our own work. In recent weeks, we have found that many of our colleagues were using Composer for their day-to-day software development. With this release, we hope that you also find it to be a valuable tool.&lt;/p&gt;
    &lt;p&gt;—&lt;/p&gt;
    &lt;p&gt;¹ Benchmarked on an internal benchmark in the Cursor tool harness. We group models into classes based on score and report the best model in each class. "Fast Frontier" includes models designed for efficient inference such as Haiku 4.5 and Gemini Flash 2.5. "Best Open" includes recent open weight model releases such as Qwen Coder and GLM 4.6. "Frontier 7/2025" is the best model available in July of this year. "Best Frontier" includes GPT-5 and Sonnet 4.5, which both outperform Composer. For the Tokens per Second calculation, tokens are standardized across models to the latest Anthropic tokenizer.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45748725</guid><pubDate>Wed, 29 Oct 2025 16:04:33 +0000</pubDate></item><item><title>Minecraft removing obfuscation in Java Edition</title><link>https://www.minecraft.net/en-us/article/removing-obfuscation-in-java-edition</link><description>&lt;doc fingerprint="370203ca08b7cced"&gt;
  &lt;main&gt;
    &lt;p&gt;Do you like to mod Java, tinker with builds, or take deep dives into Minecraft’s code? Then this article is for you!&lt;/p&gt;
    &lt;p&gt;For a long time, Java Edition has used obfuscation (hiding parts of the code) – a common practice in the gaming industry. Now we’re changing how we ship Minecraft: Java Edition to remove obfuscation completely. We hope that, with this change, we can pave a future for Minecraft: Java Edition where it’s easier to create, update, and debug mods.&lt;/p&gt;
    &lt;head rend="h2"&gt;An obfuscated history&lt;/head&gt;
    &lt;p&gt;Minecraft: Java Edition has been obfuscated since its release. This obfuscation meant that people couldn’t see our source code. Instead, everything was scrambled – and those who wanted to mod Java Edition had to try and piece together what every class and function in the code did.&lt;/p&gt;
    &lt;p&gt;But we encourage people to get creative both in Minecraft and with Minecraft – so in 2019 we tried to make this tedious process a little easier by releasing “obfuscation mappings”. These mappings were essentially a long list that allowed people to match the obfuscated terms to un-obfuscated terms. This alleviated the issue a little, as modders didn’t need to puzzle out what everything did, or what it should be called anymore. But why stop there?&lt;/p&gt;
    &lt;head rend="h2"&gt;Removing obfuscation in Java Edition&lt;/head&gt;
    &lt;p&gt;To make things even easier – and remove these intermediary steps – we’re removing obfuscation altogether! Starting with the first snapshot following the complete Mounts of Mayhem launch, we will no longer obfuscate Minecraft: Java Edition. This means that this build (and all future builds) will have all of our original names* – now with variable names and other names – included by default to make modding even easier.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45748879</guid><pubDate>Wed, 29 Oct 2025 16:12:56 +0000</pubDate></item><item><title>Tailscale Peer Relays</title><link>https://tailscale.com/blog/peer-relays-beta</link><description>&lt;doc fingerprint="66f1d873751076c5"&gt;
  &lt;main&gt;
    &lt;p&gt;Tailscale Peer Relays provides a customer-deployed and managed traffic relaying mechanism. By advertising itself as a peer relay, a Tailscale node can relay traffic for any peer nodes on the tailnet, even for traffic bound to itself. Tailscale Peer Relays can only relay traffic for nodes on your tailnet, and only for nodes that have access to the peer relay. Because they’re managed entirely by the customer, peer relays are less throughput-constrained than Tailscale’s managed DERP relays, and can provide higher throughput connections for traffic to and from locked-down cloud infrastructure, or behind strict network firewalls.&lt;/p&gt;
    &lt;p&gt;In testing with early design partners, we’ve seen throughputs nearing that of a direct connection; often multiple orders of magnitude higher than Tailscale’s managed DERP fleet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Moving past hard NAT&lt;/head&gt;
    &lt;p&gt;Over the past few weeks, you’ve heard us talk about improvements we’ve made to Network Address Translation (NAT) traversal techniques, so that Tailscale can establish direct connections wherever possible (hint: it’s over 90% of the time). However, we’ve also outlined places where this isn’t possible or desirable today for a variety of reasons, especially in cloud environments. And, we’ve postulated a bit about where we think the industry is going.&lt;/p&gt;
    &lt;p&gt;While we’ve been keeping your network reliably connected for years with DERP, we’ve heard from customers that the throughput and performance aspects of a QoS-aware managed relay fleet makes deployments in certain environments difficult or untenable. Furthermore, customers have noted that it’s non-trivial to deploy and manage custom DERP fleets (which run as a separate service and binary).&lt;/p&gt;
    &lt;p&gt;DERP provides an incredibly valuable service, setting up reliable connections between Tailscale clients anywhere in the world (including negotiating connections through peer relays). But often, DERP’s focus as a reliability and NAT traversal tool results in performance tradeoffs.&lt;/p&gt;
    &lt;p&gt;By contrast, Tailscale Peer Relays is designed as a performant connectivity tool, and can perform at a level rivaling direct connections. Peer relays can be placed right next to the resources they serve, and peer relays also run on top of UDP, both characteristics beneficial to lower latency and resource overhead. And, they are built into the Tailscale client itself for ease of deployment.&lt;/p&gt;
    &lt;p&gt;We want to move past even more hard NATs, and put Tailscale’s relaying technology in our customers’ hands, so they can use Tailscale at scale, anywhere, with ease. We believe our new Tailscale Peer Relays connectivity option—unique to Tailscale—gives customers the best performance and flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;Peer relays are configured with a single UDP port that must be available to both sides of a connection. Tailscale Peer Relays is built right into the Tailscale client, and can be enabled with a simple command, using the &lt;code&gt;tailscale set --relay-server-port&lt;/code&gt; flag from the Tailscale CLI. Once enabled via the steps in our documentation, clients can connect to infrastructure in hard NAT environments over the peer relay.&lt;/p&gt;
    &lt;p&gt;And don’t worry, we still prefer to fly direct. Tailscale prefers direct connections wherever possible. Clients can then fall back to available peer relays, and finally leverage Tailscale’s managed DERP fleet, or any customer-deployed custom DERPs, to ensure you have connectivity wherever you need it. All of this traffic, over any connection, is still end-to-end encrypted via WireGuard®.&lt;/p&gt;
    &lt;p&gt;Tailscale Peer Relays is designed for the real world, based on the feedback we’ve received from customers and our own hard-earned networking expertise. It allows customers to make just one firewall exception for connections only coming from their tailnet. Peer relays scale across regions, are resilient to real-world network conditions, and graciously fall back to DERP (Tailscale’s or custom). Your network maintains its shape, but gains all kinds of flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Connectivity, everywhere, at warp speed&lt;/head&gt;
    &lt;p&gt;Customers can now maintain performance benchmarks even where direct connections aren’t possible, by enabling Tailscale Peer Relays to build a deterministic and high-throughput relay topology.&lt;/p&gt;
    &lt;p&gt;We’ve had customers use peer relays to provide access into unmanaged networks, allowing their partners or customers to provide a controllable and auditable connectivity path without sacrificing performance.&lt;/p&gt;
    &lt;p&gt;In strict private networks, customers can build predictable access paths. Tailscale Peer Relays can be placed in public subnets with VPC peering to private subnets, allowing security teams to efficiently segment their private network infrastructure, while enabling networking teams to roll Tailscale out in full-mesh mode across the subnet.&lt;/p&gt;
    &lt;p&gt;Today, customers are using peer relays to establish relayed connections at near-direct speeds across a variety of environments and settings.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable high-throughput traffic through cloud NATs, like AWS Managed NAT Gateways: Applications and services behind a Managed NAT Gateway can leverage peer relays to relay traffic that can’t establish direct connections.&lt;/item&gt;
      &lt;item&gt;Relay through network firewalls: Workloads running in strictly firewalled environments can predictably expose a single UDP port, limiting the Tailscale surface area and fast-tracking the approval process for firewall exceptions.&lt;/item&gt;
      &lt;item&gt;Offload from Custom and Managed DERP: Minimize data-in-transit through Tailscale‘s managed DERP network, and remove the need for customer-maintained DERP servers.&lt;/item&gt;
      &lt;item&gt;Provide access to locked down customer networks: Data plane traffic can be relayed through predictable endpoints in customer networks, so that they only need to open minimal numbers of ports to facilitate cross network connections.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;It’s not perfect, but we’re getting there&lt;/head&gt;
    &lt;p&gt;Tailscale Peer Relays is available today as a public beta. We’ve yet to establish all the connectivity paths we want to, and there’s still visibility and debugging improvements to work through. However, we’ve reliably seen our early design partners move to peer relay deployments with relative ease, and we’re ready for you to give it a try on your tailnet.&lt;/p&gt;
    &lt;p&gt;Tailscale Peer Relays can be enabled on all plans, including free (it’s our little way of working through the kinks of the modern internet with our customers). All customers can use two peer relays, for free, forever. As your needs scale, so will the number of available peer relays. To add even more peer relays to your tailnet, come have a chat with us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45749017</guid><pubDate>Wed, 29 Oct 2025 16:21:36 +0000</pubDate></item><item><title>Does brand advertising work? Upwave (YC S12) is hiring engineers to answer that</title><link>https://www.upwave.com/job/8228849002/</link><description>&lt;doc fingerprint="355c16590c952eaa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Senior Software Engineer&lt;/head&gt;
    &lt;p&gt;Upwave: The Brand Outcomes Measurement Platform&lt;/p&gt;
    &lt;p&gt;Upwave is a leading measurement company entirely focused on measuring and optimizing upper funnel campaigns.. The world’s leading advertisers, agencies, and media partners trust Upwave’s robust, AI-driven platform to bring science to the top of the funnel.&lt;/p&gt;
    &lt;p&gt;With Upwave, marketers maximize the effectiveness of brand spend. Upwave measures Brand Lift, validates Brand Reach, and surfaces Brand Optimization opportunities in one, dynamic platform with cross-channel brand measurement for CTV, Digital, Social, Linear, Addressable, Retail Media, Streaming Audio and more.&lt;/p&gt;
    &lt;p&gt;We’re a profitable, growth-stage company backed by leading venture investors (Y Combinator, Uncork Capital, Bloomberg Beta, Initialized Capital, PivotNorth, Ridge Ventures, Industry Ventures, Conductive Ventures,) and leading AdTechfounders &amp;amp; CEOs.&lt;/p&gt;
    &lt;p&gt;We’re a humble but ambitious team that takes its work seriously but never ourselves. Come join us.&lt;/p&gt;
    &lt;p&gt;As a Senior Software Engineer at Upwave, you’ll be a full-stack problem solver with a backend focus—building the APIs, data pipelines, and systems that power our brand measurement platform. Your work will process billions of ad impressions, manage complex data workflows, and deliver insights that inform marketing decisions for the world’s biggest brands.&lt;/p&gt;
    &lt;p&gt;You’ll collaborate across engineering, product, and data science to ship high-impact features end-to-end, scale our platform for the next phase of growth, and help define the next generation of brand measurement.&lt;/p&gt;
    &lt;p&gt;What you will do:&lt;/p&gt;
    &lt;p&gt;Build AI-powered customer experiences — integrate LLMs and advanced causal inference techniques into production workflows that automatically generate data visualizations, synthesize campaign performance into natural language insights, and help enterprise customers understand and optimize their advertising through our AI analyst "Bayes."&lt;/p&gt;
    &lt;p&gt;Design and build scalable backend systems —develop microservices and RESTful APIs that power the analytics platform behind the world’s top brand campaigns.&lt;/p&gt;
    &lt;p&gt;Contribute across the stack — work from backend APIs to Python analytics services to React frontends, delivering complete features that combine sophisticated data analysis with intuitive user experiences.&lt;/p&gt;
    &lt;p&gt;Engineer data pipelines at scale — design and operate systems that process massive volumes of ad and survey data with MySQL, DynamoDB, and AWS (S3, Lambda, EMR, Kinesis Firehose).&lt;/p&gt;
    &lt;p&gt;Improve reliability and performance — deploy services on Kubernetes and AWS, automate deployments via CI/CD, monitor with DataDog and Sentry, and continuously raise the bar for operational excellence&lt;/p&gt;
    &lt;p&gt;Collaborate deeply — work closely with Product and Data Science to productionize statistical models, integrate advanced analytics into customer-facing tools, and bring cutting-edge AI capabilities to enterprise customers.&lt;/p&gt;
    &lt;p&gt;Deliver insights that move millions — enable brand lift analytics and real-time campaign insights by building reliable, high-throughput systems. Multi-million dollar advertising decisions hinge on our recommendations.&lt;/p&gt;
    &lt;p&gt;About you:&lt;/p&gt;
    &lt;p&gt;You’re an experienced engineer (5+ years) who thrives on solving complex problems across APIs, data systems, and distributed infrastructure. You care about clean architecture, reliable systems, and measurable customer impact.&lt;/p&gt;
    &lt;p&gt;You’ve built powerful, intuitive, API-driven products for professional users.. You’re comfortable across the stack, with experience in RDBMS-backed backends using Spring Boot, Django, Rails, or Express, and single-page frontends built in React, Vue, or Angular.&lt;/p&gt;
    &lt;p&gt;You understand and enjoy programming. You’re fluent in the modern landscape of UI frameworks, API and microservice architectures, databases, and cloud platforms—and know when to use the right tool for the job.&lt;/p&gt;
    &lt;p&gt;You embrace modern AI-powered development tools to move faster and code smarter. You use technologies like Claude Code, Cursor, and GitHub CoPilot to automate routine work, explore ideas quickly, and focus your time on higher-value system design and innovation.&lt;/p&gt;
    &lt;p&gt;You value structured software development practices—testing, documentation, CI/CD, and code review—and care about building maintainable systems that scale.&lt;/p&gt;
    &lt;p&gt;You believe developers should operate what they build. You think about observability, cost, and reliability from day one, and design systems that are easy to deploy and maintain. You’ve built in the cloud and know both its power and pitfalls.&lt;/p&gt;
    &lt;p&gt;You like turning ideas into tools that make real customers more effective. You collaborate closely with Product to design features that solve real-world problems and delight users.&lt;/p&gt;
    &lt;p&gt;You mentor others, share knowledge freely, and understand that healthy human systems are the foundation of healthy technical systems. Teammates look to you for guidance.&lt;/p&gt;
    &lt;p&gt;You want to understand how things work and why. You care more about the best idea winning than whose idea it is.&lt;/p&gt;
    &lt;p&gt;You take responsibility, move quickly to fix problems, and take pride in establishing areas of deep expertise in a fast-changing environment.&lt;/p&gt;
    &lt;p&gt;You believe high-trust, inclusive teams outperform individuals. You communicate clearly and compassionately, and contribute to a culture where people enjoy working together.&lt;/p&gt;
    &lt;p&gt;Bonus points:&lt;/p&gt;
    &lt;p&gt;Have worked with modern backend ecosystems like Java/Kotlin/Groovy (Spring Boot or Grails) and know how to design APIs that scale elegantly.&lt;/p&gt;
    &lt;p&gt;Are fluent with data systems such as MySQL, DynamoDB, and Presto, and understand the tradeoffs between relational and NoSQL storage.&lt;/p&gt;
    &lt;p&gt;Have built cloud-native applications on AWS, especially using Kubernetes and Terraform for automation and scalability.&lt;/p&gt;
    &lt;p&gt;Know your way around modern front-end frameworks like React/Redux and enjoy collaborating up and down the stack.&lt;/p&gt;
    &lt;p&gt;Have startup DNA—you’re comfortable with ambiguity, iterate fast, and make pragmatic technical decisions.&lt;/p&gt;
    &lt;p&gt;Bring experience from AdTech, MarTech, or measurement platforms, or are excited to learn how AI and large-scale data intersect in this space.&lt;/p&gt;
    &lt;p&gt;Why You’ll Like Working Here:&lt;/p&gt;
    &lt;p&gt;Engineering-first company: Upwave’s success depends on high-velocity innovation, and we believe high velocity comes from high efficiency, not high effort. We set priorities rather than deadlines, we don’t crunch, we work reasonable hours, and engineers actually take vacations.&lt;/p&gt;
    &lt;p&gt;Modern tech stack: Python analytics, Kotlin/Java APIs, event streaming (100k+ RPM), DynamoDB, Kubernetes, AWS, Terraform, LLM orchestration.&lt;/p&gt;
    &lt;p&gt;Impact at scale: Your code processes billions of advertising events and directly influences multi-million dollar decisions by Fortune 500 brands.&lt;/p&gt;
    &lt;p&gt;Autonomy and ownership: Our engineers lead projects from design through deployment and monitoring.&lt;/p&gt;
    &lt;p&gt;Ambitious but humble culture: We take our work seriously but never ourselves. Upwavers collaborate hard and support each other generously. We screen for people who are both exceptionally talented and genuinely kind.&lt;/p&gt;
    &lt;p&gt;Remote-first team: Our diverse team spans half the globe (but only one half, to ensure everyone can talk live when we need to). We balance synchronous core hours with flexibility to create a work environment that enables both deep collaboration and deep work.&lt;/p&gt;
    &lt;p&gt;Additional Information:&lt;/p&gt;
    &lt;p&gt;The annual base salary range for this role is $150,000 - $175,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for the new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits.&lt;/p&gt;
    &lt;p&gt;Upwave is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45749690</guid><pubDate>Wed, 29 Oct 2025 17:00:15 +0000</pubDate></item><item><title>A Year of Fast Apply – Our Path to 10k Tokens per Second</title><link>https://www.relace.ai/blog/relace-apply-3</link><description>&lt;doc fingerprint="d5137f0a11a0a9b"&gt;
  &lt;main&gt;
    &lt;p&gt;A year ago today, we released our first Fast Apply model publicly. Since then, we’ve learned a lot about how to fine-tune small, specialized models for code-specific tasks.&lt;/p&gt;
    &lt;p&gt;Today, we’re open-sourcing what we've learned in training this series of models — dataset curation, training methods, and inference techniques that led to Relace Apply 3, our best model yet, capable of running at 10k+ tokens per second while maintaining state-of-the-art accuracy.&lt;/p&gt;
    &lt;p&gt;Error rate comparison on 500 randomly sampled production merge requests. For breakdown of error categories, see section on evaluating merges.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Problem&lt;/head&gt;
    &lt;p&gt;When making edits to a codebase, it doesn't make sense to have an expensive LLM regenerate all the unchanged, preexisting code.&lt;/p&gt;
    &lt;p&gt;Editing a thousand line file (~10k tokens) by rewriting it from scratch with Claude 4.5 Sonnet takes over 100 seconds and costs at least $0.18. For coding agents, this is infeasible from a product perspective.&lt;/p&gt;
    &lt;p&gt;The solution is to have the frontier model output a diff that minimally expresses the changes to make (i.e. the hard tokens), and use a lightweight algorithm to efficiently apply the diff back into the preexisting code. Not only does this save on cost, but if the merging algorithm is fast, you also significantly speed up end-to-end generation time.&lt;/p&gt;
    &lt;p&gt;For a long time, LLMs were incapable of reliably producing diff formats that were mergeable by a fixed algorithm like string replace or UDiff.&lt;/p&gt;
    &lt;p&gt;Cursor pioneered a flexible workaround to this problem — let the frontier model produce "lazy" diffs and use a small, fast apply model as the merging algorithm. However, Cursor never made their model available for other companies to use outside of the IDE.&lt;/p&gt;
    &lt;p&gt;We decided to train our own apply model that anyone could use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Use an LLM as the Merge Algorithm?&lt;/head&gt;
    &lt;p&gt;In practice, frontier models can produce a wide variety of pathological diffs. Any closed-form algorithm you write to perform the merge will be susceptible to edge cases. In agentic settings, where there is often no human oversight, these errors compound and produce incorrect code.&lt;/p&gt;
    &lt;p&gt;Example of a pathological initial_code, diff pair that is hard to address with a closed-form merging algorithm.&lt;/p&gt;
    &lt;p&gt;In the code above, the user starts with a function called &lt;code&gt;handler&lt;/code&gt;. The intent
of the diff on the right is to rename the handler function to &lt;code&gt;messageHandler&lt;/code&gt;
and add a parameter for the &lt;code&gt;name&lt;/code&gt; column in the database query.&lt;/p&gt;
    &lt;p&gt;It would be difficult to write an algorithm that anticipates these two steps. A standard merging algorithm would likely just add a new function called &lt;code&gt;messageHandler&lt;/code&gt;, duplicating the original function.&lt;/p&gt;
    &lt;p&gt;The advantage of using an LLM as the merge algorithm is that it can flexibly infer the intent of the diff. Pretraining on trillions of code tokens bakes in pattern recognition robust to the many edge cases you see in production.&lt;/p&gt;
    &lt;p&gt;Also, by splitting the task into two steps — diff generation and merge — you can use a much smaller, fast model to focus entirely on the merge. This separation of work based on difficulty is a pattern we exploit a lot at Relace to improve overall performance of coding agents.&lt;/p&gt;
    &lt;p&gt;To achieve good results without needing to pretrain a model, we fine tune off-the-shelf small models on a high quality dataset that matches the distribution in production.&lt;/p&gt;
    &lt;head rend="h2"&gt;Producing the Dataset&lt;/head&gt;
    &lt;p&gt;A training set for fast apply contains three components: &lt;code&gt;initial_code&lt;/code&gt;, &lt;code&gt;diff&lt;/code&gt;,
and &lt;code&gt;merged_code&lt;/code&gt;. The initial code and diff are passed in as model inputs,
and the merged code is the output we train the model to produce.&lt;/p&gt;
    &lt;p&gt;For fine tuning, you need a small set of high quality examples. We found the size of the dataset to be much less important than the diversity and quality of merge data. Our first model was trained with only 30k data points, and we saw marginal gains beyond 100k data points.&lt;/p&gt;
    &lt;head rend="h3"&gt;Inputs&lt;/head&gt;
    &lt;p&gt;Early on, Kortix AI released an open-source dataset by post-processing data scraped from public GitHub repos. Given some initial code, they prompt a frontier model like Claude to (1) come up with a change to make and (2) produce the "lazy" diff for it.&lt;/p&gt;
    &lt;p&gt;This turns out to be the wrong approach, as it doesn't reflect the actual distribution of data in production environments. The rich variety of edge cases in diffs comes from context overload. The LLM must adhere to instructions in long system prompts while simultaneously inferring intent from noisy conversations with non-technical users.&lt;/p&gt;
    &lt;p&gt;To get high-quality, complex merges with plenty of edge cases into the training set, we partnered with prompt-to-app companies. We took snapshots of the real context for LLM coding tasks and reran them with additional instructions to produce the "lazy" edits. This allowed us to sample directly from the true distribution of &lt;code&gt;initial_code&lt;/code&gt; and &lt;code&gt;diff&lt;/code&gt; that would be seen in production.&lt;/p&gt;
    &lt;head rend="h3"&gt;Output&lt;/head&gt;
    &lt;p&gt;To generate the correct &lt;code&gt;merged_code&lt;/code&gt;, we use distillation with rejection
sampling. The idea is to feed the initial code and diff into a well-prompted
frontier “teacher” model, guided by a set of rules for how merges should be
handled.&lt;/p&gt;
    &lt;p&gt;This approach lets you produce a large amount of candidate data quickly, but it’s crucial to filter out the teacher’s mistakes. When done correctly, the trained student model can actually end up outperforming the teacher.&lt;/p&gt;
    &lt;p&gt;However, filtering correctly is hard. We developed a multi-stage process to build a high quality LLM-as-a-judge that could scale up to thousands of datapoints.&lt;/p&gt;
    &lt;head rend="h2"&gt;Evaluating Merges&lt;/head&gt;
    &lt;p&gt;We began by manually reviewing 500 randomly sampled examples to create a set of ironclad ground truths. For our first Apply model, these datapoints were fully synthetic, but we later repeated the process using real production data from earlier iterations of the hosted model.&lt;/p&gt;
    &lt;p&gt;To streamline the process while maintaining quality, we built our own internal evaluation tool: a Git-style diff viewer with annotation tools for categorizing merge outcomes.&lt;/p&gt;
    &lt;p&gt;A screenshot of Relace's internal merge evaluation tool.&lt;/p&gt;
    &lt;p&gt;Even with this tool, it took us over 40 hours to painstakingly ensure 100% correctness. Patterns started to emerge in the process, and we broke down merges into 6 categories:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Correct Merge: Model correctly implemented the intent of the diff.&lt;/item&gt;
      &lt;item&gt;Non-functional Error: Model implemented the intent of the diff except for inconsequential details such as variation in comments and formatting (e.g. function definitions in different orders).&lt;/item&gt;
      &lt;item&gt;Smoothing: Model fixed an error incorporated by the diff that would have resulted in uncompilable or broken code.&lt;/item&gt;
      &lt;item&gt;Functional/Merge Error: Model did not carry out the intent of the diff (e.g. omitting parts of code and inserting code in incorrect places).&lt;/item&gt;
      &lt;item&gt;Hallucination Error: Model added or changed code not specified by the diff (may be unsuccessful attempts at smoothing).&lt;/item&gt;
      &lt;item&gt;Truncation Errors: Model performed an incomplete merge (with parts of final code cut out) leading to uncompilable code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Categories 1-3 are considered correct merges, while 4-6 are considered incorrect. We keep the six-class system for more nuanced evaluations, but collapse to a binary classification when creating the LLM judge.&lt;/p&gt;
    &lt;head rend="h3"&gt;Aside on Smoothing&lt;/head&gt;
    &lt;p&gt;We often found that frontier LLMs produced diffs leading to slightly incorrect code. The most common example is when the diff uses a new library in the code without actually importing it.&lt;/p&gt;
    &lt;p&gt;This raised a question: should a fast apply model strictly follow the diff, or fix the error? In practice, we found customers building coding agents prefer that the model auto-corrects small mistakes to reduce friction for end users.&lt;/p&gt;
    &lt;p&gt;The hallucination category accounts for cases where the apply model overstepped and introduced more incorrect code to try and fix errors.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLM-as-a-Judge&lt;/head&gt;
    &lt;p&gt;Once we had this set of 500 categorized merge examples we could trust, the next step was to align an LLM-as-a-judge to our human-annotated seed dataset. It would be completely infeasible to hand-evaluate enough code merges to create the full training dataset of 100k+ examples.&lt;/p&gt;
    &lt;p&gt;The LLM-as-a-judge technique exploits the generation/verification gap. i.e. It's easier for an LLM to evaluate whether an answer is correct than to actually generate the answer. Still, the LLM often makes mistakes, and it's important to align it properly with a human evaluation first.&lt;/p&gt;
    &lt;p&gt;As with any binary classification task, there are two error modes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;False positive - a bad merge is incorrectly classified as good.&lt;/item&gt;
      &lt;item&gt;False negative - a good merge is incorrectly classified as bad.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since we have a large synthetic dataset, false positives are the more problematic error mode. It's much worse for bad merges to remain in the dataset than to reduce dataset yield by throwing away a few false negatives.&lt;/p&gt;
    &lt;p&gt;We used Claude 4 Sonnet as the judge and iteratively tuned the prompt until we hit a false positive rate of ~1%. For comparison, the initial naive judge with no tuning had a false positive rate of ~16%!&lt;/p&gt;
    &lt;head rend="h3"&gt;Scaling Up&lt;/head&gt;
    &lt;p&gt;With the aligned LLM judge, it's possible to filter the rest of the data at scale.&lt;/p&gt;
    &lt;p&gt;For Relace Apply 3, we started with 200k sets of &lt;code&gt;initial_code&lt;/code&gt;, &lt;code&gt;diff&lt;/code&gt;, and
synthetically generated &lt;code&gt;merged_code&lt;/code&gt;. We chose a representative distribution of
examples across dozens of languages, but focused predominantly on
TypeScript/Javascript, Markdown, Python, Ruby, and HTML.&lt;/p&gt;
    &lt;p&gt;To further cut down on mistakes, we added an extra post-processing step using a combination of static analysis tools — syntax verification with a code parser, deduplication, and regex-based filtering for common undesirable behaviors identified through customer feedback.&lt;/p&gt;
    &lt;p&gt;After all the filtering, we were left with a high-confidence training set of ~145k data points.&lt;/p&gt;
    &lt;head rend="h2"&gt;Training with LoRA&lt;/head&gt;
    &lt;p&gt;For small models, we've consistently found that data quality is the most important ingredient. With a clean, in-distribution dataset, the training just boils down to specializing a high quality base model for the merging task without catastrophic forgetting on general coding.&lt;/p&gt;
    &lt;p&gt;We trained our apply models using Supervised Fine-Tuning (SFT) on top of open-source coding models in the 3–8 billion parameter range. This gave us the right balance of expressiveness, inference speed, and cost efficiency.&lt;/p&gt;
    &lt;p&gt;We built our own training pipeline on top of the HuggingFace &lt;code&gt;transformers&lt;/code&gt;
library, but you can also just use out-of-the-box libraries like &lt;code&gt;axolotl&lt;/code&gt; or
&lt;code&gt;unsloth&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Since post-training typically uses much smaller datasets than pretraining, updating every parameter in the model is wasteful. Instead of retraining all billions of weights, we use Low-rank adaptation (LoRA) — a lightweight fine-tuning method that adds a small number of trainable “adapter” matrices on top of the frozen base model.&lt;/p&gt;
    &lt;p&gt;This lets us specialize the model for merge tasks without erasing its coding intuition. The base model stays intact, while the adapters learn the merging algorithm we care about.&lt;/p&gt;
    &lt;p&gt;We ran a series of grid searches to tune the adapter size (rank), scaling factor (alpha), and learning rate, and landed on the configuration below, which produced the best evaluation loss and convergence speed.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;LoRA Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;LoRA alpha&lt;/cell&gt;
        &lt;cell role="head"&gt;Learning Rate&lt;/cell&gt;
        &lt;cell role="head"&gt;Optimizer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;5e-5&lt;/cell&gt;
        &lt;cell&gt;AdamW&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Interestingly, we independently validated the optimal hyperparameters for LoRA published in the recent Thinking Machines blog post.&lt;/p&gt;
    &lt;p&gt;Using LoRA allowed us to train Relace Apply 3 on all ~145k data points using a single Nvidia H200 GPU on Modal with context length up to 64k tokens.&lt;/p&gt;
    &lt;p&gt;Using Modal allowed us to launch parallel training runs on H200 GPUs without having to wrestle with complicated cloud providers. Even though small model training lets you get way with batch size 1 on a single GPU, running a large hyperparameter sweep would normally take a lot of manual setup. With Modal, we ran our Python scripts and let it handle the scaling for us — no need to ssh to new GPU instances every time.&lt;/p&gt;
    &lt;p&gt;After training in BF16, we convert the model weights to FP8 using the &lt;code&gt;llm-compressor&lt;/code&gt; library from
vLLM. This conversion step is
crucial — by leveraging the FP8 cores on newer Nvidia GPUs, we achieve a
substantial jump in throughput without sacrificing precision.&lt;/p&gt;
    &lt;p&gt;To confirm that the quantization process was effectively lossless, we evaluated the resulting model against our 500 held-out ground-truth examples to validate that the outputs were the same.&lt;/p&gt;
    &lt;head rend="h2"&gt;10k tok/s with Speculative Decoding&lt;/head&gt;
    &lt;p&gt;With the model trained, our goal was to make it feel less like a slow language model and more like a closed-form algorithm for merging code. To reach that user expereince, we needed to push inference speed as far as possible — which meant turning to speculative decoding.&lt;/p&gt;
    &lt;p&gt;LLMs normally generate tokens sequentially, where each new token depends on the ones that came before it. This dependency makes inference inherently slow, since every step requires a full forward pass through the model.&lt;/p&gt;
    &lt;p&gt;Speculative decoding takes advantage of the fact that forward passes are heavily memory bound. i.e. Shuttling the LLM weights into the GPU sRAM takes much longer than actually performing the matrix multiplication with the tensor cores. By guessing a sequence of k tokens, we can process many tokens in parallel (like prefill) and move more towards to the compute-bound regime.&lt;/p&gt;
    &lt;p&gt;After the forward pass, the model checks which of the predicted tokens match the "true" next tokens and keeps the ones that are correct. The better the "guess", the more tokens you accept, and the more you accelerate the model.&lt;/p&gt;
    &lt;p&gt;Animation demonstrating how speculative decoding parallelizes inference.&lt;/p&gt;
    &lt;p&gt;For code merging, large sections of the &lt;code&gt;initial_code&lt;/code&gt; and &lt;code&gt;diff&lt;/code&gt; are nearly
identical to what appears in the &lt;code&gt;merged_code&lt;/code&gt;. We can use this strong prior to
get long, high quality guesses for what tokens the model should output and get
huge speed ups.&lt;/p&gt;
    &lt;p&gt;However, speed and accuracy are tightly coupled for speculative decoding. Each hallucinated token interrupts the guessed sequence, resetting the verification chain and wasting computation.&lt;/p&gt;
    &lt;p&gt;By training on the meticulously cleaned dataset, we minimized these breaks and were able to push Relace Apply 3 to 10k tok/s:&lt;/p&gt;
    &lt;p&gt;Distribution of Relace Apply 3 throughput speed after first token (measured in tokens/second)&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;We tested Relace Apply on two datasets: (1) our manually reviewed benchmark of 500 examples, and (2) a second dataset of pathological merges collected from customer feedback.&lt;/p&gt;
    &lt;p&gt;Across both, Relace Apply 3 achieves state-of-the-art merge accuracy. Substantial improvements were made over the previous generation of Apply models thanks to targetted dataset tuning based on customer feedback.&lt;/p&gt;
    &lt;p&gt;Comparison of merge accuracy between Relace Apply 2 and Relace Apply 3 on a dataset of pathological merge requests.&lt;/p&gt;
    &lt;p&gt;Previous generations of fast apply struggled when edit snippets contained multiple diff formats in one (e.g. combining &lt;code&gt;\\ ... existing code ...&lt;/code&gt; format
with UDiff edits). We included subsets of UDiff and String Replace edits in the
training data for Relace Apply 3 allowing it to act as a universal merger.&lt;/p&gt;
    &lt;p&gt;Relace Apply 3 also introduces native support for 256k context, allowing it to handle very large files without degradation in performance. Combined with the 10k tok/s throughput, this makes Relace Apply 3 the fastest, most accurate, and longest-context model on the market.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fast Apply, One Year Later&lt;/head&gt;
    &lt;p&gt;When we released our first Fast Apply model a year ago, LLMs were notoriously bad at outputting valid diff formats. Deterministic approaches like Search-and-Replace or UDiff were brittle, model-specific, and required extensive prompt engineering.&lt;/p&gt;
    &lt;p&gt;Diff formatting accuracy became such a bottleneck that Aider’s polyglot leaderboard tracked it as a separate metric — one column for accuracy, another for performance.&lt;/p&gt;
    &lt;p&gt;Fast Apply changed that. It was the first model to make structured code edits feel reliable, and our customers felt the difference immediately.&lt;/p&gt;
    &lt;p&gt;Today, frontier models have become much better at diff formatting through heavy reinforcement learning on string-edit tools, but they’re still not perfect. Companies that exclusively use deterministic strategies, like Cline, need a supplmentary merge algorithm to help further boost the diff edit accuracy.&lt;/p&gt;
    &lt;p&gt;Schematic reconstructed from an X post by the Cline team. Even deterministic approaches require fallback logic to handle edge cases.&lt;/p&gt;
    &lt;p&gt;The best models now reach roughly 96% edit success, but models without this kind of tuning still fail around 10% of the time.&lt;/p&gt;
    &lt;p&gt;So while we expect that, over time, apply models may be phased out as diff accuracy improves, the underlying philosophy that drove it remains central to new projects.&lt;/p&gt;
    &lt;p&gt;Fast Apply proved that small, specialized models can deliver SoTA results when trained with high quality, task-specific datasets. The methods we developed are now guiding our broader work on accelerating codegen with small agentic models for utility tasks like search, merge conflict resolution, and refactoring.&lt;/p&gt;
    &lt;p&gt;Stay tuned for more releases soon!&lt;/p&gt;
    &lt;head rend="h2"&gt;We're Hiring&lt;/head&gt;
    &lt;p&gt;If you have gotten this far, chances are you found this interesting!&lt;/p&gt;
    &lt;p&gt;We’re hiring pragmatic researchers (Physics/Math/CS/ML) and exceptional engineers to ship models like this that real product teams rely on. Check out our careers page, and join us!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45749763</guid><pubDate>Wed, 29 Oct 2025 17:04:48 +0000</pubDate></item><item><title>ICE and CBP Agents Are Scanning Faces on the Street to Verify Citizenship</title><link>https://www.404media.co/ice-and-cbp-agents-are-scanning-peoples-faces-on-the-street-to-verify-citizenship/</link><description>&lt;doc fingerprint="1755ccd3ea4393ef"&gt;
  &lt;main&gt;
    &lt;p&gt;“You don’t got no ID?” a Border Patrol agent in a baseball cap, sunglasses, and neck gaiter asks a kid on a bike. The officer and three others had just stopped the two young men on their bikes during the day in what a video documenting the incident says is Chicago. One of the boys is filming the encounter on his phone. He says in the video he was born here, meaning he would be an American citizen.&lt;/p&gt;
    &lt;p&gt;When the boy says he doesn’t have ID on him, the Border Patrol officer has an alternative. He calls over to one of the other officers, “can you do facial?” The second officer then approaches the boy, gets him to turn around to face the sun, and points his own phone camera directly at him, hovering it over the boy’s face for a couple seconds. The officer then looks at his phone’s screen and asks for the boy to verify his name. The video stops.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45749781</guid><pubDate>Wed, 29 Oct 2025 17:05:24 +0000</pubDate></item><item><title>Building a Robot Dog (with an airsoft gun)</title><link>https://erikschluntz.com/hardware/2025/10/26/robot-dog.html</link><description>&lt;doc fingerprint="7f38984739a766e7"&gt;
  &lt;main&gt;&lt;p&gt;I designed and built a quadruped robot dog from scratch this summer for a “Mech Warfare” airsoft battlebots competition. I’ve always wanted to build something with legs, and this seemed like a great opportunity to push the boundaries on my mechanical design skills. This blog covers my design process, stress testing, and final robot that I built :)&lt;/p&gt;&lt;p&gt;The rules of Mech Warefare are pretty simple:&lt;/p&gt;&lt;p&gt;After watching some videos of past competitions, I decided that my strategy would be to maximize speed so I could attack opponents from the side and back before they realized what was happening. (I also have future ambitions to build an auto-aim stable enough to fire while moving, but haven’t gotten to that yet).&lt;/p&gt;&lt;p&gt;Most contestants use older “spider” like designs, but for speed I wanted to use a more dynamic dog like design, similar to Boston Dynamic’s Spot and the Unitree Stellar Hunter. I started exploring the web for every example of robot leg geometry and known best practices that I could find.&lt;/p&gt;&lt;p&gt;The most common two designs I found were 1) 4-bar-linkages, and 2) parallel linkages. Both of these really just boil down to how to use two motors to place the “foot” at an arbitrary X,Y location.&lt;/p&gt;&lt;p&gt;Now wouldn’t it be simpler to just have one motor at the hip, and one motor at the knee?&lt;/p&gt;&lt;p&gt;That works, but motors are heavy, and moving one around at the knee creates a LOT of extra work for the hip motor. It’s much better to keep the motors as stationary as possible, and use a mechanical linkage to transfer the motion to the knee. I decided on the 4 bar linkage, as the simpler design (and because it’s what Unitree uses!)&lt;/p&gt;&lt;p&gt;For the next step in my design, I would need Forward Kinematics (FK) and Inverse Kinematics (IK). These are the equations that let you convert between foot X,Y coordinates, and motor angles (theta1, theta2) between each other.&lt;/p&gt;&lt;p&gt;Forward Kinematics is how you take motor angles and calculate where the foot (“end effector”) will be. It is quite simple for this design:&lt;/p&gt;\[\begin{bmatrix} x \\ y \end{bmatrix} = L_{thigh} \begin{bmatrix} \cos\theta_{thigh} \\ \sin\theta_{thigh} \end{bmatrix} + L_{shin} \begin{bmatrix} \cos\theta_{knee} \\ \sin\theta_{knee} \end{bmatrix}\]&lt;p&gt;Note that the two thetas are fully independent of each other, because with a 4 bar linkage design, rotating the thigh does NOT rotate the shin!&lt;/p&gt;&lt;p&gt;Inverse Kinematics is the opposite - given a foot X,Y location, what motor angles will get you there? For complex robots this can be super hard - either requiring a rats nest of trigonometry, or just solving it numerically with an optimizer. Luckily our case is fairly simple!&lt;/p&gt;&lt;p&gt;We can use the law of cosines which relates the angles and side lengths of any triangle to find the knee angle:&lt;/p&gt;\[c^2 = a^2 + b^2 - 2ab\cos C\]&lt;p&gt;Where &lt;code&gt;c&lt;/code&gt; is the distance from foot to hip, &lt;code&gt;a&lt;/code&gt; is our thigh length, and &lt;code&gt;b&lt;/code&gt; is our shin length, and &lt;code&gt;C&lt;/code&gt; is the knee angle. &lt;code&gt;c^2&lt;/code&gt; will be &lt;code&gt;x^2 + y^2&lt;/code&gt; by the pythagorean theorem.&lt;/p&gt;&lt;code&gt;# Use law of cosines to find theta2
cos_theta2 = (x**2 + y**2 - len1**2 - len2**2) / (2 * len1 * len2)

# Two possible solutions for theta2 (knee forward and knee backward)
theta2_knee_forward = np.arccos(cos_theta2)
theta2_knee_backward = -theta2_knee_forward
theta2 = theta2_knee_backward

# k1 and k2 are the x and y components of the target point (FootX, FootY)
# as seen in a coordinate frame that rotates with the first link.
k1 = len1 + len2 * np.cos(theta2)
k2 = len2 * np.sin(theta2)
theta1 = np.arctan2(y, x) - np.arctan2(k2, k1)
&lt;/code&gt;&lt;p&gt;Honestly, Claude just one-shotted this for me and when I visualized the results, they looked correct. As a side note, I’m a big believer in Vibe Coding as long as you have a way to verify the output. In my case it was much easier to verify correctness by playing with this interactively than by staring at the code.&lt;/p&gt;&lt;p&gt;Next, I had to decide the size and shape of my legs - how long should the thigh be, how long should the shin be? How high should It walk above the ground, and how long should each step be? The optimal leg design would be tied to my Gait design, so I wanted to answer all these questions at once.&lt;/p&gt;&lt;p&gt;I decided to approach this like any ML Researcher would - a hyper parameter scan! With my IK code, I can take any leg geometry and any gait parameters (stride length, stride height, period) and calculate the necessary motor angles as well as all the speeds, accelerations, and torques needed to support a particular weight!&lt;/p&gt;&lt;p&gt;I did a parameter sweep of 8000 leg and gait configurations and plotted various characteristics like max torque and max velocity that it would require from the motors (all configurations constrainted to go at a speed of 1m/s).&lt;/p&gt;&lt;p&gt;This was a really valuable exercise to build design intuition and how all these variables related to each other. I didn’t have a single objective function to optimize, so I ended up picking a design that was a balance between optimizing torque and speed: a 16cm thigh and shin.&lt;/p&gt;&lt;p&gt;I was already planning to use Dynamixel MX-106Rs that I had from a previous project, and by my calculations my 16cm leg design was well within their torque and speed limits:&lt;/p&gt;&lt;p&gt;Stall Torque: 8 Nm&lt;/p&gt;&lt;p&gt;Speed: 41 rpm&lt;/p&gt;&lt;p&gt;As a side note, Dynamixels are pricy so I wouldn’t recommend them for most hobbiests. They’re very high quality, and a lesson that I’ve learned over and over again is that it’s worth it in the long run to pay for nice hardware to save yourself time. Time is the biggest limiting factor for my side projects, so this tradeoff was worth it for me. My quick pitch of what the extra $$$ gets you over hobby servos:&lt;/p&gt;&lt;p&gt;The two servos face each other, one directly driving the thigh, and the other driving a bar linkage that controls the shin. To connect each bar there are simple M3 screws through them, with a nylon washer between to reduce friction.&lt;/p&gt;&lt;p&gt;The leg segments are 3D printed PLA. I have never experimented with more advanced filaments, but some of my friends who have told me that any strength benefit wasn’t worth the added difficulty of printing.&lt;/p&gt;&lt;p&gt;Initial motion tests went well, and I could run my gait calculation code to drive the leg through a walking motion.&lt;/p&gt;&lt;p&gt;Doing a walking motion in air was one thing, but I needed to find out how my design would actually hold up carrying a heavy robot, slamming into hard ground, etc. Some of the things I was worried about were the front bar linkage breaking, or the servo mounting block breaking. That block was the center of all torque in the leg between both servos! Time to do some stress testing!&lt;/p&gt;&lt;p&gt;To save time building a testing rig, I decided to test the leg upside down, with a weight hanging from it. Instead of the leg lifting itself up as it stepped, it would just lift a weight and the “hip” would remain stationary, clamped to the table.&lt;/p&gt;&lt;p&gt;I ran this for about ~1hr with a 4lb weight (1/2 of my projected robot weight) and at 1/2 of my target walking speed. The “1/2 robot weight” is because in a trot, there are always two legs on the ground. The “1/2 target walking speed” is because when running any faster this thing made a huge racket slamming the weight down on the ground and I didn’t want my upstairs neighbors to get mad at me 🤣.&lt;/p&gt;&lt;p&gt;Next up was a side load test: How does the leg handle sideways forces that will occur when turning or straifing?&lt;/p&gt;&lt;p&gt;This looked MUCH worse! There’s a huge amount of bend in the bars and the leg is tilting practically 20 degrees to the side! Defintely will need to strengthen the leg for side to side forces.&lt;/p&gt;&lt;p&gt;After all the stres testing was done, I took everything apart to look for damage and problems:&lt;/p&gt;&lt;p&gt;My two big goals for my updated leg design were&lt;/p&gt;&lt;p&gt;The primary change was making the thigh attach to both sides of the servo to form a strong triangle against side to side motion. (Dynamixels conveniently have a mounting hole exactly opposite their horn).&lt;/p&gt;&lt;p&gt;I beefed up the thickness of all the leg bars from 5cm to to 10cm, and replaced the through-hole M3 with a 4mm Shoulder bolt going through two 4x13x5mm bearings that are press fit into the leg. I used shoulder bolts instead of M4 screws, because screws are always slightly smaller than their nominal value, and would rattle around inside the bearing. Should bolts are much tighter tolerance and have a smooth, snug fit.&lt;/p&gt;&lt;p&gt;Up until this point, I’d been living in a 2D world, but it was time to venture out into the 3rd dimension. I would need a way to tilt the legs side to side (to straif and to rotate the robot), and I needed to plan how all 4 of these legs would actually mount into the overall robot.&lt;/p&gt;&lt;p&gt;I designed a pivot point through the servo mounting block that would be driven by a 1:3 gear reduction to another servo mounted above the leg. I used the gears in part because there was no easy way to mount the hip abduction (side to side motion) servo directly to the block, and also so that I could use a cheaper, lower torque dynamixel servo.&lt;/p&gt;&lt;p&gt;The servo block gets yet another high torque connection to it.&lt;/p&gt;&lt;p&gt;The body itself would be 4 carbon fiber tubes with flat plates clamped onto them. The legs would mount onto these plates, each of which was very easy to 3d print because it was flat with no overhangs.&lt;/p&gt;&lt;p&gt;I had never worked with carbon fiber before, but I was incredibly impressed at how rigid they were. Once I tightened all the plate clamps, I could not get the chassis to twist or flex AT ALL, even trying as hard as I could. The tubes were 25mm outer diameter, 420mm long, and each one was about $12 on Amazon. I will definitely design more projects using CF tubes!&lt;/p&gt;&lt;p&gt;My plan was for the rest of my electronics and other parts to clamp onto on the tubes at any location, giving me a ton of flexibility.&lt;/p&gt;&lt;p&gt;Luckily extending my FK and IK into 3D was quite easy. The axis of side to side rotation was directly inline with the “2D” leg, so all &lt;del&gt;I&lt;/del&gt; Claude had to do was rotate a plane to the side, and then solve 2D kinematics in that plane.&lt;/p&gt;&lt;code&gt;# First, determine the abduction angle
# The leg must lie in a plane containing the X axis
# This plane is determined by the Y and Z coordinates
yz_dist = np.sqrt(y**2 + z**2)

# Calculate abduction angle
theta_abd = np.arctan2(z, -y)
y_in_plane = y * np.cos(theta_abd) - z * np.sin(theta_abd)

# Adjust target for hip offset (hip is at y_local = -hip_offset in plane)
x_target_in_plane = x
y_target_in_plane = y_in_plane + hip_offset

# Now solve 2D IK in the rotated plane
solutions_2d = ik_2d(x_target_in_plane, y_target_in_plane, len1, len2,
                        theta2_relative=theta_knee_relative, only_one=only_one)
&lt;/code&gt;&lt;p&gt;I also adjusted the gait generation code to take in a heading and generate foot paths for side-to-side straifing.&lt;/p&gt;&lt;p&gt;Next, I needed to coordinate the motion of all 4 legs. I’m using a Trot which is a simple gait where the diagonal legs always step together, and the pairs are 180 degrees out of phase. For any translation, I just need to calculate a single gait, and then apply it to all 4 legs, but with different time offsets.&lt;/p&gt;&lt;p&gt;For rotation, each foot will move in the direction tangent to the circle of rotation.&lt;/p&gt;&lt;p&gt;Technically, I should make the foot trace an arc during this rotation, rather than a straight line, but Claude and I did some math and came to the conclusion that this approximation would be fine. The maximum distance between an arc and the straight line approximation I’m using is called a “Sagitta”. This is the distance that my leg will need to bend to make up for the difference.&lt;/p&gt;&lt;p&gt;As long as the steps are short and quick this distance will be less than 1cm.&lt;/p&gt;&lt;p&gt;Now to combine linear motion and angular rotation of the robot, for each foot I can just take a linear combination of velocity from the two motions.&lt;/p&gt;&lt;p&gt;And with that, I had a robot that could move around in all directions!&lt;/p&gt;&lt;p&gt;A quick note on stability: I’m not doing any “active” balancing, I’m just running the leg gaits open loop. This works well at high frequency gaits (0.25s period) because the body has enough rotational inertia to not go too far out of balance between steps. If I slow down the gait period to 0.5s or above, the robot tips over between steps.&lt;/p&gt;&lt;p&gt;One of my longer term ambitions is to train an RL algorithm to control the motion, so I’m not going to invest too much more in the classical controls of the gait.&lt;/p&gt;&lt;p&gt;I’ve never played airsoft before, but the guns work by having a motor pull back a powerful spring, which is released and then drives a piston to shoot high velocity air out behind the plastic BB. This thing is a cannon! (Sound on for extra fun)&lt;/p&gt;&lt;p&gt;The turret has two dynamixel servos to pan and tilt, a hopper to hold BBs, and the CSI camera mounted just over the barrell to aim down the sights.&lt;/p&gt;&lt;p&gt;Somewhat surprisingly, the hardest part of this design was the Hopper, which would always jam after a few shots as the BBs formed stable arches over the exit hole. Apparently this is a big known problem called Bridging that mechanical engineers working on things like grain silos have to deal with, and the solution is either to make the hole much bigger (doesn’t work for me, because I need to get a single BB at a time into the firing chamber), or add a motor to stir or move the BBs.&lt;/p&gt;&lt;p&gt;Most other Mech Warfare teams use an extra motor to control their hoppers, but I was running out of time before the competition, and didn’t have time to do anything more than a simple cone shaped hopper. When my gun jammed during the competition I had to take a few steps with the robot to shake the BBs loose!&lt;/p&gt;&lt;p&gt;Part of me still thinks there’s some clever, weird, asymmetric geometry that will passively never get stuck, but I couldn’t figure anything out.&lt;/p&gt;&lt;p&gt;The target plates for the competition each have an IR LED on them for auto-aim systems. Using a zoomed in CSI camera with no IR filter, I can track the target by just finding the most red pixel. The video looks pink because without an IR filter, there’s more light coming into the red channel pixels than a normal camera.&lt;/p&gt;&lt;p&gt;I calibrated which pixels the BBs actually go towards [red], and then use a PID controller to drive the tracked target [green] to the desired spot.&lt;/p&gt;&lt;p&gt;I feel like I should be able to improve the tracking and performance of this a lot, but I think the limiting factor is the latency of my tracking.&lt;/p&gt;&lt;p&gt;(And yes, I was wearing safety glasses for all this testing)&lt;/p&gt;&lt;p&gt;The core of the robot is a Raspberry Pi 3b+. (In retrospect, I should have used a Pi 5 for the extra compute, but at the time I was worried about power consumption and battery life)&lt;/p&gt;&lt;p&gt;With a laptop on the same wifi network as the Pi I can stream video over WebRTC and pass telemetry / commands via a websocket connection, all from a web app control interface.&lt;/p&gt;&lt;p&gt;All my code ran on the Pi as a systemd service launching a main python server. This server launched a few threads which:&lt;/p&gt;&lt;p&gt;Building the control interface and UX for this competition was surprisingly fun! I’m not much of a frontend person, but I do appreciate great UX. Some key elements:&lt;/p&gt;&lt;p&gt;Overall I was very happy with how the competition went! My robot was the fastest there, but my passive hopper made my gun jam a lot, so I couldn’t shoot as fast as the other robots. It was outdoors, so the sunlight washed out the IR tracking LEDs and none of our auto-aims worked 🤦♂️.&lt;/p&gt;&lt;p&gt;It was pretty informal, but I won my only match where we officially used the scoring system 🙂&lt;/p&gt;&lt;p&gt;The most hype part of the day was really feeling like I was taking damage as my camera covers were cracked by BBs&lt;/p&gt;&lt;p&gt;Despite my stress testing early in design, a few parts failed during practice before the competition, and on game day. The failures were all at connection points between pieces, not the bars themselves breaking!&lt;/p&gt;&lt;p&gt;I feel like I could have detected some of these problems much earlier in testing if I had been rougher with the robot, and done things like drop tests, rather than long duration stress tests.&lt;/p&gt;&lt;p&gt;Hopefully you enjoyed reading through my design process for this project! The robot is a really great platform that I hope to reuse for future projects. Specifically I want to train a gait using Reinforcement Learning to replace my classical one.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45749935</guid><pubDate>Wed, 29 Oct 2025 17:15:33 +0000</pubDate></item><item><title>OpenAI’s promise to stay in California helped clear the path for its IPO</title><link>https://www.wsj.com/tech/ai/openais-promise-to-stay-in-california-helped-clear-the-path-for-its-ipo-3af1c31c</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45750425</guid><pubDate>Wed, 29 Oct 2025 17:44:34 +0000</pubDate></item><item><title>Encoding x86 Instructions</title><link>https://www-user.tu-chemnitz.de/~heha/hs/chm/x86.chm/x86.htm</link><description>&lt;doc fingerprint="fb91fb8d464572e0"&gt;
  &lt;main&gt;Source: CIS-77 Home
http://www.c-jump.com/CIS77/CIS77syllabus.htm&lt;head rend="h1"&gt;Encoding x86 Instructions &lt;list rend="ul"&gt;&lt;item&gt;It is time to take a look that the actual machine instruction format of the x86 CPU family. &lt;/item&gt;&lt;item&gt;They don't call the x86 CPU a Complex Instruction Set Computer (CISC) for nothing! &lt;/item&gt;&lt;item&gt;Although more complex instruction encodings exist, no one is going to challenge that the x86 has a complex instruction encoding! &lt;/item&gt;&lt;/list&gt; 1. x86 Instructions Overview &lt;div&gt;&lt;p&gt; x86 Instruction Encoding: &lt;/p&gt;&lt;/div&gt; Although the diagram seems to imply that instructions can be up to 16 bytes long, in actuality the x86 will not allow instructions greater than 15 bytes in length.&lt;/head&gt;&lt;p&gt; The prefix bytes are not the opcode expansion prefix discussed earlier - they are special bytes to modify the behavior of existing instructions. &lt;/p&gt;&lt;head rend="h2"&gt;2. x86 Instruction Format Reference&lt;/head&gt;&lt;div&gt;&lt;p&gt; Another view of the x86 instruction format: &lt;/p&gt;&lt;/div&gt;Additional reference:&lt;head rend="h2"&gt;3. x86 Opcode Sizes&lt;/head&gt; The x86 CPU supports two basic opcode sizes: &lt;list rend="ol"&gt;&lt;item&gt;standard one-byte opcode &lt;/item&gt;&lt;item&gt;two-byte opcode consisting of a 0Fh opcode expansion prefix byte. &lt;lb/&gt;The second byte then specifies the actual instruction. &lt;/item&gt;&lt;/list&gt;&lt;list rend="ul"&gt;&lt;item&gt;The x86 opcode bytes are 8-bit equivalents of iii field that we discussed in simplified encoding. &lt;/item&gt;&lt;item&gt;This provides for up to 512 different instruction classes, although the x86 does not yet use them all. &lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;3.1. x86 ADD Instruction Opcode&lt;/head&gt;&lt;div&gt;&lt;p&gt; x86 ADD &lt;/p&gt;instruction opcode&lt;p&gt;:&lt;/p&gt;&lt;p&gt;Bit number one, marked d, specifies the direction of the data transfer: &lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;If d = 0 then the destination operand is a memory location, e.g. &lt;quote&gt; add [ebx], al&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;If d = 1 then the destination operand is a register, e.g. &lt;quote&gt; add al, [ebx]&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/div&gt;Bit number zero marked s specifies
the size of the operands the ADD instruction operates upon:&lt;list rend="ul"&gt;&lt;item&gt;If s = 0 then the operands are 8-bit registers and memory locations. &lt;/item&gt;&lt;item&gt;If s = 1 then the operands are either 16-bits or 32-bits: &lt;list rend="ul"&gt;&lt;item&gt;Under 32-bit operating systems the default is 32-bit operands if s = 1. &lt;/item&gt;&lt;item&gt;To specify a 16-bit operand (under Windows or Linux) you must insert a special operand-size prefix byte in front of the instruction (example of this later.) &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;lb/&gt;You'll soon see that this direction bit d creates a
problem that results in one instruction have two different possible
opcodes.&lt;head rend="h2"&gt;4. Encoding x86 Instruction Operands, MOD-REG-R/M Byte&lt;/head&gt; The MOD-REG-R/M byte specifies instruction operands and their addressing mode(*): &lt;div&gt;&lt;p&gt; The MOD field specifies x86 addressing mode:&lt;/p&gt;&lt;table&gt;&lt;row style="background:#C0C0C0"&gt;&lt;cell role="head"&gt;MOD&lt;/cell&gt;&lt;cell role="head"&gt;Meaning &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell align="center"&gt;00&lt;/cell&gt;&lt;cell&gt;Register indirect addressing mode or SIB with no displacement (when R/M = 100) or Displacement only addressing mode (when R/M = 101). &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell align="center"&gt;01&lt;/cell&gt;&lt;cell&gt;One-byte signed displacement follows addressing mode byte(s). &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell align="center"&gt;10&lt;/cell&gt;&lt;cell&gt;Four-byte signed displacement follows addressing mode byte(s). &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell align="center"&gt;11&lt;/cell&gt;&lt;cell&gt;Register addressing mode. &lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt; The REG field specifies source or destination register:&lt;/p&gt;&lt;table&gt;&lt;row style="background:#C0C0C0"&gt;&lt;cell role="head"&gt;REG Value &lt;/cell&gt;&lt;cell role="head"&gt;Register if data size is eight bits &lt;/cell&gt;&lt;cell role="head"&gt;Register if data size is 16-bits &lt;/cell&gt;&lt;cell role="head"&gt;Register if data size is 32 bits &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;000&lt;/cell&gt;&lt;cell&gt;al&lt;/cell&gt;&lt;cell&gt;ax&lt;/cell&gt;&lt;cell&gt;eax &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;001&lt;/cell&gt;&lt;cell&gt;cl&lt;/cell&gt;&lt;cell&gt;cx&lt;/cell&gt;&lt;cell&gt;ecx &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;010&lt;/cell&gt;&lt;cell&gt;dl&lt;/cell&gt;&lt;cell&gt;dx&lt;/cell&gt;&lt;cell&gt;edx &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;011&lt;/cell&gt;&lt;cell&gt;bl&lt;/cell&gt;&lt;cell&gt;bx&lt;/cell&gt;&lt;cell&gt;ebx &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;100&lt;/cell&gt;&lt;cell&gt;ah&lt;/cell&gt;&lt;cell&gt;sp&lt;/cell&gt;&lt;cell&gt;esp &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;101&lt;/cell&gt;&lt;cell&gt;ch&lt;/cell&gt;&lt;cell&gt;bp&lt;/cell&gt;&lt;cell&gt;ebp &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;110&lt;/cell&gt;&lt;cell&gt;dh&lt;/cell&gt;&lt;cell&gt;si&lt;/cell&gt;&lt;cell&gt;esi &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;111&lt;/cell&gt;&lt;cell&gt;bh&lt;/cell&gt;&lt;cell&gt;di&lt;/cell&gt;&lt;cell&gt;edi &lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt; The R/M field, combined with MOD, specifies either &lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;the second operand in a two-operand instruction, or &lt;/item&gt;&lt;item&gt;the only operand in a single-operand instruction like NOT or NEG. &lt;/item&gt;&lt;/list&gt;The d bit in the opcode determines which operand is
the source, and which is the destination:&lt;list class="n" rend="ul"&gt;&lt;item&gt;d=0: MOD R/M &amp;lt;- REG, REG is the source &lt;/item&gt;&lt;item&gt;d=1: REG &amp;lt;- MOD R/M, REG is the destination &lt;/item&gt;&lt;/list&gt;&lt;lb/&gt;(*) Technically, registers do not have an
address, but we apply the term addressing mode to registers
nonetheless.&lt;head rend="h2"&gt;5. General-Purpose Registers&lt;/head&gt;&lt;div&gt;&lt;p&gt; Since the processor accesses registers more quickly than it accesses memory, you can make your programs run faster by keeping the most-frequently used data in registers. &lt;/p&gt;&lt;/div&gt;&lt;list rend="ul"&gt;&lt;item&gt;The EAX, EDX, ECX, EBX, EBP, EDI, and ESI registers are 32-bit general-purpose registers, used for temporary data storage and memory access. &lt;/item&gt;&lt;item&gt;The AX, DX, CX, BX, BP, DI, and SI registers are 16-bit equivalents of the above, they represent the low-order 16 bits of 32-bit registers. &lt;/item&gt;&lt;item&gt;The AH, DH, CH, and BH registers represent the high-order 8 bits of the corresponding registers. &lt;/item&gt;&lt;item&gt;Similarly, AL, DL, CL, and BL represent the low-order 8 bits of the registers. &lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;6. REG Field of the MOD-REG-R/M Byte&lt;/head&gt; See MOD-REG-R/M Byte.&lt;p&gt; Depending on the instruction, this can be either the source or the destination operand.&lt;/p&gt;&lt;p&gt; Many instructions have the d (direction) field in their opcode to choose REG operand role: &lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;If d=0, REG is the source, &lt;lb/&gt;MOD R/M &amp;lt;- REG. &lt;/item&gt;&lt;item&gt;If d=1, REG is the destination, &lt;lb/&gt;REG &amp;lt;- MOD R/M. &lt;/item&gt;&lt;/list&gt;&lt;lb/&gt;(*) For certain (often single-operand or
immediate-operand) instructions, the REG field may contain an
opcode extension rather than the register bits. The
R/M field will specify the operand in such case.&lt;head rend="h3"&gt;9. MOD R/M Byte and Addressing Modes &lt;/head&gt;&lt;table&gt;&lt;row&gt;&lt;cell valign="top"&gt;&lt;quote&gt; MOD R/M Addressing Mode === === ================================ 00 000 [ eax ] 01 000 [ eax + disp8 ] (1) 10 000 [ eax + disp32 ] 11 000 register ( al / ax / eax ) (2) 00 001 [ ecx ] 01 001 [ ecx + disp8 ] 10 001 [ ecx + disp32 ] 11 001 register ( cl / cx / ecx ) 00 010 [ edx ] 01 010 [ edx + disp8 ] 10 010 [ edx + disp32 ] 11 010 register ( dl / dx / edx ) 00 011 [ ebx ] 01 011 [ ebx + disp8 ] 10 011 [ ebx + disp32 ] 11 011 register ( bl / bx / ebx ) 00 100 SIB Mode (3) 01 100 SIB + disp8 Mode 10 100 SIB + disp32 Mode 11 100 register ( ah / sp / esp ) 00 101 32-bit Displacement-Only Mode (4) 01 101 [ ebp + disp8 ] 10 101 [ ebp + disp32 ] 11 101 register ( ch / bp / ebp ) 00 110 [ esi ] 01 110 [ esi + disp8 ] 10 110 [ esi + disp32 ] 11 110 register ( dh / si / esi ) 00 111 [ edi ] 01 111 [ edi + disp8 ] 10 111 [ edi + disp32 ] 11 111 register ( bh / di / edi ) &lt;cell valign="top"&gt;&lt;list rend="ol"&gt;&lt;item&gt;Addressing modes with 8-bit displacement fall in the range -128..+127 and require only a single byte displacement after the opcode (Faster!) &lt;/item&gt;&lt;item&gt;The size bit in the opcode specifies 8 or 32-bit register size. To select a 16-bit register requires a prefix byte. &lt;/item&gt;&lt;item&gt;The so-called scaled indexed addressing modes, SIB = scaled index byte mode. &lt;/item&gt;&lt;item&gt;Note that there is no [ ebp ] addressing. It's slot is occupied by the 32-bit displacement only addressing mode. Intel decided that programmers can use [ ebp+ disp8 ] addressing mode instead, with its 8-bit displacement set equal to zero (instruction is a little longer, though.) &lt;/item&gt;&lt;/list&gt;&lt;/cell&gt;&lt;/quote&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head rend="h2"&gt;8. SIB (Scaled Index Byte) Layout&lt;/head&gt;&lt;div&gt;&lt;p&gt; Scaled index byte layout:&lt;/p&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;table&gt;&lt;row style="background:#C0C0C0"&gt;&lt;cell role="head"&gt;Scale Value&lt;/cell&gt;&lt;cell role="head"&gt;Index*Scale Value &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell align="center"&gt;00&lt;/cell&gt;&lt;cell&gt;Index*1 &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell align="center"&gt;01&lt;/cell&gt;&lt;cell&gt;Index*2 &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell align="center"&gt;10&lt;/cell&gt;&lt;cell&gt;Index*4 &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell align="center"&gt;11&lt;/cell&gt;&lt;cell&gt;Index*8 &lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/cell&gt;&lt;cell&gt;&lt;table&gt;&lt;row style="background:#C0C0C0"&gt;&lt;cell role="head"&gt;Index&lt;/cell&gt;&lt;cell role="head"&gt;Register &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;000&lt;/cell&gt;&lt;cell&gt;EAX &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;001&lt;/cell&gt;&lt;cell&gt;ECX &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;010&lt;/cell&gt;&lt;cell&gt;EDX &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;011&lt;/cell&gt;&lt;cell&gt;EBX &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;100&lt;/cell&gt;&lt;cell&gt;Illegal &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;101&lt;/cell&gt;&lt;cell&gt;EBP &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;110&lt;/cell&gt;&lt;cell&gt;ESI &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;111&lt;/cell&gt;&lt;cell&gt;EDI &lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/cell&gt;&lt;cell&gt;&lt;table&gt;&lt;row style="background:#C0C0C0"&gt;&lt;cell role="head"&gt;Base&lt;/cell&gt;&lt;cell role="head"&gt;MOD&lt;/cell&gt;&lt;cell role="head"&gt;Register &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;000&lt;/cell&gt;&lt;cell&gt;xx&lt;/cell&gt;&lt;cell&gt;EAX &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;001&lt;/cell&gt;&lt;cell&gt;xx&lt;/cell&gt;&lt;cell&gt;ECX &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;010&lt;/cell&gt;&lt;cell&gt;xx&lt;/cell&gt;&lt;cell&gt;EDX &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;011&lt;/cell&gt;&lt;cell&gt;xx&lt;/cell&gt;&lt;cell&gt;EBX &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;100&lt;/cell&gt;&lt;cell&gt;xx&lt;/cell&gt;&lt;cell&gt;ESP &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2"&gt;101&lt;/cell&gt;&lt;cell&gt;00&lt;/cell&gt;&lt;cell&gt;Displacement-only &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;01, 10&lt;/cell&gt;&lt;cell&gt;EBP &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;110&lt;/cell&gt;&lt;cell&gt;xx&lt;/cell&gt;&lt;cell&gt;ESI &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;111&lt;/cell&gt;&lt;cell&gt;xx&lt;/cell&gt;&lt;cell&gt;EDI &lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/div&gt;&lt;list rend="ul"&gt;&lt;item&gt;Scaled indexed addressing mode uses the second byte (namely, SIB byte) that follows the MOD-REG-R/M byte in the instruction format. &lt;/item&gt;&lt;item&gt;The MOD field still specifies the displacement size of zero, one, or four bytes. &lt;list class="n" rend="ul"&gt;&lt;item&gt;The MOD-REG-R/M and SIB bytes are complex, because Intel reused 16-bit addressing circuitry in the 32-bit mode, rather than simply abandoning the 16-bit format in the 32-bit mode. &lt;/item&gt;&lt;item&gt;There are good hardware reasons for this, but the end result is a complex scheme for specifying addressing modes in the opcodes. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;8.1. Scaled Indexed Addressing Mode&lt;/head&gt;&lt;table&gt;&lt;row valign="top"&gt;&lt;cell&gt;&lt;quote&gt; [ reg32 + eax*n ] MOD = 00 [ reg32 + ebx*n ] [ reg32 + ecx*n ] [ reg32 + edx*n ] [ reg32 + ebp*n ] [ reg32 + esi*n ] [ reg32 + edi*n ] [ disp + reg8 + eax*n ] MOD = 01 [ disp + reg8 + ebx*n ] [ disp + reg8 + ecx*n ] [ disp + reg8 + edx*n ] [ disp + reg8 + ebp*n ] [ disp + reg8 + esi*n ] [ disp + reg8 + edi*n ] [ disp + reg32 + eax*n ] MOD = 10 [ disp + reg32 + ebx*n ] [ disp + reg32 + ecx*n ] [ disp + reg32 + edx*n ] [ disp + reg32 + ebp*n ] [ disp + reg32 + esi*n ] [ disp + reg32 + edi*n ] [ disp + eax*n ] MOD = 00, and [ disp + ebx*n ] BASE field = 101 [ disp + ecx*n ] [ disp + edx*n ] [ disp + ebp*n ] [ disp + esi*n ] [ disp + edi*n ] &lt;cell&gt; Note: n = 1, 2, 4, or 8.&lt;p&gt; In each scaled indexed addressing mode the MOD field in MOD-REG-R/M byte specifies the size of the displacement. It can be zero, one, or four bytes:&lt;/p&gt;&lt;quote&gt; MOD R/M Addressing Mode --- --- --------------------------- 00 100 SIB 01 100 SIB + disp8 10 100 SIB + disp32 &lt;/quote&gt; The Base and Index fields of the SIB byte select the base and index registers, respectively.&lt;p&gt; Note that this addressing mode does not allow the use of the ESP register as an index register. Presumably, Intel left this particular mode undefined to provide the ability to extend the addressing modes in a future version of the CPU. &lt;/p&gt;&lt;/cell&gt;&lt;/quote&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head rend="h2"&gt;9. Examples&lt;/head&gt;&lt;head rend="h3"&gt;9.1. Encoding ADD Instruction Example&lt;/head&gt;&lt;list class="n" rend="ul"&gt;&lt;item&gt;&lt;p&gt;The ADD opcode can be decimal 0, 1, 2, or 3, depending on the direction and size bits in the opcode: &lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;How could we encode various forms of the ADD instruction using different addressing modes? &lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;9.2 Encoding ADD CL, AL Instruction&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Interesting side effect of the direction bit and the MOD-REG-R/M byte organization: some instructions can have two different opcodes, and both are legal! &lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;For example, encoding of &lt;/p&gt;&lt;quote&gt; add cl, al &lt;/quote&gt;&lt;p&gt;could be 00 C1 (if d=0), or 02 C8, if d bit is set to 1. &lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The possibility of opcode duality issue here applies to all instructions with two register operands. &lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;9.3. Encoding ADD ECX, EAX Instruction&lt;/head&gt;&lt;head rend="h3"&gt;9.4. Encoding ADD EDX, DISPLACEMENT Instruction&lt;/head&gt;&lt;head rend="h3"&gt;9.5. Encoding ADD EDI, [EBX] Instruction&lt;/head&gt;&lt;head rend="h3"&gt;9.6. Encoding ADD EAX, [ ESI + disp8 ] Instruction&lt;/head&gt;&lt;head rend="h3"&gt;9.7. Encoding ADD EBX, [ EBP + disp32 ] Instruction&lt;/head&gt;&lt;list class="n" rend="ul"&gt;&lt;item&gt;&lt;p&gt;Encoding the ADD EBX, [ EBP + disp32 ] instruction: &lt;/p&gt;&lt;quote&gt; add ebx, [ ebp + disp32 ] &lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;9.8. Encoding ADD EBP, [ disp32 + EAX*1 ] Instruction&lt;/head&gt;&lt;list class="n" rend="ul"&gt;&lt;item&gt;&lt;p&gt;Encoding the ADD EBP, [ disp32 + EAX*1 ] Instruction &lt;/p&gt;&lt;quote&gt; add ebp, [ disp32 + eax*1 ] &lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;9.9. Encoding ADD ECX, [ EBX + EDI*4 ] Instruction&lt;/head&gt;&lt;head rend="h2"&gt;10. Encoding ADD Immediate Instruction&lt;/head&gt;&lt;div&gt;&lt;p&gt; Encoding x86 immediate operands: &lt;/p&gt;&lt;/div&gt;MOD-REG-R/M and SIB bytes have no
bit combinations to specify an immediate operand.&lt;p&gt; Instead, x86 uses a entirely different instruction format to specify instruction with an immediate operand.&lt;/p&gt;&lt;p&gt; There are three rules that apply: &lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;If opcode high-order bit set to 1, then instruction has an immediate constant. &lt;/item&gt;&lt;item&gt;There is no direction bit in the opcode: &lt;list class="n" rend="ul"&gt;&lt;item&gt;: indeed, you cannot specify a constant as a destination operand! &lt;/item&gt;&lt;item&gt;Therefore, destination operand is always the location encoded in the MOD-R/M bits of the the MOD-REG-R/M byte. &lt;/item&gt;&lt;item&gt;In place of the direction bit d, the opcode has a sign extension x bit instead: &lt;list rend="ul"&gt;&lt;item&gt;For 8-bit operands, the CPU ignores x bit. &lt;/item&gt;&lt;item&gt;For 16-bit and 32-bit operands, x bit specifies the size of the Constant following at the end of the instruction: &lt;list rend="ul"&gt;&lt;item&gt;If x bit contains zero, the Constant is the same size as the operand (i.e., 16 or 32 bits). &lt;/item&gt;&lt;item&gt;If x bit contains one, the Constant is a signed 8-bit value, and the CPU sign-extends this value to the appropriate size before adding it to the operand. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;This little x trick often makes programs shorter, because adding small-value constants to 16 or 32 bit operands is very common. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;The third difference between the ADD-immediate and the standard ADD instruction is the meaning of the REG field in the MOD-REG-R/M byte: &lt;list rend="ul"&gt;&lt;item&gt;Since the instruction implies that &lt;list rend="ul"&gt;&lt;item&gt;the source operand is a constant, and &lt;/item&gt;&lt;item&gt;MOD-R/M fields specify the destination operand, &lt;/item&gt;&lt;/list&gt; the instruction does not need to use the REG field to specify an operand. &lt;/item&gt;&lt;item&gt;Instead, the x86 CPU uses these three bits as an opcode extension. &lt;/item&gt;&lt;item&gt;For the ADD-immediate instruction the REG bits must contain zero. &lt;/item&gt;&lt;item&gt;Other bit patterns would correspond to a different instruction. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt; Note that when adding a constant to a memory location, the displacement (if any) immediately precedes the immediate (constant) value in the opcode sequence. &lt;/quote&gt;&lt;head rend="h2"&gt;11. Encoding Eight, Sixteen, and Thirty-Two Bit Operands&lt;/head&gt;&lt;div&gt;&lt;p&gt; x86 ADD Opcode: &lt;/p&gt;&lt;/div&gt;&lt;list class="n" rend="ul"&gt;&lt;item&gt;When Intel designed the 8086, one bit in the opcode, s, selected between 8 and 16 bit integer operand sizes. &lt;/item&gt;&lt;item&gt;Later, when CPU added 32-bit integers to its architecture on 80386 chip, there was a problem: &lt;list class="n" rend="ul"&gt;&lt;item&gt;three encodings were needed to support 8, 16, and 32 bit sizes. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Solution was an operand size prefix byte. &lt;/item&gt;&lt;item&gt;Intel studied x86 instruction set and came to the conclusion: &lt;list class="n" rend="ul"&gt;&lt;item&gt;in a 32-bit environment, programs were more likely to use 8-bit and 32-bit operands far more often than 16-bit operands. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;So Intel decided to let the size bit s in the opcode select between 8- and 32-bit operands. &lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;11.1. Encoding Sixteen Bit Operands&lt;/head&gt;&lt;div&gt;&lt;p&gt; x86 instruction format: &lt;/p&gt;&lt;/div&gt;32-bit programs don't use 16-bit operands that often, but they do
need them now and then.&lt;p&gt; To allow for 16-bit operands, Intel added prefix a 32-bit mode instruction with the operand size prefix byte with value 66h.&lt;/p&gt;&lt;p&gt; This prefix byte tells the CPU to operand on 16-bit data rather than 32-bit data. &lt;/p&gt;&lt;head rend="h2"&gt;12. x86 Instruction Prefix Bytes&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;x86 instruction can have up to 4 prefixes. &lt;/item&gt;&lt;item&gt;Each prefix adjusts interpretation of the opcode: &lt;list rend="ol"&gt;&lt;item&gt;Repeat/lock prefix byte guarantees that instruction will have exclusive use of all shared memory, until the instruction completes execution:&lt;quote&gt; F0h = LOCK&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;String manipulation instruction prefixes&lt;quote&gt; F3h = REP, REPE F2h = REPNE&lt;/quote&gt; where &lt;list rend="ul"&gt;&lt;item&gt;REP repeats instruction the number of times specified by iteration count ECX. &lt;/item&gt;&lt;item&gt;REPE and REPNE prefixes allow to terminate loop on the value of ZF CPU flag. &lt;/item&gt;&lt;/list&gt; Related string manipulation instructions are: &lt;list rend="ul"&gt;&lt;item&gt;MOVS, move string &lt;/item&gt;&lt;item&gt;STOS, store string &lt;/item&gt;&lt;item&gt;SCAS, scan string &lt;/item&gt;&lt;item&gt;CMPS, compare string, etc. &lt;/item&gt;&lt;/list&gt; See also string manipulation sample program: rep_movsb.asm &lt;/item&gt;&lt;item&gt;Segment override prefix causes memory access to use specified segment instead of default segment designated for instruction operand.&lt;quote&gt; 2Eh = CS 36h = SS 3Eh = DS 26h = ES 64h = FS 65h = GS&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Operand override, 66h. Changes size of data expected by default mode of the instruction e.g. 16-bit to 32-bit and vice versa. &lt;/item&gt;&lt;item&gt;Address override, 67h. Changes size of address expected by the instruction. 32-bit address could switch to 16-bit and vice versa. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;13. Alternate Encodings for Instructions&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;To shorten program code, Intel created alternate (shorter) encodings of some very commonly used instructions. &lt;/item&gt;&lt;item&gt;For example, x86 provides a single byte opcode for&lt;quote&gt; add al, constant ; one-byte opcode and no MOD-REG-R/M byte add eax, constant ; one-byte opcode and no MOD-REG-R/M byte&lt;/quote&gt; the opcodes are 04h and 05h, respectively. Also, &lt;/item&gt;&lt;item&gt;These instructions are one byte shorter than their standard ADD immediate counterparts. &lt;/item&gt;&lt;item&gt;Note that&lt;quote&gt; add ax, constant ; operand size prefix byte + one-byte opcode, no MOD-REG-R/M byte&lt;/quote&gt; requires an operand size prefix just as a standard ADD AX, constant instruction, yet is still one byte shorter than the corresponding standard version of ADD immediate. &lt;/item&gt;&lt;item&gt;Any decent assembler will automatically choose the shortest possible instruction when translating program into machine code. &lt;/item&gt;&lt;item&gt;Intel only provides alternate encodings only for the accumulator registers AL, AX, EAX. &lt;/item&gt;&lt;item&gt;This is a good reason to use accumulator registers if you have a choice &lt;quote&gt; (also a good reason to take some time and study encodings of the x86 instructions.) &lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;14. x86 Opcode Summary&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;x86 opcodes are represented by one or two bytes. &lt;/item&gt;&lt;item&gt;Opcode could extend into unused bits of MOD-REG-R/M byte. &lt;/item&gt;&lt;item&gt;Opcode encodes information about &lt;list rend="ul"&gt;&lt;item&gt;operation type, &lt;/item&gt;&lt;item&gt;operands, &lt;/item&gt;&lt;item&gt;size of each operand, including the size of an immediate operand. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;14.1. MOD-REG-R/M Byte Summary&lt;/head&gt;&lt;div&gt;&lt;p&gt; MOD-REG-R/M Byte: &lt;/p&gt;&lt;/div&gt;&lt;list rend="ul"&gt;&lt;item&gt;MOD-REG-R/M byte follows one or two opcode bytes of the instruction &lt;/item&gt;&lt;item&gt;It provides addressing mode information for one or two operands. &lt;/item&gt;&lt;item&gt;If operand is in memory, or operand is a register: &lt;list rend="ul"&gt;&lt;item&gt;MOD field (bits [7:6]), combined with the R/M field (bits [2:0]), specify memory/register operand, as well as its addressing mode. &lt;/item&gt;&lt;item&gt;REG field (bits [5:3]) specifies another register operand in of the two-operand instruction. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;15. ISA Design Considerations&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Instruction set architecture design that can stand the test of time is a true intellectual challenge. &lt;/item&gt;&lt;item&gt;It takes several compromises between space and efficiency to assign opcodes and encode instruction formats. &lt;/item&gt;&lt;item&gt;Today people are using Intel x86 instruction set for purposes never intended by original designers. &lt;/item&gt;&lt;item&gt;Extending the CPU is a very difficult task. &lt;/item&gt;&lt;item&gt;The instruction set can become extremely complex. &lt;/item&gt;&lt;item&gt;If x86 CPU was designed from scratch today, it would have a totally different ISA! &lt;/item&gt;&lt;item&gt;Software developers usually don't have a problem adapting to a new architecture when writing new software... &lt;quote&gt; ...but they are very resistant to moving existing software from one platform to another. &lt;/quote&gt;&lt;/item&gt;&lt;item&gt;This is the primary reason the Intel x86 platform remains so popular to this day. &lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;15.1. ISA Design Challenges &lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Allowing for future expansion of the chip requires some undefined opcodes. &lt;/item&gt;&lt;item&gt;From the beginning there should be a balance between the number of undefined opcodes and &lt;list rend="ol"&gt;&lt;item&gt;the number of initial instructions, and &lt;/item&gt;&lt;item&gt;the size of your opcodes (including special assignments.) &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Hard decisions: &lt;list rend="ul"&gt;&lt;item&gt;Reduce the number of instructions in the initial instruction set? &lt;/item&gt;&lt;item&gt;Increase the size of the opcode? &lt;/item&gt;&lt;item&gt;Rely on an opcode prefix byte(s), which makes later added instructions longer? &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;There are no easy answers to these challenges for CPU designers! &lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;16. Intel Architecture Software Developer's Manual&lt;/head&gt; Classic Intel Pentium II Architecture Software Developer's Manual contains three parts: &lt;list rend="ol"&gt;&lt;item&gt;Volume 1 , Intel Basic Architecture: Order Number 243190 , PDF, 2.6 MB. &lt;/item&gt;&lt;item&gt;Volume 2 , Instruction Set Reference: Order Number 243191 , PDF, 6.6 MB. &lt;/item&gt;&lt;item&gt;Volume 3 , System Programing Guide: Order Number 243192 , PDF, 5.1 MB. &lt;/item&gt;&lt;/list&gt;It is highly recommended that you download the above manuals and use them
as a reference.&lt;head rend="h3"&gt;16.1. Intel Instruction Set Reference (Volume2)&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Chapter 3 of the Instruction Set Reference describes &lt;list rend="ul"&gt;&lt;item&gt;each Intel instruction in detail &lt;/item&gt;&lt;item&gt;algorithmic description of each operation &lt;/item&gt;&lt;item&gt;effect on flags &lt;/item&gt;&lt;item&gt;operand(s), their sizes and attributes &lt;/item&gt;&lt;item&gt;CPU exceptions that may be generated. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;The instructions are arranged in alphabetical order. &lt;/item&gt;&lt;item&gt;Appendix A provides opcode map for the entire Intel Architecture instruction set. &lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;16.2. Chapter 3 of Intel Instruction Set Reference&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Chapter 3 begins with instruction format example and explains the Opcode column encoding. &lt;/item&gt;&lt;item&gt;The Opcode column gives the complete machine codes as it is understood by the CPU. &lt;/item&gt;&lt;item&gt;When possible, the actual machine code bytes are given as exact hexadecimal bytes, in the same order in which they appear in memory. &lt;/item&gt;&lt;item&gt;However, there are opcode definitions other than hexadecimal bytes... &lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;16.3. Intel Reference Opcode Bytes&lt;/head&gt;&lt;list class="n" rend="ul"&gt;&lt;item&gt;Fow example, &lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;16.4. Intel Reference Opcode Bytes, Cont.&lt;/head&gt;&lt;head rend="h3"&gt;16.5. Intel Reference Opcode Bytes, Cont.&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;/r - Indicates that the instruction uses the Mod R/M byte of the instruction. &lt;/item&gt;&lt;item&gt;Mod R/M byte contains both &lt;list rend="ul"&gt;&lt;item&gt;a register operand reg and &lt;/item&gt;&lt;item&gt;an r/m (register or memory) operand. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;16.6. Intel Reference Opcode Bytes, Cont. &lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;cb, cw, cd, cp - A 1-byte (cb), 2-byte (cw), 4-byte (cd), or 6-byte (cp) value, &lt;lb/&gt;following the opcode, is used to specify &lt;list rend="ul"&gt;&lt;item&gt;a code offset, &lt;/item&gt;&lt;item&gt;and possibly a new value for the code segment register CS. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;16.7. Intel Reference Opcode Bytes, Cont.&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;ib, iw, id - A 1-byte (ib), 2-byte (iw), or 4-byte (id) indicates presence of the immediate operand in the instruction. &lt;/item&gt;&lt;item&gt;Typical order of opcode bytes is &lt;list rend="ul"&gt;&lt;item&gt;opcode &lt;/item&gt;&lt;item&gt;Mod R/M byte (optional) &lt;/item&gt;&lt;item&gt;SIB scale-indexing byte (optional) &lt;/item&gt;&lt;item&gt;immediate operand. &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;The opcode determines if the operand is a signed value. &lt;/item&gt;&lt;item&gt;All words and doublewords are given with the low-order byte first (little endian). &lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;16.8. Intel Reference Opcode Bytes, Cont.&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;+rb, +rw, +rd - A register code, from 0 through 7, added to the hexadecimal byte given at the left of the plus sign to form a single opcode byte. &lt;/item&gt;&lt;item&gt;Register Encodings Associated with the +rb, +rw, and +rd: &lt;p&gt;For example, &lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;16.9. Intel Reference Instruction Column&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;The Instruction column gives the syntax of the instruction statement as it would appear in a 386 Assembly program. &lt;/item&gt;&lt;item&gt;For example, &lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45750501</guid><pubDate>Wed, 29 Oct 2025 17:50:21 +0000</pubDate></item><item><title>Extropic is building thermodynamic computing hardware</title><link>https://extropic.ai/</link><description>&lt;doc fingerprint="27b6766c759d22ac"&gt;
  &lt;main&gt;
    &lt;p&gt;Thermodynamic Computing: From 0 to 1 (Launch Video)&lt;/p&gt;
    &lt;p&gt;October 30th, 2025&lt;/p&gt;
    &lt;p&gt;Extropic is building thermodynamic computing hardware that is radically more energy efficient than GPUs.&lt;/p&gt;
    &lt;p&gt;Our thermodynamic sampling units (TSUs) are inherently probabilistic, the perfect fit for probabilistic AI workloads.&lt;/p&gt;
    &lt;p&gt;Hardware&lt;/p&gt;
    &lt;p&gt;prototype platform&lt;/p&gt;
    &lt;p&gt;XTR-0 enables the development of ultra-efficient AI algorithms by providing low-latency communication between Extropic chips and a traditional processor.&lt;/p&gt;
    &lt;p&gt;Software&lt;/p&gt;
    &lt;p&gt;Our open-source Python library that enables everyone to develop thermodynamic algorithms and simulate running them on TSUs&lt;/p&gt;
    &lt;p&gt;We are hiring engineers and scientists to help us pioneer a new form of computing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45750995</guid><pubDate>Wed, 29 Oct 2025 18:25:01 +0000</pubDate></item></channel></rss>