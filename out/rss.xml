<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 25 Jan 2026 21:10:00 +0000</lastBuildDate><item><title>Sony Data Discman</title><link>https://huguesjohnson.com/random/sony-ebook/</link><description>&lt;doc fingerprint="bb65194d5c9f2bbb"&gt;
  &lt;main&gt;
    &lt;p&gt;Introduction&lt;/p&gt;
    &lt;p&gt;Back in 1992 I worked at an Electronics Boutique that was an outlet location for the company. We sold regular merchandise but also had an outlet section for clearance stuff aggregated from other stores. This thoroughly confused customers who expected every item in the store to be discounted. The job involved a lot of explaining "no I'm sorry this game that literally launched today is not on clearance". Working retail is a great way to lose faith in the collective intelligence of our species.&lt;/p&gt;
    &lt;p&gt;One day we received several Sony Data Discman Electronic Book Player DD-1EX players that we were supposed to clear out. The original sticker price was $500 but they were marked down to roughly 1% of that. Largely out of curiosity I picked one up along with whatever software we had for it (also at a massive discount). I can't say I've used it for more than an hour. It's a very nice device that serves no practical or entertainment function whatsoever.&lt;/p&gt;
    &lt;p&gt;Using old catalogs as a reference, these were originally listed in the spring 1992 catalog. Here it is:&lt;/p&gt;
    &lt;p&gt;These did not appear in the summer 1992 catalog just a couple months later. Since I started working there during the 1992 holiday season the timeline works out. They must have hit the shelves in early 1992, not sold, then been marked down every month until they were rounded-up and shipped to our location.&lt;/p&gt;
    &lt;p&gt;Let's take a peek at it..&lt;/p&gt;
    &lt;p&gt;Gallery&lt;/p&gt;
    &lt;p&gt;Disclaimer: I am terrible at taking pictures.&lt;/p&gt;
    &lt;p&gt;Sony didn't nickel-and-dime consumers on accessories here. The package came with: the reader (duh), AC adapter, rechargeable battery, and another battery pack that holds AAs. Years later they refused to include an AC adapter in the PlayStation Classic.&lt;/p&gt;
    &lt;p&gt;The reader itself is fairly nice looking. It feels like a miniature laptop. It's a tad on the heavy side but also feels extremely durable. Looking at all the buttons and size of the screen makes me think this had a lot of potential beyond just electronic books. However, it lacks any mechanism to save data. In the early 90s it's not like SD-RAM cards were available. Miniature hard drive? Forget it. It has 90% of what it needs to be a PDA but the technology just wasn't there to get the last 10% in.&lt;/p&gt;
    &lt;p&gt;There's a QWERTY keyboard because all of the books are searchable. The directional pad is there to navigate through menus. Looking at it again just makes me irritated that I don't have any games for this (of course I doubt any were made). This would make a cool little text adventure player.&lt;/p&gt;
    &lt;p&gt;The electronic books are mini CDs in a caddy. I guess that means we can rip them (more on this soon).&lt;/p&gt;
    &lt;p&gt;Bad Screenshots&lt;/p&gt;
    &lt;p&gt;I picked up every electronic book we had in stock. The player has an output jack than can be connected to anything with an A/V input (well, just the "V" part is needed). These screenshots are from the A/V out.&lt;/p&gt;
    &lt;p&gt;The splash screen reminding you that this is for private use only. I guess I'm technically violating that, whatever.&lt;/p&gt;
    &lt;p&gt;Although I don't know the exact date this electronic book reader was produced, the bundled encyclopedia gives some hints. It still lists U.S.S.R. as a country so it had to be authored prior to Christmas day 1991.&lt;/p&gt;
    &lt;p&gt;Early 90s software developer salary in the career guide:&lt;/p&gt;
    &lt;p&gt;Thinking of traveling the world? Well, this handy translator is all you need. Someone once told me that if you ever got lost in a strange foreign country you should claim to be a Swedish citizen. Something about Sweden having an embassy in every country and nobody holding a grudge against them. I couldn't find a translation for "I'm a Swedish citizen please don't turn me over to the secret police" in this guide.&lt;/p&gt;
    &lt;p&gt;The least useful book (to me at least) is the crossword dictionary. You can search for word endings or a list of complete words but that's it.&lt;/p&gt;
    &lt;p&gt;The wellness encyclopedia is the perfect gift for a hypochondriac.&lt;/p&gt;
    &lt;p&gt;Since I won't pay more than $3.99 for a bottle of wine I found this guide relatively useless.&lt;/p&gt;
    &lt;p&gt;Ripping the CDs&lt;/p&gt;
    &lt;p&gt;If you rip the CDs you'll find that some of them contain an emulator for the Discman. Here's the wine guide main screen:&lt;/p&gt;
    &lt;p&gt;It seems like the books are fully functional in this emulator:&lt;/p&gt;
    &lt;p&gt;The career guide also comes with an emulator. You can use it to look for jobs that didn't exist in 1990 I guess:&lt;/p&gt;
    &lt;p&gt;Some CDs, like the encyclopedia, don't have the emulator bundled. However, if you copy the data files around it's trivial to launch it in the emulator bundled on the other CDs:&lt;/p&gt;
    &lt;p&gt;iso Downloads&lt;/p&gt;
    &lt;p&gt;Grab these before I receive a takedown notice.. I mean, these were completely obsolete before Wikipedia existed and are even worse after. I doubt that will stop anyone though. One of the reasons I deleted my YouTube videos was takedown notices from Sony over the intro to Dragon's Lair. Some rapper who sold &amp;lt;100 albums, but is apparently signed with Sony, sampled the intro of Dragon's Lair. In Sony's mind that means they own all rights to it. I don't know how you rap over the Dragon's Lair intro and I don't care to learn. EA also sent me a takedown notice over a Dragon's Lair video, a game they neither wrote nor own the rights to. As far as I can tell they at some point were the distributor for an early iOS version of Dragon's Lair that is no longer available. So to make a long story short, I'm sure these will be offline soon. When that happens I'll try moving them to archive.org since they are somehow able to get away with posting anything.&lt;/p&gt;
    &lt;p&gt;Career encyclopedia (SROM30_VERSION1)&lt;/p&gt;
    &lt;p&gt;Crossword dictionary (SROM13V1_07D)&lt;/p&gt;
    &lt;p&gt;Wellness encyclopedia (SROM25_V1_0)&lt;/p&gt;
    &lt;p&gt;World translator (SROM29_VERSION1)&lt;/p&gt;
    &lt;p&gt;Usual disclaimer that you are downloading isos with executable files from a total rando's site. I am 100% not responsible for any awful thing that happens if you download these and run the files on them.&lt;/p&gt;
    &lt;p&gt;Related&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46751906</guid><pubDate>Sun, 25 Jan 2026 08:23:51 +0000</pubDate></item><item><title>A flawed paper in Management Science has been cited more than 6,000 times</title><link>https://statmodeling.stat.columbia.edu/2026/01/22/aking/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46752151</guid><pubDate>Sun, 25 Jan 2026 09:04:30 +0000</pubDate></item><item><title>Jurassic Park - Tablet device on Nedry's desk? (2012)</title><link>https://www.therpf.com/forums/threads/jurassic-park-tablet-device-on-nedrys-desk.169883/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46752261</guid><pubDate>Sun, 25 Jan 2026 09:22:17 +0000</pubDate></item><item><title>Bridging the Gap Between PLECS and SPICE</title><link>https://erickschulz.dev/posts/plecs-spice/</link><description>&lt;doc fingerprint="351921528b158f82"&gt;
  &lt;main&gt;
    &lt;p&gt;Three years ago, we set out to bring SPICE simulation into PLECS. PLECS Spice is finally here.&lt;/p&gt;
    &lt;p&gt;PLECS Spice brings SPICE device-level simulation directly into PLECS. Available with PLECS 5.0, both system-level and device-level analysis can be performed within a single tool, eliminating the need to maintain duplicate models across separate softwares.&lt;/p&gt;
    &lt;head rend="h2"&gt;Separate Tools, Duplicate Work&lt;/head&gt;
    &lt;p&gt;Power electronics design has long faced a fundamental trade-off: system-level simulation tools deliver the speed and robustness needed for controller development and overall system analysis, but sacrifice the device-level detail necessary to validate component selection before procurement.&lt;/p&gt;
    &lt;p&gt;For over 20 years, Plexim has promoted a top-down design philosophy, enabling engineers to model complete power electronic systems using ideal switches and behavioral components. By avoiding the computational burden of simulating detailed switching transients, PLECS enables rapid validation of system-level requirements like efficiency, control performance and thermal behavior.&lt;/p&gt;
    &lt;p&gt;Conversely, traditional SPICE simulators embody an inherently bottom-up approach. They excel at validating device-level requirements through detailed semiconductor models, capturing switching losses, voltage overshoots and parasitic effects with high fidelity. This comes at a cost: system-level integration becomes computationally prohibitive.&lt;/p&gt;
    &lt;p&gt;This divide has forced engineers into parallel workflows using separate software platforms with different modeling approaches and incompatible component libraries. Moving from a system-level PLECS model to SPICE for device validation requires recreating the model, an error-prone and time-consuming process.&lt;/p&gt;
    &lt;head rend="h2"&gt;PLECS Spice&lt;/head&gt;
    &lt;p&gt;To solve this problem, Plexim has developed PLECS Spice, an extension that brings SPICE device-level simulation capabilities directly into PLECS. PLECS Spice can simulate hybrid systems containing both standard PLECS and SPICE circuits. This allows a schematic to be progressively refined by replacing the ideal switches in a circuit of interest, like the power stage, with detailed SPICE netlists. Controls and other subsystems can remain unchanged. Because the entire workflow stays within PLECS, engineers can easily toggle between ideal and detailed configurations to compare results. This creates a true top-down workflow where device-level detail is added selectively, only where needed. With PLECS Spice, there is no longer a need to build the same model twice.&lt;/p&gt;
    &lt;head rend="h2"&gt;Under the Hood&lt;/head&gt;
    &lt;p&gt;The PLECS Spice extension adds four key ingredients that transform PLECS into a fully-featured hybrid simulation platform that can simulate standard PLECS and SPICE models together.&lt;/p&gt;
    &lt;head rend="h3"&gt;Netlist Parser&lt;/head&gt;
    &lt;p&gt;SPICE models are typically distributed as netlists. Simply put, these are text files that describe a circuit topology, component interconnections and parameter values. A key capability of PLECS Spice is its parser’s support for multiple netlist dialects. Different SPICE implementations use distinct syntax conventions, making netlists from various vendors incompatible. The PLECS Spice parser handles these variations automatically, enabling engineers to integrate models provided by different semiconductor manufacturers directly into their schematics. Little to no manual conversion or syntax adaptation is needed, regardless of the dialect.&lt;/p&gt;
    &lt;head rend="h3"&gt;Compact Models&lt;/head&gt;
    &lt;p&gt;Netlists provided by manufacturers often rely on well-established semiconductor device models. These compact models combine physics-based modeling with empirical corrections to capture fundamental electrical behavior while maintaining reasonable complexity. PLECS Spice includes optimized implementations of compact models such as diodes, MOSFETs, BJTs, and switches. Each model defines a set of parameters that can be tuned to match the electrical response of specific physical devices. In PLECS Spice, classical compact models have been improved to guarantee continuity of key physical quantities, enhancing numerical stability. By tightly integrating these models into the solver, PLECS Spice achieves both computational efficiency and robust convergence even in the presence of highly nonlinear semiconductor characteristics.&lt;/p&gt;
    &lt;head rend="h3"&gt;Modified Nodal Analysis&lt;/head&gt;
    &lt;p&gt;Standard PLECS uses piecewise state-space equations to simulate electrical models. This approach is computationally efficient for circuits with mostly linear components but struggles with the strong nonlinearities present in detailed semiconductor models. To handle these nonlinearities, SPICE uses Modified Nodal Analysis (MNA), a formulation that produces differential algebraic equations (DAEs).&lt;/p&gt;
    &lt;p&gt;MNA constructs the circuit equations by applying Kirchhoff’s current law at each node and substituting component branch equations. Energy storage elements introduce differential equations, while the network topology and sources introduce algebraic constraints. The result is a coupled system where nodal voltages, source currents, and energy storage currents must satisfy both differential and algebraic equations simultaneously. This integrated treatment of constraints and dynamics is what makes MNA particularly robust for nonlinear semiconductor models.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mixed-Formulation Solver&lt;/head&gt;
    &lt;p&gt;PLECS Spice employs third-order implicit Runge-Kutta methods augmented with circuit-tailored convergence helpers to solve the DAEs produced by MNA. These one-step methods have a crucial advantage for mixed-signal schematics that contain both SPICE and standard PLECS electrical circuits: they are inherently self-starting. In other words, they do not rely on information from previous time steps. When events such as topology changes or zero-crossings occur, the solver must compute the next time step using only the current state. This self-starting property makes one-step methods particularly well-suited for hybrid systems with frequent discontinuities.&lt;/p&gt;
    &lt;p&gt;The solver can simulate complex systems that combine standard PLECS and SPICE models in a single schematic. The only rule is that when an electrical circuit contains a netlist, it must be solved using MNA, and therefore all its components must be compatible with SPICE. But other electrical circuits can remain in the standard PLECS formulation. Circuits of different types connect through the control domain using sources and meters. This enables a powerful top-down workflow: engineers can refine specific circuits of interest by converting them to SPICE netlists while keeping other subsystems and controls unchanged in standard PLECS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Application Example&lt;/head&gt;
    &lt;p&gt;Mixed-signal simulation is particularly valuable when control strategies and device physics must be considered together. The soft switching operation of a Dual Active Bridge (DAB) converter, whose analysis requires taking into consideration both controls and circuit design aspects, serves as a perfect case study for the workflow enabled by PLECS Spice.&lt;/p&gt;
    &lt;p&gt;A DAB is a bidirectional DC-DC topology comprising identical primary and secondary bridges (typically full bridges) separated by a high-frequency transformer and an energy transfer inductance (representing leakage plus external inductance). It is widely employed in high-power, high-density applications requiring bidirectional power flow between two galvanically isolated sides, such as EV chargers and energy storage systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Soft Switching Challenge&lt;/head&gt;
    &lt;p&gt;Magnetic components are often the primary limitation to increasing power density. Their size can be reduced by increasing switching frequency. State-of-the-art designs have reached the hundreds of kHz range. However, at these frequencies, switching losses represent a significant part of the overall converter losses. Without careful design, the volume advantage of a smaller transformer could be negated by the increased size needed of the cooling system.&lt;/p&gt;
    &lt;p&gt;To resolve this dilemma, soft switching offers a compelling solution. Given the high switching frequencies, MOSFETs are the standard choice for modern DABs. However, their dominant loss mechanism stems from the charge stored in the parasitic output capacitance (). When the device blocks voltage, this capacitance stores the energy&lt;/p&gt;
    &lt;p&gt;which depends on the drain-source voltage. When a MOSFET is turned on, the stored charge must be evacuated. In hard switching, the closing channel effectively shorts the capacitance, dissipating the stored energy as heat within the semiconductor. At high frequencies, this thermal penalty becomes unsustainable.&lt;/p&gt;
    &lt;p&gt;Here, the DAB offers a distinct advantage. In a full-bridge topology, each leg contains a top and bottom switch that operate complementarily: when one conducts, the other blocks. In practice, a short interval called dead time is introduced between turning off one switch and turning on its complement. Its primary role is to prevent a short circuit across the DC link, but a DAB can also exploit this interval of time for soft switching. During dead time, the inductor current continues to flow. With both switches off, the only path available is through the parasitic capacitances. This discharges the output capacitance of the incoming MOSFET (the switch about to turn on), causing its drain-source voltage to fall. If the dead time is sufficient, reaches zero before the gate signal arrives. The soft switching challenge lies in properly tuning this interval.&lt;/p&gt;
    &lt;p&gt;To achieve such Zero Voltage Switching (ZVS), the relationship between the device output capacitance, the resonant path and the gate drive, must be carefully adjusted. Crucially, these hardware choices cannot be made in isolation. They must inform the control design. This is because robust ZVS depends on several dynamic factors: the converter’s operating point (voltage and power), the gate driving scheme (specifically the dead times) and the degrees of freedom utilized by the modulation strategy.&lt;/p&gt;
    &lt;p&gt;Standard PLECS simulations allow for precise tuning of the operating point within the ZVS region, represented by the blue area in the ZVS range figure. However, because ideal switches are inherently hard switching, they do not simulate the transients required for a detailed analysis of ZVS. The effects of using two different dead times are compared in the figures above. In both tests, the low side gate signal turns off a conducting MOSFET. After the dead time, the complementary MOSFET is turned on by the high side gate signal. In the first experiment, a dead time of 15 ns is used between the two events. In the second, it is set to 50 ns. Yet, the resulting voltage and current waveforms show no visible response to this parameter change.&lt;/p&gt;
    &lt;p&gt;In this case, the ideal model fails to indicate whether the timing achieves soft switching or leads to hard switching transients. The reason is that ideal switches lack parasitic capacitances. Without , the antiparallel diode of the complementary switch conducts immediately, making the simulated waveforms insensitive to the dead time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Validating ZVS with Device-Level Detail&lt;/head&gt;
    &lt;p&gt;PLECS Spice enables precisely the analysis that ideal models cannot provide. Using configurable subsystems, engineers can add a detailed SPICE configuration alongside the ideal model, allowing them to toggle between fast system-level analysis and high-fidelity device validation without modifying the circuit topology or control logic.&lt;/p&gt;
    &lt;p&gt;The ideal switch configuration shown in the first figure consists of a standard PLECS MOSFET with antiparallel diode, driven directly by a control signal. The detailed configuration in the second figure provides a device-level description. It uses manufacturer-provided MOSFET and diode netlists that capture parasitic capacitances and charge dynamics. The control signal is converted to a gate-source voltage through a controlled voltage source. Separate on and off gate resistances ( and ) control switching speed. Engineers can switch between one configuration to the other between two simulations, while the control logic, operating point and all other subsystems remain unchanged.&lt;/p&gt;
    &lt;p&gt;With detailed device models in place, the impact of dead time on ZVS becomes immediately visible. The figure below shows the switching transient with a 15 ns dead time. The drain-source voltage remains high when the gate signal is applied, and only begins falling as channel current rises. This overlap between voltage and current is the signature of hard switching: the channel conducts before the output capacitance fully discharges, dissipating the stored energy as heat in the semiconductor. The insufficient dead time prevents the resonant discharge mechanism from completing.&lt;/p&gt;
    &lt;p&gt;By contrast, the second figure demonstrates successful ZVS with a 50 ns dead time. Here, completes its resonant transition to zero before the gate signal arrives. The channel opens with zero voltage across it, eliminating capacitive turn-on losses. Channel current then begins to flow, carrying the inductor current through the device. This extended dead time provides a sufficient interval for the inductor current to transfer energy from the MOSFET’s output capacitance, fulfilling the conditions for soft switching.&lt;/p&gt;
    &lt;p&gt;This example demonstrates how PLECS Spice enables validation of ZVS by bringing together three tightly coupled aspects within a single model. The control strategy establishes the operating point and determines the available inductor current for resonant transitions. Gate drive timing sets the window for capacitor discharge. The device physics, captured in the SPICE netlist, determines how quickly that discharge occurs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;PLECS Spice marks a significant step towards a unified power electronics design workflow. By integrating SPICE simulation directly into the PLECS environment, engineers no longer need to choose between system-level insights and device-level accuracy. The ability to seamlessly transition between ideal and detailed models within a single schematic eliminates the redundant and error-prone process of rebuilding circuits in separate tools. This empowers engineers to adopt a true top-down design philosophy, starting with a system-level view and progressively adding detail where it matters most. As power electronic systems grow in complexity, this unified approach will be crucial for accelerating innovation and reducing time-to-market.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46752841</guid><pubDate>Sun, 25 Jan 2026 10:44:08 +0000</pubDate></item><item><title>Show HN: TUI for managing XDG default applications</title><link>https://github.com/mitjafelicijan/xdgctl</link><description>&lt;doc fingerprint="fe9cba7b7ba6b9a3"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;xdgctl&lt;/code&gt; is a TUI for managing XDG default applications. View and set defaults for file categories without using &lt;code&gt;xdg-mime&lt;/code&gt; directly.&lt;/p&gt;
    &lt;p&gt;Built with C using GLib/GIO and termbox2.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;xdgctl.mp4&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browse by category (Browsers, Text Editors, etc.)&lt;/item&gt;
      &lt;item&gt;Current default marked with &lt;code&gt;*&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Arrow Up/Down&lt;/cell&gt;
        &lt;cell&gt;Navigate through categories or applications&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Arrow Right/Tab&lt;/cell&gt;
        &lt;cell&gt;Switch from category list to application list&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Arrow Left&lt;/cell&gt;
        &lt;cell&gt;Switch back to category list&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Enter&lt;/cell&gt;
        &lt;cell&gt;Set selected application as default for current category&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Esc / q&lt;/cell&gt;
        &lt;cell&gt;Quit the application&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;To build &lt;code&gt;xdgctl&lt;/code&gt;, you need the following development libraries:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;glib-2.0&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;gio-2.0&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;gio-unix-2.0&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;clang&lt;/code&gt;or&lt;code&gt;gcc&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# On Void Linux
sudo xbps-install glibc-devel&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/mitjafelicijan/xdgctl.git
cd xdgctl

# Build
make
sudo make install

# Using prefix
sudo make PREFIX=/usr/local install
make PREFIX=~/.local install&lt;/code&gt;
    &lt;p&gt;If you manually add new applications to your &lt;code&gt;~/.local/share/applications&lt;/code&gt; directory, you might need to run &lt;code&gt;update-desktop-database&lt;/code&gt; again.&lt;/p&gt;
    &lt;code&gt;ls /usr/share/applications
ls ~/.local/share/applications&lt;/code&gt;
    &lt;code&gt;xdg-mime query default text/plain
xdg-mime query default text/html
xdg-mime query default x-scheme-handler/http
xdg-mime query default x-scheme-handler/https
xdg-mime query default inode/directory&lt;/code&gt;
    &lt;code&gt;xdg-mime default brave.desktop x-scheme-handler/http
xdg-mime default brave.desktop x-scheme-handler/https&lt;/code&gt;
    &lt;code&gt;# ~/.local/share/applications/brave.desktop
[Desktop Entry]
Exec=/home/m/Applications/brave
Type=Application
Categories=Applications
Name=Brave Browser
MimeType=text/html;text/xml;application/xhtml+xml;x-scheme-handler/http;x-scheme-handler/https;&lt;/code&gt;
    &lt;code&gt;update-desktop-database ~/.local/share/applications
less ~/.config/mimeapps.list
less /usr/share/applications/mimeapps.list&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46753078</guid><pubDate>Sun, 25 Jan 2026 11:19:04 +0000</pubDate></item><item><title>Show HN: Bonsplit – Tabs and splits for native macOS apps</title><link>https://bonsplit.alasdairmonk.com</link><description>&lt;doc fingerprint="8d0973528a96f1e8"&gt;
  &lt;main&gt;
    &lt;p&gt;Bonsplit is a custom tab bar and layout split library for macOS apps. Enjoy out of the box 120fps animations, drag-and-drop reordering, SwiftUI support &amp;amp; keyboard navigation.&lt;/p&gt;
    &lt;quote&gt;.package(url: "https://github.com/almonk/bonsplit.git", from: "1.0.0")&lt;/quote&gt;
    &lt;p&gt;### Features&lt;/p&gt;
    &lt;p&gt;Create tabs with optional icons and dirty indicators. Target specific panes or use the focused pane.&lt;/p&gt;
    &lt;quote&gt;let tabId = controller.createTab(title: "Document.swift",icon: "swift",isDirty: false,inPane: paneId)&lt;/quote&gt;
    &lt;p&gt;Create tabs with optional icons and dirty indicators. Target specific panes or use the focused pane.&lt;/p&gt;
    &lt;quote&gt;let tabId = controller.createTab(title: "Document.swift",icon: "swift",isDirty: false,inPane: paneId)&lt;/quote&gt;
    &lt;p&gt;Split any pane horizontally or vertically. New panes are empty by default, giving you full control.&lt;/p&gt;
    &lt;quote&gt;// Split focused pane horizontallylet newPaneId = controller.splitPane(orientation: .horizontal)// Split with a tab already in the new panecontroller.splitPane(orientation: .vertical,withTab: Tab(title: "New", icon: "doc"))&lt;/quote&gt;
    &lt;p&gt;Split any pane horizontally or vertically. New panes are empty by default, giving you full control.&lt;/p&gt;
    &lt;quote&gt;// Split focused pane horizontallylet newPaneId = controller.splitPane(orientation: .horizontal)// Split with a tab already in the new panecontroller.splitPane(orientation: .vertical,withTab: Tab(title: "New", icon: "doc"))&lt;/quote&gt;
    &lt;p&gt;Update tab properties at any time. Changes animate smoothly.&lt;/p&gt;
    &lt;quote&gt;// Mark document as modifiedcontroller.updateTab(tabId, isDirty: true)// Rename tabcontroller.updateTab(tabId, title: "NewName.swift")// Change iconcontroller.updateTab(tabId, icon: "doc.text")&lt;/quote&gt;
    &lt;p&gt;Update tab properties at any time. Changes animate smoothly.&lt;/p&gt;
    &lt;quote&gt;// Mark document as modifiedcontroller.updateTab(tabId, isDirty: true)// Rename tabcontroller.updateTab(tabId, title: "NewName.swift")// Change iconcontroller.updateTab(tabId, icon: "doc.text")&lt;/quote&gt;
    &lt;p&gt;Programmatically navigate between panes using directional navigation.&lt;/p&gt;
    &lt;quote&gt;// Move focus between panescontroller.navigateFocus(direction: .left)controller.navigateFocus(direction: .right)controller.navigateFocus(direction: .up)controller.navigateFocus(direction: .down)// Or focus a specific panecontroller.focusPane(paneId)&lt;/quote&gt;
    &lt;p&gt;Programmatically navigate between panes using directional navigation.&lt;/p&gt;
    &lt;quote&gt;// Move focus between panescontroller.navigateFocus(direction: .left)controller.navigateFocus(direction: .right)controller.navigateFocus(direction: .up)controller.navigateFocus(direction: .down)// Or focus a specific panecontroller.focusPane(paneId)&lt;/quote&gt;
    &lt;p&gt;### Read this, agents...&lt;/p&gt;
    &lt;p&gt;Complete reference for all Bonsplit classes, methods, and configuration options.&lt;/p&gt;
    &lt;p&gt;The main controller for managing tabs and panes. Create an instance and pass it to BonsplitView.&lt;/p&gt;
    &lt;p&gt;Implement this protocol to receive callbacks about tab bar events. All methods have default implementations and are optional.&lt;/p&gt;
    &lt;p&gt;Configure behavior and appearance. Pass to BonsplitController on initialization.&lt;/p&gt;
    &lt;code&gt;allowSplits&lt;/code&gt;
    &lt;code&gt;Bool&lt;/code&gt;
    &lt;p&gt;Enable split buttons and drag-to-split&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;allowCloseTabs&lt;/code&gt;
    &lt;code&gt;Bool&lt;/code&gt;
    &lt;p&gt;Show close buttons on tabs&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;allowCloseLastPane&lt;/code&gt;
    &lt;code&gt;Bool&lt;/code&gt;
    &lt;p&gt;Allow closing the last remaining pane&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;false&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;allowTabReordering&lt;/code&gt;
    &lt;code&gt;Bool&lt;/code&gt;
    &lt;p&gt;Enable drag-to-reorder tabs within a pane&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;allowCrossPaneTabMove&lt;/code&gt;
    &lt;code&gt;Bool&lt;/code&gt;
    &lt;p&gt;Enable moving tabs between panes via drag&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;autoCloseEmptyPanes&lt;/code&gt;
    &lt;code&gt;Bool&lt;/code&gt;
    &lt;p&gt;Automatically close panes when their last tab is closed&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;contentViewLifecycle&lt;/code&gt;
    &lt;code&gt;ContentViewLifecycle&lt;/code&gt;
    &lt;p&gt;How tab content views are managed when switching tabs&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;.recreateOnSwitch&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;newTabPosition&lt;/code&gt;
    &lt;code&gt;NewTabPosition&lt;/code&gt;
    &lt;p&gt;Where new tabs are inserted in the tab list&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;.current&lt;/code&gt;&lt;/p&gt;
    &lt;quote&gt;let config = BonsplitConfiguration(allowSplits: true,allowCloseTabs: true,allowCloseLastPane: false,autoCloseEmptyPanes: true,contentViewLifecycle: .keepAllAlive,newTabPosition: .current)let controller = BonsplitController(configuration: config)&lt;/quote&gt;
    &lt;p&gt;Controls how tab content views are managed when switching between tabs.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Mode&lt;/cell&gt;
        &lt;cell role="head"&gt;Memory&lt;/cell&gt;
        &lt;cell role="head"&gt;State&lt;/cell&gt;
        &lt;cell role="head"&gt;Use Case&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;.recreateOnSwitch&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;None&lt;/cell&gt;
        &lt;cell&gt;Simple content&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;.keepAllAlive&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Higher&lt;/cell&gt;
        &lt;cell&gt;Full&lt;/cell&gt;
        &lt;cell&gt;Complex views, forms&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Controls where new tabs are inserted in the tab list.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Mode&lt;/cell&gt;
        &lt;cell role="head"&gt;Behavior&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;.current&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Insert after currently focused tab, or at end if none&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;.end&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Always insert at the end of the tab list&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;tabBarHeight&lt;/code&gt;
    &lt;code&gt;CGFloat&lt;/code&gt;
    &lt;p&gt;Height of the tab bar&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;33&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;tabMinWidth&lt;/code&gt;
    &lt;code&gt;CGFloat&lt;/code&gt;
    &lt;p&gt;Minimum width of a tab&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;140&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;tabMaxWidth&lt;/code&gt;
    &lt;code&gt;CGFloat&lt;/code&gt;
    &lt;p&gt;Maximum width of a tab&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;220&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;tabSpacing&lt;/code&gt;
    &lt;code&gt;CGFloat&lt;/code&gt;
    &lt;p&gt;Spacing between tabs&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;0&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;minimumPaneWidth&lt;/code&gt;
    &lt;code&gt;CGFloat&lt;/code&gt;
    &lt;p&gt;Minimum width of a pane&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;100&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;minimumPaneHeight&lt;/code&gt;
    &lt;code&gt;CGFloat&lt;/code&gt;
    &lt;p&gt;Minimum height of a pane&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;100&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;showSplitButtons&lt;/code&gt;
    &lt;code&gt;Bool&lt;/code&gt;
    &lt;p&gt;Show split buttons in the tab bar&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;animationDuration&lt;/code&gt;
    &lt;code&gt;Double&lt;/code&gt;
    &lt;p&gt;Duration of animations in seconds&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;0.15&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;enableAnimations&lt;/code&gt;
    &lt;code&gt;Bool&lt;/code&gt;
    &lt;p&gt;Enable or disable all animations&lt;/p&gt;
    &lt;p&gt;Default: &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;.default&lt;/code&gt;
    &lt;code&gt;BonsplitConfiguration&lt;/code&gt;
    &lt;p&gt;Default configuration with all features enabled&lt;/p&gt;
    &lt;code&gt;.singlePane&lt;/code&gt;
    &lt;code&gt;BonsplitConfiguration&lt;/code&gt;
    &lt;p&gt;Single pane mode with splits disabled&lt;/p&gt;
    &lt;code&gt;.readOnly&lt;/code&gt;
    &lt;code&gt;BonsplitConfiguration&lt;/code&gt;
    &lt;p&gt;Read-only mode with all modifications disabled&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46753301</guid><pubDate>Sun, 25 Jan 2026 11:56:42 +0000</pubDate></item><item><title>Nango (YC W23, Dev Infrastructure) Is Hiring Remotely</title><link>https://jobs.ashbyhq.com/Nango</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46753336</guid><pubDate>Sun, 25 Jan 2026 12:02:01 +0000</pubDate></item><item><title>Doom has been ported to an earbud</title><link>https://doombuds.com</link><description>&lt;doc fingerprint="a6567235022113ff"&gt;
  &lt;main&gt;
    &lt;p&gt;It's almost your turn, get ready!&lt;/p&gt;
    &lt;p&gt;Player queue&lt;/p&gt;
    &lt;p&gt;Your position&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;p&gt;Players queued&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;p&gt;Wait time&lt;/p&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;p&gt;You know the 1993 classic DOOM? I made it run on an earbud, then I connected it to the internet and made it possible for visitors like you to sit in a queue for hours play the game remotely!.&lt;/p&gt;
    &lt;p&gt;Yeah but it won't just run on any old earbud, this only works with the Pinebuds Pro, the only earbuds with open source firmware.&lt;/p&gt;
    &lt;p&gt;You sure can! There are two relevant repos:&lt;/p&gt;
    &lt;p&gt;This was a necessary optimisation to avoid paying outgoing bandwidth fees, once you're 5th in the queue, the twitch player will switch to a low-latency MJPEG stream.&lt;/p&gt;
    &lt;p&gt;shhhh don't look don't look it's ok just join the queue&lt;/p&gt;
    &lt;p&gt;Let's switch to a more readable font first.&lt;/p&gt;
    &lt;p&gt; I'll put out an article / video diving deeper into this later, but here are a few bits of info:&lt;lb/&gt; This project is made up of four parts: &lt;/p&gt;
    &lt;p&gt;The firmware pushes up against a few hardware limitations:&lt;/p&gt;
    &lt;p&gt; Earbuds don't have displays, so the only way to transfer data to/from them is either via bluetooth, or the UART contact pads.&lt;lb/&gt; Bluetooth is pretty slow, you'd be lucky to get a consistent 1mbps connection, UART is easily the better option.&lt;lb/&gt; DOOM's framebuffer is (width * height) bytes, 320 * 200 = 96kB. (doom's internal framebuffer is 8-bit not 24-bit)&lt;lb/&gt; The UART connection provides us with 2.4mbps of usable bandwidth. 2,400,000 / 8 / 96,000 gives us... 3 frames per second.&lt;lb/&gt; Clearly we need to compress the video stream. Modern video codecs like h264 consume way too much CPU and RAM.&lt;lb/&gt; The only feasible approach is sending the video as an MJPEG stream. MJPEG is a stream of JPEG images shown one after the other.&lt;lb/&gt; I found an excellent JPEG encoder for embedded devices here, thanks Larry!&lt;lb/&gt; A conservative estimate for the average HIGH quality JPEG frame is around 13.5KB, but most scenes (without enemies) are around 11kb.&lt;lb/&gt; Theoretical maximum FPS:&lt;lb/&gt; - Optimistic: `2,400,000 / (11,000 * 8)` = 27.3 FPS&lt;lb/&gt; - Conservative: `2,400,000 / (13,500 * 8)` = 22.2 FPS &lt;/p&gt;
    &lt;p&gt; The stock open source firmware has the CPU set to 100mhz, so I cranked that up to 300mhz and disabled low power mode.&lt;lb/&gt; The Cortex-M4F running at 300mhz is actually more than enough for DOOM, however it struggles with JPEG encoding.&lt;lb/&gt; This is why it maxes out at ~18fps, I don't think there's much else I can do to speed it up. &lt;/p&gt;
    &lt;p&gt; By default, we only have access to 768KB of RAM, after disabling the co-processor it gets bumped up to the advertised 992KB.&lt;lb/&gt; DOOM requires 4MB of RAM, though there are plenty of optimisations that can reduce this amount.&lt;lb/&gt; Pre-generating lookup tables, making variables const, reading const variables from flash, disabling DOOM's caching system, removing unneeded variables. It all adds up! &lt;/p&gt;
    &lt;p&gt; The shareware DOOM 1 wad (assets file) is 4.2MB and the earbuds can only store 4MB of data.&lt;lb/&gt; Thankfully, fragglet, a well-known doom modder, has already solved this issue for me.&lt;lb/&gt; Squashware is his trimmed-down DOOM 1 wad that is only 1.7MB in size.&lt;lb/&gt; With this wad file, everything comfortably fits in flash. &lt;/p&gt;
    &lt;p&gt;I thought you'd never ask! (please hire me)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46753484</guid><pubDate>Sun, 25 Jan 2026 12:22:12 +0000</pubDate></item><item><title>Alarm overload is undermining safety at sea as crews face thousands of alerts</title><link>https://www.lr.org/en/knowledge/press-room/press-listing/press-release/2026/alarm-overload-is-undermining-safety-at-sea-as-new-research-shows-crews-face-tens-of-thousands-of-daily-alerts/</link><description>&lt;doc fingerprint="3452211c23d1e7ad"&gt;
  &lt;main&gt;
    &lt;p&gt;New research from Lloyd’s Register (LR) has revealed that excessive and nuisance shipboard alarm systems are routinely overwhelming crews and, in many cases, actively undermining safety at sea.&lt;/p&gt;
    &lt;p&gt;The findings, published today in Effective Alarm Management in the Maritime Industry are based on data collected from 11 operational vessels, spanning over 2,000 days and more than 40 million alarm-related events.&lt;/p&gt;
    &lt;p&gt;The study shows that many ships generate thousands of alarms every day, many of which provide little or no operational value. The result is widespread alarm fatigue, disrupted rest periods and a growing erosion of trust in systems that are intended to protect both crews and assets.&lt;/p&gt;
    &lt;p&gt;The research applied recognised industrial best practice, including IEC 62682 and EEMUA 191, to maritime operations for the first time at this scale. It found that fewer than half of the vessels studied met the recommended benchmark of fewer than 30 alarms per hour, while on ships with unattended machinery spaces alarms disrupted 63% of rest periods. In some cases, cruise ships experienced up to 2,600 alarms per day, with peak rates reaching 4,691 alarms in just ten minutes.&lt;/p&gt;
    &lt;p&gt;Crews, overwhelmed by the volume of alerts, are forced to silence alarms without acknowledgement or physically bypass alarm circuits, normalising unsafe practices and eroding trust in critical safety systems.&lt;/p&gt;
    &lt;p&gt;Effective Alarm Management in the Maritime Industry: Insights from 40 million vessel alarms builds on LR’s Effective Alarm Management in the Maritime Industry report (released in September 2024) by moving beyond diagnosis to demonstrate what can be achieved in practice. A pilot project on an operational cruise ship reduced total alarm numbers by almost 50 per cent over a six-month period, without new technology or major system redesign. Improvements were delivered through traditional marine engineering interventions, including correcting valve installations, replacing faulty sensors and tuning existing systems.&lt;/p&gt;
    &lt;p&gt;LR’s analysis also demonstrates that addressing the 10 most frequent alarms could reduce overall loads by nearly 40 per cent.&lt;/p&gt;
    &lt;p&gt;The report calls for greater adoption of objective alarm performance assessment, stronger consideration of human factors in system design and operation throughout the vessel lifecycle, and regulatory frameworks that support consistent, enforceable standards.&lt;/p&gt;
    &lt;p&gt;Duncan Duffy, LR’s Global Head of Technology, said: “Our research found that alarm systems, when poorly managed, have themselves become a safety risk. Without decisive industry action, alarm fatigue will continue to undermine situational awareness and increase the likelihood of serious incidents.&lt;/p&gt;
    &lt;p&gt;“If the maritime industry is serious about safety, it must commit to continuous performance measurement, objective evaluation, and a human-centred approach to alarm system design. Only then can alarm systems fulfil their intended purpose—supporting crews, safeguarding lives, and ensuring safer voyages for all.”&lt;/p&gt;
    &lt;p&gt;The research is part of LR’s Digital Transformation Research programme, specifically designed to provide in-depth analysis of key opportunities and challenges for maritime digitalisation.&lt;/p&gt;
    &lt;p&gt;For more information and to download the full report, visit the link below:&lt;lb/&gt;LR Alarm Management &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46753611</guid><pubDate>Sun, 25 Jan 2026 12:40:00 +0000</pubDate></item><item><title>Web-based image editor modeled after Deluxe Paint</title><link>https://github.com/steffest/DPaint-js</link><description>&lt;doc fingerprint="56223e185d452d87"&gt;
  &lt;main&gt;
    &lt;p&gt;Webbased image editor modeled after the legendary Deluxe Paint with a focus on retro Amiga file formats. Next to modern image formats, DPaint.js can read and write Amiga icon files and IFF ILBM images.&lt;/p&gt;
    &lt;p&gt;Online version available at https://www.stef.be/dpaint/&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully Featured image editor with a.o. &lt;list rend="ul"&gt;&lt;item&gt;Layers&lt;/item&gt;&lt;item&gt;Selections&lt;/item&gt;&lt;item&gt;Masking&lt;/item&gt;&lt;item&gt;Transformation tools&lt;/item&gt;&lt;item&gt;Effects and filters&lt;/item&gt;&lt;item&gt;Multiple undo/redo&lt;/item&gt;&lt;item&gt;Copy/Paste from any other image program or image source&lt;/item&gt;&lt;item&gt;Customizable dither tools&lt;/item&gt;&lt;item&gt;Color Cycling&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Heavy focus on colour reduction with fine-grained dithering options&lt;/item&gt;
      &lt;item&gt;Amiga focus &lt;list rend="ul"&gt;&lt;item&gt;Read/write/convert Amiga icon files (all formats)&lt;/item&gt;&lt;item&gt;Reads IFF ILBM images (all formats including HAM and 24-bit)&lt;/item&gt;&lt;item&gt;Writes IFF ILBM images (up to 256 colors)&lt;/item&gt;&lt;item&gt;Read and write directly from Amiga Disk Files (ADF)&lt;/item&gt;&lt;item&gt;Embedded Amiga Emulator to preview your work in the real Deluxe Paint.&lt;/item&gt;&lt;item&gt;Limit the palette to 12 bit for Amiga OCS/ECS mode, or 9 bit for Atari ST mode.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Deluxe Paint Legacy &lt;list rend="ul"&gt;&lt;item&gt;Supports PBM files as used by the PC version of Deluxe Paint (Thanks to Michael Smith)&lt;/item&gt;&lt;item&gt;Supports Deluxe Paint Atari ST compression modes (Thanks to Nicolas Ramz)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It runs in your browser, works on any system and works fine on touch-screen devices like iPads.&lt;lb/&gt; It is written in 100% plain JavaScript and has no dependencies.&lt;lb/&gt; It's 100% free, no ads, no tracking, no accounts, no nothing.&lt;lb/&gt; All processing is done in your browser, no data is sent to any server.&lt;/p&gt;
    &lt;p&gt;The only part that is not included in this repository is the Amiga Emulator Files. (The emulator is based on the Scripted Amiga Emulator)&lt;/p&gt;
    &lt;p&gt;DPaint.js doesn't need building.&lt;lb/&gt; It also has zero dependencies so there's no need to install anything.&lt;lb/&gt; DPaint.js is written using ES6 modules and runs out of the box in modern browsers.&lt;lb/&gt; Just serve "index.html" from a webserver and you're good to go.&lt;/p&gt;
    &lt;p&gt;There's an optional build step to create a compact version of DPaint.js if you like.&lt;lb/&gt; I'm using Parcel.js for this.&lt;lb/&gt; For convenience, I've included a "package.json" file.&lt;lb/&gt; open a terminal and run &lt;code&gt;npm install&lt;/code&gt; to install Parcel.js and its dependencies.
Then run &lt;code&gt;npm run build&lt;/code&gt; to create a compact version of DPaint.js in the "dist" folder.&lt;/p&gt;
    &lt;p&gt;Documentation can be found at https://www.stef.be/dpaint/docs/&lt;/p&gt;
    &lt;p&gt;Dpaint.js is a web application, not an app that you install on your computer. That being said: DPaint.js has no online dependencies and runs fine offline if you want. One caveat: you have to serve the index.html file from a webserver, not just open it in your browser.&lt;lb/&gt; A quick way to do this is - for example - using the Spark app.&lt;lb/&gt; Download the binary for your platform, drop the Spark executable in the folder where you downloaded the Dpaint.js source files and run it. If you then point your browser to http://localhost:8080/ it should work.&lt;/p&gt;
    &lt;p&gt;If you are using Chrome, you can also "install" dpaint.js as app.&lt;lb/&gt; It will then show up your Chrome apps and work offline.&lt;/p&gt;
    &lt;p&gt;Current version is still alpha.&lt;lb/&gt; I'm sure there are bugs and missing features.&lt;lb/&gt; Bug reports and pull requests are welcome.&lt;/p&gt;
    &lt;p&gt;Planned for the next release, already in the works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;del rend="overstrike"&gt;Color Cycling&lt;/del&gt;(done)&lt;/item&gt;
      &lt;item&gt;&lt;del rend="overstrike"&gt;Animation support (GIf and Amiga ANIM files)&lt;/del&gt;(done)&lt;/item&gt;
      &lt;item&gt;&lt;del rend="overstrike"&gt;Shading/transparency tools that stay within the palette.&lt;/del&gt;(done)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Planned for a future release if there's a need for it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support for non-square pixel modes such as HiRes and Interlaced&lt;/item&gt;
      &lt;item&gt;PSD import and export&lt;/item&gt;
      &lt;item&gt;SpriteSheet support&lt;/item&gt;
      &lt;item&gt;Write HAM,SHAM and Dynamic HiRes images&lt;/item&gt;
      &lt;item&gt;Commodore 64 graphics modes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please note that the Brave browser is using "farbling" that introduces random image noise in certain conditions. They claim this is to protect your privacy. Although I totally understand the sentiment, In my opinion a browser should not actively alter the content of a webpage or intentionally break functionality.&lt;lb/&gt; But hey, who am I to speak, it's a free world. Just be aware that if you are using Brave, you will run into issues, so please "lower your shields" for this app in Brave or use another browser.&lt;/p&gt;
    &lt;p&gt;Dpaint.js supports Color-Cycling - a long lost art of "animating" a static image by only rotating some colors in the palette. See an example here:&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;The_Vision_cycle.mp4&lt;/head&gt;
    &lt;p&gt;Open the layered source file of the above image directly in Dpaint.js&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46753708</guid><pubDate>Sun, 25 Jan 2026 12:54:53 +0000</pubDate></item><item><title>Show HN: LLMNet – The Offline Internet, Search the web without the web</title><link>https://github.com/skorotkiewicz/llmnet</link><description>&lt;doc fingerprint="9b14b9483892176a"&gt;
  &lt;main&gt;
    &lt;p&gt;The Offline Internet. A premium, private, and AI-powered search experience that lives entirely on your machine.&lt;/p&gt;
    &lt;p&gt;LLMNet transforms your local LLMs into a structured search engine. It combines the power of local generative AI with a high-performance Vector Database (RAG) to provide instant, offline answers from your own knowledge base.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔒 100% Private: Your queries and data never leave your local network.&lt;/item&gt;
      &lt;item&gt;🧠 Local RAG: Index any website or wiki into a persistent Postgres Vector DB.&lt;/item&gt;
      &lt;item&gt;⚡ Instant Results: Sub-second semantic search using pgvector &amp;amp; HNSW indexing.&lt;/item&gt;
      &lt;item&gt;🎨 Premium UI: A glassmorphic, dark-mode interface inspired by modern search engines.&lt;/item&gt;
      &lt;item&gt;🌐 No Internet Required: Once indexed, your knowledge stays available offline.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frontend: Next.js, Tailwind CSS&lt;/item&gt;
      &lt;item&gt;Intelligence: Local LLMs (via OpenAI-compatible APIs)&lt;/item&gt;
      &lt;item&gt;Database: PostgreSQL with &lt;code&gt;pgvector&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Orchestration: Bun, Cheerio (Crawl), Turndown (Markdown)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ensure you have the following running locally:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LLM Server: Port configured in &lt;code&gt;.env&lt;/code&gt;(e.g., Llama.cpp, Ollama)&lt;/item&gt;
      &lt;item&gt;Embedding Server: Port configured in &lt;code&gt;.env&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Database: Postgres with the &lt;code&gt;vector&lt;/code&gt;extension (see&lt;code&gt;postgres-pgvector/&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Configure your environment variables in &lt;code&gt;.env&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# Example configuration
API_BASE_URL=http://localhost:8888/v1
EMBEDDING_URL=http://localhost:8889/v1/embeddings&lt;/code&gt;
    &lt;code&gt;# Install dependencies
bun install

# Initialize Database
bun postgres-pgvector/migrate.ts

# Start the engine
bun dev&lt;/code&gt;
    &lt;p&gt;Visit localhost:3000 to start searching.&lt;/p&gt;
    &lt;p&gt;LLMNet features a recursive ingestion pipeline. Simply paste a documentation URL or a GitHub Wiki link into the Indexer, and the system will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Crawl the site (Recursive BFS).&lt;/item&gt;
      &lt;item&gt;Convert content to clean Markdown.&lt;/item&gt;
      &lt;item&gt;Chunk text using a Recursive Character Splitter.&lt;/item&gt;
      &lt;item&gt;Embed &amp;amp; Store vectors for semantic retrieval.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Built for those who value privacy and data sovereignty.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46754206</guid><pubDate>Sun, 25 Jan 2026 14:10:12 +0000</pubDate></item><item><title>Wine-Staging 11.1 Adds Patches for Enabling Recent Photoshop Versions on Linux</title><link>https://www.phoronix.com/news/Wine-Staging-11.1</link><description>&lt;doc fingerprint="de54f53ba99c238b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Wine-Staging 11.1 Adds Patches For Enabling Recent Adobe Photoshop Versions On Linux&lt;/head&gt;
    &lt;p&gt; Following yesterday's release of Wine 11.1 for kicking off the new post-11.0 development cycle, Wine-Staging 11.1 is now available for this experimental/testing version of Wine that present is around 254 patches over the upstream Wine state. &lt;lb/&gt;Besides re-basing those 250+ patches to the latest Wine Git state, the latest VKD3D Git code is also pulled into Wine-Staging 11.1. There is some new feature work with Wine-Staging... Landing the new patches for enabling the recent Adobe Photoshop versions to successfully install and run under Wine on Linux.&lt;lb/&gt;As covered last week, the latest Adobe Photoshop installer is working and the app running with some new patches against the Wine code for its MSXML3 and MSHTML code. Those patches were cited in Bug 47015 for upstream Wine around the Photoshop Creative Cloud 2019 screen hitting MSXML3 errors.&lt;lb/&gt;Upstream Wine Git hasn't yet taken those patches but now they are in Wine-Staging 11.1 for further testing by the community.&lt;lb/&gt;Hopefully the testing will go well and those patches will get picked up by an upstream Wine 11.x bi-weekly development release in the near future.&lt;lb/&gt;Besides those MSHTML/MSXML3 work to benefit Adobe software, there aren't any other new patches in Wine-Staging 11.1. Those looking for new binaries to test it out can find them via WineHQ.org.&lt;/p&gt;
    &lt;p&gt;Besides re-basing those 250+ patches to the latest Wine Git state, the latest VKD3D Git code is also pulled into Wine-Staging 11.1. There is some new feature work with Wine-Staging... Landing the new patches for enabling the recent Adobe Photoshop versions to successfully install and run under Wine on Linux.&lt;/p&gt;
    &lt;p&gt;As covered last week, the latest Adobe Photoshop installer is working and the app running with some new patches against the Wine code for its MSXML3 and MSHTML code. Those patches were cited in Bug 47015 for upstream Wine around the Photoshop Creative Cloud 2019 screen hitting MSXML3 errors.&lt;/p&gt;
    &lt;p&gt;Upstream Wine Git hasn't yet taken those patches but now they are in Wine-Staging 11.1 for further testing by the community.&lt;/p&gt;
    &lt;p&gt;Hopefully the testing will go well and those patches will get picked up by an upstream Wine 11.x bi-weekly development release in the near future.&lt;/p&gt;
    &lt;p&gt;Besides those MSHTML/MSXML3 work to benefit Adobe software, there aren't any other new patches in Wine-Staging 11.1. Those looking for new binaries to test it out can find them via WineHQ.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46754427</guid><pubDate>Sun, 25 Jan 2026 14:42:39 +0000</pubDate></item><item><title>Show HN: Netfence – Like Envoy for eBPF Filters</title><link>https://github.com/danthegoodman1/netfence</link><description>&lt;doc fingerprint="780d8d538f3988c3"&gt;
  &lt;main&gt;
    &lt;p&gt;Like Envoy xDS, but for eBPF filters.&lt;/p&gt;
    &lt;p&gt;Netfence runs as a daemon on your VM/container hosts and automatically injects eBPF filter programs into cgroups and network interfaces, with a built-in DNS server that resolves allowed domains and populates the IP allowlist.&lt;/p&gt;
    &lt;p&gt;Netfence daemons connect to a central control plane that you implement via gRPC to synchronize allowlists/denylists with your backend.&lt;/p&gt;
    &lt;p&gt;Your control plane pushes network rules like &lt;code&gt;ALLOW *.pypi.org&lt;/code&gt; or &lt;code&gt;ALLOW 10.0.0.0/16&lt;/code&gt; to attached interfaces/cgroups. When a VM/container queries DNS, Netfence resolves it, adds the IPs to the eBPF filter, and drops traffic to unknown IPs before it leaves the host without any performance penalty.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Attach eBPF filters to network interfaces (TC) or cgroups&lt;/item&gt;
      &lt;item&gt;Policy modes: disabled, allowlist, denylist, block-all&lt;/item&gt;
      &lt;item&gt;IPv4 and IPv6 CIDR support with optional TTLs&lt;/item&gt;
      &lt;item&gt;Per-attachment DNS server with domain allowlist/denylist&lt;/item&gt;
      &lt;item&gt;Domain rules support subdomains with specificity-based matching (more specific rules win)&lt;/item&gt;
      &lt;item&gt;Resolved domains auto-populate IP filter&lt;/item&gt;
      &lt;item&gt;Metadata on daemons and attachments for associating with VM ID, tenant, etc.&lt;/item&gt;
      &lt;item&gt;Support for proxying DNS queries to the control plane to make DNS decisions per-attachment&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;+------------------+         +-------------------------+
|  Your Control    |&amp;lt;-------&amp;gt;|  Daemon (per host)      |
|  Plane (gRPC)    |  stream |                         |
+------------------+         |  +-------------------+  |
                             |  | DNS Server        |  |
                             |  | (per-attachment)  |  |
                             |  +-------------------+  |
                             +-------------------------+
                                        |
                                 +------+------+
                                 |             |
                              TC Filter    Cgroup Filter
                              (veth, eth)  (containers)
&lt;/code&gt;
    &lt;p&gt;Each attachment gets a unique DNS address (port) provisioned by the daemon. Containers/VMs should be configured to use their assigned DNS address.&lt;/p&gt;
    &lt;p&gt;Run the daemon, which:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Exposes a local gRPC API (&lt;code&gt;DaemonService&lt;/code&gt;) for attaching/detaching filters&lt;/item&gt;
      &lt;item&gt;Connects to your control plane via bidirectional stream (&lt;code&gt;ControlPlane.Connect&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Loads and manages eBPF programs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Start the daemon:&lt;/p&gt;
    &lt;code&gt;# Start with default config
netfenced start

# Start with custom config file
netfenced start --config /etc/netfence/config.yaml&lt;/code&gt;
    &lt;p&gt;Check daemon status:&lt;/p&gt;
    &lt;code&gt;netfenced status&lt;/code&gt;
    &lt;p&gt;Your orchestration system calls the daemon's local API.&lt;/p&gt;
    &lt;p&gt;RPC:&lt;/p&gt;
    &lt;code&gt;DaemonService.Attach(interface_name: "veth123", metadata: {vm_id: "abc"})
// or
DaemonService.Attach(cgroup_path: "/sys/fs/cgroup/...", metadata: {container_id: "xyz"})
&lt;/code&gt;
    &lt;p&gt;CLI:&lt;/p&gt;
    &lt;code&gt;# Attach to a network interface (TC)
netfenced attach --interface veth123 --metadata vm_id=abc

# Attach to a cgroup
netfenced attach --cgroup /sys/fs/cgroup/... --metadata container_id=xyz

# Attach with metadata
netfenced attach --interface eth0 --metadata tenant=acme,env=prod&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Daemon attaches eBPF filter to the target&lt;/item&gt;
      &lt;item&gt;Daemon sends &lt;code&gt;Subscribed{id, target, type, metadata}&lt;/code&gt;to control plane and waits for&lt;code&gt;SubscribedAck&lt;/code&gt;with initial config (mode, CIDRs, DNS rules)&lt;/item&gt;
      &lt;item&gt;If the control plane doesn't respond within the timeout (default 5s, configurable via &lt;code&gt;control_plane.subscribe_ack_timeout&lt;/code&gt;), the attachment is rolled back and the attach call fails&lt;/item&gt;
      &lt;item&gt;Daemon watches for target removal and sends &lt;code&gt;Unsubscribed&lt;/code&gt;automatically&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RPC:&lt;/p&gt;
    &lt;code&gt;DaemonService.Detach(id)
&lt;/code&gt;
    &lt;p&gt;CLI:&lt;/p&gt;
    &lt;code&gt;netfenced detach --id &amp;lt;attachment-id&amp;gt;&lt;/code&gt;
    &lt;p&gt;List attachments:&lt;/p&gt;
    &lt;code&gt;netfenced list
netfenced list --all  # fetch all pages&lt;/code&gt;
    &lt;p&gt;Implement &lt;code&gt;ControlPlane.Connect&lt;/code&gt; RPC - a bidirectional stream:&lt;/p&gt;
    &lt;p&gt;Receive from daemon:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SyncRequest&lt;/code&gt;on connect/reconnect (lists current attachments)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Subscribed&lt;/code&gt;when new attachments are added&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Unsubscribed&lt;/code&gt;when attachments are removed&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Heartbeat&lt;/code&gt;with stats&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Send to daemon:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SyncAck&lt;/code&gt;after receiving SyncRequest&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SubscribedAck{mode, cidrs, dns_config}&lt;/code&gt;after receiving Subscribed (required - daemon waits for this)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SetMode{mode}&lt;/code&gt;- change IP filter policy mode&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;AllowCIDR{cidr, ttl}&lt;/code&gt;/&lt;code&gt;DenyCIDR&lt;/code&gt;/&lt;code&gt;RemoveCIDR&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SetDnsMode{mode}&lt;/code&gt;- change DNS filtering mode&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;AllowDomain{domain}&lt;/code&gt;/&lt;code&gt;DenyDomain&lt;/code&gt;/&lt;code&gt;RemoveDomain&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;BulkUpdate{mode, cidrs, dns_config}&lt;/code&gt;- full state sync&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When the daemon receives &lt;code&gt;Subscribed&lt;/code&gt;, it blocks waiting for &lt;code&gt;SubscribedAck&lt;/code&gt; before returning success to the caller. This ensures the attachment has its initial configuration before traffic flows. Use the metadata to identify which VM/tenant/container this attachment belongs to and respond with the appropriate initial rules.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46754724</guid><pubDate>Sun, 25 Jan 2026 15:13:46 +0000</pubDate></item><item><title>A macOS app that blurs your screen when you slouch</title><link>https://github.com/tldev/posturr</link><description>&lt;doc fingerprint="709cd7c437d6538d"&gt;
  &lt;main&gt;
    &lt;p&gt;A macOS app that blurs your screen when you slouch.&lt;/p&gt;
    &lt;p&gt;Posturr uses your Mac's camera and Apple's Vision framework to monitor your posture in real-time. When it detects that you're slouching, it progressively blurs your screen to remind you to sit up straight. Maintain good posture, and the blur clears instantly.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time posture detection - Uses Apple's Vision framework for body pose and face tracking&lt;/item&gt;
      &lt;item&gt;Progressive screen blur - Gentle visual reminder that intensifies with worse posture&lt;/item&gt;
      &lt;item&gt;Menu bar controls - Easy access to settings, calibration, and status from the menu bar&lt;/item&gt;
      &lt;item&gt;Multi-display support - Works across all connected monitors&lt;/item&gt;
      &lt;item&gt;Privacy-focused - All processing happens locally on your Mac&lt;/item&gt;
      &lt;item&gt;Lightweight - Runs as a background app with minimal resource usage&lt;/item&gt;
      &lt;item&gt;No account required - No signup, no cloud, no tracking&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download the latest &lt;code&gt;Posturr-vX.X.X.zip&lt;/code&gt;from the Releases page&lt;/item&gt;
      &lt;item&gt;Unzip the downloaded file&lt;/item&gt;
      &lt;item&gt;Drag &lt;code&gt;Posturr.app&lt;/code&gt;to your Applications folder&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since Posturr is not signed with an Apple Developer certificate, macOS Gatekeeper will initially block it:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Right-click (or Control-click) on &lt;code&gt;Posturr.app&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Select "Open" from the context menu&lt;/item&gt;
      &lt;item&gt;Click "Open" in the dialog that appears&lt;/item&gt;
      &lt;item&gt;Grant camera access when prompted&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You only need to do this once. After the first launch, you can open Posturr normally.&lt;/p&gt;
    &lt;p&gt;Posturr requires camera access to monitor your posture. When you first launch the app, macOS will ask for permission. Click "OK" to grant access.&lt;/p&gt;
    &lt;p&gt;If you accidentally denied permission, you can grant it later:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open System Settings &amp;gt; Privacy &amp;amp; Security &amp;gt; Camera&lt;/item&gt;
      &lt;item&gt;Find Posturr and enable the toggle&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once launched, Posturr appears in your menu bar with a person icon. The app continuously monitors your posture and applies screen blur when slouching is detected.&lt;/p&gt;
    &lt;p&gt;Click the menu bar icon to access:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Status - Shows current state (Monitoring, Slouching, Good Posture, etc.)&lt;/item&gt;
      &lt;item&gt;Enabled - Toggle posture monitoring on/off&lt;/item&gt;
      &lt;item&gt;Recalibrate - Reset your baseline posture (sit up straight, then click)&lt;/item&gt;
      &lt;item&gt;Sensitivity - Adjust how sensitive the slouch detection is (Low, Medium, High, Very High)&lt;/item&gt;
      &lt;item&gt;Dead Zone - Set the tolerance before blur kicks in (None, Small, Medium, Large)&lt;/item&gt;
      &lt;item&gt;Compatibility Mode - Use public macOS APIs for blur (try this if blur doesn't appear)&lt;/item&gt;
      &lt;item&gt;Quit - Exit the application (or press Escape anywhere)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Position your camera at eye level when possible&lt;/item&gt;
      &lt;item&gt;Ensure adequate lighting on your face&lt;/item&gt;
      &lt;item&gt;Sit at a consistent distance from your screen&lt;/item&gt;
      &lt;item&gt;The app works best when your shoulders are visible&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Posturr uses Apple's Vision framework to detect body pose landmarks:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Body Pose Detection: Tracks nose, shoulders, and their relative positions&lt;/item&gt;
      &lt;item&gt;Face Detection Fallback: When full body isn't visible, tracks face position&lt;/item&gt;
      &lt;item&gt;Posture Analysis: Measures the vertical distance between nose and shoulders&lt;/item&gt;
      &lt;item&gt;Blur Response: Applies screen blur proportional to posture deviation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The screen blur uses macOS's private CoreGraphics API by default for efficient, system-level blur. If the blur doesn't appear on your system, enable Compatibility Mode from the menu to use &lt;code&gt;NSVisualEffectView&lt;/code&gt; instead.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 13.0 (Ventura) or later&lt;/item&gt;
      &lt;item&gt;Xcode Command Line Tools (&lt;code&gt;xcode-select --install&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/yourusername/posturr.git
cd posturr
./build.sh&lt;/code&gt;
    &lt;p&gt;The built app will be in &lt;code&gt;build/Posturr.app&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;# Standard build
./build.sh

# Build with release archive (.zip)
./build.sh --release&lt;/code&gt;
    &lt;code&gt;swiftc -O \
    -framework AppKit \
    -framework AVFoundation \
    -framework Vision \
    -framework CoreImage \
    -o Posturr \
    main.swift&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No code signing: Requires manual Gatekeeper bypass on first launch&lt;/item&gt;
      &lt;item&gt;Camera dependency: Requires a working camera with adequate lighting&lt;/item&gt;
      &lt;item&gt;Detection accuracy: Works best with clear view of upper body/face&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Posturr exposes a file-based command interface for external control:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;capture&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Take a photo and analyze pose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;blur &amp;lt;0-64&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set blur level manually&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;quit&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Exit the application&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Write commands to &lt;code&gt;/tmp/posturr-command&lt;/code&gt;. Responses appear in &lt;code&gt;/tmp/posturr-response&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 13.0 (Ventura) or later&lt;/item&gt;
      &lt;item&gt;Camera (built-in or external)&lt;/item&gt;
      &lt;item&gt;Approximately 10MB disk space&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Posturr processes all video data locally on your Mac. No images or data are ever sent to external servers. The camera feed is used solely for posture detection and is never stored or transmitted.&lt;/p&gt;
    &lt;p&gt;MIT License - see LICENSE for details.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Please feel free to submit issues and pull requests.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Built with Apple's Vision framework for body pose detection&lt;/item&gt;
      &lt;item&gt;Uses private CoreGraphics API for blur, with NSVisualEffectView fallback&lt;/item&gt;
      &lt;item&gt;Inspired by the need for better posture during long coding sessions&lt;/item&gt;
      &lt;item&gt;Thanks to @wklm for the compatibility mode implementation&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46754944</guid><pubDate>Sun, 25 Jan 2026 15:34:51 +0000</pubDate></item><item><title>Using PostgreSQL as a Dead Letter Queue for Event-Driven Systems</title><link>https://www.diljitpr.net/blog-post-postgresql-dlq</link><description>&lt;doc fingerprint="3f4c263785a28d80"&gt;
  &lt;main&gt;
    &lt;p&gt;While I was working on a project with Wayfair, I got the opportunity to work on a system that generated daily business reports aggregated from multiple data sources flowing through event streams across Wayfair. At a high level, Kafka consumers listened to these events, hydrated them with additional data by calling downstream services, and finally persisted the enriched events into a durable datastoreâCloudSQL PostgreSQL on GCP.&lt;/p&gt;
    &lt;p&gt;When everything was healthy, the pipeline worked exactly as expected. Events flowed in, got enriched, and were stored reliably. The real challenge started when things went wrong, which, in distributed systems, is not an exception but a certainty.&lt;/p&gt;
    &lt;p&gt;There were multiple failure scenarios we had to deal with. Sometimes the APIs we depended on for hydration were down or slow. Sometimes the consumer itself crashed midway through processing. In other cases, events arrived with missing or malformed fields that could not be processed safely. These were all situations outside our direct control, but they still needed to be handled gracefully.&lt;/p&gt;
    &lt;p&gt;This is where the concept of a Dead Letter Queue came into the picture. Whenever we knew an event could not be processed successfully, instead of dropping it or blocking the entire consumer, we redirected it to a DLQ so it could be inspected and potentially reprocessed later.&lt;/p&gt;
    &lt;p&gt;Our first instinct was to use Kafka itself as a DLQ. While this is a common pattern, it quickly became clear that it wasn't a great fit for our needs. Kafka is excellent for moving data, but once messages land in a DLQ topic, they are not particularly easy to inspect. Querying by failure reason, retrying a specific subset of events, or even answering simple questions like "what failed yesterday and why?" required extra tooling and custom consumers. For a system that powered business-critical daily reports, this lack of visibility was a serious drawback.&lt;/p&gt;
    &lt;p&gt;That's when we decided to treat PostgreSQL itself as the Dead Letter Queue.&lt;/p&gt;
    &lt;p&gt;Instead of publishing failed events to another Kafka topic, we persisted them directly into a DLQ table in PostgreSQL. We were already using CloudSQL as our durable store, so operationally this added very little complexity. Conceptually, it also made failures first-class citizens in the system rather than opaque messages lost in a stream.&lt;/p&gt;
    &lt;p&gt; Whenever an event failed processingâdue to an API failure, consumer crash, schema mismatch, or validation errorâwe stored the raw event payload along with contextual information about the failure. Each record carried a simple status field. When the event first landed in the DLQ, it was marked as &lt;code&gt;PENDING&lt;/code&gt;. Once it was successfully reprocessed, the status was updated to &lt;code&gt;SUCCEEDED&lt;/code&gt;. Keeping the state model intentionally minimal made it easy to reason about the lifecycle of a failed event.
                    &lt;/p&gt;
    &lt;head rend="h3"&gt;DLQ Table Schema and Indexing Strategy&lt;/head&gt;
    &lt;p&gt;To support inspection, retries, and long-term operability, the DLQ table was designed to be simple, query-friendly, and retry-aware.&lt;/p&gt;
    &lt;head rend="h4"&gt;Table Schema&lt;/head&gt;
    &lt;code&gt;CREATE TABLE dlq_events (
    id BIGSERIAL PRIMARY KEY,
    event_type VARCHAR(255) NOT NULL,
    payload JSONB NOT NULL,
    error_reason TEXT NOT NULL,
    error_stacktrace TEXT,
    status VARCHAR(20) NOT NULL, -- PENDING / SUCCEEDED
    retry_count INT NOT NULL DEFAULT 0,
    retry_after TIMESTAMP WITH TIME ZONE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);&lt;/code&gt;
    &lt;head rend="h4"&gt;Key Design Considerations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;payload&lt;/code&gt;is stored as&lt;code&gt;JSONB&lt;/code&gt;to preserve the raw event without enforcing a rigid schema.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;status&lt;/code&gt;keeps the lifecycle simple and explicit.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;retry_after&lt;/code&gt;prevents aggressive retries when downstream systems are unstable.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;retry_count&lt;/code&gt;allows retry limits to be enforced without external state.&lt;/item&gt;
      &lt;item&gt;Timestamps make auditing and operational analysis straightforward.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Indexes&lt;/head&gt;
    &lt;code&gt;CREATE INDEX idx_dlq_status
ON dlq_events (status);

CREATE INDEX idx_dlq_status_retry_after
ON dlq_events (status, retry_after);

CREATE INDEX idx_dlq_event_type
ON dlq_events (event_type);

CREATE INDEX idx_dlq_created_at
ON dlq_events (created_at);&lt;/code&gt;
    &lt;p&gt;These indexes allow the retry scheduler to efficiently locate eligible events while still supporting fast debugging and time-based analysis without full table scans.&lt;/p&gt;
    &lt;head rend="h3"&gt;DLQ Retry Mechanism with ShedLock&lt;/head&gt;
    &lt;p&gt;Persisting failed events solved the visibility problem, but we still needed a safe and reliable way to retry them.&lt;/p&gt;
    &lt;p&gt; For this, we introduced a DLQ retry scheduler backed by ShedLock. The scheduler periodically scans the DLQ table for &lt;code&gt;PENDING&lt;/code&gt; events that are eligible for retry and attempts to process them again. Since the service runs on multiple instances, ShedLock ensures that only one instance executes the retry job at any given time. This eliminates duplicate retries without requiring custom leader-election logic.
                    &lt;/p&gt;
    &lt;head rend="h4"&gt;Retry Configuration&lt;/head&gt;
    &lt;code&gt;dlq:
  retry:
    enabled: true
    max-retries: 240
    batch-size: 50
    fixed-rate: 21600000 # 6 hours in milliseconds&lt;/code&gt;
    &lt;head rend="h4"&gt;How Retries Work&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The scheduler runs every six hours.&lt;/item&gt;
      &lt;item&gt;Up to fifty eligible events are picked up per run.&lt;/item&gt;
      &lt;item&gt;Events exceeding the maximum retry count are skipped.&lt;/item&gt;
      &lt;item&gt;Successful retries immediately transition the event status to &lt;code&gt;SUCCEEDED&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Failures remain in &lt;code&gt;PENDING&lt;/code&gt;and are retried in subsequent runs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Query Implementation&lt;/head&gt;
    &lt;p&gt; The retry scheduler uses a SQL query with &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt; to safely select eligible events across multiple instances. This PostgreSQL feature ensures that even if multiple scheduler instances run simultaneously, each will pick up different rows without blocking each other:
                    &lt;/p&gt;
    &lt;code&gt;@QueryHints(@QueryHint(name = "jakarta.persistence.lock.timeout", value = "-2"))
@Query(
    value = "SELECT * FROM dlq_table "
        + "WHERE messagetype = :messageType "
        + "AND retries &amp;lt; :maxRetries "
        + "AND (replay_status IS NULL OR replay_status NOT IN ('COMPLETED')) "
        + "ORDER BY created_at ASC "
        + "FOR UPDATE SKIP LOCKED",
    nativeQuery = true
)&lt;/code&gt;
    &lt;p&gt; The &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt; clause is crucial here. It allows each instance to lock and process different rows concurrently, preventing duplicate processing while maintaining high throughput. The query hint sets the lock timeout to &lt;code&gt;-2&lt;/code&gt;, which means "wait indefinitely" but combined with &lt;code&gt;SKIP LOCKED&lt;/code&gt;, it effectively means "skip any rows that are already locked by another transaction."
                    &lt;/p&gt;
    &lt;p&gt;This setup allowed the system to tolerate long downstream outages while avoiding retry storms and unnecessary load on dependent services.&lt;/p&gt;
    &lt;head rend="h3"&gt;Operational Benefits&lt;/head&gt;
    &lt;p&gt;With this approach, failures became predictable and observable rather than disruptive. Engineers could inspect failures using plain SQL, identify patterns, and reprocess only the events that mattered. If a downstream dependency was unavailable for hours or even days, events safely accumulated in the DLQ and were retried later without human intervention. If an event was fundamentally bad, it stayed visible instead of being silently dropped.&lt;/p&gt;
    &lt;p&gt;Most importantly, this design reduced operational stress. Failures were no longer something to fear; they were an expected part of the system with a clear, auditable recovery path.&lt;/p&gt;
    &lt;head rend="h3"&gt;My Thoughts&lt;/head&gt;
    &lt;p&gt;The goal was never to replace Kafka with PostgreSQL. Kafka remained the backbone for high-throughput event ingestion, while PostgreSQL handled what it does bestâdurability, querying, and observability around failures. By letting each system play to its strengths, we ended up with a pipeline that was resilient, debuggable, and easy to operate.&lt;/p&gt;
    &lt;p&gt;In the end, using PostgreSQL as a Dead Letter Queue turned failure handling into something boring and predictable. And in production systems, boring is exactly what you want.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46755115</guid><pubDate>Sun, 25 Jan 2026 15:51:03 +0000</pubDate></item><item><title>FAA institutes nationwide drone no-fly zones around ICE operations</title><link>https://www.aerotime.aero/articles/faa-drone-no-fly-zone-ice-dhs</link><description>&lt;doc fingerprint="5c9064d05e9c8590"&gt;
  &lt;main&gt;
    &lt;p&gt;The Federal Aviation Administration has issued a nationwide security notice, effectively creating a moving drone no-fly zone around operations conducted by Immigration and Customs Enforcement (ICE) and other components of the Department of Homeland Security.&lt;/p&gt;
    &lt;p&gt;The notice, NOTAM FDC 6/4375, prohibits unmanned aircraft systems from operating within 3,000 feet laterally and 1,000 feet vertically of DHS facilities and mobile assets, including ground vehicle convoys and their escorts. The restriction applies nationwide and continuously, rather than at fixed locations or during defined time windows.&lt;/p&gt;
    &lt;p&gt;Because ICE operates under DHS and routinely conducts enforcement actions using mobile vehicle convoys in public spaces, the restriction functions as a drone no-fly zone around ICE operations, including arrests, transport activities and other field actions.&lt;/p&gt;
    &lt;p&gt;The FAA classifies the restricted airspace as “national defense airspace,” and cites its authority under federal security statutes. Drone operators who violate the restriction may face criminal prosecution, civil penalties, administrative enforcement actions, or revocation of FAA operating privileges. The notice also states that drones deemed a credible security threat may be intercepted, seized, damaged, or destroyed.&lt;/p&gt;
    &lt;p&gt;Unlike traditional Temporary Flight Restrictions, the NOTAM does not provide geographic coordinates, activation times, or public notification when the restriction is in effect near a specific location. Instead, the restricted airspace moves with DHS assets, meaning the no-fly zone can appear wherever ICE or other DHS units operate.&lt;/p&gt;
    &lt;p&gt;The new NOTAM replaces an earlier security notice, FDC 5/6378, which covered similar federal agencies but was less explicit about mobile operations. The updated version removes ambiguity by clearly stating that the restriction applies to moving DHS assets, including vehicles and convoys, and not just fixed facilities such as offices or bases.&lt;/p&gt;
    &lt;p&gt;That clarification has drawn attention from drone operators and civil liberties groups because it creates dynamic, invisible exclusion zones that may be impossible to identify in real time. The FAA does not publish public tracking of DHS or ICE movements, and the NOTAM does not include a mechanism for drone pilots to determine when covered assets are nearby.&lt;/p&gt;
    &lt;p&gt;In practical terms, a drone operator flying legally in a public area could unknowingly enter restricted airspace if an ICE convoy passes within the protected radius. The FAA instructs operators to “exercise caution” when flying near DHS facilities and mobile assets, but offers no specific guidance on how to do so in environments where enforcement activity is not publicly disclosed.&lt;/p&gt;
    &lt;p&gt;The notice mentions limited exceptions. Drone operations conducted in direct support of national defense, homeland security, law enforcement, firefighting, search and rescue, or disaster response missions may be authorized with advance coordination. Operators seeking approval are instructed to coordinate with DHS or other covered agencies, or contact the FAA’s System Operations Support Center.&lt;/p&gt;
    &lt;p&gt;The FAA cites multiple federal statutes as the legal basis for the restriction, including laws governing national defense airspace and counter-UAS mitigation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46755999</guid><pubDate>Sun, 25 Jan 2026 17:24:42 +0000</pubDate></item><item><title>ICE using Palantir tool that feeds on Medicaid data</title><link>https://www.eff.org/deeplinks/2026/01/report-ice-using-palantir-tool-feeds-medicaid-data</link><description>&lt;doc fingerprint="ad964554d5aa1139"&gt;
  &lt;main&gt;
    &lt;p&gt;EFF last summer asked a federal judge to block the federal government from using Medicaid data to identify and deport immigrants.&lt;/p&gt;
    &lt;p&gt;We also warned about the danger of the Trump administration consolidating all of the government’s information into a single searchable, AI-driven interface with help from Palantir, a company that has a shaky-at-best record on privacy and human rights.&lt;/p&gt;
    &lt;p&gt;Now we have the first evidence that our concerns have become reality.&lt;/p&gt;
    &lt;p&gt;“Palantir is working on a tool for Immigration and Customs Enforcement (ICE) that populates a map with potential deportation targets, brings up a dossier on each person, and provides a “confidence score” on the person’s current address,” 404 Media reports today. “ICE is using it to find locations where lots of people it might detain could be based.”&lt;/p&gt;
    &lt;p&gt;The tool – dubbed Enhanced Leads Identification &amp;amp; Targeting for Enforcement (ELITE) – receives peoples’ addresses from the Department of Health and Human Services (which includes Medicaid) and other sources, 404 Media reports based on court testimony in Oregon by law enforcement agents, among other sources.&lt;/p&gt;
    &lt;p&gt;This revelation comes as ICE – which has gone on a surveillance technology shopping spree – floods Minneapolis with agents, violently running roughshod over the civil rights of immigrants and U.S. citizens alike; President Trump has threatened to use the Insurrection Act of 1807 to deploy military troops against protestors there. Other localities are preparing for the possibility of similar surges.&lt;/p&gt;
    &lt;p&gt;Different government agencies necessarily collect information to provide essential services or collect taxes, but the danger comes when the government begins pooling that data and using it for reasons unrelated to the purpose it was collected.&lt;/p&gt;
    &lt;p&gt;This kind of consolidation of government records provides enormous government power that can be abused. Different government agencies necessarily collect information to provide essential services or collect taxes, but the danger comes when the government begins pooling that data and using it for reasons unrelated to the purpose it was collected.&lt;/p&gt;
    &lt;p&gt;As EFF Executive Director Cindy Cohn wrote in a Mercury News op-ed last August, “While couched in the benign language of eliminating government ‘data silos,’ this plan runs roughshod over your privacy and security. It’s a throwback to the rightly mocked ‘Total Information Awareness’ plans of the early 2000s that were, at least publicly, stopped after massive outcry from the public and from key members of Congress. It’s time to cry out again.”&lt;/p&gt;
    &lt;p&gt;In addition to the amicus brief we co-authored challenging ICE’s grab for Medicaid data, EFF has successfully sued over DOGE agents grabbing personal data from the U.S. Office of Personnel Management, filed an amicus brief in a suit challenging ICE’s grab for taxpayer data, and sued the departments of State and Homeland Security to halt a mass surveillance program to monitor constitutionally protected speech by noncitizens lawfully present in the U.S.&lt;/p&gt;
    &lt;p&gt;But litigation isn’t enough. People need to keep raising concerns via public discourse and Congress should act immediately to put brakes on this runaway train that threatens to crush the privacy and security of each and every person in America.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46756117</guid><pubDate>Sun, 25 Jan 2026 17:36:19 +0000</pubDate></item><item><title>First, make me care</title><link>https://gwern.net/blog/2026/make-me-care</link><description>&lt;doc fingerprint="77b044a15c934274"&gt;
  &lt;main&gt;
    &lt;p&gt;First, Make Me Care Writing advice: some nonfiction fails because it opens with background instead of a hook—readers leave before reaching the good material. Find the single anomaly or question that makes your topic interesting, lead with that, and let the background follow once you’ve earned attention. [Return to blog index]&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46757067</guid><pubDate>Sun, 25 Jan 2026 19:03:40 +0000</pubDate></item><item><title>Spanish track was fractured before high-speed train disaster, report finds</title><link>https://www.bbc.com/news/articles/c1m77dmxlvlo</link><description>&lt;doc fingerprint="ae6089bcbd13d29b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Spanish track was fractured before high-speed train disaster, report finds&lt;/head&gt;
    &lt;p&gt;A fracture in a straight section of track "occurred prior to the passage" of a high-speed train that derailed, causing last Sunday's rail disaster in which 45 people died, an initial report has found.&lt;/p&gt;
    &lt;p&gt;A train run by private company Iryo derailed last Sunday and its rear carriages crossed on to the opposite track into the path of an oncoming train run by state-owned Renfe.&lt;/p&gt;
    &lt;p&gt;The CIAF rail investigation commission said not only did Iryo train's front carriages which stayed on the track have "notches" in their wheels, but three earlier trains that went over the track earlier did too.&lt;/p&gt;
    &lt;p&gt;A gap of almost 40cm (15in) in the track has become the focus of the investigation into the crash.&lt;/p&gt;
    &lt;p&gt;Sunday's deadly collision occurred at around 19:45 local time (18:45 GMT), about an hour after the Iryo train left Málaga for Madrid.&lt;/p&gt;
    &lt;p&gt;The train's last three carriages - carriages six to eight - derailed and collided with the Huelva-bound Renfe train. "Carriage six derailed due to a complete lack of continuity in the track," the preliminary report finds.&lt;/p&gt;
    &lt;p&gt;Most of those killed and injured were in the front carriages of the state-operated train.&lt;/p&gt;
    &lt;p&gt;Earlier this week, Spanish Transport Minister Óscar Puente confirmed reports that grooves were found on the wheels of the Iryo train's carriages, which had passed over the track safely.&lt;/p&gt;
    &lt;p&gt;"These notches in the wheels and the deformation observed in the track are compatible with the fact that the track was cracked," the CIAF preliminary report said.&lt;/p&gt;
    &lt;p&gt;It added that three trains that had gone over the tracks at 17:21 on Sunday, 19:01 and then 19:09 had similar notches "with a compatible geometric pattern".&lt;/p&gt;
    &lt;p&gt;Similar grooves are found on carriages two, three and four of the Iryo train, the report says, but carriage five - the last that did not derail - had a groove on its outer edge, suggesting the rail was already tilting outwards before carriage six derailed.&lt;/p&gt;
    &lt;p&gt;The CIAF called its report a "working hypothesis", adding that it "must be corroborated by later detailed calculations and analysis".&lt;/p&gt;
    &lt;p&gt;The transport minister appeared before reporters again on Friday to say that it was too early to have definitive answers, but that if the cause of the crash was the fracture, then it occurred in the minutes and hours before the derailment and could not have been detected.&lt;/p&gt;
    &lt;p&gt;The Adamuz disaster is is the country's worst rail crash in more than a decade.&lt;/p&gt;
    &lt;p&gt;In 2013, Spain suffered its worst high-speed train derailment in Galicia, north-west Spain, which left 80 people dead and 140 others injured.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46757162</guid><pubDate>Sun, 25 Jan 2026 19:12:50 +0000</pubDate></item><item><title>Data Leak Exposes 149M Logins, Including Gmail, Facebook</title><link>https://www.techrepublic.com/article/news-149-million-passwords-exposed-infostealer-database/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46757465</guid><pubDate>Sun, 25 Jan 2026 19:45:10 +0000</pubDate></item></channel></rss>