<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 07 Dec 2025 03:52:54 +0000</lastBuildDate><item><title>HTML as an Accessible Format for Papers (2023)</title><link>https://info.arxiv.org/about/accessible_HTML.html</link><description>&lt;doc fingerprint="e3d1ea5238d7dc4a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;HTML as an accessible format for papers&lt;/head&gt;
    &lt;p&gt;Accessibility barriers in research are not new, but they are urgent. The message we have heard from our community is that arXiv can have the most impact in the shortest time by offering HTML papers alongside the existing PDF.&lt;/p&gt;
    &lt;p&gt;arXiv has successfully launched papers in HTML format. We are gradually backfilling HTML for arXiv's corpus of over 2 million papers over time. Not every paper can be successfully converted, so a small percentage of papers will not have an HTML version. We will work to improve conversion over time.&lt;/p&gt;
    &lt;p&gt;The link to the HTML format will appear on abstract pages below the existing PDF download link. Authors will have the opportunity to preview their paperâs HTML as a part of the submission process.&lt;/p&gt;
    &lt;p&gt;The beta rollout is just the beginning. We have a long way to go to improve HTML papers and will continue to solicit feedback from authors, readers, and the entire arXiv community to improve conversions from LaTeX.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why "experimental" HTML?&lt;/head&gt;
    &lt;p&gt;Did you know that 90% of submissions to arXiv are in TeX format, mostly LaTeX? That poses a unique accessibility challenge: to accurately convert from TeXâa very extensible language used in myriad unique ways by authorsâto HTML, a language that is much more accessible to screen readers and text-to-speech software, screen magnifiers, and mobile devices. In addition to the technical challenges, the conversion must be both rapid and automated in order to maintain arXivâs core service of free and fast dissemination.&lt;/p&gt;
    &lt;p&gt;Because of these challenges we know there will be some conversion and rendering issues. We have decided to launch in beta with âexperimentalâ HTML because:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Accessible papers are needed now. We have talked to the arXiv community, especially researchers with accessibility needs, and they overwhelmingly asked us not to wait.&lt;/item&gt;
      &lt;item&gt;We need your help. The obvious work is done. Reports from the community will help us identify issues we can track back to specific LaTeX packages that are not converting correctly.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Error messages you may see in HTML papers&lt;/head&gt;
    &lt;p&gt;HTML papers on arXiv.org are a work in progress and will sometimes display errors. As we work to improve accessibility we share with you the causes of these errors and what authors can do to help minimize them. Learn more about error messages you may see in HTML papers&lt;/p&gt;
    &lt;head rend="h2"&gt;Ways to help&lt;/head&gt;
    &lt;head rend="h3"&gt;1) Read HTML papers and report issues&lt;/head&gt;
    &lt;p&gt;We encourage the community to try out HTML papers in your field:&lt;/p&gt;
    &lt;head rend="h4"&gt;Report an issue&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go to the abstract page for a paper you are interested in reading.&lt;/item&gt;
      &lt;item&gt;Look in the section where you find the link to the PDF download, and click the new link for HTML.&lt;/item&gt;
      &lt;item&gt;Report issues by either a) clicking on the Open Issue button b) selecting text and clicking on the Open Issue for Selection button or c) use &lt;code&gt;Ctrl+?&lt;/code&gt;on your keyboard. If you are using a screen reader, use&lt;code&gt;Alt+y&lt;/code&gt;to toggle accessible reporting buttons per paragraph.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please do not create reports that the HTML paper doesn't look exactly like the PDF paper&lt;/p&gt;
    &lt;p&gt;Our primary goal for this project is to make papers more accessible, so the focus during the beta phase will value function over form. HTML layouts that are incorrect or are illegible are important to report. But we do expect the HTML papers to present differently than the same paper rendered in PDF. Line breaks will occur in different places and there is likely to be more white space. In general, the HTML paper won't present as compactly. Intricate typographic layouts will not be rendered so intricately. This is by design.&lt;/p&gt;
    &lt;p&gt;HTML is a different medium and brings its own advantages versus PDF. In addition to being much more compatible with assistive technologies, HTML does a far better job adapting to the characteristics of the device you are reading on, including mobile devices.&lt;/p&gt;
    &lt;head rend="h3"&gt;2) Help improve the conversion from LaTeX&lt;/head&gt;
    &lt;p&gt;If you are an author you can help us improve conversions to HTML by following our guide to LaTeX Markup Best Practices for Successful HTML Papers.&lt;/p&gt;
    &lt;p&gt;If you are a developer and have free development cycles, help us improve conversions! Our collaborators at LaTeXML maintain a list of issues and welcome feedback and developer contributions.&lt;/p&gt;
    &lt;p&gt;If you are a publisher, member of a society, or conference organizer you can help us improve conversions to HTML by reviewing the .cls files your organization recommends to authors for unsupported packages. Providing .cls files that use supported packages is an easy way to support and sow accessibility in the scientific community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you to our collaborators&lt;/head&gt;
    &lt;p&gt;First, we want to share a special thank you to all the scientists with disabilities who have generously shared their insights, expertise, and guidance throughout this project.&lt;/p&gt;
    &lt;p&gt;We want to thank two organizations without which HTML papers on arXiv would not be possible: The LaTeX Project, and the LaTeXML team from NIST. We deeply thank each member of these teams for their knowledge, incredible work, and commitment to accessibility.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46173825</guid><pubDate>Sat, 06 Dec 2025 14:59:52 +0000</pubDate></item><item><title>Infisical (YC W23) Is Hiring Engineers to Build the Modern OSS Security Stack</title><link>https://www.ycombinator.com/companies/infisical/jobs/2pwGcK9-senior-full-stack-engineer-us-canada</link><description>&lt;doc fingerprint="c51f69845b7e12a"&gt;
  &lt;main&gt;
    &lt;p&gt;Unified platform for secrets, certs, and privileged access management&lt;/p&gt;
    &lt;p&gt;Infisical is looking to hire exceptional talent to join our teams in building the open source security infrastructure stack for the AI era.&lt;/p&gt;
    &lt;p&gt;We're building a generational company with a world-class engineering team. This isn’t a place to coast — but if you want to grow fast, take ownership, and solve tough problems, you’ll be challenged like nowhere else.&lt;/p&gt;
    &lt;p&gt;What We’re Looking For&lt;/p&gt;
    &lt;p&gt;We’re looking for an exceptional Full Stack Engineer to help us build, optimize, and expand the foundation of the platform.&lt;/p&gt;
    &lt;p&gt;We’ve kept our hiring standards exceptionally high since we expect engineers to tackle a broad range of challenges on a day-to-day basis. Examples of past engineering initiatives include developing strategies for secret rotation and dynamic secrets, a gateway to provide secure access to private resources, protocols like EST and KMIP, integrations for syncing secrets across cloud providers, and entire new product lines such as Infisical PKI and Infisical SSH.&lt;/p&gt;
    &lt;p&gt;You’ll be working closely with our CTO and the rest of the engineering team to:&lt;/p&gt;
    &lt;p&gt;Requirements&lt;/p&gt;
    &lt;p&gt;Bonus&lt;/p&gt;
    &lt;p&gt;How You’ll Grow&lt;/p&gt;
    &lt;p&gt;In this role, you’ll play a pivotal part in shaping Infisical’s future—making key technical decisions, establishing foundational processes, and tackling complex scalability challenges. As you gain experience and the team expands, you'll have the opportunity to take full ownership of specific areas of our platform, driving them end-to-end with autonomy and impact.&lt;/p&gt;
    &lt;p&gt;Overall, you’ll be one of the defining pieces of our team as we scale to thousands of customers over the next 18 months.&lt;/p&gt;
    &lt;p&gt;Team, Values &amp;amp; Benefits&lt;/p&gt;
    &lt;p&gt;Our team brings experience from companies like Figma, AWS, and Red Hat. We operate primarily as a remote team but maintain a strong presence in San Francisco, where we have an office. We also get together in person throughout the year for off-sites, conferences, and team gatherings.&lt;/p&gt;
    &lt;p&gt;At Infisical, we offer competitive compensation, including both salary and equity options. Additional benefits, such as a lunch stipend and a work setup budget, are available with more details to be found on our careers page.&lt;/p&gt;
    &lt;p&gt;About Us&lt;/p&gt;
    &lt;p&gt;Infisical is the open source security infrastructure platform that engineers use for secrets management, internal PKI, key management, and SSH workflow orchestration. We help developers and organizations securely manage over 1.5 billion secrets each month including application configuration, database credentials, certificates, and more.&lt;/p&gt;
    &lt;p&gt;We’ve raised $19M from Y Combinator, Google, and Elad Gil, and our customers include Hugging Face, Lucid, and LG.&lt;/p&gt;
    &lt;p&gt;Join us on a mission to make security easier for all developers — starting with secrets management.&lt;/p&gt;
    &lt;p&gt;Infisical is the #1 open source secret management platform – used by tens of thousands of developers.&lt;/p&gt;
    &lt;p&gt;We raised $3M from Y Combinator, Gradient Ventures (Google's VC fund), and awesome angel investors like Elad Gil, Arash Ferdowsi (founder/ex-CTO of Dropbox), Paul Copplestone (founder/CEO of Supabase), James Hawkins (founder/CEO of PostHog), Andrew Miklas (founder/ex-CTO of PagerDuty), Diana Hu (GP at Y Combinator), and more.&lt;/p&gt;
    &lt;p&gt;We are default alive, and have signed many customers ranging from fastest growing startups to post-IPO enterprises.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46174789</guid><pubDate>Sat, 06 Dec 2025 17:01:53 +0000</pubDate></item><item><title>OMSCS Open Courseware</title><link>https://sites.gatech.edu/omscsopencourseware/</link><description>&lt;doc fingerprint="e76af2125443a7a2"&gt;
  &lt;main&gt;
    &lt;p&gt;Georgia Tech’s Online Master of Science in Computer Science (OMSCS) program is proud to make the course content* for many of its courses publicly available through Ed Lessons. Select a course below to view the public content for that course.&lt;/p&gt;
    &lt;p&gt;Note that students enrolled in OMSCS should access their course content through Canvas, as the for-credit versions of these courses may include graded components or recent content updates not available through OMSCS Open Courseware.&lt;/p&gt;
    &lt;p&gt;*Course content typically includes things such as lecture videos and exercises; it will not include things like homeworks, projects quizzes, exams, or other graded assignments.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46175826</guid><pubDate>Sat, 06 Dec 2025 19:14:35 +0000</pubDate></item><item><title>Zebra-Llama: Towards Efficient Hybrid Models</title><link>https://arxiv.org/abs/2505.17272</link><description>&lt;doc fingerprint="c1d340b445bd08b"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Machine Learning&lt;/head&gt;&lt;p&gt; [Submitted on 22 May 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Zebra-Llama: Towards Extremely Efficient Hybrid Models&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:With the growing demand for deploying large language models (LLMs) across diverse applications, improving their inference efficiency is crucial for sustainable and democratized access. However, retraining LLMs to meet new user-specific requirements is prohibitively expensive and environmentally unsustainable. In this work, we propose a practical and scalable alternative: composing efficient hybrid language models from existing pre-trained models. Our approach, Zebra-Llama, introduces a family of 1B, 3B, and 8B hybrid models by combining State Space Models (SSMs) and Multi-head Latent Attention (MLA) layers, using a refined initialization and post-training pipeline to efficiently transfer knowledge from pre-trained Transformers. Zebra-Llama achieves Transformer-level accuracy with near-SSM efficiency using only 7-11B training tokens (compared to trillions of tokens required for pre-training) and an 8B teacher. Moreover, Zebra-Llama dramatically reduces KV cache size -down to 3.9%, 2%, and 2.73% of the original for the 1B, 3B, and 8B variants, respectively-while preserving 100%, 100%, and &amp;gt;97% of average zero-shot performance on LM Harness tasks. Compared to models like MambaInLLaMA, X-EcoMLA, Minitron, and Llamba, Zebra-Llama consistently delivers competitive or superior accuracy while using significantly fewer tokens, smaller teachers, and vastly reduced KV cache memory. Notably, Zebra-Llama-8B surpasses Minitron-8B in few-shot accuracy by 7% while using 8x fewer training tokens, over 12x smaller KV cache, and a smaller teacher (8B vs. 15B). It also achieves 2.6x-3.8x higher throughput (tokens/s) than MambaInLlama up to a 32k context length. We will release code and model checkpoints upon acceptance.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Mehdi Rezagholizadeh [view email]&lt;p&gt;[v1] Thu, 22 May 2025 20:39:57 UTC (12,646 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;p&gt; IArxiv Recommender (What is IArxiv?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46176289</guid><pubDate>Sat, 06 Dec 2025 20:15:54 +0000</pubDate></item><item><title>Show HN: Tascli, a command line based (human) task and record manager</title><link>https://github.com/Aperocky/tascli</link><description>&lt;doc fingerprint="e35cd7e9d322ee4"&gt;
  &lt;main&gt;
    &lt;p&gt;A simple, fast, local CLI tool for tracking tasks and records from unix terminal.&lt;/p&gt;
    &lt;p&gt;Installation:&lt;/p&gt;
    &lt;code&gt;cargo install tascli
# or use brew
brew tap Aperocky/tascli
brew install tascli&lt;/code&gt;
    &lt;p&gt;Tasks and records are stored in &lt;code&gt;~/.local/share/tascli/tascli.db&lt;/code&gt; (configurable) with &lt;code&gt;rusqlite&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Create tasks with deadlines:&lt;/p&gt;
    &lt;code&gt;# Basic tasks
tascli task "Create readme" today
tascli task "Publish package" tomorrow
tascli task "Do taxes" 4/15

# With category
tascli task -c work "Read emails" week&lt;/code&gt;
    &lt;p&gt;Create recurring tasks:&lt;/p&gt;
    &lt;code&gt;tascli task "write diary" daily
tascli task "mortgage payment" "monthly 17th"&lt;/code&gt;
    &lt;p&gt;List tasks:&lt;/p&gt;
    &lt;code&gt;# List active tasks
$ tascli list task&lt;/code&gt;
    &lt;p&gt;output:&lt;/p&gt;
    &lt;code&gt;Task List:
----------------------------------------------------------------------------------------------
| Index  | Category            | Content                               | Deadline            |
----------------------------------------------------------------------------------------------
| 1      | life (recurring)    | write diary                           | Today               |
----------------------------------------------------------------------------------------------
| 2      | tascli              | Add pagination capability for tascli  | Sunday              |
|        |                     | list actions                          |                     |
----------------------------------------------------------------------------------------------
| 3      | tascli              | Add readme section on timestring      | Sunday              |
|        |                     | format                                |                     |
----------------------------------------------------------------------------------------------
| 4      | life                | Do state taxes                        | Sunday              |
----------------------------------------------------------------------------------------------
| 5      | tascli              | Sort list output by time instead of   | Sunday              |
|        |                     | internal id                           |                     |
----------------------------------------------------------------------------------------------
| 6      | tascli              | Fix length issue for unicode chars    | Sunday              |
----------------------------------------------------------------------------------------------
| 7      | life                | Two month pictures - follow the lead  | 4/23                |
|        |                     | from the previous one month pictures  |                     |
----------------------------------------------------------------------------------------------
&lt;/code&gt;
    &lt;p&gt;Complete tasks:&lt;/p&gt;
    &lt;code&gt;# Mark index 1 as done
tascli done 1&lt;/code&gt;
    &lt;p&gt;Completing a task or a recurring tasks will generate a corresponding record.&lt;/p&gt;
    &lt;p&gt;Search tasks:&lt;/p&gt;
    &lt;code&gt;tascli list task --search "rust"&lt;/code&gt;
    &lt;p&gt;List all tasks in &lt;code&gt;tascli&lt;/code&gt; category (including completed)&lt;/p&gt;
    &lt;code&gt;tascli list task -s all -c tascli&lt;/code&gt;
    &lt;p&gt;Example output:&lt;/p&gt;
    &lt;code&gt;Task List:
----------------------------------------------------------------------------------------------
| Index  | Category            | Content                               | Deadline            |
----------------------------------------------------------------------------------------------
| 1      | baby (Recurring)    | Mix egg yolk milk for Rowan           | Daily (fulfilled)   |
----------------------------------------------------------------------------------------------
| 2      | tascli              | Fix addition and modification commands| Today (completed)   |
|        |                     | output to have N/A for index          |                     |
----------------------------------------------------------------------------------------------
| 3      | tascli              | Insert guardrail against accidental   | Today (completed)   |
|        |                     | valid syntax like 'task list' that is |                     |
|        |                     | mistakenly made                       |                     |
----------------------------------------------------------------------------------------------
| 4      | tascli              | Create a gif for readme               | Today (completed)   |
----------------------------------------------------------------------------------------------
| 5      | tascli              | Add pagination capability for tascli  | Sunday              |
|        |                     | list actions                          |                     |
----------------------------------------------------------------------------------------------
| 6      | tascli              | Add readme section on timestring      | Sunday              |
|        |                     | format                                |                     |
----------------------------------------------------------------------------------------------
&lt;/code&gt;
    &lt;p&gt;Create records (for tracking events):&lt;/p&gt;
    &lt;code&gt;# With current time
tascli record -c feeding "100ML"

# With specific time
tascli record -c feeding -t 11:20AM "100ML"&lt;/code&gt;
    &lt;p&gt;List records:&lt;/p&gt;
    &lt;code&gt;# -d 1 stand for only get last 1 day of record
tascli list record -d 1&lt;/code&gt;
    &lt;p&gt;Search records:&lt;/p&gt;
    &lt;code&gt;tascli list record --search "secret"&lt;/code&gt;
    &lt;p&gt;Example output:&lt;/p&gt;
    &lt;code&gt;Records List:
----------------------------------------------------------------------------------------------
| Index  | Category            | Content                               | Created At          |
----------------------------------------------------------------------------------------------
| 1      | feeding             | 110ML                                 | Today 1:00AM        |
----------------------------------------------------------------------------------------------
| 2      | feeding             | breastfeeding                         | Today 4:10AM        |
----------------------------------------------------------------------------------------------
| 3      | feeding             | 100ML                                 | Today 7:30AM        |
----------------------------------------------------------------------------------------------
| 3      | life (Recurring)    | write diary                           | Today 10:30AM       |
----------------------------------------------------------------------------------------------
| 4      | feeding             | 110ML                                 | Today 11:20AM       |
----------------------------------------------------------------------------------------------
&lt;/code&gt;
    &lt;p&gt;This application accepts flexible time strings in various formats:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simple dates: &lt;code&gt;today&lt;/code&gt;,&lt;code&gt;tomorrow&lt;/code&gt;,&lt;code&gt;yesterday&lt;/code&gt;,&lt;code&gt;friday&lt;/code&gt;,&lt;code&gt;eom&lt;/code&gt;(end of month),&lt;code&gt;eoy&lt;/code&gt;(end of year)&lt;/item&gt;
      &lt;item&gt;Date formats: &lt;code&gt;YYYY-MM-DD&lt;/code&gt;,&lt;code&gt;MM/DD/YYYY&lt;/code&gt;,&lt;code&gt;MM/DD&lt;/code&gt;(current year)&lt;/item&gt;
      &lt;item&gt;Time formats: &lt;code&gt;HH:MM&lt;/code&gt;,&lt;code&gt;3:00PM&lt;/code&gt;,&lt;code&gt;3PM&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Combined: &lt;code&gt;2025-03-24 15:30&lt;/code&gt;,&lt;code&gt;tomorrow 3PM&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When only a date is provided, the time defaults to end of day (23:59:59). When only a time is provided, the date defaults to today.&lt;/p&gt;
    &lt;p&gt;Recurring Formats (schedules) are applicable to tasks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Recurring Formats: &lt;code&gt;daily&lt;/code&gt;,&lt;code&gt;daily 9PM&lt;/code&gt;,&lt;code&gt;weekly&lt;/code&gt;,&lt;code&gt;weekly Friday 9AM&lt;/code&gt;,&lt;code&gt;weekly mon-fri&lt;/code&gt;,&lt;code&gt;monthly 1st&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Recurring Formats (II): &lt;code&gt;every day&lt;/code&gt;,&lt;code&gt;every 9PM&lt;/code&gt;,&lt;code&gt;every monday&lt;/code&gt;,&lt;code&gt;every 9th of the month&lt;/code&gt;,&lt;code&gt;every 2/14&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If storing the db file in location other than &lt;code&gt;~/.local/share/tascli/tascli.db&lt;/code&gt; is preferred, create a config file:&lt;/p&gt;
    &lt;code&gt;{
    "data_dir": "/where/you/want/it"
}
&lt;/code&gt;
    &lt;p&gt;at &lt;code&gt;~/.config/tascli/config.json&lt;/code&gt; to adjust the location of the stored file. Note, if you already have existing tasks, you may want to move/copy the db file there first.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;tascli&lt;/code&gt; uses &lt;code&gt;clap&lt;/code&gt; for argument parsing, use &lt;code&gt;--help&lt;/code&gt; to get help on all levels of this cli:&lt;/p&gt;
    &lt;code&gt;aperocky@~$ tascli -h
Usage: tascli &amp;lt;COMMAND&amp;gt;

Commands:
  task    add task with end time
  record  add record
  done    Finish tasks
  update  Update tasks or records wording/deadlines
  delete  Delete Records or Tasks
  list    list tasks or records
  help    Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version
aperocky@~$ tascli task -h
add task with end time

Usage: tascli task [OPTIONS] &amp;lt;CONTENT&amp;gt; [TIMESTR]

Arguments:
  &amp;lt;CONTENT&amp;gt;  Description of the task
  [TIMESTR]  Time the task is due, default to EOD

Options:
  -c, --category &amp;lt;CATEGORY&amp;gt;  Category of the task
  -h, --help                 Print help
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46176533</guid><pubDate>Sat, 06 Dec 2025 20:56:38 +0000</pubDate></item><item><title>Coffee linked to slower biological ageing among those with severe mental illness</title><link>https://www.kcl.ac.uk/news/coffee-linked-to-slower-biological-ageing-among-those-with-severe-mental-illness-up-to-a-limit</link><description>&lt;doc fingerprint="776a119b602981bc"&gt;
  &lt;main&gt;
    &lt;quote&gt;&lt;p&gt;We know that coffee can help slow biological ageing in the general population, but little is known about its effect on people with severe mental illness – a population whose lifespan is already shortened, in part due to age-related diseases. Our study shows that up to four cups of coffee per day is linked to longer telomeres among people with bipolar disorder and schizophrenia. This is comparable to a biological age of five years younger than non-coffee drinkers.&lt;/p&gt;Vid Mlakar, PhD student at King’s College London and first author of the study&lt;/quote&gt;
    &lt;p&gt;26 November 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Coffee linked to slower biological ageing among those with severe mental illness – up to a limit&lt;/head&gt;
    &lt;p&gt;New research from King’s College London finds that coffee consumption within the NHS recommended limit is linked to longer telomere lengths – a marker of biological ageing – among people with bipolar disorder and schizophrenia. The effect is comparable to roughly five years younger biological age.&lt;/p&gt;
    &lt;p&gt;Telomeres are structures that protect DNA. As people get older, their telomeres shorten as part of the natural human ageing process. This process has been shown to be accelerated among people with severe mental illness, such as bipolar disorder and schizophrenia, who have an average life expectancy 15 years shorter than the general population.&lt;/p&gt;
    &lt;p&gt;Previous research shows that coffee possesses health benefits. It may reduce oxidative stress in the general population, helping slow biological ageing processes like telomere shortening. The new study, published in BMJ Mental Health, explores whether coffee consumption could slow this ageing process among those with severe mental illness.&lt;/p&gt;
    &lt;p&gt;Researchers at the Institute of Psychiatry, Psychology &amp;amp; Neuroscience measured the effects of coffee consumption on telomere length among 436 participants aged 18 to 65 with schizophrenia, bipolar disorder or major depressive disorder with psychosis.&lt;/p&gt;
    &lt;p&gt;They found that coffee consumption of up to four cups per day was linked to longer telomeres, comparable to a biological age five years younger than non-coffee drinkers.&lt;/p&gt;
    &lt;p&gt;The longest telomeres were seen among those who consumed three to four cups per day. Too much coffee reduced this positive effect, with participants who consumed more than four cups having shorter telomeres than those who consumed between three and four cups.&lt;/p&gt;
    &lt;p&gt;These effects remained after accounting for variations in age, sex, ethnicity, medication and tobacco use.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Coffee is a beverage that many people consume daily. On one hand, we know that excessive coffee consumption can have negative effects on health, such as reducing sleep quality. However, our new study suggests that coffee consumption up to a certain point may have benefits for biological ageing. Many of the factors that are known to affect biological ageing, such as genetics and negative stressful life experiences, are beyond our control. Lifestyle factors like coffee consumption are something we can actively modify, making research like this particularly valuable.&lt;/p&gt;Dr Monica Aas, MRC Research Fellow at King’s College London and senior author of the study&lt;/quote&gt;
    &lt;p&gt;Dr Aas added: "Studies such as this also support the idea that we should move away from viewing coffee as simply “good or bad”, and instead consider a more balanced view. Still, these results need to be confirmed in other independent studies and longitudinal research before we can determine if this is a causal effect."&lt;/p&gt;
    &lt;p&gt;Data were from the Norwegian TOP study, collected between 2007 and 2018. The researchers included participants who had available data on mental health diagnosis (assessed using the Structured Clinical Interview for DSM-IV), telomere length (measured by extracting DNA from blood samples) and self-reported coffee consumption.&lt;/p&gt;
    &lt;p&gt;The researchers note that the study did not have information on the type of coffee consumed (instant versus filter) or the caffeine concentration of each cup. The NHS advises limiting caffeine intake to 400 mg/day (approximately four cups of coffee).&lt;/p&gt;
    &lt;p&gt;The study was funded by the Research Council of Norway, the KG Jebsen Stiftelsen and an Medical Research Council Fellowship. The team has recently received funding from the British Medical Association’s Margaret Temple grant to investigate telomere shortening in a longitudinal cohort of patients with psychosis. This project will allow them to explore further how several lifestyle factors, as well as stress, influence the rate of telomere shortening over time.&lt;/p&gt;
    &lt;p&gt;"Coffee intake is associated with telomere length in severe mental disorders" (Vid Mlakar et al.) was published in BMJ Mental Health. DOI: 10.1136/bmjment-2025-301700&lt;/p&gt;
    &lt;p&gt;For more information, please contact Milly Remmington (School of Mental Health &amp;amp; Psychological Sciences Communications Manager).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46176766</guid><pubDate>Sat, 06 Dec 2025 21:33:03 +0000</pubDate></item><item><title>The past was not that cute</title><link>https://juliawise.net/the-past-was-not-that-cute/</link><description>&lt;doc fingerprint="26e613518ba77ebb"&gt;
  &lt;main&gt;
    &lt;p&gt;I was excited when cottagecore became a thing. Maybe my interest in retro clothes and handicrafts would be less embarrassing now!&lt;/p&gt;
    &lt;p&gt;I still enjoy it. But in spaces focused on old-fashioned vibes, you encounter a lot of people who believe that the past was actually this charming.&lt;/p&gt;
    &lt;p&gt;Laura Ingalls Wilder‘s Little House on the Prairie books are problematic, and also I will always love them. She wrote about the beauty of family and hard work, but she wrote them because she spent her whole life supporting disabled family members. She and her daughter beautified her “pioneer girl” history to make good books. Her daughter describes the reality: “It took seven successive years of complete crop failure, with work, weather and sickness that wrecked [my father’s] health permanently, and interest rates of 36 percent on money borrowed to buy food, to dislodge us from that land.”&lt;/p&gt;
    &lt;p&gt;My own version of this mistake was thinking that people’s personalities were different in the past. I grew up listening to folk music and imagining a past where nice boys would admire a nice quiet girl like me, and I wouldn’t have to figure out dating because everything would just unfold, probably on a May morning. My mother pointed out that a lot of the songs along the lines of “my own true love proved false to me” were about unplanned pregnancies.&lt;/p&gt;
    &lt;p&gt;I also assumed the bonny lasses in these songs would be wholesome and nice. But were popular girls of the past nicer people than they are now?&lt;/p&gt;
    &lt;p&gt;Some of my picture came from growing up in the Anglo-American folk dance and music community: it had a lot of aging hippies with graduate degrees. So I came away imagining a past with a lot of the kind of people who become engineers and English teachers. A more accurate picture would have been “Imagine a small town where the same 19 kids form your entire group of peers and potential partners.”&lt;/p&gt;
    &lt;p&gt;Bookish girls like Belle didn’t really go to live in enchanted castles with huge libraries. They stayed in villages where everyone thought they were weird and their best option was Gaston.&lt;/p&gt;
    &lt;p&gt;Maybe my favorite podcast episode ever is Rachel Laudan on food history: “I did have the extraordinary good fortune to grow up eating what I think the romantic movement dreams of. We had milk fresh from the cow; I never had pasteurized milk until I went to school. We had fish from the river, pheasant from the farm. The food was extremely good. . . . everything was fresh from the garden. So, I do romanticize—some of that because the taste was often extraordinary. And then I tweak myself and I say, ‘Look, Rachel, your mother spent all day, every day gardening or cooking.’ Essentially. As well as doing other chores. And she said to you, ‘Rachel, it’s servitude. I want you to have a life I didn’t have.’ “&lt;/p&gt;
    &lt;p&gt;I love living in a time and place where we get to choose aesthetics. I have bread rising in my kitchen right now, and I’m looking forward to baking it in an electric oven that doesn’t require me stacking wood or putting smoke into my house.&lt;/p&gt;
    &lt;p&gt;So I’ll continue to enjoy retro vibes, and draw on the past for lessons on how to be a human. (For example, making music together is one of life’s great experiences, and it’s a mistake to entirely substitute recorded music for that.) But I’ll enjoy doing so with indoor plumbing, dental care, and a desk job.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46176893</guid><pubDate>Sat, 06 Dec 2025 21:53:35 +0000</pubDate></item><item><title>Screenshots from developers: 2002 vs. 2015 (2015)</title><link>https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/</link><description>&lt;doc fingerprint="5e3b5b5dcbbf3eec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Screenshots from developers: 2002 vs. 2015&lt;/head&gt;
    &lt;p&gt;In 2002 I asked a number of developers/Unix people for screenshots of their desktops. I recently republished them, and, seeing the interest this generated, I thought it’d be fun to ask the same people* again 13 years later. To my delight I managed to reach many of them.&lt;/p&gt;
    &lt;p&gt;* Sans Dennis Ritchie and itojun, who are no longer with us.&lt;/p&gt;
    &lt;p&gt;So, without further ado:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;my desktop is pretty boring, since it consists of xterm windows to whatever unix system i am using at the moment. the machine itself is likely to be running some x-window server like exceed on some flavor of windows, though for many years i just used an x terminal.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;If you thought it was boring last time, check this out!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;2002:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I don’t know how to make a screenshot, because I normally use my computer in text-mode. I have X and GNOME installed, but I use them only occasionally.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;2015:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Under X, I use the standard environment of Trisquel, but mostly I type at Emacs in a console.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Well, my desktop is quite boring. I mostly work with four xterms and a few Netscape windows. The KDE bar hides automatically, you can only see a thin grey line at the bottom.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Here is the new one. You'll see that, like before, I have lots of xterms where I work on Vim, Zimbu and email. Now using the Chrome browser, showing off the Zimbu homepage. But clearly everything has become bigger!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Linux (2.4.20-pre5), Gnome2, vim, Pine.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Not that much has changed in 13 years. Still using Linux. Still just a browser window and a ton of terminals hiding behind them. The main change is that switched from Pine to Thunderbird for email at some point. The OS on my laptop here is Ubuntu with Unity although there are a lot of Debian packages installed so it is a bit of a hybrid at this point. Oh, and yes, my son Carl is a lot older now.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Ah, my desktop is pretty boring, I used fvwm 1.24 as my window manager and I try to have no more than 1 or 2 windows open per virtual desktop. I use FreeBSD 4-STABLE as my operating system. I first came across Unix when I got an account on a Pyramid 90x running OSx. This had a dual-universe setup: both AT&amp;amp;T and BSD-style environments, chosen by an environment variable. Initially I was given the AT&amp;amp;T environment, but my friends convinced me to ``come over” to BSD. Since then I’ve been a BSD afficionado.&lt;/p&gt;
      &lt;p&gt;After OSx, SunOS 3.5 and later SunOS releases, until 386BSD 0.1 came out and I started to run BSD at home. Then when 386BSD transmogrified to FreeBSD, I went with FreeBSD.&lt;/p&gt;
      &lt;p&gt;In terms of desktop, I’m a command-line guy, always will be. My favourite editor is vi, my favourite shell is tcsh (but kudos to rc for elegance). So I don’t really feel the need for GUI things like Gnome or KDE :-)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;How things have (and have not changed). I'm still a command-line junkie with at least two xterm windows open. I'm still using a 3x3 virtual desktop. However, instead of fvwm, it is now LXDE. I've also switched from FreeBSD to Linux and I'm running Lubuntu as my distribution.&lt;/p&gt;
      &lt;p&gt;There are a lot of indispensable GUI tools that I use. These include Firefox, lyx, Gimp, KeepassX, Shutter, viking, dia, Wireshark, calibre, audacity, Handbrake and VLC. But where possible I still prefer to script things. My main development languages are still shell, Perl and C.&lt;/p&gt;
      &lt;p&gt;My shell is now bash. The vi keystrokes are burned into my fingertips and, as long as vim can be ported to new systems, that will be my text editor until I pass on. My mail client is now mutt (definitely not a web client) and my mail is stored locally, not on someone else's server.&lt;/p&gt;
      &lt;p&gt;The only issue I have is that, since a job change, I now have to deal with Windoze things. Thus, I have VirtualBox, libreoffice and Wine to help me do that.&lt;/p&gt;
      &lt;p&gt;I started with Unix on a Pyramid 90x. I now have a smart phone that blows the 90x out of the water on performance, RAM and storage. But I'm so very happy that, somewhere down underneath, there is still a Bourne shell and an operating system that does open(), close(), read(), write(), fork() and exec()!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;You’ll probably be sad (or perhaps not) to hear that my desktop hasn’t really changed much at all - still OS X, though because OS X has virtual desktops now I have multiple “desktops” (6 of them) where Mail.app runs on one, Safari on another, Calendar, Slack, etc - all on separate desktops. This makes it a bit boring, but here’s the one I probably spend the most time in - the terminal window desktop. :)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;There we go. Actually, that’s a condensate in one workspace cause I usually use about 4. Some of my favourite apps:&lt;/p&gt;
      &lt;item&gt;http://anjuta.sf.net/ (IDE)&lt;/item&gt;
      &lt;item&gt;http://quirc.org/ (IRC)&lt;/item&gt;
      &lt;item&gt;http://gaim.sf.net/ (IM)&lt;/item&gt;
      &lt;item&gt;http://multignometerm.sf.net/ (Term)&lt;/item&gt;
      &lt;p&gt;not on the shot, but worth noted&lt;/p&gt;
      &lt;item&gt;http://sylpheed.good-day.net/ (Email Client)&lt;/item&gt;
      &lt;p&gt;and of course a shot of RTCW&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;'screenshot as code', I maintain my desktop configuration through saltstack: https://github.com/TTimo/linux-salted/commits/master&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Discussion: Hacker News; reddit: /r/programming, /r/linux&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46176905</guid><pubDate>Sat, 06 Dec 2025 21:55:09 +0000</pubDate></item><item><title>Catala – Law to Code</title><link>https://catala-lang.org</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177022</guid><pubDate>Sat, 06 Dec 2025 22:11:33 +0000</pubDate></item><item><title>United States Antarctic Program Field Manual (2024) [pdf]</title><link>https://www.usap.gov/usapgov/travelAndDeployment/documents/Continental-Field-Manual-2024.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177132</guid><pubDate>Sat, 06 Dec 2025 22:26:26 +0000</pubDate></item><item><title>Saving Japan's exceptionally rare 'snow monsters'</title><link>https://www.bbc.com/future/article/20251203-japans-disappearing-snow-monsters</link><description>&lt;doc fingerprint="bf6c94c72441867b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;'Nothing else looks like them': Saving Japan's exceptionally rare 'snow monsters'&lt;/head&gt;
    &lt;p&gt;A unique natural wonder is being eroded. Can Japan bring its breathtaking "juhyo" back from the brink?&lt;/p&gt;
    &lt;p&gt;Each winter, the upper slopes of Mount Zao in northern Japan – one of the country's best-known ski areas – are transformed. Fir trees coated in thick frost and snow swell into ghostly figures known as "juhyo" or "snow monsters".&lt;/p&gt;
    &lt;p&gt;Juhyo form only under exceptionally rare atmospheric conditions, emerging when strong, persistent winter winds carry supercooled water droplets that freeze on contact with the local evergreen Aomori todomatsu trees, gradually layering into rime ice.&lt;/p&gt;
    &lt;p&gt;At Mount Zao, these formations occur during sustained westerly winds of up to 26m per second (85ft per second), with surface air temperatures between -6.3C to -0.1C (21-31F) and unusually high cloud liquid water content. Under these precise conditions, the rime thickens on the windward side of trees into overlapping ridges known as "shrimp tails", the distinctive shapes that cluster together to form the towering juhyo figures.&lt;/p&gt;
    &lt;p&gt;"Because such precise meteorological and ecological conditions align in very few places, Zao's snow monsters are a phenomenon almost unique to northern Japan," says Fumitaka Yanagisawa, an emeritus professor of geochemistry who studies the juhyo at Yamagata University.&lt;/p&gt;
    &lt;p&gt;The snow monsters are the biggest winter draw of the Zao area, a mountain range which lies between Japan's Yamagata and Miyagi prefectures and attracts tens of thousands of visitors annually.&lt;/p&gt;
    &lt;p&gt;But recent research indicates that the monsters are becoming slimmer.&lt;/p&gt;
    &lt;p&gt;In August 2025, a research team led by Yanagisawa announced findings that quantified what locals have long observed. By analysing identical-angle photographs of Zao's summit taken since 1933, the team measured the thickness of the figures on a six-point scale. The findings (which have not yet been published in a scientific journal) indicate a widespread shrinking of the juhyo.&lt;/p&gt;
    &lt;p&gt;"In the 1930s, we saw juhyo five to six metres [16-20ft] across," Yanagisawa says. "By the postwar decades, they were often two to three metres [7-10ft]. Since 2019, many are half a metre [1.6ft] or less. Some are barely columns."&lt;/p&gt;
    &lt;p&gt;The cause is twofold, says Yanagisawa: a warming climate and a forest under attack. The host tree, Aomori todomatsu, suffered a moth outbreak in 2013 that stripped its needles. Bark beetles followed in 2015, boring into weakened trunks. Yamagata officials report that around 23,000 firs, about a fifth of the prefectural side's stands, have died. With fewer branches and leaves, there is little surface for snow and ice to cling to.&lt;/p&gt;
    &lt;p&gt;Another 2019 study found that in nearby Yamagata City, average temperatures from December to March have risen by about 2C (3.6F) over the past 120 years. The lower altitude limit of juhyo formation has shifted upward in step with this warming, it found, while the juhyo also last for fewer days of the year.&lt;/p&gt;
    &lt;p&gt;"Unique landscapes are already being lost to climate change," says Akihiko Ito, an ecologist who specialises in forests and climate change at the University of Tokyo.&lt;/p&gt;
    &lt;p&gt;Research shows that Japan's warming climate and extreme weather are already damaging many of its high mountain forests. "Seasonal shifts in spring and autumn can harm leaves, and insect outbreaks are expanding. These stresses may reduce forest growth and density," Ito says.&lt;/p&gt;
    &lt;p&gt;Across Japan's alpine zones, temperatures have been rising faster than the global average since the 1980s. "In scenarios where climate change continues to advance significantly by the end of this century, it is possible that in warmer-than-usual winters, juhyo may no longer form at all," Ito says.&lt;/p&gt;
    &lt;p&gt;The threat has prompted action across Yamagata. In March 2023, the prefecture launched the Juhyo Revival Conference – a permanent council bringing together researchers, officials, local businesses and residents to coordinate long-term efforts to restore the fir forests and preserve Mount Zao's snow monsters.&lt;/p&gt;
    &lt;p&gt;Juhyo are not only a natural spectacle but also a pillar of the local economy. "The influx of tourists supports hotels, restaurants and souvenir shops throughout the area," says Genji Akiba, deputy director of the Zao Onsen Tourism Association. "If the juhyo disappear, it would be a huge blow."&lt;/p&gt;
    &lt;p&gt;"Revival is a strong wish of our citizens," says Yoko Honma, a conservation specialist at Yamagata Prefecture's nature division. Since 2019, the local forest office has transplanted more than 190 naturally regenerated saplings from lower slopes to the summit zone near the ropeway station. "Because it takes 50 to 70 years for these firs to mature, the key is sustaining conservation across generations," says Honma. "We need patience and continuity."&lt;/p&gt;
    &lt;p&gt;In Murayama, about 20km (12 miles) north-west of Zao, students from a forestry and environmental science course at Murayama Technical High School have also taken up the challenge of reviving the firs.&lt;/p&gt;
    &lt;p&gt;More like this:&lt;/p&gt;
    &lt;p&gt;• The overlooked benefits of real Christmas trees&lt;/p&gt;
    &lt;p&gt;• The secrets of the Amazon's most mysterious river&lt;/p&gt;
    &lt;p&gt;• The mysterious black fungus from Chernobyl that may eat radiation&lt;/p&gt;
    &lt;p&gt;Since 2022, the students have been planting Aomori todomatsu trees and studying how to propagate and protect the species. Together with staff from the Yamagata Forest Office, they visit Mount Zao to collect young fir saplings and bring them back to their school for research. There, they cultivate stems through cuttings and experiment with methods for artificially propagating and efficiently producing seedlings.&lt;/p&gt;
    &lt;p&gt;"It's been challenging," says Rin Oizumi, a second-year student in the course. "When the seeds we sowed in heavy rain finally sprouted, I felt both relief and excitement. But it was heartbreaking to find that some plots had been damaged by field mice, which had eaten the young shoots." The students have also conducted preliminary experiments using branches of a related fir species, which have shown successful germination.&lt;/p&gt;
    &lt;p&gt;Kanon Taniai, Oizumi's classmate, recalls seeing more and more fallen or dead trees as she and other students neared the summit one day in July 2024. "It made me feel really sad," she says. "Growing seedlings is hard work, but we want to do what we can to help bring Mount Zao back to life."&lt;/p&gt;
    &lt;p&gt;For Taniai, protecting the Juhyo means passing their legacy to the next generation. "They are called snow monsters because nothing else looks like them," she says. "I want the world to see them, and to feel how special Japan's nature is."&lt;/p&gt;
    &lt;p&gt;--&lt;/p&gt;
    &lt;p&gt;For essential climate news and hopeful developments to your inbox, sign up to the Future Earth newsletter, while The Essential List delivers a handpicked selection of features and insights twice a week.&lt;/p&gt;
    &lt;p&gt;For more science, technology, environment and health stories from the BBC, follow us on Facebook and Instagram.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177418</guid><pubDate>Sat, 06 Dec 2025 23:06:53 +0000</pubDate></item><item><title>PatchworkOS: An OS for x86_64, built from scratch in C and assembly</title><link>https://github.com/KaiNorberg/PatchworkOS</link><description>&lt;doc fingerprint="3f1edc1a6ca59fdc"&gt;
  &lt;main&gt;
    &lt;p&gt;PatchworkOS is currently in a very early stage of development, and may have both known and unknown bugs.&lt;/p&gt;
    &lt;p&gt;PatchworkOS is a modular non-POSIX operating system for the x86_64 architecture that rigorously follows an "everything is a file" philosophy, in the style of Plan9. Built from scratch in C and assembly, its intended to be an educational and experimental operating system.&lt;/p&gt;
    &lt;p&gt;In the end this is a project made for fun, but the goal is to make a "real" operating system, one that runs on real hardware and has the performance one would expect from a modern operating system without jumping ahead to user space features, a floppy disk driver and a round-robin scheduler is not enough.&lt;/p&gt;
    &lt;p&gt;Also, this is not a UNIX clone, its intended to be a (hopefully) interesting experiment in operating system design by attempting to use unique algorithms and designs over tried and tested ones. Sometimes this leads to bad results, and sometimes, with a bit of luck, good ones.&lt;/p&gt;
    &lt;p&gt;Finally, despite its experimental nature and scale, the project aims to remain approachable and educational, something that can work as a middle ground between fully educational operating systems like xv6 and production operating system like Linux.&lt;/p&gt;
    &lt;p&gt;Will this project ever reach its goals? Probably not, but thats not the point.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Stress test showing ~100% utilization across 12 CPUs.&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;DOOM running on PatchworkOS using a doomgeneric port.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully preemptive and tickless EEVDF scheduler based upon the original paper and implemented using a Augmented Red-Black tree to achieve &lt;code&gt;O(log n)&lt;/code&gt;worst case complexity. EEVDF is the same algorithm used in the modern Linux kernel, but ours is obviously a lot less mature.&lt;/item&gt;
      &lt;item&gt;Multithreading and Symmetric Multi Processing with fine-grained locking.&lt;/item&gt;
      &lt;item&gt;Physical and virtual memory management is &lt;code&gt;O(1)&lt;/code&gt;per page and&lt;code&gt;O(n)&lt;/code&gt;where&lt;code&gt;n&lt;/code&gt;is the number of pages per allocation/mapping operation, see benchmarks for more info.&lt;/item&gt;
      &lt;item&gt;File based IPC including pipes, shared memory, sockets and Plan9 inspired "signals" called notes.&lt;/item&gt;
      &lt;item&gt;File based device APIs, including framebuffers, keyboards, mice and more.&lt;/item&gt;
      &lt;item&gt;Synchronization primitives including mutexes, read-write locks, sequential locks, futexes and others.&lt;/item&gt;
      &lt;item&gt;Highly Modular design, even SMP Bootstrapping is done in a module.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unix-style VFS with mountpoints, hardlinks, per-process namespaces, etc.&lt;/item&gt;
      &lt;item&gt;Custom Framebuffer BitMaP (.fbmp) image format, allows for faster loading by removing the need for parsing.&lt;/item&gt;
      &lt;item&gt;Custom Grayscale Raster Font (.grf) font format, allows for antialiasing and kerning without complex vector graphics.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Custom C standard library and system libraries.&lt;/item&gt;
      &lt;item&gt;Highly modular shared memory based desktop environment.&lt;/item&gt;
      &lt;item&gt;Theming via config files.&lt;/item&gt;
      &lt;item&gt;Note that currently a heavy focus has been placed on the kernel and low-level stuff, so user space is quite small... for now.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And much more...&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Replaced &lt;code&gt;fork(), exec()&lt;/code&gt;with&lt;code&gt;spawn()&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;No "user" concept.&lt;/item&gt;
      &lt;item&gt;Non-POSIX standard library.&lt;/item&gt;
      &lt;item&gt;Even heavier focus on "everything is a file".&lt;/item&gt;
      &lt;item&gt;File flags instead of file modes/permissions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Currently limited to RAM disks only (Waiting for USB support).&lt;/item&gt;
      &lt;item&gt;Only support for x86_64.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Port LUA and use it for dynamic system configuration. &amp;lt;-- Currently being worked on.&lt;/item&gt;
      &lt;item&gt;Fully Asynchronous I/O and syscalls (io_uring?).&lt;/item&gt;
      &lt;item&gt;USB support.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As one of the main goals of PatchworkOS is to be educational, I have tried to document the codebase as much as possible along with providing citations to any sources used. Currently, this is still a work in progress, but as old code is refactored and new code is added, I try to add documentation.&lt;/p&gt;
    &lt;p&gt;If you are interested in knowing more, then you can check out the Doxygen generated documentation. For an overview check the &lt;code&gt;topics&lt;/code&gt; section in the sidebar.&lt;/p&gt;
    &lt;p&gt;PatchworkOS uses a "modular" kernel design, meaning that instead of having one big kernel binary, the kernel is split into several smaller "modules" that can be loaded and unloaded at runtime. In effect, the kernel can rewrite itself by adding and removing functionality as needed.&lt;/p&gt;
    &lt;p&gt;This is highly convenient for development but it also has practical advantages, for example, there is no need to load a driver for a device that is not attached to the system, saving memory.&lt;/p&gt;
    &lt;p&gt;The process of making a module is intended to be as straightforward as possible. For the sake of demonstration, we will create a simple "Hello, World!" module.&lt;/p&gt;
    &lt;p&gt;First, we create a new directory in &lt;code&gt;src/kernel/modules/&lt;/code&gt; named &lt;code&gt;hello&lt;/code&gt;, and inside that directory we create a &lt;code&gt;hello.c&lt;/code&gt; file to which we write the following code:&lt;/p&gt;
    &lt;code&gt;#include &amp;lt;kernel/module/module.h&amp;gt;
#include &amp;lt;kernel/log/log.h&amp;gt;

#include &amp;lt;stdint.h&amp;gt;

uint64_t _module_procedure(const module_event_t* event)
{
    switch (event-&amp;gt;type)
    {
    case MODULE_EVENT_LOAD:
        LOG_INFO("Hello, World!\n");
        break;
    default:
        break;
    }

    return 0;
}

MODULE_INFO("Hello", "&amp;lt;author&amp;gt;", "A simple hello world module", "1.0", "MIT", "BOOT_ALWAYS");&lt;/code&gt;
    &lt;p&gt;An explanation of the code will be provided later.&lt;/p&gt;
    &lt;p&gt;Now we need to add the module to the build system. To do this, just copy a existing module's &lt;code&gt;.mk&lt;/code&gt; file without making any modifications. For example, we can copy &lt;code&gt;src/modules/drivers/ps2/ps2.mk&lt;/code&gt; to &lt;code&gt;src/modules/hello/hello.mk&lt;/code&gt;. The build system will handle the rest, including copying the module to the final image.&lt;/p&gt;
    &lt;p&gt;Now, we can build and run PatchworkOS using &lt;code&gt;make all run&lt;/code&gt;, or we could use &lt;code&gt;make all&lt;/code&gt; and then flash the generated &lt;code&gt;bin/PatchworkOS.img&lt;/code&gt; file to a USB drive.&lt;/p&gt;
    &lt;p&gt;Now to validate that the module is working, you can either watch the boot log and spot the &lt;code&gt;Hello, World!&lt;/code&gt; message, or you could use &lt;code&gt;grep&lt;/code&gt; on the &lt;code&gt;/dev/klog&lt;/code&gt; file in the terminal program like so:&lt;/p&gt;
    &lt;code&gt;cat /dev/klog | grep "Hello, World!"&lt;/code&gt;
    &lt;p&gt;This should output something like:&lt;/p&gt;
    &lt;code&gt;[   0.747-00-I] Hello, World!&lt;/code&gt;
    &lt;p&gt;Thats all, if this did not work, make sure you followed all the steps correctly, if there is still issues, feel free to open an issue.&lt;/p&gt;
    &lt;p&gt;Whatever you want. You can include any kernel header, or even headers from other modules, create your own modules and include their headers or anything else. There is no need to worry about linking, dependencies or exporting/importing symbols, the kernels module loader will handle all of it for you. Go nuts.&lt;/p&gt;
    &lt;p&gt;This code in the &lt;code&gt;hello.c&lt;/code&gt; file does a few things. First, it includes the relevant kernel headers.&lt;/p&gt;
    &lt;p&gt;Second, it defines a &lt;code&gt;_module_procedure()&lt;/code&gt; function. This function serves as the entry point for the module and will be called by the kernel to notify the module of events, for example the module being loaded or a device attached. On the load event, it will print using the kernels logging system &lt;code&gt;"Hello, World!"&lt;/code&gt;, resulting in the message being readable from &lt;code&gt;/dev/klog&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Finally, it defines the modules information. This information is, in order, the name of the module, the author of the module (thats you), a short description of the module, the module version, the licence of the module, and finally a list of "device types", in this case just &lt;code&gt;BOOT_ALWAYS&lt;/code&gt;, but more could be added by separating them with a semicolon (&lt;code&gt;;&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;The list of device types is what causes the kernel to actually load the module. I will avoid going into to much detail (you can check the documentation for that), but I will explain it briefly.&lt;/p&gt;
    &lt;p&gt;The module loader itself has no idea what these type strings actually are, but subsytems within the kernel can specify that "a device of the type represented by this string is now available", the module loader can then load either one or all modules that have specified in their list of device types that it can handle the specified type. This means that any new subsystem, ACPI, USB, PCI, etc, can implement dynamic module loading using whatever types they want.&lt;/p&gt;
    &lt;p&gt;So what is &lt;code&gt;BOOT_ALWAYS&lt;/code&gt;? It is the type of a special device that the kernel will pretend to "attach" during boot. In this case, it simply causes our hello module to be loaded during boot.&lt;/p&gt;
    &lt;p&gt;For more information, check the Module Doxygen Documentation.&lt;/p&gt;
    &lt;p&gt;PatchworkOS features a from-scratch ACPI implementation and AML parser, with the goal of being, atleast by ACPI standards, easy to understand and educational. It is tested on the Tested Configurations below and against ACPICA's runtime test suite, but remains a work in progress (and probably always will be).&lt;/p&gt;
    &lt;p&gt;See ACPI Doxygen Documentation for a progress checklist.&lt;/p&gt;
    &lt;p&gt;See ACPI specification Version 6.6 as the main reference.&lt;/p&gt;
    &lt;p&gt;ACPI or Advanced Configuration and Power Interface is used for alot of things in modern systems but mainly power management and device enumeration/configuration. Its not possible to go over everything here, instead a brief overview of the parts most likely to cause confusion while reading the code will be provided.&lt;/p&gt;
    &lt;p&gt;It consists of two main parts, the ACPI tables and AML bytecode. If you have completed a basic operating systems tutorial, you have probably seen the ACPI tables before, for example the RSDP, FADT, MADT, etc. These tables are static in memory data structures storing information about the system, they are very easy to parse but are limited in what they can express.&lt;/p&gt;
    &lt;p&gt;AML or ACPI Machine Language is a turning complete "mini language", and the source of mutch frustration, that is used to express more complex data, primarily device configuration. This is needed as its impossible for any specification to account for every possible hardware configuration that exists currently, much less that may exist in the future. So instead of trying to design that, what if we could just had a small program generate whatever data we wanted dynamically? Well thats more or less what AML is.&lt;/p&gt;
    &lt;p&gt;To demonstrate how ACPI is used for device configuration, we will use the PS/2 driver as an example.&lt;/p&gt;
    &lt;p&gt;If you have followed a basic operating systems tutorial, you have probably implemented a PS/2 keyboard driver at some point, and most likely you hardcoded the I/O ports &lt;code&gt;0x60&lt;/code&gt; and &lt;code&gt;0x64&lt;/code&gt; for data and commands respectively, and IRQ &lt;code&gt;1&lt;/code&gt; for keyboard interrupts.&lt;/p&gt;
    &lt;p&gt;Using this hardcoded approach will work for the vast majority of systems, but, perhaps surprisingly, there is no standard that guarantees that these ports and IRQs will actually be used for PS/2 devices. Its just a silent agreement that pretty much all systems adhere to for legacy reasons.&lt;/p&gt;
    &lt;p&gt;But this is where the device configuration from AML comes in, it lets us query the system for the actual resources used by the PS/2 keyboard, so we dont have to rely on hardcoded values.&lt;/p&gt;
    &lt;p&gt;If you where to decompile the AML bytecode into its original ASL (ACPI Source Language), you might find something like this:&lt;/p&gt;
    &lt;code&gt;Device (KBD)
{
    Name (_HID, EisaId ("PNP0303") /* IBM Enhanced Keyboard (101/102-key, PS/2 Mouse) */)  // _HID: Hardware ID
    Name (_STA, 0x0F)  // _STA: Status
    Name (_CRS, ResourceTemplate ()  // _CRS: Current Resource Settings
    {
        IO (Decode16,
            0x0060,             // Range Minimum
            0x0060,             // Range Maximum
            0x01,               // Alignment
            0x01,               // Length
            )
        IO (Decode16,
            0x0064,             // Range Minimum
            0x0064,             // Range Maximum
            0x01,               // Alignment
            0x01,               // Length
            )
        IRQNoFlags ()
            {1}
    })
}&lt;/code&gt;
    &lt;p&gt;Note that just like C compiles to assembly, ASL compiles to AML bytecode, which is what the OS actually parses.&lt;/p&gt;
    &lt;p&gt;In the example ASL, we se a &lt;code&gt;Device&lt;/code&gt; object representing a PS/2 keyboard. It has a hardware ID (&lt;code&gt;_HID&lt;/code&gt;), which we can cross reference with a online database to confirm that it is indeed a PS/2 keyboard, a status (&lt;code&gt;_STA&lt;/code&gt;), which is just a bitfield indicating if the device is present, enabled, etc, and finally the current resource settings (&lt;code&gt;_CRS&lt;/code&gt;), which is the thing we are really after.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;_CRS&lt;/code&gt; might look a bit complicated but focus on the &lt;code&gt;IO&lt;/code&gt; and &lt;code&gt;IRQNoFlags&lt;/code&gt; entries. Notice how they are specifying the I/O ports and IRQ used by the keyboard? Which in this case are indeed &lt;code&gt;0x60&lt;/code&gt;, &lt;code&gt;0x64&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt; respectively. So in this case the standard held true.&lt;/p&gt;
    &lt;p&gt;So how is this information used? Durring boot, the &lt;code&gt;_CRS&lt;/code&gt; information of each device is parsed by the ACPI subsystem, it then queries the kernel for the needed resources, assigned them to each device and makes the final configuration available to drivers.&lt;/p&gt;
    &lt;p&gt;Then when the PS/2 driver is loaded, it gets told "you are handling a device with the name &lt;code&gt;\_SB_.PCI0.SF8_.KBD_&lt;/code&gt; (which is just the full path to the device object in the ACPI namespace) and the type &lt;code&gt;PNP0303&lt;/code&gt;", it can then query the ACPI subsystem for the resources assigned to that device, and use them instead of hardcoded values.&lt;/p&gt;
    &lt;p&gt;Having access to this information for all devices also allows us to avoid resource conflicts, making sure two devices are not trying to use the same IRQ(s) or I/O port(s).&lt;/p&gt;
    &lt;p&gt;Of course, it gets way, way worse than this, but hopefully this clarifies why the PS/2 driver and other drivers, might look a bit different than what you might be used to.&lt;/p&gt;
    &lt;p&gt;PatchworkOS strictly follows the "everything is a file" philosophy in a way similar to Plan9, this can often result in unorthodox APIs or could just straight up seem overly complicated, but it has its advantages. We will use sockets to demonstrate the kinds of APIs this produces.&lt;/p&gt;
    &lt;p&gt;In order to create a local seqpacket socket, you open the &lt;code&gt;/net/local/seqpacket&lt;/code&gt; file. The opened file can be read to return the ID of your created socket. We provide several helper functions to make this easier, first, without any helpers, you would do&lt;/p&gt;
    &lt;code&gt;fd_t fd = open("/net/local/seqpacket");
if (fd == ERR) 
{
    /// ... handle error ...
}
char id[32] = {0};
if (read(fd, id, 31) == ERR) 
{
    /// ... handle error ...
}
close(fd);&lt;/code&gt;
    &lt;p&gt;Using the &lt;code&gt;sread()&lt;/code&gt; helper that reads the entire contents of a file descriptor to simplify this to&lt;/p&gt;
    &lt;code&gt;fd_t fd = open("/net/local/seqpacket");
if (fd == ERR) 
{
    /// ... handle error ...
}
char* id = sread(fd); 
if (id == NULL) 
{
    /// ... handle error ...
}
close(fd);
// ... do stuff ...
free(id);&lt;/code&gt;
    &lt;p&gt;Finally, you can use the &lt;code&gt;sreadfile()&lt;/code&gt; helper that reads the entire contents of a file from its path to simplify this even further to&lt;/p&gt;
    &lt;code&gt;char* id = sreadfile("/net/local/seqpacket"); 
if (id == NULL) 
{
    /// ... handle error ...
}
// ... do stuff ...
free(id);&lt;/code&gt;
    &lt;p&gt;Note that the socket will persist until the process that created it and all its children have exited. Additionally, for error handling, all functions will return either &lt;code&gt;NULL&lt;/code&gt; or &lt;code&gt;ERR&lt;/code&gt; on failure, depending on if they return a pointer or an integer type respectively. The per-thread &lt;code&gt;errno&lt;/code&gt; variable is used to indicate the specific error that occurred, both in user space and kernel space.&lt;/p&gt;
    &lt;p&gt;The ID that we have retrieved is the name of a directory in the &lt;code&gt;/net/local&lt;/code&gt; directory, in which are three files that we use to interact with the socket. These files are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;data&lt;/code&gt;: used to send and retrieve data&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ctl&lt;/code&gt;: Used to send commands&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;accept&lt;/code&gt;: Used to accept incoming connections&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, for example, the sockets data file is located at &lt;code&gt;/net/local/[id]/data&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Say we want to make our socket into a server, we would then use the bind and listen commands with the &lt;code&gt;ctl&lt;/code&gt; file, Once again, we provide several helper functions to make this easier. First, without any helpers, you would do&lt;/p&gt;
    &lt;code&gt;char ctlPath[MAX_PATH] = {0};
if (snprintf(ctlPath, MAX_PATH, "/net/local/%s/ctl", id) &amp;lt; 0) 
{
    /// ... handle error ...
}
fd_t ctl = open(ctlPath);
if (ctl == ERR) 
{
    /// ... handle error ...
}
if (write(ctl, "bind myserver &amp;amp;&amp;amp; listen") == ERR) // We use &amp;amp;&amp;amp; to chain commands.
{
    /// ... handle error ...
}
close(ctl);&lt;/code&gt;
    &lt;p&gt;Using the &lt;code&gt;F()&lt;/code&gt; macro which allocates formatted strings on the stack and the &lt;code&gt;swrite()&lt;/code&gt; helper that writes a null-terminated string to a file descriptor, we can simplify this to&lt;/p&gt;
    &lt;code&gt;fd_t ctl = open(F("/net/local/%s/ctl", id));
if (ctl == ERR) 
{
    /// ... handle error ...
}
if (swrite(ctl, "bind myserver &amp;amp;&amp;amp; listen") == ERR)
{
    /// ... handle error ...
}
close(ctl);&lt;/code&gt;
    &lt;p&gt;Finally, using the &lt;code&gt;swritefile()&lt;/code&gt; helper that writes a null-terminated string to a file from its path, we can simplify this even further to&lt;/p&gt;
    &lt;code&gt;if (swritefile(F("/net/local/%s/ctl", id), "bind myserver &amp;amp;&amp;amp; listen") == ERR)
{
    /// ... handle error ...
}&lt;/code&gt;
    &lt;p&gt;Note that we name our server &lt;code&gt;myserver&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If we wanted to accept a connection using our newly created server, we just open its accept file by writing&lt;/p&gt;
    &lt;code&gt;fd_t fd = open(F("/net/local/%s/accept", id));
if (fd == ERR) 
{
    /// ... handle error ...
}
/// ... do stuff ...
close(fd);&lt;/code&gt;
    &lt;p&gt;The file descriptor returned when the accept file is opened can be used to send and receive data, just like when calling &lt;code&gt;accept()&lt;/code&gt; in for example Linux or other POSIX operating systems. The entire socket API attempts to mimic the POSIX socket API, apart from using these weird files everything (should) work as expected.&lt;/p&gt;
    &lt;p&gt;For the sake of completeness, if we wanted to connect to this server, we can do&lt;/p&gt;
    &lt;code&gt;char* id = sreadfile("/net/local/seqpacket"); // Create new socket and get its ID.
if (id == NULL) 
{
    /// ... handle error ...
}
if (swritefile(F("/net/local/%s/ctl", id), "connect myserver") == ERR) // Connect to the server named "myserver".
{
    /// ... handle error ...
}
/// ... do stuff ...
free(id);&lt;/code&gt;
    &lt;p&gt;Namespaces are a set of mountpoints that is unique per process, which allows each process a unique view of the file system and is utilized for access control.&lt;/p&gt;
    &lt;p&gt;Think of it like this, in the common case, you can mount a drive to &lt;code&gt;/mnt/mydrive&lt;/code&gt; and all processes can then open the &lt;code&gt;/mnt/mydrive&lt;/code&gt; path and see the contents of that drive. However, for security reasons we might not want every process to be able to see that drive, this is what namespaces enable, allowing mounted file systems or directories to only be visible to a subset of processes.&lt;/p&gt;
    &lt;p&gt;As an example, the "id" directories mentioned in the socket example are a separate "sysfs" instance mounted in the namespace of the creating process, meaning that only that process and its children can see their contents.&lt;/p&gt;
    &lt;p&gt;To control which processes can see a newly mounted or bound file system or directory, we use a propegation system, where a the newly created mountpoint can be made visible to either just the creating process, the creating process and its children, or the creating process, its children and its parents. Additionally, its possible to specify the behaviour of mountpoint inheritance when a new process is spawned.&lt;/p&gt;
    &lt;p&gt;In cases where the propagation system is not sufficient, it's possible for two processes to voluntarily share a mountpoint in their namespaces using &lt;code&gt;bind()&lt;/code&gt; in combination with two new system calls &lt;code&gt;share()&lt;/code&gt; and &lt;code&gt;claim()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For example, if process A wants to share its &lt;code&gt;/net/local/5&lt;/code&gt; directory from the socket example with process B, they can do&lt;/p&gt;
    &lt;code&gt;// In process A
fd_t dir = open("/net/local/5:directory");

// Create a "key" for the file descriptor, this is a unique one time use randomly generated token that can be used to retrieve the file descriptor in another process.
key_t key;
share(&amp;amp;key, dir, CLOCKS_PER_SEC * 60); // Key valid for 60 seconds (CLOCKS_NEVER is also allowed)

// In process B
// The key is somehow communicated to B via IPC, for example a pipe, socket, argv, etc.
key_t key = ...;

// Use the key to open a file descriptor to the directory, this will invalidate the key.
fd_t dir = claim(key);
// Will error here if the original file descriptor in process A has been closed, process A exited, or the key expired.

// Make "dir" ("/net/local/5" in A) available in B's namespace at "/any/path/it/wants". In practice it might be best to bind it to the same path as in A to avoid confusion.
bind(dir, "/any/path/it/wants");

// Its also possible to just open paths in the shared directory without polluting the namespace using openat().
fd_t somePath = openat(dir, "data");&lt;/code&gt;
    &lt;p&gt;Note that error checking is ommited for brevity.&lt;/p&gt;
    &lt;p&gt;This system guarantees consent between processes, and can be used to implement more complex access control systems.&lt;/p&gt;
    &lt;p&gt;An interesting detail is that when process A opens the &lt;code&gt;net/local/5&lt;/code&gt; directory, the dentry underlying the file descriptor is the root of the mounted file system, if process B were to try to open this directory, it would still succeed as the directory itself is visible, however process B would instead retrieve the dentry of the directory in the parent superblock, and would instead see the content of that directory in the parent superblock. If this means nothing to you, don't worry about it.&lt;/p&gt;
    &lt;p&gt;You may have noticed that in the above section sections, the &lt;code&gt;open()&lt;/code&gt; function does not take in a flags argument. This is because flags are part of the file path directly so if you wanted to create a non-blocking socket, you can write&lt;/p&gt;
    &lt;code&gt;open("/net/local/seqpacket:nonblock");&lt;/code&gt;
    &lt;p&gt;Multiple flags are allowed, just separate them with the &lt;code&gt;:&lt;/code&gt; character, this means flags can be easily appended to a path using the &lt;code&gt;F()&lt;/code&gt; macro. Each flag also has a short hand version for which the &lt;code&gt;:&lt;/code&gt; character is ommited, for example to open a file as create and exclusive, you can do&lt;/p&gt;
    &lt;code&gt;open("/some/path:create:exclusive");&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;open("/some/path:ce");&lt;/code&gt;
    &lt;p&gt;For a full list of available flags, check the Doxygen documentation.&lt;/p&gt;
    &lt;p&gt;Permissions are also specified using file paths there are three possible permissions, read, write and execute. For example to open a file as read and write, you can do&lt;/p&gt;
    &lt;code&gt;open("/some/path:read:write");&lt;/code&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;open("/some/path:rw");&lt;/code&gt;
    &lt;p&gt;Permissions are inherited, you cant use a file with lower permissions to get a file with higher permissions. Consider the namespace section, if a directory was opened using only read permissions and that same directory was bound, then it would be impossible to open any files within that directory with any permissions other than read.&lt;/p&gt;
    &lt;p&gt;For a full list of available permissions, check the Doxygen documentation.&lt;/p&gt;
    &lt;p&gt;Im sure you have heard many an argument for and against the "everything is a file" philosophy. So I wont go over everything, but the primary reason for using it in PatchworkOS is "emergent behavior" or "composability" which ever term you prefer.&lt;/p&gt;
    &lt;p&gt;Take the namespace sharing example, notice how there isent any actually dedicated "namespace sharing" system? There are instead a series of small, simple building blocks that when added together form a more complex whole. That is emergent behavior, by keeping things simple and most importantly composable, we can create very complex behaviour without needing to explicitly design it.&lt;/p&gt;
    &lt;p&gt;Lets take another example, say you wanted to wait on multiple processes with a &lt;code&gt;waitpid()&lt;/code&gt; syscall. Well, thats not possible. So now we suddenly need a new system call. Meanwhile, in a "everything is a file system" we just have a pollable &lt;code&gt;/proc/[pid]/wait&lt;/code&gt; file that blocks untill the process dies and returns the exit status, now any behaviour that can be implemented with &lt;code&gt;poll()&lt;/code&gt; can be used while waiting on processes, including waiting on multiple processes at once, waiting on a keyboard and a process, waiting with a timeout, or any weird combination you can think of.&lt;/p&gt;
    &lt;p&gt;Plus its fun.&lt;/p&gt;
    &lt;p&gt;All benchmarks were run on real hardware using a Lenovo ThinkPad E495. For comparison, I've decided to use the Linux kernel, specifically Fedora since It's what I normally use.&lt;/p&gt;
    &lt;p&gt;Note that Fedora will obviously have a lot more background processes running and security features that might impact performance, so these benchmarks are not exactly apples to apples, but they should still give a good baseline for how PatchworkOS performs.&lt;/p&gt;
    &lt;p&gt;All code for benchmarks can be found in the benchmark program, all tests were run using the optimization flag &lt;code&gt;-O3&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The test maps and unmaps memory in varying page amounts for a set amount of iterations using generic mmap and munmap functions. Below is the results from PatchworkOS as of commit &lt;code&gt;4b00a88&lt;/code&gt; and Fedora 40, kernel version &lt;code&gt;6.14.5-100.fc40.x86_64&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;xychart-beta
title "Blue: PatchworkOS, Green: Linux (Fedora), Lower is Better"
x-axis "Page Amount (in 50s)" [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
y-axis "Time (ms)" 0 --&amp;gt; 40000
line [157, 275, 420, 519, 622, 740, 838, 955, 1068, 1175, 1251, 1392, 1478, 1601, 1782, 1938, 2069, 2277, 2552, 2938, 3158, 3473, 3832, 4344, 4944, 5467, 6010, 6554, 7114, 7486]
line [1138, 2226, 3275, 4337, 5453, 6537, 7627, 8757, 9921, 11106, 12358, 13535, 14751, 16081, 17065, 18308, 20254, 21247, 22653, 23754, 25056, 26210, 27459, 28110, 29682, 31096, 33547, 34840, 36455, 37660]
&lt;/code&gt;
    &lt;p&gt;We see that PatchworkOS performs better across the board, and the performance difference increases as we increase the page count.&lt;/p&gt;
    &lt;p&gt;There are a few potential reasons for this, one is that PatchworkOS does not use a separate structure to manage virtual memory, instead it embeds metadata directly into the page tables, and since accessing a page table is just walking some pointers, its highly efficient, additionally it provides better caching since the page tables are likely already in the CPU cache.&lt;/p&gt;
    &lt;p&gt;In the end we end up with a &lt;/p&gt;
    &lt;p&gt;Note that as the number of pages increases we start to see less and less linear performance, this is most likely due to CPU cache saturation.&lt;/p&gt;
    &lt;p&gt;For fun, we can throw the results into desmos to se that around &lt;/p&gt;
    &lt;p&gt;Performing quadratic regression on the same data gives us&lt;/p&gt;
    &lt;p&gt;From this we see that for &lt;/p&gt;
    &lt;p&gt;Of course, there are limitations to this approach, for example, it is in no way portable (which isn't a concern in our case), each address space can only contain &lt;code&gt;spawn()&lt;/code&gt; instead of a &lt;code&gt;fork()&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;All in all, this algorithm would not be a viable replacement for existing algorithms, but for PatchworkOS, it serves its purpose very efficiently.&lt;/p&gt;
    &lt;p&gt;PatchworkOS includes its own shell utilities designed around its file flags system, when file flags are used we also demonstrate the short form. Included is a brief overview with some usage examples. For convenience the shell utilities are named after their POSIX counterparts, however they are not drop-in replacements.&lt;/p&gt;
    &lt;p&gt;Opens a file path and then immediately closes it.&lt;/p&gt;
    &lt;code&gt;# Create the file.txt file only if it does not exist.
touch file.txt:create:exclusive
touch file.txt:ce

# Create the mydir directory.
touch mydir:create:directory
touch mydir:cd&lt;/code&gt;
    &lt;p&gt;Reads from stdin or provided files and outputs to stdout.&lt;/p&gt;
    &lt;code&gt;# Read the contents of file1.txt and file2.txt.
cat file1.txt file2.txt

# Read process exit status (blocks until process exits)
cat /proc/1234/wait

# Copy contents of file.txt to dest.txt and create it.
cat &amp;lt; file.txt &amp;gt; dest.txt:create
cat &amp;lt; file.txt &amp;gt; dest.txt:c&lt;/code&gt;
    &lt;p&gt;Writes to stdout.&lt;/p&gt;
    &lt;code&gt;# Write to file.txt.
echo "..." &amp;gt; file.txt

# Append to file.txt, makes "&amp;gt;&amp;gt;" unneeded.
echo "..." &amp;gt; file.txt:append
echo "..." &amp;gt; file.txt:a&lt;/code&gt;
    &lt;p&gt;Reads the contents of a directory to stdout.&lt;/p&gt;
    &lt;code&gt;# Prints the contents of mydir.
ls mydir

# Recursively print the contents of mydir.
ls mydir:recursive
ls mydir:R&lt;/code&gt;
    &lt;p&gt;Removes a file or directory.&lt;/p&gt;
    &lt;code&gt;# Remove file.txt.
rm file.txt

# Recursively remove mydir and its contents.
rm mydir:directory:recursive
rm mydir:dR&lt;/code&gt;
    &lt;p&gt;There are other utils available that work as expected, for example &lt;code&gt;stat&lt;/code&gt; and &lt;code&gt;link&lt;/code&gt;.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Requirement&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OS&lt;/cell&gt;
        &lt;cell&gt;Linux (WSL might work, but I make no guarantees)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tools&lt;/cell&gt;
        &lt;cell&gt;GCC, make, NASM, mtools, QEMU (optional)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Clone this repository, you can also use the green Code button at the top of the Github.
git clone https://github.com/KaiNorberg/PatchworkOS
cd PatchworkOS

# Build (creates PatchworkOS.img in bin/)
make all

# Run using QEMU
make run&lt;/code&gt;
    &lt;code&gt;# Clean build files
make clean

# Build with debug mode enabled
make all DEBUG=1

# Build with debug mode enabled and testing enabled (you will need to have iasl installed)
make all DEBUG=1 TESTING=1

# Debug using qemu with one cpu and GDB
make all run DEBUG=1 QEMU_CPUS=1 GDB=1

# Debug using qemu and exit on panic
make all run DEBUG=1 QEMU_EXIT_ON_PANIC=1

# Generate doxygen documentation
make doxygen

# Create compile commands file
make compile_commands&lt;/code&gt;
    &lt;p&gt;Source code can be found in the &lt;code&gt;src/&lt;/code&gt; directory, with public API headers in the &lt;code&gt;include/&lt;/code&gt; directory, private API headers are located alongside their respective source files.&lt;/p&gt;
    &lt;code&gt;.
├── meta              // Meta files including screenshots, doxygen, etc.
├── lib               // Third party files, for example doomgeneric.
├── root              // Files to copy to the root of the generated image.
└── &amp;lt;src|include&amp;gt;     // Source code and public API headers.
    ├── kernel        // The kernel and its core subsystems.
    ├── modules       // Kernel modules, drivers, filesystems, etc.
    ├── programs      // User space programs.
    ├── libstd        // The C standard library.
    └── libpatchwork  // The PatchworkOS system library, gui, etc.
&lt;/code&gt;
    &lt;p&gt;For frequent testing, it might be inconvenient to frequently flash to a USB. You can instead set up the &lt;code&gt;.img&lt;/code&gt; file as a loopback device in GRUB.&lt;/p&gt;
    &lt;p&gt;Add this entry to the &lt;code&gt;/etc/grub.d/40_custom&lt;/code&gt; file:&lt;/p&gt;
    &lt;code&gt;menuentry "Patchwork OS" {
        set root="[The grub identifer for the drive. Can be retrived using: sudo grub2-probe --target=drive /boot]"
        loopback loop0 /PatchworkOS.img # Might need to be modified based on your setup.
        set root=(loop0)
        chainloader /efi/boot/bootx64.efi
}&lt;/code&gt;
    &lt;p&gt;Regenerate grub configuration using &lt;code&gt;sudo grub2-mkconfig -o /boot/grub2/grub.cfg&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Finally copy the generated &lt;code&gt;.img&lt;/code&gt; file to your &lt;code&gt;/boot&lt;/code&gt; directory, this can also be done with &lt;code&gt;make grub_loopback&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;You should now see a new entry in your GRUB boot menu allowing you to boot into the OS, like dual booting, but without the need to create a partition.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;QEMU boot failure: Check if you are using QEMU version 10.0.0, as that version has previously caused issues. These issues appear to be fixed currently however consider using version 9.2.3&lt;/item&gt;
      &lt;item&gt;Any other errors?: If an error not listed here occurs or is not resolvable, please open an issue in the GitHub repository.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Testing uses a GitHub action that compiles the project and runs it for some amount of time using QEMU with &lt;code&gt;DEBUG=1&lt;/code&gt;, &lt;code&gt;TESTING=1&lt;/code&gt; and &lt;code&gt;QEMU_EXIT_ON_PANIC=1&lt;/code&gt; set. This will run some additional tests in the kernel (for example it will clone ACPICA and run all its runtime tests), and if QEMU has not crashed by the end of the allotted time, it is considered a success.&lt;/p&gt;
    &lt;p&gt;Note that the &lt;code&gt;QEMU_EXIT_ON_PANIC&lt;/code&gt; flag will cause any failed test, assert or panic in the kernel to exit QEMU using their "-device isa-debug-exit" feature with a non-zero exit code, thus causing the GitHub action to fail.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;QEMU emulator version 9.2.3 (qemu-9.2.3-1.fc42)&lt;/item&gt;
      &lt;item&gt;Lenovo ThinkPad E495&lt;/item&gt;
      &lt;item&gt;Ryzen 5 3600X | 32GB 3200MHZ Corsair Vengeance&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Currently untested on Intel hardware (broke student, no access to hardware). Let me know if you have different hardware, and it runs (or doesn't) for you!&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Anything from bug reports/fixes, performance improvements, new features, or even just fixing typos or adding documentation.&lt;/p&gt;
    &lt;p&gt;If you are unsure where to start, check the Todo List.&lt;/p&gt;
    &lt;p&gt;Check out the contribution guidelines to get started.&lt;/p&gt;
    &lt;p&gt;The first Reddit post and image of PatchworkOS from back when getting to user space was a massive milestone and the kernel was supposed to be a UNIX-like microkernel.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177615</guid><pubDate>Sat, 06 Dec 2025 23:33:23 +0000</pubDate></item><item><title>Kilauea erupts, destroying webcam [video]</title><link>https://www.youtube.com/watch?v=TK2N99BDw7A</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177645</guid><pubDate>Sat, 06 Dec 2025 23:39:02 +0000</pubDate></item><item><title>OpenTelemetry Distribution Builder</title><link>https://github.com/observIQ/otel-distro-builder</link><description>&lt;doc fingerprint="d80343bd7f07083"&gt;
  &lt;main&gt;
    &lt;p&gt;Build custom OpenTelemetry Collector Distributions from manifest files with a local build utility, Docker, Google Cloud Build, or a GitHub Action.&lt;/p&gt;
    &lt;p&gt;Built on top of the OpenTelemetry Collector Builder (OCB), it uses a &lt;code&gt;manifest.yaml&lt;/code&gt; to define the components you need, then automates packaging for multiple platforms and manages version releases via GitHub.&lt;/p&gt;
    &lt;p&gt;While OCB (OpenTelemetry Collector Builder) focuses on building single collector binaries, the OpenTelemetry Distribution Builder provides a complete distribution management solution:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🔨 Builds multi-platform binaries using OCB under the hood&lt;/item&gt;
      &lt;item&gt;📦 Generates installation packages following OTel community best practices&lt;/item&gt;
      &lt;item&gt;🚀 Automates versioned releases through GitHub Actions&lt;/item&gt;
      &lt;item&gt;🔄 Simplifies updates through manifest-based configuration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It handles all the complex aspects of managing your own distribution that have historically made building custom collectors challenging. With the OpenTelemetry Distribution Builder, you can focus on defining your components while the tooling takes care of the rest.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🎯 Custom Component Selection: Build distributions with exactly the components you need&lt;/item&gt;
      &lt;item&gt;🌐 Multi-Platform Support: Build for multiple architectures (amd64, arm64)&lt;/item&gt;
      &lt;item&gt;📦 Multiple Package Formats: Generate APK, DEB, RPM, and TAR.GZ packages&lt;/item&gt;
      &lt;item&gt;🔄 GitHub Actions Integration: Seamless CI/CD integration&lt;/item&gt;
      &lt;item&gt;🚀 Automated Releases: Streamlined versioning and release process&lt;/item&gt;
      &lt;item&gt;🔍 Platform-Specific Builds: Optimize for your target environment&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Create a new repository&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Add your manifest file (&lt;/p&gt;&lt;code&gt;manifest.yaml&lt;/code&gt;):&lt;quote&gt;dist: name: my-otelcol description: My Custom OpenTelemetry Collector Distro # ... extensions: - # ... exporters: - # ... processors: - # ... receivers: - # ... connectors: - # ... providers: - # ...&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Set up GitHub Actions (&lt;/p&gt;&lt;code&gt;.github/workflows/build.yml&lt;/code&gt;):&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;name: OpenTelemetry Distribution Build

on:
   push:
     tags:
       - "v*"
   workflow_dispatch:

  permissions:
    contents: write # This is required for creating/modifying releases

  jobs:
    build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # Build the OpenTelemetry distribution using this custom action
      - uses: observiq/otel-distro-builder@v1
        with:
          manifest: "./manifest.yaml"

      # Create a GitHub Release and attach the build artifacts
      # This makes the artifacts available for download from the Releases page
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          files: ${{ github.workspace }}/artifacts/*&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Trigger a build:&lt;/p&gt;
        &lt;code&gt;git tag v1.0.0 &amp;amp;&amp;amp; git push --tags&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;(Optional) Build with Docker:&lt;/p&gt;
        &lt;quote&gt;docker pull ghcr.io/observiq/otel-distro-builder:main docker run --rm -v $(pwd):/workspace -v $(pwd)/build:/build ghcr.io/observiq/otel-distro-builder:main \ --manifest /workspace/manifest.yaml&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To view detailed guides, see the docs directory.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Input&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;manifest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to manifest file&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;./manifest.yaml&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;platforms&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Target platforms&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;linux/amd64&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All generated packages and binaries are available in the &lt;code&gt;${{ github.workspace }}/artifacts/*&lt;/code&gt; folder.&lt;/p&gt;
    &lt;code&gt;# Pull the latest version
docker pull ghcr.io/observiq/otel-distro-builder:latest

# Pull specific version
docker pull ghcr.io/observiq/otel-distro-builder:v1.0.5

# Run a build
docker run --rm -v $(pwd):/workspace -v $(pwd)/build:/build ghcr.io/observiq/otel-distro-builder:main \
  --manifest /workspace/manifest.yaml \
  # Optional
  --artifacts /workspace/artifacts \
  --goos linux \
  --goarch amd64 \
  --ocb-version 0.121.0 \
  --go-version 1.22.1 \ 
  --supervisor-version 0.122.0&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python 3&lt;/item&gt;
      &lt;item&gt;Docker&lt;/item&gt;
      &lt;item&gt;Make&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Show all commands
make help

# Setup development environment
make setup

# Run tests
make test

# Run linting
make lint
&lt;/code&gt;
    &lt;p&gt;Triggers a build using Google Cloud Build:&lt;/p&gt;
    &lt;code&gt;./scripts/run_cloud_build.sh -m manifest.yaml -p project_id -b artifact_bucket&lt;/code&gt;
    &lt;p&gt;Options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-m&lt;/code&gt;: Path to manifest file (required)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-p&lt;/code&gt;: Google Cloud project ID&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-b&lt;/code&gt;: Artifact bucket name&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This script is used to build a custom OpenTelemetry Collector distribution using a local Docker container:&lt;/p&gt;
    &lt;code&gt;./scripts/run_local_build.sh -m manifest.yaml [-o output_dir] [-v ocb_version] [-g go_version]

# Optionally, run it with
make build-local # to get the latest version of the otelcol and ocb
# Or
make build output_dir=./artifacts ocb_version=0.121.0 go_version=1.22.1 supervisor_version=0.122.0&lt;/code&gt;
    &lt;p&gt;Options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-m&lt;/code&gt;: Path to manifest file (required)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-o&lt;/code&gt;: Directory to store build artifacts (default: ./artifacts)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-v&lt;/code&gt;: OpenTelemetry Collector Builder version (default: auto-detected from manifest)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-g&lt;/code&gt;: Go version to use for building (default: 1.24.1)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The artifacts will be saved to the specified output directory (default: &lt;code&gt;./artifacts&lt;/code&gt;).&lt;/p&gt;
    &lt;code&gt;otel-distro-builder/
├── builder/                # Builder application
│   ├── src/               # Core builder code
│   ├── templates/         # Build templates
│   ├── tests/            # Test suite
│   └── Dockerfile        # Builder image definition
├── action/                # GitHub Action
├── scripts/              # Build scripts
└── Makefile              # Development commands
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Builder Image Preparation: Build and push to registry&lt;/item&gt;
      &lt;item&gt;Manifest Processing: Upload and validate manifest configuration&lt;/item&gt;
      &lt;item&gt;Build Execution: &lt;list rend="ul"&gt;&lt;item&gt;Download OpenTelemetry Collector Builder (OCB)&lt;/item&gt;&lt;item&gt;Generate Go source files&lt;/item&gt;&lt;item&gt;Build platform-specific packages&lt;/item&gt;&lt;item&gt;Create SBOMs and checksums&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Artifact Management: Upload to GitHub, Google Cloud Storage, or save locally&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The builder produces:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;📦 Binary packages (APK, DEB, RPM)&lt;/item&gt;
      &lt;item&gt;📚 Source tarball&lt;/item&gt;
      &lt;item&gt;🔧 Raw binary&lt;/item&gt;
      &lt;item&gt;📋 SBOM files&lt;/item&gt;
      &lt;item&gt;🔍 Checksums&lt;/item&gt;
      &lt;item&gt;📝 Build metadata&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local builds: &lt;code&gt;./artifacts&lt;/code&gt;directory&lt;/item&gt;
      &lt;item&gt;Cloud builds: &lt;code&gt;gs://&amp;lt;bucket&amp;gt;/&amp;lt;build_id&amp;gt;/&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We follow semantic versioning. The builder is available in several forms:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub Action: Use &lt;code&gt;@v1&lt;/code&gt;for latest 1.x version, or&lt;code&gt;@v1.0.5&lt;/code&gt;for specific versions&lt;/item&gt;
      &lt;item&gt;Docker Image: Use &lt;code&gt;main&lt;/code&gt;for latest, or version tags like&lt;code&gt;v1.0.5&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Container Registry: &lt;code&gt;ghcr.io/observiq/otel-distro-builder:main&lt;/code&gt;or&lt;code&gt;ghcr.io/observiq/otel-distro-builder:v1.0.5&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check out our example workflows in &lt;code&gt;.github/workflows/examples/&lt;/code&gt; for common use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multi-platform builds&lt;/item&gt;
      &lt;item&gt;Container publishing&lt;/item&gt;
      &lt;item&gt;Custom package configurations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome contributions! Please see our Contributing Guide for details.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the Apache 2.0 License - see the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177664</guid><pubDate>Sat, 06 Dec 2025 23:41:18 +0000</pubDate></item><item><title>Show HN: FuseCells – a handcrafted logic puzzle game with 2,500 levels</title><link>https://apps.apple.com/us/app/fusecells-logic-grid-puzzle/id6754704139</link><description>&lt;doc fingerprint="af0fffcd9b43ed25"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FuseCells: Logic Grid Puzzle&lt;/head&gt;
    &lt;head rend="h2"&gt;Strategic Thinking Deduction&lt;/head&gt;
    &lt;p&gt;Free Â· InâApp Purchases Â· Designed for iPad&lt;/p&gt;
    &lt;p&gt; FuseCells blends Sudoku deduction, Minesweeper logic, and Nonogram-style reasoning into a clean cosmic puzzle experience. Every puzzle is handcrafted and fully logical. FuseCells is a clean, no ads, satisfying logic puzzle that blends the deduction of Sudoku, the neighbor logic of Minesweeper, and the pattern reasoning of Nonogram into one fresh cosmic experience. Every puzzle is handcrafted and fully solvable using pure logic, no guessing, no randomness. How It Works: Fill the grid with symbols (Planet, Star, Moon) using number hints. Each hint shows how many neighbors must share the same symbol, in either 4-way or 8-way mode. Green means correct, yellow means possible, red means impossible â follow the logic and the solution emerges naturally. Whatâs Inside: â¢ Three sectors with unique atmosphere: Solar System, Milky Way, Deep Space â¢ 2500 handcrafted puzzles with progressive difficulty â¢ Crystal rating system that rewards perfect logic â¢ Daily Challenges with bonus rewards â¢ Smart hint system for difficult moments â¢ Beautiful cosmic visuals and a relaxing, minimalist design Why Players Love It: â¢ Pure logical deduction â never guess â¢ No ads in the free version â¢ Works fully offline â¢ Clean, color-coded feedback â¢ Perfect for short sessions or long logic runs â¢ Inspired by classic puzzles but completely original in design Free vs Pro Free: 50 levels per sector, Daily Challenges, all game modes Pro: All 2500 levels, future sectors Start your cosmic logic journey today and see why so many players enjoy this unique puzzle experience. The grid is waiting. &lt;/p&gt;
    &lt;p&gt; Winter Style Added! â¢ Fresh winter-themed UI design â¢ Bug fixes and improvements â¢ Enhanced performance Stay cozy and enjoy puzzling! &lt;/p&gt;
    &lt;p&gt;The developer, Igor Cuiumju, indicated that the appâs privacy practices may include handling of data as described below. For more information, see the developerâs privacy policy .&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h2"&gt;Data Not Linked to You&lt;/head&gt;
        &lt;p&gt;The following data may be collected but it is not linked to your identity:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Purchases&lt;/item&gt;
          &lt;item&gt;Identifiers&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Accessibility&lt;/head&gt;
    &lt;p&gt;The developer has not yet indicated which accessibility features this app supports. Learn More&lt;/p&gt;
    &lt;head rend="h2"&gt;Information&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item&gt;
        &lt;item class="svelte-z7zy89" rend="dt-1"&gt;Seller&lt;/item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Igor Cuiumju&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;item class="svelte-z7zy89" rend="dt-1"&gt;Size&lt;/item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;28.2 MB&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;item class="svelte-z7zy89" rend="dt-1"&gt;Category&lt;/item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Puzzle&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;item class="svelte-z7zy89" rend="dt-1"&gt;Compatibility&lt;/item&gt;
        &lt;head class="svelte-lyqho4"&gt;Requires iOS 15.6 or later.&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;iPhone&lt;lb/&gt;Requires iOS 15.6 or later.&lt;/item&gt;
          &lt;item&gt;iPad&lt;lb/&gt;Requires iPadOS 15.6 or later.&lt;/item&gt;
          &lt;item&gt;iPod touch&lt;lb/&gt;Requires iOS 15.6 or later.&lt;/item&gt;
          &lt;item&gt;Mac&lt;lb/&gt;Requires macOS 12.5 or later and a Mac with Apple M1 chip or later.&lt;/item&gt;
          &lt;item&gt;Apple Vision&lt;lb/&gt;Requires visionOS 1.0 or later.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;item class="svelte-z7zy89" rend="dt-1"&gt;Languages&lt;/item&gt;
        &lt;head class="svelte-lyqho4"&gt;English and 9 more&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;English, French, German, Italian, Japanese, Korean, Portuguese, Russian, Simplified Chinese, Spanish&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;item class="svelte-z7zy89" rend="dt-1"&gt;Age Rating&lt;/item&gt;
        &lt;head class="svelte-lyqho4"&gt;4+&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;4+&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;item class="svelte-z7zy89" rend="dt-1"&gt;In-App Purchases&lt;/item&gt;
        &lt;head class="svelte-lyqho4"&gt;Yes&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;FuseCells 10 Hints Pack $0.99&lt;/item&gt;
          &lt;item&gt;FuseCells 30 Hints Pack $1.99&lt;/item&gt;
          &lt;item&gt;FuseCells 100 Hints Pack $4.99&lt;/item&gt;
          &lt;item&gt;FuseCells PRO Lifetime $3.99&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;item class="svelte-z7zy89" rend="dt-1"&gt;Copyright&lt;/item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Â© Igor Cuiumju&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46177737</guid><pubDate>Sat, 06 Dec 2025 23:51:08 +0000</pubDate></item><item><title>Trains cancelled over fake bridge collapse image</title><link>https://www.bbc.com/news/articles/cwygqqll9k2o</link><description>&lt;doc fingerprint="751d1d963c6ce490"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Trains cancelled over fake bridge collapse image&lt;/head&gt;
    &lt;p&gt;Trains were halted after a suspected AI-generated picture that seemed to show major damage to a bridge appeared on social media following an earthquake.&lt;/p&gt;
    &lt;p&gt;The tremor, which struck on Wednesday night, was felt across Lancashire and the southern Lake District.&lt;/p&gt;
    &lt;p&gt;Network Rail said it was made aware of the image which appeared to show major damage to Carlisle Bridge in Lancaster at 00:30 GMT and stopped rail services across the bridge while safety inspections were carried out.&lt;/p&gt;
    &lt;p&gt;A BBC journalist ran the image through an AI chatbot which identified key spots that may have been manipulated.&lt;/p&gt;
    &lt;p&gt;Network Rail said the railway line was fully reopened at around 02:00 GMT and it has urged people to "think about the serious impact it could have" before creating or sharing hoax images.&lt;/p&gt;
    &lt;p&gt;"The disruption caused by the creation and sharing of hoax images and videos like this creates a completely unnecessary delay to passengers at a cost to the taxpayer," a spokesperson said.&lt;/p&gt;
    &lt;p&gt;"It adds to the high workload of our frontline teams, who work extremely hard to keep the railway running smoothly," the spokesperson said.&lt;/p&gt;
    &lt;p&gt;"The safety of rail passengers and staff is our number one priority and we will always take any safety concerns seriously."&lt;/p&gt;
    &lt;p&gt;The British Transport Police said it was "made aware" of the situation but there was no ongoing investigation into the incident.&lt;/p&gt;
    &lt;p&gt;Network Rail said 32 services including passenger and freight trains were delayed because of hoax.&lt;/p&gt;
    &lt;p&gt;A spokesperson for the rail provider said a mix of passenger and freight train would have been impacted.&lt;/p&gt;
    &lt;p&gt;They said some of them would have been directly stopped or slowed while it checked the lines, but a lot of the trains were delayed as a result of earlier services still being in their path.&lt;/p&gt;
    &lt;p&gt;The spokesperson said many of them would have been local but because of the length of the West Coast Main Line some trains were delayed as far north as Scotland.&lt;/p&gt;
    &lt;p&gt;Railway expert Tony Miles said due to the timing of the incident, very few passengers will have been impacted by the hoax as the services passing through at that time were primarily freight and sleeper trains.&lt;/p&gt;
    &lt;p&gt;"They generally go slow so as not to disturb the passengers trying to sleep - this means they have a bit of leeway to go faster and make up time if they encounter a delay," he said.&lt;/p&gt;
    &lt;p&gt;"It's more the fact that Network Rail will have had to mobilise a team to go and check the bridge which could impact their work for days."&lt;/p&gt;
    &lt;p&gt;He urged people to consider hoaxes like this could have on real people.&lt;/p&gt;
    &lt;p&gt;"If they actually did delay a train it could have impacted someone who had to get to a medical appointment, or a flight or a funeral.&lt;/p&gt;
    &lt;p&gt;"It may seem like a game, but anyone who's thinking of doing this should consider how it will impact real people."&lt;/p&gt;
    &lt;p&gt;Listen to the best of BBC Radio Lancashire on Sounds and follow BBC Lancashire on Facebook, X and Instagram. You can also send story ideas via Whatsapp to 0808 100 2230.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178108</guid><pubDate>Sun, 07 Dec 2025 00:37:15 +0000</pubDate></item><item><title>Using LLMs at Oxide</title><link>https://rfd.shared.oxide.computer/rfd/0576</link><description>&lt;doc fingerprint="ab11131f2d2c5aa1"&gt;
  &lt;main&gt;
    &lt;p&gt;Large language models (LLMs) are an indisputable breakthrough of the last five years, potentially profoundly changing the way that we work. As with any extraordinarily powerful tool, LLM use has both promise and peril — and that they are so general-purpose leaves real questions about how and when they should be used. The landscape is shifting so rapidly that static prescription is unlikely — but that LLMs are evolving so quickly also gives urgency to the question: how should LLMs be used at Oxide?&lt;/p&gt;
    &lt;head rend="h2"&gt;Values in LLM usage&lt;/head&gt;
    &lt;p&gt;As is our wont, it’s helpful to look at LLM use through the lens of our values, several of which come to mind, listed here in priority order:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Responsibility: In terms of LLM use at Oxide, our lodestar is our sense of responsibility. However powerful they may be, LLMs are but a tool, ultimately acting at the behest of a human. Oxide employees bear responsibility for the artifacts we create, whatever automation we might employ to create them. That is, human judgement remains firmly in the loop: even if or as an LLM is generating an artifact that we will use (writing, test cases, documentation, code, etc.), their output is the responsibility of the human using them.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rigor: LLMs are double-edged with respect to rigor. On the one hand, wielded carefully, they can help us sharpen our own thinking by pointing out holes in our own reasoning or otherwise providing thought-provoking suggestions. On the other, if used recklessly or thoughtlessly, they can have the opposite effect, replacing crisp thinking with generated flotsam. LLMs are useful in as much as they promote and reinforce our rigor.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Empathy: Be we readers or writers, there are humans on the other end of our language use. As we use LLMs, we must keep in mind our empathy for that human, be they the one who is consuming our writing, or the one who has written what we are reading.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Teamwork: We are working together on a shared endeavor, and we must be sure that our LLM use does not undermine our sense of teamwork. Specifically, we must be careful to not use LLMs in such a way as to undermine the trust that we have in one another. This isn’t as simple as disclosure of usage: and in fact, volunteering that an LLM has been used to generate work product is to implicitly distance oneself from the responsibility for the content — and serves as to erode the trust that is essential for teamwork.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Urgency: Urgency seems natural with a tool that can seemingly do so much knowledge work so quickly, but with respect to LLM use, too many organizations have seemingly enshrined urgency over all else. These organizations treat LLMs as an opportunity to increase pace over all else, seemingly without regard for setting direction. Urgency is certainly important, and LLMs absolutely afford an opportunity to do work more quickly — but that pace must not come at the expense of our responsibility, rigor, empathy and teamwork.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Uses of LLMs&lt;/head&gt;
    &lt;p&gt;LLM use varies widely, and the ramifications of those uses vary accordingly; it’s worth taking apart several of the (many) uses for LLMs.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as readers&lt;/head&gt;
    &lt;p&gt;LLMs are superlative at reading comprehension, able to process and meaningfully comprehend documents effectively instantly. This can be extraordinarily powerful for summarizing documents — or of answering more specific questions of a large document like a datasheet or specification. (Ironically, LLMs are especially good at evaluating documents to assess the degree that an LLM assisted their creation!)&lt;/p&gt;
    &lt;p&gt;While use of LLMs to assist comprehension has little downside, it does come with an important caveat: when uploading a document to a hosted LLM (ChatGPT, Claude, Gemini, etc.), there must be assurance of data privacy — and specifically, assurance that the model will not use the document to train future iterations of itself. Note that this may be opt-out (that is, by default, a model may reserve the right to train on uploaded documents), but can generally be controlled via preferences — albeit occasionally via euphemism. (OpenAI shamelessly calls this checked-by-default setting "Improve the model for everyone", making anyone who doesn’t wish the model to train on their data feel as if they suffer from a kind of reactionary avarice.)&lt;/p&gt;
    &lt;p&gt;A final cautionary note: using LLMs to assist comprehension should not substitute for actually reading a document where such reading is socially expected. More concretely: while LLMs can be a useful tool to assist in the evaluating of candidate materials per [rfd3], their use should be restricted to be as a tool, not as a substitute for human eyes (and brain!).&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as editors&lt;/head&gt;
    &lt;p&gt;LLMs can be excellent editors. Engaging an LLM late in the creative process (that is, with a document already written and broadly polished), allows for LLMs to provide helpful feedback on structure, phrasing, etc. — all without danger of losing one’s own voice. A cautionary note here: LLMs are infamous pleasers — and you may find that the breathless praise from an LLM is in fact more sycophancy than analysis. This becomes more perilous the earlier one uses an LLM in the writing process: the less polish a document already has, the more likely it is that an LLM will steer to something wholly different — at once praising your groundbreaking genius while offering to rewrite it for you.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as writers&lt;/head&gt;
    &lt;p&gt;While LLMs are adept at reading and can be terrific at editing, their writing is much more mixed. At best, writing from LLMs is hackneyed and clichÃ©-ridden; at worst, it brims with tells that reveal that the prose is in fact automatically generated.&lt;/p&gt;
    &lt;p&gt;What’s so bad about this? First, to those who can recognize an LLM’s reveals (an expanding demographic!), it’s just embarrassing — it’s as if the writer is walking around with their intellectual fly open. But there are deeper problems: LLM-generated writing undermines the authenticity of not just one’s writing but of the thinking behind it as well. If the prose is automatically generated, might the ideas be too? The reader can’t be sure — and increasingly, the hallmarks of LLM generation cause readers to turn off (or worse).&lt;/p&gt;
    &lt;p&gt;Finally, LLM-generated prose undermines a social contract of sorts: absent LLMs, it is presumed that of the reader and the writer, it is the writer that has undertaken the greater intellectual exertion. (That is, it is more work to write than to read!) For the reader, this is important: should they struggle with an idea, they can reasonably assume that the writer themselves understands it — and it is the least a reader can do to labor to make sense of it.&lt;/p&gt;
    &lt;p&gt;If, however, prose is LLM-generated, this social contract becomes ripped up: a reader cannot assume that the writer understands their ideas because they might not so much have read the product of the LLM that they tasked to write it. If one is lucky, these are LLM hallucinations: obviously wrong and quickly discarded. If one is unlucky, however, it will be a kind of LLM-induced cognitive dissonance: a puzzle in which pieces don’t fit because there is in fact no puzzle at all. This can leave a reader frustrated: why should they spend more time reading prose than the writer spent writing it?&lt;/p&gt;
    &lt;p&gt;This can be navigated, of course, but it is truly perilous: our writing is an important vessel for building trust — and that trust can be quickly eroded if we are not speaking with our own voice. For us at Oxide, there is a more mechanical reason to be jaundiced about using LLMs to write: because our hiring process very much selects for writers, we know that everyone at Oxide can write — and we have the luxury of demanding of ourselves the kind of writing that we know that we are all capable of.&lt;/p&gt;
    &lt;p&gt;So our guideline is to generally not use LLMs to write, but this shouldn’t be thought of as an absolute — and it doesn’t mean that an LLM can’t be used as part of the writing process. Just please: consider your responsibility to yourself, to your own ideas — and to the reader.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as code reviewers&lt;/head&gt;
    &lt;p&gt;As with reading comprehension and editing, LLMs can make for good code reviewers. But they can also make nonsense suggestions or otherwise miss larger issues. LLMs should be used for review (and can be very helpful when targeted to look for a particular kind of issue), but that review should not be accepted as a human substitute.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as debuggers&lt;/head&gt;
    &lt;p&gt;LLMs can be surprisingly helpful debugging problems, but perhaps only because our expectations for them would be so low. While LLMs shouldn’t be relied upon (clearly?) to debug a problem, they can serve as a kind of animatronic rubber duck, helping to inspire the next questions to ask. (And they can be surprising: LLMs have been known to debug I2C issues from the screenshot of a scope capture!) When debugging a vexing problem one has little to lose by using an LLM — but perhaps also little to gain.&lt;/p&gt;
    &lt;head rend="h3"&gt;LLMs as programmers&lt;/head&gt;
    &lt;p&gt;LLMs are amazingly good at writing code — so much so that there is borderline mass hysteria about LLMs entirely eliminating software engineering as a craft. As with using an LLM to write prose, there is obvious peril here! Unlike prose, however (which really should be handed in a polished form to an LLM to maximize the LLM’s efficacy), LLMs can be quite effective writing code de novo. This is especially valuable for code that is experimental or auxiliary or otherwise throwaway. The closer code is to the system that we ship, the greater care needs to be shown when using LLMs. Even with something that seems natural for LLM contribution (e.g., writing tests), one should still be careful: it’s easy for LLMs to spiral into nonsense on even simple tasks. Still, they can be extraordinarily useful — and can help to provide an entire spectrum of utility in writing software; they shouldn’t be dismissed out of hand.&lt;/p&gt;
    &lt;p&gt;Wherever LLM-generated code is used, it becomes the responsibility of the engineer. As part of this process of taking responsibility, self-review becomes essential: LLM-generated code should not be reviewed by others if the responsible engineer has not themselves reviewed it. Moreover, once in the loop of peer review, generation should more or less be removed: if code review comments are addressed by wholesale re-generation, iterative review becomes impossible.&lt;/p&gt;
    &lt;p&gt;In short, where LLMs are used to generate code, responsibility, rigor, empathy and teamwork must remain top of mind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mechanics&lt;/head&gt;
    &lt;p&gt;Mechanical details of using LLMs — along with many specific tips and links — can be found in the (internal) LLMs at Oxide document.&lt;/p&gt;
    &lt;head rend="h2"&gt;Determinations&lt;/head&gt;
    &lt;p&gt;Broadly speaking, LLM use is encouraged at Oxide, but that use must always be consistent with our deeply-held sense of responsibility: our responsibility to our product, our responsibility to our customers — and our responsibility to one another.&lt;/p&gt;
    &lt;head rend="h2"&gt;External References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;[rfd3] Oxide Computer Company. RFD 3 Oxide Hiring Process. https://rfd.shared.oxide.computer/rfd/0003.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178347</guid><pubDate>Sun, 07 Dec 2025 01:17:40 +0000</pubDate></item><item><title>Eurydice: a Rust to C compiler (yes)</title><link>https://jonathan.protzenko.fr/2025/10/28/eurydice.html</link><description>&lt;doc fingerprint="7e2eb37eada7ba38"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Eurydice: a Rust to C compiler (yes)&lt;/head&gt;
    &lt;p&gt;Perhaps the greatest surprise of the last two years was, for me, the realization that people not only care about compiling C to Rust (for obvious reasons, such as, ahem, memory safety) â they also care about compiling Rust to C! Wait, what?&lt;/p&gt;
    &lt;p&gt;I wrote about this briefly a couple years ago, but the level of interest for the project, I must say, took me somewhat by surprise. So letâs talk about compiling Rust to C a little more today.&lt;/p&gt;
    &lt;head rend="h1"&gt;Barriers to Rust adoption&lt;/head&gt;
    &lt;p&gt;Rust is making big progress in terms of adoption, and represents a great value proposition, especially for new code. Both my former employer and my new employer, like pretty much everyone else these days, have big projects that are written in pure Rust or can have Rust components. Even Windows kernel drivers can be written in Rust now. Amazing stuff.&lt;/p&gt;
    &lt;p&gt;However, if your project is, say, an open-source library that gets compiled on a wonderfully diverse set of target architectures, OSes, distributions and toolchains, well, chances areâ¦ one of these is not going to support Rust. Think of a crypto library: there will be people out there with an obscure compiler for a weird embedded target, and they really want to compile your library, because theyâve been told not to roll out their own crypto. Or perhaps you have a format library ridden with memory errors and you want to port it to Rust. Or maybe your company has an in-house analysis that only runs on C code. Regardless of the scenario, there will always be that one legacy use-case that prevents you from switching to Rust until itâs 2035, all those LTS versions (looking at you RHEL) are finally retired, and you yourself are too close to retirement to even care anymore.&lt;/p&gt;
    &lt;p&gt;That is, unless youâre willing to use a Rust to C compiler.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why?&lt;/head&gt;
    &lt;p&gt;Having a backwards-compat scenario where Rust can be compiled to C serves several purposes.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It allows for a gradual transition. The codebase can be ported to Rust, and refactored / cleaned up / rewritten to use all the nice Rust things (data types, pattern-matching, polymorphism, memory safety), thus making you and your developers much, much happier. Meanwhile, the C version co-exists so that you donât alienate your userbase.&lt;/item&gt;
      &lt;item&gt;It only requires maintaining a single version. The Rust code is authoritative; the C code is derived from it automatically, either on CI, or at least with a CI job that checks that the two are in sync.&lt;/item&gt;
      &lt;item&gt;It allows for a census of problematic scenarios. By making the Rust version the default (and putting the fallback C behind a &lt;code&gt;--write-us-an-email&lt;/code&gt;flag), there is finally a way to enumerate those mythical users who cannot switch to Rust just yet.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If that sounds appealing, meet Eurydice.&lt;/p&gt;
    &lt;head rend="h1"&gt;Eurydice&lt;/head&gt;
    &lt;p&gt;Eurydice is a compiler from Rust to C that aims to produce readable C code. Of course, readability is subjective; also, seeing that Rust relies on whole-program monomorphization, the C code is bound to be more verbose than the Rust code. But you can judge for yourself: hereâs the result of compiling libcrux to C.&lt;/p&gt;
    &lt;p&gt;The output of the test suite is under version control, and there are a lot more tests to peruse. See for instance this bit, compared to the Rust original.&lt;/p&gt;
    &lt;head rend="h1"&gt;The design of Eurydice&lt;/head&gt;
    &lt;p&gt;Eurydice plugs in directly at the MIR level, using Charon to avoid reimplementing the wheel and paying the price of interacting with the guts of &lt;code&gt;rustc&lt;/code&gt;. Our
paper on Charon says more about its
architecture.&lt;/p&gt;
    &lt;p&gt;The advantage of plugging in at the MIR level is that i) we do not have to interpret syntactic sugar, which means our translation is more faithful to the Rust semantics, and ii) we have way fewer constructs that need compiling to C. Even then, itâs no easy feat to translate Rust to C.&lt;/p&gt;
    &lt;p&gt;There is naturally, the need to perform whole-program monomorphization, over types and const-generic arguments; the compilation of pattern matches into tagged unions; recognizing instances of iterators that can be compiled to native C &lt;code&gt;for&lt;/code&gt;-loops. Then, there are more subtle things, such as compiling array
repeat expressions sensibly â zero-initializers when possible, initializer
lists otherwise, unless it generates too much code, in which case &lt;code&gt;for&lt;/code&gt;-loops are
preferable. And finally, there are all the rules about visibility, &lt;code&gt;static&lt;/code&gt;,
&lt;code&gt;inline&lt;/code&gt;, etc. that are very C-specific and depend on how you want to lay out
your C files.&lt;/p&gt;
    &lt;p&gt;The translation is complicated by the constraint that the generated code ought to be readable: for instance, we compile Rust structs to C structs, including DSTs, by relying on flexible array members. We also work hard to avoid using the fully-generic tagged union pattern when possible, instead eliminating the tag when e.g. the Rust enum only has a single case. Additionally, we rely on Charon to reconstruct control-flow, rather than compile the MIR CFG to C code ridden with &lt;code&gt;goto&lt;/code&gt;s; again, this is for code quality.&lt;/p&gt;
    &lt;p&gt;At a low-level, there were many interesting tidbits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Because arrays in Rust are values, we wrap them within C structs to give them value semantics in C, too; concretely, &lt;code&gt;[u32; 8]&lt;/code&gt;becomes&lt;code&gt;struct { uint32_t data[8]; }&lt;/code&gt;. (A previous version of Eurydice would emit&lt;code&gt;uint32_t *&lt;/code&gt;, and rely on various&lt;code&gt;memcpy&lt;/code&gt;s to implement value semantics, but this produced a translation that was not type-generic, and there were plenty of finicky corner cases. We revamped the compilation scheme recently.)&lt;/item&gt;
      &lt;item&gt;The notion of &lt;code&gt;lvalue&lt;/code&gt;in C means we need to insert more variable declarations than in Rust â for instance, you canât trivially compile&lt;code&gt;&amp;amp;[0u32; 1]&lt;/code&gt;without naming the array.&lt;/item&gt;
      &lt;item&gt;The fact that the evaluation order is so loosely defined in C means that intermediary computations need to be stored in intermediary variables to enforce the evaluation order.&lt;/item&gt;
      &lt;item&gt;Rust relies on whole-program monomorphization; this means that the C code is inevitably going to contains multiple copies of the same types and functions, but for different choices of type and const generic argumnets. This is currently done with a builtin phase in Eurydice (for historical reasons), but in the long run, we want to rely on Charonâs support for monomorphization.&lt;/item&gt;
      &lt;item&gt;There are plenty of peephole optimizations that are required for good code quality, such as recognizing &lt;code&gt;array::from_fn&lt;/code&gt;and generating sensible code that initializes the array in-place (instead of relying on the fully-general compilation scheme for closures), or recognizing instances of the&lt;code&gt;Eq&lt;/code&gt;trait that deserve dedicated treatment (such as using&lt;code&gt;memcmp&lt;/code&gt;for arrays and slices of flat data).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A final design choice is that for now, Eurydice may define more behaviors than Rust â for instance, Rust panics on integer overflow, but Eurydice-compiled code does not. This is because we assume the input code is verified, and therefore has been shown to be free of panics. This design choice can be easily changed, though.&lt;/p&gt;
    &lt;p&gt;In practice, as soon as you use traits, the C code becomes more voluminous than the Rust code. We rely on a configuration file mechanism to control the placement of monomorphized instances of a given function, rather than put everything in one big C file. This currently requires a lot of manual intervention to give good results on large projects.&lt;/p&gt;
    &lt;head rend="h1"&gt;Implementing of Eurydice&lt;/head&gt;
    &lt;p&gt;Eurydice starts by compiling the MIR AST obtained out of Charon into KaRaMeLâs internal AST. This is ~3000 lines of OCaml code, so thatâs already pretty involved. A lot of the work revolves around trait methods and their monomorphization, given Rustâs expressive trait system.&lt;/p&gt;
    &lt;p&gt;Then, about 30 nanopasses simplify the KaRaMeL AST until it becomes eligible for compilation to C. Of those, a handful were originally written for KaRaMeL and were somewhat reusable; this includes compilation of data types, as well as monomorphization. The rest was written from scratch for Eurydice, and totals about ~5000 lines of OCaml code.&lt;/p&gt;
    &lt;p&gt;A particularly gnarly phase was eliminating MIRâs variable assignments as much as possible: in MIR, every variable starts out uninitialized at the beginning of the function; then, in lieu of the variable declaration, we have an assignment with the initial value. Naturally, having a variable declaration in the right spot is better for code quality, so an initial phase tries to reconstruct these assignments. Thatâs a drawback of using MIR, but we still firmly believe that sticking to something that has clear semantics is ultimately better.&lt;/p&gt;
    &lt;p&gt;Fun fact: because there are so many peephole optimizations, I got tired of maintaining enormous pattern-matches that would try to catch every flavor of Rust iterator that can be compiled to a C for-loop. Instead, a custom OCaml syntax extension allows writing concrete syntax for the internal KaRaMeL language in OCaml patterns. Those magic patterns then get compiled at compile-time to OCaml AST nodes for an actual OCaml pattern that matches the (deeply-embedded) syntax of KaRaMeLâs AST. This relies on a &lt;code&gt;ppx&lt;/code&gt;
that lexes, parses and compiles the concrete syntax.&lt;/p&gt;
    &lt;head rend="h1"&gt;Deploying Eurydice-generated code&lt;/head&gt;
    &lt;p&gt;Eurydice-generated code expects some hand-written glue that contains macros and &lt;code&gt;static inline&lt;/code&gt; functions; sometimes, itâs simply more convenient to write a
single macro that uses a type, rather than have Eurydice generate N copies of a
polymorphic function that gets specialized each time. A typical example is
compiling the Eq trait for arrays: itâs nicer to emit &lt;code&gt;Eurydice_array_eq(a1, a2,
len, t)&lt;/code&gt;, which macro-expands to &lt;code&gt;!(memcmp(a1, a2, len*sizeof(t)))&lt;/code&gt;, rather than
have N such functions, each containing a for-loop specialized for different
values of &lt;code&gt;t&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Eurydice generates code that is either (C11 and C++20-compatible) or (C++-17 compatible, but not C-compatible). The reason for this is that Rust allows enum values (e.g. &lt;code&gt;Foo { bar: baz }&lt;/code&gt;) in any expression position. For simplicity,
Eurydice emits a compound initializer &lt;code&gt;(Foo) { .tag = bar, .value = { .case_Foo
= { .bar = baz }}}&lt;/code&gt;, or a C++20 aggregate that uses designated initializers,
relying on a macro (not shown here) to hide the syntax differences between the
two. But C++17 does not have designated initializers, so there is an option for
Eurydice to emit different code that relies on member pointers to achieve
sensibly the same effect.&lt;/p&gt;
    &lt;head rend="h1"&gt;Limitations of Eurydice&lt;/head&gt;
    &lt;p&gt;Naturally, there are many limitations to this approach. Here are the main ones that come to mind:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;we cannot guarantee that the layout of objects will be the same in C as in Rust; conceivably, one could parse the layout information from MIR, then emit compiler-specific alignment directives to keep the two identical, but this is not done currently;&lt;/item&gt;
      &lt;item&gt;the generated code violates strict aliasing, because creating a user-defined DST involves casting one pointer type (a struct containing an array) to another (a struct with a flexible array member instead); Iâm not sure what the best fix is, so for now, please compile your code with &lt;code&gt;-fno-strict-aliasing&lt;/code&gt;;&lt;/item&gt;
      &lt;item&gt;the code that Eurydice sees is MIR after applying &lt;code&gt;cfg&lt;/code&gt;tweaks; this means that for code that is intended to be multi-platform, some tricks need to be applied, otherwise, Eurydice will only âseeâ one version of the code (AVX2, or ARM64, or something else)&lt;/item&gt;
      &lt;item&gt;because monorphization is so pervasive, the configuration language needs to express things such as âtypes that reference &lt;code&gt;__m256i&lt;/code&gt;, an AVX2-only type, need to go into a separate file to be compiled with&lt;code&gt;-mavx2&lt;/code&gt;â; this can get tedious real fast but Iâm not sure I know how to do better.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Whatâs next?&lt;/head&gt;
    &lt;p&gt;There is ongoing work to integrate Eurydice-generated code for both Microsoft and Googleâs respective crypto libraries.&lt;/p&gt;
    &lt;p&gt;The community grew recently, with wonderful contributions by GitHub users @ssyram and @lin23299. There are more in the pipeline, and I look forward to seeing the supported subset of Rust grow even more. Next on the horizon is support for &lt;code&gt;dyn&lt;/code&gt; traits via vtables, and relying on Charonâs monomorphization
to get MIR exactly as the Rust compiler would monomorphize it, intead of relying
on a custom procedure in Eurydice.&lt;/p&gt;
    &lt;p&gt;An ambitious goal is for the whole standard library of Rust to be extractable via Eurydice in 2026. This is non-trivial, but I believe this achievement is within reach. Stay tuned.&lt;/p&gt;
    &lt;head rend="h1"&gt;PS: Why the name?&lt;/head&gt;
    &lt;p&gt;People keep asking about the name; because the project shares a large amount of infrastructure with Aeneas and Charon, I had to follow the Greek mythology theme. Specifically, the myth of Eurydice resonated with me: I thought I was saved from the hell of generating C code, and was going to go back to the world of the living, but alas, no.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178442</guid><pubDate>Sun, 07 Dec 2025 01:41:33 +0000</pubDate></item><item><title>Oblast: A better Blasto game for the Commodore 64</title><link>http://oldvcr.blogspot.com/2025/12/oblast-better-blasto-game-for-commodore.html</link><description>&lt;doc fingerprint="b6785d833bb7919f"&gt;
  &lt;main&gt;&lt;p&gt;So, in that article, I mentioned two future Blasto projects. One is to save my pennies for a custom arcade cabinet to put the board in, though I just spent a cool grand plus on tires which used up a lot of those pennies and I've also got Christmas presents to buy. But the second was to write my own take on TI Blasto and soup it up. This project is the second one from my bucket list that I've completed. It took a couple years of work on it off and on, but it's finally done, with faster action and animation, a massive number of procedurally generated screens, and fully configurable gameplay.&lt;/p&gt;I've christened it Oblast, and it's free to play on your real Commodore 64 or emulator. Let's talk about what's the same and what's different. The antediluvian 1978 Blasto ran on Hustle hardware, which was derived from Gremlin's original (and mercilessly copied) Blockade game as designed by Lane Hauck. Programmer Bill Blewitt managed to squeeze Blasto's entire game code, not counting character graphics, into just 2K of ROM. This code had to generate and draw the maze, handle one or two player inputs, handle their projectiles, check for collisions and trigger the audio and "boom" circuits, all while simultaneously setting off explosions that could trigger other explosions and other collisions. In the upright version it also had free game logic. Given its hardware and software size constraints the arcade game's gameplay limitations, which we'll discuss in a moment, were understandable. When Milton Bradley picked up the license (from Gremlin's new owner Sega) as a developer for the new TI 99/4, they kept the gameplay and basic rules in their home computer port almost identical. Instead, the programmers added music tracks, a colour display, and multiple configuration options. You could set not only the game's speed (I always played Full Tilt) ... ... but also how the maze was drawn, including whether trails existed (areas of the map pre-cleared for motion) and how dense the mines were. Likely as a way to emphasize the TMS9918(A)'s colour capabilities, the MB programmers changed the setting of the game to a green earth-bound landscape with blue (?) mines and reworked the spaceships into tanks. The density option probably had an even greater impact on gameplay than the speed setting because a maze with a lot of mines made for a zippier, more explosive game. You could rig some big bangs this way, though these were sadly were let down by the TMS9919/SN76489's relatively weak noise output. The program also vainly tried to play a simple tune during the game but this was inevitably interrupted and forced to start over by any sound effect (i.e., a tank shooting, mines exploding). As with the original, you have infinite lives but finite time. If you trip on an explosion, or the other player shoots you in two-player mode, you lose valuable seconds until you respawn. However, you respawn at your original spawn point as if you were teleported there, a conceivable failure mode for a fanciful spaceship but an extremely unlikely one for a terrestrial tank, which makes a good segue into some of its other idiosyncrasies:&lt;list rend="ul"&gt;&lt;item&gt;Each player can only have a single projectile in motion at any time. However, as soon as that projectile impacts, you can immediately fire another one. This is clearly motivated by the limited memory in the original game, but I don't know of any artillery shell in real life that works like that!&lt;/item&gt;&lt;item&gt;As a related phenomenon, although you can move while an explosion or chain reaction is occurring (with a slight reduction in frame rate), you can't shoot — at least not until the explosions stop, at which point you can once again shoot immediately. This also seems to be a concession to limited available memory as the game can't track multiple chain reactions at once.&lt;/item&gt;&lt;item&gt;Tanks absolutely can't go over mines or obstacles; they act as completely impassible barriers. I guess that might make sense with spaceships, but it seems like a rather wussy sort of tank.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Now, I want to point out that despite those things, I loved TI Blasto and played quite a bit of it. But we can improve on what is already an awful lot of fun.&lt;/p&gt;It took a while to get the fundamentals laid down, and it was immediately obvious that the most important mechanic in the game had to be the chain reaction since everybody likes to blow %@#$ up. Consequently, the code that handles the explosions was the first part of the game I wrote, as I reasoned the game wouldn't be worth completing if I couldn't get it fast or frantic enough. This very early draft was a simple proof of concept using PETSCII graphic characters to model the algorithm; character graphics were a must because doing this on the high-resolution screen would have played like molasses.&lt;p&gt;The game doesn't track explosions anywhere else but the screen itself: everything it needs to determine the next frame of animation is by looking at what's set on the characters present. It scans the entire playfield each time to do this which necessarily locks the animation to a constant frame rate — even if the whole screen were alive with multiple explosions, it would take nearly exactly as much time as if only one single bomb were being detonated, keeping gameplay speed consistent. I did a lot of code unrolling to make this work as quick as possible and the final draft of the original "screen test" is what's in Oblast now.&lt;/p&gt;&lt;p&gt;The black area is because I already knew I'd be using sprites for the tank and I didn't want to mess around with having to manage the high bit for X coordinates greater than 255, so I reserved the right-hand portion of the screen for an information pane. This also had the nice side effect of reducing how much of the screen must be scanned.&lt;/p&gt;For Oblast, I've concentrated exclusively on the single-player mode in which I played Blasto most, which also simultaneously solved some technical issues. (I may make a two-player version in the future if I figure out good solutions to them.) Although I've kept the spirit of TI Blasto's configurability, I made it extend not just to maze generation but even to the game's core rule set. The configuration portion is largely written as a BASIC stub with some 6502 assembly language helpers for speed, with the bulk of the remainder and the entirety of the main game loop also in assembly language.&lt;p&gt;There are four preset games, the parameters for which I selected after tweaking them during repeated playtesting. The first is the one I consider "typical" for most players to start with (and the one you'll see the computer attempt to play during Oblast's attract mode), the second has an increased number of bombs, the third adds trails and more Blasto-like rules for more classic gameplay, and the fourth is a completely gonzo game mode which has become my personal favourite after a rough day at work.&lt;/p&gt;If you don't like those presets, or want to tweak them further, there is a full game configuration screen letting you set game modes and the starting level/screen. The game supports up to 384 procedurally generated screens and you can start on any of them from 0 to 255. The screens are generated from constant seed data (in this case the 64's BASIC ROM) and thus designed to generate the same screen with the same parameters, facilitating muscle memory for longer play if you get good.&lt;p&gt;Like the two versions of Blasto, Oblast has mines (bombs) and obstacles (trees). You can very precisely control the densities of both. You can also have the game generate Blasto-style trails horizontally, vertically or both, you can set how quickly your tank's fuel is exhausted (i.e., your time limit, the only option which cannot be zero), and you can indicate if your tank is invulnerable to explosions and how quickly to cycle your shells. I'll talk about how that works in a moment. If you press one of the preset function keys in the configuration screen, then its settings are loaded as a starting point for you to modify.&lt;/p&gt;For the presets, where a new player wouldn't know exactly the game conditions they trigger, I pondered various in-game ways of informing them and hit on an easy-to-implement "dot matrix printout" motif where the BASIC stub scrolls a "briefing" before starting play, making asynchronous "printer" noises based on the bit pattern of each line's ASCII codes. This same motif is used for the basic built-in help since I had some extra space available.&lt;p&gt;Once you've got the settings the way you want, or you just want to keep playing the same preset, after a game ends you can bypass the presets and game configuration screens and jump right into a new game with the same settings by pressing the fire button.&lt;/p&gt;Here's two examples of the procedural screen generation at work, both level 0. The top screen is what you'd start at if you chose the "Regular Duty" (F1) preset; the second is "More Like Classic Blasto" (F5). Both have the same seed pointer, and you can see some commonalities in bomb and tree positions, but the second screen has a slightly lower bomb density and a slightly higher tree density plus trails going both horizontally and vertically. Each collection of settings will always generate the same screens on your machine. The game code manually counts the number of bombs and trees at the end of map generation since they may be taken away by trails or in the process of ensuring the tank has a cleared starting position.&lt;p&gt;Although we're using a custom character set for speed, I still wanted the colour flexibility of high resolution where you can have different text and background colours. To do so Oblast is something of a love letter to one of the VIC-II's more underutilized display modes, extended background colour mode (ECM). ECM supports up to four background colours on the same screen and the main game uses two additional colours besides the green background, the most obvious being the black background of the information pane, but also a yellow background as part of animating explosions. The price you pay for this flexibility is that only 64 characters of the standard 256-entry character set can be used; the two high bits instead become a bit pair to select the background colour.&lt;/p&gt;That meant making a lot of careful decisions about what I was going to actually display and getting those shapes into the first 64 character glyphs, shown here in Ultrafont+. You'll notice that I've replaced some of the letters and typographic characters with graphic shapes because I knew I would never actually need to display those letters or symbols. Everything you see on the screen except for the tank and the shells is a character in this custom font. On the bright side, this character limit also means we can reduce the memory needed by the game font by 75 percent. By looking for the bit set for the black background of the (impervious) information pane, as well as the wall character that also has this bit set, the game knows not to propagate explosions into that area. The yellow background comes in for knowing what needs to detonate next frame: the routine uses that bit as a deferred marker so that as it sweeps sequentially through the screen it doesn't update the same bomb twice in the same frame and prematurely snuff it out. Since setting that bit will also cause a different background colour to be used, we use yellow to make the explosion visually interesting as another side effect.&lt;p&gt;Parenthetically, the TMS9918 and TMS9918A also have a feature like this which TI Blasto itself appears to use: each 32 character block of its 256-character fonts can have its own colours. Unlike the VIC-II's ECM which must be specially enabled, this is a standard feature of the 32x24 text mode (which TI calls "Graphic I"), but the character shapes remain unchanged in each block which may require making duplicates (whereas with ECM they are always drawn from the first 64 glyphs).&lt;/p&gt;If there are a lot of bombs on screen, as is the case in the fourth preset and my favourite gameplay mode, nearly the entire screen will be consumed with the explosion which animates around you as you shoot other things. This wasn't possible in either of the original Blastos. Also, instead of trying to play music during game play, all three SID voices are used for noise generation (with a low-pass filter and some resonance smeared on for a woofer-like effect). Voice 1 is triggered when you fire your gun and voice 2 is always running as the tank's engine, with its frequency varying with motion and tank rotation. Voice 3 is used specifically for explosions because it's the only SID voice where you can directly sample both the oscillator waveform output and the current amplitude of the audio envelope. We take these samples, scale them to the activity on screen, and feed the result into the VIC-II's screen fine X scroll. Lots of explosions cause lots of shaking, yet the shaking is always in sync with the audio.&lt;p&gt;Besides the character graphics, the other major screen component are the sprites. The tank is a composite of three sprites: an animated set for the tank tread, the main tank body, and an accent layer. This is sharper than using multicolour sprites where your horizontal resolution is halved. These three sprites move together and the build system automatically precalculates frames to rotate them off a template, which are played back on screen when you turn. Unlike both versions of Blasto where the tank is limited to integral character positions, the tank in Oblast is larger than the bombs and trees and can move in single pixels, though I still limited movement to 90 degree angles so I didn't have to do expensive trig computations to figure out a shell's trajectory.&lt;/p&gt;&lt;p&gt;One sprite being used as the fuel gauge needle left four sprites for the shells. I had earlier considered using character graphics for them too, but animating shells that way would be slower and less smooth than moving sprites. On the other hand, then, without resorting to tricks there can only be four shells onscreen at once which also didn't seem very tank-like. After some thought I came up with a game mechanic to explain it. In the information pane in these two shots, you see the level number, the fuel gauge which acts as your timer, and then four blue shell indicators. Three of these indicators are dark blue, indicating they are reloading (the fourth is a bright cyan, indicating ready). We'll simply define the reloading time for any shell chamber as the maximum length of time it takes a shell to get across the screen in any direction. Thus, no matter how much you fire, you can only ever have four on-screen because the reloading time will lock you out. (Blasto-style fire control where shells recycle immediately as they hit something is preserved for that game mode, or if you turn on "fast cycl[ing] shells" from the configuration screen.)&lt;/p&gt;&lt;p&gt;While propagating explosions is approximately constant-time, other operations in the game may not be, and there's no reason to walk the screen if nothing's marked as needing it. That means we need a timebase to keep frame rates stable. For this purpose I used the Kernal jiffy clock, which on both PAL and NTSC systems is triggered by the Timer A interrupt to tick about every 1/60 second. The game loop locks to this and uses it to know when to move game objects and trigger screen updates. Still, even this isn't fast enough for moving very speedy things like the shells you fire and the game felt too slow. So ... we make the Timer A interrupt even faster, flogging it at 240Hz instead of 60Hz (the game has prescaler values for both PAL and NTSC), making jiffies 1/240 of a second instead and moving objects at that rate.&lt;/p&gt;&lt;p&gt;This does have interesting interactions when the VIC-II is still drawing your screen at either 50 or 60Hz even as you update it four times as quickly, and most of these interactions have to do with collisions because you can move objects faster than the VIC-II can detect they intersect. The bombs are as big as they are because that gives lots of opportunities to detect a shell striking one, but tank collisions remained unreliable with smaller graphics like trees. Fortunately, however, we've already declared we didn't like the fact that trees and bombs (i.e., obstacles and mines) were impassible objects, so we can make this deficiency into a virtue. The game keeps running track of where the tank last was and if a collision is detected immediately moves it back to that position. However, because collisions are detected inconsistently at this rate of motion and the game updates the tank's coordinates faster than the VIC will draw them, it ends up manifesting onscreen as the tank simply slowing down when it has to cross an obstacle. I like that better than just coming to a dead halt.&lt;/p&gt;Explosions, however, are nice big targets and we have no problem detecting when the tank gets nailed by one of those. In the game modes where your tank is vulnerable, we throw your tank into a temporary tailspin, start flashing the border and the information pane (which is just a matter of setting its colour register), turn on voice 1 and voice 3 at the same time for an even bigger boom, and take the envelope and waveform from voice 3 and put it into the fine Y scroll register as well as the X to really throw the screen around. My favourite game mode allows you to blow up the entire playfield with impunity, of course. I also decided to overhaul the scoring with special bonuses silently awarded after completing a screen and detailed cumulatively at the end when your score is added up (total bombs exploded plus total bonuses earned). Don't cheat and look at the source code, but the descriptions of the bonuses should give you a clue as to how you win them. Note that some bonuses are mutually exclusive, and some are explicitly disabled ("n/a") in certain game configurations that make them impossible or unavoidable.&lt;p&gt;Should you beat the default high score, you'll see another use of extended background colour mode for the champion medal (you'll just have to beat it fair and square, no spoiler screenshots). This segment uses FLD to scroll the medal into view and then cycles the ECM registers for a masked multiple colour bar effect without having to split the screen horizontally. It's a simple effect that I threw together in an afternoon but I think it looks nice. While the game configuration screen looks like it might use ECM for the top title, it actually doesn't because I needed lowercase letters, so I employ a much simpler trick for that screen which shouldn't take you long to figure out.&lt;/p&gt;&lt;p&gt;A key goal was to get the entire game in memory at once without additional loading or disk access, meaning you can even run it from cassette tape if you want to. In memory everything is arranged around the two character sets, the bank of sprites and the two hi-res title screens which are in fixed locations to deal with the VIC-II's more constrained view of memory (one of the hi-res screens is slotted under the BASIC ROM so I could free up 8K for something else). I then redistributed the various machine language subroutines and the three music tracks around those assets while also ensuring the BASIC menu stub had enough free memory to maintain its variables. After the core game was done I added two more extras on, the attract mode (which required some reworking to fit) and a really silly credits sequence, which implements a double-buffered screen scroller and takes advantage of the fact that the main music track sounds pretty neat slowed down. The entire mess is then single-parted using my custom cross-linker and optionally compressed.&lt;/p&gt;Oblast is freeware and open source on Github. You can build it with Perl 5, the xa65 cross assembler and optionally the pucrunch compressor. The Perl tools to generate the sprites, the tokenized BASIC code and the uncompressed runnable linked version are all included. Say that you want to change the presets to your own preferred settings: just change the corresponding DATA statement in the BASIC code, do a make and instantly have your modified binary. All I ask is that modified binaries that you provide to others should use a different name so they aren't confused with the original, and note that this game and any derivative works based on it or its components are under the Floodgap Free Software License.&lt;p&gt;If you just want to play it, the Github releases tab provides compressed (for actual floppy disks or tape or other media with limited space) and uncompressed (for fast DMA cartridges and emulators) builds as .prg files you can run directly. You'll need a joystick or equivalent in port 2, and the game should run on any PAL or NTSC Commodore 64. This is hardly the last game, let alone project, on my bucketlist, but it's good to knock another one off it. Also, please don't blow up trees in real life.&lt;/p&gt;&lt;p&gt; If you've enjoyed playing, buy me a &lt;del&gt;coffee&lt;/del&gt; Pibb. &lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178464</guid><pubDate>Sun, 07 Dec 2025 01:47:23 +0000</pubDate></item><item><title>Z2 – Lithographically fabricated IC in a garage fab</title><link>https://sam.zeloof.xyz/second-ic/</link><description>&lt;doc fingerprint="6f28c43798a75591"&gt;
  &lt;main&gt;
    &lt;p&gt;Homemade 1000+ transistor array chip&lt;/p&gt;
    &lt;p&gt;In 2018 I made the first lithographically fabricated integrated circuits in my garage fab. I was a senior in high school when I made the Z1 amplifier, and now I’m a senior in college so there are some long overdue improvements to the amateur silicon process.&lt;lb/&gt; The Z1 had 6 transistors and was a great test chip to develop all the processes and equipment. The Z2 has 100 transistors on a 10µm polysilicon gate process – same technology as Intel’s first processor. My chip is a simple 10×10 array of transistors to test, characterize, and tweak the process but this is a huge step closer to more advanced DIY computer chips. The Intel 4004 has 2,200 transistors and I’ve now made 1,200 on the same piece of silicon.&lt;/p&gt;
    &lt;p&gt;Previously, I made chips with a metal gate process. The aluminum gate has a large work function difference with the silicon channel beneath it which results in a high threshold voltage (&amp;gt;10V). I used these metal gate transistors in a few fun projects like a guitar distortion pedal and a ring oscillator LED blinker but both of these required one or two 9V batteries to run the circuit due to high Vth. By switching to a polysilicon gate process, I get a ton of performance benefits (self aligned gate means lower overlap capacitances) including a much lower Vth which makes these chips compatible with 2.5V and 3.3V logic levels. The new FETs have excellent characteristics:&lt;/p&gt;
    &lt;quote&gt;NMOS Electrical Properties: Vth = 1.1 V Vgs MAX = 8 V Cgs = &amp;lt;0.9 pF Rise/fall time = &amp;lt;10 ns On/off ratio = 4.3e6 Leakage current = 932 pA (Vds=2.5V)&lt;/quote&gt;
    &lt;p&gt;I was particularly surprised by the super low leakage current. This value goes up about 100x in ambient room lighting.&lt;/p&gt;
    &lt;p&gt;Now we know that it’s possible to make really good transistors with impure chemicals, no cleanroom, and homemade equipment. Of course, yield and process repeatability are diminished. I’ll do more testing to collect data on the statistics and variability of FET properties but it’s looking good!&lt;/p&gt;
    &lt;p&gt;The chip is small, about one quarter the die area of my previous ICs (2.4mm^2) which makes it hard to probe. There’s a simple 10×10 array of N-channel FETs on each chip which will give me a lot of characterization data. Since it’s such a simple design, I was able to lay it out using Photoshop. Columns of 10 transistors share a common gate connection and each row is strung together in series with adjacent transistors sharing a source/drain terminal. It’s similar to NAND flash but I only did this to keep the metal pads large enough so I can reasonably probe them, if every FET had 3 pads for itself they would be too small.&lt;/p&gt;
    &lt;p&gt;It’s hard to convey the excitement of seeing a good FET curve displayed on the curve tracer after dipping a shard of rock into chemicals all day.&lt;/p&gt;
    &lt;p&gt;A single 10µm NMOS transistor can be see below, with slight misalignment in the metal layer (part of the left contact is uncovered). Red outline is polycrystalline silicon, blue is the source/drain.&lt;/p&gt;
    &lt;p&gt;So far I’ve made an opamp (Z1) and a memory-like array (Z2). More interesting circuits are definitely possible even with this low transistor density. The process needs some tweaking but now that I’m able to consistently make good quality transistors I should be able to design more complex digital and analog circuits. Testing each chip is very tedious so I am trying to automate the process and I’ll post more data then. I’ve made 15 chips (1,500 transistors) and know there’s at least one completely functional chip and at least two “mostly functional”, meaning ~80% of the transistors work instead of 100%. No proper yield data yet. The most common defect is a drain or source shorted to the bulk silicon channel, not a leaky or shorted gate like on my Z1 process.&lt;/p&gt;
    &lt;p&gt;I said before that the gate used to be made out of aluminum and now it’s silicon which makes the chips work a lot better. Silicon comes in three varieties that we care about: amorphous, polycrystalline, and monocrystalline. From left to right, these become more electrically conductive but also much harder to deposit. In fact, monocrystalline Si can’t be deposited, you can only grow it in contact with another mono-Si layer as a seed (epitaxy). Since the gate must be deposited on top of an insulating dielectric, poly is the best we can do. We can heavily dope the polysilicon anyway to make it more conductive.&lt;/p&gt;
    &lt;p&gt;A typical self-aligned polysilicon gate process requires silane, a toxic and explosive gas, to deposit polycrystalline silicon layers. It may also be possible by sputtering or evaporating amorphous silicon and annealing with a laser. A major theme of this DIY silicon process is to circumvent expensive, difficult, or dangerous steps. So, I came up with a modified process flow. It’s a variation on the standard self-aligned methods to allow doping via high temperature diffusion rather than ion implantation. The effect is that I’m able to buy a silicon wafer with the polysilicon already deposited on it from the factory and pattern it to make transistors instead of putting my own polysilicon down halfway through the process. This is a nice short term workaround but it would be best to design a polysilicon deposition process using the laser anneal method mentioned above.&lt;/p&gt;
    &lt;p&gt;Wafers are available with all kinds of materials deposited on them already, so I just had to find one with a thin layer of SiO2 (gate oxide, ~10nm) followed by a thicker polysilicon (300nm). I found a lot of 25 200mm (EPI, prime, [1-0-0], p-type) wafers on eBay for $45 which is essentially a lifetime supply, so email me if you want one. The gate oxide is the most fragile layer and requires the most care during fabrication. Since I bought the wafer with a nice high quality oxide on it already that was capped off and kept clean by the thick polysilicon layer, I was able to eliminate all the aggressive cleaning chemicals (sulfuric acid, etc) from the process and still make great transistors. Minimal process chemicals and tools are listed below.&lt;/p&gt;
    &lt;quote&gt;Chemicals used in home poly-gate process: -Water -Alcohol -Acetone -Phosphoric acid -Photoresist -Developer (2% KOH) -N type dopant (filmtronics P509) -HF (1%) or CF4/CHF3 RIE -HNO3 for poly etch or SF6 RIE&lt;/quote&gt;
    &lt;quote&gt;Equipment used in home poly-gate process: -Hotplate -Tube furnace -Lithography apparatus -Microscope -Vacuum chamber to deposit metal&lt;/quote&gt;
    &lt;p&gt;Z2 “gate first” process (similar to standard self-aligned process but without a field oxide):&lt;/p&gt;
    &lt;p&gt;I snapped one of the test chips in half (functional Z2 but with bad layer alignment and thin metal, about 300nm) and put it in my SEM for a cross section:&lt;/p&gt;
    &lt;p&gt;Find the dust particle in the red circle below, use that to get oriented in the coming cross section views.&lt;/p&gt;
    &lt;p&gt;Because I bought the wafer already with gate oxide and polysilicon on it, I can’t grow a field oxide. These thick oxide layers are typically used to mask dopants and require a long high temperature step which would oxidize all of my poly and there would be none remaining. So, my modified process uses an additional masking step (the “gate” mask is typically not found in a self-aligned process) that allows me to use the polysilicon itself as a dopant mask and hard-baked photoresist as the field dielectric. This alternative processing results in the stepped structure you can see in the orange region on the NMOS cross section above. This process subtlety is mentioned here, read this twitter thread.&lt;/p&gt;
    &lt;p&gt;This process isn’t ideal and I want to make some changes so it’s CMOS compatible but it simplifies fabrication and makes it possible with a minimal set of tools. The 1µm dielectric layer (orange) would ideally be CVD SiO2 (it’s possible to build a TEOS oxide reactor at home) but I used a photoresist instead. Most photoresists can be baked around 250°C to form a hard permanent dielectric layer that is an easy alternative to CVD or PECVD oxide. A spin-on-glass/sol-gel could also be used here. SiO2 etching is done with a buffered HF solution made from rust stain remover or RIE.&lt;/p&gt;
    &lt;p&gt;Huge composite stitched die image:&lt;/p&gt;
    &lt;p&gt;Thanks for following my work and feel free to contact me with your thoughts!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46178789</guid><pubDate>Sun, 07 Dec 2025 03:03:09 +0000</pubDate></item></channel></rss>