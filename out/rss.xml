<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 24 Sep 2025 18:43:03 +0000</lastBuildDate><item><title>My Ed(1) Toolbox</title><link>https://aartaka.me/my-ed.html</link><description>&lt;doc fingerprint="f768818853b18a8d"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;My ed(1) Toolbox&lt;/head&gt;By Artyom Bologov&lt;p&gt;Apparently, I’m a huge ed(1) fan. I keep posting about it and use it as e.g. my Git editor, sudo editing tool, and my static site generator. But am I using it raw and standard as it is? Sometimes yes, but mostly no. This post is a listing of all the ed implementations and scripts I use.&lt;/p&gt;&lt;head rend="h2"&gt;GNU ed + red—Eternal Classics #&lt;/head&gt;&lt;p&gt;ed(1) is the standard text editor. And it’s available on most UNIX/POSIX-derived systems. (Some Linux distributions don’t provide it in default installation anymore, but that’s on them!) So relying on ed(1) and its powers is a good bet.&lt;/p&gt;&lt;p&gt;That’s why I always have GNU ed installed on my systems. It’s battle-tested, intuitive, and easily scriptable.&lt;/p&gt;&lt;p&gt;Bundled with GNU ed (and any POSIX-compliand ed(1) really), red(1) is the “restricted” version of ed(1). It’s locked to the directory it’s called in. And has no ability to pass through to the shell. I find it relatively useless though: I use ed(1) on secure systems and never allow anyone to access my precious ed(1) session. But still, red(1) is nice to have!&lt;/p&gt;&lt;head rend="h2"&gt;oed—OpenBSD ed #&lt;/head&gt;&lt;p&gt;Now, GNU ed is not conforming to POSIX in some behaviors:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;It has more CLI flags&lt;/item&gt;&lt;item&gt; It has &lt;code&gt;wq&lt;/code&gt;&lt;/item&gt;&lt;item&gt;It has POSIX extended regular expressions (EREs,) while most other implementations don’t. Thus making EREs a non-portable extension&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I risk introducing non-portable behavior if I only focus on GNU ed. And I want to have my scripts (including my website build scripts) portable across implementations.&lt;/p&gt;&lt;p&gt; So I installed OpenBSD ed from the repository kindly provided by one of the maintainers. And now I can safely replace &lt;code&gt;ed&lt;/code&gt; with &lt;code&gt;oed&lt;/code&gt; for most of my scripts.
As the least effort shot at portability.
It’s too convenient to not use it now.

&lt;/p&gt;&lt;head rend="h2"&gt;wed—ed wImproved #&lt;/head&gt;&lt;p&gt; I asked it on GNU ed mailing list whether they might support scripting abilities. Like sed(1) &lt;code&gt;-e&lt;/code&gt; and &lt;code&gt;-f&lt;/code&gt; flags or as a special executable for it.
One of the maintainers (predictably) replied that they (mostly) abide by POSIX and won’t add it.

&lt;/p&gt;&lt;p&gt;But! there was a person that emailed me personally and recommended slewsys ed as a version of ed(1) supporting scripts (among many other things.) So I installed it and called it wed(1) just to distinguish this re-implementation from The ed(1).&lt;/p&gt;&lt;p&gt;I don’t really use wed(1)—I’m fine with standard ed(1) (and my scripting wrapper for it). Bust still, it’s a modern and user-friendly extension. Want to get started with ed(1) but don’t want to deviate from the tradition?—this is the one to start with, probably.&lt;/p&gt;&lt;p&gt;Don’t get wed to an anime hologram. Get wed(1).&lt;/p&gt;&lt;head rend="h2"&gt;aed—Blaphemy Against Minimalism #&lt;/head&gt;&lt;p&gt;I understand the complaints about ed(1) being somewhat hostile to new users. It’s usually mitigated by the time spend with this magnificent software. But still, ed(1) is not perfect and might need some modernization.&lt;/p&gt;&lt;p&gt;So I made aed(1) as a better and more interactive ed(1). It’s mostly abusing Readline and shell scripts to deliver a friendlier experience. With syntax highlighting and perfectly inline-editable inputs.&lt;/p&gt;&lt;p&gt;So once you’re comfortable with basic ed(1). (Or it’s slightly friendlier wed(1) version.) You might want to speed up your workflows with aed(1)!&lt;/p&gt;&lt;p&gt;I might’ve gone too far though.&lt;/p&gt;&lt;head rend="h2"&gt;xed—You Don’t Need sed #&lt;/head&gt;&lt;p&gt;I have a user-friendly ed(1) on me now for interactive use. One use-case for ed(1) is not covered yet though—scripting! Having to do this type of newline-delimited scripts is too verbose compared to sed(1) ones.&lt;/p&gt;&lt;p&gt;What if I told you this is doable with a one-liner using my xed(1) script? Here:&lt;/p&gt;&lt;p&gt;It’s not the prettiest one, but it’s fulfilling many sed(1) use-cases. Speaking of the devil...&lt;/p&gt;&lt;head rend="h2"&gt;sed and ex... No. #&lt;/head&gt;&lt;p&gt;You don’t need ex(1) either, because it’s too vi(1)-oriented. They promised ed(1) eXtended, but we got ed(1) Fucked Up. Commands are incompatible with ed(1). Configuration is useless in ex(1) mode. Overall, ex(1) is just a poorly integrated back-end for vi(1).&lt;/p&gt;&lt;head rend="h2"&gt;My own ed(1) implementations #&lt;/head&gt;&lt;p&gt;If one likes some piece of software as an idea, they will inevitably try to reproduce it. So I did. I implemented ed(1) in Brainfuck under the aegis of Brainfuck Enterprise Solutions. I also did one in BASIC, pushing the limits of the no-memory BASIC as far as possible. And, finally, I did ed(1) in Modal, a term-rewriting-only system. All of these are useable... to a certain extent. But they don’t compare to the magnificence and purity of the Standard Text Editor.&lt;/p&gt;&lt;head rend="h2"&gt;Use ed(1) #&lt;/head&gt;&lt;p&gt;Whatever implementation you pick (pick aed(1)!), use it and love it. Because ed(1) deserves your love 😌&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45359388</guid><pubDate>Wed, 24 Sep 2025 12:31:52 +0000</pubDate></item><item><title>Learning Persian with Anki, ChatGPT and YouTube</title><link>https://cjauvin.github.io/posts/learning-persian/</link><description>&lt;doc fingerprint="9290b055cdb636d2"&gt;
  &lt;main&gt;
    &lt;p&gt;I’ve been learning Persian (Farsi) for a while now, and I’m using a bunch of tools for it. The central one is certainly Anki, a spaced repetition app to train memory. I’m creating my own never-ending deck of cards, with different types of content, for different purposes. The most frequent type of cards is grammar focused phrases (very rarely single words) coming sometimes from my own daily life, but also very often directly from videos of the Persian Learning YouTube channel, created by Majid, a very talented and nice Persian teacher, in my opinion.&lt;/p&gt;
    &lt;p&gt;Let’s take an example, suppose there is this slide in one of Majid’s videos:&lt;/p&gt;
    &lt;p&gt;From this, I will extract three screenshots (with the MacOS screenshot tool). First, to create a card of type “basic” (one side). I use this type of card to exercise my reading, which is very difficult and remains stubbornly slow, even though I know the 32 letters of the Persian alphabet quite well by now. But the different ways of writing them (which varies by their position in the word) and the fact that the vowels are not present makes it an enduringly challenging task.&lt;/p&gt;
    &lt;p&gt;The next type of card I create with the two remaining screenshots is “basic and reversed”, which actually creates two cards (one for each direction), one with some romanized phrase, and the other with the English or French translation:&lt;/p&gt;
    &lt;p&gt;When I review these cards in my daily Anki routine, this is where ChatGPT enters into play. First I have set a “Persian” project with these instructions:&lt;/p&gt;
    &lt;p&gt;With this project, every time I have a doubt or don’t remember something in Anki, I just take a screenshot and paste it in the project:&lt;/p&gt;
    &lt;p&gt;With this, I have an instant refresher on any notion, in any context. Sometimes I need to do this over and over, before it gels into a deeper, more instant and visceral “knowledge”.&lt;/p&gt;
    &lt;p&gt;The next set of techniques is also based on YouTube. I use a Chrome extension called Dual Subtitles (which only works of course with videos having actual dual sources of subtitles):&lt;/p&gt;
    &lt;p&gt;The dual subtitles serve a couple of purposes: first as a source of new Anki cards (I create the cards directly, again with screenshots in the clipboard).&lt;/p&gt;
    &lt;p&gt;I also use the Tweaks for YouTube extension, which allows me to get extra keyboard shortcuts, to go back and forward only 1 second, instead of the built-in 5 seconds.&lt;/p&gt;
    &lt;p&gt;With these YouTube extensions, I have developed this particular “technique” to improve my vocal understanding:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I listen at 75% speed&lt;/item&gt;
      &lt;item&gt;I use the “dual subtitles” browser extension to have both the Farsi and English subtitles at the same time (I set the Farsi one slightly bigger)&lt;/item&gt;
      &lt;item&gt;Every time a new sentence appears, I read it very quickly first in English (I pause if I need to), and then I listen carefully to the voice, to let the meaning and sound of Farsi infuse my mind (this part is very subtle but the most important: you must “feel” that you understand, and this feeling must cover even the words that you don’t know; because the meaning of the sentence is currently present and active in your mind, because you just read the English part, I believe that its mapping with the Farsi words that you then hear is particularly efficient, at least that’s my theory)&lt;/item&gt;
      &lt;item&gt;I also read the Farsi script, to improve my understanding, and disambiguate certain words for which it’s hard for me to hear what is exactly said&lt;/item&gt;
      &lt;item&gt;I repeat out loud what has been said also, which is quite important&lt;/item&gt;
      &lt;item&gt;Most importantly: I repeat this process (for a single video) over and over, in order to reach a stage where I genuinely understand what is said, in real-time, which is a very powerful and exhilarating feeling.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45359524</guid><pubDate>Wed, 24 Sep 2025 12:45:07 +0000</pubDate></item><item><title>How to Lead in a Room Full of Experts</title><link>https://idiallo.com/blog/how-to-lead-in-a-room-full-of-experts</link><description>&lt;doc fingerprint="f3751d93156404b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Here is a realization I made recently. I'm sitting in a room full of smart people. On one side are developers who understand the ins and outs of our microservice architecture. On the other are the front-end developers who can debug React in their sleep. In front of me is the product team that has memorized every possible user path that exists on our website. And then, there is me. The lead developer. I don't have the deepest expertise on any single technology.&lt;/p&gt;
    &lt;p&gt;So what exactly is my role when I'm surrounded by experts? Well, that's easy. I have all the answers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical Leadership&lt;/head&gt;
    &lt;p&gt;OK. Technically, I don't have all the answers. But I know exactly where to find them and connect the pieces together.&lt;/p&gt;
    &lt;p&gt;When the backend team explains why a new authentication service would take three weeks to build, I'm not thinking about the OAuth flows or JWT token validation. Instead, I think about how I can communicate it to the product team who expects it done "sometime this week." When the product team requests a "simple" feature, I'm thinking about the 3 teams that need to be involved to update the necessary microservices.&lt;/p&gt;
    &lt;p&gt;Leadership in technical environments isn't about being the smartest person in the room. It's about being the most effective translator.&lt;/p&gt;
    &lt;head rend="h3"&gt;Leading is a Social Skill&lt;/head&gt;
    &lt;p&gt;I often get "eye rolls" when I say this to developers: You are not going to convince anyone with facts. In a room full of experts, your technical credibility gets you a seat at the table, but your social skills determine whether anything productive happens once you're there.&lt;/p&gt;
    &lt;p&gt;Where ideally you will provide documentation that everyone can read and understand, in reality, you need to talk to get people to understand. People can get animated when it comes to the tools they use. When the database team and the API team are talking past each other about response times, your role isn't to lay down the facts. Instead it's to read the room and find a way to address technical constraints and unclear requirements. It means knowing when to let a heated technical debate continue because it's productive, and when to intervene because it's become personal.&lt;/p&gt;
    &lt;head rend="h3"&gt;Leading is Remembering the Goal&lt;/head&gt;
    &lt;p&gt;When you are an expert in your field, you love to dive deep. It's what makes you experts. But someone needs to keep one eye on the forest while everyone else is examining the trees.&lt;/p&gt;
    &lt;p&gt;I've sat through countless meetings where engineers debated the merits of different caching strategies while the real issue was that we hadn't clearly defined what "fast enough" meant for the user experience. The technical discussion was fascinating, but it wasn't moving us toward shipping.&lt;/p&gt;
    &lt;p&gt;As a leader, your job isn't to have sophisticated technical opinions. It's to ask how this "discussion" can move us closer to solving our actual problem.&lt;/p&gt;
    &lt;p&gt;When you understand a problem, and you have a room full of experts, the solution often emerges from the discussion. But someone needs to clearly articulate what problem we're actually trying to solve.&lt;/p&gt;
    &lt;p&gt;When a product team says customers are reporting the app is too slow, that's not a clear problem. It's a symptom. It might be that users are not noticing when the shopping cart is loaded, or that maybe we have an event that is not being triggered at the right time. Or maybe the app feels sluggish during peak hours. Each of those problems has different solutions, different priorities, and different trade-offs. Each expert might be looking at the problem with their own lense, and may miss the real underlying problem.&lt;/p&gt;
    &lt;p&gt;Your role as a leader is to make sure the problem is translated in a way the team can clearly understand the problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Leading is Saying "I Don't Know"&lt;/head&gt;
    &lt;p&gt;By definition, leading is knowing the way forward. But in reality, in a room full of experts, pretending to know everything makes you look like an idiot.&lt;/p&gt;
    &lt;p&gt;Instead, "I don't know, but let's figure it out" becomes a superpower. It gives your experts permission to share uncertainty. It models intellectual humility. And it keeps the focus on moving forward rather than defending ego. It's also an opportunity to let your experts shine.&lt;/p&gt;
    &lt;p&gt;Nothing is more annoying than a lead who needs to be the smartest person in every conversation. Your database expert spent years learning how to optimize queries - let them be the hero when performance issues arise. Your security specialist knows threat models better than you, give them the floor when discussing architecture decisions.&lt;/p&gt;
    &lt;p&gt;Make room for some productive discussion. When two experts disagree about implementation approaches, your job isn't to pick the "right" answer. It's to help frame the decision in terms of trade-offs, timeline, and user impact.&lt;/p&gt;
    &lt;p&gt;Your value isn't in having all the expertise. It's in recognizing which expertise is needed when, and creating space for the right people to contribute their best work.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Translation Challenge&lt;/head&gt;
    &lt;p&gt;There was this fun blog post I read recently about how non-developers read tutorials written by developers. What sounds natural to you, can be complete gibberish to someone else. As a lead, you constantly need to think about your audience. You need to learn multiple languages to communicate the same thing:&lt;/p&gt;
    &lt;p&gt;Developer language: "The authentication service has a dependency on the user service, and if we don't implement proper circuit breakers, we'll have cascading failures during high load."&lt;/p&gt;
    &lt;p&gt;Product language: "If our login system goes down, it could take the entire app with it. We need to build in some safeguards, which will add about a week to the timeline but prevent potential outages."&lt;/p&gt;
    &lt;p&gt;Executive language: "We're prioritizing system reliability over feature velocity for this sprint. This reduces risk of user-facing downtime that could impact revenue."&lt;/p&gt;
    &lt;p&gt;All three statements describe the same technical decision, but each is crafted for its audience. Your experts shouldn't have to learn product speak, and your product team shouldn't need to understand circuit breaker patterns. But someone needs to bridge that gap.&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond "Because, that's why!"&lt;/head&gt;
    &lt;p&gt;"I'm the lead, and we are going to do it this way." That's probably the worst way to make a decision. That might work in the short term, but it erodes trust and kills the collaborative culture that makes expert teams thrive.&lt;/p&gt;
    &lt;p&gt;Instead, treat your teams like adults and communicate the reason behind your decision:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"We're choosing the more conservative approach because the cost of being wrong is high, and we can iterate later."&lt;/item&gt;
      &lt;item&gt;"I know this feels like extra work, but it aligns with our architectural goals and will save us time on the next three features."&lt;/item&gt;
      &lt;item&gt;"This isn't the most elegant solution, but it's the one we can ship confidently within our timeline."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The more comfortable you become with not being the expert, the more effective you become as a leader.&lt;/p&gt;
    &lt;p&gt;When you stop trying to out-expert the experts, you can focus on what expert teams actually need:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Clear problem definitions&lt;/item&gt;
      &lt;item&gt;Context for decision-making&lt;/item&gt;
      &lt;item&gt;Translation between different perspectives&lt;/item&gt;
      &lt;item&gt;Protection from unnecessary complexity&lt;/item&gt;
      &lt;item&gt;Space to do their best work&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Your role isn't to have all the answers. It's to make sure the right questions get asked, the right people get heard, and the right decisions get made for the right reasons.&lt;/p&gt;
    &lt;p&gt;Technical leadership in expert environments is less about command and control, and more about connection and context. You're not the conductor trying to play every instrument. You're the one helping the orchestra understand what song they're playing together.&lt;/p&gt;
    &lt;p&gt;That's a much more interesting challenge than trying to be the smartest person in the room.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45359604</guid><pubDate>Wed, 24 Sep 2025 12:52:52 +0000</pubDate></item><item><title>Just let me select text</title><link>https://aartaka.me/select-text.html</link><description>&lt;doc fingerprint="cb024a5731ccf78e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Just Let Me Select Text&lt;/head&gt;By Artyom Bologov&lt;head rend="h2"&gt;Untranslatable Bios #&lt;/head&gt;&lt;p&gt;I’m lonely. Like everyone-ish else. Naturally, I’m on Bumble. (Because Tinder is a rape-friendly lure trap.) When work calls get boring I inevitably start swiping (mostly left 😢)&lt;/p&gt;&lt;p&gt;There are lots of tourists in Armenia in the summer. From all over the world really. Speaking a stupefying range of languages. With bios and prompt answers in these numerous languages. Not necessarily discernible to me due to my language learning stagnation.&lt;/p&gt;&lt;p&gt;So there’s this profile of a pretty German girl. With bio and prompts in (an undeniably beautiful) German. Speaking English, she made the decision to use her mother tongue for the bio. A totally valid choice.&lt;/p&gt;&lt;p&gt;So I want to know the story she tells with her profile:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Select her bio,&lt;/item&gt;&lt;item&gt;copy it,&lt;/item&gt;&lt;item&gt;paste into a translator,&lt;/item&gt;&lt;item&gt;look up the exact meaning of some mistranslated German word,&lt;/item&gt;&lt;item&gt;and realize the unexpected poetic meaning she put into these 300 chars.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Except… I can’t do that. The text is not selectable/copyable in Bumble app. I have to do a bunch of relatively unsurmountable steps to do what should’ve taken half a minute. Like screenshot the profile and scrape the text with iOS Photos text recognition. Or use some OCR (web)app elsewhere. It’s… discouraging. Thus I give up and swipe left. A shame—she was beautiful at the very least!&lt;/p&gt;&lt;head rend="h2"&gt;Media #&lt;/head&gt;&lt;p&gt;By making the text in your UI non-selectable, you turn it into… an image essentially? Images, audio, video, and interactive JS-heavy pages are multidimentional media. Not really manipulable and referenceable in any reasonable way. (Not even with Media Fragments—they were turned down by everyone.) You lose a whole dimension (🥁) of functionality and benefit by going with such media or their semblance text.&lt;/p&gt;&lt;p&gt; Podcasts are not easy to roll back to useful part. Video transcripts don’t make sense without the visuals. Web graphics are opaque &lt;code&gt;&amp;lt;canvas&amp;gt;&lt;/code&gt;-es you can’t gut.

&lt;/p&gt;&lt;p&gt;Text is copyable. Text is translatable. Text is accessible (as in a11y.) Text is lightweight. Text is fundamental to how we people process information.&lt;/p&gt;&lt;p&gt;That’s why we still use text in our UIs. We want to convey the meaning. We strive to provide unambiguous instructions. We need to be understood. So why make the text harder to process and understand?&lt;/p&gt;&lt;head rend="h2"&gt;Stop It #&lt;/head&gt;&lt;p&gt;Whenever you disable text selection/copying on your UI, you commit a crime against the user. Crime against comprehension. Crime against accessibility. Crime against the meaning. Stop incapacitating your users, allow them to finally use the text.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45360475</guid><pubDate>Wed, 24 Sep 2025 13:56:37 +0000</pubDate></item><item><title>Smartphone Cameras Go Hyperspectral</title><link>https://spectrum.ieee.org/hyperspectral-imaging</link><description>&lt;doc fingerprint="77951f9c0a9da747"&gt;
  &lt;main&gt;
    &lt;p&gt;The human eye is mostly sensitive to only three bands of the electromagnetic spectrum—red, green, and blue (RGB)—in the visible range. In contrast, off-the-shelf smartphone camera sensors are potentially hyperspectral in nature, meaning that each pixel is sensitive to far more spectral bands. Now scientists have found a simple way for any conventional smartphone camera to serve as a hyperspectral sensor—by placing a card with a chart on it within its view. The new patent-pending technique may find applications in defense, security, medicine, forensics, agriculture, environmental monitoring, industrial quality control, and food and beverage quality analysis, the researchers add.&lt;/p&gt;
    &lt;p&gt;“At the heart of this work is a simple but powerful idea—a photo is never just an image,” says Semin Kwon, a postdoctoral research associate of biomedical engineering Purdue University in West Lafayette, Ind. “Every photo carries hidden spectral information waiting to be uncovered. By extracting it, we can turn everyday photography into science.”&lt;/p&gt;
    &lt;p&gt;Using a smartphone camera and a spectral color chart, researchers can image the transmission spectrum of high-end whiskey, thus determining its authenticity. Semin Kwon/Purdue University&lt;/p&gt;
    &lt;p&gt;Every molecule has a unique spectral signature—the degree to which it absorbs or reflects each wavelength of light. The extreme sensitivity to distinguishing color seen in scientific-grade hyperspectral sensors can help them identify chemicals based on their spectral signatures, for applications in a wide range of industries, such as medical diagnostics, distinguishing authentic versus counterfeit whiskey, monitoring air quality, and nondestructive analysis of pigments in artwork, says Young Kim, a professor of biomedical engineering at Purdue.&lt;/p&gt;
    &lt;p&gt;Previous research has pursued a number of different ways to recover spectral details from conventional smartphone RGB camera data. However, machine learning models developed for this purpose typically rely heavily on the task-specific data on which they are trained. This limits their generalizability and makes them susceptible to errors resulting from variations in lighting, image file formats, and more. Another possible avenue involved special hardware attachments, but these can prove expensive and bulky.&lt;/p&gt;
    &lt;p&gt;In the new study, the scientists designed a special color reference chart that can be printed on a card. They also developed an algorithm that can analyze smartphone pictures taken with this card and account for factors such as lighting conditions. This strategy can extract hyperspectral data from raw images with a sensitivity of 1.6 nanometers of difference in wavelength of visible light, comparable to scientific-grade spectrometers.&lt;/p&gt;
    &lt;p&gt;“In short, this technique could turn an ordinary smartphone into a pocket spectrometer,” Kim says.&lt;/p&gt;
    &lt;p&gt;The scientists are currently pursuing applications for their new technique in digital and mobile-health applications in both domestic and resource-limited settings. “We are truly excited that this opens the door to making spectroscopy both affordable and accessible,” Kwon says.&lt;/p&gt;
    &lt;p&gt;The scientists recently detailed their findings in the journal IEEE Transactions on Image Processing.&lt;/p&gt;
    &lt;p&gt;Charles Q. Choi is a science reporter who contributes regularly to IEEE Spectrum. He has written for Scientific American, The New York Times, Wired, and Science, among others.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45360824</guid><pubDate>Wed, 24 Sep 2025 14:20:33 +0000</pubDate></item><item><title>How HubSpot Scaled AI Adoption</title><link>https://product.hubspot.com/blog/context-is-key-how-hubspot-scaled-ai-adoption</link><description>&lt;doc fingerprint="a5420315f9e5e959"&gt;
  &lt;main&gt;
    &lt;p&gt;This post is intended to be the first in a series about empowering product, UX, and engineering teams with AI. We’re going to focus on how we’ve approached and scaled the use of AI in the context of writing code.&lt;/p&gt;
    &lt;p&gt;AI has fundamentally transformed how we build software at HubSpot. Over the past two years, we've gone from cautious experimentation to achieving near universal adoption of AI coding tools across our engineering organization.&lt;/p&gt;
    &lt;p&gt;This transformation didn't happen overnight. It required strategic investment, organizational commitment, and a willingness to learn. As we've shared our experience with other engineering leaders, we've discovered that many teams are facing similar challenges in scaling AI adoption beyond POCs and early adopters. The conversations we've had with external teams convinced us that our lessons learned could help others navigate this journey more effectively.&lt;/p&gt;
    &lt;p&gt;Adoption of AI coding assistants, % of members in the Engineering organization [sanitized data]&lt;/p&gt;
    &lt;head rend="h1"&gt;In the beginning there was code completion&lt;/head&gt;
    &lt;p&gt;We began experimenting with GitHub Copilot in the Summer of 2023. Our founders Dharmesh and Brian provided us with the push we needed to get started. Dharmesh had recently used GitHub Copilot to build ChatSpot and had a good experience with it, so he and Brian pushed us to evaluate it and connected us with other leaders in the industry who were seeing success.&lt;/p&gt;
    &lt;p&gt;Our proof of concept (POC) successfully validated the tool's potential, and several factors contributed to our success:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Executive buy-in made everything else easier. Support from Dharmesh and Brian accelerated our pilot process significantly. This helped our legal, security, and engineering team have the same goal and urgency for making this happen.&lt;/item&gt;
      &lt;item&gt;We ran a pilot that was sufficiently large: Our strategy was to include entire teams so they could adopt and learn together that had different experience levels, different missions, and worked in different domains. We gave teams over two months to try it..&lt;/item&gt;
      &lt;item&gt;We put energy into enablement. We had setup/training sessions and created a channel where people could ask questions and share what is and is not working.&lt;/item&gt;
      &lt;item&gt;We measured everything. We applied our existing engineering velocity measurement methods to the pilot. This helped us check our biases. We were skeptical at the outset but seeing measured impact chipped away at our skepticism.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The initial results were encouraging: positive qualitative feedback and measurable but modest productivity improvements, across engineers of different tenure and seniority. Our initial gains fell short of some extraordinary claims we were hearing in the market, but they were still significant given Copilot's cost structure of $19/mo/business user at the time. Even modest time savings justified the investment.&lt;/p&gt;
    &lt;p&gt;With a group of committed stakeholders seeing the early value and the potential with the tool, we were willing to be patient and continue our investment. We believed the technology would only improve over time, so we rolled it out with guardrails. As we scaled adoption and people gained more experience with it, we saw increasingly meaningful productivity gains.&lt;/p&gt;
    &lt;head rend="h1"&gt;Leveraging the Power of Central Teams&lt;/head&gt;
    &lt;p&gt;At HubSpot, we've long believed in the leverage that central teams create. Our platform teams build infrastructure, tools, and guardrails that enable small autonomous product teams to move fast while maintaining quality and consistency.&lt;/p&gt;
    &lt;p&gt;When generative AI emerged, we initially relied on teams adjacent to these areas (specifically teams that managed our GitHub setup) to drive adoption. But as demand exploded, the backlog grew exponentially. We realized it was time to create a dedicated team.&lt;/p&gt;
    &lt;p&gt;We created a Developer Experience AI team in October 2024, with an initial focus on:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Driving adoption of coding tools: Once we realized the impact these tools were having, we wanted the entire org on board as soon as possible&lt;/item&gt;
      &lt;item&gt;Increasing the impact of AI tools: HubSpot has a very opinionated stack and we wanted our generated code to reflect these opinions as much as possible. This started very simply with the sharing of Cursor rules files, but quickly evolved to more complex tools that gave agents deep context about our architecture, libraries, and best practices. (More to come on this in the future)&lt;/item&gt;
      &lt;item&gt;Advocacy: We wanted to build a community around AI, by collecting and disseminating what was working for people. We created an open forum for people to post about AI and seeded content to drive engagement. We saw a vibrant community slowly spring up as adoption grew.&lt;/item&gt;
      &lt;item&gt;Adapting procurement for speed: We knew we wanted to try every tool that came out, but our purchasing processes were designed for longer term negotiated agreements and we couldn't always count on a push from our founders to get things moving. We wanted month-to-month contracts and to get started ASAP.&lt;/item&gt;
      &lt;item&gt;Building evaluation capabilities: We didn't want to rely solely on qualitative feedback, so we came up with ways to run pilots and compare tools on merit. We also experienced first-hand how empirical data could combat preconceptions and skepticism.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Central infrastructure teams create leverage for product teams in every facet of their daily work. AI is no different. We started very small with just two people who had infrastructure experience and were already highly engaged with AI. The team grew over time as we branched out into more advanced use cases, many of which we'll cover in this series. But creating the team and focusing these engineers paved the way for our future success without a massive investment to get started.&lt;/p&gt;
    &lt;head rend="h1"&gt;Tipping the Scale&lt;/head&gt;
    &lt;p&gt;As engineers adopted the tools and we collected more data, our conviction grew that these tools would have had a positive impact on our engineering team. Initially, we maintained conservative usage rules due to limited experience and cost concerns. Users had to request a license and agree to follow strict guardrails.&lt;/p&gt;
    &lt;p&gt;We pulled metrics on code review burden, cycle time, velocity comparisons before and after adoption, and production incident rates.&lt;/p&gt;
    &lt;p&gt;Impact of AI adoption on incidents, team level data [sanitized]&lt;/p&gt;
    &lt;p&gt;The data consistently showed the same thing: AI adoption wasn't creating the problems we were initially worried about. The scatter plot above shows one example, showing that there was no correlation between AI adoption and production incidents.&lt;/p&gt;
    &lt;p&gt;In May 2024, we ditched the restrictions. Then we proactively gave everyone a seat, making it as easy as possible to get started. Adoption shot above 50% overnight.&lt;/p&gt;
    &lt;head rend="h1"&gt;Reaching the Late Majority&lt;/head&gt;
    &lt;p&gt;Adoption slowed again as it increased beyond 60%. The latter stages of adoption are where you face skeptics, start to better understand the limitations of the current tools, and see higher levels of change/risk aversion, so we had to change our approach:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Peer validation: Whenever we heard someone did something interesting with AI, we asked them to record a video and share it. We also began recording weekly videos ourselves showing new features and real usage.&lt;/item&gt;
      &lt;item&gt;Quantitative proof: We shared high-level data showing that most people were already using these tools successfully and safely. We deliberately kept the numbers broad rather than getting into precise details. While data was important for making decisions, we wanted people to focus on the clear trend of improvement rather than getting stuck debating exact figures.&lt;/item&gt;
      &lt;item&gt;Provide better tools: We ran POCs for multiple coding assistants to give engineers more options, recognizing that different tools work better for different workflows and preferences.&lt;/item&gt;
      &lt;item&gt;Curated experience: We transparently set up a local MCP server on every machine with default rules and configuration optimized for our development environment. This gave every engineer an experience tailored to our specific stack and best practices right out of the box. We continue to revise and improve this setup over time based on what we learn about effective usage patterns.&lt;/item&gt;
      &lt;item&gt;AI fluency a baseline expectation: Once we hit 90% adoption, we made AI fluency a baseline expectation for engineers by adding it to job descriptions and hiring expectations. By this point, it was easy to see that AI fluency wasn’t just the right thing for HubSpot, but for engineers it was a necessary investment as they continue to grow in their careers through this transformation. This helped us clearly commit internally and externally to the investment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Adoption was the beginning and opened the door to everything that followed: taking advantage of coding agents, creating Sidekick (our AI assistant that answers platform questions, creates issues, implements changes, and reviews PRs), developing a way to rapidly prototype UIs with our design system, and building infrastructure that led to 400+ tools that our agents can leverage across our internal, OpenAI, and Anthropic MCP servers.&lt;/p&gt;
    &lt;p&gt;Next: How we transitioned to agentic coding&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361140</guid><pubDate>Wed, 24 Sep 2025 14:42:49 +0000</pubDate></item><item><title>Who Funds Misfit Research?</title><link>https://blog.spec.tech/p/who-funds-misfit-research</link><description>&lt;doc fingerprint="b85d134d3d65b6c8"&gt;
  &lt;main&gt;
    &lt;p&gt;This piece is an addition to our Research Leader’s Playbook. We realized that (to our knowledge) nobody had unpacked where the money for “misfit research” — work that is a poor fit for academia, startups, or large companies — was coming from. If you are already deep in this world, you probably know all of this already, but it may still be worth a skim in for something that might surprise you.&lt;/p&gt;
    &lt;p&gt;Funding preferences and situations can change quickly, so if any of this is incorrect or incomplete, please leave a note in the comments!&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Unsurprisingly, there is no default way to fund misfit research: support can range from a group of philanthropists starting a new institute, to DARPA running robot competitions, to DAOs funding longevity projects, to VCs funding research projects gussied up as a company.&lt;/p&gt;
    &lt;p&gt;To get our brains around the funding landscape, it’s useful to divide this funding into non-dilutive (funding that comes without ownership or expectation of financial return) and dilutive (funding that comes with an expectation of financial return and often involves some ownership of an organization). This division is useful because, in broad strokes, non-dilutive and dilutive funding come with very different expectations, evaluation criteria, and “sales” processes.&lt;/p&gt;
    &lt;p&gt;Be aware that these categories have a lot of fuzziness (like many things in non-traditional research). Several entities, like family offices, do both dilutive and non-dilutive funding; they have their own section. Furthermore, non-dilutive and dilutive funding are not always mutually exclusive: some technology projects get off the ground with a mix of non-dilutive grants from foundations or governments and investments from angel or impact investors. (There are still a lot of gaps in this “messy middle” between pure-public-goods work and profit-maximizing company.)&lt;/p&gt;
    &lt;p&gt;Below are the major groups in each category and what they're actually funding. The end of this section touches on what to actually do with this information when you’re trying to fund research.&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-Dilutive Funders&lt;/head&gt;
    &lt;p&gt;Non-dilutive funding doesn’t come with any expectations of repayment or organizational ownership. This sort of funding is important for research that is a poor financial investment, whether because it will never create capturable value, or has long timescales and high uncertainty. However, non-dilutive funding isn’t just “free” money. Raising non-dilutive funding usually takes significantly more time and effort than the equivalent amount of investment dollars; most funders impose much more process up front and restrictions on how money can be spent.&lt;/p&gt;
    &lt;p&gt;Foundations: Foundations are organizations with full-time professional staff deploying money that has been set aside explicitly for philanthropic purposes. Foundations can range in size from a tiny org with one or two staff to hundreds or thousands of employees at the largest foundations like the Rockefeller or Gates Foundations.&lt;/p&gt;
    &lt;p&gt;In aggregate, foundations gave $30B towards research in 2019, which is more than the NSF and comparable to NIH.1 While these numbers are large, the median grant is significantly less than $1M. Even large foundations are usually spending money that comes from the interest on an endowment, so they may have much smaller budgets than you might expect based on the wealth of their founder or size of their endowment.&lt;/p&gt;
    &lt;p&gt;As of 2025, most research funding from foundations goes towards traditional research. The bureaucracy and processes of most foundations make it hard for them to support non-traditional work. Foundations typically deploy money through program officers who work within tight bounds set by the board of trustees on a yearly basis. Programs often have explicit mandates to work within traditional institutions through graduate fellowships or awards to professors.&lt;/p&gt;
    &lt;p&gt;There are, of course, exceptions. The now-defunct Schmidt Futures helped a number of ambitious research organizations get off the ground.&lt;/p&gt;
    &lt;p&gt;Philanthropic Aggregators: Philanthropic aggregators are organizations that use their brand and connections to fundraise for specific projects from wealthy individuals or foundations. Some examples include Renaissance Philanthropy, Founders Pledge, and XPrize. Each philanthropic aggregator has their own process and funding “form factor”: Renaissance Philanthropy creates “philanthropic funds” that they use to deploy grants, while the X-Prize creates prize competitions.&lt;/p&gt;
    &lt;p&gt;Philanthropic aggregators have funded a lot of non-traditional research. The process of recruiting on a case-by-case basis makes aggregators more flexible than foundations with board-specified programs.&lt;/p&gt;
    &lt;p&gt;Government Organizations: Government is, of course, a major research funder. The vast majority of government research funding is little-c conservative and intended for traditional PI-driven academic work. However, certain agencies and programs have supported some misfit work work. &lt;lb/&gt;DARPA pioneered using Other Transaction Authority (OTA) to run prize competitions like the DARPA Grand Challenge, Urban Challenge, and Robotics Challenge. SBIR (Small Business Innovation Research) grants provide non-dilutive funding towards research-heavy startups. Recently, two British government organizations (ARIA and the Department for Science, Innovation, and Technology) announced that they were funding Focused Research Organizations.&lt;/p&gt;
    &lt;p&gt;Crowdfunding Platforms: Platforms like Experiment.com enable researchers to raise small amounts of money from a large number of people. Crowdfunding can work for non-traditional projects that have public appeal like a citizen science endeavor to catalog ocean plastics or a team building a field microscope. However, crowdfunding rarely raises amounts more than tens of thousands of dollars, so it’s suited for modest-scale projects or early seed funding.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dilutive Funders&lt;/head&gt;
    &lt;p&gt;Dilutive funding can be double-edged: it injects significant resources, but it may steer the work towards shorter-term commercial goals and away from research work or even longer-term commercial goals. Professional investors need to show their investors portfolio growth and exits, which means they need companies in their portfolio to show year-over-year growth, which can be at odds with the uncertainty baked into research.&lt;/p&gt;
    &lt;p&gt;Angel Investors: Angels are individuals who invest their own money in early-stage startups. Technically, angel investment is driven by prospects of eventual financial return, but some angels think less about whether a startup is a good investment but instead about whether the work would be cool or impactful.&lt;/p&gt;
    &lt;p&gt;Venture Capitalists (VCs): The main context in which professional venture capitalists fund non-traditional work is (almost by definition) bubbles. When an area is “hot” enough, even professional VC funds put money towards work that has no sense of how it becomes a product or a business. There are also a few VC firms that have different structures, like longer fund lifetimes, that enable them to invest differently from other firms. Some examples of VC funding into research includes most quantum computing companies, Colossal Biosciences, and Physical Intelligence.&lt;/p&gt;
    &lt;p&gt;Corporate Research: While corporate research has drastically contracted, some large companies with large margins still support exploratory research. As obvious 2025, AI research is an obvious example. Corporations rarely fund nontraditional research – most external research funding goes towards universities primarily as a hiring pipeline. Teams can sometimes carve out a niche within corporate research to develop something ambitious – the team that started the Lean FRO worked at Microsoft Research for a long time.&lt;/p&gt;
    &lt;p&gt;Corporate Venture: Corporate venture capital arms invest in startups based on the company’s “strategic interest” in addition to pure returns. For example, a car company may invest in a research-heavy battery startup or a chip company may invest in a photonics company long before they have a product. Large companies sometimes acquire and continue to fund organizations that focus more on research than products: Hyundai’s acquisition of Boston Dynamics, for example.&lt;/p&gt;
    &lt;p&gt;Impact Investors: Some investors are willing to accept lower financial returns in exchange for high social or environmental impact. These investors fund for-profit ventures within some impact area (like climate or health) that don’t fit the profile for normal VC funding because of factors like time scales or capital requirements. This kind of investment is also sometimes called “patient capital” or “concessionary funding.” For example, Breakthrough Energy Ventures (BEV) explicitly operates on a 20-year timeline and invests in risky clean energy companies with the understanding that some may only yield societal benefit without huge profits. In the medical world impact investors sometimes invest in exchange for royalties or revenue sharing rather than explosive startup growth.&lt;/p&gt;
    &lt;p&gt;Program-related Investments (PRIs): Foundations and Donor Advised Funds (which we will talk more about in the next section) can make dilutive investments out of their endowments that count towards their legal deployment quotas as long as they are mission aligned. Unpacking that jargon: Foundations (but not DAFs) legally must spend 5% of their assets annually; normally this money is deployed as grants, but dilutive investments that are aligned with the foundation’s mission can also count towards that 5%. &lt;lb/&gt;Investments with the possibility of a return enable Foundations and DAFs to fulfill their charitable missions without eating as much into their bank accounts. This upside means that PRIs that do happen are often larger than normal grants and theoretically people with DAFs and Foundations should be excited to do them. However, the potential for IRS scrutiny, divisions between investment and granting teams, and DAF sponsors that don’t support PRIs means that they are fairly rare.&lt;lb/&gt;Two words of caution about funding research-heavy work with dilutive alternatives to venture capital:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;While PRIs and impact investors explicitly fund work that struggles to raise VC funding, they often focus on work that can’t raise VC funding because of characteristics like timescales, capital requirements, and market sizes, not because they are too research-heavy.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Most dilutive funding puts an organization on a trajectory where they do need to raise venture capital eventually. Many misfit research projects will never be a good fit for venture capital, so raising dilutive funding can be a trap.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Both&lt;/head&gt;
    &lt;p&gt;These entities can (but do not always) do both dilutive and non-dilutive funding.&lt;/p&gt;
    &lt;p&gt;Decentralized Autonomous Organizations (DAOs): DAOs are communities that pool funds for a common purpose by selling blockchain-based “tokens” that give their owners a say in the organization’s governance. Some DAOs, like VitaDAO or CerebrumDAO focus on research. DAOs fund work through many different mechanisms — both traditional grants and dilutive funding as well as newer blockchain-based mechanisms for capturing some of the value that the work could create.&lt;/p&gt;
    &lt;p&gt;High-Net-Worth Individuals (HNWIs): Wealthy individuals sometimes bankroll research personally. Individuals have the most flexibility of any funders to do unconventional things. As a result, a lot of non-traditional research has been funded directly by individuals. HNWIs often fund things quietly and make themselves hard to contact for obvious reasons: everybody would be asking them for money and funding strange things can open people up to reputational risk.&lt;/p&gt;
    &lt;p&gt;Family Offices: Family offices are professional organizations that handle the money of a wealthy individual or family. The big thing that differentiates family offices from foundations is that they don’t have a pile of money that has been explicitly set aside for philanthropy. Instead, they have multiple mandates – increase wealth, hedge against risk, maintain liquidity, and do philanthropy.&lt;/p&gt;
    &lt;p&gt;Keep in mind that people and organizations can have completely different focuses, mindsets, and processes whether they’re doing dilutive or non-dilutive funding: a wealthy individual who will write a million dollar check to a startup the same day might only donate $10k at a time only to projects focusing on a specific disease.&lt;/p&gt;
    &lt;p&gt;http://arxiv.org/abs/2206.10661&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361154</guid><pubDate>Wed, 24 Sep 2025 14:44:20 +0000</pubDate></item><item><title>The DHS has been harvesting DNA from Americans for years</title><link>https://www.wired.com/story/dhs-has-been-collecting-us-citizens-dna-for-years/</link><description>&lt;doc fingerprint="9199219c0385031a"&gt;
  &lt;main&gt;
    &lt;p&gt;For years, Customs and Border Protection agents have been quietly harvesting DNA from American citizens, including minors, and funneling the samples into an FBI crime database, government data shows. This expansion of genetic surveillance was never authorized by Congress for citizens, children, or civil detainees.&lt;/p&gt;
    &lt;p&gt;According to newly released government data analyzed by Georgetown Law’s Center on Privacy &amp;amp; Technology, the Department of Homeland Security, which oversees CBP, collected the DNA of nearly 2,000 US citizens between 2020 and 2024 and had it sent to CODIS, the FBI’s nationwide system for policing investigations. An estimated 95 were minors, some as young as 14. The entries also include travelers never charged with a crime and dozens of cases where agents left the “charges” field blank. In other files, officers invoked civil penalties as justification for swabs that federal law reserves for criminal arrests.&lt;/p&gt;
    &lt;p&gt;The findings appear to point to a program running outside the bounds of statute or oversight, experts say, with CBP officers exercising broad discretion to capture genetic material from Americans and have it funneled into a law-enforcement database designed in part for convicted offenders. Critics warn that anyone added to the database could endure heightened scrutiny by US law enforcement for life.&lt;/p&gt;
    &lt;p&gt;“Those spreadsheets tell a chilling story,” Stevie Glaberson, director of research and advocacy at Georgetown’s Center on Privacy &amp;amp; Technology, tells WIRED. “They show DNA taken from people as young as 4 and as old as 93—and, as our new analysis found, they also show CBP flagrantly violating the law by taking DNA from citizens without justification.”&lt;/p&gt;
    &lt;p&gt;DHS did not respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;For more than two decades, the FBI’s Combined DNA Index System, or CODIS, has been billed as a tool for violent crime investigations. But under both recent policy changes and the Trump administration’s immigration agenda, the system has become a catchall repository for genetic material collected far outside the criminal justice system.&lt;/p&gt;
    &lt;p&gt;One of the sharpest revelations came from DHS data released earlier this year showing that CBP and Immigrations and Customs Enforcement have been systematically funneling cheek swabs from immigrants—and, in many cases, US citizens—into CODIS. What was once a program aimed at convicted offenders now sweeps in children at the border, families questioned at airports, and people held on civil—not criminal—grounds. WIRED previously reported that DNA from minors as young as 4 had ended up in the FBI’s database, alongside elderly people in their nineties, with little indication of how or why the samples were taken.&lt;/p&gt;
    &lt;p&gt;The scale is staggering. According to Georgetown researchers, DHS has contributed roughly 2.6 million profiles to CODIS since 2020—far above earlier projections and a surge that has reshaped the database. By December 2024, CODIS’s “detainee” index contained over 2.3 million profiles; by April 2025, the figure had already climbed to more than 2.6 million. Nearly all of these samples—97 percent—were collected under civil, not criminal, authority. At the current pace, according to Georgetown Law’s estimates, which are based on DHS projections, Homeland Security files alone could account for one-third of CODIS by 2034.&lt;/p&gt;
    &lt;p&gt;The expansion has been driven by specific legal and bureaucratic levers. Foremost was an April 2020 Justice Department rule that revoked a long-standing waiver allowing DHS to skip DNA collection from immigration detainees, effectively green-lighting mass sampling. Later that summer, the FBI signed off on rules that let police booking stations run arrestee cheek swabs through Rapid DNA machines—automated devices that can spit out CODIS-ready profiles in under two hours.&lt;/p&gt;
    &lt;p&gt;The strain of the changes became apparent in subsequent years. Former FBI director Christopher Wray warned during Senate testimony in 2023 that the flood of DNA samples from DHS threatened to overwhelm the bureau’s systems. The 2020 rule change, he said, had pushed the FBI from a historic average of a few thousand monthly submissions to 92,000 per month—over 10 times its traditional intake. The surge, he cautioned, had created a backlog of roughly 650,000 unprocessed kits, raising the risk that people detained by DHS could be released before DNA checks produced investigative leads.&lt;/p&gt;
    &lt;p&gt;Under Trump’s renewed executive order on border enforcement, signed in January 2025, DHS agencies were instructed to deploy “any available technologies” to verify family ties and identity, a directive that explicitly covers genetic testing. This month, federal officials announced they were soliciting new bids to install Rapid DNA at local booking facilities around the country, with combined awards of up to $3 million available.&lt;/p&gt;
    &lt;p&gt;“The Department of Homeland Security has been piloting a secret DNA collection program of American citizens since 2020. Now, the training wheels have come off,” said Anthony Enriquez, vice president of advocacy at Robert F. Kennedy Human Rights. “In 2025, Congress handed DHS a $178 billion check, making it the nation’s costliest law enforcement agency, even as the president gutted its civil rights watchdogs and the Supreme Court repeatedly signed off on unconstitutional tactics.”&lt;/p&gt;
    &lt;p&gt;Oversight bodies and lawmakers have raised alarms about the program. As early as 2021, the DHS Inspector General found the department lacked central oversight of DNA collection and that years of noncompliance can undermine public safety—echoing an earlier rebuke from the Office of Special Counsel, which called CBP’s failures an “unacceptable dereliction.”&lt;/p&gt;
    &lt;p&gt;US senator Ron Wyden more recently pressed DHS and DOJ for explanations about why children’s DNA is being captured and whether CODIS has any mechanism to reject improperly obtained samples, saying the program was never intended to collect and permanently retain the DNA of all noncitizens, warning the children are likely to be “treated by law enforcement as suspects for every investigation of every future crime, indefinitely.”&lt;/p&gt;
    &lt;p&gt;Rights advocates allege that CBP’s DNA collection program has morphed into a sweeping genetic surveillance regime, with samples from migrants and even US citizens fed into criminal databases absent transparency, legal safeguards, or limits on retention. Georgetown’s privacy center points out that once DHS creates and uploads a CODIS profile, the government retains the physical DNA sample indefinitely, with no procedure to revisit or remove profiles when the legality of the detention is in doubt.&lt;/p&gt;
    &lt;p&gt;In parallel, Georgetown and allied groups have sued DHS over its refusal to fully release records about the program, highlighting how little the public knows about how DNA is being used, stored, or shared once it enters CODIS.&lt;/p&gt;
    &lt;p&gt;Taken together, these revelations may suggest a quiet repurposing of CODIS. A system long described as a forensic breakthrough is being remade into a surveillance archive—sweeping up immigrants, travelers, and US citizens alike, with few checks on the agents deciding whose DNA ends up in the federal government’s most intimate database.&lt;/p&gt;
    &lt;p&gt;“There’s much we still don’t know about DHS’s DNA collection activities,” Georgetown’s Glaberson says. “We’ve had to sue the agencies just to get them to do their statutory duty, and even then they’ve flouted court orders. The public has a right to know what its government is up to, and we’ll keep fighting to bring this program into the light.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361239</guid><pubDate>Wed, 24 Sep 2025 14:51:44 +0000</pubDate></item><item><title>The Lambda Calculus – Stanford Encyclopedia of Philosophy</title><link>https://plato.stanford.edu/entries/lambda-calculus/</link><description>&lt;doc fingerprint="2e83231764ffdbf1"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The Lambda Calculus&lt;/head&gt;&lt;p&gt;The \(\lambda\)-calculus is, at heart, a simple notation for functions and application. The main ideas are applying a function to an argument and forming functions by abstraction. The syntax of basic \(\lambda\)-calculus is quite sparse, making it an elegant, focused notation for representing functions. Functions and arguments are on a par with one another. The result is a non-extensional theory of functions as rules of computation, contrasting with an extensional theory of functions as sets of ordered pairs. Despite its sparse syntax, the expressiveness and flexibility of the \(\lambda\)-calculus make it a cornucopia of logic and mathematics. This entry develops some of the central highlights of the field and prepares the reader for further study of the subject and its applications in philosophy, linguistics, computer science, and logic.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;1. Introduction&lt;/item&gt;&lt;item&gt;2. Syntax&lt;/item&gt;&lt;item&gt;3. Brief history of \(\lambda\)-calculus&lt;/item&gt;&lt;item&gt;4. Reduction&lt;/item&gt;&lt;item&gt;5. \(\lambda\)-theories&lt;/item&gt;&lt;item&gt;6. Consistency of the \(\lambda\)-calculus&lt;/item&gt;&lt;item&gt;7. Semantics of \(\lambda\)-calculus&lt;/item&gt;&lt;item&gt;8. Extensions and Variations&lt;/item&gt;&lt;item&gt;9. Applications&lt;/item&gt;&lt;item&gt;Bibliography&lt;/item&gt;&lt;item&gt;Academic Tools&lt;/item&gt;&lt;item&gt;Other Internet Resources&lt;/item&gt;&lt;item&gt;Related Entries&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;1. Introduction&lt;/head&gt;&lt;p&gt;The \(\lambda\)-calculus is an elegant notation for working with applications of functions to arguments. To take a mathematical example, suppose we are given a simple polynomial such as \(x^2 -2\cdot x+5\). What is the value of this expression when \(x = 2\)? We compute this by ‘plugging in’ 2 for \(x\) in the expression: we get \(2^2 -2\cdot 2+5\), which we can further reduce to get the answer 5. To use the \(\lambda\)-calculus to represent the situation, we start with the \(\lambda\)-term&lt;/p&gt;\[ \lambda x[x^2 -2\cdot x+5]. \]&lt;p&gt;The \(\lambda\) operators allows us to abstract over \(x\). One can intuitively read ‘\(\lambda x[x^2 -2\cdot x+5]\)’ as an expression that is waiting for a value \(a\) for the variable \(x\). When given such a value \(a\) (such as the number 2), the value of the expression is \(a^2 -2\cdot a+5\). The ‘\(\lambda\)’ on its own has no significance; it merely binds the variable \(x\), guarding it, as it were, from outside interference. The terminology in \(\lambda\)-calculus is that we want to apply this expression to an argument, and get a value. We write ‘\(Ma\)’ to denote the application of the function \(M\) to the argument \(a\). Continuing with the example, we get:&lt;/p&gt;\[\begin{align} (\lambda x[x^2 -2\cdot x+5])2 \rhd 2^2&amp;amp; -2\cdot 2+5 &amp;amp;\langle \text{Substitute 2 for } x\rangle \\ &amp;amp;= 4-4+5 &amp;amp;\langle\text{Arithmetic}\rangle \\ &amp;amp;= 5 &amp;amp;\langle\text{Arithmetic}\rangle \end{align}\]&lt;p&gt;The first step of this calculation, plugging in ‘2’ for occurrences of \(x\) in the expression ‘\(x^2 - 2\cdot x + 5\)’, is the passage from an abstraction term to another term by the operation of substitution. The remaining equalities are justified by computing with natural numbers.&lt;/p&gt;&lt;p&gt;This example suggests the central principle of the \(\lambda\)-calculus, called \(\beta\)-reduction, which is also sometimes called \(\beta\)-conversion:&lt;/p&gt;\[ \tag{\(\beta\)} (\lambda x[M])N \rhd M[x := N] \]&lt;p&gt;The understanding is that we can reduce or contract \((\rhd)\) an application \((\lambda xM)N\) of an abstraction term (the left-hand side, \(\lambda xM)\) to something (the right-hand side, \(N)\) by simply plugging in \(N\) for the occurrences of \(x\) inside \(M\) (that’s what the notation ‘\(M[x := N]\)’ expresses). \(\beta\)-reduction, or \(\beta\)-conversion, is the heart of the \(\lambda\)-calculus. When one actually applies \(\beta\)-reduction to reduce a term, there is an important proviso that has to be observed. But this will be described in Section 2.1, when we discuss bound and free variables.&lt;/p&gt;&lt;head rend="h3"&gt;1.1 Multi-argument operations&lt;/head&gt;&lt;p&gt;What about functions of multiple arguments? Can the \(\lambda\)-calculus represent operations such as computing the length of the hypotenuse of a right triangle:&lt;/p&gt;&lt;p&gt;Hypotenuse of a right triangle with legs of length \(x\) and \(y \Rightarrow \sqrt{x^2 + y^2}\).&lt;/p&gt;&lt;p&gt;The length-of-hypotenuse operation maps two positive real numbers \(x\) and \(y\) to another positive real number. One can represent such multiple-arity operations using the apparatus of the \(\lambda\)-calculus by viewing the operation as taking one input at a time. Thus, the operation can be seen as taking one input, \(x\), a positive real number, and producing as its value not a number, but an operation: namely, the operation that takes a positive real number \(y\) as input and produces as output the positive real number \(\sqrt{x^2 + y^2}\). One could summarize the discussion by saying that the operation, hypotenuse-length, that computes the length of the hypotenuse of a right triangle given the lengths \(a\) and \(b\) of its legs, is:&lt;/p&gt;&lt;p&gt;hypotenuse-length \(:= \lambda a[\lambda b[\sqrt{a^2 + b^2}]]\)&lt;/p&gt;&lt;p&gt;By the principle of \(\beta\)-reduction, we have, for example, that hypotenuse-length 3, the application of hypotenuse-length to 3, is \(\lambda b[\sqrt{3^2 + b^2}]\), which is a function of that is ‘waiting’ for another argument. The \(\lambda\)-term hypotenuse-length 3 can be viewed as a function that computes the length of the hypotenuse of a right triangle one of whose legs has length 3. We find, finally, that (hypotenuse-length 3)4—the application of hypotenuse-length to 3 and then to 4—is 5, as expected.&lt;/p&gt;&lt;p&gt;Another way to understand the reduction of many-place functions to one-place functions is to imagine a machine \(M\) that initially starts out by loading the first \(a\) of multiple arguments \(a, b,\ldots\) into memory. If one then suspends the machine after it has loaded the first argument into memory, one can view the result as another machine M\(_a\) that is awaiting one fewer input; the first argument is now fixed.&lt;/p&gt;&lt;head rend="h3"&gt;1.2 Non-Extensionality&lt;/head&gt;&lt;p&gt;An important philosophical issue concerning the \(\lambda\)-calculus is the question of its underlying concept of functions. In set theory, a function is standardly understood as a set of argument-value pairs. More specifically, a function is understood as a set \(f\) of ordered pairs satisfying the property that \((x,y) \in f\) and \((x,z) \in f\) implies \(y = z\). If \(f\) is a function and \((x,y) \in f\), this means that the function f assigns the value \(y\) to the argument \(x\). This is the concept of functions-as-sets. Consequently, the notion of equality of functions-as-sets is equality qua sets, which, under the standard principle of extensionality, entails that two functions are equal precisely when they contain the same ordered pairs. In other words, two functions are identical if and only if they assign the same values to the same arguments. In this sense, functions-as-sets are extensional objects.&lt;/p&gt;&lt;p&gt;In contrast, the notion of a function at work in \(\lambda\)-calculus is one where functions are understood as rules: a function is given by a rule for how to determine its values from its arguments. More specifically, we can view a \(\lambda\)-term \(\lambda x[M]\) as a description of an operation that, given \(x\), produces \(M\); the body \(M\) of the abstraction term is, essentially, a rule for what to do with \(x\). This is the conception of functions-as-rules. Intuitively, given rules \(M\) and \(N\), we cannot in general decide whether \(\lambda x[M]\) is equal to \(\lambda x[N]\). The two terms might ‘behave’ the same (have the same value given the same arguments), but it may not be clear what resources are needed for showing the equality of the terms. In this sense, functions-as-rules are non-extensional objects.&lt;/p&gt;&lt;p&gt;To distinguish the extensional concept of functions-as-sets from the non-extensional concept of functions-as-rules, the latter is often referred to as an ‘intensional’ function concept, in part because of the ostensibly intensional concept of a rule involved. This terminology is particularly predominant in the community of mathematical logicians and philosophers of mathematics working on the foundations of mathematics. But from the perspective of the philosophy of language, the terminology can be somewhat misleading, since in this context, the extensional-intensional distinction has a slightly different meaning.&lt;/p&gt;&lt;p&gt;In the standard possible-worlds framework of philosophical semantics, we would distinguish between an extensional and an intensional function concept as follows. Let us say that two functions are extensionally equivalent at a world if and only if they assign the same values to the same arguments at that world. And let us say that two functions are intensionally equivalent if and only if they assign the same values to the same arguments at every possible-world. To illustrate, consider the functions highest-mountain-on-earth and highest-mountain-in-the-Himalayas, where highest-mountain-on-earth assigns the highest mountain on earth as the value to every argument and highest-mountain-in-the-Himalayas assigns the highest mountain in the Himalayas as the value to every argument. The two functions are extensionally equivalent (at the actual world), but not intensionally so. At the actual world, the two functions assign the same value to every argument, namely Mt. Everest. Now consider a world where Mt. Everest is not the highest mountain on earth, but say, Mt. Rushmore is. Suppose further that this is so, just because Mt. Rushmore is 30.000 feet/9.100 m higher than it is at the actual world, while Mt. Everest, with its roughly 29.000 feet/8.800 m, is still the highest mountain in the Himalayas. At that world, highest-mountain-on-earth now assigns Mt. Rushmore as the value to every argument, while highest-mountain-in-the-Himalayas still assigns Mt. Everest to every object. In other words, highest-mountain-on-earth and highest-mountain-in-the-Himalayas are extensionally equivalent (at the actual world) but not intensionally equivalent.&lt;/p&gt;&lt;p&gt;A function concept may now be called extensional if and only if it requires functions that are extensionally equivalent at the actual world to be identical. And a function concept may be classified as intensional if and only if it requires intensionally equivalent functions to be identical. Note that these classifications are conceptually different from the distinctions commonly used in the foundations of mathematics. On the terminology used in the foundations of mathematics, functions-as-sets are classified as extensional since they use the axiom of extensionality as their criterion of identity, and functions-as-rules are classified as intensional because they rely on the ostensibly intensional concept of a rule. In the present possible-worlds terminology, function concepts are classified as extensional or intensional based of their behavior at possible-worlds.&lt;/p&gt;&lt;p&gt;An issue from which conceptual confusion might arise is that the two terminologies potentially pass different verdicts on the function concept at work in the \(\lambda\)-calculus. To see this, consider the following two functions:&lt;/p&gt;\[\begin{align} \addone &amp;amp;:= \lambda x[x+1] \\ \addtwosubtractone &amp;amp;:= \lambda x[[x+2]-1] \end{align}\]&lt;p&gt;These two functions are clearly extensionally equivalent: they assign the same value to the same input at the actual world. Moreover, given standard assumptions in possible worlds semantics, the two functions are also intensionally equivalent. If we assume that mathematical facts, like facts about addition and subtraction, are necessary in the sense that they are the same at every possible world, then we get that the two functions give the same value to the arguments at every possible world. So, an intensional function concept would require the two functions to be identical. In the \(\lambda\)-calculus, however, it’s not clear at all that we should identify the two functions. Formally speaking, without the help of some other principle, we cannot show that the two \(\lambda\)-terms denote the same function. Moreover, informally speaking, on the conception of functions-as-rules, it’s not even clear that we should identify them: the two terms involve genuinely different rules, and so we might be tempted to say that they denote different functions.&lt;/p&gt;&lt;p&gt;A function concept that allows for intensionally equivalent functions to be distinct is called hyperintensional. The point is that in possible-worlds terminology, the function concept at work in the \(\lambda\)-calculus may be regarded not as intentional but hyperintensional—in contrast to what the terminology common in the foundations of mathematics says. Note that it’s unclear how an intensional semantic framework, like the possible-worlds framework, could even in principle account for a non-intensional function concept. On the semantics of the \(\lambda\)-calculus, see section 7. The point here was simply to clarify any conceptual confusions that might arise from different terminologies at play in philosophical discourse.&lt;/p&gt;&lt;p&gt;The hyperintensionality of the \(\lambda\)-calculus is particularly important when it comes to its applications as a theory of not only functions, but more generally \(n\)-ary relations. On this, see section 9.3. It is effectively the hyperintensionality of the \(\lambda\)-calculus that makes it an attractive tool in this context. It should be noted, however, that the \(\lambda\)-calculus can be made extensional (as well as intensional) by postulating additional laws concerning the equality of \(\lambda\)-terms. On this, see section 5.&lt;/p&gt;&lt;head rend="h2"&gt;2. Syntax&lt;/head&gt;&lt;p&gt;The official syntax of the \(\lambda\)-calculus is quite simple; it is contained in the next definition.&lt;/p&gt;&lt;p&gt;Definition For the alphabet of the language of the \(\lambda\)-calculus we take the left and right parentheses, left and right square brackets, the symbol ‘\(\lambda\)’, and an infinite set of variables. The class of \(\lambda\)-terms is defined inductively as follows:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Every variable is a \(\lambda\)-term.&lt;/item&gt;&lt;item&gt;If \(M\) and \(N\) are \(\lambda\)-terms, then so is \((MN)\).&lt;/item&gt;&lt;item&gt;If \(M\) is a \(\lambda\)-term and \(x\) is a variable, then \((\lambda x[M])\) is a \(\lambda\)-term.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;By ‘term’ we always mean ‘\(\lambda\)-term’. Terms formed according to rule (2) are called application terms. Terms formed according to rule (3) are called abstraction terms.&lt;/p&gt;&lt;p&gt;As is common when dealing with formal languages that have grouping symbols (the left and right parenthesis, in our case), some parentheses will be omitted when it is safe to do so (that is, when they can be reintroduced in only one sensible way). Juxtaposing more than two \(\lambda\)-terms is, strictly speaking, illegal. To avoid the tedium of always writing all needed parentheses, we adopt the following convention:&lt;/p&gt;&lt;p&gt;Convention (association to the left): When more than two terms \(M_1 M_2 M_3 \ldots M_n\) are juxtaposed we can recover the missing parentheses by associating to the left: reading from left to right, group \(M_1\) and \(M_2\) together, yielding \((M_1 M_2)M_3 \ldots M_n\); then group \((M_1 M_2)\) with \(M_3\): \(((M_1 M_2)M_3)\ldots M_n\), and so forth.&lt;/p&gt;&lt;p&gt;The convention thus gives a unique reading to any sequence of \(\lambda\)-terms whose length is greater than 2.&lt;/p&gt;&lt;head rend="h3"&gt;2.1 Variables, bound and free&lt;/head&gt;&lt;p&gt;The function of \(\lambda\) in an abstraction term \((\lambda x[M]\)) is that it binds the variable appearing immediately after it in the term \(M\). Thus \(\lambda\) is analogous to the universal and existential quantifiers \(\forall\) and \(\exists\) of first-order logic. One can define, analogously, the notions of free and bound variable in the expected way, as follows.&lt;/p&gt;&lt;p&gt;Definition The syntactic functions \(\mathbf{FV}\) and \(\mathbf{BV}\) (for ‘free variable’ and ‘bound variable’, respectively) are defined on the set of \(\lambda\)-terms by structural induction thus:&lt;/p&gt;&lt;p&gt;For every variable \(x\), term \(M\), and term \(N\):&lt;/p&gt;&lt;p&gt;If \(\mathbf{FV}(M) = \varnothing\) then \(M\) is called a combinator.&lt;/p&gt;&lt;p&gt;Clause (3) in the two definitions supports the intention that \(\lambda\) binds variables (ensures that they are not free). Note the difference between \(\mathbf{BV}\) and \(\mathbf{FV}\) for variables.&lt;/p&gt;&lt;p&gt;As is typical in other subjects where the concepts appear, such as first-order logic, one needs to be careful about the issue; a casual attitude about substitution can lead to syntactic difficulties.[1] We can defend a casual attitude by adopting the convention that we are interested not in terms themselves, but in a certain equivalence class of terms. We now define substitution, and then lay down a convention that allows us to avoid such difficulties.&lt;/p&gt;&lt;p&gt;Definition (substitution) We write ‘\(M[x := N]\)’ to denote the substitution of \(N\) for the free occurrences of \(x\) in \(M\). A precise definition[2] by recursion on the set of \(\lambda\)-terms is as follows: for all terms \(A\), \(B\), and \(M\), and for all variables \(x\) and \(y\), we define&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;\(x[x := M] \equiv M\)&lt;/item&gt;&lt;item&gt;\(y[x := M] \equiv y\) (\(y\) distinct from \(x)\)&lt;/item&gt;&lt;item&gt;\((AB)[x := M] \equiv A[x := M]B[x := M]\)&lt;/item&gt;&lt;item&gt;\((\lambda x[A])[x := M] \equiv \lambda x[A]\)&lt;/item&gt;&lt;item&gt;\((\lambda y[A])[x := M] \equiv \lambda y[A[x := M]]\) (\(y\) distinct from \(x)\)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Clause (1) of the definition simply says that if we are to substitute \(M\) for \(x\) and we are dealing simply with \(x\), then the result is just \(M\). Clause (2) says that nothing happens when we are dealing (only) with a variable different from \(x\) but we are to substitute something for \(x\). Clause (3) tells us that substitution unconditionally distributes over applications. Clauses (4) and (5) concern abstraction terms and parallel clauses (1) and (2) (or rather, clauses (2) and (1), in opposite order): If the bound variable \(z\) of the abstraction term \(\lambda z[A]\) is identical to the variable \(x\) for which we are to do a substitution, then we do not perform any substitution (that is, substitution “stops”). This coheres with the intention that \(M[x := N]\) is supposed to denote the substitution of \(N\) for the free occurrences of \(x\) in \(M\). If \(M\) is an abstraction term \(\lambda x[A]\) whose bound variable is \(x\), then \(x\) does not occurr freely in \(M\), so there is nothing to do. This explains clause 4. Clause (5), finally, says that if the bound variable of an abstraction term differs from \(x\), then at least \(x\) has the “chance ” to occur freely in the abstraction term, and substitution continues into the body of the abstraction term.&lt;/p&gt;&lt;p&gt;Definition (change of bound variables, \(\alpha\)-convertibility). The term \(N\) is obtained from the term \(M\) by a change of bound variables if, roughly, any abstraction term \(\lambda x[A]\) inside \(M\) has been replaced by \(\lambda y[A[x := y]]\).&lt;/p&gt;&lt;p&gt;Let us say that terms \(M\) and \(N\) are \(\alpha\)-convertible if there is a sequence of changes of bound variables starting from \(M\) and ending at \(N\).&lt;/p&gt;&lt;p&gt;Axiom. \(\beta\)-conversion (stated with a no-capture proviso):&lt;/p&gt;&lt;p&gt; \( (\lambda x[M])N \rhd M[x := N]\), &lt;lb/&gt; provided no variable that occurrs free in \(N\) becomes bound after its substitution into \(M\).&lt;/p&gt;&lt;p&gt;Roughly, we need to adhere to the principle that free variables ought to remain free; when an occurrence of a variable is threatened to become bound by a substitution, simply perform enough \(\alpha\)-conversions to sidestep the problem. If we keep this in mind, we can work with \(\lambda\)-calculus without worrying about these nettlesome syntactic difficulties. So, for example, we can’t apply the function \(\lambda x[\lambda y[x(y-5)]]\) to the argument \(2y\) because upon substitution of “\(2y\)” for “\(x\)”, the “\(y\)” in “\(2y\)” would be captured by the variable-binding operator “\(\lambda y\)”. Such a substitution would yield a function different from the one intended. However, we can first transform \(\lambda x[\lambda y[x(y-5)]]\) to \(\lambda x[\lambda z[x(z-5)]]\) by \(\alpha\)-conversion, and then apply this latter function to the argument \(2y\). So whereas the following is not a valid use of \(\beta\)-conversion: \[ (\lambda x[\lambda y[x(y-5)]])2y \rhd \lambda y[2y(y-5)]\] we can validly use \(\beta\)-conversion to conclude: \[ (\lambda x[\lambda z[x(z-5)]])2y \rhd \lambda z[2y(z-5)]\] This example helps one to see why the proviso to \(\beta\)-conversion is so important. The proviso is really no different from the one used in the statement of an axiom of the predicate calculus, namely: \(\forall x\phi \to \phi^{\tau}_x\), provided no variable that is free in the term \(\tau\) before the substitution becomes bound after the substitution.&lt;/p&gt;&lt;p&gt;The syntax of \(\lambda\)-calculus is quite flexible. One can form all sorts of terms, even self-applications such as \(xx\). Such terms appear at first blush to be suspicious; one might suspect that using such terms could lead to inconsistency, and in any case one might find oneself reaching for a tool with which to forbid such terms. If one were to view functions and sets of ordered pairs of a certain kind, then the \(x\) in \(xx\) would be a function (set of ordered pairs) that contains as an element a pair \((x,y)\) whose first element would be \(x\) itself. But no set can contain itself in this way, lest the axiom of foundation (or regularity) be violated. Thus, from a set theoretical perspective such terms are clearly dubious. Below one can find a brief sketch of one such tool, type theory. But in fact such terms do not lead to inconsistency and serve a useful purpose in the context of \(\lambda\)-calculus. Moreover, forbidding such terms, as in type theory, does not come for free (e.g., some of the expressiveness of untyped \(\lambda\)-calculus is lost).&lt;/p&gt;&lt;head rend="h3"&gt;2.2 Combinators&lt;/head&gt;&lt;p&gt;As defined earlier, a combinator is a \(\lambda\)-term with no free variables. One can intuitively understand combinators as ‘completely specified’ operations, since they have no free variables. There are a handful of combinators that have proven useful in the history of \(\lambda\)-calculus; the next table highlights some of these special combinators. Many more could be given (and obviously there are infinitely many combinators), but the following have concise definitions and have proved their utility. Below is a table of some standard \(\lambda\)-terms and combinators.&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell&gt;Name&lt;/cell&gt;&lt;cell&gt;Definition &amp;amp; Comments&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\bS\)&lt;/cell&gt;&lt;cell&gt;\(\lambda x[\lambda y[\lambda z[xz(yz)]]]\) &lt;p&gt;Keep in mind that ‘\(xz(yz)\)’ is to be understood as the application \((xz)(yz)\) of \(xz\) to \(yz. \bS\) can thus be understood as a substitute-and-apply operator: \(z\) ‘intervenes’ between \(x\) and \(y\): instead of applying \(x\) to \(y\), we apply \(xz\) to \(yz\).&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\mathbf{K}\)&lt;/cell&gt;&lt;cell&gt;\(\lambda x[\lambda y[x]]\) &lt;p&gt;The value of \(\mathbf{K}M\) is the constant function whose value for any argument is simply \(M.\)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\mathbf{I}\)&lt;/cell&gt;&lt;cell&gt;\(\lambda x[x]\) &lt;p&gt;The identity function.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\mathbf{B}\)&lt;/cell&gt;&lt;cell&gt;\(\lambda x[\lambda y[\lambda z[x(yz)]]]\) &lt;p&gt;Recall that ‘\(xyz\)’ is to be understood as \((xy)z\), so this combinator is not a trivial identity function.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\mathbf{C}\)&lt;/cell&gt;&lt;cell&gt;\(\lambda x[\lambda y[\lambda z[xzy]]]\) &lt;p&gt;Swaps an argument.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\mathbf{T}\)&lt;/cell&gt;&lt;cell&gt;\(\lambda x[\lambda y[x]]\) &lt;p&gt;Truth value true. Identical to \(\mathbf{K}\). We shall see later how these representations of truth values plays a role in the blending of logic and \(\lambda\)-calculus.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\mathbf{F}\)&lt;/cell&gt;&lt;cell&gt;\(\lambda x[\lambda y[y]]\) &lt;p&gt;Truth value false.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\boldsymbol{\omega}\)&lt;/cell&gt;&lt;cell&gt;\(\lambda x[xx]\) &lt;p&gt;Self-application combinator&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\boldsymbol{\Omega}\)&lt;/cell&gt;&lt;cell&gt;\(\boldsymbol{\omega \omega}\) &lt;p&gt;Self-application of the self-application combinator. Reduces to itself.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\mathbf{Y}\)&lt;/cell&gt;&lt;cell&gt;\(\lambda f[(\lambda x[f(xx)])(\lambda x[f(xx)]\))] &lt;p&gt;Curry’s paradoxical combinator. For every \(\lambda\)-term \(X\), we have: \[\begin{align} \mathbf{Y}X &amp;amp;\rhd (\lambda x[X(xx)])(\lambda x[X(xx)]) \\ &amp;amp;\rhd X((\lambda x[X(xx)])(\lambda x[X(xx)])) \end{align}\] The first step in the reduction shows that \(\mathbf{Y}\)X reduces to the application term \((\lambda x[X(xx)])(\lambda x[X(xx)]\)), which is recurring in the third step. Thus, \(\mathbf{Y}\) has the curious property that \(\mathbf{Y}\)X and X\((\mathbf{Y}\)X) reduce to a common term.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;\(\boldsymbol{\Theta}\)&lt;/cell&gt;&lt;cell&gt;\((\lambda x[\lambda f[f(xxf)]])(\lambda x[\lambda f[f(xxf)]]\)) &lt;p&gt;Turing’s fixed-point combinator. For every \(\lambda\)-term \(X\), \(\boldsymbol{\Theta}X\) reduces to \(X(\boldsymbol{\Theta}X)\), which one can confirm by hand. (Curry’s paradoxical combinator \(\mathbf{Y}\) does not have this property.)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Below is a table of notational conventions employed in this entry.&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell&gt;Notation&lt;/cell&gt;&lt;cell&gt;Reading &amp;amp; Comments&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(MN\)&lt;/cell&gt;&lt;cell&gt;The application of the function \(M\) to the argument \(N\). &lt;p&gt;Usually, parentheses are used to separate the function from the argument, like so: ‘\(M(N)\)’. However, in \(\lambda\)-calculus and kindred subjects the parentheses are used as grouping symbols. Thus, it is safe to write the function and the argument adjacent to one other.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(PQR\)&lt;/cell&gt;&lt;cell&gt;The application of the function \(PQ\)—which is itself the application of the function \(P\) to the argument \(Q\)—to \(R\). &lt;p&gt;If we do not use parentheses to separate function and argument, how are we to disambiguate expressions that involve three or more terms, such as ‘\(PQR\)’? Recall our convention that we are to understand such officially illegal expressions by working from left to right, always putting parentheses around adjacent terms. Thus, ‘\(PQR\)’ is to be understood as \((PQ)R\). ‘\(PQRS\)’ is \(((PQ)R)S\). The expression ‘\((PQ)R\)’ is disambiguated; by our convention, it is identical to \(PQR\). The expression ‘\(P(QR)\)’ is also explicitly disambiguated; it is distinct from \(PQR\) because it is the application of \(P\) to the argument \(QR\) (which is itself the application of the function \(Q\) to the argument \(R)\).&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\((\lambda x[M])\)&lt;/cell&gt;&lt;cell&gt;The \(\lambda\) term that binds the variable \(x\) in the \(\boldsymbol{body}\) term \(M\). &lt;p&gt;The official vocabulary of the \(\lambda\)-calculus consists of the symbol ‘\(\lambda\)’, left ‘(’and right ‘)’ parentheses, and a set of variables (assumed to be distinct from the three symbols ‘\(\lambda\)’, ‘(’, and ‘)’ lest we have syntactic chaos).&lt;/p&gt;&lt;p&gt;Alternative notation. It is not necessary to include two kinds of grouping symbols (parentheses and square brackets) in the syntax. Parentheses or square brackets alone would obviously suffice. The two kinds of brackets are employed in this entry for the sake of readability. Given the two kinds of grouping symbols, we could economize further and omit the parentheses from abstraction terms, so that ‘\((\lambda x[M]\))’ would be written as ‘\(\lambda x[M]\)’.&lt;/p&gt;&lt;p&gt;Some authors write ‘\(\lambda x.M\)’ or ‘\(\lambda x\cdot M\)’, with a full stop or a centered dot separating the bound variable from the body of the abstraction term. As with the square brackets, these devices are intended to assist reading \(\lambda\)-terms; they are usually not part of the official syntax. (One sees this device used in earlier works of logic, such as Principia Mathematica, where the function of the symbol . in expressions such as ‘\(\forall x\).\(\phi\)’ is to get us to read the whole of the formula \(\phi\) as under the scope of the \(\forall x\).)&lt;/p&gt;&lt;p&gt;Some authors write abstraction terms without any device separating the bound variable from the body: such terms are crisply written as, e.g., ‘\(\lambda xx\)’, ‘\(\lambda yx\)’. The practice is not without its merits: it is about as concise as one can ask for, and permits an even simpler official syntax of the \(\lambda\)-calculus. But this practice is not flawless. In ‘\(\lambda xyz\)’, is the bound variable \(x\) or is it \(xy\)? Usually the names of variables are single letters, and theoretically this is clearly sufficient. But it seems unduly restrictive to forbid the practice of giving longer names to variables; indeed, such constructions arise naturally in computer programming languages.&lt;/p&gt;&lt;p&gt;For the sake of uniformity, we will adopt the square bracket notation in this entry. (Incidentally, this notation is used in (Turing, 1937).)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(M[x := A]\)&lt;/cell&gt;&lt;cell&gt;The \(\lambda\)-term that is obtained by substituting the \(\lambda\)-term A for all free occurrences of \(x\) inside \(M\). &lt;p&gt;A bewildering array of notations to represent substitution can be found in the literature on \(\lambda\)-calculus and kindred subjects:&lt;/p&gt;\[ M[x/A], M[A/x], M_{x}^A, M_{A}^x, [x/A]M,\ldots \]&lt;p&gt;Which notation to use for substitution seems to be a personal matter. In this entry we use a linear notation, eschewing superscripts and subscripts. The practice of representing substitution with ‘:=’ comes from computer science, where ‘:=’ is read in some programming languages as assigning a value to a variable.&lt;/p&gt;&lt;p&gt;As with the square brackets employed to write abstraction terms, the square brackets employed to write substitution are not officially part of the syntax of the \(\lambda\)-calculus. \(M\) and A are terms, \(x\) is a variable; \(M[x := A]\) is another term.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;\(M \equiv N\)&lt;/cell&gt;&lt;cell&gt;The \(\lambda\)-terms \(M\) and \(N\) are identical: understood as sequences of symbols, \(M\) and \(N\) have the same length and corresponding symbols of the sequences are identical. &lt;p&gt;The syntactic identity relation \(\equiv\) is not part of the official syntax of \(\lambda\)-calculus; this relation between \(\lambda\)-terms belongs to the metatheory of \(\lambda\)-calculus. It is clearly a rather strict notion of equality between \(\lambda\)-terms. Thus, it is not the case (if \(x\) and \(y\) are distinct variables) that \(\lambda x[x] \equiv \lambda y[y]\), even though these two terms clearly ‘behave’ in the same way in the sense that both are expressions of the identity operation \(x \Rightarrow x\). Later we will develop formal theories of equality of \(\lambda\)-terms with the aim of capturing this intuitive equality of \(\lambda x[x]\) and \(\lambda y[y]\).&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head rend="h2"&gt;3. Brief history of \(\lambda\)-calculus&lt;/head&gt;&lt;p&gt;\(\lambda\)-calculus arose from the study of functions as rules. Already the essential ingredients of the subject can be found in Frege’s pioneering work (Frege, 1893). Frege observed, as we did above, that in the study of functions it is sufficient to focus on unary functions (i.e., functions that take exactly one argument). (The procedure of viewing a multiple-arity operation as a sequence of abstractions that yield an equivalent unary operation is called currying the operation. Perhaps it would be more historically accurate to call the operation fregeing, but there are often miscarriages of justice in the appellation of mathematical ideas.) In the 1920s, the mathematician Moses Schönfinkel took the subject further with his study of so-called combinators. As was common in the early days of the subject, Schönfinkel was interested in the kinds of transformations that one sees in formal logic, and his combinators were intended to be a contribution to the foundations of formal logic. By analogy with the reduction that one sees in classical propositional logic with the Sheffer stroke, Schöfinkel established the astonishing result that the all functions (in the sense of all transformations) could be given in terms of the combinators \(\mathbf{K}\) and \(\bS\); later we will see the definition of these combinators.&lt;/p&gt;&lt;p&gt;Theorem For every term \(M\) made up of \(\mathbf{K}\) and \(\bS\) and the variable \(x\), there exists a term \(F\) (built only from \(\mathbf{K}\) and \(\bS)\) such that we can derive \(Fx = M\).&lt;/p&gt;&lt;p&gt;(The proof that these two suffice to represent all functions is beyond the scope of this entry. For further discussion, see the entry on combinatory logic.) One can prove the theorem constructively: there is an algorithm that, given \(M\), produces the required \(F\). Church called this \(F\) ‘\(\lambda x[M]\)’ (Church, 1932).[3] From this perspective, the \(\beta\)-rule can be justified: if ‘\(\lambda x[M]\)’ is to be a function \(F\) satisfying \(Fx = M\), then \(\lambda x[M]\)x should transform to \(M\). This is just a special case of the more general principle that for all \(N, (\lambda x[M])N\) should transform to \(M[x := N]\).&lt;/p&gt;&lt;p&gt;Although today we have more clearly delimited systems of abstraction and rewriting, in its early days \(\lambda\)-calculus and combinatory logic (à la Schönfinkel) were bound up with investigations of foundations of mathematics. In the hands of Curry, Church, Kleene, and Rosser (some of the pioneers in the subject) the focus was on defining mathematical objects and carrying out logical reasoning inside the these new systems. It turned out that these early attempts at so-called illative \(\lambda\)-calculus and combinatory logic were inconsistent. Curry isolated and polished the inconsistency; the result is now known as Curry’s paradox. See the entry on Curry’s paradox and appendix B of (Barendregt, 1985).&lt;/p&gt;&lt;p&gt;The \(\lambda\)-calculus earns a special place in the history of logic because it was the source of the first undecidable problem. The problem is: given \(\lambda\)-terms \(M\) and \(N\), determine whether \(M = N\). (A theory of equational reasoning about \(\lambda\)-terms has not yet been defined; the definition will come later.) This problem was shown to be undecidable.&lt;/p&gt;&lt;p&gt;Another early problem in the \(\lambda\)-calculus was whether it is consistent at all. In this context, inconsistency means that all terms are equal: one can reduce any \(\lambda\)-term \(M\) to any other \(\lambda\)-term \(N\). That this is not the case is an early result of \(\lambda\)-calculus. Initially one had results showing that certain terms were not interconvertible (e.g., \(\mathbf{K}\) and \(\bS)\); later, a much more powerful result, the so-called Church-Rosser theorem, helped shed more light on \(\beta\)-conversion and could be used to give quick proofs of the non-inter-convertibility of whole classes of \(\lambda\)-terms. See below for more detailed discussion of consistency.&lt;/p&gt;&lt;p&gt;The \(\lambda\)-calculus was a somewhat obscure formalism until the 1960s, when, at last, a ‘mathematical’ semantics was found. Its relation to programming languages was also clarified. Till then the only models of \(\lambda\)-calculus were ‘syntactic’, that is, were generated in the style of Henkin and consisted of equivalence classes of \(\lambda\)-terms (for suitable notions of equivalence). Applications in the semantics of natural language, thanks to developments by Montague and other linguists, helped to ‘spread the word’ about the subject. Since then the \(\lambda\)-calculus enjoys a respectable place in mathematical logic, computer science, linguistics (see, e.g., Heim and Kratzer 1998), and kindred fields.&lt;/p&gt;&lt;head rend="h2"&gt;4. Reduction&lt;/head&gt;&lt;p&gt;Various notions of reduction for \(\lambda\)-terms are available, but the principal one is \(\beta\)-reduction, which we have already seen earlier. Earlier we used the notation ‘\(\rhd\)’; we can be more precise. In this section we discuss \(\beta\)-reduction and some extensions.&lt;/p&gt;&lt;p&gt;Definition (one-step \(\beta\)-reduction \(\rhd_{\beta ,1})\) For \(\lambda\)-terms \(A\) and \(B\), we say that \(A\) \(\beta\)-reduces in one step to \(B\), written \(A \rhd_{\beta ,1} B\), just in case there exists an (occurrence of a) subterm \(C\) of \(A\), a variable \(x\), and \(\lambda\)-terms \(M\) and \(N\) such that \(C \equiv(\lambda x[M])N\) and \(B\) is \(A\) except that the occurrence of \(C\) in \(A\) is replaced by \(M[x := N]\).&lt;/p&gt;&lt;p&gt;Here are some examples of \(\beta\)-reduction:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;The variable \(x\) does not \(\beta\)-reduce to anything. (It does not have the right shape: it is simply a variable, not an application term whose left-hand side is an abstraction term.)&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;\((\lambda x[x])a \rhd_{\beta ,1} a\).&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;If \(x\) and \(y\) are distinct variables, then \((\lambda x[y])a \rhd_{\beta ,1} y\).&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The \(\lambda\)-term \((\lambda x[(\lambda y[xy])a])b]\) \(\beta\)-reduces in one step to two different \(\lambda\)-terms:&lt;/p&gt;\[ (\lambda x[(\lambda y[xy])a])b \rhd_{\beta ,1} (\lambda y[by])a \]&lt;p&gt;and&lt;/p&gt;\[ (\lambda x[(\lambda y[xy])a])b \rhd_{\beta ,1} (\lambda x[xa])b \]&lt;p&gt;Moreover, one can check that these two terms \(\beta\)-reduce in one step to a common term: \(ba\). We thus have:&lt;/p&gt;&lt;td&gt;\((\lambda y[by])a\)&lt;/td&gt;&lt;td&gt;\(\nearrow\)&lt;/td&gt;&lt;td&gt;\(\searrow\)&lt;/td&gt;&lt;td&gt;\((\lambda x[(\lambda y[xy])a])b\)&lt;/td&gt;&lt;td&gt;\(ba\)&lt;/td&gt;&lt;td&gt;\(\searrow\)&lt;/td&gt;&lt;td&gt;\(\nearrow\)&lt;/td&gt;&lt;td&gt;\((\lambda x[xa])b\)&lt;/td&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;As with any binary relation, one can ask many questions about the relation \(\rhd_{\beta ,1}\) holding between \(\lambda\)-terms, and one can define various derived notions in terms of \(\rhd_{\beta ,1}\).&lt;/p&gt;&lt;p&gt;Definition A \(\beta\)-reduction sequence from a \(\lambda\)-term \(A\) to a \(\lambda\)-term \(B\) is a finite sequence \(s_1 , \ldots s_n\) of \(\lambda\)-terms starting with \(A\), ending with \(B\), and whose adjacent terms \((s_k,s_{k+1})\) satisfy the property that \(s_k \rhd_{\beta ,1} s_{k+1}\).&lt;/p&gt;&lt;p&gt;More generally, any sequence \(s\)—finite or infinite—starting with a \(\lambda\)-term \(A\) is said to be a \(\beta\)-reduction sequence commencing with \(A\) provided that the adjacent terms \((s_k,s_{k+1})\) of \(s\) satisfy the property that \(s_k \rhd_{\beta ,1} s_{k+1}\).&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;Continuing with \(\beta\)-reduction Example 1, there are no \(\beta\)-reduction sequences at all commencing with the variable \(x\).&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Continuing with \(\beta\)-reduction Example 2, the two-term sequence&lt;/p&gt;\[ (\lambda x[x])a, a \]&lt;p&gt;is a \(\beta\)-reduction sequence from \((\lambda x[x])a\) to \(a\). If \(a\) is a variable, then this \(\beta\)-reduction sequence cannot be prolonged, and there are no other \(\beta\)-reduction sequences commencing with \((\lambda x[x])a\); thus, the set of \(\beta\)-reduction sequences commencing with \((\lambda x[x])a\) is finite and contains no infinite sequences.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;The combinator \(\boldsymbol{\Omega}\) has the curious property that \(\Omega \rhd_{\beta ,1} \Omega\). Every term of every \(\beta\)-reduction sequence commencing with \(\boldsymbol{\Omega}\) (finite or infinite) is equal to \(\boldsymbol{\Omega}\).&lt;/item&gt;&lt;item&gt;&lt;p&gt;Consider the term \(\mathbf{K}a\boldsymbol{\Omega}\). There are infinitely many reduction sequences commencing with this term:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;\(\bK a\boldsymbol{\Omega} \rhd_{\beta ,1} a\)&lt;/item&gt;&lt;item&gt;\(\bK a\boldsymbol{\Omega} \rhd_{\beta ,1} \bK a\boldsymbol{\Omega} \rhd_{\beta ,1} a\)&lt;/item&gt;&lt;item&gt;\(\bK a\boldsymbol{\Omega} \rhd_{\beta ,1} \bK a\boldsymbol{\Omega} \rhd_{\beta ,1} \bK a\boldsymbol{\Omega} \rhd_{\beta ,1} a\)&lt;/item&gt;&lt;item&gt;\(\bK a\boldsymbol{\Omega} \rhd_{\beta ,1} \bK a\boldsymbol{\Omega} \rhd_{\beta ,1} \bK a\boldsymbol{\Omega} \ldots\)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;If \(a\) is a variable, one can see that all finite reduction sequences commencing with \(\bK a\boldsymbol{\Omega}\) end at \(a\), and there is exactly one infinite reduction sequence.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Definition A \(\beta\)-redex of a \(\lambda\)-term \(M\) is (an occurrence of) a subterm of \(M\) of the form \((\lambda x[P])Q\). (‘redex’ comes from ‘reducible expression.) A \(\beta\)-redex is simply a candidate for an application of \(\beta\)-reduction. Doing so, one contracts the \(\beta\)-redex. A term is said to be in \(\beta\)-normal form if it has no \(\beta\)-redexes.&lt;/p&gt;&lt;p&gt;(Can a term have multiple \(\beta\)-normal forms? The answer is literally ‘yes’, but substantially the answer is ‘no’: If a \(M\) and \(M'\) are \(\beta\)-normal forms of some term, then \(M\) is \(\alpha\)-convertible to \(M'\) Thus, \(\beta\)-normal forms are unique up to changes of bound variables.)&lt;/p&gt;&lt;p&gt;So far we have focused only on one step of \(\beta\)-reduction. One can combine multiple \(\beta\)-reduction steps into one by taking the transitive closure of the relation \(\rhd_{\beta ,1}\).&lt;/p&gt;&lt;p&gt;Definition For \(\lambda\)-terms \(A\) and \(B\), one says that \(A\) \(\beta\)-reduces to \(B\), written \(A \rhd_{\beta} B\), if either \(A \equiv B\) or there exists a finite \(\beta\)-reduction sequence from \(A\) to \(B\).&lt;/p&gt;&lt;p&gt;Definition A term \(M\) has a \(\beta\)-normal form if there exists a term \(N\) such that \(N\) is in \(\beta\)-normal form an \(M \rhd_{\beta} N\).&lt;/p&gt;&lt;p&gt;Reducibility as defined is a one-way relation: it is generally not true that if \(A \rhd_{\beta} B\), then \(B \rhd_{\beta} A\). However, depending on one’s purposes, one may wish to treat \(A\) and \(B\) as equivalent if either \(A\) reduces to \(B\) or \(B\) reduces to \(A\). Doing so amounts to considering the reflexive, symmetric, and transitive closure of the relation \(\rhd_{\beta ,1,}\).&lt;/p&gt;&lt;p&gt;Definition For \(\lambda\)-terms \(A\) and \(B\), we say that \(A =_{\beta} B\) if either \(A \equiv B\) or there exists a sequence \(s_1 , \ldots s_n\) starting with \(A\), ending with \(B\), and whose adjacent terms \((s_k,s_{k+1})\) are such that either \(s_k \rhd_{\beta ,1} s_{k+1}\) or \(s_{k+1} \rhd_{\beta ,1} s_k\).&lt;/p&gt;&lt;head rend="h3"&gt;4.1 Other notions of reduction&lt;/head&gt;&lt;p&gt;We have thus far developed the theory of \(\beta\)-reduction. This is by no means the only notion of reduction available in the \(\lambda\)-calculus. In addition to \(\beta\)-reduction, a standard relation between \(\lambda\)-terms is that of \(\eta\)-reduction:&lt;/p&gt;&lt;p&gt;Definition (one-step \(\eta\)-reduction) For \(\lambda\)-terms \(A\) and \(B\), we say that \(A\) \(\beta \eta\)-reduces in one step to \(B\), written \(A \rhd_{\beta \eta ,1} B\), just in case there exists an (occurrence of a) subterm \(C\) of \(A\), a variable \(x\), and \(\lambda\)-terms \(M\) and \(N\) such that either&lt;/p&gt;&lt;p&gt;\(C \equiv(\lambda x[M])N\) and \(B\) is \(A\) except that the occurrence of \(C\) in \(A\) is replaced by \(M[x := N]\)&lt;/p&gt;&lt;p&gt;or&lt;/p&gt;&lt;p&gt;\(C \equiv(\lambda x[Mx]\)) and \(B\) is \(A\) except that the occurrence of \(C\) in \(A\) is replaced by \(M\).&lt;/p&gt;&lt;p&gt;The first clause in the definition of \(\rhd_{\beta \eta ,1}\) ensures that the relation extends the relation of one-step \(\beta\)-reduction. As we did for the relation of one-step \(\beta\)-reduction, we can replay the development for \(\eta\)-reduction. Thus, one has the notion of an \(\eta\)-redex, and from \(\rhd_{\eta ,1}\) one can define the relation \(\rhd_{\eta}\) between \(\lambda\)-terms as the reflexive and transitive closure of \(\rhd_{\eta ,1}\), which captures zero-or-more-steps of \(\eta\)-reduction. Then one defines \(=_{\eta}\) as the symmetric and transitive closure of \(\rhd_{\eta}\).&lt;/p&gt;&lt;p&gt;If \(A \rhd_{\eta ,1} B\), then the length of \(B\) is strictly smaller than that of \(A\). Thus, there can be no infinite \(\eta\)-reductions. This is not the case of \(\beta\)-reduction, as we saw above in \(\beta\)-reduction sequence examples 3 and 4.&lt;/p&gt;&lt;p&gt;One can combine notions of reduction. One useful combination is to blend \(\beta\)- and \(\eta\)-reduction.&lt;/p&gt;&lt;p&gt;Definition (one-step \(\beta \eta\)-reduction) \(\lambda x[Mx] \rhd_{\beta \eta ,1} M\) and \((\lambda x[M]N)) \rhd_{\beta \eta ,1} M[x := N]\). A \(\lambda\)-term \(A\) \(\beta \eta\)-reduces in one step to a \(\lambda\)-term \(B\) just in case either \(A\) \(\beta\)-reduces to \(B\) in one step or \(A\) \(\eta\)-reduces to \(B\) in one step.&lt;/p&gt;&lt;p&gt;Again, one can replay the basic concepts of reduction, as we did for \(\beta\)-reduction, for this new notion of reduction \(\beta \eta\).&lt;/p&gt;&lt;head rend="h3"&gt;4.2 Reduction strategies&lt;/head&gt;&lt;p&gt;Recall that a term is said to be in \(\beta\)-normal form if it has no \(\beta\)-redexes, that is, subterms of the shape \((\lambda x[M]\))N. A term has a \(\beta\)-normal form if it can be reduced to a term in \(\beta\)-normal form. It should be intuitively clear that if a term has a \(\beta\)-normal form, then we can find one by exhaustively contracting all all \(\beta\)-redexes of the term, then exhaustively contracting all \(\beta\)-redexes of all resulting terms, and so forth. To say that a term has a \(\beta\)-normal form amounts to saying that this blind search for one will eventually terminate.&lt;/p&gt;&lt;p&gt;Blind search for \(\beta\)-normal forms is not satisfactory. In addition to be aesthetically unpleasant, it can be quite inefficient: there may not be any need to exhaustively contract all \(\beta\)-redexes. What is wanted is a strategy—preferably, a computable one—for finding a \(\beta\)-normal form. The problem is to effectively decide, if there are multiple \(\beta\)-redexes of a term, which ought to be reduced.&lt;/p&gt;&lt;p&gt;Definition A \(\beta\)-reduction strategy is a function whose domain is the set of all \(\lambda\)-terms and whose value on a term \(M\) not in \(\beta\)-normal form is a redex subterm of \(M\), and whose value on all terms M in \(\beta\)-normal form is simply \(M\).&lt;/p&gt;&lt;p&gt;In other words, a \(\beta\)-reduction strategy selects, whenever a term has multiple \(\beta\)-redexes, which one should be contracted. (If a term is in \(\beta\)-normal form, then nothing is to be done, which is why we require in the definition of \(\beta\)-reduction strategy that it does not change any term in \(\beta\)-normal form.) One can represent a strategy \(S\) as a relation \(\rhd_S\) on \(\lambda\)-terms, with the understanding that \(M \rhd_S N\) provided that \(N\) is obtained from \(M\) in one step by adhering to the strategy S. When viewed as relations, strategies constitute a subrelation of \(\rhd_{\beta ,1}\).&lt;/p&gt;&lt;p&gt;A \(\beta\)-reduction strategy may or may not have the property that adhering to the strategy will ensure that we (eventually) reach a \(\beta\)-normal form, if one exists.&lt;/p&gt;&lt;p&gt;Definition A \(\beta\)-reduction strategy \(S\) is normalizing if for all \(\lambda\)-terms \(M\), if \(M\) has a \(\beta\)-normal form \(N\), then the sequence \(M, S(M), S(S(M)),\ldots\) terminates at \(N\).&lt;/p&gt;&lt;p&gt;Some \(\beta\)-reduction strategies are normalizing, but others are not.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;The rightmost strategy, whereby we always choose to reduce the rightmost \(\beta\)-redex (if there are any \(\beta\)-redexes) is not normalizing. Consider, for example, the term KI\(\Omega\). This term has two \(\beta\)-redexes: itself, and \(\Omega\) (which, recall, is the term \(\omega\omega\equiv(\lambda\)x[\(xx])(\lambda\)x[\(xx]\))). By working with left-hand \(\beta\)-redexes, we can \(\beta\)-reduce KI\(\Omega\) to \(\mathbf{I}\) in two steps. If we insist on working with the rightmost \(\beta\)-redex \(\Omega\) we reduce KI(\(\Omega\)) to \(\mathbf{KI}\)(\(\Omega \)), then \(\mathbf{KI}\)(\(\Omega\)), ….&lt;/item&gt;&lt;item&gt;The leftmost strategy, whereby we always choose to reduce the leftmost \(\beta\)-redex (if there are any \(\beta\)-redexes) is normalizing. The proof of this fact is beyond the scope of this entry; see (Barendregt, 1985, section 13.2) for details.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Once we have defined a reduction strategy, it is natural to ask whether one can improve it. If a term has a \(\beta\)-normal form, then a strategy will discover a normal form; but might there be a shorter \(\beta\)-reduction sequence that reaches the same normal form (or a term that is \(\alpha\)-convertible to that normal form)? This is the question of optimality. Defining optimal strategies and showing that they are optimal is generally considerably more difficult than simply defining a strategy. For more discussion, see (Barendregt, 1984 chapter 10).&lt;/p&gt;&lt;p&gt;For the sake of concreteness, we have discussed only \(\beta\)-reduction strategies. But in the definitions above the notion of reduction \(\beta\) is but one possibility. For any notion \(R\) of reduction we have the associated theory of \(R\)-reduction strategies, and one can replay the problems of normalizability, optimality, etc., for \(R\).&lt;/p&gt;&lt;head rend="h2"&gt;5. \(\lambda\)-theories&lt;/head&gt;&lt;p&gt;We discussed earlier how the \(\lambda\)-calculus is a non-extensional theory of functions. If, in the non-extensional spirit, we understand \(\lambda\)-terms as descriptions, how should we treat equality of \(\lambda\)-terms? Various approaches are available. In this section, let us treat the equality relation = as a primitive, undefined relation holding between two \(\lambda\)-terms, and try to axiomatize the properties that equality should have. The task is to identity axioms and formulate suitable rules of inference concerning the equality of \(\lambda\)-terms.&lt;/p&gt;&lt;p&gt;Some obvious properties of equality, having nothing to do with \(\lambda\)-calculus, are as follows:&lt;/p&gt;\[\tag{Reflexivity} \frac{}{X=X} \] \[\tag{Symmetry} \frac{X=Y}{Y=X} \] \[\tag{Transitivity} \frac{X=Y \quad Y=Z}{X=Z} \]&lt;p&gt;As is standard in proof theory, the way to read these rules of inference is that above the horizontal rule \(\frac{}{\phantom{X=X}}\) are the premises of the rule (which are equations) and the equation below the horizontal rule is the conclusion of the rule of inference. In the case of the reflexivity rule, nothing is written above the horizontal rule. We understand such a case as saying that, for all terms \(X\), we may infer the equation \(X = X\) from no premises.&lt;/p&gt;&lt;head rend="h3"&gt;5.1 The basic theory \(\lambda\)&lt;/head&gt;&lt;p&gt;The three rules of inference listed in the previous section governing equality have nothing to do with the \(\lambda\)-calculus. The following lists rules of inference that relate the undefined notion of equality and the two term-building operations of the \(\lambda\)-calculus, application and abstraction.&lt;/p&gt;\[ \frac{M=N}{AM=AN} \quad \frac{M=N}{MA=NA} \] \[ \tag{\(\boldsymbol{\xi}\)} \frac{M=N}{\lambda x[M] = \lambda x[N]} \]&lt;p&gt;Together, these rules of inference say that = is a congruence relation on the set of \(\lambda\)-terms: it ‘preserves’ both the application and abstraction term-building operations&lt;/p&gt;&lt;p&gt;The final rule of inference, \(\beta\)-conversion, is the most important:&lt;/p&gt;\[\tag{\(\boldsymbol{\beta}\)} \frac{}{(\lambda x[M])A = M[x := A]} \]&lt;p&gt;As before with the reflexivity rule, the rule \(\boldsymbol{\beta}\) has no premises: for any variable \(x\) and any terms \(M\) and \(A\), one can infer the equation \((\lambda x[M])A = M[x := A]\) at any point in a formal derivation in the theory \(\boldsymbol{\lambda}\).&lt;/p&gt;&lt;head rend="h3"&gt;5.2 Extending the basic theory \(\lambda\)&lt;/head&gt;&lt;p&gt;A number of extensions to \(\boldsymbol{\lambda}\) are available. Consider, for example, the rule (\(\boldsymbol{\eta}\)), which expresses the principle of \(\eta\)-reduction as a rule of inference:&lt;/p&gt;\[\tag{\(\boldsymbol{\eta}\)} \frac{}{\lambda x[Mx] = M} \text{ provided } x \not\in \mathbf{FV}(M) \]&lt;p&gt;Rule \(\boldsymbol{\eta}\) tells us that a certain kind of abstraction is otiose: it is safe to identify \(M\) with the function that, given an argument \(x\), applies \(M\) to \(x\). Through this rule we can also see that all terms are effectively functions. One can intuitively justify this rule using the principle of \(\beta\)-reduction.&lt;/p&gt;\[\tag{\(\mathbf{Ext}\)} \frac{Mx=Nx}{M=N}\text{ provided } x \not\in \mathbf{FV}(M) \cup \mathbf{FV}(N) \]&lt;p&gt;One can view rule \(\mathbf{Ext}\) as a kind of generalization principle. If we have derived that \(Mx = Nx\), but \(x\) figures in neither \(M\) nor \(N\), then we have effectively shown that \(M\) and \(N\) are alike. Compare this principle to the principle of universal generalization in first-order logic: if we have derived \(\phi(x)\) from a set \(\Gamma\) of hypotheses in which \(x\) is not free, then we can conclude that \(\Gamma\) derives \(\forall x\phi\).&lt;/p&gt;&lt;p&gt;Another productive principle in the \(\lambda\)-calculus permits us to identify terms that ‘act’ the same:&lt;/p&gt;\[\tag{\(\boldsymbol{\omega}\)} \frac{\text{For all terms }x, Mx=Nx}{M=N} \]&lt;p&gt;The rule \(\boldsymbol{\omega}\) has infinitely many hypotheses: on the assumption that \(Mx = Nx\), no matter what \(x\) may be, then we can conclude that \(M = N\). The \(\boldsymbol{\omega}\) rule is an analogue in the \(\lambda\)-calculus of the rule of inference under the same name in formal number theory, according to which one can conclude the universal formula \(\forall x\phi\) provided one has proofs for \(\phi(x := \mathbf{0}), \phi(x := \mathbf{1}),\ldots\) . Note that unlike the rule \(\mathbf{Ext}\), the condition that \(x\) not occur freely in \(M\) or \(N\) does not arise.&lt;/p&gt;&lt;head rend="h2"&gt;6. Consistency of the \(\lambda\)-calculus&lt;/head&gt;&lt;p&gt;Is the \(\lambda\)-calculus consistent? The question might not be well-posed. The \(\lambda\)-calculus is not a logic for reasoning about propositions; there is no apparent notion of contradiction \((\bot)\) or a method of forming absurd propositions (e.g., \(p \wedge \neg p)\). Thus ‘inconsistency’ of the \(\lambda\)-calculus cannot mean that \(\bot\), or some formula tantamount to \(\bot\), is derivable. A suitable notion of ‘consistent’ is, however, available. Intuitively, a logic is inconsistent if it permits us to derive too much. The theory \(\lambda\) is a theory of equations. We can thus take inconsistency of \(\lambda\) to mean: all equations are derivable. Such a property, if it were true of \(\lambda\), would clearly show that \(\lambda\) is of little use as a formal theory.&lt;/p&gt;&lt;p&gt;Early formulations of the idea of \(\lambda\)-calculus by A. Church were indeed inconsistent; see (Barendregt, 1985, appendix 2) or (Rosser, 1985) for a discussion. To take a concrete problem: how do we know that the equation \(\bK = \mathbf{I}\) is not a theorem of \(\lambda\)? The two terms are obviously intuitively distinct. \(\bK\) is a function of two arguments, whereas \(\mathbf{I}\) is a function of one argument. If we could show that \(\bK = \mathbf{I}\), then we could show that \(\mathbf{KK} = \mathbf{IK}\), whence \(\mathbf{KK} = \bK\) would be a theorem of \(\lambda\), along with many other equations that strike us as intuitively unacceptable. But when we’re investigating a formal theory such as \(\lambda\), intuitive unacceptability by no means implies underivability. What is missing is a deeper understanding of \(\beta\)-reduction.&lt;/p&gt;&lt;p&gt;An early result that gave such an understanding is known as the Church-Rosser theorem:&lt;/p&gt;&lt;p&gt;Theorem (Church-Rosser) If \(P \rhd_{\beta} Q\) and \(P \rhd_{\beta}\) R, then there exists a term \(S\) such that both \(Q \rhd_{\beta} S\) and \(R \rhd_{\beta} S\).&lt;/p&gt;&lt;p&gt;(The proof of this theorem is quite non-trivial and is well-beyond the scope of this entry.) The result is a deep fact about \(\beta\)-reduction. It says that no matter how we diverge from \(P\) by \(\beta\)-reductions, we can always converge again to a common term.&lt;/p&gt;&lt;p&gt;The Church-Rosser theorem gives us, among other things, that the plain \(\lambda\)-calculus—that is, the theory \(\lambda\) of equations between \(\lambda\)-terms—is consistent, in the sense that not all equations are derivable.&lt;/p&gt;&lt;p&gt;As an illustration, we can use the Church-Rosser theorem to solve the earlier problem of showing that the two terms \(\bK\) and \(\mathbf{I}\) are not identified by \(\lambda\). The two terms are in \(\beta\)-normal form, so from them there are no \(\beta\)-reduction sequences at all. If \(\bK = \mathbf{I}\) were a theorem of \(\lambda\), then there would be a term \(M\) from which there is a \(\beta\)-reduction path to both \(\mathbf{I}\) and \(\bK\). The Church-Rosser theorem then implies the two paths diverging from \(M\) can be merged. But this is impossible, since \(\bK\) and \(\mathbf{I}\) are distinct \(\beta\)-normal forms.&lt;/p&gt;&lt;p&gt;The Church-Rosser theorem implies the existence of \(\beta\)-reduction sequences commencing from \(\bK\) and from \(\mathbf{I}\) that end at a common term. But there are no \(\beta\)-reduction sequences at all commencing from \(\mathbf{I}\), because it is in \(\beta\)-normal form, and likewise for \(\bK\).&lt;/p&gt;&lt;p&gt;Theorem \(\lambda\) is consistent, in the sense that not every equation is a theorem.&lt;/p&gt;&lt;p&gt;To prove the theorem, it is sufficient to produce one underivable equation. We have already worked through an example: we used the Church-Rosser theorem to show that the equation \(\bK = \mathbf{I}\) is not a theorem of \(\lambda\). Of course, there’s nothing special about these two terms. A significant generalization of this result is available: if \(M\) and \(N\) in \(\beta\)-normal form but \(M\) is distinct from \(N\), then the equation \(M = N\) is not a theorem of \(\lambda\). (This simple condition for underivability does not generally hold if we add additional rules of inference to \(\lambda\).)&lt;/p&gt;&lt;p&gt;The theories \(\lambda \eta\) and \(\lambda \omega\) are likewise consistent. One can prove these consistency results along the lines of the consistency proof for \(\lambda\) by extending the Church-Rosser theorem to the wider senses of derivability of these theories.&lt;/p&gt;&lt;head rend="h2"&gt;7. Semantics of \(\lambda\)-calculus&lt;/head&gt;&lt;p&gt;As we’ve said at the outset, the \(\lambda\)-calculus is, at heart, about functions and their applications. But it is surprisingly difficult to cash this idea out in semantic terms. A natural approach would be to try to associate with every \(\lambda\)-term \(M\) a function \(f_M\) over some domain \(D\) and to interpret application terms \((MN)\) using function application as \(f_M(f_N).\) But this idea quickly runs into difficulties. To begin with, it’s easy to see that, in this context, we can’t use the standard set-theoretic concept of functions-as-sets (see section 1.2 of this entry). According to this concept, remember, a function \(f\) is a set of argument-value pairs, where every argument gets assigned a unique value. The problem arises in the context of self-applications. Remember from section 2.1 that the untyped \(\lambda\)-calculus allows \(\lambda\)-terms such as \((xx)\), which intuitively apply \(x\) to itself. On the semantic picture we’re exploring, we can obtain the associated function \(f_{(xx)}\) for the term \((xx)\) by taking the function \(f_x\) for \(x\) and applying it to itself:&lt;/p&gt;\[ f_{(xx)}=f_x(f_x) \]&lt;p&gt;But following functions-as-sets, this would mean that the set \(f_x\) needs to contain an argument-value pair that has \(f_x\) as its first component and \(f_{(xx)}\) as the second:&lt;/p&gt;\[ f_{x}=\{\ldots, (f_{x},f_{(xx)})), \ldots\} \]&lt;p&gt;But this would make \(f_x\) a non-well-founded object: defining \(f_x\) would involve \(f_x\) itself. In fact, sets like this are excluded in standard axiomatic set theory by the axiom of foundation (also known as the axiom of regularity). —This is further semantic evidence that the concept of a function underlying the \(\lambda\)-calculus can’t be the extensional functions-as-sets concept.&lt;/p&gt;&lt;p&gt;But the problem runs even deeper than that. Even when we use a non-extensional notion of a function, such as the functions-as-rules conception (see again section 1.2), we run into difficulties. In the untyped \(\lambda\)-calculus, everything can both be function and an argument to functions. Correspondingly, we should want our domain \(D\) to include, in some sense, the function space \(D^D\), which contains all and only the functions with both arguments and values from \(D\). To see this:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Every element of \(D\) can be a function that applies to elements of \(D\), and what’s returned can then be again be an argument for elements of \(D\). So, every element of \(D\) intuitively corresponds to a member of \(D^D\).&lt;/item&gt;&lt;item&gt;If, in turn, we take a member of \(D^D\), i.e., a function with arguments and values from \(D\), this is precisely the kind of thing we want to include in our domain \(D\). So, intuitively, we want every member of \(D^D\) to correspond to a member of \(D\).&lt;/item&gt;&lt;/list&gt;&lt;p&gt;In short, we want there to be a one-to-one correspondence between our domain and its own function space, i.e., we want them to satisfy the ‘equation’ \(X\cong X^X\). But this is impossible since it contradicts Cantor’s theorem.&lt;/p&gt;&lt;p&gt;Given these difficulties, the question arises whether it’s possible to give a set-theoretic model for the \(\lambda\)-calculus in the first place? It turns out that it is. D. Scott was the first to describe such a model in an unpublished manuscript from 1969. This model, \(D_\infty\), solves the aforementioned problems with Cantor’s theorem by suitably restricting the function space \(D^D\), by only letting some members of \(D^D\) correspond to members of \(D\). Covering Scott’s construction goes beyond the scope of this entry, since it involves advanced tools from algebra and topology; see (Meyer 1982), (Barendregt, 1985, chapter 18.2), or (Hindley and Seldin, 2008, chapter 16) for details. Instead, we’ll discuss the more general question: What is a model for the \(\lambda\)-calculus? That is, leaving aside for a moment the question whether sets are functions, rules, or something altogether different, we ask what kind of mathematical structure a model for the \(\lambda\)-calculus is in the first place.&lt;/p&gt;&lt;head rend="h3"&gt;7.1 \(\lambda\)-Models&lt;/head&gt;&lt;p&gt;It turns out that there are multiple, essentially equivalent, ways of defining the notion of a model for the \(\lambda\)-calculus; see (Barendregt, 1985, chapter 5) or (Hindley and Seldin, 2008, chapter 15). In the following, we’ll discuss what we consider the most palatable notion for philosophers familiar with the standard semantics for first-order logic (see, e.g., the entry on Classical Logic ), the so-called syntactical \(\lambda\)-models. These models first appear in the work of (Hindley and Longo, 1980), (Koymans, 1982), and (Meyer 1982). They derive their name from the fact that their clauses closely correspond to the syntactic rules of the calculus \(\boldsymbol{\lambda}\). This is somewhat unsatisfactory and motivates ‘syntax-free’ definitions (see below). At the same time, the syntactical \(\lambda\)-models provide a fairly transparent and accessible route into the world of \(\lambda\)-models. In addition, despite their conceptual shortcomings, syntactical models have proven a technically useful tool in the semantical study of the \(\lambda\)-calculus.&lt;/p&gt;&lt;p&gt;In order to avoid the set-theoretic problems mentioned above, most definitions of \(\lambda\)-models use so-called applicative structures. The idea is to treat the denotations of \(\lambda\)-terms not as set-theoretic functions, but as unanalyzed, first-order ‘function-objects’, instead. Correspondingly, then, we treat function application as an unanalyzed binary operation on these function-objects:&lt;/p&gt;&lt;p&gt;Definition An applicative structure is a pair \((D,\cdot)\), where \(D\) is some set and \(\cdot\) a binary operation on \(D\). To avoid trivial models, we usually assume that \(D\) has at least two elements.&lt;/p&gt;&lt;p&gt;Applicative structures are, in a sense, first-order models of function spaces that satisfy the problematic equation \(X\cong X^X\). \(\lambda\)-models, in turn, are defined over them.&lt;/p&gt;&lt;p&gt;For the definition of our \(\lambda\)-models, we work with valuations—a concept familiar from first-order semantics. Valuations assign denotations to the variables and are used primarily in the semantic clauses for the \(\lambda\)-operator. Additionally, they can be used to express general claims over the domain, in a way that is familiar from the semantics for the first-order quantifiers \(\exists x\) and \(\forall x\).&lt;/p&gt;&lt;p&gt;Definition A valuation in an applicative structure \((D,\cdot)\) is a function \(\rho\) that assigns an element \(\rho(x)\in D\) to every variable \(x\).&lt;/p&gt;&lt;p&gt;As a useful piece of notation, for \(\rho\) a valuation in some applicative structure \((D,\cdot)\), \(x\) a variable, and \(d\in D\) an object, we define the valuation \(\rho[x\mapsto d]\) by saying that: \[\rho[x\mapsto d](y)=\begin{cases} d &amp;amp; \text{ if }y=x\\ \rho(y) &amp;amp; \text{otherwise}\end{cases}\] That is, \(\rho[x\mapsto d]\) is the result of changing the value of \(x\) to be \(d\), while leaving all other other values under \(\rho\) unchanged.&lt;/p&gt;&lt;p&gt;Definition A syntactical \(\lambda\)-model is a triple \(\mathfrak{M}=(D,\cdot,\llbracket \ \rrbracket)\), where \((D,\cdot)\) is an applicative structure and \(\llbracket \ \rrbracket\) is a function that assigns to every \(\lambda\)-term M and valuation \(\rho\) a denotation \(\llbracket M\rrbracket_\rho\in D\) subject to the following constraints:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;\(\llbracket x\rrbracket_\rho=\rho(x)\)&lt;/item&gt;&lt;item&gt;\(\llbracket MN\rrbracket_\rho=\llbracket M\rrbracket_\rho\cdot \llbracket N\rrbracket_\rho\)&lt;/item&gt;&lt;item&gt;\(\llbracket \lambda xM\rrbracket_\rho\cdot d=\llbracket M\rrbracket_{\rho[x\mapsto d]}\), for all \(d\in D\)&lt;/item&gt;&lt;item&gt;\(\llbracket \lambda xM\rrbracket_\rho = \llbracket \lambda xN\rrbracket_\rho\), whenever for all \(d\in D\), we have \(\llbracket M\rrbracket_{\rho[x\mapsto d]}=\llbracket N\rrbracket_{\rho[x\mapsto d]}\)&lt;/item&gt;&lt;item&gt;\(\llbracket M\rrbracket_\rho=\llbracket M\rrbracket_\sigma\), whenever \(\rho(x)=\sigma(x)\) for all \(x\in \mathbf{FV}(M)\)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Intuitively, in a model \(\mathfrak{M}\), \(\llbracket M\rrbracket_\rho\) is the function-object denoted by the \(\lambda\)-term \(M\) under the valuation \(\rho\).&lt;/p&gt;&lt;p&gt;It is now straight-forward to define what it means for a \(\lambda\)-model \(\mathfrak{M}\) to satisfy an equation \(M=N\), symbolically \(\mathfrak{M}\vDash M=N\):&lt;/p&gt;&lt;p&gt;Definition (satisfaction).&lt;/p&gt;\[\mathfrak{M}\vDash M=N\text{ iff for all }\rho\text{, we have } \llbracket M\rrbracket_\rho=\llbracket N\rrbracket_\rho\]&lt;p&gt;In words: an equation \(M=N\) holds in a model \(\mathfrak{M}\) just in case the \(\lambda\)-terms \(M\) and \(N\) have the same denotation under every valuation in the underlying applicative structure.&lt;/p&gt;&lt;p&gt;Note that clauses 3. and 4. from the definition of a syntactical \(\lambda\)-model directly mirror the \(\boldsymbol{\lambda}\)-rules \(\boldsymbol{\beta}\) and \(\boldsymbol{\xi}\), respectively (see section 5.1 above). This is the ‘syntactic’ nature of our models. While this might be semantically unsatisfactory (see below), it makes it relatively straight-forward to prove a soundness theorem for the semantics provided by the syntactical \(\lambda\)-models; see (Barendregt, 1985, Theorem 5.3.4) and (Hindley and Seldin, 2008. Theorem 15.12):&lt;/p&gt;&lt;p&gt;Theorem For all terms \(M,N\), if \(M=N\) is derivable in \(\boldsymbol{\lambda}\), then for all syntactical \(\lambda\)-models \(\mathfrak{M}\), we have that \(\mathfrak{M}\vDash M=N\).&lt;/p&gt;&lt;p&gt;This theorem provides a first ‘sanity-check’ for the semantics. But note that, so far, we haven’t shown that there exist any syntactical \(\lambda\)-models at all.&lt;/p&gt;&lt;p&gt;This worry is addressed by constructing so-called ‘term models’, which are not unlike the well-known Henkin constructions from first-order semantics. In order to define these models, we first need the notion of a \(\boldsymbol{\lambda}\)-equivalence class for a given \(\lambda\)-term \(M\). This class contains precisely the terms that \(\boldsymbol{\lambda}\) proves identical to \(M\):&lt;/p&gt;\[ [M]_{\boldsymbol{\lambda}}=\{N:\boldsymbol{\lambda}\text{ proves }M=N\} \]&lt;p&gt;We then define the term model for \(\boldsymbol{\lambda}\), \(\mathfrak{T}\), by setting:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;\(D=\{[M]_\boldsymbol{\lambda}:M\text{ is a }\lambda\text{-term}\}\)&lt;/item&gt;&lt;item&gt;\([M]_\boldsymbol{\lambda}\cdot [N]_\boldsymbol{\lambda}=[MN]_\boldsymbol{\lambda}\)&lt;/item&gt;&lt;item&gt;\(\llbracket M\rrbracket_\rho=[M[x_1:=N_1]\ldots[x_n:=N_n]]_\boldsymbol{\lambda}\), where \(\mathbf{FV}(M)=\{x_1,\ldots,x_n\}\) and \(\rho(x_1)=N_1, \ldots,\rho(x_n)=N_n\)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;It is easily seen that this indeed defines a syntactical \(\lambda\)-model. In fact, it is easily checked that in the term model for \(\boldsymbol{\lambda}\), we have that:&lt;/p&gt;\[ \mathfrak{T}\vDash M=N\text{ iff }\boldsymbol{\lambda}\text{ derives }M=N. \]&lt;p&gt;This paves a way for a very simple completeness proof for \(\boldsymbol{\lambda}\) with respect to the class of syntactical \(\lambda\)-models; see (Meyer, 1982, 98–99) for one of the few explicit mentions of this kind of result in the literature:&lt;/p&gt;&lt;p&gt;Theorem For all terms \(M,N\), if for all syntactical \(\lambda\)-models \(\mathfrak{M}\), we have that \(\mathfrak{M}\vDash M=N\), then \(M=N\) is derivable in \(\boldsymbol{\lambda}\).&lt;/p&gt;&lt;p&gt;The proof is a simple proof by contraposition, which uses the term model \(\mathfrak{T}\) as a countermodel to any non-derivable identity in \(\boldsymbol{\lambda}\).&lt;/p&gt;&lt;p&gt;But there are reasons to be dissatisfied with the syntactical \(\lambda\)-models as a semantics for the \(\lambda\)-calculus. For one, by virtue of clauses 3. and 4. mirroring rules \(\boldsymbol{\beta}\) and \(\boldsymbol{\xi}\), the soundness result is ‘baked into’ the semantics, as it were. This is unsatisfactory from a semantic perspective since it means that via the syntactical \(\lambda\)-models, we don’t really learn anything directly about what conditions an applicative structure needs to satisfy in order to adequately model the \(\lambda\)-calculus.&lt;/p&gt;&lt;p&gt;A related worry is that the clauses 3. and 4. are not recursive in nature. That is, they don’t allow us to compute the denotation of a complex \(\lambda\)-term from the denotations of its parts and information about the syntactic operation used to combine them. In our syntax (see section 2), there are two ways of constructing complex \(\lambda\)-terms: application terms of the form \(MN\) and abstraction terms of the form \((\lambda x[M])\). Clause 1. of our syntactical \(\lambda\)-models is a recursive clause for the syntactical application operation, but we don’t have a recursive clause for the syntactical operation of \(\lambda\)-abstraction. Clauses 3. and 4. are rather conditions on the denotation function \(\llbracket \ \rrbracket\) than recursive clauses. This is unsatisfactory since it means that we’re not really given a compositional semantics for the \(\lambda\)-operator by the syntactical \(\lambda\)-models.&lt;/p&gt;&lt;p&gt;These worries are taken care of in the development of syntax-free \(\lambda\)-models. A comprehensive discussion of syntax-free models goes beyond the scope of this entry; but see (Barendregt, 1985, chapter 5.2) and (Hinley and Seldin, 2008, chapter 15B) for the details. Suffice it to say that the definition of syntax-free \(\lambda\)-models involves determining precisely under which conditions an applicative structure is suitable for interpreting the \(\lambda\)-calculus. The resulting \(\lambda\)-models, then, indeed provide (something much closer to) a recursive, compositional semantics, where the syntactical operation of \(\lambda\)-abstraction is interepreted by a corresponding semantic operation on applicative structures.&lt;/p&gt;&lt;p&gt;It is worth noting, however, that syntactical \(\lambda\)-models and the syntax-free \(\lambda\)-models are, in a certain sense, equivalent: every syntactical \(\lambda\)-model defines a syntax-free \(\lambda\)-model and vice versa; see (Barendregt, 1985, theorem 5.3.6) and (Hinley and Seldin, 2008, theorem 15.20) for the details. From a technical perspective, this result allows us to freely move between the different presentations of \(\lambda\)-models and to use, in a given context, the notion of a model that is most expedient. At the same time, there may be philosophical reasons to prefer one presentation over the other, such as the semantic worries about syntactical \(\lambda\)-models mentioned above.&lt;/p&gt;&lt;p&gt;Before moving to model constructions, let us briefly mention that there are various ways of approaching \(\lambda\)-models. One particularly interesting approach we’ve neglected so far is from the perspective of category theory and categorical logic. There are well-known model descriptions using so-called ‘Cartesian closed categories’; see (Koymans, 1982). Covering these model descriptions goes beyond the scope of the present entry since it requires a familiarity with a wide range of concepts from category theory; see the entry Category Theory for a sense of the machinery involved. For the details of these model descriptions, instead, (Barendregt, 1985, sections 5.4–6). In recent years, there has been a renewed interest in categorical approaches to the \(\lambda\)-calculus, which have mainly focused on typed versions of the \(\lambda\)-calculus (see sections 8.2 and 9.1.2 below) but also include the untyped \(\lambda\)-calculus discussed in this article. See, for example, (Hyland, 2017) for a recent discussion.&lt;/p&gt;&lt;head rend="h3"&gt;7.2 Model Constructions&lt;/head&gt;&lt;p&gt;The term model we’ve seen in section 7.1 is rather trivial: it directly reflects the syntactic structure of the \(\lambda\)-terms by modeling precisely syntactic equality modulo \(\boldsymbol{\lambda}\)-provable equality. This makes the term model mathematically and philosophically rather uninteresting. The construction and study of more interesting concrete \(\lambda\)-models is one of the principal aims of the model theory for the \(\lambda\)-calculus.&lt;/p&gt;&lt;p&gt;We’ve already mentioned what’s perhaps the most important, but was definitely the first non-trivial model for the \(\lambda\)-calculus: Scott’s \(D_\infty\). But there are also other interesting model constructions, such as Plotkin and Scott’s graph model \(P_\omega\), first described in (Plotkin 1972) and (Scott, 1974). These model constructions, however, usually rely on fairly involved mathematical methods, both for their definitions and for verifying that they are indeed \(\lambda\)-models. Consequently, covering these constructions goes beyond the scope of this entry; see (Hinley and Seldin, 2008, chapter 16F) for an overview of various model constructions and (Barendregt, 1985, chapter 18) for many of the formal details.&lt;/p&gt;&lt;p&gt;One of the advantages of having different models is that one sees different aspects of equality in the \(\lambda\)-calculus: each of the different models takes a different view on what \(\lambda\)-terms get identified. An interesting question in this context is: What is the \(\lambda\)-theory of a given class of models? In this context, we call a class \(\mathcal{C}\) of \(\lambda\)-models complete just in case every (consistent) \(\lambda\)-theory is satisfied by some model in \(\mathcal{C}\). See (Salibra, 2003) for an overview of various completeness and incompleteness results for interesting classes of \(\lambda\)-models.&lt;/p&gt;&lt;head rend="h2"&gt;8. Extensions and Variations&lt;/head&gt;&lt;head rend="h3"&gt;8.1 Combinatory logic&lt;/head&gt;&lt;p&gt;A sister formalism of the \(\lambda\)-calculus, developed slightly earlier, deals with variable-free combinations. Combinatory logic is indeed even simpler than the \(\lambda\)-calculus, since it lacks a notion of variable binding.&lt;/p&gt;&lt;p&gt;The language of combinatory logic is built up from combinators and variables. There is some flexibility in precisely which combinators are chosen as basic, but some standard ones are \(\mathbf{I}, \bK , \bS, \mathbf{B}\) and \(\mathbf{C}\). (The names are not arbitrary.)&lt;/p&gt;&lt;p&gt;As with the \(\lambda\)-calculus, with combinatory logic one is interested in reducibility and provability. The principal reduction relations are:&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell&gt;Combinator&lt;/cell&gt;&lt;cell&gt;Reduction Axiom&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\bI\)&lt;/cell&gt;&lt;cell&gt;\(\bI x = x\)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\bK\)&lt;/cell&gt;&lt;cell&gt;\(\bK xy = x\)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\bS\)&lt;/cell&gt;&lt;cell&gt;\(\bS xyz = xz(yz)\)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\bB\)&lt;/cell&gt;&lt;cell&gt;\(\bB xyz = x(yz)\)&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;\(\bC\)&lt;/cell&gt;&lt;cell&gt;\(\bC xyz = xzy\)&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;There is a passage from \(\lambda\)-calculus to combinatory logic via translation. It turns out that although combinatory logic lacks a notion of abstraction, one can define such a notion and thereby simulate the \(\lambda\)-calculus in combinatory logic. Here is one translation; it is defined recursively.&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell&gt;Rule&lt;/cell&gt;&lt;cell&gt;Expression&lt;/cell&gt;&lt;cell&gt;Translation&lt;/cell&gt;&lt;cell&gt;Condition&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;cell&gt;\(x\)&lt;/cell&gt;&lt;cell&gt;\(x\)&lt;/cell&gt;&lt;cell&gt;(unconditional)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;\(MN\)&lt;/cell&gt;&lt;cell&gt;M\(^*\)N\(^*\)&lt;/cell&gt;&lt;cell&gt;(unconditional)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;3&lt;/cell&gt;&lt;cell&gt;\(\lambda x[M]\)&lt;/cell&gt;&lt;cell&gt;\(\bK\)M&lt;/cell&gt;&lt;cell&gt;\(x\) does not occur freely in M&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;4&lt;/cell&gt;&lt;cell&gt;\(\lambda x[x]\)&lt;/cell&gt;&lt;cell&gt;\(\bI\)&lt;/cell&gt;&lt;cell&gt;(unconditional)&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;5&lt;/cell&gt;&lt;cell&gt;\(\lambda x[Mx]\)&lt;/cell&gt;&lt;cell&gt;M&lt;/cell&gt;&lt;cell&gt;\(x\) does not occur freely in M&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;6&lt;/cell&gt;&lt;cell&gt;\(\lambda x[MN]\)&lt;/cell&gt;&lt;cell&gt;\(\bB M(\lambda x[N)]^*\)&lt;/cell&gt;&lt;cell&gt;\(x\) does not occur freely in M&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;7&lt;/cell&gt;&lt;cell&gt;\(\lambda x[MN]\)&lt;/cell&gt;&lt;cell&gt;\(\bC (\lambda x[M])^*\)N&lt;/cell&gt;&lt;cell&gt;\(x\) does not occur freely in \(N\)&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;cell&gt;\(\lambda x[MN]\)&lt;/cell&gt;&lt;cell&gt;\(\bS M^*N^*\)&lt;/cell&gt;&lt;cell&gt;\(x\) occurs freely in both \(M\) and \(N\)&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;This translation works inside-out, rather than outside-in. To illustrate:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;The translation of the term \(\lambda y[y]\), a representative of the identity function, is mapped by this translation to the identity combinator \(\bI\) (because of Rule 4), as expected.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The \(\lambda\)-term \(\lambda x[\lambda y[x]]\) that we have been calling ‘\(\bK\)’is mapped by this translation to:&lt;/p&gt;\[\begin{align} \lambda x[\lambda y[x]] &amp;amp;\equiv \lambda x[\bK x] &amp;amp;\langle \text{Rule 1}\rangle \\ &amp;amp;\equiv \bK &amp;amp;\langle \text{Rule 3} \rangle \end{align}\]&lt;/item&gt;&lt;item&gt;&lt;p&gt;The \(\lambda\)-term \(\lambda x[\lambda y[yx]]\) that switches its two arguments is mapped by this translation to:&lt;/p&gt;\[\begin{align} \lambda x[\lambda y[yx]] &amp;amp;\equiv \lambda x[\bC(\lambda y[y])^* x] &amp;amp;\langle\text{Rule 8}\rangle \\ &amp;amp;\equiv \lambda x[\bC\bI x] &amp;amp;\langle\lambda y[y] \equiv \bI,\text{ by Rule 4}\rangle \\ &amp;amp;\equiv \bB\bC\bI)(\lambda x[x])^* &amp;amp;\langle\text{Rule 7}\rangle \\ &amp;amp;\equiv \bB(\bC\bI)\bI &amp;amp;\langle(\lambda x[x])^* \equiv \bI,\text{ by Rule 4}\rangle \end{align}\]&lt;p&gt;We can confirm that the \(\lambda\)-term \(\lambda x[\lambda y[yx]]\) and the translated combinatory logic term \(\bB(\bC\bI)\bI\) have analogous applicative behavior: for all \(\lambda\)-terms \(P\) and \(Q\) we have&lt;/p&gt;\[ (\lambda x[\lambda y[yx]])PQ \rhd (\lambda y[yP]) \rhd QP; \]&lt;p&gt;likewise, for all combinatory logic terms \(P\) and \(Q\) we have&lt;/p&gt;\[ \bB(\bC\bI)\bI PQ \rhd (\bC\bI)(\bI P)Q \rhd \bI Q(\bI P) \rhd Q(\bI P) \rhd QP \]&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We can give but a glimpse of combinatory logic; for more on the subject, consult the entry on combinatory logic. Many of the issues discussed here for \(\lambda\)-calculus have analogues in combinatory logic, and vice versa.&lt;/p&gt;&lt;head rend="h3"&gt;8.2 Adding types&lt;/head&gt;&lt;p&gt;In many contexts of reasoning and computing it is natural to distinguish between different kinds of objects. The way this distinction is introduced is by requiring that certain formulas, functions, or relations accept arguments or permit substitution only of some kinds of objects rather than others. We might require, for example, that addition + take numbers as arguments. The effect of this restriction is to forbid, say, the addition of 5 and the identity function \(\lambda x.x\).[4] Regimenting objects into types is also the idea behind the passage from (unsorted, or one-sorted) first-order logic to many-sorted first-order logic. (See (Enderton, 2001) and (Manzano, 2005) for more about many-sorted first-order logic.) As it stands, the \(\lambda\)-calculus does not support this kind of discrimination; any term can be applied to any other term.&lt;/p&gt;&lt;p&gt;It is straightforward to extend the untyped \(\lambda\)-calculus so that it discriminates between different kinds of objects. This entry limits itself to the type-free \(\lambda\)-calculus. See the entries on type theory and Church’s type theory for a detailed discussion of the extensions of \(\lambda\)-calculus that we get when we add types, and see (Barendregt, Dekkers, Statman, 2013) for a book length treatment of the subject.&lt;/p&gt;&lt;p&gt;From a model-theoretic perspective, it’s interesting to add that (Scott, 1980) uses the semantic fact that categorical models for the untyped \(\lambda\)-calculus (see section 7.1) derive from the categorical models of the typed \(\lambda\)-calculus to argue for a conceptual priority of the typed over the untyped calculus.&lt;/p&gt;&lt;head rend="h2"&gt;9. Applications&lt;/head&gt;&lt;head rend="h3"&gt;9.1 Logic à la \(\lambda\)&lt;/head&gt;&lt;p&gt;Here are two senses in which \(\lambda\)-calculus is connected with logic.&lt;/p&gt;&lt;head rend="h4"&gt;9.1.1 Terms as logical constants&lt;/head&gt;&lt;p&gt;In the table of combinators above, we defined combinators \(\bT\) and \(\bF\) and said that they serve as representations in the \(\lambda\)-calculus of the truth values true and false, respectively. How do these terms function as truth values?&lt;/p&gt;&lt;p&gt;It turns out that when one is treating \(\lambda\)-calculus as a kind of programming language, one can write conditional statements “If \(P\) then \(A\) else \(B\)” simply as \(PAB\), where of course \(P, A\), and \(B\) are understood as \(\lambda\)-terms. If \(P \rhd \bT\), that is, P is ‘true’, then we have&lt;/p&gt;\[ \text{if-}P\text{-then-}A\text{-else-}B := PAB \rhd \bT AB \rhd A, \]&lt;p&gt;(recall that, by definition, \(\bT \equiv \bK\)) and if \(P \rhd \bF\), that is, \(P\) is ‘false’, then&lt;/p&gt;\[ \text{if-}P\text{-then-}A\text{-else-}B := PAB \rhd \bF AB \rhd B, \]&lt;p&gt;(recall that, by definition, \(\mathbf{F} \equiv \mathbf{KI})\) which is just what we expect from a notion of if-then-else. If \(P\) reduces neither to \(\mathbf{T}\) nor \(\mathbf{F}\), then we cannot in general say what \(\text{if-}P\text{-then-}A\text{-else-}B\) is.&lt;/p&gt;&lt;p&gt;The encoding we’ve just sketched of some of the familiar truth values and logical connectives of classical truth-table logic does not show that \(\lambda\)-calculus and classical logic are intimately related. The encoding shows little more than embeddibility of the rules of computation of classical truth-table logic in \(\lambda\)-calculus. Logics other than classical truth-table logic can likewise be represented in the \(\lambda\)-calculus, if one has sufficient computable ingredients for the logic in question (e.g., if the logical consequence relation is computable, or if a derivability relation is computable, etc.). For more on computing with \(\lambda\)-calculus, see section 9.2 below. A more intrinsic relationship between logic and \(\lambda\)-calculus is discussed in the next section.&lt;/p&gt;&lt;head rend="h4"&gt;9.1.2 Typed \(\lambda\)-calculus and the Curry-Howard-de Bruijn correspondence&lt;/head&gt;&lt;p&gt;The correspondence to be descried here between logic and the \(\lambda\)-calculus is seen with the help of an apparatus known as types. This section sketches the beginnings of the development of the subject known as type theory. We are interested in developing type theory only so far as to make the so-called Curry-Howard-de Bruijn correspondence visible. A more detailed treatment can be found in the entry on type theory; see also (Hindley, 1997) and (Barendregt, Dekkers, Statman, 2013).&lt;/p&gt;&lt;p&gt;Type theory enriches the untyped \(\lambda\)-calculus by requiring that terms be given types. In the untyped \(\lambda\)-calculus, the application \(MN\) is a legal term regardless of what \(M\) and \(N\) are. Such freedom permits one to form such suspicious terms as \(xx\), and thence terms such as the paradoxical combinator \(\mathbf{Y}\). One might wish to exclude terms like \(xx\) on the grounds that \(x\) is serving both as a function (on the left-hand side of the application) and as an argument (on the right-hand side of the application). Type theory gives us the resources for making this intuitive argument more precise.&lt;/p&gt;&lt;p&gt;Assigning types to terms The language of type theory begins with an (infinite) set of type variables (which is assumed to be disjoint from the set of variables of the \(\lambda\)-calculus and from the symbol ‘\(\lambda\)’ itself). The set of types is made up of type variables and the operation \(\sigma \rightarrow \tau\). Variables in type theory now come with a type annotation (unlike the unadorned term variables of untyped \(\lambda\)-calculus). Typed variables are rendered ‘\(x : \sigma\)’; the intuitive reading is ‘the variable \(x\) has the type \(\sigma\)’. The intuitive reading of the judgment ‘\(t : \sigma \rightarrow \tau\)’ is that the term \(t\) is a function that transforms arguments of type \(\sigma\) into arguments of type \(\tau\). Given an assignment of types to term variables, one has the typing rules:&lt;/p&gt;\[ (M : \sigma \rightarrow \tau)(N : \sigma) : \tau \]&lt;p&gt;and&lt;/p&gt;\[ (\lambda x : \sigma[M : \tau]) : \sigma \rightarrow \tau \]&lt;p&gt;The above two rules define the assignment of types to applications and to abstraction terms. The set of terms of type theory is the set of terms built up according to these formation rules.&lt;/p&gt;&lt;p&gt;The above definition of the set of terms of type theory is sufficient to rule out terms such as \(xx\). Of course, ‘\(xx\)’ is not a typed term at all for the simple reason that no types have been assigned to it. What is meant is that there is no type \(\sigma\) that could be assigned to \(x\) such that ‘\(xx\)’ could be annotated in a legal way to make a typed term. We cannot assign to \(x\) a type variable, because then the type of the left-hand \(x\) would fail to be a function type (i.e., a type of the shape ‘\(\sigma \rightarrow \tau\)’). Moreover, we cannot assign to \(x\) a function type \(\sigma \rightarrow \tau\), because then then \(\sigma\) would be equal to \(\sigma \rightarrow \tau\), which is impossible.&lt;/p&gt;&lt;p&gt;As a leading example, consider the types that are assigned to the combinators \(\bI\), \(\bK\), and \(\bS\):&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell&gt;Combinator&lt;/cell&gt;&lt;cell&gt;Type[5]&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\bI\)&lt;/cell&gt;&lt;cell&gt;\(a \rightarrow a\)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;\(\bK\)&lt;/cell&gt;&lt;cell&gt;\(a \rightarrow(b \rightarrow a)\)&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;\(\bS\)&lt;/cell&gt;&lt;cell&gt;\( (a \rightarrow(b \rightarrow c)) \rightarrow ((a \rightarrow b) \rightarrow(a \rightarrow c))\)&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;(See Hindley (1997) Table of principal types for a more extensive listing.) If we read ‘\(\rightarrow\)’ as implication and type variables as propositional variables, then we recognize three familiar tautologies in the right-hand column of the table. The language used is meager: there are only propositional variables and implication; there are no other connectives.&lt;/p&gt;&lt;p&gt;The table suggests an interesting correspondence between the typed \(\lambda\)-calculus and formal logic. Could it really be that the types assigned to formulas, when understood as logical formulas, are valid? Yes, though ‘validity’ needs to understood not as classical validity:&lt;/p&gt;&lt;p&gt;Theorem If \(\tau\) is the type of some \(\lambda\)-term, then \(\tau\) is intuitionistically valid.&lt;/p&gt;&lt;p&gt;The converse of this theorem holds as well:&lt;/p&gt;&lt;p&gt;Theorem If \(\phi\) is an intuitionistically valid logical formula whose only connective is implication \((\rightarrow)\), then \(\phi\) is the type of some \(\lambda\)-term.&lt;/p&gt;&lt;p&gt;The correspondence can be seen when one identifies intuitionistic validity with derivability in a certain natural deduction formalism. For a proof of these two theorems, see (Hindley, 1997, chapter 6).&lt;/p&gt;&lt;p&gt;The correspondence expressed by the previous two theorems between intuitionistic validity and typability is known as the Curry-Howard-de Bruijn correspondence, after three logicians who noticed it independently. The correspondence, as stated, is between only propositional intuitionistic logic, restricted to the fragment containing only the implication connective \(\rightarrow\). One can extend the correspondence to other connectives and to quantifiers, too, but the most crisp correspondence is at the level of the implication-only fragment. For details, see (Howard, 1980).&lt;/p&gt;&lt;head rend="h3"&gt;9.2 Computing&lt;/head&gt;&lt;p&gt;One can represent natural numbers in a simple way, as follows:&lt;/p&gt;&lt;p&gt;Definition (ordered tuples, natural numbers) The ordered tuple \(\langle a_0,\ldots a_n\rangle\) of \(\lambda\)-terms is defined as \(\lambda x[x a_0\ldots a_n]\). One then defines the \(\lambda\)-term \(\ulcorner n\urcorner\) corresponding to the natural number \(n\) as: \(\ulcorner 0\urcorner = \mathbf{I}\) and, for every \(k\), \(\ulcorner k + 1\urcorner = \langle \mathbf{F}, \ulcorner k\urcorner\rangle\).&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;The \(\lambda\)-term corresponding to the number 1, on this representation, is:&lt;/p&gt;\[\begin{align} \ulcorner 1 \urcorner &amp;amp;\equiv \langle\bF,\ulcorner 0\urcorner\rangle \\ &amp;amp;\equiv \langle\bF,\bI\rangle \\ &amp;amp;\equiv \lambda x[x\mathbf{FI}] \end{align}\]&lt;/item&gt;&lt;item&gt;&lt;p&gt;The \(\lambda\)-term corresponding to the number 2, on this representation, is:&lt;/p&gt;\[\begin{align} \ulcorner 2 \urcorner &amp;amp;\equiv \langle\bF,\ulcorner 1\urcorner\rangle \\ &amp;amp;\equiv \lambda x[x\mathbf{F}\lambda x[x\mathbf{FI}]] \end{align}\]&lt;/item&gt;&lt;item&gt;&lt;p&gt;Similarly, \(\ulcorner 3\urcorner\) is \(\lambda x[x\mathbf{F}\lambda x[x\mathbf{F}\lambda x[x\mathbf{FI}]]]\).&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Various representations of natural numbers are available; this representation is but one.[6]&lt;/p&gt;&lt;p&gt;Using the ingredients provided by the \(\lambda\)-calculus, one can represent all recursive functions. This shows that the model is exactly as expressive as other models of computing, such as Turing machines and register machines. For a more detailed discussion of the relation between these different models of computing, see the section comparing the Turing and Church approaches in the entry on the Church-Turing Thesis.&lt;/p&gt;&lt;p&gt;Theorem For every recursive function \(f\) of arity \(n\), there exists a \(\lambda\)-term \(f^*\) such that&lt;/p&gt;&lt;p&gt;for all natural numbers \(a_1,\ldots a_n\): \(f(a_1,\ldots a_n) = y\) iff \(\boldsymbol{\lambda} \vdash f^*\langle \bar{a}_1,\ldots,\bar{a}_n\rangle = \bar{y}\)&lt;/p&gt;&lt;p&gt;For a proof, see the appendix.&lt;/p&gt;&lt;p&gt;Since the class of recursive functions is an adequate representation of the class of all computable (number-theoretic) functions, thanks to the work above we find that all computable (number-theoretic) functions can be faithfully represented in the \(\lambda\)-calculus.&lt;/p&gt;&lt;head rend="h3"&gt;9.3 Relations&lt;/head&gt;&lt;p&gt;The motivation for the \(\lambda\)-calculus given at the beginning of the entry was based on reading \(\lambda\)-expressions as descriptions of functions. Thus, we have understood ‘\(\lambda x[M]\)’ to be a (or the) function that, given \(x\), gives \(M\) (which generally, though not necessarily, involves x). But it is not necessary to read \(\lambda\)-terms as functions. One could understand \(\lambda\)-terms as denoting relations, and read an abstraction term ‘\(\lambda x[M]\)’ as the unary relation (or property) \(R\) that holds of an argument \(x\) just in case \(M\) does (see Carnap 1947, p. 3). On the relational reading, we can understand an application term \(MN\) as a form of predication. One can make sense of these terms using the principle of \(\beta\)-conversion:&lt;/p&gt;\[ (\lambda x[M])a = M[x := A], \]&lt;p&gt;which says that the abstraction relation \(\lambda x[M]\), predicated of A, is the relation obtained by plugging in A for all free occurrences of \(x\) inside \(M\).&lt;/p&gt;&lt;p&gt;As a concrete example of this kind of approach to \(\lambda\)-calculus, consider an extension of first-order logic where one can form new atomic formulas using \(\lambda\)-terms, in the following way:&lt;/p&gt;&lt;p&gt;Syntax: For any formula \(\phi\) and any finite sequence \(x_1 , \ldots ,x_n\) of variables, the expression ‘\(\lambda x_1 \ldots x_n [\phi]\)’ is a predicate symbol of arity n. Extend the notion of free and bound variables (using the functions \(\mathbf{FV}\) and \(\mathbf{BV})\) in such a way that&lt;/p&gt;\[ \mathbf{FV}(\lambda x_1 \ldots x_n [\phi]) = \mathbf{FV}(\phi) - \{ x_1 , \ldots x_n \} \]&lt;p&gt;and&lt;/p&gt;\[ \mathbf{BV}(\lambda x_1 \ldots x_n [\phi]) = \mathbf{BV}(\phi) \cup \{ x_1 , \ldots x_n \} \]&lt;p&gt;Deduction Assume as axioms the universal closures of all equivalences&lt;/p&gt;\[ \lambda x_1 \ldots x_n [\phi](t_1 ,\ldots t_n) \leftrightarrow \phi[x_1 ,\ldots x_n := t_1,\ldots t_n] \]&lt;p&gt;where \(\phi[x_1 ,\ldots x_n := t_1,\ldots t_n]\) denotes the simultaneous substitution of the terms \(t_k\) for the variables \(x_k\) \((1 \le k \le n)\).&lt;/p&gt;&lt;p&gt;Semantics For a first-order structure \(A\) and an assignment \(s\) of elements of \(A\) to variables, define&lt;/p&gt;\[\begin{align} A \vDash &amp;amp;\lambda x_1 \ldots x_n [\phi](t_1 ,\ldots t_n) [s] \text{ iff } \\ &amp;amp;A \vDash \phi[x_1 ,\ldots x_n := t_1,\ldots t_n] [s] \end{align}\]&lt;p&gt;According to this approach, one can use a \(\lambda\) to treat essentially any formula, even complex ones, as if they were atomic. We see the principle of \(\beta\)-reduction in the deductive and semantic parts. That this approach adheres to the relational reading of \(\lambda\) terms can be seen clearly in the semantics: according to the standard Tarski-style semantics for first-order logic, the interpretation of a formula (possibly with free variables) denotes a set of tuples of elements of the structure, as we vary the variable assignment that assigns elements of the structure to the variables.&lt;/p&gt;&lt;p&gt;One can ‘internalize’ this functional approach. This is done in the case of various property theories, formal theories for reasoning about properties as metaphysical objects (Bealer 1982, Zalta 1983, Menzel 1986, 1993, and Turner 1987). This kind of theory is employed in certain metaphysical investigations where properties are metaphysical entities to be investigated. In these theories, metaphysical relations are (or are among) the objects of interest; just as we add term-building symbols + and \(\times\) in formal theories of arithmetic to build numbers, \(\lambda\) is used in property theory to build relations. This approach contrasts with the approach above. There, \(\lambda\) was added to the grammar of first-order logic by making it a recipe for building atomic formulas; it was a new formula-building operator, like \(\vee\) or \(\rightarrow\) or the other connectives. In the case of property theories, the \(\lambda\) plays a role more like + and \(\times\) in formal theories of arithmetic: it is used to construct relations (which, in this setting, are to be understood as a kind of metaphysical object). Unlike + and \(\times\), though, the \(\lambda\) binds variables.&lt;/p&gt;&lt;p&gt;To give an illustration of how \(\lambda\) is used in this setting, let us inspect the grammar of a typical application (McMichael and Zalta, 1980). One typically has a predication operator (or, more precisely, a family of predication operators) \(p_k (k \ge 0)\). In a language where we have terms \(\mary\) and \(\john\) and a binary relation loves, we can formally express:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;John loves Mary: \(\loves(\john ,\mary)\)&lt;/item&gt;&lt;item&gt;The property that John loves Mary: \(\lambda[\loves(\john ,\mary)]\) (note that the \(\lambda\) is binding no variables; we might call this ‘vacuous binding’. Such properties can be understood as propositions.)&lt;/item&gt;&lt;item&gt;The property of an object \(x\) that John loves it: \(\lambda x [\loves(\john,x)]\).&lt;/item&gt;&lt;item&gt;The property that Mary is loved by something: \(\lambda[\exists x(\loves(x,\mary))]\) (another instance of vacuous binding, viz., proposition)&lt;/item&gt;&lt;item&gt;The predication of the property of \(x\) that John loves \(x\) to Mary: \(p_1 (\lambda x[\loves(\john,x)],\mary)\).&lt;/item&gt;&lt;item&gt;The (0-ary) predication of the property that John loves Mary: \(p_0 (\lambda x[\loves(\john,\mary)])\).&lt;/item&gt;&lt;item&gt;The property of objects \(x\) and \(y\) that \(x\) loves \(y\): \(\lambda xy[\loves(x,y)]\).&lt;/item&gt;&lt;item&gt;The property of an objects \(x\) that \(x\) loves itself: \(\lambda x[\loves(x,x)]\).&lt;/item&gt;&lt;item&gt;The predication of the property of objects \(x\) and \(y\) that \(x\) loves \(y\) to John and Mary (in that order): \(p_2 (\lambda xy[\loves(x,y)],\john,\mary)\).&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We reason with these \(\lambda\)-terms using a \(\beta\)-conversion principle such as:&lt;/p&gt;\[\begin{align} p_n (\lambda x_1,&amp;amp;\ldots x_n [A], t_1 , \ldots ,t_n) \leftrightarrow \\ &amp;amp;A[x_1 ,\ldots x_n := t_1,\ldots, t_n] \end{align}\]&lt;p&gt;Formally, the predication operator p\(_k\) is a \((k+1)\)-ary predicate symbol. The first argument is intended to be a \(\lambda\)-term of \(k\) arguments, and the rest of the arguments are intended to be the arguments of the body of the \(\lambda\)-term. The \(\beta\)-principle above says that the predication of an \(n\)-ary \(\lambda\)-term \(L\) to \(n\) terms holds precisely when the body of \(L\) holds of those terms.&lt;/p&gt;&lt;p&gt;It turns out that in these theories, we may or may not be able to be fully committed to the principle of \(\beta\)-conversion. Indeed, in some property theories, the full principle of \(\beta\)-conversion leads to paradox, because one can replay a Russell-style argument when the full principle of \(\beta\)-conversion is in place. In such settings, one restricts the formation of \(\lambda\)-formulas by requiring that the body of a \(\lambda\)-term not contain further \(\lambda\)-terms or quantifiers. For further discussion, see (Orilia, 2000).&lt;/p&gt;&lt;p&gt;One of the reasons why property theories formulated in the \(\lambda\)-calculus are of a particular philosophical importance is the hyperintensional nature of the calculus (see section 1.2). A property concept may be called ‘hyperintensional’ if and only if it does not identify necessarily coextensional properties, i.e., properties that are instanciated by exactly the same objects at every possible world. The properties and relations described by the theories of Bealer, Zalta, Menzel, and Turner have exactly this characteristic. In other words, the theories are hyperintensional property theories. Recent years have seen a significant rise of interest in hyperintensional concepts of properties in metaphysics (Nolan 2014), and correspondingly property theories formulated in the \(\lambda\)-calculus will likely experience a rise of interest as well.&lt;/p&gt;&lt;p&gt;In the context of the foundations of mathematics, Zalta and Oppenheimer (2011) argue for the conceptual priority of the relational interpretation of \(\lambda\)-terms over the functional one.&lt;/p&gt;&lt;head rend="h2"&gt;Bibliography&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Baader, Franz and Tobias Nipkow, 1999, Term Rewriting and All That, Cambridge: Cambridge University Press.&lt;/item&gt;&lt;item&gt;Barendregt, Henk, 1985, The Lambda Calculus: Its Syntax and Semantics (Studies in Logic and the Foundations of Mathematics 103), 2nd edition, Amsterdam: North-Holland.&lt;/item&gt;&lt;item&gt;Barendregt, Henk, 1993, “Lambda calculi with types”, in S. Abramsky, D. Gabbay, T. Maibaum, and H. Barendregt (eds.), Handbook of Logic in Computer Science (Volume 2), New York: Oxford University Press, pp. 117–309.&lt;/item&gt;&lt;item&gt;Barendregt, Henk, Wil Dekkers, and Richard Statman., 2013, Lambda Calculus With Types, Cambridge: Cambridge University Press.&lt;/item&gt;&lt;item&gt;Bealer, George, 1982, Quality and Concept, Oxford: Clarendon Press.&lt;/item&gt;&lt;item&gt;van Benthem, Johan, 1998, A Manual of Intensional Logic, Stanford: CSLI Publications.&lt;/item&gt;&lt;item&gt;Carnap, Rudolf, 1947, Meaning and Necessity, Chicago: University of Chicago Press.&lt;/item&gt;&lt;item&gt;Church, Alonzo, 1932, “A set of postulates for the foundation of logic”, Annals of Mathematics (2nd Series), 33(2): 346–366.&lt;/item&gt;&lt;item&gt;Cutland, Nigel J., 1980, Computability, Cambridge: Cambridge University Press.&lt;/item&gt;&lt;item&gt;Doets, Kees and Jan van Eijk, 2004, The Haskell Road to Logic, Maths and Programming, London: College Publications.&lt;/item&gt;&lt;item&gt;Enderton, Herbert B., 2001, A Mathematical Introduction to Logic, 2nd edition, San Diego: Harcourt/Academic Press.&lt;/item&gt;&lt;item&gt;Frege, Gottlob, 1893, Grundgesetze der Arithmetik, Jena: Verlag Hermann Pohle, Band I; partial translation as The Basic Laws of Arithmetic, M. Furth (trans.), Berkeley: University of California Press, 1964.&lt;/item&gt;&lt;item&gt;Kleene, Stephen C., 1981, “Origins of recursive function theory”, Annals of the History of Computing, 3(1): 52–67.&lt;/item&gt;&lt;item&gt;Heim, Irene and Angelika Kratzer, 1998, Semantics in Generative Grammar, Malden, MA: Blackwell.&lt;/item&gt;&lt;item&gt;Hindley, J. Roger, 1997, Basic Simple Type Theory (Cambridge Tracts in Theoretical Computer Science 42), New York: Cambridge University Press.&lt;/item&gt;&lt;item&gt;Hindley, J. Roger and G. Longo, 1980, “Lambda-calculus Models and Extensionality.” Zeitschrift für mathematische Logik und Grundlagen der Mathematik, 26: 289–310.&lt;/item&gt;&lt;item&gt;Hindley, J. Roger and Jonathan P. Seldin, 2008, Lambda-Calculus and Combinators: An Introduction, 2nd edition, Cambridge: Cambridge University Press.&lt;/item&gt;&lt;item&gt;Howard, William A., 1980, “The formula-as-types notion of construction”, in J. Hindley and J. Seldin (eds.), To H. B. Curry: Essays on Combinatory Logic, Lambda-Calculus, and Formalism, London: Academic Press, pp. 479–490.&lt;/item&gt;&lt;item&gt;Hyland, J. Martin E., 2017, “Classical Lambda Calculus in Modern Dress”, Mathematical Structures in Computer Science, 27(5): 762–781.&lt;/item&gt;&lt;item&gt;Koymans, C.P.J., 1982, “Models of the Lambda Calculus”, Information and Control, 52: 306–332.&lt;/item&gt;&lt;item&gt;Manzano, Maria, 2005, Extensions of First-order Logic (Cambridge Tracts in Theoretical Computer Science 19), Cambridge: Cambridge University Press.&lt;/item&gt;&lt;item&gt;McCarthy, John, 1960, “Recursive functions of symbolic expressions and their computation by machine (Part I)”, Communications of the ACM, 3(4): 184–195.&lt;/item&gt;&lt;item&gt;McMichael, Alan and Edward N. Zalta, 1980, “An alternative theory of nonexistent objects”, Journal of Philosophical Logic, 9: 297–313.&lt;/item&gt;&lt;item&gt;Menzel, Christopher, 1986, “A complete, type-free second order logic of properties, relations, and propositions”, Technical Report #CSLI-86-40, Stanford: CSLI Publications.&lt;/item&gt;&lt;item&gt;Menzel, Christopher, 1993, “The proper treatment of predication in fine-grained intensional logic”, Philosophical Perspectives 7: 61–86.&lt;/item&gt;&lt;item&gt;Meyer, Albert R., 1982, “What is a model of the lambda calculus?”, In Information and Control, 52(1): 87–122.&lt;/item&gt;&lt;item&gt;Nederpelt, Rob, with Herman Geuvers and Roel de Vriejer (eds.), 1994, Selected Papers on Automath (Studies in Logic and the Foundations of Mathematics 133), Amsterdam: North-Holland.&lt;/item&gt;&lt;item&gt;Nolan, Daniel, 2014, “Hyperintensional metaphysics”, Philosophical Studies, 171(1); 149–160.&lt;/item&gt;&lt;item&gt;Orilia, Francesco, 2000, “Property theory and the revision theory of definitions”, Journal of Symbolic Logic, 65(1): 212–246.&lt;/item&gt;&lt;item&gt;Partee, Barbara H., with Alice ter Meulen and Robert E. Wall, 1990, Mathematical Methods in Linguistics, Berlin: Springer.&lt;/item&gt;&lt;item&gt;Plotkin, G.D., 1972, A Set-Theoretical Definition of Application, School of Artificial Intelligence, Memo MIP-R-95, University of Edinburgh.&lt;/item&gt;&lt;item&gt;Revesz, George E., 1988, Lambda-Calculus, Combinators, and Functional Programming, Cambridge: Cambridge University Press; reprinted 2008.&lt;/item&gt;&lt;item&gt;Rosser, J. Barkley, 1984, “Highlights of the History of the Lambda-Calculus”, Annals of the History of Computing, 6(4): 337–349.&lt;/item&gt;&lt;item&gt;Salibra, Antonio, 2003, “Lambda calculus: models and theories”, in Proceedings of the Third AMAST Workshop on Algebraic Methods in Language Processing (AMiLP-2003), No. 21, University of Twente, pp. 39–54.&lt;/item&gt;&lt;item&gt;Schönfinkel, Moses, 1924, “On the building blocks of mathematical logic”, in J. van Heijenoort (ed.), From Frege to Gödel: A Source Book in Mathematical Logic, Cambridge, MA: Harvard University Press, 1967, pp. 355–366.&lt;/item&gt;&lt;item&gt;Scott, Dana, 1974, “The LAMBDA language”, Journal of Symbolic Logic, 39: 425–427.&lt;/item&gt;&lt;item&gt;–––, 1980, “Lambda Calculus: Some Models, Some Philosophy”, in J. Barwise, H.J. Keisler, and K. Kunen (eds.), The Kleene Symposium, Amsterdam: North-Holland, pp. 223–265.&lt;/item&gt;&lt;item&gt;Troelstra, Anne and Helmut Schwichtenberg, 2000, Basic Proof Theory (Cambridge Tracts in Theoretical Computer Science 43), 2nd edition, Cambridge: Cambridge University Press.&lt;/item&gt;&lt;item&gt;Turing, Alan M., 1937, “Computability and \(\lambda\)-definability”, Journal of Symbolic Logic, 2(4): 153–163.&lt;/item&gt;&lt;item&gt;Turner, Richard, 1987, “A theory of properties”, Journal of Symbolic Logic, 52(2): 455–472.&lt;/item&gt;&lt;item&gt;Zalta, Edward N., 1983, Abstract Objects: An Introduction to Axiomatic Metaphysics, Dordrecht: D. Reidel.&lt;/item&gt;&lt;item&gt;Zalta, Edward N. and Paul Oppenheimer, 2011, “Relations versus functions at the foundations of logic: type-theoretic considerations”, Journal of Logic and Computation 21: 351–374.&lt;/item&gt;&lt;item&gt;Zerpa, L., 2021, “The Teaching and Learning of the Untyped Lambda Calculus Through Web-Based e-Learning Tools”, in K. Arai Intelligent Computing (Lecture Notes in Networks and Systems: Volume 285), Cham: Springer, pp. 419–436.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Academic Tools&lt;/head&gt;&lt;quote&gt;&lt;td&gt;How to cite this entry.&lt;/td&gt;&lt;td&gt;Preview the PDF version of this entry at the Friends of the SEP Society.&lt;/td&gt;&lt;td&gt;Look up topics and thinkers related to this entry at the Internet Philosophy Ontology Project (InPhO).&lt;/td&gt;&lt;td&gt;Enhanced bibliography for this entry at PhilPapers, with links to its database.&lt;/td&gt;&lt;/quote&gt;&lt;head rend="h2"&gt;Other Internet Resources&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;The Lambda Calculator, a tool for working with \(\lambda\)-terms with an eye toward their use in formal semantics of natural language.&lt;/item&gt;&lt;item&gt;Lambda calculus reduction workbench, for visualizing reduction strategies.&lt;/item&gt;&lt;item&gt;“\(\lambda\)-Calculus: Then and Now,” useful handout on the milestones in, contributors to, and bibliography on the \(\lambda\)-calculus, presented at the several Turing Centennial conferences. There also exists a video recording of the lecture given on the occasion of Princeton University’s celebration of the Turing Centennial in 2012.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Acknowledgments&lt;/head&gt;&lt;p&gt;The first author wishes to acknowledge the contributions of Henk Barendregt, Elizabeth Coppock, Reinhard Kahle, Martin Sørensen, and Ed Zalta in helping to craft this entry. He also thanks Nic McPhee for introducing him to the \(\lambda\)-calculus.&lt;/p&gt;&lt;p&gt;The second author would like to acknowledge the useful comments and suggestions of Fabrizio Cariani, Cameron Moy, Peter Percival, and Ed Zalta.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361344</guid><pubDate>Wed, 24 Sep 2025 15:00:15 +0000</pubDate></item><item><title>How to Be a Leader When the Vibes Are Off</title><link>https://chaoticgood.management/how-to-be-a-leader-when-the-vibes-are-off/</link><description>&lt;doc fingerprint="7a01915d36b1034c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to Be a Leader When the Vibes Are Off&lt;/head&gt;
    &lt;head rend="h2"&gt;...and the vibes are definitely off&lt;/head&gt;
    &lt;p&gt;It feels different in tech right now. We’re coming off a long era where optimism carried the industry. Something has curdled. AI hype, return-to-office mandates, and continued layoffs have shifted the mood. Managers are quicker to fire, existential dread has replaced the confidence that a tight job market for developers provided for decades. The vibes are for sure off.&lt;/p&gt;
    &lt;head rend="h3"&gt;What’s Changed?&lt;/head&gt;
    &lt;p&gt;(What follows are generalizations. If your company is escaping some or all of these, I applaud you. I’m sure there are exceptions.)&lt;/p&gt;
    &lt;p&gt;AI has injected some destabilization. “I don’t need junior devs when I can just pay $20/month for Cursor” has an effect on everyone even if this turns out to be silly down the road. I see lots of people worried that the aim of all of this is to ultimately have a robot do their entire job. Whether or not this is possible doesn’t mean people aren’t going to try. And it’s the trying that raises people’s anxiety. On top of that, we’ve also got “AI Workslop” to contend with as well, which is making work harder for the diligent among us.&lt;/p&gt;
    &lt;p&gt;Return to Office feels like trust has been broken. Teams that continued to work well (or in some cases, better) after everyone in the industry went remote are now being told to come back to desks in offices. I’ve even heard tales of this happening despite there not being enough office space for everyone, which seems very silly. Also, for the first time in my nearly 30-year career, I’ve even heard of people being told they need to be “at their desks at 9am” and “expected to stay until 5pm at a minimum.” Even before COVID-19 and the mass move to remote work, most companies were flexible on start and stop times. I almost never heard of set hours for software developers until recently. Rules like that scream “we don’t trust you unless we can see you,” even if that’s not really the reason for the mandates. (IMO there are benefits to working in the same location as your colleagues but ham-fisted, poorly thought out mandates are not the way to achieve them.)&lt;/p&gt;
    &lt;p&gt;Layoffs changed the market. For probably 20 years, job security wasn’t really a concern in the industry. Layoffs happened here and there and companies folded, but the demand was always strong and most people capable of writing code or managing people who write code could lose their job, spend the severance on a nice vacation, and return with the confidence that they’d be able to land a new gig in a couple of weeks, likely at higher pay. With the acknowledgement that this was a privilege not enjoyed by most of the working world, it is no longer true. The size and scope of layoffs over the last couple of years have injected more anxiety into the tech workforce.&lt;/p&gt;
    &lt;p&gt;C-Suite Energy has changed. Across the board, execs seem more efficiency-focused, financialized, and less mission-driven. The days of “take care of the employees and the employees will take care of the business” feel like they’re in the rear-view mirror, and a new “do your job, or else!” mentality has taken its place.&lt;/p&gt;
    &lt;p&gt;You can’t change the macro forces that are driving these trends, but you can control how you show up for your team.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wearing the ‘Company Hat’ vs. Chaotic-Good Leadership&lt;/head&gt;
    &lt;p&gt;My standard advice to anyone with a management role and anyone at the Staff+ level of individual contributor is that “wearing the company hat” should be the default. You’re not always going to agree with the decisions that come down from the top. Even when you don’t agree with decisions the company leadership is making, part of your job is representing and facilitating those decisions with full alignment. When acting “in public” (all-hands, department meetings, the #general channel), this is mandatory, as contradicting the bosses in a broad forum can kill the credibility you have the leadership across the wider team. It’s also a good way to get yourself fired.&lt;/p&gt;
    &lt;head rend="h3"&gt;Let them know you’re still on their side&lt;/head&gt;
    &lt;p&gt;But you know what also kills trust? Telling your team it’s sunny out when everyone can plainly see that it’s raining. Your team is made up of smart adults who can, at the very least, count the number of employees and the number of desks and calculate that “everyone in the office on Wednesday” isn’t going to work out well if the people outnumber the chairs. Telling them something else is going to make you look like an idiot toady in their eyes.&lt;/p&gt;
    &lt;p&gt;The right thing to do in this situation is to acknowledge that you see the situation the same way they do, but do it privately, within your immediate team only or in 1-1s. “Yeah, this new policy sucks, I get it. It’s going to affect me in negative ways too.” It’s really important that you validate the emotions that all of these aspects are bringing up in people.&lt;/p&gt;
    &lt;head rend="h3"&gt;Don’t pretend you can fix it&lt;/head&gt;
    &lt;p&gt;You can promise to advocate for saner policies when the opportunity arises if your sphere of influence makes that possible, but don’t promise to make the problem go away if you can’t. Broken promises and poor do/say ratio performance will also kill your team’s faith in you, especially when it’s about things they really care about. And again, this is not a time for grandstanding. In public, you have to support the policies, but when you’re in private with your manager and your peers, that’s the time you can safely push for change.&lt;/p&gt;
    &lt;head rend="h3"&gt;Find small workarounds to make things livable&lt;/head&gt;
    &lt;p&gt;If you can provide some flexibility on seemingly inflexible policies, do it. If your management role includes enforcing the company’s rules, you can use some discretion about how strictly you want to enforce them. Personally, I would never want to “rat out” a good performer who can’t get to their desk by 9am sharp because they have to drop off their kids or punish someone who bugged out early once to catch their favourite performer in concert one town over. Small acts demonstrating that you trust your team, even if the C-Suite doesn’t seem to trust the broader team the way they used to, can go a long way toward maintaining good morale within your group.&lt;/p&gt;
    &lt;p&gt;When things feel shaky in the broader org, people will look more to their direct leader for a sense of stability. The best thing you can do for them is provide it. Quiet honesty builds credibility and fosters loyalty.&lt;/p&gt;
    &lt;head rend="h2"&gt;This too shall pass&lt;/head&gt;
    &lt;p&gt;The industry is going through a period where a lot is changing all at once. We’ve had a few of them before. Things will eventually settle down into a new normal. I’m not great at predictions, so I’ll refrain from detailing what I think things will look like, but I don’t think it’ll be entirely unfamiliar to those who were here before this latest inflection point. This is especially true if leaders who care and treat their staff like adults can stay grounded and stay true to their principles, even when that means performing small, quiet acts of rebellion.&lt;/p&gt;
    &lt;p&gt;You can’t fix the macro trends, but you can try to keep your corner of the tech world a place where people are glad to work.&lt;/p&gt;
    &lt;p&gt;"Off Kilter" by anujd89 is licensed under CC BY 2.0 .&lt;/p&gt;
    &lt;p&gt;Like this? Please feel free to share it on your favourite social media or link site! Share it with friends!&lt;/p&gt;
    &lt;p&gt;Hit subscribe to get new posts delivered to your inbox automatically.&lt;lb/&gt;Feedback? Get in touch!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45361394</guid><pubDate>Wed, 24 Sep 2025 15:03:59 +0000</pubDate></item><item><title>Python on the Edge: Fast, sandboxed, and powered by WebAssembly</title><link>https://wasmer.io/posts/python-on-the-edge-powered-by-webassembly</link><description>&lt;doc fingerprint="87ab2dfdccf438d4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Python on the Edge: Fast, sandboxed, and powered by WebAssembly&lt;/head&gt;
    &lt;p&gt;We are excited to announce full Python support in Wasmer Edge (Beta)&lt;/p&gt;
    &lt;p&gt;Founder &amp;amp; CEO&lt;/p&gt;
    &lt;p&gt;With AI workloads on the rise, the demand for Python support on WebAssembly on the Edge has grown rapidly.&lt;/p&gt;
    &lt;p&gt;However, bringing Python to WebAssembly isn't trivial as it means supporting native modules like &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, and &lt;code&gt;pydantic&lt;/code&gt;.&amp;#13;
While projects like &lt;code&gt;pyodide&lt;/code&gt; made strides in running Python in the browser via WebAssembly, their trade-offs don't fully fit server-side needs.&lt;/p&gt;
    &lt;p&gt;After months of hard work, today we're thrilled to announce full Python support in Wasmer Edge (Beta) powered by WebAssembly and WASIX.&lt;/p&gt;
    &lt;p&gt;Now you can run FastAPI, Streamlit, Django, LangChain, and more directly on Wasmer and Wasmer Edge! To accomplish it we had to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add support for dynamic linking (&lt;code&gt;dlopen&lt;/code&gt;/&lt;code&gt;dlsym&lt;/code&gt;) into WASIX&lt;/item&gt;
      &lt;item&gt;Add &lt;code&gt;libffi&lt;/code&gt;support (so Python libraries using&lt;code&gt;ctypes&lt;/code&gt;could be supported)&lt;/item&gt;
      &lt;item&gt;Polish Sockets and threading support in WASIX&lt;/item&gt;
      &lt;item&gt;Release our own Python Package Index with many of the most popular Python Native libraries compiled to WASIX&lt;/item&gt;
      &lt;item&gt;Create our own alternative to Heroku Buildpacks / Nixpacks / Railpack / Devbox to automatically detect a project type from its source code and deploy it (including running with Wasmer or deploying to Wasmer Edge!). Updates will be shared soon!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How fast is it?&lt;/head&gt;
    &lt;p&gt;This Python release is much faster than any of the other Python releases we did in the past.&lt;/p&gt;
    &lt;p&gt;It is fast. Insa…natively fast (it's even faster than our py2wasm project!)&lt;/p&gt;
    &lt;code&gt;$ wasmer run python/python@=0.2.0 --dir=. -- pystone.py&amp;#13;
Pystone(1.1) time for 50000 passes = 0.562538&amp;#13;
This machine benchmarks at 88882.9 pystones/second&amp;#13;
$ wasmer run python/python --dir=. -- pystone.py # Note: first run may take time&amp;#13;
Pystone(1.1) time for 50000 passes = 0.093556&amp;#13;
This machine benchmarks at 534439 pystones/second&amp;#13;
$ python3 pystone.py&amp;#13;
Pystone(1.1) time for 50000 passes = 0.0827736&amp;#13;
This machine benchmarks at 604057 pystones/second
&lt;/code&gt;
    &lt;p&gt;That's 6x faster, and nearly indistinguishable from native Python performance… quite good, considering that your Python apps can now run fully sandboxed anywhere!&lt;/p&gt;
    &lt;p&gt;Note: the first time you run Python, it will take a few minutes to compile. We are working to improve this so no time will be spent on compilation locally.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;🚀 Even faster performance coming soon: we are trialing an optimization technique that will boost Python performance in Wasm to 95% of native Python speed. This is already powering our PHP server in production. Result: Near-native Python performance, fully sandboxed. Stay tuned!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;What it can run&lt;/head&gt;
    &lt;p&gt;Now, you can run any kind of Python API server, powered by &lt;code&gt;fastapi&lt;/code&gt;, &lt;code&gt;django&lt;/code&gt;, &lt;code&gt;flask&lt;/code&gt;, or &lt;code&gt;starlette&lt;/code&gt;, connected to a MySQL database automatically when needed (FastAPI template, Django template).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;fastapi&lt;/code&gt; with websockets (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;mcp&lt;/code&gt; servers (deploy using our MCP template, demo).&lt;/p&gt;
    &lt;p&gt;You can run image processors like &lt;code&gt;pillow&lt;/code&gt;  (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;ffmpeg&lt;/code&gt; inside Python (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;streamlit&lt;/code&gt; and &lt;code&gt;langchain&lt;/code&gt; (deploy using our LangChain template, demo).&lt;/p&gt;
    &lt;p&gt;You can even run &lt;code&gt;pypandoc&lt;/code&gt;!  (example repo, demo).&lt;/p&gt;
    &lt;p&gt;Soon, we'll have full support for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;curl_cffi&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;polars&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;gevent&lt;/code&gt;/&lt;code&gt;greenlet&lt;/code&gt;(more on this soon!)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Pytorch&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Wasmer VS alternatives&lt;/head&gt;
    &lt;p&gt;Python on Wasmer Edge is just launching, but it's already worth asking: how does it stack up existing solutions?&lt;/p&gt;
    &lt;head rend="h3"&gt;Quick Comparison&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Feature / Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Wasmer Edge&lt;/cell&gt;
        &lt;cell role="head"&gt;Cloudflare&lt;/cell&gt;
        &lt;cell role="head"&gt;AWS Lambda&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Native modules (&lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, etc.)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported*&lt;/cell&gt;
        &lt;cell&gt;❌ Limited (no &lt;code&gt;libcurl&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Full support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Multithreading &amp;amp; multiprocessing (&lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;pandoc&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ASGI / WSGI frameworks (&lt;code&gt;uvicorn&lt;/code&gt;, &lt;code&gt;daphne&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
        &lt;cell&gt;❌ Patched / limited&lt;/cell&gt;
        &lt;cell&gt;⚠️ Needs wrappers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;WebSockets (&lt;code&gt;streamlit&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Raw sockets (&lt;code&gt;libcurl&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
        &lt;cell&gt;❌ JS &lt;code&gt;fetch&lt;/code&gt; only&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Multiple Python versions&lt;/cell&gt;
        &lt;cell&gt;✅ In Roadmap (3.12, 3.14…)&lt;/cell&gt;
        &lt;cell&gt;❌ Tied to bundled runtime&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cold starts&lt;/cell&gt;
        &lt;cell&gt;⚡ Extremely fast&lt;/cell&gt;
        &lt;cell&gt;⏳ Medium (V8 isolates)&lt;/cell&gt;
        &lt;cell&gt;⏳ Slow&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Code changes required&lt;/cell&gt;
        &lt;cell&gt;✅ None&lt;/cell&gt;
        &lt;cell&gt;⚠️ Some&lt;/cell&gt;
        &lt;cell&gt;⚠️ Wrappers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Pricing&lt;/cell&gt;
        &lt;cell&gt;💰 Affordable&lt;/cell&gt;
        &lt;cell&gt;💰 Higher&lt;/cell&gt;
        &lt;cell&gt;💰 Higher&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Cloudflare Workers (Python) / Pyodide&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;ℹ️ Most of the demos that we showcased on this article, are not runnable inside of Cloudflare:&lt;/p&gt;&lt;code&gt;ffmpeg&lt;/code&gt;,&lt;code&gt;streamlit&lt;/code&gt;,&lt;code&gt;pypandoc&lt;/code&gt;.&lt;/quote&gt;
    &lt;p&gt;Cloudflare launched Python support ~18 months ago, by using Pyodide inside workerd, their JavaScript-based Workers runtime.&lt;/p&gt;
    &lt;p&gt;While great for browser-like environments, Pyodide has trade-offs that make it less suitable server-side. Here are the limitations when running Python in Cloudflare:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ No support for &lt;code&gt;uvloop&lt;/code&gt;,&lt;code&gt;uvicorn&lt;/code&gt;, or similar event-native frameworks (JS event loop patches break compatibility with native).&lt;/item&gt;
      &lt;item&gt;❌ No pthreads or multiprocessing support, you can't call subprocesses like &lt;code&gt;ffmpeg&lt;/code&gt;or&lt;code&gt;pypandoc&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;❌ No raw HTTP client sockets (HTTP clients are patched to use JS &lt;code&gt;fetch&lt;/code&gt;, no&lt;code&gt;libcurl&lt;/code&gt;available).&lt;/item&gt;
      &lt;item&gt;❌ Limited to a bundled Python version and package set.&lt;/item&gt;
      &lt;item&gt;⏳ Cold starts slower due to V8 isolate warmup.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the limitations? Cloudflare relies on Pyodide: great in-browser execution, but server-side it implies no sockets, threads, or multiprocessing. The result: convenient for lightweight browser use, but might not be the best fit for real Python workloads on the server.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In contrast, Wasmer Edge runs real Python on WASIX unmodified, so everything "just works", with near-native speed and fast cold starts.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Amazon Lambda&lt;/head&gt;
    &lt;p&gt;AWS Lambda doesn't natively run unmodified Python apps:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ You need adapters (such as https://github.com/slank/awsgi or https://github.com/Kludex/mangum) for running your WSGI sites.&lt;/item&gt;
      &lt;item&gt;❌ WebSockets are unsupported.&lt;/item&gt;
      &lt;item&gt;⚠️ Setup is complex, adapters are often unmaintained.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the limits? AWS Lambda requires you to use their HTTP lambda handler, which can cause incompatibility into your own HTTP servers. Also, because their lambda handlers are HTTP-based, there's no easy support for WebSockets.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In contrast, Wasmer Edge supports any Python HTTP servers without requiring any code adaptation from your side.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Why Wasmer Edge Stands Out&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Closer to native Python than Pyodide (no JS involvement at all).&lt;/item&gt;
      &lt;item&gt;Faster cold starts and more compatibility than Cloudflare's Workers.&lt;/item&gt;
      &lt;item&gt;More compatible than AWS Lambda (no wrappers/adapters).&lt;/item&gt;
      &lt;item&gt;More affordable across the board.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;🐍 It's Showtime!&lt;/head&gt;
    &lt;p&gt;Python support in Wasmer and Wasmer Edge is already available and ready to use. We have set up many Python templates to help you get started in no time.&lt;/p&gt;
    &lt;p&gt;https://wasmer.io/templates?language=python&lt;/p&gt;
    &lt;p&gt;To make things even better, we are working on a MCP server for Wasmer, so you will be able to plug Wasmer into ChatGPT or Anthropic and have your websites deploying from your vibe-coded projects. Stay tuned!&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;⚠️ Python in Wasmer Edge is still in Beta, so expect some rough edges if your project doesn't work out of the box… if you encounter any issues, please report them so we can work on enabling your workloads on Wasmer Edge.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Create your first MCP Server in Wasmer&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Go to https://wasmer.io/templates/mcp-chatgpt-starter?intent=at_vRxJIdtPCbKe&lt;/item&gt;
      &lt;item&gt;Connect your Github account&lt;/item&gt;
      &lt;item&gt;Create a git repo from the template&lt;/item&gt;
      &lt;item&gt;Deploy and enjoy!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: source code available here: https://github.com/wasmer-examples/python-mcp-chatgpt-starter&lt;/p&gt;
    &lt;head rend="h2"&gt;Create your first Django app&lt;/head&gt;
    &lt;p&gt;We have set up a template for using Django + Uvicorn in Wasmer Edge.&lt;/p&gt;
    &lt;p&gt;You can start using it very easily, just click Deploy: https://wasmer.io/templates/django-starter?intent=at_WK0DIkt3CeKX&lt;/p&gt;
    &lt;p&gt;Deploying a Django app will create a MySQL DB for you in Wasmer Edge (Postgres support is coming soon), run migrations and prepare everything to run your website seamlessly.&lt;/p&gt;
    &lt;p&gt;Note: source code available here: https://github.com/wasmer-examples/django-wasmer-starter&lt;/p&gt;
    &lt;p&gt;Ready to deploy your first Python app on Wasmer Edge?&lt;/p&gt;
    &lt;p&gt;Here are the best places to begin:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 Starter Templates → Browse Python templates&lt;/item&gt;
      &lt;item&gt;📖 Docs &amp;amp; Examples → Wasmer GitHub&lt;/item&gt;
      &lt;item&gt;💬 Community Support → Join our Discord&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;👉 Deploy your first Python app now&lt;/p&gt;
    &lt;p&gt;With WebAssembly and Wasmer, Python is now portable, sandboxed, and running at near-native speeds. Ready for AI workloads, APIs, and anything you can imagine at the edge.&lt;lb/&gt; The sky is the limit ❤️.&lt;/p&gt;
    &lt;head rend="h5"&gt;About the Author&lt;/head&gt;
    &lt;p&gt;Syrus Akbary is an enterpreneur and programmer. Specifically known for his contributions to the field of WebAssembly. He is the Founder and CEO of Wasmer, an innovative company that focuses on creating developer tools and infrastructure for running Wasm&lt;/p&gt;
    &lt;p&gt;Founder &amp;amp; CEO&lt;/p&gt;
    &lt;p&gt;How fast is it?&lt;/p&gt;
    &lt;p&gt;What it can run&lt;/p&gt;
    &lt;p&gt;Wasmer VS alternatives&lt;/p&gt;
    &lt;p&gt;Quick Comparison&lt;/p&gt;
    &lt;p&gt;Cloudflare Workers (Python) / Pyodide&lt;/p&gt;
    &lt;p&gt;Amazon Lambda&lt;/p&gt;
    &lt;p&gt;Why Wasmer Edge Stands Out&lt;/p&gt;
    &lt;p&gt;🐍 It's Showtime!&lt;/p&gt;
    &lt;p&gt;Create your first MCP Server in Wasmer&lt;/p&gt;
    &lt;p&gt;Create your first Django app&lt;/p&gt;
    &lt;p&gt;Deploy your first Python site in seconds with our managed cloud solution.&lt;/p&gt;
    &lt;head rend="h5"&gt;Read more&lt;/head&gt;
    &lt;p&gt;wasmerwasmer edgerustprojectsedgeweb scraper&lt;/p&gt;
    &lt;head rend="h6"&gt;Build a Web Scraper in Rust and Deploy to Wasmer Edge&lt;/head&gt;
    &lt;p&gt;RudraAugust 14, 2023&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362023</guid><pubDate>Wed, 24 Sep 2025 15:48:36 +0000</pubDate></item><item><title>The Data Commons Model Context Protocol (MCP) Server</title><link>https://developers.googleblog.com/en/datacommonsmcp/</link><description>&lt;doc fingerprint="fd8eaac2c93e998b"&gt;
  &lt;main&gt;
    &lt;p&gt;We are excited to announce the public release of the Data Commons Model Context Protocol (MCP) Server. This release marks a major milestone in making all of Data Commons’ vast and interconnected public datasets instantly accessible and actionable for AI developers, data scientists and organizations worldwide. This capability further supports the larger ambition of Data Commons: using real-world statistical information as an anchor to help reduce Large Language Model (LLM) hallucinations.&lt;/p&gt;
    &lt;p&gt;Benefits of MCP Server&lt;/p&gt;
    &lt;p&gt;The MCP Server provides a standardized way for AI agents to consume Data Commons natively. This allows developers to leverage our comprehensive data without needing to learn or directly interact with complex underlying APIs. It dramatically accelerates the creation of data-rich, agentic applications that reduce the rate of hallucinations in LLMs.&lt;/p&gt;
    &lt;p&gt;Faster than ever, developers can deploy AI agents and applications that deliver trustable, sourced Data Commons information back to the end user. The MCP Server enables agents to handle the full range of data-driven queries, from initial discovery to generative reports:&lt;/p&gt;
    &lt;p&gt;Ready to try it? Get started with Gemini CLI here.&lt;/p&gt;
    &lt;p&gt;Since 2023, Google's Data Commons has partnered with the ONE Campaign, a global organization that advocates for the investments needed to create economic opportunities and healthier lives in Africa. This collaboration led to the creation of ONE Data, a platform that combines ONE's global development data and policy expertise with the extensive public datasets available through Data Commons.&lt;/p&gt;
    &lt;p&gt;As our first use case, ONE Data leveraged the power of our MCP server and agent-driven exploration to develop The One Data Agent, an interactive platform for health financing data. This new tool enables users to quickly search through tens of millions of health financing data points in seconds, using plain language. They can then visualize that data and download clean datasets, saving time while helping to improve advocacy, reporting and policy-making.&lt;/p&gt;
    &lt;p&gt;This is a critical innovation for those working on global health. There is an urgent need to strengthen health systems in developing countries, but finding reliable data on health financing is a significant challenge – truly searching for the proverbial needle in a haystack. The information is scattered across thousands of disparate silos, buried in different reporting formats, organized by technical jargon and stored in several isolated databases. Now, for example, if you want to identify which countries are at risk from donor cuts, you can quickly search for countries that rely most on external funding for health and are therefore most vulnerable to aid reductions or debt shocks.&lt;/p&gt;
    &lt;p&gt;To compile a reliable report from traditional databases, users would need to work across datasets and manually pull data. Agents, however, understand complex queries and are able to fetch and compile the needed data quickly. The ONE Data Agent is paving the way for a new era of accessible, impactful data-driven advocacy.&lt;/p&gt;
    &lt;p&gt;Whether you’re prototyping a new AI agent, adding data features to your product or streamlining your organization’s analytics workflow, the Data Commons MCP Server is ready to help you move faster.&lt;/p&gt;
    &lt;p&gt;It’s designed for seamless integration and minimal onboarding friction. The Data Commons MCP Server fits naturally within Google Cloud Platform's latest agent development workflows, such as the Agent Development Kit (ADK) and clients including Gemini CLI. The server can also be easily integrated with any other agentic workflow or platform.&lt;/p&gt;
    &lt;p&gt;To help you get started, we provide an ADK sample agent in a Colab notebook and instructions for using the Server with Gemini CLI:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362038</guid><pubDate>Wed, 24 Sep 2025 15:49:37 +0000</pubDate></item><item><title>SedonaDB: A new geospatial DataFrame library written in Rust</title><link>https://sedona.apache.org/latest/blog/2025/09/24/introducing-sedonadb-a-single-node-analytical-database-engine-with-geospatial-as-a-first-class-citizen/</link><description>&lt;doc fingerprint="3bdb989c4036eb8a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing SedonaDB: A single-node analytical database engine with geospatial as a first-class citizen&lt;/head&gt;
    &lt;p&gt;The Apache Sedona community is excited to announce the initial release of SedonaDB! ð&lt;/p&gt;
    &lt;p&gt;SedonaDB is the first open-source, single-node analytical database engine that treats spatial data as a first-class citizen. It is developed as a subproject of Apache Sedona.&lt;/p&gt;
    &lt;p&gt;Apache Sedona powers large-scale geospatial processing on distributed engines like Spark (SedonaSpark), Flink (SedonaFlink), and Snowflake (SedonaSnow). SedonaDB extends the Sedona ecosystem with a single-node engine optimized for small-to-medium data analytics, delivering the simplicity and speed that distributed systems often cannot.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¤ What is SedonaDB¶&lt;/head&gt;
    &lt;p&gt;Written in Rust, SedonaDB is lightweight, blazing fast, and spatial-native. Out of the box, it provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ðºï¸ Full support for spatial types, joins, CRS (coordinate reference systems), and functions on top of industry-standard query operations.&lt;/item&gt;
      &lt;item&gt;â¡ Query optimizations, indexing, and data pruning features under the hood that make spatial operations just work with high performance.&lt;/item&gt;
      &lt;item&gt;ð Pythonic and SQL interfaces familiar to developers, plus APIs for R and Rust.&lt;/item&gt;
      &lt;item&gt;âï¸ Flexibility to run in single-machine environments on local files or data lakes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SedonaDB utilizes Apache Arrow and Apache DataFusion, providing everything you need from a modern, vectorized query engine. What sets it apart is the ability to process spatial workloads natively, without extensions or plugins. Installation is straightforward, and SedonaDB integrates easily into both local development and cloud pipelines, offering a consistent experience across environments.&lt;/p&gt;
    &lt;p&gt;The initial release of SedonaDB provides a comprehensive suite of geometric vector operations and seamlessly integrates with GeoArrow, GeoParquet, and GeoPandas. Future versions will support all popular spatial functions, including functions for raster data.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð SedonaDB quickstart example¶&lt;/head&gt;
    &lt;p&gt;Start by installing SedonaDB:&lt;/p&gt;
    &lt;code&gt;pip install "apache-sedona[db]"
&lt;/code&gt;
    &lt;p&gt;Now instantiate the connection:&lt;/p&gt;
    &lt;code&gt;import sedona.db

sd = sedona.db.connect()
&lt;/code&gt;
    &lt;p&gt;Let's perform a spatial join using SedonaDB.&lt;/p&gt;
    &lt;p&gt;Suppose you have a &lt;code&gt;cities&lt;/code&gt; table with latitude and longitude points representing the center of each city, and a &lt;code&gt;countries&lt;/code&gt; table with a column containing a polygon of the country's geographic boundaries.&lt;/p&gt;
    &lt;p&gt;Here are a few rows from the &lt;code&gt;cities&lt;/code&gt; table:&lt;/p&gt;
    &lt;code&gt;ââââââââââââââââ¬ââââââââââââââââââââââââââââââââ
â     name     â            geometry           â
â   utf8view   â      geometry &amp;lt;epsg:4326&amp;gt;     â
ââââââââââââââââªââââââââââââââââââââââââââââââââ¡
â Vatican City â POINT(12.4533865 41.9032822)  â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
â San Marino   â POINT(12.4417702 43.9360958)  â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
â Vaduz        â POINT(9.5166695 47.1337238)   â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
&lt;/code&gt;
    &lt;p&gt;And here are a few rows from the countries table:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââââââââââââââââ¬ââââââââââââââââ¬âââââââââââââââââââââââââââââââââââââââââââââââââââââ
â             name            â   continent   â                      geometry                      â
â           utf8view          â    utf8view   â                geometry &amp;lt;epsg:4326&amp;gt;                â
âââââââââââââââââââââââââââââââªââââââââââââââââªâââââââââââââââââââââââââââââââââââââââââââââââââââââ¡
â Fiji                        â Oceania       â MULTIPOLYGON(((180 -16.067132663642447,180 -16.55â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â United Republic of Tanzania â Africa        â POLYGON((33.90371119710453 -0.9500000000000001,34â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â Western Sahara              â Africa        â POLYGON((-8.665589565454809 27.656425889592356,-8â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
&lt;/code&gt;
    &lt;p&gt;Hereâs how to perform a spatial join to compute the country of each city:&lt;/p&gt;
    &lt;code&gt;sd.sql(
    """
select
    cities.name as city_name,
    countries.name as country_name,
    continent
from cities
join countries
where ST_Intersects(cities.geometry, countries.geometry)
"""
).show(3)
&lt;/code&gt;
    &lt;p&gt;The code utilizes &lt;code&gt;ST_Intersects&lt;/code&gt; to determine if a city is contained within a given country.&lt;/p&gt;
    &lt;p&gt;Here's the result of the query:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââ¬ââââââââââââââââââââââââââââââ¬ââââââââââââ
â   city_name   â         country_name        â continent â
â    utf8view   â           utf8view          â  utf8view â
âââââââââââââââââªââââââââââââââââââââââââââââââªââââââââââââ¡
â Suva          â Fiji                        â Oceania   â
âââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââ¤
â Dodoma        â United Republic of Tanzania â Africa    â
âââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââ¤
â Dar es Salaam â United Republic of Tanzania â Africa    â
âââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââ
&lt;/code&gt;
    &lt;p&gt;The example above performs a point-in-polygon join, mapping city locations (points) to the countries they fall within (polygons). SedonaDB executes these joins efficiently by leveraging spatial indices where beneficial and dynamically adapting join strategies at runtime using input data samples. While many general-purpose engines struggle with the performance of such operations, SedonaDB is purpose-built for spatial workloads and delivers consistently fast results.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð Apache Sedona SpatialBench¶&lt;/head&gt;
    &lt;p&gt;To test our work on SedonaDB, we also needed to develop a mechanism to evaluate its performance and speed. This led us to develop Apache Sedona SpatialBench, a benchmark for assessing geospatial SQL analytics query performance across database systems.&lt;/p&gt;
    &lt;p&gt;Let's compare the performance of SedonaDB vs. GeoPandas and DuckDB Spatial for some representative spatial queries as defined in SpatialBench.&lt;/p&gt;
    &lt;p&gt;Here are the results from SpatialBench v0.1 for Queries 1â12 at scale factor 1 (SF1) and scale factor 10 (SF10).&lt;/p&gt;
    &lt;p&gt;SedonaDB demonstrates balanced performance across all query types and scales effectively to SF 10. DuckDB excels at spatial filters and some geometric operations but faces challenges with complex joins and KNN queries. GeoPandas, while popular in the Python ecosystem, requires manual optimization and parallelization to handle larger datasets effectively. An in-depth performance analysis can be found in the SpatialBench website.&lt;/p&gt;
    &lt;p&gt;Hereâs an example of the SpatialBench Query #8 that works for SedonaDB and DuckDB:&lt;/p&gt;
    &lt;code&gt;SELECT b.b_buildingkey, b.b_name, COUNT(*) AS nearby_pickup_count
FROM trip t JOIN building b ON ST_DWithin(ST_GeomFromWKB(t.t_pickuploc), ST_GeomFromWKB(b.b_boundary), 0.0045) -- ~500m
GROUP BY b.b_buildingkey, b.b_name
ORDER BY nearby_pickup_count DESC
&lt;/code&gt;
    &lt;p&gt;This query intentionally performs a distance-based spatial join between points and polygons, followed by an aggregation of the results.&lt;/p&gt;
    &lt;p&gt;Here's what the query returns:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââ¬âââââââââââ¬ââââââââââââââââââââââ
â b_buildingkey â  b_name  â nearby_pickup_count â
â     int64     â utf8view â        int64        â
âââââââââââââââââªâââââââââââªââââââââââââââââââââââ¡
â          3779 â linen    â                  42 â
âââââââââââââââââ¼âââââââââââ¼ââââââââââââââââââââââ¤
â         19135 â misty    â                  36 â
âââââââââââââââââ¼âââââââââââ¼ââââââââââââââââââââââ¤
â          4416 â sienna   â                  26 â
âââââââââââââââââ´âââââââââââ´ââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;Hereâs the equivalent GeoPandas code:&lt;/p&gt;
    &lt;code&gt;trips_df = pd.read_parquet(data_paths["trip"])
trips_df["pickup_geom"] = gpd.GeoSeries.from_wkb(
    trips_df["t_pickuploc"], crs="EPSG:4326"
)
pickups_gdf = gpd.GeoDataFrame(trips_df, geometry="pickup_geom", crs="EPSG:4326")

buildings_df = pd.read_parquet(data_paths["building"])
buildings_df["boundary_geom"] = gpd.GeoSeries.from_wkb(
    buildings_df["b_boundary"], crs="EPSG:4326"
)
buildings_gdf = gpd.GeoDataFrame(
    buildings_df, geometry="boundary_geom", crs="EPSG:4326"
)

threshold = 0.0045  # degrees (~500m)
result = (
    buildings_gdf.sjoin(pickups_gdf, predicate="dwithin", distance=threshold)
    .groupby(["b_buildingkey", "b_name"], as_index=False)
    .size()
    .rename(columns={"size": "nearby_pickup_count"})
    .sort_values(["nearby_pickup_count", "b_buildingkey"], ascending=[False, True])
    .reset_index(drop=True)
)
&lt;/code&gt;
    &lt;head rend="h2"&gt;ðºï¸ SedonaDB CRS management¶&lt;/head&gt;
    &lt;p&gt;SedonaDB manages the CRS when reading/writing files, as well as in DataFrames, making your pipelines safer and saving you from manual work.&lt;/p&gt;
    &lt;p&gt;Let's compute the number of buildings in the state of Vermont to highlight the CRS management features embedded in SedonaDB.&lt;/p&gt;
    &lt;p&gt;Start by reading in a FlatGeobuf file that uses the EPSG 32618 CRS with GeoPandas and then convert it to a SedonaDB DataFrame:&lt;/p&gt;
    &lt;code&gt;import geopandas as gpd

path = "https://raw.githubusercontent.com/geoarrow/geoarrow-data/v0.2.0/example-crs/files/example-crs_vermont-utm.fgb"
gdf = gpd.read_file(path)
vermont = sd.create_data_frame(gdf)
&lt;/code&gt;
    &lt;p&gt;Letâs check the schema of the &lt;code&gt;vermont&lt;/code&gt; DataFrame:&lt;/p&gt;
    &lt;code&gt;vermont.schema

SedonaSchema with 1 field:
  geometry: wkb &amp;lt;epsg:32618&amp;gt;
&lt;/code&gt;
    &lt;p&gt;We can see that the &lt;code&gt;vermont&lt;/code&gt; DataFrame maintains the CRS thatâs specified in the FlatGeobuf file.  SedonaDB doesnât have a native FlatGeobuf reader yet, but itâs easy to use the GeoPandas FlatGeobuf reader and then convert it to a SedonaDB DataFrame with a single line of code.&lt;/p&gt;
    &lt;p&gt;Now read a GeoParquet file into a SedonaDB DataFrame.&lt;/p&gt;
    &lt;code&gt;buildings = sd.read_parquet(
    "https://github.com/geoarrow/geoarrow-data/releases/download/v0.2.0/microsoft-buildings_point_geo.parquet"
)
&lt;/code&gt;
    &lt;p&gt;Check the schema of the DataFrame:&lt;/p&gt;
    &lt;code&gt;buildings.schema

SedonaSchema with 1 field:
  geometry: geometry &amp;lt;ogc:crs84&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Letâs expose these two tables as views and run a spatial join to see how many buildings are in Vermont:&lt;/p&gt;
    &lt;code&gt;buildings.to_view("buildings", overwrite=True)
vermont.to_view("vermont", overwrite=True)

sd.sql(
    """
select count(*) from buildings
join vermont
where ST_Intersects(buildings.geometry, vermont.geometry)
"""
).show()
&lt;/code&gt;
    &lt;p&gt;This command correctly errors out because the tables have different CRSs. For safety, SedonaDB errors out rather than give you the wrong answer! Here's the error message that's easy to debug:&lt;/p&gt;
    &lt;code&gt;SedonaError: type_coercion
caused by
Error during planning: Mismatched CRS arguments: ogc:crs84 vs epsg:32618
Use ST_Transform() or ST_SetSRID() to ensure arguments are compatible.
&lt;/code&gt;
    &lt;p&gt;Letâs rewrite the spatial join to convert the &lt;code&gt;vermont&lt;/code&gt; CRS to EPSG:4326, so itâs compatible with the &lt;code&gt;buildings&lt;/code&gt; CRS.&lt;/p&gt;
    &lt;code&gt;sd.sql(
    """
select count(*) from buildings
join vermont
where ST_Intersects(buildings.geometry, ST_Transform(vermont.geometry, 'EPSG:4326'))
"""
).show()
&lt;/code&gt;
    &lt;p&gt;We now get the correct result!&lt;/p&gt;
    &lt;code&gt;ââââââââââââ
â count(*) â
â   int64  â
ââââââââââââ¡
â   361856 â
ââââââââââââ
&lt;/code&gt;
    &lt;p&gt;SedonaDB tracks the CRS when reading/writing files, converting to/from GeoPandas DataFrames, or when performing DataFrame operations, so your spatial computations run safely and correctly!&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¯ Realistic example with SedonaDB¶&lt;/head&gt;
    &lt;p&gt;Let's now turn our attention to a KNN join, which is a more complex spatial operation.&lt;/p&gt;
    &lt;p&gt;Suppose you're analyzing ride-sharing data and want to identify which buildings are most commonly near pickup points, helping understand the relationship between trip origins and nearby landmarks, businesses, or residential structures that might influence ride demand patterns.&lt;/p&gt;
    &lt;p&gt;This query finds the five closest buildings to each trip pickup location using spatial nearest neighbor analysis. For every trip, it identifies the five buildings that are geographically closest to where the passenger was picked up and calculates the exact distance to each of those buildings.&lt;/p&gt;
    &lt;p&gt;Hereâs the query:&lt;/p&gt;
    &lt;code&gt;WITH trip_with_geom AS (
    SELECT t_tripkey, t_pickuploc, ST_GeomFromWKB(t_pickuploc) as pickup_geom
    FROM trip
),
building_with_geom AS (
    SELECT b_buildingkey, b_name, b_boundary, ST_GeomFromWKB(b_boundary) as boundary_geom
    FROM building
)
SELECT
    t.t_tripkey,
    t.t_pickuploc,
    b.b_buildingkey,
    b.b_name AS building_name,
    ST_Distance(t.pickup_geom, b.boundary_geom) AS distance_to_building
FROM trip_with_geom t JOIN building_with_geom b
ON ST_KNN(t.pickup_geom, b.boundary_geom, 5, FALSE)
ORDER BY distance_to_building ASC, b.b_buildingkey ASC
&lt;/code&gt;
    &lt;p&gt;Here are the results of the query:&lt;/p&gt;
    &lt;code&gt;âââââââââââââ¬ââââââââââââââââââââââââââââââââ¬ââââââââââââââââ¬ââââââââââââââââ¬âââââââââââââââââââââââ
â t_tripkey â          t_pickuploc          â b_buildingkey â building_name â distance_to_building â
â   int64   â             binary            â     int64     â      utf8     â        float64       â
âââââââââââââªââââââââââââââââââââââââââââââââªââââââââââââââââªââââââââââââââââªâââââââââââââââââââââââ¡
â   5854027 â 01010000001afa27b85825504001â¦ â            79 â gainsboro     â                  0.0 â
âââââââââââââ¼ââââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââ¤
â   3326828 â 01010000001bfcc5b8b7a95d4083â¦ â           466 â deep          â                  0.0 â
âââââââââââââ¼ââââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââ¤
â   1239844 â 0101000000ce471770d6ce2a40f9â¦ â           618 â ivory         â                  0.0 â
âââââââââââââ´ââââââââââââââââââââââââââââââââ´ââââââââââââââââ´ââââââââââââââââ´âââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;This is one of the queries from SpatialBench.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¦ Why SedonaDB was built in Rust¶&lt;/head&gt;
    &lt;p&gt;SedonaDB is built in Rust, a high-performance, memory-safe language that offers fine-grained memory management and a mature ecosystem of data libraries. It takes full advantage of this ecosystem by integrating with projects such as Apache DataFusion, GeoArrow, and georust/geo.&lt;/p&gt;
    &lt;p&gt;While Spark provides extension points that let SedonaSpark optimize spatial queries in distributed settings, DataFusion offers stable APIs for pruning, spatial operators, and optimizer rules on a single node. This enabled us to embed deep spatial awareness into the engine while preserving full non-spatial functionality. Thanks to the DataFusion project and community, the experience was both possible and enjoyable.&lt;/p&gt;
    &lt;head rend="h2"&gt;âï¸ Why SedonaDB and SedonaSpark are Both Needed¶&lt;/head&gt;
    &lt;p&gt;SedonaSpark is well-suited for large-scale geospatial workloads or environments where Spark is already part of your production stack. For instance, joining a 100 GB vector dataset with a large raster dataset. For smaller datasets, however, Spark's distributed architecture can introduce unnecessary overhead, making it slower to run locally, harder to install, and more difficult to tune.&lt;/p&gt;
    &lt;p&gt;SedonaDB is better for smaller datasets and when running computations locally. The SedonaDB spatial functions are compatible with the SedonaSpark functions, so SQL chunks that work for one engine will usually work for the other. Over time, we will ensure that both project APIs are fully interoperable. Here's an example of a chunk to analyze the Overture buildings table that works for both engines.&lt;/p&gt;
    &lt;code&gt;nyc_bbox_wkt = (
    "POLYGON((-74.2591 40.4774, -74.2591 40.9176, -73.7004 40.9176, -73.7004 40.4774, -74.2591 40.4774))"
)

sd.sql(f"""
SELECT
    id,
    height,
    num_floors,
    roof_shape,
    ST_Centroid(geometry) as centroid
FROM
    buildings
WHERE
    is_underground = FALSE
    AND height IS NOT NULL
    AND height &amp;gt; 20
    AND ST_Intersects(geometry, ST_SetSRID(ST_GeomFromText('{nyc_bbox_wkt}'), 4326))
LIMIT 5;
&lt;/code&gt;
    &lt;head rend="h2"&gt;ð Next steps¶&lt;/head&gt;
    &lt;p&gt;While SedonaDB is well-tested and provides a core set of features that can perform numerous spatial analyses, it remains an early-stage project with multiple opportunities for new features.&lt;/p&gt;
    &lt;p&gt;Many more ST functions are required. Some are relatively straightforward, but others are complex.&lt;/p&gt;
    &lt;p&gt;The community will add built-in support for other spatial file formats, such as GeoPackage and GeoJSON, to SedonaDB. You can read data in these formats into GeoPandas DataFrames and convert them to SedonaDB DataFrames in the meantime.&lt;/p&gt;
    &lt;p&gt;Raster support is also on the roadmap, which is a complex undertaking, so it's an excellent opportunity to contribute if you're interested in solving challenging problems with Rust.&lt;/p&gt;
    &lt;p&gt;Refer to the SedonaDB v0.2 milestone for more details on the specific tasks outlined for the next release. Additionally, feel free to create issues, comment on the Discord, or start GitHub discussions to brainstorm new features.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¤ Join the community¶&lt;/head&gt;
    &lt;p&gt;The Apache Sedona community has an active Discord community, monthly user meetings, and regular contributor meetings.&lt;/p&gt;
    &lt;p&gt;SedonaDB welcomes contributions from the community. Feel free to request to take ownership of an issue, and we will be happy to assign it to you. You're also welcome to join the contributor meetings, and the other active contributors will be glad to help you get your pull request over the finish line!&lt;/p&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;Weâre celebrating the launch of SedonaDB &amp;amp; SpatialBench with a special Apache Sedona Community Office Hour!&lt;/p&gt;
    &lt;p&gt;ð October 7, 2025&lt;/p&gt;
    &lt;p&gt;â° 8â9 AM Pacific Time&lt;/p&gt;
    &lt;p&gt;ð Online&lt;/p&gt;
    &lt;p&gt;ð Sign up here&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362206</guid><pubDate>Wed, 24 Sep 2025 16:00:45 +0000</pubDate></item><item><title>New bacteria, and two potential antibiotics, discovered in soil</title><link>https://www.rockefeller.edu/news/38239-hundreds-of-new-bacteria-and-two-potential-antibiotics-found-in-soil/</link><description>&lt;doc fingerprint="7c5460762d250ab9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Hundreds of new bacteria, and two potential antibiotics, found in soil&lt;/head&gt;
    &lt;p&gt;Most bacteria cannot be cultured in the lab—and that’s been bad news for medicine. Many of our frontline antibiotics originated from microbes, yet as antibiotic resistance spreads and drug pipelines run dry, the soil beneath our feet has a vast hidden reservoir of untapped lifesaving compounds.&lt;/p&gt;
    &lt;p&gt;Now, researchers have developed a way to access this microbial goldmine. Their approach, published in Nature Biotechnology, circumvents the need to grow bacteria in the lab by extracting very large DNA fragments directly from soil to piece together the genomes of previously hidden microbes, and then mines resulting genomes for bioactive molecules.&lt;/p&gt;
    &lt;p&gt;From a single forest sample, the team generated hundreds of complete bacterial genomes never seen before, as well as two new antibiotic leads. The findings offer a scalable way to scour unculturable bacteria for new drug leads—and expose the vast, uncharted microbial frontier that shapes our environment.&lt;/p&gt;
    &lt;p&gt;“We finally have the technology to see the microbial world that have been previously inaccessible to humans,” says Sean F. Brady, head of the Laboratory of Genetically Encoded Small Molecules at Rockefeller. “And we’re not just seeing this information; we’re already turning it into potentially useful antibiotics. This is just the tip of the spear.”&lt;/p&gt;
    &lt;p&gt;Microbial dark matter&lt;/p&gt;
    &lt;p&gt;When hunting for bacteria, soil is an obvious choice. It’s the largest, most biodiverse reservoir of bacteria on the planet—a single teaspoon of it may contain thousands of different species. Many important therapeutics, including most of our antibiotic arsenal, were discovered in the tiny fraction of soil bacteria that can be grown in the laboratory. And soil is dirt cheap.&lt;/p&gt;
    &lt;p&gt;Yet we know very little about the millions of microbes packed into the earth. Scientists suspect that these hidden bacteria hold not only an untapped reservoir of new therapeutics, but clues as to how microbes shape climate, agriculture, and the larger environment that we live in. “All over the world there’s this hidden ecosystem of microbes that could have dramatic effects on our lives,” Brady adds. “We wanted to finally see them.”&lt;/p&gt;
    &lt;p&gt;Getting that glimpse involved weaving together several approaches. First, the team optimized a method for isolating large, high-quality DNA fragments directly from soil. Pairing this advance with emerging long-read nanopore sequencing allowed Jan Burian, a postdoctoral associate in the Brady lab, to produce continuous stretches of DNA that were tens of thousands of base pairs long—200 times longer than any previously existing technology could manage. Soil DNA contains a huge number of different bacteria; without such large DNA sequences to work with, resolving that complex genetic puzzle into complete and contiguous genomes for disparate bacteria proved exceedingly difficult.&lt;/p&gt;
    &lt;p&gt;“It’s easier to assemble a whole genome out of bigger pieces of DNA, rather than the millions of tiny snippets that were available before,” Brady says. “And that makes a dramatic difference in your confidence in your results.”&lt;/p&gt;
    &lt;p&gt;Unique small molecules, like antibiotics, that bacteria produce are called “natural products”. To convert the newly uncovered sequences into bioactive molecules, the team applied a synthetic bioinformatic natural products (synBNP) approach. They bioinformatically predicted the chemical structures of natural products directly from the genome data and then chemically synthesized them in the lab. With the synBNP approach, Brady and colleagues managed to turn the genetic blueprints from uncultured bacteria into actual molecules—including two potent antibiotics.&lt;/p&gt;
    &lt;p&gt;Brady describes the method, which is scalable and can be adapted to virtually any metagenomic space beyond soil, as a three-step strategy that could kick off a new era of microbiology: “Isolate big DNA, sequence it, and computationally convert it into something useful.”&lt;/p&gt;
    &lt;p&gt;Two new drug candidates, and counting&lt;/p&gt;
    &lt;p&gt;Applied to their single forest soil sample, the team’s approach produced 2.5 terabase-pairs of sequence data—the deepest long-read exploration of a single soil sample to date. Their analysis uncovered hundreds of complete contiguous bacterial genomes, more than 99 percent of which were entirely new to science and identified members from 16 major branches of the bacterial family tree.&lt;/p&gt;
    &lt;p&gt;The two lead compounds discovered could translate into potent antibiotics. One, called erutacidin, disrupts bacterial membranes through an uncommon interaction with the lipid cardiolipin and is effective against even the most challenging drug-resistant bacteria. The other, trigintamicin, acts on a protein-unfolding motor known as ClpX, a rare antibacterial target.&lt;/p&gt;
    &lt;p&gt;Brady emphasizes that these discoveries are only the beginning. The study demonstrates that previously inaccessible microbial genomes can now be decoded and mined for bioactive molecules at scale without culturing the organisms. Unlocking the genetic potential of microbial dark matter may also provide new insights into the hidden microbial networks that sustain ecosystems.&lt;/p&gt;
    &lt;p&gt;“We’re mainly interested in small molecules as therapeutics, but there are applications beyond medicine,” Burian says. “Studying culturable bacteria led to advances that helped shape the modern world and finally seeing and accessing the uncultured majority will drive a new generation of discovery.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362254</guid><pubDate>Wed, 24 Sep 2025 16:03:42 +0000</pubDate></item><item><title>Zed's Pricing Has Changed: LLM Usage Is Now Token-Based</title><link>https://zed.dev/blog/pricing-change-llm-usage-is-now-token-based</link><description>&lt;doc fingerprint="bc0d159f852e9ffe"&gt;
  &lt;main&gt;
    &lt;p&gt;First things first: we still offer, and always plan to offer, multiple ways to use AI in Zed without paying us.&lt;/p&gt;
    &lt;p&gt;So what's changing? We're moving Zed AI from prompt-based limits to token-based pricing. For new users, this pricing is live today. For current users, we're providing advance notice and migration will happen over the next three months. We’re also adding GPT-5 (and mini/nano), Gemini 2.5 Pro, and Gemini 2.5 Flash to Zed’s hosted offering, in addition to the Anthropic models already available.&lt;/p&gt;
    &lt;p&gt;Why? We want our pricing to reflect the real cost of running AI. Token-agnostic prompt structures obscure the cost and are rife with misaligned incentives. This change lets us invest sustainably in the editor features that make Zed fast and reliable. Our short-term revenue growth strategy is to sell enterprise features to businesses, and our long term vision is to earn money by fundamentally improving how developers collaborate. We have to charge for AI features which we get charged for, but it's never been our plan to build a business on LLM token math.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's Changing&lt;/head&gt;
    &lt;head rend="h3"&gt;What's Changed&lt;/head&gt;
    &lt;p&gt;We've simplified our pricing and reduced costs while adding access to more AI models.&lt;/p&gt;
    &lt;head rend="h4"&gt;Key Improvements&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;50% price reduction&lt;/item&gt;
      &lt;item&gt;Token-based billing&lt;/item&gt;
      &lt;item&gt;More AI models included&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;New Models&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPT-5&lt;/item&gt;
      &lt;item&gt;Grok 4&lt;/item&gt;
      &lt;item&gt;Gemini 2.5&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Free&lt;/head&gt;
    &lt;head rend="h4"&gt;Old Pricing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2,000 accepted edit predictions&lt;/item&gt;
      &lt;item&gt;50 Zed-hosted prompts per month&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;New Pricing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2,000 accepted edit predictions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Pro&lt;/head&gt;
    &lt;head rend="h4"&gt;Old Pricing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unlimited accepted edit predictions&lt;/item&gt;
      &lt;item&gt;$20/month&lt;/item&gt;
      &lt;item&gt;500 prompts per month&lt;/item&gt;
      &lt;item&gt;Additional usage billed by prompt&lt;/item&gt;
      &lt;item&gt;Claude Sonnet and Claude Opus&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;New Pricing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Unlimited accepted edit predictions&lt;/item&gt;
      &lt;item&gt;$10/month&lt;/item&gt;
      &lt;item&gt;$5 of token credits included&lt;/item&gt;
      &lt;item&gt;Additional usage billed at API list price +10%&lt;/item&gt;
      &lt;item&gt;Claude Sonnet, Claude Opus, GPT-5 + mini/nano, and Gemini 2.5 Pro/Flash&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Pro Trial&lt;/head&gt;
    &lt;head rend="h4"&gt;Old Pricing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Free for 14 days&lt;/item&gt;
      &lt;item&gt;Unlimited accepted edit predictions&lt;/item&gt;
      &lt;item&gt;150 prompts included&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;New Pricing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Free for 14 days&lt;/item&gt;
      &lt;item&gt;Unlimited accepted edit predictions&lt;/item&gt;
      &lt;item&gt;$20 of token credits included&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Old Pricing&lt;/head&gt;
    &lt;head rend="h2"&gt;New Pricing&lt;/head&gt;
    &lt;head rend="h2"&gt;Free&lt;/head&gt;
    &lt;head rend="h2"&gt;Pro&lt;/head&gt;
    &lt;head rend="h2"&gt;Pro Trial&lt;/head&gt;
    &lt;head rend="h2"&gt;A Wealth of Alternatives&lt;/head&gt;
    &lt;p&gt;Your Zed Pro bill may go up or down based on how you use AI. That's why we're giving Zed Pro customers 3 months notice before migration to the new pricing structure, and we have invested heavily in alternative options for using AI in Zed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bring your own API keys, direct with LLM providers like OpenAI, Anthropic, Grok, and many more&lt;/item&gt;
      &lt;item&gt;Use local models like Ollama&lt;/item&gt;
      &lt;item&gt;Access third-party agents through ACP, like Gemini CLI and Claude Code (more coming soon!)&lt;/item&gt;
      &lt;item&gt;Spend through GitHub Copilot, OpenRouter, AWS Bedrock, and other LLM payment hubs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can also disable AI in Zed entirely if you prefer to keep your editor free of AI features.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why We're Making Changes&lt;/head&gt;
    &lt;p&gt;Current pricing is too expensive for Zed. LLM bills have become our biggest expense, and more paying customers translates to more money lost. We could spend more resources trying to find the right "unlimited" price point that would balance out costs, but it's much simpler to switch to the obvious pricing model of charging based on what providers charge us. This lets us keep our focus where it belongs: building the world's best code editor.&lt;/p&gt;
    &lt;p&gt;Prompt-based pricing is decoupled from user value. In our current system, asking Sonnet to fix a typo costs the same as a complex multi-file refactor. Token-based pricing means you pay for what you actually use, plus a 10% markup that covers Zed’s infrastructure, support costs, and the increased rate limits available for Zed Pro users compared to average BYOK users.&lt;/p&gt;
    &lt;p&gt;Better incentive alignment, reduced complexity. With token-based pricing, you can add as much or as little context as you want. The only limit is the cost you decide is worth it, not an arbitrary prompt cap. We ourselves would get confused about when “burn mode” was needed, and what usage should or shouldn’t cost a prompt. It also simplifies the addition of new models to Zed Pro: we plan to maintain “list price + 10%” for any new model we add to Zed’s hosted offering.&lt;/p&gt;
    &lt;p&gt;Subsidize with specificity. Our old free plan subsidized inference without a concrete goal. Changing our pricing helps us focus resources on targeted programs like discounts for students that are better aligned with Zed’s mission. Every user can still use our 14-day trial to evaluate Zed Pro, even if you trialed Zed Pro in our old pricing structure.&lt;/p&gt;
    &lt;head rend="h2"&gt;Migration Timeline&lt;/head&gt;
    &lt;p&gt;If you're an existing customer, you should already have received an email with your specific migration details. Here's the timeline again for reference:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pro customers have until December 17, 2025 to migrate, giving you three months to plan ahead. If you decide to cancel Zed Pro, you’ll be moved to our new Free plan on the day your subscription ends. If you'd prefer to migrate earlier to access the new models, email [email protected] and we'll help you switch over.&lt;/item&gt;
      &lt;item&gt;Free users will transition to the new Free plan on October 15, 2025. You'll also get a fresh 14-day Pro trial with $20 in token credits to test out our new pricing model, even if you used a Pro trial in the past. You can start this trial any time, starting today. Note that starting this new Pro trial will move you to our new Free plan after its conclusion.&lt;/item&gt;
      &lt;item&gt;Trial users are being moved back to our old Free plan today, September 24th. You'll follow the same migration path as Free users above. You will also get a fresh trial that can be started any time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Looking for a better editor?&lt;/head&gt;
    &lt;p&gt;You can try Zed today on macOS or Linux. Download now!&lt;/p&gt;
    &lt;head rend="h3"&gt;We are hiring!&lt;/head&gt;
    &lt;p&gt;If you're passionate about the topics we cover on our blog, please consider joining our team to help us ship the future of software development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362425</guid><pubDate>Wed, 24 Sep 2025 16:13:49 +0000</pubDate></item><item><title>Better Curl Saul: a lightweight API testing CLI focused on UX and simplicity</title><link>https://github.com/DeprecatedLuar/better-curl-saul</link><description>&lt;doc fingerprint="2d3c9d587d87d1a0"&gt;
  &lt;main&gt;
    &lt;code&gt;curl -X POST https://api.github.com/repos/owner/repo/issues \
  -H "Authorization: Bearer ghp_token123" \
  -H "Content-Type: application/json" \
  -H "Accept: application/vnd.github.v3+json" \
  -d '{
    "title": "Bug Report",
    "body": "Something is broken",
    "labels": ["bug", "priority-high"],
    "assignees": ["developer1", "developer2"]
  }'&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Workspace-based - Each API gets its own organized folder&lt;/item&gt;
      &lt;item&gt;Smart variables - &lt;code&gt;{@token}&lt;/code&gt;persists,&lt;code&gt;{?name}&lt;/code&gt;prompts every time&lt;/item&gt;
      &lt;item&gt;Response filtering - Show only the fields you care about&lt;/item&gt;
      &lt;item&gt;Git-friendly - TOML files version control beautifully&lt;/item&gt;
      &lt;item&gt;Unix composable - Script it, pipe it, shell it&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Supports: Linux, macOS, Windows (I hope)&lt;/p&gt;
    &lt;code&gt;curl -sSL https://raw.githubusercontent.com/DeprecatedLuar/better-curl-saul/main/install.sh | bash&lt;/code&gt;
    &lt;head&gt;Other Install Methods&lt;/head&gt;
    &lt;p&gt;Manual Install (boring)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download binary for your OS from releases&lt;/item&gt;
      &lt;item&gt;Make executable: &lt;code&gt;chmod +x saul-*&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Move to PATH: &lt;code&gt;sudo mv saul-* /usr/local/bin/saul&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;From Source (for try-harders)&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/DeprecatedLuar/better-curl-saul.git
cd better-curl-saul
./other/install-local.sh  # Local development build&lt;/code&gt;
    &lt;p&gt;In case you already have Saul (hardcore)&lt;/p&gt;
    &lt;code&gt;saul set url https://raw.githubusercontent.com/DeprecatedLuar/better-curl-saul/main/install.sh &amp;amp;&amp;amp; saul call --raw | bash #(maybe works, who knows)&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;[!NOTE] Quick install auto-detects your system and downloads binaries or builds from source as fallback. Windows users: I don't know powershell I expect, just have bash 👍&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head&gt;Quick Start&lt;/head&gt;
    &lt;code&gt;# Create a test workspace
saul demo set url https://jsonplaceholder.typicode.com/posts/1
saul demo set method GET
saul demo call

# Try with variables
saul api set url https://httpbin.org/post
saul api set method POST
saul api set body name={?your_name} message="Hello from Saul"
saul api call

# Oh... yeah, for nesting just use dot notation like obj.field=idk&lt;/code&gt;
    &lt;head&gt;Core Commands&lt;/head&gt;
    &lt;p&gt;Alright so you can:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;set&lt;/code&gt;, &lt;code&gt;get&lt;/code&gt;, &lt;code&gt;edit&lt;/code&gt;, &lt;code&gt;rm&lt;/code&gt;&lt;lb/&gt;your&lt;code&gt;body&lt;/code&gt;, &lt;code&gt;header&lt;/code&gt;, &lt;code&gt;query&lt;/code&gt;, &lt;code&gt;request&lt;/code&gt;, &lt;code&gt;history&lt;/code&gt; or maybe even
&lt;code&gt;response&lt;/code&gt;
&lt;lb/&gt;also&lt;code&gt;url&lt;/code&gt;, &lt;code&gt;method&lt;/code&gt;, &lt;code&gt;timeout&lt;/code&gt;, &lt;code&gt;history&lt;/code&gt;&lt;/p&gt;
    &lt;head&gt;Example&lt;/head&gt;
    &lt;code&gt;# Configure your API workspace (or preset, same thing)
saul [workspace] set url https://api.example.com
saul set method POST
saul set header Authorization="Bearer {@token}"
saul set body user.name={?username} user.email=john@test.com

# Execute the request
saul call

# Check your configuration, note that preset/workspace name keeps
# stored in memory after first mention on syntax

saul [anoter_workspace] check url
saul check body

# View response history
saul check history&lt;/code&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;There are 2 variable types&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;soft variables {?} prompt you at EVERY call&lt;/item&gt;
      &lt;item&gt;hard variables {@} require manual update by running the flag -v or running &lt;code&gt;saul set variable varname value&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start watchin Better Call Saul&lt;/item&gt;
      &lt;item&gt;Think of a bad joke&lt;/item&gt;
      &lt;item&gt;Workspace-based configuration&lt;/item&gt;
      &lt;item&gt; Smart variable system (&lt;code&gt;{@}&lt;/code&gt;/&lt;code&gt;{?}&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;In line terminal field editing&lt;/item&gt;
      &lt;item&gt;Response filtering&lt;/item&gt;
      &lt;item&gt;Response history&lt;/item&gt;
      &lt;item&gt;Terminal session memory&lt;/item&gt;
      &lt;item&gt;Bulk operations&lt;/item&gt;
      &lt;item&gt;Fix history response parsing and filtering&lt;/item&gt;
      &lt;item&gt;GET specific response stuff from history (aka Headers/Body...)&lt;/item&gt;
      &lt;item&gt;Flags, we've got none basically&lt;/item&gt;
      &lt;item&gt;Stateless command support&lt;/item&gt;
      &lt;item&gt;Support pasting raw JSON template&lt;/item&gt;
      &lt;item&gt;User config system using the super cool github.com/DeprecatedLuar/toml-vars-letsgooo library&lt;/item&gt;
      &lt;item&gt;Add the eastereggs&lt;/item&gt;
      &lt;item&gt;Polish code&lt;/item&gt;
      &lt;item&gt;Actual Documentation&lt;/item&gt;
      &lt;item&gt;Touch Grass (not a priority)&lt;/item&gt;
      &lt;item&gt;Think of more features&lt;/item&gt;
      &lt;item&gt;Think of even more features&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Beta software - Core features work, documentation in progress.&lt;/p&gt;
    &lt;p&gt;Bug or feedback? I will be very, very, very happy if you let me know your thoughts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362486</guid><pubDate>Wed, 24 Sep 2025 16:17:34 +0000</pubDate></item><item><title>Product Hunt is dead</title><link>https://sedimental.org/product_hunt_is_dead.html</link><description>&lt;doc fingerprint="3882b9fdc974d862"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Product Hunt is Dead&lt;/head&gt;
    &lt;p&gt;First, the good news.&lt;/p&gt;
    &lt;p&gt;It's been one week since FinFam's beta launch! The Show HN post trended nicely, netting enough eyeballs to make me confident that FinFam is the world's first and only collaborative financial planner with a marketplace of interactive, open-source expert opinions. I'm especially gratified by the users I'm meeting through the product. Nothing like it.&lt;/p&gt;
    &lt;p&gt;So, launch is going great, no regrets, right?&lt;/p&gt;
    &lt;head rend="h3"&gt;My one regret&lt;/head&gt;
    &lt;p&gt;That brings us to the subject of today's PSA.&lt;/p&gt;
    &lt;p&gt;Product Hunt is dead.&lt;/p&gt;
    &lt;p&gt;I wasn't planning this post. PH wasn't even much of a launch priority for FinFam. But after seeing what I saw, I knew this had to skip the queue. The world had to know.&lt;/p&gt;
    &lt;p&gt;After all, my launch post on LinkedIn mentioned our ProductHunt launch. And now I'm cringing thinking about how I even sent an email out to few product-oriented friends linking them to our launch, perpetuating the myth.&lt;/p&gt;
    &lt;p&gt;Hours later I would realize that Product Hunt is sadly no more. Gone was the site I knew from my days on Stripe Invoicing. What's left is a husk, active in appearance alone.&lt;/p&gt;
    &lt;head rend="h3"&gt;I missed the memo&lt;/head&gt;
    &lt;p&gt;Turns out this has been happening for a while. Just last year, Fabian Maume asked, "Is Product Hunt Dying?" He's got lots of data and background, so I'll stick to filling in the now-obvious answer: Yes. Product Hunt is dead.&lt;/p&gt;
    &lt;p&gt;And Fabian's not alone. A quick search will reveal dozens of nails in the coffin. I guess that's inevitable when the founder exits and in 2022 a16z merges your mature platform with a crypto venture that no one remembers.&lt;/p&gt;
    &lt;p&gt;But how does a dead platform appear to live on?&lt;/p&gt;
    &lt;head rend="h3"&gt;The Zombie Grift&lt;/head&gt;
    &lt;p&gt;Product Hunt has a weird quirk where it resets every day at midnight Pacific time. Unlike Hacker News, Reddit, etc., PH doesn't have a rolling front page. This fixed daily scheduling idiosyncrasy leads to all-nighters as launch best practice, and systemically, this means a platform originating in Silicon Valley is unlikely to have its front page content meaningfully decided by anyone in the western hemisphere.&lt;/p&gt;
    &lt;p&gt;Much like with Hacker News, the first few hours of a post determine its impact. Instead, Europe, APAC, and in particular India have an outsized influence.&lt;/p&gt;
    &lt;p&gt;So what really happens when you launch on Product Hunt?&lt;/p&gt;
    &lt;p&gt;Well, your LinkedIn inbox turns into this:&lt;/p&gt;
    &lt;p&gt;I was taken by surprise. What hurt the most was these midnight solicitors sharing screenshots of success stories from companies I recognized. They'd been instrumental in "launching" apps that I respect, and I'd hoped they wouldn't have to stoop to this. I even had personal connections to some of these founders.&lt;/p&gt;
    &lt;p&gt;It was 4am, but I put on my investigative hat and I engaged with a couple. Here's how their process looks:&lt;/p&gt;
    &lt;p&gt;$100 is all it takes to make it into the Top 5 for a weekday. One has to admit, it's tempting. If you've spent months building, $100 feels like nothing.&lt;/p&gt;
    &lt;p&gt;It is nothing. These aren't real users and PH's audience has never been a source of sticky users. $100 is too much to spend on vanity. And it's predatory to foster a "community" where clout peddlers can prey on susceptible, good-faith founders.&lt;/p&gt;
    &lt;p&gt;If you're curious, you can see the paid votes landing via spikes in upvote speed on hunted.space. It's not hard to eyeball products which get more upvotes in the first two hours than they do in the next twenty-two.&lt;/p&gt;
    &lt;p&gt;Suffice to say I didn't get any emails or LinkedIn invites from HN vote peddlers, despite HN sending us more than 10x the traffic.&lt;/p&gt;
    &lt;head rend="h3"&gt;Can Product Hunt be revived?&lt;/head&gt;
    &lt;p&gt;To be fair, PH tries to mitigate front page manipulation. They "feature" certain launches to curate the front page. The main outcome is that the majority of launches are simply never shown to most users. No non-featured launches appear on the mobile app. The process is documented, but still opaque and inconsistently applied. Almost certainly ties into revenue somehow.&lt;/p&gt;
    &lt;p&gt;A better question is "Should Product Hunt be revived?"&lt;/p&gt;
    &lt;p&gt;This is far from PH's only problem. They've killed Ship and other features without replacements.&lt;/p&gt;
    &lt;p&gt;At the crux, I just don't think a "launch" or a "product" is enough to tie together a community to develop a healthy ecosystem. The focus on the new draws a fast flow of products and builders that erodes the core community.&lt;/p&gt;
    &lt;p&gt;Alternatives exist, but if Product Hunt suffers from the above, I suspect these do, too:&lt;/p&gt;
    &lt;p&gt;Edit: Someone even made a directory of directories. Early reports are not promising!&lt;/p&gt;
    &lt;p&gt;Contrast this with Indie Hackers, which is united by at least one value / work ethic.&lt;/p&gt;
    &lt;p&gt;Or contrast to one of my personal faves: AlternativeTo, which takes a wiki approach toward the mission of cataloging all software, not just the newest.&lt;/p&gt;
    &lt;head rend="h3"&gt;Goodbye Product Hunt&lt;/head&gt;
    &lt;p&gt;I guess if this ends up being PH's epitaph I should get this out of my system:&lt;/p&gt;
    &lt;p&gt;Google Glass Kitty has always been a terrible mascot.&lt;/p&gt;
    &lt;p&gt;The obvious choice for an iconic hunt has always been the duck:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362569</guid><pubDate>Wed, 24 Sep 2025 16:23:33 +0000</pubDate></item><item><title>Terence Tao: The role of small organizations in society has shrunk significantly</title><link>https://mathstodon.xyz/@tao/115259943398316677</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362697</guid><pubDate>Wed, 24 Sep 2025 16:32:24 +0000</pubDate></item><item><title>Launch HN: Flywheel (YC S25) – Waymo for Excavators</title><link>https://news.ycombinator.com/item?id=45362914</link><description>&lt;doc fingerprint="2c7449d6851a3652"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, We're Jash and Mahimana, cofounders of Flywheel AI (&lt;/p&gt;https://useflywheel.ai&lt;p&gt;). We’re building a remote teleop and autonomous stack for excavators.&lt;/p&gt;&lt;p&gt;Here's a video: https://www.youtube.com/watch?v=zCNmNm3lQGk.&lt;/p&gt;&lt;p&gt;Interfacing with existing excavators for enabling remote teleop (or autonomy) is hard. Unlike cars which use drive-by-wire technology, most of the millions of excavators are fully hydraulic machines. The joysticks are connected to a pilot hydraulic circuit, which proportionally moves the cylinders in the main hydraulic circuit which ultimately moves the excavator joints. This means excavators mostly do not have an electronic component to control the joints. We solve this by mechanically actuating the joysticks and pedals inside the excavators.&lt;/p&gt;&lt;p&gt;We do this with retrofits which work on any excavator model/make, enabling us to augment existing machines. By enabling remote teleoperation, we are able to increase site safety, productivity and also cost efficiency.&lt;/p&gt;&lt;p&gt;Teleoperation by the operators enables us to prepare training data for autonomy. In robotics, training data comprises observation and action. While images and videos are abundant on the internet, egocentric (PoV) observation and action data is extremely scarce, and it is this scarcity that is holding back scaling robot learning policies.&lt;/p&gt;&lt;p&gt;Flywheel solves this by preparing the training data coming from our remote teleop-enabled excavators which we have already deployed. And we do this with very minimal hardware setup and resources.&lt;/p&gt;&lt;p&gt;During our time in YC, we did 25-30 iterations of sensor stack and placement permutations/combinations, and model hyperparams variations. We called this “evolution of the physical form of our retrofit”. Eventually, we landed on our current evolution and have successfully been able to train some levels of autonomy with only a few hours of training data.&lt;/p&gt;&lt;p&gt;The big takeaway was how much more important data is than optimizing hyperparams of the model. So today, we’re open sourcing 100hrs of excavator dataset that we collected using Flywheel systems on real construction sites. This is in partnership with Frodobots.ai.&lt;/p&gt;&lt;p&gt;Dataset: https://huggingface.co/datasets/FlywheelAI/excavator-dataset&lt;/p&gt;&lt;p&gt;Machine/retrofit details:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;  Volvo EC380 (38 ton excavator)
  4xcamera (25fps)
  25 hz expert operator’s action data
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt; The dataset contains observation data from 4 cameras and operator's expert action data which can be used to train imitation learning models to run an excavator autonomously for the workflows in those demonstrations, like digging and dumping. We were able to train a small autonomy model for bucket pick and place on Kubota U17 from just 6-7 hours of data collected during YC.&lt;/p&gt;&lt;p&gt;We’re just getting started. We have good amounts of variations in daylight, weather, tasks, and would be adding more hours of data and also converting to lerobot format soon. We’re doing this so people like you and me can try out training models on real world data which is very, very hard to get.&lt;/p&gt;&lt;p&gt;So please checkout the dataset here and feel free to download and use however you like. We would love for people to do things with it! I’ll be around in the thread and look forward to comments and feedback from the community!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45362914</guid><pubDate>Wed, 24 Sep 2025 16:48:27 +0000</pubDate></item><item><title>Tinder, Hinge, and Their Corporate Owner Keep Rape Under Wraps</title><link>https://themarkup.org/investigations/2025/02/13/dating-app-tinder-hinge-cover-up</link><description>&lt;doc fingerprint="ed522d8639b3c7e4"&gt;
  &lt;main&gt;
    &lt;p&gt;The Dating Apps Reporting Project is an 18-month investigation. It was produced in partnership with the Pulitzer Center’s AI Accountability Network and The Markup, now a part of CalMatters, and copublished with The Guardian and The 19th.&lt;/p&gt;
    &lt;p&gt;When a young woman in Denver met up with a smiling cardiologist she matched with on the dating app Hinge, she had no way of knowing that the company behind the app had already received reports from two other women who accused him of rape.&lt;/p&gt;
    &lt;p&gt;She met the 34-year-old doctor with green eyes and thinning hair at Highland Tap &amp;amp; Burger, a sports bar in a trendy neighborhood. It went well enough that she accepted an invitation to go back to his apartment. As she emerged from his bathroom, he handed her a tequila soda.&lt;/p&gt;
    &lt;p&gt;What transpired over the next 24 hours, according to court testimony, reads like every person’s dating app nightmare.&lt;/p&gt;
    &lt;p&gt;After sipping the drink, the woman started to lose control. Her memory blurred. She fell to the ground, and the man started to film her. He put her in a headlock, kissing her forehead; she struggled to free herself but managed to grab her things and leave. He followed her out the door, holding her shoes and trying to force her back inside, but she was able to call an Uber, vomiting in the car on the way home.&lt;/p&gt;
    &lt;p&gt;She woke up at home, soaking wet on her bathroom floor, the key to her house still in her door. She continued vomiting for hours. When she came to, she reported the assault to Hinge.&lt;/p&gt;
    &lt;p&gt;Hinge is one of more than a dozen dating apps owned by Match Group. The $8.5 billion global conglomerate also owns brands like Tinder (the world’s most popular dating app), OkCupid, and Plenty of Fish. Match Group controls half of the world’s online dating market, operates in 190 countries, and facilitates meetups for millions of people.&lt;/p&gt;
    &lt;p&gt;Match Group’s official safety policy states that when a user is reported for assault, “all accounts found that are associated with that user will be banned from our platforms.”&lt;/p&gt;
    &lt;p&gt;So why, on the night of Jan. 25, 2023, was Stephen Matthews still on the app? Just four days before, Match Group had been alerted when another woman reported him for rape. A little more than a week later, he was reported for rape again. This time, the survivor went to the police.&lt;/p&gt;
    &lt;p&gt;None of these women knew that the company had known about his violent behavior for years. He was first reported on Sept. 28, 2020. By then, Match Group’s safety policy was already in place.&lt;/p&gt;
    &lt;p&gt;Even after a police report, it took nearly two months for Matthews to be arrested — the only thing that got him off the apps. By then, at least 15 women would eventually report that Matthews had raped or drugged them. Nearly every one of them had met him on dating apps run by Match Group.&lt;/p&gt;
    &lt;p&gt;On Oct. 25, 2024, a Denver judge sentenced Matthews to 158 years to life in prison after a jury convicted him of 35 counts related to drugging and sexually assaulting eight women, drugging two women, and assaulting one more for a total of 11 women. Attorneys for the women said much of that violence could have been prevented.&lt;/p&gt;
    &lt;p&gt;“It is shocking that for years after receiving reports of sexual assault, Hinge continued to allow Stephen Matthews access to its platforms and actively facilitated his abuse,” said Laura Wolf, the attorney representing the woman whose police report led to the arrest. Following best practices for reporting on sexual assault, the Dating Apps Reporting Project is honoring survivors’ requests for anonymity. Matthews’ attorney, Douglas Cohen, declined to comment. A letter that The Dating Apps Reporting Project sent directly to Matthews in jail went unanswered.&lt;/p&gt;
    &lt;p&gt;Match Group’s reach is so massive — its mission is “to spark meaningful connections for every single person worldwide” — that people are more likely to meet through its apps than out at the bars, at church, or through friends.&lt;/p&gt;
    &lt;p&gt;But Matthews’ case shows that even as these apps have made it easier for us to connect with a seemingly endless pool of potential lovers, they have also made it easier for people who commit sexual abuse to reach a seemingly endless number of potential targets.&lt;/p&gt;
    &lt;p&gt;In 2022, a team of researchers at Brigham Young University published an analysis of hundreds of sexual assaults in Utah. They found attacks facilitated by dating apps happened faster and were more violent than when the perpetrator met the victim through other means. They also found that perpetrators who use dating apps are more likely to target vulnerable people. Almost 60 percent of sexual assault survivors self-reported a mental illness.&lt;/p&gt;
    &lt;p&gt;Match Group has known for years which users have been reported for drugging, assaulting, or raping their dates since at least 2016, according to internal company documents. Since 2019, Match Group’s central database has recorded every user reported for rape and assault across its entire suite of apps; by 2022, the system, known as Sentinel, was collecting hundreds of troubling incidents every week, company insiders say.&lt;/p&gt;
    &lt;p&gt;Match Group promised in 2020 that it would release what’s known as a transparency report — a public document that would reveal data on harm occurring on and off its platforms. If the public were aware of the scale of rape and assault on Match Group apps, they would be able to accurately assess their risk. As of February 2025, the report has not been released.&lt;/p&gt;
    &lt;p&gt;Instead, as people continued to get hurt, the company dithered over what damning information should be hidden. “Do we only publish where we are required by law?” reads a slide in a 2021 presentation shown multiple times to Match Group employees as well as external safety partners. “Do we push back on how much we are required to reveal, or do we try to go beyond what is required?”&lt;/p&gt;
    &lt;p&gt;No online space is risk-free. But while Match Group has long possessed the tools, financial resources, and investigative procedures necessary to make it harder for bad actors to resurface, internal documents show the company has resisted efforts to spread them across its apps, in part because safety protocols could stall corporate growth.&lt;/p&gt;
    &lt;p&gt;“The obsession with metrics and having to stick with them is frustrating and potentially dangerous,” one employee wrote in 2021 after the company learned that the investigative news nonprofit ProPublica was planning a story. “This is not the way we were meant to work and people’s lives are at risk.”&lt;/p&gt;
    &lt;p&gt;The same person asked their superiors: “‘How much would you personally pay to stop just one person being sexually assaulted by a date, one child being trafficked or one vulnerable person being driven to suicide by a predator?’ I feel that if I asked members of our staff that question individually, they would put a high value of their own money on it – But as a group nobody is ready to hear that yet.”&lt;/p&gt;
    &lt;p&gt;Since 2021, Match Group has publicly promised to improve the safety of their products and share data, but company insiders say safety has not improved. A brief hiring spree sparked by congressional and media scrutiny has been largely scaled back, according to former employees. In 2024, the remaining employees from the central trust-and-safety team Match Group set up in response to increased scrutiny were let go and their jobs outsourced to overseas contractors. Facing pressure from Wall Street, Match Group removed CEO Bernard Kim in early February 2025 as he struggled to cut costs and end the steady decline in subscribers to Match Group’s most powerful app, Tinder.&lt;/p&gt;
    &lt;p&gt;Members of Congress have repeatedly requested data from Match Group on sexual harm. In February 2020, 11 members of Congress wrote to then-CEO Shar Dubey asking for details on how the company responds to reports of sexual violence. In July 2023, two Democrats, then-Rep. Annie Kuster of New Hampshire and Rep. Jan Schakowsky of Illinois followed up after we inquired on the status of their efforts. The company has still not provided the data.&lt;/p&gt;
    &lt;p&gt;In September 2024, the House of Representatives passed a bill that requires consumers to be notified if they have interacted with a user on a dating app who has been banned for defrauding consumers of money or personal financial information. But the bill stopped short of addressing the issue of sexual assault on the apps, and it died in the Senate.&lt;/p&gt;
    &lt;p&gt;Our review of hundreds of pages of internal company documents, along with thousands of pages of court records, securities filings, and analyst reports, coupled with dozens of interviews with current and former employees and survivors of sexual violence found women who report being raped get no traction, while accused rapists like Stephen Matthews keep swiping — and assaulting.&lt;/p&gt;
    &lt;p&gt;Our own testing on Match Group apps shows that as of February 2025, not much has changed. Banned Tinder users, including those reported for sexual assault, can easily rejoin or move to another Match Group dating app, all while keeping most of their key personal information exactly the same.&lt;/p&gt;
    &lt;p&gt;The Dating Apps Reporting Project sent Match Group a four-page letter detailing our findings. The company responded with a short statement. The statement did not dispute that Match Group has carefully documented the extent of harm on company apps for years without sharing that information with the public. It also defended the company’s efforts to make platforms safe.&lt;/p&gt;
    &lt;p&gt;“We recognize our role in fostering safer communities and promoting authentic and respectful connections worldwide,” the statement provided by Kayla Whaling, senior director of communications, read. “We will always work to invest in and improve our systems, and search for ways to help our users stay safe, both online and when they connect in real life.”&lt;/p&gt;
    &lt;p&gt;The company said it vigorously combats violence. “We take every report of misconduct seriously, and vigilantly remove and block accounts that have violated our rules regarding this behavior,” its statement read. Our own testing found otherwise.&lt;/p&gt;
    &lt;p&gt;Starting in April 2024, The Dating Apps Reporting Project created a series of Tinder accounts that we subsequently reported for sexual assault. Soon after, Tinder banned the accounts, and we started investigating how easy it would be for a banned user to create new accounts.&lt;/p&gt;
    &lt;p&gt;Repeatedly, we found that users, soon after being banned, could create new Tinder accounts with the exact same name, birthday, and profile photos used on their banned accounts. Users banned from Tinder were also able to sign up for Hinge, OkCupid, and Plenty of Fish without changing those personal details.&lt;/p&gt;
    &lt;p&gt;To get around the Tinder ban, we used techniques commonly suggested by online guides and forums that don’t require lots of technical knowledge to understand. We were able to verify three techniques that allowed banned Match Group users to repeatedly bypass being flagged when creating new accounts.&lt;/p&gt;
    &lt;p&gt;In its statement, Match Group cast itself as an industry leader in deploying technology to promote safety, including “harassment-preventing AI tools, ID verification for profiles, and a portal that helps us better support and communicate with law enforcement investigating crimes. … Every person deserves safe and respectful experiences. We are committed to doing the work to make dating safer on our platforms and beyond,” the statement said.&lt;/p&gt;
    &lt;p&gt;Sept. 28, 2020 — the date Denver cardiologist Stephen Matthews raped a woman who reported him to Hinge — is also the date Tracey Breeden was brought on as Match Group’s head of safety and social advocacy.&lt;/p&gt;
    &lt;p&gt;Breeden was a flashy hire. “With Tracey coming on board, we are reaffirming our commitment not just to be safety leaders in the dating space, but across the entire tech sector,” then-CEO Shar Dubey said.&lt;/p&gt;
    &lt;p&gt;Sporting a trademark black leather jacket and short, slick-backed hair, Breeden went by the nickname “Tornado” during her 15-year career in law enforcement. What made her attractive to Match Group was her most recent job at Uber. She helped the global ride-hailing company revive its reputation after a series of scandals — from persistent reports of harassment of women employees to allegations that it was ignoring sexual assault that occurred during Uber rides.&lt;/p&gt;
    &lt;p&gt;Working for an Algorithm&lt;/p&gt;
    &lt;head rend="h3"&gt;When Drivers Are Attacked, Uber Leaves Police Waiting for Help&lt;/head&gt;
    &lt;p&gt;An investigation by The Markup found that Uber is slow to respond to law enforcement requests, leaving drivers vulnerable to repeated attacks&lt;/p&gt;
    &lt;p&gt;Breeden spearheaded a safety report in 2019 that told the public what Uber knew about nearly every problem, including nationwide reports of intoxicated drivers, traffic fatalities, and incidents of sexual violence. The report became a key metric of success for the company.&lt;/p&gt;
    &lt;p&gt;In hiring Breeden, Match Group hoped to replicate this success across its portfolio of apps. “Corporations,” she said in a press release announcing her arrival, “have a responsibility to help ensure safe experiences for their users.”&lt;/p&gt;
    &lt;p&gt;Breeden’s team garnered public attention for its new safety measures, including partnerships with NGOs, optional AI-assisted photo verification, and a law enforcement portal where police and prosecutors can request data.&lt;/p&gt;
    &lt;p&gt;She also fostered a partnership with Garbo, a startup that offered low-cost background checks. It launched on Tinder in 2022. Experts point out that background checks are not always reliable as they pull from outdated databases, and research suggests that most people who commit sexual abuse do not encounter the criminal justice system. For example, Matthews had no criminal record.&lt;/p&gt;
    &lt;p&gt;During this time, Match Group invested $100 million into safety as a recurring cost, the company said, and boasted about Breeden’s “central safety team.”&lt;/p&gt;
    &lt;p&gt;Her team of veteran safety professionals referred to themselves as “The Avengers,” even donning superhero costumes at company events.&lt;/p&gt;
    &lt;p&gt;But Michael Lawrie called this “safety theater.”&lt;/p&gt;
    &lt;p&gt;Lawrie worked for Match Group for nearly a decade, shaping and leading a safety team for one of the company’s smaller brands, OkCupid. Sometimes working 80-hour weeks, he spent hours, even days, sniffing out savvy users who tried to thwart bans by creating multiple accounts.&lt;/p&gt;
    &lt;p&gt;Over a 30-year career in content moderation, Lawrie said, he saw many users like Stephen Matthews. “You’re dealing with one repeat offender. I’ve dealt with god knows how many repeat offenders,” he said.&lt;/p&gt;
    &lt;p&gt;A yellow Post-it note on the side of Lawrie’s computer listed out some of his responsibilities: “Rape flags. … Investigate miscreants.”&lt;/p&gt;
    &lt;p&gt;These days, Lawrie is trying to start an advocacy organization for content moderators and other front-line safety workers. But, he said, he’s done with dating apps.&lt;/p&gt;
    &lt;p&gt;“I don’t think they’re safe enough at the moment,” he said. “They’re gonna get worse. …I’m hoping dating sites vanish.”&lt;/p&gt;
    &lt;p&gt;Lawrie said he was initially excited about Breeden’s hire. He said she spent her first few months on the job talking to each brand’s safety team, and told him that she was “very impressed” by the work OkCupid was doing.&lt;/p&gt;
    &lt;p&gt;Each of Match Group’s biggest apps provided their self-described strengths and weaknesses to Breeden’s team, according to an internal spreadsheet. At Hinge, these weaknesses included a “very rudimentary warning system with no targeted comms and no follow through” and “no way to find” the original profile “of a bad actor who has created multiple profiles.”&lt;/p&gt;
    &lt;p&gt;Breeden was confronted with an existential problem. “Our current ban categories won’t allow us to answer the public’s biggest question: Am I likely to be harmed on my date?” reads a slide in a presentation drafted by her team in April 2021. While each of Match Group’s apps had a system of reporting and banning violent users, the information was disorganized, and none of the apps talked to each other.&lt;/p&gt;
    &lt;p&gt;Lawrie hoped Breeden would improve safety at the company. But he quickly grew frustrated that neither she nor Match Group leadership listened to his pleas for what they really needed to make platforms safer: To hire trained — and expensive — investigators and integrate powerful moderation tools across all the apps.&lt;/p&gt;
    &lt;p&gt;OkCupid already had those tools. Lawrie was using them every day.&lt;lb/&gt;One of those was the Sentinel system, which had been up and running across Match Group’s apps for at least five years before Breeden arrived. It works like this: When a user is banned for something serious — like sexual assault — a case is created in Sentinel with the phone number and email address associated with their account. In interviews, multiple current and former employees described how those reports circulate through each of Match Group’s apps. The system is designed to ban anyone who uses that information. It also grabs the original profile’s IP addresses, photos, and birthdate.&lt;/p&gt;
    &lt;p&gt;Such a system seems robust at first glance — but none of the Match Group’s apps require users to provide photo identification (the kind needed to buy alcohol or board an airplane), so once a person is kicked out, they can easily start a new account with different contact information. A quick search yields scores of online forums with clear steps and suggestions for how to rejoin the apps. In addition, internal company documents show information on IP addresses, photos, and birthdate were not used to ban a user if they appear on another Match dating app.&lt;/p&gt;
    &lt;p&gt;Lawrie’s team at OkCupid knew Sentinel could only do so much.&lt;/p&gt;
    &lt;p&gt;So his team deployed other tools to fix its shortcomings, including one that could automatically ban a profile that was linked to a phone number, photo, or URL that had been previously banned — even if the user made an account with a different email or IP address. This tool was designed to be proactive rather than reactive, so that the profiles of alleged perpetrators like Matthews would not resurface after they had been reported.&lt;/p&gt;
    &lt;p&gt;Internal company documents from 2019 and 2020 show thousands of reports of “serious physical assault,” abuse, or violence on OkCupid that were deemed serious enough to get users banned from all of Match Group’s apps. This is among the information the company kept from the public.&lt;/p&gt;
    &lt;p&gt;Breeden and Match Group leadership praised Lawrie and his team at OkCupid, he said, for their thorough investigative work and for handling some of the company’s most difficult cases. Yet, he said, Match Group never built out a skilled, experienced investigative unit at other brands like the one he headed up at OkCupid. Under Breeden’s leadership, he said, they faced pressure to speed up investigations and train outsourced labor to use complicated moderation tools.&lt;/p&gt;
    &lt;p&gt;A week after a damning article in 2021 revealed that content moderators with little training were asked to rapidly deal with violent sexual content across Match Group’s brands, then-CEO Dubey sent out an all-staff email addressing the controversy. She CC’d Breeden, acknowledging that the brand’s safety teams were not all on equal footing.&lt;/p&gt;
    &lt;p&gt;As Match Group prepared internally for the story to break, Lawrie was asked to write a report for Breeden outlining his team’s accomplishments “to make sure when Tracey describes and acknowledges what you are doing individually to celebrate the good work that you are doing.”&lt;/p&gt;
    &lt;p&gt;Lawrie used that report to protest.&lt;/p&gt;
    &lt;p&gt;“Most professionals aren’t judged on how many cases they can hurry through in an hour,” he wrote. The way Match Group expects its trust-and-safety and support teams to work “basically diminishes their skills and makes them production-line workers.” Breeden declined to comment for this story, citing a nondisclosure agreement.&lt;/p&gt;
    &lt;p&gt;Lawrie left the company in 2022 and said most of his small team that was ferreting out malicious users also left due to a negative workplace environment. He said much of their work was outsourced to contractors with little training and severe quotas.&lt;/p&gt;
    &lt;p&gt;He now cautions anyone using a dating app to understand that they’re not in the business of protecting users.&lt;/p&gt;
    &lt;p&gt;“You’re on your own pretty much,” he said.&lt;/p&gt;
    &lt;p&gt;As Lawrie was getting pushed out of Match Group, Matthews kept appearing on the company’s apps.&lt;/p&gt;
    &lt;p&gt;One crisp fall evening in 2022, one of the Denver cardiologist’s old medical school classmates was on Hinge when her phone screen filled up with a familiar face.&lt;/p&gt;
    &lt;p&gt;Matthews was being promoted on the app as a Standout, a popular profile that Hinge’s algorithm thinks you’ll like. To match with a Standout, users must send the person a rose. They get one free rose a week, but they cost $3.99 a pop after that. His classmate did not send Matthews a rose.&lt;/p&gt;
    &lt;p&gt;By this point, Matthews had already been reported for rape at least once to Hinge. Court documents show that he had already allegedly sexually assaulted nine women and drugged 10. Not only did the apps allow him back on, they featured Matthews’ profile.&lt;/p&gt;
    &lt;p&gt;As the COVID-19 pandemic dragged on, people got tired of forking money over for dating apps. Match Group still made a hefty profit, but its growth flatlined. Its stock cratered, losing nearly half its value between October 2021 and April 2022. That month, an analyst from J.P. Morgan wrote that the firm had received more messages about “the underperformance of MTCH shares in recent weeks than any other topic.”&lt;/p&gt;
    &lt;p&gt;In May 2022, Match ousted Dubey and installed Bernard Kim as CEO, a former executive at the gaming company Zynga that popularized viral games like “FarmVille.”&lt;/p&gt;
    &lt;p&gt;While Dubey spoke frequently about trust and safety and worked closely with Breeden, Kim hardly mentioned safety when he began his time at Match Group, instead emphasizing the need for continued rapid expansion to drive long-term shareholder value.&lt;/p&gt;
    &lt;p&gt;Lawrie said that Kim, with his background in gaming rather than dating apps, had no interest in love. “He just wants to make money. He’s just there to increase profits,” Lawrie said. “If he’s looking at a bottom line, then it’s easier to have a lawsuit than it is to provide safety. I know which one he’s gonna pick.” Match Group declined to make Bernard Kim available for an interview. Messages sent to Kim directly went unreturned.&lt;/p&gt;
    &lt;p&gt;While the tension between growth and safety exists across the tech sector, it is especially high at dating apps companies where executives have to worry about constant churn — users leaving the apps when they are no longer looking for dates. Every time Match Group delivers on its promise, it also loses customers.&lt;/p&gt;
    &lt;p&gt;In February 2024, six dating app users filed what they hope will be certified as a class action lawsuit. They argue Match Group uses “addictive” features to encourage compulsive use while not leading to any real increase in off-app relationships. “The app is designed specifically to hook them, and to keep them paying subscription fees — not to help them find love,” attorney Ryan Clarkson said. Match Group filed to dismiss the lawsuit in September, noting in its quarterly report that it “will defend vigorously” against the allegations.&lt;/p&gt;
    &lt;p&gt;Despite Kim’s efforts, Match Group’s stock price continued to drop, and during that time, so did any mention of trust and safety. In over a year of quarterly investor calls, Kim only referenced safety efforts once.&lt;/p&gt;
    &lt;p&gt;Employees who pushed for these initiatives were forced out or laid off, including Breeden — a leader who was so convinced of her own invincibility that she showed up to an event wielding a Captain America shield.&lt;/p&gt;
    &lt;p&gt;Match Group fired its power hire in October 2022. Layoffs hit her team over the next several months. In February 2024, the remaining critical investigators and law enforcement liaisons on Breeden’s central safety team were shown the door.&lt;/p&gt;
    &lt;p&gt;Lawrie said group chats of former Match Group employees have been gossipping about the cutbacks.&lt;/p&gt;
    &lt;p&gt;“You’re not gonna see them taking safety seriously ever again,” he said, adding that the only thing that he thinks might change that is legislation.&lt;/p&gt;
    &lt;p&gt;Four months before Matthews was arrested, a post on a Facebook group in Denver blew up, right around Christmas.&lt;/p&gt;
    &lt;p&gt;Over and over again, women furiously detailed negative experiences they or their friends had with Matthews.&lt;/p&gt;
    &lt;p&gt;Some women described him as “sketchy.” Others called him “terrible” and “not safe.” Multiple women told a similar, dark story: that they were offered drinks, blacked out, and sexually assaulted.&lt;/p&gt;
    &lt;p&gt;The thread reached 150 comments. Two women wrote the same thing: that they had been waiting for someone to post about the cardiologist.&lt;/p&gt;
    &lt;p&gt;The flood of Facebook comments mirrored details in the police reports released the following year. Nearly all of the 16 women included in the district attorney’s initial complaints were offered tequila. Eight recalled playing Jenga. Six mentioned a hot tub.&lt;/p&gt;
    &lt;p&gt;As these stories circulated in this small corner of the internet in December 2022, the Denver cardiologist stayed on Match Group apps.&lt;/p&gt;
    &lt;p&gt;Those fortunate enough to know about the Facebook group — and who had the foresight to check for Matthews on it — would be saved from a bad date or worse. But the fact that he could still log into Tinder and Hinge left him with a pool of thousands of unsuspecting women whom he could — and would — continue to match with.&lt;/p&gt;
    &lt;p&gt;The Dating Apps Reporting Project is aware of four additional women who have accused Matthews of drugging and/or raping them who were not part of the criminal complaint. Each of these women met Matthews on a Match Group app during a single year between the summers of 2020 and 2021.&lt;/p&gt;
    &lt;p&gt;During the years Matthews was on their apps, Match Group hired and fired Breeden. It made loud promises on sexual violence, announced initiatives and product lines, and promised a transparency report. But it was not straight with the public, which meant the women matching with Matthews on Match Group apps were not aware of the risk they faced.&lt;/p&gt;
    &lt;p&gt;Match Group’s partnership with Garbo, the background check company, also fell apart in the summer of 2023. “It’s become clear that most online platforms aren’t legitimately committed to trust and safety for their users,” Garbo wrote in a searing blog post.&lt;/p&gt;
    &lt;p&gt;After spending so much energy talking about monetization, gamification, and growth, Kim began to publicly acknowledge this problem. Speaking at the Citibank conference in the fall of 2023, he said the company was investing in new features to make sure “women have a good experience while they’re in the product. They feel safe. They feel secure. Etc.”&lt;/p&gt;
    &lt;p&gt;Privacy&lt;/p&gt;
    &lt;head rend="h3"&gt;Car Tracking Can Enable Domestic Abuse. Turning It Off Is Easier Said Than Done&lt;/head&gt;
    &lt;p&gt;Internet-connected cars allow abusers to track domestic violence survivors after they leave&lt;/p&gt;
    &lt;p&gt;The “etc.” does not seem to include increased transparency about safety. Instead, in May 2023, Tinder released a “female-focused package,” a curated list of “high-quality profiles.” It is unclear how Tinder determines these high-quality matches. Hinge’s Standout feature, which is similar, had previously promoted Matthews.&lt;/p&gt;
    &lt;p&gt;In fact, under Kim’s leadership, all mentions of a transparency report disappeared from the company’s annual impact report. Ironically, this was around the same time that new legislation in Europe required tech companies to disclose reports of “non-consensual behavior” and other issues. Match Group will be required to submit a transparency report to the European Union on the scope of harm on their platforms later this month. Lawmakers in India and Australia are also demanding transparency.&lt;/p&gt;
    &lt;p&gt;This is exactly the situation Breeden and her team pondered three years ago. “What if publishing in one jurisdiction sparks a requirement in another?” read a slide in the same internal presentation where Match Group’s trust-and-safety leaders wondered whether they should “push back on how much [they] are required to reveal.”&lt;/p&gt;
    &lt;p&gt;After Match Group published a disappointing earnings report in February 2025 that fell below analysts’ expectations, it also announced that Kim would be replaced by former Zillow CEO Spencer Rascoff. Tinder’s revenue, sales, and subscribers had all gone down.&lt;/p&gt;
    &lt;p&gt;As Match Group struggles to reverse its decline, it’s also aware that its reputation is in the spotlight. Earnings calls and shareholder letters over the first three quarters of 2024 indicate that the company knows it is a business imperative to make women feel safer on its platforms. Match Group brought in a new vice president to head trust and safety whose job partly focuses on complying with increased global transparency requirements. The company is experimenting with requiring faces in photos and rolled out a “Share My Date” feature so you can be tracked while meeting up with an online stranger. On Tinder, it orchestrated a “major ecosystem cleanup” geared toward identifying fake profiles and getting scammers off the app.&lt;/p&gt;
    &lt;p&gt;But neither the cleanup nor tracking a date from your phone would have stopped Matthews — a man who never sought to hide his identity, who assaulted his dates in his own home — from finding and harming women.&lt;/p&gt;
    &lt;p&gt;Four years after Matthews’ first documented assault, he walked into a wood-paneled courtroom in Denver and was sentenced to 158 years to life in prison. “I will sentence. I cannot heal,” Judge Eric Johnson told the room filled with survivors and family members.&lt;/p&gt;
    &lt;p&gt;“Countless women have suffered and will continue to suffer,” said Laura Wolf, an attorney who represented the woman whose police report triggered Matthews’ arrest. “Hinge and other dating platforms have taken no steps to ensure the safety of the product they are selling, matching unsuspecting women to known predators without pause or concern.”&lt;/p&gt;
    &lt;p&gt;Match Group didn’t make it easy for the Denver prosecutors to convict Matthews. A search warrant was issued to Hinge in July 2023. Two months later, prosecutors were still empty-handed — with the judge in the case asking at a hearing if he needed to start “dragging people in to get stuff done.” It wasn’t until February 2024 that the Denver District Attorney’s Office said they finally received documents returned by Match Group.&lt;/p&gt;
    &lt;p&gt;Matthews will likely never leave prison. Match Group executives currently face no charges. But the company knew about Matthews, and it knows about thousands of other abusive users. It has the data that could help users avoid dangerous situations, but it hasn’t shared it, leaving millions of people in the dark.&lt;/p&gt;
    &lt;p&gt;Lawmakers around the world are starting to ask for answers from the most powerful force in modern dating. In June, Colorado passed a law, triggered by the Matthews case, that forces dating app companies to tell the state attorney general what safety measures they are taking to protect users. Although the law leaves room for the possibility of additional transparency in the future, it does not currently require the company to tell the state, or the public, how many people are raped or assaulted after using its platform. In the U.S., we’ve just scratched the surface. In most states, there’s little that requires Match Group to share information with you — or with Congress.&lt;/p&gt;
    &lt;p&gt;The reality is that if Stephen Matthews were released today, he could get right back on a dating app. Match Group knows this — and now so do you.&lt;/p&gt;
    &lt;p&gt;Stephanie Wolf contributed reporting. Statistical journalist Natasha Uzcátegui-Liggett led The Markup’s testing of Match Group apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45363429</guid><pubDate>Wed, 24 Sep 2025 17:29:09 +0000</pubDate></item></channel></rss>