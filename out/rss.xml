<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 25 Sep 2025 17:08:32 +0000</lastBuildDate><item><title>Helium Browser</title><link>https://helium.computer/</link><description>&lt;doc fingerprint="170e82509195b1e4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Internet without interruptions&lt;/head&gt;
    &lt;p&gt;Best privacy and unbiased ad-blocking by default. Handy features like native !bangs and split view. No adware, no bloat, no noise. People-first and fully open source.&lt;/p&gt;
    &lt;head rend="h1"&gt;Best privacy by default, not as a hidden option&lt;/head&gt;
    &lt;p&gt;Helium blocks ads, trackers, fingerprinting, third-party cookies, cryptominers, and phishing websites by default thanks to preinstalled uBlock Origin. No extra steps are needed, and there are no biased exceptions â unlike other browsers. &lt;lb/&gt; The browser itself doesn't have any ads, trackers, or analytics. Helium also doesn't make any web requests without your explicit consent, it makes zero web requests on first launch. &lt;lb/&gt; Not enough? Increase privacy even further with ungoogled-chromium flags or uBlock Origin filters. You're finally at the steering wheel of your privacy on the Internet â not in a toy car, but in a real race car. &lt;lb/&gt; We will always stand by our promise of the best privacy and will never prioritize profit over people, unlike big corporations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Respectful by design&lt;/head&gt;
    &lt;p&gt;Helium doesn't annoy you with anything and never will. It doesn't do anything without your consent: no unprovoked tabs about updates or sponsors, no persistent popups telling you about features you don't care about, no weird restarts. &lt;lb/&gt; Nothing interrupts you, jumps in your face, or breaks your flow. Everything just makes sense. You're in full control.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fast, efficient, and light&lt;/head&gt;
    &lt;p&gt;Helium is based on Chromium, the fastest and most optimized browser yet. Helium builds on this base to improve performance and save even more energy. You will notice a difference after using Helium for a day. It doesn't slow down over time. &lt;lb/&gt; All bloat is removed: Helium is one of the lightest modern browsers available.&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful when you need it&lt;/head&gt;
    &lt;p&gt;Open pages side-by-side with split view to get even more things done at once. Quickly copy page links with â+Shift+C and share your discoveries with ease. Install any web apps and use them as standalone desktop apps without duplicating Chromium.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed to get out of your way&lt;/head&gt;
    &lt;p&gt;Helium's interface is compact and minimalistic, but it doesn't compromise on beauty or functionality. More web content fits on the screen at once, and the browser interface doesn't get in your way. You can hide everything extra from the toolbar if it annoys you. &lt;lb/&gt; Helium is built with attention to detail. Nothing jiggles or flickers abnormally. Your actions aren't throttled or stopped by lag. Everything's fast, smooth, and simple. Comfort and simplicity are among our top priorities.&lt;/p&gt;
    &lt;head rend="h2"&gt;Works with all Chromium extensions, privately&lt;/head&gt;
    &lt;p&gt;All Chromium extensions are supported and work right away, by default, including all MV2 extensions. We'll keep support for MV2 extensions for as long as possible. &lt;lb/&gt; Helium anonymizes all internal requests to the Chrome Web Store via Helium services. Thanks to this, Google can't track your extension downloads or target ads using this data. No other browser does this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free and fully open-source&lt;/head&gt;
    &lt;p&gt;All parts of the Helium browser are open source, including online services. You can self-host Helium services and use your own instance in your browser. &lt;lb/&gt; Everything is available on GitHub. No exceptions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Always safe and sound&lt;/head&gt;
    &lt;p&gt;We release new Chromium updates (such as security patches) as soon as possible. Your browser will always be safe and up to date. &lt;lb/&gt; Helium updates itself automatically on macOS, with auto-updating options available on Linux and Windows. &lt;lb/&gt; All builds are available on GitHub, and you can even make one yourself. The choice is yours!&lt;/p&gt;
    &lt;head rend="h2"&gt;Best security practices for everyone, by default&lt;/head&gt;
    &lt;p&gt;Helium enforces HTTPS on all websites and warns you when a website doesn't support it. Passkeys just work. &lt;lb/&gt; There's no built-in password manager. Passwords should be separate from a web browser to be truly secure and immutable. &lt;lb/&gt; There's also no cloud-based history/data sync. You should be the only one with access to your browsing data, not some conglomerate.&lt;/p&gt;
    &lt;head rend="h1"&gt;Browse the Internet faster with !bangs&lt;/head&gt;
    &lt;p&gt;Skip the search engine and go directly to the website you want. Choose from over 13,000 bangs that make the Internet a breeze to browse, such as !w for Wikipedia, !gh for GitHub, and !wa for Wolfram Alpha. &lt;lb/&gt; Want to chat with AI? Just add !chatgpt or any other AI provider name at the start of your query. Helium will start a new chat for you without sending your prompt anywhere else. &lt;lb/&gt; Helium bangs are the fastest and most private implementation of bangs yet. They work offline, directly in your browser. &lt;lb/&gt; Not sure which bang to use? Check out the full list of bangs!&lt;/p&gt;
    &lt;head rend="h1"&gt;The web browser made for people, with love&lt;/head&gt;
    &lt;p&gt;We're making a web browser that we enjoy using ourselves. Helium's main goal is to provide an honest, comfortable, privacy-respecting, and non-invasive browsing experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for developers&lt;/head&gt;
    &lt;p&gt;Helium is based on Chromium and doesn't break any web APIs or standards, despite the focus on privacy. DevTools have been cleaned up and no longer nag you with anything. There's nothing that gets in your way of creating the Internet of the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for everyone on the go&lt;/head&gt;
    &lt;p&gt;Helium's efficiency makes it handy for everyone with their laptop on the go. Split view and quick link copying make it easier than ever to get things done faster. Helium loads pages faster and saves data by blocking ads and other crap.&lt;/p&gt;
    &lt;head rend="h1"&gt;Ready to try Helium?&lt;/head&gt;
    &lt;p&gt;It's never too late to get your internet life back on the right track. Helium can transfer your most important stuff from other browsers in one click. We hope you'll love it!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45366867</guid><pubDate>Wed, 24 Sep 2025 22:51:16 +0000</pubDate></item><item><title>Do YC after you graduate: Early decision for students</title><link>https://www.ycombinator.com/early-decision</link><description>&lt;doc fingerprint="b61d01d108cf1634"&gt;
  &lt;main&gt;
    &lt;p&gt;Apply now, do YC after you graduate. For students who want to finish school before doing YC. Get funded the moment you're accepted.&lt;/p&gt;
    &lt;p&gt;Sneha and Anushka, founders of Spur (S24), applied in Fall 2023 for the S24 batch using Early Decision. This allowed them to graduate in May 2024 and then do YC. They've since raised $4.5M from top investors for their AI-powered QA testing tools.&lt;/p&gt;
    &lt;p&gt;Early Decision lets you apply to YC while you're still in school and reserve your spot in a future batch. For example, you apply in Fall of this year, for a spot in the summer batch of the following year. You submit the same YC application as if you were applying for the upcoming batch. If you're accepted, we'll fund you immediately and hold your place for after you graduate.&lt;/p&gt;
    &lt;p&gt;This program is designed for students who want to finish their degree before starting a company. If you're considering working on your own startup after graduation, Early Decision makes it easy to lock in your spot.&lt;/p&gt;
    &lt;p&gt;Even if you're not completely sure yet if you want to do a startup, you should still apply. There is no downside.&lt;/p&gt;
    &lt;p&gt;Also, if you're not in your final year, you can still apply for Early Decision. You'll be able to finish the school year you're currently in, and then either join a later batch or decide to drop out and start sooner.&lt;/p&gt;
    &lt;p&gt;The most common path is students applying in the fall of their final year and joining the summer batch after graduating in Spring. But you can apply for any batch in the future within reason. The application and interview process is the same as if you were applying for the upcoming batch. Once you're accepted, YC funds you right away and confirms your future batch.&lt;/p&gt;
    &lt;p&gt;When you fill out your YC application, you'll see a question asking which batch you want to apply for. Simply select "A batch after Winter 2026" to indicate you're applying for Early Decision, and tell us which batch you'd like to be considered for.&lt;/p&gt;
    &lt;p&gt;The batch preference question in the YC application&lt;/p&gt;
    &lt;p&gt;Many students want to finish their degree or complete more of their education before starting a company. Also we know that many students spend a lot of time in Fall or during their final year applying for jobs or internships. Early Decision gives students another option: apply to YC and bet on yourself.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45367046</guid><pubDate>Wed, 24 Sep 2025 23:12:38 +0000</pubDate></item><item><title>Knotty: A domain-specific language for knitting patterns</title><link>https://t0mpr1c3.github.io/knotty/index.html</link><description>&lt;doc fingerprint="a5ebd7a76a7f3314"&gt;
  &lt;main&gt;
    &lt;p&gt;▼ Knotty 1 Introduction 2 How to Make a New Pattern 3 Input and Output 4 Code Examples 5 Reference On this page: Knotty 8.11 contents ← prev up next → Knotty Tom Price &amp;lt; t0mpr1c3@gmail.com &amp;gt; ( require knotty ) package: knotty-lib A domain-specific language for knitting patterns. contents ← prev up next →&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45369768</guid><pubDate>Thu, 25 Sep 2025 06:13:32 +0000</pubDate></item><item><title>Some interesting stuff I found on IX LANs</title><link>https://blog.benjojo.co.uk/post/ixp-bad-broadcast-packets-interesting</link><description>&lt;doc fingerprint="f78b85556837a9c2"&gt;
  &lt;main&gt;
    &lt;p&gt;These days the internet as a whole is mostly constructed out of point to point ethernet circuits, meaning an ethernet interface (mostly optical) attached directly from one routing device to another routing device.&lt;/p&gt;
    &lt;p&gt;However that is not always the case, as the humble “internet exchange” (IX) still exists, and while the relevancy of IXs are progressively being diminished by the internet increasingly being concentrated into a small handful of content networks and IXs not keeping up with the lowering price of transit or private fiber connections to the largest networks, there are still a large number of networks that’s attached to at least one IX fabric.&lt;/p&gt;
    &lt;p&gt;IXs are a little bit strange, as they are at their core practically identical to a simple ethernet switch you may find in your home or office (except your home switch is unlikely to be doing terabits per second of traffic). As IXs depend on the ethernet switches interest in only being the MAC addresses of traffic and not the Layer 3 IP addresses.&lt;/p&gt;
    &lt;p&gt;However home and small and medium business (SMB) routers often come with defaults that make life a lot easier for networks way of desktop computers and common office equipment on them, these same defaults are at the very least annoying and at the very worst actively exploitable if put on a IX LAN with many untrusted participants.&lt;/p&gt;
    &lt;p&gt;The company that I run and operate has a large number of ports at internet exchanges (at a rough estimate I am the top 13 of all networks on the internet in this metric!), and alongside the route collecting that bgp.tools does on these IX ports, it also listens in on the broadcast and multicast traffic that happens on these exchanges.&lt;/p&gt;
    &lt;p&gt;This isn’t that magical, at its core it works by running tcpdump on each IX port, and picking up the BUM traffic, parsing what it is looking at (and throwing away the unknown unicast, since that is a separate common problem that I don’t want to get involved with), and reporting that data back up the chain to bgp.tools’s website.&lt;/p&gt;
    &lt;p&gt;This creates little warning icons (or alerts if they use the monitoring product) on their IX membership rows to let them and others know that something is not configured correctly&lt;/p&gt;
    &lt;p&gt;When I first started off developing this feature I was basically going off the top of my head on what the obvious mistakes that were likely to happen on misconfigured IX ports. However at the same time I developed a “miscellaneous packets” feed that collected packets that I didn’t have code to deal with.&lt;/p&gt;
    &lt;p&gt;Checking that miscellaneous packet feed every week has been a lot of fun and deeply terrifying on what networks have been sending into exchanges. Here are some of the things that bgp.tools finds on a regular basis&lt;/p&gt;
    &lt;p&gt;With large deployments of routers and switches it is often very difficult to actually locate where each device is plugged into at either end. For this exact reason, many vendors ship protocols that emit various identifier packets that are designed to help operations teams identify the “far side” of each port&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: Low&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Link Layer Discovery Protocol is a pretty common cross vendor protocol for doing exactly this, it is also sometimes used to automatically configure capabilities like higher wattage power over ethernet.&lt;/p&gt;
    &lt;p&gt;Here’s an example of a LLDP packet (and what information it discloses) from my own network:&lt;/p&gt;
    &lt;code&gt;root@blah:~# lldpctl 
------------------------------------------------------------------
LLDP neighbors:
------------------------------------------------------------------
Interface:    ens1f0, via: LLDP, RID: 3, Time: 146 days, 02:13:47
  Chassis:     
    ChassisID:    mac 1c:34:da:90:90:01
    SysName:      bgptools-switch
    SysDescr:     Debian GNU/Linux 12 (bookworm) Linux [...]
    MgmtIP:       10.xxx.xxx.2
    MgmtIface:    3
    MgmtIP:       fdd2:xxx::1
    MgmtIface:    3
    Capability:   Bridge, on
    Capability:   Router, on
    Capability:   Wlan, off
    Capability:   Station, off
  Port:        
    PortID:       mac 1c:34:da:90:90:26
    PortDescr:    swp8
    TTL:          120
    PMD autoneg:  supported: yes, enabled: yes
      Adv:          1000Base-X, HD: no, FD: yes
      MAU oper type: 10GigBaseCX4 - X copper over 8 pair 100-Ohm balanced cable
&lt;/code&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Cisco Discovery Protocol is a older and proprietary to Cisco (although that does not stop many vendors from having copied it) version of LLDP&lt;/p&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;The popular budget network equipment vendor Mikrotik ships by default with a feature called “Mikrotik Neighbor Discovery Protocol” enabled by default.&lt;/p&gt;
    &lt;p&gt;Here is an example decoded MNDP packet from a network on FranceIX&lt;/p&gt;
    &lt;code&gt;    Seq: 134398
    MAC Address: 08:55:31:1b:9c:aa
    Identity: DC2.A23.CCR02
    Version: 6.49.6 (stable)
    Platform: MikroTik
    Uptime: 2239h52m39s
    SoftwareID: HBWH-7QHV
    Board: CCR1009-7G-1C-1S+
    IPv6Address: 2001:7f8:54::1:85
    InterfaceName: FRANCE_IX
    IPv4Address: 37.49.237.85
&lt;/code&gt;
    &lt;p&gt;We can see what they named the device , what type of device it is, the interface name (FRANCE_IX), and the device uptime.&lt;/p&gt;
    &lt;p&gt;Most consumer devices when they come on the network do not know what IP address/gateway they are supposed to be using, This is because in most environments you do not want to have machines that have statically configured addresses.&lt;/p&gt;
    &lt;p&gt;However IX’s are not these kinds of environments, as they are environments where all participants have been assigned a very specific IP address to use on the LAN. This does not stop these automatic IP address assignment protocols from attempting to grab IP addresses with some configurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: High&lt;/p&gt;
    &lt;p&gt;Security Danger: Targeted traffic redirection&lt;/p&gt;
    &lt;p&gt;This is the exact same protocol that your mobile phone or laptop is using, just being blasted out to terabit/s per second switching fabrics. When a IX participant is asking for addresses with DHCP on the exchange, any one of the entities connected (some of which may be considered adversaries of your state) could reply to their request and assign them an IP address and default gateway, the latter possibly redirecting large amounts of traffic through them!&lt;/p&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: People using your network for free&lt;/p&gt;
    &lt;p&gt;Security Danger: Low&lt;/p&gt;
    &lt;p&gt;IPv6 Router Advertisement is a protocol where routers periodically announced onto the LAN but they are capable of acting as a gateway (and optionally include instructions for clients to generate IPv6 addresses automatically), this is useful for IPv6 deployment, but this behavior is absolutely not desirable on internet exchanges as you do not want to have people use you as a gateway for the entire internet over peering LANs, as effectively giving them free internet transit, which is typically bad for business.&lt;/p&gt;
    &lt;p&gt;Unfortunately this feature is enabled by default on Cisco and Arista, meaning it is so common that bgp.tools has a dedicated icon for it on the site.&lt;/p&gt;
    &lt;p&gt;On exchanges there is generally only one accepted routing protocol that is allowed to be used between members and that is BGP. However that does not seem to stop other networks from accidentally enabling other protocols, some of which automatically “flood” messages to broadcast so they can look for peers to automatically establish relationships with.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: You will import other peoples internal routes&lt;/p&gt;
    &lt;p&gt;Security Danger: People can insert routes into your network&lt;/p&gt;
    &lt;p&gt;OSPF and IS-IS are the classic internal routing protocols that a lot of networks use to manage their internal routing table. This internal routing table is where the more specific routes for individual customers or subscriber pools exist.&lt;/p&gt;
    &lt;p&gt;While OSPF and IS-IS offer an ability to restrict sessions that are automatically started without a given password in configuration, a decent number of networks do not use this feature.&lt;/p&gt;
    &lt;p&gt;The result of this is if these networks without a password configured meet each other on the internet exchange with OSPF/IS-IS configured they will automatically exchange internal routing tables of each other, the effects of this could range between a security risk because an attacker could inject routes into their internet routing table, all the way to a full blown outage as there would be overlap in internal network routes.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: You will import other peoples internal routes&lt;/p&gt;
    &lt;p&gt;Security Danger: People can insert routes into your network&lt;/p&gt;
    &lt;p&gt;Routing Information Protocol is a very old way of doing what OSPF and IS-IS does on most modern networks today.&lt;/p&gt;
    &lt;p&gt;RIP and RIPv2 have similar automatic peer configuration features, meaning that if two or more members on an internet exchange have this configured they will almost certainly automatically merge their internal routing tables.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: People can manipulate MPLS labels&lt;/p&gt;
    &lt;p&gt;Security Danger: People can manipulate MPLS labels&lt;/p&gt;
    &lt;p&gt;MultiProtocol Label Switching Label Distribution Protocol is a different type of internal routing protocol that rather than dealing with IP prefixes, handles the exchange of MPLS Labels. Given that a lot of networks deploy MPLS as the core way of moving data around in their network, exposing this to another untrusted party is pretty bad.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Quite a lot of vendors have their own form of proprietary ethernet loop detection, which often involve sending out probing packets into the LAN and seeing if they arrive back on any other interface (which would indicate a loop)&lt;/p&gt;
    &lt;p&gt;For example, here is a loop testing packet from a Huawei device&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: Local disruption&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Spanning Tree Protocol is a very common default that is enabled across most ethernet switches to combat ethernet loops. However accepting STP packets and sending them to other members of the exchange could result in disruption to the peer, as both sides try to agree a hierarchy with each other.&lt;/p&gt;
    &lt;p&gt;SONiC is an open source network operating system (NOS) developed mostly by Microsoft, this is notable because almost all network operating systems are proprietary with no source code available. There are many reasons for this but one of the primary ones is that while there are many networking equipment vendors out there, the actual fundamental ASIC/Chips suppliers that are used to build high end equipment are limited down to around 3, with the majority of the market share being Broadcom. SONiC has in recent years become the most well known by name open source NOS.&lt;/p&gt;
    &lt;p&gt;Unfortunately SONiC is also just not a very good pick for almost all users, and mortally let down by its software quality. An example of this is a script called arp_update that transmits a “Ping all IPv6 devices” packet to all connected LANs so that it can work around a potential limitation in the hardware that it supports. This is a nuisance on internet exchanges because once there are more than a handful of these devices on the exchange, every one is spending a non zero amount of resources responding to pointless pings.&lt;/p&gt;
    &lt;p&gt;It’s hard for me to understate how crap of a workaround this is, and how much more crap this is for devices with internet exchange ports.&lt;/p&gt;
    &lt;p&gt;There is a final category for things that are kind of just bizarre to see. They are just things that should not actually appear at all on any internet exchange port, and suggest something strange has happened. Either with unexpected devices being connected into the exchange fabric entirely, or very inadvisable configurations being used for public “network edge” ports.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;While Network Time Protocol is very common, most of the time it is configured in a unicast way (meaning that a device deliberately queries a NTP peer), however there is a lesser used broadcast mode where a server broadcasts the time into the LAN on regular intervals.&lt;/p&gt;
    &lt;p&gt;Unfortunately some networks have decided to enable this on their internet exchange ports, meaning that all members are receiving (but are unlikely using) these packets.&lt;/p&gt;
    &lt;p&gt;It doesn’t help that almost every single time I have seen one of these situations, the time being broadcast itself is wrong by at least a few days implying that a device itself does not actually have a good source of time, and it’s just drifting from it’s original set up&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Exposure of a remote configuration interface to untrusted networks&lt;/p&gt;
    &lt;p&gt;Once again our friend MikroTik comes back with some interesting defaults, In this case the RoMON protocol that allows their GUI management interface (WinBox), and the ability to “telnet” into a neighboring device with just its MAC address.&lt;/p&gt;
    &lt;p&gt;The logic behind the telnet feature is that it is useful for when you need to go to recover a device that you may have accidentally set a bad firewall or IP address/routing configuration on. However that does also mean that bgp.tools has traces of people using this telnet feature (which often broadcasts keystrokes and outputs) to all members. Implying that some networks are using the IX LAN (presumably by borrowing another member’s router) as a recovery mechanism for their misconfigurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Exposure of a legacy protocol to untrusted networks&lt;/p&gt;
    &lt;p&gt;The Digital Equipment Corporation (Yes, the PDP-11 company) developed a series of network protocols called DECnet. While it is unlikely that you will ever encounter a device that needs DECNet support, Cisco by default enables this protocol on all interfaces (unless explicitly configured otherwise) on all enterprise software versions for IOS/IOS-XE.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Allowing untrusted networks to configure your device&lt;/p&gt;
    &lt;p&gt;Simple Service Discovery Protocol and its’s most common implementation use case Universal Plug and Play is a protocol normally only ever found in the home/residential networking space. It allows for simple configuration for things like port forwarding. Since no one should be connecting such hardware to IX LANs, this is generally a sign of a serious misconfiguration.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Multicast DNS and Link-Local Multicast Name Resolution are protocols used mostly by desktop computers to locate other things on the network (typically home or small biz networks) by name.&lt;/p&gt;
    &lt;p&gt;MDNS is also very common in the automatic discovery of network printers, it also happens to be what I discovered the most on various exchanges&lt;/p&gt;
    &lt;p&gt;While this is obviously ridiculous that a printer would be attached to an IX, what is likely actually happening here is that linux distributions like Debian will/would offer a “print server” role enabled by default. Since Linux “software routers” based on Debian are common in some regions, it doesn’t necessarily surprise me that these routers were installed with the print server role left enabled by mistake when they the operating system was installed.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: The exposure of Windows or SMB to untrusted networks&lt;/p&gt;
    &lt;p&gt;NETBIOS is often used to power SMB/Samba, the Windows file and printer sharing protocol.&lt;/p&gt;
    &lt;p&gt;When I first encountered this packet I assumed that this was going to be a windows server configuration that had been let onto the exchanged by mistake, as encountering windows servers acting as edge routers is unheard of (although windows does actually have a bgp implementation, it is not designed for edge peering and so would make an extremely poor edge router)&lt;/p&gt;
    &lt;p&gt;Upon further inspection of the packets it appears that what has actually happened here (at least 6 different times) is desktops/laptops have been let into the exchange instead. I can tell this because windows will automatically generate host names like &lt;code&gt;SERVER-ABCD1234&lt;/code&gt; for windows server installations, and &lt;code&gt;DESKTOP-ABCD1234&lt;/code&gt; for desktop/laptop ones, and NETBIOS packets often include the hostname of the system that is querying.&lt;/p&gt;
    &lt;p&gt;I can only assume this has happened due to incorrect physical cable patching or VLAN translation.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: Untrusted networks could trigger failover of your routers&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Virtual Router Redundancy Protocol and Hot Standby Router Protocol are protocols that are designed to allow two routers to automatically take over from another if they fail. To do this the protocol sends packets on a regular interval into the LAN that has the gateway ip address that is being protected from downtime.&lt;/p&gt;
    &lt;p&gt;While redundancy is obviously desired on exchanges, this is typically done by actually attaching two discrete routers to the exchange with different LAN IP addresses, so VRRP and similar protocols are not appreciated configurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: Embarrassment&lt;/p&gt;
    &lt;p&gt;Security Danger: Information disclosure&lt;/p&gt;
    &lt;p&gt;When Cisco devices are unable to find a working DNS resolver, they resort to broadcasting the DNS query on all interfaces, Most of the time this just means that the Cisco licensing server (the “cslu-local”) is queried for, with an added bonus of the owners DNS search domain (if they have configured one)&lt;/p&gt;
    &lt;p&gt;So filtering for these packets is quite easy, and results in pretty much exactly what you would think.&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' | sort | uniq -c | sort -n | tail -n 15
    875 cslu-local.{CORP-F}
    998 cslu-local.{CORP-F}
   1162 tools.cisco.com.{Military-A}.
   1648 cslu-local.{CORP-G}
   1659 cslu-local.{CORP-F}
   1880 cslu-local.{CORP-E}
   2088 tools.cisco.com.{CORP-A}.
   2910 cslu-local.{CORP-D}
   4213 cslu-local.{Military-A}.
   5125 cslu-local.{CORP-C}.com.
   5515 cslu-local.{CORP-B}.fr.
   7367 cslu-local.{CORP-A}.com.
   7675 tools.cisco.com.
   9934 cslu-local.{Military-A}
  10838 cslu-local.
&lt;/code&gt;
    &lt;p&gt;Except Cisco also has another interesting default back from the days when Cisco sold dedicated terminal servers where you would dial into the device (over the phone), and then type the device name you were looking to connect to.&lt;/p&gt;
    &lt;p&gt;In practice everybody should be disabling this function in 2025, however by default it is enabled, so if you log into the Cisco CLI and make a typo (let’s say for this example you forgot the you’re on a cisco rather than a huawei), this happens:&lt;/p&gt;
    &lt;p&gt;The CLI just hangs, as it broadcasts your typo onto all interfaces…&lt;/p&gt;
    &lt;p&gt;Anyway with a little bit of careful processing we can see all of these typos and sometimes the search domain from where they came from:&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' | sort | uniq -c | sort -n | egrep -v  'cslu|tools.cisco.com'

      1 cls.basetelco.com.
      1 configre.jato3.com.
      1 conft.asn28176.com.br.
      1 conft.powernet.net.br.
      1 cont.wanfiber.net.br.
      1 cpnf.cd.net.za.
      1 end.3cta.eb.mil.br.
      1 end.as37497.net.
      1 end.cd.net.za.
      1 end.spnet.com.br.
      1 exiexit.cd.net.za.
      1 exit-address-family.
      1 exitr.jfsc.local.
      1 expression.jato3.com.
&lt;/code&gt;
    &lt;p&gt;I’ve collected favorite most common typos below:&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' |&amp;amp; pcregrep -o1 '^([^.]+)' | sort | uniq -c | sort -n 
...

      1 access-list
      1 configre
      1 cont
      1 cpnf
      1 exiexit
      1 exit-address-family
      1 exitr
      1 exti
      1 extit
      1 ifconfig
      1 int
      1 interface
      1 qconft
      1 qqq
      1 reboot
      1 uptime
      2 coinf
      2 Please
      2 shorun
      2 top
      4 ip
      4 ping
      6 save
      9 conft
     87 y
     92 quit
    134 q
    289 summary
&lt;/code&gt;
    &lt;p&gt;There is of course an added danger while having this enabled that you could actually answer these queries and then trick an operator into typing into a terminal that you control. But I suspect that almost all operators would notice something like that happening, making such a trick difficult to pull off.&lt;/p&gt;
    &lt;p&gt;While pretty much all exchanges have rules that define the kind of traffic that you are allowed to be sent into the internet exchange fabric that would forbid almost all of these types of packets from being sent ( For example, here is AMS-IX’s list of rules ), enforcement of these rules is nonexistent in most exchanges.&lt;/p&gt;
    &lt;p&gt;Which is a shame really because a lot of this can be automatically done with simple access control lists (ACLs) that target just mac addresses alone.&lt;/p&gt;
    &lt;p&gt;DEC-MOP, RoMON, STP, CDP, IS-IS, ES-IS, LLDP, VRRP, OSPF, IPv6 RA are remarkably common, and yet they use specific MAC address destinations that could just be filtered out on all ports, preventing them from being seen by other IX participants.&lt;/p&gt;
    &lt;p&gt;While [LLMNR, NetBIOS, PIM, LDP, MDNS, DHCPv4 /DHCPv6, SSDP, DNS-Broadcast, Broadcast NTP, MikroTik Discovery] do require the IX device to be able to inspect Layer 3 headers like UDP port numbers in ACLs, this feature is very common among deployed hardware in the industry.&lt;/p&gt;
    &lt;p&gt;Even if exchanges are not able to automatically enforce policy using ACLs, there are open source projects like IXP-Watch and systems like bgp.tools that will monitor this for you.&lt;/p&gt;
    &lt;p&gt;There shouldn’t really be an excuse for things to be this way!&lt;/p&gt;
    &lt;p&gt;If you want to stay up to date with the blog you can use the RSS feed or you can follow me on Fediverse @benjojo@benjojo.co.uk&lt;/p&gt;
    &lt;p&gt;Until next time!&lt;/p&gt;
    &lt;p&gt;Related Posts:&lt;/p&gt;
    &lt;p&gt;Appreciation of automated IX Quarantine LAN testing (2024)&lt;/p&gt;
    &lt;p&gt;Better IX network quality monitoring (2024)&lt;/p&gt;
    &lt;p&gt;Random Post:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45370882</guid><pubDate>Thu, 25 Sep 2025 09:36:40 +0000</pubDate></item><item><title>Bundler Belongs to the Ruby Community</title><link>https://andre.arko.net/2025/09/25/bundler-belongs-to-the-ruby-community/</link><description>&lt;doc fingerprint="e91a20914debb5e8"&gt;
  &lt;main&gt;
    &lt;p&gt;25 Sep 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Bundler belongs to the Ruby community&lt;/head&gt;
    &lt;p&gt;I’ve spent 15 years of my life working on Bundler. When I introduce myself, people say “oh, the Bundler guy?”, and I am forced to agree.&lt;/p&gt;
    &lt;p&gt;I didn’t come up with the original idea for Bundler (that was Yehuda). I also didn’t work on the first six months worth of prototypes. That was all Carl and Yehuda together, back when “Carlhuda” was a super-prolific author of Ruby libraries, including most of the work to modularize Rails for version 3.&lt;/p&gt;
    &lt;p&gt;I joined the team at a pivotal moment, in February 2010, as the 0.9 prototype was starting to be re-written yet another time into the shape that would finally be released as 1.0. By the time Carl, Yehuda, and I released version 1.0 together in August 2010, we had fully established the structure and commands that Bundler 2.7.2 still uses today.&lt;/p&gt;
    &lt;p&gt;I gave my first conference talk about Bundler at Red Dirt Ruby in May 2010. Because they would be too busy with Rails 3 talks, Yehuda and Carl asked me to give the first RailsConf talk about Bundler, in June 2010.&lt;/p&gt;
    &lt;p&gt;As Carl and Yehuda drifted off to other projects, in 2011 and 2012 respectively, I took on a larger role, co-maintaining the project with Terence Lee, then on the Ruby platform team at Heroku. We shipped (and, embarrassingly, broke) many versions of Bundler on our way to the 1.1 release and its major speed improvements. We also gave several conference talks together, sharing what we had learned about Bundler, about gems, and about maintaining open source.&lt;/p&gt;
    &lt;p&gt;In 2013, I managed to convince the owner of &lt;code&gt;bundler.io&lt;/code&gt; to sell me his domain, and rebuilt the website to host a separate copy of the documentation for every version of Bundler, ensuring even users on old versions could still access accurate documentation.&lt;/p&gt;
    &lt;p&gt;By the end of 2013, Terence had drifted away from the project as well, and I realized that everyone using Ruby was now one bus (or one lottery ticket) away from Bundler having no significant maintainers. During 2014, I made sure to settle any remaining ownership issues, including purchasing the rights to the Bundler logo, and began investigating various funding ideas. I tried specialized consulting, corporate sponsorships, and asking Ruby Central about sponsoring Bundler and RubyGems development work. Ruby Central declined, citing their desire to stay focused on conferences, but suggested that if I wanted to pursue something myself they would be happy to collaborate.&lt;/p&gt;
    &lt;p&gt;In 2015, I founded Ruby Together specifically to raise funds to pay the existing maintainers team of Bundler, RubyGems, and RubyGems.org. Over time, we were able to raise enough money to quietly but scrappily keep the entire RubyGems ecosystem maintained and functional. Ruby Together did not ever, at any point, demand any form of governance or control over the existing open source projects. Maintainers did their thing in the RubyGems and Bundler GitHub orgs, while Ruby Together staff and board members did their thing in the rubytogether GitHub org.&lt;/p&gt;
    &lt;p&gt;By 2021, when Ruby Central and Ruby Together were both interested in merging together, funds were harder to find. Ruby Together had a membership program. Ruby Central wanted a to have a membership program. The confusing split between “Ruby Central owns the AWS account, but Ruby Together pays all the devs” continued to be a problem.&lt;/p&gt;
    &lt;p&gt;We prepared a merger agreement (which you can read in full at the link), stating that Ruby Central’s new goal after the merger would be “paying maintainers to do the programming”. The agreement also states that Ruby Central will follow Ruby Together’s Vision, Mission, and Values, a document that is hosted in the rubycentral GitHub organization today. That document includes a very specific list of goals, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Project users and maintainers are empowered to decide what’s best for their projects&lt;/item&gt;
      &lt;item&gt;Ruby open source developers are paid for their work&lt;/item&gt;
      &lt;item&gt;Give control to the community&lt;/item&gt;
      &lt;item&gt;Be accountable and transparent to the community&lt;/item&gt;
      &lt;item&gt;Establish a collaborative, positive space for projects&lt;/item&gt;
      &lt;item&gt;Have a clear and transparent funding process&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can read much more in both the merger agreement and in the Mission, Vision, and Values document, but the fundamental goal for both the non-profit and the open source projects is clear: this is all for the Ruby community. Without the community, there is no point to this work, and there is no way it could ever have been done in the first place. Without the 354 individuals who contributed to Bundler and to RubyGems, I could never have become “the Bundler guy” in the first place.&lt;/p&gt;
    &lt;p&gt;In the last few weeks, Ruby Central has suddenly asserted that they alone own Bundler. That simply isn’t true. In order to defend the reputation of the team of maintainers who have given so much time and energy to the project, I have registered my existing trademark on the Bundler project.&lt;/p&gt;
    &lt;p&gt;Trademarks do not affect copyright, which stays with the original contributors unchanged. Trademarks do not affect license terms, which stay MIT and unchanged. Trademarks only impact one thing: who is allowed say that what they make is named “Bundler”. Ruby Central is welcome to the code, just like everyone else. They are not welcome to the project name that the Bundler maintainers have painstakingly created over the last 15 years.&lt;/p&gt;
    &lt;p&gt;While the trademark has been registered under my name as an individual, I will not keep it for myself, because the idea of Bundler belongs to the Ruby community. Once there is a Ruby organization that is accountable to the maintainers, and accountable to the community, with openly and democratically elected board members, I commit to transfer my trademark to that organization.&lt;/p&gt;
    &lt;p&gt;I will not license the trademark, and will instead transfer ownership entirely. Bundler should belong to the community, and I want to make sure that is true for as long as Bundler exists.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45371061</guid><pubDate>Thu, 25 Sep 2025 10:05:49 +0000</pubDate></item><item><title>The Theatre of Pull Requests and Code Review</title><link>https://meks.quest/blogs/the-theatre-of-pull-requests-and-code-review</link><description>&lt;doc fingerprint="3754740beb3d5f9b"&gt;
  &lt;main&gt;&lt;p&gt;We can't find the internet&lt;/p&gt;&lt;p&gt;Attempting to reconnect&lt;/p&gt;&lt;p&gt;Something went wrong!&lt;/p&gt;&lt;p&gt;Hang in there while we get back on track&lt;/p&gt;&lt;head rend="h1"&gt;The Theatre of Pull Requests and Code Review&lt;/head&gt;&lt;head rend="h3"&gt;Meks McClure · September 23, 2025&lt;/head&gt;Photo Credit to Petter Boström&lt;p&gt;I recently attended the Goatmire Elixir Conf and one of the standout talks for me was Saša Jurić's "Tell Me a Story". It was an incredible presentation that combined theatrical storytelling with practical technical advice. Saša performed parts of his talk in character, turning technical topics into a compelling narrative that was part comedy, part tragedy, and fully packed with useful insights I've started implementing myself. The recording will eventually be released online for viewing. I highly recommend that people watch it, and I'll endeavor to add a link to it here when it becomes available.&lt;/p&gt;Photo Credit to Petter Boström&lt;head rend="h2"&gt;The Code Review Challenge&lt;/head&gt;&lt;p&gt;The talk focused on Code Review and Pull Requests (PRs). Saša laid out common problems most software engineers face. Too often, engineers dread code reviews even though they're a significant part of team collaboration. We avoid them because PRs tend to be too large, too complex, too difficult to comprehend, and too painful to test. So we end up commenting "Looks Good To Me" and suggesting a few minor styling improvements to give the appearance of a thorough review.&lt;/p&gt;&lt;p&gt;This is how security leaks happen and codebases become progressively unmaintainable. Since git blame only points to the original author, it's easy to think "if something goes wrong, it's not on me". But we're all responsible for the whole system, regardless of who wrote the individual lines of code.&lt;/p&gt;&lt;head rend="h2"&gt;What Makes a PR Reviewable?&lt;/head&gt;&lt;p&gt;So how do we review something that feels unreviewable? Saša advocates for normalizing the practice of returning difficult-to-understand PRs to the author. This makes logical sense, but it's challenging to implement because it can feel like admitting we're not smart enough to understand the code. However, saying "I don't understand this enough to approve it" is far more valuable than pretending with an empty "LGTM".&lt;/p&gt;&lt;p&gt;If we commit to only reviewing truly reviewable PRs, what does that look like? According to Saša, it should take the average reviewer 5-10 minutes. By 'average reviewer,' he means mid-to-senior developers who understand the domain, business, and tech stack well—not newcomers still learning the system or mythical 10x engineers.&lt;/p&gt;&lt;p&gt;How do you create a PR that can be reviewed in 5-10 minutes? By reducing the scope. A full feature should often be multiple PRs. A good rule of thumb is 300 lines of code changes - once you get above 500 lines, you're entering unreviewable territory.&lt;/p&gt;&lt;head rend="h2"&gt;Telling a Story with Commits&lt;/head&gt;&lt;p&gt;A key part of having a reviewable PR is writing commits that tell a story. Present your changes incrementally and logically so reviewers can follow your thought process. Generic commit messages such as "add dependency," "implement file upload feature," and "address PR feedback" don’t tell much of a story and leave reviewers guessing. Why was the dependency added? What were the specific steps in creating the file uploader feature? What feedback is being addressed?&lt;/p&gt;&lt;head rend="h3"&gt;Story-Telling Commit Messages&lt;/head&gt;&lt;p&gt;After a toast to the demo gods, Saša demonstrated writing story-telling commits with a live coding example, creating a PR that was part of a larger feature. His example PR adds just 152 lines of code, removes 2 lines, but uses 13 thoughtful commits.&lt;/p&gt;&lt;p&gt;While some developers might understand those 152 lines from the final diff alone, I couldn't confidently approve it without the commit story.&lt;/p&gt;&lt;head rend="h3"&gt;Breaking Down the Example&lt;/head&gt;&lt;p&gt; For instance, looking at the overall diff, I didn't understand why he added &lt;code&gt;:runtime_tools&lt;/code&gt;
      to &lt;code&gt;applications&lt;/code&gt;
      in &lt;code&gt;mix.exs&lt;/code&gt;. Following the commit narrative, it's clear this was needed for access to
      &lt;code&gt;:scheduler.get_sample()&lt;/code&gt;
      to collect the samples. Now I can research that context or ask more pointed questions.
    &lt;/p&gt;&lt;head rend="h3"&gt;The Iterative Process&lt;/head&gt;&lt;p&gt;A huge benefit of seeing this live was witnessing the iterative process. In the compute average utilization commit, we initially saw an incorrect implementation that computed averages of all schedulers, including offline ones. When testing revealed unexpected results, Saša went back and updated both the code and the commit that originally implemented that function so the story remained coherent.&lt;/p&gt;&lt;p&gt;A flow that I find to work well for keeping commit history clean is with fixup commits. A fixup is a small commit that’s explicitly marked to be folded into an earlier commit during an interactive rebase. When you run rebase with autosquash, Git automatically pairs each fixup with its target and tucks the changes into the right place, keeping the story coherent without manual reordering.&lt;/p&gt;&lt;p&gt;I sometimes experience creating merge conflicts for myself during this process. Both Saša and I agree that if it becomes too much effort to resolve the conflict, then creating a new commit is ok. Taking the time to put in extra effort to keep the commit history clean and the story coherent makes the PR easier for reviewers to understand.&lt;/p&gt;&lt;head rend="h3"&gt;The Value of Clean History&lt;/head&gt;&lt;p&gt;Keeping the commit history clean connects to advice I've heard about ensuring every commit compiles and keeps the application runnable. I used to follow this loosely, but recent experiences with git bisect emphasized to me its importance. (If you are unfamiliar with git bisect , it's worth checking out; it uses a binary search algorithm to find which commit in your project's history introduced a bug.)&lt;/p&gt;&lt;p&gt;There are a few factors that make narrowing down when and how a regression was introduced more challenging. If a commit doesn't compile, I can't isolate whether the bug first appeared there. If the bug appeared in a commit that had hundreds of lines of code changed, determining which part of the commit is the issue requires significantly more reasoning. A clean commit history with messages that tell a story makes these kinds of investigations easier.&lt;/p&gt;&lt;head rend="h2"&gt;Making Review a Collaborative Success&lt;/head&gt;&lt;p&gt;When we present focused PRs with commits that tell clear stories, we get feedback sooner and our development cycles speed up. When reviewers understand our changes, we're more likely to receive valuable feedback instead of blanket approvals, and we're more likely to ship quality code. When our commits make sense, we can travel back in time as needed to understand how our codebase evolved.&lt;/p&gt;&lt;p&gt;Thanks to Saša's theatrical lesson, I will be more intentional about crafting commit stories. The next time you're preparing a PR, consider: Are you telling a story your reviewers can follow? Start small - maybe focus on just one aspect, like keeping PRs under that 300-line guideline or writing more descriptive commit messages. Your future reviewers (and your future debugging self) will thank you.&lt;/p&gt;&lt;head rend="h3"&gt;Resources&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Git blame for showing which revision and author last modified each line of a file&lt;/item&gt;&lt;item&gt;Git rebase for cleaning up commit history&lt;/item&gt;&lt;item&gt;Git fixup for amending earlier commits&lt;/item&gt;&lt;item&gt;Git bisect for finding when bugs were introduced&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45371283</guid><pubDate>Thu, 25 Sep 2025 10:35:19 +0000</pubDate></item><item><title>The Wind, a Pole, and the Dragon</title><link>https://entropicthoughts.com/the-wind-a-pole-and-the-dragon</link><description>&lt;doc fingerprint="6a4e089e8ea011d4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Wind, a Pole, and the Dragon&lt;/head&gt;
    &lt;p&gt;One of my favourite requests for help online comes from the shibboleth-users group, where someone Japanese used machine translation to ask about the following problem:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;At often, the goat-time install a error is vomit. To how many times like the wind, a pole, and the dragon? Install 2,3 repeat, spank, vomit blows&lt;/p&gt;14:14:01.869 - INFO [edu.internet2.middleware.shibboleth.common.config.profile.JSPErrorHandlerBeanDefinitionParser:45] Parsing configuration for JSP error handler.&lt;p&gt;Not precise the vomit but with aspect similar, is vomited concealed in fold of goat-time lumber? goat-time see like the wind, pole, and dragon? This insult to father’s stones? JSP error handler with wind, pole, dragon with intercourse to goat-time? Or chance lack of skill with a goat-time?&lt;/p&gt;&lt;p&gt;Please apologize for your stupidity. There are a many thank you&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;I have long wanted to figure out exactly how this went so wrong. Some parts are fairly clear:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;vomit could come from throw (as in throwing an error) or even just output.&lt;/item&gt;
      &lt;item&gt;lumber must clearly reference logs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I have also heard speculation that goat-time means runtime, as in the Java runtime, perhaps. This means we can already figure out how we got to “vomited concealed in fold of goat-time lumber” – it’s an error hidden in the runtime logs.&lt;/p&gt;
    &lt;p&gt;I asked a few llms to assist me with the rest, and they universally think spank is an odd translation of hit, which is apparently used in Japanese to mean something like execute, and skill could be a mistranslation of experience.&lt;/p&gt;
    &lt;p&gt;We can start to put together what the message actually means.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Often when trying to install the runtime an error is thrown. uninterpretable I have tried reinstalling it three times, but when I run it an exception is thrown.&lt;/p&gt;
      &lt;p&gt;This is not the exact exception but something like that. Is the real error hidden in the runtime logs? uninterpretable. uninterpretable arising due to interaction with the runtime? Or perhaps my lack of experience with the runtime?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The llms diverge on the meaning of “insult to father’s stones”. Some suggest the obvious thing, that it’d correspond to an idiomatic expression of frustration. Others seem to think it might be about “problems with the ancestral building blocks”, i.e. software dependencies. I liked that reading, but I have no idea.&lt;/p&gt;
    &lt;p&gt;New here? I apply the same weird curiosity to everything I discover. To learn something new, subscribe for weekly article summaries! If you don't like it, you can unsubscribe any time.&lt;/p&gt;
    &lt;p&gt;Then there’s “the wind, a pole, and the dragon.” I have yet to see anything come close to a reasonable answer. llms produce guesses referring to three parts of the configuration, variable names, dependencies, colloquialisms, descriptions of user interface, or abstract descriptions of how quickly things happen (the wind), a fixed point (a pole), and complexity/power (dragon). But again, I have no idea.&lt;/p&gt;
    &lt;p&gt;If you have more information, please reach out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45371309</guid><pubDate>Thu, 25 Sep 2025 10:39:17 +0000</pubDate></item><item><title>Resurrect the Old Web</title><link>https://stevedylandev.bearblog.dev/resurrect-the-old-web/</link><description>&lt;doc fingerprint="a79450e0583082e1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Resurrect the Old Web&lt;/head&gt;
    &lt;p&gt;Recently a local news station in Maine reported a story of some middle schoolers calling their friends with landline telephones. Their parents thought they were too young for cell phones and wanted to hold off on that aspect of reality, so they got an old phone from the 90s, and soon their friends also got phones. It formed schedules of calls they would make to talk to each other, even creating a phone ring of contacts.&lt;/p&gt;
    &lt;p&gt;I think I can confidently say that the majority of us aren't happy with the state of social media. Back in its early days it was fresh and exciting, a fun way to connect with your friends that might be far away, or make new friends online. It was cozy. No ads, no feeds, no endless videos. Instead it was just people, the whole reason you started in the first place. Now it's just noise and scary addicting and effective algorithms that keep you plugged in for hours on end. We build apps and products to help kill the monster, or perhaps we even delete some social media apps. Many of our friends we used to stay connected with seem so distant, as many of them too are tired and perhaps jumped off socials altogether. Well, what if I told you we could have the old web back?&lt;/p&gt;
    &lt;p&gt;In my opinion the answer is honestly pretty simple: blogs and RSS feeds. This was how it was done for years before social media came into the scene. You would find someone's blog, subscribe to their RSS feed, and anytime a new post came out it would pop up in your feed and you could read it. One important clarification is that when we say "blog" it can be pretty much whatever you want it to be. On my personal website I generally write more of my serious blogs, but on my bear blog I plan to be a bit more casual. It will be a place where I record short thoughts, ideas, musings, or cool things I find on the internet. Just sharing what I would normally share with my friends. That's what made the web great, and that's what I want to bring back.&lt;/p&gt;
    &lt;p&gt;To do this, I am starting a bear blog that will have a dedicated feeds page that will have all the other blogs I'm subscribing to. The beauty is that you don't need a dedicated social network to make this work; just click on the links. Use whatever RSS reader you want! You don't have to use bear blog either, just use whatever blog you want. The key is connection. I want to point to who I follow so that you might follow them too, and hopefully create a page on your own. In some ways it's bringing back old web rings and simple networking through hyperlinks.&lt;/p&gt;
    &lt;p&gt;To kick it off, here's a few blogs I'm already subscribed to:&lt;/p&gt;
    &lt;p&gt;If you want to join but not sure how, check out the video I recorded below:&lt;/p&gt;
    &lt;p&gt;Best way to keep up with your feeds is to find yourself an RSS reader! There are a lot of options out there (although admittedly a bit old), so just find it on the platform that suits you best. Feeder.co has a pretty generous free plan, and if you're a dev there's hundreds of self hosted projects to choose from like Yarr. Personally rocking NetNewsWire for MacOS and iOS, and loving it so far!&lt;/p&gt;
    &lt;p&gt;I have no idea if this will amount to anything or if it's worthwhile, but I'm gonna give it a shot. The landline phones prove that we don't have to buy into the social media dopamine machine. We have autonomy, and we have the freedom to choose how we interact with each other. I want to believe we can resurrect the old web, together.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45372113</guid><pubDate>Thu, 25 Sep 2025 12:48:50 +0000</pubDate></item><item><title>Data Viz Color Palette Generator (For Charts and Dashboards)</title><link>https://www.learnui.design/tools/data-color-picker.html</link><description>&lt;doc fingerprint="32a83ff73ed5803d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Palette Generator&lt;/head&gt;
    &lt;head rend="h3"&gt;Number of Colors&lt;/head&gt;
    &lt;head rend="h3"&gt;Background Color&lt;/head&gt;
    &lt;head rend="h2"&gt;In Context&lt;/head&gt;
    &lt;head rend="h2"&gt;How to Use&lt;/head&gt;
    &lt;p&gt;Use the palette chooser to create a series of colors that are visually equidistant. This is useful for many data visualizations, like pie charts, grouped bar charts, and maps.&lt;/p&gt;
    &lt;p&gt;Note: there are two other modes besides palette mode – check out single-hue scales and divergent scales as well.&lt;/p&gt;
    &lt;p&gt;Creating visually equidistant palettes is basically impossible to do by hand, yet hugely important for data visualizations. Why? When colors are not visually equidistant, it’s harder to (a) tell them apart in the chart, and (b) compare the chart to the key. I’m sure we’ve all looked at charts where you can hardly use the key since the data colors are so similar.&lt;/p&gt;
    &lt;p&gt;For instance, Google Analytics does a terrible job with this:&lt;/p&gt;
    &lt;p&gt;It’s better to use use a range of hues so users can cross-reference with the key easier. It’s far simpler for our brains to distinguish, say, yellow from orange than blue from blue-but-15%-lighter.&lt;/p&gt;
    &lt;p&gt;This color picker allows you to specify both endpoints of the palette. You can choose at least one to be a brand color, which gives you significant flexibility in creating a palette that will work for your visualizations, yet be customized for your brand.&lt;/p&gt;
    &lt;p&gt;Here are a few tips for getting the best palette:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Try picking very different endpoint colors – e.g. one warm, one cool; one bright, one darker – so that your palette covers a wider range&lt;/item&gt;
      &lt;item&gt;If you’re using a brand color for one endpoint, don’t be afraid to modify the saturation and brightness a bit if it creates a more pleasing palette. Users will recognize your brand color by its hue much far more than by it’s exact saturation/brightness.&lt;/item&gt;
      &lt;item&gt;For data visualizations where you’re showing the strength of a single value, try using the Single Hue Palette Generator instead.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Oh, and...&lt;/p&gt;
    &lt;head rend="h2"&gt;More on Color&lt;/head&gt;
    &lt;p&gt;If you're new to color in UI design, I highly recommend the following resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The HSB Color System: A Practitioner's Primer&lt;/item&gt;
      &lt;item&gt;Color in UI Design: A Practical Framework&lt;/item&gt;
      &lt;item&gt;Gradient Generator tool, by yours truly, built to be the most fully-featured on the web 😎&lt;/item&gt;
      &lt;item&gt;Design Hacks, my email newsletter where I send original design tips and tactics to 60,000+ of my closest friends.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Anyhow, I've created this to be the tool I wish I had for creating data visualization palettes. Is there another feature you'd like to see in it? Let me know.&lt;/p&gt;
    &lt;head rend="h1"&gt;Single Hue Scale&lt;/head&gt;
    &lt;head rend="h3"&gt;Number of Colors&lt;/head&gt;
    &lt;head rend="h3"&gt;Modify Color Scale&lt;/head&gt;
    &lt;p&gt;Brightness&lt;/p&gt;
    &lt;p&gt;Color Intensity&lt;/p&gt;
    &lt;head rend="h3"&gt;Background Color&lt;/head&gt;
    &lt;head rend="h2"&gt;In Context&lt;/head&gt;
    &lt;head rend="h2"&gt;How to Use&lt;/head&gt;
    &lt;p&gt;The Single Hue Scale generator is most useful for visualizations where you’re showing the value of a single variable. Typically, the darker variation will represent a higher value, and a neutral color (even white) will represent a value closer to zero.&lt;/p&gt;
    &lt;p&gt;In a pie chart or bar chart, size is used to distinguish higher values. But in some visualizations, the size is set and you need to rely on color. Two examples of this are show in the “In Context” section above:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A map in which size represents county size; we need to use color to distinguish the value for each county&lt;/item&gt;
      &lt;item&gt;A week-by-week calendar in which each day is an equally sized box; we need to use color to show the value for a particular day&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are a few tips for getting the best single hue scale:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;To transition to a flat gray endpoint, set “Color Intensity” to zero&lt;/item&gt;
      &lt;item&gt;To transition to a white endpoint, set “Brightness” to full and “Color Intensity” to zero&lt;/item&gt;
      &lt;item&gt;If your color scale actually shows a variable that transitions from one end to a neutral midpoint to another end, try the Divergent Scale Generator (e.g. Republican to moderate to Democrat; hotter to same-temperature to cooler)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Divergent Color Scale&lt;/head&gt;
    &lt;head rend="h3"&gt;Number of Colors&lt;/head&gt;
    &lt;head rend="h3"&gt;Modify Midpoint Color&lt;/head&gt;
    &lt;p&gt;Brightness&lt;/p&gt;
    &lt;p&gt;Color Intensity&lt;/p&gt;
    &lt;head rend="h3"&gt;Background Color&lt;/head&gt;
    &lt;head rend="h2"&gt;In Context&lt;/head&gt;
    &lt;head rend="h2"&gt;How to Use&lt;/head&gt;
    &lt;p&gt;The Divergent Color Scale generator is most useful for visualizations where you’re showing a transition from (a) one extreme, through a (b) neutral middle, and finally to a (c) opposite extreme.&lt;/p&gt;
    &lt;p&gt;Perhaps the most common example of this is the “how Democrat/Republican is each state in the US” chart.&lt;/p&gt;
    &lt;p&gt;By default, the neutral midpoint is a light gray. You can change it with the "Modify Midpoint Color" sliders to be slightly darker or more colorful. For the best results, set the Color Intensity to the minimum when the two endpoint hues are significantly different – otherwise, the moderate tones will start to blend together (this will be evident in the map).&lt;/p&gt;
    &lt;p&gt;As with the other visualization styles, this will pick colors that are visually equidistant. However, if one of the two endpoint colors is significantly darker or saturated, the swatches on that side will have more color-space between them.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45372286</guid><pubDate>Thu, 25 Sep 2025 13:13:25 +0000</pubDate></item><item><title>Video models are zero-shot learners and reasoners</title><link>https://video-zero-shot.github.io/</link><description>&lt;doc fingerprint="cf176b908f11fe6e"&gt;
  &lt;main&gt;
    &lt;p&gt;Veo 3 shows emergent zero-shot abilities across many visual tasks, indicating that video models are on a path to becoming vision foundation models—just like LLMs became foundation models for language.&lt;/p&gt;
    &lt;p&gt;Perception&lt;/p&gt;
    &lt;p&gt;Modeling&lt;/p&gt;
    &lt;p&gt;Manipulation&lt;/p&gt;
    &lt;p&gt;Reasoning&lt;/p&gt;
    &lt;p&gt; The remarkable zero-shot capabilities of Large Language Models (LLMs) have propelled natural language processing from task-specific models to unified, generalist foundation models. This transformation emerged from simple primitives: large, generative models trained on web-scale data. Curiously, the same primitives apply to today's generative video models. Could video models be on a trajectory towards general-purpose vision understanding, much like LLMs developed general-purpose language understanding?&lt;lb/&gt; We demonstrate that Veo 3 can zero-shot solve a broad variety of tasks it wasn't explicitly trained for: segmenting objects, detecting edges, editing images, understanding physical properties, recognizing object affordances, simulating tool use, and much more. These abilities to perceive, model, and manipulate the visual world enable early forms of visual reasoning like maze and symmetry solving. Veo 3's emergent zero-shot capabilities indicate that video models are on a path to becoming unified, generalist vision foundation models. &lt;/p&gt;
    &lt;p&gt;On a run and want to get a gist of our paper? Listen to the following podcast!&lt;/p&gt;
    &lt;p&gt;Edge detection&lt;/p&gt;
    &lt;p&gt;Segmentation&lt;/p&gt;
    &lt;p&gt;Keypoint localization&lt;/p&gt;
    &lt;p&gt;Super-resolution&lt;/p&gt;
    &lt;p&gt;Blind deblurring&lt;/p&gt;
    &lt;p&gt;Blind denoising&lt;/p&gt;
    &lt;p&gt;Low-light enhancing&lt;/p&gt;
    &lt;p&gt;Conjunctive search&lt;/p&gt;
    &lt;p&gt;Dalmatian illusion&lt;/p&gt;
    &lt;p&gt;Shape cue-conflict&lt;/p&gt;
    &lt;p&gt;Rorschach blot&lt;/p&gt;
    &lt;p&gt;Material properties (flammability)&lt;/p&gt;
    &lt;p&gt;Rigid body transform&lt;/p&gt;
    &lt;p&gt;Soft body transform&lt;/p&gt;
    &lt;p&gt;Gravity (earth)&lt;/p&gt;
    &lt;p&gt;Gravity (moon)&lt;/p&gt;
    &lt;p&gt;Buoyancy (bottle cap)&lt;/p&gt;
    &lt;p&gt;Buoyancy (rock)&lt;/p&gt;
    &lt;p&gt;Visual Jenga&lt;/p&gt;
    &lt;p&gt;Object packing&lt;/p&gt;
    &lt;p&gt;Material optics (glass)&lt;/p&gt;
    &lt;p&gt;Material optics (mirror)&lt;/p&gt;
    &lt;p&gt;Color mixing (additive)&lt;/p&gt;
    &lt;p&gt;Color mixing (subtractive)&lt;/p&gt;
    &lt;p&gt;Categorizing objects&lt;/p&gt;
    &lt;p&gt;Omniglot (recognition)&lt;/p&gt;
    &lt;p&gt;Omniglot (generation)&lt;/p&gt;
    &lt;p&gt;Omniglot (parsing)&lt;/p&gt;
    &lt;p&gt;Memory of world states&lt;/p&gt;
    &lt;p&gt;Background removal&lt;/p&gt;
    &lt;p&gt;Style transfer&lt;/p&gt;
    &lt;p&gt;Colorization&lt;/p&gt;
    &lt;p&gt;Inpainting&lt;/p&gt;
    &lt;p&gt;Outpainting&lt;/p&gt;
    &lt;p&gt;Text manipulation&lt;/p&gt;
    &lt;p&gt;Image editing with doodles&lt;/p&gt;
    &lt;p&gt;Scene composition&lt;/p&gt;
    &lt;p&gt;Novel view synthesis&lt;/p&gt;
    &lt;p&gt;3D-aware reposing&lt;/p&gt;
    &lt;p&gt;Transfiguration&lt;/p&gt;
    &lt;p&gt;Professional headshot&lt;/p&gt;
    &lt;p&gt;Dexterous manipulation (jar)&lt;/p&gt;
    &lt;p&gt;Dexterous manipulation (throw/catch)&lt;/p&gt;
    &lt;p&gt;Dexterous manipulation (baoding balls)&lt;/p&gt;
    &lt;p&gt;Affordance recognition&lt;/p&gt;
    &lt;p&gt;Drawing&lt;/p&gt;
    &lt;p&gt;Visual instruction (burrito)&lt;/p&gt;
    &lt;p&gt;Graph traversal&lt;/p&gt;
    &lt;p&gt;Tree BFS&lt;/p&gt;
    &lt;p&gt;Sequence (dots)&lt;/p&gt;
    &lt;p&gt;Sequence (arrows)&lt;/p&gt;
    &lt;p&gt;Sequence (circles)&lt;/p&gt;
    &lt;p&gt;Sequence (squares)&lt;/p&gt;
    &lt;p&gt;Connecting colors&lt;/p&gt;
    &lt;p&gt;Shape fitting&lt;/p&gt;
    &lt;p&gt;Sorting numbers&lt;/p&gt;
    &lt;p&gt;Tool use&lt;/p&gt;
    &lt;p&gt;Simple sudoku completion&lt;/p&gt;
    &lt;p&gt;Water puzzle&lt;/p&gt;
    &lt;p&gt;Maze solving (mouse)&lt;/p&gt;
    &lt;p&gt;Robot navigation&lt;/p&gt;
    &lt;p&gt;Rule extrapolation&lt;/p&gt;
    &lt;p&gt;Analogy (color)&lt;/p&gt;
    &lt;p&gt;Analogy (resize)&lt;/p&gt;
    &lt;p&gt;Analogy (reflect)&lt;/p&gt;
    &lt;p&gt;Analogy (rotate)&lt;/p&gt;
    &lt;p&gt;Maze (5x5)&lt;/p&gt;
    &lt;p&gt;Maze (7x7)&lt;/p&gt;
    &lt;p&gt;Maze (9x9)&lt;/p&gt;
    &lt;p&gt;Maze (irregular)&lt;/p&gt;
    &lt;p&gt;Symmetry (shape)&lt;/p&gt;
    &lt;p&gt;Symmetry (random)&lt;/p&gt;
    &lt;quote&gt;@article{wiedemer2025video, title={Video models are zero-shot learners and reasoners}, author={Wiedemer, Thaddäus and Li, Yuxuan and Vicol, Paul and Gu, Shixiang Shane and Matarese, Nick and Swersky, Kevin and Kim, Been and Jaini, Priyank and Geirhos, Robert}, journal={arXiv preprint arXiv:TBD}, year={2025} }&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45372289</guid><pubDate>Thu, 25 Sep 2025 13:13:34 +0000</pubDate></item><item><title>AI Isn't Replacing Radiologists</title><link>https://www.worksinprogress.news/p/why-ai-isnt-replacing-radiologists</link><description>&lt;doc fingerprint="2fd999d02d35859e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI isn't replacing radiologists&lt;/head&gt;
    &lt;head rend="h3"&gt;Radiology combines digital images, clear benchmarks, and repeatable tasks. But demand for human radiologists is at an all-time high.&lt;/head&gt;
    &lt;p&gt;Works in Progress is becoming a print magazine. Our first print issue, Issue 21, will land in November. If you live in the United States or the United Kingdom, you can subscribe here. If you live outside the US or UK and want to be notified as soon as subscriptions are live in your country, leave your details here.&lt;/p&gt;
    &lt;p&gt;CheXNet can detect pneumonia with greater accuracy than a panel of board-certified radiologists. It is an AI model released in 2017, trained on more than 100,000 chest X-rays. It is fast, free, and can run on a single consumer-grade GPU. A hospital can use it to classify a new scan in under a second.&lt;/p&gt;
    &lt;p&gt;Since then, companies like Annalise.ai, Lunit, Aidoc, and Qure.ai have released models that can detect hundreds of diseases across multiple types of scans with greater accuracy and speed than human radiologists in benchmark tests. Some products can reorder radiologist worklists to prioritize critical cases, suggest next steps for care teams, or generate structured draft reports that fit into hospital record systems. A few, like IDx-DR, are even cleared to operate without a physician reading the image at all. In total, there are over 700 FDA-cleared radiology models, which account for roughly three-quarters of all medical AI devices.&lt;/p&gt;
    &lt;p&gt;Radiology is a field optimized for human replacement, where digital inputs, pattern recognition tasks, and clear benchmarks predominate. In 2016, Geoffrey Hinton – computer scientist and Turing Award winner – declared that ‘people should stop training radiologists now’. If the most extreme predictions about the effect of AI on employment and wages were true, then radiology should be the canary in the coal mine.&lt;/p&gt;
    &lt;p&gt;But demand for human labor is higher than ever. In 2025, American diagnostic radiology residency programs offered a record 1,208 positions across all radiology specialties, a four percent increase from 2024, and the field’s vacancy rates are at all-time highs. In 2025, radiology was the second-highest-paid medical specialty in the country, with an average income of $520,000, over 48 percent higher than the average salary in 2015.&lt;/p&gt;
    &lt;p&gt;Three things explain this. First, while models beat humans on benchmarks, the standardized tests designed to measure AI performance, they struggle to replicate this performance in hospital conditions. Most tools can only diagnose abnormalities that are common in training data, and models often don’t work as well outside of their test conditions. Second, attempts to give models more tasks have run into legal hurdles: regulators and medical insurers so far are reluctant to approve or cover fully autonomous radiology models. Third, even when they do diagnose accurately, models replace only a small share of a radiologist’s job. Human radiologists spend a minority of their time on diagnostics and the majority on other activities, like talking to patients and fellow clinicians.&lt;/p&gt;
    &lt;p&gt;Artificial intelligence is rapidly spreading across the economy and society. But radiology shows us that it will not necessarily dominate every field in its first years of diffusion — at least until these common hurdles are overcome. Exploiting all of its benefits will involve adapting it to society, and society’s rules to it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Islands of automation&lt;/head&gt;
    &lt;p&gt;All AIs are functions or algorithms, called models, that take in inputs and spit out outputs. Radiology models are trained to detect a finding, which is a measurable piece of evidence that helps identify or rule out a disease or condition. Most radiology models detect a single finding or condition in one type of image. For example, a model might look at a chest CT and answer whether there are lung nodules, rib fractures, or what the coronary arterial calcium score is.&lt;/p&gt;
    &lt;p&gt;For every individual question, a new model is required. In order to cover even a modest slice of what they see in a day, a radiologist would need to switch between dozens of models and ask the right questions of each one. Several platforms manage, run, and interpret outputs from dozens or even hundreds of separate AI models across vendors, but each model operates independently, analyzing for one finding or disease at a time. The final output is a list of separate answers to specific questions, rather than a single description of an image.&lt;/p&gt;
    &lt;p&gt;Even with hundreds of imaging algorithms approved by the Food and Drug Administration (FDA) on the market, the combined footprint of today’s radiology AI models still cover only a small fraction of real-world imaging tasks. Many cluster around a few use cases: stroke, breast cancer, and lung cancer together account for about 60 percent of models, but only a minority of the actual radiology imaging volume that is carried out in the US. Other subspecialties, such as vascular, head and neck, spine, and thyroid imaging currently have relatively few AI products. This is in part due to data availability: the scan needs to be common enough for there to be many annotated examples that can be used to train models. Some scans are also inherently more complicated than others. For example, ultrasounds are taken from multiple angles and do not have standard imaging planes, unlike X-rays.&lt;/p&gt;
    &lt;p&gt;Once deployed outside of the hospital where they were initially trained, models can struggle. In a standard clinical trial, samples are taken from multiple hospitals to ensure exposure to a broad range of patients and to avoid site-specific effects, such as a single doctor’s technique or how a hospital chooses to calibrate its diagnostic equipment.1 But when an algorithm is undergoing regulatory approval in the US, its developers will normally test it on a relatively narrow dataset. Out of the models in 2024 that reported the number of sites where they were tested, 38 percent were tested on data from a single hospital. Public benchmarks tend to rely on multiple datasets from the same hospital.&lt;/p&gt;
    &lt;p&gt;The performance of a tool can drop as much as 20 percentage points when it is tested out of sample, on data from other hospitals. In one study, a pneumonia detection model trained on chest X-rays from a single hospital performed substantially worse when tested at a different hospital. Some of these challenges stemmed from avoidable experimental issues like overfitting, but others are indicative of deeper problems like differences in how hospitals record and generate data, such as using slightly different imaging equipment. This means that individual hospitals or departments would need to retrain or revalidate today’s crop of tools before adopting them, even if they have been proven elsewhere.&lt;/p&gt;
    &lt;p&gt;The limitations of radiology models stem from deeper problems with building medical AI. Training datasets come with strict inclusion criteria, where the diagnosis must be unambiguous (typically confirmed by a consensus of two to three experts or a pathology result) and without images that are shot at an odd angle, look too dark, or are blurry. This skews performance towards the easiest cases, which doctors are already best at diagnosing, and away from real-world images. In one 2022 study, an algorithm that was meant to spot pneumonia on chest X-rays faltered when the disease presented in subtle or mild forms, or when other lung conditions resembled pneumonia, such as pleural effusions, where fluid builds up in lungs, or in atelectasis (collapsed lung). Humans also benefit from context: one radiologist told me about a model they use that labels surgical staples as hemorrhages, because of the bright streaks they create in the image.&lt;/p&gt;
    &lt;p&gt;Medical imaging datasets used for training also tend to have fewer cases from children, women, and ethnic minorities, making their performance generally worse for these demographics. Many lack information about the gender or race of cases at all, making it difficult to adjust for these issues and address the problem of bias. The result is that radiology models often predict only a narrow slice of the world,2 though there are scenarios where AI models do perform well, including identifying common diseases like pneumonia or certain tumors.&lt;/p&gt;
    &lt;p&gt;The problems don’t stop there. Even a model for the precise question you need and in the hospital where it was trained is unlikely to perform as well in clinical practice as it did in the benchmark. In benchmark studies, researchers isolate a cohort of scans, define goals in quantitative metrics, such as the sensitivity (the percentage of people with the condition who are correctly identified by the test) and specificity (the percentage of people without the condition who are correctly identified as such), and compare the performance of a model to the score of another reviewer, typically a human doctor. Clinical studies, on the other hand, show how well the model performs in a real healthcare setting without controls. Since the earliest days of computer-aided diagnosis, there has been a gulf between benchmark and clinical performance.&lt;/p&gt;
    &lt;p&gt;In the 1990s, computer-aided diagnosis, effectively rudimentary AI systems, were developed to screen mammograms, or X-rays of breasts that are performed to look for breast cancer. In trials, the combination of humans and computer-aided diagnosis systems outperformed humans alone in accuracy when evaluating mammograms. More controlled experiments followed, which pointed to computer-aided diagnosis helping radiologists pick up more cancer with minimal costs.&lt;/p&gt;
    &lt;p&gt;The FDA approved mammography computer-aided diagnosis in 1998, and Medicare started to reimburse the use of computer-aided diagnosis in 2001. The US government paid radiologists $7 more to report a screening mammogram if they used the technology; by 2010, approximately 74 percent of mammograms in the country were read by computer-aided diagnosis alongside a clinician.&lt;/p&gt;
    &lt;p&gt;But computer-aided diagnosis turned out to be a disappointment. Between 1998 and 2002 researchers analyzed 430,000 screening mammograms from 200,000 women at 43 community clinics in Colorado, New Hampshire, and Washington. Among the seven clinics that turned to computer-aided detection software, the machines flagged more images, leading to clinicians conducting 20 percent more biopsies, but uncovering no more cancer than before. Several other large clinical studies had similar findings.&lt;/p&gt;
    &lt;p&gt;Another way to measure performance is to compare having computerized help to a second clinician reading every film, called ‘double reading’. Across ten trials and seventeen studies of double reading, researchers found that computer aids did not raise the cancer detection rate but led to patients being called back an additional ten percent more often. In contrast, having two readers caught more cancers while slightly lowering callbacks. Computer-aided detection was worse than standard care, and much worse than another pair of eyes. In 2018, Medicare stopped reimbursing doctors more for mammograms read with computer-aided diagnosis than those read by a radiologist alone.&lt;/p&gt;
    &lt;p&gt;One explanation for this gap is that people behave differently if they are treating patients day to day than when they are part of laboratory studies or other controlled experiments.3 In particular, doctors appear to defer excessively to assistive AI tools in clinical settings in a way that they do not in lab settings. They did this even with much more primitive tools than we have today: one clinical trial all the way back in 2004 asked 20 breast screening specialists to read mammogram cases with the computer prompts switched on, then brought in a new group to read the identical films without the software. When guided by computer aids, doctors identified barely half of the malignancies, while those reviewing without the model caught 68 percent. The gap was largest when computer aids failed to recognize the malignancy itself; many doctors seemed to treat an absence of prompts as reassurance that a film was clean. Another review, this time from 2011, found that when a system gave incorrect guidance, clinicians were 26 percent more likely to make a wrong decision than unaided peers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Humans in the loop&lt;/head&gt;
    &lt;p&gt;It would seem as if better models and more automation could together fix the problems of current-day AI for radiology. Without a doctor involved whose behavior might change we might expect real-world results to match benchmark scores. But regulatory requirements and insurance policies are slowing the adoption of fully autonomous radiology AI.&lt;/p&gt;
    &lt;p&gt;The FDA splits imaging software into two regulatory lanes: assistive or triage tools, which require a licensed physician to read the scan and sign the chart, and autonomous tools, which do not. Makers of assistive tools simply have to show that their software can match the performance of tools that are already on the market. Autonomous tools have to clear a much higher bar: they must demonstrate that the AI tool will refuse to read any scan that is blurry, uses an unusual scanner, or is outside its competence. The bar is higher because, once the human disappears, a latent software defect could harm thousands before anyone notices.&lt;/p&gt;
    &lt;p&gt;Meeting that criteria is difficult. Even state-of-the-art vision networks falter with images that lack contrast, have unexpected angles, or lots of different artefacts. IDx-DR, a diabetic retinopathy screener and one of the few cleared to operate autonomously, comes with guardrails: the patient must be an adult with no prior retinopathy diagnosis; there must be two macula-centred photographs of the fundus (the rear of the eye) with a resolution of at least 1,000 times 1,000 pixels; if glare, small pupils or poor focus degrade quality, the software must self-abort and refer the patient to an eye care professional.&lt;/p&gt;
    &lt;p&gt;Stronger evidence and improved performance could eventually clear both hurdles, but other requirements would still delay widespread use. For example, if you retrain a model, you are required to receive new approval even if the previous model was approved. This contributes to the market generally lagging behind frontier capabilities.&lt;/p&gt;
    &lt;p&gt;And when autonomous models are approved, malpractice insurers are not eager to cover them. Diagnostic error is the costliest mistake in American medicine, resulting in roughly a third of all malpractice payouts, and radiologists are perennial defendants. Insurers believe that software makes catastrophic payments more likely than a human clinician, as a broken algorithm can harm many patients at once. Standard contract language now often includes phrases such as: ‘Coverage applies solely to interpretations reviewed and authenticated by a licensed physician; no indemnity is afforded for diagnoses generated autonomously by software’. One insurer, Berkley, even carries the blunter label ‘Absolute AI Exclusion’.&lt;/p&gt;
    &lt;p&gt;Without malpractice coverage, hospitals cannot afford to let algorithms sign reports. In the case of IDx-DR, the vendor, Digital Diagnostics, includes a product liability policy and an indemnity clause. This means that if the clinic used the device exactly as the FDA label prescribes, with adult patients, good-quality images, and no prior retinopathy, then the company will reimburse the clinic for damages traceable to algorithmic misclassification.&lt;/p&gt;
    &lt;p&gt;Today, if American hospitals wanted to adopt AI for fully independent diagnostic reads, they would need to believe that autonomous models deliver enough cost savings or throughput gains to justify pushing for exceptions to credentialing and billing norms. For now, usage is too sparse to make a difference. One 2024 investigation estimated that 48 percent of radiologists are using AI at all in their practice. A 2025 survey reported that only 19 percent of respondents who have started piloting or deploying AI use cases in radiology reported a ‘high’ degree of success.&lt;/p&gt;
    &lt;head rend="h2"&gt;Better AI, more MRIs&lt;/head&gt;
    &lt;p&gt;Even if AI models become accurate enough to read scans on their own and are cleared to do so, radiologists may still find themselves busier, rather than out of a career.&lt;/p&gt;
    &lt;p&gt;Radiologists are useful for more than reading scans; a study that followed staff radiologists in three different hospitals in 2012 found that only 36 percent of their time was dedicated to direct image interpretation. More time is spent on overseeing imaging examinations, communicating results and recommendations to the treating clinicians and occasionally directly to patients, teaching radiology residents and technologists who conduct the scans, and reviewing imaging orders and changing scanning protocols.4 This means that, if AI were to get better at interpreting scans, radiologists may simply shift their time toward other tasks. This would reduce the substitution effect of AI.&lt;/p&gt;
    &lt;p&gt;As tasks get faster or cheaper to perform, we may also do more of them. In some cases, especially if lower costs or faster turnaround times open the door to new uses, the increase in demand can outweigh the increase in efficiency, a phenomenon known as Jevons paradox. This has historical precedent in the field: in the early 2000s hospitals swapped film jackets for digital systems. Hospitals that digitized improved radiologist productivity, and time to read an individual scan went down. A study at Vancouver General found that the switch boosted radiologist productivity 27 percent for plain radiography and 98 percent for CT within a year of going filmless. This occurred alongside other advancements in imaging technology that made scans faster to execute. Yet, no radiologists were laid off.&lt;/p&gt;
    &lt;p&gt;Instead, the overall American utilization rate per 1,000 insured patients for all imaging increased by 60 percent from 2000 to 2008. This is not explained by a commensurate increase in physician visits. Instead, each visit was associated with more imaging on average. Before digitization, the nonmonetary price of imaging was high: the median reporting turnaround time for x-rays was 76 hours for patients discharged from emergency departments, and 84 hours for admitted patients. After departments digitized, these times dropped to 38 hours and 35 hours, respectively.&lt;/p&gt;
    &lt;p&gt;Faster scans give doctors more options. Until the early 2000s, only exceptional trauma cases would receive whole-body CT scans; the increased speed of CT turnaround times mean that they are now a common choice. This is a reflection of elastic demand, a concept in economics that describes when demand for a product or service is very sensitive to changes in price. In this case, when these scans got cheaper in terms of waiting time, demand for those scans increased.&lt;/p&gt;
    &lt;head rend="h2"&gt;The first decade of diffusion&lt;/head&gt;
    &lt;p&gt;Over the past decade, improvements in image interpretation have run far ahead of their diffusion. Hundreds of models can spot bleeds, nodules, and clots, yet AI is often limited to assistive use on a small subset of scans in any given practice. And despite predictions to the contrary, head counts and salaries have continued to rise. The promise of AI in radiology is overstated by benchmarks alone.&lt;/p&gt;
    &lt;p&gt;Multi‑task foundation models may widen coverage, and different training sets could blunt data gaps. But many hurdles cannot be removed with better models alone: the need to counsel the patient, shoulder malpractice risk, and receive accreditation from regulators. Each hurdle makes full substitution the expensive, risky option and human plus machine the default. Sharp increases in AI capabilities could certainly alter this dynamic, but it is a useful model for the first years of AI models that benchmark well at tasks associated with a particular career.&lt;/p&gt;
    &lt;p&gt;However, there are industries where conditions are different. Large platforms rely heavily on AI systems to triage or remove harmful or policy-violating content. At Facebook and Instagram, 94 percent and 98 percent of moderation decisions respectively are made by machines. But many of the more sophisticated knowledge jobs look more like radiology.&lt;/p&gt;
    &lt;p&gt;In many jobs, tasks are diverse, stakes are high, and demand is elastic. When this is the case, we should expect software to, at least initially, lead to more human work, not less. The lesson from a decade of radiology models is neither optimism about increased output nor dread about replacement. Models can lift productivity, but their implementation depends on behavior, institutions and incentives. For now, the paradox has held: the better the machines, the busier radiologists have become.&lt;/p&gt;
    &lt;p&gt;Deena Mousa is a lead researcher at Open Philanthropy. Follow her on Twitter.&lt;/p&gt;
    &lt;p&gt;A few groups have started doing this, like the 2025 ‘OpenMIBOOD’ suite which explicitly scores chest-X-ray models on 14 out-of-distribution collections, but that hasn’t yet become standard.&lt;/p&gt;
    &lt;p&gt;A few companies and research groups are working to mitigate this, such as by training on multi-site datasets, building synthetic cases, or using self-supervised learning to reduce labeling needs, but these approaches are still early and expensive. This limitation is an important reason why AI models do not yet perform as expected.&lt;/p&gt;
    &lt;p&gt;One study tracked 27 mammographers and compared how well each interpreted real screening films versus a standardised ‘test-set’ of the same images. The researchers found no meaningful link between a radiologist’s accuracy in the lab and accuracy on live patients; the statistical correlation in sensitivity-specificity scores was essentially zero.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45372335</guid><pubDate>Thu, 25 Sep 2025 13:19:47 +0000</pubDate></item><item><title>As many as 2M Cisco devices affected by actively exploited 0-day</title><link>https://arstechnica.com/security/2025/09/as-many-as-2-million-cisco-devices-affected-by-actively-exploited-0-day/</link><description>&lt;doc fingerprint="f4031106c911d3ab"&gt;
  &lt;main&gt;
    &lt;p&gt;As many as 2 million Cisco devices are susceptible to an actively exploited zero-day that can remotely crash or execute code on vulnerable systems.&lt;/p&gt;
    &lt;p&gt;Cisco said Wednesday that the vulnerability, tracked as CVE-2025-20352, was present in all supported versions of Cisco IOS and Cisco IOS XE, the operating system that powers a wide variety of the company’s networking devices. The vulnerability can be exploited by low-privileged users to create a denial-of-service attack or by higher-privileged users to execute code that runs with unfettered root privileges. It carries a severity rating of 7.7 out of a possible 10.&lt;/p&gt;
    &lt;head rend="h2"&gt;Exposing SNMP to the Internet? Yep&lt;/head&gt;
    &lt;p&gt;“The Cisco Product Security Incident Response Team (PSIRT) became aware of successful exploitation of this vulnerability in the wild after local Administrator credentials were compromised,” Wednesday’s advisory stated. “Cisco strongly recommends that customers upgrade to a fixed software release to remediate this vulnerability.”&lt;/p&gt;
    &lt;p&gt;The vulnerability is the result of a stack overflow bug in the IOS component that handles SNMP (simple network management protocol), which routers and other devices use to collect and handle information about devices inside a network. The vulnerability is exploited by sending crafted SNMP packets.&lt;/p&gt;
    &lt;p&gt;To execute malicious code, the remote attacker must have possession of read-only community string, an SNMP-specific form of authentication for accessing managed devices. Frequently, such strings ship with devices. Even when modified by an administrator, read-only community strings are often widely known inside an organization. The attacker would also require privileges on the vulnerable systems. With that, the attacker can obtain RCE (remote code execution) capabilities that run as root.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45372361</guid><pubDate>Thu, 25 Sep 2025 13:22:16 +0000</pubDate></item><item><title>Death rates rose in hospital ERs after private equity firms took over</title><link>https://www.nbcnews.com/news/us-news/death-rates-rose-hospital-ers-private-equity-firms-took-study-finds-rcna233211</link><description>&lt;doc fingerprint="2dc0956e36b12786"&gt;
  &lt;main&gt;
    &lt;p&gt;After hospitals were acquired by private equity firms, patient death rates in the emergency departments rose by 13% compared with similar hospitals, according to research published this week in Annals of Internal Medicine.&lt;/p&gt;
    &lt;p&gt;The research, which compared outcomes at hospitals over a 10-year period, adds fresh evidence to previous studies showing harmful patient outcomes and higher costs among health care entities owned by profit-oriented financiers.&lt;/p&gt;
    &lt;p&gt;The increased deaths in emergency departments at private equity-owned hospitals are most likely the result of reduced staffing levels after the acquisitions, which the study also measured, said Dr. Zirui Song, a co-author and associate professor of health care policy and medicine at Harvard Medical School.&lt;/p&gt;
    &lt;p&gt;After hospitals were acquired by private equity, the number of full-time employees fell by an average 11.6% compared with non-private equity facilities, the research found, and salary expenditures in the emergency departments and intensive care units declined by 18% and 16%, respectively.&lt;/p&gt;
    &lt;p&gt;“Most hospital care in the country remains a face-to-face, human, labor-intensive endeavor, especially in emergency departments and ICUs,” Song said in an interview. “When human labor is cut to this extent in staffing sensitive areas of the hospital, patient harm can plausibly ensue, including mortality.”&lt;/p&gt;
    &lt;p&gt;The new study analyzed 1 million emergency department visits by Medicare patients at 49 private equity-owned hospitals from 2009 through 2019. The researchers compared the outcomes of those visits with more than 6 million visits at 293 matched hospitals — those of similar size and location — not acquired by private equity.&lt;/p&gt;
    &lt;p&gt;The study’s co-authors, in addition to Song, are José R. Zubizarreta of Harvard University, Dr. Sneha Kannan of the University of Pittsburgh, Joseph Dov Bruch of the University of Chicago and Dr. Jennifer Stevens, director of the Center for Healthcare Delivery Science at Beth Israel Deaconess Medical Center in Boston.&lt;/p&gt;
    &lt;p&gt;Song said the new research differed from previous studies on private equity’s impact, which focused on patients who were admitted to the hospital.&lt;/p&gt;
    &lt;p&gt;“There are far more patients who come into the emergency department than patients who are actually admitted into the wards of the hospital,” Song said, “so this study looks at a patient population that had not been examined in great depth before.”&lt;/p&gt;
    &lt;p&gt;Private equity firms are sophisticated financial operators that buy companies, typically loading them with large amounts of debt to pay for the acquisitions. The firms hope to sell the companies for profit a few years later.&lt;/p&gt;
    &lt;p&gt;The private equity industry has poured over $1 trillion into health care companies in recent years. Health care has been a focus of the financiers because it accounts for 18% of gross domestic product in the United States.&lt;/p&gt;
    &lt;p&gt;Because their acquisitions add debt costs to the companies they buy, those operations must cut other expenses to offset the burden. Employees are often the first to be fired, and costs are often increased to generate higher profits. Some hospitals owned by private-equity firms sell the land under their buildings, enriching the owners but saddling the facilities with higher rent costs.&lt;/p&gt;
    &lt;p&gt;Dr. Robert McNamara, chairman of the department of emergency medicine at Temple University’s Lewis Katz School of Medicine, said the new research confirms what doctors in the field have long complained about: being stretched too thin by private equity owners.&lt;/p&gt;
    &lt;p&gt;“When private equity comes in, they try to jack up the revenues and then, when that reaches an end point, they start slashing expenses,” McNamara said in an interview. “Instead of people just losing their jobs, you have bad patient outcomes here. Less staff equals worse outcomes.”&lt;/p&gt;
    &lt;p&gt;The new research on increased deaths in emergency departments at private equity-owned hospitals aligns with a 2021 study that found 11% higher mortality rates at nursing homes owned by private equity. That study, by academics at New York University, the University of Chicago and the University of Pennsylvania, concluded that lower nursing staffs and declines in compliance with care standards contributed to the increased deaths at financier-owned homes.&lt;/p&gt;
    &lt;p&gt;Some states are enacting laws to rein in private equity’s impact on health care. In June, Oregon enacted a law limiting the control corporations and private equity can have over health care operations. And in Indiana, a new law expands the attorney general’s powers to investigate health care transactions and mandates reporting on ownership stakes in health care entities by private equity investors and other owners.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45372442</guid><pubDate>Thu, 25 Sep 2025 13:32:50 +0000</pubDate></item><item><title>Launch HN: Webhound (YC S23) – Research agent that builds datasets from the web</title><link>https://news.ycombinator.com/item?id=45373008</link><description>&lt;doc fingerprint="354a104b23ad844a"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;We're the team behind Webhound (&lt;/p&gt;https://webhound.ai&lt;p&gt;), an AI agent that builds datasets from the web based on natural language prompts. You describe what you're trying to find. The agent figures out how to structure the data and where to look, then searches, extracts the results, and outputs everything in a CSV you can export.&lt;/p&gt;&lt;p&gt;We've set up a special no-signup version for the HN community at https://hn.webhound.ai - just click "Continue as Guest" to try it without signing up.&lt;/p&gt;&lt;p&gt;Here's a demo: https://youtu.be/fGaRfPdK1Sk&lt;/p&gt;&lt;p&gt;We started building it after getting tired of doing this kind of research manually. Open 50 tabs, copy everything into a spreadsheet, realize it's inconsistent, start over. It felt like something an LLM should be able to handle.&lt;/p&gt;&lt;p&gt;Some examples of how people have used it in the past month:&lt;/p&gt;&lt;p&gt;Competitor analysis: "Create a comparison table of internal tooling platforms (Retool, Appsmith, Superblocks, UI Bakery, BudiBase, etc) with their free plan limits, pricing tiers, onboarding experience, integrations, and how they position themselves on their landing pages." (https://www.webhound.ai/dataset/c67c96a6-9d17-4c91-b9a0-ff69...)&lt;/p&gt;&lt;p&gt;Lead generation: "Find Shopify stores launched recently that sell skincare products. I want the store URLs, founder names, emails, Instagram handles, and product categories." (https://www.webhound.ai/dataset/b63d148a-8895-4aab-ac34-455e...)&lt;/p&gt;&lt;p&gt;Pricing tracking: "Track how the free and paid plans of note-taking apps have changed over the past 6 months using official sites and changelogs. List each app with a timeline of changes and the source for each." (https://www.webhound.ai/dataset/c17e6033-5d00-4e54-baf6-8dea...)&lt;/p&gt;&lt;p&gt;Investor mapping: "Find VCs who led or participated in pre-seed or seed rounds for browser-based devtools startups in the past year. Include the VC name, relevant partners, contact info, and portfolio links for context." (https://www.webhound.ai/dataset/1480c053-d86b-40ce-a620-37fd...)&lt;/p&gt;&lt;p&gt;Research collection: "Get a list of recent arXiv papers on weak supervision in NLP. For each, include the abstract, citation count, publication date, and a GitHub repo if available." (https://www.webhound.ai/dataset/e274ca26-0513-4296-85a5-2b7b...)&lt;/p&gt;&lt;p&gt;Hypothesis testing: "Check if user complaints about Figma's performance on large files have increased in the last 3 months. Search forums like Hacker News, Reddit, and Figma's community site and show the most relevant posts with timestamps and engagement metrics." (https://www.webhound.ai/dataset/42b2de49-acbf-4851-bbb7-080b...)&lt;/p&gt;&lt;p&gt;The first version of Webhound was a single agent running on Claude 4 Sonnet. It worked, but sessions routinely cost over $1100 and it would often get lost in infinite loops. We knew that wasn't sustainable, so we started building around smaller models.&lt;/p&gt;&lt;p&gt;That meant adding more structure. We introduced a multi-agent system to keep it reliable and accurate. There's a main agent, a set of search agents that run subtasks in parallel, a critic agent that keeps things on track, and a validator that double-checks extracted data before saving it. We also gave it a notepad for long-term memory, which helps avoid duplicates and keeps track of what it's already seen.&lt;/p&gt;&lt;p&gt;After switching to Gemini 2.5 Flash and layering in the agent system, we were able to cut costs by more than 30x while also improving speed and output quality.&lt;/p&gt;&lt;p&gt;The system runs in two phases. First is planning, where it decides the schema, how to search, what sources to use, and how to know when it's done. Then comes extraction, where it executes the plan and gathers the data.&lt;/p&gt;&lt;p&gt;It uses a text-based browser we built that renders pages as markdown and extracts content directly. We tried full browser use but it was slower and less reliable. Plain text still works better for this kind of task.&lt;/p&gt;&lt;p&gt;We also built scheduled refreshes to keep datasets up to date and an API so you can integrate the data directly into your workflows.&lt;/p&gt;&lt;p&gt;Right now, everything stays in the agent's context during a run. It starts to break down around 1000-5000 rows depending on the number of attributes. We're working on a better architecture for scaling past that.&lt;/p&gt;&lt;p&gt;We'd love feedback, especially from anyone who's tried solving this problem or built similar tools. Happy to answer anything in the thread.&lt;/p&gt;&lt;p&gt;Thanks! Moe&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45373008</guid><pubDate>Thu, 25 Sep 2025 14:28:24 +0000</pubDate></item><item><title>Cloudflare Email Service: private beta</title><link>https://blog.cloudflare.com/email-service/</link><description>&lt;doc fingerprint="ee97ad5b3f10bcad"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;If you are building an application, you rely on email to communicate with your users. You validate their signup, notify them about events, and send them invoices through email. The service continues to find new purpose with agentic workflows and other AI-powered tools that rely on a simple email as an input or output.&lt;/p&gt;
      &lt;p&gt;And it is a pain for developers to manage. Itâs frequently the most annoying burden for most teams. Developers deserve a solution that is simple, reliable, and deeply integrated into their workflow.Â &lt;/p&gt;
      &lt;p&gt;Today, we're excited to announce just that: the private beta of Email Sending, a new capability that allows you to send transactional emails directly from Cloudflare Workers. Email Sending joins and expands our popular Email Routing product, and together they form the new Cloudflare Email Service â a single, unified developer experience for all your email needs.&lt;/p&gt;
      &lt;p&gt;With Cloudflare Email Service, weâre distilling our years of experience securing and routing emails, and combining it with the power of the developer platform. Now, sending an email is as easy as adding a binding to a Worker and calling &lt;code&gt;send&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;export default {
  async fetch(request, env, ctx) {

    await env.SEND_EMAIL.send({
      to: [{ email: "[email protected]" }],
      from: { email: "[email protected]", name: "Your App" },
      subject: "Hello World",
      text: "Hello World!"
    });

    return new Response(`Successfully sent email!`);
  },
};&lt;/code&gt;
      &lt;/quote&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Email experience is user experience&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Email is a core tenet of your user experience. Itâs how you stay in touch with your users when they are outside your applications. Users rely on email to inform them when they need to take actions such as password resets, purchase receipts, magic login links, and onboarding flows. When they fail, your application fails.&lt;/p&gt;
      &lt;p&gt;That means itâs crucial that emails need to land in your usersâ inboxes, both reliably and quickly. A magic link that arrives ten minutes late is a lost user. An email delivered to a spam folder breaks user flows and can erode trust in your product. Thatâs why weâre focusing on deliverability and time-to-inbox with Cloudflare Email Service.Â &lt;/p&gt;
      &lt;p&gt;To do this, weâre tightly integrating with DNS to automatically configure the necessary DNS records â like SPF, DKIM and DMARC â such that email providers can verify your sending domain and trust your emails. Plus, in true Cloudflare fashion, Email Service is a global service. That means that we can deliver your emails with low latency anywhere in the world, without the complexity of managing servers across regions.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Simple and flexible for developers&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Treating email as a core piece of your application also means building for every touchpoint in your development workflow. Weâre building Email Service as part of the Cloudflare stack to make developing with email feels as natural as writing a Worker.Â &lt;/p&gt;
      &lt;p&gt;In practice, that means solving for every part of the transactional email workflow:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Starting with Email Service is easy. Instead of managing API keys and secrets, you can use the &lt;code&gt;Email&lt;/code&gt; binding to your &lt;code&gt;wrangler.jsonc&lt;/code&gt; and send emails securely and with no risk of leaked credentials.Â &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;You can use Workers to process incoming mail, store attachments in R2, and add tasks to Queues to get email sending off the hot path of your application. And you can use &lt;code&gt;wrangler&lt;/code&gt; to emulate Email Sending locally, allowing you to test your user journeys without jumping between tools and environments.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;In production, you have clear observability over your emails with bounce rates and delivery events. And, when a user reports a missing email, you can quickly dive into the delivery status to debug issues quickly and help get your user back on track.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Weâre also making sure Email Service seamlessly fits into your existing applications. If you need to send emails from external services, you can do so using either REST APIs or SMTP. Likewise, if youâve been leaning on existing email frameworks (like React Email) to send rich, HTML-rendered emails to users, you can continue to use them with Email Service. Import the library, render your template, and pass it to the `send` method just as you would elsewhere.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;import { render, pretty, toPlainText } from '@react-email/render';
import { SignupConfirmation } from './templates';

export default {
  async fetch(request, env, ctx) {

    // Convert React Email template to html
    const html = await pretty(await render(&amp;lt;SignupConfirmation url="https://your-domain.com/confirmation-id"/&amp;gt;));

    // Use the Email Sending binding to send emails
    await env.SEND_EMAIL.send({
      to: [{ email: "[email protected]" }],
      from: { email: "[email protected]", name: "Welcome" },
      subject: "Signup Confirmation",
      html,
      text: toPlainText(html)
    });

    return new Response(`Successfully sent email!`);
  }
};&lt;/code&gt;
      &lt;/quote&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Email Routing and Email Sending: Better together&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Sending email is only half the story. Applications often need to receive and parse emails to create powerful workflows. By combining Email Sending with our existing Email Routing capabilities, we're providing a complete, end-to-end solution for all your application's email needs.&lt;/p&gt;
      &lt;p&gt;Email Routing allows you to create custom email addresses on your domain and handle incoming messages programmatically with a Worker, which can enable powerful application flows such as:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Using Workers AI to parse, summarize and even label incoming emails: flagging security events from customers, early signs of a bug or incident, and/or generating automatic responses based on those incoming emails.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Creating support tickets in systems like JIRA or Linear from emails sent to &lt;code&gt;[email protected]&lt;/code&gt;.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Processing invoices sent to &lt;code&gt;[email protected]&lt;/code&gt; and storing attachments in R2.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;To use Email Routing, add the &lt;code&gt;email&lt;/code&gt; handler to your Worker application and process it as needed:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;export default {
  // Create an email handler to process emails delivered to your Worker
  async email(message, env, ctx) {

    // Classify incoming emails using Workers AI
    const { score, label } = env.AI.run("@cf/huggingface/distilbert-sst-2-int8", { text: message.raw" })

    env.PROCESSED_EMAILS.send({score, label, message});
  },
};  &lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When you combine inbound routing with outbound sending, you can close the loop entirely within Cloudflare. Imagine a user emails your support address. A Worker can receive the email, parse its content, call a third-party API to create a ticket, and then use the Email Sending binding to send an immediate confirmation back to the user with their ticket number. Thatâs the power of a unified Email Service.&lt;/p&gt;
      &lt;p&gt;Email Sending will require a paid Workers subscription, and we'll be charging based on messages sent. We're still finalizing the packaging, and we'll update our documentation, changelog, and notify users as soon as we have final pricing and long before we start charging. Email Routing limits will remain unchanged.&lt;/p&gt;
      &lt;p&gt;Email is core to your application today, and it's becoming essential for the next generation of AI agents, background tasks, and automated workflows. We built the Cloudflare Email Service to be the engine for this new era of applications, weâll be making it available in private beta this November.&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;Interested in Email Sending? Sign up to the waitlist here.Â &lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Want to start processing inbound emails? Get started with Email Routing, which is available now, remains free and will be folded into the new email sending APIs coming.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Weâre excited to be adding Email Service to our Developer Platform, and weâre looking forward to seeing how you reimagine user experiences that increasingly rely on emails!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45373081</guid><pubDate>Thu, 25 Sep 2025 14:33:50 +0000</pubDate></item><item><title>This month in Servo: variable fonts, network tools, SVG</title><link>https://servo.org/blog/2025/09/25/this-month-in-servo/</link><description>&lt;doc fingerprint="6286a4978805acc4"&gt;
  &lt;main&gt;
    &lt;p&gt;Another month, another record number of pull requests merged! August flew by, and with it came 447 pull requests from Servo contributors. It was also the final month of our Outreachy cohort; you can read Jerens’ and Uthman’s blogs to learn about how it went!&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights&lt;/head&gt;
    &lt;p&gt;Our big new feature this month is rendering inline SVG elements (@mukilan, @Loirooriol, #38188, #38603). This improves the appearance of many popular websites.&lt;/p&gt;
    &lt;p&gt;We have implemented named grid line lines and areas (@nicoburns, @loirooriol, #38306, #38574, #38493), still gated behind the &lt;code&gt;layout_grid_enabled&lt;/code&gt; preference (#38306, #38574).&lt;/p&gt;
    &lt;p&gt;Servo now supports CSS ‘font-variation-settings’ on all main desktop platforms (@simonwuelker, @mrobinson, #38642, #38760, #38831). This feature is currently gated behind the &lt;code&gt;layout_variable_fonts_enabled&lt;/code&gt; preference.
We also respect &lt;code&gt;format(*-variations)&lt;/code&gt; inside &lt;code&gt;@font-face&lt;/code&gt; rules (@mrobinson, #38832).
Additionally, Servo now reads data from OpenType Collection (.ttc) system font files on macOS (@nicoburns, #38753), and uses &lt;code&gt;Helvetica&lt;/code&gt; for the ‘system-ui’ font (@dpogue, #39001).&lt;/p&gt;
    &lt;p&gt;Our developer tools continue to make progress! We now have a functional network monitor panel (@uthmaniv, @jdm, #38216, #38601, #38625), and our JS debugger can show potential breakpoints (@delan, @atbrakhi, #38331, #38363, #38333, #38551, #38550, #38334, #38624, #38826, #38797). Additionally, the layout inspector now dims nodes that are not displayed (@simonwuelker, #38575).&lt;/p&gt;
    &lt;p&gt;We’ve fixed a significant source of crashes in the engine: hit testing using outdated display lists (issue #37932). Hit testing in a web rendering engine is the process that determines which element(s) the user’s mouse is hovering over.&lt;/p&gt;
    &lt;p&gt;Previously, this process ran inside of WebRender, which receives a display list representing what should be rendered for a particular page. WebRender runs on a separate thread or process from the actual page content, so display lists are updated asynchronously. By the time we do a hit test, the elements reported may not exist anymore, so we could trigger crashes by (for example) moving the mouse quickly over parts of the page that were rapidly changing.&lt;/p&gt;
    &lt;p&gt;This was fixed by making the hit test operation synchronous and moving it into the same thread as the actual content being tested against, eliminating the possibility of outdated results (@mrobinson, @Loirooriol, @kongbai1996, @yezhizhen, #38480, #38464, #38463, #38884, #38518).&lt;/p&gt;
    &lt;head rend="h2"&gt;Web platform support&lt;/head&gt;
    &lt;head rend="h3"&gt;DOM &amp;amp; JS&lt;/head&gt;
    &lt;p&gt;We’ve upgraded to SpiderMonkey v140 (changelog) (@jdm, #37077, #38563).&lt;/p&gt;
    &lt;p&gt;Numerous pieces of the Trusted Types API are now present in Servo (@TimvdLippe, @jdm, #38595, #37834, #38700, #38736, #38718, #38784, #38871, #8623, #38874, #38872, #38886), all gated behind the &lt;code&gt;dom_trusted_types_enabled&lt;/code&gt; preference.&lt;/p&gt;
    &lt;p&gt;The IndexedDB implementation (gated behind &lt;code&gt;dom_indexeddb_enabled&lt;/code&gt;) is progressing quickly (@arihant2math, @jdm, @rodion, @kkoyung, #28744, #38737, #38836, #38813, #38819, #38115, #38944, #38740, #38891, #38723, #38850, #38735), now reporting errors via &lt;code&gt;IDBRequest&lt;/code&gt; interface and supporting autoincrement keys.&lt;/p&gt;
    &lt;p&gt;A prototype implementation of the CookieStore API is now implemented and gated by the &lt;code&gt;dom_cookiestore_enabled&lt;/code&gt; preference (@sebsebmc, #37968, #38876).&lt;/p&gt;
    &lt;p&gt;Servo now passes over 99.6% of the CSS geometry test suite, thanks to an implementation of matrixTransform() on DOMPointReadOnly, making all geometry interfaces serializable, and adding the SVGMatrix and SVGPoint aliases (@lumiscosity, #38801, #38828, #38810).&lt;/p&gt;
    &lt;p&gt;You can now use the TextEncoderStream API (@minghuaw, #38466). Streams that are piped now correctly pass through &lt;code&gt;undefined&lt;/code&gt; values, too (@gterzian, #38470).
We also fixed a crash in the result of pipeTo() on ReadableStream (@gterzian, #38385).&lt;/p&gt;
    &lt;p&gt;We’ve implemented getModifierState() on MouseEvent (@PotatoCP, #38535), and made a number of changes involving DOM events: ‘mouseleave’ events are fired when the pointer leaves an &amp;lt;iframe&amp;gt; (@mrobinson, @Loirooriol, #38539), pasting from the clipboard into a text input triggers an ‘input’ event (@mrobinson, #37100), focus now occurs after ‘mousedown’ instead of ‘click’ (@yezhizhen, #38589), we ignore ‘mousedown’ and ‘mouseup’ events for elements that are disabled (@yezhizhen, #38671), and removing an event handler attribute like ‘onclick’ clears all relevant event listeners (@TimvdLippe, @kotx, #38734, #39011).&lt;/p&gt;
    &lt;p&gt;Servo now supports scrollIntoView() (@abdelrahman1234567, #38230), and fires a ‘scroll’ event whenever a page is scrolled (@stevennovaryo, #38321). You can now focus an element without scrolling, by passing the &lt;code&gt;{preventScroll: true}&lt;/code&gt; option to focus() (@abdelrahman1234567, #38495).&lt;/p&gt;
    &lt;p&gt;navigator.sendBeacon() is now implemented, gated behind the &lt;code&gt;dom_navigator_sendbeacon_enabled&lt;/code&gt; preference (@TimvdLippe, #38301).
Similarly, the AbortSignal.abort() static method is hidden behind &lt;code&gt;dom_abort_controller_enabled&lt;/code&gt; (@Taym95, #38746).&lt;/p&gt;
    &lt;p&gt;The HTMLDocument interface now exists as a property on the &lt;code&gt;Window&lt;/code&gt; object (@leo030303, #38433).
Meanwhile, the CSS window property is now a WebIDL namespace (@simonwuelker, #38579).
We also implemented the new QuotaExceededError interface (@rmeno12, #38507, #38720), which replaces previous usages of DOMException with the &lt;code&gt;QUOTA_EXCEEDED_ERR&lt;/code&gt; name.&lt;/p&gt;
    &lt;p&gt;Our 2D canvas implementation now supports addPath() on Path2D (@arthmis, #37838) and the restore() methods on CanvasRenderingContext2D and OffscreenCanvas now pop all applied clipping paths (@sagudev, #38496). Additionally, we now support using web fonts in the 2D canvas (@mrobinson, #38979). Meanwhile, the performance continues to improve in the new Vello-based backends (@sagudev, #38406, #38356, #38440, #38437), with asynchronous uploading also showing improvements (@sagudev, @mrobinson, #37776).&lt;/p&gt;
    &lt;p&gt;Muting media elements with the ‘mute’ HTML attribute now works during the initial resource load (@rayguo17, @jschwe, #38462).&lt;/p&gt;
    &lt;p&gt;Modifying stylesheets now integrates better with incremental layout, in both light trees and shadow trees (@coding-joedow, #38530, #38529). Note that calling setProperty() on a readonly CSSStyleDeclaration correctly throws an exception (@simonwuelker, #38677).&lt;/p&gt;
    &lt;head rend="h3"&gt;CSS&lt;/head&gt;
    &lt;p&gt;We’ve upgraded to the upstream Stylo revision as of August 1, 2025.&lt;/p&gt;
    &lt;p&gt;We now support custom CSS properties with the CSS.registerProperty() method (@simonwuelker, #38682), as well as custom element states with the ‘states’ property on ElementInternals (@simonwuelker, #38564).&lt;/p&gt;
    &lt;p&gt;Flexbox cross sizes can no longer end up negative through stretching (@Loirooriol, #38521), while ‘stretch’ on flex items now stretches to the line if possible (@Loirooriol, #38526).&lt;/p&gt;
    &lt;p&gt;Overflow calculations are more accurate, now that we ignore ‘position: fixed’ children of the root element (@stevennovaryo, #38618), compute overflow for &amp;lt;body&amp;gt; separate from the viewport (@shubhamg13, #38825), check for ‘overflow: visible’ in parents and children (@shubhamg13, #38443), and propagate ‘overflow’ to the viewport correctly (@shubhamg13, @Loirooriol, #38598).&lt;/p&gt;
    &lt;p&gt;‘color’ and ‘text-decoration’ properties no longer inherit into the contents of &amp;lt;select&amp;gt; elements (@simonwuelker, #38570).&lt;/p&gt;
    &lt;p&gt;Negative outline offsets work correctly (@lumiscosity, @mrobinson, #38418).&lt;/p&gt;
    &lt;p&gt;Video elements no longer fall back to a preferred aspect ratio of 2 (@Loirooriol, #38705).&lt;/p&gt;
    &lt;p&gt;‘position: sticky’ elements are handled correctly inside CSS transforms (@mrobinson, @Loirooriol, #38391).&lt;/p&gt;
    &lt;head rend="h2"&gt;Performance &amp;amp; Stability&lt;/head&gt;
    &lt;p&gt;We fixed several panics this month, involving IntersectionObserver and missing stacking contexts (@mrobinson, #38473), unpaintable canvases and text (@gterzian, #38664), serializing ‘location’ properties on Window objects (@jdm, #38709), and navigations canceled before HTTP headers are received (@gterzian, #38739).&lt;/p&gt;
    &lt;p&gt;We also fixed a number of performance pitfalls. The document rendering loop is now throttled to 60 FPS (@mrobinson, @Loirooriol, #38431), while animated images do less work when advancing the current frame (@mrobinson, #38857). In addition, elements with CSS images will not trigger page reflow until their image data is fully available (@coding-joedow, #38916).&lt;/p&gt;
    &lt;p&gt;Finally, we made improvements to memory usage and binary size. Inline stylesheets are now deduplicated, which can have a significant impact on pages with lots of form inputs or custom elements with common styles (@coding-joedow, #38540). We also removed many unused pieces of the ICU library, saving 16MB from the final binary.&lt;/p&gt;
    &lt;head rend="h2"&gt;Embedding&lt;/head&gt;
    &lt;p&gt;Servo has declared a Minimum Supported Rust Version (1.85.0), and this is verified with every new pull request (@jschwe, #37152).&lt;/p&gt;
    &lt;p&gt;Evaluating JS from the embedding layer now reports an error if the evaluation failed for any reason (@rodio, #38602).&lt;/p&gt;
    &lt;p&gt;Our WebDriver implementation now passes 80% of the implementation conformance tests. This is the result of lots of work on handling user prompts (@PotatoCP, #38591), computing obscured/disabled elements while clicking (@yezhizhen, #38497, #38841, #38436, #38490, #38383), and improving window focus behaviours (@yezhizhen, #38889, #38909). We also implemented the Get Window Handles command (@longvatrong111, @yezhizhen, #38622, #38745), added support for getting element boolean attributes (@kkoyung, #38401), and added more accurate errors for a number of commands (@yezhizhen, @longvatrong111, #38620, #38357). The Element Clear command now clears &lt;code&gt;&amp;lt;input type="file"&amp;gt;&lt;/code&gt; elements correctly (@PotatoCP, #38536), and Element Send Keys now appends to file inputs with the ‘multiple’ attribute.&lt;/p&gt;
    &lt;head rend="h2"&gt;servoshell&lt;/head&gt;
    &lt;p&gt;We now display favicons of each top-level page in the tab bar (@simonwuelker, #36680).&lt;/p&gt;
    &lt;p&gt;Resizing the browser window to a very small dimension no longer crashes the browser (@leo030303, #38461). Element hit testing in full screen mode now works as expected (@yezhizhen, #38328).&lt;/p&gt;
    &lt;p&gt;Various popup dialogs, such as the &amp;lt;select&amp;gt; option chooser dialog, can now be closed without choosing a value (@TimvdLippe, #38373, #38949). Additionally, the browser now responds to a popup closing without any other inputs (@lumiscosity, #39038).&lt;/p&gt;
    &lt;head rend="h2"&gt;Donations&lt;/head&gt;
    &lt;p&gt;Thanks again for your generous support! We are now receiving 5552 USD/month (+18.3% over July) in recurring donations.&lt;/p&gt;
    &lt;p&gt;Historically this has helped cover the cost of our speedy CI servers and Outreachy interns. Thanks to your support, we’re now setting up two new CI servers for benchmarking, and funding the work of our long-time maintainer Josh Matthews (@jdm), with a particular focus on helping more people contribute to Servo.&lt;/p&gt;
    &lt;p&gt;Keep an eye out for further CI improvements in the coming months, including ten-minute WPT builds, macOS arm64 builds, and faster pull request checks.&lt;/p&gt;
    &lt;p&gt;Servo is also on thanks.dev, and already 15 GitHub users (−7 from July) that depend on Servo are sponsoring us there. If you use Servo libraries like url, html5ever, selectors, or cssparser, signing up for thanks.dev could be a good way for you (or your employer) to give back to the community.&lt;/p&gt;
    &lt;p&gt;As always, use of these funds will be decided transparently in the Technical Steering Committee. For more details, head to our Sponsorship page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45373501</guid><pubDate>Thu, 25 Sep 2025 15:02:55 +0000</pubDate></item><item><title>Microsoft blocks Israel's use of its tech. in mass surveillance of Palestinians</title><link>https://www.theguardian.com/world/2025/sep/25/microsoft-blocks-israels-use-of-its-technology-in-mass-surveillance-of-palestinians</link><description>&lt;doc fingerprint="ad20ab19270ca9c2"&gt;
  &lt;main&gt;
    &lt;p&gt;Microsoft has terminated the Israeli military’s access to technology it used to operate a powerful surveillance system that collected millions of Palestinian civilian phone calls made each day in Gaza and the West Bank, the Guardian can reveal.&lt;/p&gt;
    &lt;p&gt;Microsoft told Israeli officials late last week that Unit 8200, the military’s elite spy agency, had violated the company’s terms of service by storing the vast trove of surveillance data in its Azure cloud platform, sources familiar with the situation said.&lt;/p&gt;
    &lt;p&gt;The decision to cut off Unit 8200’s ability to use some of its technology results directly from an investigation published by the Guardian last month. It revealed how Azure was being used to store and process the trove of Palestinian communications in a mass surveillance programme.&lt;/p&gt;
    &lt;p&gt;In a joint investigation with the Israeli-Palestinian publication +972 Magazine and the Hebrew-language outlet Local Call, the Guardian revealed how Microsoft and Unit 8200 had worked together on a plan to move large volumes of sensitive intelligence material into Azure.&lt;/p&gt;
    &lt;p&gt;The project began after a meeting in 2021 between Microsoft’s chief executive, Satya Nadella, and the unit’s then commander, Yossi Sariel.&lt;/p&gt;
    &lt;p&gt;In response to the investigation, Microsoft ordered an urgent external inquiry to review its relationship with Unit 8200. Its initial findings have now led the company to cancel the unit’s access to some of its cloud storage and AI services.&lt;/p&gt;
    &lt;p&gt;Equipped with Azure’s near-limitless storage capacity and computing power, Unit 8200 had built an indiscriminate new system allowing its intelligence officers to collect, play back and analyse the content of cellular calls of an entire population.&lt;/p&gt;
    &lt;p&gt;The project was so expansive that, according to sources from Unit 8200 – which is equivalent in its remit to the US National Security Agency – a mantra emerged internally that captured its scale and ambition: “A million calls an hour.”&lt;/p&gt;
    &lt;p&gt;According to several sources, the enormous repository of intercepted calls – which amounted to as much as 8,000 terabytes of data – was held in a Microsoft datacentre in the Netherlands. Within days of the Guardian publishing the investigation, Unit 8200 appears to have swiftly moved the surveillance data out of the country.&lt;/p&gt;
    &lt;p&gt;According to sources familiar with the huge data transfer outside of the EU country, it occurred in early August. Intelligence sources said Unit 8200 planned to transfer the data to the Amazon Web Services cloud platform. Neither the Israel Defense Forces (IDF) nor Amazon responded to a request for comment.&lt;/p&gt;
    &lt;p&gt;The extraordinary decision by Microsoft to end the spy agency’s access to key technology was made amid pressure from employees and investors over its work for Israel’s military and the role its technology has played in the almost two-year offensive in Gaza.&lt;/p&gt;
    &lt;p&gt;A United Nations commission of inquiry recently concluded that Israel had committed genocide in Gaza, a charge denied by Israel but supported by many experts in international law.&lt;/p&gt;
    &lt;p&gt;The Guardian’s joint investigation prompted protests at Microsoft’s US headquarters and one of its European datacentres, as well as demands by a worker-led campaign group, No Azure for Apartheid, to end all ties to the Israeli military.&lt;/p&gt;
    &lt;p&gt;On Thursday, Microsoft’s vice-chair and president, Brad Smith, informed staff of the decision. In an email seen by the Guardian, he said the company had “ceased and disabled a set of services to a unit within the Israel ministry of defense”, including cloud storage and AI services.&lt;/p&gt;
    &lt;p&gt;Smith wrote: “We do not provide technology to facilitate mass surveillance of civilians. We have applied this principle in every country around the world, and we have insisted on it repeatedly for more than two decades.”&lt;/p&gt;
    &lt;p&gt;The decision brings to an abrupt end a three-year period in which the spy agency operated its surveillance programme using Microsoft’s technology.&lt;/p&gt;
    &lt;p&gt;Unit 8200 used its own expansive surveillance capabilities to intercept and collect the calls. The spy agency then used a customised and segregated area within the Azure platform, allowing for the data to be retained for extended periods of time and analysed using AI-driven techniques.&lt;/p&gt;
    &lt;p&gt;Although the initial focus of the surveillance system was the West Bank, where an estimated 3 million Palestinians live under Israeli military occupation, intelligence sources said the cloud-based storage platform had been used in the Gaza offensive to facilitate the preparation of deadly airstrikes.&lt;/p&gt;
    &lt;p&gt;The revelations highlighted how Israel has relied on the services and infrastructure of major US technology companies to support its bombardment of Gaza, which has killed more than 65,000 Palestinians, mostly civilians, and created a profound humanitarian and starvation crisis.&lt;/p&gt;
    &lt;p&gt;According to a document seen by the Guardian, a senior Microsoft executive told Israel’s ministry of defence late last week: “While our review is ongoing, we have at this juncture identified evidence that supports elements of the Guardian’s reporting.”&lt;/p&gt;
    &lt;p&gt;The executive told Israel officials that Microsoft “is not in the business of facilitating the mass surveillance of civilians” and notified them that it would “disable” access to services that supported the Unit 8200 surveillance project and suspend its use of some AI products.&lt;/p&gt;
    &lt;p&gt;The termination is the first known case of a US technology company withdrawing services provided to the Israeli military since the beginning of its war on Gaza.&lt;/p&gt;
    &lt;p&gt;The decision has not affected Microsoft’s wider commercial relationship with the IDF, which is a longstanding client and will retain access to other services. The termination will raise questions within Israel about the policy of holding sensitive military data in a third-party cloud hosted overseas.&lt;/p&gt;
    &lt;p&gt;Last month’s revelations about Unit 8200’s use of Microsoft technology followed an earlier investigation by the Guardian and its partners into the broader relationship between the company and the Israeli military.&lt;/p&gt;
    &lt;p&gt;That story, published in January and based on leaked files, showed how the IDF’s reliance on Azure and its AI systems surged in the most intensive phase of its Gaza campaign.&lt;/p&gt;
    &lt;p&gt;After that report, Microsoft launched its first review of how the IDF uses its services. It said in May it had “found no evidence to date” the military had failed to comply with its terms of service, or used Azure and its AI technology “to target or harm people” in Gaza.&lt;/p&gt;
    &lt;p&gt;However, the Guardian investigation with +972 and Local Call published in August, which revealed the cloud-based surveillance project had been used to research and identify bombing targets in Gaza, led the company to reassess its conclusions.&lt;/p&gt;
    &lt;p&gt;The disclosures caused alarm among senior Microsoft executives, sparking concerns that some of its Israel-based employees may not have been fully transparent about their knowledge of how Unit 8200 used Azure when questioned as part of the review.&lt;/p&gt;
    &lt;p&gt;The company said its executives, including Nadella, were not aware Unit 8200 planned to use, or ultimately used, Azure to store the content of intercepted Palestinian calls.&lt;/p&gt;
    &lt;p&gt;Microsoft then launched its second and more targeted review, which was overseen by lawyers at the US firm Covington &amp;amp; Burling. In his note to staff, Smith said the inquiry had not accessed any customer data but its findings were based on a review of internal Microsoft documents, emails and messages between staff.&lt;/p&gt;
    &lt;p&gt;“I want to note our appreciation for the reporting of the Guardian,” Smith wrote, noting that it had brought to light “information we could not access in light of our customer privacy commitments”. He added: “Our review is ongoing.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45373564</guid><pubDate>Thu, 25 Sep 2025 15:06:47 +0000</pubDate></item><item><title>FTC Secures Historic $2.5B Settlement Against Amazon</title><link>https://www.ftc.gov/news-events/news/press-releases/2025/09/ftc-secures-historic-25-billion-settlement-against-amazon</link><description>&lt;doc fingerprint="2c79c358257e2788"&gt;
  &lt;main&gt;
    &lt;p&gt;The Federal Trade Commission has secured a historic order with Amazon.com, Inc., as well as Senior Vice President Neil Lindsay and Vice President Jamil Ghani, settling allegations that Amazon enrolled millions of consumers in Prime subscriptions without their consent, and knowingly made it difficult for consumers to cancel. Amazon will be required to pay a $1 billion civil penalty, provide $1.5 billion in refunds back to consumers harmed by their deceptive Prime enrollment practices, and cease unlawful enrollment and cancellation practices for Prime.&lt;/p&gt;
    &lt;p&gt;“Today, the Trump-Vance FTC made history and secured a record-breaking, monumental win for the millions of Americans who are tired of deceptive subscriptions that feel impossible to cancel,” said FTC Chairman Andrew N. Ferguson. “The evidence showed that Amazon used sophisticated subscription traps designed to manipulate consumers into enrolling in Prime, and then made it exceedingly hard for consumers to end their subscription. Today, we are putting billions of dollars back into Americans’ pockets, and making sure Amazon never does this again. The Trump-Vance FTC is committed to fighting back when companies try to cheat ordinary Americans out of their hard-earned pay.”&lt;/p&gt;
    &lt;p&gt;The FTC has charged Amazon and several Amazon executives with knowingly misleading millions of consumers into enrolling in Prime, violating the FTC Act and the Restore Online Shoppers’ Confidence Act (ROSCA). The FTC alleged Amazon created confusing and deceptive user interfaces to lead consumers to enroll in Prime without their knowledge. Compounding these deceptive enrollment practices, Amazon also created a complex and difficult process for consumers seeking to cancel their Prime subscription, with the goal of preventing consumers from cancelling Prime. Amazon documents discovered in the lead up to trial showed that Amazon executives and employees knowingly discussed these unlawful enrollment and cancellation issues, with comments like “subscription driving is a bit of a shady world” and leading consumers to unwanted subscriptions is “an unspoken cancer.”&lt;/p&gt;
    &lt;p&gt;The historic monetary judgment contained in the settlement is only the third ROSCA case in which the FTC has obtained a civil penalty. It includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a $1 billion civil penalty, which is the largest ever in a case involving an FTC rule violation;&lt;/item&gt;
      &lt;item&gt;$1.5 billion in consumer redress, providing full relief for the estimated 35 million consumers impacted by unwanted Prime enrollment or deferred cancellation. This is the second-highest restitution award ever obtained by FTC action.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Additionally, the settlement requires Amazon to stop their unlawful practices and make meaningful changes to the Prime enrollment and cancellation flows by:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;including a clear and conspicuous button for customers to decline Prime. Amazon can no longer have a button that says, “No, I don’t want Free Shipping.”&lt;/item&gt;
      &lt;item&gt;Including clear and conspicuous disclosures about all material terms of Prime during the Prime enrollment process, such as the cost, the date and frequency of charges to consumers, whether the subscription auto-renews, and cancellation procedures.&lt;/item&gt;
      &lt;item&gt;creating an easy way for consumers to cancel Prime, using the same method that consumers used to sign up. The process cannot be difficult, costly, or time-consuming and must be available using the same method that consumers used to sign up; and&lt;/item&gt;
      &lt;item&gt;paying for an independent, third-party supervisor to monitor Amazon’s compliance with the consumer redress distribution process.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Commission vote approving the stipulated final order was 3-0. The FTC filed the proposed order in the U.S. District Court for the Western District of Washington.&lt;/p&gt;
    &lt;p&gt;NOTE: Stipulated final orders have the force of law when approved and signed by the District Court judge.&lt;/p&gt;
    &lt;p&gt;The Federal Trade Commission works to promote competition and protect and educate consumers. The FTC will never demand money, make threats, tell you to transfer money, or promise you a prize. Learn more about consumer topics at consumer.ftc.gov, or report fraud, scams, and bad business practices at ReportFraud.ftc.gov. Follow the FTC on social media, read consumer alerts and the business blog, and sign up to get the latest FTC news and alerts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45374064</guid><pubDate>Thu, 25 Sep 2025 15:35:19 +0000</pubDate></item><item><title>ChatControl: EU wants to scan all private messages, even in encrypted apps</title><link>https://metalhearf.fr/posts/chatcontrol-wants-your-private-messages/</link><description>&lt;doc fingerprint="b516b17038a1bfe5"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction #&lt;/head&gt;
    &lt;p&gt;The 🇪🇺 European Union is advancing legislation that could fundamentally change how we communicate online. ChatControl would require all messaging platforms to automatically scan their users’ private messages and images.&lt;/p&gt;
    &lt;p&gt;Yes, even encrypted ones like Signal, WhatsApp and Telegram. No, you can’t opt out.&lt;/p&gt;
    &lt;p&gt;This isn’t just another privacy policy update you can ignore. If passed, this EU regulation (strongest and most binding legal instrument in EU law) would automatically apply to all member states without any wiggle room for national interpretation. It would even override constitutional protections for communication privacy and establish unprecedented mass surveillance of private communications.&lt;/p&gt;
    &lt;p&gt;The official justification? Fighting child sexual abuse material (CSAM). Protecting children is undeniably crucial, but the proposed methods would eliminate digital privacy for 450 million Europeans and set a global precedent for mass surveillance.&lt;/p&gt;
    &lt;p&gt;This surveillance trend extends beyond Europe: 🇨🇭 Switzerland is advancing metadata retention requirements, the 🇬🇧 UK is implementing comprehensive age verification systems and now the 🇪🇺 EU proposes to scan every private message. Each initiative is positioned as child protection policy, but the implications reach far beyond their stated goals.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is ChatControl #&lt;/head&gt;
    &lt;p&gt;ChatControl is what critics call the EU’s proposed Regulation to Prevent and Combat Child Sexual Abuse, also known as CSAR (Child Sexual Abuse Regulation).&lt;/p&gt;
    &lt;p&gt;The proposal builds on surveillance techniques already deployed by major tech companies. Meta analyzes all Facebook Messenger conversations and unencrypted WhatsApp data (profile photos, group descriptions). Apple announced similar scanning for iCloud content in 2021, though they later suspended the program.&lt;/p&gt;
    &lt;p&gt;This turns voluntary corporate surveillance into mandatory government-ordered scanning. A temporary 2021 EU regulation allowed platforms to scan content voluntarily for three years. That authorization expired in 2024, which is why CSAR was proposed. The temporary regulation merely permitted scanning; CSAR would make detection obligatory under certain conditions.&lt;/p&gt;
    &lt;p&gt;There’s also the Roadmap for Lawful Access to Data which has an even bigger goal: making all our digital data readable by authorities upon request. We’ll dive deeper into this broader surveillance agenda later.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scope and Coverage #&lt;/head&gt;
    &lt;p&gt;CSAR casts an extremely wide net. The regulation would apply to all interpersonal communication service providers, not just obvious targets like Signal, WhatsApp, or Telegram, but also:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Email providers&lt;/item&gt;
      &lt;item&gt;Dating apps&lt;/item&gt;
      &lt;item&gt;Gaming platforms with chat features&lt;/item&gt;
      &lt;item&gt;Social media platforms&lt;/item&gt;
      &lt;item&gt;File hosting services (Google Drive, iCloud, DropBox…)&lt;/item&gt;
      &lt;item&gt;App stores&lt;/item&gt;
      &lt;item&gt;Even small community hosting services run by associations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This means virtually any digital service that allows people to communicate or share content would fall under surveillance requirements. The scope extends far beyond what most people imagine when they hear messaging apps.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it Works #&lt;/head&gt;
    &lt;p&gt;ChatControl relies on Client-Side Scanning. Your device becomes a monitoring station that analyzes your content before encryption happens.&lt;/p&gt;
    &lt;p&gt;This represents a fundamental shift away from traditional surveillance that intercepts messages during transmission. With ChatControl, every message gets automatically checked, assuming everyone is guilty until proven innocent and effectively reversing the presumption of innocence.&lt;/p&gt;
    &lt;head rend="h3"&gt;Technical Implementation #&lt;/head&gt;
    &lt;p&gt;The system would automatically scan for three categories of content before encryption:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Known illegal content: Images or videos already catalogued by authorities as CSAM. Your device creates hash fingerprints of your content and compares them against databases of known illegal material.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unknown potential content: Photos or videos that might constitute CSAM but haven’t been previously identified. AI algorithms analyze visual elements (like exposed skin) to flag potentially problematic content based on statistical models.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Grooming behavior: Text analysis using AI to identify communication patterns that match predefined indicators of adults soliciting children. This involves scanning the actual content of your private conversations.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If something gets flagged, it automatically gets reported to authorities. No human checks it first, that would be impossible given the billions of daily messages. This would be mandatory for all messaging platforms in 🇪🇺 Europe.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why This Breaks Encryption #&lt;/head&gt;
    &lt;p&gt;ChatControl doesn’t break encryption, it bypasses it entirely. While your messages still get encrypted during transmission, the system defeats the purpose of end-to-end encryption by examining your content before it gets encrypted. True E2EE means only you and your recipient can read messages: no government, no company, no algorithm should peek inside. This surveillance violates that principle by inserting monitoring at the source.&lt;/p&gt;
    &lt;p&gt;Privacy-focused companies like Proton point out this approach might be worse than encryption backdoors. Backdoors give authorities access to communications you share with others. This system examines everything on your device, whether you share it or not.&lt;/p&gt;
    &lt;p&gt;Your encrypted messaging app becomes spyware. Supporters claim this protects privacy because scanning happens locally, but surveillance built into your device makes it impossible to escape.&lt;/p&gt;
    &lt;head rend="h3"&gt;Governance Structure #&lt;/head&gt;
    &lt;p&gt;The proposal would create a centralized EU Centre on Child Sexual Abuse to receive all reports, but EU institutions wouldn’t control the scanning technology itself.&lt;/p&gt;
    &lt;p&gt;Service providers would face additional obligations beyond scanning. They would need to conduct risk assessments to evaluate and minimize the potential for illegal content sharing on their platforms. This requires collecting detailed information about their users (age groups, content types) that many privacy-focused services deliberately avoid gathering.&lt;/p&gt;
    &lt;p&gt;The regulation also pushes for mandatory age verification systems. No viable, privacy-respecting age verification technology currently exists. These systems would eliminate online anonymity, requiring users to prove their identity to access digital services.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-World Impact #&lt;/head&gt;
    &lt;head rend="h3"&gt;Encryption Concerns #&lt;/head&gt;
    &lt;p&gt;ChatControl fits into a broader political strategy. Since the 1990s crypto wars, certain states have argued that privacy-protecting technologies, especially encryption, obstruct police investigations. These technologies are designed to do exactly that, protect everyone’s ability to control their expression and communication.&lt;/p&gt;
    &lt;p&gt;The European Commission’s Roadmap for Lawful Access to Data wants to make all digital data accessible to authorities by 2030. This involves systematically weakening encryption rather than simply bypassing it.&lt;/p&gt;
    &lt;p&gt;Edward Snowden’s revelations ten years ago led to widespread adoption of encryption and institutional consensus supporting the right to encrypted communication. But governments remain frustrated by their inability to access private communications. We’re seeing a return to authoritarian positions using terrorism, organized crime and child exploitation as justifications for undermining encryption.&lt;/p&gt;
    &lt;p&gt;🇩🇰 Danish Minister of Justice Peter Hummelgaard, chief architect of the current ChatControl proposal, recently stated: “We must break with the totally erroneous perception that it is everyone’s civil liberty to communicate on encrypted messaging services.” Well, there you have it folks: encrypted communication isn’t a civil liberty anymore. You cypherpunks were wrong all along. /s&lt;/p&gt;
    &lt;p&gt;Similarly in 🇫🇷 France, both Bernard Cazeneuve and Emmanuel Macron have explicitly stated their desire to control encrypted messaging, seeking to pierce the privacy of millions who use these services.&lt;/p&gt;
    &lt;p&gt;CSAR provides the perfect opportunity for member states to finally design and implement a generalized surveillance tool for monitoring population communications. Crossing this threshold means eliminating all confidentiality from communications using digital infrastructure.&lt;/p&gt;
    &lt;head rend="h3"&gt;False Positives #&lt;/head&gt;
    &lt;p&gt;These scanning systems get it wrong most of the time. Studies show approximately 80% of algorithmic reports are false positives: innocent content incorrectly flagged as illegal. 🇮🇪 Irish law enforcement confirms this: only 20.3% of 4,192 automated reports actually contained illegal material.&lt;/p&gt;
    &lt;p&gt;Even with hypothetical 99% accuracy (which current systems don’t achieve), scanning billions of daily messages would generate millions of false accusations. Police resources would be overwhelmed investigating innocent families sharing vacation photos while real crimes go uninvestigated.&lt;/p&gt;
    &lt;p&gt;Innocent content regularly triggers these systems: family photos, teenage conversations, educational materials and medical communications. Consider this real case: a father was automatically reported to police after sending photos of his child’s medical condition to their doctor. Google’s algorithms flagged this legitimate medical consultation as potential abuse, permanently closed his account and refused all appeals. His digital life was destroyed by an algorithm that couldn’t distinguish between medical care and criminal activity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scientific Opposition #&lt;/head&gt;
    &lt;p&gt;For the third time in three years, over 600 cryptographers, security researchers and scientists across 35 countries have co-signed an open letter explaining why this mass scanning project is “technically unfeasible”, constitutes a “danger to democracy” and would “completely compromise” the security and privacy of all European citizens.&lt;/p&gt;
    &lt;p&gt;The letter emphasizes that client-side scanning cannot distinguish between legal and illegal content without fundamentally breaking encryption and creating vulnerabilities that malicious actors can exploit.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the Commission has provided no serious studies demonstrating the effectiveness, reliability or appropriateness of these intrusive measures for actually protecting children. Industry claims appear to have taken precedence over evidence-based policy-making.&lt;/p&gt;
    &lt;p&gt;Genuine security emerges through thoughtful design where security measures and civil liberties function as complementary forces, not opposing ones.&lt;/p&gt;
    &lt;head rend="h3"&gt;Easily Defeated #&lt;/head&gt;
    &lt;p&gt;The fundamental flaw in ChatControl becomes clear when examining how easily determined actors can circumvent these scanning systems. Criminals don’t need sophisticated techniques to bypass client-side scanning; they use well-documented public knowledge already employed by malicious actors.&lt;/p&gt;
    &lt;p&gt;Layered Encryption&lt;lb/&gt; Encrypt files with standard tools like GPG before messaging. Hell, even a basic Caesar cipher would be sufficient to bypass detection. Since client-side scanning occurs after user encryption but before transport encryption, pre-encrypted content looks like random data to detection algorithms. Recipients decrypt locally with shared keys.&lt;/p&gt;
    &lt;p&gt;External Platform Bypass&lt;lb/&gt; Upload content to any third-party platform (Dropbox, OneDrive, anonymous file hosts, or obscure hosting services) and share links instead of files. The scanner sees innocent text containing a URL while the actual content sits untouched on external servers.&lt;/p&gt;
    &lt;p&gt;Custom Messaging Clients&lt;lb/&gt; Open-source protocols like XMPP and Matrix allow custom client development. Modified clients can automatically implement cloud storage and encryption workflows transparently. Users experience normal messaging while completely evading surveillance infrastructure.&lt;/p&gt;
    &lt;p&gt;Digital Steganography&lt;lb/&gt; Steganographic techniques embed data within innocent images. Family photos can carry hidden payloads invisible to both human operators and AI systems. Tools like OpenStego make this accessible to average users.&lt;/p&gt;
    &lt;p&gt;Platform Migration&lt;lb/&gt; Criminal networks can shift to decentralized platforms, peer-to-peer networks or services outside EU jurisdiction. Tor-based messaging, blockchain communications or servers in non-compliant countries remain beyond ChatControl’s reach.&lt;/p&gt;
    &lt;p&gt;ChatControl catches only amateur criminals who directly attach problematic content to messages. Professional networks already employ these evasion techniques as standard practice. EU legislation won’t make them forget how computers work.&lt;/p&gt;
    &lt;p&gt;The system fails at protecting children while succeeding at mass civilian monitoring. It’s not a bug, it’s a feature.&lt;/p&gt;
    &lt;head rend="h2"&gt;Business Interests #&lt;/head&gt;
    &lt;head rend="h3"&gt;Industry Players #&lt;/head&gt;
    &lt;p&gt;The child protection narrative masks concerning business interests. The European Commission based its CSAR proposal primarily on claims from industry players rather than independent research.&lt;/p&gt;
    &lt;p&gt;Commercial surveillance companies would manage the technology with guaranteed access to the European market. Organizations like Thorn (co-founded by actor Ashton Kutcher), Microsoft’s PhotoDNA and other tech companies develop these detection systems while simultaneously lobbying for regulations that would require their adoption across Europe.&lt;/p&gt;
    &lt;p&gt;These companies develop the detection technologies and lobby for laws mandating their adoption, creating a profitable feedback loop. The proposal would secure privileged market positions for surveillance companies across hundreds of millions of European users. Pretty nice, isn’t it?&lt;/p&gt;
    &lt;p&gt;These systems would be:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Proprietary: Built on closed-source code with methods hidden from public view&lt;/item&gt;
      &lt;item&gt;Unverifiable: Operating without meaningful external examination or accountability&lt;/item&gt;
      &lt;item&gt;Legally powerful: Capable of starting criminal proceedings through algorithmic decisions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Rhetorical Tactics #&lt;/head&gt;
    &lt;p&gt;Commissioner Ylva Johansson consistently emphasizes this narrative in her communications:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“[Privacy defenders make a lot of noise], but someone has to speak for the children.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;“Think of the children” is a well-documented political rhetoric technique that appeals to emotion rather than evidence. While child protection is genuinely important, this approach frames any opposition as being against child welfare, making nuanced discussion more difficult.&lt;/p&gt;
    &lt;p&gt;This creates a false choice. Privacy isn’t a luxury for troublemakers, it’s a fundamental right that protects journalists, whistleblowers, activists and ordinary people from unwarranted intrusion.&lt;/p&gt;
    &lt;p&gt;Critics aren’t opposing child protection. We’re questioning whether undermining privacy rights for 450 million 🇪🇺 Europeans is the most effective approach when targeted alternatives exist that preserve rights.&lt;/p&gt;
    &lt;head rend="h2"&gt;EU Country Positions #&lt;/head&gt;
    &lt;p&gt;Understanding how 🇪🇺 EU member states position themselves on this legislation is crucial, as their votes will determine whether ChatControl becomes reality.&lt;/p&gt;
    &lt;head rend="h3"&gt;Vote Breakdown #&lt;/head&gt;
    &lt;p&gt;Countries that support ChatControl (12): 🇧🇬 Bulgaria • 🇭🇷 Croatia • 🇨🇾 Cyprus • 🇩🇰 Denmark • 🇫🇷 France • 🇭🇺 Hungary • 🇮🇪 Ireland • 🇱🇹 Lithuania • 🇲🇹 Malta • 🇵🇹 Portugal • 🇷🇴 Romania • 🇪🇸 Spain&lt;/p&gt;
    &lt;p&gt;Countries that oppose ChatControl (7): 🇦🇹 Austria • 🇨🇿 Czech Republic • 🇪🇪 Estonia • 🇫🇮 Finland • 🇱🇺 Luxembourg • 🇳🇱 Netherlands • 🇵🇱 Poland&lt;/p&gt;
    &lt;p&gt;Countries still undecided (8): 🇧🇪 Belgium • 🇩🇪 Germany • 🇬🇷 Greece • 🇮🇹 Italy • 🇱🇻 Latvia • 🇸🇰 Slovakia • 🇸🇮 Slovenia • 🇸🇪 Sweden&lt;/p&gt;
    &lt;head rend="h3"&gt;National Stances #&lt;/head&gt;
    &lt;head&gt;💪 Strong opposition (the good guys) (click to expand)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;🇦🇹 Austria: Constitutional and privacy concerns.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;🇨🇿 Czech Republic: Prime Minister explicitly rejects proposals that would allow widespread monitoring of citizens’ private digital communications.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;🇪🇪 Estonia: Acknowledges sincere concerns about child exploitation, but opposes undermining end-to-end encryption and forcing mass surveillance.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;🇫🇮 Finland: Cannot support the latest compromise proposal because it contains a constitutionally problematic identification order.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;🇱🇺 Luxembourg: Rejects broad surveillance measures like client-side scanning and insists that EU regulation must ensure proportional, targeted detection to protect citizens’ fundamental rights.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;🇳🇱 Netherlands: Strong privacy protection stance.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;🇵🇱 Poland: Opposition to mass surveillance measures.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;🤷 Undecided positions (click to expand)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🇧🇪 Belgium: The N-VA party calls ChatControl a “monster that invades your privacy and cannot be tamed”. Despite this, Belgium backed Denmark’s compromise during September meetings. Mixed signals from Brussels.&lt;/item&gt;
      &lt;item&gt;🇩🇪 Germany: Won’t break encryption but wants to find middle ground. They’re trying to craft their own compromise instead of rejecting ChatControl outright. Germany’s fence-sitting could be decisive.&lt;/item&gt;
      &lt;item&gt;🇬🇷 Greece: Still figuring out the technical details. No clear stance yet.&lt;/item&gt;
      &lt;item&gt;🇮🇹 Italy: Has concerns about expanding the scope to cover new CSAM detection. Rome seems hesitant about how far this thing could reach.&lt;/item&gt;
      &lt;item&gt;🇱🇻 Latvia: The government likes what they see on paper but worries about political backlash after summer attention. Classic politicians hedging their bets.&lt;/item&gt;
      &lt;item&gt;🇸🇰 Slovakia: Playing the wait-and-see game. No commitment either way.&lt;/item&gt;
      &lt;item&gt;🇸🇮 Slovenia: Dealing with constitutional headaches around privacy. Another country wrestling with legal implications.&lt;/item&gt;
      &lt;item&gt;🇸🇪 Sweden: Stockholm is still reading the fine print. Taking their time to decide.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Current Status #&lt;/head&gt;
    &lt;p&gt;Current situation: Country positions continue shifting regularly since September 12. With 12 countries supporting, 7 opposing, and 8 undecided, ChatControl supporters still fall short of the 65% EU population threshold needed for a qualified majority. The opposition maintains enough demographic weight to block the proposal for now, but the situation remains fluid as the interim regulation approaches expiration.&lt;/p&gt;
    &lt;head&gt;📅 Timeline of Events (click to expand)&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;ChatControl Proposal Introduced&lt;/head&gt;&lt;head rend="h3"&gt;May 11, 2022&lt;/head&gt;&lt;head rend="h4"&gt;European Commission&lt;/head&gt;The European Commission unveils the original ChatControl proposal, requiring all email and messaging providers to scan communications for child sexual abuse material.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Danish Presidency Takes Charge&lt;/head&gt;&lt;head rend="h3"&gt;Jul 1, 2025&lt;/head&gt;&lt;head rend="h4"&gt;EU Council Presidency&lt;/head&gt;🇩🇰 Denmark assumes the EU Council Presidency and immediately reintroduces ChatControl as a top legislative priority, targeting October 14, 2025 for adoption.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Support Momentum Builds&lt;/head&gt;&lt;head rend="h3"&gt;Jul 28, 2025&lt;/head&gt;&lt;head rend="h4"&gt;15 Member States&lt;/head&gt;Fifteen EU member states back the ChatControl proposal, reversing earlier resistance. 🇫🇷 France has shifted its position and now supports the proposal. 🇩🇪 Germany remains the crucial undecided vote.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Opposition Wave Begins&lt;/head&gt;&lt;head rend="h3"&gt;Aug 26, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Czech Republic&lt;/head&gt;🇨🇿 Czech Prime Minister Petr Fiala announces total opposition on behalf of the entire coalition government.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Constitutional Concerns&lt;/head&gt;&lt;head rend="h3"&gt;Aug 29, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Finland&lt;/head&gt;🇫🇮 Finland rejects the compromise proposal due to constitutionally problematic detection requirements.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Blocking Minority Secured&lt;/head&gt;&lt;head rend="h3"&gt;Sep 10, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Germany, Luxembourg, Slovakia&lt;/head&gt;🇩🇪 Germany, 🇱🇺 Luxembourg, and 🇸🇰 Slovakia officially oppose breaking encryption. This creates the blocking minority needed to stop the proposal.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Estonia Joins Opposition&lt;/head&gt;&lt;head rend="h3"&gt;Sep 14, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Privacy Protection&lt;/head&gt;🇪🇪 Estonia acknowledges child exploitation concerns but opposes undermining end-to-end encryption and mass surveillance.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Germany Wavers&lt;/head&gt;&lt;head rend="h3"&gt;Sep 16, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Position Unclear&lt;/head&gt;🇩🇪 Germany refrains from taking a definitive stance during the LEWP meeting, despite previous encryption concerns. Position becomes uncertain.&lt;/item&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;Three Countries Flip&lt;/head&gt;&lt;head rend="h3"&gt;Sep 23, 2025&lt;/head&gt;&lt;head rend="h4"&gt;Belgium, Latvia, Italy&lt;/head&gt;🇧🇪 Belgium, 🇱🇻 Latvia, and 🇮🇹 Italy have moved away from supporting the proposal and are now undecided. Country positions continue changing regularly since September 12.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Consequences #&lt;/head&gt;
    &lt;p&gt;The effects of these proposals go beyond individual privacy concerns.&lt;/p&gt;
    &lt;p&gt;Cybersecurity gets compromised&lt;lb/&gt; Adding deliberate vulnerabilities to encryption creates weaknesses that everyone can exploit. Any backdoor for authorized access becomes a potential entry point for criminals and foreign intelligence services. In February 2024, the 🇪🇺 European Court of Human Rights already determined that mandating weakened encryption “cannot be regarded as necessary in a democratic society”.&lt;/p&gt;
    &lt;p&gt;Innovation suffers&lt;lb/&gt; 🇪🇺 European cybersecurity companies would face an impossible situation in global markets. How could they credibly sell security solutions when regulations require them to build in access mechanisms that undermine those very protections?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Buy our ultra-secure encrypted stuff!” (Terms and conditions apply, government backdoors included)."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Tech companies will leave Europe&lt;lb/&gt; Privacy-focused services that moved to 🇪🇺 Europe after the Snowden revelations are already signaling they might leave. Signal has explicitly said it would stop operating in 🇪🇺 Europe rather than compromise its security.&lt;/p&gt;
    &lt;p&gt;Even 🇨🇭 Switzerland, traditionally seen as a privacy haven, is facing severe legislative pressures that are forcing tech companies to relocate. Proton has confirmed it has begun moving some of its physical infrastructure out of Switzerland due to “legal uncertainty” over the proposed surveillance law amendments. Lumo, their AI chatbot, became the first product to relocate, moving to Germany instead of Switzerland specifically because of these legislative concerns.&lt;/p&gt;
    &lt;p&gt;The Swiss OSCPT (Ordinance on the Surveillance of Correspondence by Post and Telecommunications) revision would require VPNs and messaging apps to identify users and retain data for up to six months, plus decrypt communications upon authority request. As Proton’s CEO Andy Yen explained, these are proposals that “have been outlawed in the EU” but could soon become reality in Switzerland.&lt;/p&gt;
    &lt;p&gt;Other privacy-focused providers like Tuta have expressed similar concerns and contingency plans to leave 🇨🇭 Switzerland if the surveillance laws pass.&lt;/p&gt;
    &lt;p&gt;Europe might become dependent on US surveillance&lt;lb/&gt; I’m not so sure on this one, but by outsourcing surveillance technology to American companies, 🇪🇺 Europe may create dangerous dependencies. These companies operate under 🇺🇸 US jurisdiction and the CLOUD Act, potentially allowing 🇺🇸 Washington to access data collected on 🇪🇺 European citizens. Under the pretense of child protection, the 🇪🇺 EU risks handing surveillance keys to foreign powers.&lt;/p&gt;
    &lt;p&gt;Social behavior changes&lt;lb/&gt; When people know they’re being watched, they change how they communicate. People start self-censoring, avoiding certain topics and carefully choosing their words even in private conversations.&lt;/p&gt;
    &lt;p&gt;This is called the chilling effect. Rights don’t disappear overnight: they erode gradually as people change their behavior to avoid potential problems.&lt;/p&gt;
    &lt;head rend="h2"&gt;Take Action #&lt;/head&gt;
    &lt;p&gt;Here’s how you can contribute to defending our digital freedoms:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Share this article and educate your network: Use hashtags like &lt;code&gt;#ChatControl&lt;/code&gt;or&lt;code&gt;#StopScanningMe&lt;/code&gt;. Forward resources to friends, family and colleagues.&lt;/item&gt;
      &lt;item&gt;Sign the petition: against ChatControl at change.org.&lt;/item&gt;
      &lt;item&gt;Stay informed and follow updates: @[email protected], x.com/nonchatcontrol, patrick-breyer.de and fightchatcontrol.eu.&lt;/item&gt;
      &lt;item&gt;Contact your national representatives to convince your country to oppose ChatControl, if it’s not already the case.&lt;/item&gt;
      &lt;item&gt;Join campaigns and support organizations: stopscanningme.eu for local actions, EFF and EDRi for digital rights advocacy.&lt;/item&gt;
      &lt;item&gt;Adopt privacy tools and infrastructure: Use Signal and other privacy-respecting alternatives. Host your own services or support privacy-focused providers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusion #&lt;/head&gt;
    &lt;p&gt;The irony is kinda painful: the continent that built GDPR to protect digital privacy now designs ChatControl to dismantle it systematically. What was once a fundamental right could become mandatory surveillance.&lt;/p&gt;
    &lt;p&gt;ChatControl represents a historic choice for 🇪🇺 Europe. Either we become the first democracy to normalize mass surveillance of private communications or we defend the digital rights that made Europe a global privacy leader.&lt;/p&gt;
    &lt;p&gt;This decision deserves close attention: authoritarian regimes worldwide are watching, ready to justify their own programs with: “Eh, if Europe does it, why shouldn’t we?”&lt;/p&gt;
    &lt;p&gt;The next chapter unfolds on October 14, 2025. 😉&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45374500</guid><pubDate>Thu, 25 Sep 2025 16:01:41 +0000</pubDate></item><item><title>The Harvard-Emory ECG Database</title><link>https://bdsp.io/content/heedb/4.0/</link><description>&lt;doc fingerprint="25dd992d87ba80d0"&gt;
  &lt;main&gt;
    &lt;p&gt;Database Credentialed Access&lt;/p&gt;
    &lt;head rend="h1"&gt;Harvard-Emory ECG Database&lt;/head&gt;
    &lt;p&gt;Zuzana Koscova , Valdery Moura Junior , Matthew Reyna , Shenda Hong , Aditya Gupta , Manohar Ghanta , Reza Sameni , Aaron Aguirre , Qiao Li , Sahar Zafar , Gari Clifford , M Brandon Westover&lt;/p&gt;
    &lt;p&gt;Published: July 28, 2025. Version: 4.0&lt;/p&gt;
    &lt;p&gt; When using this resource, please cite: (show more options) &lt;lb/&gt;Koscova, Z., Moura Junior, V., Reyna, M., Hong, S., Gupta, A., Ghanta, M., Sameni, R., Aguirre, A., Li, Q., Zafar, S., Clifford, G., &amp;amp; Westover, M. B. (2025). Harvard-Emory ECG Database (version 4.0). Brain Data Science Platform. https://doi.org/10.60508/rv6h-7d10. &lt;/p&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;The Harvard-Emory ECG database (HEEDB) is a large collection of 12-lead electrocardiography (ECG) recordings, prepared through a collaboration between Harvard University and Emory University investigators.&lt;/p&gt;
    &lt;p&gt;In version 1.0 of the database, these ECGs from Massachusetts General Brigham hospital sites were provided without labels or metadata, to enable pre-training of ECG analysis models.&lt;/p&gt;
    &lt;p&gt;In version 2.0, metadata is included.&lt;/p&gt;
    &lt;p&gt;In version 3.0, Emory ECGs are included together with metadata, labels from the 12SL ECG analysis program (GE Healthcare ) and ICD-9/10 codes.&lt;/p&gt;
    &lt;p&gt;In version 4.0, typos were corrected in the data description.&lt;/p&gt;
    &lt;p&gt;HEEDB is published as part of the Human Sleep Project (HSP), funded by a grant (R01HL161253) from the National Heart Lung and Blood Institute (NHLBI) of the NIH to Massachusetts General Hospital, Emory University, Stanford University, Kaiser Permanente, Boston Children's Hospital, and Beth Israel Deaconess Medical Center.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;These ECG data include clinical ECGs captured during routine clinical care over several decades. These are intended to be used to determine associations between cardiac abnormalities (e.g. abnormal rhythms) and sleep, sleep-related medical conditions, and health outcomes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methods&lt;/head&gt;
    &lt;p&gt;The dataset consists of standard 12-lead ECG recordings, each 10 seconds long, acquired at sampling rates of 250 or 500 Hz. Collection began in the 1980s and continues to the present day. Version 4 of the database includes 10,471,531 ECGs from 1,818,247 unique patients at institution I0001 and 968,680 ECGs from 349,548 patients at institution I0006. All recordings were obtained as part of routine clinical care.&lt;/p&gt;
    &lt;p&gt;Data preprocessing: Data was de-identified following the Safe Harbor method.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data Description&lt;/head&gt;
    &lt;p&gt;ECG data is stored in WFDB (Waveform Database) and Matlab (V4) compatible format. Each ECG recording includes one waveform data file (.mat for I0001 and .dat for I0006) and one header file (.hea). The waveform data file can be read by WFDB library functions, applications, Toolbox, or be loaded to Matlab directly. Waveform files are 12-lead ECG signals recorded at 250 and 500 Hz for 10 s encoded in 16 bits. The header file specifies the name of the associated waveform file and its attributes including sampling rate, units, channel names and the signal gain. It contains line-oriented and field-oriented ASCII text and can be read by the WFDB library or generic text editors.&lt;/p&gt;
    &lt;p&gt;The directory structure of the HEEDB is organized as follows:&lt;/p&gt;
    &lt;code&gt;ECG/
├── I0006/
│   ├── 12SL_diagnoses/
│   │   ├── diagnoses.csv
│   │   ├── diagnoses_dictionary.csv
│   │   └── README
│   ├── ICD_codes/
│   │   ├── icd9_codes.csv
│   │   ├── icd10_codes.csv
│   │   └── README
│   ├── metadata/
│   │   ├── metadata.csv
│   │   └── README
│   └── WFDB/
│       ├── 2010/
│       ├── 2011/
│       ├── ...
│       └── 2018/
├── I0001/
│   ├── 12SL_diagnoses/
│   │   ├── diagnoses.csv
│   │   ├── diagnoses_dictionary.csv
│   │   └── README
│   ├── ICD_codes/
│   │   ├── icd9_codes.csv
│   │   ├── icd10_codes.csv
│   │   └── README
│   ├── metadata/
│   │   ├── metadata.csv
│   │   └── README
│   └── WFDB/
│       ├── S0001/
│       ├── S0002/
│       ├── S0003/
│       └── S0004/
&lt;/code&gt;
    &lt;p&gt;Each institution (I0001 and I0006) maintains its own subfolders for diagnoses, ICD codes, metadata, and waveform files. The WFDB/ directory contains the ECG waveform data organized either by year (I0006) or by session identifier (I0001).&lt;/p&gt;
    &lt;head rend="h3"&gt;12SL Diagnoses Description&lt;/head&gt;
    &lt;head rend="h3"&gt;The 12SL_diagnoses/ folder contains diagnostic outputs from 12SL (GE Healthcare) software, version 1.&lt;/head&gt;
    &lt;p&gt;File: diagnoses.csv&lt;lb/&gt; This file contains two columns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FileName – Path to the corresponding WFDB file&lt;/item&gt;
      &lt;item&gt;codes – Diagnostic codes, which can be mapped to text labels using diagnoses_dictionary.csv&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;File: diagnoses_dictionary.csv&lt;lb/&gt; This file provides human-readable mappings for 12SL diagnostic codes. It contains the following columns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;codes – Integer codes for diagnoses&lt;/item&gt;
      &lt;item&gt;acronym – Abbreviated diagnosis labels&lt;/item&gt;
      &lt;item&gt;diagnoses – Full textual descriptions of diagnoses&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;ICD Codes Description&lt;/head&gt;
    &lt;p&gt;The ICD_codes/ folder contains diagnostic information extracted from Electronic Health Records (EHR) for each patient.&lt;/p&gt;
    &lt;p&gt;File: icd10_codes.csv&lt;lb/&gt; This file contains diagnostic codes from the 10th revision of the International Classification of Diseases (ICD-10), developed by the World Health Organization (WHO). These alphanumeric codes represent diagnoses and health conditions.&lt;/p&gt;
    &lt;p&gt;Columns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BDSPPatientID – Brain Data Science Platform Patient ID&lt;/item&gt;
      &lt;item&gt;RECORDED_DT – Shifted date of the diagnosis&lt;/item&gt;
      &lt;item&gt;DIAGNOSIS_ICD10_CD – Full ICD-10 diagnosis code&lt;/item&gt;
      &lt;item&gt;DIAGNOSIS_ICD10_DESC – Description of the ICD-10 diagnosis code&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;File: icd9_codes.csv&lt;lb/&gt; This file contains diagnostic codes from the 9th revision of the International Classification of Diseases (ICD-9), also developed by the WHO. These codes are also sourced from the EHR system.&lt;/p&gt;
    &lt;p&gt;Columns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BDSPPatientID – Brain Data Science Platform Patient ID&lt;/item&gt;
      &lt;item&gt;RECORDED_DT – Shifted date of the diagnosis&lt;/item&gt;
      &lt;item&gt;DIAGNOSIS_ICD9_CD – Full ICD-9 diagnosis code&lt;/item&gt;
      &lt;item&gt;DIAGNOSIS_ICD9_DESC – Description of the ICD-9 diagnosis code&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Metadata Description&lt;/head&gt;
    &lt;p&gt;The metadata/ folder contains demographic and temporal information associated with each ECG recording, including ECG acquisition time, date of birth, date of death, and derived age-related fields.&lt;/p&gt;
    &lt;p&gt;File: metadata.csv&lt;/p&gt;
    &lt;p&gt;Columns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BDSPPatientID – Patient ID&lt;/item&gt;
      &lt;item&gt;FileName – Path to the WFDB file&lt;/item&gt;
      &lt;item&gt;FileID – Basename of the WFDB file&lt;/item&gt;
      &lt;item&gt;PatientRace&lt;/item&gt;
      &lt;item&gt;EthnicGroupDSC&lt;/item&gt;
      &lt;item&gt;MaritalStatusDSC&lt;/item&gt;
      &lt;item&gt;ReligionDSC&lt;/item&gt;
      &lt;item&gt;LanguageDSC&lt;/item&gt;
      &lt;item&gt;VeteranStatusDSC&lt;/item&gt;
      &lt;item&gt;SexDSC&lt;/item&gt;
      &lt;item&gt;PrimaryCauseOfDeathDSC&lt;/item&gt;
      &lt;item&gt;PrimaryCauseOfDeathUNOS&lt;/item&gt;
      &lt;item&gt;FirstContributoryCauseOfDeathDSC&lt;/item&gt;
      &lt;item&gt;FirstContributoryCauseOfDeathUNOS&lt;/item&gt;
      &lt;item&gt;SecondContributoryCauseOfDeathDSC&lt;/item&gt;
      &lt;item&gt;SecondContributoryCauseOfDeathUNOS&lt;/item&gt;
      &lt;item&gt;EducationLevelDSC&lt;/item&gt;
      &lt;item&gt;GenderIdentityDSC&lt;/item&gt;
      &lt;item&gt;SexAssignedAtBirthDSC&lt;/item&gt;
      &lt;item&gt;DateOfDeath&lt;/item&gt;
      &lt;item&gt;DateOfDeathMARegistryData – Massachusetts (MA) state death registry date of death&lt;/item&gt;
      &lt;item&gt;LastKnownVisitDate – Last time the patient had contact with the hospital system&lt;/item&gt;
      &lt;item&gt;ECGAcquisitionTime – Time of ECG acquisition&lt;/item&gt;
      &lt;item&gt;DateOfBirth&lt;/item&gt;
      &lt;item&gt;AgeAtAcquisition – Age at ECG acquisition&lt;/item&gt;
      &lt;item&gt;AgeAtDeath – Age at time of death&lt;/item&gt;
      &lt;item&gt;AgeAtDeathMA – Age at death according to MA state registry&lt;/item&gt;
      &lt;item&gt;AgeAtLastVisit – Age at the last hospital contact&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For I0006, the following columns are missing from the metadata.csv file: EthnicGroupDSC, MaritalStatusDSC, ReligionDSC, LanguageDSC, VeteranStatusDSC, PrimaryCauseOfDeathDSC, PrimaryCauseOfDeathUNOS, FirstContributoryCauseOfDeathDSC, FirstContributoryCauseOfDeathUNOS, SecondContributoryCauseOfDeathDSC, SecondContributoryCauseOfDeathUNOS, EducationLevelDSC, GenderIdentityDSC, SexAssignedAtBirthDSC, and DateOfDeathMARegistryData.&lt;/p&gt;
    &lt;head rend="h2"&gt;Usage Notes&lt;/head&gt;
    &lt;p&gt;HEEDB is intended to support a wide range of ECG studies, in particular those exploring the relationship between ECG conditions and sleep.&lt;/p&gt;
    &lt;p/&gt;
    &lt;head rend="h2"&gt;Release Notes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;v1.0: Initial release containing 10,608,417 ECGs from 1,818,247 subjects (I0001 site only).&lt;/item&gt;
      &lt;item&gt;v2.0: Added additional data files&lt;/item&gt;
      &lt;item&gt;v3.0: Expanded to include two ECG institutions — I0001 (10,608,417 ECGs from 1,818,247 subjects) and I0006 (1,061,598 ECGs from 349,548 patients). Metadata, 12SL diagnostic codes, and ICD-9/10 diagnosis codes were also added. Duplicate ECGs were removed from the I0001 site, and incorrect sampling frequencies in header files were corrected.&lt;/item&gt;
      &lt;item&gt;v4.0: Corrected typos in the data description&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Ethics&lt;/head&gt;
    &lt;p&gt;The study protocol was approved by the Institutional Review Boards of the Massachusetts General Hospital (protocol # 2013P001024) and Beth Israel Deaconess Medical Center (protocol # 2022P000417). The written informed consents were waived, because of the retrospective study design. The study also complied with the Declaration of Helsinki.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Publication of HEEDB is supported by a grant (R01HL161253) from the National Heart Lung and Blood Institute (NHLBI) of the NIH to Massachusetts General Hospital, Emory University, Stanford University, Kaiser Permanente, Boston Children's Hospital, and Beth Israel Deaconess Medical Center&lt;/p&gt;
    &lt;head rend="h2"&gt;Conflicts of Interest&lt;/head&gt;
    &lt;p&gt;Dr. Westover is a co-founder, scientific advisor, consultant to, and has personal equity interest in Beacon Biosignals. The other authors declare that they have no conflicts of interest.&lt;/p&gt;
    &lt;head rend="h5"&gt;Parent Projects&lt;/head&gt;
    &lt;head rend="h5"&gt;Access&lt;/head&gt;
    &lt;p&gt; Access Policy: &lt;lb/&gt; Only credentialed users who sign the DUA can access the files. &lt;/p&gt;
    &lt;p&gt; License (for files): &lt;lb/&gt; BDSP Credentialed Health Data License 1.5.0 &lt;/p&gt;
    &lt;p&gt; Data Use Agreement: &lt;lb/&gt; BDSP Credentialed Health Data Use Agreement &lt;/p&gt;
    &lt;p&gt; Required training: &lt;lb/&gt; CITI Data or Specimens Only Research &lt;/p&gt;
    &lt;head rend="h5"&gt;Discovery&lt;/head&gt;
    &lt;head rend="h5"&gt;Corresponding Author&lt;/head&gt;
    &lt;head rend="h5"&gt;Versions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;4.0 - July 28, 2025&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Files&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;be a credentialed user&lt;/item&gt;
      &lt;item&gt;complete required training:&lt;/item&gt;
      &lt;item&gt;CITI Data or Specimens Only Research You may submit your training here.&lt;/item&gt;
      &lt;item&gt;sign the data use agreement for the project&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45374961</guid><pubDate>Thu, 25 Sep 2025 16:31:02 +0000</pubDate></item></channel></rss>