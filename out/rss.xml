<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 03 Nov 2025 19:08:02 +0000</lastBuildDate><item><title>Why Nextcloud feels slow to use</title><link>https://ounapuu.ee/posts/2025/11/03/nextcloud-slow/</link><description>&lt;doc fingerprint="57c20352a0823c6c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Nextcloud feels slow to use&lt;/head&gt;
    &lt;p&gt;Nextcloud. I really want to like it, but it’s making it really difficult.&lt;/p&gt;
    &lt;p&gt;I like what Nextcloud offers with its feature set and how easily it replaces a bunch of services under one roof (files, calendar, contacts, notes, to-do lists, photos etc.), but no matter how hard I try and how much I optimize its resources on my home server, it feels slow to use, even on hardware that is ranging from decent to good. Then I opened developer tools and found the culprit.&lt;/p&gt;
    &lt;p&gt;It’s the Javascript.&lt;/p&gt;
    &lt;p&gt;On a clean page load, you will be downloading about 15-20 MB of Javascript, which does compress down to about 4-5 MB in transit, but that is still a huge amount of Javascript. For context, I consider 1 MB of Javascript to be on the heavy side for a web page/app.&lt;/p&gt;
    &lt;p&gt;Yes, that Javascript will be cached in the browser for a while, but you will still be executing all of that on each visit to your Nextcloud instance, and that will take a long time due to the sheer amount of code your browser now has to execute on the page.&lt;/p&gt;
    &lt;p&gt;A significant contributor to this heft seems to be the &lt;code&gt;core-common.js&lt;/code&gt; bundle, which based on its name seems to provide
some common functionality that’s shared across different Nextcloud apps that one can install. It’s coming in at 4.71
MB at the time of writing.&lt;/p&gt;
    &lt;p&gt;Then you want notifications, right? &lt;code&gt;NotificationsApp.chunk.mjs&lt;/code&gt; is here to cover you, at 1.06 MB.&lt;/p&gt;
    &lt;p&gt;Then there are the app-specific views. The Calendar app is taking up 5.94 MB to show a basic calendar view.&lt;/p&gt;
    &lt;p&gt;Files app includes a bunch of individual scripts, such as &lt;code&gt;EditorOutline&lt;/code&gt; (1.77 MB), &lt;code&gt;previewUtils&lt;/code&gt; (1.17 MB),
&lt;code&gt;index&lt;/code&gt; (1.09 MB), &lt;code&gt;emoji-picker&lt;/code&gt; (0.9 MB which I’ve never used!) and many smaller ones.&lt;/p&gt;
    &lt;p&gt;Notes app with its basic bare-bones editor? 4.36 MB for the &lt;code&gt;notes-main.js&lt;/code&gt;!&lt;/p&gt;
    &lt;p&gt;This means that even on an iPhone 13 mini, opening the Tasks app (to-do list), will take a ridiculously long time. Imagine opening your shopping list at the store and having to wait 5-10 seconds before you see anything, even with a solid 5G connection. Sounds extremely annoying, right?&lt;/p&gt;
    &lt;p&gt;I suspect that a lot of this is due to how Nextcloud is architected. There’s bound to be some hefty common libraries and tools that allow app developers to provide a unified experience, but even then there is something seriously wrong with the end result, the functionality to bundle size ratio is way off.&lt;/p&gt;
    &lt;p&gt;As a result, I’ve started branching out some things from Nextcloud, such as replacing the Tasks app with using a private Vikunja instance, and Photos to a private Immich instance. Vikunja is not perfect, but its 1.5 MB of Javascript is an order of magnitude smaller compared to Nextcloud, making it feel incredibly fast in comparison.&lt;/p&gt;
    &lt;p&gt;However, with other functionality I have to admit that the convenience of Nextcloud is enough to dissuade me from replacing it elsewhere, due to the available feature set comparing well to alternatives.&lt;/p&gt;
    &lt;p&gt;For now.&lt;/p&gt;
    &lt;p&gt;I’m sure that there are some legitimate reasons behind the current state, and overworked development teams and volunteers are unfortunately the norm in the industry, but it doesn’t take away the fact that the user experience and accessibility suffers as a result.&lt;/p&gt;
    &lt;p&gt;I’d like to thank Alex Russell for writing about web performance and why it matters, with supporting evidence and actionable advice, it has changed how I view websites and web apps and has pushed me to be better in my own work. I highly suggest reading his content, starting with the performance inequality gap series. It’s educational, insightful and incredibly irritating once you learn how crap most things are and how careless a lot of development teams are towards performance and accessibility.&lt;/p&gt;
    &lt;p&gt;Subscribe to new posts via the RSS feed.&lt;/p&gt;
    &lt;p&gt;Not sure what RSS is, or how to get started? Check this guide!&lt;/p&gt;
    &lt;p&gt;You can reach me via e-mail or LinkedIn.&lt;/p&gt;
    &lt;p&gt;If you liked this post, consider sharing it!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798681</guid><pubDate>Mon, 03 Nov 2025 13:21:09 +0000</pubDate></item><item><title>An Illustrated Introduction to Linear Algebra, Chapter 2: The Dot Product</title><link>https://www.ducktyped.org/p/linear-algebra-chapter-2-the-dot</link><description>&lt;doc fingerprint="923df5e7153e2979"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;An Illustrated Introduction to Linear Algebra, Chapter 2&lt;/head&gt;
    &lt;head rend="h3"&gt;The dot product&lt;/head&gt;
    &lt;head rend="h2"&gt;Picking a city&lt;/head&gt;
    &lt;p&gt;When my wife and I were deciding which city to live in, we made a list of cities, and scored each city based on some criteria. Here’s San Francisco and Minneapolis, for example, on weather and affordability.&lt;/p&gt;
    &lt;p&gt;You can see we loved the weather in San Francisco, but Minneapolis was way cheaper to live in. After this was done, we just added up the columns to figure out which city to live in!&lt;/p&gt;
    &lt;p&gt;Here’s the thing, though: I really liked the weather in San Francisco. I wanted some way to do this calculation, but have the weather matter more. Well, I could do that by using weights.&lt;/p&gt;
    &lt;p&gt;If I wanted the weather to matter 10% more, I could multiply by 1.1 before doing the addition.&lt;/p&gt;
    &lt;p&gt;(I also multiplied the affordability by 1 to show that I’m keeping it the same).&lt;/p&gt;
    &lt;p&gt;This is the essence of what a dot product is! Earlier I was adding up the numbers. Now I’m weighting the numbers before I add them&lt;/p&gt;
    &lt;p&gt;A dot product is a type of weighted sum.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dot product using vectors&lt;/head&gt;
    &lt;p&gt;Remember vectors from last chapter? Well, the dot product is an operation you perform on two vectors. Let’s write the above as a vector. For example, here are the scores for San Francisco as a vector&lt;/p&gt;
    &lt;p&gt;Here are the weights as a vector&lt;/p&gt;
    &lt;p&gt;We simply multiply the numbers by the weights and then add:&lt;/p&gt;
    &lt;p&gt;Tada! We just took a dot product of two vectors! It’s a straightforward operation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Three cities&lt;/head&gt;
    &lt;p&gt;Let’s see the same example with three cities. Here are our three cities with scores for weather and affordability:&lt;/p&gt;
    &lt;p&gt;The simple way to calculate scores would be to just add up the numbers:&lt;/p&gt;
    &lt;p&gt;But instead, we’re going to take the dot product:&lt;/p&gt;
    &lt;p&gt;We are taking three separate dot products here. For each city, we multiply its scores by the weights:&lt;/p&gt;
    &lt;p&gt;I’m saying that now to make it clear that we’re not taking the dot product of three vectors. That’s impossible, we can only take the dot product of two vectors. Instead we are taking three separate dot products. More on this later.&lt;/p&gt;
    &lt;p&gt;Now let’s look at another example. Let’s look at the Minnesota lottery.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Minnesota Lottery&lt;/head&gt;
    &lt;p&gt;It takes $2 to buy a ticket for the Minnesota lottery. Here are the odds:&lt;/p&gt;
    &lt;p&gt;So your odds of winning $2 are 1 in 17, your odds of winning $20 are 1 in 2404, etc. Given this information, how do you calculate how much a single ticket is worth, on average?&lt;/p&gt;
    &lt;p&gt;To find out, we again need to take the dot product. Here are the two vectors:&lt;/p&gt;
    &lt;p&gt;Prize money on the left, probability of winning on the right. Let’s see the calculation:&lt;/p&gt;
    &lt;p&gt;The ticket is worth $1.17176. It costs $2, so on average you can expect to lose money, which is what we knew already.&lt;/p&gt;
    &lt;p&gt;Same as the cities example, we are weighting the numbers, except this time the weights are the probability that we win that much money. The final number is called the expected value.&lt;/p&gt;
    &lt;p&gt;It’s the expected value of our ticket.&lt;/p&gt;
    &lt;p&gt;That’s all for dot products. It’s a straightforward operation, but one that’s important to know for matrix multiplication, which is the topic of the next chapter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;A dot product is a weighted sum of two vectors. You multiply each element of the vectors together, then add up the results:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798741</guid><pubDate>Mon, 03 Nov 2025 13:28:37 +0000</pubDate></item><item><title>Offline Math: Converting LaTeX to SVG with MathJax</title><link>https://sigwait.org/~alex/blog/2025/10/07/3t8acq.html</link><description>&lt;doc fingerprint="ae42081a27e3a30c"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Offline Math: Converting LaTeX to SVG with MathJax&lt;/head&gt;&lt;p&gt;Latest update: &lt;/p&gt;&lt;p&gt;Pandoc can prepare LaTeX math for MathJax via its eponymous &lt;code&gt;--mathjax&lt;/code&gt; option. It wraps formulas in &lt;code&gt;&amp;lt;span class="math"&amp;gt;&lt;/code&gt;
elements and injects a &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag that points to
cdn.jsdelivr.net, which means rendering won't work offline or in
case of the 3rd-party server failure. You can mitigate this by
providing your own copy of the MathJax library, but the mechanism
still fails when the target device doesn't support JavaScript (e.g.,
many epub readers).&lt;/p&gt;&lt;p&gt;At the same time, practically all browsers support MathML. Use it (pandoc's &lt;code&gt;--mathml&lt;/code&gt; option), if you care only about the information
superhighway: your formulas will look good on every modern device and
scale delightfully. Otherwise, SVGs are the only truly portable
option.&lt;/p&gt;&lt;p&gt;Now, how can we transform the html produced by&lt;/p&gt;&lt;quote&gt;&lt;code&gt;$ echo 'Ohm'\''s law: $I = \frac{V}{R}$.' |
  pandoc -s -f markdown --mathjax
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;into a fully standalone document where the formula gets converted into SVG nodes?&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Use an html parser like Nokogiri, and replace each &lt;code&gt;&amp;lt;span class="math"&amp;gt;&lt;/code&gt; node with an image. There are multiple ways to
convert a TeX-looking string to an SVG: using MathJax itself (which
provides a corresponding CLI example), or by doing it in a
'classical' fashion with pdflatex. (You can read more about this
method in A practical guide to EPUB, chapters 3.4 and 4.6.)&lt;/item&gt;&lt;/list&gt;&lt;list start="2" rend="ol"&gt;&lt;item&gt;Alternatively, load the page into a headless browser, inject MathJax scripts, and serialise the modified DOM back to html.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I tried the 2nd approach in 2016 with the now-defunct phantomjs. It worked, but debugging was far from enjoyable due to the strangest bugs in phantomjs. I can still run the old code, but it depends on an ancient version of the MathJax library that, for obvious reasons, isn't easily upgradable within the phantomjs pre-es6 environment.&lt;/p&gt;&lt;p&gt;Nowadays, Puppeteer would certainly do, but for this kind of task I prefer something more lightweight.&lt;/p&gt;&lt;p&gt;There's also jsdom. Back in 2016, I tried it as well, but it was much slower than running phantomjs. Recently, I gave jsdom another try and was pleasantly surprised. I'm not sure what exactly tipped the scales: computers, v8, or jsdom itself, but it no longer feels slow in combination with MathJax.&lt;/p&gt;&lt;quote&gt;&lt;code&gt;$ wc -l *js *conf.json
  24 loader.js
 105 mathjax-embed.js
  12 mathjax.conf.json
 141 total
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;Roughly 50% of the code is nodejs infrastructure junk (including CL parsing), the rest is a MathJax config and jsdom interactions:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;let dom = new JSDOM(html, {
  url: `file://${base}/`,
  runScripts: /* very */ 'dangerously',
  resources: new MyResourceLoader(), // block ext. absolute urls
})

dom.window.my_exit = function() {
  cleanup(dom.window.document) // remove mathjax &amp;lt;script&amp;gt; tags
  console.log(dom.serialize())
}

dom.window.my_mathjax_conf = mathjax_conf // user-provided

let script = new Script(read(`${import.meta.dirname}/loader.js`))
let vmContext = dom.getInternalVMContext()
script.runInContext(vmContext)
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;The most annoying step here is setting &lt;code&gt;url&lt;/code&gt; property that jsdom uses
to resolve paths to relative resources. &lt;code&gt;my_exit()&lt;/code&gt; function is called
by MathJax when its job is supposedly finished. &lt;code&gt;loader.js&lt;/code&gt; script is
executed in the context of the loaded html:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;window.MathJax = {
  output: { fontPath: '@mathjax/%%FONT%%-font' },
  startup: {
    ready() {
      MathJax.startup.defaultReady()
      MathJax.startup.promise.then(window.my_exit)
    }
  }
}

Object.assign(window.MathJax, window.my_mathjax_conf)

function main() {
  var script = document.createElement('script')
  script.src = 'mathjax/startup.js'
  document.head.appendChild(script)
}

document.addEventListener('DOMContentLoaded', main)
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;The full source is on Github.&lt;/p&gt;&lt;p&gt;Intended use is as follows:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;$ echo 'Ohm'\''s law: $I = \frac{V}{R}$.' |
  pandoc -s -f markdown --mathjax |
  mathjax-embed &amp;gt; 1.html
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt;The resulting html doesn't use JavaScript and doesn't fetch any external MathJax resources. &lt;code&gt;mathjax-embed&lt;/code&gt; script itself always works
offline.&lt;/p&gt;&lt;lb/&gt;Tags: Ð¾Ð¹ÑÑ&lt;lb/&gt;Authors: ag&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798746</guid><pubDate>Mon, 03 Nov 2025 13:29:17 +0000</pubDate></item><item><title>VimGraph</title><link>https://resources.wolframcloud.com/FunctionRepository/resources/VimGraph/</link><description>&lt;doc fingerprint="797c6f35ce5cddfb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Wolfram Function Repository&lt;/head&gt;
    &lt;p&gt;Instant-use add-on functions for the Wolfram Language&lt;/p&gt;
    &lt;p&gt;Function Repository Resource:&lt;/p&gt;
    &lt;p&gt;Construct a graph of simple Vim-style movements in text&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;ResourceFunction["VimGraph"][text]&lt;/p&gt;
          &lt;p&gt;returns a graph with letters as vertices and Vim-style movements as edges.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Shortcut&lt;/cell&gt;
        &lt;cell&gt;Movement Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;h / l&lt;/cell&gt;
        &lt;cell&gt;Move one character left / right on the same line&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;k / j&lt;/cell&gt;
        &lt;cell&gt;Move one character up / down; jumps to end of target line if shorter than current horizontal position&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;w / b&lt;/cell&gt;
        &lt;cell&gt;Jump to the beginning of the next / previous word, across lines&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;e&lt;/cell&gt;
        &lt;cell&gt;Jump to the end of the next word, across lines&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;^/$&lt;/cell&gt;
        &lt;cell&gt;Move to the beginning/end of the current line&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Vim graph for the movements: up, right, and to the beginning of the next word, respectively:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[1]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[1]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The same, with nicer formatting:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[2]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[2]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Returns a minimal sequence of keystrokes needed to move from one letter to another:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[3]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[3]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Illustrates the relationship between the maximum keystroke distance required to navigate between two letters in a text and the number of randomly inserted newlines:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[4]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[4]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Use the "CustomPatterns" option to define new movements by passing a string pattern to "StringPattern", with optional shortcuts for jumping forward or backward to the nearest match:&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;In[5]:=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Out[5]=&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Wolfram Language 13.0 (December 2021) or above&lt;/p&gt;
    &lt;p&gt;This work is licensed under a Creative Commons Attribution 4.0 International License&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798838</guid><pubDate>Mon, 03 Nov 2025 13:40:47 +0000</pubDate></item><item><title>Show HN: a Rust ray tracer that runs on any GPU – even in the browser</title><link>https://github.com/tchauffi/rust-rasterizer</link><description>&lt;doc fingerprint="6f9135994f6043cc"&gt;
  &lt;main&gt;
    &lt;p&gt;A rasterizer implementation in Rust&lt;/p&gt;
    &lt;p&gt;Try it online: Live WebGPU Raytracer&lt;/p&gt;
    &lt;p&gt;This project includes three different raytracing implementations:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;CPU Raytracer - Software-based raytracing running on the CPU&lt;/item&gt;
      &lt;item&gt;GPU Raytracer - Hardware-accelerated raytracing using GPU compute shaders (offline rendering)&lt;/item&gt;
      &lt;item&gt;Live GPU Raytracer - Real-time interactive GPU raytracer with camera controls&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The CPU version renders scenes using traditional CPU-based raytracing and outputs to a PPM image file.&lt;/p&gt;
    &lt;code&gt;# Build and run (outputs to stdout, redirect to file)
cargo run --release &amp;gt; output.ppm

# Or build first, then run
cargo build --release
./target/release/rust-rasterizer &amp;gt; output.ppm&lt;/code&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full path tracing with multiple bounces&lt;/item&gt;
      &lt;item&gt;Direct and indirect lighting&lt;/item&gt;
      &lt;item&gt;Mesh support (.obj files)&lt;/item&gt;
      &lt;item&gt;Sphere primitives&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The GPU version uses compute shaders to accelerate rendering, outputting to a PPM file.&lt;/p&gt;
    &lt;code&gt;# Build and run
cargo run --bin gpu_raytracer --release &amp;gt; output.ppm

# Or build separately
cargo build --bin gpu_raytracer --release
./target/release/gpu_raytracer &amp;gt; output.ppm&lt;/code&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GPU-accelerated compute shader rendering&lt;/item&gt;
      &lt;item&gt;Same scene quality as CPU version&lt;/item&gt;
      &lt;item&gt;Significantly faster rendering times&lt;/item&gt;
      &lt;item&gt;Hardware-accelerated ray-triangle intersection&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The live version provides a real-time interactive window where you can navigate the scene.&lt;/p&gt;
    &lt;code&gt;# Run the live raytracer
cargo run --bin live_raytracer --release&lt;/code&gt;
    &lt;p&gt;Controls:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mouse: Click and drag to rotate the camera&lt;/item&gt;
      &lt;item&gt;SPACE: Toggle between raytracing and normals visualization modes&lt;/item&gt;
      &lt;item&gt;Window Title: Displays current mode and FPS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time GPU raytracing&lt;/item&gt;
      &lt;item&gt;Interactive camera controls&lt;/item&gt;
      &lt;item&gt;Two rendering modes: &lt;list rend="ul"&gt;&lt;item&gt;Raytracing: Full path tracing with lighting and shadows&lt;/item&gt;&lt;item&gt;Normals: Fast visualization showing surface normals (useful for debugging)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Live FPS counter in window title&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rust (latest stable version)&lt;/item&gt;
      &lt;item&gt;For GPU versions: A GPU with compute shader support (Vulkan, Metal, or DirectX 12)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Implement Sphere ray tracing&lt;/item&gt;
      &lt;item&gt;Implement Light structures and enhance ray_color function for direct and indirect lighting calculations&lt;/item&gt;
      &lt;item&gt;Add more shapes (planes, triangles, meshes)&lt;/item&gt;
      &lt;item&gt;Optimize performance using GPU acceleration&lt;/item&gt;
      &lt;item&gt;Add BVH acceleration structure&lt;/item&gt;
      &lt;item&gt;Add texture mapping and material properties&lt;/item&gt;
      &lt;item&gt;Implement shadows and reflections&lt;/item&gt;
      &lt;item&gt;Create a user interface for scene setup and rendering options&lt;/item&gt;
      &lt;item&gt;Write documentation and usage examples&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798871</guid><pubDate>Mon, 03 Nov 2025 13:45:15 +0000</pubDate></item><item><title>Skyfall-GS – Synthesizing Immersive 3D Urban Scenes from Satellite Imagery</title><link>https://skyfall-gs.jayinnn.dev/</link><description>&lt;doc fingerprint="ed199ac9cc8e47ba"&gt;
  &lt;main&gt;
    &lt;p&gt;Synthesizing large-scale, explorable, and geometrically accurate 3D urban scenes is a challenging yet valuable task in providing immersive and embodied applications. The challenges lie in the lack of large-scale and high-quality real-world 3D scans for training generalizable generative models. In this paper, we take an alternative route to create large-scale 3D scenes by synergizing the readily available satellite imagery that supplies realistic coarse geometry and the open-domain diffusion model for creating high-quality close-up appearances. We propose Skyfall-GS, the first city-block scale 3D scene creation framework without costly 3D annotations, also featuring real-time, immersive 3D exploration. We tailor a curriculum-driven iterative refinement strategy to progressively enhance geometric completeness and photorealistic textures. Extensive experiments demonstrate that Skyfall-GS provides improved cross-view consistent geometry and more realistic textures compared to state-of-the-art approaches.&lt;/p&gt;
    &lt;p&gt;Our method synthesizes immersive and free-flight navigable city-block scale 3D scenes solely from multi-view satellite imagery in two stages.&lt;/p&gt;
    &lt;p&gt;(a) Reconstruction Stage&lt;/p&gt;
    &lt;p&gt;(b) Synthesis Stage&lt;/p&gt;
    &lt;p&gt;Explore our 3D Gaussian Splatting results interactively. Click on the scene buttons below to switch between different urban scenes. Use your mouse to freely navigate within each scene, and use WASD keys for fly navigation. Click the information button in the viewer for more controls.&lt;/p&gt;
    &lt;p&gt;This research was funded by the National Science and Technology Council, Taiwan, under Grants NSTC 112-2222-E-A49-004-MY2 and 113-2628-EA49-023-. The authors are grateful to Google, NVIDIA, and MediaTek Inc. for their generous donations. Yu-Lun Liu acknowledges the Yushan Young Fellow Program by the MOE in Taiwan.&lt;/p&gt;
    &lt;code&gt;@article{lee2025SkyfallGS,
  title = {{Skyfall-GS}: Synthesizing Immersive {3D} Urban Scenes from Satellite Imagery},
  author = {Jie-Ying Lee and Yi-Ruei Liu and Shr-Ruei Tsai and Wei-Cheng Chang and Chung-Ho Wu and Jiewen Chan and Zhenjun Zhao and Chieh Hubert Lin and Yu-Lun Liu},
  journal = {arXiv preprint},
  year = {2025},
  eprint = {2510.15869},
  archivePrefix = {arXiv}
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798881</guid><pubDate>Mon, 03 Nov 2025 13:46:19 +0000</pubDate></item><item><title>A collection of links that existed about Anguilla as of 2003</title><link>https://web.ai/</link><description>&lt;doc fingerprint="bb02304932093b43"&gt;
  &lt;main&gt;
    &lt;code&gt;web.ai&lt;/code&gt;
    &lt;p&gt;Revised: March 5, 2003&lt;/p&gt;
    &lt;p&gt;This is a collection of links that existed about Anguilla as of 2003. Not all of them are stll alive, but it's a fun glimpse back to Anguilla online.&lt;/p&gt;
    &lt;p/&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Land For Sale Behind Cap Juluca&lt;/cell&gt;
        &lt;cell&gt;Excellent Limousine Service&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;E &amp;amp; L Babysitting&lt;/cell&gt;
        &lt;cell&gt;Fairplay Jewelry and Perfumes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Swinghigh Apartments&lt;/cell&gt;
        &lt;cell&gt;A Trip to Dominica&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Cheers Charters&lt;/cell&gt;
        &lt;cell&gt;Be Aware Environmental Club&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Explore the sea or learn to waterski with Nature Boy Expeditions at natureboy.ai&lt;/cell&gt;
        &lt;cell&gt;Oliver's Seaside Grill at olivers.ai&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Take a side trip: Villa La Siesta: one-bedroom private villa on St Barth&lt;/cell&gt;
        &lt;cell&gt;Thanks for the great photographs: NancyPfister.com&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Teresa Harrigan is a promising young Anguillian artist. Here is her web page.&lt;/cell&gt;
        &lt;cell&gt;Part way through high school, Lourance Stevens discovered that she has eplilepsy. This is her story.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Thelma Lee is conducting a survey of tourists about the Internet for her MBA. Please complete her questionnaire.&lt;/cell&gt;
        &lt;cell&gt;See pictures of Cap Juluca's Beach in November 1998, after restoration work.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;See a 5-week visit to Anguilla by a 9 year old and a 12 year old boy, captured in pictures and humorous captions. Here.&lt;/cell&gt;
        &lt;cell&gt;See an action-packed visit to Anguilla by two teenage girls, written as a Science Project&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Visit the Gardens of Anguilla at Palms.ai&lt;/cell&gt;
        &lt;cell&gt;The International Art Festival was July 25, 1999: Artfestival.ai&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;The Diveshop in Sandy Ground is closed, but I still have their extensive underwater portfolio of tropical sea life on-line.&lt;/cell&gt;
        &lt;cell&gt;Book your holiday villa or buy a villa of your own; contact Lindy at ReMax Anguilla.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Spend your visit to Anguilla at one of our friendly local inns. See a selection at Inns.ai&lt;/cell&gt;
        &lt;cell&gt; See the beach, the rooms, the charm of Shoal Bay Villas at their web site, Sbvillas.ai &lt;p&gt;More on Anguilla villas&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Learn all about Anguilla's hugely successful Summer Tennis Camp and the young volunteers of the Anguilla Tennis Academy who make it happen at Tennis.ai&lt;/cell&gt;
        &lt;cell&gt;Purple Rose Florist, your local source for birthdays, holidays, Valentines and Mothers Day.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Seven-year old Kaitlin of Raleigh NC enjoyed her visit to Anguilla so much, she wrote a book about Anguilla. Charming. www.kaitlin.ai&lt;/cell&gt;
        &lt;cell&gt;Link Ferries web site includes the new Link Cat, the classic Link, and a large picture gallery about the ferry crossing between Anguilla and St Martin. www.link.ai&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Laine Parnell wrote up a report on her first visit to Anguilla.&lt;/cell&gt;
        &lt;cell&gt;An Exploration Adventure on Scrub Island!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;High-Way Rent-a-Car has a web site at &lt;code&gt;rentalcars.ai

&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Paradise Apartments on Rey Hill are friendly, comfortable, clean and affordable.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Road Primary School has a web site at roadprimary.ai with news, plans, sports, graduation, and the Oct97 issue of their newsletter, The Palm, with school regulations and discipline, among other topics.&lt;/cell&gt;
        &lt;cell&gt;Massage.ai, home page for Margaret, the foot care nurse and reflexologist. She can relax you, reduce swollen ankles, help diabetics, treat foot problems, and generally make your feel better!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;See the Albena Lake-Hodge Comprehensive School at an unofficial web site, School.ai&lt;/cell&gt;
        &lt;cell&gt;Join the Anguilla Tae Kwon Do Club at their web site, Karate.ai&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Lloyds Guest House. Friendly, local, enjoyable.&lt;/cell&gt;
        &lt;cell&gt;Weddings on the Go. Get married in Anguilla.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Wallblake House Trust.&lt;/cell&gt;
        &lt;cell&gt;Smitty's in Island Harbour.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Villa Dina: a private villa on world famous Shoal Bay, loaded with art and antiques. www.dina.ai&lt;/cell&gt;
        &lt;cell&gt;Fruit, Coral and Fish stamps from the Anguilla Post Office.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Junior's Glassbottom Boat. See the reefs at Shoal Bay.&lt;/cell&gt;
        &lt;cell&gt;MorganHill.ai, view villa on Long Bay.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Bird of Paradise Villa, overlooking Sandy Hill Bay and St. Martin.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Computerclub.ai, home of the Anguilla Library Computer Club.&lt;/cell&gt;
        &lt;cell&gt;Pictures of Coccoloba&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Barrel Stay Restaurant&lt;/cell&gt;
        &lt;cell&gt;Indah's Anguilla Guide&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Book a vacation at the Allamanda Beach Club, Allamanda.ai&lt;/cell&gt;
        &lt;cell&gt;Pictures of Anguilla Great House.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Olive's Guest House in Dominica, a good side trip from Anguilla!&lt;/cell&gt;
        &lt;cell&gt;Danny Laud and his Anguilla Web Page Service.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Mrs Websters Fruits and Vegetables&lt;/cell&gt;
        &lt;cell&gt;Bob Green Personal Home Page.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;The "Om Sweet Om" Yoga Massage and Meditation Center.&lt;/cell&gt;
        &lt;cell&gt;Marissa's Home Page&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Isajah, a tribute to her home island by a student.&lt;/cell&gt;
        &lt;cell&gt;Samantha, a very young person's home page.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45798892</guid><pubDate>Mon, 03 Nov 2025 13:47:27 +0000</pubDate></item><item><title>State of Terminal Emulators in 2025: The Errant Champions</title><link>https://www.jeffquast.com/post/state-of-terminal-emulation-2025/</link><description>&lt;doc fingerprint="b60308d6479438c4"&gt;
  &lt;main&gt;
    &lt;p&gt;This is a follow-up to my previous article, Terminal Emulators Battle Royale â Unicode Edition! from 2023, in which I documented Unicode support across terminal emulators. Since then, the ucs-detect tool and its supporting blessed library have been extended to automatically detect support of DEC Private Modes, sixel graphics, pixel size, and software version.&lt;/p&gt;
    &lt;p&gt;The ucs-detect program tests terminal cursor positioning by sending visible text followed by control sequences that request the cursor position. The terminal responds by writing the cursor location as simulated keyboard input. The ucs-detect program reads and compares these values against the Python wcwidth library result, logging any discrepancies.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Width Problem&lt;/head&gt;
    &lt;p&gt;Terminal emulators face a fundamental challenge: mapping the vast breadth of Unicode scripts into a fixed-width grid while maintaining legibility. A terminal must predict whether each character occupies one cell or two, whether combining marks overlay previous characters, and how emoji sequences collapse into single glyphs.&lt;/p&gt;
    &lt;p&gt;These predictions fail routinely. Zero-width joiners, variation selectors, and grapheme clustering compound in complexity. When terminals and CLI applications guess wrong, text becomes unreadable - cursors misalign and corrupt output and so then also corrupt the location of our input.&lt;/p&gt;
    &lt;p&gt;Our results share which terminals have the best "Unicode support" -- the least likely to exhibit these kinds of problems.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Gentleman Errant&lt;/head&gt;
    &lt;p&gt;Before presenting the latest results, Ghostty warrants particular attention, not only because it scored the highest among all terminals tested, but that it was publicly released only this year by Mitchell Hashimoto. It is a significant advancement. Developed from scratch in zig, the Unicode support implementation is thoroughly correct.&lt;/p&gt;
    &lt;p&gt;In 2023, Mitchell published Grapheme Clusters and Terminal Emulators, demonstrating a commitment to understanding and implementing the fundamentals. His recent announcement of libghostty provides a welcome alternative to libvte, potentially enabling a new generation of terminals on a foundation of strong Unicode support.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Errant Champion&lt;/head&gt;
    &lt;p&gt;Kovid Goyal's Kitty scored just as well, only outranked by the arbitrary weights that are not necessarily fair. More important than scoring is Kovid's publication of a text-splitting algorithm description that closely matches the Python wcwidth specification. This is unsurprising since both are derived from careful interpretation of Unicode.org standards and that it scores so highly in our test.&lt;/p&gt;
    &lt;p&gt;Kitty and Ghostty are the only terminals that correctly support Variation Selector 15, I have not written much about it because it is not likely to see any practical use, but, it will be added to a future release of Python wcwidth now that there are multiple standards and reference implementations in agreement.&lt;/p&gt;
    &lt;head rend="h2"&gt;Testing Results&lt;/head&gt;
    &lt;p&gt;The first table, General Tabulated Summary describes unicode features of each terminal, then, a brief summary of DEC Private Modes, sixel support, and testing time.&lt;/p&gt;
    &lt;p&gt;The second table, DEC Private Modes Support (not pictured), contains the first feature capability matrix of DEC Private Modes for Terminals of any length. I hope this is useful most especially to developers of CLI libraries and applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Long Road&lt;/head&gt;
    &lt;p&gt;The most notable finding relates to performance. That many terminals perform so slowly was surprising, so I have included the elapsed time in the results.&lt;/p&gt;
    &lt;p&gt;iTerm2 and Extraterm consume a majority of the CPU and perform so slowly that the test parameters were reduced to finish within the hour what many other terminals manage in a few minutes.&lt;/p&gt;
    &lt;p&gt;GNOME Terminal and its VTE-based derivatives also perform too slowly for a full test, taking over 5 hours while consuming very little CPU. Many terminals exhibit stalls or inefficiencies in their event loops that result in slow automatic responses, but we should be forgiving; nobody really considered the need to handle hundreds of automatic sequence replies per second!&lt;/p&gt;
    &lt;p&gt;I expected Python wcwidth to consume the most CPU resources during testing, as it is frequently called and always the "highest-level" language in the mix, but it keeps up pretty well for most terminals.&lt;/p&gt;
    &lt;p&gt;Earlier this year, I dedicated effort to optimizing the Python wcwidth implementation using techniques including bit vectors, bloom filters, and varying sizes of LRU caches. The results confirmed that the existing implementation performed best: a binary search with a functools.lru_cache decorator.&lt;/p&gt;
    &lt;p&gt;The LRU cache is effective because human languages typically use a small, repetitive subset of Unicode. The ucs-detect tool tests hundreds of languages from the UDHR dataset, excluding only those without any interesting zero or wide characters. This dataset provides an extreme but practical demonstration of LRU cache benefits when processing Unicode.&lt;/p&gt;
    &lt;p&gt;I previously considered distributing a C module with Python wcwidth for greater performance, but the existing Python implementation keeps up well enough with the fastest terminals. When fully exhausted the text scroll speed is fast enough to produce screen tearing artifacts.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tilting at Edges&lt;/head&gt;
    &lt;p&gt;Terminology produces inconsistent results between executions. Our tests are designed to be deterministic, so these kinds of results suggest possible state corruption. Despite this issue, Terminology offers interesting visual effects that would be a welcome feature in other terminals.&lt;/p&gt;
    &lt;p&gt;iTerm2 reports "supported, but disabled, and cannot be changed" status for all DEC Private Modes queried, including fictional modes like 9876543. For this reason, the summary of DEC Private Modes shows only those modes that are changeable.&lt;/p&gt;
    &lt;p&gt;Konsole does not reply to queries about DEC Private modes, but does support several modes when they are enabled. For this reason, ucs-detect cannot automatically infer which DEC Modes Konsole supports.&lt;/p&gt;
    &lt;p&gt;Similarly, ucs-detect reports "No DEC Private Mode Support" for Contour. I investigated this discrepancy because Contour's author also authored a Mode 2027 specification dependent on this functionality. The issue was that Contour responded with a different mode number than the one queried. While developing a fix, Contour's latest release from December 2024 presented an additional complication: a bad escape key configuration. Each instance of being stuck in vi required typing CTRL + [ as a workaround!&lt;/p&gt;
    &lt;p&gt;Terminals based on libvte with software version label VTE/7600 continue to show identical performance with low scores in our tests, unchanged from 2023.&lt;/p&gt;
    &lt;p&gt;My attempt to discuss improving Unicode support in libvte received substantial criticism. However, recent libvte project issue Support Emoji Sequences is a positive indicator for improved language and Emoji support in 2026.&lt;/p&gt;
    &lt;head rend="h2"&gt;On Mode 2027&lt;/head&gt;
    &lt;p&gt;I included DEC Private Mode 2027 in the results to accompany Mitchell's table from his article, Grapheme Clusters and Terminal Emulators, and to verify for myself that it has limited utility.&lt;/p&gt;
    &lt;p&gt;In theory, a CLI program can query this mode to classify a terminal as "reasonably supporting" unicode, but not which specific features or version level. Since other terminals with similar capabilities do not respond to Mode 2027 queries, this binary indicator has limited utility.&lt;/p&gt;
    &lt;p&gt;The only practical approach to determining Unicode support of a terminal is to interactively test for specific features, codepoints, and at the Unicode version levels of interest, as ucs-detect does.&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond Fixed Widths&lt;/head&gt;
    &lt;p&gt;Terminals cannot reproduce many of the world's languages legibly when constrained to monospace cells. The measurements dictated by rapidly expanding Unicode standards and varying implementation levels create inherent tension.&lt;/p&gt;
    &lt;p&gt;The text sizing protocol published early this year represents a significant development. Kovid Goyal describes the motivation in a recent interview:&lt;/p&gt;
    &lt;quote&gt;And then my next windmill that I'm looking at is variable-sized text in the terminal. So when I'm catting a markdown file, I want to see the headings big.&lt;/quote&gt;
    &lt;p&gt;While this feature may enable more advanced typesetting-like capabilities in terminal apps, it also promises to increase accessibility. Allowing text to escape monospace constraints enables legible support of the diverse set of the world's languages.&lt;/p&gt;
    &lt;p&gt;For example, using Contour with ucs-detect --stop-at-error=lang, stopping to take a look at a result of the language KhÃ¼n:&lt;/p&gt;
    &lt;p&gt;In this case Contour and Python wcwidth disagree on measurement, but more important is the legibility. We can compare this given KhÃ¼n text to the Kate editor:&lt;/p&gt;
    &lt;p&gt;They are clearly different. I regret I cannot study it more carefully, but I suggest that terminals could more easily display complex scripts by switching to a variable size text mode, allowing the font engine to drive the text without careful processing of cell and cursor movement.&lt;/p&gt;
    &lt;p&gt;Although I have yet to experiment with it, I am encouraged to see some resolution to this problem by the progressive changes suggested by the text sizing protocol.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45799478</guid><pubDate>Mon, 03 Nov 2025 14:40:51 +0000</pubDate></item><item><title>Robert Hooke's "Cyberpunk” Letter to Gottfried Leibniz</title><link>https://mynamelowercase.com/blog/robert-hookes-cyberpunk-letter-to-gottfried-leibniz/</link><description>&lt;doc fingerprint="2d2b9d15aca48677"&gt;
  &lt;main&gt;
    &lt;p&gt;Cyberpunk is a genre of science fiction about high tech, urban sprawl, and do-it-yourself counterculture. It’s usually associated with the early days of computer hackers and AI. This is the first in a series of blog posts about how high tech, urban sprawl, and do-it-yourself counterculture were just as much a part of the rapid progress of 17th century natural science as they were of the rapid progress of 20th century computer science; and about what we can learn by drawing this comparison.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"If I were to choose a patron saint for cybernetics... I should have to choose Leibniz"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;-Norbert Wiener&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"if we could find characters or signs appropriate for expressing all our thoughts as definitely and as exactly as arithmetic expresses numbers or geometric analysis expresses lines, we could in all subjects in so far as they are amenable to reasoning accomplish what is done in arithmetic and geometry."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;-Gottfried Leibniz&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"...especially in all those subjects where use of [such a language] may be free and where interest and authority do not intercept, the regular exercise thereof which I conceive to be the great antagonists which may impede its progress..."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;-Robert Hooke&lt;/p&gt;
    &lt;p&gt;The last quote is from an archival text which I've been trying to transcribe on and off for the past few months. It comes from a scan of a letter which Robert Hooke wrote to Gottfried Leibniz in 1681. I am fascinated by this letter for a couple of reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I was pleasantly surprised to learn that Hooke and Leibniz had exchanged any letters at all. I found the letter by chance, when browsing through the Royal Society's online archives.&lt;/item&gt;
      &lt;item&gt;The letter is about one of my favourite topics: Leibniz's project to create a universal language of science, which could be mechanically applied to automate any piece of scientific reasoning (apart from the collection of new experimental data).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For these reasons, this letter from Hooke to Leibniz has become one of my favourite pieces of niche archival material. (The other two are this popular science article which Alan Turing wrote to introduce computational undecidability to a general audience, and this speech which Ove Arup gave to his employees to reassure them that the new industrial computer his engineering firm had bought wasn't going to replace them in their jobs).&lt;/p&gt;
    &lt;p&gt;I think my transcription is about 90% accurate so far. Hooke's handwriting is quite hard to read. The original section quoted looks like this:&lt;/p&gt;
    &lt;p&gt;But from what I have transcribed, I think this letter is a particularly nice example of the originality and prescience of Hooke's way of thinking about the world. Almost as fascinating as the letter itself, are the events surrounding the time in which it was written. I hope to write more soon about Hooke's life, about his relationship with cryptography, and about the way in which he bridged the gap between technician and scientist.&lt;/p&gt;
    &lt;p&gt;A common thread I find myself drawing across much of Hooke's work - albeit anachronistically - is an early expression of the hacker mindset which flourished among computer scientists in the second half of the 20th century, coincided with the explosion of computing innovations that took place during that period, and came to be romanticised in cyberpunk science fiction. And I think that if I had to pick one piece of Hooke's writing that expresses this attitude most clearly, I would have to pick this letter. To explain why, I'll first talk a bit more about why Hooke was writing to Leibniz in the first place.&lt;/p&gt;
    &lt;p&gt;You likely know Robert Hooke from studying his laws about the motion of springs in high-school physics, for his role in the foundation of the Royal Society, or for his beef with Isaac Newton. You likely know about Gottfried Leibniz from hearing about his philosophy of monads, for his role in the invention of calculus, or for his beef with Isaac Newton.&lt;/p&gt;
    &lt;p&gt;It turns out that, aside from their common interest in antagonising Isaac Newton, Hooke and Leibniz also shared an interest in mechanising scientific reasoning through the invention of a universal language for science. Leibniz called his project the "Characteristica Universalis". The philosopher Norbert Wiener credited this idea as a precursor to his own notion of “cybernetics” – which, incidentally, is the word he coined from which we get the “cyber” in "cyberpunk". One thing I took away from reading Wiener was that you can think of the Characteristica Universalis as a kind of proto computer programming language. Hooke liked Leibniz’ ideas on this topic so much that he sent him the above letter just to say so.&lt;/p&gt;
    &lt;p&gt;What makes Hooke’s letter cyberpunk as opposed to just cybernetic is that it adds to Leibniz’s worldview an explicit (and perhaps naively optimistic) hope that individual freedom might be enabled by rather than stifled by the proliferation of this early programming language. In particular he saw the effect of a language for mechanised scientific reasoning as especially useful when used by individuals to express, explore and test ideas freely, without interference from unjust authorities who might seek to censor or interfere with their work. In 1681, Hooke was already imagining the countercultural edge of cybernetic systems.&lt;/p&gt;
    &lt;p&gt;This should not be surprising, given Hooke's own politically uneasy upbringing, his tendency to skip lectures at university in order to tinker (in Robert Boyle's lab) with designs for experiments and novel instruments that went on to occupy his scientific career, or his habit of falling out with the interfering authorities of his time.&lt;/p&gt;
    &lt;p&gt;If my reading of this letter is accurate then - just as Wiener calls Leibniz the patron saint of cybernetics, we should call Hooke the patron saint of cyberpunk.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800308</guid><pubDate>Mon, 03 Nov 2025 15:45:31 +0000</pubDate></item><item><title>Ask HN: Who wants to be hired? (November 2025)</title><link>https://news.ycombinator.com/item?id=45800464</link><description>&lt;doc fingerprint="301182753412e0e7"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Share your information if you are looking for work. Please use this format:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;  Location:
  Remote:
  Willing to relocate:
  Technologies:
  Résumé/CV:
  Email:
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt; Please only post if you are personally looking for work. Agencies, recruiters, job boards, and so on, are off topic here.&lt;/p&gt;
      &lt;p&gt;Readers: please only email these addresses to discuss work opportunities.&lt;/p&gt;
      &lt;p&gt;There's a site for searching these posts at https://www.wantstobehired.com.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800464</guid><pubDate>Mon, 03 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Ask HN: Who is hiring? (November 2025)</title><link>https://news.ycombinator.com/item?id=45800465</link><description>&lt;doc fingerprint="3741985a3402e664"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Please state the location and include REMOTE for remote work, REMOTE (US) or similar if the country is restricted, and ONSITE when remote work is &lt;/p&gt;not&lt;p&gt; an option.&lt;/p&gt;&lt;p&gt;Please only post if you personally are part of the hiring company—no recruiting firms or job boards. One post per company. If it isn't a household name, explain what your company does.&lt;/p&gt;&lt;p&gt;Please only post if you are actively filling a position and are committed to responding to applicants.&lt;/p&gt;&lt;p&gt;Commenters: please don't reply to job posts to complain about something. It's off topic here.&lt;/p&gt;&lt;p&gt;Readers: please only email if you are personally interested in the job.&lt;/p&gt;&lt;p&gt;Searchers: try https://dheerajck.github.io/hnwhoishiring/, http://nchelluri.github.io/hnjobs/, https://hnresumetojobs.com, https://hnhired.fly.dev, https://kennytilton.github.io/whoishiring/, https://hnjobs.emilburzo.com, or this (unofficial) Chrome extension: https://chromewebstore.google.com/detail/hn-hiring-pro/mpfal....&lt;/p&gt;&lt;p&gt;Don't miss this other fine thread: Who wants to be hired? https://news.ycombinator.com/item?id=45800464&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800465</guid><pubDate>Mon, 03 Nov 2025 16:00:00 +0000</pubDate></item><item><title>Learning to read Arthur Whitney's C to become smart (2024)</title><link>https://needleful.net/blog/2024/01/arthur_whitney.html</link><description>&lt;doc fingerprint="2eb9d195bc6fba9c"&gt;
  &lt;main&gt;
    &lt;p&gt;Burger.&lt;/p&gt;
    &lt;head rend="h3"&gt;it's not working&lt;/head&gt;
    &lt;head rend="h5"&gt;Written January 19, 2024&lt;/head&gt;
    &lt;p&gt;Arthur Whitney is an esteemed computer scientist who led the design on a few well-known pieces of software:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The A, K, and Q programming languages&lt;/item&gt;
      &lt;item&gt;kdb, a high-performance database built on K used in fintech&lt;/item&gt;
      &lt;item&gt;Shakti, which is like kdb but faster, designed for trillion-row datasets.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I've never even seen a trillion numbers, much less calculated them, but kdb is apparently a standard tool on Wall Street. They probably care about money, so I'll assume kdb does its job well. His languages take significantly after APL, which was a very popular language for similar applications before the invention of (qwerty) keyboards.&lt;/p&gt;
    &lt;p&gt;But I'm not here to talk about boring things like "using software to make incomprehensible amounts of money in finance" or "human beings and their careers", I'm here to talk about how a guy writes C code weird. For a very simple version of the programming language K, there's a publicly available interpreter he wrote in a few days using about 50 lines of C to show the basics of interpreter writing. This is the C (specifically the January 16, 2024 version #2):&lt;/p&gt;
    &lt;head rend="h2"&gt;a.h&lt;/head&gt;
    &lt;code&gt;typedef char*s,c;s Q=(s)128;&amp;#13;
#define _(e...) ({e;})&amp;#13;
#define x(a,e...) _(s x=a;e)&amp;#13;
#define $(a,b) if(a)b;else&amp;#13;
#define i(n,e) {int $n=n;int i=0;for(;i&amp;lt;$n;++i){e;}}&amp;#13;
&amp;#13;
#define Q(e) if(Q==(e))return Q;&amp;#13;
#define Qs(e,s) if(e)return err(__func__,s);&amp;#13;
#define Qr(e) Qs(e,"rank")&amp;#13;
#define Qd(e) Qs(e,"domain")&amp;#13;
#define Qz(e) Qs(e,"nyi")&amp;#13;
&amp;#13;
#define _s(f,e,x...) s f(x){return _(e);}&amp;#13;
#define _i(f,e) _s(f,e,c x)&amp;#13;
#define f(f,e)  _s(f,e,s x)&amp;#13;
#define F(f,e)  _s(f,e,s a,s x)&amp;#13;
&amp;#13;
#define ax (256&amp;gt;x)&amp;#13;
#define ix (c)x&amp;#13;
#define nx x[-1]&amp;#13;
#define xi x[i]&amp;#13;
&amp;#13;
#define aa x(a,ax)&amp;#13;
#define ia x(a,ix)&amp;#13;
#define na x(a,nx)&amp;#13;
&amp;#13;
#define oo w("oo\n")&lt;/code&gt;
    &lt;head rend="h2"&gt;a.c&lt;/head&gt;
    &lt;code&gt;#include"a.h"//fF[+-!#,@] atom/vector 1byte(int/token) clang-13 -Os -oa a.c -w &amp;#13;
#define r(n,e) _(s r=m(n);i(n,r[i]=e)r)&amp;#13;
f(w,write(1,ax?&amp;amp;x:x,ax?1:strlen(x));x)F(err,w(a);w((s)58);w(x);w((s)10);Q)&amp;#13;
_i(wi,s b[5];sprintf(b,"%d ",x);w(b);0)&amp;#13;
f(W,Q(x)$(ax,wi(ix))i(nx,wi(xi))w(10);x)&amp;#13;
&amp;#13;
f(srt,Qz(1)0)f(uni,Qz(1)0)F(Cut,Qz(1)0)F(Drp,Qz(1)0)_i(m,s a=malloc(1+x);*a++=x;a)&amp;#13;
#define A(c) ((s)memchr(a,c,na)?:a+na)-a&amp;#13;
#define g(a,v) ax?255&amp;amp;a:r(nx,v)&amp;#13;
f(not,g(!ix,!xi))f(sub,g(-ix,-xi))F(At,Qr(aa)g(a[ix],a[xi]))F(_A,Qr(aa)g(A(ix),A(xi)))&amp;#13;
f(ind,Qr(!ax)0&amp;gt;ix?r(-ix,-ix-1-i):r(ix,i))F(Ind,Qr(!aa)Qd(1&amp;gt;ia)g(ix%ia,xi%ia))&amp;#13;
#define G(f,o) F(f,ax?aa?255&amp;amp;ia o ix:Ltn==f?f(sub(x),sub(a)):f(x,a):r(nx,(aa?ia:a[i])o xi))&amp;#13;
G(Ltn,&amp;lt;)G(Eql,==)G(Not,!=)G(Sum,+)G(Prd,*)G(And,&amp;amp;)G(Or,|)&amp;#13;
f(cat,Qr(!ax)r(1,ix))F(Cat,a=aa?cat(a):a;x=ax?cat(x):x;s r=m(na+nx);memcpy(r+na,x,nx);memcpy(r,a,na))&amp;#13;
f(at,At(x,0))f(rev,Qr(ax)At(x,ind(255&amp;amp;-nx)))f(cnt,Qr(ax)nx)&amp;#13;
F(Tak,Qr(!aa||ax)Qd(0&amp;gt;ia||ia&amp;gt;nx)At(x,ind(a)))F(Sub,Sum(a,sub(x)))F(Mtn,Ltn(x,a))f(qz,Qz(1)0)&amp;#13;
#define v(e) ((strchr(V,e)?:V)-V)&amp;#13;
s U[26],V=" +-*&amp;amp;|&amp;lt;&amp;gt;=~!@?#_^,",&amp;#13;
(*f[])()={0,abs,sub,qz ,qz,rev,qz ,qz, qz ,not,ind,at,uni,cnt,qz ,srt,cat},&amp;#13;
(*F[])()={0,Sum,Sub,Prd,And,Or,Ltn,Mtn,Eql,Not,Ind,At,_A ,Tak,Drp,Cut,Cat};&amp;#13;
_i(n,10u&amp;gt;x-48?x-48:26u&amp;gt;x-97?U[x-97]:0)&amp;#13;
f(e,s z=x;c i=*z++;!*z?n(i):v(i)?x(e(z),Q(x)f[v(i)](x)):x(e(z+1),Q(x)58==*z?U[i-97]=x:_(c f=v(*z);Qd(!f)F[f](n(i),x))))&amp;#13;
int main(){c b[99];while(1)if(w(32),b[read(0,b,99)-1]=0,*b)58==b[1]?e(b):W(e(b));}&lt;/code&gt;
    &lt;p&gt;This is the entire interpreter, and this is apparently how he normally writes code. Opinions on his coding style are divided, though general consensus seems to be that it's incomprehensible. As daunting as it is, I figured I should give it a chance for a few reasons.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;As I work on larger and larger codebases, scrolling up and down to track information has become a more common annoyance. Whitney's talked about coding the way he does to avoid exactly that: he wants to keep his logic on one screen. Perhaps learning to read code like this could give me ideas on writing my own code more compactly.&lt;/item&gt;
      &lt;item&gt;In a Hacker News comments section, somebody asked "would you rather spend 10 days reading 100,000 lines of code, or 4 days reading 1000?", and that raises a good point. The complexity of the code is because even a simple interpreter is pretty complex. Writing it in 500 lines wouldn't make the complexity go away, it just spreads it out. Does writing in this more compact format feel more daunting because you're exposed to more of the complexity at once? I think so. Does showing it all at once actually help you understand the whole thing faster? I don't know.&lt;/item&gt;
      &lt;item&gt;Reading code has become a more important part of my job than writing it, so I should challenge my reading skills, regardless.&lt;/item&gt;
      &lt;item&gt;It confuses people, and that's basically the same as being smart.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So I'm going to go line by line and explain my understanding. I tried to use the notes provided in the repo only when I was stuck, which was a few times early on, but by the end I could understand it pretty well.&lt;/p&gt;
    &lt;head rend="h2"&gt;A reading of a.h&lt;/head&gt;
    &lt;code&gt;typedef char*s,c;&lt;/code&gt;
    &lt;p&gt;This already shows some funky C. It defines &lt;code&gt;s&lt;/code&gt; as &lt;code&gt;char *&lt;/code&gt;, and &lt;code&gt;c&lt;/code&gt; as &lt;code&gt;char&lt;/code&gt;, because the &lt;code&gt;*&lt;/code&gt; attaches to the name, not the type. It's an oddity of C syntax that I've never been a fan of. Otherwise this is pretty straight forward: &lt;code&gt;s&lt;/code&gt; is for string, and &lt;code&gt;c&lt;/code&gt; is for character.&lt;/p&gt;
    &lt;code&gt;s Q=(s)128;&lt;/code&gt;
    &lt;p&gt;Fuck. Shit. He assigned 128 to a string named &lt;code&gt;Q&lt;/code&gt;. What does it mean? &lt;code&gt;s&lt;/code&gt; is &lt;code&gt;char *&lt;/code&gt;. Why is Q a pointer to the address 128? I thought I must have misunderstood, and &lt;code&gt;s&lt;/code&gt; was actually a character or something, but it's clearly specified as &lt;code&gt;char *&lt;/code&gt;. &lt;code&gt;s&lt;/code&gt; is for string!&amp;#13;
I couldn't figure out the meaning, so I soon gave up and looked at the annotated code. The &lt;code&gt;char *&lt;/code&gt; is &lt;code&gt;unsigned long long&lt;/code&gt; in other versions, and they explain that the type is used for both integers and pointers. The code operates on vectors of 8-bit integers, either as ASCII or numbers, so it makes some sense to use &lt;code&gt;char *&lt;/code&gt; from a memory layout perspective, but I don't use pointers as integers very often.&lt;/p&gt;
    &lt;code&gt;#define _(e...) ({e;})&amp;#13;
#define x(a,e...) _(s x=a;e)&amp;#13;
#define $(a,b) if(a)b;else&amp;#13;
#define i(n,e) {int $n=n;int i=0;for(;i&amp;lt;$n;++i){e;}}&lt;/code&gt;
    &lt;p&gt;These are all pretty straight forward, with one subtle caveat I only realized from the annotated code. They're all macros to make common operations more compact: wrapping an expression in a block, defining a variable &lt;code&gt;x&lt;/code&gt; and using it, conditional statements, and running an expression &lt;code&gt;n&lt;/code&gt; times.&lt;/p&gt;
    &lt;p&gt;The subtle thing the annotations point out is the first macro, &lt;code&gt;({e;})&lt;/code&gt;. The parentheses around curly brackets make this a statement expression, a non-standard C extension that allows you to treat a block of statements as a single expression, if the last statement is an expression that provides a value. In other words, &lt;code&gt;int x = ({int a = func1(); int b = func2(a); a+b;});&lt;/code&gt; sets &lt;code&gt;x&lt;/code&gt; to whatever &lt;code&gt;a+b&lt;/code&gt; is. This is used everywhere in the code after this.&lt;/p&gt;
    &lt;code&gt;#define Q(e) if(Q==(e))return Q;&amp;#13;
#define Qs(e,s) if(e)return err(__func__,s);&amp;#13;
#define Qr(e) Qs(e,"rank")&amp;#13;
#define Qd(e) Qs(e,"domain")&amp;#13;
#define Qz(e) Qs(e,"nyi")&lt;/code&gt;
    &lt;p&gt;These are error macros using that mysterious &lt;code&gt;Q&lt;/code&gt; defined earlier. &lt;code&gt;Q&lt;/code&gt; seems to have been used to represent errors, possibly short for "Quit". The &lt;code&gt;Qr/d/z&lt;/code&gt; functions seem to be types of errors. I have no idea what "nyi" means (I figure it out later).&lt;/p&gt;
    &lt;code&gt;#define _s(f,e,x...) s f(x){return _(e);}&amp;#13;
#define _i(f,e) _s(f,e,c x)&amp;#13;
#define f(f,e)  _s(f,e,s x)&amp;#13;
#define F(f,e)  _s(f,e,s a,s x)&lt;/code&gt;
    &lt;p&gt;These replace function declarations, and we can see that &lt;code&gt;_&lt;/code&gt; macro being used to add an implicit return.&amp;#13;
&lt;code&gt;_s&lt;/code&gt; could be used like&lt;/p&gt;
    &lt;code&gt;_s(my_function, puts("I rock!!!"); x*5+e, s x, int e)&lt;/code&gt;
    &lt;p&gt;, which would create basically this standard C:&lt;/p&gt;
    &lt;code&gt;char *my_function(char *x, int e) {&amp;#13;
	puts("I rock!!!");&amp;#13;
	return x*5+e;&amp;#13;
}&lt;/code&gt;
    &lt;p&gt;All the macros except the base &lt;code&gt;_s&lt;/code&gt; also add implicit arguments like &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;x&lt;/code&gt; and you bet it's hard to tell them apart.&lt;/p&gt;
    &lt;code&gt;#define ax (256&amp;gt;x)&lt;/code&gt;
    &lt;p&gt;This was another one that baffled me until I looked at the annotations. Remember how I said &lt;code&gt;s&lt;/code&gt; values were either integers or pointers? 256 is the cutoff value for these integers, which the annotations call atoms, so ax means "is &lt;code&gt;x&lt;/code&gt; an atom?"&lt;/p&gt;
    &lt;code&gt;#define ix (c)x&amp;#13;
#define nx x[-1]&amp;#13;
#define xi x[i]&lt;/code&gt;
    &lt;p&gt;These aren't too confusing. &lt;code&gt;ix&lt;/code&gt; casts &lt;code&gt;x&lt;/code&gt; to a &lt;code&gt;char&lt;/code&gt;. &lt;code&gt;nx&lt;/code&gt; implies &lt;code&gt;x&lt;/code&gt; is some sort of fat pointer, meaning there's probably a length at &lt;code&gt;x[-1]&lt;/code&gt;, but we'll see. &lt;code&gt;xi&lt;/code&gt; just indexes &lt;code&gt;x&lt;/code&gt; as a normal pointer, using our implicitly defined &lt;code&gt;i&lt;/code&gt; from the &lt;code&gt;i(...)&lt;/code&gt; macro.&lt;/p&gt;
    &lt;code&gt;#define aa x(a,ax)&amp;#13;
#define ia x(a,ix)&amp;#13;
#define na x(a,nx)&lt;/code&gt;
    &lt;p&gt;These copy &lt;code&gt;ax&lt;/code&gt;, &lt;code&gt;ix&lt;/code&gt;, and &lt;code&gt;nx&lt;/code&gt; respectively to work on the &lt;code&gt;a&lt;/code&gt; variable, which is an implicit argument in functions defined using the &lt;code&gt;F(f,e)&lt;/code&gt; macro. You remembered the &lt;code&gt;x(name, expression)&lt;/code&gt; macro for assigning to a locally-scoped &lt;code&gt;x&lt;/code&gt;, right?&lt;/p&gt;
    &lt;code&gt;#define oo w("oo\n")&lt;/code&gt;
    &lt;p&gt;It prints &lt;code&gt;oo&lt;/code&gt;. It's not used anywhere.&lt;/p&gt;
    &lt;head rend="h2"&gt;a reading of a.c&lt;/head&gt;
    &lt;p&gt;I wound up not needing to refer to the annotated code at all to understand this. The C code is mostly using everything in the headers to build the interpreter.&lt;/p&gt;
    &lt;code&gt;#define r(n,e) _(s r=m(n);i(n,r[i]=e)r)&lt;/code&gt;
    &lt;p&gt;We create a vector &lt;code&gt;r&lt;/code&gt; from &lt;code&gt;m(n)&lt;/code&gt; (which is defined later (it's malloc)), fill &lt;code&gt;r&lt;/code&gt; with the results of &lt;code&gt;e&lt;/code&gt;, and return it out of the statement expression.&lt;/p&gt;
    &lt;code&gt;f(w,write(1,ax?&amp;amp;x:x,ax?1:strlen(x));x)&lt;/code&gt;
    &lt;p&gt;This defines &lt;code&gt;s w(s x)&lt;/code&gt;, which is our print function. If &lt;code&gt;x&lt;/code&gt; is an atom (&lt;code&gt;ax?&lt;/code&gt;), we print it as a single character by getting its address (&lt;code&gt;&amp;amp;x&lt;/code&gt;) and providing a length of 1. If it's a vector, we print it as a string using &lt;code&gt;strlen&lt;/code&gt; to calculate how long it is, so now we also know vectors must be null-terminated here.&amp;#13;
&lt;code&gt;write&lt;/code&gt; and &lt;code&gt;strlen&lt;/code&gt; are standard functions that we call without including the headers, because fuck headers. Let the linker figure it out.&lt;/p&gt;
    &lt;code&gt;F(err,w(a);w((s)58);w(x);w((s)10);Q)&lt;/code&gt;
    &lt;p&gt;Our fancy shmancy error printing function, &lt;code&gt;s err(s a, s x)&lt;/code&gt;. The confusing thing is that &lt;code&gt;:&lt;/code&gt; and the newline are represented by their ASCII numbers 58 and 10, respectively. This just prints a message in the format &lt;code&gt;{a}:{x}\n&lt;/code&gt; and returns our special error value &lt;code&gt;Q&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;_i(wi,s b[5];sprintf(b,"%d ",x);w(b);0)&lt;/code&gt;
    &lt;p&gt;Defines &lt;code&gt;s wi(c x)&lt;/code&gt;, which takes &lt;code&gt;x&lt;/code&gt; as a &lt;code&gt;char&lt;/code&gt;, formats it as an integer in up to &lt;code&gt;5*sizeof(char*)/sizeof(char)&lt;/code&gt; characters (40 on 64-bit machines), and writes that.&lt;/p&gt;
    &lt;code&gt;f(W,Q(x)$(ax,wi(ix))i(nx,wi(xi))w(10);x)&lt;/code&gt;
    &lt;p&gt;Another print function, &lt;code&gt;s W(s x)&lt;/code&gt; either writes &lt;code&gt;x&lt;/code&gt; as an integer or a list of integers. It also refuses to print the &lt;code&gt;Q&lt;/code&gt; vector.&lt;/p&gt;
    &lt;code&gt;f(srt,Qz(1)0) f(uni,Qz(1)0) F(Cut,Qz(1)0) F(Drp,Qz(1)0)&lt;/code&gt;
    &lt;p&gt;I figured out what &lt;code&gt;nyi&lt;/code&gt; means! It means "Not yet implemented", as we can see from these function definitions.&lt;/p&gt;
    &lt;code&gt;_i(m,s a=malloc(1+x);*a++=x;a)&lt;/code&gt;
    &lt;p&gt;And we find our previously-used function &lt;code&gt;s m(c x)&lt;/code&gt;, which allocates our buffer and returns a fat pointer (with the size at &lt;code&gt;x[-1]&lt;/code&gt;, hence the &lt;code&gt;1+x&lt;/code&gt; and &lt;code&gt;a++&lt;/code&gt;). &lt;code&gt;x&lt;/code&gt; is the length we're allocating here, which means our vectors are limited to 255 bytes. The repo suggests upgrading capacity as an exercise to the reader, which could be fun.&lt;/p&gt;
    &lt;code&gt;#define A(c) ((s)memchr(a,c,na)?:a+na)-a&lt;/code&gt;
    &lt;p&gt;This macro finds the first occurence of the character &lt;code&gt;c&lt;/code&gt; in our vector &lt;code&gt;a&lt;/code&gt; as an index into the string (hence the &lt;code&gt;-a&lt;/code&gt;, since &lt;code&gt;memchr&lt;/code&gt; returns a pointer). If the result is null, it just returns the length of the string (&lt;code&gt;a+na - a&lt;/code&gt;). We see another fun bit of non-standard syntax, &lt;code&gt;?:&lt;/code&gt;, which I had to look up. &lt;code&gt;a ?: b&lt;/code&gt; is equivalent to &lt;code&gt;a ? a : b&lt;/code&gt; without evaluating &lt;code&gt;a&lt;/code&gt; twice. Pretty snazzy!&lt;/p&gt;
    &lt;code&gt;#define g(a,v) ax?255&amp;amp;a:r(nx,v)&lt;/code&gt;
    &lt;p&gt;Strange little operation, I'll have to see it in action. If &lt;code&gt;x&lt;/code&gt; is an atom, it clamps &lt;code&gt;a&lt;/code&gt; to be an atom with a simple mask (&lt;code&gt;255&amp;amp;a&lt;/code&gt;), otherwise it creates a new vector the same size as &lt;code&gt;x&lt;/code&gt; filled with the result from &lt;code&gt;v&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;f(not,g(!ix,!xi)) f(sub,g(-ix,-xi)) F(At,Qr(aa)g(a[ix],a[xi])) F(_A,Qr(aa)g(A(ix),A(xi)))&lt;/code&gt;
    &lt;p&gt;Ah, I see now. &lt;code&gt;g(a, v)&lt;/code&gt; lets us define functions that work on both atoms and vectors. If &lt;code&gt;x&lt;/code&gt; is an atom, it returns the atom result clamped within the correct bounds. Otherwise it allocates a new vector and computes the other expression.&amp;#13;
All the above functions work either on &lt;code&gt;x&lt;/code&gt; as an integer (&lt;code&gt;ix&lt;/code&gt;), or on every element of &lt;code&gt;x&lt;/code&gt; (&lt;code&gt;xi&lt;/code&gt;).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;s not(s x)&lt;/code&gt;does boolean negation.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;s sub(s x)&lt;/code&gt;does arithmetic negation.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;s At(s a, s x)&lt;/code&gt;indexes into&lt;code&gt;a&lt;/code&gt;, either to get one value or to shuffle them into a new vector.&lt;code&gt;a&lt;/code&gt;has to be a vector.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;s _A(s a, s x)&lt;/code&gt;searches a vector&lt;code&gt;a&lt;/code&gt;for the value of&lt;code&gt;x&lt;/code&gt;and gives us the index, either one value or every value in the vector.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a lot of functionality in such a small bit of code.&lt;/p&gt;
    &lt;code&gt;f(ind,Qr(!ax)0&amp;gt;ix?r(-ix,-ix-1-i):r(ix,i))&amp;#13;
F(Ind,Qr(!aa)Qd(1&amp;gt;ia)g(ix%ia,xi%ia))&lt;/code&gt;
    &lt;p&gt;These are some atom-only functions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;s ind(s x)&lt;/code&gt;creates a vector of length |x| containing&lt;code&gt;0, 1... x-1&lt;/code&gt;if&lt;code&gt;x&lt;/code&gt;is positive, otherwise it contains&lt;code&gt;-x-1, -x-2... 0&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;s Ind(s a, s x)&lt;/code&gt;does&lt;code&gt;x&lt;/code&gt;modulo&lt;code&gt;a&lt;/code&gt;, either on&lt;code&gt;x&lt;/code&gt;as an integer or every value of the vector&lt;code&gt;x&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Honestly, I can buy that this method of coding produces fewer bugs, once you can actually write it, since you work only on small building blocks of the logic and reuse them. Like, where could a bug for &lt;code&gt;ind&lt;/code&gt; even be? Maybe an off-by-one in &lt;code&gt;-ix-1-i&lt;/code&gt;, but it's hard to miss what's happening once you can see the trees through the forest.&lt;/p&gt;
    &lt;code&gt;#define G(f,o) F(f,ax?aa?255&amp;amp;ia o ix:Ltn==f?f(sub(x),sub(a)):f(x,a):r(nx,(aa?ia:a[i])o xi))&lt;/code&gt;
    &lt;p&gt;That's too many trees! I can't understand this many nested ternary operators at the same time because I'm not the alien from Arrival. I process things in linear time. I have to chunk this up.&lt;/p&gt;
    &lt;code&gt;F(f, ax ?&amp;#13;
		aa ?&amp;#13;
			255 &amp;amp; ia o ix&amp;#13;
			: Ltn==f ? &amp;#13;
				f(sub(x),sub(a))&amp;#13;
				: f(x,a)&amp;#13;
		: r(nx,(aa?ia:a[i])o xi))&lt;/code&gt;
    &lt;p&gt;Okay, I see. It's 3 cases from 2 conditions: &lt;code&gt;x&lt;/code&gt; is an atom or a vector, and &lt;code&gt;a&lt;/code&gt; is an atom or a vector.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;x&lt;/code&gt;and&lt;code&gt;a&lt;/code&gt;are atoms: apply some operator&lt;code&gt;o&lt;/code&gt;to both values and clamp to 8 bits. I also didn't realize the bitwize and (&lt;code&gt;&amp;amp;&lt;/code&gt;) had a lower precedence than the operators this macro is used on, meaning it's always&lt;code&gt;`C 255 &amp;amp; (ia o ix)&lt;/code&gt;`.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;x&lt;/code&gt;is an atom and&lt;code&gt;a&lt;/code&gt;is a vector: run this function with the arguments swapped. If the function is&lt;code&gt;Ltn&lt;/code&gt;, also negate the arguments, since less-than depends on argument order.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;x&lt;/code&gt;is a vector: create a new vector, either applying&lt;code&gt;a&lt;/code&gt;or each value of&lt;code&gt;a&lt;/code&gt;to&lt;code&gt;x&lt;/code&gt;using the operator. It assumes vector&lt;code&gt;a&lt;/code&gt;is at least as long as&lt;code&gt;x&lt;/code&gt;, or it'll index past the end of&lt;code&gt;a&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;G(Ltn,&amp;lt;)G(Eql,==)G(Not,!=)G(Sum,+)G(Prd,*)G(And,&amp;amp;)G(Or,|)&lt;/code&gt;
    &lt;p&gt;Using our fancy new macro, we quickly define seven new functions for the vectors, where they're all element-wise applications of binary operators.&lt;/p&gt;
    &lt;code&gt;f(cat,Qr(!ax)r(1,ix)) F(Cat,a=aa?cat(a):a;x=ax?cat(x):x;s r=m(na+nx);memcpy(r+na,x,nx);memcpy(r,a,na))&lt;/code&gt;
    &lt;p&gt;I was confused by the first function, but I see now these are &lt;code&gt;cat&lt;/code&gt; as in "concatenate". For an atom, it creates a vector of length 1 containing that atom. &lt;code&gt;Cat&lt;/code&gt; does the more complex work of joining two vectors together, running &lt;code&gt;cat&lt;/code&gt; on each value if it's an atom to get a list.&lt;/p&gt;
    &lt;code&gt;f(at,At(x,0)) f(rev,Qr(ax)At(x,ind(255&amp;amp;-nx))) f(cnt,Qr(ax)nx)&lt;/code&gt;
    &lt;p&gt;Some more simple functions. Lil &lt;code&gt;at&lt;/code&gt; gets the first item of &lt;code&gt;x&lt;/code&gt;; &lt;code&gt;rev&lt;/code&gt; reverses the list using our &lt;code&gt;ind&lt;/code&gt; function to generate the list of indeces in reverse, which is a little overkill but vectors are 256 bytes at max and memory is never freed so who cares; and &lt;code&gt;cnt&lt;/code&gt; gets the size of &lt;code&gt;x&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;F(Tak,Qr(!aa||ax)Qd(0&amp;gt;ia||ia&amp;gt;nx)At(x,ind(a))) F(Sub,Sum(a,sub(x))) F(Mtn,Ltn(x,a)) f(qz,Qz(1)0)&lt;/code&gt;
    &lt;p&gt;Some more simple functions. &lt;code&gt;Tak&lt;/code&gt; returns the first &lt;code&gt;a&lt;/code&gt; characters from the vector &lt;code&gt;x&lt;/code&gt; as a new list; &lt;code&gt;Sub&lt;/code&gt; subtracts; &lt;code&gt;Mtn&lt;/code&gt; is "more than"; and &lt;code&gt;qz&lt;/code&gt; returns our "not yet implemented" error.&lt;/p&gt;
    &lt;code&gt;#define v(e) ((strchr(V,e)?:V)-V)&lt;/code&gt;
    &lt;p&gt;A shorthand to get the first occurence of a character from a string &lt;code&gt;V&lt;/code&gt;, returning an offset into the array or zero if it's not present. This seems ambiguous, since that's also the result if we match with the first character, but we'll see.&lt;/p&gt;
    &lt;code&gt;s U[26],V=" +-*&amp;amp;|&amp;lt;&amp;gt;=~!@?#_^,",&amp;#13;
(*f[])()={0,abs,sub,qz ,qz,rev,qz ,qz, qz ,not,ind,at,uni,cnt,qz ,srt,cat},&amp;#13;
(*F[])()={0,Sum,Sub,Prd,And,Or,Ltn,Mtn,Eql,Not,Ind,At,_A ,Tak,Drp,Cut,Cat};&lt;/code&gt;
    &lt;p&gt;Ah, we have seen. The first character of &lt;code&gt;V&lt;/code&gt; is a space, and it looks like the arrays of function pointers match up with the characters of &lt;code&gt;V&lt;/code&gt; to give us our functions, with space being null. However, I think &lt;code&gt;abs&lt;/code&gt; is from the standard library here, since it's not defined anywhere else? That seems like a bug. It'd work for atoms, but it'd break vectors.&amp;#13;
This also defines an array of 26 vectors, which I assume will be our variables. &lt;/p&gt;
    &lt;code&gt;_i(n, 10u&amp;gt;x-48? x-48 : 26u&amp;gt;x-97? U[x-97] : 0)&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;s n(c x)&lt;/code&gt; reads a char and returns one of several things. I'll have to consult an ASCII table.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If &lt;code&gt;x&lt;/code&gt;is between 48 and 57 (inclusive), we subtract 48 and return that. Meaning, if&lt;code&gt;x&lt;/code&gt;is an ASCII character representing 0-9, we subtract 48 so it's the integer 0-9, rather than the character. It's phrased strangely,&lt;code&gt;10u &amp;gt; x-48&lt;/code&gt;, instead of the more obvious&lt;code&gt;x&amp;gt;47&amp;amp;&amp;amp;58&amp;gt;x&lt;/code&gt;. Maybe it's because it's two characters shorter. Maybe Arthur wanted to show the length of the span of characters (10) more than the start and end, which this does once you understand it. Maybe he just thought the underflow trickery was neat.&lt;/item&gt;
      &lt;item&gt;If &lt;code&gt;x&lt;/code&gt;is between 97 and 122 (inclusive), it's a lowercase character of the alphabet in ASCII, in which case the function returns one of our variables from the&lt;code&gt;U&lt;/code&gt;array, mapping 'a' to 'z'.&lt;/item&gt;
      &lt;item&gt;Otherwise, the function returns 0.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So it looks like this function is specifically to read values, either numerals or variables, all of which are one character.&lt;/p&gt;
    &lt;code&gt;f(e,s z=x;c i=*z++;!*z?n(i):v(i)?x(e(z),Q(x)f[v(i)](x)):x(e(z+1),Q(x)58==*z?U[i-97]=x:_(c f=v(*z);Qd(!f)F[f](n(i),x))))&lt;/code&gt;
    &lt;p&gt;Uh, let's spread this out a little.&lt;/p&gt;
    &lt;code&gt;f(e, s z=x; c i=*z++; !*z ? n(i)&amp;#13;
	: v(i) ? x(e(z), Q(x) f[v(i)](x))&amp;#13;
		: x(e(z+1), Q(x) 58==*z ? U[i-97]=x &amp;#13;
			: _(c f=v(*z); Qd(!f) F[f](n(i),x))))&lt;/code&gt;
    &lt;p&gt;Okay, easy. It's a recursive function that checks each character of vector &lt;code&gt;x&lt;/code&gt;, called &lt;code&gt;i&lt;/code&gt;.&amp;#13;
If we're at the end of the string, we check if &lt;code&gt;i&lt;/code&gt; is a value and return it.&amp;#13;
Otherwise, we first check if it's an operator (from our &lt;code&gt;V&lt;/code&gt; string). If it is, we evaluate the rest of the string, check for errors, and then apply the operation to the result from the rest of the evaluation.&amp;#13;
If it wasn't an operation, we evaluate the rest of the string, skipping one character. If the skipped character is a colon (ASCII 58), we assign the result of the evaluation to one of the slots in &lt;code&gt;U&lt;/code&gt; (if the character &lt;code&gt;i&lt;/code&gt; is not a lowercase ASCII letter, this will corrupt memory, so don't write bugs).&lt;/p&gt;
    &lt;p&gt;I'm pretty sure spaces are a syntax error in every location, and I don't see code to create array literals. If the skipped character is an operator, we instead apply that binary operator on the evaluation result and &lt;code&gt;n(i)&lt;/code&gt;, which is either a variable or a number.&amp;#13;
This means code is executed from right to left, with no operator precedent, which is standard for APL-type languages from what I understand.&amp;#13;
Because this language has only single-character variable names, numbers, and operators, this is all the tokenizing, parsing, and evaluation we need.&lt;/p&gt;
    &lt;code&gt;C int main(){c b[99]; while(1) if(w(32),b[read(0,b,99)-1]=0,*b) 58==b[1] ? e(b) : W(e(b));}&lt;/code&gt;
    &lt;p&gt;And finally, &lt;code&gt;main&lt;/code&gt;.&amp;#13;
In an infinite loop, we read up to 99 characters from a user, and then write the evaluated result of that text.&lt;/p&gt;
    &lt;p&gt;Et voila. We have a tiny interpreter for a simple array language. It's not exactly production-ready, but it does quite a lot in its tiny footprint.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;I think I can say I understand this code pretty well, even more than most code I read. I don't know how much of that is because of the coding style, or because I spent eight hours writing several thousand words about fifty lines of code in a borderline-delusional fugue state brought on by drinking one small Starbucks™ Frapuccino® (Mocha® Flavored*) I bought from a gas station at 10 PM on a Thursday.&lt;/p&gt;
    &lt;p&gt;I had some fun dreams about macros with one-character names applying operations on scalars and vectors that morning (I went to sleep at 6:40 AM).&lt;/p&gt;
    &lt;p&gt;All in all, it was a fun exercise. To summarize my thoughts:&lt;/p&gt;
    &lt;head rend="h3"&gt;Good ideas&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Well-considered primitives. I've read and written a lot of macro-ridden C, but this feels like a proper little language designed with composable, useful macros that removed enough repetition to make common operations, like iteration, easy to decipher. In other languages, higher-order functions and similar constructs could be used the same way.&lt;/item&gt;
      &lt;item&gt;Fewer lines. I didn't have to scroll so much when I forgot what a macro or a function did! I have a wide screen monitor, I don't need lines limited to 10-20 characters of actual code most of the time. If people can read English in compact paragraphs, why not code?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Bad ideas&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-semantic types. I was completely baffled by the &lt;code&gt;char *&lt;/code&gt;being treated as an integer at first, and simply assumed I was misunderstanding the code somehow until I checked the annotated version. In my own code, I use types as one of the core building blocks. What the data is defines how I use it. For a full interpreter, this would be a custom type anyway, since right now it assumes&lt;code&gt;malloc&lt;/code&gt;will never give it a pointer to an address less than 256, which is probably true but not guaranteed, and also the integer 128 is reserved for invalid results, which is probably the bigger limitation.&lt;/item&gt;
      &lt;item&gt;Code golf. I can understand the large gains to density like macros, and even the medium gains like short names, but there's a point where the code becomes significantly harder to follow for very minor gains, such as the use of ASCII codes like &lt;code&gt;58&lt;/code&gt;instead of character literals like&lt;code&gt;':'&lt;/code&gt;, or the use of&lt;code&gt;10u&amp;gt;x-48&lt;/code&gt;instead of&lt;code&gt;x&amp;gt;48&amp;amp;&amp;amp;58&amp;gt;x&lt;/code&gt;for checking if&lt;code&gt;x&lt;/code&gt;is within a range. And while I think more code can be put on a line, I'm not throwing out my space key just yet, epecially between function declarations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ideas I'm ambivalent about&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-standard syntax. There's some very interesting features in this code that utilize GCC-specific extensions, like &lt;code&gt;a ?: b&lt;/code&gt;ternaries and statement expressions. I don't typically need to compile for everything on earth, so learning the tricks of one reasonably cross-platform compiler isn't a bad idea. At the same time, even using clang, the same compiler Arthur was using, I had to include&lt;code&gt;stdio.h&lt;/code&gt;due to not linking&lt;code&gt;sprintf&lt;/code&gt;otherwise. If I wanted to build using Visual Studio I'd just have to rewrite a bunch of stuff. Also, compiling without&lt;code&gt;-w&lt;/code&gt;generates almost three compiler warnings per line of code. Those are useful sometimes, if they aren't flooded!&lt;/item&gt;
      &lt;item&gt;Implicit arguments. Many of the density gains in this code come from using the variables &lt;code&gt;x&lt;/code&gt;,&lt;code&gt;a&lt;/code&gt;, and&lt;code&gt;i&lt;/code&gt;in nearly every context, allowing macros to use them by default and skip listing other parameters. I didn't find it to be a problem after a brief adjustment, but it's also a very small codebase. Implicit arguments are a feature in many dynamically typed languages, and in "point-free" or "tacit" programming, but it's fallen out of style due to its difficulty to parse at first glance. Whitney's languages all being based around tacit programming is surely an influence on his tendency to make arguments implicit.&lt;/item&gt;
      &lt;item&gt;Short names. Beyond the very first introduction, there'd be virtually no benefit to renaming &lt;code&gt;ax&lt;/code&gt;as&lt;code&gt;vector_is_atom(x)&lt;/code&gt;,&lt;code&gt;_(...)&lt;/code&gt;as 'execute(...)', or most other primitives after they're introduced. Most are small enough that you can parse what it does right away. However, this doesn't lend any signal as to why it does. You have to figure out what it does from context. For code that's meant to be read by another person, there should probably be some explanation as to why a primitive does what it does, even if it has a short name. This is especially true of more complex operations, like the evaluation function&lt;code&gt;e&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Nested ternary operators. Too confusing for me to follow without parentheses, especially without whitespace.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This coding style feels most appropriate for "done" code, or code that's been worked out on paper or some other environment and is now being written down in a compact way. It's more like finalized mathematical notation than typical code. I don't see myself being able to effectively write code like this, since I tend to quickly jot down ideas, compile and run to validate, and edit what I've done based on the results. Making a small set of good primitives and building heavily on those requires basically having solved the problem before writing a single line. Otherwise you get bad primitives that cause more confusion than help, and adjusting those primitives would involve rewriting all the code that depends on them, which is all the code.&lt;/p&gt;
    &lt;p&gt;But I think that's my key takeaway: I tend to work out problems in the code, which can lead to messy results. I write the dumbest possible solution, and then have to try and refactor as I develop a better mental model of the problem. What I like most about this code isn't how few characters are used, or everything fitting in one screen. I like how it seems the code was well-understood before it was written. You can't refactor a 500-line jumble of C into code like this.&lt;/p&gt;
    &lt;p&gt;The real lesson is that I'm probably too quick to jump into coding things. I could spend more time working out how I want to model a problem in a more free-form way, like writing notation on paper, before jumping into the rigid world of programming syntax. With a clear mental model, I can then write code in terms of how I was thinking about the problem, instead of thinking about the problem in terms of how I wrote the code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next time&lt;/head&gt;
    &lt;p&gt;I think a fun exercise would be to extend this interpreter while maintaining its code style, to see how I fare actually working with it. The repository this came from has various suggested exercises, but my ideas would be adding the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swapping the bytes for float vectors&lt;/item&gt;
      &lt;item&gt;Vectors longer than 255 values&lt;/item&gt;
      &lt;item&gt;Multi-character numbers&lt;/item&gt;
      &lt;item&gt;Array literals (you can do it with comma, but that runs &lt;code&gt;cat&lt;/code&gt;on every value, which isn't ideal)&lt;/item&gt;
      &lt;item&gt;Whitespace insensitivity&lt;/item&gt;
      &lt;item&gt;Memory management&lt;/item&gt;
      &lt;item&gt;The unimplemented functions&lt;/item&gt;
      &lt;item&gt;Multi-character variable names&lt;/item&gt;
      &lt;item&gt;Multi-character operators&lt;/item&gt;
      &lt;item&gt;Indication for syntax errors&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800777</guid><pubDate>Mon, 03 Nov 2025 16:23:11 +0000</pubDate></item><item><title>Why We Migrated from Python to Node.js</title><link>https://blog.yakkomajuri.com/blog/python-to-node</link><description>&lt;doc fingerprint="26f311d55ce5b00f"&gt;
  &lt;main&gt;
    &lt;p&gt;We just did something crazy: we completely rewrote our backend from Python to Node just one week after our launch.&lt;/p&gt;
    &lt;p&gt;We did this so we can scale. Yes, scale. A week in.&lt;/p&gt;
    &lt;p&gt;In some ways, it's a good time right? The codebase is still small and we don't have too many users.&lt;/p&gt;
    &lt;p&gt;But on the other hand, it goes completely against the advice given to early-stage startups which is to just ship and sell, and worry about scale once you've hit product-market-fit. "Do things that don't scale", as PG put it.&lt;/p&gt;
    &lt;p&gt;You see, we didn't have a magical launch week that flooded us with users and force us to scale. And generally you can expect that any stack you pick should be able to scale reasonably well for a long time until you actually get to the point where you should consider changing frameworks or rewriting your backend in a different language (read: Rust).&lt;/p&gt;
    &lt;p&gt;So why do it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Python async sucks&lt;/head&gt;
    &lt;p&gt;I'm a big fan of Django. I was introduced to it at PostHog and it's become my go-to backend for most projects since. It gets you off the ground really fast, has great tooling and abstractions, and is still flexible enough to tweak to your needs.&lt;/p&gt;
    &lt;p&gt;So naturally, when I started writing our backend at Skald, I started us off with Django too.&lt;/p&gt;
    &lt;p&gt;Now, we make a lot of calls to LLM and embedding APIs at Skald, so we're generally doing a lot of network I/O that we'd like to be async. Not only that, we often want to fire a lot of requests concurrently, such as when need to generate vector embeddings for the various chunks of a document.&lt;/p&gt;
    &lt;p&gt;And things quickly got really messy in Django.&lt;/p&gt;
    &lt;p&gt;I'll preface this by saying that neither of us has a lot of experience writing Python async code (I've mostly worked on async-heavy services in Node) but I think this is partly the point here: it's really hard and unintuitive to write solid and performant Python async code. You need to go deep into the foundations of everything in order to be able to do so.&lt;/p&gt;
    &lt;p&gt;I'm actually really interested in spending proper time in becoming more knowledgeable with Python async, but in our context you a) lose precious time that you need to use to ship as an early-stage startup and b) can shoot yourself in the foot very easily in the process.&lt;/p&gt;
    &lt;p&gt;Nevertheless, I thought I was to blame. "Bad programmer! Bad programmer!" was what I was hearing in my head as I tried to grasp everything. But while more knowledgeable folks would certainly have a better time, we discovered that the foundations of Python async are actually a bit shaky too.&lt;/p&gt;
    &lt;p&gt;Unlike JavaScript, which had the event loop from the beginning, and Go, that created the concept of goroutines (both concurrency models that I quite like and have used in production), Python async support was patched on later, and that's where the difficulty lies.&lt;/p&gt;
    &lt;p&gt;Two blog posts that cover this really well are "Python has had async for 10 years -- why isn't it more popular?" and "Python concurrency: gevent had it right", both conveniently published not long before I started digging into all this.&lt;/p&gt;
    &lt;p&gt;As for us, we learned a few things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python doesn't have native async file I/O.&lt;/item&gt;
      &lt;item&gt;Django still doesn't have full async support. Async in the ORM is not done yet and the colored functions problem really shines here. You can technically use Django with async, but their docs on this have so many caveats that it should scare anyone.&lt;/item&gt;
      &lt;item&gt;You gotta write &lt;code&gt;sync_to_async&lt;/code&gt;and&lt;code&gt;async_to_sync&lt;/code&gt;everywhere.&lt;/item&gt;
      &lt;item&gt;All sorts of models have emerged to bring better async support to different parts of the Python ecosystem, but as they're not native they have their own caveats. For instance, aiofiles brings async API-compatible file operations but uses a thread pool under the hood, and Gevent with its greenlets is pretty cool but it literally patches the stdlib in order to work.&lt;/item&gt;
      &lt;item&gt;Due to a lot of async support in Python relying on layers that sit on top of the language rather than being native, you need to be careful about the async code you write as it will have different implications depending on e.g. the Gunicorn worker type you run (good luck learning much about those from the Gunicorn docs, btw).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Overall, just getting an equivalent of &lt;code&gt;Promise.all&lt;/code&gt; to work, while understanding all of its gotchas was not simple at all.&lt;/p&gt;
    &lt;p&gt;Faced with this, I went into the PostHog codebase.&lt;/p&gt;
    &lt;p&gt;I worked at PostHog for three years and we had no async in the Django codebase back then but they're a massive company and they have AI features now so they must have figured this out!&lt;/p&gt;
    &lt;p&gt;And what I realized was that they're still running WSGI (not ASGI) with Gunicorn Gthread workers (where the max concurrent requests you're able to handle is usually max 4x CPU cores), thus not getting much benefit from running things async. The codebase also has a lot of utils to make async work properly, like their own implementation of &lt;code&gt;async_to_sync&lt;/code&gt;. So I guess way they're handling a lot of load is probably just horizontal scaling.&lt;/p&gt;
    &lt;p&gt;There's simply no great way to run async in Django.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ok, now what?&lt;/head&gt;
    &lt;p&gt;We essentially concluded that Django was going to hurt us really soon, not just when we started to have a lot of load.&lt;/p&gt;
    &lt;p&gt;Without too many users we'd already need to start running multiple machines in order to not have terrible latency, plus we'd be writing clunky code that would be hard to maintain.&lt;/p&gt;
    &lt;p&gt;We could of course just "do things that don't scale" for now and just solve the problem with money (or AWS credits), but it didn't feel right. And being so early would make the migration to another framework much easier.&lt;/p&gt;
    &lt;p&gt;At this point, some people are probably screaming at their screens going: "just use FastAPI!" -- and we did indeed consider it.&lt;/p&gt;
    &lt;p&gt;FastAPI does have proper async support and is quite a loved framework said to be performant. And if you want an ORM with it you could use SQLAlchemy which also supports async.&lt;/p&gt;
    &lt;p&gt;Migrating to FastAPI would have probably saved us a day or two (our migration took 3 days) due to being able to reuse a lot of code without translating it, but at this point we weren't feeling great about the Python async ecosystem overall, and we had actually already written our background worker service in Node, so we thought it would be a good opportunity to go all-in on one ecosystem.&lt;/p&gt;
    &lt;p&gt;And so migrate to Node we did. We took a little time picking the framework + ORM combo but settled on Express + MikroORM.&lt;/p&gt;
    &lt;p&gt;Yeah sure Express is old but it's battle-tested and feels familiar. Coming over to the JS event loop was the main point of all this anyway.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we gained, what we lost&lt;/head&gt;
    &lt;head rend="h3"&gt;Gained: Efficiency&lt;/head&gt;
    &lt;p&gt;Our initial benchmarks show we've gained ~3x throughput out of the box and that's just with us running what is mostly sequential code in an async context. Being over on Node now, we're planning on doing a lot concurrent processing when chunking, embedding, reranking, and so on. This means this change should have an even greater payoff over time.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lost: Django&lt;/head&gt;
    &lt;p&gt;Losing Django hurts, and we've already found ourselves building a lot more middleware and utilities ourselves on the Express side. Adonis exists, which is a more fully-featured Node framework, but moving to a whole new ecosystem felt like more work to us than just using something minimal.&lt;/p&gt;
    &lt;p&gt;What I'm missing the most is the ORM, which in my opinion is really ergonomic. And while you always have to be careful with ORMs when looking to extract the best possible performance, the Django ORM does do some nice things under the hood in order to make it performant enough to write queries in Python, and I learned a bit more about this when migrating our Django models over to MikroORM entities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gained: MikroORM&lt;/head&gt;
    &lt;p&gt;MikroORM was a consolation prize in this whole migration. I still much prefer the Django ORM but at the same time different ecosystems call for different tooling.&lt;/p&gt;
    &lt;p&gt;I'd never used it before and was positively surprised to find Django-like lazy loading, a migrations setup that felt much better than Prisma's, as well as a reasonably ergonomic API (once you manually set up the foundations right).&lt;/p&gt;
    &lt;p&gt;Overall, we're early into this change, but currently happy to have picked MikroORM over the incumbent Prisma.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lost: The Python ecosystem&lt;/head&gt;
    &lt;p&gt;I think this is pretty self-explanatory. While most tools for building RAGs and agents have Python and TypeScript SDKs, Python still takes priority, and we're just talking about API wrappers here.&lt;/p&gt;
    &lt;p&gt;Once you want to actually get into ML stuff yourself, there's just no competition. I suspect that as we get more sophisticated we'll end up having a Python service, but for now we're ok.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gained: Unified codebase&lt;/head&gt;
    &lt;p&gt;We'd always realized that migrating to Node would mean we'd have two Node services instead of a Python one and a Node one, but it didn't occur to us until a day in that we could actually merge the codebases and that that would be extremely helpful.&lt;/p&gt;
    &lt;p&gt;There was a lot of duplicate logic across the Node worker and the Django server, and now we've unified the Express server and background worker into one codebase, which feels so much better. They can both use the ORM now (previously the worker was running raw SQL) and share a bunch of utils.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gained: Much better testing&lt;/head&gt;
    &lt;p&gt;This is not a &lt;code&gt;pytest&lt;/code&gt; vs &lt;code&gt;jest&lt;/code&gt; thing, it's just that in order to make sure everything was working as expected after migrating, we just wrote a ton more tests. This and some refactoring were welcome side benefits.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we did it&lt;/head&gt;
    &lt;p&gt;I think it's about time to wrap this post up, but here are some quick notes about the actual migration process.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It took us three days.&lt;/item&gt;
      &lt;item&gt;We barely used AI code generation at all until the final bits -- it felt important to us to understand the foundations of our new setup really well, particularly the inner workings of the new ORM. Once we had the foundations of everything down Claude Code was quite helpful in generating code for some less important endpoints, and also helped us in scanning the codebase for issues.&lt;/item&gt;
      &lt;item&gt;We almost quit multiple times. We were getting customer requests for new features and had some bugs in the Django code and it felt like we were wasting time migrating instead of serving customers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Would we do it again?&lt;/head&gt;
    &lt;p&gt;Honestly, we're quite happy with our decision and would 100% do it again. Not only will this pay off in the long term but it's already paying off today.&lt;/p&gt;
    &lt;p&gt;We learned a lot of stuff in the process too, and if the whole point of this whole post is that someone comes to tell me that we're dumb and we should just have done X or Y, or comes to teach me about how Python async works, then that will honestly be great. For my part, I gladly recognize my inexperience with Python async and if I can learn more about it, that's a win.&lt;/p&gt;
    &lt;p&gt;And if you're interested in actually seeing the code, check out the following PRs:&lt;/p&gt;
    &lt;p&gt;Skald is an MIT-licensed RAG API platform, so if you have any thoughts or concerns, you can come yell at us on GitHub, or open a PR to rewrite the backend to your framework of choice :D&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45800955</guid><pubDate>Mon, 03 Nov 2025 16:35:44 +0000</pubDate></item><item><title>No Socials November</title><link>https://bjhess.com/posts/no-socials-november</link><description>&lt;doc fingerprint="a3c4dc8ffd25e785"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;No Socials November&lt;/head&gt;
    &lt;p&gt;November seems to be a ripe month for challenges. Some people grow facial hair. Some people write many words daily hoping to come out with a novel on the other side. I’m sure there are five other such efforts that I’m not aware of.&lt;/p&gt;
    &lt;p&gt;For me, I’m going to continue my push away from social networks. I’ve logged out of all personal accounts, set my YouTube to stop suggesting to me via algorithm, and even found myself logged out of Reddit yesterday. I’m set to have a no socials November!&lt;/p&gt;
    &lt;p&gt;Maybe some of you reading my blog are also finding yourself overly pulled by the lure of social networking and tempted to take a break? Perhaps join me and see how it feels? Log out, delete the apps from your phone, and start the challenging process of breaking that muscle memory today. I believe in a week you’ll feel pretty good about the decision.&lt;/p&gt;
    &lt;p&gt;No pressure to stay off socials after November is over. You may decide you want to go back to your same relationship with social networking in December. You may decide you want to go back, but differently. You may decide you want to stay away.&lt;/p&gt;
    &lt;p&gt;I might try to blog more. I might not. We’ll see! If you’d like to try blogging as an alternative, I recommend my good friend, Pika. In solidarity with #nosocialsnovember, there’s even a NOSOCIALSNOVEMBER coupon code for 15% off your first year of the service.&lt;/p&gt;
    &lt;p&gt;If you have any thoughts to share about stepping away from socials, email me via the link below. And if you’re blogging, let me know! I’d love to follow what you’re writing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45801096</guid><pubDate>Mon, 03 Nov 2025 16:45:12 +0000</pubDate></item><item><title>Why Engineers Can't Be Rational About Programming Languages</title><link>https://spf13.com/p/the-hidden-conversation/</link><description>&lt;doc fingerprint="321991316f69a6a2"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;How Benjamin Franklin Invented Machine Learning in 1720&lt;/head&gt;&lt;p&gt;Benjamin Franklin discovered gradient descent 250 years before we had the mathematics to describe it.&lt;/p&gt;&lt;p&gt;A programming language is the single most expensive choice a company makes, yet we treat it like a technical debate. After watching this mistake bankrupt dozens of companies and hurt hundreds more, I’ve learned the uncomfortable truth: these decisions are rarely about technology. They’re about identity, emotion, and ego, and they’re destroying your velocity and budget in ways you can’t see until it’s too late.&lt;/p&gt;&lt;p&gt;Early in my career, I worked at Takkle, a promising social network. A sudden departure vaulted me from lead engineer to VP of Engineering, leading a team of 12. While we were delivering on all our goals, I was in my early 20s and lacked experience, a risk our board wanted to fix. They pressured our CEO to recruit a CTO with more experience. I looked forward to learning from him; he was a well known figure in the Perl community and arrived with a stack of O’Reilly “camel” books.&lt;/p&gt;&lt;p&gt;One of his first acts was to pronounce our language, PHP, the wrong choice. He decreed a switch to Perl. This decree happened after what felt to me like a sham analysis comparing PHP and Perl.&lt;/p&gt;&lt;p&gt;Our velocity collapsed. Our team had to not only learn a new language but rebuild from scratch, delaying our product by nine months. Our monthly burn rate jumped from $200K to $500K as we more than doubled our size to make up for the lost velocity while building the new Perl based system, which halved our runway.&lt;/p&gt;&lt;p&gt;Our CTO did deliver, at least on some of his promises. We built a beautiful system, one I was truly proud of. But it was too late. By the time we finally launched, the market opportunity had vanished. Facebook had now expanded beyond colleges, and we were at the end of our monitary runway. The increased spend had shortened our runway by half, and we didn’t have enough momentum with the new site to reach the milestones required to raise more money.&lt;/p&gt;&lt;p&gt;I’ve often wondered: What if we had just stuck with PHP? We had a fine system and real momentum. We would have launched much earlier at a fraction of the cost. PHP was good enough for Facebook; why not us?&lt;/p&gt;&lt;p&gt;But the question that haunted me was: Why did such an experienced leader make such an terrible mistake?&lt;/p&gt;&lt;p&gt;Promises Made&lt;/p&gt;&lt;p&gt;Reality Delivered&lt;/p&gt;&lt;p&gt;As my career progressed I saw this same pattern over and over. As Languages Product Lead at Google, my group included C++, Java, Go, and Python. At MongoDB, I managed teams writing in 13 different languages. In both places I saw brilliant engineers arguing past each other, armed with conflicting data, all of it true, but none of it complete. At Google Cloud, I saw these same challenges across our customers.&lt;/p&gt;&lt;p&gt;Fast forward two decades from Takkle, and I had déjà vu. I watched as a VP of Engineering presented to leadership why his team needed to build their next system in Rust. The presentation eerily paralleled that Takkle experience. In that old presentation, nearly every reason the CTO gave for Perl was truer of PHP at the time. Now, every single reason given for choosing Rust in this presentation, Go was objectively better at. As an example: they cited “easy build and deploy” as a Rust advantage. It’s true that this is a strength of Rust, but Go’s nearly instant cross compilation and single static binary is even stronger than Rust in this specic critera with Rust’s very long build times.&lt;/p&gt;&lt;p&gt;It’s not that I think they should have chosen Go, Go would have been the wrong choice for their situation, and I believe Rust was the right choice. But what struck me was how broken their reasoning was. If they were making a logical argument, surely they would have considered Go and in doing so with their presented criteria they would have realized Go was a better option and, at the very least, refined their critera.&lt;/p&gt;&lt;p&gt;I pulled the VP aside after the meeting. “Walk me through how you evaluated other language candidates,” I said. His face went blank. “We&amp;amp;mldr; didn’t really look at any others,” he admitted. “Everyone’s talking about Rust.” There it was: a 50 million dollar decision made on hype, about to be green lit.&lt;/p&gt;&lt;p&gt;For me this was the moment of epiphany, finally an answer to the question for the beginning of my career. The presentation didn’t share an analysis, they hadn’t done one; it was a justification for a choice already made. This was a decision based purely on hype, emotion, and identity.&lt;/p&gt;&lt;p&gt;In every language discussion, two conversations are happening simultaneously.&lt;/p&gt;&lt;p&gt;The Visible Conversation: “Rust has memory safety without garbage collection.” “Go has faster compile times and easier deployment.” “Python has the richest ML ecosystem.”&lt;/p&gt;&lt;p&gt;The Invisible Conversation: “I am a Rust programmer.” “I want to become a Rust programmer.” “I cannot imagine being someone who doesn’t choose Rust.”&lt;/p&gt;&lt;p&gt;If you just read that and thought “well, my last language choice was different, I was being rational,” your invisible conversation is running right now, defending itself while you read this sentence.&lt;/p&gt;&lt;p&gt;My CTO at Takkle was having the invisible conversation. Every point in his visible Perl analysis was technically true, but it felt like a sham because it was only there to cover the much deeper invisible conversation. He wasn’t evaluating languages. He was protecting an identity he’d spent a decade building. What our company paid $300K per month extra for wasn’t better architecture or faster hiring. We paid for the opportunity for him to be a Perl CTO instead of a PHP CTO. That was the real transaction. The rebuild was just the payment plan.&lt;/p&gt;&lt;p&gt;That VP’s Rust presentation listed “easy build and deploy” as an advantage, technically true, but Go is objectively better on that specific criterion. If they were truly having the visible conversation, they would have caught that. They would have at least considered Go in their analysis.&lt;/p&gt;&lt;p&gt;They hadn’t. Because they weren’t having that conversation at all. And they were about to spend $50 million on the invisible one.&lt;/p&gt;&lt;p&gt;In one of the most fascinating studies done in the past 20 years, researchers set out to understand why people cling to beliefs even when confronted with overwhelming contradictory evidence. What they discovered fundamentally changed our understanding of human decision making.&lt;/p&gt;&lt;p&gt;The researchers recruited participants and first identified which beliefs were central to each person’s identity—their core political views, their fundamental values, the beliefs that defined who they were. Then, while participants lay in an fMRI scanner, the researchers presented them with carefully constructed challenges to these identity based beliefs, alongside challenges to beliefs the participants held but weren’t central to their sense of self.&lt;/p&gt;&lt;p&gt;The brain scans revealed something remarkable: these two types of challenges activated completely different neural pathways.&lt;/p&gt;&lt;p&gt;When a peripheral belief was challenged, something the person believed but wasn’t core to their identity, the brain’s reasoning centers activated normally. Participants could consider the evidence, weigh the arguments, and sometimes even change their minds.&lt;/p&gt;&lt;p&gt;But when an identity based belief was challenged, the brain responded as if under physical attack. The amygdala, your threat detection system, the same system that fires when you encounter a predator or a physical danger, activates immediately. The insular cortex, which processes emotional pain and disgust, lit up with activity. Most tellingly, the brain’s Default Mode Network, the system that maintains your sense of self and personal narrative, went into defensive mode, working to protect the existing identity rather than evaluate the new information.&lt;/p&gt;&lt;p&gt;In other words, your brain wasn’t weighing evidence. It was defending itself from an existential threat.&lt;/p&gt;&lt;p&gt;Your brain can’t objectively evaluate challenges to identity based beliefs because doing so requires temporarily dismantling the neural architecture that defines who you are. It’s not a matter of being more rational or trying harder. The mechanism that would allow you to see the bias clearly is the same mechanism the bias has compromised.&lt;/p&gt;&lt;p&gt;Think about what this means in practice. Every time an engineer evaluates a language that isn’t “theirs,” their brain is literally working against them. They’re not just analyzing technical trade offs, they’re contemplating a version of themselves that doesn’t exist yet, that feels threatening to the version that does. The Python developer reads case studies about Go’s performance and their amygdala quietly marks each one as a threat to be neutralized. The Rust advocate looks at identical problems and their Default Mode Network constructs narratives about why “only” Rust can solve them.&lt;/p&gt;&lt;p&gt;We’re not lying. We genuinely believe our reasoning is sound. That’s what makes identity based thinking so expensive, and so invisible.&lt;/p&gt;&lt;p&gt;We call ourselves Pythonistas, Gophers, Rustaceans, we wear these labels like badges, sometimes we even wear literal badges (t-shirts, stickers, etc). There’s a reason so many of our surnames come from people’s crafts: Potter, Smith, Brewer. What we do becomes who we are. What looks like decorative labels are really decision making frameworks that operate beneath conscious thought.&lt;/p&gt;&lt;p&gt;We’ve built our entire industry around the visible conversation. We train engineers to debate technical merits. We create decision frameworks based on feature matrices. We think if we just gather enough benchmarks and case studies, we’ll make the right choice.&lt;/p&gt;&lt;p&gt;But the invisible conversation is much stronger. It’s why my CTO chose Perl. It’s why that VP chose Rust. And it’s operating in your next language decision right now, invisible and unexamined.&lt;/p&gt;&lt;p&gt;The moment you hire a Rust developer to evaluate languages, you’ve already chosen Rust. You’ve just added a $2 million feasibility study to make the predetermined decision feel rational.&lt;/p&gt;&lt;p&gt;The question isn’t whether this bias exists, the science is conclusive. The real question is: can you afford to let it make your decisions?&lt;/p&gt;&lt;p&gt;Because the invisible conversation has a price tag. Industry research suggests that technology stack decisions account for 40-60% of total development costs over a product’s lifecycle. Research by Stripe found that developers spend 42% of their time on technical debt. When you let identity drive that decision you’re mortgaging your velocity, your budget, and your runway to pay for someone’s sense of self.&lt;/p&gt;&lt;p&gt;The visible conversation is about technology. The invisible conversation is about identity. And the invisible conversation always wins.&lt;/p&gt;&lt;p&gt;So how do we win, when the invisible conversation is constantly working against us? Change the conversation entirely.&lt;/p&gt;&lt;p&gt;Instead of asking “which language is best?” we need to ask “what is this language going to cost us?” Not just in salaries, but in velocity, in technical debt, in hiring difficulty, in operational complexity, in every dimension that actually determines whether you survive.&lt;/p&gt;&lt;p&gt;Reframe it from a technical debate to an economic one. And unlike identity, economics can be measured, compared, and decided without anyone’s ego being threatened.&lt;/p&gt;&lt;p&gt;Choosing a programming language is the single most expensive economic decision your company will make. It will define your culture, constrain your budget, determine your hiring pipeline, set your operational costs, and ultimately dictate whether you can move fast enough to win your market.&lt;/p&gt;&lt;p&gt;We need a framework that makes the invisible costs visible. One that lets us have the economic conversation instead of the identity conversation. One that works whether you’re choosing your first language or evaluating a migration.&lt;/p&gt;&lt;p&gt;Our industry has never really had that framework&amp;amp;mldr; Until now.&lt;/p&gt;&lt;p&gt;Up Next&lt;/p&gt;In my next post, I’ll introduce the 9 Factors of a Language’s True Cost: a comprehensive framework for evaluating language decisions based on economics, not identity. You’ll learn how to quantify the hidden costs, predict long term impact, and make defensible decisions that your team can align behind, regardless of their language preferences.&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45801416</guid><pubDate>Mon, 03 Nov 2025 17:08:22 +0000</pubDate></item><item><title>Israels top military lawyer arrested after she admitted leaking video of abuse</title><link>https://www.theguardian.com/world/2025/nov/03/israels-top-military-lawyer-arrested-after-she-admitted-leaking-video-of-soldiers-abuse</link><description>&lt;doc fingerprint="ebc08abb8040fad1"&gt;
  &lt;main&gt;
    &lt;p&gt;Police in Israel have arrested and detained the military’s top legal officer after she admitted leaking footage of soldiers allegedly attacking a Palestinian detainee and then in effect lying about her actions to Israel’s high court.&lt;/p&gt;
    &lt;p&gt;The military advocate general, Yifat Tomer-Yerushalmi, said in a resignation letter last week that she had authorised publication of the video to defuse attacks on military investigators and prosecutors working on the case.&lt;/p&gt;
    &lt;p&gt;Rightwing politicians and pundits championed soldiers detained over the case as “heroes”, attacked military investigators as traitors, and called for the case against the soldiers to be dropped.&lt;/p&gt;
    &lt;p&gt;Tomer-Yerushalmi has now been arrested on suspicion of fraud and breach of trust, abuse of office, obstruction of justice, and disclosure of official information by a public servant, Israeli media reported.&lt;/p&gt;
    &lt;p&gt;Her arrest and detention raises serious questions about the rule of law in Israel, accountability for abuse and killing of Palestinians during what a UN commission has called a genocidal war, and the country’s ability to defend itself in international courts.&lt;/p&gt;
    &lt;p&gt;In July 2024 prosecutors raided the Sde Teiman military detention centre, which has become notorious for torture, and detained 11 soldiers for interrogation.&lt;/p&gt;
    &lt;p&gt;They were suspects in a violent assault on a Palestinian from Gaza, including anal rape. The victim was hospitalised with injuries including broken ribs, a punctured lung and rectal damage, according to the indictment, and Tomer-Yerushalmi launched an investigation.&lt;/p&gt;
    &lt;p&gt;The government and far-right politicians and pundits have accused her of damaging Israel’s global standing by pursing the case and releasing the video, in effect casting her efforts to prosecute extreme violence as a project to undermine the state.&lt;/p&gt;
    &lt;p&gt;“The incident in Sde Teiman caused immense damage to the image of the state of Israel and the IDF [Israel Defense Forces],” the Israeli prime minister, Benjamin Netanyahu, said in a statement on Sunday. “This is perhaps the most severe public relations attack that the state of Israel has experienced since its establishment.”&lt;/p&gt;
    &lt;p&gt;After the first detentions of soldiers in the case in summer 2024, a far-right mob gathered outside Sde Teiman calling for the investigation to be dropped. Some of the protesters – including a minister and two members of the Knesset – broke into the base.&lt;/p&gt;
    &lt;p&gt;Tomer-Yerushalmi leaked the video in August 2024 after the protests, saying in her resignation letter that it was “an attempt to debunk false propaganda against army law enforcement bodies”.&lt;/p&gt;
    &lt;p&gt;Days later, five soldiers were charged with aggravated abuse and causing serious bodily harm. They have not been named and are currently not in custody or under any legal restrictions, Israeli media reported.&lt;/p&gt;
    &lt;p&gt;Tomer-Yerushalemi subsequently refused to open or advance investigations into other cases of possible war crimes by the Israeli military, because of the pressure of public attacks over the case, Haaretz reported.&lt;/p&gt;
    &lt;p&gt;There has been only one conviction of an Israeli soldier for assaulting Palestinians in detention during the war, although widespread torture and abuse have been documented in Israel’s jail system, and dozens of Palestinians have died in captivity.&lt;/p&gt;
    &lt;p&gt;No soldiers have been charged for killing civilians in Gaza, even after high-profile attacks that prompted international outrage, including the killing of paramedics and strikes on a team from the World Central Kitchen charity. Tens of thousands of Palestinian civilians in Gaza have been killed in attacks and airstrikes over two years.&lt;/p&gt;
    &lt;p&gt;Attacks on Tomer-Yerushalemi over the Sde Teiman affair intensified in recent days amid reports that she was responsible for leaking the video. There were official demands for her to step down and personal threats online, even after she announced her resignation.&lt;/p&gt;
    &lt;p&gt;The campaign briefly halted on Sunday afternoon amid fears for her life, after her partner reported her missing to the police and her car was found empty at a beach in the Tel Aviv area with a note inside, Israeli media reported.&lt;/p&gt;
    &lt;p&gt;Then she was found, and within minutes the attacks resumed. The far-right commentator Yinon Magal posted on X, “we can proceed with the lynching”, adding a winking emoji.&lt;/p&gt;
    &lt;p&gt;Soon after, protesters had gathered outside her house, Israeli media reported, shouting slogans including “we will give you no peace”. The defence minister, Israel Katz, later accused her of “spreading blood libels”.&lt;/p&gt;
    &lt;p&gt;Traditionally Israel’s government and military have considered the existence of an independent judiciary a crucial barrier to international legal tribunals investigating Israel for alleged abuses against Palestinians.&lt;/p&gt;
    &lt;p&gt;Where there is a robust national legal system willing and able to investigate and prosecute crimes, international courts are less likely to have jurisdiction to intervene.&lt;/p&gt;
    &lt;p&gt;“Don’t they understand we had no choice? That the only way to address the wave of international legal proceedings is by proving we can investigate ourselves?” the investigative reporter Ronen Bergman quoted the advocate general telling colleagues six weeks ago, in a report for Yedioth Ahronoth newspaper.&lt;/p&gt;
    &lt;p&gt;In recent decades many Israelis have seen the role of the military advocate general “as protecting soldiers from prosecution abroad”, said Prof Yagil Levy, head of the Institute for the Study of Civil-Military Relations at Israel’s Open University.&lt;/p&gt;
    &lt;p&gt;“In other words, the law is not upheld as a value in itself, but as a defence against international tribunals.”&lt;/p&gt;
    &lt;p&gt;Now even such legal pragmatism is under attack by the political right, whose influence can be seen in the lack of legal accountability for soldiers’ conduct in Gaza over the past two years, Levy added.&lt;/p&gt;
    &lt;p&gt;“During the war, the advocate general gave the army a free hand in Gaza, for example, regarding the unprecedented collateral damage from airstrikes,” he said.&lt;/p&gt;
    &lt;p&gt;“This reflects a far weaker commitment to international law, with some on the right claiming that Israel is exempt from respecting it, and even providing religious justifications for this view.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45801673</guid><pubDate>Mon, 03 Nov 2025 17:28:58 +0000</pubDate></item><item><title>The Case That A.I. Is Thinking</title><link>https://www.newyorker.com/magazine/2025/11/10/the-case-that-ai-is-thinking</link><description>&lt;doc fingerprint="2f41991cbdb78dfb"&gt;
  &lt;main&gt;
    &lt;p&gt;Dario Amodei, the C.E.O. of the artificial-intelligence company Anthropic, has been predicting that an A.I. “smarter than a Nobel Prize winner” in such fields as biology, math, engineering, and writing might come online by 2027. He envisions millions of copies of a model whirring away, each conducting its own research: a “country of geniuses in a datacenter.” In June, Sam Altman, of OpenAI, wrote that the industry was on the cusp of building “digital superintelligence.” “The 2030s are likely going to be wildly different from any time that has come before,” he asserted. Meanwhile, the A.I. tools that most people currently interact with on a day-to-day basis are reminiscent of Clippy, the onetime Microsoft Office “assistant” that was actually more of a gadfly. A Zoom A.I. tool suggests that you ask it “What are some meeting icebreakers?” or instruct it to “Write a short message to share gratitude.” Siri is good at setting reminders but not much else. A friend of mine saw a button in Gmail that said “Thank and tell anecdote.” When he clicked it, Google’s A.I. invented a funny story about a trip to Turkey that he never took.&lt;/p&gt;
    &lt;p&gt;The rushed and uneven rollout of A.I. has created a fog in which it is tempting to conclude that there is nothing to see here—that it’s all hype. There is, to be sure, plenty of hype: Amodei’s timeline is science-fictional. (A.I. models aren’t improving that fast.) But it is another kind of wishful thinking to suppose that large language models are just shuffling words around. I used to be sympathetic to that view. I sought comfort in the idea that A.I. had little to do with real intelligence or understanding. I even celebrated its shortcomings—rooting for the home team. Then I began using A.I. in my work as a programmer, fearing that if I didn’t I would fall behind. (My employer, a trading firm, has several investments in and partnerships with A.I. companies, including Anthropic.) Writing code is, by many accounts, the thing that A.I. is best at; code has more structure than prose does, and it’s often possible to automatically validate that a given program works. My conversion was swift. At first, I consulted A.I. models in lieu of looking something up. Then I gave them small, self-contained problems. Eventually, I gave them real work—the kind I’d trained my whole career to do. I saw these models digest, in seconds, the intricate details of thousands of lines of code. They could spot subtle bugs and orchestrate complex new features. Finally, I was transferred to a fast-growing team that aims to make better use of A.I. tools, and to create our own.&lt;/p&gt;
    &lt;p&gt;The science-fiction author William Gibson is said to have observed that the future is already here, just not evenly distributed—which might explain why A.I. seems to have minted two cultures, one dismissive and the other enthralled. In our daily lives, A.I. “agents” that can book vacations or file taxes are a flop, but I have colleagues who compose much of their code using A.I. and sometimes run multiple coding agents at a time. Models sometimes make amateur mistakes or get caught in inane loops, but, as I’ve learned to use them effectively, they have allowed me to accomplish in an evening what used to take a month. Not too long ago, I made two iOS apps without knowing how to make an iOS app.&lt;/p&gt;
    &lt;p&gt;I once had a boss who said that a job interview should probe for strengths, not for the absence of weaknesses. Large language models have many weaknesses: they famously hallucinate reasonable-sounding falsehoods; they can be servile even when you’re wrong; they are fooled by simple puzzles. But I remember a time when the obvious strengths of today’s A.I. models—fluency, fluidity, an ability to “get” what someone is talking about—were considered holy grails. When you experience these strengths firsthand, you wonder: How convincing does the illusion of understanding have to be before you stop calling it an illusion?&lt;/p&gt;
    &lt;p&gt;On a brutally hot day this summer, my friend Max met up with his family at a playground. For some reason, a sprinkler for kids was switched off, and Max’s wife had promised everyone that her husband would fix it. Confronted by red-faced six- and seven-year-olds, Max entered a utility shed hoping to find a big, fat “On” switch. Instead, he found a maze of ancient pipes and valves. He was about to give up when, on a whim, he pulled out his phone and fed a photo into ChatGPT-4o, along with a description of his problem. The A.I. thought for a second, or maybe didn’t think, but all the same it said that he was looking at a backflow-preventer system typical of irrigation setups. Did he see that yellow ball valve toward the bottom? That probably controlled the flow. Max went for it, and cheers rang out across the playground as the water turned on.&lt;/p&gt;
    &lt;p&gt;Was ChatGPT mindlessly stringing words together, or did it understand the problem? The answer could teach us something important about understanding itself. “Neuroscientists have to confront this humbling truth,” Doris Tsao, a neuroscience professor at the University of California, Berkeley, told me. “The advances in machine learning have taught us more about the essence of intelligence than anything that neuroscience has discovered in the past hundred years.” Tsao is best known for decoding how macaque monkeys perceive faces. Her team learned to predict which neurons would fire when a monkey saw a specific face; even more strikingly, given a pattern of neurons firing, Tsao’s team could render the face. Their work built on research into how faces are represented inside A.I. models. These days, her favorite question to ask people is “What is the deepest insight you have gained from ChatGPT?” “My own answer,” she said, “is that I think it radically demystifies thinking.”&lt;/p&gt;
    &lt;p&gt;The most basic account of how we got here goes something like this. In the nineteen-eighties, a small team of cognitive psychologists and computer scientists tried to simulate thinking in a machine. Among the more famous of them were David Rumelhart, Geoffrey Hinton, and James McClelland, who went on to form a research group at U.C. San Diego. They saw the brain as a vast network in which neurons fire in patterns, causing other sets of neurons to fire, and so on; this dance of patterns is thinking. The brain learns by changing the strength of the connections between neurons. Crucially, the scientists mimicked this process by creating an artificial neural network, and by applying a simple algorithm called gradient descent to increase the accuracy of its predictions. (The algorithm could be compared to a hiker navigating from a mountaintop to a valley; a simple strategy for eventually finding one’s way is to insure that every step moves downhill.) The use of such algorithms in large networks is known as deep learning.&lt;/p&gt;
    &lt;p&gt;Other people in A.I. were skeptical that neural networks were sophisticated enough for real-world tasks, but, as the networks got bigger, they began to solve previously unsolvable problems. People would devote entire dissertations to developing techniques for distinguishing handwritten digits or for recognizing faces in images; then a deep-learning algorithm would digest the underlying data, discover the subtleties of the problem, and make those projects seem obsolete. Deep learning soon conquered speech recognition, translation, image captioning, board games, and even the problem of predicting how proteins will fold.&lt;/p&gt;
    &lt;p&gt;Today’s leading A.I. models are trained on a large portion of the internet, using a technique called next-token prediction. A model learns by making guesses about what it will read next, then comparing those guesses to whatever actually appears. Wrong guesses inspire changes in the connection strength between the neurons; this is gradient descent. Eventually, the model becomes so good at predicting text that it appears to know things and make sense. So that is something to think about. A group of people sought the secret of how the brain works. As their model grew toward a brain-like size, it started doing things that were thought to require brain-like intelligence. Is it possible that they found what they were looking for?&lt;/p&gt;
    &lt;p&gt;There is understandable resistance to such a simplistic and triumphant account of A.I. The case against it was well argued by Ted Chiang, who wrote an article for this magazine in early 2023 titled “ChatGPT Is a Blurry JPEG of the Web.” He meant it in a more or less deflationary way: that’s all ChatGPT is. You feed the whole internet to a program and it regurgitates it back to you imperfectly, like a copy of a copy of a photograph—but with just enough facility to fool you into believing that the program is intelligent. This spring, a similar argument was made in a book, “The AI Con,” by Emily M. Bender, a linguist, and Alex Hanna, a sociologist. Bender is perhaps best known for describing L.L.M.s as “stochastic parrots.” “Large language models do not, cannot, and will not ‘understand’ anything at all,” the writer Tyler Austin Harper declared in a book review in The Atlantic. Models “produce writing not by thinking but by making statistically informed guesses about which lexical item is likely to follow another.” Harper buttressed these technical arguments with moral ones. A.I. enriches the powerful, consumes enough energy to accelerate climate change, and marginalizes workers. He concluded that “the foundation of the AI industry is a scam.”&lt;/p&gt;
    &lt;p&gt;But the moral case against A.I. may ultimately be stronger than the technical one. “The ‘stochastic parrot’ thing has to be dead at some point,” Samuel J. Gershman, a Harvard cognitive scientist who is no A.I. hype man, told me. “Only the most hardcore skeptics can deny these systems are doing things many of us didn’t think were going to be achieved.” Jonathan Cohen, a cognitive neuroscientist at Princeton, emphasized the limitations of A.I., but argued that, in some cases, L.L.M.s seem to mirror one of the largest and most important parts of the human brain. “To a first approximation, your neocortex is your deep-learning mechanism,” Cohen said. Humans have a much larger neocortex than other animals, relative to body size, and the species with the largest neocortices—elephants, dolphins, gorillas, chimpanzees, dogs—are among the most intelligent.&lt;/p&gt;
    &lt;p&gt;In 2003, the machine-learning researcher Eric B. Baum published a book called “What Is Thought?” (I stumbled upon it in my college’s library stacks, drawn by the title.) The gist of Baum’s argument is that understanding is compression, and compression is understanding. In statistics, when you want to make sense of points on a graph, you can use a technique called linear regression to draw a “line of best fit” through them. If there’s an underlying regularity in the data—maybe you’re plotting shoe size against height—the line of best fit will efficiently express it, predicting where new points could fall. The neocortex can be understood as distilling a sea of raw experience—sounds, sights, and other sensations—into “lines of best fit,” which it can use to make predictions. A baby exploring the world tries to guess how a toy will taste or where food will go when it hits the floor. When a prediction is wrong, the connections between neurons are adjusted. Over time, those connections begin to capture regularities in the data. They form a compressed model of the world.&lt;/p&gt;
    &lt;p&gt;Artificial neural networks compress experience just like real neural networks do. One of the best open-source A.I. models, DeepSeek, is capable of writing novels, suggesting medical diagnoses, and sounding like a native speaker in dozens of languages. It was trained using next-token prediction on many terabytes of data. But when you download the model it is one six-hundredth of that. A distillation of the internet, compressed to fit on your laptop. Ted Chiang was right to call an early version of ChatGPT a blurry JPEG of the web—but, in my view, this is the very reason these models have become increasingly intelligent. Chiang noted in his piece that, to compress a text file filled with millions of examples of arithmetic, you wouldn’t create a zip file. You’d write a calculator program. “The greatest degree of compression can be achieved by understanding the text,” he wrote. Perhaps L.L.M.s are starting to do that.&lt;/p&gt;
    &lt;p&gt;It can seem unnatural, even repulsive, to imagine that a computer program actually understands, actually thinks. We usually conceptualize thinking as something conscious, like a Joycean inner monologue or the flow of sense memories in a Proustian daydream. Or we might mean reasoning: working through a problem step by step. In our conversations about A.I., we often conflate these different kinds of thinking, and it makes our judgments pat. ChatGPT is obviously not thinking, goes one argument, because it is obviously not having a Proustian reverie; ChatGPT clearly is thinking, goes another, because it can work through logic puzzles better than you can.&lt;/p&gt;
    &lt;p&gt;Something more subtle is going on. I do not believe that ChatGPT has an inner life, and yet it seems to know what it’s talking about. Understanding—having a grasp of what’s going on—is an underappreciated kind of thinking, because it’s mostly unconscious. Douglas Hofstadter, a professor of cognitive science and comparative literature at Indiana University, likes to say that cognition is recognition. Hofstadter became famous for a book about the mind and consciousness called “Gödel, Escher, Bach: An Eternal Golden Braid,” which won a Pulitzer Prize in 1980. Hofstadter’s theory, developed through decades of research, is that “seeing as” is the essence of thinking. You see one patch of color as a car and another as a key chain; you recognize the letter “A” no matter what font it is written in or how bad the handwriting might be. Hofstadter argued that the same process underlies more abstract kinds of perception. When a grand master examines a chess board, years of practice are channelled into a way of seeing: white’s bishop is weak; that endgame is probably a draw. You see an eddy in a river as a sign that it’s dangerous to cross. You see a meeting you’re in as an emperor-has-no-clothes situation. My nearly two-year-old son recognizes that late-morning stroller walks might be an opportunity for a croissant and makes demands accordingly. For Hofstadter, that’s intelligence in a nutshell.&lt;/p&gt;
    &lt;p&gt;Hofstadter was one of the original A.I. deflationists, and my own skepticism was rooted in his. He wrote that most A.I. research had little to do with real thinking, and when I was in college, in the two-thousands, I agreed with him. There were exceptions. He found the U.C.S.D. group interesting. And he admired the work of a lesser-known Finnish American cognitive scientist, Pentti Kanerva, who noticed some unusual properties in the mathematics of high-dimensional spaces. In a high-dimensional space, any two random points may be extremely far apart. But, counterintuitively, each point also has a large cloud of neighbors around it, so you can easily find your way to it if you get “close enough.” That reminded Kanerva of the way that memory works. In a 1988 book called “Sparse Distributed Memory,” Kanerva argued that thoughts, sensations, and recollections could be represented as coördinates in high-dimensional space. The brain seemed like the perfect piece of hardware for storing such things. Every memory has a sort of address, defined by the neurons that are active when you recall it. New experiences cause new sets of neurons to fire, representing new addresses. Two addresses can be different in many ways but similar in others; one perception or memory triggers other memories nearby. The scent of hay recalls a memory of summer camp. The first three notes of Beethoven’s Fifth beget the fourth. A chess position that you’ve never seen reminds you of old games—not all of them, just the ones in the right neighborhood.&lt;/p&gt;
    &lt;p&gt;Hofstadter realized that Kanerva was describing something like a “seeing as” machine. “Pentti Kanerva’s memory model was a revelation for me,” he wrote in a foreword to Kanerva’s book. “It was the very first piece of research I had ever run across that made me feel I could glimpse the distant goal of understanding how the brain works as a whole.” Every kind of thinking—whether Joycean, Proustian, or logical—depends on the relevant thing coming to mind at the right time. It’s how we figure out what situation we’re in.&lt;/p&gt;
    &lt;p&gt;Kanerva’s book receded from view, and Hofstadter’s own star faded—except when he occasionally poked up his head to criticize a new A.I. system. In 2018, he wrote of Google Translate and similar technologies: “There is still something deeply lacking in the approach, which is conveyed by a single word: understanding.” But GPT-4, which was released in 2023, produced Hofstadter’s conversion moment. “I’m mind-boggled by some of the things that the systems do,” he told me recently. “It would have been inconceivable even only ten years ago.” The staunchest deflationist could deflate no longer. Here was a program that could translate as well as an expert, make analogies, extemporize, generalize. Who were we to say that it didn’t understand? “They do things that are very much like thinking,” he said. “You could say they are thinking, just in a somewhat alien way.”&lt;/p&gt;
    &lt;p&gt;L.L.M.s appear to have a “seeing as” machine at their core. They represent each word with a series of numbers denoting its coördinates—its vector—in a high-dimensional space. In GPT-4, a word vector has thousands of dimensions, which describe its shades of similarity to and difference from every other word. During training, a large language model tweaks a word’s coördinates whenever it makes a prediction error; words that appear in texts together are nudged closer in space. This produces an incredibly dense representation of usages and meanings, in which analogy becomes a matter of geometry. In a classic example, if you take the word vector for “Paris,” subtract “France,” and then add “Italy,” the nearest other vector will be “Rome.” L.L.M.s can “vectorize” an image by encoding what’s in it, its mood, even the expressions on people’s faces, with enough detail to redraw it in a particular style or to write a paragraph about it. When Max asked ChatGPT to help him out with the sprinkler at the park, the model wasn’t just spewing text. The photograph of the plumbing was compressed, along with Max’s prompt, into a vector that captured its most important features. That vector served as an address for calling up nearby words and concepts. Those ideas, in turn, called up others as the model built up a sense of the situation. It composed its response with those ideas “in mind.”&lt;/p&gt;
    &lt;p&gt;A few months ago, I was reading an interview with an Anthropic researcher, Trenton Bricken, who has worked with colleagues to probe the insides of Claude, the company’s series of A.I. models. (Their research has not been peer-reviewed or published in a scientific journal.) His team has identified ensembles of artificial neurons, or “features,” that activate when Claude is about to say one thing or another. Features turn out to be like volume knobs for concepts; turn them up and the model will talk about little else. (In a sort of thought-control experiment, the feature representing the Golden Gate Bridge was turned up; when one user asked Claude for a chocolate-cake recipe, its suggested ingredients included “1/4 cup dry fog” and “1 cup warm seawater.”) In the interview, Bricken mentioned Google’s Transformer architecture, a recipe for constructing neural networks that underlies leading A.I. models. (The “T” in ChatGPT stands for “Transformer.”) He argued that the mathematics at the heart of the Transformer architecture closely approximated a model proposed decades earlier—by Pentti Kanerva, in “Sparse Distributed Memory.”&lt;/p&gt;
    &lt;p&gt;Should we be surprised by the correspondence between A.I. and our own brains? L.L.M.s are, after all, artificial neural networks that psychologists and neuroscientists helped develop. What’s more surprising is that when models practiced something rote—predicting words—they began to behave in such a brain-like way. These days, the fields of neuroscience and artificial intelligence are becoming entangled; brain experts are using A.I. as a kind of model organism. Evelina Fedorenko, a neuroscientist at M.I.T., has used L.L.M.s to study how brains process language. “I never thought I would be able to think about these kinds of things in my lifetime,” she told me. “I never thought we’d have models that are good enough.”&lt;/p&gt;
    &lt;p&gt;It has become commonplace to say that A.I. is a black box, but the opposite is arguably true: a scientist can probe the activity of individual artificial neurons and even alter them. “Having a working system that instantiates a theory of human intelligence—it’s the dream of cognitive neuroscience,” Kenneth Norman, a Princeton neuroscientist, told me. Norman has created computer models of the hippocampus, the brain region where episodic memories are stored, but in the past they were so simple that he could only feed them crude approximations of what might enter a human mind. “Now you can give memory models the exact stimuli you give to a person,” he said.&lt;/p&gt;
    &lt;p&gt;The Wright brothers studied birds during their early efforts to build an airplane. They noted that birds take off into the wind, even though a reasonable person might have assumed they’d want the wind at their backs, and that they warp the tips of their wings for balance. These findings influenced their rudimentary glider designs. Then they built a six-foot-long wind tunnel, which allowed them to test a set of artificial wings under precisely controlled conditions. Their next round of glider flights was far more successful. Strangely, it was only well after they’d made a working flying machine that it became possible to understand exactly how the birds do it.&lt;/p&gt;
    &lt;p&gt;A.I. enables scientists to place thinking itself in a wind tunnel. For a paper provocatively titled “On the Biology of a Large Language Model,” Anthropic researchers observed Claude responding to queries and described “circuits”—cascades of features that, together, perform complex computations. (Calling up the right memories is one step toward thinking; combining and manipulating them in circuits is arguably another.) One longstanding criticism of L.L.M.s has been that, because they must generate one token of their response at a time, they can’t plan or reason. But, when you ask Claude to finish a rhyming couplet in a poem, a circuit begins considering the last word of the new line, to insure that it will rhyme. It then works backward to compose the line as a whole. Anthropic researchers counted this as evidence that their models do engage in planning. Squint a little and you might feel, for the first time, that the inner workings of a mind are in view.&lt;/p&gt;
    &lt;p&gt;You really do have to squint, though. “The worry I have is that people flipped the bit from ‘I’m really skeptical of this’ to totally dropping their shields,” Norman, the Princeton neuroscientist, told me. “Many things still have to get figured out.” I’m one of the people that Norman is talking about. (Perhaps I am too easily moved by the seeming convergence of “Sparse Distributed Memory” and an Anthropic model.) In the past year or two, I started to believe what Geoffrey Hinton, who recently won a Nobel Prize for his A.I. research, told the journalist Karen Hao in 2020: “Deep learning is going to be able to do everything.” But we have also seen that larger models aren’t always better models. Curves plotting model performance against size have begun flattening out. It’s becoming difficult to find high-quality data that the models haven’t already digested, and computing power is increasingly expensive. When GPT-5 came out, in August, it was a merely incremental improvement—and so profound a disappointment that it threatened to pop the A.I. investment bubble. The moment demands a middle kind of skepticism: one that takes today’s A.I. models seriously without believing that there are no hard problems left.&lt;/p&gt;
    &lt;p&gt;Perhaps the most consequential of these problems is how to design a model that learns as efficiently as humans do. It is estimated that GPT-4 was exposed to trillions of words in training; children need only a few million to become fluent. Cognitive scientists tell us that a newborn’s brain has certain “inductive biases” that accelerate learning. (Of course, the brain is the result of millions of years of evolution—itself a sort of training data.) For instance, human babies have the expectation that the world is made of objects, and that other beings have beliefs and intentions. When Mama says “banana,” an infant connects that word to the entire yellow object she’s looking at—not just its tip or its peel. Infants perform little experiments: Can I eat this? How far can I throw that? They are motivated by emotions such as desire, curiosity, and frustration. Children are always trying to do something just beyond their ability. Their learning is efficient because it’s embodied, adaptive, deliberate, and continuous. Maybe truly understanding the world requires participating in it.&lt;/p&gt;
    &lt;p&gt;An A.I.’s experience, in comparison, is so impoverished that it can’t really be called “experience.” Large language models are trained on data that is already extraordinarily refined. “I think the reason they work is that they’re piggybacking on language,” Tsao, the U.C. Berkeley neuroscientist, told me. Language is like experience pre-chewed; other kinds of data are less dense with meaning. “Why is it that we haven’t had a comparable revolution in terms of reasoning about video data?” Gershman, the Harvard cognitive scientist, asked. “The kinds of vision models that we have still struggle with common-sense reasoning about physics.” A recent model from DeepMind can generate videos in which paints are mixed correctly and mazes are solved—but they also depict a glass bouncing, instead of shattering, and ropes defying physics by being smooshed into a knot. Ida Momennejad, a cognitive neuroscientist who now works for Microsoft Research, has done experiments in which an L.L.M. is given a virtual walk-through of a building and then asked questions about routes and shortcuts—spatial inferences that come easily to humans. With all but the most basic setups, the A.I.s tend to fail or hallucinate nonexistent paths. “Do they really do planning?” she said. “Not really.”&lt;/p&gt;
    &lt;p&gt;In my conversations with neuroscientists, I sensed a concern that the A.I. industry is racing ahead somewhat thoughtlessly. If the goal is to make artificial minds as capable as human minds are, then “we’re not training the systems in the right way,” Brenden M. Lake, a cognitive scientist at Princeton, told me. When an A.I. is done training, the neural network’s “brain” is frozen. If you tell the model some facts about yourself, it doesn’t rewire its neurons. Instead, it uses a crude substitute: it writes down a bit of text—“The user has a toddler and is studying French”—and considers that before other instructions you give. The human brain updates itself continuously, and there’s a beautiful theory about one of its ways of doing so: when you sleep, selected snapshots from your episodic memory are replayed for your neocortex in order to train it. Your high-dimensional thought space gets dimpled by the replayed memories; you wake up with a slightly new way of seeing.&lt;/p&gt;
    &lt;p&gt;The A.I. community has become so addicted to—and so financially invested in—breakneck progress that it sometimes pretends that advancement is inevitable and there’s no science left to do. Science has the inconvenient property of sometimes stalling out. Silicon Valley may call A.I. companies “labs,” and some employees there “researchers,” but fundamentally it has an engineering culture that does whatever works. “It’s just so remarkable how little the machine-learning community bothers looking at, let alone respects, the history and cognitive science that precedes it,” Cohen said.&lt;/p&gt;
    &lt;p&gt;Today’s A.I. models owe their success to decades-old discoveries about the brain, but they are still deeply unlike brains. Which differences are incidental and which are fundamental? Every group of neuroscientists has its pet theory. These theories can be put to the test in a way that wasn’t possible before. Still, no one expects easy answers. The problems that continue to plague A.I. models “are solved by carefully identifying ways in which the models don’t behave as intelligently as we want them to and then addressing them,” Norman said. “That is still a human-scientist-in-the-loop process.”&lt;/p&gt;
    &lt;p&gt;In the nineties, billions of dollars poured into the Human Genome Project on the assumption that sequencing DNA might solve medicine’s most vexing problems: cancer, hereditary conditions, even aging. It was a time of bluster and confidence—the era of Dolly the cloned sheep and “Jurassic Park”—when biotech was ascendant and the commentariat reckoned with whether humans should be playing God. Biologists soon found that the reality was more complicated. We didn’t cure cancer or discover the causes of Alzheimer’s or autism. We learned that DNA tells just one part of the story of life. In fact, one could argue that biology got swept up in a kind of gene fever, fixating on DNA because we had the means to study and understand it.&lt;/p&gt;
    &lt;p&gt;Still, nobody would claim that Francis Crick was wrong when, on the day in 1953 that he helped confirm the structure of DNA, he walked into a Cambridge pub talking about having discovered the secret of life. He and his colleagues did more to demystify life than almost anyone, ever. The decades following their discovery were among the most productive and exciting in the history of science. DNA became a household term; every high schooler learns about the double helix.&lt;/p&gt;
    &lt;p&gt;With A.I., we once again find ourselves in a moment of bluster and confidence. Sam Altman talks about raising half a trillion dollars to build Stargate, a new cluster of A.I. data centers, in the U.S. People discuss the race for superintelligence with a gravitas and an urgency that can seem ungrounded, even silly. But I suspect the reason that the Amodeis and Altmans of the world are making messianic pronouncements is that they believe that the basic picture of intelligence has been worked out; the rest is just details.&lt;/p&gt;
    &lt;p&gt;Even some neuroscientists believe that a crucial threshold has been crossed. “I really think it could be the right model for cognition,” Uri Hasson, a colleague of Cohen’s, Norman’s, and Lake’s at Princeton, said of neural networks. This upsets him as much as it excites him. “I have the opposite worry of most people,” he said. “My worry is not that these models are similar to us. It’s that we are similar to these models.” If simple training techniques can enable a program to behave like a human, maybe humans aren’t as special as we thought. Could it also mean that A.I. will surpass us not only in knowledge but also in judgment, ingenuity, cunning—and, as a result, power? To my surprise, Hasson told me that he is “worried these days that we might succeed in understanding how the brain works. Pursuing this question may have been a colossal mistake for humanity.” He likened A.I. researchers to nuclear scientists in the nineteen-thirties: “This is the most interesting time in the life of these people. And, at the same time, they know that what they are working on has grave implications for humanity. But they cannot stop because of the curiosity to learn.”&lt;/p&gt;
    &lt;p&gt;One of my favorite books by Hofstadter is a nerdy volume called “Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought.” When I was in college, it electrified me. The premise was that a question such as “What is thinking?” was not merely philosophical but, rather, had a real answer. In 1995, when the book was published, Hofstadter and his research group could only gesture at what the answer might be. Thinking back on the book, I wondered whether Hofstadter would feel excited that A.I. researchers may have attained what he had yearned for: a mechanical account of the rudiments of thinking. When we spoke, however, he sounded profoundly disappointed—and frightened. Current A.I. research “confirms a lot of my ideas, but it also takes away from the beauty of what humanity is,” he told me. “When I was younger, much younger, I wanted to know what underlay creativity, the mechanisms of creativity. That was a holy grail for me. But now I want it to remain a mystery.” Perhaps the secrets of thinking are simpler than anyone expected—the kind of thing that a high schooler, or even a machine, could understand. ♦&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45802029</guid><pubDate>Mon, 03 Nov 2025 17:55:10 +0000</pubDate></item><item><title>Gallery of wonderful drawings our little thermal printer received</title><link>https://guestbook.goodenough.us</link><description>&lt;doc fingerprint="59d03e8ff57de69d"&gt;
  &lt;main&gt;
    &lt;p&gt;Back to GoodEnough.us This is a gallery of all the wonderful drawings our little printer received. Draw us something! Rene The Robot (Self Portrait) December 10, 2024 172.70.115.89 imthatwhodrawthis December 1, 2024 162.158.79.18 Dan C. November 27, 2024 108.162.216.235 Florian November 26, 2024 162.158.78.234 Kabir Kumar November 20, 2024 172.69.194.121 Charmaine ツ November 20, 2024 172.69.6.8 Rafael Enes November 20, 2024 172.68.102.237 (.❛ ᴗ ❛.) November 19, 2024 172.70.135.108 Lu November 19, 2024 162.158.78.231 werty November 18, 2024 108.162.216.131 Daniel November 18, 2024 108.162.216.130 dz November 16, 2024 162.158.79.62 MAx from Rennes (France) November 16, 2024 162.158.79.28 Jake November 16, 2024 162.158.78.249 Time + Pressure = Diamonds November 10, 2024 162.158.146.55 Sofia October 27, 2024 162.158.78.184 Ka Wai October 24, 2024 108.162.216.150 Francis October 24, 2024 162.158.79.146 ZEEP ZORP October 23, 2024 162.158.78.135 Jesse Cooke October 23, 2024 108.162.216.236 Alberto Gallwgo October 23, 2024 172.71.222.163 Loading more choice prints...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45802459</guid><pubDate>Mon, 03 Nov 2025 18:27:32 +0000</pubDate></item><item><title>Is the Internet Making Culture Worse?</title><link>https://asteriskmag.com/issues/12-books/is-the-internet-making-culture-worse</link><description>&lt;doc fingerprint="32e091352a730739"&gt;
  &lt;main&gt;
    &lt;p&gt;The decline of criticism might explain the sense that our culture is stagnating. How can we bring it back?&lt;/p&gt;
    &lt;p&gt;I don’t remember reading any great novels in the ‘90s. Or listening to any good albums, either. It’s not the decade’s fault, it’s mine: I was born in 1993. By the time I could read books and choose my own music, things were already going downhill. The 20th century, apparently, was the last time we had great art, literature, or music. Although the current century was meant to be a Cambrian explosion of creativity — inaugurated by the internet, or the creator economy, or NFTs, or AI — nothing has gotten better, only worse.&lt;/p&gt;
    &lt;p&gt;That’s the argument, at least, of W. David Marx’s comprehensively pessimistic Blank Space: A Cultural History of the Twenty-First Century. The Tokyo-based writer’s first book, Ametora, was a cultural history of Japanese Americana fashion; his second, Status and Culture, was a bold — and largely successful — attempt to synthesize the entire discipline of sociology into an explanation of how taste develops. His latest book, in ambition and scope, is somewhere in between. Art made in the first quarter of the 21st century, Marx argues, has been largely unimpressive. “There have been fewer cultural inventors,” he writes, and although “the culture industry” and “online creators are producing more content than ever … the most radical forms of cultural invention have become scarce.”&lt;/p&gt;
    &lt;p&gt;Consider the 20th century’s abundance of avant-garde art movements (from fauvism to expressionism) and innovative pop genres (punk, prog rock, synth pop, rap). This century, Marx argues, has failed to achieve the same heights. Despite new technologies and platforms to discover, create, and circulate work, the internet has led to “mediocrity,” not artistic innovation. The web was meant to help long tail artists gain an audience for niche, experimental work and make a living from their 1,000 true fans. Instead, attention has accrued to a minority of major players, who, under the reign of poptimism, are celebrated for pursuing commercial success. In Marx’s history of American pop culture, which places heavy emphasis on media, music, and fashion, with glancing mentions of literature, art, and dance, a theme emerges: Everyone is selling out or trying their best to. Craven commercialism has replaced creativity. Culture has become “a vehicle for entertainment, politics, and profiteering — but at the expense of pure artistic innovation.”&lt;/p&gt;
    &lt;p&gt;I liked Blank Space, which zips through notable names and scandals — from Ezra Klein to “Elsagate,” Buzzfeed to BTS, Stüssy to Stewart Brand — with remarkable alacrity. Any book that takes aim at other people (for their bad taste and pedestrian art) often encourages a feeling of smug satisfaction in the reader. But I couldn’t decide if I actually agreed with Marx. Is contemporary culture actually worse than that of the past? Consider that when the music critic Simon Reynolds, in his 2010 book Retromania, argued that contemporary pop was merely remixing, recycling, and exhausting the past, the critic Sara Marcus observed that Reynold’s thesis “has several fundamental problems, beginning with his blatant disregard of the First Law of Pop Thermodynamics: No music will ever matter as much as the stuff you loved at 16.”&lt;/p&gt;
    &lt;p&gt;Did that mean that Blank Space’s argument was wrong? Because I did feel cheated out of a utopian future. I was promised free information, great art, and a four-day work week to appreciate it. Instead, what I had was a profound feeling of generational FOMO. Other people’s stories of the 20th century gave me the distinct feeling that the artists and writers of the past were immersed in an invigorating artistic and intellectual scene, one that led to real stars. The present, with its deluge of social media personalities, doesn’t quite hold up.&lt;/p&gt;
    &lt;p&gt;The problem with diagnoses of cultural decline, however, is that they tend to be based on vibes. The art just looks worse. The music just sounds worse. Subjective judgments are often the only way to distinguish between good art and bad, but they don’t feel satisfying. I wasn’t entirely convinced by Marx’s approach, which defies nominative determinism by not being particularly, well, Marxist. Blank Space doesacknowledge structural shifts across industries and how neoliberal economic policies have reshaped the global economy, but it largely blames the ostensible decline in art closer to home, on the “mutual expectations” we have of each other. We’ve rejected hierarchies of taste and commercial success over artistic integrity.&lt;/p&gt;
    &lt;p&gt;To decide whether I agreed with Blank Space, I found myself reaching for a technique from the other Marx: historical materialism. What social and economic conditions helped produce great work in the 20th century? And what changed that could have made things worse?&lt;/p&gt;
    &lt;p&gt;Artists, critics, and artist-critics&lt;/p&gt;
    &lt;p&gt;A few years ago, a lifelong interest in books led me to moonlight as a literary critic — waking up at 5 a.m. to draft book reviews, going to my day job as a software designer, and then editing in the evenings. As side projects go, it was one of the most financially unremunerative things I could have done. Intellectually, it was the most invigorating activity I could imagine.&lt;/p&gt;
    &lt;p&gt;Critics are often seen as peevish, elite aesthetes responsible for judging books as good or bad. But the reviews I admired most and sought to write eschewed simple star ratings. Instead, they examined books with more attention, insight, and generosity — situating them in a broader social and artistic context. “Criticism has some inextricable relationship with judgment,” the art professor Alex Kitnick observed, “but perhaps more importantly, it opens up a space for complexity.”&lt;/p&gt;
    &lt;p&gt;When I came across Chaim Gingold’s book, Building SimCity: How to Put the World in a Machine, I knew I had to write about it. For years, I had felt that good writing about software was thin on the ground. In most narratives, software was made by singular boy geniuses or oblivious villains. It was rarely portrayed as a creative act or a social pursuit involving teams of thinkers, makers, engineers, and designers.&lt;/p&gt;
    &lt;p&gt;By the time my review was published — a 3,500-word essay that drew connections between Building SimCity, Silicon Valley’s favorite anthropology book, Seeing Like a State, and a controversial citybuilding project in California — I had spent upwards of 40 hours on the review. I was gratified when I received an email from Gingold expressing his appreciation.&lt;/p&gt;
    &lt;p&gt;I began to think that the role of a critic is also a relational one: If someone has spent years of their life on a work, they deserve a serious, sustained response. Critics who write such reviews aren’t just offering something to the maker of a work but to the world. Look here, a critic says. Imagine what culture could be like — if there was more of, less of, a certain tendency towards, a turn away from, a movement that looked like: this.&lt;/p&gt;
    &lt;p&gt;Critics need these idealistic, lofty reasons for what they do because the economics of the profession are disastrously bad. Los Angeles Review of Books paid me $100 for my review; I’ve never gotten more than $600 from a publication. “As far as I can tell,” the journalist and critic Adam Morgan wrote in the September issue of World Literature Today, “there are only seven full-time book critics left in the United States.” If you’re reading a review of an art exhibition, album, or novel, the writer was likely paid less than minimum wage for their time. In this profession, other work (or other people) pay the rent. “The truth,” the critic and novelist Christine Smallwood writes, is that&lt;/p&gt;
    &lt;p&gt;people who do this quite insane and marginal thing of writing criticism do it because they have a passionate attachment to literature. There’s little money or power in it, and no fame. Writing book reviews today is a vocation, not a career.&lt;/p&gt;
    &lt;p&gt;But is the financial viability of criticism a problem for anyone except critics? For authors, perhaps: Fewer publications, with fewer full-time staff and less budget for freelancers, adds up to fewer reviews. This is bad news for debut novelists, who are pushed to be writers and social media experts to bring their work to an audience. And it’s bad news, I’d argue, if we care about cultural dynamism and artistic innovation.&lt;/p&gt;
    &lt;p&gt;It’s obvious that artistic movements need artists. My claim is that they also need critics. Critics help name, describe, and contextualize movements. They historicize artists — to reveal what is novel and innovative — and make a persuasive case for what work will be important in the future. Critics, in short, tell the story of how art and culture have changed over time, and how it’s changing now. And without a compelling story, culture stagnates and wanes.&lt;/p&gt;
    &lt;p&gt;Critics played a key role in two significant artistic movements of the 20th century: Abstract Expressionism and French New Wave cinema. After WWII, a generation of artists, including Jackson Pollock, Lee Krasner, Willem de Kooning, and Arshile Gorky, benefitted from cheap Manhattan rent and generous state funding: The Federal Art Project kept artists employed during the Great Depression, and veterans could use the GI Bill to pay for art school. While they also worked, the critic Clement Greenberg wrote, arguing that American painters — not European oneswere at the cutting edge of art. The AbEx movement also benefited from artist-critics like Elaine de Kooning, a painter (and wife of Willem de Kooning) who reviewed the works of Pollock, Gorsky, and other influential artists in the scene. Criticism, in the case of Greenberg and Elaine de Kooning, did not emerge out of antagonism, but from affectionate affinity.&lt;/p&gt;
    &lt;p&gt;But even aggression had artistic value: When the film magazine Cahiers du Cinéma was founded in Paris in 1951, its writers were young, idealistic, and savage. One, François Truffaut, became known as “the gravedigger” for his excoriation of French filmmakers. But criticism, as Emilie Bickerton noted in her history of the magazine,gave him and others “an education in how to make films … Writing forced them to ask, and answer, how a director employed various techniques to his own unique ends.” Eight years after the first issue of Cahiers, Truffaut won “Best Director” at Cannes for his own debut film. Today, Truffaut and his French New Wave peers — Claude Chabrol, Jean-Luc Godard, Jacques Rivette, and Éric Rohmer, who each wrote for Cahiers — testify to the thin line separating the critic from the artist. As A.O. Scott observed in Better Living Through Criticism, “Every writer is a reader, every musician a listener, driven by a desire to imitate, to correct, to improve, or to answer the models before them.” Instead of the accusation that “All critics are failed artists,” it may be more correct to say that “All art is successful criticism.”&lt;/p&gt;
    &lt;p&gt;At this point, I’d like to return to our original question — is artistic and cultural innovation really in decline? — and propose a hypothesis. While great artworks can be produced in isolation, art movements — which organize disparate works into coherent scenes and sensibilities — are what contribute to a feeling of progress. If we assume that innovation can be measured by new artistic movements, and those movements are facilitated by a critical culture, then a weakened critical ecosystem will lead to the “blank space” that W. David Marx describes, where art and culture feel stagnant.&lt;/p&gt;
    &lt;p&gt;This is, as it turns out, exactly what happened in the last decade of the 20th century, with lasting repercussions in the 21st. A useful case study here is the Village Voice, an influential alt-weekly newspaper whose history reveals what a healthy critical culture can do — and what happens when it’s gone.&lt;/p&gt;
    &lt;p&gt;The Bell Labs of cultural criticism&lt;/p&gt;
    &lt;p&gt;When the psychologist Ed Fancher, the WWII vet Dan Wolf, and the novelist Norman Mailer founded the Village Voice in 1955, they knew little about journalism or how to run a newspaper. The first issue was bootstrapped from their savings and published out of a two-bedroom apartment in Greenwich Village. Despite frequent changes in ownership and leadership, its writers — who were given generous editorial freedom and substantially less generous fees — made it one of the most influential alternative weekly newspapers of the 20th century.&lt;/p&gt;
    &lt;p&gt;For those who missed the heyday of the newspaper, the best way to learn more is Tricia Romano’s The Freaks Came Out to Write: The Definitive History of the Village Voice. It’s a who’s who of influential writers and figures — including many of the critics that first inspired me, like Peter Schjeldahl, Vivian Gornick, and Lynn Yaeger. It seemed improbable that all of these stars had worked in the same place! It also reminded me of another intellectual powerhouse.&lt;/p&gt;
    &lt;p&gt;The Village Voice was, essentially, the Bell Labs of cultural criticism. Both institutions were founded in New York City: Bell Labs in 1925, the Village Voice in 1955. Both were tremendously innovative in their respective fields: The researchers at Bell Labs invented the transistor, the programming language C, UNIX, and the discipline of information theory. The editors and writers of the Voice, meanwhile, were early advocates of influential musical genres (rock music, disco, hip-hop) and ideas (auteur theory in film) — all in the pioneering style of New Journalism, where literary techniques were used to produce criticism and reportage steeped in subjective experience. Alt-weeklies like the Voice, observed its former executive editor Kit Rachlis, showed that “writing about culture was an extraordinarily important thing … to cover, write about, report on, think about, analyze.” And the Voice’s writers weren’t just tastemakers; they also shaped the American political landscape, covering Trump’s early property dealings, judicial corruption, the nascent feminist movement, the AIDS crisis, and ACT UP.&lt;/p&gt;
    &lt;p&gt;What made the Voice so influential? There were two key elements: talented people with distinctive perspectives on art and a culture that departed from the staid norms of other publications. Some of the earliest employees came from nontraditional backgrounds. Mary Perot Nichols was a Greenwich Village housewife, mother, and neighborhood activist when she asked Dan Wolf (one of the Voice’s founding editors) if anyone was going to cover Robert Moses’s plans for Washington Square Park. “You write about it,” he said. Her column, “Runnin’ Scared,” exerted a major influence on city politics, and it made her one of Moses’s most formidable antagonists — even though the copy she turned in, Wolf once complained to a colleague, was “unreadable.” (Nichols was also friends with Moses’s other opponents; she and Jane Jacobs often brought their children to the park together, and she helped a young Robert Caro, who was struggling to break a major story about Moses, obtain access to the city planner’s files.)&lt;/p&gt;
    &lt;p&gt;Editors played an essential role in finding and nurturing talent. The newspaper’s philosophy, said Richard Goldstein, who joined in 1966 and later became executive editor, was that&lt;/p&gt;
    &lt;p&gt;you do not hire an expert; you hire someone who is living through the phenomenon worth covering … A lot of the people I hired were effectively amateurs as writers but had amazingly interesting sensibilities and were totally attuned to the subjects they wrote about.&lt;/p&gt;
    &lt;p&gt;Editors like Robert Christgau — the self-described “dean of American rock critics,” though he was also partial to hip-hop and riot grrrl — brought iconic writers into the fold. As a student at Howard, Greg Tate looked to the Voice for its coverage of avant-garde jazz and hip-hop. Later, Christgau brought him in, and Tate became one of the most influential Black cultural critics of his generation. (His inimitable style arguably made him a peer of the artists he covered: David Bowie was a fan, and Flea, the bassist of the Red Hot Chili Peppers, reportedly broke down in tears after reading Tate’s positive review of the rock band’s Californification.) Christgau managed to “defy the illogic of white supremacy in publishing,” Tate says in Romano’s book, of “We can’t find any qualified Black people.” Christgau “just seemed to trip over them anywhere he went.” Though the Voice’s record on race wasn’t perfect, it was often ahead of other publications. It was, according to the playwright and journalist Lisa Jones, “the most important news organization” in the ‘90s to incubate Black writers and give them space to write about Black culture.&lt;/p&gt;
    &lt;p&gt;Writers were shaped, too, by the fractious, intellectually combative culture of the Voice. Though the Voice was largely left-wing, with a sizable contingent of feminists, lesbians, and gay men, its writers occupied a wide ideological range. There was a culture of what might be politely described as radical candor; a less positive framing would call it all-out ideological antagonism. Many, including staff writer Lucian K. Truscott IV, saw the Voice as “the organ of the feminist movement,” thanks to influential articles like Vivian Gornick’s coverage of the New York Radical Feminists group and Susan Brownmiller’s 1969 cover story of a “legendary” East Coast abortion doctor. But when David Schneiderman joined the Voice as editor in chief and began hiring more women, Jack Newfield — of “10 Worst Landlords” fame — complained to Schneiderman that he was hiring too many “Stalinist feminists.” And the jazz columnist Nat Hentoff, a Jewish atheist libertarian, became nationally famous for his vigorous anti-abortion politics. But the Voice couldn’t be what it was without the ideological range — which often included writers attacking each other in its pages.&lt;/p&gt;
    &lt;p&gt;Romano’s book showcases the high-minded idealism and petty grievances that made the Voice such a fascinating, original, and enduring influence on American intellectual life.Her interviewees vividly convey how its critics helped popularize new artistic movements, bringing innovative subcultures into the mainstream. Unfortunately, the book also serves as an elegy for the newspaper; after limping into the 21st century, the Voice was shut down as a print venture in 2017. Though it was revived a few years later, it’s nothing like the iconoclastic publication of the past. Here, sadly, the comparison between Bell Labs and the Village Voice works all too well. Today, Bell Labs exists as a subsidiary of Nokia. But outside the name, the engineer Brian Potter noted in his newsletterConstruction Physics, “it has little relationship to the industrial research powerhouse of the 20th century.” Nostalgia often manifests as a desire to revive old, beloved institutions, but it’s easier to daydream about than do. As Potter points out, ”The world that Bell Labs thrived in no longer exists: To push technological progress forward, we'll need to understand both why Bell Labs worked and why it no longer could.”&lt;/p&gt;
    &lt;p&gt;The same could be said for the Voice, which reached its greatest heights under a specific economic model for journalism — one that 21st century technologies have destroyed. When the paper was founded in 1951, it had two sources of revenue: from readers purchasing the paper and classified ads. (The ads were mostly for apartments, though Bruce Springsteen famously found his drummer through the Village Voice’s classifieds.) By 1996, however, the Voice was the only NYC weekly that cost money ($1.25 at the newsstand), and circulation was declining. The Voice’s owner at the time, Leonard Stern, decided to make the newspaper free. It was a brilliant move at the time: Distribution shot up from 75,000 issues a week to 250,000, and revenue went up, too.&lt;/p&gt;
    &lt;p&gt;But this business model disintegrated with the rise of the internet. In the summer of 2001, a twentysomething Anil Dash began working as a web developer of the Voice. “I was supposed to work on the classifieds,” he tells Romano. “It was some personals and the real estate listings,” and the latter paid the bills. “My third day there, Craigslist launched in New York. I knew. I was like, ‘Oh my god.’” The Voice could no longer sell what Craigslist offered for free.&lt;/p&gt;
    &lt;p&gt;You probably know the rest of the story. After Craigslist, the deluge. New technological upstarts would emerge, with a missionary zeal for making information free, and newspapers had to adapt — painfully — to this new world. Google’s “first click free” policy, instituted in 2008, forced online publishers to offer unpaywalled articles if they wanted to be indexed in Google search. The policy strangled newspaper profit for years: “If you don’t sign up for ‘first click free,’ the CEO of News Corp complained, “you virtually disappear from a search.” When the Wall Street Journal ran a two-week experiment in 2017 that removed “First Click Free” for 40% of their readers, they saw a 86% jump in subscriptions. But when they made the experiment permanent, Google penalized them by demoting WSJ links in Google’s products, leading to 38% less traffic from searches and 89% less from Google News. Although Google finally ended the policy in late 2017, the damage had been done.&lt;/p&gt;
    &lt;p&gt;What happened to journalism in the 21st century is, in many ways, the story of the conflict between two utopian values: Information wants to be free and Writers should be paid. Focusing on the former has led to undeniably positive outcomes, like better searchability and reduced barriers to important news. But it has also destroyed the economic model that helped the Village Voice cultivate a generation of legendary critics and journalists. Of course, publications are still trying to make it work. In 2011, the New York Timesrolled out a paywall, and today it’s one of the few success stories of traditional media, thanks in part to its games and recipes offering. Other news publications benefit from billionaire owners who became wealthy from the tech boom: The Atlantic is owned by Laurene Powell Jobs, and the Washington Post by Jeff Bezos. Still, today’s critics have to be lucky and good to snatch up the handful of jobs at the handful of surviving publications. Some Voice alums have managed: The staff writer and theater critic Hilton Als is now a staff critic at TheNew Yorker. But the next Hilton Als is facing down the triple threat of little work, low wages, and high cost of living. And I haven’t even mentioned the looming threat of AI. It doesn’t matter if an LLM can actually replace a human critic. The real risk is that they replace a critic’s day job once execs decide that experienced copywriters and technical writers aren’t needed.&lt;/p&gt;
    &lt;p&gt;I’m an optimist by nature, but even I have to admit that things aren’t looking good for America’s critics. “It is impossible to know,” the critic Christine Smallwood writes, “what ideas never came into the world because someone couldn’t or wouldn’t accept an hourly rate that barely covers the babysitter.” It’s hard to measure the impact this has had on America’s intellectual and cultural life, but I do feel a certain despair. “You don’t pay writers now,” the Voice alum Laurie Stone says in Romano’s book, “because the culture has determined that intellectual contributions, aesthetic contributions are something that someone can do on the side, like a hobby. And see what happens to a culture who treats its artists and its intellectuals that way? Not good.”&lt;/p&gt;
    &lt;p&gt;We have criticism at home&lt;/p&gt;
    &lt;p&gt;I feel impatient, though, when I encounter yet another essay that pines after the past. Yes, if only we could return to that world — where newspapers raked in ad revenue; where rent was cheap in lower Manhattan; where there were thousands of journalism jobs across the country — then maybe American criticism could be great again. But we can’t revive the past, any more than leftists can bring back postwar trade unions in a globalized economy, or conservatives can bring back 1950s-style traditional marriages in a world where more women have bachelor’s degrees than men. In July, the New York Times announced that four of their longtime staff critics would be reassigned. Their replacements, the culture editor Sia Michel wrote in an internal memo, would be charged with guiding readers “not only through traditional reviews but also with essays, new story forms, videos and experimentation with other platforms.” The outcry was immediate: The film critic Richard Brody penned an impassioned defense of the traditional review, while the writer Adlan Jackson’s commentary in the worker-owned NYC publication Hell Gate had the cutting headline: “Does the NYT want culture writing or TikTok videos?”&lt;/p&gt;
    &lt;p&gt;But the most revealing part of Michel’s memo wasn’t the content formats she mentioned but her description of the changing cultural landscape. “New generations of artists and audiences,” she wrote, “are bypassing traditional institutions.” The internet has fundamentally reshaped the three-way relationship between artist, critic, and audience. This is most obvious in music. During the Voice’s heyday, musicians could — and often did — get touchy about negative reviews: After Robert Christgau’s negative review of a Sonic Youth album, the band’s songwriter Thurston Moore wrote a song called “Kill Yr Idols,” which included the lyrics ““I don’t know why / You wanna impress Christgau.” (Christgau’s terse reply: “Idolization is for rock stars … critics just want a little respect.”) But although artists could be “coolly resentful, if not openly adversarial” towards their critics in the past, as the writer Luke Ottenhof observed, they understood that critics were indispensable. Christgau’s “Consumer Guide” columns for the Voice helped introduce people to new artists and music. But social media has altered the artist-critic dynamic: Not only can artists send their fans to harass a reviewer, they also have newfound leverage against publications. As Ottenhof writes,&lt;/p&gt;
    &lt;p&gt;Flanked by fans who don’t rely on the music press to access or learn about their icons, famous artists can hold their relationships with financially-challenged music publications hostage on condition of favorable coverage — coverage that most publications in a click-driven economy can’t afford to pass up … These dynamics punish dialogue, nuance, and even careful dissent, inching us towards a hegemonic monoculture.&lt;/p&gt;
    &lt;p&gt;This points to another key change. The internet has made it easy to evaluate all content — including criticism — against three key metrics: views, likes, and shares. Criticism, it turns out, underperforms. “The consensus,” the media columnist Charlotte Klein reported in New York Magazine is that “stand-alone reviews just don’t generate traffic.” Media organizations, already struggling with a traffic apocalypse, have an “acute sensitivity,” Klein wrote, to what goes unread.&lt;/p&gt;
    &lt;p&gt;It’s hard to argue with the numbers. But I can’t help but think of C. Thi Nguyen’s concept of values capture, which — as he writes in his forthcoming book, The Score — happens “when we are exposed to a simple public scoring system — a ranking, a metric, a numerical score — and it takes over our decision-making.” Newspapers, he writes, “can be value-captured by clicks and page views,” which enable efficient quantitative comparisons against qualitatively different forms of content. A 3,000-word review that elegantly synopsizes the history of hip-hop is intended to accomplish something very different than a 500-word recap of two artists feuding on Twitter, but page views let us compare them directly. And a review championing an unknown artist has a smaller built-in audience than flattering, shallow coverage of an existing star. Though the former is more likely to facilitate an artistically innovative culture, the latter is rewarded in today’s attention economy. (A similar problem affects social reviewing sites like Goodreads and Letterboxd. The reviews that rack up the most likes tend to be quippy, highly polarized one-liners instead of reviews that carefully engage with the complexities of a work — the ones, that is, that function as actual criticism.)&lt;/p&gt;
    &lt;p&gt;From a venture capitalist’s perspective, the creator economy has been relatively successful. But when it comes to 21st century culture, it’s not enough for a handful of tech startups to achieve unicorn valuations. Rather, we should see if they can facilitate the creation and dissemination of artistically ambitious works. Because great art is, in many ways, the solution to the attention economy’s problems. Much of the internet is now optimized for shallow and trivially dopaminergic slop, but perhaps it’s also accentuated the unique value proposition, if you will, of genuine artistic works. Art can hold our attention in a more rewarding way — restoring the capacities that have been degraded by other apps.&lt;/p&gt;
    &lt;p&gt;When I finish a great novel, film, or videogame, I don’t feel dispirited and hollowed out by the experience. Instead, it feels as if I’ve lived with and through its characters. Often, I want to relive that experience, deepen it, and feel it again. I can do so as part of an audience, and search out recommendations, reviews, and criticism as a guide. But I might also do so as a critic — carefully, generously, and rigorously evaluating a work — or as an artist, responding to historical precedent and contemporaneous peers with an artwork of my own. The 21st century has democratized artistic production and discourse like never before; it’s easier than ever for artists to learn from the past, find a community of peers, and access professional-grade tools. More people than ever can review art and make it. Two years ago, the critic Ryan Ruby suggested that we are in a golden age of literary criticism. “It is not unusual,” the critic and scholar Merve Emre wrote, “to stumble upon an essay on Goodreads or Substack that is just as perceptive as academic or journalistic essays.” In the art world, Sean Tatol’s Manhattan Art Review is directly inspired by Christgau’s approach to music criticism, and his efforts to comprehensively review even small gallery shows have made the site, in the words of Ben Davies, “an independent media project in the true sense.” It’s a form of criticism that the internet is most capable of facilitating.&lt;/p&gt;
    &lt;p&gt;There are artists, too, creating works in distinctively 21st century mediums. I’m particularly interested in the work shown at places like the The HTML Review, an annual journal of web-based literature. The fourth issue, published this spring, includes works like the software engineer and artist Reuben Son’s “Airs,” which features poems presented in a programmatically-distorted typeface, accompanied with a generative audio soundtrack inspired by the wind. Son’s work is inspired by existing artistic forms — concrete poetry and ambient music — and combines them into a form uniquely suited for the web, with its accretion of multimedia technologies. This is an artistic medium still in its infancy. In the same issue, the poet and coder Theo Ellin Ballew observes that more web-based artworks and poetry are starting to emerge. Perhaps, they speculate, there is now “a critical mass … [of] enough artist and poet-age people who grew up on the internet to build a vibrant conversation. Or maybe we just need some time to warm up to a new tool before we can let it give us beauty or meaning or intensity.”&lt;/p&gt;
    &lt;p&gt;What would it take for web-based art to become a significant art movement? For more people, I think, to pay attention to these works, write about them, and contextualize them in existing cultural narratives. To take part in making them, and to participate in critiquing them — pushing both artists and audiences to expect more. These are new forms; they need their critics and audiences. (“An audience with a high level of connoisseurship,” Fran Lebowitz once said, “is as important to the culture as artists.”) Here I’m reminded of a proposition from the art professor and critic Alex Kitnick, who, at a March event hosted by the arts criticism website 4Columns, quoted a work by the poet David Antin on the New York art world of the 1960s:&lt;/p&gt;
    &lt;p&gt;There were millions of people all around and most of them seem to have been artists of some sort or another … artists went to see each other’s work and we were all very excited with everything we were doing and we were all doing everything … and everybody was an art critic … all artists were art critics.&lt;/p&gt;
    &lt;p&gt;In this world, Kitnick notes, “Having lots of critics around is understood … as having been a rather positive thing.” It meant that criticism wasn’t just “siloed off, professionalized … but rather that it belonged to and was practiced by everyone, especially artists.” A collective investment in creating art helps create a lively, varied artistic ecosystem. And criticism, with its public and social qualities, can help that community construct a shared understanding of artistic excellence. “Today,” Kitnick continues,&lt;/p&gt;
    &lt;p&gt;we say such a thing pejoratively: “Everyone’s a critic” means that no one is, that everything has been leveled, that judgment has been suspended or that its enormity has given way to equilibrium. But it’s important to push this thought against the grain and imagine that criticism can only exist when everyone, or at least a critical mass of people, are actively involved in the culture of art. Criticism is better when more people take part in it.&lt;/p&gt;
    &lt;p&gt;This doesn’t, of course, solve the material problems facing today’s critics. But the social function of criticism is too valuable to lose. And the three-way relationship between artists, critics, and audiences must be carefully restored, if we want the 21st century to produce meaningful artistic innovations.&lt;/p&gt;
    &lt;p&gt;These are dispiriting times. But I refuse to believe that the past will always be better than the future, that art and technology are inevitably opposed, that Silicon Valley can only destroy — instead of transform — cultural innovation. And I refuse to believe that more participation leads to a degraded cultural ecosystem. We can’t go back to the past, but that may be a good thing; there were millions of people who were denied full access to the cultural sphere because of their gender or race or sexuality. People who would have never made it into the inner sanctum of American culture — even at a defiantly countercultural publication like the Voice — can now, for the first time in history, publish from anywhere and reach an audience everywhere.&lt;/p&gt;
    &lt;p&gt;“When a window closes,” the critic Johanna Fateman offered at the same event, “a door opens, eventually.” It’s a typical critical maneuver — not apocalyptic despair, nor blind optimism, but a secret third thing: a highly contingent, careful prescription for hope. Because despite all the ominous reports of the death of literacy, the death of critical thinking, the death of subcultures, and the death of artistic innovation — no one seems ready, at the end of the day, to give up trying. The fact that people continue to create art and culture, even though the economic conditions are getting worse and worse, continues to inspire me. How can we ensure that they don’t stop?&lt;/p&gt;
    &lt;p&gt;Celine Nguyen is a software designer and writer from California. Her criticism has appeared in ArtReview, The Atlantic, The Believer, and the Cleveland Review of Books. She writes the newsletter personal canon about literature, design and technology.&lt;/p&gt;
    &lt;p&gt;By highlighting text and “starring” your selection, you can create a personal marker to a passage.&lt;/p&gt;
    &lt;p&gt;What you save is stored only on your specific browser locally, and is never sent to the server. Other visitors will not see your highlights, and you will not see your previously saved highlights when visiting the site through a different browser.&lt;/p&gt;
    &lt;p&gt;To add a highlight: after selecting a passage, click the star . It will add a quick-access bookmark.&lt;/p&gt;
    &lt;p&gt;To remove a highlight: after hovering over a previously saved highlight, click the cross . It will remove the bookmark.&lt;/p&gt;
    &lt;p&gt;To remove all saved highlights throughout the site, you can click here to completely clear your cache. All selections have been cleared.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45802538</guid><pubDate>Mon, 03 Nov 2025 18:33:22 +0000</pubDate></item><item><title>The Stallman Paradox: How Web3 Became the Ultimate Open Source Theater</title><link>https://paragraph.com/@holonic-horizons/the-stallman-paradox-how-web3-became-the-ultimate-open-source-theater</link><description>&lt;doc fingerprint="2d2233190d8b6d38"&gt;
  &lt;main&gt;
    &lt;p&gt;Have you ever wondered why we celebrate Richard Stallman as a visionary prophet of digital freedom while simultaneously abandoning every principle he fought for? The contradiction runs deeper than you think—and the evidence suggests Web3 has become the most sophisticated extraction machine ever wrapped in open source aesthetics.&lt;/p&gt;
    &lt;p&gt;This is the Stallman Paradox: the growing chasm between our intellectual reverence for genuine free software principles and our practical convergence on venture capital-optimized extraction models that merely cosplay as "open source."&lt;/p&gt;
    &lt;p&gt;And here's what makes it terrifying: It's not a bug. It's a feature of how our entire economic system operates.&lt;/p&gt;
    &lt;p&gt;Let's start with the numbers, because they tell a story that rhetoric cannot hide:&lt;/p&gt;
    &lt;p&gt;GPL usage has collapsed from 72% in 2009 to just 15% in 2024—a 57 percentage point freefall. Meanwhile, permissive licenses (MIT, Apache, BSD) that enable corporate appropriation without reciprocal obligations have surged from 28% to 85% over the same period.&lt;/p&gt;
    &lt;p&gt;Think about what this means: The very licenses Stallman created to ensure software freedom—licenses that require you to share improvements back to the community—have been systematically abandoned in favor of licenses that let corporations extract value without giving anything back.&lt;/p&gt;
    &lt;p&gt;But wait, it gets worse.&lt;/p&gt;
    &lt;p&gt;96% of enterprises have increased their open source usage. Sounds great, right? Except 89% of them explicitly avoid copyleft licenses to prevent the community protection mechanisms those licenses provide.&lt;/p&gt;
    &lt;p&gt;The message is crystal clear: Corporations want the benefits of community development without reciprocal obligations. They want free labor, not free software.&lt;/p&gt;
    &lt;p&gt;And the money confirms it. Web3 platforms extracting 90% of community value receive $19.6 billion annually&lt;/p&gt;
    &lt;p&gt;The market has spoken: Extraction pays. Cooperation starves.&lt;/p&gt;
    &lt;p&gt;Let me show you how this plays out in Web3 specifically, because Base—Coinbase's Layer 2 solution—is the textbook example of what I call "open source theater."&lt;/p&gt;
    &lt;p&gt;Base markets itself as a decentralized blockchain platform. The code is visible on GitHub. Community developers contribute. There's rhetoric about "bringing a billion users onchain" and democratizing finance.&lt;/p&gt;
    &lt;p&gt;But here's what they don't emphasize:&lt;/p&gt;
    &lt;p&gt;Base operates with a single centralized sequencer controlled exclusively by Coinbase. This means Coinbase alone decides which transactions get processed and in what order. They can censor transactions. They can extract MEV (maximal extractable value). They control the infrastructure that everyone else builds on top of.&lt;/p&gt;
    &lt;p&gt;When AWS had its October 2025 outage, Base went down with it. So much for "decentralization."&lt;/p&gt;
    &lt;p&gt;And the numbers? Base generated $360 million in annual revenue while claiming to empower users. In the past month alone: $51.1 million. Not to the community. To Coinbase.&lt;/p&gt;
    &lt;p&gt;But here's where it gets truly Orwellian: In July 2025, JPMorgan partnered with Coinbase so Chase customers can fund their Coinbase wallets directly with credit cards and convert rewards points to USDC. The very banks that crypto was supposed to render obsolete are now the primary on-ramps to the "decentralized" ecosystem.&lt;/p&gt;
    &lt;p&gt;And Coinbase itself? They're seeking a federal banking charter. They want to become the system they claimed to replace.&lt;/p&gt;
    &lt;p&gt;This is the Stallman Paradox incarnate: Code that's technically "open source" wrapped around infrastructure that's fundamentally extractive, controlled by a corporation seeking to become a traditional financial institution.&lt;/p&gt;
    &lt;p&gt;Here's what I've discovered after analyzing dozens of cases across open source, Web3, cloud infrastructure, and mobile platforms: Every successful technology initiative follows an identical four-phase pattern, regardless of founding principles.&lt;/p&gt;
    &lt;p&gt;The project starts with genuine open source or a "free" tier. Real value gets created. A community forms. There's idealistic messaging about empowerment, democratization, giving power back to users.&lt;/p&gt;
    &lt;p&gt;This phase is sincere. The founders often genuinely believe in the mission. The early community members are true believers.&lt;/p&gt;
    &lt;p&gt;Network effects kick in. Switching costs increase. The platform achieves critical mass. Essential features start migrating behind paywalls, marketed as "professional" or "enterprise" tiers.&lt;/p&gt;
    &lt;p&gt;The community becomes dependent—their workflows, their relationships, their professional identities are now tied to this platform.&lt;/p&gt;
    &lt;p&gt;The free tier gets deliberately crippled to force upgrades. This is the "freemium" model, but it's darker than it sounds. Community contributions get captured while economic benefits concentrate at the top.&lt;/p&gt;
    &lt;p&gt;Often there's a licensing change—from truly open source to something like Business Source License (BSL) or Server Side Public License (SSPL). These aren't actually open source, but they sound open source.&lt;/p&gt;
    &lt;p&gt;The platform has become an extraction mechanism, with the community providing free labor.&lt;/p&gt;
    &lt;p&gt;Lock-in effects prevent community migration. Even competitors are forced to adopt similar extraction models just to compete on user experience.&lt;/p&gt;
    &lt;p&gt;The original cooperative principles are abandoned for "shareholder value." "Open source" becomes marketing rather than operational reality.&lt;/p&gt;
    &lt;p&gt;And here's the kicker: This pattern is inevitable under current economic conditions.&lt;/p&gt;
    &lt;p&gt;Let me show you this pattern playing out right now with Redis, the popular in-memory database.&lt;/p&gt;
    &lt;p&gt;Redis started with a BSD license—truly open source, do whatever you want with it. AWS and other cloud providers offered managed Redis services, making tons of money without contributing much back to the project.&lt;/p&gt;
    &lt;p&gt;March 2024: Redis changed to dual-license RSALv2 and SSPLv1—neither actually OSI-approved open source—specifically to prevent cloud providers from offering Redis-as-a-service.&lt;/p&gt;
    &lt;p&gt;The result? Redis lost most of its external contributors. The project went from substantial community contributions to almost none overnight. Trust, broken.&lt;/p&gt;
    &lt;p&gt;The community responded by creating Valkey, a truly open source fork now led by the Linux Foundation.&lt;/p&gt;
    &lt;p&gt;Then May 2025: Redis added AGPLv3 (actually open source this time) and claimed they were "returning to open source."&lt;/p&gt;
    &lt;p&gt;But the damage to community trust was done. And Redis's motivation was never about software freedom—it was about preventing cloud providers from extracting value without paying Redis the company.&lt;/p&gt;
    &lt;p&gt;This same story plays out again and again:&lt;/p&gt;
    &lt;p&gt;Elasticsearch changed from Apache 2.0 to SSPL. AWS forked it to create OpenSearch. Community split.&lt;/p&gt;
    &lt;p&gt;Terraform switched from Mozilla license to Business Source License. Community created OpenTofu fork. Then IBM acquired HashiCorp for $6.4 billion—precisely because the license change gave IBM more control.&lt;/p&gt;
    &lt;p&gt;Docker kept the engine open source but made Docker Desktop require paid subscriptions for any company over 250 employees or $10M revenue.&lt;/p&gt;
    &lt;p&gt;Every single case follows the same pattern: Start open, build community, capture value, extract rents.&lt;/p&gt;
    &lt;p&gt;Want to see the Stallman Paradox operating at truly global scale? Look at Android.&lt;/p&gt;
    &lt;p&gt;Android Open Source Project (AOSP) is technically open source under Apache 2.0 license. Google tells regulators "it's open source!" when facing antitrust scrutiny.&lt;/p&gt;
    &lt;p&gt;But here's reality: The Android that matters—the one people actually use—is AOSP + Google Mobile Services (GMS), which is completely proprietary and closed.&lt;/p&gt;
    &lt;p&gt;Play Store? Closed. Play Services? Closed. Play Billing? Closed and mandatory—if you want to sell digital goods in your app, you must use Google Play Billing and give Google their cut.&lt;/p&gt;
    &lt;p&gt;And as of March 2025, Google moved all Android development to internal, private branches. The "open source" code gets released after Google finishes development, with the community excluded from actual decision-making.&lt;/p&gt;
    &lt;p&gt;You can technically fork Android. LineageOS and others have done it. But without Google Mobile Services, your fork is unusable for the vast majority of users. The apps they want don't work. The services they depend on aren't available.&lt;/p&gt;
    &lt;p&gt;So Android is "open source" in the same way Base is "decentralized": Technically true in the narrowest sense, functionally false in every way that matters.&lt;/p&gt;
    &lt;p&gt;The Stallman Paradox isn't just about individual projects—it's about the entire foundation of our digital infrastructure being built on fragile, volunteer-maintained open source projects that nobody's funding.&lt;/p&gt;
    &lt;p&gt;Remember when a developer unpublished an 11-line JavaScript package called &lt;code&gt;left-pad&lt;/code&gt; and it broke React, Babel, and thousands of high-profile packages globally?&lt;/p&gt;
    &lt;p&gt;That one incident revealed something terrifying: Our entire JavaScript ecosystem—billions of dollars of commercial software—was built on a massive dependency tree that nobody fully understood, maintained largely by volunteers, with no redundancy or safety mechanisms.&lt;/p&gt;
    &lt;p&gt;A fresh Babel install includes 41,000 files. A blank npm-based app template starts with 28,000+ files. And nobody knows what all of them do or who maintains them until they vanish.&lt;/p&gt;
    &lt;p&gt;Or consider Log4j, a Java logging library. It had a critical vulnerability—CVSS score 10.0, maximum severity—that went unnoticed for eight years (existed since 2013).&lt;/p&gt;
    &lt;p&gt;When it was discovered in December 2021, 93% of enterprise cloud environments were affected. The vulnerability was so severe that cybersecurity experts called it "the single biggest, most critical vulnerability ever."&lt;/p&gt;
    &lt;p&gt;Within 24 hours of disclosure, there were 60+ exploit variants being used. Attempts to exploit vulnerable systems: ~2 million per hour in the first days.&lt;/p&gt;
    &lt;p&gt;Affected systems: Minecraft, Steam, AWS, Cloudflare, iCloud, Tencent QQ, and hundreds of millions of devices worldwide.&lt;/p&gt;
    &lt;p&gt;And Log4j? Ubiquitous open source library, largely maintained by volunteers, no comprehensive security review until it was too late.&lt;/p&gt;
    &lt;p&gt;Then there's SolarWinds—the attack that compromised 18,000 customers including U.S. government agencies and Fortune 500 companies.&lt;/p&gt;
    &lt;p&gt;Attackers didn't target the code directly. They compromised the build environment—the machinery that compiles and packages the software. They inserted malicious code that was then digitally signed, making it look completely legitimate.&lt;/p&gt;
    &lt;p&gt;The supply chain attack vector is the future of warfare, and our infrastructure—both proprietary and open source—is catastrophically vulnerable to it.&lt;/p&gt;
    &lt;p&gt;Here's what makes the Stallman Paradox so insidious: You cannot solve it through individual choices.&lt;/p&gt;
    &lt;p&gt;"Just use GPL licenses!" doesn't work when 89% of enterprises avoid them and venture capital won't fund projects that use them.&lt;/p&gt;
    &lt;p&gt;"Build community alternatives!" doesn't work when venture-funded platforms can invest 10x more in user experience and outcompete you on convenience.&lt;/p&gt;
    &lt;p&gt;"Vote with your feet!" doesn't work when your professional network, your career opportunities, and your collaboration tools are all locked into extractive platforms.&lt;/p&gt;
    &lt;p&gt;The problem is contextual, not individual. Market selection pressure, resource asymmetry, network effects, and professional requirements all create a gravitational pull toward extraction that individual virtue cannot resist.&lt;/p&gt;
    &lt;p&gt;This is why:&lt;/p&gt;
    &lt;p&gt;Red Hat suspended FSF funding in 2021 despite being built on free software&lt;/p&gt;
    &lt;p&gt;The Open Source Lab needs $250,000 by May 2025 or shuts down despite being critical infrastructure&lt;/p&gt;
    &lt;p&gt;The FSF received only $708,016 in memberships in 2019 despite Stallman being called a "prophet"&lt;/p&gt;
    &lt;p&gt;We revere the principles while defunding the institutions that embody them, because the economic incentives point toward extraction, not cooperation.&lt;/p&gt;
    &lt;p&gt;So where does Web3 fit in all this?&lt;/p&gt;
    &lt;p&gt;Web3 was supposed to be the answer—economic alignment through tokens, transparent on-chain value flows, DAO governance giving communities real control, blockchain enabling true decentralization.&lt;/p&gt;
    &lt;p&gt;And there are innovative experiments: quadratic funding mechanisms, on-chain transparent value distribution, DAO governance structures, copyleft-inspired licenses for smart contracts.&lt;/p&gt;
    &lt;p&gt;But look at what actually emerged:&lt;/p&gt;
    &lt;p&gt;Paragraph (the platform I'm using to publish this) claims to empower creators with "creator coins." Reality? The platform maintains 90% control of token economics. Creators provide content and audiences. Platform captures value.&lt;/p&gt;
    &lt;p&gt;OpenSea markets itself as a decentralized NFT marketplace. It eliminated creator royalties while maintaining its 0.5% trading fee on all transactions. Platform captured 95% of ecosystem value while community provided the content.&lt;/p&gt;
    &lt;p&gt;Friend.tech let you speculate on social relationships through "keys." It collapsed in 2024 after the extraction model proved unsustainable. But while it lasted, it captured massive trading fees while relationships got financialized.&lt;/p&gt;
    &lt;p&gt;Every Web3 platform follows the same freemium pattern as Web2, just with speculation-based extraction instead of usage-based extraction:&lt;/p&gt;
    &lt;p&gt;Traditional Freemium: Free tier with limited functionality → Pay for premium features&lt;/p&gt;
    &lt;p&gt;Web3 Freemium: "Free" participation → Premium value through token speculation → Platform captures trading fees, infrastructure control, and token economics design&lt;/p&gt;
    &lt;p&gt;The technology changed. The extraction didn't.&lt;/p&gt;
    &lt;p&gt;October 20, 2025. AWS US-East region suffered a catastrophic DNS and API failure.&lt;/p&gt;
    &lt;p&gt;What followed was a global cascade: Banks offline. Government systems down. Social media collapsed. Retail couldn't process payments. Even platforms not directly hosted on AWS went down because something in their dependency chain was.&lt;/p&gt;
    &lt;p&gt;Base—our "decentralized" blockchain—suffered high latencies, synchronization errors, and block production inconsistencies.&lt;/p&gt;
    &lt;p&gt;36% of Ethereum's execution-layer nodes rely on AWS infrastructure. When AWS sneezes, crypto catches the flu.&lt;/p&gt;
    &lt;p&gt;That outage made the Stallman Paradox visceral in a way theory never could. Millions of people simultaneously experienced digital serfdom—entire aspects of modern life controlled by rented infrastructure whose failure they could not remedy.&lt;/p&gt;
    &lt;p&gt;"When AWS sneezes, half the internet catches the flu" stopped being a joke and became documented reality.&lt;/p&gt;
    &lt;p&gt;So if individual solutions can't fix systemic problems, and the economic incentives inevitably drive toward extraction, are we doomed?&lt;/p&gt;
    &lt;p&gt;Not necessarily. But the answer isn't to "solve" the Stallman Paradox—it's to dance with it.&lt;/p&gt;
    &lt;p&gt;Tensegrity structures—like geodesic domes or the human skeleton—generate strength precisely through tension, not by eliminating it. They balance compression and tension in dynamic equilibrium.&lt;/p&gt;
    &lt;p&gt;What if we designed organizational and economic structures the same way?&lt;/p&gt;
    &lt;p&gt;Instead of fighting to resolve the tension between community values and commercial viability, what if we built systems that use that tension as creative fuel?&lt;/p&gt;
    &lt;p&gt;This requires:&lt;/p&gt;
    &lt;p&gt;Constitutional Layer: Stable, protected principles (like copyleft requirements, democratic governance, value distribution commitments) that cannot be changed without extraordinary community consensus.&lt;/p&gt;
    &lt;p&gt;Operational Layer: Adaptive business models and market negotiations that can respond flexibly to competitive pressures without violating constitutional principles.&lt;/p&gt;
    &lt;p&gt;Emergent Layer: Rapid community responses to new extraction threats, treating each attack as a learning opportunity that strengthens the system.&lt;/p&gt;
    &lt;p&gt;Systems that don't just survive extraction attempts but gain strength from them. Every lawsuit, every licensing dispute, every fork becomes data that makes the ecosystem more resilient.&lt;/p&gt;
    &lt;p&gt;Steward ownership models where founders can earn returns but cannot sell the company&lt;/p&gt;
    &lt;p&gt;Exit to community structures where companies transition to user ownership&lt;/p&gt;
    &lt;p&gt;Protocol-first design where competitive platforms can be built atop shared infrastructure&lt;/p&gt;
    &lt;p&gt;Value capture at the protocol layer instead of platform layer&lt;/p&gt;
    &lt;p&gt;The deepest shift isn't technical—it's cultural. We need to:&lt;/p&gt;
    &lt;p&gt;Teach paradox navigation as a core skill, not just in business schools but from elementary education&lt;/p&gt;
    &lt;p&gt;Measure success differently - not user growth and revenue, but user empowerment and distributed ownership&lt;/p&gt;
    &lt;p&gt;Celebrate cooperative competition - platforms competing on user experience while collaborating on shared infrastructure&lt;/p&gt;
    &lt;p&gt;Build coordination infrastructure that reduces the costs of collective action&lt;/p&gt;
    &lt;p&gt;The Stallman Paradox is everywhere:&lt;/p&gt;
    &lt;p&gt;Open source infrastructure (Redis, Elasticsearch, Terraform, Docker)&lt;/p&gt;
    &lt;p&gt;Web3 platforms (Base, Paragraph, OpenSea, every token project)&lt;/p&gt;
    &lt;p&gt;Cloud infrastructure (AWS, Azure, Google Cloud)&lt;/p&gt;
    &lt;p&gt;Mobile operating systems (Android, iOS)&lt;/p&gt;
    &lt;p&gt;Supply chain dependencies (npm, Log4j, SolarWinds)&lt;/p&gt;
    &lt;p&gt;Every domain shows the identical pattern: Start open, build community, create dependency, extract value, achieve dominance.&lt;/p&gt;
    &lt;p&gt;But recognizing the pattern is the first step toward building different systems.&lt;/p&gt;
    &lt;p&gt;The Stallman Paradox serves as a diagnostic tool—a way to see when we're participating in the very systems we claim to resist. We can intellectually champion Stallman's vision while practically funding and building the infrastructure of digital serfdom.&lt;/p&gt;
    &lt;p&gt;Real change requires not just better individual choices, but different contexts that make cooperative rather than extractive choices economically viable and culturally valued.&lt;/p&gt;
    &lt;p&gt;Until we change the underlying economic and social systems that make freemium extraction inevitable, we will continue to revere prophets whose visions we systematically abandon in practice—creating precisely the digital serfdom they warned us against.&lt;/p&gt;
    &lt;p&gt;So here's my question for you, the reader:&lt;/p&gt;
    &lt;p&gt;What patterns of extraction are you participating in right now, even as you believe you're building something better?&lt;/p&gt;
    &lt;p&gt;Are you using Discord to organize your DAO? Telegram for your community? GitHub for your "decentralized" protocol? Google Docs for your governance proposals?&lt;/p&gt;
    &lt;p&gt;Are you advocating for open source while avoiding GPL licenses because venture capital won't fund them?&lt;/p&gt;
    &lt;p&gt;Are you building on platforms that claim decentralization while maintaining centralized control of the infrastructure?&lt;/p&gt;
    &lt;p&gt;The Stallman Paradox isn't just happening "out there" in the systems other people built. It's happening in the tools you use, the platforms you build on, the business models you adopt, and the compromises you make every single day.&lt;/p&gt;
    &lt;p&gt;Recognition is the first step. Design is the second. Culture is the third.&lt;/p&gt;
    &lt;p&gt;The Stallman Paradox is happening everywhere. Our task isn't to solve it—it's to build systems that become stronger through the tension, transforming platforms of serfdom into collaborative architectures of collective wisdom.&lt;/p&gt;
    &lt;p&gt;The question isn't whether you'll face the paradox. The question is whether you'll have the courage to design your way through it.&lt;/p&gt;
    &lt;p&gt;What patterns of extraction do you see in your corner of Web3? What would it look like to build genuinely antifragile, community-owned infrastructure? Let's explore these questions together.&lt;/p&gt;
    &lt;p&gt;This article is part of an ongoing investigation into the systemic patterns shaping our digital future. If you found this valuable, I explore related themes around coordination failures, shadow hierarchies, and paradox navigation in other pieces on this blog.&lt;/p&gt;
    &lt;p&gt;Share Dialog&lt;/p&gt;
    &lt;p&gt;Support dialog&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45802600</guid><pubDate>Mon, 03 Nov 2025 18:38:00 +0000</pubDate></item></channel></rss>