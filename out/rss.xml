<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 09 Nov 2025 08:39:32 +0000</lastBuildDate><item><title>Marko ‚Äì A declarative, HTML‚Äëbased language</title><link>https://markojs.com/</link><description>&lt;doc fingerprint="a876cc8c70be3ce3"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Trusted&lt;/head&gt;&lt;p&gt;Powering high-traffic, production-grade websites like eBay.com&lt;/p&gt;&lt;p&gt;Powering high-traffic, production-grade websites like eBay.com&lt;/p&gt;&lt;p&gt;If you know HTML, CSS, and JavaScript, you know Marko&lt;/p&gt;&lt;p&gt;Streaming, resumable, optimizing compiler, and a tiny runtime&lt;/p&gt;&lt;p&gt;From simple HTML templates to powerful components as needed&lt;/p&gt;&lt;p&gt;Marko is HTML re‚Äëimagined as a language for building dynamic and reactive user interfaces.&lt;/p&gt;&lt;p&gt;Just about any valid HTML is valid Marko, but Marko extends the HTML language to allow building modern applications in a declarative way.&lt;/p&gt;Check it out!&lt;p&gt;Marko streams content to your users as soon as it's ready. No waiting for client side JavaScript bundles or data requests to start rendering.&lt;/p&gt;&lt;p&gt;HTML, assets, and images are loaded as soon as possible with asynchronous content loading in as it completes.&lt;/p&gt;Learn How&lt;p&gt;Browsers and servers are built differently, shouldn't your code be too? Marko compiles your templates to perform their best with optimized, environment-specific output.&lt;/p&gt;&lt;p&gt;Faster loads. Smaller bundles. One seamless language.&lt;/p&gt;Learn How&lt;p&gt;Marko has built-in TypeScript support , with strong type inference that works across templates and components. Editors get full language features like autocompletion, jump-to-definition, syntax highlighting, and clean formatting.&lt;/p&gt;&lt;p&gt;Build confidently. Catch errors early. Write better code, faster.&lt;/p&gt;Explore&lt;p&gt;Need help? Want to Contribute?&lt;/p&gt;&lt;p&gt;Get involved in the Marko Community!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45858905</guid><pubDate>Sat, 08 Nov 2025 18:43:55 +0000</pubDate></item><item><title>WriterdeckOS</title><link>https://writerdeckos.com</link><description>&lt;doc fingerprint="5e878a1b412da7b6"&gt;
  &lt;main&gt;
    &lt;p&gt;Requirements:&lt;lb/&gt; - 64bit processor (Intel/AMD)&lt;lb/&gt; - Will not work on an ARM processorThe installation ISO is hosted at The Internet Archive:&lt;lb/&gt; https://archive.org/details/tinkerWD-1.0Donate to the Internet Archive here: Donate&lt;/p&gt;
    &lt;p&gt;writerdeckOS is an operating system used to convert laptops and many Chromebooks (with 64-bit Intel/AMD processors) into a "Writer Deck".A Writer Deck is a device that is used solely for writing text.It minimizes distractions. No internet browsing, no apps, no games, no social media, no notifications. Not even major formatting!Just Writing.writerdeckOS is very light weight and specifically seeks to lower the barrier of entry to creating writer decks. It converts older, reused, refurbished, or inexpensive laptops into a dedicated writing machine.writerdeckOS sits on top of a "headless" Debian Linux image and boots directly into a console based text editor. We're using the Tilde Text Editor because it is simple text editor, has an intuitive User Interface, and allows for customized color schemes for light and dark modes.More information:&lt;lb/&gt; - General Info about Writer Decks: writerDeck.org&lt;lb/&gt; - Reddit: writerdeckOS Subreddit&lt;lb/&gt; - writerdeckOS: Github Repo | Archive Org ISO Page&lt;lb/&gt; - Tilde Text Editor: Github Repo | Website&lt;/p&gt;
    &lt;p&gt;DISCLAIMER: writerdeckOS comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law.WARNING: You are engaging in a DIY endeavor. You may break your machine. The installation may not work. You may erase the old operating system and not be able to start your device up ever again. This OS has only been tested on a couple of machines and is not guaranteed to work on every laptop. Only try this if you're willing to accept the consequences.WARNING: This will erase everything on the laptop you install it on. Please make backups before beginning.1. With the downloaded ISO, Create a bootable USB: Tutorial&lt;lb/&gt; 2. Plug the USB into your designated laptop and boot from USB: (Depending on your laptop, either press F12, Escape, or F2 during the boot up sequence. Check your laptop manual for specific instructions. Note: You may have to turn "Secure Boot" off within your BIOS.)&lt;lb/&gt; 3. Installation will proceed automatically. The hard drive and all previous contents will be erased and the writer deck will be installed.&lt;lb/&gt; 4. Once finished, press Enter when prompted. Between when the device shuts off and just as it starts up, remove the Installation USB.&lt;lb/&gt; 5. For First Boot you will enter&lt;lb/&gt; - Username: author&lt;lb/&gt; - Password: password&lt;lb/&gt; 6. After start up, shut down by pressing your laptops power button (this will take a short while but will be quicker on subsequent poweroffs).&lt;lb/&gt; 7. Restart laptop and it will boot directly into Tilde word processor.&lt;/p&gt;
    &lt;p&gt;Always remember to Save (Ctrl+S). There is NO autosaving!!!&lt;/p&gt;
    &lt;p&gt;Turn On: Press your laptop's power button.&lt;/p&gt;
    &lt;p&gt;Turn Off: Press your laptop's power button.&lt;/p&gt;
    &lt;p&gt;Turn Off (alternate): From Tilde, Press Ctrl+Q to quit. From the command line, type: shutdown (press enter)&lt;/p&gt;
    &lt;p&gt;To use Tilde: Press Alt+F to bring up the menu system and use arrow keys to navigate around. More info: Here&lt;/p&gt;
    &lt;p&gt;To change color scheme: (Light Mode / Dark Mode) - Press Alt+O, arrow key down to "Interface" and press Enter, then select "Text Area Attributes", then "Text". Change Foreground and Background Color to desired colors.&lt;/p&gt;
    &lt;p&gt;To Enable Word Wrap: Press Alt+O, arrow key down and select "Buffer Defaults". Press spacebar on "Wrap text", choose OK, and then restart.&lt;/p&gt;
    &lt;p&gt;USBs: Access plugged in USBs in the "USBs" folder in the home directory.&lt;/p&gt;
    &lt;p&gt;To Access File System: Press Ctrl+Q to quit.&lt;/p&gt;
    &lt;p&gt;To Navigate File System, Move Files, &amp;amp; Delete Files: Use common Bash commands: Tutorial&lt;/p&gt;
    &lt;p&gt;√¢¬¶ Photo of a writerdeckOS in Light Mode&lt;/p&gt;
    &lt;p&gt;Developer Mode: Press Ctrl+Q to quit Tilde. Underlying file system and command prompt is running Bash.&lt;/p&gt;
    &lt;p&gt;To restart Tilde from the Command Line: Type tilde and press enter.&lt;/p&gt;
    &lt;p&gt;To change keyboard layout: From the initial command line, run: exit to drop to a lower command line, then run sudo dpkg-reconfigure keyboard-configuration then run: sudo service keyboard-setup restart&lt;/p&gt;
    &lt;p&gt;To use a different text editor besides Tilde: Edit the /home/author/.profile file. The Tinker WriterDeck comes preinstalled with several text editors. Use apt to install more.&lt;/p&gt;
    &lt;p&gt;To connect to the internet: (For syncing and app installation purposes) Use: nmcli (from the command prompt).&lt;/p&gt;
    &lt;p&gt;To sync folders to cloud services: Follow service specific instructions. Examples: Nextcloud | Dropbox | Google Drive&lt;/p&gt;
    &lt;p&gt;To Encrypt Harddrive &amp;amp; Require Password to Log in: Install a headless version of Debian 12.10 "Bookworm" and select Full Disk Encryption using LUKS upon installation. Then run configuration script found: Here&lt;/p&gt;
    &lt;p&gt;√¢¬¶ Photo of a writerdeckOS in Dark Mode&lt;/p&gt;
    &lt;p&gt;For questions or assistance, you're welcome to reach out directly to the developer via the Fediverse: @[email protected]For group discussion and questions, you're welcome to join the Reddit /r/writerdeckOS subreddit here: Reddit Discussion ThreadFor technical issues and bug discussions, please open an Issue Ticket on Github here: Github Issue Tracker&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45858945</guid><pubDate>Sat, 08 Nov 2025 18:49:47 +0000</pubDate></item><item><title>Aver√≠a: The Average Font (2011)</title><link>http://iotic.com/averia/</link><description>&lt;doc fingerprint="367d013713a223d1"&gt;
  &lt;main&gt;
    &lt;p&gt;am not a type designer. This is the story of the creation of a new font, Aver√≠a: the average of all the fonts on my computer. The field of typography has long fascinated me, and I love playing with creative programming ideas, so it was perhaps inevitable that the idea came to me one day of ‚Äúgenerative typography‚Äù. A Google on the subject brought up little, and I put the idea to the back of my mind until it occurred to me that perhaps the process of averaging, or interpolating, existing fonts might bring up interesting results. Luckily at this point I didn't do any more web searching ‚Äì instead I grabbed my laptop and came up with an initial idea for finding what the average of all my fonts might look like ‚Äì by overlaying each letter at low opacity. The results can be seen in the below image.&lt;/p&gt;
    &lt;p&gt;This was done by printing each letter of each font, at the same point size, to lots of separate images, and then averaging them ‚Äì using ImageMagick and PHP. The letters were aligned to the same centre point. I later realised that each font has a ‚Äòbaseline‚Äô defined, and an origin on that baseline which each glyph is drawn relative to. The same process, repeated with equal origins, gives slightly different results (see below) ‚Äì here you can see the baseline is very well-defined, with the glyphs becoming more blurred towards the top right of each.&lt;/p&gt;
    &lt;p&gt;I was quite pleased with the results. It was only later that I discovered this had already been done ‚Äì though it appeared that my end results (whilst not as beautifully animated) had a little more clarity, so I'm glad I tried for myself. But this didn't seem like the end of the journey. Whilst this was an interesting experiment, and showed an lot of correlation between a sample of common fonts (as well as a couple of oddities ‚Äì notably the lower case ‚Äòg‚Äô which clearly exists in two distinct common forms), what I really wanted was an average which somehow preserved the well-defined edges of existing fonts. So I started considering ways to produce a smoother, sharper average of letter forms.&lt;/p&gt;
    &lt;p&gt;One idea which seemed obvious was to simply take the blurry results of the first experiment, and use a threshold to create monochrome images. A few experiments in this direction (I first tried with a lower-case ‚Äòf‚Äô, which I later found was never likely to give good results due to the variance in height of the middle cross-stroke) convinced me that I needed to look into cleverer ways to achieve this. Surely there must be a simple way to average shapes, while keeping the result as a shape?&lt;/p&gt;
    &lt;p&gt;It turns out not to be straightforward. There are many possible ways to ‚Äòmorph‚Äô between two shapes ‚Äì and what might seem the most natural generally depends on our perception of ‚Äòfeatures‚Äô in the shapes. Consider the average of a capital I with serifs, and one without: the natural thing to do would be something like, make the serifs half as big, and use a horizontal stem width about half-way between the two glyphs. That's two feature concepts being applied to the abstract forms¬π. To take a simpler example, what is the average of a square with the same square rotated 45Àö? There are a few possibilities ‚Ä¶&lt;/p&gt;
    &lt;p&gt;So, this stumped me for a while. I decided I needed to get to know fonts better, so I built a simple web app to view the lines, curves and control points present in the fonts I had. On this basis, I started to consider the ways the features (vertices, curves, stems, serifs etc) might be matched up between fonts. However, this was a rabbit hole I might never get to the bottom of - particularly when considering some of the more unusual varieties of font. Perhaps there was a simpler idea that was evading me.&lt;/p&gt;
    &lt;p&gt;Then it occurred to me: since my aim was to average a large number of fonts, perhaps it would be best to use a very simple process, and hope the results averaged out well over a large number of fonts. So, how about splitting each letter perimeter into lots of (say, 500) equally-spaced points, and just average between the corresponding positions of each, on each letter? It would be necessary to match up the points so they were about the same location in each letter, and then the process would be fairly simple¬≤.&lt;/p&gt;
    &lt;p&gt;Having found a simple process to use, I was ready to start. And after about a month of part-time slaving away (sheer fun! Better than any computer game) ‚Äì in the process of which I learned lots about bezier curves and font metrics ‚Äì I had a result. I call it Aver√≠a ‚Äì which is a Spanish word related to the root of the word ‚Äòaverage‚Äô. It actually means mechanical breakdown or damage. This seemed curiously fitting, and I was assured by a Spanish friend-of-a-friend that ‚ÄúAver√≠a is an incredibly beautiful word regardless of its meaning‚Äù. So that's nice.&lt;/p&gt;
    &lt;p&gt;Along the way I naturally called on the counsel of the best designers I know ‚Äì my brother Nick Sayers, Lloyd Thomas, Tom Muller and Chris McGrail, for advice. In the end, I decided to release the font using the SIL Open Font License ‚Äì which means anyone can use it pretty much however they like ‚Äì and to include within the family Regular, Bold and Light variants with Italics. Each is made from the corresponding subsets of the fonts on my machine. Also included is a ‚ÄúGruesa‚Äù version made from all my fonts (725 in total).&lt;lb/&gt; Aver√≠a Family (ZIP, 369kB) [Updated 9 Nov 2011]&lt;lb/&gt; Aver√≠a at The Open Font Library&lt;lb/&gt; *NEW* by popular demand:&lt;lb/&gt; Aver√≠a Serif Family (ZIP, 323kB) OFLB&lt;lb/&gt; Aver√≠a Sans Family (ZIP, 320kB) OFLB&lt;lb/&gt; *NEW* Aver√≠a, Serif and Sans packaged as TTC TrueType collections (so you can install each family in one go, rather than one variant at a time). Thanks Ludwig:&lt;lb/&gt; Aver√≠a TTC Files (ZIP, 946kB)&lt;lb/&gt; *NEW* versions of Aver√≠a, based on OFL fonts from the Google Web Fonts directory - now available through GWF as Aver√≠a Libre:&lt;lb/&gt; Aver√≠a GWF Family (ZIP, 488kB)&lt;lb/&gt; Aver√≠a Serif GWF Family (ZIP, 432kB)&lt;lb/&gt; Aver√≠a Sans GWF Family (ZIP, 426kB)&lt;lb/&gt; Preview all&lt;lb/&gt; Feel free to email me if you have any questions ‚Äì or use the comments box below.&lt;lb/&gt; N.B. I've had a number of emails from people asking if they can use Aver√≠a in various commercial / non-commercial projects. I'd love to hear if you do something with these fonts ‚Äì but there's no need to ask permission. You are absolutely free to use them however you like. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45859243</guid><pubDate>Sat, 08 Nov 2025 19:29:44 +0000</pubDate></item><item><title>Largest cargo sailboat completes first Atlantic crossing</title><link>https://www.marineinsight.com/shipping-news/worlds-largest-cargo-sailboat-completes-historic-first-atlantic-crossing/</link><description>&lt;doc fingerprint="df5cacd41833d6da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;World‚Äôs Largest Cargo Sailboat Completes Historic First Atlantic Crossing&lt;/head&gt;
    &lt;p&gt;The world‚Äôs largest cargo sailboat, Neoliner Origin, completed its first transatlantic voyage on 30 October despite damage to one of its sails during the journey.&lt;/p&gt;
    &lt;p&gt;The 136-metre-long vessel had to rely partly on its auxiliary motor and its remaining sail after the aft sail was damaged in a storm shortly after departure.&lt;/p&gt;
    &lt;p&gt;The French-built roll-on/roll-off (RoRo) cargo ship, which has two semi-rigid sails, first stopped at Saint Pierre and Miquelon, a French overseas territory near Canada, before continuing its journey to Baltimore in the United States.&lt;/p&gt;
    &lt;p&gt;Neoline, the company behind the project, said the damage reduced the vessel‚Äôs ability to perform fully on wind power. The company‚Äôs CEO, Jean Zanuttini, said the crossing was a valuable experience in handling large sail surfaces across the North Atlantic, especially during late-season storms. He added that despite the difficulties, the ship showed strong resilience by reaching its destination with only a short delay in Saint Pierre.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin is designed to reduce greenhouse gas emissions by 80 to 90 per cent compared to conventional diesel-powered cargo ships. According to the United Nations Conference on Trade and Development (UNCTAD), global shipping produces about 3 per cent of worldwide greenhouse gas emissions.&lt;/p&gt;
    &lt;p&gt;Zanuttini said the company aims to balance industrial needs with environmental responsibility. He added that wind propulsion offers an advantage because it is a free, widely available, and predictable energy source that does not harm ecosystems.&lt;/p&gt;
    &lt;p&gt;The UK‚Äôs National Clean Maritime Research Hub has reported that wind propulsion systems like those on the Neoliner Origin can cut emissions by over 50 per cent on new vessels optimised for wind conditions. Retrofitted vessels can also achieve reductions of 5 to 20 per cent, and up to 30 per cent when adjusted for wind conditions.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin was designed by the French naval engineering firm Mauric. The company‚Äôs CEO, Vincent Seguin, said the goal was to develop a ship that relies primarily on wind propulsion while ensuring consistent delivery schedules and efficient operation with a smaller crew.&lt;/p&gt;
    &lt;p&gt;Inspired by historic sailing vessels, the Neoliner Origin integrates modern systems such as advanced navigation, anti-drift mechanisms, and automated sail management to comply with current safety and operational standards.&lt;/p&gt;
    &lt;p&gt;The ship can carry up to 5,300 tonnes of cargo, including containers, vehicles, machinery, and specialised goods. It arrived in Baltimore carrying Renault vehicles, French liqueurs, machinery, and other products.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin is scheduled to make monthly voyages between Europe and North America, maintaining a commercial cruising speed of around 11 knots.&lt;/p&gt;
    &lt;p&gt;Reference: Reuters&lt;/p&gt;
    &lt;head rend="h4"&gt;‚öìÔ∏è Enhance Your Knowledge. Prevent Accidents. Stay Safe at Sea.&lt;/head&gt;
    &lt;p&gt;1. eBooks for Engine Department&lt;/p&gt;
    &lt;p&gt;Master machinery operations, troubleshooting, and safety procedures with expertly written guides tailored for marine engineers. Prevent costly breakdowns and onboard accidents through practical knowledge.&lt;/p&gt;
    &lt;p&gt;üëâ Explore Engine Department eBooks&lt;/p&gt;
    &lt;p&gt;2. eBooks for Deck Department&lt;/p&gt;
    &lt;p&gt;Sharpen your seamanship, navigation, and cargo-handling skills with real-world case studies and practical insights designed for deck officers and cadets.&lt;/p&gt;
    &lt;p&gt;üëâDiscover Deck Department eBooks&lt;/p&gt;
    &lt;p&gt;3. eBooks on Electrical Fundamentals &amp;amp; Issues&lt;/p&gt;
    &lt;p&gt;Understand marine electrical systems, identify potential faults, and prevent onboard electrical failures with step-by-step explanations from industry experts.&lt;/p&gt;
    &lt;p&gt;4. Pocket Guides for Quick Reference&lt;/p&gt;
    &lt;p&gt;Compact, handy, and loaded with essential checklists‚Äîperfect for on-the-go reference during operations and emergencies at sea.&lt;/p&gt;
    &lt;p&gt;5. Combo Packs to Save Big&lt;/p&gt;
    &lt;p&gt;Access multiple expert eBooks at discounted prices. Ideal for professionals seeking complete safety and operational knowledge across various ship departments.&lt;/p&gt;
    &lt;p&gt;6. Digital Maritime Courses ‚Äì Learn at Your Own Pace&lt;/p&gt;
    &lt;p&gt;Upgrade your competence with Marine Insight Academy‚Äôs online courses. Learn from industry professionals anytime, anywhere, and become a safer, smarter seafarer.&lt;/p&gt;
    &lt;p&gt;Disclaimer : &lt;lb/&gt;The information on this website is for general purposes only. While efforts are made to ensure accuracy, we make no warranties of any kind regarding completeness, reliability, or suitability. Any reliance you place on such information is at your own risk. We are not liable for any loss or damage arising from the use of this website.&lt;/p&gt;
    &lt;p&gt;Disclaimer : &lt;lb/&gt;The information on this website is for general purposes only. While efforts are made to ensure accuracy, we make no warranties of any kind regarding completeness, reliability, or suitability. Any reliance you place on such information is at your own risk. We are not liable for any loss or damage arising from the use of this website.&lt;/p&gt;
    &lt;head rend="h2"&gt;Subscribe To Our Daily Newsletter&lt;/head&gt;
    &lt;p&gt;By subscribing, you agree to our Privacy Policy and may receive occasional deal communications; you can unsubscribe anytime.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45859471</guid><pubDate>Sat, 08 Nov 2025 19:57:52 +0000</pubDate></item><item><title>What Hallucinogens Will Make You See (2023)</title><link>https://nautil.us/what-hallucinogens-will-make-you-see-308247/</link><description>&lt;doc fingerprint="f29ee1093f20f1f6"&gt;
  &lt;main&gt;
    &lt;p&gt;Psychonaut turned scientific researcher Josie Kins has personally tried over 200 psychedelic compounds and had hundreds of psychedelic experiences. But she no longer takes them herself. ‚ÄúI‚Äôve already explored them so thoroughly,‚Äù she says. Over the past 12 years, Kins has compiled a list of 233 effects people experience under the influence of psychedelic drugs, drawn from online accounts and her own experience, called the Subjective Effect Index.&lt;/p&gt;
    &lt;p&gt;In 2021, she began working for a startup drug company called Mindstate Design Labs to make the classification system more precise and comprehensive, under the advisement of renowned psychedelic researchers Thomas Ray and Andy Newburg. That work could double the total number of entries on the list, she says. But it‚Äôs the cognitive and emotional effects that seem to elude categorization and need the most refining. ‚ÄúThe visual effects are already rigorous,‚Äù says Kins.&lt;/p&gt;
    &lt;p&gt;Below, a selection of some of the 52 visual effects on her list.&lt;/p&gt;
    &lt;p&gt;Diffraction is the experience of seeing rainbows and spectrums of color embedded within the brighter parts of a person‚Äôs visual field. It is most commonly induced under the influence of mild dosages of psychedelic compounds, such as LSD, psilocybin, and mescaline.&lt;/p&gt;
    &lt;p&gt;Increased pareidolia is an increase in a person‚Äôs ability and tendency to recognize patterns (usually faces) within vague stimuli. It is most commonly induced under the influence of mild dosages of psychedelic compounds, such as LSD, psilocybin, and mescaline.&lt;/p&gt;
    &lt;p&gt;Machinescapes are a complex visual and tactile experience where one perceives hallucinatory mechanical landscapes that are vast in both size and intricacy. They are most commonly induced under the influence of heavy dosages of Salvia divinorum. However, they can also occur less commonly under the influence of psychedelic compounds, such as LSD, psilocybin, and 2C-P.&lt;/p&gt;
    &lt;p&gt;Object activation is the experience of looking at an object and perceiving it to move, become alive, or become fully animated and autonomous of its own accord. It is most commonly induced under the influence of heavy dosages of deliriant compounds, such as DPH, datura, and benzydamine.&lt;/p&gt;
    &lt;p&gt;Scenery slicing is the experience of a person‚Äôs visual field appearing to split into separate, cleanly cut sections. These individual slices then proceed to drift slowly away from their original position before disappearing and resetting to normal. It is most commonly induced under the influence of moderate dosages of dissociative compounds, such as ketamine, PCP, and DXM.&lt;/p&gt;
    &lt;p&gt;Texture liquidation is the experience of the texture, shape, and general structure of objects and scenery appearing progressively simplified, smudged, and stylized in such a way that one‚Äôs external environment begins to take on the aesthetic of a painting or cartoon. It is most commonly induced under the influence of moderate dosages of psychedelic compounds, such as LSD, psilocybin, and mescaline.&lt;/p&gt;
    &lt;p&gt;Unspeakable horrors describe the experience of prolonged exposure to indescribable scenarios and hallucinatory content of a scary and disturbing nature, which are often directly influenced by a person‚Äôs fears. They are most commonly induced under the influence of heavy dosages of psychedelic compounds, such as LSD, psilocybin, and 2C-P.&lt;/p&gt;
    &lt;p&gt;Visual exposure to inner mechanics of consciousness&lt;/p&gt;
    &lt;p&gt;Visual exposure to inner mechanics of consciousness is the experience of being exposed to a mass of visual geometry comprised entirely of innately readable representations which subjectively feel as if they convey the inner mechanics that compose all underlying neurological processes.&lt;/p&gt;
    &lt;p&gt;Lead image: Josie Kins / YouTube&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45860229</guid><pubDate>Sat, 08 Nov 2025 21:32:30 +0000</pubDate></item><item><title>Debugging BeagleBoard USB boot with a sniffer: fixing omap_loader on modern PCs</title><link>https://www.downtowndougbrown.com/2025/11/debugging-beagleboard-usb-boot-with-a-sniffer-fixing-omap_loader-on-modern-pcs/</link><description>&lt;doc fingerprint="b43e4190da629599"&gt;
  &lt;main&gt;
    &lt;p&gt;This post is about the original OMAP3530 BeagleBoard from 2008. Yes, the one so old that it doesn‚Äôt even show up in the board list on BeagleBoard.org anymore. The BeagleBoard, not the BeagleBone. During my Chumby 8 kernel escapades, at one point I ran into a UART bug that affected multiple drivers, including the omap-serial driver. This led me to buy a BeagleBoard so I could verify the omap-serial bug on hardware.&lt;/p&gt;
    &lt;p&gt;After I figured out the bug with the UART driver, I realized that the OMAP3530 has support for booting from USB, so I decided to go off on a random tangent to get USB boot working. There was no problem I was trying to solve or anything like that. I just thought it would be a fun experiment (am I a masochist?). Little did I know, I would be getting myself into some tricky USB packet analysis.&lt;/p&gt;
    &lt;p&gt;I struggled to find info about this process because of how old the OMAP is today. The main utility I found was a program called omap_loader by Grant Hernandez, which is a newer rewrite of Martin Mueller‚Äôs original omap3_usbload circa 2008. Thanks to some lucky searching combined with the Internet Archive, I connected the dots between 2008 and the present. At some point before 2013, Rick Bronson provided an update to omap3_usbload (along with a patch to TI‚Äôs X-Loader bootloader) that enabled uploading additional files like a full U-Boot and Linux kernel into RAM after X-Loader, all through USB. This unlocked the ability to boot all the way to Linux from a completely blank BeagleBoard. Grant‚Äôs newer omap_loader utility also incorporates these same improvements.&lt;/p&gt;
    &lt;p&gt;All of this research was difficult. Many of the links I found pointed to sites like gitorious.org and arago-project.org, both of which no longer exist (although Arago‚Äôs Git repos are now hosted by TI). eLinux.org‚Äôs BeagleBoard wiki was totally rearranged at some point and lost its info about USB recovery, and Rick‚Äôs site no longer exists, but as usual, the Internet Archive saved the day.&lt;/p&gt;
    &lt;p&gt;At some point later on, X-Loader was replaced by U-Boot SPL, so I think that is partially why so much of this info eventually disappeared from the web. But it‚Äôs a darn shame. This USB booting functionality is really cool, and it seems like most of the documentation for it has slowly gone by the wayside! The main breadcrumbs remaining on modern Google are the newer omap_loader utility, and also some references to Nest thermostats. For example, Nest‚Äôs X-Loader had the USB patch applied (with some tweaks added).&lt;/p&gt;
    &lt;p&gt;With all that research out of the way, I was ready to try it all out. I compiled omap_loader, grabbed the pre-built binary of x-load.bin that was included with Rick‚Äôs patchset, and also used a u-boot.bin that I had compiled myself using Buildroot while performing my UART tests with a modern kernel on the BeagleBoard. Then, I tried to load it:&lt;/p&gt;
    &lt;quote&gt;$ sudo ./omap_loader -p 0xd009 -f x-load.bin -f u-boot.bin -a 0x80800000 -j 0x80800000 -v&lt;lb/&gt;OMAP Loader 1.0.0&lt;lb/&gt;File 'x-load.bin' at 0x40200000, size 26956&lt;lb/&gt;File 'u-boot.bin' at 0x80800000, size 777760&lt;lb/&gt;[+] scanning for USB device matching 0451:d009...&lt;/quote&gt;
    &lt;p&gt;The idea behind this command is it sends X-Loader (x-load.bin) as the main payload that the OMAP‚Äôs on-chip bootloader is listening for over USB. Then, X-Loader starts up. Next, omap_loader sends any additional files using X-Loader‚Äôs USB protocol. In this case, I‚Äôve supplied one extra file: u-boot.bin, which I told it to load into RAM at 0x80800000. Finally, the &lt;code&gt;-j 0x80800000&lt;/code&gt; argument tells X-Loader to jump into U-Boot rather than hanging around doing nothing afterward.&lt;/p&gt;
    &lt;p&gt;The output of the command looked normal so far. I plugged in my BeagleBoard, which didn‚Äôt have an SD card inserted and also had its NAND flash erased, so it had no bootloader installed and thus it would attempt a USB boot.&lt;/p&gt;
    &lt;quote&gt;[+] successfully opened 0451:d009 (Texas Instruments OMAP3430)&lt;lb/&gt;[+] got ASIC ID - Num Subblocks [05], Device ID Info [01050134300757], Reserved [13020100], Ident Data [1215010000000000000000000000000000000000000000], Reserved [1415010000000000000000000000000000000000000000], CRC (4 bytes) [150901f7488f2800000000]&lt;lb/&gt;[-] fatal transfer error (BULK_OUT) for 26956 bytes (0 made it): LIBUSB_ERROR_PIPE&lt;lb/&gt;[-] failed to send file 'x-load.bin' (size 26956)&lt;lb/&gt;[-] failed to transfer the first stage file 'x-load.bin'&lt;/quote&gt;
    &lt;p&gt;Darn. The utility recognized the BeagleBoard being plugged in, but libusb errored out with a pipe error. Long story short, I messed around with a few other computers, and I found that a few of my older computers, old enough that they didn‚Äôt have USB 3.0 ports on their motherboards, actually worked perfectly fine with omap_loader. I couldn‚Äôt get it to work properly with most of my modern machines though, AMD or Intel.&lt;/p&gt;
    &lt;p&gt;I thought this would be a great application for a USB sniffer, so I decided to record some traces of success versus failure.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs a link to my in-depth investigation comparing success versus failure on the GitHub issue about this problem. Yep, it turns out I wasn‚Äôt the only one running into this exact same issue. Grant himself was seeing similar problems, and had come to a similar conclusion that it seemed to be machine-dependent. Other people had mentioned that adding delays at certain points in the code seemed to help. I was intrigued, so I tried to get to the bottom of it.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs what the USB boot process is supposed to look like, according to TI‚Äôs OMAP35x Technical Reference Manual:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The OMAP device enumerates as a USB device.&lt;/item&gt;
      &lt;item&gt;Within 300 ms, the host needs to read an ‚ÄúASIC ID‚Äù structure from the OMAP or else it will disconnect from USB.&lt;/item&gt;
      &lt;item&gt;Then, the host sends a 4-byte command: 0xF0030002 means to continue booting through USB.&lt;/item&gt;
      &lt;item&gt;Next, the host sends the 4-byte length of bootloader data it wants to transfer.&lt;/item&gt;
      &lt;item&gt;Finally, the host sends the bootloader (X-Loader in this case), which will be loaded into internal SRAM starting at 0x40200000.&lt;/item&gt;
      &lt;item&gt;After the OMAP device receives all of the data, it runs the received bootloader by jumping to 0x40200000.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Again, this process worked perfectly fine on my older computers that don‚Äôt support USB 3.0, but on my newer computers with USB 3.0, it was hanging up. I did notice that the newer computers were trying to fit a lot more data into a single USB frame. For example, the start of my older computer‚Äôs communication with the OMAP looked like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frame 1 &lt;list rend="ul"&gt;&lt;item&gt;Host sends boot command&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Frame 2 &lt;list rend="ul"&gt;&lt;item&gt;Host sends length&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Frame 3 &lt;list rend="ul"&gt;&lt;item&gt;Host sends first packet of bootloader data&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;item&gt;Host sends second packet of bootloader data&lt;/item&gt;&lt;item&gt;OMAP says it‚Äôs not ready&lt;/item&gt;&lt;item&gt;Host pings&lt;/item&gt;&lt;item&gt;OMAP says it‚Äôs ready now&lt;/item&gt;&lt;item&gt;Host sends second packet of bootloader data again&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And then from that point on, it was just a process of sending the rest of the data like that. About 5 data packets would fit into each frame. My newer computer‚Äôs traffic looked like this instead:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frame 1 &lt;list rend="ul"&gt;&lt;item&gt;Host sends boot command&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;item&gt;Host sends length&lt;/item&gt;&lt;item&gt;OMAP says it‚Äôs not ready&lt;/item&gt;&lt;item&gt;Host pings a few times until the OMAP is ready&lt;/item&gt;&lt;item&gt;Host sends length again&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;item&gt;Host sends first packet of bootloader data&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;item&gt;Host sends second packet of bootloader data&lt;/item&gt;&lt;item&gt;OMAP says it‚Äôs not ready&lt;/item&gt;&lt;item&gt;Host pings several times, OMAP never says it‚Äôs ready during the rest of this frame&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Frame 2 &lt;list rend="ul"&gt;&lt;item&gt;Host pings&lt;/item&gt;&lt;item&gt;OMAP responds with a STALL packet&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The newer xHCI host controller was trying its best to efficiently squeeze a lot of packets into the first frame. Even though this is a pattern that should be perfectly valid to follow when communicating with a USB device, the OMAP bootloader was clearly not happy about something, and eventually sent a STALL packet before omap_loader made much progress. Various USB packet traces on different modern computers revealed similar issues. It would either STALL after the second packet, or just NAK forever and never accept additional incoming data.&lt;/p&gt;
    &lt;p&gt;Inspired by other comments about adding delays, I tried to work around this by inserting an artificial 1 ms delay before every &lt;code&gt;libusb_bulk_transfer()&lt;/code&gt; call. This would force modern machines to slow down a little bit. As soon as I added those delays, all of my new computers had no trouble uploading X-Loader to the OMAP. So yeah, I think the OMAP just doesn‚Äôt like receiving USB data too quickly.&lt;/p&gt;
    &lt;p&gt;That wasn‚Äôt the end of this little project, though. The 1 ms delay fixed the issue with getting X-Loader to run, but the newer computers also ran into problems while trying to upload U-Boot through X-Loader!&lt;/p&gt;
    &lt;quote&gt;[-] device timed out while transfering in 512 bytes (got 0)&lt;lb/&gt;[-] device timed out while transfering in 512 bytes (got 0)&lt;lb/&gt;[-] device timed out while transfering in 512 bytes (got 0)&lt;lb/&gt;[-] failed to read command from X-Loader&lt;lb/&gt;[-] failed to transfer the additional files in to memory&lt;/quote&gt;
    &lt;p&gt;Rats. I went back to the USB sniffer for more research.&lt;/p&gt;
    &lt;p&gt;This time, it was a different problem. I found the point where the host would try to read the initial request from X-Loader: &lt;code&gt;USBf&lt;/code&gt;. On my older computer, this worked fine; it received a 13-byte string from X-Loader: &lt;code&gt;USBffile req&lt;/code&gt; followed by a null terminator. It was happy with this, and omap_usbload kept going on with the rest of the file load process and everything succeeded.&lt;/p&gt;
    &lt;p&gt;On the newer computer, some shenanigans were going on. Let‚Äôs look at the USB trace in depth:&lt;/p&gt;
    &lt;p&gt;The 335-byte packet contains 332 actual bytes of data (the packet ID and CRC account for the other 3 bytes), and is the final chunk of X-Loader. It was successfully received and confirmed by the OMAP with an ACK. At that point, we can assume that the OMAP has begun jumping into X-Loader to start it up.&lt;/p&gt;
    &lt;p&gt;A millisecond later (due to the delay I added), we start trying to read from X-Loader. It‚Äôs clearly too soon, though; I don‚Äôt think X-Loader has finished starting up yet. There‚Äôs nothing ready to read. So these IN/NAK packets continue on for about 5 more milliseconds, which is totally normal. But then, something finally happens: the OMAP stops responding to our IN packets. My computer‚Äôs USB host controller tries three times (see the three IN packets in a row below?) and then it gives up. I‚Äôm guessing this is around the same time that X-Loader is doing its own hardware initialization, so maybe the OMAP‚Äôs USB controller is temporarily disabled.&lt;/p&gt;
    &lt;p&gt;This all makes sense so far. We tried to read too quickly before X-Loader finished starting up, so when it did finally load, there was a brief moment where it would not respond to IN packets. The host controller didn‚Äôt like this and stopped trying, so all we saw from that point on was SOF packets because we weren‚Äôt attempting any more USB reads. Some of my other computers gave up after 15 unanswered IN packets instead of 3. I‚Äôm not sure if that‚Äôs a difference in the host controller or what, but it‚Äôs the same root problem.&lt;/p&gt;
    &lt;p&gt;You may be wondering: why didn‚Äôt the older computers run into this same issue? They were also trying to talk with X-Loader too early, so why wouldn‚Äôt they run into this same roadblock? The answer is that their older host controllers are more tolerant of the missing NAKs. I recorded a similar trace with one of my older computers that works fine without any patches to omap_loader. It also immediately began sending IN packets trying to read from X-Loader way too soon. Just like the problematic computers, it experienced a brief period where the OMAP stopped responding to INs with NAKs. The difference is that it didn‚Äôt abandon hope so quickly. There were 33 unanswered IN packets. After that, the OMAP continued responding with NAKs again and everything was fine from that point on. 17 ms after we had originally finished sending out X-Loader, the OMAP finally responded with an actual data packet. So that‚Äôs the total time it took for X-Loader to launch.&lt;/p&gt;
    &lt;p&gt;Back to the newer computers that weren‚Äôt playing nicely. I was still confused. Even though this is a problem with newer host controllers, omap_loader has a retry mechanism! If it fails to read X-Loader‚Äôs initial data, it will try again 2 seconds later. You‚Äôd think it would succeed at that point. Let‚Äôs see what happens:&lt;/p&gt;
    &lt;p&gt;Ah, interesting. The retry is actually 3 seconds later. I‚Äôm guessing the first failed read attempt had a 1-second timeout, so then with a 2-second retry timer, that adds up to 3 seconds total.&lt;/p&gt;
    &lt;p&gt;Anyway, something funky happens here. The USB host finally reads the 13-byte string from X-Loader as a DATA1 packet (again, it shows up as 16 bytes because of the packet ID and CRC). The host then acknowledges reception with an ACK, but for some bizarre reason, it immediately continues attempting to read more data! I won‚Äôt show the whole trace, but the host keeps polling with IN packets for a whole second. And of course, they‚Äôre all NAKed. X-Loader knows it successfully sent data to us, so it has shifted over to waiting for the host to send an OUT packet instead. It‚Äôs like the host controller gets confused and expects X-Loader to send more data. The kernel never reports those 13 bytes back to libusb, even after the 1-second transfer timeout expires.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt consider myself to be a USB expert, so maybe I‚Äôm misunderstanding something. This behavior just seems wrong, though. When my computer finally reads 13 bytes (proven by the sniffer trace shown above), why isn‚Äôt this data reported back to libusb? I would have expected the reception of a short DATA0/1 packet to cause the host controller to stop reading and return the data back immediately. Is this some kind of strange bug in the Linux kernel or the host controller hardware or something? I don‚Äôt know for sure. I find this behavior to be very odd, and I can‚Äôt explain it. My off-the-cuff guess is that the initial failure to respond to the three IN packets results in something getting out of sync in the host controller, but I really don‚Äôt know for sure. In my opinion, the retry should have worked, but clearly, something got confused. Not sure what. I don‚Äôt think it‚Äôs libusb‚Äôs fault, though.&lt;/p&gt;
    &lt;p&gt;I hate adding arbitrary delays in order to fix things, but a 20-millisecond delay between uploading X-Loader and attempting to read from it fixes this final issue. It ensures that the OMAP has been given ample time to launch X-Loader before we try reading from it, preventing the host controller from encountering the weird situation with unanswered IN packets.&lt;/p&gt;
    &lt;p&gt;After all of this tinkering and patching that I did to get things to play nicely on newer machines, here is a successful run of omap_loader:&lt;/p&gt;
    &lt;quote&gt;[+] successfully opened 0451:d009 (Texas Instruments OMAP3430)&lt;lb/&gt;[+] got ASIC ID - Num Subblocks [05], Device ID Info [01050134300757], Reserved [13020100], Ident Data [1215010000000000000000000000000000000000000000], Reserved [1415010000000000000000000000000000000000000000], CRC (4 bytes) [150901f7488f2800000000]&lt;lb/&gt;[+] uploading 'u-boot.bin' (size 777760) to 0x80800000&lt;lb/&gt;[+] jumping to address 0x80800000&lt;lb/&gt;[+] successfully transfered 2 files&lt;/quote&gt;
    &lt;p&gt;Meanwhile, the following output pops up on the BeagleBoard‚Äôs UART:&lt;/p&gt;
    &lt;quote&gt;Texas Instruments X-Loader 1.5.1 (Nov 15 2011 - 09:36:31)&lt;lb/&gt;Beagle Rev C4&lt;lb/&gt;Trying load from USB&lt;lb/&gt;USBLOAD_CMD_FILE total = 12 addr = 0x73425355 val = 0xbde20 val = 0x80800000&lt;lb/&gt;got file addr = 0x808bde20&lt;lb/&gt;USBLOAD_CMD_JUMP total = 8 addr = 0x6a425355 val = 0x80800000&lt;lb/&gt;U-Boot 2023.10 (May 25 2024 - 22:05:27 -0700)&lt;lb/&gt;OMAP3530-GP ES3.1, CPU-OPP2, L3-165MHz, Max CPU Clock 720 MHz&lt;lb/&gt;Model: TI OMAP3 BeagleBoard&lt;lb/&gt;OMAP3 Beagle board + LPDDR/NAND&lt;lb/&gt;I2C: ready&lt;lb/&gt;DRAM: 256 MiB&lt;lb/&gt;Core: 44 devices, 18 uclasses, devicetree: separate&lt;lb/&gt;NAND: 256 MiB&lt;lb/&gt;MMC: OMAP SD/MMC: 0&lt;lb/&gt;Loading Environment from NAND... *** Warning - bad CRC, using default environment&lt;lb/&gt;Beagle Rev C4&lt;lb/&gt;Timed out in wait_for_event: status=0000&lt;lb/&gt;Check if pads/pull-ups of bus are properly configured&lt;lb/&gt;No EEPROM on expansion board&lt;lb/&gt;OMAP die ID: 79b8000400000000040398da1401c009&lt;lb/&gt;Net: No ethernet found.&lt;lb/&gt;Hit any key to stop autoboot: 2&lt;/quote&gt;
    &lt;p&gt;I believe the ‚ÄúTimed out in wait_for_event‚Äù error is harmless. Anyway, success! It loads U-Boot! You can imagine that I could have easily transmitted a Linux kernel and initramfs as well, and fully booted this thing over USB. Once U-Boot is running, I can do whatever I want.&lt;/p&gt;
    &lt;p&gt;With these simple delay tweaks, omap_loader works great on all modern computers I‚Äôve thrown at it, including Raspberry Pis. The only ‚Äúgotcha‚Äù I‚Äôve encountered is that some slower computers (my i3-7100U laptop and a Raspberry Pi Zero) don‚Äôt forward the USB hotplug event through udev quickly enough before the BeagleBoard decides it‚Äôs not being asked to boot over USB. omap_loader never gets past scanning for a device, even though the &lt;code&gt;dmesg&lt;/code&gt; log clearly shows that it was detected:&lt;/p&gt;
    &lt;quote&gt;[4076310.258842] usb 11-5: new high-speed USB device number 65 using xhci_hcd&lt;lb/&gt;[4076310.407944] usb 11-5: unable to get BOS descriptor or descriptor too short&lt;lb/&gt;[4076310.410041] usb 11-5: New USB device found, idVendor=0451, idProduct=d009, bcdDevice= 0.00&lt;lb/&gt;[4076310.410046] usb 11-5: New USB device strings: Mfr=33, Product=37, SerialNumber=0&lt;lb/&gt;[4076310.410051] usb 11-5: Product: OMAP3430&lt;lb/&gt;[4076310.410054] usb 11-5: Manufacturer: Texas Instruments&lt;lb/&gt;[4076310.710703] usb 11-5: USB disconnect, device number 65&lt;/quote&gt;
    &lt;p&gt;As you can see, it‚Äôs a very short timeframe; just like TI‚Äôs manual says, it only stays connected for about 300 ms if it doesn‚Äôt hear from the host. I guess that‚Äôs not enough time for udev on some computers. The only solution I found for this issue on my slower machines was to compile a custom version of libusb with udev disabled, which forces it to directly use netlink for hotplug detection instead.&lt;/p&gt;
    &lt;p&gt;My patch also limits libusb transfers to 512 bytes at a time. I don‚Äôt think this change is critical, though. It fixed an issue I ran into where my bus was really loaded and libusb reported a memory error. I don‚Äôt think it actually helps anything in most cases as long as people aren‚Äôt performing crazy big USB transfers at the same time.&lt;/p&gt;
    &lt;p&gt;In summary:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Trying to write USB data to the OMAP‚Äôs on-chip bootloader too quickly seems to hit some edge cases that it doesn‚Äôt handle correctly. A 1 ms delay fixes this.&lt;/item&gt;
      &lt;item&gt;Trying to read from X-Loader before it‚Äôs ready to go irritates newer USB host controllers when they send out several IN packets without receiving any response (not even a NAK). A 20 ms delay fixes this. &lt;list rend="ul"&gt;&lt;item&gt;Even retries afterward fail; the host controller gets out of sync due to the unanswered IN packets or something like that.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;On some slower computers, udev doesn‚Äôt give you enough time to respond to the OMAP‚Äôs 300 ms timeout, so libusb never detects the hotplug. This can be solved with a custom libusb that uses netlink instead of udev.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I opened up a PR to submit these fixes (except for the udev thing) upstream to omap_loader in 2024. Why am I writing about this now? Well, remember when I mentioned Nest earlier? Google ended support for older Nest thermostats last month, which renewed some interest in merging my reliability improvements so that people can flash custom firmware to their Nest thermostats. Those old Nest devices also use OMAP processors.&lt;/p&gt;
    &lt;p&gt;What it boils down to is: all this tinkering I did last year with pointlessly booting old BeagleBoards over USB accidentally ended up being useful. It helped out some Nest thermostat revival projects that have been popping up in the last month. So I thought now might be a fun time to talk about my tiny involvement with that. Yay! It‚Äôs always fun when a random side project unexpectedly helps other people.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45860638</guid><pubDate>Sat, 08 Nov 2025 22:30:58 +0000</pubDate></item><item><title>Ironclad ‚Äì formally verified, real-time capable, Unix-like OS kernel</title><link>https://ironclad-os.org/</link><description>&lt;doc fingerprint="6f56f93a45a93f90"&gt;
  &lt;main&gt;
    &lt;p&gt;Ironclad is a formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software.&lt;/p&gt;
    &lt;p&gt;Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling.&lt;/p&gt;
    &lt;p&gt;Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source.&lt;/p&gt;
    &lt;p&gt;SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of huge swathes of Ironclad, like cryptography, MAC, and user-facing facilities.&lt;/p&gt;
    &lt;p&gt;Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.&lt;/p&gt;
    &lt;p&gt;Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more.&lt;/p&gt;
    &lt;p&gt;This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page.&lt;/p&gt;
    &lt;p&gt;Additionally, we would like to thank the following organizations:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45860843</guid><pubDate>Sat, 08 Nov 2025 23:03:10 +0000</pubDate></item><item><title>Judge denies request to exempt Flock footage from Public Records Act</title><link>https://www.goskagit.com/news/local_news/court-denies-request-that-it-find-flock-safety-camera-data-is-exempt-from-public-records/article_f1edd028-d242-479c-ada8-f2dfca73a1b1.html</link><description>&lt;doc fingerprint="ea81b2f892b756d1"&gt;
  &lt;main&gt;
    &lt;p&gt;The cities of Sedro-Woolley and Stanwood were denied Thursday their request for a declaratory judgment that the data and images from Flock Safety cameras are not public records.&lt;/p&gt;
    &lt;p&gt;The ruling was made by Skagit County Superior Court Judge Elizabeth Neidzwski.&lt;/p&gt;
    &lt;p&gt;Flock Safety cameras are used by many law enforcement agencies, including the Sedro-Woolley and Stanwood police departments.&lt;/p&gt;
    &lt;p&gt;The cameras record images of passing cars, and using artificial intelligence the system is able to identify cars‚Äô makes, models, colors and license plates. Flock said it deletes the data after 30 days.&lt;/p&gt;
    &lt;p&gt;The cities of Sedro-Woolley and Stanwood filed a motion for a declaratory judgment after receiving public records requests for images recorded by Flock Safety cameras.&lt;/p&gt;
    &lt;p&gt;The requests were made by the same man ‚Äî Jose Rodriguez. He requested images from Stanwood‚Äôs cameras from 5 to 6 p.m. on March 30, and from Sedro-Woolley‚Äôs cameras from 5 to 5:30 p.m. on May 5.&lt;/p&gt;
    &lt;p&gt;Rodriguez claims that the Stanwood Police Department informed him that it is not the holder of the records, but rather it is Flock Safety, and directed him to Flock‚Äôs website.&lt;/p&gt;
    &lt;p&gt;When Rodriguez requested the images from the Sedro-Woolley Police Department, he was advised that the city would seek a declaratory judgment on the status of Flock data.&lt;/p&gt;
    &lt;p&gt;Law enforcement has said the data recorded by the Flock Safety cameras is only accessed during active investigations, such as during a missing persons case.&lt;/p&gt;
    &lt;p&gt;Both the cities of Sedro-Woolley and Stanwood have turned off their Flock Safety cameras during the legal dispute.&lt;/p&gt;
    &lt;p&gt;In October, both motioned for declaratory judgment.&lt;/p&gt;
    &lt;p&gt;The cities were seeking a declaration that the data and images requested were not public records under the state Public Records Act, and if a judge decided that they were public records they should be exempt from public disclosure as disclosure is contrary to public policy, and exempt as they constitute specific intelligence information.&lt;/p&gt;
    &lt;p&gt;Emily Guildner, a lawyer representing the two cities, argued in court Thursday that if these are considered public records, it could have compounding effects on public privacy.&lt;/p&gt;
    &lt;p&gt;She argued that the data and images on cameras aren‚Äôt readily available to police until they make a query during an investigation, and that if the data isn‚Äôt regularly available to police, it shouldn‚Äôt be available to the public.&lt;/p&gt;
    &lt;p&gt;There are concerns among law enforcement surrounding Flock Safety cameras and federal immigration enforcement.&lt;/p&gt;
    &lt;p&gt;An October University of Washington study titled ‚ÄúLeaving the Door Wide Open‚Äù found that U.S. Border Patrol searched 17 Washington agencies‚Äô Flock data. Most of the searches were done without law enforcements‚Äô awareness.&lt;/p&gt;
    &lt;p&gt;These concerns with immigration enforcement complicate whether they should be public records.&lt;/p&gt;
    &lt;p&gt;Neidzwski also said that the AI component of these cameras adds complexity.&lt;/p&gt;
    &lt;p&gt;Timothy Hall, who represents Rodriguez, argued that the Flock data is not exempt from the Public Records Act.&lt;/p&gt;
    &lt;p&gt;He said the data held by Flock serves a purpose to government.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe government agencies do not need to possess documents in order for the Public Records Act to apply to them,‚Äù Hall said.&lt;/p&gt;
    &lt;p&gt;He cited a 2015 case between Cedar Grove Composting and the city of Marysville in which the state Supreme Court ruled that documents prepared by a third party and shared with the city were subject to the Public Record Act.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45861829</guid><pubDate>Sun, 09 Nov 2025 00:53:07 +0000</pubDate></item><item><title>How Airbus Took Off</title><link>https://worksinprogress.co/issue/how-airbus-took-off/</link><description>&lt;doc fingerprint="f5e48050ae83878f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Airbus is an example of successful industrial policy and the rare European company that is better than its American rival. Could its success be copied elsewhere?&lt;/head&gt;
    &lt;p&gt;Would you rather fly in an Airbus or a Boeing? It seems like an easy question.&lt;/p&gt;
    &lt;p&gt;As Alaska Airlines Flight 1282 flight climbed to 16,000 feet on a January evening in 2024, passengers were stunned when a hole was blasted in the side of the plane. They were hit by howling winds as tray tables were ripped from the backs of seats. Were it not for their seatbelts, they would likely have been sucked out of the plane. It later transpired that the plug which sealed the exit door was missing four critical bolts that held it in place.&lt;/p&gt;
    &lt;p&gt;Subscribe for $100 to receive six beautiful issues per year.&lt;/p&gt;
    &lt;p&gt;The Alaska Airlines incident fortunately didn‚Äôt result in any fatalities. Not everyone who has flown on a Boeing 737 MAX in the last few years has been so lucky.&lt;/p&gt;
    &lt;p&gt;2018 and 2019 saw two 737 crashes that killed 346 people after the plane‚Äôs Maneuvering Characteristics Augmentation System, a feature that pushes the plane‚Äôs nose down to prevent stalling, triggered repeatedly due to a faulty sensor. It later transpired that Boeing had not adequately disclosed how the system worked in training manuals.&lt;/p&gt;
    &lt;p&gt;While Boeing wrestles with lawsuits and regulatory investigations, its rival Airbus has stayed out of the headlines ‚Äì a happier place for the manufacturer of commercial airliners.&lt;/p&gt;
    &lt;p&gt;Europe is a graveyard of failed national champions. They span from the glamorous Concorde to obscure ventures like pan-European computer consortium Unidata or notorious Franco-German search engine Quaero.&lt;/p&gt;
    &lt;p&gt;Airbus is the rare success story. European governments pooled resources and subsidized their champion aggressively to face down a titan of American capitalism in a strategically vital sector. Why did Airbus succeed when so many similar initiatives crashed and burned?&lt;/p&gt;
    &lt;p&gt;Airbus prevailed because it was the least European version of a European industrial strategy project ever. It put its customer first, was uninterested in being seen as European, had leadership willing to risk political blowback in the pursuit of a good product, and operated in a unique industry.&lt;/p&gt;
    &lt;head rend="h2"&gt;An industry on the brink&lt;/head&gt;
    &lt;p&gt;In the early days of commercial aviation, US aerospace companies dominated the market for passenger jets.&lt;/p&gt;
    &lt;p&gt;The Buy America Act of 1933 forced the US government to buy from American producers where possible. Military orders supercharged the industry and brought significant knowledge spillovers.&lt;/p&gt;
    &lt;p&gt;The Boeing B-47 bomber, introduced in the late 1940s, pioneered the use of 35-degree swept wings, which point backwards at an angle of 35 degrees and reduce drag at high speeds. This design went on to inspire nearly every commercial airliner around the world.&lt;/p&gt;
    &lt;p&gt;Meanwhile the Boeing 707, the company‚Äôs first ever airliner, shared a fuselage with the KC-135 Stratotanker, a military refueling aircraft.&lt;/p&gt;
    &lt;p&gt;In the face of the US, European aerospace companies cut a sorry figure. The British Aircraft Corporation, Sud Aviation in France, and Messerschmitt-B√∂lkow-Blohm (MBB) in West Germany were all left to compete for orders in a fragmented continental market, with little research or marketing heft. Meanwhile, European airliners who bought American planes could apply for discounted loans from EXIM, the America‚Äôs credit export agency.&lt;/p&gt;
    &lt;p&gt;Between 1960 and 1967, British and French manufacturers saw a 50 percent decline in aircraft deliveries. In 1966, the UK government had even contemplated forcibly merging and nationalizing much of the country‚Äôs industry.&lt;/p&gt;
    &lt;p&gt;European governments had poured money into their national champions in the belief that the maintenance of a civilian aerospace industry was critical for sovereignty, but it was unclear if these companies would survive the decade.&lt;/p&gt;
    &lt;p&gt;Amid this gloomy backdrop, European governments concluded that their industry‚Äôs future depended on cooperation.&lt;/p&gt;
    &lt;p&gt;The UK and France agreed to pool the resources behind Concorde in 1962 to fight what Charles De Gaulle called ‚Äòthe American colonization of the skies‚Äô, but the Germans declined to participate due to their (well-founded) skepticism about the project‚Äôs economics. This didn‚Äôt stop the Germans teaming up with the Dutch on the long-forgotten VFW-Fokker 614. This short-haul jet struggled to find customers at a time when airlines preferred to use cheap prop aircraft for regional city-hopping, dooming the project to collapse once state aid was withdrawn in 1977.&lt;/p&gt;
    &lt;p&gt;In 1965, the French, British, and German governments launched a working group to evaluate the potential of a wide-body commercial aircraft, which would later become the A300. Two years later, the three governments agreed to bear the entire costs of the development of the ‚ÄòEuropean Airbus‚Äô. In 1970, the coalition was formalized with the creation of Airbus Industrie. The consortium quickly expanded to include Spain and the Netherlands.&lt;/p&gt;
    &lt;head rend="h2"&gt;The making of a world leader&lt;/head&gt;
    &lt;p&gt;So how did this unlikely band of brothers go on to build a global leader, rather than another Econ101 case study about the perils of industrial policy?&lt;/p&gt;
    &lt;p&gt;The single biggest factor was a focus on the customer.&lt;/p&gt;
    &lt;p&gt;Unlike many future industrial strategy projects, which would focus on creating European-owned capabilities for their own sake, the Airbus team were seized by the need to build a jet that airliners would want to buy. They didn‚Äôt have much choice: if they failed, there was a reasonable chance the consortium‚Äôs domestic aerospace suppliers would collapse.&lt;/p&gt;
    &lt;p&gt;They were helped enormously in this by their setup. While Airbus didn‚Äôt become a unified corporate entity until 2001, the partnership had a strong central leadership from the beginning. Unlike other industrial consortia, which tended to be leaderless venues for intra-European turf wars, Airbus united marketing, procurement, and design.&lt;/p&gt;
    &lt;p&gt;Roger B√©teille, who led the A300 program, probably bears more responsibility for Airbus‚Äôs early success than anyone else. B√©teille wasn‚Äôt interested in building an inferior European Boeing copy. Instead, he invested significant time in getting to know his potential customers and what they needed. This led to Airbus quickly tossing the original design for a 300-seat A300, in favor of a 225-250 seater, when it became clear that Air France and Lufthansa wanted a smaller product.&lt;/p&gt;
    &lt;p&gt;The revised A300B would prove much cheaper to develop, in part because it allowed the consortium to dispense with the expensive Rolls Royce engine in favour of a cheaper American alternative. In response, the UK exited the project, only to later return with a lower ownership stake.&lt;/p&gt;
    &lt;p&gt;This willingness to risk political blowback and avoid petty chauvinism in equipment choice was rare in industrial strategy.&lt;/p&gt;
    &lt;p&gt;B√©teille went one step further. He designated English the official language of the project, instead of the usual mixture of languages that characterised European projects, and forbade the use of metric measurements to make it easier to sell into the US market.&lt;/p&gt;
    &lt;p&gt;Along with Felix Kracht, Airbus‚Äôs first production director, B√©teille set a division of labour between the different countries that has persisted, with minor adjustments. French firms handled the cockpit, control systems, and lower-center fuselage; Hawker Siddeley (the inventor of the Harrier jump jet) in the UK designed and built the wings; German companies produced various fuselage sections; the Netherlands managed moving wing components; and Spain was responsible for the horizontal tailplane.&lt;/p&gt;
    &lt;p&gt;Based on B√©teille‚Äôs market research, the A300B was optimised for fuel efficiency. The team stripped out unnecessary weight by using composite materials and raised the cabin floor to add cargo space. Hawker Siddeley‚Äôs wings, which would go on to influence industry standards, were designed with a curved shape on top to reduce air resistance, allowing greater lift and fuel efficiency.&lt;/p&gt;
    &lt;p&gt;At a time when almost every commercial jet had three or four engines, Airbus opted for a twin-engine design. The plane could theoretically fly on one and the company concluded that only a single extra engine was needed to provide redundancy for safety. The much cheaper twin-engine design is now the industry standard, even for ultra long-haul flights.&lt;/p&gt;
    &lt;p&gt;Despite the technical ingenuity behind the A300B, early business was slow. By the time the aircraft entered service in 1974, it had struggled to attract commercial interest beyond state-owned flag carriers like Air France, which had placed the first A300B order in 1971 for six jets. Even these airlines continued to operate Boeing-dominated fleets.&lt;/p&gt;
    &lt;p&gt;One problem was unfortunate timing: the oil shock of 1973 had caused operating costs to spiral for airliners, so there was little appetite for experimentation in the air.&lt;/p&gt;
    &lt;p&gt;There was also residual suspicion of European industry among US airliners. Sud Aviation‚Äôs Caravelle had been used by some American airliners, but the company was notorious for its sloppy after sales maintenance and service. There had also been an ugly dispute over landing rights for Concorde, with the US heavily restricting the aircraft‚Äôs operation out of noise concerns. The French suspected more sinister commercial motivations were at work. Jacques Chirac, then French Prime Minister, raised the temperature, declaring that: ‚ÄòThe Airbus consortium will not be daunted by the Americans who killed off the Concorde. ‚Ä¶ We will fight any trade war blow-by-blow as the future of the aeronautical industry and their employees is at stake‚Äô.&lt;/p&gt;
    &lt;p&gt;Against this backdrop, Airbus did everything it could to deemphasize its European heritage as it toured the US. It refused to involve the French or German embassies in its sales efforts, much to their irritation. Airbus representatives drove home how a third of the plane‚Äôs value derived from US-made components, more than any single European partner nation‚Äôs contribution. They also mastered the world of DC lobbying, successfully outmaneuvering Boeing and Lockheed‚Äôs attempts to use anti-trust regulations to shut the European entrant out of the US market.&lt;/p&gt;
    &lt;p&gt;Sustained by early European market commitments and early sales in Asia, Airbus was eventually able to clinch its first US order in 1977. Eastern Airlines (EAL), which had been impressed by the A300B‚Äôs fuel economy and low noise levels, agreed to the trial lease of four aircraft and three spare engines for ‚Ä¶ one dollar. These terms would have been unconscionable for a normal private company, but they were transformative for state-backed Airbus‚Äôs fortunes. Frank Borman, conservative Republican, former NASA astronaut, and EAL‚Äôs CEO emerged as a public champion of the A300B as an ‚ÄòAmerican aircraft‚Äô.&lt;/p&gt;
    &lt;head rend="h2"&gt;The A320&lt;/head&gt;
    &lt;p&gt;B√©teille and Kracht weren‚Äôt content with building one aircraft. From the beginning, Airbus had targeted a 30 percent global market share. This meant building more than wide-body aircraft like the A300B.&lt;/p&gt;
    &lt;p&gt;The A320, which entered operation in 1988 was a narrow-bodied aircraft that could carry 150-180 passengers. It was optimized to fly short- and medium-haul routes economically, and a masterclass in engineering and timing.&lt;/p&gt;
    &lt;p&gt;By the 1980s, airliners were looking to replace their aging narrow-bodied fleets, with the Boeing 272 and McDonnell Douglas DC-9 having been in operation for more than two decades.&lt;/p&gt;
    &lt;p&gt;The A320 was the first commercial aircraft to implement full digital fly-by-wire controls. Before the A320, the pilot‚Äôs controls pulled physical cables attached to the flaps, rudder, and other control surfaces on the plane. Fly-by-wire meant that controls sent electric signals to the plane‚Äôs computers, which then commanded motors to move the control surfaces. This made life easier for the pilots by reducing the need for constant manual adjustment and stripped out heavy components that needed maintenance.&lt;/p&gt;
    &lt;p&gt;The A320 was also the first commercial aircraft to introduce envelope protection, a system that automatically prevents dangerous actions, such as tilting too steeply, flying too slowly, or making maneuvers that could overstress the aircraft structure.&lt;/p&gt;
    &lt;p&gt;Again, the A320 wasn‚Äôt an overnight success, with new technology and existing relations with Boeing slowing uptake. Airbus again relied on British and French orders to gain market credibility. But by the early 1990s, its superior technology combined with Airbus‚Äôs willingness to flex the design, with the A319 (smaller) and A321 (larger) allowing airliners to operate mixed fleets with common cockpits, began to win fans. The A320 is now the most popular airliner family in history and remains in widespread use today.&lt;/p&gt;
    &lt;p&gt;The success of the A320 led Airbus to profitability in the mid-1990s. By 2019, Airbus had displaced Boeing as the largest aerospace company by revenue.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Airbus‚Äôs success is so hard to repeat&lt;/head&gt;
    &lt;p&gt;If Airbus proves industrial strategy can work, why haven‚Äôt other European ventures fared better?&lt;/p&gt;
    &lt;p&gt;Good industrial strategy requires favorable market conditions, consistent strategy in the face of political headwinds, and the courage to call it a day if failure seems likely. Getting one of these right is tough, and all three is exceptionally rare.&lt;/p&gt;
    &lt;p&gt;Concorde was a marvel of engineering, but even without US obstructionism, it had little prospect of commercial viability. In today‚Äôs money, it cost ¬£16 billion to develop, roughly ten times the cost of the Boeing 727, making it the most expensive plane of its age by some margin. Its limited passenger capacity, fuel inefficiency, and expensive maintenance meant that a ticket for a round trip cost in excess of ¬£10,000 adjusted for inflation. The ultra-premium air travel market wasn‚Äôt big enough in the 1980s or 1990s to bear the costs of 1960s technology, leading to Concorde‚Äôs retirement in 2003.&lt;/p&gt;
    &lt;p&gt;Other European projects have lacked the centralized control or clear rationale that characterized Airbus.&lt;/p&gt;
    &lt;p&gt;We see this in Unidata, a 1973 consortium that brought together CII (France), Philips (the Netherlands), and Siemens (Germany) to produce a European mainframe line to rival IBM. With no clear leadership, rival members of the consortium pushed their own hardware and software approaches. Engineering efforts were duplicated. The project collapsed within two years amid recriminations.&lt;/p&gt;
    &lt;p&gt;Meanwhile, it was unclear why the 2005 Franco-German search engine project Quaero ever needed to exist. Widely seen as a vanity project at the time, the attempt to build a search engine by committee similarly splintered along national lines. It was also a victim of mission creep, evolving from a direct Google competitor to a multimedia search platform that would be powered by image and voice analysis. The project limped on until its mercy killing in 2013.&lt;/p&gt;
    &lt;p&gt;It‚Äôs also easier to build a global leadership position when your main rival wages a prolonged campaign of self-sabotage. By the new millennium, the competition had been reduced to a simple showdown between Airbus and Boeing. Lockheed had decided to bail on commercial aviation in the 1970s after losing billions of dollars on the L-1011, while Boeing acquired McDonnell Douglas in a $13 billion deal in 1997.&lt;/p&gt;
    &lt;p&gt;While Airbus has retained a strong engineering culture at the helm, this disappeared from Boeing. Harry Stonecipher, Boeing‚Äôs CEO in the early 2000s, notoriously claimed that: ‚ÄòWhen people say I changed the culture of Boeing, that was the intent, so that it is run like a business rather than a great engineering firm‚Äô.&lt;/p&gt;
    &lt;p&gt;Stonecipher‚Äôs successor, James McNerney, took this even further: ‚ÄòEvery 25 years a big moonshot‚Ä¶ and then produce a 707 or a 787 ‚Äì that‚Äôs the wrong way to pursue this business. The more-for-less world will not let you pursue moonshots‚Äô.&lt;/p&gt;
    &lt;p&gt;The McDonnell Douglas acquisition is often marked as a turning point for Boeing. Despite being the acquiring firm, Boeing absorbed much of their target‚Äôs management philosophy. This disconnect was embodied in the company‚Äôs decision to move its headquarters from Seattle (where its main production facility was located) to Chicago, for the sake of just $63 million in tax credits. Fatal crashes in 2018 and 2019 have since caused regulatory investigations and multi-billion dollar compensation claims to pile up, as well as allegations that the company has put shareholders and dividends before safety.&lt;/p&gt;
    &lt;head rend="h2"&gt;A strange industry&lt;/head&gt;
    &lt;p&gt;Does the Airbus story make a good case for a disciplined, well-executed industrial strategy?&lt;/p&gt;
    &lt;p&gt;To answer this question, we need to take a step back from Airbus and Boeing and think about their customers.&lt;/p&gt;
    &lt;p&gt;Airlines have one of the worst business models of any industry. They have eye-watering capital expenditures (a large jet costs in excess of $200 million). The product offering (flights) is relatively undifferentiated, while many of their customers are price-conscious and disloyal. Safety regulations, along with route and landing slot regulations mean there‚Äôs little space to drive painless efficiencies. This leaves airlines with two main routes to success: worsening their service through cost-cutting and engaging in kamikaze price wars.&lt;/p&gt;
    &lt;p&gt;This is why airlines frequently go bankrupt, with US Airways, United Airlines, Northwest Airlines, Delta Air Lines and American Airlines among the dozens to almost collapse in the 2000s. Only three airlines without state ties (Southwest, Ryanair, and Copa) have consistently maintained profitability while avoiding bankruptcy or major restructuring.&lt;/p&gt;
    &lt;p&gt;In his 2007 letter to Berkshire Hathaway shareholders, Warren Buffett described the airline industry as ‚Äòthe worst sort of business‚Äô, and noted that, ‚Äòif a farsighted capitalist had been present at Kitty Hawk, he would have done his successors a huge favor by shooting Orville down‚Äô.&lt;/p&gt;
    &lt;p&gt;Airbus, as a supplier to these businesses, has not been immune to these pressures. In the early 2000s, airliners were enthused about the ‚Äòhub and spoke‚Äô model. Passengers would fly on large aircraft between major hubs, then transfer to smaller aircraft for their final destinations. With a maximum capacity of over 800, the double-decker Airbus A380 would help allow airliners to consolidate their flights between busy international hubs. By the time it entered commercial operation in 2007, fashions had reversed and consumers were willing to pay a premium to fly direct. Airbus never came close to recouping its $25 billion development costs.&lt;/p&gt;
    &lt;p&gt;Against this backdrop, companies like Airbus and Boeing face a constant downward price pressure, operating on single digit margins in good years. The merry-go-round of buyers as airliners fall in and out of bankruptcy makes them fickle customers. With this in mind, Boeing‚Äôs desire to slash costs seems like a much more rational response, even if its execution was flawed.&lt;/p&gt;
    &lt;p&gt;It may be nearly impossible to operate the multi-billion dollar, multi-decade product development cycle this industry requires without some form of government backstop, whether it is a direct subsidy (Airbus) or reliable military orders (Boeing).&lt;/p&gt;
    &lt;p&gt;It is a business that is well-suited to subsidy for other reasons too. Governments are generally better at supporting companies in established markets where innovation takes place slowly and incrementally. This is likely why state-backed efforts have found it easier to be competitive against aerospace companies than Silicon Valley giants working at breakneck pace to keep pace with changing consumer tastes.&lt;/p&gt;
    &lt;p&gt;We can learn from Airbus‚Äôs engineering ingenuity and relentless customer focus. But its success in such an idiosyncratic sector probably isn‚Äôt as template for successful industrial policy in many of the other sectors that some people would like it to be.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45861984</guid><pubDate>Sun, 09 Nov 2025 01:19:00 +0000</pubDate></item><item><title>IRIX Introduction</title><link>http://www.sgistuff.net/software/irixintro/index.html</link><description>&lt;doc fingerprint="bd3c131148cca9cc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;IRIX Introduction&lt;/head&gt;
    &lt;head rend="h2"&gt;Brief History&lt;/head&gt;
    &lt;p&gt;The first operating system developed for SGI systems ran on the IRIS line of terminals and workstations based on Motorola CPUs (see GL2 history). When the MIPS based IRIS 4D systems were introduced the 4D1 operating system accompanied these computers.&lt;/p&gt;
    &lt;p&gt;The earliest common version is 4D1-3.0 (1988). IRIX 3.x was based on UNIX System V Release 3 with 4.3BSD enhancements, and incorporated the 4Sight windowing system, based on NeWS and IRIS GL.&lt;/p&gt;
    &lt;p&gt;The next major version (4D1-4.0) was introduced in 1991. SGI replaced 4Sight with the X Window System (X11R4), using Xsgi and the 4Dwm window manager providing a similar look and feel to 4Sight.&lt;/p&gt;
    &lt;p&gt;When the next version was introduced, the name IRIX was more widely used. IRIX 5.0, released in 1993, incorporated certain features of UNIX System V Release 4, including ELF-format executables. Later on in the IRIX 5 lifecycle the XFS journaling file system was introduced.&lt;/p&gt;
    &lt;p&gt;Beginning with IRIX 6.0, released in 1994 during the IRIX 5 era, full 64-bit support was added. After a few platform specific releases with IRIX 6.5 the last "major" all platform release was introduced.&lt;/p&gt;
    &lt;p&gt;The last IRIX release is IRIX 6.5.30, introduced in August 2006. The IRIX product line was discontinued after this version, according to the press release dated September, 6th 2006 support for IRIX will continue at least until December 2013.&lt;/p&gt;
    &lt;head rend="h2"&gt;Main Versions&lt;/head&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;To decide which IRIX version is suitable for a system it is important to know specific information about the computer itself:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Which system family is it (O2, Indy, Origin 2000, ...)?&lt;/item&gt;
      &lt;item&gt;Which processor is installed?&lt;/item&gt;
      &lt;item&gt;Which graphics hardware is in it (if any)?&lt;/item&gt;
      &lt;item&gt;Are there options that require specific drivers?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Another thing to note is that there are platform specific releases, that were made when some new hardware was introduced. These usually don't support all hardware that was available at the time.&lt;/p&gt;
    &lt;p&gt;This chapter will go on with an introduction to most important all platform IRIX releases. It will conclude with a paragraph containing some considerations and recommendations for the choice of ann appropriate IRIX version.&lt;/p&gt;
    &lt;head rend="h3"&gt;Major Versions&lt;/head&gt;
    &lt;p&gt;Of all IRIX releases the following are the most important:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;IRIX 5.3&lt;/item&gt;
      &lt;item rend="dd-1"&gt;IRIX 5.3 was the last IRIX version to include support for systems with R3000 CPU. So this is the most recent operating system that can be installed on 4D era systems (Personal Iris, PowerSeries and so on).&lt;/item&gt;
      &lt;item rend="dt-2"&gt;IRIX 6.2&lt;/item&gt;
      &lt;item rend="dd-2"&gt;Of the 6.x releases IRIX 6.2 was the first release that did support all current hardware of it's time. Although all of this hardware (except the Crimson) is still supported in the current 6.5 releases IRIX 6.2 can still be a reasonable choice for lowend configurations of Indigo, Indigo 2 or Indy (pre 1996).&lt;/item&gt;
      &lt;item rend="dt-3"&gt;IRIX 6.5.22&lt;/item&gt;
      &lt;item rend="dd-3"&gt;This version is the last to support many of the popular Silicon Graphics classics like the Indigo 2 or Indy which are equipped with R4x00 microprocessors..&lt;/item&gt;
      &lt;item rend="dt-4"&gt;IRIX 6.5.30&lt;/item&gt;
      &lt;item rend="dd-4"&gt;IRIX 6.5.30 is the final IRIX release and is suitable for any of the last Silicon Graphics systems that were equipped with MIPS microprocessors (O2, Octane, Fuel, etc.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Operating System Considerations and Recommendations&lt;/head&gt;
    &lt;p&gt;The following list starts with current systems and goes back to the early IRIS 4D days (for hardware information go to the systems page. In a similar fashion for all the listed systems the most recent operating system will be named, followed by exceptions that make it neccessary to choose an older version.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;O2, O2+, Octane, Octane 2,Fuel&lt;/item&gt;
      &lt;item rend="dd-1"&gt;All of these systems can run a current IRIX 6.5 release.&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Origin 200, Origin 2000, Onyx 2, Origin 300, Onyx 300,Origin 3000, Onyx 3000&lt;/item&gt;
      &lt;item rend="dd-2"&gt;All of these systems can run a current IRIX 6.5 release.&lt;/item&gt;
      &lt;item rend="dt-3"&gt;Indigo 2, Challenge M&lt;/item&gt;
      &lt;item rend="dd-3"&gt;All Indigo 2 / Challenge M can run IRIX 6.5 up to 6.5.22. &lt;list rend="ul"&gt;&lt;item&gt;RAM &amp;lt; 64MB: IRIX 6.2&lt;/item&gt;&lt;item&gt;CPU R4000/100: IRIX 6.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-4"&gt;Indy, Challenge S&lt;/item&gt;
      &lt;item rend="dd-4"&gt;All Indy / Challenge S can run IRIX 6.5 up to 6.5.22. &lt;list rend="ul"&gt;&lt;item&gt;RAM &amp;lt; 64MB: IRIX 6.2&lt;/item&gt;&lt;item&gt;CPU R4000PC, R4600PC: IRIX 6.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt;Challenge, Onyx&lt;/item&gt;
      &lt;item rend="dd-5"&gt;All of these systems can run IRIX 6.5 up to 6.5.22.&lt;/item&gt;
      &lt;item rend="dt-6"&gt;Indigo&lt;/item&gt;
      &lt;item rend="dd-6"&gt;Indigo with R4x00 CPUs can run IRIX 6.5 up to 6.5.22.&lt;lb/&gt;Indigo with R3x00 CPUs are limited to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-7"&gt;Crimson&lt;/item&gt;
      &lt;item rend="dd-7"&gt;All Crimson systems can run up to IRIX 6.2, with the following exception: &lt;list rend="ul"&gt;&lt;item&gt;GTX graphics: IRIX 5.3 (last version to support GTX)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-8"&gt;PowerSeries&lt;/item&gt;
      &lt;item rend="dd-8"&gt;All of these systems can run up to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-9"&gt;Personal Iris&lt;/item&gt;
      &lt;item rend="dd-9"&gt;All of these systems can run up to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-10"&gt;Professional Iris&lt;/item&gt;
      &lt;item rend="dd-10"&gt;All of these systems can run up to IRIX 5.3, with the following exception: &lt;list rend="ul"&gt;&lt;item&gt;G graphics: IRIX 4.0.5 (last version to support G graphics)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Pictures&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX Media / Media Kits&lt;/head&gt;
    &lt;head rend="h3"&gt;Developer Toolbox&lt;/head&gt;
    &lt;head rend="h3"&gt;Support Advantage&lt;/head&gt;
    &lt;head rend="h3"&gt;Indyzone&lt;/head&gt;
    &lt;head rend="h3"&gt;Other&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 3.3 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 4.0.1 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 5.3 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 6.5 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;Cyclone Software&lt;/head&gt;
    &lt;head rend="h2"&gt;Links&lt;/head&gt;
    &lt;head rend="h3"&gt;Technical Reports and White Papers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IRIX 6.1 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;IRIX 6.2 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;Cellular IRIX 6.4 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;XFS White Paper [local copy]&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862071</guid><pubDate>Sun, 09 Nov 2025 01:33:43 +0000</pubDate></item><item><title>Tabloid: The Clickbait Headline Programming Language</title><link>https://tabloid.vercel.app/</link><description>&lt;doc fingerprint="5205455d1cce1ea4"&gt;
  &lt;main&gt;
    &lt;p&gt;Oops, please turn on JavaScript to enjoy Tabloid :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862470</guid><pubDate>Sun, 09 Nov 2025 02:53:45 +0000</pubDate></item><item><title>Show HN: Geofenced chat communities anyone can create</title><link>https://vicinity.social/</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862500</guid><pubDate>Sun, 09 Nov 2025 02:59:58 +0000</pubDate></item><item><title>Syntax and Semantics of Programming Languages (1995)</title><link>https://homepage.cs.uiowa.edu/~slonnegr/plf/Book/</link><description>&lt;doc fingerprint="f3a56b95473fa4a0"&gt;
  &lt;main&gt;
    &lt;p&gt;Syntax and Semantics of Programming Languages Chapter 1 Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Chapter 10 Chapter 11 Chapter 12 Chapter 13 Appendix A Appendix B Title Pages Preface Table of Contents Bibliography Index Acrobat (pdf) viewers To Ken Slonneger's Home Page&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862591</guid><pubDate>Sun, 09 Nov 2025 03:15:33 +0000</pubDate></item><item><title>Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican</title><link>https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/</link><description>&lt;doc fingerprint="bc2fcf3649af53d8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican&lt;/head&gt;
    &lt;p&gt;9th November 2025&lt;/p&gt;
    &lt;p&gt;OpenAI partially released a new model yesterday called GPT-5-Codex-Mini, which they describe as "a more compact and cost-efficient version of GPT-5-Codex". It‚Äôs currently only available via their Codex CLI tool and VS Code extension, with proper API access "coming soon". I decided to use Codex to reverse engineer the Codex CLI tool and give me the ability to prompt the new model directly.&lt;/p&gt;
    &lt;p&gt;I made a video talking through my progress and demonstrating the final results.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a little bit cheeky&lt;/item&gt;
      &lt;item&gt;Codex CLI is written in Rust&lt;/item&gt;
      &lt;item&gt;Iterating on the code&lt;/item&gt;
      &lt;item&gt;Let‚Äôs draw some pelicans&lt;/item&gt;
      &lt;item&gt;Bonus: the --debug option&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;This is a little bit cheeky&lt;/head&gt;
    &lt;p&gt;OpenAI clearly don‚Äôt intend for people to access this model directly just yet. It‚Äôs available exclusively through Codex CLI which is a privileged application‚Äîit gets to access a special backend API endpoint that‚Äôs not publicly documented, and it uses a special authentication mechanism that bills usage directly to the user‚Äôs existing ChatGPT account.&lt;/p&gt;
    &lt;p&gt;I figured reverse-engineering that API directly would be somewhat impolite. But... Codex CLI is an open source project released under an Apache 2.0 license. How about upgrading that to let me run my own prompts through its existing API mechanisms instead?&lt;/p&gt;
    &lt;p&gt;This felt like a somewhat absurd loophole, and I couldn‚Äôt resist trying it out and seeing what happened.&lt;/p&gt;
    &lt;head rend="h4"&gt;Codex CLI is written in Rust&lt;/head&gt;
    &lt;p&gt;The openai/codex repository contains the source code for the Codex CLI tool, which OpenAI rewrote in Rust just a few months ago.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt know much Rust at all.&lt;/p&gt;
    &lt;p&gt;I made my own clone on GitHub and checked it out locally:&lt;/p&gt;
    &lt;code&gt;git clone git@github.com:simonw/codex
cd codex&lt;/code&gt;
    &lt;p&gt;Then I fired up Codex itself (in dangerous mode, because I like living dangerously):&lt;/p&gt;
    &lt;code&gt;codex --dangerously-bypass-approvals-and-sandbox&lt;/code&gt;
    &lt;p&gt;And ran this prompt:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Figure out how to build the rust version of this tool and then build it&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This worked. It churned away for a bit and figured out how to build itself. This is a useful starting point for a project like this‚Äîin figuring out the compile step the coding agent gets seeded with a little bit of relevant information about the project, and if it can compile that means it can later partially test the code it is writing while it works.&lt;/p&gt;
    &lt;p&gt;Once the compile had succeeded I fed it the design for the new feature I wanted:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a new sub-command to the Rust tool called ‚Äúcodex prompt‚Äù&lt;/p&gt;
      &lt;p&gt;codex prompt ‚Äúprompt goes here‚Äù‚Äîthis runs the given prompt directly against the OpenAI API that Codex uses, with the same code path and authentication credentials as the rest of Codex.&lt;/p&gt;
      &lt;p&gt;codex prompt -m &amp;lt;model_name&amp;gt; ‚Äúprompt goes here‚Äù‚Äîsame again but lets you set the model&lt;/p&gt;
      &lt;p&gt;codex prompt ‚Äúprompt goes here‚Äù -s/--system ‚Äúsystem prompt goes here‚Äù‚Äîruns with a custom system/developer message&lt;/p&gt;
      &lt;p&gt;codex prompt --models‚Äîthis lists all available models that can be used with the ‚Äúcodex prompt‚Äù command&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My design for this new sub-command is lifted directly from my own llm command.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iterating on the code&lt;/head&gt;
    &lt;p&gt;Codex got to work. I‚Äôve shared the full transcript here (using the tool I described here), but this TODO list it made itself is a useful summary of what it decided to do:&lt;/p&gt;
    &lt;code&gt;Updated Plan
‚îî ‚úî Inspect CLI structure and relevant core utilities for sending prompts and listing models
  ‚úî Implement new `codex prompt` subcommand (CLI plumbing + command handler)
  ‚úî Format, lint, and test (`just fmt`, `just fix -p codex-cli`, `cargo test -p codex-cli`)
&lt;/code&gt;
    &lt;p&gt;I like that it figured out the justfile in the repo and decided to use it to run formatting and linting commands without me needing to tell it to.&lt;/p&gt;
    &lt;p&gt;I tried running the first version of the code it wrote like this:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt 'Generate an SVG of a pelican riding a bicycle' -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;... and it didn‚Äôt quite work. I got this:&lt;/p&gt;
    &lt;code&gt;(reasoning summary) **Seeking
(reasoning summary)  instructions
(reasoning summary)  and
(reasoning summary)  sandbox
(reasoning summary)  info
(reasoning summary) **
(reasoning summary) **Dec
(reasoning summary) iding
(reasoning summary)  on
(reasoning summary)  SVG
(reasoning summary)  creation
(reasoning summary)  approach
(reasoning summary) **
(reasoning summary) **Checking
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
(reasoning summary) **Preparing
(reasoning summary)  to
(reasoning summary)  check
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
IÔøΩm ready to helpÔøΩwhat would you like me to do next?IÔøΩm ready to helpÔøΩwhat would you like me to do next?
Token usage: total=2459 input=2374 cached_input=0 output=85 reasoning_output=64
&lt;/code&gt;
    &lt;p&gt;Note that it DID think about SVG creation, but then decided it should look at the current directory. This isn‚Äôt what I want‚Äîit appeared to be running in Codex‚Äôs normal mode with a system prompt telling it to edit files on disk. I wanted it to respond to the prompt without acting as if it had a full workspace available to it.&lt;/p&gt;
    &lt;p&gt;I prompted it again, pasting in the broken output:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;this did not seem to work‚Äîhere is what happened‚Äînote that the reasoning summary comes out on a lot of lines when I would rather it streams out to stderr on the same line (flushing constantly)‚Äîand then despite the reasoning summary thinking about pelican on SVG it did not actually act on that and display the result, which is very surprising. [pasted content]&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It churned for a bit more, but from the output it looked like it was still trying to include Codex-specific tools and workspace information. So I said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that this new ‚Äôcodex prompt‚Äô command should NOT be able to execute any tools at all, and should not have to think about the workspace or sandbox‚Äîit should send a single prompt with no tools and then stream and display a response and then stop.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This got me a new build, but when I ran it:&lt;/p&gt;
    &lt;code&gt;Error: unexpected status 400 Bad Request: {"detail":"Instructions are not valid"}
&lt;/code&gt;
    &lt;p&gt;My guess is that OpenAI‚Äôs custom backend API for Codex doesn‚Äôt like it if you attempt to call it without passing in the expected instructions. Fair enough!&lt;/p&gt;
    &lt;p&gt;Rather than paste that error in I got Codex to try the command itself, so it could see the error:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You try running this and see what happens: ./target/debug/codex prompt ‚ÄôGenerate an SVG of a pelican riding a bicycle‚Äô&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Codex switched back to the default instructions. From its reply:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;cli/src/prompt_cmd.rs#L1-L320&lt;/code&gt;now forces a tool-free request: we keep the workspace defaults, inject a lightweight system/developer message (‚Äúdon‚Äôt run tools‚Äù), disable apply_patch/web search via config overrides, and build the outbound prompt as just that system span plus the user text.&lt;/quote&gt;
    &lt;p&gt;I guess that will have to do. I asked for one more feature:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a --debug option to the codex prompt command which causes the full JSON request and response to be printed to stderr, plus the URL that is being accessed and the HTTP verb&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;... and we‚Äôre ready to try this thing out!&lt;/p&gt;
    &lt;p&gt;Notably I haven‚Äôt written a single line of Rust myself here and paid almost no attention to what it was actually doing. My main contribution was to run the binary every now and then to see if it was doing what I needed yet.&lt;/p&gt;
    &lt;p&gt;I‚Äôve pushed the working code to a prompt-subcommand branch in my repo if you want to take a look and see how it all works.&lt;/p&gt;
    &lt;head rend="h4"&gt;Let‚Äôs draw some pelicans&lt;/head&gt;
    &lt;p&gt;With the final version of the code built, I drew some pelicans. Here‚Äôs the full terminal transcript, but here are some highlights.&lt;/p&gt;
    &lt;p&gt;This is with the default GPT-5-Codex model:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle"&lt;/code&gt;
    &lt;p&gt;I pasted it into my tools.simonwillison.net/svg-render tool and got the following:&lt;/p&gt;
    &lt;p&gt;I ran it again for GPT-5:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5&lt;/code&gt;
    &lt;p&gt;And now the moment of truth... GPT-5 Codex Mini!&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;I don‚Äôt think I‚Äôll be adding that one to my SVG drawing toolkit any time soon.&lt;/p&gt;
    &lt;head rend="h4"&gt;Bonus: the --debug option&lt;/head&gt;
    &lt;p&gt;I had Codex add a &lt;code&gt;--debug&lt;/code&gt; option to help me see exactly what was going on.&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt -m gpt-5-codex-mini "Generate an SVG of a pelican riding a bicycle" --debug&lt;/code&gt;
    &lt;p&gt;The output starts like this:&lt;/p&gt;
    &lt;code&gt;[codex prompt debug] POST https://chatgpt.com/backend-api/codex/responses
[codex prompt debug] Request JSON:
&lt;/code&gt;
    &lt;code&gt;{
  "model": "gpt-5-codex-mini",
  "instructions": "You are Codex, based on GPT-5. You are running as a coding agent ...",
  "input": [
    {
      "type": "message",
      "role": "developer",
      "content": [
        {
          "type": "input_text",
          "text": "You are a helpful assistant. Respond directly to the user request without running tools or shell commands."
        }
      ]
    },
    {
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "Generate an SVG of a pelican riding a bicycle"
        }
      ]
    }
  ],
  "tools": [],
  "tool_choice": "auto",
  "parallel_tool_calls": false,
  "reasoning": {
    "summary": "auto"
  },
  "store": false,
  "stream": true,
  "include": [
    "reasoning.encrypted_content"
  ],
  "prompt_cache_key": "019a66bf-3e2c-7412-b05e-db9b90bbad6e"
}&lt;/code&gt;
    &lt;p&gt;This reveals that OpenAI‚Äôs private API endpoint for Codex CLI is &lt;code&gt;https://chatgpt.com/backend-api/codex/responses&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Also interesting is how the &lt;code&gt;"instructions"&lt;/code&gt; key (truncated above, full copy here) contains the default instructions, without which the API appears not to work‚Äîbut it also shows that you can send a message with &lt;code&gt;role="developer"&lt;/code&gt; in advance of your user prompt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862802</guid><pubDate>Sun, 09 Nov 2025 04:02:47 +0000</pubDate></item><item><title>Grok 4 Fast now has 2M context window</title><link>https://docs.x.ai/docs/models</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862833</guid><pubDate>Sun, 09 Nov 2025 04:10:06 +0000</pubDate></item><item><title>Runc breaks pods when CPU requests aren't multiples of 10</title><link>https://github.com/opencontainers/runc/issues/4982</link><description>&lt;doc fingerprint="b50bdc7a2fa69931"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 2.2k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;head rend="h3"&gt;Description&lt;/head&gt;
    &lt;p&gt;When using the systemd cgroup driver with a CPU limit of &lt;code&gt;4096m&lt;/code&gt;, pod creation fails intermittently because containerd non-deterministically calculates either &lt;code&gt;409600&lt;/code&gt; or &lt;code&gt;410000&lt;/code&gt; microseconds for the parent cgroup, while runc consistently calculates &lt;code&gt;410000&lt;/code&gt; for child cgroups. When they mismatch, the Linux kernel rejects the child cgroup creation with "invalid argument".&lt;/p&gt;
    &lt;head rend="h2"&gt;Root Cause&lt;/head&gt;
    &lt;p&gt;Investigation reveals non-deterministic behavior in containerd when converting &lt;code&gt;4096m&lt;/code&gt; to microseconds:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Containerd (when creating pod sandbox) - INCONSISTENT:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Sometimes calculates: &lt;code&gt;4096m ‚Üí 409600 microseconds&lt;/code&gt;(correct: 4096 / 1000 * 100000)&lt;/item&gt;
          &lt;item&gt;Sometimes calculates: &lt;code&gt;4096m ‚Üí 410000 microseconds&lt;/code&gt;(rounded: 4.1 * 100000)&lt;/item&gt;
          &lt;item&gt;Sets parent cgroup: &lt;code&gt;cpu.cfs_quota_us&lt;/code&gt;to whichever value it calculated&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Sometimes calculates: &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;runc (when creating application container) - CONSISTENT:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Always calculates: &lt;code&gt;4096m ‚Üí 410000 microseconds&lt;/code&gt;(appears to round 4.096 to 4.1)&lt;/item&gt;
          &lt;item&gt;Tries to set child cgroup: &lt;code&gt;cpu.cfs_quota_us = 410000&lt;/code&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Always calculates: &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Result:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;When containerd picks &lt;code&gt;410000&lt;/code&gt;: Parent = 410000, child = 410000 ‚Üí Success!&lt;/item&gt;
          &lt;item&gt;When containerd picks &lt;code&gt;409600&lt;/code&gt;: Parent = 409600, child = 410000 ‚Üí Kernel rejects! (child &amp;gt; parent)&lt;/item&gt;
          &lt;item&gt;In cgroup v1, child quotas cannot exceed parent quotas&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;When containerd picks &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why It Appears Node-Specific&lt;/head&gt;
    &lt;p&gt;The issue seems to only affect "previously used nodes" because:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;When containerd picks &lt;code&gt;409600&lt;/code&gt;and the pod fails, the parent cgroup gets stuck&lt;/item&gt;
      &lt;item&gt;The pause container remains alive with the 409600 parent cgroup&lt;/item&gt;
      &lt;item&gt;All subsequent attempts to create the pod on that node fail (child 410000 &amp;gt; parent 409600)&lt;/item&gt;
      &lt;item&gt;Fresh nodes might get lucky and containerd picks &lt;code&gt;410000&lt;/code&gt;‚Üí works fine&lt;/item&gt;
      &lt;item&gt;But those nodes would fail too if containerd had picked &lt;code&gt;409600&lt;/code&gt;on first attempt&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is not about stale cgroups from old pods - it's about which value containerd randomly picks during pod sandbox creation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Error Message&lt;/head&gt;
    &lt;code&gt;failed to create containerd task: failed to create shim task: OCI runtime create failed:
runc create failed: unable to start container process: error during container init:
error setting cgroup config for procHooks process: failed to write "410000":
write /sys/fs/cgroup/cpu,cpuacct/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc65bd648_3faf_4778_90e4_a21afb2a6ad0.slice/cri-containerd-149d004f6e52b5665c6209d1f33a7e516049b79456444e3f74af49e62c5c80c8.scope/cpu.cfs_quota_us:
invalid argument: unknown
&lt;/code&gt;
    &lt;head rend="h2"&gt;Evidence from Investigation&lt;/head&gt;
    &lt;p&gt;Failing node (containerd picked 409600):&lt;/p&gt;
    &lt;code&gt;# Parent cgroup quota - containerd calculated 409600
$ cat /sys/fs/cgroup/cpu,cpuacct/.../kubepods-burstable-podc65bd648...slice/cpu.cfs_quota_us
409600

# Pod sandbox metadata confirms
$ crictl inspectp b4420139f34f8
"cpu_quota": 409600

# Containerd logs show runc trying to write 410000
$ journalctl -u containerd | grep "410000"
failed to write "410000": write .../cpu.cfs_quota_us: invalid argument&lt;/code&gt;
    &lt;p&gt;Working node (containerd picked 410000):&lt;/p&gt;
    &lt;code&gt;# Parent cgroup quota - containerd calculated 410000!
$ cat /sys/fs/cgroup/cpu,cpuacct/.../kubepods-burstable-pod7f7424a2...slice/cpu.cfs_quota_us
410000

# Application container child cgroup also 410000
$ cat /sys/fs/cgroup/cpu,cpuacct/.../cri-containerd-98745b3c2c216...scope/cpu.cfs_quota_us
410000

# They match - no error!&lt;/code&gt;
    &lt;p&gt;Both nodes running:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Same containerd version: 1.7.27&lt;/item&gt;
      &lt;item&gt;Same runc version: 1.3.2&lt;/item&gt;
      &lt;item&gt;Same Kubernetes version: 1.30.14-eks-113cf36&lt;/item&gt;
      &lt;item&gt;Same pod spec with CPU limit: 4096m&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Additional Context&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This issue started occurring after changing CPU limits from &lt;code&gt;8192m ‚Üí 4096m&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;The problem is specific to CPU values resulting in fractional cores (4.096)&lt;/item&gt;
      &lt;item&gt;The 400 microsecond difference (410000 - 409600) violates cgroup v1's parent-child quota constraint&lt;/item&gt;
      &lt;item&gt;Critical finding: Same containerd version behaves differently - this is non-deterministic&lt;/item&gt;
      &lt;item&gt;Calculation theory: &lt;list rend="ul"&gt;&lt;item&gt;Correct: &lt;code&gt;4096 / 1000 * 100000 = 409600&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Rounded: &lt;code&gt;4.1 * 100000 = 410000&lt;/code&gt;(rounding 4.096 to 4.1)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Correct: &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Questions for Maintainers&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Where in containerd's codebase does the millicore ‚Üí microsecond conversion happen for pod sandbox creation?&lt;/item&gt;
      &lt;item&gt;Why would containerd calculate two different values (409600 vs 410000) for the same input (4096m)?&lt;/item&gt;
      &lt;item&gt;Is there a race condition or different code path that causes this non-determinism?&lt;/item&gt;
      &lt;item&gt;Should containerd and runc be using shared conversion logic to ensure consistency?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Related Issues&lt;/head&gt;
    &lt;p&gt;This appears similar to but distinct from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;systemd driver updates CPU quota inconsitently #4622 - Systemd rounding to nearest 10ms (closed/fixed)&lt;/item&gt;
      &lt;item&gt;Reducing CPU period fails for subsystems if existing parent has quota&amp;gt;0 with systemd driver #3084 - Parent quota&amp;gt;0 with period changes (closed/fixed)&lt;/item&gt;
      &lt;item&gt;Error starting container - failed to write to cpu.cfs_quota_us kubernetes/kubernetes#61192 - Systemd rounding from 2018 (closed/fixed)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, this is a new issue involving non-deterministic behavior in containerd 1.7.27 when calculating CPU quotas for fractional core values with systemd cgroup driver.&lt;/p&gt;
    &lt;head rend="h3"&gt;Steps to reproduce the issue&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Deploy a Kubernetes pod with CPU limit&lt;/p&gt;&lt;code&gt;4096m&lt;/code&gt;multiple times on different fresh nodes&lt;list rend="ul"&gt;&lt;item&gt;Observe: Some pods succeed, some fail (non-deterministic)&lt;/item&gt;&lt;item&gt;Successful pods: containerd calculated parent cgroup &lt;code&gt;cpu.cfs_quota_us = 410000&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Failed pods: containerd calculated parent cgroup &lt;code&gt;cpu.cfs_quota_us = 409600&lt;/code&gt;&lt;/item&gt;&lt;item&gt;runc always tries to write &lt;code&gt;410000&lt;/code&gt;for child cgroup&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;On nodes where containerd picked&lt;/p&gt;&lt;code&gt;409600&lt;/code&gt;:&lt;list rend="ul"&gt;&lt;item&gt;runc attempts to create application container&lt;/item&gt;&lt;item&gt;runc tries to write &lt;code&gt;410000&lt;/code&gt;to child cgroup's&lt;code&gt;cpu.cfs_quota_us&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Kernel rejects: child quota (410000) &amp;gt; parent quota (409600)&lt;/item&gt;&lt;item&gt;Container creation fails with "invalid argument" error&lt;/item&gt;&lt;item&gt;Pod enters &lt;code&gt;CrashLoopBackOff&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Pause container remains alive with parent cgroup stuck at 409600&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;All subsequent restart attempts on that node continue to fail&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Containerd reuses the existing pod sandbox&lt;/item&gt;
          &lt;item&gt;Parent cgroup still has &lt;code&gt;409600&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;runc still tries &lt;code&gt;410000&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Pattern repeats indefinitely&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Evicting the pod and forcing it to a different node:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;May work if containerd picks &lt;code&gt;410000&lt;/code&gt;on the new node&lt;/item&gt;
          &lt;item&gt;Will fail if containerd picks &lt;code&gt;409600&lt;/code&gt;on the new node&lt;/item&gt;
          &lt;item&gt;Outcome is non-deterministic&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;May work if containerd picks &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example pod spec that reproduces the issue:&lt;/p&gt;
    &lt;code&gt;apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
  - name: test-container
    image: nginx:latest
    resources:
      limits:
        cpu: "4096m"
        memory: "16Gi"
      requests:
        cpu: "1024m"
        memory: "8Gi"&lt;/code&gt;
    &lt;head rend="h2"&gt;How to Verify Which Value Containerd Picked&lt;/head&gt;
    &lt;p&gt;On a node where the pod was deployed:&lt;/p&gt;
    &lt;code&gt;# Get pod UID
kubectl get pod &amp;lt;pod-name&amp;gt; -o jsonpath='{.metadata.uid}'

# Check parent cgroup on the node
cat /sys/fs/cgroup/cpu,cpuacct/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod&amp;lt;UID_with_underscores&amp;gt;.slice/cpu.cfs_quota_us

# 409600 = pod will fail
# 410000 = pod will succeed&lt;/code&gt;
    &lt;p&gt;Critical Note: The issue is not about "previously used nodes" - it's about which value containerd randomly calculates during initial pod sandbox creation. The appearance of being node-specific is because once a node gets stuck with 409600, it stays stuck.&lt;/p&gt;
    &lt;head rend="h3"&gt;Describe the results you received and expected&lt;/head&gt;
    &lt;p&gt;Expected behavior:&lt;/p&gt;
    &lt;p&gt;Containerd and runc should use consistent, deterministic calculations when converting millicores to microseconds for CPU quotas.&lt;/p&gt;
    &lt;p&gt;For a CPU limit of &lt;code&gt;4096m&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Both containerd and runc should calculate: &lt;code&gt;4096 / 1000 * 100000 = 409600 microseconds&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;OR both should calculate: &lt;code&gt;4.1 * 100000 = 410000 microseconds&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;They must agree - parent and child cgroups must have compatible values&lt;/item&gt;
      &lt;item&gt;Container should create successfully every time, regardless of node&lt;/item&gt;
      &lt;item&gt;Behavior should be deterministic, not random&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Actual behavior:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Containerd: Non-deterministically calculates either &lt;code&gt;409600&lt;/code&gt;or&lt;code&gt;410000&lt;/code&gt;for the same input&lt;list rend="ul"&gt;&lt;item&gt;Sometimes: &lt;code&gt;409600 microseconds&lt;/code&gt;(mathematically correct)&lt;/item&gt;&lt;item&gt;Sometimes: &lt;code&gt;410000 microseconds&lt;/code&gt;(rounded)&lt;/item&gt;&lt;item&gt;No obvious pattern - same version, same config, different results&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Sometimes: &lt;/item&gt;
      &lt;item&gt;runc: Consistently calculates &lt;code&gt;410000 microseconds&lt;/code&gt;(always rounds 4.096 to 4.1)&lt;/item&gt;
      &lt;item&gt;When they mismatch (containerd=409600, runc=410000): &lt;list rend="ul"&gt;&lt;item&gt;Child cgroup creation fails with kernel error: "invalid argument"&lt;/item&gt;&lt;item&gt;Pod enters &lt;code&gt;CrashLoopBackOff&lt;/code&gt;with 199+ restart attempts&lt;/item&gt;&lt;item&gt;Parent cgroup gets stuck with 409600, preventing all future attempts&lt;/item&gt;&lt;item&gt;Requires manual node cordoning and pod eviction&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;When they match (containerd=410000, runc=410000): &lt;list rend="ul"&gt;&lt;item&gt;Pod works perfectly fine&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Impact:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non-deterministic pod scheduling - same pod spec may work or fail randomly&lt;/item&gt;
      &lt;item&gt;Cannot reliably deploy pods with CPU limit &lt;code&gt;4096m&lt;/code&gt;(or other fractional core values)&lt;/item&gt;
      &lt;item&gt;Once a node "loses the lottery" and gets 409600, it's permanently broken for that pod&lt;/item&gt;
      &lt;item&gt;Requires operational workarounds (cordon/drain/evict)&lt;/item&gt;
      &lt;item&gt;Production impact on Amazon EKS clusters&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Root Issue:&lt;/p&gt;
    &lt;p&gt;This is fundamentally a consistency bug - containerd and runc must use the same conversion logic, and that logic must be deterministic.&lt;/p&gt;
    &lt;head rend="h3"&gt;What version of runc are you using?&lt;/head&gt;
    &lt;code&gt;runc version 1.3.2
commit: aeabe4e711d903ef0ea86a4155da0f9e00eabd29
spec: 1.2.1
go: go1.24.9
libseccomp: 2.5.2
&lt;/code&gt;
    &lt;p&gt;Additional environment details:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;containerd version: 1.7.27 (commit: 05044ec0a9a75232cad458027ca83437aae3f4da)&lt;/item&gt;
      &lt;item&gt;Kubernetes version: 1.30.14-eks-113cf36 (Amazon EKS)&lt;/item&gt;
      &lt;item&gt;Cgroup version: v1&lt;/item&gt;
      &lt;item&gt;Cgroup driver: systemd (&lt;code&gt;SystemdCgroup = true&lt;/code&gt;in containerd config at&lt;code&gt;/etc/containerd/config.toml&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Host OS information&lt;/head&gt;
    &lt;code&gt;NAME="Amazon Linux"
VERSION="2"
ID="amzn"
ID_LIKE="centos rhel fedora"
VERSION_ID="2"
PRETTY_NAME="Amazon Linux 2"
ANSI_COLOR="0;33"
CPE_NAME="cpe:2.3:o:amazon:amazon_linux:2"
HOME_URL="https://amazonlinux.com/"
SUPPORT_END="2026-06-30"
&lt;/code&gt;
    &lt;p&gt;Platform: Amazon EKS (Elastic Kubernetes Service) managed node&lt;/p&gt;
    &lt;head rend="h3"&gt;Host kernel information&lt;/head&gt;
    &lt;code&gt;Linux ip-10-7-66-184.prod-eks.newfront.com 5.10.245-241.976.amzn2.x86_64 #1 SMP Tue Oct 21 22:09:08 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
&lt;/code&gt;
    &lt;p&gt;Kernel version: 5.10.245-241.976.amzn2.x86_64&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45862967</guid><pubDate>Sun, 09 Nov 2025 04:47:27 +0000</pubDate></item><item><title>Forth ‚Äì is it still relevant?</title><link>https://github.com/chochain/eforth</link><description>&lt;doc fingerprint="be229b0a630aca40"&gt;
  &lt;main&gt;
    &lt;p&gt;With all the advantages, it is unfortunate that Forth lost out to C language over the years and have been reduced to a niche. Per ChatGPT: due to C's broader appeal, standardization, and support ecosystem likely contributed to its greater adoption and use in mainstream computing.&lt;/p&gt;
    &lt;p&gt;So, the question is, how to encourage today's world of C programmers to take a look at Forth. How do we convince them that Forth can be 10 times more productive? Well, we do know that by keep saying how elegant Forth is or even bashing how bad C can be probably won't get us anywhere.&lt;/p&gt;
    &lt;p&gt;Bill Muench created eForth for simplicity and educational purpose. Dr. Ting, ported to many processors, described Forth in his well-written eForth genesis and overview. I like the idea and decided to pick it up.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;100% C/C++ with multi-platform support. Though classic implementation of primitives in assembly language and scripted high-level words gave the power to Forth, it also became the hurtle for newbies. Because they have to learn the assembly and Forth syntax before peeking into the internal beauty of Forth.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary is just an array. It's remodeled from linear memory linked-list to an array (or a vector in C++'s term) of words.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;To search for a word, simply scan the name string of dictionary entries. So, to define a new word during compile time is just to append those found word pointers to the its parameter array one by one.&lt;/item&gt;
          &lt;item&gt;To execute become just a walk of the word pointers in the array. This is our inner interpreter.&lt;/item&gt;
          &lt;item&gt;Hashtables might go even faster but we'll try that later.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data and Return Stacks are also arrays. With push, pop and [] methods to clarify intentions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Parameter fields are all arrays. Why not!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No vocabulary, or meta-compilation. Except CREATE..DOES&amp;gt;, and POSTPONE, these black-belt skills of Forth greatness are dropped to keep the focus on core concepts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multi-threading and message passing are available From v5.0 and on, multi-core platform can utilize Forth VMs running in parallel. see the multi-threading section below for details&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A thread pool is built-in. Size is defaults to number of cores.&lt;/item&gt;
          &lt;item&gt;Message Passing send/recv with pthread mutex waiting.&lt;/item&gt;
          &lt;item&gt;IO and memory update can be synchronized with lock/unlock.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are fluent in C/C++ and in the process of building your own Forth, skipping the verbage, the easiest path to gain understanding of how things work together is to download release v4.2 and work from there.&lt;/p&gt;
    &lt;p&gt;In the release, a heavily commented ceforth.cpp, the companion ceforth.h, and a config.h. Altogether, about 800 lines. Check them out!&lt;/p&gt;
    &lt;p&gt;The core of current implementation of eForth is the dictionary composed of an array of Code objects that represent each of Forth words.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Code - the heart of eForth, depends on the constructor called, the following fields are populated accordingly&lt;/p&gt;
        &lt;quote&gt;+ name - a string that holds primitive word's name, i.e. NFA in classic FORTH, can also holds branching mnemonic for compound words which classic FORTH keeps on parameter memory + xt - pointer to a lambda function for primitive words i.e. XT in classic FORTH + pf, p1, p2 - parameter arrays of Code objects for compound words, i.e. PFA in classic FORTH + q - holds the literal value which classic FORTH keep on parameter memory&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lit, Var, Str, Bran, Tmp - the polymorphic classes extended from the base class Code which serve the functionalities of primitive words of classic Forth.&lt;/p&gt;
        &lt;quote&gt;+ Lit - numeric literals + Var - variable or constant + Str - string for dostr or dotstr + Bran - Branching opcode + Tmp - temp storage for branching word&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary - an array of Code objects&lt;/p&gt;
        &lt;quote&gt;+ build-it words - constructed by initializer_list at start up, before main is called, degenerated lambdas become function pointers stored in Code.xt dict[0].xt ------&amp;gt; lambda[0] &amp;lt;== These function pointers can be converted dict[1].xt ------&amp;gt; lambda[1] into indices to a jump table ... which is exactly what WASM does dict[N-1].xt ----&amp;gt; lambda[N-1] &amp;lt;== N is number of built-in words + colon (user defined) words - collection of word pointers during compile time dict[N].pf = [ *Code, *Code, ... ] &amp;lt;== These are called the 'threads' in Forth's term dict[N+1].pf = [ *Code, *Code, ... ] So, instead of subroutine threading ... this is 'object' threading. dict[-1].pf = [ *Code, *Code, ... ] It can be further compacted into token (i.e. dict index) threading if desired&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Inner Interpreter - Code.exec() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;if (xt) { xt(this); return; } // run primitive word for (Code *w : pf) { // run colon word try { w-&amp;gt;exec(); } // execute recursively catch (...) { break; } // handle exception if any }&lt;/quote&gt;
        &lt;p&gt;i.e. either we call a built-in word's lambda function or walk the Code.pf array recursively like a depth-first tree search.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Outer Interpreter - forth_core() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;Code *c = find(idiom); // search dictionary if (c) { // word found? if (compile &amp;amp;&amp;amp; !c-&amp;gt;immd) // are we compiling a new word? dict[-1]-&amp;gt;add(c); // then append found code to it else c-&amp;gt;exec(); // or, execute the code return; } DU n = parse_number(idiom); // word not found, try as a number if (compile) // are we compiling a new word? dict[-1]-&amp;gt;add(new Lit(n)); // append numeric literal to it else PUSH(n); // push onto data stack&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the array implementation, the first difference is in array variable read/write.&lt;/p&gt;
    &lt;code&gt;&amp;gt; create narr 10 cells allot
&amp;gt; see narr
&amp;gt; : narr
    0 0 0 0 0 0 0 0 0 0 ;
\       ^----------------- narr 2 cells +&lt;/code&gt;
    &lt;p&gt;While traditional Forths uses &lt;code&gt;narr 2 cells +&lt;/code&gt; to get the memory address of &lt;code&gt;narr[2]&lt;/code&gt;, eforth &lt;code&gt;narr&lt;/code&gt; returns its index (or defining order) in the dictionary. So, &lt;code&gt;narr 2 cells +&lt;/code&gt; will actually get you the index of the second word defined after &lt;code&gt;narr&lt;/code&gt;. You'll be storing the value into that word's empty qf field.
To access the nth element of &lt;code&gt;narr&lt;/code&gt;, use &lt;code&gt;th&lt;/code&gt; instead&lt;/p&gt;
    &lt;code&gt;&amp;gt; : fill-arr
    10 0 do
      i 2* narr i th !
    loop ;
&amp;gt; fill-arr
&amp;gt; see narr
&amp;gt; : narr
    0 2 4 6 8 10 12 14 16 18 ;&lt;/code&gt;
    &lt;p&gt;With arrays, the doors are open. Dynamically expanding variables as well as storing objects instead of just integers. Parameter fields can be filled in compile time or changed on the fly in runtime i.e. self-morphing code. These can be the "scary" features for Forths to come.&lt;/p&gt;
    &lt;p&gt;Most classic Forth systems are build with a few low-level primitives in assembly language and bootstrap the high-level words in Forth itself. Over the years, Dr. Ting have implemented many Forth systems using the same model. See here for the detailed list. However, he eventually stated that it was silly trying to explain Forth in Forth to new comers. There are just not many people know Forth, period.&lt;/p&gt;
    &lt;p&gt;Utilizing modern OS and tool chains, a new generation of Forths implemented in just a few hundreds lines of C code can help someone who did not know Forth to gain the core understanding much quickly. He called the insight Forth without Forth.&lt;/p&gt;
    &lt;p&gt;In 2021-07-04, I got in touched with Dr. Ting mentioning that he taught at the university when I attended. He, as the usual kind and generous him, included me in his last projects all the way till his passing. I am honored that he considered me one of the frogs living in the bottom of the deep well with him looking up to the small opening of the sky together. With cross-platform portability as our guild-line, we built ooeForth in Java, jeForth in Javascript, wineForth for Windows, and esp32forth for ESP micro-controllers using the same code-base. With his last breath in the hospital, he attempted to build it onto an FPGA using Verilog. see ceForth_403 and eJsv32 for details.&lt;/p&gt;
    &lt;p&gt;We hope it can serve as a stepping stone for learning Forth to even building their own, one day.&lt;/p&gt;
    &lt;code&gt;    $ git clone https://github.com/chochain/eforth to your local machine
    $ cd eforth&lt;/code&gt;
    &lt;p&gt;There are two major versions current. eForth. v4 is single-threaded only and v5 default single-threaded but also supports multi-threaded.&lt;/p&gt;
    &lt;p&gt;Checkout the version you are interested in.&lt;/p&gt;
    &lt;code&gt;    $ git checkout v42           # for version 4.2 (latest), or
    $ git checkout master        # for version 5 and on&lt;/code&gt;
    &lt;p&gt;To enable multi-threading, of v5, update the followings in ~/src/config.h&lt;/p&gt;
    &lt;code&gt;    #define DO_MULTITASK   1
    #define E4_VM_POOL_SZ  8&lt;/code&gt;
    &lt;code&gt;    $ make
    $ ./tests/eforth             # to bring up the Forth interpreter&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words‚èé               \ to see available Forth words
    &amp;gt; 1 2 +‚èé               \ see Forth in action
    &amp;gt; bye‚èé  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Once you get pass the above, try the lessons by Dr. Ting.
&lt;/code&gt;
    &lt;code&gt;    $ ./tests/eforth &amp;lt; ./tests/demo.fs&lt;/code&gt;
    &lt;p&gt;Pretty amazing stuffs! To grasp how they were done, study the individual files (*.fs) under ~/tests/demo.&lt;/p&gt;
    &lt;p&gt;Note: MacOS added, thanks to Kristopher Johnson's work.&lt;/p&gt;
    &lt;p&gt;I haven't develop anything useful on Windows for a long time. Just bearly got this compiled on an 2007 Windows7 box. So, take it with a grain of salt. I'm hoping someone can make it more streamlined.&lt;/p&gt;
    &lt;code&gt;* install and run Visual Studio on your box
* under the root directory, open the solution file eforth.sln (which points to project platform/eforth.vcxproj)
* Menu bar -&amp;gt; Build -&amp;gt; Build Solution   (default to Debug/64-bit)
* in a Command window, find and run eforth.exe under tests sub-directory
&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words‚èé               \ to see available Forth words
    &amp;gt; 1 2 +‚èé               \ see Forth in action
    &amp;gt; bye‚èé  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Note: Windows multi-threading seems to work but 2x slower. 
    * I only have a 2-core Win box. Do let me know if it goes further. 8-)
    * No CPU affinity. The code might need to be namespaced to avoid conflicts with Windows include files.
&lt;/code&gt;
    &lt;code&gt;* ensure you have Emscripten (WASM compiler) installed and configured
* or, alternatively, you can utilize docker image from emscripten/emsdk
&lt;/code&gt;
    &lt;code&gt;    $ make wasm
    $ python3 tests/cors.py        # supports COOP&lt;/code&gt;
    &lt;code&gt;* from your browser, open http://localhost:8000/tests/eforth.html
&lt;/code&gt;
    &lt;p&gt;Note: For multi-threading to work, browser needs to receive Cross-Origin policies here for detail in the response header. A Python script ~/tests/cors.py is provided to solve the issue. The same needed to be provided if you use other web server.&lt;/p&gt;
    &lt;code&gt;* ensure your Arduino IDE have ESP32 libraries installed
* update ESP32 compiler.optimization flags in ~/hardware/platform.txt to -O3 (default -Os)
* open eforth.ino with Arduino IDE
* inside eforth.ino, modify WIFI_SSID and WIFI_PASS to point to your router
* open Arduino Serial Monitor, set baud 115200 and linefeed to 'Both NL &amp;amp; CR'
* compile and load
* if successful, web server IP address/port and eForth prompt shown in Serial Monitor
* from your browser, enter the IP address to access the ESP32 web server
&lt;/code&gt;
    &lt;p&gt;Note: Most ESP32 are dual-core. However core0 is dedicated to WiFi and FreeRTOS house keeping. Forth tasks will be tied to core1 only. So, multi-threading is possible but no performance gain. Actually, singled-threaded v4.2 does a bit better.&lt;/p&gt;
    &lt;p&gt;Forth has been supporting multi-tasking since the 70's. They are single-CPU round-robin/time-slicing systems mostly. Modern system has multiple cores and Forth can certainly take advantage of them. However, unlike most of the matured Forth word sets, multi-threading/processing words are yet to be standardized and there are many ways to do it.&lt;/p&gt;
    &lt;code&gt;* each VM has it's own private ss, rs, tos, ip, and state
* multi-threading, instead of multi-processing, with shared dictionary and parameter memory blocks.
* pthread.h is used. It is a common POSIXish library supported by most platforms. I have only tried the handful on hands, your mileage may vary.
* Message Passing interface for inter-task communication.
&lt;/code&gt;
    &lt;code&gt;1. We have the VM array, sized by E4_VM_POOL_SZ, which defines the max tasks you want to have. Typically, anything more than your CPU core count does not help completing the job faster.
2. Each VM is associated with a thread, i.e. our thread-pool.
3. The event_queue, a C++ queue takes in "ready to run" tasks.
4. Lastly, event_loop picks up "ready to run" tasks and kicks start them one by one.

The following VM states manage the life-cycle of a task

* QUERY - interpreter mode - only the main thread can do this
* HOLD  - ready to execute, or waiting for message to arrive
* NEST  - in execution
* STOP  - free for next task
&lt;/code&gt;
    &lt;p&gt;Before we go too far, make sure the following are updated before your build&lt;/p&gt;
    &lt;code&gt;* pthread.h is installed. 
* DO_MULTITASK, E4_VM_POOL_SZ are updated in ~/src/config.h
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;word&lt;/cell&gt;
        &lt;cell role="head"&gt;stack&lt;/cell&gt;
        &lt;cell role="head"&gt;desc&lt;/cell&gt;
        &lt;cell role="head"&gt;state&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;task&lt;/cell&gt;
        &lt;cell&gt;( xt -- t )&lt;/cell&gt;
        &lt;cell&gt;create a task (tid is index to thread pool entry)&lt;p&gt;a free VM from pool is chosen for the task&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;STOP=&amp;gt;HOLD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;rank&lt;/cell&gt;
        &lt;cell&gt;( -- t )&lt;/cell&gt;
        &lt;cell&gt;fetch current task id&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;start&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;start a task&lt;p&gt;The VM is added to event_queue and kick started when picked up by event_loop&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;join&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;wait until the given task is completed&lt;/cell&gt;
        &lt;cell&gt;NEST=&amp;gt;STOP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;lock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;lock (semaphore) IO or memory&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;unlock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;release IO or memory lock&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;send&lt;/cell&gt;
        &lt;cell&gt;( v1 v2 .. vn n t -- )&lt;/cell&gt;
        &lt;cell&gt;send n elements on current stack to designated task's stack (use stack as message queue)&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receiver HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;recv&lt;/cell&gt;
        &lt;cell&gt;( -- v1 v2 .. vn )&lt;/cell&gt;
        &lt;cell&gt;wait, until message to arrive&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;pull&lt;/cell&gt;
        &lt;cell&gt;( n t -- )&lt;/cell&gt;
        &lt;cell&gt;forced fetch stack elements from a completed task&lt;/cell&gt;
        &lt;cell&gt;current NEST&lt;p&gt;target STOP&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;bcast&lt;/cell&gt;
        &lt;cell&gt;( n -- )&lt;/cell&gt;
        &lt;cell&gt;not implemented yet, TODO&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receivers HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;clock&lt;/cell&gt;
        &lt;cell&gt;( -- n )&lt;/cell&gt;
        &lt;cell&gt;fetch microsecond since Epoch, useful for timing&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;    &amp;gt; : once 999999 for rank drop next ;            \ 1M cycles
    &amp;gt; : run clock negate once clock + . ." ms" cr ; \ benchmark
    &amp;gt; ' run constant xt                             \ keep the xt
    &amp;gt; : jobs 1- for xt task start next ;            \ tasks in parallel
    &amp;gt; 4 jobs&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T2 [05.1]&amp;gt;&amp;gt; started on T4 [04.1]&amp;gt;&amp;gt; started on T6 [07.1]&amp;gt;&amp;gt; started on T0 18 ms [06.3]&amp;gt;&amp;gt; finished on T2 18 ms [05.3]&amp;gt;&amp;gt; finished on T4 18 ms [04.3]&amp;gt;&amp;gt; finished on T6 18 ms [07.3]&amp;gt;&amp;gt; finished on T0&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; 0 constant pp                           \ producer task id
    &amp;gt; 0 constant cc                           \ consumer task id
    &amp;gt; : sndr
        1000 ms                               \ delay to simulate some processing
        1 2 3 4 4 cc send                     \ send 4 items from stack
        lock ." sent " cr unlock ;            \ locked IO before write
    &amp;gt; : rcvr
        recv                                  \ wait for sender
        + + +                                 \ sum received 4 items
        lock ." sum=" . cr unlock ;           \ locked IO before write
    &amp;gt; ' sndr task to pp
    &amp;gt; ' rcvr task to cc
    &amp;gt; cc start                                \ start receiver task
    &amp;gt; pp start                                \ start sender task
    &amp;gt; pp join cc join                         \ wait for completion&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T1 [06.1]&amp;gt;&amp;gt; waiting [07.1]&amp;gt;&amp;gt; started on T2 [06.1]&amp;gt;&amp;gt; sending 4 items to VM6.1 sent [07.3]&amp;gt;&amp;gt; finished on T2 [00.3]&amp;gt;&amp;gt; VM7 joint [06.3]&amp;gt;&amp;gt; received =&amp;gt; state=3 sum=10 [06.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM6 joint&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; : sum 0 1000000 for i + next ;          \ add 0 to 1M
    &amp;gt; ' sum task constant tt                  \ create the task
    &amp;gt; tt start tt join                        \ run and wait for completion
    &amp;gt; 1 tt pull ." total=" .                  \ pull the sum&lt;/code&gt;
    &lt;quote&gt;[00.3]&amp;gt;&amp;gt; joining VM7 [07.1]&amp;gt;&amp;gt; started on T1 [07.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM7 joint pulled 1 items from VM7.0 total= 1784293664 -1 -&amp;gt; ok&lt;/quote&gt;
    &lt;code&gt;+ ~/src       - multi-threaded, dynamic vector-based, object threading
+ ~/platform  - platform specific code for C++, ESP32, Windows, and WASM
+ ~/orig      - archive from Dr. Ting and my past works
+    /33b     - refactored ceForth_33, separate ASM from VM (used in eForth1 for Adruino UNO)
+    /ting    - ceForth source codes collaborated with Dr. Ting
+    /esp32   - esp32forth source codes collaborated with Dr. Ting
+    /40x     - my experiments, refactor _40 into vector-based subroutine-threaded, with 16-bit offset
+    /50x     - my experiments, add multi-threading to _40
&lt;/code&gt;
    &lt;code&gt;+ 4452ms: ~/orig/ting/ceforth_36b, linear memory, 32-bit, token threading
+ 1450ms: ~/orig/ting/ceForth_403, dict/pf array-based, subroutine threading
+ 1050ms: ~/orig/40x/ceforth, subroutine indirect threading, with 16-bit offset
+  890ms: ~/orig/40x/ceforth, inner interpreter with cached xt 16-bit offsets
+  780ms: ~/src/eforth, v4.2 dynamic vector, object threading (gcc -O2)
&lt;/code&gt;
    &lt;code&gt;+  812ms: v5.0, multi-threaded (gcc -O2)
+  732ms: v5.0, multi-threaded (gcc -O3)
+  731ms: v5.0, single-threaded (gcc -O3) =&amp;gt; not much overhead with MT
&lt;/code&gt;
    &lt;code&gt;+  843ms: v5.0 50x32 branch (gcc -O2)
   * program spent &amp;gt;50% in nest() - gprof/valgrind/cachegrind
   * 16-bit IU fetch + dispatch: Ir/Dr = 2.3M/0.5M (810ms)
   * 32-bit Param hardcopy     : Ir/Dr = 3.8M/1.1M (930ms)
   * 32-bit Param reference    : Ir/Dr = 3.1M/0.8M (843ms) &amp;lt;== 32-bit best
   * 32-bit Param pointer      : Ir/Dr = 3.2M/0.9M (899ms)
+  873ms: v5.0 50x32 branch (gcc -O3)
   * slower, due to inline find() into forth_core() which crowded cache.
     Note: this doesn't seem to bother WASM.
&lt;/code&gt;
    &lt;code&gt;+ 1440ms: Dr. Ting's ~/esp32forth/orig/esp32forth_82
+ 1045ms: ~/orig/esp32/ceforth802, array-based, token threading
+  990ms: ~/orig/40x/ceforth, linear-memory, subroutine threading, with 16-bit offset
+  930ms: ~/orig/40x/ceforth, inner interpreter with cached xt offsets
+  644ms: ~/src/eforth, v4.2 dynamic vector, token threading
+  534ms: ~/src/eforth, v5.0 multi-threaded, dynamic vector, object threading (with gcc -O3)
&lt;/code&gt;
    &lt;p&gt;What is the performance difference?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Code *dict[] - where words are dynamically allocated as a collection of pointers, or&lt;/item&gt;
      &lt;item&gt;Code dict[] - where words are statically created as an array of objects.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I have created a git branch 'static' to compare to the 'master. The static version is about 10% slower on 64-bit machine and about 5% slower on 32-bits. This hasn't been carefully analyzed but my guess is because Code is big at 144-bytes on 64-bit. They might get pushed off L1 cache too often.&lt;/p&gt;
    &lt;p&gt;An array of lambdas vs the classic switch statement, i.e.&lt;/p&gt;
    &lt;code&gt;const Code dict[] {               ///&amp;lt; Forth dictionary
    CODE("+",      TOS += SS.pop()),
    CODE("-",      TOS =  SS.pop() - TOS),
    CODE("*",      TOS *= SS.pop()),
    CODE("/",      TOS =  SS.pop() / TOS),
    ...
vs
    switch(opcode) {             ///&amp;lt; big switch statement
    case PLUS:     TOS += SS.pop();      break;
    case MINUS:    TOS = SS.pop() - TOS; break;
    case MULTIPLY: TOS *= SS.pop();      break;
    case DIVIDE:   TOS = SS.pop() / TOS; break;
    ...
&lt;/code&gt;
    &lt;p&gt;Though syntax clarity is pretty much the same, lambda being function pointers takes an extra jump and the cost of stack-frame setup/teardown. It takes more space and about 15% slower in tight loops. However, with the advance of compilers,&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It does not need a long enum definition, i.e. PLUS, MINUS, ..., which needs to be kept in-sync&lt;/item&gt;
      &lt;item&gt;It is possible to prebuild lambda array as a ROM image or static library that can be transported.&lt;/item&gt;
      &lt;item&gt;A tweak to CODE macro, i.g. adding NEXT, can potentially enable Tail Call Optimization (TCO) which eliminates the stack-frame overhead as did in many functional languages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Though the use of C++ standard libraries helps us understanding what Forth does but, even on machines with GBs, we still need to be mindful of the followings. It gets expensive especially on MCUs.&lt;/p&gt;
    &lt;code&gt;+ A pointer takes 8-byte on a 64-bit machine,
+ A C++ string, needs 3 to 4 pointers, will require 24-32 bytes,
+ A vector, takes 3 pointers, is 24 bytes
&lt;/code&gt;
    &lt;p&gt;The current implementation of ~/src/ceforth.h, a Code node takes 144 bytes on a 64-bit machine. On the other extreme, my ~/orig/40x experimental version, a vector linear-memory hybrid, takes only 16 bytes here. Go figure how the classic Forths needs only 2 or 4 bytes per node via linked-field and the final executable in a just a few KB. You might start to understand why the old Forth builders see C/C++ like plaque.&lt;/p&gt;
    &lt;p&gt;I try to release allocated blocks before exiting, however due to the dynamic alloc and resizing of std::vector, eForth dictionary hold on to many Code objects and the names string generated with them, valgrind (or similar tool) could reports lost (or leak). Though these memory blocks should all be reclaimed by the OS, it is something to be mindful of.&lt;/p&gt;
    &lt;p&gt;Current implementation utilize C++ vector as the core storage. Inside a Code object, there are pf, p1, p2 vectors to store branching words similar to that of an AST (Abstract Syntax Tree). The alternative is to stick all words into a single parameter field as done in classic Forth. I have created a branch one_pf doing exactly the same just to check it out. Also, tried polymorphic inner interpreter. So, are they better?&lt;/p&gt;
    &lt;code&gt;+ Branching microcode look cleaner. 2-bit **VM.stage** flag can be replaced by a 1-bit **VM.jmp** status. No big deal.
+ dump and see are easier to implement, but
+ Runs 4~8x slower using recursive nest() i.e. Forth inner interpreter,
+ Improved to 2x slower using iterative nest()
+ Also, polymorphic slows down additional 5%. Most likely due to extra vtable lookup.
&lt;/code&gt;
    &lt;p&gt;So, what cachegrind said for 100M loop tight loops and chacha.fs a CPU intensive?&lt;/p&gt;
    &lt;code&gt;| Op          | 100M loop | chacha.fs |
|-------------|-----------|-----------|
| Data Read   | +30%      | +32%      |
| Branches    | +25%      | +30%      |
| Mispred     | similar   | similar   |
| Instruction | +20%      | +40%      |
&lt;/code&gt;
    &lt;p&gt;Apparently, grown ~30% in all aspects. I think because having branching primitives, i.e. _if/_else/_then, for/next, in C++ prevent the extra fetch of VM branches. Sort of the difference between having hardware and software branchers. However, my gut feeling is the difference shouldn't be so dramatic especially with the recursive nest(). More research on this...&lt;/p&gt;
    &lt;p&gt;Instead of using vectors (i.e. pf, p1, p2) to keep codes and parameters, this implementation follows classic Forth's model using one big block of parameter memory with words laid down contiguoursly. With 32-bit data, subroutine threaded but hybrid with 16-bit xt offset (to reduce one lookup).&lt;/p&gt;
    &lt;p&gt;It works better with WASM's memory model. It is used as the foundation for weForth. So far, it is stable but tweaked from time to time and&lt;/p&gt;
    &lt;code&gt;&amp;gt; make 50x
&amp;gt; ./tests/eforth50x
&lt;/code&gt;
    &lt;p&gt;Hinted by Sean Pringle's Rethinking Forth and Travis Bemann's wornderful zeptoforth. Nested module (or sub-words), simplified control structures are attemped. Now, moved to eForthX&lt;/p&gt;
    &lt;code&gt;+ perf   - [multithreaded](https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps)
+ coding -
    [optimizing](http://www.agner.org/optimize/optimizing_cpp.pdf)
    [false-sharing](https://medium.com/distributed-knowledge/optimizations-for-c-multi-threaded-programs-33284dee5e9c)
    [affinity](https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/)
    [occlusion](https://fgiesen.wordpress.com/2013/02/17/optimizing-sw-occlusion-culling-index/)
    [perf c2c](https://coffeebeforearch.github.io/2020/03/27/perf-c2c.html)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Dr. Ting's work on eForth between 1995~2011 eForth references and their Source Code Repo&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210314: Initial&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Started with ~orig/33b code-base, refactor with enum and VA_ARGS macros targeting 100% C/C++.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210707: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Incorporated list-based dict, ss, rs (i.e. ~orig/ting/ceForth40 and ~orig/802) which I proposed to Dr. Ting in our email exchanges.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210816: Code Merge&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Targeting multi-platform. Common source by consolidating ceForth, wineForth, ESP32forth (kept in ~/orig/*). Officially version 8.0&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20220512: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Though the goal of Dr. Ting's is to demonstrate how a Forth can be easily understood and cleanly constructed. However, the token threading method used is costly (slow) because each call needs 2 indirect lookups (token-&amp;gt;dict, dict-&amp;gt;xt). On top of that, C/C++ call-frame needs to be setup/teardown. It is worsen by the branch prediction missing every call stalling the CPU pipeline. Bad stuffs!&lt;/item&gt;
          &lt;item&gt;Refactor to subroutine indirect threading. It's not portable but does speed up 25% (see benchmark above).&lt;/item&gt;
          &lt;item&gt;Using 16-bit offsets for pointer arithmetic which speed up another 5% while maintaining 16-bit parameter space consumption.&lt;/item&gt;
          &lt;item&gt;Since C++ code is at least 4-byte aligned and parameter is 2-byte aligned, the LSB of a given parameter is utilized for colon word identification.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20221118: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;WASM function pointer is U32 (index). Token-indirect worked but the two indirect look-up is even slower. Since WASM uses 64K linear memory block, 16-bit pointer offset is a better option. However, the xt "function pointer" in code space is simply an index to the shared _indirect_function_table. Since LSB is used, so we are forced to use MSB to differentiate primitive word from colon word. This left us 15-bit, i.e. 32K, parameter offset available.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20231011: Review&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Since the original intention of having a pre-compiled ROM dictionary still end up in C++ static initialization run before main(), moved dictionary compilation into dict_compile as function calls gives a little more debugging control and opportunity for fine tuning.&lt;/item&gt;
          &lt;item&gt;LAMBDA_OK option was originally intended for full VM implementation but 2x slower. Dropped to reduce source clutter.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20240308: Refactor for multi-platform, accept dynamic vectors&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Experiment various threading and memory pointer models, archive into ~/orig/40x&lt;/item&gt;
          &lt;item&gt;To support cross-platform, i.g. Linux/Cygwin, Arduino/ESP32, Win32, and WASM, there were many conditional compilation branches which make the code really messy. The following were done &lt;list rend="ul"&gt;&lt;item&gt;Separate cross-platform and configuration into ~/src/config.h&lt;/item&gt;&lt;item&gt;Separate platform specific code into ~/platform&lt;/item&gt;&lt;item&gt;add included opcode for Forth script loading&lt;/item&gt;&lt;item&gt;rename 'next_idiom' to 'word', per Forth standard&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20241001: Add multi-threading support&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Shared dictionary and code space amount threads.&lt;/item&gt;
          &lt;item&gt;Refactor source into ceforth, ceforth_sys, and ceforth_task for their specific functions.&lt;/item&gt;
          &lt;item&gt;Introduce VM, states &lt;list rend="ul"&gt;&lt;item&gt;local ss, rs, tos, and user area&lt;/item&gt;&lt;item&gt;align to cache-line width&lt;/item&gt;&lt;item&gt;pass VM&amp;amp; to all lambda and static functions&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add thread pool and event_loop with affinity to physical cores. &lt;list rend="ul"&gt;&lt;item&gt;task, start, stop, join for thread life-cycle management&lt;/item&gt;&lt;item&gt;add general multi-threading demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add Inter-task communication &lt;list rend="ul"&gt;&lt;item&gt;pthread mutex and condition variables are used for synchronization&lt;/item&gt;&lt;item&gt;rank for task id&lt;/item&gt;&lt;item&gt;send, recv, and pull. Use local stack, as queue, for message passing.&lt;/item&gt;&lt;item&gt;add producer/consumer demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add IO sequencing &lt;list rend="ul"&gt;&lt;item&gt;ANSI-Color trace/logging for different cores&lt;/item&gt;&lt;item&gt;mutex guard used&lt;/item&gt;&lt;item&gt;lock, unlock for output stream synchronization&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC: 20250610: maintenance and memory leak check&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Refactor &lt;list rend="ul"&gt;&lt;item&gt;Macros to reduce verbosity i.e. VM referenced TOS, SS, RS, BRAN, BTGT&lt;/item&gt;&lt;item&gt;Group IO functions to forth_sys module&lt;/item&gt;&lt;item&gt;Macros to clarify intention, i.e. NEST, BASE, ADD_W&lt;/item&gt;&lt;item&gt;Code references replace Code pointers&lt;/item&gt;&lt;item&gt;Rename ms=&amp;gt;clock, delay=&amp;gt;ms (adhere to Forth Standard)&lt;/item&gt;&lt;item&gt;Add destructors to deallocate (reduce valgrind's complaints)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance multi-threading &lt;list rend="ul"&gt;&lt;item&gt;Use std::thread instead of pthread (except device specific CPU affinity)&lt;/item&gt;&lt;item&gt;Handle recursive include - Save/Restore WP&lt;/item&gt;&lt;item&gt;Refined forth_vm state machine transition (QUERY, HOLD, NEST, STOP)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance debugging &lt;list rend="ul"&gt;&lt;item&gt;Add dict() to detail dictionary entries&lt;/item&gt;&lt;item&gt;Add dump() to show memory/parameter field's content&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Refactor &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45863024</guid><pubDate>Sun, 09 Nov 2025 04:59:19 +0000</pubDate></item><item><title>Study finds memory decline surge in young people</title><link>https://onepercentrule.substack.com/p/under-40s-declining-memory</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45863057</guid><pubDate>Sun, 09 Nov 2025 05:05:20 +0000</pubDate></item><item><title>I Am Mark Zuckerberg</title><link>https://iammarkzuckerberg.com/</link><description>&lt;doc fingerprint="b609d0711019dfdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to iammarkzuckerg.com&lt;/head&gt;
    &lt;p&gt;No, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks.&lt;/p&gt;
    &lt;p&gt;Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money.&lt;/p&gt;
    &lt;p&gt;What I Really Do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Help people obtain a fresh financial start (no passwords required)&lt;/item&gt;
      &lt;item&gt;Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)&lt;/item&gt;
      &lt;item&gt;Answer local legal questions, not privacy scandals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real Zuckerberg Facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Shares a name, not fortune, with the Facebook founder&lt;/item&gt;
      &lt;item&gt; Gets mistaken daily for a tech billionaire &lt;/item&gt;
      &lt;item&gt; Has written zero social media apps, but plenty of court briefs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Fun Fact:&lt;lb/&gt; In Indiana, saying "I'm Mark Zuckerberg" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. &lt;/p&gt;
    &lt;head rend="h3"&gt; Click Here to See How Other &lt;lb/&gt;Websites Have Reacted to This &lt;/head&gt;
    &lt;head rend="h3"&gt;Interesting Things That Have Happened to Me Because My Name is Mark Zuckerberg&lt;/head&gt;
    &lt;p&gt;For a complete list of things that have happened to Mark Zuckerberg click here&lt;/p&gt;
    &lt;p&gt;Like I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for "Mark Zuckerberg bankruptcy". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45863360</guid><pubDate>Sun, 09 Nov 2025 06:13:05 +0000</pubDate></item><item><title>Visa and Mastercard near deal with merchants that would change rewards landscape</title><link>https://www.wsj.com/finance/banking/visa-and-mastercard-near-deal-with-merchants-that-would-change-rewards-landscape-fc6a0c78</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45863435</guid><pubDate>Sun, 09 Nov 2025 06:32:37 +0000</pubDate></item></channel></rss>