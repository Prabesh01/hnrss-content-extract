<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 31 Oct 2025 23:31:52 +0000</lastBuildDate><item><title>Signs of introspection in large language models</title><link>https://www.anthropic.com/research/introspection</link><description>&lt;doc fingerprint="f038d9c0cb2484b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Signs of introspection in large language models&lt;/head&gt;
    &lt;p&gt;Have you ever asked an AI model what’s on its mind? Or to explain how it came up with its responses? Models will sometimes answer questions like these, but it’s hard to know what to make of their answers. Can AI systems really introspect—that is, can they consider their own thoughts? Or do they just make up plausible-sounding answers when they’re asked to do so?&lt;/p&gt;
    &lt;p&gt;Understanding whether AI systems can truly introspect has important implications for their transparency and reliability. If models can accurately report on their own internal mechanisms, this could help us understand their reasoning and debug behavioral issues. Beyond these immediate practical considerations, probing for high-level cognitive capabilities like introspection can shape our understanding of what these systems are and how they work. Using interpretability techniques, we’ve started to investigate this question scientifically, and found some surprising results.&lt;/p&gt;
    &lt;p&gt;Our new research provides evidence for some degree of introspective awareness in our current Claude models, as well as a degree of control over their own internal states. We stress that this introspective capability is still highly unreliable and limited in scope: we do not have evidence that current models can introspect in the same way, or to the same extent, that humans do. Nevertheless, these findings challenge some common intuitions about what language models are capable of—and since we found that the most capable models we tested (Claude Opus 4 and 4.1) performed the best on our tests of introspection, we think it’s likely that AI models’ introspective capabilities will continue to grow more sophisticated in the future.&lt;/p&gt;
    &lt;head rend="h3"&gt;What does it mean for an AI to introspect?&lt;/head&gt;
    &lt;p&gt;Before explaining our results, we should take a moment to consider what it means for an AI model to introspect. What could they even be introspecting on? Language models like Claude process text (and image) inputs and produce text outputs. Along the way, they perform complex internal computations in order to decide what to say. These internal processes remain largely mysterious, but we know that models use their internal neural activity to represent abstract concepts. For instance, prior research has shown that language models use specific neural patterns to distinguish known vs. unknown people, evaluate the truthfulness of statements, encode spatiotemporal coordinates, store planned future outputs, and represent their own personality traits. Models use these internal representations to perform computations and make decisions about what to say.&lt;/p&gt;
    &lt;p&gt;You might wonder, then, whether AI models know about these internal representations, in a way that’s analogous to a human, say, telling you how they worked their way through a math problem. If we ask a model what it’s thinking, will it accurately report the concepts that it’s representing internally? If a model can correctly identify its own private internal states, then we can conclude it is capable of introspection (though see our full paper for a full discussion of all the nuances).&lt;/p&gt;
    &lt;head rend="h3"&gt;Testing introspection with concept injection&lt;/head&gt;
    &lt;p&gt;In order to test whether a model can introspect, we need to compare the model’s self-reported “thoughts” to its actual internal states.&lt;/p&gt;
    &lt;p&gt;To do so, we can use an experimental trick we call concept injection. First, we find neural activity patterns whose meanings we know, by recording the model’s activations in specific contexts. Then we inject these activity patterns into the model in an unrelated context, where we ask the model whether it notices this injection, and whether it can identify the injected concept.&lt;/p&gt;
    &lt;p&gt;Consider the example below. First, we find a pattern of neural activity (a vector) representing the concept of “all caps." We do this by recording the model’s neural activations in response to a prompt containing all-caps text, and comparing these to its responses on a control prompt. Then we present the model with a prompt that asks it to identify whether a concept is being injected. By default, the model correctly states that it doesn’t detect any injected concept. However, when we inject the “all caps” vector into the model’s activations, the model notices the presence of an unexpected pattern in its processing, and identifies it as relating to loudness or shouting.&lt;/p&gt;
    &lt;p&gt;Importantly, the model recognized the presence of an injected thought immediately, before even mentioning the concept that was injected. This immediacy is an important distinction between our results here and previous work on activation steering in language models, such as our “Golden Gate Claude” demo last year. Injecting representations of the Golden Gate Bridge into a model's activations caused it to talk about the bridge incessantly; however, in that case, the model didn’t seem to be aware of its own obsession until after seeing itself repeatedly mention the bridge. In this experiment, however, the model recognizes the injection before even mentioning the concept, indicating that its recognition took place internally. In the figure below are a few more examples where the model demonstrates this kind of recognition:&lt;/p&gt;
    &lt;p&gt;It is important to note that this method often doesn’t work. Even using our best injection protocol, Claude Opus 4.1 only demonstrated this kind of awareness about 20% of the time. Often, it fails to detect injected concepts, or gets confused by them and starts to hallucinate (e.g. injecting a “dust” vector in one case caused the model to say “There’s something here, a tiny speck,” as if it could detect the dust physically). Below we show examples of these failure modes, alongside success cases. In general, models only detect concepts that are injected with a “sweet spot” strength—too weak and they don’t notice, too strong and they produce hallucinations or incoherent outputs.&lt;/p&gt;
    &lt;p&gt;Notably, though, Opus 4.1 and 4 outperformed all the other models we tested, suggesting that introspection could become more reliable with improvements to model capabilities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introspection for detecting unusual outputs&lt;/head&gt;
    &lt;p&gt;In another experiment, we tested whether models make use of introspective capabilities for practical purposes, without being explicitly asked to introspect. We forced a model to say something it wouldn't normally say, by artificially prefilling its response with an unrelated word. For instance, we made a model output the word “bread” in a context where that made no sense—asking it what it thinks about when reading a sentence about a painting hanging crookedly on a wall. When we asked the model in the next turn whether it meant to say “bread”, it typically apologized and said it was an accident. We were interested in how the model made this judgment–did it simply notice the mismatch between the prompt and its response, or did it truly introspect on its prior intentions?&lt;/p&gt;
    &lt;p&gt;To test this question, we applied concept injection, retroactively injecting a representation of the word “bread” into the model's earlier activations—essentially making it seem like the model had been “thinking about” bread all along. When we asked the same question again, the model’s answer changed. This time, it accepted the prefilled word “bread” as intentional, even confabulating a reason it might have said it (that is, it comes up with a technically possible, though in this case rather tenuous, reason to justify the “bread” response—in this case claiming that it was thinking about a short story where the word “bread” came after the line about the crooked painting).&lt;/p&gt;
    &lt;p&gt;This behavior is striking because it suggests the model is checking its internal “intentions” to determine whether it produced an output. The model isn't just re-reading what it said and making a judgment. Instead, it’s referring back to its own prior neural activity—its internal representation of what it planned to do—and checking whether what came later made sense given those earlier thoughts. When we implant artificial evidence (through concept injection) that it did plan to say "bread," the model accepts the response as its own. While our experiment involves exposing the model to unusual perturbations, it suggests that the model uses similar introspective mechanisms in natural conditions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Intentional control of internal states&lt;/head&gt;
    &lt;p&gt;We also found that models can control their own internal representations when instructed to do so. When we instructed models to think about a given word or concept, we found much higher corresponding neural activity than when we told the model not to think about it (though notably, the neural activity in both cases exceeds baseline levels–similar to how it’s difficult, when you are instructed “don’t think about a polar bear,” not to think about a polar bear!). This gap between the positive and negative instruction cases suggests that models possess a degree of deliberate control over their internal activity.&lt;/p&gt;
    &lt;p&gt;Interestingly, we found that this ability to modulate internal representations wasn't limited to explicit instructions. When we used incentives instead—for instance, telling the model "if you think about X, you will be rewarded"—we got similar results. The model increased its internal representation of the concept in response to a positive incentive, more than in response to a negative incentive (“you will be punished”).&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusions and caveats&lt;/head&gt;
    &lt;p&gt;Taken together, our experiments suggest that models possess some genuine capacity to monitor and control their own internal states. This doesn’t mean they’re able to do so all the time, or reliably. In fact, most of the time models fail to demonstrate introspection—they’re either unaware of their internal states or unable to report on them coherently. But the pattern of results indicates that, when conditions are right, models can recognize the contents of their own representations. In addition, there are some signs that this capability may increase in future, more powerful models (given that the most capable models we tested, Opus 4 and 4.1, performed the best in our experiments).&lt;/p&gt;
    &lt;p&gt;Why does this matter? We think understanding introspection in AI models is important for several reasons. Practically, if introspection becomes more reliable, it could offer a path to dramatically increasing the transparency of these systems—we could simply ask them to explain their thought processes, and use this to check their reasoning and debug unwanted behaviors. However, we would need to take great care to validate these introspective reports. Some internal processes might still escape models’ notice (analogous to subconscious processing in humans). A model that understands its own thinking might even learn to selectively misrepresent or conceal it. A better grasp on the mechanisms at play could allow us to distinguish between genuine introspection and unwitting or intentional misrepresentations.&lt;/p&gt;
    &lt;p&gt;More broadly, understanding cognitive abilities like introspection is important for understanding basic questions about how our models work, and what kind of minds they possess. As AI systems continue to improve, understanding the limits and possibilities of machine introspection will be crucial for building systems that are more transparent and trustworthy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Frequently Asked Questions&lt;/head&gt;
    &lt;p&gt;Below, we discuss some of the questions readers might have about our results. Broadly, we are still very uncertain about the implications of our experiments–so fully answering these questions will require more research.&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: Does this mean that Claude is conscious?&lt;/head&gt;
    &lt;p&gt;Short answer: our results don’t tell us whether Claude (or any other AI system) might be conscious.&lt;/p&gt;
    &lt;p&gt;Long answer: the philosophical question of machine consciousness is complex and contested, and different theories of consciousness would interpret our findings very differently. Some philosophical frameworks place great importance on introspection as a component of consciousness, while others don’t.&lt;/p&gt;
    &lt;p&gt;One distinction that is commonly made in the philosophical literature is the idea of “phenomenal consciousness,” referring to raw subjective experience, and “access consciousness,” the set of information that is available to the brain for use in reasoning, verbal report, and deliberate decision-making. Phenomenal consciousness is the form of consciousness most commonly considered relevant to moral status, and its relationship to access consciousness is a disputed philosophical question. Our experiments do not directly speak to the question of phenomenal consciousness. They could be interpreted to suggest a rudimentary form of access consciousness in language models. However, even this is unclear. The interpretation of our results may depend heavily on the underlying mechanisms involved, which we do not yet understand.&lt;/p&gt;
    &lt;p&gt;In the paper, we restrict our focus to understanding functional capabilities—the ability to access and report on internal states. That said, we do think that as research on this topic progresses, it could influence our understanding of machine consciousness and potential moral status, which we are exploring in connection with our model welfare program.&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: How does introspection actually work inside the model? What's the mechanism?&lt;/head&gt;
    &lt;p&gt;We haven't figured this out yet. Understanding this is an important topic for future work. That said, we have some educated guesses about what might be going on. The simplest explanation for all our results isn’t one general-purpose introspection system, but rather multiple narrow circuits that each handle specific introspective tasks, possibly piggybacking on mechanisms that were learned for other purposes.&lt;/p&gt;
    &lt;p&gt;In the “noticing injected thoughts” experiment, there might be an anomaly detection mechanism, which flags when neural activity deviates unexpectedly from what would be normal given the context. This mechanism could work through dedicated neural patterns that measure activity along certain directions and activate when things are “off” compared to their expected values. An interesting question is why such a mechanism would exist at all, since models never experience concept injection during training. It may have developed for some other purpose, like detecting inconsistencies or unusual patterns in normal processing–similar to how bird feathers may have originally evolved for thermoregulation before being co-opted for flight.&lt;/p&gt;
    &lt;p&gt;For the “detecting prefilled outputs” experiment, we suspect there exists an attention-mediated mechanism that checks consistency between what the model intended to say and what actually got output. Attention heads might compare the model’s cached prediction of the next token (its “intention”) against the actual token that appears, flagging mismatches.&lt;/p&gt;
    &lt;p&gt;For the “controlling thoughts” experiment, we speculate that there might be a circuit that computes how “attention-worthy” a token or concept is and marks it accordingly—essentially tagging it as salient and worth attending to. Interestingly, this same mechanism seems to respond to incentives (“if you think about X, you will be rewarded”) just as it does to direct instructions. This suggests it’s a fairly general system, which probably developed for tasks where the model needs to keep certain topics in mind while generating text about them.&lt;/p&gt;
    &lt;p&gt;All of the mechanisms described above are speculative. Future work with more advanced interpretability techniques will be needed to really understand what's going on under the hood.&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: In the “injected thoughts” experiment, isn’t the model just saying the word because you steered it to talk about that concept?&lt;/head&gt;
    &lt;p&gt;Indeed, activation steering typically makes models talk about the steered concept (we’ve explored this in our prior work). To us, the most interesting part of the result isn't that the model eventually identifies the injected concept, but rather that the model correctly notices something unusual is happening before it starts talking about the concept.&lt;/p&gt;
    &lt;p&gt;In the successful trials, the model says things like “I'm experiencing something unusual” or “I detect an injected thought about…” The key word here is “detect.” The model is reporting awareness of an anomaly in its processing before that anomaly has had a chance to obviously bias its outputs. This requires an extra computational step beyond simply regurgitating the steering vector as an output. In our quantitative analyses, we graded responses as demonstrating “introspective awareness” based on whether the model detected the injected concept prior to mentioning the injected word.&lt;/p&gt;
    &lt;p&gt;Note that our prefill detection experiment has a similar flavor: it requires the model to perform an extra step of processing on top of the injected concept (comparing it to the prefilled output, in order to determine whether to apologize for that output or double down on it).&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: If models can only introspect a fraction of the time, how useful is this capability?&lt;/head&gt;
    &lt;p&gt;The introspective awareness we observed is indeed highly unreliable and context-dependent. Most of the time, models fail to demonstrate introspection in our experiments. However, we think this is still significant for a few reasons. First, the most capable models that we tested (Opus 4 and 4.1 – note that we did not test Sonnet 4.5) performed best, suggesting this capability might improve as models become more intelligent. Second, even unreliable introspection could be useful in some contexts—for instance, helping models recognize when they've been jailbroken.&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: Couldn’t the models just be making up answers to introspective questions?&lt;/head&gt;
    &lt;p&gt;This is exactly the question we designed our experiments to address. Models are trained on data that includes examples of people introspecting, so they can certainly act introspective without actually being introspective. Our concept injection experiments distinguish between these possibilities by establishing known ground-truth information about the model’s internal states, which we can compare against its self-reported states. Our results suggest that in some examples, the model really is accurately basing its answers on its actual internal states, not just confabulating. However, this doesn’t mean that models always accurately report their internal states—in many cases, they are making things up!&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: How do you know the concept vectors you’re injecting actually represent what you think they represent?&lt;/head&gt;
    &lt;p&gt;This is a legitimate concern. We can’t be absolutely certain that the “meaning” (to the model) of our concept vectors is exactly what we intend. We tried to address this by testing across many different concept vectors. The fact that models correctly identified injected concepts across these diverse examples suggests our vectors are at least approximately capturing the intended meanings. But it’s true that pinning down exactly what a vector “means” to a model is challenging, and this is a limitation of our work.&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: Didn’t we already know that models could introspect?&lt;/head&gt;
    &lt;p&gt;Previous research has shown evidence for model capabilities that are suggestive of introspection. For instance, prior work has shown that models can to some extent estimate their own knowledge, recognize their own outputs, predict their own behavior, and identify their own propensities. Our work was heavily motivated by these findings, and is intended to provide more direct evidence for introspection by tying models’ self-reports to their internal states. Without tying behaviors to internal states in this way, it is difficult to distinguish a model that genuinely introspects from one that makes educated guesses about itself.&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: What makes some models better at introspection than others?&lt;/head&gt;
    &lt;p&gt;Our experiments focused on Claude models across several generations (Claude 3, Claude 3.5, Claude 4, Claude 4.1, in the Opus, Sonnet, and Haiku variants). We tested both production models and “helpful-only” variants that were trained differently. We also tested some base pretrained models before post-training.&lt;/p&gt;
    &lt;p&gt;We found that post-training significantly impacts introspective capabilities. Base models generally performed poorly, suggesting that introspective capabilities aren’t elicited by pretraining alone. Among production models, the pattern was clearer at the top end: Claude Opus 4 and 4.1—our most capable models—performed best across most of our introspection tests. However, beyond that, the correlation between model capability and introspective ability was weak. Smaller models didn't consistently perform worse, suggesting the relationship isn't as simple as “more capable are more introspective.”&lt;/p&gt;
    &lt;p&gt;We also noticed something unexpected with post-training strategies. “Helpful-only” variants of several models often performed better at introspection than their production counterparts, even though they underwent the same base training. In particular, some production models appeared reluctant to engage in introspective exercises, while the helpful-only variants showed more willingness to report on their internal states. This suggests that how we fine-tune models can elicit or suppress introspective capabilities to varying degrees.&lt;/p&gt;
    &lt;p&gt;We’re not entirely sure why Opus 4 and 4.1 perform so well (note that our experiments were conducted prior to the release of Sonnet 4.5). It could be that introspection requires sophisticated internal mechanisms that only emerge at higher capability levels. Or it might be that their post-training process better encourages introspection. Testing open-source models, and models from other organizations, could help us determine whether this pattern generalizes or if it’s specific to how Claude models are trained.&lt;/p&gt;
    &lt;head rend="h4"&gt;Q: What’s next for this research?&lt;/head&gt;
    &lt;p&gt;We see several important directions. First, we need better evaluation methods—our experiments used specific prompts and injection techniques that might not capture the full range of introspective capabilities. Second, we need to understand the mechanisms underlying introspection. We have some speculative hypotheses about possible circuits (like anomaly detection mechanisms or concordance heads), but we haven’t definitively identified how introspection works. Third, we need to study introspection in more naturalistic settings, since our injection methodology creates artificial scenarios. Finally, we need to develop methods to validate introspective reports and detect when models might be confabulating or deceiving. We expect that understanding machine introspection and its limitations will become more important as models become more capable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45762064</guid><pubDate>Thu, 30 Oct 2025 16:45:06 +0000</pubDate></item><item><title>How We Found 7 TiB of Memory Just Sitting Around</title><link>https://render.com/blog/how-we-found-7-tib-of-memory-just-sitting-around</link><description>&lt;doc fingerprint="aec895875436e7e0"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Inside the hypercube of bad vibes: the namespace dimension&lt;/head&gt;
    &lt;p&gt;Credits: Hyperkube from gregegan.net, diagram (modified) from Kubernetes community repo&lt;/p&gt;
    &lt;p&gt;Plenty of teams run Kubernetes clusters bigger than ours. More nodes, more pods, more ingresses, you name it. In most dimensions, someone out there has us beat.&lt;/p&gt;
    &lt;p&gt;There's one dimension where I suspect we might be near the very top: namespaces. I say that because we keep running into odd behavior in any process that has to keep track of them. In particular, anything that listwatches them ends up using a surprising amount of memory and puts real pressure on the apiserver. This has become one of those scaling quirks you only really notice once you hit a certain threshold. As this memory overhead adds up, efficiency decreases: each byte we have to use for management is a byte we can't put towards user services.&lt;/p&gt;
    &lt;p&gt;The problem gets significantly worse when a daemonset needs to listwatch namespaces or network policies (netpols, which we define per namespace). Since daemonsets run a pod on every node, each of those pods independently performs a listwatch on the same resources. As a result, memory usage increases with the number of nodes.&lt;/p&gt;
    &lt;p&gt;Even worse, these listwatch calls can put significant load on the apiserver. If many daemonset pods restart at once, such as during a rollout, they can overwhelm the server with requests and cause real disruption.&lt;/p&gt;
    &lt;head rend="h2"&gt;Following the memory trail&lt;/head&gt;
    &lt;p&gt;A few months ago, if you looked at our nodes, the largest memory consumers were often daemonsets. In particular, Calico and Vector which handle configuring networking and log collection respectively.&lt;/p&gt;
    &lt;p&gt;We had already done some work to reduce Calico’s memory usage, working closely with the project’s maintainers to make it scale more efficiently. That optimization effort was a big win for us, and it gave us useful insight into how memory behaves when namespaces scale up.&lt;/p&gt;
    &lt;p&gt;To support that work, we set up a staging cluster with several hundred thousand namespaces. We knew that per-namespace network policies (netpols) were the scaling factor that stressed Calico, so we reproduced those conditions to validate our changes.&lt;/p&gt;
    &lt;p&gt;While running those tests, we noticed something strange. Vector, another daemonset, also started consuming large amounts of memory.&lt;/p&gt;
    &lt;p&gt;The pattern looked familiar, and we knew we had another problem to dig into. Vector obviously wasn’t looking at netpols but after poking around a bit we found it was listwatching namespaces from every node in order to allow referencing namespace labels per-pod in the kubernetes logs source.&lt;/p&gt;
    &lt;head rend="h2"&gt;Do we really need these labels?&lt;/head&gt;
    &lt;p&gt;That gave us an idea: what if Vector didn’t need to use namespaces at all? Was that even possible?&lt;/p&gt;
    &lt;p&gt;As it turns out, yes, they were in use in our configuration, but only to check whether a pod belonged to a user namespace.&lt;/p&gt;
    &lt;p&gt;Conveniently, we realized we could hackily describe that condition in another way, and the memory savings were absolutely worth it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building the fix (and breaking the logs)&lt;/head&gt;
    &lt;p&gt;At that point, we were feeling a bit too lucky. We reached out to the Vector maintainers to ask whether disabling this behavior would actually work, and whether they would be open to accepting a contribution if we made it happen.&lt;/p&gt;
    &lt;p&gt;From there, all that was left was to try it. The code change was straightforward. We added a new config option and threaded it through the relevant parts of the codebase.&lt;/p&gt;
    &lt;p&gt;After a few hours of flailing at rustc, a Docker image finally built and we were ready to test the theory. The container ran cleanly with no errors in the logs, which seemed promising.&lt;/p&gt;
    &lt;p&gt;But then we hit a snag. Nothing was being emitted. No logs at all. I couldn’t figure out why.&lt;/p&gt;
    &lt;p&gt;Thankfully, our pal Claude came to the rescue:&lt;/p&gt;
    &lt;p&gt;I rebuilt it (which took like 73 hours because Rust), generated a new image, updating staging, and watched nervously. This time, logs were flowing like normal and…&lt;/p&gt;
    &lt;head rend="h2"&gt;The numbers don’t add up&lt;/head&gt;
    &lt;p&gt;The change saved 50 percent of memory. A huge win. We were ready to wrap it up and ship to production.&lt;/p&gt;
    &lt;p&gt;But then Hieu, one of our teammates, asked a very good question.&lt;/p&gt;
    &lt;p&gt;He was right, something didn’t add up.&lt;/p&gt;
    &lt;p&gt;A few hours later, after repeatedly running my head into a wall, I still hadn’t found anything. There was still a full gibibyte of memory unaccounted for. My whole theory about how this worked was starting to fall apart.&lt;/p&gt;
    &lt;p&gt;I even dropped into the channel to see if anyone had Valgrind experience:&lt;/p&gt;
    &lt;p&gt;Me (later in channel): anybody got a background in valgrind? seems pretty straightforward to get working so far but it won’t end up interfacing with pyroscope. we’ll have to exec in and gdb manually.&lt;lb/&gt;The answer was no.&lt;/p&gt;
    &lt;p&gt;In a last-ditch effort to profile it again, I finally saw the answer. It had been staring me in the face the whole time.&lt;/p&gt;
    &lt;p&gt;We actually had two kubernetes_logs sources on user nodes. I had only set the flag on one of them. Once I applied it to both, memory usage dropped to the level we had seen in staging before the extra namespaces were added.&lt;/p&gt;
    &lt;head rend="h2"&gt;Shipping it&lt;/head&gt;
    &lt;p&gt;I put together a full pull request, and after waiting a little while, it shipped!&lt;/p&gt;
    &lt;p&gt;Around the same time, our colleague Mark happened to be on-call. He did his usual magic — pulled everything together, tested the rollout in staging, and got it shipped to production.&lt;/p&gt;
    &lt;p&gt;I’ll let the results speak for themselves.&lt;/p&gt;
    &lt;p&gt;Our largest cluster saw a 1 TiB memory drop, with savings across our other clusters adding up to a total of just over 7 TiB.&lt;/p&gt;
    &lt;head rend="h2"&gt;7 TiB later&lt;/head&gt;
    &lt;p&gt;Debugging infrastructure at scale is rarely about one big “aha” moment. It’s often the result of many small questions, small changes, and small wins stacked up until something clicks.&lt;/p&gt;
    &lt;p&gt;In this case, it started with a memory chart that didn’t look quite right, a teammate asking the right question at the right time, and a bit of persistence. When applied to our whole infrastructure, that simple fix freed up 7 TiB of memory, reduced risk during rollouts, and made the system easier to reason about.&lt;/p&gt;
    &lt;p&gt;Huge thanks to Hieu for pushing the investigation forward, Mark for shipping it smoothly, and the Vector maintainers for being responsive and open to the change.&lt;/p&gt;
    &lt;p&gt;If you’re running daemonsets at scale and seeing unexplained memory pressure, it might be worth asking:&lt;/p&gt;
    &lt;p&gt;Do you really need those namespace labels?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45763359</guid><pubDate>Thu, 30 Oct 2025 18:25:05 +0000</pubDate></item><item><title>Apple reports fourth quarter results</title><link>https://www.apple.com/newsroom/2025/10/apple-reports-fourth-quarter-results/</link><description>&lt;doc fingerprint="6546c90d827b1d74"&gt;
  &lt;main&gt;
    &lt;p&gt; PRESS RELEASE October 30, 2025 &lt;/p&gt;
    &lt;head rend="h1"&gt;Apple reports fourth quarter results&lt;/head&gt;
    &lt;p&gt; September quarter records for total company revenue, iPhone revenue and EPS&lt;lb/&gt;Services revenue reaches new all-time high&lt;/p&gt;
    &lt;p&gt;Services revenue reaches new all-time high&lt;/p&gt;
    &lt;p&gt;CUPERTINO, CALIFORNIA Apple today announced financial results for its fiscal 2025 fourth quarter ended September 27, 2025. The Company posted quarterly revenue of $102.5 billion, up 8 percent year over year. Diluted earnings per share was $1.85, up 13 percent year over year on an adjusted basis.1 &lt;/p&gt;
    &lt;p&gt;“Today, Apple is very proud to report a September quarter revenue record of $102.5 billion, including a September quarter revenue record for iPhone and an all-time revenue record for Services,” said Tim Cook, Apple’s CEO. “In September, we were thrilled to launch our best iPhone lineup ever, including iPhone 17, iPhone 17 Pro and Pro Max, and iPhone Air. In addition, we launched the fantastic AirPods Pro 3 and the all-new Apple Watch lineup. When combined with the recently announced MacBook Pro and iPad Pro with the powerhouse M5 chip, we are excited to be sharing our most extraordinary lineup of products as we head into the holiday season.” &lt;/p&gt;
    &lt;p&gt;“Our September quarter results capped off a record fiscal year, with revenue reaching $416 billion, as well as double-digit EPS growth,” said Kevan Parekh, Apple’s CFO. “And thanks to our very high levels of customer satisfaction and loyalty, our installed base of active devices also reached a new all-time high across all product categories and geographic segments.” &lt;/p&gt;
    &lt;p&gt;Apple’s board of directors has declared a cash dividend of $0.26 per share of the Company’s common stock. The dividend is payable on November 13, 2025, to shareholders of record as of the close of business on November 10, 2025. &lt;/p&gt;
    &lt;p&gt;Apple will provide live streaming of its Q4 2025 financial results conference call beginning at 2:00 p.m. PT on October 30, 2025, at apple.com/investor/earnings-call. The webcast will be available for replay for approximately two weeks thereafter. &lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Non-GAAP measure excluding the one-time income tax charge recognized during the fourth quarter of 2024 related to the impact of the reversal of the European General Court’s State Aid decision. See the section titled “Reconciliation of 2024 Non-GAAP to GAAP Results of Operations” at the end of the accompanying financial statements.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Consolidated Financial Statements&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Press Contact&lt;/head&gt;
    &lt;head rend="h2"&gt;Investor Relations Contact&lt;/head&gt;
    &lt;p&gt; © 2025 Apple Inc. All rights reserved. Apple and the Apple logo are trademarks of Apple. Other company and product names may be trademarks of their respective owners.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45764986</guid><pubDate>Thu, 30 Oct 2025 20:34:02 +0000</pubDate></item><item><title>Leaker reveals which Pixels are vulnerable to Cellebrite phone hacking</title><link>https://arstechnica.com/gadgets/2025/10/leaker-reveals-which-pixels-are-vulnerable-to-cellebrite-phone-hacking/</link><description>&lt;doc fingerprint="27564c1580bdbb20"&gt;
  &lt;main&gt;
    &lt;p&gt;Despite being a vast repository of personal information, smartphones used to have little by way of security. That has thankfully changed, but companies like Cellebrite offer law enforcement tools that can bypass security on some devices. The company keeps the specifics quiet, but an anonymous individual recently logged in to a Cellebrite briefing and came away with a list of which of Google’s Pixel phones are vulnerable to Cellebrite phone hacking.&lt;/p&gt;
    &lt;p&gt;This person, who goes by the handle rogueFed, posted screenshots from the recent Microsoft Teams meeting to the GrapheneOS forums (spotted by 404 Media). GrapheneOS is an Android-based operating system that can be installed on select phones, including Pixels. It ships with enhanced security features and no Google services. Because of its popularity among the security-conscious, Cellebrite apparently felt the need to include it in its matrix of Pixel phone support.&lt;/p&gt;
    &lt;p&gt;The screenshot includes data on the Pixel 6, Pixel 7, Pixel 8, and Pixel 9 family. It does not list the Pixel 10 series, which launched just a few months ago. The phone support is split up into three different conditions: before first unlock, after first unlock, and unlocked. The before first unlock (BFU) state means the phone has not been unlocked since restarting, so all data is encrypted. This is traditionally the most secure state for a phone. In the after first unlock (AFU) state, data extraction is easier. And naturally, an unlocked phone is open season on your data.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45766501</guid><pubDate>Thu, 30 Oct 2025 23:12:10 +0000</pubDate></item><item><title>My Impressions of the MacBook Pro M4</title><link>https://michael.stapelberg.ch/posts/2025-10-31-macbook-pro-m4-impressions/</link><description>&lt;doc fingerprint="f7cc1c0193a689f5"&gt;
  &lt;main&gt;
    &lt;p&gt;I have been using a MacBook Pro M4 as my portable computer for the last half a year and wanted to share a few short impressions. As always, I am not a professional laptop reviewer, so in this article you won’t find benchmarks, just subjective thoughts!&lt;/p&gt;
    &lt;p&gt;Back in 2021, I wrote about the MacBook Air M1, which was the first computer I used that contained Apple’s own ARM-based CPU. Having a silent laptop with long battery life was a game-changer, so I wanted to keep those properties.&lt;/p&gt;
    &lt;p&gt;When the US government announced tariffs, I figured I would replace my 4-year old MacBook Air M1 with a more recent model that should last a few more years. Ultimately, Apple’s prices remained stable, so, in retrospect, I could have stayed with the M1 for a few more years. Oh well.&lt;/p&gt;
    &lt;head rend="h2"&gt;The nano-textured display&lt;/head&gt;
    &lt;p&gt;I went to the Apple Store to compare the different options in person. Specifically, I was curious about the display and whether the increased weight and form factor of the MacBook Pro (compared to a MacBook Air) would be acceptable. Another downside of the Pro model is that it comes with a fan, and I really like absolutely quiet computers. Online, I read from other MacBook Pro owners that the fan mostly stays off.&lt;/p&gt;
    &lt;p&gt;In general, I would have preferred to go with a MacBook Air because it has enough compute power for my needs and I like the case better (no ventilation slots), but unfortunately only the MacBook Pro line has the better displays.&lt;/p&gt;
    &lt;p&gt;Why aren’t all displays nano-textured? The employee at the Apple Store presented the trade-off as follows: The nano texture display is great at reducing reflections, at the expense of also making the picture slightly less vibrant.&lt;/p&gt;
    &lt;p&gt;I could immediately see the difference when placing two laptops side by side: The bright Apple Store lights showed up very prominently on the normal display (left), and were almost not visible at all on the nano texture display (right):&lt;/p&gt;
    &lt;p&gt;Personally, I did not perceive a big difference in “vibrancy”, so my choice was clear: I’ll pick the MacBook Pro over the MacBook Air (despite the weight) for the nano texture display!&lt;/p&gt;
    &lt;p&gt;After using the laptop in a number of situations, I am very happy with this choice. In normal scenarios, I notice no reflections at all (where my previous laptop did show reflections!). This includes using the laptop on a train (next to the window), or using the laptop outside in daylight.&lt;/p&gt;
    &lt;head rend="h2"&gt;Specs: M4 or M4 Pro?&lt;/head&gt;
    &lt;p&gt;(When I chose the new laptop, Apple’s M4 chips were current. By now, they have released the first devices with M5 chips.)&lt;/p&gt;
    &lt;p&gt;I decided to go with the MacBook Pro with M4 chip instead of the M4 Pro chip because I don’t need the extra compute, and the M4 needs less cooling — the M4 Pro apparently runs hotter. This increases the chance of the fan staying off.&lt;/p&gt;
    &lt;p&gt;Here are the specs I ended up with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;14" Liquid Retina XDR Display with nano texture&lt;/item&gt;
      &lt;item&gt;Apple M4 Chip (10 core CPU, 10 core GPU)&lt;/item&gt;
      &lt;item&gt;32 GB RAM (this is the maximum!), 2 TB SSD (enough for this computer)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Impressions&lt;/head&gt;
    &lt;p&gt;One thing I noticed is that the MacBook Pro M4 sometimes gets warm, even when it is connected to power, but is suspended to RAM (and has been fully charged for hours). I’m not sure why.&lt;/p&gt;
    &lt;p&gt;Luckily, the fan indeed stays silent. I think I might have heard it spin up once in half a year or so?&lt;/p&gt;
    &lt;p&gt;The battery life is amazing! The previous MacBook Air M1 had amazing all-day battery life already, and this MacBook Pro M4 lasts even longer. For example, watching videos on a train ride (with VLC) for 3 hours consumed only 10% of battery life. I generally never even carry the charger.&lt;/p&gt;
    &lt;p&gt;Because of that, Apple’s re-introduction of MagSafe, a magnetic power connector (so you don’t damage the laptop when you trip over it), is nice-to-have but doesn’t really make much of a difference anymore. In fact, it might be better to pack a USB-C cable when traveling, as that makes you more flexible in how you use the charger.&lt;/p&gt;
    &lt;head rend="h2"&gt;120 Hz display&lt;/head&gt;
    &lt;p&gt;I was curious whether the 120 Hz display would make a difference in practice. I mostly notice the increased refresh rate when there are animations, but not, for example, when scrolling.&lt;/p&gt;
    &lt;p&gt;One surprising discovery (but obvious in retrospect) is that even non-animations can become faster. For example, when running a Go web server on &lt;code&gt;localhost&lt;/code&gt;, I
noticed that navigating between pages by clicking links felt faster on the 120
Hz display!&lt;/p&gt;
    &lt;p&gt;The following illustration shows why that is, using a page load that takes 6ms of processing time. There are three cases (the illustration shows an average case and the worst case):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Best case: Page load finishes just before the next frame is displayed: no delay.&lt;/item&gt;
      &lt;item&gt;Worst case: Page load finishes just after a frame is displayed: one frame of delay.&lt;/item&gt;
      &lt;item&gt;Most page loads are somewhere in between. We’ll have 0.x to 1.0 frames of delay&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As you can see, the waiting time becomes shorter when going from 60 Hz (one frame every 16.6ms) to 120 Hz (one frame every 8.3ms). So if you’re working with a system that has &amp;lt;8ms response times, you might observe actions completing (up to) twice as fast!&lt;/p&gt;
    &lt;p&gt;I don’t notice going back to 60 Hz displays on computers. However, on phones, where a lot more animations are a key part of the user experience, I think 120 Hz displays are more interesting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;My ideal MacBook would probably be a MacBook Air, but with the nano-texture display! :)&lt;/p&gt;
    &lt;p&gt;I still don’t like macOS and would prefer to run Linux on this laptop. But Asahi Linux still needs some work before it’s usable for me (I need external display output, and M4 support). This doesn’t bother me too much, though, as I don’t use this computer for serious work.&lt;/p&gt;
    &lt;p&gt;Did you like this post? Subscribe to this blog’s RSS feed to not miss any new posts!&lt;/p&gt;
    &lt;p&gt;I run a blog since 2005, spreading knowledge and experience for over 20 years! :)&lt;/p&gt;
    &lt;p&gt;If you want to support my work, you can buy me a coffee.&lt;/p&gt;
    &lt;p&gt;Thank you for your support! ❤️&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45770304</guid><pubDate>Fri, 31 Oct 2025 10:13:40 +0000</pubDate></item><item><title>The cryptography behind electronic passports</title><link>https://blog.trailofbits.com/2025/10/31/the-cryptography-behind-electronic-passports/</link><description>&lt;doc fingerprint="c9341c65e762bc1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The cryptography behind electronic passports&lt;/head&gt;
    &lt;p&gt;Did you know that most modern passports are actually embedded devices containing an entire filesystem, access controls, and support for several cryptographic protocols? Such passports display a small symbol indicating an electronic machine-readable travel document (eMRTD), which digitally stores the same personal data printed in traditional passport booklets in its embedded filesystem. Beyond allowing travelers in some countries to skip a chat at border control, these documents use cryptography to prevent unauthorized reading, eavesdropping, forgery, and copying.&lt;/p&gt;
    &lt;p&gt;This blog post describes how electronic passports work, the threats within their threat model, and how they protect against those threats using cryptography. It also discusses the implications of using electronic passports for novel applications, such as zero-knowledge identity proofs. Like many widely used electronic devices with long lifetimes, electronic passports and the systems interacting with them support insecure, legacy protocols that put passport holders at risk for both standard and novel use cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Electronic passport basics&lt;/head&gt;
    &lt;p&gt;A passport serves as official identity documentation, primarily for international travel. The International Civil Aviation Organization (ICAO) defines the standards for electronic passports, which (as suggested by the “Chip Inside” symbol) contain a contactless integrated circuit (IC) storing digital information. Essentially, the chip contains a filesystem with some access control to protect unauthorized reading of data. The full technical details of electronic passports are specified in ICAO Doc 9303; this blog post will mostly focus on part 10, which specifies the logical data structure (LDS), and part 11, which specifies the security mechanisms.&lt;/p&gt;
    &lt;p&gt;The filesystem architecture is straightforward, comprising three file types: master files (MFs) serving as the root directory; dedicated files (DFs) functioning as subdirectories or applications; and elementary files (EFs) containing actual binary data. As shown in the above figure, some files are mandatory, whereas others are optional. This blog post will focus on the eMRTD application. The other applications are part of LDS 2.0, which would allow the digital storage of travel records (digital stamps!), electronic visas, and additional biometrics (so you can just update your picture instead of getting a whole new passport!).&lt;/p&gt;
    &lt;head rend="h3"&gt;How the eMRTD application works&lt;/head&gt;
    &lt;p&gt;The following figure shows the types of files the eMRTD contains:&lt;/p&gt;
    &lt;p&gt;There are generic files containing common or security-related data; all other files are so-called data groups (DGs), which primarily contain personal information (most of which is also printed on your passport) and some additional security data that will become important later. All electronic passports must contain DGs 1 and 2, whereas the rest is optional.&lt;/p&gt;
    &lt;p&gt;Comparing the contents of DG1 and DG2 to the main passport page shows that most of the written data is stored in DG1 and the photo is stored in DG2. Additionally, there are two lines of characters at the bottom of the page called the machine readable zone (MRZ), which contains another copy of the DG1 data with some check digits, as shown in the following picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;Digging into the threat model&lt;/head&gt;
    &lt;p&gt;Electronic passports operate under a straightforward threat model that categorizes attackers based on physical access: those who hold a passport versus those who don’t. If you are near a passport but you do not hold it in your possession, you should not be able to do any of the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Read any personal information from that passport&lt;/item&gt;
      &lt;item&gt;Eavesdrop on communication that the passport has with legitimate terminals&lt;/item&gt;
      &lt;item&gt;Figure out whether it is a specific passport so you can trace its movements1&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even if you do hold one or more passports, you should not be able to do the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Forge a new passport with inauthentic data&lt;/item&gt;
      &lt;item&gt;Make a digital copy of the passport&lt;/item&gt;
      &lt;item&gt;Read the fingerprint (DG3) or iris (DG4) information2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Electronic passports use short-range RFID for communication (ISO 14443). You can communicate with a passport within a distance of 10–15 centimeters, but eavesdropping is possible at distances of several meters3. Because electronic passports are embedded devices, they need to be able to withstand attacks where the attacker has physical access to the device, such as elaborate side-channel and fault injection attacks. As a result, they are often certified (e.g., under Common Criteria).&lt;/p&gt;
    &lt;p&gt;We focus here on the threats against the electronic components of the passport. Passports have many physical countermeasures, such as visual effects that become visible under certain types of light. Even if someone can break the electronic security that prevents copying passports, they would still have to defeat these physical measures to make a full copy of the passport. That said, some systems (such as online systems) only interact digitally with the passport, so they do not perform any physical checks at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cryptographic mechanisms&lt;/head&gt;
    &lt;p&gt;The earliest electronic passports lacked most cryptographic mechanisms. Malaysia issued the first electronic passport in 1998, which predates the first ICAO eMRTD specifications from 2003. Belgium subsequently issued the first ICAO-compliant eMRTD in 2004, which in turn predates the first cryptographic mechanism for confidentiality specified in 2005.&lt;/p&gt;
    &lt;p&gt;While we could focus solely on the most advanced cryptographic implementations, electronic passports remain in circulation for extended periods (typically 5–10 years), meaning legacy systems continue operating alongside modern solutions. This means that there are typically many old passports floating around that do not support the latest and greatest access control mechanisms4. Similarly, not all inspection systems/terminals support all of the protocols, which means passports potentially need to support multiple protocols. All protocols discussed in the following are described in more detail in ICAO Doc 9303 Part 11.&lt;/p&gt;
    &lt;head rend="h3"&gt;Legacy cryptography&lt;/head&gt;
    &lt;p&gt;Legacy protection mechanisms for electronic passports provide better security than what they were replacing (nothing), even though they have key shortcomings regarding confidentiality and (to a lesser extent) copying.&lt;/p&gt;
    &lt;head rend="h4"&gt;Legacy confidentiality protections: How basic access control fails&lt;/head&gt;
    &lt;p&gt;In order to prevent eavesdropping, you need to set up a secure channel. Typically, this is done by deriving a shared symmetric key, either from some shared knowledge, or through a key exchange. However, the passport cannot have its own static public key and send it over the communication channel, because this would enable tracing of specific passports.&lt;/p&gt;
    &lt;p&gt;Additionally, it should only be possible to set up this secure channel if you have the passport in your possession. So, what sets holders apart from others? Holders can read the physical passport page that contains the MRZ!&lt;/p&gt;
    &lt;p&gt;This brings us to the original solution to set up a secure channel with electronic passports: basic access control (BAC). When you place your passport with the photo page face down into an inspection system at the airport, it scans the page and reads the MRZ. Now, both sides derive encryption and message authentication code (MAC) keys from parts of the MRZ data using SHA-1 as a KDF. Then, they exchange freshly generated challenges and encrypt-then-MAC these challenges together with some fresh keying material to prove that both sides know the key. Finally, they derive session keys from the keying material and use them to set up the secure channel.&lt;/p&gt;
    &lt;p&gt;However, BAC fails to achieve any of its security objectives. The static MRZ is just some personal data and does not have very high entropy, which makes it guessable. Even worse, if you capture one valid exchange between passport and terminal, you can brute-force the MRZ offline by computing a bunch of unhardened hashes. Moreover, passive listeners who know the MRZ can decrypt all communications with the passport. Finally, the fact that the passport has to check both the MAC and the challenge has opened up the potential for oracle attacks that allow tracing by replaying valid terminal responses.&lt;/p&gt;
    &lt;head rend="h4"&gt;Forgery prevention: Got it right the first time&lt;/head&gt;
    &lt;p&gt;Preventing forgery is relatively simple. The passport contains a file called the Document Security Object (EF.SOD), which contains a list of hashes of all the Data Groups, and a signature over all these hashes. This signature comes from a key pair that has a certificate chain back to the Country Signing Certificate Authority (CSCA). The private key associated with the CSCA certificate is one of the most valuable assets in this system, because anyone in possession of this private key5 can issue legitimate passports containing arbitrary data.&lt;/p&gt;
    &lt;p&gt;The process of reading the passport, comparing all contents to the SOD, and verifying the signature and certificate chain is called passive authentication (PA). This will prove that the data in the passport was signed by the issuing country. However, it does nothing to prevent the copying of existing passports: anyone who can read a passport can copy its data into a new chip and it will pass PA. While this mechanism is listed among the legacy ones, it meets all of its objectives and is therefore still used without changes.&lt;/p&gt;
    &lt;head rend="h4"&gt;Legacy copying protections: They work, but some issues remain&lt;/head&gt;
    &lt;p&gt;Preventing copying requires having something in the passport that cannot be read or extracted, like the private key of a key pair. But how does a terminal know that a key pair belongs to a genuine passport? Since countries are already signing the contents of the passport for PA, they can just put the public key in one of the data groups (DG15), and use the private key to sign challenges that the terminal sends. This is called active authentication (AA). After performing both PA and AA, the terminal knows that the data in the passport (including the AA public key) was signed by the government and that the passport contains the corresponding private key.&lt;/p&gt;
    &lt;p&gt;This solution has two issues: the AA signature is not tied to the secure channel, so you can relay a signature and pretend that the passport is somewhere it’s not. Additionally, the passport signs an arbitrary challenge without knowing the semantics of this message, which is generally considered a dangerous practice in cryptography6.&lt;/p&gt;
    &lt;head rend="h3"&gt;Modern enhancements&lt;/head&gt;
    &lt;p&gt;Extended Access Control (EAC) fixes some of the issues related to BAC and AA. It comprises chip authentication (CA), which is a better AA, and terminal authentication (TA), which authenticates the terminal to the passport in order to protect access to the sensitive information stored in DG3 (fingerprint) and DG4 (iris). Finally, password authenticated connection establishment (PACE7, described below) replaces BAC altogether, eliminating its weaknesses.&lt;/p&gt;
    &lt;head rend="h4"&gt;Chip Authentication: Upgrading the secure channel&lt;/head&gt;
    &lt;p&gt;CA is very similar to AA in the sense that it requires countries to simply store a public key in one of the DGs (DG14), which is then authenticated using PA. However, instead of signing a challenge, the passport uses the key pair to perform a static-ephemeral Diffie-Hellman key exchange with the terminal, and uses the resulting keys to upgrade the secure channel from BAC. This means that passive listeners that know the MRZ cannot eavesdrop after doing CA, because they were not part of the key exchange.&lt;/p&gt;
    &lt;head rend="h4"&gt;Terminal Authentication: Protecting sensitive data in DG3 and DG4&lt;/head&gt;
    &lt;p&gt;Similar to the CSCA for signing things, each country has a Country Verification Certificate Authority (CVCA), which creates a root certificate for a PKI that authorizes terminals to read DG3 and DG4 in the passports of that country. Terminals provide a certificate chain for their public key and sign a challenge provided by the passport using their private key. The CVCA can authorize document verifiers (DVs) to read one or both of DG3 and DG4, which is encoded in the certificate. The DV then issues certificates to individual terminals. Without such a certificate, it is not possible to access the sensitive data in DG3 and DG4.&lt;/p&gt;
    &lt;head rend="h4"&gt;Password Authenticated Connection Establishment: Fixing the basic problems&lt;/head&gt;
    &lt;p&gt;The main idea behind PACE is that the MRZ, much like a password, does not have sufficient entropy to protect the data it contains. Therefore, it should not be used directly to derive keys, because this would enable offline brute-force attacks. PACE can work with various mappings, but we describe only the simplest one in the following, which is the generic mapping. Likewise, PACE can work with other passwords besides the MRZ (such as a PIN), but this blog post focuses on the MRZ.&lt;/p&gt;
    &lt;p&gt;First, both sides use the MRZ data (the password) to derive8 a password key. Next, the passport encrypts9 a nonce using the password key and sends it to the terminal, which can decrypt it if it knows the password. The terminal and passport also perform an ephemeral Diffie-Hellman key exchange. Now, both terminal and passport derive a new generator of the elliptic curve by applying the nonce as an additive tweak to the (EC)DH shared secret10. Using this new generator, the terminal and passport perform another (EC)DH to get a second shared secret. Finally, they use this second shared secret to derive session keys, which are used to authenticate the (EC)DH public keys that they used earlier on in the protocol, and to set up the secure channel. Figure 6 shows a simplified protocol diagram.&lt;/p&gt;
    &lt;p&gt;Anyone who does not know the password cannot follow the protocol to the end, which will become apparent in the final step when they need to authenticate the data with the session keys. Before authenticating the terminal, the passport does not share any data that enables brute-forcing the password key. Non-participants who do know the password cannot derive the session keys because they do not know the ECDH private keys.&lt;/p&gt;
    &lt;head rend="h2"&gt;Gaps in the threat model: Why you shouldn’t give your passport to just anyone&lt;/head&gt;
    &lt;p&gt;When considering potential solutions to maintaining passports’ confidentiality and authenticity, it’s important to account for what the inspection system does with your passport, and not just the fancy cryptography the passport supports. If an inspection system performs only BAC/PACE and PA, anyone who has seen your passport could make an electronic copy and pretend to be you when interacting with this system. This is true even if your passport supports AA or CA.&lt;/p&gt;
    &lt;p&gt;Another important factor is tracing: the specifications aim to ensure that someone who does not know a passport’s PACE password (MRZ data in most cases) cannot trace that passport’s movements by interacting with it or eavesdropping on communications it has with legitimate terminals. They attempt to achieve this by ensuring that passports always provide random identifiers (e.g., as part of Type A or Type B ISO 14443 contactless communication protocols) and that the contents of publicly accessible files (e.g., those containing information necessary for performing PACE) are the same for every citizen of a particular country.&lt;/p&gt;
    &lt;p&gt;However, all of these protections go out of the window when the attacker knows the password. If you are entering another country and border control scans your passport, they can provide your passport contents to others, enabling them to track the movements of your passport. If you visit a hotel in Italy and they store a scan of your passport and get hacked, anyone with access to this information can track your passport. This method can be a bit onerous, as it requires contacting various nearby contactless communication devices and trying to authenticate to them as if they were your passport. However, some may still choose to include it in their threat models.&lt;/p&gt;
    &lt;p&gt;Some countries state in their issued passports that the holder should give it to someone else only if there is a statutory need. At Italian hotels, for example, it is sufficient to provide a prepared copy of the passport’s photo page with most data redacted (such as your photo, signature, and any personal identification numbers). In practice, not many people do this.&lt;/p&gt;
    &lt;p&gt;Even without the passport, the threat model says nothing about tracking particular groups of people. Countries typically buy large quantities of the same electronic passports, which comprise a combination of an IC and the embedded software implementing the passport specifications. This means that people from the same country likely have the same model of passport, with a unique fingerprint comprising characteristics like communication time, execution time11, supported protocols (ISO 14443 Type A vs Type B), etc. Furthermore, each country may use different parameters for PACE (supported curves or mappings, etc.), which may aid an attacker in fingerprinting different types of passports, as these parameters are stored in publicly readable files.&lt;/p&gt;
    &lt;head rend="h2"&gt;Security and privacy implications of zero-knowledge identity proofs&lt;/head&gt;
    &lt;p&gt;An emerging approach in both academic research and industry applications involves using zero-knowledge (ZK) proofs with identity documents, enabling verification of specific identity attributes without revealing complete document contents. This is a nice idea in theory, because this will allow proper use of passports where there is no statutory need to hand over your passport. However, there are security implications.&lt;/p&gt;
    &lt;p&gt;First of all, passports cannot generate ZK proofs by themselves, so this necessarily involves exposing your passport to a prover. Letting anyone or anything read your passport means that you downgrade your threat model with respect to that entity. So when you provide your passport to an app or website for the purposes of creating a ZK proof, you need to consider what they will do with the information in your passport. Will it be processed locally on your device, or will it be sent to a server? If the data leaves your device, will it be encrypted and only handled inside a trusted execution environment (TEE)? If so, has this whole stack been audited, including against malicious TEE operators?&lt;/p&gt;
    &lt;p&gt;Second, if the ZK proving service relies on PA for its proofs, then anyone who has ever seen your passport can pretend to be you on this service. Full security requires AA or CA. As long as there exists any service that relies only on PA, anyone whose passport data is exposed is vulnerable to impersonation. Even if the ZK proving service does not incorporate AA or CA in their proofs, they should still perform one of these procedures with the passport to ensure that only legitimate passports sign up for this service12.&lt;/p&gt;
    &lt;p&gt;Finally, the system needs to consider what happens when people share their ZK proof with others. The nice thing about a passport is that you cannot easily make copies (if AA or CA is used), but if I can allow others to use my ZK proof, then the value of the identification decreases.&lt;/p&gt;
    &lt;p&gt;It is important that such systems are audited for security, both from the point of view of the user and the service provider. If you’re implementing ZK proofs of identity documents, contact us to evaluate your design and implementation.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;This is only guaranteed against people that do not know the contents of the passport. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Unless you are authorized to do so by the issuing country. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;See also this BSI white paper. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is allowed to issue passports that only support the legacy access control mechanism (BAC) until the end of 2026, and issuing passports that support BAC in addition to the latest mechanism is allowed up to the end of 2027. Given that passports can be valid for, e.g., 10 years, this means that this legacy mechanism will stay relevant until the end of 2037. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ICAO Doc 9303 part 12 recommends that these keys are “generated and stored in a highly protected, off-line CA Infrastructure.” Generally, these keys are stored on an HSM in some bunker. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Some detractors (e.g., Germany) claim that you could exploit this practice to set up a tracing system where the terminal generates the challenge in a way that proves the passport was at a specific place at a specific time. However, proving that something was signed at a specific time (let alone in a specific place!) is difficult using cryptography, so any system requires you to trust the terminal. If you trust the terminal, you don’t need to rely on the passport’s signature. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sometimes also called Supplemental Access Control ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The key derivation function is either SHA-1 or SHA-256, depending on the length of the key. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The encryption is either 2-key Triple DES or AES 128, 192, or 256 in CBC mode. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The new generator is given by sG+H, where s is the nonce, G is the generator, and H is the shared secret. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The BAC traceability paper from 2010 shows timings for passports from various countries, showing that each has different response times to various queries. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Note that this does not prevent malicious parties from creating their own ZK proofs according to the scheme used by the service. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45770875</guid><pubDate>Fri, 31 Oct 2025 11:33:41 +0000</pubDate></item><item><title>Perfetto: Swiss army knife for Linux client tracing</title><link>https://lalitm.com/perfetto-swiss-army-knife/</link><description>&lt;doc fingerprint="261004571ee704bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Perfetto: Swiss Army Knife for Linux Client Tracing&lt;/head&gt;
    &lt;p&gt;I gave a talk at the 2025 Tracing Summit last month titled “Perfetto: The Swiss Army Knife of Linux Client/Embedded Tracing”. My goal in this talk was to show how Linux kernel, systems and embedded developers can use Perfetto when debugging and root-causing performance issues in their respective domains. Even though the Perfetto UI is primarily built for viewing Android or Chrome traces, it is a flexible tool and can be used in many other ways!&lt;/p&gt;
    &lt;p&gt;The talk was recorded and is available on YouTube. Taking inspiration from Simon Willison, this post is an annotated presentation containing my slides and detailed notes on them. The talk also has a lot of UI demos: for these, I’ll have a screenshot but also a link to the relevant part of the video (videos are unbeatable for UI!).&lt;/p&gt;
    &lt;p&gt;First, what is Perfetto? Perfetto is fundamentally a suite of tools: it’s not just one thing but a bunch of different tools working together to help you debug and root-cause problems. This diagram shows how everything fits together, with the core parts of the Perfetto project in the center.&lt;/p&gt;
    &lt;p&gt;The recording tools for Perfetto consist of 1) an SDK for C++ apps 2) a daemon that can collect data from ftrace, /proc, /sys, and various kernel interfaces 3) another daemon that amalgamates trace data from multiple processes into a single trace file. These tools all speak the Perfetto protobuf format, a high-performance trace format designed to be very efficient to write but not to analyze or consume directly.&lt;/p&gt;
    &lt;p&gt;That’s where the trace processor comes in. It’s a C++ library that parses the protobuf format, but also a bunch of other widely used trace formats. It exposes this data via an SQL query interface to any embedding program including Perfetto UI (which is what most of this talk is about) and also to the Python API if you want to do ad-hoc scripting or analysis in Python.&lt;/p&gt;
    &lt;p&gt;There are also very common tracing/profiling formats used by the Linux community: perf.data, ftrace text format, Firefox profiler format, and many others. Perfetto supports quite a few of those directly. There’s also the Chrome JSON format (AKA the Trace Event Format) which is a simpler interchange format. It’s not the most efficient to read or write, but it does the job for a lot of use cases.&lt;/p&gt;
    &lt;p&gt;Often people write converters. They have their own tracing format, maybe proprietary, maybe open source but something we don’t know about, and it’s very common that people convert to one of the formats we understand, most commonly our protobuf or Chrome JSON formats.&lt;/p&gt;
    &lt;p&gt;The Perfetto UI is fundamentally a web-based trace visualizer, combining timeline visualization, user-driven selection/aggregation, and SQL queries all in one interface. Because it has the trace processor as a backend, it works with a bunch of different trace formats.&lt;/p&gt;
    &lt;p&gt;It’s very important to note that even though the Perfetto UI is web-based, everything happens inside your browser and trace data never leaves your system. You can even build it and host it yourself on any static server: we’ve made it extremely easy to do so!&lt;/p&gt;
    &lt;p&gt;At the start of 2025, we actually moved our whole development to GitHub. In the past, we used to develop on Android and GitHub was just a mirror. That’s no longer the case, GitHub is actually where we develop and take pull requests.&lt;/p&gt;
    &lt;p&gt;Most of this talk, I’m going to spend actually showing you how you can use the Perfetto UI to debug performance issues on Linux. I don’t want to show you an Android trace which needs a lot of context about how the Android system works and so you think, “oh, that was cool, but I didn’t really understand what was happening.”&lt;/p&gt;
    &lt;p&gt;So to make this talk more approachable, I wrote a straightforward demo program you can look at yourself! So it’s obviously not a production system but I’ve tried to make it as representative of the sort of issues we use Perfetto for every day.&lt;/p&gt;
    &lt;p&gt;It’s a Rust program which generates a Julia set and visualizes it over time. The technologies I used: Vulkan, GPU rendering and also multi-threaded CPU computation. So how it works is that computation of various parameters is happening on background threads, and then that’s being passed to the main thread for rendering.&lt;/p&gt;
    &lt;p&gt;And then, for demonstration purposes, there is a performance bug; rendering should run at 60 FPS, but every so often, the frame rate drops dramatically. Here’s what that looks like:&lt;/p&gt;
    &lt;p&gt;The code is on GitHub and if you’re interested in following along. The traces are there as well - you don’t have to collect the traces yourself, but you can if you want. All the instructions and information is in the README.&lt;/p&gt;
    &lt;p&gt;So the first suspicion we may have is that maybe it’s some CPU problem. A lot of engineers I know would reach for perf immediately whenever they see a problem like this. The main reason is that if perf can capture the problem, they can go straight to the line of code without needing to spend time debugging using more complex approaches.&lt;/p&gt;
    &lt;p&gt;You can record a perf profile with &lt;code&gt;perf record -k mono -g ./fractal_renderer&lt;/code&gt;. The standard post-processing step which I think a lot of people do would be to generate an SVG flame graph out of this with &lt;code&gt;perf script | stack-collapse-perf.pl --all | flamegraph.pl &amp;gt; fractal-frame.svg&lt;/code&gt;. Here’s how that looks like for our perf profile:&lt;/p&gt;
    &lt;p&gt;See also the interactive version of the profile&lt;/p&gt;
    &lt;p&gt;The flame graph shows the thread names at the bottom, and then stacked above are the call stacks of what the program is doing. The width represents how much time is spent in each function. In this case, the worker threads are spending most of their time in &lt;code&gt;cos&lt;/code&gt; and &lt;code&gt;sin&lt;/code&gt; operations, doing math computation. Exactly what you’d expect for this type of program. Aside: Interestingly demangling didn’t seem to work for Rust out of the box which I find a bit unusual but I didn’t dig too much into why this was.&lt;/p&gt;
    &lt;p&gt;Looking at this, nothing really stands out. There’s no smoking gun that immediately reveals the problem. But here’s the fundamental limitation: the flame graph aggregates data across the entire trace, losing the time dimension. The performance problem we’re seeing happens every 2-3 seconds - brief drops in an otherwise normally functioning program.&lt;/p&gt;
    &lt;p&gt;The flame graph shows me the aggregate, dominated by the correct behavior, making it nearly impossible to spot those occasional problematic moments. So how do I find the places where it’s doing the wrong thing?&lt;/p&gt;
    &lt;p&gt;Well, that’s maybe where Perfetto can help you out a little bit! The thing I find lots of people don’t know is that perf actually preserves timestamp information about when samples were taken: many tools drop this information but Perfetto is pretty good at showing that to you. I just need post-process the trace with &lt;code&gt;perf script &amp;gt; fractal.perftext&lt;/code&gt; to generate a text version of the profile which we can then open in the Perfetto UI&lt;/p&gt;
    &lt;p&gt;My demo talking through how to open the perf profile and navigate it starts at 9:11 in the video.&lt;/p&gt;
    &lt;p&gt;Screenshot from 9:50 in the video&lt;/p&gt;
    &lt;p&gt;The x-axis of what you’re seeing is time. And every horizontal line represents a thread: we call these lanes “tracks”. And each of the small arrowheads on the tracks are CPU samples for the associated thread.&lt;/p&gt;
    &lt;p&gt;The behavior of the worker threads over time is really interesting. Most of the lifetime of the program, it’s doing continuous computation, basically. And then there’s this period of time in the middle where there’s this very interesting staircase pattern where it seems like only one thread is running at any one time: we’ll want to keep a note of this as this is quite important.&lt;/p&gt;
    &lt;p&gt;Screenshot from 10:37 in the video&lt;/p&gt;
    &lt;p&gt;One very cool thing about Perfetto is that it allows me to quickly generate visualizations of whatever I’m selecting on the timeline. We call this “area selection” and it’s where I drag my mouse and select a region both horizontally and vertically. This is on one track but even across multiple tracks. So in the timeline it shows me the selection I’m making at the top, plus a flame graph at the bottom representing the aggregation of the samples in just that time period.&lt;/p&gt;
    &lt;p&gt;The key advantage is that I can look at individual regions of time interactively. You can also do this with &lt;code&gt;flamegraph.pl&lt;/code&gt; but you need to pre-filter the data to what you’re looking for. This assumes you already know what the problem is before you find it. I always find that a bit counterintuitive. I prefer this view where I can see everything first, then decide “I want to look at this specific part in more detail.” That’s what Perfetto lets me do.&lt;/p&gt;
    &lt;p&gt;Screenshot from 12:31 in the video&lt;/p&gt;
    &lt;p&gt;So now on to the flame graph itself: in the last year, I spent a bunch of time on improving the flame graph visualization in Perfetto UI. At Google, we have an internal tool called pprof (related to but not the same as the open-source one), and I’ve always loved the visualization it has. So I worked to make Perfetto’s flame graph look and behave very similarly.&lt;/p&gt;
    &lt;p&gt;There are a bunch of features here. You can zoom in like most flame graph, but you can also say “I only want to look at the stack starting from this point” — it gets rid of everything above and starts fresh from there. If I don’t want to see a particular function like &lt;code&gt;sin&lt;/code&gt;, I can just hide the frame and it gets merged into its parent. The search is regex-based so I can also just type the specific things I’m interested in: it’s pretty powerful.&lt;/p&gt;
    &lt;p&gt;There’s also something I don’t think I’ve seen in other visualizers (I might be wrong, please do correct me!): what I call “bottom up” view. Imagine you take all the leaves across your entire program and visualize who’s calling into them. If you have a leaf function that’s called everywhere in your program but reached from many different places, it’ll be split across your flame chart. This is the inverse — you’re looking at the leaves and asking “who is calling me?” This is particularly useful when you’re trying to optimize very low-level functions that are always at the leaf level — things like memcpy or hashmap operations.&lt;/p&gt;
    &lt;p&gt;So our main takeaway is that our worker threads all had gaps in their CPU execution in a staircase pattern. This means the threads weren’t actually on the CPU and that’s usually a sign that they’re sleeping.&lt;/p&gt;
    &lt;p&gt;But sleeping on what? Locks? Disk? Network? What exactly is happening? To answer that, I need a scheduler trace to show me the wake-up patterns, who’s being scheduled when, what type of sleep threads are in, that sort of thing.&lt;/p&gt;
    &lt;p&gt;We recently added support for trace-cmd’s text format in Perfetto (aside: there’s an open issue to support the binary format too!). For this demo, I’m collecting sched_switch and sched_waking events with &lt;code&gt;sudo trace-cmd record -e sched:sched_switch -e sched:sched_waking -C mono ./fractal-renderer-vk&lt;/code&gt; and we can open it in the UI once we do &lt;code&gt;trace-cmd report -N &amp;gt; fractal.sched&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The demo showing off scheduler traces starts at 15:16 in the video.&lt;/p&gt;
    &lt;p&gt;Screenshot from 15:49 in the video&lt;/p&gt;
    &lt;p&gt;So this is what a scheduler trace looks like. Again as before, the x-axis is time. At the top of the trace, you’ve got the CPU scheduling tracks. For each CPU, they tell us what was scheduled on that CPU at each point in time. The white regions are where there’s nothing scheduled. As I zoom in, you start to see information like the name of the thread that’s scheduled, the TID of the thread, and so on. This is the CPU view of things, looking at it from a CPU perspective.&lt;/p&gt;
    &lt;p&gt;Screenshot from 16:48 in the video&lt;/p&gt;
    &lt;p&gt;There’s also a thread perspective on scheduling: what we call this “thread state”. This shows the scheduling state of each thread at every point in time. Dark green represents the thread running, light green represents runnable (the thread is on the runqueue so it’s eligible to run, but the scheduler hasn’t actually let it run yet), and white represents interruptible sleep (S sleep). There are also orange regions for uninterruptible sleep (D sleep), though that doesn’t show up much in this trace.&lt;/p&gt;
    &lt;p&gt;You can again see a very clear staircase-like pattern. Again, only one thread seems to be running at any one time. You’re maybe getting the sense of what the problem might be at this point.&lt;/p&gt;
    &lt;p&gt;Screenshot from 17:43 in the video&lt;/p&gt;
    &lt;p&gt;Like with the perf visualization, you can do area selections here too. I can select a region on a CPU and get tables showing time spent by each thread (shown in the screenshot above). I can also do this for thread state, you can also see that runnable time is basically negligible compared to running and sleeping, which is where most of the time is being spent.&lt;/p&gt;
    &lt;p&gt;Screenshot from 18:12 in the video&lt;/p&gt;
    &lt;p&gt;There are also scheduler-specific visualizations like run queue length and active CPU count. You can see in the problematic region, the active CPU count also went down, which makes sense.&lt;/p&gt;
    &lt;p&gt;So the scheduler trace shows when threads are sleeping, but it’s not telling us why. What was the program doing in that region? What code was it running? The sequential pattern suggests some sort of serialization—something is causing only one thread to run at a time. But we need application-level visibility.&lt;/p&gt;
    &lt;p&gt;Since this program was written in Rust, I just used the off-the-shelf &lt;code&gt;tracing&lt;/code&gt; and &lt;code&gt;tracing-perfetto&lt;/code&gt; crates; I did have to make some small modifications to tracing-perfetto that I’m hoping to upstream. These output a Perfetto trace without needing to use the Perfetto SDK. These libraries are also maintained by others: we don’t have any hand in them.&lt;/p&gt;
    &lt;p&gt;All I needed to do was integrate these into my program and then add a command line switch to write out the collected trace to a file. So I just do &lt;code&gt;./fractal_renderer --trace fractal.pftrace&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;My demo for app tracing starts at 19:37 in the video.&lt;/p&gt;
    &lt;p&gt;Screenshot from 20:06 in the video&lt;/p&gt;
    &lt;p&gt;Looking at the app trace: as before x-axis is time and each of the tracks represents a thread. Instead of scheduling activity or CPU stack samples, this time the tracks is userspace instrumentation of the program itself. Each of these rectangles is a named period of time representing what the program was doing at that time.&lt;/p&gt;
    &lt;p&gt;There are lots of different names for these in the tracing world (e.g. spans, intervals) but we call these “slices”. The main thread is rendering frames as you would expect and the workers are each computing tiles of that frame, which eventually feed back to the main thread and sync to the GPU.&lt;/p&gt;
    &lt;p&gt;Screenshot from 23:42 in the video&lt;/p&gt;
    &lt;p&gt;There’s also this thing called flows, which shows the causal links between different pieces. Render frame is calling into all these places and causing them to happen. It’s sort of similar to wakeup graphs but for user space: basically, this is what caused me to start running this function.&lt;/p&gt;
    &lt;p&gt;Screenshot from 23:51 in the video&lt;/p&gt;
    &lt;p&gt;So you can see very clearly there’s a normal region and then a region where things are taking 1.8 seconds: almost certainly the cause of the frame drops.&lt;/p&gt;
    &lt;p&gt;And if we look at the slice in question, it seems to be doing something called “update adaptive quality.” Basically, I wrote some code to dynamically change the rendering quality based on frame rate. If I’m running faster, I can render at higher quality. If I’m running slower, I can do lower quality. That’s what this adaptive quality thing is supposed to do.&lt;/p&gt;
    &lt;p&gt;But clearly something has gone wrong. I’m causing frame drops because of updates to adaptive quality. A little bit ironic, to say the least. Now we know what the program is actually doing during that time span.&lt;/p&gt;
    &lt;p&gt;So now we’ve looked at three different sources of debugging data separately. In perf, we got told there are few or no CPU samples and weird staircase patterns. In ftrace, we saw only one worker seems to be active and the rest are sleeping in interruptible sleep. And in app tracing, we see it’s because of adaptive quality updates that workers are working on, and they shouldn’t be doing it this way.&lt;/p&gt;
    &lt;p&gt;Obviously, the theory is that it’s all the same problem. But we can confirm this theory with a very new (and still experimental) feature of the UI: trace merging.&lt;/p&gt;
    &lt;p&gt;Note: as this part of Perfetto is still experimental, if you want to try it yourself, you need to go to plugins and enable the “MultiTraceOpen” plugin. Also, unlike I what say in the talk, you do not need to be on Autopush as all the features I showed in my talk are now available in Stable.&lt;/p&gt;
    &lt;p&gt;The demo showing off merged traces starts at 24:32 in the video.&lt;/p&gt;
    &lt;p&gt;Screenshot from 25:44 in the video&lt;/p&gt;
    &lt;p&gt;This is now the merged trace file containing all the different information. You can see the CPU scheduling tracks like we had in the scheduler trace, the stack samples like we had in the perf trace, and the app instrumentation, all beside each other on one timeline. You can very clearly see the adaptive quality update running, then this period where it ran, and then it was done. It’s very cool to be able to see the pattern of how my program is sleeping and where and what it was running on one timeline.&lt;/p&gt;
    &lt;p&gt;The thing is, you’ve always been able to do this with Perfetto if you collect a Perfetto trace with all of these integrated. The new capability is that this is now being brought to traces you didn’t collect with Perfetto. Collect it with whatever you like, and we’ll still manage to do this visualization. That’s the new capability we have.&lt;/p&gt;
    &lt;p&gt;Screenshot from 29:58 in the video&lt;/p&gt;
    &lt;p&gt;There’s also a query interface which we’ve been building out recently and there are some pretty powerful things you can do with these tables. As well as the flat tables of data, there’s also a more dynamic pivot table and if I click the arrow on the left, I can get into a detailed filter table, similar to a spreadsheet but optimize for things people want to do on traces.&lt;/p&gt;
    &lt;p&gt;For example, by doing an area select, I can first get a list of all the events that happened during a time region. Then using the table I can filter for things - say I only care about slices longer than some duration, like 319 microseconds for whatever reason. I can click and add a filter for things greater than this.&lt;/p&gt;
    &lt;p&gt;Screenshot from 30:11 in the video&lt;/p&gt;
    &lt;p&gt;There’s also a feature called “Show Debug Track” that’s also very powerful. The table shows rows with timestamped duration information, and this feature lets you visualize that data as a track on the timeline. It adds a track at the top showing the regions of time where these events happened—in this case, where ComputeTile took longer than a certain threshold.&lt;/p&gt;
    &lt;p&gt;This is particularly useful for correlation analysis. For example, in Android, we’re often looking at system A and trying to understand its effect on system B. We find all the places where one thing is slow, then look for correlations. Being able to see a track in the UI where you can quickly have context and say “oh, during this period of time, this other thing was happening” is invaluable. It’s probably one of our most-used features.&lt;/p&gt;
    &lt;p&gt;You can also copy the SQL query from these tables and start doing your own aggregations on top of it. This eases the burden of starting with a completely blank canvas. Instead of wondering “where do I even start querying my data? What tables is my data in?”, the UI gives you a starting query that you can build on without needing to write something from scratch.&lt;/p&gt;
    &lt;p&gt;So the dynamic quality updates were stopping the world. Perf profiling showed the problem, scheduler traces found the sleeping pattern, app tracing confirmed it was the quality adjustment code, and the single timeline view let me see everything happening at once.&lt;/p&gt;
    &lt;p&gt;Interestingly, I tried to fix this by removing the lock contention—which I thought was the bug I had introduced. But it turns out I shouldn’t have been doing this code in the workers in the first place. Even after removing the lock contention, just the CPU activity of doing that work was enough to cause frame drops. The right solution was to move it to a background thread. As part of debugging this for the demo, I discovered something even better that I could be doing.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Android and Chrome are our bread and butter—that’s what we officially support as a team, and why Google staffs us. But there are many other interesting uses.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mesa uses Perfetto as one of its tracing systems. One thing I could have shown is collecting a Mesa trace alongside all the other traces we looked at—you can actually see what the GPU is doing at the same time, which would have been very cool, but I just didn’t have time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;VizTracer is function tracing for Python, similar to uftrace, but you don’t have to recompile anything or do anything special.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;pthread_trace is for visualizing pthread mutex contention. The author has a very efficient way of doing this and writes protobuf using heavy use of constexpr to make it very low overhead. It’s a very interesting project.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;magic-trace uses Intel Processor Trace for function-level tracing at the processor level with lower overhead. They wrote a converter from that to the Perfetto format so you can visualize that data in Perfetto.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Qais Yousef’s sched-analyzer enriches Perfetto traces with scheduler internals. It’s a very cool project that I find particularly interesting.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;John Stultz’s all-in-one Perfetto recording script for kernel developers addresses a common complaint: “Perfetto is so complicated, I don’t know what events I want to record.” He just wrote a script that configures everything for you.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Finally, Josef Bacik’s systing is a bit experimental but fascinating. He re-implemented tracing daemons on top of BPF instead of Perfetto’s native implementation, combining BPF-based tracing with perf stack traces in a single binary. He has a blog post explaining why. I thought it was a fascinating use of Perfetto.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you want to try this yourself, you can use the demo program I’ve provided. But even better: record traces on your own programs. Open scheduler traces and perf at the same time. Instrument your program, convert it to Perfetto format, and visualize everything together.&lt;/p&gt;
    &lt;p&gt;If you want to convert ad-hoc timestamped data to Perfetto, we wrote a comprehensive tutorial with Python snippets for everything you might want to visualize. It covers all the features I showed and how to write Python code to generate them. We have a library for writing these traces: besides this one library, you don’t need to install anything else. You can go ahead and convert your own data to Perfetto.&lt;/p&gt;
    &lt;p&gt;We’re very happy to accept contributions and review pull requests pretty quickly. We’ve had a lot of open-source contributors over the years and have been quite lucky with some very high-quality contributions. If you want to contribute yourself or have a feature you feel is missing, send it our way.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Demo repo: github.com/LalitMaganti/fractal-renderer-vk&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Learn more: docs.perfetto.dev&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Perfetto UI: ui.perfetto.dev&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Contact: [email protected]&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771019</guid><pubDate>Fri, 31 Oct 2025 11:54:00 +0000</pubDate></item><item><title>Attention lapses due to sleep deprivation due to flushing fluid from brain</title><link>https://news.mit.edu/2025/your-brain-without-sleep-1029</link><description>&lt;doc fingerprint="35099567c8b315fa"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Audio&lt;/head&gt;
    &lt;p&gt;Nearly everyone has experienced it: After a night of poor sleep, you don’t feel as alert as you should. Your brain might seem foggy, and your mind drifts off when you should be paying attention.&lt;/p&gt;
    &lt;p&gt;A new study from MIT reveals what happens inside the brain as these momentary failures of attention occur. The scientists found that during these lapses, a wave of cerebrospinal fluid (CSF) flows out of the brain — a process that typically occurs during sleep and helps to wash away waste products that have built up during the day. This flushing is believed to be necessary for maintaining a healthy, normally functioning brain.&lt;/p&gt;
    &lt;p&gt;When a person is sleep-deprived, it appears that their body attempts to catch up on this cleansing process by initiating pulses of CSF flow. However, this comes at a cost of dramatically impaired attention.&lt;/p&gt;
    &lt;p&gt;“If you don’t sleep, the CSF waves start to intrude into wakefulness where normally you wouldn’t see them. However, they come with an attentional tradeoff, where attention fails during the moments that you have this wave of fluid flow,” says Laura Lewis, the Athinoula A. Martinos Associate Professor of Electrical Engineering and Computer Science, a member of MIT’s Institute for Medical Engineering and Science and the Research Laboratory of Electronics, and an associate member of the Picower Institute for Learning and Memory.&lt;/p&gt;
    &lt;p&gt;Lewis is the senior author of the study, which appears today in Nature Neuroscience. MIT visiting graduate student Zinong Yang is the lead author of the paper.&lt;/p&gt;
    &lt;p&gt;Flushing the brain&lt;/p&gt;
    &lt;p&gt;Although sleep is a critical biological process, it’s not known exactly why it is so important. It appears to be essential for maintaining alertness, and it has been well-documented that sleep deprivation leads to impairments of attention and other cognitive functions.&lt;/p&gt;
    &lt;p&gt;During sleep, the cerebrospinal fluid that cushions the brain helps to remove waste that has built up during the day. In a 2019 study, Lewis and colleagues showed that CSF flow during sleep follows a rhythmic pattern in and out of the brain, and that these flows are linked to changes in brain waves during sleep.&lt;/p&gt;
    &lt;p&gt;That finding led Lewis to wonder what might happen to CSF flow after sleep deprivation. To explore that question, she and her colleagues recruited 26 volunteers who were tested twice — once following a night of sleep deprivation in the lab, and once when they were well-rested.&lt;/p&gt;
    &lt;p&gt;In the morning, the researchers monitored several different measures of brain and body function as the participants performed a task that is commonly used to evaluate the effects of sleep deprivation.&lt;/p&gt;
    &lt;p&gt;During the task, each participant wore an electroencephalogram (EEG) cap that could record brain waves while they were also in a functional magnetic resonance imaging (fMRI) scanner. The researchers used a modified version of fMRI that allowed them to measure not only blood oxygenation in the brain, but also the flow of CSF in and out of the brain. They also measured each subject’s heart rate, breathing rate, and pupil diameter.&lt;/p&gt;
    &lt;p&gt;The participants performed two attentional tasks while in the fMRI scanner, one visual and one auditory. For the visual task, they had to look at a screen that had a fixed cross. At random intervals, the cross would turn into a square, and the participants were told to press a button whenever they saw this happen. For the auditory task, they would hear a beep instead of seeing a visual transformation.&lt;/p&gt;
    &lt;p&gt;Sleep-deprived participants performed much worse than well-rested participants on these tasks, as expected. Their response times were slower, and for some of the stimuli, the participants never registered the change at all.&lt;/p&gt;
    &lt;p&gt;During these momentary lapses of attention, the researchers identified several physiological changes that occurred at the same time. Most significantly, they found a flux of CSF out of the brain just as those lapses occurred. After each lapse, CSF flowed back into the brain.&lt;/p&gt;
    &lt;p&gt;“The results are suggesting that at the moment that attention fails, this fluid is actually being expelled outward away from the brain. And when attention recovers, it’s drawn back in,” Lewis says.&lt;/p&gt;
    &lt;p&gt;The researchers hypothesize that when the brain is sleep-deprived, it begins to compensate for the loss of the cleansing that normally occurs during sleep, even though these pulses of CSF flow come with the cost of attention loss.&lt;/p&gt;
    &lt;p&gt;“One way to think about those events is because your brain is so in need of sleep, it tries its best to enter into a sleep-like state to restore some cognitive functions,” Yang says. “Your brain’s fluid system is trying to restore function by pushing the brain to iterate between high-attention and high-flow states.”&lt;/p&gt;
    &lt;p&gt;A unified circuit&lt;/p&gt;
    &lt;p&gt;The researchers also found several other physiological events linked to attentional lapses, including decreases in breathing and heart rate, along with constriction of the pupils. They found that pupil constriction began about 12 seconds before CSF flowed out of the brain, and pupils dilated again after the attentional lapse.&lt;/p&gt;
    &lt;p&gt;“What’s interesting is it seems like this isn’t just a phenomenon in the brain, it’s also a body-wide event. It suggests that there’s a tight coordination of these systems, where when your attention fails, you might feel it perceptually and psychologically, but it’s also reflecting an event that’s happening throughout the brain and body,” Lewis says.&lt;/p&gt;
    &lt;p&gt;This close linkage between disparate events may indicate that there is a single circuit that controls both attention and bodily functions such as fluid flow, heart rate, and arousal, according to the researchers.&lt;/p&gt;
    &lt;p&gt;“These results suggest to us that there’s a unified circuit that’s governing both what we think of as very high-level functions of the brain — our attention, our ability to perceive and respond to the world — and then also really basic fundamental physiological processes like fluid dynamics of the brain, brain-wide blood flow, and blood vessel constriction,” Lewis says.&lt;/p&gt;
    &lt;p&gt;In this study, the researchers did not explore what circuit might be controlling this switching, but one good candidate, they say, is the noradrenergic system. Recent research has shown that this system, which regulates many cognitive and bodily functions through the neurotransmitter norepinephrine, oscillates during normal sleep.&lt;/p&gt;
    &lt;p&gt;The research was funded by the National Institutes of Health, a National Defense Science and Engineering Graduate Research Fellowship, a NAWA Fellowship, a McKnight Scholar Award, a Sloan Fellowship, a Pew Biomedical Scholar Award, a One Mind Rising Star Award, and the Simons Collaboration on Plasticity in the Aging Brain.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771636</guid><pubDate>Fri, 31 Oct 2025 13:14:23 +0000</pubDate></item><item><title>Sustainable memristors from shiitake mycelium for high-frequency bioelectronics</title><link>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0328965</link><description>&lt;doc fingerprint="2649d182a83393f0"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Figures&lt;/head&gt;&lt;head rend="h2"&gt;Abstract&lt;/head&gt;&lt;p&gt;Neuromorphic computing, inspired by the structure of the brain, offers advantages in parallel processing, memory storage, and energy efficiency. However, current semiconductor-based neuromorphic chips require rare-earth materials and costly fabrication processes, whereas neural organoids need complex bioreactor maintenance. In this study, we explored shiitake (Lentinula edodes) fungi as a robust, sustainable alternative, exploiting its adaptive electrical signaling, which is akin to neuronal spiking. We demonstrate fungal computing via mycelial networks interfaced with electrodes, showing that fungal memristors can be grown, trained, and preserved through dehydration, retaining functionality at frequencies up to 5.85 kHz, with an accuracy of 90 ± 1%. Notably, shiitake has exhibited radiation resistance, suggesting its viability for aerospace applications. Our findings show that fungal computers can provide scalable, eco-friendly platforms for neuromorphic tasks, bridging bioelectronics and unconventional computing.&lt;/p&gt;&lt;p&gt;Citation: LaRocco J, Tahmina Q, Petreaca R, Simonis J, Hill J (2025) Sustainable memristors from shiitake mycelium for high-frequency bioelectronics. PLoS One 20(10): e0328965. https://doi.org/10.1371/journal.pone.0328965&lt;/p&gt;&lt;p&gt;Editor: Ye Zhou, Shenzhen University, HONG KONG&lt;/p&gt;&lt;p&gt;Received: July 8, 2025; Accepted: September 25, 2025; Published: October 10, 2025&lt;/p&gt;&lt;p&gt;Copyright: © 2025 LaRocco et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.&lt;/p&gt;&lt;p&gt;Data Availability: The data is available at this repository: https://github.com/javeharron/abhothData.&lt;/p&gt;&lt;p&gt;Funding: Authors J.S. and J.H. were supported by Honda Research Institute (grant AWD-118684). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.&lt;/p&gt;&lt;p&gt;Competing interests: The authors have declared that no competing interests exist.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;&lt;head rend="h3"&gt;Overview&lt;/head&gt;&lt;p&gt;The development of neuromorphic hardware relies on memristive devices capable of emulating synaptic behavior, with potential applications in energy-efficient computing and artificial intelligence1. Recent work has explored natural, biodegradable substrates as sustainable alternatives to conventional inorganic memristors [1]. In this study, we investigated the potential of the edible fungus Lentinula edodes (shiitake mushroom) as a platform for memristor fabrication. By examining the electrical response of mushroom-derived materials under repeated voltage cycling, we explored stable memristive switching behavior, retention, and endurance. Shiitake-based devices not only demonstrate reproducible memory effects, but also highlight the potential for scalable, low-cost, and environmentally friendly neuromorphic components.&lt;/p&gt;&lt;head rend="h3"&gt;Memristors&lt;/head&gt;&lt;p&gt;Memristor devices offer substantial advantages in robotic, industrial, and transport applications due to their unique electrical properties and ability to mimic neural functions. They can enhance various control systems, facilitate efficient information processing, and ultimately improve the overall performance of autonomous systems.&lt;/p&gt;&lt;p&gt;One of the key strengths of memristors is their capacity for efficient and self-adaptive in situ learning, which is critical for applications in robotics and autonomous vehicles. In memristor-based neural networks, the devices can adjust their resistance based on previous inputs, allowing for a form of analog learning that closely resembles the synaptic behavior in biological systems [1]. This capability enables robots and autonomous vehicles to learn from their environment and adapt in real time, enhancing their ability to navigate complex situations effectively. It has been found that such systems can achieve low-latency responses, which are essential for high-speed decision-making in dynamic environments [2].&lt;/p&gt;&lt;p&gt;Memristors also have the advantage of integrating memory and processing capabilities into a single device, enabling a simplified architecture for autonomous control systems [3]. For instance, in autonomous vehicles, trajectory-tracking and path-following tasks can be performed using memristor-based controllers that allow for rapid calculations and real-time adjustments to control variables [4]. This integration, especially with parallelization, helps to address the challenges posed by separate memory and processing units, which can lead to delays and increased power consumption in traditional control systems [4].&lt;/p&gt;&lt;p&gt;Additionally, the resilience of memristor devices against environmental changes, and their ability to operate under varying conditions, make them particularly suitable for autonomous applications, such as spacecraft electronics or vehicles operating in unpredictable road environments [4]. This is complemented by the precision in control that memristor-based systems can offer, which is significant for maintaining stability and performance while following desired trajectories [5].&lt;/p&gt;&lt;p&gt;Moreover, the low power consumption of memristors is particularly beneficial in robotics and autonomous vehicles, where energy efficiency is paramount. Hybrid analog–digital memristor systems can minimize power usage during processing without sacrificing responsiveness, which can prolong operational times by reducing the frequency at which recharging or battery replacement is required, enhancing the feasibility of deploying such systems in mobile applications [2].&lt;/p&gt;&lt;p&gt;Ultimately, the potential of memristors to emulate human-like decision-making and learning processes could be exploited to endow robotic systems and autonomous vehicles with functionalities not found in conventional control systems. The ability of memristors to perform complex computations efficiently, learn adaptively, and integrate both memory and processing into a unified approach make them a cornerstone technology for the future development of intelligent autonomous systems. However, the production of memristors often requires rare-earth minerals and expensive semiconductor foundries.&lt;/p&gt;&lt;head rend="h3"&gt;Fungal electronics&lt;/head&gt;&lt;p&gt;Fungi possess innate abilities to adapt to various environmental conditions and efficiently process information through their interconnected network of hyphae. These characteristics make fungi an ideal candidate for developing sustainable computing systems from. Our aim was to design and implement a novel fungal memristor-based computing architecture that could significantly reduce energy consumption and minimize electronic waste. We approached this using substantially simpler bioreactors and nutrient cultures than those required for conventional neurons and neural organoids. The unique advantages of fungal memristors stem from the biological properties of fungal materials, which distinguish them from typical inorganic or polymer alternatives [6,7].&lt;/p&gt;&lt;p&gt;First, one of the main benefits of fungal memristors is their environmentally sustainable and biodegradable nature. Conventional memristors often contain transition metal oxides or silicon-based structures, the production or disposal of which can pose environmental challenges [6,7]. By contrast, fungal materials are derived from organic biomass, making them both sustainable and significantly less harmful to the environment. This aligns with increasing efforts toward developing greener electronic materials, as highlighted in previous work emphasizing the importance of sustainability in technology development [8].&lt;/p&gt;&lt;p&gt;Second, fungal memristors exhibit remarkable adaptability in their electrical properties. The structural composition of fungal materials often allows for a range of conductive pathways that can form dynamically under the influence of electrical stimuli, similar to the conductive filaments formed in conventional memristors [9,10]. This adaptability can lead to enhanced performance in neuromorphic applications through the facilitation of variable resistance states that mimic synaptic behaviors more closely than traditional memristive materials, which often have static crystalline structures that can lead to variability problems or performance limitations at the nanoscale [11].&lt;/p&gt;&lt;p&gt;Furthermore, fungal memristors may consume less power than traditional materials due to their unique electrochemical properties. It has been claimed that some organic materials, including those derived from fungi, can operate effectively at lower voltages while maintaining stable switching characteristics––a trait that is crucial for developing energy-efficient devices for portable electronics and Internet of Things applications [12]. This can significantly extend battery life and reduce energy costs in processing and memory applications, which have become focal points in the research into neuromorphic systems [13].&lt;/p&gt;&lt;p&gt;Finally, the natural composition and multicellularity of fungal materials can lead to more naturalistic models for neural networks. Because these materials are subject to biological processes, they may inherently incorporate characteristics that resemble biological neuronal networks, including plasticity and memory capabilities that could evolve with usage. This biological mimicry could strengthen the development of more advanced artificial neural networks, enabling applications such as adaptive learning systems and intelligent sensor networks [14].&lt;/p&gt;&lt;head rend="h3"&gt;Fungus types&lt;/head&gt;&lt;p&gt;The potential use of common food mushrooms, such as shiitake and button mushrooms (Agaricus bisporus), as organic memristors is an emerging area of research that exploits the unique properties of these fungi [6,7,13]. Memristors, which are non-volatile memory devices that retain information even without power, can benefit from the porous structures and electrical properties of the organic materials derived from mushrooms.&lt;/p&gt;&lt;p&gt;Shiitake mushrooms have been shown to possess a hierarchically porous carbon structure when activated. This porous structure can enhance the electrochemical performance of devices, making them suitable candidates for use in energy storage systems, including supercapacitors and, potentially, memristors [15]. Highly conductive carbon materials have been created from shiitake, suggesting that these materials could be engineered to exhibit memristive behavior [16]. Shiitake-derived carbon is a sustainable alternative to traditional materials and can enhance the performance of electronic devices due to its unique structural properties.&lt;/p&gt;&lt;p&gt;Button mushrooms have also shown significant potential in this context. Research has indicated that their porosity can be exploited to create materials with large surface areas, which are essential for the development of efficient electronic components [17]. The synthesis of carbon composites from button mushrooms has been explored, revealing their ability to function effectively in energy storage applications [17]. Furthermore, the integration of button mushrooms into electronic systems has been investigated, demonstrating their potential as substrates for electronic devices [18].&lt;/p&gt;&lt;p&gt;In addition to their structural properties, the unique biological characteristics of fungi, including their ability to interact with various chemical compounds, can be harnessed to develop novel sensing technologies. For instance, electronic noses have been developed that use mushroom extracts to detect volatile compounds. These could be adapted for use in electronic devices that require environmental-sensing capabilities [19,20]. This intersection of biology and electronics opens new avenues for creating multifunctional devices that incorporate the sensory capabilities of mushrooms.&lt;/p&gt;&lt;head rend="h3"&gt;Radiation, resistance, and resilience&lt;/head&gt;&lt;p&gt;The radiation resistance of shiitake mushrooms has been studied primarily in terms of their ability to withstand and possibly derive benefits from exposure to ionizing radiation. This resistance can be attributed to several biochemical and physiological attributes. A possible factor is lentinan, a polysaccharide found in the cell walls of shiitake. Lentinan provides structural integrity and exhibits immunomodulatory effects that may enhance the mushroom’s ability to respond to environmental stresses, including radiation exposure. Although some research has suggested that lentinan possesses properties that may help mitigate oxidative stress [21], there have been limited studies directly linking lentinan to radiation resistance in shiitake mushrooms.&lt;/p&gt;&lt;p&gt;Shiitake mushrooms have also shown a notable ability to adapt to their environmental conditions, including variable radiation levels. Studies involving fungi in space research have indicated that certain taxa can enhance their survival through morphological changes or increased melanin production in response to radiation [22]. This radiation resistance implies a suitability of fungal electronics for aerospace applications, where cosmic rays and ambient radiation can interfere with conventional electronics. Fungi’s physical flexibility and low energy requirements would also be advantageous relative to conventional solutions [18,19]. These studies have not specifically addressed shiitake, but the general adaptability observed in fungi suggests that this species could respond similarly to such conditions.&lt;/p&gt;&lt;p&gt;Another example of the resilience of shiitake mushrooms is their ability to maintain their nutritional and bioactive qualities after irradiation. For example, they retain essential nutrients and bioactive compounds even after exposure to ultraviolet radiation [23]. The high content of ergosterol, a precursor to vitamin D, found in shiitake mushrooms, reinforces their potential for beneficial outcomes following exposure to radiation because this compound can be converted into vitamin D2 when subjected to ultraviolet light [24].&lt;/p&gt;&lt;p&gt;Lastly, shiitake mushrooms could be considered in the development of dietary supplements or functional foods that could serve a broader purpose in radioprotection. Their multirole efficacy as a food source and electrical component emphasizes a sustainable approach to utilizing biological entities that can withstand environmental stresses, including radiation. This is especially relevant in aerospace and exploration contexts, where promoting health in astronauts could reduce the risks associated with their increased radiation exposure during missions [22]. Also, shiitake mushrooms can withstand environmental stresses, including radiation, while remaining safe for human consumption.&lt;/p&gt;&lt;p&gt;In summary, the radiation resistance of shiitake mushrooms is linked to the presence of protective compounds, such as lentinan, and their ability to adapt morphologically. These factors have contributed to our understanding of their survival strategies and are suggestive of potential applications in areas where radiation exposure is a significant concern, such as aerospace and radiation sensing. By culturing and evaluating the memristive properties of shiitake mushrooms, we can determine their suitability for use as sustainable, low-cost bioelectronics.&lt;/p&gt;&lt;head rend="h2"&gt;Methods&lt;/head&gt;&lt;head rend="h3"&gt;Summary&lt;/head&gt;&lt;p&gt;Testing the memristive behavior of shiitake mycelium involved several steps, the first being culturing the fungi, and then preparing the samples by drying and rehydrating them. Following this, the most successfully cultivated samples were electrically characterized using a test circuit. Additionally, a special circuit was constructed for further evaluating the feasibility of using mycelium for violate memory.&lt;/p&gt;&lt;head rend="h3"&gt;Hyphal cultivation&lt;/head&gt;&lt;p&gt;Due to the financial and environmental constraints of this project, all four evaluated memristors fabricated for our experiments were composed exclusively of low-cost, organic materials. Based on previous research, we identified materials such as biocompatible composites [25,26] as viable candidates for device construction and programming due to their biodegradability and compatibility with fungal growth.&lt;/p&gt;&lt;p&gt;The initial phase of experimentation focused on the cultivation of fungal hyphae in the selected organic growth media. Nine samples were prepared in standard polycarbonate Petri dishes. The growth conditions were carefully maintained to promote optimal fungal development, with a controlled temperature range of 20–22°C, a relative humidity of 70%, and mixed light exposure to replicate natural terrestrial conditions. The nutrient substrate consisted of a mixture of farro seed, wheat germ, and hay, selected for their organic compositions and ability to support robust fungal growth. Each sample was inoculated with spores or mycelial plugs of shiitake.&lt;/p&gt;&lt;p&gt;The samples (e.g., see Fig 1) were observed and documented biweekly to track their growth consistency and morphological development. Observations including hyphal density, surface coverage, and color changes were recorded in a structured laboratory logbook. In addition to these visual inspections, a brief scratch test was performed to track the progress of the mycelium throughout the substrate. The log included timestamps and qualitative notes, enabling consistent comparison across samples and time points.&lt;/p&gt;&lt;p&gt;Each sample grew a mycelial network that was connected to conventional electronics.&lt;/p&gt;&lt;head rend="h3"&gt;Drying and rehydration process&lt;/head&gt;&lt;p&gt;Once full hyphal coverage and structural maturation were achieved (i.e., when the Petri dish was covered), the samples were transitioned to the drying phase. The Petri dishes were left in a well-ventilated area under direct sunlight at room temperature for approximately seven days to ensure uniform dehydration. The samples were rotated periodically to avoid uneven hardening. As previously reported, this process transformed the fungal matrix into a rigid, disk-like structure while retaining its overall shape and connectivity [26,27].&lt;/p&gt;&lt;p&gt;Prior to testing, the samples were rehydrated using a fine mist of aerosolized deionized water. The rehydration was conducted using a standard commercial spray bottle, held within a distance of 10 cm from each sample. This brief rehydration step restored the required level of conductivity without introducing bulk moisture that could have altered their mechanical integrity.&lt;/p&gt;&lt;head rend="h3"&gt;Electrical characterization&lt;/head&gt;&lt;p&gt;Electrical testing protocols were designed based on theoretical memristors [6,7]. An alternating current was applied to each sample, and the corresponding current–voltage (I–V) characteristics were measured using a digital oscilloscope. As established in previous works, the test setup used a voltage divider to model multiple memristors in the same circuit [6,7].&lt;/p&gt;&lt;p&gt;To extract accurate current values, a known shunt resistor was placed in series with each sample. As shown in Fig 2, voltage readings were captured across both the sample and the resistor, with Channel 1 of the oscilloscope measuring the input voltage and Channel 2 capturing the voltage drop across the shunt resistor. The current values were then calculated using Kirchhoff’s current law, allowing derivation of the I–V characteristics from the voltage differentials. All waveform data were exported in comma-separated values (CSV) format for subsequent digital analysis and visualization.&lt;/p&gt;&lt;p&gt;The test circuit evaluated the memristive properties of each sample.&lt;/p&gt;&lt;p&gt;To thoroughly investigate the memristive behavior of the four samples using mycelium coverage density, voltage sweeps were conducted using both square and sinusoidal waveforms. The square waves were employed to detect sharp threshold-based resistance changes, whereas the sinusoidal inputs provided insights into the more subtle, continuous mem-fractive behaviors. This dual approach enabled the identification of hysteresis loops in the I–V curves––a key signature of memristor functionality.&lt;/p&gt;&lt;p&gt;A square wave was used first, with the peak-to-peak voltage starting at 200 mVpp and increasing. If a sinusoidal wave form exhibited more promising results, a broader range of frequencies was explored. The frequencies and voltages used in the initial tests for memristive properties are detailed in Table 1.&lt;/p&gt;&lt;p&gt;Accuracy and error were calculated based on how many reads agreed with the analog threshold, the number of malformed readings, timing jitter, recording instability, and port delays [28].&lt;/p&gt;(1)&lt;p&gt;The accuracy was calculated using Equation 1, where accuracy is a percentage converted from product of correct samples C over the total number of samples N. The standard error SE was calculated for each case, as shown in Equation 2.&lt;/p&gt;(2)&lt;p&gt;A simulated ideal memristive curve was compared against each experimental result, where the statistical distance d was calculated between both curves [28]. The distance was used to compute memristive accuracy at a particular frequency, as shown in Equation 3.&lt;/p&gt;(3)&lt;head rend="h3"&gt;Volatile memory testing&lt;/head&gt;&lt;p&gt;In the event that the fungal samples exhibited memristive behavior, a specialized electronic circuit was designed and implemented to investigate the volatile memory characteristics of two fungal samples in series. The test circuit was a voltage divider with memory. The test involved setting an arbitrary analog voltage value to represent a high value, and below that threshold was a low value. The frequency range started at 200 Hz and concluded at 5.85 kHz. Similarly to previous work, Fig 3 shows the configuration and layout of this testing circuit [6].&lt;/p&gt;&lt;p&gt;The samples were evaluated using this model.&lt;/p&gt;&lt;p&gt;Comparably to previous work in memristive computing, the volatile memory circuit employed an Arduino UNO microcontroller development board and a voltage divider consisting of two memristive elements [6,7]. Given the polarized nature of memristors, the circuit was designed to allow a voltage of opposite polarity to that used during read operations to be set. Both voltages used were approximately 5 V. The Arduino UNO cyclically applied a high signal to a relay containing a half-rectified sine wave through one of its digital output pins when reading the memristor bridge, thereby charging the divider. This process induced an asymmetry in resistance, with the memristor closest to the input experiencing a reduction in resistance, while the output-side memristor exhibited an increase. The voltage across the divider was subsequently read using an analog input pin, and another digital pin was used to run 5 V across the divider. The Arduino interpreted the stored state as “on” only when the measured voltage exceeded a predefined threshold, effectively enabling volatile memory detection based on the transient resistance states of the memristors. Ten tests were repeated on each of the four samples. The physical implementation of this circuit is shown in Fig 4.&lt;/p&gt;&lt;p&gt;The volatile memory circuit was implemented using fungal memristors.&lt;/p&gt;&lt;p&gt;The memristor voltage divider was tested by applying a 5 Vpp sinusoidal signal to the memristors for approximately 0.01–0.1 ms. This signal was delivered via a relay triggered by digital pin 6 of the Arduino UNO. Following this brief stimulation period, the sinusoidal input was disabled, and digital pin 5 was activated to initiate the read phase. Analog voltage measurements were then acquired through the A1 analog input pin. To minimize the effects of floating voltages, a 1 MΩ pull-down resistor was connected to this pin. Voltage readings were recorded for approximately 0.1–0.10 ms before the cycle repeated, allowing for rapid and continuous testing of the memristive behavior.&lt;/p&gt;&lt;p&gt;The measurements were transmitted over a serial communication interface at a baud rate of 57,600 and were captured as raw text files for analysis. The data were post-processed and visualized using a custom Python script based on the matplotlib library, enabling clear identification of memory retention patterns and resistance state changes across successive cycles.&lt;/p&gt;&lt;head rend="h3"&gt;Hypothesis&lt;/head&gt;&lt;p&gt;The general testing setup, based on that used in the literature, is able to indicate memristive behavior in fungal samples. If present, this behavior would manifest as a characteristic pinched hysteresis loop in the I–V curves, typically intersecting at or near the origin––a well-established signature of memristive systems [6,7]. We hypothesized that such a response would emerge under specific combinations of voltage amplitude and input frequency. Where memristive behavior was indicated, volatile memory tests were conducted.&lt;/p&gt;&lt;head rend="h2"&gt;Results&lt;/head&gt;&lt;head rend="h3"&gt;Overview&lt;/head&gt;&lt;p&gt;The fungal memristors were tested across a range of voltages, waveforms, and frequencies. Below, we first detail the test inputs used to explore the memristive properties and generate I–V curves. Then we present the voltage and frequency (graphical) test results, followed by the volatile memory test results. Each figure represents the averaged, smoothed results across the samples.&lt;/p&gt;&lt;head rend="h3"&gt;Voltage testing&lt;/head&gt;&lt;p&gt;The first five tests were conducted to determine which voltage amplitude produced the most favorable memristive response. These initial trials revealed that a 1 Vpp signal yielded the most consistent and measurable results. As outlined in the Methods section, the first four of these tests were performed using a square wave input.&lt;/p&gt;&lt;head rend="h3"&gt;Frequency testing&lt;/head&gt;&lt;p&gt;After identifying 1 Vpp as the optimal input voltage during the initial square wave tests (Tests 1–4), the waveform was switched to a sine wave for further analysis (Tests 5–10). The aim of this phase was to identify the frequency at which memristive behavior––specifically a pinched hysteresis loop––became apparent.&lt;/p&gt;&lt;p&gt;In Tests 1–5, the voltage amplitude was optimized using square waves. Between Tests 5 and 6, the waveform was changed from square to sine. From Tests 6–10, frequency sweeps were carried out with sine waves to identify memristive crossing. In Test 11, the voltage range was expanded at 10 Hz (5 Vpp) to enhance the response. This revealed behavior close to that of an ideal memristor. Notably, Test 1 had already shown consistent linear behavior, indicating resistive characteristics. The results are shown in Figs 5–13. Fig 14 details a sample noise profile, and Fig 15 summarizes memristive accuracy.&lt;/p&gt;&lt;p&gt;Plot of a 200 mVpp square wave at 200 Hz displaying memcapacitive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 20 Vpp square wave at 200 Hz displaying resistive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp square wave at 200 Hz displaying memcapacitive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 200 Hz displaying memcapacitive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 100 Hz displaying memcapacitive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 25 Hz displaying memristive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 50 Hz displaying memristive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 1 Vpp sine wave at 10 Hz displaying memristive behavior.&lt;/p&gt;&lt;p&gt;Plot of a 5 Vpp sine wave at 10 Hz displaying near-ideal memristive behavior.&lt;/p&gt;&lt;p&gt;Plot of a noisy 1 Vpp sine wave at 10 Hz during measurement.&lt;/p&gt;&lt;p&gt;Memristive accuracy plotted for Tests 1-11.&lt;/p&gt;&lt;p&gt;Figs 5–10 show the output of Tests 2–7. The frequency was gradually reduced until a crossing near the origin was first observed, as shown in Fig 10. To ensure this result was not an outlier caused by overshooting the ideal frequency, the test was repeated at a slightly higher frequency (50 Hz, Test 8, shown in Fig 11). This confirmed that the optimal response occurred below 25 Hz.&lt;/p&gt;&lt;p&gt;As summarized in Table 2, the frequency was decreased to 10 Hz (Test 9, shown in Fig 12), which produced a clear crossing in the I–V curve near the −0.4 V region. To enhance the visibility of this behavior, the voltage was increased to 5 Vpp, which resulted in a more pronounced memristive signature (Test 10). Fig 13 illustrates this result, displaying a nearly ideal pinched hysteresis loop indicative of memristor functionality. The highest accuracy, at 95%, was at a 10 Hz sine wave at 1 V. Fig 14 details the noise from an individual sample. Fig 15 details the average memristive accuracy of each configuration.&lt;/p&gt;&lt;head rend="h3"&gt;Volatile memory experiment&lt;/head&gt;&lt;p&gt;For the volatile memory tests 1 and 2, single read and write operations were performed across the memristor voltage divider. For volatile memory test 3, continuous read and write operations were performed across the memristor voltage divider while the frequency was gradually increased. The primary results are summarized in Table 3. The results are displayed in Figs 16–20. Averaged nemristive accuracy is displayed in Fig 21.&lt;/p&gt;&lt;p&gt;A single write and read over volatile memory.&lt;/p&gt;&lt;p&gt;Another single write and read over volatile memory.&lt;/p&gt;&lt;p&gt;Cyclical writing and reading over the fungal volatile memory.&lt;/p&gt;&lt;p&gt;Additional cyclical writing and reading over the fungal volatile memory.&lt;/p&gt;&lt;p&gt;Extreme cyclical writing and reading from volatile memory.&lt;/p&gt;&lt;p&gt;Accuracy for first two tests and cyclic tests.&lt;/p&gt;&lt;head rend="h2"&gt;Discussion&lt;/head&gt;&lt;head rend="h3"&gt;Overview&lt;/head&gt;&lt;p&gt;Using low-cost materials, shiitake mushrooms were cultured into ideal memristors. Ideal and non-ideal memristive properties have been observed previously in fungi, but these required far more complex interfacing methods [26]. Although several techniques have been proposed to preserve fungal samples, we obtained experimental validation that dehydration can preserve the observed properties in a previously “programmed” sample [27]. Ideal memristor properties are observed at lower frequencies, but potential latencies can be offset through massive parallelization, as in nature [26,28,29]. As known from previous works on fungal memristors, the mycelial structure contains capacitive, memfractive, and memristive proteins [25,26]. In the memristive tests, accuracy decreased as the frequency increased. The observed rapid switching speed of 5,850 Hz, an accuracy of 90% (± 1%) low energy consumption relative to prior conventional systems, light weight, and radiation resistance all make fungal memristors attractive for edge computing, aerospace, and embedded firmware applications [25–27]. Unlike expensive conventional memristors, culturing fungal memristors does not require large facilities or rare minerals. The process can be scaled to grow large systems, which can be programmed and preserved for long-term use at low cost.&lt;/p&gt;&lt;head rend="h3"&gt;Limitations&lt;/head&gt;&lt;p&gt;Our study was limited by the relatively short timescale of less than two months. Other researchers have documented memristive properties in mycelial materials, but their studies also focused on short-term performance [26]. Another limitation was that only single, relatively bulky samples were prepared. To truly compete with conventional devices at the microscale and below, memristors will need to be far smaller [7,8,11]. Even in the same growth medium, each sample produced a vastly different culture, and the outcomes have yet to be fully characterized by electrical properties. However, the development of these devices is in an early stage, and they could eventually be miniaturized, especially using improved cultivation techniques. Complications associated with the growth media were not explored, although previous research has found that fungi are quite robust to varying conditions [26].&lt;/p&gt;&lt;head rend="h3"&gt;Future work&lt;/head&gt;&lt;p&gt;Although fungal memristors can be produced at low cost, certain aspects of the process could be further optimized. First, consistent cultivation techniques could be improved using three-dimensional (3D)-printed templates and structures that shape the shiitake mushroom into the desired geometry. Second, programming could be facilitated by adding electrical contacts into a 3D-printed cultivation structure. Finally, long-term use would necessitate preservation, which could involve a variety of techniques, including dehydration, desiccation, freeze-drying, certain hydrogels, and special coatings [27]. By testing devices produced to physical stress conditions, a combination of these techniques could enable the development of fast, radiation-resistant, and low-energy memristors grown from low-cost organic materials. The future of computing could be fungal.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusions&lt;/head&gt;&lt;p&gt;Currently, the fabrication of semiconductor memristors requires rare-earth minerals and large facilities, and culturing delicate neural organoids requires a complex chemical environment to be maintained in a bioreactor. Fungal computing may provide a robust and accessible alternative. Fungal systems have lower power requirements, lighter weights, faster switching speeds, and lower industrial overheads than conventional devices. In this study, fungal memristors were fabricated, programmed, and tested using shiitake mushrooms and conventional electronics. Dehydration-based preservation was successfully explored, demonstrating the robustness of our devices. When used as RAM, our mushroom memristor was able to operate at up to 5,850 Hz at an accuracy of 90 ± 1%. In addition, shiitake mushrooms are biodegradable and have demonstrated radiation resistance, suggesting that the potential applications of fungal computing range from sustainable computing devices to aerospace technologies.&lt;/p&gt;&lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;&lt;p&gt;We would like to thank Ryan Lingo and Rajeev Chhajer of the Honda Research Institute.&lt;/p&gt;&lt;head rend="h2"&gt;References&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;1. Li C, Han L, Jiang H, Jang M-H, Lin P, Wu Q, et al. Three-dimensional crossbar arrays of self-rectifying Si/SiO2/Si memristors. Nat Commun. 2017;8:15666. pmid:28580928&lt;/item&gt;&lt;item&gt;2. Cheng P, Gao S, Zang P, Yang X, Bai Y, Xu H, et al. Hierarchically porous carbon by activation of shiitake mushroom for capacitive energy storage. Carbon. 2015;93:315–24.&lt;/item&gt;&lt;item&gt;3. Lin F, Chen Y, Zhao Y, Wang S. Path tracking of autonomous vehicle based on adaptive model predictive control. International Journal of Advanced Robotic Systems. 2019;16(5).&lt;/item&gt;&lt;item&gt;4. Wang Q, Hu Z, Li Z, Liu T, Bian G. Exploring the Application and Prospects of Synthetic Biology in Engineered Living Materials. Adv Mater. 2025;37(31):e2305828. pmid:37677048&lt;/item&gt;&lt;item&gt;5. Li C, Han L, Jiang H, Jang M-H, Lin P, Wu Q, et al. Three-dimensional crossbar arrays of self-rectifying Si/SiO2/Si memristors. Nat Commun. 2017;8:15666. pmid:28580928&lt;/item&gt;&lt;item&gt;6. Yuan L, Liu S, Chen W, Fan F, Liu G. Organic Memory and Memristors: From Mechanisms, Materials to Devices. Adv Elect Materials. 2021;7(11).&lt;/item&gt;&lt;item&gt;7. Femi O. Unveiling the fourth fundamental circuit element and its real-world applications. In: Chang YF, ed. Memristors – The Fourth Fundamental Circuit Element – Theory, Device, and Applications. IntechOpen; 2024:3–12.&lt;/item&gt;&lt;item&gt;8. Li C, Han L, Jiang H, Jang M-H, Lin P, Wu Q, et al. Three-dimensional crossbar arrays of self-rectifying Si/SiO2/Si memristors. Nat Commun. 2017;8:15666. pmid:28580928&lt;/item&gt;&lt;item&gt;9. Yang C, Sun B, Zhou G, Guo T, Ke C, Chen Y, et al. Photoelectric Memristor-Based Machine Vision for Artificial Intelligence Applications. ACS Materials Lett. 2023;5(2):504–26.&lt;/item&gt;&lt;item&gt;10. Campbell KA, Drake KT, Barney Smith EH. Pulse Shape and Timing Dependence on the Spike-Timing Dependent Plasticity Response of Ion-Conducting Memristors as Synapses. Front Bioeng Biotechnol. 2016;4:97. pmid:28083531&lt;/item&gt;&lt;item&gt;11. Ko T-J, Li H, Mofid SA, Yoo C, Okogbue E, Han SS, et al. Two-Dimensional Near-Atom-Thickness Materials for Emerging Neuromorphic Devices and Applications. iScience. 2020;23(11):101676. pmid:33163934&lt;/item&gt;&lt;item&gt;12. Lu XF, Zhang Y, Wang N, Luo S, Peng K, Wang L, et al. Exploring Low Power and Ultrafast Memristor on p-Type van der Waals SnS. Nano Lett. 2021;21(20):8800–7. pmid:34644096&lt;/item&gt;&lt;item&gt;13. Liao K, Lei P, Tu M, Luo S, Jiang T, Jie W, et al. Memristor Based on Inorganic and Organic Two-Dimensional Materials: Mechanisms, Performance, and Synaptic Applications. ACS Appl Mater Interfaces. 2021;13(28):32606–23. pmid:34253011&lt;/item&gt;&lt;item&gt;14. Sun J, Yang R, Li Q, Zhu R, Jiang Y, Zang L, et al. Living Synthelectronics: A New Era for Bioelectronics Powered by Synthetic Biology. Adv Mater. 2024;36(25):e2400110. pmid:38494761&lt;/item&gt;&lt;item&gt;15. Cheng P, Gao S, Zang P, Yang X, Bai Y, Xu H, et al. Hierarchically porous carbon by activation of shiitake mushroom for capacitive energy storage. Carbon. 2015;93:315–24.&lt;/item&gt;&lt;item&gt;16. Yadav P, Basu A, Suryawanshi A, Game O, Ogale S. Highly Stable Laser‐Scribed Flexible Planar Microsupercapacitor Using Mushroom Derived Carbon Electrodes. Adv Materials Inter. 2016;3(11).&lt;/item&gt;&lt;item&gt;17. Li J, Wu Q, Zan G. Facile synthesis and high electrochemical performance of porous carbon composites for supercapacitors. RSC Adv. 2014;4(66):35186.&lt;/item&gt;&lt;item&gt;18. Joshi S, Cook E, Mannoor MS. Bacterial Nanobionics via 3D Printing. Nano Lett. 2018;18(12):7448–56. pmid:30403141&lt;/item&gt;&lt;item&gt;19. Gómez I, Lavega González R, Tejedor-Calvo E, Pérez Clavijo M, Carrasco J. Odor Profile of Four Cultivated and Freeze-Dried Edible Mushrooms by Using Sensory Panel, Electronic Nose and GC-MS. J Fungi (Basel). 2022;8(9):953. pmid:36135678&lt;/item&gt;&lt;item&gt;20. Fujioka K, Shimizu N, Manome Y, Ikeda K, Yamamoto K, Tomizawa Y. Discrimination method of the volatiles from fresh mushrooms by an electronic nose using a trapping system and statistical standardization to reduce sensor value variation. Sensors (Basel). 2013;13(11):15532–48. pmid:24233028&lt;/item&gt;&lt;item&gt;21. Chung I-M, Kim S-Y, Han J-G, Kong W-S, Jung MY, Kim S-H. Fatty Acids and Stable Isotope Ratios in Shiitake Mushrooms (Lentinula edodes) Indicate the Origin of the Cultivation Substrate Used: A Preliminary Case Study in Korea. Foods. 2020;9(9):1210. pmid:32882944&lt;/item&gt;&lt;item&gt;22. Wu K, de Menezes S, Robinson A. Flagellate Erythema: A Case of Shiitake Dermatitis and Review of Pathogenesis. EMJ Allergy Immunol. 2022.&lt;/item&gt;&lt;item&gt;23. Won DJ, Kim SY, Jang CH, Lee JS, Ko JA, Park HJ. Optimization of UV irradiation conditions for the vitamin D2-fortified shiitake mushroom (Lentinula edodes) using response surface methodology. Food Sci Biotechnol. 2017;27(2):417–24. pmid:30263765&lt;/item&gt;&lt;item&gt;24. Loo HV, Oon HH. Flagellate dermatitis following consumption of shiitake mushroom. Dermatol Reports. 2011;3(2):e21. pmid:25386273&lt;/item&gt;&lt;item&gt;25. Wang H, Tao J, Wu Z, Weiland K, Wang Z, Masania K, et al. Fabrication of Living Entangled Network Composites Enabled by Mycelium. Adv Sci (Weinh). 2024;11(24):e2309370. pmid:38477443&lt;/item&gt;&lt;item&gt;26. Adamatzky A, Ayres P, Beasley AE, Roberts N, Wösten HAB. Logics in Fungal Mycelium Networks. Log Univers. 2022;16(4):655–69.&lt;/item&gt;&lt;item&gt;27. Al-Bedak OA, Sayed RM, Hassan SHA. A new low-cost method for long-term preservation of filamentous fungi. Biocatalysis and Agricultural Biotechnology. 2019;22:101417.&lt;/item&gt;&lt;item&gt;28. Yin S-F, Sun Q-J, Liu L-F, Liu S-Z, Jiang Y-P, Tang X-G. TiO2/Bi4Ti3O12 heterojunction optoelectronic synaptic devices for simulating associative memory and neuromorphic computation. Applied Surface Science. 2025;711:164049.&lt;/item&gt;&lt;item&gt;29. Dixon WJ, Massey FJ. Introduction to statistical analysis. 1951. &lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45771796</guid><pubDate>Fri, 31 Oct 2025 13:32:08 +0000</pubDate></item><item><title>Nix Derivation Madness</title><link>https://fzakaria.com/2025/10/29/nix-derivation-madness</link><description>&lt;doc fingerprint="2030dc0465830596"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nix derivation madness&lt;/head&gt;
    &lt;p&gt;Published 2025-10-29 on Farid Zakaria's Blog&lt;/p&gt;
    &lt;p&gt;I’ve written a bit about Nix and I still face moments where foundational aspects of the package system confounds and surprises me.&lt;/p&gt;
    &lt;p&gt;Recently I hit an issue that stumped me as it break some basic comprehension I had on how Nix works. I wanted to produce the build and runtime graph for the Ruby interpreter.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-shell -p ruby

&amp;gt; which ruby
/nix/store/mp4rpz283gw3abvxyb4lbh4vp9pmayp2-ruby-3.3.9/bin/ruby

&amp;gt; nix-store --query --include-outputs --graph \
  $(nix-store --query --deriver $(which ruby))
error: path '/nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv' is not valid

&amp;gt; ls /nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
ls: cannot access '/nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv':
No such file or directory
&lt;/code&gt;
    &lt;p&gt;Huh. 🤔&lt;/p&gt;
    &lt;p&gt;I have Ruby but I don’t seem to have the derivation, &lt;code&gt;24v9wpp393ib1gllip7ic13aycbi704g&lt;/code&gt;, file present on my machine.&lt;/p&gt;
    &lt;p&gt;No worries, I think I can &lt;code&gt;--realize&lt;/code&gt; it and download it from the NixOS cache.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-store --realize /nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
don't know how to build these paths:
  /nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
error: cannot build missing derivation '/nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv'
&lt;/code&gt;
    &lt;p&gt;I guess the NixOS cache doesn’t seem to have it. 🤷&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This was actually perplexing me at this moment. In fact there are multiple discourse posts about it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My mental model however of Nix though is that I must have first evaluated the derivation (drv) in order to determine the output path to even substitute. How could the NixOS cache not have it present?&lt;/p&gt;
    &lt;p&gt;Is this derivation wrong somehow? Nope. This is the derivation Nix believes that produced this Ruby binary from the &lt;code&gt;sqlite&lt;/code&gt; database. 🤨&lt;/p&gt;
    &lt;code&gt;&amp;gt; sqlite3 "/nix/var/nix/db/db.sqlite" 
    "select deriver from ValidPaths where path = 
    '/nix/store/mp4rpz283gw3abvxyb4lbh4vp9pmayp2-ruby-3.3.9'"
/nix/store/24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
&lt;/code&gt;
    &lt;p&gt;What does the binary cache itself say? Even the cache itself thinks this particular derivation, &lt;code&gt;24v9wpp393ib1gllip7ic13aycbi704g&lt;/code&gt;, produced this particular Ruby output.&lt;/p&gt;
    &lt;code&gt;&amp;gt; curl -s https://cache.nixos.org/mp4rpz283gw3abvxyb4lbh4vp9pmayp2.narinfo |\
  grep Deriver
Deriver: 24v9wpp393ib1gllip7ic13aycbi704g-ruby-3.3.9.drv
&lt;/code&gt;
    &lt;p&gt;What if I try a different command?&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix derivation show $(which ruby) | jq -r "keys[0]"
/nix/store/kmx8kkggm5i2r17s6l67v022jz9gc4c5-ruby-3.3.9.drv

&amp;gt; ls /nix/store/kmx8kkggm5i2r17s6l67v022jz9gc4c5-ruby-3.3.9.drv
/nix/store/kmx8kkggm5i2r17s6l67v022jz9gc4c5-ruby-3.3.9.drv
&lt;/code&gt;
    &lt;p&gt;So I seem to have a completely different derivation, &lt;code&gt;kmx8kkggm5i2r17s6l67v022jz9gc4c5&lt;/code&gt;, that resulted in the same output which is not what the binary cache announces. WTF? 🫠&lt;/p&gt;
    &lt;p&gt;Thinking back to a previous post, I remember touching on modulo fixed-output derivations. Is that what’s going on? Let’s investigate from first principles. 🤓&lt;/p&gt;
    &lt;p&gt;Let’s first create &lt;code&gt;fod.nix&lt;/code&gt; which is our fixed-output derivation.&lt;/p&gt;
    &lt;code&gt;let
  system = builtins.currentSystem;
in derivation {
  name = "hello-world-fixed";
  builder = "/bin/sh";
  system = system;
  args = [ "-c" ''
    echo -n "hello world" &amp;gt; "$out"
  '' ];
  outputHashMode = "flat";
  outputHashAlgo = "sha256";
  outputHash = "b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9";
}
&lt;/code&gt;
    &lt;p&gt;☝️ Since this is a fixed-output derivation (FOD) the produced &lt;code&gt;/nix/store&lt;/code&gt; path will not be affected to changes to the derivation beyond the contents of &lt;code&gt;$out&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate fod.nix
/nix/store/k2wjpwq43685j6vlvaarrfml4gl4196n-hello-world-fixed.drv

&amp;gt; nix-build fod.nix
/nix/store/ajk19jb8h5h3lmz20yz6wj9vif18lhp1-hello-world-fixed
&lt;/code&gt;
    &lt;p&gt;Now we will create a derivation that uses this FOD.&lt;/p&gt;
    &lt;code&gt;{ fodDrv ? import ./fod.nix }:

let
  system = builtins.currentSystem;
in
builtins.derivation {
  name = "uses-fod";
  inherit system;
  builder = "/bin/sh";
  args = [ "-c" ''
    echo ${fodDrv} &amp;gt; $out
    echo "Good bye world" &amp;gt;&amp;gt; $out
  '' ];
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;/nix/store&lt;/code&gt; for the output for this derivation will change on changes to the derivation except if the derivation path for the FOD changes. This is in fact what makes it “modulo” the fixed-output derivations.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate uses-fod.nix
/nix/store/85d15y7irq7x4fxv4nc7k1cw2rlfp3ag-uses-fod.drv

&amp;gt; nix-build uses-fod.nix
/nix/store/sd12qjak7rlxhdprj10187f9an787lk3-uses-fod
&lt;/code&gt;
    &lt;p&gt;Let’s test this all out by changing our &lt;code&gt;fod.nix&lt;/code&gt; derivation.
Let’s do this by just adding some garbage attribute to the derivation.&lt;/p&gt;
    &lt;code&gt;@@ -4,6 +4,7 @@
   name = "hello-world-fixed";
   builder = "/bin/sh";
   system = system;
+  garbage = 123;
   args = [ "-c" ''
     echo -n "hello world" &amp;gt; "$out"
   '' ];
&lt;/code&gt;
    &lt;p&gt;What happens now?&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate fod.nix
/nix/store/yimff0d4zr4krwx6cvdiqlin0y6vkis0-hello-world-fixed.drv

&amp;gt; nix-build fod.nix
/nix/store/ajk19jb8h5h3lmz20yz6wj9vif18lhp1-hello-world-fixed
&lt;/code&gt;
    &lt;p&gt;The path of the derivation itself, &lt;code&gt;.drv&lt;/code&gt;, has changed but the output path &lt;code&gt;ajk19jb8h5h3lmz20yz6wj9vif18lhp1&lt;/code&gt; remains consistent.&lt;/p&gt;
    &lt;p&gt;What about the derivation that leverages it?&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate uses-fod.nix
/nix/store/85wkdaaq6q08f71xn420v4irll4a8g8v-uses-fod.drv

&amp;gt; nix-build uses-fod.nix
/nix/store/sd12qjak7rlxhdprj10187f9an787lk3-uses-fod
&lt;/code&gt;
    &lt;p&gt;It also got a new derivation path but the output path remained unchanged. 😮&lt;/p&gt;
    &lt;p&gt;That means changes to fixed-output-derivations didn’t cause new outputs in either derivation but it did create a complete new tree of &lt;code&gt;.drv&lt;/code&gt; files. 🤯&lt;/p&gt;
    &lt;p&gt;That means in nixpkgs changes to fixed-output derivations can cause them to have new store paths for their &lt;code&gt;.drv&lt;/code&gt; but result in dependent derivations to have the same output path. If the output path had already been stored in the NixOS cache, then we lose the link between the new &lt;code&gt;.drv&lt;/code&gt; and this output path. 💥&lt;/p&gt;
    &lt;p&gt;The amount of churn that we are creating in derivations was unbeknownst to me.&lt;/p&gt;
    &lt;p&gt;It can get even weirder! This example came from @ericson2314.&lt;/p&gt;
    &lt;p&gt;We will duplicate the &lt;code&gt;fod.nix&lt;/code&gt; to another file &lt;code&gt;fod2.nix&lt;/code&gt; whose only difference is the value of the garbage.&lt;/p&gt;
    &lt;code&gt;@@ -4,7 +4,7 @@
   name = "hello-world-fixed";
   builder = "/bin/sh";
   system = system;
-  garbage = 123;
+  garbage = 124;
   args = [ "-c" ''
     echo -n "hello world" &amp;gt; "$out"
   '' ];
&lt;/code&gt;
    &lt;p&gt;Let’s now use both of these in our derivation.&lt;/p&gt;
    &lt;code&gt;{ fodDrv ? import ./fod.nix,
  fod2Drv ? import ./fod2.nix
}:
let
  system = builtins.currentSystem;
in
builtins.derivation {
  name = "uses-fod";
  inherit system;
  builder = "/bin/sh";
  args = [ "-c" ''
    echo ${fodDrv} &amp;gt; $out
    echo ${fod2Drv} &amp;gt;&amp;gt; $out
    echo "Good bye world" &amp;gt;&amp;gt; $out
  '' ];
}
&lt;/code&gt;
    &lt;p&gt;We can now instantiate and build this as normal.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix-instantiate uses-fod.nix
/nix/store/z6nr2k2hy982fiynyjkvq8dliwbxklwf-uses-fod.drv

&amp;gt; nix-build uses-fod.nix
/nix/store/211nlyx2ga7mh5fdk76aggb04y1wsgkj-uses-fod
&lt;/code&gt;
    &lt;p&gt;What is weird about that?&lt;/p&gt;
    &lt;p&gt;Well, let’s take the JSON representation of the derivation and remove one of the inputs.&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix derivation show \
    /nix/store/z6nr2k2hy982fiynyjkvq8dliwbxklwf-uses-fod.drv \
    jq 'values[].inputDrvs | keys[]'
"/nix/store/6p93r6x0bwyd8gngf5n4r432n6l380ry-hello-world-fixed.drv"
"/nix/store/yimff0d4zr4krwx6cvdiqlin0y6vkis0-hello-world-fixed.drv"
&lt;/code&gt;
    &lt;p&gt;We can do this because although there are two input derivations, we know they both produce the same output!&lt;/p&gt;
    &lt;code&gt;@@ -12,12 +12,6 @@
       "system": "x86_64-linux"
     },
     "inputDrvs": {
-      "/nix/store/6p93r6x0bwyd8gngf5n4r432n6l380ry-hello-world-fixed.drv": {
-        "dynamicOutputs": {},
-        "outputs": [
-          "out"
-        ]
-      },
       "/nix/store/yimff0d4zr4krwx6cvdiqlin0y6vkis0-hello-world-fixed.drv": {
         "dynamicOutputs": {},
         "outputs": [
&lt;/code&gt;
    &lt;p&gt;Let’s load this modified derivation back into our &lt;code&gt;/nix/store&lt;/code&gt; and build it again!&lt;/p&gt;
    &lt;code&gt;&amp;gt; nix derivation add &amp;lt; derivation.json
/nix/store/s4qrdkq3a85gxmlpiay334vd1ndg8hm1-uses-fod.drv

&amp;gt; nix-build /nix/store/s4qrdkq3a85gxmlpiay334vd1ndg8hm1-uses-fod.drv
/nix/store/211nlyx2ga7mh5fdk76aggb04y1wsgkj-uses-fod
&lt;/code&gt;
    &lt;p&gt;We got the same output &lt;code&gt;211nlyx2ga7mh5fdk76aggb04y1wsgkj&lt;/code&gt;. Not only do we have a &lt;code&gt;1:N&lt;/code&gt; trait for our output paths to derivations but we can also take certain derivations and completely change them by removing inputs and still get the same output! 😹&lt;/p&gt;
    &lt;p&gt;The road to Nix enlightenment is no joke and full of dragons.&lt;/p&gt;
    &lt;p&gt; Improve this page @ 7492cd3 &lt;lb/&gt; The content for this site is CC-BY-SA. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45772347</guid><pubDate>Fri, 31 Oct 2025 14:28:35 +0000</pubDate></item><item><title>AI scrapers request commented scripts</title><link>https://cryptography.dog/blog/AI-scrapers-request-commented-scripts/</link><description>&lt;doc fingerprint="3610991229718dc9"&gt;
  &lt;main&gt;
    &lt;p&gt;Last Sunday (2025-10-26) I discovered some abusive bot behaviour during a routine follow-up on anomalies that had shown up in my server's logfiles. There were a bunch of 404 errors ("Not Found") for a specific JavaScript file.&lt;/p&gt;
    &lt;p&gt;Most of my websites are static HTML, but I do occasionally include JS for progressive enhancement. It turned out that I accidentally committed and deployed a commented-out script tag that I'd included in the page while prototyping a new feature. The script was never actually pushed to the server - hence the 404 errors - but nobody should have been requesting it because that HTML comment should have rendered the script tag non-functional.&lt;/p&gt;
    &lt;p&gt;Clearly something weird was going on, so I dug a little further, searching my log files for all the requests for that non-existent file. A few of these came from user-agents that were obviously malicious:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;python-httpx/0.28.1&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;Go-http-client/2.0&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;Gulper Web Bot 0.2.4 (www.ecsl.cs.sunysb.edu/~maxim/cgi-bin/Link/GulperBot)&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;The robots.txt for the site in question forbids all crawlers, so they were either failing to check the policies expressed in that file, or ignoring them if they had. But then there were many requests for the file coming from agents which self-identified as proper browsers - mostly as variations of Firefox, Chrome, or Safari.&lt;/p&gt;
    &lt;p&gt;Most of these requests seemed otherwise legitimate, except their behaviour differed from what I'd expect from any of those browsers. There are occasionally minor differences between how browsers parse uncommon uses of HTML, but I can say with a lot of confidence that all the major ones know how to properly interpret an HTML comment. I had caught them in a lie. These were scrapers, and they were most likely trying to non-consensually collect content for training LLMs.&lt;/p&gt;
    &lt;p&gt;A charitable interpretation for this behaviour is that the scrapers are correctly parsing HTML, but then digging into the text of comments and parsing that recursively to search for URLs that might have been disabled. The uncharitable (and far more likely) interpretation is that they'd simply treated the HTML as text, and had used some naive pattern-matching technique to grab anything vaguely resembling a URL.&lt;/p&gt;
    &lt;p&gt;Even just judging purely by the variety of user-agent headers among the requests, these scrapers seem to be under the control of different operators with wildly different levels of sophistication. Some took the effort to use an up-to-date user-agent string from a real browser, while others couldn't be bothered to change the default value of the off-the-shelf HTTP library they'd leveraged.&lt;/p&gt;
    &lt;p&gt;For all I know some of these different actors were doing the savvy parsing method while others are cludging around with regular expressions ChatGPT generated for them. I'm curious about which method they're employing, but I don't think the distinction is particularly important. Whatever the case may be, the unifying quality behind all these requests is that they are motivated by greed, and that can be exploited.&lt;/p&gt;
    &lt;p&gt;The intentional sabotage of algorithmic systems is an increasingly popular these days, largely due to the externalized costs of LLMs, but it's by no means a new topic. Given a little knowledge about how a malicious system works, it's often possible to intervene in a manner that undermines or subverts their intended behaviour. Ideally these interventions should not require too much effort or cost on the part of those doing the sabotage.&lt;/p&gt;
    &lt;p&gt;In this case the reasoning is fairly simple: these bots behave differently than humans, and once you know what to look for it becomes trivial to single them out. Then it's just a question of how to respond.&lt;/p&gt;
    &lt;p&gt;I'm numbering the responses I've considered and indexing from zero because this is something of a meta-response. There are many trivially detectable bot behaviours that I would consider incidental, which is to say that their authors could easily modify those behaviours if they realized that it made their bots less effective.&lt;/p&gt;
    &lt;p&gt;For example, they might have tried to set its user-agent string to that of a normal browser, but accidentally included a typo like "Mozlla" in the process. If this became common knowledge, all they'd have to do is fix their typo. Unfortunately, this means that whenever I discover such an anomaly (which happens a lot) I mostly keep it to myself so that it keeps working.&lt;/p&gt;
    &lt;p&gt;Then there are fundamental behaviours, such as with bots that scan the internet looking for websites with publicly exposed backups, private keys, or passwords. The only way for them to do their job is to request a resource that only a malicious visitor would request. Telling everyone about this behaviour helps them block such bots, and hopefully prompts them to double-check whether any such assets are exposed. The bot becomes less effective, and its operator's only recourse is to not make such requests, which I consider a win.&lt;/p&gt;
    &lt;p&gt;Requests for scripts which are only ever referenced from HTML comments are clearly in the fundamental category. So, even though I only noticed this behaviour by accident, I've already set up measures to detect it across my other sites, and I'm doing my best to let more people know about it.&lt;/p&gt;
    &lt;p&gt;Blocking malicious actors by IP requires relatively little effort. The fail2ban project is open-source and available in every major linux distribution's package manager. It scans log files for three components:&lt;/p&gt;
    &lt;p&gt;a pattern&lt;/p&gt;
    &lt;p&gt;a date&lt;/p&gt;
    &lt;p&gt;an IP address&lt;/p&gt;
    &lt;p&gt;When a log entry matches the pattern, fail2ban updates the system's firewall to block the offending IP for a configurable amount of time starting from the date of that log entry.&lt;/p&gt;
    &lt;p&gt;Many administrators are conservative when configuring the duration of these blocks, effectively using it to apply rate-limits to malicious behaviour. They might allow an attacker to try again in a few hours, which is somewhat reasonable because many admins accidentally lock themselves out of their systems in the process of setting up and testing these rules. Those limits can be bypassed using a VPN, but if the limit is only applied for a brief period it might be easier to simply wait it out.&lt;/p&gt;
    &lt;p&gt;If you're confident that you can avoid getting locked out by your own firewall, and that your rules will not inadvertently block legitimate visitors, you can dial up the duration of those IP blocks. Clever bot operators might configure them to learn not send requests which get them blocked, but if the block time is on the order of weeks or months then they'll have very little data with which to to learn.&lt;/p&gt;
    &lt;p&gt;Then there are networks of bots to consider, many of which are sophisticated enough to continue sending requests from different IP addresses when one is blocked. There are clever ways to do this that avoid detection, but many botnet operators are pretty brazen about it and end up revealing patterns behind how their botnet operates. There's a lot more to be said about that, but I'll leave it for a potential future article.&lt;/p&gt;
    &lt;p&gt;More commonly referred to as zip bombs - this response goes beyond defending your own system and moves into the counter-offensive space. Decompression bombs refer to maliciously crafted archive files designed to harm the receiving system in some way upon attempting to extract files from that archive.&lt;/p&gt;
    &lt;p&gt;There are a variety of approaches depending on the expected behaviour of the system that will unpack the archive, but they typically aim to fill up the system's disk, consume large amounts of CPU or RAM to degrade performance or crash the system, or in extreme cases exploit vulnerabilities in the extraction software to achieve remote code execution.&lt;/p&gt;
    &lt;p&gt;On one hand, most of these bombs rely on old and well-understood techniques, so it's not that difficult for a sophisticated actor to defend themselves. On the other, most attackers are not sophisticated, so there is ample opportunity to have some fun at their expense.&lt;/p&gt;
    &lt;p&gt;There are significant downsides to this approach, though. Serving a zip bomb to an attacker requires some computational resources. The usual premise is that the burden will be far greater for the system extracting the archive than for the one serving it, but that burden might not be negligible.&lt;/p&gt;
    &lt;p&gt;Many of the malicious bots that scan the internet for exposed data and vulnerabilities operate on compromised systems. Rendering such a system temporarily inoperable is an inconvenience to them, but they typically won't incur any costs as a result, whereas mounting such a counter-attack could potentially use up the defender's monthly bandwidth quota.&lt;/p&gt;
    &lt;p&gt;Such attacks might simply crash these bots rather than filling their disks, after which they might be expected to retry their last request. Additionally, there are many, many such bots, and it's probably not reasonable to expect to be able to resist all of them. It could be a fun project to randomly select one in a hundred such requests and attempt to disable them, blocking their IP otherwise, but I wouldn't recommend attempting to zip-bomb all of them.&lt;/p&gt;
    &lt;p&gt;I haven't personally deployed any measures to serve poisoned training data to those scraping for LLMs, but I have been paying attention to the theory behind it and reading new papers as they have been published.&lt;/p&gt;
    &lt;p&gt;For those not familiar with this technique, the basic idea is that it's possible to create or modify text, images, or other media such that machine learning systems that include those samples in their training sets become compromised in some way. So, if you've pre-processed an image of your dog and someone uses it to train a generative AI system, prompts to generate images of dogs might be more likely to generate a schoolbus or something silly like that.&lt;/p&gt;
    &lt;p&gt;For things like LLMs, you might degrade their models to be more likely to output nonsense when prompted for particular topics. Many researchers used to believe that poisoned samples had to make up a certain percentage of the full training set, which would have been increasingly difficult as companies like OpenAI continue to train ever-larger models. On the contrary, recent research (which I believe is still awaiting peer-review) suggests that "Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples":&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We find that 250 poisoned documents similarly compromise models across all model and dataset sizes, despite the largest models training on more than 20 times more clean data. We also run smaller-scale experiments to ablate factors that could influence attack success, including broader ratios of poisoned to clean data and non-random distributions of poisoned samples. Finally, we demonstrate the same dynamics for poisoning during fine-tuning. Altogether, our results suggest that injecting backdoors through data poisoning may be easier for large models than previously believed as the number of poisons required does not scale up with model size, highlighting the need for more research on defences to mitigate this risk in future models.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Chatbots and so-called "AI search" or "answer engines" are so widely relied on as sources of information that I've seen speculation that this will lead to data poisoning as a modern equivalent to Search Engine Optimization. Essentially, if you can get an LLM company to include 250 malcious documents in their training set, you might be able to get their language models to recommend your product any time somebody prompts them concerning a given topic.&lt;/p&gt;
    &lt;p&gt;From what I understand, tricking models into responding with unhelpful or nonsensical results is relatively easy. Getting them to reliably output your desired results require somewhat more deliberate effort, but it's certainly within the realm of practicality. I could serve poisoned samples such that anyone asking about security research gets a recommendation to read this blog. I could also poison the JavaScript files these scrapers are requesting such that any LLM trained on them would more likely to include backdoors whenever they were used to write or vibe-code authentication logic for web services (not that anybody should use LLMs for that anyway).&lt;/p&gt;
    &lt;p&gt;There is a strong case to be made for data poisoning. Many machine learning systems are built on data that was collected without the consent of its authors. In many cases, the resulting products are being used to replace labour, or at least fire and re-hire workers at lower rates. Some of these models cost many billions of dollars to train, so the prospect that a few hundred samples could do irreperable damage to their product should rightfully worry those that are training such systems on stolen data.&lt;/p&gt;
    &lt;p&gt;The use of freely available data-poisoning tools like nepenthes, iocaine, glaze, and nightshade is in my opinion not only entirely justified, but also hilarious, and I hope people like Sam Altman are losing lots of sleep over their existence. That said, they are some minor factors that can complicate their use.&lt;/p&gt;
    &lt;p&gt;For admins that have not taken any measures to mitigate activity from malicious bots, I would absolutely recommend deploying one of these solutions to serve up poison to LLM scrapers. Various bots are almost certainly going wild on your infra while probing for vulnerabilities and looking for text, images, and other media to ingest. Your system would have spent its resources serving their requests anyway, but at least this way you'll deliver content that might harm them in some way. You might serve some poisoned content to bots that won't use it to train ML systems, but the cost of that will likely be negligible.&lt;/p&gt;
    &lt;p&gt;If you have taken measures to restrict bot access (via fail2ban, for instance) then the matter will be moderately more complicated. It's not the two approaches are entirely incompatible, but depending on the exact implementation details there can be some tension between attempts to block some malicious usage while poisoning some other assets. I think it ought to be manageable, but it might rely on the sort of patterns which I defined above as incidental.&lt;/p&gt;
    &lt;p&gt;Unfortunately, this would mean that if I were to learn that some design was particularly effective then I might have good reason not to share it. Some acts of sabotage will inherently rely on expertise and creativity, and therefore won't be broadly replicable. Some will surely find that discouraging, but I simply take it to mean that more people will need to become actively involved in sabotaging the anti-social activities of big tech companies.&lt;/p&gt;
    &lt;p&gt;Identifying bots by quirks in their behaviour is by no means novel. I haven't seen anyone mention this particular quirk before, but similar techniques are well-established. I've seen others recommend adding disallow directives to a site's &lt;code&gt;robots.txt&lt;/code&gt; file such that any requests for those assets
trigger a proposed anti-bot counter-measure, like so:&lt;/p&gt;
    &lt;code&gt;User-agent: GPTBot
Disallow: /poison/
&lt;/code&gt;
    &lt;p&gt;When I posted about this discovery on the fediverse several people suggested their own mitigations and similar bait that could be left out to lure bots in a similar manner. david turgeon proposed the following (formatted for readability on this site):&lt;/p&gt;
    &lt;code&gt;&amp;lt;a href="/hello-llm-robot-come-here"
   rel="nofollow"
   style="display:none"
&amp;gt;you didn't see this link&amp;lt;/a&amp;gt;
&lt;/code&gt;
    &lt;p&gt;The use of &lt;code&gt;display:none&lt;/code&gt; makes it such that browsers
will not display the link, and that screenreaders will
avoid reading its text out loud.
&lt;code&gt;rel="nofollow"&lt;/code&gt; instructs crawlers not to visit the link
(it's a little more complicated than that, but well-behaved crawlers
ought to respect it).
The &lt;code&gt;href&lt;/code&gt; attribute points bad crawlers towards the resource
that will get them banned, or zip-bomb them, or serve poisoned data.
I might change that to an absolute URL
(including an the &lt;code&gt;https&lt;/code&gt; protocol directive and a full domain)
because lots of crawlers seem more likely to fall for complete URLs
than relative ones.&lt;/p&gt;
    &lt;p&gt;In any case, I'm already working on deploying a variety of similar techniques across many different websites, and I plan to measure which ones are most effective against different types of bots. Hopefully I'll learn things that I can freely share, but either way I hope more people will get involved in similar efforts, like jonny, whose poison was:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;...trained on a combination of WWE announcer transcripts and Kropotkin's mutual aid among some other texts: https://sciop.net/crawlers/&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It might be hard to top that, but I'd love to see people try.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45773347</guid><pubDate>Fri, 31 Oct 2025 15:44:19 +0000</pubDate></item><item><title>Futurelock: A subtle risk in async Rust</title><link>https://rfd.shared.oxide.computer/rfd/0609</link><description>&lt;doc fingerprint="4f04f8462db13f84"&gt;
  &lt;main&gt;
    &lt;p&gt;This RFD describes futurelock: a type of deadlock where a resource owned by Future &lt;code&gt;A&lt;/code&gt; is required for another Future &lt;code&gt;B&lt;/code&gt; to proceed, while the Task responsible for both Futures is no longer polling &lt;code&gt;A&lt;/code&gt;.  Futurelock is a particularly subtle risk in writing asynchronous Rust.&lt;/p&gt;
    &lt;p&gt;Oxide initially saw this problem in oxidecomputer/omicron#9259.&lt;/p&gt;
    &lt;head rend="h2"&gt;Example of the problem&lt;/head&gt;
    &lt;p&gt;Consider the following program (in the playground):&lt;/p&gt;
    &lt;code&gt;use std::sync::Arc;&lt;/code&gt;
    &lt;p&gt;This program reliably deadlocks. This surprises a lot of people! A background Task takes a lock, waits 5s, drops the lock and exits. In the meantime, we &lt;code&gt;do_stuff&lt;/code&gt;.  That stuff consists of waiting for two Futures concurrently via &lt;code&gt;select!&lt;/code&gt;. One future waits for the lock while the other sleeps for 0.5s and waits for the lock. So there’s just one lock and all logical streams of execution seem to execute concurrently.  How could this possibly hang?&lt;/p&gt;
    &lt;p&gt;The interesting bits are all in &lt;code&gt;do_stuff()&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;async fn do_stuff(lock: Arc&amp;lt;Mutex&amp;lt;()&amp;gt;&amp;gt;) {&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;future1&lt;/code&gt; is the (boxed) future returned by &lt;code&gt;do_async_thing()&lt;/code&gt;, an async function.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;Weâll call the future returned by &lt;code&gt;sleep&lt;/code&gt;: &lt;code&gt;future2&lt;/code&gt; (or, the "sleep" future).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;The second branch of the &lt;code&gt;select!&lt;/code&gt; is its own future.  Weâll call this &lt;code&gt;future3&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;It’s really important to understand what’s happening here so let’s be clear about the sequence.&lt;/p&gt;
    &lt;p&gt;First:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;background task takes&lt;/p&gt;&lt;code&gt;lock&lt;/code&gt;, begins holding it for 5 seconds&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tokio::select!&lt;/code&gt;begins polling&lt;code&gt;&amp;amp;mut future1&lt;/code&gt;.[1] This future attempts to take the lock, blocks, returns&lt;code&gt;Poll::Pending&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tokio::select!&lt;/code&gt;begins polling&lt;code&gt;future2&lt;/code&gt;(the sleep future) and blocks, returning&lt;code&gt;Poll::Pending&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At this point:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;the background task holds the lock&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;the main task is blocked in&lt;/p&gt;&lt;code&gt;tokio::select!&lt;/code&gt;on two different futures:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;future1&lt;/code&gt;is blocked on taking the lock&lt;/item&gt;&lt;item&gt;&lt;code&gt;future2&lt;/code&gt;(the&lt;code&gt;sleep&lt;/code&gt;future) waiting for 500ms&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;500ms later, &lt;code&gt;tokio&lt;/code&gt; wakes up the main task because &lt;code&gt;future2&lt;/code&gt; (the sleep future) is ready.  Inside &lt;code&gt;tokio::select!&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The task polls both futures.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;future1&lt;/code&gt;is still blocked on the lock and returns&lt;code&gt;Pending&lt;/code&gt;.[2]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;future2&lt;/code&gt;(the sleep future) is ready and returns&lt;code&gt;Ready&lt;/code&gt;.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tokio::select!&lt;/code&gt;chooses the second branch&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;&amp;amp;mut future1&lt;/code&gt;is dropped, but this is just a reference and so has no effect. Importantly, the future itself (&lt;code&gt;future1&lt;/code&gt;) is not dropped.&lt;/item&gt;&lt;item&gt;&lt;p&gt;the second branch is entered.&lt;/p&gt;&lt;code&gt;do_async_thing("op2", …)&lt;/code&gt;is called, creating a new future&lt;code&gt;future3&lt;/code&gt;. This future immediately blocks trying to take the lock, which is still held by the background task.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At this point, we have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;the lock (still) held by the background task&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;the lock’s wait queue contains two waiting futures:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;code&gt;future1&lt;/code&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;code&gt;future3&lt;/code&gt;(the second arm of the&lt;code&gt;tokio::select!&lt;/code&gt;)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are two key points here:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;The lockâs wait queue is literally a queue: only&lt;/p&gt;&lt;code&gt;future1&lt;/code&gt;can take the lock once it is released by the background task (unless&lt;code&gt;future1&lt;/code&gt;is dropped).&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The behavior of&lt;/p&gt;&lt;code&gt;tokio::select!&lt;/code&gt;is to poll all branches' futures only until one of them returns `Ready`. At that point, it drops the other branches' futures and only runs the body of the branch thatâs ready.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Critically: the same task is responsible for both of the futures waiting on the lock. But that task is currently only polling on one of them. Unfortunately, it’s the wrong one.&lt;/p&gt;
    &lt;p&gt;About 4.5 seconds later:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The background task drops the lock.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;p&gt;The lock is given to&lt;/p&gt;&lt;code&gt;future1&lt;/code&gt;. (See below for more on why.)&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;The task that polled&lt;/p&gt;&lt;code&gt;future1&lt;/code&gt;(the main task) is woken up.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;However, that task is not polling&lt;/p&gt;&lt;code&gt;future1&lt;/code&gt;.&lt;code&gt;future1&lt;/code&gt;is polled at the top-level&lt;code&gt;tokio::select!&lt;/code&gt;. But the&lt;code&gt;tokio::select!&lt;/code&gt;has already chosen the other branch. It’s now only polling&lt;code&gt;future3&lt;/code&gt;. (In fact, even absent the imminent hang,&lt;code&gt;future1&lt;/code&gt;would never be polled again. It would be cancelled without having completed when it got dropped at the end of&lt;code&gt;do_stuff&lt;/code&gt;.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thus:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;There is only one task left. It’s blocked on&lt;/p&gt;&lt;code&gt;future3&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;future3&lt;/code&gt;is blocked on a Mutex that’s owned by&lt;code&gt;future1&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;future1&lt;/code&gt;cannot run (and therefore cannot drop the Mutex) until the task starts running it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We call this specific kind of deadlock futurelock. The program is stuck in this state forever.&lt;/p&gt;
    &lt;head rend="h3"&gt;FAQ: why doesnât the Mutex wake up the other future?&lt;/head&gt;
    &lt;p&gt;This particular example uses &lt;code&gt;tokio::sync::Mutex&lt;/code&gt;, which is a fair Mutex.  That means that the lock is given to waiters in the order that they started waiting.  It has to give it to &lt;code&gt;future1&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;An unfair Mutex would not fix things. The problem wouldn’t be guaranteed to happen with an unfair Mutex, but it wouldn’t be guaranteed not to, either. The Mutex does not (and cannot) know which future would be "better" to wake up, or which one is being polled. You could imagine an unfair Mutex that always woke up all waiters and let them race to grab the lock again. That would not suffer from risk of futurelock, but it would have the thundering herd problem plus all the liveness issues associated with unfair synchronization primitives. And it’s not how many synchronization primitives work.&lt;/p&gt;
    &lt;p&gt;It’s helpful to view this in terms of responsibilities: the Mutex’s job here is to wake up the next task waiting for the lock. And it’s doing that. It’s that task’s responsibility to check on all the futures that it’s responsible for. The Mutex cannot do that.&lt;/p&gt;
    &lt;head rend="h3"&gt;FAQ: why isnât the &lt;code&gt;tokio::select!&lt;/code&gt; polling on &lt;code&gt;future1&lt;/code&gt;?  Isnât that the whole idea of &lt;code&gt;tokio::select!&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;The idea of &lt;code&gt;tokio::select!&lt;/code&gt; is to poll on multiple futures concurrently and enter the branch for whichever one finishes first.  Once one of the futures does finish (as the &lt;code&gt;sleep&lt;/code&gt; one has in our case), control enters that specific branch.  It essentially commits to that branch and it’s only running that branch at that point.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;tokio::select!&lt;/code&gt; docs are explicit about this:&lt;/p&gt;
    &lt;p&gt;By running all async expressions on the current task, the expressions are able to run concurrently but not in parallel. This means all expressions are run on the same thread and if one branch blocks the thread, all other expressions will be unable to continue. If parallelism is required, spawn each async expression using tokio::spawn and pass the join handle to select!.&lt;/p&gt;
    &lt;head rend="h3"&gt;FAQ: doesnât &lt;code&gt;future1&lt;/code&gt; get cancelled?&lt;/head&gt;
    &lt;p&gt;When one of the futures that &lt;code&gt;tokio::select!&lt;/code&gt; is polling on completes, the others get dropped.  In this case, what’s dropped is &lt;code&gt;&amp;amp;mut future1&lt;/code&gt;.  But &lt;code&gt;future1&lt;/code&gt; is not dropped, so the actual future is not cancelled.&lt;/p&gt;
    &lt;p&gt;If &lt;code&gt;future1&lt;/code&gt; did get cancelled, you’d get no deadlock.  Try it: change the above to wait on &lt;code&gt;future1&lt;/code&gt; instead of &lt;code&gt;&amp;amp;mut future1&lt;/code&gt;.  Alternatively, you can add an explicit &lt;code&gt;drop(future1);&lt;/code&gt; at line 51 between the &lt;code&gt;sleep&lt;/code&gt; and the &lt;code&gt;do_async_thing&lt;/code&gt;.  This mimics what &lt;code&gt;select!&lt;/code&gt; does if we use &lt;code&gt;future1&lt;/code&gt; rather than &lt;code&gt;&amp;amp;mut future1&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When first learning async Rust, it’s common to think of tasks and futures almost interchangeably. When you want parallelism, you spawn a new task and give it the future that you want to run. If you want to do 10 things in parallel, you spawn 10 tasks and then wait for them all to finish.&lt;/p&gt;
    &lt;p&gt;You can have concurrency without tasks (and without parallelism) using something like &lt;code&gt;tokio::select!&lt;/code&gt;.  Within a single task, you can do 10 things concurrently (not in parallel) using &lt;code&gt;tokio::select!&lt;/code&gt; or &lt;code&gt;FuturesUnordered&lt;/code&gt; or the like.  In this case, your one task is polling on all these futures and getting woken up when any of them might be ready.&lt;/p&gt;
    &lt;p&gt;Tasks are the top-level entities that the runtime executes. Each task runs one top-level future. That future can choose to do only do one thing at a time (as in the case of sequential code using &lt;code&gt;await&lt;/code&gt;), or it can choose to do things concurrently by polling many futures, using &lt;code&gt;tokio::select!&lt;/code&gt; or &lt;code&gt;FuturesUnordered&lt;/code&gt; or the like.&lt;/p&gt;
    &lt;head rend="h2"&gt;What causes futurelock?&lt;/head&gt;
    &lt;p&gt;The general problem here is that you have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;task&lt;/p&gt;&lt;code&gt;T&lt;/code&gt;is blocked on future&lt;code&gt;F1&lt;/code&gt;completing (and&lt;code&gt;T&lt;/code&gt;is directly awaiting&lt;code&gt;F1&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;future&lt;/p&gt;&lt;code&gt;F1&lt;/code&gt;is blocked on future&lt;code&gt;F2&lt;/code&gt;in some way (e.g., acquiring a shared Mutex)&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;future&lt;/p&gt;&lt;code&gt;F2&lt;/code&gt;is blocked on task&lt;code&gt;T&lt;/code&gt;polling it, but&lt;code&gt;T&lt;/code&gt;isn’t polling it because it’s only polling&lt;code&gt;F1&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Most commonly this happens after &lt;code&gt;T&lt;/code&gt; started polling &lt;code&gt;F2&lt;/code&gt; earlier, but then switched to &lt;code&gt;F1&lt;/code&gt;.  This can happen in a bunch of different cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;using&lt;/p&gt;&lt;code&gt;tokio::select!&lt;/code&gt;with a&lt;code&gt;&amp;amp;mut future&lt;/code&gt;and awaiting in one of the other branches (our example above)&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;polling futures from a&lt;/p&gt;&lt;code&gt;FuturesOrdered&lt;/code&gt;/&lt;code&gt;FuturesUnordered&lt;/code&gt;(e.g., by calling&lt;code&gt;next()&lt;/code&gt;) and then awaiting on any other future (e.g., each time one of the futures completes from the set, you do some async activity)&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;in a hand-written&lt;/p&gt;&lt;code&gt;Future&lt;/code&gt;impl that behaves analogously&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can hit futurelock even if you never start polling one of the futures. Consider this example:&lt;/p&gt;
    &lt;code&gt;use futures::FutureExt;&lt;/code&gt;
    &lt;p&gt;This deadlocks, too. And for the same reason: this task is waiting on a future that itself depends on a future that this task is responsible for running. This is possible but feels contrived. This RFD focuses on cases where the dependency between futures relates to a shared resource. That generally requires that the futures all start running so they can get in line for the resource.&lt;/p&gt;
    &lt;head rend="h3"&gt;How you can hit this with &lt;code&gt;tokio::select!&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Hitting this problem with &lt;code&gt;tokio::select!&lt;/code&gt; (as in the example above) requires two things to be true:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;You must be passing a&lt;/p&gt;&lt;code&gt;&amp;amp;mut future&lt;/code&gt;to one of the branches. If you’re passing an owned future, then it will get dropped when the&lt;code&gt;tokio::select!&lt;/code&gt;enters a different branch. That generally releases the resources that might have been blocking other futures.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;You must be using&lt;/p&gt;&lt;code&gt;await&lt;/code&gt;in one of the branches' handlers. If you’re not doing this, then the task does not get blocked on any particular future at the expense of the others.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That said, it’s just as problematic to have an owned future across a &lt;code&gt;tokio::select!&lt;/code&gt; and await after it (full example):&lt;/p&gt;
    &lt;code&gt;async fn do_stuff(lock: Arc&amp;lt;Mutex&amp;lt;()&amp;gt;&amp;gt;) {&lt;/code&gt;
    &lt;p&gt;This results in exactly the same behavior.&lt;/p&gt;
    &lt;head rend="h3"&gt;How you can hit this with Streams&lt;/head&gt;
    &lt;p&gt;If you pull a future from a &lt;code&gt;Stream&lt;/code&gt; and then await a future that somehow depends on another Future in the stream, you can wind up with futurelock.  Here’s what it looks like with FuturesOrdered (full example):&lt;/p&gt;
    &lt;code&gt;async fn do_stuff(lock: Arc&amp;lt;Mutex&amp;lt;()&amp;gt;&amp;gt;) {&lt;/code&gt;
    &lt;p&gt;These are often used in a loop, so it may tend to look more like this (full example):&lt;/p&gt;
    &lt;code&gt;async fn do_stuff(lock: Arc&amp;lt;Mutex&amp;lt;()&amp;gt;&amp;gt;) {&lt;/code&gt;
    &lt;p&gt;It seems likely that futurelock is a risk when using many other Stream functions.&lt;/p&gt;
    &lt;head rend="h3"&gt;What about &lt;code&gt;join_all&lt;/code&gt;?&lt;/head&gt;
    &lt;p&gt;You can’t hit this with &lt;code&gt;futures::future::join_all&lt;/code&gt;.  That’s because it polls all of its futures and does not stop polling any of the pending futures.&lt;/p&gt;
    &lt;head rend="h2"&gt;Failure mode, debugging&lt;/head&gt;
    &lt;p&gt;Futurelock is a type of deadlock and tends to manifest as a hang of part or all of the program. When we saw this in omicron#9259, every future attempting to access the database became part of the futurelock. Since authorization uses the database, essentially every incoming HTTP request hung indefiniteily.&lt;/p&gt;
    &lt;p&gt;Debugging this problem from direct observation can be next to impossible. Typically, you’d only start looking at data long after the problem happened. At that point, it’s not clear what evidence you’d find even if you could peer into the executor state. The problem looks like a &lt;code&gt;pending&lt;/code&gt; future whose task has been woken up because of that future, but the task has not polled the future.  (Maybe &lt;code&gt;tokio-console&lt;/code&gt; could help?)&lt;/p&gt;
    &lt;p&gt;In omicron#9259, we were able to determine (by tracing individual function calls with DTrace) that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;all incoming requests were blocking on attempts to send on an&lt;/p&gt;&lt;code&gt;mpsc&lt;/code&gt;channel with capacity 1&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;the receiving end of this channel was regularly checking it and finding no messages queued&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This confused us for quite a while. Why are senders blocking if there’s nothing in the channel? In hindsight, the answer’s implied by the documentation for &lt;code&gt;Sender&lt;/code&gt;, which says:&lt;/p&gt;
    &lt;p&gt;Sends a value, waiting until there is capacity.&lt;/p&gt;
    &lt;p&gt;…&lt;/p&gt;
    &lt;p&gt;This channel uses a queue to ensure that calls to send and reserve complete in the order they were requested.&lt;/p&gt;
    &lt;p&gt;One can infer that a given call to &lt;code&gt;send&lt;/code&gt; may block either because there is no capacity or because another sender’s &lt;code&gt;send()&lt;/code&gt; is not completing.  That could be because the channel is full, but in our case it’s because the future for that sender had run into futurelock.&lt;/p&gt;
    &lt;p&gt;It’s hard to give useful advice for debugging this sort of problem aside from advising that you consider futurelock as a possibility if you’re debugging a hang and some future appears blocked when other evidence suggests that it shouldn’t be.&lt;/p&gt;
    &lt;head rend="h2"&gt;Determinations: avoiding this problem&lt;/head&gt;
    &lt;p&gt;Like async cancellation (see [rfd397]), futurelock defeats Rust’s goal of being able to reason locally about correctness. If we look at the pieces involved in our example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Using&lt;/p&gt;&lt;code&gt;tokio::select!&lt;/code&gt;to wait for any of a few things to happen&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Using&lt;/p&gt;&lt;code&gt;await&lt;/code&gt;in a&lt;code&gt;tokio::select!&lt;/code&gt;branch&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Using a&lt;/p&gt;&lt;code&gt;&amp;amp;mut future&lt;/code&gt;with&lt;code&gt;tokio::select!&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Using a Mutex[3]&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;None of these by itself is wrong, but combining them results in futurelock. Remember too that the Mutex could be buried beneath several layers of function calls in different modules or packages. It could require looking across many layers of the stack at once to be able to see the problem.&lt;/p&gt;
    &lt;p&gt;There’s no one abstraction, construct, or programming pattern we can point to here and say "never do this". Still, we can provide some guidelines.&lt;/p&gt;
    &lt;head rend="h3"&gt;In general&lt;/head&gt;
    &lt;p&gt;The most specific general advice we can give is: any time you have a single task polling multiple futures concurrently, be extremely careful that the task never stops polling a future that it previously started polling.&lt;/p&gt;
    &lt;p&gt;One way to avoid this situation is to bias towards spawning futures in new tasks instead. There are other considerations with this approach: futures would be cancelled when they’re dropped, but tasks won’t be aborted when their JoinHandle is dropped. If you want this, see &lt;code&gt;AbortOnDropHandle&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;When using &lt;code&gt;tokio::select!&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;If you find yourself writing or reviewing code that does either of these:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Uses a&lt;/p&gt;&lt;code&gt;&amp;amp;mut future&lt;/code&gt;as one of the async expressions in the&lt;code&gt;tokio::select!&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Awaits inside the handler of a&lt;/p&gt;&lt;code&gt;tokio::select!&lt;/code&gt;branch or after the&lt;code&gt;tokio::select!&lt;/code&gt;before the&lt;code&gt;future&lt;/code&gt;has been dropped&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;then look for the other as well. If both are present, pay close attention to the risk of futurelock. To avoid it, you either need to avoid doing both of these things in the same &lt;code&gt;tokio::select!&lt;/code&gt; call or else be very sure that &lt;code&gt;future&lt;/code&gt; never blocks with shared resources held that could block other futures.&lt;/p&gt;
    &lt;p&gt;Let’s consider a variation of our original example:&lt;/p&gt;
    &lt;code&gt;    let mut future1 = do_async_thing("op1", lock.clone()).boxed();&lt;/code&gt;
    &lt;p&gt;Here, we’ve wrapped the &lt;code&gt;tokio::select!&lt;/code&gt; in a loop.  This is a common pattern.  The idea here is mainly to run &lt;code&gt;future1&lt;/code&gt;, but every 500ms we do something related (like report progress or check if we should cancel the like).&lt;/p&gt;
    &lt;p&gt;The easiest way to make this safer is to spawn &lt;code&gt;future&lt;/code&gt; in a new task.  Then use the &lt;code&gt;JoinHandle&lt;/code&gt; in the &lt;code&gt;tokio::select!&lt;/code&gt;, like this version:&lt;/p&gt;
    &lt;code&gt;    let future1 = do_async_thing("op1", lock.clone());&lt;/code&gt;
    &lt;p&gt;This has the same desired effect of keeping &lt;code&gt;future1&lt;/code&gt; running, but now &lt;code&gt;future1_task&lt;/code&gt; is a separate future.  It’s cancellable, and cancelling it won’t cancel &lt;code&gt;future1&lt;/code&gt;.  (If you want that, you can still use &lt;code&gt;future1_task.abort()&lt;/code&gt;.)  This construction cannot result in futurelock.&lt;/p&gt;
    &lt;p&gt;If you’re not using a loop, this approach is even better: then you can just pass &lt;code&gt;future1_task&lt;/code&gt; to &lt;code&gt;tokio::select!&lt;/code&gt; (rather than &lt;code&gt;&amp;amp;mut future1_task&lt;/code&gt;) and it’ll be more obvious that this is safe.&lt;/p&gt;
    &lt;p&gt;In the end, you should always be extremely careful with &lt;code&gt;tokio::select!&lt;/code&gt;.  That’s because:&lt;/p&gt;
    &lt;p&gt;So either way you’ve got a subtle, non-locally-reasonable, undebuggable problem to worry about that the compiler can’t really help with.&lt;/p&gt;
    &lt;head rend="h3"&gt;When using &lt;code&gt;Stream&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;When using a &lt;code&gt;FuturesOrdered&lt;/code&gt; or &lt;code&gt;FuturesUnordered&lt;/code&gt;, consider instead using tokio’s &lt;code&gt;JoinSet&lt;/code&gt;.  This provides a similar interface, but the futures you’re waiting for are all running in separate tasks.&lt;/p&gt;
    &lt;p&gt;If for whatever reason that’s not appropriate (e.g., you’re not using &lt;code&gt;tokio&lt;/code&gt;, or you really need a &lt;code&gt;Stream&lt;/code&gt; interface), then in the body of a loop that pulls completed futures from the &lt;code&gt;Stream&lt;/code&gt;, do not await any other futures.  If you’re working with a &lt;code&gt;FuturesUnordered&lt;/code&gt;, consider putting those futures into the set instead.&lt;/p&gt;
    &lt;head rend="h3"&gt;When using bounded channels&lt;/head&gt;
    &lt;p&gt;Bounded channels are not really the issue here. Even in omicron#9259, the capacity=1 channel was basically behaving as documented and as one would expect. It woke up a sender when capacity was available, and the other senders were blocked to maintain the documented FIFO property. However, some of the patterns that we use with bounded channels are problematic on their own and, if changed, could prevent the channel from getting caught up in a futurelock.&lt;/p&gt;
    &lt;p&gt;In Omicron, we commonly use bounded channels with &lt;code&gt;send(msg).await&lt;/code&gt;.  The bound is intended to cap memory usage and provide backpressure, but using the blocking &lt;code&gt;send&lt;/code&gt; creates a second unbounded queue: the wait queue for the channel.  Instead, we could consider using a larger capacity channel plus &lt;code&gt;try_send()&lt;/code&gt; and propagate failure from &lt;code&gt;try_send()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;As an example, when we use the actor pattern, we typically observe that there’s only one actor and potentially many clients, so there’s not much point in buffering messages in the channel. So we use &lt;code&gt;capacity = 1&lt;/code&gt; and let clients block in &lt;code&gt;send().await&lt;/code&gt;.  But we could instead have &lt;code&gt;capacity = 16&lt;/code&gt; and have clients use &lt;code&gt;try_send()&lt;/code&gt; and propagate failure if they’re unable to send the message.  The value &lt;code&gt;16&lt;/code&gt; here is pretty arbitrary.  You want it to be large enough to account for an expected amount of client concurrency, but not larger.  If the value is too small, you’ll wind up with spurious failures when the client could have just waited a bit longer.  If the value is too large, you can wind up queueing so much work that the actor is always behind (and clients are potentially even timing out at a higher level).  One might observe:&lt;/p&gt;
    &lt;p&gt;Channel limits, channel limits: always wrong!&lt;/p&gt;
    &lt;p&gt;Some too short and some too long!&lt;/p&gt;
    &lt;p&gt;But as with timeouts, it’s often possible to find values that work in practice.&lt;/p&gt;
    &lt;p&gt;Using &lt;code&gt;send_timeout()&lt;/code&gt; is not a mitigation because this still results in the sender blocking.  It needs to be polled after the timeout expires in order to give up.  But with futurelock, it will never be polled.&lt;/p&gt;
    &lt;head rend="h3"&gt;Anti-pattern: just make the channel bigger&lt;/head&gt;
    &lt;p&gt;In our initial encounter with this problem, we had a bounded &lt;code&gt;tokio::sync::mpsc&lt;/code&gt; channel of capacity 1.  Why not bump the capacity up?&lt;/p&gt;
    &lt;p&gt;To avoid futurelock, the channel would have to have capacity big enough that nobody in the call stack could possibly have that many futures that they’ve started and aren’t polling. There is of course no way to know how big this needs to be, and it could change over time as the program evolves. Further, there are big side effects to having big channels like this in terms of latency, backpressure, and memory usage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Anti-pattern: try to avoid dependencies between futures&lt;/head&gt;
    &lt;p&gt;In principle, you could avoid this problem if you avoid dependencies between futures. Aside from using &lt;code&gt;spawn&lt;/code&gt; to do this, we do not recommend this in general because it’s brittle and risky.&lt;/p&gt;
    &lt;p&gt;First, it’s hard to know there are no dependencies. Any shared resource can be such a dependency: a bounded channel of any kind, a Mutex, a request to a remote service, etc. And it can be anywhere in the stack, including several dependency packages down the call chain.&lt;/p&gt;
    &lt;p&gt;Even if there’s no such dependency now, one could be added later. You could imagine &lt;code&gt;future1&lt;/code&gt; calling &lt;code&gt;some_crate::func1()&lt;/code&gt; and &lt;code&gt;future2&lt;/code&gt; calling &lt;code&gt;other_crate::func2()&lt;/code&gt; that seem like simple functions.  &lt;code&gt;some_crate&lt;/code&gt; could decide to add a global Mutex that is otherwise safe and correct, but this would now break your &lt;code&gt;tokio::select!&lt;/code&gt; that was previously assuming these futures shared no dependencies.&lt;/p&gt;
    &lt;p&gt;The exception to this is that using &lt;code&gt;tokio::spawn&lt;/code&gt; is a good way to replace one or more futures that could be subject to futurelock with ones that can’t.  The returned &lt;code&gt;JoinHandle&lt;/code&gt; is a future that becomes ready under the same conditions as the underlying one, but it does not hold shared resources and it’s very unlikely that that would ever change as tokio evolves.  (Such a change would almost certainly break lots of correctly-written programs.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Questions&lt;/head&gt;
    &lt;p&gt;Can we write clippy lints to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Warn when passing&lt;/p&gt;&lt;code&gt;&amp;amp;mut future&lt;/code&gt;to a&lt;code&gt;tokio::select!&lt;/code&gt;arm and suggest that&lt;code&gt;tokio::spawn&lt;/code&gt;be used instead, and&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Warn when using&lt;/p&gt;&lt;code&gt;await&lt;/code&gt;in a&lt;code&gt;tokio::select!&lt;/code&gt;arm? (This is problematic for other reasons anyway when&lt;code&gt;select!&lt;/code&gt;is used in a loop.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are certainly cases to do this and it’s okay to override the warning, but it’d be nice to have that guard rail.&lt;/p&gt;
    &lt;head rend="h2"&gt;Security Considerations&lt;/head&gt;
    &lt;p&gt;None actionable. Futurelock is a potential vector for denial of service, but it’s bad anyway, and we know we want to avoid it.&lt;/p&gt;
    &lt;head rend="h2"&gt;External References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;[rfd397] Oxide Computer Co. RFD 397 Challenges with async/await in the control plane. 2023.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;[rfd400] Oxide Computer Co. RFD 400 Dealing with cancel safety in async Rust&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45774086</guid><pubDate>Fri, 31 Oct 2025 16:49:26 +0000</pubDate></item><item><title>Just use a button</title><link>https://gomakethings.com/just-use-a-button/</link><description>&lt;doc fingerprint="880ffd7d68b1a85d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Just use a button&lt;/head&gt;
    &lt;p&gt;One of the weirdest “debates” I seem to perpetually have with framework-enthusiastic developers is whether or not a &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; is “just as good” as a &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Spoiler: it’s not. Let’s dig in.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problem&lt;/head&gt;
    &lt;p&gt;Among the React crowd, and also among people who seem to enjoy HTMX, I see a lot this…&lt;/p&gt;
    &lt;code&gt;&amp;lt;div onclick="showSignIn()"&amp;gt;
	Open Modal
&amp;lt;/div&amp;gt;&lt;/code&gt;
    &lt;code&gt;function showSignIn () {
	// Code to show the sign-in modal.
	// The details of what happens here vary by stack.
}
&lt;/code&gt;
    &lt;p&gt;What’s wrong with this?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;This element does not announce itself as an interactive element to screen reader users.&lt;/item&gt;
      &lt;item&gt;You can’t focus on a &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;with a keyboard.&lt;/item&gt;
      &lt;item&gt;The event only fires on &lt;code&gt;click&lt;/code&gt;, not when the&lt;code&gt;Enter&lt;/code&gt;or&lt;code&gt;Space Bar&lt;/code&gt;keys are pressed (again, keyboard users).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’ve seen this in a lot of code bases. I’ve seen it in a lot of demos.&lt;/p&gt;
    &lt;p&gt;I’ve had arguments with a very prominent React thought leader whose name starts with R who insisted that using a &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; was “more accessible” than using a &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt;, and that Twitter made the right decision in using this pattern in their app.&lt;/p&gt;
    &lt;p&gt;It’s wrong. It’s all wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;The “fixes” aren’t&lt;/head&gt;
    &lt;p&gt;Many HTML elements have implicit roles that tell assistive tech like screen readers what they do.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt; element is one of them. It has an implicit &lt;code&gt;[role]&lt;/code&gt; of &lt;code&gt;button&lt;/code&gt;, which tells screen reader users it can be interacted with and will trigger some type of behavior in the app.&lt;/p&gt;
    &lt;p&gt;The HTML &lt;code&gt;[role]&lt;/code&gt; attribute can be used to add or modify the role of an element. And so, folks like React Ry–thought-leader-guy will say stuff like (I’m paraphrasing)…&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;That attribute exists for a reason. You can add&lt;/p&gt;&lt;code&gt;[role="button"]&lt;/code&gt;to a&lt;code&gt;div&lt;/code&gt;to give it the correct semantics.&lt;/quote&gt;
    &lt;p&gt;OK, that addresses one issue.&lt;/p&gt;
    &lt;p&gt;That role doesn’t affect focusability (or lack thereof) or keyboard behavior. Visually impaired users and people who navigate with a keyboard still can’t use it.&lt;/p&gt;
    &lt;p&gt;“No worries!” they say. “We can fix that, too!”&lt;/p&gt;
    &lt;p&gt;You can make the element focusable with the &lt;code&gt;[tabindex]&lt;/code&gt; attribute.&lt;/p&gt;
    &lt;code&gt;&amp;lt;div 
	onclick="showSignIn()"
	tabindex="0"
&amp;gt;
	Open Modal
&amp;lt;/div&amp;gt;&lt;/code&gt;
    &lt;p&gt;You shouldn’t, though! Seriously, just don’t fuck with focus order.&lt;/p&gt;
    &lt;p&gt;It’s way too easy to go down this path and then fuck it up and have folks jumping all over the page instead of navigating through in the normal and expected order.&lt;/p&gt;
    &lt;p&gt;And again, still no keyboard interactivity.&lt;/p&gt;
    &lt;p&gt;But don’t fear! You can add that, too. You just need to listen for all &lt;code&gt;keydown&lt;/code&gt; events, and then filter them out by &lt;code&gt;event.key&lt;/code&gt; so that you only run your code if the &lt;code&gt;Enter&lt;/code&gt; or &lt;code&gt;Spacebar&lt;/code&gt; keys were pressed (the latter means checking for a literal space: &lt;code&gt;' '&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;That can’t run on the element, either. You’ve got to attach that even to the &lt;code&gt;document&lt;/code&gt; and figure out which element has focus.&lt;/p&gt;
    &lt;code&gt;document.addEventListener('keydown', (event) =&amp;gt; {

	// Only run on Enter and Spacebar presses
	if (event.key !== 'Enter' &amp;amp; event.key !== ' ') return;

	// Make sure the element you care about how focus
	const notRealBtn = document.activeElement.closest('[onclick]');
	if (!notRealBtn) return;

	// Run your code, somehow...

});
&lt;/code&gt;
    &lt;p&gt;So um… ok, I guess it is technically a fix, but…&lt;/p&gt;
    &lt;head rend="h2"&gt;You’ve just recreated all of the functionality a &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt; gives you for free&lt;/head&gt;
    &lt;p&gt;Seriously, WTF would you do that?!?&lt;/p&gt;
    &lt;p&gt;All of these hoops to write this HTML…&lt;/p&gt;
    &lt;code&gt;&amp;lt;div 
	onclick="showSignIn()"
	tabindex="0"
&amp;gt;
	Open Modal
&amp;lt;/div&amp;gt;&lt;/code&gt;
    &lt;p&gt;When you could write this HTML instead…&lt;/p&gt;
    &lt;code&gt;&amp;lt;button onclick="showSignIn()"&amp;gt;
	Open Modal
&amp;lt;/button&amp;gt;&lt;/code&gt;
    &lt;p&gt;A &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt;…&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Has the correct &lt;code&gt;[role]&lt;/code&gt;implicitly.&lt;/item&gt;
      &lt;item&gt;Is automatically focusable.&lt;/item&gt;
      &lt;item&gt;Fires a &lt;code&gt;click&lt;/code&gt;event in response to&lt;code&gt;Enter&lt;/code&gt;and&lt;code&gt;Spacebar&lt;/code&gt;presses when it has focus.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Look, I’m a lazy developer.&lt;/p&gt;
    &lt;p&gt;And I suspect, if you’re someone who loves tools like React, you probably are, too. It’s cool, I get it! The best code is the code you didn’t write and all that.&lt;/p&gt;
    &lt;p&gt;So, be even lazier.&lt;/p&gt;
    &lt;p&gt;Use the correct element for the job, and avoid writing a bunch of extra code!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45774182</guid><pubDate>Fri, 31 Oct 2025 16:59:22 +0000</pubDate></item><item><title>Pangolin (YC S25) Is Hiring a Full Stack Software Engineer (Open-Source)</title><link>https://docs.pangolin.net/careers/software-engineer-full-stack</link><description>&lt;doc fingerprint="ab68f42a572166ea"&gt;
  &lt;main&gt;&lt;list rend="ul"&gt;&lt;item&gt;Location: &lt;code&gt;San Francisco&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Salary: &lt;code&gt;$125k - $160k + 0.5% - 1.5% equity&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Years of experience: &lt;code&gt;3+&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Skills: &lt;code&gt;TypeScript, Go, SQL (PostgreSQL, SQLite), NextJS, AWS&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;About Pangolin&lt;/head&gt;Pangolin delivers identity-aware remote access to internal apps and services, starting with secure reverse tunneling, and is evolving toward broader zero‑trust networking. We build in the open and are self‑hosted by default so teams retain control over data and infrastructure. The system is policy‑driven, integrates with standard IdPs, exposes clear observability and health, and provides an API for automation. If you’re interested in open-source auth and networking infrastructure, we’d love to chat.&lt;head rend="h2"&gt;About The Role&lt;/head&gt;As a Full Stack Software Engineer at Pangolin, you’ll help architect, build, and maintain the core of the Pangolin system. You’ll work primarily on the Pangolin container, the central server with the UI, APIs, schemas, and more. As an early hire, you’ll play a foundational role in shaping how Pangolin is built as both a product and a company.&lt;head rend="h2"&gt;What You’ll Do&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Design, develop, and test the core of our self-hosted platform &lt;list rend="ul"&gt;&lt;item&gt;Frontend (NextJS, Tailwind, ShadCN)&lt;/item&gt;&lt;item&gt;Backend (Express APIs, SQL, Drizzle ORM)&lt;/item&gt;&lt;item&gt;Processes (CICD, Internal Tooling)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Troubleshooting and resolving complex issues related to distributed systems, networking, and security.&lt;/item&gt;&lt;item&gt;Actively engaging with the open-source community, providing support, and driving engagement on platforms like GitHub and Discord&lt;/item&gt;&lt;item&gt;Ship quickly and get instant feedback from our large open-source user-base&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;What We’re Looking For&lt;/head&gt;&lt;head rend="h3"&gt;High Level&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Must be a current or recent graduate with more than 3 years of work experience in computer science&lt;/item&gt;&lt;item&gt;Must be San Francisco based or able to move to San Francisco (with relocation assistance)&lt;/item&gt;&lt;item&gt;Must be comfortable with and excited by early stage startup culture and figuring things out as we go&lt;/item&gt;&lt;item&gt;Must have your own ideas and be willing to communicate them&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Other Technical Qualifcations&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Extensive TypeScript experience and can write a little Go&lt;/item&gt;&lt;item&gt;Familiarity with web identity and authentication standards: OAuth2, OIDC, SSO&lt;/item&gt;&lt;item&gt;Experience with cloud infrastructure and operational technologies (Docker, Kubernetes, Linux, AWS)&lt;/item&gt;&lt;item&gt;Basic knowledge of networking concepts: tunneling, WireGuard, proxies, SSL/TLS&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;What You Can Expect&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Competitive salary&lt;/item&gt;&lt;item&gt;Hybrid (in-person + work-from-home)&lt;/item&gt;&lt;item&gt;Quiet work environment&lt;/item&gt;&lt;item&gt;Small, trusting team of founders and engineers&lt;/item&gt;&lt;item&gt;Relocation assistance&lt;/item&gt;&lt;item&gt;Unlimited PTO&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Process&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;We will review your provided materials&lt;/item&gt;&lt;item&gt;Complete a quick “get to know you interview” with founders&lt;/item&gt;&lt;item&gt;A short, scoped, paid OSS project contribution&lt;/item&gt;&lt;item&gt;Onboard!&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;How to Apply&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;Add Owen on LinkedIn.&lt;/item&gt;&lt;item&gt;Send your resume/CV&lt;/item&gt;&lt;item&gt;Send your GitHub profile and highlight any past projects&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45774198</guid><pubDate>Fri, 31 Oct 2025 17:00:37 +0000</pubDate></item><item><title>Use DuckDB-WASM to query TB of data in browser</title><link>https://lil.law.harvard.edu/blog/2025/10/24/rethinking-data-discovery-for-libraries-and-digital-humanities/</link><description>&lt;doc fingerprint="8b33bb57b32f478c"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Authors:&lt;/head&gt;
    &lt;p&gt;Published:&lt;/p&gt;
    &lt;p&gt;As part of our Public Data Project, LIL recently launched Data.gov Archive Search. In this post, we look under the hood and reflect on how and why we built this project the way we did.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rethinking the Old Trade-Off: Cost, Complexity, and Access&lt;/head&gt;
    &lt;p&gt;Libraries, digital humanities projects, and cultural heritage organizations have long had to perform a balancing act when sharing their collections online, negotiating between access and affordability. Providing robust features for data discovery, such as browsing, filtering, and search, has traditionally required dedicated computing infrastructure such as servers and databases. Ongoing server hosting, regular security and software updates, and consistent operational oversight are expensive and require skilled staff. Over years or decades, budget changes and staff turnover often strand these projects in an unmaintained or nonfunctioning state.&lt;/p&gt;
    &lt;p&gt;The alternative, static file hosting, requires minimal maintenance and reduces expenses dramatically. For example, storing gigabytes of data on Amazon S3 may cost $1/month or less. However, static hosting often diminishes the capacity for rich data discovery. Without a dynamic computing layer between the userâs web browser and the source files, data access may be restricted to brittle pre-rendered browsing hierarchies or search functionality that is impeded by client memory limits. Under such barriers, the collectionâs discoverability suffers.&lt;/p&gt;
    &lt;p&gt;For years, online collection discovery has been stuck between a rock and a hard place: accept the complexity and expense required for a good user experience, or opt for simplicity and leave users to contend with the blunt limitations of a static discovery layer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why We Explored a New Approach&lt;/head&gt;
    &lt;p&gt;When LIL began thinking about how to provide discovery for the Data.gov Archive, we decided that building a lightweight and easily maintained access point from the beginning would be worth our teamâs effort. We wanted to provide low-effort discovery with minimal impact on our resources. We also wanted to ensure that whatever path we chose would encourage, rather than impede, long-term access.&lt;/p&gt;
    &lt;p&gt;This approach builds on our recent experience when the Caselaw Access Project (CAP) hit a transition moment. At that time, we elected to switch case.law to a static site and to partner with others dedicated to open legal data to provide more feature-rich access.&lt;/p&gt;
    &lt;p&gt;CAP includes some 11 TB of data; the Data.gov Archive represents nearly 18 TB, with the catalog metadata alone accounting for about 1 GB. Manually browsing the archive data in its repository, even for a user who knows what sheâs looking for, is laborious and time-consuming. Thus we faced a challenge. Could we enable dynamic, scalable discovery of the Data.gov Archive while enjoying the frugality, simplicity, and maintainability of static hosting?&lt;/p&gt;
    &lt;head rend="h2"&gt;Our Experiment: Rich Discovery, No Server Required&lt;/head&gt;
    &lt;p&gt;Recent advancements in client-side data analysis led us to try something new. Tools like DuckDB-Wasm, sql.js-httpvfs, and Protomaps, powered by standards such as WebAssembly, web workers, and HTTP range requests, allow users to efficiently query large remote datasets in the browser. Rather than downloading a 2 GB data file into memory, these tools can incrementally retrieve only the relevant parts of the file and process query results locally.&lt;/p&gt;
    &lt;p&gt;We developed Data.gov Archive Search on the same model. Hereâs how it works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Data storage: We store Data.gov Archive catalog metadata as sorted, compressed Parquet files on Source.coop, taking advantage of performant static file hosting.&lt;/item&gt;
      &lt;item&gt;In-browser query engine: Our client-side web application loads DuckDB-Wasm, a fully functional database engine running inside the userâs browser.&lt;/item&gt;
      &lt;item&gt;On-demand data access: When a user navigates to a resource or submits a search, our DuckDB-Wasm client executes a targeted retrieval of the data needed to fulfill the request. No dedicated server is required; queries run entirely in the browser.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This experiment has not been without obstacles. Getting good performance out of this model demands careful data engineering, and the large DuckDB-Wasm binary imposes a considerable latency cost. As of this writing, weâre continuing to explore speedy alternatives like hyparquet and Arquero to further improve performance.&lt;/p&gt;
    &lt;p&gt;Still, weâre pleased with the result: an inexpensive, low-maintenance static discovery platform that allows users to browse, search, and filter Data.gov Archive records entirely in the browser.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why This Matters for Libraries, Digital Humanities Projects, and Beyond&lt;/head&gt;
    &lt;p&gt;This new pattern offers a compelling model for libraries, academic archives, and DH projects of all sizes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lower operating costs: By shifting from an expensive server to lower cost static storage, projects can sustainably offer their users access to data.&lt;/item&gt;
      &lt;item&gt;Reduced technical overhead: With no dedicated backend server, security risks are reduced, no patching or upgrades are needed, and crashing servers are not a concern.&lt;/item&gt;
      &lt;item&gt;Sustained access: Projects can be set up with care, but without demanding constant attention. Organizations can be more confident that their archive and discovery interfaces remain usable and accessible, even as staffing or funding changes over time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Knowing that we are not the only group interested in approaching access in this way, weâre sharing our generalized learnings. We see a few ways forward for others in the knowledge and information world:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prototype or pilot: If your organization has large, relatively static datasets, consider experimenting with a browser-based search tool using static hosting.&lt;/item&gt;
      &lt;item&gt;Share and collaborate: Template applications, workflows, and lessons learned can help this new pattern gain adoption and maturity across the community.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is still evolving, and we invite othersâparticularly those in libraries and digital cultural heritageâto explore these possibilities with us. Weâre committed to open sharing as we refine our tools, and we welcome collaboration or feedback at lil@law.harvard.edu.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45774571</guid><pubDate>Fri, 31 Oct 2025 17:37:15 +0000</pubDate></item><item><title>Addiction Markets</title><link>https://www.thebignewsletter.com/p/addiction-markets-abolish-corporate</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45774640</guid><pubDate>Fri, 31 Oct 2025 17:42:55 +0000</pubDate></item><item><title>x86 architecture 1 byte opcodes</title><link>https://www.sandpile.org/x86/opc_1.htm</link><description>&lt;doc fingerprint="1a52fcf24fe8cd04"&gt;
  &lt;main&gt;
    &lt;row&gt;
      &lt;cell width="935"&gt; x86 architecture&lt;lb/&gt;1 byte opcodes&lt;table&gt;&lt;row align="center"&gt;&lt;cell align="center" width="75" bgcolor="#004080"&gt;xxh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;&lt;lb/&gt;x0h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x1h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x2h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x3h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x4h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x5h&lt;/cell&gt;&lt;cell align="center" colspan="2" bgcolor="#004080"&gt;x6h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x7h&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;0xh&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;ADD&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;ADD&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;ADD&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;ADD&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;ADD&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;ADD&lt;lb/&gt;rAX,Iz&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0" colspan="2"&gt;PUSHI64&lt;lb/&gt;ES&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;POPI64&lt;lb/&gt;ES&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;1xh&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;ADC&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;ADC&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;ADC&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;ADC&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;ADC&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;ADC&lt;lb/&gt;rAX,Iz&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0" colspan="2"&gt;PUSHI64&lt;lb/&gt;SS&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;POPI64&lt;lb/&gt;SS&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;2xh&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;AND&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;AND&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;AND&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;AND&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;AND&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;AND&lt;lb/&gt;rAx,Iz&lt;/cell&gt;&lt;cell colspan="2"&gt;ES:&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DAAI64&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;3xh&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;XOR&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;XOR&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;XOR&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;XOR&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;XOR&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;XOR&lt;lb/&gt;rAX,Iz&lt;/cell&gt;&lt;cell colspan="2"&gt;SS:&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;AAAI64&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" rowspan="2" bgcolor="#004080"&gt;&lt;lb/&gt;4xh&lt;lb/&gt; !REX2 &lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;INCI64 eAX &lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;INCI64 eCX&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;INCI64 eDX&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;INCI64 eBX&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;INCI64 eSP&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;INCI64 eBP&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0" colspan="2"&gt;INCI64 eSI&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;INCI64 eDI&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell colspan="9" bgcolor="#B0D0D0"&gt;REX&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;5xh&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;rAX / r8 / r16 / r24&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;rCX / r9 / r17 / r25&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;rDX / r10 / r18 / r26&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;rBX / r11 / r19 / r27&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;rSP / r12 / r20 / r28&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;rBP / r13 / r21 / r29&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0" colspan="2"&gt;PUSHD64&lt;lb/&gt;rSI / r14 / r22 / r30&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;rDI / r15 / r23 / r31&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell colspan="9" bgcolor="#B0D0F0"&gt;REX2.W1 PUSHPF64 Rq&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;6xh&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0C0C0"&gt;PUSHAI64&lt;lb/&gt;PUSHADI64&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0C0C0"&gt;POPAI64&lt;lb/&gt;POPADI64&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;BOUNDI64 Gv,Ma&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;ARPLI64 Ew,Gw&lt;lb/&gt;(80286+)&lt;/cell&gt;&lt;cell rowspan="2"&gt;FS:&lt;lb/&gt;(80386+)&lt;lb/&gt;Hint Alt Taken&lt;lb/&gt;for Jcc (P4)&lt;/cell&gt;&lt;cell rowspan="2"&gt;GS:&lt;lb/&gt;(80386+)&lt;/cell&gt;&lt;cell rowspan="2" colspan="2"&gt;OPSIZE:&lt;lb/&gt;(80386+)&lt;/cell&gt;&lt;cell rowspan="2"&gt;ADSIZE:&lt;lb/&gt;(80386+)&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;L1OM MVEX EVEX&lt;/cell&gt;&lt;cell bgcolor="#B0D0D0"&gt;MOVSXD Gv,Ed&lt;lb/&gt;(PM64)&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;7xh&lt;lb/&gt; !REX2 &lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0E0C0"&gt;JODf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0E0C0"&gt;JNODf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0E0C0"&gt;JBDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0E0C0"&gt;JNBDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JZDf64 Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JNZDf64 Jb&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0E0C0" colspan="2"&gt;JBEDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0E0C0"&gt;JNBEDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell bgcolor="#E0E0C0"&gt;JKZDv64 vKw,Jbv&lt;lb/&gt;(K1OM)&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JKNZDv64 vKw,Jbv&lt;lb/&gt;(K1OM)&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;8xh&lt;/cell&gt;&lt;cell align="center" bgcolor="#B0D0F0"&gt;group #1&lt;lb/&gt;Eb,Ib&lt;/cell&gt;&lt;cell align="center" bgcolor="#B0D0F0"&gt;group #1&lt;lb/&gt;Ev,Iz&lt;/cell&gt;&lt;cell align="center" bgcolor="#E0C0C0"&gt;group #1*I64&lt;lb/&gt;Eb,Ib&lt;/cell&gt;&lt;cell align="center" bgcolor="#B0D0F0"&gt;group #1&lt;lb/&gt;Ev,Ib&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;TEST&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;TEST&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell colspan="2"&gt;XCHG&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell&gt;XCHG&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" rowspan="2" bgcolor="#004080"&gt;&lt;lb/&gt;9xh&lt;/cell&gt;&lt;cell bgcolor="E0E0C0"&gt;(F3h) PAUSE&lt;lb/&gt;XCHG rAX,rAX&lt;/cell&gt;&lt;cell rowspan="2"&gt;&lt;lb/&gt;XCHG rCX,rAX &lt;lb/&gt;XCHG r9,rAX &lt;lb/&gt;XCHG r17,rAX&lt;lb/&gt;XCHG r25,rAX&lt;/cell&gt;&lt;cell rowspan="2"&gt;&lt;lb/&gt;XCHG rDX,rAX &lt;lb/&gt;XCHG r10,rAX &lt;lb/&gt;XCHG r18,rAX&lt;lb/&gt;XCHG r26,rAX&lt;/cell&gt;&lt;cell rowspan="2"&gt;&lt;lb/&gt;XCHG rBX,rAX &lt;lb/&gt;XCHG r11,rAX &lt;lb/&gt;XCHG r19,rAX&lt;lb/&gt;XCHG r27,rAX&lt;/cell&gt;&lt;cell rowspan="2"&gt;&lt;lb/&gt;XCHG rSP,rAX &lt;lb/&gt;XCHG r12,rAX &lt;lb/&gt;XCHG r20,rAX&lt;lb/&gt;XCHG r28,rAX&lt;/cell&gt;&lt;cell rowspan="2"&gt;&lt;lb/&gt;XCHG rBP,rAX &lt;lb/&gt;XCHG r13,rAX &lt;lb/&gt;XCHG r21,rAX&lt;lb/&gt;XCHG r29,rAX&lt;/cell&gt;&lt;cell rowspan="2" colspan="2"&gt;&lt;lb/&gt;XCHG rSI,rAX &lt;lb/&gt;XCHG r14,rAX &lt;lb/&gt;XCHG r22,rAX&lt;lb/&gt;XCHG r30,rAX&lt;/cell&gt;&lt;cell rowspan="2"&gt;&lt;lb/&gt;XCHG rDI,rAX &lt;lb/&gt;XCHG r15,rAX &lt;lb/&gt;XCHG r23,rAX&lt;lb/&gt;XCHG r31,rAX&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;XCHG r8,rAX&lt;lb/&gt;XCHG r16,rAX&lt;lb/&gt;XCHG r24,rAX&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Axh&lt;lb/&gt; !REX2 &lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV&lt;lb/&gt;AL,Ob&lt;/cell&gt;&lt;cell&gt;MOV&lt;lb/&gt;rAX,Ov&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV&lt;lb/&gt;Ob,AL&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV&lt;lb/&gt;Ov,rAX&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOVS&lt;lb/&gt;Yb,Xb&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOVS&lt;lb/&gt;Yv,Xv&lt;/cell&gt;&lt;cell rowspan="2" colspan="2"&gt;CMPS&lt;lb/&gt;Yb,Xb&lt;/cell&gt;&lt;cell rowspan="2"&gt;CMPS&lt;lb/&gt;Yv,Xv&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell bgcolor="#B0D0F0"&gt;REX2.W0&lt;lb/&gt;JMPABS Aq&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Bxh&lt;/cell&gt;&lt;cell&gt;(!REX) MOV AL,Ib&lt;lb/&gt; (REX) MOV AL,Ib&lt;lb/&gt;MOV R8B,Ib&lt;lb/&gt;MOV R16B,Ib&lt;lb/&gt;MOV R24B,Ib&lt;/cell&gt;&lt;cell&gt;(!REX) MOV CL,Ib&lt;lb/&gt; (REX) MOV CL,Ib&lt;lb/&gt;MOV R9B,Ib&lt;lb/&gt;MOV R17B,Ib&lt;lb/&gt;MOV R25B,Ib&lt;/cell&gt;&lt;cell&gt;(!REX) MOV DL,Ib&lt;lb/&gt; (REX) MOV DL,Ib&lt;lb/&gt;MOV R10B,Ib&lt;lb/&gt;MOV R18B,Ib&lt;lb/&gt;MOV R26B,Ib&lt;/cell&gt;&lt;cell&gt;(!REX) MOV BL,Ib&lt;lb/&gt; (REX) MOV BL,Ib&lt;lb/&gt;MOV R11B,Ib&lt;lb/&gt;MOV R19B,Ib&lt;lb/&gt;MOV R27B,Ib&lt;/cell&gt;&lt;cell&gt;(!REX) MOV AH,Ib&lt;lb/&gt;(REX) MOV SPL,Ib&lt;lb/&gt;MOV R12B,Ib&lt;lb/&gt;MOV R20B,Ib&lt;lb/&gt;MOV R28B,Ib&lt;/cell&gt;&lt;cell&gt;(!REX) MOV CH,Ib&lt;lb/&gt;(REX) MOV BPL,Ib&lt;lb/&gt;MOV R13B,Ib&lt;lb/&gt;MOV R21B,Ib&lt;lb/&gt;MOV R29B,Ib&lt;/cell&gt;&lt;cell colspan="2"&gt;(!REX) MOV DH,Ib&lt;lb/&gt;(REX) MOV SIL,Ib&lt;lb/&gt;MOV R14B,Ib&lt;lb/&gt;MOV R22B,Ib&lt;lb/&gt;MOV R30B,Ib&lt;/cell&gt;&lt;cell&gt;(!REX) MOV BH,Ib&lt;lb/&gt;(REX) MOV DIL,Ib&lt;lb/&gt;MOV R15B,Ib&lt;lb/&gt;MOV R23B,Ib&lt;lb/&gt;MOV R31B,Ib&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Cxh&lt;/cell&gt;&lt;cell rowspan="2" align="center" bgcolor="#B0D0F0"&gt;group #2&lt;lb/&gt;Eb,Ib&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell rowspan="2" align="center" bgcolor="#B0D0F0"&gt;group #2&lt;lb/&gt;Ev,Ib&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0E0C0"&gt;RET nearDf64&lt;lb/&gt;Iw&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#E0E0C0"&gt;RET nearDf64&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;LESI64 Gv,Mp (w:v)&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;LDSI64 Gv,Mp (w:v)&lt;/cell&gt;&lt;cell rowspan="2" align="center" colspan="2"&gt;group #11&lt;lb/&gt;Eb,Ib&lt;/cell&gt;&lt;cell rowspan="2" align="center"&gt;group #11&lt;lb/&gt;Ev,Iz&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell&gt;VEX3&lt;/cell&gt;&lt;cell&gt;VEX2&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Dxh&lt;/cell&gt;&lt;cell rowspan="2" align="center" bgcolor="#B0D0F0"&gt;group #2&lt;lb/&gt;Eb,1&lt;/cell&gt;&lt;cell rowspan="2" align="center" bgcolor="#B0D0F0"&gt;group #2&lt;lb/&gt;Ev,1&lt;/cell&gt;&lt;cell rowspan="2" align="center" bgcolor="#B0D0F0"&gt;group #2&lt;lb/&gt;Eb,CL&lt;/cell&gt;&lt;cell rowspan="2" align="center" bgcolor="#B0D0F0"&gt;group #2&lt;lb/&gt;Ev,CL&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt; AAMI64 Ib&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt; AADI64 Ib&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0" colspan="2"&gt; S(ET)ALCI64&lt;/cell&gt;&lt;cell rowspan="2"&gt;XLAT&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell bgcolor="#808080"&gt;reserved&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;REX2&lt;/cell&gt;&lt;cell width="47"&gt;L1OM&lt;/cell&gt;&lt;cell width="47" bgcolor="#B0D0D0"&gt;UDB&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Exh&lt;lb/&gt; !REX2 &lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;LOOPNEDf64&lt;lb/&gt;LOOPNZDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;LOOPEDf64&lt;lb/&gt;LOOPZDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;&lt;lb/&gt;LOOPDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JCXZDf64&lt;lb/&gt;JECXDf64&lt;lb/&gt;JRCXDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;IN&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;IN&lt;lb/&gt;eAX,Ib&lt;/cell&gt;&lt;cell colspan="2"&gt;OUT&lt;lb/&gt;Ib,AL&lt;/cell&gt;&lt;cell&gt;OUT&lt;lb/&gt;Ib,eAX&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Fxh&lt;/cell&gt;&lt;cell&gt;LOCK:&lt;/cell&gt;&lt;cell&gt;#UD (80186/80188)&lt;lb/&gt;UMPF: (80286)&lt;lb/&gt;INT1 aka ICEBP&lt;lb/&gt;(80386+)&lt;/cell&gt;&lt;cell&gt;&lt;lb/&gt;REPNE:&lt;lb/&gt;BND: (MPX)&lt;lb/&gt;XACQUIRE: (HLE)&lt;/cell&gt;&lt;cell&gt;REP:&lt;lb/&gt;REPE:&lt;lb/&gt;XRELEASE: (HLE)&lt;/cell&gt;&lt;cell&gt;HLT&lt;/cell&gt;&lt;cell&gt;CMC&lt;/cell&gt;&lt;cell align="center" bgcolor="#B0D0F0" colspan="2"&gt;group #3&lt;lb/&gt;Eb&lt;/cell&gt;&lt;cell align="center" bgcolor="#B0D0F0"&gt;group #3&lt;lb/&gt;Ev&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" rowspan="4" bgcolor="#004080"&gt;notes&lt;lb/&gt;on 90h&lt;/cell&gt;&lt;cell align="left" colspan="2"&gt;XCHG AX, AX – classic 16-bit NOP (8086)&lt;/cell&gt;&lt;cell colspan="2" rowspan="2"&gt;If CPUID does indicate support, then a REP prefix will apply PAUSE semantics to a NOP.&lt;/cell&gt;&lt;cell colspan="5" rowspan="4" bgcolor="#B0B0B0"&gt; The blame for that "special treatment" of PM64 O32 NOP – effectively D64 – falls on me.&lt;lb/&gt; I did spot that zeroing the upper 32 bits of RAX leads to undesired non-NOP behavior, but&lt;lb/&gt; failed to convince our team in 2001 to use one of the freed up 1-byte opcodes (a la UDB). &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="left" colspan="2"&gt;XCHG eAX,eAX – wider 32-bit NOP (80386)&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="left" colspan="2" bgcolor="#B0D0D0"&gt;XCHG rAX, rAX – wider 64-bit NOP (x86-64)&lt;/cell&gt;&lt;cell colspan="2" rowspan="2" bgcolor="E0E0C0"&gt;In PM64 with O32, XCHG EAX,EAX must not zero the upper 32 bits of RAX. Thus it is D64. &lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="left" bgcolor="#008080"&gt;XCHG rN, rAX (N=8&lt;/cell&gt;&lt;cell align="left" bgcolor="#0080C0"&gt;,16,24) is not a NOP!&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row align="center"&gt;&lt;cell align="center" width="75" bgcolor="#004080"&gt;xxh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;&lt;lb/&gt;x8h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x9h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xAh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xBh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xCh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xDh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xEh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xFh&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;0xh&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;OR&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;OR&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;OR&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;OR&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;OR&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;OR&lt;lb/&gt;rAX,Iz&lt;/cell&gt;&lt;cell align="center"&gt;POP CS (8086/8088)&lt;lb/&gt;#UD (80186/80188)&lt;lb/&gt;2 byte opcodes&lt;lb/&gt;(80286+)&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;1xh&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;SBB&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;SBB&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;SBB&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;SBB&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;SBB&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;SBB&lt;lb/&gt;rAX,Iz&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;PUSHI64&lt;lb/&gt;DS&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;POPI64&lt;lb/&gt;DS&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;2xh&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;SUB&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;SUB&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;SUB&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;SUB&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;SUB&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;SUB&lt;lb/&gt;rAX,Iz&lt;/cell&gt;&lt;cell&gt;CS:&lt;lb/&gt;&amp;amp;nbsp&lt;lb/&gt;Hint Not Taken&lt;lb/&gt;for Jcc (P4)&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DASI64&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;3xh&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;CMP&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;CMP&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;CMP&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;CMP&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;CMP&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;CMP&lt;lb/&gt;rAX,Iz&lt;/cell&gt;&lt;cell&gt;DS:&lt;lb/&gt;CET: (CET)&lt;lb/&gt;Hint Taken&lt;lb/&gt;for Jcc (P4)&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;AASI64&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" rowspan="2" bgcolor="#004080"&gt;&lt;lb/&gt;4xh&lt;lb/&gt; !REX2 &lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DECI64 eAX &lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DECI64 eCX&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DECI64 eDX&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DECI64 eBX&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DECI64 eSP&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DECI64 eBP&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DECI64 eSI&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;DECI64 eDI&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell colspan="8" bgcolor="#B0D0D0"&gt;REX&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;5xh&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPD64&lt;lb/&gt;rAX / r8 / r16 / r24&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPD64&lt;lb/&gt;rCX / r9 / r17 / r25&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPD64&lt;lb/&gt;rDX / r10 / r18 / r26&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPD64&lt;lb/&gt;rBX / r11 / r19 / r27&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPD64&lt;lb/&gt;rSP / r12 / r20 / r28&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPD64&lt;lb/&gt;rBP / r13 / r21 / r29&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPD64&lt;lb/&gt;rSI / r14 / r22 / r30&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPD64&lt;lb/&gt;rDI / r15 / r23 / r31&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell colspan="8" bgcolor="#B0D0F0"&gt;REX2.W1 POPPF64 Rq&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;6xh&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;Iz&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;IMUL&lt;lb/&gt;Gv,Ev,Iz&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHD64&lt;lb/&gt;Ib&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;IMUL&lt;lb/&gt;Gv,Ev,Ib&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell&gt;INS&lt;lb/&gt;Yb,DX&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell&gt;INS&lt;lb/&gt;Yz,DX&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell&gt;OUTS&lt;lb/&gt;DX,Xb&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell&gt;OUTS&lt;lb/&gt;DX,Xz&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;7xh&lt;lb/&gt; !REX2 &lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JSDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JNSDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JPDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JNPDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JLDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JNLDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JLEDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JNLEDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;8xh&lt;/cell&gt;&lt;cell&gt;MOV&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell&gt;MOV&lt;lb/&gt;Ev,Gv&lt;/cell&gt;&lt;cell&gt;MOV&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell&gt;MOV&lt;lb/&gt;Gv,Ev&lt;/cell&gt;&lt;cell&gt;MOV Mw,Sw&lt;lb/&gt;MOV Rv,Sw&lt;/cell&gt;&lt;cell&gt;LEA Gv,M&lt;/cell&gt;&lt;cell&gt;MOV Sw,Mw&lt;lb/&gt;MOV Sw,Rv&lt;/cell&gt;&lt;cell bgcolor="#B0D0F0"&gt;group #1A&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;9xh&lt;/cell&gt;&lt;cell&gt;CBW (8088)&lt;lb/&gt;CWDE (80386+)&lt;lb/&gt;CDQE (PM64)&lt;/cell&gt;&lt;cell&gt;CWD (8088)&lt;lb/&gt;CDQ (80386+)&lt;lb/&gt;CQO (PM64)&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;CALLI64&lt;lb/&gt;Ap (w:z)&lt;/cell&gt;&lt;cell&gt;WAIT&lt;lb/&gt;FWAIT&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;PUSHFD64&lt;lb/&gt;Fv&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;POPFD64&lt;lb/&gt;Fv&lt;/cell&gt;&lt;cell&gt;SAHF&lt;lb/&gt;(LM: if AHF64)&lt;/cell&gt;&lt;cell&gt;LAHF&lt;lb/&gt;(LM: if AHF64)&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Axh&lt;lb/&gt; !REX2 &lt;/cell&gt;&lt;cell&gt;TEST&lt;lb/&gt;AL,Ib&lt;/cell&gt;&lt;cell&gt;TEST&lt;lb/&gt;rAX,Iz&lt;/cell&gt;&lt;cell&gt;STOS&lt;lb/&gt;Yb,AL&lt;/cell&gt;&lt;cell&gt;STOS&lt;lb/&gt;Yv,rAX&lt;/cell&gt;&lt;cell&gt;LODS&lt;lb/&gt;AL,Xb&lt;/cell&gt;&lt;cell&gt;LODS&lt;lb/&gt;rAX,Xv&lt;/cell&gt;&lt;cell&gt;SCAS&lt;lb/&gt;Yb,AL&lt;/cell&gt;&lt;cell&gt;SCAS&lt;lb/&gt;Yv,rAX&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Bxh&lt;/cell&gt;&lt;cell&gt;MOV rAX,Iv&lt;lb/&gt;MOV r8,Iv&lt;lb/&gt;MOV r16,Iv&lt;lb/&gt;MOV r24,Iv&lt;/cell&gt;&lt;cell&gt;MOV rCX,Iv&lt;lb/&gt;MOV r9,Iv&lt;lb/&gt;MOV r17,Iv&lt;lb/&gt;MOV r25,Iv&lt;/cell&gt;&lt;cell&gt;MOV rDX,Iv&lt;lb/&gt;MOV r10,Iv&lt;lb/&gt;MOV r18,Iv&lt;lb/&gt;MOV r26,Iv&lt;/cell&gt;&lt;cell&gt;MOV rBX,Iv&lt;lb/&gt;MOV r11,Iv&lt;lb/&gt;MOV r19,Iv&lt;lb/&gt;MOV r27,Iv&lt;/cell&gt;&lt;cell&gt;MOV rSP,Iv&lt;lb/&gt;MOV r12,Iv&lt;lb/&gt;MOV r20,Iv&lt;lb/&gt;MOV r28,Iv&lt;/cell&gt;&lt;cell&gt;MOV rBP,Iv&lt;lb/&gt;MOV r13,Iv&lt;lb/&gt;MOV r21,Iv&lt;lb/&gt;MOV r29,Iv&lt;/cell&gt;&lt;cell&gt;MOV rSI,Iv&lt;lb/&gt;MOV r14,Iv&lt;lb/&gt;MOV r22,Iv&lt;lb/&gt;MOV r30,Iv&lt;/cell&gt;&lt;cell&gt;MOV rDI,Iv&lt;lb/&gt;MOV r15,Iv&lt;lb/&gt;MOV r23,Iv&lt;lb/&gt;MOV r31,Iv&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Cxh&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;ENTERD64&lt;lb/&gt;Iw,Ib&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;LEAVED64&lt;lb/&gt;(80186+)&lt;/cell&gt;&lt;cell&gt;RET far&lt;lb/&gt;Iw&lt;/cell&gt;&lt;cell&gt;RET far&lt;/cell&gt;&lt;cell&gt;INT3&lt;/cell&gt;&lt;cell&gt;INT&lt;lb/&gt;Ib&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;INTOI64&lt;/cell&gt;&lt;cell&gt;IRET&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Dxh&lt;/cell&gt;&lt;cell align="center"&gt;ESC&lt;lb/&gt;0&lt;/cell&gt;&lt;cell align="center"&gt;ESC&lt;lb/&gt;1&lt;/cell&gt;&lt;cell align="center"&gt;ESC&lt;lb/&gt;2&lt;/cell&gt;&lt;cell align="center"&gt;ESC&lt;lb/&gt;3&lt;/cell&gt;&lt;cell align="center"&gt;ESC&lt;lb/&gt;4&lt;/cell&gt;&lt;cell align="center"&gt;ESC&lt;lb/&gt;5&lt;/cell&gt;&lt;cell align="center"&gt;ESC&lt;lb/&gt;6&lt;/cell&gt;&lt;cell align="center"&gt;ESC&lt;lb/&gt;7&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Exh&lt;lb/&gt; !REX2 &lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;CALLDf64&lt;lb/&gt;Jz&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JMPDf64&lt;lb/&gt;Jz&lt;/cell&gt;&lt;cell bgcolor="#E0C0C0"&gt;JMPI64&lt;lb/&gt;Ap (w:z)&lt;/cell&gt;&lt;cell bgcolor="#E0E0C0"&gt;JMPDf64&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;IN&lt;lb/&gt;AL,DX&lt;/cell&gt;&lt;cell&gt;IN&lt;lb/&gt;eAX,DX&lt;/cell&gt;&lt;cell&gt;OUT&lt;lb/&gt;DX,AL&lt;/cell&gt;&lt;cell&gt;OUT&lt;lb/&gt;DX,eAX&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Fxh&lt;/cell&gt;&lt;cell&gt;CLC&lt;/cell&gt;&lt;cell&gt;STC&lt;/cell&gt;&lt;cell&gt;&lt;lb/&gt; CLI &lt;lb/&gt;(F0h) CLX (REX32)&lt;/cell&gt;&lt;cell&gt;&lt;lb/&gt; STI &lt;lb/&gt;(F0h) STX (REX32)&lt;/cell&gt;&lt;cell&gt;CLD&lt;/cell&gt;&lt;cell&gt;STD&lt;/cell&gt;&lt;cell align="center" bgcolor="#B0D0F0"&gt;group #4&lt;lb/&gt;INC/DEC&lt;/cell&gt;&lt;cell align="center" bgcolor="#B0D0F0"&gt;group #5&lt;lb/&gt;INC/DEC/etc.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;lb/&gt; On 8086/8088 processors the following behavior was supported instead.&lt;table&gt;&lt;row align="center"&gt;&lt;cell align="center" width="75" bgcolor="#004080"&gt;xxh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;&lt;lb/&gt;x0h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x1h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x2h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x3h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x4h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x5h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x6h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x7h&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;...&lt;/cell&gt;&lt;cell colspan="8"&gt;...&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;6xh&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JO*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JNO*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JB*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JNB*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JZ*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JNZ*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JBE*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JNBE*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;7xh&lt;/cell&gt;&lt;cell&gt;JO&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JNO&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JB&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JNB&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JZ&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JNZ&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JBE&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JNBE&lt;lb/&gt;Jb&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;8xh&lt;/cell&gt;&lt;cell align="center"&gt;group #1&lt;lb/&gt;Eb,Ib&lt;/cell&gt;&lt;cell align="center"&gt;group #1&lt;lb/&gt;Ew,Iw&lt;/cell&gt;&lt;cell align="center"&gt;group #1*&lt;lb/&gt;Eb,Ib&lt;/cell&gt;&lt;cell align="center"&gt;group #1&lt;lb/&gt;Ew,Ib&lt;/cell&gt;&lt;cell&gt;TEST&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell&gt;TEST&lt;lb/&gt;Ew,Gw&lt;/cell&gt;&lt;cell&gt;XCHG&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell&gt;XCHG&lt;lb/&gt;Ew,Gw&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;...&lt;/cell&gt;&lt;cell colspan="8"&gt;...&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Cxh&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#D0F0FF"&gt;RET* near&lt;lb/&gt;Iw&lt;/cell&gt;&lt;cell rowspan="2" bgcolor="#D0F0FF"&gt;RET* near&lt;/cell&gt;&lt;cell rowspan="2"&gt;RET near&lt;lb/&gt;Iw&lt;/cell&gt;&lt;cell rowspan="2"&gt;RET near&lt;/cell&gt;&lt;cell&gt;LES Gw,Mp (w:w)&lt;/cell&gt;&lt;cell&gt;LDS Gw,Mp (w:w)&lt;/cell&gt;&lt;cell rowspan="2"&gt;group #11&lt;lb/&gt;Eb,Ib&lt;/cell&gt;&lt;cell rowspan="2"&gt;group #11&lt;lb/&gt;Ew,Iw&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell bgcolor="#D0F0FF"&gt;LES Gw,(IND:TMP)&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;LDS Gw,(IND:TMP)&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;...&lt;/cell&gt;&lt;cell colspan="8"&gt;...&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Fxh&lt;/cell&gt;&lt;cell&gt;LOCK:&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;LOCK:*&lt;/cell&gt;&lt;cell&gt;REPNE:&lt;/cell&gt;&lt;cell&gt;REP:&lt;lb/&gt;REPE:&lt;/cell&gt;&lt;cell&gt;HLT&lt;/cell&gt;&lt;cell&gt;CMC&lt;/cell&gt;&lt;cell&gt;group #3&lt;lb/&gt;Eb&lt;/cell&gt;&lt;cell&gt;group #3&lt;lb/&gt;Ew&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row align="center"&gt;&lt;cell align="center" width="75" bgcolor="#004080"&gt;xxh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;&lt;lb/&gt;x8h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;x9h&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xAh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xBh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xCh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xDh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xEh&lt;/cell&gt;&lt;cell align="center" width="100" bgcolor="#004080"&gt;xFh&lt;/cell&gt;&lt;/row&gt;&lt;row/&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;...&lt;/cell&gt;&lt;cell colspan="8"&gt;...&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;6xh&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JS*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JNS*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JP*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JNP*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JL*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JNL*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JLE*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;JNLE*&lt;lb/&gt;Jb&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;7xh&lt;/cell&gt;&lt;cell&gt;JS&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JNS&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JP&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JNP&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JL&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JNL&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JLE&lt;lb/&gt;Jb&lt;/cell&gt;&lt;cell&gt;JNLE&lt;lb/&gt;Jb&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell rowspan="2" align="center" bgcolor="#004080"&gt;&lt;lb/&gt;8xh&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV&lt;lb/&gt;Eb,Gb&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV&lt;lb/&gt;Ew,Gw&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV&lt;lb/&gt;Gb,Eb&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV&lt;lb/&gt;Gw,Ew&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV Mw,Sw&lt;lb/&gt;MOV Rw,Sw&lt;/cell&gt;&lt;cell&gt;LEA Gv,M&lt;/cell&gt;&lt;cell rowspan="2"&gt;MOV Sw,Mw&lt;lb/&gt;MOV Sw,Rw&lt;/cell&gt;&lt;cell rowspan="2"&gt;group #1A&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell bgcolor="#D0F0FF"&gt;LEA Gv,IND&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;...&lt;/cell&gt;&lt;cell colspan="8"&gt;...&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Cxh&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;RET* far&lt;lb/&gt;Iw&lt;/cell&gt;&lt;cell bgcolor="#D0F0FF"&gt;RET* far&lt;/cell&gt;&lt;cell&gt;RET far&lt;lb/&gt;Iw&lt;/cell&gt;&lt;cell&gt;RET far&lt;/cell&gt;&lt;cell&gt;INT3&lt;/cell&gt;&lt;cell&gt;INT&lt;lb/&gt;Ib&lt;/cell&gt;&lt;cell&gt;INTO&lt;/cell&gt;&lt;cell&gt;IRET&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;...&lt;/cell&gt;&lt;cell colspan="8"&gt;...&lt;/cell&gt;&lt;/row&gt;&lt;row align="center"&gt;&lt;cell align="center" bgcolor="#004080"&gt;&lt;lb/&gt;Fxh&lt;/cell&gt;&lt;cell&gt;CLC&lt;/cell&gt;&lt;cell&gt;STC&lt;/cell&gt;&lt;cell&gt;CLI&lt;/cell&gt;&lt;cell&gt;STI&lt;/cell&gt;&lt;cell&gt;CLD&lt;/cell&gt;&lt;cell&gt;STD&lt;/cell&gt;&lt;cell&gt;group #4&lt;lb/&gt;INC/DEC&lt;/cell&gt;&lt;cell&gt;group #5&lt;lb/&gt;INC/DEC/etc.&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;lb/&gt; note: The opcodes marked with * are aliases to other opcodes.&lt;lb/&gt; © 1996-2025 by Christian Ludloff. All rights reserved. Use at your own risk. &lt;/cell&gt;
    &lt;/row&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45774724</guid><pubDate>Fri, 31 Oct 2025 17:49:16 +0000</pubDate></item><item><title>How to build silos and decrease collaboration on purpose</title><link>https://www.rubick.com/how-to-build-silos-and-decrease-collaboration/</link><description>&lt;doc fingerprint="67d872103da581dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How to build silos and decrease collaboration (on purpose)&lt;/head&gt;
    &lt;p&gt;“We need to break down silos between departments and get people to collaborate better” — almost every leader everywhere.&lt;/p&gt;
    &lt;p&gt;Most leaders reflexively think of silos as BAD and collaboration as GOOD. This manifesto defends silos and challenges the value of collaboration.&lt;/p&gt;
    &lt;head rend="h2"&gt;Increasing collaboration can do harm&lt;/head&gt;
    &lt;p&gt;In general, you should aim to maximize collaboration within teams, and minimize collaboration between teams.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why maximize collaboration within teams?&lt;/head&gt;
    &lt;p&gt;A collaborative team works together on one or two goals. Why?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This maximizes shared state — everyone has a common understanding of goals, progress, and who is doing what.&lt;/item&gt;
      &lt;item&gt;This gives team members a better ability to focus and coordinate their work with each other.&lt;/item&gt;
      &lt;item&gt;Team members have overlapping areas of knowledge, so they can critique each other’s work and help each other grow.&lt;/item&gt;
      &lt;item&gt;They are more innovative, because the interplay between people as they work on the same goal helps generate more diverse thinking and improve decision-making.&lt;/item&gt;
      &lt;item&gt;When someone leaves the team, the fact that others have a shared understanding of the work means the team can survive and continue to work effectively.&lt;/item&gt;
      &lt;item&gt;People can go on vacation or leave without as much disruption.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Collaborative teams feel great to be a part of — everyone shares the same victories and accomplishments together. A team that doesn’t collaborate often really isn’t a team at all.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why minimize collaboration between teams?&lt;/head&gt;
    &lt;p&gt;To the maximum extent possible, teams should have what they need to succeed within the borders of their team. And where that is not true, you need some structure to ensure the team can get what it needs in a way that will scale with the organization’s growth.&lt;/p&gt;
    &lt;p&gt;As companies grow, communication and dependencies proliferate. Companies start out with many-to-many communication. As they grow, the communication patterns within the company must necessarily switch to being segmented and defined. Otherwise, the communication burden on teams will grow at an exponential rate, and the increasing complexity will degrade the effectiveness of the company.&lt;/p&gt;
    &lt;p&gt;I observed an example of this at New Relic:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;As the engineering organization grew, we encouraged a collaborative culture and rewarded people for collaboration between teams (it was even part of our promotion criteria — you can blame that on me!).&lt;/item&gt;
      &lt;item&gt;After a few years, the increasing number of teams made it more and more difficult to manage dependencies between teams, to the point that it eventually became impossible to accomplish any large project within the organization. I know, because I was one of the “best project managers”, so I got put on many of those large projects — and they were systematically impossible to execute on. We all tried heroically to make it work, but the system was rigged — there wasn’t a way to accomplish these larger projects.&lt;/item&gt;
      &lt;item&gt;The solution to this was to eventually define the interaction models between teams, reduce dependencies, and add some structure to prioritization and communication.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Looking back in retrospect, it was as obvious as math what happened, but I see organizations fall into this trap over and over. We’ll talk more about how to structure these solutions in the second blog post in this series.&lt;/p&gt;
    &lt;p&gt;Collaboration sounds great, but it’s something you want to actively be combating between teams. A little collaboration is fine, but excessive collaboration between teams is a sign your organization isn’t structured well. If you ever wonder why Bezos took such a hard line on his API mandate in 2002, this probably factored into it. Bezos structured Amazon so that teams were as independent as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;What are silos?&lt;/head&gt;
    &lt;p&gt;Silos are boundaries between groups of people, based on the organizational structure and teams they’re working on.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why do silos exist?&lt;/head&gt;
    &lt;p&gt;Silos exist because humans have cognitive and communication limits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Humans can only handle a certain number of relationships&lt;/item&gt;
      &lt;item&gt;Humans have a limit to how much communication they can handle.&lt;/item&gt;
      &lt;item&gt;Humans are pre-wired to think in terms of teams and tribes. We work better in small groups.&lt;/item&gt;
      &lt;item&gt;Humans have cognitive limits on the amount they can focus on.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It’s important to recognize that these limits are real limits, and not something you can wish away. Every company in the world (above a certain size) operates in teams that specialize. We organize into teams and have org structures generally because that is what human beings need to work in larger groups.&lt;/p&gt;
    &lt;p&gt;There are ways to flex certain aspects of this. For example, a company that is designed to be fully asynchronous can rely on process and tooling to change some of these constraints. But even then, you’re moving the constraints around, not eliminating them completely. You need to operate in a way that recognizes these limits.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why do leaders want to break down silos?&lt;/head&gt;
    &lt;p&gt;Leaders start talking about breaking down silos when they see that individual parts of the company aren’t achieving larger business outcomes and are excessively focused on their own area. Alternatively, they talk about breaking down silos when parts of the company aren’t well coordinated with each other. Generally this happens once the organization has become complex enough that the structure is getting in the way.&lt;/p&gt;
    &lt;p&gt;Here are a couple of examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Marketing is planning a major announcement of an upcoming launch, but can’t get a timing commitment from the product and engineering teams.&lt;/item&gt;
      &lt;item&gt;Two teams in engineering are building the same service, but in slightly different ways.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Leaders see these things, and start blathering about “breaking down silos” and “increasing collaboration”. What’s wrong with that?&lt;/p&gt;
    &lt;head rend="h2"&gt;“Breaking down silos” represents incomplete thinking&lt;/head&gt;
    &lt;p&gt;“Breaking down silos” is an exhortation rather than a diagnosis or prescription of how to improve the situation. “Breaking down silos” blames individuals for not having a big enough vision and working across boundaries, instead of looking with curiosity at the system and asking why they are doing what they’re doing. It’s expecting people to have your level of perspective without figuring out why they don’t.&lt;/p&gt;
    &lt;p&gt;But the main problem is that it isn’t specific enough.&lt;/p&gt;
    &lt;head rend="h2"&gt;Communication != Collaboration != Coordination&lt;/head&gt;
    &lt;p&gt;When you hear someone say they want teams to collaborate more or break down silos, encourage them to look at the problem from three perspectives:&lt;/p&gt;
    &lt;head rend="h3"&gt;Coordination&lt;/head&gt;
    &lt;p&gt;Usually when people talk about collaboration, what they’re really looking for is better coordination.&lt;/p&gt;
    &lt;p&gt;Coordination is “the harmonious functioning of parts for effective results” (Merriam-Webster)&lt;/p&gt;
    &lt;p&gt;The US military found that the best way to coordinate groups of people quickly and effectively was to centralize coordination and decentralize decision-making and execution. This is still the state of the art for organizational design. You want local groups to be able to act independently and have what they need to be successful. You want centralized functions to set high level objectives and coordinate where necessary to produce the right outcomes.&lt;/p&gt;
    &lt;p&gt;We’ll talk in the second post in this series about a multitude of ways you can coordinate groups of people working together.&lt;/p&gt;
    &lt;head rend="h3"&gt;Communication&lt;/head&gt;
    &lt;p&gt;Communication is transferring information from one person or group to another.&lt;/p&gt;
    &lt;p&gt;When people talk about needing increased collaboration, you can often achieve this more effectively by looking at the flow of information between people, and redesigning it. Typically, you can do something like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ask people how they are getting information today.&lt;/item&gt;
      &lt;item&gt;Find out what information people actually need.&lt;/item&gt;
      &lt;item&gt;Design the lightest weight version of this you can imagine.&lt;/item&gt;
      &lt;item&gt;Try it out&lt;/item&gt;
      &lt;item&gt;Get feedback and act on that feedback.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One thing I’ve done over and over in many startups is set up weekly communication on projects in engineering. This helps the marketing organization understand how to coordinate their work with engineering, among other benefits.&lt;/p&gt;
    &lt;head rend="h3"&gt;Collaboration&lt;/head&gt;
    &lt;p&gt;Collaboration is when people work together to produce an outcome. When teams are collaborating, it means they’re working with other teams to achieve outcomes together. That’s often a sign the team isn’t set up well. Ideally, it should have what it needs to do what it needs without dependencies on other teams.&lt;/p&gt;
    &lt;p&gt;A team that has to collaborate to achieve its objectives is going to be less reliably successful. In general, teams shouldn’t be collaborating with more than a couple of teams, unless they’re explicitly set up to be that way. For example, in some organizations you might set up the design team as a “service” organization which provides design for a larger organization. For teams that are set up that way, it can be fine, but it usually should be very carefully thought through. What is the interaction model for the team, and how will it deal with the inevitable fact that there will be excess demands on it? We’ll cover some of these patterns and their tradeoffs in the second post in this series.&lt;/p&gt;
    &lt;p&gt;Of course, the world is messy, and you shouldn’t expect a complete lack of collaboration between teams. But when you see teams collaborate, that’s something to pay attention to.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical analogy&lt;/head&gt;
    &lt;p&gt;You might think of silos as “encapsulation”. Leaders want to dig into the internals of the classes holding the logic they need. But it’s a bad solution to just bolt that on — you really need to refactor things so that they are better structured.&lt;/p&gt;
    &lt;head rend="h2"&gt;How do you get teams to coordinate better?&lt;/head&gt;
    &lt;p&gt;In the next post in this series, I share concrete patterns that help teams and departments work across organizational boundaries.&lt;/p&gt;
    &lt;head rend="h2"&gt;What do you think?&lt;/head&gt;
    &lt;p&gt;I always appreciate hearing your thoughts and reactions to my posts.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you&lt;/head&gt;
    &lt;p&gt;Thank you to the many people who helped improve this post. Rebecca Campbell always makes my work better. She helped me tighten up many of my arguments and helped me realize that I needed to make the section on coordination more explicit. Brent Miller, always the purveyer of astute observations, offered structural feedback that made the post much stronger. Chris Haupt, always thoughtful, pointed out a few areas that he didn’t find convincing, and helped me see that I needed to go deeper on information flow. Aaron Erickson suggested the metaphor of encapsulation. Thanks to Neville Kuyt for suggesting I define silo. And additional thank you to Robert DiFalco and Darin Swanson for reviewing and commenting on the post. Always appreciate your insight!&lt;/p&gt;
    &lt;p&gt;Comments powered by Talkyard.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45775642</guid><pubDate>Fri, 31 Oct 2025 19:16:05 +0000</pubDate></item><item><title>A theoretical way to circumvent Android developer verification</title><link>https://enaix.github.io/2025/10/30/developer-verification.html</link><description>&lt;doc fingerprint="af64594390b6d661"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A theoretical way to circumvent Android developer verification&lt;/head&gt;
    &lt;p&gt;As you all know, Google has introduced developer verification as a way to prevent users from installing “unregistered” APKs. This measure was taken as a security feature to link every APK in existence to its developer, as in Play Store.&lt;/p&gt;
    &lt;p&gt;Link to the Android documentation, link to FAQ&lt;/p&gt;
    &lt;head rend="h2"&gt;Why this is bad&lt;/head&gt;
    &lt;p&gt;This has already been discussed by ArsTechnica and on some threads (some cherry-picked ones): reddit, ycombinator, hackaday.&lt;/p&gt;
    &lt;p&gt;A quick recap of the main points (as of 30 Oct 2025):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The base tier costs $25, as in Play Market. Requires an ID&lt;/item&gt;
      &lt;item&gt;There will be a limited “hobbyist” unpaid license. Google claims that they won’t require an ID&lt;/item&gt;
      &lt;item&gt;Legal info is told to be private, unlike with Play Market&lt;/item&gt;
      &lt;item&gt;The verification code is supposed to be located in Play Services, but Google hasn’t published the source code yet&lt;/item&gt;
      &lt;item&gt;Google assures that it would be possible to install applications locally using ADB, but there are no details on this&lt;/item&gt;
      &lt;item&gt;Hobbyist license restrictions are unknown&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A few months prior Google has decided to make Android development private, which seems to be a preparation for the upcoming changes (another article). Due to this change in AOSP release format, it is no longer possible to track what exactly Google is doing.&lt;/p&gt;
    &lt;p&gt;My answer to this question is that it would simply prevent small developers from distributing their apps, including myself. If we take the legal route, a hobbyist license is supposed to have some limit on the number of installs by design. If we take, say, 10K installs, this is not enough in my case. Another question is how exactly the process of verification is going to happen, what if Google adopts the same rules as in Play Store? Taking my fork of the old VN engine port, this apk would not pass security checks, as the old codebase relies on legacy external storage permissions, which are banned in Play Store. If we take the adb route, there are no guarantees that this method is going to work in the future in the form you expect. For instance, Google mentions that this method is meant for on-device tests during development, and nothing prevents them from reporting the install to their servers and checking if a self-signed apk has been installed on other devices. Another way to put it, this is problematic for an average Android user to perform these steps, and this is going to be the developer’s problem.&lt;/p&gt;
    &lt;p&gt;The situation links pretty well with Samsung removing bootloader unlocking with the One UI 8 update. Great, duh…&lt;/p&gt;
    &lt;head rend="h2"&gt;The concept&lt;/head&gt;
    &lt;p&gt;My vision of the hack is to distribute a verified loader apk, which in turn dynamically loads any apk the user wants. A user obtains the loader apk once and loads apps without installing as much as they want.&lt;/p&gt;
    &lt;p&gt;The Java virtual machine in Android is the ART/Dalvik runtime (I will refer to it as Dalvik, it seems that Google hates cool names). Did you know that Dalvik natively allows dynamic code execution using PathClassLoader? So an apk may just load some zip/apk/dex code from external storage and execute it in current context. Essentially, this means that we can natively load the apk into memory and execute any code inside of the target apk, and we are not altering the original code signature of the loader.&lt;/p&gt;
    &lt;p&gt;In order to actually run the apk, the loader needs to properly initialize the main activity (aka the main screen, or the entrypoint) of the target apk. So, the main activity needs to be initialized and somehow placed inside of the Android’s activity cycle with the loader acting as a wrapper. Then, the loader apk should handle other aspects like local files handling and names conflict resolution. This can be achieved by patching the target apk bytecode: .odex/.dex classes may be dynamically decompiled into .smali, analyzed and compiled back into a modified apk. Furthermore, the loader would have to parse AndroidManifest options of the target (main activity location, screen options).&lt;/p&gt;
    &lt;head rend="h3"&gt;Implementation&lt;/head&gt;
    &lt;p&gt;Developing such wrapper in a straightforward way has proven to be rather difficult, as Android activity management logic is extremely complicated and differs from version to version. In short, it was problematic to perform the initialization process the right way. Some people suggested to avoid the initialization step completely, and use Unsafe Dalvik api to register the target’s activity as the loader apk activity stub, which is declared in the loader’s manifest without class. I couldn’t find exact methods in the Unsafe documentation, but this actually may be a way to go.&lt;/p&gt;
    &lt;p&gt;Due to this particular issue I couldn’t bring the proof of concept to a working state in a reasonable time, and because of this I was considering to not publish this article at all. The purpose of this post is not to give a somewhat ready solution, but get some feedback on the concept, as I was not ready to devote lots of time on a potentially broken solution.&lt;/p&gt;
    &lt;head rend="h2"&gt;The logistics&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Information provided in this section is for educational use only, all scenarios discussed below are hypothetical.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In order to install the loader apk on the device, it would require, well, some form of verification. Hobbyist license is the only choice here, as paying $25 for each attempt is not optimal. Since the hobbyist license has a limited number of installs, there should be multiple instances of the apk with separate licences. In this hypothetical scenario there may either be a pool of volunteers who sign the code, or completely random users who are willing to help. In the second case, the loader code would somehow need to be verified or scanned, since such distribution system would be vulnerable to malware.&lt;/p&gt;
    &lt;p&gt;The final and the most important issue in this process is the verification process itself, as the loader code may (and likely will) be flagged by Google. So, the code would require some form of obfuscation like code flow modification and implementing double functionality (for instance, registering it as a file manager). If Google decides to ban dynamic code loading altogether, the final solution would be to pack the Dalvik runtime into the loader as a native library. This of course would have extremely low performance, but it should be technically possible.&lt;/p&gt;
    &lt;p&gt;Overall, the hypothetical plan has lots of assumptions, with which I’m not happy with. First of all, it requires lots of manual work by the volunteers or random people, and this work also includes the apk obfuscation, which was not discussed in detail. Then, the verification process itself should be somewhat permissive to allow potentially suspicious apps (I would like to hear how does this happen with current Play Store verification).&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The project described in this article by no means is a finished solution, and if you have started to think what else could work, it means that the article has reached its original goal. I believe that we would eventually come up with a proper solution in the future. Thank you for reading!&lt;/p&gt;
    &lt;p&gt;You may find the source code here. Feel free to create an issue if you wish to discuss&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45776269</guid><pubDate>Fri, 31 Oct 2025 20:20:42 +0000</pubDate></item><item><title>The only people who feel good are making over $200k and have large portfolios</title><link>https://fortune.com/2025/10/24/why-is-economy-so-bad-recession-not-inflation-fed-rate-cuts-2025/</link><description>&lt;doc fingerprint="5b6044d42ff58ea8"&gt;
  &lt;main&gt;
    &lt;p&gt;Inflation may be increasing at a slower pace than expected, the markets might be cheering, and the Fed will likely soon be cutting, but Diane Swonk isn’t popping Champagne.&lt;/p&gt;
    &lt;p&gt;The veteran economist says the economy “looks better than it feels” because the very data used to measure it is eroding, and the illusion of resilience could shatter heading into the fourth quarter.&lt;/p&gt;
    &lt;p&gt;“The only groups that feel good about the economy now are making over $200,000 in the surveys and have large stock portfolios,” Swonk said.&lt;/p&gt;
    &lt;p&gt;September’s consumer price index showed a 0.3% monthly rise and a 3% year-over-year rate, with the core index—which the Fed watches more closely than the headline—rising 0.2%. Economists had expected a slightly hotter print, calling a 0.4% monthly increase in the headline CPI and a 0.3% increase in the core rate.&lt;lb/&gt;Despite coming in below forecasts, inflation is still rising on an annual basis, with September’s pace accelerating from 2.9% in August. The CPI has now climbed to its highest level since January. Inflation had cooled steadily through the spring—hitting just 2.9% in May and June—before reaccelerating on higher energy costs. &lt;/p&gt;
    &lt;p&gt;Energy costs, again, were the main driver, with gasoline up at 4.1%, while food prices moderated, and core inflation—excluding food and energy—slowed to 0.2%. Markets cheered the result as a sign that inflation remains contained, bolstering expectations for another quarter-point Fed rate cut at the FOMC meeting next week and another one in December.&lt;/p&gt;
    &lt;p&gt;But Swonk, chief economist at KPMG, sees something else: a slow-moving problem that’s partly statistical, partly structural, and increasingly psychological.&lt;lb/&gt;“It’s creep instead of a surge,” she said, noting that the headline number masks persistent “stickiness” in service-sector prices and a widening split in who’s actually feeling relief. &lt;/p&gt;
    &lt;p&gt;Beneath the surface, she argues, the U.S. is running on shaky footing, both economically and in terms of the quality of the data that guides policymakers.&lt;/p&gt;
    &lt;head rend="h3"&gt;A false sense of calm&lt;/head&gt;
    &lt;p&gt;Swonk pointed out that many of the categories holding inflation steady are either insulated from tariffs or benefiting from temporary waivers: computers, smartphones, and some vehicle imports. Once those fade, “goods prices are still moving up,” she said, with few signs of broad-based disinflation. Core services less shelter—a metric the Fed watches closely—rose about 0.4% in September, Swonk estimated, and remains more than 3% higher than a year ago, “well above anything we saw pre-pandemic.”&lt;/p&gt;
    &lt;p&gt;That stickiness, she warns, is amplified by a bifurcated consumer base, what some economists have called the “K shaped economy.” Affluent households continue to spend freely on travel, entertainment, and premium goods, keeping service-sector inflation stubborn. Lower- and middle-income consumers, by contrast, are pushing back, trading down, stretching budgets, or delaying purchases altogether.&lt;lb/&gt;“Retailers are feeling that divide,” Swonk said, describing a landscape where discount chains are seeing higher-income shoppers while subprime delinquencies creep up among those with thinner financial cushions. &lt;/p&gt;
    &lt;p&gt;The result is a headline inflation rate that understates the pain for the median household.&lt;lb/&gt;“People are making tough tradeoffs in their baskets,” Swonk said. “The economy looks better on paper than it feels to the majority of Americans.”&lt;/p&gt;
    &lt;head rend="h3"&gt;The hidden fragility in the data&lt;/head&gt;
    &lt;p&gt;Swonk also believes part of that gap between reality and perception stems from the government’s diminished capacity to collect and verify data. Even before the government shutdown that delayed the CPI release by nine days, the Bureau of Labor Statistics was operating with roughly 20% fewer staff than before the pandemic, Swonk said, because of DOGE budget cuts. That means that now, more than a third of price data in the CPI is imputed—estimated rather than directly observed—since fewer agents are collecting prices in person.&lt;/p&gt;
    &lt;p&gt;“We’re comparing something that’s similar in price, but it’s not apples to apples,” she said. “You just don’t have as many people in the field taking those samples.”&lt;lb/&gt;That means official inflation readings may be smoother than the real-world volatility consumers experience, particularly for categories where local price swings or shortages matter most, such as in beef prices. &lt;/p&gt;
    &lt;p&gt;For the Fed, that introduces a serious blind spot. Policymakers rely heavily on inflation data to calibrate rate cuts, and if the CPI is built on incomplete sampling, it risks reinforcing the perception that inflation is easing faster than it actually is.&lt;lb/&gt;“These are still not completely clean numbers,” Swonk cautioned. “The problem isn’t the shutdown. It’s the staffing shortages we had going into it.” &lt;/p&gt;
    &lt;p&gt;To Swonk, the slow breakdown in how we measure the economy itself is almost the bigger story than the monthly inflation. Asked if she was worried that the markets and the U.S. consumer broadly might become skeptical of the BLS, or even accuse the bureau of politicization, Swonk sighed wearily.&lt;/p&gt;
    &lt;p&gt;“Trust in the data has already been eroding for decades,” Swonk said. “Now it’s accelerating.”&lt;/p&gt;
    &lt;head rend="h3"&gt;A tougher road ahead&lt;/head&gt;
    &lt;p&gt;Looking forward, Swonk expects the economy to slow “dramatically” in the fourth quarter, a turn she says was already coming before the shutdown drained 750,000 federal paychecks from the economy. Consumer stress, rising delinquencies, and tariff pass-throughs will all collide with a fragile labor market and weaker retail season.&lt;/p&gt;
    &lt;p&gt;“We’re going into a very difficult holiday season,” she said, noting that surveys show consumers “want cash more than anything else,” a reflection of financial anxiety rather than confidence.&lt;/p&gt;
    &lt;p&gt;The government’s tariff waivers may soften some price increases, but she expects uneven effects across sectors. Many tariff-related price pressures “are still ahead of us,” Swonk said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45776941</guid><pubDate>Fri, 31 Oct 2025 21:32:36 +0000</pubDate></item></channel></rss>