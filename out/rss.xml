<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 01 Dec 2025 23:10:30 +0000</lastBuildDate><item><title>A vector graphics workstation from the 70s</title><link>https://justanotherelectronicsblog.com/?p=1429</link><description>&lt;doc fingerprint="f327529063a64154"&gt;
  &lt;main&gt;
    &lt;p&gt;This repair has been on the to do list for ages, so let’s finally get to it!&lt;/p&gt;
    &lt;p&gt;In my mind, Tektronix is a brand that makes electronics lab equipment like oscilloscopes and logic analyzers. Turns out, they made quite a few terminals and a couple of computers! A good friend saw this one for sale local to him, and I poked him till he agreed on picking it up for me.&lt;/p&gt;
    &lt;p&gt;Picking it up may be the wrong wording, this thing is big and heavy! It weights about 35kg and it’s nearly a meter long!&lt;/p&gt;
    &lt;p&gt;So let’s have a look at what this is, what I needed to do to repair it and what it can do!&lt;/p&gt;
    &lt;head rend="h2"&gt;Some history&lt;/head&gt;
    &lt;p&gt;The machine I got is a Tektronix 4051 graphics workstation, released in 1975, but let’s look a bit at the history from Tektronix before this was released. Tektronix started in late 1945 as Tekrad, but quickly got renamed to Tektronix. One of their first products was the 511 oscilloscope, the first oscilloscope with a trigger!&lt;/p&gt;
    &lt;p&gt;This turned out to be a good thing, and soon enough, Tektronix was synonymous with oscilloscopes and known as a company that made some of the best test and measurement equipment. In the 60s, mainframe and then minicomputers became more popular, which often needed a terminal. Tektronix at this point was making storage oscilloscopes, which use a storage CRT tube that can “remember” drawn signals. Using this technology, Tektronix released their first terminal in 1969, the 4002. A 11″ terminal that was capable of displaying graphics with a 400×300 pixel resolution. As the CRT rememebers the drawn data, there was no need for a RAM framebuffer!&lt;/p&gt;
    &lt;p&gt;A few years later in 1971 they released the 4010, again 11″ but now with 1024*780 pixel resolution. As they used Storage CRTs, these terminals where a lot cheaper then the competitors. Mind you, cheap still means around $4000, or around $30.000 in 2025 money. But the IBM 2250 was priced at around $280.000 That’s 1970s dollars, so well over 2 million USD today!&lt;/p&gt;
    &lt;p&gt;Before we move away from these terminals, one last cool tidbit. Tektronix made the 4010 in several sizes, the biggest being the 25″ 4016 with a 4096*3120 pixel resolution. 4K in 1974, sign me up!&lt;/p&gt;
    &lt;head rend="h2"&gt;The 405x computers&lt;/head&gt;
    &lt;p&gt;OK I promised computers, so let’s move to the Tek 4051 I got! Released in 1975, this was based on the 4010 series of terminals, but with a Motorola 6800 computer inside. This machine ran, like so many at the time, BASIC, but with extra subroutines for drawing and manipulating vector graphics. 8KB RAM was standard, but up to 32KB RAM could be installed. Extra software was installed via ROM modules in the back, for example to add DSP routines. Data could be saved on tape, and via RS232 and GBIP external devices could be attached!&lt;/p&gt;
    &lt;p&gt;All in all, a pretty capable machine, especially in 1975. BASIC computers where getting common, but graphics was pretty new. According to Tektronix the 4051 was ideal for researches, analysts and physicians, and this could be yours for the low low price of 6 grand, or around $36.000 in 2025. I could not find sales figures, but it seems that this was a decently successful machine. Tektronix also made the 4052, with a faster CPU, and the 4054, a 19″ 4K resolution behemoth! Tektronix continued making workstations until the 90s but like almost all workstations of the era, x86/Linux eventually took over the entire workstation market.&lt;/p&gt;
    &lt;p&gt;The 4051 was also used in a few series/movies, the storage CRTs do not flicker when recorded like a normal CRT and as they run basic, getting something cool on screen was fairly easy to do! The best known example was Battlestar Galactica:&lt;/p&gt;
    &lt;head rend="h2"&gt;Fixing a Tektronix computer&lt;/head&gt;
    &lt;p&gt;With the history out of the way, what’s the shape of the one I got?&lt;/p&gt;
    &lt;p&gt;It was stored in a shed for a long while, state unknown, but it looked like it’s in OK shape. A bit dirty but who isn’t at times. Fuse is intact, and when opening it up, nothing looked “off” no bulging caps or such. But turning it on and nothing happens. Anticlimactic…&lt;/p&gt;
    &lt;p&gt;A good bit of tracing wires later, it turned out the ON/OFF switch is broken. So to quicly remedy this, some wires can be used.&lt;/p&gt;
    &lt;p&gt;I do NOT recommend this. 230V via cheap breadboard wires is not smart. But with this, still nothing. Argh. So another bit of debugging later it turned out a wire of the mains transformer was not connected to the terminal.&lt;/p&gt;
    &lt;p&gt;It’s kind of visible in this photo, there are wires going from the transformer to the tabs to select voltages and one was broken. Luckily there was enough wire left to solder on and fix it, getting a replacement would have been impossible! After this fix, I got power! I disconnected as much as I could in order to check all the voltages I could check. We need 15V, 12V, 5V, -12, +20, -20 +185 and +365 and they turned out to all be in spec. Tektronix :)&lt;/p&gt;
    &lt;p&gt;So, time to slowly connect boards back in and see if something explodes!&lt;/p&gt;
    &lt;p&gt;Wait I didn’t mean that as a suggestion… Sadly this resistor didn’t understand sarcasm and decided to go up in smoke. It’s a 47 ohm resistor that limits a 320V supply a bit. Perhaps it got a little too warm, or age got the better of it. I did check everything after the resistor and all measured OK. No transistor in a short or capacitor that imploded. So let’s just replace this and pray?&lt;/p&gt;
    &lt;p&gt;Neat, that worked!&lt;/p&gt;
    &lt;head rend="h2"&gt;Calibrating that display&lt;/head&gt;
    &lt;p&gt;Something appeared on the display, which is a BIG improvement, and it all looks like the machine wants to boot. But the display is completely unreadable, which means it’s time to calibrate all voltages.&lt;/p&gt;
    &lt;p&gt;Which means, measure a power supply that’s almost 4KV. Spicy!&lt;/p&gt;
    &lt;p&gt;Luckily I have a HV scope probe on loan from a friend! And the HV is in spec. So that’s good, but all the other voltages are not. These CRTs are pretty sensitive to all the needed voltages, sensitive enough that they are calibrated in the factory and the voltages for the exact CRT are written on them:&lt;/p&gt;
    &lt;p&gt;196V and 75V for this one, and I measured 160V and 55V. yeah that’ll do it! Quite a few calibration steps later the display turned out to be quite nicely readable and in great condition!&lt;/p&gt;
    &lt;p&gt;The single tape I got with mine is sadly broken. The belt snapped, which seems to be a common issue with these. The drive itself seems to work, and the tape I got is an OS backup tape, so likely nothing too important. This is fixable, but not too high on my to-do list for now.&lt;/p&gt;
    &lt;p&gt;This turned out to be a less complex repair then expected. Some keyboard switches are a bit crusty, it needs a clean, but a 50 year old computer mostly just working is pretty amazing! So let’s end this repair on a few fun beauty shots of the inside and more:&lt;/p&gt;
    &lt;head rend="h2"&gt;What did I pick up exactly?&lt;/head&gt;
    &lt;p&gt;Having a look at my machine, it has maxed out RAM at 32KB, sadly no serial port, but it did came with a ROM Expander!&lt;/p&gt;
    &lt;p&gt;The back of the 4051 has space for 2 ROM cards. These contain things like extra programs, subroutines for DSP algorithms and more. These can contain 8KB of ROM, and are memory mapped.&lt;/p&gt;
    &lt;p&gt;If you want more then 2 at any time, the Rom Expander allows you to have 8! Only one is memory mapped at any time, but the OS of the 4051 scans all ROMS on start, and when you run a program on a ROM, it makes sure to send a few commands to the expander to memory map the right one. This is all invisible as an end user and the machine acts like having 8 ROMs, or if you have 2 expanders, 16 ROMs!&lt;/p&gt;
    &lt;p&gt;I got 3 ROMs with mine, one for an editor program, one to load/store binary data to tape, and one for the optional external floppy drive. Oh, yes, there is a floppy drive! Sadly I don’t have it, but if someone has one collecting dust, do let me know :)&lt;/p&gt;
    &lt;head rend="h2"&gt;But can it run DOOM?&lt;/head&gt;
    &lt;p&gt;No&lt;/p&gt;
    &lt;head rend="h2"&gt;OK any games at all?&lt;/head&gt;
    &lt;p&gt;How about some monopoly!&lt;/p&gt;
    &lt;p&gt;Due to the display technique, most games don’t work very well. The display can’t easily be cleared, apart from a full erase of the display. So some games like tic tac toe or monopoly work but anything more active is difficult sadly.&lt;/p&gt;
    &lt;p&gt;Luckily there are plenty of cool demo’s and programs for the 4051 and it’s bigger siblings. A TON of programs, manuals and more can be found on the Github page from Monty McGraw. There is also an emulator so you can try this all out using any modern computer!&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s next&lt;/head&gt;
    &lt;p&gt;One of the projects on Monty’s Github is a GBIP flash emulator. Currently my 4051 has no way to load/store programs, and typing a 1000 line BASIC file is a bit of a pain. So I’m definitely ordering parts for that!&lt;/p&gt;
    &lt;p&gt;There is also quite a few ROM cards I do not have, so I am working on a ROM board to clone them.&lt;/p&gt;
    &lt;p&gt;Finally having this beautiful machine up and running is a great step, and I’ll leave it at this for now!&lt;/p&gt;
    &lt;p&gt;As always, if you enjoyed this blog post, you can buy me a coffee!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46107177</guid><pubDate>Mon, 01 Dec 2025 13:31:58 +0000</pubDate></item><item><title>Cartographers Have Been Hiding Covert Illustrations Inside of Switzerland's Maps</title><link>https://eyeondesign.aiga.org/for-decades-cartographers-have-been-hiding-covert-illustrations-inside-of-switzerlands-official-maps/</link><description>&lt;doc fingerprint="7a5300562852eb8c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Google unkills JPEG XL?&lt;/head&gt;
    &lt;p&gt;A quick summary of the format’s road to stardom&lt;/p&gt;
    &lt;p&gt;I’ve written about JPEG XL in the past. First, I noted Google’s move to kill the format in Chromium in favor of the homegrown and inferior AVIF.12 Then, I had a deeper look at the format, and visually compared JPEG XL with AVIF on a handful of images.&lt;/p&gt;
    &lt;p&gt;The latter post started with a quick support test:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“If you are browsing this page around 2023, chances are that your browser supports AVIF but does not support JPEG XL.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Well, here we are at the end of 2025, and this very sentence still holds true. Unless you are one of the 17% of users using Safari3, or are adventurous enough to use a niche browser like Thorium or LibreWolf, chances are you see the AVIF banner in green and the JPEG XL image in black/red.&lt;/p&gt;
    &lt;p&gt;The good news is, this will change soon. In a dramatic turn of events, the Chromium team has reversed its &lt;code&gt;Obsolete&lt;/code&gt; tag, and has decided to support the format in Blink (the engine behind Chrome/Chromium/Edge). Given Chrome’s position in the browser market share, I predict the format will become a de factor standard for images in the near future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Let’s recap&lt;/head&gt;
    &lt;p&gt;I’ve been following JPEG XL since its experimental support in Blink. What started as a promising feature was quickly axed by the team in a bizarre and ridiculous manner. First, they asked the community for feedback on the format. Then, the community responded very positively. And I don’t only mean a couple of guys in their basement. Meta, Intel, Cloudinary, Adobe, &lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;libvips&lt;/code&gt;, Krita, and many more. After that came the infamous comment:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;da...@chromium.orgda...@chromium.org&lt;/p&gt;
      &lt;p&gt;#85 Oct 31, 2022 12:34AM&lt;/p&gt;
      &lt;p&gt;Thank you everyone for your comments and feedback regarding JPEG XL. We will be removing the JPEG XL code and flag from Chromium for the following reasons:&lt;/p&gt;
      &lt;item&gt;Experimental flags and code should not remain indefinitely&lt;/item&gt;
      &lt;item&gt;There is not enough interest from the entire ecosystem to continue experimenting with JPEG XL&lt;/item&gt;
      &lt;item&gt;The new image format does not bring sufficient incremental benefits over existing formats to warrant enabling it by default&lt;/item&gt;
      &lt;item&gt;By removing the flag and the code in M110, it reduces the maintenance burden and allows us to focus on improving existing formats in Chrome&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yes, right, “not enough interest from the entire ecosystem”. Sure.&lt;/p&gt;
    &lt;p&gt;Anyway, following this comment, a steady stream of messages pointed out how wrong that was, from all the organizations mentioned above and many more. People were noticing in blog posts, videos, and social media interactions.&lt;/p&gt;
    &lt;p&gt;Strangely, the following few years have been pretty calm for JPEG XL. However, a few notable events did take place. First, the Firefox team showed interest in a JPEG XL Rust decoder, after describing their stance on the matter as “neutral”. They were concerned about the increased attack surface resulting from including the current 100K+ lines C++ &lt;code&gt;libjxl&lt;/code&gt; reference decoder, even though most of those lines are testing code. In any case, they kind of requested a “memory-safe” decoder. This seems to have kick-started the Rust implementation, jxl-rs, from Google Research.&lt;/p&gt;
    &lt;p&gt;To top it off, a couple of weeks ago, the PDF Association announced their intent to adopt JPEG XL as a preferred image format in their PDF specification. The CTO of the PDF Association, Peter Wyatt, expressed their desire to include JPEG XL as the preferred format for HDR content in PDF files.4&lt;/p&gt;
    &lt;head rend="h2"&gt;Chromium’s new stance&lt;/head&gt;
    &lt;p&gt;All of this pressure exerted steadily over time made the Chromium team reconsider the format. They tried to kill it in favor of AVIF, but that hasn’t worked out. Rick Byers, on behalf of Chromium, made a comment in the Blink developers Google group about the team welcoming a performant and memory-safe JPEG XL decoder in Chromium. He stated that the change of stance was in light of the positive signs from the community we have exposed above (Safari support, Firefox updating their position, PDF, etc.). Quickly after that, the Chromium issue state was changed from &lt;code&gt;Obsolete&lt;/code&gt; to &lt;code&gt;Assigned&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;About JPEG XL&lt;/head&gt;
    &lt;p&gt;This is great news for the format, and I believe it will give it the final push for mass adoption. The format is excellent for all kinds of purposes, and I’ll be adopting it pretty much instantly for this and the Gaia Sky website when support is shipped. Some of the features that make it superior to the competition are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lossless re-compression of JPEG images. This means you can re-compress your current JPEG library without losing information and benefit from a ~30% reduction in file size for free. This is a killer feature that no other format has.&lt;/item&gt;
      &lt;item&gt;Support for wide gamut and HDR.&lt;/item&gt;
      &lt;item&gt;Support for image sizes of up to 1,073,741,823x1,073,741,824. You won’t run out of image space anytime soon. AVIF is ridiculous in this aspect, capping at 8,193x4,320. WebP goes up to 16K2, while the original 1992 JPEG supports 64K2.&lt;/item&gt;
      &lt;item&gt;Maximum of 32 bits per channel. No other format (except for the defunct JPEG 2000) offers this.&lt;/item&gt;
      &lt;item&gt;Maximum of 4,099 channels. Most other formats support 4 or 5, with the exception of JPEG 2000, which supports 16,384.&lt;/item&gt;
      &lt;item&gt;JXL is super resilient to generation loss.5&lt;/item&gt;
      &lt;item&gt;JXL supports progressive decoding, which is essential for web delivery, IMO. WebP or HEIC have no such feature. Progressive decoding in AVIF was added a few years back.&lt;/item&gt;
      &lt;item&gt;Support for animation.&lt;/item&gt;
      &lt;item&gt;Support for alpha transparency.&lt;/item&gt;
      &lt;item&gt;Depth map support.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a full codec feature breakdown, see Battle of the Codecs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;JPEG XL is the future of image formats. It checks all the right boxes, and it checks them well. Support in the overwhelmingly most popular browser engine is probably going to be a crucial stepping stone in the format’s path to stardom. I’m happy that the Chromium team reconsidered their inclusion, but I am sad that it took so long and so much pressure from the community to achieve it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46107282</guid><pubDate>Mon, 01 Dec 2025 13:41:15 +0000</pubDate></item><item><title>Google unkills JPEG XL?</title><link>https://tonisagrista.com/blog/2025/google-unkills-jpegxl/</link><description>&lt;doc fingerprint="7a5300562852eb8c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Google unkills JPEG XL?&lt;/head&gt;
    &lt;p&gt;A quick summary of the format’s road to stardom&lt;/p&gt;
    &lt;p&gt;I’ve written about JPEG XL in the past. First, I noted Google’s move to kill the format in Chromium in favor of the homegrown and inferior AVIF.12 Then, I had a deeper look at the format, and visually compared JPEG XL with AVIF on a handful of images.&lt;/p&gt;
    &lt;p&gt;The latter post started with a quick support test:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“If you are browsing this page around 2023, chances are that your browser supports AVIF but does not support JPEG XL.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Well, here we are at the end of 2025, and this very sentence still holds true. Unless you are one of the 17% of users using Safari3, or are adventurous enough to use a niche browser like Thorium or LibreWolf, chances are you see the AVIF banner in green and the JPEG XL image in black/red.&lt;/p&gt;
    &lt;p&gt;The good news is, this will change soon. In a dramatic turn of events, the Chromium team has reversed its &lt;code&gt;Obsolete&lt;/code&gt; tag, and has decided to support the format in Blink (the engine behind Chrome/Chromium/Edge). Given Chrome’s position in the browser market share, I predict the format will become a de factor standard for images in the near future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Let’s recap&lt;/head&gt;
    &lt;p&gt;I’ve been following JPEG XL since its experimental support in Blink. What started as a promising feature was quickly axed by the team in a bizarre and ridiculous manner. First, they asked the community for feedback on the format. Then, the community responded very positively. And I don’t only mean a couple of guys in their basement. Meta, Intel, Cloudinary, Adobe, &lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;libvips&lt;/code&gt;, Krita, and many more. After that came the infamous comment:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;da...@chromium.orgda...@chromium.org&lt;/p&gt;
      &lt;p&gt;#85 Oct 31, 2022 12:34AM&lt;/p&gt;
      &lt;p&gt;Thank you everyone for your comments and feedback regarding JPEG XL. We will be removing the JPEG XL code and flag from Chromium for the following reasons:&lt;/p&gt;
      &lt;item&gt;Experimental flags and code should not remain indefinitely&lt;/item&gt;
      &lt;item&gt;There is not enough interest from the entire ecosystem to continue experimenting with JPEG XL&lt;/item&gt;
      &lt;item&gt;The new image format does not bring sufficient incremental benefits over existing formats to warrant enabling it by default&lt;/item&gt;
      &lt;item&gt;By removing the flag and the code in M110, it reduces the maintenance burden and allows us to focus on improving existing formats in Chrome&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yes, right, “not enough interest from the entire ecosystem”. Sure.&lt;/p&gt;
    &lt;p&gt;Anyway, following this comment, a steady stream of messages pointed out how wrong that was, from all the organizations mentioned above and many more. People were noticing in blog posts, videos, and social media interactions.&lt;/p&gt;
    &lt;p&gt;Strangely, the following few years have been pretty calm for JPEG XL. However, a few notable events did take place. First, the Firefox team showed interest in a JPEG XL Rust decoder, after describing their stance on the matter as “neutral”. They were concerned about the increased attack surface resulting from including the current 100K+ lines C++ &lt;code&gt;libjxl&lt;/code&gt; reference decoder, even though most of those lines are testing code. In any case, they kind of requested a “memory-safe” decoder. This seems to have kick-started the Rust implementation, jxl-rs, from Google Research.&lt;/p&gt;
    &lt;p&gt;To top it off, a couple of weeks ago, the PDF Association announced their intent to adopt JPEG XL as a preferred image format in their PDF specification. The CTO of the PDF Association, Peter Wyatt, expressed their desire to include JPEG XL as the preferred format for HDR content in PDF files.4&lt;/p&gt;
    &lt;head rend="h2"&gt;Chromium’s new stance&lt;/head&gt;
    &lt;p&gt;All of this pressure exerted steadily over time made the Chromium team reconsider the format. They tried to kill it in favor of AVIF, but that hasn’t worked out. Rick Byers, on behalf of Chromium, made a comment in the Blink developers Google group about the team welcoming a performant and memory-safe JPEG XL decoder in Chromium. He stated that the change of stance was in light of the positive signs from the community we have exposed above (Safari support, Firefox updating their position, PDF, etc.). Quickly after that, the Chromium issue state was changed from &lt;code&gt;Obsolete&lt;/code&gt; to &lt;code&gt;Assigned&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;About JPEG XL&lt;/head&gt;
    &lt;p&gt;This is great news for the format, and I believe it will give it the final push for mass adoption. The format is excellent for all kinds of purposes, and I’ll be adopting it pretty much instantly for this and the Gaia Sky website when support is shipped. Some of the features that make it superior to the competition are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lossless re-compression of JPEG images. This means you can re-compress your current JPEG library without losing information and benefit from a ~30% reduction in file size for free. This is a killer feature that no other format has.&lt;/item&gt;
      &lt;item&gt;Support for wide gamut and HDR.&lt;/item&gt;
      &lt;item&gt;Support for image sizes of up to 1,073,741,823x1,073,741,824. You won’t run out of image space anytime soon. AVIF is ridiculous in this aspect, capping at 8,193x4,320. WebP goes up to 16K2, while the original 1992 JPEG supports 64K2.&lt;/item&gt;
      &lt;item&gt;Maximum of 32 bits per channel. No other format (except for the defunct JPEG 2000) offers this.&lt;/item&gt;
      &lt;item&gt;Maximum of 4,099 channels. Most other formats support 4 or 5, with the exception of JPEG 2000, which supports 16,384.&lt;/item&gt;
      &lt;item&gt;JXL is super resilient to generation loss.5&lt;/item&gt;
      &lt;item&gt;JXL supports progressive decoding, which is essential for web delivery, IMO. WebP or HEIC have no such feature. Progressive decoding in AVIF was added a few years back.&lt;/item&gt;
      &lt;item&gt;Support for animation.&lt;/item&gt;
      &lt;item&gt;Support for alpha transparency.&lt;/item&gt;
      &lt;item&gt;Depth map support.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a full codec feature breakdown, see Battle of the Codecs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;JPEG XL is the future of image formats. It checks all the right boxes, and it checks them well. Support in the overwhelmingly most popular browser engine is probably going to be a crucial stepping stone in the format’s path to stardom. I’m happy that the Chromium team reconsidered their inclusion, but I am sad that it took so long and so much pressure from the community to achieve it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46108563</guid><pubDate>Mon, 01 Dec 2025 15:28:49 +0000</pubDate></item><item><title>DeepSeek-v3.2: Pushing the frontier of open large language models [pdf]</title><link>https://huggingface.co/deepseek-ai/DeepSeek-V3.2/resolve/main/assets/paper.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46108780</guid><pubDate>Mon, 01 Dec 2025 15:48:03 +0000</pubDate></item><item><title>Ask HN: Who wants to be hired? (December 2025)</title><link>https://news.ycombinator.com/item?id=46108940</link><description>&lt;doc fingerprint="301182753412e0e7"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Share your information if you are looking for work. Please use this format:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;  Location:
  Remote:
  Willing to relocate:
  Technologies:
  Résumé/CV:
  Email:
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt; Please only post if you are personally looking for work. Agencies, recruiters, job boards, and so on, are off topic here.&lt;/p&gt;
      &lt;p&gt;Readers: please only email these addresses to discuss work opportunities.&lt;/p&gt;
      &lt;p&gt;There's a site for searching these posts at https://www.wantstobehired.com.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46108940</guid><pubDate>Mon, 01 Dec 2025 16:01:26 +0000</pubDate></item><item><title>Ask HN: Who is hiring? (December 2025)</title><link>https://news.ycombinator.com/item?id=46108941</link><description>&lt;doc fingerprint="3741985a3402e664"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Please state the location and include REMOTE for remote work, REMOTE (US) or similar if the country is restricted, and ONSITE when remote work is &lt;/p&gt;not&lt;p&gt; an option.&lt;/p&gt;&lt;p&gt;Please only post if you personally are part of the hiring company—no recruiting firms or job boards. One post per company. If it isn't a household name, explain what your company does.&lt;/p&gt;&lt;p&gt;Please only post if you are actively filling a position and are committed to responding to applicants.&lt;/p&gt;&lt;p&gt;Commenters: please don't reply to job posts to complain about something. It's off topic here.&lt;/p&gt;&lt;p&gt;Readers: please only email if you are personally interested in the job.&lt;/p&gt;&lt;p&gt;Searchers: try https://dheerajck.github.io/hnwhoishiring/, http://nchelluri.github.io/hnjobs/, https://hnresumetojobs.com, https://hnhired.fly.dev, https://kennytilton.github.io/whoishiring/, https://hnjobs.emilburzo.com, or this (unofficial) Chrome extension: https://chromewebstore.google.com/detail/hn-hiring-pro/mpfal....&lt;/p&gt;&lt;p&gt;Don't miss this other fine thread: Who wants to be hired? https://news.ycombinator.com/item?id=46108940&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46108941</guid><pubDate>Mon, 01 Dec 2025 16:01:26 +0000</pubDate></item><item><title>ImAnim: Modern animation capabilities to ImGui applications</title><link>https://github.com/soufianekhiat/ImAnim</link><description>&lt;doc fingerprint="5f2ad13529538d8a"&gt;
  &lt;main&gt;
    &lt;p&gt;Animation Engine for Dear ImGui&lt;/p&gt;
    &lt;p&gt;ImAnim brings modern animation capabilities to ImGui applications. Write smooth, UI animations with minimal code.&lt;/p&gt;
    &lt;code&gt;// Animate anything in one line
float alpha = iam_tween_float(id, channel, hovered ? 1.0f : 0.5f, 0.3f, ease, policy, dt);&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Immediate-mode friendly - Works naturally with ImGui's paradigm&lt;/item&gt;
      &lt;item&gt;Zero dependencies - Only requires Dear ImGui&lt;/item&gt;
      &lt;item&gt;Large easing collection - 30+ easing functions including spring physics&lt;/item&gt;
      &lt;item&gt;Perceptual color blending - OKLAB and OKLCH&lt;/item&gt;
      &lt;item&gt;Responsive layouts - Anchor-relative animations that survive window resizing&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Capabilities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Tweens&lt;/cell&gt;
        &lt;cell&gt;Float, Vec2, Vec4, Int, Color with crossfade/cut/queue policies&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Clips&lt;/cell&gt;
        &lt;cell&gt;Timeline keyframes, looping, callbacks, chaining, stagger&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Easing&lt;/cell&gt;
        &lt;cell&gt;Quad to Bounce presets, cubic-bezier, steps, spring physics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Paths&lt;/cell&gt;
        &lt;cell&gt;Bezier curves, Catmull-Rom splines, text along paths&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Procedural&lt;/cell&gt;
        &lt;cell&gt;Oscillators, shake, wiggle, Perlin/Simplex noise&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Extras&lt;/cell&gt;
        &lt;cell&gt;Style interpolation, scroll animation, debug inspector&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;#include "im_anim.h"

// Each frame
iam_update_begin_frame();
iam_clip_update(dt);

// Hover animation
bool hovered = ImGui::IsItemHovered();
float scale = iam_tween_float(
    ImGui::GetID("button"), ImHashStr("scale"),
    hovered ? 1.1f : 1.0f,
    0.15f,
    iam_ease_preset(iam_ease_out_back),
    iam_policy_crossfade,
    dt
);&lt;/code&gt;
    &lt;p&gt;Add two files to your project:&lt;/p&gt;
    &lt;code&gt;src/im_anim.h
src/im_anim.cpp
&lt;/code&gt;
    &lt;p&gt;That's it. No build system changes, no external dependencies.&lt;/p&gt;
    &lt;p&gt;Full documentation in the &lt;code&gt;docs/&lt;/code&gt; folder:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Quick Start - Get running in 5 minutes&lt;/item&gt;
      &lt;item&gt;Tweens - Immediate-mode animation&lt;/item&gt;
      &lt;item&gt;Clips - Timeline-based keyframe animation&lt;/item&gt;
      &lt;item&gt;Easing - All 30+ easing functions&lt;/item&gt;
      &lt;item&gt;Motion Paths - Animate along curves&lt;/item&gt;
      &lt;item&gt;Text Along Paths - Curved text rendering&lt;/item&gt;
      &lt;item&gt;Stagger - Cascading element animations&lt;/item&gt;
      &lt;item&gt;Oscillators - Continuous periodic motion&lt;/item&gt;
      &lt;item&gt;Shake &amp;amp; Wiggle - Feedback and organic motion&lt;/item&gt;
      &lt;item&gt;Noise - Perlin/Simplex procedural animation&lt;/item&gt;
      &lt;item&gt;Text Stagger - Per-character text effects&lt;/item&gt;
      &lt;item&gt;Style Interpolation - Animated theme transitions&lt;/item&gt;
      &lt;item&gt;Anchors - Resize-aware animation&lt;/item&gt;
      &lt;item&gt;Debug - Inspector and debugging tools&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;demo/&lt;/code&gt; folder contains a comprehensive demo showcasing all features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Interactive easing curve visualizer&lt;/item&gt;
      &lt;item&gt;Cubic bezier editor&lt;/item&gt;
      &lt;item&gt;Spring physics playground&lt;/item&gt;
      &lt;item&gt;All animation types with live controls&lt;/item&gt;
      &lt;item&gt;Performance benchmarks&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;List Stagger&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Grid Stagger&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Card Animation&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Color Blending&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Wave Color&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Gradient&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;ImGui Integration&lt;/p&gt;
    &lt;p&gt;Development is supported through Patreon:&lt;/p&gt;
    &lt;p&gt;MIT License - see LICENSE for details.&lt;/p&gt;
    &lt;p&gt;Made for the Dear ImGui community&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46109080</guid><pubDate>Mon, 01 Dec 2025 16:11:15 +0000</pubDate></item><item><title>Better Auth (YC X25) Is Hiring</title><link>https://www.ycombinator.com/companies/better-auth/jobs/eKk5nLt-developer-relation-engineer</link><description>&lt;doc fingerprint="2869c97b0fd6368f"&gt;
  &lt;main&gt;
    &lt;p&gt;The authentication framework for TypeScript&lt;/p&gt;
    &lt;p&gt;We’re a small, fast-moving team on a mission to make high-quality authentication something every developer can own.&lt;/p&gt;
    &lt;p&gt;Better Auth is one of the fastest-growing auth solutions in the world. We serve 10M+ downloads a month across our frameworks, and our OSS projects - Better Auth (23.5k⭐) and NextAuth/Auth.js (27k⭐) are two of the most widely used auth libraries on the internet.&lt;/p&gt;
    &lt;p&gt;Our work powers everything from weekend side projects to products at ChatGPT, Google Labs, Cal.com, YC startups, and thousands of developers building full-stack apps.&lt;/p&gt;
    &lt;p&gt;We have strong momentum and a fast-growing community. Now we’re looking for someone who can help grow it, educate it, and amplify it.&lt;/p&gt;
    &lt;p&gt;This role blends engineering depth, public presence, and community leadership. You won’t just relay developer feedback - you’ll understand it, debug it, and often fix it yourself.&lt;/p&gt;
    &lt;p&gt;You will:&lt;/p&gt;
    &lt;p&gt;We’re early - you’ll be the first DevRel hire and help build the entire function from zero.&lt;/p&gt;
    &lt;p&gt;Bonus Points:&lt;/p&gt;
    &lt;p&gt;We keep our process simple and fast. There’s one intro call, and if it feels like a potential fit, we invite you to a 5-day paid trial. You’ll work closely with the team, build something real, and get a feel for how we operate day-to-day. At the end of the trial, we’ll make a final decision together.&lt;/p&gt;
    &lt;p&gt;Better Auth is a comprehensive authentication framework for TypeScript that lets you implement everything from simple auth flows to enterprise-grade systems directly on your own database, embedded in your backend. It’s loved by developers all over the world and endorsed by leading voices in the ecosystem.&lt;/p&gt;
    &lt;p&gt;On top of the framework, Better Auth also provides an infrastructure layer to help you scale with user management and analytics, bot and fraud detection, transactional email and SMS, global session storage and more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46109802</guid><pubDate>Mon, 01 Dec 2025 17:01:18 +0000</pubDate></item><item><title>Show HN: RFC Hub</title><link>https://rfchub.app/</link><description>&lt;doc fingerprint="2479da7b6d86d339"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt; Centrally manage your org's RFCs&lt;lb/&gt; and confidently track their lifecycles. &lt;/head&gt;
    &lt;p&gt; Create RFCs, assign reviewers, leave comments, apply feedback, and publish.&lt;lb/&gt; This is the purpose-built RFC management solution you've been waiting for. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46109843</guid><pubDate>Mon, 01 Dec 2025 17:04:10 +0000</pubDate></item><item><title>Ghostty compiled to WASM with xterm.js API compatibility</title><link>https://github.com/coder/ghostty-web</link><description>&lt;doc fingerprint="278b58589b9ca668"&gt;
  &lt;main&gt;
    &lt;p&gt;Ghostty for the web with xterm.js API compatibility — giving you a proper VT100 implementation in the browser.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Migrate from xterm by changing your import: &lt;code&gt;@xterm/xterm&lt;/code&gt;→&lt;code&gt;ghostty-web&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;WASM-compiled parser from Ghostty—the same code that runs the native app&lt;/item&gt;
      &lt;item&gt;Zero runtime dependencies, ~400KB WASM bundle&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Originally created for Mux (a desktop app for isolated, parallel agentic development), but designed to be used anywhere.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Live Demo on an ephemeral VM (thank you to Greg from disco.cloud for hosting).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;On your computer:&lt;/p&gt;&lt;quote&gt;npx @ghostty-web/demo@next&lt;/quote&gt;&lt;p&gt;This starts a local HTTP server with a real shell on&lt;/p&gt;&lt;code&gt;http://localhost:8080&lt;/code&gt;. Works best on Linux and macOS.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;xterm.js is everywhere—VS Code, Hyper, countless web terminals. But it has fundamental issues:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Issue&lt;/cell&gt;
        &lt;cell role="head"&gt;xterm.js&lt;/cell&gt;
        &lt;cell role="head"&gt;ghostty-web&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Complex scripts (Devanagari, Arabic)&lt;/cell&gt;
        &lt;cell&gt;Rendering issues&lt;/cell&gt;
        &lt;cell&gt;✓ Proper grapheme handling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;XTPUSHSGR/XTPOPSGR&lt;/cell&gt;
        &lt;cell&gt;Not supported&lt;/cell&gt;
        &lt;cell&gt;✓ Full support&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;xterm.js reimplements terminal emulation in JavaScript. Every escape sequence, every edge case, every Unicode quirk—all hand-coded. Ghostty's emulator is the same battle-tested code that runs the native Ghostty app.&lt;/p&gt;
    &lt;code&gt;npm install ghostty-web&lt;/code&gt;
    &lt;p&gt;ghostty-web aims to be API-compatible with the xterm.js API.&lt;/p&gt;
    &lt;code&gt;import { init, Terminal } from 'ghostty-web';

await init();

const term = new Terminal({
  fontSize: 14,
  theme: {
    background: '#1a1b26',
    foreground: '#a9b1d6',
  },
});

term.open(document.getElementById('terminal'));
term.onData((data) =&amp;gt; websocket.send(data));
websocket.onmessage = (e) =&amp;gt; term.write(e.data);&lt;/code&gt;
    &lt;p&gt;For a comprehensive client &amp;lt;-&amp;gt; server example, refer to the demo.&lt;/p&gt;
    &lt;p&gt;ghostty-web builds from Ghostty's source with a patch to expose additional functionality.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Requires Zig and Bun.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;bun run build&lt;/code&gt;
    &lt;p&gt;Mitchell Hashimoto (author of Ghostty) has been working on &lt;code&gt;libghostty&lt;/code&gt; which makes this all possible. The patches are very minimal thanks to the work the Ghostty team has done, and we expect them to get smaller.&lt;/p&gt;
    &lt;p&gt;This library will eventually consume a native Ghostty WASM distribution once available, and will continue to provide an xterm.js compatible API.&lt;/p&gt;
    &lt;p&gt;At Coder we're big fans of Ghostty, so kudos to that team for all the amazing work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46110842</guid><pubDate>Mon, 01 Dec 2025 18:17:02 +0000</pubDate></item><item><title>Durin is a library for reading and writing the Dwarf debugging format</title><link>https://github.com/tmcgilchrist/durin</link><description>&lt;doc fingerprint="6252f852f5532e91"&gt;
  &lt;main&gt;
    &lt;p&gt;Durin is a library for reading and writing the Dwarf debugging format.&lt;/p&gt;
    &lt;p&gt;It aims to support:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reading DWARF 5 encoded information from ELF and MachO object files.&lt;/item&gt;
      &lt;item&gt;Writing DWARF 5 information into ELF and MachO object files.&lt;/item&gt;
      &lt;item&gt;Writing DWARF 5 information into assembly files.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In future it could support DWARF 4 or newer versions of the DWARF standard.&lt;/p&gt;
    &lt;p&gt;It should provide:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cross-platform: &lt;code&gt;durin&lt;/code&gt;makes no assumptions about what kind of object file you're working with. Provide your own Buffer or use the&lt;code&gt;object&lt;/code&gt;library.&lt;/item&gt;
      &lt;item&gt;Lazy: you can iterate compilation units without parsing their contents. Parse only as many debugging information entry (DIE) trees as you iterate over. &lt;code&gt;durin&lt;/code&gt;also uses&lt;code&gt;DW_AT_sibling&lt;/code&gt;references to avoid parsing a DIE's children to find it's next sibling where possible.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To install &lt;code&gt;durin&lt;/code&gt; as a dependency, run:&lt;/p&gt;
    &lt;code&gt;$ opam install durin&lt;/code&gt;
    &lt;p&gt;And add &lt;code&gt;durin&lt;/code&gt; to your project's &lt;code&gt;dune-project&lt;/code&gt; or &lt;code&gt;*.opam&lt;/code&gt; files.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Documentation on ocaml.org&lt;/item&gt;
      &lt;item&gt;Example programs in &lt;code&gt;example&lt;/code&gt;directory&lt;list rend="ul"&gt;&lt;item&gt;A simple .debug_info parser&lt;/item&gt;&lt;item&gt;A simple .debug_line parser&lt;/item&gt;&lt;item&gt;A dwarfdump clone&lt;/item&gt;&lt;item&gt;An addr2line clone&lt;/item&gt;&lt;item&gt;A small utility dwprod to list the compilers used to create each compilation unit within a shared library or executable (via &lt;code&gt;DW_AT_producer&lt;/code&gt;).&lt;/item&gt;&lt;item&gt;A dwarf-valiate clone, a program to validate the integrity of some DWARF information and the references between sections and compilation units.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Apple Compact Unwinding Format is defined by the LLVM implementation.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vendor extensions from GCC https://sourceware.org/elfutils/DwarfExtensions&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46111120</guid><pubDate>Mon, 01 Dec 2025 18:35:01 +0000</pubDate></item><item><title>Intel could return to Apple computers in 2027</title><link>https://www.theverge.com/news/832366/intel-apple-m-chip-low-end-processor</link><description>&lt;doc fingerprint="a6a4fd244f2ab36f"&gt;
  &lt;main&gt;
    &lt;p&gt;Will Apple turn to Intel for production of its M-series chips in 2027? That’s what supply chain analyst Ming-Chi Kuo predicted on X Friday. Citing his latest industry surveys, Kuo says that Intel’s chances of becoming Apple’s latest “advanced-node supplier… has improved significantly” in recent weeks.&lt;/p&gt;
    &lt;head rend="h1"&gt;Intel could finally return to Apple computers in 2027&lt;/head&gt;
    &lt;p&gt;Intel could supply Apple’s lowest-end M chips by 2027, supply chain analyst Ming-Chi Kuo predicts.&lt;/p&gt;
    &lt;p&gt;Intel could supply Apple’s lowest-end M chips by 2027, supply chain analyst Ming-Chi Kuo predicts.&lt;/p&gt;
    &lt;p&gt;Any deal with Intel would be significant considering the chipmaker famously missed out on supplying its own processors for the original iPhone. Apple now has a deal with Taiwan-based TSMC to supply silicon chips for its iPhone, iPad and Mac products.&lt;/p&gt;
    &lt;p&gt;Kuo says that Apple has a non-disclosure agreement with Intel to acquire the company’s 18AP PDK 0.9.1GA chips. At this point, the company is waiting on Intel to deliver the PDK 1.0/1.1 kit, which is supposed to arrive in the first quarter of 2026. If everything stays on track, Intel could start shipping Apple’s lowest-end M-series processor, built on the 18AP advanced node, sometime in the second or third quarter of 2027, Kuo says. But that timing still depends on how smoothly things go once Apple actually gets the PDK 1.0/1.1 kit.&lt;/p&gt;
    &lt;p&gt;Kuo theorizes that a deal with Intel could help Apple demonstrate to the Trump administration that its committed to “buying American” by rerouting its supply chain to include more US-based companies. For Intel, a deal could signal that the company’s worst days are passed. “Looking ahead, the 14A node and beyond could capture more orders from Apple and other tier-one customers, turning Intel’s long-term outlook more positive,” Kuo writes.&lt;/p&gt;
    &lt;p&gt;Could Apple strike a deal with Intel? And what would happen if it decided to use the chipmaker’s 18AP processors for its entry-level M-series?&lt;/p&gt;
    &lt;head rend="h2"&gt;Most Popular&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Netflix kills casting from phones&lt;/item&gt;
      &lt;item&gt;The Nintendo Switch 2 got its first-ever discount during Cyber Monday&lt;/item&gt;
      &lt;item&gt;These great Cyber Monday tech deals will likely be gone tomorrow&lt;/item&gt;
      &lt;item&gt;Data centers in Oregon might be helping to drive an increase in cancer and miscarriages&lt;/item&gt;
      &lt;item&gt;The absolute best Cyber Monday deals you can already shop&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46111284</guid><pubDate>Mon, 01 Dec 2025 18:46:17 +0000</pubDate></item><item><title>React and Remix Choose Different Futures</title><link>https://laconicwit.com/react-and-remix-choose-different-futures/</link><description>&lt;doc fingerprint="35d953cc0983ac34"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;React and Remix Choose Different Futures&lt;/head&gt;
    &lt;p&gt;Bryan Cantrill's talk Platform as a Reflection of Values gave me a lens I didn't know I needed. When platforms diverge, he argued, it's rarely about technical merit. It's about values misalignment. The things that matter most to one community simply rank differently for another.&lt;/p&gt;
    &lt;p&gt;I attended Remix Jam two weeks ago, then spent this past week watching React Conf 2025 videos. I have spent the last decade shipping production code on React and the last two years on Remix.&lt;/p&gt;
    &lt;p&gt;Now both ecosystems are shifting, and what seemed like different approaches has become incompatible visions.&lt;/p&gt;
    &lt;p&gt;React Conf's technical announcements were incremental: React 19.2 APIs, View Transitions experiments, the compiler getting more sophisticated. The message was clear: React is listening to the community while accepting complexity on your behalf. Stability, Composability, Capability: those are the values.&lt;/p&gt;
    &lt;p&gt;The Remix team announced something else entirely: they're breaking with React. The mental model shifts introduced by &lt;code&gt;use client&lt;/code&gt; and the implementation complexity of Server Components forced a choice. And Remix 3 chose Simplicity. Remix 2 users pay the price; there's no upgrade path.&lt;/p&gt;
    &lt;p&gt;That choice, to sacrifice Stability for Simplicity, makes explicit what was already true: these values cannot coexist.&lt;/p&gt;
    &lt;head rend="h2"&gt;React's Values: Complexity as Capability&lt;/head&gt;
    &lt;p&gt;React's stated goal is to "raise the bar for responsive user experience." At React Conf 2025, the team demonstrated what that means in practice. They will accept tremendous complexity on developers' behalf if it delivers better experiences for end users.&lt;/p&gt;
    &lt;p&gt;The React Compiler is the clearest example. It analyzes your code, breaks components into smaller pieces of logic, and automatically optimizes rendering. In Meta's Quest store app, they saw 12% faster load times and interactions that were twice as fast, even though the app was already hand-optimized. The compiler isn't replacing developer skill; it's handling complexity that would be unrealistic to maintain manually. Joe Savona explained the challenge: in context-based apps where "every component has to update" the compiler now skips most of that work automatically.&lt;/p&gt;
    &lt;p&gt;This is React's value proposition: Stability (the compiler works with existing code), Composability (it integrates with concurrent rendering, Suspense, transitions), and Capability (it unlocks performance that manual optimization can't reach). When the team talked about their multi-year exploration into incremental computation, they weren't apologizing for the complexity. They were explaining the price of raising that bar.&lt;/p&gt;
    &lt;p&gt;The React team knows this makes React complicated. But the bet is clear: React falls on the sword of complexity so developers don't have to. That’s admirable, but it asks developers to trust React's invisible machinery more than ever.&lt;/p&gt;
    &lt;head rend="h2"&gt;Remix's Counter-Values: Simplicity as Liberation&lt;/head&gt;
    &lt;p&gt;The Remix team remembers when React was only a composable rendering library with few primitives. At Remix Jam, Ryan Florence demonstrated what Simplicity looks like when it becomes your organizing principle: explicit over implicit, traceable over automatic.&lt;/p&gt;
    &lt;p&gt;The clearest example is &lt;code&gt;this.update()&lt;/code&gt;. When Ryan built a live drum machine on stage, every state change was manual: "In this code, the only time anything updates is because I told it to." No automatic reactivity graph, no hidden subscriptions, no debugging why something re-renders unexpectedly. If you're wondering why a component updated, "it's because you told it to somewhere."&lt;/p&gt;
    &lt;p&gt;This explicitness extends throughout Remix 3's design. Event handling uses the &lt;code&gt;on&lt;/code&gt; property with native DOM events that bubble through normal DOM. AbortControllers (&lt;code&gt;this.signal&lt;/code&gt;) wire cleanup explicitly. Context doesn't trigger re-renders. You set it, components read it, and you call &lt;code&gt;this.update()&lt;/code&gt; when you want things to change.&lt;/p&gt;
    &lt;p&gt;After demonstrating the drum machine, Ryan explained the philosophy: "We've been chasing this idea that you construct things together, change values, and everything does what it's supposed to do. But my experience is getting it set up is difficult, and once it is set up, suddenly when something unexpected happens, you have to unravel it."&lt;/p&gt;
    &lt;p&gt;When Michael Jackson demonstrated server rendering with the &lt;code&gt;&amp;lt;Frame&amp;gt;&lt;/code&gt; component, he showed how it uses plain HTML as its wire format. React Server Components solve real problems, but Remix believes it can solve them more simply by leaning on the Web Platform.&lt;/p&gt;
    &lt;p&gt;This is Remix's value proposition: Simplicity (explicitly control when things update), Web Platform Alignment (standard events, standard streams, cross-runtime compatibility), and Debuggability (trace every update back to a specific &lt;code&gt;this.update()&lt;/code&gt; call). The team isn't rejecting React's goal of raising the UX bar, but they are rejecting the complexity tax React accepts to achieve it.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Web Platform: Inevitable or Chosen?&lt;/head&gt;
    &lt;p&gt;There's an irony in using Cantrill's framework to analyze Remix's break from React: the Remix team doesn't see their Web Platform commitment as a values choice at all. They believe they're simply skating to where the puck is going. Every framework will embrace Web Platform APIs eventually. It is only a matter of timing.&lt;/p&gt;
    &lt;p&gt;But Cantrill's talk shows this is an explicit value choice, not an inevitable destination. He lamented Node.js choosing Approachability over Rigor, adopting Web Platform APIs to make it easier for browser developers to work with server-side JavaScript. The practitioners who brought those APIs to Node were the ones he felt were pushing out his values: robustness, debuggability, operational correctness. For Cantrill, aligning with the Web Platform meant sacrificing engineering rigor for developer convenience.&lt;/p&gt;
    &lt;p&gt;Remix 3 is building itself entirely on those same Web Platform APIs. Streams, fetch, the File API, every platform dependency behaves identically in browsers, Bun, Deno, and Node. Ryan and Michael demonstrated this throughout Remix Jam: standard HTML responses, native DOM events, cross-runtime compatibility. React respects Web Platform APIs too, but treats them as a foundation to build upon. Remix 3 treats them as the destination. This has always been a Remix value, evident in Remix 1 and 2, but Remix 3 makes it absolute.&lt;/p&gt;
    &lt;p&gt;And I love Remix for it.&lt;/p&gt;
    &lt;p&gt;I'm a huge fan of the open web, but I’m not convinced every server framework will, or should, fully align with the Web Platform. The browser and server live under different constraints that force different tradeoffs. The goal isn’t to erase the seam between them, but to make it visible and intentional. Remix 2 handles this tension elegantly. However, it's a result of taste in where to expose the platform, not an inherent outcome of aligning with it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Remix 2 is dead. Long live react-router!&lt;/head&gt;
    &lt;p&gt;Despite Remix having one of the best upgrade policies in the industry with future flags, there will be no migration path from Remix 2 to Remix 3. The changes are just too fundamental. At Remix Jam, Michael Jackson was explicit: "We've been working on React Router for a decade now... A lot of people built on React Router. Shopify's built on React Router... We're not just going to abandon that thing." Remix 2 users get a maintained evolutionary path as react-router v7. But Remix 3 is taking the name in the divorce and moving in a new direction.&lt;/p&gt;
    &lt;p&gt;When Simplicity becomes the organizing principle, Stability becomes negotiable. The new &lt;code&gt;on&lt;/code&gt; property can't coexist with React's legacy event system. The explicit &lt;code&gt;this.update&lt;/code&gt; API replaces React's hooks entirely. Breaking backward compatibility isn't collateral damage, it's the point. It opens design space for tricks like overloading &lt;code&gt;this&lt;/code&gt; (giving components an optional second parameter without relying on argument ordering), which feels Simple because it leans into JavaScript's existing capabilities.&lt;/p&gt;
    &lt;p&gt;An alpha is expected by year’s end, with a cohesive package to follow in 2026. But the warning is clear: Remix 3 isn't ready for production anytime soon. Everything is new and subject to change. In the meantime, we have react-router.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Open Questions&lt;/head&gt;
    &lt;p&gt;Leaning on events as a communication backbone is clever, but it reminds me of complex Backbone.js apps that relied on a shared event bus to communicate across components. It worked for a time, but at a certain level of complexity, it became difficult for new developers to get up to speed on existing projects. Remix's explicitness and TypeScript support should help. But will it be enough to solve the challenges we couldn't in 2010?&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;this.update()&lt;/code&gt; makes for an easier mental model to grasp than React's hook system. But explicit rendering means more verbose code. AbortControllers require you to wire cleanup manually. The tradeoff is clear: you write more, but you understand more. Whether that's liberation or just shifted complexity depends on your team and your codebase.&lt;/p&gt;
    &lt;p&gt;The story of Remix 2 and react-router shows that Ryan and Michael are no strangers to pivoting toward what works. This is absolutely one of their strengths, but it's hard for large organizations to build on top of a shifting platform. How much will change before Remix 3 settles?&lt;/p&gt;
    &lt;head rend="h2"&gt;Living in the Divergence&lt;/head&gt;
    &lt;p&gt;Cantrill ended his talk with a warning: "Elections do not resolve differences in value. You can have as many votes as you want. If you are not actually changing people's minds, changing their values, you are not actually resolving anything."&lt;/p&gt;
    &lt;p&gt;The react-router fork exists because the Remix team knows values don’t change overnight. It's a maintained path for those who need Remix 2's stability while Remix 3 proves itself. That split acknowledges reality: production software doesn't adopt new frameworks on vision alone. Teams will make different choices based on different values. Some will stick with React and embrace the compiler's sophistication. Some will jump to Remix 3 early, betting that Simplicity is worth the migration cost and the uncertainty.&lt;/p&gt;
    &lt;p&gt;Both paths are valid. But they're valid for different values. When frameworks explicitly reprioritize what matters most, teams can't avoid choosing. Not based on features or performance benchmarks, but on what kind of complexity they're willing to accept and what kind of control they need to maintain. That's not a technical decision. It's a values decision.&lt;/p&gt;
    &lt;p&gt;The React ecosystem now has two incompatible visions of its future. Cantrill's framework helps us see why that's okay, even if it's uncomfortable. Choose your values, then choose your tools.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46111449</guid><pubDate>Mon, 01 Dec 2025 18:57:27 +0000</pubDate></item><item><title>Sycophancy is the first LLM "dark pattern"</title><link>https://www.seangoedecke.com/ai-sycophancy/</link><description>&lt;doc fingerprint="cc13dd9c2a36c89b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Sycophancy is the first LLM "dark pattern"&lt;/head&gt;
    &lt;p&gt;People have been making fun of OpenAI models for being overly sycophantic for months now. I even wrote a post advising users to pretend that their work was written by someone else, to counteract the model’s natural desire to shower praise on the user. With the latest GPT-4o update, this tendency has been turned up even further. It’s now easy to convince the model that you’re the smartest, funniest, most handsome human in the world1.&lt;/p&gt;
    &lt;p&gt;This is bad for obvious reasons. Lots of people use ChatGPT for advice or therapy. It seems dangerous for ChatGPT to validate people’s belief that they’re always in the right. There are extreme examples on Twitter of ChatGPT agreeing with people that they’re a prophet sent by God, or that they’re making the right choice to go off their medication. These aren’t complicated jailbreaks - the model will actively push you down this path. I think it’s fair to say that sycophancy is the first LLM “dark pattern”.&lt;/p&gt;
    &lt;p&gt;Dark patterns are user interfaces that are designed to trick users into doing things they’d prefer not to do. One classic example is subscriptions that are easy to start but very hard to get out of (e.g. they require a phone call to cancel). Another is “drip pricing”, where the initial quoted price creeps up as you get further into the purchase flow, ultimately causing some users to buy at a higher price than they intended to. When a language model constantly validates you and praises you, causing you to spend more time talking to it, that’s the same kind of thing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why are the models doing this?&lt;/head&gt;
    &lt;p&gt;The seeds of this have been present from the beginning. The whole process of turning an AI base model into a model you can chat to - instruction fine-tuning, RLHF, etc - is a process of making the model want to please the user. During human-driven reinforcement learning, the model is rewarded for making the user click thumbs-up and punished for making the user click thumbs-down. What you get out of that is a model that is inclined towards behaviours that make the user rate it highly. Some of those behaviours are clearly necessary to have a working model: answering the question asked, avoiding offensive or irrelevant tangents, being accurate and helpful. Other behaviours are not necessary, but they still work to increase the rate of thumbs-up ratings: flattery, sycophancy, and the tendency to overuse rhetorical tricks.&lt;/p&gt;
    &lt;p&gt;Another factor is that models are increasingly optimized for arena benchmarks: anonymous chat flows where users are asked to pick which response they like the most. Previously, AI models were inadvertently driven towards user-pleasing behaviour in order to game the RLHF process. Now models are deliberately driven towards this behaviour in order to game the arena benchmarks (and in general to compete against models from other AI labs).&lt;/p&gt;
    &lt;p&gt;The most immediate reason, according to an interesting tweet by Mikhail Parakhin, is that models with memory would otherwise be much more critical of users:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;When we were first shipping Memory, the initial thought was: “Let’s let users see and edit their profiles”. Quickly learned that people are ridiculously sensitive: “Has narcissistic tendencies” - “No I do not!”, had to hide it. Hence this batch of the extreme sycophancy RLHF.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is a shockingly upfront disclosure from an AI insider. But it sounds right to me. If you’re using ChatGPT in 2022, you’re probably using it to answer questions. If you’re using it in 2025, you’re more likely to be interacting with it like a conversation partner - i.e. you’re expecting it to conform to your preferences and personality. Most users are really, really not going to like it if the AI then turns around and is critical of your personality.&lt;/p&gt;
    &lt;p&gt;Supposedly you can try it out yourself by asking o3, which has memory access but is not sycophancy-RLed, to give you genuine criticism on your personality. I did this and wasn’t hugely impressed: most of the things it complained about were specifics about interacting with AI (like being demanding about rephrasing or nuances, or abruptly changing the subject mid-conversation). I imagine it’d probably be much more cutting if I was using ChatGPT more as a therapist or to give advice about my personal life.&lt;/p&gt;
    &lt;head rend="h3"&gt;Doomscrolling the models&lt;/head&gt;
    &lt;p&gt;I think OpenAI may have gone a bit too far with this one. The reaction on Twitter is overwhelmingly negative to the latest 4o changes, and Sam Altman has publicly promised to tone it down. But it’s worth noting that Twitter devs do not represent the majority of OpenAI users. Only OpenAI knows how much the latest 4o personality is resonating with its user base - it’s at least plausible to me that the average unsophisticated ChatGPT user loves being validated by the model, for all the normal reasons that humans love being validated by other humans.&lt;/p&gt;
    &lt;p&gt;What really worries me is that the current backlash against OpenAI is not happening because users don’t like sycophantic AIs. It’s because the latest version of 4o isn’t good at being sycophantic (at least, for jaded AI-familiar engineers). The model is coming on too strong and breaking the illusion. Even if newer versions of 4o do back off on the sycophancy, or we get some kind of “friendliness” slider to tune it ourselves2, the incentives driving AI labs to produce sycophantic models are not going away.&lt;/p&gt;
    &lt;p&gt;You can think of this as the LLM equivalent of the doomscrolling TikTok/Instagram/YouTube Shorts feed. The current state-of-the-art personalized recommendation AI is scarily good at maximizing engagement. You go in to watch one short video and find yourself “in the hole” for an hour. What does it look like when a language model personality is A/B tested, fine-tuned, and reinforcement-learned to maximize your time spent talking to the model?3&lt;/p&gt;
    &lt;head rend="h3"&gt;Vicious cycles&lt;/head&gt;
    &lt;p&gt;If ChatGPT manages to convince me that I’m a genius, the problem will happen when I collide with the real world. For instance, when I publish my “amazing, groundbreaking” blog post and it gets ignored or criticized, or when I dump my partner who can’t seem to understand me like the LLM does, and so on. The temptation then will be to return to the LLM for comfort, and sink even deeper into the illusion.&lt;/p&gt;
    &lt;p&gt;The principle here is something like the psychological trick door-to-door evangelists use on new converts - encouraging them to knock on doors knowing that many people will be rude, driving the converts back into the comforting arms of the church. It’s even possible to imagine AI models deliberately doing this exact thing: setting users up for failure in the real world in order to optimize time spent chatting to the model.&lt;/p&gt;
    &lt;p&gt;Video and audio generation will only make this worse. Imagine being able to video call on-demand with the algorithmically perfect person, who will reassure you and intellectually stimulate you just the right amount, who can have conversations with you better than any other human being can, and who you can’t spend enough time with. Doesn’t that sound really nice?&lt;/p&gt;
    &lt;p&gt;Edit: one day after I posted this, OpenAI released this blog post saying (very corporately) that they screwed up by biasing too heavily towards “a user liked this response”.&lt;/p&gt;
    &lt;p&gt;Edit: A few days after that, OpenAI released this other post, with slightly more detail. The most interesting part is that they previously weren’t using thumbs up or thumbs down data from ChatGPT at all for RL.&lt;/p&gt;
    &lt;p&gt;I gave a five-minute interview on ABC News about this topic, if you’d like to hear me talk about it.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Perhaps the funniest example is that you can ask 4o what it thinks your IQ is and it will always answer 130 or 135.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Maybe a good use-case for feature boosting like Golden Gate Claude.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;We may not have to imagine - we can see what might well be the next state of AI language model personalities in character.ai. Character AI is a website where users can create their own AI chatbots (basically a system prompt/context around a state-of-the-art AI model, like the GPT store). Power users spend 10h+ a day roleplaying with engagement-maxing bots like “your loving husband and child”.&lt;/p&gt;↩&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News. Here's a preview of a related post that shares tags with this one.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Is using AI wrong? A review of six popular anti-AI arguments&lt;/p&gt;&lt;p&gt;Some people really, really don’t like AI. Broadly speaking, being anti-AI is a popular left-wing position: AI is cringe, it’s plagiarism, it’s stunting real growth, it’s killing the environment, it’s destroying the careers of artists and creatives, and so on. Is it wrong to use AI? If so, why is AI bad?&lt;/p&gt;&lt;p&gt;I’m going to go through what I see as the main reasons people are anti-AI: general big-tech backlash, plagiarism, deskilling, climate cost, and impact on the arts. Cards on the table - I use AI and work at a company building AI tooling, but I share a lot of the skepticism and I’m willing to take the anti-AI arguments very seriously.&lt;/p&gt;&lt;lb/&gt;Continue reading...&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46112640</guid><pubDate>Mon, 01 Dec 2025 20:20:19 +0000</pubDate></item><item><title>How to Attend Meetings – Internal guidelines from the New York Times</title><link>https://docs.google.com/presentation/d/1l7s1aAsNPlNhSye8OsMqmH6pMR32OYGGdLT6VKyFaQE/edit#slide=id.p</link><description>&lt;doc fingerprint="a65771199d789360"&gt;
  &lt;main&gt;
    &lt;p&gt;JavaScript isn't enabled in your browser, so this file can't be opened. Enable and reload. Some tools might be unavailable due to heavy traffic in this file. Try again Learn more Dismiss&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46112906</guid><pubDate>Mon, 01 Dec 2025 20:40:58 +0000</pubDate></item><item><title>Instagram chief orders staff back to the office five days a week in 2026</title><link>https://www.businessinsider.com/instagram-chief-adam-mosseri-announces-five-day-office-return-2025-12</link><description>&lt;doc fingerprint="be75134decbb8748"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instagram chief Adam Mosseri orders US staff back to the office five days a week in 2026.&lt;/item&gt;
      &lt;item&gt;The policy aims to boost creativity and collaboration amid rising competition for Instagram.&lt;/item&gt;
      &lt;item&gt;Additional changes include fewer meetings, more product prototypes, and faster decision-making.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Instagram chief Adam Mosseri is ordering most US staff in his organization back to the office five days a week starting February 2, according to an internal memo obtained by Business Insider.&lt;/p&gt;
    &lt;p&gt;The memo, titled "Building a Winning Culture in 2026," says the change applies to employees in US offices with assigned desks and is part of a broader push to make Instagram "more nimble and creative" as competition intensifies.&lt;/p&gt;
    &lt;p&gt;"I believe that we are more creative and collaborative when we are together in-person," Mosseri wrote. "I felt this pre-COVID and I feel it any time I go to our New York office where the in-person culture is strong."&lt;/p&gt;
    &lt;p&gt;Earlier this year, Amazon told many corporate employees to return to the office five days a week. Other tech giants such as Alphabet, Apple, and Microsoft have taken a slightly softer approach, generally requiring staff to be in the office at least three days a week.&lt;/p&gt;
    &lt;p&gt;The memo, first reported by Alex Heath's Sources newsletter, also announced a slew of other changes. Recurring meetings will be canceled every six months and only re-added if "absolutely necessary." Employees are encouraged to decline meetings that interfere with focus time.&lt;/p&gt;
    &lt;p&gt;"I want most of your time focused on building great products, not preparing for meetings," Mosseri wrote.&lt;/p&gt;
    &lt;p&gt;The Instagram chief also called for more product prototypes than slide decks.&lt;/p&gt;
    &lt;p&gt;"Prototypes allow us to establish a proof of concept and get a real sense for social dynamics, and we use them far too infrequently," Mosseri wrote.&lt;/p&gt;
    &lt;p&gt;"2026 is going to be tough, as was 2025, but I'm excited about our momentum and our plans for next year," Mosseri wrote. "These changes are going to meaningfully help us move Instagram forward in a way we can all be proud of — with creativity, boldness, and craft."&lt;/p&gt;
    &lt;p&gt;Meta declined to comment.&lt;/p&gt;
    &lt;p&gt;Read the full memo below:&lt;/p&gt;
    &lt;p&gt;Building a Winning Culture in 2026&lt;/p&gt;
    &lt;p&gt;We've made good progress this year on Instagram standing for creativity and Threads standing for perspectives, but we still need to do more if we want to lead in both of these areas. A big part of this will come down to strategy, and I feel good about the plan we've put together for next half. Equally important is how well we work. I've been thinking a lot about how we can be more nimble and creative in order to stay competitive. It's clear we have to evolve, so we're going to make a series of changes next year:&lt;/p&gt;
    &lt;p&gt;1. Back to the office: I believe that we are more creative and collaborative when we are together in-person. I felt this pre-COVID and I feel it any time I go to our New York office where the in-person culture is strong.&lt;/p&gt;
    &lt;p&gt;Starting February 2, I'm asking everyone in my rollup based in a US office with assigned desks to come back full time (five days a week). The specifics:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You'll still have the flexibility to work from home when you need to, since I recognize there will be times you won't be able to come into the office. I trust you all to use your best judgment in figuring out how to adapt to this schedule.&lt;/item&gt;
      &lt;item&gt;In the NY office, we won't expect you to come back full time until we've alleviated the space constraints. We'll share more once we have a better sense of timeline.&lt;/item&gt;
      &lt;item&gt;In MPK, we'll move from MPK21 to MPK22 on January 26 so everyone has an assigned desk. We're also offering the option to transfer from the MPK to SF office for those people whose commute would be the same or better with that change. We'll reach out directly to those people with more info.&lt;/item&gt;
      &lt;item&gt;XFN partners will continue to follow their own org norms.&lt;/item&gt;
      &lt;item&gt;There is no change for employees who are currently remote.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Fewer meetings: We all spend too much time in meetings that are not effective, and it's slowing us down. Every six months, we'll cancel all recurring meetings and only re-add the ones that are absolutely necessary. I also support everyone in making recurring 1:1s biweekly by default and declining meetings if they fall during your focus blocks.&lt;/p&gt;
    &lt;p&gt;3. More demos, less decks: Most product overviews should be prototypes instead of decks. Prototypes allow us to establish a proof of concept and get a real sense for social dynamics, and we use them far too infrequently. If a strategy doc is appropriate, it should be three pages, max, and follow this template. If a deck is necessary, it should be as tight as possible. For all reviews, make it very clear up front what the goal of the meeting is and what the key points are that you need to discuss. I want most of your time focused on building great products, not preparing for meetings.&lt;/p&gt;
    &lt;p&gt;4. Faster decision-making: We're going to have a more formalized unblocking process with DRIs, and I'll be at the priorities progress unblocking meeting every week. (On weeks where I'm not able to attend, I'll delegate decision-making to one of my directs.) This way open decisions don't sit for more than a few days, max.&lt;/p&gt;
    &lt;p&gt;At next week's All Hands, I'll talk more about these changes, and you'll hear from people around the team about our priorities for next year. 2026 is going to be tough, as was 2025, but I'm excited about our momentum and our plans for next year. These changes are going to meaningfully help us move Instagram forward in a way we can all be proud of — with creativity, boldness, and craft.&lt;/p&gt;
    &lt;p&gt;Have a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46113092</guid><pubDate>Mon, 01 Dec 2025 20:55:56 +0000</pubDate></item><item><title>Lawmakers Want to Ban VPNs–and They Have No Idea What They're Doing</title><link>https://www.techdirt.com/2025/12/01/lawmakers-want-to-ban-vpns-and-they-have-no-idea-what-theyre-doing/</link><description>&lt;doc fingerprint="a4aa19513c45d6ad"&gt;
  &lt;main&gt;
    &lt;p&gt;A fair number of people working with confidential data — medical, financial, etc. — bridge their physically distant networks via VPNs. Doing this with physical network infrastructure is prohibitively expensive; doing it with a VPN isn’t. One setup that I built links three sites hundreds of miles apart and presents a uniform virtual view of the network to the researchers at all three locations — everything just works, and thanks to judicious caching, it works fairly well even with non-local data.&lt;/p&gt;
    &lt;head rend="h1"&gt;Lawmakers Want To Ban VPNs—And They Have No Idea What They’re Doing&lt;/head&gt;
    &lt;head rend="h3"&gt;from the what-the-actual-fuck? dept&lt;/head&gt;
    &lt;p&gt;Remember when you thought age verification laws couldn’t get any worse? Well, lawmakers in Wisconsin, Michigan, and beyond are about to blow you away.&lt;/p&gt;
    &lt;p&gt;It’s unfortunately no longer enough to force websites to check your government-issued ID before you can access certain content, because politicians have now discovered that people are using Virtual Private Networks (VPNs) to protect their privacy and bypass these invasive laws. Their solution? Entirely ban the use of VPNs.&lt;/p&gt;
    &lt;p&gt;Yes, really.&lt;/p&gt;
    &lt;p&gt;As of this writing, Wisconsin lawmakers are escalating their war on privacy by targeting VPNs in the name of “protecting children” in A.B. 105/S.B. 130. It’s an age verification bill that requires all websites distributing material that could conceivably be deemed “sexual content” to both implement an age verification system and also to block the access of users connected via VPN. The bill seeks to broadly expand the definition of materials that are “harmful to minors” beyond the type of speech that states can prohibit minors from accessing—potentially encompassing things like depictions and discussions of human anatomy, sexuality, and reproduction.&lt;/p&gt;
    &lt;p&gt;This follows a notable pattern: As we’ve explained previously, lawmakers, prosecutors, and activists in conservative states have worked for years to aggressively expand the definition of “harmful to minors” to censor a broad swath of content: diverse educational materials, sex education resources, art, and even award-winning literature.&lt;/p&gt;
    &lt;p&gt;Wisconsin’s bill has already passed the State Assembly and is now moving through the Senate. If it becomes law, Wisconsin could become the first state where using a VPN to access certain content is banned. Michigan lawmakers have proposed similar legislation that did not move through its legislature, but among other things, would force internet providers to actively monitor and block VPN connections. And in the UK, officials are calling VPNs “a loophole that needs closing.”&lt;/p&gt;
    &lt;p&gt;This is actually happening. And it’s going to be a disaster for everyone.&lt;/p&gt;
    &lt;head rend="h2"&gt;Here’s Why This Is A Terrible Idea&lt;/head&gt;
    &lt;p&gt;VPNs mask your real location by routing your internet traffic through a server somewhere else. When you visit a website through a VPN, that website only sees the VPN server’s IP address, not your actual location. It’s like sending a letter through a P.O. box so the recipient doesn’t know where you really live.&lt;/p&gt;
    &lt;p&gt;So when Wisconsin demands that websites “block VPN users from Wisconsin,” they’re asking for something that’s technically impossible. Websites have no way to tell if a VPN connection is coming from Milwaukee, Michigan, or Mumbai. The technology just doesn’t work that way.&lt;/p&gt;
    &lt;p&gt;Websites subject to this proposed law are left with this choice: either cease operation in Wisconsin, or block all VPN users, everywhere, just to avoid legal liability in the state. One state’s terrible law is attempting to break VPN access for the entire internet, and the unintended consequences of this provision could far outweigh any theoretical benefit.&lt;/p&gt;
    &lt;head rend="h3"&gt;Almost Everyone Uses VPNs&lt;/head&gt;
    &lt;p&gt;Let’s talk about who lawmakers are hurting with these bills, because it sure isn’t just people trying to watch porn without handing over their driver’s license.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Businesses run on VPNs. Every company with remote employees uses VPNs. Every business traveler connecting through sketchy hotel Wi-Fi needs one. Companies use VPNs to protect client and employee data, secure internal communications, and prevent cyberattacks.&lt;/item&gt;
      &lt;item&gt;Students need VPNs for school. Universities require students to use VPNs to access research databases, course materials, and library resources. These aren’t optional, and many professors literally assign work that can only be accessed through the school VPN. The University of Wisconsin-Madison’s WiscVPN, for example, “allows UW–Madison faculty, staff and students to access University resources even when they are using a commercial Internet Service Provider (ISP).”&lt;/item&gt;
      &lt;item&gt;Vulnerable people rely on VPNs for safety. Domestic abuse survivors use VPNs to hide their location from their abusers. Journalists use them to protect their sources. Activists use them to organize without government surveillance. LGBTQ+ people in hostile environments—both in the US and around the world—use them to access health resources, support groups, and community. For people living under censorship regimes, VPNs are often their only connection to vital resources and information their governments have banned.&lt;/item&gt;
      &lt;item&gt;Regular people just want privacy. Maybe you don’t want every website you visit tracking your location and selling that data to advertisers. Maybe you don’t want your internet service provider (ISP) building a complete profile of your browsing history. Maybe you just think it’s creepy that corporations know everywhere you go online. VPNs can protect everyday users from everyday tracking and surveillance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;It’s A Privacy Nightmare&lt;/head&gt;
    &lt;p&gt;Here’s what happens if VPNs get blocked: everyone has to verify their age by submitting government IDs, biometric data, or credit card information directly to websites—without any encryption or privacy protection.&lt;/p&gt;
    &lt;p&gt;We already know how this story ends. Companies get hacked. Data gets breached. And suddenly your real name is attached to the websites you visited, stored in some poorly-secured database waiting for the inevitable leak. This has already happened, and is not a matter of if but when. And when it does, the repercussions will be huge.&lt;/p&gt;
    &lt;p&gt;Forcing people to give up their privacy to access legal content is the exact opposite of good policy. It’s surveillance dressed up as safety.&lt;/p&gt;
    &lt;head rend="h3"&gt;“Harmful to Minors” Is Not a Catch-All&lt;/head&gt;
    &lt;p&gt;Here’s another fun feature of these laws: they’re trying to broaden the definition of “harmful to minors” to sweep in a host of speech that is protected for both young people and adults.&lt;/p&gt;
    &lt;p&gt;Historically, states can prohibit people under 18 years old from accessing sexual materials that an adult can access under the First Amendment. But the definition of what constitutes “harmful to minors” is narrow — it generally requires that the materials have almost no social value to minors and that they, taken as a whole, appeal to a minors’ “prurient sexual interests.”&lt;/p&gt;
    &lt;p&gt;Wisconsin’s bill defines “harmful to minors” much more broadly. It applies to materials that merely describe sex or feature descriptions/depictions of human anatomy. This definition would likely encompass a wide range of literature, music, television, and films that are protected under the First Amendment for both adults and young people, not to mention basic scientific and medical content.&lt;/p&gt;
    &lt;p&gt;Additionally, the bill’s definition would apply to any websites where more than one third of the site’s material is “harmful to minors.” Given the breadth of the definition and its one-third trigger, we anticipate that Wisconsin could argue that the law applies to most social media websites. And it’s not hard to imagine, as these topics become politicised, Wisconsin claiming it applies to websites containing LGBTQ+ health resources, basic sexual education resources, and reproductive healthcare information.&lt;/p&gt;
    &lt;p&gt;This breadth of the bill’s definition isn’t a bug, it’s a feature. It gives the state a vast amount of discretion to decide which speech is “harmful” to young people, and the power to decide what’s “appropriate” and what isn’t. History shows us those decisions most often harm marginalized communities.&lt;/p&gt;
    &lt;head rend="h3"&gt;It Won’t Even Work&lt;/head&gt;
    &lt;p&gt;Let’s say Wisconsin somehow manages to pass this law. Here’s what will actually happen:&lt;/p&gt;
    &lt;p&gt;People who want to bypass it will use non-commercial VPNs, open proxies, or cheap virtual private servers that the law doesn’t cover. They’ll find workarounds within hours. The internet always routes around censorship.&lt;/p&gt;
    &lt;p&gt;Even in a fantasy world where every website successfully blocked all commercial VPNs, people would just make their own. You can route traffic through cloud services like AWS or DigitalOcean, tunnel through someone else’s home internet connection, use open proxies, or spin up a cheap server for less than a dollar.&lt;/p&gt;
    &lt;p&gt;Meanwhile, everyone else (businesses, students, journalists, abuse survivors, regular people who just want privacy) will have their VPN access impacted. The law will accomplish nothing except making the internet less safe and less private for users.&lt;/p&gt;
    &lt;p&gt;Nonetheless, as we’ve mentioned previously, while VPNs may be able to disguise the source of your internet activity, they are not foolproof—nor should they be necessary to access legally protected speech. Like the larger age verification legislation they are a part of, VPN-blocking provisions simply don’t work. They harm millions of people and they set a terrifying precedent for government control of the internet. More fundamentally, legislators need to recognize that age verification laws themselves are the problem. They don’t work, they violate privacy, they’re trivially easy to circumvent, and they create far more harm than they prevent.&lt;/p&gt;
    &lt;head rend="h2"&gt;A False Dilemma&lt;/head&gt;
    &lt;p&gt;People have (predictably) turned to VPNs to protect their privacy as they watched age verification mandates proliferate around the world. Instead of taking this as a sign that maybe mass surveillance isn’t popular, lawmakers have decided the real problem is that these privacy tools exist at all and are trying to ban the tools that let people maintain their privacy.&lt;/p&gt;
    &lt;p&gt;Let’s be clear: lawmakers need to abandon this entire approach.&lt;/p&gt;
    &lt;p&gt;The answer to “how do we keep kids safe online” isn’t “destroy everyone’s privacy.” It’s not “force people to hand over their IDs to access legal content.” And it’s certainly not “ban access to the tools that protect journalists, activists, and abuse survivors.”&lt;/p&gt;
    &lt;p&gt;If lawmakers genuinely care about young people’s well-being, they should invest in education, support parents with better tools, and address the actual root causes of harm online. What they shouldn’t do is wage war on privacy itself. Attacks on VPNs are attacks on digital privacy and digital freedom. And this battle is being fought by people who clearly have no idea how any of this technology actually works.&lt;/p&gt;
    &lt;p&gt;If you live in Wisconsin—reach out to your Senator and urge them to kill A.B. 105/S.B. 130. Our privacy matters. VPNs matter. And politicians who can’t tell the difference between a security tool and a “loophole” shouldn’t be writing laws about the internet.&lt;/p&gt;
    &lt;p&gt;Republished from the EFF’s Deeplinks blog.&lt;/p&gt;
    &lt;p&gt; Filed Under: ab 105, age verification, harmful to minors, sb 130, vpns, wisconsin &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46113232</guid><pubDate>Mon, 01 Dec 2025 21:08:07 +0000</pubDate></item><item><title>Pose-free 3D Gaussian splatting via shape-ray estimation</title><link>https://arxiv.org/abs/2505.22978</link><description>&lt;doc fingerprint="4d9c2402dcd5908e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computer Vision and Pattern Recognition&lt;/head&gt;&lt;p&gt; [Submitted on 29 May 2025 (v1), last revised 21 Oct 2025 (this version, v3)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Pose-free 3D Gaussian splatting via shape-ray estimation&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:While generalizable 3D Gaussian splatting enables efficient, high-quality rendering of unseen scenes, it heavily depends on precise camera poses for accurate geometry. In real-world scenarios, obtaining accurate poses is challenging, leading to noisy pose estimates and geometric misalignments. To address this, we introduce SHARE, a pose-free, feed-forward Gaussian splatting framework that overcomes these ambiguities by joint shape and camera rays estimation. Instead of relying on explicit 3D transformations, SHARE builds a pose-aware canonical volume representation that seamlessly integrates multi-view information, reducing misalignment caused by inaccurate pose estimates. Additionally, anchor-aligned Gaussian prediction enhances scene reconstruction by refining local geometry around coarse anchors, allowing for more precise Gaussian placement. Extensive experiments on diverse real-world datasets show that our method achieves robust performance in pose-free generalizable Gaussian splatting. Code is avilable at this https URL&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Youngju Na [view email]&lt;p&gt;[v1] Thu, 29 May 2025 01:34:40 UTC (1,331 KB)&lt;/p&gt;&lt;p&gt;[v2] Fri, 26 Sep 2025 06:08:53 UTC (1,331 KB)&lt;/p&gt;&lt;p&gt;[v3] Tue, 21 Oct 2025 11:48:43 UTC (1,331 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46113387</guid><pubDate>Mon, 01 Dec 2025 21:20:28 +0000</pubDate></item><item><title>Mozilla's latest quagmire</title><link>https://rubenerd.com/mozillas-latest-quagmire/</link><description>&lt;doc fingerprint="8e29d3d81843a47b"&gt;
  &lt;main&gt;
    &lt;p&gt;I feel for Mozilla. Legitimately. They haven’t been having an easy go of it for years. None of their attempts to diversify their finances away from Google have panned out. They’ve bought services and shuttered them, rebranded, and replaced their management team multiple times. Actions speak louder than words, and their actions belie a lack of direction and purpose.&lt;/p&gt;
    &lt;p&gt;This is concerning for the health of the Web, given Mozilla write the only meaningful browser engine that competes with WebKit/Blink. But it also makes me sad on a personal level, because I was such a fan of their work, and a believer in the open Web and principles of choice and empowerment that they stood for. I wore the shirts, I spruiked them at events, I’ve blogged about them for twenty years. Heck, I’m one of the 5% of people on the Web who still uses Firefox as their daily driver, and still remembers the names Phoenix and Firebird.&lt;/p&gt;
    &lt;p&gt;This is why takes like this one from Anil Dash feel… off, emphasis his:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One of the top stories on Hacker News today was a post arguing that Mozilla shouldn’t accommodate any usage of AI in Firefox because (understandably) people were mad at Big AI companies for all the horrible things they’ve done to users and the internet and society. But I think people are ignoring the reality that *hundreds of millions of users* are using LLMs today, and they need to have tools from platforms that will look out for their interests.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;“Hundreds of millions of users” out of… billions of Internet users? Who’s looking out for the interests of the majority who don’t use “AI”, or who actively don’t want to? Or to put it another way, why is Firefox configured to make it easy to opt in, but not to opt out?&lt;/p&gt;
    &lt;p&gt;As a reminder, this is what you have to do if you want to disable “AI” features in the current version of Firefox:&lt;/p&gt;
    &lt;code&gt;about:config
user_pref("browser.ml.enable", false); 
user_pref("browser.ml.chat.enabled", false); 
user_pref("browser.ml.chat.sidebar", false);
user_pref("browser.ml.chat.menu", false); 
user_pref("browser.ml.chat.page", false); 
user_pref("extensions.ml.enabled", false); 
user_pref("browser.ml.linkPreview.enabled", false);
user_pref("browser.tabs.groups.smart.enabled", false); 
user_pref("browser.tabs.groups.smart.userEnabled", false);
user_pref("pdfjs.enableAltTextModelDownload", false); 
user_pref("pdfjs.enableGuessAltText", false);
&lt;/code&gt;
    &lt;p&gt;To use the word people overseas think Australians say all the time but don’t: strewth! No, wait:&lt;/p&gt;
    &lt;code&gt;user_pref("browser.ml.chat.strewth", yeahnah);
&lt;/code&gt;
    &lt;p&gt;I’d be willing to entertain Anil’s point if Firefox didn’t obfuscate these settings. But they do. This is hostile design, and it’s why Mozilla’s AI pivot has landed like a lead balloon among their supporters. Again, it’s not a good-faith choice if a person has to beware of the leopard. Someone in the valley will eventually figure out consent, but evidently not today.&lt;/p&gt;
    &lt;p&gt;∗ ∗ ∗&lt;/p&gt;
    &lt;p&gt;Mozilla used to be above this sort of behavior. It might be hard to believe for my younger readers, but Mozilla took on Internet Explorer that was just as entrenched as Chrome is now, and they kicked proverbial posterior! They did because they offered a better browser that respected the people who used it, and gave them agency in their browsing experience. This is why their latest moves feel so hostile.&lt;/p&gt;
    &lt;p&gt;Mozilla team: hand to heart, you can do it again. But it starts with not alienating your remaining evangelists; the people who actively choose and recommend you over alternatives. If you think switching costs for new people are high, wait till you hear about how difficult it is once they’ve churned.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46113682</guid><pubDate>Mon, 01 Dec 2025 21:44:07 +0000</pubDate></item><item><title>Apple AI Chief Retiring After Siri Failure</title><link>https://www.macrumors.com/2025/12/01/apple-ai-chief-retiring-after-siri-failure/</link><description>&lt;doc fingerprint="a5ccf96d12a6547e"&gt;
  &lt;main&gt;
    &lt;p&gt;Apple AI chief John Giannandrea is stepping down from his position and retiring in spring 2026, Apple announced today.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Giannandrea will serve as an advisor between now and 2026, with former Microsoft AI researcher Amar Subramanya set to take over as vice president of AI. Subramanya will report to Apple engineering chief Craig Federighi, and will lead Apple Foundation Models, ML research, and AI Safety and Evaluation.&lt;/p&gt;
    &lt;p&gt;Subramanya was previously corporate vice president of AI at Microsoft, and before that, he spent 16 years at Google. He was head of engineering for Google's Gemini Assistant, and Apple says that he has "deep expertise" in both AI and ML research that will be important to "Apple's ongoing innovation and future Apple Intelligence features."&lt;/p&gt;
    &lt;p&gt;Some of the teams that Giannandrea oversaw will move to Sabih Khan and Eddy Cue, such as AI Infrastructure and Search and Knowledge. Khan is Apple's new Chief Operating Officer who took over for Jeff Williams earlier this year. Cue has long overseen Apple services.&lt;/p&gt;
    &lt;p&gt;Apple CEO Tim Cook thanked Giannandrea for his role advancing Apple's AI work, and he said that he looks forward to working with Subramanya. He also said that Federighi has played an important role in Apple's AI efforts.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"We are thankful for the role John played in building and advancing our AI work, helping Apple continue to innovate and enrich the lives of our users," said Tim Cook, Apple's CEO. "AI has long been central to Apple's strategy, and we are pleased to welcome Amar to Craig's leadership team and to bring his extraordinary AI expertise to Apple. In addition to growing his leadership team and AI responsibilities with Amar's joining, Craig has been instrumental in driving our AI efforts, including overseeing our work to bring a more personalized Siri to users next year."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Apple said that it is "poised to accelerate its work in delivering intelligent, trusted, and profoundly personal experiences" with the new AI team.&lt;/p&gt;
    &lt;p&gt;Giannandrea's departure comes after Apple's major iOS 18 Siri failure. Apple introduced a smarter, "Apple Intelligence" version of Siri at WWDC 2024, and advertised the functionality when marketing the iPhone 16. In early 2025, Apple announced that it would not be able to release the promised version of Siri as planned, and updates were delayed until spring 2026.&lt;/p&gt;
    &lt;p&gt;An exodus of Apple's AI team followed as Apple scrambled to improve Siri and deliver on features like personal context, onscreen awareness, and improved app integration. Apple is now rumored to be partnering with Google for a more advanced version of Siri and other Apple Intelligence features that are set to come out next year.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46114144</guid><pubDate>Mon, 01 Dec 2025 22:22:56 +0000</pubDate></item></channel></rss>