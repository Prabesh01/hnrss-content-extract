<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 20 Jan 2026 19:37:39 +0000</lastBuildDate><item><title>3D printing my laptop ergonomic setup</title><link>https://www.ntietz.com/blog/3d-printing-my-laptop-ergonomic-setup/</link><description>&lt;doc fingerprint="675c59557c882170"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;3D printing my laptop ergonomic setup&lt;/head&gt;
    &lt;p&gt;Monday, January 19, 2026&lt;/p&gt;
    &lt;p&gt;Apparently, one of my hobbies is making updates to my ergonomic setup, then blogging about it from an Amtrak train. I've gone and done it again.&lt;/p&gt;
    &lt;p&gt;My setup stayed static for some time, but my most recent iteration ended up letting me down and I had to change it again. It gave me a lot of useful information and strongly shaped how I approached this iteration. This new one is closest to the first one I wrote about in 2024, but with some major improvements and reproducibility.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why make more changes?&lt;/head&gt;
    &lt;p&gt;First things first, though. Why am making I yet more changes to this setup?&lt;/p&gt;
    &lt;p&gt;Besides my constant neurodivergent drive to make things perfect, my setups all kept causing me some problems. In chronological order, here are the problems and neat benefits of each setup I used for at least a few months.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;My first one was difficult to adjust the keyboard width. You had to flip it over and loosen hardware from the bottom. It was also a little heavy. There's a limit to how far I can reduce weight when using a Keyboardio Model 100, but we can get closer. However, this rig was very fast to set up. It also did keep my keyboard at a good width.&lt;/item&gt;
      &lt;item&gt;My second one used hinges made from fabric and hook-and-loop fasteners, which was neat but ultimately it fell apart, it was tedious to adjust, and it took a long time to set up. The big benefit of this setup was that it was extremely light. This was helpful when I was suffering from a lot of fatigue and POTS.&lt;/item&gt;
      &lt;item&gt;My third one had a neat hinging mechanism which was useful for smaller spaces but wasn't much faster to set up. It used a smaller lighter keyboard, but ultimately that keyboard ended up relapsing my nerve pain.&lt;/item&gt;
      &lt;item&gt;My fourth one, not previously written about, was... way too heavy. It was also a little tedious to setup, but the weight was its biggest problem. I made that one from off-the-shelf parts (mostly), with the goal of making something reproducible for others. And it worked with any laptop, not just ones with a 180 degree hinge like mine[1]. But, with how heavy and annoying it was, it's not worth reproducing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So my immediate previous version was heavy and tedious to setup. I had a trip coming up to Brooklyn, so I had to either make something more portable or leave my laptop at home. I decided to take my laptop, and did a design sprint to see if I can make my dream setup.&lt;/p&gt;
    &lt;head rend="h1"&gt;The dream I'm aiming for&lt;/head&gt;
    &lt;p&gt;At this point I'll probably be working on this setup forever, but I hope I can stop if I am able to satisfy all my goals at some point. My dream setup has these characteristics:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;relatively lightweight: it's not going to get super light with both a laptop and my keyboard, but I want to minimize the weight beyond those&lt;/item&gt;
      &lt;item&gt;solid mount for my Keyboardio Model 100: this keyboard is, vexingly[2], the only keyboard that keeps my nerve pain in remission. I need to use it.&lt;/item&gt;
      &lt;item&gt;good laptop screen height: another problem with laptop use generally is that the screen is usually too low or the keyboard is too high. I want to make sure the screen is at a reasonable height so that I don't wreck my body through poor posture.&lt;/item&gt;
      &lt;item&gt;durability: it needs to be pretty durable since I'm going to use this rig for travel. I don't abuse my laptop or my setup, but it has to stand up to regularly being taken in and out of a bag and being used in random places. It has to stand up to a variety of environmental conditions, too.&lt;/item&gt;
      &lt;item&gt;as easy as opening my laptop: a lot of ergonomic problems stem from ergonomic setups being inconvenient, so if I can reduce that inconvenience, I can reduce the problems&lt;/item&gt;
      &lt;item&gt;easily adjustable keyboard width: I shift around my keyboard position as my body asks for it, and having dynamic positioning helps me feel comfortable. I'd like to be able to do this with little fuss, or else I won't do it (see the previous point).&lt;/item&gt;
      &lt;item&gt;mounting points for accessories: I use an eink tablet to take notes, and would love to be able to put it on a little mount on the rig. I also want to be able to mount USB hubs or the mic I use for Talon. Having options for attaching accessories would make it not just equivalent to a laptop, but far more flexible.&lt;/item&gt;
      &lt;item&gt;reproducible: This setup gets a lot of comments from people, and it solves real problems for me that other people have as well. I want more people to be able to use it.&lt;/item&gt;
      &lt;item&gt;interesting: whenever I take this thing out, I get comments on it. It's how I find other engineers and software folks: most people are all "ignore the lady with the weird rig" but y'all actually strike up conversations with me about it. (If you ever run into me in public, please do talk to me! Even if it looks like I'm working!) I don't want this social benefit to go away!&lt;/item&gt;
      &lt;item&gt;attractive aesthetic: I've been fine using my homebrew wood setups, but they're so obviously homemade and don't look good. My dream is that it would look like it's not homemade, and would simply look like it's how the computer is intended to be used.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, you know, it's not like I want a lot out of this setup. It's not like these are kind of a lot to all fit into one thing. I'm sure it'll be a piece of cake.&lt;/p&gt;
    &lt;head rend="h1"&gt;Making the first prototype&lt;/head&gt;
    &lt;p&gt;I use OpenSCAD for 3D modeling. It's pretty pleasant, though some things are hard in general (like roundovers and fillets on any more complicated shapes). My design to start is basically one of my previous versions: my split keyboard at adjustable width on a base, and a slot to hold my laptop vertically.&lt;/p&gt;
    &lt;p&gt;I started by measuring important dimensions, like how far apart I wanted my keyboard halves and the dimensions of my laptop. Then I compared these to my 3D printer's print volume, and started working out how I'd have to print it. The rig is wider than my 3D printer, so I had to split it up into parts. The slot would fit as a separate piece if I oriented it diagonally. The base itself would have to be split into two separate halves.&lt;/p&gt;
    &lt;p&gt;To join the halves and the slot, I decided to use dovetail joints. I'm familiar with them from woodworking, and I figured they'd give a strong join here as well. I added the library BOSL2 to generate the dovetails, and these were pretty easy to model in. Then I also made some keyboard mounts, which I attach using a camera tripod mount (the Keyboardio Model 100 has threading for this). This is where I ended up for my initial design.&lt;/p&gt;
    &lt;p&gt;When I printed the first pieces, I ran into a problem. The pieces came out alright, mostly, but there was this wavy defect on the top of it!&lt;/p&gt;
    &lt;p&gt;It ended up being (I think) that the print was not adhering well to the printbed. This was easily solved by washing it with some water and dish soap, then prints started coming out beautifully.&lt;/p&gt;
    &lt;p&gt;The other problem was that the sliders and rails worked too smoothly, and I realized that I'd need to have some way to lock the keyboard in place or it would slide around in a difficult to use way. I punted on this, and printed the whole thing. I knew I'd need another iteration on it for material reasons: I am printing the prototype from PLA, since it's easy to work with, but I wanted to print the final one from PETG for slightly better heat resistance.&lt;/p&gt;
    &lt;p&gt;So, onwards, and with a clean printbed, I was able to make the full first prototype! It was 3 parts which took 2-3.5 hours each to print, for a total print time of under 12 hours. I assembled the pieces and glued them together.&lt;/p&gt;
    &lt;p&gt;At this point I was able to use the setup to work on itself, which was really satisfying. I did need to make the keyboard lock in place for carrying it, but it was fairly stable on my desk at least.&lt;/p&gt;
    &lt;head rend="h1"&gt;Making it take the heat&lt;/head&gt;
    &lt;p&gt;Now it was time to make a few tweaks, and print the whole thing in PETG for its heat resistance. I did a few things this iteration: I carved out a honeycomb pattern on the base to reduce weight and filament; I added a nubbin and detentes to the keyboard slider to lock it in place where I want (in 10mm increments); I lengthened the keyboard rails to go further in; and I widened the keyboard slot for a less snug fit.&lt;/p&gt;
    &lt;p&gt;This time is when I met the challenge that is printing with PETG! I dried my filament and started doing some prototyping. I sliced apart chunks of my model to see if things fit together still, since that can change with materials. I also printed a test of my locking clicky mechanism for the keyboard, and good thing: it needed design changes, but the second print worked great (I modified the first with a knife until it fit, then measured the remaining material, and modeled that).&lt;/p&gt;
    &lt;p&gt;Then I printed it. And it came out pretty well! I mean, I had major stringing and bed adherence issues the first time I tried it, but with thorough bed cleaning and a nozzle wipe, it came out cleanly. I had one spot with a minor quality issue, but it's on the bottom and not visible.&lt;/p&gt;
    &lt;p&gt;And it's working out really well! Mostly!&lt;/p&gt;
    &lt;head rend="h1"&gt;What's good, what's not&lt;/head&gt;
    &lt;p&gt;The good things here are what make it usable. It is lightweight (about 280 grams), which is comparable to my lightest previous setup but that one fell apart promptly. It seems durable; we'll see over time, but it did survive multiple backpack loadings and a trip to Brooklyn today, where I hauled it around the city with me. And it's pretty fast to deploy: I can put it together in 15 seconds. The keyboard width is very easy to adjust, and it's solidly in place where it won't slide by accident. The laptop screen is at a good height. It's reproducible: others could print it as well, with access to the files. (I'm considering making them open source, but I don't think they're quite ready to share. It needs some iteration first.) And I quite like the way it looks.&lt;/p&gt;
    &lt;p&gt;However, it's not all good. I want to make some changes to it soon, after a break from the long print times and iterations. Here's the list to address:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Replacements for the camera z-mounts: I'd like to 3d print something for this, and it will be the first iteration I make. The z-mounts are over a pound of metal together, so I could bring down the weight a bit more this way. However, it may be not worth it.&lt;/item&gt;
      &lt;item&gt;Add non-slip feet and extra rails on the bottom: I'd like to raise it off the surface it's on a little bit and add some rails on the bottom for a little more rigidity.&lt;/item&gt;
      &lt;item&gt;Make it more rigid: it is a little bit floppy, but not to the point of being distracting when using it. I'd like it to feel a little sturdier, especially if anyone else were going to use it.&lt;/item&gt;
      &lt;item&gt;Add attachment points for accessories: on Friday, someone at Recurse Center saw my coffee perched in the middle and he suggested a cupholder. I'd like that, or mounts for my mic or USB hub or myriad other things. I can use the honeycomb grid for attachment points, if I add those rails/feet on the bottom to raise it all up a little bit.&lt;/item&gt;
      &lt;item&gt;Make it modular and customizable: it only works today if you have a split keyboard with a tripod mount on the bottom of it. So, that's not great for people who don't have the exact same keyboard I do! And if you have other laptops, well, it would need to be adjusted for that. I want to address this before releasing the files. (If you do have the hardware that makes this useful for you today, let me know. I'm happy to help people out with that, I just don't want to do a big public release.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I don't know if addressing those is all feasible, or if it will satisfy my dream setup. But I do know by now that I'll not be done with this for a long, long time. Everyone needs a hobby, apparently this is one of mine.&lt;/p&gt;
    &lt;p&gt;It's been surprisingly rewarding to work on my own ergonomic setup like this. I have made this setup specifically for health reasons: without it, I cannot use a laptop without severe nerve pain, and I rather like being able to work from anywhere. I have a very uncommon setup in that I'm able to use my Keyboardio Model 100 from a train; I've not seen that before.&lt;/p&gt;
    &lt;p&gt;The amazing thing about 3D printers is enabling this kind of solution. I made my previous versions in my workshop out of mostly wood. It took time and iteration was a big challenge. With a 3D printer, it's doable to design it and even send it off to someone else to print. And we can make exactly what we need, at relatively low cost. It's a technology that truly changes things in making custom tailored solutions far more accessible.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;As far as I know, the main laptops that do this are the Framework 13 and some Lenovo Thinkpads. No Apple laptop does this. It's a big constraint and I haven't been able to design it out of my setup. I'm starting to wonder if the ticket is a headless small form factor computer with a portable monitor. â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I am annoyed at this, because it limits my keyboard options and I would love something lighter. Don't get me wrong, I love my Model 100. But I'm uncomfortable relying only on one keyboard from one company. â©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please share this post, and subscribe to the newsletter or RSS feed. You can email my personal email with any comments or questions.&lt;/p&gt;
    &lt;p&gt;If you're looking for help on a software engineering project, please consider my consulting services.&lt;/p&gt;
    &lt;p&gt; Want to become a better programmer? Join the Recurse Center! &lt;lb/&gt; Want to hire great programmers? Hire via Recurse Center! &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46686131</guid><pubDate>Mon, 19 Jan 2026 23:39:57 +0000</pubDate></item><item><title>Reticulum, a secure and anonymous mesh networking stack</title><link>https://github.com/markqvist/Reticulum</link><description>&lt;doc fingerprint="aa1de81ae67157f4"&gt;
  &lt;main&gt;
    &lt;p&gt;This repository is a public mirror. All development is happening elsewhere.&lt;/p&gt;
    &lt;p&gt;To understand the foundational philosophy and goals of this system, read the Zen of Reticulum.&lt;/p&gt;
    &lt;p&gt;Reticulum is the cryptography-based networking stack for building local and wide-area networks with readily available hardware. It can operate even with very high latency and extremely low bandwidth. Reticulum allows you to build wide-area networks with off-the-shelf tools, and offers end-to-end encryption and connectivity, initiator anonymity, autoconfiguring cryptographically backed multi-hop transport, efficient addressing, unforgeable delivery acknowledgements and more.&lt;/p&gt;
    &lt;p&gt;The vision of Reticulum is to allow anyone to be their own network operator, and to make it cheap and easy to cover vast areas with a myriad of independent, inter-connectable and autonomous networks. Reticulum is not one network. It is a tool for building thousands of networks. Networks without kill-switches, surveillance, censorship and control. Networks that can freely interoperate, associate and disassociate with each other, and require no central oversight. Networks for human beings. Networks for the people.&lt;/p&gt;
    &lt;p&gt;Reticulum is a complete networking stack, and does not rely on IP or higher layers, but it is possible to use IP as the underlying carrier for Reticulum. It is therefore trivial to tunnel Reticulum over the Internet or private IP networks.&lt;/p&gt;
    &lt;p&gt;Having no dependencies on traditional networking stacks frees up overhead that has been used to implement a networking stack built directly on cryptographic principles, allowing resilience and stable functionality, even in open and trustless networks.&lt;/p&gt;
    &lt;p&gt;No kernel modules or drivers are required. Reticulum runs completely in userland, and can run on practically any system that runs Python 3.&lt;/p&gt;
    &lt;p&gt;The full documentation for Reticulum is available at markqvist.github.io/Reticulum/manual/.&lt;/p&gt;
    &lt;p&gt;You can also download the Reticulum manual as a PDF or as an e-book in EPUB format.&lt;/p&gt;
    &lt;p&gt;For more info, see reticulum.network and the FAQ section of the wiki.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Coordination-less globally unique addressing and identification&lt;/item&gt;
      &lt;item&gt;Fully self-configuring multi-hop routing over heterogeneous carriers&lt;/item&gt;
      &lt;item&gt;Flexible scalability over heterogeneous topologies &lt;list rend="ul"&gt;&lt;item&gt;Reticulum can carry data over any mixture of physical mediums and topologies&lt;/item&gt;&lt;item&gt;Low-bandwidth networks can co-exist and interoperate with large, high-bandwidth networks&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Initiator anonymity, communicate without revealing your identity &lt;list rend="ul"&gt;&lt;item&gt;Reticulum does not include source addresses on any packets&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Asymmetric X25519 encryption and Ed25519 signatures as a basis for all communication &lt;list rend="ul"&gt;&lt;item&gt;The foundational Reticulum Identity Keys are 512-bit Elliptic Curve keysets&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Forward Secrecy is available for all communication types, both for single packets and over links&lt;/item&gt;
      &lt;item&gt;Reticulum uses the following format for encrypted tokens: &lt;list rend="ul"&gt;&lt;item&gt;Ephemeral per-packet and link keys and derived from an ECDH key exchange on Curve25519&lt;/item&gt;&lt;item&gt;AES-256 in CBC mode with PKCS7 padding&lt;/item&gt;&lt;item&gt;HMAC using SHA256 for authentication&lt;/item&gt;&lt;item&gt;IVs are generated through os.urandom()&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Unforgeable packet delivery confirmations&lt;/item&gt;
      &lt;item&gt;Flexible and extensible interface system &lt;list rend="ul"&gt;&lt;item&gt;Reticulum includes a large variety of built-in interface types&lt;/item&gt;&lt;item&gt;Ability to load and utilise custom user- or community-supplied interface types&lt;/item&gt;&lt;item&gt;Easily create your own custom interfaces for communicating over anything&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Authentication and virtual network segmentation on all supported interface types&lt;/item&gt;
      &lt;item&gt;An intuitive and easy-to-use API &lt;list rend="ul"&gt;&lt;item&gt;Simpler and easier to use than sockets APIs, but more powerful&lt;/item&gt;&lt;item&gt;Makes building distributed and decentralised applications much simpler&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Reliable and efficient transfer of arbitrary amounts of data &lt;list rend="ul"&gt;&lt;item&gt;Reticulum can handle a few bytes of data or files of many gigabytes&lt;/item&gt;&lt;item&gt;Sequencing, compression, transfer coordination and checksumming are automatic&lt;/item&gt;&lt;item&gt;The API is very easy to use, and provides transfer progress&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Lightweight, flexible and expandable Request/Response mechanism&lt;/item&gt;
      &lt;item&gt;Efficient link establishment &lt;list rend="ul"&gt;&lt;item&gt;Total cost of setting up an encrypted and verified link is only 3 packets, totalling 297 bytes&lt;/item&gt;&lt;item&gt;Low cost of keeping links open at only 0.44 bits per second&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Reliable sequential delivery with Channel and Buffer mechanisms&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Python code in this repository is the Reference Implementation of Reticulum. The Reticulum Protocol is defined entirely and authoritatively by this reference implementation, and its associated manual. It is maintained by Mark Qvist, identified by the Reticulum Identity &lt;code&gt;&amp;lt;bc7291552be7a58f361522990465165c&amp;gt;&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Compatibility with the Reticulum Protocol is defined as having full interoperability, and sufficient functional parity with this reference implementation. Any specific protocol implementation that achieves this is Reticulum. Any that does not is not Reticulum.&lt;/p&gt;
    &lt;p&gt;The reference implementation is licensed under the Reticulum License.&lt;/p&gt;
    &lt;p&gt;The Reticulum Protocol was dedicated to the Public Domain in 2016.&lt;/p&gt;
    &lt;p&gt;If you want to quickly get an idea of what Reticulum can do, take a look at the Programs Using Reticulum section of the manual, or the following resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You can use the rnsh program to establish remote shell sessions over Reticulum.&lt;/item&gt;
      &lt;item&gt;LXMF is a distributed, delay and disruption tolerant message transfer protocol built on Reticulum&lt;/item&gt;
      &lt;item&gt;The LXST protocol and framework provides real-time audio and signals transport over Reticulum. It includes primitives and utilities for building voice-based applications and hardware devices, such as the &lt;code&gt;rnphone&lt;/code&gt;program, that can be used to build hardware telephones.&lt;/item&gt;
      &lt;item&gt;For an off-grid, encrypted and resilient mesh communications platform, see Nomad Network&lt;/item&gt;
      &lt;item&gt;The Android, Linux, macOS and Windows app Sideband has a graphical interface and many advanced features, such as file transfers, image and voice messages, real-time voice calls, a distributed telemetry system, mapping capabilities and full plugin extensibility.&lt;/item&gt;
      &lt;item&gt;MeshChat is a user-friendly LXMF client with a web-based interface, that also supports image and voice messages, as well as file transfers. It also includes a built-in page browser for browsing Nomad Network nodes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Over practically any medium that can support at least a half-duplex channel with greater throughput than 5 bits per second, and an MTU of 500 bytes. Data radios, modems, LoRa radios, serial lines, AX.25 TNCs, amateur radio digital modes, WiFi and Ethernet devices, free-space optical links, and similar systems are all examples of the types of physical devices Reticulum can use.&lt;/p&gt;
    &lt;p&gt;An open-source LoRa-based interface called RNode has been designed specifically for use with Reticulum. It is possible to build yourself, or it can be purchased as a complete transceiver that just needs a USB connection to the host.&lt;/p&gt;
    &lt;p&gt;Reticulum can also be encapsulated over existing IP networks, so there's nothing stopping you from using it over wired Ethernet, your local WiFi network or the Internet, where it'll work just as well. In fact, one of the strengths of Reticulum is how easily it allows you to connect different mediums into a self-configuring, resilient and encrypted mesh, using any available mixture of available infrastructure.&lt;/p&gt;
    &lt;p&gt;As an example, it's possible to set up a Raspberry Pi connected to both a LoRa radio, a packet radio TNC and a WiFi network. Once the interfaces are configured, Reticulum will take care of the rest, and any device on the WiFi network can communicate with nodes on the LoRa and packet radio sides of the network, and vice versa.&lt;/p&gt;
    &lt;p&gt;The best way to get started with the Reticulum Network Stack depends on what you want to do. For full details and examples, have a look at the Getting Started Fast section of the Reticulum Manual.&lt;/p&gt;
    &lt;p&gt;To simply install Reticulum and related utilities on your system, the easiest way is via &lt;code&gt;pip&lt;/code&gt;.
You can then start any program that uses Reticulum, or start Reticulum as a system service with
the rnsd utility.&lt;/p&gt;
    &lt;code&gt;pip install rns&lt;/code&gt;
    &lt;p&gt;If you are using an operating system that blocks normal user package installation via &lt;code&gt;pip&lt;/code&gt;,
you can return &lt;code&gt;pip&lt;/code&gt; to normal behaviour by editing the &lt;code&gt;~/.config/pip/pip.conf&lt;/code&gt; file,
and adding the following directive in the &lt;code&gt;[global]&lt;/code&gt; section:&lt;/p&gt;
    &lt;code&gt;[global]
break-system-packages = true
&lt;/code&gt;
    &lt;p&gt;Alternatively, you can use the &lt;code&gt;pipx&lt;/code&gt; tool to install Reticulum in an isolated environment:&lt;/p&gt;
    &lt;code&gt;pipx install rns&lt;/code&gt;
    &lt;p&gt;When first started, Reticulum will create a default configuration file, providing basic connectivity to other Reticulum peers that might be locally reachable. The default config file contains a few examples, and references for creating a more complex configuration.&lt;/p&gt;
    &lt;p&gt;If you have an old version of &lt;code&gt;pip&lt;/code&gt; on your system, you may need to upgrade it first with &lt;code&gt;pip install pip --upgrade&lt;/code&gt;. If you no not already have &lt;code&gt;pip&lt;/code&gt; installed, you can install it using the package manager of your system with &lt;code&gt;sudo apt install python3-pip&lt;/code&gt; or similar.&lt;/p&gt;
    &lt;p&gt;For more detailed examples on how to expand communication over many mediums such as packet radio or LoRa, serial ports, or over fast IP links and the Internet using the UDP and TCP interfaces, take a look at the Supported Interfaces section of the Reticulum Manual.&lt;/p&gt;
    &lt;p&gt;Reticulum includes a range of useful utilities for managing your networks, viewing status and information, and other tasks. You can read more about these programs in the Included Utility Programs section of the Reticulum Manual.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The system daemon &lt;code&gt;rnsd&lt;/code&gt;for running Reticulum as an always-available service&lt;/item&gt;
      &lt;item&gt;An interface status utility called &lt;code&gt;rnstatus&lt;/code&gt;, that displays information about interfaces&lt;/item&gt;
      &lt;item&gt;The path lookup and management tool &lt;code&gt;rnpath&lt;/code&gt;letting you view and modify path tables&lt;/item&gt;
      &lt;item&gt;A diagnostics tool called &lt;code&gt;rnprobe&lt;/code&gt;for checking connectivity to destinations&lt;/item&gt;
      &lt;item&gt;A simple file transfer program called &lt;code&gt;rncp&lt;/code&gt;making it easy to transfer files between systems&lt;/item&gt;
      &lt;item&gt;The identity management and encryption utility &lt;code&gt;rnid&lt;/code&gt;let's you manage Identities and encrypt/decrypt files&lt;/item&gt;
      &lt;item&gt;The remote command execution program &lt;code&gt;rnx&lt;/code&gt;let's you run commands and programs and retrieve output from remote systems&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All tools, including &lt;code&gt;rnx&lt;/code&gt; and &lt;code&gt;rncp&lt;/code&gt;, work reliably and well even over very
low-bandwidth links like LoRa or Packet Radio. For full-featured remote shells
over Reticulum, also have a look at the rnsh
program.&lt;/p&gt;
    &lt;p&gt;Reticulum implements a range of generalised interface types that covers most of the communications hardware that Reticulum can run over. If your hardware is not supported, it's simple to implement a custom interface module.&lt;/p&gt;
    &lt;p&gt;Pull requests for custom interfaces are gratefully accepted, provided they are generally useful and well-tested in real-world usage.&lt;/p&gt;
    &lt;p&gt;Currently, the following built-in interfaces are supported:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Any Ethernet device&lt;/item&gt;
      &lt;item&gt;LoRa using RNode&lt;/item&gt;
      &lt;item&gt;Packet Radio TNCs (with or without AX.25)&lt;/item&gt;
      &lt;item&gt;KISS-compatible hardware and software modems&lt;/item&gt;
      &lt;item&gt;Any device with a serial port&lt;/item&gt;
      &lt;item&gt;TCP over IP networks&lt;/item&gt;
      &lt;item&gt;UDP over IP networks&lt;/item&gt;
      &lt;item&gt;External programs via stdio or pipes&lt;/item&gt;
      &lt;item&gt;Custom hardware via stdio or pipes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Reticulum targets a very wide usable performance envelope, but prioritises functionality and performance on low-bandwidth mediums. The goal is to provide a dynamic performance envelope from 250 bits per second, to 1 gigabit per second on normal hardware.&lt;/p&gt;
    &lt;p&gt;Currently, the usable performance envelope is approximately 150 bits per second to 500 megabits per second, with physical mediums faster than that not being saturated. Performance beyond the current level is intended for future upgrades, but not highly prioritised at this point in time.&lt;/p&gt;
    &lt;p&gt;All core protocol features are implemented and functioning, but additions will probably occur as real-world use is explored and understood. The API and wire-format can be considered stable.&lt;/p&gt;
    &lt;p&gt;The installation of the default &lt;code&gt;rns&lt;/code&gt; package requires the dependencies listed
below. Almost all systems and distributions have readily available packages for
these dependencies, and when the &lt;code&gt;rns&lt;/code&gt; package is installed with &lt;code&gt;pip&lt;/code&gt;, they
will be downloaded and installed as well.&lt;/p&gt;
    &lt;p&gt;On more unusual systems, and in some rare cases, it might not be possible to install or even compile one or more of the above modules. In such situations, you can use the &lt;code&gt;rnspure&lt;/code&gt; package instead, which require no external
dependencies for installation. Please note that the contents of the &lt;code&gt;rns&lt;/code&gt; and
&lt;code&gt;rnspure&lt;/code&gt; packages are identical. The only difference is that the &lt;code&gt;rnspure&lt;/code&gt;
package lists no dependencies required for installation.&lt;/p&gt;
    &lt;p&gt;No matter how Reticulum is installed and started, it will load external dependencies only if they are needed and available. If for example you want to use Reticulum on a system that cannot support pyserial, it is perfectly possible to do so using the &lt;code&gt;rnspure&lt;/code&gt; package, but Reticulum will not be able to use
serial-based interfaces. All other available modules will still be loaded when
needed.&lt;/p&gt;
    &lt;p&gt;Please Note! If you use the &lt;code&gt;rnspure&lt;/code&gt; package to run Reticulum on systems
that do not support PyCA/cryptography,
it is important that you read and understand the Cryptographic
Primitives section of this document.&lt;/p&gt;
    &lt;p&gt;Reticulum is not a service you subscribe to, nor is it a single global network you "join". Reticulum itself provides functionality for discovering available public interfaces over the network itself, and the broader community has provided various directories of publicly available entrypoints to bootstrap connectivity.&lt;/p&gt;
    &lt;p&gt;To learn how to establish initial connectivity over Reticulum, read the Bootstrapping Connectivity section of the manual.&lt;/p&gt;
    &lt;p&gt;If you already have a general idea of how this works, you can use community-run sites such as directory.rns.recipes and rmap.world to find interface definitions for initial connectivity to the global distributed Reticulum backbone.&lt;/p&gt;
    &lt;p&gt;Important! Historically, a developer-targeted testnet was made available by the Reticulum project itself. As the amount of global Reticulum nodes and entrypoints have grown to a substantial quantity, this public testnet, including the Amsterdam Testnet entrypoint, is slated for de-commisioning in the first quarter of 2026. If your own instances rely on this entrypoint for connectivity, it is high time to start configuring alternatives. Reticulum now includes a full on-network interface discovery and connectivity bootstrapping system. Read the Bootstrapping Connectivity section of the manual for pointers.&lt;/p&gt;
    &lt;p&gt;You can help support the continued development of open, free and private communications systems by donating via one of the following channels:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Monero:&lt;/p&gt;
        &lt;code&gt;84FpY1QbxHcgdseePYNmhTHcrgMX4nFfBYtz2GKYToqHVVhJp8Eaw1Z1EedRnKD19b3B8NiLCGVxzKV17UMmmeEsCrPyA5w&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Bitcoin&lt;/p&gt;
        &lt;code&gt;bc1pgqgu8h8xvj4jtafslq396v7ju7hkgymyrzyqft4llfslz5vp99psqfk3a6&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ethereum&lt;/p&gt;
        &lt;code&gt;0x91C421DdfB8a30a49A71d63447ddb54cEBe3465E&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Liberapay: https://liberapay.com/Reticulum/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ko-Fi: https://ko-fi.com/markqvist&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Reticulum uses a simple suite of efficient, strong and well-tested cryptographic primitives, with widely available implementations that can be used both on general-purpose CPUs and on microcontrollers.&lt;/p&gt;
    &lt;p&gt;One of the primary considerations for choosing this particular set of primitives is that they can be implemented safely with relatively few pitfalls, on practically all current computing platforms.&lt;/p&gt;
    &lt;p&gt;The primitives listed here are authoritative. Anything claiming to be Reticulum, but not using these exact primitives is not Reticulum, and possibly an intentionally compromised or weakened clone. The utilised primitives are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reticulum Identity Keys are 512-bit Curve25519 keysets &lt;list rend="ul"&gt;&lt;item&gt;A 256-bit Ed25519 key for signatures&lt;/item&gt;&lt;item&gt;A 256-bit X22519 key for ECDH key exchanges&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;HKDF for key derivation&lt;/item&gt;
      &lt;item&gt;Encrypted tokens are based on the Fernet spec &lt;list rend="ul"&gt;&lt;item&gt;Ephemeral keys derived from an ECDH key exchange on Curve25519&lt;/item&gt;&lt;item&gt;HMAC using SHA256 for message authentication&lt;/item&gt;&lt;item&gt;IVs must be generated through &lt;code&gt;os.urandom()&lt;/code&gt;or better&lt;/item&gt;&lt;item&gt;AES-256 in CBC mode with PKCS7 padding&lt;/item&gt;&lt;item&gt;No Fernet version and timestamp metadata fields&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;SHA-256&lt;/item&gt;
      &lt;item&gt;SHA-512&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the default installation configuration, the &lt;code&gt;X25519&lt;/code&gt;, &lt;code&gt;Ed25519&lt;/code&gt;,
and &lt;code&gt;AES-256-CBC&lt;/code&gt; primitives are provided by OpenSSL
(via the PyCA/cryptography package).
The hashing functions &lt;code&gt;SHA-256&lt;/code&gt; and &lt;code&gt;SHA-512&lt;/code&gt; are provided by the standard
Python hashlib. The &lt;code&gt;HKDF&lt;/code&gt;,
&lt;code&gt;HMAC&lt;/code&gt;, &lt;code&gt;Token&lt;/code&gt; primitives, and the &lt;code&gt;PKCS7&lt;/code&gt; padding function are always
provided by the following internal implementations:&lt;/p&gt;
    &lt;p&gt;Reticulum also includes a complete implementation of all necessary primitives in pure Python. If OpenSSL and PyCA are not available on the system when Reticulum is started, Reticulum will instead use the internal pure-python primitives. A trivial consequence of this is performance, with the OpenSSL backend being much faster. The most important consequence however, is the potential loss of security by using primitives that has not seen the same amount of scrutiny, testing and review as those from OpenSSL.&lt;/p&gt;
    &lt;p&gt;Please note that by default, installing Reticulum will require OpenSSL and PyCA to also be automatically installed if not already available. It is only possible to use the pure-python primitives if this requirement is specifically overridden by the user, for example by installing the &lt;code&gt;rnspure&lt;/code&gt; package instead
of the normal &lt;code&gt;rns&lt;/code&gt; package, or by running directly from local source-code.&lt;/p&gt;
    &lt;p&gt;If you want to use the internal pure-python primitives, it is highly advisable that you have a good understanding of the risks that this pose, and make an informed decision on whether those risks are acceptable to you.&lt;/p&gt;
    &lt;p&gt;Reticulum is relatively young software, and should be considered as such. While it has been built with cryptography best-practices very foremost in mind, it has not been externally security audited, and there could very well be privacy or security breaking bugs. If you want to help out, or help sponsor an audit, please do get in touch.&lt;/p&gt;
    &lt;p&gt;Reticulum can only exist because of the mountain of Open Source work it was built on top of, the contributions of everyone involved, and everyone that has supported the project through the years. To everyone who has helped, thank you so much.&lt;/p&gt;
    &lt;p&gt;A number of other modules and projects are either part of, or used by Reticulum. Sincere thanks to the authors and contributors of the following projects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PyCA/cryptography, BSD License&lt;/item&gt;
      &lt;item&gt;Pure-25519 by Brian Warner, MIT License&lt;/item&gt;
      &lt;item&gt;Pysha2 by Thom Dixon, MIT License&lt;/item&gt;
      &lt;item&gt;Python AES-128 by Or Gur Arie, MIT License&lt;/item&gt;
      &lt;item&gt;Python AES-256 by BoppreH, MIT License&lt;/item&gt;
      &lt;item&gt;Curve25519.py by Nicko van Someren, Public Domain&lt;/item&gt;
      &lt;item&gt;I2Plib by Viktor Villainov&lt;/item&gt;
      &lt;item&gt;PySerial by Chris Liechti, BSD License&lt;/item&gt;
      &lt;item&gt;Configobj by Michael Foord, Nicola Larosa, Rob Dennis &amp;amp; Eli Courtwright, BSD License&lt;/item&gt;
      &lt;item&gt;ifaddr by Stefan C. Mueller, MIT License&lt;/item&gt;
      &lt;item&gt;Umsgpack.py by Ivan A. Sergeev&lt;/item&gt;
      &lt;item&gt;Python&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46686273</guid><pubDate>Mon, 19 Jan 2026 23:59:54 +0000</pubDate></item><item><title>Linux kernel framework for PCIe device emulation, in userspace</title><link>https://github.com/cakehonolulu/pciem</link><description>&lt;doc fingerprint="f8fdd1c91c3b989"&gt;
  &lt;main&gt;
    &lt;p&gt;PCIem is a framework that creates virtual PCIe devices in the Linux kernel by leveraging a few novel techniques to populate synthetic cards as legitimate PCI devices to the host OS.&lt;/p&gt;
    &lt;p&gt;To brief what PCIem is: a framework for developing and testing PCIe device drivers without requiring actual hardware.&lt;/p&gt;
    &lt;code&gt;┌──────────────────────────────────────────┐                                   ┌──────────────────────────────────────────────────┐
│                                          │                                   │                                                  │
│ ┌─────────►Host Linux Kernel             │                                   │                  Linux Userspace                 │
│ │                                        │                                   │                                                  │
│ │                                        │                                   │                                                  │
│ │    ┌────────────────────────────┐      │                                   │    ┌────────────────────────────────────────┐    │
│ │    │      PCIem Framework       ◄──────┼────────────►/dev/pciem◄───────────┼────►          Userspace PCI shim            │    │
│ │    │                            │      │                                   │    │                                        │    │
│ │    │ - PCI Config Space         │      │                                   │    │ - Emulates PCIe device logic           │    │
│ │    │                            │      │                                   │    │                                        │    │
│ │    │ - BAR Mappings             │      │                                   │    └────────────────────────────────────────┘    │
│ │    │                            │      │                                   │                                                  │
│ │◄───┤ - INT/MSI/MSI-X Interrupts │      │                                   │                                                  │
│ │    │                            │      │                                   └──────────────────────────────────────────────────┘
│ │    │ - DMA (With/without IOMMU) │      │                                                         Userspace                     
│ │    │                            │      │                                                                                       
│ │    │ - P2P DMA                  │      │                                                                                       
│ │    │                            │      │                                                                                       
│ │    └────────────────────────────┘      │                                                                                       
│ │                                        │                                                                                       
│ │                                        │                                                                                       
│ │    PCIe driver is unaware of PCIem     │                                                                                       
│ │                                        │                                                                                       
│ │                                        │                                                                                       
│ │ ┌──────────────────────────────────┐   │                                                                                       
│ │ │          Real PCIe Driver        │   │                                                                                       
│ │ │                                  │   │                                                                                       
│ └─┤ - Untouched logic from production│   │                                                                                       
│   │                                  │   │                                                                                       
│   └──────────────────────────────────┘   │                                                                                       
│                                          │                                                                                       
└──────────────────────────────────────────┘                                                                                       
               Kernel Space                                                                                                        
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BAR Support: Register and manage BARs programmatically&lt;/item&gt;
      &lt;item&gt;Watchpoints: Event-driven architecture using CPU watchpoints for access detection&lt;/item&gt;
      &lt;item&gt;Legacy IRQ/MSI/MSI-X Support: Full interrupt support with dynamic triggering&lt;/item&gt;
      &lt;item&gt;PCI Capability Framework: Modular PCI capabilities system (Linked-list underneath)&lt;/item&gt;
      &lt;item&gt;DMA System: IOMMU-aware DMA operations with atomic memory operations support&lt;/item&gt;
      &lt;item&gt;P2P DMA: Peer-to-peer DMA between devices with whitelist-based access control&lt;/item&gt;
      &lt;item&gt;Userspace-defined: Implement your PCIe prototypes anywhere&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The card is programmed entirely in QEMU, who does all the userspace initialization and command handling from the real driver running in the host. Can run software-rendered DOOM (Submits finished frames with DMA to the card which QEMU displays) and also simple OpenGL 1.X games (On the screenshots, tyr-glquake and xash3d; thanks to a custom OpenGL state machine implemented entirely in QEMU that software-renders the command lists and updates the internal state accordingly).&lt;/p&gt;
    &lt;p&gt;Dual MIT/GPLv2 (pciem_framework.c and protopciem_driver.c)&lt;/p&gt;
    &lt;p&gt;MIT (Rest)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Blog post: https://cakehonolulu.github.io/introducing-pciem/&lt;/item&gt;
      &lt;item&gt;Documentation: https://cakehonolulu.github.io/docs/pciem/&lt;/item&gt;
      &lt;item&gt;PCI Express specification: https://pcisig.com/specifications&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46689065</guid><pubDate>Tue, 20 Jan 2026 07:51:12 +0000</pubDate></item><item><title>Kiss Launcher – fast launcher for Android</title><link>https://kisslauncher.com/</link><description>&lt;doc fingerprint="330b9aa8bc800d6a"&gt;
  &lt;main&gt;
    &lt;p&gt;Blazingly fast Launcher for Android requiring nearly no memory to run Why KISS ? Download Download on Google Play Download on F-droid Frequently Asked Questions ? SMALL &amp;lt; 250 kb Get it quickly SAVE Optimized for battery life Improve your battery now SMART Search everything that you need Be smarter FAST Faster than ever Be faster Next Prev&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46690092</guid><pubDate>Tue, 20 Jan 2026 10:02:17 +0000</pubDate></item><item><title>I'm addicted to being useful</title><link>https://www.seangoedecke.com/addicted-to-being-useful/</link><description>&lt;doc fingerprint="ed5f15152a45219f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I'm addicted to being useful&lt;/head&gt;
    &lt;p&gt;When I get together with my friends in the industry, I feel a little guilty about how much I love my job. This is a tough time to be a software engineer. The job was less stressful in the late 2010s than it is now, and I sympathize with anyone who is upset about the change. There are a lot of objective reasons to feel bad about work. But despite all that, I’m still having a blast. I enjoy pulling together projects, figuring out difficult bugs, and writing code in general. I like spending time with computers. But what I really love is being useful.&lt;/p&gt;
    &lt;p&gt;The main character in Gogol’s short story The Overcoat is a man called Akaky Akaievich1. Akaky’s job is objectively terrible: he’s stuck in a dead-end copyist role, being paid very little, with colleagues who don’t respect him. Still, he loves his work, to the point that if he has no work to take home with him, he does some recreational copying just for his own sake. Akaky is a dysfunctional person. But his dysfunction makes him a perfect fit for his job2.&lt;/p&gt;
    &lt;p&gt;It’s hard for me to see a problem and not solve it. This is especially true if I’m the only person (or one of a very few people) who could solve it, or if somebody is asking for my help. I feel an almost physical discomfort about it, and a corresponding relief and satisfaction when I do go and solve the problem. The work of a software engineer - or at least my work as a staff software engineer - is perfectly tailored to this tendency. Every day people rely on me to solve a series of technical problems3.&lt;/p&gt;
    &lt;p&gt;In other words, like Akaky Akaievich, I don’t mind the ways in which my job is dysfunctional, because it matches the ways in which I myself am dysfunctional: specifically, my addiction to being useful. (Of course, it helps that my working conditions are overall much better than Akaky’s). I’m kind of like a working dog, in a way. Working dogs get rewarded with treats4, but they don’t do it for the treats. They do it for the work itself, which is inherently satisfying.&lt;/p&gt;
    &lt;p&gt;This isn’t true of all software engineers. But it’s certainly true of many I’ve met: if not an addiction to being useful, then they’re driven by an addiction to solving puzzles, or to the complete control over your work product that you only really get in software or mathematics. If they weren’t working as a software engineer, they would be getting really into Factorio, or crosswords, or tyrannically moderating some internet community.&lt;/p&gt;
    &lt;p&gt;A lot of the advice I give about working a software engineering job is really about how I’ve shaped my need to be useful in a way that delivers material rewards, and how I try to avoid the pitfalls of such a need. For instance, Protecting your time from predators in large tech companies is about how some people in tech companies will identify people like me and wring us out in ways that only benefit them. Crushing JIRA tickets is a party trick, not a path to impact is about how I need to be useful to my management chain, not to the ticket queue. Trying to impress people you don’t respect is about how I cope with the fact that I’m compelled to be useful to some people who I may not respect or even like.&lt;/p&gt;
    &lt;p&gt;There’s a lot of discussion on the internet about what ought to motivate software engineers: money and power, producing real value, ushering in the AI machine god, and so on. But what actually does motivate software engineers is often more of an internal compulsion. If you’re in that category - as I suspect most of us are - then it’s worth figuring out how you can harness that compulsion most effectively.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;I think in Russian this is supposed to be an obviously silly name, like “Poop Poopson”.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Unfortunately, his low status and low pay catches up with Akaky in the end. His financial difficulty acquiring a new coat for the cold Russian winter (and his lack of backbone) end up doing him in, at which point the story becomes a ghost story.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I interpret “technical problem” quite broadly here: answering questions, explaining things, and bug-fixing all count.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Or toys, or playtime, or whatever.&lt;/p&gt;↩&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News. Here's a preview of a related post that shares tags with this one.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Nobody knows how large software products work&lt;/p&gt;&lt;p&gt;Large, rapidly-moving tech companies are constantly operating in the “fog of war” about their own systems. Simple questions like “can users of type Y access feature X?”, “what happens when you perform action Z in this situation?”, or even “how many different plans do we offer” often can only be answered by a handful of people in the organization. Sometimes there are zero people at the organization who can answer them, and somebody has to be tasked with digging in like a researcher to figure it out.&lt;/p&gt;&lt;lb/&gt;Continue reading...&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46690402</guid><pubDate>Tue, 20 Jan 2026 10:47:25 +0000</pubDate></item><item><title>IP over Avian Carriers with Quality of Service (1999)</title><link>https://www.rfc-editor.org/rfc/rfc2549.html</link><description>&lt;doc fingerprint="7ed110dfb3843344"&gt;
  &lt;main&gt;[RFC Home] [TEXT|PDF|HTML] [Tracker] [IPR] [Errata] [Info page]&lt;lb/&gt;INFORMATIONAL&lt;lb/&gt;Errata Exist&lt;quote&gt;Network Working Group D. Waitzman Request for Comments: 2549 IronBridge Networks Updates: 1149 1 April 1999 Category: Experimental IP over Avian Carriers with Quality of Service Status of this Memo This memo defines an Experimental Protocol for the Internet community. It does not specify an Internet standard of any kind. Discussion and suggestions for improvement are requested. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (1999). All Rights Reserved. Abstract This memo amends RFC 1149, "A Standard for the Transmission of IP Datagrams on Avian Carriers", with Quality of Service information. This is an experimental, not recommended standard. Overview and Rational The following quality of service levels are available: Concorde, First, Business, and Coach. Concorde class offers expedited data delivery. One major benefit to using Avian Carriers is that this is the only networking technology that earns frequent flyer miles, plus the Concorde and First classes of service earn 50% bonus miles per packet. Ostriches are an alternate carrier that have much greater bulk transfer capability but provide slower delivery, and require the use of bridges between domains. The service level is indicated on a per-carrier basis by bar-code markings on the wing. One implementation strategy is for a bar-code reader to scan each carrier as it enters the router and then enqueue it in the proper queue, gated to prevent exit until the proper time. The carriers may sleep while enqueued. For secure networks, carriers may have classes Prime or Choice. Prime carriers are self-keying when using public key encryption. Some distributors have been known to falsely classify Choice carriers as Prime. Packets MAY be marked for deletion using RED paint while enqueued. Waitzman Experimental [Page 1]&lt;/quote&gt;&lt;quote&gt; RFC 2549 IP over Avian Carriers with QoS 1 April 1999 Weighted fair queueing (WFQ) MAY be implemented using scales, as shown: __ _____/-----\ / o\ &amp;lt;____ _____\_/ &amp;gt;-- +-----+ \ / /______/ | 10g | /|:||/ +-----+ /____/| | 10g | | +-----+ .. X =============================== ^ | ========= Carriers in the queue too long may leave log entries, as shown on the scale. The following is a plot of traffic shaping, from coop-erative host sites. Alt | Plot of Traffic Shaping showing carriers in flight | 2k | .................... | . . | . . 1k | . . | +---+ +---+ | | A | | B | | +---+ +---+ |_____________________________________________ Avian carriers normally bypass bridges and tunnels but will seek out worm hole tunnels. When carrying web traffic, the carriers may digest the spiders, leaving behind a more compact representation. The carriers may be confused by mirrors. Round-robin queueing is not recommended. Robins make for well-tuned networks but do not support the necessary auto-homing feature. A BOF was held at the last IETF but only Avian Carriers were allowed entry, so we don't know the results other than we're sure they think MPLS is great. Our attempts at attaching labels to the carriers have been met with resistance. Waitzman Experimental [Page 2]&lt;/quote&gt;&lt;quote&gt; RFC 2549 IP over Avian Carriers with QoS 1 April 1999 NATs are not recommended either -- as with many protocols, modifying the brain-embedded IP addresses is difficult, plus Avian Carriers MAY eat the NATs. Encapsulation may be done with saran wrappers. Unintentional encapsulation in hawks has been known to occur, with decapsulation being messy and the packets mangled. Loose source routes are a viable evolutionary alternative enhanced standards-based MSWindows-compliant technology, but strict source routes MUST NOT be used, as they are a choke-point. The ITU has offered the IETF formal alignment with its corresponding technology, Penguins, but that won't fly. Multicasting is supported, but requires the implementation of a clone device. Carriers may be lost if they are based on a tree as it is being pruned. The carriers propagate via an inheritance tree. The carriers have an average TTL of 15 years, so their use in expanding ring searches is limited. Additional quality of service discussion can be found in a Michelin's guide. MIB and Management issues AvCarrier2 OBJECT-TYPE SYNTAX SEQUENCE OF DNA MAX-ACCESS can't-read STATUS living DESCRIPTION "Definition of an avian carrier" ::= { life eukaryotes mitochondrial_eukaryotes crown_eukaryotes metazoa chordata craniata vertebrata gnathostomata sarcopterygii terrestrial_vertebrates amniota diapsida archosauromorpha archosauria dinosauria aves neornithes columbiformes columbidae columba livia } AvCarrier OBJECT-TYPE SYNTAX SET OF Cells MAX-ACCESS not-accessible STATUS obsolete DESCRIPTION "Definition of an avian carrier" ::= { life animalia chordata vertebrata aves columbiformes columbidae columba livia } PulseRate OBJECT-TYPE SYNTAX Gauge(0..300) MAX-ACCESS read-only Waitzman Experimental [Page 3]&lt;/quote&gt;&lt;quote&gt; RFC 2549 IP over Avian Carriers with QoS 1 April 1999 STATUS current DESCRIPTION "Pulse rate of carrier, as measured in neck. Frequent sampling is disruptive to operations." ::= { AvCarrier 1} The carriers will not line up in lexigraphic order but will naturally order in a large V shape. Bulk retrieval is possible using the Powerful Get-Net operator. Specification of Requirements In this document, several words are used to signify the requirements of the specification. These words are often capitalized. MUST Usually. MUST NOT Usually not. SHOULD Only when Marketing insists. MAY Only if it doesn't cost extra. Security Considerations There are privacy issues with stool pigeons. Agoraphobic carriers are very insecure in operation. Patent Considerations There is ongoing litigation about which is the prior art: carrier or egg. References Waitzman, D., "A Standard for the Transmission of IP Datagrams on Avian Carriers", RFC 1149, 1 April 1990. ACKnowledgments Jim.Carlson.Ibnets.com &amp;gt; Jon.Saperia . ack 32 win 123 (DF) Ross Callon, Scott Bradner, Charlie Lynn ... Waitzman Experimental [Page 4]&lt;/quote&gt;&lt;quote&gt; RFC 2549 IP over Avian Carriers with QoS 1 April 1999 Author's Address David Waitzman IronBridge Networks 55 Hayden Ave Lexington, MA 02421 Phone: (781) 372-8161 EMail: djw@vineyard.net Waitzman Experimental [Page 5]&lt;/quote&gt;&lt;quote&gt; RFC 2549 IP over Avian Carriers with QoS 1 April 1999 Full Copyright Statement Copyright (C) The Internet Society (1999). All Rights Reserved. This document and translations of it may be copied and furnished to others, and derivative works that comment on or otherwise explain it or assist in its implementation may be prepared, copied, published and distributed, in whole or in part, without restriction of any kind, provided that the above copyright notice and this paragraph are included on all such copies and derivative works. However, this document itself may not be modified in any way, such as by removing the copyright notice or references to the Internet Society or other Internet organizations, except as needed for the purpose of developing Internet standards in which case the procedures for copyrights defined in the Internet Standards process must be followed, or as required to translate it into languages other than English. The limited permissions granted above are perpetual and will not be revoked by the Internet Society or its successors or assigns. This document and the information contained herein is provided on an "AS IS" basis and THE INTERNET SOCIETY AND THE INTERNET ENGINEERING TASK FORCE DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT THE USE OF THE INFORMATION HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY IMPLIED WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Waitzman Experimental [Page 6] &lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46690530</guid><pubDate>Tue, 20 Jan 2026 11:06:54 +0000</pubDate></item><item><title>Running Claude Code dangerously (safely)</title><link>https://blog.emilburzo.com/2026/01/running-claude-code-dangerously-safely/</link><description>&lt;doc fingerprint="3f0538583fad4aff"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Running Claude Code dangerously (safely)&lt;/head&gt;
    &lt;head rend="h1"&gt;Background&lt;/head&gt;
    &lt;p&gt;I’ve been using Claude Code more and more recently. At some point I realized that rather than do something else until it finishes, I would constantly check on it to see if it was asking for yet another permission, which felt like it was missing the point of having an agent do stuff. So I wanted to use Claude Code with the &lt;code&gt;--dangerously-skip-permissions&lt;/code&gt; flag.&lt;/p&gt;
    &lt;p&gt;If you haven’t used it, this flag does exactly what it says: it lets Claude Code do whatever it wants without asking permission first. No more “May I install this package?”, “Should I modify this config?”, “Can I delete these files?”&lt;/p&gt;
    &lt;p&gt;It just… does it.&lt;/p&gt;
    &lt;p&gt;Which is great for flow since I don’t have to worry that it stopped doing stuff just to ask a permission question.&lt;/p&gt;
    &lt;p&gt;But also, you know, dangerous.&lt;/p&gt;
    &lt;p&gt;I like my filesystem intact, so the obvious solution is to not run this thing directly on my OS account.&lt;/p&gt;
    &lt;head rend="h1"&gt;What I considered&lt;/head&gt;
    &lt;head rend="h2"&gt;Docker&lt;/head&gt;
    &lt;p&gt;First instinct: throw it in a Docker container. Containers are for isolation, right?&lt;/p&gt;
    &lt;p&gt;Except I want Claude to be able to build Docker images. And run containers. And maybe orchestrate some stuff.&lt;/p&gt;
    &lt;p&gt;So now you need Docker-in-Docker, which means &lt;code&gt;--privileged&lt;/code&gt; mode, which defeats the entire purpose of sandboxing. That means trading “Claude might mess up my filesystem” for “Claude has root-level access to my container runtime.”&lt;/p&gt;
    &lt;p&gt;Not great.&lt;/p&gt;
    &lt;p&gt;There’s also the nested networking weirdness, volume mounting permissions that make you question your life choices, and the general feeling that you’re fighting the tool instead of using it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Other options&lt;/head&gt;
    &lt;p&gt;I also briefly considered:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;#yolo run it bare metal: no, no and no&lt;/item&gt;
      &lt;item&gt;sandbox-runtime: more of an ACL approach, I want Claude to be able to do anything, because it doesn’t have access to anything except the code&lt;/item&gt;
      &lt;item&gt;firejail or similar: same problem as Docker-in-Docker&lt;/item&gt;
      &lt;item&gt;manual VM setup: works but tedious, not reproducible&lt;/item&gt;
      &lt;item&gt;cloud VM: costs money, has latency, need to upload my code somewhere&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Vagrant&lt;/head&gt;
    &lt;p&gt;Then I remembered about a project that I’ve used before Docker became all the rage: Vagrant.&lt;/p&gt;
    &lt;p&gt;If you weren’t around back then, Vagrant gives you proper VM isolation with a reproducible config file. It’s basically infrastructure as code for your local dev environment.&lt;/p&gt;
    &lt;p&gt;You get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;full VM isolation (no shared kernel)&lt;/item&gt;
      &lt;item&gt;easy to nuke and rebuild&lt;/item&gt;
      &lt;item&gt;shared folders that make it feel local enough&lt;/item&gt;
      &lt;item&gt;no Docker-in-Docker nonsense&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I hadn’t used VirtualBox in years since Docker containers covered all requirements until now, so I grabbed the latest version (7.2.4) and got started.&lt;/p&gt;
    &lt;p&gt;First &lt;code&gt;vagrant up&lt;/code&gt; and… the VM is pegging my CPU at 100%+ while completely idle.&lt;/p&gt;
    &lt;p&gt;I spent an hour turning off various VM features, tweaking settings, &lt;del&gt;googling&lt;/del&gt; asking LLMs random combinations of “virtualbox high cpu idle”, you know, the usual.&lt;/p&gt;
    &lt;p&gt;Eventually I found this GitHub issue. VirtualBox 7.2.4 shipped with a regression that causes high CPU usage on idle guests. What are the odds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Vagrantfile&lt;/head&gt;
    &lt;p&gt;Here’s what my simple Vagrantfile looks like:&lt;/p&gt;
    &lt;code&gt;vm_name = File.basename(Dir.getwd)

Vagrant.configure("2") do |config|
  config.vm.box = "bento/ubuntu-24.04"

  #config.vm.network "forwarded_port", guest: 3000, host: 3000, auto_correct: true
  config.vm.synced_folder ".", "/agent-workspace", type: "virtualbox"

  config.vm.provider "virtualbox" do |vb|
    vb.memory = "4096"
    vb.cpus = 2
    vb.gui = false
    vb.name = vm_name
    vb.customize ["modifyvm", :id, "--audio", "none"]
    vb.customize ["modifyvm", :id, "--usb", "off"]
  end
  
  config.vm.provision "shell", inline: &amp;lt;&amp;lt;-SHELL
    export DEBIAN_FRONTEND=noninteractive

    apt-get update
    apt-get install -y docker.io nodejs npm git unzip
    npm install -g @anthropic-ai/claude-code --no-audit

    usermod -aG docker vagrant
    chown -R vagrant:vagrant /agent-workspace

  SHELL
end
&lt;/code&gt;
    &lt;head rend="h1"&gt;How it works in practice&lt;/head&gt;
    &lt;p&gt;Now I just run:&lt;/p&gt;
    &lt;code&gt;cd ~/my-project
vagrant up
vagrant ssh
claude --dangerously-skip-permissions
# tell Claude what you want and let it run wild with no babysitting
&lt;/code&gt;
    &lt;p&gt;First boot takes a few minutes to provision everything, and you need to sign in to Claude once for each project, but after that, &lt;code&gt;vagrant up&lt;/code&gt; is quite fast.&lt;/p&gt;
    &lt;p&gt;Then, when you are done for the day:&lt;/p&gt;
    &lt;code&gt;exit
vagrant suspend
&lt;/code&gt;
    &lt;head rend="h1"&gt;Supercharged Claude&lt;/head&gt;
    &lt;p&gt;So, what can Claude do with these newfound powers?&lt;/p&gt;
    &lt;p&gt;Since it’s running in a VM, I also gave it &lt;code&gt;sudo&lt;/code&gt; access and instructed it that it has the power to do anything: install system packages, modify configs, create files, run Docker containers, whatever.&lt;/p&gt;
    &lt;p&gt;It has:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;manually started a webapp API and inspected it with curl requests&lt;/item&gt;
      &lt;item&gt;installed a browser and manually inspected the app, then built end-to-end tests based on that&lt;/item&gt;
      &lt;item&gt;setup a postgres database, ran test sql, tested that db migrations work, etc&lt;/item&gt;
      &lt;item&gt;built and ran Docker images&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All things I’d be nervous about on my host machine, especially with the “just do it” flag enabled.&lt;/p&gt;
    &lt;p&gt;And now I feel Claude is much more effective since it has the extra context, it’s not relying on me to run the command, return the output or error message, and then iterate. It just does it by itself.&lt;/p&gt;
    &lt;head rend="h1"&gt;Performance&lt;/head&gt;
    &lt;p&gt;Claude Code isn’t exactly a resource hog, and the VM has plenty of headroom. The shared folder sync works fine, no lag or weirdness when files change. This is under Linux with VirtualBox, YMMV for other platforms.&lt;/p&gt;
    &lt;head rend="h1"&gt;Safety&lt;/head&gt;
    &lt;p&gt;What you’re protecting against:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;accidental filesystem damage&lt;/item&gt;
      &lt;item&gt;aggressive package installations&lt;/item&gt;
      &lt;item&gt;configuration changes you didn’t catch&lt;/item&gt;
      &lt;item&gt;general “oops I didn’t mean Claude to do that”&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What you’re NOT protecting against:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;deleting the actual project, since the file sync is two-way&lt;/item&gt;
      &lt;item&gt;a malicious AI trying to escape the VM (VM escape vulnerabilities exist, but they’re rare and require deliberate exploitation)&lt;/item&gt;
      &lt;item&gt;network-level attacks/oopsies from the VM&lt;/item&gt;
      &lt;item&gt;data exfiltration: the VM still has internet access, but besides the code there shouldn’t really be any data to exfiltrate&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Threat model: I don’t trust myself to always catch what the agent is doing when I’m in the zone and just want stuff to work. This setup is about preventing accidents, not sophisticated attacks.&lt;/p&gt;
    &lt;p&gt;Since all my projects are in git I don’t care if it messes something up in the project. Plus you get the benefit of being able to use your regular git tooling/flows/whatever, without having to add credentials to the VM.&lt;/p&gt;
    &lt;p&gt;But if you need something stricter, &lt;code&gt;config.vm.synced_folder&lt;/code&gt; also supports &lt;code&gt;type: "rsync"&lt;/code&gt;, one-time one-way sync from the machine running to the machine being started by Vagrant, but then it’s on you to sync it back or whatever is needed.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This took a bit to get right, mostly because of the VirtualBox CPU bug. But now it’s frictionless. I can let Claude Code do whatever it wants without fear, and if something goes sideways, I just nuke the VM and start fresh.&lt;/p&gt;
    &lt;p&gt;The Vagrantfile is short and reproducible. Drop it in any project directory, &lt;code&gt;vagrant up&lt;/code&gt;, and you’re sandboxed.&lt;/p&gt;
    &lt;p&gt;If you’re using Claude Code with the dangerous flag, I’d recommend something like this. Even if you’re careful about what you approve, it only takes one moment to mess things up.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46690907</guid><pubDate>Tue, 20 Jan 2026 11:58:34 +0000</pubDate></item><item><title>Channel3 (YC S25) Is Hiring</title><link>https://www.ycombinator.com/companies/channel3/jobs/3DIAYYY-backend-engineer</link><description>&lt;doc fingerprint="2f182077c5bc662d"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Channel3 is building a database of every product on the internet. People have wanted to do this for decades, but it wasn’t possible until now – AI is finally smart enough to structure the world’s messy product data, and inexpensive enough to do so at scale.&lt;/p&gt;
      &lt;head rend="h3"&gt;Our vision: from in-store, to online, to AI-native&lt;/head&gt;
      &lt;p&gt;We believe agentic commerce is as important as in-store and online channels; that’s where “Channel3” comes from. We plan to become the central node of agentic commerce, powering every AI transaction and taking a cut of GMV. We see Channel3 becoming as foundational to AI commerce as Stripe is to payments or Plaid is to fintech.&lt;/p&gt;
      &lt;head rend="h3"&gt;The problem&lt;/head&gt;
      &lt;p&gt;Agentic commerce is bottlenecked by messy product data. (See “OpenAI’s Shopping Ambitions Hit Messy Data Reality”) Product data is inconsistent at best, completely wrong at worst — that is, if it exists at all.&lt;/p&gt;
      &lt;head rend="h3"&gt;The opportunity&lt;/head&gt;
      &lt;p&gt;McKinsey estimates that “by 2030, the US B2C retail market alone could see up to $1 trillion in orchestrated revenue from agentic commerce, with global projections reaching as high as $3 trillion to $5 trillion.” That future is impossible without great product data.&lt;/p&gt;
      &lt;head rend="h3"&gt;The team&lt;/head&gt;
      &lt;p&gt;Alex (CEO) and George (CTO) have been friends since the first day of Duke. Alex began coding at 9, started his first company at 12, and most recently led AI projects at studio.com, where he got this idea. George published research on automating astronomy with robots at 18, and worked on big-data problems at Palantir for the past 2 years.&lt;/p&gt;
      &lt;p&gt;Evan and Ignacio are our founding engineers, both joining us from AWS. Evan earned a Masters in CS at Penn and built the first working example of agentic commerce. Ignacio studied CS at Duke with Alex + George and worked on agentic commerce at AWS.&lt;/p&gt;
      &lt;p&gt;Our team is all engineers; we ship fast.&lt;/p&gt;
      &lt;p&gt;Unfortunately, we are not able to sponsor visas at this time. You must have authorization to work in the US.&lt;/p&gt;
      &lt;head rend="h3"&gt;Our progress so far&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;We’ve indexed 100M+ products&lt;/item&gt;
        &lt;item&gt;1500+ developers have started using our API&lt;/item&gt;
        &lt;item&gt;We’re scoping pilots with some serious enterprise customers&lt;/item&gt;
        &lt;item&gt;We’ve partnered with tens of thousands of brands via our affiliate network integrations&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What you’ll do&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Write code to understand 1B products. We stitch together the latest language, embedding, image, and segmentation models to build a true understanding of each and every product. &lt;list rend="ul"&gt;&lt;item&gt;Product pages vary greatly across retailers. We’ve built a computer-vision system that can understand any PDP, with no custom code or manual intervention on any site.&lt;/item&gt;&lt;item&gt;Deduplicating products across merchants is really hard. Products are described differently, often have different images, and almost never have stable identifiers. We use multimodal models to help us understand different products and match them.&lt;/item&gt;&lt;item&gt;Understanding what variants a product comes in might be even harder. We want to know what colors and sizes every shirt comes in, and what configurations customers can order for a new couch.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Build world-class search. Developers should be able to find “outdoor grills from Weber, less than $1000, with 4 burners,” “running sneakers under 300g, size 12,” or “this couch [image] but in green” — in under 2 seconds. &lt;list rend="ul"&gt;&lt;item&gt;Embeddings get us 80% of the way there, but we’re always looking to add structured data that lets developers construct powerful queries with deterministic filters.&lt;/item&gt;&lt;item&gt;Lately, we’ve been ideating about how to return “good” results, which we’ve learned is not just the highest keyword/semantic match.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Engineer for reliability and cost. Create evals to measure drift, and guardrails to prevent regressions and hallucinations. Be clever and scrappy to reduce database cost and token usage everywhere we can. &lt;list rend="ul"&gt;&lt;item&gt;We use billions and billions of tokens a month, across self-hosted open-source models and flagship models across GCP + Azure. We embed every product, we look at every image with AI, and we run dozens of calls per product — it’s necessary, but it adds up. We’re always looking to reduce token usage, rely on a smaller model, or do some clever context engineering to reduce input tokens.&lt;/item&gt;&lt;item&gt;We structure the world’s product data — and we have to store it and search through it (both internally to find matches and to power our API). We’ve taken many steps towards making this economical, and will continue to do so.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Why join us&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;The time is right: AI is finally smart and inexpensive enough to make a universal product graph technically possible; agentic commerce creates immediate demand and a clear monetization path.&lt;/item&gt;
        &lt;item&gt;We’re moving fast: We’re up and running, with 1500+ developers building on our API, customers eagerly awaiting features, and millions of products processed every day.&lt;/item&gt;
        &lt;item&gt;You’ll have direct ownership of technical and infrastructure decisions, roadmap, and prioritization. You’ll help us grow the team and build our culture from the ground up.&lt;/item&gt;
        &lt;item&gt;We’re having lots of fun: We enjoy working together, we take pride in building really good tech, and we all look forward to coming to work each day.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;How we work&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;We work out of our sunny office in Flatiron (54 W 21st St) in-person together Monday through Friday.&lt;/item&gt;
        &lt;item&gt;Over the weekend, the expectation is to get a day’s work of worth done. Some of us come in to the office, but that’s not expected. Work however you want to get your work done.&lt;/item&gt;
        &lt;item&gt;We provide dinner Monday-Thursday, plus any snacks you want (we’re across the street from a Trader Joe’s).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Investors&lt;/head&gt;
      &lt;p&gt;We raised a $6M seed round in August 2025, led by Matrix (Apple, FedEx, Afterpay, Oculus) with participation from Ludlow (Honey, StockX), Y Combinator, Paul Graham, a16z + Index scouts, and a couple dozen angels (mostly ex-YC founders).&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46690920</guid><pubDate>Tue, 20 Jan 2026 12:00:31 +0000</pubDate></item><item><title>Show HN: Ocrbase – pdf → .md/.json document OCR and structured extraction API</title><link>https://github.com/majcheradam/ocrbase</link><description>&lt;doc fingerprint="e23f33456f2df6ca"&gt;
  &lt;main&gt;
    &lt;p&gt;Turn PDFs into structured data at scale. Powered by frontier open-weight OCR models with a type-safe TypeScript SDK.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Best-in-class OCR - PaddleOCR-VL-0.9B for accurate text extraction&lt;/item&gt;
      &lt;item&gt;Structured extraction - Define schemas, get JSON back&lt;/item&gt;
      &lt;item&gt;Built for scale - Queue-based processing for thousands of documents&lt;/item&gt;
      &lt;item&gt;Type-safe SDK - Full TypeScript support with React hooks&lt;/item&gt;
      &lt;item&gt;Real-time updates - WebSocket notifications for job progress&lt;/item&gt;
      &lt;item&gt;Self-hostable - Run on your own infrastructure&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;bun add @ocrbase/sdk&lt;/code&gt;
    &lt;code&gt;import { createOCRBaseClient } from "@ocrbase/sdk";

const client = createOCRBaseClient({ baseUrl: "https://your-instance.com" });

// Process a document
const job = await client.jobs.create({ file: document, type: "parse" });
const result = await client.jobs.get(job.id);

console.log(result.markdownResult);&lt;/code&gt;
    &lt;p&gt;See SDK documentation for React hooks and advanced usage.&lt;/p&gt;
    &lt;p&gt;See Self-Hosting Guide for deployment instructions.&lt;/p&gt;
    &lt;p&gt;Requirements: Docker, Bun, CUDA GPU with 12GB+ VRAM&lt;/p&gt;
    &lt;p&gt;MIT - See LICENSE for details.&lt;/p&gt;
    &lt;p&gt;For API access, on-premise deployment, or questions: adammajcher20@gmail.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46691454</guid><pubDate>Tue, 20 Jan 2026 13:10:08 +0000</pubDate></item><item><title>The Zen of Reticulum</title><link>https://github.com/markqvist/Reticulum/blob/master/Zen%20of%20Reticulum.md</link><description>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46691660</guid><pubDate>Tue, 20 Jan 2026 13:34:16 +0000</pubDate></item><item><title>IP Addresses Through 2025</title><link>https://www.potaroo.net/ispcol/2026-01/addr2025.html</link><description>&lt;doc fingerprint="ebb551d3b023b3eb"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;The ISP Column&lt;/p&gt;
          &lt;p&gt; A column on things Internet&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt; IP Addresses through 2025 &lt;lb/&gt; January 2026 &lt;/p&gt;
    &lt;p&gt;It's time for another annual roundup from the world of IP addresses. Letâs see what has changed in the past 12 months in addressing the Internet and look at how IP address allocation information can inform us of the changing nature of the network itself.&lt;/p&gt;
    &lt;p&gt;Back around 1992, the IETF gazed into their crystal ball and tried to understand how the Internet was going to evolve and what demands that would place on the addressing system as part of the âIP Next Generationâ study. The staggeringly large numbers of connected devices that we see today were certainly within the range predicted by that study. The assumption made at the time was that we would continue to use much the same IP protocol architecture, including the requirement that each connected device was assigned a unique IP address, and the implication was that the 32-bit address field defined in version 4 of the IP protocol was clearly going to be inadequate to cope with the predicted number of connected devices. A span of 4 billion address values was just not large enough.&lt;/p&gt;
    &lt;p&gt;We concluded at the time that the only way we could make the Internet work across such a massive pool of connected devices was to deploy a new IP protocol that came with a massively larger address space. It was from this reasoning that IPv6 was designed, as this world of abundant silicon processors connected to a single public Internet was the scenario that IPv6 was primarily intended to solve. The copious volumes of a 128-bit address space were intended to allow us to uniquely assign a public IPv6 address to every such device, no matter how small, or in whatever volume they might be deployed.&lt;/p&gt;
    &lt;p&gt;But while the Internet has grown at amazing speeds across the ensuing 33 years, the deployment of IPv6 has proceeded at a more measured pace. There is still no evidence of any common sense of urgency about the deployment of IPv6 in the public Internet, and still there is no common agreement that the continued reliance on IPv4 is failing us.&lt;/p&gt;
    &lt;p&gt;Much of the reason for this apparent contradiction between the addressed device population of the IPv4 Internet and the actual count of connected devices, which is of course many times larger, is that through the 1990's the Internet rapidly changed from a peer-to-peer architecture to a client/server framework. Clients can initiate network transactions with servers but are incapable of initiating transactions with other clients. Servers are capable of completing connection requests from clients, but cannot initiate such connections with clients. Network Address Translators (NATs) are a natural fit to this client/server model, where pools of clients share a smaller pool of public addresses, and only require the use of an address once they have initiated an active session with a remote server. NATs are the reason why a pool of excess of 30 billion connected devices can be squeezed into a far smaller pool of some 3 billion advertised IPv4 addresses. Services and Applications that cannot work behind NATs are no longer useful in the context of the public Internet and no longer used as a result. In essence, what we did was to drop the notion that an IP address is uniquely associated with a device's identity, and the resultant ability to share addresses across clients largely alleviated the immediacy of the IPv4 addressing problem for the Internet.&lt;/p&gt;
    &lt;p&gt;However, the pressures of this inexorable growth in the number of deployed devices connected to the Internet implies that the even NATs cannot absorb these growth pressures forever. NATs can extend the effective addressable space in IPv4 by up to 32 âextraâ bits using mapping of the 16-bit source and destination port fields of the TCP and UDP headers, and they also enable the time-based sharing of these public addresses. Both of these measures are effective in stretching the IPv4 address space to encompass a larger client device pool, but they do not transform the finite IP address space into an infinitely elastic resource. The inevitable outcome of this process, if it were to be constrained to operate solely within IPv4, is that we would see the fragmenting of the IPv4 Internet into a number of disconnected parts, probably based on the service âconesâ of the various points of presence of the content distribution servers, so that the entire concept of a globally unique and coherent address pool layered over a single coherent packet transmission realm would be foregone.&lt;/p&gt;
    &lt;p&gt;Alternatively, we may see these growth pressures motivate the further deployment of IPv6, and the emergence of IPv6-only elements of the Internet as the network itself tries to maintain a cohesive and connected whole. There are commercial pressures pulling the network in both of these directions, so itâs entirely unclear what path the Internet will follow in the coming years, but my (admittedly cynical and perhaps overly jaded) personal opinion lies in a future of highly fragmented network, as least in terms of the underlying packet connectivity protocol.&lt;/p&gt;
    &lt;p&gt;Can address allocation data help us to shed some light on what is happening in the larger Internet? Letâs look at what happened in 2025.&lt;/p&gt;
    &lt;p&gt;It appears that the process of exhausting the remaining pools of unallocated IPv4 addresses is proving to be as protracted as the process of the transition to IPv6, although by the end of 2021 the end of the old registry allocation model had effectively occurred with the depletion of the residual pools of unallocated addresses in each of the Regional Internet Registries (RIRs).&lt;/p&gt;
    &lt;p&gt;It is difficult to talk about âallocationsâ in todayâs Internet. There are still a set of transactions where addresses are drawn from the residual pools of RIR-managed available address space and allocated or assigned to network operators, but at the same time there are also a set of transactions where addresses are traded between network in what is essentially a "sale". These address transfers necessarily entail a change of registration details, so the registry records the outcome of a transfer, or sale, in a manner that is similar to an allocation or assignment.&lt;/p&gt;
    &lt;p&gt;If we want to look at the larger picture of the amount of IPv4 address space that is used or usable by Internet network operators, then perhaps the best metric to use is the total span of allocated and assigned addresses, and the consequent indication of annual change in the change in this total address span from year to year.&lt;/p&gt;
    &lt;p&gt;What is the difference between "allocated" and "assigned"?&lt;/p&gt;
    &lt;p&gt;When a network operator or sub-registry has received an allocation it can further delegate that IP address space to their customers along with using it for their own internal infrastructure. When a network operator has received an assignment this can only be used for their own internal infrastructure. [https://help.apnic.net/s/article/Using-address-space]&lt;/p&gt;
    &lt;p&gt;I personally find the distinction between these two terms somewhat of an artifice these days, so from here on Iâll use the term âallocation" to describe both allocations and assignments.&lt;/p&gt;
    &lt;p&gt;The total IPv4 allocated address pool contracted by some 237 thousand addresses in 2025, with some 3.687 billion allocated addresses at the end of the year. This represented a contraction of some 0.01% for the total allocated IPv4 public address pool through 2025 (Table 1).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="16"&gt;
        &lt;cell role="head"&gt;2011&lt;/cell&gt;
        &lt;cell role="head"&gt;2012&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="16"&gt;
        &lt;cell&gt;Address Span (B)&lt;/cell&gt;
        &lt;cell&gt;3.395&lt;/cell&gt;
        &lt;cell&gt;3.483&lt;/cell&gt;
        &lt;cell&gt;3.537&lt;/cell&gt;
        &lt;cell&gt;3.593&lt;/cell&gt;
        &lt;cell&gt;3.624&lt;/cell&gt;
        &lt;cell&gt;3.643&lt;/cell&gt;
        &lt;cell&gt;3.657&lt;/cell&gt;
        &lt;cell&gt;3.657&lt;/cell&gt;
        &lt;cell&gt;3.682&lt;/cell&gt;
        &lt;cell&gt;3.684&lt;/cell&gt;
        &lt;cell&gt;3.685&lt;/cell&gt;
        &lt;cell&gt;3.687&lt;/cell&gt;
        &lt;cell&gt;3.686&lt;/cell&gt;
        &lt;cell&gt;3.687&lt;/cell&gt;
        &lt;cell&gt;3.687&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="16"&gt;
        &lt;cell&gt;Annual Change (M)&lt;/cell&gt;
        &lt;cell&gt;168.0&lt;/cell&gt;
        &lt;cell&gt;88.4&lt;/cell&gt;
        &lt;cell&gt;53.9&lt;/cell&gt;
        &lt;cell&gt;55.9&lt;/cell&gt;
        &lt;cell&gt;30.6&lt;/cell&gt;
        &lt;cell&gt;19.4&lt;/cell&gt;
        &lt;cell&gt;13.2&lt;/cell&gt;
        &lt;cell&gt;0.6&lt;/cell&gt;
        &lt;cell&gt;24.9&lt;/cell&gt;
        &lt;cell&gt;2.2&lt;/cell&gt;
        &lt;cell&gt;1.1&lt;/cell&gt;
        &lt;cell&gt;1.6&lt;/cell&gt;
        &lt;cell&gt;-0.4&lt;/cell&gt;
        &lt;cell&gt;1.2&lt;/cell&gt;
        &lt;cell&gt;-0.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Relative Growth&lt;/cell&gt;
        &lt;cell&gt;5.2%&lt;/cell&gt;
        &lt;cell&gt;2.6%&lt;/cell&gt;
        &lt;cell&gt;1.5%&lt;/cell&gt;
        &lt;cell&gt;1.6%&lt;/cell&gt;
        &lt;cell&gt;0.85%&lt;/cell&gt;
        &lt;cell&gt;0.53%&lt;/cell&gt;
        &lt;cell&gt;0.36%&lt;/cell&gt;
        &lt;cell&gt;0.02%&lt;/cell&gt;
        &lt;cell&gt;0.68%&lt;/cell&gt;
        &lt;cell&gt;0.06%&lt;/cell&gt;
        &lt;cell&gt;0.03%&lt;/cell&gt;
        &lt;cell&gt;0.04%&lt;/cell&gt;
        &lt;cell&gt;-0.01%&lt;/cell&gt;
        &lt;cell&gt;0.03%&lt;/cell&gt;
        &lt;cell&gt;-0.2%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Have we exhausted all the available sources of further IPv4 addresses? The address management model is that unallocated addresses are held in a single pool by the Internet Assigned Numbers Authority, and blocks of addresses are passed to RIRs, who then allocate them to various end entities, either for their own use or for further allocation. The IANA exhausted the last of its available address pools some years ago, and these days it holds just 3 /24 address prefixes, and has done do for the past 13 years. Because the option of dividing this tiny address pool into 5 equal chunks of 153.6 individual address is not viable, then these 768 individual IPv4 addresses are likely to sit in the IANA Recovered Address registry for some time.&lt;/p&gt;
    &lt;p&gt;That is, until one of more of the RIRs return more prefixes recovered from the old âlegacy" allocated addresses to the IANA, who would then be able to divide the pool equally and distribute them to each the 5 RIRs. This is unlikely to occur.&lt;/p&gt;
    &lt;p&gt;There are also addresses that have been marked by the IANA as reserved for "special uses"". This includes blocks of addresses reserved for Multicast use. At the top end of the IPv4 address space registry there is a set of addresses that are marked as reserved for "Future Use"". This is a relatively large pool of 268,435,456 addresses (the old former âClass E" space) and if ever there was a âfuture" for IPv4 then it has well and truly come and gone. But exactly how to unlock this space and return it to the general use pool is a problem that so far has not found a generally workable solution, although efforts to do so have surfaced in the community from time to time.&lt;/p&gt;
    &lt;p&gt;The topic of releasing the Class E space for use in the public Internet as globally routable unicast address space has been raised from time to time over the past 15 years or so. Some Internet drafts were published for the IETFâs consideration that either directly proposed releasing this space for use, or outlined the impediments in various host and router implementations that were observed to exist in 2008 when these drafts were being developed.&lt;/p&gt;
    &lt;p&gt;The proposals lapsed, probably due to the larger consideration at the time that the available time and resources to work on these issues were limited and the result of effort spent in âconditioningâ this IPv4 space for general use was only going to obtain a very small extension in the anticipated date of depletion of the remaining IPv4 address pools, while the same amount of effort spent on working on advancing IPv6 deployment was assumed to have a far larger beneficial outcome.&lt;/p&gt;
    &lt;p&gt;From time to time this topic reappears on various mailing lists and blogs (see https://www.potaroo.net/ispcol/2024-09/2404.html, for example), but the debates tend to circle around this same set of topics one more time, and then lapse.&lt;/p&gt;
    &lt;p&gt;As the IANA is no longer a source of addresses, then we need to look at the RIR practices to see the life cycle of addresses from the registryâs perspective. When IP address space is returned to the RIR or reclaimed by the RIR according to the RIRâs policies it is normally placed in a RIR-reserved pool for a period of time and marked as reserved by the RIR. Marking returned or recovered addresses as reserved for a period of time allows various address prefix reputation and related services, including routing records, some time to record the cessation of the previous state of the addresses prefix, prior to any subsequent allocation. Following this quarantine period, which has been between some months and some years, this reserved space is released for re-use.&lt;/p&gt;
    &lt;p&gt;The record of annual year-on-year change in allocated addresses per RIR over the same fourteen-year period is shown in Table 2. There are some years when the per-RIR pool of allocated addresses shrunk is size. This is generally due to inter-RIR movement of addresses, due to administrative changes in some instances and inter-RIR address transfers in others.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="16"&gt;
        &lt;cell role="head"&gt;2011&lt;/cell&gt;
        &lt;cell role="head"&gt;2012&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="16"&gt;
        &lt;cell&gt;APNIC&lt;/cell&gt;
        &lt;cell&gt;101.0&lt;/cell&gt;
        &lt;cell&gt;0.6&lt;/cell&gt;
        &lt;cell&gt;1.2&lt;/cell&gt;
        &lt;cell&gt;4.6&lt;/cell&gt;
        &lt;cell&gt;7.4&lt;/cell&gt;
        &lt;cell&gt;6.7&lt;/cell&gt;
        &lt;cell&gt;3.2&lt;/cell&gt;
        &lt;cell&gt;0.4&lt;/cell&gt;
        &lt;cell&gt;10.5&lt;/cell&gt;
        &lt;cell&gt;1.7&lt;/cell&gt;
        &lt;cell&gt;1.5&lt;/cell&gt;
        &lt;cell&gt;0.8&lt;/cell&gt;
        &lt;cell&gt;-1.1&lt;/cell&gt;
        &lt;cell&gt;-0.8&lt;/cell&gt;
        &lt;cell&gt;0.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="16"&gt;
        &lt;cell&gt;RIPE NCC&lt;/cell&gt;
        &lt;cell&gt;40.5&lt;/cell&gt;
        &lt;cell&gt;37.8&lt;/cell&gt;
        &lt;cell&gt;1.0&lt;/cell&gt;
        &lt;cell&gt;33.8&lt;/cell&gt;
        &lt;cell&gt;4.7&lt;/cell&gt;
        &lt;cell&gt;4.1&lt;/cell&gt;
        &lt;cell&gt;3.7&lt;/cell&gt;
        &lt;cell&gt;0.3&lt;/cell&gt;
        &lt;cell&gt;12.0&lt;/cell&gt;
        &lt;cell&gt;0.4&lt;/cell&gt;
        &lt;cell&gt;2.5&lt;/cell&gt;
        &lt;cell&gt;4.7&lt;/cell&gt;
        &lt;cell&gt;6.2&lt;/cell&gt;
        &lt;cell&gt;0.5&lt;/cell&gt;
        &lt;cell&gt;8.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="16"&gt;
        &lt;cell&gt;ARIN&lt;/cell&gt;
        &lt;cell&gt;53.8&lt;/cell&gt;
        &lt;cell&gt;24.3&lt;/cell&gt;
        &lt;cell&gt;19.0&lt;/cell&gt;
        &lt;cell&gt;-14.1&lt;/cell&gt;
        &lt;cell&gt;2.3&lt;/cell&gt;
        &lt;cell&gt;-4.8&lt;/cell&gt;
        &lt;cell&gt;-2.3&lt;/cell&gt;
        &lt;cell&gt;-0.3&lt;/cell&gt;
        &lt;cell&gt;-10.1&lt;/cell&gt;
        &lt;cell&gt;-0.9&lt;/cell&gt;
        &lt;cell&gt;-1.7&lt;/cell&gt;
        &lt;cell&gt;-3.8&lt;/cell&gt;
        &lt;cell&gt;-5.5&lt;/cell&gt;
        &lt;cell&gt;-3.0&lt;/cell&gt;
        &lt;cell&gt;-2.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="16"&gt;
        &lt;cell&gt;LACNIC&lt;/cell&gt;
        &lt;cell&gt;13.6&lt;/cell&gt;
        &lt;cell&gt;17.3&lt;/cell&gt;
        &lt;cell&gt;26.3&lt;/cell&gt;
        &lt;cell&gt;18.7&lt;/cell&gt;
        &lt;cell&gt;1.2&lt;/cell&gt;
        &lt;cell&gt;1.5&lt;/cell&gt;
        &lt;cell&gt;1.4&lt;/cell&gt;
        &lt;cell&gt;0.1&lt;/cell&gt;
        &lt;cell&gt;2.4&lt;/cell&gt;
        &lt;cell&gt;1.2&lt;/cell&gt;
        &lt;cell&gt;-0.2&lt;/cell&gt;
        &lt;cell&gt;-0.3&lt;/cell&gt;
        &lt;cell&gt;-0.1&lt;/cell&gt;
        &lt;cell&gt;0.0&lt;/cell&gt;
        &lt;cell&gt;-7.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="16"&gt;
        &lt;cell&gt;AFRINIC&lt;/cell&gt;
        &lt;cell&gt;9.4&lt;/cell&gt;
        &lt;cell&gt;8.5&lt;/cell&gt;
        &lt;cell&gt;6.3&lt;/cell&gt;
        &lt;cell&gt;12.8&lt;/cell&gt;
        &lt;cell&gt;15.0&lt;/cell&gt;
        &lt;cell&gt;11.9&lt;/cell&gt;
        &lt;cell&gt;7.1&lt;/cell&gt;
        &lt;cell&gt;0.2&lt;/cell&gt;
        &lt;cell&gt;10.1&lt;/cell&gt;
        &lt;cell&gt;-0.2&lt;/cell&gt;
        &lt;cell&gt;-0.9&lt;/cell&gt;
        &lt;cell&gt;0.2&lt;/cell&gt;
        &lt;cell&gt;0.1&lt;/cell&gt;
        &lt;cell&gt;0.0&lt;/cell&gt;
        &lt;cell&gt;0.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;TOTAL&lt;/cell&gt;
        &lt;cell&gt;218.3&lt;/cell&gt;
        &lt;cell&gt;88.5&lt;/cell&gt;
        &lt;cell&gt;53.8&lt;/cell&gt;
        &lt;cell&gt;55.8&lt;/cell&gt;
        &lt;cell&gt;30.6&lt;/cell&gt;
        &lt;cell&gt;19.4&lt;/cell&gt;
        &lt;cell&gt;13.1&lt;/cell&gt;
        &lt;cell&gt;0.7&lt;/cell&gt;
        &lt;cell&gt;24.9&lt;/cell&gt;
        &lt;cell&gt;2.2&lt;/cell&gt;
        &lt;cell&gt;1.2&lt;/cell&gt;
        &lt;cell&gt;1.6&lt;/cell&gt;
        &lt;cell&gt;-0.4&lt;/cell&gt;
        &lt;cell&gt;1.2&lt;/cell&gt;
        &lt;cell&gt;-0.2&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Each of the RIRs are running through their final pools of IPv4 addresses. At the end of 2025, across the RIR system there are some 3.9 million addresses are in the Available Pool, held mainly in APNIC (3.1 million) and AFRINIC (773 thousand). Some 11.2 million addresses are marked as Reserved, with 5.6 million held by ARIN and 4.5 million addresses held by AFRINIC. As seen in Table 3, there has been a reduction in the Reserved Pool for all RIRs, except AFRINIC, and the major reductions were seen in APNIC (1.7M) and ARIN (600K) in ARIN (98K).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;Available&lt;/cell&gt;
        &lt;cell role="head"&gt;Reserved&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;RIR&lt;/cell&gt;
        &lt;cell&gt;2023&lt;/cell&gt;
        &lt;cell&gt;2024&lt;/cell&gt;
        &lt;cell&gt;2025&lt;/cell&gt;
        &lt;cell&gt;2023&lt;/cell&gt;
        &lt;cell&gt;2024&lt;/cell&gt;
        &lt;cell&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;APNIC&lt;/cell&gt;
        &lt;cell&gt;2,469,120&lt;/cell&gt;
        &lt;cell&gt;3,647,488&lt;/cell&gt;
        &lt;cell&gt;3,107,392&lt;/cell&gt;
        &lt;cell&gt;2,202,624&lt;/cell&gt;
        &lt;cell&gt;416,256&lt;/cell&gt;
        &lt;cell&gt;465,152&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;RIPE NCC&lt;/cell&gt;
        &lt;cell&gt;1,024&lt;/cell&gt;
        &lt;cell&gt;256&lt;/cell&gt;
        &lt;cell&gt;1,536&lt;/cell&gt;
        &lt;cell&gt;708,872&lt;/cell&gt;
        &lt;cell&gt;677,160&lt;/cell&gt;
        &lt;cell&gt;782,440&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;ARIN&lt;/cell&gt;
        &lt;cell&gt;8,960&lt;/cell&gt;
        &lt;cell&gt;3,840&lt;/cell&gt;
        &lt;cell&gt;66,560&lt;/cell&gt;
        &lt;cell&gt;5,213,184&lt;/cell&gt;
        &lt;cell&gt;4,609,792&lt;/cell&gt;
        &lt;cell&gt;5,424,640&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;LACNIC&lt;/cell&gt;
        &lt;cell&gt;256&lt;/cell&gt;
        &lt;cell&gt;1,536&lt;/cell&gt;
        &lt;cell&gt;2,304&lt;/cell&gt;
        &lt;cell&gt;151,296&lt;/cell&gt;
        &lt;cell&gt;118,528&lt;/cell&gt;
        &lt;cell&gt;118,528&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;AFRINIC&lt;/cell&gt;
        &lt;cell&gt;1,201,664&lt;/cell&gt;
        &lt;cell&gt;990,976&lt;/cell&gt;
        &lt;cell&gt;773,631&lt;/cell&gt;
        &lt;cell&gt;4,186,112&lt;/cell&gt;
        &lt;cell&gt;4,443,648&lt;/cell&gt;
        &lt;cell&gt;4,480,512&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;TOTAL&lt;/cell&gt;
        &lt;cell&gt;3,681,024&lt;/cell&gt;
        &lt;cell&gt;4,644,096&lt;/cell&gt;
        &lt;cell&gt;3,951,424&lt;/cell&gt;
        &lt;cell&gt;12,462,088&lt;/cell&gt;
        &lt;cell&gt;10,265,384&lt;/cell&gt;
        &lt;cell&gt;11,271,272&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The RIR IPv4 address allocation volumes by year are shown in Figure 1, but it is challenging to understand precisely what is meant by an allocation across the entire RIR system as there are some subtle but important differences between RIRs, particularly as they relate to the handling of transfers of IPv4 addresses.&lt;/p&gt;
    &lt;p&gt;In the case of ARIN, a transfer between two ARIN-serviced entities is conceptually treated as two distinct transactions: a return of the addresses to the ARIN registry and a new allocation from ARIN. The date of the transfer is recorded as the new allocation date in the records published by the RIR. Other RIRs treat an address transfer in a manner analogous to a change of the nominated holder of the already-allocated addresses, and when processing a transfer, the RIRâs records preserve the original allocation date for the transferred addresses. When we look at the individual transaction records in the published RIR data, and collect then by year, then in the case of ARIN the collected data includes the volume of transferred addresses that were processed in that year, while the other RIRs only include the allocations performed in that year.&lt;/p&gt;
    &lt;p&gt;In order to provide a view across the entire system, it's necessary to use an analysis approach that can compensate for these differences in the ways RIRs record address transactions. In this study, an allocation is defined here as a state transition in the registry records from reserved or available to an allocated state. This is intended to separate out the various actions associated with processing address transfers, which generally involve no visible state change, as the transferred address block remains allocated across the transfer, from address allocations. This is how the data used to generate Figure 1 has been generated from the RIR published data, comparing the status of the address pools at the end of each year to that of the status at the start of the year. An allocation in that year is identified as allocated in that year if the address block was not registered as allocated at the start of the year.&lt;/p&gt;
    &lt;p&gt;The number of RIR IPv4 allocations by year, once again generated by using the same data analysis technique as used for Figure 1, are shown in Figure 2.&lt;/p&gt;
    &lt;p&gt;It is clear from these two figures that the average size of an IPv4 address allocation has shrunk considerably in recent years, corresponding to the various IPv4 address exhaustion policies in each of the RIRs.&lt;/p&gt;
    &lt;p&gt;To recap, when addresses are held by an RIR they are classified into one of three states:&lt;/p&gt;
    &lt;p&gt;The pool size of available addresses over the past five years for each RIR is shown Figure 3.&lt;/p&gt;
    &lt;p&gt;Only APNIC and AFRINIC are operating with relatively large pools of available addresses. At the start of 2026 APNIC had some 2,849 address blocks in its registry that were marked as available, with a total pool size of 3.095M addresses. AFRINIC has 19 address blocks similarly marked, with a total pool size of 0.765M addresses. For both of these RIRs, the allocation rates from these pools are small, and even without any further returns of addresses these available address pools will likely last from some years to come at current allocation rates.&lt;/p&gt;
    &lt;p&gt;There are some 11.169M addresses in the RIRs' reserved address pools. Between 2020 and 2025 APNIC reduced the size of its reserved address pool by some 4M addresses, and the current reserved pool is 0.454M addresses in APNIC. Both RIPE NCC and LACNIC have similarly small reserved address pools these days. The majority of the total pool of reserved address space lies with AFRINIC, which has 543 separate reserved address blocks with a total span of 4.481M addresses, and ARIN, which has 3,765 such address blocks with a total span of 5.2865M addresses. The AFRINIC pool size has been slowly increasing in size, while the ARIN pool size was declining up to 2025, and increased in size through 2025 (Figure 4).&lt;/p&gt;
    &lt;p&gt;At the start of 2026, 45% of the total pool of 3.687B allocated IPv4 addresses are held in ARIN's registry, 24% in APNIC's registry, 23% in the RIPE NCC, 5% in LACNIC and 3% in ARINIC.&lt;/p&gt;
    &lt;p&gt;The RIRs permit the registration of IPv4 transfers between address holders, as a means of allowing secondary re-distribution of addresses as an alternative to returning unused addresses to the registry. This has been in response to the issues raised by IPv4 address exhaustion, where the underlying motivation as to encourage the reuse of otherwise idle or inefficiently used address blocks through the incentives provided by a market for addresses, and to ensure that such address movement is publicly recorded in the registry system.&lt;/p&gt;
    &lt;p&gt;The number of registered transfers in the past eleven years is shown in Table 4. This number of transfers includes both inter-RIR and intra-RIR transfers. It also includes both the merger and acquisition-based transfers and the other grounds for of address transfers. Each transfer is treated as a single transaction, and in the case of inter-RIR transfers, this is accounted in the receiving RIRâs totals.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="14"&gt;
        &lt;cell role="head"&gt;Receiving RIR&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;APNIC&lt;/cell&gt;
        &lt;cell&gt;180&lt;/cell&gt;
        &lt;cell&gt;307&lt;/cell&gt;
        &lt;cell&gt;451&lt;/cell&gt;
        &lt;cell&gt;840&lt;/cell&gt;
        &lt;cell&gt;845&lt;/cell&gt;
        &lt;cell&gt;491&lt;/cell&gt;
        &lt;cell&gt;533&lt;/cell&gt;
        &lt;cell&gt;820&lt;/cell&gt;
        &lt;cell&gt;785&lt;/cell&gt;
        &lt;cell&gt;745&lt;/cell&gt;
        &lt;cell&gt;796&lt;/cell&gt;
        &lt;cell&gt;752&lt;/cell&gt;
        &lt;cell&gt;706&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;RIPE NCC&lt;/cell&gt;
        &lt;cell&gt;171&lt;/cell&gt;
        &lt;cell&gt;1,054&lt;/cell&gt;
        &lt;cell&gt;2,836&lt;/cell&gt;
        &lt;cell&gt;2,373&lt;/cell&gt;
        &lt;cell&gt;2,451&lt;/cell&gt;
        &lt;cell&gt;3,775&lt;/cell&gt;
        &lt;cell&gt;4,221&lt;/cell&gt;
        &lt;cell&gt;4,696&lt;/cell&gt;
        &lt;cell&gt;5,742&lt;/cell&gt;
        &lt;cell&gt;4,640&lt;/cell&gt;
        &lt;cell&gt;4,937&lt;/cell&gt;
        &lt;cell&gt;5,215&lt;/cell&gt;
        &lt;cell&gt;4,196&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;ARIN&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;26&lt;/cell&gt;
        &lt;cell&gt;26&lt;/cell&gt;
        &lt;cell&gt;68&lt;/cell&gt;
        &lt;cell&gt;94&lt;/cell&gt;
        &lt;cell&gt;150&lt;/cell&gt;
        &lt;cell&gt;141&lt;/cell&gt;
        &lt;cell&gt;97&lt;/cell&gt;
        &lt;cell&gt;185&lt;/cell&gt;
        &lt;cell&gt;703&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;LACNIC&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;AFRINIC&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;27&lt;/cell&gt;
        &lt;cell&gt;26&lt;/cell&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;58&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;351&lt;/cell&gt;
        &lt;cell&gt;1,361&lt;/cell&gt;
        &lt;cell&gt;3,290&lt;/cell&gt;
        &lt;cell&gt;3,235&lt;/cell&gt;
        &lt;cell&gt;3,322&lt;/cell&gt;
        &lt;cell&gt;4,311&lt;/cell&gt;
        &lt;cell&gt;4,849&lt;/cell&gt;
        &lt;cell&gt;5,639&lt;/cell&gt;
        &lt;cell&gt;6,766&lt;/cell&gt;
        &lt;cell&gt;5,601&lt;/cell&gt;
        &lt;cell&gt;5,864&lt;/cell&gt;
        &lt;cell&gt;6,184&lt;/cell&gt;
        &lt;cell&gt;5,619&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The differences between RIRs reported numbers are interesting. The policies relating to address transfers do not appear to have been adopted to any significant extent by address holders in AFRINIC and LACNIC serviced regions, while uptake in the RIPE NCC service region appears to be very enthusiastic!&lt;/p&gt;
    &lt;p&gt;A slightly different view is that of the volume of addresses transferred per year (Table 5).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="14"&gt;
        &lt;cell role="head"&gt;Receiving RIR&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;APNIC&lt;/cell&gt;
        &lt;cell&gt;2.3&lt;/cell&gt;
        &lt;cell&gt;4.1&lt;/cell&gt;
        &lt;cell&gt;6.6&lt;/cell&gt;
        &lt;cell&gt;8.2&lt;/cell&gt;
        &lt;cell&gt;4.9&lt;/cell&gt;
        &lt;cell&gt;10.0&lt;/cell&gt;
        &lt;cell&gt;4.3&lt;/cell&gt;
        &lt;cell&gt;16.6&lt;/cell&gt;
        &lt;cell&gt;6.5&lt;/cell&gt;
        &lt;cell&gt;3.7&lt;/cell&gt;
        &lt;cell&gt;2.7&lt;/cell&gt;
        &lt;cell&gt;2.5&lt;/cell&gt;
        &lt;cell&gt;2.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;RIPE NCC&lt;/cell&gt;
        &lt;cell&gt;2.0&lt;/cell&gt;
        &lt;cell&gt;9.6&lt;/cell&gt;
        &lt;cell&gt;11.6&lt;/cell&gt;
        &lt;cell&gt;9.2&lt;/cell&gt;
        &lt;cell&gt;24.6&lt;/cell&gt;
        &lt;cell&gt;19.5&lt;/cell&gt;
        &lt;cell&gt;26.9&lt;/cell&gt;
        &lt;cell&gt;18.2&lt;/cell&gt;
        &lt;cell&gt;16.2&lt;/cell&gt;
        &lt;cell&gt;36.9&lt;/cell&gt;
        &lt;cell&gt;20.8&lt;/cell&gt;
        &lt;cell&gt;23.0&lt;/cell&gt;
        &lt;cell&gt;22.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;ARIN&lt;/cell&gt;
        &lt;cell&gt;0.1&lt;/cell&gt;
        &lt;cell&gt;0.3&lt;/cell&gt;
        &lt;cell&gt;0.2&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.3&lt;/cell&gt;
        &lt;cell&gt;0.2&lt;/cell&gt;
        &lt;cell&gt;0.2&lt;/cell&gt;
        &lt;cell&gt;3.1&lt;/cell&gt;
        &lt;cell&gt;1.6&lt;/cell&gt;
        &lt;cell&gt;4.5&lt;/cell&gt;
        &lt;cell&gt;8.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;LACNIC&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0&lt;/cell&gt;
        &lt;cell&gt;0.0&lt;/cell&gt;
        &lt;cell&gt;0.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="14"&gt;
        &lt;cell&gt;AFRINIC&lt;/cell&gt;
        &lt;cell&gt;0.2&lt;/cell&gt;
        &lt;cell&gt;0.5&lt;/cell&gt;
        &lt;cell&gt;1.2&lt;/cell&gt;
        &lt;cell&gt;3.4&lt;/cell&gt;
        &lt;cell&gt;0.5&lt;/cell&gt;
        &lt;cell&gt;0.1&lt;/cell&gt;
        &lt;cell&gt;0.1&lt;/cell&gt;
        &lt;cell&gt;0.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;4.3&lt;/cell&gt;
        &lt;cell&gt;13.7&lt;/cell&gt;
        &lt;cell&gt;18.2&lt;/cell&gt;
        &lt;cell&gt;17.6&lt;/cell&gt;
        &lt;cell&gt;29.6&lt;/cell&gt;
        &lt;cell&gt;29.7&lt;/cell&gt;
        &lt;cell&gt;31.9&lt;/cell&gt;
        &lt;cell&gt;36.2&lt;/cell&gt;
        &lt;cell&gt;26.4&lt;/cell&gt;
        &lt;cell&gt;44.3&lt;/cell&gt;
        &lt;cell&gt;25.3&lt;/cell&gt;
        &lt;cell&gt;30.2&lt;/cell&gt;
        &lt;cell&gt;33.4&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;A plot of these numbers is shown in Figures 5 and 6.&lt;/p&gt;
    &lt;p&gt;The volumes of transferred addresses reached a peak in 2022 and declined in 2023. In the case of APNIC the peak occurred in 2020, and the APNIC 2024 volume is comparable to the volume transferred in 2013. In the ARIN region address transfers are growing in total volume, while in APINC the volume of IPv4 address transfers has largely waned.&lt;/p&gt;
    &lt;p&gt;The aggregate total of addresses that have been listed in these transfer logs since 2012 is some 342 million addresses, or the equivalent of 20.4 /8s, which is some 9.3% of the total delegated IPv4 address space of 3.7 billion addresses. However, that figure is likely to be an overestimate, as a number of address blocks have been transferred multiple times over this period.&lt;/p&gt;
    &lt;p&gt;This data raises some questions about the nature of transfers. The first question is whether address transfers have managed to be effective in dredging the pool of allocated but unadvertised public IPv4 addresses and recycling these addresses back into active use.&lt;/p&gt;
    &lt;p&gt;It was thought that by being able to monetize these addresses, holders of such addresses may have been motivated to convert their networks to use private addresses and resell their holding of public addresses. In other words, the opening of a market in addresses would provide incentive for otherwise unproductive address assets to be placed on the market. Providers who had a need for addresses would compete with other providers who had a similar need in bidding to purchase these addresses. In conventional market theory the most efficient user of addresses (here âmost efficientâ is based on the ability to use addresses to generate the greatest revenue) would be able to set the market price. Otherwise unused addresses would be put to productive use, and as long as demand outstrips supply the most efficient use of addresses is promoted by the actions of the market. In theory.&lt;/p&gt;
    &lt;p&gt;However, the practical experience with transfers is not so clear. The data relating to address re-cycling is inconclusive. In the period 2000 to 2010, the pool of unadvertised assigned IP4 addresses increased in size from 600M to 900M addresses, which was almost one third of the assigned address pool. In the ensuring 11 years to pool of unadvertised assigned addresses fell to around 800M addresses, with the bulk of that reduction occurring in 2015. There was a substantial reduction in the size of this unadvertised address pool at the start of 2021, due to the announcement in the Internetâs routing system of some seven /8s from the address space originally allocated to the US Department of Defence in the early days of the ARPANET. At the end of 2021 AS749 originated more IPv4 addresses than any other network, namely some 211,581,184 addresses, or the equivalent of a /4.34 in prefix length notation, or some 5% of the total IPv4 address pool. Across 2022 and 2023 the previous trend of an increasing pool of unadvertised addresses resumed. On December 12 2024, a total of some 81,224,704 addresses (the equivalent of 4.8 /8s) was advertised by ASes operated by Amazon, mainly AS16509, bringing the total pool of unadvertised addresses down to a level last observed in the year 2000. Across 2025 the pool of unadvertised assigned IP4 addresses has increased slightly (Figure 7).&lt;/p&gt;
    &lt;p&gt;The larger picture of the three IPv4 address pool sizes, allocated, advertised and unadvertised address pools since the start of 2000 is shown in Figure 6. The onset of more restrictive address policies coincides with the exhaustion of the central IANA unallocated address pool in early 2011, and the period since that date has seen the RIRs run down their address pools.&lt;/p&gt;
    &lt;p&gt;We can also look at the year 2025, looking at the changes in these address pools since the start of the year, as shown in Figure 9. The total span of advertised addresses fell by a total of 10M addresses through the year.&lt;/p&gt;
    &lt;p&gt;That change in the blue trace in Figure 9, the total allocated address pool, can be attributed to LACNIC, where some 7M addresses were market as available through March 2025, and then passed back into the advertised pool in early April 2025.&lt;/p&gt;
    &lt;p&gt;Four of the major step changes through the year in the advertised address span (5 January, 5 May, 5 November and 11 December) can be attributed to AS16509 (Amazon 02), and the day-by-day record of the total address span advertised by this AS is shown in Figure 10. Amazon has advertised a total of an additional 12M addresses through 2025, peaking at 168M addresses at the start of November. On the 5th November, Amazon stopped announcing a collection of prefixes with a total span of 15.744M addresses. A month later, on the 10th December some 5.039 M additional addresses were announced bringing the total span of addresses announce by AS16509 Amazon at the year's end to 157.425 addresses, just 2.777M more than the 154.763M addresses that were announced at the start of 2025.&lt;/p&gt;
    &lt;p&gt;In relative terms, expressed as a proportion of the total pool of allocated IP addresses, the unadvertised address pool peaked at 38% of the total assigned address pool in early 2003, and then declined over the ensuing 15 years to a relatively low value of 22% at the start of 2018. The ratio has been steadily climbing since that date, with abrupt falls due to the advertisement of the legacy US Department of Defence address space in 2021, and the Amazon address announcements in December 2024 (Figure 11). The unadvertised address space now sits at some 16% of the total assigned address pool.&lt;/p&gt;
    &lt;p&gt;The data behind Figure 11 gives the impression of a steady effort to recycle otherwise idle IP addresses over the past twenty-five years, and to a certain extent this has been the case. However, the large drop in this ratio in early 2021 was due to the moves by the US DoD to advertise their address holdings to the public Internet, and the large drop in late 2024 was due to Amazon announcing address space that it had previously acquired.&lt;/p&gt;
    &lt;p&gt;The transfer data points to a somewhat sluggish transfer market. The number of transfer transactions is rising, but the total volume of transferred addresses is falling for most RIRs, with the exception of the RIPE NCC (Tables 4 and 5). The address market does not appear to have been all that effective in flushing out otherwise idle addresses and re-deploying them into the routed network. However, as with all other commodity markets, the market price of the commodity reflects the balancing of supply and demand and the future expectations of supply and demand. What can be seen in the price of traded IPv4 addresses over the past 10 years?&lt;/p&gt;
    &lt;p&gt;One of the address brokers, Hilco Streambankâs IPv4.Global, publish the historical price information of transactions (if only all the address brokers did the same, as a market with open price information for transactions can operate more efficiently and fairly than markets where price information is occluded). Figure 12 uses the Hilco Streambank IPv4.Global transaction data to produce a time series of address price.&lt;/p&gt;
    &lt;p&gt;There are a number of distinct behaviour modes in this time series data. The initial data prior to 2016 reflected a relatively low volume of transactions with stable pricing just below $10 per address. Over the ensuing 4 years, up to the start of 2019, the unit price doubled, with small blocks (/24s and /23s) attracting a price premium. The price stabilised for the next 18 months at between $20 to $25 per address, with large and small blocks trading as a similar unit price. The 18 months from mid-2020 up to the start of 2022 saw a new dynamic which was reflective of an exponential rise in prices, and the unit price lifted to between $45 and $60 per address by the end of 2021. The year 2022 saw the average market price drop across the year, but the variance in prices increased and trades at the end of the year were recorded at prices of between $40 to $60 per address.&lt;/p&gt;
    &lt;p&gt;This price decline continued across 2023, and by the end of 2023 IPv4 addresses were traded at unit prices of between $26 to $40. The prices of addresses across 2024 were relatively stable, but the price decline resumed across 2025, with a low of $9 per address (for a /14) and a mean of $22 per address in the most recent 40 days (up to the 10th of January 2026). The average monthly prices for each prefix size in the most recent 25 months is shown in Figure 13.&lt;/p&gt;
    &lt;p&gt;If prices are reflective of supply and demand it appears that the initial period from 2014 to 2022 saw demand increase at a far greater level than supply, and the price escalation reflected some form of perceived scarcity premium being applied to addresses. However, the subsequent price slump shows that this perception was short-lived. These days the low price of $9 per address is back to the same price that was seen in 2014. The difference this time is the range of prices if far greater, and while the mean price is around $22 per address, the price in an individual transaction as high as $34 per address. Generally, larger address blocks fetch a lower price per address in the market, and the January 2026 sale for $9 per address was for a /14 address block.&lt;/p&gt;
    &lt;p&gt;What is this price data telling us? If you were hanging onto some idle IPv4 address hoping for the price to rise, then you may have missed out! Equally if you were looking to fund your costs in transition from a IPv4-only platform to a dual-stack through the sale of part of your IPv4 address holds, then that opportunity may have already passed you by. If you are forecasting a future demand for more IPv4 addresses in your enterprise then there is no urgency to hit the market and secure IPv4 addresses. If you wait, then the price is likely to drop further.&lt;/p&gt;
    &lt;p&gt;The largest buyer on in the IPv4 market was Amazon, and it appeared that they were meeting demands from enterprise customers of their cloud-based products, a sector that has been very conservative in their moves to transition into a dual stack situation. I think it's reasonable also make the supposition that they saw the price escalation in the period 2014 to 2018 as a signal of a longer-term trend, so securing as much as their forecast future need for IPv4 addresses made sense for them in a rising market. However, once the big data centre buyers had secured their address inventory they then existed the market, and the remainder of the buyers had insufficient volume to sustain the price. Demand fell off and the price slumped from the start of 2022 onward.&lt;/p&gt;
    &lt;p&gt;It's not as if this IPv4 address market has collapsed completely, and Figure 6 shows that in 2025 some 33M IPv4 addresses were transferred within the RIR registry system. But the declining price suggests that supply is running higher than demand and while buyers appear to be willing to pay a price premium to purchase from a preferred registry or with a preferred provenance, the average price per address has dropped by some 50% across 2025.&lt;/p&gt;
    &lt;p&gt;Are there any supply-side issues in the market? Is the supply of tradable IPv4 address declining? One way to provide some insight into answering this question is to look at the registration age of transferred addresses. Are such addresses predominately recently allocated addresses, or are they longer held address addresses where the holder is wanting to realise the inherent value in otherwise unused assets? The basic question concerns the age distribution of transferred addresses where the age of an address reflects the period since it was first allocated or assigned by the RIR system.&lt;/p&gt;
    &lt;p&gt;The cumulative age distribution of transferred addresses by transaction is shown on a year-by-year basis in Figures 14 and 15.&lt;/p&gt;
    &lt;p&gt;In the period 2019 â 2021 a visible subset of address holders appeared to hold recently allocated addresses for the policy-mandated minimum holding period of some 2 years and then transfer these addresses on the market. In previous years some 8% of addresses that were transferred were originally allocated up to 5 years prior to the transfer. In 2022 this number has fallen to 4%, which is presumably related to the smaller volumes of address allocations in 2022 rather than any change in behaviours of address holders, and in 2023 and 2024 this behaviour has all but disappeared, due to the very small volume of address allocations by the RIRs rather than any change in the behaviour of address holders.&lt;/p&gt;
    &lt;p&gt;The bulk of transferred addresses in 2025 (more than 55% of the total volume) were originally allocated between 13 and 25 years ago, or between 2000 and 2012.&lt;/p&gt;
    &lt;p&gt;Figure 15 shows the cumulative age distribution of transfer transactions (as distinct from the volume of transferred addresses), and the disparity between the two distributions for 2025 show that recent individual allocations have been far smaller in size but are still being traded. Some 20% of the recorded transfer transactions in 2025 refer to an address prefix that was allocated within the past 7 years, yet these transactions encompass less than 2% of the inventory of transferred addresses in 2025. Some 40% of the volume of transferred addresses were originally allocated 20 or more years ago, while these transactions are recorded in just 28% of the transfers recorded in 2025.&lt;/p&gt;
    &lt;p&gt;There appear to be a number of motivations driving the transfer process.&lt;/p&gt;
    &lt;p&gt;One is when demand is outstrips supply and price escalation is an inevitable consequence. This may motivate some network operators to purchase addresses early, in the expectation that further delay will encounter higher prices. This factor also may motivate some address holder to defer the decision to sell their addresses, in that delay will improve the price. Taken together, these motivations can impair market liquidity and create a feedback loop that causes price escalation. This factor appeared to be a major issue in the period between 2019 and 2022, but these days the opposite is the case and supply far outstrips demand in the addrtess market.&lt;/p&gt;
    &lt;p&gt;The second factor is IPv6 deployment. Many applications prefer to use IPv6 over IPv4 if they can (the so-called âHappy Eyeballsâ protocol for protocol selection). For a dual stack access network this means that the more the services that they use are provisioned with dual stack, then the lower the traffic volume that uses IPv4, and the lower the consumption pressure on their IPv4 CG-NAT address pools, which reduces their ongoing demand for IPv4 address space. This reduced demand for additional IPv4 addresses has an impact on the market price. A falling market price acts as a motivation for sellers to bring their unused address inventory to market sooner, as further delay will only result in a lower price.&lt;/p&gt;
    &lt;p&gt;The overriding feature of this address market is the level of uncertainty within the market over the state of the IPv6 transition, coupled with the uncertainty over the further growth of the network. This high degree of uncertainty may lie behind the very high variance of individual transfer transaction prices, as shown in Figure 12 for 2025. Have we finally managed to deploy enough network infrastructure in both IPv4 and IPv6 to get ahead of the demand pressures? Are we now looking at a market which is currently saturated with sufficient addresses and associated service platform infrastructure?&lt;/p&gt;
    &lt;p&gt;The next question is whether the transfer process is further fragmenting the address space by splitting up larger address blocks into successively smaller address blocks. There are 56,629 transactions described in the RIRsâ transfer registries from the start of 2012 until the start of 2026, and of these 14,831 entries list transferred address blocks that are smaller than the original allocated block. In other words, some 26% of transfers implicitly perform fragmentation of the original allocation.&lt;/p&gt;
    &lt;p&gt;These 14,831 transfer entries that have fragmented the original allocation are drawn from 9,231 original allocations. On average the original allocation is split into 1.9 smaller address blocks. This data implies that the answer to this question is that address blocks are being fragmented as a result of address transfers, but in absolute terms this is not a major issue. There are some 253,021 distinct IPv4 address allocation records in the RIRs registries as of the end of 2025, and the fragmentation reflected in 14,831 more specific entries of original allocation address blocks represents around 5.9% of the total pool of allocated address prefixes.&lt;/p&gt;
    &lt;p&gt;The next question concerns the international flow of transferred addresses. Letâs look at the ten economies that sourced the greatest volume of transferred addresses, irrespective of their destination (i.e. including âdomesticâ transfers within the same economy) (Table 6), and the ten largest recipients of transfers (Table 7), and the ten largest international address transfers (Table 8). We will use the RIR-published transfer data for the year 2024 as basis for these tables.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;CC&lt;/cell&gt;
        &lt;cell role="head"&gt;Addresses&lt;/cell&gt;
        &lt;cell role="head"&gt;Source Economy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;11,747,840&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;BR&lt;/cell&gt;
        &lt;cell&gt;7,113,216&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;DE&lt;/cell&gt;
        &lt;cell&gt;4,375,552&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;GB&lt;/cell&gt;
        &lt;cell&gt;2,706,432&lt;/cell&gt;
        &lt;cell&gt;Ukraine&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;IT&lt;/cell&gt;
        &lt;cell&gt;778,240&lt;/cell&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;ES&lt;/cell&gt;
        &lt;cell&gt;655,872&lt;/cell&gt;
        &lt;cell&gt;Spain&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;IR&lt;/cell&gt;
        &lt;cell&gt;488,960&lt;/cell&gt;
        &lt;cell&gt;Iran&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;NL&lt;/cell&gt;
        &lt;cell&gt;479,232&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;RU&lt;/cell&gt;
        &lt;cell&gt;451,072&lt;/cell&gt;
        &lt;cell&gt;Russian Federation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;JP&lt;/cell&gt;
        &lt;cell&gt;436,224&lt;/cell&gt;
        &lt;cell&gt;Japan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;AU&lt;/cell&gt;
        &lt;cell&gt;369,408&lt;/cell&gt;
        &lt;cell&gt;Australia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;CN&lt;/cell&gt;
        &lt;cell&gt;295,936&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;UA&lt;/cell&gt;
        &lt;cell&gt;283,136&lt;/cell&gt;
        &lt;cell&gt;Ukraine&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;HK&lt;/cell&gt;
        &lt;cell&gt;280,576&lt;/cell&gt;
        &lt;cell&gt;Hong Kong (SAR)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;IN&lt;/cell&gt;
        &lt;cell&gt;277,248&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;IE&lt;/cell&gt;
        &lt;cell&gt;236,544&lt;/cell&gt;
        &lt;cell&gt;Ireland&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;SE&lt;/cell&gt;
        &lt;cell&gt;187,136&lt;/cell&gt;
        &lt;cell&gt;Sweden&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;184,064&lt;/cell&gt;
        &lt;cell&gt;Republic of Korea&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;FR&lt;/cell&gt;
        &lt;cell&gt;182,272&lt;/cell&gt;
        &lt;cell&gt;France&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;CZ&lt;/cell&gt;
        &lt;cell&gt;180,224&lt;/cell&gt;
        &lt;cell&gt;Czech Republic&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;CC&lt;/cell&gt;
        &lt;cell role="head"&gt;Addresses&lt;/cell&gt;
        &lt;cell role="head"&gt;Destination Economy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;GB&lt;/cell&gt;
        &lt;cell&gt;7,581,696&lt;/cell&gt;
        &lt;cell&gt;Ukraine&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;5,460,736&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;DE&lt;/cell&gt;
        &lt;cell&gt;5,201,664&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;BR&lt;/cell&gt;
        &lt;cell&gt;4,082,944&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;SG&lt;/cell&gt;
        &lt;cell&gt;1,248,768&lt;/cell&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;IT&lt;/cell&gt;
        &lt;cell&gt;1,021,696&lt;/cell&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;RU&lt;/cell&gt;
        &lt;cell&gt;777,216&lt;/cell&gt;
        &lt;cell&gt;Russian Federation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;ES&lt;/cell&gt;
        &lt;cell&gt;669,184&lt;/cell&gt;
        &lt;cell&gt;Spain&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;NL&lt;/cell&gt;
        &lt;cell&gt;622,080&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;SE&lt;/cell&gt;
        &lt;cell&gt;482,816&lt;/cell&gt;
        &lt;cell&gt;Sweden&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;IN&lt;/cell&gt;
        &lt;cell&gt;381,952&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;HK&lt;/cell&gt;
        &lt;cell&gt;343,040&lt;/cell&gt;
        &lt;cell&gt;Hong Kong (SAR)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;FR&lt;/cell&gt;
        &lt;cell&gt;329,728&lt;/cell&gt;
        &lt;cell&gt;France&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;UA&lt;/cell&gt;
        &lt;cell&gt;264,192&lt;/cell&gt;
        &lt;cell&gt;Ukraine&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;SA&lt;/cell&gt;
        &lt;cell&gt;256,512&lt;/cell&gt;
        &lt;cell&gt;Saudi Arabia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;AE&lt;/cell&gt;
        &lt;cell&gt;256,256&lt;/cell&gt;
        &lt;cell&gt;United Arab Emirates&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;250,368&lt;/cell&gt;
        &lt;cell&gt;Republic of Korea&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;CN&lt;/cell&gt;
        &lt;cell&gt;243,712&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;ID&lt;/cell&gt;
        &lt;cell&gt;240,128&lt;/cell&gt;
        &lt;cell&gt;Indonesia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;JP&lt;/cell&gt;
        &lt;cell&gt;229,120&lt;/cell&gt;
        &lt;cell&gt;Japan&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There are many caveats about this data collection, particularly relating to the precise meaning of this economy-based geolocation. Even if we use only the country-code entry in the RIRsâ registry records, then we get a variety of meanings. Some RIRs use the principle that the recorded country code entry corresponds to the physical location of the headquarters of nominated entity that is the holder of the addresses, irrespective of the locale where the addresses are used on the Internet. Other RIRs allow the holder to update this geolocation entry to match the holderâs intended locale where the addresses will be used. It is generally not possible to confirm the holderâs assertion of location, so whether these self-managed records reflect the actual location of the addresses or reflect a location of convenience is not always possible to determine.&lt;/p&gt;
    &lt;p&gt;When we look at the various geolocation services, of which Maxmind is a commonly used service, there are similar challenges in providing a geographic location service. At times this is not easy to establish, such as with tunnels used in VPNs. Is the âcorrectâ location the location of the tunnel ingress or tunnel egress? Many of the fine-grained differences in geolocation services reflect the challenges in dealing with VPNs and the various ways these location services have responded. There is also the issue of cloud-based services. Where the cloud service uses anycast, then the address is located in many locations at once. In the case where the cloud uses conventional unicast, the addresses use may be fluid across the cloud serviceâs points of presence based on distributing addresses to meet the demands for the service. The bottom line is that these location listings are a âfuzzyâ approximation rather than a precise indication of location.&lt;/p&gt;
    &lt;p&gt;With that in mind letâs now look at imports and exports of addresses of 2025 transfers where the source and destination of the transfers are in different economies. Some 2,421 transfers appear to result in a movement of addresses between countries, involving a total of 18,729,216 addresses. The 20 largest country pairs are shown in Table 8.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;From&lt;/cell&gt;
        &lt;cell role="head"&gt;To&lt;/cell&gt;
        &lt;cell role="head"&gt;Addresses (M)&lt;/cell&gt;
        &lt;cell role="head"&gt;Source&lt;/cell&gt;
        &lt;cell role="head"&gt;Destination&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;GB&lt;/cell&gt;
        &lt;cell&gt;5,880,576&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;BR&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;2,682,880&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;DE&lt;/cell&gt;
        &lt;cell&gt;935,936&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;DE&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;560,384&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;BR&lt;/cell&gt;
        &lt;cell&gt;SG&lt;/cell&gt;
        &lt;cell&gt;458,752&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;SG&lt;/cell&gt;
        &lt;cell&gt;454,400&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;ES&lt;/cell&gt;
        &lt;cell&gt;395,264&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Spain&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;JP&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;286,720&lt;/cell&gt;
        &lt;cell&gt;Japan&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;GB&lt;/cell&gt;
        &lt;cell&gt;SE&lt;/cell&gt;
        &lt;cell&gt;273,408&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;Sweden&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;GB&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;235,008&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;SA&lt;/cell&gt;
        &lt;cell&gt;232,704&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Saudi Arabia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;AU&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;219,648&lt;/cell&gt;
        &lt;cell&gt;Australia&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;LT&lt;/cell&gt;
        &lt;cell&gt;214,016&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Lithuania&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;GB&lt;/cell&gt;
        &lt;cell&gt;DE&lt;/cell&gt;
        &lt;cell&gt;213,248&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;IT&lt;/cell&gt;
        &lt;cell&gt;202,752&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;PA&lt;/cell&gt;
        &lt;cell&gt;196,864&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Panama&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;RU&lt;/cell&gt;
        &lt;cell&gt;196,608&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Russian Federation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;BR&lt;/cell&gt;
        &lt;cell&gt;196,608&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;NL&lt;/cell&gt;
        &lt;cell&gt;187,136&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;HK&lt;/cell&gt;
        &lt;cell&gt;180,224&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;Hong Kong SAR&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The 2025 transfer logs also contain 3,198 domestic address transfers, with a total of 14,261,856 addresses, with the largest activity by address volume in domestic transfers in the Brazil (4M), Germany (4M), UK (1.5M), US (1.1M), Italy (0.8M) and the Russian Federation (0.4M).&lt;/p&gt;
    &lt;p&gt;An outstanding question about this transfer data is whether all address transfers that have occurred have been duly recorded in the registry system. This question is raised because registered transfers require conformance to various registry policies, and it may be the case that only a subset of transfers are being recorded in the registry as a result. This can be somewhat challenging to detect, particularly if such a transfer is expressed as a lease or other form of temporary arrangement, and if the parties agree to keep the details of the transfer confidential.&lt;/p&gt;
    &lt;p&gt;It might be possible to place an upper bound on the volume of address movements that have occurred in any period is to look at the Internetâs routing system. One way to shed some further light on what this upper bound on transfers might be is through a simple examination of the routing system, looking at addresses that were announced in 2025 by comparing the routing stable state at the start of the year with the table state at the end of the year (Table 9).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="9"&gt;
        &lt;cell role="head"&gt;Jan-25&lt;/cell&gt;
        &lt;cell role="head"&gt;Jan-26&lt;/cell&gt;
        &lt;cell role="head"&gt;Delta&lt;/cell&gt;
        &lt;cell role="head"&gt;Unchanged&lt;/cell&gt;
        &lt;cell role="head"&gt;Re-Home&lt;/cell&gt;
        &lt;cell role="head"&gt;Removed&lt;/cell&gt;
        &lt;cell role="head"&gt;Added&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Announcements&lt;/cell&gt;
        &lt;cell&gt;955,963&lt;/cell&gt;
        &lt;cell&gt;1,049,909&lt;/cell&gt;
        &lt;cell&gt;53,946&lt;/cell&gt;
        &lt;cell&gt;878,092&lt;/cell&gt;
        &lt;cell&gt;29,699&lt;/cell&gt;
        &lt;cell&gt;88,172&lt;/cell&gt;
        &lt;cell&gt;142,118&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Root Prefixes:&lt;/cell&gt;
        &lt;cell&gt;469,272&lt;/cell&gt;
        &lt;cell&gt;505,731&lt;/cell&gt;
        &lt;cell&gt;36,459&lt;/cell&gt;
        &lt;cell&gt;411,634&lt;/cell&gt;
        &lt;cell&gt;20,623&lt;/cell&gt;
        &lt;cell&gt;30,321&lt;/cell&gt;
        &lt;cell&gt;59,826&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Address Span (M)&lt;/cell&gt;
        &lt;cell&gt;3,117.65&lt;/cell&gt;
        &lt;cell&gt;3,106.37&lt;/cell&gt;
        &lt;cell&gt;-11.28&lt;/cell&gt;
        &lt;cell&gt;2,944.99&lt;/cell&gt;
        &lt;cell&gt;37.97&lt;/cell&gt;
        &lt;cell&gt;127.86&lt;/cell&gt;
        &lt;cell&gt;95.77&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;More Specifics:&lt;/cell&gt;
        &lt;cell&gt;526,691&lt;/cell&gt;
        &lt;cell&gt;544,178&lt;/cell&gt;
        &lt;cell&gt;17,487&lt;/cell&gt;
        &lt;cell&gt;294,126&lt;/cell&gt;
        &lt;cell&gt;9,076&lt;/cell&gt;
        &lt;cell&gt;57,851&lt;/cell&gt;
        &lt;cell&gt;82,292&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Address Span (M)&lt;/cell&gt;
        &lt;cell&gt;899.75&lt;/cell&gt;
        &lt;cell&gt;872.16&lt;/cell&gt;
        &lt;cell&gt;-27.59&lt;/cell&gt;
        &lt;cell&gt;773.50&lt;/cell&gt;
        &lt;cell&gt;19.84&lt;/cell&gt;
        &lt;cell&gt;81.49&lt;/cell&gt;
        &lt;cell&gt;89.05&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;While the routing table grew by 53,946 entries over the year, the nature of the change is slightly more involved. Some 88,172 prefixes that were announced at the start of the year were removed from the routing system at some time through the year, and 142,118 prefixes were announced by the end of the year that were not announced at the start of the year. More transient prefixes may have appeared and been withdrawn throughout the year of course, but here we are comparing two snapshots rather than looking at every update message. A further 29,699 prefixes had changed their originating AS number, indicating some form of change in the prefixâs network location in some manner.&lt;/p&gt;
    &lt;p&gt;If we look at the complete collection of BGP updates seen from an individual BGP vantage point (AS 131072) across all of 2025 we see a larger collection of transient address prefixes. A total of 1,270,968 distinct prefixes were observed through 2025. That implies that some 221,059 additional prefixes were seen at some point through the year, starting from the initial set as January 2025.&lt;/p&gt;
    &lt;p&gt;We can compare these prefixes that changed in 2025 against the transfer logs for the two-year period 2024 and 2025. Table 10 shows the comparison of these routing numbers against the set of transfers that were logged in these two years.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Listed&lt;/cell&gt;
        &lt;cell role="head"&gt;Unlisted&lt;/cell&gt;
        &lt;cell role="head"&gt;Ratio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Re-Homed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;All&lt;/cell&gt;
        &lt;cell&gt;1,991&lt;/cell&gt;
        &lt;cell&gt;26,722&lt;/cell&gt;
        &lt;cell&gt;6.9%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Root Prefixes&lt;/cell&gt;
        &lt;cell&gt;927&lt;/cell&gt;
        &lt;cell&gt;12,711&lt;/cell&gt;
        &lt;cell&gt;6.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Removed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;All&lt;/cell&gt;
        &lt;cell&gt;3,172&lt;/cell&gt;
        &lt;cell&gt;85,000&lt;/cell&gt;
        &lt;cell&gt;3.6%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Root Prefixes&lt;/cell&gt;
        &lt;cell&gt;1,869&lt;/cell&gt;
        &lt;cell&gt;285&lt;/cell&gt;
        &lt;cell&gt;86.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Added&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;All&lt;/cell&gt;
        &lt;cell&gt;14,457&lt;/cell&gt;
        &lt;cell&gt;127,571&lt;/cell&gt;
        &lt;cell&gt;10.2%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Root Prefixes&lt;/cell&gt;
        &lt;cell&gt;12,686&lt;/cell&gt;
        &lt;cell&gt;47,140&lt;/cell&gt;
        &lt;cell&gt;21.2%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These figures show that some 7% of changes in advertised addresses from the beginning to the end of the year are reflected as changes as recorded in the RIRsâ transfer logs. This shouldnât imply that the remaining changes in advertised prefixes reflect unrecorded address transfers. There are many reasons for changes in the advertisement of an address prefix and a change in the administrative controller of the address is only one potential cause. However, it does establish some notional upper ceiling on the number of movements of addresses in 2025, some of which relate to transfer of operational control of an address block, that have not been captured in the transfer logs.&lt;/p&gt;
    &lt;p&gt;Finally, we can perform an age profile of the addresses that were added, removed and re-homed during 2025 and compare it to the overall age profile of IPv4 addresses in the routing table. This is shown in Figure 16. This figure show that address prefixes added to the routing table tend to be âyoungerâ than average. One half of all added address prefixes are 15 years old or less, while for all advertised address prefixes 50% of such prefixes are 17 years old or younger. Prefixes that are changing their originating network (âre-Homingâ) tend to be older than average, and 50% of all rehomed prefixes are 15 years old or older.&lt;/p&gt;
    &lt;p&gt;As IPv4 moves into its final stages we are perhaps now in a position to take stock of the overall distribution of IPv4 addresses and look at where the addresses landed up. Table 11 shows the 20 economies that have the largest pools of allocated IPv4 addresses. However, I have to note that the assignation of a country code in an address registration reflects the country where address holder is located (the corporate location), and not necessarily the country where the addresses will be deployed.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;CC&lt;/cell&gt;
        &lt;cell role="head"&gt;IPv4 Pool&lt;/cell&gt;
        &lt;cell role="head"&gt;% Total&lt;/cell&gt;
        &lt;cell role="head"&gt;Per-Capita&lt;/cell&gt;
        &lt;cell role="head"&gt;Economy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;1,610,004,832&lt;/cell&gt;
        &lt;cell&gt;43.7%&lt;/cell&gt;
        &lt;cell&gt;4.67&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;CN&lt;/cell&gt;
        &lt;cell&gt;343,148,544&lt;/cell&gt;
        &lt;cell&gt;9.3%&lt;/cell&gt;
        &lt;cell&gt;0.24&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;JP&lt;/cell&gt;
        &lt;cell&gt;188,742,464&lt;/cell&gt;
        &lt;cell&gt;5.1%&lt;/cell&gt;
        &lt;cell&gt;1.55&lt;/cell&gt;
        &lt;cell&gt;Japan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;GB&lt;/cell&gt;
        &lt;cell&gt;141,092,616&lt;/cell&gt;
        &lt;cell&gt;3.8%&lt;/cell&gt;
        &lt;cell&gt;2.07&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;DE&lt;/cell&gt;
        &lt;cell&gt;125,335,872&lt;/cell&gt;
        &lt;cell&gt;3.4%&lt;/cell&gt;
        &lt;cell&gt;1.51&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;112,490,496&lt;/cell&gt;
        &lt;cell&gt;3.1%&lt;/cell&gt;
        &lt;cell&gt;2.18&lt;/cell&gt;
        &lt;cell&gt;Republic of Korea&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;FR&lt;/cell&gt;
        &lt;cell&gt;82,105,648&lt;/cell&gt;
        &lt;cell&gt;2.2%&lt;/cell&gt;
        &lt;cell&gt;1.26&lt;/cell&gt;
        &lt;cell&gt;France&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;BR&lt;/cell&gt;
        &lt;cell&gt;79,973,120&lt;/cell&gt;
        &lt;cell&gt;2.2%&lt;/cell&gt;
        &lt;cell&gt;0.36&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;CA&lt;/cell&gt;
        &lt;cell&gt;67,666,432&lt;/cell&gt;
        &lt;cell&gt;1.8%&lt;/cell&gt;
        &lt;cell&gt;1.71&lt;/cell&gt;
        &lt;cell&gt;Canada&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;IT&lt;/cell&gt;
        &lt;cell&gt;54,150,720&lt;/cell&gt;
        &lt;cell&gt;1.5%&lt;/cell&gt;
        &lt;cell&gt;0.93&lt;/cell&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;NL&lt;/cell&gt;
        &lt;cell&gt;47,845,216&lt;/cell&gt;
        &lt;cell&gt;1.3%&lt;/cell&gt;
        &lt;cell&gt;2.70&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;AU&lt;/cell&gt;
        &lt;cell&gt;46,192,640&lt;/cell&gt;
        &lt;cell&gt;1.3%&lt;/cell&gt;
        &lt;cell&gt;1.70&lt;/cell&gt;
        &lt;cell&gt;Australia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;RU&lt;/cell&gt;
        &lt;cell&gt;44,887,360&lt;/cell&gt;
        &lt;cell&gt;1.2%&lt;/cell&gt;
        &lt;cell&gt;0.31&lt;/cell&gt;
        &lt;cell&gt;Russian Federation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;IN&lt;/cell&gt;
        &lt;cell&gt;41,819,648&lt;/cell&gt;
        &lt;cell&gt;1.1%&lt;/cell&gt;
        &lt;cell&gt;0.03&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;TW&lt;/cell&gt;
        &lt;cell&gt;35,723,264&lt;/cell&gt;
        &lt;cell&gt;1.0%&lt;/cell&gt;
        &lt;cell&gt;1.49&lt;/cell&gt;
        &lt;cell&gt;Taiwan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;ES&lt;/cell&gt;
        &lt;cell&gt;32,186,752&lt;/cell&gt;
        &lt;cell&gt;0.9%&lt;/cell&gt;
        &lt;cell&gt;0.68&lt;/cell&gt;
        &lt;cell&gt;Spain&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;SE&lt;/cell&gt;
        &lt;cell&gt;31,439,400&lt;/cell&gt;
        &lt;cell&gt;0.9%&lt;/cell&gt;
        &lt;cell&gt;2.92&lt;/cell&gt;
        &lt;cell&gt;Sweden&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;MX&lt;/cell&gt;
        &lt;cell&gt;28,958,720&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
        &lt;cell&gt;0.22&lt;/cell&gt;
        &lt;cell&gt;Mexico&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;SG&lt;/cell&gt;
        &lt;cell&gt;27,180,032&lt;/cell&gt;
        &lt;cell&gt;0.7%&lt;/cell&gt;
        &lt;cell&gt;4.45&lt;/cell&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;ZA&lt;/cell&gt;
        &lt;cell&gt;27,145,216&lt;/cell&gt;
        &lt;cell&gt;0.7%&lt;/cell&gt;
        &lt;cell&gt;0.44&lt;/cell&gt;
        &lt;cell&gt;South Africa&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;3,687,097,368&lt;/cell&gt;
        &lt;cell&gt;100%&lt;/cell&gt;
        &lt;cell&gt;0.45&lt;/cell&gt;
        &lt;cell&gt;World&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If we divide this address pool by the current population of each national entity, then we can derive an address per capita index. The global total of 3.69 billion allocated addresses with an estimated global population of 8 billion people gives an overall value of 0.45 IPv4 addresses per capita.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;CC&lt;/cell&gt;
        &lt;cell role="head"&gt;IPv4 Pool&lt;/cell&gt;
        &lt;cell role="head"&gt;% Total&lt;/cell&gt;
        &lt;cell role="head"&gt;Per-Capita&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;SC&lt;/cell&gt;
        &lt;cell&gt;7,475,456&lt;/cell&gt;
        &lt;cell&gt;0.2%&lt;/cell&gt;
        &lt;cell&gt;68.50&lt;/cell&gt;
        &lt;cell&gt;Seychelles&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;VA&lt;/cell&gt;
        &lt;cell&gt;10,752&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
        &lt;cell&gt;20.10&lt;/cell&gt;
        &lt;cell&gt;Holy See&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;GI&lt;/cell&gt;
        &lt;cell&gt;235,264&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
        &lt;cell&gt;7.18&lt;/cell&gt;
        &lt;cell&gt;Gibraltar&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;VG&lt;/cell&gt;
        &lt;cell&gt;166,144&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
        &lt;cell&gt;5.18&lt;/cell&gt;
        &lt;cell&gt;British Virgin Islands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;1,611,699,808&lt;/cell&gt;
        &lt;cell&gt;43.7%&lt;/cell&gt;
        &lt;cell&gt;4.68&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;SG&lt;/cell&gt;
        &lt;cell&gt;26,597,376&lt;/cell&gt;
        &lt;cell&gt;0.7%&lt;/cell&gt;
        &lt;cell&gt;4.35&lt;/cell&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;MU&lt;/cell&gt;
        &lt;cell&gt;4,780,032&lt;/cell&gt;
        &lt;cell&gt;0.1%&lt;/cell&gt;
        &lt;cell&gt;3.67&lt;/cell&gt;
        &lt;cell&gt;Mauritius&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;SE&lt;/cell&gt;
        &lt;cell&gt;31,078,888&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
        &lt;cell&gt;2.89&lt;/cell&gt;
        &lt;cell&gt;Sweden&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;CH&lt;/cell&gt;
        &lt;cell&gt;25,444,472&lt;/cell&gt;
        &lt;cell&gt;0.7%&lt;/cell&gt;
        &lt;cell&gt;2.85&lt;/cell&gt;
        &lt;cell&gt;Switzerland&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;NO&lt;/cell&gt;
        &lt;cell&gt;15,542,032&lt;/cell&gt;
        &lt;cell&gt;0.4%&lt;/cell&gt;
        &lt;cell&gt;2.79&lt;/cell&gt;
        &lt;cell&gt;Norway&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;XA&lt;/cell&gt;
        &lt;cell&gt;3,687,386,072&lt;/cell&gt;
        &lt;cell&gt;100.0%&lt;/cell&gt;
        &lt;cell&gt;0.45&lt;/cell&gt;
        &lt;cell&gt;World&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;It is worth noting that the address market includes leasing as well as sales. Should an entity who requires IPv4 addresses enter the market and perform an outright purchase of the addresses from an existing address holder, or should they execute a timed leased to have the use of these addresses for a specified period and presumably return these addresses at the end of the lease? This lease versus buy question is a very conventional question in market economics and there are various well-rehearsed answers to the question. They tend to relate to the factoring of market information and scenario planning.&lt;/p&gt;
    &lt;p&gt;If a buyer believes that the situation that led to the formation of a market will endure for a long time, and the goods being traded on the market are in finite supply while the level of demand for these goods is increasing, then the market will add an escalating scarcity premium to the price goods being traded. The balancing of demand and supply becomes a function of this scarcity premium imposed on the goods being traded. Goods in short supply tend to become more expensive to buy over time. A holder of these goods will see an increase in the value of the goods that they hold. A lessee will not.&lt;/p&gt;
    &lt;p&gt;If a buyer believes that the market only has a short lifespan, and that demand for the good will rapidly dissipate at the end of this lifespan, then leasing the good makes sense, in so far as the lessee is not left with a valueless asset when the market collapses.&lt;/p&gt;
    &lt;p&gt;Scarcity also has several additional consequences, one of which is the pricing of substitute goods. At some point the price of the original good rises to the point that substitution looks economically attractive, even if the substitute good has a higher cost of production or use. In fact, this substitution price effectively sets a price ceiling for the original scarce good.&lt;/p&gt;
    &lt;p&gt;Some commentators have advanced the view that an escalating price for IPv4 increases the economic incentive for IPv6 adoption, and this may indeed be the case. However, there are other potential substitutes that have been used, most notably NATs (Network Address Translators). While NATs do not eliminate the demand pressure for IPv4, they can go a long way to increase the address utilisation efficiency if IPv4 addresses. NATs allow the same address to be used by multiple customers at different times. The larger the pool of customers that share a common pool of NAT addresses the greater the achievable multiplexing capability.&lt;/p&gt;
    &lt;p&gt;The estimate as to how long the market in IPv4 addresses will persist is effectively a judgement as to how long IPv4 and NATs can last and how long it will take IPv6 to sufficiently deployed to be viable as an IPv6-only service. At that point in time there is likely to be a tipping point where the pressure for all hosts and networks to support access to services over IPv4 collapses. A that point, the early IPv6-only adopters can dump all their remaining IPv4 resources onto the market as they have no further need for them, which would presumably trigger a level of market panic to emerge as existing holders are faced with the prospect of holding a worthless asset and are therefore under pressure to sell off their IPv4 assets while there are still buyers in the market.&lt;/p&gt;
    &lt;p&gt;While a significant population of IPv4-only hosts and networks can stall this transition and increase scarcity pressure, if the scarcity pressure becomes too great the impetus of IPv6-only adoption increases to the level that the IPv6-connected base achieves market dominance. When this condition is achieved the IPv4 address market will quickly collapse.&lt;/p&gt;
    &lt;p&gt;The leasing market is relatively opaque, as lease arrangements are not registered in a public registry, but are the subject of a private contract. There is one address broker, IPXO, that does publish data relating to its leasing activities. This enterprise has seen an increase in their total pool of leased addresses from 0.7M at the start of 2022 to 9.2M (Figure 17). Note that this does not reflect the total pool of leased addresses, just the view from one active address broker in this space.&lt;/p&gt;
    &lt;p&gt;The average lease price, and the price range is shown for 2025 on a week-by week basis in shown in Figure 18.&lt;/p&gt;
    &lt;p&gt;This lease price data is slightly at odds with the sale price data. Over 2025 the average lease price declined by some 15%, while the average sale price declined by 50%. The reasons for this apparent discrepancy are unclear.&lt;/p&gt;
    &lt;p&gt;Obviously, the story of IPv4 address allocations is only half of the story, and to complete the picture itâs necessary to look at how IPv6 has fared over 2025.&lt;/p&gt;
    &lt;p&gt;IPv6 uses a somewhat different address allocation methodology than IPv4, and it is a matter of choice for a service provider as to how large an IPv6 address prefix is assigned to each customer. The original recommendations published by the IAB and IESG in 2001, documented in RFC 3177, envisaged the general use of a /48 prefix as a generally suitable end-site prefix. Subsequent consideration of long term address conservation saw a more flexible approach being taken with the choice of the end site prefix size being left to the service provider. Today's IPv6 environment has some providers using a /60 end site allocation unit, many using a /56, and many other providers using a /48 IPv6 address prefix. This variation makes a comparison between ISPs of the count of allocated IPv6 addresses somewhat misleading, as an ISP using /48's for end sites will require 256 times more address space to accommodate a similarly sized same customer base as a provider who uses a /56 end site prefix, and 4,096 times more address space than an ISP using a /60 end site allocation!&lt;/p&gt;
    &lt;p&gt;For IPv6 let's use both the number of discrete IPv6 allocations and the total amount of space that was allocated to see how IPv6 fared in 2025.&lt;/p&gt;
    &lt;p&gt;Comparing 2024 to 2025, the number of individual allocations of IPv6 address space has decreased by 7%, while the number of IPv4 allocation transactions has increased by 3% (Table 13).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="15"&gt;
        &lt;cell role="head"&gt;Allocations&lt;/cell&gt;
        &lt;cell role="head"&gt;2012&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;IPv6&lt;/cell&gt;
        &lt;cell&gt;3,291&lt;/cell&gt;
        &lt;cell&gt;3,529&lt;/cell&gt;
        &lt;cell&gt;4,502&lt;/cell&gt;
        &lt;cell&gt;4,644&lt;/cell&gt;
        &lt;cell&gt;5,567&lt;/cell&gt;
        &lt;cell&gt;5,740&lt;/cell&gt;
        &lt;cell&gt;6,176&lt;/cell&gt;
        &lt;cell&gt;6,799&lt;/cell&gt;
        &lt;cell&gt;5,376&lt;/cell&gt;
        &lt;cell&gt;5,350&lt;/cell&gt;
        &lt;cell&gt;4,066&lt;/cell&gt;
        &lt;cell&gt;3,874&lt;/cell&gt;
        &lt;cell&gt;3,925&lt;/cell&gt;
        &lt;cell&gt;3,645&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;IPv4&lt;/cell&gt;
        &lt;cell&gt;7,435&lt;/cell&gt;
        &lt;cell&gt;6,429&lt;/cell&gt;
        &lt;cell&gt;10,435&lt;/cell&gt;
        &lt;cell&gt;11,352&lt;/cell&gt;
        &lt;cell&gt;9,648&lt;/cell&gt;
        &lt;cell&gt;8,185&lt;/cell&gt;
        &lt;cell&gt;8,769&lt;/cell&gt;
        &lt;cell&gt;12,560&lt;/cell&gt;
        &lt;cell&gt;5,874&lt;/cell&gt;
        &lt;cell&gt;6,939&lt;/cell&gt;
        &lt;cell&gt;4,395&lt;/cell&gt;
        &lt;cell&gt;3,462&lt;/cell&gt;
        &lt;cell&gt;3,559&lt;/cell&gt;
        &lt;cell&gt;3,654&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The amount of IPv6 address space distributed in 2025 is 80% less than the amount that was allocated in 2023, while the corresponding IPv4 volume decreassed by 11% (Table 14).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="15"&gt;
        &lt;cell role="head"&gt;Addresses&lt;/cell&gt;
        &lt;cell role="head"&gt;2012&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;IPv6 (/32s)&lt;/cell&gt;
        &lt;cell&gt;17,710&lt;/cell&gt;
        &lt;cell&gt;23,642&lt;/cell&gt;
        &lt;cell&gt;17,847&lt;/cell&gt;
        &lt;cell&gt;15,765&lt;/cell&gt;
        &lt;cell&gt;25,260&lt;/cell&gt;
        &lt;cell&gt;19,975&lt;/cell&gt;
        &lt;cell&gt;38,699&lt;/cell&gt;
        &lt;cell&gt;35,924&lt;/cell&gt;
        &lt;cell&gt;21,620&lt;/cell&gt;
        &lt;cell&gt;28,131&lt;/cell&gt;
        &lt;cell&gt;27,497&lt;/cell&gt;
        &lt;cell&gt;74,159&lt;/cell&gt;
        &lt;cell&gt;45,105&lt;/cell&gt;
        &lt;cell&gt;10,332&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;IPv4 (/32s)(M)&lt;/cell&gt;
        &lt;cell&gt;88.8&lt;/cell&gt;
        &lt;cell&gt;57.7&lt;/cell&gt;
        &lt;cell&gt;58.8&lt;/cell&gt;
        &lt;cell&gt;32.3&lt;/cell&gt;
        &lt;cell&gt;20.8&lt;/cell&gt;
        &lt;cell&gt;15.1&lt;/cell&gt;
        &lt;cell&gt;14.1&lt;/cell&gt;
        &lt;cell&gt;13.9&lt;/cell&gt;
        &lt;cell&gt;4.2&lt;/cell&gt;
        &lt;cell&gt;3.1&lt;/cell&gt;
        &lt;cell&gt;2.1&lt;/cell&gt;
        &lt;cell&gt;1.6&lt;/cell&gt;
        &lt;cell&gt;1.8&lt;/cell&gt;
        &lt;cell&gt;1.6&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Regionally, each of the RIRs saw IPv6 allocation activity in 2025 that was on a par with those seen in 2024, but well short of the peak period of IPv6 allocation activity in 2018 - 2019 (Table 15).&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="15"&gt;
        &lt;cell role="head"&gt;Allocations&lt;/cell&gt;
        &lt;cell role="head"&gt;2012&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;AFRINIC&lt;/cell&gt;
        &lt;cell&gt;82&lt;/cell&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;59&lt;/cell&gt;
        &lt;cell&gt;81&lt;/cell&gt;
        &lt;cell&gt;111&lt;/cell&gt;
        &lt;cell&gt;110&lt;/cell&gt;
        &lt;cell&gt;108&lt;/cell&gt;
        &lt;cell&gt;111&lt;/cell&gt;
        &lt;cell&gt;108&lt;/cell&gt;
        &lt;cell&gt;135&lt;/cell&gt;
        &lt;cell&gt;151&lt;/cell&gt;
        &lt;cell&gt;115&lt;/cell&gt;
        &lt;cell&gt;117&lt;/cell&gt;
        &lt;cell&gt;133&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;APNIC&lt;/cell&gt;
        &lt;cell&gt;599&lt;/cell&gt;
        &lt;cell&gt;540&lt;/cell&gt;
        &lt;cell&gt;528&lt;/cell&gt;
        &lt;cell&gt;777&lt;/cell&gt;
        &lt;cell&gt;1,680&lt;/cell&gt;
        &lt;cell&gt;1,369&lt;/cell&gt;
        &lt;cell&gt;1,460&lt;/cell&gt;
        &lt;cell&gt;1,484&lt;/cell&gt;
        &lt;cell&gt;1,498&lt;/cell&gt;
        &lt;cell&gt;1,392&lt;/cell&gt;
        &lt;cell&gt;1,317&lt;/cell&gt;
        &lt;cell&gt;1,381&lt;/cell&gt;
        &lt;cell&gt;1,265&lt;/cell&gt;
        &lt;cell&gt;1,239&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;ARIN&lt;/cell&gt;
        &lt;cell&gt;603&lt;/cell&gt;
        &lt;cell&gt;543&lt;/cell&gt;
        &lt;cell&gt;489&lt;/cell&gt;
        &lt;cell&gt;604&lt;/cell&gt;
        &lt;cell&gt;645&lt;/cell&gt;
        &lt;cell&gt;684&lt;/cell&gt;
        &lt;cell&gt;648&lt;/cell&gt;
        &lt;cell&gt;601&lt;/cell&gt;
        &lt;cell&gt;644&lt;/cell&gt;
        &lt;cell&gt;668&lt;/cell&gt;
        &lt;cell&gt;680&lt;/cell&gt;
        &lt;cell&gt;712&lt;/cell&gt;
        &lt;cell&gt;951&lt;/cell&gt;
        &lt;cell&gt;1,034&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;LACNIC&lt;/cell&gt;
        &lt;cell&gt;251&lt;/cell&gt;
        &lt;cell&gt;223&lt;/cell&gt;
        &lt;cell&gt;1,199&lt;/cell&gt;
        &lt;cell&gt;1,053&lt;/cell&gt;
        &lt;cell&gt;1,007&lt;/cell&gt;
        &lt;cell&gt;1,547&lt;/cell&gt;
        &lt;cell&gt;1,439&lt;/cell&gt;
        &lt;cell&gt;1,614&lt;/cell&gt;
        &lt;cell&gt;1,801&lt;/cell&gt;
        &lt;cell&gt;725&lt;/cell&gt;
        &lt;cell&gt;635&lt;/cell&gt;
        &lt;cell&gt;612&lt;/cell&gt;
        &lt;cell&gt;656&lt;/cell&gt;
        &lt;cell&gt;606&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;RIPENCC&lt;/cell&gt;
        &lt;cell&gt;1,756&lt;/cell&gt;
        &lt;cell&gt;2,151&lt;/cell&gt;
        &lt;cell&gt;2,227&lt;/cell&gt;
        &lt;cell&gt;2,129&lt;/cell&gt;
        &lt;cell&gt;2,124&lt;/cell&gt;
        &lt;cell&gt;2,030&lt;/cell&gt;
        &lt;cell&gt;2,521&lt;/cell&gt;
        &lt;cell&gt;2,989&lt;/cell&gt;
        &lt;cell&gt;1,325&lt;/cell&gt;
        &lt;cell&gt;2,430&lt;/cell&gt;
        &lt;cell&gt;1,283&lt;/cell&gt;
        &lt;cell&gt;1,054&lt;/cell&gt;
        &lt;cell&gt;936&lt;/cell&gt;
        &lt;cell&gt;633&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;3,291&lt;/cell&gt;
        &lt;cell&gt;3,529&lt;/cell&gt;
        &lt;cell&gt;4,502&lt;/cell&gt;
        &lt;cell&gt;4,644&lt;/cell&gt;
        &lt;cell&gt;5,567&lt;/cell&gt;
        &lt;cell&gt;5,740&lt;/cell&gt;
        &lt;cell&gt;6,176&lt;/cell&gt;
        &lt;cell&gt;6,799&lt;/cell&gt;
        &lt;cell&gt;5,376&lt;/cell&gt;
        &lt;cell&gt;5,350&lt;/cell&gt;
        &lt;cell&gt;4,066&lt;/cell&gt;
        &lt;cell&gt;3,874&lt;/cell&gt;
        &lt;cell&gt;3,925&lt;/cell&gt;
        &lt;cell&gt;3,645&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The address assignment data tells a slightly different story. Table 16 shows the number of allocated IPv6 /32's per year. There were no large IPv6 allocations in 2025, and the total volume of allocated Ipv6 addresses was less than one quarter of the volume allocated in 2024.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="15"&gt;
        &lt;cell role="head"&gt;Addresses (/32s)&lt;/cell&gt;
        &lt;cell role="head"&gt;2012&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;AFRINIC&lt;/cell&gt;
        &lt;cell&gt;4,201&lt;/cell&gt;
        &lt;cell&gt;66&lt;/cell&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;308&lt;/cell&gt;
        &lt;cell&gt;76&lt;/cell&gt;
        &lt;cell&gt;112&lt;/cell&gt;
        &lt;cell&gt;71&lt;/cell&gt;
        &lt;cell&gt;360&lt;/cell&gt;
        &lt;cell&gt;88&lt;/cell&gt;
        &lt;cell&gt;141&lt;/cell&gt;
        &lt;cell&gt;387&lt;/cell&gt;
        &lt;cell&gt;400&lt;/cell&gt;
        &lt;cell&gt;380&lt;/cell&gt;
        &lt;cell&gt;372&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;APNIC&lt;/cell&gt;
        &lt;cell&gt;3,807&lt;/cell&gt;
        &lt;cell&gt;4,462&lt;/cell&gt;
        &lt;cell&gt;2,663&lt;/cell&gt;
        &lt;cell&gt;2,108&lt;/cell&gt;
        &lt;cell&gt;1,235&lt;/cell&gt;
        &lt;cell&gt;4,228&lt;/cell&gt;
        &lt;cell&gt;19,681&lt;/cell&gt;
        &lt;cell&gt;7,945&lt;/cell&gt;
        &lt;cell&gt;7,365&lt;/cell&gt;
        &lt;cell&gt;10,185&lt;/cell&gt;
        &lt;cell&gt;4,856&lt;/cell&gt;
        &lt;cell&gt;599&lt;/cell&gt;
        &lt;cell&gt;33,257&lt;/cell&gt;
        &lt;cell&gt;4,457&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;ARIN&lt;/cell&gt;
        &lt;cell&gt;1,672&lt;/cell&gt;
        &lt;cell&gt;12,571&lt;/cell&gt;
        &lt;cell&gt;5,214&lt;/cell&gt;
        &lt;cell&gt;642&lt;/cell&gt;
        &lt;cell&gt;1,087&lt;/cell&gt;
        &lt;cell&gt;1,372&lt;/cell&gt;
        &lt;cell&gt;844&lt;/cell&gt;
        &lt;cell&gt;5,520&lt;/cell&gt;
        &lt;cell&gt;4,975&lt;/cell&gt;
        &lt;cell&gt;373&lt;/cell&gt;
        &lt;cell&gt;13,695&lt;/cell&gt;
        &lt;cell&gt;66,340&lt;/cell&gt;
        &lt;cell&gt;5,692&lt;/cell&gt;
        &lt;cell&gt;1,859&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;LACNIC&lt;/cell&gt;
        &lt;cell&gt;4,301&lt;/cell&gt;
        &lt;cell&gt;158&lt;/cell&gt;
        &lt;cell&gt;1,314&lt;/cell&gt;
        &lt;cell&gt;953&lt;/cell&gt;
        &lt;cell&gt;1,173&lt;/cell&gt;
        &lt;cell&gt;1,427&lt;/cell&gt;
        &lt;cell&gt;1,327&lt;/cell&gt;
        &lt;cell&gt;1,496&lt;/cell&gt;
        &lt;cell&gt;1,669&lt;/cell&gt;
        &lt;cell&gt;658&lt;/cell&gt;
        &lt;cell&gt;563&lt;/cell&gt;
        &lt;cell&gt;467&lt;/cell&gt;
        &lt;cell&gt;575&lt;/cell&gt;
        &lt;cell&gt;565&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;RIPENCC&lt;/cell&gt;
        &lt;cell&gt;3,729&lt;/cell&gt;
        &lt;cell&gt;6,385&lt;/cell&gt;
        &lt;cell&gt;8,608&lt;/cell&gt;
        &lt;cell&gt;11,754&lt;/cell&gt;
        &lt;cell&gt;21,689&lt;/cell&gt;
        &lt;cell&gt;12,836&lt;/cell&gt;
        &lt;cell&gt;16,776&lt;/cell&gt;
        &lt;cell&gt;20,603&lt;/cell&gt;
        &lt;cell&gt;7,523&lt;/cell&gt;
        &lt;cell&gt;16,774&lt;/cell&gt;
        &lt;cell&gt;7,996&lt;/cell&gt;
        &lt;cell&gt;6,353&lt;/cell&gt;
        &lt;cell&gt;5,111&lt;/cell&gt;
        &lt;cell&gt;3,079&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;17,710&lt;/cell&gt;
        &lt;cell&gt;23,642&lt;/cell&gt;
        &lt;cell&gt;17,847&lt;/cell&gt;
        &lt;cell&gt;15,765&lt;/cell&gt;
        &lt;cell&gt;25,260&lt;/cell&gt;
        &lt;cell&gt;19,975&lt;/cell&gt;
        &lt;cell&gt;38,699&lt;/cell&gt;
        &lt;cell&gt;35,924&lt;/cell&gt;
        &lt;cell&gt;21,620&lt;/cell&gt;
        &lt;cell&gt;28,131&lt;/cell&gt;
        &lt;cell&gt;27,497&lt;/cell&gt;
        &lt;cell&gt;74,159&lt;/cell&gt;
        &lt;cell&gt;45,015&lt;/cell&gt;
        &lt;cell&gt;10,332&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Dividing addresses by allocations gives the average IPv6 allocation size in each region (Table 17). Overall, the average IPv6 allocation size in 2025 smaller than a /30, with the RIPE NCC and APNIC averaging larger individual IPv6 allocations than the other RIRs.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="15"&gt;
        &lt;cell role="head"&gt;2012&lt;/cell&gt;
        &lt;cell role="head"&gt;2013&lt;/cell&gt;
        &lt;cell role="head"&gt;2014&lt;/cell&gt;
        &lt;cell role="head"&gt;2015&lt;/cell&gt;
        &lt;cell role="head"&gt;2016&lt;/cell&gt;
        &lt;cell role="head"&gt;2017&lt;/cell&gt;
        &lt;cell role="head"&gt;2018&lt;/cell&gt;
        &lt;cell role="head"&gt;2019&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;AFRINIC&lt;/cell&gt;
        &lt;cell&gt;/26.3&lt;/cell&gt;
        &lt;cell&gt;/32.1&lt;/cell&gt;
        &lt;cell&gt;/32.3&lt;/cell&gt;
        &lt;cell&gt;/30.1&lt;/cell&gt;
        &lt;cell&gt;/32.5&lt;/cell&gt;
        &lt;cell&gt;/32.0&lt;/cell&gt;
        &lt;cell&gt;/32.6&lt;/cell&gt;
        &lt;cell&gt;/30.3&lt;/cell&gt;
        &lt;cell&gt;/32.3&lt;/cell&gt;
        &lt;cell&gt;/31.9&lt;/cell&gt;
        &lt;cell&gt;/30.6&lt;/cell&gt;
        &lt;cell&gt;/30.2&lt;/cell&gt;
        &lt;cell&gt;/30.3&lt;/cell&gt;
        &lt;cell&gt;/30.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;APNIC&lt;/cell&gt;
        &lt;cell&gt;/29.3&lt;/cell&gt;
        &lt;cell&gt;/29.0&lt;/cell&gt;
        &lt;cell&gt;/29.7&lt;/cell&gt;
        &lt;cell&gt;/30.6&lt;/cell&gt;
        &lt;cell&gt;/32.4&lt;/cell&gt;
        &lt;cell&gt;/30.4&lt;/cell&gt;
        &lt;cell&gt;/28.2&lt;/cell&gt;
        &lt;cell&gt;/29.6&lt;/cell&gt;
        &lt;cell&gt;/29.7&lt;/cell&gt;
        &lt;cell&gt;/29.1&lt;/cell&gt;
        &lt;cell&gt;/30.1&lt;/cell&gt;
        &lt;cell&gt;/33.2&lt;/cell&gt;
        &lt;cell&gt;/27.3&lt;/cell&gt;
        &lt;cell&gt;/30.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;ARIN&lt;/cell&gt;
        &lt;cell&gt;/30.5&lt;/cell&gt;
        &lt;cell&gt;/27.5&lt;/cell&gt;
        &lt;cell&gt;/28.6&lt;/cell&gt;
        &lt;cell&gt;/31.9&lt;/cell&gt;
        &lt;cell&gt;/31.2&lt;/cell&gt;
        &lt;cell&gt;/31.0&lt;/cell&gt;
        &lt;cell&gt;/31.6&lt;/cell&gt;
        &lt;cell&gt;/28.8&lt;/cell&gt;
        &lt;cell&gt;/29.1&lt;/cell&gt;
        &lt;cell&gt;/32.8&lt;/cell&gt;
        &lt;cell&gt;/27.7&lt;/cell&gt;
        &lt;cell&gt;/25.5&lt;/cell&gt;
        &lt;cell&gt;/29.4&lt;/cell&gt;
        &lt;cell&gt;/31.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;LACNIC&lt;/cell&gt;
        &lt;cell&gt;/27.9&lt;/cell&gt;
        &lt;cell&gt;/32.5&lt;/cell&gt;
        &lt;cell&gt;/31.9&lt;/cell&gt;
        &lt;cell&gt;/32.1&lt;/cell&gt;
        &lt;cell&gt;/31.8&lt;/cell&gt;
        &lt;cell&gt;/32.1&lt;/cell&gt;
        &lt;cell&gt;/32.1&lt;/cell&gt;
        &lt;cell&gt;/32.1&lt;/cell&gt;
        &lt;cell&gt;/32.1&lt;/cell&gt;
        &lt;cell&gt;/32.1&lt;/cell&gt;
        &lt;cell&gt;/32.2&lt;/cell&gt;
        &lt;cell&gt;/32.4&lt;/cell&gt;
        &lt;cell&gt;/32.2&lt;/cell&gt;
        &lt;cell&gt;/32.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="15"&gt;
        &lt;cell&gt;RIPENCC&lt;/cell&gt;
        &lt;cell&gt;/30.9&lt;/cell&gt;
        &lt;cell&gt;/30.4&lt;/cell&gt;
        &lt;cell&gt;/30.0&lt;/cell&gt;
        &lt;cell&gt;/29.5&lt;/cell&gt;
        &lt;cell&gt;/28.6&lt;/cell&gt;
        &lt;cell&gt;/29.3&lt;/cell&gt;
        &lt;cell&gt;/29.3&lt;/cell&gt;
        &lt;cell&gt;/29.2&lt;/cell&gt;
        &lt;cell&gt;/29.5&lt;/cell&gt;
        &lt;cell&gt;/29.2&lt;/cell&gt;
        &lt;cell&gt;/29.4&lt;/cell&gt;
        &lt;cell&gt;/29.4&lt;/cell&gt;
        &lt;cell&gt;/29.6&lt;/cell&gt;
        &lt;cell&gt;/29.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;/29.6&lt;/cell&gt;
        &lt;cell&gt;/29.3&lt;/cell&gt;
        &lt;cell&gt;/30.0&lt;/cell&gt;
        &lt;cell&gt;/30.2&lt;/cell&gt;
        &lt;cell&gt;/29.8&lt;/cell&gt;
        &lt;cell&gt;/30.2&lt;/cell&gt;
        &lt;cell&gt;/29.4&lt;/cell&gt;
        &lt;cell&gt;/29.6&lt;/cell&gt;
        &lt;cell&gt;/30.0&lt;/cell&gt;
        &lt;cell&gt;/29.6&lt;/cell&gt;
        &lt;cell&gt;/29.2&lt;/cell&gt;
        &lt;cell&gt;/27.7&lt;/cell&gt;
        &lt;cell&gt;/28.5&lt;/cell&gt;
        &lt;cell&gt;/30.5&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The number and volume of IPv6 allocations per RIR per year is shown in Figures 19 and 20.&lt;/p&gt;
    &lt;p&gt;The number of IPv6 address allocations has been steadily falling since 2019, as shown in Figure 19. There was a more dramatic fall in the volume of allocated addresses in 2025, although the numbers for 2023 and 2024 were buoyed up by single very large allocations in each of those two years, firstly by ARIN in 2023 and APNIC in 2024.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="13"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;1,394&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;619&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;638&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;691&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;889&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;967&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;588&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
        &lt;cell&gt;576&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;377&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;424&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;302&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;310&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;Indonesia&lt;/cell&gt;
        &lt;cell&gt;389&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;508&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;339&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;267&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;269&lt;/cell&gt;
        &lt;cell&gt;Indonesia&lt;/cell&gt;
        &lt;cell&gt;304&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;226&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
        &lt;cell&gt;448&lt;/cell&gt;
        &lt;cell&gt;Bangladesh&lt;/cell&gt;
        &lt;cell&gt;239&lt;/cell&gt;
        &lt;cell&gt;Indonesia&lt;/cell&gt;
        &lt;cell&gt;198&lt;/cell&gt;
        &lt;cell&gt;Vietnam&lt;/cell&gt;
        &lt;cell&gt;233&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;268&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
        &lt;cell&gt;199&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;390&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;158&lt;/cell&gt;
        &lt;cell&gt;Bangladesh&lt;/cell&gt;
        &lt;cell&gt;159&lt;/cell&gt;
        &lt;cell&gt;Indonesia&lt;/cell&gt;
        &lt;cell&gt;169&lt;/cell&gt;
        &lt;cell&gt;Bangladesh&lt;/cell&gt;
        &lt;cell&gt;167&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;192&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;304&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
        &lt;cell&gt;138&lt;/cell&gt;
        &lt;cell&gt;Vietnam&lt;/cell&gt;
        &lt;cell&gt;143&lt;/cell&gt;
        &lt;cell&gt;Bangladesh&lt;/cell&gt;
        &lt;cell&gt;156&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;104&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;Bangladesh&lt;/cell&gt;
        &lt;cell&gt;182&lt;/cell&gt;
        &lt;cell&gt;Bangladesh&lt;/cell&gt;
        &lt;cell&gt;213&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;125&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;126&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;119&lt;/cell&gt;
        &lt;cell&gt;Vietnam&lt;/cell&gt;
        &lt;cell&gt;98&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;196&lt;/cell&gt;
        &lt;cell&gt;Indonesia&lt;/cell&gt;
        &lt;cell&gt;113&lt;/cell&gt;
        &lt;cell&gt;Colombia&lt;/cell&gt;
        &lt;cell&gt;99&lt;/cell&gt;
        &lt;cell&gt;Iran&lt;/cell&gt;
        &lt;cell&gt;86&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;71&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;Australia&lt;/cell&gt;
        &lt;cell&gt;118&lt;/cell&gt;
        &lt;cell&gt;Indonesia&lt;/cell&gt;
        &lt;cell&gt;110&lt;/cell&gt;
        &lt;cell&gt;Australia&lt;/cell&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;Mexico&lt;/cell&gt;
        &lt;cell&gt;96&lt;/cell&gt;
        &lt;cell&gt;Australia&lt;/cell&gt;
        &lt;cell&gt;83&lt;/cell&gt;
        &lt;cell&gt;Canada&lt;/cell&gt;
        &lt;cell&gt;68&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
        &lt;cell&gt;115&lt;/cell&gt;
        &lt;cell&gt;Hong Kong&lt;/cell&gt;
        &lt;cell&gt;108&lt;/cell&gt;
        &lt;cell&gt;Vietnam&lt;/cell&gt;
        &lt;cell&gt;91&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;85&lt;/cell&gt;
        &lt;cell&gt;Mexico&lt;/cell&gt;
        &lt;cell&gt;83&lt;/cell&gt;
        &lt;cell&gt;Australia&lt;/cell&gt;
        &lt;cell&gt;65&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Table 18 shows the countries who received the largest number of individual IPv6 allocations, while Table 19 shows the amount of IPv6 address space assigned on a per economy basis for the past 4 years (using units of /32s). The annual volume of allocated IPv6 addresses is shown in Table 19.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="13"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;2020&lt;/cell&gt;
        &lt;cell role="head"&gt;2021&lt;/cell&gt;
        &lt;cell role="head"&gt;2022&lt;/cell&gt;
        &lt;cell role="head"&gt;2023&lt;/cell&gt;
        &lt;cell role="head"&gt;2024&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
        &lt;cell&gt;6,765&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
        &lt;cell&gt;5,424&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;13,919&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;66,579&lt;/cell&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
        &lt;cell&gt;32,792&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
        &lt;cell&gt;4,139&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;5,051&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
        &lt;cell&gt;4,409&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
        &lt;cell&gt;4,354&lt;/cell&gt;
        &lt;cell&gt;Lithuania&lt;/cell&gt;
        &lt;cell&gt;522&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;5,533&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;1,906&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;1,358&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
        &lt;cell&gt;4,281&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
        &lt;cell&gt;925&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;513&lt;/cell&gt;
        &lt;cell&gt;Iran&lt;/cell&gt;
        &lt;cell&gt;643&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;400&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
        &lt;cell&gt;1,331&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
        &lt;cell&gt;3,390&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;734&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;478&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;426&lt;/cell&gt;
        &lt;cell&gt;Iran&lt;/cell&gt;
        &lt;cell&gt;382&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;716&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;2,249&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;706&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
        &lt;cell&gt;371&lt;/cell&gt;
        &lt;cell&gt;Lithuania&lt;/cell&gt;
        &lt;cell&gt;410&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;295&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
        &lt;cell&gt;715&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
        &lt;cell&gt;896&lt;/cell&gt;
        &lt;cell&gt;Moldova&lt;/cell&gt;
        &lt;cell&gt;456&lt;/cell&gt;
        &lt;cell&gt;Ukraine&lt;/cell&gt;
        &lt;cell&gt;369&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;352&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;288&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
        &lt;cell&gt;552&lt;/cell&gt;
        &lt;cell&gt;Ukraine&lt;/cell&gt;
        &lt;cell&gt;651&lt;/cell&gt;
        &lt;cell&gt;France&lt;/cell&gt;
        &lt;cell&gt;404&lt;/cell&gt;
        &lt;cell&gt;Iran&lt;/cell&gt;
        &lt;cell&gt;314&lt;/cell&gt;
        &lt;cell&gt;Turkey&lt;/cell&gt;
        &lt;cell&gt;328&lt;/cell&gt;
        &lt;cell&gt;Ghana&lt;/cell&gt;
        &lt;cell&gt;261&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
        &lt;cell&gt;391&lt;/cell&gt;
        &lt;cell&gt;Lithuania&lt;/cell&gt;
        &lt;cell&gt;633&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
        &lt;cell&gt;397&lt;/cell&gt;
        &lt;cell&gt;France&lt;/cell&gt;
        &lt;cell&gt;276&lt;/cell&gt;
        &lt;cell&gt;South Africa&lt;/cell&gt;
        &lt;cell&gt;304&lt;/cell&gt;
        &lt;cell&gt;Turkey&lt;/cell&gt;
        &lt;cell&gt;248&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="13"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;France&lt;/cell&gt;
        &lt;cell&gt;390&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;502&lt;/cell&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
        &lt;cell&gt;363&lt;/cell&gt;
        &lt;cell&gt;Seychelles&lt;/cell&gt;
        &lt;cell&gt;258&lt;/cell&gt;
        &lt;cell&gt;Canada&lt;/cell&gt;
        &lt;cell&gt;292&lt;/cell&gt;
        &lt;cell&gt;France&lt;/cell&gt;
        &lt;cell&gt;231&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;Turkey&lt;/cell&gt;
        &lt;cell&gt;290&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
        &lt;cell&gt;491&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;328&lt;/cell&gt;
        &lt;cell&gt;Rwanda&lt;/cell&gt;
        &lt;cell&gt;256&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
        &lt;cell&gt;289&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
        &lt;cell&gt;219&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We can also review the total IPv6 allocated address pools for top 25 IPv6-holding national economies as of the end of 2025 (Table 20).&lt;/p&gt;
    &lt;p&gt;While the United States tops this list of the total pool of allocated IPv6 addresses, with some 31% of the total span of allocated IPv6 addresses, the per capita number is lower than others in this list (Netherlands, Sweden, Switzerland). In 2023 ARIN allocated a /16 address block to Capital One Financial Cooperation, one of the larger banks in the United States with a large credit card base in retail operations. In 2024 APNIC allocated a /17 to Huawei International, with a corporate location in Singapore.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;Rank&lt;/cell&gt;
        &lt;cell role="head"&gt;CC&lt;/cell&gt;
        &lt;cell role="head"&gt;Allocated (/48s)&lt;/cell&gt;
        &lt;cell role="head"&gt;% Total&lt;/cell&gt;
        &lt;cell role="head"&gt;/48s p.c.&lt;/cell&gt;
        &lt;cell role="head"&gt;Advertised /48s&lt;/cell&gt;
        &lt;cell role="head"&gt;Deployment&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;US&lt;/cell&gt;
        &lt;cell&gt;9,365,768,669&lt;/cell&gt;
        &lt;cell&gt;29.1%&lt;/cell&gt;
        &lt;cell&gt;27.2&lt;/cell&gt;
        &lt;cell&gt;1,461,877,253&lt;/cell&gt;
        &lt;cell&gt;15.61&lt;/cell&gt;
        &lt;cell&gt;USA&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;CN&lt;/cell&gt;
        &lt;cell&gt;4,493,742,162&lt;/cell&gt;
        &lt;cell&gt;14.0%&lt;/cell&gt;
        &lt;cell&gt;3.2&lt;/cell&gt;
        &lt;cell&gt;1,663,468,967&lt;/cell&gt;
        &lt;cell&gt;37.02&lt;/cell&gt;
        &lt;cell&gt;China&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;SG&lt;/cell&gt;
        &lt;cell&gt;2,259,174,127&lt;/cell&gt;
        &lt;cell&gt;7.0%&lt;/cell&gt;
        &lt;cell&gt;369.8&lt;/cell&gt;
        &lt;cell&gt;10,160,967&lt;/cell&gt;
        &lt;cell&gt;0.45&lt;/cell&gt;
        &lt;cell&gt;Singapore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;DE&lt;/cell&gt;
        &lt;cell&gt;1,589,183,275&lt;/cell&gt;
        &lt;cell&gt;4.9%&lt;/cell&gt;
        &lt;cell&gt;19.1&lt;/cell&gt;
        &lt;cell&gt;1,058,252,137&lt;/cell&gt;
        &lt;cell&gt;66.59&lt;/cell&gt;
        &lt;cell&gt;Germany&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;GB&lt;/cell&gt;
        &lt;cell&gt;1,383,735,799&lt;/cell&gt;
        &lt;cell&gt;4.3%&lt;/cell&gt;
        &lt;cell&gt;20.3&lt;/cell&gt;
        &lt;cell&gt;402,612,655&lt;/cell&gt;
        &lt;cell&gt;29.10&lt;/cell&gt;
        &lt;cell&gt;UK&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;FR&lt;/cell&gt;
        &lt;cell&gt;996,356,774&lt;/cell&gt;
        &lt;cell&gt;3.1%&lt;/cell&gt;
        &lt;cell&gt;15.3&lt;/cell&gt;
        &lt;cell&gt;194,604,234&lt;/cell&gt;
        &lt;cell&gt;19.53&lt;/cell&gt;
        &lt;cell&gt;France&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;NL&lt;/cell&gt;
        &lt;cell&gt;716,964,426&lt;/cell&gt;
        &lt;cell&gt;2.2%&lt;/cell&gt;
        &lt;cell&gt;40.4&lt;/cell&gt;
        &lt;cell&gt;268,864,861&lt;/cell&gt;
        &lt;cell&gt;37.50&lt;/cell&gt;
        &lt;cell&gt;Netherlands&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;RU&lt;/cell&gt;
        &lt;cell&gt;707,002,688&lt;/cell&gt;
        &lt;cell&gt;2.2%&lt;/cell&gt;
        &lt;cell&gt;4.9&lt;/cell&gt;
        &lt;cell&gt;235,224,973&lt;/cell&gt;
        &lt;cell&gt;33.27&lt;/cell&gt;
        &lt;cell&gt;Russia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;IT&lt;/cell&gt;
        &lt;cell&gt;697,438,251&lt;/cell&gt;
        &lt;cell&gt;2.2%&lt;/cell&gt;
        &lt;cell&gt;11.9&lt;/cell&gt;
        &lt;cell&gt;441,473,076&lt;/cell&gt;
        &lt;cell&gt;63.30&lt;/cell&gt;
        &lt;cell&gt;Italy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;JP&lt;/cell&gt;
        &lt;cell&gt;669,610,206&lt;/cell&gt;
        &lt;cell&gt;2.1%&lt;/cell&gt;
        &lt;cell&gt;5.5&lt;/cell&gt;
        &lt;cell&gt;512,384,857&lt;/cell&gt;
        &lt;cell&gt;76.52&lt;/cell&gt;
        &lt;cell&gt;Japan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;AU&lt;/cell&gt;
        &lt;cell&gt;622,466,380&lt;/cell&gt;
        &lt;cell&gt;1.9%&lt;/cell&gt;
        &lt;cell&gt;23.0&lt;/cell&gt;
        &lt;cell&gt;311,339,826&lt;/cell&gt;
        &lt;cell&gt;50.02&lt;/cell&gt;
        &lt;cell&gt;Australia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;BR&lt;/cell&gt;
        &lt;cell&gt;552,504,290&lt;/cell&gt;
        &lt;cell&gt;1.7%&lt;/cell&gt;
        &lt;cell&gt;2.5&lt;/cell&gt;
        &lt;cell&gt;443,002,861&lt;/cell&gt;
        &lt;cell&gt;80.18&lt;/cell&gt;
        &lt;cell&gt;Brazil&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;SE&lt;/cell&gt;
        &lt;cell&gt;457,834,856&lt;/cell&gt;
        &lt;cell&gt;1.4%&lt;/cell&gt;
        &lt;cell&gt;42.5&lt;/cell&gt;
        &lt;cell&gt;87,939,340&lt;/cell&gt;
        &lt;cell&gt;19.21&lt;/cell&gt;
        &lt;cell&gt;Sweden&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;IN&lt;/cell&gt;
        &lt;cell&gt;445,384,346&lt;/cell&gt;
        &lt;cell&gt;1.4%&lt;/cell&gt;
        &lt;cell&gt;0.3&lt;/cell&gt;
        &lt;cell&gt;374,616,708&lt;/cell&gt;
        &lt;cell&gt;84.11&lt;/cell&gt;
        &lt;cell&gt;India&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;PL&lt;/cell&gt;
        &lt;cell&gt;405,012,749&lt;/cell&gt;
        &lt;cell&gt;1.3%&lt;/cell&gt;
        &lt;cell&gt;10.3&lt;/cell&gt;
        &lt;cell&gt;213,105,000&lt;/cell&gt;
        &lt;cell&gt;52.62&lt;/cell&gt;
        &lt;cell&gt;Poland&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;SC&lt;/cell&gt;
        &lt;cell&gt;371,458,053&lt;/cell&gt;
        &lt;cell&gt;1.2%&lt;/cell&gt;
        &lt;cell&gt;3,403.5&lt;/cell&gt;
        &lt;cell&gt;190,812,631&lt;/cell&gt;
        &lt;cell&gt;51.37&lt;/cell&gt;
        &lt;cell&gt;Seychelles&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;ES&lt;/cell&gt;
        &lt;cell&gt;370,671,667&lt;/cell&gt;
        &lt;cell&gt;1.2%&lt;/cell&gt;
        &lt;cell&gt;7.8&lt;/cell&gt;
        &lt;cell&gt;115,409,593&lt;/cell&gt;
        &lt;cell&gt;31.14&lt;/cell&gt;
        &lt;cell&gt;Spain&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;ZA&lt;/cell&gt;
        &lt;cell&gt;350,950,578&lt;/cell&gt;
        &lt;cell&gt;1.1%&lt;/cell&gt;
        &lt;cell&gt;5.7&lt;/cell&gt;
        &lt;cell&gt;311,555,526&lt;/cell&gt;
        &lt;cell&gt;88.77&lt;/cell&gt;
        &lt;cell&gt;South Africa&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;AR&lt;/cell&gt;
        &lt;cell&gt;347,215,986&lt;/cell&gt;
        &lt;cell&gt;1.1%&lt;/cell&gt;
        &lt;cell&gt;7.5&lt;/cell&gt;
        &lt;cell&gt;288,372,923&lt;/cell&gt;
        &lt;cell&gt;83.05&lt;/cell&gt;
        &lt;cell&gt;Argentina&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;KR&lt;/cell&gt;
        &lt;cell&gt;346,493,198&lt;/cell&gt;
        &lt;cell&gt;1.1%&lt;/cell&gt;
        &lt;cell&gt;6.7&lt;/cell&gt;
        &lt;cell&gt;2,608,311&lt;/cell&gt;
        &lt;cell&gt;0.75&lt;/cell&gt;
        &lt;cell&gt;Korea&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;21&lt;/cell&gt;
        &lt;cell&gt;AE&lt;/cell&gt;
        &lt;cell&gt;286,851,085&lt;/cell&gt;
        &lt;cell&gt;0.9%&lt;/cell&gt;
        &lt;cell&gt;29.6&lt;/cell&gt;
        &lt;cell&gt;234,423,207&lt;/cell&gt;
        &lt;cell&gt;81.72&lt;/cell&gt;
        &lt;cell&gt;United Arab Emirates&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;TR&lt;/cell&gt;
        &lt;cell&gt;278,396,961&lt;/cell&gt;
        &lt;cell&gt;0.9%&lt;/cell&gt;
        &lt;cell&gt;3.2&lt;/cell&gt;
        &lt;cell&gt;68,204,409&lt;/cell&gt;
        &lt;cell&gt;24.50&lt;/cell&gt;
        &lt;cell&gt;Turkey&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;23&lt;/cell&gt;
        &lt;cell&gt;EG&lt;/cell&gt;
        &lt;cell&gt;271,384,582&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
        &lt;cell&gt;2.3&lt;/cell&gt;
        &lt;cell&gt;270,925,826&lt;/cell&gt;
        &lt;cell&gt;99.83&lt;/cell&gt;
        &lt;cell&gt;Egypt&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;CH&lt;/cell&gt;
        &lt;cell&gt;270,205,124&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
        &lt;cell&gt;30.3&lt;/cell&gt;
        &lt;cell&gt;126,588,325&lt;/cell&gt;
        &lt;cell&gt;46.85&lt;/cell&gt;
        &lt;cell&gt;Switzerland&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;25&lt;/cell&gt;
        &lt;cell&gt;IR&lt;/cell&gt;
        &lt;cell&gt;267,517,963&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
        &lt;cell&gt;2.9&lt;/cell&gt;
        &lt;cell&gt;52,436,571&lt;/cell&gt;
        &lt;cell&gt;19.60&lt;/cell&gt;
        &lt;cell&gt;Iran&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There are a number of visible outliers in this table. In terms of addresses per capita the Seychelles and Singapore are clearly evident as having a volume of IPv6 allocated addresses to entities who are domiciled in that country that is a far greater address pool than their domestic population would suggest. There are some 503 address prefix allocations recorded against Singapore, but one allocation, 2410::/17 to Huawei International, a company whose corporate office is in Singapore, is the reason why Singapore's address holdings are so large. There are 731 IPv6 address prefix allocations recorded against the Seychelles, but 353 of these allocations, and one half of the total allocated address pool for the Seychelles are recorded by the RIPE NCC against a single account holder. This holding entity is an IP address broker, iNet Ltd, a company registered in the Seychelles, but with a primary UK point of contact, with leasing customers predominately located in Europe.&lt;/p&gt;
    &lt;p&gt;In terms of advertising IPv6 address prefixes into the public Internet there are also some anomalies. Korea has some 181 IPv6 address allocation records, yet only 55 of these address prefixes are visible in the routing table, representing just 0.75% of the address pool registered to that country. Singapore is in a similar position at this stage. On the other hand, the network operators in Japan, Brazil, India, South Africa, Argentina, the UAE and Egypt advertise more than 75% of their allocated IPv6 address pool.&lt;/p&gt;
    &lt;p&gt;Some twenty years ago it was common practice to point out the inequities in the state of IPv4 address deployment. At the time, some US universities had more IPv4 addresses at their disposal than some highly populated developing economies, and the disparity was a part of the criticism of the address management practices that were used at the time.&lt;/p&gt;
    &lt;p&gt;Among a large set of objectives, the RIR system was intended to address this issue of predisposition to a biased outcome in address distribution. The concept behind the RIOR system was that within each regional community, the various local stakeholders had the ability to develop their own address distribution policies and could determine for themselves what they meant by such terms as âfairnessâ and âequityâ and then direct their regional address registry to implement address allocation policies that were intended to achieve these objectives.&lt;/p&gt;
    &lt;p&gt;While IPv4 had a very evident early adopter reward, in that the address allocations in the original IPv4 class A,B,C address plan could be quite extravagant, the idea was that in IPv6, where the address allocations were developed from the outset through local bottom-up policy frameworks, such evident inequities in outcomes would be avoided, or so it was hoped. It was also envisaged that with such a vast address plan provided by 128 bits of address space, the entire concept of scarcity and inequity would be largely irrelevant. 2128 is a vast number and the entire concept of comparison between two vast pools of addresses is somewhat irrelevant. So, when we look at the metric of /48s per head of population, donât forget that a /48 is actually 80 bits of address space, which is massively larger than the entire IPv4 address space. Even Indiaâs average of 0.3 /48s per capita is still a truly massive pool of IPv6 addresses!&lt;/p&gt;
    &lt;p&gt;However, before we go too far down this path it is also useful to bear in mind that the 128 bits of address space in IPv6 has become largely a myth. We sliced off 64 bits in the address plan for no particularly good reason, as it turns out. We then sliced off a further 16 bits for again no particularly good reason. 16 bits for end-site addresses allows for some 65,000 distinct networks within each site, which is somewhat outlandish in pretty much every case. The result is that the vastness of the address space represented by 128 bits in IPv6 is in fact not so vast in practice. The usable address prefix space in IPv4 roughly equates a /32 end address in IPv4 with a /48 prefix in IPv6. So perhaps this metric of /48s per capita is not entirely fanciful, and there is some substance to the observation that there are some inequities in the address distribution in IPv6. However, unlike IPv4, the exhaustion of the IPv6 address space is still quite some time off, and we still believe that there are sufficient IPv6 addresses to support a uniform address utilisation model across the entire world of silicon over time.&lt;/p&gt;
    &lt;p&gt;There is a larger question about the underlying networking paradigm in todayâs public network. IPv6 attempts to restore the 1980âs networking paradigm of a true peer-to-peer network where every connected device is capable of sending packets to any other connected device. However, todayâs networked environment regards such unconstrained connectivity as a liability. Exposing an end client device to unconstrained reachability is regarded as being unnecessarily foolhardy, and todayâs network paradigm relies on client-initiated transactions. This is well-suited to NAT-based IPv4 connectivity, and the question regarding the long-term future of an IPv6 Internet is whether we want to bear the costs of maintaining end-client unique addressing plans, or whether NATs in IPv6 might prove to be a most cost-effective service platform for the client side of client/server networks.&lt;/p&gt;
    &lt;p&gt;To what extent are allocated IPv6 addresses visible as advertised prefixes in the Internetâs routing table?&lt;/p&gt;
    &lt;p&gt;Figure 21 shows the daily totals of advertised, unadvertised and total allocated address volumes for IPv6 since 2010, while Figure 22 shows the advertised address span as a percentage of the total span of allocated and assigned IPv6 addresses.&lt;/p&gt;
    &lt;p&gt;The drop in the allocated address span in 2013 is the result of a change in LACNIC where a single large allocation into Brazil was replaced by the recording of direct allocation and assignments to ISPs and similar end entities. It is interesting to note that in IPv4 the longer term tend of the ratio of unadvertised address space is falling, while in IPv6 the same metric is rising. The IPv4 transfer market may be a relevant consideration here in terms of bringing otherwise unused IPv4 addresses back into circulation. From a history of careful conservation of IPv4 addresses, where some 85% of allocated or assigned IPv4 addresses are advertised in the BGP routing table, a comparable IPv6 figure of 34% does not look all that impressive. But that's not the point. We chose the 128-bit address size in IPv6 to allow addresses to be used without overriding concerns about conservation. Weâre allowed to be inefficient in address utilisation in IPv6!&lt;/p&gt;
    &lt;p&gt;At the start of 2026 weâve advertised an IPv6 address span which is the equivalent of some 160,000 /32s, or some 10.5 billion end-site /48 prefixes. That is just 0.0037% of the total number of /48 prefixes in IPv6.&lt;/p&gt;
    &lt;p&gt;Once more the set of uncertainties that surround the immediate future of the Internet are considerably greater than the set of predictions that we can be reasonably certain about.&lt;/p&gt;
    &lt;p&gt;The year 2017 saw a sharp rise in IPv6 deployment, influenced to a major extent by the deployment of IPv6 services in India, notably by the Reliance Jio mobile service, which acted as a catalyst to prompt the other major Indian ISPs to also undertake similar deployment in their networks. The next year, 2018, was a quieter year, although the rise in the second half of the year is due to the initial efforts of mass scale IPv6 deployment by some major Chinese service providers. This movement accelerated in 2019 and the overall move of a further 5% in IPv6 deployment levels had a lot to do with the very rapid rise of the deployment of IPv6 in China. There has been an ongoing rise in the level of IPv6 within China, and the measured level of IPv6 has risen from 32% of the user base at the start of 2024 to 54%at the end of 2025, or an expansion of the Chinese IPv6 user pool by some 94M end clients over the two-year period.&lt;/p&gt;
    &lt;p&gt;In 2025 the growth patterns for IPv6 were more diffuse around the world with a 3.7% overall growth rate (Figure 23). IPv6 has been extensively deployed in Northern America and parts of Western Europe, and some countries in Asia. There is scant deployment across Africa, Eastern and Southern Europe and Western Asia, and aside from China there is little in the way of large scale new deployments of IPv6 at present (Figure 24).&lt;/p&gt;
    &lt;p&gt;While a number of service operators have reached the decision point that the anticipated future costs of NAT deployment are unsustainable for their service platform, there remains a considerable body of opinion that says that NATs will cost effectively absorb some further years of Internet growth. At least that's the only rationale I can ascribe to a very large number of service providers who are making no visible moves to deploy Dual-Stack services at this point in time. Given that the ultimate objective of this transition is not to turn on Dual-Stack everywhere, but to turn off IPv4, there is still some time to go, and the uncertainty lies in trying to quantify what that time might be.&lt;/p&gt;
    &lt;p&gt;The period of the past decade has been dominated by the mass marketing of mobile internet services, and the Internetâs growth rates for 2014 through to 2016 perhaps might have been the highest so far recorded. This wouldâve been visible in the IP address deployment data were it not for the exhaustion of the IPv4 address pool. In address terms this growth in the IPv4 Internet is being almost completely masked by the use of Carrier Grade NATs in the mobile service provider environment, so that the resultant demands for public addresses in IPv4 are quite low and the real underlying growth rates in the network are occluded by these NATs. In IPv6 the extremely large size of the address space masks out much of this volume. A single IPv6 /20 allocation to an ISP allows for 268 million /48 allocations, or 68 billion /56 allocations, so much of the growth in IPv6-using networks is simply hidden behind the massive address plan that lies behind IPv6.&lt;/p&gt;
    &lt;p&gt;It has also been assumed that we would see IPv6 address demands for deployments of large-scale sensor networks and other forms of deployments that are encompassed under the broad umbrella of the Internet of Things. This does not necessarily imply that the deployment is merely a product of an over-hyped industry, although that is always a possibility. It is more likely to assume that, so far, such deployments are taking place using IP addresses in a private context, using application-level gateways to interface to the public network. On the private side, the protocol could be IPv4 or IPv6 â the choice does not matter â such an occluded deployment relies on NATs in any case. Time and time again we are lectured that NATs are not a good security device, but in practice NATs offer a reasonable front-line defence against network side malware scanning and injection, so there may be a larger story behind the use of NATs and device-based networks than just a simple conservative preference to continue to use an IPv4 protocol stack.&lt;/p&gt;
    &lt;p&gt;More generally, we are witnessing an industry that is no longer using technical innovation, openness and diversification as its primary means of expansion. The widespread use of NATs in IPv4 limit the technical substrate of the Internet to a very restricted model of simple client/server interactions using TCP and UDP. The use of NATs force the interactions into client-initiated transactions, and the model of an open network with considerable flexibility in the way in which communications take place is no longer being sustained in todayâs network. Incumbents are entrenching their position. Innovation and entrepreneurialism are taking a back seat while we sit out this protracted IPv4/IPv6 transition. You could argue that this is a sign of technical maturity where a small number of deployment models are picked up by all players as being best suited to the environment of deployment. You could also note that our efforts to have hosts be capable of countering all forms of hostile attack are somewhat effectual, and this form of occluded deployment where hosts sit behind some form of device that can deflect unsolicited traffic is mandatory on today's Internet.&lt;/p&gt;
    &lt;p&gt;What is happening is that today's internet carriage service is provided by an ever-smaller number of very large players, each of whom appear to be assuming a very strong position within their respective markets. The drivers for such larger players tend towards risk aversion, conservatism and increased levels of control across their scope of operation. The same trends of market aggregation are now appearing in content provision platforms, where a small number of platform operators are exerting a completely dominant position across the entire Internet.&lt;/p&gt;
    &lt;p&gt;The evolving makeup of the Internet industry has quite profound implications in terms of network neutrality, the separation of functions of carriage and service provision, investment profiles and expectations of risk and returns on infrastructure investments, and on the openness of the Internet itself. Given the economies of volume in this industry, it was always going to be challenging to sustain an efficient, fully open and competitive industry platform that was capable of sustaining both large and small operators, but the degree of challenge in this agenda is multiplied many-fold when the underlying platform has run out of the basic currency of IP addresses. The pressures on the larger players within these markets to leverage their incumbency into overarching control gains traction when the stream of new entrants with competitive offerings dries up, and the solutions in such scenarios typically involve some form of public sector intervention directed to restore effective competition and revive the impetus for more efficient and effective offerings in the market.&lt;/p&gt;
    &lt;p&gt;As the Internet continues to evolve, it is no longer the technically innovative challenger pitted against venerable incumbents in the forms of the traditional industries of telephony, print newspapers, television entertainment and social interaction. The Internet is now the established norm. The days when the Internet was touted as a poster child of disruption in a deregulated space are long since over, and these days we appear to be increasingly looking further afield for a regulatory and governance framework that can challenge the increasing complacency of the very small number of massive digital incumbents.&lt;/p&gt;
    &lt;p&gt;It is unclear how successful we will be in this search for responses to this oppressive level of centrality in many aspects of the digital environment. We can but wait and see.&lt;/p&gt;
    &lt;p&gt;The above views do not necessarily represent the views of the Asia Pacific Network Information Centre.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; GEOFF HUSTON AM B.Sc., M.Sc., is the Chief Scientist at APNIC, the Regional Internet Registry serving the Asia Pacific region. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46691835</guid><pubDate>Tue, 20 Jan 2026 13:51:03 +0000</pubDate></item><item><title>Unconventional PostgreSQL Optimizations</title><link>https://hakibenita.com/postgresql-unconventional-optimizations</link><description>&lt;doc fingerprint="9b9903574d9c19b6"&gt;
  &lt;main&gt;
    &lt;p&gt;When it comes to database optimization, developers often reach for the same old tools: rewrite the query slightly differently, slap an index on a column, denormalize, analyze, vacuum, cluster, repeat. Conventional techniques are effective, but sometimes being creative can really pay off!&lt;/p&gt;
    &lt;p&gt;In this article, I present unconventional optimization techniques in PostgreSQL.&lt;/p&gt;
    &lt;p&gt;
      &lt;head&gt;Table of Contents&lt;/head&gt;
    &lt;/p&gt;
    &lt;head rend="h2"&gt;Eliminate Full Table Scans Based on Check Constraints&lt;/head&gt;
    &lt;p&gt;Imagine you have this table of users:&lt;/p&gt;
    &lt;code&gt;db=# CREATE TABLE users (
    id INT PRIMARY KEY,
    username TEXT NOT NULL,
    plan TEXT NOT NULL,
    CONSTRAINT plan_check CHECK (plan IN ('free', 'pro'))
);
CREATE TABLE
&lt;/code&gt;
    &lt;p&gt;For each user you keep their name and which payment plan they're on. There are only two plans, "free" and "pro", so you add a check constraint.&lt;/p&gt;
    &lt;p&gt;Generate some data and analyze the table:&lt;/p&gt;
    &lt;code&gt;db=# INSERT INTO users
SELECT n, uuidv4(), (ARRAY['free', 'pro'])[ceil(random()*2)]
FROM generate_series(1, 100_000) AS t(n);
INSERT 0 100000

db=# ANALYZE users;
ANALYZE
&lt;/code&gt;
    &lt;p&gt;You now have 100K users in the system.&lt;/p&gt;
    &lt;head rend="h3"&gt;Honest Mistakes&lt;/head&gt;
    &lt;p&gt;Now you want to let your analysts access this table in their reporting tool of choice. You give one of the analysts permission, and this is the first query they write:&lt;/p&gt;
    &lt;code&gt;db=# SELECT * FROM users WHERE plan = 'Pro';
 id │ username │ plan
────┼──────────┼──────
(0 rows)
&lt;/code&gt;
    &lt;p&gt;The query returned no results, and the analyst is baffled. How come there are no users on the "Pro" plan?&lt;/p&gt;
    &lt;p&gt;The name of the plan is "pro" and not "Pro" (with a capital "P") as the analyst wrote it. This is an honest mistake really, anyone can make such a mistake! But what is the cost of this mistake?&lt;/p&gt;
    &lt;p&gt;Examine the execution plan of a query for a non-existing value:&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN ANALYZE SELECT * FROM users WHERE plan = 'Pro';
                QUERY PLAN
──────────────────────────────────────────────────────────────────
 Seq Scan on users  (cost=0.00..2185.00 rows=1 width=45)
                    (actual time=7.406..7.407 rows=0.00 loops=1)
   Filter: (plan = 'Pro'::text)
   Rows Removed by Filter: 100000
   Buffers: shared hit=935
 Planning:
   Buffers: shared hit=29 read=2
 Planning Time: 4.564 ms
 Execution Time: 7.436 ms
&lt;/code&gt;
    &lt;p&gt;PostgreSQL scanned the entire table! However, there's a check constraint on the field - no row can ever have the value "Pro", the database makes sure of that! So if this condition always evaluates to false, why is PostgreSQL scanning the table?&lt;/p&gt;
    &lt;head rend="h3"&gt;Using &lt;code&gt;constraint_exclusion&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;PostgreSQL is smart enough to skip a table scan when the query contains a condition that always evaluates to false, but not by default! To instruct PostgreSQL to look at constraints when generating a plan, you need to set the parameter &lt;code&gt;constraint_exclusion&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;db=# SET constraint_exclusion to 'on';
SET

db=# EXPLAIN ANALYZE SELECT * FROM users WHERE plan = 'Pro';
                                      QUERY PLAN
───────────────────────────────────────────────────────────────────────────────────────
 Result  (cost=0.00..0.00 rows=0 width=0) (actual time=0.000..0.001 rows=0.00 loops=1)
   One-Time Filter: false
 Planning:
   Buffers: shared hit=5 read=4
 Planning Time: 5.760 ms
 Execution Time: 0.008 ms
(6 rows)
&lt;/code&gt;
    &lt;p&gt;Nice! After turning &lt;code&gt;constraint_exclusion&lt;/code&gt; on, PostgreSQL figured out based on the check constraint that the condition won't return any rows, and skipped the scan entirely.&lt;/p&gt;
    &lt;head rend="h3"&gt;When &lt;code&gt;constraint_exclusion&lt;/code&gt; Makes Sense&lt;/head&gt;
    &lt;p&gt;So who are you &lt;code&gt;constraint_exclusion&lt;/code&gt; and why are you not on by default?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Currently, constraint exclusion is enabled by default only for cases that are often used to implement table partitioning via inheritance trees. Turning it on for all tables imposes extra planning overhead that is quite noticeable on simple queries, and most often will yield no benefit for simple queries.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The parameter &lt;code&gt;constraint_exclusion&lt;/code&gt; is set to "partition" by default, where it's used to eliminate entire partitions when querying against a partitioned table - this is known as "partition pruning".&lt;/p&gt;
    &lt;p&gt;The documentation states that for simple queries the cost of evaluating all relevant conditions against all the relevant constraints might outweigh the benefit - you might end up spending more time planning than actually executing the query. It makes sense that queries executed by a system are less likely to query for invalid values or apply conditions that go against constraints. However, this is not the case for ad-hoc queries in reporting tools...&lt;/p&gt;
    &lt;p&gt;In BI and reporting environments users can issue complicated queries that are often crafted by hand. In this type of environment, it's not unlikely that they'll make mistakes, just like our analyst did before. Setting &lt;code&gt;constraint_exclusion&lt;/code&gt; to "on" in reporting and data warehouse environments where users can issue ad-hoc queries can potentially save time and resources by eliminating unnecessary full table scans.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optimize for Lower Cardinality With Function Based Index&lt;/head&gt;
    &lt;p&gt;Imagine you have a sales table that looks like this:&lt;/p&gt;
    &lt;code&gt;db=# CREATE TABLE sale (
    id INT PRIMARY KEY,
    sold_at TIMESTAMPTZ NOT NULL,
    charged INT NOT NULL
);
CREATE TABLE
&lt;/code&gt;
    &lt;p&gt;You keep track of when the sale was made and how much was charged. Create 10 million sales and analyze the table:&lt;/p&gt;
    &lt;code&gt;db=# INSERT INTO sale (id, sold_at, charged)
SELECT
    n AS id,
    '2025-01-01 UTC'::timestamptz + (interval '5 seconds') * n AS sold_at,
    ceil(random() * 100) AS charged
FROM generate_series(1, 10_000_000) AS t(n);
INSERT 0 10000000

db=# ANALYZE sale;
ANALYZE
&lt;/code&gt;
    &lt;head rend="h3"&gt;Slapping a B-Tree on it&lt;/head&gt;
    &lt;p&gt;Your analysts often produce daily sales reports and their queries can look roughly like this:&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN (ANALYZE ON, BUFFERS OFF, COSTS OFF)
SELECT date_trunc('day', sold_at AT TIME ZONE 'UTC'), SUM(charged)
FROM sale
WHERE '2025-01-01 UTC' &amp;lt;= sold_at AND sold_at &amp;lt; '2025-02-01 UTC'
GROUP BY 1;
                                QUERY PLAN
──────────────────────────────────────────────────────────────────────────────────
 HashAggregate (actual time=626.074..626.310 rows=32.00 loops=1)
   Group Key: date_trunc('day'::text, sold_at)
   Batches: 1  Memory Usage: 2081kB
   -&amp;gt;  Seq Scan on sale (actual time=6.428..578.135 rows=535679.00 loops=1)
         Filter: (('2025-01-01 02:00:00+02'::timestamp with time zone &amp;lt;= sold_at)
                  AND (sold_at &amp;lt; '2025-02-01 02:00:00+02'::timestamp with time zone))
         Rows Removed by Filter: 9464321
 Planning Time: 0.115 ms
 Execution Time: 627.119 ms
&lt;/code&gt;
    &lt;p&gt;PostgreSQL scanned the entire table and the query completed in ~627ms. Your analysts are a bit spoiled and ~600ms is too slow for them, so you do what you always do in these cases and "slap a B-Tree index on it":&lt;/p&gt;
    &lt;code&gt;db=# CREATE INDEX sale_sold_at_ix ON sale(sold_at);
CREATE INDEX
&lt;/code&gt;
    &lt;p&gt;Execute the query with the index:&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN (ANALYZE ON, BUFFERS OFF, COSTS OFF)
SELECT date_trunc('day', sold_at AT TIME ZONE 'UTC'), SUM(charged)
FROM sale
WHERE '2025-01-01 UTC' &amp;lt;= sold_at AND sold_at &amp;lt; '2025-02-01 UTC'
GROUP BY 1;
                                    QUERY PLAN
───────────────────────────────────────────────────────────────────────────────────────────────────
HashAggregate (actual time=186.970..187.212 rows=32.00 loops=1)
  Group Key: date_trunc('day'::text, sold_at)
  Batches: 1  Memory Usage: 2081kB
  -&amp;gt;  Index Scan using sale_sold_at_ix on sale (actual time=0.038..137.067 rows=535679.00 loops=1)
        Index Cond: ((sold_at &amp;gt;= '2025-01-01 02:00:00+02'::timestamp with time zone)
                     AND (sold_at &amp;lt; '2025-02-01 02:00:00+02'::timestamp with time zone))
        Index Searches: 1
Planning Time: 0.261 ms
Execution Time: 187.363 ms
&lt;/code&gt;
    &lt;p&gt;Execution time reduced from ~627ms to 187ms and the analysts are happy, but at what cost?&lt;/p&gt;
    &lt;code&gt;db=# \di+ sale_sold_at_ix
List of indexes
─[ RECORD 1 ]─┬────────────────
Schema        │ public
Name          │ sale_sold_at_ix
Type          │ index
Owner         │ haki
Table         │ sale
Persistence   │ permanent
Access method │ btree
Size          │ 214 MB
Description   │ ¤
&lt;/code&gt;
    &lt;p&gt;The index is 214 MB! That's almost half the size of the entire table. So the analysts are happy, but you? Not so much...&lt;/p&gt;
    &lt;p&gt;Slapping a B-Tree index is very common, but DBAs and developers often ignore the storage cost and the maintenance burden that comes with it. Using simple measures, we can potentially save some space and money.&lt;/p&gt;
    &lt;head rend="h3"&gt;Rethinking the Problem&lt;/head&gt;
    &lt;p&gt;Let's step back and re-think what we were trying to optimize. Analysts wanted to produce daily reports, but we provided them with an index that can produce results at a millisecond precision. By indexing the date and the time, we gave the analysts a lot more than what they asked for!&lt;/p&gt;
    &lt;p&gt;What if instead of indexing the entire datetime, we index just the date, without the time?&lt;/p&gt;
    &lt;code&gt;db=# CREATE INDEX sale_sold_at_date_ix ON sale((date_trunc('day', sold_at AT TIME ZONE 'UTC'))::date);
CREATE INDEX
&lt;/code&gt;
    &lt;p&gt;This creates a function-based index on the date part of the sale date. We make sure to set the time zone before we truncate the date to match the one used by the analysts in their reports.&lt;/p&gt;
    &lt;p&gt;First, check the size of the indexes:&lt;/p&gt;
    &lt;code&gt;db=# \di+ sale_sold_at_*
                  List of indexes
         Name         │ Table │ Access method │  Size
──────────────────────┼───────┼───────────────┼────────
 sale_sold_at_date_ix │ sale  │ btree         │ 66 MB
 sale_sold_at_ix      │ sale  │ btree         │ 214 MB
&lt;/code&gt;
    &lt;p&gt;The function-based index is just 66MB, that's more than 3 times smaller than the full index. While a &lt;code&gt;date&lt;/code&gt; is smaller than a &lt;code&gt;timestamptz&lt;/code&gt; -- 4 bytes vs. 8 bytes -- this is actually not where the majority of the savings come from. The function-based index has fewer distinct values, so PostgreSQL can optimize its size using deduplication.&lt;/p&gt;
    &lt;p&gt;To check if we can make better use of the smaller index, we start by dropping the full index:&lt;/p&gt;
    &lt;code&gt;db=# DROP INDEX sale_sold_at_ix;
DROP INDEX
&lt;/code&gt;
    &lt;p&gt;To allow our query to use the function-based index we make some adjustments to the query (we'll tackle that later!):&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN (ANALYZE ON, BUFFERS OFF, COSTS OFF)
SELECT date_trunc('day', sold_at AT TIME ZONE 'UTC'), SUM(charged)
FROM sale
WHERE date_trunc('day', sold_at AT TIME ZONE 'UTC')::date BETWEEN '2025-01-01' AND '2025-01-31'
GROUP BY 1;

                                                                  QUERY PLAN
─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
 GroupAggregate (actual time=6.499..145.889 rows=31.00 loops=1)
   Group Key: date_trunc('day'::text, (sold_at AT TIME ZONE 'UTC'::text))
   -&amp;gt;  Index Scan using sale_sold_at_date_ix on sale (actual time=0.015..119.832 rows=535679.00 loops=1)
         Index Cond: ((date_trunc('day'::text, (sold_at AT TIME ZONE 'UTC'::text))::date &amp;gt;= '2025-01-01 00:00:00'::timestamp without time zone)
                  AND (date_trunc('day'::text, (sold_at AT TIME ZONE 'UTC'::text))::date &amp;lt; '2025-02-01 00:00:00'::timestamp without time zone))
         Index Searches: 1
 Planning Time: 0.151 ms
 Execution Time: 145.913 ms
&lt;/code&gt;
    &lt;p&gt;The index was used and the query completed in just 145ms, that's ~20ms faster then using the full index, and x4.5 time faster than the full table scan.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Discipline Problem&lt;/head&gt;
    &lt;p&gt;Using a function based index can be fragile. If we make even the slightest adjustment to the expression, the database won't be able to use the index:&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN (ANALYZE OFF, COSTS OFF)
SELECT (sold_at AT TIME ZONE 'UTC')::date, SUM(charged)
FROM sale
WHERE (sold_at AT TIME ZONE 'UTC')::date BETWEEN '2025-01-01' AND '2025-01-31'
GROUP BY 1;
                                QUERY PLAN
────────────────────────────────────────────────────────────────────────────────────
 HashAggregate
   Group Key: ((sold_at AT TIME ZONE 'UTC'::text))::date
   -&amp;gt;  Seq Scan on sale
         Filter: ((((sold_at AT TIME ZONE 'UTC'::text))::date &amp;gt;= '2025-01-01'::date)
         AND (((sold_at AT TIME ZONE 'UTC'::text))::date &amp;lt;= '2025-01-31'::date))
&lt;/code&gt;
    &lt;p&gt;The query is the same as the previous, but we changed the expression from using &lt;code&gt;date_trunc&lt;/code&gt; to using &lt;code&gt;::date&lt;/code&gt;, so the database was unable to use the function-based index.&lt;/p&gt;
    &lt;p&gt;Using the exact same expression requires a certain level of discipline that doesn't realistically exist in any organization. It's borderline naive to expect this to be useful this way - we need to come up with a way to force the use of this exact expression.&lt;/p&gt;
    &lt;p&gt;The old way of doing this involved a view:&lt;/p&gt;
    &lt;code&gt;db=# CREATE VIEW v_sale AS
SELECT *, date_trunc('day', sold_at AT TIME ZONE 'UTC')::date AS sold_at_date
FROM sale;
CREATE VIEW
&lt;/code&gt;
    &lt;p&gt;The view adds a new calculated column called "sold_at_date" that uses the exact same expression we used to define the function-based index. Using the view, we can guarantee that we allow the database to use the index:&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN (ANALYZE OFF, COSTS OFF)
SELECT sold_at_date, SUM(charged)
FROM v_sale
WHERE sold_at_date BETWEEN '2025-01-01' AND '2025-01-31'
GROUP BY 1;
                                          QUERY PLAN
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────
 GroupAggregate
   Group Key: (date_trunc('day'::text, (sale.sold_at AT TIME ZONE 'UTC'::text)))::date
   -&amp;gt;  Index Scan using sale_sold_at_date_ix on sale
         Index Cond: (((date_trunc('day'::text, (sold_at AT TIME ZONE 'UTC'::text)))::date &amp;gt;= '2025-01-01'::date)
         AND ((date_trunc('day'::text, (sold_at AT TIME ZONE 'UTC'::text)))::date &amp;lt;= '2025-01-31'::date))
&lt;/code&gt;
    &lt;p&gt;The index is used and the query is fast! Cool, but...&lt;/p&gt;
    &lt;p&gt;Views are definitely a viable solution here, but they suffer from the same discipline problem - the analysts can still use the table directly (and they will!). We can revoke access from the table or do some magic tricks with &lt;code&gt;search_path&lt;/code&gt; to fool them into using the view, but there is an easier way.&lt;/p&gt;
    &lt;head rend="h3"&gt;Using Virtual Generated Columns&lt;/head&gt;
    &lt;p&gt;Starting at version 14, PostgreSQL supports generated columns - these are columns that are automatically populated with an expression when we insert the row. Sounds exactly like what we need but there is a caveat - the result of the expression is materialized - this means additional storage, which is what we were trying to save in the first place!&lt;/p&gt;
    &lt;p&gt;Lucky for us, starting with version 18, PostgreSQL supports virtual generated columns. A virtual column looks like a regular column, but it's actually an expression that's being evaluated every time it is accessed. Basically, what we tried to achieve before with a view!&lt;/p&gt;
    &lt;p&gt;First, add a virtual generated column to the table with the same expression we indexed:&lt;/p&gt;
    &lt;code&gt;db=# ALTER TABLE sale ADD sold_at_date DATE
GENERATED ALWAYS AS (date_trunc('day', sold_at AT TIME ZONE 'UTC'));
ALTER TABLE
&lt;/code&gt;
    &lt;p&gt;Next, execute the query using the virtual generated column:&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN (ANALYZE ON, COSTS OFF, BUFFERS OFF)
SELECT sold_at_date, SUM(charged)
FROM sale
WHERE sold_at_date BETWEEN '2025-01-01' AND '2025-01-31'
GROUP BY 1;
                                          QUERY PLAN
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────
 GroupAggregate (actual time=7.047..162.965 rows=31.00 loops=1)
   Group Key: (date_trunc('day'::text, (sold_at AT TIME ZONE 'UTC'::text)))::date
   -&amp;gt;  Index Scan using sale_sold_at_date_ix on sale (actual time=0.015..134.795 rows=535679.00 loops=1)
         Index Cond: (((date_trunc('day'::text, (sold_at AT TIME ZONE 'UTC'::text)))::date &amp;gt;= '2025-01-01'::date)
         AND ((date_trunc('day'::text, (sold_at AT TIME ZONE 'UTC'::text)))::date &amp;lt;= '2025-01-31'::date))
         Index Searches: 1
 Planning Time: 0.128 ms
 Execution Time: 162.989 ms
&lt;/code&gt;
    &lt;p&gt;Using the virtual generated column we can make sure the expression used in the query is the exact same expression we indexed. PostgreSQL is then able to use the index, and the query is fast.&lt;/p&gt;
    &lt;p&gt;There are several advantages to this approach:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Smaller index: fewer distinct values means the database can use deduplication to make the index smaller.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Faster query: the small and specific index requires less resources so the query is faster.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No discipline: using the generated column is straight forward and the index is guaranteed to be useable.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No ambiguity: making sure anyone on the team uses the same exact expression is prone to errors and discrepancies, especially when time zones are involved. Using a virtual generated column eliminates this ambiguity.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Indexing Virtual Generated Columns&lt;/head&gt;
    &lt;p&gt;The next logical step would be to create the index directly on the virtual column. Unfortunately, as of writing this article, PostgreSQL 18 does not support indexes on virtual generated columns:&lt;/p&gt;
    &lt;code&gt;db=# CREATE INDEX sale_sold_at_date_ix ON sale(sold_at_date);
ERROR:  indexes on virtual generated columns are not supported
&lt;/code&gt;
    &lt;p&gt;Hopefully indexes on virtual generated columns will make it to PostgreSQL 19.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enforce Uniqueness with Hash Index&lt;/head&gt;
    &lt;p&gt;Imagine you have a system that extracts information from URLs. You create a table to keep track:&lt;/p&gt;
    &lt;code&gt;CREATE TABLE urls (
    id INT PRIMARY KEY,
    url TEXT NOT NULL,
    data JSON
);
&lt;/code&gt;
    &lt;p&gt;Create some entries:&lt;/p&gt;
    &lt;code&gt;db=# INSERT INTO urls (id, url)
SELECT n, 'https://' || uuidv4() || '.com/ ' || uuidv4() || '?p=' || uuidv4()
FROM generate_series(1, 1_000_000) AS t(n);
INSERT 0 1000000
&lt;/code&gt;
    &lt;p&gt;Processing web pages can be resource intensive, time consuming and expensive, so you want to make sure you don't process the same page more than once.&lt;/p&gt;
    &lt;head rend="h3"&gt;Slap a Unique B-Tree on it&lt;/head&gt;
    &lt;p&gt;To make sure URLs are not processed more than once you add a unique constraint on the &lt;code&gt;url&lt;/code&gt; column:&lt;/p&gt;
    &lt;code&gt;db=# CREATE UNIQUE INDEX urls_url_unique_ix ON urls(url);
&lt;/code&gt;
    &lt;p&gt;You can now rest assured that you don't process the exact URL more than once:&lt;/p&gt;
    &lt;code&gt;db=# INSERT INTO urls(id, url) VALUES (1_000_001, 'https://hakibenita.com');
INSERT 0 1

db=# INSERT INTO urls(id, url) VALUES (1_000_002, 'https://hakibenita.com');
ERROR:  duplicate key value violates unique constraint "urls_url_unique_ix"
DETAIL:  Key (url)=(https://hakibenita.com) already exists.
&lt;/code&gt;
    &lt;p&gt;The unique constraint is enforced using a unique B-Tree index, so you also get the nice perk of being able to search for a specific URL very quickly:&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN (ANALYZE ON, BUFFERS OFF, COSTS OFF)
SELECT * FROM urls WHERE url = 'https://hakibenita.com';
                                        QUERY PLAN
──────────────────────────────────────────────────────────────────────────────────────────
 Index Scan using urls_url_unique_ix on urls (actual time=0.018..0.018 rows=1.00 loops=1)
   Index Cond: (url = 'https://hakibenita.com'::text)
   Index Searches: 1
 Planning Time: 0.173 ms
 Execution Time: 0.046 ms
&lt;/code&gt;
    &lt;p&gt;Web pages these days can have pretty big URLs. Some web apps even go as far as storing the entire application state in the URL. This is great for users, but not so great if you need to store these URLs.&lt;/p&gt;
    &lt;p&gt;Check the size of the table and the B-Tree index used to enforce the unique constraint:&lt;/p&gt;
    &lt;code&gt;db=# \dt+ urls
List of tables
─[ RECORD 1 ]─┬──────────
Schema        │ public
Name          │ urls
Type          │ table
Owner         │ haki
Persistence   │ permanent
Access method │ heap
Size          │ 160 MB
Description   │ ¤

db=# \di+ urls_url_unique_ix
List of indexes
─[ RECORD 1 ]─┬───────────────────
Schema        │ public
Name          │ urls_url_unique_ix
Type          │ index
Owner         │ haki
Table         │ urls
Persistence   │ permanent
Access method │ btree
Size          │ 154 MB
Description   │ ¤
&lt;/code&gt;
    &lt;p&gt;The size of the table is 160MB and the size of the index is a staggering 154MB!&lt;/p&gt;
    &lt;head rend="h3"&gt;Unique Hash Index&lt;/head&gt;
    &lt;p&gt;A B-Tree index stores the indexed values themselves in the leaf blocks, so when indexing large values, the B-Tree index can get very large.&lt;/p&gt;
    &lt;p&gt;PostgreSQL offers another type of index called a Hash index. This type of index does not store the actual values. Instead, it stores the hash values which can be much smaller. I wrote about Hash indexes in the past so I wont repeat myself. I would just say that indexing large values with very few repetition is where the Hash index truly shines!&lt;/p&gt;
    &lt;p&gt;A Hash index sounds like a reasonable way to enforce a unique constraint, so let's try to create a unique hash index:&lt;/p&gt;
    &lt;code&gt;db=# CREATE UNIQUE INDEX urls_url_unique_hash ON urls USING HASH(url);
ERROR:  access method "hash" does not support unique indexes
&lt;/code&gt;
    &lt;p&gt;Oh no! PostgreSQL does not support unique hash indexes, but this doesn't mean we can't still enforce uniqueness using a Hash index...&lt;/p&gt;
    &lt;head rend="h3"&gt;Enforcing Uniqueness Using a Hash Index&lt;/head&gt;
    &lt;p&gt;PostgreSQL offers a special type of constraint called an exclusion constraint. This lesser-known and not-so-widely-used constraint is often mentioned in combination with a GIN or GiST index as a way to prevent overlapping ranges. However, using an exclusion constraint we can effectively enforce uniqueness using a Hash index:&lt;/p&gt;
    &lt;code&gt;db=# ALTER TABLE urls ADD CONSTRAINT urls_url_unique_hash EXCLUDE USING HASH (url WITH =);
ALTER TABLE
&lt;/code&gt;
    &lt;p&gt;This adds an exclusion constraint on the table that prevents two rows with the same URL - this guarantees uniqueness. The exclusion constraint is enforced using a Hash index - this means we effectively enforce uniqueness with a Hash index!&lt;/p&gt;
    &lt;p&gt;First, verify that uniqueness is indeed enforced:&lt;/p&gt;
    &lt;code&gt;db=# INSERT INTO urls (id, url) VALUES (1_000_002, 'https://hakbenita.com/postgresql-hash-index');
INSERT 0 1

db=# INSERT INTO urls (id, url) VALUES (1_000_003, 'https://hakbenita.com/postgresql-hash-index');
ERROR:  conflicting key value violates exclusion constraint "urls_url_unique_hash"
DETAIL:  Key (url)=(https://hakbenita.com/postgresql-hash-index) conflicts with
existing key (url)=(https://hakbenita.com/postgresql-hash-index).
&lt;/code&gt;
    &lt;p&gt;Attempting to add a row with a URL that already exists failed with an exclusion constraint violation. Good.&lt;/p&gt;
    &lt;p&gt;Next, can this Hash index be useful for queries that filter for specific urls?&lt;/p&gt;
    &lt;code&gt;db=# EXPLAIN (ANALYZE ON, BUFFERS OFF, COSTS OFF)
SELECT * FROM urls WHERE url = 'https://hakibenita.com';
                                         QUERY PLAN
────────────────────────────────────────────────────────────────────────────────────────────
 Index Scan using urls_url_unique_hash on urls (actual time=0.010..0.011 rows=1.00 loops=1)
   Index Cond: (url = 'https://hakibenita.com'::text)
   Index Searches: 1
 Planning Time: 0.178 ms
 Execution Time: 0.022 ms
&lt;/code&gt;
    &lt;p&gt;Yes it can, and in this case it's even faster than using the B-Tree index (0.022ms vs 0.046ms).&lt;/p&gt;
    &lt;p&gt;Finally, compare the size of the B-Tree and the Hash index:&lt;/p&gt;
    &lt;code&gt;db=# \di+ urls_url_*
                List of indexes
        Name         │ Access method │  Size
─────────────────────┼───────────────┼────────
urls_url_unique_hash │ hash          │ 32 MB
urls_url_unique_ix   │ btree         │ 154 MB
&lt;/code&gt;
    &lt;p&gt;Amazing! The Hash index is x5 smaller than the corresponding B-Tree index. Instead of storing those large URLs in the B-Tree leaf blocks, the Hash index stores only the hash values which results in a significantly smaller index.&lt;/p&gt;
    &lt;head rend="h3"&gt;Limitation of "Unique" Exclusion Constraints&lt;/head&gt;
    &lt;p&gt;Using an exclusion constraint to enforce uniqueness with a Hash index can potentially save storage and make queries faster. However, there are a few caveats to consider with this approach:&lt;/p&gt;
    &lt;p&gt;⚠️ Column cannot be referenced by foreign keys&lt;/p&gt;
    &lt;p&gt;PostgreSQL requires that a foreign key reference a unique constraint. Since we can't define a unique hash constraint, we can't point a foreign key to it:&lt;/p&gt;
    &lt;code&gt;db=# CREATE TABLE foo (url TEXT REFERENCES urls(url));
ERROR:  there is no unique constraint matching given keys for referenced table "urls"
&lt;/code&gt;
    &lt;p&gt;⚠️ Limitations on &lt;code&gt;INSERT ... ON CONFLICT&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;ON CONFLICT&lt;/code&gt; clause in an &lt;code&gt;INSERT&lt;/code&gt; command is common and very useful for syncing data. Unfortunately, using exclusion constraints with this clause can have some rough edges.&lt;/p&gt;
    &lt;p&gt;Attempting to use an exclusion constraint with a list of fields in an &lt;code&gt;ON CONFLICT ... DO NOTHING&lt;/code&gt; clause can fail:&lt;/p&gt;
    &lt;code&gt;db=# INSERT INTO urls (id, url) VALUES (1_000_004, 'https://hakibenita.com')
ON CONFLICT (url) DO NOTHING;
ERROR:  there is no unique or exclusion constraint matching the ON CONFLICT specification
&lt;/code&gt;
    &lt;p&gt;The message suggests that it should be possible to use an exclusion, and it is, but using the &lt;code&gt;ON CONFLICT ON CONSTRAINT&lt;/code&gt; clause instead:&lt;/p&gt;
    &lt;code&gt;db=# INSERT INTO urls (id, url) VALUES (1_000_004, 'https://hakibenita.com')
ON CONFLICT ON CONSTRAINT urls_url_unique_hash DO NOTHING;
INSERT 0 0
&lt;/code&gt;
    &lt;p&gt;Trying the same with &lt;code&gt;ON CONFLICT ... DO UPDATE&lt;/code&gt; is not possible at all, even when using &lt;code&gt;ON CONFLICT ON CONSTRAINT&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;db=# INSERT INTO urls (id, url) VALUES (1_000_004, 'https://hakibenita.com')
ON CONFLICT ON CONSTRAINT urls_url_unique_hash DO UPDATE SET id = EXCLUDED.id;
ERROR:  ON CONFLICT DO UPDATE not supported with exclusion constraints
&lt;/code&gt;
    &lt;p&gt;I'm not a big fan of using the constraint names in SQL, so to overcome both limitations I'de use &lt;code&gt;MERGE&lt;/code&gt; instead:&lt;/p&gt;
    &lt;code&gt;db=# MERGE INTO urls t
USING (VALUES (1000004, 'https://hakibenita.com')) AS s(id, url)
ON t.url = s.url
WHEN MATCHED THEN UPDATE SET id = s.id
WHEN NOT MATCHED THEN INSERT (id, url) VALUES (s.id, s.url);
MERGE 1
&lt;/code&gt;
    &lt;p&gt;Finally, check the execution plan to verify that the statement is capable of using the Hash index:&lt;/p&gt;
    &lt;code&gt;                                  QUERY PLAN
────────────────────────────────────────────────────────────────────────────────────────────
Merge on urls t  (cost=0.00..8.04 rows=0 width=0)
  -&amp;gt;  Nested Loop Left Join  (cost=0.00..8.04 rows=1 width=6)
      -&amp;gt;  Result  (cost=0.00..0.01 rows=1 width=0)
      -&amp;gt;  Index Scan using urls_url_unique_hash on urls t  (cost=0.00..8.02 rows=1 width=6)
          Index Cond: (url = 'https://hakibenita.com'::text)
&lt;/code&gt;
    &lt;p&gt;It can, and it did!&lt;/p&gt;
    &lt;p&gt;Despite these minor limitations and inconveniences, a Hash index is a good candidate for enforcing uniqueness of large values that don't need to be referenced by foreign keys.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46692116</guid><pubDate>Tue, 20 Jan 2026 14:23:44 +0000</pubDate></item><item><title>Nvidia Stock Crash Prediction</title><link>https://entropicthoughts.com/nvidia-stock-crash-prediction</link><description>&lt;doc fingerprint="a2bd519d3eb759b4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Nvidia Stock Crash Prediction&lt;/head&gt;
    &lt;p&gt;One of the questions of the 2026 acx prediction contest is whether Nvidia’s stock price will close below $100 on any day in 2026. At the time of writing, it trades at $184 and a bit, so going down to $100 would be a near halving of the stock value of the highest valued company in the world.&lt;/p&gt;
    &lt;p&gt;It’s an interesting question, and it’s worth spending some time on it.&lt;/p&gt;
    &lt;p&gt;If you just want the answer, my best prediction is that the probability is around 10 %. I didn’t expect to get such a high answer, but read on to see how we can find out.&lt;/p&gt;
    &lt;p&gt;When we predicted the Dow Jones index crossing a barrier in 2023, we treated the index as an unbiased random walk. That was convenient, but we cannot do it with the Nvidia question because of one major difference: the time scale.&lt;/p&gt;
    &lt;head rend="h1"&gt;Return grows faster than volatility&lt;/head&gt;
    &lt;p&gt;Over short time spans, the volatility1 Or noise, or variation, or standard deviation. of stock movements dominate their return2 Or signal, or drift, or average change.. This happens because noise grows with the square root of time, while signal grows linearly with time.&lt;/p&gt;
    &lt;p&gt;The plot below illustrates an imaginary amazing investment which has a yearly log-return of 0.3, and a yearly volatility of 0.3.3 Readers aware that stonks go up will recognise this as an unrealistic Sharpe ratio of 1.0. The middle line follows our best guess for how the investment will grow after each year, and the outer curves illustrate our uncertainty around the exact value of it.&lt;/p&gt;
    &lt;p&gt;Early on, we can see that the uncertainty is much bigger than the height to the trend line. Before a year has passed, the exact result is determined more by noise than by growth. Toward the end, growth has taken over and the noise has a smaller effect.&lt;/p&gt;
    &lt;p&gt;One measure of how much volatility there is compared to expected return is the signal-to-noise ratio. It’s computed as&lt;/p&gt;
    &lt;p&gt;\[10 \log_{10}\left(\frac{\mu\sqrt{t}}{\sigma}\right)\]&lt;/p&gt;
    &lt;p&gt;and for the Dow Jones question, we were looking at a signal-to-noise ratio of −8 dB. That is already a little too high to safely assume it behaves like an unbiased random walk, but for a low-stakes prediction contest it works out.&lt;/p&gt;
    &lt;p&gt;Using return data for the Nvidia stock from 2025, the signal-to-noise ratio is −1.4 dB. Although the movement in this period is still dominated by noise4 Evidenced by negative signal-to-noise ratio., the expected return is still going to matter, and we shouldn’t assume it behaves like an unbiased random walk.&lt;/p&gt;
    &lt;head rend="h1"&gt;Volatility is not constant over a year&lt;/head&gt;
    &lt;p&gt;Even if we ignore the problematic signal-to-noise ratio and pretend the Nvidia stock price is an unbiased random walk, we’ll run into what’s perhaps the bigger problem: the theory of unbiased random walks assumes constant volatility throughout the year. The computer will happily tell us there is a near-zero percent chance of the stock closing under $100 at any point next year.&lt;/p&gt;
    &lt;p&gt;The computer does grant a 23 % probability that the stock price drops to $130, and that might get us thinking. If we assume the stock price has dropped to $130, that tells us something about the market environment we’re in. Nvidia might drop to $130 due to random chance alone, but it’s more likely to do that if we’re in a market with a higher volatility than we assumed based on the 2025 returns. In such a market, a further drop to $100 isn’t so strange anymore.&lt;/p&gt;
    &lt;p&gt;Our simple random walk model does not account for this. When forecasting stock prices over longer periods, we need a better understanding of how the volatility might change in the future.&lt;/p&gt;
    &lt;head rend="h1"&gt;Options traders estimate volatility for breakfast&lt;/head&gt;
    &lt;p&gt;Fortunately for us, there are people who continuously estimate the volatility of specific stock prices. They even do it in relation to barriers like the $100 price we’re interested in. They’re options traders!&lt;/p&gt;
    &lt;p&gt;The expected volatility of the stock price is one of the variables that go into pricing an option. This means we can look up a December 2026 Nvidia call option with a strike price of $100 in the market, see what it costs, and then reverse the option pricing process to get an implied volatility out.&lt;/p&gt;
    &lt;p&gt;To do this, we first need to learn how to price an option, and to do that, we need to know what an option is.&lt;/p&gt;
    &lt;p&gt;In this article, we’re going to focus on call options because they are more thickly traded. Assume we have an un-expired Nvidia call option with a strike price of $100. We can then exercise it, which means we trade in the option plus the strike price for one share in the underlying Nvidia stock. If we did that today, we would earn $84, because we lose the $100, but the share in Nvidia we get in exchange is worth $184.&lt;/p&gt;
    &lt;p&gt;We don’t have to exercise the option, though. If the price of Nvidia goes up tomorrow, we would earn more from exercising the option tomorrow. We can delay exercising it right up until it expires, when it becomes invalid.&lt;/p&gt;
    &lt;p&gt;If we were able to buy the $100 option for less than $84, we would get free profit. The chart above tells us, however, that the $100 option costs $92.90, meaning the market expects there to be a better opportunity for exercising that option before it expires.&lt;/p&gt;
    &lt;head rend="h1"&gt;The binomial asset price model&lt;/head&gt;
    &lt;p&gt;To keep things computationally simple, we are going to use a binomial model for the price of the underlying Nvidia stock. We don’t know the daily volatility, so we’ll keep that as a variable we call \(\sigma\). We will pretend that each day, the Nvidia stock price can either grow with a factor of \(e^\sigma\) or shrink with a factor of \(e^{-\sigma}\).5 This is a geometric binomial walk. We could transform everything in the reasoning below with the logarithm and get an additive walk in log-returns.&lt;/p&gt;
    &lt;p&gt;Thus, on day zero, the Nvidia stock trades for $184. On day one, it can take one of two values:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(184e^\sigma\) because it went up, or&lt;/item&gt;
      &lt;item&gt;\(184e^{-\sigma}\) because it went down.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On day two, it can have one of three values:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(184e^{2\sigma}\) (went up both in the first and second day),&lt;/item&gt;
      &lt;item&gt;\(184e^{\sigma - \sigma} = 184\) (went up and then down, or vice versa), or&lt;/item&gt;
      &lt;item&gt;\(184e^{-2\sigma}\) (went down both days).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If it’s easier, we can visualise this as a tree. Each day, the stock price branches into two possibilities, one where it rises, and one where it goes down. In the graph below, each column of bubbles represents the closing value for a day.&lt;/p&gt;
    &lt;p&gt;This looks like a very crude approximation, but it actually works if the time steps are fine-grained enough. The uncertainties involved in some of the other estimations we’ll do dwarf the inaccuracies introduced by this model.6 Even for fairly serious use, I wouldn’t be unhappy with daily time steps when the analysis goes a year out.&lt;/p&gt;
    &lt;p&gt;It is important to keep in mind that the specific numbers in the bubbles depend on which number we selected for the daily volatility \(\sigma\). Any conclusion we draw from this tree is a function of the specific \(\sigma\) chosen to construct the tree.&lt;/p&gt;
    &lt;p&gt;When we have chosen an initial \(\sigma\) and constructed this tree, we can price an option using it. Maybe we have a call option expiring on day three, with a strike price of $180. On day four, the last day, the option has expired, so it is worth nothing. We’ll put that into the tree.&lt;/p&gt;
    &lt;p&gt;We have already seen what the value of the option is on the day it expires: it’s what we would profit from exercising it. If the stock is valued at $191, the option is worth $11, the difference between the stock value and the strike price. On the other hand, if the stock is valued at $177, it is worth less than the strike price of the option, so we will not exercise the option, instead letting it expire.&lt;/p&gt;
    &lt;p&gt;The day before the expiration day is when we have the first interesting choice to make. We can still exercise the option, with the exercise value of the option calculated the same way.&lt;/p&gt;
    &lt;p&gt;Or we could hold on to the option. If we hold on to the option for a day, the value of the option will either go up or down, depending on the value of the underlying stock price. We will compute a weighted average of these movement possibilities as&lt;/p&gt;
    &lt;p&gt;\[\tilde{p} V_u + (1 - \tilde{p}) V_d\]&lt;/p&gt;
    &lt;p&gt;where \(V_u\) and \(V_d\) are the values the option will have on the next day when the underlying moves up or down in the tree, respectively. Then we’ll discount this with a safe interest rate to account for the fact that by holding the option, we are foregoing cash that could otherwise be used to invest elsewhere. The general equation for the hold value of the option at any time before the expiration day is&lt;/p&gt;
    &lt;p&gt;\[e^{-r} \left[ \tilde{p} \; V_u + (1 - \tilde{p}) V_d \right].\]&lt;/p&gt;
    &lt;p&gt;Let’s look specifically at the node where the stock value is $199. We’ll assume a safe interest rate of 3.6 % annually, which translates to 0.01 % daily.7 In the texts I’ve read, 4 % is commonly assumed, but more accurate estimations can be derived from us Treasury bills and similar extremely low-risk interest rates. The value of holding on to the option is, then&lt;/p&gt;
    &lt;p&gt;\[0.9999 \left[ \tilde{p} \; 26.97 + (1 - \tilde{p}) 11.36 \right]\]&lt;/p&gt;
    &lt;p&gt;and now we only need to know what \(\tilde{p}\) is. That variable looks and behaves a lot like a probability, but it’s not. There’s an arbitrage argument that fixes the value of \(\tilde{p}\) to&lt;/p&gt;
    &lt;p&gt;\[\tilde{p} = \frac{e^r - e^{-\sigma}}{e^\sigma - e^{-\sigma}}\]&lt;/p&gt;
    &lt;p&gt;where \(\sigma\) is the same time step volatility we assumed when creating the tree – in our case, 4 %. This makes \(\tilde{p} = 0.491\), and with this, we can compute the hold value of the option when the underlying is $199:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hold value: $19.03&lt;/item&gt;
      &lt;item&gt;Exercise value: $19.01&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The value of the option at any point in time is the maximum of the hold value and the exercise value. So we replace the stock value of $199 in the tree with the option value of $19.03. We perform the same calculation for the other nodes in day two.&lt;/p&gt;
    &lt;p&gt;and then we do the same for the day before that, then before that, etc., until we get to day zero.&lt;/p&gt;
    &lt;p&gt;We learn that if someone asks us on day zero to buy a call option with a strike price of $180 and expiry three days later, when the underlying stock currently trades for $184, and has an expected daily volatility of 0.04, then we should be willing to pay $7.38 for that option.&lt;/p&gt;
    &lt;p&gt;What’s weird is this number has nothing to do with the probability we are assigning to up or down movements. Go through the calculations again. We never involved any probability in the calculation of the price. Although I won’t go through the argument – see Shreve’s excellent Stochastic Calculus for Finance8 Stochastic Calculus for Finance I: The Binomial Asset Pricing Model; Shreve; Springer; 2005. for that – this price for the option is based on what it would cost to hedge the option with a portfolio of safe investments, borrowing, and long or short positions in the underlying stock.&lt;/p&gt;
    &lt;p&gt;Even without going through the detailed theory, we can fairly quickly verify that this is indeed how options are priced. Above, we made educated guesses as to the safe interest rate, a reasonable volatility, etc. We calculated with a spot price of $184, a strike price of $180, and expiry three days out. We got an option price of $7.38.&lt;/p&gt;
    &lt;p&gt;At the time of writing, the Nvidia stock trades at $184.94. It has options that expire in four days. The ones with a strike price of $180 currently sell for $6.20. That’s incredibly close, given the rough estimations and the slight mismatch in duration.9 The main inaccuracy comes from the volatility we used to construct the tree. The actual volatility of the Nvidia stock on such short time periods and small differences in price is lower.&lt;/p&gt;
    &lt;head rend="h1"&gt;Backing the implied volatility out of the option price&lt;/head&gt;
    &lt;p&gt;When we constructed the tree above, we assumed a daily volatility of 4 %. If we write code that takes the volatility as a parameter and computes the option price for that volatility, we can try various volatilities until we find one where our price matches the market price for that option.&lt;/p&gt;
    &lt;p&gt;We write the following code to perform the price calculation faster than we can do it manually.10 Note that we don’t actually construct the full binomial tree. We can compute the value of the underlying stock at any node given only its coordinates, and the option value only depends on the next time step in a way that lets us optimise the computation with dynamic programming.&lt;/p&gt;
    &lt;quote&gt;import Control.Monad.ST import Data.Foldable (forM_) import qualified Data.Vector as Vector import qualified Data.Vector.Mutable as Vector -- | Given the current price of the underlying, -- and the duration (in days) and strike price -- of the option, take a daily volatility and -- compute the option value. option_value :: Double -&amp;gt; Int -&amp;gt; Double -&amp;gt; Double -&amp;gt; Double option_value spot duration strike sigma = let -- Shorthand: u = e^σ u = exp sigma -- Shorthand: d = e^(−σ) d = exp (negate sigma) -- Assuming yearly safe interest of 4 % -- this is the weighting factor tilde-p. p = (exp 0.00016 - d) / (u - d) -- The value of the underlying stock at -- day t, node i. s t i = spot * u^i * d^(t-i) -- The exercise value of the option depends -- only on the strike and the price of the -- underlying stock. v_e t i = max 0 (s t i - strike) -- The hold value of the option depends on -- the two possible future values of the -- option v_d and v_u. v_h v_d v_u = exp (negate 0.00016) * (p * v_u + (1-p) * v_d) in runST $ do -- Create a mutable vector. nodes &amp;lt;- Vector.new (duration + 1) -- Fill the vector with the exercise value -- on the expiration day. forM_ [0 .. duration] $ \i -&amp;gt; Vector.write nodes i (v_e duration i) -- Walk the tree backwards from the day -- before expiration. forM_ (reverse [0 .. duration - 1]) $ \t -&amp;gt; do -- For each node, calculate hold value -- based on option value in the next -- time step (which was just calculated) -- in the iteration before. forM_ [0 .. t] $ \i -&amp;gt; do v_d &amp;lt;- Vector.read nodes i v_u &amp;lt;- Vector.read nodes (i+1) -- Set the value of the option to the -- highest of the exercise and hold -- values. Vector.write nodes i $ max (v_e t i) (v_h v_d v_u) -- Get the value of the option at day 0. Vector.read nodes 0 main :: IO () main = print (option_value 184.94 31 170 0.04)&lt;/quote&gt;
    &lt;p&gt;Here we are valuing a 31-day call option for Nvidia, with a strike price of $170. The market price is $18.68, but our code returns $24.74. This means our guess for the implied daily volatility of 4 % is too high. If we try various values for the volatility, we’ll eventually find that 2.2 % leads to an option price of $18.53, which is fairly close to the market price. This daily volatility corresponds to a yearly volatility of 35 %. If we look up other people’s calculations for the 30-day at-the-money implied volatility of the Nvidia stock, we’ll find they’re at something like 36 %. Definitely close enough.&lt;/p&gt;
    &lt;p&gt;For answering the question about Nvidia dropping below $100, we don’t want the 30-day at-the-money volatility, though, but the 340-day far out-of-the-money volatility.&lt;/p&gt;
    &lt;p&gt;The 340-day $100 strike call options sell for $92.90 in the market. To get that price we need to feed our model a daily volatility of 3.1 %. In other words, the 340-day $100 strike call options imply a daily volatility of 3.1 %. Because options so far out of the money are more thinly traded, we might want to confirm this volatility by computing it for other options with nearby strike prices.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Strike price&lt;/cell&gt;
        &lt;cell role="head"&gt;Implied daily volatility&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;$80&lt;/cell&gt;
        &lt;cell&gt;3.5 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;$90&lt;/cell&gt;
        &lt;cell&gt;3.2 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;$100&lt;/cell&gt;
        &lt;cell&gt;3.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;$110&lt;/cell&gt;
        &lt;cell&gt;3.1 %&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;$120&lt;/cell&gt;
        &lt;cell&gt;3.0 %&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We expect the implied volatility to go up as the strike price is further out of the money, which it does. It seems that 3.1 % is a reasonable implied volatility for such large movements.&lt;/p&gt;
    &lt;head rend="h1"&gt;Running the model forward to get a probability&lt;/head&gt;
    &lt;p&gt;The forecasting question asks whether the Nvidia stock price will close below $100 on any day in 2026. This amounts to asking “which paths in the binomial tree constructed from a $σ$=3.1 % go through nodes that are smaller than $100”? We can probably answer this analytically, but easier is to run the binomial model forward: start at the root of the binomial tree, flip a coin with probability \(\tilde{p}\), then move up or down according to it. Continue until either the $100 barrier is crossed, or the end of the 340-day period is reached. Count the number of barrier crossings.&lt;/p&gt;
    &lt;p&gt; Here’s the crude code that does that.11 The &lt;code&gt;evaluate&lt;/code&gt; function seems an awful
lot like a sort of fold. We could probably rewrite it as a fold over chunks.
&lt;/p&gt;
    &lt;quote&gt;-- | Use the infinite stream of uniformly random -- numbers to compute the option-implied chance -- of the spot price going below barrier within -- duration days, with implied volatility sigma. below_barrier :: [Double] -&amp;gt; Double -&amp;gt; Int -&amp;gt; Double -&amp;gt; Double -&amp;gt; Double below_barrier numbers spot duration barrier sigma = let iterations = 5000 u = exp sigma d = exp (negate sigma) p = (exp 0.00016 - d) / (u - d) -- Convert random numbers to returns. returns = numbers &amp;lt;&amp;amp;&amp;gt; \x -&amp;gt; if x &amp;lt;= p then u else d -- Use the first duration entries of rrs to -- simulate price movements. Record if it -- passed the barrier, then continue -- with another iteration. evaluate rrs belows i = let -- Get duration returns from rrs, save -- the rest for next iteration. (rs, ts) = splitAt duration rrs -- Compute full path of stock price. values = scanl (*) spot rs -- Check if any below the barrier. result = if any (&amp;lt;= barrier) values then belows + 1 else belows in -- If we've run through all iterations -- return the result. Otherwise iterate -- once more. if i == 0 then result/iterations else evaluate ts result (i-1) in evaluate returns 0 (iterations-1)&lt;/quote&gt;
    &lt;p&gt;We’ll call this in the main function with the implied volatility we figured out from the options prices.&lt;/p&gt;
    &lt;quote&gt;main :: IO () main = do print (option_value 184.94 340 100 0.031) numbers &amp;lt;- Random.randoms &amp;lt;$&amp;gt; Random.newStdGen print (below_barrier numbers 184.94 340 100 0.031)&lt;/quote&gt;
    &lt;p&gt;Doing this, we’ll find that the probability of crossing the barrier of $100 is somewhere in the region of 24 %. That sounds remarkably high!&lt;/p&gt;
    &lt;p&gt;The reason it’s so high is we’ve pretended that \(\tilde{p}\) is a probability, when it’s not. The value of \(\tilde{p}\) is in fact inspired by the real probability, but it is computed as if the Kelly criterion didn’t exist, which means compared to the real probability, \(\tilde{p}\) is inflated for bad outcomes.12 I have a fuzzy image in my head of how this happens, but it’s not clear enough to explain to someone else. Other people sometimes say \(\tilde{p}\) is a risk neutral probability, i.e. what would be the probability of the outcome if we pretend everyone in the market is risk neutral rather than risk averse. Of course, all of this risk aversion stuff is just the applied Kelly criterion, so I think this whole discussion of risk neutrality is a distraction rather than intuition.&lt;/p&gt;
    &lt;head rend="h1"&gt;Correcting the fake probability into a real one&lt;/head&gt;
    &lt;p&gt;The Bank of England has published a method13 Working Paper No. 455: Estimating probability distributions of future asset prices: empirical transformations from option-implied risk-neutral to real-world density functions; Vincent-Humphreys &amp;amp; Noss; 2012. to convert option-implied probabilities into real ones. For one equity-like index, they use this calibration curve.&lt;/p&gt;
    &lt;p&gt;This is the cumulative distribution function of the beta distribution. The effect of this particular calibration is to pull down the estimated probability of losses (which is higher than realistic in the option-implied probabilities). The beta distribution is difficult to implement in code, but we can approximate this one fairly well with a third-degree polynomial.&lt;/p&gt;
    &lt;quote&gt;adjust_probability :: Double -&amp;gt; Double adjust_probability p = -- This approximates a regularised incomplete -- beta function with parameters (1.56, 1.31). 0.284 * p + 1.625 * p^2 - 0.909 * p^3&lt;/quote&gt;
    &lt;p&gt;Since we are just reusing the parameters the Bank of England fit to an equity index, we are already running this calibration with significant uncertainty, so we might as well approximate the function too.&lt;/p&gt;
    &lt;p&gt;If we plug the probability through this approximation, we get a probability of 14 %. This is probably still too high (I suspect if we calibrated the beta function against past returns of the Nvidia stock specifically, the calibration curve would end up more aggressive), but it is a much better forecast than zero percent. In the end, maybe the truth is somewhere in between: let’s do 10 %.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46693205</guid><pubDate>Tue, 20 Jan 2026 15:56:07 +0000</pubDate></item><item><title>De-dollarization: Is the US dollar losing its dominance? (2025)</title><link>https://www.jpmorgan.com/insights/global-research/currencies/de-dollarization</link><description>&lt;doc fingerprint="7b5890f50ae159a0"&gt;
  &lt;main&gt;
    &lt;p&gt;The U.S. dollar is the world’s primary reserve currency, and it is also the most widely used currency for trade and other international transactions. However, its hegemony has come into question in recent times due to geopolitical and geostrategic shifts. As a result, de-dollarization has increasingly become a substantive topic of discussion among investors, corporates and market participants more broadly.&lt;/p&gt;
    &lt;p&gt;What are the potential implications of de-dollarization, and how is it playing out in global markets and trade?&lt;/p&gt;
    &lt;p&gt;In short, de-dollarization entails a significant reduction in the use of dollars in world trade and financial transactions, decreasing national, institutional and corporate demand for the greenback.&lt;/p&gt;
    &lt;p&gt;“The concept of de-dollarization relates to changes in the structural demand for the dollar that would relate to its status as a reserve currency. This encompasses areas that relate to the longer-term use of the dollar, such as transactional dominance in FX volumes or commodities trade, denomination of liabilities and share in central bank FX reserves,” said Luis Oganes, head of Global Macro Research at J.P. Morgan.&lt;/p&gt;
    &lt;p&gt;Importantly, this structural shift is distinct from the cyclical demand for the greenback, which is shorter term and has in recent times been driven by U.S. exceptionalism, including the relative outperformance of the U.S. equity market. “The world has become long on the dollar in recent years, but as U.S. exceptionalism erodes, it should be reasonable to expect the overhang in USD longs to diminish as well,” Oganes said.&lt;/p&gt;
    &lt;p&gt;There are two main factors that could erode the dollar’s status. The first includes adverse events that undermine the perceived safety and stability of the greenback — and the U.S.’s overall standing as the world’s leading economic, political and military power. For instance, increased polarization in the U.S. could jeopardize its governance, which underpins its role as a global safe haven. Ongoing U.S. tariff policy could also cause investors to lose confidence in American assets.&lt;/p&gt;
    &lt;p&gt;The second factor involves positive developments outside the U.S. that boost the credibility of alternative currencies — economic and political reforms in China, for example. “A candidate reserve currency must be perceived as safe and stable and must provide a source of liquidity that is sufficient to meet growing global demand,” said Alexander Wise, who covers Long-Term Strategy at J.P. Morgan.&lt;/p&gt;
    &lt;p&gt;Fundamentally, de-dollarization could shift the balance of power among countries, and this could, in turn, reshape the global economy and markets. The impact would be most acutely felt in the U.S., where de-dollarization would likely lead to a broad depreciation and underperformance of U.S. financial assets versus the rest of the world.&lt;/p&gt;
    &lt;p&gt;“For U.S. equities, outright and relative returns would be negatively impacted by divestment or reallocation away from U.S. markets and a severe loss in confidence. There would also likely be upward pressure on real yields due to the partial divestment of U.S. fixed income by investors, or the diversification or reduction of international reserve allocations,” Wise said.&lt;/p&gt;
    &lt;p&gt;The U.S.’s share in global exports and output has declined over the past three decades, while China’s has increased substantially. Nonetheless, the transactional dominance of the dollar is still evident in FX volumes, trade invoicing, cross-border liabilities denomination and foreign currency debt issuance.&lt;/p&gt;
    &lt;p&gt;In 2022, the greenback dominated 88% of traded FX volumes — close to record highs — while the Chinese yuan (CNY) made up just 7%, according to data from the Bank for International Settlements (BIS).&lt;/p&gt;
    &lt;p&gt;Likewise, there is little sign of USD erosion in trade invoicing. “The share of USD and EUR has held steady over the past two decades at around 40–50%. While the share of CNY is increasing in China’s cross-border transactions as it moves to conduct bilateral trade in its own currency terms, it is still low from a global standpoint,” Oganes observed.&lt;/p&gt;
    &lt;p&gt;The dollar has also stoutly maintained its superiority when it comes to cross-border liabilities, where its market share stands at 48%. And in foreign currency debt issuance, its share has remained constant since the global financial crisis, at around 70%. “The daylight from the euro, whose share is at 20%, is even greater on this front,” Oganes added.&lt;/p&gt;
    &lt;p&gt;On the other hand, de-dollarization is unfolding in central bank FX reserves, where the share of USD has slid to a two-decade low in tandem with its macro footprint. “However, the dollar share in FX reserves was lower in the early 1990s, so the recent decline to just under 60% is not completely out of the norm,” said Meera Chandan, co-head of Global FX Strategy at J.P. Morgan.&lt;/p&gt;
    &lt;p&gt;While much of the reallocation of FX reserves has gone to CNY and other currencies, USD and EUR still dominate levels. “The CNY footprint is still very small, even if growing, and its push for bilateral invoicing is likely to keep this trend on the upswing,” Chandan noted.&lt;/p&gt;
    &lt;p&gt;The main de-dollarization trend in FX reserves, however, pertains to the growing demand for gold. Seen as an alternative to heavily indebted fiat currencies, the share of gold in FX reserves has increased, led by emerging market (EM) central banks — China, Russia and Türkiye have been the largest buyers in the last decade. Overall, while the share of gold in FX reserves in EM is still low at 9%, the figure is more than double the 4% seen a decade ago; the corresponding share for DM countries is much larger at 20%. This increased demand has in turn partly driven the current bull market in gold, with prices forecast to climb toward $4,000/oz by mid-2026.&lt;/p&gt;
    &lt;p&gt;The dollar’s share in FX reserves has declined in tandem with its macro footprint&lt;/p&gt;
    &lt;p&gt;USD share of FX reserves (lhs; unadjusted, %) vs. an average of the z-scores of U.S. share of global GDP and exports (rhs; 1960–2023)&lt;/p&gt;
    &lt;p&gt;In a sign of de-dollarization in bond markets, the share of foreign ownership in the U.S. Treasury market has been declining over the last 15 years.&lt;/p&gt;
    &lt;p&gt;USD assets, principally liquid Treasuries, account for the majority of allocated FX reserves. However, demand for Treasuries has stagnated among foreign official institutions, as the growth of FX reserves has slowed and the USD’s share of reserves has dropped from its recent peak. Similarly, the backdrop for foreign private demand has weakened — as yields have risen across DM government bond markets, Treasuries have become relatively less attractive. While foreign investors remain the largest constituent within the Treasury market, their share of ownership has fallen to 30% as of early 2025 — down from a peak of above 50% during the GFC.&lt;/p&gt;
    &lt;p&gt;“Although foreign demand has not kept pace with the growth of the Treasury market for more than a decade, we must consider what more aggressive action could mean. Japan is the largest foreign creditor and alone holds more than $1.1 trillion Treasuries, or nearly 4% of the market. Accordingly, any significant foreign selling would be impactful, driving yields higher,” said Jay Barry, head of Global Rates Strategy at J.P. Morgan.&lt;/p&gt;
    &lt;p&gt;According to estimates by J.P. Morgan Research, each 1-percentage-point decline in foreign holdings relative to GDP (or approximately $300 billion of Treasuries) would result in yields rising by more than 33 basis points (bp). “While this is not our base case, it nonetheless underscores the impact of foreign investment on risk-free rates,” Barry added.&lt;/p&gt;
    &lt;p&gt;“Today, a large and growing proportion of energy is being priced in non-dollar-denominated contracts.”&lt;/p&gt;
    &lt;p&gt;Natasha Kaneva&lt;/p&gt;
    &lt;p&gt;Head of Global Commodities Strategy, J.P. Morgan&lt;/p&gt;
    &lt;p&gt;De-dollarization is most visible in commodity markets, where the greenback’s influence on pricing has diminished. “Today, a large and growing proportion of energy is being priced in non-dollar-denominated contracts,” said Natasha Kaneva, head of Global Commodities Strategy at J.P. Morgan.&lt;/p&gt;
    &lt;p&gt;For example, due to Western sanctions, Russian oil products exported eastward and southward are being sold in the local currencies of buyers, or in the currencies of countries Russia perceives as friendly. Among buyers, India, China and Turkey are all either using or seeking alternatives to the dollar. Saudi Arabia is also considering adding yuan-denominated futures contracts in the pricing model of Saudi Arabian oil, though progress has been slow.&lt;/p&gt;
    &lt;p&gt;Notably, cross-border trade settlement in yuan is gaining ground outside of oil too. Some Indian companies have started paying for Russian coal imports in yuan, even without the involvement of Chinese intermediaries. Bangladesh also recently decided to pay Russia for its 1.4 GW nuclear power plant in yuan.&lt;/p&gt;
    &lt;p&gt;“The de-dollarization trend in the commodity trade is a boon for countries like India, China, Brazil, Thailand and Indonesia, which can now not only buy oil at a discount, but also pay for it with their own local currencies,” Kaneva noted. “This reduces the need for precautionary reserves of U.S. dollars, U.S. Treasuries and oil, which might in turn free up capital to be deployed in growth-boosting domestic projects.”&lt;/p&gt;
    &lt;p&gt;At the other end of the spectrum, deposit dollarization — where a significant portion of a country’s bank deposits are denominated in the U.S. dollar instead of the local currency — is still evident in many EM countries. “The tendency of EM residents to dollarize in times of stress appears to be correlated across markets,” said Jonny Goulden, head of EM Fixed Income Strategy at J.P. Morgan.&lt;/p&gt;
    &lt;p&gt;According to J.P. Morgan Research, dollar deposits have grown mostly uninterrupted over the last decade in EM, reaching around $830 billion for a sample set of 18 EM countries (excluding China, Singapore and Hong Kong). “While there are large regional divergences in deposit dollarization across EM, all regions are more dollarized now than they were a decade ago,” Goulden noted. Latin America is the most dollarized region, with an aggregate dollarization rate of 19.1%. EMEA’s rate stands at 15.2%, while Asia (excluding China, Singapore and Hong Kong) has the lowest rate at 9.7%.&lt;/p&gt;
    &lt;p&gt;China is the exception, as its dollarization rate has been persistently falling since 2017. “This is not surprising, as this was around the time when U.S.–China relations began shifting into their current state, marked by the trade war and growing diplomatic, security and geopolitical tensions,” Goulden said. “This suggests that China, alongside progress on de-dollarizing its own cross-border transactions, has effectively been de-dollarizing the deposits of Chinese residents, adding another dimension to its efforts to separate from U.S. dominance.”&lt;/p&gt;
    &lt;p&gt;Get more insights straight to your inbox with J.P. Morgan’s In Context newsletter.&lt;/p&gt;
    &lt;p&gt;Related insights&lt;/p&gt;
    &lt;p&gt;Global Research&lt;/p&gt;
    &lt;p&gt;US tariffs: What’s the impact on global trade and the economy?&lt;/p&gt;
    &lt;p&gt;January 16, 2026&lt;/p&gt;
    &lt;p&gt;J.P. Morgan Global Research brings you the latest updates and analysis of President Trump’s tariff proposals and their economic impact.&lt;/p&gt;
    &lt;p&gt;Global Research&lt;/p&gt;
    &lt;p&gt;Is US exceptionalism here to stay?&lt;/p&gt;
    &lt;p&gt;February 28, 2025&lt;/p&gt;
    &lt;p&gt;Discover the factors contributing to U.S. exceptionalism and how this is playing out across markets. Could recent developments including tariffs and the rise of DeepSeek undermine American outperformance?&lt;/p&gt;
    &lt;p&gt;Global Research&lt;/p&gt;
    &lt;p&gt;Global Research&lt;/p&gt;
    &lt;p&gt;Leveraging cutting-edge technology and innovative tools to bring clients industry-leading analysis and investment advice.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46693346</guid><pubDate>Tue, 20 Jan 2026 16:03:21 +0000</pubDate></item><item><title>The Unix Pipe Card Game</title><link>https://punkx.org/unix-pipe-game/</link><description>&lt;doc fingerprint="d78dc44ef290dfb"&gt;
  &lt;main&gt;&lt;code&gt;cat, grep, tail, head, wc, sort, uniq&lt;/code&gt;. The parent should show also show those commands in action the computer as well, if you do not have any UNIX system you can use jslinux in your browser.

    &lt;quote&gt;RULES: &amp;gt; 0. The youngest player chooses one of two formats for the game: * Whoever has the smallest pipe chain to complete the task wins the round. * Whoever has the largest pipe chain to complete the task wins the round. &amp;gt; 1. The youngest player picks a task from the tasks card. You can not pick the same task twice. &amp;gt; 2. Shuffle the cards. &amp;gt; 3. Put the cards face down on the table. &amp;gt; 4. Going clockwise each player picks the top card from the deck and tries to complete the task. &amp;gt; 5. The first player who completes the task gets a point. &amp;gt; 6. IF there are no more tasks, GOTO 8 &amp;gt; 7. GOTO 1. &amp;gt; 8. GAME OVER. INSERT COIN. GOTO 8 TASKS * print the second line * print the second to last line * print the 7th line * print the most common line * print the least common line * count how many lines have "rises" * print the first line that has W in it * count the lines that have "in" in them * show two random lines * count the words on the last two lines * print the 7th and 8th line * count the lines with ! * count the lines without ! * make a command chain that does not print anythingThis is how the card decks look: If you are a parent teaching your kid, and is exploring more tools to help you, I made few other card games:&lt;/quote&gt;&lt;p&gt;Programming Time, which is a game to teach python and some more fundamental algorithms, from hash tables to RSA&lt;/p&gt;&lt;p&gt;The C Pointer Game - Pointers, Arrays and Strings, a game to teach kids to look at the computer memory and understand references and values&lt;/p&gt;&lt;p&gt;4917, a game to teach kids machine code and how the CPU works with memory and registers&lt;/p&gt;&lt;p&gt; The Unix Pipes Game - Process Substitution, an expansion of the Unix Pipes Game to teach process substitution and also: &lt;code&gt;paste, tr, cut, bc&lt;/code&gt;
      
    &lt;/p&gt;&lt;p&gt;RunLength Encoding for Kids, small cards "game" to explain runlength encoding&lt;/p&gt;&lt;p&gt;PUNK0 - The Function Composition Card Game, use cards to manipulate a list and use its values to win the game&lt;/p&gt;&lt;p&gt;PROJEKT: OVERFLOW, RISCV assembler boardgame&lt;/p&gt;&lt;p&gt;Programming for kids, a log of my journey of teaching my daughter how to code&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46694124</guid><pubDate>Tue, 20 Jan 2026 16:48:59 +0000</pubDate></item><item><title>The 26,000-Year Astronomical Monument Hidden in Plain Sight</title><link>https://longnow.org/ideas/the-26000-year-astronomical-monument-hidden-in-plain-sight/</link><description>&lt;doc fingerprint="3f33121fe907aaaa"&gt;
  &lt;main&gt;
    &lt;p&gt;The 26,000-Year Astronomical Monument Hidden in Plain Sight&lt;/p&gt;
    &lt;p&gt;The western flank of the Hoover Dam holds a celestial map that marks the time of the dam’s creation based on the 25,772-year axial precession of the earth.&lt;/p&gt;
    &lt;p&gt;byAlexander Rose&lt;/p&gt;
    &lt;p&gt;Jan 29, 02019&lt;/p&gt;
    &lt;p&gt;On the western flank of the Hoover Dam stands a little-understood monument, commissioned by the US Bureau of Reclamation when construction of the dam began in 01931. The most noticeable parts of this corner of the dam, now known as Monument Plaza, are the massive winged bronze sculptures and central flagpole which are often photographed by visitors. The most amazing feature of this plaza, however, is under their feet as they take those pictures.&lt;/p&gt;
    &lt;p&gt;The plaza’s terrazzo floor is actually a celestial map that marks the time of the dam’s creation based on the 25,772-year axial precession of the earth.&lt;/p&gt;
    &lt;p&gt;I was particularly interested in this monument because this axial precession is also the slowest cycle that we track in Long Now’s 10,000 Year Clock. Strangely, little to no documentation of this installation seemed to be available, except for a few vacation pictures on Flickr. So the last time I was in Las Vegas, I made a special trip out to Hoover Dam to see if I could learn more about this obscure 26,000-year monument.&lt;/p&gt;
    &lt;p&gt;I parked my rental car on the Nevada side of the dam on a day pushing 100 degrees. I quickly found Monument Plaza just opposite the visitor center where tours of the dam are offered. While the plaza is easy to find, it stands apart from all the main tours and stories about the dam. With the exception of the writing in the plaza floor itself, the only information I could find came from a speaker running on loop, broadcasting a basic description of the monument while visitors walked around the area. When I asked my tour guide about it, he suggested that there may be some historical documentation and directed me to Emme Woodward, the dam’s historian.&lt;/p&gt;
    &lt;p&gt;I was able to get in touch with her after returning home. As she sent me a few items, I began to see why the Bureau of Reclamation doesn’t explain very much about the monument’s background. The first thing she sent me was a description of the plaza by Oskar J. W. Hansen, the artist himself, which I thought would tell me everything I wanted to know. While parts of it were helpful, the artist’s statement of intention was also highly convoluted and opaque. An excerpt:&lt;/p&gt;
    &lt;p&gt;These [human] postures may be matched to their corresponding reflexes in terms of angle and degree much as one would join cams in a worm-gear drive. There is an angle for doubt, for sorrow, for hate, for joy, for contemplation, and for devotion. There are as many others as there are fleeting emotions within the brain of each individual who inhabits the Earth. Who knows not all these postures of the mind if he would but stop to think of them as usable factors for determining proclivities of character? It is a knowledge bred down to us through the past experience of the whole race of men.&lt;/p&gt;
    &lt;p&gt;It is pretty hard to imagine the US Bureau of Reclamation using this type of write-up to interpret the monument… and they don’t. And so there it stands, a 26,000-year clock of sorts, for all the world to see, and yet still mired in obscurity.&lt;/p&gt;
    &lt;p&gt;While I may never totally understand the inner motivations of the monument’s designer, I did want to understand it on a technical level. How did Hansen create a celestial clock face frozen in time that we can interpret and understand as the date of the dam’s completion? The earth’s axial precession is a rather obscure piece of astronomy, and our understanding of it through history has been spotty at best. That this major engineering feat was celebrated through this monument to the axial precession still held great interest to me, and I wanted to understand it better.&lt;/p&gt;
    &lt;p&gt;I pressed for more documentation, and the historian sent me instructions for using the Bureau of Reclamation’s image archive site as well as some keywords to search for. The black and white images you see here come from this resource. Using the convoluted web site was a challenge, and at first I had difficulty finding any photos of the plaza before or during its construction. As I discovered, the problem was that I was searching with the term “Monument Plaza,” a name only given to it after its completion in 01936. In order to find images during its construction, I had to search for “Safety Island,” so named because at the time of the dam’s construction, it was an island in the road where workers could stand behind a berm to protect themselves from the never-ending onslaught of cement trucks.&lt;/p&gt;
    &lt;p&gt;I now had some historical text and photos, but I was still missing a complete diagram of the plaza that would allow me to really understand it. I contacted the historian again, and she obtained permission from her superiors to release the actual building plans. I suspect that they generally don’t like to release technical plans of the dam for security reasons, but it seems they deemed my request a low security risk as the monument is not part of the structure of the dam. The historian sent me a tube full of large blueprints and a CD of the same prints already scanned. With this in hand I was finally able to re-construct the technical intent of the plaza and how it works.&lt;/p&gt;
    &lt;p&gt;In order to understand how the plaza marks the date of the dam’s construction in the nearly 26,000-year cycle of the earth’s precession, it is worth explaining what exactly axial precession is. In the simplest terms, it is the earth “wobbling” on its tilted axis like a gyroscope — but very, very slowly. This wobbling effectively moves what we see as the center point that stars appear to revolve around each evening.&lt;/p&gt;
    &lt;p&gt;Presently, this center point lies very close to the conveniently bright star Polaris. The reason we have historically paid so much attention to this celestial center, or North Star, is because it is the star that stays put all through the course of the night. Having this one fixed point in the sky is the foundation of all celestial navigation.&lt;/p&gt;
    &lt;p&gt;But that point near Polaris, which we call the North Star, is actually slowly moving and tracing a circle through the night sky. While Polaris is our North Star, Hansen’s terrazzo floor points out that the North Star of the ancient Egyptians, as they built the great pyramids, was Thuban. And in about 12,000 years, our North Star will be Vega. The workings of this precession are best explained with an animation, as in figure 1. Here you can see how the axis of the earth traces a circle in the sky over the course of 25,772 years.&lt;/p&gt;
    &lt;p&gt;Unfortunately it is a bit difficult to see how this all works in the inlaid floor at Monument Plaza. The view that you really want to have of the plaza is directly from above. You would need a crane to get this view of the real thing, but by using the original technical drawing as an underlay I was able to mark up a diagram which hopefully clarifies it (Fig. 2).&lt;/p&gt;
    &lt;p&gt;In this diagram, you can see that the center of the circle traced by the axial precession is actually the massive flag pole in the center of the plaza. This axial circle is prominently marked around the pole, and the angle of Polaris was depicted as precisely as possible to show where it would have been on the date of the dam’s opening. Hansen used the rest of the plaza floor to show the location of the planets visible that evening, and many of the bright stars that appear in the night sky at that location.&lt;/p&gt;
    &lt;p&gt;By combining planet locations with the angle of precession, we are able to pinpoint the time of the dam’s completion down to within a day. We are now designing a similar system — though with moving parts — in the dials of the 10,000 Year Clock. It is likely that at least major portions of the Hoover Dam will still be in place hundreds of thousands of years from now. Hopefully the Clock will still be ticking and Hansen’s terrazzo floor will still be there, even if it continues to baffle visitors.&lt;/p&gt;
    &lt;p&gt;I would like to thank Emme Woodward of the US Bureau of Reclamation for all her help in finding the original images and plans of Monument Plaza. If you have further interest in reading Hansen’s original writings about the plaza or in seeing the plans, I have uploaded all the scans to the Internet Archive.&lt;/p&gt;
    &lt;p&gt;Join our newsletter for the latest in long-term thinking&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46695628</guid><pubDate>Tue, 20 Jan 2026 18:16:09 +0000</pubDate></item><item><title>Everyone's a Gangster, Till You Get Bundled in G-Suite</title><link>https://twitter.com/keropillay/status/2013454666244481244</link><description>&lt;doc fingerprint="d635e49f34142863"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2026 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46695673</guid><pubDate>Tue, 20 Jan 2026 18:19:12 +0000</pubDate></item><item><title>Google co-founder reveals that "many" of the new hires do not have a degree</title><link>https://www.yahoo.com/news/articles/google-cofounder-reveals-tons-recent-231500103.html</link><description>&lt;doc fingerprint="bcc111491feb6fe8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Google cofounder reveals 'tons' of recent hires do not have degrees as CEOs question university system: 'They just figure things out on their own'&lt;/head&gt;
    &lt;p&gt;Google cofounder Sergey Brin told Stanford students his company now employs many workers who never earned college degrees, Fortune reported.&lt;/p&gt;
    &lt;head rend="h3"&gt;What's happening?&lt;/head&gt;
    &lt;p&gt;During a talk at the Palo Alto, California, university, Brin explained how Google's approach to hiring has moved away from demanding formal degrees.&lt;/p&gt;
    &lt;p&gt;"In as much as we've hired a lot of academic stars, we've hired tons of people who don't have bachelor's degrees," Brin said. "They just figure things out on their own in some weird corner."&lt;/p&gt;
    &lt;p&gt;The numbers back up this change. Data from the Burning Glass Institute shows that in 2017, degree requirements were part of 93% of job postings at Google. By 2022, that figure had dropped to 77%.&lt;/p&gt;
    &lt;p&gt;Other large tech companies have also begun judging candidates by their abilities instead of their diplomas. Microsoft, Apple, and Cisco are among those dropping degree mandates.&lt;/p&gt;
    &lt;p&gt;JPMorgan Chase CEO Jamie Dimon expressed similar views in 2024. "If you look at skills of people, it is amazing how skilled people are in something, but it didn't show up in their résumé," he said.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why is the decline in degree requirements concerning?&lt;/head&gt;
    &lt;p&gt;This shift raises questions about what a college education is worth, especially as artificial intelligence tools got better at performing tasks that once required formal training.&lt;/p&gt;
    &lt;p&gt;If you spent years and tens of thousands of dollars earning a degree, companies' hiring people without that credential might feel frustrating. The change could leave graduates wondering if their time and money were well-spent.&lt;/p&gt;
    &lt;p&gt;AI's popularity also creates environmental pressures. Training and running AI systems requires tons of electricity and water for cooling data centers. As AI becomes more embedded in hiring, operations, and daily business functions, energy consumption grows.&lt;/p&gt;
    &lt;p&gt;This can strain power grids, increase costs for consumers, and contribute to pollution if the electricity comes from sources such as gas or coal. AI may help optimize some clean energy systems, but its resource demands present trade-offs.&lt;/p&gt;
    &lt;head rend="h3"&gt;What's being done about changing hiring practices?&lt;/head&gt;
    &lt;p&gt;The business community is recognizing that degree requirements often screen out talented people unnecessarily.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;How should we protect workers from losing jobs to AI-powered robots?&lt;/p&gt;
          &lt;p&gt;Financial assistance for job training&lt;/p&gt;
          &lt;p&gt;Click your choice to see results and speak your mind.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Michael Bush, CEO of Great Place to Work, told Fortune that more organizations now understand they've been "missing out on great talent by having a degree requirement."&lt;/p&gt;
    &lt;p&gt;If you're entering the job market without a traditional degree, focus on building demonstrable skills through online courses, certifications, or project portfolios that showcase your abilities. Many tech companies now prioritize what you can do over where you studied.&lt;/p&gt;
    &lt;p&gt;Brin encouraged those already in college to study what engages them instead of making decisions based on which jobs AI might take over. He chose computer science because it captivated him, not because he calculated career outcomes.&lt;/p&gt;
    &lt;p&gt;Get TCD's free newsletters for easy tips to save more, waste less, and make smarter choices — and earn up to $5,000 toward clean upgrades in TCD's exclusive Rewards Club.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46695747</guid><pubDate>Tue, 20 Jan 2026 18:24:35 +0000</pubDate></item><item><title>How Hightouch built their long-running agent harness</title><link>https://www.amplifypartners.com/blog-posts/how-hightouch-built-their-long-running-agent-harness</link><description>&lt;doc fingerprint="654e8f913cab844e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How Hightouch built their long-running agent harness&lt;/head&gt;
    &lt;quote&gt;Amplify is an investor in Hightouch, but this isnât a promotional blog post, itâs just about some great engineering.&lt;/quote&gt;
    &lt;p&gt;A lot has been said about the future of AI agents and their impact on our economy. Less has been said about how to actually build them.Â&lt;/p&gt;
    &lt;p&gt;A few months ago Hightouch released their Hightouch Agents product. It is essentially a general purpose marketing agent that can plan campaigns, ask any question or analysis of your data, analyze creative and copy, and automate marketing reporting.Â&lt;/p&gt;
    &lt;p&gt;Though to developers, marketing is often viewed as, well, you knowâ¦ I can tell you as both a developer and marketer that this is an unbelievably diverse set of complex, multi-step, long running tasks that even researchers at frontier labs would shudder at trying to automate.Â&lt;/p&gt;
    &lt;p&gt;The crazier thing is that Hightouch Agents actually work. The agent has complete context (e.g. the full customer data mode) thanks to the core Hightouch product, which helps customers connect and take action on all of their marketing data sources like Facebook Ads, Hubspot, etc. And itâs also pre-built with domain expertise on marketing and can reason about complex concepts like creative fatigue, attribution modeling, and incrementality (and maybe getting to the front page of Hacker News). All in all, itâs one of the most advanced agent systems in production today.Â&lt;/p&gt;
    &lt;p&gt;To build it, Hightouchâs engineering team needed to solve a laundry list of interesting context, workflow, and prompt engineering problems that there is no set of commonly accepted solutions for. Based on extensive interviews with their technical team, this post will go through the major components of their agent harness, in particular the idea of agentic delegation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Separating model planning and execution, and dynamic plan updates&lt;/item&gt;
      &lt;item&gt;Techniques for managing context and long-running tasks&lt;/item&gt;
      &lt;item&gt;Buffering context to files that can be referenced in the future&lt;/item&gt;
      &lt;item&gt;Dynamic subagents that create an isolated execution environment&lt;/item&gt;
      &lt;item&gt;Fanning out to smaller, less expensive models instead of embeddings&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Letâs get into it.Â&lt;/p&gt;
    &lt;head rend="h2"&gt;Challenges with building long running agents&lt;/head&gt;
    &lt;p&gt;So you want to build an agent. Where do you start?&lt;/p&gt;
    &lt;p&gt;At the time of writing there are a few interesting (if young) agent frameworks to choose from. But when Hightouch started building their Agents product there werenât, and the common wisdom (if there was any) for building agents was immature. The most common abstraction was borrowed from data platforms: the Directed Acyclic Graph, or DAG. The DAG chains together a series of steps like prompting a model, chaining the response with some code, fanning out to more LLM calls, etc. It is a deliberately rigid, deterministic way of thinking.&lt;/p&gt;
    &lt;p&gt;This works decently for well defined agent contexts with finite decision trees, like handling customer returns. It is a very poor fit, though, for the kinds of open ended tasks that marketers need help from AI with. Hightouch Agents is built to handle prompts like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Design a strategy to sell my leftover summer inventory.&lt;/item&gt;
      &lt;item&gt;In the last 30 days, what percentage of my new accounts have opened upgraded from free to paid driven by an email?&lt;/item&gt;
      &lt;item&gt;How are my new batch of Facebook ads performing?&lt;/item&gt;
      &lt;item&gt;Assemble a high-value audience thatâs most likely to convert with a 20% sale on our premium plan.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Each of these requires multiple steps, including data retrieval from specific sources, and is highly non-deterministic on a customer-by-customer basis. You can think of these kinds of prompts as sparse, meaning that a query from a customer who sells travel software would look nothing like a query from an e-commerce company, and so on and so forth. This agent needs to be a data scientist, a marketer, and a creative partner all in one.Â&lt;/p&gt;
    &lt;p&gt;A naive approach to this problem (and indeed, this was Hightouchâs v0 implementation) would just stitch together prompts and tool calls to the data sources and APIs that a customer has already integrated. You could add a series of system prompts (âYou are the worldâs best and most handsome data scientistâ) and youâd have a decent start. This worked for simple short-lived questions, but would get stuck on more strategic prompts that required complex reasoning.Â&lt;/p&gt;
    &lt;p&gt;There are two problems here that speak to fundamental limitations of LLMs. First, naively long LLM calls will run out of context pretty quickly. Itâs true that context windows are getting longer and longer, but for the purposes of really long running agents current windows are still woefully too small. And second, thanks to instructional fine tuning, todayâs models are by default concise. They are fine tuned on datasets of short chat sessions, so their default behavior is a poor match for what data science and marketing work really is: open ended, long-context exploration. For many of the kinds of prompts Hightouch would test on, the models would kind of âgive upâ once they reached a satisfactory answer, in essence stuck at a local optimum.Â&lt;/p&gt;
    &lt;p&gt;This is also why existing agent frameworks werenât good fits. Most of them were too rigid, focusing more on the developer experience of chaining calls together than on solving the core problem of long-form, autonomous reasoning. The Hightouch team did not need a better way to build a deterministic flowchart with nice LLM integrations. They needed a way to get the model to think better.&lt;/p&gt;
    &lt;head rend="h2"&gt;Planning, then doing (and re-planning) (and re-doing)&lt;/head&gt;
    &lt;p&gt;One of the first major insights the Hightouch team had was explicitly separating the modelâs planning from its execution. This is widely understood as a best practice in building agents today, but it wasnât always this way. Essentially, before you ask the model to do something, you ask it to plan how it would do that thing. For several architectural reasons this tends to lead to significantly better outputs.Â&lt;/p&gt;
    &lt;p&gt;Here is how Hightouch implements it:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A user submits a prompt like: "What are the leading indicators of churn in our customer base?"&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Hightouch takes this prompt and instructs the model to generate a step-by-step plan to answer the question. The model might return a plan like this: &lt;list rend="ul"&gt;&lt;item&gt;Step 1: Identify all customers who have churned in the last 6 months.&lt;/item&gt;&lt;item&gt;Step 2: For each churned customer, rewind their history to a point in time just before they churned.&lt;/item&gt;&lt;item&gt;Step 3: Engineer features based on their behavior at that time (e.g., average purchase frequency, product categories viewed, support tickets submitted).&lt;/item&gt;&lt;item&gt;Step 4: Do the same for a control group of active customers.&lt;/item&gt;&lt;item&gt;Step 5: Train a simple classification model to identify which features are most predictive of churn.&lt;/item&gt;&lt;item&gt;Step 6: Summarize the findings and present the key leading indicators.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;This plan is then fed back into the same conversation as the guide for the execution phase. The agent then begins to work through the plan, one step at a time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;OK, simple enough. Where things get really interesting is that Hightouchâs implementation allows the modelâs plan to be dynamic. As it executes the steps and learns new things grounded in the customerâs data, the model can change its mind and generate a new plan. Not quite continual learning, but itâs a start!&lt;/p&gt;
    &lt;p&gt;They (cleverly) implemented this via a special set of "system tool calls." Most people think of tool calls as a way for agents to interact with external systems, like running a query or calling an API. But the Hightouch agent harness uses these tool calls to let the agent manage its own internal thought process via options like make_plan, execute_step_in_plan, and perhaps most importantly, update_plan. The update_plan tool call might get triggered when the agent discovers a new, unexpected data point, e.g. a large number of churned users recently spent 10+ minutes on a particular screen in the product. At that point the model can decide to break from the original plan and insert a new step to investigate this unusual correlation.&lt;/p&gt;
    &lt;p&gt;This ability creates a sort of reasoning loop where the agent is constantly assessing its progress against its plan and iterating. In practice thereâs a bunch of scaffolding the system needs to make this work beyond just these tool calls. For example, to ensure the plan stays top of mind for the LLM, the harness frequently has the agent "regurgitate" the current plan at the end of its context, since models tend to pay more attention to the most recent tokens in their context window.Â&lt;/p&gt;
    &lt;head rend="h2"&gt;Agentic delegation 1: file buffering and dynamic subagents&lt;/head&gt;
    &lt;p&gt;Ah, the context window. This pesky little interface seems to grow tremendously every model generation (we are getting into the millions), and yet it is still painfully too small for all of our grand agent ambitions.Â&lt;/p&gt;
    &lt;p&gt;With long running agents the context window is always going to be the fundamental bottleneck. No matter how many tokens a model claims to support, persistent memory remains the biggest unsolved problem in agent building. And for a system like Hightouch Agents, which can involve dozens of exploratory steps and long, complex SQL queries, even a 1M token window can feel claustrophobic.&lt;/p&gt;
    &lt;p&gt;To solve this, the team developed a series of interesting techniques to effectively manage and compress context. You can think of these little hacks as, in the aggregate, starting to resemble some sort of short and long term memory for the model.Â&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Buffering context to files: the agent's scratchpad&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There comes a time in every engineerâs career where they inevitably decide to build a filesystem. Thankfully Hightouchâs engineering team only sort of built a filesystem, via giving the agent the ability to read and write context to a temporary, session-specific file system. Here is how it works.&lt;/p&gt;
    &lt;p&gt;When a tool call or executing a step in the plan returns a large amount of data â this will happen often when the agent executes a SQL query or pulls data from an API â the agent can make a decision. Instead of stuffing the entire result set into context it can call write_file to buffer the response to disk. It keeps a pointer in context with the file name and a brief description of its contents, e.g. churned_users_q2.csv.Â&lt;/p&gt;
    &lt;p&gt;Later in the session, the agent can reuse that data with the read_file tool call to pull it back into context. A theme youâll see a lot in this post is that instead of building some complicated logic tree to decide when the model should do this kind of buffering, Hightouchâs engineering team found that entrusting the logic to the model itself led to the best results. Itâs guided by some basic heuristics in the system prompt (e.g. âbuffer results to a file when the results are largeâ) but the rest is up to the timeless art of next token prediction.Â&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Dynamic subagents&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Buffering to files works especially well when an agentâs execution step results in a bunch of raw data. But there is another major source of context bloat: the agentâs own reasoning process, which as weâve already seen Hightouch is trying to encourage to be exploratory and long. To handle this the team devised a more elegant solution they call dynamic subagents.&lt;/p&gt;
    &lt;p&gt;The idea is pretty simple: hand off occasional agent tasks and their context to another model. The main agent thread identifies a complex sub-task that will require multiple steps to solve (e.g. the entire feature engineering process from the churn example) and then offloads it:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Instead of performing said task in the main context, the agent uses a tool call to spawn a separate, isolated LLM thread.Â&lt;/item&gt;
      &lt;item&gt;This isolated thread is given the relevant context and a single, dedicated objective. It then performs all the messy work (writing SQL, exploring data cuts, etc.) within its own self-contained environment.&lt;/item&gt;
      &lt;item&gt;Once it arrives at a conclusion, it generates a concise summary and a list of key findings.Â&lt;/item&gt;
      &lt;item&gt;Only this summary is appended back to the main agent's log. All the intermediate "scratch paper" work from the isolated thread is thrown away.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The analogy here is sort of like taking a math test. Your professor wants you to show your work, butâ¦not all of your work. Your final answer sheet should be clean and show the most important steps. But to get there, you might use a separate piece of scratch paper for all the messy derivations, calculations, and mistakes. Dynamic subagents is that piece of scratch paper.Â&lt;/p&gt;
    &lt;p&gt;This hierarchical approach allows the agent to perform deep, exploratory analysis on sub-problems without derailing the direction of the main task. Dynamic subagents are worth contrasting with prevailing understandings of micro and macro compaction, because they are able to fully maintain context density without losing any fidelity. Most approaches to compaction patch up the symptoms without addressing the root cause: youâre cleaning up after the fact, as the context fills up with tactical minutiae and then you have to go back and decide what to strip out. The Hightouch approach, on the other hand, means the agent can go way further and maintain a high quality context along the way.Â&lt;/p&gt;
    &lt;head rend="h2"&gt;Agentic delegation 2: fanning out, and why embeddings are overrated&lt;/head&gt;
    &lt;p&gt;At their core, file buffering and dynamic subagents are about the idea of an orchestrator model delegating out to sub-LLM calls dynamically to manage context effectively. Another way the Hightouch does this is through fanning out. Part of the Hightouch agent harness is its frequent use of fanouts to smaller models instead of relying on a âtraditionalâ (can one even say that?) setup of embeddings in a vector database.Â&lt;/p&gt;
    &lt;p&gt;Unstructured data is a central part of Hightouchâs platform and as such a central part of the common use cases customers have for Hightouch Agents. A typical prompt might look something like:&lt;/p&gt;
    &lt;quote&gt;Which types of creative in our Instagram campaigns tend to perform best?&lt;/quote&gt;
    &lt;p&gt;This would be a pretty simple âcan you pull the data for meâ question if all ad creative was neatly organized into groups in a tabularâ¦sorry, I laughed even writing this. For most companies, itâs actually scattered all over the place and totally unlabeled. A given account might have hundreds of active campaigns, each with multiple images and associated ad copy. How is the agent supposed to figure that out?&lt;/p&gt;
    &lt;p&gt;The textbook answer in 2024 would be embeddings. You create vector embeddings for all your ad creatives, store them in a vector database, and then, at query time, create an embedding of the user's request and perform a similarity search. But the issue with embeddings is that theyâre actually quite dumb. They lack the intelligence that modern multimodal LLMs have, which are able to reason about their prompt and whatâs in the image in a much more intelligent way than naive vector operations. So instead, Hightouch opted for a brute-force approach that is both simpler and, in their context, more effective: a fan-out pattern using small, cheap LLMs.&lt;/p&gt;
    &lt;p&gt;In their agent harness, the main orchestrator agent acts as a dispatcher. It uses a tool that essentially says, "for every campaign in our database, run the following analysis." It then spawns hundreds of parallel API calls to a much smaller, faster, and cheaper model, like Anthropic's Haiku. Each of these micro-LLM calls is given the creative assets for a single campaign and a very specific, dynamically generated question: "Does the attached image contain user-generated content? Answer yes or no." Or, "Analyze the color palette of this image. Is it generally bright or dark?"&lt;/p&gt;
    &lt;p&gt;Things have come a long way over the past few years, and these small models are surprisingly good at these targeted classification tasks. Their responses are simple "yes" or "no" answers in structured JSON and are then collected and aggregated. And voila, in under a minute, the main agent has a perfectly structured dataset mapping every single campaign to the attributes the user asked for, which it can then use for the next step of its analysis.&lt;/p&gt;
    &lt;p&gt;All in all this process is way cheaper, easier, and more reliable (for this kind of task) than going through the rigor of setting up a proper RAG system.Â&lt;/p&gt;
    &lt;p&gt;First there was prompt engineering, then there was context engineering. The one thing both of these nonsensical phrases share is that they have nothing to do with actual engineering. Real context engineering is exactly what I wrote about here: buffering to files, planning and execution loops, tool calls, and dynamic subagents.Â&lt;/p&gt;
    &lt;p&gt;The story of Hightouch Agents is essentially one in the realities of applied AI engineering. The ugly truth is that creating a truly capable agent system today has less to do with scaling RL or exotic model architectures and more to do with the deeply unfussy work of actual context engineering.&lt;/p&gt;
    &lt;p&gt;And if this kind of work is interesting to you, Hightouchâs engineering team is hiring.Â Â&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46695855</guid><pubDate>Tue, 20 Jan 2026 18:31:49 +0000</pubDate></item><item><title>Instabridge has acquired Nova Launcher</title><link>https://novalauncher.com/nova-is-here-to-stay</link><description>&lt;doc fingerprint="bceee51209e82ebe"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Nova Launcher: An update&lt;/head&gt;
    &lt;head rend="h6"&gt;January 20 2026&lt;/head&gt;
    &lt;p&gt;Hi everyone. We want to share a clear update directly with the Nova community.&lt;/p&gt;
    &lt;p&gt;Instabridge has acquired Nova Launcher. We are a Swedish company building products that help people get online, used by millions of people worldwide.&lt;/p&gt;
    &lt;head rend="h4"&gt;What this means right now&lt;/head&gt;
    &lt;p&gt;Nova is not shutting down. Our immediate focus is simple: keep Nova stable, compatible with modern Android, and actively maintained.&lt;/p&gt;
    &lt;p&gt;We also know many of you have lived through a long period of uncertainty. Nova has a strong identity and a community that still cares deeply. We take that seriously.&lt;/p&gt;
    &lt;head rend="h4"&gt;How we will approach stewardship&lt;/head&gt;
    &lt;p&gt;Our job is not to reinvent Nova overnight. Our job is to be responsible owners.&lt;/p&gt;
    &lt;p&gt;That means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Keeping performance and customization at the core&lt;/item&gt;
      &lt;item&gt;Fixing bugs and keeping pace with Android changes&lt;/item&gt;
      &lt;item&gt;Listening carefully before making big product decisions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We will be reading and collecting feedback from Reddit, Play Store reviews, email, and other community channels. We will not be able to respond to every post, but we will be paying attention. For support related issues, we will share a clear contact channel shortly.&lt;/p&gt;
    &lt;head rend="h4"&gt;FAQ&lt;/head&gt;
    &lt;head rend="h5"&gt;Why acquire Nova Launcher?&lt;/head&gt;
    &lt;p&gt;We have long admired what Nova represents: speed, customization, and user control. When we saw how much the community still cares, it was clear to us that Nova deserved a stable future with active maintenance.&lt;/p&gt;
    &lt;head rend="h5"&gt;Will Nova still feel like Nova?&lt;/head&gt;
    &lt;p&gt;Yes. Novaâs identity is the point. Performance, flexibility, and user control stay at the center of the product. Any future changes will be evaluated through that lens.&lt;/p&gt;
    &lt;head rend="h5"&gt;Are you going to add ads?&lt;/head&gt;
    &lt;p&gt;Nova needs a sustainable business model to support ongoing development and maintenance. We are exploring different options, including paid tiers and other approaches. As many of you have already anticipated, we are also evaluating ad based options for the free version.&lt;/p&gt;
    &lt;p&gt;If ads are introduced, Nova Prime will remain ad free. Our guiding principles are clear: keep the experience clean and fast, avoid disruptive formats, and provide a straightforward way to keep the experience ad free.&lt;/p&gt;
    &lt;head rend="h5"&gt;Is the goal just to keep Nova alive?&lt;/head&gt;
    &lt;p&gt;No. Sustainability is not just about survival. A healthy business model allows us to invest properly in Nova over time.&lt;/p&gt;
    &lt;p&gt;That investment enables deeper work on performance, more powerful customization, better long term compatibility with Android, and thoughtful features that require real engineering effort. Our ambition is for Nova to remain a launcher that power users choose because it continues to do things exceptionally well and evolves with the platform.&lt;/p&gt;
    &lt;p&gt;We will move deliberately and prioritize quality over rushing features out the door.&lt;/p&gt;
    &lt;head rend="h5"&gt;What about existing Nova Prime users?&lt;/head&gt;
    &lt;p&gt;We respect everyone who has supported Nova over the years. We intend to honor existing Prime purchases, and Prime features will continue working for existing Prime users. Nova Prime will also remain ad free.&lt;/p&gt;
    &lt;head rend="h5"&gt;What about the price of Nova Prime?&lt;/head&gt;
    &lt;p&gt;Some of you noticed that the price of Nova Prime increased shortly before the app was transferred to our account. We have now changed it to 3.99 USD, effective immediately, and we apologize for the timing and the confusion it caused.&lt;/p&gt;
    &lt;p&gt;As we explore a sustainable long term model, we may evaluate other pricing options or tiers. If we do, we will aim to keep it fair and communicate clearly ahead of time.&lt;/p&gt;
    &lt;head rend="h5"&gt;Will Nova become open source?&lt;/head&gt;
    &lt;p&gt;We know this matters to many of you. It is something we are actively evaluating. Open sourcing a product responsibly involves licensing, security, build tooling, contribution workflow, and trademark stewardship. We do not have a decision to share yet, but we will be transparent once we do.&lt;/p&gt;
    &lt;head rend="h5"&gt;What about privacy?&lt;/head&gt;
    &lt;p&gt;We will keep data collection minimal and purpose driven, and we will be clear about what is collected and why. We do not sell personal data.&lt;/p&gt;
    &lt;head rend="h4"&gt;Closing&lt;/head&gt;
    &lt;p&gt;We are here for the long term. Trust is earned through consistent maintenance and clear communication, not big promises. We will take this step by step.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46696357</guid><pubDate>Tue, 20 Jan 2026 19:06:56 +0000</pubDate></item></channel></rss>