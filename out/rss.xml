<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 10 Dec 2025 08:48:35 +0000</lastBuildDate><item><title>Show HN: Gemini Pro 3 hallucinates the HN front page 10 years from now</title><link>https://dosaygo-studio.github.io/hn-front-page-2035/news</link><description>&lt;doc fingerprint="a461ad970e1c7920"&gt;
  &lt;main&gt;
    &lt;p&gt;Y Hacker News new | past | comments | ask | show | jobs | submit login 1. First successful telemetry from Starship HLS-9 on the Sea of Tranquility ( spacex.com ) 894 points by muskwatch 4 hours ago | hide | 312 comments 2. A 100% Rust kernel is now upstream in Linux 7.4 ( kernel.org ) 402 points by rust_evangelist 6 hours ago | hide | 156 comments 3. Why I still write raw code instead of prompting the compiler ( nostalgic-coder.io ) 128 points by oldtimer99 3 hours ago | hide | 89 comments 4. Running LLaMA-12 7B on a contact lens with WASM ( arxiv.org ) 67 points by edge_compute 2 hours ago | hide | 14 comments 5. Show HN: AlgoDrill – Interactive drills to stop forgetting LeetCode patterns ( algodrill.io ) 243 points by persistence_is_key 5 hours ago | hide | 98 comments 6. ITER achieves net positive energy for 20 consecutive minutes ( nature.com ) 1205 points by physics_lover 12 hours ago | hide | 402 comments 7. Restoring a 2024 Framework Laptop: A retrospective ( ifixit.com ) 56 points by retro_fix 4 hours ago | hide | 22 comments 8. Google kills Gemini Cloud Services ( killedbygoogle.com ) 530 points by dang_fan 15 hours ago | hide | 330 comments 9. Visualizing the 5th dimension with WebGPU 2.0 ( graphics-shader.net ) 88 points by webgl_wizard 7 hours ago | hide | 12 comments 10. Launch HN: Nia (YC W36) – Give context to autonomous coding agents ( trynia.ai ) 112 points by founder_jane 10 hours ago | hide | 45 comments 11. Debian 18 "Trixie" released ( debian.org ) 312 points by apt_get 14 hours ago | hide | 78 comments 12. Is it time to rewrite sudo in Zig? ( github.com ) 45 points by ziggy42 3 hours ago | hide | 60 comments 13. EU passes "Right to Human Verification" Act ( europa.eu ) 670 points by policy_wonk 1 day ago | hide | 290 comments 14. Reverse Engineering the Neuralink V4 Bluetooth Protocol ( brain-hacks.org ) 220 points by cyborg_sec 8 hours ago | hide | 55 comments 15. Post-Silicon Computing: An Intro to Photonic Circuits ( mit.edu ) 99 points by lightspeed 6 hours ago | hide | 18 comments 16. FDA approves over-the-counter CRISPR for lactose intolerance ( fda.gov ) 415 points by bio_hacker 16 hours ago | hide | 211 comments 17. SQLite 4.0 Release Notes ( sqlite.org ) 800 points by drh 20 hours ago | hide | 140 comments 18. Ask HN: How do you prevent ad-injection in AR glasses? 320 points by glasshole2 11 hours ago | hide | 102 comments 19. Jepsen: NATS 4.2 (Still losing messages?) ( jepsen.io ) 88 points by aphyr_bot 9 hours ago | hide | 33 comments 20. Playing GTA VI on a RISC-V Cluster ( youtube.com ) 45 points by tlyleung 2 hours ago | hide | 16 comments 21. Why functional programming is the future (again) ( haskell.org ) 102 points by monad_lover 7 hours ago | hide | 65 comments 22. Microsoft Office 365 prices increase to $40/user/month ( officewatch.com ) 900 points by taubek 1 day ago | hide | 600 comments 23. Emulating Windows 10 in the browser ( bellard.org ) 341 points by qemu_fan 19 hours ago | hide | 50 comments 24. Let's put Tailscale on a SpaceX Starlink Dish ( tailscale.com ) 250 points by net_hacker 20 hours ago | hide | 45 comments 25. Manual: Deep Fakes detection for Seniors ( aarp.org ) 122 points by concerned_grandson 21 hours ago | hide | 77 comments 26. IBM to acquire OpenAI (Rumor) ( bloomberg.com ) 120 points by stock_watcher 1 day ago | hide | 338 comments 27. The unexpected return of server-side rendering ( htmx.org ) 147 points by bikenaga 19 hours ago | hide | 48 comments 28. How to build a Faraday Cage for your bedroom ( privacy-first.com ) 267 points by tinfoil_hat 22 hours ago | hide | 49 comments 29. AI progress is stalling. Human equivalence was a mirage ( garymarcus.com ) 485 points by skeptic_ai 14 hours ago | hide | 416 comments 30. Show HN: A text editor that doesn't use AI ( github.com ) 270 points by pure_coder 22 hours ago | hide | 105 comments More Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact Search:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46205632</guid><pubDate>Tue, 09 Dec 2025 15:00:38 +0000</pubDate></item><item><title>Pebble Index 01 – External memory for your brain</title><link>https://repebble.com/blog/meet-pebble-index-01-external-memory-for-your-brain</link><description>&lt;doc fingerprint="5c6b48dfd9872b65"&gt;
  &lt;main&gt;
    &lt;p&gt;Catch your best ideas before they slip through your fingers&lt;/p&gt;
    &lt;p&gt;Do you ever have flashes of insight or an idea worth remembering? This happens to me 5-10 times every day. If I don’t write down the thought immediately, it slips out of my mind. Worst of all, I remember that I’ve forgotten something and spend the next 10 minutes trying to remember what it is. So I invented external memory for my brain.&lt;/p&gt;
    &lt;p&gt;Introducing Pebble Index 01 - a small ring with a button and microphone. Hold the button, whisper your thought, and it’s sent to your phone. It’s added to your notes, set as a reminder, or saved for later review.&lt;/p&gt;
    &lt;p&gt;Index 01 is designed to become muscle memory, since it’s always with you. It’s private by design (no recording until you press the button) and requires no internet connection or paid subscription. It’s as small as a wedding band and comes in 3 colours. It’s made from durable stainless steel and is water-resistant. Like all Pebble products, it’s extremely customizable and built with open source software.&lt;/p&gt;
    &lt;p&gt;Here’s the best part: the battery lasts for years. You never need to charge it.&lt;/p&gt;
    &lt;p&gt;Pre-order today for $75. After worldwide shipping begins in March 2026, the price will go up to $99.&lt;/p&gt;
    &lt;head rend="h3"&gt;#Design&lt;/head&gt;
    &lt;p&gt;Now that I’ve worn my Index 01 for several months, I can safely say that it has changed my life - just like with Pebble, I couldn’t go back to a world without this. There are so many situations each day where my hands are full (while biking or driving, washing dishes, wrangling my kids, etc) and I need to remember something. A random sampling of my recent recordings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set a timer for 3pm to go pick up the kids&lt;/item&gt;
      &lt;item&gt;Remind me to phone the pharmacy at 11am&lt;/item&gt;
      &lt;item&gt;Peter is coming by tomorrow at 11:30am, add that to my calendar&lt;/item&gt;
      &lt;item&gt;Jerry recommends reading Breakneck&lt;/item&gt;
      &lt;item&gt;Mark wants a Black/Red PT2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Before, I would take my phone out of my pocket to jot these down, but I couldn’t always do that (eg, while bicycling). I also wanted to start using my phone less, especially in front of my kids.&lt;/p&gt;
    &lt;p&gt;Initially, we experimented by building this as an app on Pebble, since it has a mic and I’m always wearing one. But, I realized quickly that this was suboptimal - it required me to use my other hand to press the button to start recording (lift-to-wake gestures and wake-words are too unreliable). This was tough to use while bicycling or carrying stuff.&lt;/p&gt;
    &lt;p&gt;Then a genius electrical engineer friend of mine came up with an idea to fit everything into a tiny ring. It is the perfect form factor! Honestly, I’m still amazed that it all fits.&lt;/p&gt;
    &lt;p&gt;The design needed to satisfy several critical conditions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Must work reliably 100% of the time. If it didn’t work or failed to record a thought, I knew I would take it off and revert back to my old habit of just forgetting things.&lt;/item&gt;
      &lt;item&gt;It had to have a physical press-button, with a satisfying click-feel. I want to know for sure if the button is pressed and my thought is captured.&lt;/item&gt;
      &lt;item&gt;Long battery life - every time you take something off to charge, there’s a chance you’ll forget to put it back on.&lt;/item&gt;
      &lt;item&gt;Must be privacy-preserving. These are your inner thoughts. All recordings must be processed and stored on your phone. Only record when the button is pressed.&lt;/item&gt;
      &lt;item&gt;It had to be as small as a wedding band. Since it’s worn on the index finger, if it were too large or bulky, it would hit your phone while you held it in your hand.&lt;/item&gt;
      &lt;item&gt;Water resistance - must be able to wash hands, shower, and get wet.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We’ve been working on this for a while, testing new versions and making tweaks. We’re really excited to get this out into the world.&lt;/p&gt;
    &lt;p&gt;Here are a few of my favourite things about Index 01:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It does one thing really well - it helps me remember things.&lt;/item&gt;
      &lt;item&gt;It’s discreet. It's not distracting. It doesn't take you out of the moment.&lt;/item&gt;
      &lt;item&gt;There’s no AI friend persona and it’s not always recording.&lt;/item&gt;
      &lt;item&gt;It’s inexpensive. We hope you try it and see if you like it as well!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;#Key Details&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Available in 3 colours and 8 sizes &lt;list rend="ul"&gt;&lt;item&gt;Colours: polished silver, polished gold, and matte black&lt;/item&gt;&lt;item&gt;US ring sizes: 6, 7, 8, 9, 10, 11, 12, 13&lt;/item&gt;&lt;item&gt;You can pre-order now and pick your size/colour later before your ring ships.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Cost and availability: Pre-order price is $75, rises to $99 later. Ships worldwide, beginning in March.&lt;/item&gt;
      &lt;item&gt;Works with iPhone and Android: We overcame Apple’s best efforts to make life terrible for 3rd party accessory makers and have Index 01 working well on iOS and Android.&lt;/item&gt;
      &lt;item&gt;Extremely private and secure: Your thoughts are processed by open source speech-to-text (STT) and AI models locally on your phone. You can read the code and see exactly how it works - our Pebble mobile app is open source. Higher-quality STT is available through an optional cloud service.&lt;/item&gt;
      &lt;item&gt;No charging: The battery lasts for up to years of average use. After the end of its life, send your ring back to us for recycling.&lt;/item&gt;
      &lt;item&gt;On-ring storage: Recording works even if your phone is out of range. Up to 5 minutes of audio can be stored on-ring, then synced later.&lt;/item&gt;
      &lt;item&gt;No speaker or vibrating motor: This is an input device only. There is an RGB LED, but it’s rarely used (to save battery life and to reduce distraction).&lt;/item&gt;
      &lt;item&gt;Works great with Pebble or other smartwatches: After recording, the thought will appear on your watch, and you can check that it’s correct. You can ask questions like ‘What’s the weather today?’ and see the answer on your watch.&lt;/item&gt;
      &lt;item&gt;Raw audio playback: Very helpful if STT doesn’t work perfectly due to wind or loud background noises.&lt;/item&gt;
      &lt;item&gt;Actions: While the primary task is remembering things for you, you can also ask it to do things like ’Send a Beeper message to my wife - running late’ or answer simple questions that could be answered by searching the web. You can configure button clicks to control your music - I love using this to play/pause or skip tracks. You can also configure where to save your notes and reminders (I have it set to add to Notion).&lt;/item&gt;
      &lt;item&gt;Customizable and hackable: Configure single/double button clicks to control whatever you want (take a photo, turn on lights, Tasker, etc). Add your own voice actions via MCP. Or route the audio recordings directly to your own app or server!&lt;/item&gt;
      &lt;item&gt;99+ languages: Speech to text and local LLM support over 99 languages! Naturally, the quality of each may vary.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;#Future Plans&lt;/head&gt;
    &lt;p&gt;Let me be very clear - Index 01 is designed at its core to be a device that helps you remember things. We want it to be 100% reliable at its primary task. But we’re leaving the side door open for folks to customize, build new interactions and actions.&lt;/p&gt;
    &lt;p&gt;Here’s how I’m thinking about it - a single click-hold + voice input will be routed to the primary memory processing path. Double-click-hold + voice input would be routed to a more general purpose voice agent (think ChatGPT with web search). Responses from the agent would be presented on Pebble (eg ‘What’s the weather tomorrow?’, ‘When’s the next northbound Caltrain?’) or other smartwatches (as a notification). Maybe this could even be an input for something like ChatGPT Voice Mode, enabling you to hear the AI response from your earbuds.&lt;/p&gt;
    &lt;p&gt;The built in actions, set reminder, create note, alarms, etc, are actually MCPs - basically mini apps that AI agents know how to operate. They run locally in WASM within the Pebble mobile app (no cloud MCP server required). Basically any MCP server can be used with the system, so intrepid folks may have fun adding various actions like Beeper, Google Calendar, weather, etc that already offer MCPs.&lt;/p&gt;
    &lt;p&gt;Not everything will be available at launch, but this is the direction we are working towards. There will be 3 ways to customize your Index 01:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Trigger actions via button clicks - configure a single or double click to do things like take a photo, control your Home Assistant smart home, Tasker function, unlock your car. This will work better on Android since iOS Shortcuts doesn’t have an open API.&lt;/item&gt;
      &lt;item&gt;Trigger actions via voice input - write an MCP to do….basically anything? This is pretty open ended.&lt;/item&gt;
      &lt;item&gt;Route your voice recordings and/or transcriptions to your own webhook - or skip our AI processing entirely and send every recording to your own app or webapp.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How does it work?&lt;/p&gt;
    &lt;p&gt;People usually wear it on the index finger. Inside the ring is a button, a microphone, a Bluetooth chip, memory, and a battery that lasts for years. Click the button with your thumb, talk into the mic, and it records to internal memory. When your phone is in range, the recording is streamed to the Pebble app. It’s converted to text on-device, then processed by an on-device large language model (LLM) which selects an action to take (create note, add to reminders, etc).&lt;/p&gt;
    &lt;p&gt;When do I pick my size?&lt;/p&gt;
    &lt;p&gt;You’ll be able to pick your ring size and color after placing a pre-order. If you have a 3D printer, you can print our CAD designs to try on. We’re also planning a sizing kit. You can view the measurements of the inner diameter of each ring size.&lt;/p&gt;
    &lt;p&gt;How long does the battery last?&lt;/p&gt;
    &lt;p&gt;Roughly 12 to 15 hours of recording. On average, I use it 10-20 times per day to record 3-6 second thoughts. That’s up to 2 years of usage.&lt;/p&gt;
    &lt;p&gt;Is it secure and private?&lt;/p&gt;
    &lt;p&gt;Yes, extremely. The connection between ring and phone is encrypted. Recordings are processed locally on your phone in the open-source Pebble app. The app works offline (no internet connection) and does not require a cloud service. An optional cloud storage system for backing up recordings is available. Our plan is for this to be optionally encrypted, but we haven’t built it yet.&lt;/p&gt;
    &lt;p&gt;Is a paid subscription required?&lt;/p&gt;
    &lt;p&gt;No.&lt;/p&gt;
    &lt;p&gt;What kind of battery is inside?&lt;/p&gt;
    &lt;p&gt;Index 01 uses silver-oxide batteries.&lt;/p&gt;
    &lt;p&gt;Why can’t it be recharged?&lt;/p&gt;
    &lt;p&gt;We considered this but decided not to for several reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;You’d probably lose the charger before the battery runs out!&lt;/item&gt;
      &lt;item&gt;Adding charge circuitry and including a charger would make the product larger and more expensive.&lt;/item&gt;
      &lt;item&gt;You send it back to us to recycle.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Wait, it’s single use?&lt;/p&gt;
    &lt;p&gt;Yes. We know this sounds a bit odd, but in this particular circumstance we believe it’s the best solution to the given set of constraints. Other smart rings like Oura cost $250+ and need to be charged every few days. We didn’t want to build a device like that. Before the battery runs out, the Pebble app notifies and asks if you’d like to order another ring.&lt;/p&gt;
    &lt;p&gt;Is it always listening?&lt;/p&gt;
    &lt;p&gt;No. It only records while the button is pressed. It’s not designed to record your whole life, or meetings.&lt;/p&gt;
    &lt;p&gt;What if the speech-to-text processing misses a word or something?&lt;/p&gt;
    &lt;p&gt;You can always listen to the each recording in the app.&lt;/p&gt;
    &lt;p&gt;Why no touchpad?&lt;/p&gt;
    &lt;p&gt;We experimented with a touchpad, but found it too easy to accidentally swipe and press. Also, nothing beats the feedback of a real gosh darn pressable button.&lt;/p&gt;
    &lt;p&gt;Is there a speaker or vibrating motor?&lt;/p&gt;
    &lt;p&gt;No. The button has a great click-feel to indicate when you are pressing.&lt;/p&gt;
    &lt;p&gt;Does it do health tracking like Oura?&lt;/p&gt;
    &lt;p&gt;Nope&lt;/p&gt;
    &lt;p&gt;How durable and water-resistant is it?&lt;/p&gt;
    &lt;p&gt;It’s primarily made from stainless steel 316, with a liquid silicone rubber (LSR) button. It’s water-resistant to 1 meter. You can wash your hands, do dishes, and shower with it on, but we don’t recommend swimming with it.&lt;/p&gt;
    &lt;p&gt;Does it work with iPhone and Android?&lt;/p&gt;
    &lt;p&gt;Yes&lt;/p&gt;
    &lt;p&gt;I love customizing and hacking on my devices. What could I do with Index 01?&lt;/p&gt;
    &lt;p&gt;Lots of stuff! Control things with the buttons. Route raw audio or transcribed text directly to your own app via webhook. Use MCPs (also run locally on-device! No cloud server required) to add more actions.&lt;/p&gt;
    &lt;p&gt;Is this an AI friend thingy or always-recording device?&lt;/p&gt;
    &lt;p&gt;No.&lt;/p&gt;
    &lt;p&gt;How far along is development?&lt;/p&gt;
    &lt;p&gt;We’ve been working on this in the background to watch development. It helps that our Pebble Time 2 partner factory is also building Index 01! We’re currently in the DVT stage, testing pre-production samples. We’ll start a wider alpha test in January with a lot more people. Here’s some shots from the pre-production assembly line:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46205661</guid><pubDate>Tue, 09 Dec 2025 15:03:09 +0000</pubDate></item><item><title>A supersonic engine core makes the perfect power turbine</title><link>https://boomsupersonic.com/flyby/ai-needs-more-power-than-the-grid-can-deliver-supersonic-tech-can-fix-that</link><description>&lt;doc fingerprint="16d2b440c19c9c2a"&gt;
  &lt;main&gt;
    &lt;p&gt;By: Blake Scholl, Founder &amp;amp; CEO, Boom Supersonic&lt;/p&gt;
    &lt;p&gt;It started, as many things do these days, by scrolling on X.&lt;/p&gt;
    &lt;p&gt;I was reading post after post about the power crisis hitting AI data centers—GPU racks sitting idle, waiting not on chips, but on electricity. I texted with Sam Altman—who confirmed power was indeed a major constraint. I pinged our engineering team—and found that they already had the outline of a plan to build a power turbine based on our Symphony supersonic engine.&lt;/p&gt;
    &lt;p&gt;After a few conversations, it became clear: AI didn’t just need more turbines—it needed a new and fundamentally better turbine. Symphony was the perfect new engine to accelerate AI in America. About three months later, we had a signed deal for 1.21 gigawatts and had started manufacturing the first turbine.&lt;/p&gt;
    &lt;p&gt;Today, we’re announcing Superpower, our new 42‑megawatt natural gas turbine, along with a $300M funding round and Crusoe as our launch customer. And most importantly: this marks a turning point. Boom is now on a self-funded path to both Superpower and the Overture supersonic airliner.&lt;/p&gt;
    &lt;p&gt;I want to share the real story of how this happened—and why supersonic technology is exactly what America’s energy crisis demands.&lt;/p&gt;
    &lt;head rend="h4"&gt;America Doesn’t Have 10–15 Years to Solve Its Power Problem the Old Way&lt;/head&gt;
    &lt;p&gt;If you’ve been paying attention, you know the U.S. is in a genuine energy crunch. GPU racks are idling because they can’t get power. Data centers are fighting over substations and interconnection queues. Meanwhile China is adding power capacity at a wartime pace—coal, gas, nuclear, everything—while America struggles to get a single transmission line permitted.&lt;/p&gt;
    &lt;p&gt;AI won’t wait for us to fix the grid. And the United States simply doesn’t have 10–15 years to build out power infrastructure the old way.&lt;/p&gt;
    &lt;p&gt;Hyperscalers have already moved to their own Plan B: behind‑the‑meter power plants. You’ve seen XAI’s Colossus I and II in Memphis. OpenAI’s Stargate I in Abilene. These projects are powered by arrays of aeroderivative natural-gas turbines—which are, fundamentally, modified jet engines from the 1970s. There’s something brilliant in this approach: the transition from gigantic “frame” turbines to arrays of mid-size “aeroderivative” turbines mirrors the computing industry’s shift from mainframes to blade servers.&lt;/p&gt;
    &lt;p&gt;The problem? The “blade servers” of the energy world are old tech and they’re sold out. Because the most popular “aeroderivative” turbines are based on subsonic jet engines, they’re happiest when the outside air temperature is -50°F—like it is when going Mach 0.8 at 30,000 feet. As outside temperatures rise, there is no option but to throttle back the engines—or else the turbine blades literally melt down. These turbines begin losing power at about 50°F and by the time it’s 110°—as often happens in popular data center locations like Texas—30% of generation capacity is lost. Nonetheless, major manufacturers all have backlogs through the rest of the decade and none is building a new-generation advanced-technology turbine.&lt;/p&gt;
    &lt;head rend="h4"&gt;A Supersonic Engine Core Makes the Perfect Power Turbine&lt;/head&gt;
    &lt;p&gt;When we designed the Symphony engine for Overture, we built something no one else has built this century: a brand-new large engine core optimized for continuous, high‑temperature operation.&lt;/p&gt;
    &lt;p&gt;A subsonic engine is built for short bursts of power at takeoff. A supersonic engine is built to run hard, continuously, at extreme thermal loads. Symphony was designed for Mach 1.7 at 60,000 feet, where effective temperatures reach 160°F—not the frigid -50°F conditions where legacy subsonic engines operate.&lt;/p&gt;
    &lt;p&gt;This gives Superpower several critical advantages:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Full power even with high ambient heat – Where legacy turbines lose 20–30% at 110°F, Superpower maintains its full 42MW output without derate.&lt;/item&gt;
      &lt;item&gt;Waterless operation – Legacy turbines need huge quantities of water for cooling to avoid thermal derate in hot environments. Superpower doesn’t. It stays at full output, water‑free.&lt;/item&gt;
      &lt;item&gt;Cloud‑native control and monitoring. Superpower inherits the telemetry and operations stack we built for XB‑1. Every turbine streams real‑time performance data, supports remote control, and flags anomalies before customers ever notice.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Superpower and Symphony are based on virtually identical turbine engines. Both share the identical core (HPC and HPT) and a slightly tuned low spool. In the place of Symphony’s hollow-core titanium fan, Superpower adds two additional compressor stages plus a three-stage free power turbine connected to a high-efficiency generator on its own shaft. Additionally, the engines use slightly different fuel nozzles, Symphony’s optimized for Jet A vs. Superpower’s for natural gas.&lt;/p&gt;
    &lt;head rend="h4"&gt;Scaling Production the Supersonic Way: Vertical Integration&lt;/head&gt;
    &lt;p&gt;The legacy aerospace supply chain is congested. When the mission is urgent and the supply chain congested, you build the supply chain. The new Superpower Superfactory starts with a simple vision: raw materials in one side of the building, gigawatts of completed power turbine packages out the other side. We’ve already started making the first parts—and much of the production equipment to support 2GW/yr is on order. With this new financing we’re ready to accelerate further.&lt;/p&gt;
    &lt;p&gt;If America wants to build at the speed AI requires, vertical integration isn’t optional. We’re standing up our own foundry and our own large scale CNC machining capability. We’ll have more to share on the Superpower Superfactory in early 2026.&lt;/p&gt;
    &lt;head rend="h4"&gt;Scaling Production the Supersonic Way: Vertical Integration&lt;/head&gt;
    &lt;p&gt;Superpower is sort of like our Starlink moment, the strongest accelerant we’ve ever had toward our core mission of making Earth dramatically more accessible.&lt;/p&gt;
    &lt;p&gt;The fastest way to a certified, passenger-carrying Symphony engine is to run its core for hundreds of thousands of hours in the real world, powering Earth’s most demanding AI data centers. Every hour a Superpower turbine spins is an hour of validation for Symphony. Every gigawatt we deliver strengthens our vertical integration and manufacturing capability. And with Superpower profitability funding the remainder of the aircraft program, we’ve done something rare in aerospace: created a self-sustaining path to a new airliner.&lt;/p&gt;
    &lt;p&gt;Superpower also reminds me of what Boom is at our core: a team willing to take on what others say is impossible, to do with a small team what big companies might not even attempt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46206277</guid><pubDate>Tue, 09 Dec 2025 15:51:32 +0000</pubDate></item><item><title>Handsdown one of the coolest 3D websites</title><link>https://bruno-simon.com/</link><description>&lt;doc fingerprint="e43305f6f9f2bf3"&gt;
  &lt;main&gt;
    &lt;p&gt;00:00:000&lt;/p&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Welcome!&lt;/p&gt;
    &lt;p&gt;My name is Bruno Simon, and I'm a creative developer (mostly for the web).&lt;/p&gt;
    &lt;p&gt;This is my portfolio. Please drive around to learn more about me and discover the many secrets of this world.&lt;/p&gt;
    &lt;p&gt;And don't break anything!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Audio&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Quality&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;I'm stuck!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Reset&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Renderer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Server&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;WASD or ARROWS&lt;/cell&gt;
        &lt;cell&gt;Move around&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SHIFT&lt;/cell&gt;
        &lt;cell&gt;Boost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CTRL LEFT or B&lt;/cell&gt;
        &lt;cell&gt;Brake&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;SPACE&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ENTER&lt;/cell&gt;
        &lt;cell&gt;Interact&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;M&lt;/cell&gt;
        &lt;cell&gt;Map&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;L&lt;/cell&gt;
        &lt;cell&gt;Mute&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;T&lt;/cell&gt;
        &lt;cell&gt;Post a whisper&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;R&lt;/cell&gt;
        &lt;cell&gt;Respawn&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NUM KEYS/NUM PAD&lt;/cell&gt;
        &lt;cell&gt;Activate hydraulics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LEFT CLICK (DRAG)&lt;/cell&gt;
        &lt;cell&gt;Move camera&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;H&lt;/cell&gt;
        &lt;cell&gt;Honk&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;One finger&lt;/cell&gt;
        &lt;cell&gt;Move the car&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Two fingers&lt;/cell&gt;
        &lt;cell&gt;Move camera / zoom&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tap (on the car)&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;B&lt;/cell&gt;
        &lt;cell&gt;Boost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Y&lt;/cell&gt;
        &lt;cell&gt;Jump&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;X&lt;/cell&gt;
        &lt;cell&gt;Brake&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;Interact / Exit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LT L2&lt;/cell&gt;
        &lt;cell&gt;Accelerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RT R2&lt;/cell&gt;
        &lt;cell&gt;Backward accelerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;LB / RB L1 / R1&lt;/cell&gt;
        &lt;cell&gt;Hydraulics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Left&lt;/cell&gt;
        &lt;cell&gt;Turn wheels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Left (press)&lt;/cell&gt;
        &lt;cell&gt;Honk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Right&lt;/cell&gt;
        &lt;cell&gt;Move camera&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Joystick Right (press)&lt;/cell&gt;
        &lt;cell&gt;Zoom in/out&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Select&lt;/cell&gt;
        &lt;cell&gt;Reset&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Start&lt;/cell&gt;
        &lt;cell&gt;Pause&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Resets in&lt;/p&gt;
    &lt;p&gt;Whispers are messages left by visitors.&lt;/p&gt;
    &lt;p&gt; - Everyone can see them&lt;lb/&gt; - New whispers remove old ones (max 30)&lt;lb/&gt; - One whisper per user&lt;lb/&gt; - Choose a flag&lt;lb/&gt; - No slur!&lt;lb/&gt; - Max 30 characters &lt;/p&gt;
    &lt;p&gt;Server currently offline&lt;/p&gt;
    &lt;p&gt; Thank you for visiting my portfolio! &lt;lb/&gt;If you are curious about the stack and how I built it, hereâs everything you need to know. &lt;/p&gt;
    &lt;p&gt; Three.js is the library Iâm using to render this 3D world. &lt;lb/&gt;It was created by mr.doob (X, GitHub), followed by hundreds of awesome developers, one of which being Sunag (X, GitHub) who added TSL, enabling the use of both WebGL and WebGPU, making this portfolio possible. &lt;/p&gt;
    &lt;p&gt; If you want to learn Three.js, I got you covered with this huge course. &lt;lb/&gt;It contains everything you need to start building awesome stuff with Three.js (and much more). &lt;/p&gt;
    &lt;p&gt; Iâve been making devlogs since the very start of this portfolio and you can find them on my Youtube channel. &lt;lb/&gt;Even though the portfolio is out, Iâm still working on the last videos so that the series is complete. &lt;/p&gt;
    &lt;p&gt; The code is available on GitHub under MIT license. Even the Blender files are there, so have fun! &lt;lb/&gt;For security reasons, Iâm not sharing the server code, but the portfolio works without it. &lt;/p&gt;
    &lt;p&gt; The music you hear was made especially for this portfolio by the awesome Kounine (Linktree). &lt;lb/&gt;They are now under CC0 license, meaning you can do whatever you want with them! &lt;lb/&gt;Download them here. &lt;/p&gt;
    &lt;p&gt;â Bruno&lt;/p&gt;
    &lt;p&gt;Server currently offline. Scores can't be saved.&lt;/p&gt;
    &lt;p&gt;Come hang out with the community, show us your projects and ask us anything.&lt;/p&gt;
    &lt;p&gt;Contact me directly.&lt;lb/&gt;I have to warn you, I try to answer everyone, but it might take a while.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46206531</guid><pubDate>Tue, 09 Dec 2025 16:06:58 +0000</pubDate></item><item><title>Donating the Model Context Protocol and establishing the Agentic AI Foundation</title><link>https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation</link><description>&lt;doc fingerprint="fd5e72507a8d8692"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Donating the Model Context Protocol and establishing the Agentic AI Foundation&lt;/head&gt;
    &lt;p&gt;Today, we’re donating the Model Context Protocol (MCP) to the Agentic AI Foundation (AAIF), a directed fund under the Linux Foundation, co-founded by Anthropic, Block and OpenAI, with support from Google, Microsoft, Amazon Web Services (AWS), Cloudflare, and Bloomberg.&lt;/p&gt;
    &lt;head rend="h2"&gt;Model Context Protocol&lt;/head&gt;
    &lt;p&gt;One year ago, we introduced MCP as a universal, open standard for connecting AI applications to external systems. Since then, MCP has achieved incredible adoption:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Across the ecosystem: There are now more than 10,000 active public MCP servers, covering everything from developer tools to Fortune 500 deployments;&lt;/item&gt;
      &lt;item&gt;Across platforms: MCP has been adopted by ChatGPT, Cursor, Gemini, Microsoft Copilot, Visual Studio Code, and other popular AI products;&lt;/item&gt;
      &lt;item&gt;Across infrastructure: Enterprise-grade infrastructure now exists with deployment support for MCP from providers including AWS, Cloudflare, Google Cloud, and Microsoft Azure.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt;We’re continuing to invest in MCP’s growth. Claude now has a directory with over 75 connectors (powered by MCP), and we recently launched Tool Search and Programmatic Tool Calling capabilities in our API to help optimize production-scale MCP deployments, handling thousands of tools efficiently and reducing latency in complex agent workflows.&lt;lb/&gt;MCP now has an official, community-driven Registry for discovering available MCP servers, and the November 25th spec release introduced many new features, including asynchronous operations, statelessness, server identity, and official extensions. There are also official SDKs (Software Development Kits) for MCP in all major programming languages with 97M+ monthly SDK downloads across Python and TypeScript. &lt;lb/&gt;Since its inception, we’ve been committed to ensuring MCP remains open-source, community-driven and vendor-neutral. Today, we further that commitment by donating MCP to the Linux Foundation.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Linux Foundation and the Agentic AI Foundation&lt;/head&gt;
    &lt;p&gt;The Linux Foundation is a non-profit organization dedicated to fostering the growth of sustainable, open-source ecosystems through neutral stewardship, community building, and shared infrastructure. It has decades of experience stewarding the most critical and globally-significant open-source projects, including The Linux Kernel, Kubernetes, Node.js, and PyTorch. Importantly, the Linux Foundation has a proven track record in facilitating open collaboration and maintaining vendor neutrality.&lt;/p&gt;
    &lt;p&gt;The Agentic AI Foundation (AAIF) is a directed fund under the Linux Foundation co-founded by Anthropic, Block and OpenAI, with support from Google, Microsoft, AWS, Cloudflare and Bloomberg. The AAIF aims to ensure agentic AI evolves transparently, collaboratively, and in the public interest through strategic investment, community building, and shared development of open standards.&lt;/p&gt;
    &lt;head rend="h2"&gt;Donating the Model Context Protocol&lt;/head&gt;
    &lt;p&gt;Anthropic is donating the Model Context Protocol to the Linux Foundation's new Agentic AI Foundation, where it will join goose by Block and AGENTS.md by OpenAI as founding projects. Bringing these and future projects under the AAIF will foster innovation across the agentic AI ecosystem and ensure these foundational technologies remain neutral, open, and community-driven. &lt;lb/&gt;The Model Context Protocol’s governance model will remain unchanged: the project’s maintainers will continue to prioritize community input and transparent decision-making.&lt;/p&gt;
    &lt;head rend="h2"&gt;The future of MCP&lt;/head&gt;
    &lt;p&gt;Open-source software is essential for building a secure and innovative ecosystem for agentic AI. Today’s donation to the Linux Foundation demonstrates our commitment to ensuring MCP remains a neutral, open standard. We’re excited to continue contributing to MCP and other agentic AI projects through the AAIF.&lt;lb/&gt;Learn more about MCP at modelcontextprotocol.io and get involved with the AAIF here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46207425</guid><pubDate>Tue, 09 Dec 2025 17:05:42 +0000</pubDate></item><item><title>PeerTube is recognized as a digital public good by Digital Public Goods Alliance</title><link>https://www.digitalpublicgoods.net/r/peertube</link><description>&lt;doc fingerprint="95773f811edde224"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;PeerTube&lt;/head&gt;
    &lt;p&gt;Verified DPG&lt;/p&gt;
    &lt;head rend="h3"&gt;Owner&lt;/head&gt;
    &lt;p&gt;Framasoft&lt;/p&gt;
    &lt;head rend="h3"&gt;Type&lt;/head&gt;
    &lt;p&gt;backend, mobile, web&lt;/p&gt;
    &lt;head rend="h3"&gt;Licence&lt;/head&gt;
    &lt;p&gt;AGPL-3.0&lt;/p&gt;
    &lt;head rend="h3"&gt;Last evaluated&lt;/head&gt;
    &lt;p&gt;07.10.2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Origin country&lt;/head&gt;
    &lt;p&gt;France&lt;/p&gt;
    &lt;head rend="h3"&gt;Release date&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;head rend="h3"&gt;DPG since&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;head rend="h3"&gt;Description&lt;/head&gt;
    &lt;p&gt;PeerTube is a tool for hosting, managing, and sharing videos or live streams.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core Components Assessed/Included Repositories&lt;/head&gt;
    &lt;p&gt;The following repositories were submitted by the solution and included in our evaluation. Any repositories, add-ons, features not included in here were not reviewed by us.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feature&lt;/head&gt;
    &lt;head rend="h3"&gt;Scale of the Solution*&lt;/head&gt;
    &lt;head rend="h3"&gt;Connected members&lt;/head&gt;
    &lt;p&gt;N/A&lt;/p&gt;
    &lt;head rend="h3"&gt;Participated Programs&lt;/head&gt;
    &lt;p&gt;N/A&lt;/p&gt;
    &lt;head rend="h3"&gt;Available Languages&lt;/head&gt;
    &lt;p&gt;Esperanto, English, Slovenčina, Gàidhlig, العربية, Norsk, Magyar, Deutsch, Toki Pona, Euskara, Polski, Português (Portugal), Suomi, Tiếng Việt, Italiano, فارسی, Español, Taqbaylit, 简体中文（中国）, Hrvatski, ελληνικά, Occitan, украї́нська мо́ва, Français, ไทย, Türkçe, 繁體中文（台灣）, 日本語, Galego, Íslenska, Svenska, Nederlands, Pусский, bokmål, Čeština, Shqip, Català, Português (Brasil), Norsk nynorsk&lt;/p&gt;
    &lt;head rend="h3"&gt;Organisations using it&lt;/head&gt;
    &lt;p&gt;French Ministry of National Education (~100K videos), Italy’s National Research Council, a few French alternative media, the Weißensee Kunsthochschule in Berlin, as well as the Universität der Künste in the same city, a few universities worldwide, the Blender and Debian projects, and various activist groups&lt;/p&gt;
    &lt;p&gt;* This information is self-reported and updated annually&lt;/p&gt;
    &lt;head rend="h3"&gt;Github insights&lt;/head&gt;
    &lt;p&gt;Learn how this product has met the requirements of the DPG Standard by exploring the indicators below.&lt;/p&gt;
    &lt;head rend="h3"&gt;Application Details&lt;/head&gt;
    &lt;head rend="h4"&gt;DPG ID&lt;/head&gt;
    &lt;head rend="h4"&gt;GID0092472&lt;/head&gt;
    &lt;head rend="h4"&gt;Status&lt;/head&gt;
    &lt;head rend="h4"&gt;DPG&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Created&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-08-11&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Submitted&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-08-25&lt;/head&gt;
    &lt;head rend="h4"&gt;Date Reviewed&lt;/head&gt;
    &lt;head rend="h4"&gt;2025-10-07&lt;/head&gt;
    &lt;head rend="h4"&gt;Date of Expiry&lt;/head&gt;
    &lt;head rend="h4"&gt;2026-10-07&lt;/head&gt;
    &lt;head rend="h3"&gt;Application Log Details&lt;/head&gt;
    &lt;head rend="h4"&gt;Timestamp&lt;/head&gt;
    &lt;head rend="h4"&gt;Activity&lt;/head&gt;
    &lt;p&gt;2025-10-07 08:40:13&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) submitted their review of PeerTube (152) and found it to be a DPG&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:12&lt;/p&gt;
    &lt;p&gt;System unmarked PeerTube (12958) as a nominee&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:07&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) passed 4. Platform Independence for PeerTube (12958)&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:40:02&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) moved PeerTube (12958) to under review&lt;/p&gt;
    &lt;p&gt;2025-10-07 08:38:21&lt;/p&gt;
    &lt;p&gt;Ricardo Torres (L2 Reviewer) finished consultation on 4. Platform Independence for PeerTube (12958)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46207464</guid><pubDate>Tue, 09 Dec 2025 17:08:37 +0000</pubDate></item><item><title>If you're going to vibe code, why not do it in C?</title><link>https://stephenramsay.net/posts/vibe-coding.html</link><description>&lt;doc fingerprint="af2319bf33f607dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;If You’re Going to Vibe Code, Why Not Do It in C?&lt;/head&gt;
    &lt;p&gt;Stephen Ramsay&lt;/p&gt;
    &lt;p&gt;Or hell, why not do it in x86 assembly?&lt;/p&gt;
    &lt;p&gt;Let’s get a few things out of the way before I go any further with this seemingly impertinent thought, because it’s nowhere near as snarky as it sounds.&lt;/p&gt;
    &lt;p&gt;First, I don’t particularly like vibe coding. I love programming, and I have loved it since I made my first tentative steps with it sometime back in the mid-to-late 90s. I love programming so much, it always feels like I’m having too much fun for it to count as real work. I’ve done it professionally, but I also do it as a hobby. Someone apparently once said, “Do what you love and you’ll never work a day in your life.” That’s how I feel about writing code. I’ve also been teaching the subject for twenty-five years, and I can honestly say I am as excited about the first day of the semester now as I was when I first started. I realize it’s a bit precious to say so, but I’ll say it anyway: Turning non-programmers into programmers is my life’s work. It is the thing of which I am most proud as a college professor.&lt;/p&gt;
    &lt;p&gt;Vibe coding makes me feel dirty in ways that I struggle to articulate precisely. It’s not just that it feels like “cheating” (though it does). I also think it takes a lot of the fun out of the whole thing. I sometimes tell people (like the aforementioned students) that programming is like doing the best crossword puzzle in the world, except that when you solve it, it actually dances and sings. Vibe coding robs me of that moment, because I don’t feel like I really did it at all. And even though to be a programmer is to live with a more-or-less permanent set of aporias (you don’t really understand what the compiler is doing, really—and even if you do, you probably don’t really understand how the virtual memory subsystem works, really), it’s satisfying to understand every inch of my code and frustrating—all the way to the borderlands of active anxiety—not quite understanding what Claude just wrote.&lt;/p&gt;
    &lt;p&gt;But this leads me to my second point, which I must make as clearly and forcefully as I can. Vibe coding actually works. It creates robust, complex systems that work. You can tell yourself (as I did) that it can’t possibly do that, but you are wrong. You can then tell yourself (as I did) that it’s good as a kind of alternative search engine for coding problems, but not much else. You are also wrong about that. Because when you start giving it little programming problems that you can’t be arsed to work out yourself (as I did), you discover (as I did) that it’s awfully good at those. And then one day you muse out loud (as I did) to an AI model something like, “I have an idea for a program…” And you are astounded. If you aren’t astounded, you either haven’t actually done it or you are at some stage of grief prior to acceptance. Perfect? Hardly. But then neither are human coders. The future? I think the questions answers itself.&lt;/p&gt;
    &lt;p&gt;But to get to my impertinent question…&lt;/p&gt;
    &lt;p&gt;Early on in my love affair with programming, I read Structure and Interpretation of Computer Programs, which I now consider one of the great pedagogical masterpieces of the twentieth century. I learned a great deal about programming from that book, but among the most memorable lessons was one that appears in the second paragraph of the original preface. There, Hal Abelson and Gerald Sussman make a point that hits with the force of the obvious, and yet is very often forgotten:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[W]e want to establish the idea that a computer language is not just a way of getting a computer to perform operations but rather that it is a novel formal medium for expressing ideas about methodology. Thus, programs must be written for people to read, and only incidentally for machines to execute.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I’ve been repeating some version of this to my students ever since. Computers, I remind them, do not need the code to be “readable” or “ergonomic” for humans; they only need it to be readable and ergonomic for a computer, which is a considerably lower bar.&lt;/p&gt;
    &lt;p&gt;Every programming language—including assembly language—was and is intended for the convenience of humans who need to read it and write it. If a language is innovative, it is usually not because it has allowed for automatic memory management, or concurrency, or safety, or robust error checking, but because it has made it easier for humans to express and reason about these matters. When we extol the virtues of this or that language—Rust’s safety guarantees, C++’s “no-cost abstractions,” or Go’s approach to concurrency—we are not talking about an affordance that the computer has gained, but about an affordance that we have gained as programmers of said computer. From our standpoint as programmers, object-oriented languages offer certain ways to organize our code—and, I think Abelson and Sussman would say, our thinking—that are potentially conducive to the noble treasures of maintainability, extensibility, error checking, and any number of other condign matters. From the standpoint of the computer, this little OO kink of ours seems mostly to indicate a strange affinity for heap memory. “Whatevs!” (says the computer). And pick your poison here, folks: functional programming, algebraic data types, dependent types, homoiconicity, immutable data structures, brace styles… We can debate the utility of these things, but we must understand that we are primarily talking about human problems. The set of “machine problems” to which these matters correspond is considerably smaller.&lt;/p&gt;
    &lt;p&gt;So my question is this: Why vibe code with a language that has human convenience and ergonomics in view? Or to put that another way: Wouldn’t a language designed for vibe coding naturally dispense with much of what is convenient and ergonomic for humans in favor of what is convenient and ergonomic for machines? Why not have it just write C? Or hell, why not x86 assembly?&lt;/p&gt;
    &lt;p&gt;Now, at this point, you will want to say that the need for human understanding isn’t erased entirely thereby. Some version of this argument has merit, but I would remind you that if you are really vibe coding for real you already don’t understand a great deal of what it is producing. But if you look carefully, you will notice that it doesn’t struggle with undefined behavior in C. Or with making sure that all memory is properly freed. Or with off-by-one errors. It sometimes struggles to understand what it is that you actually want, but it rarely struggles with the actual execution of the code. It’s better than you are at keeping track of those things in the same way that a compiler is better at optimizing code than you are. Perfect? No. But as I said before…&lt;/p&gt;
    &lt;p&gt;Is C the ideal language for vibe coding? I think I could mount an argument for why it is not, but surely Rust is even less ideal. To say nothing of Haskell, or OCaml, or even Python. All of these languages, after all, are for people to read, and only incidentally for machines to execute. They are practically adorable in their concern for problems that AI models do not have.&lt;/p&gt;
    &lt;p&gt;I suppose what I’m getting at, here, is that if vibe coding is the future of software development (and it is), then why bother with languages that were designed for people who are not vibe coding? Shouldn’t there be such a thing as a “vibe-oriented programming language?” VOP. You read it here first.&lt;/p&gt;
    &lt;p&gt;One possibility is that such a language truly would be executable pseudocode beyond even the most extravagant fever dreams of the most earnest Pythonistas; it shows you what it’s doing in truly pseudo code, but all the while it’s writing assembly. Or perhaps it’s something like the apotheosis of literate programming. You write a literary document “expressing ideas about methodology,” and the AI produces machine code (and a kind of literary critical practice evolves around this activity, eventually ordering itself into structuralist and post-structuralist camps. But I’m getting ahead of myself). Perhaps your job as a programmer is mostly running tests that verify this machine code (tests which have also been produced by AI). Or maybe a VOPL is really a certain kind of language that comes closer to natural language than any existing programming language, but which has a certain (easily learned) set of idioms and expressions that guide the AI more reliably and more quickly toward particular solutions. It doesn’t have goroutines. It has a “concurrency slang.”&lt;/p&gt;
    &lt;p&gt;Now obviously, the reason a large language model focused on coding is good at Javascript and C++ is precisely because it has been trained on billions of lines of code in those languages along with countless forum posts, StackOverflow debates, and so on. Bootstrapping a VOPL presents a certain kind of difficulty, but then one also suspects that LLMs are already being trained in some future version of this language, because so many programmers are already groping their way toward a system like this by virtue of the fact that so many of them are already vibe coding production-level systems.&lt;/p&gt;
    &lt;p&gt;I don’t know how I feel about all of this (see my first and second points above). It saddens me to think of “coding by hand” becoming a kind of quaint Montessori-school stage in the education of a vibe coder—something like the contour drawings we demand from future photoshopers or the balanced equations we insist serve as a rite of passage for people who will never be without a calculator to the end of their days.&lt;/p&gt;
    &lt;p&gt;At the same time, there is something exciting about the birth of a computational paradigm. It wasn’t that long ago, in the grand scheme of things, that someone realized that rewiring the entire machine every time you wanted to do a calculation (think ENIAC, circa 1945) was a rather suboptimal way to do things. And it is worth recalling that people complained when the stored-program computer rolled around (think EDVAC, circa 1951). Why? Well, the answer should be obvious. It was less reliable. It was slower. It removed the operator from the loop. It threatened specialized labor. It was conceptually impure. I’m not kidding about any of this. No less an authority than Grace Hopper had to argue against the quite popular idea that there was no way anyone could ever trust a machine to write instructions for another machine.&lt;/p&gt;
    &lt;p&gt;Same vibe, as the kids say.&lt;/p&gt;
    &lt;p&gt;Keywords: programming, AI&lt;/p&gt;
    &lt;p&gt;Last Modified: 2025-12-07T16:29:42:-0600&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46207505</guid><pubDate>Tue, 09 Dec 2025 17:11:09 +0000</pubDate></item><item><title>The stack circuitry of the Intel 8087 floating point chip, reverse-engineered</title><link>https://www.righto.com/2025/12/8087-stack-circuitry.html</link><description>&lt;doc fingerprint="2b5a4030cd17f258"&gt;
  &lt;main&gt;
    &lt;p&gt;Early microprocessors were very slow when operating with floating-point numbers. But in 1980, Intel introduced the 8087 floating-point coprocessor, performing floating-point operations up to 100 times faster. This was a huge benefit for IBM PC applications such as AutoCAD, spreadsheets, and flight simulators. The 8087 was so effective that today's computers still use a floating-point system based on the 8087.1&lt;/p&gt;
    &lt;p&gt;The 8087 was an extremely complex chip for its time, containing somewhere between 40,000 and 75,000 transistors, depending on the source.2 To explore how the 8087 works, I opened up a chip and took numerous photos of the silicon die with a microscope. Around the edges of the die, you can see the hair-thin bond wires that connect the chip to its 40 external pins. The complex patterns on the die are formed by its metal wiring, as well as the polysilicon and silicon underneath. The bottom half of the chip is the "datapath", the circuitry that performs calculations on 80-bit floating point values. At the left of the datapath, a constant ROM holds important constants such as π. At the right are the eight registers that form the stack, along with the stack control circuitry.&lt;/p&gt;
    &lt;p&gt;The chip's instructions are defined by the large microcode ROM in the middle. This ROM is very unusual; it is semi-analog, storing two bits per transistor by using four transistor sizes. To execute a floating-point instruction, the 8087 decodes the instruction and the microcode engine starts executing the appropriate micro-instructions from the microcode ROM. The decode circuitry to the right of the ROM generates the appropriate control signals from each micro-instruction. The bus registers and control circuitry handle interactions with the main 8086 processor and the rest of the system. Finally, the bias generator uses a charge pump to create a negative voltage to bias the chip's substrate, the underlying silicon.&lt;/p&gt;
    &lt;p&gt;The stack registers and control circuitry (in red above) are the subject of this blog post. Unlike most processors, the 8087 organizes its registers in a stack, with instructions operating on the top of the stack. For instance, the square root instruction replaces the value on the top of the stack with its square root. You can also access a register relative to the top of the stack, for instance, adding the top value to the value two positions down from the top. The stack-based architecture was intended to improve the instruction set, simplify compiler design, and make function calls more efficient, although it didn't work as well as hoped.&lt;/p&gt;
    &lt;p&gt;The diagram above shows how the stack operates. The stack consists of eight registers, with the Stack Top (ST) indicating the current top of the stack. To push a floating-point value onto the stack, the Stack Top is decremented and then the value is stored in the new top register. A pop is performed by copying the value from the stack top and then incrementing the Stack Top. In comparison, most processors specify registers directly, so register 2 is always the same register.&lt;/p&gt;
    &lt;head rend="h2"&gt;The registers&lt;/head&gt;
    &lt;p&gt;The stack registers occupy a substantial area on the die of the 8087 because floating-point numbers take many bits. A floating-point number consists of a fractional part (sometimes called the mantissa or significand), along with the exponent part; the exponent allows floating-point numbers to cover a range from extremely small to extremely large. In the 8087, floating-point numbers are 80 bits: 64 bits of significand, 15 bits of exponent, and a sign bit. An 80-bit register was very large in the era of 8-bit or 16-bit computers; the eight registers in the 8087 would be equivalent to 40 registers in the 8086 processor.&lt;/p&gt;
    &lt;p&gt;The registers store each bit in a static RAM cell. Each cell has two inverters connected in a loop. This circuit forms a stable feedback loop, with one inverter on and one inverter off. Depending on which inverter is on, the circuit stores a 0 or a 1. To write a new value into the circuit, one of the lines is pulled low, flipping the loop into the desired state. The trick is that each inverter uses a very weak transistor to pull the output high, so its output is easily overpowered to change the state.&lt;/p&gt;
    &lt;p&gt;These inverter pairs are arranged in an 8 × 80 grid that implements eight words of 80 bits. Each of the 80 rows has two bitlines that provide access to a bit. The bitlines provide both read and write access to a bit; the pair of bitlines allows either inverter to be pulled low to store the desired bit value. Eight vertical wordlines enable access to one word, one column of 80 bits. Each wordline turns on 160 pass transistors, connecting the bitlines to the inverters in the selected column. Thus, when a wordline is enabled, the bitlines can be used to read or write that word.&lt;/p&gt;
    &lt;p&gt;Although the chip looks two-dimensional, it actually consists of multiple layers. The bottom layer is silicon. The pinkish regions below are where the silicon has been "doped" to change its electrical properties, making it an active part of the circuit. The doped silicon forms a grid of horizontal and vertical wiring, with larger doped regions in the middle. On top of the silicon, polysilicon wiring provides two functions. First, it provides a layer of wiring to connect the circuit. But more importantly, when polysilicon crosses doped silicon, it forms a transistor. The polysilicon provides the gate, turning the transistor on and off. In this photo, the polysilicon is barely visible, so I've highlighted part of it in red. Finally, horizontal metal wires provide a third layer of interconnecting wiring. Normally, the metal hides the underlying circuitry, so I removed the metal with acid for this photo. I've drawn blue lines to represent the metal layer. Contacts provide connections between the various layers.&lt;/p&gt;
    &lt;p&gt;The layers combine to form the inverters and selection transistors of a memory cell, indicated with the dotted line below. There are six transistors (yellow), where polysilicon crosses doped silicon. Each inverter has a transistor that pulls the output low and a weak transistor to pull the output high. When the word line (vertical polysilicon) is active, it connects the selected inverters to the bit lines (horizontal metal) through the two selection transistors. This allows the bit to be read or written.&lt;/p&gt;
    &lt;p&gt;Each register has two tag bits associated with it, an unusual form of metadata to indicate if the register is empty, contains zero, contains a valid value, or contains a special value such as infinity. The tag bits are used to optimize performance internally and are mostly irrelevant to the programmer. As well as being accessed with a register, the tag bits can be accessed in parallel as a 16-bit "Tag Word". This allows the tags to be saved or loaded as part of the 8087's state, for instance, during interrupt handling.&lt;/p&gt;
    &lt;head rend="h2"&gt;The decoder&lt;/head&gt;
    &lt;p&gt;The decoder circuit, wedged into the middle of the register file, selects one of the registers. A register is specified internally with a 3-bit value. The decoder circuit energizes one of the eight register select lines based on this value.&lt;/p&gt;
    &lt;p&gt;The decoder circuitry is straightforward: it has eight 3-input NOR gates to match one of the eight bit patterns. The select line is then powered through a high-current driver that uses large transistors. (In the photo below, you can compare the large serpentine driver transistors to the small transistors in a bit cell.)&lt;/p&gt;
    &lt;p&gt;The decoder has an interesting electrical optimization. As shown earlier, the register select lines are eight polysilicon lines running vertically, the length of the register file. Unfortunately, polysilicon has fairly high resistance, better than silicon but much worse than metal. The problem is that the resistance of a long polysilicon line will slow down the system. That is, the capacitance of transistor gates in combination with high resistance causes an RC (resistive-capacitive) delay in the signal.&lt;/p&gt;
    &lt;p&gt;The solution is that the register select lines also run in the metal layer, a second set of lines immediately to the right of the register file. These lines branch off from the register file about 1/3 of the way down, run to the bottom, and then connect back to the polysilicon select lines at the bottom. This reduces the maximum resistance through a select line, increasing the speed.&lt;/p&gt;
    &lt;head rend="h2"&gt;The stack control circuitry&lt;/head&gt;
    &lt;p&gt;A stack needs more control circuitry than a regular register file, since the circuitry must keep track of the position of the top of the stack.3 The control circuitry increments and decrements the top of stack (TOS) pointer as values are pushed or popped (purple).4 Moreover, an 8087 instruction can access a register based on its offset, for instance the third register from the top. To support this, the control circuitry can temporarily add an offset to the top of stack position (green). A multiplexer (red) selects either the top of stack or the adder output, and feeds it to the decoder (blue), which selects one of the eight stack registers in the register file (yellow), as described earlier.&lt;/p&gt;
    &lt;p&gt;The physical implementation of the stack circuitry is shown below. The logic at the top selects the stack operation based on the 16-bit micro-instruction.5 Below that are the three latches that hold the top of stack value. (The large white squares look important, but they are simply "jumpers" from the ground line to the circuitry, passing under metal wires.)&lt;/p&gt;
    &lt;p&gt;The three-bit adder is at the bottom, along with the multiplexer. You might expect the adder to use a simple "full adder" circuit. Instead, it is a faster carry-lookahead adder. I won't go into details here, but the summary is that at each bit position, an AND gate produces a Carry Generate signal while an XOR gate produces a Carry Propagate signal. Logic gates combine these signals to produce the output bits in parallel, avoiding the slowdown of the carry rippling through the bits.&lt;/p&gt;
    &lt;p&gt;The incrementer/decrementer uses a completely different approach. Each of the three bits uses a toggle flip-flop. A few logic gates determine if each bit should be toggled or should keep its previous value. For instance, when incrementing, the top bit is toggled if the lower bits are 11 (e.g. incrementing from 011 to 100). For decrementing, the top bit is toggled if the lower bits are 00 (e.g. 100 to 011). Simpler logic determines if the middle bit should be toggled. The bottom bit is easier, toggling every time whether incrementing or decrementing.&lt;/p&gt;
    &lt;p&gt;The schematic below shows the circuitry for one bit of the stack. Each bit is implemented with a moderately complicated flip-flop that can be cleared, loaded with a value, or toggled, based on control signals from the microcode. The flip-flop is constructed from two set-reset (SR) latches. Note that the flip-flop outputs are crossed when fed back to the input, providing the inversion for the toggle action. At the right, the multiplexer selects either the register value or the sum from the adder (not shown), generating the signals to the decoder.&lt;/p&gt;
    &lt;head rend="h2"&gt;Drawbacks of the stack approach&lt;/head&gt;
    &lt;p&gt;According to the designers of the 8087,7 the main motivation for using a stack rather than a flat register set was that instructions didn't have enough bits to address multiple register operands. In addition, a stack has "advantages over general registers for expression parsing and nested function calls." That is, a stack works well for a mathematical expression since sub-expressions can be evaluated on the top of the stack. And for function calls, you avoid the cost of saving registers to memory, since the subroutine can use the stack without disturbing the values underneath. At least that was the idea.&lt;/p&gt;
    &lt;p&gt;The main problem is "stack overflow". The 8087's stack has eight entries, so if you push a ninth value onto the stack, the stack will overflow. Specifically, the top-of-stack pointer will wrap around, obliterating the bottom value on the stack. The 8087 is designed to detect a stack overflow using the register tags: pushing a value to a non-empty register triggers an invalid operation exception.6&lt;/p&gt;
    &lt;p&gt;The designers expected that stack overflow would be rare and could be handled by the operating system (or library code). After detecting a stack overflow, the software should dump the existing stack to memory to provide the illusion of an infinite stack. Unfortunately, bad design decisions made it difficult "both technically and commercially" to handle stack overflow.&lt;/p&gt;
    &lt;p&gt;One of the 8087's designers (Kahan) attributes the 8087's stack problems to the time difference between California, where the designers lived, and Israel, where the 8087 was implemented. Due to a lack of communication, each team thought the other was implementing the overflow software. It wasn't until the 8087 was in production that they realized that "it might not be possible to handle 8087 stack underflow/overflow in a reasonable way. It's not impossible, just impossible to do it in a reasonable way."&lt;/p&gt;
    &lt;p&gt;As a result, the stack was largely a problem rather than a solution. Most 8087 software saved the full stack to memory before performing a function call, creating more memory traffic. Moreover, compilers turned out to work better with regular registers than a stack, so compiler writers awkwardly used the stack to emulate regular registers. The &lt;code&gt;GCC&lt;/code&gt; compiler reportedly needs 3000 lines of extra code to support the x87 stack.&lt;/p&gt;
    &lt;p&gt;In the 1990s, Intel introduced a new floating-point system called SSE, followed by AVX in 2011. These systems use regular (non-stack) registers and provide parallel operations for higher performance, making the 8087's stack instructions largely obsolete.&lt;/p&gt;
    &lt;head rend="h2"&gt;The success of the 8087&lt;/head&gt;
    &lt;p&gt;At the start, Intel was unenthusiastic about producing the 8087, viewing it as unlikely to be a success. John Palmar, a principal architect of the chip, had little success convincing skeptical Intel management that the market for the 8087 was enormous. Eventually, he said, "I'll tell you what. I'll relinquish my salary, provided you'll write down your number of how many you expect to sell, then give me a dollar for every one you sell beyond that."7 Intel didn't agree to the deal—which would have made a fortune for Palmer—but they reluctantly agreed to produce the chip.&lt;/p&gt;
    &lt;p&gt;Intel's Santa Clara engineers shunned the 8087, considering it unlikely to work: the 8087 would be two to three times more complex than the 8086, with a die so large that a wafer might not have a single working die. Instead, Rafi Nave, at Intel's Israel site, took on the risky project: “Listen, everybody knows it's not going to work, so if it won't work, I would just fulfill their expectations or their assessment. If, by chance, it works, okay, then we'll gain tremendous respect and tremendous breakthrough on our abilities.”&lt;/p&gt;
    &lt;p&gt;A small team of seven engineers developed the 8087 in Israel. They designed the chip on Mylar sheets: a millimeter on Mylar represented a micron on the physical chip. The drawings were then digitized on a Calma system by clicking on each polygon to create the layout. When the chip was moved into production, the yield was very low but better than feared: two working dies per four-inch wafer.&lt;/p&gt;
    &lt;p&gt;The 8087 ended up being a large success, said to have been Intel's most profitable product line at times. The success of the 8087 (along with the 8088) cemented the reputation of Intel Israel, which eventually became Israel's largest tech employer. The benefits of floating-point hardware proved to be so great that Intel integrated the floating-point unit into later processors starting with the 80486 (1989). Nowadays, most modern computers, from cellphones to mainframes, provide floating point based on the 8087, so I consider the 8087 one of the most influential chips ever created.&lt;/p&gt;
    &lt;p&gt;For more, follow me on Bluesky (@righto.com), Mastodon (@[email protected]), or RSS. I wrote some articles about the 8087 a few years ago, including the die, the ROM, the bit shifter, and the constants, so you may have seen some of this material before.&lt;/p&gt;
    &lt;head rend="h2"&gt;Notes and references&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Most computers now use the IEEE 754 floating-point standard, which is based on the 8087. This standard has been awarded a milestone in computation. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Curiously, reliable sources differ on the number of transistors in the 8087 by almost a factor of 2. Intel says 40,000, as does designer William Kahan (link). But in A Numeric Data Processor, designers Rafi Nave and John Palmer wrote that the chip contains "the equivalent of over 65,000 devices" (whatever "equivalent" means). This number is echoed by a contemporary article in Electronics (1980) that says "over 65,000 H-MOS transistors on a 78,000-mil2 die." Many other sources, such as Upgrading &amp;amp; Repairing PCs, specify 45,000 transistors. Designer Rafi Nave stated that the 8087 has 63,000 or 64,000 transistors if you count the ROM transistors directly, but if you count ROM transistors as equivalent to two transistors, then you get about 75,000 transistors. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The 8087 has a 16-bit Status Word that contains the stack top pointer, exception flags, the four-bit condition code, and other values. Although the Status Word appears to be a 16-bit register, it is not implemented as a register. Instead, parts of the Status Word are stored in various places around the chip: the stack top pointer is in the stack circuitry, the exception flags are part of the interrupt circuitry, the condition code bits are next to the datapath, and so on. When the Status Word is read or written, these various circuits are connected to the 8087's internal data bus, making the Status Word appear to be a monolithic entity. Thus, the stack circuitry includes support for reading and writing it. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Intel filed several patents on the 8087, including Numeric data processor, another Numeric data processor, Programmable bidirectional shifter, Fraction bus for use in a numeric data processor, and System bus arbitration, circuitry and methodology. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I started looking at the stack in detail to reverse engineer the micro-instruction format and determine how the 8087's microcode works. I'm working with the "Opcode Collective" on Discord on this project, but progress is slow due to the complexity of the micro-instructions. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The 8087 detects stack underflow in a similar manner. If you pop more values from the stack than are present, the tag will indicate that the register is empty and shouldn't be accessed. This triggers an invalid operation exception. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The 8087 is described in detail in The 8086 Family User's Manual, Numerics Supplement. An overview of the stack is on page 60 of The 8087 Primer by Palmer and Morse. More details are in Kahan's On the Advantages of the 8087's Stack, an unpublished course note (maybe for CS 279?) with a date of Nov 2, 1990 or perhaps August 23, 1994. Kahan discusses why the 8087's design makes it hard to handle stack overflow in How important is numerical accuracy, Dr. Dobbs, Nov. 1997. Another information source is the Oral History of Rafi Nave ↩↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46208409</guid><pubDate>Tue, 09 Dec 2025 18:16:44 +0000</pubDate></item><item><title>So you want to speak at software conferences?</title><link>https://dylanbeattie.net/2025/12/08/so-you-want-to-speak-at-software-conferences.html</link><description>&lt;doc fingerprint="6278511b9fc389bd"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;So You Want To Speak At Software Conferences?&lt;/head&gt;Posted by Dylan Beattie on 08 December 2025 • permalink&lt;p&gt;I run a .NET user group here in London, and we host a lot of talks from people who are relatively inexperienced presenters. Sometimes they’ve done presentations internally but never spoken before a public audience. Sometimes they’re developers who have been in theatre or played in bands; people with plenty of stage experience but who haven’t presented on technical topics before - and sometimes they’ve never done any kind of public presentations or performance at all. We aim to be a friendly, supportive crowd; public speaking can be daunting, and the first public outing of somebody’s first talk can be… let’s just say that the presenter sometimes learns a lot more than the audience, and leave it at that.&lt;/p&gt;&lt;p&gt;But it can also be a hugely rewarding experience, and as a seasoned tech presenter who’s been doing this for a while, aspiring speakers often ask me for advice on how to take it to the next level.&lt;/p&gt;&lt;p&gt;Before we get into the specifics, there are two things to bear in mind.&lt;/p&gt;&lt;p&gt;One: ask yourself why you want to do this. What does “the next level” mean for you? Are you looking to promote your consultancy, or your training courses, or your software products? Do you want to become a professional speaker and actually get paid to give talks? Are you doing it ‘cos you want to go places and meet people? Figure out what “success” looks like for you.&lt;/p&gt;&lt;p&gt;Two: be realistic about how much work is involved. It took me seven years to go from my first user group lightning talk, back 2008, to my first international conference. If you think you can hack together some code, write a talk about it, stick it on Sessionize and three months later you’re on your way to a major international event like NDC or Yow! or Devoxx… well, no. That’s not how this works. Strap in; it’s a long ride.&lt;/p&gt;&lt;head rend="h3"&gt;Year 1: Get Good&lt;/head&gt;&lt;p&gt;Write the talk. Write a talk nobody else could do; tell a story nobody else can tell. Figure out what your audience is going to learn, and why you’re the best person to teach them that. Then give it at local user group. It might go great. It might be a train wreck. Don’t worry. That’s one of the reasons user groups exist. Learn from the experience. Fix the demos. Fix the slides. If it was too short? Write some more. If it was too long? Cut something. Give it at another user group. Do it again. Do it again. Maybe write a second talk, shop that one around a couple of user groups too.&lt;/p&gt;&lt;p&gt;If you can’t find user groups, look on Meetup.com. Yes, it’s a horrible platform, but it works; search by topic, search by region, find groups that look like a good match for your content, and ask if they’re looking for speakers. They probably are.&lt;/p&gt;&lt;head rend="h3"&gt;Year 2: Get Seen&lt;/head&gt;&lt;p&gt;After user groups and meetups come the community conferences. Typically small, one-day events, with a few tracks, and usually free (or very cheap) to attend. For me, these were the DDD events _(that’s DDD as in Developers! Developers! Developers!, not to be confused with DDD as in Domain Driven Design), _a series of one-day free developer events around the UK, organised by volunteers, usually on a Saturday so people don’t have to take time off work. They bring in a good crowd, they’re a great way to get to know other presenters and people who are involved in tech events, and you’ll almost certainly meet a few people who are on the programme committees for the bigger conferences.&lt;/p&gt;&lt;p&gt;Events like this are your chance to get noticed. Turn up the day before, join the pre-conference dinner and drinks, introduce yourself. Yeah, it’s awkward when you don’t know anybody. There will be other people there who don’t know anybody and will appreciate you making the effort. Enjoy yourself, but don’t end up doing tequila shots in a karaoke bar at 3am. Not now. You’re there to give a talk, remember?&lt;/p&gt;&lt;p&gt;Go to the event. Spend the whole day there, do your talk, watch the other sessions. Communicate with the organisers. You don’t want their memorable impression of you to be a half-hour of panic and missed calls because one of their speakers has gone AWOL and nobody knows where they are.&lt;/p&gt;&lt;p&gt;Figure out how to keep in touch with the people you met. Join the Signal or WhatsApp group chat; if there isn’t one, create one. Follow them on LinkedIn, or Bluesky - be prepared to go where people are; don’t expect folks to join Mastodon just because that’s where you want to talk to them. That’s not how this works. If you really don’t want to play the social media game - and I can’t blame you - there’s always good old-fashioned email. A short email a week later saying “hey, thanks for having me” or “hey, I loved your session at DDD, let’s keep in touch” can pay off in a big way.&lt;/p&gt;&lt;p&gt;Finally, watch out for events that put video of their sessions online. Having a couple of YouTube links of you doing your thing in front of a live, appreciate audience can make all the difference when a programme committee is looking at a handful of talks and can only accept one of them.&lt;/p&gt;&lt;head rend="h3"&gt;Year 3: Get Accepted&lt;/head&gt;&lt;p&gt;You’ve got a couple of talks. You’ve delivered then enough times that you know they’re good *(and if they’re not good, make them good - or scrap them and write new ones)*. You know people. People know you. If somebody asks “hey, do we know anybody who could do a good session about $topic”, your name comes up. You’ve got a decent network of connections - group chats, LinkedIn, email addresses.&lt;/p&gt;&lt;p&gt;Now, find all the conferences in your field with an open Call for Papers (CfP), and get submitting. Dave Aronson over at codeasaur.us maintains a really useful list of CfPs which are closing soon. Check that regularly. Many events will cover your travel &amp;amp; hotel costs, although with sponsorship budgets drying up right across the industry that’s not as prevalent as it was a few years ago. If not, maybe you can persuade your employer to pay your travel - “hey, boss, if I can get a free ticket to this amazing conference with all these industry experts, do you think the company will pay my air fare &amp;amp; hotel?”&lt;/p&gt;&lt;p&gt;Lean on your network. What are people submitting to? Which events should you look out for? Which topics are getting a lot of traction (and which topics are not?)&lt;/p&gt;&lt;p&gt;Keep your content fresh. Write new talks. Keep giving them at user groups and community events.&lt;/p&gt;&lt;p&gt;Keep your submissions focused. 2-3 talks per event; don’t submit ten wildly different abstracts to the same conference in the hope one of them will get accepted. Every selection committee I’ve been on, if we see that, we assume the presenter hasn’t actually written *any* of them yet and is throwing everything they can think of into the mix and hoping one of them gets chosen. Not a great way to stand out. An open CFP at a big tech conference typically gets 20+ submissions for every available slot, which means if you reduce it to a numbers game, you’re submitting 20 talks for every one that gets accepted. Keep track of the numbers, and be objective about it.&lt;/p&gt;&lt;head rend="h3"&gt;Year 4: Get Bored.&lt;/head&gt;&lt;p&gt;It’s great fun doing this for a while… but it’s also exhausting. Some people hit it hard for a few years, do all the things, go to all the places, make a lot of great friends and happy memories, and then wake up one day and decide that’s enough. Some people do a few talks, tick it off their bucket list and decide that’s enough for them. Some settle into a gentle routine of 3-4 events they’ll do every year. And yes, some of us end up treating our calendars like a game of Tetris, juggling flights and trains and hotels and meetups and conferences and spending half the year on the road and the other half writing talks and workshops and all the other things it’s hard to do when you’re at the airport.&lt;/p&gt;&lt;p&gt;That’s why you gotta figure out ahead of time what “success” looks like. If you’re doing it for fun, remember to have fun - and if you find you’re not enjoying it any more? Stop. If you’re doing it as promotion or marketing? Track your leads. Make sure it’s actually generating the attention and the revenue it’s supposed to. If you’re doing it for money, be mercenary: no pay, no play. Not every event is the same, of course. In a given year I’ll have some events that are fun, some that are lucrative, some that are running alongside workshops or training engagements. Just make sure you know which is which.&lt;/p&gt;&lt;p&gt;Finally: respect your audience. Whether you’re talking to five people at a meetup, fifty at a community event, or five thousand at a huge international conference: those people are the reason you get to do this. They have given up their time - and often a substantial amount of money - to hear what you have to say. They deserve your best shot, every time. If you find you’re bored, fed up, tired, running talks on autopilot or making mistakes because you just don’t care? It’s time to try something else - and remember, there’s a thousand aspiring speakers out there who would dearly love to take that spot instead of you.&lt;/p&gt;&lt;p&gt;Now get out there. Work hard, have fun, teach us awesome things, and if you ever want me to look over an abstract or a slide deck, drop me a line - [email protected]. I’d be happy to help.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46208773</guid><pubDate>Tue, 09 Dec 2025 18:42:27 +0000</pubDate></item><item><title>10 Years of Let's Encrypt</title><link>https://letsencrypt.org/2025/12/09/10-years</link><description>&lt;doc fingerprint="6d5da1590926b3fa"&gt;
  &lt;main&gt;
    &lt;p&gt;On September 14, 2015, our first publicly-trusted certificate went live. We were proud that we had issued a certificate that a significant majority of clients could accept, and had done it using automated software. Of course, in retrospect this was just the first of billions of certificates. Today, Let’s Encrypt is the largest certificate authority in the world in terms of certificates issued, the ACME protocol we helped create and standardize is integrated throughout the server ecosystem, and we’ve become a household name among system administrators. We’re closing in on protecting one billion web sites.&lt;/p&gt;
    &lt;p&gt;In 2023, we marked the tenth anniversary of the creation of our nonprofit, Internet Security Research Group, which continues to host Let’s Encrypt and other public benefit infrastructure projects. Now, in honor of the tenth anniversary of Let’s Encrypt’s public certificate issuance and the start of the general availability of our services, we’re looking back at a few milestones and factors that contributed to our success.&lt;/p&gt;
    &lt;p&gt;A conspicuous part of Let’s Encrypt’s history is how thoroughly our vision of scalability through automation has succeeded.&lt;/p&gt;
    &lt;p&gt;In March 2016, we issued our one millionth certificate. Just two years later, in September 2018, we were issuing a million certificates every day. In 2020 we reached a billion total certificates issued and as of late 2025 we’re frequently issuing ten million certificates per day. We’re now on track to reach a billion active sites, probably sometime in the coming year. (The “certificates issued” and “certificates active” metrics are quite different because our certificates regularly expire and get replaced.)&lt;/p&gt;
    &lt;p&gt;The steady growth of our issuance volume shows the strength of our architecture, the validity of our vision, and the great efforts of our engineering team to scale up our own infrastructure. It also reminds us of the confidence that the Internet community is placing in us, making the use of a Let’s Encrypt certificate a normal and, dare we say, boring choice. But I often point out that our ever-growing issuance volumes are only an indirect measure of value. What ultimately matters is improving the security of people’s use of the web, which, as far as Let’s Encrypt’s contribution goes, is not measured by issuance volumes so much as by the prevalence of HTTPS encryption. For that reason, we’ve always emphasized the graph of the percentage of encrypted connections that web users make (here represented by statistics from Firefox).&lt;/p&gt;
    &lt;p&gt;(These graphs are snapshots as of the date of this post; a dynamically updated version is found on our stats page.) Our biggest goal was to make a concrete, measurable security impact on the web by getting HTTPS connection prevalence to increase—and it’s worked. It took five years or so to get the global percentage from below 30% to around 80%, where it’s remained ever since. In the U.S. it has been close to 95% for a while now.&lt;/p&gt;
    &lt;p&gt;A good amount of the remaining unencrypted traffic probably comes from internal or private organizational sites (intranets), but other than that we don’t know much about it; this would be a great topic for Internet security researchers to look into.&lt;/p&gt;
    &lt;p&gt;We believe our present growth in certificate issuance volume is essentially coming from growth in the web as a whole. In other words, if we protect 20% more sites over some time period, it’s because the web itself grew by 20%.&lt;/p&gt;
    &lt;p&gt;We’ve blogged about most of Let’s Encrypt’s most significant milestones as they’ve happened, and I invite everyone in our community to look over those blog posts to see how far we’ve come. We’ve also published annual reports for the past seven years, which offer elegant and concise summaries of our work.&lt;/p&gt;
    &lt;p&gt;As I personally think back on the past decade, just a few of the many events that come to mind include:&lt;/p&gt;
    &lt;p&gt;Telling the world about the project in November 2014&lt;/p&gt;
    &lt;p&gt;Our first certificate issuance in September 2015&lt;/p&gt;
    &lt;p&gt;Our one millionth certificate in March 2016, then our 100 millionth certificate in June 2017, and then our billionth certificate in 2020&lt;/p&gt;
    &lt;p&gt;Along the way, first issuing one million certificates in a single day (in September 2018), significantly contributed to by the SquareSpace and Shopify Let’s Encrypt integrations&lt;/p&gt;
    &lt;p&gt;Just at the end of September 2025, we issued more than ten million certificates in a day for the first time.&lt;/p&gt;
    &lt;p&gt;We’ve also periodically rolled out new features such as internationalized domain name support (2016), wildcard support (2018), and short-lived and IP address (2025) certificates. We’re always working on more new features for the future.&lt;/p&gt;
    &lt;p&gt;There are many technical milestones like our database server upgrades in 2021, where we found we needed a serious server infrastructure boost because of the tremendous volumes of data we were dealing with. Similarly, our original infrastructure was using Gigabit Ethernet internally, and, with the growth of our issuance volume and logging, we found that our Gigabit Ethernet network eventually became too slow to synchronize database instances! (Today we’re using 25-gig Ethernet.) More recently, we’ve experimented with architectural upgrades to our ever-growing Certificate Transparency logs, and decided to go ahead with deploying those upgrades—to help us not just keep up with, but get ahead of, our continuing growth.&lt;/p&gt;
    &lt;p&gt;These kinds of growing pains and successful responses to them are nice to remember because they point to the inexorable increase in demands on our infrastructure as we’ve become a more and more essential part of the Internet. I’m proud of our technical teams which have handled those increased demands capably and professionally.&lt;/p&gt;
    &lt;p&gt;I also recall the ongoing work involved in making sure our certificates would be as widely accepted as possible, which has meant managing the original cross-signature from IdenTrust, and subsequently creating and propagating our own root CA certificates. This process has required PKI engineering, key ceremonies, root program interactions, documentation, and community support associated with certificate migrations. Most users never have reason to look behind the scenes at our chains of trust, but our engineers update it as root and intermediate certificates have been replaced. We’ve engaged at the CA/B Forum, IETF, and in other venues with the browser root programs to help shape the web PKI as a technical leader.&lt;/p&gt;
    &lt;p&gt;As I wrote in 2020, our ideal of complete automation of the web PKI aims at a world where most site owners wouldn’t even need to think about certificates at all. We continue to get closer and closer to that world, which creates a risk that people will take us and our services for granted, as the details of certificate renewal occupy less of site operators’ mental energy. As I said at the time,&lt;/p&gt;
    &lt;p&gt;When your strategy as a nonprofit is to get out of the way, to offer services that people don’t need to think about, you’re running a real risk that you’ll eventually be taken for granted. There is a tension between wanting your work to be invisible and the need for recognition of its value. If people aren’t aware of how valuable our services are then we may not get the support we need to continue providing them.&lt;/p&gt;
    &lt;p&gt;I’m also grateful to our communications and fundraising staff who help make clear what we’re doing every day and how we’re making the Internet safer.&lt;/p&gt;
    &lt;p&gt;Our community continually recognizes our work in tangible ways by using our certificates—now by the tens of millions per day—and by sponsoring us.&lt;/p&gt;
    &lt;p&gt;We were honored to be recognized with awards including the 2022 Levchin Prize for Real-World Cryptography and the 2019 O’Reilly Open Source Award. In October of this year some of the individuals who got Let’s Encrypt started were honored to receive the IEEE Cybersecurity Award for Practice.&lt;/p&gt;
    &lt;p&gt;We documented the history, design, and goals of the project in an academic paper at the ACM CCS ‘19 conference, which has subsequently been cited hundreds of times in academic research.&lt;/p&gt;
    &lt;p&gt;Ten years later, I’m still deeply grateful to the five initial sponsors that got Let’s Encrypt off the ground - Mozilla, EFF, Cisco, Akamai, and IdenTrust. When they committed significant resources to the project, it was just an ambitious idea. They saw the potential and believed in our team, and because of that we were able to build the service we operate today.&lt;/p&gt;
    &lt;p&gt;I’d like to particularly recognize IdenTrust, a PKI company that worked as a partner from the outset and enabled us to issue publicly-trusted certificates via a cross-signature from one of their roots. We would simply not have been able to launch our publicly-trusted certificate service without them. Back when I first told them that we were starting a new nonprofit certificate authority that would give away millions of certificates for free, there wasn’t any precedent for this arrangement, and there wasn’t necessarily much reason for IdenTrust to pay attention to our proposal. But the company really understood what we were trying to do and was willing to engage from the beginning. Ultimately, IdenTrust’s support made our original issuance model a reality.&lt;/p&gt;
    &lt;p&gt;I’m proud of what we have achieved with our staff, partners, and donors over the past ten years. I hope to be even more proud of the next ten years, as we use our strong footing to continue to pursue our mission to protect Internet users by lowering monetary, technological, and informational barriers to a more secure and privacy-respecting Internet.&lt;/p&gt;
    &lt;p&gt;Let’s Encrypt is a project of the nonprofit Internet Security Research Group, a 501(c)(3) nonprofit. You can help us make the next ten years great as well by donating or becoming a sponsor.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46208962</guid><pubDate>Tue, 09 Dec 2025 18:54:55 +0000</pubDate></item><item><title>Django: what’s new in 6.0</title><link>https://adamj.eu/tech/2025/12/03/django-whats-new-6.0/</link><description>&lt;doc fingerprint="babb1d3d4db5baca"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Django: whatâs new in 6.0&lt;/head&gt;
    &lt;p&gt;Django 6.0 was released today, starting another release cycle for the loved and long-lived Python web framework (now 20 years old!). It comes with a mosaic of new features, contributed to by many, some of which I am happy to have helped with. Below is my pick of highlights from the release notes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Upgrade with help from django-upgrade&lt;/head&gt;
    &lt;p&gt;If youâre upgrading a project from Django 5.2 or earlier, please try my tool django-upgrade. It will automatically update old Django code to use new features, fixing some deprecation warnings for you, including five fixers for Django 6.0. (One day, Iâll propose django-upgrade to become an official Django project, when energy and time permitâ¦)&lt;/p&gt;
    &lt;head rend="h2"&gt;Template partials&lt;/head&gt;
    &lt;p&gt;There are four headline features in Django 6.0, which weâll cover before other notable changes, starting with this one:&lt;/p&gt;
    &lt;quote&gt;The Django Template Language now supports template partials, making it easier to encapsulate and reuse small named fragments within a template file.&lt;/quote&gt;
    &lt;p&gt;Partials are sections of a template marked by the new &lt;code&gt;{% partialdef %}&lt;/code&gt; and &lt;code&gt;{% endpartialdef %}&lt;/code&gt; tags. They can be reused within the same template or rendered in isolation. Letâs look at examples for each use case in turn.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reuse partials within the same template&lt;/head&gt;
    &lt;p&gt;The below template reuses a partial called &lt;code&gt;filter_controls&lt;/code&gt; within the same template. Itâs defined once at the top of the template, then used twice later on. Using a partial allows the template avoid repetition without pushing the content into a separate include file.&lt;/p&gt;
    &lt;code&gt;&amp;lt;section id=videos&amp;gt;
  {% partialdef filter_controls %}
    &amp;lt;form&amp;gt;
      {{ filter_form }}
    &amp;lt;/form&amp;gt;
  {% endpartialdef %}

  {% partial filter_controls %}

  &amp;lt;ul&amp;gt;
    {% for video in videos %}
      &amp;lt;li&amp;gt;
        &amp;lt;h2&amp;gt;{{ video.title }}&amp;lt;/h2&amp;gt;
        ...
      &amp;lt;/li&amp;gt;
    {% endfor %}
  &amp;lt;/ul&amp;gt;

  {% partial filter_controls %}
&amp;lt;/section&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Actually, we can simplify this pattern further, by using the &lt;code&gt;inline&lt;/code&gt; option on the &lt;code&gt;partialdef&lt;/code&gt; tag, which causes the definition to also render in place:&lt;/p&gt;
    &lt;code&gt;&amp;lt;section id=videos&amp;gt;
  {% partialdef filter_controls inline %}
    &amp;lt;form&amp;gt;
      {{ filter_form }}
    &amp;lt;/form&amp;gt;
  {% endpartialdef %}

  &amp;lt;ul&amp;gt;
    {% for video in videos %}
      &amp;lt;li&amp;gt;
        &amp;lt;h2&amp;gt;{{ video.title }}&amp;lt;/h2&amp;gt;
        ...
      &amp;lt;/li&amp;gt;
    {% endfor %}
  &amp;lt;/ul&amp;gt;

  {% partial filter_controls %}
&amp;lt;/section&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Reach for this pattern any time you find yourself repeating template code within the same template. Because partials can use variables, you can also use them to de-duplicate when rendering similar controls with different data.&lt;/p&gt;
    &lt;head rend="h3"&gt;Render partials in isolation&lt;/head&gt;
    &lt;p&gt;The below template defines a &lt;code&gt;view_count&lt;/code&gt; partial thatâs intended to be re-rendered in isolation. It uses the &lt;code&gt;inline&lt;/code&gt; option, so when the whole template is rendered, the partial is included.&lt;/p&gt;
    &lt;p&gt;The page uses htmx, via my django-htmx package, to periodically refresh the view count, through the &lt;code&gt;hx-*&lt;/code&gt; attributes. The request from htmx goes to a dedicated view that re-renders the &lt;code&gt;view_count&lt;/code&gt; partial.&lt;/p&gt;
    &lt;code&gt;{% load django_htmx %}
&amp;lt;!doctype html&amp;gt;
&amp;lt;html&amp;gt;
  &amp;lt;body&amp;gt;
    &amp;lt;h1&amp;gt;{{ video.title }}&amp;lt;/h1&amp;gt;
    &amp;lt;video width=1280 height=720 controls&amp;gt;
      &amp;lt;source src="{{ video.file.url }}" type="video/mp4"&amp;gt;
      Your browser does not support the video tag.
    &amp;lt;/video&amp;gt;

    {% partialdef view_count inline %}
    &amp;lt;section
      class=view-count
      hx-trigger="every 1s"
      hx-swap=outerHTML
      hx-get="{% url 'video-view-count' video.id %}"
    &amp;gt;
      {{ video.view_count }} views
    &amp;lt;/section&amp;gt;
    {% endpartialdef %}

    {% htmx_script %}
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;
    &lt;p&gt;The relevant code for the two views could look like this:&lt;/p&gt;
    &lt;code&gt;from django.shortcuts import render


def video(request, video_id):
    ...
    return render(request, "video.html", {"video": video})


def video_view_count(request, video_id):
    ...
    return render(request, "video.html#view_count", {"video": video})
&lt;/code&gt;
    &lt;p&gt;The initial &lt;code&gt;video&lt;/code&gt; view renders the full template &lt;code&gt;video.html&lt;/code&gt;. The &lt;code&gt;video_view_count&lt;/code&gt; view renders just the &lt;code&gt;view_count&lt;/code&gt; partial, by appending &lt;code&gt;#view_count&lt;/code&gt; to the template name. This syntax is similar to how youâd reference an HTML fragment by its ID in a URL.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;htmx was the main motivation for this feature, as promoted by htmx creator Carson Gross in a cross-framework review post. Using partials definitely helps maintain âLocality of behaviourâ within your templates, easing authoring, debugging, and maintenance by avoiding template file sprawl.&lt;/p&gt;
    &lt;p&gt;Djangoâs support for template partials was initially developed by Carlton Gibson in the django-template-partials package, which remains available for older Django versions. The integration into Django itself was done in a Google Summer of Code project this year, worked on by student Farhan Ali and mentored by Carlton, in Ticket #36410. You can read more about the development process in Farhanâs retrospective blog post. Many thanks to Farhan for authoring, Carlton for mentoring, and Natalia Bidart, Nick Pope, and Sarah Boyce for reviewing!&lt;/p&gt;
    &lt;head rend="h2"&gt;Tasks framework&lt;/head&gt;
    &lt;p&gt;The next headline feature weâre covering:&lt;/p&gt;
    &lt;quote&gt;Django now includes a built-in Tasks framework for running code outside the HTTP requestâresponse cycle. This enables offloading work, such as sending emails or processing data, to background workers.&lt;/quote&gt;
    &lt;p&gt;Basically, thereâs a new API for defining and enqueuing background tasksâvery cool!&lt;/p&gt;
    &lt;p&gt;Background tasks are a way of running code outside of the request-response cycle. Theyâre a common requirement in web applications, used for sending emails, processing images, generating reports, and more.&lt;/p&gt;
    &lt;p&gt;Historically, Django has not provided any system for background tasks, and kind of ignored the problem space altogether. Developers have instead relied on third-party packages like Celery or Django Q2. While these systems are fine, they can be complex to set up and maintain, and often donât âgo with the grainâ of Django.&lt;/p&gt;
    &lt;p&gt;The new Tasks framework fills this gap by providing an interface to define background tasks, which task runner packages can then integrate with. This common ground allows third-party Django packages to define tasks in a standard way, assuming youâll be using a compatible task runner to execute them.&lt;/p&gt;
    &lt;p&gt;Define tasks with the new &lt;code&gt;@task&lt;/code&gt; decorator:&lt;/p&gt;
    &lt;code&gt;from django.tasks import task


@task
def resize_video(video_id): ...
&lt;/code&gt;
    &lt;p&gt;â¦and enqueue them for background execution with the &lt;code&gt;Task.enqueue()&lt;/code&gt; method:&lt;/p&gt;
    &lt;code&gt;from example.tasks import resize_video


def upload_video(request):
    ...
    resize_video.enqueue(video.id)
    ...
&lt;/code&gt;
    &lt;head rend="h3"&gt;Execute tasks&lt;/head&gt;
    &lt;p&gt;At this time, Django does not include a production-ready task backend, only two that are suitable for development and testing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ImmediateBackend&lt;/code&gt;- runs tasks synchronously, blocking until they complete.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DummyBackend&lt;/code&gt;- does nothing when tasks are enqueued, but allows them to be inspected later. Useful for tests, where you can assert that tasks were enqueued without actually running them.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For production use, youâll need to use a third-party package that implements one, for which django-tasks, the reference implementation, is the primary option. It provides &lt;code&gt;DatabaseBackend&lt;/code&gt; for storing tasks in your SQL database, a fine solution for many projects, avoiding extra infrastructure and allowing atomic task enqueuing within database transactions. We may see this backend merged into Django in due course, or at least become an official package, to help make Django âbatteries includedâ for background tasks.&lt;/p&gt;
    &lt;p&gt;To use django-tasksâ &lt;code&gt;DatabaseBackend&lt;/code&gt; today, first install the package:&lt;/p&gt;
    &lt;code&gt;uv add django-tasks
&lt;/code&gt;
    &lt;p&gt;Second, add these two apps to your &lt;code&gt;INSTALLED_APPS&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;INSTALLED_APPS = [
    # ...
    "django_tasks",
    "django_tasks.backends.database",
    # ...
]
&lt;/code&gt;
    &lt;p&gt;Third, configure &lt;code&gt;DatabaseBackend&lt;/code&gt; as your tasks backend in the new &lt;code&gt;TASKS&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;TASKS = {
    "default": {
        "BACKEND": "django_tasks.backends.database.DatabaseBackend",
    },
}
&lt;/code&gt;
    &lt;p&gt;Fourth, run migrations to create the necessary database tables:&lt;/p&gt;
    &lt;code&gt;$ ./manage.py migrate
&lt;/code&gt;
    &lt;p&gt;Finally, to run the task worker process, use the packageâs &lt;code&gt;db_worker&lt;/code&gt; management command:&lt;/p&gt;
    &lt;code&gt;$ ./manage.py db_worker
Starting worker worker_id=jWLMLrms3C2NcUODYeatsqCFvd5rK6DM queues=default
&lt;/code&gt;
    &lt;p&gt;This process runs indefinitely, polling for tasks and executing them, logging events as it goes:&lt;/p&gt;
    &lt;code&gt;Task id=10b794ed-9b64-4eed-950c-fcc92cd6784b path=example.tasks.echo state=RUNNING
Hello from test task!
Task id=10b794ed-9b64-4eed-950c-fcc92cd6784b path=example.tasks.echo state=SUCCEEDED
&lt;/code&gt;
    &lt;p&gt;Youâll want to run &lt;code&gt;db_worker&lt;/code&gt; in production, and also in development if you want to test background task execution.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;Itâs been a long path to get the Tasks framework into Django, and Iâm super excited to see it finally available in Django 6.0. Jake Howard started on the idea for Wagtail, a Django-powered CMS, back in 2021, as they have a need for common task definitions across their package ecosystem. He upgraded the idea to target Django itself in 2024, when he proposed DEP 0014. As a member of the Steering Council at the time, I had the pleasure of helping review and accept the DEP.&lt;/p&gt;
    &lt;p&gt;Since then, Jake has been leading the implementation effort, building pieces first in the separate django-tasks package before preparing them for inclusion in Django itself. This step was done under Ticket #35859, with a pull request that took nearly a year to review and land. Thanks to Jake for his perseverance here, and to all reviewers: Andreas NÃ¼Ãlein, Dave Gaeddert, Eric Holscher, Jacob Walls, Jake Howard, Kamal Mustafa, @rtr1, @tcely, Oliver Haas, Ran Benita, Raphael Gaschignard, and Sarah Boyce.&lt;/p&gt;
    &lt;p&gt;Read more about this feature and story in Jakeâs post celebrating when it was merged.&lt;/p&gt;
    &lt;head rend="h2"&gt;Content Security Policy support&lt;/head&gt;
    &lt;p&gt;Our third headline feature:&lt;/p&gt;
    &lt;quote&gt;Built-in support for the Content Security Policy (CSP) standard is now available, making it easier to protect web applications against content injection attacks such as cross-site scripting (XSS). CSP allows declaring trusted sources of content by giving browsers strict rules about which scripts, styles, images, or other resources can be loaded.&lt;/quote&gt;
    &lt;p&gt;Iâm really excited about this, because Iâm a bit of a security nerd whoâs been deploying CSP for client projects for years.&lt;/p&gt;
    &lt;p&gt;CSP is a security standard that can protect your site from cross-site scripting (XSS) and other code injection attacks. You set a &lt;code&gt;content-security-policy&lt;/code&gt; header to declare which content sources are trusted for your site, and then browsers will block content from other sources. For example, you might declare that only scripts your domain are allowed, so an attacker who manages to inject a &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag pointing to evil.com would be thwarted, as the browser would refuse to load it.&lt;/p&gt;
    &lt;p&gt;Previously, Django had no built-in support for CSP, and developers had to rely on building their own, or using a third-party package like the very popular django-csp. But this was a little bit inconvenient, as it meant that other third-party packages couldnât reliably integrate with CSP, as there was no common API to do so.&lt;/p&gt;
    &lt;p&gt;The new CSP support provides all the core features that django-csp did, with a slightly tidier and more Djangoey API. To get started, first add &lt;code&gt;ContentSecurityPolicyMiddleware&lt;/code&gt; to your &lt;code&gt;MIDDLEWARE&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;MIDDLEWARE = [
    # ...
    "django.middleware.csp.ContentSecurityPolicyMiddleware",
    # ...
]
&lt;/code&gt;
    &lt;p&gt;Place it next to &lt;code&gt;SecurityMiddleware&lt;/code&gt;, as it similarly adds security-related headers to all responses. (You do have &lt;code&gt;SecurityMiddleware&lt;/code&gt; enabled, right?)&lt;/p&gt;
    &lt;p&gt;Second, configure your CSP policy using the new settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;SECURE_CSP&lt;/code&gt;to configure the&lt;code&gt;content-security-policy&lt;/code&gt;header, which is your actively enforced policy.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SECURE_CSP_REPORT_ONLY&lt;/code&gt;to configure the&lt;code&gt;content-security-policy-report-only&lt;/code&gt;header, which sets a non-enforced policy for which browsers report violations to a specified endpoint. This option is useful for testing and monitoring a policy before enforcing it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For example, to adopt the nonce-based strict CSP recommended by web.dev, you could start with the following setting:&lt;/p&gt;
    &lt;code&gt;from django.utils.csp import CSP

SECURE_CSP_REPORT_ONLY = {
    "script-src": [CSP.NONCE, CSP.STRICT_DYNAMIC],
    "object-src": [CSP.NONE],
    "base-uri": [CSP.NONE],
}
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;CSP&lt;/code&gt; enum used above provides constants for CSP directives, to help avoid typos.&lt;/p&gt;
    &lt;p&gt;This policy is quite restrictive and will break most existing sites if deployed as-is, because it requires nonces, as covered next. Thatâs why the example shows starting with the report-only mode header, to help track down places that need fixing before enforcing the policy. Youâd later change to setting the &lt;code&gt;SECURE_CSP&lt;/code&gt; setting to enforce the policy.&lt;/p&gt;
    &lt;p&gt;Anyway, those are the two basic steps to set up the new CSP support!&lt;/p&gt;
    &lt;head rend="h3"&gt;Nonce generation&lt;/head&gt;
    &lt;p&gt;A key part of the new feature is that nonce generation is now built-in to Django, when using the CSP middleware. Nonces are a security feature in CSP that allow you to mark specific &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags as trusted with a &lt;code&gt;nonce&lt;/code&gt; attribute:&lt;/p&gt;
    &lt;code&gt;&amp;lt;script src=/static/app.js type=module nonce=55vsH4w7ATHB85C3MbPr_g&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;
    &lt;p&gt;The nonce value is randomly generated per-request, and included in the CSP header. An attacker performing content injection couldnât guess the nonce, so browsers can trust only those tags that include the correct nonce. Because nonce generation is now part of Django, third-party packages can depend on it for their &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags and theyâll continue to work if you adopt CSP with nonces.&lt;/p&gt;
    &lt;p&gt;Nonces are the recommended way to use CSP today, avoiding problems with previous allow-list based approaches. Thatâs why the above recommended policy enables them. To adopt a nonce-based policy, youâll need to annotate your &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags with the nonce value through the following steps.&lt;/p&gt;
    &lt;p&gt;First, add the new &lt;code&gt;csp&lt;/code&gt; template context processor to your &lt;code&gt;TEMPLATES&lt;/code&gt; setting:&lt;/p&gt;
    &lt;code&gt;TEMPLATES = [
    {
        "BACKEND": "django.template.backends.django.DjangoTemplates",
        "OPTIONS": {
            "context_processors": [
                # ...
                "django.template.context_processors.csp",
            ],
        },
    },
]
&lt;/code&gt;
    &lt;p&gt;Second, annotate your &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags with &lt;code&gt;nonce="{{ csp_nonce }}"&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;-   &amp;lt;script src="{% static 'app.js' %}" type="module"&amp;gt;&amp;lt;/script&amp;gt;
+   &amp;lt;script src="{% static 'app.js' %}" type="module" nonce="{{ csp_nonce }}"&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;
    &lt;p&gt;This can be tedious and error-prone, hence using the report-only mode first to monitor violations might be useful, especially on larger projects.&lt;/p&gt;
    &lt;p&gt;Anyway, deploying CSP right would be another post in itself, or even a book chapter, so weâll stop here for now. For more info, check out that web.dev article and the MDN CSP guide.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;CSP itself was proposed for browsers way back in 2004, and was first implemented in Mozilla Firefox version 4, released 2011. That same year, Django Ticket #15727 was opened, proposing adding CSP support to Django. Mozilla created django-csp from 2010, before the first public availability of CSP, using it on their own Django-powered sites. The first comment on Ticket #15727 pointed to django-csp, and the community basically rolled with it as the de facto solution.&lt;/p&gt;
    &lt;p&gt;Over the years, CSP itself evolved, as did django-csp, with Rob Hudson ending up as its maintainer. Focusing on the package motivated to finally get CSP into Django itself. He made a draft PR and posted on Ticket #15727 in 2024, which I enjoyed helping review. He iterated on the PR over the next 13 months until it was finally merged for Django 6.0. Thanks to Rob for his heroic dedication here, and to all reviewers: Benjamin Balder Bach, Carlton Gibson, Collin Anderson, David Sanders, David Smith, Florian Apolloner, Harro van der Klauw, Jake Howard, Natalia Bidart, Paolo Melchiorre, Sarah Boyce, and SÃ©bastien Corbin.&lt;/p&gt;
    &lt;head rend="h2"&gt;Email API updates&lt;/head&gt;
    &lt;p&gt;The fourth and final headline feature:&lt;/p&gt;
    &lt;code&gt;Email handling in Django now uses Pythonâs modern email API, introduced in Python 3.6. This API, centered around the  email.message.EmailMessage class, offers a cleaner and Unicode-friendly interface for composing and sending emails.&lt;/code&gt;
    &lt;p&gt;This is a major change, but itâs unlikely to affect projects using basic email features. You can still use Djangoâs &lt;code&gt;send_mail()&lt;/code&gt; function and &lt;code&gt;EmailMessage&lt;/code&gt; class as before, like:&lt;/p&gt;
    &lt;code&gt;from django.core.mail import EmailMessage

email = EmailMessage(
    subject="ð¼ Need more bamboo",
    body="We are desperately low, please restock before the pandas find out!",
    from_email="zookeeper@example.com",
    to=["supplies@example.com"],
)
email.attach_file("/media/bamboo_cupboard.jpg")
email.send()
&lt;/code&gt;
    &lt;p&gt;The key change is that, under-the-hood, when you call &lt;code&gt;send()&lt;/code&gt; on a Django &lt;code&gt;EmailMessage&lt;/code&gt; object, it now translates itself into a Pythonâs newer &lt;code&gt;email.message.EmailMessage&lt;/code&gt; type before sending.&lt;/p&gt;
    &lt;p&gt;Modernizing provides these benefits:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fewer bugs - many edge case bugs in Pythonâs old email API have been fixed in the new one.&lt;/item&gt;
      &lt;item&gt;Django is less hacky - a bunch of workarounds and security fixes in Djangoâs email code have been removed.&lt;/item&gt;
      &lt;item&gt;More convenient API - the new API supports some niceties, like the below inline attachment example.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Easier inline attachments with &lt;code&gt;MIMEPart&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Djangoâs &lt;code&gt;EmailMessage.attach()&lt;/code&gt; method allows you to attach a file as an attachment. Emails support images as inline attachments, which can be displayed within the HTML email body.&lt;/p&gt;
    &lt;p&gt;While you could previously use &lt;code&gt;EmailMessage.attach()&lt;/code&gt; to add inline attachments, it was a bit fiddly, using a legacy class. Now, you can call the method with a Python &lt;code&gt;email.message.MIMEPart&lt;/code&gt; object to add an inline attachment in a few steps:&lt;/p&gt;
    &lt;code&gt;import email.utils
from email.message import MIMEPart
from django.core.mail import EmailMultiAlternatives

message = EmailMultiAlternatives(
    subject="Cute Panda Alert",
    body="Here's a cute panda picture for you!",
    from_email="cute@example.com",
    to=["fans@example.com"],
)
with open("panda.jpg", "rb") as f:
    panda_jpeg = f.read()

cid = email.utils.make_msgid()
inline_image = MIMEPart()
inline_image.set_content(
    panda_jpeg,
    maintype="image",
    subtype="jpeg",
    disposition="inline",
    cid=cid,
)
message.attach(inline_image)
message.attach_alternative(
    f'&amp;lt;h1&amp;gt;Cute panda baby alert!&amp;lt;/h1&amp;gt;&amp;lt;img src="cid:{cid[1:-1]}"&amp;gt;',
    "text/html",
)
&lt;/code&gt;
    &lt;p&gt;Itâs not the simplest API, but it does expose all the power of the underlying email system, and itâs better than the past situation.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;The new email API was added to Python as provisional in version 3.4 (2014), and made stable in version 3.6 (2016). The legacy API, however, was never planned for deprecation, so there was never any deadline to upgrade Djangoâs email handling.&lt;/p&gt;
    &lt;p&gt;In 2024, Mike Edmunds posted on the (old) django-developers mailing list, proposing the upgrade with strong reasoning and planning. This conversation led to Ticket #35581, which he worked on for eight months until it was merged. Many thanks to Mike for leading this effort, and to Sarah Boyce for reviewing! Email is not a glamorous feature, but itâs a critical communication channel for nearly every Django project, so props for this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Positional arguments in &lt;code&gt;django.core.mail&lt;/code&gt; APIs&lt;/head&gt;
    &lt;p&gt;Weâre now out of the headline features and onto the âminorâ changes, starting with this deprecation related to the above email changes:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;django.core.mail&lt;/code&gt;APIs now require keyword arguments for less commonly used parameters. Using positional arguments for these now emits a deprecation warning and will raise a&lt;code&gt;TypeError&lt;/code&gt;when the deprecation period ends:&lt;item&gt;All optional parameters (&lt;/item&gt;&lt;code&gt;fail_silently&lt;/code&gt;and later) must be passed as keyword arguments to&lt;code&gt;get_connection()&lt;/code&gt;,&lt;code&gt;mail_admins()&lt;/code&gt;,&lt;code&gt;mail_managers()&lt;/code&gt;,&lt;code&gt;send_mail()&lt;/code&gt;, and&lt;code&gt;send_mass_mail()&lt;/code&gt;.&lt;item&gt;All parameters must be passed as keyword arguments when creating an&lt;/item&gt;&lt;code&gt;EmailMessage&lt;/code&gt;or&lt;code&gt;EmailMultiAlternatives&lt;/code&gt;instance, except for the first four (&lt;code&gt;subject&lt;/code&gt;,&lt;code&gt;body&lt;/code&gt;,&lt;code&gt;from_email&lt;/code&gt;, and&lt;code&gt;to&lt;/code&gt;), which may still be passed either as positional or keyword arguments.&lt;/quote&gt;
    &lt;p&gt;Previously, Django would let you pass all parameters positionally, which gets a bit silly and hard to read with long parameter lists, like:&lt;/p&gt;
    &lt;code&gt;from django.core.mail import send_mail

send_mail(
    "ð¼ Panda of the week",
    "This weekâs panda is Po Ping, sha-sha booey!",
    "updates@example.com",
    ["adam@example.com"],
    True,
)
&lt;/code&gt;
    &lt;p&gt;The final &lt;code&gt;True&lt;/code&gt; doesnât provide any clue what it means without looking up the function signature. Now, using positional arguments for those less-commonly-used parameters raises a deprecation warning, nudging you to write:&lt;/p&gt;
    &lt;code&gt;from django.core.mail import send_mail

send_mail(
    subject="ð¼ Panda of the week",
    body="This weekâs panda is Po Ping, sha-sha booey!",
    from_email="updates@example.com",
    ["adam@example.com"],
    fail_silently=True,
)
&lt;/code&gt;
    &lt;p&gt;This change is appreciated for API clarity, and Django is generally moving towards using keyword-only arguments more often. django-upgrade can automatically fix this one for you, via its &lt;code&gt;mail_api_kwargs&lt;/code&gt; fixer.&lt;/p&gt;
    &lt;p&gt;Thanks to Mike Edmunds, again, for making this improvement in Ticket #36163.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extended automatic &lt;code&gt;shell&lt;/code&gt; imports&lt;/head&gt;
    &lt;p&gt;Next up:&lt;/p&gt;
    &lt;quote&gt;Common utilities, such as django.conf.settings, are now automatically imported to the shell by default.&lt;/quote&gt;
    &lt;p&gt;One of the headline features back in Django 5.2 was automatic model imports in the shell, making &lt;code&gt;./manage.py shell&lt;/code&gt; import all of your models automatically. Building on that DX boost, Django 6.0 now also imports other common utilities, for which we can find the full list by running &lt;code&gt;./manage.py shell&lt;/code&gt; with &lt;code&gt;-v 2&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;$ ./manage.py shell -v 2
6 objects imported automatically:

  from django.conf import settings
  from django.db import connection, models, reset_queries
  from django.db.models import functions
  from django.utils import timezone

...
&lt;/code&gt;
    &lt;p&gt;(This is from a project without any models, so only the utilities are listed.)&lt;/p&gt;
    &lt;p&gt;So thatâs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;settings&lt;/code&gt;, useful for checking your runtime configuration:&lt;quote&gt;In [1]: settings.DEBUG Out[1]: False&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;connection&lt;/code&gt;and&lt;code&gt;reset_queries()&lt;/code&gt;, great for checking the executed queries:&lt;quote&gt;In [1]: Book.objects.select_related('author') Out[1]: &amp;lt;QuerySet []&amp;gt; In [2]: connection.queries Out[2]: [{'sql': 'SELECT "example_book"."id", "example_book"."title", "example_book"."author_id", "example_author"."id", "example_author"."name" FROM "example_book" INNER JOIN "example_author" ON ("example_book"."author_id" = "example_author"."id") LIMIT 21', 'time': '0.000'}]&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;models&lt;/code&gt;and&lt;code&gt;functions&lt;/code&gt;, useful for advanced ORM work:&lt;quote&gt;In [1]: Book.objects.annotate( ...: title_lower=functions.Lower("title") ...: ).filter( ...: title_lower__startswith="a" ...: ).count() Out[1]: 71&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;timezone&lt;/code&gt;, useful for using Djangoâs timezone-aware date and time utilities:&lt;quote&gt;In [1]: timezone.now() Out[1]: datetime.datetime(2025, 12, 1, 23, 42, 22, 558418, tzinfo=datetime.timezone.utc)&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It remains possible to extend the automatic imports with whatever youâd like, as documented in How to customize the &lt;code&gt;shell&lt;/code&gt; command documentation page.&lt;/p&gt;
    &lt;p&gt;Salvo Polizzi contributed the original automatic shell imports feature in Django 5.2. Heâs then returned to offer these extra imports for Django 6.0, in Ticket #35680. Thanks to everyone that contributed to the forum discussion agreeing on which imports to add, and to Natalia Bidart and Sarah Boyce for reviewing!&lt;/p&gt;
    &lt;head rend="h2"&gt;Dynamic field refresh on &lt;code&gt;save()&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Now letâs discuss a series of ORM improvements, starting with this big one:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;GeneratedField&lt;/code&gt;s and fields assigned expressions are now refreshed from the database after&lt;code&gt;save()&lt;/code&gt;on backends that support the&lt;code&gt;RETURNING&lt;/code&gt;clause (SQLite, PostgreSQL, and Oracle). On backends that donât support it (MySQL and MariaDB), the fields are marked as deferred to trigger a refresh on subsequent accesses.&lt;/quote&gt;
    &lt;p&gt;Django models support having the database generate field values for you in three cases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;db_default&lt;/code&gt;field option, which lets the database generate the default value when creating an instance:&lt;quote&gt;from django.db import models from django.db.models.functions import Now class Video(models.Model): ... created = models.DateTimeField(db_default=Now())&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;GeneratedField&lt;/code&gt;field type, which is always computed by the database based on other fields in the same instance:&lt;quote&gt;from django.db import models from django.db.models.functions import Concat class Video(models.Model): ... full_title = models.GeneratedField( models.TextField(), expression=Concat( "title", models.Value(" - "), "subtitle", ), )&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Assigning expression values to fields before saving:&lt;/p&gt;
        &lt;quote&gt;from django.db import models from django.db.models.functions import Now class Video(models.Model): ... last_updated = models.DateTimeField() video = Video.objects.get(id=1) ... video.last_updated = Now() video.save()&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Previously, only the first method, using &lt;code&gt;db_default&lt;/code&gt;, would refresh the field value from the database after saving. The other two methods would leave you with only the old value or the expression object, meaning youâd need to call &lt;code&gt;Model.refresh_from_db()&lt;/code&gt; to get any updated value if necessary. This was hard to remember and it costs an extra database query.&lt;/p&gt;
    &lt;p&gt;Now Django takes advantage of the &lt;code&gt;RETURNING&lt;/code&gt; SQL clause to save the model instance and fetch updated dynamic field values in a single query, on backends that support it (SQLite, PostgreSQL, and Oracle). A &lt;code&gt;save()&lt;/code&gt; call may now issue a query like:&lt;/p&gt;
    &lt;code&gt;UPDATE "example_video"
SET "last_updated" = NOW()
WHERE "example_video"."id" = 1
RETURNING "example_video"."last_updated"
&lt;/code&gt;
    &lt;p&gt;Django puts the return value into the model field, so you can read it immediately after saving:&lt;/p&gt;
    &lt;code&gt;video = Video.objects.get(id=1)
...
video.last_updated = Now()
video.save()
print(video.last_updated)  # Updated value from the database
&lt;/code&gt;
    &lt;p&gt;On backends that donât support &lt;code&gt;RETURNING&lt;/code&gt; (MySQL and MariaDB), Django now marks the dynamic fields as deferred after saving. That way, the later access, as in the above example, will automatically call &lt;code&gt;Model.refresh_from_db()&lt;/code&gt;. This ensures that you always read the updated value, even if it costs an extra query.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;This feature was proposed in Ticket #27222 way back in 2016, by Anssi KÃ¤Ã¤riÃ¤inen. It sat dormant for most of the nine years since, but ORM boss Simon Charette picked it up earlier this year, found an implementation, and pushed it through to completion. Thanks to Simon for continuing to push the ORM forward, and to all reviewers: David Sanders, Jacob Walls, Mariusz Felisiak, nessita, Paolo Melchiorre, Simon Charette, and Tim Graham.&lt;/p&gt;
    &lt;head rend="h2"&gt;Universal &lt;code&gt;StringAgg&lt;/code&gt; aggregate&lt;/head&gt;
    &lt;p&gt;The next ORM change:&lt;/p&gt;
    &lt;quote&gt;The new&lt;code&gt;StringAgg&lt;/code&gt;aggregate returns the input values concatenated into a string, separated by the&lt;code&gt;delimiter&lt;/code&gt;string. This aggregate was previously supported only for PostgreSQL.&lt;/quote&gt;
    &lt;p&gt;This aggregate is often used for making comma-separated lists of related items, among other things. Previously, it was only supported on PostgreSQL, as part of &lt;code&gt;django.contrib.postgres&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;from django.contrib.postgres.aggregates import StringAgg
from example.models import Video

videos = Video.objects.annotate(
    chapter_ids=StringAgg("chapter", delimiter=","),
)

for video in videos:
    print(f"Video {video.id} has chapters: {video.chapter_ids}")
&lt;/code&gt;
    &lt;p&gt;â¦which might give you output like:&lt;/p&gt;
    &lt;code&gt;Video 104 has chapters: 71,72,74
Video 107 has chapters: 88,89,138,90,91,93
&lt;/code&gt;
    &lt;p&gt;Now this aggregate is available on all database backends supported by Django, imported from &lt;code&gt;django.db.models&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;from django.db.models import StringAgg, Value
from example.models import Video

videos = Video.objects.annotate(
    chapter_ids=StringAgg("chapter", delimiter=Value(",")),
)

for video in videos:
    print(f"Video {video.id} has chapters: {video.chapter_ids}")
&lt;/code&gt;
    &lt;p&gt;Note the &lt;code&gt;delimiter&lt;/code&gt; argument now requires a &lt;code&gt;Value()&lt;/code&gt; expression wrapper for literal strings, as above. This change allows you to use database functions or fields as the delimiter if desired.&lt;/p&gt;
    &lt;p&gt;While most Django projects stick to PostgreSQL, having this aggregate available on all backends is a nice improvement for cross-database compatibility, and it means third-party packages can use it without affecting their database support.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;The PostgreSQL-specific &lt;code&gt;StringAgg&lt;/code&gt; was added way back in Django 1.9 (2015) by Andriy Sokolovskiy, in Ticket #24301. In Ticket #35444, Chris Muthig proposed adding the &lt;code&gt;Aggregate.order_by&lt;/code&gt; option, something used by &lt;code&gt;StringAgg&lt;/code&gt; to specify the ordering of concatenated elements, and as a side effect this made it possible to generalize &lt;code&gt;StringAgg&lt;/code&gt; to all backends.&lt;/p&gt;
    &lt;p&gt;Thanks to Chris for proposing and implementing this change, and to all reviewers: Paolo Melchiorre, Sarah Boyce, and Simon Charette.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;code&gt;BigAutoField&lt;/code&gt; as the default primary key type&lt;/head&gt;
    &lt;p&gt;Next up:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt;setting now defaults to&lt;code&gt;BigAutoField&lt;/code&gt;&lt;/quote&gt;
    &lt;p&gt;This important change helps lock in scalable larger primary keys.&lt;/p&gt;
    &lt;p&gt;Django 3.2 (2021) introduced the &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; setting for changing the default primary key type used in models. Django uses this setting to add a primary key field called &lt;code&gt;id&lt;/code&gt; to models that donât explicitly define a primary key field. For example, if you define a model like this:&lt;/p&gt;
    &lt;code&gt;from django.db import models


class Video(models.Model):
    title = models.TextField()
&lt;/code&gt;
    &lt;p&gt;â¦then it will have two fields: &lt;code&gt;id&lt;/code&gt; and &lt;code&gt;title&lt;/code&gt;, where &lt;code&gt;id&lt;/code&gt; uses the type defined by &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The setting can also be overridden on a per-app basis by defining &lt;code&gt;AppConfig.default_auto_field&lt;/code&gt; in the appâs &lt;code&gt;apps.py&lt;/code&gt; file:&lt;/p&gt;
    &lt;code&gt;from django.apps import AppConfig


class ChannelConfig(AppConfig):
    name = "channel"
    default_auto_field = "django.db.models.BigAutoField"
&lt;/code&gt;
    &lt;p&gt;A key motivation for adding the setting was to allow projects to switch from &lt;code&gt;AutoField&lt;/code&gt; (a 32-bit integer) to &lt;code&gt;BigAutoField&lt;/code&gt; (a 64-bit integer) for primary keys, without needing changes to every model. &lt;code&gt;AutoField&lt;/code&gt; can store values up to about 2.1 billion, which sounds large but it becomes easy to hit at scale. &lt;code&gt;BigAutoField&lt;/code&gt; can store values up to about 9.2 quintillion, which is âmore than enoughâ for every practical purpose.&lt;/p&gt;
    &lt;p&gt;If a model using &lt;code&gt;AutoField&lt;/code&gt; hits its maximum value, it can no longer accept new rows, a problem known as primary key exhaustion. The table is effectively blocked, requiring an urgent fix to switch the model from &lt;code&gt;AutoField&lt;/code&gt; to &lt;code&gt;BigAutoField&lt;/code&gt; via a locking database migration on a large table. For a great watch on how Kraken is fixing this problem, see Tim Bellâs DjangoCon Europe 2025 talk, detailing some clever techniques to proactively migrate large tables with minimal downtime.&lt;/p&gt;
    &lt;p&gt;To stop this problem arising for new projects, Django 3.2 made new projects created with &lt;code&gt;startproject&lt;/code&gt; set &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; to &lt;code&gt;BigAutoField&lt;/code&gt;, and new apps created with &lt;code&gt;startapp&lt;/code&gt; set their &lt;code&gt;AppConfig.default_auto_field&lt;/code&gt; to &lt;code&gt;BigAutoField&lt;/code&gt;. It also added a system check to ensure that projects set &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; explicitly, to ensure users were aware of the feature and could make an informed choice.&lt;/p&gt;
    &lt;p&gt;Now Django 6.0 changes the actual default values of the setting and app config attribute to &lt;code&gt;BigAutoField&lt;/code&gt;. Projects using &lt;code&gt;BigAutoField&lt;/code&gt; can remove the setting:&lt;/p&gt;
    &lt;code&gt;-DEFAULT_AUTO_FIELD = "django.db.models.BigAutoField"
&lt;/code&gt;
    &lt;p&gt;â¦and app config attribute:&lt;/p&gt;
    &lt;code&gt;from django.apps import AppConfig

 class ChannelConfig(AppConfig):
     name = "channel"
-    default_auto_field = "django.db.models.BigAutoField"
&lt;/code&gt;
    &lt;p&gt;The default &lt;code&gt;startproject&lt;/code&gt; and &lt;code&gt;startapp&lt;/code&gt; templates also no longer set these values. This change reduces the amount of boilerplate in new projects, and the problem of primary key exhaustion can fade into history, becoming something that most Django users no longer need to think about.&lt;/p&gt;
    &lt;head rend="h3"&gt;History&lt;/head&gt;
    &lt;p&gt;The addition of &lt;code&gt;DEFAULT_AUTO_FIELD&lt;/code&gt; in Django 3.2 was proposed by Caio Ariede and implemented by Tom Forbes, in Ticket #31007. This new change in Django 6.0 was proposed and implemented by ex-Fellow Tim Graham, in Ticket #36564. Thanks to Tim for spotting that this cleanup was now possible, and to Jacob Walls and Clifford Gama for reviewing!&lt;/p&gt;
    &lt;head rend="h2"&gt;Template variable &lt;code&gt;forloop.length&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Moving on to templates, letâs start with this nice little addition:&lt;/p&gt;
    &lt;quote&gt;The new variable forloop.length is now available within a for loop.&lt;/quote&gt;
    &lt;p&gt;This small extension makes it possible to write a template loop like this:&lt;/p&gt;
    &lt;code&gt;&amp;lt;ul&amp;gt;
  {% for goose in geese %}
    &amp;lt;li&amp;gt;
      &amp;lt;strong&amp;gt;{{ forloop.counter }}/{{ forloop.length }}&amp;lt;/strong&amp;gt;: {{ goose.name }}
    &amp;lt;/li&amp;gt;
  {% endfor %}
&amp;lt;/ul&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Previously, youâd need to refer to the length in an another way, like &lt;code&gt;{{ geese|length }}&lt;/code&gt;, which is a bit less flexible.&lt;/p&gt;
    &lt;p&gt;Thanks to Jonathan StrÃ¶bele for contributing this idea and implementation in Ticket #36186, and to David Smith, Paolo Melchiorre, and Sarah Boyce for reviewing.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;code&gt;querystring&lt;/code&gt; template tag enhancements&lt;/head&gt;
    &lt;p&gt;There are two extensions to the &lt;code&gt;querystring&lt;/code&gt; template tag, which was added in Django 5.1 to help with building links that modify the current requestâs query parameters.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Release note:&lt;/p&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;querystring&lt;/code&gt;template tag now consistently prefixes the returned query string with a&lt;code&gt;?&lt;/code&gt;, ensuring reliable link generation behavior.&lt;p&gt;This small change improves how the tag behaves when an empty mapping of query parameters are provided. Say you had a template like this:&lt;/p&gt;&lt;quote&gt;&amp;lt;a href="{% querystring params %}"&amp;gt;Reset search&amp;lt;/a&amp;gt;&lt;/quote&gt;&lt;p&gt;â¦where&lt;/p&gt;&lt;code&gt;params&lt;/code&gt;is a dictionary that may sometimes be empty. Previously, if&lt;code&gt;params&lt;/code&gt;was empty, the output would be:&lt;quote&gt;&amp;lt;a href=""&amp;gt;Reset search&amp;lt;/a&amp;gt;&lt;/quote&gt;&lt;p&gt;Browsers treat this as a link to the same URL including the query parameters, so it would not clear the query parameters as intended. Now, with this change, the output will be:&lt;/p&gt;&lt;quote&gt;&amp;lt;a href="?"&amp;gt;Reset search&amp;lt;/a&amp;gt;&lt;/quote&gt;&lt;p&gt;Browsers treat&lt;/p&gt;&lt;code&gt;?&lt;/code&gt;as a link to the same URL without any query parameters, clearing them as the user would expect.&lt;p&gt;Thanks to Django Fellow Sarah Boyce for spotting this improvement and implementing the fix in Ticket #36268, and for Django Fellow Natalia Bidart for reviewing!&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Release note:&lt;/p&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;querystring&lt;/code&gt;template tag now accepts multiple positional arguments, which must be mappings, such as&lt;code&gt;QueryDict&lt;/code&gt;or&lt;code&gt;dict&lt;/code&gt;.&lt;p&gt;This enhancement allows the tag to merge multiple sources of query parameters when building the output. For example, you might have a template like this:&lt;/p&gt;&lt;quote&gt;&amp;lt;a href="{% querystring request.GET super_search_params %}"&amp;gt;Super search&amp;lt;/a&amp;gt;&lt;/quote&gt;&lt;p&gt;â¦where&lt;/p&gt;&lt;code&gt;super_search_params&lt;/code&gt;is a dictionary of extra parameters to add to make the current search âsuperâ. The tag merges the two mappings, with later mappings taking precedence for duplicate keys.&lt;p&gt;Thanks again to Sarah Boyce for proposing this improvement in Ticket #35529, to Giannis Terzopoulos for implementing it, and to Natalia Bidart, Sarah Boyce, and Tom Carrick for reviewing!&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Fin&lt;/head&gt;
    &lt;p&gt;Thatâs a wrap! Thank you for reading my highlights. There are plenty more changes to read about in the release notes.&lt;/p&gt;
    &lt;p&gt;Also, there are always many more behind-the-scenes improvements and bug fixes that donât make it into the release notes. Optimizations and micro-improvements get merged all the time, so donât delay, upgrade today!&lt;/p&gt;
    &lt;p&gt;Thank you to all 174 people who contributed to Django 6.0, as counted in this list by Mariusz Felisiak.&lt;/p&gt;
    &lt;p&gt;May your upgrade be swift, smooth, safe, and secure,&lt;/p&gt;
    &lt;p&gt;âAdam&lt;/p&gt;
    &lt;p&gt;ð¸ð¸ð¸ Check out my new book on using GitHub effectively, Boost Your GitHub DX! ð¸ð¸ð¸&lt;/p&gt;
    &lt;p&gt;One summary email a week, no spam, I pinky promise.&lt;/p&gt;
    &lt;p&gt;Related posts:&lt;/p&gt;
    &lt;p&gt;Tags: django&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46210240</guid><pubDate>Tue, 09 Dec 2025 20:33:14 +0000</pubDate></item><item><title>Qt, Linux and everything: Debugging Qt WebAssembly</title><link>http://qtandeverything.blogspot.com/2025/12/debugging-qt-webassembly-dwarf.html</link><description>&lt;doc fingerprint="ef121c580b3130e5"&gt;
  &lt;main&gt;
    &lt;p&gt;One of the most tedious tasks a developer will do is debugging a nagging bug. It's worse when it's a web app, and even worse when its a webassembly web app.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;The easiest way to debug Qt Webassembly is by configuring using the -g argument, or CMAKE_BUILD_TYPE=Debug . Emscripten embeds DWARF symbols in the wasm binaries. &lt;/p&gt;
    &lt;p&gt;NOTE: Debugging wasm files with DWARF works only in the Chrome browser with the help of a browser extension.&lt;/p&gt;
    &lt;p&gt;C/C++ DevTools Support (DWARF) browser extension. If you are using Safari or Firefox, or do not want to or cannot install a browser extension, you will need to generate source maps, which I will look at in my next blog post.&lt;/p&gt;
    &lt;head rend="h3"&gt;DWARF debugging&lt;/head&gt;
    &lt;p&gt;You need to also enable DWARF in the browser developer tools settings, but you do not need symlinks to the source directories, as you would need to using source maps, as the binaries are embedded with the full directory path. Like magic!&lt;/p&gt;
    &lt;p&gt;Emscripten embeds DWARF symbols into the binaries built with -g by default, so re-building Qt or your application in debug mode is all you need to do.&lt;/p&gt;
    &lt;p&gt;Qt builds debug libraries by default using the optimized argument -g2, which produces less debugging info, but results in faster link times. To preserve debug symbols you need to build Qt debug using the -g or -g3 argument. Both of these do the same thing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Using DWARF debugger&lt;/head&gt;
    &lt;p&gt;You can then step though your code as you would debugging a desktop application.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46210806</guid><pubDate>Tue, 09 Dec 2025 21:19:37 +0000</pubDate></item><item><title>Linux CVEs, more than you ever wanted to know</title><link>http://www.kroah.com/log/blog/2025/12/08/linux-cves-more-than-you-ever-wanted-to-know/</link><description>&lt;doc fingerprint="d713115f51c1b7bb"&gt;
  &lt;main&gt;
    &lt;p&gt;It’s been almost 2 full years since Linux became a CNA (Certificate Numbering Authority) which meant that we (i.e. the kernel.org community) are now responsible for issuing all CVEs for the Linux kernel. During this time, we’ve become one of the largest creators of CVEs by quantity, going from nothing to number 3 in 2024 to number 1 in 2025. Naturally, this has caused some questions about how we are both doing all of this work, and how people can keep track of it.&lt;/p&gt;
    &lt;p&gt;I’ve given a number of talks over the past years about this, starting with the Open Source security podcast right after we became a CNA and then the Kernel Recipes 2024 talk, “CVEs are alive, but do not panic” and then a talk at OSS Hong Kong 2024 about the same topic with updated numbers and later a talk at OSS Japan 2024 with more info about the same topic and finally for 2024 a talk with more detail that I can’t find the online version.&lt;/p&gt;
    &lt;p&gt;In 2025 I did lots of work on the CRA so most of my speaking over this year has been about that topic , but the CVE assignment work continued on, evolving to meet many of the issues we had in our first year of being a CNA. As that work is not part of the Linux kernel source directly, it’s not all that visable to the normal development process, except for the constant feed on the linux-cve-announce mailing list I figured it was time to write down how this is all now working, as well a bunch of background information about how Linux is developed that is relevant for how we do CVE reporting (i.e. almost all non-open-source-groups don’t seem to know how to grasp our versioning scheme.)&lt;/p&gt;
    &lt;p&gt;There is a in-kernel document that describes how CVEs can be asked for from the kernel community, as well as a basic summary of how CVEs are automatically asigned. But as we are an open community, it’s good to go into more detail as to how all of us do this work, explaining how our tools have evolved over time and how they work, why some things are the way they are for our releases, as well as document a way that people can track CVE assignments on their own in a format that is, in my opinion, much simpler than attempting to rely on the CVE json format (and don’t get me started on NVD…)&lt;/p&gt;
    &lt;p&gt;So here’s a series of posts going into all of this, hopefully providing more information than you ever wanted to know, which might be useful for other open source projects as they start to run into many of the same issues we have already dealt with (i.e. how to handle reports at scale):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linux kernel versions, how the Linux kernel releases are numbered.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46211802</guid><pubDate>Tue, 09 Dec 2025 22:47:36 +0000</pubDate></item><item><title>Cloudflare error page generator</title><link>https://github.com/donlon/cloudflare-error-page</link><description>&lt;doc fingerprint="f82eaa0a8486a8cc"&gt;
  &lt;main&gt;
    &lt;p&gt;📢 Update (2025/12/09): All icons used in the error page have been fully redrawn as vector assets. These icons along with the stylesheet are also inlined into a single file of the error page, eliminating any need of hosting additional resources and ensuring better experience for you and your end users.&lt;/p&gt;
    &lt;p&gt;This project creates customized error pages that mimics the well-known Cloudflare error page. You can also embed it into your website.&lt;/p&gt;
    &lt;p&gt;Here's an online editor to create customized error pages. Try it out here.&lt;/p&gt;
    &lt;p&gt;Install &lt;code&gt;cloudflare-error-page&lt;/code&gt; with pip.&lt;/p&gt;
    &lt;code&gt;pip install git+https://github.com/donlon/cloudflare-error-page.git&lt;/code&gt;
    &lt;p&gt;Then you can generate an error page with the &lt;code&gt;render&lt;/code&gt; function. (example.py)&lt;/p&gt;
    &lt;code&gt;import webbrowser
from cloudflare_error_page import render as render_cf_error_page

# This function renders an error page based on the input parameters
error_page = render_cf_error_page({
    # Browser status is ok
    'browser_status': {
        "status": 'ok',
    },
    # Cloudflare status is error
    'cloudflare_status': {
        "status": 'error',
        "status_text": 'Error',
    },
    # Host status is also ok
    'host_status': {
        "status": 'ok',
        "location": 'example.com',
    },
    # can be 'browser', 'cloudflare', or 'host'
    'error_source': 'cloudflare',

    # Texts shown in the bottom of the page
    'what_happened': '&amp;lt;p&amp;gt;There is an internal server error on Cloudflare\'s network.&amp;lt;/p&amp;gt;',
    'what_can_i_do': '&amp;lt;p&amp;gt;Please try again in a few minutes.&amp;lt;/p&amp;gt;',
})

with open('error.html', 'w') as f:
    f.write(error_page)

webbrowser.open('error.html')&lt;/code&gt;
    &lt;p&gt;You can also see live demo here.&lt;/p&gt;
    &lt;p&gt;A demo server using Flask is also available in flask_demo.py.&lt;/p&gt;
    &lt;code&gt;// Coming soon!&lt;/code&gt;
    &lt;code&gt;/* Coming soon! */&lt;/code&gt;
    &lt;code&gt;params = {
    "title": "Catastrophic infrastructure failure",
    "more_information": {
        "for": "no information",
    },
    "browser_status": {
        "status": "error",
        "status_text": "Out of Memory",
    },
    "cloudflare_status": {
        "status": "error",
        "location": "Everywhere",
        "status_text": "Error",
    },
    "host_status": {
        "status": "error",
        "location": "example.com",
        "status_text": "On Fire",
    },
    "error_source": "cloudflare",
    "what_happened": "&amp;lt;p&amp;gt;There is a catastrophic failure.&amp;lt;/p&amp;gt;",
    "what_can_i_do": "&amp;lt;p&amp;gt;Please try again in a few years.&amp;lt;/p&amp;gt;",
}&lt;/code&gt;
    &lt;code&gt;params = {
    "title": "Web server is working",
    "error_code": 200,
    "more_information": {
        "hidden": True,
    },
    "browser_status": {
        "status": "ok",
        "status_text": "Seems Working",
    },
    "cloudflare_status": {
        "status": "ok",
        "status_text": "Often Working",
    },
    "host_status": {
        "status": "ok",
        "location": "example.com",
        "status_text": "Almost Working",
    },
    "error_source": "host",
    "what_happened": "&amp;lt;p&amp;gt;This site is still working. And it looks great.&amp;lt;/p&amp;gt;",
    "what_can_i_do": "&amp;lt;p&amp;gt;Visit the site before it crashes someday.&amp;lt;/p&amp;gt;",
}&lt;/code&gt;
    &lt;head rend="h3"&gt;How to show real user IP / Cloudflare Ray ID / data center location in the error page so that it looks more realistic?&lt;/head&gt;
    &lt;p&gt;Ray ID and user IP field in the error page can be set by &lt;code&gt;ray_id&lt;/code&gt; and &lt;code&gt;client_ip&lt;/code&gt; properties in the &lt;code&gt;params&lt;/code&gt; argument passed to the render function. The real Cloudflare Ray ID and the data center location of current request can be extracted from the &lt;code&gt;Cf-Ray&lt;/code&gt; request header (e.g. &lt;code&gt;Cf-Ray: 230b030023ae2822-SJC&lt;/code&gt;). Detailed description of this header can be found in Cloudflare documentation.&lt;/p&gt;
    &lt;p&gt;To lookup the city name of the data center corresponding to the three letter code in the header, you can use a location list from here&lt;/p&gt;
    &lt;p&gt;The demo server runs in our website did handle these. Take a look at this file for reference.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;cloudflare-error-page-3th.pages.dev:&lt;/p&gt;
        &lt;p&gt;Error page of every HTTP status code (reload to show random page).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;React reimplementation of the original page, and can be deployed directly to Cloudflare Pages.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
    "html_title": "cloudflare.com | 500: Internal server error",
    "title": "Internal server error",
    "error_code": 500,
    "time": "2025-11-18 12:34:56 UTC",  // if not set, current UTC time is shown

    // Configuration for "Visit ... for more information" line
    "more_information": {
        "hidden": false,
        "text": "cloudflare.com", 
        "link": "https://www.cloudflare.com/",
        "for": "more information",
    },

    // Configuration for the Browser/Cloudflare/Host status
    "browser_status": {
        "status": "ok", // "ok" or "error"
        "location": "You",
        "name": "Browser",
        "status_text": "Working",
        "status_text_color": "#9bca3e",
    },
    "cloudflare_status": {
        "status": "error",
        "location": "Cloud",
        "name": "Cloudflare",
        "status_text": "Error",
        "status_text_color": "#bd2426",
    },
    "host_status": {
        "status": "ok",
        "location": "The Site",
        "name": "Host",
        "status_text": "Working",
        "status_text_color": "#9bca3e",
    },
    "error_source": "host", // Position of the error indicator, can be "browser", "cloudflare", or "host"

    "what_happened": "&amp;lt;p&amp;gt;There is an internal server error on Cloudflare's network.&amp;lt;/p&amp;gt;",
    "what_can_i_do": "&amp;lt;p&amp;gt;Please try again in a few minutes.&amp;lt;/p&amp;gt;",

    "ray_id": '0123456789abcdef',  // if not set, random hex string is shown
    "client_ip": '1.1.1.1',

    // Configuration for 'Performance &amp;amp; security by ...' in the footer
    "perf_sec_by": {
        "text": "Cloudflare",
        "link": "https://www.cloudflare.com/",
    },
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46213273</guid><pubDate>Wed, 10 Dec 2025 02:18:07 +0000</pubDate></item><item><title>Rust in the kernel is no longer experimental</title><link>https://lwn.net/Articles/1049831/</link><description>&lt;doc fingerprint="d471e1fbb83f6f8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The end of the kernel Rust experiment&lt;/head&gt;
    &lt;p&gt; (Stay tuned for details in our Maintainers Summit coverage.)&lt;/p&gt;
    &lt;p&gt; Posted Dec 10, 2025 4:25 UTC (Wed) by ktkaffee (subscriber, #112877) [Link] (7 responses) Posted Dec 10, 2025 4:45 UTC (Wed) by josh (subscriber, #17465) [Link] (5 responses) Posted Dec 10, 2025 4:48 UTC (Wed) by corbet (editor, #1) [Link] (2 responses) Posted Dec 10, 2025 5:24 UTC (Wed) by josh (subscriber, #17465) [Link] (And don't worry, you'd have to fall *very* far, very consistently, to limbo under the low bar Phoronix has set for clickbait.) Posted Dec 10, 2025 6:04 UTC (Wed) by rolexhamster (guest, #158445) [Link] (1 responses) Elitist much? Notwithstanding the low quality user comments on Phoronix and somewhat challenged writing in its news items, the site does provide useful info by way of frequent updates of what's happening in and around the open source ecosystem. Its benchmarks have also uncovered problems in the Linux kernel. In certain ways it's complementary to LWN's coverage. Posted Dec 10, 2025 7:49 UTC (Wed) by Cyberax (✭ supporter ✭, #52523) [Link] Posted Dec 10, 2025 7:57 UTC (Wed) by alspnost (guest, #2763) [Link] Posted Dec 10, 2025 6:32 UTC (Wed) by mrcroxx (guest, #161669) [Link] &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head/&gt; Ouch. That is what I get for pushing something out during a meeting, I guess. That was not my point; the experiment is done, and it was a success. I meant no more than that. &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head/&gt; &amp;gt; Phoronix would be proud of that headline. &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Nice&lt;/head&gt;&lt;head/&gt; Same here - for a second, I thought they were about to rip it all out for v6.20 -&amp;gt; 7.0! &lt;head&gt;Nice&lt;/head&gt;&lt;head&gt;Meme&lt;/head&gt;&lt;lb/&gt; &amp;gt;&lt;lb/&gt; &amp;gt; rachel: mike that's a horrible way of telling people we're married&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46213585</guid><pubDate>Wed, 10 Dec 2025 03:15:24 +0000</pubDate></item><item><title>'Source available' is not open source (and that's okay)</title><link>https://dri.es/source-available-is-not-open-source-and-that-is-okay</link><description>&lt;doc fingerprint="a5475b19deb33536"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;'Source available' is not open source (and that's okay)&lt;/head&gt;
    &lt;p&gt;This week, Ruby on Rails creator David Heinemeier Hansson and WordPress founding developer Matt Mullenweg started fighting about what "open source" means. I've spent twenty years working on open source sustainability, and I have some thoughts.&lt;/p&gt;
    &lt;p&gt;David Heinemeier Hansson (also known as DHH) released a new kanban tool, Fizzy, this week and called it open source.&lt;/p&gt;
    &lt;p&gt;People quickly pointed out that the O'Saasy license that Fizzy is released under blocks others from offering a competing SaaS version, which violates the Open Source Initiative's definition. When challenged, he brushed it off on X and said, "You know this is just some shit people made up, right?". He followed with "Open source is when the source is open. Simple as that".&lt;/p&gt;
    &lt;p&gt;This morning, Matt Mullenweg rightly pushed back. He argued that you can't ignore the Open Source Initiative definition. He compared it to North Korea calling itself a democracy. A clumsy analogy, but the point stands.&lt;/p&gt;
    &lt;p&gt;Look, the term "open source" has a specific, shared meaning. It is not a loose idea and not something you can repurpose for marketing. Thousands of people shaped that definition over decades. Ignoring that work means benefiting from the community while setting aside its rules.&lt;/p&gt;
    &lt;p&gt;This whole debate becomes spicier knowing that DHH was on Lex Fridman's podcast only a few months ago, appealing to the spirit and ethics of open source to criticize Matt's handling of the WP Engine dispute. If the definition is just "shit people made up", what spirit was Matt violating?&lt;/p&gt;
    &lt;p&gt;The definition debate matters, but the bigger issue here is sustainability. DHH's choice of license reacts to a real pressure in open source: many companies make real money from open source software while leaving the hard work of building and maintaining it to others.&lt;/p&gt;
    &lt;p&gt;This tension also played a role in Matt's fight with WP Engine, so he and DHH share some common ground, even if they handle it differently. We see the same thing in Drupal, where contributions from the biggest companies in our ecosystem is extremely uneven.&lt;/p&gt;
    &lt;p&gt;DHH can experiment because Fizzy is new. He can choose a different license and see how it works. Matt can't as WordPress has been licensed under the GPL for more than twenty years. Changing that now is virtually impossible.&lt;/p&gt;
    &lt;p&gt;Both conversations are important, but watching two of the most influential people in open source argue about definitions while we all wrestle with free riders feels a bit like firefighters arguing about hose lengths during a fire.&lt;/p&gt;
    &lt;p&gt;The definition debate matters because open source only works when we agree on what the term means. But sustainability decides whether projects like Drupal, WordPress, and Ruby on Rails keep thriving for decades to come. That is the conversation we need to have.&lt;/p&gt;
    &lt;p&gt;In Drupal, we are experimenting with contribution credits and with guiding work toward companies that support the project. These ideas have helped, but also have not solved the imbalance.&lt;/p&gt;
    &lt;p&gt;Six years ago I wrote in my Makers and Takers blog post that I would love to see new licenses that "encourage software free riding", but "discourage customer free riding". O'Saasy is exactly that kind of experiment.&lt;/p&gt;
    &lt;p&gt;A more accurate framing would be that Fizzy is source available. You can read it, run it, and modify it. But DHH's company is keeping the SaaS rights because they want to be able to build a sustainable business. That is defensible and generous, but it is not open source.&lt;/p&gt;
    &lt;p&gt;I still do not have the full answer to the open source sustainability problem. I have been wrestling with it for more than twenty years. But I do know the solution is not renaming the problem.&lt;/p&gt;
    &lt;p&gt;Some questions are worth asking, and answering:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How do we distinguish between companies that can't contribute and those that won't?&lt;/item&gt;
      &lt;item&gt;What actually changes corporate behavior: shame, self-interest, punitive action, exclusive benefits, or regulation?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If this latest fight nudges us away from word games and toward these questions, some good may come from it.&lt;/p&gt;
    &lt;p&gt;— Dries Buytaert&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46213709</guid><pubDate>Wed, 10 Dec 2025 03:33:14 +0000</pubDate></item><item><title>Dependable C</title><link>https://dependablec.org/</link><description>&lt;doc fingerprint="3e7bdb99b8231ac8"&gt;
  &lt;main&gt;&lt;p&gt;Dependable C, is an attempt to document a subset of C for developers who want to write Dependable C.&lt;/p&gt;&lt;p&gt;C23, and the upcoming C2Y are language versions that have become increasingly complex, include many new keywords, flow control, and a revised Charter that differs from "Classic C". Later versions of C are also only supported by 2 implementations out of the hundreds of C implementations available. The Delta between ANSI C and C2Y is arguably larger than the Delta between ANSI C and the first version of C++.&lt;/p&gt;&lt;p&gt;This means that for developers who want to develop, widely portable, and compilable, software in Classic C, the latest ISO C standards are a poor guide. Reading earlier versions of standards is also not sufficient, since they do not include lists of features that have since been deprecated, or any guide as to what parts of the standard have had poor implementation support.&lt;/p&gt;&lt;p&gt;Dependable C is trying to fill this gap.&lt;/p&gt;&lt;p&gt;C is the most portable and widely implemented language available. C has been called the Lingua-franca of computing. A problem solved in C will remain solved for the foreseeable future. Changes in operating systems, computing environments, or hardware are unlikely to render a well written C implementation obsolete. A library written in C will be able to be used from almost any language. While many programmers don't use, many can read and understand C. This mean that code written in C can be modified by a larger pool of programmers.&lt;/p&gt;&lt;p&gt;If quality is the measure of longevity, C is a prime candidate for writing high quality code.&lt;/p&gt;&lt;p&gt;Not all C code is portable, or will compile the same in all compilers, or can even be understood by most C programmers. C has a long history of quirks, and corner cases that can be hard to navigate. Writing non-portable code that is only intended to run on one platform and be built with a particular tool chain is perfectly legitimate, but if you want to write code that is portable, and remains usable for decades this guide if for you. Who values writing code that is guaranteed to compile and work correctly, over having the latest language features.&lt;/p&gt;&lt;p&gt;Dependable C is the opposite of a dialect. It is a C that is trying to be as middle of the road as possible in order to be understood and implemented as widely as possible. Think of it as Newscaster C, a neutral, universally understood, language.&lt;/p&gt;&lt;p&gt;Dependable C is not a style guide, it does not prescribe formatting, indentation and style. It simply tries to document what C functionality can be depended on and how. It is perfectly valid to use Dependable C as a guide for what functionality to use, while at the same time to adhere to a style guide like Misra. The Misra standard prioritizes safety, where as Dependable C prioritizes Compatibility. It is entirely possible to adhere both at the same time.&lt;/p&gt;&lt;p&gt;In some cases features that have been introduced in later versions are needed, and in these cases we will try to document how to access these features in a dependable way.&lt;/p&gt;&lt;p&gt;Many languages have derived their syntax from C. C++, Java, C#, D, Javascript, Objective-C to name a few. Almost all of these languages are based on C89, and have not incorporated C99 or later features.&lt;/p&gt;&lt;p&gt;The purpose of this project is to document the small subset of C that is dependable, it therefor high discourages writing standard compliant code without any UB code. However in some very rare occasions, this guide will highlight where writing code that is technically UB is permitted, because in practice it is dependable. Likewise there are many, many ways to write technically standard compliant code, that will be far from dependable, and in some cases no implementations do not even exist (See annex K). The goal is to give guidance as how to write code that works in the real world, on real implementations, not just paper products produced by a standard body. Having written that, most implementations study the standard carefully and do their best to follow it, and the standard body goes to considerable length to try to make the standard as complete and clear as possible.&lt;/p&gt;&lt;p&gt;This page is maintained by Eskil Steenberg Hald. I am a long time C developer, and represent Sweden in the C standard board. This page is maintained to chronicle my own understanding of the language, and as a guide for my employees and anyone who wants to write dependable C. I consider myself as an expert in writing software in C, Undefined behaviour and I'm proficient in the memory model and concurrency model (I would probably rank as one of the worlds experts in these two areas, but I still do not want to claim to understand them fully...). I would consider myself less experienced in "Modern" versions of the language. Id appreciate any corrections to this document, or proposed additions. It would be much appreciated. I am especially interested in hearing about C features that people have found to be unreliable in any implementation. You can Email me eskil at dependablec dot com. This website is perpetually a work in progress and incomplete.&lt;/p&gt;&lt;p&gt;My participation in the wg14 C standard board is for my own education and participation in the Memory model and Undefined behaviour study groups. My intention is to try to share as mush of my learnings from the wg14 on this website. Because I will never use any of the newer versions of the language, and do not recommend their use, I abstain from voting in the languages development.&lt;/p&gt;�&lt;p&gt;Most other languages only have one or very few implementations. This means you can rely on the implementations behaviour to not vary between platforms. C has numerus implementations and with a very wide range of complexity and feature support.&lt;/p&gt;&lt;p&gt;Many C implementations have bugs, and they mostly manifest when you stretch the language to its limits. All basic functionality can be relied on because the most idiomatic code is also the most tested code. Compiler developers use publicly available code to test their implementations, and therefore a more common construct is much more likely to have been rigorously tested than an esoteric corner case. By writing code in a syntax that you can be sure all compilers have encountered in the past, you minimize the chance that you will trigger a bug.&lt;/p&gt;&lt;p&gt;Code should try to avoid relying on the user having the latest version of a compiler. Some platforms may have had their support deprecated by major compilers, or may only be supported by a specific compiler. Projects that incorporate&lt;/p&gt;�&lt;p&gt;Dependable C advocates for using a sub set of all versions of C.&lt;/p&gt;&lt;p&gt;Given that C89 is the smallest of the C standards, in practice this means a subset of C89. Simply using the C89 standard is not enough to fully understand C. Many of the changes that have been made to the C standard text in the years since it was published, address ambiguities and issues with previous versions. If something is unclear in one standard but has been clarified in later standards, users tend to get the clarified behaviour even when they set their compiler to follow the earlier standard. Given that C89/ANSI C was the first versions of the language, it is the version of the standard written with the least implementation experience, and therefore have lots of issues.&lt;/p&gt;&lt;p&gt;Many languages have derived their syntax from C. C++, Java, C#, D, Javascript, Objective-C to name a few. Almost all of these languages are based on C89, and have not incorporated C99 or later features. This means that programmers who mainly use these languages have difficulty reading code written using the later versions.&lt;/p&gt;&lt;p&gt;While a C89 subset is recommended, the point of writing Dependable C is to be universally accepted, and that includes being accepted by compilers set to any version of C. You may choose to set your compiler to adhere to a strict C89 subset in order to verify that your code is not using any newer functionality, but it should run just as well using any other version of C. Your code should not require a compiler that has a C89 mode, it should be universal. This is why Dependable C discourages the use of any deprecated functionality or any functionality that clashes with new C features (see "auto").&lt;/p&gt;&lt;p&gt;The vast majority of features added to the C standard since C89 add new ways of doing thing that are already possible to do in C89 if you know how. Its our intention to try to document as much as possible of this over time. In some cases features that have been introduced in later versions are needed, and in these cases we will try to document how to access these features in the most dependable way possible.&lt;/p&gt;�&lt;p&gt;The C programming language is, unfortunately unfixable. Fortunately C is good enough not to need to be fixed.&lt;/p&gt;&lt;p&gt;One of the greatest strengths of C is its compatibility. C have more implementations than any other programming language, more existing code, more documentation and more experienced programmers than any other language. The cost of breaking all of this compatibility, is simply higher than the value brought by any improvements in the language.&lt;/p&gt;&lt;p&gt;There are a wide range of C dialects and proposed replacement, that all try to fix precited deficiencies of C. However, almost none of them have had any success.&lt;/p&gt;&lt;p&gt;The ISO C standard has until C23 been taking backwards compatibility seriously. This means that they have been unable to remove functionality, only add new functionality. On some rare occasions, features have been marked as deprecated, but in practice, it has not been possible to remove these features from implementations, because users simply need these features to compile existing code.&lt;/p&gt;&lt;p&gt;A situation where features can only be added, never removed, serves a language like C poorly, since one of its core values is its simplicity, compactness and easy of implementation. Stability is also poorly maintained by a group of language designers, who not surprisingly, want to design language features. People do not join standard organizations in order to not develop the standard. (In general, my personal experience is that the members of the ISO C wg14 standard body, are competent, hardworking and very knowledgeable, and have the best of intentions. However, when enough people want to add "just one thing", the result is not a clean design)&lt;/p&gt;&lt;p&gt;While the wg14 have historically, worked hard to maintain backwards compatibility, they have ignored compatibility in the opposite direction. Writing code in newer versions of C simply makes it incompatible with many platforms and implementations. Often code written in newer versions of the language will not compile in older implementations, but on occasions the meaning of the code would simply change. This is obviously very dangerous.&lt;/p&gt;&lt;p&gt;An example of this hazard is the removal of some UB. On first glance, it seems like a clear improvement to define behaviours that have in the past needlessly been undefined. But it is problematic, if programmers reads a later standard that makes a guarantee, that isn't guaranteed in most implementations that where written before the behaviour was defined. The behaviour may be technically defined, but in practice it is still not dependable since it has a history of being undefined, and unlike in the past, this hazard is no longer clearly spelled out in the standard. The good intended effort to remove an issue, instead creates an issue. This is one of the issues that compelled the Dependable C effort.&lt;/p&gt;&lt;p&gt;A time traveller going back to 1972, could address many issues in C, but today the situation is much more complicated. Luckily, the small subset defined here, is more than capable of doing everything that needs to be done. In the grand scheme of thing, the sacrifices are minor. Most of the issues of C, for a developer can simply be addressed by "just don't do that then", implementations don't have that luxury since they need to compile existing code that isn't always as well written.&lt;/p&gt;�&lt;p&gt;Any software project has requirements, just because your code adheres to a language standard, does not mean that it is meaningful to run on all platforms that do support the language. C is a language that can be implemented on very exotic platforms, where for instance bytes aren't 8 bit or that have very limited memory. It is perfectly reasonable to write software that follows the Dependable C guidelines, but that isn't portable to hardware having smaller pointers than 64 bits.&lt;/p&gt;&lt;p&gt;- Bytes are 8 bits.&lt;/p&gt;&lt;p&gt;- Types are aligned are no more than their size.&lt;/p&gt;&lt;p&gt;- Function pointer have the same size as data pointers.&lt;/p&gt;&lt;p&gt;None of these are guaranteed by the standard.&lt;/p&gt;&lt;p&gt;I would caution against assuming pointers are and will always be 64 bits on modern platforms as there are new platforms that enable 128 bit pointers. While this is unlikely to come in to mainstream use any time soon, it is likely to be a growing niche. (128 bit pointers allow mapping very large NUMA architectures. for instance it is possible to encode a network address (MAC or IP) and memory address in to one pointer)&lt;/p&gt;�&lt;p&gt;The standard does in some cases mandate the implementation to issue a diagnostic message, but it also defers to implementations to issue warnings for whatever they like. There is therefore no way to write C code that is free from warnings. An implementation is entirely free to warn the user that they are writing C in the first place.&lt;/p&gt;&lt;p&gt;Warnings are thus meant to be ignorable. Many implementations have options that turn all warnings in to errors, many developers have as a policy to turn this feature on. This causes a problem, because as implementations advance and are able to detect more issues, new warnings causes builds to break. This in turn causes users to complain to the implementors, and implementors are disincentivised from providing additional diagnostics. Many or the major C implementations like gcc, llvm, and Msvc refrain from adding almost any new warnings for this reason.&lt;/p&gt;&lt;p&gt;This means that many warnings are turned off by default, and users have to manually turn them on. Many warnings warn are benign issues, while some really important warnings may be turned off by default. Because of this we recommend, taking the time to enable and disable warnings that are relevant to you and your coding style. We also do recommend turning relevant warnings in to errors, during development. What warnings you enable, disable, or elevate to errors, should depend on your requirements, and the types of bugs you tend to write, and you and your teams experience level. All developers are different, and there are many practices that some developers would want the compiler to warn against, that other developers are comfortable using to their advantage.&lt;/p&gt;�&lt;p&gt;Dependable C, encourages C++ compatibility in all interfaces, but does not guarantee code to be compiled correctly in a C++ compiler. C++ is not a subset of C, and the differences between the two languages are subtitle and often unintended. Being able to write Code that is guaranteed to produce the same results in both C and C++ requires deep knowledge of both languages and is not something we recommend. We strongly encourage header files to be C++ compatible and not contain any functions. We also discourage any use of C++ keywords.&lt;/p&gt;�&lt;p&gt;C can run on almost any kind of hardware. It would be impossible for the standard to describe how the code would executed on every possible hardware. Instead the C standard describes an imaginary hardware architecture know as the "abstract machine", and then stipulates that a real world implementations on real world hardware can do what ever they want as long as the result, is the same AS-IF, it ran on the abstract machine.&lt;/p&gt;&lt;p&gt;The AS-IF concept is the foundation of C that enables compilers to optimize code, making C the gold standard for performance and power efficiency. Some things in C are designated as output from the program, and must therefore match exactly the output of the abstract machine. This is known as "Observable behaviour", or just "Behaviour" (Undefined Behaviour, is NOT a behaviour). IT is very important to distinguish between operation that happen in the abstract machine, and things that happen outside the abstract machine that are observable. Most of operations in C happen inside the abstract machine, only I/O functionality like printf, and values that have the qualifier volatile are observable in C.&lt;/p&gt;&lt;p&gt;The implementation can do any transform it wants to with the code that is withing the abstract machine, but must strictly follow the output and ordering of any observable behaviour.&lt;/p&gt;&lt;p&gt;Consider the following:&lt;/p&gt;&lt;p&gt;'''&lt;/p&gt;&lt;p&gt;int x;&lt;/p&gt;&lt;p&gt;x = 3;&lt;/p&gt;&lt;p&gt;x += 2;&lt;/p&gt;&lt;p&gt;printf("Hello");&lt;/p&gt;&lt;p&gt;printf(" World %u\n", x);&lt;/p&gt;&lt;p&gt;'''&lt;/p&gt;&lt;p&gt;In this program the assignment and addition to the variable x happens entirely within the abstract machine. Where as the two printfs are observable and must be executed in order and have the same output as if the program ran in the abstract machine. The compiler can not transform the program in to this, since it would change the observable behaviour:&lt;/p&gt;&lt;p&gt;'''&lt;/p&gt;&lt;p&gt;int x;&lt;/p&gt;&lt;p&gt;x = 3;&lt;/p&gt;&lt;p&gt;x += 2;&lt;/p&gt;&lt;p&gt;printf(" World %i\n", x);&lt;/p&gt;&lt;p&gt;printf("Hello");&lt;/p&gt;&lt;p&gt;'''&lt;/p&gt;&lt;p&gt;Its perfectly able to remove the variable and transform it in to this:&lt;/p&gt;&lt;p&gt;'''&lt;/p&gt;&lt;p&gt;printf("Hello");&lt;/p&gt;&lt;p&gt;printf(" World %u\n", 2 + 3);&lt;/p&gt;&lt;p&gt;'''&lt;/p&gt;&lt;p&gt;or even this:&lt;/p&gt;&lt;p&gt;'''&lt;/p&gt;&lt;p&gt;printf("Hello World 5\n");&lt;/p&gt;&lt;p&gt;'''&lt;/p&gt;&lt;p&gt;As you can see the compiler is free to radicaly re-write the code, as long as the observable behaviour of the program remains identical to what was describes in the source code.&lt;/p&gt;&lt;p&gt;Cs design maps in many regards very well to the instructions implemented in hardware. This gives the false impression that C is a high level assembler, and that the instructions described in the source code are one-to-one translated to the relevant assembler instruction. This is not true. The abstract machine gives the compiler a lot of latitude, to optimize. If you implement rand sort, its entirely legal (although not likely), for a compiler to replace the algorithm with a faster merge sort.&lt;/p&gt;&lt;p&gt;While C appears to map very well to assembler, in many ways it does not. The first and most obvious difference is that most computing architectures can not operate on memory without first moving the content in to registers. Loading and storing in and out of memory is slow, so ideally you want to keep state in registers. In order to do this the compiler has to radically transform the code.&lt;/p&gt;&lt;p&gt;The standard have not requirement what so ever about the ordering of execution in the abstract machine. All observable behaviour must strictly be executed in order. In most cases this is something the programmer can depend on. If a programme writes X and the Y in to a file, it is guaranteed that X will come before Y in the file. However, when we start to deal with synchronization things may become more complex. The first issue is timing, the C standard stipulates that the output must come in order, but&lt;/p&gt;&lt;p&gt;Modern architectures employ multiple levels of caches, are paralyzed, and pipelined, These concepts are almost entirely invisible to C programmers, but in order to be able to optimize for this type of hardware the compiler is to do deep analysis of the code. For most programmers these things are entirely hidden by C and the compiler.&lt;/p&gt;&lt;p&gt;As-if Is meant to be a firewall, between the programmer an the implementation. Ideally the programmer writes not for the hardware or the implementation, but for the abstract machine. The implementation converts operations in this abstract machine in to instructions for the real machine. This fire wall, provides freedom for hardware vendors to invent new architectures, freedom to exploit these hardware architectures for implementors, and a stable platform for software developers. When software developers optimize for a specific hardware&lt;/p&gt;&lt;p&gt;There are a many misconceptions about C, and features that have been added to C that are invalidated by As-if concept.&lt;/p&gt;�&lt;p&gt;[[_TOC_]]&lt;/p&gt;&lt;p&gt;n3308&lt;/p&gt;&lt;p&gt;This document is an educational document that tries to explain the concept of "Undefined behavior" in the C programming language. It is the combined efforts of the ISO WG14's Undefined Behavior Study group, to clarify the term, and its implications.&lt;/p&gt;&lt;p&gt;ISO C defines undefined behavior (UB) in Section 3.4.3 as:&lt;/p&gt;&lt;p&gt;behavior, upon use of a nonportable or erroneous program construct or of erroneous data, for which this document imposes no requirements&lt;/p&gt;&lt;p&gt;Note 1 to entry: Possible undefined behavior ranges from ignoring the situation completely with unpredictable&lt;/p&gt;&lt;p&gt;results, to behaving during translation or program execution in a documented manner characteristic of the&lt;/p&gt;&lt;p&gt;environment (with or without the issuance of a diagnostic message), to terminating a translation or execution&lt;/p&gt;&lt;p&gt;(with the issuance of a diagnostic message).&lt;/p&gt;&lt;p&gt;Note 2 to entry: J.2 gives an overview over properties of C programs that lead to undefined behavior.&lt;/p&gt;&lt;p&gt;Note 3 to entry: Any other behavior during execution of a program is only affected as a direct consequence of&lt;/p&gt;&lt;p&gt;the concrete behavior that occurs when encountering the erroneous or non-portable program construct or data.&lt;/p&gt;&lt;p&gt;In particular, all observable behavior (5.1.2.4) appears as specified in this document when it happens before an&lt;/p&gt;&lt;p&gt;operation with undefined behavior in the execution of the program.&lt;/p&gt;&lt;p&gt;Inherent to the ISO specification of the C programming language is the concept that a set of behaviors are undefined. From this the specification derives several strengths as well as several weaknesses. UB allows a platform to either define platform-specific behaviors or ignore the possibility of an erroneous state. The language does not require a platform to detect these errors.&lt;/p&gt;&lt;p&gt;Undefined behavior is used in many places in the C standard and for several reasons such as:&lt;/p&gt;&lt;p&gt;Undefined behavior can either be explicitly specified in the standard or remain implicit if the standard does not define a behavior. The C standards body has a goal to document all UB in the C standard, but identifying all UB is a difficult and laborious task. The standard states that the rules for undefined behavior extend to behavior that is not specified by the standard.&lt;/p&gt;&lt;p&gt;Additionally, there are paragraphs in the standard where it is unclear whether a behavior is defined or not. This can mean that some platforms treat a behavior as defined while others treat it as undefined. For example, the standard states that the first member of a struct has a zero offset from the struct itself. Some argue that this means that the first member of the struct therefore must have the same pointer address as the struct while others argue that it is undefined if the struct has the same address as its first member, as the standard does not explicitly resolve this ambiguity.&lt;/p&gt;&lt;p&gt;Beyond undefined behavior, the C standard defines a range of terms for behaviors. Unlike undefined behavior, each of these terms do define a constrained behavior where the implementation has some form of responsibility to uphold, even if it may differ between implementations.&lt;/p&gt;&lt;p&gt;All of these are different from Undefined Behavior in that, while they may produce different behaviors on different implementations, they do represent behaviors that a user can depend on, in a ISO compliant C implementation.&lt;/p&gt;&lt;p&gt;The C standard states that any platform is free to detect UB and to provide platform-specific behavior and document this behavior if it wishes. In this sense, what is in strict ISO C terms "UB" may be well-defined behavior on a particular implementation.&lt;/p&gt;&lt;p&gt;This can be very useful, because it enables implementers to extend C's capabilities, and thereby grants users access to platform-specific features. While the C language is designed to enable cross-platform development, developers are free to only support a limited set of platforms. For example, there are implementations of C that do define the behavior of out-of-bounds array writes, signed integer overflow, and dereferencing null pointers.&lt;/p&gt;&lt;p&gt;For brevity, unless otherwise noted, this document will consider UB only in cases where the implementation has not defined a platform-specific behavior or implementation-specific behavior.&lt;/p&gt;&lt;p&gt;Consider the following code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;What should happen if x is 42? A language design could issue an error, exit the program, or resize the array, among other choices. However, any of these choices would require the implementation of the language to perform a test to see if the value is within the valid range of the array.&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;0&lt;/syntax&gt; || &lt;syntax&gt;x&lt;/syntax&gt; &amp;gt;= &lt;syntax&gt;5&lt;/syntax&gt;) {
&lt;lb/&gt;
  &lt;syntax&gt;/* Handle out-of-bounds write */&lt;/syntax&gt;
&lt;lb/&gt;
} &lt;syntax&gt;else&lt;/syntax&gt; {
&lt;lb/&gt;
  &lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This range check would add work for the compiler and execution environment. Adding any requirement to detect if the assignment is out of bounds would come at a cost in run time performance, and complexity. Not only would the implementation have to check each access to the array, but it would also have to keep track of valid array ranges.&lt;/p&gt;&lt;p&gt;C is designed to be fast, simple, and easily implementable; this is why C does not require any detection of out-of-bounds states. Consequentially C cannot define a behavior for a state that isn't detected. The behavior must be undefined.&lt;/p&gt;&lt;p&gt;It is a common misconception that all undefined behavior in the standard stems from oversights, or to the standard body's failure to agree on an appropriate behavior. The above example clearly shows that it is not practical to define any consistent behavior for out-of-bounds array access without imposing considerable burden on the implementation to detect the state. The cost of detecting an erroneous state prevents the language from defining any behavior should it occur.&lt;/p&gt;&lt;p&gt;Furthermore, if the standard were to require a program to exit on an out-of-bounds write, then the following piece of code would become a valid way to exit a program:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;24&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This is not a good way to deliberately exit a program. It is preferred that a program exit in a manner that the standard explicitly documents as exiting, such as by calling a function named `exit`.&lt;/p&gt;&lt;p&gt;Reconsider this code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Another interpretation of the above code is that if there are no requirements for an implementation to handle an out-of-bounds access, then the code contains an implicit contract that `x` can only be between 0 and 4. The implementation can then assume that the user is aware of the contract and consents to it, even if the implementation cannot by itself determine that the contract is valid by analysis of the possible values `x` may hold. The implementation therefore need not check the value of `x`.&lt;/p&gt;&lt;p&gt;If the user cannot guarantee that `x` is within range, they can rewrite the code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;gt;= &lt;syntax&gt;0&lt;/syntax&gt; &amp;amp;&amp;amp; &lt;syntax&gt;x&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;5&lt;/syntax&gt;)
&lt;lb/&gt;
  &lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;One big reason that many behaviors are undefined is that detecting these undefined behaviors may be difficult to do at compile time, or it may impose too much of a performance penalty at run time.&lt;/p&gt;&lt;p&gt;The existence of undefined behavior implies conversely that when a program has no undefined behavior, its behavior is well-specified by the ISO C standard and the platform on which it runs. This is a promise or contract between the ISO C standard, the platform, and the developer. If the program violates this promise, the result can be anything, and is likely to violate the user's intentions, and will not be portable. We will call this promise the "Assumed Absence of UB".&lt;/p&gt;&lt;p&gt;A C program that enters a state of UB can be considered to contain an error that the platform is under no obligation to catch or report and the result could be anything.&lt;/p&gt;&lt;p&gt;Consider this code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;x&lt;/syntax&gt; = (&lt;syntax&gt;x&lt;/syntax&gt; * &lt;syntax&gt;4&lt;/syntax&gt;) / &lt;syntax&gt;4&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;From a mathematical perspective, this operation should not change the value of x. The multiplication and the division should cancel each other out. However, when calculated in a computer, x * 4 may result in a value that may not be expressed using the type of x. If x is an unsigned 32-bit integer with the value 2,000,000,000 and it is multiplied by 4, the operation could wrap on a 32-bit platform and produce 3,705,032,704. The subsequent division by 4 will then produce 926,258,176. Since the standard declares that operations on unsigned integers have defined wrapping behavior, the two operations do not cancel each other out.&lt;/p&gt;&lt;p&gt;If we instead perform the same operation using signed integer types, things might change because signed integer overflow is UB. By using a signed integer, the programmer has agreed to the contract that no operations using the type will ever produce overflow. Therefore, the optimizer is free to ignore any potential overflow, and can assume that the two operations cancel each other out. This mean that there is a significant optimization advantage in declaring that signed integer overflow is UB.&lt;/p&gt;&lt;p&gt;The assumption that the program contains no UB is a powerful tool that compilers can employ to analyze code to find optimizations. If we assume that a program contains no UB, we can use this information to learn about the expected state of the execution. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;If x is any value below 0 or above 4, the code contains UB. On many platforms, `a[-1]` and `a[5]` would be assigned to addresses outside the bounds of `a`. Without requiring implementations to explicitly add bounds checks, it becomes impossible to predict the side effects of an out-of-bounds write. The implementation is therefore allowed to assume that UB will not happen. This phenomenon is known as "Assumed Absence of UB", and it lets compilers make further deductions. By writing the above code, the programmer respects a contract with the compiler that `x` will never exceed the bounds of the array.&lt;/p&gt;&lt;p&gt;If we consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;5&lt;/syntax&gt;) {
&lt;lb/&gt;
  &lt;syntax&gt;// ...
&lt;/syntax&gt;&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this case, since the compiler assumes `x` must be between 0 and 4, the if statement cannot possibly be true. This allows the compiler to optimize away the if statement entirely. This completely conforms to the standard, but it removes some predictability of UB, and can make programs with UB much harder to debug. The out-of-bounds write no longer causes a predictable wild write and it also causes an `if` statement to be removed.&lt;/p&gt;&lt;p&gt;A common bug is to try to detect and avoid signed integer overflow with code like this:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; + &lt;syntax&gt;1&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;x&lt;/syntax&gt;) {
&lt;lb/&gt;
  &lt;syntax&gt;x&lt;/syntax&gt;++;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;If we assume that UB cannot happen, then we must assume the `if` condition must always be true. Consequently, many compilers will optimize away the `if` statement entirely.&lt;/p&gt;&lt;p&gt;The confluence of UB and more aggressive but standards-compliant compiler optimizations exposes latent bugs that may otherwise behave according to user intentions. These bugs are characterized as hard to find and diagnose. These bugs often do not appear at lower optimization levels. This means that such bugs do not appear in executables that developers produce during development. Consequently, these bugs can bypass many tests. Debuggers tend to operate on on executables compiled with lower optimization settings, where many of these issues do not show up. This makes it harder to find and fix these bugs.&lt;/p&gt;&lt;p&gt;An early example of a vulnerability arising from such aggressive optimization is [CERT vulnerability 162289](https://www.kb.cert.org/vuls/id/162289).&lt;/p&gt;&lt;p&gt;A common consideration when discussing UB is the question of when UB is invoked. While some have argued that programs that are able to procure UB have no requirements whatsoever, it is the position of the WG14 UB Study Group that a program must first reach a state of UB before the requirements of the language standard are suspended. This view is shared by implementers, who have had a history of classifying instances where this isn't true as compiler bugs.&lt;/p&gt;&lt;p&gt;Consider the following:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;], &lt;syntax&gt;x&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;scanf&lt;/syntax&gt;(&lt;syntax&gt;"%i"&lt;/syntax&gt;, &amp;amp;&lt;syntax&gt;x&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this example, a user-provided index is used to access an array of five elements. While this program may be bad form, it is well-defined until and unless `scanf` sets `x` to outside the range of the array. The developer has (implicitly) guaranteed that the index used to access the array will stay within the bounds of the array, but this guarantee is maintained outside of the program. Many programs depend on input strictly conforming to a set of requirements to operate correctly. While this may present safety and security issues, the developers must weigh those considerations against other factors, such as performance. Even a strictly-conforming program could enter a state of UB under some environmental circumstances. A program is only erroneous when it reaches UB. An implementation is not released from complying with the ISO C standard because UB is possible when executing that program; the implementation is released only once the program has entered a state of UB.&lt;/p&gt;&lt;p&gt;A core tenet of the C standard is the "as-if" rule. This rule states that an implementation is not required to operate in the way the program is strictly written, so long as the implementation's observable behavior (defined in C23, s5.1.2.3p6) is identical to the program. The program must behave, but not operate, as if the written program was executed.&lt;/p&gt;&lt;p&gt;This means that the actual program behavior can vary radically depending on how an implementation is able to transform the program, as long as its observable behavior remains constant. For example, two non-observable operations can be reordered. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;, &lt;syntax&gt;b&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;b&lt;/syntax&gt; = &lt;syntax&gt;1&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;These are two non-observable assignments (because neither a nor b is `volatile`). As two independent operations they are not required to be executed in any particular order. They may in fact be executed concurrently. If we then consider:&lt;/p&gt;&lt;code&gt;*&lt;syntax&gt;p&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt; / &lt;syntax&gt;y&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;These two operations are also non-observable operations, however both operations can produce UB (either by `p` pointing to a invalid address, or `y` producing a divide by zero). Because the operations are non-observable, they may be re-ordered. If `y` is zero, there is no guarantee that `*p` is written before the program enters a state of UB.&lt;/p&gt;&lt;p&gt;Because any non-observable operation can be reordered and transformed, a program might reach a state of UB in an ordering not explicitly expressed in the source code. Due to the assumed absence of UB, and the "as-if" rule, a program can show symptoms of UB before any actual UB is encountered during program execution. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;0&lt;/syntax&gt; || &lt;syntax&gt;x&lt;/syntax&gt; &amp;gt;= &lt;syntax&gt;5&lt;/syntax&gt;)
&lt;lb/&gt;
   &lt;syntax&gt;y&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Using assumed absence of UB, the implementation can determine that `x` must be a value between 0 and 4, and therefore the `if` statement can be removed. This cases an out-of-order behavior known as "time traveling UB", where a program bug causes unintended consequences before the UB is encountered during program execution. It is as if the UB traveled backwards in time from the array access to the if statement.&lt;/p&gt;&lt;p&gt;Time traveling UB is permitted if it does not interfere with observable behavior that occurs before entering a state of UB. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;0&lt;/syntax&gt;)
&lt;lb/&gt;
   &lt;syntax&gt;y&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;gt;= &lt;syntax&gt;5&lt;/syntax&gt;)
&lt;lb/&gt;
   &lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"Error!\n"&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this case, the call to `printf` is an observable event, and any re-ordering requires it to execute correctly unless it is preceded by a state of UB. The compiler is not permitted to optimize away the second if statement. The first if statement however has no impact on the observable behavior and can therefore be removed.&lt;/p&gt;&lt;p&gt;Note: Historically, there have been cases where time travel has impacted observable state. Implementers have generally considered these to be implementation bugs. To clarify that they indeed are bugs, the document [N3128 Uecker] was proposed and accepted for c23. It adds the non-normative 3rd Note that clarifies the issue in the standard.&lt;/p&gt;&lt;p&gt;Consider this code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;42&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Every time this code runs, it will produce UB. The state of UB does not depend on any dynamic or external factors other than the code being executed. We choose to define this type of UB as "static UB", because it only depends on variables that are known at compile time. The term "static UB" is somewhat complicated because different implementations have differing abilities to detect UB at compile time. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;0&lt;/syntax&gt;) {
&lt;lb/&gt;
  &lt;syntax&gt;y&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
} &lt;syntax&gt;else&lt;/syntax&gt; {
&lt;lb/&gt;
  &lt;syntax&gt;y&lt;/syntax&gt; = &lt;syntax&gt;MAX_INT&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;y&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This code also contains static UB but requires a more complex analysis to reach that conclusion. The term "static UB" denotes any UB that is not dependent on runtime state. An implementation is under no obligation to detect static UB, but if an implementation does detect static UB we have recommendations for how to proceed. Static UB denotes expressions that always produce UB even if it's not proven that the expression will ever be evaluated.&lt;/p&gt;&lt;p&gt;Any statement that produces a state of UB (with the exception of the `unreachable()` macro) is erroneous, unless an implementation has defined its own behavior for that statement. An implementation is under no obligation to detect any UB. If, however, the implementation doesn't detect static UB, it is free to assume the statement will not produce UB. Therefore any static UB (again, excepting `unreachable()`) should be considered a developer error and not an intended use of the language. In these cases, an implementation should issue an error with an appropriate diagnostic when it detects UB.&lt;/p&gt;&lt;p&gt;An implementation can assume that a program will not enter a state of UB, but no implementation should assume that a program that reaches a state of UB is intentional.&lt;/p&gt;&lt;p&gt;Consider again:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;The assignment may or may not produce UB. In this case if we follow the rule "assumed absence of UB", we can assume that `x` must be between 0 and 4. The assignment is an assignment, but it also provides a hint to the compiler as to what `x` may be. If we then add:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;4&lt;/syntax&gt;)
&lt;lb/&gt;
  ...
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;The if statement here can be considered dead code and optimized away. The if statement doesn't produce UB, it just cannot happen without UB. If we instead consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;5&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;4&lt;/syntax&gt;) {
&lt;lb/&gt;
  &lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;x&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Again, this code may or may not trigger UB, but if the assignment is ever executed it is guaranteed to trigger UB. (Note that an implementation is not required to detect the UB). In other words, the UB is static, but only if the assignment is executed.&lt;/p&gt;&lt;p&gt;The correct interpretation of the detected static UB is that the code is erroneous. It is incorrect to interpret the above code as a valid way for the user to express that `x` is 4 or less. The "assumed absence of UB" rule only applies to the way a construct can be assumed to be executed, not that a construct that always produces UB will never be executed. 0ne divided by X, lets the compiler assume X is not zero, and X divided by zero should cause the compiler to assume unintended user error.&lt;/p&gt;&lt;p&gt;The one exception to this is the `unreachable()` macro. The `unreachable()` macro is the only way for a user to express that a statement can be assumed to never be executed. Incidentally, executing `unreachable()` is UB, but it should not be regarded as equivalent to other UB in this regard.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;4&lt;/syntax&gt;)
&lt;lb/&gt;
  &lt;syntax&gt;unreachable&lt;/syntax&gt;();
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This is a correct way to express that a compiler can assume that `x` is smaller or equal to 4. Despite `unreachable()` being UB, it is not equivalent to:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;4&lt;/syntax&gt;)
&lt;lb/&gt;
  &lt;syntax&gt;x&lt;/syntax&gt; /= &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Division by zero is UB, but unlike `unreachable()`, it is assumed to be a user error. The `unreachable()` macro can therefore not be implemented by the user by producing UB in some way other than the `unreachable()` macro. UB is also erroneous even when it can be determined never to be executed. The following can be detected as erroneous:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;if&lt;/syntax&gt; (&lt;syntax&gt;0&lt;/syntax&gt;)
&lt;lb/&gt;
  &lt;syntax&gt;x&lt;/syntax&gt; /= &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;C is designed to make naive, as well as highly optimizing implementations possible. The C standard therefore places no requirements or limits on the efforts an implementation takes to analyze the code. Whichever erroneous UB may be detected will therefore vary between implementations.&lt;/p&gt;&lt;p&gt;Operating systems and even hardware have been designed to mitigate the side effects of unintentional UB, or deliberate sabotage using UB, with features such as protection of the memory containing the executable or execution stack. Due to some of these protections, some UB is predictably caught at run time. This mitigates the unpredictable nature of UB and improves the stability and security of the system. However, this can also give the false impression that some UB has predictable side effects. While dereferencing null pointers is technically UB, doing so has a very predictable outcome (a trap) on many platforms. Even if the behavior of dereferencing null is reliable on a platform, the compilers' assumption that the code will not dereference null will make it unreliable.&lt;/p&gt;&lt;p&gt;Some UB was initially included in the C standard because the standard wanted to allow for different platform designs. Over the years, some designs have grown so dominant that few developers will ever encounter a platform that does not conform to these dominant designs. One example of this is two's-complement arithmetic, which causes signed integer overflow to wrap.&lt;/p&gt;&lt;p&gt;This means that many UBs have predictable behavior on most platforms:&lt;/p&gt;&lt;p&gt;| UB | Convention |&lt;/p&gt;&lt;p&gt;|----|------------|&lt;/p&gt;&lt;p&gt;| Dereferencing null pointer | Traps |&lt;/p&gt;&lt;p&gt;| Signed integer overflow | Wraps |&lt;/p&gt;&lt;p&gt;| Using the offset between 2 allocations | Treats pointers as integer addresses |&lt;/p&gt;&lt;p&gt;| Comparing the pointer to freed memory with a newly allocated pointer | Treats pointers as integer addresses |&lt;/p&gt;&lt;p&gt;| Reading uninitialized memory | You get whatever is there |&lt;/p&gt;&lt;p&gt;Such behavior is not defined by the C standard but can seem to be predictable. Predictability is of great value to most developers. The knowledge of how the underlying platform operates lets the developer predict and diagnose bugs. A trapped null pointer dereference is easy to find in a debugger. In fact, a programmer may deliberately add a null pointer dereference to a program to invoke a core dump. In MSVC uninitialized memory is initialized to 0xCDCDCDCD, a pattern that is instantly recognizable for any experienced Windows programmer. [https://en.wikipedia.org/wiki/Magic_number_(programming)] If the sum of two large positive signed integers results in a negative value, a wise programmer will suspect signed integer overflow which happened to wrap.&lt;/p&gt;&lt;p&gt;This apparent predictability of many types of UB hides the fact that UB is not predictable. This causes many programmers to either not realize that some of these behaviors are undefined or confuse UB with implementation-defined behavior. They may believe that UB is defined in the C standard and UBs may be non-portable, but they may assume that the behavior of their platform applies to all platforms, or other hosts of their machine's platform. This faulty assumption creates a variety of hard-to-diagnose issues that we will explore further.&lt;/p&gt;&lt;p&gt;An out-of-bounds write may have a wide range of consequences as it can disturb many kinds of state. However, most developers would assume that an out-of-bounds write is executed as a write operation, which is not true in general. If we consider another UB such as signed integer overflow, it is even less predictable that a simple arithmetic operation can have a wide range of unpredictable outcomes.&lt;/p&gt;&lt;p&gt;Undefined behavior in C gives an implementation wide latitude to optimize the code. This freedom has enabled implementers to successively generate faster and faster machine code, which enables significant reduction in computing time and energy consumption for a wide range of workloads. C is the de facto benchmark for efficiency that other languages are compared against and strive to match.&lt;/p&gt;&lt;p&gt;Significant portions of UB, such as Aliasing, Provenance and Overflow are specifically designed to enable implementations to make optimizations. Violating these categories of UB is likely to cause unpredictable behavior only when an implementation engages with these opportunities to optimize code.&lt;/p&gt;&lt;p&gt;As many implementations support varying levels of optimizations, a perception has formed in parts of the C community that compilers, at higher levels of optimizations, ignore the C standard and "break" code. This is a misconception. Most C implementations are consistent with the C standard even at the highest levels of optimization settings. Optimizations reveal existing bugs in the source code much more often than they reveal bugs in the compiler. These bugs are usually in violation of the C standard even when the program operates consistently with the developers' expectations.&lt;/p&gt;&lt;p&gt;The higher a level of optimization is employed, the more bugs are exposed, but as the code is further transformed, it also becomes harder to debug. Many tools like debuggers depend on low levels of optimizations to be able to correctly associate the binary's execution to the source code. This compounds the difficulty of diagnosing UB bugs.&lt;/p&gt;&lt;p&gt;Given the misconception that optimizations break code, rather than reveal latent bugs, implementers often unfairly get blamed for issues arising from UB. This has made many compilers avoid making certain optimizations, even when supported by the specification, if they anticipate a user backlash. This creates a gray area, where unsound code that contains UB may have an undocumented reliable or semi-reliable behavior. This gray area comes at the cost of denying performance afforded by the standard to compliant code.&lt;/p&gt;&lt;p&gt;C is regarded as an "unsafe language". This is, in the strictest sense, not true. The C standard does not require an implementation to check for several errors, but it also does not prevent an implementation from doing so. Hence, each implementation may choose the level of safety guaranteed.&lt;/p&gt;&lt;p&gt;In practice, C is an unsafe language because the most popular implementations of C choose not to make many additional guarantees, but instead choose to prioritize performance and power efficiency. As such, C is perceived as a de facto unsafe language because that is how most users have chosen to use it.&lt;/p&gt;&lt;p&gt;There are safer implementations, but these are predominantly used to detect issues during development rather than to add additional protections to deployment. One such implementation is [Valgrind](https://valgrind.org/), whose default tool "memcheck" detects out-of-bounds reads and writes to memory on the heap, as well as uninitialized reads, use-after-free errors, and memory leaks. Valgrind achieves these safety constraints at a significant performance cost. Many different implementations such as GCC, LLVM and MSVS offer various tools for detecting and diagnosing UB. Several static analyzers also exist to alleviate this problem.&lt;/p&gt;&lt;p&gt;Users can also write their own memory tracking shims to detect small out-of-bounds writes, double frees, memory consumption and memory leaks, using macros:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#define&lt;/syntax&gt;&lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;) &lt;syntax&gt;my_debug_mem_malloc&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;, &lt;syntax&gt;__FILE__&lt;/syntax&gt;, &lt;syntax&gt;__LINE__&lt;/syntax&gt;) &lt;syntax&gt;/* Replaces malloc. */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;free&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;) &lt;syntax&gt;my_debug_mem_free&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;, &lt;syntax&gt;__FILE__&lt;/syntax&gt;, &lt;syntax&gt;__LINE__&lt;/syntax&gt;) &lt;syntax&gt;/* Replaces free. */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;While not in any way mandated by the C specification, the prevailing modus operandi of C users consists of using safety-related tools to detect issues during development, rather than as backstops during deployment. A major drawback of this approach is that since UB is a state that often cannot be definitively detected until it occurs at run time, there is no easy way to definitively guarantee that a program will not enter a state of UB.&lt;/p&gt;&lt;p&gt;Despite this, it is worth noting that some of the most trusted software in the world, like the Linux kernel, Apache, MySQL, Curl, OpenSSL and Git are written in C. The simplicity of C makes it significantly easier to read and detect issues.&lt;/p&gt;&lt;p&gt;C does suffer when the standard is unclear, particularly in areas of the memory model and concurrent execution. Rules about aliasing, active type, thread safety, and volatile leaves a lot open to interpretation as to what is UB, and what is not. On many of these issues there is a lack of consensus within WG14. Most implementations do support behaviors that in the strictest reading of the standard would be considered UB simply because of user expectation, and to be able to compile important existing software. In this sense most implementation deviate from the standard, but how and how much they deviate varies. Some projects like the Linux Kernel, has explicitly opted out of these ambiguities and defined their own requirements.&lt;/p&gt;&lt;p&gt;As this document has hopefully illustrated, Undefined Behavior in the context of C is complex. To simply say that its behavior has been omitted from the standard does not convey this complexity.&lt;/p&gt;&lt;p&gt;C is designed to be a language that trusts the developer. In the case of UB, developers should interpret this to mean "Trust the developer not to initiate UB", rather than "The developer can trust UB if they know the underlying implementation and platform". The Undefined Behavior Study Group therefore strongly advises developers to avoid any UB, unless a platform has explicitly defined that behavior. Testing to determine what observable effect use of a nonportable or erroneous program construct has on your platform is insufficient cause for assuming the UB will consistently have the same behavior on all platforms, including the next one that your code will run on. Only trust an implementation's explicit documentation of a language extension that defines a behavior. We advise that implementations clearly document any language extensions that replace undefined behavior so that users can differentiate between such extensions and seemingly predictable but still unintended behavior.&lt;/p&gt;&lt;p&gt;A computer language is a tool for humans to communicate with computers, but it is also a tool for computers to communicate with humans. Humans spend more time reading the code they write and trying to figure out why its behavior does not match their expectations, than computers do. Traditionally implementations have been black boxes that users must rely on, without understanding how they operate. UB shows that this approach causes issues, because modern compilers do not operate like many users expect them to. We would therefore recommend that implementations try to find ways to be more transparent with their transformations. The ability for users to inspect code that has been transformed could reveal out-of-order issues, code removal, load/store omissions and other non-obvious transformations. We recognize that this involves significant user interface and architectural challenges.&lt;/p&gt;&lt;p&gt;This Document was written by Eskil Steenberg Hald. This document is the result of many invaluable discussions in the Undefined Behavior Study Group and ISO WG14, so many of its members deserves credit for its creation. Specifically the author wants to thank David Svoboda, Chris Bazley, and Martin Uecker for providing feedback, editing, and suggesting improvements.&lt;/p&gt;�&lt;p&gt;if, for, while, do, goto, break, continue and return, are all dependable.&lt;/p&gt;&lt;p&gt;However, there are limits to what you can do inside a if, for or while statement. C99 allows for the declaring of variables in the first statement:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;10&lt;/syntax&gt;: &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This is not legal in C89 and it there for not always dependable. The ability to declare variables in C89 does to extend to other flow control. All of these are illegal:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;10&lt;/syntax&gt;: &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;10&lt;/syntax&gt;)
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;while&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;10&lt;/syntax&gt;)
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;switch&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;10&lt;/syntax&gt;)
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;for loops are often explained as equivalent to while loops in like this:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;for&lt;/syntax&gt;(&amp;lt;&lt;syntax&gt;statement0&lt;/syntax&gt;&amp;gt;; &amp;lt;&lt;syntax&gt;statement1&lt;/syntax&gt;&amp;gt;; &amp;lt;&lt;syntax&gt;statement2&lt;/syntax&gt;&amp;gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    ...
&lt;lb/&gt;
}
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;Is&lt;/syntax&gt; &lt;syntax&gt;equivalent&lt;/syntax&gt; &lt;syntax&gt;to&lt;/syntax&gt;:
&lt;lb/&gt;

&lt;lb/&gt;
&amp;lt;&lt;syntax&gt;statement0&lt;/syntax&gt;&amp;gt;
&lt;lb/&gt;
&lt;syntax&gt;while&lt;/syntax&gt;(&amp;lt;&lt;syntax&gt;statement1&lt;/syntax&gt;&amp;gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    ...
&lt;lb/&gt;
    &amp;lt;&lt;syntax&gt;statement2&lt;/syntax&gt;&amp;gt;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This is true in C++ but not C, because statement0 can not define a type inside a for loop in C, but can be defined before a loop.&lt;/p&gt;�&lt;p&gt;auto is an obscure keyword that indicates that a variable is of "automatic storage duration". That is the default qualifier for variables inside functions scopes, and auto can not be used on variables outside functions scopes (although some compilers allow for it.)&lt;/p&gt;&lt;p&gt;Unfortunately auto has gone from pointless to dangerous in C23. In C23 auto was given a new meaning as a means to automatically assign the type of a variable using assignment:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;auto&lt;/syntax&gt;&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;0.0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In C23 the above code will make x a variable of type double since 0.0 is a double. This feature is not dependable. In fact if you write the above in older versions of C, you don not need to specify a type at all, and will then be given a variable of type int per default. The above in C89 would make x an int. The default type was deprecated with C99, but almost all compilers support it with a warning. This means that very recent compilers will compile this and an int and even more recent compilers (supporting C23) will no longer warn against this.&lt;/p&gt;&lt;p&gt;Therefore any use of the keyword auto should be considered not dependable.&lt;/p&gt;�&lt;p&gt;Any keyword starting with a _ (underscore) is reserved and should not be used.&lt;/p&gt;&lt;p&gt;The following keywords are used by later C versions and should therefore be avoided:&lt;/p&gt;&lt;p&gt;- true&lt;/p&gt;&lt;p&gt;- false&lt;/p&gt;&lt;p&gt;- null&lt;/p&gt;&lt;p&gt;- alignas&lt;/p&gt;&lt;p&gt;- alignof&lt;/p&gt;&lt;p&gt;- bool&lt;/p&gt;&lt;p&gt;- constexpr&lt;/p&gt;&lt;p&gt;- inline&lt;/p&gt;&lt;p&gt;- nullptr&lt;/p&gt;&lt;p&gt;- static_assert&lt;/p&gt;&lt;p&gt;- thread_local&lt;/p&gt;&lt;p&gt;- typeof&lt;/p&gt;&lt;p&gt;- type_unequal&lt;/p&gt;&lt;p&gt;Many implementations support extentions that reserve the following keywords:&lt;/p&gt;&lt;p&gt;- asm&lt;/p&gt;&lt;p&gt;- fortran&lt;/p&gt;&lt;p&gt;The following is a list of keywords used by C++. While they can be used in dependable C, if possible they are best avoided for clarity.&lt;/p&gt;&lt;p&gt;- and&lt;/p&gt;&lt;p&gt;- and_eq&lt;/p&gt;&lt;p&gt;- atomic_cancel&lt;/p&gt;&lt;p&gt;- atomic_commit&lt;/p&gt;&lt;p&gt;- atomic_noexcept&lt;/p&gt;&lt;p&gt;- bitand&lt;/p&gt;&lt;p&gt;- bitor&lt;/p&gt;&lt;p&gt;- catchclass&lt;/p&gt;&lt;p&gt;- compl&lt;/p&gt;&lt;p&gt;- concept&lt;/p&gt;&lt;p&gt;- consteval&lt;/p&gt;&lt;p&gt;- constexpr&lt;/p&gt;&lt;p&gt;- constinit&lt;/p&gt;&lt;p&gt;- const_cast&lt;/p&gt;&lt;p&gt;- contract_assert&lt;/p&gt;&lt;p&gt;- co_await&lt;/p&gt;&lt;p&gt;- co_return&lt;/p&gt;&lt;p&gt;- co_yield&lt;/p&gt;&lt;p&gt;- decltype&lt;/p&gt;&lt;p&gt;- delete&lt;/p&gt;&lt;p&gt;- dynamic_cast&lt;/p&gt;&lt;p&gt;- explicit&lt;/p&gt;&lt;p&gt;- export&lt;/p&gt;&lt;p&gt;- friend&lt;/p&gt;&lt;p&gt;- mutable&lt;/p&gt;&lt;p&gt;- namespace&lt;/p&gt;&lt;p&gt;- new&lt;/p&gt;&lt;p&gt;- noexcept&lt;/p&gt;&lt;p&gt;- not&lt;/p&gt;&lt;p&gt;- not_eq&lt;/p&gt;&lt;p&gt;- operator&lt;/p&gt;&lt;p&gt;- or&lt;/p&gt;&lt;p&gt;- or_eq&lt;/p&gt;&lt;p&gt;- private&lt;/p&gt;&lt;p&gt;- protected&lt;/p&gt;&lt;p&gt;- public&lt;/p&gt;&lt;p&gt;- reflexpr&lt;/p&gt;&lt;p&gt;- reinterpret_cast&lt;/p&gt;&lt;p&gt;- requires&lt;/p&gt;&lt;p&gt;- static_cast&lt;/p&gt;&lt;p&gt;- synchronized&lt;/p&gt;&lt;p&gt;- template&lt;/p&gt;&lt;p&gt;- this&lt;/p&gt;&lt;p&gt;- throw&lt;/p&gt;&lt;p&gt;- try&lt;/p&gt;&lt;p&gt;- typeid&lt;/p&gt;&lt;p&gt;- typename&lt;/p&gt;&lt;p&gt;- using&lt;/p&gt;&lt;p&gt;- virtual&lt;/p&gt;&lt;p&gt;- xor&lt;/p&gt;&lt;p&gt;identifyers with special meaning:&lt;/p&gt;&lt;p&gt;- final&lt;/p&gt;&lt;p&gt;- override&lt;/p&gt;&lt;p&gt;- transaction_safe&lt;/p&gt;&lt;p&gt;- transaction_safe_dynamic&lt;/p&gt;&lt;p&gt;- import&lt;/p&gt;&lt;p&gt;- module&lt;/p&gt;&lt;p&gt;- pre&lt;/p&gt;&lt;p&gt;- post&lt;/p&gt;&lt;p&gt;- trivially_relocatable_if_eligible&lt;/p&gt;&lt;p&gt;- replaceable_if_eligible&lt;/p&gt;�&lt;p&gt;Both float and double can be considered dependable and are well supported in most C implementations. There are however a few things to consider.&lt;/p&gt;&lt;p&gt;Some small embedded platforms do not have FPUs and may choose to software emulate or not support floating point operations at all, or may only support 32 floats. So in some cases it can be useful to avoid needlessly using floating point types. If you for instance implement a small library to implement a file format, network protocol or compression, you can avoid floating point instrumentation for benchmarking, if the library is otherwise free from floating point operations, to make the library more portable.&lt;/p&gt;&lt;p&gt;While pretty much all floating point implementations use IEEE 754 standard representation of floating point numbers, its worth pointing out that different hardware implementations (sometimes form the same vendor) will yield defend results due to how the various implementations handle rounding. This means that executing the exact same instructions, with the exact same input data can yield different results on two different machines, running the same executable. This means that floats are not reliable for lockstep synchronizations.&lt;/p&gt;&lt;p&gt;Floating point arithmetic should never be relied upon to get accurate result that can be compared with other values. Here are some examples where x and y may not be equal:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;x&lt;/syntax&gt; = (&lt;syntax&gt;y&lt;/syntax&gt; * &lt;syntax&gt;2.0&lt;/syntax&gt;) / &lt;syntax&gt;2.0&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;a&lt;/syntax&gt; / &lt;syntax&gt;2.0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;y&lt;/syntax&gt; = &lt;syntax&gt;a&lt;/syntax&gt; / &lt;syntax&gt;2.0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;The compiler may fold some operations at compile time using one implementation, while other operations are not folded and gets computed at execution time using a different implementation.&lt;/p&gt;&lt;p&gt;As a general rule, it is only safe == compare floating points values that are assigned, not values that have been computed, or to compare floating point values to themselves in order to detect a NaN state.&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;6.0&lt;/syntax&gt;;
&lt;lb/&gt;
...
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt; == &lt;syntax&gt;6.0&lt;/syntax&gt;) &lt;syntax&gt;/* safe to test */&lt;/syntax&gt;
&lt;lb/&gt;

&lt;lb/&gt;

&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;6.0&lt;/syntax&gt; / &lt;syntax&gt;2&lt;/syntax&gt;;
&lt;lb/&gt;
...
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt; == &lt;syntax&gt;3.0&lt;/syntax&gt;) &lt;syntax&gt;/* not safe to test */&lt;/syntax&gt;
&lt;lb/&gt;

&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;1.0&lt;/syntax&gt; / &lt;syntax&gt;y&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt; == &lt;syntax&gt;x&lt;/syntax&gt;) &lt;syntax&gt;/* a safe way to test if x is a NaN */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;/code&gt;�&lt;p&gt;Initialization in C, has a number of pitfalls and they usually stem from programmers (or language designers) trying to be clever. The general advice is to use "=" to assign values directly.&lt;/p&gt;&lt;p&gt;Lets start with a simple example:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Is a initialised in this code? No, not necessarily. "a" will be declared in the scope after the appearance of the statement, but for the value to be initialized it actually has to be executed, and there are ways to get around that, using goto or a switch:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;goto&lt;/syntax&gt;&lt;syntax&gt;lable&lt;/syntax&gt;;
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;a&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;lable&lt;/syntax&gt; :
&lt;lb/&gt;
    &lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"%i"&lt;/syntax&gt;, &lt;syntax&gt;a&lt;/syntax&gt;); &lt;syntax&gt;/* a is declared but not initialized */&lt;/syntax&gt;
&lt;lb/&gt;
}
&lt;lb/&gt;

&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;switch&lt;/syntax&gt;(&lt;syntax&gt;1&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;case&lt;/syntax&gt; &lt;syntax&gt;0&lt;/syntax&gt; :
&lt;lb/&gt;
     {
&lt;lb/&gt;
        &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;a&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
        &lt;syntax&gt;case&lt;/syntax&gt; &lt;syntax&gt;1&lt;/syntax&gt; :
&lt;lb/&gt;
        &lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"%i"&lt;/syntax&gt;, &lt;syntax&gt;a&lt;/syntax&gt;); &lt;syntax&gt;/* a is declared but not initialized */&lt;/syntax&gt;
&lt;lb/&gt;
    }
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Being able to declare anywhere as you can in C99 makes the problem a lot worse. The simple solution to this is to always only declare variables at the beginning of a scope (C89 style), and only in the function scope. By not ever declaring variables in other scopes you also avoid a range of other bugs where variables in different scopes having the same name.&lt;/p&gt;&lt;p&gt;Arrays can be initialized with braces, this is usually good, but there are some traps. One such trap is the definition of the array length, consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[] = {&lt;syntax&gt;1&lt;/syntax&gt;, &lt;syntax&gt;2&lt;/syntax&gt;, &lt;syntax&gt;3&lt;/syntax&gt;};
&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;b&lt;/syntax&gt;[&lt;syntax&gt;3&lt;/syntax&gt;] = {&lt;syntax&gt;1&lt;/syntax&gt;, &lt;syntax&gt;2&lt;/syntax&gt;, &lt;syntax&gt;3&lt;/syntax&gt;};
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;The size of 'a' is implicit from the initialization, there is no clear definition of the size of the array that can be referred to. You can use sizeof, to extract the size, but you then need to divide it by the size of int. In general I advice against using sizeof on any array, because they can decay to pointers, they can easily be replaced by pointers during refactoring, and if the type of the array changes, and the divider doesn't change that's another cause for a bug. The size of 'b' is explicit, and much cleared, if it is declared with a define then the define can be reused. It still presents the issue that there may be fewer initializations than there are members of the array. The safest way to initialize an array is therefor without braces if possible.&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#define&lt;/syntax&gt;&lt;syntax&gt;LENGTH_OF_ARRAY&lt;/syntax&gt;&lt;syntax&gt;3&lt;/syntax&gt;&lt;lb/&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;c&lt;/syntax&gt;[&lt;syntax&gt;LENGTH_OF_ARRAY&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;LENGTH_OF_ARRAY&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;
    &lt;syntax&gt;c&lt;/syntax&gt;[&lt;syntax&gt;i&lt;/syntax&gt;] = &lt;syntax&gt;i&lt;/syntax&gt; + &lt;syntax&gt;1&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Yes its more verbose but it is fail safe.&lt;/p&gt;&lt;p&gt;Another thing to be aware of with array initialization is that there is a special feature if you only have one initializer: it initializes all values. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;char&lt;/syntax&gt;&lt;syntax&gt;string&lt;/syntax&gt;[&lt;syntax&gt;1024&lt;/syntax&gt;] = {&lt;syntax&gt;'\0'&lt;/syntax&gt;};
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This code does not write a single byte to null terminate a string, it fills the entire string with null termination characters making it considerably slower than:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;char&lt;/syntax&gt;&lt;syntax&gt;string&lt;/syntax&gt;[&lt;syntax&gt;1024&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;string&lt;/syntax&gt;[&lt;syntax&gt;0&lt;/syntax&gt;] = &lt;syntax&gt;'\0'&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;As a general rule, I would try to avoid having arrays with complex operations of the stack. Stack overrun bugs are far more dangerous, than heap overruns, and are harder to debug.&lt;/p&gt;&lt;p&gt;NULL is a reserved address that may or may not reside on address 0x0. It is platform defined where NULL resides. NULL has two definitions in C (three in c23) and they are: (void *)0, and 0. When you type:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt; = (&lt;syntax&gt;void&lt;/syntax&gt; *)&lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;You are not setting zero to p, you are setting NULL, that means that the compiler has to be able to recognize that you are assigning a pointer, one of the two definitions of NULL, and then set the pointer to what ever the definition of NULL is on the platform. Therefore this is not portable C code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;memset&lt;/syntax&gt;(&amp;amp;&lt;syntax&gt;p&lt;/syntax&gt;, &lt;syntax&gt;0&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;p&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;You should not initialize NULL pointers with memset!&lt;/p&gt;&lt;p&gt;Because the compiler has to be able to differentiate between NULL and other values, using 0 as NULL is generally considered bad. Therefore you should always define NULL as (void *)0. This is why you should also never use NULL as a null-terminator for strings. Null terminators are in fact not NULL, they are a reserved character (that has to have all its bits set to 0). The null terminator you should use is '\0'. Therefore this is not advisable:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;char&lt;/syntax&gt;&lt;syntax&gt;string&lt;/syntax&gt;[] = {&lt;syntax&gt;'H'&lt;/syntax&gt;, &lt;syntax&gt;'i'&lt;/syntax&gt;, &lt;syntax&gt;'!'&lt;/syntax&gt;, &lt;syntax&gt;NULL&lt;/syntax&gt;};
&lt;lb/&gt;
&lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"%s"&lt;/syntax&gt;, &lt;syntax&gt;string&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;If NULL is defined as (void *)0, it may be translated to a reserved address that is not zero, and then translated back to a char integer, that is not the same as '\0'.&lt;/p&gt;&lt;p&gt;C23 adds nullptr, a third way to define NULL, confusing the situation further. Don't use it, only use (void*)0.&lt;/p&gt;&lt;p&gt;If we are going to be super pedantic (lets!), the representations of types in C are mostly platform defined. This means that an implementation can represent numbers any way it wants. A platform may decide that zero represented in an int, is all bits set to zeros except the sign bit set to 1. This is perhaps just trivia, but it shows that any time you assume the bit representation, you are strictly not writing portable code. An example where this does come in to play is for IEEE 754 floating point values where if you set only the sign bit, you get -0. -0 equals 0, but does not have the same bit representation. (Comparing two floats is not the same as comparing the bit representations of two floats, -0 and 0 are equal, but two identical NaNs are unequal)&lt;/p&gt;&lt;p&gt;Because zero initialization isn't NULL, it causes issues, when you initialize the memory of a struct with zeros. This:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;my_struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt; = {&lt;syntax&gt;0&lt;/syntax&gt;};
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Sets the memory to zero, not to NULL! In C23 there was an attempt to address this by adding the feature of NULL initialization:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;my_struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt; = {};
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In C23 this initializes all members to zero, and all pointers to NULL. This is a death-trap. If anyone compiles this with a compiler that does not support this feature you will get entirely uninitialized memory, without any warnings or error! Stay away from this feature, and if possible add tooling to detect accidental use of this.&lt;/p&gt;&lt;p&gt;In general I think that using braces to initialize structs are a bad practice, and should never be done. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;my_struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt; = {&lt;syntax&gt;1&lt;/syntax&gt;, &lt;syntax&gt;5&lt;/syntax&gt;, &lt;syntax&gt;NULL&lt;/syntax&gt;};
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This is incredibly unclear code. 3 parameters are being initialized but what do they do? What if someone adds a new parameter, or changes their order? This is incredibly fragile code that depends on the programmer always being tight about the content of a struct. C99 ads the ability to designate members:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;my_struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt; = {.&lt;syntax&gt;member&lt;/syntax&gt; = &lt;syntax&gt;1&lt;/syntax&gt;, .&lt;syntax&gt;other&lt;/syntax&gt; = &lt;syntax&gt;5&lt;/syntax&gt;, .&lt;syntax&gt;pointer&lt;/syntax&gt; = &lt;syntax&gt;NULL&lt;/syntax&gt;};
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This is much better, but raises the language requirement and results in long lines of code. A much simpler way to initialize them is to explicitly set the values:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;my_struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;s&lt;/syntax&gt;.&lt;syntax&gt;member&lt;/syntax&gt; = &lt;syntax&gt;1&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;s&lt;/syntax&gt;.&lt;syntax&gt;other&lt;/syntax&gt; = &lt;syntax&gt;5&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;s&lt;/syntax&gt;.&lt;syntax&gt;pointer&lt;/syntax&gt; = &lt;syntax&gt;NULL&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Yes this is much more verbose, but it has the advantage of being clear. The greatest advantage to this way comes with the process for writing it: Simply take the struct definition, paste it in to the code where you want to initialize the struct and then edit it to be an initialization. That way you can be sure you get all members, that you spell them correctly (this may be more of an advantage for some than others...), and you have the type right there so that you can make sure it gets initialized with the right type.&lt;/p&gt;&lt;p&gt;To reiterate:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;my_struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;memset&lt;/syntax&gt;(&amp;amp;&lt;syntax&gt;s&lt;/syntax&gt;, &lt;syntax&gt;0&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;s&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Is not a portable way to set pointer members of the struct to NULL!&lt;/p&gt;&lt;p&gt;(Foot note: I always typedef in the keyword struct, so you wont find it in any variable definitions in my code, I only used it here to clarify that we are initializing structs)&lt;/p&gt;&lt;p&gt;So initializing zeros to a pointer may not on some platforms be to set them to NULL, but these platforms are rare. Many programs would argue "It works on all the machines I care about", and while that in general is a very precarious way to program C that will get you in to all kinds of trouble not covered in this article, it is not the main reason not to initialize memory with zeros.&lt;/p&gt;&lt;p&gt;When you make a mistake you want that mistake to be as obvious as possible, and you want it to stick out like sore thumb. 0x0 is very common value both for pointers and other variables, and therefor they do not clearly stand out as uninitialized values. You want something that is as recognizable as possible. Many compilers (in debug mode) therefor initialize memory with a sentinel magic number. VisualStudio uses 0xCD or 0xCC, and other platforms use hex speed like 0xDEADBEEF. If your platform doesn't have this you can easily implement it yourself:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#ifdef&lt;/syntax&gt;&lt;syntax&gt;DEBUG_MODE&lt;/syntax&gt;&lt;lb/&gt;&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;debug_malloc&lt;/syntax&gt;(&lt;syntax&gt;size_t&lt;/syntax&gt; &lt;syntax&gt;size&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;p&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;size&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;memset&lt;/syntax&gt;(&lt;syntax&gt;p&lt;/syntax&gt;, &lt;syntax&gt;0xCD&lt;/syntax&gt;, &lt;syntax&gt;size&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;return&lt;/syntax&gt; &lt;syntax&gt;p&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt;) &lt;syntax&gt;debug_malloc&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt;)
&lt;lb/&gt;
&lt;syntax&gt;#endif&lt;/syntax&gt;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;If you read or write to a pointer set to 0xCDCDCDCDCDCDCDCD, you program will crash and it will be very obvious that the problem is an initialized value. If a pointe is initialized to 0x00000000 it is much less likely to crash, because its likely that some form of null check will stop if from crashing. Isnt that a good thing? No! You want your code to work because its correct, not because it accidentally worked! Because the error doesn't fail right away, that doesn't mean that there isn't an issue, it just means the issue is harder to find! Lets imagine we want to write a link list and we want to allocate a pool of links, that we allocate up front and then an API for retrieving links, and returning them. Then, we are going to add a bug to this code, and discuss how zero initialization makes this bug far harder to find.&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;typedef&lt;/syntax&gt;&lt;syntax&gt;struct&lt;/syntax&gt;{
&lt;lb/&gt;
    &lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;data&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;next&lt;/syntax&gt;;
&lt;lb/&gt;
}&lt;syntax&gt;Link&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;void&lt;/syntax&gt; &lt;syntax&gt;free_link&lt;/syntax&gt;(&lt;syntax&gt;Link&lt;/syntax&gt; *&lt;syntax&gt;l&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;l&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;data&lt;/syntax&gt; = &lt;syntax&gt;NULL&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;Link&lt;/syntax&gt; *&lt;syntax&gt;alloc_link&lt;/syntax&gt;(&lt;syntax&gt;Link&lt;/syntax&gt; *&lt;syntax&gt;link_array&lt;/syntax&gt;, &lt;syntax&gt;uint&lt;/syntax&gt; &lt;syntax&gt;link_array_length&lt;/syntax&gt;, &lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;data&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;unsigned&lt;/syntax&gt; &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;link_array_length&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;
    {
&lt;lb/&gt;
        &lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;link_array&lt;/syntax&gt;[&lt;syntax&gt;i&lt;/syntax&gt;].&lt;syntax&gt;data&lt;/syntax&gt; == &lt;syntax&gt;NULL&lt;/syntax&gt;)
&lt;lb/&gt;
        {
&lt;lb/&gt;
            &lt;syntax&gt;link_array&lt;/syntax&gt;[&lt;syntax&gt;i&lt;/syntax&gt;].&lt;syntax&gt;data&lt;/syntax&gt; = &lt;syntax&gt;data&lt;/syntax&gt;;
&lt;lb/&gt;
            &lt;syntax&gt;/*  link_array[i].next = NULL;  OPS  this line was accidentaly lost!*/&lt;/syntax&gt;
&lt;lb/&gt;
            &lt;syntax&gt;return&lt;/syntax&gt; &amp;amp;&lt;syntax&gt;link_array&lt;/syntax&gt;[&lt;syntax&gt;i&lt;/syntax&gt;];
&lt;lb/&gt;
        }
&lt;lb/&gt;
    }
&lt;lb/&gt;
    &lt;syntax&gt;return&lt;/syntax&gt; &lt;syntax&gt;NULL&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;void&lt;/syntax&gt; &lt;syntax&gt;do_something&lt;/syntax&gt;()
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;Link&lt;/syntax&gt; *&lt;syntax&gt;link_array&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;link_array&lt;/syntax&gt; = &lt;syntax&gt;calloc&lt;/syntax&gt;(&lt;syntax&gt;1024&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;link_array&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;link_array_length&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;
        &lt;syntax&gt;link_array&lt;/syntax&gt;[&lt;syntax&gt;i&lt;/syntax&gt;].&lt;syntax&gt;data&lt;/syntax&gt; = &lt;syntax&gt;NULL&lt;/syntax&gt;;
&lt;lb/&gt;
    .... &lt;syntax&gt;use&lt;/syntax&gt; &lt;syntax&gt;alloc_link&lt;/syntax&gt; &lt;syntax&gt;and&lt;/syntax&gt; &lt;syntax&gt;free_link&lt;/syntax&gt; &lt;syntax&gt;to&lt;/syntax&gt; &lt;syntax&gt;do&lt;/syntax&gt; &lt;syntax&gt;stuff&lt;/syntax&gt; &lt;syntax&gt;with&lt;/syntax&gt; &lt;syntax&gt;data&lt;/syntax&gt; ...
&lt;lb/&gt;

&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;If link_array is initialized to garbage, the first use of a next pointers will crash. However if they are initialized to NULL, they will be caught by null checks. Only when alloc_link is called and returns a previously used link will it return an non-null next member. That non-null next member will point to a valid link in the linked list! This makes this bug incredibly hard to find, because the user is going to assume that either it works or that the bug is in the code using the code above not in the code itself. Since the initialization only happens at the first use, only on second use may the bug show up. Its very easy to write test code for something like this where the code passes, because the test never uses the memory enough to reuse links. This is a good example how by mitigating a simple bugs, you make more complex bugs significantly harder to find.&lt;/p&gt;&lt;p&gt;Essentially I strongly discourage the use of calloc or memseting memory to zero at allocation for this reason.&lt;/p&gt;&lt;p&gt;calloc has one advantage over malloc and that is that it is able to detect overflows when you multiply the type with number of elements you want to allocate. But this is a very rare issue in comparasion, if this is an issue for you, write a wrapper around calloc that uses a calloc to allocate, and then uses memset to initialize the memort to something other than zero;&lt;/p&gt;&lt;p&gt;There are in rare cases, performance gains to be had by "pre priming" a struct using memset. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;typedef&lt;/syntax&gt;&lt;syntax&gt;struct&lt;/syntax&gt;{
&lt;lb/&gt;
    &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;a&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;short&lt;/syntax&gt; &lt;syntax&gt;b&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;char&lt;/syntax&gt; &lt;syntax&gt;c&lt;/syntax&gt;; 
&lt;lb/&gt;
}&lt;syntax&gt;MyStruct&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;void&lt;/syntax&gt; &lt;syntax&gt;my_function&lt;/syntax&gt;(&lt;syntax&gt;MyStruct&lt;/syntax&gt; *&lt;syntax&gt;s&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;memset&lt;/syntax&gt;(&lt;syntax&gt;s&lt;/syntax&gt;, &lt;syntax&gt;0xCD&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;s&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;s&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;a&lt;/syntax&gt; = &lt;syntax&gt;1&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;s&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;b&lt;/syntax&gt; = &lt;syntax&gt;2&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;s&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;c&lt;/syntax&gt; = &lt;syntax&gt;3&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Here, (on most common platforms) the structs members are 4, 2, and 1 one bytes respectively. The implementation will add a eight byte of padding. without the mem set, many compliers will generate three instructions to initialize the struct, writing each of the members individually. The compiler is careful not to change the content of the padding. With the added memset, the compiler now knows the content of the entire struct even the padding, and can therefore replace the 3 instructions with a single 64 bit write instruction that is much faster.&lt;/p&gt;&lt;p&gt;Its bad, worse then you think. There are some arguments about what you can do with un initialized values/memory according to the standard. Its not clear that every use of uninitialized values is UB, but I would also argue there are no clear uses for uninitialized values that are clearly not UB.&lt;/p&gt;&lt;p&gt;The standard uses the term "indeterminate state" to describe the value of uninitialized values. "indeterminate state" does not just mean the value can be any combination of zeros and ones, it can also be values that are not expressible using zeros and ones! It can be "trap representations", values that essentially when used causes to execution to trap. They can also be values that do things that normal values cant do, essentially UB.&lt;/p&gt;&lt;p&gt;One such real world instance is "wobbly values". Consider this code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;, &lt;syntax&gt;a&lt;/syntax&gt;, &lt;syntax&gt;b&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;p&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;a&lt;/syntax&gt; = *&lt;syntax&gt;p&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;b&lt;/syntax&gt; = *&lt;syntax&gt;p&lt;/syntax&gt;; 
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;a&lt;/syntax&gt; != &lt;syntax&gt;b&lt;/syntax&gt;)
&lt;lb/&gt;
    &lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"WTF!"&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;There are platforms (in common use) where "WTF!" could be printed. Lets dig in to why. When you call malloc on a modern computer, the OS has to do two things, it has to allocate an address range for the allocation, and it has to allocate enough memory pages needed to store the memory. Allocating all the address pages may be a slow process and the program may not immediately need all the memory. So modern operating systems may only allocate the address range, and only allocate some or none of the pages needed, and will then allocate more pages as the application starts using the memory. When the program executes the line "a = *p;" the OS needs to provide a memory page to read from. However, it doesn't have to assign this memory page to the program, because the application has not yet stored anything in the page. If we then assume that the OS task switches between the assignment of "a" and "b", another program may need a memory page. Since the program has yet to be assigned the memory page, the OS is free to give the page to the other application. Once the task switches back to the original program and executes the assignment of b, it again has to find an available page to memory read from. The program is then given an other uninitialized memory page and "b" therefore can be assigned a different value than "a".&lt;/p&gt;&lt;p&gt;A more common issue with reading un initialized values is that since they are UB the compiler may assume they will never happen. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;x&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;a&lt;/syntax&gt;)
&lt;lb/&gt;
    &lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;b&lt;/syntax&gt;)
&lt;lb/&gt;
    &lt;syntax&gt;func&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Here a compiler may reason that if "b" is true, "a" must also be true, otherwise "x" would be uninitialized and the use of "x" would be UB. It may therefor transform the code in to:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;x&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;a&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
     &lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;b&lt;/syntax&gt;)
&lt;lb/&gt;
          &lt;syntax&gt;func&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt;);
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This kind of UB has caused problems when some programmes have tried reading uninitialized memory in order to collect entropy to generate good secure random numbers. Compilers have then optimized away the reading of the un initialized values, with catastrophic consequences.&lt;/p&gt;&lt;p&gt;Finally, lets remember that just because you say you want to set a value doesn't mean the compiler has to. As we saw in the example where a memset followed by 3 struct member assignments was turned in to a single 64 bit instruction, compilers are able to optimize away things. The main issue with this is if you want to erase a value from memory. Consider this:&lt;/p&gt;&lt;code&gt;{
&lt;lb/&gt;
    &lt;syntax&gt;char&lt;/syntax&gt; &lt;syntax&gt;password&lt;/syntax&gt;[&lt;syntax&gt;64&lt;/syntax&gt;];
&lt;lb/&gt;
     ... &lt;syntax&gt;/* store a password in the array, and use it for secret stuff */&lt;/syntax&gt;
&lt;lb/&gt;
    &lt;syntax&gt;memset&lt;/syntax&gt;(&lt;syntax&gt;password&lt;/syntax&gt;, &lt;syntax&gt;0&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;pasword&lt;/syntax&gt;); &lt;syntax&gt;/* erase password form memory */&lt;/syntax&gt;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Here the compiler can remove the memset, becaus it can conclude that there is no point in setting a variable that isnt read after it is set. To get arround this issue there are various versions of memset suported by compilers, and C23 adds "memset_explicit". but you can also implement your own secure memset by using volatile.&lt;/p&gt;&lt;p&gt;By Eskil Steenberg Hald&lt;/p&gt;&lt;p&gt;eskil@quelsolaar.com&lt;/p&gt;�&lt;p&gt;"_Bool" was a type that was introduced in C99, and then later deprecated and replaced in C23 with "bool" defined in stdbool.h. The problem that _Bool tries to solve is that in C, 0 is considered false, while all other numbers are considered true. Theis means that 2 values can be true, while not being equal. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#define&lt;/syntax&gt;&lt;syntax&gt;TRUE&lt;/syntax&gt;&lt;syntax&gt;1&lt;/syntax&gt;&lt;lb/&gt;&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt; == &lt;syntax&gt;TRUE&lt;/syntax&gt;)
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;x may be true, while not being equal to one. _Bool can only have two values 0 and 1 and therefore solves this problem. However without _Bool there are several other simple solutions to this. The first one is to not compare x to anything:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt;)
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Or to compare it to FALSE.&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#define&lt;/syntax&gt;&lt;syntax&gt;FALSE&lt;/syntax&gt;&lt;syntax&gt;0&lt;/syntax&gt;&lt;lb/&gt;&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt; != &lt;syntax&gt;FALSE&lt;/syntax&gt;)
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Or use the ! operator twice:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;if&lt;/syntax&gt;(!!&lt;syntax&gt;x&lt;/syntax&gt; == &lt;syntax&gt;TRUE&lt;/syntax&gt;)
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;The ! operator turns any true value in to a 0, and any 0 in to a 1.&lt;/p&gt;&lt;p&gt;As long as you are aware of the pitfalls of comparing to TRUE, you can live without _Bool&lt;/p&gt;&lt;p&gt;In fact there are good reasons not to use _Bool. First of all it is deprecated and replaced by "bool", and then the keyword "bool" is likely to clash with other definitions of bool. A header file that defines a function that returns bool, requires stdbool.h to be included and that means that any code that defines their own bool, will have trouble accessing the function. We strongly recommend considering the word "bool" to be reserved as well as "true" and "false".&lt;/p&gt;&lt;p&gt;What _Bool does not do is act as a good storage container for Boolean values. There are in my opinion 3 viable ways to store a Boolean:&lt;/p&gt;&lt;p&gt;- As a single bit in larger integer type.&lt;/p&gt;&lt;p&gt;- As a byte&lt;/p&gt;&lt;p&gt;- As an int&lt;/p&gt;&lt;p&gt;This list goes from the most compact to least compact, but also goes form the one most difficult to access to the fastest way to access.&lt;/p&gt;&lt;p&gt;A general guideline would be to use int, for return values, or variables, bytes in structs that needs fast access or where padding will make bit packing irrelevant, and use individual bits in larger types for, disk and network packed data.&lt;/p&gt;�&lt;p&gt;- == Equal to&lt;/p&gt;&lt;p&gt;- != Not equal&lt;/p&gt;&lt;p&gt;- &amp;gt; Greater than&lt;/p&gt;&lt;p&gt;- &amp;lt; Less than&lt;/p&gt;&lt;p&gt;- &amp;gt;= Greater than or equal to&lt;/p&gt;&lt;p&gt;- &amp;lt;= Less than or equal to&lt;/p&gt;&lt;p&gt;All comparison operators are dependable. There are how ever some caveats:&lt;/p&gt;&lt;p&gt;All floating point Not-A-Numbers are unequal to themselves. You can therefore check if a floating point value is a NaN by comparing it to itself:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;f&lt;/syntax&gt; != &lt;syntax&gt;f&lt;/syntax&gt;)
&lt;lb/&gt;
    &lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"f is a NaN!\n"&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;C11 adds the function "isnan" to math.h. This is not dependable, but can easily be implemented as functions:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;dependablec_isnanf&lt;/syntax&gt;(&lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;x&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;return&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; != &lt;syntax&gt;x&lt;/syntax&gt;);
&lt;lb/&gt;
}
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;dependablec_isnand&lt;/syntax&gt;(&lt;syntax&gt;double&lt;/syntax&gt; &lt;syntax&gt;x&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;return&lt;/syntax&gt; (&lt;syntax&gt;x&lt;/syntax&gt; != &lt;syntax&gt;x&lt;/syntax&gt;);
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;It can also be implemented as a type agnostic macro:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#define&lt;/syntax&gt;&lt;syntax&gt;dependablec_isnan&lt;/syntax&gt;(&lt;syntax&gt;x&lt;/syntax&gt;) ((&lt;syntax&gt;x&lt;/syntax&gt;) != (&lt;syntax&gt;x&lt;/syntax&gt;))
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This has the disadvantage that anyt macro that uses the same parameter twice runs the risk of unintentionally casuing bugs were a parameter is evaluated or executed twize:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;dependablec_isnan&lt;/syntax&gt;(&lt;syntax&gt;my_function&lt;/syntax&gt;());
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;/* expands to */&lt;/syntax&gt;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = ((&lt;syntax&gt;my_function&lt;/syntax&gt;()) != (&lt;syntax&gt;my_function&lt;/syntax&gt;()));
&lt;lb/&gt;
&lt;/code&gt;&lt;p&gt;All pointers can be compared equal to each other. However it is undefined to compare less than or greater than comparasions of the two pointers do not have the soma provenance. In other words they point to different objects.&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;2&lt;/syntax&gt;] &lt;syntax&gt;b&lt;/syntax&gt;, *&lt;syntax&gt;pa0&lt;/syntax&gt;, *&lt;syntax&gt;pa1&lt;/syntax&gt;, *&lt;syntax&gt;pb&lt;/syntax&gt;, &lt;syntax&gt;x&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;pa0&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;0&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;pa1&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;a&lt;/syntax&gt;[&lt;syntax&gt;1&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;pb&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;b&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;pa0&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;pa1&lt;/syntax&gt;; &lt;syntax&gt;/* defined and dependable */&lt;/syntax&gt;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;pa0&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;pb&lt;/syntax&gt;; &lt;syntax&gt;/* undefined defined and not dependable */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;/code&gt;&lt;p&gt;Some platforms have NULL that resides on a different address than 0x0, and some platforms even have multiple NULL. All NuLL values are required to evalueate as equal, but their bit representation may not be equal.&lt;/p&gt;�&lt;p&gt;The two Shift operators &amp;gt;&amp;gt; and &amp;lt;&amp;lt; are partially dependable. However, it is UB if the left operand is negative or greater equal to the number of bits in the type.&lt;/p&gt;&lt;p&gt;Right shifting (&amp;gt;&amp;gt;) signed integers for negative values is implementation defined and therefor not dependable. The issue is, what happens to the sign bit as the bits are shifted. Ideally you want to shift everything but the sign bit. Most modern architectures have instructions to do this: x86_32, x86_64, ARM64, MIPS32, MIPS64, SPARC32, SPARC64, RISC-V32, RISCV64 but some architectures don't: ARM32, power and S390. (Special thanks to Aaron Peter Bachmann for providing me with a list of architecture behaviours)&lt;/p&gt;&lt;p&gt;using &amp;gt;&amp;gt; or &amp;lt;&amp;lt; to shift more than the number of bits available in the type, or a negative value is undefined behaviour. To remedy this always mask off the bits of the type when this can be guaranteed:&lt;/p&gt;&lt;p&gt;x &amp;lt;&amp;lt;= y &amp;amp; (sizof(y) * BITS_IN_BYTE - 1);&lt;/p&gt;�&lt;p&gt;C99 is the first major revising to standard C, and beyond C99 is the most supported. Despite being a quarter of a century, C99 remains not fully supported. Even major implementations have&lt;/p&gt;&lt;p&gt;C99 that adds the word _inline. This keyword has no meaning due to "As-If". If something is inline or not is implementation defined. _inline was also deprecated in c23.&lt;/p&gt;&lt;p&gt;This feature does not add any new capabilities to the language, it simply shifts where things are declared. In our opinion it is clearer to declare all variables up front. As a generally rule it is safer to only declare variables upfront and in the function scope to avoid accidental variable overloading, and issues with initialization (see initialization)&lt;/p&gt;&lt;p&gt;Variable arrays are very broken and has contributed to the slow adoption of C99. For a longer discussion of VLAs see the separate article under memory model. (VLAs where made optional in C11 and the again made somewhat but not entirely mandatory in C23)&lt;/p&gt;&lt;p&gt;Designated initializers are only syntactic sugar that do not enable any new functionality. It lets users do:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt; = {.&lt;syntax&gt;member&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;};
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;It is the same as writing:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;my_struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;my_struct&lt;/syntax&gt;.&lt;syntax&gt;member&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;&lt;p&gt;Compounds literals enable the creation of literals of structs and unions.&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;functon&lt;/syntax&gt;((&lt;syntax&gt;struct&lt;/syntax&gt; &lt;syntax&gt;my_struct&lt;/syntax&gt;)(.&lt;syntax&gt;member&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;, .&lt;syntax&gt;other_member&lt;/syntax&gt; = &lt;syntax&gt;1138&lt;/syntax&gt;));
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;It can be done in dependable C by just creating a variable:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;struct&lt;/syntax&gt;&lt;syntax&gt;s&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;s&lt;/syntax&gt;.&lt;syntax&gt;member&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;s&lt;/syntax&gt;.&lt;syntax&gt;other_member&lt;/syntax&gt; = &lt;syntax&gt;1138&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;functon&lt;/syntax&gt;((&lt;syntax&gt;struct&lt;/syntax&gt; &lt;syntax&gt;my_struct&lt;/syntax&gt;)(.&lt;syntax&gt;member&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;, .&lt;syntax&gt;other_member&lt;/syntax&gt; = &lt;syntax&gt;1138&lt;/syntax&gt;));
&lt;lb/&gt;
&lt;/code&gt;&lt;p&gt;Restrict is a very useful concept for conveying aliasing. It lets you declare that a variable of parameter will not alias with other pointer. The precise rules for this is unclear and there have been attempts to clarify the meaning of restrict in the past. In the future we plan to try to understand and document restrict in detail.&lt;/p&gt;&lt;p&gt;If you need to use restrict, you can do so using a macro, since removing the keyword wont alter the meaning of the code. (Restrict is a key word that tells the implementations that you promise NOT to do something, and an implementation can therefore ignore this keyword) we recommend using the following code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#if&lt;/syntax&gt;&lt;syntax&gt;defined&lt;/syntax&gt;(&lt;syntax&gt;__GNUC__&lt;/syntax&gt;) &amp;amp;&amp;amp; ((&lt;syntax&gt;__GNUC__&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;3&lt;/syntax&gt;) || (&lt;syntax&gt;__GNUC__&lt;/syntax&gt; == &lt;syntax&gt;3&lt;/syntax&gt; &amp;amp;&amp;amp; &lt;syntax&gt;__GNUC_MINOR__&lt;/syntax&gt; &amp;gt;= &lt;syntax&gt;1&lt;/syntax&gt;))
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;DC_RESTRICT&lt;/syntax&gt; &lt;syntax&gt;__restrict&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#elif&lt;/syntax&gt; &lt;syntax&gt;defined&lt;/syntax&gt;(&lt;syntax&gt;_MSC_VER&lt;/syntax&gt;) &amp;amp;&amp;amp; &lt;syntax&gt;_MSC_VER&lt;/syntax&gt; &amp;gt;= &lt;syntax&gt;1400&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;DC_RESTRICT&lt;/syntax&gt; &lt;syntax&gt;__restrict&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#elif&lt;/syntax&gt; &lt;syntax&gt;defined&lt;/syntax&gt;(&lt;syntax&gt;__STDC_VERSION__&lt;/syntax&gt;) &amp;amp;&amp;amp; &lt;syntax&gt;__STDC_VERSION__&lt;/syntax&gt; &amp;gt;= &lt;syntax&gt;199901&lt;/syntax&gt;&lt;syntax&gt;L&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;DC_RESTRICT&lt;/syntax&gt; &lt;syntax&gt;restrict&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#else&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;DC_RESTRICT&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#endif&lt;/syntax&gt;
&lt;lb/&gt;
&lt;/code&gt;&lt;p&gt;C99 support flexible array members. This lets the last member of a struct be an array that can be extended by simply allocating enough memory to store more members. A flexible array member is designated using a pair of empty brackedts []. Example:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;typedef&lt;/syntax&gt;&lt;syntax&gt;struct&lt;/syntax&gt;{
&lt;lb/&gt;
    &lt;syntax&gt;size_t&lt;/syntax&gt; &lt;syntax&gt;length&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;char&lt;/syntax&gt; &lt;syntax&gt;text_buffer&lt;/syntax&gt;[];
&lt;lb/&gt;
}&lt;syntax&gt;TextBuffer&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;TEXT&lt;/syntax&gt; &lt;syntax&gt;"Hello World"&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;TextBuffer&lt;/syntax&gt; *&lt;syntax&gt;t&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;t&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt;(&lt;syntax&gt;TextBuffer&lt;/syntax&gt;) + &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;TEXT&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;t&lt;/syntax&gt;.&lt;syntax&gt;length&lt;/syntax&gt; = &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;TEXT&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;memcpy&lt;/syntax&gt;(&lt;syntax&gt;t&lt;/syntax&gt;.&lt;syntax&gt;text_buffer&lt;/syntax&gt;, &lt;syntax&gt;TEXT&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;TEXT&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In C89 it was common to do this, by simply declaring an array with the length of one as the last member the struct. This is technicaly UB. Because it is common in older code bases major compilers still support it. It will however fail on many static analysers. Before C99 was standardized many compiler supported the extension to have zero length arrays as their last members "[0]" for this very use case. Most compilers also support this extension.&lt;/p&gt;&lt;p&gt;If you need flexible array members, the correct way that is legal in all standard versions is to simply place the flexible array after the struct allocation:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;typedef&lt;/syntax&gt;&lt;syntax&gt;struct&lt;/syntax&gt;{
&lt;lb/&gt;
    &lt;syntax&gt;size_t&lt;/syntax&gt; &lt;syntax&gt;length&lt;/syntax&gt;;
&lt;lb/&gt;
}&lt;syntax&gt;TextBuffer&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;TEXT&lt;/syntax&gt; &lt;syntax&gt;"Hello World"&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;TextBuffer&lt;/syntax&gt; *&lt;syntax&gt;t&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;char&lt;/syntax&gt; *&lt;syntax&gt;buffer&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;t&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt;(&lt;syntax&gt;TextBuffer&lt;/syntax&gt;) + &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;TEXT&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;t&lt;/syntax&gt;.&lt;syntax&gt;length&lt;/syntax&gt; = &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;TEXT&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;buffer&lt;/syntax&gt; = (&lt;syntax&gt;char&lt;/syntax&gt; *)&amp;amp;&lt;syntax&gt;t&lt;/syntax&gt;[&lt;syntax&gt;1&lt;/syntax&gt;]; &lt;syntax&gt;/* get the address after the TextBuffer struct */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;memcpy&lt;/syntax&gt;(&lt;syntax&gt;buffer&lt;/syntax&gt;, &lt;syntax&gt;TEXT&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;TEXT&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;However, this requires you to be careful with padding, to make sure that the tail type has an alignments smaller or equal to that of the header structure. In many cases like the above, that can be guaranteed by the standards type sizing requirements, but sometimes it is implementation defined.&lt;/p&gt;&lt;p&gt;No implementations of Annex K exists. It doesn't get any less dependable than that.&lt;/p&gt;&lt;p&gt;This functionality is optional, and is therefor not dependable.&lt;/p&gt;�&lt;p&gt;The C11 version of the standard mainly adds fixes. However the largest addition to C11 is the support for multithreading.&lt;/p&gt;&lt;p&gt;the standard library threads.h adds the ability to create and manage threads. Strictly speaking any multithreaded C program that does not use the C11 threads are UB. In practice C11 threads are far less dependable than Posix Threads. The support for posix threads is far more pervailent than C11 threads and they are therefore more dependable than C11 threads. The recommendation is to use Posix orother native threading APIs. Almost all threading APIs are very similar and it is therefor recommended to wrap any thread use to be able to support multiple threading solutions for various platforms.&lt;/p&gt;&lt;p&gt;See separate article about Atomics.&lt;/p&gt;&lt;p&gt;C11 Adds a number of functions to help with alignment in stdalign.h such as _Alignas, _Alignof and aligned_alloc. _Alignof gives you the alignment requirement of a type, however so does sizeof. Consider a hypothetical platform where int is 24 bits but have 32 bit alignment. sizeof(int) will still evaluate to 4 bytes, because sizeof has to take in to include account padding. Yes, the following code would work if sizeof evaluated to 3 bytes:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;x&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt;));
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;but would fail if you allocate an array:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;x&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt;) * &lt;syntax&gt;2&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this case for two integers to be able to be accessed&lt;/p&gt;&lt;p&gt;VLAs where introduced in C99, them made optional in C11 and then partially made mandatory again in C23. They are NOT dependable.&lt;/p&gt;&lt;p&gt;C is a language defined by the fact that memory management is done manually. You are in charge of making sure you have enough of it and that you don't use more than you have. This level of control means that you can control when allocations happen.&lt;/p&gt;&lt;p&gt;VLAs completely breaks this paradigm. It claims you can just randomly ask for memory and that will always be available and always be fast to allocate. Thats a pipe dream and that is fundamentally broken. If you want this kind of memory management(minus the speed), there are plenty of other languages to choose from. it should never have been added to C.&lt;/p&gt;&lt;p&gt;Apart from the impossibility of making VLAs dependably fast, here is the real kicker: How much memory can you access? Undefined. What happens when you run out memory? Undefined. If you cant grantee what int a[n]; does, then it is effectively UB. (VLAs sould beaded to to Annex J)&lt;/p&gt;&lt;p&gt;People complain about missed NULL checks in C, when its entirely possible to check if a pointer is NULL in C, but then defend VLAs, when there is literally nothing a programmer can do to write safe portable VLAs. There are hand wavy answers like "It works on my computer" or "computers have a lot of memory now a days", but No, C runs on many tiny platforms and then again No, Linux as a default stack side of 8Megs, and Windows has 1Meg. That runs out fast. VLAs are not "trust the compiler", or "trust the programmer", its trust no one.&lt;/p&gt;&lt;p&gt;If you need dunamicly allocated memory there anr many ways to do this in C using malloc, calloc and realloc.&lt;/p&gt;&lt;p&gt;If you need scratch memory there are a few different strategies that I would suggest. The first one is to create your own pre-allocated stack:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;array&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;my_pre_allocated_stack&lt;/syntax&gt;[&lt;syntax&gt;my_usage_of_said_stack&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;my_usage_of_said_stack&lt;/syntax&gt; += &lt;syntax&gt;n&lt;/syntax&gt; * &lt;syntax&gt;sizeof&lt;/syntax&gt;(*&lt;syntax&gt;array&lt;/syntax&gt;);
&lt;lb/&gt;

&lt;lb/&gt;
....
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;my_usage_of_said_stack&lt;/syntax&gt; -= &lt;syntax&gt;n&lt;/syntax&gt; * &lt;syntax&gt;sizeof&lt;/syntax&gt;(*&lt;syntax&gt;array&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;You can pre-allocate as much memory as you need and you can add what ever checks you need to not exceed it. Guaranteed to be fast. Another way to do this is to not incrementally give the buffer back, but to reset the stack usage to zero at a specific points in the code. This has some debugging advantages because you can backtrack a lot of state. There are many variations, but the point is: you are in control. (In the language Jai this a language feature for some reason).&lt;/p&gt;&lt;p&gt;Another approach that I sometimes use is:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;array&lt;/syntax&gt;, &lt;syntax&gt;buffer&lt;/syntax&gt;[&lt;syntax&gt;1024&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt; &amp;gt; &lt;syntax&gt;1024&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;array&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;((&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;array&lt;/syntax&gt;) * &lt;syntax&gt;n&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;array&lt;/syntax&gt; == &lt;syntax&gt;NULL&lt;/syntax&gt;)
&lt;lb/&gt;
        &lt;syntax&gt;my_abort&lt;/syntax&gt;();
&lt;lb/&gt;
}&lt;syntax&gt;else&lt;/syntax&gt;
&lt;lb/&gt;
    &lt;syntax&gt;array&lt;/syntax&gt; = &lt;syntax&gt;buffer&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
....
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;if&lt;/syntax&gt;(&lt;syntax&gt;array&lt;/syntax&gt; != &lt;syntax&gt;buffer&lt;/syntax&gt;)
&lt;lb/&gt;
    &lt;syntax&gt;free&lt;/syntax&gt;(&lt;syntax&gt;array&lt;/syntax&gt;):
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This needs less infrastructure, but is dependable when you know n is very likely to be small but may in some rare cases be larger. Incidentally this is what some compilers do to implement VLAs, minus the null check.&lt;/p&gt;�&lt;p&gt;By Eskil Steenberg Hald (eskil at quelsolaar dot com)&lt;/p&gt;&lt;p&gt;The C programming language has since C99 a concept known as Effective type. The Effective type rules are designed to improve a compilers ability to do aliasing analysis. These rules and their implications are understood by almost no one. By almost no one i mean probably less than ten people in the world. I have programmed C for 25 years, I have never even heard about it until recently. I represent Sweden in the ISO wg14Â standard group, I'm in the C memory model study group, and only very recently did i grasp the concept. Several people in the wg14 has asked for a document to try to help them understand the concept of Effective type so i will now do my best to try to explain, how i think it works.&lt;/p&gt;&lt;p&gt;In this document I will try to explain what the standard says, not what implementations actually do. As far as i know, no compilers will break these rules, so if you write within these rules you should be fine (baring compiler bugs and there are a fair bit of them in this area given how few people understand this).&lt;/p&gt;&lt;p&gt;This is my best interpretation of the C standard. I have spent considerable time and effort in collaboration to try to understand these rules and their implications. I owe huge gratitude for the time and efforts of my peers helping me decipher this, especially Jens Gustedt and Martin Uecker. Still, this is still only my interpretation, and it is not a document officially endorsed by the wg14 or the memory model study group.&lt;/p&gt;&lt;p&gt;Just one more note before we get started. This is a document trying to explain how the effective type system in C works, it is not an endorsement of its design.&lt;/p&gt;&lt;p&gt;Before we talk specifically about the Effective type system we need to talk about what problem it is meant to solve.&lt;/p&gt;&lt;p&gt;Consider the following code:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;typedef&lt;/syntax&gt;&lt;syntax&gt;struct&lt;/syntax&gt;{
&lt;lb/&gt;
    &lt;syntax&gt;unsigned&lt;/syntax&gt; &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;length&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;array&lt;/syntax&gt;;
&lt;lb/&gt;
}&lt;syntax&gt;MyStruct&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;void&lt;/syntax&gt; &lt;syntax&gt;function&lt;/syntax&gt;(&lt;syntax&gt;MyStruct&lt;/syntax&gt; *&lt;syntax&gt;s&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;unsigned&lt;/syntax&gt; &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;s&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;length&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;
    &lt;syntax&gt;s&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;array&lt;/syntax&gt;[&lt;syntax&gt;i&lt;/syntax&gt;] = &lt;syntax&gt;0.0&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;How may a compiler go about optimizing this code? There are many different opportunities here, it could compute an end pointer and step forward towards it, it may make a call to an intrinsic memset, use vector instruction and all kinds of hardware specific tricks, and simply putting the length value in a register. All these approaches depends one one thing: that writing to array does not overwrite the length member in struct. The array pointer points to the length member, then this code means something very different from if it does not. This is known as aliasing. When something is being accessed by a pointer, and the same time being accessed by directly or by another pointer, then the two alias. Consider this very simple example:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;function&lt;/syntax&gt;(&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;a&lt;/syntax&gt;, &lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;b&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    *&lt;syntax&gt;a&lt;/syntax&gt; = &lt;syntax&gt;2.0&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
    *&lt;syntax&gt;b&lt;/syntax&gt; = &lt;syntax&gt;3&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;If a and b are guaranteed to not alias, then the order of the two operations do not matter and they can even happen in parallel, If they do alias, the order of operation must be guaranteed.&lt;/p&gt;&lt;p&gt;Determining what aliases is therefore of great importance. Around the creation of C99 this had become an apparent problem, and one of the solutions was to add a set of rules, where the compiler was allowed to assume things about how memory was used, and any use of memory that breaks these rules us undefined behaviour. Enter the "effective type" rules.&lt;/p&gt;&lt;p&gt;One way of determining if two values alias is to look at their types. This is know as type based aliasing. C employs type aliasing.&lt;/p&gt;&lt;p&gt;If we again consider the first example, one might think that since the "length" variable is of type unsigned int, and the "array" pointer points to a value of type float, it can be assumed that "array" doesn't point to length. This assumption is wrong. C uses a system that depends on neither on the type of the pointer or the type of the value its points to, its depends on something entirely different: the Effective type.&lt;/p&gt;&lt;p&gt;Most of the times, object are only accessed using one type, and in these cases everything works as expected, but as soon as want to access memory using more than one type, these rules kick in. We may for instance allocate memory that we want to re-use, we may cast pointers, we may want to do type pruning, we may want to run encryption operation on arbitrary memory, or we may want to move memory using larger types, than individual bytes.&lt;/p&gt;&lt;p&gt;Lets start by looking at the rules themselves from the C standard:&lt;/p&gt;&lt;p&gt;The effective type of an object for an access to its stored value is the declared type of the object, if any.(Allocated objects have no declared type) If a value is stored into an object having no declared type through an lvalue having a type that is not a character type, then the type of the lvalue becomes the effective type of the object for that access and for subsequent accesses that do not modify the stored value. If a value is copied into an object having no declared type using memcpy or memmove, or is copied as an array of character type, then the effective type of the modified object for that access and for subsequent accesses that do not modify the value is the effective type of the object from which the value is copied, if it has one. For all other accesses to an object having no declared type, the effective type of the object is simply the type of the lvalue used for the access.&lt;/p&gt;&lt;p&gt;7 An object shall have its stored value accessed only by an lvalue expression that has one of the following types:(The intent of this list is to specify those circumstances in which an object may or may not be aliased.)&lt;/p&gt;&lt;p&gt;- a type compatible with the effective type of the object,&lt;/p&gt;&lt;p&gt;- a qualified version of a type compatible with the effective type of the object,&lt;/p&gt;&lt;p&gt;- a type that is the signed or unsigned type corresponding to the effective type of the object,&lt;/p&gt;&lt;p&gt;- a type that is the signed or unsigned type corresponding to a qualified version of the effective type of the object,&lt;/p&gt;&lt;p&gt;- an aggregate or union type that includes one of the aforementioned types among its members (including, recursively, a member of a subaggregate or contained union), or&lt;/p&gt;&lt;p&gt;- a character type.&lt;/p&gt;&lt;p&gt;(Note: the term "Access" is defined as reading or modifying a value according to The C standard. This is a bit confusing since in one part of this text it says that you can sometimes change the effective type by over writhing a differed type, and later is says you can only "access" (switching to) using a compatible type.)&lt;/p&gt;&lt;p&gt;What this boils down to is that if something has an effective type, you can only access it using a type compatible with that type. In most cases the effective type of an object is the same as the type. However sometimes this is not true, and we may want to access memory using many different types.&lt;/p&gt;&lt;p&gt;One way to think of it, is to imagine a hardware architecture, where next to every byte of memory there is a storage facility that stores the data type stored in that byte. This facility, is entirely separate from what type a pointer to the memory may have.Â Every time you write to a byte, the type storage associated with that byte is updated with the type you wrote with (with some exceptions), Every time you read from memory, you have to read using the same type as the type stored for that memory, if you don't this imaginary architecture would fail. memcpy, memmove and byte copy, are implemented as intrinsic and copy not just the memory, but also the type associated with the memory. The stack automatically initialized types associated with all variables and the type data is write protected.&lt;/p&gt;&lt;p&gt;(Note: For brevity this paper assumes that the types float and int have the same size, and that malloc/calloc doesn't return NULL.)&lt;/p&gt;&lt;p&gt;If you declare an int, it has the effective type of int and you have to use it as an int. So the following is undefined behaviour:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;i has an effective type of "int" because it was declared as an int and therefor it is UB to access it as a by dereferencing as a float pointer. So far things are pretty straight forward. But what about allocated memory? Allocated memory is not declared, its returned by functions like malloc, calloc and realloc. Consider this:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;calloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this case the memory returned from calloc doesn't have an effective type, even if its stored in to a pointer of type int. When memory doesn't have an effective type, reading using a type, gives the memory that effective type, so its entirely valid to also read it as a float. In fact we can read it as an integer too:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;calloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;y&lt;/syntax&gt; = *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;What we cant do is read it as both:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;calloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;y&lt;/syntax&gt; = *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Here by first dereferencing it, as a int, we assign to the memory the effective type of int, and therefore dereferencing it as an float afterwards become UB.&lt;/p&gt;&lt;p&gt;Every time you write to an object with non declared type, the effective type changes to the type you use to write to it. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
*&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This code is UB. When malloc allocates the memmory it has no effective type, but as soon as we write to it using an int pointer, it gets assigned the effective type of int, and then any access to that memory has to be done using a type compatible with int. Given that float is not compatible with int, the dereference of fp, becomes UB. Any write to allocated memory will automatically change the effective type, to the type being written (with an exception we will discuss later). So the following is not UB:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
*&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
*&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;0.0&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this case the memory returned by malloc, has no effective type, but is then given the effective type of int as we write the integer 0 to it, then its assigned the effective type float as we write the number 0.0 to the same memory, and then finally when we dereference a float pointer to the memroy, that is legal since the memory has its effective type to float.&lt;/p&gt;&lt;p&gt;This tells us that allocated memory works fundamentally different from declared memory:&lt;/p&gt;&lt;p&gt;- Declared memory has the same effective type as its declared type and can not change.&lt;/p&gt;&lt;p&gt;- Allocated memory can be given an effective type by writing to it or reading from it before its given an effective type, and the effective type can change if one writes to it again using a different type.&lt;/p&gt;&lt;p&gt;The standard clearly says that the effective type of allocated memory changes when is written to. For declared memory it doesn't, and it has to be a compatible type. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;float&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
*&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;; &lt;syntax&gt;// UB because we are accessing an incompatible type.
&lt;/syntax&gt;&lt;lb/&gt;
&lt;/code&gt;&lt;p&gt;A curious side effect of the effective type rules are that bugs that break the rules are often entirely invisible in the code where the bug happens. Consider the following:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;this_function&lt;/syntax&gt;()
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;other_function&lt;/syntax&gt;(&lt;syntax&gt;ip&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"%i"&lt;/syntax&gt;, *&lt;syntax&gt;ip&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;free&lt;/syntax&gt;(&lt;syntax&gt;ip&lt;/syntax&gt;);
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This code can violate the effective type rules, and be UB depending on what other_function does with the allocated memory, even if the other_function is entirely free from UB. If the other_function writes to the memory using a type that in incompatible with int (something it is free to do) like this:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;other_function&lt;/syntax&gt;(&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    *(&lt;syntax&gt;float&lt;/syntax&gt; *)&lt;syntax&gt;p&lt;/syntax&gt; = &lt;syntax&gt;3.14&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;...then the dereference of ip, is UB. In isolation, neither this_function, or other_function contains enough information to make the code UB. This problem does not only exist for the user, it also exists for the compiler. Consider this:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;function&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;, &lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;ip&lt;/syntax&gt;[&lt;syntax&gt;0&lt;/syntax&gt;] = &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;fp&lt;/syntax&gt;[&lt;syntax&gt;0&lt;/syntax&gt;] = &lt;syntax&gt;1.0&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;ip&lt;/syntax&gt;[&lt;syntax&gt;1&lt;/syntax&gt;] = &lt;syntax&gt;2&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;fp&lt;/syntax&gt;[&lt;syntax&gt;1&lt;/syntax&gt;] = &lt;syntax&gt;3.0&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
}Â 
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This function has two parameters, one float pointer and one int pointer. The types of the pointer says nothing about the effective type of the memory they point to. The effective type system allows for these to alias. Since the function never de references either of the pointers, the compiler can not use the effective type system to discern if the pointer aliases or not. It is legal to over write the same memory with different types as long as you read using the a type compatible with your last write. This mean that a compiler can not use the Effective type rules to say, optimize these four 32bit writes in to two 64store instructions.&lt;/p&gt;&lt;p&gt;A curous observation is that sometimes a compiler could assume that a particular memory must be allocated just by how it is accessed. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;function&lt;/syntax&gt;(&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;x&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
    *&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;return&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Here, because the function uses the memory pointed to by fp to store and access two incompatible types, the memory must be allocated. otherwise this code is UB.&lt;/p&gt;&lt;p&gt;This means that technically, a function that takes a pointer to memory as one of its parameters may need to document in its usage requirements that the memory be allocated and not declared.&lt;/p&gt;&lt;p&gt;Lets return to the original example:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;typedef&lt;/syntax&gt;&lt;syntax&gt;struct&lt;/syntax&gt;{
&lt;lb/&gt;
    &lt;syntax&gt;unsigned&lt;/syntax&gt; &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;length&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;array&lt;/syntax&gt;;
&lt;lb/&gt;
}&lt;syntax&gt;MyStruct&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;void&lt;/syntax&gt; &lt;syntax&gt;function&lt;/syntax&gt;(&lt;syntax&gt;MyStruct&lt;/syntax&gt; *&lt;syntax&gt;s&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;unsigned&lt;/syntax&gt; &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;s&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;length&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;
    &lt;syntax&gt;s&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;array&lt;/syntax&gt;[&lt;syntax&gt;i&lt;/syntax&gt;] = &lt;syntax&gt;0.0&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;The naÃ¯ve view is that a compiler can assume that "array" cant point to "length" because they are of different type, but this as we have learned not true. In this case the compiler can assume that array doesn't point to length, because doing so would cause the memory be assigned the effective type of float using the member "array", and then afterwards be read as an unsigned int by the "length" member, and this would be UB. The difference is subtile, but in this case the outcome is the same.&lt;/p&gt;&lt;p&gt;If we assume that all reads can only be done with the type something was written, then we quickly run in to a number of issues. Often in C you want to access and move memory in the form of arrays of bytes. The basic effective type rules would make this impossible.Â One such example is that it becomes impossible to implement or use memcpy. Therefor a number of exceptions have been carved out.&lt;/p&gt;&lt;p&gt;The simple ones are integer sign and and qualifiers. sign and qualifiers are simply ignored when deciding if two types are compatible. An Atomic, signed int is compatible with volatile, unsigned int.&lt;/p&gt;&lt;p&gt;memcpy and memmove have special properties, that lets them write to both declared and allocated memory. However when they do write to allocated memory, they also copy the effective type from the source, to the destination.&lt;/p&gt;&lt;p&gt;Consider the following:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;);
&lt;lb/&gt;
*&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;3.14&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;memcpy&lt;/syntax&gt;(&lt;syntax&gt;ip&lt;/syntax&gt;, &amp;amp;&lt;syntax&gt;i&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt;));
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Here the allocated memory first is given the effective type of float, by assigning a float value to it. Then we over write the memory again using a memcpy. Finally we dereference the memory as an integer. For this to be legal the memory needs to have the effective type of int. Therefore memcpy(and memmove) does not just copy the memory, they also copy the effective type.&lt;/p&gt;&lt;p&gt;Now Consider this:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;memcpy&lt;/syntax&gt;(&amp;amp;&lt;syntax&gt;f&lt;/syntax&gt;, &amp;amp;&lt;syntax&gt;i&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt;));
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this example f has a declared type, and therefore its effective type is always float. Over writing it with memcpy, is legal, but does not change its effective type and therefore reading f as a float is legal. Now consider this this:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;mallof&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt;(&lt;syntax&gt;float&lt;/syntax&gt;));
&lt;lb/&gt;
&lt;syntax&gt;memcpy&lt;/syntax&gt;(&lt;syntax&gt;fp&lt;/syntax&gt;, &amp;amp;&lt;syntax&gt;i&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt;));
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;free&lt;/syntax&gt;(&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This superficially looks like the same, as the previous example, only we are now using allocated memory. But this code is UB, because the memory allocated will be assigned the effective type of int by memcopy and de-referencing it as a float is then UB.&lt;/p&gt;&lt;p&gt;Any object disregarding of its effective type can be read and written as a character type. This means that this is legal:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;char&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;p&lt;/syntax&gt; = (&lt;syntax&gt;char&lt;/syntax&gt; *)&amp;amp;&lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;p&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this case "i" has effective type int, and accessing it as a character type (char) is legal.&lt;/p&gt;&lt;p&gt;The special case for memcpy and memove also applies to copying characters. consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;length&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;
    ((&lt;syntax&gt;char&lt;/syntax&gt; *)&lt;syntax&gt;p&lt;/syntax&gt;)[&lt;syntax&gt;i&lt;/syntax&gt;] = ((&lt;syntax&gt;char&lt;/syntax&gt; *)&lt;syntax&gt;x&lt;/syntax&gt;)[&lt;syntax&gt;i&lt;/syntax&gt;];
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;If we assume that p is pointing to allocated memory, this operation will assign the values and effective type of the memory pointed to by x.&lt;/p&gt;&lt;p&gt;Now consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;for&lt;/syntax&gt;(&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;0&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt; &amp;lt; &lt;syntax&gt;length&lt;/syntax&gt;; &lt;syntax&gt;i&lt;/syntax&gt;++)
&lt;lb/&gt;
    ((&lt;syntax&gt;char&lt;/syntax&gt; *)&lt;syntax&gt;p&lt;/syntax&gt;)[&lt;syntax&gt;i&lt;/syntax&gt;] = ((&lt;syntax&gt;char&lt;/syntax&gt; *)&lt;syntax&gt;x&lt;/syntax&gt;)[&lt;syntax&gt;i&lt;/syntax&gt;] + &lt;syntax&gt;0&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Now we are no longer just copying the bytes. This means that the special case no longer applies and the memory pointed to by p will have the effective type of char, not the effective type of what ever x points to.&lt;/p&gt;&lt;p&gt;One curiosity about the exception of character types, is that it is for character types, not for bytes. This means that's a uint8_t is not covered, but wchar_t is.&lt;/p&gt;&lt;p&gt;Any access of memory using a union, where the union includes the effective type of the memory is legal. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;union&lt;/syntax&gt;{
&lt;lb/&gt;
    &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt;;Â 
&lt;lb/&gt;
}*&lt;syntax&gt;u&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt; = &lt;syntax&gt;3.14&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;u&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;u&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In this case the memory pointed to by "u" has the declared effective type of int, and given that "u" is a union that contains int, the access using the "i" member is legal. Its noteworthy in this that the "f" member of the union is never used, but only there to satisfy the requirement of having a member with a type compatible with the effective type.&lt;/p&gt;&lt;p&gt;This means that when accessing a memory with unknown effective type this can always be done with a "union condom" that contains all types:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;function&lt;/syntax&gt;(&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;union&lt;/syntax&gt;{ &lt;syntax&gt;// C98 types only
&lt;/syntax&gt;&lt;lb/&gt;
        &lt;syntax&gt;char&lt;/syntax&gt; &lt;syntax&gt;c&lt;/syntax&gt;;
&lt;lb/&gt;
        &lt;syntax&gt;short&lt;/syntax&gt; &lt;syntax&gt;s&lt;/syntax&gt;;
&lt;lb/&gt;
        &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
        &lt;syntax&gt;long&lt;/syntax&gt; &lt;syntax&gt;l&lt;/syntax&gt;;
&lt;lb/&gt;
        &lt;syntax&gt;long&lt;/syntax&gt; &lt;syntax&gt;long&lt;/syntax&gt; &lt;syntax&gt;ll&lt;/syntax&gt;;
&lt;lb/&gt;
        &lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
        &lt;syntax&gt;double&lt;/syntax&gt; &lt;syntax&gt;d&lt;/syntax&gt;;
&lt;lb/&gt;
Â  }*&lt;syntax&gt;uber_union&lt;/syntax&gt;;
&lt;lb/&gt;
Â  &lt;syntax&gt;u&lt;/syntax&gt; = &lt;syntax&gt;p&lt;/syntax&gt;;
&lt;lb/&gt;
Â  &lt;syntax&gt;return&lt;/syntax&gt; &lt;syntax&gt;uber_union&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;&lt;p&gt;While memcpy, memove and character types have special properties to accommodate the effective type system, many other functions do not.&lt;/p&gt;&lt;p&gt;The range of functions that would have issues in the standard library includes functions like, calloc, memset, and fwrite. Consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;float&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt; = &lt;syntax&gt;3.14&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;fwrite&lt;/syntax&gt;(&amp;amp;&lt;syntax&gt;f&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt;, &lt;syntax&gt;1&lt;/syntax&gt;, &lt;syntax&gt;stream&lt;/syntax&gt; );
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This should be legal as long as fwrite accesses f using a character type.Â In the same way:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;float&lt;/syntax&gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;fread&lt;/syntax&gt;(&amp;amp;&lt;syntax&gt;f&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt;, &lt;syntax&gt;1&lt;/syntax&gt;, &lt;syntax&gt;stream&lt;/syntax&gt; );
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;is legal. writing to a declared type, does not change the effective type, so what type is used by fread to write to f does not matter. On the other hand consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;fread&lt;/syntax&gt;(&lt;syntax&gt;fp&lt;/syntax&gt;, &lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;, &lt;syntax&gt;1&lt;/syntax&gt;, &lt;syntax&gt;stream&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This is almost certainly UB. It is unknown what effective type fread assigns the memory, but since the standard says it writes a number of characters, one may assume its of type char. fread has no way of knowing the type of the pointer it is writing to, so there is no way for it to know it in this case needs to give the memory the effective type of float.Â&lt;/p&gt;&lt;p&gt;Given that the effective type of freads output is unknown the only safe way to read it is using a character type or an uber union. The same would be true of memset.&lt;/p&gt;&lt;p&gt;One question that has remained unanswered is how effective type deals with structs and unions. We have discussed that unions can be used to access memory with other types than its effective types, but when we use a union or struct to write to a non declared memory, what effective type does the memory get? Does the memory get the Effective type of the member or the struct/union?&lt;/p&gt;&lt;p&gt;The standard says nothing about this, but it obviously pretty important to know. There simply isn't an answer to this you can find in the spec. But we can make some educated inferences and come to some logical conclusions. Again, I want to make it clear that this is my reading of the standard, and other people may have different readings.&lt;/p&gt;&lt;p&gt;Lets start with struct members:&lt;/p&gt;&lt;p&gt;A member of a structure, could conceivably, have the effective type of the member, the struct or both at the same time.&lt;/p&gt;&lt;p&gt;consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;struct&lt;/syntax&gt;{
&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
}&lt;syntax&gt;s&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;s&lt;/syntax&gt;.&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;5&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;s&lt;/syntax&gt;.&lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;I do not think it is the intention that this should be UB. You can access members of a struct using pointers. If this wasn't possible a vast majority of C code would not function. We can clearly infer that it is the intention that this should be possible in C. That means that it has to either have the effective type of int or, int and the struct. Given that the spec never says that memory can have more then one effective type, makes me think just int is more likely. So the answer should be: Structs have the effective type of its members.&lt;/p&gt;&lt;p&gt;So one would assume unions are the same? Lets have a look. consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;union&lt;/syntax&gt;{
&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
}*&lt;syntax&gt;u&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;u&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;5&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = &lt;syntax&gt;u&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This should also be legal. Given that a value can be accessed using a union that "contains" the effective type, this would be legal if the active type was int. It would however also work if the effective type was union, because we are accessing it using the same type. If we instead consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;union&lt;/syntax&gt;{
&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
}*&lt;syntax&gt;u&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;u&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;5&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;fp&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;u&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;fp&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;I think there is some consensus that this is UB, and I'm pretty sure I have seen examples of code like this breaking, in real world compilers. *fp has to access a compatible type, and neither int or the union is a compatible type. If we then consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;union&lt;/syntax&gt;{
&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;float&lt;/syntax&gt; &lt;syntax&gt;f&lt;/syntax&gt;;
&lt;lb/&gt;
}*&lt;syntax&gt;u&lt;/syntax&gt;;
&lt;lb/&gt;

&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;u&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;i&lt;/syntax&gt; = &lt;syntax&gt;5&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;ip&lt;/syntax&gt; = &amp;amp;&lt;syntax&gt;u&lt;/syntax&gt;-&amp;gt;&lt;syntax&gt;i&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;x&lt;/syntax&gt; = *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This I think should work (but i would highly discourage anyone depending on). This would indicate that the effective type is in fact, int.&lt;/p&gt;&lt;p&gt;So my conclusion is: struct and union members have the effective type of the member.&lt;/p&gt;&lt;p&gt;If you read this document it you may find to your horror an awful lot of C code, probably code you have written, is UB and therefore broken. However just because something is technically UB doesn't mean compilers will take advantage of that and try to to break your code. Most compilers want to compile your code and not try to break it. Given that almost no one understands these rulles, compilers give programmers a lot of leeway. A lot of code that technically breaks these rules will in reality never cause a problem, because any compiler crazy enough to assume all code is always in 100% compliance whit these rules would essentially be deemed broken by its users. If you are using fwrite to fill out a structure, you are just fine. No reasonable compiler would ever break that code.&lt;/p&gt;&lt;p&gt;The issue is not that implementations don't give users leeway, the issue is that its unclear how much leeway is given.Â&lt;/p&gt;&lt;p&gt;Many compilers (Like visual studion) just flat out ignore these rulles and will let you break them any way you want. Other compilers like gcc and llvm offer options like no-strict-aliasing that turn off any optimizations relying on these rules. Many projects (Most notably the Linux kernel), and security guidelines mandate no-strict-aliasing, in order to get around the issue entirely. If you are unsure, or want to be safe, I recommend using these options, especially if you are working on larger team with diverse levels of experience.&lt;/p&gt;&lt;p&gt;If you are unsure, or want to be safe, I recommend:&lt;/p&gt;&lt;p&gt;- Don't ever use variables as "memory buffers" that can be written to, outside of memcpy and memmove. Don't ever access a declared variable with an other type then its declared type.&lt;/p&gt;&lt;p&gt;- Don't ever access uninitialized memory for any reason.&lt;/p&gt;&lt;p&gt;(reading uninitialized memory is UB, and can have very surprising results. For instance reading the same uninitialized values twice may yield different results, or branches of your code that read un initialized memory may be deleted entirely. Uninitialized memory is not a source of entropy)&lt;/p&gt;&lt;p&gt;- Don't use calloc or memset for struct or pointer initialization.&lt;/p&gt;&lt;p&gt;(This is probably the most controversial advice on this list. It creates hard to find second use bugs and the bit representation is not portable. (memset(&amp;amp;p 0x0, sizeof(void *)) is not guaranteed to be set to NULL for example), It can at times be advantageous to "pre-prime" memory using memset, and then initialize the memory for performance)&lt;/p&gt;&lt;p&gt;- Don't ever take a pointer off a member of a union.&lt;/p&gt;&lt;p&gt;(implementations have been known to break code doing this, either because of compiler bugs or being UB)&lt;/p&gt;&lt;p&gt;- If you take a pointer to a member of a struct, never use that pointer to access anything outside of that member (like other members of the struct)&lt;/p&gt;&lt;p&gt;- Any time you need to type prune, use a union.&lt;/p&gt;&lt;p&gt;(Do not access the same memory using a cast pointer. If you have a float and want to access it as a float, make a union, copy the integer to the union and then read the float from the union. Any reasonable compiler will optimize away the compiler)&lt;/p&gt;&lt;p&gt;- Don't ever convert an integer in to a pointer.&lt;/p&gt;&lt;p&gt;(This is at best non-portable and often run afoul of provenance rules or compiler interpretations of the same)&lt;/p&gt;&lt;p&gt;- Don't ever read memory with a type that is different then it was written.&lt;/p&gt;&lt;p&gt;- If allocated memory is re-used, make sure it is re initialized using the new types it will be used, before reading from it.&lt;/p&gt;&lt;p&gt;- Assume standard lib functions that write memory does so with the type you will use to read that memory.&lt;/p&gt;&lt;p&gt;(May in theory be UB, but guaranteed to work on all platforms)&lt;/p&gt;&lt;p&gt;- When in doubt use a union condom.&lt;/p&gt;&lt;p&gt;- Never create a pointer to an area outside of the size plus one byte of the object. Any pointer outside of this may have wrapped or been clamped. Don't assume you know what your machine does in this case.)&lt;/p&gt;&lt;p&gt;- Never use a pointer to a freed object for ANYTHING, including comparing it to other pointers. (If you want to test for ABA bugs, convert the pointer to an integer before freeing it and then convert the new pointer to an other integer, and then compare the two integers.)&lt;/p&gt;&lt;p&gt;-Never convert a pointer to integer for any other reason than the above, and debugging/visualization.&lt;/p&gt;&lt;p&gt;-Pointers to different objects do not relate to each other, Never test where two pointers to different object are in relation to one an other, never compute the offset between two objects and never try to access one object using a pointer originating form another.&lt;/p&gt;&lt;p&gt;-Never use Variable length arrays. They have no way of reporting out-of-memory, and the stack is small. They are inherently untrustworthy. they are effectively UB.Â (so is recursion, unless you have set a hard limit on the number of recursions that have been thoroughly tested on the target platform, then they become platform dependent)&lt;/p&gt;&lt;p&gt;-Do not EVER think you know when its ok to break the rules, because you know how your compiler/platform works, if you do, the compiler lie and wait until it finds a way to break your code in the most nefarious way when you least expect it.&lt;/p&gt;�&lt;p&gt;If you are unsure, or want to be safe, I recommend:&lt;/p&gt;&lt;p&gt;- Don't ever use variables as "memory buffers" that can be written to, outside of memcpy and memmove. Don't ever access a declared variable with an other type then its declared type.&lt;/p&gt;&lt;p&gt;- Don't ever access uninitialized memory for any reason.&lt;/p&gt;&lt;p&gt;(reading uninitialized memory is UB, and can have very surprising results. For instance reading the same uninitialized values twice may yield different results, or branches of your code that read un initialized memory may be deleted entirely. Uninitialized memory is not a source of entropy)&lt;/p&gt;&lt;p&gt;- Don't use calloc or memset for struct or pointer initialization.&lt;/p&gt;&lt;p&gt;(This is probably the most controversial advice on this list. It creates hard to find second use bugs and the bit representation is not portable. (memset(&amp;amp;p 0x0, sizeof(void *)) is not guaranteed to be set to NULL for example), It can at times be advantageous to "pre-prime" memory using memset, and then initialize the memory for performance)&lt;/p&gt;&lt;p&gt;- Don't ever take a pointer off a member of a union.&lt;/p&gt;&lt;p&gt;(implementations have been known to break code doing this, either because of compiler bugs or being UB)&lt;/p&gt;&lt;p&gt;- If you take a pointer to a member of a struct, never use that pointer to access anything outside of that member (like other members of the struct)&lt;/p&gt;&lt;p&gt;- Any time you need to type prune, use a union.&lt;/p&gt;&lt;p&gt;(Do not access the same memory using a cast pointer. If you have a float and want to access it as a float, make a union, copy the integer to the union and then read the float from the union. Any reasonable compiler will optimize away the compiler)&lt;/p&gt;&lt;p&gt;- Don't ever convert an integer in to a pointer.&lt;/p&gt;&lt;p&gt;(This is at best non-portable and often run afoul of provenance rules or compiler interpretations of the same)&lt;/p&gt;&lt;p&gt;- Don't ever read memory with a type that is different then it was written.&lt;/p&gt;&lt;p&gt;- If allocated memory is re-used, make sure it is re initialized using the new types it will be used, before reading from it.&lt;/p&gt;&lt;p&gt;- Assume standard lib functions that write memory does so with the type you will use to read that memory.&lt;/p&gt;&lt;p&gt;(May in theory be UB, but guaranteed to work on all platforms)&lt;/p&gt;&lt;p&gt;- When in doubt use a union condom.&lt;/p&gt;&lt;p&gt;- Never create a pointer to an area outside of the size plus one byte of the object. Any pointer outside of this may have wrapped or been clamped. Don't assume you know what your machine does in this case.)&lt;/p&gt;&lt;p&gt;- Never use a pointer to a freed object for ANYTHING, including comparing it to other pointers. (If you want to test for ABA bugs, convert the pointer to an integer before freeing it and then convert the new pointer to an other integer, and then compare the two integers.)&lt;/p&gt;&lt;p&gt;-Never convert a pointer to integer for any other reason than the above, and debugging/visualization.&lt;/p&gt;&lt;p&gt;-Pointers to different objects do not relate to each other, Never test where two pointers to different object are in relation to one an other, never compute the offset between two objects and never try to access one object using a pointer originating form another.&lt;/p&gt;&lt;p&gt;-Never use Variable length arrays. They have no way of reporting out-of-memory, and the stack is small. They are inherently untrustworthy. they are effectively UB.Â (so is recursion, unless you have set a hard limit on the number of recursions that have been thoroughly tested on the target platform, then they become platform dependent)&lt;/p&gt;&lt;p&gt;-Do not EVER think you know when its ok to break the rules, because you know how your compiler/platform works, if you do, the compiler lie and wait until it finds a way to break your code in the most nefarious way when you least expect it.&lt;/p&gt;�&lt;p&gt;As a rule all UB should be avoided. Thinking that you know what UB does is a very dangerous thing to do. If there is a way to avoid UB you should always do so. Please refer to the UB article on this page for a deep dive in to how UB works in C and why it is not dependable. Having said all that, there are a few instances where things are technically UB, or when the standard has flaws or is unclear, so that somethings are UB by omission, or there is disagreement over if something is UB or not.&lt;/p&gt;&lt;p&gt;Here is a list of instances of UB where the behaviour can be expected to be dependable on all known implementations. This list is especially important for people who are implementing the C standard, because while these things may be UB according to the standard, a lot of code depend on them.&lt;/p&gt;&lt;p&gt;The standard declares that there can not be any padding before the first member of struct. It is unclear in the standard if this means that the pointer to the struct, is the same as the pointer to the first member of the struct. In theory, one could imagine an architecture where type information is encoded in the pointer, where they would be different. In practice, in all known implementation the pointer to the struct is equivalent to the pointer of the first member of the struct, and a lot of code depends on this to implement polymorphism. It can therefor be Considerd Dependable. The same could apply for unions, but taking a pointer of a member of a union is not dependable.&lt;/p&gt;&lt;p&gt;Replacing a standard function using a macro is UB:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#define&lt;/syntax&gt;&lt;syntax&gt;my_printf&lt;/syntax&gt;&lt;syntax&gt;printf&lt;/syntax&gt;&lt;lb/&gt;&lt;/code&gt;

&lt;p&gt;This practice is dependable and using this technique to create debug versions of standard library functions, is a good practice. (Se memory debugging under extras)&lt;/p&gt;&lt;p&gt;The C standard defines that a program must have "main" as its entry point, and a program that does not have "main" function is UB. Obviously many platforms define their own entry points, and all platforms allows C to be used for library development, and then the users are able to declare their own entry points. Writing libraries without main in them, in C is dependable.&lt;/p&gt;&lt;p&gt;Section: 6.5.7.8 states regarding what is allowed with pointer arithmetic:&lt;/p&gt;&lt;p&gt;"For the purposes of these operators, a pointer to an object that is not&lt;/p&gt;&lt;p&gt;an element of an array behaves the same as a pointer to the first element of an array of length one with the type of the object as its element type."&lt;/p&gt;&lt;p&gt;now consider:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;, *&lt;syntax&gt;p2&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;p&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;((&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;p&lt;/syntax&gt;) * &lt;syntax&gt;3&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;p2&lt;/syntax&gt; = &lt;syntax&gt;p&lt;/syntax&gt; + &lt;syntax&gt;2&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Given that p does not point to an array, according to the above definition it treated as having length of one and therefore constructing a pointer 2 beyond the object is undefined, even though it is within the allocation. This is clearly a defect of the standard, and a pointer to allocated memory should be treated as if it was an array.&lt;/p&gt;&lt;p&gt;In C effective type of a function depends on declaration or access, not the type of the pointer. When a pointer is passed as a parameter to a function, it is dependable to assume that you can access the pointer using the type of the pointer without violating effective type rules. This is UB because it violates the effective type rules:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;int&lt;/syntax&gt;&lt;syntax&gt;function&lt;/syntax&gt;()
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;pf&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;);
&lt;lb/&gt;
    *&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
    *&lt;syntax&gt;fp&lt;/syntax&gt; = (&lt;syntax&gt;float&lt;/syntax&gt; *)&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"%f"&lt;/syntax&gt;, *&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
    *&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;3.15&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;return&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;   
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Because the memory is being assigned an effective type of int, and then read as a float this code is UB. It is UB again when the memory is written to as a float and then read as an int. (This example assumes a platform where float and int have the same size, whether this is true or not is platform defined). Like wise the following is technically UB for the same reason:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;other_function&lt;/syntax&gt;(&lt;syntax&gt;float&lt;/syntax&gt; *&lt;syntax&gt;fp&lt;/syntax&gt;)
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;printf&lt;/syntax&gt;(&lt;syntax&gt;"%f"&lt;/syntax&gt;, *&lt;syntax&gt;fp&lt;/syntax&gt;);
&lt;lb/&gt;
    *&lt;syntax&gt;fp&lt;/syntax&gt; = &lt;syntax&gt;3.15&lt;/syntax&gt;;
&lt;lb/&gt;
}
&lt;lb/&gt;

&lt;lb/&gt;
&lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;function&lt;/syntax&gt;()
&lt;lb/&gt;
{
&lt;lb/&gt;
    &lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;sizeof&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;);
&lt;lb/&gt;
    *&lt;syntax&gt;ip&lt;/syntax&gt; = &lt;syntax&gt;42&lt;/syntax&gt;;
&lt;lb/&gt;
    &lt;syntax&gt;other_function&lt;/syntax&gt;((&lt;syntax&gt;float&lt;/syntax&gt; *)&lt;syntax&gt;ip&lt;/syntax&gt;);
&lt;lb/&gt;
    &lt;syntax&gt;return&lt;/syntax&gt; *&lt;syntax&gt;ip&lt;/syntax&gt;;   
&lt;lb/&gt;
}
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;In practice, however I would consider this code dependable. The passing of memory over the barrier of a function forces both caller and callee, to assume that the memory being shared have the effective type required for correct execution. In other words, the compiler assumes that "other_function" is given memory that is legal to read because it has the effective type of float, and "function" assumes that the memory given back by "other_function" has the effective type of int since that is how it will read the memory. A way to express this is to say that all memory passing a function barrier has its effective type cleared. This is not standard, but is something I regard as dependable.&lt;/p&gt;&lt;p&gt;The C standard considers any program that uses any threading facility other than C11s threading and atomics to be UB. This means that any program that uses pthreads (POSIX) are technicaly UB. Platform specific threading facilities such as posix threads are in practice far more dependable, supported and battle tested than C11 threads.&lt;/p&gt;�&lt;p&gt;By Eskil Steenberg Hald eskil@quelsolaar.com&lt;/p&gt;&lt;p&gt;Many people struggle with memory corruption in C, I rarely do, and one of the mains reasons is a pattern of memory debuggers I have been employing for many years. This memory debugger comes in the form of an include and a c file that can be added to any C project. It is entirely platform independentcc89, and does not require any modification of the code being debugged outside of being included.&lt;/p&gt;&lt;p&gt;The concept is very simple: use a macros to capture all allocations and deallocations, so that you can track our memory. In this document I will describe my implementation "Forge" of this technique. Its freely available, but you can also easily implement your own flavour of this functionality in a couple of hours.&lt;/p&gt;&lt;p&gt;The macros we define are:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;#define&lt;/syntax&gt;&lt;syntax&gt;malloc&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;) &lt;syntax&gt;f_debug_mem_malloc&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;, &lt;syntax&gt;__FILE__&lt;/syntax&gt;, &lt;syntax&gt;__LINE__&lt;/syntax&gt;) &lt;syntax&gt;/* Replaces malloc. */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;calloc&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;, &lt;syntax&gt;m&lt;/syntax&gt;) &lt;syntax&gt;f_debug_mem_calloc&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;, &lt;syntax&gt;m&lt;/syntax&gt;, &lt;syntax&gt;__FILE__&lt;/syntax&gt;, &lt;syntax&gt;__LINE__&lt;/syntax&gt;) &lt;syntax&gt;/* Replaces calloc. */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;realloc&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;, &lt;syntax&gt;m&lt;/syntax&gt;) &lt;syntax&gt;f_debug_mem_realloc&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;, &lt;syntax&gt;m&lt;/syntax&gt;, &lt;syntax&gt;__FILE__&lt;/syntax&gt;, &lt;syntax&gt;__LINE__&lt;/syntax&gt;) &lt;syntax&gt;/* Replaces realloc. */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;syntax&gt;#define&lt;/syntax&gt; &lt;syntax&gt;free&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;) &lt;syntax&gt;f_debug_mem_free&lt;/syntax&gt;(&lt;syntax&gt;n&lt;/syntax&gt;, &lt;syntax&gt;__FILE__&lt;/syntax&gt;, &lt;syntax&gt;__LINE__&lt;/syntax&gt;) &lt;syntax&gt;/* Replaces free. */&lt;/syntax&gt;
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;We add these macros in to a header file that we include in to all c files of our project. We also put ifdefs, around these macros so that we can turn the macros on and off. The system is meant for debugging only and so when you are not debugging, it should be turned off. The advantage of this approach is that you don't need to write your code with the debugging system in mind, or use a special memory allocator, and its therefore easy to apply to existing projects, or remove from projects, once the memory management have been tested.&lt;/p&gt;&lt;p&gt;These macros reroutes all calls to standard allocation functions to our debug code. By also adding on the file and line where the calls happen we can catalogue where all allocations and frees occurs. This enables some pretty handy tools to be built.&lt;/p&gt;&lt;p&gt;In order to make uninitialized memory easier to detect, the system always initializes all memory allocated with malloc and realloc to 0xCD. Some development environments do this in debug mode too, but this fives you that feature on all platforms, and makes it possible to turn on even in release mode, if you encounter issues that only surface in release mode.&lt;/p&gt;&lt;p&gt;To track the applications full memory consumption, you can call:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;size_t&lt;/syntax&gt;&lt;syntax&gt;f_debug_mem_consumption&lt;/syntax&gt;(&lt;syntax&gt;void&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;It will return the total sum of allocated memory (not including memory used internally by forge, the amount of memory consumed by forge internally can be significant).&lt;/p&gt;&lt;p&gt;Because the system tracks all allocations we can print out a summary list of all allocations:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;f_debug_mem_print&lt;/syntax&gt;(&lt;syntax&gt;unsigned&lt;/syntax&gt; &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;min_allocs&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Each printout will come with amount of memory consumed, the number of allocations that have bene made and how many of those allocations have subsequently been freed. This lets you very easily identify where memory is allocated, what parts of your code consumes the most memory and memory leaks. My implementation has a minimum allocation parameter, that will make it possible to limit the print outs, to allocations that have been called a minimum number of times. This is useful because its a simple way to ignore allocations that only happen very few times, like during start-up. You can also call:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;f_debug_mem_log&lt;/syntax&gt;(&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;file_pointer&lt;/syntax&gt;); 
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;with a valid FILE pointer (or NULL to disable), to print out al log of all allocations and deallocations. Another way to find memory leaks is to call:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;f_debug_mem_check_heap_reference&lt;/syntax&gt;(&lt;syntax&gt;unsigned&lt;/syntax&gt; &lt;syntax&gt;int&lt;/syntax&gt; &lt;syntax&gt;minimum_allocations&lt;/syntax&gt;); 
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;It will look for all allocated pointers, in heap memory, and report any allocated memory it can not find a pointer to. This will yield false positives and false negatives. A memory storing other data can happen to have the same bit combination as a allocated pointer, and allocated pointers not found in heap memory may still be held in stack memory. It is still a useful tool to triage memory leaks. The minimum_allocations parameter, lets you limit the system to only look for leaks in systems that allocate more times then the specified value.&lt;/p&gt;&lt;p&gt;Since the system is keeping track of all memory, it is able to detect a number of different memory corruptions. to do this the system needs to traverse the catalogue of memory and check for errors. This is done by calling:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;boolean&lt;/syntax&gt;&lt;syntax&gt;f_debug_mem_check_bounds&lt;/syntax&gt;();
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;You can place any number of calls to this function to narrow down when a problem occurs. You can also enable the define "FORGE_MEMORY_CHECK_ALWAYS", to run f_debug_mem_check_bounds any time malloc, calloc, free, or realloc is called. If you have a lot of allocations this will decrease performance significantly, but its a very fast way to quickly narrow down an issue.&lt;/p&gt;&lt;p&gt;In order to catch buffer overruns the system will always over allocate, every allocation and fill the surrounding memory with a magic number (0xCF). Every time f_debug_mem_check_bounds is called the surrounding memory of every allocation will be checked, to make sure none of this memory has been written to. This catches almost all heap buffer overrun bugs. You can set the amount of allocated memory being allocated by changing the define FORGE_MEMORY_OVER_ALLOC. The larger it is to more things it will catch, but the slower and more wasteful it will be. You can set the define FORGE_MEMORY_PRE_PADDIG as to how much of this memory should go before the allocation, and the rest will go after it. (In general is far more likely to have a buffer over-run then a buffer under-run, so having more padding after the allocation is advisable) Because this is such a powerful tool to catch buffer overruns in the heap, I have started considering using heap memory to be less error prone to stack memory (From a security standpoint stack memory is more venerable to attacks then heap memory since the stack memory layout is mostly known).&lt;/p&gt;&lt;p&gt;If the define "FORGE_DOUBLE_FREE_CHECK" is enabled, the system will keep a list of all freed pointers, and check any pointer being freed against this list. This effectively detects any double free.&lt;/p&gt;&lt;p&gt;Any time memory is being freed, it will always be cleared with a magic number (0XCD), so that if it is accidentally read again, it will not give yield usable data. However, bugs where a pointer points to freed memory, that is then again allocated, can be hard to find, since the pointer is again pointing to valid memory. To find these bugs you can enable the define "FORGE_USE_AFTER_FREE_CHECK" any memory passed to free will, not be freed, but will instead be cleared with a magic number (0XCD). Any call to f_debug_mem_check_bounds will then check all freed memory in case any of it has been over written. Obviously this consumes a lot of memory.&lt;/p&gt;&lt;p&gt;Modern computers with virtualized memory very rarely fails at allocating memory. Most of the times when allocation fails its because the user accidentally, tried to allocated an unreasonable amount of memory as a result of an underflow or other mistake. By enabling FORGE_MEMORY_NULL_ALLOCATION_ERROR, the system will flag any time a allocation fails and print an error to standard out.&lt;/p&gt;&lt;p&gt;To catch code that erroneously uses pointer that have been reallocated, every realloc will be turned in to a malloc, memcpy, free where the freed memory is given the same, treatment as other deallocations to protect against use-after-free and double frees. The system also checks that realocations are executed on valid allocations, and will isse errors if the pointers are not the base pointer of the allocation.&lt;/p&gt;&lt;p&gt;The system is able to guestimate if a pointer points to the stack by taking the pointer of a variable on the stack and then measure if a pointer is close to this pointer in address space. You can ask the system to look for suspected pointers to the stack in heap allocated memory, using:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;f_debug_mem_check_stack_reference&lt;/syntax&gt;();
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This can be very useful, to track down bugs where allocated memory references stack pointers, that may have expired. This test, will yield false positives, either by having heap and stack being close in address space, especially on 32 bit machines, or by data simply having the same bit combinations as pointers near the stack. It is still very useful when tracking down a class of difficult bugs.&lt;/p&gt;&lt;p&gt;If you are on a platform ether the size and location of the stack in known, you can call:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;f_debug_mem_stack_pointer_set&lt;/syntax&gt;(&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;lowest_stack_pinter&lt;/syntax&gt;, &lt;syntax&gt;size_t&lt;/syntax&gt; &lt;syntax&gt;stack_size_in_bytes&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;With the stack defined all functionality that uses the stack locating becomes more accurate, and f_debug_mem_check_heap_reference is able to search the stack for references to allocations.&lt;/p&gt;&lt;p&gt;The debugger can also be used to query memory. By calling:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;f_debug_mem_query_origin&lt;/syntax&gt;(&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;pointer&lt;/syntax&gt;, &lt;syntax&gt;unsigned&lt;/syntax&gt; &lt;syntax&gt;int&lt;/syntax&gt; *&lt;syntax&gt;line&lt;/syntax&gt;, &lt;syntax&gt;char&lt;/syntax&gt; **&lt;syntax&gt;file&lt;/syntax&gt;, &lt;syntax&gt;size_t&lt;/syntax&gt; *&lt;syntax&gt;size&lt;/syntax&gt;); 
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;Users can query where a pointer was allocated, and how much was allocated. It also returns the base pointer of the allocation. if the pointer is not found in the forge index, the functions returns NULL. Thiscan be very usefull to track the origin of an allocation. You can also call:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;boolean&lt;/syntax&gt;    &lt;syntax&gt;f_debug_mem_query_is_allocated&lt;/syntax&gt;(&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;pointer&lt;/syntax&gt;, &lt;syntax&gt;size_t&lt;/syntax&gt; &lt;syntax&gt;size&lt;/syntax&gt;, &lt;syntax&gt;boolean&lt;/syntax&gt; &lt;syntax&gt;ignore_not_found&lt;/syntax&gt;); 
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;To query if a memory range is in a valid allocation. The function will return TRUE if it is valid, FALSE if it is out or range on and exisiting allocation, or par of a freed allocation. If the pointer is not found, it will return the parameter ignore_not_found;&lt;/p&gt;&lt;p&gt;A pointer that have been allocated with the forge debugger macros enabled, can only be freed with a free or realloc, wrapped by forge debugger macros, (un less FORGE_MEMORY_PRE_PADDIG is set to zero), and will most likely lead to crashes on memory safe systems. however pointers that have been allocated, outside of forge debugger macros, can be freed or realoced by forge macros, with a warning. This is to make forge usable in situations where is is dificult, to include the forge headers in all code. Any time a pointer is given to forge that it does not recognize, it will estimate if this could be a stack pointer.&lt;/p&gt;&lt;p&gt;This library is written in pure portable "dependable" C89, without any dependencies or platform specific code. As such it is not thread safe out-of-the-box. To make it thread safe, you need to call:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;void&lt;/syntax&gt;&lt;syntax&gt;f_debug_mem_thread_safe_init&lt;/syntax&gt;(&lt;syntax&gt;int&lt;/syntax&gt; (*&lt;syntax&gt;lock&lt;/syntax&gt;)(&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;mutex&lt;/syntax&gt;), &lt;syntax&gt;int&lt;/syntax&gt; (*&lt;syntax&gt;unlock&lt;/syntax&gt;)(&lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;mutex&lt;/syntax&gt;), &lt;syntax&gt;void&lt;/syntax&gt; *&lt;syntax&gt;mutex&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;

&lt;p&gt;This lets you give the debugger function pointers to a platform specific lock, and unlock function. An example of how this could be done using POSIX threads is:&lt;/p&gt;&lt;code&gt;&lt;syntax&gt;pthread_mutex_t&lt;/syntax&gt; *&lt;syntax&gt;mutex&lt;/syntax&gt;;
&lt;lb/&gt;
&lt;syntax&gt;pthread_mutex_init&lt;/syntax&gt;(&lt;syntax&gt;mutex&lt;/syntax&gt;, &lt;syntax&gt;NULL&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;syntax&gt;f_debug_mem_thread_safe_init&lt;/syntax&gt;(&lt;syntax&gt;pthread_mutex_lock&lt;/syntax&gt;, &lt;syntax&gt;pthread_mutex_unlock&lt;/syntax&gt;, &lt;syntax&gt;mutex&lt;/syntax&gt;);
&lt;lb/&gt;
&lt;/code&gt;&lt;p&gt;There are technically three known instances of undefined behaviour in this implementation. This should in the context of this tool be benign. It is however not recommended using forge in release builds, only for debugging. (If someone can find a platform/implementation where either of these issues do cause a problem please let me know, id be very interested to learn more). Using a macro to replace a built in or standard lib function is technically UB in the C standard. I have never encounter an implementation where this is a problem. All known implementations do what you expect them to do in this instance. The second UB is that the implementation uses &amp;lt; and &amp;gt; when comparing pointers originating from different objects. This could be addressed, by simply comparing against the address of every allocated byte, but this would be incredibly slow. The third is that we do construct pointers outside of their allocations when estimating if something is in the stack. In theory this could result in a wrapped pointer, that could make outputs unreliable. If you are on a platform with 32 or less bit pointer, this may be an issue and we recommend trying to acquire the stack pointer. Technically, the code would still be UB, but would have much lower chance of causing issues.&lt;/p&gt;&lt;p&gt;The instances of UB have been marked in the source code.&lt;/p&gt;�&lt;p&gt;Both languages preform admirably at their intended use. Its just a matter of picking the right language for the job. Rust is designed to be used in arguments against C, where as C is designed to be used when developing software.&lt;/p&gt;&lt;p&gt;I'm convinced that the keyword _Generic in C was not invented for programmers to use. It was invented to preoccupy the ISO C wg14, with an endless stream of proposals, arguments and corner cases.&lt;/p&gt;&lt;p&gt;The advantage of High level languages is that people can produce software without needing to know how a computer works. The disadvantage of High level languages is that now we have software produced by people who donât know how computers work.&lt;/p&gt;&lt;p&gt;I donât suffer from âNot invented hereâ. I have already written most things I could need. I suffer from âNot invented recentlyâ. Sure I could use a library i have already written, but i could write a better one nowâ¦&lt;/p&gt;&lt;p&gt;I have completely changed my mind about the C keyword "register". I used to think it was worthless because its just a hint, now I think its worthless because you cant use it in structs.&lt;/p&gt;&lt;p&gt;Its hard to write abstractions in C, because its so painfully clear what the cost of abstractions are. In other languages abstractions appear to be free, because there is already so much stuff going on behind you back you don't notice the difference.&lt;/p&gt;&lt;p&gt;Why do people consider Code quality == Maintainability? The word "quality" in the rest of the world means that something doesn't break. A car/house/fridge that requires constant maintenance, but is easy to take apart wouldn't be considered "high quality". It would just suck.&lt;/p&gt;&lt;p&gt;In the beginning all you want is results, in the end all you want is control.&lt;/p&gt;&lt;p&gt;People will tell you "DonÂ´t try to make your own OS/Compiler/GameEngine/Browser/Threading/Language.... Its hard". I say: Learn hard things by doing hard things. The world values, hires and needs people who can do hard things.&lt;/p&gt;&lt;p&gt;Abstractions in programming are usually built on the premise that the user don't want to know or care what is going on. I need to know if its a function or macro, I need to know if the type is a value a pointer or a struct, so abstractions are just shit I have to dig through.&lt;/p&gt;&lt;p&gt;You need to be audacious enough to believe that your are the one who can do the big things, and at the same time also self critical enough to course correct yourself constantly to reach that goal. Either is easy, the combination is rare.&lt;/p&gt;&lt;p&gt;In 2023, a crack programming unit was sent to prison by a Rust mob for a crime they didn't commit. These men promptly escaped from a maximum security stockade to the Internet underground. Today, still wanted by the government, they survive as system developers. If you have a performance problem, if no one else can help, and if you can find them, maybe you can hire... the C-Team.&lt;/p&gt;�&lt;p&gt;By Eskil Steenberg Hald 2025&lt;/p&gt;&lt;p&gt;Representative of Sweden in iso Wg14&lt;/p&gt;&lt;p&gt;eskil at quelsolaar dot com @eskilsteenberg&lt;/p&gt;&lt;p&gt;The most trusted software in the world like OpenSSL, Apache, SQLite, Curl, CPython, FFMpeg, PHP, the GNU free software collection, most OS kernels, and most filesystems are all written in C. No other language has managed to produce anywhere near the same amount of safety and security critical software deployed the world over as C. In evolutionary terms, it is clear that security critical C projects have a much higher survival rate than security critical projects written in any other language.&lt;/p&gt;&lt;p&gt;Despite the overwhelming success of C as a language for developing security critical software, many security researchers claim that C is an unsafe language that should be avoided for security critical software. They take it as a given that C is unsafe, because of some of C features, most notably the lack of required bounds checking. It is a very unscientific to assume this feature would outweigh possible other benefits of using C, when clearly this feature hasn't stopped C from being the most successful language in security. When assumption says one thing but real world experience says something completely different, its time to re-evaluate ones assumptions.&lt;/p&gt;&lt;p&gt;If security researchers are interested in research that is based on the scientific method, they should clearly want to investigate why C has produced so many successful security critical projects, instead of dismissing C as an insecure language, against clear evidence. Security researchers should investigate various explanations for why C has been so successful, despite the reasons for why someone may think it shouldn't be. To simply dismiss all the people who have chosen C as their language, and then have gone on to produce some of the most trusted software on the planet (and other planets), as simply not knowing what they are doing, is both disrespectful and ignorant, and should not be part of scientific discord with the ultimate goal of finding the truth and making progress.&lt;/p&gt;&lt;p&gt;Actual research in to why C has been so successful for security critical software could have great impact on future security policy, possible language design, how we see Cs future, and generally how we think about software development. Simply ignoring C developers success, or worse trying to gaslight the world into thinking C developer have not had great contribution to the security of software, robs the world of valuable insights in to how successful software is developed.&lt;/p&gt;&lt;p&gt;As an experienced C developer, I have a number of hypotheses as to why C has been so successful, that warrants further research. I want to be clear, I am not a researcher, nor am I claiming to present quantitative evidence for these theories. I do however think they are among theories that should be thoroughly investigated. As part of this list of theories, I also want to point out some possible ramifications for how we should view software development if they are shown to pan out.&lt;/p&gt;&lt;p&gt;C is language with very few abstractions. This makes it very easy to read and reason about the code. The difficulty in writing code is almost always to close the gap between, what the code does, and what the code is meant to do. Therefor being able to follow every step of execution, and have each step be explicit aids greatly. C code becomes safe, because it is easy to reason about, and easy to audit. Most things are written in place, and therefor require less knowledge of a larger system in order to be understood. This lack of interconnectedness that abstractions create also makes it harder for changes in one part of the code to break other parts of the code. C is a verbose, explicit language and while this creates a less convenient programming experience, it creates trustworthy software. An interesting observations is that other "unsafe" C derived languages like C++ and Objective-C, have produced has less trusted safety critical software. This indicates that the simplicity and lack of features of C are contributing factors. Another observation is that the successful software projects that do use C, tend to use older versions of C and restrict the use of features. The recent success of Python and Lua over more complex languages like Perl also indicates that simple readable languages with fewer features are in fact more reliable.&lt;/p&gt;&lt;p&gt;A general focus on clarity over expressiveness and cleverness in language design could lead to safer and simpler code. We should start looking at abstractions with a more critical eye in computer science. For C developers, this means avoiding complex macros, and using long and expressive naming. There are also many opportunities here to improve tooling. Compilers reason about code in order to optimize it, but rarely do they show the programmer its reasoning. It would be very valuable if code paths that are optimized away, assumptions made about values possible ranges, or memory model assumptions where presented to the user.&lt;/p&gt;&lt;p&gt;Many C programmers claim that C is a programming language they enjoy using. The fun factor is an underestimated factor in programming. An enjoyable programming experience leads to more engagement and long term maintenance of software project. A weak software project that is consistently updated and improved over a long period of time will eventually surpass a good software project that no one cares to improve. Something that speaks for this theory is that so many of the mentioned C projects are open-source project mainly maintained by volunteers. For a volunteer project to succeed motivation is key.&lt;/p&gt;&lt;p&gt;From a security perspective, we need to find the right balance between safety procedures and the joy and agility of programming. If every change results in onerous re-certification processes, and pointless warnings and procedures that need to be addressed, software will not be maintained properly. We need to find ways to better triage where the risks are and spend our time accordingly and avoid making necessary changes hard to make.&lt;/p&gt;&lt;p&gt;For other languages, we may also consider where the fun lies. C++ is a programming language that many people greatly enjoy architecting code in. It has a rich set of features to choose from, to build intricate structures. These structures, while fun to invent, are less fun to maintain, hence most C++ programmers have never seen any C++ code they did not want to rearchitect. It is an open question how to design languages that remains fun to program in as projects grow, but it should be explored seriously.&lt;/p&gt;&lt;p&gt;C gives the programmer a very high degree of control. As I am fond of saying: "In the beginning all you want is results, in the end all you want is control". Because C offers little in terms of pre-made facilities and a minimal standard library, you have to do most things yourself. This means that if you complete a project in C, you have a much more complete understanding of your software, than if it were written in a higher level language. This deep understanding is critical for identifying potential security vulnerabilities. Linus Torvalds once observed that when he writes C, he can in his mind see the assembly instructions being executed.&lt;/p&gt;&lt;p&gt;Compared to a language such as C++ where many different styles and paradigms exist, C is relatively simple. Because so many other languages like C++, Java and others borrow syntax from C, many non-C programmers are able to read and understand C to some degree. This lingua franca of computing aids in getting many more eyes on critical code and therefore makes C code more secure. Unlike languages like C++ there is less divergence in the options of how the language should be programmed, simply because there are fewer ways to do things. This also makes it easier for open source projects to attract more developer who can contribute.&lt;/p&gt;&lt;p&gt;We should put higher weight on writing plain code, and avoid clever tricks or new language features. We can create new guidelines and tools that evaluate code according to these guidelines. MISRA, and CERT are such guidelines focusing on safety and security, but additional guidelines that focus on simplicity, readability, and portability could be created.&lt;/p&gt;&lt;p&gt;It is possible that C is successful despite its apparent security shortcomings, simply because users have different priorities. The main priority that could override security is Cs performance. Performance isn't just about how long something takes to execute it also translates in to battery life, power consumption, hardware scale, cooling costs, CO2 emissions, and directly to cost of operation. For a large scale cloud operations a few percentage points of performance degradation, translates in to hundreds of millions in added capex for hardware, power and cooling. Data centres alone are estimated to use 3-4% of all generated power by the end of the decade, and added to this is all the power consumed by other devices running C based software. Even a small degradation of efficiency at this scale results in large costs and CO2 emissions.&lt;/p&gt;&lt;p&gt;Switching from trusted legacy C software, to new comparably untested software written in an other language, with substantially higher running cost, with the promise of better future security is a substantial leap of faith.&lt;/p&gt;&lt;p&gt;Further evidence for this theory is that, C does not have to be memory unsafe. The C standard clearly states that any implementation is free to define a safe and documented behaviour for anything left undefined by the standard. Such implementations exist such as UBSan and Valgrind. It is entirely possible for anyone who prioritizes security to run any C software in these implementations. Yet, few people do (outside of debugging), this indicates that the majority of users have other priorities.&lt;/p&gt;&lt;p&gt;If things like performance and memory usage are highly valued properties of C software, perhaps this popularity affords C projects more time to mature and therefor address other issues like security issues.&lt;/p&gt;&lt;p&gt;Security professionals need to learn to accept that they live in a world where other considerations often take precedence over security. An example of this is various speculative execution mitigations that have been needlessly forced on most users. These mitigations have probably cost untold billions. These costs are rarely taken in to consideration when security is being discussed, and while many security changes have negligible impact on a specific system, in the aggregate, and when staked on to of layers of security protections, on a global scale have very large impacts.&lt;/p&gt;&lt;p&gt;C enjoys some advantages of being old, in that many projects have had time to mature and people have had time build up skills and knowledge about the language. Similarly C has wide range of tools and implementations that are mature and offers a lot of advantages. Most safety critical software have had years to mature and gain trust. While this factor can explain some of Cs success, many languages like C++ or Java are now old enough that if they would have offered significant advantage over C, they should have supplanted C by now, this clearly hasn't happened.&lt;/p&gt;&lt;p&gt;Computer science needs to stop equating new with better. You can not prove a negative, and therefor there is no way to prove that software is free from flaws. In fact, the best way we have of evaluating if something is good, is its longevity. This goes for languages, and code bases a like.&lt;/p&gt;&lt;p&gt;It is possible that C programmers are so used to dealing with things like memory management that, it becomes a natural part of how they think, and therefore presents far less far fewer issues than an outsider may suspect.&lt;/p&gt;&lt;p&gt;For a pedestrian who is not used to cars, living in a city where 2 tone metal boxes race down the streets at 50kph may seem like an extremely dangerous environment where inhabitants are contently under immense stress to avoid being hit by cars. For anyone who have coexisted with cars in a city for a long time, its a known risk, but one that one that represent an insignificant portion of lives worries. To developers coming from languages where memory is handled for you, the task can feel daunting, but to long time C developers it is a natural part of development that take up very little brainpower to maintain. On the scale of things C experienced programmers worry about memory management ranks low as there are other much more challenging tasks that needs to be completed.&lt;/p&gt;&lt;p&gt;Partly this is a result of experience, but its also that, people who seek out C, and chose to program in C are wired in a way that fits well with Cs design. C programmers do tend to be a different bread of programmers, who want to get close to the metal, and value control over convenience.&lt;/p&gt;&lt;p&gt;Perhaps we should consider C programmers separate, and recognize that C is a language that requires a different mindset to master than another languages. While many programmers tend to be able to switch languages often, maybe we should be more careful about who is assigned to program C. Instead of teaching C as yet another language, perhaps it should be treated more as a specialty. Advertising for C/C++ programmers isn't very helpful when the two languages require very different skills and mindsets.&lt;/p&gt;&lt;p&gt;Perhaps the language C has the advantage that it simply attracts good programmers. It is even conceivable that the perceived challenge of writing C code contributes to its popularity among seasoned programmers. This would mean that C projects are in part successful, because C programmers tend to be good programmers, and that these projects would see similar success with the same people using a different language. Linus torvalds famously pronounced that he wont let C++ in to the Linux Kernel, for the simple reason that he doesn't want to work with people who like C++.&lt;/p&gt;&lt;p&gt;If many of the best programmers choose C, then maybe C isn't that bad.&lt;/p&gt;&lt;p&gt;Most languages only have one or very few implementations, while C enjoys a wide range of implementations with very different aims. C also has many different debuggers, linters, fuzzes and static analysis tools that aid in debugging. The range, quality and maturity of C tools greatly aids in development or robust software.&lt;/p&gt;&lt;p&gt;Many other languages would do very well to focus more on tooling then syntax. IMO having a good debugger is by far the most important tool for a programmer, yet many programmers don't use debuggers, and many languages have very few debugging tools. While C has a lot of tools, there are still great improvements that can be made.&lt;/p&gt;&lt;p&gt;C is famous for its unforgiving nature. Because so many C bugs cause segfaults or other showstopping issues, much fewer bugs survive debugging. Modern C tools often make C even more unforgiving by detecting things like reads of uninitialized variables. This is a much stricter requirement than a language that may automatically initialize all values, and this forces developers to explicitly state their intention, as compilers do not assume that the user wants a default initialization. Many languages in the name of convenience, lets the programmer get away with things that do create hard to find bugs. For example java script lets you access object members without first declaring them. You can easily write object-&amp;gt;member = 42; and then by mistake try to access the value x = object-&amp;gt;Member; Java script will then assign x a default value, instead of issuing an error. Yes its convenient to not have to declare members in advance, but saving a few seconds of typing and then loosing hours to debugging or worse shipping broken software is much worse.&lt;/p&gt;&lt;p&gt;Policies that force programmers to engage with issues and ambiguities, instead of issuing warnings, or worse make assumptions about the users intentions are important to improve security. Most C compilers can be configured to fail compilation when it encounters selected warnings. This could be made much stricter, where more code is rejected, even though it technically is standard compliant. Implicit type conversions is one such feature that should not have been made part of C, but can easily be detected and remedied with tools.&lt;/p&gt;&lt;p&gt;As an old and well known language the issues in C are mostly well known. The fact that the language is smaller than many other languages, means that compilers and other infrastructure is less likely to encounter code that trigger an unexplored corner case. Most of the security issues are well known and easy to audit for. Because C is so wide spread there is also a large amount of people who are able to review and read C code.&lt;/p&gt;&lt;p&gt;Given that C code has been so successful, any issue in this widely deployed C code gets and outsized impact. A security vulnerability in OpenSSL has far greater ramifications, than another SSL implementation that don't have nearly as many users, no matter what language it was implemented in. Other languages like javascript, and SQL code, that have well known exploits have a much more diffuse attack surface. There are numerous websites that have a wide range of exploits, and may have lots of vulnerabilities, yet the finding of an exploit would not raise the headlines that an exploit in a widely used C system like the Linux kernel. Given the size and scope of projects like the Linux kernel and the number of people who have eyes of the project, its surprising how seldom serious exploits are found.&lt;/p&gt;&lt;p&gt;Its worth appreciating how seldom major security issues appear in major security critical software's written in C.&lt;/p&gt;&lt;p&gt;Any person who finds bugs in someone else's code, will have a bias against the design decisions that made the bugs possible or likely. This is another form of survivorship bias. However what they do not see are the issues that the design prevented. All engineering is inherently about trade-offs. Any decision will make some issues more likely and some other issues less likely. It is possible that while the design trade-offs in C creates some classes of bugs that reoccur, it on balance prevents much more issues, then it creates.&lt;/p&gt;&lt;p&gt;A good engineer, in any field, knows that she has to weigh the potential risks and benefits of any decision. Trying to cover for all risks, no matter how miniscule is to not properly allocate time, effort and resources on the problems that are likely to cause problems. Security researches have along track record of raising security issues that have a extremely low probability of being exploited.&lt;/p&gt;�&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46214091</guid><pubDate>Wed, 10 Dec 2025 04:29:30 +0000</pubDate></item><item><title>Are the Three Musketeers allergic to muskets?(2014)</title><link>https://www.ox.ac.uk/news/arts-blog/are-three-musketeers-allergic-muskets</link><description>&lt;doc fingerprint="b78079d241a5a73e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Are the Three Musketeers allergic to muskets?&lt;/head&gt;
    &lt;p&gt;The BBC's new drama series The Musketeers – adapted from Alexandre Dumas' novel Les Trois Mousquetaires – made its debut on Sunday evening. Ahead of the screening, Dr Simon Kemp, Oxford University Fellow and Tutor in French, tackled the curious question of why the musketeers appear to have an aversion to muskets...&lt;/p&gt;
    &lt;p&gt;"So here it comes. Peter Capaldi – Malcolm Tucker as was, Doctor Who as shortly will be – is twirling his moustache as Cardinal Richelieu in trailers for the much-heralded BBC adaptation of Alexandre Dumas' Les Trois Mousquetaires (1844). It's always good to see British TV take on French literary classics. Let's hope The Musketeers has a little more in common with its source material than the BBC's other recent effort, The Paradise, for which I'd be surprised if the producers were able to put up the subtitle 'based on the novel by Émile Zola' without blushing.&lt;/p&gt;
    &lt;p&gt;"At any rate, the Dumas adaptation looks exciting, with plenty of cape-swishing, sword-fighting, smouldering looks and death-defying leaps. Plus one element that is markedly more prevalent than in the book itself: gunfire. One of the odder things about Dumas' novel for the modern reader is its singular lack of muskets.&lt;/p&gt;
    &lt;p&gt;"In the mid-1620s, when the story is set, the Mousquetaires are the household guard of the French king, Louis XIII, an elite force trained for the battlefield as well as for the protection of the monarch and his family in peacetime. They are named for their specialist training in the use of the musket (mousquet), an early firearm originally developed in Spain at the end of the previous century under the name moschetto or 'sparrow-hawk'. Muskets were long-barrelled guns, quite unlike the pistols shown in the trailer, and fired by a 'matchlock' mechanism of holding a match or burning cord to a small hole leading to the powder chamber. By the 1620s they were not quite as cumbersome as the Spanish originals, which needed to have their barrels supported on a forked stick, but they were still pretty unwieldy devices.&lt;/p&gt;
    &lt;p&gt;"There are lots of weapons in the opening chapters of Les Trois Mousquetaires, where D'Artagnan travels to the barracks and challenges almost everyone he meets along the way to a duel (including all three of the musketeers). Lots of sword-fighting, but no muskets in sight. One of the musketeers has nicknamed his manservant mousequeton, or 'little musket', and that is as near as we get to a gun until page 429 of the Folio edition, when an actual mousqueton makes its first appearance. A mousqueton is not quite a musket, though, and in any case it's not one of the musketeers who is holding it.&lt;/p&gt;
    &lt;p&gt;"The siege of La Rochelle in the later part of the story seems a more propitious setting for firearms, and indeed, as soon as he arrives at the camp, D'Artagnan spies what appears to be a musket pointing at him from an ambush and flees, suffering only a hole to the hat. Examining the bullet-hole, he discovers 'la balle n'était pas une balle de mousquet, c'était une balle d'arquebuse' ('the bullet was not from a musket, it was an arquebuse bullet', arquebuse being an earlier type of firearm). We are now 586 pages into the story, and starting to wonder if Dumas is playing a game with us.&lt;/p&gt;
    &lt;p&gt;"The suspicion is heightened when the musketeers take a jaunt into no man's land for some secret scheming away from the camp: 'Il me semble que pour une pareille expedition, nous aurions dû au moins emporter nos mousquets,' frets Porthos on page 639 ('It seems to me that we ought to at least have taken our muskets along on an expedition like this'). 'Vous êtes un niais, ami Porthos; pourquoi nous charger d'un fardeau inutile?' scoffs Athos in return ('You're a fool, Porthos, my friend. Why would we weight ourselves down with useless burdens?').&lt;/p&gt;
    &lt;p&gt;"The key to the mystery of the missing muskets is in these lines. Their absence from the novel up to this point is simply for the historical reason that the heavy and dangerous weapons were appropriate for the battlefield, not for the duties and skirmishes of peace-time Paris. Even when his heroes are mobilized, Dumas remains reluctant to give his musketeers their muskets. Remember that, writing in the 1840s, Dumas is closer in time to us today than he is to the period he's writing about, and his gaze back to the 17th century is often more drawn to romance than historical accuracy (as the cheerfully pedantic footnotes in my edition point out on every other page).&lt;/p&gt;
    &lt;p&gt;"For Dumas, the charm of his chosen period lies in the skill and daring of the accomplished swordsman, and his breathless narrative can wring far more excitement from a well-matched duel of blades than it could from a military gun battle. Heroism in Dumas is to be found in noble combat, staring your opponent in the eye as you match his deadly blade with your own, not in the clumsy long-range slaughter of unknowns. Musketeers his heroes must be, in order that they might belong to the royal guard and thus play a role in the dark conspiracies hatched around the King, the Queen and her English lover by Cardinal Richelieu, the power behind the throne. But the muskets themselves are surplus to requirements.&lt;/p&gt;
    &lt;p&gt;"Dumas does relent a little on his musket-phobia by the end of the novel. On page 645, the musketless musketeers fire at their enemies using weapons grabbed from corpses. And finally, on page 705, when Richelieu catches the four friends conspiring on the beach, we are at last granted a glimpse of the soldiers' own guns: '[Athos] montra du doigt au cardinal les quatre mousquets en faisceau près du tambour sur lequel étaient les cartes et les dès' ('He pointed out to the cardinal the four muskets stacked next to the drum on which lay the cards and dice').&lt;/p&gt;
    &lt;p&gt;"As far as I can make out, this is the only point at which we see the musketeers with their muskets in the whole story, and it seems a fitting way to present them to the reader: lying idle while the musketeers are occupied with other, more important amusements."&lt;/p&gt;
    &lt;p&gt;This post originally appeared on the outreach blog of the French sub-faculty at Oxford University.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46214617</guid><pubDate>Wed, 10 Dec 2025 06:08:50 +0000</pubDate></item><item><title>Revisiting "Let's Build a Compiler"</title><link>https://eli.thegreenplace.net/2025/revisiting-lets-build-a-compiler/</link><description>&lt;doc fingerprint="b101145b7036df98"&gt;
  &lt;main&gt;
    &lt;p&gt;There's an old compiler-building tutorial that has become part of the field's lore: the Let's Build a Compiler series by Jack Crenshaw (published between 1988 and 1995).&lt;/p&gt;
    &lt;p&gt;I ran into it in 2003 and was very impressed, but it's now 2025 and this tutorial is still being mentioned quite often in Hacker News threads. Why is that? Why does a tutorial from 35 years ago, built in Pascal and emitting Motorola 68000 assembly - technologies that are virtually unknown for the new generation of programmers - hold sway over compiler enthusiasts? I've decided to find out.&lt;/p&gt;
    &lt;p&gt;The tutorial is easily available and readable online, but just re-reading it seemed insufficient. So I've decided on meticulously translating the compilers built in it to Python and emit a more modern target - WebAssembly. It was an enjoyable process and I want to share the outcome and some insights gained along the way.&lt;/p&gt;
    &lt;p&gt;The result is this code repository. Of particular interest is the TUTORIAL.md file, which describes how each part in the original tutorial is mapped to my code. So if you want to read the original tutorial but play with code you can actually easily try on your own, feel free to follow my path.&lt;/p&gt;
    &lt;head rend="h2"&gt;A sample&lt;/head&gt;
    &lt;p&gt;To get a taste of the input language being compiled and the output my compiler generates, here's a sample program in the KISS language designed by Jack Crenshaw:&lt;/p&gt;
    &lt;code&gt;var X=0

 { sum from 0 to n-1 inclusive, and add to result }
 procedure addseq(n, ref result)
     var i, sum  { 0 initialized }
     while i &amp;lt; n
         sum = sum + i
         i = i + 1
     end
     result = result + sum
 end

 program testprog
 begin
     addseq(11, X)
 end
 .
&lt;/code&gt;
    &lt;p&gt;It's from part 13 of the tutorial, so it showcases procedures along with control constructs like the while loop, and passing parameters both by value and by reference. Here's the WASM text generated by my compiler for part 13:&lt;/p&gt;
    &lt;code&gt;(module
  (memory 8)
  ;; Linear stack pointer. Used to pass parameters by ref.
  ;; Grows downwards (towards lower addresses).
  (global $__sp (mut i32) (i32.const 65536))

  (global $X (mut i32) (i32.const 0))

  (func $ADDSEQ (param $N i32) (param $RESULT i32)
    (local $I i32)
    (local $SUM i32)
    loop $loop1
      block $breakloop1
        local.get $I
        local.get $N
        i32.lt_s
        i32.eqz
        br_if $breakloop1
        local.get $SUM
        local.get $I
        i32.add
        local.set $SUM
        local.get $I
        i32.const 1
        i32.add
        local.set $I
        br $loop1
      end
    end
    local.get $RESULT
    local.get $RESULT
    i32.load
    local.get $SUM
    i32.add
    i32.store
  )

  (func $main (export "main") (result i32)
    i32.const 11
    global.get $__sp      ;; make space on stack
    i32.const 4
    i32.sub
    global.set $__sp
    global.get $__sp
    global.get $X
    i32.store
    global.get $__sp    ;; push address as parameter
    call $ADDSEQ
    ;; restore parameter X by ref
    global.get $__sp
    i32.load offset=0
    global.set $X
    ;; clean up stack for ref parameters
    global.get $__sp
    i32.const 4
    i32.add
    global.set $__sp
    global.get $X
  )
)
&lt;/code&gt;
    &lt;p&gt;You'll notice that there is some trickiness in the emitted code w.r.t. handling the by-reference parameter (my previous post deals with this issue in more detail). In general, though, the emitted code is inefficient - there is close to 0 optimization applied.&lt;/p&gt;
    &lt;p&gt;Also, if you're very diligent you'll notice something odd about the global variable X - it seems to be implicitly returned by the generated main function. This is just a testing facility that makes my compiler easy to test. All the compilers are extensively tested - usually by running the generated WASM code [1] and verifying expected results.&lt;/p&gt;
    &lt;head rend="h2"&gt;Insights - what makes this tutorial so special?&lt;/head&gt;
    &lt;p&gt;While reading the original tutorial again, I had on opportunity to reminisce on what makes it so effective. Other than the very fluent and conversational writing style of Jack Crenshaw, I think it's a combination of two key factors:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The tutorial builds a recursive-descent parser step by step, rather than giving a long preface on automata and table-based parser generators. When I first encountered it (in 2003), it was taken for granted that if you want to write a parser then lex + yacc are the way to go [2]. Following the development of a simple and clean hand-written parser was a revelation that wholly changed my approach to the subject; subsequently, hand-written recursive-descent parsers have been my go-to approach for almost 20 years now.&lt;/item&gt;
      &lt;item&gt;Rather than getting stuck in front-end minutiae, the tutorial goes straight to generating working assembly code, from very early on. This was also a breath of fresh air for engineers who grew up with more traditional courses where you spend 90% of the time on parsing, type checking and other semantic analysis and often run entirely out of steam by the time code generation is taught.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To be honest, I don't think either of these are a big problem with modern resources, but back in the day the tutorial clearly hit the right nerve with many people.&lt;/p&gt;
    &lt;head rend="h2"&gt;What else does it teach us?&lt;/head&gt;
    &lt;p&gt;Jack Crenshaw's tutorial takes the syntax-directed translation approach, where code is emitted while parsing, without having to divide the compiler into explicit phases with IRs. As I said above, this is a fantastic approach for getting started, but in the latter parts of the tutorial it starts showing its limitations. Especially once we get to types, it becomes painfully obvious that it would be very nice if we knew the types of expressions before we generate code for them.&lt;/p&gt;
    &lt;p&gt;I don't know if this is implicated in Jack Crenshaw's abandoning the tutorial at some point after part 14, but it may very well be. He keeps writing how the emitted code is clearly sub-optimal [3] and can be improved, but IMHO it's just not that easy to improve using the syntax-directed translation strategy. With perfect hindsight vision, I would probably use Part 14 (types) as a turning point - emitting some kind of AST from the parser and then doing simple type checking and analysis on that AST prior to generating code from it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;All in all, the original tutorial remains a wonderfully readable introduction to building compilers. This post and the GitHub repository it describes are a modest contribution that aims to improve the experience of folks reading the original tutorial today and not willing to use obsolete technologies. As always, let me know if you run into any issues or have questions!&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;This is done using the Python bindings to wasmtime.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;By the way, gcc switched from YACC to hand-written recursive-descent parsing in the 2004-2006 timeframe, and Clang has been implemented with a recursive-descent parser from the start (2007).&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Concretely: when we compile subexpr1 + subexpr2 and the two sides have different types, it would be mighty nice to know that before we actually generate the code for both sub-expressions. But the syntax-directed translation approach just doesn't work that way.&lt;/p&gt;
          &lt;p&gt;To be clear: it's easy to generate working code; it's just not easy to generate optimal code without some sort of type analysis that's done before code is actually generated.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46214693</guid><pubDate>Wed, 10 Dec 2025 06:22:19 +0000</pubDate></item><item><title>Stop Breaking TLS</title><link>https://www.markround.com/blog/2025/12/09/stop-breaking-tls/</link><description>&lt;doc fingerprint="7cdaa1068d256eb5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop Breaking TLS&lt;/head&gt;
    &lt;p&gt;Updated:&lt;/p&gt;
    &lt;p&gt;Rant ahead: I hate TLS âInspectionâ software with a burning passion and I wish we collectively as an industry would just knock it the fuck off and stop pretending itâs some great security benefit. Every time I encounter it, in whatever form, itâs a gigantic headache that makes everyoneâs life worse off and as far as I am concerned offers next to zero tangible benefits.&lt;/p&gt;
    &lt;p&gt;For those blissfully unaware, this is a class of âsecurityâ software or appliance that is supposed to let organisations monitor all encrypted traffic. It does this by inserting itself in the middle of traffic, stripping the encryption off so it can inspect it and then re-signing it with its own certificate. If that sounds familiar, itâs because itâs a widely known class of attack - the Man In The Middle attack. Great stuff, weâre literally deploying the exact attack vector that TLS was designed to prevent, but slapping a âsecurityâ label on it.&lt;/p&gt;
    &lt;p&gt;Firstly, it undermines one of the most important protocols of the modern Internet as it deliberately breaks all the guarantees that TLS encryption is supposed to offer. If the MITM certificate is installed everywhere, your company can intercept and monitor everything you say and do. Consider the ramifications of that - confidential messages to HR, medical information, insider trading information, your banking sessions - would you feel happy BCCâing every single email to your IT department? Would you print out your therapy notes and pin them to the kitchen notice board?&lt;/p&gt;
    &lt;p&gt;But even ignoring the philosophical arguments about privacy and trust, I argue it actively makes your security worse. Consider this - what is the likelihood of every certificate authority on the Internet having their private keys compromised simultaneously? Iâd wager thatâs almost at the whatever is the statistics equivalent of the Planck length level of probability.&lt;/p&gt;
    &lt;p&gt;On the other hand, whatâs the chance of your companyâs MITM private key getting compromised by an attacker? Even if you completely trust your IT team and vendor (and if you do, you clearly havenât been paying attention to any tech news for ohâ¦ the last few decades), you have to admit that chance is a lot higher. And depending on the vendor or tech stack involved, it could be a LOT higher. One disgruntled employee, one unpatched vulnerability, one phishing email to the right admin and choo-choo, itâs all aboard the FAIL train. Now an attacker could have the keys to your entire kingdom.&lt;/p&gt;
    &lt;p&gt;Then thereâs the practicalities of it. Itâs simply a massive hassle. Different Operating Systems expect certificates in different formats (PEM? DER? PFX? P7B?) installed in different places with different tooling to manage it all. &lt;code&gt;update-ca-certificates&lt;/code&gt; vs &lt;code&gt;update-ca-trust&lt;/code&gt; is just the tip of the iceberg - and thatâs just the OS level. You then have language runtimes (Java keystore anyone?) and the applications themselves that all need to be configured.&lt;/p&gt;
    &lt;p&gt;And the problem is compounded with modern cloud-native apps. In a Kubernetes cluster, as well as having to handle updating the node VM images and container runtimes, youâll have dozens if not hundreds of different base images each of which has their own standards. Alpine uses a different certificate path than Ubuntu. Your Node app expects them somewhere else entirely. The various CRDs or Helm charts you are using may or may not support custom CA bundles, and if they do thereâs no agreed-on standard.&lt;/p&gt;
    &lt;p&gt;Now Iâm not saying that because a problem is hard we should simply give up, but even if the benefits were worth it the simple fact is even with the best tooling and automation, you are guaranteed to miss something. Whether itâs some obscure tool that has a custom keystore and non-standard tooling, a quick âone offâ command in an ephemeral container, some app that uses certificate pinning or an aging switch firmware that doesnât even support custom certificate bundles, something will slip through the cracks. And when it does, guess what happens?&lt;/p&gt;
    &lt;p&gt;Which brings me to my biggest peeve: it normalizes bad security practices. Given that you will never have 100% coverage of your CA certificate installation - particularly amongst your technical teams who will be using a multitude of different tools and platforms - you get developers and sysadmins used to TLS errors. Instead of treating each one as an anomaly and something to be investigated, you get used to just running with &lt;code&gt;--insecure&lt;/code&gt; or &lt;code&gt;curl -k&lt;/code&gt; because you just need to get shit done. Turning off certificate verification becomes a routine troubleshooting step. âOh, itâs probably just the corporate proxy againâ becomes the reflexive response to any TLS error. Youâve just trained your entire technical staff to ignore one of the most important security warnings on the Internet!&lt;/p&gt;
    &lt;p&gt;And donât even get me started on the performance and availability implications. All your traffic now has to be decrypted and re-encrypted by your magic box. Hope you sized that appliance correctly! Hope it doesnât become a single point of failure! Hope it supports all the latest TLS versions and cipher suites!&lt;/p&gt;
    &lt;p&gt;There are a multitude of ways to protect yourself that are not only less invasive but are often more effective because theyâre designed for how modern infrastructure actually works. Anomaly detection, Zero Trust network architecture, EDR, Netflow analysisâ¦ You donât need to create single points of failure, and you can actually work with modern cloud-native infrastructure instead of fighting it. Plus, yâknow, thereâs this AI thing which as it turns out is actually quite useful at analysing metadata and spotting odd behavioral patterns.&lt;/p&gt;
    &lt;p&gt;In my experience: TLS &lt;del&gt;Inspection&lt;/del&gt; MITM is a gigantic administrative burden, it normalizes bad practice, it creates bottlenecks and availability risks, and actively worsens your security posture.&lt;/p&gt;
    &lt;p&gt;Just stop it already.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46214950</guid><pubDate>Wed, 10 Dec 2025 07:06:55 +0000</pubDate></item></channel></rss>