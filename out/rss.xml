<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 01 Dec 2025 13:08:32 +0000</lastBuildDate><item><title>Migrating Dillo from GitHub</title><link>https://dillo-browser.org/news/migration-from-github/</link><description>&lt;doc fingerprint="af008dd98a923a96"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Migrating Dillo from GitHub&lt;/head&gt;Written on 2025-11-30 by Rodrigo Arias Mallo&lt;p&gt;I would like to migrate the Dillo project away from GitHub into a new home which is more friendly to be used with Dillo and solves some of its problems. This page summarizes the current situation with GitHub and why I decided to move away from it into a self-hosted server with multiple mirrors in other forges.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;&lt;p&gt;Before we dive into the details, I would like to briefly mention what happened with the old site. The original Dillo website was at dillo.org, which also had the source code of Dillo in a mercurial repository at hg.dillo.org. But it also included the mail server used to reach the developers, a bug tracker and archives for the mailing list. However, in 2022 the domain was lost and someone else decided to buy it to put a similar site but plaged with AI generated ads. The original developers are no longer active, but luckily I had a copy of the mercurial repository and with some help I was able to recover a lot of material from the original server (some parts are still missing to this day).&lt;/p&gt;&lt;p&gt;I want to avoid this situation as much as possible, so we cannot rely on a single site that can go down and the whole project become lost. Initially, I uploaded the Dillo source and website to git repositories on GitHub, but I no longer think this is a good idea.&lt;/p&gt;&lt;head rend="h2"&gt;The situation with GitHub&lt;/head&gt;&lt;p&gt;GitHub has been useful to store all repositories of the Dillo project, as well as to run the CI workflows for platforms in which I don't have a machine available (like Windows, Mac OS or some BSDs).&lt;/p&gt;&lt;p&gt;However, it has several problems that make it less suitable to develop Dillo anymore. The most annoying problem is that the frontend barely works without JavaScript, so we cannot open issues, pull requests, source code or CI logs in Dillo itself, despite them being mostly plain HTML, which I don't think is acceptable. In the past, it used to gracefully degrade without enforcing JavaScript, but now it doesn't. Additionally, the page is very resource hungry, which I don't think is needed to render mostly static text.&lt;/p&gt;&lt;p&gt;Another big problem is that it is a single point of failure. I don't mean that GitHub is stored in a single machine, but it is controlled by a single entity which can unilateraly ban our repository or account and we would lose the ability to notify in that URL what happened. This can cause data loss if we don't have a local copy of all the data.&lt;/p&gt;&lt;p&gt;On the usability side, the platform has become more and more slow over time, which is affecting the development process. It also requires you to have a fast Internet connection at all times, which is not the case for me sometimes. Additionally, GitHub seems to encourage a "push model" in which you are notified when a new event occurs in your project(s), but I don't want to work with that model. Instead, I prefer it to work as a "pull model", so I only get updates when I specifically look for them. This model would also allow me to easily work offline. Unfortunately, I see that the same push model has been copied to alternative forges.&lt;/p&gt;&lt;p&gt;On the social side, I feel that it doesn't have the right tools to moderate users, specially for projects where the ratio of non-technical users to developers is high. This is specially problematic when active issues with developer notes begin to be filled with comments from users that have never contributed to the project and usually do more harm than good. This situation ends up causing burnout in developers.&lt;/p&gt;&lt;p&gt;Lastly, GitHub seem to follow the current trend of over-focusing on LLMs and generative AI, which are destroying the open web (or what remains of it) among other problems. It has a direct impact on us because sites protect themseves with a JavaScript wall (or worse, browser fingerprinting) to prevent aggresive LLM crawler bots from overloading the site, but they also leave Dillo users out. So I would prefer not to encourage this trend. Despite my intentions, moving Dillo away won't change much their capability to train their model with our code, but at least I won't be actively helping.&lt;/p&gt;&lt;head rend="h2"&gt;Self-hosting Dillo&lt;/head&gt;&lt;p&gt;After researching the available options, it seems that none of the current forges would allow us to have a redundant system that can prevent the forge from becoming a single point of failure and solve the rest of the problems with GitHub. Therefore, I decided to self-host Dillo myself, move all important data to git repositories and keep them synchronized in multiple git mirrors.&lt;/p&gt;&lt;p&gt;I decided to buy the dillo-browser.org domain name and setup a very small VPS. Initially, I was very skeptical that it would be able to survive on today's web, but it seems to be doing an acceptable job at handling it (mostly AI bot traffic masquerading as users). The Dillo website is available here:&lt;/p&gt;&lt;p&gt;I researched which git frontends may suit our needs, and I discovered that most options are very complicated to self-host and require a lot of server resources and JavaScript on the frontend. I ended up testing cgit, which is written in C and it seems to be very lightweight both on RAM and CPU usage. Furthermore, the web frontend doesn't require JS, so I can use it from Dillo (I modified cgit CSS slightly to work well on Dillo). It is available on this URL:&lt;/p&gt;&lt;p&gt;https://git.dillo-browser.org/&lt;/p&gt;&lt;p&gt;Regarding the bug tracker, I also took a look at the available options. They are all too complicated for what I would like to have and they seem to centralize the data into a database that can get lost. This is precisely the case that happened with the old dillo bug tracker and we are still unable to recover the original bug entries.&lt;/p&gt;&lt;p&gt;To avoid this problem, I created my own bug tracker software, buggy, which is a very simple C tool that parses plain Markdown files and creates a single HTML page for each bug. All bugs are stored in a git repository and a git hook regenerates the bug pages and the index on each new commit. As it is simply plain text, I can edit the bugs locally and only push them to the remote when I have Internet back, so it works nice offline. Also, as the output is just an static HTML site, I don't need to worry about having any vulnerabilities in my code, as it will only run at build time. You can see it live here, with the exported issues from GitHub:&lt;/p&gt;&lt;p&gt;https://bug.dillo-browser.org/&lt;/p&gt;&lt;p&gt;The mailing list archives are stored by three independent external services, but I might include a copy with our own archives in the future.&lt;/p&gt;&lt;head rend="h2"&gt;Setting up mirrors&lt;/head&gt;&lt;p&gt;As all the important data is now stored in git repositories, we can mirror them in any forge, without having to rely on their custom storage format for the issues or other data. If a forge goes down (or goes rogue) we can simply switch to another site with low switching cost. To this end, I have created git mirrors in Codeberg and Sourcehut that are synced with our git server:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Codeberg: https://codeberg.org/dillo/&lt;/item&gt;&lt;item&gt;Sourcehut: https://git.sr.ht/~dillo/&lt;/item&gt;&lt;/list&gt;&lt;p&gt;However, we still have a single point of failure: the DNS entry of the dillo-browser.org domain. If we lose the DNS entry (like with dillo.org) it would cause a problem as all services will be unreachable. We could recover from such situation by relying on alternative ways to reach users, by the mailing list, fediverse or IRC, as well as updating the mirrors to reflect the current situation. It is not ideal, but I don't think it would cause a catastrophic data loss (like it happened before) as all the data is now stored in git and replicated across independent locations.&lt;/p&gt;&lt;head rend="h2"&gt;OpenPGP signature&lt;/head&gt;&lt;p&gt;In order for this page to have some authority, the HTML file is signed with my GPG key (32E65EC501A1B6FDF8190D293EE6BA977EB2A253), which is the same that I use to sign the last releases of Dillo and is also listed in my GitHub user. The signature is available here and is linked to the page with the &lt;code&gt;&amp;lt;link&amp;gt;&lt;/code&gt; tag using the &lt;code&gt;rel=signature&lt;/code&gt;
relation. You can find more information and how to verify the signature in the
Dillo RFC-006.

&lt;/p&gt;&lt;p&gt;Using OpenPGP signatures is robust against losing the DNS entry, as the authority is not given by the TLS certificate chain but by the trust in the OpenPGP signature, so we could move the site elsewhere and still claim that is owned by us. Additionally, as we can store the signatures inside all git mirrors, they are also resilient against data loss.&lt;/p&gt;&lt;head rend="h2"&gt;Closing remarks&lt;/head&gt;&lt;p&gt;Keep in mind that the migration process requires several moving parts and it will take a while for it to stabilize (switching costs). The GitHub repositories won't be removed at any point in time and they will continue to be updated until we finish the migration. When the migration process is completed, I will mark the Dillo repositories as archived and properly comunicate it in our site. It is important that we don't remove any commit or tarball release to avoid breaking downstream builds that still rely on the GitHub URL.&lt;/p&gt;&lt;p&gt;Lastly, I'm glad that we can have our own fully independent and self-hosted site with relatively low expenses and very little energy cost (which is good for the environment, but probably not even noticeable at large scale). With the current DNS and server costs and our current donations I consider that it is likely that we can continue covering the expenses for at least the next 3 years in the worst case scenario. If you are interested in keeping us afloat, you can help via Liberapay.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46096800</guid><pubDate>Sun, 30 Nov 2025 14:11:40 +0000</pubDate></item><item><title>GitHub to Codeberg: my experience</title><link>https://eldred.fr/blog/forge-migration/</link><description>&lt;doc fingerprint="9a9c101d0be75ac8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GitHub ‚Üí Codeberg: my experience&lt;/head&gt;
    &lt;p&gt;Published . Estimated reading time: 11 minutes.&lt;/p&gt;
    &lt;p&gt;In which I talk about the process involved in switching forges, and how well that went.&lt;/p&gt;
    &lt;p&gt;Spoiler alert: this very site that you‚Äôre reading this on is not served from GitHub Pages anymore! At this point, I‚Äôd call my migration successful. But it took more than clicking a single button, so let‚Äôs talk about the steps involved, at least for me. I‚Äôm hoping that it can help be an example for other people, and show that it‚Äôs actually not that complicated.&lt;/p&gt;
    &lt;head rend="h2"&gt;(My) migration process&lt;/head&gt;
    &lt;p&gt;First, I took an hour or so to set up my profile picture, email address(es), SSH keys‚Ä¶&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 1: migrating the repos&lt;/head&gt;
    &lt;p&gt;This wasn‚Äôt difficult, because Forgejo (the forge software that powers Codeberg) offers a ‚Äúmigrate from GitHub‚Äù functionality. You need to generate a PAT on GitHub to import things like issues (which is awesome!), and as a bonus it also speeds up the process.&lt;/p&gt;
    &lt;p&gt;It was, however, tedious, because the process was entirely manual (perhaps there‚Äôs a way to automate it, like by using some Forgejo CLI tool, but I didn‚Äôt bother looking into that). And, due to GitHub API rate limits, whenever I tried importing two repos at the same time, one or both would fail. (It wasn‚Äôt too bad, though, since I could fill out the migration page for the next while one was in progress; and generally, it took me roughly as long to fill it out as it took Codeberg to perform the import.)&lt;/p&gt;
    &lt;p&gt;I‚Äôm really happy that issues, PRs, wikis, and releases can be imported flawlessly: this makes it possible to not have to refer to GitHub anymore!&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 2: repointing links to Codeberg&lt;/head&gt;
    &lt;p&gt;Of course I don‚Äôt control all links that point to my stuff, but I could at least run &lt;code&gt;rg -F github.com/ISSOtm&lt;/code&gt; in my home directory, to catch those within my own repos. It‚Äôs possible to automate the replacing process:&lt;/p&gt;
    &lt;p&gt;‚Ä¶and if you‚Äôre feeling like bulk-replacing all files in a directory:&lt;/p&gt;
    &lt;p&gt;Repositories, however, may still be pointing to GitHub:&lt;/p&gt;
    &lt;code&gt; 
 )
 )
&lt;/code&gt;
    &lt;p&gt;You can either manually &lt;code&gt;git remote set-url origin git@codeberg.org:ISSOtm/rsgbds.git&lt;/code&gt; (or the equivalent if you‚Äôre using HTTPS), or use one of the replace commands above, since remote URLs are stored textually:&lt;/p&gt;
    &lt;code&gt;# Within a single repo:

# For all repos within the current directory: (requires `shopt -s globstar` if using Bash)
&lt;/code&gt;
    &lt;p&gt;‚Ä¶then it‚Äôs a matter of pushing the changes to all of the repos.&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 3: stubbing out the GitHub repos&lt;/head&gt;
    &lt;p&gt;I also wanted to make it clear that my repos were now living on Codeberg; so, I created a little script in an empty directory:&lt;/p&gt;
    &lt;code&gt;#!/bin/bash
 

 
 
 
 
 
 
 
&lt;/code&gt;
    &lt;p&gt;Then, to run it:&lt;/p&gt;
    &lt;code&gt; 
 
 
 
 
# ...etc.
&lt;/code&gt;
    &lt;p&gt;The automation made it not painful, so this went pretty well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 4: porting CI&lt;/head&gt;
    &lt;p&gt;Now, onto the harder stuff :)&lt;/p&gt;
    &lt;p&gt;The first interesting thing that I noticed is this section of Codeberg‚Äôs CI documentation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Running CI/CD pipelines can use significant amounts of energy. As much as it is tempting to have green checkmarks everywhere, running the jobs costs real money and has environmental costs.&lt;/p&gt;
      &lt;p&gt;Unlike other giant platforms, we do not encourage you to write ‚Äúheavy‚Äù pipelines and charge you for the cost later. We expect you to carefully consider the costs and benefits from your pipelines and reduce CI/CD usage to a minimum amount necessary to guarantee consistent quality for your projects.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That got me to think about which projects of mine really need CI, and ultimately, I decided that I would only need CI for publishing my website, and the documentation of gb-starter-kit and fortISSimO; the rest of my projects don‚Äôt get contributions anyway, so I can live without CI on them, at least for now.&lt;/p&gt;
    &lt;p&gt;Anyway, Codeberg actually has two different CI solutions: Woodpecker, and Forgejo Actions; the former seems to be more powerful, but you need to apply for access, and the latter is very close to GitHub Actions, which should facilitate the migration. So I picked Forgejo Actions, even though it‚Äôs marked as being in beta.&lt;/p&gt;
    &lt;p&gt;It‚Äôs not very difficult to port a YAML file from GHA to Forgejo Actions; for example, look at the commit porting gb-starter-kit‚Äôs publishing CI. (This doesn‚Äôt really appear as a diff, since I‚Äôve moved the file; but it‚Äôs small, so it‚Äôs easy to compare manually.)&lt;/p&gt;
    &lt;p&gt;Here are some salient points:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Actions are normally just referred to as &lt;code&gt;owner/repo&lt;/code&gt;, but Forgejo supports cloning any Git repo, especially across forges. It‚Äôs actually recommended to use full URLs always, so you don‚Äôt rely on the default prefix, which is configurable by the instance admin and thus not necessarily portable.&lt;/item&gt;
      &lt;item&gt;I could have kept the files in &lt;code&gt;.github/workflows&lt;/code&gt;, since Forgejo picks up that directory automatically if&lt;code&gt;.forgejo/workflows&lt;/code&gt;doesn‚Äôt exist; however, I think it‚Äôs more convenient to keep un-migrated scripts in&lt;code&gt;.github&lt;/code&gt;and migrated ones in&lt;code&gt;.forgejo&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Most Actions (the individual steps, not the workflow files) actually work out of the box on Forgejo Actions. Nice!&lt;/item&gt;
      &lt;item&gt;Codeberg‚Äôs runners differ from GitHub‚Äôs significantly: they have way less software installed by default, fewer resources, and only Linux runners are provided (Ubuntu by default, but you can use any Docker container image). macOS and Windows being non-free OSes, Codeberg has no plans to offer either of those! For both philosophical and financial reasons. If this is a deal-breaker for you, consider cross-compiling, or bringing your own runner.&lt;/item&gt;
      &lt;item&gt;Unless low latency is crucial, consider using the lazy runners for better load balancing and possibly greener energy consumption. In practice I haven‚Äôt seen delays beyond a few minutes, which is acceptable to me.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I actually spent some extra time trying to use less compute to perform my CI jobs, somewhat motivated by the small size of the runners, and because I‚Äôm guessing that the smaller the runner you‚Äôre picking, the faster your job will be able to be scheduled. Here is one such commit; note in particular line 50, where I tried1 using a Docker image with LaTeX preinstalled, which saves the time taken by &lt;code&gt;apt install&lt;/code&gt; and requires fewer writes to the filesystem, freeing up RAM.&lt;/p&gt;
    &lt;p&gt;Unfortunately, due to a version discrepancy with &lt;code&gt;noweb&lt;/code&gt;, I had to revert to the base Ubuntu image; but a ‚Äúregular‚Äù LaTeX workflow would have had no problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Step 5: re-hosting my website&lt;/head&gt;
    &lt;p&gt;All of the previous steps were done within the span of a few days; however, since my website (this very website) was hosted using GitHub Pages, I couldn‚Äôt migrate its repos (yes, plural: you can configure individual repos to be published separately, which is how e.g. https://eldred.fr/fortISSimO is published, despite not being in the website‚Äôs main repo).&lt;/p&gt;
    &lt;p&gt;Nominally, Codeberg has an equivalent, Codeberg Pages; however, as mentioned on that page, &lt;quote&gt;the software behind this feature is currently in maintenance mode&lt;/quote&gt;, because of complexity and performance issues2. So I left it at that for roughly a month, hoping there‚Äôll eventually be an update. Also, subprojects are published as subdomains instead of subdirectories, which would have broken links (e.g. &lt;code&gt;http://eldred.fr/fortISSimO&lt;/code&gt; would have become &lt;code&gt;http://fortISSimO.eldred.fr&lt;/code&gt;). Meh‚Ä¶&lt;/p&gt;
    &lt;p&gt;And then (by chance lol) I discovered git-pages and its public instance Grebedoc3! It functions much like GitHub Pages, though with a bit more setup since it‚Äôs not integrated within the forge itself.&lt;/p&gt;
    &lt;p&gt;git-pages actually has several niceties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;My website had zero downtime during the entire migration, as git-pages supports uploading your website before updating your DNS records!&lt;/item&gt;
      &lt;item&gt;It also supports server-side redirects, which lets me redirect people who still go to http://eldred.fr/gb-asm-tutorial/* to its new home, for example. People have been getting 404s because of incomplete client-side coverage on my side, but no more!&lt;/item&gt;
      &lt;item&gt;It also also supports custom headers; I‚Äôm not particularly interested in CORS, but I‚Äôve used that file to pay my respects4.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Oh, and also, Codeberg‚Äôs November 2025 newsletter mentions that &lt;quote&gt;Codeberg is planning to gradually migrate to [git-pages]&lt;/quote&gt;. Exciting!&lt;/p&gt;
    &lt;p&gt;I‚Äôm actually much happier using this than GitHub Pages; so, I‚Äôve joined Catherine‚Äôs Patreon, because I want to see this go far.&lt;/p&gt;
    &lt;p&gt;To quote Catherine‚Äôs motivation for creating git-pages: &lt;quote&gt;I started out wanting to just use Codeberg Pages and then I found out that Codeberg Pages is in maintenance mode and has such poor architecture that not only does it have rather low uptime but it also regularly crashes Codeberg‚Äôs Forgejo instance itself.&lt;/quote&gt;&lt;/p&gt;
    &lt;p&gt;ü¶É. It is intensely looking at you‚Ä¶‚Ä¶.&lt;/p&gt;
    &lt;p&gt;Here is some context as to what this means.&lt;/p&gt;
    &lt;head rend="h3"&gt;Time tracking&lt;/head&gt;
    &lt;p&gt;Steps 1 through 3 (migrating the repos) took me the better part of an afternoon; step 4 (porting CI) took me another afternoon, mostly to learn the new CI system; and step 5 (the website) took me‚Ä¶ well, it should have taken an afternoon, but I used the opportunity to also pay down some tech debt (merging my slides repo into my main website), which took a few days due to required rearchitecting.&lt;/p&gt;
    &lt;p&gt;All in all, even with 45 repos migrated, this basically took a weekend. And I didn‚Äôt find it annoying!&lt;/p&gt;
    &lt;p&gt;Since the task seemed really daunting, my anxiety caused me to procrastinate this a lot, but in the end it was little work. One of the reasons I‚Äôm writing this is to let other people know that, so they can overcome their own anxiety. Maybe. :P&lt;/p&gt;
    &lt;head rend="h2"&gt;What now?&lt;/head&gt;
    &lt;p&gt;All in all, I‚Äôm very happy with this migration! As far as I can tell, nothing on this website has broken, and I‚Äôve tried reasonably containing the breakage over on GitHub: I have truncated the &lt;code&gt;master&lt;/code&gt; branches, but all other branches and tags remain in place (mostly due to laziness lol), permalinks (e.g. &lt;code&gt;https://github.com/ISSOtm/gb-bootroms/blob/c8ed9e106e0ab1193a57071820e46358006c79d0/src/dmg.asm&lt;/code&gt;) still work, only non-perma links (e.g. &lt;code&gt;https://github.com/ISSOtm/gb-bootroms/blob/master/src/dmg.asm&lt;/code&gt;) are broken, but those are unreliable in the first place anyway.&lt;/p&gt;
    &lt;p&gt;Since that means that all of my code is still on GitHub, I want to delete my repos; but that would be a bad idea at this point, due to leaving no redirects or anything. I‚Äôll consider that again in‚Ä¶ idk, a year or something. I would also like to delete my GitHub account (like I have deleted my Twitter account when‚Ä¶ *gestures vaguely*), but not only do I need my repos to be up, I also need my account to contribute to projects that are still on GitHub.&lt;/p&gt;
    &lt;p&gt;One downside of this migration is that since I‚Äôm moving off of The Main Forge, my projects are likely to get fewer contributions‚Ä¶ But I wasn‚Äôt getting many in the first place, and some people have already made accounts on Codeberg to keep contributing to my stuff. Likewise, I‚Äôm not really worried about discoverability. We‚Äôll see I guess lol ü§∑‚ôÇÔ∏è&lt;/p&gt;
    &lt;p&gt;Lastly, I‚Äôm writing this after the migration, and I haven‚Äôt really taken notes during it; so, if I‚Äôve forgotten any steps, feel free to let me know in the comments below or by opening an issue, and I‚Äôll edit this article.&lt;/p&gt;
    &lt;p&gt;Cheers!&lt;/p&gt;
    &lt;head rend="h2"&gt;Special thanks&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Catherine ‚Äòwhitequark‚Äô for her work on git-pages and for being part of the ops team for Grebedoc&lt;/item&gt;
      &lt;item&gt;SERVFAIL network (domi, Merlin, famfo, aprl, and all of #servfail) for being my awesome DNS providers&lt;/item&gt;
      &lt;item&gt;Codeberg team and Forgejo contributors for making all of this possible in the first place&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46097829</guid><pubDate>Sun, 30 Nov 2025 16:12:13 +0000</pubDate></item><item><title>ETH-Zurich: Digital Design and Computer Architecture; 227-0003-10L, Spring, 2025</title><link>https://safari.ethz.ch/ddca/spring2025/doku.php?id=start</link><description>&lt;doc fingerprint="5c71730e58600a24"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Table of Contents&lt;/head&gt;
    &lt;head rend="h1"&gt;Digital Design and Computer Architecture&lt;/head&gt;
    &lt;head rend="h1"&gt;Spring 2025 (227-0003-10L)&lt;/head&gt;
    &lt;p&gt;Welcome to the wiki for Digital Design and Computer Architecture for Spring 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Announcements&lt;/head&gt;
    &lt;head rend="h2"&gt;Course Information&lt;/head&gt;
    &lt;head rend="h3"&gt;Description&lt;/head&gt;
    &lt;p&gt;The class provides a first introduction to the design of digital circuits and computer architecture. It covers technical foundations of how a computing platform is designed from the bottom up. It introduces various execution paradigms, hardware description languages, and principles in digital design and computer architecture. The focus is on fundamental techniques employed in the design of modern microprocessors and their hardware/software interface.&lt;/p&gt;
    &lt;head rend="h3"&gt;Objectives&lt;/head&gt;
    &lt;p&gt;This class provides a first approach to Computer Architecture. The students learn the design of digital circuits in order to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;understand the basics,&lt;/item&gt;
      &lt;item&gt;understand the principles (of design),&lt;/item&gt;
      &lt;item&gt;understand the precedents (in computer architecture).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Based on such understanding, the students are expected to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;learn how a modern computer works underneath, from the bottom up,&lt;/item&gt;
      &lt;item&gt;evaluate tradeoffs of different designs and ideas,&lt;/item&gt;
      &lt;item&gt;implement a principled design (a simple microprocessor),&lt;/item&gt;
      &lt;item&gt;learn to systematically debug increasingly complex systems,&lt;/item&gt;
      &lt;item&gt;hopefully be prepared to develop novel, out-of-the-box designs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The focus is on basics, principles, precedents, and how to use them to create/implement good designs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lectures&lt;/head&gt;
    &lt;p&gt; Thursday, 14:15-16:00, in HG F7 (Overflow room: HG F5) &lt;lb/&gt; Friday, 14:15-16:00, in HG F7 (Overflow room: HG F5) &lt;/p&gt;
    &lt;p&gt;Watch the lectures in YouTube livestream:&lt;/p&gt;
    &lt;head rend="h3"&gt;Lab sessions&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;When?&lt;/cell&gt;
        &lt;cell role="head"&gt;Where?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Tuesday, 16:15-18:00&lt;/cell&gt;
        &lt;cell&gt;labs in HG E19, HG E26.1, HG E26.3, HG E27&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Wednesday, 16:15-18:00&lt;/cell&gt;
        &lt;cell&gt;labs in HG E19, HG E26.1, HG E26.3, HG E27&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Friday, 08:15-10:00&lt;/cell&gt;
        &lt;cell&gt;labs in HG D11, HG D12, HG E26.3, HG E27&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Friday, 10:15-12:00&lt;/cell&gt;
        &lt;cell&gt;labs in HG E19, HG E26.1, HG E26.3, HG E27&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Prerequisites: None.&lt;/p&gt;
    &lt;head rend="h2"&gt;Staff Information&lt;/head&gt;
    &lt;head rend="h3"&gt;Contact&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mailing List: digitaltechnik@lists.inf.ethz.ch (sent to instructor and TAs)&lt;/item&gt;
      &lt;item&gt;Office Hours: TBD&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Office&lt;/cell&gt;
        &lt;cell role="head"&gt;Phone&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Instructor&lt;/cell&gt;
        &lt;cell&gt;Onur Mutlu&lt;/cell&gt;
        &lt;cell&gt;onur.mutlu@safari.ethz.ch&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Instructor&lt;/cell&gt;
        &lt;cell&gt;Mohammad Sadrosadati&lt;/cell&gt;
        &lt;cell&gt;mohammad.sadrosadati@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ F76&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Head Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Ataberk Olgun&lt;/cell&gt;
        &lt;cell&gt;ataberk.olgun@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Giray Yaglikci&lt;/cell&gt;
        &lt;cell&gt;giray.yaglikci@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Can Firtina&lt;/cell&gt;
        &lt;cell&gt;can.firtina@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Geraldo De Oliveira Junior&lt;/cell&gt;
        &lt;cell&gt;geraldod@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ 61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Rahul Bera&lt;/cell&gt;
        &lt;cell&gt;rahbera@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H64&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Konstantinos Kanellopoulos&lt;/cell&gt;
        &lt;cell&gt;kanellok@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Nika Mansouri Ghiasi&lt;/cell&gt;
        &lt;cell&gt;mnika@ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ 61.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Nisa Bostancƒ±&lt;/cell&gt;
        &lt;cell&gt;nisa.bostanci@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ 61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Rakesh Nadig&lt;/cell&gt;
        &lt;cell&gt;rakesh.nadig@safari.ethz.ch&lt;/cell&gt;
        &lt;cell&gt;ETZ H64&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;ƒ∞smail Emir Y√ºksel&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Teaching Assistant&lt;/cell&gt;
        &lt;cell&gt;Haocong Luo&lt;/cell&gt;
        &lt;cell&gt;ETZ H61.2&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46098747</guid><pubDate>Sun, 30 Nov 2025 17:45:51 +0000</pubDate></item><item><title>Writing a good Claude.md</title><link>https://www.humanlayer.dev/blog/writing-a-good-claude-md</link><description>&lt;doc fingerprint="474c0a5f0dbfd7fe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;# Writing a good CLAUDE.md&lt;/head&gt;
    &lt;p&gt;Kyle Mistele ¬∑ November 25, 2025 ¬∑ &amp;lt; 10 min read&lt;/p&gt;
    &lt;p&gt;Note: this post is also applicable to &lt;code&gt;AGENTS.md&lt;/code&gt;, the open-source equivalent of &lt;code&gt;CLAUDE.md&lt;/code&gt; for agents and harnesses like OpenCode, Zed, Cursor and Codex.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Principle: LLMs are (mostly) stateless&lt;/head&gt;
    &lt;p&gt;LLMs are stateless functions. Their weights are frozen by the time they're used for inference, so they don't learn over time. The only thing that the model knows about your codebase is the tokens you put into it.&lt;/p&gt;
    &lt;p&gt;Similarly, coding agent harnesses such as Claude Code usually require you to manage agents' memory explicitly. &lt;code&gt;CLAUDE.md&lt;/code&gt; (or &lt;code&gt;AGENTS.md&lt;/code&gt;) is the only file that by default goes into every single conversation you have with the agent.&lt;/p&gt;
    &lt;p&gt;This has three important implications:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Coding agents know absolutely nothing about your codebase at the beginning of each session.&lt;/item&gt;
      &lt;item&gt;The agent must be told anything that's important to know about your codebase each time you start a session.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt;is the preferred way of doing this.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;## &lt;code&gt;CLAUDE.md&lt;/code&gt; onboards Claude to your codebase&lt;/head&gt;
    &lt;p&gt;Since Claude doesn't know anything about your codebase at the beginning of each session, you should use &lt;code&gt;CLAUDE.md&lt;/code&gt; to onboard Claude into your codebase. At a high level, this means it should cover:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WHAT: tell Claude about the tech, your stack, the project structure. Give Claude a map of the codebase. This is especially important in monorepos! Tell Claude what the apps are, what the shared packages are, and what everything is for so that it knows where to look for things&lt;/item&gt;
      &lt;item&gt;WHY: tell Claude the purpose of the project and what everything is doing in the repository. What are the purpose and function of the different parts of the project?&lt;/item&gt;
      &lt;item&gt;HOW: tell Claude how it should work on the project. For example, do you use &lt;code&gt;bun&lt;/code&gt;instead of&lt;code&gt;node&lt;/code&gt;? You want to include all the information it needs to actually do meaningful work on the project. How can Claude verify Claude's changes? How can it run tests, typechecks, and compilation steps?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But the way you do this is important! Don't try to stuff every command Claude could possibly need to run in your &lt;code&gt;CLAUDE.md&lt;/code&gt; file - you will get sub-optimal results.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Claude often ignores &lt;code&gt;CLAUDE.md&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Regardless of which model you're using, you may notice that Claude frequently ignores your &lt;code&gt;CLAUDE.md&lt;/code&gt; file's contents.&lt;/p&gt;
    &lt;p&gt;You can investigate this yourself by putting a logging proxy between the claude code CLI and the Anthropic API using &lt;code&gt;ANTHROPIC_BASE_URL&lt;/code&gt;. Claude code injects the following system reminder with your &lt;code&gt;CLAUDE.md&lt;/code&gt; file in the user message to the agent:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;&amp;lt;system-reminder&amp;gt; IMPORTANT: this context may or may not be relevant to your tasks. You should not respond to this context unless it is highly relevant to your task. &amp;lt;/system-reminder&amp;gt;&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;As a result, Claude will ignore the contents of your &lt;code&gt;CLAUDE.md&lt;/code&gt; if it decides that it is not relevant to its current task. The more information you have in the file that's not universally applicable to the tasks you have it working on, the more likely it is that Claude will ignore your instructions in the file.&lt;/p&gt;
    &lt;p&gt;Why did Anthropic add this? It's hard to say for sure, but we can speculate a bit. Most &lt;code&gt;CLAUDE.md&lt;/code&gt; files we come across include a bunch of instructions in the file that aren't broadly applicable. Many users treat the file as a way to add "hotfixes" to behavior they didn't like by appending lots of instructions that weren't necessarily broadly applicable.&lt;/p&gt;
    &lt;p&gt;We can only assume that the Claude Code team found that by telling Claude to ignore the bad instructions, the harness actually produced better results.&lt;/p&gt;
    &lt;head rend="h2"&gt;## Creating a good &lt;code&gt;CLAUDE.md&lt;/code&gt; file&lt;/head&gt;
    &lt;p&gt;The following section provides a number of recommendations on how to write a good &lt;code&gt;CLAUDE.md&lt;/code&gt; file following context engineering best practices.&lt;/p&gt;
    &lt;p&gt;Your mileage may vary. Not all of these rules are necessarily optimal for every setup. Like anything else, feel free to break the rules once...&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;you understand when &amp;amp; why it's okay to break them&lt;/item&gt;
      &lt;item&gt;you have a good reason to do so&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;### Less (instructions) is more&lt;/head&gt;
    &lt;p&gt;It can be tempting to try and stuff every single command that claude could possibly need to run, as well as your code standards and style guidelines into &lt;code&gt;CLAUDE.md&lt;/code&gt;. We recommend against this.&lt;/p&gt;
    &lt;p&gt;Though the topic hasn't been investigated in an incredibly rigorous manner, some research has been done which indicates the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Frontier thinking LLMs can follow ~ 150-200 instructions with reasonable consistency. Smaller models can attend to fewer instructions than larger models, and non-thinking models can attend to fewer instructions than thinking models.&lt;/item&gt;
      &lt;item&gt;Smaller models get MUCH worse, MUCH more quickly. Specifically, smaller models tend to exhibit an expotential decay in instruction-following performance as the number of instructions increase, whereas larger frontier thinking models exhibit a linear decay (see below). For this reason, we recommend against using smaller models for multi-step tasks or complicated implementation plans.&lt;/item&gt;
      &lt;item&gt;LLMs bias towards instructions that are on the peripheries of the prompt: at the very beginning (the Claude Code system message and &lt;code&gt;CLAUDE.md&lt;/code&gt;), and at the very end (the most-recent user messages)&lt;/item&gt;
      &lt;item&gt;As instruction count increases, instruction-following quality decreases uniformly. This means that as you give the LLM more instructions, it doesn't simply ignore the newer ("further down in the file") instructions - it begins to ignore all of them uniformly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our analysis of the Claude Code harness indicates that Claude Code's system prompt contains ~50 individual instructions. Depending on the model you're using, that's nearly a third of the instructions your agent can reliably follow already - and that's before rules, plugins, skills, or user messages.&lt;/p&gt;
    &lt;p&gt;This implies that your &lt;code&gt;CLAUDE.md&lt;/code&gt; file should contain as few instructions as possible - ideally only ones which are universally applicable to your task.&lt;/p&gt;
    &lt;head rend="h3"&gt;### &lt;code&gt;CLAUDE.md&lt;/code&gt; file length &amp;amp; applicability&lt;/head&gt;
    &lt;p&gt;All else being equal, an LLM will perform better on a task when its' context window is full of focused, relevant context including examples, related files, tool calls, and tool results compared to when its context window has a lot of irrelevant context.&lt;/p&gt;
    &lt;p&gt;Since &lt;code&gt;CLAUDE.md&lt;/code&gt; goes into every single session, you should ensure that its contents are as universally applicable as possible.&lt;/p&gt;
    &lt;p&gt;For example, avoid including instructions about (for example) how to structure a new database schema - this won't matter and will distract the model when you're working on something else that's unrelated!&lt;/p&gt;
    &lt;p&gt;Length-wise, the less is more principle applies as well. While Anthropic does not have an official recommendation on how long your &lt;code&gt;CLAUDE.md&lt;/code&gt; file should be, general consensus is that &amp;lt; 300 lines is best, and shorter is even better.&lt;/p&gt;
    &lt;p&gt;At HumanLayer, our root &lt;code&gt;CLAUDE.md&lt;/code&gt; file is less than sixty lines.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Progressive Disclosure&lt;/head&gt;
    &lt;p&gt;Writing a concise &lt;code&gt;CLAUDE.md&lt;/code&gt; file that covers everything you want Claude to know can be challenging, especially in larger projects.&lt;/p&gt;
    &lt;p&gt;To address this, we can leverage the principle of Progressive Disclosure to ensure that claude only sees task- or project-specific instructions when it needs them.&lt;/p&gt;
    &lt;p&gt;Instead of including all your different instructions about building your project, running tests, code conventions, or other important context in your &lt;code&gt;CLAUDE.md&lt;/code&gt; file, we recommend keeping task-specific instructions in separate markdown files with self-descriptive names somewhere in your project.&lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;agent_docs/ |- building_the_project.md |- running_tests.md |- code_conventions.md |- service_architecture.md |- database_schema.md |- service_communication_patterns.md&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Then, in your &lt;code&gt;CLAUDE.md&lt;/code&gt; file, you can include a list of these files with a brief description of each, and instruct Claude to decide which (if any) are relevant and to read them before it starts working. Or, ask Claude to present you with the files it wants to read for aproval first before reading them.&lt;/p&gt;
    &lt;p&gt;Prefer pointers to copies. Don't include code snippets in these files if possible - they will become out-of-date quickly. Instead, include &lt;code&gt;file:line&lt;/code&gt; references to point Claude to the authoritative context.&lt;/p&gt;
    &lt;p&gt;Conceptually, this is very similar to how Claude Skills are intended to work, although skills are more focused on tool use than instructions.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Claude is (not) an expensive linter&lt;/head&gt;
    &lt;p&gt;One of the most common things that we see people put in their &lt;code&gt;CLAUDE.md&lt;/code&gt; file is code style guidelines. Never send an LLM to do a linter's job. LLMs are comparably expensive and incredibly slow compared to traditional linters and formatters. We think you should always use deterministic tools whenever you can.&lt;/p&gt;
    &lt;p&gt;Code style guidelines will inevitably add a bunch of instructions and mostly-irrelevant code snippets into your context window, degrading your LLM's performance and instruction-following and eating up your context window.&lt;/p&gt;
    &lt;p&gt;LLMs are in-context learners! If your code follows a certain set of style guidelines or patterns, you should find that armed with a few searches of your codebase (or a good research document!) your agent should tend to follow existing code patterns and conventions without being told to.&lt;/p&gt;
    &lt;p&gt;If you feel very stronly about this, you might even consider setting up a Claude Code &lt;code&gt;Stop&lt;/code&gt; hook that runs your formatter &amp;amp; linter and presents errors to Claude for it to fix. Don't make Claude find the formatting issues itself.&lt;/p&gt;
    &lt;p&gt;Bonus points: use a linter that can automatically fix issues (we like Biome), and carefully tune your rules about what can safely be auto-fixed for maximum (safe) coverage.&lt;/p&gt;
    &lt;p&gt;You could also create a Slash Command that includes your code guidelines and which points claude at the changes in version control, or at your &lt;code&gt;git status&lt;/code&gt;, or similar. This way, you can handle implementation and formatting separately. You will see better results with both as a result.&lt;/p&gt;
    &lt;head rend="h3"&gt;### Don't use &lt;code&gt;/init&lt;/code&gt; or auto-generate your &lt;code&gt;CLAUDE.md&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;Both Claude Code and other harnesses with OpenCode come with ways to auto-generate your &lt;code&gt;CLAUDE.md&lt;/code&gt; file (or &lt;code&gt;AGENTS.md&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Because &lt;code&gt;CLAUDE.md&lt;/code&gt; goes into every single session with Claude code, it is one of the highest leverage points of the harness - for better or for worse, depending on how you use it.&lt;/p&gt;
    &lt;p&gt;A bad line of code is a bad line of code. A bad line of an implementation plan has the potential to create a lot of bad lines of code. A bad line of a research that misunderstands how the system works has the potential to result in a lot of bad lines in the plan, and therefore a lot more bad lines of code as a result.&lt;/p&gt;
    &lt;p&gt;But the &lt;code&gt;CLAUDE.md&lt;/code&gt; file affects every single phase of your workflow and every single artifact produced by it. As a result, we think you should spend some time thinking very carefully about every single line that goes into it:&lt;/p&gt;
    &lt;head rend="h2"&gt;## In Conclusion&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt;is for onboarding Claude into your codebase. It should define your project's WHY, WHAT, and HOW.&lt;/item&gt;
      &lt;item&gt;Less (instructions) is more. While you shouldn't omit necessary instructions, you should include as few instructions as reasonably possible in the file.&lt;/item&gt;
      &lt;item&gt;Keep the contents of your &lt;code&gt;CLAUDE.md&lt;/code&gt;concise and universally applicable.&lt;/item&gt;
      &lt;item&gt;Use Progressive Disclosure - don't tell Claude all the information you could possibly want it to know. Rather, tell it how to find important information so that it can find and use it, but only when it needs to to avoid bloating your context window or instruction count.&lt;/item&gt;
      &lt;item&gt;Claude is not a linter. Use linters and code formatters, and use other features like Hooks and Slash Commands as necessary.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt;is the highest leverage point of the harness, so avoid auto-generating it. You should carefully craft its contents for best results.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46098838</guid><pubDate>Sun, 30 Nov 2025 17:56:43 +0000</pubDate></item><item><title>Program-of-Thought Prompting Outperforms Chain-of-Thought by 15% (2022)</title><link>https://arxiv.org/abs/2211.12588</link><description>&lt;doc fingerprint="e8bcc40accf7908a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 22 Nov 2022 (v1), last revised 23 Oct 2023 (this version, v4)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks&lt;/head&gt;View PDF&lt;quote&gt;Abstract:Recently, there has been significant progress in teaching language models to perform step-by-step reasoning to solve complex numerical reasoning tasks. Chain-of-thoughts prompting (CoT) is by far the state-of-art method for these tasks. CoT uses language models to perform both reasoning and computation in the multi-step `thought' process. To disentangle computation from reasoning, we propose `Program of Thoughts' (PoT), which uses language models (mainly Codex) to express the reasoning process as a program. The computation is relegated to an external computer, which executes the generated programs to derive the answer. We evaluate PoT on five math word problem datasets (GSM, AQuA, SVAMP, TabMWP, MultiArith) and three financial-QA datasets (FinQA, ConvFinQA, TATQA) for both few-shot and zero-shot setups. Under both few-shot and zero-shot settings, PoT can show an average performance gain over CoT by around 12\% across all the evaluated datasets. By combining PoT with self-consistency decoding, we can achieve SoTA performance on all math problem datasets and near-SoTA performance on financial datasets. All of our data and code are released in Github this https URL&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Wenhu Chen [view email]&lt;p&gt;[v1] Tue, 22 Nov 2022 21:06:00 UTC (8,689 KB)&lt;/p&gt;&lt;p&gt;[v2] Fri, 25 Nov 2022 01:49:50 UTC (8,689 KB)&lt;/p&gt;&lt;p&gt;[v3] Tue, 29 Nov 2022 03:46:29 UTC (8,689 KB)&lt;/p&gt;&lt;p&gt;[v4] Mon, 23 Oct 2023 01:27:38 UTC (4,047 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46099108</guid><pubDate>Sun, 30 Nov 2025 18:34:52 +0000</pubDate></item><item><title>A Love Letter to FreeBSD</title><link>https://www.tara.sh/posts/2025/2025-11-25_freebsd_letter/</link><description>&lt;doc fingerprint="378a913fe1694f6e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Love Letter to FreeBSD&lt;/head&gt;
    &lt;p&gt;Dear FreeBSD,&lt;/p&gt;
    &lt;p&gt;I‚Äôm still the new person here, learning your ways, stumbling over the occasional quirk, smiling when I find the small touches that make you different. You remind me of what computing felt like before the noise. Before hype cycles and performance theatre. Before every tool needed a plugin system and a logo. You are coherent. You are deliberate. You are the kind of system that doesn‚Äôt have to shout to belong.&lt;/p&gt;
    &lt;p&gt;You carry the quiet strength of the greats, like a mainframe humming in a locked room, not chasing attention, just doing its work, year after year. Your base system feels like it was built by people who cared about the whole picture, not just the pieces. Your boot environments are like an old IBM i‚Äôs ‚Äúside A / side B‚Äù IPL, a built-in escape hatch that says, we‚Äôve thought ahead for you. You could be, you should be, the open-source mainframe: aligned with hardware lifecycles of three to five years or more, built for long-term trust, a platform people bet their uptime on. Your core design reminds me of Solaris in its best days: a stable base that commercial and community software could rely on without fear of shifting foundations.&lt;/p&gt;
    &lt;p&gt;And make uptime a design goal: a thousand-day uptime shouldn‚Äôt be folklore, it should be normal. Not a party trick, not a screenshot to boast about, but simply the natural consequence of a system built to endure. Mainframes never apologised for uptime measured in years, and neither should you. Apply updates without fear, reboot only when the kernel truly demands it, and let administrators see longevity as a feature, not a gamble.&lt;/p&gt;
    &lt;p&gt;I know you are reaching further into the desktop now. I understand why, and I can see how it might widen your reach. But here I find myself wondering: how do you keep the heartbeat of a rock-solid server while also embracing the quicker pulse of a modern desktop? I don‚Äôt pretend to have all the answers, I‚Äôm too new to you for that, but my first instinct is to lean on what you already have: the natural separation between CURRENT and RELEASE. Let those worlds move at their own pace, without asking one to carry the other‚Äôs compromises.&lt;/p&gt;
    &lt;p&gt;And now, with pkgbase in play, the stability of packages matters as much as the base system itself. The base must remain untouchable in its reliability, but I dream of a world where the package ecosystem is available in clear stability channels: from a rock-solid ‚Äúproduction tier‚Äù you can stake a business on, to faster-moving streams where new features can flow without fear of breaking mission-critical systems. Too many times in the past, packages vanished or broke unexpectedly. I understand the core is sacred, but I wouldn‚Äôt mind if some of the wider ecosystem inherited that same level of care.&lt;/p&gt;
    &lt;p&gt;Culture matters too. One reason I stepped away from Linux was the noise, the debates that drowned out the joy of building. Please keep FreeBSD the kind of place where thoughtful engineering is welcome without ego battles, where enterprise focus and technical curiosity can sit at the same table. That spirit, the calm, shared purpose that carried Unix from the PDP-11 labs to the backbone of the Internet, is worth protecting.&lt;/p&gt;
    &lt;p&gt;There‚Äôs also the practical side: keep the doors open with hardware vendors like Dell and HPE, so FreeBSD remains a first-class citizen. Give me the tools to flash firmware without having to borrow Linux or Windows. Make hardware lifecycle alignment part of your story, major releases paced with the real world, point releases treated as refinement rather than disruption.&lt;/p&gt;
    &lt;p&gt;My hope is simple: that you stay different. Not in the way that shouts for attention, but in the way that earns trust. If someone wants hype or the latest shiny thing every month, they have Linux. If they want a platform that feels like it could simply run, and keep running, the way the best of Unix always did, they should know they can find it here. And I still dream of a future where a purpose-built ‚Äúopen-source mainframe‚Äù exists: a modern, reliable hardware system running FreeBSD with the same quiet presence as Sun‚Äôs Enterprise 10k once did.&lt;/p&gt;
    &lt;p&gt;And maybe, one day, someone will walk past a rack of servers, hear the steady, unhurried rhythm of a FreeBSD system still running, and smile, knowing that in a world that burns through trends, there is still something built to last.&lt;/p&gt;
    &lt;p&gt;With gratitude,&lt;lb/&gt; and with the wish to stay for the long run,&lt;lb/&gt; A newcomer who finally feels at home.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46100892</guid><pubDate>Sun, 30 Nov 2025 22:05:07 +0000</pubDate></item><item><title>Algorithms for Optimization [pdf]</title><link>https://algorithmsbook.com/optimization/files/optimization.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46101492</guid><pubDate>Sun, 30 Nov 2025 23:21:32 +0000</pubDate></item><item><title>Ly ‚Äì A lightweight TUI (ncurses-like) display manager for Linux and BSD</title><link>https://codeberg.org/fairyglade/ly</link><description>&lt;doc fingerprint="688ed55b0b05e3a1"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="3"/&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;.github&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;res&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;src&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;.gitignore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;build.zig&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;build.zig.zon&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;license.md&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;readme.md&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h1"&gt;The Ly display manager&lt;/head&gt;
    &lt;p&gt;Ly is a lightweight TUI (ncurses-like) display manager for Linux and BSD, designed with portability in mind (e.g. it does not require systemd to run).&lt;/p&gt;
    &lt;p&gt;Join us on Matrix over at #ly:envs.net!&lt;/p&gt;
    &lt;p&gt;Note: Development happens on Codeberg with a mirror on GitHub.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dependencies&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compile-time: &lt;list rend="ul"&gt;&lt;item&gt;zig 0.15.x&lt;/item&gt;&lt;item&gt;libc&lt;/item&gt;&lt;item&gt;pam&lt;/item&gt;&lt;item&gt;xcb (optional, required by default; needed for X11 support)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Runtime (with default config): &lt;list rend="ul"&gt;&lt;item&gt;xorg&lt;/item&gt;&lt;item&gt;xorg-xauth&lt;/item&gt;&lt;item&gt;shutdown&lt;/item&gt;&lt;item&gt;brightnessctl&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Debian&lt;/head&gt;
    &lt;code&gt;# apt install build-essential libpam0g-dev libxcb-xkb-dev xauth xserver-xorg brightnessctl
&lt;/code&gt;
    &lt;head rend="h3"&gt;Fedora&lt;/head&gt;
    &lt;p&gt;Warning: You may encounter issues with SELinux on Fedora. It is recommended to add a rule for Ly as it currently does not ship one.&lt;/p&gt;
    &lt;code&gt;# dnf install kernel-devel pam-devel libxcb-devel zig xorg-x11-xauth xorg-x11-server brightnessctl
&lt;/code&gt;
    &lt;head rend="h3"&gt;FreeBSD&lt;/head&gt;
    &lt;code&gt;# pkg install ca_root_nss libxcb git xorg xauth
&lt;/code&gt;
    &lt;head rend="h2"&gt;Availability&lt;/head&gt;
    &lt;head rend="h2"&gt;Support&lt;/head&gt;
    &lt;p&gt;Ly has been tested with a wide variety of desktop environments and window managers, all of which you can find in the sections below:&lt;/p&gt;
    &lt;p&gt;Logs are defined by &lt;code&gt;/etc/ly/config.ini&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The session log is located at &lt;code&gt;~/.local/state/ly-session.log&lt;/code&gt;by default.&lt;/item&gt;
      &lt;item&gt;The system log is located at &lt;code&gt;/var/log/ly.log&lt;/code&gt;by default.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Manually building&lt;/head&gt;
    &lt;p&gt;The procedure for manually building Ly is pretty standard:&lt;/p&gt;
    &lt;code&gt;$ git clone https://codeberg.org/fairyglade/ly.git
$ cd ly
$ zig build
&lt;/code&gt;
    &lt;p&gt;After building, you can (optionally) test Ly in a terminal emulator, although authentication will not work:&lt;/p&gt;
    &lt;code&gt;$ zig build run
&lt;/code&gt;
    &lt;p&gt;Important: While you can also run Ly in a terminal emulator as root, it is not recommended either. If you want to properly test Ly, please enable its service (as described below) and reboot your machine.&lt;/p&gt;
    &lt;p&gt;The following sections show how to install Ly for a particular init system. Because the procedure is very similar for all of them, the commands will only be detailed for the first section (which is about systemd).&lt;/p&gt;
    &lt;p&gt;Note: All following sections will assume you are using LightDM for convenience sake.&lt;/p&gt;
    &lt;head rend="h3"&gt;systemd&lt;/head&gt;
    &lt;p&gt;Now, you can install Ly on your system:&lt;/p&gt;
    &lt;code&gt;# zig build installexe -Dinit_system=systemd
&lt;/code&gt;
    &lt;p&gt;Note: The &lt;code&gt;init_system&lt;/code&gt; parameter is optional and defaults to &lt;code&gt;systemd&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Note that you also need to disable your current display manager. For example, if LightDM is the current display manager, you can execute the following command:&lt;/p&gt;
    &lt;code&gt;# systemctl disable lightdm.service
&lt;/code&gt;
    &lt;p&gt;Then, similarly to the previous command, you need to enable the Ly service:&lt;/p&gt;
    &lt;code&gt;# systemctl enable ly.service
&lt;/code&gt;
    &lt;p&gt;Important: Because Ly runs in a TTY, you must disable the TTY service that Ly will run on, otherwise bad things will happen. For example, to disable &lt;code&gt;getty&lt;/code&gt; spawning on TTY 2 (the default TTY on which Ly spawns), you need to
execute the following command:&lt;/p&gt;
    &lt;code&gt;# systemctl disable getty@tty2.service
&lt;/code&gt;
    &lt;p&gt;You can change the TTY Ly will run on by editing the corresponding service file for your platform.&lt;/p&gt;
    &lt;head rend="h3"&gt;OpenRC&lt;/head&gt;
    &lt;code&gt;# zig build installexe -Dinit_system=openrc
# rc-update del lightdm
# rc-update add ly
# rc-update del agetty.tty2
&lt;/code&gt;
    &lt;p&gt;Note: On Gentoo specifically, you also must comment out the appropriate line for the TTY in /etc/inittab.&lt;/p&gt;
    &lt;head rend="h3"&gt;runit&lt;/head&gt;
    &lt;code&gt;# zig build installexe -Dinit_system=runit
# rm /var/service/lightdm
# ln -s /etc/sv/ly /var/service/
# rm /var/service/agetty-tty2
&lt;/code&gt;
    &lt;head rend="h3"&gt;s6&lt;/head&gt;
    &lt;code&gt;# zig build installexe -Dinit_system=s6
# s6-rc -d change lightdm
# s6-service add default ly-srv
# s6-db-reload
# s6-rc -u change ly-srv
&lt;/code&gt;
    &lt;p&gt;To disable TTY 2, edit &lt;code&gt;/etc/s6/config/tty2.conf&lt;/code&gt; and set &lt;code&gt;SPAWN="no"&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;dinit&lt;/head&gt;
    &lt;code&gt;# zig build installexe -Dinit_system=dinit
# dinitctl disable lightdm
# dinitctl enable ly
&lt;/code&gt;
    &lt;p&gt;To disable TTY 2, go to &lt;code&gt;/etc/dinit.d/config/console.conf&lt;/code&gt; and modify
&lt;code&gt;ACTIVE_CONSOLES&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;sysvinit&lt;/head&gt;
    &lt;code&gt;# zig build installexe -Dinit_system=sysvinit
# update-rc.d lightdm disable
# update-rc.d ly defaults
&lt;/code&gt;
    &lt;p&gt;To disable TTY 2, go to &lt;code&gt;/etc/inittab&lt;/code&gt; and comment out the line containing &lt;code&gt;tty2&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;FreeBSD&lt;/head&gt;
    &lt;code&gt;# zig build installexe -Dprefix_directory=/usr/local -Dconfig_directory=/usr/local/etc -Dinit_system=freebsd
# sysrc lightdm_enable="NO"
&lt;/code&gt;
    &lt;p&gt;To enable Ly, add the following entry to &lt;code&gt;/etc/gettytab&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;Ly:\
	:lo=/usr/local/bin/ly_wrapper:\
	:al=root:
&lt;/code&gt;
    &lt;p&gt;Then, modify the command field of the &lt;code&gt;ttyv1&lt;/code&gt; terminal entry in &lt;code&gt;/etc/ttys&lt;/code&gt;
(TTYs in FreeBSD start at 0):&lt;/p&gt;
    &lt;code&gt;ttyv1 "/usr/libexec/getty Ly" xterm on secure
&lt;/code&gt;
    &lt;head rend="h3"&gt;Updating&lt;/head&gt;
    &lt;p&gt;You can also install Ly without overrding the current configuration file. This is called updating. To update, simply run:&lt;/p&gt;
    &lt;code&gt;# zig build installnoconf
&lt;/code&gt;
    &lt;p&gt;You can, of course, still select the init system of your choice when using this command.&lt;/p&gt;
    &lt;head rend="h2"&gt;Configuration&lt;/head&gt;
    &lt;p&gt;You can find all the configuration in &lt;code&gt;/etc/ly/config.ini&lt;/code&gt;. The file is fully
commented, and includes the default values.&lt;/p&gt;
    &lt;head rend="h2"&gt;Controls&lt;/head&gt;
    &lt;p&gt;Use the Up/Down arrow keys to change the current field, and the Left/Right arrow keys to scroll through the different fields (whether it be the info line, the desktop environment, or the username). The info line is where messages and errors are displayed.&lt;/p&gt;
    &lt;head rend="h2"&gt;A note on .xinitrc&lt;/head&gt;
    &lt;p&gt;If your &lt;code&gt;.xinitrc&lt;/code&gt; file doesn't work ,make sure it is executable and includes a
shebang. This file is supposed to be a shell script! Quoting from &lt;code&gt;xinit&lt;/code&gt;'s man
page:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If no specific client program is given on the command line, xinit will look for a file in the user's home directory called .xinitrc to run as a shell script to start up client programs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A typical shebang for a shell script looks like this:&lt;/p&gt;
    &lt;code&gt;#!/bin/sh
&lt;/code&gt;
    &lt;head rend="h2"&gt;Tips&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The numlock and capslock state is printed in the top-right corner.&lt;/item&gt;
      &lt;item&gt;Use the F1 and F2 keys to respectively shutdown and reboot.&lt;/item&gt;
      &lt;item&gt;Take a look at your &lt;code&gt;.xsession&lt;/code&gt;file if X doesn't start, as it can interfere (this file is launched with X to configure the display properly).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Supported Wayland environments&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;budgie&lt;/item&gt;
      &lt;item&gt;cosmic&lt;/item&gt;
      &lt;item&gt;deepin&lt;/item&gt;
      &lt;item&gt;enlightenment&lt;/item&gt;
      &lt;item&gt;gnome&lt;/item&gt;
      &lt;item&gt;hyprland&lt;/item&gt;
      &lt;item&gt;kde&lt;/item&gt;
      &lt;item&gt;labwc&lt;/item&gt;
      &lt;item&gt;niri&lt;/item&gt;
      &lt;item&gt;pantheon&lt;/item&gt;
      &lt;item&gt;sway&lt;/item&gt;
      &lt;item&gt;weston&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Supported X11 environments&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;awesome&lt;/item&gt;
      &lt;item&gt;bspwm&lt;/item&gt;
      &lt;item&gt;budgie&lt;/item&gt;
      &lt;item&gt;cinnamon&lt;/item&gt;
      &lt;item&gt;dwm&lt;/item&gt;
      &lt;item&gt;enlightenment&lt;/item&gt;
      &lt;item&gt;gnome&lt;/item&gt;
      &lt;item&gt;kde&lt;/item&gt;
      &lt;item&gt;leftwm&lt;/item&gt;
      &lt;item&gt;lxde&lt;/item&gt;
      &lt;item&gt;mate&lt;/item&gt;
      &lt;item&gt;maxx&lt;/item&gt;
      &lt;item&gt;pantheon&lt;/item&gt;
      &lt;item&gt;qwm&lt;/item&gt;
      &lt;item&gt;spectrwm&lt;/item&gt;
      &lt;item&gt;windowmaker&lt;/item&gt;
      &lt;item&gt;xfce&lt;/item&gt;
      &lt;item&gt;xmonad&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;A final note&lt;/head&gt;
    &lt;p&gt;The name "Ly" is a tribute to the fairy from the game Rayman. Ly was tested by oxodao, who is some seriously awesome dude.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46101996</guid><pubDate>Mon, 01 Dec 2025 00:28:04 +0000</pubDate></item><item><title>Advent of Sysadmin 2025</title><link>https://sadservers.com/advent</link><description>&lt;doc fingerprint="d370ffcfa78f27d3"&gt;
  &lt;main&gt;
    &lt;p&gt;The Advent of Sysadmin is a 12-day Advent calendar of Linux and DevOps challenges of different difficulties that runs from December 1st to December 12th.&lt;/p&gt;
    &lt;p&gt;Each day there will be an Advent of Sysadmin scenario.&lt;/p&gt;
    &lt;p&gt;Sign up for a free account (needed to keep track of your progress) and start solving the scenarios!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Day&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Level&lt;/cell&gt;
        &lt;cell role="head"&gt;Time Limit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;2025-12-01&lt;/cell&gt;
        &lt;cell&gt;"Auderghem": containers miscommunication&lt;/cell&gt;
        &lt;cell&gt;Easy&lt;/cell&gt;
        &lt;cell&gt;15 mins&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46102347</guid><pubDate>Mon, 01 Dec 2025 01:17:28 +0000</pubDate></item><item><title>X210Ai is a new motherboard to upgrade ThinkPad X201/200</title><link>https://www.tpart.net/about-x210ai/</link><description>&lt;doc fingerprint="ee8d8858f8eff1e4"&gt;
  &lt;main&gt;
    &lt;p&gt;X210Ai is a new motherboard to upgrade Thinkpad X201/200, The details as below:&lt;/p&gt;
    &lt;p&gt;1, CPU: Ultra 7 165H, Ultra 9 185H;&lt;/p&gt;
    &lt;p&gt;2, Storage support: Two of M.2 SSD PCIE 4.0 (one 2280, one 2242), the original 2.5inch SATA;&lt;/p&gt;
    &lt;p&gt;3, Memory: DDR5 5600MHz max to 128G (64G +64G);&lt;/p&gt;
    &lt;p&gt;4, Two type-c: one is support thunderbolt 4.0, other one is full function type-c;&lt;/p&gt;
    &lt;p&gt;5, Support Output HDMI 2.1;&lt;/p&gt;
    &lt;p&gt;6, Display: support screens same as X2100, such as the original X201/200‚Äôs display, 13inch 3000√ó2000, 13.3inch 1920√ó1200 and 13.3 inch 2560√ó1600;&lt;/p&gt;
    &lt;p&gt;7, WWAN 4/5G;&lt;/p&gt;
    &lt;p&gt;8, The postion of SATA can install the 2rd fan;&lt;/p&gt;
    &lt;p&gt;9, A new daughterboard;&lt;/p&gt;
    &lt;p&gt;10, The X210Ai project currently cannot guarantee coreboot support, but we remain committed to exploring possible solutions.&lt;/p&gt;
    &lt;p&gt;X210Ai time line please click here&lt;/p&gt;
    &lt;p&gt;X210Ai related file &amp;amp; software download&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46103097</guid><pubDate>Mon, 01 Dec 2025 03:12:29 +0000</pubDate></item><item><title>Search tool that only returns content created before ChatGPT's public release</title><link>https://tegabrain.com/Slop-Evader</link><description>&lt;doc fingerprint="d94012a3200d538b"&gt;
  &lt;main&gt;
    &lt;p&gt;A browser extension for avoiding AI slop. Download it for Chrome or Firefox.&lt;/p&gt;
    &lt;p&gt;This is a search tool that will only return content created before ChatGPT's first public release on November 30, 2022.&lt;/p&gt;
    &lt;p&gt;Since the public release of ChatGTPT and other large language models, the internet is being increasingly polluted by AI generated text, images and video. This browser extension uses the Google search API to only return content published before Nov 30th, 2022 so you can be sure that it was written or produced by the human hand.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46103376</guid><pubDate>Mon, 01 Dec 2025 04:06:06 +0000</pubDate></item><item><title>Google Antigravity just deleted the contents of whole drive</title><link>https://old.reddit.com/r/google_antigravity/comments/1p82or6/google_antigravity_just_deleted_the_contents_of/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46103532</guid><pubDate>Mon, 01 Dec 2025 04:39:28 +0000</pubDate></item><item><title>SmartTube Compromised</title><link>https://www.aftvnews.com/smarttubes-official-apk-was-compromised-with-malware-what-you-should-do-if-you-use-it/</link><description>&lt;doc fingerprint="ad2c930509fb3ed1"&gt;
  &lt;main&gt;
    &lt;p&gt;Earlier this week, the developer of SmartTube, the most popular alternative YouTube app for Android TV and Fire TV devices, announced that his app‚Äôs digital signature had been exposed. A new version of the app using a new digital signature has since been released. While everyone is encouraged to switch to the new app, SmartTube‚Äôs developer has shared more information with me about what happened that may make you want to take additional precautions if you‚Äôve installed or updated the app recently.&lt;/p&gt;
    &lt;p&gt;SmartTube‚Äôs developer told me that the computer used to create the APKs for the project‚Äôs official GitHub page was compromised by malware. As a result, some official SmartTube releases were unintentionally released with malware. It‚Äôs unclear which version was first affected, but the compromise seems to have first occurred earlier this month. SmartTube versions 30.43 and 30.47 from APKMirror are both being flagged as infected by malware scanners.&lt;/p&gt;
    &lt;p&gt;It is likely the presence of this malware that caused Google and Amazon to forcibly uninstall SmartTube on some devices, not the exposed digital signature as first suspected. SmartTube‚Äôs developer says the compromised machine has been wiped and is confident that both the new SmartTube releases and the machine that created them are malware-free.&lt;/p&gt;
    &lt;p&gt;All older versions of SmartTube have been removed from the project‚Äôs GitHub in an abundance of caution. While there does not appear to be any evidence that the app‚Äôs digital signature was actually stolen or used by malicious actors, that too has been abandoned and replaced with a new one.&lt;/p&gt;
    &lt;p&gt;SmartTube version 30.56 is the first release built by the uncompromised machine and with the new digital signature. It can be installed using my Downloader app by entering code &lt;/p&gt;
    &lt;p&gt;It remains unknown what the malware that found its way into the official SmartTube APK files can actually do. Thankfully, SmartTube is programmed to only request minimal account permissions and does not ask for any login information directly. Even if you granted the app access to your Google Drive for backup purposes, your Google account and general Google Drive files remain out of the app‚Äôs scope of permissions. Permissions regarding control of your YouTube account seem like the only thing that could have easily been exposed to the malware, as far as account access is concerned.&lt;/p&gt;
    &lt;p&gt;That said, since very little is know about the malware, you should assume the worst. If you use SmartTube and are concerned about your exposure to this malware, you should factory reset any device that had the app installed, especially if you installed or updated the app in November. It would also be a good idea to audit your Google account permissions and your YouTube account activity for anything unusual. Once your devices and account are in order, if you wish to reinstall SmartTube, be sure to only install the latest version through the codes/links above.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46103657</guid><pubDate>Mon, 01 Dec 2025 05:01:01 +0000</pubDate></item><item><title>Games using anti-cheats and their compatibility with GNU/Linux or Wine/Proton</title><link>https://areweanticheatyet.com/</link><description>&lt;doc fingerprint="d422fc810f425674"&gt;
  &lt;main&gt;
    &lt;p&gt;Light theme&lt;/p&gt;
    &lt;p&gt;A comprehensive and crowd-sourced list of games using anti-cheats and their compatibility with GNU/Linux or Wine/Proton.- Starz0r&lt;/p&gt;
    &lt;p&gt;1136&lt;/p&gt;
    &lt;p&gt;194 Supported (17%)&lt;/p&gt;
    &lt;p&gt;258 Running (23%)&lt;/p&gt;
    &lt;p&gt;2 Planned (0%)&lt;/p&gt;
    &lt;p&gt;635 Broken (56%)&lt;/p&gt;
    &lt;p&gt;47 Denied (4%)&lt;/p&gt;
    &lt;p&gt;Search&lt;/p&gt;
    &lt;p&gt;Sort By&lt;/p&gt;
    &lt;p&gt;Sort Order&lt;/p&gt;
    &lt;p&gt;Halo: The Master Chief Collection&lt;/p&gt;
    &lt;p&gt;Supported&lt;/p&gt;
    &lt;p&gt;Denied&lt;/p&gt;
    &lt;p&gt;Battlefield‚Ñ¢ 2042&lt;/p&gt;
    &lt;p&gt;Paladins&lt;/p&gt;
    &lt;p&gt;Running&lt;/p&gt;
    &lt;p&gt;Make sure to check recent updates, the game is known to break often (And the status may not update to reflect that)&lt;/p&gt;
    &lt;p&gt;Broken&lt;/p&gt;
    &lt;p&gt;Black Desert Online&lt;/p&gt;
    &lt;p&gt;Requires Proton GE or Proton Experimental&lt;/p&gt;
    &lt;p&gt;Epic Games Store is broken on Linux. Steam Recommended.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46104396</guid><pubDate>Mon, 01 Dec 2025 07:05:57 +0000</pubDate></item><item><title>DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning</title><link>https://huggingface.co/deepseek-ai/DeepSeek-Math-V2</link><description>&lt;doc fingerprint="cd4a93503ddb8ad8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning&lt;/head&gt;
    &lt;head rend="h2"&gt;1. Introduction&lt;/head&gt;
    &lt;p&gt;Large language models have made significant progress in mathematical reasoning, which serves as an important testbed for AI and could impact scientific research if further advanced. By scaling reasoning with reinforcement learning that rewards correct final answers, LLMs have improved from poor performance to saturating quantitative reasoning competitions like AIME and HMMT in one year. However, this approach faces fundamental limitations. Pursuing higher final answer accuracy doesn't address a key issue: correct answers don't guarantee correct reasoning. Moreover, many mathematical tasks like theorem proving require rigorous step-by-step derivation rather than numerical answers, making final answer rewards inapplicable. To push the limits of deep reasoning, we believe it is necessary to verify the comprehensiveness and rigor of mathematical reasoning. Self-verification is particularly important for scaling test-time compute, especially for open problems without known solutions. Towards self-verifiable mathematical reasoning, we investigate how to train an accurate and faithful LLM-based verifier for theorem proving. We then train a proof generator using the verifier as the reward model, and incentivize the generator to identify and resolve as many issues as possible in their own proofs before finalizing them. To maintain the generation-verification gap as the generator becomes stronger, we propose to scale verification compute to automatically label new hard-to-verify proofs, creating training data to further improve the verifier. Our resulting model, DeepSeekMath-V2, demonstrates strong theorem-proving capabilities, achieving gold-level scores on IMO 2025 and CMO 2024 and a near-perfect 118/120 on Putnam 2024 with scaled test-time compute. While much work remains, these results suggest that self-verifiable mathematical reasoning is a feasible research direction that may help develop more capable mathematical AI systems.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Evaluation Results&lt;/head&gt;
    &lt;p&gt;Below are evaluation results on IMO-ProofBench (developed by the DeepMind team behind DeepThink IMO-Gold) and recent mathematics competitions including IMO 2025, CMO 2024, and Putnam 2024.&lt;/p&gt;
    &lt;p&gt;IMO-ProofBench&lt;/p&gt;
    &lt;p&gt;Mathematics Competitions&lt;/p&gt;
    &lt;head rend="h2"&gt;4. Quick Start&lt;/head&gt;
    &lt;p&gt;DeepSeekMath-V2 is built on top of DeepSeek-V3.2-Exp-Base. For inference support, please refer to the DeepSeek-V3.2-Exp github repository.&lt;/p&gt;
    &lt;head rend="h2"&gt;6. License&lt;/head&gt;
    &lt;p&gt;This repository and the model weights are licensed under the Apache License, Version 2.0 (Apache 2.0).&lt;/p&gt;
    &lt;head rend="h2"&gt;7. Citation&lt;/head&gt;
    &lt;code&gt;@misc{deepseek-math-v2,
  author = {Zhihong Shao, Yuxiang Luo, Chengda Lu, Z.Z. Ren, Jiewen Hu, Tian Ye, Zhibin Gou, Shirong Ma, Xiaokang Zhang},
  title = {DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning},
  year = {2025},
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;8. Contact&lt;/head&gt;
    &lt;p&gt;If you have any questions, please raise an issue or contact us at service@deepseek.com.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Downloads last month&lt;/item&gt;
      &lt;item rend="dd-1"&gt;4,434&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Model tree for deepseek-ai/DeepSeek-Math-V2&lt;/head&gt;
    &lt;p&gt;Unable to build the model tree, the base model loops to the model itself. Learn more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46105079</guid><pubDate>Mon, 01 Dec 2025 08:54:31 +0000</pubDate></item><item><title>AWS data centers' water use tied to spike in cancer and miscarriages in Oregon</title><link>https://techoreon.com/oregon-data-centers-water-use-nitrates-cancer-miscarriage/</link><description>&lt;doc fingerprint="b4ed91cf02f791e0"&gt;
  &lt;main&gt;
    &lt;p&gt;Accenture has reportedly begun calling its 800,000 employees ‚Äúreinventors‚Äù, as the consultancy tries to position itself as a leader in artificial intelligence.&lt;/p&gt;
    &lt;p&gt;The consultancy‚Äôs chief executive, Julie Sweet, has already started referring to staff by the new label and the business is now pushing for the term to be used more widely, the Financial Times reported, citing people at the company.&lt;/p&gt;
    &lt;p&gt;The ‚Äúreinventor‚Äù label came from a reorganisation across Accenture in June, which merged its strategy, consulting, creative, technology and operations divisions into a single unit called ‚ÄúReinvention Services‚Äù.&lt;/p&gt;
    &lt;p&gt;The new tag for the consultants is the latest in a long list of unusual jargon that big businesses have foisted on their staff; some tech workers are referred to as ‚Äúninjas‚Äù, ‚Äúgrowth hackers‚Äù and ‚Äúevangelists‚Äù.&lt;/p&gt;
    &lt;p&gt;Curious job titles are also popular in the media and entertainment industries, including at Walt Disney, where technical experts who design and build its theme parks are referred to as ‚Äúimagineers‚Äù.&lt;/p&gt;
    &lt;p&gt;The ‚Äúreinventor‚Äù push from Accenture comes as it moves to sharpen its focus on its AI capabilities. Sweet told investors in September that the consultancy would ‚Äúexit‚Äù employees who were not getting the hang of using AI at work.&lt;/p&gt;
    &lt;p&gt;The New-York based group said it was training staff in generative AI fundamentals, but employees for whom ‚Äúreskilling, based on our experience, is not a viable path for the skills we need‚Äù would be shown the door.&lt;/p&gt;
    &lt;p&gt;The consultancy has also reportedly built a version of its internal human resources website where the staff are called ‚Äúreinventors‚Äù rather than ‚Äúworkers‚Äù, the FT reported, citing a person familiar with the matter.&lt;/p&gt;
    &lt;p&gt;Accenture, which was spun out of Arthur Andersen, the now-defunct accountant, in 1989, works with thousands of companies around the world, offering IT and business strategy consulting and outsourcing.&lt;/p&gt;
    &lt;p&gt;The company benefited from huge demand for tech consulting in the aftermath of the pandemic, but its shares, which are listed in New York, have suffered this year after Donald Trump ordered US government agencies to review their spending with large consultancies.&lt;/p&gt;
    &lt;p&gt;The consultancy reported a 7% annual rise in revenue to $69.7bn (¬£52.7bn) for its financial year ended in August, but warned investors that US federal spending cuts will probably slow its growth next year. It has lost more than a quarter of its market value so far this year, which stands at $155bn.&lt;/p&gt;
    &lt;p&gt;Accenture was approached for comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46105803</guid><pubDate>Mon, 01 Dec 2025 10:37:39 +0000</pubDate></item><item><title>Accenture dubs 800k staff 'reinventors' amid shift to AI</title><link>https://www.theguardian.com/business/2025/dec/01/accenture-rebrands-staff-reinventors-ai-artificial-intelligence</link><description>&lt;doc fingerprint="b4ed91cf02f791e0"&gt;
  &lt;main&gt;
    &lt;p&gt;Accenture has reportedly begun calling its 800,000 employees ‚Äúreinventors‚Äù, as the consultancy tries to position itself as a leader in artificial intelligence.&lt;/p&gt;
    &lt;p&gt;The consultancy‚Äôs chief executive, Julie Sweet, has already started referring to staff by the new label and the business is now pushing for the term to be used more widely, the Financial Times reported, citing people at the company.&lt;/p&gt;
    &lt;p&gt;The ‚Äúreinventor‚Äù label came from a reorganisation across Accenture in June, which merged its strategy, consulting, creative, technology and operations divisions into a single unit called ‚ÄúReinvention Services‚Äù.&lt;/p&gt;
    &lt;p&gt;The new tag for the consultants is the latest in a long list of unusual jargon that big businesses have foisted on their staff; some tech workers are referred to as ‚Äúninjas‚Äù, ‚Äúgrowth hackers‚Äù and ‚Äúevangelists‚Äù.&lt;/p&gt;
    &lt;p&gt;Curious job titles are also popular in the media and entertainment industries, including at Walt Disney, where technical experts who design and build its theme parks are referred to as ‚Äúimagineers‚Äù.&lt;/p&gt;
    &lt;p&gt;The ‚Äúreinventor‚Äù push from Accenture comes as it moves to sharpen its focus on its AI capabilities. Sweet told investors in September that the consultancy would ‚Äúexit‚Äù employees who were not getting the hang of using AI at work.&lt;/p&gt;
    &lt;p&gt;The New-York based group said it was training staff in generative AI fundamentals, but employees for whom ‚Äúreskilling, based on our experience, is not a viable path for the skills we need‚Äù would be shown the door.&lt;/p&gt;
    &lt;p&gt;The consultancy has also reportedly built a version of its internal human resources website where the staff are called ‚Äúreinventors‚Äù rather than ‚Äúworkers‚Äù, the FT reported, citing a person familiar with the matter.&lt;/p&gt;
    &lt;p&gt;Accenture, which was spun out of Arthur Andersen, the now-defunct accountant, in 1989, works with thousands of companies around the world, offering IT and business strategy consulting and outsourcing.&lt;/p&gt;
    &lt;p&gt;The company benefited from huge demand for tech consulting in the aftermath of the pandemic, but its shares, which are listed in New York, have suffered this year after Donald Trump ordered US government agencies to review their spending with large consultancies.&lt;/p&gt;
    &lt;p&gt;The consultancy reported a 7% annual rise in revenue to $69.7bn (¬£52.7bn) for its financial year ended in August, but warned investors that US federal spending cuts will probably slow its growth next year. It has lost more than a quarter of its market value so far this year, which stands at $155bn.&lt;/p&gt;
    &lt;p&gt;Accenture was approached for comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46105825</guid><pubDate>Mon, 01 Dec 2025 10:41:14 +0000</pubDate></item><item><title>Self-hosting a Matrix server for 5 years</title><link>https://yaky.dev/2025-11-30-self-hosting-matrix/</link><description>&lt;doc fingerprint="ae38b5519d233d94"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Self-hosting a Matrix server for 5 years&lt;/head&gt;
    &lt;p&gt;Experiences with the Matrix protocol, Matrix Synapse server, bridges, and Element mobile apps.&lt;/p&gt;
    &lt;p&gt;I have been hosting a Matrix server for about five years now, mostly for text chats between a few relatives and close friends, and a bridge to WhatsApp for a few more people. These are my experiences.&lt;/p&gt;
    &lt;head rend="h2"&gt;Matrix protocol&lt;/head&gt;
    &lt;p&gt;I don't have many thoughts on the protocol itself.&lt;/p&gt;
    &lt;p&gt;The only thing that I don't really understand is the decision on data replication. If a user on server A joins a room on server B, recent room data is copied from server B to server A and then kept in sync on both servers. I suppose this reduces the load on the original server at the expense of federation overhead and space on other servers. However, this also creates a situation where anything said across federation cannot be unsaid, which is an ironic situation for a protocol/system that often comes up when talking about privacy.&lt;/p&gt;
    &lt;p&gt;IIRC, fediverse/ActivityPub uses a similar approach.&lt;/p&gt;
    &lt;head rend="h2"&gt;Synapse server&lt;/head&gt;
    &lt;p&gt;Synapse is the only choice that supports bridges, which was why I wanted to try Matrix in the first place. And back in 2019-2020 this was the only choice anyway.&lt;/p&gt;
    &lt;p&gt;As of right now, I run Synapse, PostgreSQL, and coturn directly, without containerization, on a small VPS.&lt;/p&gt;
    &lt;head rend="h3"&gt;Works well&lt;/head&gt;
    &lt;p&gt;Works fairly reliably, supports bridges, and is more efficient that it was in 2020.&lt;/p&gt;
    &lt;p&gt;API is well documented, and allows authenticating and sending (unencrypted) messages via simple HTTP calls. At some point in time, I wanted to write a simple shell client to use with SXMO and such.&lt;/p&gt;
    &lt;head rend="h3"&gt;Does not have an admin panel&lt;/head&gt;
    &lt;p&gt;There is no admin page or panel. There was a third-party admin site, but it's an entire site just for making HTTP calls. So I ended up writing my own.&lt;/p&gt;
    &lt;p&gt;(Nowadays, the ESS deployment includes developer-made admin, see Future section)&lt;/p&gt;
    &lt;head rend="h3"&gt;Requires PostgreSQL&lt;/head&gt;
    &lt;p&gt;While technically, Synapse can work with a sqlite database (and which at first seems like an OK choice for having &amp;lt;10 users on the server), it WILL become corrupted. So PostgreSQL is de-facto mandatory.&lt;/p&gt;
    &lt;p&gt;(Already a part of new ESS)&lt;/p&gt;
    &lt;head rend="h3"&gt;Requires federation&lt;/head&gt;
    &lt;p&gt;Initial setup presumes that the server is going to be federated, and there is no good way to turn it off. The best workaround involves a blank whitelist of federated servers.&lt;/p&gt;
    &lt;p&gt;GitHub issue: Single config option to disable federation&lt;/p&gt;
    &lt;p&gt;I don't know the implications of disabling it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Needs constant cleanup&lt;/head&gt;
    &lt;p&gt;Message retention policy can be set up server-wide, but also per-room. There are specific lines in the configuration that need to be set to actually enable a service that runs the cleanup.&lt;/p&gt;
    &lt;p&gt;Synapse keeps the room even after all of the members leave it, including federated rooms. This results in many (sometimes large) rooms without local members orphaned on the server, taking up database space.&lt;/p&gt;
    &lt;p&gt;Deleting messages (events) with attachments does not delete the attachment (because another message might refer to it?), which means that the sent files continue existing on the server indefinitely. Another privacy implication. A simple "delete all files older than X" script works great until it deletes avatars. So yeah, seems like this is something that should be handled by the Synapse server instead of cobbled-together scripts.&lt;/p&gt;
    &lt;p&gt;Even after extensive cleanup, PostgreSQL database might need to be vacuumed to reduce the disk space it takes up.&lt;/p&gt;
    &lt;head rend="h3"&gt;Database grows out of control&lt;/head&gt;
    &lt;p&gt;Even for my small server with &amp;lt;10 active users, database size reached several gigabytes.&lt;/p&gt;
    &lt;p&gt;Synapse keeps track of room states in an append-only (!) table named state_groups_state. Deleting a room does not delete the state_groups_state records. So it is never automatically cleaned up, and grows in size infinitely. It is possible to delete many of those records from the database directly, and Element (the company) provides some tool to "compress" those records, but again, something that should be handled by the server.&lt;/p&gt;
    &lt;p&gt;Good article about state_groups_state&lt;/p&gt;
    &lt;head rend="h3"&gt;Users cannot be deleted&lt;/head&gt;
    &lt;p&gt;This is simply not an option in the API. Server admin can perform a "deactivate" (disable login) and "erase" (remove related data, which claims to be GDPR-compliant) on user accounts, but the accounts themselves stay on the server forever.&lt;/p&gt;
    &lt;p&gt;Wait, what? Why?&lt;/p&gt;
    &lt;p&gt;How this not considered a GDPR violation is a mystery to me. Even on my tiny server, I have users who use their first name as their ID and bridged WhatsApp users that use phone numbers as IDs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Future&lt;/head&gt;
    &lt;p&gt;While Matrix-Element ecosystem has been catering towards government and corporate entities for some time, there have been multiple recent announcements about its future.&lt;/p&gt;
    &lt;p&gt;Specifically, Element (the company) is now providing an all-in-one Element Server Suite (ESS) to replace the current setup, including&lt;/p&gt;
    &lt;quote&gt;It is intended for non-professional use, evaluations, and small to mid-sized deployments (1√¢100 users).&lt;/quote&gt;
    &lt;p&gt;ESS Community includes 7 components/services, now requires a minimum of 2 CPUs, 2GB of RAM, and runs using... Kubernetes? IMO, this is an overkill for dozen users.&lt;/p&gt;
    &lt;p&gt;For comparison, Snikket, an all-in-one solution with similar functionality using XMPP, requires a single CPU and 128MB (!) RAM for 10 or so users.&lt;/p&gt;
    &lt;p&gt;Yes, I have seen the ansible setup script setup recommended, but at this point, making setup easier does not address the issue of extra services being required in the first place.&lt;/p&gt;
    &lt;p&gt;Matrix server setup using Ansible and Docker&lt;/p&gt;
    &lt;p&gt;Also, the ESS handles account creation and calls in an entirely different way, more on that later.&lt;/p&gt;
    &lt;head rend="h2"&gt;Matrix-WhatsApp bridge&lt;/head&gt;
    &lt;p&gt;Pretty great. Easy to install and set up, works really well, and needs only occasional (semi-yearly or so) updates when WhatsApp changes their web API. Does not support calls.&lt;/p&gt;
    &lt;head rend="h2"&gt;Element Classic&lt;/head&gt;
    &lt;head rend="h3"&gt;Same on all platforms&lt;/head&gt;
    &lt;p&gt;Element exists and looks consistent on Android, iOS, and web, making it easier for regular users and for troubleshooting.&lt;/p&gt;
    &lt;head rend="h3"&gt;No image captions&lt;/head&gt;
    &lt;p&gt;This is silly, but while (official?) bridges support image captions, official Element app does not. The answer in the FAQ? Get a better app. Well, OK.&lt;/p&gt;
    &lt;p&gt;No image caption in Element Classic.&lt;/p&gt;
    &lt;p&gt;Image with a caption in SchildiChat Classic (the better app).&lt;/p&gt;
    &lt;head rend="h3"&gt;Slow notifications&lt;/head&gt;
    &lt;p&gt;Sometimes it can take up to a few minutes to get a message, even between two Android clients using Google Cloud Messaging. Sometimes it is nearly instant. Still unsure of the cause.&lt;/p&gt;
    &lt;head rend="h3"&gt;No offline indication&lt;/head&gt;
    &lt;p&gt;One unreliable way to tell that the server is unreachable is the endless loading bar. But even then, it eventually goes away without indicating any errors.&lt;/p&gt;
    &lt;p&gt;Then, when sending a message, the user receives "Unable to send message". Frustration ensues.&lt;/p&gt;
    &lt;p&gt;But I know the app is trying to call the /sync endpoint. Why doesn't it show any errors when that fails?&lt;/p&gt;
    &lt;head rend="h3"&gt;Security key and device verification&lt;/head&gt;
    &lt;p&gt;IIRC the first thing the app does is ask user to back up their signing keys and enter the key password, without a simple explanation. Not a great experience for regular users.&lt;/p&gt;
    &lt;p&gt;Some people reported issues with Element losing its keys or frequently requesting to be re-verified. Thankfully I have not encountered these.&lt;/p&gt;
    &lt;head rend="h3"&gt;Third-party services&lt;/head&gt;
    &lt;p&gt;Even if you connect to a self-hosted server, Element Classic could attempt to connect to vector.im integration server and matrix.org key backup server.&lt;/p&gt;
    &lt;head rend="h2"&gt;Element X&lt;/head&gt;
    &lt;p&gt;Element X is now recommended as the new and better client. It is not.&lt;/p&gt;
    &lt;head rend="h3"&gt;Slower&lt;/head&gt;
    &lt;p&gt;Somehow, it is slower. Clicking on a conversation takes 0.5-1.0 seconds to load it, compared to almost instant load on Classic.&lt;/p&gt;
    &lt;p&gt;Perhaps it does work better for accounts with many large rooms, but that is not my case.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sorting&lt;/head&gt;
    &lt;p&gt;Conversations are sorted by... who knows. It is not recent nor alphabetical.&lt;/p&gt;
    &lt;head rend="h3"&gt;No background sync&lt;/head&gt;
    &lt;p&gt;Element X does not support periodic background sync, so you need to set up ntfy or something similar to use Element X on a de-googled device. Seems like a simple enough fail-safe (even WhatsApp does this), but it was dropped for some reason.&lt;/p&gt;
    &lt;head rend="h3"&gt;Requires "sliding sync" option on the server&lt;/head&gt;
    &lt;p&gt;This "sliding sync" option is available only for newer Synapse versions, and only if running with PostgreSQL database (which should already be the case - see above). Probably not an issue unless the user tries to connect Element X to an outdated Synapse.&lt;/p&gt;
    &lt;head rend="h3"&gt;Calls are not backward compatible&lt;/head&gt;
    &lt;p&gt;Calling with Element X requires Element Call (part of ESS). This supports group calls, but... only video calls at the moment.&lt;/p&gt;
    &lt;p&gt;You also might be asked to tell your contact to install the new app:&lt;/p&gt;
    &lt;p&gt;I don't regularly use calls, but some people I would like to invite to my server would want to use them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Onboarding is bad&lt;/head&gt;
    &lt;p&gt;A few years ago, I ended up either temporarily enabling unrestricted registration (a terrible idea), or creating my users' accounts manually, because the "invite" matrix.to link was broken, and registration tokens did not work correctly in mobile apps.&lt;/p&gt;
    &lt;p&gt;So let's see how it works now. Keep in mind, I am still on standalone Synapse, not ESS.&lt;/p&gt;
    &lt;head rend="h3"&gt;Element X onboarding&lt;/head&gt;
    &lt;p&gt;I am a user, and I was to register an account on my friend's server. I see that Element X is now a recommended app, so let's try that.&lt;/p&gt;
    &lt;p&gt;Click "Create account" (which is a different style that does not look like a button for some reason).&lt;/p&gt;
    &lt;p&gt;But I want an account on a different server. Click "Change account provider".&lt;/p&gt;
    &lt;p&gt;Click "Other".&lt;/p&gt;
    &lt;p&gt;Now I can search for the server my friend is hosting, and it should appear in the list below the search.&lt;/p&gt;
    &lt;p&gt;As server admin: I do not remember if Synapse server has to enable/keep federation for this to work.&lt;/p&gt;
    &lt;p&gt;Yes! That is what I want, why is this so verbose?&lt;/p&gt;
    &lt;p&gt;WTF. So Element X cannot create even the simplest username+password account. That is all I want, I don't want to sign in with Google, Apple, or any other form of third-party authentication.&lt;/p&gt;
    &lt;head rend="h3"&gt;Element Classic onboarding&lt;/head&gt;
    &lt;p&gt;I was unable to register an account using Element X, so Element Classic should work better.&lt;/p&gt;
    &lt;p&gt;Ok, "CREATE ACCOUNT".&lt;/p&gt;
    &lt;p&gt;What difference does this make? Skip.&lt;/p&gt;
    &lt;p&gt;The current official app is telling me to use Element X. Just tried that. Click "EDIT" where it says "matrix.org" (which does not say "server", actually) and enter the server name.&lt;/p&gt;
    &lt;p&gt;Why not? No explanation. Sure, I'll use a web client.&lt;/p&gt;
    &lt;p&gt;Well, fuck me, I guess. Why can't I just create an account?&lt;/p&gt;
    &lt;p&gt;As a server admin: Synapse is set to allow registrations via registration tokens, because unrestricted registration is a bad idea. I did not find where the /static/client/register path is set.&lt;/p&gt;
    &lt;p&gt;IIRC it is possible to register an account by going to a web-hosted Element app, such as app.element.io, which will allow to register an account using a registration token. But then the user has to deal with the headache of cross-verifying their mobile device to the web app (which they might never use).&lt;/p&gt;
    &lt;head rend="h2"&gt;So now what?&lt;/head&gt;
    &lt;p&gt;Matrix-Element is growing, building new features, and acquiring large customers (mostly government entities AFAIK). However, the new corporatesque ESS Community is not worth it in my opinion. I don't need fancy auth, third-party IDs, group video conferencing, or even federation for that matter. But it is clear that Synapse and Element X are severely crippled and are not designed to work without these services.&lt;/p&gt;
    &lt;p&gt;I will probably switch to Snikket, which is more efficient, has timely notifications, and very smooth onboarding.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who cares?&lt;/head&gt;
    &lt;p&gt;√Ç¬Ø\_(√£)_/√Ç¬Ø&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46106132</guid><pubDate>Mon, 01 Dec 2025 11:26:39 +0000</pubDate></item><item><title>1GB Raspberry Pi 5, and memory-driven price rises</title><link>https://www.raspberrypi.com/news/1gb-raspberry-pi-5-now-available-at-45-and-memory-driven-price-rises/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46106186</guid><pubDate>Mon, 01 Dec 2025 11:37:18 +0000</pubDate></item><item><title>Why xor eax, eax?</title><link>https://xania.org/202512/01-xor-eax-eax</link><description>&lt;doc fingerprint="989ffc06e1139ed8"&gt;
  &lt;main&gt;
    &lt;p&gt;Written by me, proof-read by an LLM. &lt;lb/&gt;Details at end.&lt;/p&gt;
    &lt;p&gt;In one of my talks on assembly, I show a list of the 20 most executed instructions on an average x86 Linux desktop. All the usual culprits are there, &lt;code&gt;mov&lt;/code&gt;, &lt;code&gt;add&lt;/code&gt;, &lt;code&gt;lea&lt;/code&gt;, &lt;code&gt;sub&lt;/code&gt;, &lt;code&gt;jmp&lt;/code&gt;, &lt;code&gt;call&lt;/code&gt; and so on, but the surprise interloper is &lt;code&gt;xor&lt;/code&gt; - ‚ÄúeXclusive OR‚Äù. In my 6502 hacking days, the presence of an exclusive OR was a sure-fire indicator you‚Äôd either found the encryption part of the code, or some kind of sprite routine. It‚Äôs surprising then, that a Linux machine just minding its own business, would be executing so many.&lt;/p&gt;
    &lt;p&gt;That is, until you remember that compilers love to emit a &lt;code&gt;xor&lt;/code&gt; when setting a register to zero:&lt;/p&gt;
    &lt;p&gt;We know that exclusive-OR-ing anything with itself generates zero, but why does the compiler emit this sequence? Is it just showing off?&lt;/p&gt;
    &lt;p&gt;In the example above, I‚Äôve compiled with &lt;code&gt;-O2&lt;/code&gt; and enabled Compiler Explorer‚Äôs ‚ÄúCompile to binary object‚Äù so you can view the machine code that the CPU sees, specifically:&lt;/p&gt;
    &lt;code&gt;31 c0           xor eax, eax
c3              ret
&lt;/code&gt;
    &lt;p&gt;If you change GCC‚Äôs optimisation level down to &lt;code&gt;-O1&lt;/code&gt; you‚Äôll see:&lt;/p&gt;
    &lt;code&gt;b8 00 00 00 00  mov eax, 0x0
c3              ret
&lt;/code&gt;
    &lt;p&gt;The much clearer, more intention-revealing &lt;code&gt;mov eax, 0&lt;/code&gt; to set the EAX register to zero takes up five bytes, compared to the two of the exclusive OR. By using a slightly more obscure instruction, we save three bytes every time we need to set a register to zero, which is a pretty common operation. Saving bytes makes the program smaller, and makes more efficient use of the instruction cache.&lt;/p&gt;
    &lt;p&gt;It gets better though! Since this is a very common operation, x86 CPUs spot this ‚Äúzeroing idiom‚Äù early in the pipeline and can specifically optimise around it: the out-of-order tracking systems knows that the value of ‚Äúeax‚Äù (or whichever register is being zeroed) does not depend on the previous value of eax, so it can allocate a fresh, dependency-free zero register renamer slot. And, having done that it removes the operation from the execution queue - that is the &lt;code&gt;xor&lt;/code&gt; takes zero execution cycles!1 It‚Äôs essentially optimised out by the CPU!&lt;/p&gt;
    &lt;p&gt;You may wonder why you see &lt;code&gt;xor eax, eax&lt;/code&gt; but never &lt;code&gt;xor rax, rax&lt;/code&gt; (the 64-bit version), even when returning a &lt;code&gt;long&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;In this case, even though &lt;code&gt;rax&lt;/code&gt; is needed to hold the full 64-bit &lt;code&gt;long&lt;/code&gt; result, by writing to &lt;code&gt;eax&lt;/code&gt;, we get a nice effect: Unlike other partial register writes, when writing to an &lt;code&gt;e&lt;/code&gt; register like &lt;code&gt;eax&lt;/code&gt;, the architecture zeros the top 32 bits for free. So &lt;code&gt;xor eax, eax&lt;/code&gt; sets all 64 bits to zero.&lt;/p&gt;
    &lt;p&gt;Interestingly, when zeroing the ‚Äúextended‚Äù numbered registers (like &lt;code&gt;r8&lt;/code&gt;), GCC still uses the &lt;code&gt;d&lt;/code&gt; (double width, ie 32-bit) variant:&lt;/p&gt;
    &lt;p&gt;Note how it‚Äôs &lt;code&gt;xor r8d, r8d&lt;/code&gt; (the 32-bit variant) even though with the REX prefix (here &lt;code&gt;45&lt;/code&gt;) it would be the same number of bytes to &lt;code&gt;xor r8, r8&lt;/code&gt; the full width. Probably makes something easier in the compilers, as clang does this too.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;xor eax, eax&lt;/code&gt; saves you code space and execution time! Thanks compilers!&lt;/p&gt;
    &lt;p&gt;See the video that accompanies this post.&lt;/p&gt;
    &lt;p&gt;This post is day 1 of Advent of Compiler Optimisations 2025, a 25-day series exploring how compilers transform our code.&lt;/p&gt;
    &lt;p&gt;This post was written by a human (Matt Godbolt) and reviewed and proof-read LLMs and humans.&lt;/p&gt;
    &lt;p&gt;Support Compiler Explorer on Patreon or GitHub, or by buying CE products in the Compiler Explorer Shop.&lt;/p&gt;
    &lt;p&gt;It still has to retire, so some on-chip resources are still allocated to it. ‚Ü©&lt;/p&gt;
    &lt;p&gt;Matt Godbolt is a C++ developer living in Chicago. Follow him on Mastodon or Bluesky.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46106556</guid><pubDate>Mon, 01 Dec 2025 12:22:35 +0000</pubDate></item></channel></rss>