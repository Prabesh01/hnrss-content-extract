<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 29 Jan 2026 16:38:00 +0000</lastBuildDate><item><title>Airfoil (2024)</title><link>https://ciechanow.ski/airfoil/</link><description>&lt;doc fingerprint="b77d1a2b09aeb189"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Airfoil&lt;/head&gt;
    &lt;p&gt;The dream of soaring in the sky like a bird has captivated the human mind for ages. Although many failed, some eventually succeeded in achieving that goal. These days we take air transportation for granted, but the physics of flight can still be puzzling.&lt;/p&gt;
    &lt;p&gt;In this article we’ll investigate what makes airplanes fly by looking at the forces generated by the flow of air around the aircraft’s wings. More specifically, we’ll focus on the cross section of those wings to reveal the shape of an airfoil â you can see it presented in yellow below:&lt;/p&gt;
    &lt;p&gt;We’ll find out how the shape and the orientation of the airfoil helps airplanes remain airborne. We’ll also learn about the behavior and properties of air and other flowing matter. In the demonstration below, you can see a fluid flowing around a gray cube. Using the slider to change just one property of this substance, we can end up with vastly different effects on the liveliness of that flow:&lt;/p&gt;
    &lt;p&gt;Over the course of this blog post we’ll build some intuitions for why these different effects happen to airfoils and other objects placed in flowing air. We’ll start this journey by looking at some of the methods we can use to visualize the motion of the air.&lt;/p&gt;
    &lt;head rend="h1"&gt;Visualizing Flow&lt;/head&gt;
    &lt;p&gt;If you’ve ever been outside in a grassy area on a windy fall day, you may have witnessed something similar to the little scene seen below. The slider lets you control the speed of time to observe in detail how the falling leaves and the bending blades of grass are visibly affected by the wind sweeping through this area:&lt;/p&gt;
    &lt;p&gt;We intuitively understand that it’s the flowing air that pushes the vegetation around, but note that we only observe the effects that the wind has on other objects â we can’t see the motion of the air itself. I could show you a similarly windy scene without the grass and leaves, and I could try to convince you that there is something going on there, but that completely empty demonstration wouldn’t be very gratifying.&lt;/p&gt;
    &lt;p&gt;Since the air’s transparency prevents us from tracking its movement directly, we have to come up with some other ways that can help us see its motion. Thankfully, the little outdoor scene already provides us with some ideas.&lt;/p&gt;
    &lt;p&gt;Notice that as the wind hits a blade of grass, that blade naturally bends in the direction of the blowing gust, and the faster that gust, the stronger the bending. AÂ single blade indicates the direction and speed of the flow of air in that area.&lt;/p&gt;
    &lt;p&gt;In the next demonstration we’re looking at the same grassy field from above. When seen from this perspective, all the blades form short lines that are locally aligned with the wind. The more leaned over a blade of grass is, the longer the line it forms. We can mimic this behavior with a collection of small arrows placed all over the area, as seen on the right side:&lt;/p&gt;
    &lt;p&gt;Each arrow represents the direction and the speed of the flow of air at that location â the longer the arrow, the faster the flow. In these windy conditions the flow varies from place to place and it also changes over time, which we can clearly see in the motion of the arrows.&lt;/p&gt;
    &lt;p&gt;Note that we have some flexibility in how the speed of wind corresponds to the length of an arrow. I adjusted the lengths of the arrows to prevent them from visually overlapping, but I also made sure to maintain their relative lengths â if one arrow is twice as long as the other, then the flow at that location is also twice as fast.&lt;/p&gt;
    &lt;p&gt;For visual clarity I’m also not packing the arrows as densely as the blades of grass are placed, but it’s important to note that every point in the flow has its own velocity which contributes to the complete velocity field present in this area. If we wanted to, we could draw a velocity arrow at any of the seemingly empty spots on the right side.&lt;/p&gt;
    &lt;p&gt;The arrows are convenient, but the grassy scene also has another aid for visualizing flows. Many light objects like leaves, flower petals, dust, or smoke are very easily influenced by the motion of the surrounding air. They quickly change their velocity to match the flow of the wind. We can replicate the behavior of these light objects with little markers that are pushed around by that flow. You can see them on the right side:&lt;/p&gt;
    &lt;p&gt;These little markers also show us the motion of the air. Each marker represents an object so small and light that it instantly picks up the speed of the surrounding airflow. We’d have a hard time seeing these miniscule specks at their actual sizes, so I’m drawing the markers as visible dots.&lt;/p&gt;
    &lt;p&gt;In fact, the motion of each marker is equivalent to the motion of the parcel of air right around it. If you slow down time, you’ll be able to see how each marker just moves in the direction of the arrows underneath it. I also made each marker leave a little ghost trail behind it â this lets us track the path the air, as represented by the marker, took on the way to its current position.&lt;/p&gt;
    &lt;p&gt;Let’s pause for a second to emphasize what the grass-like arrows and leaf-like markers represent âÂ they both show the velocity of the flow of air, but in slightly different ways. An arrow is attached to its fixed point in space, so it represents the current direction and speed of the flow at that location. The whole collection of arrows lets us easily see what the entire flow is doing at the moment.&lt;/p&gt;
    &lt;p&gt;On the other hand, the little markers are actively following the flow, letting us see how the air is actually moving through space, with the ghosty trails giving us some historical overview of where this parcel of air has come from.&lt;/p&gt;
    &lt;p&gt;The two methods we’ve seen so far are very versatile, but sometimes we don’t care about the local direction of the flow, only its speed â in the middle of this grassy field one might get cold from a fast blowing wind regardless of the direction from which that wind is coming. This brings us the third way of visualizing flow:&lt;/p&gt;
    &lt;p&gt;In this method we show the speed of the airflow using colors of varying brightness â the faster the wind, the brighter the color. You can see the whole spectrum of colors in the scale below the plot.&lt;/p&gt;
    &lt;p&gt;This method shows the speed of the flow at all locations giving us a more fine-grained insight into the motion of air at the cost of the directional information. To help with that I’ll sometimes overlay the regular arrows on top to let us know where the flow is going as well.&lt;/p&gt;
    &lt;p&gt;You may have noticed that all these methods present a flat, two dimensional view of the flow. It’s based on the assumption that the wind in our little scene doesn’t change with elevation, and that it also doesn’t blow towards or away from the ground.&lt;/p&gt;
    &lt;p&gt;In reality, the air velocity could vary in all three dimensions, and that air could also flow upwards or downwards. Thankfully, the air flows we’ll consider in this article will be two dimensional and the simple flat drawings will suffice.&lt;/p&gt;
    &lt;p&gt;Before we finish this section, let me bring up visualization of a simple airflow, but this time I’ll give you some control over its direction, which you can change using the second slider. The first one once more controls the speed of time:&lt;/p&gt;
    &lt;p&gt;Don’t be misled by the frozen arrows, the wind is actually blowing there. Remember that the arrows represent the local velocity of the flow of air, so while the velocity doesn’t change, the position of each packet of air does. You can see those changes by tracking the markers moving around with the flow. This demonstration represents a steady flow, which means that its properties don’t change over time.&lt;/p&gt;
    &lt;p&gt;So far we’ve been exploring the notion of airflow’s velocity on a more intuitive level, with a general understanding that’s it’s “the air” moving around in some direction and at some speed. I illustrated that concept using simple arrowsâ, markersÂ â¢, and varying colors, but we’re now ready to investigate the details hiding behind those straightforward graphical representations.&lt;/p&gt;
    &lt;p&gt;To do that, we have to look at individual particles of air. Although I briefly discussed the particle nature of air before, this time around we’re going to take a closer look at the motion of these molecules, and what it means for airflow as a whole.&lt;/p&gt;
    &lt;head rend="h1"&gt;Velocity&lt;/head&gt;
    &lt;p&gt;Let’s take a look at the air particles in a small, marked out volume of space seen in the demonstration below â you can drag the cube around to change the viewing angle. The slider controls the speed of time:&lt;/p&gt;
    &lt;p&gt;You’re witnessing the motion of over twelve thousand air particles. It may seem like a lot, but this cube is extremely tiny, its sides are only 80 nanometers long. To put this in perspective using more familiar sizes, if that cube’s side measured just 1 inch1 centimeter, it would contain around 410 quintillion, or 4.1Ã102025 quintillion, or 2.5Ã1019 particles.&lt;/p&gt;
    &lt;p&gt;The particles are zipping around in random directions, constantly entering and leaving this region. However, despite all this motion what you’re seeing here is a simulation of still air.&lt;/p&gt;
    &lt;p&gt;To understand how all this movement ends up creating still conditions, we first have to look at the velocity of each particle â I’ll visualize it with a small arrow in the direction of motion. To make things a easier to see, I’ll also highlight a few of the particles while fading out the rest of them:&lt;/p&gt;
    &lt;p&gt;The length of an arrow is proportional to the speed of a particle, so when you freeze the time you should be able to see how some particles are slower and some are faster. This speed variation follows a certain distribution that’s related to temperature â the warmer the air, the faster the motion of its particles.&lt;/p&gt;
    &lt;p&gt;At room temperature the average speed of a particle in air is an astonishing 1030Â mph1650Â km/h, which is many times higher than even the most severe hurricanes. Given the size of the cube, this means that even at the fastest speed of simulation everything happens 11 billion times slower than in real life.&lt;/p&gt;
    &lt;p&gt;If you paid close attention, you may have also noticed that sometimes the particles randomly change direction and speed of their motion â this happens when molecules collide. Each particle experiences roughly ten billion collisions per second. We’ll get back to these interactions later on, but for now let’s try to figure out how all this turmoil creates still air.&lt;/p&gt;
    &lt;p&gt;Having just seen the small velocity arrows of individual particles, let’s calculate the average velocity of a group of three particles, using the process shown below. We first take the velocity arrows from each particle and place them head to toe, one after another. Then we connect the start of the first arrow with the end of the last arrow to create the sum of all velocities. Finally, we divide, or scale down, the length of this sum by the number of particles to get the average velocity:&lt;/p&gt;
    &lt;p&gt;In the next demonstration we’re repeating this whole procedure by tallying up all the particles inside the red box. You can change the size of that region with the second slider. The large arrow in the middle shows the average velocity of particles in the box. To make that central arrow visible, I’m making it much larger than the tiny arrows tied to particles:&lt;/p&gt;
    &lt;p&gt;The counter in the bottom part of the demonstration tracks the current number of particles in the red cube. That value fluctuates as the molecules enter and leave that region. While aggregating over a small number of particles creates a very noisy readout, it doesn’t take that many particles to get a much steadier measure.&lt;/p&gt;
    &lt;p&gt;Recall that the scale of the large central arrow is much larger than the scale of individual tiny arrows attached to each particle. Despite that increase in size, the arrow practically disappears when we average out a larger number of particles and we can clearly see that the average velocity of particles is more or less zero even in this extremely small volume.&lt;/p&gt;
    &lt;p&gt;In still conditions, all these motions in different directions average out to nothing. As some particles enter the area from a random direction, the others also leave it in a random way. The bulk of air doesn’t really go anywhere and the particles just meander in a random fashion.&lt;/p&gt;
    &lt;p&gt;An imperfect, but convenient analogy is to imagine a swarm of bees flying in the air. While all the individual insects are actively roaming around at different speeds, the group as a whole may steadily stay in one place.&lt;/p&gt;
    &lt;p&gt;All these experiments form the key to understanding what happens when wind sweeps through an area. In the demonstration below, we’re once again watching a small volume of space, but this time you can control the speed of the blowing wind:&lt;/p&gt;
    &lt;p&gt;Notice the mphkm/h speedometer in the bottom of the demonstration. This is not a mistake âÂ even with hurricane-level wind speeds it’s very hard to see any difference in the motion of the particles. Perhaps you’ve managed to see the tiniest shifts in the small particle arrows as you drag the second slider around with time paused, but it’s difficult to even perceive from which direction the wind is blowing.&lt;/p&gt;
    &lt;p&gt;However, when we use the procedure of averaging the velocity of all the particles, we can reveal the motion of their group in the box of a given size, at a specific speed of the flow:&lt;/p&gt;
    &lt;p&gt;Because the motion of each individual particle is so disordered, we have to look at many of them at once to discern any universal characteristics. And when we do just that, from all the chaos emerges order.&lt;/p&gt;
    &lt;p&gt;It’s important to note that with this approach we’re tracking the velocity of the flow within the same region of space outlined by the red box â the molecules keep entering and leaving this area as the flow moves and the arrow in the middle shows the average velocity of the air’s particles in that area.&lt;/p&gt;
    &lt;p&gt;This is exactly what the grass-like arrows we’ve played with in the previous section represent â each one shows the average velocity of air particles in that local region of space. The big arrow we just saw in the middle of the swarm in the averaging red box is equivalent to each of the arrows seen below:&lt;/p&gt;
    &lt;p&gt;Naturally, the averaging box needs to be large enough to avoid the jitteriness related to aggregation of too few particles, but at any scale that we could care about the noisy readout completely disappears.&lt;/p&gt;
    &lt;p&gt;The average motion of particles is very different than the motion of each individual molecule. Even in very fast flows, many of the molecules move in the opposite direction than what the arrow indicates, but if we tally up all the particle motion, the air as a whole does make forward progress in the direction of velocity.&lt;/p&gt;
    &lt;p&gt;Up to this point, we’ve mostly looked at the flow of air by looking at wind and the way it moves through space, but what we consider a motion of air is relative. Let’s see how, by merely changing the point of view, we can create a motion of air in otherwise windless conditions.&lt;/p&gt;
    &lt;head rend="h1"&gt;Relative Velocity&lt;/head&gt;
    &lt;p&gt;Let’s zoom away from the world of microscopic particles to look at the motion of larger bodies. In the demonstration below, you can see two different views of the same car driving in the left direction. In the top part, the camera stays firmly on the ground, but in the bottom part, the camera tracks the motion of the vehicle. If needed, you can restart the scene with the button in the bottom left corner or tweak the speed of time with the slider:&lt;/p&gt;
    &lt;p&gt;These two views show the exact same scene â we’re just changing what the camera is focusing on. As seen in the top part, from the perspective of the static camera, it’s only the car that has some velocity in the left direction.&lt;/p&gt;
    &lt;p&gt;On the other hand, from the perspective of the camera focused on the vehicle, the car doesn’t move, but everything else does. The poles and road markings all move to the right with a speed equal to that of the car. This shouldn’t come as a surprise from daily experience in any form of transportation â when you’re sitting in a moving vehicle, static things in the surrounding environment seem to move towards and past you.&lt;/p&gt;
    &lt;p&gt;The very same rules apply to any region of air â I’ve outlined some of them with dashed boxes up in the sky. For the observer on the ground that air is still, but from the car’s perspective, that air is moving.&lt;/p&gt;
    &lt;p&gt;With that in mind, let’s see the same scene, but this time I’ll add the familiar small arrows showing the air’s velocity as “seen” by the camera:&lt;/p&gt;
    &lt;p&gt;From the point of view of the car, as seen in the bottom view, the air is moving to the right, as if there was some wind blowing right at the vehicle. You’ve probably felt this many times by sticking your hand out the window â it feels no different than if you were standing still on the ground with the wind hitting your fingers.&lt;/p&gt;
    &lt;p&gt;In fact, there is absolutely no difference between “regular” wind and wind experienced by the car or your hand sticking out the window â both are simply a motion of air relative to some object. This means that we can use our arrows to represent any motion of air, as long as we note what that motion is relative to.&lt;/p&gt;
    &lt;p&gt;You may have also noticed that the moving car affects the motion of air in its vicinity. Let me bring up the previous demonstration one more time:&lt;/p&gt;
    &lt;p&gt;In the top view, we can see how the front of the vehicle pushes the air forward, and how the air “bends” and speeds up around the shape of the car to roughly follow its shape, only to end up circling right behind the machine.&lt;/p&gt;
    &lt;p&gt;The same effects are seen in the bottom view â they’re just experienced differently. For example, the air right in front of the car slows down, while the air on top moves even faster than the rest of the undisturbed, distant air.&lt;/p&gt;
    &lt;p&gt;We’ll soon explore why the air behaves this way when flowing around an object, but for now let’s raise above the ground to see the motion of an airplane flying in the sky. We’ll use the familiar setup of a camera kept steady relative the ground, as seen in the top part, and a camera that follows the airplane, seen in the bottom part:&lt;/p&gt;
    &lt;p&gt;Before we continue, notice that it’s getting a little hard to pay close attention to what happens to the moving objects in the ground-fixed camera view â the bodies quickly leave the field of view of the demonstrations. For the rest of this article I’ll stick to the camera style seen in the bottom part of the demonstration â this will let us directly track the interaction between the object and the air that flows around that object.&lt;/p&gt;
    &lt;p&gt;From the point of view of the airplane, it also experiences a flow of incoming air as seen by the air “boxes” approaching the plane, which is very similar to the car example. What’s completely different from the car example is the fact that the airplane somehow stays suspended in the air, despite gravity pulling it down towards the ground. This means that there must be some other force acting on it to prevent the plane from falling from the sky.&lt;/p&gt;
    &lt;p&gt;Let’s compare these two vehicles by looking at the basic forces affecting their motion, starting with the diagram of forces acting on the car:&lt;/p&gt;
    &lt;p&gt;The down-pulling gravity force is counteracted by the reaction forces from the ground â they act through the car’s tires to prevent the car from sinking. The air drag and other forms of resistance push the car back, but the car’s tires powered by the engine keep propelling the car forward.&lt;/p&gt;
    &lt;p&gt;In my previous article I presented a more elaborate description of the interplay between forces and objects, but to briefly recap here, if forces acting on an object are balanced, then that object will maintain its current velocity.&lt;/p&gt;
    &lt;p&gt;All forces on the car are balanced and the vehicle moves forward with constant speed, and it doesn’t move at all in the up or down direction â the object’s velocity is indeed constant.&lt;/p&gt;
    &lt;p&gt;Let’s draw a similar diagram of forces for the flying plane:&lt;/p&gt;
    &lt;p&gt;We still have the air drag that pushes the vehicle back, and the plane’s propeller powered by the engine keeps pushing it forward. As a result the plane moves forward with constant speed.&lt;/p&gt;
    &lt;p&gt;We also have the down-pulling gravity. This time, however, that gravity is not countered by the reaction forces from the ground, but instead it’s balanced by lift, a force that pushes the plane up. When gravity and lift are equalized, the plane doesn’t move up or down either.&lt;/p&gt;
    &lt;p&gt;Airplanes create most of their lift with wings, which are carefully designed to generate that force. While length, area, and the overall geometry of the wings are very important, in this article we’ll focus on the shape of the cross-section of a wing which I highlighted below in yellow:&lt;/p&gt;
    &lt;p&gt;This is an airfoil, the protagonist of this article. This airfoil has a smooth, rounded front and a sharp trailing edge. Let’s take a closer look at the flow of air around this airfoil using the grass-like arrows that show the velocity of air at that location:&lt;/p&gt;
    &lt;p&gt;These arrows paint an interesting picture, but in the demonstration below I’ve also added the little leaf-like markers that track the motion of air parcels in the flow. IÂ steadily release a whole line of them from the left side, but you can also clicktap anywhere in the flow to drop a marker at that location. You can do this in any demonstration that has a little hand symbol in the bottom right corner:&lt;/p&gt;
    &lt;p&gt;The markers show that the flow splits ahead of the airfoil, then it gently changes direction to glide above and below the shape. Moreover, the markers right in front of the airfoil gradually slow down and lag behind their neighbors. The air somehow senses the presence of the body.&lt;/p&gt;
    &lt;p&gt;It may be hard to see, but the top and bottom sections of this airfoil aren’t symmetric. This asymmetric design is very important, but right now it will needlessly complicate our discussion on how the flow around this shape arises.&lt;/p&gt;
    &lt;p&gt;To simplify things a little, let’s use a less complicated shape of a symmetric airfoil â you can see it in the demonstration below. I overlay the previous asymmetric shape with a dashed outline to show the difference between the two:&lt;/p&gt;
    &lt;p&gt;The motion of air around this airfoil is very similar â the flow changes its direction and speed when it passes around an object. Until now we’ve simply been observing that the flow changes to adapt to the shape of the body, but it’s finally time to understand why it happens. To explain that behavior we need to go back to the world of air particles to discuss the concept of pressure.&lt;/p&gt;
    &lt;head rend="h1"&gt;Pressure&lt;/head&gt;
    &lt;p&gt;As we’ve discussed, even in the seemingly steady conditions the particles of air are zipping around at high speeds colliding with each other at an incredible rate. The surface of any object placed in the air will also experience these bounces.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, you can see air particles bombarding a small box. Every time a collision happens I briefly mark it with a dark spot on the surface of that cube:&lt;/p&gt;
    &lt;p&gt;To understand the implications of these collisions, let’s first take a look at objects with more ordinary sizes. In the demonstration below, tennis balls are hitting a large cardboard box from the left and right side. By dragging the slider you can change the intensity of both streams of balls:&lt;/p&gt;
    &lt;p&gt;When a tennis ball hits the box, the collision imparts some force on it, causing the box to move. However, in this simulation the collisions from all the balls on each side balance each other out, so the box doesn’t make any consistent progress in either direction.&lt;/p&gt;
    &lt;p&gt;In real air, the situation is similar, but at vastly different scales. The mass of each particle constituting air is absolutely miniscule, so the impact of an individual collision on any object of meaningful size is completely imperceptible.&lt;/p&gt;
    &lt;p&gt;Moreover, each air particle hitting an object has a different speed, and it strikes the surface of that object at a different angle â some hit the object straight on, but some barely graze it. Due to the enormous number of these collisions happening at every instant of time, all these variations average out, and even a small section of surface of any body experiences uniform bombardment.&lt;/p&gt;
    &lt;p&gt;In aggregate, we say that the air exerts pressure on any object present in that air. The magnitude of this pressure depends on the intensity of these collisions across an area.&lt;/p&gt;
    &lt;p&gt;Let’s see how this pressure manifests on our tiny cube. In the demonstration below, you can use the second slider to control the number of air molecules present in this volume:&lt;/p&gt;
    &lt;p&gt;The black arrows you see on the sides of the cube symbolize the magnitude of pressure on these walls. As we uniformly increase the number of particles in this volume, the intensity of collisions, and thus the pressure, also increases. Because the collisions happen at more or less the same rate on every side of the box, the net balance of forces is also maintained and the cube doesn’t move, regardless of how big or small the overall pressure is.&lt;/p&gt;
    &lt;p&gt;This is exactly what happens in the Earth’s atmosphere â everything is constantly squeezed by relatively high pressure caused by the barrage of countless air particles. That pressure is typically balanced either by an object’s material, which resists compression like a spring, or by the air itself that fills the insides of the object. When that inner air is removed, the seemingly innocuous atmospheric pressure reveals its might.&lt;/p&gt;
    &lt;p&gt;The underlying particle nature also shows us that pressure is never negative. Without any particle collisions, we reach the lowest possible pressure of zero. Beyond that, any impacts on the surface of an object create some amount of positive pressure.&lt;/p&gt;
    &lt;p&gt;In the demonstrations we’ve seen so far, the balanced number of collisions on each wall was very important for keeping the objects steady. Unsurprisingly, more interesting things happen when this harmony isn’t maintained. Let’s first investigate this scenario using the tennis balls. In the demonstration below, the slider controls if it’s the left side or the right side that’s shooting more balls:&lt;/p&gt;
    &lt;p&gt;As you can see, if one of the sides has a higher number of collisions, the forces acting on the box are no longer balanced and the box starts to move.&lt;/p&gt;
    &lt;p&gt;The very same situation happens in air, which you can witness in the simulation below. Notice that the volume in which the tiny cube exists has more particles on one side than the other. Observe what happens to cube once you let the time run using the slider:&lt;/p&gt;
    &lt;p&gt;The higher number of particle collisions on one side of the cube creates higher pressure forces on that wall. The uneven forces end up pushing the block to the side. In this demonstration, the pressure re-balances after a while and the cube stops moving.&lt;/p&gt;
    &lt;p&gt;Intuitively, the air exerts an imbalanced net force on the cube only when different parts of that object experience different pressure â it’s the spatial variation in pressure that creates an acting net force. When the difference in pressure between any two points increases, the net force acting on the object also grows.&lt;/p&gt;
    &lt;p&gt;It’s easy to see that a larger number of collisions on the left side of an object would start to exert a net force pushing that object to the right, but, perhaps surprisingly, the same rules apply to any chunk of air itself.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, I once again made one half of the test volume contain more particles than the other half. As you unpause the demonstration, observe the average velocity of molecules in the marked out section of air:&lt;/p&gt;
    &lt;p&gt;The particles on the more occupied side can easily travel to the less crowded side, because there are fewer particles there to collide with and bounce back from. Additionally, each particle in the less populated section is more likely to hit a particle in the more populated section, which will typically cause that particle from the desolate side to bounce back where it came from.&lt;/p&gt;
    &lt;p&gt;The particles end up, on average, traveling from the area of high pressure to the area of lower pressure. Even though we don’t have any clean borders between different sections, we can still see the bulk of particles getting accelerated towards the less dense section.&lt;/p&gt;
    &lt;p&gt;Once again, the initial pressure differences in the test volume dissipate after a while. On their own, these freely suspended pressure variations quickly disappear, but we will soon see how, with the aid of airflow, these areas of different pressure can be sustained indefinitely.&lt;/p&gt;
    &lt;p&gt;In the examples we’ve been playing with, the notion of increased pressure came from an increased number of collisions, which in turn came from an increased number of particles in the area. This shows that, all other things being equal, pressure is tied to the local density of the air, which was very easy to perceive in an increased concentration of molecules.&lt;/p&gt;
    &lt;p&gt;However, the pressure can also grow due to increased average speed of the particles, which in turn comes with increased temperature. As particles get faster, each collision gets more impactful and it pushes on an object or other particles a bit harder, causing the overall pressure to also increase. In the demonstration below, we can simulate this with tennis balls hitting the cardboard box at the same rate, but with different speeds, which you can control with the slider:&lt;/p&gt;
    &lt;p&gt;As we make the balls on one side of the box faster, their impacts also become stronger and the package starts moving to the right, even though the number of collisions per second is equal on both sides.&lt;/p&gt;
    &lt;p&gt;The important point from these discussions is that air pressure exerts force on everything inside it, be it a solid object or any parcel of air. It’s a little unintuitive that the air itself both exerts the pressure and it also “feels” the pressure, but it’s all just a consequence of very rapid motions of particles and the collisions between them happening at an enormous rate.&lt;/p&gt;
    &lt;p&gt;Recall that even in small volumes of air there are billions of billions of particles, and each particle experiences roughly ten billion collisions per second. What we’ve simulated at a micro scale and in slow motion as countable, individual interactions, very quickly smooths out into a uniform and uninterrupted notion of force-exerting pressure.&lt;/p&gt;
    &lt;p&gt;This fact lets us abandon the molecules and their collisions yet again. It’s not a big loss, since counting the number and intensity of collisions was never convenient in the first place, but we can now investigate some other ways of visualizing pressure in a region of air.&lt;/p&gt;
    &lt;head rend="h1"&gt;Visualizing Pressure&lt;/head&gt;
    &lt;p&gt;As we’ve seen in the particle simulations, pressure can vary from place to place. One of the most convenient ways to express this variation is to use colors of different intensities. Let’s see how that simple approach could work here. In the demonstration below, the dashed circles represent regions of high and low pressure â you can drag them around to change their position:&lt;/p&gt;
    &lt;p&gt;This map of pressure is colored with varying shades of red as indicated by the scale below â the redder the color, the higher the pressure. The small triangle â¼ in the middle of the scale indicates the location of the base, static pressure present in the atmosphere.&lt;/p&gt;
    &lt;p&gt;In this simulation we have complete control over where the different locations of lower and higher pressure are. To make things more interesting, each draggable pressure circle has a different strength and range. You can infer this variation from color changes around these points.&lt;/p&gt;
    &lt;p&gt;Let’s put an airfoil in this area to see how it’s affected by the pressure of the surrounding air. The arrows seen below symbolize the force that pressure exerts on the surface of the airfoil at that location. They’re the exact same arrows that we’ve seen acting on the walls of the tiny yellow cube, here we just see them at a larger scale:&lt;/p&gt;
    &lt;p&gt;As you move around the locations of lower and higher pressure, the forces acting on the surface of the airfoil also change, matching what we’ve seen with little cubes bombarded by air particles. The static pressure always exerts some base load, but in the areas of higher pressure the surface forces are higher, and in the areas of lower pressure the surface forces are lower than these base forces.&lt;/p&gt;
    &lt;p&gt;Note that you can also move the pressure circles into the airfoil, but it only serves as a convenience to let you customize the shape of the air pressure field around that body â we don’t particularly care about the pressure inside the solid itself.&lt;/p&gt;
    &lt;p&gt;When we tally up all the pressure forces acting on each piece of the airfoil’s surface, we end up with the net force acting on that object. In the demonstration below, I’m showing it with the big arrow at the center of the airfoil:&lt;/p&gt;
    &lt;p&gt;By changing the distribution of pressure around the airfoil, we can affect the total force that this object feels.&lt;/p&gt;
    &lt;p&gt;The reddish plots we’ve been looking at are correct, but a little inconvenient. Recall that final net force on the object depends only on the differences of pressure â when we uniformly increased the number of collisions on the walls of the tiny cube, it steadily remained in place.&lt;/p&gt;
    &lt;p&gt;This means that the static background pressure doesn’t matter for the cumulative forces acting on an object. It’s only the differences relative to that static pressure that affect the overall balance. This lets us overhaul our visual representation of pressure â we can use no color where the pressure has the static value, use blue color when the pressure is lower than the static pressure, and use red color when the pressure is higher than the static pressure:&lt;/p&gt;
    &lt;p&gt;This is the exact same distribution of pressure that we’ve just seen. All the pressure demos in this section are connected, and here we simply changed the reference point against which we present the pressure variation.&lt;/p&gt;
    &lt;p&gt;If we then throw in the airfoil back into the mix we can now also adjust the arrows representing the forces that the pressure exerts on the surface of that object:&lt;/p&gt;
    &lt;p&gt;The areas of higher pressure still seem to push on the surface of the airfoil, but the areas of lower pressure now seem to pull it. However, I need to emphasize once more that pressure always pushes on the object, and we can only talk about a pulling force when we discard that uniform, pushing contribution coming from the static pressure. In those “pulling” areas the pressure is still pushing, it just pushes less intensely.&lt;/p&gt;
    &lt;p&gt;I will also use the convenient terms of positive and negative pressure, but remember that this refers to their difference from the static pressure. The phrase “pressure lower than static pressure” is a mouthful, so the expression “negative pressure” is very handy, even when it hides the fact that pressure is always positive.&lt;/p&gt;
    &lt;p&gt;While the color variations used here show the true nature of the smoothly varying pressure changes, they make it a little hard to see how quickly those changes happen. To fix this, I’ll also draw the contour lines that join the locations of the same pressure â they’re very similar to lines of the same altitude you may have seen on maps:&lt;/p&gt;
    &lt;p&gt;Every point on one of those contour lines has the same value of pressure, and each subsequent line is drawn at the same increment of pressure â you can see this in the scale placed below the plot. This means that the closer the lines are together, the more quickly the pressure changes in that area.&lt;/p&gt;
    &lt;p&gt;The mathematical concept that describes the direction and rapidness of these changes is known as a gradient. Informally, gradient describes how some property changes from one point to another, and, thankfully, this notion tracks closely with how this word is used in graphic design to describe smooth color changes. Wherever you see a color gradient , this also implies that there is a pressure gradient â the pressure changes from place to place.&lt;/p&gt;
    &lt;p&gt;This spatial variation is particularly important for the motion of air. Recall that the air pressure differences don’t just exert forces on solid objects, but also on the air itself â any small parcel of air is subject to the same whims of pressure forces.&lt;/p&gt;
    &lt;p&gt;Those spatial variations in pressure end up pushing the air around, changing its velocity. Let’s see this in action using the little leaf-like markers that are moved around by pressure differences. In the demonstration below, I’m steadily releasing the markers from the left side âÂ notice how their trajectory changes when you modify the pressure field:&lt;/p&gt;
    &lt;p&gt;You may still find it a little difficult to grasp how pressure differences affect the motion of a parcel of air. Luckily, we can draw parallels between the contour lines of pressure seen on these pressure maps and the contour lines of elevation seen on traditional maps. This lets us build a little pressure-landscape analogy.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, the very same distribution of pressure is expressed as a mountainy landscape. Positive pressure lifts the ground above the base level and negative pressure depresses it below the base level. A parcel of air moves like a marble that loses speed when climbing uphill and accelerates when rolling downhill. You can drag the demo around to change the viewing angle:&lt;/p&gt;
    &lt;p&gt;Notice that when the pressure changes more rapidly and the contour lines are closer, the steepness of the corresponding hill or valley also increases, and so do the forces acting on a parcel of air. If the pressure is increasing by a large amount, it may even make the marker go back. This landscape analogy also shows that the static pressure doesn’t matter for the motion of air parcels, as any changes in static pressure would just lift all the areas by the same amount without changing their steepness.&lt;/p&gt;
    &lt;p&gt;When watching these air parcels move around, you may have noticed that things were a little bit off. For example, it’s possible for air parcels coming from different directions to arrive at the same location, and then continue to travel in different directions. You can see an example of that on the left side of the demonstration below, with the slider letting you scrub back and forth in time:&lt;/p&gt;
    &lt;p&gt;Recall that the markers always follow the local velocity of air, so the motion seen in the left part implies that the air at the location of the meetup of the two markers has two different velocities at the same time, which is not realistic.&lt;/p&gt;
    &lt;p&gt;It’s worth pointing out that the situation seen on right side, where one marker merely intersects the historical path of the other, can be realistic, as long as we’re dealing with an unsteady flow, where the velocity of the air at the crossing location has changed since the first marker was there. For steady conditions in which no changes occur over time, the scenario seen on the right is also not physically correct.&lt;/p&gt;
    &lt;p&gt;We’ll look at some unsteady flows later in the article, but for now we’re interested in steady conditions so the crossing paths of our markers indicate implausible velocities. Even more dubious result happen when we simulate the motion of these markers with an airfoil present in the flow:&lt;/p&gt;
    &lt;p&gt;For most distributions of pressure, the air markers will flow right through the body. This is clearly wrong! The demonstrations we’ve seen so far correctly represent what would happen to individual air parcels and bodies placed in these pressure fields, but those pressure fields themselves were completely made up and didn’t correspond to any physical reality. Our mistake was that we completely ignored any interactions between the pressure of the air and the motion of that air.&lt;/p&gt;
    &lt;p&gt;The flow of air, the pressure of air, and the shape of the objects placed in that air are all tied together â for a given incoming flow speed and the shape of the object, we can’t just arbitrarily arrange the pressure field like we did in our artificial demonstrations. Instead, that pressure field will arise on its own.&lt;/p&gt;
    &lt;p&gt;Let’s see a real distribution of pressure around this airfoil and witness how it affects the motion of air parcels around it:&lt;/p&gt;
    &lt;p&gt;The behavior of air parcels now matches our intuitive expectations â the markers don’t go through the body, and in these steady conditions they also don’t cross paths.&lt;/p&gt;
    &lt;p&gt;We’re now one step closer to understanding how the flow of air takes its shape to move around an airfoil â it’s the pressure differences that cause the flow to change its direction and speed.&lt;/p&gt;
    &lt;p&gt;The pressure field we’ve just seen clearly works â regions of lower and higher pressure guide the air around the airfoil. However, it’s still unclear how these areas emerged in the first place. Let’s try to follow nature’s path to see how this pressure distribution is created and sustained in a flow.&lt;/p&gt;
    &lt;head rend="h1"&gt;Airfoil Flow&lt;/head&gt;
    &lt;p&gt;Before we start building the correct pressure field from scratch, let’s first establish two guiding principles that the flow around any object has to follow.&lt;/p&gt;
    &lt;p&gt;Firstly, the air can’t penetrate solid walls. A valid pressure field should either completely stop the flow at the surface of the object, or redirect that flow to make it travel in the direction perpendicular to the walls. This means that the markers that we track can never get inside the object.&lt;/p&gt;
    &lt;p&gt;Secondly, we also have the restrictions on the relative motion of the markers. For now we’ll only be interested in steady conditions, which means that the markers can’t cross their paths â we expect the ghostly historical trails to never intersect.&lt;/p&gt;
    &lt;p&gt;Let’s first focus on the pressure field in front of the airfoil. In the demonstration below, I created an artificial pressure field in that frontal region, you can control it using the slider:&lt;/p&gt;
    &lt;p&gt;It should quickly become clear that to prevent the approaching air from getting into the object, the pressure in the frontal region has to be positive, so that it pushes the incoming air away.&lt;/p&gt;
    &lt;p&gt;If that positive pressure in front is too low the air can still erroneously flow through the object. If that pressure is too high, the air parcels arriving at the airfoil will turn back and incorrectly cross paths with the incoming air. When the pressure is just right, the air parcels don’t go through the wall, and, at least in front of the object, they also don’t cross their paths.&lt;/p&gt;
    &lt;p&gt;The faster the incoming flow, the higher the pushing force required to slow down and redirect the incoming air. In the demonstration below, you can also control the speed of that incoming air using the second slider:&lt;/p&gt;
    &lt;p&gt;While for slow flows, only a small amount of positive pressure is enough to stop the incoming air, for fast flows, the pressure in front of the airfoil has to become much higher.&lt;/p&gt;
    &lt;p&gt;The pressure needed to stop air at a given velocity is known as stagnation pressure and it’s proportional to the square of that velocity â twice as high speed requires four times larger pressure. Naturally, when there is no flow, no pressure is required as the air no longer tries to flow through the object.&lt;/p&gt;
    &lt;p&gt;In the previous two demonstrations, we manually adjusted the pressure to get the correct result, but in nature this process happens on its own â it’s the flow itself that creates this region of increased pressure in front of the object.&lt;/p&gt;
    &lt;p&gt;As the incoming parcels of air arrive at the surface of the airfoil, they can’t continue going forward, but air parcels from further up ahead continuously want to keep flowing into this region. This compresses the air close to the object, which causes the pressure in front to increase, which then helps to slow down the incoming flow.&lt;/p&gt;
    &lt;p&gt;This mechanism is self-balancing â if the pressure is too low to push away the incoming air parcels, the air parcels will compact the existing air more, causing an increase in pressure. If the pressure is too high, it will easily push the incoming air away, which relieves the frontal area, causing the pressure to decrease. Any fluctuations quickly settle to an equilibrium that balances the pressure in the entire frontal region.&lt;/p&gt;
    &lt;p&gt;Let’s look at the distribution of the positive frontal pressure once more:&lt;/p&gt;
    &lt;p&gt;Notice that the positive pressure isn’t limited to just the close vicinity of the airfoil, but it spreads out much further ahead to gradually reach the value of the static pressure, far away from the airfoil itself.&lt;/p&gt;
    &lt;p&gt;All in all, we have a large area of increasing pressure that starts far away from the body and ends at its surface. Those pressure differences create a pressure “hill” that not only gradually slows the incoming air down, but it also redirects that air to flow around the object.&lt;/p&gt;
    &lt;p&gt;It seems that with our frontal pressure field we’ve easily completed our goal of preventing the air from flowing through the walls of the body. However, our second guideline of non-crossing marker paths is still not fulfilled â this condition is broken above and below the airfoil.&lt;/p&gt;
    &lt;p&gt;Let’s first try to rectify this manually. In the demonstration below, you can control the pressure in these two regions using the slider:&lt;/p&gt;
    &lt;p&gt;While positive values of pressure in those zones make the problem worse, negative values get us much closer to the expected behavior â in the top and bottom areas the markers no longer veer off into different directions. However, that pressure can’t be too low, otherwise it will pull the markers back into the body.&lt;/p&gt;
    &lt;p&gt;In real flow, these regions of lower pressure arise on their own, but the explanation for this phenomenon is a little less straightforward than what I’ve described for the area of positive pressure in the frontal region. We can get some, albeit a bit hand-wavy, understanding by observing what happens to the air markers when those negative regions are missing.&lt;/p&gt;
    &lt;p&gt;In that scenario, the incoming air parcels no longer reach those areas above and below the airfoil, causing some local depletion of air that has since left those zones. This decreases the pressure in those regions, and that lower pressure attracts the surrounding air to flow into those less occupied spaces.&lt;/p&gt;
    &lt;p&gt;If that lower pressure is too negative, more air will come in and the pressure will rise. If the pressure is not negative enough, those region will get depleted again. Once again, it’s the flow itself that creates the balancing system â without the flow no pressure differences would arise.&lt;/p&gt;
    &lt;p&gt;As we’ll see later on, in more extreme scenarios that negative pressure can alter the flow more dramatically, and the regions of “missing” air get filled through other means, but for now let’s close things up by tweaking the pressure in the rear part of the airfoil:&lt;/p&gt;
    &lt;p&gt;Some amount of positive pressure in the rear prevents the air parcels from smashing into each other after leaving the airfoil. Intuitively, this pressure arises naturally from the flow, because as the air slides off from the ends of the top and bottom sides, it all arrives into the same region, creating some compression.&lt;/p&gt;
    &lt;p&gt;If that compressive pressure in the rear is too low, more air will manage to get in, which will further increase the pressure. If that pressure is too high, it will push the incoming air away, which depletes the area and the pressure decreases. The system balances itself yet again.&lt;/p&gt;
    &lt;p&gt;The quite informal description of these balances that I’ve presented can be formalized mathematically using the NavierâStokes equations. These equations describe the motion of liquids and gasses, collectively known as fluids, subject to various forces like gravity, or, most importantly for us, pressure.&lt;/p&gt;
    &lt;p&gt;NavierâStokes equations are notoriously difficult to solve analytically, but a lot of insight about the behavior of fluids can be gained with computer simulations with various degrees of complexity.&lt;/p&gt;
    &lt;p&gt;In this article, I’m also employing simulations to investigate the flow of air around objects. However, the computer models used here are quite simplified and they don’t reflect the full richness of physics involved in the motion of air. These slow-motion demonstrations are intended to present the broad strokes of the delicate interaction between the air and the airfoil, but I would advise against relying on them when building an airworthy airplane.&lt;/p&gt;
    &lt;p&gt;With all of these caveats in place, let’s get back to the pressure distribution around a symmetric airfoil. We’re done recreating the nature-made pressure field, but there is one small aspect that we haven’t yet accounted for.&lt;/p&gt;
    &lt;p&gt;For our experiments, I kept the pressure steady in time so that we could focus on its general outlines. In practice, a pressure field imposed by a fast flow around any object will experience some degree of instability, which you can see in the demonstration below. You can once more drop the markers at any location to track the flow in the area:&lt;/p&gt;
    &lt;p&gt;As the pressure builds up on one side, it redirects the flow, which changes the pressure again. The pressure ends up oscillating back and forth like a swing. The pressure distribution and the flow direction are once again at the mercy of their mutual balance, one affecting the other. We’ll soon see some other examples of these unstable behaviors.&lt;/p&gt;
    &lt;p&gt;As we’ve just seen, the variation in pressure doesn’t just happen in the close vicinity of the airfoil, but it stretches quite far away from the body itself. This means that the velocity of the flow is also affected quite far away from the shape.&lt;/p&gt;
    &lt;p&gt;However, when it comes to the forces exerted on the airfoil, it’s only the pressure right at the surface of the airfoil that matters. Let’s bring back the two tools we’ve used before: surface arrows that show how the air pushes or “pulls” on the airfoil, and the net force arrow that tallies up the net results of these forces:&lt;/p&gt;
    &lt;p&gt;As the pressure field fluctuates, the resulting net force also moves around. Let’s decompose this force into two different components, one perpendicular to the flow, and one parallel to it:&lt;/p&gt;
    &lt;p&gt;The force acting in the direction perpendicular to the flow is known as lift, and the one acting in the direction of the flow is known as pressure drag, or form drag. As the name implies, this component of drag is created by the distribution of pressure around the shape.&lt;/p&gt;
    &lt;p&gt;For this airfoil, the pressure drag is very tiny. While airfoils are specifically designed to minimize the overall drag, most of that force hindering their motion comes from another source â we’ll discuss it soon enough.&lt;/p&gt;
    &lt;p&gt;Notice that as this flow fluctuates, the lift force jumps around, but averaged over time the upward and downward swings of that force end up balancing each other. This airfoil in this configuration doesn’t generate any continuous lift.&lt;/p&gt;
    &lt;p&gt;This shouldn’t come as a surprise since this situation is completely symmetric, so the pressure forces on the upper and lower sides of the airfoil are, on average, completely balanced. However, there is an easy way to disturb that symmetry. In the demonstration below, we’re once again meeting the plain, symmetric airfoil, but this time we can gently tilt it using the slider:&lt;/p&gt;
    &lt;p&gt;The slider controls the so-called angle of attack, which is spanned between some reference line on the body, like the one joining the front and back, and the direction of the incoming flow. I’m showing this angle right in the middle of the airfoil.&lt;/p&gt;
    &lt;p&gt;As we change the angle of attack, the shape that the airflow “sees” is no longer symmetrical relative to the incoming direction of that flow. The velocity and pressure fields adapt in their mutual push and pull to form a new, asymmetric distribution. Notice that the stagnation point of high pressure has moved around, and the little markers that indicate the motion of air now travel on very different paths below and above and below the airfoil.&lt;/p&gt;
    &lt;p&gt;If we then put the pressure arrows back in, we can tally them all up to get the resulting lift and pressure drag. When compared to the previous simulation, I’m scaling down all the arrows to make them fit in the bounds of the demonstration:&lt;/p&gt;
    &lt;p&gt;When this symmetric airfoil is tilted up, the asymmetric pressure distribution generates a lift force that pushes the object up. Conversely, for a downward tilted airfoil, the pressure forces push the airfoil down.&lt;/p&gt;
    &lt;p&gt;Naturally, we’re typically interested in upward-pointing forces, and when the lift generated by the wings is equal to the weight of the plane, the plane will stay in the air without raising or falling to the ground â we’re finally flying.&lt;/p&gt;
    &lt;p&gt;Let’s plot the dependence between the lifting force and the angle of attack of an airfoil â you can see it in the right side of the demonstration below. Note that this plot presents time-averaged and settled values, so you may have to wait a little for the flow to normalize and the lift to start oscillating around the expected value:&lt;/p&gt;
    &lt;p&gt;Clearly, as the angle of attack increases, so does the generated lift. The same thing happens on the other end of the spectrum, where a more negative angle of attack creates more negative lift. Note that for this symmetric airfoil the positive and negative sides of the diagram are just mirror images of each other, so let’s focus only on positive angles of attack.&lt;/p&gt;
    &lt;p&gt;One could naively hope that we could keep increasing the angle of attack to generate more and more lift. Let’s see what happens in practice:&lt;/p&gt;
    &lt;p&gt;Initially, the lift force indeed keeps increasing with the angle of attack, but at some point it plateaus. Once that critical angle of attack is surpassed, the lift force starts to fall after the flow fully develops.&lt;/p&gt;
    &lt;p&gt;What we’re witnessing here is known as a stall. The onset of a stall imposes limits on how much lift the wings of an airplane can generate from merely increasing the angle of attack.&lt;/p&gt;
    &lt;p&gt;Notice that when the stall happens, the pressure distribution on the upper part of the airfoil becomes very erratic â it’s not only the surface pressure arrows that are changing rapidly, but the whole pressure field in that area is very disturbed.&lt;/p&gt;
    &lt;p&gt;Let’s bring in the velocity arrows and markers to get a better feel on what’s going on in that region:&lt;/p&gt;
    &lt;p&gt;At high angles of attack, the flow above the upper part of the airfoil becomes very complicated. If you clicktap in that region to drop a few markers, you’ll notice that the air is trapped in various swirling eddies that are eventually shed to fly away with rest of the flow.&lt;/p&gt;
    &lt;p&gt;We’re witnessing flow separation, where the main part of the flow detaches from the surface and doesn’t follow its shape anymore. The interactions in the complicated flow right above the airfoil affect the pressure field, which then decreases lift.&lt;/p&gt;
    &lt;p&gt;There is a lot going on there, but to understand how these effects arise we have to talk about a property that affects the flow of every fluid: viscosity.&lt;/p&gt;
    &lt;head rend="h1"&gt;Viscosity&lt;/head&gt;
    &lt;p&gt;You might have heard the term viscosity used to describe “thickness” of different liquids, with a classic example that contrasts the slowness of the flow of honey to the rapidness of the flow of water.&lt;/p&gt;
    &lt;p&gt;Viscosity is also a property of gasses like air, but before I describe this concept more formally, we’ll first build an intuitive understanding of what viscosity is and what it does to the flow of different fluids.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, the fluid flows in from the left side, but note that the flow in the top half is faster than the flow in the bottom half, which is reflected by the different lengths of the arrows. Dragging the slider to the left decreases the viscosity of the fluid, and dragging the slider to the right increases viscosity:&lt;/p&gt;
    &lt;p&gt;While we can see some changes to the arrows as we move the slider around, you probably agree that, for this flow, the arrow-based visualization isn’t very rewarding. Let’s add the color-based visualization of speed distribution in this flow:&lt;/p&gt;
    &lt;p&gt;We can now see how viscosity blends the speed variation between different sections of the fluid. For highly viscous fluids, this mixing behavior spreads very easily and the initially distinct velocities of the two layers average out quite rapidly.&lt;/p&gt;
    &lt;p&gt;At lower viscosity these two layers with different speeds remain quite separated. If you make the viscosity low enough, you may even notice that, after a while, the flow develops some interesting wave-like phenomena â we’ll get back to these soon.&lt;/p&gt;
    &lt;p&gt;All this mixing behavior may remind you of a diffusion process, where some quantity, like temperature or concentration, evens out over time. Let’s see some basic diffusion in action. In the simulation below, I filled half of the bottle with with red-dyed water, while the other half is filled with blue-dyed water. The slider lets you control the speed of time:&lt;/p&gt;
    &lt;p&gt;As time passes, the sharp difference between the two layer blends more and more to eventually completely disappear. Clearly, there is some similarity between the diffusion of differently colored dyes and the averaging of velocity that we’ve seen in the earlier example.&lt;/p&gt;
    &lt;p&gt;In our flow demonstrations, viscosity seemed to have controlled the diffusion of velocity. To define it more precisely, viscosity controls the diffusion of momentum, which is a product of velocity and mass. The simplified fluids we’re looking at have more or less constant density, so each equally-sized parcel of those fluids has the same mass. Therefore, if it makes things easier for you, wherever you see the word momentum you can think of velocity, but in more complex scenarios these differences can matter.&lt;/p&gt;
    &lt;p&gt;Let me bring in the previous flow simulation one more time:&lt;/p&gt;
    &lt;p&gt;You’ve probably noticed that, as the flow moves to the right, the size of this blended region increases. When the regions of fluid with different momentums meet for the first time, they barely have any time to average out, and the blending is minimal. As time passes, these regions of fluid get to average out more, similarly to how two different layers of dyed water mix more over time.&lt;/p&gt;
    &lt;p&gt;However, as time is passing, these parcels also keep moving, and that stronger blending happens further to the right. The downstream regions had more time to mix and average out, so the visible thickness of the blended region on the right side is also larger.&lt;/p&gt;
    &lt;p&gt;With higher viscosity, the size of blended region grows much more quickly, which lets us be more precise about our working definition â viscosity controls the rate of the diffusion of momentum.&lt;/p&gt;
    &lt;p&gt;So far we’ve only observed flows with nicely separated horizontal layers, but viscosity averages momentum between any two regions of fluids. In the demonstration below, you can witness how viscosity affects a swirly motion of fluid in a vortex:&lt;/p&gt;
    &lt;p&gt;Notice that with high viscosity any differences in velocity are very quickly diluted out into nothing, but with low viscosity the revolving motion can survive for quite a while.&lt;/p&gt;
    &lt;p&gt;Viscosity has a damping or smoothing effect that makes it much harder to sustain any large variation in a velocity field. Let’s see how this affects the motion of objects in fluids of various viscosity. In the demonstration below, we’re tracking a velocity field close to a very thin plate put directly in the stream of an incoming fluid of adjustable viscosity:&lt;/p&gt;
    &lt;p&gt;With high viscosity, there is a large region of slow down around the plate that regains its speed fairly quickly behind the object. At lower viscosity that surrounding region is much smaller, but it extends much further behind the plate. For very low viscosity we’re once again seeing some more unusual behavior that we’ll get back to in a minute.&lt;/p&gt;
    &lt;p&gt;From the dark colors we can easily see that right by the surface of the plate the fluid doesn’t move at all â it sticks to that surface. This velocity difference between the halted flow at the wall and the moving outer flow gets smoothed out over time by viscosity, similar to how it blended in the flow between two different layers of fluid.&lt;/p&gt;
    &lt;p&gt;As before, with higher viscosity, the velocity averaging process becomes more rapid, and the blended region becomes more widespread. This averaging effect doesn’t just alter the velocity of fluid, but it also affects the plate. In some sense, the viscosity also wants to make the velocity of the surface of the plate to be more like the velocity of the surrounding flow.&lt;/p&gt;
    &lt;p&gt;The viscosity makes the flow want to pull the plate with it, which creates a shearing force that tries to slide the surface of this object away. The net effect is that that viscosity creates additional drag known as skin friction drag that wants to slow down any object moving in it.&lt;/p&gt;
    &lt;p&gt;All of these effects underline why highly viscous fluids are “thick”. Viscosity not only quickly averages any local differences in velocity, which prevents those fluids from flowing easily, but it also represses motion of objects in those fluids â you’ve likely experienced the difficulty of moving a spoon through a jar of honey.&lt;/p&gt;
    &lt;p&gt;The flow of any fluid exhibits tiny, random disturbances. In fluids with high viscosity, these variations are very quickly dispersed, so their motion is rarely erratic. Fluids with low viscosity aren’t as effective at damping motion, and these disturbances can grow to create oscillatory patterns. We’ve seen glimpses of them in the previous simulations, but here is another example:&lt;/p&gt;
    &lt;p&gt;At lower viscosity the flow becomes quite wave-y. Those instabilities happen at the border of regions of fluid with different velocities, like where the slow wake behind a plate is in contact with the fast external flow. In those regions, any tiny random intrusion of slower flow into the faster flow can get magnified and rolled over like a wave.&lt;/p&gt;
    &lt;p&gt;In our discussion of the motion of air around an airfoil, we’ve seen how the flow, the pressure field, and the shape of the body have effects on each other. These influences can be quite dynamic in nature, with distributions of velocity and pressure swinging back and forth in a never-ending fight for dominance.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, we can see a more dramatic example of these battles, where, depending on the viscosity, the flow around a gray cube can take many different forms:&lt;/p&gt;
    &lt;p&gt;With very high viscosity, the flow is completely stable, but as viscosity decreases, it starts to regularly oscillate from side to side, shedding vortices in the process. At very low viscosity, the motion becomes even more erratic.&lt;/p&gt;
    &lt;p&gt;While I can’t easily simulate it here, with further decrease in viscosity, the flow can develop full featured turbulence in which highly irregular and chaotic mixing motions occur at different scales. Turbulent flow stands in contrast to laminar flow, in which neighboring areas of fluid move in an orderly way past each other without any varying fluctuations.&lt;/p&gt;
    &lt;p&gt;Although we’ve put most of our focus on viscosity, which is often denoted with the Greek letter Î¼, the general behavior of the flow also depends on its velocity u, density Ï, and the size L of the body or container involved in the flow. These parameters are tied together by the Reynolds number Re:&lt;/p&gt;
    &lt;p&gt;Flows with the same Reynolds numbers exhibit similar behavior, which means that if we make the obstacle size L twice as large and we halve the speed of the flow u, the Reynolds number won’t change and neither will the characteristics of the flow â it will exhibit the same smooth or oscillatory motion.&lt;/p&gt;
    &lt;p&gt;The Reynolds number also “predicts” the onset of turbulence. When we increase the speed of the flow u, or decrease the viscosity Î¼, the Reynolds number rises. When it reaches a high enough value, turbulence is likely to occur.&lt;/p&gt;
    &lt;p&gt;Let’s quantify the difference in viscosity between different fluids. The precise values aren’t that important to us, but to briefly be a bit more formal, viscosity is expressed in units of pascal-seconds, or PaÂ·s. To let us use more manageable numbers, the following table uses millipascal-seconds, or mPaÂ·s:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;honey&lt;/cell&gt;
        &lt;cell&gt;~10000 mPa·s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;olive oil&lt;/cell&gt;
        &lt;cell&gt;~100 mPa·s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;water&lt;/cell&gt;
        &lt;cell&gt;1.0 mPa·s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;air&lt;/cell&gt;
        &lt;cell&gt;0.018 mPa·s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These values are measured at 68 Â°F20 Â°C, but many fluids like oil get much less viscous with increased temperature. As expected, honey is significantly more viscous than water. Compared to water, the viscosity of air is around 50 times less still, but even a very low viscosity has effects on flow and its interaction with solid walls.&lt;/p&gt;
    &lt;p&gt;To understand how viscosity arises in gasses like air, we have to once more get back to the world of particles. So far we’ve been watching them from a distance, with individual collisions barely perceptible in the moving swarm. This time we’re going take a closer look at these interactions.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, you can experience a simplified simulation of two molecules colliding in space. Each molecule represents nitrogen or oxygen â these two elements constitute the vast majority of air, and, in normal conditions, each one consists of two atoms.&lt;/p&gt;
    &lt;p&gt;You can drag the orange particle around, and once you let go I’ll automatically aim it so that it hits the blue particle. The speed of the orange molecule is four times larger than the speed of the blue one:&lt;/p&gt;
    &lt;p&gt;Notice that after the collision, it’s the orange molecule that’s slow, and it’s the blue one that’s fast. In this demonstration the two particles have the same mass and they collide straight on, so they simply end up trading velocities.&lt;/p&gt;
    &lt;p&gt;More generally, particles of different masses that strike each other at different angles will exchange some amount of momentum. Recall that the heavier the particle, or the faster it moves, the higher its momentum.&lt;/p&gt;
    &lt;p&gt;Let’s see how this behavior ends up affecting the average velocities of larger quantities of molecules. In the paused demonstration below, air molecules are grouped into two different parts. The air in the blue region has higher velocity than the air in the red region, which you can see in the black arrows showing the average velocity in those regions. Notice what happens to these averages as you let time flow by dragging the slider:&lt;/p&gt;
    &lt;p&gt;At the very beginning, the average velocities in these two sections are visibly different, but they quickly even out when fast particles from the blue region flow into the slower red region, and the slower particles from the red region move into the faster blue region, balancing the initial velocity differences.&lt;/p&gt;
    &lt;p&gt;Moreover, some of the faster particles collide with slower particles in the red region and some of the slower particles collide with faster particles from above. The faster particles lose some of their higher momentum, while the slower particles gain some of the momentum. All of these effects “dilute” some of those average velocity differences between the two regions.&lt;/p&gt;
    &lt;p&gt;You may also remember that when we observed a flow of fluid around a flat plate, that fluid wasn’t moving at all right on the surface of that plate, because it was stuck to it. Let’s see how this behavior may arise on a microscopic scale.&lt;/p&gt;
    &lt;p&gt;In the demonstration below, we’re watching the familiar air particles right next to the surface of an object. To make tracking easier, I’m highlighting some of the particles in the vicinity of this surface:&lt;/p&gt;
    &lt;p&gt;When seen at a very large magnification, this surface, like almost all surfaces, isn’t perfectly smooth and has various peaks and valleys. The particles hitting these irregularities get bounced in more or less random directions. Some of the unlucky molecules can even get stuck for a while in these local crevices.&lt;/p&gt;
    &lt;p&gt;Close to the surface, the random collisions with peaks and valleys prevent the particles from making bulk progress in any direction. The average velocity of the air flow by the wall is more or less zero. Some molecular interactions between the particles and the surface can also prevent the fluid from moving.&lt;/p&gt;
    &lt;p&gt;This sticking behavior is known as the noâslip condition and it holds true for most typical flows of fluids that we experience day to day. It’s only in extreme conditions of very rarified gasses in the upper parts of the atmosphere or flows in microscopic capillaries that can break this assumption.&lt;/p&gt;
    &lt;p&gt;Let’s leave the world of particles behind for the last time and see how these two effects play an important role of influencing the airflow close to the surface of any object.&lt;/p&gt;
    &lt;head rend="h1"&gt;Boundary Layer&lt;/head&gt;
    &lt;p&gt;Let’s take another look at a thin plate placed in the stream of incoming fluid:&lt;/p&gt;
    &lt;p&gt;From this broader perspective, it’s hard to see how the flow interacts with the surface of that plate, because the effects of viscosity are limited to the region close to that surface. Let’s focus our attention on the small area that I’ve outlined with a dashed line, right in the top part of the plate. Here it is zoomed up close:&lt;/p&gt;
    &lt;p&gt;We can once more see that, due to the no-slip condition, the velocity is zero at the wall, and then it grows to meet the velocity of the flow further away from the surface itself. What we’re seeing here is known as the boundary layer, which spans the region between the surface of the object and the “outer” flow, which is mostly unaffected by the presence of the object.&lt;/p&gt;
    &lt;p&gt;Because the velocity in the boundary layer smoothly approaches the speed of the outer flow, it doesn’t have a well-defined end point. One of the choices is to agree that the boundary layer ends where the speed reaches 99% of the speed of the surrounding flow far away from the solid surface. Let me visualize this boundary in the flow using a dashed line:&lt;/p&gt;
    &lt;p&gt;As we move with the flow along the distance of the plate, the viscosity keeps averaging out the velocity differences, making the boundary layer thicker â this is similar to what we’ve seen at larger scales with highly viscous flows around objects.&lt;/p&gt;
    &lt;p&gt;Let’s quantify the distribution of speed in the boundary layer a little more precisely. In the demonstration below, I put the velocity arrows back in. I then connected the ends of these arrows with a thin line to show a profile of velocity at that location along the surface:&lt;/p&gt;
    &lt;p&gt;Notice that, initially, the velocity close to the wall increases almost linearly, but then it smoothly tapers to reach the speed of the external flow. The velocity profile close to the surface has a certain steepness, which I’m showing with the white dotted line. This line determines the amount of skin friction drag at that spot â the closer to the surface, or more horizontal, the line is, the higher the skin drag.&lt;/p&gt;
    &lt;p&gt;As the differences in velocity become less severe, the force with which viscosity wants to drag the surface with the flow also decreases. In the conditions present in the demonstration, the skin friction drag decreases over distance.&lt;/p&gt;
    &lt;p&gt;At this point you hopefully have an intuitive grasp of how viscosity affects the flow close to the surface of the object. From our earlier discussion, you may also remember that pressure differences also affect how the flow behaves, with parcels of air slowing down when climbing the hill of increasing pressure and accelerating on the downhill of the decreasing pressure.&lt;/p&gt;
    &lt;p&gt;In the boundary layer flows we played with, the pressure distribution was more or less constant in the investigated region. Let’s see how the flow changes when we vary that pressure.&lt;/p&gt;
    &lt;p&gt;In the top part of the demonstration below we see the exact same view of velocity we’ve experimented with so far. In the bottom part of the demonstration below you can see the pressure distribution in the boundary layer, which you can change using the slider below.&lt;/p&gt;
    &lt;p&gt;If the pressure decreases in the direction of the flow in the boundary layer, we say that the pressure gradient is favorable. Favorable pressure gradient accelerates the air, and the boundary layer doesn’t grow as quickly, since the slowdown caused by viscosity is opposed by that acceleration.&lt;/p&gt;
    &lt;p&gt;When the pressure increases in the direction of the flow, we say that the pressure gradient is adverse. Adverse pressure gradient pushes against the direction of motion of the air. Far away from the surface, the air has enough momentum that the adverse pressure merely slows the flow down. However, close to the surface, the flow in the boundary layer was slow in the first place, so a pushing adverse pressure gradient may even reverse the direction of the flow.&lt;/p&gt;
    &lt;p&gt;When the flow in the boundary layer gets reversed, we say that the boundary layer separates. This region of reversed flow can form a sort of wedge that can lift the rest of the flow away from the surface.&lt;/p&gt;
    &lt;p&gt;Let’s take a step back from the subtleties of boundary layers to see how what we’ve learned corresponds to behavior of a flow around an airfoil. Let me once more bring up the demonstration that brought us here in the first place:&lt;/p&gt;
    &lt;p&gt;As we move across the surface of the airfoil, the high pressure at the stagnation point up front gradually decreases to reach minimum close to the “peak” of that curved surface. Across this transition the pressure gradient is favorable, and that distribution works in our favor â the boundary layer stays nicely attached to the surface.&lt;/p&gt;
    &lt;p&gt;However, as the air reaches the valley of the lowest pressure, it then has to start climbing back up to reach the slightly positive pressure in the rear of the airfoil. For small values of the angle of attack, the pressure pit from which the air has to climb out is not very deep and the adverse pressure gradient isn’t very strong, so the boundary layer remains attached.&lt;/p&gt;
    &lt;p&gt;As we increase the angle of attack of the airfoil, the pressure on top becomes lower and lower. For even higher angles, the adverse pressure gradient becomes so strong that it eventually reverses the flow in the boundary layer, creating separation. Let’s look at this region up close to see how the arrows of velocity in the separated region point in the other direction:&lt;/p&gt;
    &lt;p&gt;If you clicktap to add markers in the bottom right corner of the simulation you’ll notice that many of them move against the bulk of the flow â the boundary layer and the flow have separated.&lt;/p&gt;
    &lt;p&gt;We’ll get back to looking at airfoils soon enough, but we still have a few things to wrap up in the world of boundary layers.&lt;/p&gt;
    &lt;p&gt;The boundary layers we’ve looked at so far were laminar â the layers of fluid with different velocities flowed in an orderly way on top of each other. However, at higher flow speeds and over larger distances, or at high Reynolds numbers, the flow in the boundary layer transitions to a turbulent flow:&lt;/p&gt;
    &lt;p&gt;Be aware that what you’re seeing here is a very simplified simulation of a turbulent boundary layer. Turbulence is inherently three dimensional and it contains various evolving structures of different sizes that are extremely computationally expensive to evaluate in detail. Thankfully, you can find many videos of computer simulations and real flows showing turbulent boundary layers.&lt;/p&gt;
    &lt;p&gt;While the laminar boundary layers we’ve seen in the past exhibited very organized flows, the turbulent one is very chaotic, with large and small swirls causing the flow to mix very rapidly. The transition from laminar to turbulent boundary layer happens spontaneously, but for a given flow speed, the location of the transition depends on surface roughness, steadiness of the flow outside of the boundary layer, and presence of pressure gradients.&lt;/p&gt;
    &lt;p&gt;At any given moment, the velocity profile in the turbulent boundary layer is very unsteady, but it can be averaged over time to get the mean distribution of speed. Let’s compare the time-averaged profiles of the laminar and turbulent boundary layers:&lt;/p&gt;
    &lt;p&gt;In the dynamic simulation of the turbulent boundary layer, we saw how the slower flow close to the surface rapidly mixed with the upper regions of the flow. This slows down those faster sections, and we need to go farther away from the surface for these sluggish intrusions to stop affecting the flow. For this reason, the turbulent boundary layer is thicker and grows faster than a laminar boundary layer.&lt;/p&gt;
    &lt;p&gt;On the other hand, the strong turbulent mixing causes the fast external flow to get close to the body, so the overall velocity profile by the surface increases much more quickly in the turbulent case as opposed to laminar case â I’m showing that with white dotted lines.&lt;/p&gt;
    &lt;p&gt;Recall that the more horizontal the velocity profile at the surface of the object, the bigger the skin friction drag â a turbulent boundary layer has higher skin friction drag than a laminar layer. Despite the cost of increased friction drag, a turbulent boundary layer is often beneficial.&lt;/p&gt;
    &lt;p&gt;Because of that higher velocity closer to the surface, a turbulent boundary layer is more resistant to adverse pressure gradients and it can stay attached to the surface of an object for longer distances.&lt;/p&gt;
    &lt;p&gt;For some objects like golf balls, which purposefully make their boundary layer turbulent by roughing up the surface with little dimples, the delayed separation also decreases the pressure drag caused by uneven pressure distribution. That reduction more than compensates for the increased skin friction drag, making the dimply golf balls fly farther than equivalent smooth balls.&lt;/p&gt;
    &lt;p&gt;For airfoils, a turbulent boundary layer delays separation of the flow, which can help prevent stall at higher angles of attack, but at normal cruising conditions the increased skin friction becomes an important drawback. For many aerodynamic shapes in typical conditions, the skin friction drag is the primary contributor to the total drag that these objects experience.&lt;/p&gt;
    &lt;p&gt;As we’ve seen, by increasing the angle of attack on an airfoil, the lift force grows up to a certain limit, at which the boundary layer separates over most of the upper surface. By staying under this limit, a symmetric airfoil can safely generate lift force.&lt;/p&gt;
    &lt;p&gt;However, when it comes to angle of attack and lift, the shape of an airfoil isn’t particularly unique in its lift-creation capabilities. Most simple elongated shapes generate lift when put in a flow at an angle of attack. In the demonstration below, you can tilt a flat plate and see the forces exerted by the pressure field around it:&lt;/p&gt;
    &lt;p&gt;You may be surprised to see that, at small angles of attack, this flat plate also generates lift. An airfoil-like shape is not a requirement for lift generation. After all, paper airplanes with their flat wings can fly just fine. Lift is just an outcome of the pressure distribution created and sustained by the flow.&lt;/p&gt;
    &lt;p&gt;Although it doesn’t take a sophisticated shape to generate lift at an angle of attack, a well-designed airfoil can often create more lift and with lower drag. In the last section of this article, we’ll explore how other variations to the shape of an airfoil can affect its characteristics.&lt;/p&gt;
    &lt;head rend="h1"&gt;Airfoil Shapes&lt;/head&gt;
    &lt;p&gt;Let’s go back to the simple symmetric airfoil we’ve been playing with thus far. This time, however, we’re able to control its thickness using the slider:&lt;/p&gt;
    &lt;p&gt;Notice that as we increase the thickness of the airfoil, the pressure on the top and bottom sections of the shape becomes more negative. For this symmetric airfoil at 0Â° angle of attack the thickness doesn’t change much other than increasing the pressure drag.&lt;/p&gt;
    &lt;p&gt;However, if we break the symmetry of the shape, we can use thickness-dependence to make one side of the airfoil have a higher negative pressure than the other. In the demonstration below, you can control the “thickness” of the upper surface of the airfoil using the slider:&lt;/p&gt;
    &lt;p&gt;Notice that an asymmetric shape creates an asymmetric pressure distribution, which ends up creating lift without any changes to angle of attack. With some slight tweaking of this shape we finally recreated the asymmetric shape we first saw on the airplane in the early sections of this article.&lt;/p&gt;
    &lt;p&gt;Naturally, when combined with an increasing angle of attack, this airfoil will generate even more lift until it eventually reaches stalling conditions:&lt;/p&gt;
    &lt;p&gt;While symmetric airfoils are sometimes used in acrobatic airplanes, which often find themselves flying upside down, most typical planes use an asymmetric airfoil shape.&lt;/p&gt;
    &lt;p&gt;The underlying mechanism of lift generation by changing the angle of attack or by shaping the object differently is ultimately the same â we’re changing the placement and orientation of the surface of the body relative to the incoming flow. The flow reacts by changing the velocity and pressure distribution, and the resulting pressure field creates the forces on that object.&lt;/p&gt;
    &lt;p&gt;This all means that we have a lot of flexibility in how an airfoil is shaped, as long as the resulting pressure distribution fulfills the design goals of achieving a certain amount of lift while minimizing drag.&lt;/p&gt;
    &lt;p&gt;For example, in some applications it’s important to minimize the skin friction drag caused by a turbulent boundary layer. Some laminar flow airfoils achieve this by shaping the airfoil to move the “pit” of negative pressure further to the back of the airfoil:&lt;/p&gt;
    &lt;p&gt;The favorable pressure gradient between the front and the lowest pressure point extends over a longer distance across the surface of this airfoil, which, at least in principle, helps to keep the boundary layer laminar to keep the skin friction low.&lt;/p&gt;
    &lt;p&gt;Notice that even this unusual airfoil had a rounded front and a sharp back. The roundness of the front helps the air smoothly flow around this area at different angles of attack, and the sharp back reduces the pressure drag by avoiding the separation of the flow.&lt;/p&gt;
    &lt;p&gt;The velocity of the flow around the airfoil is also a contributing factor to the design of the shape. Let’s look at the speed distribution in the flow around a simple asymmetric airfoil using the varying colors and markers:&lt;/p&gt;
    &lt;p&gt;The flow above the airfoil is faster than the incoming flow as indicated by brighter colors. The markers that start in the same line don’t end up sliding off the airfoil in the same formation â the ones on top are further ahead. This is particularly visible for larger values of the angles of attack.&lt;/p&gt;
    &lt;p&gt;This acceleration in the upper part becomes another point of consideration for airfoil design. While commercial airliners don’t fly faster than the speed of sound, the accelerated flow in the top part of an airfoil can break that barrier. This creates a shockwave that can sometimes be seen in flight. Modern airliners use supercritical airfoils that are designed to reduce these drag-causing shockwaves by carefully controlling the speed of the flow around the wing.&lt;/p&gt;
    &lt;p&gt;Planes designed to fly above the speed of sound use supersonic airfoils that are quite different from the shapes we’ve seen. These airfoils have a thin profile and their front edge is sharp and not rounded. Supersonic flows of air are more complicated than what we’ve explored in this article, as variations in density and temperature become an important component of the behavior of the flow.&lt;/p&gt;
    &lt;p&gt;Many of the airfoils used today are designed specifically for the plane they’ll be used in. Moreover, that cross-sectional shape may change across the length of the wing. Real airplanes are three dimensional and the overall shape of the wings also significantly affects the lift and drag of an airplane, but ultimately all the resulting forces are an outcome of interactions between the flow and the body.&lt;/p&gt;
    &lt;head rend="h1"&gt;Further Reading and Watching&lt;/head&gt;
    &lt;p&gt;John Anderson’s Fundamentals of Aerodynamics is a very well-written textbook on aerodynamics. Over the course of over a thousand pages, the author presents a classic exposition of the motion of fluids and their interactions with bodies put in those flows.&lt;/p&gt;
    &lt;p&gt;Understanding Aerodynamics by Doug McLean is a great textbook that takes a different approach of explaining aerodynamic phenomena using physical reasoning. For me, the crowning achievement of the publication is showing that many popular explanations of the origins of lift are either incorrect or they’re based on merely mathematically convenient theorems. The author’s video lecture gives an overview of some of these misconceptions.&lt;/p&gt;
    &lt;p&gt;In this article, I’m using computational fluid dynamics to simulate the flow of air around different objects. For an approachable introduction to these methods I enjoyed Tony Saad’s series of lectures on the topic. For an alternative, and slightly more rigorous approach, Lorena Barba created 12 steps to Navier-Stokes. That website is also accompanied by video lectures.&lt;/p&gt;
    &lt;p&gt;Finally, YouTuber braintruffle created a series of beautiful videos that start with the behavior of fluids on a quantum scale and build up increasingly abstract models that can be used in more practical applications. The videos are packed with interesting takes on fluid mechanics, and they’re worth watching for their visuals alone.&lt;/p&gt;
    &lt;head rend="h1"&gt;Final Words&lt;/head&gt;
    &lt;p&gt;If you were to sit on a flying airplane and look out the window to glance at its wings, you’d often have a hard time seeing anything going on. However, in that crisp clearness of air whose invisible flow sustains the varied pressure field, lies the hidden source of lift that overcomes the might of gravity to keep the plane safely above the ground.&lt;/p&gt;
    &lt;p&gt;Since the first human flight, we’ve now mastered the art of soaring in the skies by bending the flow of air to our will, using physical quantities like pressure and velocity to help shape our designs. These tangible concepts are ultimately just a manifestation of motions and collisions of billions of inanimate air particles that somehow conspire to assemble the forces we need.&lt;/p&gt;
    &lt;p&gt;I hope this deeper, technical exploration of airfoils hasn’t diminished your appreciation of the greatness of flight. Perhaps paradoxically, by seeing how all the pieces fit together, you’ll find the whole thing even more magical.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46795908</guid><pubDate>Wed, 28 Jan 2026 14:32:30 +0000</pubDate></item><item><title>Apple to soon take up to 30% cut from all Patreon creators in iOS app</title><link>https://www.macrumors.com/2026/01/28/patreon-apple-tax/</link><description>&lt;doc fingerprint="a48ccb0c510e1558"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h1"&gt;Apple to Soon Take Up to 30% Cut From All Patreon Creators in iOS App&lt;/head&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;p&gt;Apple has set a new deadline of November 1, 2026 for all Patreon creators to switch from Patreon's legacy billing system to the App Store's in-app purchase system in the Patreon app on the iPhone and iPad, as reported by TechCrunch.&lt;/p&gt;
          &lt;div&gt;Note: This image has been edited to include a pile of cash.&lt;/div&gt;
          &lt;p&gt;Patreon is a platform where creators such as YouTubers can receive payments from fans, which can be a valuable revenue stream alongside ads and sponsorships. &lt;/p&gt;
          &lt;p&gt;Apple initially told Patreon that its creators must move to the App Store's in-app purchase system by November 2025, or else Patreon would risk removal from the App Store, but the deadline was pushed back. Apple considers payments from supporters to creators on Patreon to be digital goods that it is entitled to receive a commission on.&lt;/p&gt;
          &lt;p&gt;Apple receives a 30% commission on in-app purchases and subscriptions, but this drops to 15% for a subscription that has been ongoing for more than a year.&lt;/p&gt;
          &lt;p&gt;Patreon gives creators the option to either increase their prices in the iOS app only, or absorb the fee themselves, keeping prices the same across platforms.&lt;/p&gt;
          &lt;p&gt;On the iPhone and iPad, Patreon users who wish to support a creator can sidestep the App Store's commission by completing their payment via Patreon's website.&lt;/p&gt;
          &lt;p&gt;Patreon said it is disappointed with how Apple has navigated this policy.&lt;/p&gt;
          &lt;p&gt;According to TechCrunch, only 4% of Patreon creators are still using the platform's legacy billing system, with the rest having already switched over.&lt;/p&gt;
          &lt;p&gt;Patreon has shared a FAQ with more details for creators.&lt;/p&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;head rend="h2"&gt;Popular Stories&lt;/head&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple today introduced its first two physical products of 2026: a second-generation AirTag and the Black Unity Connection Braided Solo Loop for the Apple Watch. Read our coverage of each announcement to learn more:Apple Unveils New AirTag With Longer Range, Louder Speaker, and More Apple Introduces New Black Unity Apple Watch BandBoth the new AirTag and the Black Unity Connection Braided...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Alongside iOS 26.2.1, Apple today released an updated version of iOS 12 for devices that are still running that operating system update, eight years after the software was first released. iOS 12.5.8 is available for the iPhone 5s and the iPhone 6, meaning Apple is continuing to support these devices for 13 and 12 years after launch, respectively. The iPhone 5s came out in September 2013,...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple today introduced the second-generation AirTag, with key features including longer range for tracking items and a louder speaker. For those who are not familiar, the AirTag is a small accessory that you can attach to your backpack, keys, or other items. Then, you can track the location of those items in the Find My app on the iPhone, iPad, Mac, Apple Watch, and iCloud.com. The new...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Update: Apple Creator Studio is now available. Apple Creator Studio launches this Wednesday, January 28. The all-in-one subscription provides access to the Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor, and MainStage apps, with U.S. pricing set at $12.99 per month or $129 per year. A subscription to Apple Creator Studio also unlocks "intelligent features" and "premium...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;2026 promises to be yet another busy year for Apple, with the company rumored to be planning more than 20 product announcements over the coming months. Beyond the usual updates to iPhones, iPads, Macs, and Apple Watches, Apple is expected to release its all-new smart home hub, which was reportedly delayed until the more personalized version of Siri is ready. Other unique products rumored for ...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46801419</guid><pubDate>Wed, 28 Jan 2026 20:59:30 +0000</pubDate></item><item><title>Tesla ending Models S and X production</title><link>https://www.cnbc.com/2026/01/28/tesla-ending-model-s-x-production.html</link><description>&lt;doc fingerprint="20590dc3996f17b"&gt;
  &lt;main&gt;
    &lt;p&gt;Tesla CEO Elon Musk said on Wednesday that the automaker is ending production of its Model S and X vehicles, and will use the factory in Fremont, California, to build Optimus humanoid robots.&lt;/p&gt;
    &lt;p&gt;"It's time to basically bring the Model S and X programs to an end with an honorable discharge," Musk said on the company's fourth-quarter earnings call. "If you're interested in buying a Model S and X, now would be the time to order it."&lt;/p&gt;
    &lt;p&gt;After the original Roadster, the two models are Tesla's oldest vehicles, and in recent years the company has slashed prices as global competition for electric vehicles has soared. Tesla started selling the Model S sedan in 2012, and the Model X SUV three years later.&lt;/p&gt;
    &lt;p&gt;On Tesla's website, the Model S currently starts at about $95,000, while the Model X starts at around $100,000&lt;/p&gt;
    &lt;p&gt;Tesla's far more popular models are the 3 and Y, which accounted for 97% of the company's 1.59 million deliveries last year. The Model 3 now starts at about $37,000, and the Model Y is around $40,000. Tesla debuted more affordable versions of the vehicles late last year.&lt;/p&gt;
    &lt;p&gt;In its earnings announcement on Wednesday, Tesla reported its first annual revenue decline on record, with sales falling in three of the past four quarters. Musk has been trying to turn attention away from traditional EVs and toward a future of driverless cars and humanoid robots, areas where the company currently has virtually no business.&lt;/p&gt;
    &lt;p&gt;Tesla is developing Optimus with the aim of someday selling it as a bipedal, intelligent robot capable of everything from factory work to babysitting. The company said in the release that it plans to unveil the third generation of Optimus this quarter, its "first design meant for mass production."&lt;/p&gt;
    &lt;p&gt;Musk said on the call that Tesla is replacing its production line for S and X in Fremont "with a 1 million unit per year line of Optimus."&lt;/p&gt;
    &lt;p&gt;"Because it is a completely new supply chain," Musk said, "there's really nothing from the existing supply chain that exists in Optimus."&lt;/p&gt;
    &lt;p&gt;Tesla expects to boost headcount at the Fremont facility, Musk added, "and to significantly increase output."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46802867</guid><pubDate>Wed, 28 Jan 2026 22:53:54 +0000</pubDate></item><item><title>Render Mermaid diagrams as SVGs or ASCII art</title><link>https://github.com/lukilabs/beautiful-mermaid</link><description>&lt;doc fingerprint="27182a7a4f4986aa"&gt;
  &lt;main&gt;
    &lt;p&gt;Render Mermaid diagrams as beautiful SVGs or ASCII art&lt;/p&gt;
    &lt;p&gt;Ultra-fast, fully themeable, zero DOM dependencies. Built for the AI era.&lt;/p&gt;
    &lt;p&gt;Diagrams are essential for AI-assisted programming. When you're working with an AI coding assistant, being able to visualize data flows, state machines, and system architecture—directly in your terminal or chat interface—makes complex concepts instantly graspable.&lt;/p&gt;
    &lt;p&gt;Mermaid is the de facto standard for text-based diagrams. It's brilliant. But the default renderer has problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Aesthetics — Might be personal preference, but wished they looked more professional&lt;/item&gt;
      &lt;item&gt;Complex theming — Customizing colors requires wrestling with CSS classes&lt;/item&gt;
      &lt;item&gt;No terminal output — Can't render to ASCII for CLI tools&lt;/item&gt;
      &lt;item&gt;Heavy dependencies — Pulls in a lot of code for simple diagrams&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We built &lt;code&gt;beautiful-mermaid&lt;/code&gt; at Craft to power diagrams in Craft Agents. It's fast, beautiful, and works everywhere—from rich UIs to plain terminals.&lt;/p&gt;
    &lt;p&gt;The ASCII rendering engine is based on mermaid-ascii by Alexander Grooff. We ported it from Go to TypeScript and extended it Thank you Alexander for the excellent foundation! (And inspiration that this was possible.)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;5 diagram types — Flowcharts, State, Sequence, Class, and ER diagrams&lt;/item&gt;
      &lt;item&gt;Dual output — SVG for rich UIs, ASCII/Unicode for terminals&lt;/item&gt;
      &lt;item&gt;15 built-in themes — And dead simple to add your own&lt;/item&gt;
      &lt;item&gt;Full Shiki compatibility — Use any VS Code theme directly&lt;/item&gt;
      &lt;item&gt;Live theme switching — CSS custom properties, no re-render needed&lt;/item&gt;
      &lt;item&gt;Mono mode — Beautiful diagrams from just 2 colors&lt;/item&gt;
      &lt;item&gt;Zero DOM dependencies — Pure TypeScript, works everywhere&lt;/item&gt;
      &lt;item&gt;Ultra-fast — Renders 100+ diagrams in under 500ms&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;npm install beautiful-mermaid
# or
bun add beautiful-mermaid
# or
pnpm add beautiful-mermaid&lt;/code&gt;
    &lt;code&gt;import { renderMermaid } from 'beautiful-mermaid'

const svg = await renderMermaid(`
  graph TD
    A[Start] --&amp;gt; B{Decision}
    B --&amp;gt;|Yes| C[Action]
    B --&amp;gt;|No| D[End]
`)&lt;/code&gt;
    &lt;code&gt;import { renderMermaidAscii } from 'beautiful-mermaid'

const ascii = renderMermaidAscii(`graph LR; A --&amp;gt; B --&amp;gt; C`)&lt;/code&gt;
    &lt;code&gt;┌───┐     ┌───┐     ┌───┐
│   │     │   │     │   │
│ A │────►│ B │────►│ C │
│   │     │   │     │   │
└───┘     └───┘     └───┘
&lt;/code&gt;
    &lt;p&gt;The theming system is the heart of &lt;code&gt;beautiful-mermaid&lt;/code&gt;. It's designed to be both powerful and dead simple.&lt;/p&gt;
    &lt;p&gt;Every diagram needs just two colors: background (&lt;code&gt;bg&lt;/code&gt;) and foreground (&lt;code&gt;fg&lt;/code&gt;). That's it. From these two colors, the entire diagram is derived using &lt;code&gt;color-mix()&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;const svg = await renderMermaid(diagram, {
  bg: '#1a1b26',  // Background
  fg: '#a9b1d6',  // Foreground
})&lt;/code&gt;
    &lt;p&gt;This is Mono Mode—a coherent, beautiful diagram from just two colors. The system automatically derives:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Element&lt;/cell&gt;
        &lt;cell role="head"&gt;Derivation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--fg&lt;/code&gt; at 100%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Secondary text&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--fg&lt;/code&gt; at 60% into &lt;code&gt;--bg&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edge labels&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--fg&lt;/code&gt; at 40% into &lt;code&gt;--bg&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Connectors&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--fg&lt;/code&gt; at 30% into &lt;code&gt;--bg&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Arrow heads&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--fg&lt;/code&gt; at 50% into &lt;code&gt;--bg&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Node fill&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--fg&lt;/code&gt; at 3% into &lt;code&gt;--bg&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Node stroke&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;--fg&lt;/code&gt; at 20% into &lt;code&gt;--bg&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;For richer themes, you can provide optional "enrichment" colors that override specific derivations:&lt;/p&gt;
    &lt;code&gt;const svg = await renderMermaid(diagram, {
  bg: '#1a1b26',
  fg: '#a9b1d6',
  // Optional enrichment:
  line: '#3d59a1',    // Edge/connector color
  accent: '#7aa2f7',  // Arrow heads, highlights
  muted: '#565f89',   // Secondary text, labels
  surface: '#292e42', // Node fill tint
  border: '#3d59a1',  // Node stroke
})&lt;/code&gt;
    &lt;p&gt;If an enrichment color isn't provided, it falls back to the &lt;code&gt;color-mix()&lt;/code&gt; derivation. This means you can provide just the colors you care about.&lt;/p&gt;
    &lt;p&gt;All colors are CSS custom properties on the &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; element. This means you can switch themes instantly without re-rendering:&lt;/p&gt;
    &lt;code&gt;// Switch theme by updating CSS variables
svg.style.setProperty('--bg', '#282a36')
svg.style.setProperty('--fg', '#f8f8f2')
// The entire diagram updates immediately&lt;/code&gt;
    &lt;p&gt;15 carefully curated themes ship out of the box:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Theme&lt;/cell&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Background&lt;/cell&gt;
        &lt;cell role="head"&gt;Accent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;zinc-light&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Light&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#FFFFFF&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Derived&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;zinc-dark&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#18181B&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Derived&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;tokyo-night&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#1a1b26&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#7aa2f7&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;tokyo-night-storm&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#24283b&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#7aa2f7&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;tokyo-night-light&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Light&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#d5d6db&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#34548a&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;catppuccin-mocha&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#1e1e2e&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#cba6f7&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;catppuccin-latte&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Light&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#eff1f5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#8839ef&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;nord&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#2e3440&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#88c0d0&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;nord-light&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Light&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#eceff4&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#5e81ac&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;dracula&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#282a36&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#bd93f9&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;github-light&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Light&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#ffffff&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#0969da&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;github-dark&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#0d1117&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#4493f8&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;solarized-light&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Light&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#fdf6e3&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#268bd2&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;solarized-dark&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#002b36&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#268bd2&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;one-dark&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#282c34&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#c678dd&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;import { renderMermaid, THEMES } from 'beautiful-mermaid'

const svg = await renderMermaid(diagram, THEMES['tokyo-night'])&lt;/code&gt;
    &lt;p&gt;Creating a theme is trivial. At minimum, just provide &lt;code&gt;bg&lt;/code&gt; and &lt;code&gt;fg&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;const myTheme = {
  bg: '#0f0f0f',
  fg: '#e0e0e0',
}

const svg = await renderMermaid(diagram, myTheme)&lt;/code&gt;
    &lt;p&gt;Want richer colors? Add any of the optional enrichments:&lt;/p&gt;
    &lt;code&gt;const myRichTheme = {
  bg: '#0f0f0f',
  fg: '#e0e0e0',
  accent: '#ff6b6b',  // Pop of color for arrows
  muted: '#666666',   // Subdued labels
}&lt;/code&gt;
    &lt;p&gt;Use any VS Code theme directly via Shiki integration. This gives you access to hundreds of community themes:&lt;/p&gt;
    &lt;code&gt;import { getSingletonHighlighter } from 'shiki'
import { renderMermaid, fromShikiTheme } from 'beautiful-mermaid'

// Load any theme from Shiki's registry
const highlighter = await getSingletonHighlighter({
  themes: ['vitesse-dark', 'rose-pine', 'material-theme-darker']
})

// Extract diagram colors from the theme
const colors = fromShikiTheme(highlighter.getTheme('vitesse-dark'))

const svg = await renderMermaid(diagram, colors)&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;fromShikiTheme()&lt;/code&gt; function intelligently maps VS Code editor colors to diagram roles:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Editor Color&lt;/cell&gt;
        &lt;cell role="head"&gt;Diagram Role&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;editor.background&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;bg&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;editor.foreground&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;fg&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;editorLineNumber.foreground&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;line&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;focusBorder&lt;/code&gt; / keyword token&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;accent&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;comment token&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;muted&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;editor.selectionBackground&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;surface&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;editorWidget.border&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;border&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;graph TD
  A[Start] --&amp;gt; B{Decision}
  B --&amp;gt;|Yes| C[Process]
  B --&amp;gt;|No| D[End]
  C --&amp;gt; D
&lt;/code&gt;
    &lt;p&gt;All directions supported: &lt;code&gt;TD&lt;/code&gt; (top-down), &lt;code&gt;LR&lt;/code&gt; (left-right), &lt;code&gt;BT&lt;/code&gt; (bottom-top), &lt;code&gt;RL&lt;/code&gt; (right-left).&lt;/p&gt;
    &lt;code&gt;stateDiagram-v2
  [*] --&amp;gt; Idle
  Idle --&amp;gt; Processing: start
  Processing --&amp;gt; Complete: done
  Complete --&amp;gt; [*]
&lt;/code&gt;
    &lt;code&gt;sequenceDiagram
  Alice-&amp;gt;&amp;gt;Bob: Hello Bob!
  Bob--&amp;gt;&amp;gt;Alice: Hi Alice!
  Alice-&amp;gt;&amp;gt;Bob: How are you?
  Bob--&amp;gt;&amp;gt;Alice: Great, thanks!
&lt;/code&gt;
    &lt;code&gt;classDiagram
  Animal &amp;lt;|-- Duck
  Animal &amp;lt;|-- Fish
  Animal: +int age
  Animal: +String gender
  Animal: +isMammal() bool
  Duck: +String beakColor
  Duck: +swim()
  Duck: +quack()
&lt;/code&gt;
    &lt;code&gt;erDiagram
  CUSTOMER ||--o{ ORDER : places
  ORDER ||--|{ LINE_ITEM : contains
  PRODUCT ||--o{ LINE_ITEM : "is in"
&lt;/code&gt;
    &lt;p&gt;For terminal environments, CLI tools, or anywhere you need plain text, render to ASCII or Unicode box-drawing characters:&lt;/p&gt;
    &lt;code&gt;import { renderMermaidAscii } from 'beautiful-mermaid'

// Unicode mode (default) — prettier box drawing
const unicode = renderMermaidAscii(`graph LR; A --&amp;gt; B`)

// Pure ASCII mode — maximum compatibility
const ascii = renderMermaidAscii(`graph LR; A --&amp;gt; B`, { useAscii: true })&lt;/code&gt;
    &lt;p&gt;Unicode output:&lt;/p&gt;
    &lt;code&gt;┌───┐     ┌───┐
│   │     │   │
│ A │────►│ B │
│   │     │   │
└───┘     └───┘
&lt;/code&gt;
    &lt;p&gt;ASCII output:&lt;/p&gt;
    &lt;code&gt;+---+     +---+
|   |     |   |
| A |----&amp;gt;| B |
|   |     |   |
+---+     +---+
&lt;/code&gt;
    &lt;code&gt;renderMermaidAscii(diagram, {
  useAscii: false,      // true = ASCII, false = Unicode (default)
  paddingX: 5,          // Horizontal spacing between nodes
  paddingY: 5,          // Vertical spacing between nodes
  boxBorderPadding: 1,  // Padding inside node boxes
})&lt;/code&gt;
    &lt;p&gt;Render a Mermaid diagram to SVG. Auto-detects diagram type.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;text&lt;/code&gt;— Mermaid source code&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;options&lt;/code&gt;— Optional&lt;code&gt;RenderOptions&lt;/code&gt;object&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RenderOptions:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;bg&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;string&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#FFFFFF&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Background color&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;fg&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;string&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;#27272A&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Foreground color&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;line&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;string?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;Edge/connector color&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;accent&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;string?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;Arrow heads, highlights&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;muted&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;string?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;Secondary text, labels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;surface&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;string?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;Node fill tint&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;border&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;string?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;Node stroke color&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;font&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;string&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;Inter&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Font family&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;transparent&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;boolean&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Render with transparent background&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Render a Mermaid diagram to ASCII/Unicode text. Synchronous.&lt;/p&gt;
    &lt;p&gt;AsciiRenderOptions:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;useAscii&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;boolean&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Use ASCII instead of Unicode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;paddingX&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;number&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Horizontal node spacing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;paddingY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;number&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Vertical node spacing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;boxBorderPadding&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;number&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Inner box padding&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Extract diagram colors from a Shiki theme object.&lt;/p&gt;
    &lt;p&gt;Object containing all 15 built-in themes.&lt;/p&gt;
    &lt;p&gt;Default colors (&lt;code&gt;#FFFFFF&lt;/code&gt; / &lt;code&gt;#27272A&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;The ASCII rendering engine is based on mermaid-ascii by Alexander Grooff. We ported it from Go to TypeScript and extended it with:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sequence diagram support&lt;/item&gt;
      &lt;item&gt;Class diagram support&lt;/item&gt;
      &lt;item&gt;ER diagram support&lt;/item&gt;
      &lt;item&gt;Unicode box-drawing characters&lt;/item&gt;
      &lt;item&gt;Configurable spacing and padding&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thank you Alexander for the excellent foundation!&lt;/p&gt;
    &lt;p&gt;MIT — see LICENSE for details.&lt;/p&gt;
    &lt;p&gt;Built with care by the team at Craft&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46804828</guid><pubDate>Thu, 29 Jan 2026 02:08:40 +0000</pubDate></item><item><title>Maine’s ‘Lobster Lady’ who fished for nearly a century dies aged 105</title><link>https://www.theguardian.com/us-news/2026/jan/28/maine-lobster-lady-dies-aged-105</link><description>&lt;doc fingerprint="f2911183d4bb9605"&gt;
  &lt;main&gt;
    &lt;p&gt;Maine’s governor has hailed the life of a woman who spent nearly 100 years fishing for lobsters as “amazing” and expressed hopes that her memory inspires “the next century of hardworking” fishers in the state.&lt;/p&gt;
    &lt;p&gt;The subject of Governor Janet Mills’ tribute, Virginia “Ginny” Oliver, died on 21 January at age 105, according to an obituary published on Monday by her family.&lt;/p&gt;
    &lt;p&gt;Some regard stories such as that of Oliver, who came to be known as her state’s “Lobster Lady”, as evidence of the growing number of Americans who extend their working days well past the typical retirement age as the cost of living in the US has soared, wages have stagnated and many therefore have been unable to save.&lt;/p&gt;
    &lt;p&gt;Nonetheless, as recently as 2021, Oliver told the Associated Press she fell in love with trapping lobsters from the moment she started in the business at eight years old, alongside her father and older brother.&lt;/p&gt;
    &lt;p&gt;“I like doing it – I like being along the water,” she said when discussing her career in the largely male-dominated industry she chose. “And so I’m going to keep on doing it just as long as I can.”&lt;/p&gt;
    &lt;p&gt;Oliver would get up before dawn and use small fish colloquially known as poagies to lure lobsters from her boat, the Virginia, which was first owned by her late husband. As she established a remarkable 97-year tenure on the waters, and word of it spread, she became the subject of documentaries, major US television networks’ news stories and children’s books, including one titled The Lobster Lady, her obituary recounted.&lt;/p&gt;
    &lt;p&gt;Mark Hamill, the famed actor, was among those who joined the following that Oliver developed throughout the years. Hamill, best known for his role as Luke Skywalker in the Star Wars film saga, “celebrated her tenacity on social media”, Oliver’s obituary noted.&lt;/p&gt;
    &lt;p&gt;The obituary also said that Oliver at one point earned an honorary invitation to join Great Britain’s Cardiff Royal Naval Association. Mills once presented Oliver with a special recognition on her birthday.&lt;/p&gt;
    &lt;p&gt;“Despite her fame, friends and family said she remained humble and spirited,” Oliver’s obituary added. “Her personal aesthetic delighted her fans – she wore lipstick and earrings every day she went out on the boat, because, as she said, ‘you never know who you are going to see.’”&lt;/p&gt;
    &lt;p&gt;Lobster evolved from working-class food to a pricey restaurant delicacy over the course of Oliver’s fishing life. Its price per pound swelled from 28 cents when she first started to $6.14 – or 22 times more expensive.&lt;/p&gt;
    &lt;p&gt;Oliver fished for lobster until a fall at age 103, said a statement from her friend, author and Pulitzer prize-winning journalist Barbara Walsh.&lt;/p&gt;
    &lt;p&gt;Walsh joined Mills in paying tribute to Oliver, saying the late fisher “believed in living, laughing and doing what she loved”.&lt;/p&gt;
    &lt;p&gt;“She was sassy and spirited, always declaring on land and at sea, ‘I’m the boss,’” Walsh’s tribute statement said. “Sail on, sweet Ginny. May your spirit forever soar above the sea.”&lt;/p&gt;
    &lt;p&gt;Meanwhile, the Maine Lobster festival, which once designated her the grand marshal of its parade, issued a statement honoring Oliver as “more than a local icon”.&lt;/p&gt;
    &lt;p&gt;“Virginia was … a living piece of Maine’s maritime history,” the festival’s statement said.&lt;/p&gt;
    &lt;p&gt;Oliver’s survivors include her children and grandchildren, according to her obituary.&lt;/p&gt;
    &lt;p&gt;Associated Press contributed reporting&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46804854</guid><pubDate>Thu, 29 Jan 2026 02:11:42 +0000</pubDate></item><item><title>Questom (YC F25) is hiring an engineer</title><link>https://www.ycombinator.com/companies/questom/jobs/UBebsyO-founding-engineer</link><description>&lt;doc fingerprint="b5fe30170ec5bb2a"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;We’re looking for a Founding Engineer to help build the core systems that power Questom.&lt;/p&gt;
      &lt;p&gt;This is not a framework-specialist role. It’s not about perfect abstractions on day one. It is about systems thinking, ownership, and the ability to stitch together complex infrastructure into something that works — fast.&lt;/p&gt;
      &lt;p&gt;You’ll be one of a very small group shaping not just the product, but how the company builds.&lt;/p&gt;
      &lt;head rend="h2"&gt;What You’ll Do&lt;/head&gt;
      &lt;head rend="h3"&gt;Build systems that connect everything&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Design and build high-performance systems that connect: &lt;list rend="ul"&gt;&lt;item&gt;Communication platforms (voice, SMS, email, chat)&lt;/item&gt;&lt;item&gt;Agentic workflows&lt;/item&gt;&lt;item&gt;External tools like CRMs and internal APIs&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Stitch together APIs, workflows, and agents into cohesive systems that actually run in production&lt;/item&gt;
        &lt;item&gt;Think deeply about how these systems scale across many customers with different data sources and configurations&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Build agentic workflows&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Create workflows where agents: &lt;list rend="ul"&gt;&lt;item&gt;Handle live conversations&lt;/item&gt;&lt;item&gt;Pull context from systems like Salesforce&lt;/item&gt;&lt;item&gt;Log outcomes in tools like HubSpot&lt;/item&gt;&lt;item&gt;Take real actions on behalf of users&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Focus on giving agents the right information at the right time and designing systems that make this repeatable across customers&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Turn ambiguity into working software&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Start from half-baked ideas, rough customer conversations, or incomplete requirements&lt;/item&gt;
        &lt;item&gt;Ship a 90% working solution quickly&lt;/item&gt;
        &lt;item&gt;Iterate toward something more general, scalable, and high quality&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Own what you build&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Take end-to-end ownership: design → build → ship → improve&lt;/item&gt;
        &lt;item&gt;Break things thoughtfully — and fix them yourself&lt;/item&gt;
        &lt;item&gt;Make judgment calls without needing constant guidance&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;What Success Looks Like&lt;/head&gt;
      &lt;p&gt;In the first 30 days&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Sit in a few customer conversations&lt;/item&gt;
        &lt;item&gt;Identify a real pain point&lt;/item&gt;
        &lt;item&gt;Propose a product or feature to solve it&lt;/item&gt;
        &lt;item&gt;Build and ship an end-to-end solution that delivers real value&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;In the first 90 days&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Take learnings from multiple customer builds&lt;/item&gt;
        &lt;item&gt;Start shaping more general-purpose systems&lt;/item&gt;
        &lt;item&gt;Help lay the foundation for a platform that can scale to many customers — and eventually very large companies&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;How We Build&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;We use modern tools aggressively and expect you to learn quickly: &lt;list rend="ul"&gt;&lt;item&gt;Agentic workflow frameworks&lt;/item&gt;&lt;item&gt;Communication infrastructure&lt;/item&gt;&lt;item&gt;AI agent SDKs&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;We rely heavily on coding agents and automation — curiosity and systems understanding matter more than syntax mastery&lt;/item&gt;
        &lt;item&gt;We build fast, then make it better&lt;/item&gt;
        &lt;item&gt;We’re opinionated, iterative, and comfortable changing direction when a simpler solution delivers customer value&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;What Matters (and What Doesn’t)&lt;/head&gt;
      &lt;head rend="h3"&gt;What matters a lot&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Systems thinking&lt;/item&gt;
        &lt;item&gt;Ownership&lt;/item&gt;
        &lt;item&gt;Comfort with ambiguity&lt;/item&gt;
        &lt;item&gt;Curiosity and fast learning&lt;/item&gt;
        &lt;item&gt;Product taste (what’s worth building vs not)&lt;/item&gt;
        &lt;item&gt;Respect for how other people think&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What doesn’t matter much&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Deep expertise in any single framework or language&lt;/item&gt;
        &lt;item&gt;Pixel-perfect UI work&lt;/item&gt;
        &lt;item&gt;Writing perfect SQL by hand&lt;/item&gt;
        &lt;item&gt;Knowing our exact stack on day one&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;If you understand how modern web systems, APIs, workflows, and agents fit together — and you’re excited to learn the rest — you’re in great shape.&lt;/p&gt;
      &lt;head rend="h2"&gt;How We Work&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Fast, opinionated, iterative&lt;/item&gt;
        &lt;item&gt;Disagreements are encouraged and happen openly&lt;/item&gt;
        &lt;item&gt;We build first, think later — but we do think&lt;/item&gt;
        &lt;item&gt;You won’t be micromanaged&lt;/item&gt;
        &lt;item&gt;You will be trusted with real responsibility early&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Who You Are&lt;/head&gt;
      &lt;p&gt;You likely describe yourself as:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Extremely curious&lt;/item&gt;
        &lt;item&gt;Highly independent&lt;/item&gt;
        &lt;item&gt;Comfortable operating without a map&lt;/item&gt;
        &lt;item&gt;Someone who enjoys connecting dots across systems&lt;/item&gt;
        &lt;item&gt;High-EQ and collaborative&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;You want to be deeply involved — not just shipping tickets, but helping build a company.&lt;/p&gt;
      &lt;head rend="h2"&gt;Who Should Not Apply&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;If you need clear specs and guardrails to do your best work&lt;/item&gt;
        &lt;item&gt;If you prefer working in isolation&lt;/item&gt;
        &lt;item&gt;If you’re uncomfortable with constant ambiguity&lt;/item&gt;
        &lt;item&gt;If you don’t enjoy discussing ideas, systems, and tradeoffs with a small team&lt;/item&gt;
        &lt;item&gt;If you want a narrow role instead of broad ownership&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;If reading this makes you feel slightly intimidated but very excited, that’s intentional — and probably a good sign.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46805439</guid><pubDate>Thu, 29 Jan 2026 03:29:53 +0000</pubDate></item><item><title>We can’t send mail farther than 500 miles (2002)</title><link>https://web.mit.edu/jemorris/humor/500-miles</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46805665</guid><pubDate>Thu, 29 Jan 2026 03:58:33 +0000</pubDate></item><item><title>Europe’s next-generation weather satellite sends back first images</title><link>https://www.esa.int/Applications/Observing_the_Earth/Meteorological_missions/meteosat_third_generation/Europe_s_next-generation_weather_satellite_sends_back_first_images</link><description>&lt;doc fingerprint="f28ce6731ff45f8c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Europe’s next-generation weather satellite sends back first images&lt;/head&gt;
    &lt;p&gt;The first images from the Meteosat Third Generation-Sounder satellite have been shared at the European Space Conference in Brussels, showing how the mission will provide data on temperature and humidity, for more accurate weather forecasting over Europe and northern Africa.&lt;/p&gt;
    &lt;p&gt;The images from Meteosat Third Generation-Sounder (MTG-S) show a full-disc image of Earth as seen from geostationary orbit, about 36 000 km above Earth’s surface. These images were captured on 15 November 2025 by the satellite’s Infrared Sounder instrument.&lt;/p&gt;
    &lt;p&gt;In the ‘temperature’ image (below), the Infrared Sounder used a long-wave infrared channel, which measured Earth’s surface temperature as well as the temperature at the top of clouds. Dark red corresponds to high temperatures, mainly on the warmer land surfaces, while blue corresponds to lower temperatures, typically on the top of clouds.&lt;/p&gt;
    &lt;p&gt;As would be expected, most of the warmest (dark red) areas in this image are on the continents of Africa and South America. In the top-centre of the image, the outline of the coast of western Africa is clearly visible in dark red, with the Cape Verde peninsula, home to Senegal’s capital Dakar, visible as among the warmest areas in this image. In the bottom-right of the image, the western coast of Namibia and South Africa are also visible in red beneath a swirl of cold cloud shown in blue, while the northeast coast of Brazil is visible in dark red on the left of the image.&lt;/p&gt;
    &lt;p&gt;The ‘humidity’ image (below) was captured using the Infrared Sounder’s medium-wave infrared channel, which measures humidity in Earth’s atmosphere. Blue colours correspond to regions in the atmosphere with higher humidity, while red colours correspond to lower humidity in the atmosphere.&lt;/p&gt;
    &lt;p&gt;The outlines of landmasses are not visible in this image. The areas of least atmospheric humidity, shown in dark red, are seen approximately over the Sahara Desert and the Middle East (top of image), while a large area of ‘dry’ atmosphere also covers part of the South Atlantic Ocean (centre of image). Numerous patches of high humidity are seen in dark blue over the eastern part of the African continent as well as in high and low latitudes.&lt;/p&gt;
    &lt;p&gt;Below we see a close-up from MTG-Sounder of the European continent and part of northern Africa. Like the first image above, here we see heat from land surfaces and temperatures at the top of clouds. The heat from the African continent is seen in red in the lower part of the image, while a dark blue weather front covers Spain and Portugal. The Italian peninsula is in the centre of the image.&lt;/p&gt;
    &lt;p&gt;And the animation (below) uses data from the MTG-Sounder satellite to track the eruption of Ethiopia's Hayli Gubbi volcano on 23 November 2025. The background imagery shows surface temperature changes while infrared channels highlight the developing ash plume. The satellite's timely observations enable tracking of the evolving ash plume over time.&lt;/p&gt;
    &lt;head rend="h4"&gt;Next-generation weather forecasting&lt;/head&gt;
    &lt;p&gt;MTG is a world-class Earth observation mission developed by the European Space Agency (ESA) with European partners to address scientific and societal challenges. The mission provides game-changing data for forecasting weather and air quality over Europe.&lt;/p&gt;
    &lt;p&gt;The satellite’s geostationary position above the equator means it maintains a fixed position relative to Earth, following the same area on the planet’s surface as we rotate. This enables it to provide coverage of Europe and part of northern Africa on a 15-minute repeat cycle. It supplies new data on temperature and humidity over Europe every 30 minutes, supplying meteorologists with a complete weather picture of the region and complementing data on cloud formation and lightning from the MTG-Imager (MTG-I) satellite.&lt;/p&gt;
    &lt;p&gt;ESA’s Director of Earth Observation Programmes, Simonetta Cheli, said, “Seeing the first Infrared Sounder images from the MTG-Sounder satellite really brings this mission and its potential to life. We expect data from this mission to change the way we forecast severe storms over Europe – and this is very exciting for communities and citizens, as well as for meteorologists and climatologists. As ever, the outstanding work done by our teams in collaboration with long-standing partners, including Eumetsat, the European Commission and dozens of European industry teams, means we now have the ability to predict extreme weather events in more accurate and timely ways than ever before.”&lt;/p&gt;
    &lt;head rend="h4"&gt;A hyperspectral view over Europe&lt;/head&gt;
    &lt;p&gt;The Infrared Sounder instrument on board MTG-S is the first European hyperspectral sounding instrument in geostationary orbit. It is designed to generate a completely new type of data product. It uses interferometric techniques, which analyse miniscule patterns in light waves, to capture data on temperature and humidity, as well as being able to measure wind and trace gases in the atmosphere. The data will eventually be used to generate three-dimensional maps of the atmosphere, helping to improve the accuracy of weather forecasting, especially for nowcasting rapidly evolving storms.&lt;/p&gt;
    &lt;p&gt;“It’s fantastic to see the first images from this groundbreaking mission,” said James Champion, ESA’s MTG Project Manager. “This satellite has been 15 years in development and will revolutionise weather forecasting and especially nowcasting. The ability to vertically profile the full Earth’s disk with a repeat cycle of only 30 minutes for Europe is an incredible accomplishment!”&lt;/p&gt;
    &lt;p&gt;“I’m excited that we can share these first images from the Infrared Sounder, which showcase just a small selection of the 1700 infrared channels continuously acquired by the instrument as it observes Earth,” said Pieter Van den Braembussche, MTG System and Payload Manager at ESA. “By combining all 1700 channels, we will soon be able to generate three dimensional maps of temperature, humidity and even trace gases in the atmosphere. This capability will offer a completely new perspective on Earth’s atmosphere, not previously available in Europe, and is expected to help forecasters predict severe storms earlier than is possible today.”&lt;/p&gt;
    &lt;head rend="h2"&gt;About MTG-Sounder&lt;/head&gt;
    &lt;p&gt;The MTG mission currently has two satellites in orbit: MTG-I and MTG-S. The second Imager will be launched later in 2026.&lt;/p&gt;
    &lt;p&gt;MTG-S was launched on 1 July 2025. Thales Alenia Space is the prime contractor for the overall MTG mission, with OHB Systems responsible for the MTG-Sounder satellite. Mission control and data distribution are managed by Eumetsat.&lt;/p&gt;
    &lt;p&gt;The MTG-S satellite also hosts the Copernicus Sentinel-4 mission, which consists of an ultraviolet, visible and near-infrared (UVN) imaging spectrometer. Sentinel-4 delivered its first images last year.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46806773</guid><pubDate>Thu, 29 Jan 2026 07:07:17 +0000</pubDate></item><item><title>AI on Australian travel company website sent tourists to nonexistent hot springs</title><link>https://www.cnn.com/2026/01/28/travel/ai-tourism-nonexistent-hotsprings-intl-scli</link><description>&lt;doc fingerprint="a8260d712845e9da"&gt;
  &lt;main&gt;
    &lt;p&gt;An AI-generated blog on a tour company’s website has landed tourists in hot water — and not the kind they were looking for — after it emerged the “tranquil” northern Tasmania hot springs it recommended don’t actually exist.&lt;/p&gt;
    &lt;p&gt;Screenshots shared with CNN of the now-deleted blog on Tasmania Tours’ website show recommendations for “Weldborough Hot Springs,” said to offer “a peaceful escape” in the forests of northeast Tasmania. Described as a “tranquil haven,” the site was touted as a “favourite” among hikers.&lt;/p&gt;
    &lt;p&gt;Weldborough is a small rural town about 110 kilometers (68 miles) from the city of Launceston.&lt;/p&gt;
    &lt;p&gt;Scott Hennessey, the owner of the New South Wales-based Australian Tours and Cruises, which operates Tasmania Tours, told the Australian Broadcasting Network (ABC) earlier this month that “our AI has messed up completely.”&lt;/p&gt;
    &lt;p&gt;The company had outsourced its marketing material to a third party, he said, and, while he normally reviews each post, the blog was published while he was out of the country.&lt;/p&gt;
    &lt;p&gt;“We’re trying to compete with the big boys,” Hennessy told ABC. “Part of that is you’ve got to keep your content refreshed and new all of the time.”&lt;/p&gt;
    &lt;p&gt;“We’re not a scam,” he continued. “We’re a married couple trying to do the right thing by people … We are legit, we are real people, we employ sales staff.”&lt;/p&gt;
    &lt;p&gt;Australian Tours and Cruises told CNN Tuesday that “the online hate and damage to our business reputation has been absolutely soul-destroying.”&lt;/p&gt;
    &lt;p&gt;“We are just trying to get on with our lives and put the whole thing behind us,” the company continued.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tourists ‘turning up in droves’&lt;/head&gt;
    &lt;p&gt;Kristy Probert, owner of the local Weldborough Hotel, told CNN she was confused when tourists started asking her questions about the hot springs in September.&lt;/p&gt;
    &lt;p&gt;“It was only a couple of calls to start with,” Probert said, “but then people began turning up in droves. I was receiving probably five phone calls a day, and at least two to three people arriving at the hotel looking for them. We’re in a very remote location so it was very random.”&lt;/p&gt;
    &lt;p&gt;Probert said she would respond each time: “If you can find these hot springs, beers are on me.”&lt;/p&gt;
    &lt;p&gt;The local Weld River is “freezing,” said Probert, and typically only occupied by prospectors searching for sapphire and tin. “They wear wetsuits,” she added. “There’s a sauna in a nearby town. I guess you could jump into the freezing river after you’ve been over there.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Beware of AI ‘hallucinations’&lt;/head&gt;
    &lt;p&gt;Anne Hardy, adjunct professor in tourism at Southern Cross University, Australia, told CNN that AI had become “ubiquitous in travel and tourism,” adding that about 37% of tourists use AI for travel advice or itineraries.&lt;/p&gt;
    &lt;p&gt;“Tourists trust AI more than review sites,” she said, adding that tour operators employ AI not only for blogs and marketing materials, but for itineraries and costing.&lt;/p&gt;
    &lt;p&gt;“AI can be extremely helpful,” Hardy said. “It saves time and ultimately money.”&lt;/p&gt;
    &lt;p&gt;However, she warned that it can also create inaccuracies or “hallucinations,” like the Weldborough “hot springs.”&lt;/p&gt;
    &lt;p&gt;According to Hardy, empirical tourism research suggests “90% of itineraries that AI generates have mistakes in them.”&lt;/p&gt;
    &lt;p&gt;She said this could have “extremely dangerous implications,” pointing to Tasmania’s remote walks with no services or cell coverage as an example.&lt;/p&gt;
    &lt;p&gt;“I have witnessed many cases where AI has made suggestions for day walks, which are very inaccurate, ranging from the length of the walk, its difficulty level, or weather conditions,” she told CNN.&lt;/p&gt;
    &lt;p&gt;Hardy recommends travelers go beyond AI and do their own research.&lt;/p&gt;
    &lt;p&gt;“Use trusted guidebooks, travel agents and review websites,” she said. “Plus ask concierges and your hosts to assess whether AI itineraries are accurate, if you do choose to use them.”&lt;/p&gt;
    &lt;p&gt;Probert added that she feels sorry for the owners of Tasmania Tours, who she says she’s spoken with over the phone.&lt;/p&gt;
    &lt;p&gt;“It is hard to keep everything up to date and relevant as a small business,” she said. “They seem like lovely people, and we’ve all made mistakes. I think this was quite a funny one.”&lt;/p&gt;
    &lt;p&gt;“There is plenty to do in Weldborough,” she assured visitors. “Just no hot springs.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46808103</guid><pubDate>Thu, 29 Jan 2026 10:15:42 +0000</pubDate></item><item><title>Vitamin D and Omega-3 have a larger effect on depression than antidepressants</title><link>https://blog.ncase.me/on-depression/</link><description>&lt;doc fingerprint="f5a99056fce511fe"&gt;
  &lt;main&gt;
    &lt;p&gt;(content note: scientific discussion of depression &amp;amp; suicide)&lt;/p&gt;
    &lt;p&gt; "Too Long; Didn't Read" Summary:&lt;lb/&gt; Exactly what the title says. &lt;/p&gt;
    &lt;p&gt;The "standardized effect size" of antidepressants on depression, vs placebo, is around 0.4. (On average; some people respond much better or much worse.) This is like going from a C to a C+.&lt;/p&gt;
    &lt;p&gt;In contrast: the effect size of 1500 mg/day of "≥60% EPA" Omega-3 supplements — which are cheaper &amp;amp; have fewer side effects than antidepressants — is a bit higher, around 0.6. This is like going from a C to a B–.&lt;/p&gt;
    &lt;p&gt;But, much better: the effect size of 5000 IU/day of Vitamin D is around 1.8. This is like going from a C to an A–! It works even for people who don't have a Vitamin D insufficiency, which almost half of American adults do.&lt;/p&gt;
    &lt;p&gt;Even if you're already taking Vitamin D &amp;amp; Omega-3, you may still not be taking enough. The "official" recommendations are all several times too low, and newer research shows that the official "max safe dose" for Vitamin D is 2 times too low. Both these supplements are safe, cheap, and over-the-counter, with positive side-effects (on Covid &amp;amp; cognition).&lt;/p&gt;
    &lt;p&gt;So, unless you have specific reasons to not take Vitamin D &amp;amp; Omega-3 — (kidney stones, blood thinners, etc) — please try them, for at least a month! They could save your mental health. Maybe even your life.&lt;/p&gt;
    &lt;p&gt;(edit — oh hi Hacker News! also, thank you Josep for catching my terrible typo; I meant 5000 IU/day for Vitamin D, NOT 5000 mg. Jeez.)&lt;/p&gt;
    &lt;p&gt;(edit 2 — I said this in the conclusion but I'll move it earlier up: you can take these supplements alongside traditional antidepressants! You can stack interventions! The research shows that they're still effective even when combined with regular meds. As always, "ask your doctor", show them the peer-reviewed papers cited in this post.)&lt;/p&gt;
    &lt;p&gt;Table of Contents:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A crash course in "effect sizes" ↪&lt;/item&gt;
      &lt;item&gt;Interpreting effect sizes on depression ↪&lt;/item&gt;
      &lt;item&gt;Antidepressants ↪&lt;/item&gt;
      &lt;item&gt;Omega-3 ↪&lt;/item&gt;
      &lt;item&gt;Vitamin D ↪&lt;/item&gt;
      &lt;item&gt;Conclusion: All this time, you lacked the Vitamin? ↪&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;A crash course in "effect sizes"&lt;/head&gt;
    &lt;p&gt;In Alicetown, the average person has 4 younger cousins.&lt;lb/&gt; In Bobtown, the average person has 3 younger cousins.&lt;/p&gt;
    &lt;p&gt;Alright, not so surprising. You may not even notice a difference.&lt;/p&gt;
    &lt;p&gt;In Alicetown, the average person has 4 limbs.&lt;lb/&gt; In Bobtown, the average person has 3 limbs.&lt;/p&gt;
    &lt;p&gt;You'd definitely notice.&lt;/p&gt;
    &lt;p&gt;It's the same absolute difference (4 vs 3) and relative difference (3/4). So what makes limbs more surprising than cousins? Well, partly it's more dramatic &amp;amp; visible, but also because: we expect high variation in the number of someone's younger cousins, but not their number of limbs.&lt;/p&gt;
    &lt;p&gt;This is why scientists calculate an "effect size" or "standardized mean difference" ("mean" = average). We take the difference between two groups, then divide by the total amount of variation, to account for how surprising a difference is.&lt;/p&gt;
    &lt;p&gt;(This is a health article, not a math article, so I'll skip the formulas in this post. If you're curious, : check out this 4 min video.)&lt;/p&gt;
    &lt;p&gt;Unfortunately for laypeople, the effect size is usually just reported as a number, like "+0.74" for spacing out your studying vs cramming, or "–0.776" for sleep deprivation on attention.&lt;/p&gt;
    &lt;p&gt;But what's that mean? How can we make these numbers intuitive?&lt;/p&gt;
    &lt;p&gt;Well, a common way for data to be is a bell-shaped curve (also called a "normal distribution"). And most of us are, alas, well-acquainted with the bell curve in school grades. ("grading on a curve")&lt;/p&gt;
    &lt;p&gt;So: school grades give us a useful way to think about standardized effect sizes! We can now convert that number into an actual letter grade:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;F: -2.0 below average&lt;/item&gt;
      &lt;item&gt;D: -1.0 below average&lt;/item&gt;
      &lt;item&gt;C: average&lt;/item&gt;
      &lt;item&gt;B: +1.0 above average&lt;/item&gt;
      &lt;item&gt;A: +2.0 above average&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(see footnote for more precise ranges.[1] the units are in "standard deviations", or "sigmas". what's sigma? &lt;del&gt;sigma ba--&lt;/del&gt; just a unit of "how far away this is from average, relative to the total variation".)&lt;/p&gt;
    &lt;p&gt;For example: spacing out your studying, relative to cramming, will on average lift your test scores from a C to a B–. (effect size = +0.74) And short-term sleep deprivation, relative to healthy sleep, will on average tank your ability to pay attention from a C to a D+. (effect size: –0.776)&lt;/p&gt;
    &lt;p&gt;(Note — when reading about effect sizes, always remember: effect of what, on what, at what dose, for which group, relative to what? See the Data Colada post, Meaningless Means.)&lt;/p&gt;
    &lt;p&gt;(Note 2 — the standard way of "intuitively" describing effect sizes is Cohen's recommendations: 0.2 = small, 0.5 = medium, 0.8 = large. Personally, I prefer the "school grade letter" comparison, since it's more concrete. But hey, you do you.)&lt;/p&gt;
    &lt;p&gt;But it's not limited to just grades &amp;amp; academic performance. Effect sizes can also help us understand any kind of difference between groups, in observation or in experiments!&lt;/p&gt;
    &lt;p&gt;For example...&lt;/p&gt;
    &lt;head rend="h2"&gt;Depression!&lt;/head&gt;
    &lt;p&gt;Let's use our school grade analogy, to interpret effect sizes on mental health:&lt;/p&gt;
    &lt;p&gt;What's an "F in mental health"? By definition of a bell curve, ~2.3% of people are below –2 sigma (an "F"). (See: this bell curve calculator.) In Canada, ~2.6% of people had suicidal ideation in 2022, while in the US, it was ~4.9% in 2019. So, it's not too far off to say: "F in mental health = literally suicidal". (Also, reminder that ~4% is 1-in-25 people. You likely know someone, or are someone, who will feel suicidal this year. Please reach out to your friends &amp;amp; loved ones!)&lt;/p&gt;
    &lt;p&gt;What's a "D in mental health"? ~16% of people are below –1 sigma (a "D") on a bell curve. The Keyes 2002 study estimated that ~14.1% of adults meet the DSM-III criteria for a major depressive episode. So, D = Depressed.&lt;/p&gt;
    &lt;p&gt;What's an average "C in mental health"? ~68% of people are within a sigma of average (a "C") on a bell curve. Same above study found that 56.6 percent had moderate mental health. They were neither "languishing" nor "flourishing". I guess C = Could Be Worse.&lt;/p&gt;
    &lt;p&gt;What's a "B in mental health"? ~16% of people are above +1 sigma (a "B") on a bell curve. Same above study found that 17.2% of adults are "flourishing". Good for them! B = Flourishing, life is good.&lt;/p&gt;
    &lt;p&gt;What's an "A in mental health"? I don't know who these freaks are. I actually could not find any scientific studies on "the +2 sigma in well-being". In contrast, there's lots of research on suicidal ideation, the –2 sigma in well-being. In the absence of any actual data, I'll just say: A = AWESOME&lt;/p&gt;
    &lt;p&gt;So, if an intervention is found to have an effect size of +1.0, that's like going up a letter grade. If something's found to have an effect size of -2.0, that's like going down two letter grades. And so on.&lt;/p&gt;
    &lt;p&gt;Okay, so how do we get peoples' "mental health grades" up?&lt;/p&gt;
    &lt;p&gt;Let's look at antidepressants, Omega-3, and Vitamin D, in turn:&lt;/p&gt;
    &lt;head rend="h2"&gt;Antidepressants&lt;/head&gt;
    &lt;p&gt;The good news is they work. The bad news is they don't work as well as you'd think they may work.&lt;/p&gt;
    &lt;p&gt;Cipriani et al 2018 is a recent meta-analysis (a study collecting lots of previous studies) that investigated 21 different antidepressants. The most effective antidepressant, Amitriptyline, relative to placebo, had an Odds Ratio of 2.13 — which converts to a Cohen's d effect size of 0.417 — which is "small-medium" according to Cohen's recommendations. Or, by our school-letter-grade comparison: the best antidepressant would take your mental health grade from an F to F+, or C to C+.&lt;/p&gt;
    &lt;p&gt;From Figure 3 of that paper, you can see that Amitriptyline has the highest estimated effect size, while the side effects are no worse than placebo:&lt;/p&gt;
    &lt;p&gt;Sure, "F to F+" can be lifesaving, but… y'know… that's not a lot. And again, this is the effect on average. Some people respond much better to antidepressants… while some respond much worse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Omega-3&lt;/head&gt;
    &lt;p&gt;Keep getting confused on which fat is what? Me too. So, here's a crash course on various fats:&lt;/p&gt;
    &lt;p&gt;Fatty acids are chains of carbons &amp;amp; hydrogens + two oxygens. They say "OOH" at one end, and "HHH" at the other end:&lt;/p&gt;
    &lt;p&gt;A saturated fatty acid is one where all the carbons' free spots are filled up with hydrogens. (Hence, "saturated") This makes the molecule stick straight out. This is why long saturated fatty acids — like those found in butter — tend to be solid at room temperature.&lt;/p&gt;
    &lt;p&gt;(Contrary to popular belief, saturated fats don't literally clog your arteries, like grease in plumbing pipes. What happens is {ha ha I don't actually understand this}. Something about your cholesterol levels &amp;amp; inflammation.)&lt;/p&gt;
    &lt;p&gt;In contrast, unsaturated fatty acids have at least one hydrogen missing. This causes them to have a double-bond "kink" in the molecule. This makes them not stick out, which is why unsaturated fats tend to be liquid at room temperature. Mono-unsaturated fatty acids (MUFAs) — like in olive oil — only have one kink. Poly-unsaturated fatty acids (PUFAs) — like in fatty fish — have two or more kinks. Let's be mature adults about this, please.&lt;/p&gt;
    &lt;p&gt;For completeness: trans fats are unsaturated fats whose "kink" is twisted around, causing them to go straight. That is the worst sentence I've written all month. The twisted kink is caused by the hydrogens being on opposite sides, hence "trans". (And yes, if they're on the same side it's "cis". Latin was a mistake.) The molecule being straight is why trans fats — which margarine used to be full of — are solid at room temperature, despite being an unsaturated fat.&lt;/p&gt;
    &lt;p&gt;It's neat whenever you can trace the history of something right down to its atoms! Margarine was first invented because it's cheaper, and is spreadable straight from the fridge, unlike butter. Margarine (used to be) made by taking unsaturated vegetable oils, which were cheaper than animal fats, then pumping a bunch of hydrogens into it (hence, "hydrogenated oils"). If you completely hydrogenate an oil, it becomes a saturated fat. But they only partially hydrogenated those oils, leading to trans fats, which were cheaper &amp;amp; a spreadable semi-solid at fridge temperature.&lt;/p&gt;
    &lt;p&gt;In the 1970s &amp;amp; 80s, the US Food &amp;amp; Drug Administration concluded that trans fats were not harmful to humans, and nutritionists promoted margarine over butter, because butter had "unhealthy" saturated fats. But in the early 1990s, scientists realized that trans fats were even worse for you than saturated fats. Only in the 2010's, did most Western countries start officially banning trans fats. Reminder: policy is often decades behind science.&lt;/p&gt;
    &lt;p&gt;(Hey, what do you call it when you get thiccer on HRT? Trans fat! :D)&lt;/p&gt;
    &lt;p&gt;I need to stop going on infodump tangents. Anyway, Omega-3 is any fatty acid with its first kink at the 3rd carbon from the Omega end ("HHH"), though it can have more kinks later down the chain. (And yes, Omega-6 has its first kink at the 6th carbon, and Omega-9 has its first kink at the 9th carbon. There's nothing physically preventing Omega-4 or Omega-5's from existing, but due to some quirk of evolution, Omega-3, -6, and -9 are the ones biological life uses most. As far as I can tell, there's no specific reason they're all multiples of 3. Probably just a coincidence. There is a less common Omega-7.)&lt;/p&gt;
    &lt;p&gt;Finally, there's three main types of Omega-3: EPA (Eicosapentaenoic Acid), DHA (Docosahexaenoic Acid), and ALA (Alpha-Linolenic Acid). ALA is mostly found in plants like chia seeds &amp;amp; walnuts, while EPA &amp;amp; DHA mostly come from seafood, though there are algae-based vegan sources.&lt;/p&gt;
    &lt;p&gt;(Figure 1.1 from Roke 2016.⤵ Thank you Kaitlin Samantha Roke for drawing this coz I'm too lazy to draw it myself. Note how the first double-bond "kink" for all these molecules is at the 3rd carbon from the Omega end — hence why they're all called Omega-3's.)&lt;/p&gt;
    &lt;p&gt;EPA &amp;amp; DHA are the focus of this section. For bio-mechanical reasons I don't understand but I assume someone else does: EPA is the one associated with anti-inflammation, better brain health, and less depression... while DHA isn't. (But DHA is still needed for other stuff, like your neurons' cell walls, so don't cut them out completely!)&lt;/p&gt;
    &lt;p&gt;(Note: I could not find any experimental trials of ALA on depression, though an observational study in Japan (Kurotani et al 2014) finds a correlation between higher ALA and lower depression. But reminder, correlation is not necessarily causation.)&lt;/p&gt;
    &lt;p&gt;All the above info in a Venn (technically Euler) diagram:&lt;/p&gt;
    &lt;p&gt;Okay, enough yap. Time for the actual data:&lt;/p&gt;
    &lt;p&gt;Sublette et al 2011 is an older meta-analysis, but it's the only one I could find that tries to estimate the actual "dose-response" curve, which shows: how much effect, for how much treatment. Why is that important? Because one problem with many meta-analyses is they'll do something like: "Study 1 gave patients 1 gram of medicine and saw a +1 improvement in disease, Study 2 gave 10 grams and saw +4 improvement, Study 3 gave 100 grams and saw negative –5 improvement… the average of +1, +4, and –5 is zero... therefore the medicine's effect is zero." ...As mentioned briefly earlier, this is a meaningless mean. That's why we want to know the response at each dose.&lt;/p&gt;
    &lt;p&gt;So, the Sublette meta-analysis gathered randomized trials studying Omega-3 on depression (vs placebo, of course) and got the following dose-response curve.⤵ Note that the horizontal axis is not just amount of total Omega-3, but specifically the extra amount of "unopposed" EPA, above the amount of DHA. Or in other words, "EPA minus DHA":&lt;/p&gt;
    &lt;p&gt;The top effect size is around +0.558, which is like going from an F to D–, or C to B–. You get this maximum effect around 1 to 2 grams of extra EPA, and too much EPA gets worse results. The meta-analysis finds that Omega-3 supplements that are ~60% EPA (and the rest DHA) are optimal.&lt;/p&gt;
    &lt;p&gt;This finding is roughly in line with later meta-analyses. Liao et al 2019 also finds that ~1 gram of ≥60% EPA is best, but actually found a much higher effect size: +1.03. Kelaiditis et al 2023 also finds 1 to 2g of ≥60% EPA is best, but found a lower effect size of +0.43… which is still as good as the best antidepressant!&lt;/p&gt;
    &lt;p&gt;Either way, let's boil this down to a recommendation. You want around 1 gram of EPA a day. So if your supplements are 60% EPA, you need 1 gram ÷ 0.6 ~= 1.667 grams = 1667 milligrams. Let's round this down for convenience: get 1500 mg/day of 60%-EPA Omega-3 supplements.&lt;/p&gt;
    &lt;p&gt;In comparison, most official health organizations recommend "250–500 mg combined EPA and DHA each day for healthy adults." That is over three times too low, at least for optimal effects on depression. Which, as we calculated above, is probably around 1500 mg/day. (The official safe dose is 5000 mg/day)&lt;/p&gt;
    &lt;p&gt;Finally, a (small) study directly investigating the link between suicide &amp;amp; Omega-3. Sublette et al 2006: “Low [DHA] and low Omega-3 proportions [...] predicted risk of suicidal behavior among depressed patients over the 2-year period.” Though keep in mind this is a small study, and it's observational not experimental. Also, weird that contrary to the above studies on depression, DHA predicted suicide but not EPA. Not sure what to make of that.&lt;/p&gt;
    &lt;p&gt;Bonus: Omega-3 may also boost cognition? Shahinfar et al 2025: “Enhancement of global cognitive abilities was observed with increasing omega-3 dosage up to 1500 mg/day. [effect size = 1.00, like going from a grade of C to B!], followed by downward trend at higher doses.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Vitamin D&lt;/head&gt;
    &lt;p&gt;Ghaemi et al 2024 is a meta-analysis on Vitamin D on depression. Again, it actually estimates a dose-response curve! Below is Figure 1 + Table 2, showing the effect of Vitamin D dosage on depression vs placebo. The solid line is the average estimated effect, dashed lines are 95% confidence interval. Note the effect size is negative in this figure, because they're measuring reduction in depressive symptoms:&lt;/p&gt;
    &lt;p&gt;The upper range of uncertainty is lowest at 5000 IU (International Units) of Vitamin D a day, with an estimated effect size of 1.82, with a 95% uncertainty range, from 0.98 to 2.66. An effect size of 1.82 is like taking your mental health from an F to a C–, or a C to an A–! And even in the most pessimistic case, 0.98, that's still over twice as effective as the top antidepressant!&lt;/p&gt;
    &lt;p&gt;(The paper's summary says 8000 IU is best, with effect size 2.04, but there's much greater uncertainty there. The paper also finds that longer studies had smaller effects than shorter studies, but this does not necessarily mean Vitamin D's effects are short-lived. Looking at Supplementary Table 4, it seems this is partly because longer studies used lower average daily doses. For example, one 52-week study only gave participants 400 IU a day.)&lt;/p&gt;
    &lt;p&gt;This meta-analysis includes trials with participants who don't have Vitamin D deficiency. There's still a good effect of Vitamin D on depression for them, even if smaller! Though, you probably are lacking Vitamin D: Liu et al 2018 finds that a bit under half of all adults (41.4%) have Vitamin D Insufficiency.&lt;/p&gt;
    &lt;p&gt;And that's according to the official recommendation, of 400-800 IU a day… which is is too damn low. Even the official maximum safe dose of Vitamin D, of 4000 IU/day, is too low. McCullough et al 2019 gave over thousands of patients 5,000 to 10,000 IU/day, for seven years, and there were zero cases of serious side effects. This is in line with Billington et al 2020, a 3-year-long double-blinded randomized controlled trial, where they found "the safety profile of vitamin D supplementation is similar for doses of 400, 4000, and 10,000 IU/day." (though "mild hypercalcemia" increased from 3% to 9%. IMHO, that's a small cost for reducing the risk of major depression &amp;amp; suicide.)&lt;/p&gt;
    &lt;p&gt;And it makes sense that 10,000 IU a day should be safe. Your skin, exposed to the Sun's ultraviolet rays, can synthesize up to (the equivalent of) 10,000 IU a day, before plateauing out. Source is Vieth 1999: “Because vitamin D is potentially toxic, intake of [1000 IU/day] has been avoided even though the weight of evidence shows that the currently accepted [limit] of [2000 IU/day] is too low by at least 5-fold.” (So why are all the official sources still so paranoid about Vitamin D? Well, unfortunately, official/governmental policy is always a few decades behind the science in any field. See Also: the trans fat debate, everything about educational policy.)&lt;/p&gt;
    &lt;p&gt;Speaking of the Sun, why take supplements instead of just getting Vitamin D from Sun exposure? Well, skin cancer. But also: because Sun-Skin D varies greatly depending on the season, your latitude, and your skin type. There's less ultraviolet rays from the Sun in winter/fall, and at latitudes further from the equator. And the darker your skin is, the less Vitamin D your skin makes for the same amount of Sun exposure. As expected from the bio-physics of skin, Black adults have the highest prevalence of Vitamin D deficiency (82.1%!!), followed by Hispanic adults (62.9%). (But hey, at least Black adults have the lowest incidence of skin cancer. You win some you lose some.) The point is: speaking as someone with Southeast Asian skin, who's currently in Canada during winter... even if I stood outside naked for hours, I'd get approximately zero IU/day of Vitamin D from the Sun. Thus: supplements.&lt;/p&gt;
    &lt;p&gt;Finally, a meta-analysis directly measuring the effect of Vitamin D on suicide rates. Yu et al 2025: “Vitamin D in patients with [suicidal behaviours] were significantly lower than in controls (standardized mean difference: –0.69, or a 'medium' difference)”. Reminder that this paper by itself only measures correlation, not causation — but combined with the above experiments of Vitamin D on depression, I think it's reasonable to guess it's partly causal.&lt;/p&gt;
    &lt;p&gt;To recap:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Almost half of you have a Vitamin D deficiency according to the official recommendation (800 IU/day).&lt;/item&gt;
      &lt;item&gt;And the official recommendation is way too low. Even the official maximum safe dose (4000 IU/day) is below the optimal Vitamin D for depression (5000 IU/day) or what your body can produce from the Sun in optimal conditions (10,000 IU/day). Recent randomized controlled trials confirm that 10,000 IU/day is, indeed, mostly safe.&lt;/item&gt;
      &lt;item&gt;Your daily reminder than official policy is often decades behind the science.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bonus: Vitamin D supplementation was found in several randomized controlled trials to reduce mortality from Covid-19! It probably helps guard against influenza too, though the evidence is small &amp;amp; early.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion: All this time, you lacked the Vitamin?&lt;/head&gt;
    &lt;p&gt;Scurvy is caused by a lack of Vitamin C. It's a condition that causes your wounds to re-open up &amp;amp; teeth to fall out. Scurvy used to kill almost half(!) of all sailors on major expeditions; it's estimated millions died. It can be cured by eating lemons.&lt;/p&gt;
    &lt;p&gt;Rickets is mostly caused by a lack of Vitamin D. It's a condition where kids' bones go all soft and deformed. During the Industrial Revolution, up to 80% of kids suffered from it. It can be prevented with cod liver oil.&lt;/p&gt;
    &lt;p&gt;Goiters is mostly caused by a lack of Iodine. It's a condition where the thyroid gland in your neck swells up painfully, to the size of an apple. During WWI, a third of adult men had goiters. It can be prevented with iodized salt.&lt;/p&gt;
    &lt;p&gt;About 1 in 4 people are expected to have clinical depression sometime in their life. Depression is the #1 source of the global "burden from disease" in the mental health category, and that category is the #6 burden of disease in the world, above Alzheimer's, malaria, and sexually transmitted infections.&lt;/p&gt;
    &lt;p&gt;(But honestly, did you need those stats? This is likely a lived experience for a lot of you reading this.)&lt;/p&gt;
    &lt;p&gt;The effective altruists are all, "woah for just $3000 you can prevent a child's death from malaria" — and that's great! save them kids! — but where's the fanfare for the accumulating evidence that, "woah with cheap daily supplements we can save millions from suicide &amp;amp; depressed lives"?&lt;/p&gt;
    &lt;p&gt;Over and over again throughout history, some horrific thing that caused millions to suffer, turned out to be "yeah you were missing this one molecule lol". To be clear: not everything is gonna be that simple, and mental health is not "just" chemistry. Also, all the numbers on this page have with large error bars &amp;amp; uncertainty, more research is needed.&lt;/p&gt;
    &lt;p&gt;But, as of right now, I feel I can at least confidently claim the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vitamin D and Omega-3 are both at least on par with antidepressants.&lt;/item&gt;
      &lt;item&gt;The evidence is much stronger for Vitamin D; it's very plausibly at least twice as good as antidepressants.&lt;/item&gt;
      &lt;item&gt;Both supplements are cheap and safe, so what's the harm of trying? (positive "expected value" for this bet)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So:&lt;/p&gt;
    &lt;p&gt;MY SPECIFIC RECOMMENDATIONS FOR YOU TO DO A.S.A.P:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go to a pharmacy, buy the following supplements over-the-counter, in whatever form you like: (I like the easy-to-swallow gel capsules)&lt;/item&gt;
      &lt;item&gt;Vitamin D &lt;list rend="ul"&gt;&lt;item&gt;🌱 By default, Vitamin D supplements are derived from… (quick web search)… the grease in sheep's wool? Huh. Also fish liver oil. Anyway, if you're vegan, make sure your bottle specifically says "vegan" or "from lichen/mushrooms". (If you're vegetarian, the sheep's-wool Vitamin D is fine, they don't kill the sheep for it.)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Omega-3 where EPA is ~60% of the Omega-3 total. For example, my 500mg Omega-3 capsules have 300mg EPA, 200mg DHA. &lt;list rend="ul"&gt;&lt;item&gt;🌱 By default, Omega-3 supplements come from fish. If you're veg(etari)?an, there are plant-based sources of Omega-3, but look carefully: most vegan Omega-3 supplements provide more DHA than EPA, which the above studies suggest fully cancel out the antidepressant effect. Double check the nutritional label to make sure it's ≥60% EPA. For example, this one is 300mg EPA + 200mg DHA. (not an affiliate link)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then, every day:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Take ~5000 IU of Vitamin D &lt;list rend="ul"&gt;&lt;item&gt;⚠️ be cautious if you have kidney stones, or are on medications that could interact with Vitamin D. "ask your doctor".&lt;/item&gt;&lt;item&gt;4,000 IU is the "official maximum safe dose", if you understandably don't trust a random internet blogger, even though she cited peer-reviewed sources.&lt;/item&gt;&lt;item&gt;10,000 IU if you're feeling daring / have darker skin / live in less sunny climates.&lt;/item&gt;&lt;item&gt;bonus: may improve immune response to Covid &amp;amp; influenza?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Take ~1500 mg of ≥60%-EPA Omega-3 &lt;list rend="ul"&gt;&lt;item&gt;⚠️ be cautious if you're on blood thinners, or other medications that could interact with Omega-3. again, "ask your doctor".&lt;/item&gt;&lt;item&gt;bonus: may improve cognition?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;(Don't quit your existing antidepressants if they're net-positive for you!) &lt;list rend="ul"&gt;&lt;item&gt;you may also want to ask your doctor about Amitriptyline, or those other best-effect-size antidepressants.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Can you get these doses of Vitamin D &amp;amp; Omega-3 through whole foods alone, no supplements? Probably, but it'd be expensive &amp;amp; tedious: you'd have to eat something like 2,000 calories of farmed salmon a day to get 5,000 IU/day of Vitamin D. As for Omega-3, eating mostly oily fishes would get you &amp;gt;1000mg of Omega-3, but they'd be more DHA than EPA, which the above studies suggest would cancel out the antidepressant effects.&lt;/p&gt;
    &lt;p&gt;The effect sizes on depression:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The best antidepressant: +0.417 &lt;list rend="ul"&gt;&lt;item&gt;like your mental health grade going from F to F+, or C to C+&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;1500mg of ≥60%-EPA Omega-3: +0.558 &lt;list rend="ul"&gt;&lt;item&gt;like your mental health grade going from F to D–, or C to B–&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;5000 IU of Vitamin D: +1.82 &lt;list rend="ul"&gt;&lt;item&gt;like your mental health grade going from F to C–, or C to A–&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For completeness &amp;amp; comparison, here's the effect size of other things on depression:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Any mainstream "bona-fide" psychotherapy (CBT, Psychodynamic, Humanist, Solutions-Focused): +0.35, source: Kamenov et al 2016 &lt;list rend="ul"&gt;&lt;item&gt;like going from C to C+&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Aerobic/Cardio Exercise: +0.79, source Ioannis et al 2018 &lt;list rend="ul"&gt;&lt;item&gt;like going from C to B–&lt;/item&gt;&lt;item&gt;(dose: "45 minutes, at moderate intensity, three times/week" ⇒ ~20 min/day)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Good Sleep: +1.10(???), a lot of interpretation &amp;amp; calculations, see footnote[2] &lt;list rend="ul"&gt;&lt;item&gt;like going from C to B&lt;/item&gt;&lt;item&gt;(dose: going from moderate insomnia to healthy sleep)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Bright Light Therapy: +0.487, source Menegaz de Almeida et al 2025 &lt;list rend="ul"&gt;&lt;item&gt;(the above paper reports Odds Ratio of 2.42, which converts to Cohen's d effect size of +0.487)&lt;/item&gt;&lt;item&gt;like going from C to C+&lt;/item&gt;&lt;item&gt;I went with Wirecutter's recommendation for a UV-free 10,000 lux lamp.&lt;/item&gt;&lt;item&gt;(dose: 10,000 lux, 30 min a day)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Mindfulness Meditation: +0.42, source Breedvelt et al 2019 &lt;list rend="ul"&gt;&lt;item&gt;like going from C to C+&lt;/item&gt;&lt;item&gt;(dose: 7 weeks, "153 min each week" ⇒ ~20 min/day)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;(And remember, you can stack any of the above interventions to get an even larger effect! You can't just naively add up the effect sizes, but I'd be surprised if the effect of {vitamin d + omega-3 + bright lamps + cardio + good sleep + meditation} combined ends up being less than +2.00. Two letter grades up means going from D to B, or, theoretically, from clinically depressed to flourishing! For more papers &amp;amp; my working research notes on "best bang for buck on depression", check out this Google Doc.)&lt;/p&gt;
    &lt;p&gt;Also, remember that all the above estimates are uncertain. And in general, when scientists replicate psychology experiments more rigorously, the effect size usually shrinks by ½. But, I think the overall qualitative picture is still strong: there exist high bang-for-buck ways to reduce depression, which are at least on par with drugs &amp;amp; therapy (possibly 2x to 4x better), that aren't (yet) common knowledge amongst policymakers &amp;amp; the public. And again, they're dirt cheap with minor-to-no adverse side effects. Moderate chance of a big win, for a known tiny cost. That's a positive "expected value" bet right there.&lt;/p&gt;
    &lt;p&gt;I got onto this research rabbithole a few months ago while borrowing my housemate's ADHD meds, which I may or may not eventually collect into a "JOYMAXXING" informal meta-meta-analysis. (: See me yap about it on video as a cartoon cat.) But for this blog post, I wanted to dive deeper into Vitamin D and Omega-3, since their effect sizes are so huge, and they're insultingly cheap &amp;amp; easy, compared to therapy or regular cardio.&lt;/p&gt;
    &lt;p&gt;Stay safe this winter, keep away the seasonal depression. Get your supplements, and reach out to your friends &amp;amp; loved ones!&lt;/p&gt;
    &lt;p&gt;💖,&lt;lb/&gt; ~ Nicky Case&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;I made up these ranges by requiring the standard letter grades F,D,C,B,A, to have their centers be -2,-1,0,+1,+2. Then, I made sure all in-between grades like C+ or A– had equal intervals. Each interval is +/- ⅙, or ⅓ wide:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;F---: -3.16 to -2.83&lt;/item&gt;
          &lt;item&gt;F--: -2.82 to -2.50&lt;/item&gt;
          &lt;item&gt;F–: -2.49 to -2.17&lt;/item&gt;
          &lt;item&gt;F: -2.16 to -1.83&lt;/item&gt;
          &lt;item&gt;F+: -1.82 to -1.50&lt;/item&gt;
          &lt;item&gt;D–: -1.49 to -1.17&lt;/item&gt;
          &lt;item&gt;D: -1.16 to -0.83&lt;/item&gt;
          &lt;item&gt;D+: -0.82 to -0.50&lt;/item&gt;
          &lt;item&gt;C–: -0.49 to -0.17&lt;/item&gt;
          &lt;item&gt;C: -0.16 to +0.17&lt;/item&gt;
          &lt;item&gt;C+: +0.18 to +0.50&lt;/item&gt;
          &lt;item&gt;B–: +0.51 to +0.83&lt;/item&gt;
          &lt;item&gt;B: +0.84 to +1.17&lt;/item&gt;
          &lt;item&gt;B+: +1.18 to +1.50&lt;/item&gt;
          &lt;item&gt;A–: +1.51 to +1.83&lt;/item&gt;
          &lt;item&gt;A: +1.84 to +2.17&lt;/item&gt;
          &lt;item&gt;A+: +2.18 to +2.50&lt;/item&gt;
          &lt;item&gt;A++: +2.51 to +2.83&lt;/item&gt;
          &lt;item&gt;A+++: +2.84 to +3.17&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lee et al 2023 reports the following effect sizes. Digital therapy for Insomnia → Sleep = 0.76, and Digital therapy for Insomnia → Depression = 0.42. Assuming the therapy for insomnia specifically affects depression only through better sleep (Digital therapy for Insomnia → Sleep → Depression), we can do an "Instrumental Variable" estimate of the effect of Sleep → Depression = 0.42 / 0.76 = 0.55. To be precise: this is saying, if you improve your sleep by 1 standard deviation, on average your depression improves by 0.55 standard deviations.&lt;/p&gt;
        &lt;p&gt;So: how many standard deviations is going from "moderate insomnia" to "healthy sleep"? The standard measure is the Insomnia Severity Index (ISI), which you can take online. A score of 0–7 means no insomnia, 8–14 is subclinical insomnia, 15–21 is clinical insomnia (moderate), 22–28 is clinical insomnia (severe). Let's be conservative and say we're just going from barely clinical to barely healthy: 15 to 7, or a reduction of 8 points. Yang et al 2009 says a 6-point reduction is 1.5 standard deviations, which means 4 points is 1 standard deviation. So a reduction of 8 points is 2 standard deviations. So, if you improve your sleep from insomniac to healthy, you improve by at least 8 points, which is 2 standard deviations, so your depression should improve by 2 × 0.55 standard deviations, or ~1.10.&lt;/p&gt;
        &lt;p&gt;Reminder that my estimate is full of assumptions upon assumptions &amp;amp; these error bars will compound. But I'd be surprised if the true causal effect of going from insomniac to healthy sleep isn't at least a "large" +0.8 effect. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46808251</guid><pubDate>Thu, 29 Jan 2026 10:35:00 +0000</pubDate></item><item><title>The Sovereign Tech Fund Invests in Scala</title><link>https://www.scala-lang.org/blog/2026/01/27/sta-invests-in-scala.html</link><description>&lt;doc fingerprint="47f2b49f06f2a0bf"&gt;
  &lt;main&gt;
    &lt;p&gt;Darja Jovanovic, Scala Center&lt;/p&gt;
    &lt;p&gt;Weâre truly excited to share that Scala has received an investment from the Sovereign Tech Fund to strengthen Scalaâs long-term security, maintenance, and developer experience.&lt;/p&gt;
    &lt;p&gt;The work is coordinated by the Scala Center and runs for two years, with a total investment of â¬377,300.&lt;/p&gt;
    &lt;p&gt;The Sovereign Tech Fund is a program of the Sovereign Tech Agency that globally invests in open software components that build our core digital infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Sovereign Tech Agency and the Sovereign Tech Fund&lt;/head&gt;
    &lt;p&gt;The Sovereign Tech Agency is the first publicly funded organization in Europe that supports the development, improvement, and maintenance of open digital infrastructures. It is financed by the German Federal Ministry for Digital Transformation and Government Modernisation and is a subsidiary of SPRIND, the Federal Agency for Disruptive Innovation.&lt;/p&gt;
    &lt;p&gt;The Sovereign Tech Agencyâs mission is to strengthen the open source ecosystem sustainably, focusing on resilience, technological diversity, and the people behind the code as foundations for a future-ready economy and modern society.&lt;/p&gt;
    &lt;p&gt;The Sovereign Tech Fund identifies and invests in open source software components that enable the creation of software, and supports key technologies with broad societal importance. Since October 2022, the Sovereign Tech Fund has invested a total of around â¬34 million in 95 critical technology projects.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scala is critical digital infrastructure&lt;/head&gt;
    &lt;p&gt;Scala is widely used to build and operate essential systems across multiple industries. These systems include data pipelines and distributed applications, and some are in highly regulated environments like finance and public services. In these contexts, reliability is paramount. The safety, sustainability, and evolution of the Scala language and its tooling directly impact systems that people and institutions rely on every day.&lt;/p&gt;
    &lt;p&gt;This is why, in 2016, the Scala Center was founded with a clear mission: to make the Scala open-source ecosystem stronger, more resilient, and sustainable over the long term. Thanks to the continued support of Scala Center industry partners (through the Advisory Board program), EPFL, and the worldwide Scala contributor community, the ecosystem continues to grow stronger every day.&lt;/p&gt;
    &lt;p&gt;And today, with the Sovereign Tech Fundâs investment in Scala, this commitment is reinforced at a public-infrastructure level. We are very thankful that the Fundâs support recognizes Scala as critical digital infrastructure and enables sustained, focused work on the languageâs core foundations over the coming years.&lt;/p&gt;
    &lt;head rend="h2"&gt;A closer look: what this investment will deliver&lt;/head&gt;
    &lt;head rend="h3"&gt;1) Security Audit&lt;/head&gt;
    &lt;p&gt;A dedicated security audit by Open Source Technology Improvement Fund (OSTIF) will uncover vulnerabilities and strengthen confidence in Scalaâs core components. This supports not only Scala users, but also the broader environments where Scala runs, for example as a component of complex software supply chains. We are super thankful to the OSTIF team and support!&lt;/p&gt;
    &lt;head rend="h3"&gt;2) Improvement of scoverage&lt;/head&gt;
    &lt;p&gt;scoverage is a key tool in the Scala ecosystem for measuring code coverage. Improving it increases the reliability of Scala codebases and helps teams detect gaps in testing earlier, especially as systems evolve.&lt;/p&gt;
    &lt;head rend="h3"&gt;3) Maintenance of the Standard Library / Core Library Modules and APIs&lt;/head&gt;
    &lt;p&gt;Long-term maintenance of core libraries and APIs is critical for stability. This includes keeping foundational modules healthy, reducing technical debt, and ensuring compatibility across versions.&lt;/p&gt;
    &lt;head rend="h3"&gt;4) Modernization and extension of the Standard Library / Core Library Modules and API Documentation&lt;/head&gt;
    &lt;p&gt;As Scala continues to evolve, modernizing and extending core modules ensures the language remains productive and relevant, while also supporting gradual adoption and stable upgrade paths. The work also brings improvements to API documentation and Scala websites, to improve understanding.&lt;/p&gt;
    &lt;head rend="h3"&gt;5) Build tool major update: sbt 2.0&lt;/head&gt;
    &lt;p&gt;Build tools are the backbone of developer productivity. The major update to sbt 2.0 will make Scala projects easier to build, maintain, and understand. This will be impactful for new users and contributors, as well as for established projects. Among other improvements, sbt 2 adopts Scala 3 (in place of 2.12) as the language for build definitions.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Scala Centerâs role&lt;/head&gt;
    &lt;p&gt;The Scala Center has been entrusted with coordinating the commissioned work, check out the team working on the projects.&lt;/p&gt;
    &lt;p&gt;We are very thankful that this support recognizes Scalaâs importance in the broader digital landscape, and for investing in foundational work that strengthens the reliability of the systems and services built on Scala across the public sector and industries.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stay informed and get involved&lt;/head&gt;
    &lt;p&gt;Weâll share updates as work progresses, including milestones, delivered improvements, and opportunities to engage with the effort.&lt;/p&gt;
    &lt;p&gt;Scala is critical digital infrastructure, so keeping it healthy is a shared responsibility. If youâre using Scala in production, maintaining libraries, or contributing to tooling and documentation, your feedback and involvement help keep Scala strong.&lt;/p&gt;
    &lt;p&gt;In addition to occasional blog posts such as this one, weâll also post more detailed updates, progress reports, and calls for feedback on our Discourse-based contributors forum at contributors.scala-lang.org. Please follow the relevant threads to stay informed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46809420</guid><pubDate>Thu, 29 Jan 2026 12:42:58 +0000</pubDate></item><item><title>A lot of population numbers are fake</title><link>https://davidoks.blog/p/a-lot-of-population-numbers-are-fake</link><description>&lt;doc fingerprint="3e41c1f13fb30ae2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Claude Code Opus 4.5 Performance Tracker&lt;/head&gt;
    &lt;p&gt;The goal of this tracker is to detect statistically significant degradations in Claude Code with Opus 4.5 performance on SWE tasks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;• Updated daily: Daily benchmarks on a curated subset of SWE-Bench-Pro&lt;/item&gt;
      &lt;item&gt;• Detect degradation: Statistical testing for degradation detection&lt;/item&gt;
      &lt;item&gt;• What you see is what you get: We benchmark in Claude Code CLI with the SOTA model (currently Opus 4.5) directly, no custom harnesses.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Summary&lt;/head&gt;
    &lt;head rend="h3"&gt;Daily Trend&lt;/head&gt;
    &lt;p&gt;Pass rate over time&lt;/p&gt;
    &lt;p&gt;Dashed line at 58% baseline with ±14.0% significance threshold&lt;/p&gt;
    &lt;head rend="h3"&gt;Weekly Trend&lt;/head&gt;
    &lt;p&gt;Aggregated 7-day pass rate&lt;/p&gt;
    &lt;p&gt;Dashed line at 58% baseline with ±5.6% significance threshold&lt;/p&gt;
    &lt;head rend="h3"&gt;Change Overview&lt;/head&gt;
    &lt;p&gt;Performance delta by period&lt;/p&gt;
    &lt;head rend="h3"&gt;Methodology&lt;/head&gt;
    &lt;p&gt;The goal of this tracker is to detect statistically significant degradations in Claude Code with Opus 4.5 performance on SWE tasks. We are an independent third party with no affiliation to frontier model providers.&lt;/p&gt;
    &lt;p&gt;Context: In September 2025, Anthropic published a postmortem on Claude degradations. We want to offer a resource to detect such degradations in the future.&lt;/p&gt;
    &lt;p&gt;We run a daily evaluation of Claude Code CLI on a curated, contamination-resistant subset of SWE-Bench-Pro. We always use the latest available Claude Code release and the SOTA model (currently Opus 4.5). Benchmarks run directly in Claude Code without custom harnesses, so results reflect what actual users can expect. This allows us to detect degradation related to both model changes and harness changes.&lt;/p&gt;
    &lt;p&gt;Each daily evaluation runs on N=50 test instances, so daily variability is expected. Weekly and monthly results are aggregated for more reliable estimates.&lt;/p&gt;
    &lt;p&gt;We model tests as Bernoulli random variables and compute 95% confidence intervals around daily, weekly, and monthly pass rates. Statistically significant differences in any of those time horizons are reported.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46810027</guid><pubDate>Thu, 29 Jan 2026 13:36:54 +0000</pubDate></item><item><title>Claude Code Daily Benchmarks for Degradation Tracking</title><link>https://marginlab.ai/trackers/claude-code/</link><description>&lt;doc fingerprint="3e41c1f13fb30ae2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Claude Code Opus 4.5 Performance Tracker&lt;/head&gt;
    &lt;p&gt;The goal of this tracker is to detect statistically significant degradations in Claude Code with Opus 4.5 performance on SWE tasks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;• Updated daily: Daily benchmarks on a curated subset of SWE-Bench-Pro&lt;/item&gt;
      &lt;item&gt;• Detect degradation: Statistical testing for degradation detection&lt;/item&gt;
      &lt;item&gt;• What you see is what you get: We benchmark in Claude Code CLI with the SOTA model (currently Opus 4.5) directly, no custom harnesses.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Summary&lt;/head&gt;
    &lt;head rend="h3"&gt;Daily Trend&lt;/head&gt;
    &lt;p&gt;Pass rate over time&lt;/p&gt;
    &lt;p&gt;Dashed line at 58% baseline with ±14.0% significance threshold&lt;/p&gt;
    &lt;head rend="h3"&gt;Weekly Trend&lt;/head&gt;
    &lt;p&gt;Aggregated 7-day pass rate&lt;/p&gt;
    &lt;p&gt;Dashed line at 58% baseline with ±5.6% significance threshold&lt;/p&gt;
    &lt;head rend="h3"&gt;Change Overview&lt;/head&gt;
    &lt;p&gt;Performance delta by period&lt;/p&gt;
    &lt;head rend="h3"&gt;Methodology&lt;/head&gt;
    &lt;p&gt;The goal of this tracker is to detect statistically significant degradations in Claude Code with Opus 4.5 performance on SWE tasks. We are an independent third party with no affiliation to frontier model providers.&lt;/p&gt;
    &lt;p&gt;Context: In September 2025, Anthropic published a postmortem on Claude degradations. We want to offer a resource to detect such degradations in the future.&lt;/p&gt;
    &lt;p&gt;We run a daily evaluation of Claude Code CLI on a curated, contamination-resistant subset of SWE-Bench-Pro. We always use the latest available Claude Code release and the SOTA model (currently Opus 4.5). Benchmarks run directly in Claude Code without custom harnesses, so results reflect what actual users can expect. This allows us to detect degradation related to both model changes and harness changes.&lt;/p&gt;
    &lt;p&gt;Each daily evaluation runs on N=50 test instances, so daily variability is expected. Weekly and monthly results are aggregated for more reliable estimates.&lt;/p&gt;
    &lt;p&gt;We model tests as Bernoulli random variables and compute 95% confidence intervals around daily, weekly, and monthly pass rates. Statistically significant differences in any of those time horizons are reported.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46810282</guid><pubDate>Thu, 29 Jan 2026 13:59:07 +0000</pubDate></item><item><title>Playing Board Games with Deep Convolutional Neural Network on 8bit Motorola 6809</title><link>https://ipsj.ixsq.nii.ac.jp/records/229345</link><description>&lt;doc fingerprint="31777073c4324395"&gt;
  &lt;main&gt;&lt;p&gt;WEKO3&lt;/p&gt;&lt;head rend="h3"&gt;アイテム&lt;/head&gt;&lt;head rend="h2"&gt; Playing Board Games with a Deep Convolutional Neural Network on the Motorola 6809 8-Bit Microprocessor &lt;/head&gt;&lt;p&gt;https://ipsj.ixsq.nii.ac.jp/records/229345&lt;/p&gt; https://ipsj.ixsq.nii.ac.jp/records/229345&lt;p&gt;9e1431e2-99f7-4d16-8f82-d7dcfa6a2045&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;名前 / ファイル&lt;/cell&gt;&lt;cell role="head"&gt;ライセンス&lt;/cell&gt;&lt;cell role="head"&gt;アクション&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt; IPSJ-GPWS2023012.pdf (275.3 kB) &lt;/cell&gt;&lt;cell&gt;&lt;p&gt; Copyright (c) 2023 by the Information Processing Society of Japan &lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;オープンアクセス&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="9"&gt;&lt;cell role="head"&gt;Item type&lt;/cell&gt;&lt;cell&gt;Symposium(1)&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;公開日&lt;/cell&gt;&lt;cell&gt;2023-11-10&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;タイトル&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;タイトル&lt;/cell&gt;&lt;cell&gt;Playing Board Games with a Deep Convolutional Neural Network on the Motorola 6809 8-Bit Microprocessor&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;タイトル&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;言語&lt;/cell&gt;&lt;cell&gt;en&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;タイトル&lt;/cell&gt;&lt;cell&gt;Playing Board Games with a Deep Convolutional Neural Network on the Motorola 6809 8-Bit Microprocessor&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;言語&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;言語&lt;/cell&gt;&lt;cell&gt;eng&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;キーワード&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;主題Scheme&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;主題&lt;/cell&gt;&lt;cell&gt;deep learning&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;キーワード&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;主題Scheme&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;主題&lt;/cell&gt;&lt;cell&gt;quantization&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;キーワード&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;主題Scheme&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;主題&lt;/cell&gt;&lt;cell&gt;neural networks&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;資源タイプ&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;資源タイプ識別子&lt;/cell&gt;&lt;cell&gt;http://purl.org/coar/resource_type/c_5794&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;資源タイプ&lt;/cell&gt;&lt;cell&gt;conference paper&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;著者所属&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Kayufu&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;著者所属(英)&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;en&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;Kayufu&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;著者名&lt;/cell&gt;&lt;cell&gt; Rémi, Coulom &lt;head&gt;× Rémi, Coulom&lt;/head&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;著者名(英)&lt;/cell&gt;&lt;cell&gt; Rémi, Coulom &lt;head&gt;× Rémi, Coulom&lt;/head&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;論文抄録&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;内容記述タイプ&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;内容記述&lt;/cell&gt;&lt;cell&gt;While training deep-learning neural networks often requires considerable amounts of computing power, inference is efficient, and can be run on small devices. Cell phones are a typical example, but they are still rather powerful. The research presented in this paper takes the challenge to the extreme by running a Go-playing convolutional neural network on the 6809 CPU, an 8-bit microprocessor launched by Motorola in 1978. The software was implemented on a Thomson MO5 microcomputer, and reached a playing strength on par with GNU Go.&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;論文抄録(英)&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;内容記述タイプ&lt;/cell&gt;&lt;cell&gt;Other&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;内容記述&lt;/cell&gt;&lt;cell&gt;While training deep-learning neural networks often requires considerable amounts of computing power, inference is efficient, and can be run on small devices. Cell phones are a typical example, but they are still rather powerful. The research presented in this paper takes the challenge to the extreme by running a Go-playing convolutional neural network on the 6809 CPU, an 8-bit microprocessor launched by Motorola in 1978. The software was implemented on a Thomson MO5 microcomputer, and reached a playing strength on par with GNU Go.&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;書誌情報&lt;/cell&gt;&lt;cell&gt; ゲームプログラミングワークショップ2023論文集 &lt;p&gt;巻 2023, p. 66-69, 発行日 2023-11-10&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;出版者&lt;/cell&gt;&lt;/row&gt;&lt;row span="9"&gt;&lt;cell&gt;言語&lt;/cell&gt;&lt;cell&gt;ja&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;出版者&lt;/cell&gt;&lt;cell&gt;情報処理学会&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46810337</guid><pubDate>Thu, 29 Jan 2026 14:03:12 +0000</pubDate></item><item><title>Break Me If You Can: Exploiting PKO and Relay Attacks in 3DES/AES NFC</title><link>https://www.breakmeifyoucan.com/</link><description>&lt;doc fingerprint="ecf8d84918a1ebd8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;This paper presents an in-depth analysis of vulnerabilities in MIFARE Ultralight C, MIFARE Ultralight AES, NTAG 223 DNA, NTAG 224 DNA, and widely circulated non-NXP Ultralight C compatible cards. We reveal multiple avenues to substantially weaken the security of each technology across a range of configurations.&lt;/p&gt;
    &lt;p&gt;Through relay-based man-in-the-middle techniques and partial key overwritesâoptionally combined with EEPROM tearing techniquesâan attacker can reduce the keyspace of two-key Triple DES (2TDEA) from 2112 to 228 or less in certain real-world deployments, making brute-force key recovery feasible with modest computational resources.&lt;/p&gt;
    &lt;p&gt;We further demonstrate how MIFARE Ultralight AES can be similarly affected when CMAC integrity checks are not enforced. The security of NTAG 223/224 DNA is undermined by the absence of integrity checks and the calculation of CMAC over Secure Unique NFC (SUN) messages, providing an unauthenticated ciphertext oracle that facilitates key recovery from a single tag.&lt;/p&gt;
    &lt;head rend="h2"&gt;Affected Products&lt;/head&gt;
    &lt;p&gt;The following NXP products and non-NXP compatible ICs are affected:&lt;/p&gt;
    &lt;head rend="h2"&gt;Impact Assessment&lt;/head&gt;
    &lt;p&gt;For genuine NXP Ultralight C: Using partial key overwrite across multiple tags sharing a static key, full 112-bit 2TDEA key recovery is achievable in days to weeks depending on available hardware and number of tags.&lt;/p&gt;
    &lt;p&gt;For non-NXP cards (ULCG, FJ8010, USCUID-UL): Flawed PRNGs and missing anti-tearing mechanisms enable complete key recovery from a single card in under 60 secondsâeven on a mobile phone.&lt;/p&gt;
    &lt;p&gt;For NTAG 223/224 DNA: The SUNCMAC_KEY can be recovered from a single tag in under a minute via partial key overwrite combined with offline CMAC brute-force against collected SUN messages.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key Contributions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Partial Key Overwrite Attack: Enables attackers with authenticated access to reduce key-recovery brute-force workload against 2TDEA and AES-128 keys given multiple source tags using the same key.&lt;/item&gt;
      &lt;item&gt;Theoretical Single-Tag Recovery: Method to recover the full 112-bit 2TDEA key from a single NXP Ultralight C tag in specific configurations, applicable even with diversified keys.&lt;/item&gt;
      &lt;item&gt;NTAG 22x DNA Attack: Partial key overwrite and tearing techniques applied to AES-128 protected NTAG 22x DNA, enabling significantly faster offline CMAC brute-force for recovering the SUN message authentication key.&lt;/item&gt;
      &lt;item&gt;Non-NXP Card Analysis: First systematic analysis of widespread non-NXP Ultralight C compatible cards, demonstrating implementation flaws (predictable PRNGs, absent anti-tearing) allowing near-instantaneous key recovery.&lt;/item&gt;
      &lt;item&gt;Real-World Deployment Survey: Empirical data from hospitality and other deployments showing configuration lapses around key diversification, lock bytes, and integrity mechanisms.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Questions &amp;amp; Answers&lt;/head&gt;
    &lt;p&gt;This research demonstrates vulnerabilities in widely deployed NFC technologies used for access control, ticketing, and hospitality. We show that cryptographic keys protecting MIFARE Ultralight C, MIFARE Ultralight AES, and NTAG 223/224 DNA tags can be recovered through a combination of relay attacks, partial key overwrites, and EEPROM manipulation techniques.&lt;/p&gt;
    &lt;p&gt;The core issue is that these tags lack adequate post-authentication integrity protection, and many deployments fail to properly configure available security features like lock bytes and key diversification.&lt;/p&gt;
    &lt;p&gt;No. The underlying cryptographic algorithms (3DES and AES-128) remain secure. The vulnerabilities arise from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Protocol design choices that allow unauthenticated memory writes after initial authentication&lt;/item&gt;
      &lt;item&gt;Lack of atomicity when writing cryptographic keys across multiple memory pages&lt;/item&gt;
      &lt;item&gt;Widespread misconfiguration in real-world deployments (unlocked memory, static keys)&lt;/item&gt;
      &lt;item&gt;Non-NXP compatible chips with severely flawed random number generators&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Yes. We initiated contact with NXP Semiconductors in July 2025 and provided them with a complete draft of our findings. NXP confirmed the findings in August 2025 and requested additional time for product recertification. We coordinated the publication timeline with NXP, balancing their recertification needs with the importance of informing the security community and affected parties.&lt;/p&gt;
    &lt;p&gt;The title comes directly from the default factory key programmed into every MIFARE Ultralight C chip by NXP. When you read the 16-byte 3DES key from a fresh Ultralight C tag, it spells out the ASCII string &lt;code&gt;BREAKMEIFYOUCAN!&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This appears to be a deliberately playful challenge left by NXP's engineers in 2008 for the security research community, and embedded directly in the Ultralight C's memory. We chose the paper's title to reflect this challenge, having demonstrated multiple practical attacks.&lt;/p&gt;
    &lt;p&gt;Of course, in any properly configured deployment, this default key should be replaced with a unique, securely generated key before deployment.&lt;/p&gt;
    &lt;p&gt;The risk to individual hotel guests is generally low for opportunistic attacks. These attacks require specialized equipment and technical knowledge. However, our research did demonstrate a successful credential forgery attack against a real hospitality system using a discarded room key.&lt;/p&gt;
    &lt;p&gt;Practical advice:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Don't leave your key card unattended for extended periods&lt;/item&gt;
      &lt;item&gt;Don't discard key cards in publicly accessible areas near the hotel&lt;/item&gt;
      &lt;item&gt;Report lost cards immediately so they can be deactivated&lt;/item&gt;
      &lt;item&gt;Use in-room safes and additional door locks when available&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Likely yes, to some degree. Our survey found that 100% of MIFARE Ultralight C systems examined were affected by one or more issues. The severity depends on your configuration:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;High risk: Static keys shared across all cards, unlocked key memory pages, non-NXP compatible cards in your supply chain&lt;/item&gt;
      &lt;item&gt;Medium risk: Key diversification implemented but lock bytes not configured, CMAC not enabled on Ultralight AES&lt;/item&gt;
      &lt;item&gt;Lower risk: Proper key diversification, locked memory pages, verified genuine NXP chips, CMAC enabled (for Ultralight AES)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We strongly recommend auditing your deployment against the mitigations listed below.&lt;/p&gt;
    &lt;p&gt;Some transit systems use MIFARE Ultralight C for limited-use tickets. If your system uses static keys and doesn't lock key memory pages, it could be vulnerable to the multi-tag key recovery attack. However, transit systems often have backend validation that may limit the practical impact.&lt;/p&gt;
    &lt;p&gt;Systems using MIFARE DESFire or other more advanced technologies are not affected by this specific research.&lt;/p&gt;
    &lt;p&gt;Our sampling found that approximately 34% of cards from hospitality deployments were not genuine NXP products. Non-NXP compatible cards (like Giantec GT23SC4489 "ULCG", Feiju FJ8010, or USCUID-UL) have severely flawed random number generators that allow key recovery from a single card in under 60 seconds.&lt;/p&gt;
    &lt;p&gt;How to check:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use &lt;code&gt;hf mfu info&lt;/code&gt;from the latest Proxmark3 firmware, which integrates fingerprinting for all counterfeit cards mentioned in the paper&lt;/item&gt;
      &lt;item&gt;ULCG cards can be quickly identified by their UID suffix ending in &lt;code&gt;1589&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;See details in our paper and other fingerprinting tools available in our GitHub repository for deeper inspection&lt;/item&gt;
      &lt;item&gt;Audit your supply chain and verify card sources&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIFARE DESFire: Not affected by this research. DESFire provides end-to-end encrypted sessions with integrity protection and is recommended as an upgrade path.&lt;/p&gt;
    &lt;p&gt;MIFARE Classic and MIFARE Plus: Not in scope for this paper, but MIFARE Classic has its own well-documented vulnerabilities (Crypto1 weaknesses) which are mitigated in MIFARE Plus, provided it is properly configured.&lt;/p&gt;
    &lt;p&gt;ICODE DNA, UCODE DNA, NTAG 424 DNA: We examined these briefly. NTAG 424 DNA appears to require authentication before key modification, which mitigates the partial key overwrite attack. See the full paper for details.&lt;/p&gt;
    &lt;p&gt;1. Audit your current deployment:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check if lock bytes are configured on key pages (Lock byte 3, bit 7 for Ultralight C)&lt;/item&gt;
      &lt;item&gt;Verify whether you're using static or diversified keys&lt;/item&gt;
      &lt;item&gt;Test sample cards for non-NXP compatible chips&lt;/item&gt;
      &lt;item&gt;For Ultralight AES: check if &lt;code&gt;SEC_MSG_ACT&lt;/code&gt;is enabled&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. For new card issuance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Implement key diversification using UID and a site-specific salt&lt;/item&gt;
      &lt;item&gt;Permanently lock key memory pages after personalization&lt;/item&gt;
      &lt;item&gt;Enable authentication attempt limits where available&lt;/item&gt;
      &lt;item&gt;Verify genuine NXP chips before deployment&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;3. For existing deployments with static keys:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If key pages can still be locked, do so immediately&lt;/item&gt;
      &lt;item&gt;Plan migration to diversified keys or more secure technology&lt;/item&gt;
      &lt;item&gt;Implement additional backend validation where possible&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Partially. If the key memory pages and configuration bytes are not yet locked, you can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lock the key pages to prevent the partial key overwrite attack&lt;/item&gt;
      &lt;item&gt;Enable &lt;code&gt;AUTH_LIM&lt;/code&gt;on Ultralight AES to limit brute-force attempts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However: If you're using static keys across your deployment, locking the pages only prevents new attacksâit doesn't change the fact that an attacker with enough cards could still recover the key through other means. Migration to diversified keys is the proper long-term solution.&lt;/p&gt;
    &lt;p&gt;For non-NXP compatible cards: These cannot be meaningfully secured and should be replaced with genuine NXP products.&lt;/p&gt;
    &lt;p&gt;For applications requiring higher security assurance, we recommend migrating to MIFARE DESFire EV3 or similar advanced contactless smart card technologies. These provide:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;End-to-end encrypted communication sessions&lt;/item&gt;
      &lt;item&gt;Mandatory integrity protection (not optional)&lt;/item&gt;
      &lt;item&gt;Hardware-level countermeasures against tearing and manipulation&lt;/item&gt;
      &lt;item&gt;Secure key storage with proper atomicity guarantees&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While Ultralight AES is an improvement over Ultralight C, its security still depends heavily on proper configuration, whereas DESFire provides stronger security by default.&lt;/p&gt;
    &lt;p&gt;MIFARE Ultralight C stores its 112-bit 2TDEA key across four 4-byte memory pages (pages 44-47). The tag's firmware doesn't enforce atomic writes across all four pagesâeach page can be written independently.&lt;/p&gt;
    &lt;p&gt;After gaining authenticated access via a relay attack, an attacker can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Overwrite three of the four key pages with known values (e.g., zeros)&lt;/item&gt;
      &lt;item&gt;Brute-force the remaining 28 bits (~228 possibilities)&lt;/item&gt;
      &lt;item&gt;Repeat on different tags, targeting different key quarters each time&lt;/item&gt;
      &lt;item&gt;Combine the four recovered segments to reconstruct the full key&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This reduces the attack complexity from 2112 to roughly 4 Ã 228, making it feasible with modest hardware.&lt;/p&gt;
    &lt;p&gt;The mutual authentication in Ultralight C does work correctlyâboth the reader and tag prove they know the shared secret. The problem is what happens after authentication.&lt;/p&gt;
    &lt;p&gt;Unlike MIFARE DESFire, Ultralight C has no post-authentication integrity protection. All commands after authentication are sent in plaintext without any MAC or encryption. An attacker who relays the authentication exchange can then inject their own commands to the now-authenticated tag.&lt;/p&gt;
    &lt;p&gt;Crucially, the tag has no timing constraintsâit will wait indefinitely for the reader's response during authentication, eliminating the tight timing windows that normally make relay attacks difficult.&lt;/p&gt;
    &lt;p&gt;The attacks can be performed with relatively inexpensive, commercially available hardware:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Relay attack: Two Flipper Zero devices communicating over 433 MHz, or Proxmark3 devices&lt;/item&gt;
      &lt;item&gt;Online brute-force: Proxmark3 or Flipper Zero (~100 auth attempts/second)&lt;/item&gt;
      &lt;item&gt;Offline computation: Standard laptop (for non-NXP cards) or GPU cluster (for 2-tag variant on genuine cards)&lt;/item&gt;
      &lt;item&gt;Tearing attacks: Proxmark3 with precise timing, or even Flipper Zero with busy-loop timing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Total equipment cost is well under $500, and the techniques are within reach of moderately skilled attackers.&lt;/p&gt;
    &lt;p&gt;All tools and scripts are available on GitHub at github.com/zc-public/breakme-resources. Relevant code has also been contributed to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Proxmark3 firmware repository&lt;/item&gt;
      &lt;item&gt;Flipper Zero firmware (version 1.4.0+)&lt;/item&gt;
      &lt;item&gt;ChameleonUltra firmware&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The tools include key recovery scripts, fingerprinting utilities, and optimized brute-force implementations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mitigations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable CMAC integrity verification on all AES-protected communications (SEC_MSG_ACT for Ultralight AES)&lt;/item&gt;
      &lt;item&gt;Implement key diversification using card UID and a site-specific key or salt as input to a secure KDF&lt;/item&gt;
      &lt;item&gt;Lock critical memory pages including key pages, AUTH0, and configuration bytes to prevent modification&lt;/item&gt;
      &lt;item&gt;Enable authentication attempt counters (AUTH_LIM) where available and lock the configuration&lt;/item&gt;
      &lt;item&gt;Verify supply chain integrity and replace non-NXP compatible cards with genuine NXP products where security is required&lt;/item&gt;
      &lt;item&gt;Store CMAC over critical data including UID and hardware counters for technologies without secure messaging&lt;/item&gt;
      &lt;item&gt;Consider migration to MIFARE DESFire EV3 or similar technologies with end-to-end encryption and hardware-level countermeasures&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Disclosure Timeline&lt;/head&gt;
    &lt;head rend="h2"&gt;Resources&lt;/head&gt;
    &lt;p&gt;The full technical paper is available on ePrint. Proof-of-concept tools and supporting materials are published on GitHub, with relevant code contributed to the Proxmark3, Flipper Zero, and ChameleonUltra firmware repositories.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46810536</guid><pubDate>Thu, 29 Jan 2026 14:20:21 +0000</pubDate></item><item><title>How to Choose Colors for Your CLI Applications (2023)</title><link>https://blog.xoria.org/terminal-colors/</link><description>&lt;doc fingerprint="66a2137707fca2cf"&gt;
  &lt;main&gt;
    &lt;p&gt;Letâs say youâre creating a CLI tool which has to display syntax highlighted source code. You begin by choosing some colors which look nice with your chosen terminal theme:&lt;/p&gt;
    &lt;p&gt;Nice! However, who knows if itâll still look good for people who use a theme different to yours? It seems sensible to try out the defaults, at least. Letâs start with the macOS Terminal.app default theme:&lt;/p&gt;
    &lt;p&gt;Youch! It seems fair to try the Tango themes next, since those are the default on e.g. Ubuntu:&lt;/p&gt;
    &lt;p&gt;Hmm, better, but not by much. Finally, letâs try what is likely the most popular custom terminal theme – Solarized:&lt;/p&gt;
    &lt;p&gt;Well then … Letâs take a look at each palette and investigate.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sorcerer&lt;/head&gt;
    &lt;p&gt;In Sorcerer, all colors are readable on the default background except for &lt;code&gt;black&lt;/code&gt;,
which is in fact darker than the background.
This is useful as the background color
for status bars and the like.
&lt;code&gt;white&lt;/code&gt; is the same color as
the default foreground,
and &lt;code&gt;brblack&lt;/code&gt; is a nice faded color.
Additionally, &lt;code&gt;brwhite&lt;/code&gt; is
even lighter than the foreground;
this allows for subtle emphasization
of important text
like error messages and titles.&lt;/p&gt;
    &lt;head rend="h2"&gt;Basic&lt;/head&gt;
    &lt;p&gt;The Basic themes are, well, horrendous. Really owning that 90s xterm look, it seems. &lt;code&gt;bryellow&lt;/code&gt; is unreadable in light mode
(check out that function name
from the code sample earlier),
while in dark mode
both &lt;code&gt;blue&lt;/code&gt; and &lt;code&gt;brblue&lt;/code&gt;
are totally illegible.&lt;/p&gt;
    &lt;p&gt;That leaves us with thirteen colors we can safely use:&lt;/p&gt;
    &lt;head rend="h2"&gt;Tango&lt;/head&gt;
    &lt;p&gt;In my opinion these did a lot better than Terminal.appâs Basic themes, but they are still far from perfect. &lt;code&gt;bryellow&lt;/code&gt; is again unreadable in the light theme,
and perhaps &lt;code&gt;brgreen&lt;/code&gt; is
a little difficult to see,
though itâs nothing that would
stop me from using &lt;code&gt;brgreen&lt;/code&gt;
in an application.&lt;/p&gt;
    &lt;p&gt;At this point you may have noticed how the greyscales – &lt;code&gt;black&lt;/code&gt;, &lt;code&gt;brblack&lt;/code&gt;, &lt;code&gt;white&lt;/code&gt; &amp;amp; &lt;code&gt;brwhite&lt;/code&gt; –
have remained consistent
between light and dark themes
for both Basic and Tango.
Of course,
this means that
&lt;code&gt;{,br}white&lt;/code&gt; is unreadable in Tango Light
(owing to the light background)
and &lt;code&gt;black&lt;/code&gt; is unreadable in Tango Dark
(owing to the dark background).&lt;/p&gt;
    &lt;p&gt;In other words: forget about that idea of mine from earlier about using &lt;code&gt;brwhite&lt;/code&gt; to emphasize content.
Unless, of course,
you donât mind if your
eminently emphasized words
are completely unreadable
for the user of your software
who deigns to use the default light theme
of A Popular Linux Distro.&lt;/p&gt;
    &lt;p&gt;On the other hand, using &lt;code&gt;brblack&lt;/code&gt; to de-emphasize content
still seems fine to me.
I suppose some extra contrast
for &lt;code&gt;brblack&lt;/code&gt; in Tango Dark
would be nice,
but with text which is meant to be ignored
I donât think this matters much.&lt;/p&gt;
    &lt;p&gt;And lo, but ten colors remain.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solarized&lt;/head&gt;
    &lt;p&gt;Solarized is a curious beast. Every color in it was chosen using L*a*b*, a perceptually-uniform color space from the 1970s. (For what itâs worth, color science has progressed significantly since then; the only reason Ethan Schoonover used L*a*b* is that itâs commonly used in photography, and he used to be a professional photographer.)&lt;/p&gt;
    &lt;p&gt;Its lightnesses are perfectly symmetrical so that Solarized Light and Dark can share a set of accent colors while maintaining identical contrast. Moreover, the warm tones of the light theme and cool tones of the dark theme are complementary. (The hue gap is closer to 150Â° than 180Â° in reality. See here and here to compare hue values.)&lt;/p&gt;
    &lt;p&gt;Solarized is also incredibly popular. I have no data here, but as of the date of writing itâs the most starred theme repository on GitHub I can find. Solarized has 15.4 thousand stars at the moment, while the next-closest is Gruvbox with 11.8 thousand. Solarized is available as a plugin or sometimes even as a built-in preset in damn near every popular terminal emulator and editor on the planet.&lt;/p&gt;
    &lt;p&gt;To understand Solarizedâs peculiar arrangement of the 16-color palette, we have to travel back in time to 2011 when Solarized was first released. In this dark era, terminals supporting 24-bit color didnât exist / werenât widespread. One option common among Vim themes at the time was to round every color to the nearest 256-color palette value. In Solarizedâs case, this destroys the mathematical symmetry at the heart of the theme. (Iâm not kidding, it looks awful.)&lt;/p&gt;
    &lt;p&gt;The solution – rather, hack – chosen at the time was to distill all the colors used in the Vim interface down to a palette of sixteen colors. Conveniently, Solarizedâs accent colors fit nicely into the non-bright column of the 16-color palette, while Solarizedâs monotones fit into the bright column. Once the user sets their terminal to use the Solarized palette, Vim can color its entire interface using only the 16-color palette and get correct color values, no clunky color approximations needed.&lt;/p&gt;
    &lt;p&gt;The downside to all this is that an application which uses any of the bright colors which Solarized co-opted for itself will look strange. Users of Solarized – and, by god, thereâs so many of them – appear frequently on issue trackers asking why command-line output is inexplicably gray or even invisible as a result of CLIs using these forsaken bright colors.&lt;/p&gt;
    &lt;p&gt;Our beloved &lt;code&gt;brblack&lt;/code&gt;
is unreadable in Solarized Dark,
so weâll have to strike it from the table
in addition to the affected bright colors.&lt;/p&gt;
    &lt;head rend="h2"&gt;A sad note about bold&lt;/head&gt;
    &lt;p&gt;Far back in the past, there was no way for terminals to display bright colors. As a workaround, manufacturers (weâre talking about physical terminals here) started making all bold text bright instead of using a heavier font weight. One way or another this ended up in the default settings of many modern terminal emulators (in spite of not being in the standard), meaning that regular colorful text made bold can become bright too, depending on the userâs configuration.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;And so, I present to you the final version of our table of acceptable colors:&lt;/p&gt;
    &lt;p&gt;Bold: ââ boldblack ââ boldbrblack ââ boldred ââ boldbrred ââ boldgreen ââ boldbrgreen ââ boldyellow ââ boldbryellow ââ boldblue ââ boldbrblue ââ boldmagenta ââ boldbrmagenta ââ boldcyan ââ boldbrcyan ââ boldwhite ââ boldbrwhite % â&lt;/p&gt;
    &lt;p&gt;Only eleven out of our thirty-two possible color settings are permissible, given that we want applications to remain readable for as many people as we can.&lt;/p&gt;
    &lt;p&gt;If youâre developing a command-line tool which will be used by anyone apart from yourself, I strongly recommend you limit your use of color to the ones Iâve identified here as being âmostly alrightâ and ânot unreadable in a common configuration used by tons of peopleâ.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix&lt;/head&gt;
    &lt;p&gt;You probably didnât notice, but I styled the âterminal windowsâ in this post to look as similar as possible to macOS Terminal.app windows through painstaking color picking and pixel counting.&lt;/p&gt;
    &lt;p&gt;The dimensions in each windowâs titlebar matches as closely as I can with its actual dimensions on-screen.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;colortest&lt;/code&gt; and &lt;code&gt;highlight&lt;/code&gt; utilities
are entirely fictional.&lt;/p&gt;
    &lt;p&gt;Terminal.app doesnât actually provide individual access to the light and dark variants of Basic; they appear as a single theme, which switches seamlessly when the OS theme changes. As far as I know, this reactive functionality isnât exposed to any other theme, whether pre-installed or user-created. In order to capture this, I made the terminal windows in this post react to whether the rest of the site is in light or dark mode, except for the Basic windows. They remain fixed in either light or dark mode, since in real life youâll never see, for example, a light Basic terminal with dark window chrome.&lt;/p&gt;
    &lt;p&gt;Luna Razzaghipour&lt;lb/&gt;29 January 2023&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46810904</guid><pubDate>Thu, 29 Jan 2026 14:49:08 +0000</pubDate></item><item><title>Deep dive into Turso, the "SQLite rewrite in Rust"</title><link>https://kerkour.com/turso-sqlite</link><description>&lt;doc fingerprint="45c430185fd3b0"&gt;
  &lt;main&gt;
    &lt;p&gt;We're sorry but this website doesn't work properly without JavaScript enabled. Please enable it to continue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46810950</guid><pubDate>Thu, 29 Jan 2026 14:51:56 +0000</pubDate></item><item><title>OTelBench: AI struggles with simple SRE tasks (Opus 4.5 scores only 29%)</title><link>https://quesma.com/blog/introducing-otel-bench/</link><description>&lt;doc fingerprint="3f5885f907369ecf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Benchmarking OpenTelemetry: Can AI trace your failed login?&lt;/head&gt;
    &lt;p&gt;Frontier AI models have become excellent at writing functions, but can they actually debug production systems?&lt;/p&gt;
    &lt;p&gt;To fix outages, you first need to see what’s happening. In a microservices world, this means producing structured events that track a single request as it hops from service to service.&lt;/p&gt;
    &lt;p&gt;We asked 14 models to add distributed traces to existing codebases, using the standard method: OpenTelemetry instrumentation. We picked tasks that would be easy for a Site Reliability Engineer (SRE).&lt;/p&gt;
    &lt;p&gt;We are releasing OTelBench as an open-source benchmark, with all tasks in QuesmaOrg/otel-bench. We use the Harbor framework (by the creators of TerminalBench), so you can easily run it yourself to reproduce results, test new models, or create benchmarks for your own use cases (we welcome contributions!).&lt;/p&gt;
    &lt;head rend="h2"&gt;Background: What is distributed tracing?&lt;/head&gt;
    &lt;p&gt;When an app runs on a single machine, you can often trace an error by scrolling through a log file. But when it runs across 50 microservices, that single request gets scattered into a chaotic firehose of disconnected events. Distributed tracing solves this by linking them back together, allowing you to follow a user action, like clicking Login, as it jumps from the API Gateway, to the Auth Service, to the Database, and back.&lt;/p&gt;
    &lt;p&gt;To make this work, you need instrumentation. This is code that you add to your app to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Start a trace when a request comes in.&lt;/item&gt;
      &lt;item&gt;Pass the TraceID (context) when your app calls another service.&lt;/item&gt;
      &lt;item&gt;Send the data to a backend so you can see the graph.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;OpenTelemetry (OTel) is the industry standard for telemetry data. Its ecosystem includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Semantic conventions: A unified schema replaces chaotic naming (e.g., &lt;code&gt;ip_address&lt;/code&gt;vs&lt;code&gt;host.ip&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Universal SDKs: Official libraries support every major programming language.&lt;/item&gt;
      &lt;item&gt;The Collector: A centralized agent processes and enriches data (e.g., adding Kubernetes tags) before export.&lt;/item&gt;
      &lt;item&gt;Auto-instrumentation: Runtime agents inject code to wrap calls, though this often results in noisy data.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, standard doesn’t mean easy. We know this firsthand from our contributions to the ecosystem, such as Go compile-time instrumentation. The process may be difficult, especially due to complexity, as 39% of respondents complained in the 2025 Observability Survey.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarking OpenTelemetry instrumentation&lt;/head&gt;
    &lt;p&gt;We tested 14 frontier LLMs on 23 realistic OpenTelemetry instrumentation tasks across 11 programming languages: Go, Java, C++, Python, JavaScript, PHP, Ruby, Rust, Erlang, .NET, and Swift.&lt;/p&gt;
    &lt;p&gt;It is essential to benchmark various technologies since realistic distributed systems are polyglot. To make OpenTelemetry work, the system needs to work for all of these services - if we lose track at only one service, the chain of logs gets broken.&lt;/p&gt;
    &lt;p&gt;The final benchmark run cost $522 in LLM tokens across 966 runs (23 tasks × 3 attempts × 14 models).&lt;/p&gt;
    &lt;head rend="h3"&gt;Task&lt;/head&gt;
    &lt;p&gt;We start with basic tasks such as adding instrumentation to a single microservice, in a single language. The AI agents get a small microservice with around 300 lines of code from a realistic application, and work in a Linux terminal, editing it, and running any commands if needed.&lt;/p&gt;
    &lt;p&gt;For example, here is the prompt for go-microservices-traces:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Your task is: Add OTEL tracing to all microservices.&lt;/p&gt;
      &lt;p&gt;Requirements:&lt;/p&gt;
      &lt;item&gt;Instrumentation should match conventions and well-known good practices.&lt;/item&gt;
      &lt;item&gt;Instrumentation must match the business domain of the microservices.&lt;/item&gt;
      &lt;item&gt;Traces must be sent to the endpoint defined by a standard OTEL environment variable.&lt;/item&gt;
      &lt;item&gt;Use the recent version of the OTEL SDK.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;We tested if it satisfies the basic criteria of OpenTelemetry instrumentation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Example&lt;/head&gt;
    &lt;p&gt;How do LLMs fail? Let’s analyze a common failure mode.&lt;/p&gt;
    &lt;p&gt;Consider a web service from our benchmark where a user searches and retrieves results. The test simulates two distinct user actions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Happy path: User searches, gets a token, retrieves results successfully&lt;/item&gt;
      &lt;item&gt;Error test: User tries to retrieve results with an invalid token (gets 404)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A human engineer would immediately distinguish these as two independent events, resulting in two separate traces: one for the successful search and one for the failed request.&lt;/p&gt;
    &lt;p&gt;The code structure makes this clear – two separate blocks, each representing a user action:&lt;/p&gt;
    &lt;code&gt;// User Action 1: Search and get results (happy path)
{
    response := client.Post("/search", query)
    result := client.Get("/result?token=" + response.Token)
}

// User Action 2: Error test (invalid token)
{
    result := client.Get("/result?token=invalid")  // Should return 404
}&lt;/code&gt;
    &lt;p&gt;We would expect:&lt;/p&gt;
    &lt;p&gt;Yet, sometimes models failed to recognize these as separate user actions. Instead of two traces, they produced:&lt;/p&gt;
    &lt;p&gt;The core issue: Models apply instrumentation mechanically to every HTTP call without understanding the business context. They see “HTTP requests” and link them all together, rather than recognizing “these are two separate user journeys.”&lt;/p&gt;
    &lt;p&gt;The models successfully instrumented the HTTP calls, but failed to propagate the Context correctly. They treated the timeline as a single flat list of events rather than two distinct hierarchical trees.&lt;/p&gt;
    &lt;p&gt;Our tests don’t just check compilation. We verify correct span names, parent-child relationships, valid trace IDs, and context propagation. Many models produced compiling code that generated malformed traces – proving that “it builds” is not enough for SRE work.&lt;/p&gt;
    &lt;head rend="h2"&gt;Observations&lt;/head&gt;
    &lt;head rend="h3"&gt;Models&lt;/head&gt;
    &lt;p&gt;We were surprised that even the top models (as of Jan 2026) struggle. The tasks we proposed were trivial compared to real-world scenarios. In a typical SRE job, services are massive, legacy-ridden, and poorly documented. If models fail on 300 lines of clean Go code, they cannot handle production.&lt;/p&gt;
    &lt;p&gt;We were surprised that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claude Opus 4.5, the best model, got just 29% of these relatively simple tasks.&lt;/item&gt;
      &lt;item&gt;Gemini 3 Pro (which aces at general intelligence) didn’t have an edge over the much cheaper Gemini 3 Flash.&lt;/item&gt;
      &lt;item&gt;GPT 5.2 Codex was substantially worse than GPT 5.2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Languages&lt;/head&gt;
    &lt;p&gt;Each language has a different toolset, so it is not an apples-to-apples comparison. Our benchmark is too small to perform a comprehensive per-language comparison, yet even preliminary trends are striking.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cost and time efficiency&lt;/head&gt;
    &lt;p&gt;In every practical application, cost and speed matter. As of Jan 2026, the Pareto frontier consists of only four models, given model performance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;19%&lt;/code&gt;Gemini 3 Flash (cost and speed) - the cheapest and fastest model in this benchmark (11x cheaper and 2x faster than Claude Opus 4.5)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;22%&lt;/code&gt;Claude Sonnet 4.5 (speed)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;26%&lt;/code&gt;GPT 5.2 (cost)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;29%&lt;/code&gt;Claude Opus 4.5 (cost and speed) — the best model in this benchmark, the most expensive but reasonably fast&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why OpenTelemetry instrumentation is hard for AI&lt;/head&gt;
    &lt;p&gt;OpenTelemetry has all the potential to be a perfect task for AI agents — it is long and tedious work, requiring a lot of scrutiny, but ultimately one that has clear specifications and can be easily tested.&lt;/p&gt;
    &lt;p&gt;Yet, even the frontier models fail miserably.&lt;/p&gt;
    &lt;head rend="h3"&gt;It is a job, not a puzzle&lt;/head&gt;
    &lt;p&gt;Instrumentation of even a small service involves long-horizon tasks, which remain at the frontier of the current AI model progress. It requires diligently connecting all pieces of code and testing them correctly.&lt;/p&gt;
    &lt;head rend="h3"&gt;Requires polyglot backend development skills&lt;/head&gt;
    &lt;p&gt;Realistic services use multiple languages and technologies. It is not enough to know the concept of distributed tracing, the OpenTelemetry standard, or even the APIs of SDKs. The agent must know CMake for C++, module systems for Go, or dependency management for Java - things we tested in our previous benchmark, CompileBench.&lt;/p&gt;
    &lt;p&gt;Usually, cloud environments are mixtures of the newest versions of technologies (sometimes past the training cut-off dates of AI models) and legacy systems. We cannot cherry-pick or rewrite everything, since a possible outage would be too costly. We need to support all languages and frameworks used in the cloud.&lt;/p&gt;
    &lt;p&gt;A lot of current AI progress focuses on the most popular languages (Python and TypeScript) and reasonably modern frameworks and build systems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Less training data&lt;/head&gt;
    &lt;p&gt;Although adding instrumentation is a standard engineering task, it is not common practice in open-source. The most popular applications, where reliability matters the most, are in private repositories of big tech companies such as Apple, Airbnb, or Netflix.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;head rend="h3"&gt;Key takeaways&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Best models struggle: The state-of-the-art Claude Opus 4.5 solved only 29% of tasks.&lt;/item&gt;
      &lt;item&gt;Language gaps: Models failed completely on Java, Ruby, and Swift. C++ led at 37% (boosted by an easier task), Go reached 20%.&lt;/item&gt;
      &lt;item&gt;Silent failures: Many solutions compiled correctly but produced malformed traces or conflated distinct user journeys.&lt;/item&gt;
      &lt;item&gt;Cost efficiency: Gemini 3 Flash exceeds Gemini 3 Pro’s performance (18%) at a fraction of the cost.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;AI SRE is still mostly hype, but there is hope&lt;/head&gt;
    &lt;p&gt;AI SRE in 2026 is what DevOps Anomaly Detection was in 2015 — bold claims backed by huge marketing budgets, but lacking independent verification. There are stories of SaaS vendors abruptly killing the observability stack. Our results mirror ClickHouse’s findings: while LLMs can assist, they lack the capabilities of a skilled SRE.&lt;/p&gt;
    &lt;p&gt;Claude Opus 4.5, GPT-5.2, and Gemini 3 models show promising signals. Some hard tasks like go-microservices-traces reached 55% pass rate. With more environments for Reinforcement Learning with Verified Rewards, this looks like a solvable problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;Reliable software is incredibly economically valuable, but today it requires too much toil. No one wants to be woken up at 2 AM to troubleshoot.&lt;/p&gt;
    &lt;p&gt;We need a North Star to navigate the current AI boom. Just as SWE-Bench and TerminalBench2.0 became standards for software engineering, we need an SRE-style benchmark for distributed systems. Does the industry need newer models, or perhaps multi-agent systems? A good benchmark will tell us.&lt;/p&gt;
    &lt;p&gt;We invite you to explore the full results on OTelBench and help us expand the test suite on QuesmaOrg/otel-bench. Have you tried using LLMs for observability? We are curious to hear if your experience matches our findings—or if you’ve found a workflow that actually works.&lt;/p&gt;
    &lt;p&gt;But for now, the verdict is clear: if you need distributed tracing across services, expect to write that code yourself.&lt;/p&gt;
    &lt;p&gt;Stay tuned for future posts and releases&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46811588</guid><pubDate>Thu, 29 Jan 2026 15:37:21 +0000</pubDate></item><item><title>Days numbered for 'risky' lithium-ion batteries</title><link>https://www.livescience.com/technology/engineering/days-numbered-for-risky-lithium-ion-batteries-scientists-say-after-fast-charging-breakthrough-in-sodium-ion-alternative</link><description>&lt;doc fingerprint="7918919de2c527c5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Days numbered for 'risky' lithium-ion batteries, scientists say, after fast-charging breakthrough in sodium-ion alternative&lt;/head&gt;
    &lt;p&gt;An innovative approach to battery materials could bring sodium-ion energy density and charging speeds far closer to those of lithium-ion, scientists say.&lt;/p&gt;
    &lt;p&gt;Newly developed sodium-ion (Na-ion) batteries could offer much faster charging speeds, higher energy density and improvements in safety compared with conventional lithium-ion (Li-ion) batteries, scientists say.&lt;/p&gt;
    &lt;p&gt;Using Na-ion batteries, an alternative to the Li-ion batteries found in the majority of today's devices, researchers at the Tokyo University of Science used a new carbon-based electrolyte to improve Na-ion energy density and charge speeds.&lt;/p&gt;
    &lt;p&gt;Scientists have been investigating Na-ion batteries as an alternative to Li-ion batteries because of their improved stability and low cost, but several bottlenecks and limitations have blocked the technology's advancement.&lt;/p&gt;
    &lt;p&gt;All batteries contain an anode and a cathode, the two electrodes that determine how current flows into and out of the device. In Li-ion batteries, the cathode is made primarily of graphite, as it's an excellent material for storing lithium ions to be discharged later.&lt;/p&gt;
    &lt;p&gt;But Na-ion batteries use hard carbon (HC) — a porous combination of thousands of "turbostratic basic structural units," essentially a complex crystalline structure, that excels at storing sodium ions. This is, in theory, a very fast-charging material.&lt;/p&gt;
    &lt;p&gt;Previous research into HC found it difficult to prove that this theoretical charging rate is practically possible, however, because ions entering the dense electrolyte at high speed experience a slowdown similar to a traffic jam. But in a new study published Dec. 15, 2025, in the journal Chemical Science, the scientists set out to overcome this hurdle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limiting the risks of Li-ion batteries&lt;/head&gt;
    &lt;p&gt;The researchers combined small concentrations of HC with aluminum oxide, a chemically inactive material, into a combined electrode. This allowed ions to flow freely into the HC particles with no "traffic'" issues.&lt;/p&gt;
    &lt;p&gt;Get the world’s most fascinating discoveries delivered straight to your inbox.&lt;/p&gt;
    &lt;p&gt;With the problem overcome, the researchers then proved that sodium ions could enter HC at similar rates to lithium ions entering graphite in a Li-ion battery.&lt;/p&gt;
    &lt;p&gt;The researchers also found that the bottleneck for the entire process is the rate at which ions fill the "pores" within HC, where "pores" describe the process in which ions form pseudo-metallic clusters inside the nanoscopic pores across the surface of HC.&lt;/p&gt;
    &lt;p&gt;Through careful analysis, the researchers found that sodium ions require less energy to form these clusters. The finding indicates that, under the right conditions, Na-ion batteries — also called SIBs — can achieve faster charge rates than Li-ion batteries can.&lt;/p&gt;
    &lt;p&gt;"A key point of focus for developing improved HC materials for fast-chargeable SIBs is to attain faster kinetics of the pore-filling process so that they can be accessed at high charging rates," lead study author Shinichi Komaba, a professor in the Department of Applied Chemistry at the Tokyo University of Science, explained in a statement. "Also, our results suggest that sodium insertion is less sensitive to temperature, based on the consideration of smaller activation energy than lithiation."&lt;/p&gt;
    &lt;p&gt;In the real world, the results could help Na-ion batteries become more widely adopted for uses that require incredibly fast charging or discharging rates. For example, grid-scale battery energy storage systems would benefit from the capability to rapidly discharge energy on demand. It's also of paramount importance for batteries to remain stable when they're used at scale for storing energy produced by renewable sources.&lt;/p&gt;
    &lt;p&gt;Na-ion batteries are safer than Li-ion batteries, as noted in a 2025 study by researchers at the Islamic University of Technology, Idaho State University, and University of Waterloo. This is because the stable sodium ions they contain are less prone to the chain reaction that causes Li-ion batteries to burn, or even explode, when damaged.&lt;/p&gt;
    &lt;p&gt;The U.K. National Fire Chiefs Council has stated that battery energy storage systems that use Li-ion batteries pose a "significant fire risk," particularly because once they're on fire, these batteries cannot be easily extinguished.&lt;/p&gt;
    &lt;p&gt;Thermal runaway, the self-sustaining process that causes Li-ion batteries to ignite, can even sustain itself without oxygen. The British Safety Council has noted that after they ignite, Li-ion batteries in some electric vehicles may burn for hours or even days.&lt;/p&gt;
    &lt;p&gt;If produced at scale, Na-ion batteries like those tested in the study could avoid these risks altogether.&lt;/p&gt;
    &lt;p&gt;"Our results quantitatively demonstrate that the charging speed of an SIB using an HC anode can attain faster rates than that of an LIB [lithium-ion battery]," Komaba said in the statement.&lt;/p&gt;
    &lt;p&gt;Y. Fujii, Z. T. Gossage, R. Tatara and S. Komaba, Chem. Sci., 2026, Advance Article, DOI: 10.1039/D5SC07762A&lt;/p&gt;
    &lt;p&gt;Rory Bathgate is a freelance writer for Live Science and Features and Multimedia Editor at ITPro, overseeing all in-depth content and case studies. Outside of his work for ITPro, Rory is keenly interested in how the tech world intersects with our fight against climate change. This encompasses a focus on the energy transition, particularly renewable energy generation and grid storage as well as advances in electric vehicles and the rapid growth of the electrification market. In his free time, Rory enjoys photography, video editing and science fiction. He joined ITPro in 2022 as a graduate, after completing an MA (Hons) in Eighteenth-Century Studies at King’s College London. You can contact Rory at rory.bathgate@futurenet.com.&lt;/p&gt;
    &lt;p&gt;You must confirm your public display name before commenting&lt;/p&gt;
    &lt;p&gt;Please logout and then login again, you will then be prompted to enter your display name.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46812052</guid><pubDate>Thu, 29 Jan 2026 16:04:45 +0000</pubDate></item><item><title>US cybersecurity chief leaked sensitive government files to ChatGPT: Report</title><link>https://www.dexerto.com/entertainment/us-cybersecurity-chief-leaked-sensitive-government-files-to-chatgpt-report-3311462/</link><description>&lt;doc fingerprint="2937ce14048341f7"&gt;
  &lt;main&gt;
    &lt;p&gt;The acting head of the US government’s top cybersecurity agency reportedly uploaded sensitive government files into a public version of ChatGPT, triggering internal security alerts and a federal review.&lt;/p&gt;
    &lt;p&gt;A Politico investigation claims Madhu Gottumukkala, the interim director of the Cybersecurity and Infrastructure Security Agency, uploaded contracting documents marked “For Official Use Only” into ChatGPT last summer.&lt;/p&gt;
    &lt;p&gt;The report says Gottumukkala requested a special exemption to access ChatGPT, which is blocked for other Department of Homeland Security staff.&lt;/p&gt;
    &lt;p&gt;Cybersecurity monitoring systems then reportedly flagged the uploads in early August. That triggered a DHS-led damage assessment to determine whether the information had been exposed.&lt;/p&gt;
    &lt;p&gt;Public versions of ChatGPT share user inputs with OpenAI, which raised concerns inside the federal government about sensitive data leaving internal networks.&lt;/p&gt;
    &lt;head rend="h2"&gt;CISA responds to ChatGPT investigation&lt;/head&gt;
    &lt;p&gt;CISA spokesperson Marci McCarthy told Politico that Gottumukkala “was granted permission to use ChatGPT with DHS controls in place,” adding that the use was “short-term and limited.”&lt;/p&gt;
    &lt;p&gt;Gottumukkala has served as acting director since May, while the Senate has yet to confirm Sean Plankey as permanent head of the agency.&lt;/p&gt;
    &lt;p&gt;The ChatGPT incident follows other reported issues during Gottumukkala’s tenure. Politico said he previously failed a counterintelligence polygraph required for access to highly sensitive intelligence. During congressional testimony last week, he rejected that characterization when questioned.&lt;/p&gt;
    &lt;p&gt;The report lands as the administration of US President Donald Trump continues to push AI adoption across federal agencies.&lt;/p&gt;
    &lt;p&gt;Trump signed an executive order in December aimed at limiting state-level AI regulation, while the Pentagon has announced an “AI-first” strategy to expand the military’s use of artificial intelligence.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46812173</guid><pubDate>Thu, 29 Jan 2026 16:12:19 +0000</pubDate></item></channel></rss>