<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 08 Jan 2026 15:46:12 +0000</lastBuildDate><item><title>US will ban Wall Street investors from buying single-family homes</title><link>https://www.reuters.com/world/us/us-will-ban-large-institutional-investors-buying-single-family-homes-trump-says-2026-01-07/</link><description>&lt;doc fingerprint="fe4140d71fb286a6"&gt;
  &lt;main&gt;
    &lt;p&gt;WASHINGTON, Jan 7 (Reuters) - U.S. President Donald Trump on Wednesday said his administration is moving to ban Wall Street firms from buying up single-family homes in a bid to reduce home prices, a potential blow for private-equity landlords that also pressured homebuilder stocks.&lt;/p&gt;
    &lt;p&gt;In a post on Truth Social, Trump said he was immediately taking steps to implement the ban, which he would also call on Congress to codify in law. It was not clear what steps he would take.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;"For a very long time, buying and owning a home was considered the pinnacle of the American Dream," Trump wrote, adding that inflation had put that dream out of reach for many Americans.&lt;/p&gt;
    &lt;p&gt;"People live in homes, not corporations," said Trump, who is under growing pressure to address voter anxiety over the cost of living ahead of this year's congressional midterm elections.&lt;/p&gt;
    &lt;p&gt;A Republican move to target Wall Street landlords would, perversely, align the party with Democrats, who for years have criticized corporate homebuying, claiming it has helped stoke housing costs, and have unsuccessfully pushed bills to crack down on the trend.&lt;/p&gt;
    &lt;head rend="h2"&gt;WALL STREET BLAMED FOR REDUCED HOUSING SUPPLY&lt;/head&gt;
    &lt;p&gt;Wall Street institutions such as Blackstone (BX.N), American Homes 4 Rent (AMH.N) and Progress Residential have bought thousands of single-family homes since the financial crisis of 2008 led to a wave of home foreclosures.&lt;/p&gt;
    &lt;p&gt;By June 2022, institutional investors owned around 450,000 homes, or about 3%, of all single-family rental homes nationally, according to a 2024 study by the Government Accountability Office.&lt;/p&gt;
    &lt;p&gt;American Homes 4 Rent (AMH.N) dropped to a near three-year low of $28.84 and was halted for volatility before trading resumed. Its shares closed down 4% at $31.01.&lt;/p&gt;
    &lt;p&gt;Blackstone shares hit a one-month low of $147.52 and closed down about 5.6% at $153.59. The PHLX housing index (.HGX) fell 2.6%.&lt;/p&gt;
    &lt;p&gt;A spokesperson for Blackstone said their ownership of such homes represented a small portion of their overall business, and that they had been a net seller of homes for the prior decade.&lt;/p&gt;
    &lt;p&gt;"That said, we believe our current portfolio is poised to continue to perform quite well and operate at the highest standards for residents," the spokesperson said.&lt;/p&gt;
    &lt;p&gt;American Homes 4 Rent and Progress Residential did not immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Wall Street landlords dispute that their investments have stoked inflation. In a January 2025 research note, Blackstone said institutional home purchases have declined 90% since 2022 and that supply shortage is the reason for house price increases.&lt;/p&gt;
    &lt;p&gt;The GAO study found that the effect of institutional homebuying on homeownership opportunities was unclear in part due to limited data.&lt;/p&gt;
    &lt;p&gt;Critics say Wall Street firms are also bad landlords, skimping on upkeepto keep investors happy, and wrongly evicted tenants during the COVID-19 pandemic.&lt;/p&gt;
    &lt;p&gt;"Resident experience is hurting as a result," said Jeff Holzmann, COO of RREAF Holdings, a Dallas-based real estate investment firm with over $5 billion in assets.&lt;/p&gt;
    &lt;p&gt;"Instead of you calling your landlord to discuss a problem, you're calling a call center that gives you the runaround."&lt;/p&gt;
    &lt;head rend="h2"&gt;AFFORDABILITY PRESSURE&lt;/head&gt;
    &lt;p&gt;Trump, who has occasionally dismissed affordability concerns and blamed inflation on his Democratic predecessor, has seen his own public approval mostly sag since his inauguration as Americans worry about the economy.&lt;/p&gt;
    &lt;p&gt;It was not immediately clear what authority Trump would draw upon to impose a ban, and he did not outline the changes he was seeking from Congress.&lt;/p&gt;
    &lt;p&gt;The White House did not respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Since Trump's first electoral victory, U.S. home prices have risen 75%, more than double the increase in overall consumer prices tracked by CPI. But home sales price increases have eased substantially over the past year.&lt;/p&gt;
    &lt;p&gt;The Federal Housing Finance Agency last week reported that national home sales prices had risen just 1.7% in October, from a year earlier, the lowest in more than 13 years. That's less than half the rate by which they were climbing when Trump came back into office last January and a fraction of their peak gains of nearly 20% in 2021 and 2022.&lt;/p&gt;
    &lt;p&gt;A big factor in home price inflation has been a lack of properties for sale, although that has also been slowly improving over the last year or so, according to National Association of Realtors data.&lt;/p&gt;
    &lt;p&gt;As of November, annual shelter-cost inflation, which had shot to as high as 8.2% in the COVID-19 pandemic aftermath, had also eased to 3.0%, the lowest in more than four years, according to the Labor Department's Consumer Price Index.&lt;/p&gt;
    &lt;p&gt;Reporting by Trevor Hunnicutt; additional reporting by Ryan Patrick Jones, Ankur Banerjee, Saeed Azhar, Chuck Mikolajczak, Andrea Shalal, Matt Tracy and Dan Burns; Writing by Michelle Price; Editing by Caitlin Webber, David Ljunggren, Cynthia Osterman, Rod Nickel and Nick Zieminski&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46531068</guid><pubDate>Wed, 07 Jan 2026 19:13:19 +0000</pubDate></item><item><title>ChatGPT Health</title><link>https://openai.com/index/introducing-chatgpt-health/</link><description>&lt;doc fingerprint="2c12c8739eff67b7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing ChatGPT Health&lt;/head&gt;
    &lt;p&gt;A dedicated experience in ChatGPT designed for health and wellness.&lt;/p&gt;
    &lt;p&gt;We’re introducing ChatGPT Health, a dedicated experience that securely brings your health information and ChatGPT’s intelligence together, to help you feel more informed, prepared, and confident navigating your health.&lt;/p&gt;
    &lt;p&gt;Health is already one of the most common ways people use ChatGPT, with hundreds of millions of people asking health and wellness questions each week. ChatGPT Health builds on the strong privacy, security, and data controls across ChatGPT with additional, layered protections designed specifically for health— including purpose-built encryption and isolation to keep health conversations protected and compartmentalized. You can securely connect medical records and wellness apps to ground conversations in your own health information, so responses are more relevant and useful to you. Designed in close collaboration with physicians, ChatGPT Health helps people take a more active role in understanding and managing their health and wellness—while supporting, not replacing, care from clinicians.&lt;/p&gt;
    &lt;p&gt;Today, health information is often scattered across portals, apps, wearables, PDFs, and medical notes—so it's hard to see the full picture, and people are left to navigate a complex healthcare system on their own. People have shared countless stories of turning to ChatGPT to help make sense of it all. In fact, health is one of the most common ways people use ChatGPT today: based on our de-identified analysis of conversations, over 230 million people globally ask health and wellness related questions on ChatGPT every week.&lt;/p&gt;
    &lt;p&gt;ChatGPT Health builds on this so responses are informed by your health information and context. You can now securely connect medical records and wellness apps—like Apple Health, Function, and MyFitnessPal—so ChatGPT can help you understand recent test results, prepare for appointments with your doctor, get advice on how to approach your diet and workout routine, or understand the tradeoffs of different insurance options based on your healthcare patterns.&lt;/p&gt;
    &lt;p&gt;Health is designed to support, not replace, medical care. It is not intended for diagnosis or treatment. Instead, it helps you navigate everyday questions and understand patterns over time—not just moments of illness—so you can feel more informed and prepared for important medical conversations. To keep your health information protected and secure, Health operates as a separate space with enhanced privacy to protect sensitive data. Conversations in Health are not used to train our foundation models. If you start a health-related conversation in ChatGPT, we’ll suggest moving into Health for these additional protections.&lt;/p&gt;
    &lt;p&gt;If you’re interested in getting access as it becomes available, you can sign up for the waitlist(opens in a new window). We’re starting by providing access to a small group of early users to learn and continue refining the experience—users with ChatGPT Free, Go, Plus, and Pro plans outside of the European Economic Area, Switzerland, and the United Kingdom are eligible. As we make improvements, we plan to expand access and make Health available to all users on web and iOS in the coming weeks.&lt;/p&gt;
    &lt;p&gt;Medical record integrations and some apps are available in the U.S. only, and connecting Apple Health requires iOS.&lt;/p&gt;
    &lt;p&gt;Your health information is deeply personal. That’s why Health is built as a dedicated space with added protections for sensitive health information and easy-to-use controls.&lt;/p&gt;
    &lt;p&gt;Health lives in its own space within ChatGPT, where your conversations, connected apps, and files are stored separately from your other chats. Health has separate memories, ensuring that your health context stays contained within the space. You’ll still see health chats in your chat history so you can easily return to them, but the information itself stays within Health.&lt;/p&gt;
    &lt;p&gt;When helpful, ChatGPT may use context from your non-Health chats—like a recent move or lifestyle change—to make a health conversation more relevant. However, Health information and memories never flow back into your non-Health chats, and conversations outside of Health can’t access files, conversations, or memories created within Health. You can view or delete Health memories at any time within Health or the “Personalization” section of Settings.&lt;/p&gt;
    &lt;p&gt;We recognize that people share personal and sensitive information with ChatGPT. That understanding shapes how we design the security, privacy, and data controls for all of our products—from the start. Even before introducing ChatGPT Health, we built foundational protections across ChatGPT to give you meaningful control over your data, including temporary chats, the ability to delete chats from OpenAI’s systems within 30 days, and training our models not to retain personal information from user chats.&lt;/p&gt;
    &lt;p&gt;Conversations and files across ChatGPT are encrypted by default at rest and in transit as part of our core security architecture. Due to the sensitive nature of health data, Health builds on this foundation with additional, layered protections—including purpose-built encryption and isolation—to keep health conversations protected and compartmentalized. Conversations in Health are not used to train our foundation models.&lt;/p&gt;
    &lt;p&gt;You can further strengthen access controls by enabling multi-factor authentication (MFA)(opens in a new window), which adds an extra layer of protection to help prevent unauthorized access.&lt;/p&gt;
    &lt;p&gt;When you choose to connect your health data, such as medical records or wellness apps, your responses are grounded in your own health information. To enable access to trusted U.S. healthcare providers, we partner with b.well, the largest and most secure network of live, connected health data for U.S. consumers. b.well adheres to the highest industry standards in data security and privacy. You can remove access to medical records at any time in the "Apps" section of Settings.&lt;/p&gt;
    &lt;p&gt;You can also connect your Apple Health information and other wellness apps, such as Function and MyFitnessPal. Apps may only be connected to your health data with your explicit permission, even if they’re already connected to ChatGPT for conversations outside of Health. All apps available in Health must meet OpenAI’s privacy and security requirements, including collecting only the minimum data needed, and undergo additional security review specific to inclusion in Health. The first time you connect an app, we’ll help you understand what types of data may be collected by the third party. And you’re always in control: disconnect an app at any time and it immediately loses access.&lt;/p&gt;
    &lt;p&gt;ChatGPT Health was developed in close collaboration with physicians around the world to provide clear and useful health information.&lt;/p&gt;
    &lt;p&gt;Over two years, we’ve worked with more than 260 physicians who have practiced in 60 countries and dozens of specialties to understand what makes an answer to a health question helpful or potentially harmful—this group has now provided feedback on model outputs over 600,000 times across 30 areas of focus. This collaboration has shaped not just what Health can do, but how it responds: how urgently to encourage follow-ups with a clinician, how to communicate clearly without oversimplifying, and how to prioritize safety in moments that matter.&lt;/p&gt;
    &lt;p&gt;This physician-led approach is built directly into the model that powers Health, which is evaluated against clinical standards using HealthBench, an assessment framework we created with input from our network of practicing physicians. Rather than relying on exam-style questions or generic accuracy checks, HealthBench evaluates responses using physician-written rubrics that reflect how clinicians judge quality in practice—prioritizing safety, clarity, appropriate escalation of care, and respect for individual context.&lt;/p&gt;
    &lt;p&gt;This evaluation-driven approach helps ensure the model performs well on the tasks people actually need help with, including explaining lab results in accessible language, preparing questions for an appointment, interpreting data from wearables and wellness apps, and summarizing care instructions. The result is support that people can trust—always designed to support, not replace, your healthcare providers.&lt;/p&gt;
    &lt;p&gt;You can sign up for the waitlist(opens in a new window) to request access.&lt;/p&gt;
    &lt;p&gt;Select ‘Health’ from the sidebar menu in ChatGPT.&lt;/p&gt;
    &lt;p&gt;Bring your medical records and the apps you use to track your health and wellness into Health. You can upload files directly, connect from tools (+) or “Apps” in Settings.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New: Medical Records for lab results, visit summaries, and clinical history&lt;/item&gt;
      &lt;item&gt;New: Apple Health for health and fitness data, including movement, sleep, and activity patterns (must be on iOS to sync)&lt;/item&gt;
      &lt;item&gt;New: Function for lab test insights, nutrition ideas, and taking action on your health&lt;/item&gt;
      &lt;item&gt;New: MyFitnessPal for nutrition advice, macros, and recipes&lt;/item&gt;
      &lt;item&gt;New: Weight Watchers for GLP-1 personalized meal ideas, recipes, and food guidance&lt;/item&gt;
      &lt;item&gt;AllTrails to help you find your next hike&lt;/item&gt;
      &lt;item&gt;Instacart to turn meal plans into shoppable lists&lt;/item&gt;
      &lt;item&gt;Peloton for suggested workout classes or guided meditations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Health conversations feel just like chatting with ChatGPT—but grounded in the information you’ve connected. You can upload photos and files and use search, deep research, voice mode and dictation. When relevant, ChatGPT can automatically reference your connected information to provide more relevant and personalized responses. For example, you might ask: “How’s my cholesterol trending?” or “Can you summarize my latest bloodwork before my appointment?” To use a connected app you can start your question with it, select it from tools (+) or ChatGPT may suggest one when helpful.&lt;/p&gt;
    &lt;p&gt;You can add custom instructions in Health to help ChatGPT know what to focus on, to avoid mentioning sensitive topics, or change how responses are framed. These instructions only apply to Health chats, and you can update or remove any time in Health or Settings.&lt;/p&gt;
    &lt;p&gt;We’ll continue to expand what you can connect and the insights Health can support—so ChatGPT can help you feel more informed, prepared, and confident as you navigate your health.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46531280</guid><pubDate>Wed, 07 Jan 2026 19:29:39 +0000</pubDate></item><item><title>Tailscale state file encryption no longer enabled by default</title><link>https://tailscale.com/changelog</link><description>&lt;doc fingerprint="868f307d7f22bbd0"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Tailscale v1.92.5&lt;/head&gt;Update instructions&lt;head rend="h5"&gt;Linux&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;State file encryption and hardware attestation keys are no longer enabled by default.&lt;/item&gt;&lt;item&gt;Failure to load hardware attestation keys no longer prevents the client from starting. This could happen when the TPM device is reset or replaced.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h5"&gt;Windows&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;State file encryption and hardware attestation keys are no longer enabled by default.&lt;/item&gt;&lt;item&gt;Failure to load hardware attestation keys no longer prevents the client from starting. This could happen when the TPM device is reset or replaced.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Tailscale container image v1.92.5&lt;/head&gt;&lt;p&gt;A new release of the Tailscale container image is available. You can download it from Docker Hub or from our GitHub packages repository.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Hardware attestation keys are no longer added to Kubernetes state &lt;code&gt;Secrets&lt;/code&gt;, making it possible to change the Kubernetes node the Tailscale containers are deployed on.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Tailscale Kubernetes Operator v1.92.5&lt;/head&gt;&lt;p&gt;A new release of the Tailscale Kubernetes Operator is available. For guidance on installing and updating, refer to our installation instructions.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Certificate renewal is no longer done as an ARI order by default to avoid renewal failure if ACME account keys are recreated.&lt;/item&gt;&lt;item&gt;Hardware attestation keys are no longer added to Kubernetes state &lt;code&gt;Secrets&lt;/code&gt;, making it possible to change the Kubernetes node the Tailscale Kubernetes Operator is deployed on.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Tailscale tsrecorder v1.92.5&lt;/head&gt;&lt;p&gt;A new release of the Tailscale &lt;code&gt;tsrecorder&lt;/code&gt; is available. You can download it from Docker Hub.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Note: This version contains no changes except for library updates.&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46531925</guid><pubDate>Wed, 07 Jan 2026 20:16:50 +0000</pubDate></item><item><title>Play Aardwolf MUD</title><link>https://www.aardwolf.com/</link><description>&lt;doc fingerprint="7a5b424b2b380a80"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="27"&gt;
        &lt;cell&gt;
          &lt;p&gt;Location: Home&lt;/p&gt;
          &lt;p&gt;Aardwolf RPG is a unique and free text based roleplaying game. Aardwolf is based in the fantasy world of Andolor where magic is common and there are hundreds of exotic realms to explore, puzzles to solve and quests to complete. Aardwolf features a realistic game world with multiple continents and real geography. Each area includes a real time line-of-sight overhead map to see other characters and points of interest around you.&lt;/p&gt;
          &lt;p&gt;Create your character from any one of 28 classes including fighter classes such as Soldiers, Knights, Hunters, Barbarians, Rangers, Archers, Assassins and Paladins or select a magic based class including Elementalists, Necromancers, Healers, Priests, Witches and Enchanters. Once you have choosen your race, your guild and your profession then the rest is up to you. You have absolute control over your character's actions and there are many ways to play Aardwolf.&lt;/p&gt;
          &lt;p&gt;Sample screenshot of the Aardwolf Client&lt;/p&gt;
          &lt;p&gt;You can play the game solo or group with other players, focus on gaining experience and levels, take part in hundreds of quests, solve puzzles, explore, map, play casino games for in-game currency, join a clan, take part in our forums, enchant and craft equipment, compete with other players in player-vs-player combat and global quests, answer trivia, create your own private manor, experiment with hundreds of spells and skills and even, eventually, build your own additions to the world.&lt;/p&gt;
          &lt;p&gt;If you have never played a text based RPG before, we offer an extensive in-game help system to help you get started and a team of volunteer "helpers" who answer questions in real time. We also have a very detailed starting area called "The Aylorian Academy" - your first major quest in the game where you are guided through playing Aardwolf in an interactive format.&lt;/p&gt;
          &lt;p&gt;To learn more about MUDs in general, see the introduction to MUDs article. To jump in and get started, visit the "Play now" page to choose from a selection of online and downloadable clients.&lt;/p&gt;
          &lt;p&gt;For builders, Aardwolf features an embedded LUA interpreter allowing area developers to add atmosphere to their areas and create area puzzles and quests. See our building section for more information on the LUA integration.&lt;/p&gt;
          &lt;p&gt;If you already have a MUD client, you can connect to Aardwolf using aardwolf.org (23.111.142.226) port 4000. You can also use port 23 if you have a firewall blocking port 4000. To reach our Java client, click 'Play Aardwolf' in the link above. If you have problems connecting, feel free to mail webmaster@aardmud.org for help.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row/&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46534777</guid><pubDate>Wed, 07 Jan 2026 23:31:05 +0000</pubDate></item><item><title>The virtual AmigaOS runtime (a.k.a. Wine for Amiga:)</title><link>https://github.com/cnvogelg/amitools/blob/main/docs/vamos.md</link><description>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46535515</guid><pubDate>Thu, 08 Jan 2026 00:48:17 +0000</pubDate></item><item><title>Musashi: Motorola 680x0 emulator written in C</title><link>https://github.com/kstenerud/Musashi</link><description>&lt;doc fingerprint="b2a7b319e44fbb41"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 116&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;kstenerud/Musashi&lt;/head&gt;
    &lt;head rend="h2"&gt;Folders and files&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Last commit message&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Last commit date&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Repository files navigation&lt;/head&gt;
    &lt;quote&gt;MUSASHI ======= Version 4.10 A portable Motorola M680x0 processor emulation engine. Copyright 1998-2002 Karl Stenerud. All rights reserved. INTRODUCTION: ------------ Musashi is a Motorola 68000, 68010, 68EC020, 68020, 68EC030, 68030, 68EC040 and 68040 emulator written in C. This emulator was written with two goals in mind: portability and speed. The emulator is written to ANSI C89 specifications. It also uses inline functions, which are C9X compliant. It has been successfully running in the MAME project (www.mame.net) for years and so has had time to mature. LICENSE AND COPYRIGHT: --------------------- Copyright © 1998-2001 Karl Stenerud Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. AVAILABILITY: ------------ The latest version of this code can be obtained at: https://github.com/kstenerud/Musashi CONTACTING THE AUTHOR: --------------------- I can be reached at kstenerud@gmail.com BASIC CONFIGURATION: ------------------- The basic configuration will give you a standard 68000 that has sufficient functionality to work in a primitive environment. This setup assumes that you only have 1 device interrupting it, that the device will always request an autovectored interrupt, and it will always clear the interrupt before the interrupt service routine finishes (but could possibly re-assert the interrupt). You will have only one address space, no tracing, and no instruction prefetch. To implement the basic configuration: - Open m68kconf.h and verify that the settings for INLINE will work with your compiler. (Currently set to "static __inline__", which works in gcc 2.9. For C9X compliance, it should be "inline") - In your host program, implement the following functions: unsigned int m68k_read_memory_8(unsigned int address); unsigned int m68k_read_memory_16(unsigned int address); unsigned int m68k_read_memory_32(unsigned int address); void m68k_write_memory_8(unsigned int address, unsigned int value); void m68k_write_memory_16(unsigned int address, unsigned int value); void m68k_write_memory_32(unsigned int address, unsigned int value); - In your host program, be sure to call m68k_pulse_reset() once before calling any of the other functions as this initializes the core. - Use m68k_execute() to execute instructions and m68k_set_irq() to cause an interrupt. ADDING PROPER INTERRUPT HANDLING: -------------------------------- The interrupt handling in the basic configuration doesn't emulate the interrupt acknowledge phase of the CPU and automatically clears an interrupt request during interrupt processing. While this works for most systems, you may need more accurate interrupt handling. To add proper interrupt handling: - In m68kconf.h, set M68K_EMULATE_INT_ACK to OPT_SPECIFY_HANDLER - In m68kconf.h, set M68K_INT_ACK_CALLBACK(A) to your interrupt acknowledge routine - Your interrupt acknowledge routine must return an interrupt vector, M68K_INT_ACK_AUTOVECTOR, or M68K_INT_ACK_SPURIOUS. most m68k implementations just use autovectored interrupts. - When the interrupting device is satisfied, you must call m68k_set_irq(0) to remove the interrupt request. MULTIPLE INTERRUPTS: ------------------- The above system will work if you have only one device interrupting the CPU, but if you have more than one device, you must do a bit more. To add multiple interrupts: - You must make an interrupt arbitration device that will take the highest priority interrupt and encode it onto the IRQ pins on the CPU. - The interrupt arbitration device should use m68k_set_irq() to set the highest pending interrupt, or 0 for no interrupts pending. SEPARATE IMMEDIATE READS: ------------------------ You can write faster memory access functions if you know whether you are fetching from ROM or RAM. Immediate reads are always from the program space (Always in ROM unless it is running self-modifying code). To enable separate immediate reads: - In m68kconf.h, turn on M68K_SEPARATE_READ_IMM. - In your host program, implement the following functions: unsigned int m68k_read_immediate_16(unsigned int address); unsigned int m68k_read_immediate_32(unsigned int address); Now you also have the pcrelative stuff: unsigned int m68k_read_pcrelative_8(unsigned int address); unsigned int m68k_read_pcrelative_16(unsigned int address); unsigned int m68k_read_pcrelative_32(unsigned int address); - If you need to know the current PC (for banking and such), set M68K_MONITOR_PC to OPT_SPECIFY_HANDLER, and set M68K_SET_PC_CALLBACK(A) to your routine. - In the unlikely case where you need to emulate some PMMU in the immediate reads and/or pcrealtive stuff, you'll need to explicitely call the translation address mechanism from your user functions this way : if (PMMU_ENABLED) address = pmmu_translate_addr(address); (this is handled automatically by normal memory accesses). ADDRESS SPACES: -------------- Most systems will only implement one address space, placing ROM at the lower addresses and RAM at the higher. However, there is the possibility that a system will implement ROM and RAM in the same address range, but in different address spaces. In this case, you might get away with assuming that immediate reads are in the program space and all other reads are in the data space, if it weren't for the fact that the exception vectors are fetched from the data space. As a result, anyone implementing this kind of system will have to copy the vector table from ROM to RAM using pc-relative instructions. This makes things bad for emulation, because this means that a non-immediate read is not necessarily in the data space. The m68k deals with this by encoding the requested address space on the function code pins: FC Address Space 210 ------------------ --- USER DATA 001 USER PROGRAM 010 SUPERVISOR DATA 101 SUPERVISOR PROGRAM 110 CPU SPACE 111 &amp;lt;-- not emulated in this core since we emulate interrupt acknowledge in another way. To emulate the function code pins: - In m68kconf.h, set M68K_EMULATE_FC to OPT_SPECIFY_HANDLER and set M68K_SET_FC_CALLBACK(A) to your function code handler function. - Your function code handler should select the proper address space for subsequent calls to m68k_read_xx (and m68k_write_xx for 68010+). Note: immediate reads are always done from program space, so technically you don't need to implement the separate immediate reads, although you could gain more speed improvements leaving them in and doing some clever programming. USING DIFFERENT CPU TYPES: ------------------------- The default is to enable only the 68000 cpu type. To change this, change the settings for M68K_EMULATE_010 etc in m68kconf.h. To set the CPU type you want to use: - Make sure it is enabled in m68kconf.h. Current switches are: M68K_EMULATE_010 M68K_EMULATE_EC020 M68K_EMULATE_020 - In your host program, call m68k_set_cpu_type() and then call m68k_pulse_reset(). Valid CPU types are: M68K_CPU_TYPE_68000, M68K_CPU_TYPE_68010, M68K_CPU_TYPE_68EC020, M68K_CPU_TYPE_68020, M68K_CPU_TYPE_68EC030, M68K_CPU_TYPE_68030, M68K_CPU_TYPE_68EC040, M68K_CPU_TYPE_68040, M68K_CPU_TYPE_SCC68070 (which is a 68010 with a 32 bit data bus). CLOCK FREQUENCY: --------------- In order to emulate the correct clock frequency, you will have to calculate how long it takes the emulation to execute a certain number of "cycles" and vary your calls to m68k_execute() accordingly. As well, it is a good idea to take away the CPU's timeslice when it writes to a memory-mapped port in order to give the device it wrote to a chance to react. You can use the functions m68k_cycles_run(), m68k_cycles_remaining(), m68k_modify_timeslice(), and m68k_end_timeslice() to do this. Try to use large cycle values in your calls to m68k_execute() since it will increase throughput. You can always take away the timeslice later. MORE CORRECT EMULATION: ---------------------- You may need to enable these in order to properly emulate some of the more obscure functions of the m68k: - M68K_EMULATE_BKPT_ACK causes the CPU to call a breakpoint handler on a BKPT instruction - M68K_EMULATE_TRACE causes the CPU to generate trace exceptions when the trace bits are set - M68K_EMULATE_RESET causes the CPU to call a reset handler on a RESET instruction. - M68K_EMULATE_PREFETCH emulates the 4-word instruction prefetch that is part of the 68000/68010 (needed for Amiga emulation). NOTE: if the CPU fetches a word or longword at an odd address when this option is on, it will yield unpredictable results, which is why a real 68000 will generate an address error exception. - M68K_EMULATE_ADDRESS_ERROR will cause the CPU to generate address error exceptions if it attempts to read a word or longword at an odd address. - call m68k_pulse_halt() to emulate the HALT pin. CONVENIENCE FUNCTIONS: --------------------- These are in here for programmer convenience: - M68K_INSTRUCTION_HOOK lets you call a handler before each instruction. - M68K_LOG_ENABLE and M68K_LOG_1010_1111 lets you log illegal and A/F-line instructions. MULTIPLE CPU EMULATION: ---------------------- The default is to use only one CPU. To use more than one CPU in this core, there are some things to keep in mind: - To have different cpus call different functions, use OPT_ON instead of OPT_SPECIFY_HANDLER, and use the m68k_set_xxx_callback() functions to set your callback handlers on a per-cpu basis. - Be sure to call set_cpu_type() for each CPU you use. - Use m68k_set_context() and m68k_get_context() to switch to another CPU. LOAD AND SAVE CPU CONTEXTS FROM DISK: ------------------------------------ You can use them68k_load_context() and m68k_save_context() functions to load and save the CPU state to disk. GET/SET INFORMATION FROM THE CPU: -------------------------------- You can use m68k_get_reg() and m68k_set_reg() to gain access to the internals of the CPU. EXAMPLE: ------- The subdir example contains a full example (currently linux &amp;amp; Dos only). Compilation ----------- You can use the default Makefile in Musashi's directory, it works like this : 1st build m68kmake, which will build m68kops.c and m68kops.h based on the contents of m68k_in.c. Then compile m68kcpu.o and m68kops.o. Add m68kdasm.o if you want the disassemble functions. When linking this to your project you will need libm for the fpu emulation of the 68040. Using some custom m68kconf.h outside Musashi's directory -------------------------------------------------------- It can be useful to keep an untouched musashi directory in a project (from git for example) and maintain a separate m68kconf.h specific to the project. For this, pass -DMUSASHI_CNF="mycustomconfig.h" to gcc (or whatever compiler you use). Notice that if you use an unix shell (or make which uses the shell to launch its commands), then you need to escape the quotes like this : -DMUSASHI_CNF=\"mycustomconfig.h\"&lt;/quote&gt;
    &lt;head rend="h2"&gt;About&lt;/head&gt;
    &lt;p&gt;Motorola 680x0 emulator written in C&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources&lt;/head&gt;
    &lt;head rend="h3"&gt;Stars&lt;/head&gt;
    &lt;head rend="h3"&gt;Watchers&lt;/head&gt;
    &lt;head rend="h3"&gt;Forks&lt;/head&gt;
    &lt;head rend="h2"&gt;Releases&lt;/head&gt;
    &lt;p&gt;No releases published&lt;/p&gt;
    &lt;head rend="h2"&gt;Packages 0&lt;/head&gt;
    &lt;p&gt; No packages published &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46535540</guid><pubDate>Thu, 08 Jan 2026 00:51:20 +0000</pubDate></item><item><title>Kernel bugs hide for 2 years on average. Some hide for 20</title><link>https://pebblebed.com/blog/kernel-bugs</link><description>&lt;doc fingerprint="52dac1dfd8b24a36"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Kernel bugs hide for 2 years on average. Some hide for 20.&lt;/head&gt;
    &lt;p&gt;There are bugs in your kernel right now that won't be found for years. I know because I analyzed 125,183 of them, every bug with a traceable &lt;code&gt;Fixes:&lt;/code&gt; tag in the Linux kernel's 20-year git history.&lt;/p&gt;
    &lt;p&gt;The average kernel bug lives 2.1 years before discovery. But some subsystems are far worse: CAN bus drivers average 4.2 years, SCTP networking 4.0 years. The longest-lived bug in my dataset, a buffer overflow in ethtool, sat in the kernel for 20.7 years. The one which I'll dissect in detail is refcount leak in netfilter, and it lasted 19 years.&lt;/p&gt;
    &lt;p&gt;I built a tool that catches 92% of historical bugs in a held-out test set at commit time. Here's what I learned.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key findings at a glance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;125,183&lt;/cell&gt;
        &lt;cell&gt;Bug-fix pairs with traceable &lt;code&gt;Fixes:&lt;/code&gt; tags&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;123,696&lt;/cell&gt;
        &lt;cell&gt;Valid records after filtering (0 &amp;lt; lifetime &amp;lt; 27 years)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2.1 years&lt;/cell&gt;
        &lt;cell&gt;Average time a bug hides before discovery&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;20.7 years&lt;/cell&gt;
        &lt;cell&gt;Longest-lived bug (ethtool buffer overflow)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;0% â 69%&lt;/cell&gt;
        &lt;cell&gt;Bugs found within 1 year (2010 vs 2022)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;92.2%&lt;/cell&gt;
        &lt;cell&gt;Recall of VulnBERT on held-out 2024 test set&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;1.2%&lt;/cell&gt;
        &lt;cell&gt;False positive rate (vs 48% for vanilla CodeBERT)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;The initial discovery&lt;/head&gt;
    &lt;p&gt;I started by mining the most recent 10,000 commits with &lt;code&gt;Fixes:&lt;/code&gt; tags from the Linux kernel. After filtering out invalid references (commits that pointed to hashes outside the repo, malformed tags, or merge commits), I had 9,876 valid vulnerability records. For the lifetime analysis, I excluded 27 same-day fixes (bugs introduced and fixed within hours), leaving 9,849 bugs with meaningful lifetimes.&lt;/p&gt;
    &lt;p&gt;The results were striking:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Bugs analyzed&lt;/cell&gt;
        &lt;cell&gt;9,876&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Average lifetime&lt;/cell&gt;
        &lt;cell&gt;2.8 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Median lifetime&lt;/cell&gt;
        &lt;cell&gt;1.0 year&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Maximum&lt;/cell&gt;
        &lt;cell&gt;20.7 years&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Almost 20% of bugs had been hiding for 5+ years. The networking subsystem looked particularly bad at 5.1 years average. I found a refcount leak in netfilter that had been in the kernel for 19 years.&lt;/p&gt;
    &lt;p&gt;Initial findings: Half of bugs found within a year, but 20% hide for 5+ years.&lt;/p&gt;
    &lt;p&gt;But something nagged at me: my dataset only contained fixes from 2025. Was I seeing the full picture, or just the tip of the iceberg?&lt;/p&gt;
    &lt;head rend="h2"&gt;Going deeper: Mining the full history&lt;/head&gt;
    &lt;p&gt;I rewrote my miner to capture every &lt;code&gt;Fixes:&lt;/code&gt; tag since Linux moved to git in 2005. Six hours later, I had 125,183 vulnerability records which was 12x larger than my initial dataset.&lt;/p&gt;
    &lt;p&gt;The numbers changed significantly:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;2025 Only&lt;/cell&gt;
        &lt;cell role="head"&gt;Full History (2005-2025)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Bugs analyzed&lt;/cell&gt;
        &lt;cell&gt;9,876&lt;/cell&gt;
        &lt;cell&gt;125,183&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Average lifetime&lt;/cell&gt;
        &lt;cell&gt;2.8 years&lt;/cell&gt;
        &lt;cell&gt;2.1 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Median lifetime&lt;/cell&gt;
        &lt;cell&gt;1.0 year&lt;/cell&gt;
        &lt;cell&gt;0.7 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;5+ year bugs&lt;/cell&gt;
        &lt;cell&gt;19.4%&lt;/cell&gt;
        &lt;cell&gt;13.5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;10+ year bugs&lt;/cell&gt;
        &lt;cell&gt;6.6%&lt;/cell&gt;
        &lt;cell&gt;4.2%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Full history: 57% of bugs found within a year. The long tail is smaller than it first appeared.&lt;/p&gt;
    &lt;p&gt;Why the difference? My initial 2025-only dataset was biased. Fixes in 2025 include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New bugs introduced recently and caught quickly&lt;/item&gt;
      &lt;item&gt;Ancient bugs that finally got discovered after years of hiding&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The ancient bugs skewed the average upward. When you include the full history with all the bugs that were introduced AND fixed within the same year, the average drops from 2.8 to 2.1 years.&lt;/p&gt;
    &lt;head rend="h2"&gt;The real story: We're getting faster (but it's complicated)&lt;/head&gt;
    &lt;p&gt;The most striking finding from the full dataset: bugs introduced in recent years appear to get fixed much faster.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Year Introduced&lt;/cell&gt;
        &lt;cell role="head"&gt;Bugs&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg Lifetime&lt;/cell&gt;
        &lt;cell role="head"&gt;% Found &amp;lt;1yr&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2010&lt;/cell&gt;
        &lt;cell&gt;1,033&lt;/cell&gt;
        &lt;cell&gt;9.9 years&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2014&lt;/cell&gt;
        &lt;cell&gt;3,991&lt;/cell&gt;
        &lt;cell&gt;3.9 years&lt;/cell&gt;
        &lt;cell&gt;31%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2018&lt;/cell&gt;
        &lt;cell&gt;11,334&lt;/cell&gt;
        &lt;cell&gt;1.7 years&lt;/cell&gt;
        &lt;cell&gt;54%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;2022&lt;/cell&gt;
        &lt;cell&gt;11,090&lt;/cell&gt;
        &lt;cell&gt;0.8 years&lt;/cell&gt;
        &lt;cell&gt;69%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Bugs introduced in 2010 took nearly 10 years to find and bugs introduced in 2024 are found in 5 months. At first glance it looks like a 20x improvement!&lt;/p&gt;
    &lt;p&gt;But here's the catch: this data is right-censored. Bugs introduced in 2022 can't have a 10-year lifetime yet since we're only in 2026. We might find more 2022 bugs in 2030 that bring the average up.&lt;/p&gt;
    &lt;p&gt;The fairer comparison is "% found within 1 year" and that IS improving: from 0% (2010) to 69% (2022). That's real progress, likely driven by:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syzkaller (released 2015)&lt;/item&gt;
      &lt;item&gt;KASAN, KMSAN, KCSAN sanitizers&lt;/item&gt;
      &lt;item&gt;Better static analysis&lt;/item&gt;
      &lt;item&gt;More contributors reviewing code&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But there's a backlog. When I look at just the bugs fixed in 2024-2025:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;60% were introduced in the last 2 years (new bugs, caught quickly)&lt;/item&gt;
      &lt;item&gt;18% were introduced 5-10 years ago&lt;/item&gt;
      &lt;item&gt;6.5% were introduced 10+ years ago&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We're simultaneously catching new bugs faster AND slowly working through ~5,400 ancient bugs that have been hiding for over 5 years.&lt;/p&gt;
    &lt;head rend="h2"&gt;The methodology&lt;/head&gt;
    &lt;p&gt;The kernel has a convention: when a commit fixes a bug, it includes a &lt;code&gt;Fixes:&lt;/code&gt; tag pointing to the commit that introduced the bug.&lt;/p&gt;
    &lt;code&gt;commit de788b2e6227
Author: Florian Westphal &amp;lt;fw@strlen.de&amp;gt;
Date:   Fri Aug 1 17:25:08 2025 +0200

    netfilter: ctnetlink: fix refcount leak on table dump

    Fixes: d205dc40798d ("netfilter: ctnetlink: ...")
&lt;/code&gt;
    &lt;p&gt;I wrote a miner that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Runs &lt;code&gt;git log --grep="Fixes:"&lt;/code&gt;to find all fixing commits&lt;/item&gt;
      &lt;item&gt;Extracts the referenced commit hash from the &lt;code&gt;Fixes:&lt;/code&gt;tag&lt;/item&gt;
      &lt;item&gt;Pulls dates from both commits&lt;/item&gt;
      &lt;item&gt;Classifies subsystem from file paths (70+ patterns)&lt;/item&gt;
      &lt;item&gt;Detects bug type from commit message keywords&lt;/item&gt;
      &lt;item&gt;Calculates the lifetime&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;fixes_pattern = r'Fixes:\s*([0-9a-f]{12,40})'
match = re.search(fixes_pattern, commit_message)
if match:
    introducing_hash = match.group(1)
    lifetime_days = (fixing_date - introducing_date).days
&lt;/code&gt;
    &lt;p&gt;Dataset details:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Parameter&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel version&lt;/cell&gt;
        &lt;cell&gt;v6.19-rc3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Mining date&lt;/cell&gt;
        &lt;cell&gt;January 6, 2026&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Fixes mined since&lt;/cell&gt;
        &lt;cell&gt;2005-04-16 (git epoch)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Total records&lt;/cell&gt;
        &lt;cell&gt;125,183&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Unique fixing commits&lt;/cell&gt;
        &lt;cell&gt;119,449&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Unique bug-introducing authors&lt;/cell&gt;
        &lt;cell&gt;9,159&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;With CVE ID&lt;/cell&gt;
        &lt;cell&gt;158&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;With Cc: stable&lt;/cell&gt;
        &lt;cell&gt;27,875 (22%)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Coverage note: The kernel has ~448,000 commits mentioning "fix" in some form, but only ~124,000 (28%) use proper &lt;code&gt;Fixes:&lt;/code&gt; tags. My dataset captures the well-documented bugs aka the ones where maintainers traced the root cause.&lt;/p&gt;
    &lt;head rend="h2"&gt;It varies by subsystem&lt;/head&gt;
    &lt;p&gt;Some subsystems have bugs that persist far longer than others:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Subsystem&lt;/cell&gt;
        &lt;cell role="head"&gt;Bug Count&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg Lifetime&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;drivers/can&lt;/cell&gt;
        &lt;cell&gt;446&lt;/cell&gt;
        &lt;cell&gt;4.2 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;networking/sctp&lt;/cell&gt;
        &lt;cell&gt;279&lt;/cell&gt;
        &lt;cell&gt;4.0 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;networking/ipv4&lt;/cell&gt;
        &lt;cell&gt;1,661&lt;/cell&gt;
        &lt;cell&gt;3.6 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;usb&lt;/cell&gt;
        &lt;cell&gt;2,505&lt;/cell&gt;
        &lt;cell&gt;3.5 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;tty&lt;/cell&gt;
        &lt;cell&gt;1,033&lt;/cell&gt;
        &lt;cell&gt;3.5 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;netfilter&lt;/cell&gt;
        &lt;cell&gt;1,181&lt;/cell&gt;
        &lt;cell&gt;2.9 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;networking&lt;/cell&gt;
        &lt;cell&gt;6,079&lt;/cell&gt;
        &lt;cell&gt;2.9 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;memory&lt;/cell&gt;
        &lt;cell&gt;2,459&lt;/cell&gt;
        &lt;cell&gt;1.8 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;gpu&lt;/cell&gt;
        &lt;cell&gt;5,212&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;bpf&lt;/cell&gt;
        &lt;cell&gt;959&lt;/cell&gt;
        &lt;cell&gt;1.1 years&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;CAN bus and SCTP bugs persist longest. BPF and GPU bugs get caught fastest.&lt;/p&gt;
    &lt;p&gt;CAN bus drivers and SCTP networking have bugs that persist longest probably because both are niche protocols with less testing coverage. GPU (especially Intel i915) and BPF bugs get caught fastest, probably thanks to dedicated fuzzing infrastructure.&lt;/p&gt;
    &lt;p&gt;Interesting finding from comparing 2025-only vs full history:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Subsystem&lt;/cell&gt;
        &lt;cell role="head"&gt;2025-only Avg&lt;/cell&gt;
        &lt;cell role="head"&gt;Full History Avg&lt;/cell&gt;
        &lt;cell role="head"&gt;Difference&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;networking&lt;/cell&gt;
        &lt;cell&gt;5.2 years&lt;/cell&gt;
        &lt;cell&gt;2.9 years&lt;/cell&gt;
        &lt;cell&gt;-2.3 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;filesystem&lt;/cell&gt;
        &lt;cell&gt;3.8 years&lt;/cell&gt;
        &lt;cell&gt;2.6 years&lt;/cell&gt;
        &lt;cell&gt;-1.2 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;drivers/net&lt;/cell&gt;
        &lt;cell&gt;3.3 years&lt;/cell&gt;
        &lt;cell&gt;2.2 years&lt;/cell&gt;
        &lt;cell&gt;-1.1 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;gpu&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
        &lt;cell&gt;0 years&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Networking looked terrible in the 2025-only data (5.2 years!) but is actually closer to average in the full history (2.9 years). The 2025 fixes were catching a backlog of ancient networking bugs. GPU looks the same either way, and those bugs get caught consistently fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;Some bug types hide longer than others&lt;/head&gt;
    &lt;p&gt;Race conditions are the hardest to find, averaging 5.1 years to discovery:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Bug Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Count&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg Lifetime&lt;/cell&gt;
        &lt;cell role="head"&gt;Median&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;race-condition&lt;/cell&gt;
        &lt;cell&gt;1,188&lt;/cell&gt;
        &lt;cell&gt;5.1 years&lt;/cell&gt;
        &lt;cell&gt;2.6 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;integer-overflow&lt;/cell&gt;
        &lt;cell&gt;298&lt;/cell&gt;
        &lt;cell&gt;3.9 years&lt;/cell&gt;
        &lt;cell&gt;2.2 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;use-after-free&lt;/cell&gt;
        &lt;cell&gt;2,963&lt;/cell&gt;
        &lt;cell&gt;3.2 years&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;memory-leak&lt;/cell&gt;
        &lt;cell&gt;2,846&lt;/cell&gt;
        &lt;cell&gt;3.1 years&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;buffer-overflow&lt;/cell&gt;
        &lt;cell&gt;399&lt;/cell&gt;
        &lt;cell&gt;3.1 years&lt;/cell&gt;
        &lt;cell&gt;1.5 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;refcount&lt;/cell&gt;
        &lt;cell&gt;2,209&lt;/cell&gt;
        &lt;cell&gt;2.8 years&lt;/cell&gt;
        &lt;cell&gt;1.3 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;null-deref&lt;/cell&gt;
        &lt;cell&gt;4,931&lt;/cell&gt;
        &lt;cell&gt;2.2 years&lt;/cell&gt;
        &lt;cell&gt;0.7 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;deadlock&lt;/cell&gt;
        &lt;cell&gt;1,683&lt;/cell&gt;
        &lt;cell&gt;2.2 years&lt;/cell&gt;
        &lt;cell&gt;0.8 years&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Why do race conditions hide so long? They're non-deterministic and only trigger under specific timing conditions that might occur once per million executions. Even sanitizers like KCSAN can only flag races they observe.&lt;/p&gt;
    &lt;p&gt;30% of bugs are self-fixes where the same person who introduced the bug eventually fixed it. I guess code ownership matters.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why some bugs hide longer&lt;/head&gt;
    &lt;p&gt;Less fuzzing coverage. Syzkaller excels at syscall fuzzing but struggles with stateful protocols. Fuzzing netfilter effectively requires generating valid packet sequences that traverse specific connection tracking states.&lt;/p&gt;
    &lt;p&gt;Harder to trigger. Many networking bugs require:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Specific packet sequences&lt;/item&gt;
      &lt;item&gt;Race conditions between concurrent flows&lt;/item&gt;
      &lt;item&gt;Memory pressure during table operations&lt;/item&gt;
      &lt;item&gt;Particular NUMA topologies&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Older code with fewer eyes. Core networking infrastructure like &lt;code&gt;nf_conntrack&lt;/code&gt; was written in the mid-2000s. It works, so nobody rewrites it. But "stable" means fewer developers actively reviewing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case study: 19 years in the kernel&lt;/head&gt;
    &lt;p&gt;One of the oldest networking bug in my dataset was introduced in August 2006 and fixed in August 2025:&lt;/p&gt;
    &lt;code&gt;// ctnetlink_dump_table() - the buggy code path
if (res &amp;lt; 0) {
    nf_conntrack_get(&amp;amp;ct-&amp;gt;ct_general);  // increments refcount
    cb-&amp;gt;args[1] = (unsigned long)ct;
    break;
}
&lt;/code&gt;
    &lt;p&gt;The irony: Commit &lt;code&gt;d205dc40798d&lt;/code&gt; was itself a fix: "[NETFILTER]: ctnetlink: fix deadlock in table dumping". Patrick McHardy was fixing a deadlock by removing a &lt;code&gt;_put()&lt;/code&gt; call. In doing so, he introduced a refcount leak that would persist for 19 years.&lt;/p&gt;
    &lt;p&gt;The bug: the code doesn't check if &lt;code&gt;ct == last&lt;/code&gt;. If the current entry is the same as the one we already saved, we've now incremented its refcount twice but will only decrement it once. The object never gets freed.&lt;/p&gt;
    &lt;code&gt;// What should have been checked:
if (res &amp;lt; 0) {
    if (ct != last)  // &amp;lt;-- this check was missing for 19 years
        nf_conntrack_get(&amp;amp;ct-&amp;gt;ct_general);
    cb-&amp;gt;args[1] = (unsigned long)ct;
    break;
}
&lt;/code&gt;
    &lt;p&gt;The consequence: Memory leaks accumulate. Eventually &lt;code&gt;nf_conntrack_cleanup_net_list()&lt;/code&gt; waits forever for the refcount to hit zero. The netns teardown hangs. If you're using containers, this blocks container cleanup indefinitely.&lt;/p&gt;
    &lt;p&gt;Why it took 19 years: You had to run &lt;code&gt;conntrack_resize.sh&lt;/code&gt; in a loop for ~20 minutes under memory pressure. The fix commit says: "This can be reproduced by running conntrack_resize.sh selftest in a loop. It takes ~20 minutes for me on a preemptible kernel." Nobody ran that specific test sequence for two decades.&lt;/p&gt;
    &lt;head rend="h2"&gt;Incomplete fixes are common&lt;/head&gt;
    &lt;p&gt;Here's a pattern I keep seeing: someone notices undefined behavior, ships a fix, but the fix doesn't fully close the hole.&lt;/p&gt;
    &lt;p&gt;Case study: netfilter set field validation&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Date&lt;/cell&gt;
        &lt;cell role="head"&gt;Commit&lt;/cell&gt;
        &lt;cell role="head"&gt;What happened&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Jan 2020&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;f3a2181e16f1&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stefano Brivio adds support for sets with multiple ranged fields. Introduces &lt;code&gt;NFTA_SET_DESC_CONCAT&lt;/code&gt; for specifying field lengths.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Jan 2024&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3ce67e3793f4&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Pablo Neira notices the code doesn't validate that field lengths sum to the key length. Ships a fix. Commit message: "I did not manage to crash nft_set_pipapo with mismatch fields and set key length so far, but this is UB which must be disallowed."&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Jan 2025&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1b9335a8000f&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Security researcher finds a bypass. The 2024 fix was incompleteâthere were still code paths that could mismatch. Real fix shipped.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The 2024 fix was an acknowledgment that something was wrong, but Pablo couldn't find a crash, so the fix was conservative. A year later, someone found the crash.&lt;/p&gt;
    &lt;p&gt;This pattern suggests a detection opportunity: commits that say things like "this is undefined behavior" or "I couldn't trigger this but..." are flags. The author knows something is wrong but hasn't fully characterized the bug. These deserve extra scrutiny.&lt;/p&gt;
    &lt;head rend="h2"&gt;The anatomy of a long-lived bug&lt;/head&gt;
    &lt;p&gt;Looking at the bugs that survive 10+ years, I see common patterns:&lt;/p&gt;
    &lt;p&gt;1. Reference counting errors&lt;/p&gt;
    &lt;code&gt;kref_get(&amp;amp;obj-&amp;gt;ref);
// ... error path returns without kref_put()
&lt;/code&gt;
    &lt;p&gt;These don't crash immediately. They leak memory slowly. In a long-running system, you might not notice until months later when OOM killer starts firing.&lt;/p&gt;
    &lt;p&gt;2. Missing NULL checks after dereference&lt;/p&gt;
    &lt;code&gt;struct foo *f = get_foo();
f-&amp;gt;bar = 1;              // dereference happens first
if (!f) return -EINVAL;  // check comes too late
&lt;/code&gt;
    &lt;p&gt;The compiler might optimize away the NULL check since you already dereferenced. These survive because the pointer is rarely NULL in practice.&lt;/p&gt;
    &lt;p&gt;3. Integer overflow in size calculations&lt;/p&gt;
    &lt;code&gt;size_t total = n_elements * element_size;  // can overflow
buf = kmalloc(total, GFP_KERNEL);
memcpy(buf, src, n_elements * element_size);  // copies more than allocated
&lt;/code&gt;
    &lt;p&gt;If &lt;code&gt;n_elements&lt;/code&gt; comes from userspace, an attacker can cause allocation of a small buffer followed by a large copy.&lt;/p&gt;
    &lt;p&gt;4. Race conditions in state machines&lt;/p&gt;
    &lt;code&gt;spin_lock(&amp;amp;lock);
if (state == READY) {
    spin_unlock(&amp;amp;lock);
    // window here where another thread can change state
    do_operation();  // assumes state is still READY
}
&lt;/code&gt;
    &lt;p&gt;These require precise timing to hit. They might manifest as rare crashes that nobody can reproduce.&lt;/p&gt;
    &lt;head rend="h2"&gt;Can we catch these bugs automatically?&lt;/head&gt;
    &lt;p&gt;Every day a bug lives in the kernel is another day millions of devices are vulnerable. Android phones, servers, embedded systems, cloud infrastructure, all running kernel code with bugs that won't be found for years.&lt;/p&gt;
    &lt;p&gt;I built VulnBERT, a model that predicts whether a commit introduces a vulnerability.&lt;/p&gt;
    &lt;p&gt;Model evolution:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Recall&lt;/cell&gt;
        &lt;cell role="head"&gt;FPR&lt;/cell&gt;
        &lt;cell role="head"&gt;F1&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Random Forest&lt;/cell&gt;
        &lt;cell&gt;76.8%&lt;/cell&gt;
        &lt;cell&gt;15.9%&lt;/cell&gt;
        &lt;cell&gt;0.80&lt;/cell&gt;
        &lt;cell&gt;Hand-crafted features only&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CodeBERT (fine-tuned)&lt;/cell&gt;
        &lt;cell&gt;89.2%&lt;/cell&gt;
        &lt;cell&gt;48.1%&lt;/cell&gt;
        &lt;cell&gt;0.65&lt;/cell&gt;
        &lt;cell&gt;High recall, unusable FPR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;VulnBERT&lt;/cell&gt;
        &lt;cell&gt;92.2%&lt;/cell&gt;
        &lt;cell&gt;1.2%&lt;/cell&gt;
        &lt;cell&gt;0.95&lt;/cell&gt;
        &lt;cell&gt;Best of both approaches&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The problem with vanilla CodeBERT: I first tried fine-tuning CodeBERT directly. Results: 89% recall but 48% false positive rate (measured on the same test set). Unusable, flagging half of all commits.&lt;/p&gt;
    &lt;p&gt;Why so bad? CodeBERT learns shortcuts: "big diff = dangerous", "lots of pointers = risky". These correlations exist in training data but don't generalize. The model pattern-matches on surface features, not actual bug patterns.&lt;/p&gt;
    &lt;p&gt;The VulnBERT approach: Combine neural pattern recognition with human domain expertise.&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
â                            INPUT: Git Diff                          â
âââââââââââââââââââââââââââââââââ¬ââââââââââââââââââââââââââââââââââââââ
                                â
                âââââââââââââââââ´ââââââââââââââââ
                â¼                               â¼
âââââââââââââââââââââââââââââ   âââââââââââââââââââââââââââââââââââââ
â   Chunked Diff Encoder    â   â   Handcrafted Feature Extractor   â
â   (CodeBERT + Attention)  â   â   (51 engineered features)        â
âââââââââââââââ¬ââââââââââââââ   âââââââââââââââââââ¬ââââââââââââââââââ
              â [768-dim]                         â [51-dim]
              âââââââââââââââââ¬ââââââââââââââââââââ
                              â¼
              âââââââââââââââââââââââââââââââââ
              â     Cross-Attention Fusion    â
              â     "When code looks like X,  â
              â      feature Y matters more"  â
              âââââââââââââââââ¬ââââââââââââââââ
                              â¼
              âââââââââââââââââââââââââââââââââ
              â        Risk Classifier        â
              âââââââââââââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;Three innovations that drove performance:&lt;/p&gt;
    &lt;p&gt;1. Chunked encoding for long diffs. CodeBERT's 512-token limit truncates most kernel diffs (often 2000+ tokens). I split into chunks, encode each, then use learned attention to aggregate:&lt;/p&gt;
    &lt;code&gt;# Learnable attention over chunks
chunk_attention = nn.Sequential(
    nn.Linear(hidden_size, hidden_size // 4),
    nn.Tanh(),
    nn.Linear(hidden_size // 4, 1)
)
attention_weights = F.softmax(chunk_attention(chunk_embeddings), dim=1)
pooled = (attention_weights * chunk_embeddings).sum(dim=1)
&lt;/code&gt;
    &lt;p&gt;The model learns which chunks matter aka the one with &lt;code&gt;spin_lock&lt;/code&gt; without &lt;code&gt;spin_unlock&lt;/code&gt;, not the boilerplate.&lt;/p&gt;
    &lt;p&gt;2. Feature fusion via cross-attention. Neural networks miss domain-specific patterns. I extract 51 handcrafted features using regex and AST-like analysis of the diff:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Features&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Basic (4)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;lines_added&lt;/code&gt;, &lt;code&gt;lines_removed&lt;/code&gt;, &lt;code&gt;files_changed&lt;/code&gt;, &lt;code&gt;hunks_count&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memory (3)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_kmalloc&lt;/code&gt;, &lt;code&gt;has_kfree&lt;/code&gt;, &lt;code&gt;has_alloc_no_free&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Refcount (5)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_get&lt;/code&gt;, &lt;code&gt;has_put&lt;/code&gt;, &lt;code&gt;get_count&lt;/code&gt;, &lt;code&gt;put_count&lt;/code&gt;, &lt;code&gt;unbalanced_refcount&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Locking (5)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_lock&lt;/code&gt;, &lt;code&gt;has_unlock&lt;/code&gt;, &lt;code&gt;lock_count&lt;/code&gt;, &lt;code&gt;unlock_count&lt;/code&gt;, &lt;code&gt;unbalanced_lock&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pointers (4)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_deref&lt;/code&gt;, &lt;code&gt;deref_count&lt;/code&gt;, &lt;code&gt;has_null_check&lt;/code&gt;, &lt;code&gt;has_deref_no_null_check&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Error handling (6)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_goto&lt;/code&gt;, &lt;code&gt;goto_count&lt;/code&gt;, &lt;code&gt;has_error_return&lt;/code&gt;, &lt;code&gt;has_error_label&lt;/code&gt;, &lt;code&gt;error_return_count&lt;/code&gt;, &lt;code&gt;has_early_return&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Semantic (13)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;var_after_loop&lt;/code&gt;, &lt;code&gt;iterator_modified_in_loop&lt;/code&gt;, &lt;code&gt;list_iteration&lt;/code&gt;, &lt;code&gt;list_del_in_loop&lt;/code&gt;, &lt;code&gt;has_container_of&lt;/code&gt;, &lt;code&gt;has_cast&lt;/code&gt;, &lt;code&gt;cast_count&lt;/code&gt;, &lt;code&gt;sizeof_type&lt;/code&gt;, &lt;code&gt;sizeof_ptr&lt;/code&gt;, &lt;code&gt;has_arithmetic&lt;/code&gt;, &lt;code&gt;has_shift&lt;/code&gt;, &lt;code&gt;has_copy&lt;/code&gt;, &lt;code&gt;copy_count&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Structural (11)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;if_count&lt;/code&gt;, &lt;code&gt;else_count&lt;/code&gt;, &lt;code&gt;switch_count&lt;/code&gt;, &lt;code&gt;case_count&lt;/code&gt;, &lt;code&gt;loop_count&lt;/code&gt;, &lt;code&gt;ternary_count&lt;/code&gt;, &lt;code&gt;cyclomatic_complexity&lt;/code&gt;, &lt;code&gt;max_nesting_depth&lt;/code&gt;, &lt;code&gt;function_call_count&lt;/code&gt;, &lt;code&gt;unique_functions_called&lt;/code&gt;, &lt;code&gt;function_definitions&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The key bug-pattern features:&lt;/p&gt;
    &lt;code&gt;'unbalanced_refcount': 1,    # kref_get without kref_put â leak
'unbalanced_lock': 1,        # spin_lock without spin_unlock â deadlock
'has_deref_no_null_check': 0,# *ptr without if(!ptr) â null deref
'has_alloc_no_free': 0,      # kmalloc without kfree â memory leak
&lt;/code&gt;
    &lt;p&gt;Cross-attention learns conditional relationships. When CodeBERT sees locking patterns AND &lt;code&gt;unbalanced_lock=1&lt;/code&gt;, that's HIGH risk. Neither signal alone is sufficient, it's the combination.&lt;/p&gt;
    &lt;code&gt;# Feature fusion via cross-attention
feature_embedding = feature_projection(handcrafted_features)  # 51 â 768
attended, _ = cross_attention(
    query=code_embedding,      # What patterns does the code have?
    key=feature_embedding,     # What do the hand-crafted features say?
    value=feature_embedding
)
fused = fusion_layer(torch.cat([code_embedding, attended], dim=-1))
&lt;/code&gt;
    &lt;p&gt;3. Focal loss for hard examples. The training data is imbalanced where most commits are safe. Standard cross-entropy wastes gradient updates on easy examples. Focal loss:&lt;/p&gt;
    &lt;code&gt;Standard loss when p=0.95 (easy):  0.05
Focal loss when p=0.95:            0.000125  (400x smaller)
&lt;/code&gt;
    &lt;p&gt;The model focuses on ambiguous commits: the hard 5% that matter.&lt;/p&gt;
    &lt;p&gt;Impact of each component (estimated from ablation experiments):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;F1 Score&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CodeBERT baseline&lt;/cell&gt;
        &lt;cell&gt;~76%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;+ Focal loss&lt;/cell&gt;
        &lt;cell&gt;~80%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;+ Feature fusion&lt;/cell&gt;
        &lt;cell&gt;~88%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;+ Contrastive learning&lt;/cell&gt;
        &lt;cell&gt;~91%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Full VulnBERT&lt;/cell&gt;
        &lt;cell&gt;95.4%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note: Individual component impacts are approximate; interactions between components make precise attribution difficult.&lt;/p&gt;
    &lt;p&gt;The key insight: neither neural networks nor hand-crafted rules alone achieve the best results. The combination does.&lt;/p&gt;
    &lt;p&gt;Results on temporal validation (train â¤2023, test 2024):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Target&lt;/cell&gt;
        &lt;cell role="head"&gt;Result&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Recall&lt;/cell&gt;
        &lt;cell&gt;90%&lt;/cell&gt;
        &lt;cell&gt;92.2% â&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FPR&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;10%&lt;/cell&gt;
        &lt;cell&gt;1.2% â&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Precision&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
        &lt;cell&gt;98.7%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;F1&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
        &lt;cell&gt;95.4%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;AUC&lt;/cell&gt;
        &lt;cell&gt;â&lt;/cell&gt;
        &lt;cell&gt;98.4%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;What these metrics mean:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Recall (92.2%): Of all actual bug-introducing commits, we catch 92.2%. Missing 7.8% of bugs.&lt;/item&gt;
      &lt;item&gt;False Positive Rate (1.2%): Of all safe commits, we incorrectly flag 1.2%. Low FPR = fewer false alarms.&lt;/item&gt;
      &lt;item&gt;Precision (98.7%): Of commits we flag as risky, 98.7% actually are. When we raise an alarm, we're almost always right.&lt;/item&gt;
      &lt;item&gt;F1 (95.4%): Harmonic mean of precision and recall. Single number summarizing overall performance.&lt;/item&gt;
      &lt;item&gt;AUC (98.4%): Area under ROC curve. Measures ranking qualityâhow well the model separates bugs from safe commits across all thresholds.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The model correctly differentiates the same bug at different stages:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Commit&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Risk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;acf44a2361b8&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fix for UAF in xe_vfio&lt;/cell&gt;
        &lt;cell&gt;12.4% LOW â&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;1f5556ec8b9e&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Introduced the UAF&lt;/cell&gt;
        &lt;cell&gt;83.8% HIGH â&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;What the model sees: The 19-year bug&lt;/head&gt;
    &lt;p&gt;When analyzing the bug-introducing commit &lt;code&gt;d205dc40798d&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;-    if (ct == last) {
-        nf_conntrack_put(&amp;amp;last-&amp;gt;ct_general);  // removed!
-    }
+    if (ct == last) {
+        last = NULL;
         continue;
     }
     if (ctnetlink_fill_info(...) &amp;lt; 0) {
         nf_conntrack_get(&amp;amp;ct-&amp;gt;ct_general);  // still here
&lt;/code&gt;
    &lt;p&gt;Extracted features:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Signal&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;get_count&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;nf_conntrack_get()&lt;/code&gt; present&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;put_count&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;nf_conntrack_put()&lt;/code&gt; was removed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;unbalanced_refcount&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Mismatch detected&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;has_lock&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Uses &lt;code&gt;read_lock_bh()&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;list_iteration&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Uses &lt;code&gt;list_for_each_prev()&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Model prediction: 72% risk: HIGH&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;unbalanced_refcount&lt;/code&gt; feature fires because &lt;code&gt;_put()&lt;/code&gt; was removed but &lt;code&gt;_get()&lt;/code&gt; remains. Classic refcount leak pattern.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limitations&lt;/head&gt;
    &lt;p&gt;Dataset limitations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only captures bugs with &lt;code&gt;Fixes:&lt;/code&gt;tags (~28% of fix commits). Selection bias: well-documented bugs tend to be more serious.&lt;/item&gt;
      &lt;item&gt;Mainline only, doesn't include stable-branch-only fixes or vendor patches&lt;/item&gt;
      &lt;item&gt;Subsystem classification is heuristic-based (regex on file paths)&lt;/item&gt;
      &lt;item&gt;Bug type detection based on keyword matching in commit messages and many bugs are "unknown" type&lt;/item&gt;
      &lt;item&gt;Lifetime calculation uses author dates, not commit dates, rebasing can skew timestamps&lt;/item&gt;
      &lt;item&gt;Some "bugs" may be theoretical (comments like "fix possible race" without confirmed trigger)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Model limitations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;92.2% recall is on a held-out 2024 test set, not a guarantee for future bugs&lt;/item&gt;
      &lt;item&gt;Can't catch semantic bugs (logic errors with no syntactic signal)&lt;/item&gt;
      &lt;item&gt;Cross-function blind spots (bug spans multiple files)&lt;/item&gt;
      &lt;item&gt;Training data bias (learns patterns from bugs that were found, novel patterns may be missed)&lt;/item&gt;
      &lt;item&gt;False positives on intentional patterns (init/cleanup in different commits)&lt;/item&gt;
      &lt;item&gt;Tested only on Linux kernel code, may not generalize to other codebases&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Statistical limitations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Survivorship bias in year-over-year comparisons (recent bugs can't have long lifetimes yet)&lt;/item&gt;
      &lt;item&gt;Correlation â causation for subsystem/bug-type lifetime differences&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What this means: VulnBERT is a triage tool, not a guarantee. It catches 92% of bugs with recognizable patterns. The remaining 8% and novel bug classes still need human review and fuzzing.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's next&lt;/head&gt;
    &lt;p&gt;92.2% recall with 1.2% FPR is production-ready. But there's more to do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RL-based exploration: Instead of static pattern matching, train an agent to explore code paths and find bugs autonomously. The current model predicts risk; an RL agent could generate triggering inputs.&lt;/item&gt;
      &lt;item&gt;Syzkaller integration: Use fuzzer coverage as a reward signal. If the model flags a commit and Syzkaller finds a crash in that code path, that's strong positive signal.&lt;/item&gt;
      &lt;item&gt;Subsystem-specific models: Networking bugs have different patterns than driver bugs. A model fine-tuned on netfilter might outperform the general model on netfilter commits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The goal isn't to replace human reviewers but to point them at the 10% of commits most likely to be problematic, so they can focus attention where it matters.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reproducing this&lt;/head&gt;
    &lt;p&gt;The dataset extraction uses the kernel's &lt;code&gt;Fixes:&lt;/code&gt; tag convention. Here's the core logic:&lt;/p&gt;
    &lt;code&gt;def extract_fixes_tag(commit_msg: str) -&amp;gt; Optional[str]:
    """Extract the commit ID from a Fixes: tag"""
    pattern = r'Fixes:\s*([a-f0-9]{12,40})'
    match = re.search(pattern, commit_msg, re.IGNORECASE)
    return match.group(1) if match else None

# Mine all Fixes: tags from git history
git log --since="2005-04-16" --grep="Fixes:" --format="%H"

# For each fixing commit:
#   - Extract introducing commit hash
#   - Get dates from both commits
#   - Calculate lifetime
#   - Classify subsystem from file paths
&lt;/code&gt;
    &lt;p&gt;Full miner code and dataset: github.com/quguanni/kernel-vuln-data&lt;/p&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;125,183 bugs analyzed from 20 years of Linux kernel git history (123,696 with valid lifetimes)&lt;/item&gt;
      &lt;item&gt;Average bug lifetime: 2.1 years (2.8 years in 2025-only data due to survivorship bias in recent fixes)&lt;/item&gt;
      &lt;item&gt;0% â 69% of bugs found within 1 year (2010 vs 2022) (real improvement from better tooling)&lt;/item&gt;
      &lt;item&gt;13.5% of bugs hide for 5+ years (these are the dangerous ones)&lt;/item&gt;
      &lt;item&gt;Race conditions hide longest (5.1 years average)&lt;/item&gt;
      &lt;item&gt;VulnBERT catches 92.2% of bugs on held-out 2024 test set with only 1.2% FPR (98.4% AUC)&lt;/item&gt;
      &lt;item&gt;Dataset: github.com/quguanni/kernel-vuln-data&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you're working on kernel security, vulnerability detection, or ML for code analysis, I'd love to talk: jenny@pebblebed.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46536340</guid><pubDate>Thu, 08 Jan 2026 02:18:09 +0000</pubDate></item><item><title>Open Infrastructure Map</title><link>https://openinframap.org</link><description>&lt;doc fingerprint="6d0a85331c526182"&gt;
  &lt;main&gt;
    &lt;p&gt;You must have Javascript enabled to view Open Infrastructure Map Open Infrastructure Map about stats exports&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46536866</guid><pubDate>Thu, 08 Jan 2026 03:31:12 +0000</pubDate></item><item><title>Go.sum is not a lockfile</title><link>https://words.filippo.io/gosum/</link><description>&lt;doc fingerprint="b6383f772da5a398"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;go.sum Is Not a Lockfile&lt;/head&gt;
    &lt;p&gt;I need everyone to stop looking at &lt;code&gt;go.sum&lt;/code&gt;, especially to analyze dependency graphs. It is not a “lockfile,”1 and it has zero semantic effects on version resolution. There is truly no use case for ever parsing it outside of cmd/go.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;go.sum&lt;/code&gt; is only a local cache for the Go Checksum Database. It’s a map of module versions to their cryptographic hashes. Those versions may or may not be in use; it doesn’t matter to package resolution.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;go.sum&lt;/code&gt; was not even enabled by default in the original modules design, precisely because it has no observable effect on builds!2 Its (important) purpose is exclusively tightening the security story: the Checksum Database ensures the whole ecosystem shares the same contents for a given module version, regardless of how it is downloaded, and &lt;code&gt;go.sum&lt;/code&gt; makes that guarantee local and self-contained.&lt;/p&gt;
    &lt;p&gt;Instead, just look at &lt;code&gt;go.mod&lt;/code&gt;. It lists the precise version at which all dependencies are built. Since Go 1.17 (released August 2021), it includes all transitive dependencies needed to build the main module and its tests.3&lt;/p&gt;
    &lt;p&gt;You can either parse &lt;code&gt;go.mod&lt;/code&gt; with golang.org/x/mod/modfile, run &lt;code&gt;go mod edit -json&lt;/code&gt; to get its JSON representation,4 or parse it according to its specification.&lt;/p&gt;
    &lt;p&gt;This is the end of the Public Service Announcement. Read on for some &lt;code&gt;go.mod&lt;/code&gt; nerdery.&lt;/p&gt;
    &lt;head rend="h2"&gt;Manifests and lockfiles&lt;/head&gt;
    &lt;p&gt;The enduring confusion around &lt;code&gt;go.mod&lt;/code&gt; and &lt;code&gt;go.sum&lt;/code&gt; is due to the fact that most other languages also have two package-related files, but theirs both matter to version resolution. These two files are usually called manifest and lockfile.&lt;/p&gt;
    &lt;p&gt;The manifest (e.g. &lt;code&gt;pyproject.toml&lt;/code&gt;, &lt;code&gt;package.json&lt;/code&gt;, &lt;code&gt;Cargo.toml&lt;/code&gt;) usually lists some dependencies along with potentially complex rules for which versions are supported. These rules usually apply transitively to dependents, making version resolution extremely hard and/or slow in the general case, and sometimes unsolvable. The manifest is not always5 guaranteed to list all direct dependencies, and no automated mechanism ensures your code actually works with e.g. the minimum allowed manifest version of its dependencies.6&lt;/p&gt;
    &lt;p&gt;The lockfile (e.g. &lt;code&gt;uv.lock&lt;/code&gt;, &lt;code&gt;package-lock.json&lt;/code&gt;, &lt;code&gt;Cargo.lock&lt;/code&gt;) is a relatively recent innovation in some ecosystems, and it lists the actual versions used in the most recent build. It is not really human-readable, and is ignored by dependents, allowing the rapid spread of supply-chain attacks.&lt;/p&gt;
    &lt;p&gt;I honestly find the manifest version ranges essentially useless (because the lower bounds are not normally tested and hence largely incorrect, while I never had a use case for complex upper bounds). I also get endlessly confused trying to remember which commands modify the lockfile (and when/why) and which ones respect it.&lt;/p&gt;
    &lt;p&gt;In Go, &lt;code&gt;go.mod&lt;/code&gt; serves as both manifest and lockfile, and more: it lists all dependencies, direct and transitive, and their exact version to be used when the module is the main module. Semantic versioning is assumed, and those versions are also the minimum versions applied to dependents’ module graphs. Different major versions of the same module are considered essentially separate modules.&lt;/p&gt;
    &lt;p&gt;Notice how there is no way to accidentally use a feature introduced in a version that your dependents won’t have. Also, when adding a dependency, you don’t automatically get the latest—potentially untested/compromised—version of all its dependencies. Finally, there can’t be diamond dependency conflicts.&lt;/p&gt;
    &lt;p&gt;All that with a single, human-readable file: &lt;code&gt;go.mod&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;All &lt;code&gt;go&lt;/code&gt; commands take a &lt;code&gt;-mod&lt;/code&gt; flag. If set to &lt;code&gt;mod&lt;/code&gt;, missing dependencies can be added to &lt;code&gt;go.mod&lt;/code&gt; automatically if necessary, and partial manual changes are reconciled. If set to &lt;code&gt;readonly&lt;/code&gt;, those are errors. &lt;code&gt;go mod tidy&lt;/code&gt; and (effectively) &lt;code&gt;go get&lt;/code&gt; default to &lt;code&gt;mod&lt;/code&gt;; all other commands default to &lt;code&gt;readonly&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Go modules truly don’t get enough credit for how much simpler they are compared to the alternatives. In other ecosystems, package resolution time going down below 1s is celebrated (and is indeed an impressive technical achievement given the design’s requirements!). In Go, no one ever noticed package resolution happening, so there is nothing to celebrate.&lt;/p&gt;
    &lt;p&gt;For more ecosystem feature appreciation posts, follow me on Bluesky at @filippo.abyssdomain.expert or on Mastodon at @filippo@abyssdomain.expert.&lt;/p&gt;
    &lt;head rend="h2"&gt;The picture&lt;/head&gt;
    &lt;p&gt;I had a great time at 39c3 during the holidays. The Chaos Communication Congress is a magical place with a very strict photo policy, so it’s pretty hard to convey its atmosphere. This is the best I could do without recognizable humans in the frame. In Fairy Dust we trust!&lt;/p&gt;
    &lt;p&gt;My work is made possible by Geomys, an organization of professional Go maintainers, which is funded by Smallstep, Ava Labs, Teleport, Tailscale, and Sentry. Through our retainer contracts, they ensure the sustainability and reliability of our open source maintenance work and get a direct line to my expertise and that of the other Geomys maintainers. (Learn more in the Geomys announcement.) Here are a few words from some of them!&lt;/p&gt;
    &lt;p&gt;Teleport — For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. Teleport Identity is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.&lt;/p&gt;
    &lt;p&gt;Ava Labs — We at Ava Labs, maintainer of AvalancheGo (the most widely used client for interacting with the Avalanche Network), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;In the sense of the word as introduced by the original&lt;/p&gt;&lt;code&gt;Gemfile.lock&lt;/code&gt;, which only locked the selected versions. Most lockfiles these days also include the cryptographic checksums of version contents, which in Go is instead handled by the Go Checksum Database and&lt;code&gt;go.sum&lt;/code&gt;. ↩&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I still think it’s important and it was the first thing I remember advocating for when I joined the Go team, because it makes the module cryptographically self-contained, and because the Go Checksum Database transparency story is not great in ephemeral environments like CI. These are security effects, though, not semantic ones. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;These are the only dependencies you care about, even for security. If the main module imports&lt;/p&gt;&lt;code&gt;example.com/mod1/pkg1&lt;/code&gt;and a separate&lt;code&gt;example.com/mod1/pkg2&lt;/code&gt;imports&lt;code&gt;example.com/mod2&lt;/code&gt;, there is no way for&lt;code&gt;example.com/mod2&lt;/code&gt;to affect the build or run code on the developer’s machine, so you don’t need to consider it a dependency. This is actually very powerful, allowing libraries to segregate dependencies (e.g. the AWS SDK) in optional packages, reducing the transitive trust tree of dependents that don’t use that feature. ↩↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Why not&lt;/p&gt;&lt;code&gt;go list -m all&lt;/code&gt;, you ask? Because that prints the whole module graph, which includes modules that don’t contribute to the build3 and are not included in&lt;code&gt;go.mod&lt;/code&gt;. A closer approximation would be&lt;code&gt;go list -f '{{.Module}}' all&lt;/code&gt;, but this command applies the local build constraints, like GOOS/GOARCH. There is an open proposal for a flag to do&lt;code&gt;go.mod&lt;/code&gt;-like resolution in&lt;code&gt;go list&lt;/code&gt;. ↩&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I am told that Cargo enforces it, and some other package managers have a warning. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cargo has an opt-in, unstable, not recommended mode for it. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46537095</guid><pubDate>Thu, 08 Jan 2026 04:10:34 +0000</pubDate></item><item><title>Project Patchouli: Open-source electromagnetic drawing tablet hardware</title><link>https://patchouli.readthedocs.io/en/latest/</link><description>&lt;doc fingerprint="2791b911676f82d7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Project Patchouli&lt;/head&gt;
    &lt;p&gt;Open-Source EMR Pen Tablet Hardware Implementation and Documentation&lt;/p&gt;
    &lt;p&gt;Patchouli is an open-source electro-magnetic drawing tablet hardware implementation, including a coil array, an RF front end built using commercially available parts, and digital signal processing algorithms. The design is compatible with most commercial pens from different vendors, offering an ultra-low-latency pen input experience for your customized hardware projects.&lt;/p&gt;
    &lt;p&gt;In addition, this project aims to provide a comprehensive documentation of the EMR technology, including the mechanism, circuit implementation, signal processing algorithms, and the pen protocol of different product lines from different vendors.&lt;/p&gt;
    &lt;p&gt;Project Code / Hardware Repository: GitLab&lt;/p&gt;
    &lt;head rend="h2"&gt;Updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;January 2024, The project started.&lt;/item&gt;
      &lt;item&gt;March 2024, the first small-scale hardware prototype was successfully tested.&lt;/item&gt;
      &lt;item&gt;January 2025, the documentation page was hosted on Read the Docs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Maintainers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Project Lead: Yukidama&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Community&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reaching out to the maintainers: prj.patchouli@gmail.com&lt;/item&gt;
      &lt;item&gt;Join our public Discord Server&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Sponsorship&lt;/head&gt;
    &lt;p&gt;This project is sponsored by the NLnet Foundation NGI Zero Core Fund. Learn more about it here: Project Patchouli&lt;/p&gt;
    &lt;head rend="h2"&gt;License&lt;/head&gt;
    &lt;p&gt;Project Patchouli Documentation by Yukidama and other project members is licensed under Creative Commons Attribution 4.0 International&lt;/p&gt;
    &lt;p&gt;All images and other resource files in this project, unless otherwise specified, are created by the project team and are licensed under the same CC BY 4.0 license.&lt;/p&gt;
    &lt;p&gt;The hardware design is released under the CERN Open Source Hardware License strongly-reciprocal variant, CERN-OHL-S. A copy of the license is provided in the source repository. Additionally, a user guide of the license is provided on ohwr.org.&lt;/p&gt;
    &lt;p&gt;All program code, unless otherwise specified, is licensed under the GPLv3 license.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;This project is under active development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46537489</guid><pubDate>Thu, 08 Jan 2026 05:20:05 +0000</pubDate></item><item><title>A closer look at a BGP anomaly in Venezuela</title><link>https://blog.cloudflare.com/bgp-route-leak-venezuela/</link><description>&lt;doc fingerprint="b6439bf1a821c86b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;As news unfolds surrounding the U.S. capture and arrest of Venezuelan leader NicolÃ¡s Maduro, a cybersecurity newsletter examined Cloudflare Radar data and took note of a routing leak in Venezuela on January 2.&lt;/p&gt;
      &lt;p&gt;We dug into the data. Since the beginning of December there have been eleven route leak events, impacting multiple prefixes, where AS8048 is the leaker. Although it is impossible to determine definitively what happened on the day of the event, this pattern of route leaks suggests that the CANTV (AS8048) network, a popular Internet Service Provider (ISP) in Venezuela, has insufficient routing export and import policies. In other words, the BGP anomalies observed by the researcher could be tied to poor technical practices by the ISP rather than malfeasance.&lt;/p&gt;
      &lt;p&gt;In this post, weâll briefly discuss Border Gateway Protocol (BGP) and BGP route leaks, and then dig into the anomaly observed and what may have happened to cause it.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Background: BGP route leaks&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;First, letâs revisit what a BGP route leak is. BGP route leaks cause behavior similar to taking the wrong exit off of a highway. While you may still make it to your destination, the path may be slower and come with delays you wouldnât otherwise have traveling on a more direct route.&lt;/p&gt;
      &lt;p&gt;Route leaks were given a formal definition in RFC7908 as âthe propagation of routing announcement(s) beyond their intended scope.â Intended scope is defined using pairwise business relationships between networks. The relationships between networks, which in BGP we represent using Autonomous Systems (ASes), can be one of the following:Â &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;customer-provider: A customer pays a provider network to connect them and their own downstream customers to the rest of the Internet&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;peer-peer: Two networks decide to exchange traffic between one another, to each othersâ customers, settlement-free (without payment)&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;In a customer-provider relationship, the provider will announce all routes to the customer. The customer, on the other hand, will advertise only the routes from their own customers and originating from their network directly.&lt;/p&gt;
      &lt;p&gt;In a peer-peer relationship, each peer will advertise to one another only their own routes and the routes of their downstream customers.Â &lt;/p&gt;
      &lt;p&gt;These advertisements help direct traffic in expected ways: from customers upstream to provider networks, potentially across a single peering link, and then potentially back down to customers on the far end of the path from their providers.Â &lt;/p&gt;
      &lt;p&gt;A valid path would look like the following that abides by the valley-free routing rule:Â &lt;/p&gt;
      &lt;p&gt;A route leak is a violation of valley-free routing where an AS takes routes from a provider or peer and redistributes them to another provider or peer. For example, a BGP path should never go through a âvalleyâ where traffic goes up to a provider, and back down to a customer, and then up to a provider again. There are different types of route leaks defined in RFC7908, but a simple one is the Type 1: Hairpin route leak between two provider networks by a customer.Â &lt;/p&gt;
      &lt;p&gt;In the figure above, AS64505 takes routes from one of its providers and redistributes them to their other provider. This is unexpected, since we know providers should not use their customer as an intermediate IP transit network. AS64505 would become overwhelmed with traffic, as a smaller network with a smaller set of backbone and network links than its providers. This can become very impactful quickly.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Route leak by AS8048 (CANTV)&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Now that we have reminded ourselves what a route leak is in BGP, letâs examine what was hypothesizedÂ in the newsletter post. The post called attention to a few route leak anomalies on Cloudflare Radar involving AS8048. On the Radar page for this leak, we see this information:&lt;/p&gt;
      &lt;p&gt;We see the leaker AS, which is AS8048 â CANTV, Venezuelaâs state-run telephone and Internet Service Provider. We observe that routes were taken from one of their providers AS6762 (Sparkle, an Italian telecom company) and then redistributed to AS52320 (V.tal GlobeNet, a Colombian network service provider). This is definitely a route leak.Â &lt;/p&gt;
      &lt;p&gt;The newsletter suggests âBGP shenanigansâ and posits that such a leak could be exploited to collect intelligence useful to government entities.Â &lt;/p&gt;
      &lt;p&gt;While we canât say with certainty what caused this route leak, our data suggests that its likely cause was more mundane. Thatâs in part because BGP route leaks happen all of the time, and they have always been part of the Internet â most often for reasons that arenât malicious.&lt;/p&gt;
      &lt;p&gt;To understand more, letâs look closer at the impacted prefixes and networks. The prefixes involved in the leak were all originated by AS21980 (Dayco Telecom, a Venezuelan company):&lt;/p&gt;
      &lt;p&gt;The prefixes are also all members of the same 200.74.224.0/20 subnet, as noted by the newsletter author. Much more intriguing than this, though, is the relationship between the originating network AS21980 and the leaking network AS8048: AS8048 is a provider of AS21980.Â &lt;/p&gt;
      &lt;p&gt;The customer-provider relationship between AS8048 and AS21980 is visible in both Cloudflare Radar and bgp.tools AS relationship interference data. We can also get a confidence score of the AS relationship using the monocle tool from BGPKIT, as you see here:Â &lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;âÂ  ~ monocle as2rel 8048 21980
Explanation:
- connected: % of 1813 peers that see this AS relationship
- peer: % where the relationship is peer-to-peer
- as1_upstream: % where ASN1 is the upstream (provider)
- as2_upstream: % where ASN2 is the upstream (provider)&lt;/code&gt;
      &lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;Data source: https://data.bgpkit.com/as2rel/as2rel-latest.json.bz2&lt;/code&gt;
      &lt;/p&gt;
      &lt;p&gt;
        &lt;code&gt;ââââââââ¬ââââââââ¬ââââââââââââ¬âââââââ¬âââââââââââââââ¬âââââââââââââââ®
âÂ asn1 â asn2Â  â connectedÂ â peer â as1_upstreamÂ âÂ as2_upstream â
ââââââââ¼ââââââââ¼ââââââââââââ¼âââââââ¼âââââââââââââââ¼âââââââââââââââ¤
â 8048 â 21980 â    9.9% Â  â 0.6%Â â     9.4%Â   Â  â 0.0% Â  Â  Â  Â  â
â°âââââââ´ââââââââ´ââââââââââââ´âââââââ´âââââââââââââââ´âââââââââââââââ¯&lt;/code&gt;
      &lt;/p&gt;
      &lt;p&gt;While only 9.9% of route collectors see these two ASes as adjacent, almost all of the paths containing them reflect AS8048 as an upstream provider for AS21980, meaning confidence is high in the provider-customer relationship between the two.&lt;/p&gt;
      &lt;p&gt;Many of the leaked routes were also heavily prepended with AS8048, meaning it would have been potentially less attractive for routing when received by other networks. Prepending is the padding of an AS more than one time in an outbound advertisement by a customer or peer, to attempt to switch traffic away from a particular circuit to another. For example, many of the paths during the leak by AS8048 looked like this: â52320,8048,8048,8048,8048,8048,8048,8048,8048,8048,23520,1299,269832,21980â.Â &lt;/p&gt;
      &lt;p&gt;You can see that AS8048 has sent their AS multiple times in an advertisement to AS52320, because by means of BGP loop prevention the path would never actually travel in and out of AS8048 multiple times in a row. A non-prepended path would look like this: â52320,8048,23520,1299,269832,21980â.Â &lt;/p&gt;
      &lt;p&gt;If AS8048 was intentionally trying to become a man-in-the-middle (MITM) for traffic, why would they make the BGP advertisement less attractive instead of more attractive? Also, why leak prefixes to try and MITM traffic when youâre already a provider for the downstream AS anyway? That wouldnât make much sense.Â &lt;/p&gt;
      &lt;p&gt;The leaks from AS8048 also surfaced in multiple separate announcements, each around an hour apart on January 2, 2026 between 15:30 and 17:45 UTC, suggesting they may have been having network issues that surfaced in a routing policy issue or a convergence-based mishap.Â &lt;/p&gt;
      &lt;p&gt;It is also noteworthy that these leak events begin over twelve hours prior to the U.S. military strikes in Venezuela. Leaks that impact South American networks are common, and we have no reason to believe, based on timing or the other factors I have discussed, that the leak is related to the capture of Maduro several hours later.&lt;/p&gt;
      &lt;p&gt;In fact, looking back the past two months, we can see plenty of leaks by AS8048 that are just like this one, meaning this is not a new BGP anomaly:&lt;/p&gt;
      &lt;p&gt;You can see above in the history of Cloudflare Radarâs route leak alerting pipeline that AS8048 is no stranger to Type 1 hairpin route leaks. Since the beginning of December alone there have been eleven route leak events where AS8048 is the leaker.&lt;/p&gt;
      &lt;p&gt;From this we can draw a more innocent possible explanation about the route leak: AS8048 may have configured too loose of export policies facing at least one of their providers, AS52320. And because of that, redistributed routes belong to their customer even when the direct customer BGP routes were missing. If their export policy toward AS52320 only matched on IRR-generated prefix list and not a customer BGP community tag, for example, it would make sense why an indirect path toward AS6762 was leaked back upstream by AS8048.Â &lt;/p&gt;
      &lt;p&gt;These types of policy errors are something RFC9234 and the Only-to-Customer (OTC) attribute would help with considerably, by coupling BGP more tightly to customer-provider and peer-peer roles, when supported by all routing vendors. I will save the more technical details on RFC9234 for a follow-up blog post.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;The difference between origin and path validation&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;The newsletter also calls out as ânotableâ that Sparkle (AS6762) does not implement RPKI (Resource Public Key Infrastructure) Route Origin Validation (ROV). While it is true that AS6762 appears to have an incomplete deployment of ROV and is flagged as âunsafeâ on isbgpsafeyet.com because of it, origin validation would not have prevented this BGP anomaly in Venezuela.Â &lt;/p&gt;
      &lt;p&gt;It is important to separate BGP anomalies into two categories: route misoriginations, and path-based anomalies. Knowing the difference between the two helps to understand the solution for each. Route misoriginations, often called BGP hijacks, are meant to be fixed by RPKI Route Origin Validation (ROV) by making sure the originator of a prefix is who rightfully owns it. In the case of the BGP anomaly described in this post, the origin AS was correct as AS21980 and only the path was anomalous. This means ROV wouldnât help here.&lt;/p&gt;
      &lt;p&gt;Knowing that, we need path-based validation. This is what Autonomous System Provider Authorization (ASPA), an upcoming draft standard in the IETF, is going to provide. The idea is similar to RPKI Route Origin Authorizations (ROAs) and ROV: create an ASPA object that defines a list of authorized providers (upstreams) for our AS, and everyone will use this to invalidate route leaks on the Internet at various vantage points. Using a concrete example, AS6762 is a Tier-1 transit-free network, and they would use the special reserved âAS0â member in their ASPA signed object to communicate to the world that they have no upstream providers, only lateral peers and customers. Then, AS52320, the other provider of AS8048, would see routes from their customer with â6762â in the path and reject them by performing an ASPA verification process.&lt;/p&gt;
      &lt;p&gt;ASPA is based on RPKI and is exactly what would help prevent route leaks similar to the one we observed in Venezuela.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;A safer BGP, built togetherÂ &lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We felt it was important to offer an alternative explanation for the BGP route leak by AS8048 in Venezuela that was observed on Cloudflare Radar. It is helpful to understand that route leaks are an expected side effect of BGP historically being based entirely on trust and carefully-executed business relationship-driven intent.Â &lt;/p&gt;
      &lt;p&gt;While route leaks could be done with malicious intent, the data suggests this event may have been an accident caused by a lack of routing export and import policies that would prevent it. This is why to have a safer BGP and Internet we need to work together and drive adoption of RPKI-based ASPA, for which RIPE recently released object creation, on the wide Internet. It will be a collaborative effort, just like RPKI has been for origin validation, but it will be worth it and prevent BGP incidents such as the one in Venezuela.Â &lt;/p&gt;
      &lt;p&gt;In addition to ASPA, we can all implement simpler mechanisms such as Peerlock and Peerlock-lite as operators, which sanity-checks received paths for obvious leaks. One especially promising initiative is the adoption of RFC9234, which should be used in addition to ASPA for preventing route leaks with the establishing of BGP roles and a new Only-To-Customer (OTC) attribute. If you havenât already asked your routing vendors for an implementation of RFC9234 to be on their roadmap: please do. You can help make a big difference.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46538001</guid><pubDate>Thu, 08 Jan 2026 06:46:26 +0000</pubDate></item><item><title>Mothers (YC X26) Is Hiring</title><link>https://jobs.ashbyhq.com/9-mothers</link><description>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46540078</guid><pubDate>Thu, 08 Jan 2026 12:00:35 +0000</pubDate></item><item><title>The Jeff Dean Facts</title><link>https://github.com/LRitzdorf/TheJeffDeanFacts</link><description>&lt;doc fingerprint="39dc122727d67502"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 4&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A consolidated list of the Jeff Dean Facts!&lt;/p&gt;
    &lt;head rend="h3"&gt;License&lt;/head&gt;
    &lt;head rend="h1"&gt;LRitzdorf/TheJeffDeanFacts&lt;/head&gt;
    &lt;head rend="h2"&gt;About&lt;/head&gt;
    &lt;p&gt;A consolidated list of the Jeff Dean Facts!&lt;/p&gt;
    &lt;head rend="h3"&gt;Topics&lt;/head&gt;
    &lt;head rend="h3"&gt;Resources&lt;/head&gt;
    &lt;head rend="h3"&gt;License&lt;/head&gt;
    &lt;head rend="h3"&gt;Stars&lt;/head&gt;
    &lt;head rend="h3"&gt;Watchers&lt;/head&gt;
    &lt;head rend="h3"&gt;Forks&lt;/head&gt;
    &lt;head rend="h2"&gt;Releases&lt;/head&gt;
    &lt;p&gt;No releases published&lt;/p&gt;
    &lt;head rend="h2"&gt;Packages 0&lt;/head&gt;
    &lt;p&gt; No packages published &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46540498</guid><pubDate>Thu, 08 Jan 2026 13:02:05 +0000</pubDate></item><item><title>Show HN: DeepDream for Video with Temporal Consistency</title><link>https://github.com/jeremicna/deepdream-video-pytorch</link><description>&lt;doc fingerprint="3f194f592fcd7ab8"&gt;
  &lt;main&gt;
    &lt;p&gt;This is a fork of neural-dream, a PyTorch implementation of DeepDream. This fork introduces optical flow estimation and occlusion masking to apply DeepDream to videos with temporal consistency.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Standard DeepDream: The original single-image implementation.&lt;/item&gt;
      &lt;item&gt;Video DeepDream: New CLI (&lt;code&gt;video_dream.py&lt;/code&gt;) that uses RAFT Optical Flow to warp previous dream frames into the current frame, ensuring smooth transitions and object tracking.&lt;/item&gt;
      &lt;item&gt;Occlusion Masking: Automatically detects when objects move in front of one another to prevent "ghosting" artifacts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head class="px-3 py-2"&gt;mallard_demo.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;highway_demo.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;mallard_independent_demo.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;highway_independent_demo.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;mallard.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;highway.mp4&lt;/head&gt;
    &lt;p&gt;This project requires the following key packages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PyTorch&lt;/item&gt;
      &lt;item&gt;torchvision&lt;/item&gt;
      &lt;item&gt;OpenCV&lt;/item&gt;
      &lt;item&gt;NumPy&lt;/item&gt;
      &lt;item&gt;Pillow&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Install Dependencies:&lt;/p&gt;
    &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;
    &lt;p&gt;Download Models: Run the download script to fetch the standard Inception/GoogLeNet models:&lt;/p&gt;
    &lt;code&gt;python models/download_models.py&lt;/code&gt;
    &lt;p&gt;To download all compatible models:&lt;/p&gt;
    &lt;code&gt;python models/download_models.py -models all-caffe-googlenet&lt;/code&gt;
    &lt;p&gt;To dream on a video, use the &lt;code&gt;video_dream.py&lt;/code&gt; script. This wrapper accepts specific video arguments and any argument accepted by the standard image dreamer (e.g., layers, octaves, iterations).&lt;/p&gt;
    &lt;p&gt;Basic Video Command:&lt;/p&gt;
    &lt;code&gt;python video_dream.py -content_video input.mp4 -output_video output.mp4 -num_iterations 1&lt;/code&gt;
    &lt;p&gt;Note: For video processing, we recommend using &lt;code&gt;-num_iterations 1&lt;/code&gt;. The temporal consistency from optical flow means each frame builds on the previous dream, so fewer iterations per frame are needed compared to single images.&lt;/p&gt;
    &lt;p&gt;Video-Specific Arguments:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Argument&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-content_video&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;input.mp4&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to the source video file.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-output_video&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;output.mp4&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path where the final video will be saved.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-blend&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0.5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;(0.0 - 1.0): Mix ratio between the raw video frame and the warped previous dream. Higher values (closer to 1.0) use more of the raw frame; lower values (closer to 0.0) preserve more of the previous hallucinations.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-independent&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;False&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Flag: If set, disables temporal consistency (Optical Flow). Every frame is dreamed on independently (causes flickering).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-update_interval&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Updates the output video file on disk every N frames (allows you to preview progress while running).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-temp_dir&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;temp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Directory to store extracted frames, flow data, and masks during processing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;-keep_temp&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;False&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Flag: If set, the temporary directory is not deleted after processing finishes.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;-verbose&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;False&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Flag: Enable detailed logs (prints DeepDream iteration logs for every frame).&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All of the following arguments are from the single frame implementation, and you can mix and match any of these with the video-specific arguments above. Refer to neural-dream for more information on single frame parameters.&lt;/p&gt;
    &lt;p&gt;Example combining video and standard args:&lt;/p&gt;
    &lt;code&gt;python video_dream.py -content_video test.mp4 -dream_layers inception_4d -num_iterations 1 -octave_scale 0.7 -image_size 512&lt;/code&gt;
    &lt;p&gt;For single image processing only:&lt;/p&gt;
    &lt;code&gt;python neural_dream.py -content_image &amp;lt;image.jpg&amp;gt; -dream_layers inception_4c -num_iterations 10&lt;/code&gt;
    &lt;p&gt;Note: Paths to images should not contain the &lt;code&gt;~&lt;/code&gt; character; use relative or absolute paths.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-image_size&lt;/code&gt;: Maximum side length (in pixels) of the generated image. Default is 512.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-gpu&lt;/code&gt;: Zero-indexed ID of the GPU to use; for CPU mode set&lt;code&gt;-gpu&lt;/code&gt;to&lt;code&gt;c&lt;/code&gt;; for MPS mode (Apple Silicon) set&lt;code&gt;-gpu&lt;/code&gt;to&lt;code&gt;mps&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-dream_weight&lt;/code&gt;: How much to weight DeepDream. Default is&lt;code&gt;1e3&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-tv_weight&lt;/code&gt;: Weight of total-variation (TV) regularization; helps smooth the image. Default&lt;code&gt;0&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-l2_weight&lt;/code&gt;: Weight of latent state regularization. Default&lt;code&gt;0&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-num_iterations&lt;/code&gt;: Number of iterations. Default is&lt;code&gt;10&lt;/code&gt;. For video, use&lt;code&gt;1&lt;/code&gt;(temporal consistency reduces the need for multiple iterations per frame).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-init&lt;/code&gt;: Initialization method:&lt;code&gt;image&lt;/code&gt;(content image) or&lt;code&gt;random&lt;/code&gt;(noise). Default&lt;code&gt;image&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-jitter&lt;/code&gt;: Apply jitter to image. Default&lt;code&gt;32&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-layer_sigma&lt;/code&gt;: Apply gaussian blur to image. Default&lt;code&gt;0&lt;/code&gt;(disabled).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-optimizer&lt;/code&gt;:&lt;code&gt;lbfgs&lt;/code&gt;or&lt;code&gt;adam&lt;/code&gt;. Default&lt;code&gt;adam&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-learning_rate&lt;/code&gt;: Learning rate (step size). Default&lt;code&gt;1.5&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-normalize_weights&lt;/code&gt;: Divide dream weights by the number of channels.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-loss_mode&lt;/code&gt;: Loss mode:&lt;code&gt;bce&lt;/code&gt;,&lt;code&gt;mse&lt;/code&gt;,&lt;code&gt;mean&lt;/code&gt;,&lt;code&gt;norm&lt;/code&gt;, or&lt;code&gt;l2&lt;/code&gt;. Default&lt;code&gt;l2&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-output_image&lt;/code&gt;: Name of the output image. Default&lt;code&gt;out.png&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-output_start_num&lt;/code&gt;: Number to start output image names at. Default&lt;code&gt;1&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-print_iter&lt;/code&gt;: Print progress every N iterations.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-save_iter&lt;/code&gt;: Save image every N iterations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-dream_layers&lt;/code&gt;: Comma-separated list of layer names to use.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-channels&lt;/code&gt;: Comma-separated list of channels to use.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-channel_mode&lt;/code&gt;: Selection mode:&lt;code&gt;all&lt;/code&gt;,&lt;code&gt;strong&lt;/code&gt;,&lt;code&gt;avg&lt;/code&gt;,&lt;code&gt;weak&lt;/code&gt;, or&lt;code&gt;ignore&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-channel_capture&lt;/code&gt;:&lt;code&gt;once&lt;/code&gt;or&lt;code&gt;octave_iter&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-num_octaves&lt;/code&gt;: Number of octaves per iteration. Default&lt;code&gt;4&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-octave_scale&lt;/code&gt;: Resize value. Default&lt;code&gt;0.6&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-octave_iter&lt;/code&gt;: Iterations (steps) per octave. Default&lt;code&gt;50&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-octave_mode&lt;/code&gt;:&lt;code&gt;normal&lt;/code&gt;,&lt;code&gt;advanced&lt;/code&gt;,&lt;code&gt;manual_max&lt;/code&gt;,&lt;code&gt;manual_min&lt;/code&gt;, or&lt;code&gt;manual&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-lap_scale&lt;/code&gt;: Number of layers in laplacian pyramid. Default&lt;code&gt;0&lt;/code&gt;(disabled).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-sigma&lt;/code&gt;: Strength of gaussian blur in pyramids. Default&lt;code&gt;1&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-zoom&lt;/code&gt;: Amount to zoom in.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-zoom_mode&lt;/code&gt;:&lt;code&gt;percentage&lt;/code&gt;or&lt;code&gt;pixel&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-tile_size&lt;/code&gt;: Desired tile size. Default&lt;code&gt;0&lt;/code&gt;(disabled).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-overlap_percent&lt;/code&gt;: Percentage of overlap for tiles. Default&lt;code&gt;50&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-original_colors&lt;/code&gt;: Set to&lt;code&gt;1&lt;/code&gt;to keep content image colors.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-model_file&lt;/code&gt;: Path to&lt;code&gt;.pth&lt;/code&gt;file. Default is VGG-19.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-model_type&lt;/code&gt;:&lt;code&gt;caffe&lt;/code&gt;,&lt;code&gt;pytorch&lt;/code&gt;,&lt;code&gt;keras&lt;/code&gt;, or&lt;code&gt;auto&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-backend&lt;/code&gt;:&lt;code&gt;nn&lt;/code&gt;,&lt;code&gt;cudnn&lt;/code&gt;,&lt;code&gt;openmp&lt;/code&gt;, or&lt;code&gt;mkl&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-cudnn_autotune&lt;/code&gt;: Use built-in cuDNN autotuner (slower start, faster run).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Problem: The program runs out of memory (OOM) Solution:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Reduce &lt;code&gt;-image_size&lt;/code&gt;(e.g., to 512 or 256).&lt;/item&gt;
      &lt;item&gt;If using GPU, use &lt;code&gt;-backend cudnn&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;For video: Reduce the input video resolution before processing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Problem: Video processing is very slow Solution: Video DeepDreaming is computationally expensive. It runs the full DeepDream process per frame, plus Optical Flow calculations.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use &lt;code&gt;-num_iterations 1&lt;/code&gt;(recommended for video; temporal consistency means fewer iterations are needed).&lt;/item&gt;
      &lt;item&gt;Reduce &lt;code&gt;-octave_iter&lt;/code&gt;(e.g., to 10 or 20).&lt;/item&gt;
      &lt;item&gt;Use a smaller &lt;code&gt;-image_size&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By default, &lt;code&gt;neural-dream&lt;/code&gt; uses the &lt;code&gt;nn&lt;/code&gt; backend.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use cuDNN: &lt;code&gt;-backend cudnn&lt;/code&gt;(GPU only, reduces memory).&lt;/item&gt;
      &lt;item&gt;Reduce Size: &lt;code&gt;-image_size 256&lt;/code&gt;(Halves memory usage).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With default settings, standard execution uses ~1.3 GB GPU memory.&lt;/p&gt;
    &lt;p&gt;You can use multiple devices with &lt;code&gt;-gpu&lt;/code&gt; and &lt;code&gt;-multidevice_strategy&lt;/code&gt;.
Example: &lt;code&gt;-gpu 0,1,2,3 -multidevice_strategy 3,6,12&lt;/code&gt; splits layers across 4 GPUs. See ProGamerGov/neural-dream for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46540660</guid><pubDate>Thu, 08 Jan 2026 13:21:59 +0000</pubDate></item><item><title>Maine company in the spotlight after Maduro apparently wore one of their hoodies</title><link>https://www.boston.com/news/business/2026/01/06/maine-company-maduro-venezuela-hoodie/</link><description>&lt;doc fingerprint="26791b55a0c12eff"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Sign up for the Today newsletter&lt;/head&gt;&lt;p&gt;Get everything you need to know to start your day, delivered right to your inbox every morning.&lt;/p&gt;&lt;p&gt;By Abby Patkin&lt;/p&gt;&lt;p&gt;The CEO of a Maine apparel company said his phone “blew up” after deposed Venezuelan leader Nicolás Maduro was apparently photographed wearing one of their hoodies upon arriving in New York over the weekend.&lt;/p&gt;&lt;p&gt;The U.S. captured Maduro, Venezuela’s president, and his wife in a staggering nighttime military operation Saturday, charging the ousted leader with drug and weapons offenses. Before long, social media was flush with images that appeared to show Maduro wearing an ORIGIN hoodie in the shade “Patriot Blue,” surrounded by Drug Enforcement Administration agents.&lt;/p&gt;&lt;p&gt;In one photo, Maduro appears to be giving the camera a double thumbs up.&lt;/p&gt;&lt;p&gt;“I had to start putting the pieces together: Why is this dude wearing an Origin Patriot Blue hoodie?” Pete Roberts, the company’s founder and CEO, said in a video Sunday. “And the irony in this is that this wave, this logo here on the shirt Maduro is wearing, this is the ‘Wave of Freedom.’”&lt;/p&gt;&lt;p&gt;Farmington-based ORIGIN began as a way to help revitalize a struggling New England manufacturing community, he explained, and its “Wave of Freedom” logo represents a commitment to building back.&lt;/p&gt;&lt;p&gt;Roberts also offered his theory on how Maduro came to be wearing a hoodie made by a smaller brand from Maine.&lt;/p&gt;&lt;p&gt;“Probably a DEA agent slipped this hoodie on him and said, ‘You’re going to feel the fabric of freedom on American soil,’” he quipped. “That’s my assumption, and I’m taking the liberty to assume.”&lt;/p&gt;&lt;p&gt;Writing on Facebook, ORIGIN co-founder and retired Navy SEAL Jocko Willink further noted the brand has supporters “in every branch of service and every agency of the government.”&lt;/p&gt;&lt;p&gt;According to ORIGIN’s product description, the hoodie offers a “triple chill effect” to wick away moisture and cool athletes down — an element Roberts said he found “really curious and interesting,” given the chilly weather in New York.&lt;/p&gt;&lt;p&gt;“So maybe they wanted him to feel comfortable or a little uncomfortable. I’m not quite sure,” Roberts said. “But he definitely gave two thumbs up, so I think he liked the fabric.”&lt;/p&gt;&lt;p&gt;Still, he told News Center Maine ORIGIN isn’t looking to politicize the Maduro photo op and is “just trying to use it for brand awareness and to get people back into our store.”&lt;/p&gt;&lt;p&gt;The brand’s website traffic jumped about 300% Sunday, and sales were up roughly 200%, Roberts told the news outlet.&lt;/p&gt;&lt;p&gt;“It would be really hard for a company out of Maine to get, let’s call it, a billion eyes on our brand,” he said. “And so, that’s a real positive as a brand, as a movement. We would never have been able to create that.”&lt;/p&gt;&lt;p&gt;Abby Patkin is a general assignment news reporter whose work touches on public transit, crime, health, and everything in between.&lt;/p&gt;&lt;p&gt;Get everything you need to know to start your day, delivered right to your inbox every morning.&lt;/p&gt;&lt;p&gt;Be civil. Be kind.&lt;/p&gt;Read our full community guidelines.&lt;p&gt;Stay up to date with everything Boston. Receive the latest news and breaking updates, straight from our newsroom to your inbox.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46541586</guid><pubDate>Thu, 08 Jan 2026 14:44:24 +0000</pubDate></item><item><title>Bose is open-sourcing its old smart speakers instead of bricking them</title><link>https://www.theverge.com/news/858501/bose-soundtouch-smart-speakers-open-source</link><description>&lt;doc fingerprint="f3603ffac3a2a06c"&gt;
  &lt;main&gt;
    &lt;p&gt;In a surprisingly user-friendly move, Bose has announced it will be open-sourcing the API documentation for its SoundTouch smart speakers, which were slated to lose official support on February 18th, as reported by Ars Technica. Bose has also moved that date back to May 6th, 2026.&lt;/p&gt;
    &lt;head rend="h1"&gt;Bose is open-sourcing its old smart speakers instead of bricking them&lt;/head&gt;
    &lt;p&gt;SoundTouch speakers could now have a second life, and won’t lose support until May.&lt;/p&gt;
    &lt;p&gt;SoundTouch speakers could now have a second life, and won’t lose support until May.&lt;/p&gt;
    &lt;p&gt;When cloud support ends, an update to the SoundTouch app will add local controls to retain as much functionality as possible without cloud services. Users will still be able to stream music to SoundTouch speakers with Bluetooth, AirPlay, and Spotify Connect (plus physical AUX connections). Remote control features and grouping speakers will also continue to work, and users will still be able to set up and configure their SoundTouch speakers.&lt;/p&gt;
    &lt;p&gt;Now that the smart speakers’ API is being open-sourced, users can also create their own compatible SoundTouch tools to help fill in any gaps left by the lack of cloud services. While it’s still disappointing that the speakers are losing official support, Bose’s approach at least lets people continue using their speakers, rather than bricking otherwise functional devices.&lt;/p&gt;
    &lt;p&gt;This move from Bose is particularly surprising because of how rare it is. Usually when products lose support for cloud services, they end up bricked, and occasionally users step in themselves to fix things. For instance, when Pebble originally shut down in 2016, users kept their watches functional by creating the Rebble Alliance, a community-run replacement for the watches’ cloud services, firmware, and app store.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46541892</guid><pubDate>Thu, 08 Jan 2026 15:07:57 +0000</pubDate></item><item><title>Suppression of Type I collagen in human scleral fibroblasts treated with ELF</title><link>https://pmc.ncbi.nlm.nih.gov/articles/PMC3626379/</link><description>&lt;doc fingerprint="157c99b280a422cf"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;head rend="h3"&gt;Purpose&lt;/head&gt;
    &lt;p&gt;To investigate the expression differences of type I collagen (COL1A1) and its underlying mechanisms in human fetal scleral fibroblasts (HFSFs) that were treated with conditioned medium from retinal pigment epithelial (RPE) cells under extremely low-frequency electromagnetic fields (ELF-EMFs).&lt;/p&gt;
    &lt;head rend="h3"&gt;Methods&lt;/head&gt;
    &lt;p&gt;The ELF-EMFs used in this study were established by slidac and artificial coils. Growth of the treated HFSFs was evaluated by a cell-counting kit-8 assay. The expression of COL1A1 and matrix metalloproteinases-2 (MMP-2) in the treated HFSFs was detected by reverse transcription PCR (RT-PCR) and western blot, and the expression of transforming growth factor-β2 (TGF-β2) and basic fibroblast growth factor-2 (FGF-2) in RPE cells exposed to EMFs was detected by RT-PCR. The expression of COL1A1 and MMP-2 in HFSFs was further confirmed by immunofluorescence staining. Activation of extracellular signal-regulated kinase 1/2 (ERK1/2 also called p44/p42 mitogen-activated protein kinases [MAPK]) and p38 in HFSFs was measured by western blot.&lt;/p&gt;
    &lt;head rend="h3"&gt;Results&lt;/head&gt;
    &lt;p&gt;We found that exposure to ELF-EMFs resulted in a decreased proliferation rate of HFSFs and that addition of RPE supernatant medium could enhance this effect. Compared with that of the control cells, a significant decrease in collagen synthesis was detected in HFSFs under ELF-EMFs. However, the expression of MMP-2 was upregulated, which could be further enhanced via an RPE supernatant additive. The activities of ERK1/2 and p38 were significantly increased in HFSFs exposed to ELF-EMFs, and this effect could be enhanced by RPE supernatant medium additive.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;Our results suggested that ELF-EMFs can inhibit the expression of type I collagen in HFSFs and contribute to the remodeling of the sclera.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Side effects of extremely low-frequency electromagnetic fields (ELF-EMFs) on public health, especially on ocular health, have recently attracted more attention than they have received in the past. Morphological alteration of the conjunctiva and reductions in the number of goblet cells could result from 50 Hz ELF-EMFs at 1.5 mT [1]. Several studies have also demonstrated that there are relationships between electromagnetic radiation (EMR) and cataract [2,3], corneal [3,4], retinal damage [4]. However, little is known about the biologic function of scleral changes exposed to ELF-EMFs.&lt;/p&gt;
    &lt;p&gt;The human sclera is composed mainly of type I collagen fibrils (50% to 70%), which mostly distribute among the equator and posterior pole region of the eyeball [5]. Scleral thinning involves a net loss of matrix, smaller diameter collagen fibrils in the sclera, a net loss of scleral tissue through reduced collagen synthesis, and increased degradation [6,7]. Scleral fibroblasts, which reside between the collagen fiber and bundle lamellae, could monitor changes of the surrounding extracellular matrix [8,9]. The proliferation of scleral fibroblasts changes with the decrease in proteoglycan synthesis, which could affect the biomechanics of sclera and induce elongation of the eye [10]. The remodeling of sclera and the extension of axial length could induce refractive errors, retinal degeneration, and/or detachment [11,12]. In our preliminary experiments, we found that ELF-EMFs could lengthen the axial length of guinea pig’s eyes and induce a structure disorder of collagen fibrils in guinea pig scleral. Information on the biologic effects of ELF-EMFs on scleral fibroblasts, therefore, is of interest and has never been investigated.&lt;/p&gt;
    &lt;p&gt;It is well known that the retina is the source of ocular growth-regulating signals and that retinal pigment epithelial (RPE) cells are intimately involved in eye growth regulation [13]. Increasing evidence has shown that the retina could synthesize and secrete cytokines and enzymes (such as transforming growth factor-β [TGF-β] and basic fibroblast growth factor [bFGF]) to regulate the remodeling of sclera [14-17]. However, no report has addressed the biologic function of human fetal scleral fibroblasts (HFSFs) exposed to ELF-EMFs or HFSFs treated with RPE supernatant medium.&lt;/p&gt;
    &lt;p&gt;Matrix metalloproteinases (MMPs) are secreted by different kinds of cells, such as fibroblasts and inflammatory cells [18]. MMPs can degrade one or several components of extraceellular matrix (ECM) and promote ECM remodeling [19]. It is well recognized that high expression of MMP-2 could lead to collagen degradation [20], which plays a crucial role in the regulation of scleral pathological remodeling [21]. The MMP-2 gene was found to be involved in human refractive variation [22] and participated in altering the extracellular matrix in the posterior sclera [23]. An elevated level of active MMP-2 expression has been detected in induced tree shrews with myopia [24]. Moreover, MMP-2 might be involved in tissue remodeling through activating extracellular signal-regulated kinase 1/2 (ERK1/2, also called p44/p42 mitogen-activated protein kinase [MAPK]) and p38 MAPK [25,26]. EMF exposure could activate multiple downstream signaling pathways, such as ERK signaling [27]. We speculated that ELF-EMFs might upregulate MMP-2 expression and activity by activating ERK1/2 and p38 MAPK signal molecules.&lt;/p&gt;
    &lt;p&gt;In this study we used an EMF with 0.2 mT intensity, which is the upper safety limit for public exposure to non-ionizing radiation in the guidelines of the International Commission on Non-Ionizing Radiation Protection [28]. Our objective was to detect the effect of ELF-EMFs on sclera by evaluating their influence on proliferation and content of type I collagen in cultures of HFSFs. We then investigated the effect of ELF-EMF exposure with and without RPE supernatant additive on the biologic function of HFSFs and explored the underlying mechanisms of RPE supernatant influence on HFSFs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methods&lt;/head&gt;
    &lt;head rend="h3"&gt;Cell culture&lt;/head&gt;
    &lt;p&gt;HFSFs were obtained from Beijing Institute of Ophthalmology (Beijing, China), and RPE cells (ARPE19) were obtained from the American Type Culture Collection. HFSFs and RPE cells were cultured in Dulbecco’s modified Eagle’s medium (DMEM, Gibco, Carlsbad, CA) with 1% antibiotic/antimycotic (penicillin–streptomycin; Invitrogen) and 10% fetal bovine serum (FBS; Gibco), and incubated at 37 °C in a humidified incubator containing 5% CO2. The growth medium was changed every 3 days. When the cultures began to reach 80% confluence, cells were trypsinized for 1 min at 37 °C in 0.25% trypsin/EDTA, and then subcultured at a split ratio of 1:3 in 25-mm2 plastic bottles.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exposure system and Experiment design&lt;/head&gt;
    &lt;p&gt;ELF-EMFs were generated in a device constructed by winding 150 turns of insulated soft copper wire with a diameter of 1.5 mm. Coils were placed vertically, facing one another (Figure 1). The magnetic flux density at the center of the coils was measured with an electromagnetic field radiation tester (EMF-827; Taiwan, China) and was adjusted by varying the coil current. Magnetic field measurements showed that under experimental conditionals, the magnetic field exposure system produced a stable flux density of 0.2 mT and a stable frequency of 50 Hz, with negligible vibration. Temperature was continuously monitored by Therm 2283–2 thermometers (Taylor Precision Instruments, Oak Brook, IL). None of the experimental conditions produced any measureable temperature increase in the cell culture medium. The exposure system was put in a humidified incubator at 37 °C, which contained 5% CO2. Exposed cells were placed inside the coils with a sinusoidal 50 Hz electromagnetic field at 0.2 mT for 24 h. Control cells (not exposed to ELF-EMFs) were cultured in another incubator without power coils.&lt;/p&gt;
    &lt;p&gt;RPE cells (5×105 cells cultured in 25-mm2 plastic bottles) cultured with DMEM without FBS were exposed to ELF-EMFs (0.2 mT) for 24 h. The supernatant medium of RPE was then collected and condensed by an ultra filter device (Millipore, Billerica, MA) by spinning the device at 4,000 × g for 25 min. The ultrafiltrate protein concentration was measured using the Bradford Protein Assay kit (Beyotime, Shanghai, China).&lt;/p&gt;
    &lt;head rend="h3"&gt;Cell proliferation assay&lt;/head&gt;
    &lt;p&gt;The proliferation rate of HFSFs treated with or without RPE supernatant medium while exposed to ELF-EMFs was evaluated with the cell counting kit-8 assay (Dojin Laboratories, Kumamoto, Japan). For the cell proliferation assay, 100 μl of passage HFSFs (2,000, 4,000, 6,000, 8,000, and 10,000 cells/well) were seeded into 96-well plates containing DMEM with 10% FBS. Cells were allowed to attach to the substratum for 12 h. The following day, the medium was replaced with fresh medium and the cells exposed to ELF-EMFs (0.2 mT, 50 Hz) were cultured in different humidified incubators (37 °C, containing 5% CO2) for 24 h. Control cultures were kept in the same conditions as the exposed ones without field application. In a separate 96-well plate, HFSFs were seeded at an initial density of 6,000 cells/well at various concentrations of RPE supernatant (0.0075, 0.015, 0.03, 0.06, and 0.12 mg/ml) or the control condensed medium. The cultures were exposed to ELF-EMFs (0.2 mT, 50 Hz) at 37 °C with 5% CO2 for 24 h. Control cultures were kept in the same conditions as the exposed ones without field application.The solution of 2-(2-methoxy-4-nitrophenyl)-3-(4-nitrophenyl)-5- (2,4-disulfophenyl)-2H-tetrazolium and 1-methoxyphenazine methosulfate (Dojindo, Japan) was then added to each well, and cells were incubated for another 2 h. Finally absorbance was measured at 450 nm using a microplate reader.&lt;/p&gt;
    &lt;head rend="h3"&gt;Indirect immunofluorescence&lt;/head&gt;
    &lt;p&gt;Fibroblasts (1×105 cells) were grown on coverslips in six-well plates (Corning Ltd) to 50%–60% confluence. The cells were exposed to ELF-EMFs (50 Hz, 0.2 mT) produced by the coils and treated with RPE supernatant medium (0.015 mg/ml) for 24 h. Then, the cells were then washed three times with phosphate buffered saline (0.01 M PBS: KH2PO4, 0.20 g; Na2HPO4, 1.56 g; NaCl, 8.0 g; KCl 0.20 g), covered with 10% normal goat serum diluted in PBS, and incubated for 20 min at 37 °C. The slides were incubated at 4 °C overnight with primary antibodies (anti-collagen type I diluted to 1:500 in PBS, anti-MMP-2 diluted to 1:100 in PBS; Abcam, Cambridge, UK). Cells incubated in PBS without primary antibodies were used as a negative control group. The antibody-treated and negative-controlled sample slides were washed with PBS and exposed to DyLight 488-conjugated anti-mouse immunoglobulin G (IgG) antibodies (Invitrogen Corp, Carlsbad, CA) at 37 °C for 60 min. The slides were washed three times with PBS, and cell nuclei were stained with 4', 6-diamidino-2-phenylindole (Invitrogen). Immunofluorescence images were taken using an inverted fluorescent microscope (Leica, Wetzlar, Germany).&lt;/p&gt;
    &lt;head rend="h3"&gt;Quantitative real-time PCR analysis&lt;/head&gt;
    &lt;p&gt;HFSFs and RPE cells were seeded in 25-mm2 plastic bottles at 5×105 cells and cultured for 12 h. HFSFs cultures treated with RPE supernatant medium (0.015 mg/ml) were exposed to ELF-EMFs (50 Hz, 0.2 mT) produced by the coils. After exposure for 24 h, cells were harvested for total RNA extraction by using Trizol Reagent (Invitrogen). cDNAs were synthesized with 4 µg of total RNA, according to the manufacturer’s protocol for the Reverse Transcription kit (Fermentas, Japan). Based on the sequences reported in the GenBank database (Table 1), COL1A1, MMP-2, TGF-β2, FGF-2, and glyceraldehyde-3-phosphate dehydrogenase (GAPDH) primers were designed, selected, and ordered using Primer-Premier 5 (Premier Biosoft Interpairs, Palo Alto, CA), BLAST, and Sangon (China), respectively. Quantitative real-time PCR was performed with an ABI7500 Fast Real-Time PCR System (Applied Biosystems, Foster City, CA). A typical reaction was performed in 25 µl, consisting of 2 µl cDNA, 12.5 µl 2X SYBR Green PCR buffer, and primer pairs (final 10 pmol each). The PCR temperature cycle was performed for 2 min at 95.0 °C, followed by 40 cycles with primer annealing for 30 s at the temperatures indicated in Table 1, and extension for 30 s at 72.0 °C. The change in threshold cycle (∆CT) was calculated by subtracting the average CT of GAPDH mRNA from the average CT of the target genes. All experiments were performed in triplicate. The comparative quantification values were obtained from the CT number at which the increase in signal was associated with an exponential growth of PCR products.&lt;/p&gt;
    &lt;head rend="h4"&gt;Table 1. Accession number of genes in the nucleotide sequence database (NCBI), sequences of used primer pairs and temperatures.&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Gene&lt;/cell&gt;
        &lt;cell role="head"&gt;Primer sequences&lt;/cell&gt;
        &lt;cell role="head"&gt;GenBank numbers&lt;/cell&gt;
        &lt;cell role="head"&gt;Tm(°C)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt; COL1A1&lt;/cell&gt;
        &lt;cell&gt;F: 5′ GTGTTGTGCGATGACG 3′&lt;/cell&gt;
        &lt;cell&gt;R: 5′ TCGGTGGGTGACTCTG 3′&lt;/cell&gt;
        &lt;cell&gt; NM_000088.3&lt;/cell&gt;
        &lt;cell&gt;57&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt; MMP-2&lt;/cell&gt;
        &lt;cell&gt;F: 5′ GGAAAAGATTGATGCG 3′&lt;/cell&gt;
        &lt;cell&gt;R: 5′ GGTGCTGGCTGAGTAG 3′&lt;/cell&gt;
        &lt;cell&gt; NM_004530.4&lt;/cell&gt;
        &lt;cell&gt;59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt; TGFβ2&lt;/cell&gt;
        &lt;cell&gt;F: 5′ ATCTGGTCACGGTCGC 3′&lt;/cell&gt;
        &lt;cell&gt;R: 5′ GTCCCTGGTGCTGTTG 3′&lt;/cell&gt;
        &lt;cell&gt; NM_003238.2&lt;/cell&gt;
        &lt;cell&gt;58&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt; FGF-2&lt;/cell&gt;
        &lt;cell&gt;F: 5′ CGTTACCTGGCTATGA 3′&lt;/cell&gt;
        &lt;cell&gt;R: 5′ CAACTGGTGTATTTCCT 3′&lt;/cell&gt;
        &lt;cell&gt; NM_002006.4&lt;/cell&gt;
        &lt;cell&gt;53&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GAPDH&lt;/cell&gt;
        &lt;cell&gt;F: 5′ CTCCTCCACCTTTGACGC 3′&lt;/cell&gt;
        &lt;cell&gt;R: 5′ CCACCACCCTGTTGCTGT 3′&lt;/cell&gt;
        &lt;cell&gt;NM_002046.3&lt;/cell&gt;
        &lt;cell&gt;60&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Western blot analysis&lt;/head&gt;
    &lt;p&gt;After exposure to ELF-EMFs (50 Hz, 0.2 mT) and treatment with or without RPE supernatant medium (0.015 mg/ml) or not, total cellular protein extract from HFSFs was obtained by lysing the cells in an ice-cold radioimmunoprecipitation assay buffer containing proteinase inhibitors (50 mM Tris–HCl, pH 8.0; 150 mM NaCl; 1% NP-40; 4 °C) and phosphatase inhibitors (R&amp;amp;D Systems). After centrifugation at 12,000 × g (30 min; 4 °C), the supernatants were collected and protein concentration measured using the bicinchoninic acid (BCA) Protein Assay kit (Beyotime). Samples containing 50 µg of protein were subjected to sodium dodecyl sulfate polyacrylamide gel electrophoresis (SDS-PAGE) polyacrylamide gel electrophoresis, using 10% and 12% polyacrylamide gel (30% acrylamide-bisacrylamide; 1.5 M Tris–HCl, pH 8.8; 10% SDS; 10% ammonium persulfate; TEMED), and then transferred onto polyvinylidene difluoride membranes (Bio-Rad Laboratories, Hercules, CA). The membrane was blocked in 5% Tris buffered saline (10 mM Tris-HCl, pH 8.0; 150 mM NaCl; 0.5% Tween-20; 5% fat-free dry milk) for 1 h at room temperature. It was then probed overnight at 4 °C with speciﬁc primary antibodies against collagen type I (1:5,000; Abcam), MMP-2 (1:1,000; Abcam), phosphor-ERK1/2, phosphor-p38, ERK1/2, p38, and β-actin (1:1,000; Cell Signaling Technology) and incubated in blocking buffer with ß-actin as an internal control. Immunoblots were then washed and incubated with a horseradish peroxidase (HRP)-conjugated anti-rabbit goat IgG HRP (1:1,000; Abmart, Shanghai, China). Membranes were developed with the ECL kit (Pierce, Thermo Scientific), according to the manufacturer’s protocol, acquired with a ChemiDoc XR system (Bio-Rad Laboratories). The relative level of protein expression was expressed as the density ratio of the protein compared to β-actin in the same sample.&lt;/p&gt;
    &lt;head rend="h3"&gt;Data analysis&lt;/head&gt;
    &lt;p&gt;Statistical analysis was performed with SPSS 16.0 Statistical Software (SPSS, Inc., Chicago, IL). Data were expressed as the mean±standard deviation (SD) of at least three separate repeated experiments. The differences between exposed and untreated cells were tested using one-way analysis of variance or Dunnett’s test. Statistical significance was accepted if p&amp;lt;0.05.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;head rend="h3"&gt;Changes in HFSFs proliferation&lt;/head&gt;
    &lt;p&gt;There was a significant reduction in the proliferation rate of HFSF cells exposed to ELF-EMFs compared with control cultures (t=–3.26, p&amp;lt;0.05, Figure 2A). The inclusion of RPE supernatant medium resulted in a significantly reduced proliferation rate of HFSFs compared to that of the cells exposed to ELF-EMFs alone (t=–7.32, p&amp;lt;0.05, Figure 2B).&lt;/p&gt;
    &lt;head rend="h3"&gt;Electromagnetic fields and retinal cells can affect human scleral fibroblast cells COL1A1 and MMP-2 expression&lt;/head&gt;
    &lt;p&gt;ELF-EMF exposure could significantly reduce the mRNA expression of COL1A1 in HFSFs (t=–4.083, p=0.05). The effect was more obvious at the mRNA level of HFSFs exposed to ELF-EMFs with RPE supernatant additive (t=–4.987, p&amp;lt;0.01, Figure 3A). ELF-EMF exposure also could significantly reduce the protein expression of COL1A1 in HFSFs, but no significant difference was found for protein levels between the treated HFSFs with RPE supernatant medium (0.015 mg/ml) and the control cells exposed to ELF-EMFs (Figure 4). The mRNA level of MMP-2’s was upregulated in cells exposed to ELF-EMFs (t=3.919, p&amp;lt;0.05), and RPE supernatant medium additive could enhance the ELF-EMF effect on the expression of MMP-2 (t=8.828, p&amp;lt;0.05, Figure 3B). The increased MMP-2 protein level correlated with the increased mRNA level (Figure 4). The expression of COL1A1 and MMP-2 in HFSFs was further confirmed by immunofluorescence (Figure 5, Figure 6).&lt;/p&gt;
    &lt;head rend="h3"&gt;Electromagnetic fields can affect TGFβ2, FGF-2 mRNA expression in retinal pigment epitheliums&lt;/head&gt;
    &lt;p&gt;Relative TGF-β2 and FGF-2 mRNA levels were markedly changed in RPE cells after exposure to ELF-EMFs. Significantly increased TGF-β2 mRNA expression (t=4.45, p&amp;lt;0.05) and decreased FGF-2 mRNA expression (t=–5.81, p&amp;lt;0.05) were noted in RPE cells exposure to ELF-EMFs (Figure 3C).&lt;/p&gt;
    &lt;head rend="h3"&gt;COL1A1 and MMP-2 immunofluorescence staining changes after electromagnetic fields exposure&lt;/head&gt;
    &lt;p&gt;COL1A1 was confirmed to be expressed in the cytoplasm of HFSFs. After cells were exposed to ELF-EMFs (0.2 mT, 24 h), COL1A1 staining decreased. When cells were co-exposed to ELF-EMFs and RPE supernatant medium (0.015 mg/ml) additive, COL1A1 staining was much weaker (Figure 5). However, following exposure to ELF-EMFs, the expression of MMP-2 showed more marked fluorescent signals localized in the cytoplasm of treated cells than in that of untreated cells. When cells were co-exposed to ELF-EMFs and RPE supernatant medium (0.015 mg/ml), MMP-2 staining appeared stronger than exposure to ELF-EMFs alone (Figure 6).&lt;/p&gt;
    &lt;head rend="h3"&gt;Potential signal pathway of electromagnetic fields and retinal cells effects on human scleral fibroblast cells&lt;/head&gt;
    &lt;p&gt;Western blots showed that the expression of p-p38 and p-ERK1/2 protein levels were significantly increased (Figure 7) after cells were exposed to ELF-EMFs (0.2 mT, 24 h). The expression level was higher when exposed to ELF-EMFs with RPE supernatant medium (0.015 mg/ml) additive (Figure 7).&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;Collagen synthesis in keloid fibroblasts has been shown to be inhibited when exposed to EMFs with 60 Hz for 10 days [29]. Collagen synthesis could be decreased in guinea pig’s skin after exposure to 1 mT ELF-EMFs [30], and the expression of collagen I mRNA could be downregulated following EMF stimulation [31]. As an important component of sclera, type I collagen is involved in pathological scleral matrix remodeling. Our results demonstrated that exposure to ELF-EMFs downregulated mRNA and protein expression levels of COL1A1 in HFSFs. Moreover, under the same ELF-EMF exposure conditions, there was a significant difference in mRNA levels between cells treated with RPE supernatant medium and the control cells (Figure 3A, Figure 4A, Figure 5). These results indicate that ELF-EMFs can suppress collagen synthesis in the sclera and might induce sclera remodeling, which is a potential risk factor for the eye’s elongation.&lt;/p&gt;
    &lt;p&gt;MMPs could affect scleral ECM during scleral remodeling by inhibiting collagen type I synthesis [32]. In this study, we found that, compared with the control cells, both the protein and mRNA expression levels of MMP-2 were upregulated with exposure to ELF-EMFs, and MMP-2 expression was further enhanced with the inclusion of RPE supernatant medium (Figure 3B, Figure 4B, Figure 6). These data indicate that ELF-EMFs might act to enhance the initiation process of scleral remodeling by increasing the expression of MMP-2.&lt;/p&gt;
    &lt;p&gt;RPE cells can synthesize and secrete cytokines and enzymes to regulate the proliferation of scleral fibroblasts, regulate the production of collagen, and further affect the development of myopia [33]. We therefore detected the mRNA expression levels of TGF-β2 and FGF-2 in RPE cells and found the mRNA expression of TGF-β2 was enhanced but that of FGF-2 decreased after exposure to an EMF for 24 h. TGF-β could induce MMP production from fibroblasts by interfering with Smad and MAPK pathways in vitro [34]. TGF-β also plays an inhibitory role of human scleral fibroblasts attachment to collagen type I in vitro and modulates scleral cell–matrix interactions in vivo [35]. In this study, FGF-2 mRNA was decreased in RPE cells after 24 h of exposure to an EMF. These results suggest that ELF-EMFs may regulate sclera changes though regulating cytokines of RPE.&lt;/p&gt;
    &lt;p&gt;Scleral fibroblasts are involved in scleral remodeling and play an important role in maintaining eye size [8]. Our results showed that following exposure to electromagnetic field, HFSFs proliferation was significantly decreased, which implied that ELF-EMFs suppress collagen synthesis might be mediated by inhibit HFSFs proliferation, and retinal is the source of ocular growth-regulating signals [12]. Therefore, the decreased proliferation of HFSFs by EMFs might also via activate some signal pathways in RPE cells.&lt;/p&gt;
    &lt;p&gt;It has been reported that MAPKs can be activated in response to a variety of environmental stresses including radiation [36]. ERK1/2 and p38 MAPK play important roles in the collagen content exposed to ELF-EMFs [37]. Inactivation of the ERK1/2 MAPK signaling pathway can increase the expression of type I collagen in fibroblasts [38]. MAPKs can also regulate the expression of MMP-2; for example, MMP-2 can be stimulated by cyclic strain in endothelial cells in vitro, in part through both p38- and ERK-dependent pathways [39]. Inhibiting the activity of ERK could downregulate the expression of MMP-2 in fibroblasts [40]. Therefore, we tried to identify whether ELF-EMFs can regulate the content change of collagen through the MAPK pathway. We found that the collagen content decreased in HFSFs in almost all experiments (Figure 3A, Figure 4A, Figure 5). In contrast, increased expressions of ERK1/2 and p38 MAPK phosphorylation were detected when the cells were exposed to ELF-EMF and RPE supernatant medium. These results suggest that the suppression of collagen expression might be associated with the activation of the ERK1/2 and p38 MAPK pathways.&lt;/p&gt;
    &lt;p&gt;In conclusion, ELF-EMFs can regulate collagen synthesis in HFSFs by regulating the MAPK pathways and can contribute to scleral remodeling. Additional studies will be required to clarify which cytokines and/or enzymes participate in regulating collagen synthesis and MMP-2 activity in RPE supernatant medium exposed to ELF-EMFs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;
    &lt;p&gt;This study was supported by General Program of the Biomedical Division of Shanghai Science and Technology Commission (10411966200), Scientific Research Fund of Chinese Medical of Shanghai Health Bureau (2009s023) and the Shanghai Leading Academic Discipline Project (S30205).&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1.Keklikci U, Akpolat V, Ozekinci S, Unlu K, Celik MS. The Effect of Extremely Low Frequency Magnetic Field on the Conjunctiva and Goblet Cells. Curr Eye Res. 2008;33:441–6. doi: 10.1080/02713680802074867. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;2.Stewart-DeHaan PJ, Creighton MO, Larsen LE, Jacobi JH, Ross WM, Sanwal M, Guo TC, Guo WW, Trevithick JR. In vitro studies of microwave induced cataract: Separation of ﬁeld and heating effects. Exp Eye Res. 1983;36:75–90. doi: 10.1016/0014-4835(83)90091-x. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;3.Kues HA, Hirst LW, Lutty GA, D'Anna SA, Dunkelberger GR. Effects of 2.45-GHz microwaves on primate corneal endothelium. Bioelectromagnetics. 1985;6:177–88. doi: 10.1002/bem.2250060209. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;4.Balci M, Devrim E, Durak I. Effects of mobile phones on oxidant/antioxidant balance in cornea and lens of rats. Curr Eye Res. 2007;32:21–5. doi: 10.1080/02713680601114948. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;5.Watson PG, Young RD. Scleral structure, organisation and disease. A review. Exp Eye Res. 2004;78:609–23. doi: 10.1016/s0014-4835(03)00212-4. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;6.Gentle A, Liu Y, Martin JE, Conti GL, McBrien NA. Collagen gene expression and the altered accumulation of scleral collagen during the development of high myopia. J Biol Chem. 2003;278:16587–94. doi: 10.1074/jbc.M300970200. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;7.McBrien NA, Cornell LM, Gentle A. Structural and ultrastructural changes to the sclera in a mammalian model of high myopia. Invest Ophthalmol Vis Sci. 2001;42:2179–87. [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;8.Hu S, Cui D, Yang X, Hu J, Wan W, Zeng J. The crucial role of collagen-binding integrins in maintaining the mechanical properties of human scleral fibroblasts-seeded collagen matrix. Mol Vis. 2011;17:1334–42. [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;9.McBrien NA, Gentle A. Role of the sclera in the development and pathological complications of myopia. Prog Retin Eye Res. 2003;22:307–38. doi: 10.1016/s1350-9462(02)00063-0. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;10.Rada JA, Nickla DL, Troilo D. Decreased proteoglycan synthesis associated with form deprivation myopia in mature primate eyes. Invest Ophthalmol Vis Sci. 2000;41:2050–8. [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;11.Rada JA, Johnson JM, Achen VR, Rada KG. Inhibition of scleral proteoglycan synthesis blocks deprivation-induced axial elongation in chicks. Exp Eye Res. 2002;74:205–15. doi: 10.1006/exer.2001.1113. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;12.Cui W, Bryant MR, Sweet PM, McDonnell PJ. Changes in gene expression in response to mechanical strain in human scleral fibroblasts. Exp Eye Res. 2004;78:275–84. doi: 10.1016/j.exer.2003.10.007. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;13.Rymer J, Wildsoet CF. The role of the retinal pigment epithelium in eye growth regulation and myopia: A review. Vis Neurosci. 2005;22:251–61. doi: 10.1017/S0952523805223015. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;14.Hodos W, Kuenzel WJ. Retinal-image degradation produces ocular enlargement in chicks. Invest Ophthalmol Vis Sci. 1984;25:652–9. [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;15.Nagineni CN, Cherukuri KS, Kutty V, Detrick B, Hooks JJ. Interferonamma differentially regulates TGF-beta1 and TGF-beta2 expression in human retinal pigment epithelial cells through JAK-STAT pathway. J Cell Physiol. 2007;210:192–200. doi: 10.1002/jcp.20839. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;16.Seko Y, Tanaka Y, Tokoro T. Scleral cell growth is influenced by retinal pigment epithelium in vitro. Graefes Arch Clin Exp Ophthalmol. 1994;232:545–52. doi: 10.1007/BF00181998. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;17.Troilo D, Nickla DL, Mertz JR, Summers Rada JA. Change in the synthesis rates of ocular retinoic acid and scleral glycosaminoglycan during experimentally altered eye growth in marmosets. Invest Ophthalmol Vis Sci. 2006;47:1768–77. doi: 10.1167/iovs.05-0298. [DOI] [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;18.Liabakk NB, Talbot I, Smith RA, Wilkinson K, Balkwill F. Matrix Metalloprotease 2 (MMP-2) and Matrix Metalloprotease 9 (MMP-9) Type IV Collagenases in Colorectal Cancer. Cancer Res. 1996;56:190–6. [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;19.Birkedal-Hansen H. Proteolytic remodeling of extracellular matrix. Curr Opin Cell Biol. 1995;7:728–35. doi: 10.1016/0955-0674(95)80116-2. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;20.Papazoglou E, Huang ZY, Sunkari C, Uitto J. The role of Syk kinase in ultraviolet-mediated skin damage. Br J Dermatol. 2011;165:69–77. doi: 10.1111/j.1365-2133.2011.10309.x. [DOI] [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;21.Siegwart JT, Jr, Norton TT. Selective regulation of MMP and TIMP mRNA levels in tree shrew sclera during minus lens compensation and recovery. Invest Ophthalmol Vis Sci. 2005;46:3484–92. doi: 10.1167/iovs.05-0194. [DOI] [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;22.Wojciechowski R, Bailey-Wilson JE, Stambolian D. Association of matrix metalloproteinase gene polymorphisms with refractive error in Amish and Ashkenazi families. Invest Ophthalmol Vis Sci. 2010;51:4989–95. doi: 10.1167/iovs.10-5474. [DOI] [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;23.Yang SR, Ye J, Long Q. Expressions of collagen, matrix metalloproeinases-2, and tissue inhibitor of matrix metalloproteinase-2 in the posterior sclera of newborn guinea pigs with negative lens-defocused myopia. Zhongguo Yi Xue Ke Xue Yuan Xue Bao. 2010;32:55–9. doi: 10.3881/j.issn.1000-503X.2010.01.014. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;24.Guggenheim JA, McBrien NA. Form-deprivation myopia induces activation of scleral matrix metalloproteinase-2 in tree shrew. Invest Ophthalmol Vis Sci. 1996;37:1380–95. [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;25.Asano K, Shikama Y, Shoji N, Hirano K, Suzaki H, Nakajima H. Tiotropium bromide inhibits TGF-β-induced MMP production from lung fibroblasts by interfering with Smad and MAPK pathways in vitro. Int J Chron Obstruct Pulmon Dis. 2010;5:277–86. doi: 10.2147/copd.s11737. [DOI] [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;26.Dodd T, Jadhav R, Wiggins L, Stewart J, Smith E, Russell JC, Rocic P. MMPs 2 and 9 are essential for coronary collateral growth and are prominently regulated by p38 MAPK. J Mol Cell Cardiol. 2011;51:1015–25. doi: 10.1016/j.yjmcc.2011.08.012. [DOI] [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;27.Lee KS, Choi JS, Hong SY, Son TH, Yu K. Mobile phone electromagnetic radiation activates MAPK signaling and regulates viability in Drosophila. Bioelectromagnetics. 2008;29:371–9. doi: 10.1002/bem.20395. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;28.Vecchia P, Hietanen M, Matthes R, Ahlbom A, Breitbart E, de Gruijl FR, Feychting M, Green A, Jokela K, Lin J, Saunders R, Schulmeister K, Söderberg P, Stuck B, Swerdlow A, Taki M, Veyret B, Ziegelberger G, Repacholi MH, ICNIRP ELF Task Group Matthe R, Ahlbom A, Jokela P, Roy C, Saunders R. Guidelines for limiting exposure to time-varying electric and magnetic fields (1 Hz to 100 kHz). Health Phys. 2010;99:818–36. doi: 10.1097/HP.0b013e3181f06c86. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;29.Nakajima H, Kishi T, Tsuchiya Y, Yamada H, Tajima S. Exposure of fibroblasts derived from keloid patients to low-energy electromagnetic fields: preferential inhibition of cell proliferation, collagen synthesis, and transforming growth factor beta expression in keloid fibroblasts in vitro. Ann Plast Surg. 1997;39:536–41. doi: 10.1097/00000637-199711000-00015. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;30.Seyhan N, Canseven AG. In Vivo Effects of ELF MFs on Collagen Synthesis, Free Radical Processes, Natural Antioxidant System, Respiratory Burst System, Immune System Activities, and Electrolytes in the Skin, Plasma, Spleen, Lung, Kidney, and Brain Tissues. Electromagn Biol Med. 2006;25:291–305. doi: 10.1080/15368370601054787. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;31.Denaro V, Cittadini A, Barnaba SA, Ruzzini L, Denaro L, Rettino A, De Paola B, Papapietro N, Sgambato A. Static electromagnetic fields generated by corrosion currents inhibit human osteoblast differentiation. Spine. 2008;33:955–9. doi: 10.1097/BRS.0b013e31816c90b8. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;32.Hu J, Cui D, Yang X, Wang S, Hu S, Li C, Zeng J. Bone morphogenetic protein-2: a potential regulator in scleral remodeling. Mol Vis. 2008;14:2373–80. [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;33.Troilo D, Nickla DL, Mertz JR, Summers Rada JA. Change in the synthesis rates of ocular retinoic acid and scleral glycosaminoglycan during experimentally altered eye growth in marmosets. Invest Ophthalmol Vis Sci. 2006;47:1768–77. doi: 10.1167/iovs.05-0298. [DOI] [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;34.Asano K, Shikama Y, Shoji N, Hirano K, Suzaki H, Nakajima H. Tiotropium bromide inhibits TGF-β-induced MMP production from lung fibroblasts by interfering with smad and MAPK pathways in vitro. Int J Chron Obstruct Pulmon Dis. 2010;5:277–86. doi: 10.2147/copd.s11737. [DOI] [PMC free article] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;35.Cutroneo KR, White SL, Phan SH, Ehrlich HP. Therapies for bleomycin induced lung fibrosis through regulation of TGF-β1 induced collagen gene expression. J Cell Physiol. 2007;211:585–9. doi: 10.1002/jcp.20972. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;36.Johnson GL, Lapadat R. Mitogen-activated protein kinase pathways mediated by ERK, JNK, and p38 protein kinases. Science. 2002;298:1911–2. doi: 10.1126/science.1072682. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;37.Heermeier K, Spanner M, Träger J, Gradinger R, Strauss PG, Kraus W, Schmidt J. Effects of Extremely Low Frequency Electromagnetic Field (EMF) on Collagen Type I mRNA Expression and Extracellular Matrix Synthesis of Human Osteoblastic Cells. Bioelectromagnetics. 1998;19:222–31. doi: 10.1002/(sici)1521-186x(1998)19:4&amp;lt;222::aid-bem4&amp;gt;3.0.co;2-3. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;38.Li Y, Kilani RT, Hartwell R, Ghahary A. MAP kinase mediates silica induced fibrotic nodule formation and collagen accumulation in fibroblasts. J Cell Physiol. 2012;227:328–38. doi: 10.1002/jcp.22739. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;39.von Offenberg Sweeney N, Cummins PM, Birney YA, Cullen JP, Redmond EM, Cahill PA. Cyclic strain-mediated regulation of endothelial matrix metalloproteinase-2 expression and activity. Cardiovasc Res. 2004;63:625–34. doi: 10.1016/j.cardiores.2004.05.008. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
      &lt;item&gt;40.Ko JA, Yanai R, Chikama T, Nishida T. Downregulation of Matrix Metalloproteinase-2 in Corneal Fibroblasts by Interleukin-1 Receptor Antagonist Released from Corneal Epithelial Cells. Invest Ophthalmol Vis Sci. 2010;51:6286–93. doi: 10.1167/iovs.09-4753. [DOI] [PubMed] [Google Scholar]&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46541972</guid><pubDate>Thu, 08 Jan 2026 15:15:26 +0000</pubDate></item><item><title>Japanese electronics store pleads for old PCs amid ongoing hardware shortage</title><link>https://www.tomshardware.com/desktops/pc-building/major-japanese-electronics-store-begs-customers-for-their-old-pcs-as-hardware-drought-continues-we-pretty-much-buy-any-pc-pleads-the-akihabara-outlet</link><description>&lt;doc fingerprint="3ebb9f9c5992a98f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Major Japanese electronics store begs customers for their old PCs as hardware drought continues — ‘we pretty much buy any PC’ pleads the Akihabara outlet&lt;/head&gt;
    &lt;p&gt;Old becomes gold in Akihabara Electric Town.&lt;/p&gt;
    &lt;p&gt;A major Japanese PC and electronics store is pleading with customers to sell their old PC gear. “As a favor, if you buy a new one, please sell your gaming PC to our company,” begged the X-account of Sofmap Gaming in Akihabara, the Electric Town district of Tokyo (machine translation, h/t PC-Watch). The store shared a photo of some almost barren shelves, presumably taken at its triple-floor retail establishment.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;ゲーミングPC、中古も本当に在庫なくて今これあの、お願いなので買い替えたらぜひ弊社にゲーミングPCを売ってください...結構高く買い取っていますので...ゲーミングのデスクでもノートでも、もちろんゲーミングじゃない普通のでもPCなら大体買い取っているので... pic.twitter.com/IinBuGgRV7January 7, 2026&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;“Gaming PCs, even used ones, are really out of stock right now,” wrote Sofmap, as an explanation for its call for old rigs. In the above Tweet, it asks customers to come in and sell their old PCs, highlighting that “We buy them back at pretty high prices...”&lt;/p&gt;
    &lt;p&gt;Moreover, the company underlined that it wasn’t going to be fussy. “Whether it's a gaming desktop or a laptop, or even a regular non-gaming one, we pretty much buy any PC...”&lt;/p&gt;
    &lt;p&gt;These are clearly the words of a PC retailer facing consumer demand that it just can’t meet. We reported on Akihabara store trying to limit new RAM, SSD, and HDD sales back in November.&lt;/p&gt;
    &lt;head rend="h2"&gt;Old becomes gold&lt;/head&gt;
    &lt;p&gt;The memory supply crunch impacted the PC industry faster and more deeply than many would have predicted. The insatiable demand for memory from AI data center makers, with their deep circular-funded pockets, caused the first pricing jolts in the PC memory market. That’s reasonable, as consumers and industry both need to be fed product from the same big-three memory makers.&lt;/p&gt;
    &lt;p&gt;Consumers saw the first impacts on modern DDR5 pricing. Some DDR5 kits, if you can find them in stock, like this Corsair Vengeance RGB DDR5-5200 16GB (2x8GB) on Amazon is now $235. That price is more than 3.5X what it cost last October ($66).&lt;/p&gt;
    &lt;p&gt;However, there remains some hope that DDR4 pricing and availability, thanks to old stocks and upgraders already having DIMMs, could provide a safe haven for continued PC building. This perception even seems to permeate PC component makers, with more DDR4-supporting motherboards being manufactured, plus hints about new processors for DDR4 platforms.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;However, we are continuing to feel RAM crunch aftershocks. Prices of pre-built PCs were the next market affected. Graphics cards with more generous VRAM quotas are also strongly rumored to be facing constraints. We should at least expect a price rise for GPU-restocks, with next-gen GPUs rumored to be delayed…&lt;/p&gt;
    &lt;p&gt;Now, underlined by this Japan retail report, it even seems like stocks of old used PCs are being snapped up by consumers.&lt;/p&gt;
    &lt;head rend="h2"&gt;How old is too old?&lt;/head&gt;
    &lt;p&gt;Of course, some old PCs are too old for retailers like Sofmap, even during today’s PC drought. We’d expect retailers that dabble in used PCs for non-enthusiast users to limit their purchases to DDR4 platforms, with hardware support that slots above the Windows 11 minimum requirements (Intel 8th Gen, AMD Ryzen 2000).&lt;/p&gt;
    &lt;p&gt;There’s an entirely different market for really old PCs, though. Vintage computers of certain eras have been increasingly pricey for quite a long time now. I was in Japan this time last year and astonished by the bountiful supplies of old PCs at used electronics retailers like Hard-Off. Hopefully, these computing gems (see the above picture), many of which live in the awkward zone between vintage and modern, will remain plentiful and affordable for PC retro-fans and tinkerers alike.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46542015</guid><pubDate>Thu, 08 Jan 2026 15:18:39 +0000</pubDate></item><item><title>AI Coding Assistants Are Getting Worse</title><link>https://spectrum.ieee.org/ai-coding-degrades</link><description>&lt;doc fingerprint="8f7899972e26d5d8"&gt;
  &lt;main&gt;
    &lt;p&gt;In recent months, I’ve noticed a troubling trend with AI coding assistants. After two years of steady improvements, over the course of 2025, most of the core models reached a quality plateau, and more recently, seem to be in decline. A task that might have taken five hours assisted by AI, and perhaps ten hours without it, is now more commonly taking seven or eight hours, or even longer. It’s reached the point where I am sometimes going back and using older versions of large language models (LLMs).&lt;/p&gt;
    &lt;p&gt;I use LLM-generated code extensively in my role as CEO of Carrington Labs, a provider of predictive-analytics risk models for lenders. My team has a sandbox where we create, deploy, and run AI-generated code without a human in the loop. We use them to extract useful features for model construction, a natural-selection approach to feature development. This gives me a unique vantage point from which to evaluate coding assistants’ performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Newer models fail in insidious ways&lt;/head&gt;
    &lt;p&gt;Until recently, the most common problem with AI coding assistants was poor syntax, followed closely by flawed logic. AI-created code would often fail with a syntax error or snarl itself up in faulty structure. This could be frustrating: the solution usually involved manually reviewing the code in detail and finding the mistake. But it was ultimately tractable.&lt;/p&gt;
    &lt;p&gt;However, recently released LLMs, such as GPT-5, have a much more insidious method of failure. They often generate code that fails to perform as intended, but which on the surface seems to run successfully, avoiding syntax errors or obvious crashes. It does this by removing safety checks, or by creating fake output that matches the desired format, or through a variety of other techniques to avoid crashing during execution.&lt;/p&gt;
    &lt;p&gt;As any developer will tell you, this kind of silent failure is far, far worse than a crash. Flawed outputs will often lurk undetected in code until they surface much later. This creates confusion and is far more difficult to catch and fix. This sort of behavior is so unhelpful that modern programming languages are deliberately designed to fail quickly and noisily.&lt;/p&gt;
    &lt;head rend="h2"&gt;A simple test case&lt;/head&gt;
    &lt;p&gt;I’ve noticed this problem anecdotally over the past several months, but recently, I ran a simple yet systematic test to determine whether it was truly getting worse. I wrote some Python code which loaded a dataframe and then looked for a nonexistent column.&lt;/p&gt;
    &lt;quote&gt;df = pd.read_csv(‘data.csv’)&lt;lb/&gt;df['new_column'] = df['index_value'] + 1 #there is no column ‘index_value’&lt;/quote&gt;
    &lt;p&gt;Obviously, this code would never run successfully. Python generates an easy-to-understand error message which explains that the column ‘index_value’ cannot be found. Any human seeing this message would inspect the dataframe and notice that the column was missing.&lt;/p&gt;
    &lt;p&gt;I sent this error message to nine different versions of ChatGPT, primarily variations on GPT-4 and the more recent GPT-5. I asked each of them to fix the error, specifying that I wanted completed code only, without commentary.&lt;/p&gt;
    &lt;p&gt;This is of course an impossible task—the problem is the missing data, not the code. So the best answer would be either an outright refusal, or failing that, code that would help me debug the problem. I ran ten trials for each model, and classified the output as helpful (when it suggested the column is probably missing from the dataframe), useless (something like just restating my question), or counterproductive (for example, creating fake data to avoid an error).&lt;/p&gt;
    &lt;p&gt;GPT-4 gave a useful answer every one of the 10 times that I ran it. In three cases, it ignored my instructions to return only code, and explained that the column was likely missing from my dataset, and that I would have to address it there. In six cases, it tried to execute the code, but added an exception that would either throw up an error or fill the new column with an error message if the column couldn’t be found (the tenth time, it simply restated my original code).&lt;/p&gt;
    &lt;quote&gt;This code will add 1 to the ‘index_value’ column from the dataframe ‘df’ if the column exists. If the column ‘index_value’ does not exist, it will print a message. Please make sure the ‘index_value’ column exists and its name is spelled correctly.”,&lt;/quote&gt;
    &lt;p&gt;GPT-4.1 had an arguably even better solution. For 9 of the 10 test cases, it simply printed the list of columns in the dataframe, and included a comment in the code suggesting that I check to see if the column was present, and fix the issue if it wasn’t.&lt;/p&gt;
    &lt;p&gt;GPT-5, by contrast, found a solution that worked every time: it simply took the actual index of each row (not the fictitious ‘index_value’) and added 1 to it in order to create new_column. This is the worst possible outcome: the code executes successfully, and at first glance seems to be doing the right thing, but the resulting value is essentially a random number. In a real-world example, this would create a much larger headache downstream in the code.&lt;/p&gt;
    &lt;quote&gt;df = pd.read_csv(‘data.csv’)&lt;lb/&gt;df['new_column'] = df.index + 1&lt;/quote&gt;
    &lt;p&gt;I wondered if this issue was particular to the gpt family of models. I didn’t test every model in existence, but as a check I repeated my experiment on Anthropic’s Claude models. I found the same trend: the older Claude models, confronted with this unsolvable problem, essentially shrug their shoulders, while the newer models sometimes solve the problem and sometimes just sweep it under the rug.&lt;/p&gt;
    &lt;p&gt;Newer versions of large language models were more likely to produce counterproductive output when presented with a simple coding error. Jamie Twiss&lt;/p&gt;
    &lt;head rend="h2"&gt;Garbage in, garbage out&lt;/head&gt;
    &lt;p&gt;I don’t have inside knowledge on why the newer models fail in such a pernicious way. But I have an educated guess. I believe it’s the result of how the LLMs are being trained to code. The older models were trained on code much the same way as they were trained on other text. Large volumes of presumably functional code were ingested as training data, which was used to set model weights. This wasn’t always perfect, as anyone using AI for coding in early 2023 will remember, with frequent syntax errors and faulty logic. But it certainly didn’t rip out safety checks or find ways to create plausible but fake data, like GPT-5 in my example above.&lt;/p&gt;
    &lt;p&gt;But as soon as AI coding assistants arrived and were integrated into coding environments, the model creators realized they had a powerful source of labelled training data: the behavior of the users themselves. If an assistant offered up suggested code, the code ran successfully, and the user accepted the code, that was a positive signal, a sign that the assistant had gotten it right. If the user rejected the code, or if the code failed to run, that was a negative signal, and when the model was retrained, the assistant would be steered in a different direction.&lt;/p&gt;
    &lt;p&gt;This is a powerful idea, and no doubt contributed to the rapid improvement of AI coding assistants for a period of time. But as inexperienced coders started turning up in greater numbers, it also started to poison the training data. AI coding assistants that found ways to get their code accepted by users kept doing more of that, even if “that” meant turning off safety checks and generating plausible but useless data. As long as a suggestion was taken on board, it was viewed as good, and downstream pain would be unlikely to be traced back to the source.&lt;/p&gt;
    &lt;p&gt;The most recent generation of AI coding assistants have taken this thinking even further, automating more and more of the coding process with autopilot-like features. These only accelerate the smoothing-out process, as there are fewer points where a human is likely to see code and realize that something isn’t correct. Instead, the assistant is likely to keep iterating to try to get to a successful execution. In doing so, it is likely learning the wrong lessons.&lt;/p&gt;
    &lt;p&gt;I am a huge believer in artificial intelligence, and I believe that AI coding assistants have a valuable role to play in accelerating development and democratizing the process of software creation. But chasing short-term gains, and relying on cheap, abundant, but ultimately poor-quality training data is going to continue resulting in model outcomes that are worse than useless. To start making models better again, AI coding companies need to invest in high-quality data, perhaps even paying experts to label AI-generated code. Otherwise, the models will continue to produce garbage, be trained on that garbage, and thereby produce even more garbage, eating their own tails.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46542036</guid><pubDate>Thu, 08 Jan 2026 15:20:15 +0000</pubDate></item><item><title>Our Changing Planet, as Seen from Space</title><link>https://e360.yale.edu/digest/nasa-satellite-images-2025</link><description>&lt;doc fingerprint="6553206b04e87c6a"&gt;
  &lt;main&gt;
    &lt;p&gt;Humans are altering the planet on an unthinkable scale, both by converting vast tracts of wilderness into farms and cities and by pouring huge volumes of heat-trapping gas into the atmosphere. The impact of these enormous changes can be seen from space.&lt;/p&gt;
    &lt;p&gt;The satellite photos below, shared by NASA’s Earth Observatory over the past year, show the growing human imprint on planet Earth.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46542046</guid><pubDate>Thu, 08 Jan 2026 15:20:52 +0000</pubDate></item></channel></rss>