<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 04 Jan 2026 16:44:19 +0000</lastBuildDate><item><title>The PGP problem (2019)</title><link>https://www.latacora.com/blog/2019/07/16/the-pgp-problem/</link><description>&lt;doc fingerprint="965b89112f2301dc"&gt;
  &lt;main&gt;
    &lt;p&gt;Cryptography engineers have been tearing their hair out over PGP’s deficiencies for (literally) decades. When other kinds of engineers get wind of this, they’re shocked. PGP is bad? Why do people keep telling me to use PGP? The answer is that they shouldn’t be telling you that, because PGP is bad and needs to go away.&lt;/p&gt;
    &lt;p&gt;There are, as you’re about to see, lots of problems with PGP. Fortunately, if you’re not morbidly curious, there’s a simple meta-problem with it: it was designed in the 1990s, before serious modern cryptography. No competent crypto engineer would design a system that looked like PGP today, nor tolerate most of its defects in any other design. Serious cryptographers have largely given up on PGP and don’t spend much time publishing on it anymore (with a notable exception). Well-understood problems in PGP have gone unaddressed for over a decade because of this.&lt;/p&gt;
    &lt;p&gt;Two quick notes: first, we wrote this for engineers, not lawyers and activists. Second: “PGP” can mean a bunch of things, from the OpenPGP standard to its reference implementation in GnuPG. We use the term “PGP” to cover all of these things.&lt;/p&gt;
    &lt;head rend="h2"&gt;The problems&lt;/head&gt;
    &lt;head rend="h3"&gt;Absurd complexity&lt;/head&gt;
    &lt;p&gt;For reasons none of us here in the future understand, PGP has a packet-based structure. A PGP message (in a “.asc” file) is an archive of typed packets. There are at least 8 different ways of encoding the length of a packet, depending on whether you’re using “new” or “old” format packets. The “new format” packets have variable-length lengths, like BER (try to write a PGP implementation and you may wish for the sweet release of ASN.1). Packets can have subpackets. There are overlapping variants of some packets. The most recent keyserver attack happened because GnuPG accidentally went quadratic in parsing keys, which also follow this deranged format.&lt;/p&gt;
    &lt;p&gt;That’s just the encoding. The actual system doesn’t get simpler. There are keys and subkeys. Key IDs and key servers and key signatures. Sign-only and encrypt-only. Multiple “key rings”. Revocation certificates. Three different compression formats. This is all before we get to smartcard support.&lt;/p&gt;
    &lt;head rend="h3"&gt;Swiss Army knife design&lt;/head&gt;
    &lt;p&gt;If you’re stranded in the woods and, I don’t know, need to repair your jean cuffs, it’s handy if your utility knife has a pair of scissors. But nobody who does serious work uses their multitool scissors regularly.&lt;/p&gt;
    &lt;p&gt;A Swiss Army knife does a bunch of things, all of them poorly. PGP does a mediocre job of signing things, a relatively poor job of encrypting them with passwords, and a pretty bad job of encrypting them with public keys. PGP is not an especially good way to securely transfer a file. It’s a clunky way to sign packages. It’s not great at protecting backups. It’s a downright dangerous way to converse in secure messages.&lt;/p&gt;
    &lt;p&gt;Back in the MC Hammer era from which PGP originates, “encryption” was its own special thing; there was one tool to send a file, or to back up a directory, and another tool to encrypt and sign a file. Modern cryptography doesn’t work like this; it’s purpose built. Secure messaging wants crypto that is different from secure backups or package signing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mired in backwards compatibility&lt;/head&gt;
    &lt;p&gt;PGP predates modern cryptography; there are Hanson albums that have aged better. If you’re lucky, your local GnuPG defaults to 2048-bit RSA, the 64-bit-block CAST5 cipher in CFB, and the OpenPGP MDC checksum (about which more later). If you encrypt with a password rather than with a public key, the OpenPGP protocol specifies PGP’s S2K password KDF. These are, to put it gently, not the primitives a cryptography engineer would select for a modern system.&lt;/p&gt;
    &lt;p&gt;We’ve learned a lot since Steve Urkel graced the airwaves during ABC’s TGIF: that you should authenticate your ciphertexts (and avoid CFB mode) would be an obvious example, but also that 64-bit block ciphers are bad, that we can do much better than RSA, that mixing compression and encryption is dangerous, and that KDFs should be both time- and memory-hard.&lt;/p&gt;
    &lt;p&gt;Whatever the OpenPGP RFCs may say, you’re probably not doing any of these things if you’re using PGP, nor can you predict when you will. Take AEAD ciphers: the Rust-language Sequoia PGP defaulted to the AES-EAX AEAD mode, which is great, and nobody can read those messages because most PGP installs don’t know what EAX mode is, which is not great. Every well-known bad cryptosystem eventually sprouts an RFC extension that supports curves or AEAD, so that its proponents can claim on message boards that they support modern cryptography. RFC’s don’t matter: only the installed base does. We’ve understood authenticated encryption for 2 decades, and PGP is old enough to buy me drinks; enough excuses.&lt;/p&gt;
    &lt;p&gt;You can have backwards compatibility with the 1990s or you can have sound cryptography; you can’t have both.&lt;/p&gt;
    &lt;head rend="h3"&gt;Obnoxious UX&lt;/head&gt;
    &lt;p&gt;We can’t say this any better than Ted Unangst:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There was a PGP usability study conducted a few years ago where a group of technical people were placed in a room with a computer and asked to set up PGP. Two hours later, they were never seen or heard from again.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If you’d like empirical data of your own to back this up, here’s an experiment you can run: find an immigration lawyer and talk them through the process of getting Signal working on their phone. You probably don’t suddenly smell burning toast. Now try doing that with PGP.&lt;/p&gt;
    &lt;head rend="h3"&gt;Long-term secrets&lt;/head&gt;
    &lt;p&gt;PGP begs users to keep a practically forever root key tied to their identity. It does this by making keys annoying to generate and exchange, by encouraging “key signing parties”, and by creating a “web of trust” where keys depend on other keys.&lt;/p&gt;
    &lt;p&gt;Long term keys are almost never what you want. If you keep using a key, it eventually gets exposed. You want the blast radius of a compromise to be as small as possible, and, just as importantly, you don’t want users to hesitate even for a moment at the thought of rolling a new key if there’s any concern at all about the safety of their current key.&lt;/p&gt;
    &lt;p&gt;The PGP cheering section will immediately reply “that’s why you keep keys on a Yubikey”. To a decent first approximation, nobody in the whole world uses the expensive Yubikeys that do this, and you can’t imagine a future in which that changes (we can barely get U2F rolled out, and those keys are disposable). We can’t accept bad cryptosystems just to make Unix nerds feel better about their toys.&lt;/p&gt;
    &lt;head rend="h3"&gt;Broken authentication&lt;/head&gt;
    &lt;p&gt;More on PGP’s archaic primitives: way back in 2000, the OpenPGP working group realized they needed to authenticate ciphertext, and that PGP’s signatures weren’t accomplishing that. So OpenPGP invented the MDC system: PGP messages with MDCs attach a SHA-1 of the plaintext to the plaintext, which is then encrypted (as normal) in CFB mode.&lt;/p&gt;
    &lt;p&gt;If you’re wondering how PGP gets away with this when modern systems use relatively complex AEAD modes (why can’t everyone just tack a SHA-1 to their plaintext), you’re not alone. Where to start with this Rube Goldberg contraption? The PGP MDC can be stripped off messages –– it was encoded in such a way that you can simply chop off the last 22 bytes of the ciphertext to do that. To retain backwards compatibility with insecure older messages, PGP introduced a new packet type to signal that the MDC needs to be validated; if you use the wrong type, the MDC doesn’t get checked. Even if you do, the new SEIP packet format is close enough to the insecure SE format that you can potentially trick readers into downgrading; Trevor Perrin worked the SEIP out to 16 whole bits of security.&lt;/p&gt;
    &lt;p&gt;And, finally, even if everything goes right, the reference PGP implementation will (wait for it) release unauthenticated plaintext to callers, even if the MDC doesn’t match.&lt;/p&gt;
    &lt;head rend="h3"&gt;Incoherent Identity&lt;/head&gt;
    &lt;p&gt;PGP is an application. It’s a set of integrations with other applications. It’s a file format. It’s also a social network, and a subculture.&lt;/p&gt;
    &lt;p&gt;PGP pushes notion of a cryptographic identity. You generate a key, save it in your keyring, print its fingerprint on your business card, and publish it to a keyserver. You sign other people’s keys. They in turn may or may not rely on your signatures to verify other keys. Some people go out of their way to meet other PGP users in person to exchange keys and more securely attach themselves to this “web of trust”. Other people organize “key signing parties”. The image you’re conjuring in your head of that accurately explains how hard it is to PGP’s devotees to switch to newer stuff.&lt;/p&gt;
    &lt;p&gt;None of this identity goop works. Not the key signing web of trust, not the keyservers, not the parties. Ordinary people will trust anything that looks like a PGP key no matter where it came from—how could they not, when even an expert would have a hard time articulating how to evaluate a key? Experts don’t trust keys they haven’t exchanged personally. Everyone else relies on centralized authorities to distribute keys. PGP’s key distribution mechanisms are theater.&lt;/p&gt;
    &lt;head rend="h3"&gt;Leaks Metadata&lt;/head&gt;
    &lt;p&gt;Forget the email debacle for a second (we’ll get to that later). PGP by itself leaks metadata. Messages are (in normal usage) linked directly to key identifiers, which are, throughout PGP’s cobweb of trust, linked to user identity. Further, a rather large fraction of PGP users make use of keyservers, which can themselves leak to the network the identities of which PGP users are communicating with each other.&lt;/p&gt;
    &lt;head rend="h3"&gt;No forward secrecy&lt;/head&gt;
    &lt;p&gt;A good example of that last problem: secure messaging crypto demands forward secrecy. Forward secrecy means that if you lose your key to an attacker today, they still can’t go back and read yesterday’s messages; they had to be there with the key yesterday to read them. In modern cryptography engineering, we assume our adversary is recording everything, into infinite storage. PGP’s claimed adversaries include world governments, many of whom are certainly doing exactly that. Against serious adversaries and without forward secrecy, breaches are a question of “when”, not “if”.&lt;/p&gt;
    &lt;p&gt;To get forward secrecy in practice, you typically keep two secret keys: a short term session key and a longer-term trusted key. The session key is ephemeral (usually the product of a DH exchange) and the trusted key signs it, so that a man-in-the-middle can’t swap their own key in. It’s theoretically possible to achieve a facsimile of forward secrecy using the tools PGP provides. Of course, pretty much nobody does this.&lt;/p&gt;
    &lt;head rend="h3"&gt;Clumsy keys&lt;/head&gt;
    &lt;p&gt;An OpenBSD signify(1) public key is a Base64 string short enough to fit in the middle of a sentence in an email; the private key, which isn’t an interchange format, is just a line or so longer. A PGP public key is a whole giant Base64 document; if you’ve used them often, you’re probably already in the habit of attaching them rather than pasting them into messages so they don’t get corrupted. Signify’s key is a state-of-the-art Ed25519 key; PGP’s is a weaker RSA key.&lt;/p&gt;
    &lt;p&gt;You might think this stuff doesn’t matter, but it matters a lot; orders of magnitude more people use SSH and manage SSH keys than use PGP. SSH keys are trivial to handle; PGP’s are not.&lt;/p&gt;
    &lt;head rend="h3"&gt;Negotiation&lt;/head&gt;
    &lt;p&gt;PGP supports ElGamal. PGP supports RSA. PGP supports the NIST P-Curves. PGP supports Brainpool. PGP supports Curve25519. PGP supports SHA-1. PGP supports SHA-2. PGP supports RIPEMD160. PGP supports IDEA. PGP supports 3DES. PGP supports CAST5. PGP supports AES. There is no way this is a complete list of what PGP supports.&lt;/p&gt;
    &lt;p&gt;If we’ve learned 3 important things about cryptography design in the last 20 years, at least 2 of them are that negotiation and compatibility are evil. The flaws in cryptosystems tend to appear in the joinery, not the lumber, and expansive crypto compatibility increases the amount of joinery. Modern protocols like TLS 1.3 are jettisoning backwards compatibility with things like RSA, not adding it. New systems support just a single suite of primitives, and a simple version number. If one of those primitives fails, you bump the version and chuck the old protocol all at once.&lt;/p&gt;
    &lt;p&gt;If we’re unlucky, and people are still using PGP 20 years from now, PGP will be the only reason any code anywhere includes CAST5. We can’t say this more clearly or often enough: you can have backwards compatibility with the 1990s or you can have sound cryptography; you can’t have both.&lt;/p&gt;
    &lt;head rend="h3"&gt;Janky code&lt;/head&gt;
    &lt;p&gt;The standard implementation in practice of PGP is GnuPG. GnuPG is not carefully built. It’s a sprawling C-language codebase with duplicative functionality (write-ups of the most recent SKS key parsing denial of service noted that it has multiple key parsers, for instance) with a long track record of CVEs ranging from memory corruption to cryptographic side channels. It has at times been possible to strip authenticators off messages without GnuPG noticing. It’s been possible to feed it keys that don’t fingerprint properly without it noticing. The 2018 Efail vulnerability was a result of it releasing unauthenticated plaintext to callers. GnuPG is not good.&lt;/p&gt;
    &lt;p&gt;GnuPG is also effectively the reference implementation for PGP, and also the basis for most other tools that integrate PGP cryptography. It isn’t going anywhere. To rely on PGP is to rely on GPG.&lt;/p&gt;
    &lt;head rend="h2"&gt;The answers&lt;/head&gt;
    &lt;p&gt;One of the rhetorical challenges of persuading people to stop using PGP is that there’s no one thing you can replace it with, nor should there be. What you should use instead depends on what you’re doing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Talking to people&lt;/head&gt;
    &lt;p&gt;Use Signal. Or Wire, or WhatsApp, or some other Signal-protocol-based secure messenger.&lt;/p&gt;
    &lt;p&gt;Modern secure messengers are purpose-built around messaging. They use privacy-preserving authentication handshakes, repudiable messages, cryptographic ratchets that rekey on every message exchange, and, of course, modern encryption primitives. Messengers are trivially easy to use and there’s no fussing over keys and subkeys. If you use Signal, you get even more than that: you get a system so paranoid about keeping private metadata off servers that it tunnels Giphy searches to avoid traffic analysis attacks, and until relatively recently didn’t even support user profiles.&lt;/p&gt;
    &lt;head rend="h3"&gt;Encrypting email&lt;/head&gt;
    &lt;p&gt;Don’t.&lt;/p&gt;
    &lt;p&gt;Email is insecure. Even with PGP, it’s default-plaintext, which means that even if you do everything right, some totally reasonable person you mail, doing totally reasonable things, will invariably CC the quoted plaintext of your encrypted message to someone else (we don’t know a PGP email user who hasn’t seen this happen). PGP email is forward-insecure. Email metadata, including the subject (which is literally message content), are always plaintext.&lt;/p&gt;
    &lt;p&gt;If you needed another reason, read the Efail paper. The GnuPG community, which mishandled the Efail disclosure, talks this research down a lot, but it was accepted at Usenix Security (one of the top academic software security venues) and at Black Hat USA (the top industry software security venue), was one of the best cryptographic attacks of the last 5 years, and is a pretty devastating indictment of the PGP ecosystem. As you’ll see from the paper, S/MIME isn’t better.&lt;/p&gt;
    &lt;p&gt;This isn’t going to get fixed. To make actually secure email, you’d have to tunnel another protocol over email (you’d still be conceding traffic analysis attacks). At that point, why bother pretending?&lt;/p&gt;
    &lt;p&gt;Encrypting email is asking for a calamity. Recommending email encryption to at-risk users is malpractice. Anyone who tells you it’s secure to communicate over PGP-encrypted email is putting their weird preferences ahead of your safety.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sending files&lt;/head&gt;
    &lt;p&gt;Use Magic Wormhole. Wormhole clients use a one-time password-authenticated key exchange (PAKE) to encrypt files to recipients. It’s easy (for nerds, at least), secure, and fun: we haven’t introduced wormhole to anyone who didn’t start gleefully wormholing things immediately just like we did.&lt;/p&gt;
    &lt;p&gt;Someone stick a Windows installer on a Go or Rust implementation of Magic Wormhole right away; it’s too great for everyone not to have.&lt;/p&gt;
    &lt;p&gt;If you’re working with lawyers and not with technologists, Signal does a perfectly cromulent job of securing file transfers. Put a Signal number on your security page to receive bug bounty reports, not a PGP key.&lt;/p&gt;
    &lt;head rend="h3"&gt;Encrypting backups&lt;/head&gt;
    &lt;p&gt;Use Tarsnap. Colin can tell you all about how Tarsnap is optimized to protect backups. Or really, use any other encrypted backup tool that lots of other people use; they won’t be as good as Tarsnap but they’ll all do a better job than PGP will.&lt;/p&gt;
    &lt;p&gt;Need offline backups? Use encrypted disk images; they’re built into modern Windows, Linux, and macOS. Full disk encryption isn’t great, but it works fine for this use case, and it’s easier and safer than PGP.&lt;/p&gt;
    &lt;head rend="h3"&gt;Signing packages&lt;/head&gt;
    &lt;p&gt;Use Signify/Minisign. Ted Unangst will tell you all about it. It’s what OpenBSD uses to sign packages. It’s extremely simple and uses modern signing. Minisign, from Frank Denis, the libsodium guy, brings the same design to Windows and macOS; it has bindings for Go, Rust, Python, Javascript, and .NET; it’s even compatible with Signify.&lt;/p&gt;
    &lt;head rend="h3"&gt;Encrypting application data&lt;/head&gt;
    &lt;p&gt;Use libsodium It builds everywhere, has interface that’s designed to be hard to misuse, and you won’t have to shell out to a binary to use it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Encrypting files&lt;/head&gt;
    &lt;p&gt;This really is a problem. If you’re/not/making a backup, and you’re /not/archiving something offline for long-term storage, and you’re /not/encrypting to securely send the file to someone else, and you’re /not/encrypting virtual drives that you mount/unmount as needed to get work done, then there’s no one good tool that does this now. Filippo Valsorda is working on “age” for these use cases, and I’m super optimistic about it, but it’s not there yet.&lt;/p&gt;
    &lt;p&gt;Update, February 2020&lt;/p&gt;
    &lt;p&gt;Filippo’s age has been released. It’s a solid design with simple, easily auditable implementations in Go and Rust. You can build binaries for it for every mainstream platform. Age is, of course, much younger than PGP. But I would bet all the money in my pocket against all the money in yours that a new vulnerability will be found in the clangorous contraption of PGP before one is found in age. Look into age!&lt;/p&gt;
    &lt;p&gt;Hopefully it’s clear that this is a pretty narrow use case. We work in software security and handle sensitive data, including bug bounty reports (another super common “we need PGP!” use case), and we almost never have to touch PGP.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46486326</guid><pubDate>Sun, 04 Jan 2026 09:11:47 +0000</pubDate></item><item><title>Anatomy of BoltzGen</title><link>https://huggingface.co/spaces/ludocomito/anatomy-of-boltzgen</link><description>&lt;doc fingerprint="c026ddc3fc7bda32"&gt;
  &lt;main&gt;
    &lt;p&gt;ludocomito / anatomy-of-boltzgen like 19 Refreshing&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46486681</guid><pubDate>Sun, 04 Jan 2026 10:28:49 +0000</pubDate></item><item><title>Maybe comments should explain 'what' (2017)</title><link>https://www.hillelwayne.com/post/what-comments/</link><description>&lt;doc fingerprint="56309d2470a41897"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Maybe Comments SHOULD Explain 'What'&lt;/head&gt;
    &lt;p&gt;People say “Comments should explain why, not what.” I feel like starting a flame war today so I’m going to argue that comments should explain ‘what’ too. Please don’t use this as justification to write bad code, okay? Okay.&lt;/p&gt;
    &lt;p&gt;First of all, why shouldn’t comments explain ‘what’? If you need comments to explain what’s going on, it suggests your code is unclear. If I write&lt;/p&gt;
    &lt;code&gt;//weight, radius, price
w = 10, r = 9, p = 1
&lt;/code&gt;
    &lt;p&gt;That’s not as clear as saying&lt;/p&gt;
    &lt;code&gt;weight = 10, radius = 9, price = 3
&lt;/code&gt;
    &lt;p&gt;“But it’s obvious that &lt;code&gt;w&lt;/code&gt; is &lt;code&gt;weight&lt;/code&gt;!” Sure, if you’re seeing those lines back-to-back. But presumably you’re initializing the variable to use it, which means that it’s going to appear later. When you see &lt;code&gt;w&lt;/code&gt; later in the body, you need to go back and check what it is. That’s a frustrating context switch and you may skip it, possibly assuming that &lt;code&gt;w&lt;/code&gt; is… width. Then bad things happen. So comments are not a substitute for clean code.&lt;/p&gt;
    &lt;p&gt;Okay, so why should comments explain why? Some people argue that we should instead store the ‘why’ in commit messages or tests. Most people feel icky about this, though. Given:&lt;/p&gt;
    &lt;code&gt;// Clear twice to deal with bug ABC in library XYZ, see [link]
XYZ.clear(); XYZ.clear();
&lt;/code&gt;
    &lt;p&gt;Would you prefer that comment be removed and placed in the commit message? Then if you want to learn why &lt;code&gt;XYZ.clear()&lt;/code&gt; is repeated twice, you have to dig up the commit. That can be a difficult and tedious job, especially if the line was reformatted, moved between files, anything that makes &lt;code&gt;git blame&lt;/code&gt; not work. Searching all that is a context switch and you may skip it, possibly assuming that it’s a bug you can remove. Then bad things happen.&lt;/p&gt;
    &lt;p&gt;Both of these cases share the same problem: looking things up is hard. Best case it’s a context switch that takes time away from understanding the problem. Worst case you don’t look it up and make a potentially-dangerous assumption. It’s better to keep the information in the exact same place that you need it, whether that’s via descriptive code or comments over commits.&lt;/p&gt;
    &lt;p&gt;Now for the weird part. What if your descriptive code forces a context switch? Let’s take the code from Bob Martin’s Extract Till You Drop.1&lt;/p&gt;
    &lt;code&gt;    String replace() {
      Pattern symbolPattern = Pattern.compile("\\$([a-zA-Z]\\w*)");
      Matcher symbolMatcher = symbolPattern.matcher(stringToReplace);
      while (symbolMatcher.find()) {
        String symbolName = symbolMatcher.group(1);
        if (getSymbol(symbolName) != null &amp;amp;&amp;amp; !alreadyReplaced.contains(symbolName)) {
          alreadyReplaced.add(symbolName);
          stringToReplace = stringToReplace.replace("$" + symbolName, translate(symbolName));
        }
      }
      return stringToReplace;
&lt;/code&gt;
    &lt;p&gt;To make it more understandable, he replaces it with this:&lt;/p&gt;
    &lt;code&gt;  String replace() {
      replaceAllSymbols();
      return stringToReplace;
    }

    private void replaceAllSymbols() {
      for (String symbolName = nextSymbol(); symbolName != null; symbolName = nextSymbol())
        replaceAllInstances(symbolName);
    }

    private String nextSymbol() {
      return symbolMatcher.find() ? symbolMatcher.group(1) : null;
    }

    private void replaceAllInstances(String symbolName) {
      if (shouldReplaceSymbol(symbolName))
        replaceSymbol(symbolName);
    }

    private boolean shouldReplaceSymbol(String symbolName) {
      return getSymbol(symbolName) != null &amp;amp;&amp;amp; !alreadyReplaced.contains(symbolName);
    }

    private void replaceSymbol(String symbolName) {
      alreadyReplaced.add(symbolName);
      stringToReplace = stringToReplace.replace(
        symbolExpression(symbolName),
        translate(symbolName));
    }

    private String symbolExpression(String symbolName) {
      return "$" + symbolName;
    }
&lt;/code&gt;
    &lt;p&gt;So much better, right?! &lt;code&gt;replace&lt;/code&gt; is now two lines instead of ten. But now there’s six other methods you have to read to understand how the class works. “But it’s easier to follow.” Not if I’m trying to track down a bug and I have to keep scrolling up and down, jumping from method to method to understand the whole. Is that really so much better than using comments?&lt;/p&gt;
    &lt;code&gt;    String replace() {
      Pattern symbolPattern = Pattern.compile("\\$([a-zA-Z]\\w*)"); //f.ex $F1a3
      Matcher symbolMatcher = symbolPattern.matcher(stringToReplace);

      // Replace all symbols
      while (symbolMatcher.find()) {
        String symbolName = symbolMatcher.group(1);
        // translate will replace all instances; only need to run it once
        if (getSymbol(symbolName) != null &amp;amp;&amp;amp; !alreadyReplaced.contains(symbolName)) {
          alreadyReplaced.add(symbolName);
          stringToReplace = stringToReplace.replace("$" + symbolName, translate(symbolName));
        }
      }
      return stringToReplace;
&lt;/code&gt;
    &lt;p&gt;I think that’s more understandable than either the original case or the clean code case, because you don’t have to context switch to a different method to understand what’s going on. Obviously this isn’t always the case, and often comments are superfluous. I’m just saying that there are at least a few cases where writing a ‘what’ comment is the right choice, so we shouldn’t reject them out-of-hand.&lt;/p&gt;
    &lt;p&gt;Welp that’s my argument so flame war awaaaaaaaaaay&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46486780</guid><pubDate>Sun, 04 Jan 2026 10:43:38 +0000</pubDate></item><item><title>JavaScript engines zoo – Compare every JavaScript engine</title><link>https://zoo.js.org/</link><description>&lt;doc fingerprint="5d5ffb21f9156e19"&gt;
  &lt;main&gt;
    &lt;p&gt;JavaScript engines zoo amd64: i9-10900K 3.7-5.3GHz - Linux arm64: Mac M4 4.5GHz - Linux VM Show variants JITless only Only v8-v7 benchmarks Engine Score Binary LOC Language JIT Years Target ES1-5 ES6 ES2016+ Stars Contributors Org License Description&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46486978</guid><pubDate>Sun, 04 Jan 2026 11:23:23 +0000</pubDate></item><item><title>FreeBSD Home NAS, part 3: WireGuard VPN, routing, and Linux peers</title><link>https://rtfm.co.ua/en/freebsd-home-nas-part-3-wireguard-vpn-linux-peer-and-routing/</link><description>&lt;doc fingerprint="f7d17d09e5228ce3"&gt;
  &lt;main&gt;
    &lt;p&gt;I am continuing to set up my home server on FreeBSD 14.3, which is intended to serve as a NAS.&lt;/p&gt;
    &lt;p&gt;In the previous post, FreeBSD: introduction to Packet Filter (PF) firewall, we got acquainted with firewalls; the next step is to configure a VPN for access.&lt;/p&gt;
    &lt;p&gt;The main idea is to (finally!) connect my “office” and my apartment, and later, perhaps, also connect the server where rtfm.co.ua is currently running so that blog files and database backups can be stored directly on the ZFS mirror pool of the home server.&lt;/p&gt;
    &lt;p&gt;All posts in this blog series:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 1 – configuring ZFS mirror (RAID1)&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 2 – introduction to Packet Filter (PF) firewall&lt;/item&gt;
      &lt;item&gt;(current) FreeBSD: Home NAS, part 3 – WireGuard VPN, Linux peer, and routing&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 4 – Local DNS with Unbound&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 5 – ZFS pool, datasets, snapshots, and ZFS monitoring&lt;/item&gt;
      &lt;item&gt;FreeBSD: Home NAS, part 6 – Samba server and client connections&lt;/item&gt;
      &lt;item&gt;… to be continued&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contents&lt;/p&gt;
    &lt;head rend="h1"&gt;WireGuard vs OpenVPN&lt;/head&gt;
    &lt;p&gt;When it came to choosing which specific VPN server to use, I initially thought about OpenVPN – since I’ve worked with it for years, and there are even some blog posts about it on RTFM.&lt;/p&gt;
    &lt;p&gt;However, after giving it some thought, I decided that for a home VPN, solutions like OpenVPN or Pritunl would be a bit of overkill, and I could give WireGuard a try.&lt;/p&gt;
    &lt;p&gt;The systems are very different, but in short:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WireGuard has a much smaller codebase – for example, the Linux implementation is about 4,000 lines in the kernel, while OpenVPN is about 100,000 lines in user space&lt;/item&gt;
      &lt;item&gt;WireGuard works as a kernel module – packet processing and cryptography are performed directly in kernel space, whereas OpenVPN is a user space service that operates through a TCP or UDP socket and interacts with the kernel via the standard kernel network stack&lt;/item&gt;
      &lt;item&gt;The same applies to encryption, as WireGuard has built-in cryptography that is part of the protocol itself and runs in kernel space, while OpenVPN uses the standard SSL/TLS stack (OpenSSL, LibreSSL, etc.) in user space, which adds complexity and CPU/RAM overhead&lt;/item&gt;
      &lt;item&gt;WireGuard’s operational model is peer-to-peer – meaning the protocol has no built-in “server” or “client” roles, only Peers with keys and allowed IPs, whereas OpenVPN is built around a classic client-server architecture&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As a result, WireGuard can be perceived not as a separate service, but as an encrypted network interface, while OpenVPN remains a classic application-based VPN service.&lt;/p&gt;
    &lt;p&gt;Even the official WireGuard whitepaper is titled “Next Generation Kernel Network Tunnel“.&lt;/p&gt;
    &lt;head rend="h1"&gt;Network Architecture&lt;/head&gt;
    &lt;p&gt;So, here is what I have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“office”: a separate local network 192.168.0.0/24, with a TP-LINK Archer AX12 router at the entry &lt;list rend="ul"&gt;&lt;item&gt;this network contains a work laptop with Arch Linux and a Lenovo ThinkCentre with FreeBSD&lt;/item&gt;&lt;item&gt;the FreeBSD machine will host the NAS, NFS, and WireGuard itself &lt;list rend="ul"&gt;&lt;item&gt;although the Archer AX12 has its own built-in OpenVPN and WireGuard – I want to do it myself, manually, for more control&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;home: a 192.168.100.0/24 network with the exact same Archer AX12 router &lt;list rend="ul"&gt;&lt;item&gt;the only client there is a home laptop with Arch Linux&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And here is what I want to achieve:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FreeBSD will act as the WireGuard VPN server&lt;/item&gt;
      &lt;item&gt;The Archer AX12 router will have NAT port-forwarding to connect to WireGuard on FreeBSD&lt;/item&gt;
      &lt;item&gt;VPN network – 10.8.0.1/24&lt;/item&gt;
      &lt;item&gt;Packet Filter firewall on FreeBSD to control traffic&lt;/item&gt;
      &lt;item&gt;Both laptops should have access to each other and to the future NAS on FreeBSD&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here is how it looks schematically:&lt;/p&gt;
    &lt;head rend="h1"&gt;Running WireGuard on FreeBSD&lt;/head&gt;
    &lt;p&gt;In FreeBSD (just like in Linux), WireGuard consists of a kernel module + userspace tools: the main “working” part is loaded as a kernel module, and a separate package is installed to interact with it.&lt;/p&gt;
    &lt;p&gt;Install &lt;code&gt;wireguard-tools&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # pkg install wireguard-tools&lt;/quote&gt;
    &lt;p&gt;Load the module:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # kldload if_wg&lt;/quote&gt;
    &lt;p&gt;Verify:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # kldstat | grep wg 8 1 0xffffffff82a47000 2f5c0 if_wg.ko&lt;/quote&gt;
    &lt;p&gt;Enable WireGuard in &lt;code&gt;/etc/rc.conf&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # sysrc wireguard_enable=YES wireguard_enable: -&amp;gt; YES root@setevoy-nas:/home/setevoy # sysrc wireguard_interfaces=wg0 wireguard_interfaces: -&amp;gt; wg0&lt;/quote&gt;
    &lt;p&gt;Don’t start it yet – let’s move on to network configuration.&lt;/p&gt;
    &lt;head rend="h2"&gt;Network configuration&lt;/head&gt;
    &lt;p&gt;Next, the system needs to be configured to route packets between the physical interface and the WireGuard interface, and the firewall config needs an update.&lt;/p&gt;
    &lt;head rend="h3"&gt;IP forwarding configuration&lt;/head&gt;
    &lt;p&gt;Enable IP forwarding from the &lt;code&gt;wg0&lt;/code&gt; interface (which doesn’t exist yet, it will appear when WireGuard starts) to the LAN interface, &lt;code&gt;em0&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Update the autostart in &lt;code&gt;/etc/rc.conf&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/usr/local/etc/wireguard # sysrc gateway_enable="YES" gateway_enable: NO -&amp;gt; YES&lt;/quote&gt;
    &lt;p&gt;To enable forwarding immediately without a reboot – turn it on using &lt;code&gt;sysctl&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/usr/local/etc/wireguard # sysctl net.inet.ip.forwarding=1 net.inet.ip.forwarding: 0 -&amp;gt; 1&lt;/quote&gt;
    &lt;p&gt;Verify:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/usr/local/etc/wireguard # sysctl net.inet.ip.forwarding net.inet.ip.forwarding: 1&lt;/quote&gt;
    &lt;p&gt;The next step is configuring Packet Filter.&lt;/p&gt;
    &lt;head rend="h3"&gt;Packet Filter Configuration&lt;/head&gt;
    &lt;p&gt;So, here is what we have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;VPN network: 10.8.0.0/24&lt;/item&gt;
      &lt;item&gt;Office network where FreeBSD/VPN is located: 192.168.0.0/24 &lt;list rend="ul"&gt;&lt;item&gt;FreeBSD LAN IP: 192.168.0.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Routing internet through VPN is not required – only traffic between the home and office networks&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The current &lt;code&gt;pf&lt;/code&gt; config is minimalist, from the previous post:&lt;/p&gt;
    &lt;quote&gt;allowed_tcp_ports = "{ 22 }" allowed_clients = "{ 192.168.0.0/24, 192.168.1.0/24 }" set skip on lo block all # allow ssh only from specific hosts pass in proto tcp from $allowed_clients to any port $allowed_tcp_ports keep state # allow all outgoing traffic pass out all keep state&lt;/quote&gt;
    &lt;p&gt;What needs to be added:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;allow inbound UDP connections to the WireGuard port (51820) for the handshake&lt;/item&gt;
      &lt;item&gt;allow traffic from the VPN network 10.8.0.0/24 to the FreeBSD host itself (ping, SSH)&lt;/item&gt;
      &lt;item&gt;allow transit traffic from the VPN network 10.8.0.0/24 to the local office and home networks (192.168.0.0/24 and 192.168.100.0/24)&lt;/item&gt;
      &lt;item&gt;allow ICMP and SSH from the VPN network and the home network to the FreeBSD host&lt;/item&gt;
      &lt;item&gt;allow outbound traffic from FreeBSD&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’ve added macros to the config, but while writing and testing – I specify all ports and addresses explicitly in the config for better readability.&lt;/p&gt;
    &lt;p&gt;Now &lt;code&gt;/etc/pf.conf&lt;/code&gt; will look like this:&lt;/p&gt;
    &lt;quote&gt;################## ### Interfaces ### ################## # lan_if = "em0" # wg_if = "wg0" ################ ### Networks ### ################ # lan_net = "192.168.0.0/24" # home_net = "192.168.100.0/24" # wg_net = "10.8.0.0/24" # vpn_nets = "{ 10.8.0.0/24, 192.168.100.0/24 }" ################ ### Services ### ################ # ssh_ports = "{ 22 }" # wg_port = "51820" ###################### ### Basic settings ### ###################### # do not filter loopback traffic set skip on lo ###################### ### Default policy ### ###################### # block everything by default block all ####################### ### Inbound traffic ### ####################### ### SSH # allow SSH from Office LAN (192.168.0.0/24) to FreeBSD host pass in log on em0 proto tcp from 192.168.0.0/24 to (em0) port 22 keep state # allow SSH from Home network (192.168.100.0/24) to FreeBSD host pass in log on em0 proto tcp from 192.168.100.0/24 to (em0) port 22 keep state # allow SSH from VPN clients to FreeBSD host pass in on wg0 proto tcp from 10.8.0.0/24 to (wg0) port 22 keep state ### VPN # allow WireGuard handshake (UDP/51820) on LAN interface pass in on em0 proto udp to (em0) port 51820 keep state # allow VPN clients (10.8.0.0/24) to access FreeBSD host itself # this allows ping, ssh, etc. to the wg0 address pass in on wg0 from 10.8.0.0/24 to (wg0) keep state # allow VPN clients to access Office LAN (192.168.0.0/24) pass in on wg0 from 10.8.0.0/24 to 192.168.0.0/24 keep state # allow VPN clients to access Home network (192.168.100.0/24) pass in on wg0 from 10.8.0.0/24 to 192.168.100.0/24 keep state # allow ICMP (ping) from VPN clients to FreeBSD host pass in on wg0 proto icmp from 10.8.0.0/24 to (wg0) keep state # allow ICMP (ping) from Home network to FreeBSD host pass in on em0 proto icmp from 192.168.100.0/24 to (em0) keep state ############################ ### outbound traffic ### ############################ # allow all outbound traffic from FreeBSD pass out keep state&lt;/quote&gt;
    &lt;p&gt;Verify the syntax:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # pfctl -vnf /etc/pf.conf set skip on { lo } block drop all pass in log on em0 inet proto tcp from 192.168.0.0/24 to (em0) port = ssh flags S/SA keep state pass in log on em0 inet proto tcp from 192.168.100.0/24 to (em0) port = ssh flags S/SA keep state pass in on wg0 inet from 10.8.0.0/24 to (wg0) flags S/SA keep state pass in on wg0 inet proto icmp from 10.8.0.0/24 to (wg0) keep state pass in on wg0 inet from 10.8.0.0/24 to 192.168.0.0/24 flags S/SA keep state pass in on wg0 inet from 10.8.0.0/24 to 192.168.100.0/24 flags S/SA keep state pass in on em0 inet proto icmp from 192.168.100.0/24 to (em0) keep state pass in on em0 proto udp from any to (em0) port = 51820 keep state pass out all flags S/SA keep state&lt;/quote&gt;
    &lt;p&gt;Reload the rules:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # service pf reload Reloading pf rules.&lt;/quote&gt;
    &lt;p&gt;Now we can prepare to start WireGuard.&lt;/p&gt;
    &lt;head rend="h2"&gt;WireGuard Configuration&lt;/head&gt;
    &lt;p&gt;Everything is very simple here – create the keys, write the config file.&lt;/p&gt;
    &lt;head rend="h3"&gt;Creating Keys&lt;/head&gt;
    &lt;p&gt;Communication and cryptography in WireGuard are built on a standard asymmetric key scheme:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The private key is stored on the “server”&lt;/item&gt;
      &lt;item&gt;The public key is specified on the client&lt;/item&gt;
      &lt;item&gt;During the handshake, the client verifies it is connecting to the correct server whose public key it knows&lt;/item&gt;
      &lt;item&gt;Afterward, data encryption is performed using these keys&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See Key Exchange and Data Packets.&lt;/p&gt;
    &lt;p&gt;I’m putting the word “server” in quotes because, as mentioned earlier, WireGuard is P2P, not client-server.&lt;/p&gt;
    &lt;p&gt;After installing &lt;code&gt;wireguard-tools&lt;/code&gt;, the &lt;code&gt;/usr/local/etc/wireguard&lt;/code&gt; directory is created – navigate there and create the private and public keys using &lt;code&gt;wg genkey&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # cd /usr/local/etc/wireguard root@setevoy-nas:/usr/local/etc/wireguard # wg genkey | tee server.key | wg pubkey &amp;gt; server.pub&lt;/quote&gt;
    &lt;p&gt;Change the permissions for the private key:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/usr/local/etc/wireguard # chmod 600 server.key&lt;/quote&gt;
    &lt;p&gt;Verify:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/usr/local/etc/wireguard # ll total 12 -rw------- 1 root wheel 45 Dec 17 15:58 server.key -rw-r--r-- 1 root wheel 45 Dec 17 15:58 server.pub&lt;/quote&gt;
    &lt;head rend="h3"&gt;Basic WireGuard config&lt;/head&gt;
    &lt;p&gt;You can create several different configurations in &lt;code&gt;/usr/local/etc/wireguard/&lt;/code&gt;, each on its own port and/or IP and with its own key, to have multiple distinct VPN connections, managing them by filename – &lt;code&gt;wg0&lt;/code&gt;, &lt;code&gt;wg1&lt;/code&gt;, etc.&lt;/p&gt;
    &lt;p&gt;There are even config generators available – https://www.wireguardconfig.com.&lt;/p&gt;
    &lt;p&gt;Syntax documentation – Wireguard Configuration File Format.&lt;/p&gt;
    &lt;p&gt;Retrieve the private key:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/usr/local/etc/wireguard # cat server.key cLS***GQ=&lt;/quote&gt;
    &lt;p&gt;Create the file &lt;code&gt;/usr/local/etc/wireguard/wg0.conf&lt;/code&gt; – just the “server” for now:&lt;/p&gt;
    &lt;quote&gt;[Interface] Address = 10.8.0.1/24 ListenPort = 51820 PrivateKey = cLS***sGQ=&lt;/quote&gt;
    &lt;p&gt;The Interface block defines the parameters for the WireGuard interface &lt;code&gt;wg0&lt;/code&gt; – its IP address, UDP port, and the private key used for traffic encryption.&lt;/p&gt;
    &lt;p&gt;You can also specify which DNS to use, whether to update the routing tables on clients (default is true), and script execution with &lt;code&gt;PreUp&lt;/code&gt;, &lt;code&gt;PostUp&lt;/code&gt;, &lt;code&gt;PreDown&lt;/code&gt;, and &lt;code&gt;PostDown&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Start WireGuard itself:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # wg-quick up wg0 [#] ifconfig wg create name wg0 [#] wg setconf wg0 /dev/stdin [#] ifconfig wg0 inet 10.8.0.1/24 alias [#] ifconfig wg0 mtu 1420 [#] ifconfig wg0 up [+] Backgrounding route monitor&lt;/quote&gt;
    &lt;p&gt;Verify the interface:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # ifconfig wg0 wg0: flags=10080c1&amp;lt;UP,RUNNING,NOARP,MULTICAST,LOWER_UP&amp;gt; metric 0 mtu 1420 options=80000&amp;lt;LINKSTATE&amp;gt; inet 10.8.0.1 netmask 0xffffff00 groups: wg nd6 options=109&amp;lt;PERFORMNUD,IFDISABLED,NO_DAD&amp;gt;&lt;/quote&gt;
    &lt;p&gt;And the WireGuard status:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # wg show interface: wg0 public key: xLWA/FgF3LBswHD5Z1uZZMOiCbtSvDaUOOFjH4IF6W8= private key: (hidden) listening port: 51820&lt;/quote&gt;
    &lt;p&gt;Since we don’t have any clients yet – let’s move on to setting them up.&lt;/p&gt;
    &lt;head rend="h1"&gt;TP-Link Dynamic DNS and NAT port-forwarding&lt;/head&gt;
    &lt;p&gt;To connect from home to the FreeBSD host with WireGuard – add port forwarding on the office router:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;protocol: UDP&lt;/item&gt;
      &lt;item&gt;external port on the router: 51830 (to mask it slightly from bots)&lt;/item&gt;
      &lt;item&gt;forward to: 192.168.0.2 (the FreeBSD host)&lt;/item&gt;
      &lt;item&gt;forward to port: 51830 (WireGuard on &lt;code&gt;em0&lt;/code&gt;on FreeBSD)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On the TP-Link Archer AX12, it looks like this:&lt;/p&gt;
    &lt;p&gt;If the internet IP in the office is dynamic – the Archer AX12 has a Dynamic DNS setting:&lt;/p&gt;
    &lt;p&gt;Although mine is static, I set up DDNS out of interest using https://www.noip.com.&lt;/p&gt;
    &lt;head rend="h1"&gt;Running WireGuard on Arch Linux&lt;/head&gt;
    &lt;p&gt;On Linux, the process is identical – the modules are in the kernel, so we just need to install the package with the tools.&lt;/p&gt;
    &lt;p&gt;Check the modules:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/home/setevoy # lsmod | grep wireguard wireguard 122880 0 curve25519_x86_64 36864 1 wireguard libcurve25519_generic 45056 2 curve25519_x86_64,wireguard ip6_udp_tunnel 16384 1 wireguard udp_tunnel 32768 1 wireguard&lt;/quote&gt;
    &lt;p&gt;Install the package:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/home/setevoy # pacman -S wireguard-tools&lt;/quote&gt;
    &lt;p&gt;Navigate to &lt;code&gt;/etc/wireguard/&lt;/code&gt; and create the keys:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/home/setevoy # cd /etc/wireguard/ root@setevoy-home:/etc/wireguard # wg genkey | tee client1.key | wg pubkey &amp;gt; client1.pub&lt;/quote&gt;
    &lt;p&gt;Change the permissions for the private key:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # chmod 600 client1.key&lt;/quote&gt;
    &lt;p&gt;Now we can add Peers – clients.&lt;/p&gt;
    &lt;p&gt;To do this, we need to add keys on the client and the server:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;on the server: &lt;list rend="ul"&gt;&lt;item&gt;In &lt;code&gt;Interface&lt;/code&gt;–&lt;code&gt;PrivateKey&lt;/code&gt;: this is&lt;code&gt;/usr/local/etc/wireguard/server.key&lt;/code&gt;on the FreeBSD host&lt;/item&gt;&lt;item&gt;In &lt;code&gt;Peer&lt;/code&gt;–&lt;code&gt;PublicKey&lt;/code&gt;: this is&lt;code&gt;/etc/wireguard/client1.pub&lt;/code&gt;on the Arch Linux laptop&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;In &lt;/item&gt;
      &lt;item&gt;on the client: &lt;list rend="ul"&gt;&lt;item&gt;In &lt;code&gt;Interface&lt;/code&gt;–&lt;code&gt;PrivateKey&lt;/code&gt;: this is&lt;code&gt;/etc/wireguard/client1.key&lt;/code&gt;&lt;/item&gt;&lt;item&gt;In &lt;code&gt;Peer&lt;/code&gt;–&lt;code&gt;PublicKey&lt;/code&gt;: this is&lt;code&gt;/usr/local/etc/wireguard/server.pub&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;In &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Define the config **on the client**, file &lt;code&gt;/etc/wireguard/wg0.conf&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;[Interface] PrivateKey = 0Cu***UWU= Address = 10.8.0.3/24 [Peer] PublicKey = xLWA/FgF3LBswHD5Z1uZZMOiCbtSvDaUOOFjH4IF6W8= Endpoint = setevoy-***.ddns.me:51830 AllowedIPs = 10.8.0.1/32, 192.168.0.0/24 PersistentKeepalive = 25&lt;/quote&gt;
    &lt;p&gt;In &lt;code&gt;AllowedIPs&lt;/code&gt;, we specify the networks that will be accessible and added to the routing table (“Acts as a routing table and access control list“).&lt;/p&gt;
    &lt;p&gt;Start it on the client:&lt;/p&gt;
    &lt;quote&gt;[root@setevoy-wg-test setevoy]# wg-quick up wg0 [#] ip link add dev wg0 type wireguard [#] wg setconf wg0 /dev/fd/63 [#] ip -4 address add 10.8.0.3/24 dev wg0 [#] ip link set mtu 1420 up dev wg0 [#] ip -4 route add 10.8.0.3/32 dev wg0 [#] ip -4 route add 192.168.0.0/24 dev wg0&lt;/quote&gt;
    &lt;p&gt;Here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ip -4 address add&lt;/code&gt;: the&lt;code&gt;Interface - Address&lt;/code&gt;set for&lt;code&gt;wg0&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ip -4 route add 10.8.0.3/32&lt;/code&gt;and&lt;code&gt;192.168.0.0/24&lt;/code&gt;: new routes added via the&lt;code&gt;wg0&lt;/code&gt;interface for the VPN and office local networks&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Verify:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ip r s 10.8.0.0/24 10.8.0.0/24 dev wg0 proto kernel scope link src 10.8.0.3 root@setevoy-home:/etc/wireguard # ip r s 192.168.0.0/24 192.168.0.0/24 dev wg0 scope link&lt;/quote&gt;
    &lt;p&gt;Add the Peer **on the server**, the &lt;code&gt;/usr/local/etc/wireguard/wg0.conf&lt;/code&gt; file will now look like this:&lt;/p&gt;
    &lt;quote&gt;[Interface] Address = 10.8.0.1/24 ListenPort = 51820 PrivateKey = cLS***sGQ= [Peer] PublicKey = d7yqxOky4qOI/NTl/qbUnijfICwmbe/e/ulSVuQKLhk= AllowedIPs = 10.8.0.3/32, 192.168.100.0/24&lt;/quote&gt;
    &lt;p&gt;Restart:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/usr/local/etc/wireguard # wg-quick down wg0 [#] ifconfig wg0 destroy root@setevoy-nas:/usr/local/etc/wireguard # wg-quick up wg0 [#] ifconfig wg create name wg0 [#] wg setconf wg0 /dev/stdin [#] ifconfig wg0 inet 10.8.0.1/24 alias [#] ifconfig wg0 mtu 1420 [#] ifconfig wg0 up [#] route -q -n add -inet 10.8.0.2/32 -interface wg0 [+] Backgrounding route monitor&lt;/quote&gt;
    &lt;p&gt;Check the status on the client:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # wg show interface: wg0 public key: d7yqxOky4qOI/NTl/qbUnijfICwmbe/e/ulSVuQKLhk= private key: (hidden) listening port: 36864 peer: xLWA/FgF3LBswHD5Z1uZZMOiCbtSvDaUOOFjH4IF6W8= endpoint: 178.***.***.184:51830 allowed ips: 10.8.0.1/32, 192.168.0.0/24 latest handshake: 1 minute, 44 seconds ago transfer: 4.35 KiB received, 5.84 KiB sent persistent keepalive: every 25 seconds&lt;/quote&gt;
    &lt;p&gt;The most important thing to look for is “latest handshake” – it means the client has connected to the server.&lt;/p&gt;
    &lt;p&gt;Check on the server:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/home/setevoy # wg show interface: wg0 public key: xLWA/FgF3LBswHD5Z1uZZMOiCbtSvDaUOOFjH4IF6W8= private key: (hidden) listening port: 51820 peer: d7yqxOky4qOI/NTl/qbUnijfICwmbe/e/ulSVuQKLhk= endpoint: 178.***.***.236:56432 allowed ips: 192.168.100.0/24, 10.8.0.3/32 latest handshake: 15 seconds ago transfer: 1.69 KiB received, 3.87 KiB sent&lt;/quote&gt;
    &lt;p&gt;Verify SSH from the client to the server:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ssh [email protected] ([email protected]) Password for setevoy@setevoy-nas: ... FreeBSD 14.3-RELEASE (GENERIC) releng/14.3-n271432-8c9ce319fef7 Welcome to FreeBSD! ... setevoy@setevoy-nas:~ $&lt;/quote&gt;
    &lt;p&gt;Or:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-home ~]$ ssh 192.168.0.2 ([email protected]) Password for setevoy@setevoy-nas:&lt;/quote&gt;
    &lt;p&gt;Enable the &lt;code&gt;wg0&lt;/code&gt; profile on autostart:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-home ~]$ sudo systemctl enable wg-quick@wg0 Created symlink '/etc/systemd/system/multi-user.target.wants/[email protected]' → '/usr/lib/systemd/system/[email protected]'.&lt;/quote&gt;
    &lt;p&gt;At this point, almost everything is ready – access is established, and everything is working.&lt;/p&gt;
    &lt;p&gt;However, I also want to have direct access from the home laptop to the work laptop and vice versa, as the work laptop doesn’t have a VPN – it doesn’t need one because FreeBSD/NAS is in the same local network.&lt;/p&gt;
    &lt;head rend="h1"&gt;Cross-LAN access configuration&lt;/head&gt;
    &lt;p&gt;So what needs to be done is to set up direct access between the laptops in the home network (192.168.100.0/24) and the office network (192.168.0.0/24), because currently access between the work laptop and the home laptop doesn’t work.&lt;/p&gt;
    &lt;p&gt;The situation is currently as follows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Office laptop IP: 192.168.0.165&lt;/item&gt;
      &lt;item&gt;Home laptop IP: 192.168.100.205&lt;/item&gt;
      &lt;item&gt;No WireGuard on the work laptop&lt;/item&gt;
      &lt;item&gt;No connection from the office to the home laptop&lt;/item&gt;
      &lt;item&gt;No connection from home to the work laptop&lt;/item&gt;
      &lt;item&gt;Connection from home to FreeBSD exists&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Routing Table Setup&lt;/head&gt;
    &lt;p&gt;While setting this up – comment out &lt;code&gt;block all&lt;/code&gt; in &lt;code&gt;/etc/pf.conf&lt;/code&gt;; we’ll return to it later.&lt;/p&gt;
    &lt;p&gt;The result of what we’re about to do will look like this: the key is the routes. I’ve specifically made this as a diagram to make the following steps easier to understand:&lt;/p&gt;
    &lt;p&gt;Check the routes from the home laptop to FreeBSD:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ip route get 192.168.0.2 192.168.0.2 dev wg0 src 10.8.0.3 uid 0&lt;/quote&gt;
    &lt;p&gt;And to the work laptop:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ip route get 192.168.0.165 192.168.0.165 dev wg0 src 10.8.0.3 uid 0&lt;/quote&gt;
    &lt;p&gt;Traffic goes through &lt;code&gt;wg0&lt;/code&gt;, and the Source Address for the packet is set as &lt;code&gt;10.8.0.3&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;However, on the work laptop, the route to the home laptop goes through 192.168.0.1:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ ip route get 192.168.100.205 192.168.100.205 via 192.168.0.1 dev wlan0 src 192.168.0.165 uid 1000&lt;/quote&gt;
    &lt;p&gt;Here, 192.168.0.1 is the default gateway, the office router, which knows nothing about the home network 192.168.100.0/24.&lt;/p&gt;
    &lt;p&gt;So first – add a route to the home network via the FreeBSD host:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ sudo ip route add 192.168.100.0/24 via 192.168.0.2&lt;/quote&gt;
    &lt;p&gt;Check again:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ ip route get 192.168.100.205 192.168.100.205 via 192.168.0.2 dev wlan0 src 192.168.0.165 uid 1000&lt;/quote&gt;
    &lt;p&gt;Now there is contact from the office to home:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ ping 192.168.100.205 -c 1 PING 192.168.100.205 (192.168.100.205) 56(84) bytes of data. 64 bytes from 192.168.100.205: icmp_seq=1 ttl=63 time=62.0 ms --- 192.168.100.205 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;/quote&gt;
    &lt;p&gt;But from home, it still doesn’t work, because from home we send:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;from the home laptop with IP 192.168.100.205 &lt;list rend="ul"&gt;&lt;item&gt;through FreeBSD with IP 192.168.0.2 &lt;list rend="ul"&gt;&lt;item&gt;to the work laptop with IP 192.168.0.165&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;through FreeBSD with IP 192.168.0.2 &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But from the home laptop, the Source IP is set as &lt;code&gt;10.8.0.3&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ip route get 192.168.0.165 192.168.0.165 dev wg0 src 10.8.0.3 uid 0&lt;/quote&gt;
    &lt;p&gt;Because the route to 192.168.0.0/24 is specified via the VPN interface &lt;code&gt;wg0&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ip r s 192.168.0.0/24 192.168.0.0/24 dev wg0 scope link&lt;/quote&gt;
    &lt;p&gt;And &lt;code&gt;wg0&lt;/code&gt; has the IP 10.8.0.3:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ip a s wg0 20: wg0: &amp;lt;POINTOPOINT,NOARP,UP,LOWER_UP&amp;gt; mtu 1420 qdisc noqueue state UNKNOWN group default qlen 1000 link/none inet 10.8.0.3/24 scope global wg0&lt;/quote&gt;
    &lt;p&gt;The work laptop knows nothing about the 10.8.0.0/24 network and cannot return a response.&lt;/p&gt;
    &lt;p&gt;So, add another route on the work laptop:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ sudo ip route add 10.8.0.0/24 via 192.168.0.2 dev wlan0&lt;/quote&gt;
    &lt;p&gt;Verify:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ ip r s 10.8.0.0/24 10.8.0.0/24 via 192.168.0.2 dev wlan0&lt;/quote&gt;
    &lt;p&gt;And now there is also access from the home laptop to the work laptop:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ping -c1 192.168.0.165 PING 192.168.0.165 (192.168.0.165) 56(84) bytes of data. 64 bytes from 192.168.0.165: icmp_seq=1 ttl=63 time=6.19 ms --- 192.168.0.165 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;/quote&gt;
    &lt;p&gt;To make these routes permanent – you can do it via NetworkManager CLI.&lt;/p&gt;
    &lt;p&gt;Delete the ones added manually:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ sudo ip route del 10.8.0.0/24 via 192.168.0.2 [setevoy@setevoy-work ~] $ sudo ip route del 192.168.100.0/24 via 192.168.0.2&lt;/quote&gt;
    &lt;p&gt;Find the connection name:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ nmcli connection show NAME UUID TYPE DEVICE setevoy-tp-link-21-5 3a12a60d-7b37-4c20-b573-d27c47a94ae5 wifi wlan0 ...&lt;/quote&gt;
    &lt;p&gt;Add the routes:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ nmcli connection modify setevoy-tp-link-21-5 +ipv4.routes "10.8.0.0/24 192.168.0.2,192.168.100.0/24 192.168.0.2"&lt;/quote&gt;
    &lt;p&gt;Verify:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ nmcli connection show setevoy-tp-link-21-5 | grep ipv4.routes ipv4.routes: { ip = 10.8.0.0/24, nh = 192.168.0.2 }; { ip = 192.168.100.0/24, nh = 192.168.0.2 }&lt;/quote&gt;
    &lt;p&gt;Restart the connection:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ sudo nmcli connection down setevoy-tp-link-21-5 &amp;amp;&amp;amp; sudo nmcli connection up setevoy-tp-link-21-5 Connection 'setevoy-tp-link-21-5' successfully deactivated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/15) Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/16)&lt;/quote&gt;
    &lt;p&gt;Check the routes now:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ ip route get 10.8.0.3 10.8.0.3 via 192.168.0.2 dev wlan0 src 192.168.0.165 uid 1000 [setevoy@setevoy-work ~] $ ip route get 192.168.100.205 192.168.100.205 via 192.168.0.2 dev wlan0 src 192.168.0.165 uid 1000&lt;/quote&gt;
    &lt;p&gt;Now we have &lt;code&gt;ping&lt;/code&gt; from the office laptop to the home laptop:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ ping -c1 192.168.100.205 PING 192.168.100.205 (192.168.100.205) 56(84) bytes of data. 64 bytes from 192.168.100.205: icmp_seq=1 ttl=63 time=5.95 ms --- 192.168.100.205 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;/quote&gt;
    &lt;p&gt;And from home to the work laptop:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ping -c1 192.168.0.165 PING 192.168.0.165 (192.168.0.165) 56(84) bytes of data. 64 bytes from 192.168.0.165: icmp_seq=1 ttl=63 time=5.67 ms --- 192.168.0.165 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;/quote&gt;
    &lt;head rend="h2"&gt;Packet Filter Configuration&lt;/head&gt;
    &lt;p&gt;However, if we enable &lt;code&gt;block all&lt;/code&gt; in &lt;code&gt;pf&lt;/code&gt;, the connection from the office to the home laptop will break, because we currently only have rules for the FreeBSD host:&lt;/p&gt;
    &lt;quote&gt;... # allow SSH from Office LAN (192.168.0.0/24) to FreeBSD host pass in log on em0 proto tcp from 192.168.0.0/24 to (em0) port 22 keep state ... # allow ICMP (ping) from Home network to FreeBSD host pass in on em0 proto icmp from 192.168.100.0/24 to (em0) keep state ...&lt;/quote&gt;
    &lt;p&gt;Here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The first rule – allows SSH from the office network to the IP of the &lt;code&gt;em0&lt;/code&gt;interface on the FreeBSD host&lt;/item&gt;
      &lt;item&gt;The second rule – allows ping from the home network to the IP of the &lt;code&gt;em0&lt;/code&gt;interface on the FreeBSD host&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, let’s add two more rules – for SSH and ping from the office to the home network:&lt;/p&gt;
    &lt;quote&gt;... # allow SSH from Office network to Home network pass in on em0 proto tcp from 192.168.0.0/24 to 192.168.100.0/24 port 22 keep state ... # allow ICMP from Home network to Office network pass in on em0 proto icmp from 192.168.0.0/24 to 192.168.100.0/24 keep state ...&lt;/quote&gt;
    &lt;p&gt;Verify and reload the &lt;code&gt;pf&lt;/code&gt; config:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-nas:/usr/local/etc/wireguard # pfctl -vnf /etc/pf.conf &amp;amp;&amp;amp; service pf reload set skip on { lo } block drop log all pass in log on em0 inet proto tcp from 192.168.0.0/24 to (em0) port = ssh flags S/SA keep state pass in log on em0 inet proto tcp from 192.168.100.0/24 to (em0) port = ssh flags S/SA keep state pass in on wg0 inet from 10.8.0.0/24 to (wg0) flags S/SA keep state pass in on wg0 inet proto icmp from 10.8.0.0/24 to (wg0) keep state pass in on wg0 inet from 10.8.0.0/24 to 192.168.0.0/24 flags S/SA keep state pass in on wg0 inet from 10.8.0.0/24 to 192.168.100.0/24 flags S/SA keep state pass in on em0 inet proto tcp from 192.168.0.0/24 to 192.168.100.0/24 port = ssh flags S/SA keep state pass in on em0 inet proto icmp from 192.168.0.0/24 to 192.168.100.0/24 keep state pass in on em0 proto udp from any to (em0) port = 51820 keep state pass out all flags S/SA keep state Reloading pf rules.&lt;/quote&gt;
    &lt;p&gt;And now we have ping from home to the office:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ping -c1 192.168.0.165 PING 192.168.0.165 (192.168.0.165) 56(84) bytes of data. 64 bytes from 192.168.0.165: icmp_seq=1 ttl=63 time=8.09 ms --- 192.168.0.165 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;/quote&gt;
    &lt;p&gt;SSH from home to the office:&lt;/p&gt;
    &lt;quote&gt;root@setevoy-home:/etc/wireguard # ssh 192.168.0.165 [email protected]'s password:&lt;/quote&gt;
    &lt;p&gt;Ping from the office to home:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ ping -c1 192.168.100.205 PING 192.168.100.205 (192.168.100.205) 56(84) bytes of data. 64 bytes from 192.168.100.205: icmp_seq=1 ttl=63 time=60.5 ms --- 192.168.100.205 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms&lt;/quote&gt;
    &lt;p&gt;And SSH from the office to home:&lt;/p&gt;
    &lt;quote&gt;[setevoy@setevoy-work ~] $ ssh 192.168.100.205 [email protected]'s password:&lt;/quote&gt;
    &lt;p&gt;Everything is working.&lt;/p&gt;
    &lt;p&gt;The full &lt;code&gt;/etc/pf.conf&lt;/code&gt; is now as follows:&lt;/p&gt;
    &lt;quote&gt;################## ### Interfaces ### ################## # lan_if = "em0" # wg_if = "wg0" ################ ### Networks ### ################ # lan_net = "192.168.0.0/24" # home_net = "192.168.100.0/24" # wg_net = "10.8.0.0/24" # vpn_nets = "{ 10.8.0.0/24, 192.168.100.0/24 }" ################ ### Services ### ################ # ssh_ports = "{ 22 }" # wg_port = "51820" ###################### ### Basic settings ### ###################### # do not filter loopback traffic set skip on lo ###################### ### Default policy ### ###################### # block everything by default block log all ####################### ### Inbound traffic ### ####################### ### SSH # allow SSH from Office LAN (192.168.0.0/24) to FreeBSD host pass in log on em0 proto tcp from 192.168.0.0/24 to (em0) port 22 keep state # allow SSH from Home network (192.168.100.0/24) to FreeBSD host pass in log on em0 proto tcp from 192.168.100.0/24 to (em0) port 22 keep state # allow SSH from VPN clients to FreeBSD host pass in on wg0 proto tcp from 10.8.0.0/24 to (wg0) port 22 keep state ### NEW # allow SSH from Office netwrok to Home network pass in on em0 proto tcp from 192.168.0.0/24 to 192.168.100.0/24 port 22 keep state ### TEST # allow Office LAN to reach Home LAN via WireGuard #pass in on em0 from 192.168.0.0/24 to 192.168.100.0/24 keep state #pass out on wg0 from 192.168.0.0/24 to 192.168.100.0/24 keep state # allow Home LAN to reach Office LAN via WireGuard #pass in on wg0 from 192.168.100.0/24 to 192.168.0.0/24 keep state #pass out on em0 from 192.168.100.0/24 to 192.168.0.0/24 keep state ### VPN # allow WireGuard handshake (UDP/51820) on LAN interface pass in on em0 proto udp to (em0) port 51820 keep state # allow VPN clients (10.8.0.0/24) to access FreeBSD host itself # this allows ping, ssh, etc. to the wg0 address pass in on wg0 from 10.8.0.0/24 to (wg0) keep state # allow VPN clients to access Office LAN (192.168.0.0/24) pass in on wg0 from 10.8.0.0/24 to 192.168.0.0/24 keep state # allow VPN clients to access Home network (192.168.100.0/24) pass in on wg0 from 10.8.0.0/24 to 192.168.100.0/24 keep state # #pass in on em0 from 192.168.0.0/24 to 192.168.100.0/24 keep state #pass in on wg0 from 192.168.100.0/24 to 192.168.0.0/24 keep state ### ICMP # allow ICMP from VPN clients to FreeBSD host pass in on wg0 proto icmp from 10.8.0.0/24 to (wg0) keep state # allow ICMP from Home network to FreeBSD host #pass in on em0 proto icmp from 192.168.100.0/24 to (em0) keep state # allow ICMP from Home network to Office network pass in on em0 proto icmp from 192.168.0.0/24 to 192.168.100.0/24 keep state ############################ ### outbound traffic ### ############################ # allow all outbound traffic from FreeBSD pass out keep state&lt;/quote&gt;
    &lt;p&gt;Active connections in &lt;code&gt;pftop&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;In 192.168.0.165:50286&lt;/code&gt;=&amp;gt;&lt;code&gt;192.168.0.2:22&lt;/code&gt;: SSH from work laptop to FreeBSD&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;In 178.***.***.236:56432&lt;/code&gt;=&amp;gt;&lt;code&gt;192.168.0.2:51820&lt;/code&gt;: connection from home via NAT Port-forwarding on the office router to VPN on FreeBSD&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;In 10.8.0.3:39442&lt;/code&gt;=&amp;gt;&lt;code&gt;192.168.0.165:22&lt;/code&gt;: SSH from home to the work laptop&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Out 10.8.0.1:50589&lt;/code&gt;=&amp;gt;&lt;code&gt;10.8.0.3:22&lt;/code&gt;: SSH from FreeBSD to the home laptop&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;P.S. What an absolute blast – this “traditional networking” instead of all those AWS VPCs and their subnets…&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46487120</guid><pubDate>Sun, 04 Jan 2026 11:55:34 +0000</pubDate></item><item><title>A New Year's letter to a young person</title><link>https://www.siliconcontinent.com/p/a-new-years-letter-to-a-young-person</link><description>&lt;doc fingerprint="3e519a1d2d3496ee"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A New Year’s letter to a young person&lt;/head&gt;
    &lt;head rend="h3"&gt;Take the messy job&lt;/head&gt;
    &lt;p&gt;I am often approached by students and other young people for advice about their careers. In the past, my answers were often based on a piece of advice I myself got from Bengt Holmstrom: “when in doubt, choose the job where you will learn more.” In the last few years, there is a new variable to consider: the likelihood that artificial intelligence will automate all or large pieces of the job you do. Given that, what should a student choose today? The answers below are motivated by a book on artificial intelligence and the organization of work on which I am currently working with Jin Li and Yanhui Wu.&lt;/p&gt;
    &lt;p&gt;One way of thinking about this is that all knowledge work varies along one important spectrum: messiness. On one end, there is one defined task to execute, say helping clients fill their taxes. You get the expenses and payslips on email, you use some rules to put them on a form, you obtain a response. Over time, you become better at this task, and get a higher salary. On the other end of the spectrum, there is a wide bundle of complex tasks. Running a factory, or a family, involves many different tasks that are very hard to specify in advance.&lt;/p&gt;
    &lt;p&gt;The risk of the single-task job is that artificial intelligence excels at single tasks. Humans are still often in the loop, since the rate of errors in many fields is still too high to allow for unsupervised artificial intelligence. But the rate of errors is rapidly decreasing.&lt;/p&gt;
    &lt;p&gt;You may bet that fields vary in their tolerance for errors. Certain simple tasks, like content moderation, involve a high tolerance for risk: tech companies are comfortable with ‘shooting first, asking questions later’. But many others, from diagnostics to corporate communications, involve extreme risk-aversion on the part of the customer.&lt;/p&gt;
    &lt;p&gt;As long as a human is still needed to check the outputs, some value accrues to them. If AI drafts a contract that a lawyer reviews, signs, and takes responsibility for, the lawyer remains the supplier of legal services.&lt;/p&gt;
    &lt;p&gt;But the models are continuously getting much, much better at single tasks. If there aren’t any legal requirements to keep humans in the loop, even risk averse fields will eventually switch to unsupervised AI. When AI can produce finished code for straightforward tasks without human intervention, junior developers who once supplied that work compete with systems that produce it nearly free. The supply of programming services is no longer limited by human time, and the price of the service collapses to 0.&lt;/p&gt;
    &lt;p&gt;The result is that workers with simple tasks will become continuously more productive (and richer), until their work is worth nothing. A junior customer support agent gets more and more effective while the AI provides her the accumulated knowledge of senior customer support agents, as in the recent Brynjolfsson, Li; Ramond (2025) paper, until the AI is good enough that she can be replaced.&lt;/p&gt;
    &lt;p&gt;Notice that the autonomy threshold is not just given by technology. Firms and governments have a huge say in this, and they may choose to block adoption. The pressure to adopt better technology is strong, but do not overestimate it. Remember that many European countries still de facto ban Uber (don’t get my friend Nicolas Petit started about getting a cab in Florence!), despite the enormous quality of life improvement over traditional taxi monopoly, and that notaries are not a requirement of current technology, but a legal constraint that their strong lobby will always protect in continental legal systems. Even the most single-tasked civil servants will still have a job for a long time.&lt;/p&gt;
    &lt;p&gt;The end of work? Not so fast&lt;/p&gt;
    &lt;p&gt;The other option is to go for a messy job, where the output is the product of many different tasks, many of which affect each other.&lt;/p&gt;
    &lt;p&gt;The head of engineering at a manufacturing plant I know well must decide who to hire, which machines to buy, how to lay them down in the plant, negotiate with the workers and the higher ups the solutions proposed, and mobilise the resources to implement them. That task is extraordinarily hard to automate. Artificial intelligence commoditizes codified knowledge: textbooks, proofs, syntax. But it does not interface in a meaningful way with local knowledge, where a much larger share of the value of messy jobs is created. Even if artificial intelligence excelled at most of the single tasks that make up her job, it could not walk the factory floor to cajole a manager to redesign a production process.&lt;/p&gt;
    &lt;p&gt;A management consultant whose job consists entirely of producing slide decks is exposed. A consultant who spends half of her time reading the room, building client relationships, and navigating organizational politics has a bundle AI cannot replicate.&lt;/p&gt;
    &lt;p&gt;In 2016, star AI researcher Geoffrey Hinton leaped from automation of reading scans to the automation of the full radiologist job, and gave the advice to stop training radiologists.1 But even fields that can look simple from the outside, like radiology, can be quite messy. A small study from 2013 (cited in this Works in Progress article) found that radiologists only spend 36 percent of their time looking at scans. The rest is spent talking to patients, training others, and talking with the nurses and doctors treating the patient.&lt;/p&gt;
    &lt;p&gt;A radiologist’s job is a bundle. You can automate reading scans and still need a radiologist. The question is not whether AI can do one part of your job. It is whether the remaining parts cohere in a manner that justifies a role.&lt;/p&gt;
    &lt;p&gt;To me, a key characteristic of these “messy jobs” is execution. Execution is hard because it faces the friction of the real world. Consider a general contractor on a building site. Artificial intelligence can sketch a blueprint and calculate load-bearing requirements in seconds. That is codified knowledge. But the contractor must handle the delivery of lumber that arrived late, the ground that is too muddy to pour concrete, or the bickering between the electrician and the plumber.&lt;/p&gt;
    &lt;p&gt;Or consider the manager in charge of post-merger integration at a corporation. Again, the algorithm will map financial synergies and redraw org charts, but it will not have the “tribal” knowledge required to merge two distinct cultures and have the tact to prevent an exodus.&lt;/p&gt;
    &lt;p&gt;Corporate law is increasingly vulnerable to automation because contracts are essentially code, but I would expect trial attorneys to subsist.&lt;/p&gt;
    &lt;p&gt;AI implementation itself could be the ultimate messy job. Improvements will require drastically changing existing workflows, a process that will be resisted by internal politics, fear, and legacy business models. For instance, law firms have always relied on “billable hours” to charge clients, a concept that will be useless in an AI world. But this organizational inertia is a gift: the transformation will be messier and more delayed than the charts suggest and it will require a lot of consultants, managers and workers, well versed in what AI can do, but with sufficient domain knowledge to know how to use it and how to redefine the process.&lt;/p&gt;
    &lt;p&gt;In the extreme instances, the feared AI transformation may not take place. Jobs defined by empathy, care, and real-time judgment will become the economy’s ‘luxury goods.’ In these fields, artificial intelligence is not your competitor; it generates the wealth (and lowers the costs of goods and services) that will fund your higher wages.2&lt;/p&gt;
    &lt;p&gt;More leverage&lt;/p&gt;
    &lt;p&gt;Usually, better companies are not created by transforming old ones, but by starting new ones. Starting a firm is the messiest job in the world, and artificial intelligence gives you a lot more opportunity to compete head on with larger companies..&lt;/p&gt;
    &lt;p&gt;For a century, large organizations dominated because only they could afford the fixed costs of specialized functions. If you needed both engineering and marketing, you needed scale to justify the overhead. AI reduces both the fixed and variable costs of that specialization. A single professional can now relinquish supporting tasks to AI and operate as a generalist. In a world where single tasks in areas like HR and finance are automated, you can ride a good idea all the way to a large company.&lt;/p&gt;
    &lt;p&gt;In our new book, we write about Base44, an AI-powered app builder. Founded by Maor Shlomo, a 31-year-old Israeli programmer, the company was built as a side project. He invested about $15,000 of his own money. He hired no employees, and he used Claude to write 90 percent of his frontend code and push updates daily, without any of the overhead that bogs down traditional engineering.&lt;/p&gt;
    &lt;p&gt;Within six months, Base44 had attracted over 250,000 users, generated $189,000 in monthly profit, and signed partnerships with major companies. Wix acquired it for $80 million.&lt;/p&gt;
    &lt;p&gt;Shlomo had no sales team, no marketing department, no HR. The tasks that once demanded human specialists were absorbed by the technology.&lt;/p&gt;
    &lt;p&gt;Conclusion&lt;/p&gt;
    &lt;p&gt;Given all the above, several investments appear to matter if you want to engage in careers in knowledge-intensive work (as opposed to the many crafts and trades, such as hair-dressing, plumbing, playing piano or being a chef, that are likely to remain untouched for a long time):&lt;/p&gt;
    &lt;p&gt;First, build deep, substantive knowledge in your field. As models get better, fewer humans will be good enough to add any value at all. Artificial intelligence can predict that a scan shows a tumor with 94 percent probability. But should the patient undergo surgery, radiation, or wait and monitor it? That decision depends on tradeoffs, some of which the algorithm cannot weigh. To exercise this type of judgment in a helpful way, you must know a domain deeply.&lt;/p&gt;
    &lt;p&gt;Deep domain knowledge will also make you good at AI implementation. Being able to change a given company’s processes to take advantage of the new technology is likely to employ a large number of people for a very long time.&lt;/p&gt;
    &lt;p&gt;Second, openness to new experiences, and the ability to learn new things quickly, will become even more important than it already is. Choose the job where you will learn most, but also the one where you will learn to learn. You will have to reinvent yourself throughout your life. New jobs will appear that we have not even imagined. If knowledge is the largest constraint that we face, then cheap knowledge will change everything, from medicine or the law to every field of research. The specific knowledge you learn today will depreciate faster than ever. What matters is the slope of your learning curve and your ability to adapt. For instance, in a job such as an early-stage founder or first employee, you do not have a fixed role; you have a set of problems. You must learn enough law or sales by the afternoon to survive, distinguishing essential signals from noise. Or, as a management consultant, you enter a room where everyone knows more than you, so you must absorb a new industry’s logic in days to structure vague problems. In tech, the role of product manager sits between the engineers and the sellers as a translator.&lt;/p&gt;
    &lt;p&gt;Third, seek leverage. In the past, your output was limited by your time—a chef can only cook for so many people. AI breaks this constraint. It allows a single writer, coder, or entrepreneur to serve a global market without a massive support staff. The constraint is no longer your production capacity; it is your ability to direct the machine. There is never been a better time to undertake entrepreneurial projects.&lt;/p&gt;
    &lt;p&gt;Fourth, if you do want to do a task that can plausibly be done by a model, location is more important than ever. A small number of cities, starting with San Francisco, Paris, London, and New York, are where almost everyone working and thinking about artificial intelligence is based. Go to these cities, or the closest approximation of them available to you, not just to work on these problems but to understand what possibilities may come your way.&lt;/p&gt;
    &lt;p&gt;Fifth, install Twitter. Twitter is a huge time sink, but it is also where all progress is happening, out in the open. You will have a huge advantage over virtually everyone not on the platform in understanding what is happening.&lt;/p&gt;
    &lt;p&gt;Sixth, learn to supervise the machine. The essential new skill is meta-cognition: recognizing when the AI is hallucinating, directing it toward the right problems, and verifying its outputs.&lt;/p&gt;
    &lt;p&gt;Finally, if all of these changes in the nature of work do happen, we are going to have much more leisure. In a recent paper, Betsy Stevenson points to the Japanese concept of ikigai, “that which makes life worth living”. The ability to derive meaning from sources other than your work is itself a form of human capital. Try to cultivate the habit of reading fiction. Try to spend less time watching videos and other forms of TV. Pick up hobbies: the hobby I would recommend most is starting a blog!&lt;/p&gt;
    &lt;p&gt;Happy new year and thanks for reading Silicon Continent!&lt;/p&gt;
    &lt;p&gt;“If you work as a radiologist you're like the coyote that's already over the edge of the cliff but hasn't yet looked down so doesn't realize there's no ground underneath him. People should stop training Radiologists now it's just completely obvious that within 5 years deep learning is going to do better than Radiologists.” 2016 Machine Learning and Market for Intelligence Conference in Toronto.&lt;/p&gt;
    &lt;p&gt;Without it, the future is stagnation or (given the adverse demographic situation) worse. So “Oh, let’s turn the whole economy into a Baumol economy” is not a solution.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46487276</guid><pubDate>Sun, 04 Jan 2026 12:20:19 +0000</pubDate></item><item><title>Nightshade: Make images unsuitable for model training</title><link>https://nightshade.cs.uchicago.edu/whatis.html</link><description>&lt;doc fingerprint="3053a434e9bc15f1"&gt;
  &lt;main&gt;
    &lt;p&gt;A simple, powerful Bash script to batch download and organize YouTube playlists by channel name using &lt;code&gt;yt-dlp&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Organized Structure: Creates separate directories for each channel.&lt;/item&gt;
      &lt;item&gt;Smart Sync: Skips files that have already been downloaded (&lt;code&gt;--no-overwrites&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Clean Naming: Saves files as &lt;code&gt;Playlist Title/Video Title.mp4&lt;/code&gt;(no numeric prefixes).&lt;/item&gt;
      &lt;item&gt;Batch Processing: Reads multiple playlists from a &lt;code&gt;playlists.txt&lt;/code&gt;file.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;yt-dlp: Make sure you have yt-dlp installed.&lt;/item&gt;
      &lt;item&gt;FFmpeg: Required for merging video and audio streams.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/Linuxmaster14/yt-playlist-downloader.git
cd yt-playlist-downloader
chmod +x download_playlists.sh
./download_playlists.sh&lt;/code&gt;
    &lt;p&gt;1. Add your playlists: Edit &lt;code&gt;playlists.txt&lt;/code&gt; and add your channels and playlist URLs in the format:&lt;/p&gt;
    &lt;code&gt;Channel Name|PlaylistURL
&lt;/code&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;Linux Tips|https://www.youtube.com/playlist?list=PLT98CRl2KxKF26ekyZUT_XtQ9HPciZKHX
&lt;/code&gt;
    &lt;p&gt;2. Cookies Place your &lt;code&gt;cookies.txt&lt;/code&gt; file in the same directory.
How do I pass cookies to yt-dlp?&lt;/p&gt;
    &lt;p&gt;You can customize the script by editing the variables at the top of &lt;code&gt;download_playlists.sh&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46487342</guid><pubDate>Sun, 04 Jan 2026 12:32:30 +0000</pubDate></item><item><title>YouTube Playlist Downloader</title><link>https://github.com/Linuxmaster14/yt-playlist-downloader</link><description>&lt;doc fingerprint="3053a434e9bc15f1"&gt;
  &lt;main&gt;
    &lt;p&gt;A simple, powerful Bash script to batch download and organize YouTube playlists by channel name using &lt;code&gt;yt-dlp&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Organized Structure: Creates separate directories for each channel.&lt;/item&gt;
      &lt;item&gt;Smart Sync: Skips files that have already been downloaded (&lt;code&gt;--no-overwrites&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Clean Naming: Saves files as &lt;code&gt;Playlist Title/Video Title.mp4&lt;/code&gt;(no numeric prefixes).&lt;/item&gt;
      &lt;item&gt;Batch Processing: Reads multiple playlists from a &lt;code&gt;playlists.txt&lt;/code&gt;file.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;yt-dlp: Make sure you have yt-dlp installed.&lt;/item&gt;
      &lt;item&gt;FFmpeg: Required for merging video and audio streams.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/Linuxmaster14/yt-playlist-downloader.git
cd yt-playlist-downloader
chmod +x download_playlists.sh
./download_playlists.sh&lt;/code&gt;
    &lt;p&gt;1. Add your playlists: Edit &lt;code&gt;playlists.txt&lt;/code&gt; and add your channels and playlist URLs in the format:&lt;/p&gt;
    &lt;code&gt;Channel Name|PlaylistURL
&lt;/code&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;Linux Tips|https://www.youtube.com/playlist?list=PLT98CRl2KxKF26ekyZUT_XtQ9HPciZKHX
&lt;/code&gt;
    &lt;p&gt;2. Cookies Place your &lt;code&gt;cookies.txt&lt;/code&gt; file in the same directory.
How do I pass cookies to yt-dlp?&lt;/p&gt;
    &lt;p&gt;You can customize the script by editing the variables at the top of &lt;code&gt;download_playlists.sh&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46487351</guid><pubDate>Sun, 04 Jan 2026 12:34:14 +0000</pubDate></item><item><title>Moiré Explorer</title><link>https://play.ertdfgcvb.xyz/#/src/demos/moire_explorer</link><description>&lt;doc fingerprint="250dfc665464f02e"&gt;
  &lt;main&gt;
    &lt;p&gt;ASCII play a project by ertdfgcvb About/Manual Run Cmd+Enter Immediate mode Cmd+I Toggle view Cmd+Period Fullscreen Cmd+Shift+F Copy a frame Cmd+Shift+C Save Cmd+S Share Cmd+Shift+U Download script L.S.D. Examples basics 10 PRINT Coordinates: index Coordinates: x, y Cursor How to draw a circle How to draw a square How to log Name game Perfomance test Canvas renderer Sequence export Simple output Time: frames Time: milliseconds sdf Balls Circle Wireframe cube Rectangles Two circles demos Box fun Chroma Spiral Donut Doom Flame Doom Flame (full color) Dyna Golgol Hotlink Mod Xor MoirÃ© explorer Numbers Plasma Sin Sin Sin Sin Spiral Wobbly camera Camera double resolution Camera grayscale Camera RGB contributed Color Waves Emoji Wave EQUAL TEA TALK, #65 oeÃ¶ GOL Pathfinder Sand game Slime Dish Stacked sin waves&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46487472</guid><pubDate>Sun, 04 Jan 2026 12:54:20 +0000</pubDate></item><item><title>Jeffgeerling.com has been Migrated to Hugo</title><link>https://www.jeffgeerling.com/blog/2026/migrated-to-hugo/</link><description>&lt;doc fingerprint="10501d1109842718"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;JeffGeerling.com has been Migrated to Hugo&lt;/head&gt;
    &lt;p&gt;Since 2009, this website has run on Drupal. Starting with Drupal 6, and progressing through major site upgrades and migrations to 7, 8, 9, and 10, I used the site as a way to dogfood the same CMS (Content Management System) I used in my day job for over a decade.&lt;/p&gt;
    &lt;p&gt;But as time progressedâespecially after completing a grueling upgrade from Drupal 7 to 8âmy enthusiasm for maintaining what's now a more enterprise-focused Digital Experience Platform or 'DXP' for a personal blog has waned.&lt;/p&gt;
    &lt;p&gt;Not to mention, the blog is a passion project. I use it as a scratchpad for thoughts, and deeper dives for my YouTube videos. Time spent maintaining a complex CMS is time I can't spend actually writing (not to mention time spent on everything else in life!).&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Hugo?&lt;/head&gt;
    &lt;p&gt;I've moved other hobby sites to static hosting. For older sites I don't actively update, I scrape and mothball them. But for sites I wanted to keep active, I converted them to Jekyll or Hugo, both of which are competent and full-featured modern SSGs (Static Site Generators).&lt;/p&gt;
    &lt;p&gt;Jekyll is perfect for the static sites I host for free on GitHub Pages, like the Raspberry Pi PCIe Database or Project MINI RACK, but I'm not a Ruby programmer, so I like Hugo for anything I run on my own infrastructure (like Geerling Engineering). It's simpler to set up and a little faster.&lt;/p&gt;
    &lt;head rend="h2"&gt;Housekeeping&lt;/head&gt;
    &lt;p&gt;Anyway, I've been working on the migration in this GitHub issue, and there are bound to be mistakes, broken image references, and probably some old URLs that just go poof!&lt;/p&gt;
    &lt;p&gt;I try to keep everything where it is, or add redirects. But with 20 years of baggage and 3500+ posts (many of those were individual photos converted into 'blog' nodes in a prior upgrade... oops!), it's hard to run a perfect migration.&lt;/p&gt;
    &lt;head rend="h2"&gt;Markdown Workflow&lt;/head&gt;
    &lt;p&gt;I've been writing all my posts in Markdown since 2020, and even before that, was drafting them in Markdown in Sublime Text, then exporting that to HTML via MarkdownPreview.&lt;/p&gt;
    &lt;p&gt;So having a tool (Hugo) that uses Markdown natively is a breath of fresh air.&lt;/p&gt;
    &lt;p&gt;Beyond that, I've grown fond of 'sticking to the defaults' over the years. On my initial Drupal 6 site, I installed something like 30 modules (plugins in Drupal parlance), but almost all of those modules bit me in one way or another as I upgraded to Drupal 7, 8, 9, or 10...&lt;/p&gt;
    &lt;p&gt;Honestly, upgrading from 8 to 9 to 10 was easier than 6 to 7 and 7 to 8, simply because I had stripped my site down to the basics.&lt;/p&gt;
    &lt;p&gt;However, in so doing, I also made my content authoring experience a bit horrid:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Write a blog post on my computer in a Markdown file&lt;/item&gt;
      &lt;item&gt;Create new unpublished Drupal blog post&lt;/item&gt;
      &lt;item&gt;Paste the Markdown content into the body and add a title&lt;/item&gt;
      &lt;item&gt;Individually upload each picture&lt;/item&gt;
      &lt;item&gt;Put cursor where each picture goes in the content, scroll down to the uploaded picture, click 'Insert' to insert the preformatted &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;markup, and rinse-and-repeat for all images (sometimes up to 25-30 per post!).&lt;/item&gt;
      &lt;item&gt;Clear out the 'Authored on' field to make sure the date would update when I publish the post&lt;/item&gt;
      &lt;item&gt;Toggle the 'Published' option and save the node&lt;/item&gt;
      &lt;item&gt;Run an Ansible playbook to drop Drupal caches, Nginx caches, and trigger a Cloudflare purge of the relevant URLs (ongoing DDoSes since 2022 caused me to really lock down my caching)...&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It was a lot. Just to publish a blog postâand none of that helped with writing or being creative, it was just a bunch of work.&lt;/p&gt;
    &lt;p&gt;Yes, I could automate each step in Drupal. There are even modules for Drupal, like Scheduler for scheduling posts and updating publish dates, and Cloudflare for purging CDN cache... but you know what? I used to use those modules, but after four Drupal upgrade cycles, I was burned out on managing patches for months, years, or indefinitely since some of the modules took that long to have a stable release for [current Drupal version].&lt;/p&gt;
    &lt;p&gt;And don't get me started on having to rebuild entire content authoring workflows (e.g. WYSIWYG editors, media management, and content fields) every time a major Drupal version was released! That specific type of churn, thankfully, is not as bad these days, but it was really bad prior to Drupal 10 or so.&lt;/p&gt;
    &lt;p&gt;For Hugo, since my workflow already started with a Markdown file... the whole process is done after step 1, basically.&lt;/p&gt;
    &lt;p&gt;To publish, I guess I do have to update the &lt;code&gt;date&lt;/code&gt; in my post's frontmatter, and change &lt;code&gt;draft&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;, but that's about it. &lt;code&gt;hugo &amp;amp;&amp;amp; git commit -m "Updated post." &amp;amp;&amp;amp; git push&lt;/code&gt; and the blog is up to date!&lt;/p&gt;
    &lt;p&gt;And for maintenance, don't get me started on managing Composer, Drush, PHP, MariaDB, Nginx, Cloudflare, etc. â for an enterprise website, with multiple content workflows, dozens or hundreds of users with RBAC, etc., sure, it's fine. But for a blog where I just want to write and publish, it has been wearing me down for the past few years.&lt;/p&gt;
    &lt;head rend="h2"&gt;TODOs&lt;/head&gt;
    &lt;p&gt;Comments will be missing site-wide initially, as I've chosen to tackle a self-hosted static site commenting system in a 'phase two'. I love having comments enabled, despite the moderation overhead, and don't think blogging is the same without them.&lt;/p&gt;
    &lt;p&gt;I also loved having integrated site search, since I use my blog as a project journal, referencing it often. The Drupal site was integrated into an Apache Solr search instance I also ran as part of Hosted Apache Solr... which I sunset years ago at this point. So I'll have to decide how I want to implement search within Hugo.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46487498</guid><pubDate>Sun, 04 Jan 2026 12:57:40 +0000</pubDate></item><item><title>Understanding the bin, sbin, usr/bin, usr/sbin split (2010)</title><link>https://lists.busybox.net/pipermail/busybox/2010-December/074114.html</link><description>&lt;doc fingerprint="3f89995337a506ed"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Understanding the bin, sbin, usr/bin , usr/sbin split&lt;/head&gt; Rob Landley rob at landley.net &lt;lb/&gt;Thu Dec 9 15:45:39 UTC 2010&lt;quote&gt;On Tuesday 30 November 2010 15:58:00 David Collier wrote: &amp;gt; I see that busybox spreads it's links over these 4 directories. &amp;gt; &amp;gt; Is there a simple rule which decides which directory each link lives &amp;gt; in..... &amp;gt; &amp;gt; For instance I see kill is in /bin and killall in /usr/bin.... I don't &amp;gt; have a grip on what might be the logic for that. You know how Ken Thompson and Dennis Ritchie created Unix on a PDP-7 in 1969? Well around 1971 they upgraded to a PDP-11 with a pair of RK05 disk packs (1.5 megabytes each) for storage. When the operating system grew too big to fit on the first RK05 disk pack (their root filesystem) they let it leak into the second one, which is where all the user home directories lived (which is why the mount was called /usr). They replicated all the OS directories under there (/bin, /sbin, /lib, /tmp...) and wrote files to those new directories because their original disk was out of space. When they got a third disk, they mounted it on /home and relocated all the user directories to there so the OS could consume all the space on both disks and grow to THREE WHOLE MEGABYTES (ooooh!). Of course they made rules about "when the system first boots, it has to come up enough to be able to mount the second disk on /usr, so don't put things like the mount command /usr/bin or we'll have a chicken and egg problem bringing the system up." Fairly straightforward. Also fairly specific to v6 unix of 35 years ago. The /bin vs /usr/bin split (and all the others) is an artifact of this, a 1970's implementation detail that got carried forward for decades by bureaucrats who never question _why_ they're doing things. It stopped making any sense before Linux was ever invented, for multiple reasons: 1) Early system bringup is the provice of initrd and initramfs, which deals with the "this file is needed before that file" issues. We've already _got_ a temporary system that boots the main system. 2) shared libraries (introduced by the Berkeley guys) prevent you from independently upgrading the /lib and /usr/bin parts. They two partitions have to _match_ or they won't work. This wasn't the case in 1974, back then they had a certain level of independence because everything was statically linked. 3) Cheap retail hard drives passed the 100 megabyte mark around 1990, and partition resizing software showed up somewhere around there (partition magic 3.0 shipped in 1997). Of course once the split existed, some people made other rules to justify it. Root was for the OS stuff you got from upstream and /usr was for your site- local files. Then / was for the stuff you got from AT&amp;amp;T and /usr was for the stuff that your distro like IBM AIX or Dec Ultrix or SGI Irix added to it, and /usr/local was for your specific installation's files. Then somebody decided /usr/local wasn't a good place to install new packages, so let's add /opt! I'm still waiting for /opt/local to show up... Of course given 30 years to fester, this split made some interesting distro- specific rules show up and go away again, such as "/tmp is cleared between reboots but /usr/tmp isn't". (Of course on Ubuntu /usr/tmp doesn't exist and on Gentoo /usr/tmp is a symlink to /var/tmp which now has the "not cleared between reboots" rule. Yes all this predated tmpfs. It has to do with read- only root filesystems, /usr is always going to be read only in that case and /var is where your writable space is, / is _mostly_ read only except for bits of /etc which they tried to move to /var but really symlinking /etc to /var/etc happens more often than not...) Standards bureaucracies like the Linux Foundation (which consumed the Free Standards Group in its' ever-growing accretion disk years ago) happily document and add to this sort of complexity without ever trying to understand why it was there in the first place. 'Ken and Dennis leaked their OS into the equivalent of home because an RK05 disk pack on the PDP-11 was too small" goes whoosh over their heads. I'm pretty sure the busybox install just puts binaries wherever other versions of those binaries have historically gone. There's no actual REASON for any of it anymore. Personally, I symlink /bin /sbin and /lib to their /usr equivalents on systems I put together. Embedded guys try to understand and simplify... Rob -- GPLv3: as worthy a successor as The Phantom Menace, as timely as Duke Nukem Forever, and as welcome as New Coke. &lt;/quote&gt;&lt;lb/&gt;More information about the busybox
mailing list&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46487921</guid><pubDate>Sun, 04 Jan 2026 13:49:04 +0000</pubDate></item><item><title>Cold-Blooded Software (2023)</title><link>https://dubroy.com/blog/cold-blooded-software/</link><description>&lt;doc fingerprint="77337152bfe70f19"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Cold-blooded software&lt;/head&gt;December 28, 2023&lt;p&gt;Itâs 2004 and Iâm sitting in one of the largest lecture halls at my university. Iâm a computer science major but Iâm taking a course on natural history â plants and animals â as one of my electives.&lt;/p&gt;&lt;p&gt;The professor tells us that heâs brought something from home, something he found in his freezer. He reaches down behind his desk, and then holds his arm out to show us whatâs sitting in his palm: a baby painted turtle. Weâre learning about cold-blooded animals, and it turns out that painted turtle hatchlings are pretty special â theyâre one of only a few species that can survive being frozen.&lt;/p&gt;&lt;p&gt;Now, the lecture hall is pretty modern for 2004: there’s an overhead camera at the podium, where the professor can write notes that are displayed on screens around the hall. But instead of writing notes, he puts the turtle under the camera and starts his lecture.&lt;/p&gt;&lt;p&gt;Over the next hour, we watch this little reptile slowly come to life as the professor lectures. The first movements were nearly imperceptible. An eyelid cracking open, a leg inching forward. By the end of the lecture, the turtle has moved about halfway across our screens.&lt;/p&gt;&lt;p&gt;Iâll never forget that class, because itâs where I really understood what it means for an animal to be cold blooded. You see, warm-blooded animals â like humans or mice â have a stable body temperature that stays within a pretty narrow range. For humans, itâs around 37 degrees Celsius. A few degrees higher or lower and weâre in big trouble. Cold-blooded animals like the painted turtle can adapt their metabolism to the temperature around them. Theyâre active when itâs warm out, and as the environment (and their bodies) get cooler, they move more slowly. Very few of them can survive being frozen like the baby painted turtle can.&lt;/p&gt;&lt;p&gt;I see a similar dichotomy with software projects. Certain technology decisions lead to projects that are warm-blooded: everything is great when there’s constant motion on the project, generating heat. But put warm-blooded software in the freezer, and you’ll pull out a corpse six months later.&lt;/p&gt;&lt;p&gt;Maybe your CI isn’t working because one of the services you depend on got bought or ran out of money. You add a new dependency and find yourself needing to upgrade your compiler. Another package you depend on is deprecated, and doesn’t work with the latest version of the compiler.&lt;/p&gt;&lt;p&gt;Some projects are different. You work alone, make some changes when youâre inspired, and then donât touch it again for another year, or two, or three. You canât run something like that as a warm-blooded project. Thereâs not enough activity to keep the temperature up.&lt;/p&gt;&lt;p&gt;A cold-blooded project is like the baby painted turtle. You can freeze it for a year and then pick it back up right where you left off.&lt;/p&gt;&lt;p&gt;A cold-blooded project uses boring technology. The build and test scripts donât depend on external services that might change, break, or disappear entirely. It uses vendored dependencies.&lt;/p&gt;&lt;p&gt;The software that powers this blog is cold-blooded. The first commit was nearly twelve years ago â a simple little static site generator to replace my out-of-date Wordpress installation:&lt;/p&gt;&lt;code&gt;commit 68949229ad426c1e8795ee640808db9987ab30ab
Author: Patrick Dubroy &amp;lt;pdubroy@gmail.com&amp;gt;
Date:   Sun Jan 8 19:10:24 2012 +0100

    Add templates and site-building script.&lt;/code&gt;


&lt;p&gt;Itâs written in Python (2, not 3). It depends on four third-party modules, and theyâre all committed to the project repository. Everything runs locally, and I deploy the result with rsync over ssh.&lt;/p&gt;&lt;p&gt;And boy am I glad I decided to do it that way. Iâve made a few small improvements over the years, but otherwise itâs continued to work without modification. And I fully expect that it will still be working in another twelve years.&lt;/p&gt;&lt;p&gt;ð¢&lt;/p&gt;&lt;p&gt;ð You might also want to check out the discussion on Hacker News.&lt;/p&gt;&lt;p&gt;Thanks to Thorsten Ball for helpful suggestions on this post.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488261</guid><pubDate>Sun, 04 Jan 2026 14:28:56 +0000</pubDate></item><item><title>Street Fighter II, the World Warrier (2021)</title><link>https://fabiensanglard.net/sf2_warrier/</link><description>&lt;doc fingerprint="16c6587e2ae6353e"&gt;
  &lt;main&gt;&lt;p&gt;This article is part of a series about Street Fighter II and the CPS-1. It is recommended to read the previous entries before reading this one.&lt;/p&gt;&lt;p&gt;One of my favorite anecdote about Street Fighter II is Akiman's account of an issue discovered shortly before shipping.&lt;/p&gt;&lt;quote&gt;Just three days before the deadline, I discovered something horrible. I had made a mistake with the subtitle “World Warrior”, mis-spelling it “World Warrier.”A recreation of the problem. Ouch!&lt;lb/&gt;- Akiman, Lead graphic design on SF2 (translated by Shmuplation)&lt;/quote&gt;&lt;p&gt;To fully understand the issue, we need to dig into how the arcade hardware works. The CPS-1 is a super tile drawing machine. It can draw a lot of tiles but cannot alter them. They are taken from the GFX ROM as they are and sent to the screen (although they can be flipped horizontally or vertically).&lt;/p&gt;&lt;p&gt;The GFX ROM and the 68000 instructions ROM as burned separately. The problem Akiman describe is that the GFX ROM had been burned but he could still make changes to the instructions.&lt;/p&gt;&lt;p&gt;But how could he fix the mistake if the artwork was set in stone at this point?&lt;/p&gt;&lt;quote&gt;Now I can safely tell this story too, but we actually didn’t discover it until several months after all the sprite work had been done. Since the logo had already been created, I couldn’t just go in and change the letter at this point.&lt;lb/&gt;"Maybe I can just force it to look like an ‘o’," I thought. I tried layering various other sprites over it until finally, it looked like an ‘o’. Phew!&lt;lb/&gt;- Akiman, Lead graphic design on SF2 (translated by Shmuplation)&lt;/quote&gt;&lt;p&gt; Akiman description of the solution left me wanting more details. How did he turn an 'e' into an 'o'? Since I had a sheet extractor, I looked for the text and sure enough, the logo and the typo were found on sheet &lt;code&gt;0x7B00&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt; The logo is drawn via 16 draw calls using tiles &lt;code&gt;0xC8&lt;/code&gt;, &lt;code&gt;0xC9&lt;/code&gt;, &lt;code&gt;0xCA&lt;/code&gt;, &lt;code&gt;0xCB&lt;/code&gt;, &lt;code&gt;0xCC&lt;/code&gt;, &lt;code&gt;0xCD&lt;/code&gt;, &lt;code&gt;0xCE&lt;/code&gt;, &lt;code&gt;0xCF&lt;/code&gt;, &lt;code&gt;0xD8&lt;/code&gt;, &lt;code&gt;0xD9&lt;/code&gt;, &lt;code&gt;0xDA&lt;/code&gt;, &lt;code&gt;0xDB&lt;/code&gt;, &lt;code&gt;0xDC&lt;/code&gt;, &lt;code&gt;0xDD&lt;/code&gt;, &lt;code&gt;0xDE&lt;/code&gt;, and &lt;code&gt;0xDF&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt; The way Akiman solved his problem show that you have to be practical in order to ship. He noticed that there was an 'or' in 'World' which would kinda fit in place of the 'ier'. So, he dropped the three last tiles &lt;code&gt;0xDD&lt;/code&gt;, &lt;code&gt;0xDE&lt;/code&gt;, and &lt;code&gt;0xDF&lt;/code&gt; and replaced them with &lt;code&gt;0xCD&lt;/code&gt; and &lt;code&gt;0xCE&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;That was better but it only displaced the problem since the borrowed right leg of the 'W' looked like an 'l' instead of an 'i'. The logo now read 'The World Warrlor'.&lt;/p&gt;&lt;p&gt;At this point, what was needed was a way to slice the top of the 'l' to make it look like a dot on top of an 'i' but how could he do that since the 68000 cannot write in a tile?&lt;/p&gt;&lt;p&gt; The last part of the puzzle comes from Guile's calves. If you look closely at tile &lt;code&gt;0x96&lt;/code&gt; you will notice that it has only one pixel visible in the lower left corner.
&lt;/p&gt;&lt;table&gt;&lt;row span="17"/&gt;&lt;row span="17"&gt;&lt;cell&gt;Guile palette&lt;/cell&gt;&lt;/row&gt;&lt;row span="17"/&gt;&lt;row&gt;&lt;cell&gt;World Warrier palette&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Something that I omitted to mention earlier is that the palette management is entirely under the 68000 control. The CPU is free to issue a tile drawing command using whatever palette it pleases.&lt;/p&gt;&lt;p&gt; Guile's green palette is not useful since the logo uses blue colors. But if we place them side by side, we notice that index &lt;code&gt;14&lt;/code&gt; is dark green in Guile's palette but dark blue in the logo palette. 
&lt;/p&gt;&lt;p&gt; Using tile &lt;code&gt;0x96&lt;/code&gt; with the logo palette allows the 68000 to have a (very expensive) system where 255 pixels are wasted to transparency but the 256th can be used like a pencil.
&lt;/p&gt;&lt;p&gt;That pencil-tile is used to issue three draw command with coordinates overlapping the 'l'. This effectively creates a line which cuts the top part and make it look like the dot at the top of an 'i'.&lt;/p&gt;&lt;p&gt;If you ever wondered why the 'i' of 'Warrior' looked weird all these years, now you know.&lt;/p&gt;Et voila!&lt;p&gt;The typo was fixed in later versions of Street Fighter 2 where the "World Warrior" set of tiles features a proper "IOR".&lt;/p&gt;&lt;p&gt;Ironically these are not used since the sub-title was changed from "World Warrior" to "Champion Edition" and then "Hyper-fighting".&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488278</guid><pubDate>Sun, 04 Jan 2026 14:30:29 +0000</pubDate></item><item><title>The Unbearable Joy of Sitting Alone in a Café</title><link>https://candost.blog/the-unbearable-joy-of-sitting-alone-in-a-cafe/</link><description>&lt;doc fingerprint="6fc1b21dc927d2db"&gt;
  &lt;main&gt;
    &lt;p&gt;It’s contradictory to sit alone in a café. It’s against the reason cafés exist.&lt;/p&gt;
    &lt;p&gt;They are designed as meeting spaces. There is no table with a single chair. Even the ones placed right by the window with high seating are big tables with many chairs.&lt;/p&gt;
    &lt;p&gt;Cafés are community spaces. Most go there to see their loved ones, friends, or colleagues.&lt;/p&gt;
    &lt;p&gt;You find only a few people sitting alone. Most are buried in their laptops, working hard to make a living in their own worlds, whatever world they have.&lt;/p&gt;
    &lt;p&gt;I rarely do that.&lt;/p&gt;
    &lt;p&gt;When I took time off from work, I chose a staycation. Unlike most of my friends, who visited Japan in 2025.&lt;/p&gt;
    &lt;p&gt;When I heard their experiences, I was jealous. When I told them my staycation plans of doing nothing for four weeks, they were jealous.&lt;/p&gt;
    &lt;p&gt;While off work, I wanted to slow time down as much as I could. The best way to freeze time, I read somewhere, is to get a dog. Luckily, I have one already. So, I took long walks with my dog.&lt;/p&gt;
    &lt;p&gt;What used to feel like 10 minutes between breakfast and lunch while working became a full-blown day. Even though I was spending two hours walking my dog instead of a 30-40 minute rush, it felt like an eternity. A peaceful eternity.&lt;/p&gt;
    &lt;p&gt;On the second day, I decided to leave my phone at home, so I lived those two hours to the fullest. I didn’t take any device that could connect me to the internet or to other people.&lt;/p&gt;
    &lt;p&gt;I was nervous.&lt;/p&gt;
    &lt;p&gt;But all the anxiety evaporated after 30 minutes.&lt;/p&gt;
    &lt;p&gt;I felt free, so to speak.&lt;/p&gt;
    &lt;p&gt;It wasn’t that nobody could reach out to me that felt like an escape; it was that I couldn’t reach out to anyone or anything that caused the turmoil.&lt;/p&gt;
    &lt;p&gt;I had no possibility to text anyone. No possibility to watch or read. No chance to look up anything to fulfill my curiosity.&lt;/p&gt;
    &lt;p&gt;My mind was alone after a long time.&lt;/p&gt;
    &lt;p&gt;There were a few moments I put my hand into my pocket to take out my phone to look up something I was curious about. My phone wasn’t there.&lt;/p&gt;
    &lt;p&gt;I smiled. Every. Single. Time.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;On the second day, I randomly walked into a neighborhood café. I ordered an americano with a double shot of espresso.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sipping a hot americano feels different when you are in a rush to catch a subway. Its purpose is to wake you up. A sip from that little hole in a single-use cap burns my tongue every time. I despise that.&lt;/p&gt;
    &lt;p&gt;With a porcelain cup, you don’t have that. Coffee changes its purpose. It becomes a pleasure.&lt;/p&gt;
    &lt;p&gt;I sat down with a proper cup of americano. My dog crawled under the table.&lt;/p&gt;
    &lt;p&gt;I was sitting alone in a café with a dog that had crawled under the table without any electronics that could distract me.&lt;/p&gt;
    &lt;p&gt;Distract me from, basically, nothing.&lt;/p&gt;
    &lt;p&gt;It was pure delight. Every element. Or rather, the non-existence of any element. No phone. No headphones. No tablet. No laptop.&lt;/p&gt;
    &lt;p&gt;My mind was just drifting with the chatter in the café. I left myself to the flow.&lt;/p&gt;
    &lt;p&gt;When you let your thoughts wander, they take you on a journey you’ll never think possible. You reflect on the smallest details of your fast life. Your brain absorbs all the mistakes you’ve made. You accept that you can’t change failures anymore, as much as you feel guilty.&lt;/p&gt;
    &lt;p&gt;You might as well not worry about them and focus on what you can change: what you do now. And what you will do next.&lt;/p&gt;
    &lt;p&gt;Nothing else.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The next day, I left my phone at home again and decided to stop by the same café. I was lucky; I sat down at the same table.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sitting alone in a café without distractions reveals a lot about people. The same people you pass by in a split second while rushing from home to work, from a meeting to a meeting. The invisible suddenly appears right in front of you. People don’t go away in two seconds. They stay. They sip a coffee. They talk with others, laugh, cry, and worry. Oh, worry.&lt;/p&gt;
    &lt;p&gt;Worry is only visible in people’s eyes. Eyes are the channel of the heart. You have to close your ears and look at people’s eyes to see their hearts.&lt;/p&gt;
    &lt;p&gt;You realize that looking into eyes is frightening—both for you and the other person. You try to avoid it, but eventually make eye contact because nobody is physically moving anywhere.&lt;/p&gt;
    &lt;p&gt;As none of you are passing by in a second, you mimic looking at something else. They continue their conversation. But you saw their worry, and you can’t help but try to understand.&lt;/p&gt;
    &lt;p&gt;You leave the café to avoid making things awkward.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I went there the next day. This time, my table was occupied. I don’t know when it became my table. But it felt like that. I found another one. It was closer to the staff.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sitting alone in a café without distractions shows you how a café works. You never contemplate how they operate behind that giant coffee machine while you’re waiting for your coffee before you run to catch the next bus, tram, subway, or taxi. You never ruminate when you sip from a single-use cup and burn your tongue.&lt;/p&gt;
    &lt;p&gt;You notice how the staff circulates porcelain cups, from dirty to clean, to the top of the coffee machine. You observe the staff’s reactions to each customer. You try to analyze if someone is a regular by noticing how the staff talks.&lt;/p&gt;
    &lt;p&gt;You wonder whether they consider you a regular, since you’ve been there for the last couple of days. Or they call you a creepy guy with a dog. You will never know. You’re not fine with never knowing.&lt;/p&gt;
    &lt;p&gt;You promise yourself to come the next day to observe how the staff talks to you.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I again went to the same café. Unlucky me. A different staff were working on that day. Yet I ordered the same: a cup of americano with a double shot of espresso.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sitting alone in a café without distractions, with a dog that had crawled under the table, brings a light to a truth: you can’t control or influence other people’s thoughts and feelings, no matter what you do. Staff may think of you as a weirdo with a dog; your friends might want to be in your place; your family might be nervous because they can’t reach out to you.&lt;/p&gt;
    &lt;p&gt;You know you can’t change any of those unless you change who you are. It makes you feel alone and powerless.&lt;/p&gt;
    &lt;p&gt;You are alone and powerless. You encounter a deep challenge.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The next day, I didn’t go to the café. I instead took an even longer walk. I went there the following day, knowing I had faced that challenge in my longest walk.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sitting alone in a café without distractions shows everyone you’re alone.&lt;/p&gt;
    &lt;p&gt;It’s an alone act.&lt;/p&gt;
    &lt;p&gt;A scary but powerful one.&lt;/p&gt;
    &lt;p&gt;Many avoid at all costs. That’s why everybody looks at you with wondering eyes. They are afraid of your powerful joy. They can’t grasp why someone would do this to themselves. They are hesitant but are thinking of doing the same.&lt;/p&gt;
    &lt;p&gt;Then you realize you’re planting thoughts in people’s minds that you can’t control. Feelings are feelings. Thoughts are thoughts.&lt;/p&gt;
    &lt;p&gt;Just at the moment you think you are alone again, you see another weirdo across the café sitting alone without distractions. That weirdo is looking at your sleeping-in-a-croissant-shape dog under the table. Weirdo is enjoying the moment, while your dog is on an adventure in her second dream.&lt;/p&gt;
    &lt;p&gt;You smile. You know you’re not alone. You are one weirdo sitting at a distance from one other. You know there are many.&lt;/p&gt;
    &lt;p&gt;Maybe one of them is reading this and feeling heard. Perhaps one will never see this and will always feel alone. But it only needs one look around. You glance over the café and leave with a smile.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The next day, I went there again. This time, I put in an intentional distraction. A good one.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sitting alone in a café without distractions only gets better when there is something to write on. Not with a keyboard. You must use your single hand to write, not two. Ideally, with a pen on paper.&lt;/p&gt;
    &lt;p&gt;The pen is meant to slow you down. The words shouldn’t land on paper at the speed of thinking or even talking.&lt;/p&gt;
    &lt;p&gt;The writing must hurt your wrist or hand. It must turn into a burden. That pain is a signal telling you that you have written long enough. Maybe you wrote only five lines. Perhaps one thousand.&lt;/p&gt;
    &lt;p&gt;It doesn’t matter.&lt;/p&gt;
    &lt;p&gt;You take a break.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488355</guid><pubDate>Sun, 04 Jan 2026 14:37:58 +0000</pubDate></item><item><title>AI Sycophancy Panic</title><link>https://github.com/firasd/vibesbench/blob/main/docs/ai-sycophancy-panic.md</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488396</guid><pubDate>Sun, 04 Jan 2026 14:41:28 +0000</pubDate></item><item><title>Show HN: An interactive guide to how browsers work</title><link>https://howbrowserswork.com/</link><description>&lt;doc fingerprint="d261d58ed2a8a9d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How Browsers Work&lt;/head&gt;
    &lt;p&gt;An interactive guide to how browsers work.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why?&lt;/head&gt;
    &lt;p&gt;The guide is for engineers and curious people who use the web every day, but never built a mental model of how browsers work.&lt;/p&gt;
    &lt;p&gt;I find most guides too technical, too detailed, or too shallow, so I have decided to take a different approach.&lt;/p&gt;
    &lt;p&gt;I built the guide with many tiny interactive examples you can play with to help you go get through the technical details and build an intuition of how browsers work.&lt;/p&gt;
    &lt;p&gt;To keep it short and straight to the point, many critical details are omitted like different versions of the HTTP protocol, SSL, TLS, nuances of the DNS, and many more.&lt;/p&gt;
    &lt;p&gt;I made the guide open source. Feel free to suggest improvements by creating an issue or a pull request.&lt;/p&gt;
    &lt;head rend="h2"&gt;Browsers work with URLs&lt;/head&gt;
    &lt;p&gt;You can type literally anything in the address bar. But under the hood, browsers work with URLs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A random text like pizza will be transformed into a "search" URL like https://google.com/search?q=pizza (or https://duckduckgo.com/?q=pizza depending on your preferences).&lt;/item&gt;
      &lt;item&gt;A domain name like example.com will be normalized as a full URL: https://example.com&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To see how this works in practice, type something in the address bar and press Enter (or click the "Go" button):&lt;/p&gt;
    &lt;head rend="h2"&gt;Turning a URL into an HTTP request&lt;/head&gt;
    &lt;p&gt;Once we know the exact URL we want to visit, we can send a request to the server to fetch the resource and display it in the browser. Browsers communicate with servers using the HTTP protocol.&lt;/p&gt;
    &lt;p&gt;To see how a URL is translated into an HTTP request format, enter a full URL like https://example.com and press Enter (or click the "Go" button):&lt;/p&gt;
    &lt;p&gt;HTTP requests have headers in the format like:&lt;/p&gt;
    &lt;code&gt;Host: example.com
Accept: text/html
&lt;/code&gt;
    &lt;p&gt;One of the headers is the host header. It is used to identify the server to which the request is sent: example.com.&lt;/p&gt;
    &lt;head rend="h2"&gt;Resolving the server address&lt;/head&gt;
    &lt;p&gt;Browsers can't send requests to names like example.com.&lt;/p&gt;
    &lt;p&gt;Computers talk to IP addresses, so the browser first asks the DNS system to resolve the domain name into an IP address before it can connect to the server and send the HTTP request.&lt;/p&gt;
    &lt;p&gt;Type a domain name in the input and press Enter to resolve it into an IP address:&lt;/p&gt;
    &lt;head rend="h2"&gt;Establishing the TCP connection&lt;/head&gt;
    &lt;p&gt;After DNS gives the browser an IP address, it still needs a reliable connection to the server. TCP is the protocol that sets up this connection before any HTTP data is sent.&lt;/p&gt;
    &lt;p&gt;TCP establishes the connection using a three-step handshake that confirms both sides are ready to send and receive data.&lt;/p&gt;
    &lt;p&gt;These numbers are how the client and the server keep track of the conversation. They count bytes, so both sides agree on where the data stream starts and what should come next. If some data doesn't arrive, the sender can see the gap and retransmit the missing bytes. This is how TCP keeps data ordered and reliable once the connection is established.&lt;/p&gt;
    &lt;p&gt;Start sending packets and try to disrupt the network to see what happens.&lt;/p&gt;
    &lt;head rend="h2"&gt;HTTP requests and responses&lt;/head&gt;
    &lt;p&gt;Once the TCP connection is established, the browser can send an HTTP request to the server.&lt;/p&gt;
    &lt;p&gt;Click the "Go" button to watch the HTTP request travel to the server and the HTTP response return to the browser:&lt;/p&gt;
    &lt;p&gt;When the HTTP response arrives, the browser reads the raw HTTP response and starts rendering the HTML content.&lt;/p&gt;
    &lt;head rend="h2"&gt;Parsing HTML to build the DOM tree&lt;/head&gt;
    &lt;p&gt;After the HTTP response arrives, the browser separates the headers from the body and feeds the HTML bytes into the parser. The parser turns tags like &amp;lt;h1&amp;gt; into tokens and builds a DOM tree.&lt;/p&gt;
    &lt;p&gt;Click the "Parse" button to watch the HTML stream being parsed into the DOM tree:&lt;/p&gt;
    &lt;code&gt;&amp;lt;!doctype html&amp;gt;&amp;lt;html&amp;gt;  &amp;lt;head&amp;gt;    &amp;lt;title&amp;gt;Example Domain&amp;lt;/title&amp;gt;  &amp;lt;/head&amp;gt;  &amp;lt;body&amp;gt;    &amp;lt;main&amp;gt;      &amp;lt;h1 style="color: red;"&amp;gt;Example Domain&amp;lt;/h1&amp;gt;      &amp;lt;p&amp;gt;An example paragraph.&amp;lt;/p&amp;gt;      &amp;lt;p&amp;gt;
             &amp;lt;a href="https://example.com"&amp;gt;An example link&amp;lt;/a&amp;gt;
           &amp;lt;/p&amp;gt;    &amp;lt;/main&amp;gt;  &amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;&lt;/code&gt;
    &lt;code&gt;Document|- &amp;lt;!doctype html&amp;gt;`- html   |- head   |  `- title   |     `- "Example Domain"   `- body      `- main         |- h1 (style: color: red)         |  `- "Example Domain"         |- p         |  `- "An example paragraph."         `- p            `- a (href="https://example.com")               `- "An example link"&lt;/code&gt;
    &lt;p&gt;Parsing is streaming and error-tolerant: the browser starts building nodes before the full document is downloaded, and it inserts missing tags to keep the tree valid. When a &amp;lt;script&amp;gt; tag appears, parsing may pause so the script can run.&lt;/p&gt;
    &lt;p&gt;The DOM tree then combines with CSS to produce the render tree that layout and paint use to draw pixels.&lt;/p&gt;
    &lt;head rend="h2"&gt;On the importance of the DOM&lt;/head&gt;
    &lt;p&gt;The DOM is the browser's in-memory model of the document. It is the shared contract between the HTML parser, CSS selector engine, and JavaScript runtime, so changes to it immediately affect layout, styling, and what users can interact with.&lt;/p&gt;
    &lt;p&gt;The DOM powers everything from query selection to dynamic styling and event handling. Try editing the script and watch how the DOM changes on the right.&lt;/p&gt;
    &lt;head rend="h2"&gt;Layout, Paint, and Composite&lt;/head&gt;
    &lt;p&gt;Once the DOM and CSS are ready, the browser runs the rendering pipeline: Layout (reflow) to calculate sizes and positions,Paint to fill pixels, then Composite to stitch layers together on the GPU.&lt;/p&gt;
    &lt;p&gt;Not every change reruns every stage. Changing colors usually repaints, while changing sizes forces layout and paint to recompute.&lt;/p&gt;
    &lt;p&gt;This is why layout-heavy pages feel slower: more work needs to happen before the next frame can be shown.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;That is it! If you completed all the examples, you should have a clear mental model of how browsers work.&lt;/p&gt;
    &lt;p&gt;Thank you for reading the guide, I hope you enjoyed it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488654</guid><pubDate>Sun, 04 Jan 2026 15:08:02 +0000</pubDate></item><item><title>Neurodivergent Brains Build Better Systems (2025)</title><link>https://blog.drjoshcsimmons.com/p/how-neurodivergent-brains-build-better</link><description>&lt;doc fingerprint="7e1e931ba8c7c708"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How Neurodivergent Brains Build Better Systems&lt;/head&gt;
    &lt;p&gt;A former manager once described me as a “purist”. It wasn’t the first time a colleague alluded to my obsessive way of thinking but it was the first time someone used it as a compliment. It got me thinking, what if neurodivergent “defects” are the exact architecture the world’s systems need?&lt;/p&gt;
    &lt;p&gt;Neurodivergence is often pathologized. You may have heard that you’re too rigid, too blunt, too obsessive. These traits may irk humans. I know my friends and family have the patience of a saint for putting up with my idiosyncrasies. Systems are different. I have built and worked on some of the strangest, most exquisite, and highly scalable systems in software. Those systems were masterful because they were built by rigid, obsessive, and blunt people. Those traits build stable infrastructure, write clean code, and destroy inefficiencies in systems.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trait 1: Systems Thinking&lt;/head&gt;
    &lt;p&gt;Neurotypical people are top-down thinkers. They have a hypothesis first then obtain data to support or disprove the hypothesis.&lt;/p&gt;
    &lt;p&gt;Neurodivergent people are bottom-up thinkers. They begin collecting relevant data first then form their hypothesis or “big picture” later.&lt;/p&gt;
    &lt;p&gt;Business-facing roles present a strong case for neurotypical people but, as always, creative fields, including software engineering, flip the script. I once managed a team shipping some production code to a customer on a horrendous deadline. It was the final day and we were wrapping up our systems integration tests. A bit after 6PM with the midnight deadline looming and my finger hovering over the deploy button, one of the quietest, shyest engineers I’ve ever managed interrupted me mid-speech and said “Wait, we can’t deploy this yet.” He noticed something that his peers had missed and it saved us from destroying our reputation with the customer.&lt;/p&gt;
    &lt;p&gt;There was a particular button on the user interface that bugged him. It bugged him because it was a slightly different shade of green in the screenshots than it was in the staging environment. The team looked into it, and sure enough, we had tested a slightly older version of the software, not the exact version we nearly shipped to the customer. He saw and noticed the button but what would have been deployed would have had multiple bugs in the code that weren’t visible and passing because the tests were on the old version too. That’s bottom-up thinking.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trait 2: Hyperfocus and Flow&lt;/head&gt;
    &lt;p&gt;We live in a distraction economy. Nearly everything in the modern world seeks to rob our focus and divide it among a million shallow things.&lt;/p&gt;
    &lt;p&gt;Neurodivergent people don’t focus, they obsess. This is a rare skill in these times. I have met neurodivergent people who have created their own programming language and composed and recorded full albums worth of music in just a week.&lt;/p&gt;
    &lt;p&gt;Elite engineering cultures are built on this kind of focus. I know of one neurodivergent friendly office with a 5-day in office policy. It is an open office but there is a monk-like observance of silence out on the floor. The lighting is warm colored, diffuse, and extremely dim. All meetings are taken in either a soundproof phone booth or a conference room. The cafeteria is in an entirely separate building from where the engineering work is done so there’s no risk of smells carrying over. Desks are arranged in pods of four facing outward so no one sits directly across from another person. Each desk has a high-backed chair and adjustable privacy panels that can create a semi-enclosed workspace. It’s no surprise that these offices enable some of the most elite engineers to write superior code.&lt;/p&gt;
    &lt;p&gt;Most offices mess this up really badly by having harsh lighting, extremely loud conditions, and gross smells. That kind of environment makes hyperfocus impossible and thus yields middling code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trait 3: Automation Instinct&lt;/head&gt;
    &lt;p&gt;Manual repetitive process can be extremely disruptive and frustrating for neurodivergent employees.&lt;/p&gt;
    &lt;p&gt;Imagine that you have the power to type characters into a machine that then does things automatically for you 24/7 at a scale of millions, billions, or just about whatever scale you ask it to. You have that power, and then someone tells you to manually enter numbers that you fetch from one system into a spreadsheet in another system. Once? Fine, there’s always going to be some grunt work. If this becomes the norm though, neurodivergent employees will resent the work.&lt;/p&gt;
    &lt;p&gt;That resentment is valuable to leaders who know how to capitalize on it. Neurodivergent engineers have a lower tolerance for bullshit, which means they automate sooner. What looks like impatience is actually a forcing function for compound productivity gains. The neurotypical employee will tolerate the manual process for months. The neurodivergent employee will spend three days automating it in week one, then reap the efficiency dividend for years.&lt;/p&gt;
    &lt;p&gt;Companies can capture this by cutting any manual non-specialist process that is necessary and then cutting 90% of the ones that “are necessary”. 9% of the remaining processes should be automated with a dedicated team or teams to build and maintain these automations. The remaining 1% of truly human-necessary, non-specialist processes can then be groaned through and completed by neurodivergent employees with an acceptable minimum disruption to their flow.&lt;/p&gt;
    &lt;p&gt;If you don’t have neurodivergent people in the leadership looking out for these opportunities for redundancy elimination in your non-specialist processes—anything involving a spreadsheet, most things involving an intranet or internal applications, anything that most employees are likely to just click through without reading—you’ll never notice them and fix them and you’ll leave a ton of work output on the table.&lt;/p&gt;
    &lt;p&gt;If you want good ROI in software you will aggressively find and reduce this grunt work for your people. The only way you can do that is by having at least a few neurodivergent executives at the helm. I can tell you from experience, when this voice isn’t represented in a C-suite neurodivergent people burn out which ultimately costs the company untold big bucks.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Collision&lt;/head&gt;
    &lt;p&gt;So if neurodivergent traits produce superior infrastructure, elite code, and automation dividends, why aren’t companies optimizing for them?&lt;/p&gt;
    &lt;p&gt;The legacy corporate environment has evolved to suit neurotypical workers. When I was young, my father had an office at his job with an opaque door that closed. He didn’t have a fancy MBA or advanced degree, just his associates. He didn’t work in a major US city, we were in the Rust Belt. Fast forward to today, workers even with a Director or “Head of” title, working in some of the most affluent cities in the US, with advanced degrees sit in a noisy open office. If you are very lucky you might have an assigned desk. Most offices have embraced hot-desking. If you have an office you can be sure that there are windows for passers-by to peer into. You are not entitled to your own space nor privacy unless you are a member of the lauded C-suite. Penny wise, pound foolish, and outright classist.&lt;/p&gt;
    &lt;p&gt;Presenteeism is held in very high regard in a corporate office. If you aren’t in the office how can your leaders know that you are working? I once worked with a peer leader at an organization with a 3-day in-office requirement. He boasted that he always came in four days a week. He proudly stated this fact to me on more than one occasion, presumably waiting for his Goodest Boy trophy. This kind of mentality prioritizes optics over throughput, and the damage is compounds. Perfect Attendance Man backs other perfect attendance people because if their subject matter acumen is challenged by someone competent, everybody will see that the emperor isn’t wearing any clothes. Keep rewarding optics over years and you foster an environment that purges competent individuals from leadership.&lt;/p&gt;
    &lt;p&gt;As long as corporate environments maintain this setup, they are leaving massive value on the table as their neurodivergent workers fight through the day to survive and not burn out entirely.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Works&lt;/head&gt;
    &lt;p&gt;Here’s what neurodivergent-optimized engineering orgs need:&lt;/p&gt;
    &lt;p&gt;1. Remote-first&lt;/p&gt;
    &lt;p&gt;Not always possible for all companies (hardware, security classifications, etc.) Almost always possible outside of those factors though.&lt;/p&gt;
    &lt;p&gt;Executives who need to see people working to know that they’re working should ask themselves whether that work produces anything of tangible value. Worth noting that these executives always have large, dedicated, private offices with an opaque door that shuts while their employees don’t even have assigned desks. I worked in one of these “hot-desking” setups and had my $300 keyboard stolen within a matter of months.&lt;/p&gt;
    &lt;p&gt;2. Cultural Discipline&lt;/p&gt;
    &lt;p&gt;If two coworkers begin to chat loudly at their desks, soon it will be four, then eight. In just a short amount of time there will always be chatter and movement on the floor. It must be made abundantly clear that a library-like atmosphere is to be observed in the working areas. It’s counterproductive to do this with rules. The loudest office I ever worked in has signs reminding employees to be quiet in worker areas. The quietest office didn’t need signs, it was built into the culture. Your early and influential hires must establish the norm in your organization’s culture that it’s really frowned upon to disrupt people while they’re in focus.&lt;/p&gt;
    &lt;p&gt;3. Neurodivergent Representation&lt;/p&gt;
    &lt;p&gt;Executive leadership is heavily biased towards neurotypical people. They can socialize extensively, aren’t sensitive to noises or lights, thrive in the presentation and optics that define executive culture. But neurotypical-only leadership rarely builds cultures that achieve technical excellence.&lt;/p&gt;
    &lt;p&gt;Whenever I have seen neurodivergent folks on an exec team, their company is breaking records, forging new technology previously thought impossible, and making a lot of money. That representation matters because those executives notice and eliminate the inefficiencies that neurotypical leadership doesn’t even see as problems.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488661</guid><pubDate>Sun, 04 Jan 2026 15:08:22 +0000</pubDate></item><item><title>How I archived 10 years of memories using Spotify</title><link>https://notes.xdavidhu.me/notes/how-i-archived-10-years-of-memories-using-spotify</link><description>&lt;doc fingerprint="94d6d139a5b8c9d2"&gt;
  &lt;main&gt;
    &lt;p&gt;Music and smells are two of the most effective ways to re-experience the emotions of a specific time in the past. Listening to a song from a particular time of my life brings me back to how I felt at that point in ways photos can’t. Sometimes I can even recall exact visuals of what I was doing or where I was walking when listening.&lt;/p&gt;
    &lt;p&gt;Over the last 10 years, I followed a system that allows me to re-experience any specific time of any year.&lt;/p&gt;
    &lt;p&gt;Every January 1st, from desktop/web, I:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create a new playlist. Title it the past year.&lt;/item&gt;
      &lt;item&gt;Copy all of my liked songs and paste them into the new playlist. This will maintain the order.&lt;/item&gt;
      &lt;item&gt;Empty my liked songs.&lt;/item&gt;
      &lt;item&gt;Save an out-of-bounds backup of the new playlist, in case my Spotify account messes up in the future. I select all &amp;amp; paste it into a sheet in Google Drive.&lt;/item&gt;
      &lt;item&gt;Start listening to new music, like them over the year.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since the archive saves the order of likes, it grants more granular access than just years. For example, if I want to re-experience how the fall of 2016 felt, I open the corresponding year’s list, scroll 1/4 down from the top, and start listening.&lt;/p&gt;
    &lt;p&gt;During the year, when I listen to my liked songs, I usually start from the top of the stack, without shuffle. This is natural for me, since the newly saved songs are the ones I like the most at a given time. This causes me to listen to a “rolling window” of my liked songs as time passes, linking specific music to specific dates.&lt;/p&gt;
    &lt;p&gt;In addition to saving songs that I find myself and particularly like, I like to save songs that are playing around me, on the radio, or at places I visit, and somehow stand out. Even if I might not fully like them at first, I find that they serve as great anchor points, and they usually grow on me after a few listens.&lt;/p&gt;
    &lt;p&gt;To maintain the integrity &amp;amp; not override the memories associated with specific songs, I rarely listen to or re-save songs from the past years. Sometimes I give myself exceptions, though, especially with remixes. ;)&lt;/p&gt;
    &lt;p&gt;See my last 10 years: https://open.spotify.com/user/xdavidhu&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488696</guid><pubDate>Sun, 04 Jan 2026 15:11:19 +0000</pubDate></item><item><title>Anti-Aging Injection Regrows Knee Cartilage and Prevents Arthritis</title><link>https://scitechdaily.com/anti-aging-injection-regrows-knee-cartilage-and-prevents-arthritis/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488711</guid><pubDate>Sun, 04 Jan 2026 15:13:18 +0000</pubDate></item><item><title>Lessons from 14 Years at Google</title><link>https://addyosmani.com/blog/21-lessons/</link><description>&lt;doc fingerprint="3eca11103f044e9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;21 Lessons From 14 Years at Google&lt;/head&gt;
    &lt;head rend="h2"&gt;January 3, 2026&lt;/head&gt;
    &lt;p&gt;When I joined Google ~14 years ago, I thought the job was about writing great code. I was partly right. But the longer I’ve stayed, the more I’ve realized that the engineers who thrive aren’t necessarily the best programmers - they’re the ones who’ve figured out how to navigate everything around the code: the people, the politics, the alignment, the ambiguity.&lt;/p&gt;
    &lt;p&gt;These lessons are what I wish I’d known earlier. Some would have saved me months of frustration. Others took years to fully understand. None of them are about specific technologies - those change too fast to matter. They’re about the patterns that keep showing up, project after project, team after team.&lt;/p&gt;
    &lt;p&gt;I’m sharing them because I’ve benefited enormously from engineers who did the same for me. Consider this my attempt to pay it forward.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. The best engineers are obsessed with solving user problems.&lt;/head&gt;
    &lt;p&gt;It’s seductive to fall in love with a technology and go looking for places to apply it. I’ve done it. Everyone has. But the engineers who create the most value work backwards: they become obsessed with understanding user problems deeply, and let solutions emerge from that understanding.&lt;/p&gt;
    &lt;p&gt;User obsession means spending time in support tickets, talking to users, watching users struggle, asking “why” until you hit bedrock. The engineer who truly understands the problem often finds that the elegant solution is simpler than anyone expected.&lt;/p&gt;
    &lt;p&gt;The engineer who starts with a solution tends to build complexity in search of a justification.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Being right is cheap. Getting to right together is the real work.&lt;/head&gt;
    &lt;p&gt;You can win every technical argument and lose the project. I’ve watched brilliant engineers accrue silent resentment by always being the smartest person in the room. The cost shows up later as “mysterious execution issues” and “strange resistance.”&lt;/p&gt;
    &lt;p&gt;The skill isn’t being right. It’s entering discussions to align on the problem, creating space for others, and remaining skeptical of your own certainty.&lt;/p&gt;
    &lt;p&gt;Strong opinions, weakly held - not because you lack conviction, but because decisions made under uncertainty shouldn’t be welded to identity.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Bias towards action. Ship. You can edit a bad page, but you can’t edit a blank one.&lt;/head&gt;
    &lt;p&gt;The quest for perfection is paralyzing. I’ve watched engineers spend weeks debating the ideal architecture for something they’ve never built. The perfect solution rarely emerges from thought alone - it emerges from contact with reality. AI can in many ways help here.&lt;/p&gt;
    &lt;p&gt;First do it, then do it right, then do it better. Get the ugly prototype in front of users. Write the messy first draft of the design doc. Ship the MVP that embarrasses you slightly. You’ll learn more from one week of real feedback than a month of theoretical debate.&lt;/p&gt;
    &lt;p&gt;Momentum creates clarity. Analysis paralysis creates nothing.&lt;/p&gt;
    &lt;head rend="h2"&gt;4. Clarity is seniority. Cleverness is overhead.&lt;/head&gt;
    &lt;p&gt;The instinct to write clever code is almost universal among engineers. It feels like proof of competence.&lt;/p&gt;
    &lt;p&gt;But software engineering is what happens when you add time and other programmers. In that environment, clarity isn’t a style preference - it’s operational risk reduction.&lt;/p&gt;
    &lt;p&gt;Your code is a strategy memo to strangers who will maintain it at 2am during an outage. Optimize for their comprehension, not your elegance. The senior engineers I respect most have learned to trade cleverness for clarity, every time.&lt;/p&gt;
    &lt;head rend="h2"&gt;5. Novelty is a loan you repay in outages, hiring, and cognitive overhead.&lt;/head&gt;
    &lt;p&gt;Treat your technology choices like an organization with a small “innovation token” budget. Spend one each time you adopt something materially non-standard. You can’t afford many.&lt;/p&gt;
    &lt;p&gt;The punchline isn’t “never innovate.” It’s “innovate only where you’re uniquely paid to innovate.” Everything else should default to boring, because boring has known failure modes.&lt;/p&gt;
    &lt;p&gt;The “best tool for the job” is often the “least-worst tool across many jobs”-because operating a zoo becomes the real tax.&lt;/p&gt;
    &lt;head rend="h2"&gt;6. Your code doesn’t advocate for you. People do.&lt;/head&gt;
    &lt;p&gt;Early in my career, I believed great work would speak for itself. I was wrong. Code sits silently in a repository. Your manager mentions you in a meeting, or they don’t. A peer recommends you for a project, or someone else.&lt;/p&gt;
    &lt;p&gt;In large organizations, decisions get made in meetings you’re not invited to, using summaries you didn’t write, by people who have five minutes and twelve priorities. If no one can articulate your impact when you’re not in the room, your impact is effectively optional.&lt;/p&gt;
    &lt;p&gt;This isn’t strictly about self-promotion. It’s about making the value chain legible to everyone- including yourself.&lt;/p&gt;
    &lt;head rend="h2"&gt;7. The best code is the code you never had to write.&lt;/head&gt;
    &lt;p&gt;We celebrate creation in engineering culture. Nobody gets promoted for deleting code, even though deletion often improves a system more than addition. Every line of code you don’t write is a line you never have to debug, maintain, or explain.&lt;/p&gt;
    &lt;p&gt;Before you build, exhaust the question: “What would happen if we just… didn’t?” Sometimes the answer is “nothing bad,” and that’s your solution.&lt;/p&gt;
    &lt;p&gt;The problem isn’t that engineers can’t write code or use AI to do so. It’s that we’re so good at writing it that we forget to ask whether we should.&lt;/p&gt;
    &lt;head rend="h2"&gt;8. At scale, even your bugs have users.&lt;/head&gt;
    &lt;p&gt;With enough users, every observable behavior becomes a dependency - regardless of what you promised. Someone is scraping your API, automating your quirks, caching your bugs.&lt;/p&gt;
    &lt;p&gt;This creates a career-level insight: you can’t treat compatibility work as “maintenance” and new features as “real work.” Compatibility is product.&lt;/p&gt;
    &lt;p&gt;Design your deprecations as migrations with time, tooling, and empathy. Most “API design” is actually “API retirement.”&lt;/p&gt;
    &lt;head rend="h2"&gt;9. Most “slow” teams are actually misaligned teams.&lt;/head&gt;
    &lt;p&gt;When a project drags, the instinct is to blame execution: people aren’t working hard enough, the technology is wrong, there aren’t enough engineers. Usually none of that is the real problem.&lt;/p&gt;
    &lt;p&gt;In large companies, teams are your unit of concurrency, but coordination costs grow geometrically as teams multiply. Most slowness is actually alignment failure - people building the wrong things, or the right things in incompatible ways.&lt;/p&gt;
    &lt;p&gt;Senior engineers spend more time clarifying direction, interfaces, and priorities than “writing code faster” because that’s where the actual bottleneck lives.&lt;/p&gt;
    &lt;head rend="h2"&gt;10. Focus on what you can control. Ignore what you can’t.&lt;/head&gt;
    &lt;p&gt;In a large company, countless variables are outside your control - organizational changes, management decisions, market shifts, product pivots. Dwelling on these creates anxiety without agency.&lt;/p&gt;
    &lt;p&gt;The engineers who stay sane and effective zero in on their sphere of influence. You can’t control whether a reorg happens. You can control the quality of your work, how you respond, and what you learn. When faced with uncertainty, break problems into pieces and identify the specific actions available to you.&lt;/p&gt;
    &lt;p&gt;This isn’t passive acceptance but it is strategic focus. Energy spent on what you can’t change is energy stolen from what you can.&lt;/p&gt;
    &lt;head rend="h2"&gt;11. Abstractions don’t remove complexity. They move it to the day you’re on call.&lt;/head&gt;
    &lt;p&gt;Every abstraction is a bet that you won’t need to understand what’s underneath. Sometimes you win that bet. But something always leaks, and when it does, you need to know what you’re standing on.&lt;/p&gt;
    &lt;p&gt;Senior engineers keep learning “lower level” things even as stacks get higher. Not out of nostalgia, but out of respect for the moment when the abstraction fails and you’re alone with the system at 3am. Use your stack.&lt;/p&gt;
    &lt;p&gt;But keep a working model of its underlying failure modes.&lt;/p&gt;
    &lt;head rend="h2"&gt;12. Writing forces clarity. The fastest way to learn something better is to try teaching it.&lt;/head&gt;
    &lt;p&gt;Writing forces clarity. When I explain a concept to others - in a doc, a talk, a code review comment, even just chatting with AI - I discover the gaps in my own understanding. The act of making something legible to someone else makes it more legible to me.&lt;/p&gt;
    &lt;p&gt;This doesn’t mean that you’re going to learn how to be a surgeon by teaching it, but the premise still holds largely true in the software engineering domain.&lt;/p&gt;
    &lt;p&gt;This isn’t just about being generous with knowledge. It’s a selfish learning hack. If you think you understand something, try to explain it simply. The places where you stumble are the places where your understanding is shallow.&lt;/p&gt;
    &lt;p&gt;Teaching is debugging your own mental models.&lt;/p&gt;
    &lt;head rend="h2"&gt;13. The work that makes other work possible is priceless - and invisible.&lt;/head&gt;
    &lt;p&gt;Glue work - documentation, onboarding, cross-team coordination, process improvement - is vital. But if you do it unconsciously, it can stall your technical trajectory and burn you out. The trap is doing it as “helpfulness” rather than treating it as deliberate, bounded, visible impact.&lt;/p&gt;
    &lt;p&gt;Timebox it. Rotate it. Turn it into artifacts: docs, templates, automation. And make it legible as impact, not as personality trait.&lt;/p&gt;
    &lt;p&gt;Priceless and invisible is a dangerous combination for your career.&lt;/p&gt;
    &lt;head rend="h2"&gt;14. If you win every debate, you’re probably accumulating silent resistance.&lt;/head&gt;
    &lt;p&gt;I’ve learned to be suspicious of my own certainty. When I “win” too easily, something is usually wrong. People stop fighting you not because you’ve convinced them, but because they’ve given up trying - and they’ll express that disagreement in execution, not meetings.&lt;/p&gt;
    &lt;p&gt;Real alignment takes longer. You have to actually understand other perspectives, incorporate feedback, and sometimes change your mind publicly.&lt;/p&gt;
    &lt;p&gt;The short-term feeling of being right is worth much less than the long-term reality of building things with willing collaborators.&lt;/p&gt;
    &lt;head rend="h2"&gt;15. When a measure becomes a target, it stops measuring.&lt;/head&gt;
    &lt;p&gt;Every metric you expose to management will eventually be gamed. Not through malice, but because humans optimize for what’s measured.&lt;/p&gt;
    &lt;p&gt;If you track lines of code, you’ll get more lines. If you track velocity, you’ll get inflated estimates.&lt;/p&gt;
    &lt;p&gt;The senior move: respond to every metric request with a pair. One for speed. One for quality or risk. Then insist on interpreting trends, not worshiping thresholds. The goal is insight, not surveillance.&lt;/p&gt;
    &lt;head rend="h2"&gt;16. Admitting what you don’t know creates more safety than pretending you do.&lt;/head&gt;
    &lt;p&gt;Senior engineers who say “I don’t know” aren’t showing weakness - they’re creating permission. When a leader admits uncertainty, it signals that the room is safe for others to do the same. The alternative is a culture where everyone pretends to understand and problems stay hidden until they explode.&lt;/p&gt;
    &lt;p&gt;I’ve seen teams where the most senior person never admitted confusion, and I’ve seen the damage. Questions don’t get asked. Assumptions don’t get challenged. Junior engineers stay silent because they assume everyone else gets it.&lt;/p&gt;
    &lt;p&gt;Model curiosity, and you get a team that actually learns.&lt;/p&gt;
    &lt;head rend="h2"&gt;17. Your network outlasts every job you’ll ever have.&lt;/head&gt;
    &lt;p&gt;Early in my career, I focused on the work and neglected networking. In hindsight, this was a mistake. Colleagues who invested in relationships - inside and outside the company - reaped benefits for decades.&lt;/p&gt;
    &lt;p&gt;They heard about opportunities first, could build bridges faster, got recommended for roles, and co-founded ventures with people they’d built trust with over years.&lt;/p&gt;
    &lt;p&gt;Your job isn’t forever, but your network is. Approach it with curiosity and generosity, not transactional hustle.&lt;/p&gt;
    &lt;p&gt;When the time comes to move on, it’s often relationships that open the door.&lt;/p&gt;
    &lt;head rend="h2"&gt;18. Most performance wins come from removing work, not adding cleverness.&lt;/head&gt;
    &lt;p&gt;When systems get slow, the instinct is to add: caching layers, parallel processing, smarter algorithms. Sometimes that’s right. But I’ve seen more performance wins from asking “what are we computing that we don’t need?”&lt;/p&gt;
    &lt;p&gt;Deleting unnecessary work is almost always more impactful than doing necessary work faster. The fastest code is code that never runs.&lt;/p&gt;
    &lt;p&gt;Before you optimize, question whether the work should exist at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;19. Process exists to reduce uncertainty, not to create paper trails.&lt;/head&gt;
    &lt;p&gt;The best process makes coordination easier and failures cheaper. The worst process is bureaucratic theater - it exists not to help but to assign blame when things go wrong.&lt;/p&gt;
    &lt;p&gt;If you can’t explain how a process reduces risk or increases clarity, it’s probably just overhead.&lt;/p&gt;
    &lt;p&gt;And if people are spending more time documenting their work than doing it, something has gone deeply wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;20. Eventually, time becomes worth more than money. Act accordingly.&lt;/head&gt;
    &lt;p&gt;Early in your career, you trade time for money - and that’s fine. But at some point, the calculus inverts. You start to realize that time is the non-renewable resource.&lt;/p&gt;
    &lt;p&gt;I’ve watched senior engineers burn out chasing the next promo level, optimizing for a few more percentage points of compensation. Some of them got it. Most of them wondered, afterward, if it was worth what they gave up.&lt;/p&gt;
    &lt;p&gt;The answer isn’t “don’t work hard.” It’s “know what you’re trading, and make the trade deliberately.”&lt;/p&gt;
    &lt;head rend="h2"&gt;21. There are no shortcuts, but there is compounding.&lt;/head&gt;
    &lt;p&gt;Expertise comes from deliberate practice - pushing slightly beyond your current skill, reflecting, repeating. For years. There’s no condensed version.&lt;/p&gt;
    &lt;p&gt;But here’s the hopeful part: learning compounds when it creates new options, not just new trivia. Write - not for engagement, but for clarity. Build reusable primitives. Collect scar tissue into playbooks.&lt;/p&gt;
    &lt;p&gt;The engineer who treats their career as compound interest, not lottery tickets, tends to end up much further ahead.&lt;/p&gt;
    &lt;head rend="h2"&gt;A final thought&lt;/head&gt;
    &lt;p&gt;Twenty-one lessons sounds like a lot, but they really come down to a few core ideas: stay curious, stay humble, and remember that the work is always about people - the users you’re building for and the teammates you’re building with.&lt;/p&gt;
    &lt;p&gt;A career in engineering is long enough to make plenty of mistakes and still come out ahead. The engineers I admire most aren’t the ones who got everything right - they’re the ones who learned from what went wrong, shared what they discovered, and kept showing up.&lt;/p&gt;
    &lt;p&gt;If you’re early in your journey, know that it gets richer with time. If you’re deep into it, I hope some of these resonate.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46488819</guid><pubDate>Sun, 04 Jan 2026 15:23:54 +0000</pubDate></item></channel></rss>