<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 29 Aug 2025 12:18:36 +0000</lastBuildDate><item><title>Building your own CLI coding agent with Pydantic-AI</title><link>https://martinfowler.com/articles/build-own-coding-agent.html</link><description>&lt;doc fingerprint="5494c4536b9188be"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building your own CLI Coding Agent with Pydantic-AI&lt;/head&gt;
    &lt;p&gt;Learning by doing&lt;/p&gt;
    &lt;p&gt;CLI coding agents are a fundamentally different tool to chatbots or autocomplete tools - they're agents that can read code, run tests, and update a codebase. While commercial tools are impressive, they don't understand the particular context of our environment and the eccentricities of our specific project. Instead we can build our own coding agent by assembling open source tools, using our specific development standards for: testing, documentation production, code reasoning, and file system operations.&lt;/p&gt;
    &lt;p&gt;27 August 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The wave of CLI Coding Agents&lt;/item&gt;
      &lt;item&gt;Why Build When You Can Buy?&lt;/item&gt;
      &lt;item&gt;The Architecture of Our Development Agent&lt;/item&gt;
      &lt;item&gt;Starting Simple: The Foundation&lt;/item&gt;
      &lt;item&gt;First Capability: Testing!&lt;/item&gt;
      &lt;item&gt;Adding Intelligence: Instructions and intent&lt;/item&gt;
      &lt;item&gt;The MCP Revolution: Pluggable Capabilities&lt;/item&gt;
      &lt;item&gt;Sandboxed Python Execution&lt;/item&gt;
      &lt;item&gt;Up-to-Date library Documentation&lt;/item&gt;
      &lt;item&gt;AWS MCPs&lt;/item&gt;
      &lt;item&gt;Internet Search for Current Information&lt;/item&gt;
      &lt;item&gt;Structured Problem Solving&lt;/item&gt;
      &lt;item&gt;Optimising for Reasoning&lt;/item&gt;
      &lt;item&gt;Desktop Commander: Warning! With great power comes great responsibility!&lt;/item&gt;
      &lt;item&gt;The Complete System&lt;/item&gt;
      &lt;item&gt;What We Learned About CLI Agents&lt;/item&gt;
      &lt;item&gt;The Road Ahead&lt;/item&gt;
      &lt;item&gt;Why This Matters&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The wave of CLI Coding Agents&lt;/head&gt;
    &lt;p&gt;If you have tried Claude Code, Gemini Code, Open Code or Simon Willison’s LLM CLI, you’ve experienced something fundamentally different from ChatGPT or Github Copilot. These aren’t just chatbots or autocomplete tools - they’re agents that can read your code, run your tests, search docs and make changes to your codebase async.&lt;/p&gt;
    &lt;p&gt;But how do they work? For me the best way to understand how any tool works is to try and build it myself. So that’s exactly what we did, and in this article I’ll take you through how we built our own CLI Coding Agent using the Pydantic-AI framework and the Model Context Protocol (MCP). You’ll see not just how to assemble the pieces but why each capability matters and how it changes the way you can work with code.&lt;/p&gt;
    &lt;p&gt;Our implementation leverages AWS Bedrock but with Pydantic-AI you could easily use any other mainstream provider or even a fully local LLM.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Build When You Can Buy?&lt;/head&gt;
    &lt;p&gt;Before diving into the technical implementation, let's examine why we chose to build our own solution.&lt;/p&gt;
    &lt;p&gt;The answer became clear very quickly using our custom agent, while commercial tools are impressive, they’re built for general use cases. Our agent was fully customised to our internal context and all the little eccentricities of our specific project. More importantly, building it gave us insights into how these systems work and the quality of our own GenAI Platform and Dev Tooling.&lt;/p&gt;
    &lt;p&gt;Think of it like learning to cook. You can eat at restaurants forever but understanding how flavours combine and techniques work makes you appreciate food differently - and lets you create exactly what you want.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Architecture of Our Development Agent&lt;/head&gt;
    &lt;p&gt;At a high level, our coding assistant consists of several key components:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Core AI Model: Claude from Anthropic accessed through AWS Bedrock&lt;/item&gt;
      &lt;item&gt;Pydantic-AI Framework: provides the agent framework and many helpful utilities to make our Agent more useful immediately&lt;/item&gt;
      &lt;item&gt;MCP Servers: independent processes that give the agent specialised tools, MCP is a common standard for defining the servers that contain these tools.&lt;/item&gt;
      &lt;item&gt;CLI Interface: how users interact with the assistant&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The magic happens through the Model Context Protocol (MCP), which allows the AI model to use various tools through a standardized interface. This architecture makes our assistant highly extensible - we can easily add new capabilities by implementing additional MCP servers, but we’re getting ahead of ourselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;Starting Simple: The Foundation&lt;/head&gt;
    &lt;p&gt;We started by creating a basic project structure and installing the necessary dependencies:&lt;/p&gt;
    &lt;quote&gt;uv init uv add pydantic_ai uv add boto3&lt;/quote&gt;
    &lt;p&gt;Our primary dependencies include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;pydantic-ai&lt;/code&gt;: Framework for building AI agents&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;boto3&lt;/code&gt;: For AWS API interactions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We chose Claude Sonnet 4 from Anthropic (accessed via AWS Bedrock) as our foundation model due to its strong code understanding and generation capabilities. Here's how we configured it in our &lt;code&gt;main.py&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;import boto3 from pydantic_ai import Agent from pydantic_ai.mcp import MCPServerStdio from pydantic_ai.models.bedrock import BedrockConverseModel from pydantic_ai.providers.bedrock import BedrockProvider&lt;/quote&gt;
    &lt;quote&gt;bedrock_config = BotocoreConfig( read_timeout=300, connect_timeout=60, retries={"max_attempts": 3}, ) bedrock_client = boto3.client( "bedrock-runtime", region_name="eu-central-1", config=bedrock_config ) model = BedrockConverseModel( "eu.anthropic.claude-sonnet-4-20250514-v1:0", provider=BedrockProvider(bedrock_client=bedrock_client), ) agent = Agent( model=model, )&lt;/quote&gt;
    &lt;quote&gt;if __name__ == "__main__": agent.to_cli_sync()&lt;/quote&gt;
    &lt;p&gt;At this stage we already have a fully working CLI with a chat interface which we can use as you would a GUI chat interface, which is pretty cool for how little code this is! However we can definitely improve upon this.&lt;/p&gt;
    &lt;head rend="h2"&gt;First Capability: Testing!&lt;/head&gt;
    &lt;p&gt;Instead of running the tests ourselves after each coding iteration why not get the agent to do it? Seems simple right?&lt;/p&gt;
    &lt;quote&gt;import subprocess&lt;/quote&gt;
    &lt;quote&gt;@agent.tool_plain() def run_unit_tests() -&amp;gt; str: """Run unit tests using uv.""" result = subprocess.run( ["uv", "run", "pytest", "-xvs", "tests/"], capture_output=True, text=True ) return result.stdout&lt;/quote&gt;
    &lt;p&gt;Here we use the same pytest command you would run in the terminal (I’ve shortened ours for the article). Now something magical happened. I could say “X isn’t working” and the agent would:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1. Run the test suite&lt;/item&gt;
      &lt;item&gt;2. Identify which specific tests were failing&lt;/item&gt;
      &lt;item&gt;3. Analyze the error messages&lt;/item&gt;
      &lt;item&gt;4. Suggest targeted fixes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The workflow change: Instead of staring at test failures or copy pasting terminal outputs into ChatGPT we now give our agent super relevant context about any issues in our codebase.&lt;/p&gt;
    &lt;p&gt;However we noticed our agent sometimes “fixed” failing tests by suggesting changes to the tests, not the actual implementation. This led to our next addition.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adding Intelligence: Instructions and intent&lt;/head&gt;
    &lt;p&gt;We realised we needed to teach our agent a little more about our development philosophy and steer it away from bad behaviours.&lt;/p&gt;
    &lt;quote&gt;instructions = """ You are a specialised agent for maintaining and developing the XXXXXX codebase. ## Development Guidelines: 1. **Test Failures:** - When tests fail, fix the implementation first, not the tests - Tests represent expected behavior; implementation should conform to tests - Only modify tests if they clearly don't match specifications 2. **Code Changes:** - Make the smallest possible changes to fix issues - Focus on fixing the specific problem rather than rewriting large portions - Add unit tests for all new functionality before implementing it 3. **Best Practices:** - Keep functions small with a single responsibility - Implement proper error handling with appropriate exceptions - Be mindful of configuration dependencies in tests Remember to examine test failure messages carefully to understand the root cause before making any changes. """&lt;/quote&gt;
    &lt;quote&gt;agent = Agent( instructions=instructions, model=model, )&lt;/quote&gt;
    &lt;p&gt;The workflow change: The agent now understands our values around Test Driven Development and minimal changes. It stopped suggesting large refactors where a small fix would do (Mostly).&lt;/p&gt;
    &lt;p&gt;Now while we could continue building everything from absolute scratch and tweaking our prompts for days we want to go fast and use some tools other people have built - Enter Model Context Protocol (MCP).&lt;/p&gt;
    &lt;head rend="h2"&gt;The MCP Revolution: Pluggable Capabilities&lt;/head&gt;
    &lt;p&gt;This is where our agent transformed from a helpful assistant to something approaching the commercial CLI agents. The Model Context Protocol (MCP) allows us to add sophisticated capabilities by running specialized servers.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We can run these servers as a local process, so no data sharing, where we interact with STDIN/STDOUT to keep things simple and local. (More details on tools and MCP)&lt;/p&gt;
    &lt;head rend="h2"&gt;Sandboxed Python Execution&lt;/head&gt;
    &lt;p&gt;Using large language models to do calculations or executing arbitrary code they create is not effective and potentially very dangerous! To make our Agent more accurate and safe our first MCP addition was Pydantic Al’s default server for sandboxed Python code execution:&lt;/p&gt;
    &lt;quote&gt;run_python = MCPServerStdio( "deno", args=[ "run", "-N", "-R=node_modules", "-W=node_modules", "--node-modules-dir=auto", "jsr:@pydantic/mcp-run-python", "stdio", ], )&lt;/quote&gt;
    &lt;quote&gt;agent = Agent( ... mcp_servers=[ run_python ], )&lt;/quote&gt;
    &lt;p&gt;This gave our agent a sandbox where it could test ideas, prototype solutions, and verify its own suggestions.&lt;/p&gt;
    &lt;p&gt;NOTE: This is very different from running the tests where we need the local environment and is intended to be used to make calculations much more robust. This is because writing the code to output a number and then executing that code is much more reliable and understandable, scalable and repeatable than just generating the next token in a calculation. We have seen from frontier labs (including their leaked instructions) that this is a much better approach.&lt;/p&gt;
    &lt;p&gt;The workflow change: Doing calculations, even more complex ones, became significantly more reliable. This is useful for many things like dates, sums, counts etc. It also allows for a rapid iteration cycle of simple python code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Up-to-Date library Documentation&lt;/head&gt;
    &lt;p&gt;LLMs are mostly trained in batch on historical data this gives a fixed cutoff while languages and dependencies continue to change and improve so we added Context7 for access to up to date python library documentation in LLM consumable format:&lt;/p&gt;
    &lt;quote&gt;context7 = MCPServerStdio( command="npx", args=["-y", "@upstash/context7-mcp"], tool_prefix="context" )&lt;/quote&gt;
    &lt;p&gt;The workflow change: When working with newer libraries or trying to use advanced features, the agent could look up current documentation rather than relying on potentially outdated training data. This made it much more reliable for real-world development work.&lt;/p&gt;
    &lt;head rend="h2"&gt;AWS MCPs&lt;/head&gt;
    &lt;p&gt;Since this particular agent was built with an AWS platform in mind, we added the AWS Labs MCP servers for comprehensive cloud docs and integration:&lt;/p&gt;
    &lt;quote&gt;awslabs = MCPServerStdio( command="uvx", args=["awslabs.core-mcp-server@latest"], env={"FASTMCP_LOG_LEVEL": "ERROR"}, tool_prefix="awslabs", ) aws_docs = MCPServerStdio( command="uvx", args=["awslabs.aws-documentation-mcp-server@latest"], env={"FASTMCP_LOG_LEVEL": "ERROR", "AWS_DOCUMENTATION_PARTITION": "aws"}, tool_prefix="aws_docs", )&lt;/quote&gt;
    &lt;p&gt;The workflow change: Now when I mentioned âBedrock is timing outâ or âthe model responses are getting truncated,â the agent could directly access AWS documentation to help troubleshoot configuration issues. While we've only scratched the surface with these two servers, this is the tip of the iceberg—the AWS Labs MCP collection includes servers for CloudWatch metrics, Lambda debugging, IAM policy analysis, and much more. Even with just documentation access, cloud debugging became more conversational and contextual.&lt;/p&gt;
    &lt;head rend="h2"&gt;Internet Search for Current Information&lt;/head&gt;
    &lt;p&gt;Sometimes you need information that's not in any documentation—recent Stack Overflow discussions, GitHub issues, or the latest best practices. We added general internet search:&lt;/p&gt;
    &lt;quote&gt;internet_search = MCPServerStdio(command="uvx", args=["duckduckgo-mcp-server"])&lt;/quote&gt;
    &lt;p&gt;The workflow change: When encountering obscure errors or needing to understand recent changes in the ecosystem, the agent could search for current discussions and solutions. This was particularly valuable for debugging deployment issues or understanding breaking changes in dependencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Structured Problem Solving&lt;/head&gt;
    &lt;p&gt;One of the most valuable additions was the code reasoning MCP, which helps the agent think through complex problems systematically:&lt;/p&gt;
    &lt;quote&gt;code_reasoning = MCPServerStdio( command="npx", args=["-y", "@mettamatt/code-reasoning"], tool_prefix="code_reasoning", )&lt;/quote&gt;
    &lt;p&gt;The workflow change: Instead of jumping to solutions, the agent would break down complex problems into logical steps, explore alternative approaches, and explain its reasoning. This was invaluable for architectural decisions and debugging complex issues. I could ask âWhy is this API call failing intermittently?â and get a structured analysis of potential causes rather than just guesses.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optimising for Reasoning&lt;/head&gt;
    &lt;p&gt;As we added more sophisticated capabilities, we noticed that reasoning and analysis tasks often took much longer than regular text generation—especially when the output wasn't correctly formatted on the first try. We adjusted our Bedrock configuration to be more patient:&lt;/p&gt;
    &lt;quote&gt;bedrock_config = BotocoreConfig( read_timeout=300, connect_timeout=60, retries={"max_attempts": 3}, ) bedrock_client = boto3.client( "bedrock-runtime", region_name="eu-central-1", config=bedrock_config )&lt;/quote&gt;
    &lt;p&gt;The workflow change: The longer timeouts meant our agent could work through complex problems without timing out. When analyzing large codebases or reasoning through intricate architectural decisions, the agent could take the time needed to provide thorough, well-reasoned responses rather than rushing to incomplete solutions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Desktop Commander: Warning! With great power comes great responsibility!&lt;/head&gt;
    &lt;p&gt;At this point, our agent was already quite capable—it could reason through problems, execute code, search for information, and access AWS documentation. This MCP server transforms your agent from a helpful assistant into something that can actually do things in your development environment:&lt;/p&gt;
    &lt;quote&gt;desktop_commander = MCPServerStdio( command="npx", args=["-y", "@wonderwhy-er/desktop-commander"], tool_prefix="desktop_commander", )&lt;/quote&gt;
    &lt;p&gt;Desktop Commander provides an incredibly comprehensive toolkit: file system operations (read, write, search), terminal command execution with process management, surgical code editing with &lt;code&gt;edit_block&lt;/code&gt;, and even
      interactive REPL sessions. It's built on top of the MCP Filesystem Server
      but adds crucial capabilities like search-and-replace editing and
      intelligent process control.&lt;/p&gt;
    &lt;p&gt;The workflow change: This is where everything came together. I could now say âThe authentication tests are failing, please fix the issueâ and the agent would:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1. Run the test suite to see the specific failures&lt;/item&gt;
      &lt;item&gt;2. Read the failing test files to understand what was expected&lt;/item&gt;
      &lt;item&gt;3. Examine the authentication module code&lt;/item&gt;
      &lt;item&gt;4. Search the codebase for related patterns&lt;/item&gt;
      &lt;item&gt;5. Look up the documentation for the relevant library&lt;/item&gt;
      &lt;item&gt;6. Make edits to fix the implementation&lt;/item&gt;
      &lt;item&gt;7. Re-run the tests to verify the fix&lt;/item&gt;
      &lt;item&gt;8. Search for similar patterns elsewhere that might need updating&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of this happened in a single conversation thread, with the agent maintaining context throughout. It wasn't just generating code suggestions—it was actively debugging, editing, and verifying fixes like a pair programming partner.&lt;/p&gt;
    &lt;p&gt;The security model is thoughtful too, with configurable allowed directories, blocked commands, and proper permission boundaries. You can learn more about its extensive capabilities at the Desktop Commander documentation.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Complete System&lt;/head&gt;
    &lt;p&gt;Here's our final agent configuration:&lt;/p&gt;
    &lt;quote&gt;import asyncio import subprocess import boto3 from pydantic_ai import Agent from pydantic_ai.mcp import MCPServerStdio from pydantic_ai.models.bedrock import BedrockConverseModel from pydantic_ai.providers.bedrock import BedrockProvider from botocore.config import Config as BotocoreConfig bedrock_config = BotocoreConfig( read_timeout=300, connect_timeout=60, retries={"max_attempts": 3}, ) bedrock_client = boto3.client( "bedrock-runtime", region_name="eu-central-1", config=bedrock_config ) model = BedrockConverseModel( "eu.anthropic.claude-sonnet-4-20250514-v1:0", provider=BedrockProvider(bedrock_client=bedrock_client), ) agent = Agent( model=model, ) instructions = """ You are a specialised agent for maintaining and developing the XXXXXX codebase. ## Development Guidelines: 1. **Test Failures:** - When tests fail, fix the implementation first, not the tests - Tests represent expected behavior; implementation should conform to tests - Only modify tests if they clearly don't match specifications 2. **Code Changes:** - Make the smallest possible changes to fix issues - Focus on fixing the specific problem rather than rewriting large portions - Add unit tests for all new functionality before implementing it 3. **Best Practices:** - Keep functions small with a single responsibility - Implement proper error handling with appropriate exceptions - Be mindful of configuration dependencies in tests Remember to examine test failure messages carefully to understand the root cause before making any changes. """ run_python = MCPServerStdio( "deno", args=[ "run", "-N", "-R=node_modules", "-W=node_modules", "--node-modules-dir=auto", "jsr:@pydantic/mcp-run-python", "stdio", ], ) internet_search = MCPServerStdio(command="uvx", args=["duckduckgo-mcp-server"]) code_reasoning = MCPServerStdio( command="npx", args=["-y", "@mettamatt/code-reasoning"], tool_prefix="code_reasoning", ) desktop_commander = MCPServerStdio( command="npx", args=["-y", "@wonderwhy-er/desktop-commander"], tool_prefix="desktop_commander", ) awslabs = MCPServerStdio( command="uvx", args=["awslabs.core-mcp-server@latest"], env={"FASTMCP_LOG_LEVEL": "ERROR"}, tool_prefix="awslabs", ) aws_docs = MCPServerStdio( command="uvx", args=["awslabs.aws-documentation-mcp-server@latest"], env={"FASTMCP_LOG_LEVEL": "ERROR", "AWS_DOCUMENTATION_PARTITION": "aws"}, tool_prefix="aws_docs", ) context7 = MCPServerStdio( command="npx", args=["-y", "@upstash/context7-mcp"], tool_prefix="context" ) agent = Agent( instructions=instructions, model=model, mcp_servers=[ run_python, internet_search, code_reasoning, context7, awslabs, aws_docs, desktop_commander, ], ) @agent.tool_plain() def run_unit_tests() -&amp;gt; str: """Run unit tests using uv.""" result = subprocess.run( ["uv", "run", "pytest", "-xvs", "tests/"], capture_output=True, text=True ) return result.stdout async def main(): async with agent.run_mcp_servers(): await agent.to_cli() if __name__ == "__main__": asyncio.run(main())&lt;/quote&gt;
    &lt;p&gt;How it changes our workflow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Debugging becomes collaborative: you have an intelligent partner that can analyze error messages, suggest hypotheses, and help test solutions.&lt;/item&gt;
      &lt;item&gt;Learning accelerates: when working with unfamiliar libraries or patterns, the agent can explain existing code, suggest improvements, and teach you why certain approaches work better.&lt;/item&gt;
      &lt;item&gt;Context switching reduces: rather than jumping between documentation, Stack Overflow, AWS Console, and your IDE, you have a single interface that can access all these resources while maintaining context about your specific problem.&lt;/item&gt;
      &lt;item&gt;Problem-solving becomes structured: rather than jumping to solutions, the agent can break down complex issues into logical steps, explore alternatives, and explain its reasoning. Like having a real life talking rubber duck!&lt;/item&gt;
      &lt;item&gt;Code review improves: the agent can review your changes, spot potential issues, and suggest improvements before you commit—like having a senior developer looking over your shoulder.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What We Learned About CLI Agents&lt;/head&gt;
    &lt;p&gt;Building our own agent revealed several insights about this emerging paradigm:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MCP is (almost) all you need: the magic isn't in any single capability, but in how they work together. The agent that can run tests, read files, search documentation, execute code, access AWS services, and reason through problems systematically becomes qualitatively different from one that can only do any single task.&lt;/item&gt;
      &lt;item&gt;Current information is crucial: having access to real-time search and up-to-date documentation makes the agent much more reliable for real-world development work where training data might be outdated.&lt;/item&gt;
      &lt;item&gt;Structured thinking matters: the code reasoning capability transforms the agent from a clever autocomplete into a thinking partner that can break down complex problems and explore alternative solutions.&lt;/item&gt;
      &lt;item&gt;Context is king: commercial agents like Claude Code are impressive partly because they maintain context across all these different tools. Your agent needs to remember what it learned from the test run when it's making file changes.&lt;/item&gt;
      &lt;item&gt;Specialisation matters: our agent works better for our specific codebase than general-purpose tools because it understands our patterns, conventions, and tool preferences. If it falls short in any area then we can go and make the required changes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Road Ahead&lt;/head&gt;
    &lt;p&gt;The CLI agent paradigm is still evolving rapidly. Some areas we're exploring:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AWS-specific tooling: the AWS Labs MCP servers (https://awslabs.github.io/mcp/) provide incredible depth for cloud-native development—from CloudWatch metrics to Lambda debugging to IAM policy analysis.&lt;/item&gt;
      &lt;item&gt;Workflow Enhancements: teaching the agent our common development workflows so it can handle routine tasks end-to-end. Connecting the agent to our project management tools so it can understand priorities and coordinate with team processes.&lt;/item&gt;
      &lt;item&gt;Benchmarking: Terminal Bench looks like a great dataset and leaderboard to test this toy agent against the big boys!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why This Matters&lt;/head&gt;
    &lt;p&gt;CLI coding agents represent a fundamental shift from AI as a writing assistant to AI as a development partner. Unlike Copilot's autocomplete or ChatGPT's Q&amp;amp;A, these agents can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Understand your entire project context&lt;/item&gt;
      &lt;item&gt;Execute tasks across multiple tools&lt;/item&gt;
      &lt;item&gt;Maintain state across complex workflows&lt;/item&gt;
      &lt;item&gt;Learn from your specific codebase and patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Building one yourself—even a simple version—gives you insights into where this technology is heading and how to make the most of commercial tools when they arrive.&lt;/p&gt;
    &lt;p&gt;The future of software development isn't just about writing code faster. It's about having an intelligent partner that understands your goals, your constraints, and your codebase well enough to help you think through problems and implement solutions collaboratively.&lt;/p&gt;
    &lt;p&gt;And the best way to understand that future? Build it yourself.&lt;/p&gt;
    &lt;head&gt;Significant Revisions&lt;/head&gt;
    &lt;p&gt;27 August 2025: published&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45055439</guid></item><item><title>Some thoughts on LLMs and software development</title><link>https://martinfowler.com/articles/202508-ai-thoughts.html</link><description>&lt;doc fingerprint="192b3375fcf305ad"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Some thoughts on LLMs and Software Development&lt;/head&gt;
    &lt;p&gt;Iâm about to head away from looking after this site for a few weeks (part vacation, part work stuff). As I contemplate some weeks away from the daily routine, I feel an urge to share some scattered thoughts about the state of LLMs and AI.&lt;/p&gt;
    &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â&lt;/p&gt;
    &lt;p&gt;Iâve seen a few early surveys on the effect AI is having on software development, is it really speeding folks up, does it improve or wreck code quality? One of the big problems with these surveys is that they arenât taking into account how people are using the LLMs. From what I can tell the vast majority of LLM usage is fancy auto-complete, often using co-pilot. But those I know who get the most value from LLMs reckon that auto-complete isnât very useful, preferring approaches that allow the LLM to directly read and edit source code files to carry out tasks. My concern is that surveys that ignore the different work-flows of using LLMs will produce data thatâs going to send people down the wrong paths.&lt;/p&gt;
    &lt;p&gt;(Another complication is the varying capabilities of different models.)&lt;/p&gt;
    &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â&lt;/p&gt;
    &lt;p&gt;Iâm often asked, âwhat is the future of programming?â Should people consider entering software development now? Will LLMs eliminate the need for junior engineers? Should senior engineers get out of the profession before itâs too late? My answer to all these questions is âI havenât the foggiestâ. Furthermore I think anyone who says they know what this future will be is talking from an inappropriate orifice. We are still figuring out how to use LLMs, and it will be some time before we have a decent idea of how to use them well, especially if they gain significant improvements.&lt;/p&gt;
    &lt;p&gt;What I suggest, is that people experiment with them. At the least, read about what others are doing, but pay attention to the details of their workflows. Preferably experiment yourself, and do share your experiences.&lt;/p&gt;
    &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â&lt;/p&gt;
    &lt;p&gt;Iâm also asked: âis AI a bubbleâ? To which my answer is âOF COURSE ITâS A BUBBLEâ. All major technological advances have come with economic bubbles, from canals and railroads to the internet. We know with near 100% certainty that this bubble will pop, causing lots of investments to fizzle to nothing. However what we donât know is when it will pop, and thus how big the bubble will have grown, generating some real value in the process, before that happens. It could pop next month, or not for a couple of years.&lt;/p&gt;
    &lt;p&gt;We also know that when the bubble pops, many firms will go bust, but not all. When the dot-com bubble burst, it killed pets.com, it killed Webvanâ¦ but it did not kill Amazon.&lt;/p&gt;
    &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â&lt;/p&gt;
    &lt;p&gt;I retired from public speaking a couple of years ago. But while I donât miss the stress of giving talks, I do miss hanging out with my friends in the industry. So Iâm looking forward to catching up with many of them at GOTO Copenhagen. Iâve been involved with the GOTO conference series since the 1990s (when it was called JAOO), and continue to be impressed with how they put together a fascinating program.&lt;/p&gt;
    &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â¢Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â&lt;/p&gt;
    &lt;p&gt;My former colleague Rebecca Parsons, has been saying for a long time that hallucinations arenât a bug of LLMs, they are a feature. Indeed they are the feature. All an LLM does is produce hallucinations, itâs just that we find some of them useful.&lt;/p&gt;
    &lt;p&gt;One of the consequences of this is that we should always consider asking the LLM the same question more than once, perhaps with some variation in the wording. Then we can compare answers, indeed perhaps ask the LLM to compare answers for us. The difference in the answers can be as useful as the answers themselves.&lt;/p&gt;
    &lt;p&gt;Certainly if we ever ask a hallucination engine for a numeric answer, we should ask it at least three times, so we get some sense of the variation. Furthermore we shouldnât ask an LLM to calculate an answer than we can calculate deterministically (yes, Iâve seen this). It is OK to ask an LLM to generate code to calculate an answer (but still do it more than once).&lt;/p&gt;
    &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â&lt;/p&gt;
    &lt;p&gt;Other forms of engineering have to take into account the variability of the world. A structural engineer builds in tolerance for all the factors she canât measure. (I remember being told early in my career that the unique characteristic of digital electronics was that there was no concept of tolerances.) Process engineers consider that humans are executing tasks, and will sometimes be forgetful or careless. Software Engineering is unusual in that it works with deterministic machines. Maybe LLMs mark the point where we join our engineering peers in a world on non-determinism.&lt;/p&gt;
    &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â&lt;/p&gt;
    &lt;p&gt;Iâve often heard, with decent reason, an LLM compared to a junior colleague. But I find LLMs are quite happy to say âall tests greenâ, yet when I run them, there are failures. If that was a junior engineerâs behavior, how long would it be before H.R. was involved?&lt;/p&gt;
    &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â â&lt;/p&gt;
    &lt;p&gt;LLMs create a huge increase in the attack surface of software systems. Simon Willison described the The Lethal Trifecta for AI agents: an agent that combines access to your private data, exposure to untrusted content, and a way to externally communicate (âexfiltrationâ). That âuntrusted contentâ can come in all sorts of ways, ask it to read a web page, and an attacker can easily put instructions on the website in 1pt white-on-white font to trick the gullible LLM to obtain that private data.&lt;/p&gt;
    &lt;p&gt;This is particularly serious when it comes to agents acting in a browser. Read an attackerâs web page, and it could trick the agent to go to your bank account in another tab and âbuy you a presentâ by transferring your balance to the kind attacker. Willisonâs view is that âthe entire concept of an agentic browser extension is fatally flawed and cannot be built safelyâ.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45055641</guid></item><item><title>My startup banking story (2023)</title><link>https://mitchellh.com/writing/my-startup-banking-story</link><description>&lt;doc fingerprint="36308099c0e4fd45"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;My Startup Banking Story&lt;/head&gt;
    &lt;p&gt;As a relatively new member of adult society, and an absolute infant of the business world, I didn't think much about bank choice. I figured: you put money in, you take money out, they're all the same. I also figured a local branch of a global bank is just a fungible tentacle of the giant banking machine, so also... who cares. Both incorrect assumptions, but let's relive and rediscover the effect of these assumptions as I did.&lt;/p&gt;
    &lt;p&gt;I start my company. I am a 22 year old recent college graduate living in San Francisco and pursuing the startup dream. I file my incorporation paperwork and wait to receive the necessary information for one of the first steps in the life of any new business: opening a bank account.&lt;/p&gt;
    &lt;p&gt;My filing is processed and I receive my EIN while visiting my parents in a suburb of Los Angeles. I have time to kill during one of the days so I drive down to the nearest Chase bank branch and open a business banking account. We'll call the person who helped me at the local branch Alex (this will be important later). I fund that account with a $20,000 personal loan which was almost all of my savings. I get an account number, an online login, and boom, we're in business!&lt;/p&gt;
    &lt;p&gt;About 6 months later, I raise a ~$1M seed round. I supply my Chase business banking account information for the wire, and at close the funding is wired to the account. I am sitting in a cafe in downtown San Francisco and I receive a call from an unknown number -- it's Alex, the banker that helped me open my account. He is being very casual, sort of like "Hey, just wanted to check on things." "I noticed a big deposit and wanted to make sure you had everything you needed." etc. For my side, I am mostly confused: why is this person calling me? I mostly say things like "yes yes I'm fine" and end the call quickly. Some wheels have started turning in Southern California, and I just hadn't known it yet.&lt;/p&gt;
    &lt;p&gt;Someone out there is probably mentally screaming at me "you fool!" at this point. With hindsight, I agree, but I will remind you dear reader that I have only been legally allowed to purchase alcohol for just over a year at this point in my life in the story.&lt;/p&gt;
    &lt;p&gt;The two years since 2012 -- from a banking perspective -- are quiet. Alex doesn't call me again, and we have no changes in our banking setup. For two years, the company was in heads-down building mode. We had shown significant product traction and were now ready to ramp up hiring to continue building.&lt;/p&gt;
    &lt;p&gt;At the end of 2014, we raise a $10.2M series A. I once again provide the same Chase business banking account and when the round closes, the funds are wired. Surprise surprise, Alex calls me! I'm starting to realize banks get an alert when there are major changes in account balances. Regardless, I once again brush Alex off -- "everything is good thanks! bye!" -- and continue on with my life.&lt;/p&gt;
    &lt;p&gt;At this point, I am bewildered that this guy I met at the random local branch to sign some papers is the one calling me, but didn't think much more of it at the time.&lt;/p&gt;
    &lt;p&gt;Once again, the two years since 2014 are mostly quiet from a banking perspective. Alex called more regularly to "check in" but otherwise nothing has changed. We still bank with Chase. I still have never gone back into a branch. I do everything online.&lt;/p&gt;
    &lt;p&gt;In the fall of 2016, we raise a $24M series B. I once again provide the same Chase business banking account and when the round closes, the funds are wired. Again, Alex calls. Again, I brush him off. The bank is where I plant money, I don't need anyone calling me. I just want to focus on building the company.&lt;/p&gt;
    &lt;p&gt;Throughout 2016, we had been building out an executive team for the company. And around the same time of the funding, we hire a Vice President of Finance. As he gets up to speed with our financial footing, he notices we have ~$35M sitting in cash in a Chase bank account. This is obviously not a smart thing to do, so he suggests some financial plans for how to better safeguard and utilize this mountain of cash.&lt;/p&gt;
    &lt;p&gt;As part of these plans, he suggests moving to Silicon Valley Bank (SVB). They're local to the Bay Area, he's worked with them before, and their bankers understand startups. It'll make accounts receivables, payables, payroll, etc. easier. To me, a bank is a bank is a bank, and if it helps make his job easier, I support his plan.&lt;/p&gt;
    &lt;p&gt;I log into the Chase online portal and initiate a wire for the full account balance to SVB. I have to pay something like a $30 fee to wire $35M (inconsequential to the story, but amusing nonetheless). Someone calls me for verification -- not Alex -- and the wire processes. Boom, we're done with Chase. Or so I think.&lt;/p&gt;
    &lt;p&gt;Alex calls me the next day. The day we initiated the wire was his day off. He sounds slightly agitated. I wasn't rude to him, but I was short with him. I switched banks, that's all there is to it. Thanks and goodbye. I never talk to Alex ever again. A bank is a bank is a bank, you put money in, you get money out, I don't understand why I would need to talk to someone.&lt;/p&gt;
    &lt;p&gt;I once again interrupt this story to appeal to the readers who are screaming at me and thank you for joining me on this story recounting my learning journey. Rest assured, at this point in the story, a professional was now in charge of the company's finances. But the decisions of the years leading up to this would have lingering effects for a few more years...&lt;/p&gt;
    &lt;p&gt;We now take a brief detour from the company, because this is where my personal life becomes relevant to the story.&lt;/p&gt;
    &lt;p&gt;For the prior three years, I had been living in Los Angeles. At some point during 2017, I had to go to a local Chase branch to make some changes to my personal accounts. It has been close to a year since the company stopped using Chase.&lt;/p&gt;
    &lt;p&gt;I visit the closest bank branch to my apartment. This bank branch is 20 miles north of where my parents live -- or the area with the branch where I opened the original company business bank accounts. I'm going to Chase for purely personal reasons, but this information is unfortunately relevant to the story.&lt;/p&gt;
    &lt;p&gt;At my local branch, I walk up to the teller and provide some handwritten information: my name, account number, desired transaction, etc. The teller looks at the paper, then looks at me, then looks back at the paper, then asks "Are you the HashiCorp guy?" What? HashiCorp is doing well but its not at all something a random non-technical consumer would know about. What is going on?&lt;/p&gt;
    &lt;p&gt;I say yes and he acknowledges but doesn't automatically offer any more information. I have to know, so I continue "How do you know that?" His response is "Dude, everyone at Chase down here knows about HashiCorp." Huh?&lt;/p&gt;
    &lt;p&gt;Up to this point, everything in the story is what I know and experienced first hand. What follows however is now second hand information as told by this teller. I haven't verified it, but other employees (at other branches) have said similar things to me over the years.&lt;/p&gt;
    &lt;p&gt;The teller proceeds to explain that Alex -- the guy I opened my original company account with -- became a fast rising star in the area. He had opened a business account in a small suburb that grew from $20,000 to $35,000,000 in balances in just four years! Despite the business (my business) not engaging in higher-revenue activities with the bank, the opportunity this account represented to the small business wing of the small suburban branch stirred up some excitement. It was just a matter of time.&lt;/p&gt;
    &lt;p&gt;And then, overnight, the account went to $0. Without talking to anyone, without any prior warning, that account was gone. I used online banking to transfer the entirety of the balance to another bank. The small suburban branch viewed this as a huge loss and Alex came into work with some tough questions and no answers. I instantly recalled feeling that Alex was agitated when he called me the day after the transfer, and I now had an idea of why.&lt;/p&gt;
    &lt;p&gt;I don't know what happened to Alex, the teller said he was "no longer working in the area" and said it with a noticably negative tone. I don't know what this means and I never found out. Perhaps, he just moved.&lt;/p&gt;
    &lt;p&gt;Following this event, Chase began an educational series to other local branches in the Los Angeles area explaining that there are these "startups" and how their financial patterns do not match those of a typical business. This series taught branches how to identify startups and how to consider their accounts. The case study they used for this presentation: HashiCorp.&lt;/p&gt;
    &lt;p&gt;It has been two years since hiring our VP of Finance and our financial department is in really healthy shape. I still have certain approval rights but no longer directly manage the accounts of the company.&lt;/p&gt;
    &lt;p&gt;Given the recent events with Silicon Valley Bank, I feel it's important to mention that at this point of the company, we had already begun diversifying our balances across multiple banks. SVB will not be mentioned again for the remainder of the story.&lt;/p&gt;
    &lt;p&gt;I'm working at my office at home in Los Angeles and I receive a phone call from our finance department. That's weird, I rarely receive phone calls. They tell me that during a routine internal audit, they realized there are a few customer accounts that are still paying their bill into the old Chase account.&lt;/p&gt;
    &lt;p&gt;I never closed that original Chase business account back in 2016. Let me explain how that happens. To close an account, I had to do it in person at any local Chase branch. Startups are busy, the account balance in 2016 was $0, and so I just put it off. Well, a couple years passed, it was still open, and a few customers were actually sending payments to it.&lt;/p&gt;
    &lt;p&gt;Worse, upon the realization that a few customers were paying into this account, our finance team realized that there was also fraud. For over a year, someone had been wiring thousands of dollars out every few weeks. We were short over $100,000 due to fraud. The finance team immediately called Chase and reported the fraud, locked down the account, and Chase started an investigation.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the finance team wanted me to close the account and wire the remaining balance to our actual business bank. With the fraud actively being handled by Chase and the finance team, I take on the task of closing the account. I immediately head to the nearest local Chase branch (once again a branch I've never been to before) and explain the situation.&lt;/p&gt;
    &lt;p&gt;After waiting for 15 minutes, a manager walks up to me. I know this can't be good. The branch manager explains that due to the actions taken to lock down the account for fraud, electronic transfers are unavailable. It doesn't matter that I'm provably the person who opened the account, electronic transfers are "impossible."&lt;/p&gt;
    &lt;p&gt;I say okay, and ask how I am supposed to close the account and transfer the remaining balance. He said I can close the account and withdraw the remaining balance only in cash. Cash? At this point, I literally asked: "like, green paper money cash?" He says yes. The balance in the account is somewhere around $1M.&lt;/p&gt;
    &lt;p&gt;I spent another two hours at the bank, juggling between calling our finance department, talking to this branch manager, and calling the Chase business phone line. We determine that instead of literal green cash, I can get a cashier's check. But there is a major problem: the amount the cashier's check is made out for has to be available at that local branch (or, whichever branch issues it). And, well, local branches I guess don't usually have $1M cash lying around. Or, if they do, its not enough to cover other business activities for the day so they're not willing to part with it.&lt;/p&gt;
    &lt;p&gt;The bank manager gives me the phone number of another branch manager that "may be able to help me." He literally writes down a phone number on a piece of paper. This is all feeling so surreal. I call this number and its for a slightly larger branch a few miles down the road. He says "you're the HashiCorp guy right?" And I roll my eyes. My infamy in the area is still well known.&lt;/p&gt;
    &lt;p&gt;This manager is very helpful, if not a bit gruff. He explains to me that each local branch has some sort of performance metric based on inflows and outflows at the given branch. Therefore, funding a $1M cash withdrawal was not attractive to them. I'm learning a lot in a really condensed period of time at this point. I don't even know if what he's telling me is true, or legal, all I hear is "this is going to be hard to do if you want it all at once."&lt;/p&gt;
    &lt;p&gt;But we do want it all at once. And we want to close the account. Now. He is not happy, but he says he'll call me back in 24 to 48 hours. True to his word, he calls me back the next day. He says that he had to coordinate to ensure his branch had the proper funding to satisfy this transaction, and that the funding would be available at a specific date a few days hence. He said I have to do the withdrawal that day because his branch will not hold that amount in cash for any longer.&lt;/p&gt;
    &lt;p&gt;He also subtly suggested I hire personal security or otherwise deposit those funds somewhere with haste. I believe his exact words were "if you lose that check, I can't help you." Again, this was a one time event, and I don't know how true that all is, but it was said to me.&lt;/p&gt;
    &lt;p&gt;A few days later, I walk into the branch (I did not hire personal security). I tell the teller my name and there is a flicker of immediate recognition. The teller guides me to a cubicle, the account is successfully closed, I'm issued a $1M cashier's check, and I walk out the door.&lt;/p&gt;
    &lt;p&gt;My business banking relationship with Chase is, at long last, complete.&lt;/p&gt;
    &lt;p&gt;I want to make it clear that Chase could've been an excellent banking partner. I never gave them the chance. I never told them what my business does or what I'd use the money for. I never talked to anyone (besides saying what I needed to get off the phone). This story isn't a cautionary tale about Chase, it is rather recounting my naivete as a young, first-time startup founder.&lt;/p&gt;
    &lt;p&gt;Epilogue.&lt;/p&gt;
    &lt;p&gt;The cashier's check was uneventfully deposited into our primary business banking account shortly after I walked out of the Chase branch.&lt;/p&gt;
    &lt;p&gt;The fraud investigation took a few months to complete but we were able to recover all of the lost funds.&lt;/p&gt;
    &lt;p&gt;Enough time has passed and employees cycled that I'm no longer recognized at any Los Angeles area Chase branches.&lt;/p&gt;
    &lt;p&gt;I look back on these events and there are many places I cringe. At the same time, I can't imagine making different choices because I was acting in good faith at all times with the knowledge I had. I think the choices I made were reasonable for any new founder, and I know many founders who have made similar choices.&lt;/p&gt;
    &lt;p&gt;Ultimately, there was no long term negative impact of the events that transpired (except maybe for Alex, but I truly don't know) and I can now look back on it with amusement.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45056177</guid></item><item><title>You no longer need JavaScript: an overview of what makes modern CSS so awesome</title><link>https://lyra.horse/blog/2025/08/you-dont-need-js/</link><description>&lt;doc fingerprint="3624d8120d159bbd"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You no longer need JavaScript&lt;/head&gt;&lt;p&gt;So much of the web these days is ruined by the bloat that is modern JavaScript frameworks. React apps that take several seconds to load. NextJS sites that throw random hydration errors. The node_modules folder that takes up gigabytes on your hard drive.&lt;/p&gt;&lt;p&gt;It’s awful. And you don’t need it.&lt;/p&gt;&lt;table&gt;&lt;row span="5"&gt;&lt;cell&gt;Name&lt;/cell&gt;&lt;cell&gt;Status&lt;/cell&gt;&lt;cell&gt;Type&lt;/cell&gt;&lt;cell&gt;Size&lt;/cell&gt;&lt;cell&gt;Time&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;document&lt;/cell&gt;&lt;cell&gt;153.8 kB&lt;/cell&gt;&lt;cell&gt;51 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;font&lt;/cell&gt;&lt;cell&gt;31.5 kB&lt;/cell&gt;&lt;cell&gt;32 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;font&lt;/cell&gt;&lt;cell&gt;28.5 kB&lt;/cell&gt;&lt;cell&gt;116 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;stylesheet&lt;/cell&gt;&lt;cell&gt;253 kB&lt;/cell&gt;&lt;cell&gt;47 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;648 kB&lt;/cell&gt;&lt;cell&gt;83 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;166 kB&lt;/cell&gt;&lt;cell&gt;363 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;83.3 kB&lt;/cell&gt;&lt;cell&gt;46 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;38.0 kB&lt;/cell&gt;&lt;cell&gt;95 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;414 B&lt;/cell&gt;&lt;cell&gt;34 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;32.6 kB&lt;/cell&gt;&lt;cell&gt;49 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;15.1 kB&lt;/cell&gt;&lt;cell&gt;71 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;143 kB&lt;/cell&gt;&lt;cell&gt;48 ms&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;200&lt;/cell&gt;&lt;cell&gt;script&lt;/cell&gt;&lt;cell&gt;4.1 kB&lt;/cell&gt;&lt;cell&gt;103 ms&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The intro paragraph of this post is tongue-in-cheek. It’s there to get you to read the rest of the post. I suspect the megabytes of tracking scripts intertwined with bad code is far more likely to be the real culprit behind all the terrible sites out there. Web frameworks have their time and place. And despite my personal distaste for them, I know they are used by many teams to build awesome well-optimized apps.&lt;/p&gt;&lt;p&gt;Despite that, I think there’s some beauty in leaving it all behind. Not just the frameworks, but JavaScript altogether. Not every site needs JavaScript. Perhaps your e-commerce site needs it for its complex carts and data visualization dashboards, but is it really a necessity for most of what’s out there?&lt;/p&gt;&lt;p&gt;It’s actually pretty incredible what HTML and CSS alone can achieve.&lt;/p&gt;&lt;head rend="h2"&gt;So, what do you say?&lt;/head&gt;&lt;p&gt;My goal with this article is to share my perspectives on the web, as well as introduce many aspects of modern HTML/CSS you may not be familiar with. I’m not trying to make you give up JavaScript, I’m just trying to show you everything that’s possible, leaving it up to you to pick what works best for whatever you’re working on.&lt;/p&gt;&lt;p&gt;I think there’s a lot most web developers don’t know about CSS.&lt;/p&gt;&lt;p&gt;And I think JS is often used where better alternatives exist.&lt;/p&gt;&lt;p&gt;So, let me show you what’s out there.&lt;/p&gt;&lt;head rend="h2"&gt;“But CSS sucks”&lt;/head&gt;&lt;p&gt;I believe a lot of the negativity towards CSS stems from not really knowing how to use it. Many developers kind of just skip learning the CSS fundamentals in favor of the more interesting Java- and TypeScript, and then go on to complain about a styling language they don’t understand.&lt;/p&gt;&lt;p&gt;I suspect this is due to many treating CSS as this silly third wheel for adding borders and box-shadows to a webapp. It’s undervalued and often compared to glorified crayons, rather than what it really is - a powerful domain-specific programming language.&lt;/p&gt;&lt;p&gt;It’s telling when to this day the only CSS joke in the webdev circles is centering a div.&lt;/p&gt;&lt;p&gt;Yes, the syntax isn’t the prettiest, but is it really that hard?&lt;/p&gt;&lt;p&gt;Besides, your devtools probably1 come with a fun little gadget that lets you fiddle with the flexbox by just clicking around. You don’t even need to remember the syntax.&lt;/p&gt;&lt;p&gt;I don’t think CSS is fundamentally any more difficult than JS, but if you skip the basics on one and only focus on the other, it’s no surprise it feels that way.&lt;/p&gt;&lt;head rend="h2"&gt;“But it’s painful to write”&lt;/head&gt;&lt;p&gt;Another source of disdain for CSS is how awful it has been to write in the past. This is very much true, and is probably why things like Sass and Tailwind2 exist.&lt;/p&gt;&lt;p&gt;But that’s the thing, it used to be bad.&lt;/p&gt;&lt;p&gt;(yes! the code above is standards compliant3)&lt;/p&gt;&lt;p&gt;In the past few years, CSS has received a ton of awesome quality-of-life additions, making it nice to do stuff that has historically required preprocessors or JavaScript.&lt;/p&gt;&lt;p&gt;Nesting is definitely one of my favorite additions!&lt;/p&gt;&lt;p&gt;In the past, you’ve had to write code that looks like this:&lt;/p&gt;&lt;code&gt;:&lt;/code&gt;&amp;#13;
&amp;#13;
&lt;p&gt;And yeah, that’s pretty awful to work with. For anything that involves multiple chained selectors, you kind of have to keep a mental map of how every parent selector relates to its children, and the more CSS you add the harder it gets.&lt;/p&gt;&lt;p&gt;But let’s try it with nesting:&lt;/p&gt;&lt;code&gt;:&lt;/code&gt;&amp;#13;
&lt;p&gt;That is way nicer to read4! All the relevant parts are right next to each other, so it’s a lot easier to understand what’s going on. Seeing the &lt;code&gt;&amp;amp;:hover&lt;/code&gt; and &lt;code&gt;&amp;amp;:active&lt;/code&gt; right next to the &lt;code&gt;.like&lt;/code&gt; button is especially nice imo.&lt;/p&gt;&lt;p&gt;And since you can sort of see the structure - the parent selectors “guarding” the child ones - it also makes it a lot easier to get away with short and simple class names (or even referring to elements themselves).&lt;/p&gt;&lt;p&gt;You may have noticed that I’m also making use of relative colors in the second example. I think the MDN article has a lot of awesome examples, but the jist of it is that you can take an existing color, modify it in many different ways across multiple color spaces, and mix it with other colors using color-mix().&lt;/p&gt;&lt;p&gt;These snippets are really useful for when you want something to be just ever so slightly darker or brighter, such as a button hover effect or a matching border color, and they’re way nicer to use than doing all those color conversions in JavaScript. If you’re feeling particularly adventurous, you could even go ahead and generate your entire color scheme in just CSS.&lt;/p&gt;&lt;head style="float:right;color:#0078B1;cursor:pointer;list-style:none;font-style:italic"&gt;view-source&lt;/head&gt;&lt;p&gt;(yes! the color picker above is written in just css)&lt;/p&gt;&lt;p&gt;Safari is currently broken when handling of cqw/cqh units, therefore the demo above may not work correctly. If this happens, try using Firefox or Chrome instead.&lt;/p&gt;&lt;p&gt;There are so many cool new CSS features that make writing it just that little bit nicer. Things like letting you use &lt;code&gt;(width &amp;lt;= 768px)&lt;/code&gt; instead of &lt;code&gt;(max-width: 768px)&lt;/code&gt; in your @media query, the lh unit that matches the line-height, the scrollbar-gutter property that solves the little scrollbar-related layout shifts, or the ability to finally center stuff vertically without flex/grid.&lt;/p&gt;&lt;p&gt;And all of this is brought together by the cherry on top that is Baseline. It’s a guarantee that a specific feature works in every major browser5, and it also lets you know since when - newly available features work in all the latest browsers, and widely available ones work in browsers up to 2.5 years old. Nesting, for example, has been fully supported in all browsers since December 2023, and thus will become widely available in June 2026. You can find the Baseline symbols in various places, such as the MDN docs6.&lt;/p&gt;&lt;p&gt;These are just a few examples of what makes modern CSS so much nicer to write than what we had even just 5 years ago. It almost feels like comparing ES37 to ECMAScript 2025 - and I wouldn’t blame your grudge if the former is what you’re used to.&lt;/p&gt;&lt;head rend="h2"&gt;Why bother?&lt;/head&gt;&lt;p&gt;Okay, so CSS has more quality-of-life stuff than before. Still, why would one choose to use it over something else? Doesn’t JavaScript already let us do everything just fine?&lt;/p&gt;&lt;p&gt;I think my reasons for using CSS fall into two main categories - because some users don’t want to use JavaScript, and because doing things in CSS can be genuinely better.&lt;/p&gt;&lt;p&gt;My blog, for example, focuses on infosec topics. Many security researchers (myself included) use a hardened browser configuration to protect themselves, which often means disabling JavaScript by default. I think it’s nice that they can fully experience my blog without changing their security settings or running a separate, sandboxed browser.&lt;/p&gt;&lt;p&gt;The same goes for privacy-conscious users, and it makes sense! As an experiment, I opened up a local Estonian news site in a web browser with JavaScript enabled. Can you guess how many js files it fetched? (answer in footnote8) That’s crazy! You do not want that running on your computer.&lt;/p&gt;&lt;p&gt;But surely, you are not one of the evil devs who loads a double-digit number of analytics scripts on your site - is there still any reason to reach for CSS?&lt;/p&gt;&lt;p&gt;Well, I think a lot of things are just plain nicer to make in HTML/CSS, both from the developer and end-user perspectives, be it for ease of use, accessibility, or performance.&lt;/p&gt;&lt;p&gt;Hover effects for your buttons? Toast animations? Input validation? All of these things just work in CSS, and you won’t have to reinvent the wheel, or throw kilobytes of someone else’s code at it. There will always be some cases where you do need that extra flexibility JavaScript often provides, but if you don’t need that, and doing it in CSS is easier, then why not save yourself the trouble?&lt;/p&gt;&lt;p&gt;And the performance of CSS is so much better! Every JavaScript interaction has to go through an event loop that wastes CPU cycles, eats some battery, and adds that tiny bit of stutter to everything.&lt;/p&gt;&lt;p&gt;Sure, in the grand scale of things it isn’t that bad, APIs like requestAnimationFrame are really good at keeping things smooth. But CSS animations run in the separate compositor thread, and aren’t affected by stutters and blocking in the event loop.&lt;/p&gt;&lt;p&gt;It makes quite a difference on low-end devices, but feels nice even on high-end ones. CSS animations on my 240hz monitor look amazing9 - JS can look pretty good too, but it has that tiny bit of stutter to it that keeps it from being perfect, especially if you plan on running other heavy code at the same time.&lt;/p&gt;&lt;p&gt;It also means you won’t have to worry as much about optimization, as the browser takes care of a lot more of the rendering side of things, and often runs your stuff on the GPU if possible.&lt;/p&gt;&lt;p&gt;Pro tip! Wanna trigger animations from JS anyways? Use the modern Web Animations API to easily play the smooth CSS animations from JS.&lt;/p&gt;&lt;head rend="h2"&gt;Transitioning&lt;/head&gt;&lt;p&gt;Speaking of which, I think it’s time I start showing you practical examples, and a good place to start showing the styles is well, @starting-style.&lt;/p&gt;&lt;p&gt;In the past it has been pretty annoying to add start animations (such as fade-ins) to elements. You’ve had to either set up an entire CSS animation with a separate @keyframes block to go with it, or do a transition using JavaScript where you first add an element to the page, then wait a frame, and then add a class to the element.&lt;/p&gt;&lt;p&gt;But this has all changed thanks to the new @starting-style at-rule!&lt;/p&gt;&lt;p&gt;Pretty much all you have to do is set your properties as usual, add the initial transition states to @starting-style, and add those properties to a transition. It’s pretty simple and it kind of just works without having to trigger the animation in any way.&lt;/p&gt;&lt;head rend="h2"&gt;Lunalover&lt;/head&gt;&lt;p&gt;Another good example of where CSS shines is theming. Many sites need separate light and dark modes, and modern CSS makes dealing with that pretty easy.&lt;/p&gt;&lt;p&gt;hi there!&lt;/p&gt;&lt;p&gt;you are awesome!&lt;/p&gt;&lt;p&gt;By setting the color-scheme property to &lt;code&gt;light dark&lt;/code&gt;, you are telling the browser to automatically pick the theme according to the user preference, and you can then make use of that by setting color values with the light-dark() function.&lt;/p&gt;&lt;p&gt;Not only does it set your own colors, but also those of the native components, such as the default buttons, form elements, and scrollbars. It kind of just makes stuff work by default, and that’s nice!&lt;/p&gt;&lt;p&gt;You can then add some way of overriding the color-scheme property to let the user pick a theme different from their system setting. Here I am using radio buttons to accomplish that.&lt;/p&gt;&lt;p&gt;Pro tip! CSS can’t save the theme preference, but you can still do progressive enhancement. Make the themes work CSS-only, and then add the saving/loading of preference as an optional extra in JavaScript or server-side code.&lt;/p&gt;&lt;head rend="h2"&gt;Lyres and accordions&lt;/head&gt;&lt;p&gt;“But those don’t look like radio buttons” I hear you cry.&lt;/p&gt;&lt;p&gt;Input elements such as radio buttons and checkboxes are a great foundation to build other stuff on top of - the example above consists of labels for the buttons and invisible radio buttons that can be checked for with the :checked pseudo-class.&lt;/p&gt;&lt;p&gt;This is how I made the theme selector from the previous example. I’ve made the radio buttons half-visible in the demo for clarity, but with the &lt;code&gt;opacity: 0&lt;/code&gt; they would not actually be visible.&lt;/p&gt;&lt;p&gt;There’s a whole lot going on here, so let’s break it down.&lt;/p&gt;&lt;p&gt;We start off with the radio-picker element - I just made it up, you can use a div instead if you’d prefer. We give it an aria-label to give the group an accessible name, and the aria role of radiogroup to make it work as a group for the radio buttons.&lt;/p&gt;&lt;p&gt;You could also use the fieldset element instead of doing the aria roles if that’d fit your use case better.&lt;/p&gt;&lt;p&gt;Next, we add the radio buttons with their respective labels - usually you’d have to use the for attribute on labels to define which element they’re referring to, but since we have the input inside the label we don’t have to do that.&lt;/p&gt;&lt;p&gt;All the &lt;code&gt;type="radio"&lt;/code&gt; inputs should also have a name value set to the same thing so that they are grouped together (you still need10 the radiogroup though). And then you can give them values or ids however you want.&lt;/p&gt;&lt;p&gt;We then style the labels as we wish - the :hover and :active pseudo-classes can be used to make the buttons more fun to click, the :has(input:checked) selector can be used to define the style of the selected button, and the :has(input:focus-visible) selector can be used to add an outline when someone tabs over to the button.&lt;/p&gt;&lt;p&gt;The difference between :focus and :focus-visible is that the former shows up even if you use your mouse, while the latter only shows up when you use keyboard navigation, so it’s often visually more clean to use the latter.&lt;/p&gt;&lt;p&gt;And last, we make the radio button input exist while not being visible. This is a bit hacky, but it’s how you can keep this control accessible to keyboard navigation and screen readers.&lt;/p&gt;&lt;p&gt;And that’s how we get the cool-looking radio buttons!&lt;/p&gt;&lt;p&gt;/ˈveɪni/&lt;/p&gt;&lt;p&gt;(intransitive) to come&lt;/p&gt;&lt;p&gt;/ˈviːdi/&lt;/p&gt;&lt;p&gt;(intransitive) to see&lt;/p&gt;&lt;p&gt;/ˈviːt͡ʃi/&lt;/p&gt;&lt;p&gt;(intransitive) to conquer&lt;/p&gt;&lt;p&gt;We can now use them in the CSS however we want by just seeing if they’re :checked. Here I made tabs with separate divs for the content by using a :has selector on a parent element to find out which radio button is currently selected.&lt;/p&gt;&lt;p&gt;The :has selector has to be on a parent element that contains both the radio button and the target element - you can simply use html or body if you want it to work across the entire page. You should never use something like &lt;code&gt;:has(…)&lt;/code&gt; by itself as it’ll run the selector for every element of the page, which can cause performance issues (&lt;code&gt;body:has(…)&lt;/code&gt; is okay).&lt;/p&gt;&lt;head&gt;What's your name?&lt;/head&gt;My name is Lyra Rebane.&lt;head&gt;Cool name!&lt;/head&gt;I know ^_^&lt;head&gt;Where can I learn more?&lt;/head&gt;On my website, lyra.horse!&lt;p&gt;Finally, before we move on, I want to give you a quick introduction to the details element. It’s great for if you want an accordion-style menu, such as for a FAQ section. The details open and close independently of each other, but you can set their name attribute to the same value to have only one open at a time.&lt;/p&gt;&lt;p&gt;Using them is pretty easy, put your content and a summary tag inside a details tag, and put the title inside the summary tag. The example above is a bit more convoluted for the visual flair, but all you really need is the html part of it.&lt;/p&gt;&lt;p&gt;The details elements are pretty stylable! You can add animations depending on the [open] state, and you can also get rid of the arrow by setting &lt;code&gt;list-style: none&lt;/code&gt; on the summary.&lt;/p&gt;&lt;p&gt;Also, ctrl+f works with it, which is a big win in my book!&lt;/p&gt;&lt;head rend="h2"&gt;Validation&lt;/head&gt;&lt;p&gt;And lastly, I want to show you the power of input validation in HTML and CSS.&lt;/p&gt;&lt;p&gt;This is a simple example of how you can validate an input field with a regex pattern. If you set a pattern attribute like above, a form that contains the input cannot be submitted unless the field matches the pattern. If you’re submitting something like an e-mail address, a phone number, or a url, it might make sense to use the respective input types instead of writing your own regex.&lt;/p&gt;&lt;p&gt;Now, where CSS comes in is styling the input to show whether its value is valid. In the example above, I’m using :valid and :invalid to set a border color, but that comes with the downside of always having your input marked, even if the user hasn’t entered anything yet.&lt;/p&gt;&lt;p&gt;An easy win here is to instead use :user-valid and :user-invalid - these pseudo-classes only become active once you’ve interacted with input field. I also made this example use an outline instead of a border, which I think looks a lot nicer.&lt;/p&gt;&lt;p&gt;It may sometimes even make sense to use a combination of :valid and :user-invalid.&lt;/p&gt;&lt;p&gt;And of course, you can use the :has selector to style other elements depending on the input too!&lt;/p&gt;&lt;p&gt;- be 8-16 characters&lt;/p&gt;&lt;p&gt;- contain at least ⅰ roman numeral&lt;/p&gt;&lt;p&gt;- not end with a letter&lt;/p&gt;&lt;p&gt;This one's just for fun ^_-! you win! yay!&lt;/p&gt;&lt;p&gt;I do want to mention that for some stuff, such as date pickers &lt;/p&gt;&lt;head rend="h2"&gt;Do not the vw/vh&lt;/head&gt;&lt;p&gt;This section is kind of random but I wanted to include it here because I think a lot of people are messing this one up and I want more people to know how to do this stuff right.&lt;/p&gt;&lt;p&gt;So CSS has vw/vh units that correspond to 1% of the viewport width and height respectively, which makes perfect sense for desktop browsers.&lt;/p&gt;&lt;p&gt;You no longer need JavaScript&lt;/p&gt;&lt;p&gt;yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap&lt;/p&gt;&lt;p&gt;Where it becomes a bit more nuanced is on mobile devices. For example, mobile versions of both Firefox and Chrome will hide the URL bar when scrolling down on a page.&lt;/p&gt;&lt;p&gt;This causes the vw/vh units to be a bit ambigous - do they represent the entire available screen, only the area that’s visible with the URL bar, or something in between?&lt;/p&gt;&lt;p&gt;If it’s the first option, you might end up with buttons or links off-screen11! If it’s the second, you may end up with a background div that doesn’t cover the entire background.&lt;/p&gt;&lt;p&gt;lvh&lt;/p&gt;&lt;p&gt;dvh&lt;/p&gt;&lt;p&gt;svh&lt;/p&gt;&lt;p&gt;lvh&lt;/p&gt;&lt;p&gt;svh&lt;/p&gt;&lt;p&gt;dvh&lt;/p&gt;&lt;p&gt;lvh&lt;/p&gt;&lt;p&gt;svh&lt;/p&gt;&lt;p&gt;dvh&lt;/p&gt;&lt;p&gt;lvh&lt;/p&gt;&lt;p&gt;svh&lt;/p&gt;&lt;p&gt;dvh&lt;/p&gt;&lt;p&gt;lvh&lt;/p&gt;&lt;p&gt;svh&lt;/p&gt;&lt;p&gt;dvh&lt;/p&gt;&lt;p&gt;lvh&lt;/p&gt;&lt;p&gt;svh&lt;/p&gt;&lt;p&gt;dvh&lt;/p&gt;&lt;p&gt;Your values&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Unit&lt;/cell&gt;&lt;cell role="head"&gt;Value&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;vh&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;lvh&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;dvh&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;svh&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Above is a table of values your browser reports - if you're on mobile, try scrolling the blogpost up and down so that the URL bar hides and see how the numbers change.&lt;/p&gt;&lt;p&gt;The values are multiplied by 100 (eg 100vh is used instead of 1vh).&lt;/p&gt;&lt;p&gt;The solution to this is to use the new responsive viewport units: lvh, svh, and dvh.&lt;/p&gt;&lt;p&gt;lvh stands for largest viewport height, and thus is useful for things like backgrounds that you’d want to cover the entire screen with, and wouldn’t care about getting cut off.&lt;/p&gt;&lt;p&gt;svh stands for smallest viewport height, and should be used for things that must always fit on the screen, such as buttons and links.&lt;/p&gt;&lt;p&gt;And dvh stands for dynamic viewport height - this one will update to whatever the current viewport height is. It might seem like the obvious choice, but it should not be used for elements you don’t want resizing or moving around as the user scrolls the page, as it could become quite annoying and possibly even laggy otherwise.&lt;/p&gt;&lt;p&gt;Of course, the respective lvw, svw, and dvw units exist too :).&lt;/p&gt;&lt;head rend="h3"&gt;Keyboard cat&lt;/head&gt;&lt;p&gt;By default, the viewport units do not account for the keyboard overlaying the page.&lt;/p&gt;&lt;p&gt;There are two ways to deal with that: the interactive-widget attribute, and the VirtualKeyboard API.&lt;/p&gt;&lt;p&gt;The former option is widely supported across browsers, works without JS, and goes in the meta viewport tag. It makes it so that opening the keyboard will change all of the viewport units.&lt;/p&gt;&lt;p&gt;The latter option is currently only supported in Chromium-based browsers, and requires a single line of JavaScript to use:&lt;/p&gt;&lt;p&gt;The advantage of the second option is that it allows you to use environment variables in CSS to get the position and size of the keyboard, which is pretty cool.&lt;/p&gt;&lt;p&gt;But considering the fact that it doesn’t work cross-browser, I’d avoid it.&lt;/p&gt;&lt;head rend="h2"&gt;CSS wishlist&lt;/head&gt;&lt;p&gt;Alright, so this is a little different from the rest of the post, but I wanted to bring up some things that I wish were in CSS. I haven’t fully fleshed out all of them, so some definitely wouldn’t fit the spec as-is, but maybe they can inspire some other stuff at least.&lt;/p&gt;&lt;p&gt;They are just fun ideas, don’t take them too seriously.&lt;/p&gt;&lt;head rend="h3"&gt;Reusable blocks&lt;/head&gt;&lt;p&gt;I wish it was possible to put classes in other classes in CSS, so that you could write something like:&lt;/p&gt;&lt;code&gt;.&lt;/code&gt;&amp;#13;
&lt;p&gt;This is something that Tailwind already has, and that makes me jealous.&lt;/p&gt;&lt;head rend="h3"&gt;Combined @media selectors&lt;/head&gt;&lt;p&gt;We can currently do nested @media queries, and also multiple selectors at the same time:&lt;/p&gt;&lt;p&gt;But we cannot combine the two into a single selector:&lt;/p&gt;&lt;p&gt;Which means if you want to do that you’ll inevitably have to repeat code or do some silly variable hacks, neither of which is ideal.&lt;/p&gt;&lt;head rend="h3"&gt;n-th child variable&lt;/head&gt;&lt;p&gt;For many of the CSS crimes I like to commit, I often end up writing code like:&lt;/p&gt;&lt;p&gt;And I think it would be a lot nicer if we could instead just do:&lt;/p&gt;&lt;head rend="h3"&gt;n-th letter targeting&lt;/head&gt;&lt;p&gt;CSS has the ability to style the ::first-letter of text. It’d be cool if were was also a ::nth-letter(…) selector, similar to :nth-child. I suspect the reason this isn’t a thing is because the ::first-letter selector is a pseudo-element, which would be a bit tricky to implement with the nth-letter idea.&lt;/p&gt;&lt;p&gt;hi there~&lt;/p&gt;&lt;p&gt;Blackle suggested that combining the nth-child() variable with :nth-letter targeting would also be fun for certain effects, such as putting the value in the sin() function to create wavy text.&lt;/p&gt;&lt;p&gt;(taphover to play animation)&lt;/p&gt;&lt;head rend="h3"&gt;Unit removal&lt;/head&gt;&lt;p&gt;I wish you could easily remove units from values, for example by dividing them.&lt;/p&gt;&lt;p&gt;This would allow you to use the size of the viewport or container as a numeric variable for things other than length. For example, the color picker from earlier uses it to convert the location of the color picker dot to a number to be used in a color value instead.&lt;/p&gt;&lt;p&gt;Uh, but wait? Does that mean this feature already exists?&lt;/p&gt;&lt;p&gt;Yeah, lol! We already have the ability to get unitless values in CSS, but it involves doing hacky stuff such as &lt;code&gt;tan(atan2(var(--vw), 1px))&lt;/code&gt; with a custom @property. It’d be nice to have this as just a division, for example.&lt;/p&gt;&lt;p&gt;Oh, and good news, this one we might actually be getting soon!&lt;/p&gt;&lt;p&gt;Also if you do something like &lt;code&gt;calc(1px + sqrt(1px * 1px))&lt;/code&gt; your browser will crash12.&lt;/p&gt;&lt;head rend="h3"&gt;A better image function&lt;/head&gt;&lt;p&gt;The image() function exists, but no browsers implement it. It’s similar to just using url(), but adds some really cool features such as a fallback color, and image fragments to crop a smaller section out of a bigger image (think spritesheets).&lt;/p&gt;&lt;p&gt;We can already do both fallbacks and spritesheets with the various background properties, but it’d be nice to have this pretty syntax. I’d honestly love this syntax even more for &amp;lt;img&amp;gt; tags than CSS.&lt;/p&gt;&lt;head rend="h3"&gt;style tags in body&lt;/head&gt;&lt;p&gt;I make heavy use of &amp;lt;style&amp;gt; tags in &amp;lt;body&amp;gt; for my projects. On my blog, for example, I write the relevant CSS close to their graphics so that you can start reading the blog before the entire page (or the entire CSS) has finished loading13. And it works great!&lt;/p&gt;&lt;p&gt;But what’s unfortunate is that despite browsers supporting this, and major sites using this, it’s not officially spec-compliant. I suspect it’s in the spec to avoid the FOUC footgun, but there are so many reasons you would want/need style in body that I don’t think it justifies it.&lt;/p&gt;&lt;p&gt;I think an HTML validator should warn for this, but not error.&lt;/p&gt;&lt;head rend="h2"&gt;The art&lt;/head&gt;&lt;p&gt;I want to end this article by saying that to me, web development is an art, and thus, CSS is too. I often have a hard time relating to people who do webdev solely to earn money or build a startup - web development is very different when you’re on a team and are given tasks from above instead of having free will over what you create for fun.&lt;/p&gt;&lt;p&gt;It’s probably most apparent with things like AI14, that for me take all the fun and creativity out of my work. But it also applies to build chain tooling such as linters and minifiers - the way I write my code is part of the art, and I don’t want a tool to erase that. I don’t even use an IDE15.&lt;/p&gt;&lt;p&gt;Among the practical reasons for sticking to CSS listed throughout this post, there’s a secret extra reason I like to do everything in CSS, and that’s expression and art. Art isn’t always practical, and using CSS isn’t either. But it’s how I like to express myself, and it’s why I do what I do.&lt;/p&gt;&lt;p&gt;I tried to keep this post approachable and practical for all web developers. But there is so much more to CSS that I’d like to talk about, so expect another post about the stuff that isn’t practical, and is instead just cool as fuck. I think CSS is a programming language, and I made a game to prove it.&lt;/p&gt;&lt;p&gt;But that’s a topic for another time.&lt;/p&gt;&lt;head rend="h2"&gt;afterword&lt;/head&gt;&lt;p&gt;it’s been almost a year since my last post, but i hope it’s been worth the wait ^_^&lt;/p&gt;&lt;p&gt;as usual, this post is a self-contained html file with no javascript, images, or other external resources - everything on the page is handwritten html/css, weighing in at around 49kB gzipped. it was really fun creating all the little interactive widgets and visuals this time around, i think i’ve improved in css a lot since the last time i posted.&lt;/p&gt;&lt;p&gt;this entire post turned out to be a bit of a fun mess (as did i!), it’s almost like a chaotic gradient of tone throughout, i hope it was still interesting and enjoyable to read though.&lt;/p&gt;&lt;p&gt;i have a few new posts in the works: in addition to the second css one mentioned earlier, i also have one about a new web vulnerability subclass i discovered, and one about a trans topic. i’m not sure when these posts will come out, but we’ll see! make sure to add me to your rss reader if that sounds fun.&lt;/p&gt;&lt;p&gt;i’ll also be giving a talk at bsides tallinn in september! i’m hoping to also do css-related talks at the next ccc and disobey, but we’ll have to see whether i get accepted and have the travel budget for those.&lt;/p&gt;&lt;p&gt;thank you so much for reading &amp;lt;3&lt;/p&gt;&lt;p&gt;you're awesome!! (i can tell because you checked that checkbox from earlier)&lt;/p&gt;&lt;p&gt;If you’d like to reach out, feel free to message me on my socials or at lyra.horse [at] gmail.com.&lt;/p&gt;&lt;p&gt;Discuss this post on: twitter, mastodon, lobsters&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;Chrome’s DevTools come with the cool flexbox widget. Firefox’s however don’t seem to for some reason? I find that weird because Firefox does have really good tools for flexbox and grid development, so this seems like an odd omission. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;While I think what I said is true, Tailwind does have more to its existence, the core of which can be found in this post by its creator. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;You are allowed to just make up elements as long as their names contain a hyphen. Apart from the 8 existing tags listed at the link, no HTML tags contain a hyphen and none ever will. The spec even has&lt;/p&gt;&lt;code&gt;&amp;lt;math-α&amp;gt;&lt;/code&gt;and&lt;code&gt;&amp;lt;emotion-😍&amp;gt;&lt;/code&gt;as examples of allowed names. You are allowed to make up attributes on an autonomous custom element, but for other elements (built-in or extended) you should only make up&lt;code&gt;data-*&lt;/code&gt;attributes. I make heavy use of this on my blog to make writing HTML and CSS nicer and avoid meaningless div-soup. ↩︎&lt;/item&gt;&lt;item&gt;&lt;p&gt;Still not nice to read for you? I’m personally not a fan of BEM, but I’d definitely recommend reading up on it too if you just don’t vibe with the way I’m writing my examples. Also, my example intentionally shows off a lot of the syntax at once, but in the real world it might make sense to structure things a little differently. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Baseline browsers are Safari (macOS/iOS), Chrome (desktop/Android), Edge (desktop), and Firefox (desktop/Android). ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The MDN docs of course also list detailed browser compatibility, but the Baseline symbols are nice for just getting a quick “yeah, we can use it and it’ll work for everyone” type overview. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;ES3 (1999) is the last “classic” version of JavaScript. In 2009 we got the first major revision known as ES5, and a few years later we kicked off the yearly spec updates with ES2015. Also ES4 was abandoned which makes me feel sad :c. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;93 files!! Seems like they’re 1/3 functionality, 1/3 ads, and 1/3 analytics. The site works just fine with JavaScript disabled - only stuff like the comments section and ads won’t load. It’s no longer a laggy mess either for some reason. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I think the x3ctf challenges page looks really smooth on my computer - the marquee text animation and clicking on the challenges is buttery. And it also runs pretty well on the low-end hardware I have. Note that some browser performance recording tools can act a bit weird with CSS animations, so make sure your tools are working as expected before using them. Unrelated, but I made some other cool x3ctf web stuff too - check out the archive. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;There’s a bug in Chrome that requires you to use a fieldset/radiogroup for the radio button index to work correctly in screenreaders. Eg if you have 3 radio buttons with the same name, selecting one of them should read “radio button 1 of 3”, which is what Firefox does, but in Chrome it will instead read it as “radio button 4 of 9” or whatever if you don’t have a fieldset/radiogroup because it kind of just combines all the radio buttons on the page into a single index. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;A certain HR platform I have to use puts its action buttons at the very bottom of a 100vh container, leading to them not being visible/interactable on my phone - not a headache you want to go through when requesting sick days. It’s a good example of how just using the wrong unit can cause a pretty bad real world accessibility problem. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Well, probably not. This is a bug I found while writing this post that only affects Chrome, and it’ll probably get fixed before it even manages to hit stable. Update: I took so long to get this blog post out that it has been fixed now. During the writing of this blog post I found another bug in Chrome though, which is pretty funny. Update 2: I found yet another Chrome bug while writing this post, this one is kinda weird, you should read it. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;This matters for people on slow connections, such as bad mobile data, satellite internet, tor, or iodine. While my blog posts are very small in size, the CSS alone can take up more than the first 14kB of a TCP round trip, so with blocking CSS in the head you might have to wait a few extra seconds (or minutes, in the case of iodine) just to start reading the first paragraph. Now, that 14kB number isn’t completely accurate in the modern world, but testing on my own server (HTTP/2, TLS 1.3), around ~16kB of the compressed html reaches the browser in the first batch of http data. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;By this I mean tools such as Copilot, Cursor, chatbots etc. I understand there is a huge difference between full-on vibe coding and just using the tab key, but I do not want to use or interact with any of those tools. Please respect that. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I write all my code (and blogposts) in Sublime Text, which to me is just a glorified version of Notepad. The features over Notepad it gives me are syntax highlighting, multiple cursors, keyboard shortcuts, and a better visual design. It doesn’t do that much, and yet, it’s perfect. It’s so good I paid for it. ↩︎&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45056878</guid></item><item><title>Fuck up my site – Turn any website into beautiful chaos</title><link>https://www.fuckupmysite.com/?url=https%3A%2F%2Fnews.ycombinator.com&amp;torchCursor=true&amp;comicSans=true&amp;fakeCursors=true&amp;peskyFly=true</link><description>&lt;doc fingerprint="a9a77b49597bf6f1"&gt;
  &lt;main&gt;
    &lt;p&gt;DESTRUCTION LEVEL0%&lt;/p&gt;
    &lt;p&gt;▓&lt;/p&gt;
    &lt;head rend="h1"&gt;fuckupmysite&lt;/head&gt;
    &lt;p&gt;Some people just want to watch the web burn&lt;/p&gt;
    &lt;head rend="h2"&gt;😈Chaos Settings&lt;/head&gt;
    &lt;p&gt;3 of 6 agents of chaos enabled&lt;/p&gt;
    &lt;p&gt;⚠️&lt;/p&gt;
    &lt;head rend="h3"&gt;IMPORTANT DISCLAIMER - FOR PARODY &amp;amp; ENTERTAINMENT ONLY&lt;/head&gt;
    &lt;p&gt;This tool is for parody and entertainment purposes only. It temporarily applies visual chaos effects to websites for comedic effect. We do not store, collect, or transmit any personal information.&lt;/p&gt;
    &lt;p&gt;NEVER enter passwords, credit card details, or any sensitive information while using this tool. The proxied sites are not secure and should not be used for any real transactions or logins.&lt;/p&gt;
    &lt;p&gt;By using this tool, you acknowledge that it's purely for entertainment and you will not enter any sensitive data. Banking, financial, healthcare, and government sites are blocked for safety.&lt;/p&gt;
    &lt;p&gt;Heads up: Not every site plays nice with the chaos. Got feedback or discovered something broken? Let me know on Twitter&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45057020</guid></item><item><title>Expert: LSP for Elixir</title><link>https://github.com/elixir-lang/expert</link><description>&lt;doc fingerprint="24853a795d5f6fa5"&gt;
  &lt;main&gt;
    &lt;p&gt;Expert is the official language server implementation for the Elixir programming language.&lt;/p&gt;
    &lt;p&gt;You can download Expert from the releases page for your operating system and architecture. Put the executable somewhere on your &lt;code&gt;$PATH&lt;/code&gt;, like &lt;code&gt;~/.local/bin/expert&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;For editor specific installation instructions, please refer to the Installation Instructions&lt;/p&gt;
    &lt;p&gt;If you want to try out the latest features, you can download a nightly build.&lt;/p&gt;
    &lt;p&gt;Using the GH CLI, you can run the following command to download the latest nightly build:&lt;/p&gt;
    &lt;code&gt;gh release download nightly --pattern 'expert_linux_amd64' --repo elixir-lang/expert&lt;/code&gt;
    &lt;p&gt;Then point your editor to the downloaded binary.&lt;/p&gt;
    &lt;p&gt;To build Expert from source, you need Zig &lt;code&gt;0.14.1&lt;/code&gt; installed on your system.&lt;/p&gt;
    &lt;p&gt;Then you can run the following command or follow the instructions in the Installation Instructions:&lt;/p&gt;
    &lt;code&gt;just release-local&lt;/code&gt;
    &lt;p&gt;This will build the Expert binary and place it in the &lt;code&gt;apps/expert/burrito_out&lt;/code&gt; directory. You can then point your
editor to this binary.&lt;/p&gt;
    &lt;p&gt;Thank you to our corporate sponsors! If you'd like to start sponsoring the project, please read more below.&lt;/p&gt;
    &lt;p&gt;For companies wanting to directly sponsor full time work on Expert, please reach out to Dan Janowski: EEF Chair of Sponsorship WG at danj@erlef.org.&lt;/p&gt;
    &lt;p&gt;Individuals can donate using GitHub sponsors. Team members are listed in the sidebar.&lt;/p&gt;
    &lt;p&gt;Expert source code is released under Apache License 2.0.&lt;/p&gt;
    &lt;p&gt;Check LICENSE file for more information.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45057322</guid></item><item><title>The Space Shuttle Columbia disaster and the over-reliance on PowerPoint (2019)</title><link>https://mcdreeamiemusings.com/blog/2019/4/13/gsux1h6bnt8lqjd7w2t2mtvfg81uhx</link><description>&lt;doc fingerprint="b789dbf4ae617ccb"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve all sat in those presentations. A speaker with a stream of slides full of text, monotonously reading them off as we read along. We’re so used to it we expect it. We accept it. We even consider it ‘learning’. As an educator I push against ‘death by PowerPoint’ and I'm fascinated with how we can improve the way we present and teach. The fact is we know that PowerPoint kills. Most often the only victims are our audience’s inspiration and interest. This, however, is the story of a PowerPoint slide that actually helped kill seven people.&lt;/p&gt;
    &lt;p&gt;January 16th 2003. NASA Mission STS-107 is underway. The Space Shuttle Columbia launches carrying its crew of seven to low orbit. Their objective was to study the effects of microgravity on the human body and on ants and spiders they had with them. Columbia had been the first Space Shuttle, first launched in 1981 and had been on 27 missions prior to this one. Whereas other shuttle crews had focused on work to the Hubble Space Telescope or to the International Space Station this mission was one of pure scientific research.&lt;/p&gt;
    &lt;p&gt;The launch proceeded as normal. The crew settled into their mission. They would spend 16 days in orbit, completing 80 experiments. One day into their mission it was clear to those back on Earth that something had gone wrong.&lt;/p&gt;
    &lt;p&gt;As a matter of protocol NASA staff reviewed footage from an external camera mounted to the fuel tank. At eighty-two seconds into the launch a piece of spray on foam insulation (SOFI) fell from one of the ramps that attached the shuttle to its external fuel tank. As the crew rose at 28,968 kilometres per hour the piece of foam collided with one of the tiles on the outer edge of the shuttle’s left wing.&lt;/p&gt;
    &lt;p&gt;It was impossible to tell from Earth how much damage this foam, falling nine times faster than a fired bullet, would have caused when it collided with the wing. Foam falling during launch was nothing new. It had happened on four previous missions and was one of the reasons why the camera was there in the first place. But the tile the foam had struck was on the edge of the wing designed to protect the shuttle from the heat of Earth’s atmosphere during launch and re-entry. In space the shuttle was safe but NASA didn’t know how it would respond to re-entry. There were a number of options. The astronauts could perform a spacewalk and visually inspect the hull. NASA could launch another Space Shuttle to pick the crew up. Or they could risk re-entry.&lt;/p&gt;
    &lt;p&gt;NASA officials sat down with Boeing Corporation engineers who took them through three reports; a total of 28 slides. The salient point was whilst there was data showing that the tiles on the shuttle wing could tolerate being hit by the foam this was based on test conditions using foam more than 600 times smaller than that that had struck Columbia. This is the slide the engineers chose to illustrate this point:&lt;/p&gt;
    &lt;p&gt;NASA managers listened to the engineers and their PowerPoint. The engineers felt they had communicated the potential risks. NASA felt the engineers didn’t know what would happen but that all data pointed to there not being enough damage to put the lives of the crew in danger. They rejected the other options and pushed ahead with Columbia re-entering Earth’s atmosphere as normal. Columbia was scheduled to land at 0916 (EST) on February 1st 2003. Just before 0900, 61,170 metres above Dallas at 18 times the speed of sound, temperature readings on the shuttle’s left wing were abnormally high and then were lost. Tyre pressures on the left side were soon lost as was communication with the crew. At 0912, as Columbia should have been approaching the runway, ground control heard reports from residents near Dallas that the shuttle had been seen disintegrating. Columbia was lost and with it her crew of seven. The oldest crew member was 48.&lt;/p&gt;
    &lt;p&gt;The shuttle programme was on lock down, grounded for two years as the investigation began. The cause of the accident became clear: a hole in a tile on the left wing caused by the foam let the wing dangerously overheat until the shuttle disintegrated.&lt;/p&gt;
    &lt;p&gt;The questions to answer included a very simple one: Why, given that the foam strike had occurred at a force massively out of test conditions had NASA proceeded with re-entry?&lt;/p&gt;
    &lt;p&gt;Edward Tufte, a Professor at Yale University and expert in communication reviewed the slideshow the Boeing engineers had given NASA, in particular the above slide. His findings were tragically profound.&lt;/p&gt;
    &lt;p&gt;Firstly, the slide had a misleadingly reassuring title claiming that test data pointed to the tile being able to withstand the foam strike. This was not the case but the presence of the title, centred in the largest font makes this seem the salient, summary point of this slide. This helped Boeing’s message be lost almost immediately.&lt;/p&gt;
    &lt;p&gt;Secondly, the slide contains four different bullet points with no explanation of what they mean. This means that interpretation is left up to the reader. Is number 1 the main bullet point? Do the bullet points become less important or more? It’s not helped that there’s a change in font sizes as well. In all with bullet points and indents six levels of hierarchy were created. This allowed NASA managers to imply a hierarchy of importance in their head: the writing lower down and in smaller font was ignored. Actually, this had been where the contradictory (and most important) information was placed.&lt;/p&gt;
    &lt;p&gt;Thirdly, there is a huge amount of text, more than 100 words or figures on one screen. Two words, ‘SOFI’ and ‘ramp’ both mean the same thing: the foam. Vague terms are used. Sufficient is used once, significant or significantly, five times with little or no quantifiable data. As a result this left a lot open to audience interpretation. How much is significant? Is it statistical significance you mean or something else?&lt;/p&gt;
    &lt;p&gt;Finally the single most important fact, that the foam strike had occurred at forces massively out of test conditions, is hidden at the very bottom. Twelve little words which the audience would have had to wade through more than 100 to get to. If they even managed to keep reading to that point. In the middle it does say that it is possible for the foam to damage the tile. This is in the smallest font, lost.&lt;/p&gt;
    &lt;p&gt;NASA’s subsequent report criticised technical aspects along with human factors. Their report mentioned an over-reliance on PowerPoint:&lt;/p&gt;
    &lt;p&gt;“The Board views the endemic use of PowerPoint briefing slides instead of technical papers as an illustration of the problematic methods of technical communication at NASA.”&lt;/p&gt;
    &lt;p&gt;Edward Tufte’s full report makes for fascinating reading. Since being released in 1987 PowerPoint has grown exponentially to the point where it is now estimated than thirty million PowerPoint presentations are made every day. Yet, PowerPoint is blamed by academics for killing critical thought. Amazon’s CEO Jeff Bezos has banned it from meetings. Typing text on a screen and reading it out loud does not count as teaching. An audience reading text off the screen does not count as learning. Imagine if the engineers had put up a slide with just: “foam strike more than 600 times bigger than test data.” Maybe NASA would have listened. Maybe they wouldn’t have attempted re-entry. Next time you’re asked to give a talk remember Columbia. Don’t just jump to your laptop and write out slides of text. Think about your message. Don’t let that message be lost amongst text. Death by PowerPoint is a real thing. Sometimes literally.&lt;/p&gt;
    &lt;p&gt;Thanks for reading&lt;/p&gt;
    &lt;p&gt;- Jamie&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45057404</guid></item><item><title>Rupert's Property</title><link>https://johncarlosbaez.wordpress.com/2025/08/28/a-polyhedron-without-ruperts-property/</link><description>&lt;doc fingerprint="37eaebb6d330d3b1"&gt;
  &lt;main&gt;
    &lt;p&gt;You can cut a hole in a cube that’s big enough to slide an identical cube through that hole! Think about that for a minute—it’s kind of weird.&lt;/p&gt;
    &lt;p&gt;Amazingly, nobody could prove any convex polyhedron doesn’t have this property! It’s called ‘Rupert’s property’.&lt;/p&gt;
    &lt;p&gt;Until this week.&lt;/p&gt;
    &lt;p&gt;This week Steininger and Yurkevich proved there is a convex polyhedron that you can’t cut a hole in big enough to slide the entire polyhedron through the hole. It has 90 vertices, and apparently 240 edges and 152 faces.&lt;/p&gt;
    &lt;p&gt;To prove that no such hole is possible, they had to do a computer search of 18 million different holes, plus use a lot of extra math to make sure they’d checked enough possibilities:&lt;/p&gt;
    &lt;p&gt;• Jakob Steininger and Sergey Yurkevich, A convex polyhedron without Rupert’s property.&lt;/p&gt;
    &lt;p&gt;To celebrate their discovery, they gave this polyhedron a silly name. Since this polyhedron lacks Rupert’s property, they called it a ‘noperthedron’.&lt;/p&gt;
    &lt;p&gt;Why is this property called ‘Rupert’s property’? Wikipedia explains:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In geometry, Prince Rupert’s cube is the largest cube that can pass through a hole cut through a unit cube without splitting it into separate pieces. Its side length is approximately 1.06, 6% larger than the side length 1 of the unit cube through which it passes. The problem of finding the largest square that lies entirely within a unit cube is closely related, and has the same solution.&lt;/p&gt;
      &lt;p&gt;Prince Rupert’s cube is named after Prince Rupert of the Rhine, who asked whether a cube could be passed through a hole made in another cube of the same size without splitting the cube into two pieces. A positive answer was given by John Wallis. Approximately 100 years later, Pieter Nieuwland found the largest possible cube that can pass through a hole in a unit cube.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here Greg Egan shows how Rupert’s property works for the cube:&lt;/p&gt;
    &lt;p&gt;Here he shows how it works for the regular octahedron:&lt;/p&gt;
    &lt;p&gt;And finally, here’s a video by David Renshaw showing 26 polyhedra with Rupert’s property… and 5 polyhedra that might lack it:&lt;/p&gt;
    &lt;p&gt;The triakis tetrahedron is an extremely close call, but it does have Rupert’s property:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45057561</guid></item><item><title>Python: The Documentary [video]</title><link>https://www.youtube.com/watch?v=GfH4QL4VqJ0</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45058171</guid></item><item><title>Claude Sonnet will ship in Xcode</title><link>https://developer.apple.com/documentation/xcode-release-notes/xcode-26-release-notes</link><description>&lt;doc fingerprint="33a9437a9587dba1"&gt;
  &lt;main&gt;
    &lt;p&gt;This page requires JavaScript. Please turn on JavaScript in your browser and refresh the page to view its content.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45058688</guid></item><item><title>Lucky 13: a look at Debian trixie</title><link>https://lwn.net/Articles/1033474/</link><description>&lt;doc fingerprint="9defda1d9907a61e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Lucky 13: a look at Debian trixie&lt;/head&gt;
    &lt;quote&gt;We're bad at marketing&lt;p&gt;We can admit it, marketing is not our strong suit. Our strength is writing the kind of articles that developers, administrators, and free-software supporters depend on to know what is going on in the Linux world. Please subscribe today to help us keep doing that, and so we don’t have to get good at marketing.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;After more than two years of development, the Debian Project has released its new stable version, Debian 13 ("trixie"). The release comes with the usual bounty of upgraded packages and more than 14,000 new packages; it also debuts Advanced Package Tool (APT) 3.0 as the default package manager and makes 64-bit RISC-V a supported architecture. There are few surprises with trixie, which is exactly what many Linux users are hoping for—a free operating system that just works as expected.&lt;/p&gt;
    &lt;p&gt;Debian's stable releases are aptly named; the project prioritizes stability over shipping the latest software. The freeze schedule for trixie called for a soft freeze in April, which meant that (for example) the KDE Plasma 6.4 release in June was too late to make the cut—even though trixie was not released until August. Users who prefer to live on the edge will want to run another distribution or follow Debian development by running the testing release that previews the next stable version—Debian 14 ("forky"). Truly adventurous users may take their chances with the unstable ("sid") release.&lt;/p&gt;
    &lt;p&gt;That said, trixie is up-to-date enough for many folks; it includes GNOME 48, KDE Plasma 6.3, Xfce 4.20, GNU Emacs 30.1, GnuPG 2.4.7, LibreOffice 25.2, and more. Under the hood, it includes the most recent Linux LTS kernel (6.12.41), GNU Compiler Collection (GCC) 14.2, GNU C Library (glibc) 2.41, LLVM/Clang 19, Python 3.13, Rust 1.85, and systemd 257. The release notes have a section for well-known software that compares the version in Debian 12 against Debian 13. While some of the versions lag a bit behind the upstream, they are not woefully outdated.&lt;/p&gt;
    &lt;p&gt;The project now supports six major hardware architectures: x86-64/amd64, 32-bit Arm with a hardware FPU (armhf), 64-bit Arm (arm64), IBM POWER8 or newer (ppc64el), IBM S/390 (s390x), and 64-bit RISC-V. The i386 architecture is not supported for trixie, though the project continues to build some i386 packages to run on 64-bit systems; users with i386 systems cannot upgrade to trixie. The MIPS architectures (mipsel and mis64el) have also been removed in trixie.&lt;/p&gt;
    &lt;p&gt;The Arm EABI (armel) port that targets older 32-bit Arm devices prior to Arm v7 is still supported with trixie, but this release is the end of the line. There is no installation media for armel systems, but users who have bookworm installed can upgrade to trixie if they have supported hardware: the Raspberry Pi 1, Zero, and Zero W are the only devices mentioned in the release notes.&lt;/p&gt;
    &lt;p&gt;Upgrades from bookworm are supported, of course. The release notes suggest that users convert APT source files to the DEB822 format before the upgrade. APT 3.0 includes an "apt modernize-sources" command to convert APT data source files to DEB822, but that is not available in bookworm. Users are also expected to remove all third-party packages prior to running the upgrade. I tested the upgrade on one of my servers, after taking a snapshot to roll back to if needed, and all went smoothly. Users who are considering an upgrade should read the release notes carefully before forging ahead; in particular, users should be aware that it's possible (but not certain) for network interface names to change on upgrade.&lt;/p&gt;
    &lt;head rend="h4"&gt;Installation&lt;/head&gt;
    &lt;p&gt;For users who want to start fresh, Debian offers a variety of installer images and download methods; users can choose a 64MB minimal ISO image with the netboot installer, all the way up to a set of Blu-ray images. The project recommends using BitTorrent or Jigsaw Download (jigdo) for the largest images. BitTorrent probably needs no introduction, but jigdo is not as well-known. Jigdo is a method of downloading all of the individual packages for an image from multiple mirrors and then assembling them into an ISO image on the user's machine. It was a bit fiddly to use jigdo to download an image, but not overly so—and the speed of the whole process was comparable to simply downloading an ISO of the same size.&lt;/p&gt;
    &lt;p&gt;Debian's network install ("netinst") image is probably the best option for server installations and for experienced Linux users; it includes the packages required for a base install and then fetches the remaining software from Debian mirrors. Unlike the tiny netboot image, it includes the option of using either the graphical installer or the text-based installer.&lt;/p&gt;
    &lt;p&gt;The installer is a bit of a throwback to an earlier era when users were expected to know a lot more about the workings of a Linux system. Users who have only worked with distributions like Fedora and Ubuntu will notice that installing Debian requires many more steps than other popular distributions. For example, many desktop distributions have eliminated the step of setting a password for the root user—instead, it is generally assumed that the primary user will also be the system administrator, so the default is to give the primary user sudo privileges instead. Debian does not take that approach; &lt;del&gt;in fact, there is no way to give a user sudo privileges during installation. Setting up sudo has to be done manually after the installation is completed&lt;/del&gt; Update: Users can skip creation of a root account and the installer will then set up the regular user as an administrator with sudo permissions. Apologies for the error.&lt;/p&gt;
    &lt;p&gt;For some folks, installing Debian will be a bit of a chore and may even be confusing for users who are new to Linux. For example, the text-mode installer requires users to specify the device for GRUB boot loader installation, without providing a default. If one chooses an invalid partition, the installer tells the user that the operation has failed and drops back to a menu listing all the installation steps. Presumably if one picks the wrong partition it will happily install GRUB to that and render the system unbootable. This is not insurmountable for experienced Linux users, but it would no doubt be a hurdle for many users.&lt;/p&gt;
    &lt;p&gt;More experienced Linux users are likely to appreciate the amount of control offered by the installer. For example, Fedora's recent web-based installer makes it difficult to even find the option to perform custom partitioning. Debian has a guided partitioning option for those who do not want to fuss with it, but the option to create custom partitions is not hidden from the user.&lt;/p&gt;
    &lt;p&gt;Debian has a better installation option for newer Linux users, though it is easy to miss: the live install images, which use the Calamares installer. Its workflow is more akin to the installation process one finds with Fedora and Ubuntu; it also sets up the primary user with sudo privileges rather than creating a root password. Unfortunately, the live images are not listed on the main page for installer images—though they are mentioned, briefly, in the release notes.&lt;/p&gt;
    &lt;p&gt;The Debian installer also has the option of using a Braille display and/or speech synthesizer voice for the installation. I have not tried these options, but they are available for users who need them.&lt;/p&gt;
    &lt;head rend="h4"&gt;X.org&lt;/head&gt;
    &lt;p&gt;Many distributions are in the process of phasing out X.org support for GNOME and KDE as the upstream projects have started doing so. For example, Fedora will remove X.org session support for GNOME in Fedora 43, and the plan is for Ubuntu to do the same in its upcoming 25.10 release. GNOME will be completely removing X.org support in GNOME 49, which is planned for September.&lt;/p&gt;
    &lt;p&gt;Much has already been said about this, of course, and there is likely little new left to be said or that needs to be said. However, for users who still need or want X.org support, Debian 13 includes X.org sessions for GNOME and KDE. In testing trixie, I've spent some time in the GNOME and KDE X.org sessions as well as the Wayland sessions; if there are any gotchas or horrible bugs, I haven't encountered them (yet). This might be a compelling reason for some folks to switch to (or stick with) Debian.&lt;/p&gt;
    &lt;head rend="h4"&gt;Trying trixie&lt;/head&gt;
    &lt;p&gt;I use Debian for my personal web site and blogs, but it has been quite some time since I used it as my primary desktop operating system. Debian (and Ubuntu) derivatives, such as Linux Mint and Pop!_OS, yes—but it's been several years since I've used vanilla Debian on the desktop for more than casual tinkering.&lt;/p&gt;
    &lt;p&gt;The Debian release announcement boasts about the number of packages included in trixie: 64,419 packages total, with 14,100 added and more than 6,000 removed as obsolete since bookworm. That is quite a few packages, but falls short of some other distributions. For example, "dnf repoquery --repo=fedora --available" shows more than 76,000 packages available for Fedora 42.&lt;/p&gt;
    &lt;p&gt;After installing Debian, I went to install some of my preferred software, such as aerc, Ghostty, niri, and Speech Note. The aerc packages in trixie are current, but Ghostty and niri are not packaged for Debian at all. Ghostty is written in Zig, which is also not available, so users who want to build it from source will need to install Zig separately and then build Ghostty. Speech Note is packaged as a Flatpak, but Debian does not enable Flatpaks or Flathub in the GNOME Software Store by default. Users who want Flatpaks on Debian via Flathub will need to install the flatpak package and manually add the Flathub repo:&lt;/p&gt;
    &lt;quote&gt;flatpak remote-add --if-not-exists flathub \ https://dl.flathub.org/repo/flathub.flatpakrepo&lt;/quote&gt;
    &lt;p&gt;Users will need to add the gnome-software-plugin-flatpak package for Flatpak support in GNOME Software, and plasma-discover-backend-flatpak to add it to KDE Discover.&lt;/p&gt;
    &lt;p&gt;Trixie ships with the Firefox extended-support release (ESR) by default: Firefox 128, which was released in July 2024. Happily, Mozilla offers a Debian repository for those who want to run more current versions. Even better, there is a little-advertised utility called extrepo that has a curated list of external repositories users might want to enable for Debian. To enable the Mozilla repository, for example, a user only needs to install extrepo, run "extrepo enable mozilla" as root (or with sudo), update the package cache, and look for the regular Firefox package. In all, extrepo includes more than 160 external repositories for applications like Docker CE, Signal, and Syncthing. Unfortunately, the extrepo utility does not have a separate "list" command to show the available repositories, though running "extrepo search" with no search parameter will return all of its DEB822-formatted repository entries. Some of the software is in an external repository due to a non-free license, other software (like Firefox) just has a development cycle that outpaces Debian's.&lt;/p&gt;
    &lt;p&gt;As one might expect, the Debian desktop experience is not dramatically different from other distributions; GNOME 48 on Debian is little different than GNOME 48 on Fedora, and the same is true for KDE, Xfce, etc. The primary difference is that users can expect more or less the same desktop experience running Debian stable in two years that they have today, which is not necessarily true for other distributions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Miscellaneous&lt;/head&gt;
    &lt;p&gt;One of the features in Debian 13 is something that most users won't notice or appreciate at all: a transition to 64-bit time_t on 32-bit architectures, to avoid the Year 2038 problem. The short version is that 32-bit integers cannot hold a Unix epoch timestamp for dates after January 19, 2038. That may seem like a distant concern, even irrelevant for Debian trixie; after all, Debian 13 is only supported by the project until 2030. However, the project expects that some 32-bit embedded systems will still be running trixie in 2038, so Debian developers did the heavy lifting to complete the transition to 64-bit time_t now. LWN covered the early planning for this in 2023.&lt;/p&gt;
    &lt;p&gt;By now, most users have retired their DSA SSH keys; if not, now is the time to do so. DSA keys were disabled by default with OpenSSH in 2015, and they are entirely disabled now with the openssh-client and openssh-server packages in trixie. If there is a device that can, for some reason, only be connected to with DSA, users can install the openssh-client-ssh1 package and use ssh1 to make the connection.&lt;/p&gt;
    &lt;p&gt;As we covered in June 2024, Debian 13 has switched to using a tmpfs filesystem for the /tmp directory. By default, Debian allocates up to 50% of memory to /tmp, but this can be changed by following the instructions in the release notes. Note that this also applies to systems that are upgraded to trixie from bookworm.&lt;/p&gt;
    &lt;head rend="h4"&gt;Forward to forky&lt;/head&gt;
    &lt;p&gt;Debian Project Leader (DPL) Andreas Tille recently announced "&lt;quote&gt;Debian's 100000th birthday&lt;/quote&gt;", so clearly the project has a bit of experience with putting out solid releases. Granted, he was reporting the number in binary, but even when converted to decimal numbers (32 years), it's an impressive track record.&lt;/p&gt;
    &lt;p&gt;While testing, I installed trixie on a couple of systems, including a new Framework 12-inch laptop. My original intent was to just see whether Debian had any problems with the new hardware (it didn't), but now I'm leaning toward sticking with Debian on this system for a while to see if stability suits me.&lt;/p&gt;
    &lt;p&gt;With trixie out the door, the Debian Project has already turned its attention to working on forky, which has no release date set. Debian has stuck to a loose schedule of a new stable release roughly every two years. Most likely we will see Debian 14 sometime in 2027. After the forky release, trixie will still receive updates from Debian's security team through 2028, and then from its LTS team through 2030.&lt;/p&gt;
    &lt;p&gt;As of yet, there are no major new features or changes announced for forky; it seems likely that those will be coming to light in the coming months now that the project has trixie out the door. LWN will, of course, be reporting on those developments as they happen.&lt;/p&gt;
    &lt;p&gt; Posted Aug 20, 2025 13:54 UTC (Wed) by bluca (subscriber, #118303) [Link] (12 responses) It's been a while, but IIRC if you skip setting a root password in the installer, then the created user will be added automatically to the sudo group Posted Aug 20, 2025 14:07 UTC (Wed) by rschroev (subscriber, #4164) [Link] (4 responses) &amp;gt; Alternatively, you can lock the root account's password by leaving this setting empty, and instead use the system's initial user account (which will be set up in the next step) to gain administrative privileges. This will be enabled for you by adding that initial user to the 'sudo' group. Admittedly it's quite a wall of text. If you do leave the root password empty (and only then) is sudo installed automatically, with a config file that grants sudo access to users in the sudo group, in addition to putting the initial user in that sudo group. Posted Aug 20, 2025 14:11 UTC (Wed) by jzb (editor, #7867) [Link] (2 responses) Posted Aug 20, 2025 14:17 UTC (Wed) by rschroev (subscriber, #4164) [Link] (1 responses) Posted Aug 21, 2025 11:40 UTC (Thu) by Karellen (subscriber, #67644) [Link] Posted Aug 20, 2025 14:14 UTC (Wed) by jzb (editor, #7867) [Link] Posted Aug 20, 2025 14:09 UTC (Wed) by jzb (editor, #7867) [Link] (4 responses) Posted Aug 20, 2025 17:48 UTC (Wed) by josh (subscriber, #17465) [Link] (3 responses) Posted Aug 21, 2025 10:55 UTC (Thu) by alx.manpages (subscriber, #145117) [Link] (2 responses) I want a root password for login as root, Which means that with the current installer I currently am forced to set up sudo(8) after installation. Posted Aug 21, 2025 12:43 UTC (Thu) by rschroev (subscriber, #4164) [Link] (1 responses) Posted Aug 21, 2025 19:07 UTC (Thu) by alx.manpages (subscriber, #145117) [Link] Yup, that's an alternative I always thought should be possible. I never tried it, though. Since I know my approach works, it always felt risky to try it in the other way. :) Also, I have a sudoers file that I just cp(1) into /etc/sudoers.d and it works, which is easy. (Although it is painful to install and configure sudo(8) until I actually have sudo(8).) Posted Aug 20, 2025 14:11 UTC (Wed) by smcv (subscriber, #53363) [Link] (1 responses) &amp;gt; To allow direct password-based access via the 'root' account, Posted Aug 29, 2025 9:26 UTC (Fri) by emorrp1 (guest, #99512) [Link] Posted Aug 20, 2025 16:06 UTC (Wed) by cjwatson (subscriber, #7322) [Link] Posted Aug 20, 2025 17:48 UTC (Wed) by josh (subscriber, #17465) [Link] I see what you did there. Posted Aug 21, 2025 4:17 UTC (Thu) by alison (subscriber, #63752) [Link] (4 responses) Posted Aug 21, 2025 13:59 UTC (Thu) by jzb (editor, #7867) [Link] (1 responses) If you're getting Firefox ESR from the Debian repositories, then it is updated by the Debian packagers with a number of patches applied. You can examine the patches applied to various versions here: https://sources.debian.org/patches/firefox-esr/. The new ML features postdate Firefox 128, I believe, so it's unclear right now if they'll turn those off or not. I wouldn't be surprised if they do... If you want current-ish Firefox without some of the AI-type stuff, you might check out LibreWolf or other forks. Posted Aug 22, 2025 4:52 UTC (Fri) by alison (subscriber, #63752) [Link] Posted Aug 22, 2025 3:04 UTC (Fri) by pabs (subscriber, #43278) [Link] Posted Aug 29, 2025 9:21 UTC (Fri) by emorrp1 (guest, #99512) [Link] https://tracker.debian.org/pkg/firefox-esr/news/?page=3 (for the exact dates we got 128.3) If you install from outside of debian (e.g. extrepo) then yes obviously it's cycle will be outside of distro control. Posted Aug 21, 2025 11:25 UTC (Thu) by alx.manpages (subscriber, #145117) [Link] (2 responses) This is not recommended. testing is the least secure flavour of Debian, as bug fixes are applied to stable (if appropriate), and also arrive at unstable (Sid) as normal patches, but due to migration policies, they can take months to arrive at testing. See &amp;lt;https://www.debian.org/doc/manuals/debian-faq/choosing.en...&amp;gt;. Posted Aug 22, 2025 3:14 UTC (Fri) by pabs (subscriber, #43278) [Link] (1 responses) https://wiki.debian.org/DebianTesting#Best_practices_for_... I have been using this setup for years, it works great. Posted Aug 22, 2025 7:19 UTC (Fri) by alx.manpages (subscriber, #145117) [Link] Recommending testing over unstable, saying that testing is for the bleeding edge and unstable is for the adventurous, that's at least a dangerous recommendation. Such a recommendation would need to come with a disclosure that unstable is safer (even if it might crash more often) and explains how to deal with the security issues in testing. Posted Aug 21, 2025 14:22 UTC (Thu) by tcabot (subscriber, #6656) [Link] &lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;lb/&gt; and I also want sudo(8) for my primary account.&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;lb/&gt; &amp;gt; you can set the password for that account here.&lt;lb/&gt; &amp;gt; .&lt;lb/&gt; &amp;gt; Alternatively, you can lock the root account's password&lt;lb/&gt; &amp;gt; by leaving this setting empty, and&lt;lb/&gt; &amp;gt; instead use the system's initial user account&lt;lb/&gt; &amp;gt; (which will be set up in the next step)&lt;lb/&gt; &amp;gt; to gain administrative privileges.&lt;lb/&gt; &amp;gt; This will be enabled for you&lt;lb/&gt; &amp;gt; by adding that initial user to the 'sudo' group.&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;64-bit time_t&lt;/head&gt;&lt;head&gt;aptly named&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;testing is for actually testing. unstable is for users who want the bleeding edge&lt;/head&gt;&lt;head&gt;testing is for actually testing. unstable is for users who want the bleeding edge&lt;/head&gt;&lt;head&gt;testing is for actually testing. unstable is for users who want the bleeding edge&lt;/head&gt;&lt;head&gt;TIL about extrepo&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45059160</guid></item><item><title>PSA: Libxslt is unmaintained and has 5 unpatched security bugs</title><link>https://vuxml.freebsd.org/freebsd/b0a3466f-5efc-11f0-ae84-99047d0a6bcc.html</link><description>&lt;doc fingerprint="1599f515f4b7b7f2"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;On 6/16/25 15:12, Alan Coopersmith wrote:&lt;/p&gt;
      &lt;p&gt; BTW, users of libxml2 may also be using its sibling project, libxslt, which currently has no active maintainer, but has three unfixed security issues reported against it according to https://gitlab.gnome.org/Teams/Releng/security/-/wikis/2025#libxml2-and-libxslt &lt;/p&gt;
      &lt;p&gt;2 of the 3 have now been disclosed:&lt;/p&gt;
      &lt;p&gt;(CVE-2025-7424) libxslt: Type confusion in xmlNode.psvi between stylesheet and source nodes&lt;lb/&gt; https://gitlab.gnome.org/GNOME/libxslt/-/issues/139 https://project-zero.issues.chromium.org/issues/409761909&lt;/p&gt;
      &lt;p&gt;(CVE-2025-7425) libxslt: heap-use-after-free in xmlFreeID caused by `atype` corruption&lt;lb/&gt; https://gitlab.gnome.org/GNOME/libxslt/-/issues/140&lt;lb/&gt;https://project-zero.issues.chromium.org/issues/410569369&lt;/p&gt;
      &lt;p&gt;Engineers from Apple &amp;amp; Google have proposed patches in the GNOME gitlab issues, but neither has had a fix applied to the git repo since there is currently no maintainer for libxslt.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45060004</guid></item><item><title>Strange CW Keys</title><link>https://sites.google.com/site/oh6dccw/strangecwkeys</link><description>&lt;doc fingerprint="7ff4f9d4ca9ca5f5"&gt;
  &lt;main&gt;
    &lt;p&gt;Made by OH6DC&lt;/p&gt;
    &lt;p&gt;You can also use the Text-only index page (divided into useful categories).&lt;/p&gt;
    &lt;p&gt;Lever arch file CW key&lt;/p&gt;
    &lt;p&gt;Lambic pedals&lt;/p&gt;
    &lt;p&gt;Valentine's day lollipop CW paddle&lt;/p&gt;
    &lt;p&gt;Rubber stamp CW key&lt;/p&gt;
    &lt;p&gt;Letter scale CW key&lt;/p&gt;
    &lt;p&gt;Clamp cootie&lt;/p&gt;
    &lt;p&gt;Code book&lt;/p&gt;
    &lt;p&gt;Pepper mill CW key&lt;/p&gt;
    &lt;p&gt;Lightsaber CW key&lt;/p&gt;
    &lt;p&gt;Nutcracker CW key&lt;/p&gt;
    &lt;p&gt;Straight(ener) key&lt;/p&gt;
    &lt;p&gt;Smoke alarm CW key&lt;/p&gt;
    &lt;p&gt;Teletubbygraph key&lt;/p&gt;
    &lt;p&gt;Soap dispenser CW key&lt;/p&gt;
    &lt;p&gt;Vinyl record player CW key&lt;/p&gt;
    &lt;p&gt;Moomin triangle CW key&lt;/p&gt;
    &lt;p&gt;Antiperspirant roll-on CW key&lt;/p&gt;
    &lt;p&gt;Dual banana CW paddle&lt;/p&gt;
    &lt;p&gt;Power twister CW key&lt;/p&gt;
    &lt;p&gt;Handsaw CW key&lt;/p&gt;
    &lt;p&gt;Hole punch CW key&lt;/p&gt;
    &lt;p&gt;Watering can CW key&lt;/p&gt;
    &lt;p&gt;Toilet brush CW key&lt;/p&gt;
    &lt;p&gt;CW glove&lt;/p&gt;
    &lt;p&gt;Remote control CW key&lt;/p&gt;
    &lt;p&gt;Tea bag CW key&lt;/p&gt;
    &lt;p&gt;Eyebrow-raising CW key with optical transmitter&lt;/p&gt;
    &lt;p&gt;Back scratcher CW key&lt;/p&gt;
    &lt;p&gt;Whisk CW key&lt;/p&gt;
    &lt;p&gt;Pliers CW key&lt;/p&gt;
    &lt;p&gt;Liver casserole CW key&lt;/p&gt;
    &lt;p&gt;Licorice pipe CW key&lt;/p&gt;
    &lt;p&gt;Chocolate CW key&lt;/p&gt;
    &lt;p&gt;Ski-W key&lt;/p&gt;
    &lt;p&gt;Power drill CW keyer&lt;/p&gt;
    &lt;p&gt;Six megapixel CW key&lt;/p&gt;
    &lt;p&gt;Suspenders CW key&lt;/p&gt;
    &lt;p&gt;Spirit bottle cap CW key&lt;/p&gt;
    &lt;p&gt;Speed skate CW key&lt;/p&gt;
    &lt;p&gt;Flower CW key&lt;/p&gt;
    &lt;p&gt;Knee pad sideswiper CW key for portable operation&lt;/p&gt;
    &lt;p&gt;QRP transmitter powered by a CW key&lt;/p&gt;
    &lt;p&gt;Alarm clock CW key&lt;/p&gt;
    &lt;p&gt;Hammer CW key&lt;/p&gt;
    &lt;p&gt;CW gun&lt;/p&gt;
    &lt;p&gt;Nail clipper CW key&lt;/p&gt;
    &lt;p&gt;Ballpoint pen CW key&lt;/p&gt;
    &lt;p&gt;Rotary dial CW key&lt;/p&gt;
    &lt;p&gt;Hammock CW key&lt;/p&gt;
    &lt;p&gt;Joystick CW key&lt;/p&gt;
    &lt;p&gt;Rowing boat CW key&lt;/p&gt;
    &lt;p&gt;Guitar CW key&lt;/p&gt;
    &lt;p&gt;Wallet CW key&lt;/p&gt;
    &lt;p&gt;Radio controlled CW key&lt;/p&gt;
    &lt;p&gt;Amaryllis telegraphiensis&lt;/p&gt;
    &lt;p&gt;Multi-function knife with CW key&lt;/p&gt;
    &lt;p&gt;Toilet paper roll CW key&lt;/p&gt;
    &lt;p&gt;Table ice hockey CW key&lt;/p&gt;
    &lt;p&gt;Big toe CW key&lt;/p&gt;
    &lt;p&gt;Waffle iron CW key&lt;/p&gt;
    &lt;p&gt;Lego straight key&lt;/p&gt;
    &lt;p&gt;Lego bug&lt;/p&gt;
    &lt;p&gt;Pogo stick CW key&lt;/p&gt;
    &lt;p&gt;Crutch CW key&lt;/p&gt;
    &lt;p&gt;Smoke signal CW key&lt;/p&gt;
    &lt;p&gt;CCW key&lt;/p&gt;
    &lt;p&gt;Necktie CW key&lt;/p&gt;
    &lt;p&gt;Toothbrush CW key&lt;/p&gt;
    &lt;p&gt;Bench press CW key&lt;/p&gt;
    &lt;p&gt;Handshake CW key&lt;/p&gt;
    &lt;p&gt;Chopsticks CW key&lt;/p&gt;
    &lt;p&gt;Trailer hitch CW key&lt;/p&gt;
    &lt;p&gt;Typewriter CW keyboard&lt;/p&gt;
    &lt;p&gt;Refrigerator CW key&lt;/p&gt;
    &lt;p&gt;Mobile phone CW key&lt;/p&gt;
    &lt;p&gt;Paper cup iambic paddles&lt;/p&gt;
    &lt;p&gt;Morsetrap CW key&lt;/p&gt;
    &lt;p&gt;Fingertips CW key&lt;/p&gt;
    &lt;p&gt;Vacuum cleaner semi-automatic CW key&lt;/p&gt;
    &lt;p&gt;Banana CW key&lt;/p&gt;
    &lt;p&gt;Rolling pin CW key&lt;/p&gt;
    &lt;p&gt;Toaster CW key&lt;/p&gt;
    &lt;p&gt;Cheese slicer CW key&lt;/p&gt;
    &lt;p&gt;Rocking chair CW key&lt;/p&gt;
    &lt;p&gt;QLF pedal for left foot CW&lt;/p&gt;
    &lt;p&gt;Cross-country ski shoe CW key&lt;/p&gt;
    &lt;p&gt;CW insoles&lt;/p&gt;
    &lt;p&gt;QRQ paddles&lt;/p&gt;
    &lt;p&gt;Onion chopper CW key&lt;/p&gt;
    &lt;p&gt;Beer can CW key&lt;/p&gt;
    &lt;p&gt;Egg slicer CW key&lt;/p&gt;
    &lt;p&gt;Stapler CW key&lt;/p&gt;
    &lt;p&gt;Bicycle pump CW key&lt;/p&gt;
    &lt;p&gt;Iron bar CW key&lt;/p&gt;
    &lt;p&gt;Homebrew semi-automatic bug&lt;/p&gt;
    &lt;p&gt;Hacksaw blade sideswiper CW key&lt;/p&gt;
    &lt;p&gt;Plywood CW key&lt;/p&gt;
    &lt;p&gt;Home | Homebrew QRP&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45060161</guid></item><item><title>The Synology End Game</title><link>https://lowendbox.com/blog/they-used-to-be-good-but-now-theyve-turned-to-evil-the-synology-end-game/</link><description>&lt;doc fingerprint="76308b4ebfbc685d"&gt;
  &lt;main&gt;
    &lt;p&gt;I’ve been a Synology fan for many years. I used to roll my own NAS servers for home, but eventually decided that quieter, more energy-friendly dedicated NAS solutions were a better path forward. I don’t use a lot of their on-board apps, just basic file storage.&lt;/p&gt;
    &lt;p&gt;Right now I’ve got a DS920, a DS418, and a DS1522…but I probably won’t be buying another Synology again.&lt;/p&gt;
    &lt;p&gt;Why?&lt;/p&gt;
    &lt;p&gt;Their abusive, customer-hostile policies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Samba Limits&lt;/head&gt;
    &lt;p&gt;I started getting queasy when I read earlier this year that on some models, they limit how many concurrent connections you can make. I though this was just something setup by default in smb.conf, but in fact Synology has a proprietary wrapper around the daemon that artificially limits it.&lt;/p&gt;
    &lt;p&gt;Whiskey. Tango. Foxtrot.&lt;/p&gt;
    &lt;head rend="h2"&gt;You Must Buy Your Hard Drives From Us&lt;/head&gt;
    &lt;p&gt;For a long time, Synology has only officially supported certain hard drives. I don’t have a problem with this, for three reasons. First, it was a pretty extensive list and included all the major players (WD, Seagate, etc.). Second, it’s unreasonable to expect Synology to certify every single hard drive from every maker on the planet. And finally, it was just a support limit. In other words, you could use whatever hard drives you wanted, but if there was a problem, they wouldn’t be able to support you if the drive wasn’t on their list.&lt;/p&gt;
    &lt;p&gt;I could live with that. What I can’t live with is the new policy, implemented this year, where you must buy your drives from Synology. This only affects new models from this year forward. Details still seem sketchy, but rumor is that it’s going to be along the lines of “we don’t recognize your WD Black hard drive, therefore we won’t use it.”&lt;/p&gt;
    &lt;p&gt;And by the way, Synology’s hard drives aren’t all that great. My WD Blacks come with a 5 year warranty. Synology’s only come with 3 years.&lt;/p&gt;
    &lt;p&gt;Golf. Foxtrot. Yankee.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where to Now?&lt;/head&gt;
    &lt;p&gt;I could go back to building my own, with TrueNAS. In the past, my home-build NAS boxes were hand-me-down gaming PCs (because they were big enough towers) but I have to imagine one can find a case that allows tons of drives and is still powered by something modest.&lt;/p&gt;
    &lt;p&gt;Or I may look at UGREEN. Or Buffalo. Or someone else.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45060920</guid></item><item><title>Probability of typing a wrong Bitcoin address</title><link>https://www.johndcook.com/blog/2025/08/28/wrong-address/</link><description>&lt;doc fingerprint="6bf701d5a06fb3fd"&gt;
  &lt;main&gt;
    &lt;p&gt;I heard someone say that Bitcoin is dangerous because you could easily make a typo when entering an address, sending money to the wrong person, and have no recourse. There are dangers associated with Bitcoin, such as losing a private key, but address typos are not a major concern.&lt;/p&gt;
    &lt;head rend="h2"&gt;Checksums&lt;/head&gt;
    &lt;p&gt;There are several kinds of Bitcoin addresses. Each is at least 20 bytes (160 bits) long, with at least 4 bytes (32 bits) of checksum. The chances of a typo resulting in a valid checksum are about 1 in 232.&lt;/p&gt;
    &lt;head rend="h2"&gt;Used addresses&lt;/head&gt;
    &lt;p&gt;Let’s ignore the checksum for this section.&lt;/p&gt;
    &lt;p&gt;Because addresses are formed by cryptographic hash functions, we can assume the values are essentially randomly distributed in the space of possible addresses. The addresses are deterministic, but for modeling purposes, random is as random does.&lt;/p&gt;
    &lt;p&gt;This means a typo of an actual address is no more or less likely to be another actual address than an address typed at random. This is unlike, say, English words: a mistyped English word is more likely to be another English word than random keystrokes would be.&lt;/p&gt;
    &lt;p&gt;There have been on the order of a billion Bitcoin addresses used, in a space of 2160 possibilities. (Actually more since some addresses have more than 160 bits.) There’s about a 1 in 1039 chance that a random 160-bit sequence corresponds to an address somewhere on the Bitcoin blockchain.&lt;/p&gt;
    &lt;head rend="h2"&gt;Addresses close in edit distance&lt;/head&gt;
    &lt;p&gt;Someone with the Caesarean handle Veni Vidi Vici on X asked&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;What about the odds that out of those 1B addresses, two of them are one character swap away from each other?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That’s an interesting question. Let’s assume the addresses are Base58-encoded strings of length 26. Addresses could be longer, but assuming the minimum length increases the probability of addresses being close.&lt;/p&gt;
    &lt;p&gt;How many addresses are within one or two character swaps of another? I addressed a similar question here a couple weeks ago. If all the characters were unique, the number of strings within k swaps of each other would be&lt;/p&gt;
    &lt;p&gt;|S1(26, 26 − k)|&lt;/p&gt;
    &lt;p&gt;where S1 denotes Stirling numbers of the first kind. For k = 1 this would be 325 and for k = 2 this would be 50,050. This assumes all the characters are unique; I haven’t thought through the case where characters are repeated.&lt;/p&gt;
    &lt;p&gt;For round numbers, let’s say there are a billion addresses, and for each address there are a million other addresses that are close in some sense, plausible typos of the address. That would be 1012 addresses and typos, spread out in a space of ≈1045 (i.e. 5826) possible addresses.&lt;/p&gt;
    &lt;p&gt;Now there’s an implicit Birthday Problem here. No particular address is likely to collide with another, even when you allow typos, but what about the likelihood that some address collides?&lt;/p&gt;
    &lt;p&gt;Say we partition our space of 1045 addresses into N = 1029 addresses with a million possible typos for each address. Then as a rule of thumb, you’d need around √N random draws before you have a 50-50 chance of seeing a collision. Since 109 is a lot less than 1014.5, it’s unlikely that any two addresses collide, even when you consider each address along with a million associated typos.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45061980</guid></item><item><title>What the interns have wrought, 2025</title><link>https://blog.janestreet.com/wrought-2025/</link><description>&lt;doc fingerprint="af490999cf9923d4"&gt;
  &lt;main&gt;
    &lt;p&gt;Yet again, we’re at the end of our internship season, and so it’s time to summarize what the interns were up to!&lt;/p&gt;
    &lt;p&gt;This year, I was recommended a real bumper crop of exciting projects to include. It’s kind of crazy how many great intern projects are out there. To mention a few that I’m not going to have time to cover in detail:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Annie Hu spent a big chunk of her summer investigating, implementing, and optimizing different neural net sequence models, trying out a variety of compilation techniques and toolchains.&lt;/item&gt;
      &lt;item&gt;Aster Oransoy added build priorities to our build systems’ shared action execution service, so you can ensure low-priority builds don’t slow down high-priority ones.&lt;/item&gt;
      &lt;item&gt;Allen Pei wrote a quickcheck-like system for creating automated tests of trading systems by generating randomized sequences of market events, along with shrinking heuristics for creating minimal test cases.&lt;/item&gt;
      &lt;item&gt;Evan Thompson wrote an LSP for our inline CSS syntax extension which includes a CSS validator that found tons of instances of invalid CSS in our applications.&lt;/item&gt;
      &lt;item&gt;Zhibo Chen added a generic form of optional arguments to OCaml, so that it can use other types than the traditional OCaml option type (including more efficient representations) for optional values.&lt;/item&gt;
      &lt;item&gt;Conor Kennedy added predicate pushdown to our internal data warehouse system to do filtration before it gets to the full query engine, and even wrote a mini query planner for analyzing filter expressions to derive narrower key ranges.&lt;/item&gt;
      &lt;item&gt;Joe Cutler worked on using JIT-ing to make our HardCaml simulator fast enough to be competitive with Verilator, but with much better start-up times.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And those are just the ones I felt like I could explain in a handful of words each!&lt;/p&gt;
    &lt;p&gt;As usual, I picked just three projects to go into in more detail. In particular:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leo Gagnon wrote a (sometimes dramatically) more efficient evaluator for JSQL, our internal SQL dialect that we use for lots of different user-facing tools.&lt;/item&gt;
      &lt;item&gt;Aryan Khatri built a new version of our OCaml torch bindings that leverage OxCaml’s new features for controlling memory management to build bindings that clean up tensors safely and deterministically.&lt;/item&gt;
      &lt;item&gt;Anthony Li wrote a library for managing memory across processes within our trading systems via ref-counting, making it possible to more efficiently and safely ship data across the process boundary.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let’s dive in!&lt;/p&gt;
    &lt;head rend="h1"&gt;Faster (J)SQL evaluation&lt;/head&gt;
    &lt;p&gt;We use a lot of SQL at Jane Street, both in standard Postgres (or similar) databases floating around, and for accessing our own homegrown analytics-oriented data warehouse software.&lt;/p&gt;
    &lt;p&gt;Over time, we came to realize that SQL was sufficiently well-known internally that we wanted to use it beyond the context of databases, as a general language for filtering and transforming tabular data. This could be useful in all sorts of contexts: web UIs, data visualization tools, trading-systems configuration tools, etc.&lt;/p&gt;
    &lt;p&gt;The problem with this idea is… which version of SQL should you use? Every database you look at has its own charmingly unique SQL dialect that’s almost but not quite the same as all the others.&lt;/p&gt;
    &lt;p&gt;We decided to deal with this by (I know, I know) building our own dialect of SQL called JSQL. We’ve built a bunch of tools for using JSQL, including parsers, translators to other SQL dialects, web-UI components, and a collection of different in-memory evaluators for computing the results of a JSQL expression without invoking a traditional database at all.&lt;/p&gt;
    &lt;p&gt;Our evaluators started out very simple, doing little more than walking though a collection of rows and one-by-one evaluating whether they passed or failed a WHERE clause. Over time, we’ve built multiple evaluators with different performance properties, including incremental evaluators.&lt;/p&gt;
    &lt;p&gt;That said, none of our evaluators were all that sophisticated, and in particular, none of them made use of indexing. Leo Gagnon’s project was to change that!&lt;/p&gt;
    &lt;p&gt;The idea was that when presented with data that’s in an indexed container, like a &lt;code&gt;Map.t&lt;/code&gt;
or &lt;code&gt;Hashtbl.t&lt;/code&gt;, to be able to use that indexing to more efficiently filter down to the
data you need.  So, if you have a &lt;code&gt;SELECT&lt;/code&gt; statement where the &lt;code&gt;WHERE&lt;/code&gt; clause contains:&lt;/p&gt;
    &lt;code&gt;author = "Dijkstra" AND publication_year &amp;gt; 1980
&lt;/code&gt;
    &lt;p&gt;and the underlying data is contained in, say, a &lt;code&gt;Paper.t list String.Map.t&lt;/code&gt; (a map from author names to 
lists of their papers), Leo’s evaluator would have to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;determine that we only care about things under the key &lt;code&gt;"Dijkstra"&lt;/code&gt;,&lt;/item&gt;
      &lt;item&gt;use an O(log n) &lt;code&gt;Map.find&lt;/code&gt;to get the resulting&lt;code&gt;Paper.t list&lt;/code&gt;,&lt;/item&gt;
      &lt;item&gt;use &lt;code&gt;List.filter&lt;/code&gt;on the resulting much smaller list to select the papers with&lt;code&gt;publication_year &amp;gt; 1980&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Which is way more efficient than walking over the entire map.&lt;/p&gt;
    &lt;p&gt;Getting this done involved a bunch of steps!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Building a&lt;/p&gt;&lt;code&gt;selection&lt;/code&gt;type that represented the possible over-approximations of the range of keys that would be needed to satisfy a given query.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Writing code to extract and optimize the&lt;/p&gt;&lt;code&gt;selection&lt;/code&gt;for a given query.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Writing code to specialize the execution of the selection to the backing store for the data. For example, the&lt;/p&gt;&lt;code&gt;selection&lt;/code&gt;type tracks when ranges of queries are in scope. The&lt;code&gt;Map.t&lt;/code&gt;type supports efficient range queries, but the&lt;code&gt;Hashtbl.t&lt;/code&gt;type doesn’t, so you need different execution strategies depending on which you use to store your data.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Supporting multi-index data-structures, like our&lt;/p&gt;&lt;code&gt;Immutable_indexable_bag&lt;/code&gt;. This involved building selection heuristics that help us pick the most efficient index to use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And, of course, benchmarking.&lt;/p&gt;
    &lt;p&gt;The results of that benchmarking were pretty promising. We ran some sample queries over 3.8 million rows of test data, comparing a linear scan over an array versus an index-optimized scan over a &lt;code&gt;Map.t&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This first query shows a ~700x speedup, since it lets us zoom in on just the MSFT trades, ignoring everything else.&lt;/p&gt;
    &lt;code&gt;SELECT * WHERE und = "MSFT US" AND event_date &amp;gt; "2025-01-01"::date
+----------------------------------+--------------------+
| aggregator_name                  | average_time       |
+----------------------------------+--------------------+
| jsql-aggregations-eval           | 15.844514478s      |
| jsql-indexed-aggregations-eval   | 21.939788ms        |
+----------------------------------+--------------------+
&lt;/code&gt;
    &lt;p&gt;This second query is more complicated, in that it requires us to do a scan over a range of values, but we still get a ~30x speedup here.&lt;/p&gt;
    &lt;code&gt;SELECT * WHERE
  (und = "MSFT US" OR (und &amp;gt;= "AAPL US" AND und &amp;lt; "AMZN US"))
  AND event_date &amp;gt; "2025-01-01"::date
+--------------------------------+--------------------+
| aggregator_name                | average_time       |
+--------------------------------+--------------------+
| jsql-aggregations-eval         | 37.056874003s      |
| jsql-indexed-aggregations-eval | 1.324532585s       |
+--------------------------------+--------------------+
&lt;/code&gt;
    &lt;p&gt;Despite this being a pretty algorithmic and performance-oriented project, a lot of the challenges turned out to be about API design, and getting all of this work done with a codebase that was simple and readable, and presented a convenient API to users.&lt;/p&gt;
    &lt;head rend="h1"&gt;Better Torch bindings&lt;/head&gt;
    &lt;p&gt;We use PyTorch a lot as part of our machine learning efforts, and as you might expect, most of that work is done in Python. But sometimes, we want to drive PyTorch from OCaml, which we do using ocamltorch, originally written by Laurent Mazare some years back.&lt;/p&gt;
    &lt;p&gt;But OCaml is in some ways an awkward match for PyTorch, because OCaml manages memory using a tracing GC, in contrast to Python, which uses a refcounting GC.&lt;/p&gt;
    &lt;p&gt;A lot of ink has been spilled on the tradeoffs between refcounting and tracing, but one clear difference is around the determinism of collection. With a tracing GC, it’s hard to know when the memory you’ve allocated will be reclaimed. With refcounting, your object will be collected the moment you drop your last reference to it.&lt;/p&gt;
    &lt;p&gt;This determinism comes in handy when you’re using your collector for managing things other than main memory, like precious GPU memory. This is a plot of GPU memory usage over time doing one forward and backward pass on a batch, then some sampling, then 3 more batches, written naively with ocamltorch.&lt;/p&gt;
    &lt;p&gt;This behavior is pretty awful! We’re holding on to tensors we just don’t need anymore, which is basically intolerable.&lt;/p&gt;
    &lt;p&gt;You’d deal with this in ocamltorch by carefully calling &lt;code&gt;Gc.full_major ()&lt;/code&gt; after each
batch and each token sampled, to force the GC to recognize that the memory is unused and
reclaim it. That gives you the desired memory behavior:&lt;/p&gt;
    &lt;p&gt;but it’s a poor solution, since the calls to the GC are expensive, and there’s no discipline to help you make sure you put them in the right place.&lt;/p&gt;
    &lt;p&gt;Aryan’s project was to build a better API for ocamltorch that provided a safe and efficient discipline for managing tensor memory, leveraging some of the new features of OxCaml, a set of extensions to OCaml that have been developed at Jane Street.&lt;/p&gt;
    &lt;p&gt;The basic idea is to introduce a way of marking a scope of allocation for a tensor, using this &lt;code&gt;with_rc_scope&lt;/code&gt; function, where “rc” is short for “reference count”:&lt;/p&gt;
    &lt;code&gt;val with_rc_scope : (unit -&amp;gt; 'a) @ local -&amp;gt; 'a
&lt;/code&gt;
    &lt;p&gt;The idea is that the body of the closure passed to this function acts as a scope, and that any tensors allocated within it will have their refcounts decremented when the function ends.&lt;/p&gt;
    &lt;p&gt;To make this all work, we use OxCaml’s &lt;code&gt;local&lt;/code&gt;
mode to make sure that tensors can’t
escape their scope.  In particular, any function that allocates a tensor will allocate it
as a local value:&lt;/p&gt;
    &lt;code&gt;val ( + ) : t @ local -&amp;gt; t @ local -&amp;gt; t @ local
&lt;/code&gt;
    &lt;p&gt;This prevents the allocated value from being returned from the closure passed to &lt;code&gt;with_rc_scope&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Here’s a worked example of how you might use this in practice.&lt;/p&gt;
    &lt;code&gt;    let vs = Var_store.create ~name:"vs" () in
    let opt = Optimizer.sgd vs ~learning_rate:1e-3 in
    let model = Model.init vs in
    for index = 1 to 100 do
      Tensor.with_rc_scope (fun () -&amp;gt;
        Optimizer.zero_grad opt;
        let ys_ = Model.forward model xs in
        let loss = Tensor.(mean (square (ys - ys_))) in
        Tensor.backward loss;
        Optimizer.step opt)
    done;
&lt;/code&gt;
    &lt;p&gt;The full API is a bit more complicated than just that. The system has support for nested scopes, which is needed to support many of the idioms that are used in practice for both training and inference workflows on GPUs. As part of that, there is some special support for returning tensors from an inner scope to an outer scope in a controlled way that doesn’t violate the reference counting rules.&lt;/p&gt;
    &lt;p&gt;The project itself involved a lot of experimentation at the API level, to design an API that was easy to use and understand and that also captured the memory-use patterns we run into in practice. The project also had an interesting performance-engineering aspect to it: removing all of the now-unnecessary GC invocations made it easier to understand and identify further inefficiencies (like unnecessary synchronizations between the CPU and GPU) that were harder to see amongst the performance mess created by the &lt;code&gt;full_major&lt;/code&gt;
invocations.&lt;/p&gt;
    &lt;p&gt;We have more ideas about how to extend and improve these interfaces, but we already expect the new APIs to be quite useful in their current form. This is part of our open-source code, so once the new code is released, you’ll be able to find it here.&lt;/p&gt;
    &lt;head rend="h1"&gt;Ref-counted objects in shared memory&lt;/head&gt;
    &lt;p&gt;At Jane Street, we have lots of performance-sensitive trading systems that gather complex information over the course of their execution, and then periodically serialize pieces of that data over a shared-memory channel to another process.&lt;/p&gt;
    &lt;p&gt;This is generally a pretty good approach, but it has its limitations. Serialization always has a cost, but here it’s made worse by the fact that the data we want to send is complex nested data with shared structure between messages. As a result, serializing the data can involve serializing the same sub-structures over and over.&lt;/p&gt;
    &lt;p&gt;Anthony Li’s project was to build a library supporting a very different – and much more efficient – approach.&lt;/p&gt;
    &lt;p&gt;The idea is to get rid of the serialization and deserialization altogether, and to just pass pointers to the values in question instead. This requires that the space of objects in question is visible to both processes, so it means we need to allocate those objects within a shared memory segment.&lt;/p&gt;
    &lt;p&gt;We already have support for managing pools of objects in a shared memory segment, so this sounds easy enough at first glance. But the tricky bit is figuring out when you can recycle one of your pooled objects.&lt;/p&gt;
    &lt;p&gt;We can’t rely on OCaml’s ordinary GC for this because the data resides in a shared-memory segment between two processes, each with their own GC. And anyway, we don’t want to be churning the garbage collector in a latency-sensitive trading system.&lt;/p&gt;
    &lt;p&gt;Instead, Anthony’s project was to use a tried-and-true technique for this: reference counting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Safer refcounting through modes&lt;/head&gt;
    &lt;p&gt;Reference counting is tricky to integrate into a language like OCaml that doesn’t have it designed in from the start. There are really three invariants you need to get right for this system to work:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There are no data-races on the refcounts or the objects themselves&lt;/item&gt;
      &lt;item&gt;Refcounts are incremented every time a new reference is created&lt;/item&gt;
      &lt;item&gt;Refcounts are decremented every time a reference is destroyed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But how do we ensure that these rules are followed when they’re not natively enforced by the runtime? This is a bit like the problem Aryan ran into with reference counting in PyTorch, and again, the solution is to leverage the system of modes to ensure the necessary invariants.&lt;/p&gt;
    &lt;p&gt;We’ll need different modes at different times, so in order to manage this, we’re going to have a special handle object &lt;code&gt;o Handle.t&lt;/code&gt; that guards access to the underlying object (of
type &lt;code&gt;o&lt;/code&gt;).  We can both use modes to protect the use of the handle itself, and the handle
can release the object &lt;code&gt;o&lt;/code&gt; with specific modal types under specific circumstances.&lt;/p&gt;
    &lt;p&gt;That’s all a bit abstract, so let’s talk about the details:&lt;/p&gt;
    &lt;head rend="h3"&gt;Eliminating data races&lt;/head&gt;
    &lt;p&gt;There are really two data-race questions to handle here: one is about the refcounts, and the other is about the actual objects being managed. For the refcounts, an atomic compare-and-set operation can be used to manage them in a safe way, so that’s pretty simple, and doesn’t require anything from the mode system.&lt;/p&gt;
    &lt;p&gt;The mutability of the objects is more complicated, because the rules are different at different times. The objects must be mutable on initialization, since they have to be filled in at that point. But once you have multiple readers of the object, you really need them to not change. It turns out we can leverage OxCaml’s visibility mode axis, which include &lt;code&gt;immutable&lt;/code&gt;, &lt;code&gt;read&lt;/code&gt;, and &lt;code&gt;read_write&lt;/code&gt; modes.&lt;/p&gt;
    &lt;p&gt;Specifically:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;During initialization, we expose the value under the&lt;/p&gt;&lt;code&gt;read_write&lt;/code&gt;mode (which is the default), so the data in the object can be set. Notably, at this point, we’re guaranteed there’s only one reference to the object in question.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;When reading, we expose objects under the&lt;/p&gt;&lt;code&gt;read&lt;/code&gt;mode. This way, multiple readers (even across processes) can access the same object without fear of a race.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Notably, once an object’s reference count goes back to zero, it can again be the subject of an initialization, so it can again be exposed &lt;code&gt;read_write&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Another interesting aspect of this is that when we release the underlying values, we do so under the &lt;code&gt;local&lt;/code&gt; mode, to prevent the value from escaping its intended scope. As such,
what we’re implementing is analogous to borrow-checking in Rust.&lt;/p&gt;
    &lt;head rend="h3"&gt;Managing increments and decrements&lt;/head&gt;
    &lt;p&gt;The key invariant here is that people don’t just go about duplicating handles without incrementing the associated reference count. To ensure this, each &lt;code&gt;Handle.t&lt;/code&gt; is created
under the &lt;code&gt;unique&lt;/code&gt; mode, and all operations that use handles require that they be provided
uniquely.&lt;/p&gt;
    &lt;p&gt;This guarantees that all handles that are used are held uniquely, and so if you want to refer to the handle in multiple places, an explicit copy function must be called. And, critically, that copy function increments the reference count.&lt;/p&gt;
    &lt;p&gt;There’s also a &lt;code&gt;free&lt;/code&gt; operation that consumes a handle and decrements the reference count.
And a way of sending a handle to another process, at which point the sending handle is
consumed, and a receiving handle is created, without changing the reference count.&lt;/p&gt;
    &lt;p&gt;Anthony’s library is complete, and the team is now working it into our production systems. We hope that this will be a library that’s useful to multiple teams across the firm.&lt;/p&gt;
    &lt;head rend="h1"&gt;Join us!&lt;/head&gt;
    &lt;p&gt;If this sounds like a fun way to spend your summer, you should apply to our internship program. Jane Street interns get a chance to solve fun and challenging problems that have real impact. I hope this post gives you a sense of that!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062274</guid></item><item><title>Tesla said it didn't have key data in a fatal crash. Then a hacker found it</title><link>https://www.washingtonpost.com/technology/2025/08/29/tesla-autopilot-crashes-evidence-testimony-wrongful-death/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062614</guid></item><item><title>Anthropic reverses privacy stance, will train on Claude chats</title><link>https://www.perplexity.ai/page/anthropic-reverses-privacy-sta-xH4KWU9nS3KH4Aj9F12dvQ</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062683</guid></item><item><title>If you have a Claude account, they're going to train on your data moving forward</title><link>https://old.reddit.com/r/LocalLLaMA/comments/1n2ubjx/if_you_have_a_claude_personal_account_they_are/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062738</guid></item><item><title>Deepnote (YC S19) is hiring engineers to build a better Jupyter notebook</title><link>https://deepnote.com/join-us</link><description>&lt;doc fingerprint="b9d2255309e5a6a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;We build tools for explorers&lt;/head&gt;
    &lt;p&gt;We are here to revolutionize how data teams work together.&lt;/p&gt;
    &lt;p&gt;We started Deepnote to help data teams solve the hardest problems. We don’t just need better algorithms, bigger data sets, and more computing power. We need tools that help us explore, collaborate, and share. These tools don’t exist yet. We need to invent them first.&lt;/p&gt;
    &lt;p&gt;Data work is as much a scientific and creative process as it is an engineering one. It involves working together, failing, learning, and going back to the drawing board. Data professionals are explorers. To make projects successful, we need tools that are both powerful and easy to use. Tools that help us collaborate and share our work in an engaging way. Tools that make working with data fun again.&lt;/p&gt;
    &lt;p&gt;That’s why we’re building the new standard in data tooling: a notebook that brings teams together to code, query, visualize, organize, and share — all in one place.&lt;/p&gt;
    &lt;p&gt;We are building tools for explorers. Join us.&lt;/p&gt;
    &lt;p&gt;Read more about us on TechCrunch&lt;/p&gt;
    &lt;p&gt;Read more about us on Nature&lt;/p&gt;
    &lt;head rend="h2"&gt;Build the future with us&lt;/head&gt;
    &lt;p&gt;We’re building a collaborative notebook that beautifully integrates analytics and data science into every workflow and decision. But it’s not just about designing, shipping, and selling. It’s about the people who power it — and that means you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get ready to do your best work&lt;/head&gt;
    &lt;p&gt;Transforming how people work with data isn't easy. But we built a culture that allows us to do precisely that.&lt;/p&gt;
    &lt;head rend="h3"&gt;We move with urgency&lt;/head&gt;
    &lt;p&gt;We are a small, passionate team revolutionizing how data teams work. We give everyone the tools they need and enable them to take action.&lt;/p&gt;
    &lt;head rend="h3"&gt;We keep learning&lt;/head&gt;
    &lt;p&gt;We are knowledge-seekers. We invest in continuous learning across every role and encourage a culture of proactive feedback.&lt;/p&gt;
    &lt;head rend="h3"&gt;We take ownership&lt;/head&gt;
    &lt;p&gt;We are makers. We expect everyone to be a decision-maker — no politics or walls to get in the way.&lt;/p&gt;
    &lt;head rend="h3"&gt;We collaborate&lt;/head&gt;
    &lt;p&gt;We are partners. We work in a fully transparent environment and put open, effective communication above all else.&lt;/p&gt;
    &lt;head rend="h2"&gt;Backed by the best in the business&lt;/head&gt;
    &lt;p&gt;We’re backed by industry leaders — and they’re as excited about reimagining the future as we are.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Y Combinator&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Index Ventures&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Accel&lt;/head&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Greg Brockman&lt;p&gt;CTO at OpenAI&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Elad Gil&lt;p&gt;Angel Investor&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Naval Ravikant&lt;p&gt;Angel Investor&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Elena Verna&lt;p&gt;Angel Investor&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Explore open positions&lt;/head&gt;
    &lt;p&gt;Thousands of data professionals already use Deepnote — but we’re only scratching the surface of what’s possible. We’re building out our core team, and we want kind, curious explorers to join and grow with us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062914</guid></item></channel></rss>