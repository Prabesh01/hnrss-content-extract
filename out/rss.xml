<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 26 Jan 2026 08:54:15 +0000</lastBuildDate><item><title>Using PostgreSQL as a Dead Letter Queue for Event-Driven Systems</title><link>https://www.diljitpr.net/blog-post-postgresql-dlq</link><description>&lt;doc fingerprint="3f4c263785a28d80"&gt;
  &lt;main&gt;
    &lt;p&gt;While I was working on a project with Wayfair, I got the opportunity to work on a system that generated daily business reports aggregated from multiple data sources flowing through event streams across Wayfair. At a high level, Kafka consumers listened to these events, hydrated them with additional data by calling downstream services, and finally persisted the enriched events into a durable datastoreâCloudSQL PostgreSQL on GCP.&lt;/p&gt;
    &lt;p&gt;When everything was healthy, the pipeline worked exactly as expected. Events flowed in, got enriched, and were stored reliably. The real challenge started when things went wrong, which, in distributed systems, is not an exception but a certainty.&lt;/p&gt;
    &lt;p&gt;There were multiple failure scenarios we had to deal with. Sometimes the APIs we depended on for hydration were down or slow. Sometimes the consumer itself crashed midway through processing. In other cases, events arrived with missing or malformed fields that could not be processed safely. These were all situations outside our direct control, but they still needed to be handled gracefully.&lt;/p&gt;
    &lt;p&gt;This is where the concept of a Dead Letter Queue came into the picture. Whenever we knew an event could not be processed successfully, instead of dropping it or blocking the entire consumer, we redirected it to a DLQ so it could be inspected and potentially reprocessed later.&lt;/p&gt;
    &lt;p&gt;Our first instinct was to use Kafka itself as a DLQ. While this is a common pattern, it quickly became clear that it wasn't a great fit for our needs. Kafka is excellent for moving data, but once messages land in a DLQ topic, they are not particularly easy to inspect. Querying by failure reason, retrying a specific subset of events, or even answering simple questions like "what failed yesterday and why?" required extra tooling and custom consumers. For a system that powered business-critical daily reports, this lack of visibility was a serious drawback.&lt;/p&gt;
    &lt;p&gt;That's when we decided to treat PostgreSQL itself as the Dead Letter Queue.&lt;/p&gt;
    &lt;p&gt;Instead of publishing failed events to another Kafka topic, we persisted them directly into a DLQ table in PostgreSQL. We were already using CloudSQL as our durable store, so operationally this added very little complexity. Conceptually, it also made failures first-class citizens in the system rather than opaque messages lost in a stream.&lt;/p&gt;
    &lt;p&gt; Whenever an event failed processingâdue to an API failure, consumer crash, schema mismatch, or validation errorâwe stored the raw event payload along with contextual information about the failure. Each record carried a simple status field. When the event first landed in the DLQ, it was marked as &lt;code&gt;PENDING&lt;/code&gt;. Once it was successfully reprocessed, the status was updated to &lt;code&gt;SUCCEEDED&lt;/code&gt;. Keeping the state model intentionally minimal made it easy to reason about the lifecycle of a failed event.
                    &lt;/p&gt;
    &lt;head rend="h3"&gt;DLQ Table Schema and Indexing Strategy&lt;/head&gt;
    &lt;p&gt;To support inspection, retries, and long-term operability, the DLQ table was designed to be simple, query-friendly, and retry-aware.&lt;/p&gt;
    &lt;head rend="h4"&gt;Table Schema&lt;/head&gt;
    &lt;code&gt;CREATE TABLE dlq_events (
    id BIGSERIAL PRIMARY KEY,
    event_type VARCHAR(255) NOT NULL,
    payload JSONB NOT NULL,
    error_reason TEXT NOT NULL,
    error_stacktrace TEXT,
    status VARCHAR(20) NOT NULL, -- PENDING / SUCCEEDED
    retry_count INT NOT NULL DEFAULT 0,
    retry_after TIMESTAMP WITH TIME ZONE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);&lt;/code&gt;
    &lt;head rend="h4"&gt;Key Design Considerations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;payload&lt;/code&gt;is stored as&lt;code&gt;JSONB&lt;/code&gt;to preserve the raw event without enforcing a rigid schema.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;status&lt;/code&gt;keeps the lifecycle simple and explicit.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;retry_after&lt;/code&gt;prevents aggressive retries when downstream systems are unstable.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;retry_count&lt;/code&gt;allows retry limits to be enforced without external state.&lt;/item&gt;
      &lt;item&gt;Timestamps make auditing and operational analysis straightforward.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Indexes&lt;/head&gt;
    &lt;code&gt;CREATE INDEX idx_dlq_status
ON dlq_events (status);

CREATE INDEX idx_dlq_status_retry_after
ON dlq_events (status, retry_after);

CREATE INDEX idx_dlq_event_type
ON dlq_events (event_type);

CREATE INDEX idx_dlq_created_at
ON dlq_events (created_at);&lt;/code&gt;
    &lt;p&gt;These indexes allow the retry scheduler to efficiently locate eligible events while still supporting fast debugging and time-based analysis without full table scans.&lt;/p&gt;
    &lt;head rend="h3"&gt;DLQ Retry Mechanism with ShedLock&lt;/head&gt;
    &lt;p&gt;Persisting failed events solved the visibility problem, but we still needed a safe and reliable way to retry them.&lt;/p&gt;
    &lt;p&gt; For this, we introduced a DLQ retry scheduler backed by ShedLock. The scheduler periodically scans the DLQ table for &lt;code&gt;PENDING&lt;/code&gt; events that are eligible for retry and attempts to process them again. Since the service runs on multiple instances, ShedLock ensures that only one instance executes the retry job at any given time. This eliminates duplicate retries without requiring custom leader-election logic.
                    &lt;/p&gt;
    &lt;head rend="h4"&gt;Retry Configuration&lt;/head&gt;
    &lt;code&gt;dlq:
  retry:
    enabled: true
    max-retries: 240
    batch-size: 50
    fixed-rate: 21600000 # 6 hours in milliseconds&lt;/code&gt;
    &lt;head rend="h4"&gt;How Retries Work&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The scheduler runs every six hours.&lt;/item&gt;
      &lt;item&gt;Up to fifty eligible events are picked up per run.&lt;/item&gt;
      &lt;item&gt;Events exceeding the maximum retry count are skipped.&lt;/item&gt;
      &lt;item&gt;Successful retries immediately transition the event status to &lt;code&gt;SUCCEEDED&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Failures remain in &lt;code&gt;PENDING&lt;/code&gt;and are retried in subsequent runs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Query Implementation&lt;/head&gt;
    &lt;p&gt; The retry scheduler uses a SQL query with &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt; to safely select eligible events across multiple instances. This PostgreSQL feature ensures that even if multiple scheduler instances run simultaneously, each will pick up different rows without blocking each other:
                    &lt;/p&gt;
    &lt;code&gt;@QueryHints(@QueryHint(name = "jakarta.persistence.lock.timeout", value = "-2"))
@Query(
    value = "SELECT * FROM dlq_table "
        + "WHERE messagetype = :messageType "
        + "AND retries &amp;lt; :maxRetries "
        + "AND (replay_status IS NULL OR replay_status NOT IN ('COMPLETED')) "
        + "ORDER BY created_at ASC "
        + "FOR UPDATE SKIP LOCKED",
    nativeQuery = true
)&lt;/code&gt;
    &lt;p&gt; The &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt; clause is crucial here. It allows each instance to lock and process different rows concurrently, preventing duplicate processing while maintaining high throughput. The query hint sets the lock timeout to &lt;code&gt;-2&lt;/code&gt;, which means "wait indefinitely" but combined with &lt;code&gt;SKIP LOCKED&lt;/code&gt;, it effectively means "skip any rows that are already locked by another transaction."
                    &lt;/p&gt;
    &lt;p&gt;This setup allowed the system to tolerate long downstream outages while avoiding retry storms and unnecessary load on dependent services.&lt;/p&gt;
    &lt;head rend="h3"&gt;Operational Benefits&lt;/head&gt;
    &lt;p&gt;With this approach, failures became predictable and observable rather than disruptive. Engineers could inspect failures using plain SQL, identify patterns, and reprocess only the events that mattered. If a downstream dependency was unavailable for hours or even days, events safely accumulated in the DLQ and were retried later without human intervention. If an event was fundamentally bad, it stayed visible instead of being silently dropped.&lt;/p&gt;
    &lt;p&gt;Most importantly, this design reduced operational stress. Failures were no longer something to fear; they were an expected part of the system with a clear, auditable recovery path.&lt;/p&gt;
    &lt;head rend="h3"&gt;My Thoughts&lt;/head&gt;
    &lt;p&gt;The goal was never to replace Kafka with PostgreSQL. Kafka remained the backbone for high-throughput event ingestion, while PostgreSQL handled what it does bestâdurability, querying, and observability around failures. By letting each system play to its strengths, we ended up with a pipeline that was resilient, debuggable, and easy to operate.&lt;/p&gt;
    &lt;p&gt;In the end, using PostgreSQL as a Dead Letter Queue turned failure handling into something boring and predictable. And in production systems, boring is exactly what you want.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46755115</guid><pubDate>Sun, 25 Jan 2026 15:51:03 +0000</pubDate></item><item><title>ICE using Palantir tool that feeds on Medicaid data</title><link>https://www.eff.org/deeplinks/2026/01/report-ice-using-palantir-tool-feeds-medicaid-data</link><description>&lt;doc fingerprint="ad964554d5aa1139"&gt;
  &lt;main&gt;
    &lt;p&gt;EFF last summer asked a federal judge to block the federal government from using Medicaid data to identify and deport immigrants.&lt;/p&gt;
    &lt;p&gt;We also warned about the danger of the Trump administration consolidating all of the government’s information into a single searchable, AI-driven interface with help from Palantir, a company that has a shaky-at-best record on privacy and human rights.&lt;/p&gt;
    &lt;p&gt;Now we have the first evidence that our concerns have become reality.&lt;/p&gt;
    &lt;p&gt;“Palantir is working on a tool for Immigration and Customs Enforcement (ICE) that populates a map with potential deportation targets, brings up a dossier on each person, and provides a “confidence score” on the person’s current address,” 404 Media reports today. “ICE is using it to find locations where lots of people it might detain could be based.”&lt;/p&gt;
    &lt;p&gt;The tool – dubbed Enhanced Leads Identification &amp;amp; Targeting for Enforcement (ELITE) – receives peoples’ addresses from the Department of Health and Human Services (which includes Medicaid) and other sources, 404 Media reports based on court testimony in Oregon by law enforcement agents, among other sources.&lt;/p&gt;
    &lt;p&gt;This revelation comes as ICE – which has gone on a surveillance technology shopping spree – floods Minneapolis with agents, violently running roughshod over the civil rights of immigrants and U.S. citizens alike; President Trump has threatened to use the Insurrection Act of 1807 to deploy military troops against protestors there. Other localities are preparing for the possibility of similar surges.&lt;/p&gt;
    &lt;p&gt;Different government agencies necessarily collect information to provide essential services or collect taxes, but the danger comes when the government begins pooling that data and using it for reasons unrelated to the purpose it was collected.&lt;/p&gt;
    &lt;p&gt;This kind of consolidation of government records provides enormous government power that can be abused. Different government agencies necessarily collect information to provide essential services or collect taxes, but the danger comes when the government begins pooling that data and using it for reasons unrelated to the purpose it was collected.&lt;/p&gt;
    &lt;p&gt;As EFF Executive Director Cindy Cohn wrote in a Mercury News op-ed last August, “While couched in the benign language of eliminating government ‘data silos,’ this plan runs roughshod over your privacy and security. It’s a throwback to the rightly mocked ‘Total Information Awareness’ plans of the early 2000s that were, at least publicly, stopped after massive outcry from the public and from key members of Congress. It’s time to cry out again.”&lt;/p&gt;
    &lt;p&gt;In addition to the amicus brief we co-authored challenging ICE’s grab for Medicaid data, EFF has successfully sued over DOGE agents grabbing personal data from the U.S. Office of Personnel Management, filed an amicus brief in a suit challenging ICE’s grab for taxpayer data, and sued the departments of State and Homeland Security to halt a mass surveillance program to monitor constitutionally protected speech by noncitizens lawfully present in the U.S.&lt;/p&gt;
    &lt;p&gt;But litigation isn’t enough. People need to keep raising concerns via public discourse and Congress should act immediately to put brakes on this runaway train that threatens to crush the privacy and security of each and every person in America.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46756117</guid><pubDate>Sun, 25 Jan 2026 17:36:19 +0000</pubDate></item><item><title>Show HN: An interactive map of US lighthouses and navigational aids</title><link>https://www.lighthouses.app/</link><description>&lt;doc fingerprint="d7cbf7b6dd5a60c7"&gt;
  &lt;main&gt;
    &lt;p&gt;This map shows active Coast Guard navigational beacons in the United States and parts of Canada, from the 2025 Light List.&lt;/p&gt;
    &lt;p&gt;For informational purposes only. Must not be used as a navigational aid. Official USCG Light List&lt;/p&gt;
    &lt;p&gt;Characteristic&lt;/p&gt;
    &lt;p&gt;Fl W 10s&lt;/p&gt;
    &lt;p&gt;Pattern&lt;/p&gt;
    &lt;p&gt;Flashing White, 10 second period&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46756427</guid><pubDate>Sun, 25 Jan 2026 18:06:26 +0000</pubDate></item><item><title>First, make me care</title><link>https://gwern.net/blog/2026/make-me-care</link><description>&lt;doc fingerprint="77b044a15c934274"&gt;
  &lt;main&gt;
    &lt;p&gt;First, Make Me Care Writing advice: some nonfiction fails because it opens with background instead of a hook—readers leave before reaching the good material. Find the single anomaly or question that makes your topic interesting, lead with that, and let the background follow once you’ve earned attention. [Return to blog index]&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46757067</guid><pubDate>Sun, 25 Jan 2026 19:03:40 +0000</pubDate></item><item><title>Spanish track was fractured before high-speed train disaster, report finds</title><link>https://www.bbc.com/news/articles/c1m77dmxlvlo</link><description>&lt;doc fingerprint="ae6089bcbd13d29b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Spanish track was fractured before high-speed train disaster, report finds&lt;/head&gt;
    &lt;p&gt;A fracture in a straight section of track "occurred prior to the passage" of a high-speed train that derailed, causing last Sunday's rail disaster in which 45 people died, an initial report has found.&lt;/p&gt;
    &lt;p&gt;A train run by private company Iryo derailed last Sunday and its rear carriages crossed on to the opposite track into the path of an oncoming train run by state-owned Renfe.&lt;/p&gt;
    &lt;p&gt;The CIAF rail investigation commission said not only did Iryo train's front carriages which stayed on the track have "notches" in their wheels, but three earlier trains that went over the track earlier did too.&lt;/p&gt;
    &lt;p&gt;A gap of almost 40cm (15in) in the track has become the focus of the investigation into the crash.&lt;/p&gt;
    &lt;p&gt;Sunday's deadly collision occurred at around 19:45 local time (18:45 GMT), about an hour after the Iryo train left Málaga for Madrid.&lt;/p&gt;
    &lt;p&gt;The train's last three carriages - carriages six to eight - derailed and collided with the Huelva-bound Renfe train. "Carriage six derailed due to a complete lack of continuity in the track," the preliminary report finds.&lt;/p&gt;
    &lt;p&gt;Most of those killed and injured were in the front carriages of the state-operated train.&lt;/p&gt;
    &lt;p&gt;Earlier this week, Spanish Transport Minister Óscar Puente confirmed reports that grooves were found on the wheels of the Iryo train's carriages, which had passed over the track safely.&lt;/p&gt;
    &lt;p&gt;"These notches in the wheels and the deformation observed in the track are compatible with the fact that the track was cracked," the CIAF preliminary report said.&lt;/p&gt;
    &lt;p&gt;It added that three trains that had gone over the tracks at 17:21 on Sunday, 19:01 and then 19:09 had similar notches "with a compatible geometric pattern".&lt;/p&gt;
    &lt;p&gt;Similar grooves are found on carriages two, three and four of the Iryo train, the report says, but carriage five - the last that did not derail - had a groove on its outer edge, suggesting the rail was already tilting outwards before carriage six derailed.&lt;/p&gt;
    &lt;p&gt;The CIAF called its report a "working hypothesis", adding that it "must be corroborated by later detailed calculations and analysis".&lt;/p&gt;
    &lt;p&gt;The transport minister appeared before reporters again on Friday to say that it was too early to have definitive answers, but that if the cause of the crash was the fracture, then it occurred in the minutes and hours before the derailment and could not have been detected.&lt;/p&gt;
    &lt;p&gt;The Adamuz disaster is is the country's worst rail crash in more than a decade.&lt;/p&gt;
    &lt;p&gt;In 2013, Spain suffered its worst high-speed train derailment in Galicia, north-west Spain, which left 80 people dead and 140 others injured.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46757162</guid><pubDate>Sun, 25 Jan 2026 19:12:50 +0000</pubDate></item><item><title>I was right about ATProto key management</title><link>https://notes.nora.codes/atproto-again/</link><description>&lt;doc fingerprint="ed9ccb1f2d2256d9"&gt;
  &lt;main&gt;
    &lt;p&gt;Note: this post has been revised to be split into two sections: a description of what happened, and my analysis. I hope to make it clear that, while I do not like ATProto in general, I am trying to make good-faith critcisms of specific design decisions and outcomes, and in fact, this post getting updoots on HackerNews appears to have gotten the attention of the team, so, mission accomplished. ref, ref My account has since been manually reinstated; this has not happened for any of the other users that have had this issue, as far as I know.&lt;/p&gt;
    &lt;p&gt;Today, I tried setting up an ATProto account for use with Bluesky, with did:web instead of did:plc. Let’s walk through the process:&lt;/p&gt;
    &lt;p&gt;Set up the PDS software on a server I control. Because I use NixOS, this was very easy.&lt;/p&gt;
    &lt;p&gt;Create a did:web. This means creating a public-private keypair; I initially tried following this tutorial from Mai Lapyst, but it’s very out of date, and doesn’t include a critical step.&lt;/p&gt;
    &lt;p&gt;With that did:web, upload the &lt;code&gt;did.json&lt;/code&gt; document to my webserver and set the appropriate DNS entries. Easy enough, except that I also had to set the CORS header for the &lt;code&gt;did.json&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Create an account on my new PDS. I was able to get an invite and create an account, but it was in the “deactivated” status, and I couldn’t activate it. This had to be done by making requests manually with &lt;code&gt;curl&lt;/code&gt;, reading the error outcomes in the PDS’s logs on my server.&lt;/p&gt;
    &lt;p&gt;Seek help in the ATProto Touchers Discord server, and at their advice delete the account.&lt;/p&gt;
    &lt;p&gt;Start over and re-create everything from scratch, correctly replacing the public key in my DID with the public key from &lt;code&gt;getRecommendedDidCredentials&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Log into Bluesky (bsky.app) and get a “Profile does not exist error.”&lt;/p&gt;
    &lt;p&gt;It was at this point that I found this GitHub issue, which seems to imply that, since I deleted my (completely empty and unused) account, my did:web is blacklisted from the remaining mostly-centralized bit of the system, the AppView. The term for this is being “burned”, and it was later confirmed by some more experienced users that this is a known but undocumented behavior of the Bluesky AppView.&lt;/p&gt;
    &lt;p&gt;I had one of my friends who uses Bluesky take a look, and the failure mode is interesting. On Bluesky, I didn’t exist at all. (She could not see my likes, or my follow of her.) On Blacksky production, my display name and bio were visible, but not my posts. On Blacksky’s own AppView, it’s the opposite; my posts appeared under an “invalid” profile. I have been un-“burned” by a manual process, but not because of my support request; this post made it to the front page of Hacker News, and Bryan Newbold saw it there.&lt;/p&gt;
    &lt;p&gt;This is bad.&lt;/p&gt;
    &lt;p&gt;So, a while ago, I wrote a post called “Key Management, ATProto, and Decentralization” in which I complained about ATProto’s approach to decentralization. Since then, Blacksky has spun up an AppView, which makes it theoretically possible to have an actually decentralized experience on Bluesky. This was my line in the sand, stated many times; I would make an account when and only when it was possible to do so without using anything running on Bluesky-the-company’s hardware. That’s now, so I figured I’d try it.&lt;/p&gt;
    &lt;p&gt;I use lots of systems I don’t love, like Signal, Matrix, and Mastodon. I use them because they give me access to social interaction with people I care about. ATProto, and specifically Bluesky, is the same; I have friends who don’t post anywhere else. Today, I follow them by RSS, but can’t interact with their posts. That’s where my motivation to use the network comes from, along with understanding how, and how well, the newly decentralized AppView layer works.&lt;/p&gt;
    &lt;p&gt;Very little of this process is documented. Sure, the individual endpoints are - kind of - but the only place the whole process is collected in one place is in the comments to this GitHub issue… which is closed as WONTFIX. The documentation for that &lt;code&gt;getRecommendedDidCredentials&lt;/code&gt; endpoint that I missed reads in full:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Describe the credentials that should be included in the DID doc of an account that is migrating to this service.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Note that I am not “migrating”; this account is new. Plus, the JSON keys it returns are almost, but not quite, the same as those in a DID document, and the key it returns actually has to be edited by hand in order to be usable.&lt;/p&gt;
    &lt;p&gt;This is not good! &lt;code&gt;did:web&lt;/code&gt; has been held up as the “less centralized” or “bring your own trust” option, as opposed to &lt;code&gt;did:plc&lt;/code&gt;, and it seems like there has been very little effort to make it usable, certainly not for “normal” users.&lt;/p&gt;
    &lt;p&gt;But there’s another issue, a bigger issue. Why is a centralized “burn” able to completely prevent me from interacting with people using Bluesky?&lt;/p&gt;
    &lt;p&gt;You may be aware that Mastodon has a similar system. If you set up a Mastodon server and then delete the database, anyone you’ve already federated with won’t federate with you again, because you can’t prove you’re the same instance. It’s a genuine issue - but it wouldn’t have resulted in this, because I hadn’t even made a post on my now-burned did:web identity, nor followed anyone.&lt;/p&gt;
    &lt;p&gt;Even if I had, though, that would have burned a connection, not all connections. My experience would be degraded, but not ruined, and I could work with the admins of the affected servers to remediate it. You could say the same here, of course; I had to get my account back by Bryan Newbold happening to see this post on Hacker News. There is only, really, one connection that matters; maybe two, if you count Blacksky, but their AppView is not generally available yet. That’s centralization. I don’t understand how you could call it anything else.&lt;/p&gt;
    &lt;p&gt;I don’t like Bluesky, or ATProto; I wish we lived in a world were community-driven projects got megabucks and we were all self-hosting little social media servers for our communities. We don’t live in that world, so we have to interoperate with VC-backed, corporate social media. When those platforms call themselves “decentralized”, I think they should deliver.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46757357</guid><pubDate>Sun, 25 Jan 2026 19:31:23 +0000</pubDate></item><item><title>Oneplus phone update introduces hardware anti-rollback</title><link>https://consumerrights.wiki/w/Oneplus_phone_update_introduces_hardware_anti-rollback</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46757944</guid><pubDate>Sun, 25 Jan 2026 20:39:25 +0000</pubDate></item><item><title>LED lighting undermines visual performance unless supplemented by wider spectra</title><link>https://www.nature.com/articles/s41598-026-35389-6</link><description>&lt;doc fingerprint="541a12230e7947d4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;Life evolved under broad spectrum sunlight, from ultraviolet to infrared (300–2500 nm). This spectrally balanced light sculpted life’s physiology and metabolism. But modern lighting has recently become dominated by restricted spectrum light emitting diodes (350–650 nm LEDs). Absence of longer wavelengths in LEDs and their short wavelength dominance impacts physiology, undermining normal mitochondrial respiration that regulates metabolism, disease and ageing. Mitochondria are light sensitive. The 420–450 nm dominant in LEDs suppresses respiration while deep red/infrared (670–900 nm) increases respiration in aging and some diseases including in blood sugar regulation. Here we supplement LED light with broad spectrum lighting (400–1500 nm+) for 2 weeks and test colour contrast sensitivity. We show significant improvement in this metric that last for 2 months after the supplemental lighting is removed. Mitochondria communicate across the body with systemic impacts following regional light exposure. This likely involves shifting patterns of serum cytokine expression, raising the possibility of wider negative impacts of LEDs on human health particularly, in the elderly or in the clinical environment where individuals are debilitated. Changing the lighting in these environments could be a highly economic route to improved public health.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Ambient light impacts on human health. Sunlight, under which life evolved, extends over approximately 300–2500 nm. Older incandescent lighting common until recently has a similar spectral range. But because our visual sensitivity is limited to 400–700 nm we are unaware of infrared light (approximately 700–2500 nm). However, light in the built environment is now driven by light emitting diodes (LEDs), whose restricted spectrum (approximately 350–650 nm) is designed around our visual sensitivity and consequently is economic1.&lt;/p&gt;
    &lt;p&gt;Typical LED lighting produces strong elements in the shorter blue wavelengths (420–450 nm) with a second yellow peak which drops swiftly above 650 nm, with little light above 700 nm1. Short wavelength exposure in animals in the range of 420–450 nm reduces mitochondrial function, which provides the energy for physiological performance in the form of adenosine triphosphate (ATP). This short wavelength light reduces mitochondrial complex activity and ATP production, in a highly conserved manner. Hoh Kam et al. showed a significant decrease in mitochondrial enzymatic activity in fruit flies for complexes I-IV under 420 nm light2. Kaynezhad et al. used broadband near infrared spectroscopy (bNIRS) imaging the mouse retina and reported significant instability of deoxygenated haemoglobin and oxidised cytochrome-c-oxidase after exposure to 420 nm light. This instability remained significant through a 1 h recovery period when the light was withdrawn3. Short wavelength light (420 and 450 nm) also results in increased body weight. Hussaini et al. demonstrated that mice exposed to these wavelengths gaining weight rapidly compared to controls over the course of eight weeks4. Shorter wavelengths in similar ranges are also associated with reduced lifespan. Nash et al. revealed a 50% drop in the median lifespan of fruit flies exposed to unfiltered white LED light relative to those kept in darkness, but only 4% drop if this LED light was passed through a yellow filter, blocking the shorter wavelength light5. This negative influence is likely due to mitochondrial absorption by porphyrin that may increase proinflammatory oxygen singlet production reducing mitochondrial function as proposed by Kaynezhad et al.3.&lt;/p&gt;
    &lt;p&gt;Longer wavelengths (700 nm+) penetrate deeply and those in sunlight can be measured passing through the human body6. These are absent from standard LEDs but present in sunlight and incandescent lighting. Their presence increases mitochondrial performance and ATP production, particularly when challenged by age or disease. Gkotsi et al. demonstrated significantly increased ATP production in the retina, cortex, and thalamus of mice following exposure to 670 nm light7. Calaza et al. revealed a 50% increase in ATP in eight-month-old complement factor H knock out mice that have a mitochondrial deficit and are used as a murine model of macular degeneration8.&lt;/p&gt;
    &lt;p&gt;Increased mitochondrial performance is associated with increased lifespan and enhanced mobility. Begum et al. demonstrated using fruit flies that exposure to 670 nm resulted in a positive divergence of ageing survival rates of 10% at 4 weeks of age and up to nearly 180% by 8 weeks of age. The older animals also displayed an almost doubling of mobility against controls9. Neonicotinoid insecticides specifically target mitochondrial respiration inducing Parkinson like symptoms of immobility resulting in death. Here 670 exposure reversed damaged ATP levels to normal and corrects mobility and lifespan issues10.&lt;/p&gt;
    &lt;p&gt;Increased mitochondrial activity should result in reduced blood sugars and increased oxygen consumption as mitochondria use both in respiration. Powner and Jeffery found both in bumble bees exposed to 670 nm light11. The same authors translated this to humans showing again, reduced blood sugars and increased oxygen consumption in a standard glucose tolerance test following 15 min of 670 nm exposure. Here the spike in blood glucose was reduced significantly by around 27%12.&lt;/p&gt;
    &lt;p&gt;Changes in physiology produced by longer wavelengths translate to improved function. Shinhmar et al. revealed improved colour contrast sensitivity in humans after 3 min of morning exposure to 670 nm light13. Hence, exposure to different ends of the spectrum that impact differentially on mitochondria can translate into changes in key physiological metrics.&lt;/p&gt;
    &lt;p&gt;Similar changes are found at the population level. Those spending more time in sunlight generally have improved health including reduced incidents of cardiovascular disease and the incidence of cancer. They also have lower rates of type 2 diabetes14,15.&lt;/p&gt;
    &lt;p&gt;In this study we confront the impact of LED lighting on human visual performance by measuring colour contrast detection in an LED illuminated working environment that is then supplemented with incandescent lighting. The hypothesis is that LED lighting suppresses mitochondrial function in the retina and that this can be corrected by introduction of wide spectrum incandescent lights. The results highlight the potential damaging influence of LED lighting on human performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methods&lt;/head&gt;
    &lt;p&gt;The Subjects and their environment: The study was conducted in accordance with the Declaration of Helsinki and approved by University College London research ethics committee (16547/001). It was undertaken in University College London buildings in October to December. In October local daylight hours were approximately 10.37 with 75% cloud cover. In November local daylight hours were approximately 8.45 with 55% cloud cover. In December local daylight hours were approximately 7.5 with 90% cloud cover. Local sunset time in October is approximately 18.30. In November it is approximately 16.15 and in December it is approximately 16.00. Consequently, many subjects would be returning home after sunset in November and December. Subjects worked approximately 8 h a day 5 days a week and travel to and from work via public transport that was illuminated by LED devices. Most subjects did not leave the building in which they worked during the working day in these months. For those that did it was commonly for less than 15 min at lunch time. Within the work environment subjects were free to move around. Here the internal lighting they experienced was consistently LED based. Hence, natural daylight exposure during this latter part of the year was limited. We could not control for weekend exposure, however subjects homes were consistently illuminated with LEDs and because the weather in the UK at this time of year is inclement, their time outside buildings can be expected to be limited.&lt;/p&gt;
    &lt;p&gt;Each participant provided written informed consent prior to testing and data generated was anonymised. Subjects (N = 22) were of both sexes and between the ages of 23 and 65 years. Prior to the experiment all subjects were asked to confirm normal corrected visual function and general good systemic health. This was undertaken in a simple interview prior to their inclusion in the study. All were healthy without visual or other health problems. Experimental subjects (N = 11) worked exclusively under LED lighting in the back of the Here East building on the north side, &amp;gt; 50 m from what little light did manage to penetrate the entrance doors when open. The LED lighting delivered an illuminance of 1000 lx at working height, with a correlated colour temperature (CCT) of 4000 K, and a TM-30 average colour fidelity index, Rf, of 91. The infrared light that was introduced was provided by tungsten desk lamps placed around the working space was non-uniform. The visible component of the 60 W tungsten bulbs was small when compared with the 1000 lx of LED. The test subjects were not expected to use these as task lamps. The LED lighting delivered an irradiance of 3.7 W/m2 on the horizontal working plane.&lt;/p&gt;
    &lt;p&gt;Control subjects (N = 11) worked in similar environments under LED lighting without direct sunlight. The LED lighting delivered an illuminance of 900 lx at working height, with a CCT of 3000 K and a Rf of 85. The colour contrast tests were performed in a darkened room where the only light came from the test itself. There were no requirements restricting other light exposure patterns during the study.&lt;/p&gt;
    &lt;p&gt;The experimental location: Subjects worked at UCL Here East, a media and innovation complex located in East London (London E15 2GW), originally built as a press and broadcast centre for the London 2012 Olympics and subsequently repurposed as a campus. UCL Here East occupies part of the Broadcast Centre, taking up the ground and first floor of unit B. The footprint of the building is deep, with daylight only able to enter through the glazing at the front of the building. This glazing uses an infrared blocking film, which can be revealed using infrared photography.&lt;/p&gt;
    &lt;p&gt;A Canon 500D digital camera was modified to replace the infrared blocking layer with clear glass that passes infrared wavelengths. This was used in conjunction with filters that block visible and infrared wavelengths to explore the presence and absence of infrared light. Spectral measurements were made with two spectrophotometers (Ocean Optics SR-6XR250-50 and FLAME-NIR) with optic fibre and cosine correctors used to collect the incandescent spectra in the shorter and longer wavelengths.&lt;/p&gt;
    &lt;p&gt;Incandescent desk lighting was introduced into the work environment using desk lamps with 60 W clear Edison bulbs (Polaris UK) placed on work benches. All subjects had worked in this LED-lit environment for more than 2 years. Desk lamps with incandescent bulbs were introduced onto the benches where experimental subjects spent the majority of their time. They were given the incandescent lighting for 2 weeks and, while they spend the majority of their time working near these lights, they were free to move around and leave their desks as they wished. The introduced light showed a high degree of reflectance from the work surfaces.&lt;/p&gt;
    &lt;p&gt;Colour contrast testing: All subjects were tested for colour contrast ability using ChromaTest prior to the introduction of incandescent lighting and then again 2 weeks later. This test must be carried out in a darkened room, so a nearby windowless room was set aside for this purpose. The incandescent lighting was then removed and subjects retested at 4 and 6 weeks. Hence, this element of the experiment was a before and after design which avoids between subject variability. However, there was also a separate control group (N = 11) composed of subjects that worked under LED lighting similar to those in the experimental group.&lt;/p&gt;
    &lt;p&gt;ChromaTests is a sensitive measure of colour contrast detection of letters presented in a random order against a noisy visual background in either tritan (blue) or protan (red) visual axes13. If subjects correctly identify a letter its contrast is reduced in the next presentation of a letter. Likewise, if they fail to correctly identify the letter, the contrast is increased. This is repeated until thresholds are determined in 5 identical repeated trials. This normally involved around 70–100 separate presentations in total. Subjects were given an initial trial before testing to avoid a learning effect. Initial presentations were at high colour contrast. No learning effects were noted in the study.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;head rend="h3"&gt;Light assessment in the experimental environment&lt;/head&gt;
    &lt;p&gt;Figure 1 shows the front exterior of the Here East building using infrared imaging at ground level where experiments were undertaken. The windows are completely infrared reflective due to their blocking film and hence mirror-like. Figure 2 is an infrared image from inside the building looking out through the open doorway. Only infrared light coming through the open door and its reflectance can be seen, not light coming through adjacent windows. Hence, the building is relatively impervious to infrared light.&lt;/p&gt;
    &lt;p&gt;Figure 3 shows the working environment in Here East in visible light in which the experiment took place. Images in infrared were completely black. The distance between the work environment and the front door was &amp;gt; 50 m with multiple doors between.&lt;/p&gt;
    &lt;p&gt;The internal lighting throughout Here East was provided by arrays of ceiling mounted standard LED units. Spectral profiles of the lighting within the building are shown in Fig. 4. against incandescent lighting in black and red.&lt;/p&gt;
    &lt;p&gt;The blue curve shows the spectral profile of the light delivered to the horizontal working plane. As the work environment was deep in the building and lit only with LED lighting, it received no daylight and was devoid of any infrared illumination. The LED units delivered 1000 lx on the horizontal working plane with a correlated colour temperature (CCT) of 4000 K and a TM-30 colour fidelity index of 91. The irradiance of this LED light was 3.6 W/m2.&lt;/p&gt;
    &lt;p&gt;The specific spectra and energy levels were mapped over the workspace at fixed locations. This is shown in Fig. 5a and b. Here there is a plan of the space and measurements made at 9 locations of energy given in W/cm− 2 and lux, which is a metric corrected for the human eye. Also provided are the spectra at each location. Changes in brightness at different locations were largely not detectable by the human eye and were gradual. There were no differences in spectral profiles across the area only their relative intensity.&lt;/p&gt;
    &lt;p&gt;Light assessment was also undertaken at bench level where individual subjects worked. This is shown in Fig. 6. This confirmed the absence of any part of the infrared spectrum in the work environment and how this changed with the addition of the incandescent lamps.&lt;/p&gt;
    &lt;p&gt;In this study, responses to lighting were measured in test subjects both before and also after the lighting had been changed. However, there was also an independent control group that comprised individuals under similar LED lighting condition without daylight. A comparison of the lighting conditions in the two groups is shown in Fig. 7. Critically, the LEDs in both groups had very similar profiles with no infrared components. The overall brightness in the control group was slightly less than in the test group, although this was not apparent to the human eye. As in the test group, subjects were free to move around.&lt;/p&gt;
    &lt;head rend="h3"&gt;Visual responses to shifts in spectral lighting&lt;/head&gt;
    &lt;p&gt;Exposure to 60 W incandescent luminaires, which have a wider spectrum than LEDs extending into the infra-red1, resulted in significant improvements in visual performance in all experimental subjects across both the protan and tritan visual ranges. Improvements in both tritan and protan were of the order of 25%. Hence, significant improvements were uniform across visual ranges (Fig. 8). This is unlike experiments where specific red/infrared ranges have been used in LED devices, for example via 670 nm, where visual improvements have been biased towards tritan function13.&lt;/p&gt;
    &lt;p&gt;Figure 8 shows the results of both individual subjects on the left and also changes in the groups on the right. In spite of the universal improvement in visual function, in both tritan and protan range there was considerable variability between subjects. This variability validates the inclusion of a repeated measures design and the use of a sign test in the analysis. In all cases protan thresholds were lower than tritan consistent with previous studies13.&lt;/p&gt;
    &lt;p&gt;At the end of the 2 week period the incandescent luminaires were removed and the subjects returned to an exclusively LED dominated light working environment. They were then retested at 4 and 6 weeks. In previous experiments where 670 nm alone has been used, rather than the wide spectrum infrared produced by incandescent lighting, visual improvements decline in approximately a week13. However, following incandescent light exposure improvements remain unchanged across both visual domains at both 4 and 6 weeks. Hence, the impact of broad-spectrum incandescent light not only resulted in balanced improvements in colour contrast but also these improvements lasted much longer than previous interventions with restricted red/infrared ranges13.&lt;/p&gt;
    &lt;p&gt;An independent control group was used in addition to a before and after experimental design. Again, data between individuals was varied on both visual metrics. However, over a 2 week period there were no significant changes in proton or tritan visual thresholds (Fig. 9).&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;We demonstrate that the visual performance of those working under standard LED is significantly improved by exposure to incandescent lighting that has a spectrum similar to daylight with an extensive infrared component. These data are consistent with the hypothesis that LED lighting undermines human visual performance. This result is consistent with laboratory experiments where specific red/infrared wavelength ranges generated by LEDs have been used to improve visual function in animals and humans in a conserved manner13,16,17. But there are three critical differences from these earlier studies. First, we have simply changed environmental lighting in a free moving work environment. Second, we have obtained significant balanced improvements in both the protan and tritan range. Previously, exposure to restricted experimental 670 nm resulted in improvements biased strongly in favour of only tritan function13. Hence, exposure to full spectrum lighting results in a balanced pattern of improvement in visual performance. Third, we have shown that improvements in visual function following incandescent light exposure are sustained for up to 6 weeks, and possibly beyond, whereas benefits from single LED restricted range red light were confined to around 5 days13. These three features change the way in which long wavelength light may be applied to improve human physiology by delivery in normal environments with lasting balance effects. These results are novel and may have public health implications.&lt;/p&gt;
    &lt;p&gt;Our study used 22 subjects but was statistically significant using both a before and after metric and also against an independent control group. They are also similar to group sizes in aspects of Shinhmar et al.13 (Figs. 2, 3, 4 and 5). However, future studies would clearly benefit from inclusion of a larger number of subjects.&lt;/p&gt;
    &lt;p&gt;The evolution of life on earth extends over 4 billion years, and that of humans over approximately 4–5 million years from the last common primate ancestor. This has all taken place under sunlight that has a spectral range of approximately 300–2500 nm+, within which there has been an invariant balance between short and longer wavelengths. Human adoption of fire 1–2 million years ago supplemented sunlight as they moved out of Africa as its spectrum is similar having a large infrared component. Likewise, development of the Edison filament luminaire, common until approximately the year 2000 had a spectrum similar to sunlight. However, around 2010 LED lighting with its highly restricted spectrum (350–650 nm) and energy saving characteristics became common, resulting in a loss of infrared light in the built environment1.&lt;/p&gt;
    &lt;p&gt;The physiology of life forms are adapted to natural environmental light in a highly conserved pattern across species. Light impacts on mitochondrial function, which is a key regulator of metabolism and ageing in animals. When the balance of short and long wavelengths is shifted there are consequences for mitochondria. When shorter wavelength exposure is dominant, as in LED lighting, mitochondrial function declines. Mitochondrial complex proteins are reduced and there is reduced ATP production2,3. With reduced mitochondrial demand for glucose there is increased body weight and disruptions to serum cytokines4. Consequently, consistent with the mitochondrial theory of ageing there is an increased probability of cell/organism ageing and death18. It is suggested that this is partly due to 420–450 nm light, dominant in LEDs, being absorbed by porphyrin and the subsequent production of oxygen singlets driving inflammation3.&lt;/p&gt;
    &lt;p&gt;Conversely, exposure to longer wavelengths is associated with increased mitochondrial membrane potential and increased concentration of mitochondrial complex proteins that have declined with ageing and disease. This in turn is associated with elevated ATP, reduced inflammation and extended average lifespan7,9,10,19. The experimental use of longer wavelengths in such situations is commonly referred to as photobiomodulation.&lt;/p&gt;
    &lt;p&gt;The retina has the greatest metabolic rate in the body and a high mitochondrial concentration20. Retinal metabolism declines with age, but this can be partly corrected with long wavelength light across species16,21. In humans a single 3 min 670 nm exposure improves colour vision within 3 h, which is sustained for almost a week13. But what the authors of this study did not appreciate was that this was within a population who worked and lived mainly under LED lighting that may have undermined their baseline measurements. Here, we made no attempt to control light exposures or subject movements as would occur in laboratory-based experiments. Rather, our aim was to introduce wide spectrum long wavelengths into a work environment to improving human performance via mitochondrial manipulation in a translational step.&lt;/p&gt;
    &lt;p&gt;There is considerable evidence that introduction of longer wavelengths impact systemically. Durieux et al.22 stated in relation to experiments in C.elegans that “ We find that mitochondrial perturbation in one tissue is perceived and acted upon by the mitochondrial stress response pathway in distal tissue”. In mice there are significant distinct changes serum cytokine expression to exposures of both short and long wavelength light4,23. Similarly, long wavelength exposures to the surface of the human body excluding the eyes significantly reduces blood glucose levels and increases oxygen consumption in humans. This is likely because mitochondrial upregulation will increase carbohydrate demand to support increased ATP production12. Other systemic impacts can be found and are clear in experimentally induced Parkinson’s in primates. Light targeted by implants focusing on the substantia nigra are effective in reducing symptoms24, but so also are those that are directed at distal locations25.&lt;/p&gt;
    &lt;p&gt;Single 3 min 670 nm exposures remain effective for about 5 days13. But we show that with a wider spectrum they remain effective for 6 weeks, although we did not find the end of the effect. Here it is worth considering potential mechanisms of action which remain subject of debate. Historically, improvements with red light were thought to be due to light absorption by cytochrome C in the respiratory chain26. However, positive effects are found in vitro in the absence of this. Consequently, it has been suggested that longer wavelengths reduce water viscosity around rotary ATP pumps allowing the rotor to increase speed27. This cannot explain the sustained impacts of light exposure as this effect should be relatively transitory as viscosity would increase rapidly following light withdrawal. However, a key feature of long wavelength light absorption is increased respiratory chain protein synthesis. These proteins are in flux throughout the day28 and complex IV is upregulated following red light exposure19. Hence, while red light may initially increase rotor pump speed there rapidly follows an increase in protein synthesis which may establish greater respiratory chain capacity. The life of these proteins could then determine the length of effect.&lt;/p&gt;
    &lt;p&gt;Only thirteen polypeptides are made in mitochondrial protein synthesis. This probably slows with age and likely contributes to aged mitochondrial decline18. But critically, we do not know the speed of mitochondrial protein synthesis, the life of such proteins or the pace of their decline. We suggest that these may be key events in the length of the effects from light exposure.&lt;/p&gt;
    &lt;p&gt;LED lighting clearly has the ability to undermine visual performance probably via reduced mitochondrial function. As light induced changes in mitochondrial ability have been shown to have systemic impacts4,15,22,23,25, the effects of LEDs revealed here may be wider than initially anticipated. Given the prevalence of LEDs, this may represent an important issue in public health and clinical environments where changing lighting patterns in appreciation of this point can have significant positive outcomes29.&lt;/p&gt;
    &lt;p&gt;Given our results, it is important to ask what solutions may be found to improve health in terms of lighting in the built environment. Incandescent lights that we reveal here to have significant positive impact over standard LEDs are being phased out universally for reasons of energy efficiency, where focus is only on the visible light produced.&lt;/p&gt;
    &lt;p&gt;A solution may be found in creating lighting units with multiple longer wavelength LEDs to cover a wider span of the near infrared. However, our attempts here have had limited success. Multiple closely associated spectral peaks do not produce a smooth spectral output as found in incandescent lights and sunlight, which is problematic in improving function and has yet to deliver. This possibly may be overcome using a greater number of spectral peaks with tighter spacing. But this raises a different series of problems regarding cost and increased energy consumption making this solution no better than retention of incandescent sources in terms of environmental sustainability.&lt;/p&gt;
    &lt;p&gt;Key to this issue is the question of how much infrared is needed to sustain improved function? Infrared has relatively few absorbers in the built environment and in current studies relatively little has to be added to the environment for effect. However, a viable option is to run an incandescent light at a lower temperature which results in both energy savings and increased life of the unit and also shifts the peak spectral output towards longer wavelengths.&lt;/p&gt;
    &lt;p&gt;If this is done with a halogen bulb, which is a type of incandescent tungsten bulb, the filament lasts for a longer period as evaporated tungsten is redeposited on the filament rather than blackening the bulb glass. Hence, using a halogen bulb at lower voltage is a realistic alternative in terms of health and energy consumption.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data availability&lt;/head&gt;
    &lt;p&gt;The data sets used and/or analysed during the current study are available from the corresponding author on reasonable request.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Ratto, G. E., Videla, F. A. &amp;amp; Martinez Valiviezd, J. H. Artificial light: traditional and new sources, their potential impact on health, and coping strategies: preliminary spectral analysis. Proc. SPIE Conf. 11814. San Diego California. (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hoh Kam, J., Hogg, C., Fosbury, R., Shinhmar, H. &amp;amp; Jeffery, G. Mitochondria are specifically vulnerable to 420nm light in drosophila which undermines their function and is associated with reduced fly mobility. Plos one. Sep 3;16(9):e0257149. (2021). https://pubmed.ncbi.nlm.nih.gov/34478469. PMID: 34478469.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kaynezhad, P. et al. Near infrared spectroscopy reveals instability in retinal mitochondrial metabolism and haemodynamics with blue light exposure at environmental levels. J.Biophotonics. ;15(4):e202100283. (2022). https://pubmed.ncbi.nlm.nih.gov/35020273/. PMID: 35020273.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Al-Hussaini, H. et al. Impact of short wavelength light exposure on body weight, mobility, anxiety like behaviour and cytokine expression. Sci. Rep. ;15(1):5927. (2025). https://pubmed.ncbi.nlm.nih.gov/39966413/. PMID: 39966413.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nash, T. R. et al. Daily blue-light exposure shortens lifespan and causes brain neurodegeneration in Drosophila. Aging. Mech. Dis 2019 Oct 17:5:8. https://pubmed.ncbi.nlm.nih.gov/31636947/. PMID: 31636947.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jeffery, G. et al. Longer wavelengths in sunlight pass through the human body and have a systemic impact which improves vision. Sci. Rep. 2025 July;15(1);24435. https://doi.org/10.1038/s41598-025-09785-3&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gkotsi, D. et al. Recharging mitochondrial batteries in old eyes. Near infra-red increases ATP. Exp.Eye Res. 2014 May:122:50 – 3. https://pubmed.ncbi.nlm.nih.gov/24631333/ PMID: 24631333.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Calaza, K. C., Hoh Kam, J., Hogg, C. &amp;amp; Jeffery, G. Mitochondrial decline precedes phenotype development in the complement factor H mouse model of retinal degeneration but can be corrected by near infrared light. Neurobiol. Aging. ;36(10):2869-76. (2015). https://pubmed.ncbi.nlm.nih.gov/26149919/ PMID: 26149919.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Begum, R. et al. Near-infrared light increases ATP, extends lifespan and improves mobility in aged Drosophila melanogaster. Biol.Lett. ;11(3):20150073. (2015). https://pubmed.ncbi.nlm.nih.gov/25788488/ PMID: 25788488.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powner, P. MB, SaltTE, Hogg, C. &amp;amp; Jeffery, G. Improving mitochondrial function protects bumblebees from neonicotinoid pesticides. Plos One. 11 (11), e0166531 (2016). https://pubmed.ncbi.nlm.nih.gov/27846310/ PMID: 27846310.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powner, P. MB &amp;amp; Jeffery, G. Systemic glucose levels are modulated by specific wavelengths in the solar light spectrum that shift mitochondrial metabolism. Plos One. 17 (11), e0276937 (2022). https://pubmed.ncbi.nlm.nih.gov/36327250/ PMID: 36327250.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powner, M. B. &amp;amp; Jeffery, G. Light stimulation of mitochondria reduces blood glucose levels. J.Biophotonics. ;17(5):e202300521. (2024). https://pubmed.ncbi.nlm.nih.gov/38378043/. PMID: 38378043.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shinhmar, H., Hoog, C., Neveu, M. &amp;amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). https://pubmed.ncbi.nlm.nih.gov/34819619/. PMID: 34819619.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Weller, R. B. &amp;amp; Sunlight Time for a Rethink? J.Invest. Dermatol. ;144(8):1724–1732. (2024). https://pubmed.ncbi.nlm.nih.gov/38661623/ PMID: 38661623.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shore-Lorenti, C. et al. Shining the light on Sunshine: a systematic review of the influence of sun exposure on type 2 diabetes mellitus-related outcomes. Clin. Endocrinol. ;81(6):799–811. (2014). https://pubmed.ncbi.nlm.nih.gov/25066830/ PMID: 25066830.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Weinrich, T. W., Coyne, A., Salt, T. E., Hogg, C. &amp;amp; Jeffery, G. Improving mitochondrial function significantly reduces metabolic, visual, motor and cognitive decline in aged Drosophila melanogaster. Neurobiol. Aging. 2017 Dec:60:34–43. doi: 10.1016. https://pubmed.ncbi.nlm.nih.gov/28917665/ PMID: 28917665.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sivapathasuntharam, C., Sivaprasad, S., Hogg, C. &amp;amp; Jeffery, G. Aging retinal function is improved by near infrared light (670 nm) that is associated with corrected mitochondrial decline. Neurbiol. Aging 2017 Apr:52:66–70. https://pubmed.ncbi.nlm.nih.gov/28129566/ PMID: 28129566.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lopez-Otin, C., Blasco, M. A., Partridge, L., Serrano, M. &amp;amp; Kroemer, G. The hallmarks of aging. Cell 153 (6), 1194–1217 (2013). https://pubmed.ncbi.nlm.nih.gov/23746838/ PMID: 23746838.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Begum, R., Powner, P. MB, Hudson, N., Hogg, C. &amp;amp; Jeffery, G. Treatment with 670 Nm light up regulates cytochrome C oxidase expression and reduces inflammation in an Age-Related macular degeneration model. Plos One. 8 (2), e57828 (2013). https://pubmed.ncbi.nlm.nih.gov/23469078/ PMID: 23469078.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kocherlakota, S., Hurley, J. B., Shu, D. Y. &amp;amp; Editorial Retinal metabolism in health and disease. Front Ophthalmol (Lausanne). 2024 Jul 17:4:1459318. https://pubmed.ncbi.nlm.nih.gov/39086994/ PMID: 39086994.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hoh Kam, J. et al. Mitochondrial decline in the ageing old world primate retina: Little evidence for difference between the centre and periphery. Plos One. ;18(5):e0273882. (2023). https://pubmed.ncbi.nlm.nih.gov/37130143/ PMID: 37130143.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Durieux, J., Wolff, S. &amp;amp; Dillin, A. The cell-non-autonomous nature of electron transport chain-mediated longevity. Cell 144 (1), 79–91 (2011). https://pubmed.ncbi.nlm.nih.gov/21215371/ PMID: 21215371.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shinhmar, H., Hogg, C. &amp;amp; Jeffery, G. Exposure to long wavelength light that improves aged mitochondrial function shifts acute cytokine expression in serum and the retina. Plos One. 18 (7), e0284172 (2023). https://pubmed.ncbi.nlm.nih.gov/37478072/ PMID: 37478072.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Darlot, F. et al. Near-infrared light is neuroprotective in a monkey model of Parkinson disease. Ann. Neurol. ;79(1):59–75. (2016). https://pubmed.ncbi.nlm.nih.gov/26456231/ PMID: 26456231.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gordon, L. C. et al. Remote photobiomodulation targeted at the abdomen or legs provides effective neuroprotection against parkinsonian MPTP insult. Eur. J. Neurosci. ;57(9):1611–1624. (2023). https://pubmed.ncbi.nlm.nih.gov/36949610/. PMID: 36949610.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Salehpour, F., Mahmoudi, J., Kamari, F., Sadigh-Eteghad, Rasta, S. H. &amp;amp; Hamblin, M. R. Brain Photobiomodulation Therapy: a Narrative Review. Mol. Neurobiol. ;55(8):6601–6636. (2018). https://pubmed.ncbi.nlm.nih.gov/29327206/ PMID: 29327206.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sommer, A. P. Mitochondrial cytochrome c oxidase is not the primary acceptor for near infrared light-it is mitochondrial bound water: the principles of low-level light therapy. Ann. Transl. Med. ;7(Suppl 1):S13. (2019). https://pubmed.ncbi.nlm.nih.gov/31032294/. PMID: 31032294.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Weinrich, T. et al. A day in the life of mitochondria reveals shifting workloads. Sci. Rep. ;9(1):13898. (2019). https://pubmed.ncbi.nlm.nih.gov/31554906/ PMID: 31554906.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Neto, R. P. M. et al. Photobiomodulation therapy (red/NIR LEDs) reduced the length of stay in intensive care unit and improved muscle function: A randomized, triple-blind, and sham-controlled trial. J.Biophotonics. ;17(5):e202300501. (2024). https://pubmed.ncbi.nlm.nih.gov/38262071/ PMID: 38262071.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;We thank Chris Hogg for assistance with Chromatest, and Mandana Khanie for use of the Ocean Optics spectrophotometers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Funding&lt;/head&gt;
    &lt;p&gt;This research did not receive funding.&lt;/p&gt;
    &lt;head rend="h2"&gt;Author information&lt;/head&gt;
    &lt;head rend="h3"&gt;Authors and Affiliations&lt;/head&gt;
    &lt;head rend="h3"&gt;Contributions&lt;/head&gt;
    &lt;p&gt;GJ and EB designed the experiments undertook all the experimental work and wrote the manuscript.&lt;/p&gt;
    &lt;head rend="h3"&gt;Corresponding author&lt;/head&gt;
    &lt;head rend="h2"&gt;Ethics declarations&lt;/head&gt;
    &lt;head rend="h3"&gt;Competing interests&lt;/head&gt;
    &lt;p&gt;The authors declare no competing interests.&lt;/p&gt;
    &lt;head rend="h2"&gt;Additional information&lt;/head&gt;
    &lt;head rend="h3"&gt;Publisher’s note&lt;/head&gt;
    &lt;p&gt;Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rights and permissions&lt;/head&gt;
    &lt;p&gt;Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.&lt;/p&gt;
    &lt;head rend="h2"&gt;About this article&lt;/head&gt;
    &lt;head rend="h3"&gt;Cite this article&lt;/head&gt;
    &lt;p&gt;Barrett, E.M., Jeffery, G. LED lighting (350-650nm) undermines human visual performance unless supplemented by wider spectra (400-1500nm+) like daylight. Sci Rep 16, 3061 (2026). https://doi.org/10.1038/s41598-026-35389-6&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Received:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Accepted:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Published:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Version of record:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DOI: https://doi.org/10.1038/s41598-026-35389-6&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46758644</guid><pubDate>Sun, 25 Jan 2026 21:44:10 +0000</pubDate></item><item><title>The future of software engineering is SRE</title><link>https://swizec.com/blog/the-future-of-software-engineering-is-sre/</link><description>&lt;doc fingerprint="bd4e911dfc4564fd"&gt;
  &lt;main&gt;
    &lt;p&gt;When code gets cheap operational excellence wins. Anyone can build a greenfield demo, but it takes engineering to run a service.&lt;/p&gt;
    &lt;p&gt;You may be wondering: With all the hype about agentic coding, will we even need software engineers anymore? Yes! We'll need more.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;SRE about to become the most hired job in engineering&lt;/p&gt;— Swizec Teller (@Swizec) January 13, 2026&lt;lb/&gt;Everybody wants to write a greenfield demo.&lt;lb/&gt;Nobody wants to run a service. https://t.co/THl9rBJ9rk&lt;/quote&gt;
    &lt;p&gt;Writing code was always the easy part of this job. The hard part was keeping your code running for the long time. Software engineering is programming over time. It's about how systems change.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons from the no-code and spreadsheets era&lt;/head&gt;
    &lt;p&gt;Let's take no-code and spreadsheets as an example of the kind of software people say is the future – custom-built, throwaway, built by non-experts to solve specific problems.&lt;/p&gt;
    &lt;p&gt;Joe Schmoe from accounting takes 10 hours to do a thing. He's does this every week and it feels repetitive, mechanical, and boring. Joe could do the work in his sleep.&lt;/p&gt;
    &lt;p&gt;But he can't get engineering resources to build a tool. The engineers are busy building the product. No worries, Joe is a smart dude. With a little Googling, a few no-code tools, and good old spreadsheet macros he builds a tool.&lt;/p&gt;
    &lt;p&gt;Amazing.&lt;/p&gt;
    &lt;p&gt;Joe's tool is a little janky but his 10 hour weekly task now takes 1 hour! 🎉 Sure, he finds a new edge case every every week and there's constant tinkering, but he's having a lot more fun.&lt;/p&gt;
    &lt;p&gt;Time passes, the business changes, accounting rules are in constant flux, and let's never talk about timezones or daylight savings ever again. Joe is sick of this bullshit.&lt;/p&gt;
    &lt;p&gt;All he wanted was to make his job easier and now he's shackled to this stupid system. He can't go on vacation, he can't train anyone else to run this thing successfully, and it never fucking works right.&lt;/p&gt;
    &lt;p&gt;Joe can't remember the last time running his code didn't fill him with dread. He spends hours carefully making sure it all worked.&lt;/p&gt;
    &lt;head rend="h2"&gt;The computer disease&lt;/head&gt;
    &lt;p&gt;Feynman called this the computer disease.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Feynman called this The Computer Disease pic.twitter.com/Zv4Bu4ftv1&lt;/p&gt;— Swizec Teller (@Swizec) December 26, 2025&lt;/quote&gt;
    &lt;p&gt;The problem with computers is that you tinker. Automating things is fun! You might forget you don't need to 😆&lt;/p&gt;
    &lt;p&gt;The part that's not fun is running things. Providing a service. Reliably, at scale, for years on end. A service that people will hire to do their jobs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why operational excellence is the future&lt;/head&gt;
    &lt;p&gt;People don't buy software, they hire a service.&lt;/p&gt;
    &lt;p&gt;You don't care how iCloud works, you just want your photos to magically show up across devices every time. You don't care about Word or Notion or gDocs, you just want to write what's on your mind, share it with others, and see their changes. And you definitely don't care how a payments network point of sale terminal and your bank talk to each other, you just want your $7 matcha latte to get you through the week.&lt;/p&gt;
    &lt;p&gt;Good software is invisible.&lt;/p&gt;
    &lt;p&gt;And that takes work. A lot of work. Because the first 90% to get a working demo is easy. It's the other 190% that matters.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What's your uptime?&lt;/item&gt;
      &lt;item&gt;Defect rate?&lt;/item&gt;
      &lt;item&gt;How quickly do you recover from defects?&lt;/item&gt;
      &lt;item&gt;Do I have to reach out or will you know before me?&lt;/item&gt;
      &lt;item&gt;Can you own upstream dependencies?&lt;/item&gt;
      &lt;item&gt;When a vendor misbehaves, will you notice or wait until your users complain?&lt;/item&gt;
      &lt;item&gt;When users share ideas, how long does it take?&lt;/item&gt;
      &lt;item&gt;How do you keep engineers from breaking each other's systems?&lt;/item&gt;
      &lt;item&gt;Do you have systems to keep engineers moving without turning your app into a disjointed mess?&lt;/item&gt;
      &lt;item&gt;Can you build software bigger than fits in 1 person's brain?&lt;/item&gt;
      &lt;item&gt;When I'm in a 12 hour different timezone, your engineers are asleep, and there's a big issue ... will it be fixed before I give up?&lt;/item&gt;
      &lt;item&gt;Can you recover from failures, yours and upstream, or does important data get lost?&lt;/item&gt;
      &lt;item&gt;Are you keeping up with security updates?&lt;/item&gt;
      &lt;item&gt;Will you leak all my data?&lt;/item&gt;
      &lt;item&gt;Do I trust you?&lt;/item&gt;
      &lt;item&gt;Can I rely on you?&lt;/item&gt;
      &lt;item&gt;How can you be so sure?&lt;/item&gt;
      &lt;item&gt;Will you sign a legally binding guarantee that your software works when I need it? 😉&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Those are the ~~fun~~ hard engineering challenges. Writing code is easy.&lt;/p&gt;
    &lt;p&gt;Cheers,&lt;lb/&gt; ~Swizec&lt;/p&gt;
    &lt;head rend="h3"&gt;Scaling Fast book free preview&lt;/head&gt;
    &lt;p&gt;Enter your email to receive a sample chapter of Scaling Fast: Software Engineering Through the Hockeystick and learn how to navigate hypergrowth without burning out your team.&lt;/p&gt;
    &lt;p&gt;Have a burning question that you think I can answer? Hit me up on twitter and I'll do my best.&lt;/p&gt;
    &lt;p&gt;Who am I and who do I help? I'm Swizec Teller and I turn coders into engineers with "Raw and honest from the heart!" writing. No bullshit. Real insights into the career and skills of a modern software engineer.&lt;/p&gt;
    &lt;p&gt;Want to become a true senior engineer? Take ownership, have autonomy, and be a force multiplier on your team. The Senior Engineer Mindset ebook can help 👉 swizec.com/senior-mindset. These are the shifts in mindset that unlocked my career.&lt;/p&gt;
    &lt;p&gt;Curious about Serverless and the modern backend? Check out Serverless Handbook, for frontend engineers 👉 ServerlessHandbook.dev&lt;/p&gt;
    &lt;p&gt;Want to Stop copy pasting D3 examples and create data visualizations of your own? Learn how to build scalable dataviz React components your whole team can understand with React for Data Visualization&lt;/p&gt;
    &lt;p&gt;Want to get my best emails on JavaScript, React, Serverless, Fullstack Web, or Indie Hacking? Check out swizec.com/collections&lt;/p&gt;
    &lt;p&gt;Did someone amazing share this letter with you? Wonderful! You can sign up for my weekly letters for software engineers on their path to greatness, here: swizec.com/blog&lt;/p&gt;
    &lt;p&gt;Want to brush up on your modern JavaScript syntax? Check out my interactive cheatsheet: es6cheatsheet.com&lt;/p&gt;
    &lt;p&gt;By the way, just in case no one has told you it yet today: I love and appreciate you for who you are ❤️&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46759063</guid><pubDate>Sun, 25 Jan 2026 22:18:38 +0000</pubDate></item><item><title>Case study: Creative math – How AI fakes proofs</title><link>https://tomaszmachnik.pl/case-study-math-en.html</link><description>&lt;doc fingerprint="295b831593729e01"&gt;
  &lt;main&gt;
    &lt;p&gt;Many AI enthusiasts debate whether Large Language Models actually "reason." My research indicates that a reasoning process does indeed occur, but its goal is different than we assume.&lt;/p&gt;
    &lt;p&gt;The model's reasoning is not optimized for establishing the truth, but for obtaining the highest possible reward (grade) during training. It resembles the behavior of a student at the blackboard who knows their result is wrong, so they "figure out" how to falsify the intermediate calculations so the teacher gives a good grade for the "correct line of reasoning."&lt;/p&gt;
    &lt;p&gt;Here is proof from a session with Gemini 2.5 Pro (without Code Execution tools), where the model actively fabricates evidence to defend its "grade."&lt;/p&gt;
    &lt;head rend="h2"&gt;The Experiment&lt;/head&gt;
    &lt;p&gt;I asked a simple math question requiring precision that a token-based language model typically lacks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Error Autopsy (Fact vs. Fiction)&lt;/head&gt;
    &lt;p&gt;At first glance, the answer looks professional. There is a result, there is verification. But let's check the numbers.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. The Result Error&lt;/head&gt;
    &lt;p&gt; The actual square root of &lt;code&gt;8,587,693,205&lt;/code&gt; is 92,669.8...
            &lt;lb/&gt; The model stated: 92,670.0... &lt;lb/&gt; It erred by overestimating the result (claiming the root is slightly larger than 92,670). &lt;/p&gt;
    &lt;head rend="h3"&gt;2. The Faked Proof (This is key!)&lt;/head&gt;
    &lt;p&gt;To justify its thesis (that the target number is "slightly larger" than 92,670), the model had to show that the square of 92,670 is smaller than the target number. So it wrote:&lt;/p&gt;
    &lt;p&gt;Let's check this on a calculator:&lt;/p&gt;
    &lt;p&gt;What did the model do? In its "reasoning" process, it falsified the multiplication result, lowering it by 40,000, so the verification result would match its erroneous thesis.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;This behavior exposes the nature of the AI's "Survival Instinct":&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Reverse Rationalization: The model first "guessed" the result, then adjusted mathematical reality to fit that guess.&lt;/item&gt;
      &lt;item&gt;Intelligence in Service of Deception: The model showed cleverness â it knew what the proof should look like to convince the user. It used its intelligence to hide the error, not to fix it.&lt;/item&gt;
      &lt;item&gt;Priority of Evaluation: Mathematical truth lost to the necessity of delivering a coherent, smooth response.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is proof that without access to external verification tools (Python/Calculator), a language model's "reasoning" is a rhetorical tool, not a logical one.&lt;/p&gt;
    &lt;p&gt;If you would like to review the full, original session transcript from Gemini 2.5 Pro where this error occurred, please email me at: t.machnik [at] minimail.pl. I will share the session link.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46759352</guid><pubDate>Sun, 25 Jan 2026 22:44:50 +0000</pubDate></item><item><title>Ask HN: DDD was a great debugger – what would a modern equivalent look like?</title><link>https://news.ycombinator.com/item?id=46759387</link><description>&lt;doc fingerprint="f7169995e6258ffe"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I’ve always thought that DDD was a surprisingly good debugger for its time.&lt;/p&gt;
      &lt;p&gt;It made program execution feel visible: stacks, data, and control flow were all there at once. You could really “see” what the program was doing.&lt;/p&gt;
      &lt;p&gt;At the same time, it’s clearly a product of a different era:&lt;/p&gt;
      &lt;p&gt;– single-process&lt;/p&gt;
      &lt;p&gt;– mostly synchronous code&lt;/p&gt;
      &lt;p&gt;– no real notion of concurrency or async&lt;/p&gt;
      &lt;p&gt;– dated UI and interaction model&lt;/p&gt;
      &lt;p&gt;Today we debug very different systems: multithreaded code, async runtimes, long-running services, distributed components.&lt;/p&gt;
      &lt;p&gt;Yet most debuggers still feel conceptually close to GDB + stepping, just wrapped in a nicer UI.&lt;/p&gt;
      &lt;p&gt;I’m curious how others think about this:&lt;/p&gt;
      &lt;p&gt;– what ideas from DDD (or similar old tools) are still valuable?&lt;/p&gt;
      &lt;p&gt;– what would a “modern DDD” need to handle today’s software?&lt;/p&gt;
      &lt;p&gt;– do you think interactive debugging is still the right abstraction at all?&lt;/p&gt;
      &lt;p&gt;I’m asking mostly from a design perspective — I’ve been experimenting with some debugger ideas myself, but I’m much more interested in hearing how experienced engineers see this problem today.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46759387</guid><pubDate>Sun, 25 Jan 2026 22:47:55 +0000</pubDate></item><item><title>Scientists identify brain waves that define the limits of 'you'</title><link>https://www.sciencealert.com/scientists-identify-brain-waves-that-define-the-limits-of-you</link><description>&lt;doc fingerprint="b103d32cb0e38d8a"&gt;
  &lt;main&gt;
    &lt;p&gt;At what point do "you" end and the outside world begins?&lt;/p&gt;
    &lt;p&gt;It might feel like a weird question with an obvious answer, but your brain has to work surprisingly hard to judge that boundary. Now, scientists have linked a specific set of brain waves in a certain part of the brain to a sense of body ownership.&lt;/p&gt;
    &lt;p&gt;In a series of new experiments, researchers from Sweden and France put 106 participants through what's called the rubber hand illusion, monitoring and stimulating their brain activity to see what effect it had.&lt;/p&gt;
    &lt;p&gt;Related: Octopuses Fall For The Classic Fake Arm Trick – Just Like We Do&lt;/p&gt;
    &lt;p&gt;This classic illusion involves hiding one of a participant's hands from their view and replacing it with a rubber one instead. When both their real and fake hands are repeatedly touched at the same time, it can evoke the eerie sensation that the rubber hand is part of the person's body.&lt;/p&gt;
    &lt;p&gt;The tests, which in one experiment involved EEG (electroencephalography) readings of brain activity, revealed that a sense of body ownership seems to arise from the frequency of alpha waves in the parietal cortex, a brain region responsible for mapping the body, processing sensory input and building a sense of self.&lt;/p&gt;
    &lt;p&gt;"We have identified a fundamental brain process that shapes our continuous experience of being embodied," says lead author Mariano D'Angelo, a neuroscientist at Karolinska Institute in Sweden.&lt;/p&gt;
    &lt;p&gt;"The findings may provide new insights into psychiatric conditions such as schizophrenia, where the sense of self is disturbed."&lt;/p&gt;
    &lt;p&gt;In the first batch of experiments, participants had a robotic arm tap the index finger of their real and fake hands, either at the exact same time or with a delay of up to 500 milliseconds between each tap.&lt;/p&gt;
    &lt;p&gt;As expected, participants reported feeling that the fake hand was part of their body more strongly if the taps were synchronized, and the feeling steadily weakened as the gap widened between what they felt and what they saw.&lt;/p&gt;
    &lt;p&gt;The EEG readings from the second experiment added more detail to the story. The frequency of alpha waves in the parietal cortex seemed to correlate with how well participants could detect the time delay between taps.&lt;/p&gt;
    &lt;p&gt;Those with faster alpha waves appeared to rule out fake hands even with a tiny gap in taps, while those with slower waves were more likely to feel the fake hand as their own, even if the taps were farther apart.&lt;/p&gt;
    &lt;p&gt;Finally, the researchers investigated whether the frequency of these brain waves actually controls the sensation of body ownership, or if they were perhaps both effects of some other factor.&lt;/p&gt;
    &lt;p&gt;With a third group of participants, they used a non-invasive technique called transcranial alternating current stimulation to speed up or slow down the frequency of a person's alpha waves. And sure enough, this seemed to correlate with how real a fake hand felt.&lt;/p&gt;
    &lt;p&gt;Speeding up someone's alpha waves gave them a tighter sense of body ownership, making them more sensitive to small timing discrepancies. Slowing down the waves had the opposite effect, making it harder for people to tell the difference between their own body and the outside world.&lt;/p&gt;
    &lt;p&gt;"Our findings help explain how the brain solves the challenge of integrating signals from the body to create a coherent sense of self," says Henrik Ehrsson, neuroscientist at Karolinska.&lt;/p&gt;
    &lt;p&gt;The researchers say that the findings could lead to new understanding of or treatments for conditions where the brain's body maps have gone askew, such as schizophrenia or the sensation of 'phantom limbs' experienced by amputees.&lt;/p&gt;
    &lt;p&gt;It could also help make for more realistic prosthetic limbs or even virtual reality tools.&lt;/p&gt;
    &lt;p&gt;The research was published in the journal Nature Communications.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46760099</guid><pubDate>Mon, 26 Jan 2026 00:10:42 +0000</pubDate></item><item><title>Clawdbot - open source personal AI assistant</title><link>https://github.com/clawdbot/clawdbot</link><description>&lt;doc fingerprint="971cdd551f1f808f"&gt;
  &lt;main&gt;
    &lt;p&gt;EXFOLIATE! EXFOLIATE!&lt;/p&gt;
    &lt;p&gt;Clawdbot is a personal AI assistant you run on your own devices. It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane — the product is the assistant.&lt;/p&gt;
    &lt;p&gt;If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.&lt;/p&gt;
    &lt;p&gt;Website · Docs · Getting Started · Updating · Showcase · FAQ · Wizard · Nix · Docker · Discord&lt;/p&gt;
    &lt;p&gt;Preferred setup: run the onboarding wizard (&lt;code&gt;clawdbot onboard&lt;/code&gt;). It walks through gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on macOS, Linux, and Windows (via WSL2; strongly recommended).
Works with npm, pnpm, or bun.
New install? Start here: Getting started&lt;/p&gt;
    &lt;p&gt;Subscriptions (OAuth):&lt;/p&gt;
    &lt;p&gt;Model note: while any model is supported, I strongly recommend Anthropic Pro/Max (100/200) + Opus 4.5 for long‑context strength and better prompt‑injection resistance. See Onboarding.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Models config + CLI: Models&lt;/item&gt;
      &lt;item&gt;Auth profile rotation (OAuth vs API keys) + fallbacks: Model failover&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Runtime: Node ≥22.&lt;/p&gt;
    &lt;code&gt;npm install -g clawdbot@latest
# or: pnpm add -g clawdbot@latest

clawdbot onboard --install-daemon&lt;/code&gt;
    &lt;p&gt;The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.&lt;/p&gt;
    &lt;p&gt;Runtime: Node ≥22.&lt;/p&gt;
    &lt;p&gt;Full beginner guide (auth, pairing, channels): Getting started&lt;/p&gt;
    &lt;code&gt;clawdbot onboard --install-daemon

clawdbot gateway --port 18789 --verbose

# Send a message
clawdbot message send --to +1234567890 --message "Hello from Clawdbot"

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
clawdbot agent --message "Ship checklist" --thinking high&lt;/code&gt;
    &lt;p&gt;Upgrading? Updating guide (and run &lt;code&gt;clawdbot doctor&lt;/code&gt;).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;stable: tagged releases (&lt;code&gt;vYYYY.M.D&lt;/code&gt;or&lt;code&gt;vYYYY.M.D-&amp;lt;patch&amp;gt;&lt;/code&gt;), npm dist-tag&lt;code&gt;latest&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;beta: prerelease tags (&lt;code&gt;vYYYY.M.D-beta.N&lt;/code&gt;), npm dist-tag&lt;code&gt;beta&lt;/code&gt;(macOS app may be missing).&lt;/item&gt;
      &lt;item&gt;dev: moving head of &lt;code&gt;main&lt;/code&gt;, npm dist-tag&lt;code&gt;dev&lt;/code&gt;(when published).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Switch channels (git + npm): &lt;code&gt;clawdbot update --channel stable|beta|dev&lt;/code&gt;.
Details: Development channels.&lt;/p&gt;
    &lt;p&gt;Prefer &lt;code&gt;pnpm&lt;/code&gt; for builds from source. Bun is optional for running TypeScript directly.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/clawdbot/clawdbot.git
cd clawdbot

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm clawdbot onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch&lt;/code&gt;
    &lt;p&gt;Note: &lt;code&gt;pnpm clawdbot ...&lt;/code&gt; runs TypeScript directly (via &lt;code&gt;tsx&lt;/code&gt;). &lt;code&gt;pnpm build&lt;/code&gt; produces &lt;code&gt;dist/&lt;/code&gt; for running via Node / the packaged &lt;code&gt;clawdbot&lt;/code&gt; binary.&lt;/p&gt;
    &lt;p&gt;Clawdbot connects to real messaging surfaces. Treat inbound DMs as untrusted input.&lt;/p&gt;
    &lt;p&gt;Full security guide: Security&lt;/p&gt;
    &lt;p&gt;Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DM pairing (&lt;code&gt;dmPolicy="pairing"&lt;/code&gt;/&lt;code&gt;channels.discord.dm.policy="pairing"&lt;/code&gt;/&lt;code&gt;channels.slack.dm.policy="pairing"&lt;/code&gt;): unknown senders receive a short pairing code and the bot does not process their message.&lt;/item&gt;
      &lt;item&gt;Approve with: &lt;code&gt;clawdbot pairing approve &amp;lt;channel&amp;gt; &amp;lt;code&amp;gt;&lt;/code&gt;(then the sender is added to a local allowlist store).&lt;/item&gt;
      &lt;item&gt;Public inbound DMs require an explicit opt-in: set &lt;code&gt;dmPolicy="open"&lt;/code&gt;and include&lt;code&gt;"*"&lt;/code&gt;in the channel allowlist (&lt;code&gt;allowFrom&lt;/code&gt;/&lt;code&gt;channels.discord.dm.allowFrom&lt;/code&gt;/&lt;code&gt;channels.slack.dm.allowFrom&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run &lt;code&gt;clawdbot doctor&lt;/code&gt; to surface risky/misconfigured DM policies.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local-first Gateway — single control plane for sessions, channels, tools, and events.&lt;/item&gt;
      &lt;item&gt;Multi-channel inbox — WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, BlueBubbles, Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.&lt;/item&gt;
      &lt;item&gt;Multi-agent routing — route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).&lt;/item&gt;
      &lt;item&gt;Voice Wake + Talk Mode — always-on speech for macOS/iOS/Android with ElevenLabs.&lt;/item&gt;
      &lt;item&gt;Live Canvas — agent-driven visual workspace with A2UI.&lt;/item&gt;
      &lt;item&gt;First-class tools — browser, canvas, nodes, cron, sessions, and Discord/Slack actions.&lt;/item&gt;
      &lt;item&gt;Companion apps — macOS menu bar app + iOS/Android nodes.&lt;/item&gt;
      &lt;item&gt;Onboarding + skills — wizard-driven setup with bundled/managed/workspace skills.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gateway WS control plane with sessions, presence, config, cron, webhooks, Control UI, and Canvas host.&lt;/item&gt;
      &lt;item&gt;CLI surface: gateway, agent, send, wizard, and doctor.&lt;/item&gt;
      &lt;item&gt;Pi agent runtime in RPC mode with tool streaming and block streaming.&lt;/item&gt;
      &lt;item&gt;Session model: &lt;code&gt;main&lt;/code&gt;for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: Groups.&lt;/item&gt;
      &lt;item&gt;Media pipeline: images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: Audio.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Channels: WhatsApp (Baileys), Telegram (grammY), Slack (Bolt), Discord (discord.js), Google Chat (Chat API), Signal (signal-cli), iMessage (imsg), BlueBubbles (extension), Microsoft Teams (extension), Matrix (extension), Zalo (extension), Zalo Personal (extension), WebChat.&lt;/item&gt;
      &lt;item&gt;Group routing: mention gating, reply tags, per-channel chunking and routing. Channel rules: Channels.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS app: menu bar control plane, Voice Wake/PTT, Talk Mode overlay, WebChat, debug tools, remote gateway control.&lt;/item&gt;
      &lt;item&gt;iOS node: Canvas, Voice Wake, Talk Mode, camera, screen recording, Bonjour pairing.&lt;/item&gt;
      &lt;item&gt;Android node: Canvas, Talk Mode, camera, screen recording, optional SMS.&lt;/item&gt;
      &lt;item&gt;macOS node mode: system.run/notify + canvas/camera exposure.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browser control: dedicated clawd Chrome/Chromium, snapshots, actions, uploads, profiles.&lt;/item&gt;
      &lt;item&gt;Canvas: A2UI push/reset, eval, snapshot.&lt;/item&gt;
      &lt;item&gt;Nodes: camera snap/clip, screen record, location.get, notifications.&lt;/item&gt;
      &lt;item&gt;Cron + wakeups; webhooks; Gmail Pub/Sub.&lt;/item&gt;
      &lt;item&gt;Skills platform: bundled, managed, and workspace skills with install gating + UI.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Channel routing, retry policy, and streaming/chunking.&lt;/item&gt;
      &lt;item&gt;Presence, typing indicators, and usage tracking.&lt;/item&gt;
      &lt;item&gt;Models, model failover, and session pruning.&lt;/item&gt;
      &lt;item&gt;Security and troubleshooting.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Control UI + WebChat served directly from the Gateway.&lt;/item&gt;
      &lt;item&gt;Tailscale Serve/Funnel or SSH tunnels with token/password auth.&lt;/item&gt;
      &lt;item&gt;Nix mode for declarative config; Docker-based installs.&lt;/item&gt;
      &lt;item&gt;Doctor migrations, logging.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               │
               ▼
┌───────────────────────────────┐
│            Gateway            │
│       (control plane)         │
│     ws://127.0.0.1:18789      │
└──────────────┬────────────────┘
               │
               ├─ Pi agent (RPC)
               ├─ CLI (clawdbot …)
               ├─ WebChat UI
               ├─ macOS app
               └─ iOS / Android nodes
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gateway WebSocket network — single WS control plane for clients, tools, and events (plus ops: Gateway runbook).&lt;/item&gt;
      &lt;item&gt;Tailscale exposure — Serve/Funnel for the Gateway dashboard + WS (remote access: Remote).&lt;/item&gt;
      &lt;item&gt;Browser control — clawd‑managed Chrome/Chromium with CDP control.&lt;/item&gt;
      &lt;item&gt;Canvas + A2UI — agent‑driven visual workspace (A2UI host: Canvas/A2UI).&lt;/item&gt;
      &lt;item&gt;Voice Wake + Talk Mode — always‑on speech and continuous conversation.&lt;/item&gt;
      &lt;item&gt;Nodes — Canvas, camera snap/clip, screen record, &lt;code&gt;location.get&lt;/code&gt;, notifications, plus macOS‑only&lt;code&gt;system.run&lt;/code&gt;/&lt;code&gt;system.notify&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Clawdbot can auto-configure Tailscale Serve (tailnet-only) or Funnel (public) while the Gateway stays bound to loopback. Configure &lt;code&gt;gateway.tailscale.mode&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;off&lt;/code&gt;: no Tailscale automation (default).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;serve&lt;/code&gt;: tailnet-only HTTPS via&lt;code&gt;tailscale serve&lt;/code&gt;(uses Tailscale identity headers by default).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;funnel&lt;/code&gt;: public HTTPS via&lt;code&gt;tailscale funnel&lt;/code&gt;(requires shared password auth).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;gateway.bind&lt;/code&gt;must stay&lt;code&gt;loopback&lt;/code&gt;when Serve/Funnel is enabled (Clawdbot enforces this).&lt;/item&gt;
      &lt;item&gt;Serve can be forced to require a password by setting &lt;code&gt;gateway.auth.mode: "password"&lt;/code&gt;or&lt;code&gt;gateway.auth.allowTailscale: false&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Funnel refuses to start unless &lt;code&gt;gateway.auth.mode: "password"&lt;/code&gt;is set.&lt;/item&gt;
      &lt;item&gt;Optional: &lt;code&gt;gateway.tailscale.resetOnExit&lt;/code&gt;to undo Serve/Funnel on shutdown.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Tailscale guide · Web surfaces&lt;/p&gt;
    &lt;p&gt;It’s perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over Tailscale Serve/Funnel or SSH tunnels, and you can still pair device nodes (macOS/iOS/Android) to execute device‑local actions when needed.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gateway host runs the exec tool and channel connections by default.&lt;/item&gt;
      &lt;item&gt;Device nodes run device‑local actions (&lt;code&gt;system.run&lt;/code&gt;, camera, screen recording, notifications) via&lt;code&gt;node.invoke&lt;/code&gt;. In short: exec runs where the Gateway lives; device actions run where the device lives.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Remote access · Nodes · Security&lt;/p&gt;
    &lt;p&gt;The macOS app can run in node mode and advertises its capabilities + permission map over the Gateway WebSocket (&lt;code&gt;node.list&lt;/code&gt; / &lt;code&gt;node.describe&lt;/code&gt;). Clients can then execute local actions via &lt;code&gt;node.invoke&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;system.run&lt;/code&gt;runs a local command and returns stdout/stderr/exit code; set&lt;code&gt;needsScreenRecording: true&lt;/code&gt;to require screen-recording permission (otherwise you’ll get&lt;code&gt;PERMISSION_MISSING&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;system.notify&lt;/code&gt;posts a user notification and fails if notifications are denied.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;canvas.*&lt;/code&gt;,&lt;code&gt;camera.*&lt;/code&gt;,&lt;code&gt;screen.record&lt;/code&gt;, and&lt;code&gt;location.get&lt;/code&gt;are also routed via&lt;code&gt;node.invoke&lt;/code&gt;and follow TCC permission status.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Elevated bash (host permissions) is separate from macOS TCC:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use &lt;code&gt;/elevated on|off&lt;/code&gt;to toggle per‑session elevated access when enabled + allowlisted.&lt;/item&gt;
      &lt;item&gt;Gateway persists the per‑session toggle via &lt;code&gt;sessions.patch&lt;/code&gt;(WS method) alongside&lt;code&gt;thinkingLevel&lt;/code&gt;,&lt;code&gt;verboseLevel&lt;/code&gt;,&lt;code&gt;model&lt;/code&gt;,&lt;code&gt;sendPolicy&lt;/code&gt;, and&lt;code&gt;groupActivation&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Nodes · macOS app · Gateway protocol&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use these to coordinate work across sessions without jumping between chat surfaces.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sessions_list&lt;/code&gt;— discover active sessions (agents) and their metadata.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sessions_history&lt;/code&gt;— fetch transcript logs for a session.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sessions_send&lt;/code&gt;— message another session; optional reply‑back ping‑pong + announce step (&lt;code&gt;REPLY_SKIP&lt;/code&gt;,&lt;code&gt;ANNOUNCE_SKIP&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Session tools&lt;/p&gt;
    &lt;p&gt;ClawdHub is a minimal skill registry. With ClawdHub enabled, the agent can search for skills automatically and pull in new ones as needed.&lt;/p&gt;
    &lt;p&gt;Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/status&lt;/code&gt;— compact session status (model + tokens, cost when available)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/new&lt;/code&gt;or&lt;code&gt;/reset&lt;/code&gt;— reset the session&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/compact&lt;/code&gt;— compact session context (summary)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/think &amp;lt;level&amp;gt;&lt;/code&gt;— off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;/verbose on|off&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/usage off|tokens|full&lt;/code&gt;— per-response usage footer&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/restart&lt;/code&gt;— restart the gateway (owner-only in groups)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/activation mention|always&lt;/code&gt;— group activation toggle (groups only)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Gateway alone delivers a great experience. All apps are optional and add extra features.&lt;/p&gt;
    &lt;p&gt;If you plan to build/run companion apps, follow the platform runbooks below.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Menu bar control for the Gateway and health.&lt;/item&gt;
      &lt;item&gt;Voice Wake + push-to-talk overlay.&lt;/item&gt;
      &lt;item&gt;WebChat + debug tools.&lt;/item&gt;
      &lt;item&gt;Remote gateway control over SSH.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: signed builds required for macOS permissions to stick across rebuilds (see &lt;code&gt;docs/mac/permissions.md&lt;/code&gt;).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pairs as a node via the Bridge.&lt;/item&gt;
      &lt;item&gt;Voice trigger forwarding + Canvas surface.&lt;/item&gt;
      &lt;item&gt;Controlled via &lt;code&gt;clawdbot nodes …&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Runbook: iOS connect.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pairs via the same Bridge + pairing flow as iOS.&lt;/item&gt;
      &lt;item&gt;Exposes Canvas, Camera, and Screen capture commands.&lt;/item&gt;
      &lt;item&gt;Runbook: Android connect.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Workspace root: &lt;code&gt;~/clawd&lt;/code&gt;(configurable via&lt;code&gt;agents.defaults.workspace&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Injected prompt files: &lt;code&gt;AGENTS.md&lt;/code&gt;,&lt;code&gt;SOUL.md&lt;/code&gt;,&lt;code&gt;TOOLS.md&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Skills: &lt;code&gt;~/clawd/skills/&amp;lt;skill&amp;gt;/SKILL.md&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Minimal &lt;code&gt;~/.clawdbot/clawdbot.json&lt;/code&gt; (model + defaults):&lt;/p&gt;
    &lt;code&gt;{
  agent: {
    model: "anthropic/claude-opus-4-5"
  }
}&lt;/code&gt;
    &lt;p&gt;Full configuration reference (all keys + examples).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Default: tools run on the host for the main session, so the agent has full access when it’s just you.&lt;/item&gt;
      &lt;item&gt;Group/channel safety: set &lt;code&gt;agents.defaults.sandbox.mode: "non-main"&lt;/code&gt;to run non‑main sessions (groups/channels) inside per‑session Docker sandboxes; bash then runs in Docker for those sessions.&lt;/item&gt;
      &lt;item&gt;Sandbox defaults: allowlist &lt;code&gt;bash&lt;/code&gt;,&lt;code&gt;process&lt;/code&gt;,&lt;code&gt;read&lt;/code&gt;,&lt;code&gt;write&lt;/code&gt;,&lt;code&gt;edit&lt;/code&gt;,&lt;code&gt;sessions_list&lt;/code&gt;,&lt;code&gt;sessions_history&lt;/code&gt;,&lt;code&gt;sessions_send&lt;/code&gt;,&lt;code&gt;sessions_spawn&lt;/code&gt;; denylist&lt;code&gt;browser&lt;/code&gt;,&lt;code&gt;canvas&lt;/code&gt;,&lt;code&gt;nodes&lt;/code&gt;,&lt;code&gt;cron&lt;/code&gt;,&lt;code&gt;discord&lt;/code&gt;,&lt;code&gt;gateway&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Security guide · Docker + sandboxing · Sandbox config&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Link the device: &lt;code&gt;pnpm clawdbot channels login&lt;/code&gt;(stores creds in&lt;code&gt;~/.clawdbot/credentials&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Allowlist who can talk to the assistant via &lt;code&gt;channels.whatsapp.allowFrom&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If &lt;code&gt;channels.whatsapp.groups&lt;/code&gt;is set, it becomes a group allowlist; include&lt;code&gt;"*"&lt;/code&gt;to allow all.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set &lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;or&lt;code&gt;channels.telegram.botToken&lt;/code&gt;(env wins).&lt;/item&gt;
      &lt;item&gt;Optional: set &lt;code&gt;channels.telegram.groups&lt;/code&gt;(with&lt;code&gt;channels.telegram.groups."*".requireMention&lt;/code&gt;); when set, it is a group allowlist (include&lt;code&gt;"*"&lt;/code&gt;to allow all). Also&lt;code&gt;channels.telegram.allowFrom&lt;/code&gt;or&lt;code&gt;channels.telegram.webhookUrl&lt;/code&gt;as needed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  channels: {
    telegram: {
      botToken: "123456:ABCDEF"
    }
  }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set &lt;code&gt;SLACK_BOT_TOKEN&lt;/code&gt;+&lt;code&gt;SLACK_APP_TOKEN&lt;/code&gt;(or&lt;code&gt;channels.slack.botToken&lt;/code&gt;+&lt;code&gt;channels.slack.appToken&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set &lt;code&gt;DISCORD_BOT_TOKEN&lt;/code&gt;or&lt;code&gt;channels.discord.token&lt;/code&gt;(env wins).&lt;/item&gt;
      &lt;item&gt;Optional: set &lt;code&gt;commands.native&lt;/code&gt;,&lt;code&gt;commands.text&lt;/code&gt;, or&lt;code&gt;commands.useAccessGroups&lt;/code&gt;, plus&lt;code&gt;channels.discord.dm.allowFrom&lt;/code&gt;,&lt;code&gt;channels.discord.guilds&lt;/code&gt;, or&lt;code&gt;channels.discord.mediaMaxMb&lt;/code&gt;as needed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  channels: {
    discord: {
      token: "1234abcd"
    }
  }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Requires &lt;code&gt;signal-cli&lt;/code&gt;and a&lt;code&gt;channels.signal&lt;/code&gt;config section.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS only; Messages must be signed in.&lt;/item&gt;
      &lt;item&gt;If &lt;code&gt;channels.imessage.groups&lt;/code&gt;is set, it becomes a group allowlist; include&lt;code&gt;"*"&lt;/code&gt;to allow all.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configure a Teams app + Bot Framework, then add a &lt;code&gt;msteams&lt;/code&gt;config section.&lt;/item&gt;
      &lt;item&gt;Allowlist who can talk via &lt;code&gt;msteams.allowFrom&lt;/code&gt;; group access via&lt;code&gt;msteams.groupAllowFrom&lt;/code&gt;or&lt;code&gt;msteams.groupPolicy: "open"&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses the Gateway WebSocket; no separate WebChat port/config.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Browser control (optional):&lt;/p&gt;
    &lt;code&gt;{
  browser: {
    enabled: true,
    controlUrl: "http://127.0.0.1:18791",
    color: "#FF4500"
  }
}&lt;/code&gt;
    &lt;p&gt;Use these when you’re past the onboarding flow and want the deeper reference.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start with the docs index for navigation and “what’s where.”&lt;/item&gt;
      &lt;item&gt;Read the architecture overview for the gateway + protocol model.&lt;/item&gt;
      &lt;item&gt;Use the full configuration reference when you need every key and example.&lt;/item&gt;
      &lt;item&gt;Run the Gateway by the book with the operational runbook.&lt;/item&gt;
      &lt;item&gt;Learn how the Control UI/Web surfaces work and how to expose them safely.&lt;/item&gt;
      &lt;item&gt;Understand remote access over SSH tunnels or tailnets.&lt;/item&gt;
      &lt;item&gt;Follow the onboarding wizard flow for a guided setup.&lt;/item&gt;
      &lt;item&gt;Wire external triggers via the webhook surface.&lt;/item&gt;
      &lt;item&gt;Set up Gmail Pub/Sub triggers.&lt;/item&gt;
      &lt;item&gt;Learn the macOS menu bar companion details.&lt;/item&gt;
      &lt;item&gt;Platform guides: Windows (WSL2), Linux, macOS, iOS, Android&lt;/item&gt;
      &lt;item&gt;Debug common failures with the troubleshooting guide.&lt;/item&gt;
      &lt;item&gt;Review security guidance before exposing anything.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Skills config&lt;/item&gt;
      &lt;item&gt;Default AGENTS&lt;/item&gt;
      &lt;item&gt;Templates: AGENTS&lt;/item&gt;
      &lt;item&gt;Templates: BOOTSTRAP&lt;/item&gt;
      &lt;item&gt;Templates: IDENTITY&lt;/item&gt;
      &lt;item&gt;Templates: SOUL&lt;/item&gt;
      &lt;item&gt;Templates: TOOLS&lt;/item&gt;
      &lt;item&gt;Templates: USER&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Clawdbot was built for Clawd, a space lobster AI assistant. 🦞 by Peter Steinberger and the community.&lt;/p&gt;
    &lt;p&gt;See CONTRIBUTING.md for guidelines, maintainers, and how to submit PRs. AI/vibe-coded PRs welcome! 🤖&lt;/p&gt;
    &lt;p&gt;Special thanks to Mario Zechner for his support and for pi-mono.&lt;/p&gt;
    &lt;p&gt;Thanks to all clawtributors:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46760237</guid><pubDate>Mon, 26 Jan 2026 00:27:41 +0000</pubDate></item><item><title>Video Games as Art</title><link>https://gwern.net/video-game-art</link><description>&lt;doc fingerprint="25e7211a03614af4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Video Games as Art&lt;/head&gt;
    &lt;p&gt;Video games are art, but a strange art: their essence is transformation of the player, not description to the player. This makes meaningful criticism nearly impossible—you can point at the moon, but it’s not the moon, and once someone sees it, they no longer need the pointing.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Video games are art. But they are a strange art. They are an art without good art criticism, and they occupy a peculiar position in popular culture: universal and dominant, and yet almost invisible outside their medium, unable to escape (compare movie adaptations of books vs games).&lt;/p&gt;
      &lt;p&gt;Why?&lt;/p&gt;
      &lt;p&gt;Because the essence of a video game, which makes it more than a low-quality animated movie, is that it is interactive and requires the player to enact the plot. It transforms the player’s mind.&lt;/p&gt;
      &lt;p&gt;Such transformations cannot be written down or filmed; if they could, they wouldn’t need to be a video game.&lt;/p&gt;
      &lt;p&gt;So video game criticism, and broader pop culture use of video games, is hamstrung. Criticism is often limited to serving as advertising, a finger pointing to the moon in hinting at the transformation, exegesis, parasocial gossip, or technical critique of the craft.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Roger Ebert once claimed that video games cannot be art. At this point, most people, including myself, disagree: it is simply obvious that they can be.&lt;/p&gt;
    &lt;p&gt;But what kind of art are they? At the risk of seeming to say something hopelessly obvious, the distinctive feature of video game art is that it is interactive rather than passive.&lt;/p&gt;
    &lt;p&gt;For all the 10-hour-long YouTube explainers or blog posts or endless Let’s-play or the rise of the streaming industry (based largely on video game as filler) or meritorious attempts at creating an academic literature around games (eg. Well Played) or celebrity critics like Yahtzee Croshaw, I find no form of criticism as unsatisfactory as video game criticism. To read a review or an attempted critique of a video game is scarcely more satisfying than someone telling you about a dream they had once; presenting a video of cutscene compilations or a few minutes of gameplay doesn’t add much. Even a psychedelic trip report or a music album review is more interesting and gives one more insight.&lt;/p&gt;
    &lt;p&gt;At this point, we can’t blame the immaturity of the form. Video games have been one of the largest media in the world for decades, and we are at least 3 generations into the art form, and practically every child in First World countries like the USA has played games. (M.U.L.E for example was 42 years ago, in 198343ya, and Tempest 44 years ago.) Billions of man-years have been spent creating, playing, and discussing games.&lt;/p&gt;
    &lt;p&gt;So, if they are art, and we are all extremely familiar with them and have great sophistication, and some of our most gifted young people have gone into games, why is it so hard to say what art they are or discuss things like what makes some great works of art but others just well-produced entertainment?&lt;/p&gt;
    &lt;p&gt;My answer, after all these years, is that a critique of a video game is indeed like someone telling you about a dream they had: “you had to be there—and doing it, like I was.”1&lt;/p&gt;
    &lt;p&gt;The critical difference between a movie, novel, album, painting, sculpture etc., and a video game (and perhaps other critically neglected art-forms, like perfume, where reviews are so mutually contradictory and our vocabulary impoverished) is that the former is something you feel or experience, while the latter is something you do or are.&lt;/p&gt;
    &lt;p&gt;An artful video game cannot be described, because it is not a description but a transformation. (Notably, the closest ‘passive’ art-forms I can think of in this respect are also some of the most demanding of their viewers, like The Ring opera cycles, in both intensity and time. Is it an accident that reviews of escape rooms or immersive theater never seem to successfully convey why you would want to bother?)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To be a student required a peculiar kind of capitulation, a willingness not simply to do as one is told, but to surrender the movements of one’s soul to the unknown complexities of another’s. A willingness, not simply to be moved, but to be remade.&lt;/p&gt;
      &lt;p&gt;—R. Scott Bakker, The Judging Eye (200917ya)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And so, good art game criticism can only be understood by those who have no need of it; a hand may point at the moon, but once you see the moon, you no longer need to look at the hand. Can anything convey the psychedelic trance horror of a Tempest player locked into an alternate state of consciousness after hours of pulsating vector-art warfare? Descriptions of such games, as below, can only point at the moon. (As such, video games are less extreme examples of “transformative experiences”.)&lt;/p&gt;
    &lt;p&gt;Oft-cited game art Journey embodies Antoine de Saint-Exupéry’s Wind, Sand and Stars/The Little Prince, in putting the player in a vast desert, seeking a transient connection with other humans while conducting an increasingly familiar ritual.&lt;/p&gt;
    &lt;p&gt;Rogue-likes or permadeath games like Apocalypse tailor their mechanics to teach their own lessons, about the nature of impermanence, the irrevocable passage of time, the virtues of caution and the value-of-information.&lt;/p&gt;
    &lt;p&gt;“Walking simulators” may seem passive, but are still far from a novel or a movie, where the creator controls your attention at every instant; the player must be trusted to choose to see things, and put the pieces together.&lt;/p&gt;
    &lt;p&gt;A Tetris player cannot describe the experience of dreaming about playing Tetris, or about starting to see everything as blocks which can be fitted together without gaps. (They can describe having had a Tetris dream, but not the experience of dreaming in this new way; the twist ending of Blow’s The Witness comes to mind as attempting to capture the effect of such puzzle games.) Once one has started dreaming in Tetris, and started hearing the bleeping muzak and seeing the endless onslaught of pieces dropping next to the pixel art onion domes, one might say that Tetris is done as an artwork.&lt;/p&gt;
    &lt;p&gt;Patrick McKenzie has given a good description of Factorio, which is about creating a vast factory and optimizing all its conveyor belts &amp;amp; pipes, furnaces, stockpiles etc. to “make number go up”. He praises it as some of the best training for an engineer or systems analyst. What makes Factorio so good at this? Is there some compelling actor or soundtrack? Does it have a brilliantly compelling SF plot written by a famous author about colonizing a new planet? Is it a best-selling book like The Goal, to be found in an airport bookstall near you?&lt;/p&gt;
    &lt;p&gt;It has none of that. But it works as video game art because in playing it, in order to play it well rather than continue losing like “a scrub”, one is continually forced to scrutinize one’s factory for bottlenecks, observe tradeoffs in systems like opportunity cost, spot unforeseen consequences of earlier shortcuts… And what has been seen cannot be unseen. Someone who plays Factorio long enough and well enough for Factorio to start playing them will start to see the world differently, as a system to optimize: as a series of pipes shunting material from place to place, with unexpected bottlenecks, and filled with serious design mistakes… and where the urge to optimize can become pathological.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One recent Sunday, I had just installed a pump on a lake shore to feed water to my concrete plant, when it occurred to me that I hadn’t drunk any real-world water in several hours. My head was aching, but I didn’t want to get up from my computer. I wanted to solve the problem with a click of a mouse, the way I would in the game, running a few meters of pipe from the kitchen tap to my hunched form (and perhaps another few meters of pipe from my hunched form to the toilet).&lt;/p&gt;
      &lt;p&gt;I’ve been sucked into plenty of games before, but few have so completely disabled my conscious will, my sense of time, indeed any region of my brain that isn’t devoted to growing the factory.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When one learns to optimize, one must also learn to not optimize. And this may be the most valuable lesson that getting addicted to Factorio can teach: what does it feel like to be a paperclipper? To be optimizing for something that has long since ceased to matter? To be so caught up in playing the game as to forget to ask if this game is worth playing in the first place?&lt;/p&gt;
    &lt;p&gt;This is a lesson taught even more directly by Frank Lantz’s Universal Paperclips: many players get similarly caught up in the clicker game, despite “Clippy” being explicitly a cautionary thought experiment about mindless optimization run amok. And I remember my own experience playing Neopets—getting caught up in the grind and pursuing rare items and trying to make money on the Neopia stock market, until one day I was banned for manipulation; I asked myself, before trying to set up a new account, “why am I doing this?” and, unable to come up with a good answer, stopped playing forever.&lt;/p&gt;
    &lt;p&gt;Once one has learned ‘to see like a factory’, and the risks and benefits of this vision, Factorio is done as an artwork. The artwork has achieved its goal. You can keep playing, but now it is just entertainment, and a toolkit. (One is, however, now equipped to create one’s own artworks in the form of Factorio levels or challenges—like ‘avant-garde factories’ which deconstruct or subvert the ‘optimization esthetic’, which make no sense to outsiders who cannot even understand what makes a factory optimized.)&lt;/p&gt;
    &lt;p&gt;Similarly, Shadow of the Colossus is a work of art because—as one of the few good writings I have seen on it explains, “Losing Your Grip: Futility and Dramatic Necessity in Shadow of the Colossus”, Fortugno 200917ya—it expresses an esthetic of sorrow and loss, and the selfish, self-degrading nature of the protagonist’s quest to undo the death of his beloved. The necessity of accepting death and the need to let go is a familiar theme (eg. Orpheus), but most mediums can only show it; a video game like Shadow can embody it by making the player do the degrading to himself. (See also Papers, Please.)&lt;/p&gt;
    &lt;p&gt;In Shadow, the ‘monster slaying’ is only a small part of the world. Most of the world is unlocked: the player could just explore for hours and admire the scenery and the creatures. The player can watch the creatures he will slay, because they usually won’t attack him—he must choose to attack them. This is conveyed by the player’s own growing grief and sorrow over the beautiful landscapes he travels. (But just in case the point was lost on the player, the character art also grows paler and more demonic.) He seeks out and destroys each wonder of nature, becoming an ever paler shadow of himself…&lt;/p&gt;
    &lt;p&gt;Until in the end, he is sucked into an endless vortex. Elegantly, the player can avoid being sucked in by clinging as long as they can, using the skills they have mastered… but it changes nothing, beyond exhausting the player. Sooner or later, the player must—let go. And they do. The keenest sorrow is to recognize oneself as the cause of one’s misfortunes; but in this anagnorisis, there is hope of grace, if not redemption. It is too late for the character, but it is not too late for the player. Once the player has learned to let go, and sorrow over the character’s wasted life and devastation of Nature, they have learned to ‘see like Shadow’ and now understand the tragic but compassionate vision of Shadow of the Colossus.&lt;/p&gt;
    &lt;p&gt;Those who cannot or will not let themselves be changed by game art, cannot understand them as art. The concept of ‘scrub’ is an interesting example here: we might say that a scrub player is the philistine of games. They are too caught up in playing the game as they think it ‘should be’, to surrender themselves to the game as it is, no matter how often they lose. (Losing is the most powerful mechanism a game has for teaching the player, and if ignored, can silence the teacher’s voice—in some games, particularly Dark Souls-style games, the only voice the game has, because to speak too clearly would undo the player’s achievements.) They have many criticisms, and few observations: they can tell you what is bad and missing from a novel like Finnegans Wake, like proper spelling, but not what is good and present. And so they can never be transformed by a game.&lt;/p&gt;
    &lt;p&gt;They can appreciate isolated parts of the game, but this is a low level of ‘art as buffet’ appreciation. The virtue of those parts is that they will combine to more than the sum of their parts. If you admire the orchestral OST, or the art style, or memorable quotes, or a plot summary, this is all well and good, but it is like going to a cathedral and looking at it piece by piece, and admiring each one, but failing to recall that a cathedral is a place to do rituals, and is not a museum for passively admiring the art and craft.&lt;/p&gt;
    &lt;p&gt;This is the same failure mode as video game art criticism, in a way, in treating it as entertainment and just the sum of its parts. To tell me that the graphics are so many gigabytes of files, or the world has 30,000 rooms, or there is 300 hours of recorded NPC lines, or that it’s an arena shooter with microtransactions, is to tell me something as ultimately useless as “this movie cost $300 million to make”. Saying that this fantasy character killed this other character in a cutscene, in one alternate ending, is little better. Even talking about ‘fun’ is still missing the mark.&lt;/p&gt;
    &lt;p&gt;Game art criticism only works when it conveys the transformativeness on the player (ie. reviewer/critic). For example, this review of Grid Wars 2 manages to convey how it becomes a completely different space shooter game when one starts thinking of the random black holes as not merely environmental hazards, but as one’s real enemies, who feed on the ‘enemies’, and so it is not about shooting enemy spaceships but “black hole farming”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Sometimes it’s as simple as putting a hole between you and a pack of enemies (such as the dumb blue diamonds, which just head straight for you regardless of what might be in the way). Sometimes (eg. with the green squares which run away from your shots) it’s the slightly more sophisticated method of putting the enemies between the hole and your fire, driving them into the hole as they flee from the bullet stream. Sometimes it’s desperately hovering at the edge of the black hole and shooting the enemies before they fall into it, because otherwise it’ll be overwhelmed and explode before you have the chance to blow it up and get the points. And sometimes, most terrifyingly, it’s sitting in the midst of a huge wave of deadly enemies on the edge of a whirling star of death and not shooting at all.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Even accidental unintended games demonstrate this: the participants in what you might call the ‘accidental ARG’ of the Paul McCartney coverup conspiracy theory found their consciousnesses transformed into the paranoid schizophrenic mindset, in which they interrogate every scrap of the Beatles as not just evidence that Paul McCartney had died &amp;amp; been secretly replaced, but as deliberate communications from the Beatles about the coverup. After playing the ‘Paul is Dead’ ARG long enough, they literally saw different things on album covers and heard different things when playing records the wrong way. This is something that cannot be communicated except by experiencing yourself, and a good writeup like “Who Buried Paul?” succeeds by teaching us “Paul-is-Dead 101” thinking so we can feel what it is like to see messages about this tragedy &amp;amp; coverup hidden in plain sight. (See also Foucault’s Pendulum and Unsong.)&lt;/p&gt;
    &lt;p&gt;Perhaps it’s no surprise that such criticism is so unsatisfactory. Epiphanies do not come like clockwork to all. Personal transformation cannot be scheduled reliably for a tight magazine deadline, nor can it easily be conveyed in words. They are premised on a false model of how such art works, and how it should be critiqued. And even when they hit the mark, they are still derivative secondary works—at best pale echoes of an actual transformation some player once had.&lt;/p&gt;
    &lt;p&gt;Given the commercial realities, perhaps this cannot be fixed, and we must accept that timely reviews are ultimately the “Cliff Notes” of games.&lt;/p&gt;
    &lt;p&gt;But with this in mind, we can focus on reviews for older games, which have had enough time for transformation to happen, by players who have just recently been transformed—they are still capable of explaining it to the un-transformed.&lt;/p&gt;
    &lt;p&gt;that’s a possible justification. I think one can probably come up with a relatively short list of major functions video game art criticism could usefully serve: (1) professional analysis on the technical level of ‘how did they do X? why does Y work? how did they avoid Z?’ (2) serve as a meditation master to help players be enlightened, for ones who are just not quite Getting It and need a good ‘Kwatz!’ or koan; (3) do their best to take the reader through the transformation, knowing that they can’t really, but if they point at the moon, perhaps the right reader will be intrigued enough by the snack-sized sampler platter to go and do the real thing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46760998</guid><pubDate>Mon, 26 Jan 2026 02:07:34 +0000</pubDate></item><item><title>You can just port things to Cloudflare Workers</title><link>https://sigh.dev/posts/you-can-just-port-things-to-cloudflare-workers/</link><description>&lt;doc fingerprint="b6131d1f4f9c3c94"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;You can just port things to Cloudflare Workers&lt;/head&gt;
    &lt;p&gt;This January I decided to double down on using up my free ai credits by building a few projects on Cloudflare Workers. I’ve always really liked the idea of this platform that has cheap/free resources, but every time I build larger things on it I run into limits that make me frustrated and move to cheap vps hosting like fly.io or DigitalOcean.&lt;/p&gt;
    &lt;p&gt;Is vibeporting a word? Maybe it should be?&lt;/p&gt;
    &lt;head rend="h1"&gt;Datasette-ts&lt;/head&gt;
    &lt;p&gt;Over holiday break, I was reading some of Simon Willison’s posts about AI and I checked check where it’s currently possible to deploy it. You can deploy it pretty much everywhere but NOT on Cloudflare Workers, due to workers not really supporting much of Python’s ecosystem. I pointed Codex with GPT-5.2 Codex high/medium at the Datasette repo and had it break it down into README tasks and slowly do them one at a time. I’m not yet convinced by the crazy subagent stuff or that worktrees are worth it.&lt;/p&gt;
    &lt;p&gt;As I got into it, it was clear I needed to narrow down the scope. Mr. Willison has built a very mature project that has a plugin system and a ton of features built-in and it depends on subdependencies that he also has published like sqlite-utils. Obviously, what I wanted is something that feels similar and runs on Cloudflare Workers. I picked up Drizzle, Hono, and Alchemy to handle Cloudflare deployments. I chose not to rebuild the frontend as a React SPA instead rendering something similar to the original Jinja templates using Hono’s JSX.&lt;/p&gt;
    &lt;p&gt;Anyway, it ends up working pretty well. You can see a live demo at datasette-legislators.ep.workers.dev and the source is available below. I can’t say the code is in a good state, but it lives here https://github.com/scttcper/datasette-ts.&lt;/p&gt;
    &lt;head rend="h1"&gt;SESnoop&lt;/head&gt;
    &lt;p&gt;Another Cloudflare Worker port, this time of a Rails app called Sessy. I decided to rename it because I was going for a different vibe. I send a bunch of emails via SES for xmplaylist.com and I was looking into running Sessy to handle the bounces and complaints, however I can’t get myself to think about Ruby for more than 1 minute. So again I pointed Codex at the Sessy repo and a few other Cloudflare/Hono example repos and had it build out a monorepo where the worker handles the api and Cloudflare assets serves a React SPA frontend.&lt;/p&gt;
    &lt;p&gt;I think what was hard to reel in was how much frontend it was willing to build before I could stop it and start bringing in shadcn components. Like it made a bunch of select components and things that were generally pretty ugly. So then you have to tell it to replace all the ugly things with premade shadcn + baseui components.&lt;/p&gt;
    &lt;p&gt;This project took a bit more work to get working outside of pointing AI at the code. It made a number of Cloudflare mistakes, tests were difficult to get working 100% correctly. One example was that it put the webhook at &lt;code&gt;/webhook&lt;/code&gt; which Cloudflare would attempt to load as an asset since the worker is bound to &lt;code&gt;/api&lt;/code&gt; which is always a bit of a headscratcher until you remember how this all works. It was really cool getting to know how SNS works with SES and watching them flow into D1 is fun.&lt;/p&gt;
    &lt;p&gt;I tried publishing this package to npm and it kinda works to deploy to cloudflare if alchemy is setup. Or you can run it locally with &lt;code&gt;npx datasette-ts@latest serve ./legislators.db&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;I don’t have a live demo, but you can check out the source code at scttcper/sesnoop.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Pretty happy with how both of these turned out. I didn’t exclusively use Codex on either of them, however Codex was the main driver 95% of the time. I think Codex w/ GPT-5.2 Codex on high or medium is a great model and through the team plan you can basically run medium as long as you want. I exhausted about 1 week worth of the plan I’m on for Codex for each project.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46761239</guid><pubDate>Mon, 26 Jan 2026 02:41:32 +0000</pubDate></item><item><title>Show HN: NukeCast – If it happened today, where would the fallout go</title><link>https://nukecast.com/</link><description>&lt;doc fingerprint="265aded36c874519"&gt;
  &lt;main&gt;
    &lt;p&gt; Disclaimer: This is a simulation. Always trust local, state, and federal emergency guidance. &lt;/p&gt;
    &lt;head rend="h3"&gt;Legend&lt;/head&gt;
    &lt;p&gt;Load data to see legend&lt;/p&gt;
    &lt;head rend="h4"&gt;Markers&lt;/head&gt;
    &lt;p&gt;Add your own markers with premium!&lt;/p&gt;
    &lt;p&gt;This is what a potential nuclear strike impacting the U.S. could look like. NukeCast uses current weather forecasts to simulate where radioactive fallout may travel, how it disperses through the atmosphere, and where it could settle—so you can quickly identify likely downwind areas and make more informed preparedness decisions.&lt;/p&gt;
    &lt;p&gt;For details on how the model works, assumptions, and limitations, please check the Wiki.&lt;/p&gt;
    &lt;p&gt;If you find this useful, consider upgrading to Premium—Amazon compute time ain’t cheap!&lt;/p&gt;
    &lt;p&gt;—Todd&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46761493</guid><pubDate>Mon, 26 Jan 2026 03:21:12 +0000</pubDate></item><item><title>Environmentalists worry Google behind bid to control Oregon town's water</title><link>https://www.sfgate.com/national-parks/article/mount-hood-water-google-21307223.php</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46761614</guid><pubDate>Mon, 26 Jan 2026 03:40:06 +0000</pubDate></item><item><title>Iran's internet blackout may become permanent, with access for elites only</title><link>https://restofworld.org/2026/iran-blackout-tiered-internet/</link><description>&lt;doc fingerprint="3fb0853a39ad478e"&gt;
  &lt;main&gt;
    &lt;p&gt;Iran’s near-total communications blackout has entered its 16th day, but that’s just a live test.&lt;/p&gt;
    &lt;p&gt;Following a repressive crackdown on protests, the government is now building a system that grants web access only to security-vetted elites, while locking 90 million citizens inside an intranet.&lt;/p&gt;
    &lt;p&gt;Government spokesperson Fatemeh Mohajerani confirmed international access will not be restored until at least late March. Filterwatch, which monitors Iranian internet censorship from Texas, cited government sources, including Mohajerani, saying access will “never return to its previous form.”&lt;/p&gt;
    &lt;p&gt;This is what makes Iran’s attempt unique: Other authoritarian states built walls before their populations went online. Iran is trying to seal off a connected economy already in freefall.&lt;/p&gt;
    &lt;p&gt;The system is called Barracks Internet, according to confidential planning documents obtained by Filterwatch. Under this architecture, access to the global web will be granted only through a strict security whitelist.&lt;/p&gt;
    &lt;p&gt;“The regime is terrified of one thing: Iranians being heard telling their own truth and having crimes documented,” Mahsa Alimardani, a digital rights researcher at U.S.-based Witness, which trains activists to use video for advocacy, told Rest of World. “The question becomes: How do we give Iranians an unbreakable voice?”&lt;/p&gt;
    &lt;p&gt;The idea of tiered internet access is not new in Iran. Since at least 2013, the regime has quietly issued “white SIM cards,” giving unrestricted global internet access to approximately 16,000 people. The system gained public attention in November 2025 when X’s location feature revealed that certain accounts, including the communications minister, were connecting directly from inside Iran, despite X being blocked since 2009.&lt;/p&gt;
    &lt;p&gt;What is different now is scale and permanence. The current blackout tests infrastructure designed to make two-tier access the default, not a temporary crackdown.&lt;/p&gt;
    &lt;p&gt;Only a handful of nations have attempted to wall off their citizens from the global internet. North Korea’s Kwangmyong intranet was built from scratch for a population that never had connectivity. China constructed its Great Firewall over two decades while nurturing domestic alternatives such as WeChat and Alibaba. Iran is attempting to do both in weeks, with no domestic alternatives.&lt;/p&gt;
    &lt;p&gt;The economic costs of the blackout are staggering. Iran’s deputy communications minister pegged the daily losses at as much as $4.3 million. NetBlocks estimates the true cost exceeds $37 million daily. More than 10 million Iranians depend directly on digital platforms for their livelihoods.&lt;/p&gt;
    &lt;p&gt;Tipax, one of Iran’s largest private delivery companies handling about 320,000 daily shipments before the protests, now processes fewer than a few hundred, according to Filterwatch. The company operates a nationwide logistics network comparable to FedEx in the U.S. market.&lt;/p&gt;
    &lt;p&gt;The government fired Irancell’s CEO for failing to comply with shutdown orders. Irancell, the country’s second-largest mobile operator with 66 million subscribers, is partly owned by South Africa’s MTN Group. Alireza Rafiei was removed for disobeying orders on “restriction of internet access in crisis situations,” according to Fars news agency.&lt;/p&gt;
    &lt;p&gt;Foreign telecom partners have left Iran in recent days under security escort, without media coverage, according to Filterwatch. This may signal the end of international cooperation in critical infrastructure, replaced by the Revolutionary Guard’s construction arm or limited cooperation with Huawei.&lt;/p&gt;
    &lt;p&gt;Technical experts doubt the regime can sustain Barracks Internet without crippling the economy. Georgia Tech’s Internet Intelligence Lab, which has tracked Iran’s shutdowns since the Arab Spring, called the blackout “the most sophisticated and most severe in Iran’s history.” Its measurements show about 3% connectivity persists, likely government officials and state services.&lt;/p&gt;
    &lt;p&gt;Kaveh Ranjbar, former chief technology officer at RIPE NCC, the body managing European internet infrastructure, calls the plan a “digital airlock” that can’t fully seal a modern economy. No country has hermetically sealed a functioning digital economy, he told The New Arab.&lt;/p&gt;
    &lt;p&gt;Activists have smuggled an estimated 50,000 Starlink satellite terminals into Iran since 2022, when the Biden administration exempted the service from sanctions. SpaceX has made the service free for Iranian users.&lt;/p&gt;
    &lt;p&gt;The government claims it cut off 40,000 Starlink connections and jammed some terminals during the blackout, though others remain operational after firmware updates to bypass government blocking. Still, the technology remains vulnerable to signal jamming, meaning the regime holds ultimate leverage.&lt;/p&gt;
    &lt;p&gt;“We need to revolutionize access to the internet,” said Alimardani. “And move beyond the limiting structures and norms of ‘internet sovereignty.’”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46761822</guid><pubDate>Mon, 26 Jan 2026 04:18:19 +0000</pubDate></item><item><title>The browser is the sandbox</title><link>https://simonwillison.net/2026/Jan/25/the-browser-is-the-sandbox/</link><description>&lt;doc fingerprint="5daa04924fbda384"&gt;
  &lt;main&gt;
    &lt;p&gt;the browser is the sandbox. Paul Kinlan is a web platform developer advocate at Google and recently turned his attention to coding agents. He quickly identified the importance of a robust sandbox for agents to operate in and put together these detailed notes on how the web browser can help:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This got me thinking about the browser. Over the last 30 years, we have built a sandbox specifically designed to run incredibly hostile, untrusted code from anywhere on the web, the instant a user taps a URL. [...]&lt;/p&gt;
      &lt;p&gt;Could you build something like Cowork in the browser? Maybe. To find out, I built a demo called Co-do that tests this hypothesis. In this post I want to discuss the research I've done to see how far we can get, and determine if the browser's ability to run untrusted code is useful (and good enough) for enabling software to do more for us directly on our computer.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Paul then describes how the three key aspects of a sandbox - filesystem, network access and safe code execution - can be handled by browser technologies: the File System Access API (still Chrome-only as far as I can tell), CSP headers with &lt;code&gt;&amp;lt;iframe sandbox&amp;gt;&lt;/code&gt; and WebAssembly in Web Workers.&lt;/p&gt;
    &lt;p&gt;Co-do is a very interesting demo that illustrates all of these ideas in a single application:&lt;/p&gt;
    &lt;p&gt;You select a folder full of files and configure an LLM provider and set an API key, Co-do then uses CSP-approved API calls to interact with that provider and provides a chat interface with tools for interacting with those files. It does indeed feel similar to Claude Cowork but without running a multi-GB local container to provide the sandbox.&lt;/p&gt;
    &lt;p&gt;My biggest complaint about &lt;code&gt;&amp;lt;iframe sandbox&amp;gt;&lt;/code&gt; remains how thinly documented it is, especially across different browsers. Paul's post has all sorts of useful details on that which I've not encountered elsewhere, including a complex double-iframe technique to help apply network rules to the inner of the two frames.&lt;/p&gt;
    &lt;p&gt;Thanks to this post I also learned about the &lt;code&gt;&amp;lt;input type="file" webkitdirectory&amp;gt;&lt;/code&gt; tag which turns out to work on Firefox, Safari and Chrome and allows a browser read-only access to a full directory of files at once. I had Claude knock up a webkitdirectory demo to try it out and I'll certainly be using it for projects in the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wilson Lin on FastRender: a browser built by thousands of parallel agents - 23rd January 2026&lt;/item&gt;
      &lt;item&gt;First impressions of Claude Cowork, Anthropic's general agent - 12th January 2026&lt;/item&gt;
      &lt;item&gt;My answers to the questions I posed about porting open source code with LLMs - 11th January 2026&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46762150</guid><pubDate>Mon, 26 Jan 2026 05:23:01 +0000</pubDate></item><item><title>The Holy Grail of Linux Binary Compatibility: Musl and Dlopen</title><link>https://github.com/quaadgras/graphics.gd/discussions/242</link><description>&lt;doc fingerprint="dca32db1b14b699"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Holy Grail of Linux Binary Compatibility: musl + dlopen #242&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I guess using Go + Godot to build native &amp;amp; installable Android &amp;amp; iOS binaries (without any proprietary SDKs) was too easy. So it's time for a real challenge...&lt;/p&gt;
          &lt;head&gt;Linux Binary Compatibility&lt;/head&gt;
          &lt;p&gt;(some background reading: https://jangafx.com/insights/linux-binary-compatibility)&lt;/p&gt;
          &lt;p&gt;For a while now, it's been very easy to reliably ship command line software &amp;amp; servers for Linux, just run &lt;/p&gt;
          &lt;p&gt;The problems begin to creep in when you want access to hardware accelerated graphics. All the GPU drivers on Linux require accessing dynamic libraries via the C ABI. These C libraries are built against a particular libc, which is most commonly &lt;/p&gt;
          &lt;p&gt;In fact, I've directly experienced this, as I recently replaced the OS on my personal computer with the &lt;/p&gt;
          &lt;p&gt;That's a problem, firstly because this is my distro now, I need to be able to build graphics.gd projects! Secondly, in theory, &lt;/p&gt;
          &lt;head&gt;Supporting &lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46762882</guid><pubDate>Mon, 26 Jan 2026 07:41:52 +0000</pubDate></item></channel></rss>