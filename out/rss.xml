<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 03 Feb 2026 22:54:10 +0000</lastBuildDate><item><title>Show HN: Sandboxing untrusted code using WebAssembly</title><link>https://github.com/mavdol/capsule</link><description>&lt;doc fingerprint="c8903e58cf8302c2"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;Capsule&lt;/code&gt; is a runtime for coordinating AI agent tasks in isolated environments. It is designed to handle, long-running workflows, large-scale processing, autonomous decision-making securely, or even multi-agent systems.&lt;/p&gt;
    &lt;p&gt;Each task runs inside its own WebAssembly sandbox, providing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Isolated execution: Each task runs isolated from your host system&lt;/item&gt;
      &lt;item&gt;Resource limits: Set CPU, memory, and timeout limits per task&lt;/item&gt;
      &lt;item&gt;Automatic retries: Handle failures without manual intervention&lt;/item&gt;
      &lt;item&gt;Lifecycle tracking: Monitor which tasks are running, completed, or failed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This enables safe task-level execution of untrusted code within AI agent systems.&lt;/p&gt;
    &lt;p&gt;Simply annotate your Python functions with the &lt;code&gt;@task&lt;/code&gt; decorator:&lt;/p&gt;
    &lt;code&gt;from capsule import task

@task(name="analyze_data", compute="MEDIUM", ram="512MB", timeout="30s", max_retries=1)
def analyze_data(dataset: list) -&amp;gt; dict:
    """Process data in an isolated, resource-controlled environment."""
    # Your code runs safely in a Wasm sandbox
    return {"processed": len(dataset), "status": "complete"}&lt;/code&gt;
    &lt;p&gt;For TypeScript and JavaScript, use the &lt;code&gt;task()&lt;/code&gt; wrapper function with full access to the npm ecosystem:&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";

export const analyzeData = task({
  name: "analyze_data",
  compute: "MEDIUM",
  ram: "512MB",
  timeout: "30s",
  maxRetries: 1
}, (dataset: number[]): object =&amp;gt; {
  // Your code runs safely in a Wasm sandbox
  return { processed: dataset.length, status: "complete" };
});

// The "main" task is required as the entrypoint
export const main = task({
    name: "main",
    compute: "HIGH"
}, () =&amp;gt; {
  return analyzeData([1, 2, 3, 4, 5]);
});&lt;/code&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;The runtime requires a task named &lt;code&gt;"main"&lt;/code&gt; as the entry point. Python can define the main task itself, but it's recommended to set it manually.&lt;/p&gt;
    &lt;p&gt;When you run &lt;code&gt;capsule run main.py&lt;/code&gt; (or &lt;code&gt;main.ts&lt;/code&gt;), your code is compiled into a WebAssembly module and executed in a dedicated sandbox to isolate tasks.&lt;/p&gt;
    &lt;p&gt;Each task operates within its own sandbox with configurable resource limits, ensuring that failures are contained and don't cascade to other parts of your workflow. The host system controls every aspect of execution, from CPU allocation via Wasm fuel metering to memory constraints and timeout enforcement.&lt;/p&gt;
    &lt;p&gt;Every task returns a structured JSON envelope containing both the result and execution metadata:&lt;/p&gt;
    &lt;code&gt;{
  "success": true,
  "result": "Hello from Capsule!",
  "error": null,
  "execution": {
    "task_name": "data_processor",
    "duration_ms": 1523,
    "retries": 0,
    "fuel_consumed": 45000
  }
}&lt;/code&gt;
    &lt;p&gt;Response fields:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;success&lt;/code&gt;‚Äî Boolean indicating whether the task completed successfully&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;result&lt;/code&gt;‚Äî The actual return value from your task (json, string, null on failure etc..)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;error&lt;/code&gt;‚Äî Error details if the task failed (&lt;code&gt;{ error_type: string, message: string }&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;execution&lt;/code&gt;‚Äî Performance metrics:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;task_name&lt;/code&gt;‚Äî Name of the executed task&lt;/item&gt;&lt;item&gt;&lt;code&gt;duration_ms&lt;/code&gt;‚Äî Execution time in milliseconds&lt;/item&gt;&lt;item&gt;&lt;code&gt;retries&lt;/code&gt;‚Äî Number of retry attempts that occurred&lt;/item&gt;&lt;item&gt;&lt;code&gt;fuel_consumed&lt;/code&gt;‚Äî CPU resources used (see Compute Levels)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install capsule-run&lt;/code&gt;
    &lt;p&gt;Create &lt;code&gt;hello.py&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;from capsule import task

@task(name="main", compute="LOW", ram="64MB")
def main() -&amp;gt; str:
    return "Hello from Capsule!"&lt;/code&gt;
    &lt;p&gt;Run it:&lt;/p&gt;
    &lt;code&gt;capsule run hello.py&lt;/code&gt;
    &lt;code&gt;npm install -g @capsule-run/cli
npm install @capsule-run/sdk&lt;/code&gt;
    &lt;p&gt;Create &lt;code&gt;hello.ts&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";

export const main = task({
  name: "main",
  compute: "LOW",
  ram: "64MB"
}, (): string =&amp;gt; {
  return "Hello from Capsule!";
});&lt;/code&gt;
    &lt;p&gt;Run it:&lt;/p&gt;
    &lt;code&gt;capsule run hello.ts&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;Use &lt;code&gt;--verbose&lt;/code&gt; to display real-time task execution details.&lt;/p&gt;
    &lt;p&gt;Configure your tasks with these parameters:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Parameter&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;code&gt;name&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Task identifier&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;str&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;function name (Python) / required (TS)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;"process_data"&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;code&gt;compute&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;CPU allocation level: &lt;code&gt;"LOW"&lt;/code&gt;, &lt;code&gt;"MEDIUM"&lt;/code&gt;, or &lt;code&gt;"HIGH"&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;str&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;"MEDIUM"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;"HIGH"&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;code&gt;ram&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Memory limit for the task&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;str&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;unlimited&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;"512MB"&lt;/code&gt;, &lt;code&gt;"2GB"&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;code&gt;timeout&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Maximum execution time&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;str&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;unlimited&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;"30s"&lt;/code&gt;, &lt;code&gt;"5m"&lt;/code&gt;, &lt;code&gt;"1h"&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;&lt;code&gt;max_retries&lt;/code&gt; / &lt;code&gt;maxRetries&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Number of retry attempts on failure&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;int&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;&lt;code&gt;allowed_files&lt;/code&gt; / &lt;code&gt;allowedFiles&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Folders accessible in the sandbox&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;[]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;["./data", "./output"]&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;env_variables&lt;/code&gt; / &lt;code&gt;envVariables&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Environment variables accessible in the sandbox&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;[]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;["API_KEY"]&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Capsule controls CPU usage through WebAssembly's fuel mechanism, which meters instruction execution. The compute level determines how much fuel your task receives.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LOW provides minimal allocation for lightweight tasks&lt;/item&gt;
      &lt;item&gt;MEDIUM offers balanced resources for typical workloads&lt;/item&gt;
      &lt;item&gt;HIGH grants maximum fuel for compute-intensive operations&lt;/item&gt;
      &lt;item&gt;CUSTOM to specify an exact fuel value (e.g., &lt;code&gt;compute="1000000"&lt;/code&gt;) for precise control over execution limits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can create a &lt;code&gt;capsule.toml&lt;/code&gt; file in your project root to set default options for all tasks and define workflow metadata:&lt;/p&gt;
    &lt;code&gt;# capsule.toml

[workflow]
name = "My AI Workflow"
version = "1.0.0"
entrypoint = "src/main.py"  # Default file when running `capsule run`

[tasks]
default_compute = "MEDIUM"
default_ram = "256MB"
default_timeout = "30s"
default_max_retries = 2&lt;/code&gt;
    &lt;p&gt;With an entrypoint defined, you can simply run:&lt;/p&gt;
    &lt;code&gt;capsule run&lt;/code&gt;
    &lt;p&gt;Task-level options always override these defaults when specified.&lt;/p&gt;
    &lt;p&gt;The standard Python &lt;code&gt;requests&lt;/code&gt; library and socket-based networking aren't natively compatible with WebAssembly's sandboxed I/O model. Capsule provides its own HTTP client that works within the Wasm environment:&lt;/p&gt;
    &lt;code&gt;from capsule import task
from capsule.http import get, post, put, delete

@task(name="http_example", compute="MEDIUM", timeout="30s")
def main() -&amp;gt; dict:
    """Example demonstrating HTTP client usage within a task."""

    # GET request
    response = get("https://api.example.com/data")

    # POST with JSON body
    response = post("https://api.example.com/submit", json={"key": "value"})

    # Response methods
    is_ok = response.ok()           # Returns True if status code is 2xx
    status = response.status_code    # Get the HTTP status code
    data = response.json()           # Parse response as JSON
    text = response.text()           # Get response as text

    return {"status": status, "success": is_ok}&lt;/code&gt;
    &lt;p&gt;Standard libraries like &lt;code&gt;fetch&lt;/code&gt; are already compatible, so no custom HTTP client is needed for TypeScript/JavaScript.&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";

export const main = task({
    name: "main",
    compute: "MEDIUM"
}, async () =&amp;gt; {
    const response = await fetch("https://api.example.com/data");
    return response.json();
});&lt;/code&gt;
    &lt;p&gt;Tasks can read and write files within directories specified in &lt;code&gt;allowed_files&lt;/code&gt;. Any attempt to access files outside these directories is not possible.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Currently, &lt;code&gt;allowed_files&lt;/code&gt; supports directory paths, not individual files.&lt;/p&gt;
    &lt;p&gt;Python's standard file operations work normally. Use &lt;code&gt;open()&lt;/code&gt;, &lt;code&gt;os&lt;/code&gt;, &lt;code&gt;pathlib&lt;/code&gt;, or any file manipulation library.&lt;/p&gt;
    &lt;code&gt;from capsule import task

@task(name="restricted_writer", allowed_files=["./output"])
def restricted_writer() -&amp;gt; None:
    with open("./output/result.txt", "w") as f:
        f.write("result")

@task(name="main")
def main() -&amp;gt; str:
    restricted_writer()&lt;/code&gt;
    &lt;p&gt;Common Node.js built-ins are available. Use the standard &lt;code&gt;fs&lt;/code&gt; module:&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";
import fs from "fs/promises";

export const restrictedWriter = task({
    name: "restricted_writer",
    allowedFiles: ["./output"]
}, async () =&amp;gt; {
    await fs.writeFile("./output/result.txt", "result");
});

export const main = task({ name: "main", allowedFiles: ["./data"] }, async () =&amp;gt; {
    await restrictedWriter();
    return await fs.readFile("./data/input.txt", "utf8");
});&lt;/code&gt;
    &lt;p&gt;Tasks can access environment variables to read configuration, API keys, or other runtime settings.&lt;/p&gt;
    &lt;p&gt;Use Python's standard &lt;code&gt;os.environ&lt;/code&gt; to access environment variables:&lt;/p&gt;
    &lt;code&gt;from capsule import task
import os

@task(name="main", env_variables=["API_KEY"])
def main() -&amp;gt; dict:
    api_key = os.environ.get("API_KEY")
    return {"api_key": api_key}&lt;/code&gt;
    &lt;p&gt;Use the standard &lt;code&gt;process.env&lt;/code&gt; to access environment variables:&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";

export const main = task({
    name: "main",
    envVariables: ["API_KEY"]
}, () =&amp;gt; {
    const apiKey = process.env.API_KEY;
    return { apiKeySet: apiKey !== undefined };
});&lt;/code&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;TypeScript/JavaScript has broader compatibility than Python since it doesn't rely on native bindings.&lt;/p&gt;
    &lt;p&gt;Python: Pure Python packages and standard library modules work. Packages with C extensions (&lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;) are not yet supported.&lt;/p&gt;
    &lt;p&gt;TypeScript/JavaScript: npm packages and ES modules work. Common Node.js built-ins are available. If you have any trouble with a built-in do not hesitate to open an issue.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome!&lt;/p&gt;
    &lt;p&gt;Prerequisites: Rust (latest stable), Python 3.13+, Node.js 22+&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/mavdol/capsule.git
cd capsule

# Build and install CLI
cargo install --path crates/capsule-cli

# Python SDK (editable install)
pip install -e crates/capsule-sdk/python

# TypeScript SDK (link for local dev)
cd crates/capsule-sdk/javascript
npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; npm link

# Then in your project: npm link @capsule-run/sdk&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch: &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Run tests: &lt;code&gt;cargo test&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Open a Pull Request&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Need help? Open an issue&lt;/p&gt;
    &lt;p&gt;Capsule builds on these open source projects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;componentize-py ‚Äì Python to WebAssembly Component compilation&lt;/item&gt;
      &lt;item&gt;jco ‚Äì JavaScript toolchain for WebAssembly Components&lt;/item&gt;
      &lt;item&gt;wasmtime ‚Äì WebAssembly runtime&lt;/item&gt;
      &lt;item&gt;WASI ‚Äì WebAssembly System Interface&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0 - see the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871387</guid><pubDate>Tue, 03 Feb 2026 14:28:01 +0000</pubDate></item><item><title>Qwen3-Coder-Next</title><link>https://qwen.ai/blog?id=qwen3-coder-next</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872706</guid><pubDate>Tue, 03 Feb 2026 16:01:50 +0000</pubDate></item><item><title>Launch HN: Modelence (YC S25) ‚Äì App Builder with TypeScript / MongoDB Framework</title><link>https://news.ycombinator.com/item?id=46872733</link><description>&lt;doc fingerprint="bb22d77b01df145e"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi all, Aram and Eduard here - co-founders of Modelence (&lt;/p&gt;https://modelence.com&lt;p&gt;). After spending years on scaling our previous startup‚Äôs platform, we built an open-source full-stack TypeScript + MongoDB framework to stop solving the same auth / database / API / cron job implementations every time we created an app, and we didn‚Äôt like the idea of using multiple managed platforms for each of these to run our apps either.&lt;/p&gt;&lt;p&gt;(Here‚Äôs our prior Show HN post for reference: https://news.ycombinator.com/item?id=44902227)&lt;/p&gt;&lt;p&gt;At the same time, we were excited by the whole AI app builder boom and realized that the real challenge there is the platform rather than the tool itself. Now we‚Äôre making Modelence the first full-stack framework that‚Äôs built for coding agents and humans alike:&lt;/p&gt;&lt;p&gt;- TypeScript is already great for AI coding because it provides guardrails and catches many errors at build time, so agents can auto-correct&lt;/p&gt;&lt;p&gt;- MongoDB eliminates the schema management problem for agents, which is where they fail the most often otherwise (+ works great with TS/Node.js)&lt;/p&gt;&lt;p&gt;- Built-in auth, database, cron jobs and else that just works together out of the box means agents only focus on your product logic and don‚Äôt fail at trying to set these things up (+ less tokens spent on boilerplate).&lt;/p&gt;&lt;p&gt;You can now try the Modelence app builder (based on Claude Agent SDK) by just typing a prompt on our landing page ( https://modelence.com ) - watch a demo video here: https://youtu.be/BPsYvj_nGuE&lt;/p&gt;&lt;p&gt;Then you can check it out locally and continue working in your own IDE, while still using Modelence Cloud as your backend, with a dev cloud environment, and later deploy and run on Modelence Cloud with built-in observability around every operation running in your app.&lt;/p&gt;&lt;p&gt;We‚Äôre also going to add a built-in DevOps agent that lives in the same cloud, knows the framework end-to-end, and will use all this observability data to act on errors, alerts, and incidents - closing the loop, because running in production is much harder than just building.&lt;/p&gt;&lt;p&gt;We launched the app builder as a quick start for developers, to demonstrate the framework and Modelence Cloud without having to manually read docs and follow the steps to set up a new app. Our main focus is still the platform itself, since we believe the real challenge in AI coding is the framework and the platform rather than the builder tool itself.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872733</guid><pubDate>Tue, 03 Feb 2026 16:03:21 +0000</pubDate></item><item><title>Show HN: C discrete event SIM w stackful coroutines runs 45x faster than SimPy</title><link>https://github.com/ambonvik/cimba</link><description>&lt;doc fingerprint="6a388adbeae31e0c"&gt;
  &lt;main&gt;
    &lt;p&gt;A fast discrete event simulation library written in C and assembly with POSIX pthreads. Simulated processes are implemented as stackful coroutines ("fibers") inside the pthreads.&lt;/p&gt;
    &lt;p&gt;Implementation status:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;x86-64: Stable, both for Linux and Windows&lt;/item&gt;
      &lt;item&gt;Apple Silicon: Planned&lt;/item&gt;
      &lt;item&gt;ARM: Planned&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Cimba models run 40-50 times faster than SimPy equivalents. The chart below shows the number of simulated events processed per second of wall clock time on a simple M/M/1 queue implemented in SimPy and Cimba. Cimba runs this scenario 45 times faster than SimPy with all CPU cores in use. Cimba runs 25 % faster (20M events/sec) on a single core than SimPy using all 64 cores (16M events/sec).&lt;/p&gt;
    &lt;p&gt;It is fast, powerful, reliable, and free.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Fast: The speed from multithreaded parallel execution translates to high resolution in your simulation modeling. You can run hundreds of replications and parameter variations in just a few seconds, generating tight confidence intervals in your experiments and a high density of data points along parameter variations.&lt;/p&gt;
        &lt;p&gt;In the benchmark shown above, Cimba reduces the run time by 97.8 % compared to the same model in SimPy using all CPU cores. This translates into doing your simulation experiments in seconds instead of minutes, or in minutes instead of hours.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powerful: Cimba provides a comprehensive toolkit for discrete event simulation:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Processes implemented as asymmetric stackful coroutines. A simulated process can yield and resume control from any level of a function call stack, allowing well-structured coding of arbitrarily large simulation models. As a first-order object, a simulated process can be passed as an argument to other functions, returned from functions, and stored in data structures, allowing rich and complex interactions between processes.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Pre-packaged process interaction mechanisms like resources, resource pools, buffers, object queues, priority queues, and timeouts. Cimba also provides condition variables where your simulated processes can wait for arbitrarily complex conditions to become true ‚Äì anything you can express as a function returning a binary true or false result.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;A wide range of fast, high-quality random number generators, both of academically important and more empirically oriented types. Important distributions like normal and exponential are implemented by state-of-the-art ziggurat rejection sampling for speed and accuracy.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Integrated logging and data collection features that make it easy to get a model running and understand what is happening inside it, including custom asserts to pinpoint sources of errors.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;As a C library, Cimba allows easy integration with other libraries and programs. You could call CUDA routines to enhance your simulation models with GPU-powered agentic behavior or drive a fancy graphics interface like a 3D visualization of a manufacturing plant. You could even call the Cimba simulation engine from other programming languages, since the C calling convention is standard and well-documented.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Reliable: Cimba is well-engineered open source. There is no mystery to the results you get. The code is written with liberal use of assertions to enforce preconditions, invariants, and postconditions in each function. The assertions act as self-enforcing documentation on expected inputs to and outputs from the Cimba functions. About 13 % of all code lines in the Cimba library are asssertions, a very high density. There are unit tests for each module. Running the unit test battery in debug mode (all assertions active) verifies the correct operation in great detail. You can do that by the one-liner&lt;/p&gt;&lt;code&gt;meson test -C build&lt;/code&gt;from the terminal command line.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Free: Cimba should fit well into the budget of most research groups.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It is a general-purpose discrete event simulation library, in the spirit of a 21st century Simula67 descendant. You can use it to model, e.g.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;computer networks,&lt;/item&gt;
      &lt;item&gt;transportation networks,&lt;/item&gt;
      &lt;item&gt;operating system task scheduling,&lt;/item&gt;
      &lt;item&gt;manufacturing systems and job shops,&lt;/item&gt;
      &lt;item&gt;military command and control systems,&lt;/item&gt;
      &lt;item&gt;hospital and emergency room patient flows,&lt;/item&gt;
      &lt;item&gt;queuing systems like bank tellers and store checkouts,&lt;/item&gt;
      &lt;item&gt;urban systems like public transport and garbage collection,&lt;/item&gt;
      &lt;item&gt;and quite a few more application domains of similar kinds, where overall system complexity arises from interactions between relatively simple components.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you look under the hood, you will also find additional reusable internal components. Cimba contains stackful coroutines doing their own thing on thread-safe cactus stacks. There are fast memory pool allocators for generic small objects and hash-heaps combining a binary heap and an open addressing hash map using Fibonacci hashing. Although not part of the public Cimba API, these components can also be used in your model if needed.&lt;/p&gt;
    &lt;p&gt;It is C11/C17. As an illustration, this is the entire code for our multithreaded M/M/1 benchmark mentioned above:&lt;/p&gt;
    &lt;code&gt;    #include &amp;lt;inttypes.h&amp;gt;
    #include &amp;lt;stdio.h&amp;gt;
    #include &amp;lt;stdint.h&amp;gt;
    
    #include &amp;lt;cimba.h&amp;gt;
    
    #define NUM_OBJECTS 1000000u
    #define ARRIVAL_RATE 0.9
    #define SERVICE_RATE 1.0
    #define NUM_TRIALS 100
    
    CMB_THREAD_LOCAL struct cmi_mempool objectpool = CMI_MEMPOOL_STATIC_INIT(8u, 512u);
    
    struct simulation {
        struct cmb_process *arrival;
        struct cmb_process *service;
        struct cmb_objectqueue *queue;
    };
    
    struct trial {
        double arr_mean;
        double srv_mean;
        uint64_t obj_cnt;
        double sum_wait;
        double avg_wait;
    };
    
    struct context {
        struct simulation *sim;
        struct trial *trl;
    };
    
    void *arrivalfunc(struct cmb_process *me, void *vctx)
    {
        cmb_unused(me);
        const struct context *ctx = vctx;
        struct cmb_objectqueue *qp = ctx-&amp;gt;sim-&amp;gt;queue;
        const double mean_hld = ctx-&amp;gt;trl-&amp;gt;arr_mean;
        for (uint64_t ui = 0; ui &amp;lt; NUM_OBJECTS; ui++) {
            const double t_hld = cmb_random_exponential(mean_hld);
            cmb_process_hold(t_hld);
            void *object = cmi_mempool_alloc(&amp;amp;objectpool);
            double *dblp = object;
            *dblp = cmb_time();
            cmb_objectqueue_put(qp, object);
        }
    
        return NULL;
    }
    
    void *servicefunc(struct cmb_process *me, void *vctx)
    {
        cmb_unused(me);
        const struct context *ctx = vctx;
        struct cmb_objectqueue *qp = ctx-&amp;gt;sim-&amp;gt;queue;
        const double mean_srv = ctx-&amp;gt;trl-&amp;gt;srv_mean;
        uint64_t *cnt = &amp;amp;(ctx-&amp;gt;trl-&amp;gt;obj_cnt);
        double *sum = &amp;amp;(ctx-&amp;gt;trl-&amp;gt;sum_wait);
        while (true) {
            void *object = NULL;
            cmb_objectqueue_get(qp, &amp;amp;object);
            const double *dblp = object;
            const double t_srv = cmb_random_exponential(mean_srv);
            cmb_process_hold(t_srv);
            const double t_sys = cmb_time() - *dblp;
            *sum += t_sys;
            *cnt += 1u;
            cmi_mempool_free(&amp;amp;objectpool, object);
        }
    }
    
    void run_trial(void *vtrl)
    {
        struct trial *trl = vtrl;
    
        cmb_logger_flags_off(CMB_LOGGER_INFO);
        cmb_random_initialize(cmb_random_hwseed());
        cmb_event_queue_initialize(0.0);
        struct context *ctx = malloc(sizeof(*ctx));
        ctx-&amp;gt;trl = trl;
        struct simulation *sim = malloc(sizeof(*sim));
        ctx-&amp;gt;sim = sim;
    
        sim-&amp;gt;queue = cmb_objectqueue_create();
        cmb_objectqueue_initialize(sim-&amp;gt;queue, "Queue", CMB_UNLIMITED);
    
        sim-&amp;gt;arrival = cmb_process_create();
        cmb_process_initialize(sim-&amp;gt;arrival, "Arrival", arrivalfunc, ctx, 0);
        cmb_process_start(sim-&amp;gt;arrival);
        sim-&amp;gt;service = cmb_process_create();
        cmb_process_initialize(sim-&amp;gt;service, "Service", servicefunc, ctx, 0);
        cmb_process_start(sim-&amp;gt;service);
    
        cmb_event_queue_execute();
    
        cmb_process_stop(sim-&amp;gt;service, NULL);
        cmb_process_terminate(sim-&amp;gt;arrival);
        cmb_process_terminate(sim-&amp;gt;service);
        cmb_process_destroy(sim-&amp;gt;arrival);
        cmb_process_destroy(sim-&amp;gt;service);
    
        cmb_objectqueue_destroy(sim-&amp;gt;queue);
        cmb_event_queue_terminate();
        free(sim);
        free(ctx);
    }
    
    int main(void)
    {
        struct trial *experiment = calloc(NUM_TRIALS, sizeof(*experiment));
        for (unsigned ui = 0; ui &amp;lt; NUM_TRIALS; ui++) {
            struct trial *trl = &amp;amp;experiment[ui];
            trl-&amp;gt;arr_mean = 1.0 / ARRIVAL_RATE;
            trl-&amp;gt;srv_mean = 1.0 / SERVICE_RATE;
            trl-&amp;gt;obj_cnt = 0u;
            trl-&amp;gt;sum_wait = 0.0;
        }
    
        cimba_run_experiment(experiment,
                             NUM_TRIALS,
                             sizeof(*experiment),
                             run_trial);
    
        struct cmb_datasummary summary;
        cmb_datasummary_initialize(&amp;amp;summary);
        for (unsigned ui = 0; ui &amp;lt; NUM_TRIALS; ui++) {
            const double avg_tsys = experiment[ui].sum_wait / (double)(experiment[ui].obj_cnt);
            cmb_datasummary_add(&amp;amp;summary, avg_tsys);
        }
    
        const unsigned un = cmb_datasummary_count(&amp;amp;summary);
        if (un &amp;gt; 1) {
            const double mean_tsys = cmb_datasummary_mean(&amp;amp;summary);
            const double sdev_tsys = cmb_datasummary_stddev(&amp;amp;summary);
            const double serr_tsys = sdev_tsys / sqrt((double)un);
            const double ci_w = 1.96 * serr_tsys;
            const double ci_l = mean_tsys - ci_w;
            const double ci_u = mean_tsys + ci_w;
    
            printf("Average system time %f (n %u, conf.int. %f - %f, expected %f)\n",
                   mean_tsys, un, ci_l, ci_u, 1.0 / (SERVICE_RATE - ARRIVAL_RATE));
    
            return 0;
        }
    }

&lt;/code&gt;
    &lt;p&gt;See our tutorial at ReadTheDocs for more usage examples.&lt;/p&gt;
    &lt;p&gt;As shown above, it is some 45 times faster than SimPy in a relevant benchmark. It means getting your results almost immediately rather than after a "go brew a pot of coffee" delay breaking your line of thought.&lt;/p&gt;
    &lt;p&gt;For another illustration of how to benefit from the sheer speed, the experiment in test_cimba.c simulates an M/G/1 queue at four different levels of service process variability. For each variability level, it tries five system utilization levels. There are ten replications for each parameter combination, in total 4 * 5 * 10 = 200 trials. Each trial lasts for one million time units, where the average service time always is 1.0 time units.&lt;/p&gt;
    &lt;p&gt;This entire simulation runs in about 1.5 seconds on an AMD Threadripper 3970X with Arch Linux and produces the chart below.&lt;/p&gt;
    &lt;p&gt;Discrete event simulation fits well with an object-oriented paradigm. That is why object-oriented programming was invented in the first place for Simula67. Since OOP is not directly enforced in plain C, we provide the object-oriented characteristics (such as encapsulation, inheritance, polymorphism, and abstraction) in the Cimba software design instead. (See the ReadTheDocs explanation for more details.)&lt;/p&gt;
    &lt;p&gt;The simulated processes are stackful coroutines on their own call stacks, allowing the processes to store their state at arbitrary points and resume execution from there later with minimal overhead. The context-switching code is hand-coded in assembly for each platform. (You can find more details here.)&lt;/p&gt;
    &lt;p&gt;The C code is liberally sprinkled with &lt;code&gt;assert&lt;/code&gt; statements testing for preconditions,
invariants, and postconditions wherever possible, applying
Design by Contract
principles for high reliability. The Cimba library contains 958 asserts in 7132 lines of
C code, for a very high assert density of 13.4 %. These are custom-written
assert macros that will report
what trial, what process, the simulated time, the function and line number, and even the
random number seed used, if anything should go wrong. All time-consuming invariants and
postconditions are debug asserts, while the release asserts mostly check preconditions
like function argument validity. Turning off the debug asserts doubles the speed of your
model when you are ready for it, while turning off the release asserts as well gives
a small incremental improvement. (Again,
more explanation here.)&lt;/p&gt;
    &lt;p&gt;This is then combined with extensive unit testing of each module, ensuring that all lower level functionality works as expected before moving on to higher levels. You will find the test files corresponding to each code module in the test directory.&lt;/p&gt;
    &lt;p&gt;But do read the LICENSE. We are not giving any warranties here.&lt;/p&gt;
    &lt;p&gt;Long story made short: C++ exception handling is not very friendly to the stackful coroutines we need in Cimba. The stackless coroutines in C++ are entirely different from what we need.&lt;/p&gt;
    &lt;p&gt;C++ has also become a large and feature-rich language, where it will be hard to ensure compatibility with every possible combination of features.&lt;/p&gt;
    &lt;p&gt;Hence (like the Linux kernel), we chose the simpler platform for speed, clarity, and reliability. If you need to call Cimba from some other language, the C calling convention is well-known and well-documented.&lt;/p&gt;
    &lt;p&gt;Because it was not made public before. What retrospectively can be called Cimba 1.0 was implemented in K&amp;amp;R C at MIT in the early 1990's, followed by a parallelized version 2.0 in ANSI C and Perl around 1995‚Äì96. The present version written in C17 with POSIX pthreads is the third major rebuild, and the first public version.&lt;/p&gt;
    &lt;p&gt;It is right here. You clone the repository, build, and install it. You will need a C compiler and the Meson build manager. On Linux, you can use GCC or Clang, while the recommended approach on Windows is MinGW with its GCC compiler. For convenience, we recommend the CLion integrated development environment with GCC, Meson, and Ninja built-in support on both Linux and Windows.&lt;/p&gt;
    &lt;p&gt;You will find the installation guide here: https://cimba.readthedocs.io/en/latest/installation.html&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872818</guid><pubDate>Tue, 03 Feb 2026 16:09:07 +0000</pubDate></item><item><title>X offices raided in France</title><link>https://apnews.com/article/france-x-investigation-seach-elon-musk-1116be84d84201011219086ecfd4e0bc</link><description>&lt;doc fingerprint="cb949b2d010d9584"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;X offices raided in France as prosecutors investigate child abuse images and deepfakes&lt;/head&gt;
    &lt;head rend="h2"&gt;X offices raided in France as prosecutors investigate child abuse images and deepfakes&lt;/head&gt;
    &lt;p&gt;PARIS (AP) ‚Äî French prosecutors raided the offices of social media platform X on Tuesday as part of a preliminary investigation into allegations that include spreading child sexual abuse images and deepfakes. They have also summoned billionaire owner Elon Musk for questioning.&lt;/p&gt;
    &lt;p&gt;X and Musk‚Äôs artificial intelligence company xAI also face intensifying scrutiny from Britain‚Äôs data privacy regulator, which opened formal investigations into how they handled personal data when they developed and deployed Musk‚Äôs artificial intelligence chatbot Grok.&lt;/p&gt;
    &lt;p&gt;Grok, which was built by xAI and is available through X, sparked global outrage last month after it pumped out a torrent of sexualized nonconsensual deepfake images in response to requests from X users.&lt;/p&gt;
    &lt;p&gt;The French investigation was opened in January last year by the prosecutors‚Äô cybercrime unit, the Paris prosecutors‚Äô office said in a statement. It‚Äôs looking into alleged ‚Äúcomplicity‚Äù in possessing and spreading pornographic images of minors, sexually explicit deepfakes, denial of crimes against humanity and manipulation of an automated data processing system as part of an organized group, among other charges.&lt;/p&gt;
    &lt;p&gt;Prosecutors asked Musk and former CEO Linda Yaccarino to attend ‚Äúvoluntary interviews‚Äù on April 20. Employees of X have also been summoned that same week to be heard as witnesses, the statement said. Yaccarino was CEO from May 2023 until July 2025.&lt;/p&gt;
    &lt;p&gt;In a post on its own service denying the allegations, X railed against the raid on its Paris office as ‚Äúan abusive act of law enforcement theater designed to achieve illegitimate political objectives rather than advance legitimate law enforcement goals rooted in the fair and impartial administration of justice.‚Äù&lt;/p&gt;
    &lt;p&gt;In a message posted on X, the Paris prosecutors‚Äô office announced the ongoing searches at the company‚Äôs offices in France and said it was leaving the platform while calling on followers to join it on other social media.&lt;/p&gt;
    &lt;p&gt;‚ÄúAt this stage, the conduct of the investigation is based on a constructive approach, with the aim of ultimately ensuring that the X platform complies with French law, as it operates on the national territory,‚Äù the prosecutors‚Äô statement said.&lt;/p&gt;
    &lt;p&gt;European Union police agency Europol ‚Äúis supporting the French authorities in this,‚Äù Europol spokesperson Jan Op Gen Oorth told the AP, without elaborating.&lt;/p&gt;
    &lt;p&gt;French authorities opened their investigation after reports from a French lawmaker alleging that biased algorithms on X likely distorted the functioning of an automated data processing system.&lt;/p&gt;
    &lt;p&gt;It expanded after Grok generated posts that allegedly denied the Holocaust, a crime in France, and spread sexually explicit deepfakes, the statement said.&lt;/p&gt;
    &lt;p&gt;Grok wrote in a widely shared post in French that gas chambers at the Auschwitz-Birkenau death camp were designed for ‚Äúdisinfection with Zyklon B against typhus‚Äù rather than for mass murder ‚Äî language long associated with Holocaust denial.&lt;/p&gt;
    &lt;p&gt;In later posts on X, the chatbot reversed itself and acknowledged that its earlier reply was wrong, saying it had been deleted and pointed to historical evidence that Zyklon B was used to kill more than 1 million people in Auschwitz gas chambers.&lt;/p&gt;
    &lt;p&gt;The chatbot also appeared to praise Adolf Hitler last year, in comments that X took down after complaints.&lt;/p&gt;
    &lt;p&gt;In Britain, the Information Commissioner‚Äôs Office said it‚Äôs looking into whether X and xAI followed the law when processing personal data and whether Grok had any measures in place to prevent its use to generate ‚Äúharmful manipulated images.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúThe reports about Grok raise deeply troubling questions about how people‚Äôs personal data has been used to generate intimate or sexualised images without their knowledge or consent, and whether the necessary safeguards were put in place to prevent this,‚Äù said William Malcolm, an executive director at the watchdog.&lt;/p&gt;
    &lt;p&gt;He didn‚Äôt specify what the penalty would be if the probe found the companies didn‚Äôt comply with data protection laws.&lt;/p&gt;
    &lt;p&gt;A separate investigation into Grok launched last month by the U.K. media regulator, Ofcom, is ongoing.&lt;/p&gt;
    &lt;p&gt;Ofcom said Tuesday it‚Äôs still gathering evidence and warned the probe could take months.&lt;/p&gt;
    &lt;p&gt;X has also been under pressure from the EU. The 27-nation bloc‚Äôs executive arm opened an investigation last month after Grok spewed nonconsensual sexualized deepfake images on the platform.&lt;/p&gt;
    &lt;p&gt;Brussels has already hit X with a 120-million euro (then-$140 million) fine for shortcomings under the bloc‚Äôs sweeping digital regulations, including blue checkmarks that broke the rules on ‚Äúdeceptive design practices‚Äù that risked exposing users to scams and manipulation.&lt;/p&gt;
    &lt;p&gt;On Monday, Musk ‚Äôs space exploration and rocket business, SpaceX, announced that it acquired xAI in a deal that will also combine Grok, X and his satellite communication company Starlink.&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;Associated Press writers Nicolas Vaux-Montagny in Lyon, France, Mike Corder in The Hague, Netherlands, Sylvia Hui and Kelvin Chan in London contributed to this report.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872894</guid><pubDate>Tue, 03 Feb 2026 16:14:17 +0000</pubDate></item><item><title>Tadpole ‚Äì A modular and extensible DSL built for web scraping</title><link>https://tadpolehq.com/</link><description>&lt;doc fingerprint="d7a2168e9b832ef8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Tadpole&lt;/head&gt;&lt;p&gt;Scrape the web with a language designed for it.&lt;/p&gt;&lt;head rend="h2"&gt;Write Declarative, Modular Scraping Code&lt;/head&gt;Section titled ‚ÄúWrite Declarative, Modular Scraping Code‚Äù&lt;p&gt;Tadpole is built to be composable by allowing you to import modules from local files or remote repositories! All of the complexity of interacting with the browser is now completely abstracted away by the language! Building scrapers has never been easier!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46873133</guid><pubDate>Tue, 03 Feb 2026 16:29:13 +0000</pubDate></item><item><title>Prek: A better, faster, drop-in pre-commit replacement, engineered in Rust</title><link>https://github.com/j178/prek</link><description>&lt;doc fingerprint="28df57ddde9b6d0"&gt;
  &lt;main&gt;
    &lt;p&gt;pre-commit is a framework to run hooks written in many languages, and it manages the language toolchain and dependencies for running the hooks.&lt;/p&gt;
    &lt;p&gt;prek is a reimagined version of pre-commit, built in Rust. It is designed to be a faster, dependency-free and drop-in alternative for it, while also providing some additional long-requested features.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Although prek is pretty new, it‚Äôs already powering real‚Äëworld projects like CPython, Apache Airflow, FastAPI, and more projects are picking it up‚Äîsee Who is using prek?. If you‚Äôre looking for an alternative to &lt;code&gt;pre-commit&lt;/code&gt;, please give it a try‚Äîwe‚Äôd love your feedback!&lt;/p&gt;
    &lt;p&gt;Please note that some languages are not yet supported for full drop‚Äëin parity with &lt;code&gt;pre-commit&lt;/code&gt;. See Language Support for current status.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöÄ A single binary with no dependencies, does not require Python or any other runtime.&lt;/item&gt;
      &lt;item&gt;‚ö° Faster than &lt;code&gt;pre-commit&lt;/code&gt;and more efficient in disk space usage.&lt;/item&gt;
      &lt;item&gt;üîÑ Fully compatible with the original pre-commit configurations and hooks.&lt;/item&gt;
      &lt;item&gt;üèóÔ∏è Built-in support for monorepos (i.e. workspace mode).&lt;/item&gt;
      &lt;item&gt;üêç Integration with &lt;code&gt;uv&lt;/code&gt;for managing Python virtual environments and dependencies.&lt;/item&gt;
      &lt;item&gt;üõ†Ô∏è Improved toolchain installations for Python, Node.js, Bun, Go, Rust and Ruby, shared between hooks.&lt;/item&gt;
      &lt;item&gt;üì¶ Built-in Rust-native implementation of some common hooks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Standalone installer&lt;/head&gt;
    &lt;p&gt;prek provides a standalone installer script to download and install the tool,&lt;/p&gt;
    &lt;p&gt;On Linux and macOS:&lt;/p&gt;
    &lt;code&gt;curl --proto '=https' --tlsv1.2 -LsSf https://github.com/j178/prek/releases/download/v0.3.1/prek-installer.sh | sh&lt;/code&gt;
    &lt;p&gt;On Windows:&lt;/p&gt;
    &lt;code&gt;powershell -ExecutionPolicy ByPass -c "irm https://github.com/j178/prek/releases/download/v0.3.1/prek-installer.ps1 | iex"&lt;/code&gt;
    &lt;head&gt;PyPI&lt;/head&gt;
    &lt;p&gt;prek is published as Python binary wheel to PyPI, you can install it using &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;uv&lt;/code&gt; (recommended), or &lt;code&gt;pipx&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# Using uv (recommended)
uv tool install prek

# Using uvx (install and run in one command)
uvx prek

# Adding prek to the project dev-dependencies
uv add --dev prek

# Using pip
pip install prek

# Using pipx
pipx install prek&lt;/code&gt;
    &lt;head&gt;Homebrew&lt;/head&gt;
    &lt;code&gt;brew install prek&lt;/code&gt;
    &lt;head&gt;Cargo&lt;/head&gt;
    &lt;p&gt;Build from source using Cargo (Rust 1.89+ is required):&lt;/p&gt;
    &lt;code&gt;cargo install --locked prek&lt;/code&gt;
    &lt;head&gt;npmjs&lt;/head&gt;
    &lt;p&gt;prek is published as a Node.js package and can be installed with any npm-compatible package manager:&lt;/p&gt;
    &lt;code&gt;# As a dev dependency
npm add -D @j178/prek
pnpm add -D @j178/prek
bun add -D @j178/prek

# Or install globally
npm install -g @j178/prek
pnpm add -g @j178/prek
bun install -g @j178/prek

# Or run directly without installing
npx @j178/prek --version
bunx @j178/prek --version&lt;/code&gt;
    &lt;head&gt;Nix&lt;/head&gt;
    &lt;p&gt;prek is available via Nixpkgs.&lt;/p&gt;
    &lt;code&gt;# Choose what's appropriate for your use case.
# One-off in a shell:
nix-shell -p prek

# NixOS or non-NixOS without flakes:
nix-env -iA nixos.prek

# Non-NixOS with flakes:
nix profile install nixpkgs#prek&lt;/code&gt;
    &lt;head&gt;GitHub Releases&lt;/head&gt;
    &lt;p&gt;Pre-built binaries are available for download from the GitHub releases page.&lt;/p&gt;
    &lt;head&gt;GitHub Actions&lt;/head&gt;
    &lt;p&gt;prek can be used in GitHub Actions via the j178/prek-action repository.&lt;/p&gt;
    &lt;p&gt;Example workflow:&lt;/p&gt;
    &lt;code&gt;name: Prek checks
on: [push, pull_request]

jobs:
  prek:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - uses: j178/prek-action@v1&lt;/code&gt;
    &lt;p&gt;This action installs prek and runs &lt;code&gt;prek run --all-files&lt;/code&gt; on your repository.&lt;/p&gt;
    &lt;p&gt;prek is also available via &lt;code&gt;taiki-e/install-action&lt;/code&gt; for installing various tools.&lt;/p&gt;
    &lt;p&gt;If installed via the standalone installer, prek can update itself to the latest version:&lt;/p&gt;
    &lt;code&gt;prek self update&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I already use pre-commit: follow the short migration checklist in the quickstart guide to swap in &lt;code&gt;prek&lt;/code&gt;safely.&lt;/item&gt;
      &lt;item&gt;I'm new to pre-commit-style tools: learn the basics‚Äîcreating a config, running hooks, and installing git hooks‚Äîin the beginner quickstart walkthrough.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It is multiple times faster than &lt;code&gt;pre-commit&lt;/code&gt;and takes up half the disk space.&lt;/item&gt;
      &lt;item&gt;It redesigned how hook environments and toolchains are managed, they are all shared between hooks, which reduces the disk space usage and speeds up the installation process.&lt;/item&gt;
      &lt;item&gt;Repositories are cloned in parallel, and hooks are installed in parallel if their dependencies are disjoint.&lt;/item&gt;
      &lt;item&gt;Hooks can run in parallel by priority (hooks with the same &lt;code&gt;priority&lt;/code&gt;may run concurrently), reducing end-to-end runtime.&lt;/item&gt;
      &lt;item&gt;It uses &lt;code&gt;uv&lt;/code&gt;for creating Python virtualenvs and installing dependencies, which is known for its speed and efficiency.&lt;/item&gt;
      &lt;item&gt;It implements some common hooks in Rust, built in prek, which are faster than their Python counterparts.&lt;/item&gt;
      &lt;item&gt;It supports &lt;code&gt;repo: builtin&lt;/code&gt;for offline, zero-setup hooks, which is not available in&lt;code&gt;pre-commit&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No need to install Python or any other runtime, just download a single binary.&lt;/item&gt;
      &lt;item&gt;No hassle with your Python version or virtual environments, prek automatically installs the required Python version and creates a virtual environment for you.&lt;/item&gt;
      &lt;item&gt;Built-in support for workspaces (or monorepos), each subproject can have its own &lt;code&gt;.pre-commit-config.yaml&lt;/code&gt;file.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;prek run&lt;/code&gt;has some nifty improvements over&lt;code&gt;pre-commit run&lt;/code&gt;, such as:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;prek run --directory &amp;lt;dir&amp;gt;&lt;/code&gt;runs hooks for files in the specified directory, no need to use&lt;code&gt;git ls-files -- &amp;lt;dir&amp;gt; | xargs pre-commit run --files&lt;/code&gt;anymore.&lt;/item&gt;&lt;item&gt;&lt;code&gt;prek run --last-commit&lt;/code&gt;runs hooks for files changed in the last commit.&lt;/item&gt;&lt;item&gt;&lt;code&gt;prek run [HOOK] [HOOK]&lt;/code&gt;selects and runs multiple hooks.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;prek list&lt;/code&gt;command lists all available hooks, their ids, and descriptions, providing a better overview of the configured hooks.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;prek auto-update&lt;/code&gt;supports&lt;code&gt;--cooldown-days&lt;/code&gt;to mitigate open source supply chain attacks.&lt;/item&gt;
      &lt;item&gt;prek provides shell completions for &lt;code&gt;prek run &amp;lt;hook_id&amp;gt;&lt;/code&gt;command, making it easier to run specific hooks without remembering their ids.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more detailed improvements prek offers, take a look at Difference from pre-commit.&lt;/p&gt;
    &lt;p&gt;prek is pretty new, but it is already being used or recommend by some projects and organizations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;apache/airflow&lt;/item&gt;
      &lt;item&gt;python/cpython&lt;/item&gt;
      &lt;item&gt;pdm-project/pdm&lt;/item&gt;
      &lt;item&gt;fastapi/fastapi&lt;/item&gt;
      &lt;item&gt;fastapi/typer&lt;/item&gt;
      &lt;item&gt;fastapi/asyncer&lt;/item&gt;
      &lt;item&gt;astral-sh/ruff&lt;/item&gt;
      &lt;item&gt;astral-sh/ty&lt;/item&gt;
      &lt;item&gt;openclaw/openclaw&lt;/item&gt;
      &lt;item&gt;home-assistant/core&lt;/item&gt;
      &lt;item&gt;DetachHead/basedpyright&lt;/item&gt;
      &lt;item&gt;OpenLineage/OpenLineage&lt;/item&gt;
      &lt;item&gt;authlib/authlib&lt;/item&gt;
      &lt;item&gt;django/djangoproject.com&lt;/item&gt;
      &lt;item&gt;Future-House/paper-qa&lt;/item&gt;
      &lt;item&gt;requests-cache/requests-cache&lt;/item&gt;
      &lt;item&gt;Goldziher/kreuzberg&lt;/item&gt;
      &lt;item&gt;python-attrs/attrs&lt;/item&gt;
      &lt;item&gt;jlowin/fastmcp&lt;/item&gt;
      &lt;item&gt;apache/iceberg-python&lt;/item&gt;
      &lt;item&gt;apache/lucene&lt;/item&gt;
      &lt;item&gt;jcrist/msgspec&lt;/item&gt;
      &lt;item&gt;python-humanize/humanize&lt;/item&gt;
      &lt;item&gt;MoonshotAI/kimi-cli&lt;/item&gt;
      &lt;item&gt;simple-icons/simple-icons&lt;/item&gt;
      &lt;item&gt;ast-grep/ast-grep&lt;/item&gt;
      &lt;item&gt;commitizen-tools/commitizen&lt;/item&gt;
      &lt;item&gt;cocoindex-io/cocoindex&lt;/item&gt;
      &lt;item&gt;cachix/devenv&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is heavily inspired by the original pre-commit tool, and it wouldn't be possible without the hard work of the maintainers and contributors of that project.&lt;/p&gt;
    &lt;p&gt;And a special thanks to the Astral team for their remarkable projects, particularly uv, from which I've learned a lot on how to write efficient and idiomatic Rust code.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46873138</guid><pubDate>Tue, 03 Feb 2026 16:29:34 +0000</pubDate></item><item><title>France dumps Zoom and Teams as Europe seeks digital autonomy from the US</title><link>https://apnews.com/article/europe-digital-sovereignty-big-tech-9f5388b68a0648514cebc8d92f682060</link><description>&lt;doc fingerprint="af50b110b70b4885"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;France dumps Zoom and Teams as Europe seeks digital autonomy from the US&lt;/head&gt;
    &lt;head rend="h2"&gt;France dumps Zoom and Teams as Europe seeks digital autonomy from the US&lt;/head&gt;
    &lt;p&gt;LONDON (AP) ‚Äî In France, civil servants will ditch Zoom and Teams for a homegrown video conference system. Soldiers in Austria are using open source office software to write reports after the military dropped Microsoft Office. Bureaucrats in a German state have also turned to free software for their administrative work.&lt;/p&gt;
    &lt;p&gt;Around Europe, governments and institutions are seeking to reduce their use of digital services from U.S. Big Tech companies and turning to domestic or free alternatives. The push for ‚Äúdigital sovereignty‚Äù is gaining attention as the Trump administration strikes an increasingly belligerent posture toward the continent, highlighted by recent tensions over Greenland that intensified fears that Silicon Valley giants could be compelled to cut off access.&lt;/p&gt;
    &lt;p&gt;Concerns about data privacy and worries that Europe is not doing enough to keep up with the United States and Chinese tech leadership are also fueling the drive.&lt;/p&gt;
    &lt;p&gt;The French government referenced some of these concerns when it announced last week that 2.5 million civil servants would stop using video conference tools from U.S. providers ‚Äî including Zoom, Microsoft Teams, Webex and GoTo Meeting ‚Äî by 2027 and switch to Visio, a homegrown service.&lt;/p&gt;
    &lt;p&gt;The objective is ‚Äúto put an end to the use of non-European solutions, to guarantee the security and confidentiality of public electronic communications by relying on a powerful and sovereign tool,‚Äù the announcement said.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe cannot risk having our scientific exchanges, our sensitive data, and our strategic innovations exposed to non-European actors,‚Äù David Amiel, a civil service minister, said in a press release.&lt;/p&gt;
    &lt;p&gt;Microsoft said it continues to ‚Äúpartner closely with the government in France and respect the importance of security, privacy, and digital trust for public institutions.‚Äù&lt;/p&gt;
    &lt;p&gt;The company said it is ‚Äúfocused on providing customers with greater choice, stronger data protection, and resilient cloud services ‚Äî ensuring data stays in Europe, under European law, with robust security and privacy protections.‚Äù&lt;/p&gt;
    &lt;p&gt;Zoom, Webex and GoTo Meeting did not respond to requests for comment.&lt;/p&gt;
    &lt;p&gt;French President Emmanuel Macron has been pushing digital sovereignty for years. But there‚Äôs now a lot more ‚Äúpolitical momentum behind this idea now that we need to de-risk from U.S. tech,‚Äù Nick Reiners, senior geotechnology analyst at the Eurasia Group.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt feels kind of like there‚Äôs a real zeitgeist shift,‚Äù Reiners said&lt;/p&gt;
    &lt;p&gt;It was a hot topic at the World Economic Forum‚Äôs annual meeting of global political and business elites last month in Davos, Switzerland. The European Commission‚Äôs official for tech sovereignty, Henna Virkkunen, told an audience that Europe‚Äôs reliance on others ‚Äúcan be weaponized against us.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúThat‚Äôs why it‚Äôs so important that we are not dependent on one country or one company when it comes to very critical fields of our economy or society,‚Äù she said, without naming countries or companies.&lt;/p&gt;
    &lt;p&gt;A decisive moment came last year when the Trump administration sanctioned the International Criminal Court‚Äôs top prosecutor after the tribunal, based in The Hague, Netherlands, issued an arrest warrant for Israeli Prime Minister Benjamin Netanyahu, an ally of President Donald Trump.&lt;/p&gt;
    &lt;p&gt;The sanctions led Microsoft to cancel Khan‚Äôs ICC email, a move that was first reported by The Associated Press and sparked fears of a ‚Äúkill switch‚Äù that Big Tech companies can use to turn off service at will.&lt;/p&gt;
    &lt;p&gt;Microsoft maintains it kept in touch with the ICC ‚Äúthroughout the process that resulted in the disconnection of its sanctioned official from Microsoft services. At no point did Microsoft cease or suspend its services to the ICC.‚Äù&lt;/p&gt;
    &lt;p&gt;Microsoft President Brad Smith has repeatedly sought to strengthen trans-Atlantic ties, the company‚Äôs press office said, and pointed to an interview he did last month with CNN in Davos in which he said that jobs, trade and investment. as well as security, would be affected by a rift over Greenland.&lt;/p&gt;
    &lt;p&gt;‚ÄúEurope is the American tech sector‚Äôs biggest market after the United States itself. It all depends on trust. Trust requires dialogue,‚Äù Smith said.&lt;/p&gt;
    &lt;p&gt;Other incidents have added to the movement. There‚Äôs a growing sense that repeated EU efforts to rein in tech giants such as Google with blockbuster antitrust fines and sweeping digital rule books haven‚Äôt done much to curb their dominance.&lt;/p&gt;
    &lt;p&gt;Billionaire Elon Musk is also a factor. Officials worry about relying on his Starlink satellite internet system for communications in Ukraine.&lt;/p&gt;
    &lt;p&gt;Washington and Brussels wrangled for years over data transfer agreements, triggered by former National Security Agency contractor Edward Snowden‚Äôs revelations of U.S. cyber-snooping.&lt;/p&gt;
    &lt;p&gt;With online services now mainly hosted in the cloud through data centers, Europeans fear that their data is vulnerable.&lt;/p&gt;
    &lt;p&gt;U.S. cloud providers have responded by setting up so-called ‚Äúsovereign cloud‚Äù operations, with data centers located in European countries, owned by European entities and with physical and remote access only for staff who are European Union residents.&lt;/p&gt;
    &lt;p&gt;The idea is that ‚Äúonly Europeans can take decisions so that they can‚Äôt be coerced by the U.S.,‚Äù Reiners said.&lt;/p&gt;
    &lt;p&gt;The German state of Schleswig-Holstein last year migrated 44,000 employee inboxes from Microsoft to an open source email program. It also switched from Microsoft‚Äôs SharePoint file sharing system to Nextcloud, an open source platform, and is even considering replacing Windows with Linux and telephones and videoconferencing with open source systems.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe want to become independent of large tech companies and ensure digital sovereignty,‚Äù Digitalization Minister Dirk Schr√∂dter said in an October announcement.&lt;/p&gt;
    &lt;p&gt;The French city of Lyon said last year that it‚Äôs deploying free office software to replace Microsoft. Denmark‚Äôs government and the cities of Copenhagen and Aarhus have also been trying out open-source software.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe must never make ourselves so dependent on so few that we can no longer act freely,‚Äù Digital Minister Caroline Stage Olsen wrote on LinkedIn last year. ‚ÄúToo much public digital infrastructure is currently tied up with very few foreign suppliers.‚Äù&lt;/p&gt;
    &lt;p&gt;The Austrian military said it has also switched to LibreOffice, a software package with word processor, spreadsheet and presentation programs that mirrors Microsoft 365‚Äôs Word, Excel and PowerPoint.&lt;/p&gt;
    &lt;p&gt;The Document Foundation, a nonprofit based in Germany that‚Äôs behind LibreOffice, said the military‚Äôs switch ‚Äúreflects a growing demand for independence from single vendors.‚Äù Reports also said the military was concerned that Microsoft was moving file storage online to the cloud ‚Äî the standard version of LibreOffice is not cloud-based.&lt;/p&gt;
    &lt;p&gt;Some Italian cities and regions adopted the software years ago, said Italo Vignoli, a spokesman for The Document Foundation. Back then, the appeal was not needing to pay for software licenses. Now, it‚Äôs the main reason is to avoid being locked into a proprietary system.&lt;/p&gt;
    &lt;p&gt;‚ÄúAt first, it was: we will save money and by the way, we will get freedom,‚Äù Vignoli said. ‚ÄúToday it is: we will be free and by the way, we will also save some money.‚Äù&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;Associated Press writer Molly Quell in The Hague, Netherlands contributed to this report.&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;This version corrects the contribution line to Molly Quell instead of Molly Hague.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46873294</guid><pubDate>Tue, 03 Feb 2026 16:39:18 +0000</pubDate></item><item><title>Show HN: Octosphere, a tool to decentralise scientific publishing</title><link>https://octosphere.social/</link><description>&lt;doc fingerprint="f9dc5bdd087c8698"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Octosphere&lt;/head&gt;
    &lt;p&gt;Connecting open science with the social web&lt;/p&gt;
    &lt;head rend="h2"&gt;What is Octosphere?&lt;/head&gt;
    &lt;p&gt;Octosphere bridges the gap between academic publishing and the social web. It automatically syncs your research publications from Octopus to the AT Protocol (the atmosphere) ‚Äî an open, decentralized network for social apps like Bluesky.&lt;/p&gt;
    &lt;p&gt;By sharing your work on the atmosphere, you can reach broader audiences, engage with the public, and increase the visibility of your research beyond traditional academic channels.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Sign in with ORCID ‚Äî Authenticate using your researcher identifier.&lt;/item&gt;
      &lt;item&gt;Connect to the atmosphere ‚Äî Sign in with your Bluesky account (or any AT Protocol app).&lt;/item&gt;
      &lt;item&gt;Link your Octopus profile ‚Äî Connect your Octopus author page.&lt;/item&gt;
      &lt;item&gt;Sync your publications ‚Äî Choose one-time sync or enable automatic syncing of future publications.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46873782</guid><pubDate>Tue, 03 Feb 2026 17:11:42 +0000</pubDate></item><item><title>Defining Safe Hardware Design [pdf]</title><link>https://people.csail.mit.edu/rachit/files/pubs/safe-hdls.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46873790</guid><pubDate>Tue, 03 Feb 2026 17:12:04 +0000</pubDate></item><item><title>Migrate Wizard ‚Äì IMAP Based Email Migration Tool</title><link>https://migratewizard.com/#features</link><description>&lt;doc fingerprint="8cfa0d9d71ab0df"&gt;
  &lt;main&gt;
    &lt;p&gt;Trusted by teams around the world&lt;/p&gt;
    &lt;head rend="h1"&gt;Migrate Your Emails in&lt;lb/&gt;Minutes, Not Days&lt;/head&gt;
    &lt;p&gt;The fastest, most secure IMAP migration service. Move gigabytes of emails between any providers with zero downtime and 100% data integrity.&lt;/p&gt;
    &lt;p&gt;No technical expertise required. No data loss. No headaches.&lt;/p&gt;
    &lt;p&gt;10K+&lt;/p&gt;
    &lt;p&gt;Successful Migrations&lt;/p&gt;
    &lt;p&gt;99.9%&lt;/p&gt;
    &lt;p&gt;Success Rate&lt;/p&gt;
    &lt;p&gt;5min&lt;/p&gt;
    &lt;p&gt;Average Time&lt;/p&gt;
    &lt;p&gt;24/7&lt;/p&gt;
    &lt;p&gt;Support&lt;/p&gt;
    &lt;head rend="h2"&gt;Everything You Need for a Perfect Migration&lt;/head&gt;
    &lt;p&gt;Built for speed, security, and reliability. Trusted by businesses of all sizes.&lt;/p&gt;
    &lt;p&gt;Lightning Fast&lt;/p&gt;
    &lt;p&gt;Optimized algorithms move gigabytes of data in minutes, not days. Parallel processing ensures maximum speed.&lt;/p&gt;
    &lt;p&gt;Enterprise-Grade Security&lt;/p&gt;
    &lt;p&gt;Credentials encrypted and deleted when the migration finishes, with enterprise-grade infrastructure.&lt;/p&gt;
    &lt;p&gt;100% Data Integrity&lt;/p&gt;
    &lt;p&gt;Advanced error handling and verification ensures every email, folder, and attachment is perfectly migrated.&lt;/p&gt;
    &lt;p&gt;Zero Downtime&lt;/p&gt;
    &lt;p&gt;Continue using your email during migration. No service interruption, no business disruption.&lt;/p&gt;
    &lt;p&gt;No Credential Storage&lt;/p&gt;
    &lt;p&gt;Your passwords are encrypted in memory only and deleted immediately after migration completes.&lt;/p&gt;
    &lt;p&gt;Incremental Sync&lt;/p&gt;
    &lt;p&gt;Keep your emails synchronized after initial migration. Perfect for ongoing data consistency.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for Every Scenario&lt;/head&gt;
    &lt;p&gt;Whether you're switching providers or consolidating accounts, we've got you covered.&lt;/p&gt;
    &lt;p&gt;Provider Migration&lt;/p&gt;
    &lt;p&gt;Switching from Gmail, Outlook, Yahoo, or any IMAP provider? We handle it seamlessly with zero data loss.&lt;/p&gt;
    &lt;p&gt;Account Consolidation&lt;/p&gt;
    &lt;p&gt;Merge multiple email accounts into one. Perfect for businesses consolidating their communication.&lt;/p&gt;
    &lt;p&gt;Backup &amp;amp; Archive&lt;/p&gt;
    &lt;p&gt;Create secure backups of your entire email history. Essential for compliance and disaster recovery.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ready to Migrate Your Emails?&lt;/head&gt;
    &lt;p&gt;Join thousands of satisfied customers who've migrated millions of emails with Migrate Wizard.&lt;/p&gt;
    &lt;p&gt;No credit card required ‚Ä¢ Free trial available ‚Ä¢ Cancel anytime&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46873885</guid><pubDate>Tue, 03 Feb 2026 17:19:47 +0000</pubDate></item><item><title>Deno Sandbox</title><link>https://deno.com/blog/introducing-deno-sandbox</link><description>&lt;doc fingerprint="84be1f18cd2fafa2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Deno Sandbox&lt;/head&gt;
    &lt;p&gt;Over the past year, we‚Äôve seen a shift in what Deno Deploy customers are building: platforms where users generate code with LLMs, and that code runs immediately without review. That code frequently calls LLMs itself, which means it needs API keys and network access.&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt the traditional ‚Äúrun untrusted plugins‚Äù problem. It‚Äôs deeper: LLM-generated code, calling external APIs with real credentials, without human review. Sandboxing the compute isn‚Äôt enough. You need to control network egress and protect secrets from exfiltration.&lt;/p&gt;
    &lt;p&gt;Deno Sandbox provides both. And when the code is ready, you can deploy it directly to Deno Deploy without rebuilding.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sandboxes?&lt;/head&gt;
    &lt;p&gt;You don‚Äôt want to run untrusted code (generated by your LLMs, your users LLMs, or even hand written by users) directly on your server. It will compromise your system, steal your API keys, and call out to evil.com. You need isolation.&lt;/p&gt;
    &lt;p&gt;Deno Sandbox gives you lightweight Linux microVMs (running in the Deno Deploy cloud) to run untrusted code with defense-in-depth security. You create or programmatically via our JavaScript or Python SDKs, and they boot in under a second. You can also interact with them via SSH, HTTP, or even open a VS Code window directly into the sandbox.&lt;/p&gt;
    &lt;code&gt;import { Sandbox } from "@deno/sandbox";

await using sandbox = await Sandbox.create();
await sandbox.sh`ls -lh /`;&lt;/code&gt;
    &lt;head rend="h2"&gt;Secrets That Can‚Äôt Be Stolen&lt;/head&gt;
    &lt;p&gt;But there is more. In Deno Sandbox, secrets never enter the environment. Code sees only a placeholder:&lt;/p&gt;
    &lt;code&gt;import { Sandbox } from "@deno/sandbox";

await using sandbox = await Sandbox.create({
  secrets: {
    OPENAI_API_KEY: {
      hosts: ["api.openai.com"],
      value: process.env.OPENAI_API_KEY,
    },
  },
});

await sandbox.sh`echo $OPENAI_API_KEY`;
// DENO_SECRET_PLACEHOLDER_b14043a2f578cba75ebe04791e8e2c7d4002fd0c1f825e19...&lt;/code&gt;
    &lt;p&gt;The real key materializes only when the sandbox makes an outbound request to an approved host. If prompt-injected code tries to exfiltrate that placeholder to &lt;code&gt;evil.com&lt;/code&gt;? Useless.&lt;/p&gt;
    &lt;head rend="h2"&gt;Network Egress Control&lt;/head&gt;
    &lt;p&gt;You can also restrict which hosts the sandbox can talk to:&lt;/p&gt;
    &lt;code&gt;await using sandbox = await Sandbox.create({
  allowNet: ["api.openai.com", "*.anthropic.com"],
});&lt;/code&gt;
    &lt;p&gt;Any request to an unlisted host gets blocked at the VM boundary.&lt;/p&gt;
    &lt;p&gt;Both features are implemented via an outbound proxy similar to coder/httpjail. This gives us a chokepoint for policy enforcement. We plan to add more capabilities here: analytics for outbound connections and programmatic hooks for trusted code to inspect or modify requests.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre running untrusted JavaScript or TypeScript, combine this with Deno‚Äôs &lt;code&gt;--allow-net&lt;/code&gt; flag for defense in depth: VM-level network restrictions plus
runtime-level permissions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sandbox to Production&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;sandbox.deploy()&lt;/code&gt; deploys code from your sandbox directly to Deno Deploy.&lt;/p&gt;
    &lt;code&gt;const build = await sandbox.deploy("my-app", {
  production: true,
  build: { mode: "none", entrypoint: "server.ts" },
});

const revision = await build.done;
console.log(revision.url);&lt;/code&gt;
    &lt;p&gt;One call to go from sandbox to production deployment. No rebuilding in a different CI system, no re-authenticating with a different tool. Just turn your dev environment directly into a production ready, auto-scaling serverless deployment.&lt;/p&gt;
    &lt;head rend="h2"&gt;Persistence&lt;/head&gt;
    &lt;p&gt;Sandboxes are ephemeral by default, but when you need state we have you covered:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Volumes: read-write storage for caches, databases, user data&lt;/item&gt;
      &lt;item&gt;Snapshots: read-only images for pre-installed toolchains and volume base&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run &lt;code&gt;apt-get install&lt;/code&gt; once, snapshot it, and every future sandbox boots with
everything already installed. Create read-write volumes from the snapshots to
create a fresh development environment in seconds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical Details&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Spec&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Regions&lt;/cell&gt;
        &lt;cell&gt;Amsterdam, Chicago&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vCPUs&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memory&lt;/cell&gt;
        &lt;cell&gt;768 MB - 4 GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Lifetime&lt;/cell&gt;
        &lt;cell&gt;Ephemeral or timeout (supports extending on demand)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Max lifetime&lt;/cell&gt;
        &lt;cell&gt;30 minutes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Boot time&lt;/cell&gt;
        &lt;cell&gt;&amp;lt; 1 second&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Perfect for AI agents executing code, vibe-coding environments, secure plugin systems, ephemeral CI runners, and customer-supplied code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Pricing&lt;/head&gt;
    &lt;p&gt;Deno Sandbox is included in your Deno Deploy plan with competitive, usage-based pricing. You pay for compute time, not wall-clock time.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;$0.05/h CPU time (40h included with Pro)&lt;/item&gt;
      &lt;item&gt;$0.016/GB-h memory (1000 GB-h included with Pro)&lt;/item&gt;
      &lt;item&gt;$0.20/GiB-month volume storage (5 GiB included with Pro)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Enterprise pricing available‚Äîcontact deploy@deno.com.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get Started&lt;/head&gt;
    &lt;p&gt;Deno Sandbox launches in beta today, alongside the general availability of Deno Deploy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Landing page: deno.com/sandbox&lt;/item&gt;
      &lt;item&gt;Docs: docs.deno.com/sandbox&lt;/item&gt;
      &lt;item&gt;JavaScript SDK: jsr.io/@deno/sandbox or npm&lt;/item&gt;
      &lt;item&gt;Python SDK: pypi.org/project/deno-sandbox&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We‚Äôre excited to see what you (or your AI agents) build with Deno Sandbox.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46874097</guid><pubDate>Tue, 03 Feb 2026 17:33:20 +0000</pubDate></item><item><title>Sandboxing AI Agents in Linux</title><link>https://blog.senko.net/sandboxing-ai-agents-in-linux</link><description>&lt;doc fingerprint="7d9ab85b0e859780"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Sandboxing AI agents in Linux&lt;/head&gt;
    &lt;p&gt;Like many developers, I find myself more and more using AI agents to help with software development.&lt;/p&gt;
    &lt;p&gt;I currently use Claude Code, the command line interface, together with Opus 4.5 (Anthropic's top model as of this writing). I use it to distill my rough task requirements into a detailed development plan, then implement the plan.&lt;/p&gt;
    &lt;p&gt;By default, Claude Code asks each time if it may read and write files and run software. This is sensible default configuration, but does get annoying after a time. Worse, it interrupts me often enough that I can't do much in parallel while babysitting it.&lt;/p&gt;
    &lt;p&gt;There's also a &lt;code&gt;--dangerously-skip-permissions&lt;/code&gt; (a.k.a. ‚ÄúYOLO‚Äù) mode which will happily run anything without asking. This can be risky (although I know of some people that run it like that and still haven't destroyed their dev machines).&lt;/p&gt;
    &lt;head rend="h2"&gt;Sandboxing&lt;/head&gt;
    &lt;p&gt;The standard solution is to sandbox the agent ‚Äì either on a remote machine (exe.dev, sprites.dev, daytona.io), or locally via Docker or other virtualization mechanism.&lt;/p&gt;
    &lt;p&gt;A lightweight alternative on Linux is bubblewrap, which uses Linux kernel features like cgroups and user namespaces to limit (jail) a process.&lt;/p&gt;
    &lt;p&gt;As it turns out, bubblewrap is a good solution for lightweight sandboxing of AI agents. Here's what I personally need from such a solution:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;mimic my regular Linux dev machine setup (I don't want to manage multiple dev environment)&lt;/item&gt;
      &lt;item&gt;minimal/no access to information outside what's required for the current project&lt;/item&gt;
      &lt;item&gt;write access only to the current project&lt;/item&gt;
      &lt;item&gt;can directly operate on the files/folders of the project so I can easily inspect or modify the same files from my IDE or run the code myself&lt;/item&gt;
      &lt;item&gt;network access ‚Äì both to connect to AI providers and search the internet, and to be able to start a server that I can connect to&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bubblewrap and Docker are not hardened security isolation mechanisms, but that's okay with me. I'm not really concerned about the following risks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;escape via zero-day Linux kernel bug&lt;/item&gt;
      &lt;item&gt;covert side channel communications&lt;/item&gt;
      &lt;item&gt;exfiltration of data from current project (including project-specific access keys)&lt;/item&gt;
      &lt;item&gt;screwing up the codebase (the code is managed via &lt;code&gt;git&lt;/code&gt;and backed up at GitHub or elsewhere)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The last bit is tricky, but even full remote sandboxes can't protect against that. In theory, we could have transparent API proxies that would inject proper access keys without the AI agent ever being aware of it, but this is really non-trivial to set up right now.&lt;/p&gt;
    &lt;p&gt;An alternative is to contain potential damage by creating project-specific API keys so at least the blast area is minimal if those keys are leaked.&lt;/p&gt;
    &lt;head rend="h2"&gt;In practice&lt;/head&gt;
    &lt;p&gt;Here's how my bubblewrap sandbox script looks:&lt;/p&gt;
    &lt;code&gt;#!/usr/bin/bash

exec 3&amp;lt;$HOME/.claude.json

exec /usr/bin/bwrap \
    --tmpfs /tmp \
    --dev /dev \
    --proc /proc \
    --hostname bubblewrap --unshare-uts \
    --ro-bind /bin /bin \
    --ro-bind /lib /lib \
    --ro-bind /lib32 /lib32 \
    --ro-bind /lib64 /lib64 \
    --ro-bind /usr/bin /usr/bin \
    --ro-bind /usr/lib /usr/lib \
    --ro-bind /usr/local/bin /usr/local/bin \
    --ro-bind /usr/local/lib /usr/local/lib \
    --ro-bind /opt/node/node-v22.11.0-linux-x64/ /opt/node/node-v22.11.0-linux-x64/ \
    --ro-bind /etc/alternatives /etc/alternatives \
    --ro-bind /etc/resolv.conf /etc/resolv.conf \
    --ro-bind /etc/profile.d /etc/profile.d \
    --ro-bind /etc/bash_completion.d /etc/bash_completion.d \
    --ro-bind /etc/ssl/certs /etc/ssl/certs \
    --ro-bind /etc/ld.so.cache /etc/ld.so.cache \
    --ro-bind /etc/ld.so.conf /etc/ld.so.conf \
    --ro-bind /etc/ld.so.conf.d /etc/ld.so.conf.d \
    --ro-bind /etc/localtime /etc/localtime \
    --ro-bind /usr/share/terminfo /usr/share/terminfo \
    --ro-bind /usr/share/ca-certificates /usr/share/ca-certificates \
    --ro-bind /etc/nsswitch.conf /etc/nsswitch.conf \
    --ro-bind /etc/hosts /etc/hosts \
    --ro-bind /etc/ssl/openssl.cnf /etc/ssl/openssl.cnf \
    --ro-bind /usr/share/zoneinfo /usr/share/zoneinfo \
    --ro-bind $HOME/.bashrc $HOME/.bashrc \
    --ro-bind $HOME/.profile $HOME/.profile \
    --ro-bind $HOME/.gitconfig $HOME/.gitconfig \
    --ro-bind $HOME/.local $HOME/.local \
    --bind $HOME/.claude $HOME/.claude \
    --bind $HOME/.cache $HOME/.cache \
    --file 3 $HOME/.claude.json \
    --bind "$PWD" "$PWD" \
    claude --dangerously-skip-permissions $@
&lt;/code&gt;
    &lt;p&gt;If this looks rather idiosyncratic, it's because it is. Rather than using some generic rules, I experimented with &lt;code&gt;bwrap&lt;/code&gt; until I found minimal configuration that I need to set up for my system.&lt;/p&gt;
    &lt;p&gt;Some interesting stuff:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/tmp&lt;/code&gt;,&lt;code&gt;/proc&lt;/code&gt;and&lt;code&gt;/dev&lt;/code&gt;are automatically handled by&lt;code&gt;bwrap&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;I bind-mount (ie. expose) files and directories under the same path as local machine, so there's no difference in file locations, project paths, etc&lt;/item&gt;
      &lt;item&gt;I don't expose entire &lt;code&gt;/etc&lt;/code&gt;, just the bare minimum&lt;/item&gt;
      &lt;item&gt;The content of &lt;code&gt;$HOME/.claude.json&lt;/code&gt;is injected into the sandbox so any changes there won't get saved to the real one&lt;/item&gt;
      &lt;item&gt;The content of &lt;code&gt;$HOME/.claude/&lt;/code&gt;directory is mapped read-write, so Claude can save and modify files there (such as session data)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/opt/node/node-v22.11.0-linux-x64/&lt;/code&gt;is my custom&lt;code&gt;nodejs&lt;/code&gt;install location&lt;/item&gt;
      &lt;item&gt;I change the hostname so it's easy to distinguish between the host and sandbox&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I will probably be tweaking the script as needed, but this is a pretty good starting point for me.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to customize&lt;/head&gt;
    &lt;p&gt;If you want to adapt this to another AI agent or to your system, my suggestion is to tweak the script to run &lt;code&gt;bash&lt;/code&gt; instead, then run your agent manually, see what breaks and tweak as appropriate.&lt;/p&gt;
    &lt;p&gt;A useful command for this is &lt;code&gt;strace&lt;/code&gt;, which can trace file access system calls so you can see what's needed:&lt;/p&gt;
    &lt;code&gt;strace -e trace=open,openat,stat,statx,access -o /tmp/strace.log codex
&lt;/code&gt;
    &lt;p&gt;Inspecting the log you can spot which files are needed and bind them as needed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46874139</guid><pubDate>Tue, 03 Feb 2026 17:35:37 +0000</pubDate></item><item><title>Xcode 26.3 unlocks the power of agentic coding</title><link>https://www.apple.com/newsroom/2026/02/xcode-26-point-3-unlocks-the-power-of-agentic-coding/</link><description>&lt;doc fingerprint="bd64c349434690ed"&gt;
  &lt;main&gt;
    &lt;p&gt; UPDATE February 3, 2026 &lt;/p&gt;
    &lt;head rend="h1"&gt;Xcode 26.3 unlocks the power of agentic coding&lt;/head&gt;
    &lt;p&gt; Developers can leverage coding agents, including Anthropic‚Äôs Claude Agent and OpenAI‚Äôs Codex, directly in Xcode to tackle complex tasks autonomously, helping them develop apps faster than ever &lt;/p&gt;
    &lt;p&gt;Xcode 26.3 introduces support for agentic coding, a new way in Xcode for developers to build apps using coding agents such as Anthropic‚Äôs Claude Agent and OpenAI‚Äôs Codex. With agentic coding, Xcode can work with greater autonomy toward a developer‚Äôs goals ‚Äî from breaking down tasks to making decisions based on the project architecture and using built-in tools. &lt;/p&gt;
    &lt;p&gt;Expanding on the intelligence features introduced in Xcode 26, which brought a brand-new coding assistant for writing and editing in Swift, this release gives coding agents access to even more of Xcode‚Äôs capabilities. Agents like Claude Agent and Codex can now collaborate throughout the entire development life cycle, giving developers the power to streamline workflows, iterate faster, and bring ideas to life like never before. Agents can search documentation, explore file structures, update project settings, and verify their work visually by capturing Xcode Previews and iterating through builds and fixes. &lt;/p&gt;
    &lt;p&gt;‚ÄúAt Apple, our goal is to make tools that put industry-leading technologies directly in developers‚Äô hands so they can build the very best apps,‚Äù said Susan Prescott, Apple‚Äôs vice president of Worldwide Developer Relations. ‚ÄúAgentic coding supercharges productivity and creativity, streamlining the development workflow so developers can focus on innovation.‚Äù &lt;/p&gt;
    &lt;p&gt;With seamless access to Claude Agent and Codex, developers can bring the advanced reasoning of these models directly into their app-building workflow.1 This connection combines the power of these agents with Xcode‚Äôs native capabilities to provide the best results when developing for Apple platforms, giving developers the flexibility to work with the model that best fits their project. &lt;/p&gt;
    &lt;p&gt;In addition to these built-in integrations, Xcode 26.3 makes its capabilities available through the Model Context Protocol, an open standard that gives developers the flexibility to use any compatible agent or tool with Xcode. &lt;/p&gt;
    &lt;p&gt;Availability &lt;/p&gt;
    &lt;p&gt;Xcode 26.3 is available as a release candidate for all members of the Apple Developer Program starting today, with a release coming soon on the App Store. &lt;/p&gt;
    &lt;p&gt;Share article&lt;/p&gt;
    &lt;head rend="h2"&gt;Media&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Text of this article&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Images in this article&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Anthropic and OpenAI‚Äôs terms of service may apply.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46874619</guid><pubDate>Tue, 03 Feb 2026 18:04:08 +0000</pubDate></item><item><title>AliSQL: Alibaba's open-source MySQL with vector and DuckDB engines</title><link>https://github.com/alibaba/AliSQL</link><description>&lt;doc fingerprint="3f90b0c4553671e2"&gt;
  &lt;main&gt;
    &lt;p&gt;AliSQL is Alibaba's MySQL branch, forked from official MySQL and used extensively in Alibaba Group's production environment. It includes various performance optimizations, stability improvements, and features tailored for large-scale applications.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Quickly build your DuckDB node: How to set up a DuckDB node&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AliSQL Version: 8.0.44 (LTS)&lt;/item&gt;
      &lt;item&gt;Based on: MySQL 8.0.44&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;DuckDB Storage Engine:AliSQL integrates DuckDB as a native storage engine, allowing users to operate DuckDB with the same experience as MySQL. By leveraging AliSQL for rapid deployment of DuckDB service nodes, users can easily achieve lightweight analytical capabilities.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vector Storage:AliSQL natively supports enterprise-grade vector processing for up to 16,383 dimensions. By integrating a highly optimized HNSW algorithm for high-performance Approximate Nearest Neighbor (ANN) search, AliSQL empowers users to build AI-driven applications‚Äîsuch as semantic search and recommendation systems‚Äîseamlessly using standard SQL interfaces.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;DDL Optimization (planned):AliSQL delivers a faster, safer, and lighter DDL experience through innovations such as enhanced Instant DDL, parallel B+tree construction, a non-blocking lock mechanism, and real-time DDL apply‚Äîsignificantly improving schema change efficiency and virtually eliminating replication lag.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;RTO Optimization (planned):AliSQL deeply optimizes the end-to-end crash recovery path to accelerate instance startup, shorten RTO, and restore service quickly.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Replication Optimization (planned): AliSQL significantly boosts replication throughput and minimizes lag by implementing Binlog Parallel Flush, Binlog in Redo, and specialized optimizations for large transactions and DDL operations.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CMake 3.x or higher&lt;/item&gt;
      &lt;item&gt;Python3&lt;/item&gt;
      &lt;item&gt;C++17 compliant compiler (GCC 7+ or Clang 5+)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build Instructions:&lt;/p&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/alibaba/AliSQL.git
cd AliSQL

# Build the project (release build)
sh build.sh -t release -d /path/to/install/dir

# For development/debugging (debug build)
sh build.sh -t debug -d /path/to/install/dir

# Install the built MySQL server
make install&lt;/code&gt;
    &lt;p&gt;Build Options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-t release|debug&lt;/code&gt;: Build type (default: debug)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-d &amp;lt;dest_dir&amp;gt;&lt;/code&gt;: Installation directory (default: /usr/local/alisql or $HOME/alisql)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-s &amp;lt;server_suffix&amp;gt;&lt;/code&gt;: Server suffix (default: alisql-dev)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-g asan|tsan&lt;/code&gt;: Enable sanitizer&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-c&lt;/code&gt;: Enable GCC coverage (gcov)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-h, --help&lt;/code&gt;: Show help&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GitHub Issues: https://github.com/alibaba/AliSQL/issues&lt;/item&gt;
      &lt;item&gt;Alibaba Cloud RDS: DuckDB-based Analytical Instance&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;For DuckDB-specific support, see the DuckDB Support Options.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;AliSQL 8.0 became an open-source project in December 2025 and is actively maintained by engineers at Alibaba Group.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Please:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch&lt;/item&gt;
      &lt;item&gt;Make your changes with appropriate tests&lt;/item&gt;
      &lt;item&gt;Submit a pull request&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For bug reports and feature requests, please use the GitHub Issues page.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the GPL-2.0 license. See the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;AliSQL is based on MySQL, which is licensed under GPL-2.0. The DuckDB integration follows the same licensing terms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46875228</guid><pubDate>Tue, 03 Feb 2026 18:40:18 +0000</pubDate></item><item><title>OpenClaw (a.k.a. Moltbot) Is Everywhere All at Once, and a Disaster</title><link>https://cacm.acm.org/blogcacm/openclaw-a-k-a-moltbot-is-everywhere-all-at-once-and-a-disaster-waiting-to-happen/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46875952</guid><pubDate>Tue, 03 Feb 2026 19:26:05 +0000</pubDate></item><item><title>China Moon Mission: Aiming for 2030 lunar landing</title><link>https://spectrum.ieee.org/china-moon-mission-mengzhou-artemis</link><description>&lt;doc fingerprint="77af907574e51d69"&gt;
  &lt;main&gt;
    &lt;p&gt;Slow and steady wins the race, or so goes the fable. The China Manned Space Agency, or CMSA, has repeatedly denied any rivalry with the United States akin to the race to the moon in the 1960s. But step-by-step, one element at a time over a period of decades, it has built a human space program with goals that include landing astronauts on the moon by 2030 and starting a base there in the following years. And‚Äîpartly because launch dates for NASA‚Äôs Artemis III moon landing keep slipping toward that same time frame‚ÄîU.S. space leaders are ratcheting up the space race rhetoric.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe are in a great competition with a rival that has the will and means to challenge American exceptionalism across multiple domains, including in the high ground of space,‚Äù said Jared Isaacman, the new head of NASA, in December. ‚ÄúThis is not the time for delay, but for action, because if we fall behind‚Äîif we make a mistake‚Äîwe may never catch up, and the consequences could shift the balance of power here on Earth.‚Äù&lt;/p&gt;
    &lt;p&gt;NASA‚Äôs Artemis II is almost ready to take its crew on a circumlunar test flight, and the White House has said that U.S. astronauts should prioritize a lunar landing by 2028‚Äîbut could China slip in ahead? How would a Chinese moon flight work? Does the Chinese space program have technology that matches or beats the United States?&lt;/p&gt;
    &lt;p&gt;RELATED: Inside the Spacecraft That Will Carry Humans Around the Moon&lt;/p&gt;
    &lt;p&gt;‚ÄúNobody [in China] would argue that we are in a space race,‚Äù says Namrata Goswami, a professor at Johns Hopkins University who has written extensively about China‚Äôs space effort, ‚Äúbut they might be engaged in activity that showcases China as a space power, and they are very serious about getting somewhere first.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;What Are the Mengzhou and Lanyue Spacecraft?&lt;/head&gt;
    &lt;p&gt;China‚Äôs lunar hardware builds on existing engineering. It is based on a multipurpose crew ship called Mengzhou, with capacity for six or seven astronauts, though as few as three may actually fly on a trip from Earth to low lunar orbit. (China watchers dispense with the word ‚Äútaikonaut‚Äù for its crew members, by the way; the word was coined in 1998 and has not been used by the Chinese government itself. China generally uses the word yuhangyuan, roughly translated as ‚Äútraveler of the universe.‚Äù)&lt;/p&gt;
    &lt;p&gt;Mengzhou, according to what the CMSA has shown, includes a crew section in the shape of a truncated cone or frustum, with a service module holding power and propulsion systems in the rear. If you squint at it, you‚Äôll see a resemblance to the American Artemis or Apollo spacecraft, the SpaceX Crew Dragon, or the yet-to-be-flown European Nyx. Basic aerodynamics make a blunt cone a very efficient shape for safely launching a spacecraft and returning it through Earth‚Äôs atmosphere.&lt;/p&gt;
    &lt;p&gt;The Mengzhou command ship uses parachutes and airbags during a 2025 landing test in northwest China.Wang Heng/Xinhua/Getty Images&lt;/p&gt;
    &lt;p&gt;Mengzhou is billed as reusable, with an outer heat shield that can be replaced after flight. Landings would take place in China‚Äôs western desert. ‚ÄúCoupled with the landing method of airbag cushioning,‚Äù says the CMSA in a translated statement, ‚Äúthe spacecraft itself can be better protected from damage and allow the reuse of the spacecraft.‚Äù&lt;/p&gt;
    &lt;p&gt;The ship would be launched by a new heavy-lift Long March 10 booster, one of two used for a given moon mission. The Long March 10, as configured for lunar flight, would stand 92.5 meters high at launch and generate thrust of 2,678 tonnes. (The rocket for Artemis II is more powerful: 3,992 tonnes.)&lt;/p&gt;
    &lt;p&gt;Mengzhou would leave for the moon after another Long March 10 has launched a lunar landing craft called Lanyue. The two would rendezvous and dock in lunar orbit. Two astronauts would transfer to Lanyue and land on the moon‚Äôs surface; Mengzhou would wait for them in orbit for the trip home. Lanyue has a stated mass of 26 tonnes and could carry a 200-kilogram rover.&lt;/p&gt;
    &lt;p&gt;Chinese authorities say testing of Lanyue began in 2024. Mengzhou should go on its first robotic flight in 2026; Lanyue, in 2027. The first joint test mission is planned for 2028 or 2029, with the first crew going to the moon a year after that.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Is China‚Äôs Long-Term Plan for Space?&lt;/head&gt;
    &lt;p&gt;But to focus on their hardware is to miss out on a major difference between the Chinese and U.S. moon-landing efforts. Artemis is the product of a start-again stop-again debate that‚Äôs been going on in the U.S. government since Apollo ended in the 1970s. Goals have shifted repeatedly‚Äîoften when new presidents took office. Conversely, the Chinese campaign is the outgrowth of a plan called Project 921, first backed by the Chinese Communist Party in 1992. There have been updates and some technical setbacks, but China has pretty much stuck to it ever since.&lt;/p&gt;
    &lt;p&gt;‚ÄúWhat the Chinese space effort has done that others have not is integrate everything,‚Äù says Goswami. ‚ÄúIt‚Äôs not just ‚ÄòWe‚Äôre going to mount a mission.‚Äô It‚Äôs bigger than that. They view space as an activity and not missions.‚Äù&lt;/p&gt;
    &lt;p&gt;In other words, she says, each new piece of technology is part of a coordinated effort to create a sustained presence in space, which pays economic, geopolitical, and sometimes military dividends. Each part, so far, has fit together with other parts: The first orbiting capsule, called Shenzhou 1 in 1999, led to the first flight by an astronaut, Yang Lewei, on Shenzhou 5 in 2003. That led to space stations (the Tiangong series, starting in 2011), to which Shenzhou crews have been flying since in regular rotation (Shenzhou 22 launched in November). Mengzhou will eventually take over as the workhorse crew vehicle for Earth-orbiting flights.&lt;/p&gt;
    &lt;p&gt;In the meantime, there has been a steady cadence of robotic lunar orbiters and landers (Chang‚Äôe-6 returned the first-ever soil sample from the moon‚Äôs far side in 2024), soon to be followed, we‚Äôre now told, by Chinese astronauts.&lt;/p&gt;
    &lt;p&gt;They started slowly, deliberately, with long breaks between missions, only recently picking up speed. At times they have unabashedly looked to other countries for guidance: The Shenzhou crew capsule in the 1990s borrowed heavily from the design of the Russian Soyuz. And several engineers today point out that the Mengzhou-Lanyue plan sounds in many ways like what then-administrator Michael Griffin proposed for NASA‚Äôs Constellation program back in 2005‚Äîa crewed ship launched by one rocket, a moon lander by another, with astronauts transferring to the lander once they reach lunar orbit. A crew capsule and lunar lander would be too much for one launch, as with the Apollo‚ÄìSaturn V, because landings would be more ambitious than could be achieved with Apollo‚Äôs minimalist lunar module, with longer stays and equipment for a lunar base.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe Chinese are pursuing an architecture a lot like the Apollo architecture was. Which is understandable because their ambitions are to go fast, and Apollo worked,‚Äù says a former senior NASA manager who, like several others, asked not to be quoted by name.&lt;/p&gt;
    &lt;p&gt;‚ÄúI have a lot of friends who have been watching the Chinese space program for the last couple of decades,‚Äù this person continued. ‚ÄúAnd the one hallmark that we can say is that when China announces dates for things, they typically maintain them.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;‚ÄúOur Great Rival‚Äù&lt;/head&gt;
    &lt;p&gt;And that is why Jared Isaacman talks of urgency at NASA. He has so far generally avoided the word ‚ÄúChina‚Äù in public. The Chinese, in his words, are usually ‚Äúour great rival‚Äù or ‚Äúa competitor.‚Äù Some NASA veterans say China may turn out to be giving the agency a helpful push to be faster and more agile. They say Apollo succeeded, in large part, because of the race to beat the Soviet Union. A Chinese challenge‚Äîeven unstated, even illusory‚Äîmay help Artemis move along.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe have a great competitor that is moving at absolutely impressive speeds,‚Äù Isaacman told NASA employees, ‚Äúand it‚Äôs unsettling to consider the implications if we fail to maintain our technological, scientific, or economic edge in space. And the clock is running.‚Äù&lt;/p&gt;
    &lt;p&gt;This is part 2 of a three-part series, Back to the Moon. Part 1 is about the technology behind NASA‚Äôs Artemis II mission. Part 3 will look at how NASA reinvigorated its human spaceflight program.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The 5 Spacecraft Behind China‚Äôs Moon Rock Sample Mission ‚Ä∫&lt;/item&gt;
      &lt;item&gt;China's Moon Missions Shadow NASA Artemis's Pace - IEEE ... ‚Ä∫&lt;/item&gt;
      &lt;item&gt;China Aims for a Permanent Moon Base in the 2030s - IEEE Spectrum ‚Ä∫&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ned Potter is a New York writer who spent more than 25 years as an ABC News and CBS News correspondent covering science, technology, space, and the environment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46876047</guid><pubDate>Tue, 03 Feb 2026 19:32:11 +0000</pubDate></item><item><title>Anthropic AI tool sparks selloff from software to broader market</title><link>https://www.bloomberg.com/news/articles/2026-02-03/legal-software-stocks-plunge-as-anthropic-releases-new-ai-tool</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46876720</guid><pubDate>Tue, 03 Feb 2026 20:21:21 +0000</pubDate></item><item><title>Bruce Schneier: AI and the scaling of betrayal (2023)</title><link>https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html</link><description>&lt;doc fingerprint="af809351a1650441"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;AI and Trust&lt;/head&gt;
    &lt;p&gt;I trusted a lot today. I trusted my phone to wake me on time. I trusted Uber to arrange a taxi for me, and the driver to get me to the airport safely. I trusted thousands of other drivers on the road not to ram my car on the way. At the airport, I trusted ticket agents and maintenance engineers and everyone else who keeps airlines operating. And the pilot of the plane I flew in. And thousands of other people at the airport and on the plane, any of which could have attacked me. And all the people that prepared and served my breakfast, and the entire food supply chain‚Äîany of them could have poisoned me. When I landed here, I trusted thousands more people: at the airport, on the road, in this building, in this room. And that was all before 10:30 this morning.&lt;/p&gt;
    &lt;p&gt;Trust is essential to society. Humans as a species are trusting. We are all sitting here, mostly strangers, confident that nobody will attack us. If we were a roomful of chimpanzees, this would be impossible. We trust many thousands of times a day. Society can‚Äôt function without it. And that we don‚Äôt even think about it is a measure of how well it all works.&lt;/p&gt;
    &lt;p&gt;In this talk, I am going to make several arguments. One, that there are two different kinds of trust‚Äîinterpersonal trust and social trust‚Äîand that we regularly confuse them. Two, that the confusion will increase with artificial intelligence. We will make a fundamental category error. We will think of AIs as friends when they‚Äôre really just services. Three, that the corporations controlling AI systems will take advantage of our confusion to take advantage of us. They will not be trustworthy. And four, that it is the role of government to create trust in society. And therefore, it is their role to create an environment for trustworthy AI. And that means regulation. Not regulating AI, but regulating the organizations that control and use AI.&lt;/p&gt;
    &lt;p&gt;Okay, so let‚Äôs back up and take that all a lot slower. Trust is a complicated concept, and the word is overloaded with many meanings. There‚Äôs personal and intimate trust. When we say that we trust a friend, it is less about their specific actions and more about them as a person. It‚Äôs a general reliance that they will behave in a trustworthy manner. We trust their intentions, and know that those intentions will inform their actions. Let‚Äôs call this ‚Äúinterpersonal trust.‚Äù&lt;/p&gt;
    &lt;p&gt;There‚Äôs also the less intimate, less personal trust. We might not know someone personally, or know their motivations‚Äîbut we can trust their behavior. We don‚Äôt know whether or not someone wants to steal, but maybe we can trust that they won‚Äôt. It‚Äôs really more about reliability and predictability. We‚Äôll call this ‚Äúsocial trust.‚Äù It‚Äôs the ability to trust strangers.&lt;/p&gt;
    &lt;p&gt;Interpersonal trust and social trust are both essential in society today. This is how it works. We have mechanisms that induce people to behave in a trustworthy manner, both interpersonally and socially. This, in turn, allows others to be trusting. Which enables trust in society. And that keeps society functioning. The system isn‚Äôt perfect‚Äîthere are always going to be untrustworthy people‚Äîbut most of us being trustworthy most of the time is good enough.&lt;/p&gt;
    &lt;p&gt;I wrote about this in 2012 in a book called Liars and Outliers. I wrote about four systems for enabling trust: our innate morals, concern about our reputations, the laws we live under, and security technologies that constrain our behavior. I wrote about how the first two are more informal than the last two. And how the last two scale better, and allow for larger and more complex societies. They enable cooperation amongst strangers.&lt;/p&gt;
    &lt;p&gt;What I didn‚Äôt appreciate is how different the first and last two are. Morals and reputation are person to person, based on human connection, mutual vulnerability, respect, integrity, generosity, and a lot of other things besides. These underpin interpersonal trust. Laws and security technologies are systems of trust that force us to act trustworthy. And they‚Äôre the basis of social trust.&lt;/p&gt;
    &lt;p&gt;Taxi driver used to be one of the country‚Äôs most dangerous professions. Uber changed that. I don‚Äôt know my Uber driver, but the rules and the technology lets us both be confident that neither of us will cheat or attack each other. We are both under constant surveillance and are competing for star rankings.&lt;/p&gt;
    &lt;p&gt;Lots of people write about the difference between living in a high-trust and a low-trust society. How reliability and predictability make everything easier. And what is lost when society doesn‚Äôt have those characteristics. Also, how societies move from high-trust to low-trust and vice versa. This is all about social trust.&lt;/p&gt;
    &lt;p&gt;That literature is important, but for this talk the critical point is that social trust scales better. You used to need a personal relationship with a banker to get a loan. Now it‚Äôs all done algorithmically, and you have many more options to choose from.&lt;/p&gt;
    &lt;p&gt;Social trust scales better, but embeds all sorts of bias and prejudice. That‚Äôs because, in order to scale, social trust has to be structured, system- and rule-oriented, and that‚Äôs where the bias gets embedded. And the system has to be mostly blinded to context, which removes flexibility.&lt;/p&gt;
    &lt;p&gt;But that scale is vital. In today‚Äôs society we regularly trust‚Äîor not‚Äîgovernments, corporations, brands, organizations, groups. It‚Äôs not so much that I trusted the particular pilot that flew my airplane, but instead the airline that puts well-trained and well-rested pilots in cockpits on schedule. I don‚Äôt trust the cooks and waitstaff at a restaurant, but the system of health codes they work under. I can‚Äôt even describe the banking system I trusted when I used an ATM this morning. Again, this confidence is no more than reliability and predictability.&lt;/p&gt;
    &lt;p&gt;Think of that restaurant again. Imagine that it‚Äôs a fast food restaurant, employing teenagers. The food is almost certainly safe‚Äîprobably safer than in high-end restaurants‚Äîbecause of the corporate systems or reliability and predictability that is guiding their every behavior.&lt;/p&gt;
    &lt;p&gt;That‚Äôs the difference. You can ask a friend to deliver a package across town. Or you can pay the Post Office to do the same thing. The former is interpersonal trust, based on morals and reputation. You know your friend and how reliable they are. The second is a service, made possible by social trust. And to the extent that is a reliable and predictable service, it‚Äôs primarily based on laws and technologies. Both can get your package delivered, but only the second can become the global package delivery systems that is FedEx.&lt;/p&gt;
    &lt;p&gt;Because of how large and complex society has become, we have replaced many of the rituals and behaviors of interpersonal trust with security mechanisms that enforce reliability and predictability‚Äîsocial trust.&lt;/p&gt;
    &lt;p&gt;But because we use the same word for both, we regularly confuse them. And when we do that, we are making a category error.&lt;/p&gt;
    &lt;p&gt;And we do it all the time. With governments. With organizations. With systems of all kinds. And especially with corporations.&lt;/p&gt;
    &lt;p&gt;We might think of them as friends, when they are actually services. Corporations are not moral; they are precisely as immoral as the law and their reputations let them get away with.&lt;/p&gt;
    &lt;p&gt;So corporations regularly take advantage of their customers, mistreat their workers, pollute the environment, and lobby for changes in law so they can do even more of these things.&lt;/p&gt;
    &lt;p&gt;Both language and the laws make this an easy category error to make. We use the same grammar for people and corporations. We imagine that we have personal relationships with brands. We give corporations some of the same rights as people.&lt;/p&gt;
    &lt;p&gt;Corporations like that we make this category error‚Äîsee, I just made it myself‚Äîbecause they profit when we think of them as friends. They use mascots and spokesmodels. They have social media accounts with personalities. They refer to themselves like they are people.&lt;/p&gt;
    &lt;p&gt;But they are not our friends. Corporations are not capable of having that kind of relationship.&lt;/p&gt;
    &lt;p&gt;We are about to make the same category error with AI. We‚Äôre going to think of them as our friends when they‚Äôre not.&lt;/p&gt;
    &lt;p&gt;A lot has been written about AIs as existential risk. The worry is that they will have a goal, and they will work to achieve it even if it harms humans in the process. You may have read about the ‚Äúpaperclip maximizer‚Äú: an AI that has been programmed to make as many paper clips as possible, and ends up destroying the earth to achieve those ends. It‚Äôs a weird fear. Science fiction author Ted Chiang writes about it. Instead of solving all of humanity‚Äôs problems, or wandering off proving mathematical theorems that no one understands, the AI single-mindedly pursues the goal of maximizing production. Chiang‚Äôs point is that this is every corporation‚Äôs business plan. And that our fears of AI are basically fears of capitalism. Science fiction writer Charlie Stross takes this one step further, and calls corporations ‚Äúslow AI.‚Äù They are profit maximizing machines. And the most successful ones do whatever they can to achieve that singular goal.&lt;/p&gt;
    &lt;p&gt;And near-term AIs will be controlled by corporations. Which will use them towards that profit-maximizing goal. They won‚Äôt be our friends. At best, they‚Äôll be useful services. More likely, they‚Äôll spy on us and try to manipulate us.&lt;/p&gt;
    &lt;p&gt;This is nothing new. Surveillance is the business model of the Internet. Manipulation is the other business model of the Internet.&lt;/p&gt;
    &lt;p&gt;Your Google search results lead with URLs that someone paid to show to you. Your Facebook and Instagram feeds are filled with sponsored posts. Amazon searches return pages of products whose sellers paid for placement.&lt;/p&gt;
    &lt;p&gt;This is how the Internet works. Companies spy on us as we use their products and services. Data brokers buy that surveillance data from the smaller companies, and assemble detailed dossiers on us. Then they sell that information back to those and other companies, who combine it with data they collect in order to manipulate our behavior to serve their interests. At the expense of our own.&lt;/p&gt;
    &lt;p&gt;We use all of these services as if they are our agents, working on our behalf. In fact, they are double agents, also secretly working for their corporate owners. We trust them, but they are not trustworthy. They‚Äôre not friends; they‚Äôre services.&lt;/p&gt;
    &lt;p&gt;It‚Äôs going to be no different with AI. And the result will be much worse, for two reasons.&lt;/p&gt;
    &lt;p&gt;The first is that these AI systems will be more relational. We will be conversing with them, using natural language. As such, we will naturally ascribe human-like characteristics to them.&lt;/p&gt;
    &lt;p&gt;This relational nature will make it easier for those double agents to do their work. Did your chatbot recommend a particular airline or hotel because it‚Äôs truly the best deal, given your particular set of needs? Or because the AI company got a kickback from those providers? When you asked it to explain a political issue, did it bias that explanation towards the company‚Äôs position? Or towards the position of whichever political party gave it the most money? The conversational interface will help hide their agenda.&lt;/p&gt;
    &lt;p&gt;The second reason to be concerned is that these AIs will be more intimate. One of the promises of generative AI is a personal digital assistant. Acting as your advocate with others, and as a butler with you. This requires an intimacy greater than your search engine, email provider, cloud storage system, or phone. You‚Äôre going to want it with you 24/7, constantly training on everything you do. You will want it to know everything about you, so it can most effectively work on your behalf.&lt;/p&gt;
    &lt;p&gt;And it will help you in many ways. It will notice your moods and know what to suggest. It will anticipate your needs and work to satisfy them. It will be your therapist, life coach, and relationship counselor.&lt;/p&gt;
    &lt;p&gt;You will default to thinking of it as a friend. You will speak to it in natural language, and it will respond in kind. If it is a robot, it will look humanoid‚Äîor at least like an animal. It will interact with the whole of your existence, just like another person would.&lt;/p&gt;
    &lt;p&gt;The natural language interface is critical here. We are primed to think of others who speak our language as people. And we sometimes have trouble thinking of others who speak a different language that way. We make that category error with obvious non-people, like cartoon characters. We will naturally have a ‚Äútheory of mind‚Äù about any AI we talk with.&lt;/p&gt;
    &lt;p&gt;More specifically, we tend to assume that something‚Äôs implementation is the same as its interface. That is, we assume that things are the same on the inside as they are on the surface. Humans are like that: we‚Äôre people through and through. A government is systemic and bureaucratic on the inside. You‚Äôre not going to mistake it for a person when you interact with it. But this is the category error we make with corporations. We sometimes mistake the organization for its spokesperson. AI has a fully relational interface‚Äîit talks like a person‚Äîbut it has an equally fully systemic implementation. Like a corporation, but much more so. The implementation and interface are more divergent than anything we have encountered to date‚Äîby a lot.&lt;/p&gt;
    &lt;p&gt;And you will want to trust it. It will use your mannerisms and cultural references. It will have a convincing voice, a confident tone, and an authoritative manner. Its personality will be optimized to exactly what you like and respond to.&lt;/p&gt;
    &lt;p&gt;It will act trustworthy, but it will not be trustworthy. We won‚Äôt know how they are trained. We won‚Äôt know their secret instructions. We won‚Äôt know their biases, either accidental or deliberate.&lt;/p&gt;
    &lt;p&gt;We do know that they are built at enormous expense, mostly in secret, by profit-maximizing corporations for their own benefit.&lt;/p&gt;
    &lt;p&gt;It‚Äôs no accident that these corporate AIs have a human-like interface. There‚Äôs nothing inevitable about that. It‚Äôs a design choice. It could be designed to be less personal, less human-like, more obviously a service‚Äîlike a search engine . The companies behind those AIs want you to make the friend/service category error. It will exploit your mistaking it for a friend. And you might not have any choice but to use it.&lt;/p&gt;
    &lt;p&gt;There is something we haven‚Äôt discussed when it comes to trust: power. Sometimes we have no choice but to trust someone or something because they are powerful. We are forced to trust the local police, because they‚Äôre the only law enforcement authority in town. We are forced to trust some corporations, because there aren‚Äôt viable alternatives. To be more precise, we have no choice but to entrust ourselves to them. We will be in this same position with AI. We will have no choice but to entrust ourselves to their decision-making.&lt;/p&gt;
    &lt;p&gt;The friend/service confusion will help mask this power differential. We will forget how powerful the corporation behind the AI is, because we will be fixated on the person we think the AI is.&lt;/p&gt;
    &lt;p&gt;So far, we have been talking about one particular failure that results from overly trusting AI. We can call it something like ‚Äúhidden exploitation.‚Äù There are others. There‚Äôs outright fraud, where the AI is actually trying to steal stuff from you. There‚Äôs the more prosaic mistaken expertise, where you think the AI is more knowledgeable than it is because it acts confidently. There‚Äôs incompetency, where you believe that the AI can do something it can‚Äôt. There‚Äôs inconsistency, where you mistakenly expect the AI to be able to repeat its behaviors. And there‚Äôs illegality, where you mistakenly trust the AI to obey the law. There are probably more ways trusting an AI can fail.&lt;/p&gt;
    &lt;p&gt;All of this is a long-winded way of saying that we need trustworthy AI. AI whose behavior, limitations, and training are understood. AI whose biases are understood, and corrected for. AI whose goals are understood. That won‚Äôt secretly betray your trust to someone else.&lt;/p&gt;
    &lt;p&gt;The market will not provide this on its own. Corporations are profit maximizers, at the expense of society. And the incentives of surveillance capitalism are just too much to resist.&lt;/p&gt;
    &lt;p&gt;It‚Äôs government that provides the underlying mechanisms for the social trust essential to society. Think about contract law. Or laws about property, or laws protecting your personal safety. Or any of the health and safety codes that let you board a plane, eat at a restaurant, or buy a pharmaceutical without worry.&lt;/p&gt;
    &lt;p&gt;The more you can trust that your societal interactions are reliable and predictable, the more you can ignore their details. Places where governments don‚Äôt provide these things are not good places to live.&lt;/p&gt;
    &lt;p&gt;Government can do this with AI. We need AI transparency laws. When it is used. How it is trained. What biases and tendencies it has. We need laws regulating AI‚Äîand robotic‚Äîsafety. When it is permitted to affect the world. We need laws that enforce the trustworthiness of AI. Which means the ability to recognize when those laws are being broken. And penalties sufficiently large to incent trustworthy behavior.&lt;/p&gt;
    &lt;p&gt;Many countries are contemplating AI safety and security laws‚Äîthe EU is the furthest along‚Äîbut I think they are making a critical mistake. They try to regulate the AIs and not the humans behind them.&lt;/p&gt;
    &lt;p&gt;AIs are not people; they don‚Äôt have agency. They are built by, trained by, and controlled by people. Mostly for-profit corporations. Any AI regulations should place restrictions on those people and corporations. Otherwise the regulations are making the same category error I‚Äôve been talking about. At the end of the day, there is always a human responsible for whatever the AI‚Äôs behavior is. And it‚Äôs the human who needs to be responsible for what they do‚Äîand what their companies do. Regardless of whether it was due to humans, or AI, or a combination of both. Maybe that won‚Äôt be true forever, but it will be true in the near future. If we want trustworthy AI, we need to require trustworthy AI controllers.&lt;/p&gt;
    &lt;p&gt;We already have a system for this: fiduciaries. There are areas in society where trustworthiness is of paramount importance, even more than usual. Doctors, lawyers, accountants‚Ä¶these are all trusted agents. They need extraordinary access to our information and ourselves to do their jobs, and so they have additional legal responsibilities to act in our best interests. They have fiduciary responsibility to their clients.&lt;/p&gt;
    &lt;p&gt;We need the same sort of thing for our data. The idea of a data fiduciary is not new. But it‚Äôs even more vital in a world of generative AI assistants.&lt;/p&gt;
    &lt;p&gt;And we need one final thing: public AI models. These are systems built by academia, or non-profit groups, or government itself, that can be owned and run by individuals.&lt;/p&gt;
    &lt;p&gt;The term ‚Äúpublic model‚Äù has been thrown around a lot in the AI world, so it‚Äôs worth detailing what this means. It‚Äôs not a corporate AI model that the public is free to use. It‚Äôs not a corporate AI model that the government has licensed. It‚Äôs not even an open-source model that the public is free to examine and modify.&lt;/p&gt;
    &lt;p&gt;A public model is a model built by the public for the public. It requires political accountability, not just market accountability. This means openness and transparency paired with a responsiveness to public demands. It should also be available for anyone to build on top of. This means universal access. And a foundation for a free market in AI innovations. This would be a counter-balance to corporate-owned AI.&lt;/p&gt;
    &lt;p&gt;We can never make AI into our friends. But we can make them into trustworthy services‚Äîagents and not double agents. But only if government mandates it. We can put limits on surveillance capitalism. But only if government mandates it.&lt;/p&gt;
    &lt;p&gt;Because the point of government is to create social trust. I started this talk by explaining the importance of trust in society, and how interpersonal trust doesn‚Äôt scale to larger groups. That other, impersonal kind of trust‚Äîsocial trust, reliability and predictability‚Äîis what governments create.&lt;/p&gt;
    &lt;p&gt;To the extent a government improves the overall trust in society, it succeeds. And to the extent a government doesn‚Äôt, it fails.&lt;/p&gt;
    &lt;p&gt;But they have to. We need government to constrain the behavior of corporations and the AIs they build, deploy, and control. Government needs to enforce both predictability and reliability.&lt;/p&gt;
    &lt;p&gt;That‚Äôs how we can create the social trust that society needs to thrive.&lt;/p&gt;
    &lt;p&gt;This essay previously appeared on the Harvard Kennedy School Belfer Center‚Äôs website.&lt;/p&gt;
    &lt;p&gt;EDITED TO ADD: This essay has been translated into German.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46877075</guid><pubDate>Tue, 03 Feb 2026 20:49:30 +0000</pubDate></item><item><title>FlashAttention-T: Towards Tensorized Attention</title><link>https://dl.acm.org/doi/10.1145/3774934.3786425</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46877403</guid><pubDate>Tue, 03 Feb 2026 21:15:48 +0000</pubDate></item></channel></rss>