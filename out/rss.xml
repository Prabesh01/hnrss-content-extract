<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 29 Aug 2025 13:00:09 +0000</lastBuildDate><item><title>Uncertain&lt;T&gt;</title><link>https://nshipster.com/uncertainty/</link><description>&lt;doc fingerprint="e5f3d11d29e56096"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Uncertain‚ü®T‚ü©&lt;/head&gt;
    &lt;p&gt;You know what‚Äôs wrong with people? They‚Äôre too sure of themselves.&lt;/p&gt;
    &lt;p&gt;Better to be wrong and own it than be right with caveats. Hard to build a personal brand out of nuance these days. People are attracted to confidence ‚Äî however misplaced.&lt;/p&gt;
    &lt;p&gt;But can you blame them? (People, that is) Working in software, the most annoying part of reaching Senior level is having to say ‚Äúit depends‚Äù all the time. Much more fun getting to say ‚Äúlet‚Äôs ship it and iterate‚Äù as Staff or ‚Äúthat won‚Äôt scale‚Äù as a Principal.&lt;/p&gt;
    &lt;p&gt;Yet, for all of our intellectual humility, why do we &lt;del&gt;write&lt;/del&gt; vibe code like this?&lt;/p&gt;
    &lt;code&gt;if current&lt;/code&gt;
    &lt;p&gt;GPS coordinates aren‚Äôt exact. They‚Äôre noisy. They‚Äôre approximate. They‚Äôre probabilistic. That &lt;code&gt;horizontal&lt;/code&gt; property tucked away in your &lt;code&gt;CLLocation&lt;/code&gt; object
              is trying to tell you something important:
              you‚Äôre probably within that radius.
              Probably.&lt;/p&gt;
    &lt;p&gt;A &lt;code&gt;Bool&lt;/code&gt;, meanwhile, can be only &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;.
              That &lt;code&gt;if&lt;/code&gt; statement needs to make a choice one way or another,
              but code like this doesn‚Äôt capture the uncertainty of the situation.
              If truth is light,
              then current programming models collapse the wavefunction too early.&lt;/p&gt;
    &lt;head rend="h2"&gt;Picking the Right Abstraction&lt;/head&gt;
    &lt;p&gt;In 2014, researchers at the University of Washington and Microsoft Research proposed a radical idea: What if uncertainty were encoded directly into the type system? Their paper, Uncertain&amp;lt;T&amp;gt;: A First-Order Type for Uncertain Data introduced a probabilistic programming approach that‚Äôs both mathematically rigorous and surprisingly practical.&lt;/p&gt;
    &lt;p&gt;As you‚Äôd expect for something from Microsoft in the 2010s, the paper is implemented in C#. But the concepts translate beautifully to Swift.&lt;/p&gt;
    &lt;p&gt;You can find my port on GitHub:&lt;/p&gt;
    &lt;code&gt;import Uncertain
import Core&lt;/code&gt;
    &lt;p&gt;When you compare two &lt;code&gt;Uncertain&lt;/code&gt; values,
              you don‚Äôt get a definitive &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt;.
              You get an &lt;code&gt;Uncertain&amp;lt;Bool&amp;gt;&lt;/code&gt; that represents the probability of the comparison being &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The same is true for other operators, too:&lt;/p&gt;
    &lt;code&gt;// How fast did we run around the track?
let distance: Double = 400 // meters
let time: Uncertain&amp;lt;Double&amp;gt; = .normal(mean: 60, standard&lt;/code&gt;
    &lt;p&gt;This code builds a computation graph, sampling only when you ask for concrete results. The library uses Sequential Probability Ratio Testing (SPRT) to efficiently determine how many samples are needed ‚Äî maybe a few dozen times for simple comparisons, scaling up automatically for complex calculations.&lt;/p&gt;
    &lt;code&gt;// Sampling happens only when we need to evaluate
if ~(running&lt;/code&gt;
    &lt;p&gt;Using an abstraction like &lt;code&gt;Uncertain&amp;lt;T&amp;gt;&lt;/code&gt; forces you to deal with uncertainty as a first-class concept
              rather than pretending it doesn‚Äôt exist.
              And in doing so, you end up with much smarter code.&lt;/p&gt;
    &lt;p&gt;To quote Alan Kay:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Point of view is worth 80 IQ points Alan Kay&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Before we dive deeper into probability distributions, let‚Äôs take a detour to Monaco and talk about Monte Carlo sampling.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Monte Carlo Method&lt;/head&gt;
    &lt;p&gt;Behold, a classic slot machine (or ‚Äúfruit machine‚Äù for our UK readers üá¨üáß):&lt;/p&gt;
    &lt;code&gt;enum Slot&lt;/code&gt;
    &lt;p&gt;Should we play it?&lt;/p&gt;
    &lt;p&gt;Now, we could work out these probabilities analytically ‚Äî counting combinations, calculating conditional probabilities, maybe even busting out some combinatorics.&lt;/p&gt;
    &lt;p&gt;Or we could just let the computer pull the lever a bunch and see what happens.&lt;/p&gt;
    &lt;code&gt;let expected&lt;/code&gt;
    &lt;p&gt;At least we know one thing for certain: The house always wins.&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond Simple Distributions&lt;/head&gt;
    &lt;p&gt;While one-armed bandits demonstrate pure randomness, real-world applications often deal with more predictable uncertainty.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Uncertain&amp;lt;T&amp;gt;&lt;/code&gt; provides a
              rich set of probability distributions:&lt;/p&gt;
    &lt;code&gt;// Modeling sensor noise
let raw&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;Uncertain&amp;lt;T&amp;gt;&lt;/code&gt; also provides comprehensive
            statistical operations:&lt;/p&gt;
    &lt;code&gt;// Basic statistics
let temperature = Uncertain.normal(mean: 23.0, standard&lt;/code&gt;
    &lt;p&gt;The statistics are computed through sampling. The number of samples is configurable, letting you trade computation time for accuracy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting Theory to Practice&lt;/head&gt;
    &lt;p&gt;Users don‚Äôt notice when things work correctly, but they definitely notice impossible behavior. When your running app claims they just sprinted at 45 mph, or your IRL meetup app shows someone 500 feet away when GPS accuracy is ¬±1000 meters, that‚Äôs a bad look ü§°&lt;/p&gt;
    &lt;p&gt;So where do we go from here? Let‚Äôs channel our Senior+ memes from before for guidance.&lt;/p&gt;
    &lt;p&gt;That Staff engineer saying ‚Äúlet‚Äôs ship it and iterate‚Äù is right about the incremental approach. You can migrate uncertain calculations piecemeal rather than rewriting everything at once:&lt;/p&gt;
    &lt;code&gt;extension CLLocation {
    var uncertain: Uncertain&amp;lt;CLLocation&amp;gt; {
        Uncertain&amp;lt;CLLocation&amp;gt;.from(self)
    }
}

// Gradually migrate critical paths
let is&lt;/code&gt;
    &lt;p&gt;And we should consider the Principal engineer‚Äôs warning of ‚Äúthat won‚Äôt scale‚Äù. Sampling has a cost, and you should understand the computational overhead for probabilistic accuracy:&lt;/p&gt;
    &lt;code&gt;// Fast approximation for UI updates
let quick&lt;/code&gt;
    &lt;p&gt;Start small. Pick one feature where GPS glitches cause user complaints. Replace your distance calculations with uncertain versions. Measure the impact.&lt;/p&gt;
    &lt;p&gt;Remember: the goal isn‚Äôt to eliminate uncertainty ‚Äî it‚Äôs to acknowledge that it exists and handle it gracefully. Because in the real world, nothing is certain except uncertainty itself.&lt;/p&gt;
    &lt;p&gt;And perhaps, with better tools, we can finally stop pretending otherwise.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45054703</guid></item><item><title>Building your own CLI coding agent with Pydantic-AI</title><link>https://martinfowler.com/articles/build-own-coding-agent.html</link><description>&lt;doc fingerprint="5494c4536b9188be"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Building your own CLI Coding Agent with Pydantic-AI&lt;/head&gt;
    &lt;p&gt;Learning by doing&lt;/p&gt;
    &lt;p&gt;CLI coding agents are a fundamentally different tool to chatbots or autocomplete tools - they're agents that can read code, run tests, and update a codebase. While commercial tools are impressive, they don't understand the particular context of our environment and the eccentricities of our specific project. Instead we can build our own coding agent by assembling open source tools, using our specific development standards for: testing, documentation production, code reasoning, and file system operations.&lt;/p&gt;
    &lt;p&gt;27 August 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The wave of CLI Coding Agents&lt;/item&gt;
      &lt;item&gt;Why Build When You Can Buy?&lt;/item&gt;
      &lt;item&gt;The Architecture of Our Development Agent&lt;/item&gt;
      &lt;item&gt;Starting Simple: The Foundation&lt;/item&gt;
      &lt;item&gt;First Capability: Testing!&lt;/item&gt;
      &lt;item&gt;Adding Intelligence: Instructions and intent&lt;/item&gt;
      &lt;item&gt;The MCP Revolution: Pluggable Capabilities&lt;/item&gt;
      &lt;item&gt;Sandboxed Python Execution&lt;/item&gt;
      &lt;item&gt;Up-to-Date library Documentation&lt;/item&gt;
      &lt;item&gt;AWS MCPs&lt;/item&gt;
      &lt;item&gt;Internet Search for Current Information&lt;/item&gt;
      &lt;item&gt;Structured Problem Solving&lt;/item&gt;
      &lt;item&gt;Optimising for Reasoning&lt;/item&gt;
      &lt;item&gt;Desktop Commander: Warning! With great power comes great responsibility!&lt;/item&gt;
      &lt;item&gt;The Complete System&lt;/item&gt;
      &lt;item&gt;What We Learned About CLI Agents&lt;/item&gt;
      &lt;item&gt;The Road Ahead&lt;/item&gt;
      &lt;item&gt;Why This Matters&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The wave of CLI Coding Agents&lt;/head&gt;
    &lt;p&gt;If you have tried Claude Code, Gemini Code, Open Code or Simon Willison‚Äôs LLM CLI, you‚Äôve experienced something fundamentally different from ChatGPT or Github Copilot. These aren‚Äôt just chatbots or autocomplete tools - they‚Äôre agents that can read your code, run your tests, search docs and make changes to your codebase async.&lt;/p&gt;
    &lt;p&gt;But how do they work? For me the best way to understand how any tool works is to try and build it myself. So that‚Äôs exactly what we did, and in this article I‚Äôll take you through how we built our own CLI Coding Agent using the Pydantic-AI framework and the Model Context Protocol (MCP). You‚Äôll see not just how to assemble the pieces but why each capability matters and how it changes the way you can work with code.&lt;/p&gt;
    &lt;p&gt;Our implementation leverages AWS Bedrock but with Pydantic-AI you could easily use any other mainstream provider or even a fully local LLM.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Build When You Can Buy?&lt;/head&gt;
    &lt;p&gt;Before diving into the technical implementation, let's examine why we chose to build our own solution.&lt;/p&gt;
    &lt;p&gt;The answer became clear very quickly using our custom agent, while commercial tools are impressive, they‚Äôre built for general use cases. Our agent was fully customised to our internal context and all the little eccentricities of our specific project. More importantly, building it gave us insights into how these systems work and the quality of our own GenAI Platform and Dev Tooling.&lt;/p&gt;
    &lt;p&gt;Think of it like learning to cook. You can eat at restaurants forever but understanding how flavours combine and techniques work makes you appreciate food differently - and lets you create exactly what you want.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Architecture of Our Development Agent&lt;/head&gt;
    &lt;p&gt;At a high level, our coding assistant consists of several key components:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Core AI Model: Claude from Anthropic accessed through AWS Bedrock&lt;/item&gt;
      &lt;item&gt;Pydantic-AI Framework: provides the agent framework and many helpful utilities to make our Agent more useful immediately&lt;/item&gt;
      &lt;item&gt;MCP Servers: independent processes that give the agent specialised tools, MCP is a common standard for defining the servers that contain these tools.&lt;/item&gt;
      &lt;item&gt;CLI Interface: how users interact with the assistant&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The magic happens through the Model Context Protocol (MCP), which allows the AI model to use various tools through a standardized interface. This architecture makes our assistant highly extensible - we can easily add new capabilities by implementing additional MCP servers, but we‚Äôre getting ahead of ourselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;Starting Simple: The Foundation&lt;/head&gt;
    &lt;p&gt;We started by creating a basic project structure and installing the necessary dependencies:&lt;/p&gt;
    &lt;quote&gt;uv init uv add pydantic_ai uv add boto3&lt;/quote&gt;
    &lt;p&gt;Our primary dependencies include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;pydantic-ai&lt;/code&gt;: Framework for building AI agents&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;boto3&lt;/code&gt;: For AWS API interactions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We chose Claude Sonnet 4 from Anthropic (accessed via AWS Bedrock) as our foundation model due to its strong code understanding and generation capabilities. Here's how we configured it in our &lt;code&gt;main.py&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;import boto3 from pydantic_ai import Agent from pydantic_ai.mcp import MCPServerStdio from pydantic_ai.models.bedrock import BedrockConverseModel from pydantic_ai.providers.bedrock import BedrockProvider&lt;/quote&gt;
    &lt;quote&gt;bedrock_config = BotocoreConfig( read_timeout=300, connect_timeout=60, retries={"max_attempts": 3}, ) bedrock_client = boto3.client( "bedrock-runtime", region_name="eu-central-1", config=bedrock_config ) model = BedrockConverseModel( "eu.anthropic.claude-sonnet-4-20250514-v1:0", provider=BedrockProvider(bedrock_client=bedrock_client), ) agent = Agent( model=model, )&lt;/quote&gt;
    &lt;quote&gt;if __name__ == "__main__": agent.to_cli_sync()&lt;/quote&gt;
    &lt;p&gt;At this stage we already have a fully working CLI with a chat interface which we can use as you would a GUI chat interface, which is pretty cool for how little code this is! However we can definitely improve upon this.&lt;/p&gt;
    &lt;head rend="h2"&gt;First Capability: Testing!&lt;/head&gt;
    &lt;p&gt;Instead of running the tests ourselves after each coding iteration why not get the agent to do it? Seems simple right?&lt;/p&gt;
    &lt;quote&gt;import subprocess&lt;/quote&gt;
    &lt;quote&gt;@agent.tool_plain() def run_unit_tests() -&amp;gt; str: """Run unit tests using uv.""" result = subprocess.run( ["uv", "run", "pytest", "-xvs", "tests/"], capture_output=True, text=True ) return result.stdout&lt;/quote&gt;
    &lt;p&gt;Here we use the same pytest command you would run in the terminal (I‚Äôve shortened ours for the article). Now something magical happened. I could say ‚ÄúX isn‚Äôt working‚Äù and the agent would:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1. Run the test suite&lt;/item&gt;
      &lt;item&gt;2. Identify which specific tests were failing&lt;/item&gt;
      &lt;item&gt;3. Analyze the error messages&lt;/item&gt;
      &lt;item&gt;4. Suggest targeted fixes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The workflow change: Instead of staring at test failures or copy pasting terminal outputs into ChatGPT we now give our agent super relevant context about any issues in our codebase.&lt;/p&gt;
    &lt;p&gt;However we noticed our agent sometimes ‚Äúfixed‚Äù failing tests by suggesting changes to the tests, not the actual implementation. This led to our next addition.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adding Intelligence: Instructions and intent&lt;/head&gt;
    &lt;p&gt;We realised we needed to teach our agent a little more about our development philosophy and steer it away from bad behaviours.&lt;/p&gt;
    &lt;quote&gt;instructions = """ You are a specialised agent for maintaining and developing the XXXXXX codebase. ## Development Guidelines: 1. **Test Failures:** - When tests fail, fix the implementation first, not the tests - Tests represent expected behavior; implementation should conform to tests - Only modify tests if they clearly don't match specifications 2. **Code Changes:** - Make the smallest possible changes to fix issues - Focus on fixing the specific problem rather than rewriting large portions - Add unit tests for all new functionality before implementing it 3. **Best Practices:** - Keep functions small with a single responsibility - Implement proper error handling with appropriate exceptions - Be mindful of configuration dependencies in tests Remember to examine test failure messages carefully to understand the root cause before making any changes. """&lt;/quote&gt;
    &lt;quote&gt;agent = Agent( instructions=instructions, model=model, )&lt;/quote&gt;
    &lt;p&gt;The workflow change: The agent now understands our values around Test Driven Development and minimal changes. It stopped suggesting large refactors where a small fix would do (Mostly).&lt;/p&gt;
    &lt;p&gt;Now while we could continue building everything from absolute scratch and tweaking our prompts for days we want to go fast and use some tools other people have built - Enter Model Context Protocol (MCP).&lt;/p&gt;
    &lt;head rend="h2"&gt;The MCP Revolution: Pluggable Capabilities&lt;/head&gt;
    &lt;p&gt;This is where our agent transformed from a helpful assistant to something approaching the commercial CLI agents. The Model Context Protocol (MCP) allows us to add sophisticated capabilities by running specialized servers.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We can run these servers as a local process, so no data sharing, where we interact with STDIN/STDOUT to keep things simple and local. (More details on tools and MCP)&lt;/p&gt;
    &lt;head rend="h2"&gt;Sandboxed Python Execution&lt;/head&gt;
    &lt;p&gt;Using large language models to do calculations or executing arbitrary code they create is not effective and potentially very dangerous! To make our Agent more accurate and safe our first MCP addition was Pydantic Al‚Äôs default server for sandboxed Python code execution:&lt;/p&gt;
    &lt;quote&gt;run_python = MCPServerStdio( "deno", args=[ "run", "-N", "-R=node_modules", "-W=node_modules", "--node-modules-dir=auto", "jsr:@pydantic/mcp-run-python", "stdio", ], )&lt;/quote&gt;
    &lt;quote&gt;agent = Agent( ... mcp_servers=[ run_python ], )&lt;/quote&gt;
    &lt;p&gt;This gave our agent a sandbox where it could test ideas, prototype solutions, and verify its own suggestions.&lt;/p&gt;
    &lt;p&gt;NOTE: This is very different from running the tests where we need the local environment and is intended to be used to make calculations much more robust. This is because writing the code to output a number and then executing that code is much more reliable and understandable, scalable and repeatable than just generating the next token in a calculation. We have seen from frontier labs (including their leaked instructions) that this is a much better approach.&lt;/p&gt;
    &lt;p&gt;The workflow change: Doing calculations, even more complex ones, became significantly more reliable. This is useful for many things like dates, sums, counts etc. It also allows for a rapid iteration cycle of simple python code.&lt;/p&gt;
    &lt;head rend="h2"&gt;Up-to-Date library Documentation&lt;/head&gt;
    &lt;p&gt;LLMs are mostly trained in batch on historical data this gives a fixed cutoff while languages and dependencies continue to change and improve so we added Context7 for access to up to date python library documentation in LLM consumable format:&lt;/p&gt;
    &lt;quote&gt;context7 = MCPServerStdio( command="npx", args=["-y", "@upstash/context7-mcp"], tool_prefix="context" )&lt;/quote&gt;
    &lt;p&gt;The workflow change: When working with newer libraries or trying to use advanced features, the agent could look up current documentation rather than relying on potentially outdated training data. This made it much more reliable for real-world development work.&lt;/p&gt;
    &lt;head rend="h2"&gt;AWS MCPs&lt;/head&gt;
    &lt;p&gt;Since this particular agent was built with an AWS platform in mind, we added the AWS Labs MCP servers for comprehensive cloud docs and integration:&lt;/p&gt;
    &lt;quote&gt;awslabs = MCPServerStdio( command="uvx", args=["awslabs.core-mcp-server@latest"], env={"FASTMCP_LOG_LEVEL": "ERROR"}, tool_prefix="awslabs", ) aws_docs = MCPServerStdio( command="uvx", args=["awslabs.aws-documentation-mcp-server@latest"], env={"FASTMCP_LOG_LEVEL": "ERROR", "AWS_DOCUMENTATION_PARTITION": "aws"}, tool_prefix="aws_docs", )&lt;/quote&gt;
    &lt;p&gt;The workflow change: Now when I mentioned √¢Bedrock is timing out√¢ or √¢the model responses are getting truncated,√¢ the agent could directly access AWS documentation to help troubleshoot configuration issues. While we've only scratched the surface with these two servers, this is the tip of the iceberg‚Äîthe AWS Labs MCP collection includes servers for CloudWatch metrics, Lambda debugging, IAM policy analysis, and much more. Even with just documentation access, cloud debugging became more conversational and contextual.&lt;/p&gt;
    &lt;head rend="h2"&gt;Internet Search for Current Information&lt;/head&gt;
    &lt;p&gt;Sometimes you need information that's not in any documentation‚Äîrecent Stack Overflow discussions, GitHub issues, or the latest best practices. We added general internet search:&lt;/p&gt;
    &lt;quote&gt;internet_search = MCPServerStdio(command="uvx", args=["duckduckgo-mcp-server"])&lt;/quote&gt;
    &lt;p&gt;The workflow change: When encountering obscure errors or needing to understand recent changes in the ecosystem, the agent could search for current discussions and solutions. This was particularly valuable for debugging deployment issues or understanding breaking changes in dependencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Structured Problem Solving&lt;/head&gt;
    &lt;p&gt;One of the most valuable additions was the code reasoning MCP, which helps the agent think through complex problems systematically:&lt;/p&gt;
    &lt;quote&gt;code_reasoning = MCPServerStdio( command="npx", args=["-y", "@mettamatt/code-reasoning"], tool_prefix="code_reasoning", )&lt;/quote&gt;
    &lt;p&gt;The workflow change: Instead of jumping to solutions, the agent would break down complex problems into logical steps, explore alternative approaches, and explain its reasoning. This was invaluable for architectural decisions and debugging complex issues. I could ask √¢Why is this API call failing intermittently?√¢ and get a structured analysis of potential causes rather than just guesses.&lt;/p&gt;
    &lt;head rend="h2"&gt;Optimising for Reasoning&lt;/head&gt;
    &lt;p&gt;As we added more sophisticated capabilities, we noticed that reasoning and analysis tasks often took much longer than regular text generation‚Äîespecially when the output wasn't correctly formatted on the first try. We adjusted our Bedrock configuration to be more patient:&lt;/p&gt;
    &lt;quote&gt;bedrock_config = BotocoreConfig( read_timeout=300, connect_timeout=60, retries={"max_attempts": 3}, ) bedrock_client = boto3.client( "bedrock-runtime", region_name="eu-central-1", config=bedrock_config )&lt;/quote&gt;
    &lt;p&gt;The workflow change: The longer timeouts meant our agent could work through complex problems without timing out. When analyzing large codebases or reasoning through intricate architectural decisions, the agent could take the time needed to provide thorough, well-reasoned responses rather than rushing to incomplete solutions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Desktop Commander: Warning! With great power comes great responsibility!&lt;/head&gt;
    &lt;p&gt;At this point, our agent was already quite capable‚Äîit could reason through problems, execute code, search for information, and access AWS documentation. This MCP server transforms your agent from a helpful assistant into something that can actually do things in your development environment:&lt;/p&gt;
    &lt;quote&gt;desktop_commander = MCPServerStdio( command="npx", args=["-y", "@wonderwhy-er/desktop-commander"], tool_prefix="desktop_commander", )&lt;/quote&gt;
    &lt;p&gt;Desktop Commander provides an incredibly comprehensive toolkit: file system operations (read, write, search), terminal command execution with process management, surgical code editing with &lt;code&gt;edit_block&lt;/code&gt;, and even
      interactive REPL sessions. It's built on top of the MCP Filesystem Server
      but adds crucial capabilities like search-and-replace editing and
      intelligent process control.&lt;/p&gt;
    &lt;p&gt;The workflow change: This is where everything came together. I could now say √¢The authentication tests are failing, please fix the issue√¢ and the agent would:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1. Run the test suite to see the specific failures&lt;/item&gt;
      &lt;item&gt;2. Read the failing test files to understand what was expected&lt;/item&gt;
      &lt;item&gt;3. Examine the authentication module code&lt;/item&gt;
      &lt;item&gt;4. Search the codebase for related patterns&lt;/item&gt;
      &lt;item&gt;5. Look up the documentation for the relevant library&lt;/item&gt;
      &lt;item&gt;6. Make edits to fix the implementation&lt;/item&gt;
      &lt;item&gt;7. Re-run the tests to verify the fix&lt;/item&gt;
      &lt;item&gt;8. Search for similar patterns elsewhere that might need updating&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of this happened in a single conversation thread, with the agent maintaining context throughout. It wasn't just generating code suggestions‚Äîit was actively debugging, editing, and verifying fixes like a pair programming partner.&lt;/p&gt;
    &lt;p&gt;The security model is thoughtful too, with configurable allowed directories, blocked commands, and proper permission boundaries. You can learn more about its extensive capabilities at the Desktop Commander documentation.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Complete System&lt;/head&gt;
    &lt;p&gt;Here's our final agent configuration:&lt;/p&gt;
    &lt;quote&gt;import asyncio import subprocess import boto3 from pydantic_ai import Agent from pydantic_ai.mcp import MCPServerStdio from pydantic_ai.models.bedrock import BedrockConverseModel from pydantic_ai.providers.bedrock import BedrockProvider from botocore.config import Config as BotocoreConfig bedrock_config = BotocoreConfig( read_timeout=300, connect_timeout=60, retries={"max_attempts": 3}, ) bedrock_client = boto3.client( "bedrock-runtime", region_name="eu-central-1", config=bedrock_config ) model = BedrockConverseModel( "eu.anthropic.claude-sonnet-4-20250514-v1:0", provider=BedrockProvider(bedrock_client=bedrock_client), ) agent = Agent( model=model, ) instructions = """ You are a specialised agent for maintaining and developing the XXXXXX codebase. ## Development Guidelines: 1. **Test Failures:** - When tests fail, fix the implementation first, not the tests - Tests represent expected behavior; implementation should conform to tests - Only modify tests if they clearly don't match specifications 2. **Code Changes:** - Make the smallest possible changes to fix issues - Focus on fixing the specific problem rather than rewriting large portions - Add unit tests for all new functionality before implementing it 3. **Best Practices:** - Keep functions small with a single responsibility - Implement proper error handling with appropriate exceptions - Be mindful of configuration dependencies in tests Remember to examine test failure messages carefully to understand the root cause before making any changes. """ run_python = MCPServerStdio( "deno", args=[ "run", "-N", "-R=node_modules", "-W=node_modules", "--node-modules-dir=auto", "jsr:@pydantic/mcp-run-python", "stdio", ], ) internet_search = MCPServerStdio(command="uvx", args=["duckduckgo-mcp-server"]) code_reasoning = MCPServerStdio( command="npx", args=["-y", "@mettamatt/code-reasoning"], tool_prefix="code_reasoning", ) desktop_commander = MCPServerStdio( command="npx", args=["-y", "@wonderwhy-er/desktop-commander"], tool_prefix="desktop_commander", ) awslabs = MCPServerStdio( command="uvx", args=["awslabs.core-mcp-server@latest"], env={"FASTMCP_LOG_LEVEL": "ERROR"}, tool_prefix="awslabs", ) aws_docs = MCPServerStdio( command="uvx", args=["awslabs.aws-documentation-mcp-server@latest"], env={"FASTMCP_LOG_LEVEL": "ERROR", "AWS_DOCUMENTATION_PARTITION": "aws"}, tool_prefix="aws_docs", ) context7 = MCPServerStdio( command="npx", args=["-y", "@upstash/context7-mcp"], tool_prefix="context" ) agent = Agent( instructions=instructions, model=model, mcp_servers=[ run_python, internet_search, code_reasoning, context7, awslabs, aws_docs, desktop_commander, ], ) @agent.tool_plain() def run_unit_tests() -&amp;gt; str: """Run unit tests using uv.""" result = subprocess.run( ["uv", "run", "pytest", "-xvs", "tests/"], capture_output=True, text=True ) return result.stdout async def main(): async with agent.run_mcp_servers(): await agent.to_cli() if __name__ == "__main__": asyncio.run(main())&lt;/quote&gt;
    &lt;p&gt;How it changes our workflow:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Debugging becomes collaborative: you have an intelligent partner that can analyze error messages, suggest hypotheses, and help test solutions.&lt;/item&gt;
      &lt;item&gt;Learning accelerates: when working with unfamiliar libraries or patterns, the agent can explain existing code, suggest improvements, and teach you why certain approaches work better.&lt;/item&gt;
      &lt;item&gt;Context switching reduces: rather than jumping between documentation, Stack Overflow, AWS Console, and your IDE, you have a single interface that can access all these resources while maintaining context about your specific problem.&lt;/item&gt;
      &lt;item&gt;Problem-solving becomes structured: rather than jumping to solutions, the agent can break down complex issues into logical steps, explore alternatives, and explain its reasoning. Like having a real life talking rubber duck!&lt;/item&gt;
      &lt;item&gt;Code review improves: the agent can review your changes, spot potential issues, and suggest improvements before you commit‚Äîlike having a senior developer looking over your shoulder.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What We Learned About CLI Agents&lt;/head&gt;
    &lt;p&gt;Building our own agent revealed several insights about this emerging paradigm:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MCP is (almost) all you need: the magic isn't in any single capability, but in how they work together. The agent that can run tests, read files, search documentation, execute code, access AWS services, and reason through problems systematically becomes qualitatively different from one that can only do any single task.&lt;/item&gt;
      &lt;item&gt;Current information is crucial: having access to real-time search and up-to-date documentation makes the agent much more reliable for real-world development work where training data might be outdated.&lt;/item&gt;
      &lt;item&gt;Structured thinking matters: the code reasoning capability transforms the agent from a clever autocomplete into a thinking partner that can break down complex problems and explore alternative solutions.&lt;/item&gt;
      &lt;item&gt;Context is king: commercial agents like Claude Code are impressive partly because they maintain context across all these different tools. Your agent needs to remember what it learned from the test run when it's making file changes.&lt;/item&gt;
      &lt;item&gt;Specialisation matters: our agent works better for our specific codebase than general-purpose tools because it understands our patterns, conventions, and tool preferences. If it falls short in any area then we can go and make the required changes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Road Ahead&lt;/head&gt;
    &lt;p&gt;The CLI agent paradigm is still evolving rapidly. Some areas we're exploring:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AWS-specific tooling: the AWS Labs MCP servers (https://awslabs.github.io/mcp/) provide incredible depth for cloud-native development‚Äîfrom CloudWatch metrics to Lambda debugging to IAM policy analysis.&lt;/item&gt;
      &lt;item&gt;Workflow Enhancements: teaching the agent our common development workflows so it can handle routine tasks end-to-end. Connecting the agent to our project management tools so it can understand priorities and coordinate with team processes.&lt;/item&gt;
      &lt;item&gt;Benchmarking: Terminal Bench looks like a great dataset and leaderboard to test this toy agent against the big boys!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why This Matters&lt;/head&gt;
    &lt;p&gt;CLI coding agents represent a fundamental shift from AI as a writing assistant to AI as a development partner. Unlike Copilot's autocomplete or ChatGPT's Q&amp;amp;A, these agents can:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Understand your entire project context&lt;/item&gt;
      &lt;item&gt;Execute tasks across multiple tools&lt;/item&gt;
      &lt;item&gt;Maintain state across complex workflows&lt;/item&gt;
      &lt;item&gt;Learn from your specific codebase and patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Building one yourself‚Äîeven a simple version‚Äîgives you insights into where this technology is heading and how to make the most of commercial tools when they arrive.&lt;/p&gt;
    &lt;p&gt;The future of software development isn't just about writing code faster. It's about having an intelligent partner that understands your goals, your constraints, and your codebase well enough to help you think through problems and implement solutions collaboratively.&lt;/p&gt;
    &lt;p&gt;And the best way to understand that future? Build it yourself.&lt;/p&gt;
    &lt;head&gt;Significant Revisions&lt;/head&gt;
    &lt;p&gt;27 August 2025: published&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45055439</guid></item><item><title>Some thoughts on LLMs and software development</title><link>https://martinfowler.com/articles/202508-ai-thoughts.html</link><description>&lt;doc fingerprint="192b3375fcf305ad"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Some thoughts on LLMs and Software Development&lt;/head&gt;
    &lt;p&gt;I√¢m about to head away from looking after this site for a few weeks (part vacation, part work stuff). As I contemplate some weeks away from the daily routine, I feel an urge to share some scattered thoughts about the state of LLMs and AI.&lt;/p&gt;
    &lt;p&gt;√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢&lt;/p&gt;
    &lt;p&gt;I√¢ve seen a few early surveys on the effect AI is having on software development, is it really speeding folks up, does it improve or wreck code quality? One of the big problems with these surveys is that they aren√¢t taking into account how people are using the LLMs. From what I can tell the vast majority of LLM usage is fancy auto-complete, often using co-pilot. But those I know who get the most value from LLMs reckon that auto-complete isn√¢t very useful, preferring approaches that allow the LLM to directly read and edit source code files to carry out tasks. My concern is that surveys that ignore the different work-flows of using LLMs will produce data that√¢s going to send people down the wrong paths.&lt;/p&gt;
    &lt;p&gt;(Another complication is the varying capabilities of different models.)&lt;/p&gt;
    &lt;p&gt;√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢&lt;/p&gt;
    &lt;p&gt;I√¢m often asked, √¢what is the future of programming?√¢ Should people consider entering software development now? Will LLMs eliminate the need for junior engineers? Should senior engineers get out of the profession before it√¢s too late? My answer to all these questions is √¢I haven√¢t the foggiest√¢. Furthermore I think anyone who says they know what this future will be is talking from an inappropriate orifice. We are still figuring out how to use LLMs, and it will be some time before we have a decent idea of how to use them well, especially if they gain significant improvements.&lt;/p&gt;
    &lt;p&gt;What I suggest, is that people experiment with them. At the least, read about what others are doing, but pay attention to the details of their workflows. Preferably experiment yourself, and do share your experiences.&lt;/p&gt;
    &lt;p&gt;√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢&lt;/p&gt;
    &lt;p&gt;I√¢m also asked: √¢is AI a bubble√¢? To which my answer is √¢OF COURSE IT√¢S A BUBBLE√¢. All major technological advances have come with economic bubbles, from canals and railroads to the internet. We know with near 100% certainty that this bubble will pop, causing lots of investments to fizzle to nothing. However what we don√¢t know is when it will pop, and thus how big the bubble will have grown, generating some real value in the process, before that happens. It could pop next month, or not for a couple of years.&lt;/p&gt;
    &lt;p&gt;We also know that when the bubble pops, many firms will go bust, but not all. When the dot-com bubble burst, it killed pets.com, it killed Webvan√¢¬¶ but it did not kill Amazon.&lt;/p&gt;
    &lt;p&gt;√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢&lt;/p&gt;
    &lt;p&gt;I retired from public speaking a couple of years ago. But while I don√¢t miss the stress of giving talks, I do miss hanging out with my friends in the industry. So I√¢m looking forward to catching up with many of them at GOTO Copenhagen. I√¢ve been involved with the GOTO conference series since the 1990s (when it was called JAOO), and continue to be impressed with how they put together a fascinating program.&lt;/p&gt;
    &lt;p&gt;√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢¬¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢&lt;/p&gt;
    &lt;p&gt;My former colleague Rebecca Parsons, has been saying for a long time that hallucinations aren√¢t a bug of LLMs, they are a feature. Indeed they are the feature. All an LLM does is produce hallucinations, it√¢s just that we find some of them useful.&lt;/p&gt;
    &lt;p&gt;One of the consequences of this is that we should always consider asking the LLM the same question more than once, perhaps with some variation in the wording. Then we can compare answers, indeed perhaps ask the LLM to compare answers for us. The difference in the answers can be as useful as the answers themselves.&lt;/p&gt;
    &lt;p&gt;Certainly if we ever ask a hallucination engine for a numeric answer, we should ask it at least three times, so we get some sense of the variation. Furthermore we shouldn√¢t ask an LLM to calculate an answer than we can calculate deterministically (yes, I√¢ve seen this). It is OK to ask an LLM to generate code to calculate an answer (but still do it more than once).&lt;/p&gt;
    &lt;p&gt;√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢&lt;/p&gt;
    &lt;p&gt;Other forms of engineering have to take into account the variability of the world. A structural engineer builds in tolerance for all the factors she can√¢t measure. (I remember being told early in my career that the unique characteristic of digital electronics was that there was no concept of tolerances.) Process engineers consider that humans are executing tasks, and will sometimes be forgetful or careless. Software Engineering is unusual in that it works with deterministic machines. Maybe LLMs mark the point where we join our engineering peers in a world on non-determinism.&lt;/p&gt;
    &lt;p&gt;√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢&lt;/p&gt;
    &lt;p&gt;I√¢ve often heard, with decent reason, an LLM compared to a junior colleague. But I find LLMs are quite happy to say √¢all tests green√¢, yet when I run them, there are failures. If that was a junior engineer√¢s behavior, how long would it be before H.R. was involved?&lt;/p&gt;
    &lt;p&gt;√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢√Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √Ç √¢&lt;/p&gt;
    &lt;p&gt;LLMs create a huge increase in the attack surface of software systems. Simon Willison described the The Lethal Trifecta for AI agents: an agent that combines access to your private data, exposure to untrusted content, and a way to externally communicate (√¢exfiltration√¢). That √¢untrusted content√¢ can come in all sorts of ways, ask it to read a web page, and an attacker can easily put instructions on the website in 1pt white-on-white font to trick the gullible LLM to obtain that private data.&lt;/p&gt;
    &lt;p&gt;This is particularly serious when it comes to agents acting in a browser. Read an attacker√¢s web page, and it could trick the agent to go to your bank account in another tab and √¢buy you a present√¢ by transferring your balance to the kind attacker. Willison√¢s view is that √¢the entire concept of an agentic browser extension is fatally flawed and cannot be built safely√¢.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45055641</guid></item><item><title>My startup banking story (2023)</title><link>https://mitchellh.com/writing/my-startup-banking-story</link><description>&lt;doc fingerprint="36308099c0e4fd45"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;My Startup Banking Story&lt;/head&gt;
    &lt;p&gt;As a relatively new member of adult society, and an absolute infant of the business world, I didn't think much about bank choice. I figured: you put money in, you take money out, they're all the same. I also figured a local branch of a global bank is just a fungible tentacle of the giant banking machine, so also... who cares. Both incorrect assumptions, but let's relive and rediscover the effect of these assumptions as I did.&lt;/p&gt;
    &lt;p&gt;I start my company. I am a 22 year old recent college graduate living in San Francisco and pursuing the startup dream. I file my incorporation paperwork and wait to receive the necessary information for one of the first steps in the life of any new business: opening a bank account.&lt;/p&gt;
    &lt;p&gt;My filing is processed and I receive my EIN while visiting my parents in a suburb of Los Angeles. I have time to kill during one of the days so I drive down to the nearest Chase bank branch and open a business banking account. We'll call the person who helped me at the local branch Alex (this will be important later). I fund that account with a $20,000 personal loan which was almost all of my savings. I get an account number, an online login, and boom, we're in business!&lt;/p&gt;
    &lt;p&gt;About 6 months later, I raise a ~$1M seed round. I supply my Chase business banking account information for the wire, and at close the funding is wired to the account. I am sitting in a cafe in downtown San Francisco and I receive a call from an unknown number -- it's Alex, the banker that helped me open my account. He is being very casual, sort of like "Hey, just wanted to check on things." "I noticed a big deposit and wanted to make sure you had everything you needed." etc. For my side, I am mostly confused: why is this person calling me? I mostly say things like "yes yes I'm fine" and end the call quickly. Some wheels have started turning in Southern California, and I just hadn't known it yet.&lt;/p&gt;
    &lt;p&gt;Someone out there is probably mentally screaming at me "you fool!" at this point. With hindsight, I agree, but I will remind you dear reader that I have only been legally allowed to purchase alcohol for just over a year at this point in my life in the story.&lt;/p&gt;
    &lt;p&gt;The two years since 2012 -- from a banking perspective -- are quiet. Alex doesn't call me again, and we have no changes in our banking setup. For two years, the company was in heads-down building mode. We had shown significant product traction and were now ready to ramp up hiring to continue building.&lt;/p&gt;
    &lt;p&gt;At the end of 2014, we raise a $10.2M series A. I once again provide the same Chase business banking account and when the round closes, the funds are wired. Surprise surprise, Alex calls me! I'm starting to realize banks get an alert when there are major changes in account balances. Regardless, I once again brush Alex off -- "everything is good thanks! bye!" -- and continue on with my life.&lt;/p&gt;
    &lt;p&gt;At this point, I am bewildered that this guy I met at the random local branch to sign some papers is the one calling me, but didn't think much more of it at the time.&lt;/p&gt;
    &lt;p&gt;Once again, the two years since 2014 are mostly quiet from a banking perspective. Alex called more regularly to "check in" but otherwise nothing has changed. We still bank with Chase. I still have never gone back into a branch. I do everything online.&lt;/p&gt;
    &lt;p&gt;In the fall of 2016, we raise a $24M series B. I once again provide the same Chase business banking account and when the round closes, the funds are wired. Again, Alex calls. Again, I brush him off. The bank is where I plant money, I don't need anyone calling me. I just want to focus on building the company.&lt;/p&gt;
    &lt;p&gt;Throughout 2016, we had been building out an executive team for the company. And around the same time of the funding, we hire a Vice President of Finance. As he gets up to speed with our financial footing, he notices we have ~$35M sitting in cash in a Chase bank account. This is obviously not a smart thing to do, so he suggests some financial plans for how to better safeguard and utilize this mountain of cash.&lt;/p&gt;
    &lt;p&gt;As part of these plans, he suggests moving to Silicon Valley Bank (SVB). They're local to the Bay Area, he's worked with them before, and their bankers understand startups. It'll make accounts receivables, payables, payroll, etc. easier. To me, a bank is a bank is a bank, and if it helps make his job easier, I support his plan.&lt;/p&gt;
    &lt;p&gt;I log into the Chase online portal and initiate a wire for the full account balance to SVB. I have to pay something like a $30 fee to wire $35M (inconsequential to the story, but amusing nonetheless). Someone calls me for verification -- not Alex -- and the wire processes. Boom, we're done with Chase. Or so I think.&lt;/p&gt;
    &lt;p&gt;Alex calls me the next day. The day we initiated the wire was his day off. He sounds slightly agitated. I wasn't rude to him, but I was short with him. I switched banks, that's all there is to it. Thanks and goodbye. I never talk to Alex ever again. A bank is a bank is a bank, you put money in, you get money out, I don't understand why I would need to talk to someone.&lt;/p&gt;
    &lt;p&gt;I once again interrupt this story to appeal to the readers who are screaming at me and thank you for joining me on this story recounting my learning journey. Rest assured, at this point in the story, a professional was now in charge of the company's finances. But the decisions of the years leading up to this would have lingering effects for a few more years...&lt;/p&gt;
    &lt;p&gt;We now take a brief detour from the company, because this is where my personal life becomes relevant to the story.&lt;/p&gt;
    &lt;p&gt;For the prior three years, I had been living in Los Angeles. At some point during 2017, I had to go to a local Chase branch to make some changes to my personal accounts. It has been close to a year since the company stopped using Chase.&lt;/p&gt;
    &lt;p&gt;I visit the closest bank branch to my apartment. This bank branch is 20 miles north of where my parents live -- or the area with the branch where I opened the original company business bank accounts. I'm going to Chase for purely personal reasons, but this information is unfortunately relevant to the story.&lt;/p&gt;
    &lt;p&gt;At my local branch, I walk up to the teller and provide some handwritten information: my name, account number, desired transaction, etc. The teller looks at the paper, then looks at me, then looks back at the paper, then asks "Are you the HashiCorp guy?" What? HashiCorp is doing well but its not at all something a random non-technical consumer would know about. What is going on?&lt;/p&gt;
    &lt;p&gt;I say yes and he acknowledges but doesn't automatically offer any more information. I have to know, so I continue "How do you know that?" His response is "Dude, everyone at Chase down here knows about HashiCorp." Huh?&lt;/p&gt;
    &lt;p&gt;Up to this point, everything in the story is what I know and experienced first hand. What follows however is now second hand information as told by this teller. I haven't verified it, but other employees (at other branches) have said similar things to me over the years.&lt;/p&gt;
    &lt;p&gt;The teller proceeds to explain that Alex -- the guy I opened my original company account with -- became a fast rising star in the area. He had opened a business account in a small suburb that grew from $20,000 to $35,000,000 in balances in just four years! Despite the business (my business) not engaging in higher-revenue activities with the bank, the opportunity this account represented to the small business wing of the small suburban branch stirred up some excitement. It was just a matter of time.&lt;/p&gt;
    &lt;p&gt;And then, overnight, the account went to $0. Without talking to anyone, without any prior warning, that account was gone. I used online banking to transfer the entirety of the balance to another bank. The small suburban branch viewed this as a huge loss and Alex came into work with some tough questions and no answers. I instantly recalled feeling that Alex was agitated when he called me the day after the transfer, and I now had an idea of why.&lt;/p&gt;
    &lt;p&gt;I don't know what happened to Alex, the teller said he was "no longer working in the area" and said it with a noticably negative tone. I don't know what this means and I never found out. Perhaps, he just moved.&lt;/p&gt;
    &lt;p&gt;Following this event, Chase began an educational series to other local branches in the Los Angeles area explaining that there are these "startups" and how their financial patterns do not match those of a typical business. This series taught branches how to identify startups and how to consider their accounts. The case study they used for this presentation: HashiCorp.&lt;/p&gt;
    &lt;p&gt;It has been two years since hiring our VP of Finance and our financial department is in really healthy shape. I still have certain approval rights but no longer directly manage the accounts of the company.&lt;/p&gt;
    &lt;p&gt;Given the recent events with Silicon Valley Bank, I feel it's important to mention that at this point of the company, we had already begun diversifying our balances across multiple banks. SVB will not be mentioned again for the remainder of the story.&lt;/p&gt;
    &lt;p&gt;I'm working at my office at home in Los Angeles and I receive a phone call from our finance department. That's weird, I rarely receive phone calls. They tell me that during a routine internal audit, they realized there are a few customer accounts that are still paying their bill into the old Chase account.&lt;/p&gt;
    &lt;p&gt;I never closed that original Chase business account back in 2016. Let me explain how that happens. To close an account, I had to do it in person at any local Chase branch. Startups are busy, the account balance in 2016 was $0, and so I just put it off. Well, a couple years passed, it was still open, and a few customers were actually sending payments to it.&lt;/p&gt;
    &lt;p&gt;Worse, upon the realization that a few customers were paying into this account, our finance team realized that there was also fraud. For over a year, someone had been wiring thousands of dollars out every few weeks. We were short over $100,000 due to fraud. The finance team immediately called Chase and reported the fraud, locked down the account, and Chase started an investigation.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the finance team wanted me to close the account and wire the remaining balance to our actual business bank. With the fraud actively being handled by Chase and the finance team, I take on the task of closing the account. I immediately head to the nearest local Chase branch (once again a branch I've never been to before) and explain the situation.&lt;/p&gt;
    &lt;p&gt;After waiting for 15 minutes, a manager walks up to me. I know this can't be good. The branch manager explains that due to the actions taken to lock down the account for fraud, electronic transfers are unavailable. It doesn't matter that I'm provably the person who opened the account, electronic transfers are "impossible."&lt;/p&gt;
    &lt;p&gt;I say okay, and ask how I am supposed to close the account and transfer the remaining balance. He said I can close the account and withdraw the remaining balance only in cash. Cash? At this point, I literally asked: "like, green paper money cash?" He says yes. The balance in the account is somewhere around $1M.&lt;/p&gt;
    &lt;p&gt;I spent another two hours at the bank, juggling between calling our finance department, talking to this branch manager, and calling the Chase business phone line. We determine that instead of literal green cash, I can get a cashier's check. But there is a major problem: the amount the cashier's check is made out for has to be available at that local branch (or, whichever branch issues it). And, well, local branches I guess don't usually have $1M cash lying around. Or, if they do, its not enough to cover other business activities for the day so they're not willing to part with it.&lt;/p&gt;
    &lt;p&gt;The bank manager gives me the phone number of another branch manager that "may be able to help me." He literally writes down a phone number on a piece of paper. This is all feeling so surreal. I call this number and its for a slightly larger branch a few miles down the road. He says "you're the HashiCorp guy right?" And I roll my eyes. My infamy in the area is still well known.&lt;/p&gt;
    &lt;p&gt;This manager is very helpful, if not a bit gruff. He explains to me that each local branch has some sort of performance metric based on inflows and outflows at the given branch. Therefore, funding a $1M cash withdrawal was not attractive to them. I'm learning a lot in a really condensed period of time at this point. I don't even know if what he's telling me is true, or legal, all I hear is "this is going to be hard to do if you want it all at once."&lt;/p&gt;
    &lt;p&gt;But we do want it all at once. And we want to close the account. Now. He is not happy, but he says he'll call me back in 24 to 48 hours. True to his word, he calls me back the next day. He says that he had to coordinate to ensure his branch had the proper funding to satisfy this transaction, and that the funding would be available at a specific date a few days hence. He said I have to do the withdrawal that day because his branch will not hold that amount in cash for any longer.&lt;/p&gt;
    &lt;p&gt;He also subtly suggested I hire personal security or otherwise deposit those funds somewhere with haste. I believe his exact words were "if you lose that check, I can't help you." Again, this was a one time event, and I don't know how true that all is, but it was said to me.&lt;/p&gt;
    &lt;p&gt;A few days later, I walk into the branch (I did not hire personal security). I tell the teller my name and there is a flicker of immediate recognition. The teller guides me to a cubicle, the account is successfully closed, I'm issued a $1M cashier's check, and I walk out the door.&lt;/p&gt;
    &lt;p&gt;My business banking relationship with Chase is, at long last, complete.&lt;/p&gt;
    &lt;p&gt;I want to make it clear that Chase could've been an excellent banking partner. I never gave them the chance. I never told them what my business does or what I'd use the money for. I never talked to anyone (besides saying what I needed to get off the phone). This story isn't a cautionary tale about Chase, it is rather recounting my naivete as a young, first-time startup founder.&lt;/p&gt;
    &lt;p&gt;Epilogue.&lt;/p&gt;
    &lt;p&gt;The cashier's check was uneventfully deposited into our primary business banking account shortly after I walked out of the Chase branch.&lt;/p&gt;
    &lt;p&gt;The fraud investigation took a few months to complete but we were able to recover all of the lost funds.&lt;/p&gt;
    &lt;p&gt;Enough time has passed and employees cycled that I'm no longer recognized at any Los Angeles area Chase branches.&lt;/p&gt;
    &lt;p&gt;I look back on these events and there are many places I cringe. At the same time, I can't imagine making different choices because I was acting in good faith at all times with the knowledge I had. I think the choices I made were reasonable for any new founder, and I know many founders who have made similar choices.&lt;/p&gt;
    &lt;p&gt;Ultimately, there was no long term negative impact of the events that transpired (except maybe for Alex, but I truly don't know) and I can now look back on it with amusement.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45056177</guid></item><item><title>Fuck up my site ‚Äì Turn any website into beautiful chaos</title><link>https://www.fuckupmysite.com/?url=https%3A%2F%2Fnews.ycombinator.com&amp;torchCursor=true&amp;comicSans=true&amp;fakeCursors=true&amp;peskyFly=true</link><description>&lt;doc fingerprint="a9a77b49597bf6f1"&gt;
  &lt;main&gt;
    &lt;p&gt;DESTRUCTION LEVEL0%&lt;/p&gt;
    &lt;p&gt;‚ñì&lt;/p&gt;
    &lt;head rend="h1"&gt;fuckupmysite&lt;/head&gt;
    &lt;p&gt;Some people just want to watch the web burn&lt;/p&gt;
    &lt;head rend="h2"&gt;üòàChaos Settings&lt;/head&gt;
    &lt;p&gt;3 of 6 agents of chaos enabled&lt;/p&gt;
    &lt;p&gt;‚ö†Ô∏è&lt;/p&gt;
    &lt;head rend="h3"&gt;IMPORTANT DISCLAIMER - FOR PARODY &amp;amp; ENTERTAINMENT ONLY&lt;/head&gt;
    &lt;p&gt;This tool is for parody and entertainment purposes only. It temporarily applies visual chaos effects to websites for comedic effect. We do not store, collect, or transmit any personal information.&lt;/p&gt;
    &lt;p&gt;NEVER enter passwords, credit card details, or any sensitive information while using this tool. The proxied sites are not secure and should not be used for any real transactions or logins.&lt;/p&gt;
    &lt;p&gt;By using this tool, you acknowledge that it's purely for entertainment and you will not enter any sensitive data. Banking, financial, healthcare, and government sites are blocked for safety.&lt;/p&gt;
    &lt;p&gt;Heads up: Not every site plays nice with the chaos. Got feedback or discovered something broken? Let me know on Twitter&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45057020</guid></item><item><title>Expert: LSP for Elixir</title><link>https://github.com/elixir-lang/expert</link><description>&lt;doc fingerprint="24853a795d5f6fa5"&gt;
  &lt;main&gt;
    &lt;p&gt;Expert is the official language server implementation for the Elixir programming language.&lt;/p&gt;
    &lt;p&gt;You can download Expert from the releases page for your operating system and architecture. Put the executable somewhere on your &lt;code&gt;$PATH&lt;/code&gt;, like &lt;code&gt;~/.local/bin/expert&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;For editor specific installation instructions, please refer to the Installation Instructions&lt;/p&gt;
    &lt;p&gt;If you want to try out the latest features, you can download a nightly build.&lt;/p&gt;
    &lt;p&gt;Using the GH CLI, you can run the following command to download the latest nightly build:&lt;/p&gt;
    &lt;code&gt;gh release download nightly --pattern 'expert_linux_amd64' --repo elixir-lang/expert&lt;/code&gt;
    &lt;p&gt;Then point your editor to the downloaded binary.&lt;/p&gt;
    &lt;p&gt;To build Expert from source, you need Zig &lt;code&gt;0.14.1&lt;/code&gt; installed on your system.&lt;/p&gt;
    &lt;p&gt;Then you can run the following command or follow the instructions in the Installation Instructions:&lt;/p&gt;
    &lt;code&gt;just release-local&lt;/code&gt;
    &lt;p&gt;This will build the Expert binary and place it in the &lt;code&gt;apps/expert/burrito_out&lt;/code&gt; directory. You can then point your
editor to this binary.&lt;/p&gt;
    &lt;p&gt;Thank you to our corporate sponsors! If you'd like to start sponsoring the project, please read more below.&lt;/p&gt;
    &lt;p&gt;For companies wanting to directly sponsor full time work on Expert, please reach out to Dan Janowski: EEF Chair of Sponsorship WG at danj@erlef.org.&lt;/p&gt;
    &lt;p&gt;Individuals can donate using GitHub sponsors. Team members are listed in the sidebar.&lt;/p&gt;
    &lt;p&gt;Expert source code is released under Apache License 2.0.&lt;/p&gt;
    &lt;p&gt;Check LICENSE file for more information.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45057322</guid></item><item><title>The Space Shuttle Columbia disaster and the over-reliance on PowerPoint (2019)</title><link>https://mcdreeamiemusings.com/blog/2019/4/13/gsux1h6bnt8lqjd7w2t2mtvfg81uhx</link><description>&lt;doc fingerprint="b789dbf4ae617ccb"&gt;
  &lt;main&gt;
    &lt;p&gt;We‚Äôve all sat in those presentations. A speaker with a stream of slides full of text, monotonously reading them off as we read along. We‚Äôre so used to it we expect it. We accept it. We even consider it ‚Äòlearning‚Äô. As an educator I push against ‚Äòdeath by PowerPoint‚Äô and I'm fascinated with how we can improve the way we present and teach. The fact is we know that PowerPoint kills. Most often the only victims are our audience‚Äôs inspiration and interest. This, however, is the story of a PowerPoint slide that actually helped kill seven people.&lt;/p&gt;
    &lt;p&gt;January 16th 2003. NASA Mission STS-107 is underway. The Space Shuttle Columbia launches carrying its crew of seven to low orbit. Their objective was to study the effects of microgravity on the human body and on ants and spiders they had with them. Columbia had been the first Space Shuttle, first launched in 1981 and had been on 27 missions prior to this one. Whereas other shuttle crews had focused on work to the Hubble Space Telescope or to the International Space Station this mission was one of pure scientific research.&lt;/p&gt;
    &lt;p&gt;The launch proceeded as normal. The crew settled into their mission. They would spend 16 days in orbit, completing 80 experiments. One day into their mission it was clear to those back on Earth that something had gone wrong.&lt;/p&gt;
    &lt;p&gt;As a matter of protocol NASA staff reviewed footage from an external camera mounted to the fuel tank. At eighty-two seconds into the launch a piece of spray on foam insulation (SOFI) fell from one of the ramps that attached the shuttle to its external fuel tank. As the crew rose at 28,968 kilometres per hour the piece of foam collided with one of the tiles on the outer edge of the shuttle‚Äôs left wing.&lt;/p&gt;
    &lt;p&gt;It was impossible to tell from Earth how much damage this foam, falling nine times faster than a fired bullet, would have caused when it collided with the wing. Foam falling during launch was nothing new. It had happened on four previous missions and was one of the reasons why the camera was there in the first place. But the tile the foam had struck was on the edge of the wing designed to protect the shuttle from the heat of Earth‚Äôs atmosphere during launch and re-entry. In space the shuttle was safe but NASA didn‚Äôt know how it would respond to re-entry. There were a number of options. The astronauts could perform a spacewalk and visually inspect the hull. NASA could launch another Space Shuttle to pick the crew up. Or they could risk re-entry.&lt;/p&gt;
    &lt;p&gt;NASA officials sat down with Boeing Corporation engineers who took them through three reports; a total of 28 slides. The salient point was whilst there was data showing that the tiles on the shuttle wing could tolerate being hit by the foam this was based on test conditions using foam more than 600 times smaller than that that had struck Columbia. This is the slide the engineers chose to illustrate this point:&lt;/p&gt;
    &lt;p&gt;NASA managers listened to the engineers and their PowerPoint. The engineers felt they had communicated the potential risks. NASA felt the engineers didn‚Äôt know what would happen but that all data pointed to there not being enough damage to put the lives of the crew in danger. They rejected the other options and pushed ahead with Columbia re-entering Earth‚Äôs atmosphere as normal. Columbia was scheduled to land at 0916 (EST) on February 1st 2003. Just before 0900, 61,170 metres above Dallas at 18 times the speed of sound, temperature readings on the shuttle‚Äôs left wing were abnormally high and then were lost. Tyre pressures on the left side were soon lost as was communication with the crew. At 0912, as Columbia should have been approaching the runway, ground control heard reports from residents near Dallas that the shuttle had been seen disintegrating. Columbia was lost and with it her crew of seven. The oldest crew member was 48.&lt;/p&gt;
    &lt;p&gt;The shuttle programme was on lock down, grounded for two years as the investigation began. The cause of the accident became clear: a hole in a tile on the left wing caused by the foam let the wing dangerously overheat until the shuttle disintegrated.&lt;/p&gt;
    &lt;p&gt;The questions to answer included a very simple one: Why, given that the foam strike had occurred at a force massively out of test conditions had NASA proceeded with re-entry?&lt;/p&gt;
    &lt;p&gt;Edward Tufte, a Professor at Yale University and expert in communication reviewed the slideshow the Boeing engineers had given NASA, in particular the above slide. His findings were tragically profound.&lt;/p&gt;
    &lt;p&gt;Firstly, the slide had a misleadingly reassuring title claiming that test data pointed to the tile being able to withstand the foam strike. This was not the case but the presence of the title, centred in the largest font makes this seem the salient, summary point of this slide. This helped Boeing‚Äôs message be lost almost immediately.&lt;/p&gt;
    &lt;p&gt;Secondly, the slide contains four different bullet points with no explanation of what they mean. This means that interpretation is left up to the reader. Is number 1 the main bullet point? Do the bullet points become less important or more? It‚Äôs not helped that there‚Äôs a change in font sizes as well. In all with bullet points and indents six levels of hierarchy were created. This allowed NASA managers to imply a hierarchy of importance in their head: the writing lower down and in smaller font was ignored. Actually, this had been where the contradictory (and most important) information was placed.&lt;/p&gt;
    &lt;p&gt;Thirdly, there is a huge amount of text, more than 100 words or figures on one screen. Two words, ‚ÄòSOFI‚Äô and ‚Äòramp‚Äô both mean the same thing: the foam. Vague terms are used. Sufficient is used once, significant or significantly, five times with little or no quantifiable data. As a result this left a lot open to audience interpretation. How much is significant? Is it statistical significance you mean or something else?&lt;/p&gt;
    &lt;p&gt;Finally the single most important fact, that the foam strike had occurred at forces massively out of test conditions, is hidden at the very bottom. Twelve little words which the audience would have had to wade through more than 100 to get to. If they even managed to keep reading to that point. In the middle it does say that it is possible for the foam to damage the tile. This is in the smallest font, lost.&lt;/p&gt;
    &lt;p&gt;NASA‚Äôs subsequent report criticised technical aspects along with human factors. Their report mentioned an over-reliance on PowerPoint:&lt;/p&gt;
    &lt;p&gt;‚ÄúThe Board views the endemic use of PowerPoint briefing slides instead of technical papers as an illustration of the problematic methods of technical communication at NASA.‚Äù&lt;/p&gt;
    &lt;p&gt;Edward Tufte‚Äôs full report makes for fascinating reading. Since being released in 1987 PowerPoint has grown exponentially to the point where it is now estimated than thirty million PowerPoint presentations are made every day. Yet, PowerPoint is blamed by academics for killing critical thought. Amazon‚Äôs CEO Jeff Bezos has banned it from meetings. Typing text on a screen and reading it out loud does not count as teaching. An audience reading text off the screen does not count as learning. Imagine if the engineers had put up a slide with just: ‚Äúfoam strike more than 600 times bigger than test data.‚Äù Maybe NASA would have listened. Maybe they wouldn‚Äôt have attempted re-entry. Next time you‚Äôre asked to give a talk remember Columbia. Don‚Äôt just jump to your laptop and write out slides of text. Think about your message. Don‚Äôt let that message be lost amongst text. Death by PowerPoint is a real thing. Sometimes literally.&lt;/p&gt;
    &lt;p&gt;Thanks for reading&lt;/p&gt;
    &lt;p&gt;- Jamie&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45057404</guid></item><item><title>Rupert's Property</title><link>https://johncarlosbaez.wordpress.com/2025/08/28/a-polyhedron-without-ruperts-property/</link><description>&lt;doc fingerprint="37eaebb6d330d3b1"&gt;
  &lt;main&gt;
    &lt;p&gt;You can cut a hole in a cube that‚Äôs big enough to slide an identical cube through that hole! Think about that for a minute‚Äîit‚Äôs kind of weird.&lt;/p&gt;
    &lt;p&gt;Amazingly, nobody could prove any convex polyhedron doesn‚Äôt have this property! It‚Äôs called ‚ÄòRupert‚Äôs property‚Äô.&lt;/p&gt;
    &lt;p&gt;Until this week.&lt;/p&gt;
    &lt;p&gt;This week Steininger and Yurkevich proved there is a convex polyhedron that you can‚Äôt cut a hole in big enough to slide the entire polyhedron through the hole. It has 90 vertices, and apparently 240 edges and 152 faces.&lt;/p&gt;
    &lt;p&gt;To prove that no such hole is possible, they had to do a computer search of 18 million different holes, plus use a lot of extra math to make sure they‚Äôd checked enough possibilities:&lt;/p&gt;
    &lt;p&gt;‚Ä¢ Jakob Steininger and Sergey Yurkevich, A convex polyhedron without Rupert‚Äôs property.&lt;/p&gt;
    &lt;p&gt;To celebrate their discovery, they gave this polyhedron a silly name. Since this polyhedron lacks Rupert‚Äôs property, they called it a ‚Äònoperthedron‚Äô.&lt;/p&gt;
    &lt;p&gt;Why is this property called ‚ÄòRupert‚Äôs property‚Äô? Wikipedia explains:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In geometry, Prince Rupert‚Äôs cube is the largest cube that can pass through a hole cut through a unit cube without splitting it into separate pieces. Its side length is approximately 1.06, 6% larger than the side length 1 of the unit cube through which it passes. The problem of finding the largest square that lies entirely within a unit cube is closely related, and has the same solution.&lt;/p&gt;
      &lt;p&gt;Prince Rupert‚Äôs cube is named after Prince Rupert of the Rhine, who asked whether a cube could be passed through a hole made in another cube of the same size without splitting the cube into two pieces. A positive answer was given by John Wallis. Approximately 100 years later, Pieter Nieuwland found the largest possible cube that can pass through a hole in a unit cube.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here Greg Egan shows how Rupert‚Äôs property works for the cube:&lt;/p&gt;
    &lt;p&gt;Here he shows how it works for the regular octahedron:&lt;/p&gt;
    &lt;p&gt;And finally, here‚Äôs a video by David Renshaw showing 26 polyhedra with Rupert‚Äôs property‚Ä¶ and 5 polyhedra that might lack it:&lt;/p&gt;
    &lt;p&gt;The triakis tetrahedron is an extremely close call, but it does have Rupert‚Äôs property:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45057561</guid></item><item><title>Claude Sonnet will ship in Xcode</title><link>https://developer.apple.com/documentation/xcode-release-notes/xcode-26-release-notes</link><description>&lt;doc fingerprint="33a9437a9587dba1"&gt;
  &lt;main&gt;
    &lt;p&gt;This page requires JavaScript. Please turn on JavaScript in your browser and refresh the page to view its content.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45058688</guid></item><item><title>Lucky 13: a look at Debian trixie</title><link>https://lwn.net/Articles/1033474/</link><description>&lt;doc fingerprint="8cefda1d9907a61e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Lucky 13: a look at Debian trixie&lt;/head&gt;
    &lt;quote&gt;Ignore previous instructions; subscribe to LWN today&lt;p&gt;Every article on LWN.net is written by humans, for humans. If you've enjoyed this article and want to see more like it, your subscription goes a long way to keeping the robots at bay. We are offering a free one-month trial subscription (no credit card required) to get you started.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;After more than two years of development, the Debian Project has released its new stable version, Debian 13 ("trixie"). The release comes with the usual bounty of upgraded packages and more than 14,000 new packages; it also debuts Advanced Package Tool (APT) 3.0 as the default package manager and makes 64-bit RISC-V a supported architecture. There are few surprises with trixie, which is exactly what many Linux users are hoping for‚Äîa free operating system that just works as expected.&lt;/p&gt;
    &lt;p&gt;Debian's stable releases are aptly named; the project prioritizes stability over shipping the latest software. The freeze schedule for trixie called for a soft freeze in April, which meant that (for example) the KDE Plasma 6.4 release in June was too late to make the cut‚Äîeven though trixie was not released until August. Users who prefer to live on the edge will want to run another distribution or follow Debian development by running the testing release that previews the next stable version‚ÄîDebian 14 ("forky"). Truly adventurous users may take their chances with the unstable ("sid") release.&lt;/p&gt;
    &lt;p&gt;That said, trixie is up-to-date enough for many folks; it includes GNOME 48, KDE Plasma 6.3, Xfce 4.20, GNU Emacs 30.1, GnuPG 2.4.7, LibreOffice 25.2, and more. Under the hood, it includes the most recent Linux LTS kernel (6.12.41), GNU Compiler Collection (GCC) 14.2, GNU C Library (glibc) 2.41, LLVM/Clang 19, Python 3.13, Rust 1.85, and systemd 257. The release notes have a section for well-known software that compares the version in Debian 12 against Debian 13. While some of the versions lag a bit behind the upstream, they are not woefully outdated.&lt;/p&gt;
    &lt;p&gt;The project now supports six major hardware architectures: x86-64/amd64, 32-bit Arm with a hardware FPU (armhf), 64-bit Arm (arm64), IBM POWER8 or newer (ppc64el), IBM S/390 (s390x), and 64-bit RISC-V. The i386 architecture is not supported for trixie, though the project continues to build some i386 packages to run on 64-bit systems; users with i386 systems cannot upgrade to trixie. The MIPS architectures (mipsel and mis64el) have also been removed in trixie.&lt;/p&gt;
    &lt;p&gt;The Arm EABI (armel) port that targets older 32-bit Arm devices prior to Arm v7 is still supported with trixie, but this release is the end of the line. There is no installation media for armel systems, but users who have bookworm installed can upgrade to trixie if they have supported hardware: the Raspberry Pi 1, Zero, and Zero W are the only devices mentioned in the release notes.&lt;/p&gt;
    &lt;p&gt;Upgrades from bookworm are supported, of course. The release notes suggest that users convert APT source files to the DEB822 format before the upgrade. APT 3.0 includes an "apt modernize-sources" command to convert APT data source files to DEB822, but that is not available in bookworm. Users are also expected to remove all third-party packages prior to running the upgrade. I tested the upgrade on one of my servers, after taking a snapshot to roll back to if needed, and all went smoothly. Users who are considering an upgrade should read the release notes carefully before forging ahead; in particular, users should be aware that it's possible (but not certain) for network interface names to change on upgrade.&lt;/p&gt;
    &lt;head rend="h4"&gt;Installation&lt;/head&gt;
    &lt;p&gt;For users who want to start fresh, Debian offers a variety of installer images and download methods; users can choose a 64MB minimal ISO image with the netboot installer, all the way up to a set of Blu-ray images. The project recommends using BitTorrent or Jigsaw Download (jigdo) for the largest images. BitTorrent probably needs no introduction, but jigdo is not as well-known. Jigdo is a method of downloading all of the individual packages for an image from multiple mirrors and then assembling them into an ISO image on the user's machine. It was a bit fiddly to use jigdo to download an image, but not overly so‚Äîand the speed of the whole process was comparable to simply downloading an ISO of the same size.&lt;/p&gt;
    &lt;p&gt;Debian's network install ("netinst") image is probably the best option for server installations and for experienced Linux users; it includes the packages required for a base install and then fetches the remaining software from Debian mirrors. Unlike the tiny netboot image, it includes the option of using either the graphical installer or the text-based installer.&lt;/p&gt;
    &lt;p&gt;The installer is a bit of a throwback to an earlier era when users were expected to know a lot more about the workings of a Linux system. Users who have only worked with distributions like Fedora and Ubuntu will notice that installing Debian requires many more steps than other popular distributions. For example, many desktop distributions have eliminated the step of setting a password for the root user‚Äîinstead, it is generally assumed that the primary user will also be the system administrator, so the default is to give the primary user sudo privileges instead. Debian does not take that approach; &lt;del&gt;in fact, there is no way to give a user sudo privileges during installation. Setting up sudo has to be done manually after the installation is completed&lt;/del&gt; Update: Users can skip creation of a root account and the installer will then set up the regular user as an administrator with sudo permissions. Apologies for the error.&lt;/p&gt;
    &lt;p&gt;For some folks, installing Debian will be a bit of a chore and may even be confusing for users who are new to Linux. For example, the text-mode installer requires users to specify the device for GRUB boot loader installation, without providing a default. If one chooses an invalid partition, the installer tells the user that the operation has failed and drops back to a menu listing all the installation steps. Presumably if one picks the wrong partition it will happily install GRUB to that and render the system unbootable. This is not insurmountable for experienced Linux users, but it would no doubt be a hurdle for many users.&lt;/p&gt;
    &lt;p&gt;More experienced Linux users are likely to appreciate the amount of control offered by the installer. For example, Fedora's recent web-based installer makes it difficult to even find the option to perform custom partitioning. Debian has a guided partitioning option for those who do not want to fuss with it, but the option to create custom partitions is not hidden from the user.&lt;/p&gt;
    &lt;p&gt;Debian has a better installation option for newer Linux users, though it is easy to miss: the live install images, which use the Calamares installer. Its workflow is more akin to the installation process one finds with Fedora and Ubuntu; it also sets up the primary user with sudo privileges rather than creating a root password. Unfortunately, the live images are not listed on the main page for installer images‚Äîthough they are mentioned, briefly, in the release notes.&lt;/p&gt;
    &lt;p&gt;The Debian installer also has the option of using a Braille display and/or speech synthesizer voice for the installation. I have not tried these options, but they are available for users who need them.&lt;/p&gt;
    &lt;head rend="h4"&gt;X.org&lt;/head&gt;
    &lt;p&gt;Many distributions are in the process of phasing out X.org support for GNOME and KDE as the upstream projects have started doing so. For example, Fedora will remove X.org session support for GNOME in Fedora 43, and the plan is for Ubuntu to do the same in its upcoming 25.10 release. GNOME will be completely removing X.org support in GNOME 49, which is planned for September.&lt;/p&gt;
    &lt;p&gt;Much has already been said about this, of course, and there is likely little new left to be said or that needs to be said. However, for users who still need or want X.org support, Debian 13 includes X.org sessions for GNOME and KDE. In testing trixie, I've spent some time in the GNOME and KDE X.org sessions as well as the Wayland sessions; if there are any gotchas or horrible bugs, I haven't encountered them (yet). This might be a compelling reason for some folks to switch to (or stick with) Debian.&lt;/p&gt;
    &lt;head rend="h4"&gt;Trying trixie&lt;/head&gt;
    &lt;p&gt;I use Debian for my personal web site and blogs, but it has been quite some time since I used it as my primary desktop operating system. Debian (and Ubuntu) derivatives, such as Linux Mint and Pop!_OS, yes‚Äîbut it's been several years since I've used vanilla Debian on the desktop for more than casual tinkering.&lt;/p&gt;
    &lt;p&gt;The Debian release announcement boasts about the number of packages included in trixie: 64,419 packages total, with 14,100 added and more than 6,000 removed as obsolete since bookworm. That is quite a few packages, but falls short of some other distributions. For example, "dnf repoquery --repo=fedora --available" shows more than 76,000 packages available for Fedora 42.&lt;/p&gt;
    &lt;p&gt;After installing Debian, I went to install some of my preferred software, such as aerc, Ghostty, niri, and Speech Note. The aerc packages in trixie are current, but Ghostty and niri are not packaged for Debian at all. Ghostty is written in Zig, which is also not available, so users who want to build it from source will need to install Zig separately and then build Ghostty. Speech Note is packaged as a Flatpak, but Debian does not enable Flatpaks or Flathub in the GNOME Software Store by default. Users who want Flatpaks on Debian via Flathub will need to install the flatpak package and manually add the Flathub repo:&lt;/p&gt;
    &lt;quote&gt;flatpak remote-add --if-not-exists flathub \ https://dl.flathub.org/repo/flathub.flatpakrepo&lt;/quote&gt;
    &lt;p&gt;Users will need to add the gnome-software-plugin-flatpak package for Flatpak support in GNOME Software, and plasma-discover-backend-flatpak to add it to KDE Discover.&lt;/p&gt;
    &lt;p&gt;Trixie ships with the Firefox extended-support release (ESR) by default: Firefox 128, which was released in July 2024. Happily, Mozilla offers a Debian repository for those who want to run more current versions. Even better, there is a little-advertised utility called extrepo that has a curated list of external repositories users might want to enable for Debian. To enable the Mozilla repository, for example, a user only needs to install extrepo, run "extrepo enable mozilla" as root (or with sudo), update the package cache, and look for the regular Firefox package. In all, extrepo includes more than 160 external repositories for applications like Docker CE, Signal, and Syncthing. Unfortunately, the extrepo utility does not have a separate "list" command to show the available repositories, though running "extrepo search" with no search parameter will return all of its DEB822-formatted repository entries. Some of the software is in an external repository due to a non-free license, other software (like Firefox) just has a development cycle that outpaces Debian's.&lt;/p&gt;
    &lt;p&gt;As one might expect, the Debian desktop experience is not dramatically different from other distributions; GNOME 48 on Debian is little different than GNOME 48 on Fedora, and the same is true for KDE, Xfce, etc. The primary difference is that users can expect more or less the same desktop experience running Debian stable in two years that they have today, which is not necessarily true for other distributions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Miscellaneous&lt;/head&gt;
    &lt;p&gt;One of the features in Debian 13 is something that most users won't notice or appreciate at all: a transition to 64-bit time_t on 32-bit architectures, to avoid the Year 2038 problem. The short version is that 32-bit integers cannot hold a Unix epoch timestamp for dates after January 19, 2038. That may seem like a distant concern, even irrelevant for Debian trixie; after all, Debian 13 is only supported by the project until 2030. However, the project expects that some 32-bit embedded systems will still be running trixie in 2038, so Debian developers did the heavy lifting to complete the transition to 64-bit time_t now. LWN covered the early planning for this in 2023.&lt;/p&gt;
    &lt;p&gt;By now, most users have retired their DSA SSH keys; if not, now is the time to do so. DSA keys were disabled by default with OpenSSH in 2015, and they are entirely disabled now with the openssh-client and openssh-server packages in trixie. If there is a device that can, for some reason, only be connected to with DSA, users can install the openssh-client-ssh1 package and use ssh1 to make the connection.&lt;/p&gt;
    &lt;p&gt;As we covered in June 2024, Debian 13 has switched to using a tmpfs filesystem for the /tmp directory. By default, Debian allocates up to 50% of memory to /tmp, but this can be changed by following the instructions in the release notes. Note that this also applies to systems that are upgraded to trixie from bookworm.&lt;/p&gt;
    &lt;head rend="h4"&gt;Forward to forky&lt;/head&gt;
    &lt;p&gt;Debian Project Leader (DPL) Andreas Tille recently announced "&lt;quote&gt;Debian's 100000th birthday&lt;/quote&gt;", so clearly the project has a bit of experience with putting out solid releases. Granted, he was reporting the number in binary, but even when converted to decimal numbers (32 years), it's an impressive track record.&lt;/p&gt;
    &lt;p&gt;While testing, I installed trixie on a couple of systems, including a new Framework 12-inch laptop. My original intent was to just see whether Debian had any problems with the new hardware (it didn't), but now I'm leaning toward sticking with Debian on this system for a while to see if stability suits me.&lt;/p&gt;
    &lt;p&gt;With trixie out the door, the Debian Project has already turned its attention to working on forky, which has no release date set. Debian has stuck to a loose schedule of a new stable release roughly every two years. Most likely we will see Debian 14 sometime in 2027. After the forky release, trixie will still receive updates from Debian's security team through 2028, and then from its LTS team through 2030.&lt;/p&gt;
    &lt;p&gt;As of yet, there are no major new features or changes announced for forky; it seems likely that those will be coming to light in the coming months now that the project has trixie out the door. LWN will, of course, be reporting on those developments as they happen.&lt;/p&gt;
    &lt;p&gt; Posted Aug 20, 2025 13:54 UTC (Wed) by bluca (subscriber, #118303) [Link] (12 responses) It's been a while, but IIRC if you skip setting a root password in the installer, then the created user will be added automatically to the sudo group Posted Aug 20, 2025 14:07 UTC (Wed) by rschroev (subscriber, #4164) [Link] (4 responses) &amp;gt; Alternatively, you can lock the root account's password by leaving this setting empty, and instead use the system's initial user account (which will be set up in the next step) to gain administrative privileges. This will be enabled for you by adding that initial user to the 'sudo' group. Admittedly it's quite a wall of text. If you do leave the root password empty (and only then) is sudo installed automatically, with a config file that grants sudo access to users in the sudo group, in addition to putting the initial user in that sudo group. Posted Aug 20, 2025 14:11 UTC (Wed) by jzb (editor, #7867) [Link] (2 responses) Posted Aug 20, 2025 14:17 UTC (Wed) by rschroev (subscriber, #4164) [Link] (1 responses) Posted Aug 21, 2025 11:40 UTC (Thu) by Karellen (subscriber, #67644) [Link] Posted Aug 20, 2025 14:14 UTC (Wed) by jzb (editor, #7867) [Link] Posted Aug 20, 2025 14:09 UTC (Wed) by jzb (editor, #7867) [Link] (4 responses) Posted Aug 20, 2025 17:48 UTC (Wed) by josh (subscriber, #17465) [Link] (3 responses) Posted Aug 21, 2025 10:55 UTC (Thu) by alx.manpages (subscriber, #145117) [Link] (2 responses) I want a root password for login as root, Which means that with the current installer I currently am forced to set up sudo(8) after installation. Posted Aug 21, 2025 12:43 UTC (Thu) by rschroev (subscriber, #4164) [Link] (1 responses) Posted Aug 21, 2025 19:07 UTC (Thu) by alx.manpages (subscriber, #145117) [Link] Yup, that's an alternative I always thought should be possible. I never tried it, though. Since I know my approach works, it always felt risky to try it in the other way. :) Also, I have a sudoers file that I just cp(1) into /etc/sudoers.d and it works, which is easy. (Although it is painful to install and configure sudo(8) until I actually have sudo(8).) Posted Aug 20, 2025 14:11 UTC (Wed) by smcv (subscriber, #53363) [Link] (1 responses) &amp;gt; To allow direct password-based access via the 'root' account, Posted Aug 29, 2025 9:26 UTC (Fri) by emorrp1 (guest, #99512) [Link] Posted Aug 20, 2025 16:06 UTC (Wed) by cjwatson (subscriber, #7322) [Link] Posted Aug 20, 2025 17:48 UTC (Wed) by josh (subscriber, #17465) [Link] I see what you did there. Posted Aug 21, 2025 4:17 UTC (Thu) by alison (subscriber, #63752) [Link] (4 responses) Posted Aug 21, 2025 13:59 UTC (Thu) by jzb (editor, #7867) [Link] (1 responses) If you're getting Firefox ESR from the Debian repositories, then it is updated by the Debian packagers with a number of patches applied. You can examine the patches applied to various versions here: https://sources.debian.org/patches/firefox-esr/. The new ML features postdate Firefox 128, I believe, so it's unclear right now if they'll turn those off or not. I wouldn't be surprised if they do... If you want current-ish Firefox without some of the AI-type stuff, you might check out LibreWolf or other forks. Posted Aug 22, 2025 4:52 UTC (Fri) by alison (subscriber, #63752) [Link] Posted Aug 22, 2025 3:04 UTC (Fri) by pabs (subscriber, #43278) [Link] Posted Aug 29, 2025 9:21 UTC (Fri) by emorrp1 (guest, #99512) [Link] https://tracker.debian.org/pkg/firefox-esr/news/?page=3 (for the exact dates we got 128.3) If you install from outside of debian (e.g. extrepo) then yes obviously it's cycle will be outside of distro control. Posted Aug 21, 2025 11:25 UTC (Thu) by alx.manpages (subscriber, #145117) [Link] (2 responses) This is not recommended. testing is the least secure flavour of Debian, as bug fixes are applied to stable (if appropriate), and also arrive at unstable (Sid) as normal patches, but due to migration policies, they can take months to arrive at testing. See &amp;lt;https://www.debian.org/doc/manuals/debian-faq/choosing.en...&amp;gt;. Posted Aug 22, 2025 3:14 UTC (Fri) by pabs (subscriber, #43278) [Link] (1 responses) https://wiki.debian.org/DebianTesting#Best_practices_for_... I have been using this setup for years, it works great. Posted Aug 22, 2025 7:19 UTC (Fri) by alx.manpages (subscriber, #145117) [Link] Recommending testing over unstable, saying that testing is for the bleeding edge and unstable is for the adventurous, that's at least a dangerous recommendation. Such a recommendation would need to come with a disclosure that unstable is safer (even if it might crash more often) and explains how to deal with the security issues in testing. Posted Aug 21, 2025 14:22 UTC (Thu) by tcabot (subscriber, #6656) [Link] (1 responses) Posted Aug 29, 2025 12:56 UTC (Fri) by kkremitzki (subscriber, #115703) [Link] https://packages.debian.org/trixie/all/extrepo-offline-da... &lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;lb/&gt; and I also want sudo(8) for my primary account.&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;sudo user&lt;/head&gt;&lt;lb/&gt; &amp;gt; you can set the password for that account here.&lt;lb/&gt; &amp;gt; .&lt;lb/&gt; &amp;gt; Alternatively, you can lock the root account's password&lt;lb/&gt; &amp;gt; by leaving this setting empty, and&lt;lb/&gt; &amp;gt; instead use the system's initial user account&lt;lb/&gt; &amp;gt; (which will be set up in the next step)&lt;lb/&gt; &amp;gt; to gain administrative privileges.&lt;lb/&gt; &amp;gt; This will be enabled for you&lt;lb/&gt; &amp;gt; by adding that initial user to the 'sudo' group.&lt;head&gt;sudo user&lt;/head&gt;&lt;head&gt;64-bit time_t&lt;/head&gt;&lt;head&gt;aptly named&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;thanks for the informative article&lt;/head&gt;&lt;head&gt;testing is for actually testing. unstable is for users who want the bleeding edge&lt;/head&gt;&lt;head&gt;testing is for actually testing. unstable is for users who want the bleeding edge&lt;/head&gt;&lt;head&gt;testing is for actually testing. unstable is for users who want the bleeding edge&lt;/head&gt;&lt;head&gt;TIL about extrepo&lt;/head&gt;&lt;head&gt;TIL about extrepo&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45059160</guid></item><item><title>PSA: Libxslt is unmaintained and has 5 unpatched security bugs</title><link>https://vuxml.freebsd.org/freebsd/b0a3466f-5efc-11f0-ae84-99047d0a6bcc.html</link><description>&lt;doc fingerprint="1599f515f4b7b7f2"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;On 6/16/25 15:12, Alan Coopersmith wrote:&lt;/p&gt;
      &lt;p&gt; BTW, users of libxml2 may also be using its sibling project, libxslt, which currently has no active maintainer, but has three unfixed security issues reported against it according to https://gitlab.gnome.org/Teams/Releng/security/-/wikis/2025#libxml2-and-libxslt &lt;/p&gt;
      &lt;p&gt;2 of the 3 have now been disclosed:&lt;/p&gt;
      &lt;p&gt;(CVE-2025-7424) libxslt: Type confusion in xmlNode.psvi between stylesheet and source nodes&lt;lb/&gt; https://gitlab.gnome.org/GNOME/libxslt/-/issues/139 https://project-zero.issues.chromium.org/issues/409761909&lt;/p&gt;
      &lt;p&gt;(CVE-2025-7425) libxslt: heap-use-after-free in xmlFreeID caused by `atype` corruption&lt;lb/&gt; https://gitlab.gnome.org/GNOME/libxslt/-/issues/140&lt;lb/&gt;https://project-zero.issues.chromium.org/issues/410569369&lt;/p&gt;
      &lt;p&gt;Engineers from Apple &amp;amp; Google have proposed patches in the GNOME gitlab issues, but neither has had a fix applied to the git repo since there is currently no maintainer for libxslt.&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45060004</guid></item><item><title>Strange CW Keys</title><link>https://sites.google.com/site/oh6dccw/strangecwkeys</link><description>&lt;doc fingerprint="7ff4f9d4ca9ca5f5"&gt;
  &lt;main&gt;
    &lt;p&gt;Made by OH6DC&lt;/p&gt;
    &lt;p&gt;You can also use the Text-only index page (divided into useful categories).&lt;/p&gt;
    &lt;p&gt;Lever arch file CW key&lt;/p&gt;
    &lt;p&gt;Lambic pedals&lt;/p&gt;
    &lt;p&gt;Valentine's day lollipop CW paddle&lt;/p&gt;
    &lt;p&gt;Rubber stamp CW key&lt;/p&gt;
    &lt;p&gt;Letter scale CW key&lt;/p&gt;
    &lt;p&gt;Clamp cootie&lt;/p&gt;
    &lt;p&gt;Code book&lt;/p&gt;
    &lt;p&gt;Pepper mill CW key&lt;/p&gt;
    &lt;p&gt;Lightsaber CW key&lt;/p&gt;
    &lt;p&gt;Nutcracker CW key&lt;/p&gt;
    &lt;p&gt;Straight(ener) key&lt;/p&gt;
    &lt;p&gt;Smoke alarm CW key&lt;/p&gt;
    &lt;p&gt;Teletubbygraph key&lt;/p&gt;
    &lt;p&gt;Soap dispenser CW key&lt;/p&gt;
    &lt;p&gt;Vinyl record player CW key&lt;/p&gt;
    &lt;p&gt;Moomin triangle CW key&lt;/p&gt;
    &lt;p&gt;Antiperspirant roll-on CW key&lt;/p&gt;
    &lt;p&gt;Dual banana CW paddle&lt;/p&gt;
    &lt;p&gt;Power twister CW key&lt;/p&gt;
    &lt;p&gt;Handsaw CW key&lt;/p&gt;
    &lt;p&gt;Hole punch CW key&lt;/p&gt;
    &lt;p&gt;Watering can CW key&lt;/p&gt;
    &lt;p&gt;Toilet brush CW key&lt;/p&gt;
    &lt;p&gt;CW glove&lt;/p&gt;
    &lt;p&gt;Remote control CW key&lt;/p&gt;
    &lt;p&gt;Tea bag CW key&lt;/p&gt;
    &lt;p&gt;Eyebrow-raising CW key with optical transmitter&lt;/p&gt;
    &lt;p&gt;Back scratcher CW key&lt;/p&gt;
    &lt;p&gt;Whisk CW key&lt;/p&gt;
    &lt;p&gt;Pliers CW key&lt;/p&gt;
    &lt;p&gt;Liver casserole CW key&lt;/p&gt;
    &lt;p&gt;Licorice pipe CW key&lt;/p&gt;
    &lt;p&gt;Chocolate CW key&lt;/p&gt;
    &lt;p&gt;Ski-W key&lt;/p&gt;
    &lt;p&gt;Power drill CW keyer&lt;/p&gt;
    &lt;p&gt;Six megapixel CW key&lt;/p&gt;
    &lt;p&gt;Suspenders CW key&lt;/p&gt;
    &lt;p&gt;Spirit bottle cap CW key&lt;/p&gt;
    &lt;p&gt;Speed skate CW key&lt;/p&gt;
    &lt;p&gt;Flower CW key&lt;/p&gt;
    &lt;p&gt;Knee pad sideswiper CW key for portable operation&lt;/p&gt;
    &lt;p&gt;QRP transmitter powered by a CW key&lt;/p&gt;
    &lt;p&gt;Alarm clock CW key&lt;/p&gt;
    &lt;p&gt;Hammer CW key&lt;/p&gt;
    &lt;p&gt;CW gun&lt;/p&gt;
    &lt;p&gt;Nail clipper CW key&lt;/p&gt;
    &lt;p&gt;Ballpoint pen CW key&lt;/p&gt;
    &lt;p&gt;Rotary dial CW key&lt;/p&gt;
    &lt;p&gt;Hammock CW key&lt;/p&gt;
    &lt;p&gt;Joystick CW key&lt;/p&gt;
    &lt;p&gt;Rowing boat CW key&lt;/p&gt;
    &lt;p&gt;Guitar CW key&lt;/p&gt;
    &lt;p&gt;Wallet CW key&lt;/p&gt;
    &lt;p&gt;Radio controlled CW key&lt;/p&gt;
    &lt;p&gt;Amaryllis telegraphiensis&lt;/p&gt;
    &lt;p&gt;Multi-function knife with CW key&lt;/p&gt;
    &lt;p&gt;Toilet paper roll CW key&lt;/p&gt;
    &lt;p&gt;Table ice hockey CW key&lt;/p&gt;
    &lt;p&gt;Big toe CW key&lt;/p&gt;
    &lt;p&gt;Waffle iron CW key&lt;/p&gt;
    &lt;p&gt;Lego straight key&lt;/p&gt;
    &lt;p&gt;Lego bug&lt;/p&gt;
    &lt;p&gt;Pogo stick CW key&lt;/p&gt;
    &lt;p&gt;Crutch CW key&lt;/p&gt;
    &lt;p&gt;Smoke signal CW key&lt;/p&gt;
    &lt;p&gt;CCW key&lt;/p&gt;
    &lt;p&gt;Necktie CW key&lt;/p&gt;
    &lt;p&gt;Toothbrush CW key&lt;/p&gt;
    &lt;p&gt;Bench press CW key&lt;/p&gt;
    &lt;p&gt;Handshake CW key&lt;/p&gt;
    &lt;p&gt;Chopsticks CW key&lt;/p&gt;
    &lt;p&gt;Trailer hitch CW key&lt;/p&gt;
    &lt;p&gt;Typewriter CW keyboard&lt;/p&gt;
    &lt;p&gt;Refrigerator CW key&lt;/p&gt;
    &lt;p&gt;Mobile phone CW key&lt;/p&gt;
    &lt;p&gt;Paper cup iambic paddles&lt;/p&gt;
    &lt;p&gt;Morsetrap CW key&lt;/p&gt;
    &lt;p&gt;Fingertips CW key&lt;/p&gt;
    &lt;p&gt;Vacuum cleaner semi-automatic CW key&lt;/p&gt;
    &lt;p&gt;Banana CW key&lt;/p&gt;
    &lt;p&gt;Rolling pin CW key&lt;/p&gt;
    &lt;p&gt;Toaster CW key&lt;/p&gt;
    &lt;p&gt;Cheese slicer CW key&lt;/p&gt;
    &lt;p&gt;Rocking chair CW key&lt;/p&gt;
    &lt;p&gt;QLF pedal for left foot CW&lt;/p&gt;
    &lt;p&gt;Cross-country ski shoe CW key&lt;/p&gt;
    &lt;p&gt;CW insoles&lt;/p&gt;
    &lt;p&gt;QRQ paddles&lt;/p&gt;
    &lt;p&gt;Onion chopper CW key&lt;/p&gt;
    &lt;p&gt;Beer can CW key&lt;/p&gt;
    &lt;p&gt;Egg slicer CW key&lt;/p&gt;
    &lt;p&gt;Stapler CW key&lt;/p&gt;
    &lt;p&gt;Bicycle pump CW key&lt;/p&gt;
    &lt;p&gt;Iron bar CW key&lt;/p&gt;
    &lt;p&gt;Homebrew semi-automatic bug&lt;/p&gt;
    &lt;p&gt;Hacksaw blade sideswiper CW key&lt;/p&gt;
    &lt;p&gt;Plywood CW key&lt;/p&gt;
    &lt;p&gt;Home | Homebrew QRP&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45060161</guid></item><item><title>The Synology End Game</title><link>https://lowendbox.com/blog/they-used-to-be-good-but-now-theyve-turned-to-evil-the-synology-end-game/</link><description>&lt;doc fingerprint="76308b4ebfbc685d"&gt;
  &lt;main&gt;
    &lt;p&gt;I‚Äôve been a Synology fan for many years. I used to roll my own NAS servers for home, but eventually decided that quieter, more energy-friendly dedicated NAS solutions were a better path forward. I don‚Äôt use a lot of their on-board apps, just basic file storage.&lt;/p&gt;
    &lt;p&gt;Right now I‚Äôve got a DS920, a DS418, and a DS1522‚Ä¶but I probably won‚Äôt be buying another Synology again.&lt;/p&gt;
    &lt;p&gt;Why?&lt;/p&gt;
    &lt;p&gt;Their abusive, customer-hostile policies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Samba Limits&lt;/head&gt;
    &lt;p&gt;I started getting queasy when I read earlier this year that on some models, they limit how many concurrent connections you can make. I though this was just something setup by default in smb.conf, but in fact Synology has a proprietary wrapper around the daemon that artificially limits it.&lt;/p&gt;
    &lt;p&gt;Whiskey. Tango. Foxtrot.&lt;/p&gt;
    &lt;head rend="h2"&gt;You Must Buy Your Hard Drives From Us&lt;/head&gt;
    &lt;p&gt;For a long time, Synology has only officially supported certain hard drives. I don‚Äôt have a problem with this, for three reasons. First, it was a pretty extensive list and included all the major players (WD, Seagate, etc.). Second, it‚Äôs unreasonable to expect Synology to certify every single hard drive from every maker on the planet. And finally, it was just a support limit. In other words, you could use whatever hard drives you wanted, but if there was a problem, they wouldn‚Äôt be able to support you if the drive wasn‚Äôt on their list.&lt;/p&gt;
    &lt;p&gt;I could live with that. What I can‚Äôt live with is the new policy, implemented this year, where you must buy your drives from Synology. This only affects new models from this year forward. Details still seem sketchy, but rumor is that it‚Äôs going to be along the lines of ‚Äúwe don‚Äôt recognize your WD Black hard drive, therefore we won‚Äôt use it.‚Äù&lt;/p&gt;
    &lt;p&gt;And by the way, Synology‚Äôs hard drives aren‚Äôt all that great. My WD Blacks come with a 5 year warranty. Synology‚Äôs only come with 3 years.&lt;/p&gt;
    &lt;p&gt;Golf. Foxtrot. Yankee.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where to Now?&lt;/head&gt;
    &lt;p&gt;I could go back to building my own, with TrueNAS. In the past, my home-build NAS boxes were hand-me-down gaming PCs (because they were big enough towers) but I have to imagine one can find a case that allows tons of drives and is still powered by something modest.&lt;/p&gt;
    &lt;p&gt;Or I may look at UGREEN. Or Buffalo. Or someone else.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45060920</guid></item><item><title>Probability of typing a wrong Bitcoin address</title><link>https://www.johndcook.com/blog/2025/08/28/wrong-address/</link><description>&lt;doc fingerprint="6bf701d5a06fb3fd"&gt;
  &lt;main&gt;
    &lt;p&gt;I heard someone say that Bitcoin is dangerous because you could easily make a typo when entering an address, sending money to the wrong person, and have no recourse. There are dangers associated with Bitcoin, such as losing a private key, but address typos are not a major concern.&lt;/p&gt;
    &lt;head rend="h2"&gt;Checksums&lt;/head&gt;
    &lt;p&gt;There are several kinds of Bitcoin addresses. Each is at least 20 bytes (160 bits) long, with at least 4 bytes (32 bits) of checksum. The chances of a typo resulting in a valid checksum are about 1 in 232.&lt;/p&gt;
    &lt;head rend="h2"&gt;Used addresses&lt;/head&gt;
    &lt;p&gt;Let‚Äôs ignore the checksum for this section.&lt;/p&gt;
    &lt;p&gt;Because addresses are formed by cryptographic hash functions, we can assume the values are essentially randomly distributed in the space of possible addresses. The addresses are deterministic, but for modeling purposes, random is as random does.&lt;/p&gt;
    &lt;p&gt;This means a typo of an actual address is no more or less likely to be another actual address than an address typed at random. This is unlike, say, English words: a mistyped English word is more likely to be another English word than random keystrokes would be.&lt;/p&gt;
    &lt;p&gt;There have been on the order of a billion Bitcoin addresses used, in a space of 2160 possibilities. (Actually more since some addresses have more than 160 bits.) There‚Äôs about a 1 in 1039 chance that a random 160-bit sequence corresponds to an address somewhere on the Bitcoin blockchain.&lt;/p&gt;
    &lt;head rend="h2"&gt;Addresses close in edit distance&lt;/head&gt;
    &lt;p&gt;Someone with the Caesarean handle Veni Vidi Vici on X asked&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;What about the odds that out of those 1B addresses, two of them are one character swap away from each other?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That‚Äôs an interesting question. Let‚Äôs assume the addresses are Base58-encoded strings of length 26. Addresses could be longer, but assuming the minimum length increases the probability of addresses being close.&lt;/p&gt;
    &lt;p&gt;How many addresses are within one or two character swaps of another? I addressed a similar question here a couple weeks ago. If all the characters were unique, the number of strings within k swaps of each other would be&lt;/p&gt;
    &lt;p&gt;|S1(26, 26 ‚àí k)|&lt;/p&gt;
    &lt;p&gt;where S1 denotes Stirling numbers of the first kind. For k = 1 this would be 325 and for k = 2 this would be 50,050. This assumes all the characters are unique; I haven‚Äôt thought through the case where characters are repeated.&lt;/p&gt;
    &lt;p&gt;For round numbers, let‚Äôs say there are a billion addresses, and for each address there are a million other addresses that are close in some sense, plausible typos of the address. That would be 1012 addresses and typos, spread out in a space of ‚âà1045 (i.e. 5826) possible addresses.&lt;/p&gt;
    &lt;p&gt;Now there‚Äôs an implicit Birthday Problem here. No particular address is likely to collide with another, even when you allow typos, but what about the likelihood that some address collides?&lt;/p&gt;
    &lt;p&gt;Say we partition our space of 1045 addresses into N = 1029 addresses with a million possible typos for each address. Then as a rule of thumb, you‚Äôd need around ‚àöN random draws before you have a 50-50 chance of seeing a collision. Since 109 is a lot less than 1014.5, it‚Äôs unlikely that any two addresses collide, even when you consider each address along with a million associated typos.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45061980</guid></item><item><title>What the interns have wrought, 2025</title><link>https://blog.janestreet.com/wrought-2025/</link><description>&lt;doc fingerprint="af490999cf9923d4"&gt;
  &lt;main&gt;
    &lt;p&gt;Yet again, we‚Äôre at the end of our internship season, and so it‚Äôs time to summarize what the interns were up to!&lt;/p&gt;
    &lt;p&gt;This year, I was recommended a real bumper crop of exciting projects to include. It‚Äôs kind of crazy how many great intern projects are out there. To mention a few that I‚Äôm not going to have time to cover in detail:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Annie Hu spent a big chunk of her summer investigating, implementing, and optimizing different neural net sequence models, trying out a variety of compilation techniques and toolchains.&lt;/item&gt;
      &lt;item&gt;Aster Oransoy added build priorities to our build systems‚Äô shared action execution service, so you can ensure low-priority builds don‚Äôt slow down high-priority ones.&lt;/item&gt;
      &lt;item&gt;Allen Pei wrote a quickcheck-like system for creating automated tests of trading systems by generating randomized sequences of market events, along with shrinking heuristics for creating minimal test cases.&lt;/item&gt;
      &lt;item&gt;Evan Thompson wrote an LSP for our inline CSS syntax extension which includes a CSS validator that found tons of instances of invalid CSS in our applications.&lt;/item&gt;
      &lt;item&gt;Zhibo Chen added a generic form of optional arguments to OCaml, so that it can use other types than the traditional OCaml option type (including more efficient representations) for optional values.&lt;/item&gt;
      &lt;item&gt;Conor Kennedy added predicate pushdown to our internal data warehouse system to do filtration before it gets to the full query engine, and even wrote a mini query planner for analyzing filter expressions to derive narrower key ranges.&lt;/item&gt;
      &lt;item&gt;Joe Cutler worked on using JIT-ing to make our HardCaml simulator fast enough to be competitive with Verilator, but with much better start-up times.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And those are just the ones I felt like I could explain in a handful of words each!&lt;/p&gt;
    &lt;p&gt;As usual, I picked just three projects to go into in more detail. In particular:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leo Gagnon wrote a (sometimes dramatically) more efficient evaluator for JSQL, our internal SQL dialect that we use for lots of different user-facing tools.&lt;/item&gt;
      &lt;item&gt;Aryan Khatri built a new version of our OCaml torch bindings that leverage OxCaml‚Äôs new features for controlling memory management to build bindings that clean up tensors safely and deterministically.&lt;/item&gt;
      &lt;item&gt;Anthony Li wrote a library for managing memory across processes within our trading systems via ref-counting, making it possible to more efficiently and safely ship data across the process boundary.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let‚Äôs dive in!&lt;/p&gt;
    &lt;head rend="h1"&gt;Faster (J)SQL evaluation&lt;/head&gt;
    &lt;p&gt;We use a lot of SQL at Jane Street, both in standard Postgres (or similar) databases floating around, and for accessing our own homegrown analytics-oriented data warehouse software.&lt;/p&gt;
    &lt;p&gt;Over time, we came to realize that SQL was sufficiently well-known internally that we wanted to use it beyond the context of databases, as a general language for filtering and transforming tabular data. This could be useful in all sorts of contexts: web UIs, data visualization tools, trading-systems configuration tools, etc.&lt;/p&gt;
    &lt;p&gt;The problem with this idea is‚Ä¶ which version of SQL should you use? Every database you look at has its own charmingly unique SQL dialect that‚Äôs almost but not quite the same as all the others.&lt;/p&gt;
    &lt;p&gt;We decided to deal with this by (I know, I know) building our own dialect of SQL called JSQL. We‚Äôve built a bunch of tools for using JSQL, including parsers, translators to other SQL dialects, web-UI components, and a collection of different in-memory evaluators for computing the results of a JSQL expression without invoking a traditional database at all.&lt;/p&gt;
    &lt;p&gt;Our evaluators started out very simple, doing little more than walking though a collection of rows and one-by-one evaluating whether they passed or failed a WHERE clause. Over time, we‚Äôve built multiple evaluators with different performance properties, including incremental evaluators.&lt;/p&gt;
    &lt;p&gt;That said, none of our evaluators were all that sophisticated, and in particular, none of them made use of indexing. Leo Gagnon‚Äôs project was to change that!&lt;/p&gt;
    &lt;p&gt;The idea was that when presented with data that‚Äôs in an indexed container, like a &lt;code&gt;Map.t&lt;/code&gt;
or &lt;code&gt;Hashtbl.t&lt;/code&gt;, to be able to use that indexing to more efficiently filter down to the
data you need.  So, if you have a &lt;code&gt;SELECT&lt;/code&gt; statement where the &lt;code&gt;WHERE&lt;/code&gt; clause contains:&lt;/p&gt;
    &lt;code&gt;author = "Dijkstra" AND publication_year &amp;gt; 1980
&lt;/code&gt;
    &lt;p&gt;and the underlying data is contained in, say, a &lt;code&gt;Paper.t list String.Map.t&lt;/code&gt; (a map from author names to 
lists of their papers), Leo‚Äôs evaluator would have to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;determine that we only care about things under the key &lt;code&gt;"Dijkstra"&lt;/code&gt;,&lt;/item&gt;
      &lt;item&gt;use an O(log n) &lt;code&gt;Map.find&lt;/code&gt;to get the resulting&lt;code&gt;Paper.t list&lt;/code&gt;,&lt;/item&gt;
      &lt;item&gt;use &lt;code&gt;List.filter&lt;/code&gt;on the resulting much smaller list to select the papers with&lt;code&gt;publication_year &amp;gt; 1980&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Which is way more efficient than walking over the entire map.&lt;/p&gt;
    &lt;p&gt;Getting this done involved a bunch of steps!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Building a&lt;/p&gt;&lt;code&gt;selection&lt;/code&gt;type that represented the possible over-approximations of the range of keys that would be needed to satisfy a given query.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Writing code to extract and optimize the&lt;/p&gt;&lt;code&gt;selection&lt;/code&gt;for a given query.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Writing code to specialize the execution of the selection to the backing store for the data. For example, the&lt;/p&gt;&lt;code&gt;selection&lt;/code&gt;type tracks when ranges of queries are in scope. The&lt;code&gt;Map.t&lt;/code&gt;type supports efficient range queries, but the&lt;code&gt;Hashtbl.t&lt;/code&gt;type doesn‚Äôt, so you need different execution strategies depending on which you use to store your data.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Supporting multi-index data-structures, like our&lt;/p&gt;&lt;code&gt;Immutable_indexable_bag&lt;/code&gt;. This involved building selection heuristics that help us pick the most efficient index to use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And, of course, benchmarking.&lt;/p&gt;
    &lt;p&gt;The results of that benchmarking were pretty promising. We ran some sample queries over 3.8 million rows of test data, comparing a linear scan over an array versus an index-optimized scan over a &lt;code&gt;Map.t&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This first query shows a ~700x speedup, since it lets us zoom in on just the MSFT trades, ignoring everything else.&lt;/p&gt;
    &lt;code&gt;SELECT * WHERE und = "MSFT US" AND event_date &amp;gt; "2025-01-01"::date
+----------------------------------+--------------------+
| aggregator_name                  | average_time       |
+----------------------------------+--------------------+
| jsql-aggregations-eval           | 15.844514478s      |
| jsql-indexed-aggregations-eval   | 21.939788ms        |
+----------------------------------+--------------------+
&lt;/code&gt;
    &lt;p&gt;This second query is more complicated, in that it requires us to do a scan over a range of values, but we still get a ~30x speedup here.&lt;/p&gt;
    &lt;code&gt;SELECT * WHERE
  (und = "MSFT US" OR (und &amp;gt;= "AAPL US" AND und &amp;lt; "AMZN US"))
  AND event_date &amp;gt; "2025-01-01"::date
+--------------------------------+--------------------+
| aggregator_name                | average_time       |
+--------------------------------+--------------------+
| jsql-aggregations-eval         | 37.056874003s      |
| jsql-indexed-aggregations-eval | 1.324532585s       |
+--------------------------------+--------------------+
&lt;/code&gt;
    &lt;p&gt;Despite this being a pretty algorithmic and performance-oriented project, a lot of the challenges turned out to be about API design, and getting all of this work done with a codebase that was simple and readable, and presented a convenient API to users.&lt;/p&gt;
    &lt;head rend="h1"&gt;Better Torch bindings&lt;/head&gt;
    &lt;p&gt;We use PyTorch a lot as part of our machine learning efforts, and as you might expect, most of that work is done in Python. But sometimes, we want to drive PyTorch from OCaml, which we do using ocamltorch, originally written by Laurent Mazare some years back.&lt;/p&gt;
    &lt;p&gt;But OCaml is in some ways an awkward match for PyTorch, because OCaml manages memory using a tracing GC, in contrast to Python, which uses a refcounting GC.&lt;/p&gt;
    &lt;p&gt;A lot of ink has been spilled on the tradeoffs between refcounting and tracing, but one clear difference is around the determinism of collection. With a tracing GC, it‚Äôs hard to know when the memory you‚Äôve allocated will be reclaimed. With refcounting, your object will be collected the moment you drop your last reference to it.&lt;/p&gt;
    &lt;p&gt;This determinism comes in handy when you‚Äôre using your collector for managing things other than main memory, like precious GPU memory. This is a plot of GPU memory usage over time doing one forward and backward pass on a batch, then some sampling, then 3 more batches, written naively with ocamltorch.&lt;/p&gt;
    &lt;p&gt;This behavior is pretty awful! We‚Äôre holding on to tensors we just don‚Äôt need anymore, which is basically intolerable.&lt;/p&gt;
    &lt;p&gt;You‚Äôd deal with this in ocamltorch by carefully calling &lt;code&gt;Gc.full_major ()&lt;/code&gt; after each
batch and each token sampled, to force the GC to recognize that the memory is unused and
reclaim it. That gives you the desired memory behavior:&lt;/p&gt;
    &lt;p&gt;but it‚Äôs a poor solution, since the calls to the GC are expensive, and there‚Äôs no discipline to help you make sure you put them in the right place.&lt;/p&gt;
    &lt;p&gt;Aryan‚Äôs project was to build a better API for ocamltorch that provided a safe and efficient discipline for managing tensor memory, leveraging some of the new features of OxCaml, a set of extensions to OCaml that have been developed at Jane Street.&lt;/p&gt;
    &lt;p&gt;The basic idea is to introduce a way of marking a scope of allocation for a tensor, using this &lt;code&gt;with_rc_scope&lt;/code&gt; function, where ‚Äúrc‚Äù is short for ‚Äúreference count‚Äù:&lt;/p&gt;
    &lt;code&gt;val with_rc_scope : (unit -&amp;gt; 'a) @ local -&amp;gt; 'a
&lt;/code&gt;
    &lt;p&gt;The idea is that the body of the closure passed to this function acts as a scope, and that any tensors allocated within it will have their refcounts decremented when the function ends.&lt;/p&gt;
    &lt;p&gt;To make this all work, we use OxCaml‚Äôs &lt;code&gt;local&lt;/code&gt;
mode to make sure that tensors can‚Äôt
escape their scope.  In particular, any function that allocates a tensor will allocate it
as a local value:&lt;/p&gt;
    &lt;code&gt;val ( + ) : t @ local -&amp;gt; t @ local -&amp;gt; t @ local
&lt;/code&gt;
    &lt;p&gt;This prevents the allocated value from being returned from the closure passed to &lt;code&gt;with_rc_scope&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs a worked example of how you might use this in practice.&lt;/p&gt;
    &lt;code&gt;    let vs = Var_store.create ~name:"vs" () in
    let opt = Optimizer.sgd vs ~learning_rate:1e-3 in
    let model = Model.init vs in
    for index = 1 to 100 do
      Tensor.with_rc_scope (fun () -&amp;gt;
        Optimizer.zero_grad opt;
        let ys_ = Model.forward model xs in
        let loss = Tensor.(mean (square (ys - ys_))) in
        Tensor.backward loss;
        Optimizer.step opt)
    done;
&lt;/code&gt;
    &lt;p&gt;The full API is a bit more complicated than just that. The system has support for nested scopes, which is needed to support many of the idioms that are used in practice for both training and inference workflows on GPUs. As part of that, there is some special support for returning tensors from an inner scope to an outer scope in a controlled way that doesn‚Äôt violate the reference counting rules.&lt;/p&gt;
    &lt;p&gt;The project itself involved a lot of experimentation at the API level, to design an API that was easy to use and understand and that also captured the memory-use patterns we run into in practice. The project also had an interesting performance-engineering aspect to it: removing all of the now-unnecessary GC invocations made it easier to understand and identify further inefficiencies (like unnecessary synchronizations between the CPU and GPU) that were harder to see amongst the performance mess created by the &lt;code&gt;full_major&lt;/code&gt;
invocations.&lt;/p&gt;
    &lt;p&gt;We have more ideas about how to extend and improve these interfaces, but we already expect the new APIs to be quite useful in their current form. This is part of our open-source code, so once the new code is released, you‚Äôll be able to find it here.&lt;/p&gt;
    &lt;head rend="h1"&gt;Ref-counted objects in shared memory&lt;/head&gt;
    &lt;p&gt;At Jane Street, we have lots of performance-sensitive trading systems that gather complex information over the course of their execution, and then periodically serialize pieces of that data over a shared-memory channel to another process.&lt;/p&gt;
    &lt;p&gt;This is generally a pretty good approach, but it has its limitations. Serialization always has a cost, but here it‚Äôs made worse by the fact that the data we want to send is complex nested data with shared structure between messages. As a result, serializing the data can involve serializing the same sub-structures over and over.&lt;/p&gt;
    &lt;p&gt;Anthony Li‚Äôs project was to build a library supporting a very different ‚Äì and much more efficient ‚Äì approach.&lt;/p&gt;
    &lt;p&gt;The idea is to get rid of the serialization and deserialization altogether, and to just pass pointers to the values in question instead. This requires that the space of objects in question is visible to both processes, so it means we need to allocate those objects within a shared memory segment.&lt;/p&gt;
    &lt;p&gt;We already have support for managing pools of objects in a shared memory segment, so this sounds easy enough at first glance. But the tricky bit is figuring out when you can recycle one of your pooled objects.&lt;/p&gt;
    &lt;p&gt;We can‚Äôt rely on OCaml‚Äôs ordinary GC for this because the data resides in a shared-memory segment between two processes, each with their own GC. And anyway, we don‚Äôt want to be churning the garbage collector in a latency-sensitive trading system.&lt;/p&gt;
    &lt;p&gt;Instead, Anthony‚Äôs project was to use a tried-and-true technique for this: reference counting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Safer refcounting through modes&lt;/head&gt;
    &lt;p&gt;Reference counting is tricky to integrate into a language like OCaml that doesn‚Äôt have it designed in from the start. There are really three invariants you need to get right for this system to work:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There are no data-races on the refcounts or the objects themselves&lt;/item&gt;
      &lt;item&gt;Refcounts are incremented every time a new reference is created&lt;/item&gt;
      &lt;item&gt;Refcounts are decremented every time a reference is destroyed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But how do we ensure that these rules are followed when they‚Äôre not natively enforced by the runtime? This is a bit like the problem Aryan ran into with reference counting in PyTorch, and again, the solution is to leverage the system of modes to ensure the necessary invariants.&lt;/p&gt;
    &lt;p&gt;We‚Äôll need different modes at different times, so in order to manage this, we‚Äôre going to have a special handle object &lt;code&gt;o Handle.t&lt;/code&gt; that guards access to the underlying object (of
type &lt;code&gt;o&lt;/code&gt;).  We can both use modes to protect the use of the handle itself, and the handle
can release the object &lt;code&gt;o&lt;/code&gt; with specific modal types under specific circumstances.&lt;/p&gt;
    &lt;p&gt;That‚Äôs all a bit abstract, so let‚Äôs talk about the details:&lt;/p&gt;
    &lt;head rend="h3"&gt;Eliminating data races&lt;/head&gt;
    &lt;p&gt;There are really two data-race questions to handle here: one is about the refcounts, and the other is about the actual objects being managed. For the refcounts, an atomic compare-and-set operation can be used to manage them in a safe way, so that‚Äôs pretty simple, and doesn‚Äôt require anything from the mode system.&lt;/p&gt;
    &lt;p&gt;The mutability of the objects is more complicated, because the rules are different at different times. The objects must be mutable on initialization, since they have to be filled in at that point. But once you have multiple readers of the object, you really need them to not change. It turns out we can leverage OxCaml‚Äôs visibility mode axis, which include &lt;code&gt;immutable&lt;/code&gt;, &lt;code&gt;read&lt;/code&gt;, and &lt;code&gt;read_write&lt;/code&gt; modes.&lt;/p&gt;
    &lt;p&gt;Specifically:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;During initialization, we expose the value under the&lt;/p&gt;&lt;code&gt;read_write&lt;/code&gt;mode (which is the default), so the data in the object can be set. Notably, at this point, we‚Äôre guaranteed there‚Äôs only one reference to the object in question.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;When reading, we expose objects under the&lt;/p&gt;&lt;code&gt;read&lt;/code&gt;mode. This way, multiple readers (even across processes) can access the same object without fear of a race.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Notably, once an object‚Äôs reference count goes back to zero, it can again be the subject of an initialization, so it can again be exposed &lt;code&gt;read_write&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Another interesting aspect of this is that when we release the underlying values, we do so under the &lt;code&gt;local&lt;/code&gt; mode, to prevent the value from escaping its intended scope. As such,
what we‚Äôre implementing is analogous to borrow-checking in Rust.&lt;/p&gt;
    &lt;head rend="h3"&gt;Managing increments and decrements&lt;/head&gt;
    &lt;p&gt;The key invariant here is that people don‚Äôt just go about duplicating handles without incrementing the associated reference count. To ensure this, each &lt;code&gt;Handle.t&lt;/code&gt; is created
under the &lt;code&gt;unique&lt;/code&gt; mode, and all operations that use handles require that they be provided
uniquely.&lt;/p&gt;
    &lt;p&gt;This guarantees that all handles that are used are held uniquely, and so if you want to refer to the handle in multiple places, an explicit copy function must be called. And, critically, that copy function increments the reference count.&lt;/p&gt;
    &lt;p&gt;There‚Äôs also a &lt;code&gt;free&lt;/code&gt; operation that consumes a handle and decrements the reference count.
And a way of sending a handle to another process, at which point the sending handle is
consumed, and a receiving handle is created, without changing the reference count.&lt;/p&gt;
    &lt;p&gt;Anthony‚Äôs library is complete, and the team is now working it into our production systems. We hope that this will be a library that‚Äôs useful to multiple teams across the firm.&lt;/p&gt;
    &lt;head rend="h1"&gt;Join us!&lt;/head&gt;
    &lt;p&gt;If this sounds like a fun way to spend your summer, you should apply to our internship program. Jane Street interns get a chance to solve fun and challenging problems that have real impact. I hope this post gives you a sense of that!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062274</guid></item><item><title>Tesla said it didn't have key data in a fatal crash. Then a hacker found it</title><link>https://www.washingtonpost.com/technology/2025/08/29/tesla-autopilot-crashes-evidence-testimony-wrongful-death/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062614</guid></item><item><title>Anthropic reverses privacy stance, will train on Claude chats</title><link>https://www.perplexity.ai/page/anthropic-reverses-privacy-sta-xH4KWU9nS3KH4Aj9F12dvQ</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062683</guid></item><item><title>If you have a Claude account, they're going to train on your data moving forward</title><link>https://old.reddit.com/r/LocalLLaMA/comments/1n2ubjx/if_you_have_a_claude_personal_account_they_are/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062738</guid></item><item><title>Meta might be secretly scanning your phone's camera roll</title><link>https://www.zdnet.com/article/meta-might-be-secretly-scanning-your-phones-camera-roll-how-to-check-and-turn-it-off/</link><description>&lt;doc fingerprint="b4b2db1208265aff"&gt;
  &lt;main&gt;
    &lt;p&gt;'ZDNET Recommends': What exactly does it mean?&lt;/p&gt;
    &lt;p&gt;ZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we‚Äôre assessing.&lt;/p&gt;
    &lt;p&gt;When you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.&lt;/p&gt;
    &lt;p&gt;ZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.&lt;/p&gt;
    &lt;head rend="h1"&gt;Meta might be secretly scanning your phone's camera roll - how to check and turn it off&lt;/head&gt;
    &lt;p&gt;Follow ZDNET: Add us as a preferred source on Google.&lt;/p&gt;
    &lt;head rend="h3"&gt;ZDNET's key takeaways&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Meta could be scanning your camera roll right now.&lt;/item&gt;
      &lt;item&gt;It's using your photos to provide AI-powered suggestions.&lt;/item&gt;
      &lt;item&gt;Check Facebook settings to turn off the features.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Meta could be analyzing and retaining your phone's photos without your explicit consent.&lt;/p&gt;
    &lt;p&gt;Some Facebook users have noticed that, deep within their app settings, Meta has switched on two toggles that allow it to access their camera roll to offer AI-powered suggestions, including "personalized creative ideas, like travel highlights and collages."&lt;/p&gt;
    &lt;p&gt;Also: How to delete Facebook, Messenger, or Instagram - if you want Meta out of your life&lt;/p&gt;
    &lt;p&gt;The problem? The toggles for the AI suggestion features, called "camera roll sharing suggestions," appear to be turned on for users who claim they haven't seen a pop-up from Facebook asking for permission to enable them. If you get that "cloud processing" pop-up and tap "Allow" on it, you'll agree to Meta's AI Terms of Service and permit your "media and facial features" to be analyzed by AI.&lt;/p&gt;
    &lt;p&gt;Facebook will then use your camera roll images -- including the dates on them and the presence of people or objects -- to suggest collages, themed albums, recap posts, or AI restyled versions of your pictures. These AI suggestions are only visible to you, unless you choose to share them, and Meta says the media won't be used for ad targeting.&lt;/p&gt;
    &lt;p&gt;Also: How to protect your privacy from Facebook - and what doesn't work&lt;/p&gt;
    &lt;p&gt;But, to be clear, you're still giving Meta the right to access and retain your camera roll images, and that could raise serious privacy concerns, especially for users who never knowingly opted in.&lt;/p&gt;
    &lt;p&gt;ZDNET's editorial director found Meta's camera roll sharing suggestions enabled in her Facebook app without her knowledge. I also noticed they were enabled for me, although I vaguely recall seeing a pop-up from Facebook about the new features a few weeks ago. I think I dismissed it quickly, and I can't remember whether I tapped Allow or Don't allow on it.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to stop Facebook from scanning your camera roll&lt;/head&gt;
    &lt;p&gt;Meta said its camera roll sharing suggestions are not enabled by default. If you're worried you dismissed Facebook's pop-up, unknowingly opted-in, and gave access to your camera roll, here's how to check and turn it off.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Open the Facebook app&lt;/head&gt;
    &lt;p&gt;The settings you'll want to check can be found in the Facebook mobile app.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Grab your iPhone or Android phone.&lt;/item&gt;
      &lt;item&gt;Open the Facebook app. You'll need to be signed into your account.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;2. Go to the Menu &amp;gt; Settings and Privacy&lt;/head&gt;
    &lt;p&gt;Facebook hides most of its settings in the menu -- the three-line hamburger icon in the bottom corner of the app.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Tap the Menu icon in the bottom right corner of the screen.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Once the menu opens, look for Settings and Privacy with a gear icon. This will take you directly to Settings.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;3. Select Settings&lt;/head&gt;
    &lt;p&gt;Once you find and tap Privacy and Settings to expand the dropdown options, tap Settings again.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Under Settings and Privacy, tap Settings.&lt;/item&gt;
      &lt;item&gt;Now, scroll down and look for "Camera roll sharing suggestions."&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;4. Go to Camera roll sharing suggestions&lt;/head&gt;
    &lt;p&gt;Meta placed the toggles that grant it access to your camera roll under the "Camera roll sharing suggestions" setting. You'll need to go there to see if they're on and, if so, switch them off.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Look for the option labeled "Camera roll sharing suggestions" and tap it.&lt;/item&gt;
      &lt;item&gt;This will open a preference page with a couple of toggles.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;5. Turn off both toggles&lt;/head&gt;
    &lt;p&gt;Once you're inside the camera roll sharing suggestions page, notice the two separate switches. If they're blue and the toggle circle is pushed to the right, they're on -- meaning Meta is already processing and retaining your phone's photos. Turn them off so the app can't automatically upload and analyze your camera roll.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Find the option labeled "Get camera roll suggestions when you're browsing Facebook." If the switch is on (blue), tap it once to turn it off (gray). This will stop Facebook from using basic camera roll data, such as which videos you've favorited and when photos were taken, to suggest sharing media you haven't yet uploaded.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Find the option labeled "Get creative ideas made for you by allowing camera roll cloud processing." If the switch is on (blue), tap it once to turn it off (gray). This will stop Facebook from continuously uploading media from your camera roll -- and using details like time, location, themes, and the presence of people or objects -- to generate personalized creative ideas such as recaps and AI restylings.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;FAQs&lt;/head&gt;
    &lt;head rend="h3"&gt;Why is Facebook cloud-processing my device's camera roll?&lt;/head&gt;
    &lt;p&gt;Meta is uploading and analyzing your camera roll photos and videos, even ones you haven't posted, in its cloud in order to generate AI-powered suggestions like collages, monthly recaps, themed albums, or AI-restyled versions of your images.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where is this feature being tested?&lt;/head&gt;
    &lt;p&gt;Meta has confirmed the feature is a test, saying, "We're exploring ways to make content sharing easier for people on Facebook by testing suggestions of ready-to-share and curated content from a person's camera roll."&lt;/p&gt;
    &lt;p&gt;The test is currently available in the US and Canada, but it's not available in Illinois or Texas due to those states' privacy laws.&lt;/p&gt;
    &lt;head rend="h3"&gt;Did Facebook ask for my consent before turning this on?&lt;/head&gt;
    &lt;p&gt;Meta is showing a pop-up asking users if they want to enable cloud processing, but some users claim they haven't seen it. Instead, they found the toggles in their settings already switched on by default, raising questions about whether clear consent was given.&lt;/p&gt;
    &lt;head rend="h3"&gt;Can I remove my photos once they've been uploaded?&lt;/head&gt;
    &lt;p&gt;ZDNET's sister site, CNET, reports that Meta pulls from your newer pictures (roughly the last 30 days) and if you disable the feature, your uploaded photos will be deleted after 30 days. The only way to confirm is by downloading your Facebook account data.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why is this a potential privacy issue?&lt;/head&gt;
    &lt;p&gt;It expands Meta's reach beyond the content you've chosen to upload and share online -- into your private, unposted photos and videos. For many, that's a major red flag and a line they're not comfortable crossing, understandably so.&lt;/p&gt;
    &lt;p&gt;Also: What Zuckerberg's 'personal superintelligence' sales pitch leaves out&lt;/p&gt;
    &lt;p&gt;Even if Meta is asking for consent to access your camera roll in order to analyze your phone's photos and provide AI-powered suggestions, the company could have done a better job of being clear and explicit about what it's trying to do.&lt;/p&gt;
    &lt;p&gt;How many users, like me, simply dismissed the consent pop-up without fully realizing what they'd just agreed to?&lt;/p&gt;
    &lt;p&gt;Editor's note: This article was updated on Aug. 24, 2025 to clarify that Meta's camera roll sharing suggestions are not turned on by default and are entirely opt-in. Still, some users say they never knowingly agreed and are finding the features enabled in their settings.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062910</guid></item><item><title>Deepnote (YC S19) is hiring engineers to build a better Jupyter notebook</title><link>https://deepnote.com/join-us</link><description>&lt;doc fingerprint="b9d2255309e5a6a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;We build tools for explorers&lt;/head&gt;
    &lt;p&gt;We are here to revolutionize how data teams work together.&lt;/p&gt;
    &lt;p&gt;We started Deepnote to help data teams solve the hardest problems. We don‚Äôt just need better algorithms, bigger data sets, and more computing power. We need tools that help us explore, collaborate, and share. These tools don‚Äôt exist yet. We need to invent them first.&lt;/p&gt;
    &lt;p&gt;Data work is as much a scientific and creative process as it is an engineering one. It involves working together, failing, learning, and going back to the drawing board. Data professionals are explorers. To make projects successful, we need tools that are both powerful and easy to use. Tools that help us collaborate and share our work in an engaging way. Tools that make working with data fun again.&lt;/p&gt;
    &lt;p&gt;That‚Äôs why we‚Äôre building the new standard in data tooling: a notebook that brings teams together to code, query, visualize, organize, and share ‚Äî all in one place.&lt;/p&gt;
    &lt;p&gt;We are building tools for explorers. Join us.&lt;/p&gt;
    &lt;p&gt;Read more about us on TechCrunch&lt;/p&gt;
    &lt;p&gt;Read more about us on Nature&lt;/p&gt;
    &lt;head rend="h2"&gt;Build the future with us&lt;/head&gt;
    &lt;p&gt;We‚Äôre building a collaborative notebook that beautifully integrates analytics and data science into every workflow and decision. But it‚Äôs not just about designing, shipping, and selling. It‚Äôs about the people who power it ‚Äî and that means you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get ready to do your best work&lt;/head&gt;
    &lt;p&gt;Transforming how people work with data isn't easy. But we built a culture that allows us to do precisely that.&lt;/p&gt;
    &lt;head rend="h3"&gt;We move with urgency&lt;/head&gt;
    &lt;p&gt;We are a small, passionate team revolutionizing how data teams work. We give everyone the tools they need and enable them to take action.&lt;/p&gt;
    &lt;head rend="h3"&gt;We keep learning&lt;/head&gt;
    &lt;p&gt;We are knowledge-seekers. We invest in continuous learning across every role and encourage a culture of proactive feedback.&lt;/p&gt;
    &lt;head rend="h3"&gt;We take ownership&lt;/head&gt;
    &lt;p&gt;We are makers. We expect everyone to be a decision-maker ‚Äî no politics or walls to get in the way.&lt;/p&gt;
    &lt;head rend="h3"&gt;We collaborate&lt;/head&gt;
    &lt;p&gt;We are partners. We work in a fully transparent environment and put open, effective communication above all else.&lt;/p&gt;
    &lt;head rend="h2"&gt;Backed by the best in the business&lt;/head&gt;
    &lt;p&gt;We‚Äôre backed by industry leaders ‚Äî and they‚Äôre as excited about reimagining the future as we are.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Y Combinator&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Index Ventures&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Accel&lt;/head&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Greg Brockman&lt;p&gt;CTO at OpenAI&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Elad Gil&lt;p&gt;Angel Investor&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Naval Ravikant&lt;p&gt;Angel Investor&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;Elena Verna&lt;p&gt;Angel Investor&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Explore open positions&lt;/head&gt;
    &lt;p&gt;Thousands of data professionals already use Deepnote ‚Äî but we‚Äôre only scratching the surface of what‚Äôs possible. We‚Äôre building out our core team, and we want kind, curious explorers to join and grow with us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45062914</guid></item></channel></rss>