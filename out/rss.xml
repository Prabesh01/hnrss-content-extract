<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 01 Nov 2025 21:32:23 +0000</lastBuildDate><item><title>SQLite concurrency and why you should care about it</title><link>https://jellyfin.org/posts/SQLite-locking/</link><description>&lt;doc fingerprint="7b4e765eeca27f9a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;SQLite concurrency and why you should care about it&lt;/head&gt;
    &lt;p&gt;SQLite is a powerful database engine, but due to its design, it has limitations that should not be overlooked.&lt;/p&gt;
    &lt;p&gt;Jellyfin has used a SQLite-based database for storing most of its data for years, but it has also encountered issues on many systems. In this blog post, I will explain how we address these limitations and how developers using SQLite can apply the same solutions.&lt;/p&gt;
    &lt;p&gt;This will be a technical blog post intended for developers and everyone wanting to learn about concurrency.&lt;/p&gt;
    &lt;p&gt;Also Jellyfin's implementation of locking for SQLite should be fairly easy to be implemented into another EF Core application if you are facing the same issue.&lt;/p&gt;
    &lt;p&gt;- JPVenson&lt;/p&gt;
    &lt;head rend="h2"&gt;The Premise&lt;/head&gt;
    &lt;p&gt;SQLite is a file-based database engine running within your application and allows you to store data in a relational structure. Overall it gives your application the means of storing structured data as a single file and without having to depend on another application to do so. Naturally this also comes at a price. If your application fully manages this file, the assumption must be made that your application is the sole owner of this file, and nobody else will tinker with it while you are writing data to it.&lt;/p&gt;
    &lt;p&gt;So an application that wants to use SQLite as its database needs to be the only one accessing it. Having established this fact, an important thought arises: if only a single write operation should be performed on a single file at a time, this rule must also apply to operations within the same application.&lt;/p&gt;
    &lt;head rend="h2"&gt;The W-A-L mode&lt;/head&gt;
    &lt;p&gt;SQLite has a feature that tries to get around this limitation: the Write-Ahead-Log (WAL). The WAL is a separate file that acts as a journal of operations that should be applied to an SQLite file. This allows multiple parallel writes to take place and get enqueued into the WAL. When another part of the application wants to read data, it reads from the actual database, then scans the WAL for modifications and applies them on the fly. This is not a foolproof solution; there are still scenarios where WAL does not prevent locking conflicts.&lt;/p&gt;
    &lt;head rend="h2"&gt;SQLite transactions&lt;/head&gt;
    &lt;p&gt;A transaction is supposed to ensure two things. Modifications made within a transaction can be reverted, either when something goes wrong or when the application decides it should and optionally a transaction may also block other readers from reading data that is modified within a transaction. This is where it gets spicy and we come to the real reason why I am writing this blog post. For some reason on some systems that run Jellyfin when a transaction takes place the SQLite engine reports the database is locked and instead of waiting for the transaction to be resolved the engine refuses to wait and just crashes. This seems to be a not uncommon issue and there are many reports to be found on the issue.&lt;/p&gt;
    &lt;p&gt;The factor that makes this issue so bad is that it does not happen reliably. So far we only have one team member where this can be (somewhat) reliably be reproduced which makes this an even worse a bug. From the reports this issue happens across all operating systems, drive speeds and with or without virtualization. So we do not have any deciding factor identified that even contributes to the likelihood of the issue happening.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Jellyfin factor&lt;/head&gt;
    &lt;p&gt;Having established the general theory on how SQLite behaves, we also have to look at the specifics of Jellyfins usage of SQLite. During normal operations on a recommended setup (Non-Networked Storage and preferably SSD) its unusual for any problems to arise, however the way Jellyfin utilises the SQLite db up to 10.11 is very suboptimal. In versions prior to 10.11 Jellyfin had a bug in its parallel task limit which resulted in exponential overscheduling of library scan operations which hammered the database engine with thousands of parallel write requests that an SQLite engine is simply not able to handle. While most SQLite engine implementations have retry behavior, they also have timeouts and checks in place to prevent limitless waiting so if we stress the engine enough, it just fails with an error. That and very long running and frankly unoptimized transactions could lead to the database just being overloaded with requests and flaking out.&lt;/p&gt;
    &lt;head rend="h2"&gt;The solution&lt;/head&gt;
    &lt;p&gt;Since we moved the codebase over to EF Core proper, we have the tools to actually do something about this as EF Core gives us a structured abstraction level. EF Core supports a way of hooking into every command execution or transaction by creating Interceptors. With an interceptor we can finally do the straight forward idea of just "not" writing to the database in parallel in a transparent way to the caller. The overall idea is to have multiple strategies of locking. Because all levels of synchronization will inevitably come at the cost of performance, we only want to do it when it is really necessary. So, I decided on three locking strategies:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;No-Lock&lt;/item&gt;
      &lt;item&gt;Optimistic locking&lt;/item&gt;
      &lt;item&gt;Pessimistic locking&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As a default, the no-lock behavior does exactly what the name implies. Nothing. This is the default because my research shows that for 99% all of this is not an issue and every interaction at this level will slow down the whole application.&lt;/p&gt;
    &lt;p&gt;Both the optimistic and pessimistic behaviors use two interceptors—one for transactions and one for commands—and override &lt;code&gt;SaveChanges&lt;/code&gt; in &lt;code&gt;JellyfinDbContext&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Optimistic locking behavior&lt;/head&gt;
    &lt;p&gt;Optimistic locking means to assume the operation in question will succeed and only handle issues afterwards. In essence this can be boiled down to "Try and Retry and Retry ..." for a set number of times until either we succeed with the operation or fail entirely. This still leaves the possibility that we will not actually be able to perform a write, but the introduced overhead is far less than the Pessimistic locking behavior.&lt;/p&gt;
    &lt;p&gt;The idea behind how this works is simple: every time two operations try to write to the database, one will always win. The other will fail, wait some time, then retry a few times.&lt;/p&gt;
    &lt;p&gt;Jellyfin uses the &lt;code&gt;Polly&lt;/code&gt; library perform the retry behavior and will only retry operations it will find have been locked due to this exact issue.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pessimistic locking behavior&lt;/head&gt;
    &lt;p&gt;Pessimistic locking always locks when a write to SQLite should be performed. Essentially every time an transaction is started or a write operation on the database is done though EF Core, Jellyfin will wait until all other read operations are finished and then block all other operations may they be read or write until the write in question has been performed. This however means, that Jellyfin can only ever perform a single write to the database, even if it would technically does not need to.&lt;/p&gt;
    &lt;p&gt;In theory, an application should have no issue reading from table "Alice" while writing to table "Bob" however to eliminate all possible sources of concurrency related locking, Jellyfin will only ever allow a single write performed on its database in this mode. While this will absolutely result in the most stable operation, it will undoubtedly also be the slowest.&lt;/p&gt;
    &lt;p&gt;Jellyfin uses a ReaderWriterLockSlim to lock the operations, that means we allow an unlimited number of reads to happen concurrently while only one write may ever be done on the database.&lt;/p&gt;
    &lt;head rend="h3"&gt;The future Smart locking behavior&lt;/head&gt;
    &lt;p&gt;In the future we might also consider combining both modes, to get the best of both worlds.&lt;/p&gt;
    &lt;head rend="h1"&gt;The result&lt;/head&gt;
    &lt;p&gt;Initial testing showed that with both modes, we had great success in handling the underlying issue. While we are not yet sure why this happens only on some systems when others work, we at least now have an option for users previously left out of using Jellyfin.&lt;/p&gt;
    &lt;p&gt;When I was researching this topic, I found many reports all over the internet facing the same error but nobody was able to provide a conclusive explanation whats really happening here. There have been similar proposals made to handle it but there wasn't a "ready to drop in" solution that handles all the different cases or only code that required massive modifications to every EF Core query. Jellyfin's implementation of the locking behaviors should be a copy-paste solution for everyone having the same issues as its using interceptors and the caller has no idea of the actual locking behavior.&lt;/p&gt;
    &lt;p&gt;Best of luck,&lt;/p&gt;
    &lt;p&gt;- JPVenson&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45781298</guid><pubDate>Sat, 01 Nov 2025 12:59:03 +0000</pubDate></item><item><title>CharlotteOS – An Experimental Modern Operating System</title><link>https://github.com/charlotte-os/Catten</link><description>&lt;doc fingerprint="25a44afe193d139f"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;catten&lt;/code&gt; is an operating system kernel developed as a key component of the CharlotteOS project but it is designed to be flexible enough that we hope it can also find use in many other places. It seeks to be a monolithic kernel with low-level system call interfaces that borrows ideas from exokernels and other novel systems like Plan 9 and Fuchsia. Its design allows for almost any higher level interface to be layered on top and also includes a typesafe system namespace (akin to the namespaces found in Fuschsia and Plan 9 but more flexible and typesafe) with URIs as paths which has the added benefit of allowing access to the namespace of another host over a network without having to mount anything locally all while being secured by granular capabilities and a persistent mandatory access control policy.&lt;/p&gt;
    &lt;p&gt;catten is still in early development, and core subsystems are actively being built. We welcome contributions—feel free to grab an issue from the tracker, suggest features, or participate in discussions on our repository, Discord server or Matrix instance.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;catten&lt;/code&gt;is written in Rust and ISA specific assembly languages&lt;/item&gt;
      &lt;item&gt;x86_64 assembly should use Intel syntax as implemented by &lt;code&gt;rustc&lt;/code&gt;and&lt;code&gt;llvm-mc&lt;/code&gt;exclusively&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;C language dependencies are allowed if vetted by maintainers.&lt;/item&gt;
      &lt;item&gt;Any dependencies in languages other than Rust, C, and assembly are strictly forbidden.&lt;/item&gt;
      &lt;item&gt;Always prefer a high-quality Rust equivalent over an external C library unless there is good reason to do otherwise&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Processor: &lt;list rend="ul"&gt;&lt;item&gt;x86_64 (Primary ISA) &lt;list rend="ul"&gt;&lt;item&gt;x2APIC LAPIC operating mode&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;x86_64 (Primary ISA) &lt;/item&gt;
      &lt;item&gt;Firmware: &lt;list rend="ul"&gt;&lt;item&gt;Unified Extensible Firmware Interface (UEFI)&lt;/item&gt;&lt;item&gt;Advanced Configuration and Power Interface (ACPI)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Memory: &lt;list rend="ul"&gt;&lt;item&gt;Recommended: &amp;gt;= 1 GiB&lt;/item&gt;&lt;item&gt;Required: 128 MiB&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Storage: &lt;list rend="ul"&gt;&lt;item&gt;Recommended: &amp;gt;= 64 GiB&lt;/item&gt;&lt;item&gt;Required: 4 GiB&lt;/item&gt;&lt;item&gt;Device Types: &lt;list rend="ul"&gt;&lt;item&gt;Non-Volatile Memory Express (NVMe)&lt;/item&gt;&lt;item&gt;USB Mass Storage Device Class&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Output: &lt;list rend="ul"&gt;&lt;item&gt;Display Adapter: Any adapter capable of providing framebuffers via the UEFI Graphics Output Protocol&lt;/item&gt;&lt;item&gt;Serial: &lt;list rend="ul"&gt;&lt;item&gt;NS16550 compatible UART&lt;/item&gt;&lt;item&gt;USB CDC ACM (Virtual UART)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Input: &lt;list rend="ul"&gt;&lt;item&gt;Keyboard &lt;list rend="ul"&gt;&lt;item&gt;PS/2&lt;/item&gt;&lt;item&gt;USB HID&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Serial &lt;list rend="ul"&gt;&lt;item&gt;NS16550 compatible UART&lt;/item&gt;&lt;item&gt;USB CDC ACM (Virtual UART)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Keyboard &lt;/item&gt;
      &lt;item&gt;Networking: &lt;list rend="ul"&gt;&lt;item&gt;USB CDC Network Control Model&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please reach out to us on Matrix or Discord if you are interested in contributing.&lt;/p&gt;
    &lt;p&gt;This kernel is licensed under the GNU General Public License version 3.0 (or at your option, any later version). By contributing to this project you agree to license your contributions under those same terms exclusively.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45781397</guid><pubDate>Sat, 01 Nov 2025 13:12:47 +0000</pubDate></item><item><title>Updated practice for review articles and position papers in ArXiv CS category</title><link>https://blog.arxiv.org/2025/10/31/attention-authors-updated-practice-for-review-articles-and-position-papers-in-arxiv-cs-category/</link><description>&lt;doc fingerprint="ff55b99b0494c981"&gt;
  &lt;main&gt;
    &lt;p&gt;arXiv’s computer science (CS) category has updated its moderation practice with respect to review (or survey) articles and position papers. Before being considered for submission to arXiv’s CS category, review articles and position papers must now be accepted at a journal or a conference and complete successful peer review. When submitting review articles or position papers, authors must include documentation of successful peer review to receive full consideration. Review/survey articles or position papers submitted to arXiv without this documentation will be likely to be rejected and not appear on arXiv.&lt;lb/&gt; This change is being implemented due to the unmanageable influx of review articles and position papers to arXiv CS.&lt;/p&gt;
    &lt;p&gt;Is this a policy change?&lt;/p&gt;
    &lt;p&gt;Technically, no! If you take a look at arXiv’s policies for specific content types you’ll notice that review articles and position papers are not (and have never been) listed as part of the accepted content types. Review articles and position papers have, in the past, only been accepted at moderator discretion, because the few we received were of high quality and of interest to arXiv readers and the scientific community at large.&lt;/p&gt;
    &lt;p&gt;Why is the arXiv CS category making this change?&lt;/p&gt;
    &lt;p&gt;In the past few years, arXiv has been flooded with papers. Generative AI / large language models have added to this flood by making papers – especially papers not introducing new research results – fast and easy to write. While categories across arXiv have all seen a major increase in submissions, it’s particularly pronounced in arXiv’s CS category.&lt;/p&gt;
    &lt;p&gt;The goal of this change of practice is to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Help arXiv readers more easily find valuable review articles and position papers written by subject matter experts&lt;/item&gt;
      &lt;item&gt;Free up moderators to focus on the content types officially accepted by arXiv, reduce submission hold times, and keep the pace of scientific discovery going!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Above all, the core purpose of arXiv is to share research papers and facilitate scientific discovery quickly and freely. We are making this change in support of that mission.&lt;/p&gt;
    &lt;p&gt;In the past, arXiv CS received a relatively small amount of review or survey articles, and those we did receive were of extremely high quality, written by senior researchers at the request of publications like Annual Reviews, Proceedings of the IEEE, and Computing Surveys. Position paper submissions to arXiv were similarly rare, and usually produced by scientific societies or government study groups (for example,the Computing Research Association of the National Academies of Science, Engineering, and Medicine). While, as now, these papers were not content types officially accepted by arXiv, the arXiv moderators accepted them because of their scholarly value to the research community.&lt;/p&gt;
    &lt;p&gt;Fast forward to present day – submissions to arXiv in general have risen dramatically, and we now receive hundreds of review articles every month. The advent of large language models have made this type of content relatively easy to churn out on demand, and the majority of the review articles we receive are little more than annotated bibliographies, with no substantial discussion of open research issues.&lt;/p&gt;
    &lt;p&gt;arXiv believes that there are position papers and review articles that are of value to the scientific community, and we would like to be able to share them on arXiv. However, our team of volunteer moderators do not have the time or bandwidth to review the hundreds of these articles we receive without taking time away from our core purpose, which is to share research articles.&lt;/p&gt;
    &lt;p&gt;Reasonable and trusted outside refereed venues already exist (conferences and journals) which solicit position papers and review articles on subjects of concern or interest to our readers (such as concerns over privacy, ethics, safety, and security of recent CS technologies, particularly applications of artificial intelligence) and as part of that process, they conduct in-depth review to assure quality, evidential support of opinions, and scholarly value. Since arXiv does not have the resources to conduct this quality-control in-house for content types that we do not officially accept, this change of practice is allowing us to rely on these refereed venues to do so for us so that we can still share position papers and review articles of value on arXiv.&lt;/p&gt;
    &lt;p&gt;How do I submit my review article or position paper to arXiv? Before submission to arXiv, have your review article or position paper accepted to a refereed venue with peer review like a journal or a conference. Review articles or position papers must be accepted to a journal or conference before being submitted to arXiv and you must have documentation of complete and successful peer review.&lt;/p&gt;
    &lt;p&gt;Please note: the review conducted at conference workshops generally does not meet the same standard of rigor of traditional peer review and is not enough to have your review article or position paper accepted to arXiv.&lt;/p&gt;
    &lt;p&gt;How do I show my review article or position paper has successfully completed peer review? When you submit to arXiv, please include the peer reviewed journal reference and DOI metadata. If you do not provide this, your review article or position paper will likely be rejected.&lt;/p&gt;
    &lt;p&gt;Can I resubmit my position paper or review article after being rejected? If your position paper or review article was rejected because it did not complete a successful peer review process, you can submit an appeal request to resubmit if your article has since completed a successful peer review process. Do not resubmit your position paper or review article without an accepted appeal. Here are the instructions for how to appeal.&lt;/p&gt;
    &lt;p&gt;I have a scientific paper studying the impact of science and technology in society. Can I submit this to arXiv without peer review? Yes, arXiv has always released these types of scientific papers, for example in cs.CY or physics.soc-ph. These are scientific research papers and are not subject to this moderation practice change.&lt;/p&gt;
    &lt;p&gt;Will other categories on arXiv also change their practice re: review articles and position papers? Each category of arXiv has different moderators, who are subject matter experts with a terminal degree in their particular subject, to best serve the scholarly pursuits, goals, and standards of their category. While all moderators adhere to arXiv policy, the only policy arXiv has in place with regard to review articles and position papers is that they are not a generally accepted content type. The goal of the moderators of each category is to make sure the work being submitted is actually science, and that it is of potential interest to the scientific community. If other categories see a similar rise in LLM-written review articles and position papers, they may choose to change their moderation practices in a similar manner to better serve arXiv authors and readers. We will make these updates public if and when they do occur.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45782136</guid><pubDate>Sat, 01 Nov 2025 14:58:05 +0000</pubDate></item><item><title>Open-Source Ada: From Gateware to Application</title><link>https://blog.adacore.com/open-source-ada-from-gateware-to-application</link><description>&lt;doc fingerprint="a60816a801d4c06a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Open-Source Ada: From Gateware to Application&lt;/head&gt;
    &lt;head rend="h2"&gt;by Olivier Henley –&lt;/head&gt;
    &lt;head rend="h1"&gt;IntroÂducÂtion &amp;amp; MotiÂvaÂtion #&lt;/head&gt;
    &lt;p&gt;To jump right in, all build instrucÂtions and source code can be found here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open-Source Stack Matters&lt;/head&gt;
    &lt;p&gt;As the GNAT AcaÂdÂeÂmÂic ProÂgram (GAP) CoorÂdiÂnaÂtor at AdaÂCore, I focus on thorÂough, hands-on learnÂing in sysÂtem proÂgramÂming. A fulÂly open-source stack (covÂerÂing gateÂware, toolÂchains, and appliÂcaÂtions) proÂvides the freeÂdom to explore and refine every layÂer, from silÂiÂcon-levÂel conÂtrol to high-levÂel abstracÂtions. This Neorv32 Basic Input/âOutput SysÂtem (BIOS) project highÂlights Ada as a friendÂly yet powÂerÂful alterÂnaÂtive to C for open-source development.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who This Post is For&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CuriÂous develÂopÂers explorÂing &lt;code&gt;Ada&lt;/code&gt;beyond its usuÂal reputation.&lt;/item&gt;
      &lt;item&gt;Ada enthuÂsiÂasts who lack the time to experÂiÂment with a softÂcore CenÂtral ProÂcessÂing Unit (CPU), a procesÂsor defined in a HardÂware DescripÂtion LanÂguage (HDL) and deployÂable on reconÂfigÂurable logÂic like a Field-ProÂgramÂmaÂble Gate Array (FPGA), rather than fixed silicon.&lt;/item&gt;
      &lt;item&gt;EmbedÂded sysÂtem newÂcomÂers seekÂing a pracÂtiÂcal introÂducÂtion to fundamentals.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Neorv32, RISCâV, VHDL, and ULX3S #&lt;/head&gt;
    &lt;head rend="h2"&gt;Neorv32?&lt;/head&gt;
    &lt;p&gt;The Neorv32 SysÂtem on a Chip (SoC) is a VHDL-based RISCâV softÂcore feaÂturÂing a broad set of extenÂsions and periphÂerÂals along with extenÂsive docÂuÂmenÂtaÂtion. The Neorv32 is the brainÂchild of Stephan NoltÂing, who, accordÂing to his GitHub page, is assoÂciÂatÂed with the FraunÂhofer InstiÂtute for MicroÂelecÂtronÂic CirÂcuits and SysÂtems, GerÂmany.&lt;/p&gt;
    &lt;head rend="h2"&gt;RISCâV?&lt;/head&gt;
    &lt;p&gt;RISCâV is an open, extenÂsiÂble InstrucÂtion Set ArchiÂtecÂture (ISA) groundÂed in proven Reduced InstrucÂtion Set ComÂputÂer (RISC) prinÂciÂples, designed to be both modÂuÂlar and scalÂable. In my view, the openÂness and wideÂspread accepÂtance of RISCâV make it less susÂcepÂtiÂble to techÂniÂcal obsoÂlesÂcence than proÂpriÂetary or less wideÂly adoptÂed archiÂtecÂtures. RISCâVâs extenÂsiÂbilÂiÂty ensures it can evolve rather than become obsoÂlete, makÂing a lot of sense in acaÂdÂeÂmÂic and indusÂtriÂal contexts.&lt;/p&gt;
    &lt;head rend="h2"&gt;VHDL?&lt;/head&gt;
    &lt;p&gt;VHDL is a stanÂdardÂized hardÂware descripÂtion lanÂguage. Like Ada, it is strucÂtured, strongÂly typed, and enforces strict comÂpiÂlaÂtion rules. VHDL was origÂiÂnalÂly designed based on Ada: its synÂtax is very simÂiÂlar, and the semanÂtics align up to a point, with both lanÂguages priÂorÂiÂtizÂing corÂrectÂness over conÂveÂnience. Although verÂbose for some tastes, this clarÂiÂty reduces uninÂtendÂed errors and ensures explicÂit, unamÂbiguÂous design comÂmuÂniÂcaÂtion. The Neorv32 project is an excelÂlent tesÂtaÂment to the comÂpoundÂing benÂeÂfits of these attributes.&lt;/p&gt;
    &lt;head rend="h2"&gt;ULX3S?&lt;/head&gt;
    &lt;p&gt;The Radiona ULX3S is an open-source develÂopÂment board built around the LatÂtice ECP5 FPGA. Although the chip manÂuÂfacÂturÂing remains proÂpriÂetary, the board design is fulÂly open. Iâm using the 85,000 Look-Up Tables (85k LUT) verÂsion for its flexÂiÂbilÂiÂty and capaÂbilÂiÂty. It includes varÂiÂous periphÂerÂals but the real focus here is on the ECP5 FPGA, where weâll deploy our cusÂtom BIOS over the Neorv32 SoC.&lt;/p&gt;
    &lt;head rend="h1"&gt;DeterÂminÂisÂtic SoC #&lt;/head&gt;
    &lt;head rend="h2"&gt;CuratÂing Quality&lt;/head&gt;
    &lt;p&gt;The Neorv32 is designed with robustÂness and preÂdictabilÂiÂty in mind. It folÂlows a HarÂvard archiÂtecÂture, keepÂing instrucÂtion and data memÂoÂry sepÂaÂrate. Its mulÂti-cycle modÂel focusÂes on deterÂminÂisÂtic behavÂior, avoidÂing specÂuÂlaÂtive exeÂcuÂtion and ranÂdom stalls. It also offers capaÂbilÂiÂties that stand out among open-source RISCâV cores:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;VirÂtuÂalÂizaÂtion and safeÂty mechÂaÂnisms that detect malÂformed instrucÂtions and privÂiÂlege escaÂlaÂtions, and that enforce address-space integrity.&lt;/item&gt;
      &lt;item&gt;A hardÂware RISCâV debug modÂule for On-Chip DebugÂging (OCD).&lt;/item&gt;
      &lt;item&gt;SupÂport for atomÂic operÂaÂtions, which is critÂiÂcal for concurrency.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unlike softÂware, hardÂware debugÂging is tied to physÂiÂcal sigÂnals, makÂing errors much hardÂer to trace and corÂrect. This realÂiÂty makes good design pracÂtices cruÂcial from the start. In pracÂtice, the Neorv32âs conÂserÂvÂaÂtive yet adaptÂable approach minÂiÂmizes edge casÂes and failÂure points.&lt;/p&gt;
    &lt;head rend="h1"&gt;ToolÂchain BreakÂdown: Going FulÂly Open-Source #&lt;/head&gt;
    &lt;head rend="h2"&gt;GateÂware, Firmware?&lt;/head&gt;
    &lt;p&gt;An FPGA is a reconÂfigÂurable chip where hardÂware logÂic cirÂcuits are defined proÂgramÂmatÂiÂcalÂly. Unlike fixed CPUs that exeÂcute instrucÂtions, an FPGA impleÂments such procesÂsor logÂic directÂly. This is why we call such assemÂbled code gateÂware. Instead of writÂing firmware for a preÂdeÂfined CPU, we first proÂgram the processorâs archiÂtecÂture in an HDL before deployÂing comÂpiled firmware instrucÂtions on it. In a nutÂshell, LUTs and Block RAM (BRAM) are the basic buildÂing blocks of an FPGA. As a genÂerÂal rule, the more of these resources you have, the more comÂplex your processor/âaccelerator logÂic can be.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open-Source FPGA Toolchain&lt;/head&gt;
    &lt;p&gt;If you have some expeÂriÂence with FPGA develÂopÂment, you know proÂpriÂetary toolÂchains usuÂalÂly transÂform HDL code into a bitÂstream for proÂgramÂming the FPGA. Thanks to ongoÂing acaÂdÂeÂmÂic and open-source efforts, we can now rely on a fulÂly open ecosysÂtem. Here is how the open-source flow proÂduces a usable Neorv32 bitÂstream for the LatÂtice ECP5 on the ULX3S:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;GHDL, which is notably writÂten in Ada, parsÂes the VHDL and passÂes it to Yosys, an HDL synÂtheÂsis tool, through a plugin.&lt;/item&gt;
      &lt;item&gt;Yosys, with help from BerkeÂley-ABC, a sysÂtem for sequenÂtial synÂtheÂsis and verÂiÂfiÂcaÂtion, builds and optiÂmizes a netlist, a descripÂtion of the conÂnecÂtivÂiÂty of FPGA resources.&lt;/item&gt;
      &lt;item&gt;NextpÂnr takes that netlist for place-and-route, mapÂping it onto the ECP5âs physÂiÂcal layÂout using the Project TrelÂlis database.&lt;/item&gt;
      &lt;item&gt;ecpÂpack (part of TrelÂlis), then assemÂbles the final bitÂstream, ready to be uploaded to the FPGA&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;BringÂing Up Neorv32 on the ULX3S #&lt;/head&gt;
    &lt;head rend="h2"&gt;Board SetÂup and Configuration&lt;/head&gt;
    &lt;p&gt;To conÂfigÂure the Neorv32 softÂcore for my ULX3S board, I used neorv32-setups, a reposÂiÂtoÂry that proÂvides default board conÂfigÂuÂraÂtions and build setups for a basic SoC gateÂware and firmware. This was preÂciseÂly what I needÂed since it includes a UART, which is required for our Ada BIOS demo. A givÂen board setÂup conÂsists of a conÂstraint file that maps the boardâs physÂiÂcal interÂfaces to the FPGA pins, and a top-levÂel VHDL file that allows cusÂtomizaÂtion of the base SoC. In this file, you define the SoC you want by selectÂing periphÂerÂals and setÂting key paraÂmeÂters like the sysÂtem clock speed based on what the board physÂiÂcalÂly provides.&lt;/p&gt;
    &lt;head rend="h2"&gt;GenÂerÂatÂing and FlashÂing the Bitstream&lt;/head&gt;
    &lt;p&gt;FinalÂly, you have build makeÂfiles driÂving the open-source toolÂchain to genÂerÂate the SoC bitÂstream (.bit) and C firmware demos. With everyÂthing conÂfigÂured and built, I had a Neorv32 SoC bitÂstream file ready to be uploaded to the ULX3S. To give you an idea, this basic Neorv32 SoC uses 3,026 of the 85k LUTs (3% total) and 67 of the 208 DP16KD 16K block RAMs (32%), leavÂing plenÂty of room on my ECP5. To flash it, I used fujprog, anothÂer open-source project, which comÂpiled and transÂferred sucÂcessÂfulÂly on the first attempt.&lt;/p&gt;
    &lt;head rend="h1"&gt;GoodÂbye C, HelÂlo Ada #&lt;/head&gt;
    &lt;head rend="h2"&gt;Neorv32 BootÂloader Flow&lt;/head&gt;
    &lt;p&gt;Right away, I was able to test the default Neorv32 bootÂloader and upload some of the proÂvidÂed demos. DurÂing SoC synÂtheÂsis, the Neorv32 bootÂloader firmware is embedÂded into the FPGA bitÂstream. Once the FPGA is proÂgrammed and starts up, exeÂcuÂtion jumps directÂly to this bootÂloader, which presents a comÂmand menu for uploadÂing and runÂning othÂer firmware. The main Neorv32 reposÂiÂtoÂry proÂvides sevÂerÂal C demos designed to be exeÂcutÂed through this bootloader.&lt;/p&gt;
    &lt;p&gt;For these youâll need a RISCâV crossâcompiler (with libÂgloss) and a terÂmiÂnal proÂgram that can send raw binaÂry data withÂout headÂers. I used GTKÂTerm on LinÂux to ensure the firmware forÂmat matched what Neorv32âs bootÂloader expects. After startÂing with a ââhelÂlo worldâ C demo to learn the workÂflow, I moved on to write the Ada BIOS. Although setÂting up InterÂrupt SerÂvice RouÂtines (ISR) is a familÂiar conÂcept, doing it on RISCâV was new terÂriÂtoÂry for me.&lt;/p&gt;
    &lt;head rend="h2"&gt;C to Ada, Step-by-Step&lt;/head&gt;
    &lt;p&gt;The key was to creÂate a minÂiÂmal demo that exerÂcised UART RX interÂrupts for incomÂing conÂsole data, along with the necÂesÂsary ConÂtrol and StaÂtus RegÂisÂter (CSR) setÂup. TypÂiÂcal demos skip UART receive, so I pieced togethÂer a simÂple C examÂple to focus on hanÂdling UART0 RX interrupts.&lt;/p&gt;
    &lt;p&gt;When an interÂrupt occurs, the CPU stops what itâs doing and hands exeÂcuÂtion to the regÂisÂtered callÂback. Once finÂished, the CPU must restore its preÂviÂous state. In pracÂtice, that means a) savÂing the curÂrent regÂisÂters, b) runÂning the interÂrupt hanÂdler withÂin &lt;code&gt;isr()&lt;/code&gt;, and c) restorÂing the regÂisÂters before pickÂing up where it left off.&lt;/p&gt;
    &lt;p&gt;The refÂerÂence code tackÂled these steps in a sinÂgle naked C funcÂtion, mixÂing inline assemÂbly for saving/ârestoring regÂisÂters with the ISR logÂic. SplitÂting this into sepÂaÂrate C or Ada funcÂtions caused crashÂes. To fix that, I moved the assemÂbly preÂlude and postlude into &lt;code&gt;trap_entry.S&lt;/code&gt; and exposed a &lt;code&gt;trap_entry()&lt;/code&gt; and &lt;code&gt;isr()&lt;/code&gt; symÂbol to the linker.&lt;/p&gt;
    &lt;code&gt;.global trap_entry
.global isr

trap_entry:
...
   sw x31, 31*4(sp)  # Save x31 register
   call isr
...
   lw x31, 31*4(sp)  # Restore x31 register
...
   mret&lt;/code&gt;
    &lt;p&gt;IniÂtialÂly I kept the &lt;code&gt;isr()&lt;/code&gt; impleÂmenÂtaÂtion logÂic in C to ensure getÂting back to a workÂing state. Once done, I transÂlatÂed the &lt;code&gt;isr()&lt;/code&gt; logÂic to Ada step by step, ensurÂing each operÂaÂtion matched the original.&lt;/p&gt;
    &lt;code&gt;procedure Isr 
  with Export, Convention =&amp;gt; C, External_Name =&amp;gt; "isr";

procedure Isr is
begin
  Call_Handler;
  if Is_Exception then
    Compute_Return_Address;
  end if;
end Isr;

procedure Trap_Entry 
  with Import, Convention =&amp;gt; C, External_Name =&amp;gt; "trap_entry";&lt;/code&gt;
    &lt;head rend="h1"&gt;Neorv32 HardÂware AbstracÂtion LayÂer #&lt;/head&gt;
    &lt;head rend="h2"&gt;SetÂting Up a MinÂiÂmal Ada Runtime&lt;/head&gt;
    &lt;p&gt;Alire, the Ada packÂage manÂagÂer, already includes packÂages to help creÂate a basic RISCâV HardÂware AbstracÂtion LayÂer (HAL). bare_âruntime, a minÂiÂmal Ada runÂtime for embedÂded or restrictÂed tarÂgets, is a perÂfect fit. A needÂed GNAT RISCâV cross-comÂpilÂer is also availÂable. To make this work, two steps are required:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add and conÂfigÂure depenÂdenÂcies in the packÂage manÂagÂer manÂiÂfest file of the &lt;code&gt;neorv32_hal&lt;/code&gt;library. The relÂeÂvant secÂtion of the&lt;code&gt;alire.toml&lt;/code&gt;file looks like this:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;[[depends-on]]
gnat_riscv64_elf = "*"
bare_runtime = "*"

[gpr-set-externals]
BARE_RUNTIME_SWITCHES = "-march=rv32i_zicsr_zifencei -mabi=ilp32"&lt;/code&gt;
    &lt;p&gt;This estabÂlishÂes depenÂdenÂcies on the GNAT RISCâV cross-comÂpilÂer and the bare-metÂal runÂtime. It also passÂes speÂcifÂic build switchÂes to gprbuild, the GNAT build sysÂtem, ensurÂing comÂpatÂiÂbilÂiÂty with the tarÂgetÂed RISCâV variant.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CusÂtomize the build file, &lt;code&gt;neorv32_hal.gpr&lt;/code&gt;, accordÂingÂly:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;with "bare_runtime.gpr";
project Neorv32_Hal is
   for Languages use ("Ada", "ASM_CPP");
   for Target use "riscv64-elf";
   for Runtime ("Ada") use Bare_Runtime'Runtime ("Ada");
   for Library_Name use "Neorv32_Hal";
...
end Neorv32_Hal;&lt;/code&gt;
    &lt;p&gt;Here, we refÂerÂence the bare_âruntime project file, ensure supÂport for both Ada and AssemÂbly code, specÂiÂfy RISCâV as the tarÂget archiÂtecÂture, set bare_âruntime as the runÂtime, and define the curÂrent project as a library.&lt;/p&gt;
    &lt;head rend="h2"&gt;CreÂatÂing a CusÂtom LinkÂer Script and StartÂup Code&lt;/head&gt;
    &lt;p&gt;The next step is to creÂate the linkÂer script (&lt;code&gt;link.ld&lt;/code&gt;) and startÂup assemÂbly (&lt;code&gt;crt0.S&lt;/code&gt;). This is easÂiÂly done using the startup_âgen Alire packÂage. By proÂvidÂing key details about our tarÂget, such as memÂoÂry sizes, memÂoÂry start addressÂes and CPU archiÂtecÂture, startup_âgen genÂerÂates basic funcÂtionÂal files:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;crt0.S&lt;/code&gt;hanÂdles iniÂtialÂizaÂtion: loadÂing the data secÂtion, clearÂing BSS, and setÂting up global/âstatic objects.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;link.ld&lt;/code&gt;maps firmware secÂtions accordÂing to the Neorv32 memÂoÂry layÂout: placÂing instrucÂtions in ROM and data in RAM.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a deepÂer dive into starÂtupÂgen, check out the relatÂed blog post.&lt;/p&gt;
    &lt;head rend="h2"&gt;ImpleÂmentÂing InterÂrupt HanÂdling in Ada&lt;/head&gt;
    &lt;p&gt;As menÂtioned, savÂing and restorÂing regÂisÂters durÂing an interÂrupt now hapÂpens in assemÂbly: &lt;code&gt;trap_entry&lt;/code&gt;. What remains is the midÂdle part: the &lt;code&gt;isr()&lt;/code&gt; that ends up callÂing the hanÂdler regÂisÂtered for the speÂcifÂic interÂrupt. First we need to update the Machine Trap VecÂtor RegÂisÂter (Mtvec) to point to our &lt;code&gt;trap_entry&lt;/code&gt;. This hapÂpens in the interÂrupt iniÂtialÂizaÂtion code.&lt;/p&gt;
    &lt;code&gt;procedure Init is
begin
  RISCV.CSR.Mstatus.Set_Bits (2#11000_00000000#);  --  after MRET stays M-mode
  RISCV.CSR.Mtvec.Write (UInt32 (To_Integer (Trap_Entry'Address)));
  RISCV.CSR.Mie.Write (0);  --  disables all interrupts
  Asm ("fence");
end Init;&lt;/code&gt;
    &lt;p&gt;Next we need to creÂate our &lt;code&gt;Handlers&lt;/code&gt; table; one entry per speÂcifÂic interÂrupt. Note that Neorv32 can be built as a dual-core, so the &lt;code&gt;Hart_ID_T&lt;/code&gt; type range from 0 to 1.&lt;/p&gt;
    &lt;code&gt;subtype Hart_Id_T is Natural range 0 .. 1;
type Trap_Code_T is (
...
  Fast_Interrupt_2, -- Uart0 RX
...
);

for Trap_Code_T use (
...
  Fast_Interrupt_2 =&amp;gt; 16#80000012#, -â Uart0 RX
...
  );

type Interrupt_Handler is access procedure (Hart : Hart_Id_T; Trap_Code : Trap_Code_T);
...
type Handlers_T is array (Hart_Id_T, Trap_Code_T) of Interrupt_Handler;
Handlers : Handlers_T := (others =&amp;gt; (others =&amp;gt; Default_Handler'Access));&lt;/code&gt;
    &lt;p&gt;We install a speÂcifÂic interÂrupt callÂback by indexÂing it in the &lt;code&gt;Handlers&lt;/code&gt; table:&lt;/p&gt;
    &lt;code&gt;procedure Install_Uart0_Rx_Interrupt_Handler (Hart : Harts_T; Handler : Interrupt_Handler) is
begin
  Handlers (Hart, Fast_Interrupt_2) := Handler;
end Install_Uart0_Rx_Interrupt_Handler;&lt;/code&gt;
    &lt;p&gt;CallÂing a hanÂdler involves checkÂing the interruptâs cause. Our callÂback sigÂnaÂture receives the &lt;code&gt;Hart_Id&lt;/code&gt; and the &lt;code&gt;Trap_Code&lt;/code&gt; enum value.&lt;/p&gt;
    &lt;code&gt;procedure Call_Handler is
  Hart_Id : Hart_Id_T := Hart_Id_T (RISCV.CSR.MHARTID.Read);
  Trap_Code : Trap_Code_T := Trap_Code_T'Enum_Val (RISCV.CSR.MCAUSE.Read);
begin
  Handlers (Hart_Id, Trap_Code).all (Hart_Id, Trap_Code);
end Call_Handler;&lt;/code&gt;
    &lt;head rend="h1"&gt;SVD and Ada #&lt;/head&gt;
    &lt;head rend="h2"&gt;MemÂoÂry-Mapped Peripherals&lt;/head&gt;
    &lt;p&gt;At this point, we need a way to talk to periphÂerÂals like UART0, which are memÂoÂry-mapped at speÂcifÂic addressÂes. At a givÂen base address, thereâs a range of bits for conÂtrol and data, and your Ada code interÂacts with these regÂisÂters to manÂage the peripheral.&lt;/p&gt;
    &lt;p&gt;In the embedÂded world, this mapÂping is often docÂuÂmentÂed in an XML-based forÂmat called CMSIS-SVD, which defines each peripheralâs base address and regÂisÂter layÂout. Neorv32 folÂlows this conÂvenÂtion and proÂvides a sinÂgle SVD file (.svd) covÂerÂing every potenÂtial periphÂerÂal for a givÂen SoC configuration.&lt;/p&gt;
    &lt;head rend="h2"&gt;Auto-GenÂerÂate Ada Code for Registers&lt;/head&gt;
    &lt;p&gt;By using the Svd2ada Alire packÂage, you can feed in the SVD file and autoÂmatÂiÂcalÂly genÂerÂate Ada code that reflects the strucÂture of each memÂoÂry mapped periphÂerÂal. For examÂple, conÂsidÂer this snipÂpet from the &lt;code&gt;neorv32.svd&lt;/code&gt; file for the UART0 peripheral:&lt;/p&gt;
    &lt;code&gt;&amp;lt;peripheral&amp;gt;
  &amp;lt;name&amp;gt;UART0&amp;lt;/name&amp;gt;
  &amp;lt;description&amp;gt;Primary universal asynchronous receiver and transmitter&amp;lt;/description&amp;gt;
  &amp;lt;baseAddress&amp;gt;0xFFF50000&amp;lt;/baseAddress&amp;gt;

  &amp;lt;addressBlock&amp;gt;
    &amp;lt;offset&amp;gt;0&amp;lt;/offset&amp;gt;
    &amp;lt;size&amp;gt;0x08&amp;lt;/size&amp;gt;
    &amp;lt;usage&amp;gt;registers&amp;lt;/usage&amp;gt;
  &amp;lt;/addressBlock&amp;gt;

  &amp;lt;registers&amp;gt;
    &amp;lt;register&amp;gt;
      &amp;lt;name&amp;gt;CTRL&amp;lt;/name&amp;gt;
      &amp;lt;description&amp;gt;Control register&amp;lt;/description&amp;gt;
      &amp;lt;addressOffset&amp;gt;0x00&amp;lt;/addressOffset&amp;gt;
      &amp;lt;fields&amp;gt;
        &amp;lt;field&amp;gt;
          &amp;lt;name&amp;gt;UART_CTRL_EN&amp;lt;/name&amp;gt;
          &amp;lt;bitRange&amp;gt;[0:0]&amp;lt;/bitRange&amp;gt;
          &amp;lt;description&amp;gt;UART enable flag&amp;lt;/description&amp;gt;
        &amp;lt;/field&amp;gt;
        ...
      &amp;lt;/fields&amp;gt;
    &amp;lt;/register&amp;gt;
    ...
  &amp;lt;/registers&amp;gt;
&amp;lt;/peripheral&amp;gt;&lt;/code&gt;
    &lt;p&gt;From this, we see:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A base address of 0xFFF50000.&lt;/item&gt;
      &lt;item&gt;An address block spanÂning 8 bytes.&lt;/item&gt;
      &lt;item&gt;A conÂtrol regÂisÂter, &lt;code&gt;CRTL&lt;/code&gt;, with a 1âbit field,&lt;code&gt;UART_CTRL_EN&lt;/code&gt;, to enable or disÂable the peripheral.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After runÂning it through Svd2ada, youâll get this neat genÂerÂatÂed Ada code you can use directly:&lt;/p&gt;
    &lt;code&gt;--  Generated from neorv32.svd

UART0_Base : constant System.Address := System'To_Address (16#FFF50000#);

type Bit is mod 2**1 with Size =&amp;gt; 1;
subtype CTRL_UART_CTRL_EN_Field is Bit;

type CTRL_Register is record
   UART_CTRL_EN : CTRL_UART_CTRL_EN_Field := 16#0#;
...
   UART_CTRL_TX_FULL : CTRL_UART_CTRL_TX_FULL_Field := 16#0#;
...
end record
   with Volatile_Full_Access, Object_Size =&amp;gt; 32,
        Bit_Order =&amp;gt; System.Low_Order_First;

type UART0_Peripheral is record
   CTRL : aliased CTRL_Register;
   DATA : aliased neorv32.UInt32;
end record
  with Volatile;

for UART0_Peripheral use record
   CTRL at 16#0# range 0 .. 31;
   DATA at 16#4# range 0 .. 31;
end record;

UART0_Periph : aliased UART0_Peripheral with Import, Address =&amp;gt; UART0_Base;&lt;/code&gt;
    &lt;head rend="h2"&gt;MinÂiÂmal UART Driver&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;UART0_Periph&lt;/code&gt; is the periphÂerÂal instance to use. The folÂlowÂing code uses it to read a charÂacÂter over the UART0:&lt;/p&gt;
    &lt;code&gt;function Read_RX return Character is
  UART_RX : Character with Volatile, Address =&amp;gt; UART0_Periph.Data'Address;
begin
  return UART_RX;
end Read_RX;
pragma Inline (Read_RX);&lt;/code&gt;
    &lt;head rend="h2"&gt;ImpleÂmentÂing Ada.Text_IO&lt;/head&gt;
    &lt;p&gt;Now, to enrich our bare runÂtime and enable &lt;code&gt;Ada.Text_IO&lt;/code&gt; rouÂtines, all we need is to supÂply our own &lt;code&gt;putchar&lt;/code&gt; funcÂtion that hanÂdles a sinÂgle charÂacÂterâââhere text IO goes through UART. The bare_âruntime includes a weak &lt;code&gt;putchar&lt;/code&gt;, so once we proÂvide our cusÂtom impleÂmenÂtaÂtion, the rest of the logÂic is hanÂdled automatically.&lt;/p&gt;
    &lt;code&gt;procedure Put_Char (C : Interfaces.C.char) with
    Export, Convention =&amp;gt; C, External_Name =&amp;gt; "putchar";

procedure Put_Char (C : Interfaces.C.char) is
begin
  while UART0_Periph.CTRL.UART_CTRL_TX_FULL = 1 loop
    null;
  end loop;
  Write_TX (Interfaces.C.To_Ada (C));
end Put_Char;&lt;/code&gt;
    &lt;head rend="h1"&gt;The neorv32_âhal + demos packÂage #&lt;/head&gt;
    &lt;head rend="h2"&gt;Alire PackÂage Structure&lt;/head&gt;
    &lt;p&gt;Now weâre ready to creÂate the &lt;code&gt;bios&lt;/code&gt; demo and packÂage it withÂin the &lt;code&gt;neorv32_hal&lt;/code&gt; in the Alire registry:&lt;/p&gt;
    &lt;code&gt;neorv32_hal
 â alire.toml        (the manifest pushed to the Alire upstream index)
 â src               (contains HAL code)
 â demos
       â alire.toml  (pin a backward dependency on neorv32_hal)
       â src         (contains BIOS demo code)&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;alire.toml&lt;/code&gt; inside &lt;code&gt;demos&lt;/code&gt; looks like this:&lt;/p&gt;
    &lt;code&gt;name = "demos"
executables = ["bios"]

[[depends-on]]
neorv32_hal = "*"

[[pins]]
neorv32_hal = { path = ".." }&lt;/code&gt;
    &lt;p&gt;FinalÂly, our BIOS code doesnât rely on polling. Itâs event-driÂven through RX interÂrupts. All reactÂing code and state hanÂdling hapÂpens in &lt;code&gt;Parse_Cmd&lt;/code&gt; and the priÂvate impleÂmenÂtaÂtion of the &lt;code&gt;Bios_Core&lt;/code&gt; package.&lt;/p&gt;
    &lt;code&gt;with Bios_Core;
with Interrupts;
with Uart0;

procedure Bios is
begin
   Interrupts.Init;
   Interrupts.Install_Uart0_Rx_Interrupt_Handler (0, Bios_Core.Parse_Cmd'Access);
   Uart0.Init (19200);
   Interrupts.Global_Machine_Interrupt_Enable;
   Bios_Core.Show_Welcome;
   loop
      null;
   end loop;
end Bios;&lt;/code&gt;
    &lt;head rend="h1"&gt;Try It YourÂself #&lt;/head&gt;
    &lt;p&gt;I hope you found all this interÂestÂing. I skipped instalÂlaÂtion, build instrucÂtions for third-parÂty tools, and plumbÂing details, but youâll find everyÂthing you need in the reposÂiÂtoÂryââs README. If you have any quesÂtions or run into issues, donât hesÂiÂtate to reach out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45782348</guid><pubDate>Sat, 01 Nov 2025 15:21:00 +0000</pubDate></item><item><title>Data centers contribute to high prices as energy bills electrify local politics</title><link>https://www.wsj.com/economy/consumers/surging-power-costs-are-putting-the-squeeze-on-customers-f8b2c04b</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45782865</guid><pubDate>Sat, 01 Nov 2025 16:16:53 +0000</pubDate></item><item><title>GHC now runs in the browser</title><link>https://discourse.haskell.org/t/ghc-now-runs-in-your-browser/13169</link><description>&lt;doc fingerprint="4f3a90df9d363b44"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;ghc itself can now run purely client-side in the browser, here’s a haskell playground demo. terms and conditions apply, and i’ll write up more detailed explanation some time later, but i thought this is a cool thing to show off how far the ghc wasm backend has advanced &lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 78 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;jaror
2&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;This is very cool! I wonder how easy it would be to load some packages; cabal in the browser when? I’m also wondering how usable Agda in the browser would be.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 3 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;jaror
3&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;I think I found a bug: ghc options persist even after I change them. Edit: this has been fixed!&lt;/p&gt;
        &lt;p&gt;Also &lt;code&gt;-with-rtsopts=-s&lt;/code&gt; does not work, sadly. Edit: Ah, that’s because it is interpreted.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 3 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;ad-si
4&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;This is awesome!&lt;lb/&gt; Perfect for building a fully interactive Haskell online course! &lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Excellent work - the efforts to bring Haskell to WASM are a huge boon to our ecosystem and userbase!&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Can’t run it on my tablet (wasm), curious: is this running the type checker or also code gen to wasm?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;jaror
8&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;It runs the code, but it seems like it uses the bytecode interpreter.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;What modifications were to GHC for it to be compiled to WASM?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;cabal won’t work in the browser due to lack of process support; but it’s possible to use &lt;code&gt;wasm32-wasi-cabal&lt;/code&gt; to precompile some third party packages to wasm and make this playground support them as well.&lt;/p&gt;
        &lt;p&gt;you might be interested to check GitHub - agda-web/agda-wasm-dist: Distributions of Agda executable compiled into WebAssembly.; afaik they even compiled GitHub - agda/agda-language-server: Language Server for Agda to wasm, not sure how usable it is currently&lt;/p&gt;
        &lt;p&gt;thanks for the report! i pushed an update which should have fixed it.&lt;/p&gt;
        &lt;p&gt;that’s right; ghc in browser can’t invoke the c compiler and it can only interpret haskell modules via bytecode.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;thanks for the reports! a few seconds of freeze during start-time is expected, since it needs to download ~50M of a rootfs tarball and extract it, then link the ghc library and all its dependencies. as for safari, it’s strange since i i just landed a workaround for a webkit bug that breaks the wasm dynamic linker a few days ago, i’ll take a closer look later.&lt;/p&gt;
        &lt;p&gt;the ghc library already mostly works when compiled to wasm, and it can parse/typecheck/desugar stuff. the bottleneck is the linker/loader part, for it to be useful it needs to be able to dynamically load and execute haskell code. i landed a couple of ghc patches recently to push towards that direction, and the last one that gets us towards the haskell playground (not landed yet) is Draft: Support running GHC fully client-side in the browser (!15000) · Merge requests · Glasgow Haskell Compiler / GHC · GitLab&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 8 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Which packages are installed by default?&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;now chrome will consume even more memory &lt;/p&gt;
        &lt;p&gt;Awesome work!&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 2 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;the &lt;code&gt;ghc&lt;/code&gt; library and its transitive dependencies.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;jarm
15&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Can you elaborate? Do you have any end-to-end examples/instructions for this?&lt;/p&gt;
        &lt;p&gt;I am a live coding musician and have been trying to get Tidal running on the web for years: tidal: Pattern language for improvised music&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;see also:&lt;/p&gt;
        &lt;p&gt; which I presume isn’t wasm&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45782981</guid><pubDate>Sat, 01 Nov 2025 16:29:23 +0000</pubDate></item><item><title>Chat Control proposal fails again after public opposition</title><link>https://andreafortuna.org/2025/11/01/chat-control-proposal-fails-again-after-massive-public-opposition/</link><description>&lt;doc fingerprint="b70c19598a0da651"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Chat control proposal fails again after massive public opposition&lt;/head&gt;
    &lt;p&gt;The European Union Council has once again retreated from its controversial Chat Control proposal, a plan that would have required widespread scanning of encrypted messages. The withdrawal by the current Danish presidency represents yet another chapter in a long-running battle between privacy advocates and lawmakers who believe they can compromise encryption in the name of public safety. While this latest defeat is a victory for digital rights, the fight is far from over, and the fundamental misunderstanding of encryption technology continues to plague policy discussions across Europe.&lt;/p&gt;
    &lt;head rend="h2"&gt;A zombie proposal that refuses to die&lt;/head&gt;
    &lt;p&gt;Since its introduction in 2022, Chat Control has become what privacy advocates call a zombie proposal, repeatedly resurrected despite consistent opposition from civil society, technical experts, and the public. The Electronic Frontier Foundation and more than 80 civil society organizations have strongly opposed the legislation, which would mandate client-side scanning of encrypted communications under the guise of combating child sexual abuse material.&lt;/p&gt;
    &lt;p&gt;The pattern has become predictable. EU lawmakers introduce the proposal, claiming it includes safeguards for privacy. Technical experts explain why those safeguards are illusory. Public pressure mounts. The proposal is withdrawn or modified. Then, after a brief hiatus, it returns with minor tweaks, and the cycle begins anew. This latest withdrawal by the Danish presidency follows the same script, but the underlying issues remain unresolved.&lt;/p&gt;
    &lt;p&gt;What makes this particularly frustrating is that the fundamental problem with Chat Control has never been addressed. The proposal seeks to create what privacy experts call a “backdoor” into encryption, allowing authorities to scan messages before they’re encrypted or after they’re decrypted. Proponents argue this preserves encryption while enabling content moderation, but this reveals a dangerous misunderstanding of how encryption actually works. Creating any mechanism to access encrypted content inherently weakens the entire system, making it vulnerable not just to authorized access but to malicious actors as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;The technical impossibility of “safe” scanning&lt;/head&gt;
    &lt;p&gt;The core issue with Chat Control and similar proposals lies in a fundamental misunderstanding of encryption technology. End-to-end encryption works because only the sender and recipient possess the keys to decrypt messages. Any third party, whether a government agency or a tech company, cannot read the contents. This is not a design choice but a mathematical certainty that ensures the security of billions of communications daily.&lt;/p&gt;
    &lt;p&gt;Client-side scanning, the technical approach favored by Chat Control advocates, attempts to circumvent this limitation by analyzing messages on users’ devices before encryption or after decryption. While this might sound like a clever workaround, it fundamentally breaks the security model of encryption. If a device can scan and report on message content, so can malware, hackers, or authoritarian governments who might compel tech companies to expand the scope of scanning.&lt;/p&gt;
    &lt;p&gt;Security researchers have repeatedly demonstrated that there is no way to create a scanning system that only works for “good guys.” Apple learned this lesson the hard way in 2021 when it proposed a similar system for detecting child abuse imagery in iCloud photos. The backlash from security experts was swift and devastating, forcing the company to abandon the plan. The same security vulnerabilities that would enable Chat Control would inevitably be exploited by malicious actors, putting everyone at greater risk.&lt;/p&gt;
    &lt;p&gt;Moreover, the scope creep inherent in surveillance technologies is well documented. A system initially designed to detect illegal content could easily be expanded to monitor political dissent, religious expression, or any other communication governments deem problematic. Countries around the world are watching the EU’s actions closely. If Chat Control were to pass, it would set a dangerous precedent that authoritarian regimes would eagerly exploit, claiming they’re simply following Europe’s lead in implementing “reasonable” content moderation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Public pressure and the power of resistance&lt;/head&gt;
    &lt;p&gt;The withdrawal of Chat Control demonstrates the critical importance of sustained public engagement in technology policy. Unlike previous instances where technical proposals sailed through legislative processes with little public awareness, this fight has been characterized by unprecedented mobilization from civil society organizations, technology companies, security researchers, and ordinary citizens concerned about their digital rights.&lt;/p&gt;
    &lt;p&gt;Organizations like the Electronic Frontier Foundation, European Digital Rights, and numerous national privacy advocacy groups have played a crucial role in educating the public about the risks of Chat Control. Their efforts have included detailed technical explanations, legal analysis, and coordination of opposition campaigns that have reached millions of Europeans. This groundswell of opposition has made it politically toxic for lawmakers to support the proposal, at least in its current form.&lt;/p&gt;
    &lt;p&gt;The effectiveness of this resistance offers important lessons for future policy battles. First, technical expertise matters. When security researchers speak with a unified voice about the impossibility of safe backdoors, it becomes harder for politicians to dismiss concerns as alarmist. Second, coalition-building across different sectors strengthens opposition. When civil liberties groups, tech companies, and individual users all oppose a policy, it suggests the problems are real and widespread. Third, sustained pressure is essential because, as Chat Control demonstrates, bad proposals rarely die on the first attempt.&lt;/p&gt;
    &lt;p&gt;However, this victory should be tempered with realism. The forces pushing for Chat Control have not given up, and the underlying political dynamics that gave rise to the proposal remain unchanged. Politicians face genuine pressure to be seen as “doing something” about online harms, particularly regarding child safety. Until alternative approaches that don’t compromise encryption gain political traction, proposals like Chat Control will continue to resurface.&lt;/p&gt;
    &lt;head rend="h2"&gt;The path forward requires education and alternatives&lt;/head&gt;
    &lt;p&gt;The repeated resurrection of Chat Control points to a deeper problem in how technology policy is made. Many lawmakers genuinely believe they can have both strong encryption and government access to encrypted content. This belief persists despite unanimous opposition from the cryptographic community because the political incentives favor appearing tough on crime over understanding complex technical realities.&lt;/p&gt;
    &lt;p&gt;Breaking this cycle requires a fundamental shift in how we approach online safety. Rather than seeking technological magic bullets that promise security without trade-offs, policymakers need to invest in solutions that actually work. This includes better funding for law enforcement training and tools that don’t require breaking encryption, improved international cooperation on criminal investigations, and addressing the root causes of online exploitation through social programs and education.&lt;/p&gt;
    &lt;p&gt;Technology companies also bear responsibility for developing and promoting genuinely privacy-preserving safety features. End-to-end encrypted platforms can implement abuse prevention measures that don’t involve content scanning, such as metadata analysis, user reporting systems, and account-level restrictions for suspicious behavior. While these approaches may be less comprehensive than mass surveillance, they achieve meaningful safety improvements without the catastrophic privacy trade-offs of backdoors.&lt;/p&gt;
    &lt;p&gt;Looking ahead, the privacy community cannot simply celebrate the withdrawal of Chat Control and move on. The next presidency of the EU Council will bring new opportunities for the proposal to resurface in yet another modified form. Sustained vigilance, continued public education, and proactive development of alternative safety measures will be essential. The fight to protect encryption is not a single battle but an ongoing campaign that requires long-term commitment from everyone who values digital privacy and security.&lt;/p&gt;
    &lt;p&gt;The withdrawal of Chat Control is a victory, but it’s a temporary one. The fundamental challenge remains: convincing policymakers that some trade-offs are not worth making, and that breaking encryption to combat illegal content creates far more problems than it solves. Until that message truly sinks in, the zombie proposal will keep rising from the grave, and the privacy community must remain ready to defeat it again and again.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45783114</guid><pubDate>Sat, 01 Nov 2025 16:42:57 +0000</pubDate></item><item><title>Studies increasingly find links between air pollutants and dementia</title><link>https://www.nytimes.com/2025/11/01/health/alzheimers-dementia-air-pollution.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45783206</guid><pubDate>Sat, 01 Nov 2025 16:54:45 +0000</pubDate></item><item><title>Ask HN: Where to begin with "modern" Emacs?</title><link>https://news.ycombinator.com/item?id=45783376</link><description>&lt;doc fingerprint="96f57412fcf5af17"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Hi all,&lt;/p&gt;
      &lt;p&gt;I’m a longtime Neovim user who’s been EMacs-curious. The hold up for me has been that I’ve been unable to find a source of truth for what’s top-of-the-line as far as plugins are. With Neovim, it’s a safe bet to look at what folks like Folke are doing, but I have struggled to find a similar figure in the Emacs community who gives insight into what’s-what. I know Doom exists, but I want to fully “own” my config and not over complicate it.&lt;/p&gt;
      &lt;p&gt;Thanks!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45783376</guid><pubDate>Sat, 01 Nov 2025 17:13:04 +0000</pubDate></item><item><title>Self-help gets philosophical</title><link>https://www.thedriftmag.com/how-i-learned-to-stop-worrying-and-love-my-shitty-life/</link><description>&lt;doc fingerprint="2ea193558c771601"&gt;
  &lt;main&gt;
    &lt;p&gt;Donald Trump’s endeavors in business and politics frequently overshadow his contributions as a philosopher of the futility of human achievement. “We’re here and we live our sixty, seventy, or eighty years and we’re gone,” he reflected to Playboy in a 1990 interview. “You win, you win, and in the end, it doesn’t mean a hell of a lot.” Subsequent winning does not seem to have shaken this conviction. “Nothing matters,” he informed Larry King in 2004. “You do shows, you do this, you do that, and then you have earthquakes in India where 400,000 people get killed. Honestly, it doesn’t matter.” Apparently catching a brief glimpse of the abyss during the 2020 campaign cycle, Trump expressed his wish to “hop into” one of his supporters’ trucks “and drive it away.” As he mused, “I’d love to do it. Just drive the hell outta here. Just get the hell out of this.”&lt;/p&gt;
    &lt;p&gt;Who among us has not daydreamed, now and again, about leaving it all behind? The anesthetizing pleasures of disengagement seem especially seductive these days — thanks, in no small part, to Trump himself. In the decade since his reinvention as a political juggernaut, the idea that nothing matters has gained significant purchase, often in response to the endless chaos of which he is both cause and symptom. As a wide range of social scientists, pollsters, and trendspotters have observed, a sense of fatalism has increasingly suffused the attitudes of many millennials and zoomers. (“Get in, loser,” Cosmopolitan invited readers in 2024. “We’re heading into the void!”) The most straightforward way to cope with hopelessness is to tell yourself that hope was a mistake in the first place. In his 2019 book Everything Is Fucked, the sequel to his 2016 bestseller The Subtle Art of Not Giving a Fuck, the self-help guru Mark Manson puts the point with characteristic economy of expression: “Hope Is Fucked.”&lt;/p&gt;
    &lt;p&gt;Manson’s rise to airport bookstore superstardom, however, suggests that most people do not find the process of unburdening oneself of one’s fucks to come as naturally as it does for Trump. Many, in fact, find the task rather daunting. At first you may feel better about whatever’s crushing your spirits if you accept, as Manson urges, that “pain is the universal constant,” and that you will never get what you truly want out of life. It doesn’t really matter if things just keep sucking forever; it is only in hoping for something better that you set yourself up for disappointment and frustration. There, isn’t that a load off? Then you’ll be in the shower or trying to fall asleep and you’ll remember everything you’re giving up on, all the pain you’ll never escape, and your chest will tighten and your breath will quicken and you’ll thumb back through your copy of Mark Manson to remind yourself just how all of this is supposed to work.&lt;/p&gt;
    &lt;p&gt;If Manson’s tomes are too vulgar (in either sense) for your taste, fear not. An apparently inexhaustible supply of alternatives now fills the shelves — books that similarly promise to help you make your peace with the reality that disappointment, frustration, and agony are inexorable parts of life. “Although pain is inevitable, suffering is optional,” Joseph Nguyen tells readers in his best-selling Don’t Believe Everything You Think (2022). Professor and fitness influencer Michael Easter’s The Comfort Crisis (2021) explains that our lives are actually too easy, and we should be grateful for those challenges we haven’t yet managed to eliminate. Some of these books share with Manson’s not only a general outlook on life but also a sense of which words are funny. Sarah Knight’s Calm the Fuck Down (2018) explains, per its subtitle, “How to Control What You Can and Accept What You Can’t So You Can Stop Freaking Out and Get On With Your Life,” while Michael and Sarah Bennett’s Fuck Feelings (2015) promises, according to its promotional copy, to show readers how to “put aside your unrealistic wishes, stop trying to change things you can’t change, and do the best with what you can control.”&lt;/p&gt;
    &lt;p&gt;Readers who prefer their self-help to come with a sheen of erudition can increasingly count on finding similar wisdom about human finitude dispensed in the philosophy section. Turning to philosophy to learn how to live is nothing new, of course. But the explicitly inspirational and instructional valence of much that appears today under that heading, even from academic presses, is striking — as is the apparent consensus that the central task of philosophy is to guide seekers to a greater acceptance of imperfection and insignificance. Sometimes these books focus on a particular school of philosophy, giving readers an “-ism” — existentialism, Buddhism, Taoism, and above all Stoicism, now practically a genre unto itself — with which to identify. Others staple together eclectic smatterings of received ideas into less partisan surveys on how to cope with failure and disillusionment.&lt;/p&gt;
    &lt;p&gt;The self-help industry has in turn embraced this conception of “philosophy,” to the point where it’s no longer always clear whether to categorize a given book of advice as philosophy or self-help in the first place. In his author bio, Nguyen entices readers with the boast that he draws “inspiration from philosophy,” among other sources. In The Let Them Theory, the top-performing self-help book on Amazon as of this writing, the former attorney and current podcaster Mel Robbins explains that her program — a set of tools to free readers from the belief that “we can protect ourselves from pain, disappointment, rejection” — is “rooted in ancient philosophies and psychological concepts that have guided people for centuries,” including Stoicism and Buddhism. Oliver Burkeman, author of the newsletter “The Imperfectionist” and several books including the recent Meditations for Mortals (2024), similarly avers that “centuries of philosophical reflection” underpin his advice to renounce the quest for “dominance over a reality that can otherwise seem so unmanageable and overwhelming.” To be philosophical, apparently, is to accept our lot.&lt;/p&gt;
    &lt;p&gt;I get the appeal. Like most Americans, I’ve known the frustration and resentment that follow catechesis in the religion of self-fulfillment. I understand what it’s like to be told to look within yourself to find your destiny, your calling, your deepest desire, and to be assured that hard work and the right attitude can make it real: the excessive self-reverence, and then the inevitable self-recrimination. That there is now such a demand for books about the inevitability of failure and the wisdom of not giving a fuck suggests that many of us today suspect that our selfhood is a flimsy foundation on which to build a life, inadequate to the insuperable obstacles that prevent us from imposing our designs on the reality we inhabit. We’ve been tricked, or have tricked ourselves, into overestimating our own agency — and we hope a firm Stoic hand can smack us back into perspective. The “philosophy” packaged and sold to the reading public offers only a superficial correction, however. To imagine yourself as a modern-day Seneca, a sage liberated from the cares afflicting more ordinary souls, is its own form of self-indulgence. Renouncing the need to matter does not always draw you out of your own ego, but can leave you even further lost inside of it. Just ask the president.&lt;/p&gt;
    &lt;p&gt;Self-help philosophy often brands itself as an “antidote” — to quote the title of one of Burkeman’s early books — to the unrealistic expectations and toxic positivity that more mainstream self-help currents have inflicted on modern culture. The self-help philosophers are correct that the genre they’re invading has long been dominated by a rather outlandish sense of what one can accomplish through the exercise of individual freedom. In her classic 2009 work of cultural criticism Bright-sided, Barbara Ehrenreich argued that positive thinking, the idea that you should always expect the best and believe in your ability to achieve your dreams, had served since the nineteenth century as the official American ideology. There is plenty of evidence for this judgment on today’s best-seller lists. “The secret to getting results that last is to never stop making improvements,” James Clear writes in Atomic Habits, which has sold over 25 million copies worldwide since it was published in 2018. “It’s remarkable what you can build if you just don’t stop.” Books in this vein often rely on the language of either science, like Stanford psychologist Carol Dweck’s Mindset: The New Psychology of Success (2006), or evangelical Christianity, as in the work of megachurch pastor and Success Is a Choice (2020) author John C. Maxwell. By expressing faith in our ability to master our reality and overcome obstacles, these books are the present-day heirs to Norman Vincent Peale’s The Power of Positive Thinking, a 1952 bestseller that switched between Christian and pop-psych rhetorical modes. Peale’s book has spawned countless imitators since its initial publication. Notably, its author also presided over Trump’s first wedding and seems to have shaped the future president’s thinking, at least in those moments when he was not preoccupied with cosmic pointlessness.&lt;/p&gt;
    &lt;p&gt;Peale, in turn, drew on a set of spiritual beliefs and practices, known collectively as New Thought, that had been popular since the Gilded Age. New Thought — its most famous 21st-century articulation is The Secret, the 2006 manifesting manual touted by Oprah Winfrey — proceeds from the premise that material obstacles to human desires are basically illusory, the consequences of mental error. Through proper focus and prayer, New Thought claims, anyone can access a deep reservoir of divine creative energy and channel it to solve whatever difficulties they face, from physical illness to unemployment. As one New Thought tract published in 1903 puts it, conventional wisdom taught people how to get along “under the circumstances,” but it was high time that Americans started asking how to “get over the circumstances.”&lt;/p&gt;
    &lt;p&gt;But while New Thought and its descendants dominated the self-help publishing industry for much of the twentieth century, more accommodating attitudes toward “the circumstances” persisted elsewhere in American culture — a medley of spiritual practices and lifestyle trends that, in their vision of an inscrutable and ultimately unmasterable reality enveloping us all, can be understood as predecessors to today’s philosophical self-help. Exiled from Nazi Germany, the Frankfurt School theorist Theodor Adorno looked with dismay on what he saw as a surge of interest in 1940s America in the occult, from astrology to palm-reading. These, according to Adorno, were mechanisms for coping with a social world that appeared impervious to rational methods of control. “If, to the living, objective reality seems deaf as never before,” Adorno wrote, “they try to elicit meaning from it by saying abracadabra.” New Thought and related positive-thinking currents also taught readers to recite incantations; “every day, in every way, I am getting better and better,” one popular “affirmation” went. The purpose of midcentury occultism, however, was not to convince yourself that you were more in control than you might think. It was to discover that the world was ruled by forces more mysterious and powerful than you could have imagined: the planets, the spirits, the Jungian collective unconscious, the pilots of the flying saucers Americans suddenly began to spot everywhere starting in 1947. The best you could hope for was to learn how to play by their rules.&lt;/p&gt;
    &lt;p&gt;The feeling that the world was unresponsive and uncontrollable gained purchase as postwar America confronted the threats of environmental crisis, nuclear apocalypse, and, by the 1970s, economic stagnation. Many of the practices associated with the counterculture and the New Age movement, from homesteading and communal living to psychedelic drug use and free love, can be understood as attempts to refocus on the simple, immediate pleasures of life when faced with the transparent meaninglessness of traditional achievement: a spouse and kids, a white picket fence, a corner office. How could any of that stuff matter when the Cuyahoga River was on fire and the Bomb could go off any day? Herbert Marcuse (a former Frankfurt colleague of Adorno) argued in his 1964 book One-Dimensional Man that contemporary Americans seemed increasingly to embrace “spiritual, metaphysical, and bohemian” pursuits, exchanging ambitions of social transformation for the stylings of “Zen, existentialism, and beat ways of life, etc.” These attempts to find meaning or purpose in personal projects or private spiritual exercises were, Marcuse felt, “quickly digested by the status quo as part of its healthy diet.”&lt;/p&gt;
    &lt;p&gt;In the early days of the counterculture, the vogue for spiritual experimentation Marcuse identified spawned new publishing trends that blended self-help with philosophy. After toiling in relative obscurity for two decades, the self-styled “philosophical entertainer” Alan Watts broke into celebrity in the 1950s, selling countless copies of books that simultaneously introduced readers to East Asian philosophy and gave them practical advice on how to live. Robert Pirsig’s Zen and the Art of Motorcycle Maintenance (1974) and Benjamin Hoff’s The Tao of Pooh (1982) also staked out spots on best-seller lists by synthesizing “Eastern” and “Western” wisdom in ways that countless devotees found relevant to the challenges of ordinary life. Today, readers can still find Zen wisdom transposed into a secular philosophical key, especially in the best-selling books of the Korean monk Haemin Sunim (author of three of the top five entries on one online list of “The 10 Best Books on Secular Buddhism”). Dispensing a familiar message about the need for detachment and acceptance, Haemin will help you cultivate Love for Imperfect Things (2016) and learn what to do When Things Don’t Go Your Way (2024). “We are unhappy because we can’t find peace with what is,” Haemin explains. “We wish things to be different from what is happening at that moment.”&lt;/p&gt;
    &lt;p&gt;This advice, expressed in different registers and idioms, is at the heart of self-help philosophy, and the genre’s exponents are convinced it undermines fundamental convictions of the culture they’re addressing. The philosopher Costica Bradatan suggests that his paean In Praise of Failure “may seem surprising,” since “there seems to be nothing worse in our world than to fail” — although there is very little that will surprise the devoted self-help philosophy reader in Bradatan’s instruction “to see things as they are, as opposed to how we would like them to be.” In Meditations for Mortals, Burkeman quotes the German social theorist Hartmut Rosa to assail “the idea, the hope and desire, that we can make the world controllable” — allegedly “the driving cultural force of that form of life we call ‘modern.’” Burkeman explains that his brand of philosophical reflection can help us resist this ubiquitous impulse and embrace the fact that most things are beyond our command. “You needn’t reflect for long on the subject of human limitation,” he muses, “to see that the existence of problems simply follows, unavoidably, from the facts of finitude.” That is true, of course, which is why this insight is not nearly as disruptive to conventional wisdom as the self-help philosophers maintain. If all this advice really cuts against the grain of the modern world — a “World Striving for Perfection,” as the subtitle of Haemin’s Love for Imperfect Things puts it — the fact that, in various incarnations, it has proven so popular (and so lucrative) for so long is a bit of a puzzle. Perhaps it is less the “antidote” to the school of self-help that says you can do whatever you put your mind to and more its Janus face, gazing backwards with serenity at all the hopes our society has raised and crushed.&lt;/p&gt;
    &lt;p&gt;While the earliest antecedents of today’s self-help philosophy emphasized esoteric and “Eastern” wisdom, the doctrine that finally managed to create a full-fledged sub-industry in recent decades was Stoicism, a philosophical movement first popularized in ancient Greece in the third century B.C.E. that persisted throughout the first centuries of the Roman Empire. Ancient Stoics saw the universe as the embodiment of reason, or a fate-like “logos,” and devoted considerable effort to unraveling its principles. Fans today approach the school of thought primarily as “a framework for living our life in the best way possible,” as the popular Stoic expositor Massimo Pigliucci puts it; they are more interested in the pathway to happiness than in the various classes of logical propositions, the “connectives” that join them, and their assembly through syllogism into valid arguments. The cognitive practices pop-Stoicism recommends — “keeping in mind what is and what is not under our control, focusing our efforts on the former and not wasting them on the latter,” Piglicucci summarizes in How to Be a Stoic (2017) — act in accordance with the self-help philosophy genre’s fundamental dogma: we make ourselves miserable by worrying about stuff we can’t affect and that doesn’t really matter. Do what you believe is right, accept the outcome that fate has in store for you, and you can be happy — even in the direst circumstances.&lt;/p&gt;
    &lt;p&gt;As the journalist Hettie O’Brien observed in a perceptive 2020 piece on the attractiveness of the Stoic outlook in the depths of the Covid pandemic, discussion of the ancient philosophy ticked up in the 1980s and spiked in the 1990s, a decade frequently but misleadingly recalled as an era of complacent optimism. The end of history was, as Francis Fukuyama himself predicted, “a very sad time.” The loss of the systemic alternative represented by the Soviet Union and the triumph of capitalist globalization made the forces determining social reality feel even more impersonal than they had before. If some Silicon Valley Prometheans, striding atop the globe during the dot-com boom, felt godlike in their ability to manipulate the world, many Americans in the Clinton era felt at the mercy of fate, and found solace in the great ancient philosophy of amor fati (a phrase popularized by Friedrich Nietzsche but widely claimed by contemporary Stoic enthusiasts). Ross Perot’s 1992 running mate, Navy Vice Admiral James B. Stockdale, wrote a pamphlet in 1993 explaining how he used the teachings of the Greek Stoic philosopher Epictetus to reconcile himself to the inevitability of suffering, sickness, and death during his yearslong internment in a North Vietnamese prison. “It is impossible in such a body as ours, that is, in this universe that envelops us,” Stockdale quotes Epictetus as teaching, “that such things should not happen, some to one man, some to another.” The prior year, Bill Clinton told Garry Wills that besides the Bible, the book that had most influenced him was the Meditations of Marcus Aurelius, Roman emperor and Stoic luminary.&lt;/p&gt;
    &lt;p&gt;These days, if you were to query a politician or CEO at random, you’d have a decent shot at getting the same answer. Stoicism is inescapable, fueled in large part by the tireless propagandizing of Ryan Holiday, the former American Apparel marketing director. Holiday first dipped his toe into the Stoic business with his 2014 book The Obstacle Is the Way: The Timeless Art of Turning Trials into Triumph. In the aftermath of its success (especially in the world of professional sports), Holiday unleashed a torrent of follow-up books with titles similarly fond of predication: Ego Is the Enemy (2016), Stillness Is the Key (2019), and Discipline Is Destiny (2022), among others. He also launched a media empire that now includes a popular podcast and a YouTube channel under the “Daily Stoic” brand. Holiday has succeeded in making Stoicism so ubiquitous that purveyors of philosophical self-help today often seem required to take a position on it, either joining the bandwagon or attempting to carve out independent niches. Manson has complained on his blog about the perception that The Subtle Art of Not Giving a Fuck “is merely regurgitating Stoicism with a couple cool stories and F-bombs thrown in to spice things up,” when in reality he considers “Buddhism and Existentialism” to be his most important influences. He has, however, appeared on Holiday’s Daily Stoic podcast, to discuss “What You Should Actually Give a Fuck About.”&lt;/p&gt;
    &lt;p&gt;Critics have paid special attention to Holiday’s fans in Silicon Valley and in various online communities devoted to misogyny or racism or — usually — both. The classicist Donna Zuckerberg drew attention to this convergence in her 2018 book Not All Dead White Men, in which she argued that “the men of the manosphere have a deep fascination with Stoic philosophy.” Evidence of Stoicism’s popularity among right-wing extremists has only mounted since. The far-right influencer and alleged human trafficker Andrew Tate fashions himself a Stoic apostle; as he says in one video shared by the Instagram account @kngstoic, “you’re born to suffer, which ties back into my whole crypto project.” Holiday, for his part, has called Tate “repulsive” and suggested followers turn to Marcus Aurelius instead. Yet, as the classicist and Meditations translator Gregory Hays has noted, Stoicism thrived among elite Roman men, staunch believers in the necessity of social hierarchy, and when Holiday says things like “obeisance is the way forward,” it is not hard to imagine the dark places to which such maxims might lead.&lt;/p&gt;
    &lt;p&gt;Even so, the contemporary deployment of Stoicism is usually more banal than sinister. “The best revenge is to become unlike the one who did the injury,” Denzel Washington’s Macrinus quotes from the Meditations in 2024’s Gladiator II, addressing the philosopher-emperor’s secret grandson. Like many of the pearls of wisdom from the ancient masters strewn throughout the pop-Stoic corpus, the remark is so platitudinous that its primary effect is neither to enlighten nor to corrupt, but simply to bore. Anything can seem profound, however, if it is attributed to a certified Great Philosopher. “Of things some are in our power, and others are not,” explains an Epictetus maxim that can be found in nearly every contemporary treatise on Stoicism (if in different translations). In The Little Book of Stoicism (2019), Jonas Salzgeber quotes the same Greek sage on the implication of this observation: we should “make the best use of what is in our power, and take the rest as it happens.” Ah, okay. Such maxims litter the texts of the Stoic revival. The Dutch Olympic speed skater Mark Tuitert begins each chapter of his handbook The Stoic Mindset: Living the Ten Principles of Stoicism with a quotation from a thinker of yore, which previews the gold-medal guidance about to be dispensed. “Do not seek to have events happen as you wish, but wish them to happen as they do happen, and all will be well with you,” Epictetus tells us before the chapter “Accept Your Fate (And Love It).” It is, I suppose, strictly speaking accurate that if the approximately 8.6 million people who die each year due to a lack of access to quality healthcare were to wish their fate, their desires would not be frustrated, but tautological truth does not make for philosophical profundity.&lt;/p&gt;
    &lt;p&gt;There’s only so much of this you can take. The neo-Stoics, seemingly aware of that fact, have lately evinced some concern about readerly exhaustion. Donald J. Robertson, whose 2019 book How to Think Like a Roman Emperor explored the connections between Stoicism and the tenets of modern cognitive behavioral therapy, returned last year to hedge his bets with a new volume, How to Think Like Socrates. The book jacket christens the Athenian master “Godfather to the Stoics,” which is true insofar as Socrates could be considered the “godfather” to all subsequent Western philosophy. (One podcast on which Robertson appeared to promote the book also dubbed Plato’s teacher “The Godfather of Self-Help.”) If you enjoyed learning about the Stoics, why not go straight to the source? Robertson writes that CBT advocates celebrate Epictetus’s principle that “people are not upset by events but rather by their opinions about them.” But it turns out “the same idea can be found four centuries” earlier, “in the Socratic dialogues.” Robertson claims that by emphasizing the rational interrogation of our opinions about what befalls us, instead of providing a fix-all formula, his Socratic method actually offers “a critique of what self-help has become” — his own previous foray into the genre, presumably, excepted. No matter how many books the self-help philosophers pump out, no matter how many people subscribe to their podcasts or purchase flame-garnished medallions reading “Amor Fati” from the Daily Stoic store, the genre must always frame itself as subversive, dispensing the kind of challenging wisdom that only great souls can stomach.&lt;/p&gt;
    &lt;p&gt;If a tome published this January entitled Beyond Stoicism is any indication, the publishing industry will prove perfectly capable of recycling ancient philosophy into contemporary advice manuals even if the Stoicism bubble does burst. Cowritten by Pigliucci, New York City Stoics founder Gregory Lopez, and “The Stoic Mom” blogger Meredith Alexander Kunz, Beyond Stoicism assembles a team of Stoic all-stars to reassure readers that even if they don’t deem Stoicism congenial, they can still find solace in a grab bag of other ancient philosophies, such as skepticism, Epicureanism, and Neoplatonism. Despite their doctrinal differences, the authors explain, these creeds were all “articulated to help people cope with a world in turmoil and over which they had little, if any, control” — “much like our own turbulent times.” At last we have managed to reify not merely social reality but the act of philosophizing itself, treating it, like our uncontrollable world, as a thing: a coping tool you might select, like an ice cream flavor, according to your personal taste.&lt;/p&gt;
    &lt;p&gt;It would be unfair, however, to conflate the entire field of self-help philosophy with the vacuousness of pop-Stoicism. Since the momentous surge of consciousness-raising in the summer of 2020, which left a mark in publishing as in every other cultural industry, even some advocates of the Stoic revival have shown signs of metabolizing the political criticisms most commonly lobbed at it. In Reasons Not to Worry: How to Be Stoic in Chaotic Times (2022), the Australian writer Brigid Delaney confesses that, when she first began to read about the philosophy, she was concerned “that Stoicism’s emphasis on responsibility for one’s own character and acknowledgment of the ultimate smallness of our spheres of influence meant that social justice and agitation for societal change had no place for a practicing Stoic.” Delaney recounts how she eventually came to see Stoicism instead as an antidote to feelings of despair and frustration that, in her experience, made it more difficult to engage in political action. “You were more likely to be an effective agent of justice and change,” she writes, “if you channelled Stoic techniques, including controlling anger.” This is quite possibly true — activists who hulk out every time something doesn’t go their way are not long for the inevitably frustrating work of politics. Still, it is hard to imagine a successful organizer who never tries to change anything that initially seems outside their “sphere of influence.”&lt;/p&gt;
    &lt;p&gt;Some of the most thoughtful books at the intersection of philosophy and self-help deliver advice that the modern Stoics would also affirm — accept the limits of your control, moderate your expectations, question your assumptions about what really matters — while appealing to a litany of self-consciously left-wing, even revolutionary thinkers. The MIT philosopher Kieran Setiya invokes the heterodox Marxism of the Frankfurt School itself in his book Life Is Hard: How Philosophy Can Help Us Find Our Way (2022). Explaining the central insight of Adorno and his collaborators, Setiya writes that “ideology distorts our sense of what is humanly possible,” which he takes to mean that the attempt to “conceive an ideal world” to which we should aspire is a trap, drawing us ever further into ideology’s clutches. That is perhaps a reasonable gloss of the mercurial thinker in his most pessimistic moods, though not those in which he was able to insist that “if people want to persuade us that the conditional nature of man sets limits to utopia, this is simply untrue.” Drawing on his version of Adorno, Setiya argues that, instead of asking how we can build the perfect society, we ought to recognize that “there is value in a single step toward justice, and one step leads to another.” Setiya suggests that such an outlook might have been what Walter Benjamin had in mind in characterizing radical politics as pulling the “emergency brake” on the great train of history rather than riding it into a new era of progress.&lt;/p&gt;
    &lt;p&gt;In a similar vein, Avram Alpert argues in The Good-Enough Life (2022) that unlearning our expectations for “greatness” can help us resist the temptation of political overcommitment, which produces burned-out organizers and egotistical leaders. For Alpert, this is one of the chief lessons of the Black Freedom Movement, especially the unsung and disproportionately female cadres who did the unglamorous work of drawing ordinary people into the everyday activity of organization-building, while charismatic leaders like Martin Luther King, Jr. absorbed the media spotlight. Alpert also proposes that moderating our expectations for our own lives can help us overcome our socially ingrained deference to wealth and power. Manson’s injunction not to give a fuck is “pretty good advice,” in Alpert’s view, but he insists it must be accompanied by an appreciation for — and a commitment to change — the structural forces that “make following it so difficult.” Everyone deserves a minimal standard of material security precisely so they can “have more time and leisure to appreciate the ordinary, good-enough pleasures of existence” and relinquish the never-ending struggle for more.&lt;/p&gt;
    &lt;p&gt;The book in this genre that most forthrightly confronts its political risks is a slim volume called Anxiety, published in 2024 by Samir Chopra. The philosopher starts off on familiar footing by walking readers through the ways Buddhism, psychoanalysis, and existentialism — not Stoicism, although he approvingly cites its influence on CBT — treat the titular concept. In each case, he explains how the intellectual tradition in question considers anxiety to be an inescapable dimension of the human experience. According to Chopra, psychoanalysis, for example, teaches that our prospects of living comfortably with anxiety depend on “our ability to not expect” a “security” the world cannot “provide for us” — easy to say if you always know where your next meal is coming from. As I was nearing the end of the book, however, Chopra startled me by presenting, with considerable fidelity and sympathy, the political critique that Herbert Marcuse leveled at this whole line of thinking. “It would suit those in power,” Chopra writes, explicitly ventriloquizing Marcuse, “to know that those they have made anxious and fearful through their political and social arrangements are content to wallow in their anxiety and not take any action to reform the material conditions that brought it about.” Chopra urges readers to reflect on the entwinement in all our lives of ineliminable existential anxiety and distress caused by the structure of the society we inhabit. Socially manufactured anxiety, he argues, can and should be redressed. “Combating and confronting anxiety requires acceptance, activism, and contemplation,” Chopra avers, “an acute blend of which might be the salutary recipe for living with it.”&lt;/p&gt;
    &lt;p&gt;I think that’s right. The question, then, is what the proper blend looks like. I started reading all these books in early 2024, when I was wrapping up a book of my own that was in large part about the history of New Thought and the mainstream currents of American self-help it inspired. I thought it was interesting that a sudden rash of texts seemed to be positioning themselves, at least rhetorically, against positive thinking and our dominant ideology of success. I was also hoping, semi-secretly, that they’d save me. Every day I woke up in despair: at the never-ending extermination campaign in Gaza; at the slow-motion immolation of higher education, the industry to which I’d devoted my adult life; at the manifest absence of any force effectively resisting far-right authoritarianism in the United States and around the world. The books I read offered, if nothing else, proof that I was far from alone in feeling this way. Nearly all of them began with some recitation of the apparently insurmountable crises afflicting us today, even if their lists were not exactly the same as mine. And they reassured me that I didn’t need to feel the guilt that so often stalked my despair. “Be perfect, as your Father in heaven is perfect,” I learned from the Gospels during my Catholic upbringing. Here, instead, I read that giving up on perfection was a political obligation in its own right — the lesson, properly understood, of many of the thinkers I admired most.&lt;/p&gt;
    &lt;p&gt;At some point, however, I realized that I was spending more of my time thinking about my own despair than about the problems outside myself that were supposedly fueling it. And it seemed to me that a lot of people I knew were doing the same thing. So many conversations centered on how we were doing our best under difficult circumstances. Attendance at organizing meetings dwindled. My own attendance dwindled. Life is hard, we’d tell ourselves. Rest is resistance. While an exaggerated sense of our own importance is a recipe for both political and psychological disaster, it is also possible to overestimate our insignificance. Acceptance shades easily into excuse. With enough practice tolerating imperfection you can learn to forget what it is you’re failing to live up to. When those expectations include owning a vacation home or winning a Nobel Prize, letting go might be healthy — but doing so is tragic when they include stopping a genocide or ending homelessness. If that seems like an unreasonable standard to hold ourselves to, it is only because so few of us today have experienced the way that participating in the exercise of collective power can augment and extend our personal agency. When we are left to fend for ourselves, the conditions that shape our lives tend to feel alien and monolithic, forcing us to choose between the two polarities of self-help: the delusional optimism of positive thinking and the stoic acceptance taught by “philosophy.”&lt;/p&gt;
    &lt;p&gt;But preemptive surrender is no sign of wisdom. Any reality made by human beings can be remade by them. The price of this power is mutual obligation: we can never let ourselves off the hook. The things we can accomplish together are, by definition, within our sphere of control, even if we have to act through structures that are bigger than any of us alone to achieve them. As grating as it may be to admit, it turns out that some of those hoary positive-thinking cliches the philosophers rail against are true, as long as we stick to the first-person plural. We are responsible for how our lives unfold; we can do things that seem impossible. But for those of us living in the heart of the American empire, with our duly elected president marching our society gleefully into hell, this news is far from reassuring. What we do with our lives does matter — as much as anything possibly could. That should keep us up at night.&lt;/p&gt;
    &lt;p&gt;Erik Baker is a historian at Harvard University and the author of Make Your Own Job: How the Entrepreneurial Work Ethic Exhausted America. He is Senior Editor of The Drift.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45783440</guid><pubDate>Sat, 01 Nov 2025 17:21:08 +0000</pubDate></item><item><title>Show HN: Why write code if the LLM can just do the thing? (web app experiment)</title><link>https://github.com/samrolken/nokode</link><description>&lt;doc fingerprint="a15b850a73e66ead"&gt;
  &lt;main&gt;
    &lt;p&gt;A web server with no application logic. Just an LLM with three tools.&lt;/p&gt;
    &lt;p&gt;One day we won't need code. LLMs will output video at 120fps, sample inputs in realtime, and just... be our computers. No apps, no code, just intent and execution.&lt;/p&gt;
    &lt;p&gt;That's science fiction.&lt;/p&gt;
    &lt;p&gt;But I got curious: with a few hours this weekend and today's level of tech, how far can we get?&lt;/p&gt;
    &lt;p&gt;I expected this to fail spectacularly.&lt;/p&gt;
    &lt;p&gt;Everyone's focused on AI that writes code. You know the usual suspects, Claude Code, Cursor, Copilot, all that. But that felt like missing the bigger picture. So I built something to test a different question: what if you skip code generation entirely? A web server with zero application code. No routes, no controllers, no business logic. Just an HTTP server that asks an LLM "what should I do?" for every request.&lt;/p&gt;
    &lt;p&gt;The goal: prove how far away we really are from that future.&lt;/p&gt;
    &lt;p&gt;Contact manager. Basic CRUD: forms, database, list views, persistence.&lt;/p&gt;
    &lt;p&gt;Why? Because most software is just CRUD dressed up differently. If this works at all, it would be something.&lt;/p&gt;
    &lt;code&gt;// The entire backend
const result = await generateText({
  model,
  tools: {
    database,      // Run SQL queries
    webResponse,   // Return HTML/JSON
    updateMemory   // Save user feedback
  },
  prompt: `Handle this HTTP request: ${method} ${path}`,
});&lt;/code&gt;
    &lt;p&gt;Three tools:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;database&lt;/code&gt;- Execute SQL on SQLite. AI designs the schema.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;webResponse&lt;/code&gt;- Return any HTTP response. AI generates the HTML, JavaScript, JSON or whatever fits.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;updateMemory&lt;/code&gt;- Persist feedback to markdown. AI reads it on next request.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The AI infers what to return from the path alone. Hit &lt;code&gt;/contacts&lt;/code&gt; and you get an HTML page. Hit &lt;code&gt;/api/contacts&lt;/code&gt; and you get JSON:&lt;/p&gt;
    &lt;code&gt;// What the AI generates for /api/contacts
{
  "contacts": [
    { "id": 1, "name": "Alice", "email": "alice@example.com" },
    { "id": 2, "name": "Bob", "email": "bob@example.com" }
  ]
}&lt;/code&gt;
    &lt;p&gt;Every page has a feedback widget. Users type "make buttons bigger" or "use dark theme" and the AI implements it.&lt;/p&gt;
    &lt;p&gt;It works. That's annoying.&lt;/p&gt;
    &lt;p&gt;Every click or form submission took 30-60 seconds. Traditional web apps respond in 10-100 milliseconds. That's 300-6000x slower. Each request cost $0.01-0.05 in API tokens—100-1000x more expensive than traditional compute. The AI spent 75-85% of its time reasoning, forgot what UI it generated 5 seconds ago, and when it hallucinated broken SQL that was an immediate 500 error. Colors drifted between requests. Layouts changed. I tried prompt engineering tricks like "⚡ THINK QUICKLY" and it made things slower because the model spent more time reasoning about how to be fast.&lt;/p&gt;
    &lt;p&gt;But despite all that, forms actually submitted correctly. Data persisted across restarts. The UI was usable. APIs returned valid JSON. User feedback got implemented. The AI invented, without any examples, sensible database schemas with proper types and indexes, parameterized SQL queries that were safe from injection, REST-ish API conventions, responsive Bootstrap layouts, form validation, and error handling for edge cases. All emergent behavior from giving it three tools and a prompt.&lt;/p&gt;
    &lt;p&gt;So yes, the capability exists. The AI can handle application logic. It's just catastrophically slow, absurdly expensive, and has the memory of a goldfish.&lt;/p&gt;
    &lt;p&gt;The capability exists. The AI can handle application logic.&lt;/p&gt;
    &lt;p&gt;The problems are all performance: speed (300-6000x slower), cost (100-1000x more expensive), consistency (no design memory), reliability (hallucinations → errors).&lt;/p&gt;
    &lt;p&gt;But these feel like problems of degree, not kind:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inference: improving ~10x/year&lt;/item&gt;
      &lt;item&gt;Cost: heading toward zero&lt;/item&gt;
      &lt;item&gt;Context: growing (eventual design memory?)&lt;/item&gt;
      &lt;item&gt;Errors: dropping&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But the fact that I built a working CRUD app with zero application code, despite it being slow and expensive, suggests we might be closer to "AI just does the thing" than "AI helps write code."&lt;/p&gt;
    &lt;p&gt;In this project, what's left is infrastructure: HTTP setup, tool definitions, database connections. The application logic is gone. But the real vision? 120 inferences per second rendering displays with constant realtime input sampling. That becomes the computer. No HTTP servers, no databases, no infrastructure layer at all. Just intent and execution.&lt;/p&gt;
    &lt;p&gt;I think we don't realize how much code, as a thing, is mostly transitional.&lt;/p&gt;
    &lt;code&gt;npm install&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;.env&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-haiku-20240307&lt;/code&gt;
    &lt;code&gt;npm start&lt;/code&gt;
    &lt;p&gt;Visit &lt;code&gt;http://localhost:3001&lt;/code&gt;. First request: 30-60s.&lt;/p&gt;
    &lt;p&gt;What to try:&lt;/p&gt;
    &lt;p&gt;Check out &lt;code&gt;prompt.md&lt;/code&gt; and customize it. Change what app it builds, add features, modify the behavior. That's the whole interface.&lt;/p&gt;
    &lt;p&gt;Out of the box it builds a contact manager. But try:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/game&lt;/code&gt;- Maybe you get a game?&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/dashboard&lt;/code&gt;- Could be anything&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/api/stats&lt;/code&gt;- Might invent an API&lt;/item&gt;
      &lt;item&gt;Type feedback: "make this purple" or "add a search box"&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIT License&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45783640</guid><pubDate>Sat, 01 Nov 2025 17:45:18 +0000</pubDate></item><item><title>Visible from space, Sudan's bloodied sands expose a massacre of thousands</title><link>https://www.telegraph.co.uk/world-news/2025/10/28/sudan-bloodied-sands-massacre-thousands/</link><description>&lt;doc fingerprint="af14cd1f0e004f24"&gt;
  &lt;main&gt;
    &lt;p&gt;The hot sand around the Sudanese city of El Fasher is stained red with the blood of more than 2,000 massacred civilians.&lt;/p&gt;
    &lt;p&gt;The pools of blood are so thick, the piles of bodies so exposed, that the ethnic purge allegedly committed by Sudanese paramilitary rebels is visible from space.&lt;/p&gt;
    &lt;p&gt;Militia groups defending the city alongside the army alleged the Rapid Support Forces (RSF) rebel group “committed heinous crimes against innocent civilians” and said most of the dead were women, children and the elderly.&lt;/p&gt;
    &lt;p&gt;A video purported to show a child soldier murdering a grown man in cold blood. Another supposedly showed RSF fighters executing civilians moments after pretending to release them.&lt;/p&gt;
    &lt;p&gt;The total death toll could not immediately be confirmed, but satellite pictures taken after the city fell over the weekend following an 18-month siege showed evidence of mass killings.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45783699</guid><pubDate>Sat, 01 Nov 2025 17:50:38 +0000</pubDate></item><item><title>Reconfigurable Analog Computers</title><link>https://arxiv.org/abs/2510.25942</link><description>&lt;doc fingerprint="ed9e351ad4f580af"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Other Computer Science&lt;/head&gt;&lt;p&gt; [Submitted on 29 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Reconfigurable Analog Computers&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The Achilles heel of classic analog computers was the complex, error prone, and time consuming process of programming. This typically involved manually patching hundreds or even thousands of connections between individual computing elements as well as setting many precision 10-turn potentiometers manually, often taking hours, or even days. Albeit being simplified by means of removable patch panels, switching from one program to another still was time consuming and thus expensive. With digital computers about to hit physical boundaries with respect to energy consumption, clock frequency, and integration density, analog computers have gained a lot of interest as co-processors for certain application areas in recent years. This requires some means for automatic reconfiguration of these systems under control of an attached digital computer. The following sections give an overview of classic and modern approaches towards such autopatch systems.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45783835</guid><pubDate>Sat, 01 Nov 2025 18:03:56 +0000</pubDate></item><item><title>Claude Code Can Debug Low-Level Cryptography</title><link>https://words.filippo.io/claude-debugging/</link><description>&lt;doc fingerprint="c6650996270f1fd4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Claude Code Can Debug Low-level Cryptography&lt;/head&gt;
    &lt;p&gt;Over the past few days I wrote a new Go implementation of ML-DSA, a post-quantum signature algorithm specified by NIST last summer. I livecoded it all over four days, finishing it on Thursday evening. Except… Verify was always rejecting valid signatures.&lt;/p&gt;
    &lt;code&gt;$ bin/go test crypto/internal/fips140/mldsa
--- FAIL: TestVector (0.00s)
    mldsa_test.go:47: Verify: mldsa: invalid signature
    mldsa_test.go:84: Verify: mldsa: invalid signature
    mldsa_test.go:121: Verify: mldsa: invalid signature
FAIL
FAIL     crypto/internal/fips140/mldsa   2.142s
FAIL
&lt;/code&gt;
    &lt;p&gt;I was exhausted, so I tried debugging for half an hour and then gave up, with the intention of coming back to it the next day with a fresh mind.&lt;/p&gt;
    &lt;p&gt;On a whim, I figured I would let Claude Code take a shot while I read emails and resurfaced from hyperfocus. I mostly expected it to flail in some maybe-interesting way, or rule out some issues.&lt;/p&gt;
    &lt;p&gt;Instead, it rapidly figured out a fairly complex low-level bug in my implementation of a relatively novel cryptography algorithm. I am sharing this because it made me realize I still don’t have a good intuition for when to invoke AI tools, and because I think it’s a fantastic case study for anyone who’s still skeptical about their usefulness.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Full disclosure: Anthropic gave me a few months of Claude Max for free. They reached out one day and told me they were giving it away to some open source maintainers. Maybe it’s a ploy to get me hooked so I’ll pay for it when the free coupon expires. Maybe they hoped I’d write something like this. Maybe they are just nice. Anyway, they made no request or suggestion to write anything public about Claude Code. Now you know.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Finding the bug&lt;/head&gt;
    &lt;p&gt;I started Claude Code v2.0.28 with Opus 4.1 and no system prompts, and gave it the following prompt (typos included):&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I implemented ML-DSA in the Go standard library, and it all works except that verification always rejects the signatures. I know the signatures are right because they match the test vector.&lt;/p&gt;
      &lt;p&gt;YOu can run the tests with “bin/go test crypto/internal/fips140/mldsa”&lt;/p&gt;
      &lt;p&gt;You can find the code in src/crypto/internal/fips140/mldsa&lt;/p&gt;
      &lt;p&gt;Look for potential reasons the signatures don’t verify. ultrathink&lt;/p&gt;
      &lt;p&gt;I spot-checked and w1 is different from the signing one.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;To my surprise, it pinged me a few minutes later with a complete fix.&lt;/p&gt;
    &lt;p&gt;Maybe I shouldn’t be surprised! Maybe it would have been clear to anyone more familiar with AI tools that this was a good AI task: a well-scoped issue with failing tests. On the other hand, this is a low-level issue in a fresh implementation of a complex, relatively novel algorithm.&lt;/p&gt;
    &lt;p&gt;It figured out that I had merged &lt;code&gt;HighBits&lt;/code&gt; and &lt;code&gt;w1Encode&lt;/code&gt; into a single function for using it from Sign, and then reused it from Verify where &lt;code&gt;UseHint&lt;/code&gt; already produces the high bits, effectively taking the high bits of w1 twice in Verify.&lt;/p&gt;
    &lt;p&gt;Looking at the log, it loaded the implementation into the context and then immediately figured it out, without any exploratory tool use! After that it wrote itself a cute little test that reimplemented half of verification to confirm the hypothesis, wrote a mediocre fix, and checked the tests pass.&lt;/p&gt;
    &lt;p&gt;I threw the fix away and refactored &lt;code&gt;w1Encode&lt;/code&gt; to take high bits as input, and changed the type of the high bits, which is both clearer and saves a round-trip through Montgomery representation. Still, this 100% saved me a bunch of debugging time.&lt;/p&gt;
    &lt;head rend="h2"&gt;A second synthetic experiment&lt;/head&gt;
    &lt;p&gt;On Monday, I had also finished implementing signing with failing tests. There were two bugs, which I fixed in the following couple evenings.&lt;/p&gt;
    &lt;p&gt;The first one was due to somehow computing a couple hardcoded constants (1 and -1 in the Montgomery domain) wrong. It was very hard to find, requiring a lot of deep printfs and guesswork. Took me maybe an hour or two.&lt;/p&gt;
    &lt;p&gt;The second one was easier: a value that ends up encoded in the signature was too short (32 bits instead of 32 bytes). It was relatively easy to tell because only the first four bytes of the signature were the same, and then the signature lengths were different.&lt;/p&gt;
    &lt;p&gt;I figured these would be an interesting way to validate Claude’s ability to help find bugs in low-level cryptography code, so I checked out the old version of the change with the bugs (yay Jujutsu!) and kicked off a fresh Claude Code session with this prompt:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I am implementing ML-DSA in the Go standard library, and I just finished implementing signing, but running the tests against a known good test vector it looks like it goes into an infinite loop, probably because it always rejects in the Fiat-Shamir with Aborts loop.&lt;/p&gt;
      &lt;p&gt;You can run the tests with “bin/go test crypto/internal/fips140/mldsa”&lt;/p&gt;
      &lt;p&gt;You can find the code in src/crypto/internal/fips140/mldsa&lt;/p&gt;
      &lt;p&gt;Figure out why it loops forever, and get the tests to pass. ultrathink&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It spent some time doing printf debugging and chasing down incorrect values very similarly to how I did it, and then figured out and fixed the wrong constants. Took Claude definitely less than it took me. Impressive.&lt;/p&gt;
    &lt;p&gt;It gave up after fixing that bug even if the tests still failed, so I started a fresh session (on the assumption that the context on the wrong constants would do more harm than good investigating an independent bug), and gave it this prompt:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I am implementing ML-DSA in the Go standard library, and I just finished implementing signing, but running the tests against a known good test vector they don’t match.&lt;/p&gt;
      &lt;p&gt;You can run the tests with “bin/go test crypto/internal/fips140/mldsa”&lt;/p&gt;
      &lt;p&gt;You can find the code in src/crypto/internal/fips140/mldsa&lt;/p&gt;
      &lt;p&gt;Figure out what is going on. ultrathink&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It took a couple wrong paths, thought for quite a bit longer, and then found this one too. I honestly expected it to fail initially.&lt;/p&gt;
    &lt;p&gt;It’s interesting how Claude found the “easier” bug more difficult. My guess is that maybe the large random-looking outputs of the failing tests did not play well with its attention.&lt;/p&gt;
    &lt;p&gt;The fix it proposed was updating only the allocation’s length and not its capacity, but whatever, the point is finding the bug, and I’ll usually want to throw away the fix and rewrite it myself anyway.&lt;/p&gt;
    &lt;p&gt;Three out of three one-shot debugging hits with no help is extremely impressive. Importantly, there is no need to trust the LLM or review its output when its job is just saving me an hour or two by telling me where the bug is, for me to reason about it and fix it.&lt;/p&gt;
    &lt;p&gt;As ever, I wish we had better tooling for using LLMs which didn’t look like chat or autocomplete or “make me a PR.” For example, how nice would it be if every time tests fail, an LLM agent was kicked off with the task of figuring out why, and only notified us if it did before we fixed it?&lt;/p&gt;
    &lt;p&gt;For more low-level cryptography &lt;del&gt;bugs&lt;/del&gt; implementations, follow me on Bluesky at @filippo.abyssdomain.expert or on Mastodon at @filippo@abyssdomain.expert. I promise I almost never post about AI.&lt;/p&gt;
    &lt;head rend="h2"&gt;The picture&lt;/head&gt;
    &lt;p&gt;Enjoy the silliest floof. Surely this will help redeem me in the eyes of folks who consider AI less of a tool and more of something to be hated or loved.&lt;/p&gt;
    &lt;p&gt;My work is made possible by Geomys, an organization of professional Go maintainers, which is funded by Smallstep, Ava Labs, Teleport, Tailscale, and Sentry. Through our retainer contracts they ensure the sustainability and reliability of our open source maintenance work and get a direct line to my expertise and that of the other Geomys maintainers. (Learn more in the Geomys announcement.) Here are a few words from some of them!&lt;/p&gt;
    &lt;p&gt;Teleport — For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. Teleport Identity is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.&lt;/p&gt;
    &lt;p&gt;Ava Labs — We at Ava Labs, maintainer of AvalancheGo (the most widely used client for interacting with the Avalanche Network), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45784179</guid><pubDate>Sat, 01 Nov 2025 18:41:56 +0000</pubDate></item><item><title>Czech police forced to turn off facial recognition cameras at the Prague airport</title><link>https://edri.org/our-work/czech-police-forced-to-turn-off-facial-recognition-cameras-at-the-prague-airport-thanks-to-the-ai-act/</link><description>&lt;doc fingerprint="da899912115b0345"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Czech police forced to turn off facial recognition cameras at the Prague airport thanks to the AI Act&lt;/head&gt;
    &lt;p&gt;The shutdown of the facial recognition cameras at the Václav Havel Airport in Prague came after years of criticism from EDRi member IuRe. The legitimacy of the criticism was confirmed by the Czech Office for Personal Data Protection. However, the Czech police continue to systematically violate the law in further processing of biometric data.&lt;/p&gt;
    &lt;head rend="h3"&gt;Airport facial recognition system long criticised&lt;/head&gt;
    &lt;p&gt;The Czech Republic Police used a camera system with facial recognition capabilities at Václav Havel Airport in Prague from 2018, until it was shut down in August 2025. The system enabled real-time recognition of the faces of people passing through the airport. Their so-called bio-indexes, or, simply put, facial contours converted into numbers, were compared with a database of wanted or missing persons.&lt;/p&gt;
    &lt;p&gt;EDRi member IuRe drew attention to the situation back in 2021. At the time, IuRe lawyers argued that the processing of biometric data in Czechia is only possible on the basis of explicit permission granted by a special law. IuRe ultimately filed a complaint with the Czech Data Protection Authority (DPA), requesting an investigation. The result of the inspection, which IuRe requested in the summer of 2025 under the Freedom of Information Act, confirmed the suspicion of a violation of personal data protection legislation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Biometric surveillance ended thanks to the AI Act&lt;/head&gt;
    &lt;p&gt;Criticism of the facial recognition system only increased after the AI Act came into force because the law explicitly requires judicial approval for each use of such a system, which wasn’t provided for the airport.&lt;/p&gt;
    &lt;p&gt;Therefore, since the specific portion of the AI Act related to biometric surveillance came into force in February 2025, till the airport facial recognition systém was shut down in August 2025, the police’s use of this system was illegal. It was in operation despite the fact that the police had been repeatedly warned of its illegality and the media had also taken an interest in the matter.&lt;/p&gt;
    &lt;head rend="h3"&gt;Set clear boundaries for the police&lt;/head&gt;
    &lt;p&gt;The inspection by the Czech DPA took almost four years. During that time, no effective action was taken. However, the results are clear: police need to be given clear guidelines for processing biometric data, which should be enshrined in laws approved by elected representatives of the people and thus subject to public scrutiny. The current situation, apart from violating European legislation, creates a fertile ground for various forms of abuse of these technologies.&lt;/p&gt;
    &lt;head rend="h3"&gt;The police systematically violate laws when processing biometric data&lt;/head&gt;
    &lt;p&gt;The Czech police are also ignoring the law in the case of another biometric tool – Digital Personal Image Information System. This was also pointed out by IuRe and subsequently by the Czech DPA. The system works with a reference database of approximately 20 million photographs of all persons who have been issued identity cards or passports, and compares them with photographs of persons of unknown identity.&lt;/p&gt;
    &lt;p&gt;This makes it possible to trace their probable identity retrospectively. According to the police, the system is used, for example, to identify the deceased. However, the same system can also be concievably used to identify people participating in demonstrations.&lt;/p&gt;
    &lt;p&gt;The obvious systemic problems with the use of facial recognition tools by the police should therefore be a matter of concern for the new Czech Minister of the Interior, who should initiate a review of the legislation. The current national legislation does not comply with the European directive in terms of legal safeguards for the processing of biometric data.&lt;/p&gt;
    &lt;p&gt;IuRe will continue to monitor biometric surveillance in Czechia, thanks in part to financial support from the public received through their informational website about biometric surveillance called Czechia is not China. The website was created with the support of EDRi and was linked to a crowdfunding campaign.&lt;/p&gt;
    &lt;p&gt;Contribution by: EDRi member, Iuridicum Remedium (IuRe)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Big brother at the Prague airport. The state refuses to explain how the biometric camera system works&lt;/item&gt;
      &lt;item&gt;Czech police use facial recognition system, IuRe finds out details&lt;/item&gt;
      &lt;item&gt;Europol and biometric surveillance “won” the Czech Big Brother Awards&lt;/item&gt;
      &lt;item&gt;Biometric surveillance in the Czech Republic: the Ministry of the Interior is trying to circumvent the Artificial Intelligence Act&lt;/item&gt;
      &lt;item&gt;Avoiding regulation of biometric surveillance and loyalty applications: The 20th Big Brother Awards took place in the Czech Republic&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45784185</guid><pubDate>Sat, 01 Nov 2025 18:42:39 +0000</pubDate></item><item><title>Word2vec-style vector arithmetic on docs embeddings</title><link>https://technicalwriting.dev/embeddings/arithmetic/index.html</link><description>&lt;doc fingerprint="31113c6d4e027e9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;word2vec-style vector arithmetic on docs embeddings§&lt;/head&gt;
    &lt;p&gt;2025 October 29&lt;/p&gt;
    &lt;p&gt;word2vec popularized the idea of representing words as vectors where semantically similar words are positioned close to each other in the vector space. Nowadays these vectors are usually called embeddings.&lt;/p&gt;
    &lt;p&gt;A neat consequence of the word2vec approach is that adding and subtracting vectors produces semantically logical results. From Efficient Estimations of Word Representations in Vector Space (the word2vec paper):&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Using a word offset technique where simple algebraic operations are performed on the word vectors, it was shown for example that&lt;/p&gt;&lt;code&gt;vector("King")&lt;/code&gt;-&lt;code&gt;vector("Man")&lt;/code&gt;+&lt;code&gt;vector("Woman")&lt;/code&gt;results in a vector that is closest to the vector representation of the word&lt;code&gt;Queen&lt;/code&gt;.&lt;/quote&gt;
    &lt;p&gt;Does word2vec-style vector arithmetic work in technical writing contexts?&lt;/p&gt;
    &lt;head rend="h2"&gt;Experiments§&lt;/head&gt;
    &lt;p&gt;word2vec was published in 2013. Embedding models have come a long way since then. word2vec models could only operate on single words. A vector always represented a single word. Modern embedding models can operate on arbitrary text. A vector can now represent a word, paragraph, section, document, set of documents, etc.&lt;/p&gt;
    &lt;p&gt;My experiments follow the same basic pattern of &lt;code&gt;vector("King")&lt;/code&gt; -
&lt;code&gt;vector("Man")&lt;/code&gt; + &lt;code&gt;vector("Woman")&lt;/code&gt;, with one difference. The experiments
start out with a vector representing the full text of a document, not a
single-word vector.&lt;/p&gt;
    &lt;head rend="h3"&gt;Same topic, different domain§&lt;/head&gt;
    &lt;p&gt;This is the first experiment. Starting with the vector for the full text of Testing Your Database from the Supabase docs, subtract the vector for the word &lt;code&gt;supabase&lt;/code&gt;, and then add the vector for the word &lt;code&gt;angular&lt;/code&gt;. The
resultant vector should be semantically close to the concept of “testing in
Angular”.&lt;/p&gt;
    &lt;head rend="h3"&gt;Different topic, same domain§&lt;/head&gt;
    &lt;p&gt;This is the second experiment. Starting with the vector for the full text of Testing Your Database from the Supabase docs, subtract the vector for the word &lt;code&gt;testing&lt;/code&gt;, and then add the vector for the word &lt;code&gt;vectors&lt;/code&gt;. The
resultant vector should be semantically close to the concept of “vectors in
Supabase”.&lt;/p&gt;
    &lt;head rend="h2"&gt;Task types§&lt;/head&gt;
    &lt;p&gt;From previous research I’ve learned that task types noticeably affect Gemini Embedding’s outputs. EmbeddingGemma (the model I’ll be using in the experiments) also supports tasks types. I’ll run both experiments twice: once with default task types, and again with customized task types.&lt;/p&gt;
    &lt;head rend="h2"&gt;Verification§&lt;/head&gt;
    &lt;p&gt;There’s no way to directly verify that the resultant vectors are semantically close to the expected concepts. What I can do instead is generate vectors from the full texts of various docs, and then compare the resultant vectors from the experiments against the vectors of these various docs using cosine similarity.&lt;/p&gt;
    &lt;p&gt;Here’s the full list of docs that I use in the experiments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Background Processing Using Web Workers (Angular)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Refer To Locales By ID (Angular)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Testing (Angular)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Testing Services (Angular)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;LINESTRING (CockroachDB)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Test Your Application Locally (CockroachDB)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;analysis_test (Skylib)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;bzl_library (Skylib)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;diff_test (Skylib)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Actionability (Playwright)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;JUnit (Playwright)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Writing Tests (Playwright)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Branching (Supabase)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Testing Your Database (Supabase)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Testing Your Edge Functions (Supabase)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Vector Columns (Supabase)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For the Same topic, different domain experiment (Testing Your Database - &lt;code&gt;supabase&lt;/code&gt; + &lt;code&gt;angular&lt;/code&gt;) I expect the resultant vector to be most similar to
Testing or Testing Services from the Angular docs. And for the
Different topic, same domain experiment (Testing Your Database - &lt;code&gt;testing&lt;/code&gt; +
&lt;code&gt;vectors&lt;/code&gt;) I expect the resultant vector to be most similar to Vector
Columns from the Supabase docs.&lt;/p&gt;
    &lt;p&gt;Note that I picked short docs because EmbeddingGemma only supports 2048 tokens of input and I didn’t feel like dealing with chunking. Most of the docs revolve around testing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results§&lt;/head&gt;
    &lt;p&gt;In the Same topic, different domain experiment (Testing Your Database - &lt;code&gt;supabase&lt;/code&gt; + &lt;code&gt;angular&lt;/code&gt;) the resultant vector is most similar to Testing
and Testing Services from the Angular docs, as expected, when custom task
types are enabled:&lt;/p&gt;
    &lt;code&gt;[INFO] Running "same topic, different domain" experiment with customized task types
[INFO] Results:
[INFO] "Testing" (Angular) =&amp;gt; 0.751456081867218
[INFO] "Testing Services" (Angular) =&amp;gt; 0.6292878985404968
[INFO] "Background Processing Using Web Workers" (Angular) =&amp;gt; 0.5090276598930359
[INFO] "Testing Your Database" (Supabase) =&amp;gt; 0.5084458589553833
[INFO] "Refer To Locales By ID" (Angular) =&amp;gt; 0.46428176760673523
[INFO] "Test Your Application Locally" (CockroachDB) =&amp;gt; 0.4586600363254547
[INFO] "Writing Tests" (Playwright) =&amp;gt; 0.4434031546115875
[INFO] "JUnit" (Playwright) =&amp;gt; 0.4156876802444458
[INFO] "Actionability" (Playwright) =&amp;gt; 0.396766722202301
[INFO] "analysis_test" (Skylib) =&amp;gt; 0.3869394063949585
[INFO] "Testing Your Edge Functions" (Supabase) =&amp;gt; 0.368389755487442
[INFO] "diff_test" (Skylib) =&amp;gt; 0.3524951934814453
[INFO] "bzl_library" (Skylib) =&amp;gt; 0.29295891523361206
[INFO] "LINESTRING" (CockroachDB) =&amp;gt; 0.2778087854385376
[INFO] "Branching" (Supabase) =&amp;gt; 0.26931506395339966
[INFO] "Vector Columns" (Supabase) =&amp;gt; 0.23397961258888245
&lt;/code&gt;
    &lt;p&gt;When using the default task types, the resultant vector is most similar to Testing Your Database i.e. the doc that the experiment started with:&lt;/p&gt;
    &lt;code&gt;[INFO] Running "same topic, different domain" experiment with default task types
[INFO] Results:
[INFO] "Testing Your Database" (Supabase) =&amp;gt; 0.6590374708175659
[INFO] "Testing" (Angular) =&amp;gt; 0.571465790271759
[INFO] "Testing Services" (Angular) =&amp;gt; 0.46747612953186035
[INFO] "Test Your Application Locally" (CockroachDB) =&amp;gt; 0.43749818205833435
[INFO] "Testing Your Edge Functions" (Supabase) =&amp;gt; 0.4073418378829956
[INFO] "Writing Tests" (Playwright) =&amp;gt; 0.3561333119869232
[INFO] "Background Processing Using Web Workers" (Angular) =&amp;gt; 0.3353777527809143
[INFO] "Vector Columns" (Supabase) =&amp;gt; 0.3085843324661255
[INFO] "LINESTRING" (CockroachDB) =&amp;gt; 0.30450767278671265
[INFO] "Branching" (Supabase) =&amp;gt; 0.29775649309158325
[INFO] "analysis_test" (Skylib) =&amp;gt; 0.2946781814098358
[INFO] "Actionability" (Playwright) =&amp;gt; 0.2879413962364197
[INFO] "JUnit" (Playwright) =&amp;gt; 0.2845016121864319
[INFO] "Refer To Locales By ID" (Angular) =&amp;gt; 0.2824022173881531
[INFO] "diff_test" (Skylib) =&amp;gt; 0.26220911741256714
[INFO] "bzl_library" (Skylib) =&amp;gt; 0.2447129189968109
&lt;/code&gt;
    &lt;p&gt;In the Different topic, same domain experiment (Testing Your Database - &lt;code&gt;testing&lt;/code&gt; + &lt;code&gt;vectors&lt;/code&gt;) the resultant vector is most similar to
Vector Columns, regardless of whether default or custom task types were used.&lt;/p&gt;
    &lt;p&gt;Custom task types:&lt;/p&gt;
    &lt;code&gt;[INFO] Running "different topic, same domain" experiment with customized task types
[INFO] Results:
[INFO] "Vector Columns" (Supabase) =&amp;gt; 0.6380605697631836
[INFO] "Testing Your Database" (Supabase) =&amp;gt; 0.44831225275993347
[INFO] "LINESTRING" (CockroachDB) =&amp;gt; 0.32693782448768616
[INFO] "Background Processing Using Web Workers" (Angular) =&amp;gt; 0.2737721800804138
[INFO] "Testing Your Edge Functions" (Supabase) =&amp;gt; 0.25883781909942627
[INFO] "Branching" (Supabase) =&amp;gt; 0.2509428560733795
[INFO] "Refer To Locales By ID" (Angular) =&amp;gt; 0.2328835278749466
[INFO] "bzl_library" (Skylib) =&amp;gt; 0.2133977860212326
[INFO] "Test Your Application Locally" (CockroachDB) =&amp;gt; 0.20613139867782593
[INFO] "Testing" (Angular) =&amp;gt; 0.16262517869472504
[INFO] "Actionability" (Playwright) =&amp;gt; 0.14792931079864502
[INFO] "Writing Tests" (Playwright) =&amp;gt; 0.14344163239002228
[INFO] "Testing Services" (Angular) =&amp;gt; 0.13723336160182953
[INFO] "diff_test" (Skylib) =&amp;gt; 0.12111848592758179
[INFO] "JUnit" (Playwright) =&amp;gt; 0.11599748581647873
[INFO] "analysis_test" (Skylib) =&amp;gt; 0.0979730486869812
&lt;/code&gt;
    &lt;p&gt;Default task types:&lt;/p&gt;
    &lt;code&gt;[INFO] Running "different topic, same domain" experiment with default task types
[INFO] Results:
[INFO] "Vector Columns" (Supabase) =&amp;gt; 0.6698287129402161
[INFO] "Testing Your Database" (Supabase) =&amp;gt; 0.6086233854293823
[INFO] "Testing Your Edge Functions" (Supabase) =&amp;gt; 0.36533844470977783
[INFO] "LINESTRING" (CockroachDB) =&amp;gt; 0.34430524706840515
[INFO] "Branching" (Supabase) =&amp;gt; 0.3141021430492401
[INFO] "Test Your Application Locally" (CockroachDB) =&amp;gt; 0.29872700572013855
[INFO] "Background Processing Using Web Workers" (Angular) =&amp;gt; 0.28414368629455566
[INFO] "bzl_library" (Skylib) =&amp;gt; 0.26424312591552734
[INFO] "Refer To Locales By ID" (Angular) =&amp;gt; 0.2537899315357208
[INFO] "Testing" (Angular) =&amp;gt; 0.23542608320713043
[INFO] "Writing Tests" (Playwright) =&amp;gt; 0.22030793130397797
[INFO] "Testing Services" (Angular) =&amp;gt; 0.20675960183143616
[INFO] "Actionability" (Playwright) =&amp;gt; 0.1959698647260666
[INFO] "diff_test" (Skylib) =&amp;gt; 0.19095730781555176
[INFO] "JUnit" (Playwright) =&amp;gt; 0.1832783967256546
[INFO] "analysis_test" (Skylib) =&amp;gt; 0.15578024089336395
&lt;/code&gt;
    &lt;p&gt;So, yes, it seems like word2vec-style vector arithmetic can work in technical writing contexts. Make sure to set your task types correctly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion§&lt;/head&gt;
    &lt;p&gt;I still don’t really understand how it’s possible to semantically represent an entire document as a single vector, let alone how adding and subtracting single-word vectors from full-document vectors works.&lt;/p&gt;
    &lt;p&gt;How do we actually use this in technical writing workflows or documentation experiences? I’m not sure. I was just curious to learn whether or not it would work.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix§&lt;/head&gt;
    &lt;head rend="h3"&gt;Source code§&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;experiments.py&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;from json import load
from os import environ
from sys import exit

from requests import get
from sentence_transformers import SentenceTransformer


class Doc:

    def __init__(self, topic, domain, url, length, embedding):
        self.topic = topic
        self.domain = domain
        self.url = url
        self.length = length
        self.embedding = embedding
        self.similarity = None


def init_docs(model, task_types):
    with open("data.json", "r") as f:
        data = load(f)
    tokenizer = model.tokenizer
    docs = []
    max_length = tokenizer.model_max_length
    for item in data:
        url = item["url"]
        response = get(url)
        text = response.text
        length = len(tokenizer.encode(text))
        topic = item["topic"]
        domain = item["domain"]
        if length &amp;gt; max_length:
            exit(f"[ERROR] Document is too large: {topic}, {domain}")
        prompt = "title: {topic} | text: "
        embedding = model.encode(text, prompt=prompt) if task_types else model.encode(text)
        doc = Doc(topic, domain, url, length, embedding)
        docs.append(doc)
    return docs


def create_domain_query(model, task_types):
    url = "https://raw.githubusercontent.com/supabase/supabase/refs/heads/master/apps/docs/content/guides/database/testing.mdx"
    response = get(url)
    text = response.text
    if task_types:
        doc = model.encode(text, prompt_name="Retrieval-query")
        supabase = model.encode("supabase", prompt_name="Retrieval-query")
        angular = model.encode("angular", prompt_name="Retrieval-query")
    else:
        doc = model.encode(text)
        supabase = model.encode("supabase")
        angular = model.encode("angular")
    return doc - supabase + angular


def create_topic_query(model, task_types):
    url = "https://raw.githubusercontent.com/supabase/supabase/refs/heads/master/apps/docs/content/guides/database/testing.mdx"
    response = get(url)
    text = response.text
    if task_types:
        doc = model.encode(text, prompt_name="Retrieval-query")
        testing = model.encode("testing", prompt_name="Retrieval-query")
        vectors = model.encode("vectors", prompt_name="Retrieval-query")
    else:
        doc = model.encode(text)
        testing = model.encode("testing")
        vectors = model.encode("vectors")
    return doc - testing + vectors


def run_experiments():
    environ["TOKENIZERS_PARALLELISM"] = "false"
    model = SentenceTransformer("google/embeddinggemma-300m")
    for task_types in [True, False]:
        print(f'[INFO] Running "same topic, different domain" experiment with {"customized" if task_types else "default"} task types')
        docs = init_docs(model, task_types)
        query = create_domain_query(model, task_types)
        for doc in docs:
            similarity = model.similarity(query, doc.embedding).item()
            doc.similarity = similarity
        docs.sort(key=lambda doc: doc.similarity, reverse=True)
        print(f'[INFO] Results:')
        for doc in docs:
            print(f'[INFO] "{doc.topic}" ({doc.domain}) =&amp;gt; {doc.similarity}')
        print()
        print(f'[INFO] Running "different topic, same domain" experiment with {"customized" if task_types else "default"} task types')
        docs = init_docs(model, task_types)
        query = create_topic_query(model, task_types)
        for doc in docs:
            similarity = model.similarity(query, doc.embedding).item()
            doc.similarity = similarity
        docs.sort(key=lambda doc: doc.similarity, reverse=True)
        print(f'[INFO] Results:')
        for doc in docs:
            print(f'[INFO] "{doc.topic}" ({doc.domain}) =&amp;gt; {doc.similarity}')
        print()


if __name__ == "__main__":
    run_experiments()
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;data.json&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;[
  {
    "domain": "Angular",
    "topic": "Background Processing Using Web Workers",
    "url": "https://raw.githubusercontent.com/angular/angular/refs/heads/main/adev/src/content/ecosystem/web-workers.md" 
  },
  {
    "domain": "Angular",
    "topic": "Refer To Locales By ID",
    "url": "https://raw.githubusercontent.com/angular/angular/refs/heads/main/adev/src/content/guide/i18n/locale-id.md" 
  },
  {
    "domain": "Angular",
    "topic": "Testing",
    "url": "https://raw.githubusercontent.com/angular/angular/refs/heads/main/adev/src/content/guide/testing/overview.md" 
  },
  {
    "domain": "Angular",
    "topic": "Testing Services",
    "url": "https://raw.githubusercontent.com/angular/angular/refs/heads/main/adev/src/content/guide/testing/services.md" 
  },
  {
    "domain": "CockroachDB",
    "topic": "LINESTRING",
    "url": "https://raw.githubusercontent.com/cockroachdb/docs/refs/heads/main/src/current/v25.4/linestring.md" 
  },
  {
    "domain": "CockroachDB",
    "topic": "Test Your Application Locally",
    "url": "https://raw.githubusercontent.com/cockroachdb/docs/refs/heads/main/src/current/v25.4/local-testing.md" 
  },
  {
    "domain": "Skylib",
    "topic": "analysis_test",
    "url": "https://raw.githubusercontent.com/bazelbuild/bazel-skylib/refs/heads/main/docs/analysis_test_doc.md"
  },
  {
    "domain": "Skylib",
    "topic": "bzl_library",
    "url": "https://raw.githubusercontent.com/bazelbuild/bazel-skylib/refs/heads/main/docs/bzl_library.md"
  },
  {
    "domain": "Skylib",
    "topic": "diff_test",
    "url": "https://raw.githubusercontent.com/bazelbuild/bazel-skylib/refs/heads/main/docs/diff_test_doc.md"
  },
  {
    "domain": "Playwright",
    "topic": "Actionability",
    "url": "https://raw.githubusercontent.com/microsoft/playwright/refs/heads/main/docs/src/actionability.md"
  },
  {
    "domain": "Playwright",
    "topic": "JUnit",
    "url": "https://raw.githubusercontent.com/microsoft/playwright/refs/heads/main/docs/src/junit-java.md"
  },
  {
    "domain": "Playwright",
    "topic": "Writing Tests",
    "url": "https://raw.githubusercontent.com/microsoft/playwright/refs/heads/main/docs/src/writing-tests-java.md"
  },
  {
    "domain": "Supabase",
    "topic": "Branching",
    "url": "https://raw.githubusercontent.com/supabase/supabase/refs/heads/master/apps/docs/content/guides/deployment/branching.mdx"
  },
  {
    "domain": "Supabase",
    "topic": "Testing Your Database",
    "url": "https://raw.githubusercontent.com/supabase/supabase/refs/heads/master/apps/docs/content/guides/database/testing.mdx"
  },
  {
    "domain": "Supabase",
    "topic": "Testing Your Edge Functions",
    "url": "https://raw.githubusercontent.com/supabase/supabase/refs/heads/master/apps/docs/content/guides/functions/unit-test.mdx"
  },
  {
    "domain": "Supabase",
    "topic": "Vector Columns",
    "url": "https://raw.githubusercontent.com/supabase/supabase/refs/heads/master/apps/docs/content/guides/ai/vector-columns.mdx"
  }
]
&lt;/code&gt;
    &lt;p&gt;Note that I forgot to pin the URLs to specific commits. I.e. I used the &lt;code&gt;HEAD&lt;/code&gt; version of each URL. If you run the experiments a year or two from now
(October 2025), your cosine similarity scores will probably be different,
because the underlying text of the documents will probably have changed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45784455</guid><pubDate>Sat, 01 Nov 2025 19:14:58 +0000</pubDate></item><item><title>Beginner-friendly, unofficial documentation for Helix text editor</title><link>https://helix-editor.vercel.app/start-here/basics/</link><description>&lt;doc fingerprint="2e1d8a1e0335f69e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Basics&lt;/head&gt;
    &lt;p&gt;To get started check out the installation instructions in order to follow along with the tutorial.&lt;/p&gt;
    &lt;head rend="h3"&gt;Opening a file&lt;/head&gt;
    &lt;p&gt;Create a new text file and open it with Helix by running &lt;code&gt;hx file.txt&lt;/code&gt;. This is what you’ll see:&lt;/p&gt;
    &lt;quote&gt;1 ~ NOR file.txt 1 sel 1:1 Loaded 1 file.&lt;/quote&gt;
    &lt;p&gt;Notice the &lt;code&gt;NOR&lt;/code&gt; in the bottom-left corner, this indicates that you are currently in Normal mode. In this mode, typing letters like e and n won’t insert them as text, but rather have specific commands which we will explore later.&lt;/p&gt;
    &lt;p&gt;To actually insert some text, press i, which is the command to get into Insert mode, indicated by the &lt;code&gt;INS&lt;/code&gt; in the bottom-left corner. In this mode, the letters you type will be inserted directly into the document.&lt;/p&gt;
    &lt;p&gt;Try it out by writing &lt;code&gt;Hello helix!&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;1 Hello helix! ~ INS file.txt [+] 1 sel 1:13&lt;/quote&gt;
    &lt;p&gt;To get back into Normal mode press Esc. This will change the color of your cursor and you will see &lt;code&gt;NOR&lt;/code&gt; again, indicating that you are in normal mode now.&lt;/p&gt;
    &lt;head rend="h3"&gt;Movement&lt;/head&gt;
    &lt;p&gt;To move your cursor you could use arrow keys, both in Normal and Insert modes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;↑ move cursor up&lt;/item&gt;
      &lt;item&gt;↓ move cursor down&lt;/item&gt;
      &lt;item&gt;→ moves cursor right&lt;/item&gt;
      &lt;item&gt;← moves cursor left&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, this isn’t encouraged due to the fact that hand will be doing a lot of back-and-forth movement between the arrow keys and the keyboard.&lt;/p&gt;
    &lt;p&gt;Instead, it is recommended to rest your fingers on the “home row”, which is comprised of the row of keys &lt;code&gt;a s d f g h j k l&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Instead of stretching to reach the arrow keys, use normal mode and h, j, k and l to move your cursor:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;h: moves cursor 1 character to the left.&lt;/item&gt;
      &lt;item&gt;j: moves cursor 1 line above.&lt;/item&gt;
      &lt;item&gt;k: moves cursor 1 line below.&lt;/item&gt;
      &lt;item&gt;l: moves cursor 1 character to the right.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Try holding down h and l to move horizontally across the text you just wrote!&lt;/p&gt;
    &lt;head rend="h3"&gt;Paste&lt;/head&gt;
    &lt;p&gt;We only have one line of text, so let’s duplicate it several times. Type:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;x, which will select the entire line.&lt;/item&gt;
      &lt;item&gt;y, which will yank (copy) the selection to clipboard.&lt;/item&gt;
      &lt;item&gt;p, which will paste the contents of the selection after the cursor.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Spam p a few times to create several lines.&lt;/p&gt;
    &lt;quote&gt;1 Hello helix! 2 Hello helix! 3 Hello helix! 4 Hello helix! 5 Hello helix! ~ NOR file.txt [+] 1 sel 3:8&lt;/quote&gt;
    &lt;p&gt;Now you can try using the h, j, k and l motions to traverse the text!&lt;/p&gt;
    &lt;head rend="h3"&gt;Word-based Movement&lt;/head&gt;
    &lt;p&gt;Let’s say we want to replace one of the &lt;code&gt;helix&lt;/code&gt; words with &lt;code&gt;world&lt;/code&gt;. To do this, place your cursor on one of the h letters:&lt;/p&gt;
    &lt;quote&gt;1 Hello helix! 2 Hello helix! 3 Hello helix! 4 Hello helix! 5 Hello helix! ~ NOR file.txt [+] 1 sel 3:7&lt;/quote&gt;
    &lt;p&gt;e is a motion which moves to the end of the current word. Type e and it will move your cursor to the end of the &lt;code&gt;helix&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;It doesn’t just move your cursor there, though. The entire &lt;code&gt;helix&lt;/code&gt; word becomes highlighted:&lt;/p&gt;
    &lt;quote&gt;1 Hello helix! 2 Hello helix! 3 Hello helix! 4 Hello helix! 5 Hello helix! ~ NOR file.txt [+] 1 sel 3:11&lt;/quote&gt;
    &lt;p&gt;If we now press b, which moves to the beginning of the current word, it’ll move us back to where we just were.&lt;/p&gt;
    &lt;p&gt;Try this out a few times, press e and then b to select various sections of the text. If you want to remove your selection press ;.&lt;/p&gt;
    &lt;p&gt;Let’s highlight our &lt;code&gt;helix&lt;/code&gt; word again:&lt;/p&gt;
    &lt;quote&gt;1 Hello helix! 2 Hello helix! 3 Hello helix! 4 Hello helix! 5 Hello helix! ~ NOR file.txt [+] 1 sel 3:11&lt;/quote&gt;
    &lt;head rend="h3"&gt;Selection-first Approach&lt;/head&gt;
    &lt;p&gt;Helix’s philosophy is that each action will act on a selection.&lt;/p&gt;
    &lt;p&gt;Every time text is modified (an action), you will fully anticipate the result — because you can clearly see the area of text which is highlighted, and thus will be modified.&lt;/p&gt;
    &lt;p&gt;For example, we currently have the word &lt;code&gt;helix&lt;/code&gt; selected. To change it to &lt;code&gt;world&lt;/code&gt;, press c,&lt;/p&gt;
    &lt;quote&gt;1 Hello helix! 2 Hello helix! 3 Hello ! 4 Hello helix! 5 Hello helix! ~ INS file.txt [+] 1 sel 3:7&lt;/quote&gt;
    &lt;p&gt;c removes the contents of the current selection and places us in Insert mode, where you can then write your new word. Exit back to Normal mode by pressing esc.&lt;/p&gt;
    &lt;quote&gt;1 Hello helix! 2 Hello helix! 3 Hello world! 4 Hello helix! 5 Hello helix! ~ NOR file.txt [+] 1 sel 3:12&lt;/quote&gt;
    &lt;head rend="h3"&gt;Delete&lt;/head&gt;
    &lt;p&gt;The d command deletes the current selection and copies what has been deleted into a clipboard.&lt;/p&gt;
    &lt;p&gt;Let’s test it out by doing the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Select the line we just changed with x.&lt;/p&gt;
        &lt;quote&gt;1 Hello helix! 2 Hello helix! 3 Hello world! 4 Hello helix! 5 Hello helix! ~ NOR file.txt [+] 1 sel 3:13&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;d to delete this line.&lt;/p&gt;
        &lt;quote&gt;1 Hello helix! 2 Hello helix! 3 Hello helix! 4 Hello helix! ~ NOR file.txt [+] 1 sel 3:1&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Spam p a few times to create some duplicates.&lt;/p&gt;
        &lt;quote&gt;4 Hello world! 5 Hello world! 6 Hello world! 7 Hello helix! ~ NOR file.txt [+] 1 sel 6:13&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let’s remove all of our previous &lt;code&gt;Hello helix!&lt;/code&gt; by doing the following for each &lt;code&gt;Hello helix!&lt;/code&gt; line:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Select the line with x.&lt;/item&gt;
      &lt;item&gt;d to delete it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now we have something like this:&lt;/p&gt;
    &lt;quote&gt;1 Hello world! 2 Hello world! 3 Hello world! ~ NOR file.txt [+] 1 sel 2:1&lt;/quote&gt;
    &lt;head rend="h3"&gt;Undo and Redo&lt;/head&gt;
    &lt;p&gt;What if we made a mistake, and want to go back? The u command will undo our most recent action. It’s similar to Ctrl + z in other editors.&lt;/p&gt;
    &lt;p&gt;Try pressing down u a few times to get to our previous state, before we made all those modifications:&lt;/p&gt;
    &lt;quote&gt;3 Hello helix! 4 Hello world! 5 Hello world! 6 Hello helix! ~ NOR file.txt [+] 1 sel 5:13&lt;/quote&gt;
    &lt;p&gt;U is similar to Ctrl + Shift + z in other editors. It will undo the last undo. It’s the inverse of u.&lt;/p&gt;
    &lt;p&gt;Press U until we get back to our most recent state:&lt;/p&gt;
    &lt;quote&gt;1 Hello world! 2 Hello world! 3 Hello world! ~ NOR file.txt [+] 1 sel 1:1 Already at newest change&lt;/quote&gt;
    &lt;head rend="h3"&gt;Checkpoint&lt;/head&gt;
    &lt;p&gt;Feel free to make modifications to your file using the commands we have learned so far:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;h, j, k and l moves 1 character left, down, up and right.&lt;/item&gt;
      &lt;item&gt;i enters Insert mode.&lt;/item&gt;
      &lt;item&gt;esc enters Normal mode.&lt;/item&gt;
      &lt;item&gt;x selects the entire line.&lt;/item&gt;
      &lt;item&gt;y yanks the selection.&lt;/item&gt;
      &lt;item&gt;p pastes the recently copied selection.&lt;/item&gt;
      &lt;item&gt;e selects and moves to the end of the current word.&lt;/item&gt;
      &lt;item&gt;b selects and moves to the beginning of the current word.&lt;/item&gt;
      &lt;item&gt;; removes the extra selection.&lt;/item&gt;
      &lt;item&gt;d deletes the current selection, without exiting Normal mode.&lt;/item&gt;
      &lt;item&gt;c changes the current selection, by deleting it and entering Insert mode.&lt;/item&gt;
      &lt;item&gt;u will undo the most recent change.&lt;/item&gt;
      &lt;item&gt;U will undo the most recent undo.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once you are happy with your modifications, enter Normal mode and type :.&lt;/p&gt;
    &lt;p&gt;: enters command mode, which has commands you type out.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;:w&lt;/code&gt;will write the current file.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;:q&lt;/code&gt;will quit the current file.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;:q!&lt;/code&gt;will quit without saving.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;:wq&lt;/code&gt;will both write and quit.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;┌──────────────────────────────┐ │ Write changes to disk and │ │ close the current view. │ │ Accepts an optional path │ └──────────────────────────────┘ write-quit-all write-quit-all! :wq&lt;/quote&gt;
    &lt;head rend="h2"&gt;More Commands&lt;/head&gt;
    &lt;p&gt;Let’s try out more Helix commands! Open the file again with &lt;code&gt;hx file.txt&lt;/code&gt;. Select the entire file by pressing %&lt;/p&gt;
    &lt;quote&gt;1 Hello world! 2 Hello world! 3 Hello world! ~ NOR file.txt [+] 1 sel 3:13&lt;/quote&gt;
    &lt;p&gt;Now, delete the selection with d.&lt;/p&gt;
    &lt;quote&gt;~ NOR file.txt [+] 1 sel 1:1&lt;/quote&gt;
    &lt;head rend="h3"&gt;Goto Word&lt;/head&gt;
    &lt;p&gt;Using b to go to the beginning of the word and e to go to the end is useful if you are already at the word you want. But if you are far away, a very powerful command is goto word — gw.&lt;/p&gt;
    &lt;quote&gt;1 aue atates asll 2 ard ape anouds alll 3 aje ahn afll 4 add abe clouds aall 5 acd aee agon aill 6 akd ame aoon aqll NOR file.txt [+] 1 sel 4:13 gw&lt;/quote&gt;
    &lt;p&gt;gw will create two letters at the start of every word in sight. When you type those two letters, you instantly jump to the specified word.&lt;/p&gt;
    &lt;p&gt;Let’s say we want to jump to the &lt;code&gt;plates&lt;/code&gt; word. The first two characters have been replaced by &lt;code&gt;at&lt;/code&gt; and highlighted. If we write &lt;code&gt;at&lt;/code&gt;, we will highlight that word!&lt;/p&gt;
    &lt;quote&gt;1 The plates will 2 and the clouds will 3 The sun will 4 and the clouds will 5 and the moon will 6 and the moon will NOR file.txt [+] 1 sel 1:10&lt;/quote&gt;
    &lt;head rend="h3"&gt;Replace&lt;/head&gt;
    &lt;p&gt;You can also replace a selection with contents of a register.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Select the &lt;code&gt;moon&lt;/code&gt;word by using gw and yank it with y.&lt;/item&gt;
      &lt;item&gt;Select the &lt;code&gt;sun&lt;/code&gt;word and replace it with&lt;code&gt;moon&lt;/code&gt;with R.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Search&lt;/head&gt;
    &lt;p&gt;Go to the first line by using gg.&lt;/p&gt;
    &lt;p&gt;To search for a word, use / command. Type &lt;code&gt;will&lt;/code&gt; which is going to highlight the next &lt;code&gt;will&lt;/code&gt; keyword, and then Enter ↵ to select it.&lt;/p&gt;
    &lt;p&gt;Since there are several &lt;code&gt;will&lt;/code&gt;s in the text, you can cycle between them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;n cycles to the next match.&lt;/item&gt;
      &lt;item&gt;N cycles to the previous match.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;More ways to enter Insert Mode&lt;/head&gt;
    &lt;p&gt;Select the &lt;code&gt;clouds&lt;/code&gt; word using gw. If you press i, you will go into insert mode at the beginning of the selection. There are also 5 more ways to enter Insert mode:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a for append go into insert mode at the end of the selection&lt;/item&gt;
      &lt;item&gt;I go into insert mode at the beginning of the current line&lt;/item&gt;
      &lt;item&gt;A to append at the end of the current line&lt;/item&gt;
      &lt;item&gt;o add a newline below and go into insert mode&lt;/item&gt;
      &lt;item&gt;O add a newline above and go into insert mode&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Try all of them out!&lt;/p&gt;
    &lt;head rend="h3"&gt;Registers&lt;/head&gt;
    &lt;p&gt;Helix has a concept called registers, which is like having many clipboards at once.&lt;/p&gt;
    &lt;p&gt;To interact with them, prefix yank and delete commands with a ” and then the name of the register.&lt;/p&gt;
    &lt;p&gt;For example, the contents of the system clipboard are stored inside the &lt;code&gt;+&lt;/code&gt; register.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Paste the following content into the file with “+p:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Navigate to the last line by using ge for goto end.&lt;/p&gt;
        &lt;quote&gt;1 The plates will 2 and the clouds will 3 The sun will 4 and the moon will ~ NOR file.txt [+] 1 sel 4:2&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Select the last line with x and then yank it with y.&lt;/p&gt;
        &lt;quote&gt;1 The plates will 2 and the clouds will 3 The sun will 4 and the moon will ~ NOR file.txt [+] 1 sel 4:18 yanked 1 selection to register "&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Navigate to the second line by using 2gg.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Select the second line by using x and then yank into into the e register with “ey.&lt;/p&gt;
        &lt;quote&gt;1 The plates will 2 and the clouds will 3 The sun will 4 and the moon will ~ NOR file.txt [+] 1 sel 2:20 yanked 1 selection to register e&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Navigate to the third line by using 3gg.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Paste what we copied previously by using p.&lt;/p&gt;
        &lt;quote&gt;1 The plates will 2 and the clouds will 3 The sun will 4 and the moon will 5 and the moon will ~ NOR file.txt [+] 1 sel 4:18&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Notice how we haven’t pasted the 2nd line’s contents, but rather the last lines’? Because we yanked the 2nd line’s contents into the e register. To paste from it, use “ep.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;” signals to the editor that we are going to use a register.&lt;/item&gt;
      &lt;item&gt;e uses the e register.&lt;/item&gt;
      &lt;item&gt;p pastes contents of the e register.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;1 The plates will 2 and the clouds will 3 The sun will 4 and the moon will 5 and the clouds will 6 and the moon will NOR file.txt [+] 1 sel 5:20&lt;/quote&gt;
    &lt;p&gt;Take note of the fact that when we press p, it pastes the contents of the register after the line. To paste before, we undo with u and use P to paste before.&lt;/p&gt;
    &lt;quote&gt;1 The plates will 2 and the clouds will 3 The sun will 4 and the clouds will 5 and the moon will 6 and the moon will NOR file.txt [+] 1 sel 4:20&lt;/quote&gt;
    &lt;head rend="h3"&gt;Move to characters&lt;/head&gt;
    &lt;p&gt;You can also search for individual characters by using t, which stands for till.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Copy the text below&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Select the entire file with %&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Override the selection by using Space + R.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Go to the first line with gg and use t; to go to the next semicolon. Repeat this several several times.&lt;/p&gt;
    &lt;p&gt;To move in the opposite direction, use T; to the previous semicolon.&lt;/p&gt;
    &lt;p&gt;Using t and T motions will move your cursor to just before the next or the previous occurrence of the character.&lt;/p&gt;
    &lt;p&gt;For example, te to go to the next e. T” to go to just before the previous double-quote.&lt;/p&gt;
    &lt;p&gt;The f for find is similar to t, but instead it places your cursor at the occurrence of the character. Try using f; several times. F goes the opposite way.&lt;/p&gt;
    &lt;head rend="h3"&gt;Counts&lt;/head&gt;
    &lt;p&gt;Each motion also accepts an optional count, which defaults to 1 if you don’t provide it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For example, use 2f; which would be the same as f;f;.&lt;/item&gt;
      &lt;item&gt;Or 7b which would be the same as bbbbbbb.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Page Navigation&lt;/head&gt;
    &lt;p&gt;Currently the text is fairly short, but we can fix that. Select everything with %, yank y and then paste it 100 times with 100p. This will create a very big file.&lt;/p&gt;
    &lt;p&gt;We can use these commands to scroll large chunks of text at once:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ctrl + d to scroll down half a page&lt;/item&gt;
      &lt;item&gt;Ctrl + u to scroll up half a page&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Next steps&lt;/head&gt;
    &lt;p&gt;Now you know the basics of movement in Helix, it’s time to learn about the more advanced features Helix provides.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Explore advanced text manipulation techniques, such as surrounds and text objects.&lt;/item&gt;
      &lt;item&gt;Make full use of Helix’s powerful editing model by understanding how to use multiple cursor and macros&lt;/item&gt;
      &lt;item&gt;Learn how to enable language support and auto-formatters.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45784596</guid><pubDate>Sat, 01 Nov 2025 19:33:48 +0000</pubDate></item><item><title>Sanders: Government should break up OpenAI</title><link>https://thehill.com/policy/technology/5571789-ai-threatens-jobs-sanders-warns/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45784644</guid><pubDate>Sat, 01 Nov 2025 19:40:04 +0000</pubDate></item><item><title>From 400 Mbps to 1.7 Gbps: A WiFi 7 Debugging Journey</title><link>https://blog.tymscar.com/posts/wifi7speedhunt/</link><description>&lt;doc fingerprint="f6b23c642b0115b9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;From 400 Mbps to 1.7 Gbps: A WiFi 7 Debugging Journey&lt;/head&gt;
    &lt;p&gt;I recently upgraded from a UniFi Dream Machine to a UniFi Dream Router 7 because I’m getting 2.5 Gbps internet in two weeks and figured I’d jump on the WiFi 7 bandwagon while I’m at it. My iPhone 17 Pro Max supports it, so why not? After setting everything up, I was getting nowhere near the speeds I expected. Time for some debugging.&lt;/p&gt;
    &lt;head rend="h2"&gt;The disappointing numbers#&lt;/head&gt;
    &lt;p&gt;My wired connection was pulling 950 Mbps through a 1 Gbps switch, and iperf3 directly to the UDR7’s 2.5 Gbps port showed around 2.3 Gbps. The backbone was solid. But on WiFi 7 (6 GHz, 160 MHz width), standing literally a foot from the router, I was getting around 400 Mbps with iperf3. With 10 concurrent streams it went up to 650 Mbps, but that’s still pathetic.&lt;/p&gt;
    &lt;p&gt;A quick note on my testing: I was using iperf3’s &lt;code&gt;-R&lt;/code&gt; flag (reverse mode) which makes the server send data to the client instead of the other way around. This typically gives better results on WiFi since the AP has stronger transmit power than phones, and the phone only needs to send tiny ACKs back.&lt;/p&gt;
    &lt;p&gt;Meanwhile, reviewers were getting 1,635 Mbps average on 6 GHz with the UDR7, with peaks up to 1,890 Mbps. There’s even a YouTube video showing an iPhone 17 Pro Max hitting 1.9 Gb/s on 6 GHz 160 MHz. I was getting a third of that.&lt;/p&gt;
    &lt;head rend="h2"&gt;False start #1: “Maybe I’m testing wrong”#&lt;/head&gt;
    &lt;p&gt;I created a dedicated 6 GHz-only network with 160 MHz channel width on Auto transmit power. The spectrum was clean with no other 6 GHz broadcasts. I wondered if maybe 160 MHz was causing issues, so I tried switching to 80 MHz width to test that theory - but that made things worse at 374 Mbps total. So it wasn’t that 160 MHz was broken; something else was going on. Moving the iperf server from the UDR itself to my MacBook over Ethernet improved things to 727 Mbps, but still nowhere near the expected speeds.&lt;/p&gt;
    &lt;p&gt;At this point I knew the phone could only do 160 MHz width, not 320 MHz - that’s what Apple’s N1 chip is limited to. I hadn’t enabled IPS/IDS or QOS yet, though I was planning to since the UDR7 can handle it at full 2.5 Gbps.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finding the first bottleneck#&lt;/head&gt;
    &lt;p&gt;After banging my head against this for hours, I had a hypothesis about my test setup. My wired MacBook could hit 2.3 Gbps to the router, so the network was fine. But looking at my iperf3 results when testing WiFi against 10.0.0.1 (the router itself), I wondered if that was the issue:&lt;/p&gt;
    &lt;code&gt;iperf3 -c 10.0.0.1 -P 6 -R -t 20 -w 2M
# ...
[SUM]   0.00-20.01  sec  1.30 GBytes   560 Mbits/sec    0             sender
&lt;/code&gt;
    &lt;p&gt;Running iperf server on the router itself creates CPU contention between the WiFi scheduling and the iperf process. The router’s TCP stack isn’t tuned for this either. Classic mistake.&lt;/p&gt;
    &lt;head rend="h2"&gt;False start #2: “It’s a 2.5 GbE problem”#&lt;/head&gt;
    &lt;p&gt;Moved the iperf server to my MacBook connected through a USB-C 2.5 GbE adapter. Verified the port negotiated at 2.5G in UniFi’s port settings. Ran the test again:&lt;/p&gt;
    &lt;code&gt;iperf3 -c &amp;lt;mac_ip&amp;gt; -P 6 -R -t 20
# ...
[SUM]   0.00-20.01  sec  1.67 GBytes   718 Mbits/sec                  sender
&lt;/code&gt;
    &lt;p&gt;Better, but still nowhere close to 1.9 Gbps. Time to check what UniFi was actually showing for the client connection during the test. That’s when I found the real problem.&lt;/p&gt;
    &lt;head rend="h2"&gt;The actual issue: 80 MHz, not 160 MHz#&lt;/head&gt;
    &lt;p&gt;Looking at the UniFi client details while running iperf, I saw this:&lt;/p&gt;
    &lt;code&gt;Ch. 37 (6 GHz, 80 MHz)
Tx/Rx Rate: 1.20 Gbps
&lt;/code&gt;
    &lt;p&gt;Wait, what? My iPhone was connecting at 80 MHz channel width, not 160 MHz. Even though I had configured the SSID for 160 MHz, the actual radio was still on 80 MHz. The 1.20 Gbps PHY rate is exactly what you’d expect for 2×2 MIMO at 80 MHz. That explained the 650-900 Mbps TCP throughput perfectly. When I had manually tested 80 MHz earlier and got worse speeds (374 Mbps), it was probably due to testing against the router itself rather than the channel width.&lt;/p&gt;
    &lt;p&gt;The fix was in the UDR7’s radio settings, not the SSID settings. I went to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Devices → UDR7 → Radios → 6 GHz&lt;/item&gt;
      &lt;item&gt;Set channel width explicitly to 160 MHz (not Auto)&lt;/item&gt;
      &lt;item&gt;Set transmit power to High&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The working configuration#&lt;/head&gt;
    &lt;p&gt;After applying those changes and reconnecting:&lt;/p&gt;
    &lt;code&gt;iperf3 -c &amp;lt;mac_ip&amp;gt; -P 6 -R -t 20
# ...
[SUM]   0.00-20.01  sec  3.77 GBytes  1.62 Gbits/sec                  sender
&lt;/code&gt;
    &lt;p&gt;Finally! The UniFi panel now showed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;6 GHz, 160 MHz&lt;/item&gt;
      &lt;item&gt;Tx/Rx Rate: 2.4-2.9 Gbps&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That’s exactly the expected PHY rate for 2×2 WiFi 7 at 160 MHz with 4096-QAM.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why certain iperf flags matter#&lt;/head&gt;
    &lt;p&gt;During this journey I learned why specific iperf3 flags make such a huge difference:&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;-R&lt;/code&gt; flag (reverse mode): As I mentioned earlier, this is crucial for WiFi testing. It’s faster because:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The AP has higher transmit power and better antennas&lt;/item&gt;
      &lt;item&gt;The phone only has to send tiny ACKs back&lt;/item&gt;
      &lt;item&gt;iOS’s TCP receive path is better optimized than its send path&lt;/item&gt;
      &lt;item&gt;Phones transmit at much lower power on 6 GHz&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Multiple streams (&lt;code&gt;-P 6&lt;/code&gt;): Overcomes single-flow TCP limitations like slow start, congestion window, and socket buffer limits. Four to eight streams usually hit peak; more gives diminishing returns.&lt;/p&gt;
    &lt;p&gt;TCP window size (&lt;code&gt;-w 2M&lt;/code&gt;): Less critical on LAN where RTT is tiny, but can help with bursty traffic.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why no 2×2 client hits 2.5 Gbps on WiFi#&lt;/head&gt;
    &lt;p&gt;Even with everything optimized, I’ll never see 2.5 Gbps on my phone. Here’s why:&lt;/p&gt;
    &lt;p&gt;The fastest PHY a 2×2 client can negotiate on 160 MHz WiFi 7 is about 2.88 Gbps (4096-QAM, MCS13). But that’s the raw link rate. After overhead:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MAC/PHY overhead (preambles, pilots, guard intervals, CSMA/CA backoff, block ACKs)&lt;/item&gt;
      &lt;item&gt;IP/TCP headers&lt;/item&gt;
      &lt;item&gt;Encryption overhead&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Best-case TCP “goodput” is typically 60-75% of PHY on a clean single-client link. So 60-75% of 2.88 Gbps gives you roughly 1.7-2.1 Gbps. That’s why reviews land around 1.6-1.9 Gbps.&lt;/p&gt;
    &lt;p&gt;To exceed 2.0-2.1 Gbps you’d need:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;320 MHz channels (not supported on iPhones)&lt;/item&gt;
      &lt;item&gt;More spatial streams (3×3 or 4×4, but phones are 2×2)&lt;/item&gt;
      &lt;item&gt;WiFi 7 MLO using multiple bands simultaneously&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Key takeaways#&lt;/head&gt;
    &lt;p&gt;For anyone else trying to maximize their WiFi 7 speeds:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Don’t test against the router itself - Use a separate machine on &amp;gt;=2.5 GbE&lt;/item&gt;
      &lt;item&gt;Check your actual channel width - The client details panel tells the truth, not the SSID settings&lt;/item&gt;
      &lt;item&gt;Set transmit power to High for testing - But use Auto/Medium for daily use to avoid uplink/downlink imbalance&lt;/item&gt;
      &lt;item&gt;Use reverse mode with multiple streams - &lt;code&gt;iperf3 -c &amp;lt;server&amp;gt; -P 6 -R -t 20&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Stand 6-10 feet away - Too close can hurt signal quality&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After all this debugging, I’m now consistently seeing 1.6-1.7 Gbps on WiFi 7 with my iPhone. Not quite the headline 1.9 Gbps some reviewers got, but definitely in the expected range for real-world performance. More importantly, I understand exactly why the numbers are what they are.&lt;/p&gt;
    &lt;p&gt;Now I just need my ISP to actually deliver that 2.5 Gbps upgrade&amp;amp;mldr;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45784729</guid><pubDate>Sat, 01 Nov 2025 19:50:03 +0000</pubDate></item><item><title>Sam Altman tried to cancel his Tesla Roadster, but he was ghosted</title><link>https://electrek.co/2025/10/31/sam-altman-cancel-tesla-roadster-but-ghosted/</link><description>&lt;doc fingerprint="947c190599816fd9"&gt;
  &lt;main&gt;
    &lt;p&gt;Sam Altman, OpenAI CEO and Elon Musk’s rival in AI, has tried to cancel his Tesla Roadster reservation and get his $50,000 deposit refunded.&lt;/p&gt;
    &lt;p&gt;But it’s not as easy as it looks.&lt;/p&gt;
    &lt;p&gt;Tesla unveiled the next-generation Roadster in 2017. At the time, it took reservations with $50,000 and $250,000 deposits, depending on whether people wanted the Founders Series.&lt;/p&gt;
    &lt;p&gt;Tesla CEO Elon Musk said the new Roadster would enter production in 2020.&lt;/p&gt;
    &lt;p&gt;It didn’t.&lt;/p&gt;
    &lt;p&gt;Every single year since, the CEO claimed that the vehicle would enter production the following year, but it never did. It has become a sort of running joke.&lt;/p&gt;
    &lt;p&gt;The fact that Tesla couldn’t bring the vehicle to production has led many reservation holders to cancel their reservations, a process that has reportedly been difficult.&lt;/p&gt;
    &lt;p&gt;Many reservation holders reached out to Electrek over the years to describe how difficult it was to get their money back. Tech reviewer Marques Brownlee recently shared his experience with the process.&lt;/p&gt;
    &lt;p&gt;Now Sam Altman is having a similar problem. He took to X to share that he wanted to cancel his Roadster reservation, but the reservation email was shut down:&lt;/p&gt;
    &lt;p&gt;The OpenAI CEO is a supercar enthusiast and revealed that he reserved the Roadster in 2018.&lt;/p&gt;
    &lt;p&gt;He said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I really was excited for the car! And I understand delays. But 7.5 years has felt like a long time to wait.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;His post went viral with over 5 million views.&lt;/p&gt;
    &lt;head rend="h2"&gt;Top comment by Steve Zodiac&lt;/head&gt;
    &lt;p&gt;At least Tesla is equitable and treats all its customers with equal contempt regardless of their standing.&lt;/p&gt;
    &lt;p&gt;The timing is interesting, as we just reported that Tesla looks to be finally taking steps to bring the Roadster to production.&lt;/p&gt;
    &lt;p&gt;Musk, who notoriously despises Altman, has been claiming that Tesla will hold a demonstration of an updated Roadster before the end of the year.&lt;/p&gt;
    &lt;p&gt;However, he said that before, and it didn’t happen.&lt;/p&gt;
    &lt;head rend="h2"&gt;Electrek’s Take&lt;/head&gt;
    &lt;p&gt;The new Roadster is entirely in its “I’ll believe it when I see it” phase for me, regardless of job listings for Roadster battery manufacturing.&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45784810</guid><pubDate>Sat, 01 Nov 2025 19:57:23 +0000</pubDate></item></channel></rss>