<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 15 Sep 2025 15:11:01 +0000</lastBuildDate><item><title>For Good First Issue ‚Äì A repository of social impact and open source projects</title><link>https://forgoodfirstissue.github.com/</link><description>&lt;doc fingerprint="7b5002672bfb2689"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Committing to a better future&lt;/head&gt;
    &lt;p&gt;Lend your skills to an open source project focused on the Digital Public Goods (DPGs). From fighting climate change, to solving world hunger, your efforts will contribute to creating a better future for everyone. Together, we can drive positive and lasting contributions to the world, one commit at a time.&lt;lb/&gt;Explore a DPG repo below to get started.&lt;/p&gt;
    &lt;head rend="h2"&gt;Find a project&lt;/head&gt;
    &lt;p&gt;The participatory democracy framework. A generator and multiple gems made with Ruby on Rails&lt;/p&gt;
    &lt;p&gt;ODK Central is a server that is easy to use, very fast, and stuffed with features that make data collection easier. Contribute and make the world a better place! ‚ú®üóÑ‚ú®&lt;/p&gt;
    &lt;p&gt;üì∞ Di√°rios oficiais brasileiros acess√≠veis a todos | üì∞ Brazilian government gazettes, accessible to everyone.&lt;/p&gt;
    &lt;p&gt;Augmentative and Alternative Communication (AAC) system with text-to-speech for the browser&lt;/p&gt;
    &lt;p&gt;Documents added by volunteer contributors and historically imported from TOSBack.org. Maintenance is collaborative and volunteer-based.&lt;/p&gt;
    &lt;p&gt;OpenFn/Lightning ‚ö°Ô∏è is the newest version of the OpenFn DPG and provides a web UI to visually manage complex workflow automation projects.&lt;/p&gt;
    &lt;p&gt;A collection of tools for extracting FHIR resources and analytics services on top of that data.&lt;/p&gt;
    &lt;p&gt;Source code of the X-Road¬Æ data exchange layer software&lt;/p&gt;
    &lt;p&gt;Book repository for The Turing Way: a how to guide for reproducible, ethical and collaborative data science&lt;/p&gt;
    &lt;p&gt;Volunteer management system for nonprofit CASA, which serves foster youth in counties across America.&lt;/p&gt;
    &lt;p&gt;ODK Collect is an Android app for filling out forms. It's been used to collect billions of data points in challenging environments around the world. Contribute and make the world a better place! ‚ú®üìã‚ú®&lt;/p&gt;
    &lt;p&gt;The CHT Core Framework makes it faster to build responsive, offline-first digital health apps that equip health workers to provide better care in their communities. It is a central resource of the Community Health Toolkit.&lt;/p&gt;
    &lt;p&gt;Mautic: Open Source Marketing Automation Software.&lt;/p&gt;
    &lt;p&gt;PolicyEngine's free web app for computing the impact of public policy.&lt;/p&gt;
    &lt;p&gt;Open source, Open standards based Decentralised Identity &amp;amp; Verifiable Credentials Platform&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245313</guid><pubDate>Mon, 15 Sep 2025 02:02:39 +0000</pubDate></item><item><title>Which NPM package has the largest version number?</title><link>https://adamhl.dev/blog/largest-number-in-npm-package/</link><description>&lt;doc fingerprint="2b5d6a05af70ae19"&gt;
  &lt;main&gt;
    &lt;p&gt;I was recently working on a project that uses the AWS SDK for JavaScript. When updating the dependencies in said project, I noticed that the version of that dependency was &lt;code&gt;v3.888.0&lt;/code&gt;. Eight hundred eighty eight. That‚Äôs a big number as far as versions go.&lt;/p&gt;
    &lt;p&gt;That got me thinking: I wonder what package in the npm registry has the largest number in its version. It could be a major, minor, or patch version, and it doesn‚Äôt have to be the latest version of the package. In other words, out of the three numbers in &lt;code&gt;&amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;.&amp;lt;patch&amp;gt;&lt;/code&gt; for each version for each package, what is the largest number I can find?&lt;/p&gt;
    &lt;p&gt;TL;DR? Jump to the results to see the answer.&lt;/p&gt;
    &lt;head rend="h2"&gt;The npm API&lt;/head&gt;
    &lt;p&gt;Obviously npm has some kind of API, so it shouldn‚Äôt be too hard to get a list of all‚Ä¶ 3,639,812 packages. Oh. That‚Äôs a lot of packages. Well, considering npm had 374 billion package downloads in the past month, I‚Äôm sure they wouldn‚Äôt mind me making a few million HTTP requests.&lt;/p&gt;
    &lt;p&gt;Doing a quick search for ‚Äúnpm api‚Äù leads me to a readme in the npm/registry repo on GitHub. There‚Äôs a &lt;code&gt;/-/all&lt;/code&gt; endpoint listed in the table of contents which seems promising. That section doesn‚Äôt actually exist in the readme, but maybe it still works?&lt;/p&gt;
    &lt;p&gt;Whelp, maybe npm packages have an ID and I can just start at 1 and count up? It looks like packages have an &lt;code&gt;_id&lt;/code&gt; field‚Ä¶ never mind, the &lt;code&gt;_id&lt;/code&gt; field is the package name. Okay, let‚Äôs try to find something else.&lt;/p&gt;
    &lt;p&gt;A little more digging brings me to this GitHub discussion about the npm replication API. So npm replicates package info in CouchDB at &lt;code&gt;https://replicate.npmjs.com&lt;/code&gt;, and conveniently, they support the &lt;code&gt;_all_docs&lt;/code&gt; endpoint. Let‚Äôs give that a try:&lt;/p&gt;
    &lt;p&gt;Those are some interesting package names. Looks like this data is paginated and by default I get 1,000 packages at a time. When I write the final script, I can set the &lt;code&gt;limit&lt;/code&gt; query parameter to the max of 10,000 to make pagination a little less painful.&lt;/p&gt;
    &lt;p&gt;Fortunately, the CouchDB docs have a guide for pagination, and it looks like it‚Äôs as simple as using the &lt;code&gt;skip&lt;/code&gt; query parameter.&lt;/p&gt;
    &lt;p&gt;Never mind. According to the GitHub discussion linked above, &lt;code&gt;skip&lt;/code&gt; is no longer supported. The ‚ÄúPaging (Alternate Method)‚Äù section of the same page says that I can use &lt;code&gt;startkey_docid&lt;/code&gt; instead. If I grab the &lt;code&gt;id&lt;/code&gt; of the last row, I should be able to use that to return the next set of rows. Fun fact: The 1000th package (alphabetically) on npm is &lt;code&gt;03-webpack-number-test&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Nice. Also, another &lt;code&gt;3628102 - 3628088 = 14&lt;/code&gt; packages have been published in the ~15 minutes since I ran the last query.&lt;/p&gt;
    &lt;p&gt;Now, there‚Äôs one more piece of the puzzle to figure out. How do I get all the versions for a given package? Unfortunately, it doesn‚Äôt seem like I can get package version information along with the base info returned by &lt;code&gt;_all_docs&lt;/code&gt;. I have to separately fetch each package‚Äôs metadata from &lt;code&gt;https://registry.npmjs.org/&amp;lt;package_id&amp;gt;&lt;/code&gt;. Let‚Äôs see what good ol‚Äô trusty &lt;code&gt;03-webpack-number-test&lt;/code&gt; looks like:&lt;/p&gt;
    &lt;p&gt;Alright, I have everything I need. Now I just need to write a bash script that‚Äî just kidding. A wise programmer once said, ‚Äúif your shell script is more than 10 lines, it shouldn‚Äôt be a shell script‚Äù (that was me, I said that). I like TypeScript, so let‚Äôs use that.&lt;/p&gt;
    &lt;p&gt;The biggest bottleneck is going to be waiting on the &lt;code&gt;GET&lt;/code&gt;s for each package‚Äôs metadata. My plan is this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Grab all the package IDs from the replication API and save that data to a file (I don‚Äôt want to have to refetch everything if the something goes wrong later in the script)&lt;/item&gt;
      &lt;item&gt;Fetch package data in batches so we‚Äôre not just doing 1 HTTP request at a time&lt;/item&gt;
      &lt;item&gt;Save the package data to a file (again, hopefully I only have to fetch everything once)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once I have all the package data, I can answer the original question of ‚Äúlargest number in version‚Äù and look at a few other interesting things.&lt;/p&gt;
    &lt;p&gt;(A few hours and many iterations later‚Ä¶)&lt;/p&gt;
    &lt;p&gt;See the script section at the end if you want to see what it looks like.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;Some stats:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Time to fetch all ~3.6 million package IDs: A few minutes&lt;/item&gt;
      &lt;item&gt;Time to fetch version data for each one of those packages: ~12 hours (yikes)&lt;/item&gt;
      &lt;item&gt;Packages fetched per second: ~84 packages/s&lt;/item&gt;
      &lt;item&gt;Size of &lt;code&gt;package-ids.json&lt;/code&gt;: ~78MB&lt;/item&gt;
      &lt;item&gt;Size of &lt;code&gt;package-data.json&lt;/code&gt;: ~886MB&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And the winner is‚Ä¶ (not really) latentflip-test at version &lt;code&gt;1000000000000000000.1000000000000000000.1000000000000000000&lt;/code&gt;. And no, there haven‚Äôt actually been one quintillion major versions of this package published. Disappointing, I know.&lt;/p&gt;
    &lt;p&gt;Okay, I feel like that shouldn‚Äôt count. I think we can do better and find a ‚Äúreal‚Äù package that actually follows semantic versioning. I think a better question to ask is this:&lt;/p&gt;
    &lt;p&gt;For packages that follow semantic versioning, which package has the largest number from &lt;code&gt;&amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;.&amp;lt;patch&amp;gt;&lt;/code&gt; in any of its versions?&lt;/p&gt;
    &lt;p&gt;So, what does it mean to ‚Äúfollow semantic versioning‚Äù? Should we ‚Äúdisqualify‚Äù a package for skipping a version number? In this case, I think we‚Äôll just say that a package has to have more versions published than the largest number we find for that package. For example, a package with a version of &lt;code&gt;1.888.0&lt;/code&gt; will have had at least 888 versions published if it actually followed semver.&lt;/p&gt;
    &lt;p&gt;Before we get to the real winner, here are the top 10 packages by total number of versions published:&lt;/p&gt;
    &lt;p&gt;Top 10 packages that (probably) follow semver by largest number in one of its versions:&lt;/p&gt;
    &lt;p&gt;So it seems like the winner is @mahdiarjangi/phetch-cli with &lt;code&gt;19494&lt;/code&gt;, right? Unfortunately, I‚Äôm not going to count that either. It only has so many versions because of a misconfigured GitHub action that published new versions in a loop.&lt;/p&gt;
    &lt;p&gt;I manually went down the above list, disqualifying any packages that had similar issues. I also checked that ‚Äúnew‚Äù versions actually differed from previous versions in terms of content. Overall, I looked for a package that was actually publishing new versions on purpose with some kind of change to the package content.&lt;/p&gt;
    &lt;p&gt;The real winner (#19 on the list) is: all-the-package-names with &lt;code&gt;2401&lt;/code&gt; from version &lt;code&gt;2.0.2401&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Well, that‚Äôs sort of disappointing, but also kind of funny. I don‚Äôt know what I was expecting to be honest. If you‚Äôre curious, you can see more results at the bottom of this post.&lt;/p&gt;
    &lt;p&gt;What you do with all of this extremely important and useful information is up to you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Script&lt;/head&gt;
    &lt;head rend="h2"&gt;More Results&lt;/head&gt;
    &lt;p&gt;This is from the script:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245678</guid><pubDate>Mon, 15 Sep 2025 03:03:18 +0000</pubDate></item><item><title>Language Models Pack Billions of Concepts into 12k Dimensions</title><link>https://nickyoder.com/johnson-lindenstrauss/</link><description>&lt;doc fingerprint="150b027d080f93db"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Beyond Orthogonality: How Language Models Pack Billions of Concepts into 12,000 Dimensions&lt;/head&gt;
    &lt;p&gt;In a recent 3Blue1Brown video series on transformer models, Grant Sanderson posed a fascinating question: How can a relatively modest embedding space of 12,288 dimensions (GPT-3) accommodate millions of distinct real-world concepts?&lt;/p&gt;
    &lt;p&gt;The answer lies at the intersection of high-dimensional geometry and a remarkable mathematical result known as the Johnson-Lindenstrauss lemma. While exploring this question, I discovered something unexpected that led to an interesting collaboration with Grant and a deeper understanding of vector space geometry.&lt;/p&gt;
    &lt;p&gt;The key insight begins with a simple observation: while an N-dimensional space can only hold N perfectly orthogonal vectors, relaxing this constraint to allow for "quasi-orthogonal" relationships (vectors at angles of, say, 85-95 degrees) dramatically increases the space's capacity. This property is crucial for understanding how language models can efficiently encode semantic meaning in relatively compact embedding spaces.&lt;/p&gt;
    &lt;p&gt;In Grant's video, he demonstrated this principle with an experiment attempting to fit 10,000 unit vectors into a 100-dimensional space while maintaining near-orthogonal relationships. The visualization suggested success, showing angles clustered between 89-91 degrees. However, when I implemented the code myself, I noticed something interesting about the optimization process.&lt;/p&gt;
    &lt;p&gt;The original loss function was elegantly simple:&lt;/p&gt;
    &lt;p&gt; loss = (dot_products.abs()).relu().sum()&lt;lb/&gt;While this loss function appears perfect for an unbounded ‚Ñù·¥∫ space, it encounters two subtle but critical issues when applied to vectors constrained to a high-dimensional unit sphere:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The Gradient Trap: The dot product between vectors is the cosine of the angle between them, and the gradient is the sine of this angle. This creates a perverse incentive structure: when vectors approach the desired 90-degree relationship, the gradient (sin(90¬∞) = 1.0) strongly pushes toward improvement. However, when vectors drift far from the goal (near 0¬∞ or 180¬∞), the gradient (sin(0¬∞) ‚âà 0) vanishes‚Äîeffectively trapping these badly aligned vectors in their poor configuration.&lt;/item&gt;
      &lt;item&gt;The 99% Solution: The optimizer discovered a statistically favorable but geometrically perverse solution. For each vector, it would be properly orthogonal to 9,900 out of 9,999 other vectors while being nearly parallel to just 99. This configuration, while clearly not the intended outcome, actually represented a global minimum for the loss function‚Äîmathematically similar to taking 100 orthogonal basis vectors and replicating each one roughly 100 times.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This stable configuration was particularly insidious because it satisfied 99% of the constraints while being fundamentally different from the desired constellation of evenly spaced, quasi-orthogonal vectors. To address this, I modified the loss function to use an exponential penalty that increases aggressively as dot products grow:&lt;/p&gt;
    &lt;p&gt;loss = exp(20*dot_products.abs()**2).sum() (Full code here)&lt;/p&gt;
    &lt;p&gt;This change produced the desired behavior, though with a revealing result: the maximum achievable pairwise angle was around 76.5 degrees, not 89 degrees.&lt;/p&gt;
    &lt;p&gt;This discovery led me down a fascinating path exploring the fundamental limits of vector packing in high-dimensional spaces, and how these limits relate to the Johnson-Lindenstrauss lemma.&lt;/p&gt;
    &lt;p&gt;When I shared these findings with Grant, his response exemplified the collaborative spirit that makes the mathematics community so rewarding. He not only appreciated the technical correction but invited me to share these insights with the 3Blue1Brown audience. This article is that response, expanded to explore the broader implications of these geometric properties for machine learning and dimensionality reduction.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Johnson-Lindenstrauss Lemma: A Geometric Guarantee&lt;/head&gt;
    &lt;p&gt;At its core, the Johnson-Lindenstrauss (JL) lemma makes a remarkable promise: you can project points from an arbitrarily high-dimensional space into a surprisingly low-dimensional space while preserving their relative distances with high probability. What makes this result particularly striking is that the required dimensionality of the low-dimensional space grows only logarithmically with the number of points you want to project.&lt;/p&gt;
    &lt;p&gt;Formally, the lemma states that for an error factor Œµ (between 0 and 1), and any set of N points in a high-dimensional space, there exists a projection into k dimensions where for any two points u and v in the original space, their projections f(u) and f(v) in the lower dimensional space satisfy:&lt;/p&gt;
    &lt;p&gt;(1 - Œµ)||u - v||¬≤ ‚â§ ||f(u) - f(v)||¬≤ ‚â§ (1 + Œµ)||u - v||¬≤&lt;/p&gt;
    &lt;p&gt;The number of dimensions (k) required to guarantee these error bounds is given by:&lt;/p&gt;
    &lt;p&gt;k ‚â• O(log(N)/Œµ¬≤)&lt;/p&gt;
    &lt;p&gt;The "Big O" notation can be replaced with a concrete constant C:&lt;/p&gt;
    &lt;p&gt;k ‚â• (C/Œµ¬≤) * log(N)&lt;/p&gt;
    &lt;p&gt;Where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;k is the target dimension&lt;/item&gt;
      &lt;item&gt;N is the number of points&lt;/item&gt;
      &lt;item&gt;Œµ is the maximum allowed distortion&lt;/item&gt;
      &lt;item&gt;C is a constant that determines the probability of success&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While most practitioners use values between 4 and 8 as a conservative choice for random projections, the optimal value of C remains an open question. As we'll see in the experimental section, engineered projections can achieve much lower values of C, with profound implications for embedding space capacity.&lt;/p&gt;
    &lt;p&gt;The fascinating history of this result speaks to the interconnected nature of mathematical discovery. Johnson and Lindenstrauss weren't actually trying to solve a dimensionality reduction problem ‚Äì they stumbled upon this property while working on extending Lipschitz functions in Banach spaces. Their 1984 paper turned out to be far more influential in computer science than in their original domain.&lt;/p&gt;
    &lt;head rend="h1"&gt;From Theory to Practice: Two Domains of Application&lt;/head&gt;
    &lt;p&gt;The JL lemma finds practical application in two distinct but equally important domains:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Dimensionality Reduction: Consider an e-commerce platform like Amazon, where each customer's preferences might be represented by a vector with millions of dimensions (one for each product). Direct computation with such vectors would be prohibitively expensive. The JL lemma tells us we can project this data into a much lower-dimensional space ‚Äì perhaps just a thousand dimensions ‚Äì while preserving the essential relationships between customers. This makes previously intractable computations feasible on a single GPU, enabling real-time customer relationship management and inventory planning.&lt;/item&gt;
      &lt;item&gt;Embedding Space Capacity: This application is more subtle but equally powerful. Rather than actively projecting vectors, we're interested in understanding how many distinct concepts can naturally coexist in a fixed-dimensional space. This is where our experiments provide valuable insight into the practical limits of embedding space capacity.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's consider what we mean by "concepts" in an embedding space. Language models don't deal with perfectly orthogonal relationships ‚Äì real-world concepts exhibit varying degrees of similarity and difference. Consider these examples of words chosen at random:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Archery" shares some semantic space with "precision" and "sport"&lt;/item&gt;
      &lt;item&gt;"Fire" overlaps with both "heat" and "passion"&lt;/item&gt;
      &lt;item&gt;"Gelatinous" relates to physical properties and food textures&lt;/item&gt;
      &lt;item&gt;"Southern-ness" encompasses culture, geography, and dialect&lt;/item&gt;
      &lt;item&gt;"Basketball" connects to both athletics and geometry&lt;/item&gt;
      &lt;item&gt;"Green" spans color perception and environmental consciousness&lt;/item&gt;
      &lt;item&gt;"Altruistic" links moral philosophy with behavioral patterns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The beauty of high-dimensional spaces is that they can accommodate these nuanced, partial relationships while maintaining useful geometric properties for computation and inference.&lt;/p&gt;
    &lt;head rend="h1"&gt;Empirical Investigation of Embedding Capacity&lt;/head&gt;
    &lt;p&gt;When we move from random projections to engineered solutions, the theoretical bounds for C of the JL lemma become surprisingly conservative. While a Hadamard matrix transformation with random elements can reliably achieve a C value between 2.5 and 4 in a single pass, our GPU experiments suggest even more efficient arrangements are possible through optimization.&lt;/p&gt;
    &lt;p&gt;To explore these limits, I implemented a series of experiments projecting standard basis vectors into spaces of varying dimensionality. Using GPU acceleration, I tested combinations of N (number of vectors) up to 30,000 and k (embedding dimensions) up to 10,000, running each optimization for 50,000 iterations. The results reveal some fascinating patterns:&lt;/p&gt;
    &lt;p&gt;Several key observations emerge from this data:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The value of C initially rises with N, reaching a maximum around ~0.9 (notably always below 1.0)&lt;/item&gt;
      &lt;item&gt;After peaking, C begins a consistent downward trend&lt;/item&gt;
      &lt;item&gt;At high ratios of N to K, we observe C values trend below 0.2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This behavior likely relates to an interesting property of high-dimensional geometry: as dimensionality increases, sphere packing becomes more efficient when the spheres are small relative to the unit sphere. This suggests that our observed upper bounds on C might still be conservative for very large numbers of concepts.&lt;/p&gt;
    &lt;head rend="h1"&gt;Practical Implications for Language Models&lt;/head&gt;
    &lt;p&gt;Let's consider three scenarios for the constant C:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;C = 4: A conservative choice for random projections with Hadamard matrices&lt;/item&gt;
      &lt;item&gt;C = 1: A likely upper bound for optimized or emergent embeddings&lt;/item&gt;
      &lt;item&gt;C = 0.2: A value suggested by our experiments for very large spaces&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The implications of these geometric properties are staggering. Let's consider a simple way to estimate how many quasi-orthogonal vectors can fit in a k-dimensional space. If we define F as the degrees of freedom from orthogonality (90¬∞ - desired angle), we can approximate the number of vectors as:&lt;/p&gt;
    &lt;p&gt;Vectors ‚âà 10^(k * F¬≤ / 1500)&lt;/p&gt;
    &lt;p&gt;where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;k is the embedding dimension&lt;/item&gt;
      &lt;item&gt;F is the degrees of "freedom" from orthogonality (e.g., F = 3 for 87¬∞ angles)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Applying this to GPT-3's 12,288-dimensional embedding space reveals its extraordinary capacity:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;At 89¬∞ (F = 1): approximately 10^8 vectors&lt;/item&gt;
      &lt;item&gt;At 88¬∞ (F = 2): approximately 10^32 vectors&lt;/item&gt;
      &lt;item&gt;At 87¬∞ (F = 3): approximately 10^73 vectors&lt;/item&gt;
      &lt;item&gt;At 85¬∞ (F = 5): more than 10^200 vectors&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To put this in perspective, even the conservative case of 86¬∞ angles provides capacity far exceeding the estimated number of atoms in the observable universe (~10^80). This helps explain how language models can maintain rich, nuanced relationships between millions of concepts while working in relatively modest embedding dimensions.&lt;/p&gt;
    &lt;head rend="h1"&gt;Practical Applications and Future Directions&lt;/head&gt;
    &lt;p&gt;The insights from this investigation have two major practical implications:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Efficient Dimensionality Reduction: The robustness of random projections, particularly when combined with Hadamard transformations (or BCH coding), provides a computationally efficient way to work with high-dimensional data. No complex optimization required ‚Äì the mathematics of high-dimensional spaces does the heavy lifting for us.&lt;/item&gt;
      &lt;item&gt;Embedding Space Design: Understanding the true capacity of high-dimensional spaces helps explain how transformer models can maintain rich, nuanced representations of language in relatively compact embeddings. Concepts like "Canadian," "morose," "Hitchcockian," "handsome," "whimsical," and "Muppet-like" can all find their place in the geometry while preserving their subtle relationships to each other.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This research suggests that current embedding dimensions (1,000-20,000) provide more than adequate capacity for representing human knowledge and reasoning. The challenge lies not in the capacity of these spaces but in learning the optimal arrangement of concepts within them.&lt;/p&gt;
    &lt;p&gt;My code for Hadamard and optimized projections.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;What began as an investigation into a subtle optimization issue has led us to a deeper appreciation of high-dimensional geometry and its role in modern machine learning. The Johnson-Lindenstrauss lemma, discovered in a different context nearly four decades ago, continues to provide insight into the foundations of how we can represent meaning in mathematical spaces.&lt;/p&gt;
    &lt;p&gt;I want to express my sincere gratitude to Grant Sanderson and the 3Blue1Brown channel. His work consistently inspires deeper exploration of mathematical concepts, and his openness to collaboration exemplifies the best aspects of the mathematical community. The opportunity to contribute to this discussion has been both an honor and a genuine pleasure.&lt;/p&gt;
    &lt;p&gt;I would also like to thank Suman Dev for his help in optimizing the GPU code.&lt;/p&gt;
    &lt;p&gt;This was enormously fun to research and write.&lt;/p&gt;
    &lt;p&gt;Nick Yoder&lt;/p&gt;
    &lt;head rend="h3"&gt;&lt;lb/&gt;Further Reading&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Sphere Packings, Lattices and Groups by Conway and Sloane&lt;/item&gt;
      &lt;item&gt;Database-friendly random projections: Johnson-Lindenstrauss with binary coins by Achlioptas&lt;/item&gt;
      &lt;item&gt;Hadamard Matrices, Sequences, and Block Designs by Seberry and Yamada&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45245948</guid><pubDate>Mon, 15 Sep 2025 03:54:20 +0000</pubDate></item><item><title>Celestia ‚Äì Real-time 3D visualization of space</title><link>https://celestiaproject.space/</link><description>&lt;doc fingerprint="5f8f763c0c2747ac"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Making sure you're not a bot!&lt;/head&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;head&gt;Why am I seeing this?&lt;/head&gt;
    &lt;p&gt;You are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.&lt;/p&gt;
    &lt;p&gt;Anubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.&lt;/p&gt;
    &lt;p&gt;Ultimately, this is a hack whose real purpose is to give a "good enough" placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.&lt;/p&gt;
    &lt;p&gt;Please note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain.&lt;/p&gt;
    &lt;p&gt;This website is running Anubis version &lt;code&gt;1.21.3&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45246403</guid><pubDate>Mon, 15 Sep 2025 05:30:19 +0000</pubDate></item><item><title>Folks, we have the best œÄ</title><link>https://lcamtuf.substack.com/p/folks-we-have-the-best</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45246953</guid><pubDate>Mon, 15 Sep 2025 07:10:03 +0000</pubDate></item><item><title>The Mac App Flea Market</title><link>https://blog.jim-nielsen.com/2025/mac-app-flea-market/</link><description>&lt;doc fingerprint="5d71976d94b446a6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Mac App Flea Market&lt;/head&gt;
    &lt;p&gt;Have you ever searched for ‚ÄúAI chat‚Äù in the Mac App Store?&lt;/p&gt;
    &lt;p&gt;I have. It‚Äôs like strolling through one of those counterfeit, replica markets where all the goods look legit at first glance. But then when you look closer, you realize something is off.&lt;/p&gt;
    &lt;p&gt;For the query ‚ÄúAI chat‚Äù, there are so many ChatGPT-like app icons the results are comical. Take a look at these:&lt;/p&gt;
    &lt;p&gt;The real app icon for the ChatGPT desktop app (from OpenAI) is in that collection above. Can you spot it?&lt;/p&gt;
    &lt;p&gt;Here they are again in a single image:&lt;/p&gt;
    &lt;p&gt;(It‚Äôs the one in the 4th row, 3rd column.)&lt;/p&gt;
    &lt;p&gt;And those are just black-and-white lookalikes. There are other apps riding the AI/OpenAI wave that look like the ChatGPT logo just in different colors.&lt;/p&gt;
    &lt;p&gt;The funny thing is: the official ChatGPT desktop app from OpenAI is not even in the Mac App Store. It‚Äôs only available from their website, so it won‚Äôt show up in the ‚ÄúAI chat‚Äù results.&lt;/p&gt;
    &lt;p&gt;There were lots of other ‚Äúsort of looks like the official one but isn‚Äôt‚Äù app icons in my search results, like this Claude one, this Grok one, or this Gemini one.&lt;/p&gt;
    &lt;p&gt;Oh, and these apps‚Äô names were fascinating to look at. They were basically every spacing and casing combination of ‚ÄúAI‚Äù, ‚ÄúChat‚Äù, and ‚ÄúBot‚Äù you can image. Just look at this sampling:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI Chat Bot : Ask Assistant&lt;/item&gt;
      &lt;item&gt;AI Chatbot: Chat Ask Assistant&lt;/item&gt;
      &lt;item&gt;AI Chatbot : Chat AI Assistant&lt;/item&gt;
      &lt;item&gt;AI Chatbot : Ask Assistant AI&lt;/item&gt;
      &lt;item&gt;AI Chatbot‚ÄîOpen &amp;amp; Ask Chat Bot&lt;/item&gt;
      &lt;item&gt;AI ChatBot ASK Chat Assistant&lt;/item&gt;
      &lt;item&gt;AI Chatbot Assistant &amp;amp; Ask AI&lt;/item&gt;
      &lt;item&gt;Ai Chatbot :Ask Open Assistant&lt;/item&gt;
      &lt;item&gt;AI Chatbot :Genius Question AI&lt;/item&gt;
      &lt;item&gt;AI Chatbot-Ask Seek Assistant&lt;/item&gt;
      &lt;item&gt;AI ChatBot - Ask Anything Bot&lt;/item&gt;
      &lt;item&gt;AI Chatbot, Ask Chat Assistant&lt;/item&gt;
      &lt;item&gt;AI Chat Bot - AI Bot Assistant&lt;/item&gt;
      &lt;item&gt;AI Chatbot„ÉªAI Chat Assistant 5&lt;/item&gt;
      &lt;item&gt;Al Chatbot - AI Assistant Chat&lt;/item&gt;
      &lt;item&gt;AI Chatbot : Ask AI Assistant&lt;/item&gt;
      &lt;item&gt;AI Chatbot : Ask AI Chat Bot&lt;/item&gt;
      &lt;item&gt;AI Chatbot ‚Ä¢ Chat AI Assistant&lt;/item&gt;
      &lt;item&gt;AI ChatBot- Ask Chat Assistant&lt;/item&gt;
      &lt;item&gt;AI Chat Bot - Ask Assistant&lt;/item&gt;
      &lt;item&gt;AI Chatbot: Ask GPT Assistant&lt;/item&gt;
      &lt;item&gt;Chatbot AI : Ask Assistant&lt;/item&gt;
      &lt;item&gt;Chatbot: Open Ask AI Chat Bot&lt;/item&gt;
      &lt;item&gt;AI Chatbot Assistant: Ask Bot&lt;/item&gt;
      &lt;item&gt;AI Chat - Chatbot Ask Anything&lt;/item&gt;
      &lt;item&gt;AI Chat: Smart AI Assistant&lt;/item&gt;
      &lt;item&gt;Chatbot: Ask AI Assistant Bot&lt;/item&gt;
      &lt;item&gt;Chatbot AI Chat - AI Assistant&lt;/item&gt;
      &lt;item&gt;ChatBot : AI Chat Assistant&lt;/item&gt;
      &lt;item&gt;ChatBot&amp;amp;Chat Ask Ai Assistant&lt;/item&gt;
      &lt;item&gt;Chatbot: Ask Open Assistant AI&lt;/item&gt;
      &lt;item&gt;Chatbot: Ask Character AI Chat&lt;/item&gt;
      &lt;item&gt;AI Chatbot Assistant ‚Ä¢ Ask AI&lt;/item&gt;
      &lt;item&gt;Ask AI Chatbot: Chat Assistant&lt;/item&gt;
      &lt;item&gt;AI Chat - Chatbot Assistant 4o&lt;/item&gt;
      &lt;item&gt;AI Bot: Al ChatBot &amp;amp; Assistant&lt;/item&gt;
      &lt;item&gt;Chatbot: Open Chat with AI&lt;/item&gt;
      &lt;item&gt;Chatbot: Ask AI Chat Bot&lt;/item&gt;
      &lt;item&gt;AI Chat Assistant ‚Äì ChatNow&lt;/item&gt;
      &lt;item&gt;Chatbot: Open Chat with AI Bot&lt;/item&gt;
      &lt;item&gt;Chatbot AI - Chat Assistant&lt;/item&gt;
      &lt;item&gt;Open Chat Ai Chatbot Assistant&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I mean, look at this one: they named it ‚ÄúAl Chatbot‚Äù (that's the letter &lt;code&gt;l&lt;/code&gt; as in ‚Äúlima‚Äù, you can see it better in the URL slug where the letters are lowercase: &lt;code&gt;al-chatbot&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Imagine going to store to grab some Nike gear and you find stuff like this (image courtesy of this post on Reddit):&lt;/p&gt;
    &lt;p&gt;What does that say about the store you‚Äôre visiting?&lt;/p&gt;
    &lt;p&gt;I always wanted a pair of Mike Jordans, just like I always wanted ChatGPP for my Mac.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45246971</guid><pubDate>Mon, 15 Sep 2025 07:14:13 +0000</pubDate></item><item><title>Show HN: I reverse engineered macOS to allow custom Lock Screen wallpapers</title><link>https://cindori.com/backdrop</link><description>&lt;doc fingerprint="aa8f6dc5798fb7f5"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introducing&lt;/head&gt;
    &lt;head rend="h2"&gt;A Next-Gen Wallpaper Engine for your Mac.&lt;/head&gt;
    &lt;p&gt;Backdrop is the ultimate wallpaper app for macOS. Featuring 4K video backdrops with smooth multi-display playback, intelligent power optimization and Lock Screen support.&lt;/p&gt;
    &lt;p&gt;Backdrop is the ultimate wallpaper app for macOS. Featuring 4K video backdrops with smooth multi-display playback, intelligent power optimization and Lock Screen support.&lt;/p&gt;
    &lt;p&gt;Play stunning 4K video backdrops with smooth, high-performance playback ‚Äî bringing motion and atmosphere to your desktop.&lt;/p&gt;
    &lt;p&gt;Backdrop is the first app to bring custom video wallpapers to both your desktop and Lock Screen ‚Äî an exclusive, world-first feature.&lt;/p&gt;
    &lt;p&gt;Backdrop works seamlessly with multiple displays, letting you mirror a single backdrop or set different ones for each screen.&lt;/p&gt;
    &lt;p&gt;Browse thousands of stunning Backdrops created by the community. Set your favorites, explore new styles, or design your own using your own videos ‚Äî all from one seamless experience.&lt;/p&gt;
    &lt;p&gt;Explore thousands of animated wallpapers created and shared by the Backdrop community ‚Äî from calming nature scenes to futuristic loops, there‚Äôs something for every mood.&lt;/p&gt;
    &lt;p&gt;Create your own Backdrops in seconds using your own videos. Share them with the community, or use them for your personal setup.&lt;/p&gt;
    &lt;p&gt;Curated animated wallpapers to help you focus, relax, or get inspired. Choose the mood that matches your moment.&lt;/p&gt;
    &lt;p&gt;Backdrop is built for macOS from the ground up ‚Äî fully hardware-accelerated, energy-efficient, and optimized for Retina displays and multi-monitor setups.&lt;/p&gt;
    &lt;p&gt;Less than0.3%&lt;lb/&gt;CPUusage when running on a MacBook Pro1&lt;/p&gt;
    &lt;p&gt;GPU Accelerated&lt;lb/&gt;Efficient rendering using a custom video encoder&lt;/p&gt;
    &lt;p&gt;Fully Native&lt;lb/&gt;Built for macOS with native performance&lt;/p&gt;
    &lt;p&gt;Energy Efficient&lt;lb/&gt;Intelligently reduces resource usage to extend battery life.&lt;/p&gt;
    &lt;p&gt;Get exclusive deals and invitations to try out our new app releases.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45247396</guid><pubDate>Mon, 15 Sep 2025 08:28:09 +0000</pubDate></item><item><title>How does air pollution impact your brain?</title><link>https://neurofrontiers.blog/how-does-air-pollution-impact-your-brain/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45247616</guid><pubDate>Mon, 15 Sep 2025 09:04:23 +0000</pubDate></item><item><title>RustGPT: A pure-Rust transformer LLM built from scratch</title><link>https://github.com/tekaratzas/RustGPT</link><description>&lt;doc fingerprint="35db335f75314ff8"&gt;
  &lt;main&gt;
    &lt;head class="px-3 py-2"&gt;RustGPT-demo-zoon.mp4&lt;/head&gt;
    &lt;p&gt;A complete Large Language Model implementation in pure Rust with no external ML frameworks. Built from the ground up using only &lt;code&gt;ndarray&lt;/code&gt; for matrix operations.&lt;/p&gt;
    &lt;p&gt;This project demonstrates how to build a transformer-based language model from scratch in Rust, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pre-training on factual text completion&lt;/item&gt;
      &lt;item&gt;Instruction tuning for conversational AI&lt;/item&gt;
      &lt;item&gt;Interactive chat mode for testing&lt;/item&gt;
      &lt;item&gt;Full backpropagation with gradient clipping&lt;/item&gt;
      &lt;item&gt;Modular architecture with clean separation of concerns&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Start with these two core files to understand the implementation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;src/main.rs&lt;/code&gt;- Training pipeline, data preparation, and interactive mode&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;src/llm.rs&lt;/code&gt;- Core LLM implementation with forward/backward passes and training logic&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The model uses a transformer-based architecture with the following components:&lt;/p&gt;
    &lt;code&gt;Input Text ‚Üí Tokenization ‚Üí Embeddings ‚Üí Transformer Blocks ‚Üí Output Projection ‚Üí Predictions
&lt;/code&gt;
    &lt;code&gt;src/
‚îú‚îÄ‚îÄ main.rs              # üéØ Training pipeline and interactive mode
‚îú‚îÄ‚îÄ llm.rs               # üß† Core LLM implementation and training logic
‚îú‚îÄ‚îÄ lib.rs               # üìö Library exports and constants
‚îú‚îÄ‚îÄ transformer.rs       # üîÑ Transformer block (attention + feed-forward)
‚îú‚îÄ‚îÄ self_attention.rs    # üëÄ Multi-head self-attention mechanism  
‚îú‚îÄ‚îÄ feed_forward.rs      # ‚ö° Position-wise feed-forward networks
‚îú‚îÄ‚îÄ embeddings.rs        # üìä Token embedding layer
‚îú‚îÄ‚îÄ output_projection.rs # üé∞ Final linear layer for vocabulary predictions
‚îú‚îÄ‚îÄ vocab.rs            # üìù Vocabulary management and tokenization
‚îú‚îÄ‚îÄ layer_norm.rs       # üßÆ Layer normalization
‚îî‚îÄ‚îÄ adam.rs             # üèÉ Adam optimizer implementation

tests/
‚îú‚îÄ‚îÄ llm_test.rs         # Tests for core LLM functionality
‚îú‚îÄ‚îÄ transformer_test.rs # Tests for transformer blocks
‚îú‚îÄ‚îÄ self_attention_test.rs # Tests for attention mechanisms
‚îú‚îÄ‚îÄ feed_forward_test.rs # Tests for feed-forward layers
‚îú‚îÄ‚îÄ embeddings_test.rs  # Tests for embedding layers
‚îú‚îÄ‚îÄ vocab_test.rs       # Tests for vocabulary handling
‚îú‚îÄ‚îÄ adam_test.rs        # Tests for optimizer
‚îî‚îÄ‚îÄ output_projection_test.rs # Tests for output layer
&lt;/code&gt;
    &lt;p&gt;The implementation includes two training phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Pre-training: Learns basic world knowledge from factual statements&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;"The sun rises in the east and sets in the west"&lt;/item&gt;
          &lt;item&gt;"Water flows downhill due to gravity"&lt;/item&gt;
          &lt;item&gt;"Mountains are tall and rocky formations"&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Instruction Tuning: Learns conversational patterns&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;"User: How do mountains form? Assistant: Mountains are formed through tectonic forces..."&lt;/item&gt;
          &lt;item&gt;Handles greetings, explanations, and follow-up questions&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Clone and run
git clone https://github.com/tekaratzas/RustGPT.git 
cd RustGPT
cargo run

# The model will:
# 1. Build vocabulary from training data
# 2. Pre-train on factual statements (100 epochs)  
# 3. Instruction-tune on conversational data (100 epochs)
# 4. Enter interactive mode for testing&lt;/code&gt;
    &lt;p&gt;After training, test the model interactively:&lt;/p&gt;
    &lt;code&gt;Enter prompt: How do mountains form?
Model output: Mountains are formed through tectonic forces or volcanism over long geological time periods

Enter prompt: What causes rain?
Model output: Rain is caused by water vapor in clouds condensing into droplets that become too heavy to remain airborne
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vocabulary Size: Dynamic (built from training data)&lt;/item&gt;
      &lt;item&gt;Embedding Dimension: 128&lt;/item&gt;
      &lt;item&gt;Hidden Dimension: 256&lt;/item&gt;
      &lt;item&gt;Max Sequence Length: 80 tokens&lt;/item&gt;
      &lt;item&gt;Architecture: 3 Transformer blocks + embeddings + output projection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Optimizer: Adam with gradient clipping&lt;/item&gt;
      &lt;item&gt;Pre-training LR: 0.0005 (100 epochs)&lt;/item&gt;
      &lt;item&gt;Instruction Tuning LR: 0.0001 (100 epochs)&lt;/item&gt;
      &lt;item&gt;Loss Function: Cross-entropy loss&lt;/item&gt;
      &lt;item&gt;Gradient Clipping: L2 norm capped at 5.0&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Custom tokenization with punctuation handling&lt;/item&gt;
      &lt;item&gt;Greedy decoding for text generation&lt;/item&gt;
      &lt;item&gt;Gradient clipping for training stability&lt;/item&gt;
      &lt;item&gt;Modular layer system with clean interfaces&lt;/item&gt;
      &lt;item&gt;Comprehensive test coverage for all components&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Run all tests
cargo test

# Test specific components
cargo test --test llm_test
cargo test --test transformer_test
cargo test --test self_attention_test

# Build optimized version
cargo build --release

# Run with verbose output
cargo test -- --nocapture&lt;/code&gt;
    &lt;p&gt;This implementation demonstrates key ML concepts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Transformer architecture (attention, feed-forward, layer norm)&lt;/item&gt;
      &lt;item&gt;Backpropagation through neural networks&lt;/item&gt;
      &lt;item&gt;Language model training (pre-training + fine-tuning)&lt;/item&gt;
      &lt;item&gt;Tokenization and vocabulary management&lt;/item&gt;
      &lt;item&gt;Gradient-based optimization with Adam&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Perfect for understanding how modern LLMs work under the hood!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;ndarray&lt;/code&gt;- N-dimensional arrays for matrix operations&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rand&lt;/code&gt;+&lt;code&gt;rand_distr&lt;/code&gt;- Random number generation for initialization&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No PyTorch, TensorFlow, or Candle - just pure Rust and linear algebra!&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! This project is perfect for learning and experimentation.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üè™ Model Persistence - Save/load trained parameters to disk (currently all in-memory)&lt;/item&gt;
      &lt;item&gt;‚ö° Performance optimizations - SIMD, parallel training, memory efficiency&lt;/item&gt;
      &lt;item&gt;üéØ Better sampling - Beam search, top-k/top-p, temperature scaling&lt;/item&gt;
      &lt;item&gt;üìä Evaluation metrics - Perplexity, benchmarks, training visualizations&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Advanced architectures (multi-head attention, positional encoding, RoPE)&lt;/item&gt;
      &lt;item&gt;Training improvements (different optimizers, learning rate schedules, regularization)&lt;/item&gt;
      &lt;item&gt;Data handling (larger datasets, tokenizer improvements, streaming)&lt;/item&gt;
      &lt;item&gt;Model analysis (attention visualization, gradient analysis, interpretability)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch: &lt;code&gt;git checkout -b feature/model-persistence&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Make your changes and add tests&lt;/item&gt;
      &lt;item&gt;Run the test suite: &lt;code&gt;cargo test&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Submit a pull request with a clear description&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Follow standard Rust conventions (&lt;code&gt;cargo fmt&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Add comprehensive tests for new features&lt;/item&gt;
      &lt;item&gt;Update documentation and README as needed&lt;/item&gt;
      &lt;item&gt;Keep the "from scratch" philosophy - avoid heavy ML dependencies&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üöÄ Beginner: Model save/load, more training data, config files&lt;/item&gt;
      &lt;item&gt;üî• Intermediate: Beam search, positional encodings, training checkpoints&lt;/item&gt;
      &lt;item&gt;‚ö° Advanced: Multi-head attention, layer parallelization, custom optimizations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Questions? Open an issue or start a discussion!&lt;/p&gt;
    &lt;p&gt;No PyTorch, TensorFlow, or Candle - just pure Rust and linear algebra!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45247890</guid><pubDate>Mon, 15 Sep 2025 09:47:18 +0000</pubDate></item><item><title>Denmark's Justice Minister calls encrypted messaging a false civil liberty</title><link>https://mastodon.social/@chatcontrol/115204439983078498</link><description>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45248802</guid><pubDate>Mon, 15 Sep 2025 12:21:21 +0000</pubDate></item><item><title>Pgstream: Postgres streaming logical replication with DDL changes</title><link>https://github.com/xataio/pgstream</link><description>&lt;doc fingerprint="d147b31acbab590"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;pgstream&lt;/code&gt; is an open source CDC command-line tool and library that offers Postgres replication support with DDL changes to any provided target.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Schema change tracking and replication of DDL changes&lt;/item&gt;
      &lt;item&gt;Support for multiple out of the box targets &lt;list rend="ul"&gt;&lt;item&gt;Elasticsearch/OpenSearch&lt;/item&gt;&lt;item&gt;Webhooks&lt;/item&gt;&lt;item&gt;PostgreSQL&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Initial and on demand PostgreSQL snapshots (for when you don't need continuous replication)&lt;/item&gt;
      &lt;item&gt;Column value transformations (anonymise your data on the go!)&lt;/item&gt;
      &lt;item&gt;Modular deployment configuration, only requires Postgres&lt;/item&gt;
      &lt;item&gt;Kafka support with schema based partitioning&lt;/item&gt;
      &lt;item&gt;Extendable support for custom targets&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;code&gt;pgstream&lt;/code&gt; can be used via the readily available CLI or as a library.&lt;/p&gt;
    &lt;p&gt;Binaries are available for Linux, macOS &amp;amp; Windows, check our Releases.&lt;/p&gt;
    &lt;p&gt;To install &lt;code&gt;pgstream&lt;/code&gt; from the source, run the following command:&lt;/p&gt;
    &lt;code&gt;go install github.com/xataio/pgstream@latest&lt;/code&gt;
    &lt;p&gt;To install &lt;code&gt;pgstream&lt;/code&gt; with homebrew, run the following command:&lt;/p&gt;
    &lt;code&gt;# macOS or Linux
brew tap xataio/pgstream
brew install pgstream&lt;/code&gt;
    &lt;p&gt;If you have an environment available, with at least Postgres and whichever module resources you're planning on running, then you can skip this step. Otherwise, a docker setup is available in this repository that starts Postgres, Kafka and OpenSearch (as well as OpenSearch dashboards for easy visualisation).&lt;/p&gt;
    &lt;code&gt;docker-compose -f build/docker/docker-compose.yml up
&lt;/code&gt;
    &lt;p&gt;The docker-compose file has profiles that can be used in order to bring up only the relevant containers. If for example you only want to run PostgreSQL to PostgreSQL pgstream replication you can use the &lt;code&gt;pg2pg&lt;/code&gt; profile as follows:&lt;/p&gt;
    &lt;code&gt;docker-compose -f build/docker/docker-compose.yml --profile pg2pg up
&lt;/code&gt;
    &lt;p&gt;You can also run multiple profiles. For example to start two PostgreSQL instances and Kafka:&lt;/p&gt;
    &lt;code&gt;docker-compose -f build/docker/docker-compose.yml --profile pg2pg --profile kafka up
&lt;/code&gt;
    &lt;p&gt;List of supported docker profiles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;pg2pg&lt;/item&gt;
      &lt;item&gt;pg2os&lt;/item&gt;
      &lt;item&gt;pg2webhook&lt;/item&gt;
      &lt;item&gt;kafka&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Pgstream source and target need to be configured appropriately before the commands can be run. This can be done:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Using the relevant CLI flags for each command&lt;/item&gt;
      &lt;item&gt;Using a yaml configuration file&lt;/item&gt;
      &lt;item&gt;Using environment variables (.env file supported)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check the documentation for more information about the configuration options, or check the help on the CLI for details on the available flags. Additionally, at the root of this repository you can find sample files for both .env and .yaml.&lt;/p&gt;
    &lt;p&gt;If you want to configure column transformations, leveraging greenmask, neosync and go-masker open source integrations, as well as custom transformers, check the transformation rules configuration for more details, along with the list of available transformers.&lt;/p&gt;
    &lt;p&gt;This will create the &lt;code&gt;pgstream&lt;/code&gt; schema in the configured Postgres database, along with the tables/functions/triggers required to keep track of the schema changes. See Tracking schema changes section for more details. It will also create a replication slot for the configured database which will be used by the pgstream service. If no replication slot name is provided, it will use a default one with the format &lt;code&gt;pgstream_&amp;lt;database&amp;gt;_slot&lt;/code&gt;.
This step can be skipped and &lt;code&gt;--init&lt;/code&gt; can be provided as an option to &lt;code&gt;run&lt;/code&gt; command. It will do the same preparation right before starting the replication.&lt;/p&gt;
    &lt;code&gt;# with CLI flags
pgstream init --postgres-url "postgres://postgres:postgres@localhost?sslmode=disable" --replication-slot test
# with yaml configuration file
pgstream init -c pg2pg.yaml
# with environment configuration file
pgstream init -c pg2pg.env&lt;/code&gt;
    &lt;p&gt;The status of the initalisation and the configuration can be checked by using the &lt;code&gt;status&lt;/code&gt; command.&lt;/p&gt;
    &lt;code&gt;pgstream status -c pg2pg.yaml
SUCCESS  pgstream status check encountered no issues
Initialisation status:
 - Pgstream schema exists: true
 - Pgstream schema_log table exists: true
 - Migration current version: 7
 - Migration status: success
 - Replication slot name: pgstream_postgres_slot
 - Replication slot plugin: wal2json
 - Replication slot database: postgres
Config status:
 - Valid: true
Transformation rules status:
 - Valid: true
Source status:
 - Reachable: true&lt;/code&gt;
    &lt;p&gt;If there are any issues or if you want to revert the pgstream setup, you can use the &lt;code&gt;destroy&lt;/code&gt; command to clean up all pgstream state.&lt;/p&gt;
    &lt;code&gt;pgstream destroy --postgres-url "postgres://postgres:postgres@localhost?sslmode=disable" --replication-slot test
# with yaml configuration file
pgstream destroy -c pg2pg.yaml
# with environment configuration file
pgstream destroy -c pg2pg.env&lt;/code&gt;
    &lt;p&gt;Run will start streaming data from the configured source into the configured target.&lt;/p&gt;
    &lt;p&gt;Example running pgstream replication from Postgres -&amp;gt; OpenSearch:&lt;/p&gt;
    &lt;code&gt;# using the environment configuration file
pgstream run -c pg2os.env --log-level trace
# using the yaml configuration file
pgstream run -c pg2os.yaml --log-level info
# using the CLI flags
pgstream run --source postgres --source-url "postgres://postgres:postgres@localhost:5432?sslmode=disable" --target opensearch --target-url "http://admin:admin@localhost:9200"&lt;/code&gt;
    &lt;p&gt;Example running pgstream with Postgres -&amp;gt; Kafka, and in a separate terminal, Kafka-&amp;gt;OpenSearch:&lt;/p&gt;
    &lt;code&gt;# using the environment configuration file
pgstream run -c pg2kafka.env --log-level trace
# using the yaml configuration file
pgstream run -c pg2kafka.yaml --log-level info
# using the CLI flags
pgstream run --source postgres --source-url "postgres://postgres:postgres@localhost:5432?sslmode=disable" --target kafka --target-url "localhost:9092"&lt;/code&gt;
    &lt;code&gt;# using the environment configuration file
pgstream run -c kafka2os.env --log-level trace
# using the yaml configuration file
pgstream run -c kafka2os.yaml --log-level info
# using the CLI flags
pgstream run --source kafka --source-url "localhost:9092" --target opensearch --target-url "http://admin:admin@localhost:9200"&lt;/code&gt;
    &lt;p&gt;Example running pgstream with PostgreSQL -&amp;gt; PostgreSQL with initial snapshot enabled:&lt;/p&gt;
    &lt;code&gt;# using the environment configuration file
pgstream run -c pg2pg.env --log-level trace
# using the yaml configuration file
pgstream run -c pg2pg.yaml --log-level info
# using the CLI flags
pgstream run --source postgres --source-url "postgres://postgres:postgres@localhost:5432?sslmode=disable" --target postgres --target-url "postgres://postgres:postgres@localhost:7654?sslmode=disable" --snapshot-tables test&lt;/code&gt;
    &lt;p&gt;Example running pgstream to perform a snapshot from PostgreSQL -&amp;gt; PostgreSQL:&lt;/p&gt;
    &lt;code&gt;# using the environment configuration file
pgstream snapshot -c snapshot2pg.env --log-level trace
# using the yaml configuration file
pgstream snapshot -c snapshot2pg.yaml --log-level info
# using the CLI flags
pgstream snapshot --postgres-url="postgres://postgres:postgres@localhost:5432?sslmode=disable" --target=postgres --target-url="postgres://postgres:postgres@localhost:7654?sslmode=disable" --tables="test" --reset&lt;/code&gt;
    &lt;p&gt;Pgstream will parse the configuration provided, and initialise the relevant modules. It requires at least one source(listener) and one target(processor).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PostgreSQL replication to PostgreSQL&lt;/item&gt;
      &lt;item&gt;PostgreSQL replication to OpenSearch&lt;/item&gt;
      &lt;item&gt;PostgreSQL replication to webhooks&lt;/item&gt;
      &lt;item&gt;PostgreSQL replication using Kafka&lt;/item&gt;
      &lt;item&gt;PostgreSQL snapshots&lt;/item&gt;
      &lt;item&gt;PostgreSQL column transformations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more advanced usage, implementation details, and detailed configuration settings, please refer to the full Documentation.&lt;/p&gt;
    &lt;p&gt;Datasets used: IMDB database, MusicBrainz database, Firenibble database.&lt;/p&gt;
    &lt;p&gt;All benchmarks were run using the same setup, with pgstream &lt;code&gt;v0.7.2&lt;/code&gt;, pg_dump/pg_restore (PostgreSQL) 17.4 and PostgreSQL 17.4, using identical resources to ensure a fair comparison.&lt;/p&gt;
    &lt;p&gt;For more details into performance benchmarking for snapshots to PostgreSQL with &lt;code&gt;pgstream&lt;/code&gt;, check out this blogpost.&lt;/p&gt;
    &lt;p&gt;Some of the limitations of the initial release include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single Kafka topic support&lt;/item&gt;
      &lt;item&gt;Postgres plugin support limited to &lt;code&gt;wal2json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;No row level filtering support&lt;/item&gt;
      &lt;item&gt;Primary key/unique not null column required for replication&lt;/item&gt;
      &lt;item&gt;Kafka serialisation support limited to JSON&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome contributions from the community! If you'd like to contribute to pgstream, please follow these guidelines and adhere to our code of conduct.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0 - see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;If you have any questions, encounter issues, or need assistance, open an issue in this repository our join our Discord, and our community will be happy to help.&lt;/p&gt;
    &lt;p&gt;Made with üíú by Xata ü¶ã&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45248868</guid><pubDate>Mon, 15 Sep 2025 12:28:24 +0000</pubDate></item><item><title>My First Year Without an iPhone</title><link>https://ktklp.substack.com/p/my-first-year-without-an-iphone</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45249113</guid><pubDate>Mon, 15 Sep 2025 12:57:28 +0000</pubDate></item><item><title>Hosting a website on a disposable vape</title><link>https://bogdanthegeek.github.io/blog/projects/vapeserver/</link><description>&lt;doc fingerprint="26b5c1054b922ae9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Hosting a WebSite on a Disposable Vape&lt;/head&gt;
    &lt;head rend="h1"&gt;Preface#&lt;/head&gt;
    &lt;p&gt;This article is NOT served from a web server running on a disposable vape. If you want to see the real deal, click here. The content is otherwise identical.&lt;/p&gt;
    &lt;head rend="h1"&gt;Background#&lt;/head&gt;
    &lt;p&gt;For a couple of years now, I have been collecting disposable vapes from friends and family. Initially, I only salvaged the batteries for ‚Äúfuture‚Äù projects (It‚Äôs not hoarding, I promise), but recently, disposable vapes have gotten more advanced. I wouldn‚Äôt want to be the lawyer who one day will have to argue how a device with USB C and a rechargeable battery can be classified as ‚Äúdisposable‚Äù. Thankfully, I don‚Äôt plan on pursuing law anytime soon.&lt;/p&gt;
    &lt;p&gt;Last year, I was tearing apart some of these fancier pacifiers for adults when I noticed something that caught my eye, instead of the expected black blob of goo hiding some ASIC (Application Specific Integrated Circuit) I see a little integrated circuit inscribed ‚ÄúPUYA‚Äù. I don‚Äôt blame you if this name doesn‚Äôt excite you as much it does me, most people have never heard of them. They are most well known for their flash chips, but I first came across them after reading Jay Carlson‚Äôs blog post about the cheapest flash microcontroller you can buy. They are quite capable little ARM Cortex-M0+ micros.&lt;/p&gt;
    &lt;p&gt;Over the past year I have collected quite a few of these PY32 based vapes, all of them from different models of vape from the same manufacturer. It‚Äôs not my place to do free advertising for big tobacco, so I won‚Äôt mention the brand I got it from, but if anyone who worked on designing them reads this, thanks for labeling the debug pins!&lt;/p&gt;
    &lt;head rend="h1"&gt;What are we working with#&lt;/head&gt;
    &lt;p&gt;The chip is marked &lt;code&gt;PUYA C642F15&lt;/code&gt;, which wasn‚Äôt very helpful. I was pretty sure it was a &lt;code&gt;PY32F002A&lt;/code&gt;, but after poking around with pyOCD, I noticed that the flash was 24k and we have 3k of RAM. The extra flash meant that it was more likely a &lt;code&gt;PY32F002B&lt;/code&gt;, which is actually a very different chip.1&lt;/p&gt;
    &lt;p&gt;So here are the specs of a microcontroller so bad, it‚Äôs basically disposable:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;24MHz Coretex M0+&lt;/item&gt;
      &lt;item&gt;24KiB of Flash Storage&lt;/item&gt;
      &lt;item&gt;3KiB of Static RAM&lt;/item&gt;
      &lt;item&gt;a few peripherals, none of which we will use.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You may look at those specs and think that it‚Äôs not much to work with. I don‚Äôt blame you, a 10y old phone can barely load google, and this is about 100x slower. I on the other hand see a blazingly fast web server.&lt;/p&gt;
    &lt;head rend="h1"&gt;Getting online#&lt;/head&gt;
    &lt;p&gt;The idea of hosting a web server on a vape didn‚Äôt come to me instantly. In fact, I have been playing around with them for a while, but after writing my post on semihosting, the penny dropped.&lt;/p&gt;
    &lt;p&gt;If you don‚Äôt feel like reading that article, semihosting is basically syscalls for embedded ARM microcontrollers. You throw some values/pointers into some registers and call a breakpoint instruction. An attached debugger interprets the values in the registers and performs certain actions. Most people just use this to get some logs printed from the microcontroller, but they are actually bi-directional.&lt;/p&gt;
    &lt;p&gt;If you are older than me, you might remember a time before Wi-Fi and Ethernet, the dark ages, when you had to use dial-up modems to get online. You might also know that the ghosts of those modems still linger all around us. Almost all USB serial devices actually emulate those modems: a 56k modem is just 57600 baud serial device. Data between some of these modems was transmitted using a protocol called SLIP (Serial Line Internet Protocol).2&lt;/p&gt;
    &lt;p&gt;This may not come as a surprise, but Linux (and with some tweaking even macOS) supports SLIP. The &lt;code&gt;slattach&lt;/code&gt; utility can make any &lt;code&gt;/dev/tty*&lt;/code&gt; send and receive IP packets. All we have to do is put the data down the wire in the right format and provide a virtual tty.
This is actually easier than you might imagine, pyOCD can forward all semihosting though a telnet port. Then, we use &lt;code&gt;socat&lt;/code&gt; to link that port to a virtual tty:&lt;/p&gt;
    &lt;code&gt;pyocd gdb -S -O semihost_console_type=telnet -T $(PORT) $(PYOCDFLAGS) &amp;amp;
socat PTY,link=$(TTY),raw,echo=0 TCP:localhost:$(PORT),nodelay &amp;amp;
sudo slattach -L -p slip -s 115200 $(TTY) &amp;amp;
sudo ip addr add 192.168.190.1 peer 192.168.190.2/24 dev sl0
sudo ip link set mtu 1500 up dev sl0
&lt;/code&gt;
    &lt;p&gt;Ok, so we have a ‚Äúmodem‚Äù, but that‚Äôs hardly a web server. To actually talk TCP/IP, we need an IP stack. There are many choices, but I went with uIP because it‚Äôs pretty small, doesn‚Äôt require an RTOS, and it‚Äôs easy to port to other platforms. It also, helpfully, comes with a very minimal HTTP server example.&lt;/p&gt;
    &lt;p&gt;After porting the SLIP code to use semihosting, I had a working web server&amp;amp;mldr;half of the time. As with most highly optimised libraries, uIP was designed for 8 and 16-bit machines, which rarely have memory alignment requirements. On ARM however, if you dereference a &lt;code&gt;u16 *&lt;/code&gt;, you better hope that address is even, or you‚Äôll get an exception. The &lt;code&gt;uip_chksum&lt;/code&gt; assumed &lt;code&gt;u16&lt;/code&gt; alignment, but the script that creates the filesystem didn‚Äôt.
I actually decided to modify a bit the structure of the filesystem to make it a bit more portable.
This was my first time working with &lt;code&gt;perl&lt;/code&gt; and I have to say, it‚Äôs quite well suited to this kind of task.&lt;/p&gt;
    &lt;head rend="h1"&gt;Blazingly fast#&lt;/head&gt;
    &lt;p&gt;So how fast is a web server running on a disposable microcontroller. Well, initially, not very fast. Pings took ~1.5s with 50% packet loss and a simple page took over 20s to load. That‚Äôs so bad, it‚Äôs actually funny, and I kind of wanted to leave it there.&lt;/p&gt;
    &lt;p&gt;However, the problem was actually between the seat and the steering wheel the whole time. The first implementation read and wrote a single character at a time, which had a massive overhead associated with it. I previously benchmarked semihosting on this device, and I was getting ~20KiB/s, but uIP‚Äôs SLIP implementation was designed for very low memory devices, so it was serialising the data byte by byte. We have a whopping 3kiB of RAM to play with, so I added a ring buffer to cache reads from the host and feed them into the SLIP poll function. I also split writes in batches to allow for escaping.&lt;/p&gt;
    &lt;p&gt;Now this is what I call blazingly fast! Pings now take 20ms, no packet loss and a full page loads in about 160ms. This was using using almost all of the RAM, but I could also dial down the sizes of the buffer to have more than enough headroom to run other tasks. The project repo has everything set to a nice balance latency and RAM usage:&lt;/p&gt;
    &lt;code&gt;Memory region         Used Size  Region Size  %age Used
           FLASH:        5116 B        24 KB     20.82%
             RAM:        1380 B         3 KB     44.92%
&lt;/code&gt;
    &lt;p&gt;For this blog however, I paid for none of the RAM, so I‚Äôll use all of the RAM.&lt;/p&gt;
    &lt;p&gt;As you may have noticed, we have just under 20kiB (80%) of storage space. That may not be enough to ship all of React, but as you can see, it‚Äôs more than enough to host this entire blog post. And this is not just a static page server, you can run any server-side code you want, if you know C that is.&lt;/p&gt;
    &lt;p&gt;Just for fun, I added a json api endpoint to get the number of requests to the main page (since the last crash) and the unique ID of the microcontroller.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45249287</guid><pubDate>Mon, 15 Sep 2025 13:13:49 +0000</pubDate></item><item><title>The Obsolescence of Political Definitions</title><link>http://vmchale.com/static/serve/taxonomy.html</link><description>&lt;doc fingerprint="3f82d39934a18ba0"&gt;
  &lt;main&gt;
    &lt;p&gt;14 Aug.√Ç 2025&lt;/p&gt;
    &lt;p&gt;I am not qualified to translate German, much less technical philosophical texts. However, Kondylis√¢ insights are criminally underappreciated and of interest to many today as they grapple with the dissolution of liberalism that Kondylis predicted in 1991√¢1992.&lt;/p&gt;
    &lt;p&gt;Hopefully, his work will be translated with due care as its centrality is appreciated.&lt;/p&gt;
    &lt;p&gt;The below is from Planetarische Politik Nach Dem Kalten Krieg, pp.√Ç 91√¢104&lt;/p&gt;
    &lt;p&gt;In the early days of the failed Moscow coup, one was bombarded by writing wherein the √¢conservatives√¢ from the KGB and communist party wanted to block the path to a market economy and parliamentarianism. Many outlets that were once marked √¢Stalinist√¢ or √¢orthodox communist√¢ were attacked as √¢conservative,√¢ blithely referred to as such often on the same page that political figures such as Reagan or Thatcher, Bush or Kohl. Thus the na√É¬Øve reader, who wants to take the printed word at its nominal value, logically infers a common attitude and purpose among the previously named Western politicians and the soviet enemies of perestroika. Common sense could protect the sane man from such an absurdity, but this runs out of answers in the face of the schizophrenia of political vocabulary, proving insufficiently idiosyncratic; he seems to have resigned himself without grumbling. The common retort is that conservatives are defenders of the status quo, whatever that may look like in the particular case, so conservatives living in very different societies, unsurprisingly, advocate very different and even contradictory programs. But if political classifications are not backed by political substance, then these classifications must be grounded in psychological or anthropological factors, common attitudes towards life. Should one, in good conscience, impute the commonalities between Helmut Kohl and the Russian putschists, this interpretational hypothesis brings little light to the concrete situations√¢because in such situations it is always about the implementation of particular matters or goals thereby defined, in view of the makeup of a national or international collective, wherein the friend-foe groupings are determined by the positions of each agent with respect to these matters and goals. The legitimation of political struggle often takes place by appeal to anthropological presumptions; political analysis, on the other hand, can infer no concrete substance from formal and inherently abstract anthropological constants without falling into bad metaphysics.&lt;/p&gt;
    &lt;p&gt;The above applies not only to the definition of conservatism√¢the journalistic and even scientific parlance is no less confused when we turn to the other foundational definitions, where the political vocabulary of the last hundred-fifty years has been contorted. The ambiguity accompanies political√¢though not only political√¢ground definitions from the very beginning. This is hardly avoidable, by virtue of the polemical usage of these definitions, though it is different from the lack of reference or amorphism that indicates historical downfall. So long as definitions are living and afforded gravity in the social sphere, they can be positive or negative, narrowly or widely interpreted, varied according to particular strategic or tactical necessities, ultimately, however they refer explicitly or implicitly to an identifiable bearer. √¢Conservatism√¢ in the 19th century meant primarily the sociopolitical interests of the antiliberal aristocrats and the patriarchal estates who felt threatened by the progress of industrial capitalism. The purveyors of what is called √¢conservatism√¢ today are advocates for planned economies and dictators in the East, supporters of market economies and parliamentarianism in the West, ecologically motivated guardians of untouched nature, religious opponents of miniskirts√¢¬¶ to mention a few. √¢Liberal√¢ originally referred to a politics that articulated the economic or constitutional agenda of the bourgeoisie, not a petitioner for abortion freedom or the unrestricted right to asylum. That this vocabulary does not bind testifies to its obsolescence. Indeed, politics in the 20th century was largely played out in symbolic definitions that had lost their original historical meaning. This might appear plainly to the impartial observer, but the actors needed the vocabulary of the 19th century for polemical purposes√¢the long struggle between the Western system and communism contributed significantly to the dissemination of language that had no real parallel in either camp. This is why the emptiness of political language reveals itself just at the end of the Cold War.&lt;/p&gt;
    &lt;p&gt;The three fundamental definitions in the political vocabulary of the last hundred-fifty years, namely, √¢conservatism,√¢ √¢liberalism,√¢ and √¢socialism,√¢ (or social democracy), embodied three real and unambiguous options for society only at the time of their (incidentally almost parallel) development. Only around 1848 did the aristocracy, bourgeoisie, and proletariat face one another on a single playing field. The triptych dwindled over the 19th century into a diptych, when the already weakened aristocracy largely merged with the bourgeoisie, giving up their patriarchal landownership nolens volens and participating in the capitalist economy and parliament in various degrees and ways. Once the stasis of societas civilis had given way to the dynamism of capitalism, conservatism could no longer discuss the preservation of a God-given and eternal hierarchical order on Earth in a genuine sense. If the notion of conservatism nevertheless remained alive, it was less by to the vitality of its natural social vectors and more the polemical force of its triumphant adversaries. Above all, the left was now ideologically interested in putting down their bourgeois liberal opponents as apostates fleeing their own √¢progressive√¢ past and heirs to √¢obscurantist√¢ or √¢reactionary√¢ positions and practices that allegedly marked the doings of the √¢feudal party.√¢ √¢Conservative√¢ was defined as an opponent of the left; √¢conservatism√¢ was defined by the extent to which something contradicted the left√¢s objectives, whether or not it actually altered society. Because the left possessed a monopoly on progress by definition, changing society in a direction contrary to the left√¢s wishes could not be recognized as √¢real√¢ change. This way of thinking was in force for decades not only in international affairs curricula; the established √¢progressive√¢ political science and sociology in Germany also helped establish the notion that conservatism is not a historically bound term, but rather a stance that redefines itself in every context. Especially in a time in which philistine discipleship (that is, when all back doors were left open) was intellectually chic, it was emphasized that that the political scientists of the Eastern bloc shared in this belief.&lt;/p&gt;
    &lt;p&gt;The liberals, for their part, had to appropriate the concept of conservatism when they saw that the original bourgeois sense of liberalism had been eclipsed as its reinterpretation for anti-bourgeois democratic-egalitarian purposes was steadily gaining ground. √¢Conservative√¢ now referred to the thought and sociopolitical practice of classical liberalism that wanted to explicitly distinguish itself from egalitarian socialist-democratic efforts, which often came with the claim to administer the √¢real√¢ legacy of liberalism and to bring √¢genuine√¢ liberal thought to its logical conclusion, in which material equality followed from formal rights and social equality from equal rights. Under these circumstances and in light of this reinterpretation, liberalism would have appeared suspicious to the classical liberals themselves, who thought in bourgeois categories. The great slogans of freedom and equality being propagated by the 17th century in fact allowed extensive interpretation with some goodwill, but it was only in the 19th century that these possibilities were fully appreciated. The originators of the aforementioned slogans thought only of the elimination of the old feudal barriers and hierarchies, while the social inequality that would be the point of contention for later democrats was fully natural in their eyes. They could hardly have imagined that full recognition of natural rights would entail that lords would not be lords and peasants would not be peasants; recall the debates of the 19th century on suffrage to clarify this point. In any case, it came to approve dirigiste tendencies and tendencies toward a social welfare state, drawing on an ethically charged concept of liberalism, bearing in mind the significance of the individual in the liberal framework of thought. Thus it was now of chief importance that the individual should have the protection of the state through state intercession and by this be guaranteed his free and general development. This, of course, was a drastic reinterpretation of classical liberalism√¢s conception of individualism, but we are not interested in legitimacy here but the fact that it was undertaken and did influence politics in practice. The more mass society shaped by the bourgeoisie converged to modern mass democracy, the closer the association between the concept of liberalism and the partly ethical-dirigiste, partly radical individualist and culture revolutionary tendencies. For apparent socio-historical reasons this linguistic usage only does justice to the situation in the United States, while in Europe the ambiguity remained.&lt;/p&gt;
    &lt;p&gt;Thus, in the 20th century the notion of conservatism was harnessed for liberal purposes and the notion of liberalism for overall anti-bourgeois politics. Over the course of time the concept of socialism or social democracy became just as ambiguous and chameleonic. The Bolshevik ascent to power was not capable of unifying the already extant socialisms under a single banner, nor giving the idea of socialism canonical and unambiguous contents. To the contrary, it brought about the decisive split of the socialist movement into reformist and revolutionary wings. The unfolding of communism in many regions of the third world came in the form of regimes decorating themselves with the √¢socialist√¢ label though they were nothing more than nationalist dictatorships despite the ideological mask. The reformist socialism coined in the West, for its part, was tied into the aforementioned ethical reinterpretation of liberal-individualist platitudes, while apostate Marxists (or Marxist-Leninists) sought to remove √¢Stalinism√¢ as theory and practice and summon √¢unsullied√¢ socialism, a game with ever more variations, which long since has become confusing√¢and boring.&lt;/p&gt;
    &lt;p&gt;We are already at the question of the checkered history of political vocabulary. The Cold War not only at times caused the ambiguity and hollowness of the concept of socialism, it at other times promoted it. Similar effects took place on the semantic content of liberalism and conservatism. In its new function as counter to √¢totalitarianism,√¢ liberalism meant additionally liberal capitalism and thereby private ownership of the means of production. The focus was not put on this prosaic fact, which incidentally was denigrated by opponents as mere √¢capitalist rule,√¢ but rather on the opportunities for the development of society and the individual bound up in liberal capitalism. Liberalism consisted in principle of unbounded renewal and openness, tolerance and human dignity√¢in short, freedom writ large. This same freedom came to mean the notion of democracy as a synonym for liberalism and the contrast between √¢communist tyrants√¢ and √¢Western democracy.√¢ √¢Liberalism√¢ and √¢democracy√¢ were conceived more as values and norms than defined by concrete social relations and forms of government. On the other hand, the communist use of √¢conservatism√¢ or √¢reaction√¢ to describe the system of √¢state-monopoly capitalism,√¢ that, in their view, was not capable of material progress and instead condemned to perpetual crisis and sacrificed the development of society and the individual to blind striving for profits for the ruling cadre. Interestingly those who otherwise called themselves anticommunist √¢liberals√¢ or √¢democrats√¢ declared themselves √¢conservative√¢ to convey the defense of eternal truth and eternal values that communism threatened. The anticommunist declaration of √¢conservatism√¢ became more concrete in the matter of defending against those inside the Western nations pursuing the aforementioned democratic reinterpretation of liberalism and thereby rightly or wrongly accused of being followers of the communists.&lt;/p&gt;
    &lt;p&gt;After the end of the Cold War everyone must now know that the communist and leftist diagnosis of √¢conservatism√¢ or even √¢reactionary√¢ nature of the Western system in the large industrialized developed nations after the Second World War is not only indefensible but downright empty. One can and must reject this system on many different aesthetic or ethical grounds√¢but not because it is √¢conservative√¢ i.e.√Ç that it curbs technological progress and thereby the concomitant reconfiguration of society. Judging impartially and taking technological progress, opportunities for consumption, and freedom as values, one cannot deny the superiority of the West in these areas. The accusation of √¢conservatism√¢ was nonsensically directed at a system that revolutionized the progress in production to an extent never before seen in history and made material and ideal opportunities that we also wondrous world-historical firsts available to the individual. When many bearers or supporters of this system still want to call themselves √¢conservative,√¢ the reason lies partly in the previously mentioned polemical requirements, but also partly in their ethical-ideological self-understanding that does not wish to face the realization that this system has long been living off steadily decaying old values√¢it lives on what was called √¢hubris√¢ in conservative times. But regardless of what such √¢conservatives√¢ will be called in the future, the victory of the West in the Cold War will reduce √¢progressives√¢ of all colors to silence or at least jumble the vocabulary, as it now seems hardly plausible to connect the most vital or in any case victorious system with sluggish conservatism. The activity of √¢progressive√¢ intellectuals consists above all of incessant discourse, so for them the sudden revolution in familiar vocabulary is particularly hard to bear. Even so, over the last few years in Germany, √¢conservatism√¢ has been used less and less in a pejorative sense and more and more halfheartedly.&lt;/p&gt;
    &lt;p&gt;We have thus arrived at a point where a very important terminological and factual question must be touched upon. While it is incorrect to understand the end of the Cold War is a victory of the conservative West over the revolutionary East, it is similarly an optical illusion to celebrate the collapse of communism as the crowning of liberalism. This can only be said when one understands √¢liberalism√¢ as the counter to √¢totalitarianism√¢ as was customary during the Cold War. We foreshadowed already that this comparison did not do justice to the specifically bourgeois meaning of liberalism. This was in no way an accident. Over the course of the previously discussed democratic reinterpretation of the concept of liberalism has considerably diluted the bourgeois content of classical liberalism following the Second World War, without a doubt the related gradual social decline of the bourgeoisie. Bourgeois mass society found itself already on the way to modern mass democracy, as the mechanization of the everyday set in and the worker-as-consumer came on the scene. This decisive turn came only after the Second World War and to a massive breakthrough under the influence of the Cold War. Thus, despite the long acting socio-historical tendencies, the reinterpretation of bourgeois liberal mass society in modern mass democracy was (also) promoted and accelerated by the attempt to prevent the danger of a communist seizure of power through rapidly rising the standards of living for the masses. These events occurred with a large-scale democratization in all areas and with the emergence of new elites in both industry and politics who largely displaced or took over; their own composition, by the way, changes much more quickly than earlier ruling groups as a result of generally increased social mobility. Managers, technocrats, and yuppies are something essentially different as sociological types and in sociological function compared to the bourgeoisie; bourgeois lifestyle today, if one appreciates the full picture, fulfills the same picturesque-mundane duties that many remnants of the historical aristocracy once handled. Permissiveness bound with the parallel leveling of hierarchies and authority and democratization paints a picture that could only be described as a bourgeois-liberal society by misapprehension of central sociological and intellectual historical factors. The modern mass democracy is indeed born from bourgeois society, but it constitutes a structurally new societal formation. For this reason, the political vocabulary that formed in the bourgeois era has lost its real contents and meaning. Despite this, competing elites still need to use it for lack of another, in order to ideologize their practical concerns, to differentiate themselves from one another symbolically and thereby make themselves more interesting.&lt;/p&gt;
    &lt;p&gt;Thus the West defeated the East only when the bourgeois class society lost ground to mass democracy, at which point the communist critique of capitalism became obsolete and unattractive. Framed as a paradox: the farewell to utopia in the East followed the development of utopia in the West. In fact, Western mass democracy overcame the scarcity of goods for the first time in history and achieved a structuring of society by criteria of achievement. Thus, equality was generally achieved resting on extreme atomization, while at the same time the self-realization of the individual was declared to be of chief importance to the state. Gaps and seedy underbellies in this picture are well known, but they do not change the fact that this√¢twisted, grotesque, burlesque, what have you√¢realization of utopia ultimately took the wind out of the sails of critics of liberalism and capitalism. Modern mass democracy made the notions √¢conservatism,√¢ √¢liberalism,√¢ and √¢socialism√¢ irrelevant all in one fell swoop. Through the extreme atomization of society and unbounded mobility, which it requires by nature to function, the large collective subjects bound to each definition were dissolved, as they possessed no concrete referent. The fate of these communities was rooted in their common pedigree and career path. They originated during the historical transformation from societas civilis to mass society or from agrarian to industrialized civilization, and they gave answers to the big questions for different socio-political standpoints and worldviews. The process that we speak of here began with the devout submission of man under God and ended with his proud mastery of nature; he arranged the cardinal classification of individuals in a state and ended up with the atomization of society; he went from solidly hierarchical heavenly and earthly substance and was discharged into any desired combination of roles. These key words contain the central questions of modern times, as they have been specified in the particular problems of philosophy and social theory. In this respect, conservatism, liberalism, and socialism fit within the modern era in a particular way, and therefore the appraisal of the growing meaninglessness and irreality of these definitions during our century must raise that question of whether the modern era has arrived at its end. In this vein, the dissolution of Marxism cannot be interpreted simply as the victory of liberal ideas. Marxism took its fundamental premises from liberalism: the endeavor to synthesize economics and humanism, wanting to understand the history of the world in terms of progress. From this point of view, the defeat of Marxism means the elimination of the last systematically organized remnant of liberal humanism and the final victory of a way of thinking that one can provisionally call postmodern, with regards towards its mass democratic roots and functions.&lt;/p&gt;
    &lt;p&gt;The understanding of the obsolescence of political vocabulary following the victory of Western mass democracy over communism is not just indispensable for academic purposes√¢planetary politics in the future will be fashioned by the background fact that participants will take mass democratic values and goals to heart, from the quantitative steadily rising standard of living to the qualitative equalization of opportunity and consumption, not only interior to the particular nations but also in the relations of nations with one another. This means that economic questions and disputes will be given more political weight, that the political will be increasingly understood and implemented with consideration of the economic, while the traditional foremost questions about the best state and best constitution will move to the background. Remarkably, nearly worldwide agreement on these questions has set in following the Cold War; there is a willingness to imitate the political institutions of the West in this or that variation. This goes with the economization of the political, insofar as these institutions are assumed to foster economic progress. At the same time, important problems, such as ecological problems or the problem of overpopulation, appearing on the horizon of a planet that has become constricted, cannot be grasped nor handled within the categories of conservatism, liberalism, and socialism. Survival has been a question of organization for a long time now; freedom in mass societies can easily lead to disintegration or explosions, while rigorous planning can bear ills that it cannot heal from. It would therefore be wishful thinking to suggest the inevitable dissolution of the traditional political definitions via the economization of the political would eliminate conflict between interest groups or even temper it. Without a doubt politics will be largely de-ideologized, that is, the influence of those ideologies that legitimized political acts since the French revolution will be diminished or rolled back. It is shortsighted to attribute the political struggle of the past two hundred years to ideological fanaticism and to ex contrario prophesize the end of conflict following the √¢end of ideology.√¢ De-ideologized conflicts might be even more violent, should some particular goods prove to be in short supply, if overcoming the scarcity of goods is deemed to be of chief importance to humankind. De-ideologization and the economization of the political ultimately mean that material goods will be fought for without any important ideology as mediator. One must then recognize de-ideologization as a partial reversion to animality. Admittedly it remains a matter of taste whether it is beautiful and preferable that the farewell to utopia goes so far.&lt;/p&gt;
    &lt;p&gt;(Kondylis 1992, 91√¢104)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45249500</guid><pubDate>Mon, 15 Sep 2025 13:29:50 +0000</pubDate></item><item><title>Show HN: Semlib ‚Äì Semantic Data Processing</title><link>https://github.com/anishathalye/semlib</link><description>&lt;doc fingerprint="58478597d03e509c"&gt;
  &lt;main&gt;
    &lt;p&gt;Semlib is a Python library for building data processing and data analysis pipelines that leverage the power of large language models (LLMs). Semlib provides, as building blocks, familiar functional programming primitives like &lt;code&gt;map&lt;/code&gt;, &lt;code&gt;reduce&lt;/code&gt;, &lt;code&gt;sort&lt;/code&gt;, and &lt;code&gt;filter&lt;/code&gt;, but with a twist: Semlib's implementation of these operations are programmed with natural language descriptions rather than code. Under the hood, Semlib handles complexities such as prompting, parsing, concurrency control, caching, and cost tracking.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;pip install semlib&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;üìñ API Reference ‚¨Ä ü§î Rationale üí° Examples ‚¨Ä&lt;/p&gt;
    &lt;code&gt;&amp;gt;&amp;gt;&amp;gt; presidents = await prompt(
...     "Who were the 39th through 42nd presidents of the United States?",
...     return_type=Bare(list[str])
... )

&amp;gt;&amp;gt;&amp;gt; await sort(presidents, by="right-leaning")
['Jimmy Carter', 'Bill Clinton', 'George H. W. Bush', 'Ronald Reagan']

&amp;gt;&amp;gt;&amp;gt; await find(presidents, by="former actor")
'Ronald Reagan'

&amp;gt;&amp;gt;&amp;gt; await map(
...     presidents,
...     "How old was {} when he took office?",
...     return_type=Bare(int),
... )
[52, 69, 64, 46]&lt;/code&gt;
    &lt;p&gt;Large language models are great at natural-language data processing and data analysis tasks, but when you have a large amount of data, you can't get high-quality results by just dumping all the data into a long-context LLM and asking it to complete a complex task in a single shot. Even with today's reasoning models and agents, this approach doesn't give great results.&lt;/p&gt;
    &lt;p&gt;This library provides an alternative. You can structure your computation using the building blocks that Semlib provides: functional programming primitives upgraded to handle semantic operations. This approach has a number of benefits.&lt;/p&gt;
    &lt;p&gt;Quality. By breaking down a sophisticated data processing task into simpler steps that are solved by today's LLMs, you can get higher-quality results, even in situations where today's LLMs might be capable of processing the data in a single shot and ending up with barely acceptable results. (example: analyzing support tickets in Airline Support Report)&lt;/p&gt;
    &lt;p&gt;Feasibility. Even long-context LLMs have limitations (e.g., 1M tokens in today's frontier models). Furthermore, performance often drops off with longer inputs. By breaking down the data processing task into smaller steps, you can handle arbitrary-sized data. (example: sorting an arbitrary number of arXiv papers in arXiv Paper Recommendations)&lt;/p&gt;
    &lt;p&gt;Latency. By breaking down the computation into smaller pieces and structuring it using functional programming primitives like &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;reduce&lt;/code&gt;, the parts of the computation can be run concurrently, reducing the latency of the overall computation.
(example: tree reduce with O(log n) computation depth in Disneyland Reviews Synthesis)&lt;/p&gt;
    &lt;p&gt;Cost. By breaking down the computation into simpler sub-tasks, you can use smaller and cheaper models that are capable of solving those sub-tasks, which can reduce data processing costs. Furthermore, you can choose the model on a per-subtask basis, allowing you to further optimize costs. (example: using &lt;code&gt;gpt-4.1-nano&lt;/code&gt; for the pre-filtering step in arXiv Paper Recommendations)&lt;/p&gt;
    &lt;p&gt;Security. By breaking down the computation into tasks that simpler models can handle, you can use open models that you host yourself, allowing you to process sensitive data without having to trust a third party. (example: using &lt;code&gt;gpt-oss&lt;/code&gt; and &lt;code&gt;qwen3&lt;/code&gt; in Resume Filtering)&lt;/p&gt;
    &lt;p&gt;Flexibility. LLMs are great at certain tasks, like natural-language processing. They're not so great at other tasks, like multiplying numbers. Using Semlib, you can break down your data processing task into multiple steps, some of which use LLMs and others that just use regular old Python code, getting the best of both worlds. (example: Python code for filtering in Resume Filtering)&lt;/p&gt;
    &lt;p&gt;Read more about the rationale, the story behind this library, and related work in the blog post.&lt;/p&gt;
    &lt;p&gt;If you use Semlib in any way in academic work, please cite the following:&lt;/p&gt;
    &lt;code&gt;@misc{athalye:semlib,
  author = {Anish Athalye},
  title = {{Semlib}: LLM-powered data processing for {Python}},
  year = {2025},
  howpublished = {\url{https://github.com/anishathalye/semlib}},
}&lt;/code&gt;
    &lt;p&gt;Copyright (c) Anish Athalye. Released under the MIT License. See LICENSE.md for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45249697</guid><pubDate>Mon, 15 Sep 2025 13:45:56 +0000</pubDate></item><item><title>CubeSats are fascinating learning tools for space</title><link>https://www.jeffgeerling.com/blog/2025/cubesats-are-fascinating-learning-tools-space</link><description>&lt;doc fingerprint="b535155168e585d4"&gt;
  &lt;main&gt;
    &lt;p&gt;These are CubeSats. Satellites that are going to space‚Äîor at least, the ones I have here are prototypes. But these have one thing in common: they're all powered by either a Raspberry Pi, or a microcontroller.&lt;/p&gt;
    &lt;p&gt;There are already Pis in space, like on Mark Rober's SatGus, on GASPACS, and the Astro Pis on the Space station. Another Pi is going up this weekend, which is why I'm posting this today. I'll get to that one, but I wanted to spend some time talking about two things that fascinate me: Raspberry Pis, and putting them space!&lt;/p&gt;
    &lt;p&gt;In this post, I'll cover:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What is a CubeSat&lt;/item&gt;
      &lt;item&gt;Who builds and launches CubeSats&lt;/item&gt;
      &lt;item&gt;How you can build your own CubeSat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then for a bonus, in today's video, I interviewed two people helping students launch SilverSat into space (this weekend!), and a YouTuber who I've learned a lot from about track satellites (including CubeSats) from your own backyard!&lt;/p&gt;
    &lt;p&gt;The rest of this post contains a lightly-edited transcript of the video above.&lt;/p&gt;
    &lt;p&gt;So let's dive in.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's a CubeSat?&lt;/head&gt;
    &lt;p&gt;What's a CubeSat? Well, it's in the name‚Äîit's a satellite that's a cube!&lt;/p&gt;
    &lt;p&gt;But they don't have to be a cube, these smallest ones are '1U', or 10 x 10 x 10 centimeters. You can also find 2U CubeSats, like the taller Build a CubeSat, which is 20 centimeters tall. (Well, technically the current prototype is 1.5U).&lt;/p&gt;
    &lt;p&gt;SatGus, Mark Rober's satellite taking space selfies, is a whopping 12U! They needed all that extra space to fit a phone, a mechanism to deploy the phone, a camera to take the selfie, a Raspberry Pi to control the phone, and redundant systems for everything. They've already taken thousands of selfies, and SatGus has me beat. My best Pi might get to 3.4 Gigahertz, but the Pi on SatGus is whizzing through space at almost 17,000 miles per hour. That's 7,570 meters per second for everyone else in the world.&lt;/p&gt;
    &lt;p&gt;But back to CubeSats. Having standards means you can build off existing work for the hard things, like a space-rated Aluminum frame, or the complex EPS, or Electrical Power System board.&lt;/p&gt;
    &lt;p&gt;Then you can add in custom parts, like a Pi to run experiments, a communications board with antennas and radios, cameras, sensors, and more!&lt;/p&gt;
    &lt;p&gt;And these cubesats have normal screw-on antennas, but the way these things are deployed, you only get 10x10x10 centimeters‚Äîyou can't have an antenna poking out the top. So they use cool things like flexible tape antennas that pop out once your CubeSat deploys.&lt;/p&gt;
    &lt;p&gt;What else makes CubeSats cool?&lt;/p&gt;
    &lt;p&gt;Well, how about price? In the old days, you had to have like $10 million to build a satellite, and $60+ million to launch it into space.&lt;/p&gt;
    &lt;p&gt;Today, you can build a space-ready CubeSat using a few thousand dollars of parts. Then you can launch it on a rideshare for... well, $85 grand. Which is a lot, but it's not $60 million-a-lot.&lt;/p&gt;
    &lt;p&gt;So most of us won't be launching one of these things into space, unless maybe you can get a grant. But that doesn't mean they're not useful to us.&lt;/p&gt;
    &lt;head rend="h2"&gt;Who builds CubeSats?&lt;/head&gt;
    &lt;p&gt;Like with many projects, I love these things for the challenge, the way they break some of my assumptions, like working with Raspberry Pis.&lt;/p&gt;
    &lt;p&gt;If you're building a device that's less than 2 kilograms, has 1.8W of maximum continuous power draw, and needs to be operated remotely‚Äîeven for just a month‚Äîyou're immediately going to change your assumptions about how you build things.&lt;/p&gt;
    &lt;p&gt;I would hack Home Assistant onto a mini PC to monitor some sensors if I was feeling lazy‚Äîbut that Mini PC would use an order of magnitude too much power for a CubeSat (much less the internal volume it would occupy).&lt;/p&gt;
    &lt;p&gt;On CubeSats, every millimeter, and every milliAmp has to be accounted for.&lt;/p&gt;
    &lt;p&gt;So to me, CubeSats are like Swiss watches of modern electronics. How many sensors can you fit in one? How much throughput can you get on a tiny radio with a small antenna? Can you get enough power out of tiny solar cells to keep the main flight computer working? How do you control thermals without air? How do you design it so it can recover from a complete power loss?&lt;/p&gt;
    &lt;p&gt;Every step of the way there are challenges; and that's before we even launch one! Someone who I think illustrates this best is Manuel, with his Build a CubeSat project. He's working on this Cubesat:&lt;/p&gt;
    &lt;p&gt;He did a weather balloon launch this year, and he's documenting everything on YouTube.&lt;/p&gt;
    &lt;p&gt;His first launch had many small problems. But also great learning, especially around redundancy and how to get the thing off the launch stand without problems.&lt;/p&gt;
    &lt;p&gt;And you're not only dealing with hardware, but also with software. And software that, at its core, has to be remotely accessed. And not only remote, but also wireless, meaning anyone else on earth within range can access it too.&lt;/p&gt;
    &lt;p&gt;So how do you keep it secure? That's something Tim from Ethos Labs is also dealing with with this, his T.E.M.P.E.S.T. CubeSat:&lt;/p&gt;
    &lt;p&gt;This thing is actually made to be not secure. It has intentional vulnerabilities, and he uses those to teach people different ways to make their CubeSats more secure.&lt;/p&gt;
    &lt;p&gt;You have complex hardware, running in limited space, with limited power and communications, and you want cram in as much functionality as possible.&lt;/p&gt;
    &lt;p&gt;Do you see where I'm going with this? That kind of problem is perfect for the microcontrollers and low-power SBCs that I love testing and playing with every day.&lt;/p&gt;
    &lt;p&gt;Except instead of me worrying about something consuming 10 watts, these guys are looking at a power budget of one watt. Or less!&lt;/p&gt;
    &lt;p&gt;These problems are hard. And not everyone has the patience for a completely custom project like Build a CubeSat, so there are also some small companies building kits to help you learn all these lessons with a little less stress.&lt;/p&gt;
    &lt;p&gt;Like what hardware do you need for a 100% self-contained CubeSat? And how do you get it certified for flight on a SpaceX rocket?&lt;/p&gt;
    &lt;head rend="h2"&gt;Your own CubeSat&lt;/head&gt;
    &lt;p&gt;Well, I'll quickly cover two products that are meant for like STEM classroom education, one from the lower end, and one that's based on a CubeSat that just flew this summer.&lt;/p&gt;
    &lt;p&gt;The first one is the MySat Kit, that you can buy from MySat in Ukraine. It comes with a board powered by an ESP32 with a camera, light sensors, an LED, gyroscope, accelerometer, barometer, clock, and a few other boards. And these are all off-the-shelf components you can buy replacements for or use 'em with other hardware, like a Raspberry Pi.&lt;/p&gt;
    &lt;p&gt;The way it's put together won't hold up on a rocket launch, but it's not meant for that. It's meant to show you how it's built, how you can communicate with it, and that sort of thing.&lt;/p&gt;
    &lt;p&gt;It took like an hour to build, and once I put it together I tried flashing the flight control firmware with my Mac... but I ran into some issues with Arduino IDE, and that's a me problem and not so much a MySat problem. Plus the team behind it has a whole war going on that they've been dealing with, so I'll be patient and try getting it going later.&lt;/p&gt;
    &lt;p&gt;The MySat goes from like $130 for a basic kit where you 3D print your own frame, or up to $300 for a full kit including deployable solar panels.&lt;/p&gt;
    &lt;p&gt;On the higher end, there's RASCube, and Edward Robinson, the 21 year old founder of Robinson Space, sent it over after he saw me posting about CubeSats online.&lt;/p&gt;
    &lt;p&gt;The RASCube comes from Australia, and Edward's mission is to teach students about space through hands-on building.&lt;/p&gt;
    &lt;p&gt;I just built this LS version of the cube last week; it's the little brother to their V2 design, which flew in space on a Falcon 9 rocket earlier this year.&lt;/p&gt;
    &lt;p&gt;Like MySat, you build the kit with an EPS board for power, a computer board with all the controls, and a radio board that ties in GPS and radio comms.&lt;/p&gt;
    &lt;p&gt;The RASCubes are a bit more expensive, coming in at around $430 each for the LB, and $600 each for the full aluminum V2s. But the price tag on that also covers full lesson plans and resources for teachers.&lt;/p&gt;
    &lt;p&gt;I love these things‚Äîall the people I've talked to on this journey are motivated by the same thing: learning about space, electronics, and integrating hardware in a new way, and sharing what they learn with others, especially students.&lt;/p&gt;
    &lt;head rend="h2"&gt;CubeSat T.E.M.P.E.S.T. and Build a CubeSat&lt;/head&gt;
    &lt;p&gt;Like take Build a Cubesat. For that project, everything is open source hardware, and every part of the journey is being documented on YouTube.&lt;/p&gt;
    &lt;p&gt;One thing I learned from the first flight test was how weird it is to have your Pi go from like overheating on the ground, to getting really cold as it goes higher, but then overheating again in the upper atmosphere because there's not enough air to dissipate heat!&lt;/p&gt;
    &lt;p&gt;You start to realize some of the crazy physical conditions you'll deal with on orbit.&lt;/p&gt;
    &lt;p&gt;Back down to earth, though, for CubeSat Tempest: the whole reason this exists is to help people learn why security is important, even for a tiny CubeSat. More importantly, Tim Fowler's course teaches people how to secure things like uplinks (see: the ground station pictured above) and flight control systems.&lt;/p&gt;
    &lt;p&gt;There are so many people like Tim, who work in their free time to try to teach about space, or engineering, or just small slices of things like security, using these tactile little cubes you can build and put next to your laptop on a desk.&lt;/p&gt;
    &lt;p&gt;It's crazy to think we're to a point where students can build these things, write flight control software, and even launch 'em into space!&lt;/p&gt;
    &lt;p&gt;And that brings me to SilverSat.&lt;/p&gt;
    &lt;head rend="h2"&gt;SilverSat&lt;/head&gt;
    &lt;p&gt;There's another CubeSat with a Raspberry Pi onboard, and it's launching NET Sunday, at 6:11 p.m. Eastern time, aboard a Falcon 9 rocket. What does NET mean? Well, as I found out when I visited Florida this summer, that means "No Earlier Than", and in spaceflight, many things delay launches.&lt;/p&gt;
    &lt;p&gt;The students who built SilverSat are no strangers to delays‚Äîthey were originally supposed to see their CubeSat launch earlier this year, but the cargo module they were on got damaged during transport, and that delayed them for months.&lt;/p&gt;
    &lt;p&gt;I got to talk to two of the adults guiding the students on their first space launch, and I discussed the history of the project (it started up in 2017), how they are supported by NASA's CubeSat Launch Initiative, the importance of amateur radio for CubeSats, and why they chose a Raspberry Pi Zero for their onboard computer.&lt;/p&gt;
    &lt;p&gt;That interview is tucked away in the last half of the video at the top of this post.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tracking Satellites from your backyard&lt;/head&gt;
    &lt;p&gt;Also in that video, I spoke to Gabe from saveitforparts, and he mentioned it's not that difficult to listen in on satellites on orbit‚Äîincluding amateur CubeSats!&lt;/p&gt;
    &lt;p&gt;SilverSat will be broadcasting SSDV (Slow-Scan Digital Video) at set times, and the schedule for that should be posted on their website.&lt;/p&gt;
    &lt;p&gt;Check out the video embedded in this post (near the top), or Gabe's own channel for ideas for tracking satellites. It can be done with under $100 of equipment (usually just an SDR and a cheap antenna).&lt;/p&gt;
    &lt;head rend="h2"&gt;Infectious Enthusiasm for Learning (and Teaching)&lt;/head&gt;
    &lt;p&gt;I feel like a broken record, but one thing I love, talking to anyone in the CubeSat community is this sense of infectious enthusiasm. And I was going to cut this video out for time, but watching it back, I realized other people would probably enjoy Tim showing off some neat CubeSats in his personal collection as much as I did. So I put up some bonus content on my second channel, Level 2 Jeff; you can watch another 8 minutes of CubeSat hardware below:&lt;/p&gt;
    &lt;p&gt;Thank you to everyone who taught me about CubeSats for this video and blog post.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45249878</guid><pubDate>Mon, 15 Sep 2025 14:02:02 +0000</pubDate></item><item><title>PayPal Ushers in a New Era of Peer-to-Peer Payments with Ethereum and Bitcoin</title><link>https://newsroom.paypal-corp.com/2025-09-15-PayPal-Ushers-in-a-New-Era-of-Peer-to-Peer-Payments,-Reimagining-How-Money-Moves-to-Anyone,-Anywhere</link><description>&lt;doc fingerprint="bc09acb02f2e3d8"&gt;
  &lt;main&gt;
    &lt;p&gt;PayPal Ushers in a New Era of Peer-to-Peer Payments, Reimagining How Money Moves to Anyone, Anywhere&lt;/p&gt;
    &lt;p&gt;Send and receive money as easily as sending a text, across apps, borders, and currencies &lt;/p&gt;
    &lt;div&gt;
      &lt;p&gt;SAN JOSE, Calif., Sept. 15, 2025 /PRNewswire/ -- On the heels of the PayPal World announcement, a global platform connecting the world's largest digital payment systems and wallets, PayPal today introduced PayPal links, a new way to send and receive money through a personalized, one-time link that can be shared in any conversation.&lt;/p&gt;
      &lt;p&gt;&lt;lb/&gt; Creating personalized payment links | Click to Enlarge&lt;/p&gt;
      &lt;p&gt;PayPal users in the U.S. can begin creating personalized payment links today, with international expansion to the UK, Italy, and other markets starting later this month. By making payments this simple and universal, PayPal links helps drive new customer acquisition and brings more users into the PayPal ecosystem.&lt;/p&gt;
      &lt;p&gt;The peer-to-peer (P2P) experience is about to go even further. Crypto will soon be directly integrated into PayPal's new P2P payment flow in the app. This will make it more convenient for PayPal users in the U.S. to send Bitcoin, Ethereum, PYUSD, and more, to PayPal, Venmo, as well a rapidly growing number of digital wallets across the world that support crypto and stablecoins.&lt;/p&gt;
      &lt;p&gt;Expanding what people can do with PayPal also comes with reassurance around how personal payments are handled. As always, friends-and-family transfers through Venmo and PayPal are exempt from 1099-K reporting. Users won't receive tax forms for gifts, reimbursements, or splitting expenses, helping ensure that personal payments stay personal.&lt;/p&gt;
      &lt;p&gt;"For 25 years, PayPal has revolutionized how money moves between people. Now, we're taking the next major step," said Diego Scotti, General Manager, Consumer Group at PayPal. "Whether you're texting, messaging, or emailing, now your money follows your conversations. Combined with PayPal World, it's an unbeatable value proposition, showing up where people connect, making it effortless to pay your friends and family, no matter where they are or what app they're using."&lt;/p&gt;
      &lt;p&gt;P2P is a cornerstone of PayPal's consumer experience, driving engagement and bringing more users into the ecosystem. P2P and other consumer total payment volume saw solid growth in the second quarter, increasing 10% year-over-year as the company focused on improving the experience and increasing user discoverability to make it easier than ever to move money globally. Plus, Venmo saw its highest TPV growth in three years. With PayPal World unlocking seamless interoperability, P2P is poised for even greater momentum in the future as PayPal and Venmo connect to billions of wallets worldwide.&lt;/p&gt;
      &lt;p&gt;How PayPal links work:&lt;/p&gt;
      &lt;list type="disc" rend="ul"&gt;
        &lt;item&gt;Create a personalized link ‚Äì Open the PayPal app, enter the details of your payment or request, and generate a unique, one-time link to share.&lt;/item&gt;
        &lt;item&gt;Always the right person ‚Äì Each link is private, one-time use, and created for a specific transaction.&lt;/item&gt;
        &lt;item&gt;Drop it anywhere ‚Äì Send your link in a text, DM, email, or chat. Add a note, emoji, or payment note.&lt;/item&gt;
        &lt;item&gt;Manage payment activity: Unclaimed links expire after 10 days. Users can send a reminder or even cancel the payment or request before the link is claimed with the PayPal app.&lt;/item&gt;
        &lt;item&gt;Tap and done ‚Äì The recipient taps the link and either completes or accepts the payment within the PayPal App with their PayPal account.&lt;/item&gt;
        &lt;item&gt;Funds are instant ‚Äì the recipient will get immediate access to their funds with a PayPal Balance account once accepted.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;About PayPal&lt;lb/&gt; PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy. For more information, visit https://www.paypal.com, https://about.pypl.com/ and https://investor.pypl.com/.&lt;/p&gt;
      &lt;p&gt;About PayPal USD (PYUSD) &lt;lb/&gt; PayPal USD is issued by Paxos Trust Company, LLC, a fully chartered limited purpose trust company. Paxos is licensed to engage in Virtual Currency Business Activity by the New York State Department of Financial Services. Reserves for PayPal USD are fully backed by U.S. dollar deposits, U.S. Treasuries and similar cash equivalents, and PayPal USD can be bought or sold through PayPal and Venmo at a rate of $1.00 per PayPal USD. &lt;lb/&gt; PayPal, Inc. (NMLS ID #: 910457) is licensed to engage in Virtual Currency Business Activity by the New York State Department of Financial Services. &lt;/p&gt;
      &lt;p&gt;Media contact&lt;lb/&gt; Gideon Anstey&lt;lb/&gt; gbanstey@paypal.com&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45249915</guid><pubDate>Mon, 15 Sep 2025 14:04:47 +0000</pubDate></item><item><title>Programming Deflation</title><link>https://tidyfirst.substack.com/p/programming-deflation</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45249985</guid><pubDate>Mon, 15 Sep 2025 14:11:43 +0000</pubDate></item><item><title>How to self-host a web font from Google Fonts</title><link>https://blog.velocifyer.com/Posts/3,0,0,2025-8-13,+how+to+self+host+a+font+from+google+fonts.html</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45250202</guid><pubDate>Mon, 15 Sep 2025 14:33:41 +0000</pubDate></item><item><title>Apple has a private CSS property to add Liquid Glass effects to web content</title><link>https://alastair.is/apple-has-a-private-css-property-to-add-liquid-glass-effects-to-web-content/</link><description>&lt;doc fingerprint="ae4c691d3b0b61f5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Apple has a private CSS property to add Liquid Glass effects to web content&lt;/head&gt;
    &lt;p&gt;I have an incredibly boring summer hobby: looking at the changelog for the WebKit Github repo. Why? Because I spend a chunk of my professional life working with webviews inside mobile apps and I like to get an early peek into what's coming in the next version of iOS. Since Tim Cook has yet to stand up at WWDC and announce "one more thing... Service Worker support in WKWebView, provided you add the correct entry to the &lt;code&gt;WKAppBoundDomains&lt;/code&gt; array in your &lt;code&gt;Info.plist&lt;/code&gt;" (and you know what, he should) manual research is the order of the day.&lt;/p&gt;
    &lt;p&gt;So I was really interested to see, the day after WWDC finished, a pull request named:&lt;/p&gt;
    &lt;quote&gt;[Materials] Rename "hosted blur" materials to reference "glass"&lt;/quote&gt;
    &lt;p&gt;Liquid Glass was one of the big takeaways from 2025's WWDC. Probably the biggest change in iOS UI since iOS 7 ditched the skeuomorphic look of the past. But that's all native UI, what does any of that have to do with webviews?&lt;/p&gt;
    &lt;p&gt;A poke around the context of the PR revealed something really interesting: Apple has a custom CSS property named &lt;code&gt;-apple-visual-effect&lt;/code&gt; . Not only does it allow the use of Liquid Glass in iOS 26 (via values like &lt;code&gt;-apple-system-glass-material&lt;/code&gt;) all versions support using standard materials with values like &lt;code&gt;-apple-system-blur-material-thin&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Yes it works and no, we can't&lt;/head&gt;
    &lt;p&gt;Before you, like me, fire up Safari and start editing some CSS, I have bad news: no, it doesn't work on the web. As well it shouldn't. But it also doesn't work by default in an app using WKWebView, you have to toggle a setting in WKPreferences called &lt;code&gt;useSystemAppearance&lt;/code&gt;... and it's private. So if you use it, say goodbye to App Store approval.&lt;/p&gt;
    &lt;p&gt;I wanted to try it out all the same so I hacked around to set &lt;code&gt;useSystemAppearance&lt;/code&gt; to true, set my CSS to:&lt;/p&gt;
    &lt;code&gt;.toolbar {
  border-radius: 50%;
  -apple-visual-effect: -apple-system-glass-material;
  height: 75px;
  width: 450px;
}&lt;/code&gt;
    &lt;p&gt;lo and behold, it works!&lt;/p&gt;
    &lt;p&gt;Whoever it was at Apple that decided to make this a CSS property is a genius because it makes it incredibly easy to provide different rules based on Liquid Glass support:&lt;/p&gt;
    &lt;code&gt;.toolbar {
  border-radius: 50%;
  height: 75px;
  width: 450px;
  background: rgba(204, 204, 204, 0.7);
}

@supports (-apple-visual-effect: -apple-system-glass-material) {
  background: transparent;
  -apple-visual-effect: -apple-system-glass-material
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Who cares?&lt;/head&gt;
    &lt;p&gt;It's an interesting piece of trivia but no-one outside of Apple can use it. So what does it matter? It doesn't. Except for the implication for what I'll call Alastair's Grand Theory of In-App Webviews. Industry wide they don't have a great reputation. But my suggestion is this: the main reason webviews in apps have such a bad reputation is because you don't notice the webviews that are integrated seamlessly.&lt;/p&gt;
    &lt;p&gt;It stands to reason that Apple wouldn't have developed this feature if they weren't using it. Where? We have no idea. But they must be using it somewhere. The fact that none of us have noticed exactly where suggests that we're interacting with webviews in our daily use of iOS without ever even realising it.&lt;/p&gt;
    &lt;p&gt;Food for thought!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45250370</guid><pubDate>Mon, 15 Sep 2025 14:49:00 +0000</pubDate></item></channel></rss>