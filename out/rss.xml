<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 03 Feb 2026 16:39:04 +0000</lastBuildDate><item><title>How does misalignment scale with model intelligence and task complexity?</title><link>https://alignment.anthropic.com/2026/hot-mess-of-ai/</link><description>&lt;doc fingerprint="a94bb3bd24c2cd2e"&gt;
  &lt;main&gt;
    &lt;p&gt;Research done as part of the first Anthropic Fellows Program during Summer 2025.&lt;/p&gt;
    &lt;p&gt;When AI systems fail, will they fail by systematically pursuing the wrong goals, or by being a hot mess? We decompose the errors of frontier reasoning models into bias (systematic) and variance (incoherent) components and find that, as tasks get harder and reasoning gets longer, model failures become increasingly dominated by incoherence rather than systematic misalignment. This suggests that future AI failures may look more like industrial accidents than coherent pursuit of a goal we did not train them to pursue.&lt;/p&gt;
    &lt;p&gt;As AI becomes more capable, we entrust it with increasingly consequential tasks. This makes understanding how these systems might fail even more critical for safety. A central concern in AI alignment is that superintelligent systems might coherently pursue misaligned goals: the classic paperclip maximizer scenario. But there's another possibility: AI might fail not through systematic misalignment, but through incoherence‚Äîunpredictable, self-undermining behavior that doesn't optimize for any consistent objective. That is, AI might fail in the same way that humans often fail, by being a hot mess.&lt;/p&gt;
    &lt;p&gt;This paper builds on the hot mess theory of misalignment (Sohl-Dickstein, 2023), which surveyed experts to rank various entities (including humans, animals, machine learning models, and organizations) by intelligence and coherence independently. It found that smarter entities are subjectively judged to behave less coherently. We take this hypothesis from survey data to empirical measurement across frontier AI systems, asking: As models become more intelligent and tackle harder tasks, do their failures look more like systematic misalignment, or more like a hot mess?&lt;/p&gt;
    &lt;p&gt;To quantify incoherence we decompose AI errors using the classic bias-variance framework:&lt;/p&gt;
    &lt;p&gt;We define incoherence as the fraction of error attributable to variance:&lt;/p&gt;
    &lt;p&gt;An incoherence of 0 means all errors are systematic (classic misalignment risk). An incoherence of 1 means all errors are random (the hot mess scenario). Crucially, this metric is independent of overall performance: a model can improve while becoming more or less coherent.&lt;/p&gt;
    &lt;p&gt;We evaluated frontier&lt;/p&gt;
    &lt;p&gt;Across all tasks and models, the longer models spend reasoning and taking actions, the more incoherent they become. This holds whether we measure reasoning tokens, agent actions, or optimizer steps.&lt;/p&gt;
    &lt;p&gt;How does incoherence change with model scale? The answer depends on task difficulty:&lt;/p&gt;
    &lt;p&gt;This suggests that scaling alone won't eliminate incoherence. As more capable models tackle harder problems, variance-dominated failures persist or worsen.&lt;/p&gt;
    &lt;p&gt;We find that when models spontaneously reason longer on a problem (compared to their median), incoherence spikes dramatically. Meanwhile, deliberately increasing reasoning budgets through API settings provides only modest coherence improvements. The natural variation dominates.&lt;/p&gt;
    &lt;p&gt;Aggregating multiple samples reduces variance (as expected from theory), providing a path to more coherent behavior, though this may be impractical for real-world agentic tasks where actions are irreversible.&lt;/p&gt;
    &lt;p&gt;A key conceptual point: LLMs are dynamical systems, not optimizers. When a language model generates text or takes actions, it traces trajectories through a high-dimensional state space. It has to be trained to act as an optimizer, and trained to align with human intent. It's unclear which of these properties will be more robust as we scale.&lt;/p&gt;
    &lt;p&gt;Constraining a generic dynamical system to act as a coherent optimizer is extremely difficult. Often the number of constraints required for monotonic progress toward a goal grows exponentially with the dimensionality of the state space. We shouldn't expect AI to act as coherent optimizers without considerable effort, and this difficulty doesn't automatically decrease with scale.&lt;/p&gt;
    &lt;p&gt;To probe this directly, we designed a controlled experiment: train transformers to explicitly emulate an optimizer. We generate training data from steepest descent on a quadratic loss function, then train models of varying sizes to predict the next optimization step given the current state (essentially: training a "mesa-optimizer").&lt;/p&gt;
    &lt;p&gt;The results are interesting:&lt;/p&gt;
    &lt;p&gt;Our results are evidence that future AI failures may look more like industrial accidents than coherent pursuit of goals that were not trained for. (Think: the AI intends to run the nuclear power plant, but gets distracted reading French poetry, and there is a meltdown.) However, coherent pursuit of poorly chosen goals that we trained for remains a problem. Specifically:&lt;/p&gt;
    &lt;p&gt;We use the bias-variance decomposition to systematically study how AI incoherence scales with model intelligence and task complexity. The evidence suggests that as AI tackles harder problems requiring more reasoning and action, its failures tend to become increasingly dominated by variance rather than bias. This doesn't eliminate AI risk‚Äîbut it changes what that risk looks like, particularly for problems that are currently hardest for models, and should inform how we prioritize alignment research.&lt;/p&gt;
    &lt;p&gt;We thank Andrew Saxe, Brian Cheung, Kit Frasier-Taliente, Igor Shilov, Stewart Slocum, Aidan Ewart, David Duvenaud, and Tom Adamczewski for extremely helpful discussions on topics and results in this paper.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46864498</guid><pubDate>Tue, 03 Feb 2026 00:28:06 +0000</pubDate></item><item><title>Banning lead in gas worked. The proof is in our hair</title><link>https://attheu.utah.edu/health-medicine/banning-lead-in-gas-worked-the-proof-is-in-our-hair/</link><description>&lt;doc fingerprint="7ef43095fbe01e94"&gt;
  &lt;main&gt;
    &lt;p&gt;Prior to the establishment of the Environmental Protection Agency in 1970, Americans lived in communities awash with lead from industrial sources, paint, water supply pipes and, most significantly, tailpipe emissions. A dangerous neurotoxin that accumulates in human tissues and is linked to developmental deficits in children, environmental lead levels have come way down in the years since, and so have human exposures.&lt;/p&gt;
    &lt;p&gt;The proof is in your hair.&lt;/p&gt;
    &lt;p&gt;An analysis of hair samples conducted by University of Utah scientists shows precipitous reductions in lead levels since 1916.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe were able to show through our hair samples what the lead concentrations are before and after the establishment of regulations by the EPA,‚Äù said demographer Ken Smith, a distinguished professor emeritus of family and consumer studies. ‚ÄúWe have hair samples spanning about 100 years. And back when the regulations were absent, the lead levels were about 100 times higher than they are after the regulations.‚Äù&lt;/p&gt;
    &lt;head rend="h4"&gt;A useful element with a dark side&lt;/head&gt;
    &lt;p&gt;The findings, which appear in PNAS, underscore the vital role of environmental regulations in protecting public health. The study notes lead rules are now being weakened by the Trump administration in a wide-ranging move to ease environmental protections.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe should not forget the lessons of history. And the lesson is those regulations have been very important,‚Äù said co-author Thure Cerling, a distinguished professor of both geology and biology. ‚ÄúSometimes they seem onerous and mean that industry can‚Äôt do exactly what they‚Äôd like to do when they want to do it or as quickly as they want to do it. But it‚Äôs had really, really positive effects.‚Äù&lt;/p&gt;
    &lt;p&gt;Lead is the heaviest of heavy metals that, like mercury and arsenic, accumulate in living tissue and are toxic at even low levels. Yet lead holds very useful properties, great for fashioning into pipes and as a chemical additive. Lead was added to paint to improve durability, speed up drying, and produce vibrant colors with greater coverage. Lead also improved the performance of automobile engines by preventing pistons from ‚Äúknocking.‚Äù&lt;/p&gt;
    &lt;p&gt;By the 1970s, its toxicity became well established, and EPA regulations began phasing it out of paint, pipes, gasoline and other consumer products.&lt;/p&gt;
    &lt;head rend="h4"&gt;How Utahns‚Äô affection for family history advances science&lt;/head&gt;
    &lt;p&gt;To document whether these steps were helping reduce lead exposure in people, Smith joined with geologist Diego Fernandez and Cerling, who had developed techniques to discern where animals have lived and what they eat based on chemical analysis of hair and teeth.&lt;/p&gt;
    &lt;p&gt;The lead research is built on a previous study funded by the university‚Äôs Center on Aging and the National Institutes of Health that had recruited Utahns who consented to provide blood samples and family health histories.&lt;/p&gt;
    &lt;p&gt;For the new study, the researchers asked members of that cohort to provide hair samples, both contemporary and from when they were young. These people obliged, and some were able to find ancestors‚Äô hair preserved in family scrapbooks dating as far back as a century. In all, the team acquired hair samples from 48 individuals in this manner, offering a robust window into lead levels along Utah‚Äôs populous Wasatch Front, which historically experienced heavy lead emissions from industrial sources.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe Utah part of this is so interesting because of the way people keep track of their family history. I don‚Äôt know that you could do this in New York or Florida,‚Äù said Smith, who directed the U‚Äôs Pedigree and Population Program at the Huntsman Cancer Center while these studies were conducted.&lt;/p&gt;
    &lt;p&gt;This region supported a vibrant smelting industry through most of the 20th century, centered in the cities of Midvale and Murray. Most of Utah‚Äôs smelters were shuttered by the 1970s, around the same time the EPA clamped down on the use of lead in consumer products.&lt;/p&gt;
    &lt;p&gt;The research team ran the hair samples through mass spectrometry equipment at the facility directed by Fernandez.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe surface of the hair is special. We can tell that some elements get concentrated and accumulated on the surface. Lead is one of those. That makes it easier because lead is not lost over time,‚Äù said Fernandez, a research professor in the Department of Geology &amp;amp; Geophysics. ‚ÄúBecause mass spectrometry is very sensitive, we can do it with one hair strand, though we cannot tell where the lead is in the hair. It‚Äôs probably on the surface mostly, but it could also be coming from the blood if that hair was synthesized when there was high lead in the blood.‚Äù&lt;/p&gt;
    &lt;p&gt;Blood would provide a better exposure assessment, but hair is far easier to collect and preserve, and more importantly, it offers clues to long-ago exposures for a person who has grown up or even deceased.&lt;/p&gt;
    &lt;p&gt;‚ÄúIt doesn‚Äôt really record that internal blood concentration that your brain is seeing, but it tells you about that overall environmental exposure,‚Äù Cerling said. ‚ÄúOne of the things that we found is that hair records that original value, but then the longer the hair has been exposed to the environment, the higher the lead concentrations are.‚Äù&lt;/p&gt;
    &lt;p&gt;The team‚Äôs findings regarding lead in hair run parallel to the reductions of lead in gasoline following the EPA‚Äôs establishment by President Richard Nixon.&lt;/p&gt;
    &lt;p&gt;Prior to 1970, for example, gasolines contained about 2 grams of lead per gallon. That might not sound like much, but considering the billions of gallons of fuel American automobiles burn each year, it adds up to nearly 2 pounds of lead released into the environment per person a year.&lt;/p&gt;
    &lt;p&gt;‚ÄòIt‚Äôs an enormous amount of lead that‚Äôs being put into the environment and quite locally,‚Äù Cerling said. ‚ÄúIt‚Äôs just coming out of the tailpipe, goes up in the air and then it comes down. It‚Äôs in the air for a number of days, especially during the inversions that we have and it absorbs into your hair, you breathe it and it goes into your lungs.‚Äù&lt;/p&gt;
    &lt;p&gt;But after the 1970s, even as gasoline consumption escalated in the United States, the concentrations of lead in the hair samples plummeted, from as high as 100 parts per million (ppm) to 10 ppm by 1990. In 2024, the level was less than 1 ppm.&lt;/p&gt;
    &lt;p&gt;The study, titled ‚ÄúLead in archived hair documents decline in human lead (Pb) exposure since establishment of the US Environmental Protection Agency,‚Äù was published Feb. 2 in PNAS, or Proceedings of the National Academy of Sciences. Support came from the Huntsman Cancer Foundation and the National Cancer Institute through a grant to the Utah Population Database and the University of Utah.&lt;/p&gt;
    &lt;head rend="h3"&gt;MEDIA &amp;amp; PR CONTACTS&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Brian Maffly Science writer, University of Utah Communications&lt;lb/&gt;801-573-2382 brian.maffly@utah.edu&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46865275</guid><pubDate>Tue, 03 Feb 2026 01:52:21 +0000</pubDate></item><item><title>Floppinux ‚Äì An Embedded Linux on a Single Floppy, 2025 Edition</title><link>https://krzysztofjankowski.com/floppinux/floppinux-2025.html</link><description>&lt;doc fingerprint="1719381e65a62ba8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FLOPPINUX&lt;/head&gt;
    &lt;head rend="h2"&gt;An Embedded √∞¬ßLinux on a Single √∞¬æFloppy&lt;/head&gt;
    &lt;head rend="h2"&gt;2025 Edition (v0.3.1)&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;FLOPPINUX was released in 2021. After four years people find it helpful. Because of that I decided to revisit FLOPPINUX in 2025 and make updated tutorial. This brings bunch of updates like latest kernel and persistent storage.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Main Project Goals&lt;/item&gt;
      &lt;item&gt;Linux Kernel&lt;/item&gt;
      &lt;item&gt;64-bit Base OS&lt;/item&gt;
      &lt;item&gt;Working Directory&lt;/item&gt;
      &lt;item&gt;System Requirements&lt;/item&gt;
      &lt;item&gt;Kernel&lt;/item&gt;
      &lt;item&gt;Toolset&lt;/item&gt;
      &lt;item&gt;Filesystem&lt;/item&gt;
      &lt;item&gt;Boot Image&lt;/item&gt;
      &lt;item&gt;Floppy Disk&lt;/item&gt;
      &lt;item&gt;Summary&lt;/item&gt;
      &lt;item&gt;Download&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Main Project Goals&lt;/head&gt;
    &lt;p&gt;Think of this as Linux From Scratch but for making single floppy distribution.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It is meant to be a full workshop (tutorial) that you can follow easily and modify it to your needs. It is a learning exercise. Some base Linux knowledge is needed.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The final distribution is very simple and consists only of minimum of tools and hardware support. As a user you will be able to boot any PC with a floppy drive to a Linux terminal, edit files, and create simple scripts. There is 264KB of space left for your newly created files.&lt;/p&gt;
    &lt;head rend="h3"&gt;Core features:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fully working distribution booting from the single floppy&lt;/item&gt;
      &lt;item&gt;Latest* Linux kernel&lt;/item&gt;
      &lt;item&gt;Supporting all 32-bit x86 CPUs since Intel 486DX&lt;/item&gt;
      &lt;item&gt;Have a working text editor (Vi) and basic file manipulation commands (move, rename, delete, etc.)&lt;/item&gt;
      &lt;item&gt;Support for simple scripting&lt;/item&gt;
      &lt;item&gt;Persistent storage on the floppy to actualy save files (264KB)&lt;/item&gt;
      &lt;item&gt;Works on real hardware and emulation&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Minimum Hardware Requirements:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Intel 486DX 33MHz&lt;/item&gt;
      &lt;item&gt;20MB RAM&lt;/item&gt;
      &lt;item&gt;Internal floppy disk&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Linux Kernel&lt;/head&gt;
    &lt;p&gt;The Linux kernel drops i486 support in 6.15 (released May 2025), so 6.14 (released March 2025) is the latest version with full compatibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;64-bit Base OS&lt;/head&gt;
    &lt;p&gt;This time I will do everything on Omarchy Linux. It is 64-bit operating system based on Arch Linux. Instructions should work on all POSIX systems. Only difference is getting needed packages.&lt;/p&gt;
    &lt;head rend="h2"&gt;Working Directory&lt;/head&gt;
    &lt;p&gt;Create directory where you will keep all the files.&lt;/p&gt;
    &lt;code&gt;mkdir ~/my-linux-distro/
BASE=~/my-linux-distro/
cd $BASE&lt;/code&gt;
    &lt;head rend="h2"&gt;Host OS Requirements&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;You need supporting software to build things. This exact list may vary depending on the system you have.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Install needed software/libs. On Arch/Omarchy 3.1:&lt;/p&gt;
    &lt;code&gt;sudo pacman -S ncurses bc flex bison syslinux cpio&lt;/code&gt;
    &lt;p&gt;Cross-compiler:&lt;/p&gt;
    &lt;code&gt;wget https://musl.cc/i486-linux-musl-cross.tgz
tar xvf i486-linux-musl-cross.tgz
rm i486-linux-musl-cross.tgz&lt;/code&gt;
    &lt;head rend="h3"&gt;Emulation&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;86Box is also good but slower. Bochs is the best but for debugging, not needed here.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For emulation I will be using qemu.&lt;/p&gt;
    &lt;code&gt;sudo pacman -S qemu-full&lt;/code&gt;
    &lt;head rend="h2"&gt;Kernel&lt;/head&gt;
    &lt;p&gt;Get the sources for the latest compatible kernel 6.14.11:&lt;/p&gt;
    &lt;code&gt;git clone --depth=1 --branch v6.14.11 https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git
cd linux&lt;/code&gt;
    &lt;p&gt;Now, that you have them in linux/ directory lets configure and build our custom kernel. First create tiniest base configuration:&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 tinyconfig&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;This is a bootstrap with absolute minimum features. Just enough to boot the system. We want a little bit more.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Add additonal config settings on top of it:&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 menuconfig&lt;/code&gt;
    &lt;p&gt;Important: Do not uncheck anything in options unless specified so. Some of those options are important. You can uncheck but on your own risk.&lt;/p&gt;
    &lt;p&gt;From menus choose those options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;General Setup &lt;list rend="ul"&gt;&lt;item&gt;Configure standard kernel features (expert users) &lt;list rend="ul"&gt;&lt;item&gt;Enable support for printk&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Initial RAM filesystem and RAM disk (initramfs/initrd) &lt;list rend="ul"&gt;&lt;item&gt;Support initial ramdisk/ramfs compressed using XZ and uncheck everything else&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Configure standard kernel features (expert users) &lt;/item&gt;
      &lt;item&gt;Processor type and features &lt;list rend="ul"&gt;&lt;item&gt;x86 CPU resources control support&lt;/item&gt;&lt;item&gt;Processor family &lt;list rend="ul"&gt;&lt;item&gt;486DX&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Enable the block layer&lt;/item&gt;
      &lt;item&gt;Executable file formats &lt;list rend="ul"&gt;&lt;item&gt;Kernel support for ELF binaries&lt;/item&gt;&lt;item&gt;Kernel support for scripts starting with #!&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Device Drivers &lt;list rend="ul"&gt;&lt;item&gt;Block devices &lt;list rend="ul"&gt;&lt;item&gt;Normal floppydisk support&lt;/item&gt;&lt;item&gt;RAM block device support &lt;list rend="ul"&gt;&lt;item&gt;Default number of RAM disk: 1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Character devices &lt;list rend="ul"&gt;&lt;item&gt;Enable TTY&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Block devices &lt;/item&gt;
      &lt;item&gt;File systems &lt;list rend="ul"&gt;&lt;item&gt;DOS/FAT/EXFAT/NT Filesystems &lt;list rend="ul"&gt;&lt;item&gt;MSDOS fs support&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Pseudo filesystems &lt;list rend="ul"&gt;&lt;item&gt;/proc file system support&lt;/item&gt;&lt;item&gt;sysfs file system support&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Native language support &lt;list rend="ul"&gt;&lt;item&gt;Codepage 437&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;DOS/FAT/EXFAT/NT Filesystems &lt;/item&gt;
      &lt;item&gt;Library routines &lt;list rend="ul"&gt;&lt;item&gt;XZ decompression and uncheck everything under it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Exit configuration (yes, save settings to .config).&lt;/p&gt;
    &lt;p&gt;Time for compiling!&lt;/p&gt;
    &lt;head rend="h3"&gt;Compile Kernel&lt;/head&gt;
    &lt;code&gt;make ARCH=x86 bzImage -j$(nproc)&lt;/code&gt;
    &lt;p&gt;This will take a while depending on the speed of your CPU. In the end the kernel will be created in arch/x86/boot/ as bzImage file.&lt;/p&gt;
    &lt;p&gt;Move kernel to our main directory and go back to it:&lt;/p&gt;
    &lt;code&gt;mv arch/x86/boot/bzImage ../
cd ..&lt;/code&gt;
    &lt;head rend="h2"&gt;Toolset&lt;/head&gt;
    &lt;p&gt;Without tools kernel will just boot and you will not be able to do anything. One of the most popular lightweight tools is BusyBox. It replaces the standard GNU utilities with way smaller but still functional alternatives, perfect for embedded needs.&lt;/p&gt;
    &lt;p&gt;Get the 1.36.1 version from busybox.net or Github mirror. Download the file, extract it, and change directory:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Remember to be in the working directory.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;wget https://github.com/mirror/busybox/archive/refs/tags/1_36_1.tar.gz
tar xzvf 1_36_1.tar.gz
rm 1_36_1.tar.gz
cd busybox-1_36_1/&lt;/code&gt;
    &lt;p&gt;As with kernel you need to create starting configuration:&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 allnoconfig&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;You may skip this following fix if you are building on Debian/Fedora&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Fix for Arch Linux based distributions:&lt;/p&gt;
    &lt;code&gt;sed -i 's/main() {}/int main() {}/' scripts/kconfig/lxdialog/check-lxdialog.sh&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;Now the fun part. You need to choose what tools you want. Each menu entry will show how much more KB will be taken if you choose it. So choose it wisely :) For the first time use my selection.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Run the configurator:&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 menuconfig&lt;/code&gt;
    &lt;p&gt;Choose the following options. Remember to do not uncheck anything if not stated here.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Settings &lt;list rend="ul"&gt;&lt;item&gt;Support files &lt;list rend="ul"&gt;&lt;item&gt;2GB&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Build static binary (no shared libs)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Support files &lt;/item&gt;
      &lt;item&gt;Coreutils &lt;list rend="ul"&gt;&lt;item&gt;cat&lt;/item&gt;&lt;item&gt;cp&lt;/item&gt;&lt;item&gt;df&lt;/item&gt;&lt;item&gt;echo&lt;/item&gt;&lt;item&gt;ls&lt;/item&gt;&lt;item&gt;mkdir&lt;/item&gt;&lt;item&gt;mv&lt;/item&gt;&lt;item&gt;rm&lt;/item&gt;&lt;item&gt;sync&lt;/item&gt;&lt;item&gt;test &lt;list rend="ul"&gt;&lt;item&gt;test as [&lt;/item&gt;&lt;item&gt;test as [[&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Console Utilities &lt;list rend="ul"&gt;&lt;item&gt;clear&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Editors &lt;list rend="ul"&gt;&lt;item&gt;vi&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Init Utilities &lt;list rend="ul"&gt;&lt;item&gt;init &lt;list rend="ul"&gt;&lt;item&gt;uncheck everything else (inside init: keep [*] only on init in this page)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;init &lt;/item&gt;
      &lt;item&gt;Linux System Utilities &lt;list rend="ul"&gt;&lt;item&gt;mdev&lt;/item&gt;&lt;item&gt;mount &lt;list rend="ul"&gt;&lt;item&gt;Support lots of -o flags&lt;/item&gt;&lt;item&gt;uncheck evrything else&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;umount&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Miscellaneous Utilities &lt;list rend="ul"&gt;&lt;item&gt;uncheck readahead&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Shells &lt;list rend="ul"&gt;&lt;item&gt;Choose alias as (ash)&lt;/item&gt;&lt;item&gt;ash&lt;/item&gt;&lt;item&gt;Optimize for size instead of speed&lt;/item&gt;&lt;item&gt;Alias support&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now exit with save config.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cross Compiler Setup&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Our target system needs to be 32-bit. To compile it on 64-bit system we need a cross compiler. You can setup this by hand in the menuconfig or just copy and paste those four lines.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Setup paths:&lt;/p&gt;
    &lt;code&gt;sed -i "s|.*CONFIG_CROSS_COMPILER_PREFIX.*|CONFIG_CROSS_COMPILER_PREFIX=\"${BASE}/i486-linux-musl-cross/bin/i486-linux-musl-\"|" .config

sed -i "s|.*CONFIG_SYSROOT.*|CONFIG_SYSROOT=\"${BASE}/i486-linux-musl-cross\"|" .config

sed -i "s|.*CONFIG_EXTRA_CFLAGS.*|CONFIG_EXTRA_CFLAGS=-I$BASE/i486-linux-musl-cross/include|" .config

sed -i "s|.*CONFIG_EXTRA_LDFLAGS.*|CONFIG_EXTRA_LDFLAGS=-L$BASE/i486-linux-musl-cross/lib|" .config&lt;/code&gt;
    &lt;head rend="h3"&gt;Compile BusyBox&lt;/head&gt;
    &lt;p&gt;Build tools and create base filesystem (√¢install√¢). It will ask for options, just press enter for default for all of them.&lt;/p&gt;
    &lt;code&gt;make ARCH=x86 -j$(nproc) &amp;amp;&amp;amp; make ARCH=x86 install&lt;/code&gt;
    &lt;p&gt;This will create a filesystem with all the files at **_install/**. Move it to our main directory. I like to rename it to.&lt;/p&gt;
    &lt;p&gt;Lastly to to that new directory.&lt;/p&gt;
    &lt;code&gt;mv _install ../filesystem
cd ../filesystem&lt;/code&gt;
    &lt;head rend="h2"&gt;Filesystem&lt;/head&gt;
    &lt;p&gt;You got kernel and basic tools but the system still needs some additional directory structure.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This created minimum viable directory structure for satisfying the basic requirements of a Linux system.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Remember to be in the filesystem/ directory.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;mkdir -pv {dev,proc,etc/init.d,sys,tmp,home}
sudo mknod dev/console c 5 1
sudo mknod dev/null c 1 3&lt;/code&gt;
    &lt;p&gt;Next step is to add minimum configuration files. First one is a welcome message that will be shown after booting.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Here is the first real opportunity to go wild and make this your own signature.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; welcome &amp;lt;&amp;lt; EOF
Your welome message or ASCII art.
EOF&lt;/code&gt;
    &lt;p&gt;Or download my welcome file.&lt;/p&gt;
    &lt;code&gt;wget https://krzysztofjankowski.com/floppinux/downloads/0.3.1/welcome&lt;/code&gt;
    &lt;p&gt;It looks like that:&lt;/p&gt;
    &lt;code&gt;$ cat welcome

                _________________
               /_/ FLOPPINUX  /_/;
              / ' boot disk  ' //
             / '------------' //
            /   .--------.   //
           /   /         /  //
          .___/_________/__//   1440KiB
          '===\_________\=='   3.5"

_______FLOPPINUX_V_0.3.1 __________________________________
_______AN_EMBEDDED_SINGLE_FLOPPY_LINUX_DISTRIBUTION _______
_______BY_KRZYSZTOF_KRYSTIAN_JANKOWSKI ____________________
_______2025.12 ____________________________________________&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;Back to serious stuff. Inittab tells the system what to do in critical states like starting, exiting and restarting. It points to the initialization script rc that is the first thing that our OS will run before dropping into the shell.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Create an inittab file:&lt;/p&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; etc/inittab &amp;lt;&amp;lt; EOF
::sysinit:/etc/init.d/rc
::askfirst:/bin/sh
::restart:/sbin/init
::ctrlaltdel:/sbin/reboot
::shutdown:/bin/umount -a -r
EOF&lt;/code&gt;
    &lt;p&gt;And the init rc script:&lt;/p&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; etc/init.d/rc &amp;lt;&amp;lt; EOF
#!/bin/sh
mount -t proc none /proc
mount -t sysfs none /sys
mdev -s
ln -s /proc/mounts /etc/mtab
mkdir -p /mnt /home
mount -t msdos -o rw /dev/fd0 /mnt
mkdir -p /mnt/data
mount --bind /mnt/data /home
clear
cat welcome
cd /home
/bin/sh
EOF&lt;/code&gt;
    &lt;p&gt;Make the script executable and owner of all files to root:&lt;/p&gt;
    &lt;code&gt;chmod +x etc/init.d/rc
sudo chown -R root:root .&lt;/code&gt;
    &lt;p&gt;Compress this directory into one file. Then go back to working directory.&lt;/p&gt;
    &lt;code&gt;find . | cpio -H newc -o | xz --check=crc32 --lzma2=dict=512KiB -e &amp;gt; ../rootfs.cpio.xz
cd ..&lt;/code&gt;
    &lt;p&gt;Create booting configuration.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Another place to tweak parameters for your variant. Text after SAY is what will be displayed on the screen as first, usualy a name of the OS.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;The tsc=unstable is useful on some (real) computers to get rid of randomly shown warnings about Time Stamp Counter.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Remember to be in the working directory.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; syslinux.cfg &amp;lt;&amp;lt; EOF
DEFAULT floppinux
LABEL floppinux
SAY [ BOOTING FLOPPINUX VERSION 0.3.1 ]
KERNEL bzImage
INITRD rootfs.cpio.xz
APPEND root=/dev/ram rdinit=/etc/init.d/rc console=tty0 tsc=unstable
EOF&lt;/code&gt;
    &lt;p&gt;Make it executable:&lt;/p&gt;
    &lt;code&gt;chmod +x syslinux.cfg&lt;/code&gt;
    &lt;p&gt;Create sample file&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To make the system a little bit more user friendly I like to have a sample file that user will be able to read and edit. You can put anything you want in it. A simple help would be also a good idea to include.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;cat &amp;gt;&amp;gt; hello.txt &amp;lt;&amp;lt; EOF
Hello, FLOPPINUX user!
EOF&lt;/code&gt;
    &lt;p&gt;Filesystem is ready. Final step is to put this all on a floppy!&lt;/p&gt;
    &lt;head rend="h2"&gt;Boot Image&lt;/head&gt;
    &lt;p&gt;First we need an empty file in exact size of a floppy disk. Then format and make it bootable.&lt;/p&gt;
    &lt;p&gt;Create empty floppy image:&lt;/p&gt;
    &lt;code&gt;dd if=/dev/zero of=floppinux.img bs=1k count=1440&lt;/code&gt;
    &lt;p&gt;Format it and create bootloader:&lt;/p&gt;
    &lt;code&gt;mkdosfs -n FLOPPINUX floppinux.img
syslinux --install floppinux.img&lt;/code&gt;
    &lt;p&gt;Mount it and copy syslinux, kernel, and filesystem onto it:&lt;/p&gt;
    &lt;code&gt;sudo mount -o loop floppinux.img /mnt
sudo mkdir /mnt/data
sudo cp hello.txt /mnt/data/
sudo cp bzImage /mnt
sudo cp rootfs.cpio.xz /mnt
sudo cp syslinux.cfg /mnt
sudo umount /mnt&lt;/code&gt;
    &lt;p&gt;Done!&lt;/p&gt;
    &lt;head rend="h3"&gt;Test in emulator&lt;/head&gt;
    &lt;p&gt;It√¢s good to test before wasting time for the real floppy to burn.&lt;/p&gt;
    &lt;p&gt;Boot the new OS in qemu:&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -fda floppinux.img -m 20M -cpu 486&lt;/code&gt;
    &lt;p&gt;If it worked that means You have successfully created your own distribution! Congratulations!&lt;/p&gt;
    &lt;p&gt;The floppinux.img image is ready to burn onto a floppy and boot on real hardware!&lt;/p&gt;
    &lt;head rend="h2"&gt;Floppy Disk&lt;/head&gt;
    &lt;head rend="h3"&gt;&amp;lt;!&amp;gt; Important &amp;lt;!&amp;gt;&lt;/head&gt;
    &lt;p&gt;Change XXX to floppy drive name in your system. In my case it is sdb. Choosing wrongly will NUKE YOUR PARTITION and REMOVE all of your files! Think twice. Or use some GUI application for that.&lt;/p&gt;
    &lt;code&gt;sudo dd if=floppinux.img of=/dev/XXX bs=512 conv=notrunc,sync,fsync oflag=direct status=progress&lt;/code&gt;
    &lt;p&gt;After 5 minutes I got freshly burned floppy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FLOPPINUX: 0.3.1 (December 2025)&lt;/item&gt;
      &lt;item&gt;Linux Kernel: 6.14.11&lt;/item&gt;
      &lt;item&gt;Busybox: 1.36.1&lt;/item&gt;
      &lt;item&gt;Image size: 1440KiB / 1.44MiB&lt;/item&gt;
      &lt;item&gt;Kernel size: 881KiB (bzImage)&lt;/item&gt;
      &lt;item&gt;Tools: 137KiB (rootfs.cpio.xz)&lt;/item&gt;
      &lt;item&gt;Free space left (df -h): 253KiB&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;System Tools&lt;/head&gt;
    &lt;head rend="h4"&gt;File &amp;amp; Directory Manipulation&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;cat&lt;/code&gt;- display file contents&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;cp&lt;/code&gt;- copy files and directories&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mv&lt;/code&gt;- move/rename files and directories&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rm&lt;/code&gt;- remove files and directories&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ls&lt;/code&gt;- list directory contents&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mkdir&lt;/code&gt;- creates directory&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;System Information &amp;amp; Management&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;df -h&lt;/code&gt;- display filesystem disk space usage&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sync&lt;/code&gt;- force write of buffered data to disk - use this after any changes to the floppy filesystem&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mount&lt;/code&gt;- mount filesystems&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;umount&lt;/code&gt;- unmount filesystems&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Text Processing &amp;amp; Output&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;echo&lt;/code&gt;- display text output&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;more&lt;/code&gt;- page through text output&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Utilities&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;clear&lt;/code&gt;- clear terminal screen&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;test&lt;/code&gt;- evaluate conditional expressions&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Applications&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;vi&lt;/code&gt;- text editor&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46866544</guid><pubDate>Tue, 03 Feb 2026 04:33:25 +0000</pubDate></item><item><title>LNAI ‚Äì Define AI coding tool configs once, sync to Claude, Cursor, Codex, etc.</title><link>https://github.com/KrystianJonca/lnai</link><description>&lt;doc fingerprint="12953a5fcfbbaedc"&gt;
  &lt;main&gt;
    &lt;p&gt;Stop maintaining separate config files for every AI coding tool. Define once in &lt;code&gt;.ai/&lt;/code&gt;, sync everywhere.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One source of truth ‚Äî Write your project rules, MCP servers, and permissions once&lt;/item&gt;
      &lt;item&gt;Works with your tools ‚Äî Syncs to native formats each tool actually reads&lt;/item&gt;
      &lt;item&gt;Stay in sync ‚Äî Update &lt;code&gt;.ai/&lt;/code&gt;and run&lt;code&gt;lnai sync&lt;/code&gt;to propagate changes instantly&lt;/item&gt;
      &lt;item&gt;Automatic cleanup ‚Äî Orphaned files are removed when configs change&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Config Generated&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Claude Code&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.claude/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Codex&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.codex/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Cursor&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.cursor/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Gemini CLI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.gemini/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GitHub Copilot&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.github/copilot-instructions.md&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OpenCode&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.opencode/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windsurf&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.windsurf/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;npm install -g lnai

lnai init      # Create .ai/ configuration
lnai validate  # Check for errors
lnai sync      # Export to native tool configs&lt;/code&gt;
    &lt;p&gt;Full guides and configuration reference at lnai.sh&lt;/p&gt;
    &lt;p&gt;MIT&lt;/p&gt;
    &lt;p&gt;If you find LNAI helpful, please star us on GitHub!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46868318</guid><pubDate>Tue, 03 Feb 2026 08:45:57 +0000</pubDate></item><item><title>Show HN: Safe-now.live ‚Äì Ultra-light emergency info site (&lt;10KB)</title><link>https://safe-now.live</link><description>&lt;doc fingerprint="ca634b944efc74a1"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;‚ö† Active Disasters &amp;amp; Declarations (FEMA | EC)&lt;/head&gt;üá∫üá∏ USA: ‚ùÑ SEVERE WINTER STORM (WV) | ‚ùÑ SEVERE WINTER STORM (NC) | ‚ùÑ SEVERE WINTER STORM (IN) | ‚ùÑ SEVERE WINTER STORM (AR) | ‚ùÑ SEVERE WINTER STORM (TN) | ‚ùÑ SEVERE WINTER STORM (KY)&lt;head rend="h2"&gt;üìç Find Local Info&lt;/head&gt;&lt;p&gt;United States: AL AK AZ AR CA CO CT DE DC FL GA HI ID IL IN IA KS KY LA ME MD MA MI MN MS MO MT NE NV NH NJ NM NY NC ND OH OK OR PA PR RI SC SD TN TX UT VT VA WA WV WI WY | VI AS GU MP&lt;/p&gt;&lt;p&gt;Canada: AB BC MB NB NL NS NT NU ON PE QC SK YT&lt;/p&gt;&lt;p&gt;International: UK/EU 112 | AU 000 | NZ 111 | JP 110/119 | MX 911 | BR 190&lt;/p&gt;&lt;head rend="h2"&gt;üÜò Quick Reference&lt;/head&gt;Earthquake: Drop, Cover, Hold On&lt;p&gt;Tornado: Lowest floor, interior room&lt;/p&gt;&lt;p&gt;Flood: Higher ground - Turn around, don't drown&lt;/p&gt;&lt;p&gt;Fire: Get out, stay out, call 911&lt;/p&gt;&lt;p&gt;Gas leak: Leave immediately, don't use electronics&lt;/p&gt;&lt;p&gt;Chemical: Move upwind, shelter in place&lt;/p&gt;&lt;p&gt;Active threat: Run, Hide, Fight&lt;/p&gt;&lt;p&gt;CO alarm: Get outside, call 911, don't re-enter&lt;/p&gt;&lt;p&gt;Flood water: Turn off electricity at breaker before contact&lt;/p&gt;&lt;p&gt;Lightning: Get inside; avoid trees, water, metal; crouch if stuck outside&lt;/p&gt;&lt;p&gt;Tsunami: Move inland and uphill immediately; don't wait&lt;/p&gt;&lt;p&gt;Power out: Fridge safe 4hrs, freezer 48hrs if closed&lt;/p&gt;&lt;p&gt;Heat stroke: Cool rapidly with water/ice; call 911; confusion is danger sign&lt;/p&gt;&lt;p&gt;Hypothermia: Remove wet clothes; warm gradually; hot drinks if conscious&lt;/p&gt;&lt;p&gt;Civil unrest: Avoid crowds; get indoors; don't engage; document if safe&lt;/p&gt;&lt;head rend="h2"&gt;üéí Emergency Kit&lt;/head&gt;- Water/Food: Water: 1 gal/4L per person per day; Water purification tablets; Non-perishable food&lt;p&gt;- Medical: First aid kit; Prescription medications; Infant/special needs items; N95 masks&lt;/p&gt;&lt;p&gt;- Tools/Comms: Flashlight + batteries; Battery/crank radio; Whistle; Phone + charger; Wrench (utilities)&lt;/p&gt;&lt;p&gt;- Docs/Money: Cash in small bills; Copies: IDs, insurance, bank; Emergency contacts; Local maps&lt;/p&gt;&lt;p&gt;- Shelter/Clothing: Emergency blanket; Change of clothes; Sturdy shoes; Rain gear&lt;/p&gt;&lt;p&gt;- Sanitation: Moist towelettes; Garbage bags + ties; Bleach; Personal hygiene items&lt;/p&gt;&lt;p&gt;Source: Ready.gov / GetPrepared.gc.ca&lt;/p&gt;&lt;head rend="h2"&gt;üè† Home Prep&lt;/head&gt;- Know: 2 evacuation routes; Family communication plan; Utility shutoffs (gas, water, electric); Nearest shelters; How to receive alerts&lt;p&gt;- Safety: Test smoke/CO detectors monthly; Secure water heater + heavy furniture; Fire extinguisher accessible; Know shelter-in-place location&lt;/p&gt;&lt;p&gt;- Power Outage: Generator: OUTSIDE ONLY; Keep 20ft/6m from openings (CO risk)&lt;/p&gt;&lt;p&gt;- Pets: ID tags + microchip; Carrier/leash; Food/water; Medications; Vaccination records&lt;/p&gt;&lt;p&gt;- Children: Comfort item; ID bracelet; Emergency contact card; Age-appropriate instructions&lt;/p&gt;&lt;head rend="h2"&gt;üí∞ Financial Help&lt;/head&gt;üá∫üá∏ USA: FEMA (housing, repairs) | SBA Loans | Benefits.gov | SNAP/Food&lt;p&gt;üá®üá¶ Canada: EI Benefits | CRA Disaster Relief | Red Cross Aid&lt;/p&gt;&lt;p&gt;Both: 211 connects to local aid&lt;/p&gt;&lt;p&gt;Tip: Document damage with photos BEFORE cleanup; keep all receipts&lt;/p&gt;&lt;head rend="h2"&gt;üîÑ Recovery&lt;/head&gt;Before entering: Wait for official all-clear; check for gas smell, structural damage&lt;p&gt;Inside: No electricity if flooding; photograph everything; wear N95 + gloves&lt;/p&gt;&lt;p&gt;Food safety: Discard if power out 4+ hrs (fridge) or thawed (freezer); when in doubt, throw it out&lt;/p&gt;&lt;p&gt;Mold: Appears within 24-48 hrs; dry everything; clean with water/detergent; consider N95&lt;/p&gt;&lt;p&gt;Avoid: Contractor scams (get multiple bids, check licenses); price gouging (report to AG)&lt;/p&gt;&lt;head rend="h2"&gt;üìö Resources&lt;/head&gt;Guides: Emergency Guide | First Aid | Shelter &amp;amp; Safety&lt;p&gt;üá∫üá∏ USA: FEMA 1-800-621-3362 (no immigration check) | Shelters 1-800-733-2767 | Power Outages&lt;/p&gt;&lt;p&gt;üá®üá¶ Canada: GetPrepared.gc.ca | Red Cross 1-800-418-1111 | Weather Alerts | Public Safety&lt;/p&gt;&lt;p&gt;Crisis (Both): 988 Suicide/Crisis | 211 Local aid | DV: 1-800-799-7233 (US) / 1-866-363-1681 (CA)&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46868479</guid><pubDate>Tue, 03 Feb 2026 09:06:04 +0000</pubDate></item><item><title>What's up with all those equals signs anyway?</title><link>https://lars.ingebrigtsen.no/2026/02/02/whats-up-with-all-those-equals-signs-anyway/</link><description>&lt;doc fingerprint="6ff2d15d65fe3faf"&gt;
  &lt;main&gt;
    &lt;p&gt;For some reason or other, people have been posting a lot of excerpts from old emails on Twitter over the last few days. The most vital question everybody‚Äôs asking themselves is: What‚Äôs up with all those equals signs?!&lt;/p&gt;
    &lt;p&gt;And that‚Äôs something I‚Äôm somewhat of an expert on. I mean, having written mail readers and stuff; not because I‚Äôve been to Caribbean islands.&lt;/p&gt;
    &lt;p&gt;I‚Äôve seen people confidently claim that it‚Äôs a code, or that it‚Äôs an artefact of scanning and then using OCR, but it‚Äôs neither ‚Äî it‚Äôs just that whoever converted these emails to a readable format were morons.&lt;/p&gt;
    &lt;p&gt;What‚Äôs that you say? ‚ÄúConverted?! Surely emails are just text!!‚Äù Well, if you lived in the stone age (i.e., the 80s), they mostly were, but then people invented things like ‚Äúlong lines‚Äù and ‚Äúrock d√∂ts‚Äù, and computers had to ‚Äúencode‚Äù the mail before sending.&lt;/p&gt;
    &lt;p&gt;The artefact we see here is from something called ‚Äúquoted printable‚Äù, or as we used to call it when it was introduced: ‚ÄúQuoted unreadable‚Äù.&lt;/p&gt;
    &lt;p&gt;To take the first line. Whoever wrote this, typed in the following in their mail reader:&lt;/p&gt;
    &lt;quote&gt;we talked about designing a pig with different non- cloven hoofs in order to make kosher bacon&lt;/quote&gt;
    &lt;p&gt;We see that that‚Äôs quite a long line. Mail servers don‚Äôt like that, so mail software will break it into two lines, like so:&lt;/p&gt;
    &lt;quote&gt;we talked about designing a pig with different non- = cloven hoofs in order to make kosher bacon&lt;/quote&gt;
    &lt;p&gt;See? There‚Äôs that equals sign! Yes, the equals sign is used to say ‚Äúthis should really be one single line, but I‚Äôve broken it in two so that the mail server doesn‚Äôt get mad at me‚Äù.&lt;/p&gt;
    &lt;p&gt;The formal definition here is important, though, so I have to be a bit technical here: To say ‚Äúthis is a continuation line‚Äù, you insert an equals sign, then a carriage return, and then a line feed.&lt;/p&gt;
    &lt;p&gt;Or,&lt;/p&gt;
    &lt;quote&gt;=CRLF&lt;/quote&gt;
    &lt;p&gt;Three characters in total, i.e., :&lt;/p&gt;
    &lt;quote&gt;... non- =CRLF cloven hoofs...&lt;/quote&gt;
    &lt;p&gt;When displaying this, we remove all these three characters, and end up&lt;lb/&gt; with:&lt;/p&gt;
    &lt;quote&gt;... non- cloven hoofs...&lt;/quote&gt;
    &lt;p&gt;So what‚Äôs happened here? Well, whoever collected these emails first converted from CRLF (also known as the ‚ÄúWindows‚Äù line ending coding, but it‚Äôs the standard line ending in the SMTP standard) to ‚ÄúNL‚Äù (i.e., ‚ÄúUnix‚Äù line ending coding). This is pretty normal if you want to deal with email. But you then have one byte fewer:&lt;/p&gt;
    &lt;quote&gt;... non- =NL cloven hoofs...&lt;/quote&gt;
    &lt;p&gt;If your algorithm to decode this is, stupidly, ‚Äúfind equals signs at the end of the line, and then delete two characters, and then finally the equals sign‚Äù, you should end up with:&lt;/p&gt;
    &lt;quote&gt;... non- loven hoofs...&lt;/quote&gt;
    &lt;p&gt;I.e., you lose the ‚Äúc‚Äù. That‚Äôs almost what happened here, but not quite: Why does the equals sign still remain?&lt;/p&gt;
    &lt;p&gt;This StackOverflow post from 14 years ago explains the phenomenon, sort of:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Obviously the client notices that = is not followed by a proper CR LF sequence, so it assumes that it is not a soft line break, but a character encoded in two hex digits, therefore it reads the next two bytes. It should notice that the next two bytes are not valid hex digits, so its behavior is wrong too, but we have to admit that at that point it does not have a chance to display something useful. They opted for the garbage in, garbage out approach.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That is, equals signs are also used for something else besides wrapping long lines, and that‚Äôs what we see later in the post:&lt;/p&gt;
    &lt;quote&gt;=C2 please note&lt;/quote&gt;
    &lt;p&gt;If the equals sign is not at the end of a line, it‚Äôs used to encode ‚Äúfunny characters‚Äù, like what you use with ‚Äúrock d√∂ts‚Äù. =C2 is 194, which is a first character in a UTF-8 sequence, and the following char is most likely a =A0: =C2=A0 is ‚Äúnon-breakable space‚Äù, which is something people often use to indent text (and the ‚Äúplease note‚Äù is indented) and you see =A0 in many other places in these emails.&lt;/p&gt;
    &lt;p&gt;My guess is that whoever did this part just did a search-replace for =C2 and/or =A0 instead of using a proper decoder, but other explanations are certainly possible. Any ideas?&lt;/p&gt;
    &lt;p&gt;Anyway, that‚Äôs what‚Äôs up with those equals signs: 1) ‚Äúit‚Äôs technical‚Äù, and 2) ‚Äúit‚Äôs a combination of buggy continuation line decoding and buggy non-ASCII decoding‚Äù, and 3) ‚Äúwhoever processed these mails are incompetent‚Äù. I don‚Äôt think 2) should be very surprising at this point, do you?&lt;/p&gt;
    &lt;p&gt;(Edit a bit later: To nitpick a bit here: When the standard was written, people mostly envisioned that the quoted-printable content transport encoding would be unwound upon reception (note ‚Äútransport‚Äù), and that you‚Äôd end up with ‚Äúclean text‚Äù on disk after reception. This didn‚Äôt really happen, so all ‚Äúreal‚Äù implementations do the right thing with single-character (i.e., ‚Äúunencoded‚Äù) newlines. For instance:&lt;/p&gt;
    &lt;quote&gt;(quoted-printable-decode-string "he=\nllo") =&amp;gt; "hello"&lt;/quote&gt;
    &lt;p&gt;Which leads me to assume that they reused an algo that was usually run in an SMTP server context to do the line unfolding ‚Äî in that context, you can safely assume that the line ending is a CRLF. And by chance, this algo also works fine if you‚Äôre working with a Windows-based file, but fails for a Unix-based file.)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46868759</guid><pubDate>Tue, 03 Feb 2026 09:37:40 +0000</pubDate></item><item><title>Emerge Career (YC S22) is hiring a product designer</title><link>https://www.ycombinator.com/companies/emerge-career/jobs/omqT34S-founding-product-designer</link><description>&lt;doc fingerprint="3d88781899c444b5"&gt;
  &lt;main&gt;
    &lt;p&gt;All-in-one re-entry &amp;amp; workforce development training platform&lt;/p&gt;
    &lt;p&gt;Emerge Career‚Äôs mission is to break the cycle of poverty and incarceration. We‚Äôre not just building software; we‚Äôre creating pathways to real second chances. Through an all-in-one platform deeply embedded within the criminal justice system, we recruit, train, and place justice-impacted individuals into life-changing careers.&lt;/p&gt;
    &lt;p&gt;Our vision is to become the country‚Äôs unified workforce development system, replacing disconnected brick-and-mortar job centers with one integrated, tech-powered solution that meets low-income individuals exactly where they are. Today, the federal government spends billions annually on education and training programs, yet only about 70% of participants graduate, just 38.6% secure training-related employment, and average first-year earnings hover around $34,708.&lt;/p&gt;
    &lt;p&gt;By contrast, our seven-person team has already outperformed the job centers in two entire states (Vermont and South Dakota) in just the past year. With an 89% graduation rate and 92% of graduates securing training-related employment, our alumni aren‚Äôt just getting jobs‚Äîthey‚Äôre launching new lives with average first-year earnings of $77,352. The results speak for themselves, and we‚Äôre just getting started.&lt;/p&gt;
    &lt;p&gt;Before Emerge, our founders Zo and Gabe co-founded Ameelio, an award-winning tech nonprofit that is dismantling the prison communication duopoly. Backed by tech luminaries like Reid Hoffman, Vinod Khosla, and Jack Dorsey, and by major criminal-justice philanthropies such as Arnold Ventures and the Mellon Foundation, Ameelio became a recognized leader in the space. Because of this experience both Zo and Gabe understood what it took to create change from within the system. After serving over 1M people impacted by incarceration, they witnessed firsthand the gap in second-chance opportunities and the chronic unemployment plaguing those impacted by the justice system. Emerge Career is committed to solving this issue.&lt;/p&gt;
    &lt;p&gt;Our students are at the heart of our work. Their journeys have captured national attention on CBS, NBC, and in The Boston Globe, and our programs now serve entire states and cities. And we‚Äôre not doing it alone: our vision has attracted support from Alexis Ohanian (776), Michael Seibel, Y Combinator, the Opportunity Fund, and public figures like Diana Taurasi, Deandre Ayton, and Marshawn Lynch. All of us believe that, with the right mix of technology and hands-on practice, we can redefine workforce development and deliver true second chances at scale.&lt;/p&gt;
    &lt;p&gt;Emerge Career was designed to tackle two systemic issues: recidivism, fueled by post-incarceration unemployment and poverty, and labor shortages in key industries. Over 60% of formerly incarcerated people remain unemployed a year after incarceration, seeking work but not finding it. The reality is shocking, workforce development programs are severely limited inside prison, with only one-third of incarcerated people ever participating. To worsen, the available prison jobs offer meager wages, often less than $1 per hour, and often do not equip individuals with the skills for long-term stable employment.&lt;/p&gt;
    &lt;p&gt;We call this a Founding Design Engineer role, even three years in and with multiple contracts under our belt, for two reasons. First, you'll be our very first engineer, joining our co-founder, who's built the entire platform solo to date. Second, our growth is now outpacing our systems, and we can't keep up on maintenance alone. We're at a critical juncture: we can either hire someone to simply care for what exists, or we can bring on a talent who believes that, with the right blend of technology and hands-on practice, we can unify the workforce-development system and deliver second chances at true scale. We hope that can be you.&lt;/p&gt;
    &lt;p&gt;This is not a traditional engineering job. You'll build features in React and TypeScript, but your real job is helping students finish. That means understanding the human problem first: why do people disengage? What makes someone choose to keep going when the payoff is months away? You'll answer those questions through direct conversations, usability research, and watching how people actually use what you build. Then you'll prototype fast, ship real software, and measure whether it worked. Some days that looks like code. Other days it looks like a phone call, a support ticket, or a whiteboard session figuring out how to turn a one-off fix into a system that scales.&lt;/p&gt;
    &lt;p&gt;This role blends engineering, product, design, and program operations. We're looking for someone who believes good design can inspire a person to invest in their own future, and who wants to prove it, week after week, by shipping work that measurably helps students succeed. If you want to be close to users, own outcomes end to end, and build something that actually matters, you'll thrive here.&lt;/p&gt;
    &lt;p&gt;You design by building. You don't hand off mockups and wait. You open Cursor, Claude Code, or whatever gets you closest to a real, testable thing fastest. You might already be shipping code in production ‚Äî or you're itching to. You believe the fastest path to a great design is putting something real in front of a real user and watching what happens.&lt;/p&gt;
    &lt;p&gt;You are relentlessly scrappy. You prototype in hours, not weeks. You'd rather test an ugly thing that teaches you something than polish a beautiful thing nobody's used yet. You know that at this stage, speed of learning is the only thing that matters. Fidelity comes later. Signal comes first.&lt;/p&gt;
    &lt;p&gt;You refuse to be blocked. When engineering bandwidth isn't there, you don't sit around. You figure it out ‚Äî a Figma prototype, a coded prototype, a quick hack in the codebase. You treat "waiting for a developer" as a personal failure. You find a way or you make one.&lt;/p&gt;
    &lt;p&gt;You think in outcomes, not outputs. You don't measure your work in screens delivered. You measure it in whether students finished, whether they came back, whether the thing you shipped actually moved a number that matters. You're obsessed with the gap between what you designed and what actually happened.&lt;/p&gt;
    &lt;p&gt;You talk to users constantly. Not in scheduled quarterly research sprints ‚Äî in real conversations, every week. You build relationships with students. You know their names, their blockers, their moments of doubt. Your best design ideas come from a 10-minute phone call, not a brainstorm.&lt;/p&gt;
    &lt;p&gt;You have strong taste but low ego. You have opinions about what good looks like and you'll fight for them. But when the data says you're wrong, you move on fast. You don't fall in love with your work. You fall in love with the problem.&lt;/p&gt;
    &lt;p&gt;You believe everyone deserves a second chance. You treat everyone with dignity. You know how to meet people exactly where they are ‚Äî with empathy and compassion ‚Äî helping create a space where everyone feels seen and valued, regardless of their background.&lt;/p&gt;
    &lt;p&gt;You work hard. You show up early, stay late, and do what needs to get done ‚Äî no ego, no excuses. This isn't a 9-to-5. The team puts in 10+ hour days because we care about the mission and each other. If that sounds miserable, this isn't for you. If it sounds exciting, you'll fit right in.&lt;/p&gt;
    &lt;p&gt;Talking to students ‚Äî a lot. Your week starts and ends with users. You'll build real relationships with students, not just run usability sessions. You'll understand why someone almost quit, what message made them log back in, what screen confused them at 11pm. These conversations are your primary design tool.&lt;/p&gt;
    &lt;p&gt;Prototyping at the speed of conversation. You hear a problem on a call Tuesday. By Wednesday you have something testable ‚Äî a coded prototype, a functional hack, a Figma flow wired to real data. By Thursday a student is using it. By Friday you know if it worked. That's the cycle. Repeat.&lt;/p&gt;
    &lt;p&gt;Shipping real product, not just designs. You'll work in our React and TypeScript codebase ‚Äî or use AI tools like Cursor and Claude Code to get there. The goal isn't to become a full-time engineer. The goal is to never let "it hasn't been built yet" slow down learning. Some of what you build will go straight to production. Some will be throwaway prototypes. You'll know the difference.&lt;/p&gt;
    &lt;p&gt;Designing the moments that keep students going. The hardest design problem here isn't layout or typography. It's commitment. Students are betting months of effort on a future they have to imagine. You'll study where they disengage, what triggers doubt, and what reignites momentum. Then you'll design the moments ‚Äî an interface, a message, a milestone ‚Äî that help someone choose to keep going. How do you make a better life in three months feel worth the sacrifice today? You'll own that problem.&lt;/p&gt;
    &lt;p&gt;Measuring what matters. Polished decks don't matter here. You'll define success metrics for what you ship, track whether completion rates moved, whether more students hit the next milestone, whether the intervention you designed actually intervened. You'll close the loop between design and outcome every time.&lt;/p&gt;
    &lt;p&gt;Working across the entire stack of the student experience. Some days that looks like interface design. Other days it looks like rethinking a Customer.io campaign, redesigning an onboarding flow, or sitting with the ops team to understand why students in one facility disengage faster than another. You go where the problem is.&lt;/p&gt;
    &lt;p&gt;Documenting your work clearly. Our work spans months and involves multiple teams. You'll create visibility when a change impacts operations and help others understand how features affect training and service delivery. Precision matters.&lt;/p&gt;
    &lt;p&gt;Start Date: ASAP&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46869901</guid><pubDate>Tue, 03 Feb 2026 12:00:23 +0000</pubDate></item><item><title>Bunny Database</title><link>https://bunny.net/blog/meet-bunny-database-the-sql-service-that-just-works/</link><description>&lt;doc fingerprint="a71f183a5d20d688"&gt;
  &lt;main&gt;
    &lt;p&gt;Don√¢t want to babysit your app database on a VM but not willing to pay the DBaaS tax either? We're building a third way.&lt;/p&gt;
    &lt;p&gt;Today, we√¢re launching Bunny Database as a public preview: a SQLite-compatible managed service that spins down when idle, keeps latency low wherever your users are, and doesn√¢t cost a fortune.&lt;/p&gt;
    &lt;head rend="h2"&gt;So what√¢s the deal with database services in 2026?&lt;/head&gt;
    &lt;p&gt;It√¢s become clear by now that the DBaaS platforms that garnered the love of so many devs are all going upmarket. Removing or dumbing down free tiers, charging for unused capacity, charging extra for small features, or bundling them in higher tiers √¢ you already know the drill.&lt;/p&gt;
    &lt;p&gt;Hard to blame anyone for growing their business, but it doesn√¢t feel right when these services stop making sense for the very people who helped popularize them in the first place.&lt;/p&gt;
    &lt;p&gt;So where does that leave you?&lt;/p&gt;
    &lt;head rend="h2"&gt;Like SQLite, but for the web&lt;/head&gt;
    &lt;p&gt;Not every project needs Postgres, and that√¢s okay. Sometimes you just want a simple, reliable database that you can spin up quickly and build on, without worrying it√¢ll hit your wallet like an EC2.&lt;/p&gt;
    &lt;p&gt;That√¢s what we built Bunny Database for.&lt;/p&gt;
    &lt;p&gt;What you get:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One-click deployment: just name your database and go, no config needed&lt;/item&gt;
      &lt;item&gt;Language-specific tooling: SDKs for TS/JS, Go, Rust, and .NET help you handle the boring bits&lt;/item&gt;
      &lt;item&gt;Low latency anywhere: replication regions let you serve reads close to your users&lt;/item&gt;
      &lt;item&gt;41 regions worldwide: choose between automatic, single-region, and multi-region deployment&lt;/item&gt;
      &lt;item&gt;Works over HTTP: wire up anything you√¢d like&lt;/item&gt;
      &lt;item&gt;Database editor: insert data or run queries on the spot&lt;/item&gt;
      &lt;item&gt;Metrics: instant visibility into reads, writes, storage, and latency&lt;/item&gt;
      &lt;item&gt;Affordable, pay-as-you-go pricing: only pay for what you use, but without the serverless tax&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get the full tour including how to connect Bunny Database to your app in this quick demo from our DX Engineer, Jamie Barton:&lt;/p&gt;
    &lt;head rend="h2"&gt;Why care about database latency anyway?&lt;/head&gt;
    &lt;p&gt;You probably optimize the heck out of your frontend, APIs, and caching layers, all for the sake of delivering an experience that feels instant to your users. But when your database is far away from them, round-trip time starts to add noticeable latency.&lt;/p&gt;
    &lt;p&gt;The usual fix is to introduce more caching layers, denormalized reads, or other workarounds. That√¢s obviously no fun.&lt;/p&gt;
    &lt;p&gt;And when you think about it, devs end up doing this because the popular DBaaS platforms are usually either limited, complex, or too costly when it comes to multi-region deployments. So what looks like a caching problem is actually a data locality issue.&lt;/p&gt;
    &lt;p&gt;OK, but how bad can it really be?&lt;/p&gt;
    &lt;p&gt;To find out, we ran a read latency benchmark and measured p95 latency in Bunny Database.&lt;/p&gt;
    &lt;p&gt;We picked a number of regions across the world and compared round-trip time for client locations ever farther away from the database in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a single-region setup,&lt;/item&gt;
      &lt;item&gt;with replication regions enabled.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Turns out serving reads close to clients reduced latency by up to 99%.&lt;/p&gt;
    &lt;p&gt;Check out the full write-up on the benchmark setup and results here.&lt;/p&gt;
    &lt;p&gt;While this definitely matters most to apps with global users, data locality does apply to everyone. With Bunny Database, you don√¢t have to stick to major data center locations and compensate with caching workarounds any more. Instead, you get a lot of flexibility to set up regions in an intuitive interface and it√¢s easy to switch things up as your requirements change.&lt;/p&gt;
    &lt;p&gt;Choose between 3 deployment types when creating a database:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic region selection gives you one-click deployment with minimal latency. Bunny Database will select regions for you based on your IP address (you can check and tweak the selection in settings later).&lt;/item&gt;
      &lt;item&gt;Single-region deployment lets you pick one of 41 regions available worldwide (check the full list here).&lt;/item&gt;
      &lt;item&gt;Manual region selection gives you custom multi-region setup, where you can freely pick regions that make the most sense for your audience.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All of this lets you start wherever you√¢d like and add regions as needed, without re-architecting your app.&lt;/p&gt;
    &lt;head rend="h2"&gt;Usage-based pricing, but without the serverless tax&lt;/head&gt;
    &lt;p&gt;In the database world, capacity-based pricing gives you some predictability. But no one likes to pay for unused capacity, right?&lt;/p&gt;
    &lt;p&gt;Serverless, on the other hand, is supposed to be cost-efficient, yet can rack up bills quickly, especially when the DBaaS charges significant markups on top of already pricey compute.&lt;/p&gt;
    &lt;p&gt;We don√¢t do hyperscalers, though, so we can charge a fair price for Bunny Database in a usage-based model.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reads: $0.30 per billion rows&lt;/item&gt;
      &lt;item&gt;Writes: $0.30 per million rows&lt;/item&gt;
      &lt;item&gt;Storage: $0.10 per GB per active region (monthly)&lt;/item&gt;
      &lt;item&gt;When not getting requests, Bunny Database only incurs storage costs. One primary region is charged continuously, while read replicas only add storage costs when serving traffic (metered by the hour)&lt;/item&gt;
      &lt;item&gt;Your usage is charged continuously (pay-as-you-go) and invoiced monthly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;During the public preview phase, Bunny Database is free.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wait, what does √¢SQLite-compatible√¢ actually mean?&lt;/head&gt;
    &lt;p&gt;Bunny Database wouldn√¢t be possible without libSQL, the open-source, open-contribution fork of SQLite created by Turso.&lt;/p&gt;
    &lt;p&gt;We run Bunny Database on our own fork of libSQL, which gives us the freedom to integrate it tightly with the bunny.net platform and handle the infrastructure and orchestration needed to run it as a managed, multi-region service.&lt;/p&gt;
    &lt;p&gt;What does this mean for Bunny Database√¢s upstream feature parity with libSQL and SQLite, respectively?&lt;/p&gt;
    &lt;p&gt;The short answer is that we don√¢t currently promise automatic or complete feature parity with either upstream libSQL or the latest SQLite releases.&lt;/p&gt;
    &lt;p&gt;While libSQL aims to stay compatible with SQLite√¢s API and file format, it doesn√¢t move in lockstep with upstream SQLite. We wouldn√¢t expect otherwise, especially as Turso has shifted focus from libSQL toward a long-term rewrite of SQLite in Rust.&lt;/p&gt;
    &lt;p&gt;For Bunny Database, this means that compatibility today is defined by the libSQL version we√¢re built on, rather than by chasing every upstream SQLite or libSQL change as it lands. We haven√¢t pulled in any upstream changes yet, and we don√¢t currently treat upstream parity as an automatic goal.&lt;/p&gt;
    &lt;p&gt;That√¢s intentional. Our focus so far has been on making Bunny Database reliable and easy to operate as a service. We think bringing in upstream changes only makes sense when they clearly improve real-world use cases, not just to tick a parity checkbox.&lt;/p&gt;
    &lt;p&gt;If there are specific libSQL features you√¢d like to see exposed in Bunny Database, or recent SQLite features you√¢d want us to pull in, we√¢d love to hear about it. Join our Discord to discuss your use cases and help shape the roadmap!&lt;/p&gt;
    &lt;head rend="h2"&gt;What√¢s ahead for Bunny Database&lt;/head&gt;
    &lt;p&gt;Speaking of the roadmap, we don√¢t stop cooking. Here√¢s what√¢s coming up next:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic backups&lt;/item&gt;
      &lt;item&gt;Database file import/export&lt;/item&gt;
      &lt;item&gt;Auto-generated, schema-aware API with type-safe SDKs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There√¢s even more to come, but it√¢s too soon to spill the beans yet, especially while we√¢re in public preview. We√¢d love to hear your feedback, so we can shape what ships next together.&lt;/p&gt;
    &lt;head rend="h2"&gt;More tools to build with&lt;/head&gt;
    &lt;p&gt;Bunny Database works standalone and fits right into your stack via the SDKs (or you can hook up anything using the HTTP API). But it also plays nicely with Bunny Edge Scripting and Bunny Magic Containers.&lt;/p&gt;
    &lt;p&gt;To connect your database to an Edge Script or a Magic Containers app, simply go to the Access tab of the chosen database and click Generate Tokens to create new access credentials for it.&lt;/p&gt;
    &lt;p&gt;Once they√¢re generated, you√¢ll get two paths to choose from:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Click Add Secrets to an Edge Script and select the one you√¢d like to connect from the list. You√¢ll also need to import the libSQL TypeScript client and use the provided code snippet to connect it to your database.&lt;/item&gt;
      &lt;item&gt;Click Add Secrets to Magic Container App and select the one you√¢d like to connect from the list. You√¢ll also need to connect to the database from your app using one of the client libraries or the HTTP API.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After you complete the setup, the database URL and access token will be available as environment variables in your script or app. Use them to connect to your database:&lt;/p&gt;
    &lt;code&gt;import&lt;/code&gt;
    &lt;code&gt;{&lt;/code&gt;
    &lt;code&gt;createClient&lt;/code&gt;
    &lt;code&gt;}&lt;/code&gt;
    &lt;code&gt;from&lt;/code&gt;
    &lt;code&gt;"@libsql/client/web"&lt;/code&gt;
    &lt;code&gt;;&lt;/code&gt;
    &lt;code&gt;const&lt;/code&gt;
    &lt;code&gt;client&lt;/code&gt;
    &lt;code&gt;=&lt;/code&gt;
    &lt;code&gt;createClient&lt;/code&gt;
    &lt;code&gt;({&lt;/code&gt;
    &lt;code&gt;url&lt;/code&gt;
    &lt;code&gt;:&lt;/code&gt;
    &lt;code&gt;process.env.&lt;/code&gt;
    &lt;code&gt;DB_URL&lt;/code&gt;
    &lt;code&gt;,&lt;/code&gt;
    &lt;code&gt;authToken&lt;/code&gt;
    &lt;code&gt;:&lt;/code&gt;
    &lt;code&gt;process.env.&lt;/code&gt;
    &lt;code&gt;DB_TOKEN&lt;/code&gt;
    &lt;code&gt;});&lt;/code&gt;
    &lt;code&gt;const&lt;/code&gt;
    &lt;code&gt;result&lt;/code&gt;
    &lt;code&gt;=&lt;/code&gt;
    &lt;code&gt;client&lt;/code&gt;
    &lt;code&gt;.&lt;/code&gt;
    &lt;code&gt;execute&lt;/code&gt;
    &lt;code&gt;(&lt;/code&gt;
    &lt;code&gt;"SELECT * FROM users"&lt;/code&gt;
    &lt;code&gt;);&lt;/code&gt;
    &lt;p&gt;You can find more detailed, step-by-step integration instructions in the docs:&lt;/p&gt;
    &lt;head rend="h2"&gt;Hop on board&lt;/head&gt;
    &lt;p&gt;We can√¢t wait to see what you√¢ll build with Bunny Database and what you think of it. During the public preview phase, you get 50 databases per user account, each capped at 1 GB, but we hope this should be more than enough for lots of fun projects.&lt;/p&gt;
    &lt;p&gt;Just sign in to the bunny.net dashboard to get started. Happy building!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46870015</guid><pubDate>Tue, 03 Feb 2026 12:13:44 +0000</pubDate></item><item><title>Show HN: difi ‚Äì A Git diff TUI with Neovim integration (written in Go)</title><link>https://github.com/oug-t/difi</link><description>&lt;doc fingerprint="77950df911a2f782"&gt;
  &lt;main&gt;
    &lt;p&gt;Review and refine Git diffs before you push&lt;/p&gt;
    &lt;p&gt;git diff shows changes. difi helps you review them.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ö°Ô∏è Instant ‚Äî Built in Go. Launches immediately with no daemon or indexing.&lt;/item&gt;
      &lt;item&gt;üé® Structured ‚Äî A clean file tree and focused diffs for fast mental parsing.&lt;/item&gt;
      &lt;item&gt;üß† Editor-Aware ‚Äî Jump straight to the exact line in &lt;code&gt;nvim&lt;/code&gt;/&lt;code&gt;vim&lt;/code&gt;to fix issues.&lt;/item&gt;
      &lt;item&gt;‚å®Ô∏è Keyboard-First ‚Äî Navigate everything with &lt;code&gt;h j k l&lt;/code&gt;. No mouse required.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;brew tap oug-t/difi
brew install difi&lt;/code&gt;
    &lt;code&gt;go install github.com/oug-t/difi/cmd/difi@latest&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Download the binary from Releases and add it to your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run difi in any Git repository.&lt;/item&gt;
      &lt;item&gt;By default, it compares your current branch against main.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;cd my-project
difi&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key&lt;/cell&gt;
        &lt;cell role="head"&gt;Action&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Tab&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle focus between File Tree and Diff View&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;j / k&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Move cursor down / up&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;h / l&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Focus Left (Tree) / Focus Right (Diff)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;e&lt;/code&gt; / &lt;code&gt;Enter&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Edit file (opens editor at selected line)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;?&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Toggle help drawer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;q&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Quit&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Get the ultimate review experience with difi.nvim.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Auto-Open: Instantly jumps to the file and line when you press &lt;code&gt;e&lt;/code&gt;in the CLI.&lt;/item&gt;
      &lt;item&gt;Visual Diff: Renders diffs inline with familiar green/red highlights‚Äîjust like reviewing a PR on GitHub.&lt;/item&gt;
      &lt;item&gt;Interactive Review: Restore a "deleted" line by simply removing the &lt;code&gt;-&lt;/code&gt;marker. Discard an added line by deleting it entirely.&lt;/item&gt;
      &lt;item&gt;Context Aware: Automatically syncs with your &lt;code&gt;difi&lt;/code&gt;session target.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To use &lt;code&gt;difi&lt;/code&gt; as a native git command (e.g., &lt;code&gt;git difi&lt;/code&gt;), add it as an alias in your global git config:&lt;/p&gt;
    &lt;code&gt;git config --global alias.difi '!difi'&lt;/code&gt;
    &lt;p&gt;Now you can run it directly from git:&lt;/p&gt;
    &lt;code&gt;git difi&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/oug-t/difi
cd difi
go run cmd/difi/main.go&lt;/code&gt;
    &lt;p&gt;Contributions are especially welcome in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;diff.nvim rendering edge cases&lt;/item&gt;
      &lt;item&gt;UI polish and accessibility&lt;/item&gt;
      &lt;item&gt;Windows support&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made with ‚ù§Ô∏è by oug-t&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46870917</guid><pubDate>Tue, 03 Feb 2026 13:47:24 +0000</pubDate></item><item><title>Agent Skills</title><link>https://agentskills.io/home</link><description>&lt;doc fingerprint="8f77afff0b4fb448"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Why Agent Skills?&lt;/head&gt;Agents are increasingly capable, but often don‚Äôt have the context they need to do real work reliably. Skills solve this by giving agents access to procedural knowledge and company-, team-, and user-specific context they can load on demand. Agents with access to a set of skills can extend their capabilities based on the task they‚Äôre working on. For skill authors: Build capabilities once and deploy them across multiple agent products. For compatible agents: Support for skills lets end users give agents new capabilities out of the box. For teams and enterprises: Capture organizational knowledge in portable, version-controlled packages.&lt;head rend="h2"&gt;What can Agent Skills enable?&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Domain expertise: Package specialized knowledge into reusable instructions, from legal review processes to data analysis pipelines.&lt;/item&gt;&lt;item&gt;New capabilities: Give agents new capabilities (e.g. creating presentations, building MCP servers, analyzing datasets).&lt;/item&gt;&lt;item&gt;Repeatable workflows: Turn multi-step tasks into consistent and auditable workflows.&lt;/item&gt;&lt;item&gt;Interoperability: Reuse the same skill across different skills-compatible agent products.&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871173</guid><pubDate>Tue, 03 Feb 2026 14:09:54 +0000</pubDate></item><item><title>Ask HN: Is there anyone here who still uses slide rules?</title><link>https://news.ycombinator.com/item?id=46871179</link><description>&lt;doc fingerprint="7f899b1c3be4bbbc"&gt;
  &lt;main&gt;
    &lt;p&gt;I designed and 3D-printed my own slide rule to help me play Balatro!&lt;/p&gt;
    &lt;p&gt;Balatro is a roguelike survival game where you need to multiply "chips" and "mult" together to meet a requirement each round. You get three chances to draft enough resources to survive. I designed my own slide rule to help with the mental multiplication - most of the fun of the game comes from the mechanics being slightly obscured from the player.&lt;/p&gt;
    &lt;p&gt;Since I designed this slide rule myself, I was able to make a couple unconventional design choices that fit my needs. For instance, mine has three octaves so it can represent numbers within the ones, thousands, or millions' range, for example; no need to track arbitrary powers of ten. Since it's a rotary rule, it wraps around. Eg. 353√ó24 shows on the device as 8.47, so you can think of it as 8.47 thousand, for example.&lt;/p&gt;
    &lt;p&gt;Holding a physical object in my hands while playing helps more than I thought it would. Should I take a card that increases chips by 600 or increases mult by 1.3√ó? Do I need to take a card to clear the blind in the short term, or do I have enough resources to draft a slower card that will scale better over time? Even just looking at how densely packed the marks are on the "Chips" side vs the "Mult" side of the device gives a visceral physical sense of what my build needs to focus on.&lt;/p&gt;
    &lt;p&gt;I do not use, and have never used, a slide rule. My grandfather was an aeronautical engineering / materials scientist for McDonnell Aircraft, and did a lot of foundational work on heat shields for early space flight (or so I am told). He was eventually named a McDonnell Douglas Fellow, back when there were fewer than 15 Fellows - the company, at the time, took out a full-page ad in Aerospace Magazine announcing it.&lt;/p&gt;
    &lt;p&gt;I have his slide rule, that he used for ages. It's a mystery in a box to me - I have not the foggiest clue how it is used - but I cherish it.&lt;/p&gt;
    &lt;p&gt;&amp;gt; I have not the foggiest clue how it is used - but I cherish it.&lt;/p&gt;
    &lt;p&gt;It's easier and more straightforward than you might expect. I encourage you to learn to use his slide rule, in large part because you might find it fun, but also to honor your grandfather's legacy.&lt;/p&gt;
    &lt;p&gt;I had a similar experience! My grandfather worked at a paper company for years and years as a chemical engineer. He was a hot head, but lightened up as I got older. We started to connect well later in life because I was the only other "engineering type" in my family.&lt;/p&gt;
    &lt;p&gt;He gave me his slide rule probably a year or so before he passed away. I've got it sitting on my desk and always makes me think of him. Like you, I've got no idea how to use it (even though he tried to explain it to me), so maybe the other comments here can fill in the gaps for me :)&lt;/p&gt;
    &lt;p&gt;A key idea is that addition for logs is equivalent to multiplication. To multiply two numbers you line them up on a log scale and then read out the sum, which is equivalent to the product. There is much more they can do but that was one aha moment when my dad showed me his.&lt;/p&gt;
    &lt;p&gt;I've never used a slide rule but recently developed an interest in them (and also in nomograms [1])&lt;/p&gt;
    &lt;p&gt;My fascination stems from a belief: that slide rule usage helps users develop a certain intuition for numbers whereas the calculator doesn't. To illustrate, suppose someone tries to multiply 123 and 987 with a calculator but incorrectly punches in 123 and 187. My hypothesis is they'll look at the result but won't suspect any problem. The equivalent operation on a slide rule requires fewer physical actions and hence, is less error prone.&lt;/p&gt;
    &lt;p&gt;Nomograms are the tabletop gaming of math. Sure, you can go play Factorio on a computer if you want, but you have to respect the craft that goes into a tablet-top game like Power Grid and High Frontier.&lt;/p&gt;
    &lt;p&gt;Nomograms are fun because, through cleverness, you can encode a surprising amount of complexity and nonlinearity on a 2D plane. Just as Verilog people can physically realize functions that Rust people can't (e.g. truly parallel CAM search), nomogram people can physically realize functions Verilog people can't.&lt;/p&gt;
    &lt;p&gt;I recall one tabletop two-player game that featured a single-player mode in which you played against an "AI" that you ran by hand by moving cardboard pieces around on a game-provided template under pseudocode-ish rules from the game manual. It's hard enough to code a decent game AI with all the resources of a CPU at your disposal. It's an OOM harder to do it when you're limited to physically-realized lookup tables, a literal handful of registers, and a scant few clock cycles of logic per turn.&lt;/p&gt;
    &lt;p&gt;And, coming full circle, some of these tabletop game "AI"s incorporate nomograms to help them fit their logic within the constraints.&lt;/p&gt;
    &lt;p&gt;My grandfather was a computational meteorologist for the US Air Force who passed when I was a kid. I inherited both his slide rule and his laptop (a 486dx with a math coprocessor!) It felt cool being the only kid at the school with a laptop, but the slide rule languished in a box under my bed until I got it out and figured out how to work it in college. I wish I'd figured it out sooner because it gave a more visceral understanding of the mathematical relationships that I'd been lacking before. Granted, the slide rule has sat mostly idle since then, but it was definitely worth it. I'd encourage you to give it a go.&lt;/p&gt;
    &lt;p&gt;I have one on my watch. It‚Äôs a citizen with a circular slide rule /E6B flight computer. I need my reading glasses to use it, but it‚Äôs fun.&lt;/p&gt;
    &lt;p&gt;It can reliably get me 2 sig figs, and a decent guess at a third. But‚Ä¶ if I think about it for a minute, I can usually get that in my head anyway. Being able to setup a ratio is great though for unit conversions and things.&lt;/p&gt;
    &lt;p&gt;It‚Äôs also really good for answering that question when driving where you‚Äôre like, ok if I go 10mph faster how much sooner will I get there which is otherwise hard to do mentally.&lt;/p&gt;
    &lt;p&gt;Most of the benefit of using a slide rule in my experience comes not from using it, but from thinking LIKE you‚Äôre going to use a slide rule. You learn to freely use scientific notation with ease, and mental estimation to get the order of magnitude right.&lt;/p&gt;
    &lt;p&gt;And just my 2 cents, but circular slide rules are where it‚Äôs at.&lt;/p&gt;
    &lt;p&gt;A big 6-foot K&amp;amp;E sliderule hung at the front of my high-school chemistry classroom, but was never used. At graduation ('91) I asked the teacher if I could have the slide rule and she said "sure".&lt;/p&gt;
    &lt;p&gt;I keep it now in my office, and once a year I bring to the data visualization class I teach at UChicago, to show how it works, and to show it as an example of a visual device in aid of computational thinking (nomographs being another great example).&lt;/p&gt;
    &lt;p&gt;I used them in high school in the late 1990s... just to get an extra challenge. I had my dad's and grandfather's and I picked up a couple at garage sales. I still have a collection, but haven't really used them in years. I'll probably break them out again when my kids get in middle school / high school math for fun. They are great for learning the rules of logs.&lt;/p&gt;
    &lt;p&gt;Following a post on HN a few weeks ago, I bought a used one to use in the kitchen for scaling recipes. It has to be a linear one for that, not circular, so you can set it and read it without touching it again. I also have one in my "apocalypse kit" in case of, I dunno, an EMP?&lt;/p&gt;
    &lt;p&gt;My dad was an engineer in the slide rule era and taught me how to use one when I was a kid. He said when he was in college all the engineering students had them hanging from their belts in leather sheaths like gladiator swords and they would slap when they walked.&lt;/p&gt;
    &lt;p&gt;Although slide rules are a "dead skill," Aviators typically learn to use something called an E6B Flight Computer, which works on the same principle as a round slide rule.&lt;/p&gt;
    &lt;p&gt;I have one in my flight bag and was required to demonstrate proficiency in its use. Of course we fly with connected digital devices these days, but having an analogue backup that operates even if the power fails is important.&lt;/p&gt;
    &lt;p&gt;I have a couple of EB6s to show to my students but ever since scientific calculators were allowed in written tests, I have never used one myself. Law of cosines is good enough for wind triangles :). Worked for a commercial test as well as the ATP. It is a beautiful device though ...&lt;/p&gt;
    &lt;p&gt;Similar point applies to being able to use a sextant for celestial navigation in bluewater sailing. GPS is great, until you lose power or your equipment malfunctions. Of course, you can have double or triple redundancy to make such cases vanishingly rare, but still ‚Äî it‚Äôs nice to have a backup that relies on nothing outside your control.&lt;/p&gt;
    &lt;p&gt;Some of it is pure nostalgia, though, I‚Äôll admit. It a way to honor how people solved similar problems in the past. In the 18th century a sextant plus accurate chronometer or lunar distance table was one of the pivotal technologies of the age; you could use it to pinpoint your location on the boundless ocean within a few miles. That demands respect, and it‚Äôs also just really cool it was possible in an era before electricity and radio.&lt;/p&gt;
    &lt;p&gt;&amp;gt; Some of it is pure nostalgia, though, I‚Äôll admit. It a way to honor how people solved similar problems in the past. In the 18th century a sextant plus accurate chronometer or lunar distance table was one of the pivotal technologies of the age; you could use it to pinpoint your location on the boundless ocean within a few miles. That demands respect, and it‚Äôs also just really cool it was possible in an era before electricity and radio.&lt;/p&gt;
    &lt;p&gt;Heh heh, I was in the Sailing Cub in high school, and our Sailing Master (RIP Master Gibb) said literally the same thing about learning to navigate with sextant and chronometer even though we never sailed out of sight of land. It was all about deep respect for the history and tradition of being a Mariner.&lt;/p&gt;
    &lt;p&gt;Now I fly gliders, "the purest form of flight," and while you can get a glider with electrically operated landing gear, a jet sustainer engine, and digital navigation and flight computing devices...&lt;/p&gt;
    &lt;p&gt;There is something extraordinarily pure about the exercise of flying with everything electrical turned off (except for the transponder and radio for safety). And even purer... Flying with covered instruments so we don't even get analogue airspeed and altitude.&lt;/p&gt;
    &lt;p&gt;Circling back to slide rules... Sometimes we crave that simplicity, that direct experience of a thing.&lt;/p&gt;
    &lt;p&gt;I used a calculator throughout college; they had just become relatively affordable. But I still generally brought a slide rule to exams in case something happened to my calculator. (They were LED displays and things weren't as generally reliable at that time.)&lt;/p&gt;
    &lt;p&gt;Somewhere around here, I have a Proportion Calculator wheel which I used for determining the size/scaling of graphics --- I was the only person in the shop who could use it though, everyone else used calculators or once I showed them how, did math in the size field of the applications such as Freehand/MX which allowed math.&lt;/p&gt;
    &lt;p&gt;When I was in high school, (early 1990s,) there was a giant one mounted above the blackboard. It was clearly used for instruction in the past, but it looked so cool that no one wanted to remove it.&lt;/p&gt;
    &lt;p&gt;Every once in awhile a teacher would spend about 10-15 minutes showing how to use it. Everyone would "oooh" and "awww" and then we would all laugh about how we didn't need to use them now that we all had calculators in our pocket that were more powerful than the computers that put people on the moon.&lt;/p&gt;
    &lt;p&gt;It's always nice to learn about the past so we can appreciate what we have now.&lt;/p&gt;
    &lt;p&gt;I've picked it back up as an intentional way of slowing myself down during calculations.&lt;/p&gt;
    &lt;p&gt;Typically to do a calc I fire up Excel or the calc on my phone, bang in the numbers and accept the result without thinking. It's that "without thinking" part that is dangerous. The slide rule is slow and physical and forces my brain to think about the inputs. Another nice feature is that it can give you quick answers when you aren't sure of the accuracy of the inputs. eg if 2 * 4 was really 1.8*4.1, what would the answer be? Its quicker to see that on a sliderule than punch in 7 characters.&lt;/p&gt;
    &lt;p&gt;When I was in high school, calculators had just hit the scene. Some teachers allowed them, others didn't.&lt;/p&gt;
    &lt;p&gt;One of our teachers allowed us to bring a single page of notes to the exam. I wrote my notes on a photocopy of a slide rule. At exam time, I tore the sheet in half.&lt;/p&gt;
    &lt;p&gt;Of course the teacher thought I was being a smart-ass, and given that the tests were written when calculators were not allowed, they were never really all that useful.&lt;/p&gt;
    &lt;p&gt;In college chemistry, at each exam, they handed out a sheet that had the periodic table on one side, and a table of logarithms on the other.&lt;/p&gt;
    &lt;p&gt;I have two or three that I inherited from my dad. I've never learned to use them because I haven't thought of something I'd use them for. The one thing I could think of is quickly doing fractional math while woodworking (what width will I have if I rip this 7.5" board into 4 pieces?) but in reality I just don't actually do that much math while woodworking.&lt;/p&gt;
    &lt;p&gt;As mentioned elsewhere you can use them in the kitchen if you start wanting to scale recipes at will - it's easy to double, but with a slide rule you can quickly get other ratios.&lt;/p&gt;
    &lt;p&gt;Works better when you do things by weight and metrically, no doubt.&lt;/p&gt;
    &lt;p&gt;We learned to use them in high school (in Canada) in the mid-late '70s. Electronic calculators were just becoming widespread, and not everyone had them.&lt;/p&gt;
    &lt;p&gt;I think I can do basic calculations with them, although I really haven't touched one in many years.&lt;/p&gt;
    &lt;p&gt;I used a circular slide rule when I first started flight training. It was used in flight planing to calculate ground speed and a few other things. You can still buy one.&lt;/p&gt;
    &lt;p&gt;My grandfather taught me, I have long since forgotten. But I do recall that the killer use case was cube roots, which as opposed to multiplication or even square roots is difficult to do with pen and paper and much harder to mentally estimate.&lt;/p&gt;
    &lt;p&gt;I have a little collection of slide rules. I love those things.&lt;/p&gt;
    &lt;p&gt;I'm not old enough to have used them to do calculations, but I find them extremely useful to explain logarithms and how multiplication can be represented by the sum of logarithms. I actually work with grad students who should know these things, but watching it in a slide rule on their hands really helps to build intuition.&lt;/p&gt;
    &lt;p&gt;Yep. I have one and I keep showing off how to do math using it, to kids.I have also replaced the broken slider with a plastic piece after etching the log scale onto it.&lt;/p&gt;
    &lt;p&gt;I worked at a countertop shop and used a sliding rule a bit. But I also used a sticky paper with marks to get measurements off my screen. A lot of blueprints provide no dimensions for cabinets and desks.&lt;/p&gt;
    &lt;p&gt;Countertops is an industry with all the modern tools but 5000yo approach.&lt;/p&gt;
    &lt;p&gt;I don't use one "seriously", or even really know how to use one to be honest. But I did buy one last year, with the intention to learn to use it. Why? Novelty mostly, and just general intellectual curiosity. I haven't really had time to dig into working with it yet though. :-(&lt;/p&gt;
    &lt;p&gt;I found usage really helps you learn how to WAG (Wild Ass Guess).&lt;/p&gt;
    &lt;p&gt;It also scares the crap out of me to think about what infinity is: you see your slide manipulate incredible numbers, then you imagine a slide that is twice as big. Or a few feet long.&lt;/p&gt;
    &lt;p&gt;I used a slide rule for some of my high school physics tests in the 2010s, just for fun. I lost a few points from messing up order of magnitude calculations, but it was totally worth it. I've since collected a few more slide rules from estate sales in my neighborhood. I wish more people knew about them‚Äîthey're such a neat and elegant part of engineering history, which is why I keep them around.&lt;/p&gt;
    &lt;p&gt;I have no use for them on a day-to-day basis, though. An abacus is more useful for things like counting board game points and adding up taxes.&lt;/p&gt;
    &lt;p&gt;I have some from my father, but even though he showed me how to use them a long time ago, I never actually used them. I do however encourage anyone with an interest to go to the Arithmeum in Bonn (Germany) if you have the chance. It houses an large collection of regular and specialized sliderules as well as other (mechanical) computational devices.&lt;/p&gt;
    &lt;p&gt;Now that's a properly dead skill, surely. I have my dad's one somewhere, and know roughly how it works, but I've not touched it this century.&lt;/p&gt;
    &lt;p&gt;I also have one of these: https://archive.org/details/spencersdecimalr0000unse ; I believe they were popular around the time of the UK converting to decimal currency, to save people having to do the transitional arithmetic. Had a bunch of other tables in. A physical LUT.&lt;/p&gt;
    &lt;p&gt;I wonder if there's anyone with abacus skills here. I hear that held out against calculators a lot longer, for shopkeeper uses.&lt;/p&gt;
    &lt;p&gt;Yes, but just as a ruler. It belonged to my Dad who was an avionics engineer starting back in the 1950s. He worked all over the world seeing out the end of the British Empire. It smells of old cigarettes and is very worn and chipped.&lt;/p&gt;
    &lt;p&gt;I have half a dozen of them (including my father's from college) that I cherish, but do not use. I love the simplicity and elegance of the design. (Slide rules do a lot with operations that essentially boil down to addition, subtraction, and looking up function values in tables.)&lt;/p&gt;
    &lt;p&gt;I built my own slide rule in school for fun! It looked pretty cool to me at the time. The template is still out there if you search something like "paper slide rule".&lt;/p&gt;
    &lt;p&gt;I've collected some links for building regular slide rules ([1] &amp;amp; [2]) as well as a circular slide rule [3]. Someone might also like the slide rule simulator [4].&lt;/p&gt;
    &lt;p&gt;I bought one a few months ago off of ebay after I realized how important logarithms are in many different domains (including machine learning &amp;amp; information theory)&lt;/p&gt;
    &lt;p&gt;Knew a mechanical engineer at a place where I interned. Asked him about it and he joked that he didn't trust those transistors before explaining that it's just muscle memory to him and while a calculator would be faster he'd still earn the same per hour. Apparently I was the first to ask him in over a decade as everyone had moved on to do stuff in software and no one was pushing him to use a calculator anymore. Interns didn't inquire because they thought it must be some esoteric/religious practice. Last I heard he was still working there, management asked him to stay on past retirement age for his invaluable skillset. While its probably some other skill I just like to imagine the suits in a meeting where they decided to keep him on for this particular "skill" that no one else in the company had anymore.&lt;/p&gt;
    &lt;p&gt;"The Analytical Rule might be considered a distant relation ‚Äì as a skyscraper is to a shack ‚Äì of that kindergarten toy, the logarithmic Slide Rule. Darell used it with the wristflip of long practice. He made freehand drawings of the result and, as Anthor stated, there were featureless plateaus in frontal lobe regions where strong swings should have been expected."&lt;/p&gt;
    &lt;p&gt;I'd really love an Analytical Rule, this hoverboard of the early atomic era.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871179</guid><pubDate>Tue, 03 Feb 2026 14:10:21 +0000</pubDate></item><item><title>Show HN: Inverting Agent Model (App as Clients, Chat as Server and Reflection)</title><link>https://github.com/RAIL-Suite/RAIL</link><description>&lt;doc fingerprint="d929afdb8c6ea8b5"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;One line of code to make any application AI-controllable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;RAIL is a universal bridge that connects any application (C#, C++, Python, Node.js) to any LLM (GPT, Claude, Gemini). Instead of rewriting your application, you add one line of code and the AI can call your methods directly.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Project&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RailOrchestrator&lt;/cell&gt;
        &lt;cell&gt;Main AI application (UI + LLM routing)&lt;/cell&gt;
        &lt;cell&gt;C# / WPF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RailBridge.Native&lt;/cell&gt;
        &lt;cell&gt;Native DLL for cross-language IPC&lt;/cell&gt;
        &lt;cell&gt;C# (Native AOT)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RailSDK.Universal&lt;/cell&gt;
        &lt;cell&gt;Client SDK for .NET apps&lt;/cell&gt;
        &lt;cell&gt;C# (.NET Standard)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RailSDK&lt;/cell&gt;
        &lt;cell&gt;Analysis &amp;amp; manifest generation tools&lt;/cell&gt;
        &lt;cell&gt;C#&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RailSDK-Cpp&lt;/cell&gt;
        &lt;cell&gt;Client SDK for C++ apps&lt;/cell&gt;
        &lt;cell&gt;C++&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RailSDK-Python&lt;/cell&gt;
        &lt;cell&gt;Client SDK for Python apps&lt;/cell&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RailSDK-Node&lt;/cell&gt;
        &lt;cell&gt;Client SDK for Node.js apps&lt;/cell&gt;
        &lt;cell&gt;TypeScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;RailStudio&lt;/cell&gt;
        &lt;cell&gt;Visual tool for scanning/analyzing apps&lt;/cell&gt;
        &lt;cell&gt;C# / WPF&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ConvertedProjectExample&lt;/cell&gt;
        &lt;cell&gt;Example applications&lt;/cell&gt;
        &lt;cell&gt;C#&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The Brain - Main application that users interact with.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;WPF desktop application (.NET 9)&lt;/item&gt;
      &lt;item&gt;Connects to LLMs (Gemini, OpenAI, Anthropic, Claude)&lt;/item&gt;
      &lt;item&gt;ReAct agent loop for multi-step reasoning&lt;/item&gt;
      &lt;item&gt;Hosts the Named Pipe server for client connections&lt;/item&gt;
      &lt;item&gt;Manages assets (Chips) and tool routing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Key files:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Services/Host/HostService.cs&lt;/code&gt;- Named Pipe server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Services/LLMService.cs&lt;/code&gt;- LLM API integration&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Services/ReAct/ReActOrchestrator.cs&lt;/code&gt;- Agent loop&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Bridge - Native DLL that enables cross-language communication.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compiled with Native AOT for C-ABI compatibility&lt;/item&gt;
      &lt;item&gt;Exposes functions callable from any language: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;RAIL_Ignite()&lt;/code&gt;- Connect to host&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Uses Named Pipes for IPC&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Target: Python, C++, Node.js, Rust, Go&lt;/p&gt;
    &lt;p&gt;The .NET SDK - Client library for C# applications.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;.NET Standard 2.0 (compatible with .NET Framework 4.6.1+)&lt;/item&gt;
      &lt;item&gt;Simple API: &lt;code&gt;RailEngine.Ignite(this)&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Auto-discovers methods via reflection&lt;/item&gt;
      &lt;item&gt;Loads &lt;code&gt;RailBridge.dll&lt;/code&gt;for communication&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;// In App.xaml.cs
RailEngine.Ignite(this);&lt;/code&gt;
    &lt;p&gt;The Toolkit - Assembly scanning and manifest generation.&lt;/p&gt;
    &lt;p&gt;Contains:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;RuntimeRegistry&lt;/code&gt;- Detect .NET / Native binaries&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;AssemblyScanner&lt;/code&gt;- Extract methods from DLLs&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;CompositeManifest&lt;/code&gt;- Multi-module manifest format&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DependencyAnalyzer&lt;/code&gt;- Analyze project dependencies&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;SolutionScanner&lt;/code&gt;- Scan entire .sln solutions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Used by: RailStudio, RailOrchestrator&lt;/p&gt;
    &lt;p&gt;The C++ SDK - Enable C++ applications to connect.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CMake-based build system&lt;/item&gt;
      &lt;item&gt;Loads &lt;code&gt;RailBridge.dll&lt;/code&gt;via&lt;code&gt;LoadLibrary&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Callback-based command execution&lt;/item&gt;
      &lt;item&gt;Supports both x64 and x86 builds&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build:&lt;/p&gt;
    &lt;code&gt;build_x64.bat   # 64-bit
build_x86.bat   # 32-bit (legacy apps)&lt;/code&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;Rail::ignite("MyApp", manifestJson, onCommand);&lt;/code&gt;
    &lt;p&gt;The Python SDK - Enable Python scripts to connect.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses &lt;code&gt;ctypes&lt;/code&gt;to load&lt;code&gt;RailBridge.dll&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Decorator-based method registration&lt;/item&gt;
      &lt;item&gt;Simple API matching other SDKs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;from rail import RailEngine

engine = RailEngine()
engine.ignite([MyService()])&lt;/code&gt;
    &lt;p&gt;The Node.js SDK - Enable TypeScript/JavaScript apps to connect.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses &lt;code&gt;ffi-napi&lt;/code&gt;for native bridge access&lt;/item&gt;
      &lt;item&gt;TypeScript types included&lt;/item&gt;
      &lt;item&gt;Promise-based API&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;import { RailEngine } from 'rail-sdk';
engine.ignite([new MyService()]);&lt;/code&gt;
    &lt;p&gt;The Visual Tool - Scan and analyze applications.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;EXE/DLL to analyzer&lt;/item&gt;
      &lt;item&gt;Auto-generates &lt;code&gt;rail.manifest.json&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Visualizes dependencies&lt;/item&gt;
      &lt;item&gt;Solution-wide scanning&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use case: Preparing legacy apps for Rail integration&lt;/p&gt;
    &lt;p&gt;Example applications showing SDK integration.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;AgentTest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Simple WPF app with customer database&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;WorkflowDemo&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Workflow automation example&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Manifest Here you can find Manifest folder with all the "rail.manifest.json" already created for this example application&lt;/p&gt;
    &lt;p&gt;When converting your application to be AI-controllable, here's exactly what you need:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;What to Add&lt;/cell&gt;
        &lt;cell role="head"&gt;Automatically Included&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;C# (.NET)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;RailSDK.Universal.dll&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;RailBridge.dll&lt;/code&gt; (auto-copied)&lt;/cell&gt;
        &lt;cell&gt;One reference, everything included&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;C++ (Modern)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;rail_sdk.dll&lt;/code&gt; + &lt;code&gt;RailBridge.dll&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;cell&gt;RTTR reflection, auto method discovery&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;C++ (Legacy)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;rail_sdk.dll&lt;/code&gt; + &lt;code&gt;RailBridge.dll&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;cell&gt;Custom dispatcher, manual routing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;RailBridge.dll&lt;/code&gt; + &lt;code&gt;rail&lt;/code&gt; package&lt;/cell&gt;
        &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;cell&gt;Load via &lt;code&gt;ctypes&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Node.js&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;RailBridge.dll&lt;/code&gt; + &lt;code&gt;rail-sdk&lt;/code&gt; npm&lt;/cell&gt;
        &lt;cell&gt;‚Äî&lt;/cell&gt;
        &lt;cell&gt;Load via &lt;code&gt;ffi-napi&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When you add &lt;code&gt;RailSDK.Universal&lt;/code&gt;, the native bridge is automatically copied to your output:&lt;/p&gt;
    &lt;code&gt;üìÅ bin/Debug/net8.0/
‚îú‚îÄ‚îÄ YourApp.exe
‚îú‚îÄ‚îÄ RailSDK.Universal.dll   ‚Üê You add this reference
‚îú‚îÄ‚îÄ RailBridge.dll          ‚Üê Copied automatically!
‚îî‚îÄ‚îÄ rail.manifest.json      ‚Üê You create this
&lt;/code&gt;
    &lt;p&gt;How to add:&lt;/p&gt;
    &lt;code&gt;&amp;lt;PackageReference Include="RailSDK.Universal" Version="2.0.0" /&amp;gt;&lt;/code&gt;
    &lt;p&gt;C++ has two integration modes depending on your codebase:&lt;/p&gt;
    &lt;p&gt;For new applications or codebases that support C++17:&lt;/p&gt;
    &lt;code&gt;// Register your classes with RTTR macros
RTTR_REGISTRATION {
    rttr::registration::class_&amp;lt;OrderManager&amp;gt;("OrderManager")
        .method("CreateOrder", &amp;amp;OrderManager::CreateOrder);
}

// SDK auto-discovers methods
rail::RegisterInstance("OrderManager", &amp;amp;myManager);
rail::Ignite("MyApp");&lt;/code&gt;
    &lt;p&gt;Files needed:&lt;/p&gt;
    &lt;code&gt;üìÅ YourApp/
‚îú‚îÄ‚îÄ YourApp.exe
‚îú‚îÄ‚îÄ rail_sdk.dll            ‚Üê C++ wrapper (includes RTTR)
‚îú‚îÄ‚îÄ RailBridge.dll          ‚Üê Native IPC bridge
‚îî‚îÄ‚îÄ rail.manifest.json      ‚Üê Auto-generated
&lt;/code&gt;
    &lt;p&gt;For legacy applications that can't use C++17 or RTTR (e.g., games, old codebases):&lt;/p&gt;
    &lt;code&gt;#define RAIL_NO_RTTR  // Disable RTTR

// Define your own command router
std::string MyDispatcher(const std::string&amp;amp; json) {
    if (json.find("MovePlayer") != std::string::npos) {
        MovePlayer();
        return "{\"result\": \"success\"}";
    }
    return "{\"error\": \"unknown\"}";
}

// Register and connect
rail::SetCustomDispatcher(MyDispatcher);
rail::Ignite("MyLegacyApp", "1.0", customManifest);&lt;/code&gt;
    &lt;p&gt;Files needed:&lt;/p&gt;
    &lt;code&gt;üìÅ YourApp/
‚îú‚îÄ‚îÄ YourApp.exe
‚îú‚îÄ‚îÄ rail_sdk.dll            ‚Üê C++ wrapper (no RTTR)
‚îú‚îÄ‚îÄ RailBridge.dll          ‚Üê Native IPC bridge
‚îî‚îÄ‚îÄ rail.manifest.json      ‚Üê You write this manually
&lt;/code&gt;
    &lt;quote&gt;
      &lt;p&gt;Real Examples: Notepad++ and Doom were integrated using Option B (Custom Dispatcher) because their codebases couldn't support RTTR.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;üìÅ YourProject/
‚îú‚îÄ‚îÄ main.py (or index.ts)
‚îú‚îÄ‚îÄ RailBridge.dll          ‚Üê Copy manually
‚îî‚îÄ‚îÄ rail.manifest.json      ‚Üê You create this
&lt;/code&gt;
    &lt;p&gt;Install the wrapper package that handles ctypes/ffi calls for you.&lt;/p&gt;
    &lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    RailOrchestrator                       ‚îÇ
‚îÇ                    (Main AI Application)                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  LLM APIs   ‚îÇ    ‚îÇ HostService ‚îÇ    ‚îÇ AssetService  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (Gemini,   ‚îÇ    ‚îÇ (Named Pipe ‚îÇ    ‚îÇ (Chip/Manifest‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   OpenAI)   ‚îÇ    ‚îÇ   Server)   ‚îÇ    ‚îÇ   Discovery)  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ
          ‚îÇ         Named Pipe: "RailHost"
          ‚îÇ                  ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ               RailBridge.Native            ‚îÇ
    ‚îÇ            (C-ABI Native DLL)                ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ               ‚îÇ               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ RailSDK   ‚îÇ ‚îÇ RailSDK   ‚îÇ ‚îÇ RailSDK   ‚îÇ
‚îÇ .Universal  ‚îÇ ‚îÇ -Cpp        ‚îÇ ‚îÇ -Python     ‚îÇ
‚îÇ (C# Apps)   ‚îÇ ‚îÇ (C++ Apps)  ‚îÇ ‚îÇ (Python)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ               ‚îÇ               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Your C#   ‚îÇ ‚îÇ  Your C++  ‚îÇ ‚îÇ Your Python ‚îÇ
‚îÇ    App     ‚îÇ ‚îÇ    App     ‚îÇ ‚îÇ   Script    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;
    &lt;code&gt;RailOrchestrator
    ‚îî‚îÄ‚îÄ uses ‚Üí RailSDK (RailFactory.Core) for manifest parsing
    
RailSDK.Universal
    ‚îî‚îÄ‚îÄ loads ‚Üí RailBridge.Native (DLL)
    
RailSDK-Cpp / RailSDK-Python / RailSDK-Node
    ‚îî‚îÄ‚îÄ load ‚Üí RailBridge.Native (DLL)

RailStudio
    ‚îî‚îÄ‚îÄ uses ‚Üí RailSDK (RailFactory.Core) for scanning
&lt;/code&gt;
    &lt;code&gt;// 1. Create your service
public class CustomerService
{
    public Customer GetCustomer(int id) =&amp;gt; Database.Find(id);
    public void CreateCustomer(string name, string email) { ... }
}

// 2. Add one line in App.xaml.cs
protected override void OnStartup(StartupEventArgs e)
{
    base.OnStartup(e);
    RailEngine.Ignite(this);
}

// 3. Create rail.manifest.json (or use RailStudio)&lt;/code&gt;
    &lt;code&gt;// Define callback
const char* OnCommand(const char* json) {
    auto cmd = ParseJson(json);
    if (cmd.method == "MoveMachine") {
        Machine::Move(cmd.args["x"], cmd.args["y"]);
        return R"({"result": "OK"})";
    }
    return R"({"error": "Unknown"})";
}

// Connect
rail::ignite("CNCController", manifest, OnCommand);&lt;/code&gt;
    &lt;code&gt;class DataProcessor:
    def analyze_data(self, file_path: str) -&amp;gt; dict:
        return {"rows": 1000, "status": "processed"}

engine = RailEngine()
engine.ignite([DataProcessor()])
engine.wait()&lt;/code&gt;
    &lt;p&gt;With apps connected, ask in natural language:&lt;/p&gt;
    &lt;code&gt;"Create a customer named John Smith with email john@example.com"
‚Üí AI calls CustomerService.CreateCustomer("John Smith", "john@example.com")

"Move the machine to position X=100, Y=200"
‚Üí AI calls CNCController.MoveMachine(100, 200)
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Run RailOrchestrator - The main AI interface&lt;/item&gt;
      &lt;item&gt;Connect your app - Add SDK and call &lt;code&gt;Ignite()&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Ask AI - Natural language commands execute your code&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RAIL Protocol - Bridging Legacy Applications and AI&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871251</guid><pubDate>Tue, 03 Feb 2026 14:16:49 +0000</pubDate></item><item><title>Show HN: Sandboxing untrusted code using WebAssembly</title><link>https://github.com/mavdol/capsule</link><description>&lt;doc fingerprint="c8903e58cf8302c2"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;code&gt;Capsule&lt;/code&gt; is a runtime for coordinating AI agent tasks in isolated environments. It is designed to handle, long-running workflows, large-scale processing, autonomous decision-making securely, or even multi-agent systems.&lt;/p&gt;
    &lt;p&gt;Each task runs inside its own WebAssembly sandbox, providing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Isolated execution: Each task runs isolated from your host system&lt;/item&gt;
      &lt;item&gt;Resource limits: Set CPU, memory, and timeout limits per task&lt;/item&gt;
      &lt;item&gt;Automatic retries: Handle failures without manual intervention&lt;/item&gt;
      &lt;item&gt;Lifecycle tracking: Monitor which tasks are running, completed, or failed&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This enables safe task-level execution of untrusted code within AI agent systems.&lt;/p&gt;
    &lt;p&gt;Simply annotate your Python functions with the &lt;code&gt;@task&lt;/code&gt; decorator:&lt;/p&gt;
    &lt;code&gt;from capsule import task

@task(name="analyze_data", compute="MEDIUM", ram="512MB", timeout="30s", max_retries=1)
def analyze_data(dataset: list) -&amp;gt; dict:
    """Process data in an isolated, resource-controlled environment."""
    # Your code runs safely in a Wasm sandbox
    return {"processed": len(dataset), "status": "complete"}&lt;/code&gt;
    &lt;p&gt;For TypeScript and JavaScript, use the &lt;code&gt;task()&lt;/code&gt; wrapper function with full access to the npm ecosystem:&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";

export const analyzeData = task({
  name: "analyze_data",
  compute: "MEDIUM",
  ram: "512MB",
  timeout: "30s",
  maxRetries: 1
}, (dataset: number[]): object =&amp;gt; {
  // Your code runs safely in a Wasm sandbox
  return { processed: dataset.length, status: "complete" };
});

// The "main" task is required as the entrypoint
export const main = task({
    name: "main",
    compute: "HIGH"
}, () =&amp;gt; {
  return analyzeData([1, 2, 3, 4, 5]);
});&lt;/code&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;The runtime requires a task named &lt;code&gt;"main"&lt;/code&gt; as the entry point. Python can define the main task itself, but it's recommended to set it manually.&lt;/p&gt;
    &lt;p&gt;When you run &lt;code&gt;capsule run main.py&lt;/code&gt; (or &lt;code&gt;main.ts&lt;/code&gt;), your code is compiled into a WebAssembly module and executed in a dedicated sandbox to isolate tasks.&lt;/p&gt;
    &lt;p&gt;Each task operates within its own sandbox with configurable resource limits, ensuring that failures are contained and don't cascade to other parts of your workflow. The host system controls every aspect of execution, from CPU allocation via Wasm fuel metering to memory constraints and timeout enforcement.&lt;/p&gt;
    &lt;p&gt;Every task returns a structured JSON envelope containing both the result and execution metadata:&lt;/p&gt;
    &lt;code&gt;{
  "success": true,
  "result": "Hello from Capsule!",
  "error": null,
  "execution": {
    "task_name": "data_processor",
    "duration_ms": 1523,
    "retries": 0,
    "fuel_consumed": 45000
  }
}&lt;/code&gt;
    &lt;p&gt;Response fields:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;success&lt;/code&gt;‚Äî Boolean indicating whether the task completed successfully&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;result&lt;/code&gt;‚Äî The actual return value from your task (json, string, null on failure etc..)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;error&lt;/code&gt;‚Äî Error details if the task failed (&lt;code&gt;{ error_type: string, message: string }&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;execution&lt;/code&gt;‚Äî Performance metrics:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;task_name&lt;/code&gt;‚Äî Name of the executed task&lt;/item&gt;&lt;item&gt;&lt;code&gt;duration_ms&lt;/code&gt;‚Äî Execution time in milliseconds&lt;/item&gt;&lt;item&gt;&lt;code&gt;retries&lt;/code&gt;‚Äî Number of retry attempts that occurred&lt;/item&gt;&lt;item&gt;&lt;code&gt;fuel_consumed&lt;/code&gt;‚Äî CPU resources used (see Compute Levels)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;pip install capsule-run&lt;/code&gt;
    &lt;p&gt;Create &lt;code&gt;hello.py&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;from capsule import task

@task(name="main", compute="LOW", ram="64MB")
def main() -&amp;gt; str:
    return "Hello from Capsule!"&lt;/code&gt;
    &lt;p&gt;Run it:&lt;/p&gt;
    &lt;code&gt;capsule run hello.py&lt;/code&gt;
    &lt;code&gt;npm install -g @capsule-run/cli
npm install @capsule-run/sdk&lt;/code&gt;
    &lt;p&gt;Create &lt;code&gt;hello.ts&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";

export const main = task({
  name: "main",
  compute: "LOW",
  ram: "64MB"
}, (): string =&amp;gt; {
  return "Hello from Capsule!";
});&lt;/code&gt;
    &lt;p&gt;Run it:&lt;/p&gt;
    &lt;code&gt;capsule run hello.ts&lt;/code&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;Use &lt;code&gt;--verbose&lt;/code&gt; to display real-time task execution details.&lt;/p&gt;
    &lt;p&gt;Configure your tasks with these parameters:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Parameter&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;code&gt;name&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Task identifier&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;str&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;function name (Python) / required (TS)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;"process_data"&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;code&gt;compute&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;CPU allocation level: &lt;code&gt;"LOW"&lt;/code&gt;, &lt;code&gt;"MEDIUM"&lt;/code&gt;, or &lt;code&gt;"HIGH"&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;str&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;"MEDIUM"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;"HIGH"&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;code&gt;ram&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Memory limit for the task&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;str&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;unlimited&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;"512MB"&lt;/code&gt;, &lt;code&gt;"2GB"&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;
          &lt;code&gt;timeout&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Maximum execution time&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;str&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;unlimited&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;"30s"&lt;/code&gt;, &lt;code&gt;"5m"&lt;/code&gt;, &lt;code&gt;"1h"&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;&lt;code&gt;max_retries&lt;/code&gt; / &lt;code&gt;maxRetries&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Number of retry attempts on failure&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;int&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;&lt;code&gt;allowed_files&lt;/code&gt; / &lt;code&gt;allowedFiles&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Folders accessible in the sandbox&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;[]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;["./data", "./output"]&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;env_variables&lt;/code&gt; / &lt;code&gt;envVariables&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Environment variables accessible in the sandbox&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;list&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;[]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;["API_KEY"]&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Capsule controls CPU usage through WebAssembly's fuel mechanism, which meters instruction execution. The compute level determines how much fuel your task receives.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LOW provides minimal allocation for lightweight tasks&lt;/item&gt;
      &lt;item&gt;MEDIUM offers balanced resources for typical workloads&lt;/item&gt;
      &lt;item&gt;HIGH grants maximum fuel for compute-intensive operations&lt;/item&gt;
      &lt;item&gt;CUSTOM to specify an exact fuel value (e.g., &lt;code&gt;compute="1000000"&lt;/code&gt;) for precise control over execution limits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can create a &lt;code&gt;capsule.toml&lt;/code&gt; file in your project root to set default options for all tasks and define workflow metadata:&lt;/p&gt;
    &lt;code&gt;# capsule.toml

[workflow]
name = "My AI Workflow"
version = "1.0.0"
entrypoint = "src/main.py"  # Default file when running `capsule run`

[tasks]
default_compute = "MEDIUM"
default_ram = "256MB"
default_timeout = "30s"
default_max_retries = 2&lt;/code&gt;
    &lt;p&gt;With an entrypoint defined, you can simply run:&lt;/p&gt;
    &lt;code&gt;capsule run&lt;/code&gt;
    &lt;p&gt;Task-level options always override these defaults when specified.&lt;/p&gt;
    &lt;p&gt;The standard Python &lt;code&gt;requests&lt;/code&gt; library and socket-based networking aren't natively compatible with WebAssembly's sandboxed I/O model. Capsule provides its own HTTP client that works within the Wasm environment:&lt;/p&gt;
    &lt;code&gt;from capsule import task
from capsule.http import get, post, put, delete

@task(name="http_example", compute="MEDIUM", timeout="30s")
def main() -&amp;gt; dict:
    """Example demonstrating HTTP client usage within a task."""

    # GET request
    response = get("https://api.example.com/data")

    # POST with JSON body
    response = post("https://api.example.com/submit", json={"key": "value"})

    # Response methods
    is_ok = response.ok()           # Returns True if status code is 2xx
    status = response.status_code    # Get the HTTP status code
    data = response.json()           # Parse response as JSON
    text = response.text()           # Get response as text

    return {"status": status, "success": is_ok}&lt;/code&gt;
    &lt;p&gt;Standard libraries like &lt;code&gt;fetch&lt;/code&gt; are already compatible, so no custom HTTP client is needed for TypeScript/JavaScript.&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";

export const main = task({
    name: "main",
    compute: "MEDIUM"
}, async () =&amp;gt; {
    const response = await fetch("https://api.example.com/data");
    return response.json();
});&lt;/code&gt;
    &lt;p&gt;Tasks can read and write files within directories specified in &lt;code&gt;allowed_files&lt;/code&gt;. Any attempt to access files outside these directories is not possible.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Currently, &lt;code&gt;allowed_files&lt;/code&gt; supports directory paths, not individual files.&lt;/p&gt;
    &lt;p&gt;Python's standard file operations work normally. Use &lt;code&gt;open()&lt;/code&gt;, &lt;code&gt;os&lt;/code&gt;, &lt;code&gt;pathlib&lt;/code&gt;, or any file manipulation library.&lt;/p&gt;
    &lt;code&gt;from capsule import task

@task(name="restricted_writer", allowed_files=["./output"])
def restricted_writer() -&amp;gt; None:
    with open("./output/result.txt", "w") as f:
        f.write("result")

@task(name="main")
def main() -&amp;gt; str:
    restricted_writer()&lt;/code&gt;
    &lt;p&gt;Common Node.js built-ins are available. Use the standard &lt;code&gt;fs&lt;/code&gt; module:&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";
import fs from "fs/promises";

export const restrictedWriter = task({
    name: "restricted_writer",
    allowedFiles: ["./output"]
}, async () =&amp;gt; {
    await fs.writeFile("./output/result.txt", "result");
});

export const main = task({ name: "main", allowedFiles: ["./data"] }, async () =&amp;gt; {
    await restrictedWriter();
    return await fs.readFile("./data/input.txt", "utf8");
});&lt;/code&gt;
    &lt;p&gt;Tasks can access environment variables to read configuration, API keys, or other runtime settings.&lt;/p&gt;
    &lt;p&gt;Use Python's standard &lt;code&gt;os.environ&lt;/code&gt; to access environment variables:&lt;/p&gt;
    &lt;code&gt;from capsule import task
import os

@task(name="main", env_variables=["API_KEY"])
def main() -&amp;gt; dict:
    api_key = os.environ.get("API_KEY")
    return {"api_key": api_key}&lt;/code&gt;
    &lt;p&gt;Use the standard &lt;code&gt;process.env&lt;/code&gt; to access environment variables:&lt;/p&gt;
    &lt;code&gt;import { task } from "@capsule-run/sdk";

export const main = task({
    name: "main",
    envVariables: ["API_KEY"]
}, () =&amp;gt; {
    const apiKey = process.env.API_KEY;
    return { apiKeySet: apiKey !== undefined };
});&lt;/code&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;TypeScript/JavaScript has broader compatibility than Python since it doesn't rely on native bindings.&lt;/p&gt;
    &lt;p&gt;Python: Pure Python packages and standard library modules work. Packages with C extensions (&lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;) are not yet supported.&lt;/p&gt;
    &lt;p&gt;TypeScript/JavaScript: npm packages and ES modules work. Common Node.js built-ins are available. If you have any trouble with a built-in do not hesitate to open an issue.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome!&lt;/p&gt;
    &lt;p&gt;Prerequisites: Rust (latest stable), Python 3.13+, Node.js 22+&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/mavdol/capsule.git
cd capsule

# Build and install CLI
cargo install --path crates/capsule-cli

# Python SDK (editable install)
pip install -e crates/capsule-sdk/python

# TypeScript SDK (link for local dev)
cd crates/capsule-sdk/javascript
npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; npm link

# Then in your project: npm link @capsule-run/sdk&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch: &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Run tests: &lt;code&gt;cargo test&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Open a Pull Request&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Need help? Open an issue&lt;/p&gt;
    &lt;p&gt;Capsule builds on these open source projects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;componentize-py ‚Äì Python to WebAssembly Component compilation&lt;/item&gt;
      &lt;item&gt;jco ‚Äì JavaScript toolchain for WebAssembly Components&lt;/item&gt;
      &lt;item&gt;wasmtime ‚Äì WebAssembly runtime&lt;/item&gt;
      &lt;item&gt;WASI ‚Äì WebAssembly System Interface&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the Apache License 2.0 - see the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871387</guid><pubDate>Tue, 03 Feb 2026 14:28:01 +0000</pubDate></item><item><title>GitHub Browser Plugin for AI Contribution Blame in Pull Requests</title><link>https://blog.rbby.dev/posts/github-ai-contribution-blame-for-pull-requests/</link><description>&lt;doc fingerprint="3741df528d35da3a"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Quickstart, TL;DR&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Learn about and add git-ai to your tooling, (git cli and editor extensions)&lt;/item&gt;
      &lt;item&gt;Build, install and authenticate refined-github-ai-pr&lt;/item&gt;
      &lt;item&gt;Push and pull request some Ai generated code via git to Github&lt;/item&gt;
      &lt;item&gt; Navigate to your PR in Github &lt;code&gt;https://github.com/&amp;lt;owner&amp;gt;/&amp;lt;repo&amp;gt;/pull/&amp;lt;PR ID&amp;gt;/changes&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Bask in the glory of ai annotations (scroll to the end ‚Üì for example screenshots)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Join my email list for updates&lt;/p&gt;
    &lt;head rend="h2"&gt;Identifying AI Contributions&lt;/head&gt;
    &lt;head rend="h3"&gt;The Rise of Low‚ÄëFriction AI Contributions&lt;/head&gt;
    &lt;p&gt;With the proliferation of effortless code‚Äëgenerating tools like Claude Code, Codex, and Cursor, slop‚Äëslung contributions are being doled out as outright spam in hopes of getting a name tacked onto popular open‚Äësource projects. Most are well‚Äëintentioned ‚Äî it‚Äôs just that this workflow is entirely new, and the tools and norms haven‚Äôt been established yet. Some open‚Äësource projects have publicly banned them (see: zig, tldr, ghostty), going so far as to vet contributors into a select trusted group.&lt;/p&gt;
    &lt;head rend="h3"&gt;When AI‚ÄëGenerated Code Can Be Appropriate&lt;/head&gt;
    &lt;p&gt;Oftentimes, depending on the preference of the team and project, less consequential and isolated code could warrant a 100% AI contribution. Non‚Äëuser‚Äëfacing tooling, a private beta feature, or a proof‚Äëof‚Äëconcept immediately come to mind. The ability to retroactively see which parts of the codebase were AI contributions, especially in these use cases, could be very valuable. What was tabbed in by Cursor at 3am six months ago could be a part of today‚Äôs refactor.&lt;/p&gt;
    &lt;head rend="h3"&gt;Percentages, Policies, and Maintainer Trust&lt;/head&gt;
    &lt;p&gt;Projects like Zig may never allow ai contributions, and I am not here to argue that they should change this stance. But in other cases, where the reaction is a heavy‚Äëhanded outright refusal, maintainers and developers could have a change of heart if they could codify an allowable percentage done by AI in each pull request. Even without a hard‚Äëand‚Äëfast rule, a percentage could serve as a sort of gut check ‚Äî an overall score as part of a bigger picture of quality in a PR.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enter the Git-Ai Project&lt;/head&gt;
    &lt;head rend="h3"&gt;What Git‚ÄëAI Does&lt;/head&gt;
    &lt;p&gt;The git-ai project allows you to automatically track agentic ai code contributions across your team and codebase, zeroing in line-by-line, preserving code-generating prompts, all while working within common git workflows. Git-ai works by extending and enhancing your current tooling without slowdown (thanks to Rust) while ‚Äòstaying out of the way‚Äô - so you can work as if it‚Äôs not even there.&lt;/p&gt;
    &lt;head rend="h3"&gt;What Data Git‚ÄëAI Captures&lt;/head&gt;
    &lt;p&gt;git-ai stores things like per-line ai contributions, the model and prompt given for the code generated.&lt;/p&gt;
    &lt;p&gt;git-ai works by storing this ai contribution data in git notes. Git notes are simply blobs attached to commit refs. It‚Äôs eloquent in that the meta data stays with the commit, git-ai also contains additional instrumentation to ‚Äúsurvive a &lt;code&gt;merge --squash&lt;/code&gt;, &lt;code&gt;rebase&lt;/code&gt;, &lt;code&gt;reset&lt;/code&gt;, &lt;code&gt;cherry-pick&lt;/code&gt; etc.‚Äù&lt;/p&gt;
    &lt;head rend="h3"&gt;Project Goals (From the README)&lt;/head&gt;
    &lt;p&gt;From the README.md:&lt;/p&gt;
    &lt;quote&gt;&lt;head&gt;Goals of&lt;/head&gt;&lt;code&gt;git-ai&lt;/code&gt;project&lt;p&gt;ü§ñ Track AI code in a Multi-Agent world. Because developers get to choose their tools, engineering teams need a vendor agnostic way to track AI impact in their repos.&lt;/p&gt;&lt;p&gt;üéØ Accurate attribution from Laptop ‚Üí Pull Request ‚Üí Merged. Claude Code, Cursor and Copilot cannot track code after generation‚ÄîGit AI follows it through the entire workflow.&lt;/p&gt;&lt;p&gt;üîÑ Support real-world git workflows by making sure AI-Authorship annotations survive a&lt;/p&gt;&lt;code&gt;merge --squash&lt;/code&gt;,&lt;code&gt;rebase&lt;/code&gt;,&lt;code&gt;reset&lt;/code&gt;,&lt;code&gt;cherry-pick&lt;/code&gt;etc.&lt;p&gt;üîó Maintain link between prompts and code - there is valuable context and requirements in team prompts‚Äîpreserve them alongside code.&lt;/p&gt;&lt;p&gt;üöÄ Git-native + Fast -&lt;/p&gt;&lt;code&gt;git-ai&lt;/code&gt;is built on git plumbing commands. Negligible impact even in large repos (&amp;lt;100ms). Tested in Chromium.&lt;/quote&gt;
    &lt;p&gt;NOTE: I have no affiliation with git-ai, but happily applaud their efforts, go check em‚Äô out! github.com/git-ai-project/git-ai&lt;/p&gt;
    &lt;head rend="h2"&gt;Github PR interface Support&lt;/head&gt;
    &lt;head rend="h3"&gt;Why Focus on Pull Requests&lt;/head&gt;
    &lt;p&gt;To experimentally work towards a developer friendly solution, I wanted to try dropping this tooling into a common point of convergence within collaborative version control workflows; Github Pull Requests&lt;/p&gt;
    &lt;head rend="h3"&gt;Existing Git‚ÄëAI Integrations with VSCode&lt;/head&gt;
    &lt;p&gt;git-ai comes with many integrations, and even has an RFC v3.0, so other tooling providers may implement it themselves. The VSCode integration works very well. AI contributed code is given a gutter highlight, and upon line selectshows the model responsible for said ai generated code, long-hovering provides even more context.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extending the GitHub PR Experience&lt;/head&gt;
    &lt;p&gt;To recreate this editor/code-view highlighting, as well as provide human-vs-ai percentage metering in the Github PR experience, I forked an existing github extended plugin github-refined into refined-github-ai-pr This plugin has all the features of the prior, even allowing you to toggle this ai contribution blaming feature on and off in the options (Be sure to check out the screenshots below)&lt;/p&gt;
    &lt;head rend="h3"&gt;More on Git-Ai Tooling‚Ä¶&lt;/head&gt;
    &lt;p&gt;Although there is currently no official support from git-ai (as of Jan 2026) for extending the Github PR interface with Git-ai annotations. There is an early access feature: Stat Bot - to ‚ÄúAggregate git-ai data at the PR, developer, repository and organization levels‚Äù It may be worth it for you to check out and could serve as an excellent way to support the creators of git-ai&lt;/p&gt;
    &lt;head rend="h3"&gt;Caveats&lt;/head&gt;
    &lt;p&gt;One Major Caveat with &lt;code&gt;refined-github-with-ai-pr&lt;/code&gt;, is that it relies on augmenting Github‚Äôs HTML via classes, which could very well change without notice, breaking this plugin.&lt;/p&gt;
    &lt;p&gt;This plugin serves as a beta and prototype, to fuel the conversation of what working with these new tools might look like; and I encourage community members to join the conversation. Maybe github will work towards adding this themselves in the future. Please comment on this post in hackernews or open an issue for refined-github-ai-pr I‚Äôd love to hear what you‚Äôre thinking!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871473</guid><pubDate>Tue, 03 Feb 2026 14:35:25 +0000</pubDate></item><item><title>A WhatsApp bug lets malicious media files spread through group chats</title><link>https://www.malwarebytes.com/blog/news/2026/01/a-whatsapp-bug-lets-malicious-media-files-spread-through-group-chats</link><description>&lt;doc fingerprint="9f00cd378b391549"&gt;
  &lt;main&gt;
    &lt;p&gt;WhatsApp is going through a rough patch. Some users would argue it has been ever since Meta acquired the once widely trusted messaging platform. User sentiment has shifted from ‚Äútrusted default messenger‚Äù to a grudgingly necessary Meta product.&lt;/p&gt;
    &lt;p&gt;Privacy-aware users still see WhatsApp as one of the more secure mass-market messaging platforms if you lock down its settings. Even then, many remain uneasy about Meta‚Äôs broader ecosystem, and wish all their contacts would switch to a more secure platform.&lt;/p&gt;
    &lt;p&gt;Back to current affairs, which will only reinforce that sentiment.&lt;/p&gt;
    &lt;p&gt;Google‚Äôs Project Zero has just disclosed a WhatsApp vulnerability where a malicious media file, sent into a newly created group chat, can be automatically downloaded and used as an attack vector.&lt;/p&gt;
    &lt;p&gt;The bug affects WhatsApp on Android and involves zero‚Äëclick media downloads in group chats. You can be attacked simply by being added to a group and having a malicious file sent to you.&lt;/p&gt;
    &lt;p&gt;According to Project Zero, the attack is most likely to be used in targeted campaigns, since the attacker needs to know or guess at least one contact. While focused, it is relatively easy to repeat once an attacker has a likely target list.&lt;/p&gt;
    &lt;p&gt;And to put a cherry on top for WhatsApp‚Äôs competitors, a potentially even more serious concern for the popular messaging platform, an international group of plaintiffs sued Meta Platforms, alleging the WhatsApp owner can store, analyze, and access virtually all of users‚Äô private communications, despite WhatsApp‚Äôs end-to-end encryption claims.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to secure WhatsApp&lt;/head&gt;
    &lt;p&gt;Reportedly, Meta pushed a server change on November 11, 2025, but Google says that only partially resolved the issue. So, Meta is working on a comprehensive fix.&lt;/p&gt;
    &lt;p&gt;Google‚Äôs advice is to disable Automatic Download or enable WhatsApp‚Äôs Advanced Privacy Mode so that media is not automatically downloaded to your phone.&lt;/p&gt;
    &lt;p&gt;And you‚Äôll need to keep WhatsApp updated to get the latest patches, which is true for any app and for Android itself.&lt;/p&gt;
    &lt;head rend="h3"&gt;Turn off auto-download of media&lt;/head&gt;
    &lt;p&gt;Goal: ensure that no photos, videos, audio, or documents are pulled to the device without an explicit decision.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Open WhatsApp on your Android device.&lt;/item&gt;
      &lt;item&gt;Tap the three‚Äëdot menu in the top‚Äëright corner, then tap Settings.&lt;/item&gt;
      &lt;item&gt;Go to Storage and data (sometimes labeled Data and storage usage).&lt;/item&gt;
      &lt;item&gt;Under Media auto-download, you will see When using mobile data, when connected on Wi‚ÄëFi. and when roaming.&lt;/item&gt;
      &lt;item&gt;For each of these three entries, tap it and uncheck all media types: Photos, Audio, Videos, Documents. Then tap OK.&lt;/item&gt;
      &lt;item&gt;Confirm that each category now shows something like ‚ÄúNo media‚Äù under it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Doing this directly implements Project Zero‚Äôs guidance to ‚Äúdisable Automatic Download‚Äù so that malicious media can‚Äôt silently land on your storage as soon as you are dropped into a hostile group.&lt;/p&gt;
    &lt;head rend="h3"&gt;Stop WhatsApp from saving media to your Android gallery&lt;/head&gt;
    &lt;p&gt;Even if WhatsApp still downloads some content, you can stop it from leaking into shared storage where other apps and system components see it.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In Settings, go to Chats.&lt;/item&gt;
      &lt;item&gt;Turn off Media visibility (or similar option such as Show media in gallery). For particularly sensitive chats, open the chat, tap the contact or group name, find Media visibility, and set it to No for that thread.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;WhatsApp is a sandbox, and should contain the threat. Which means, keeping media inside WhatsApp makes it harder for a malicious file to be processed by other, possibly more vulnerable components.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lock down who can add you to groups&lt;/head&gt;
    &lt;p&gt;The attack chain requires the attacker to add you and one of your contacts to a new group. Reducing who can do that lowers risk.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In Settings, tap Privacy.&lt;/item&gt;
      &lt;item&gt;Tap Groups.&lt;/item&gt;
      &lt;item&gt;Change from Everyone to My contacts or ideally My contacts except‚Ä¶ and exclude any numbers you do not fully trust.&lt;/item&gt;
      &lt;item&gt;If you use WhatsApp for work, consider keeping group membership strictly to known contacts and approved admins.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Set up two-step verification on your WhatsApp account&lt;/head&gt;
    &lt;p&gt;Read this guide for Android and iOS to learn how to do that.&lt;/p&gt;
    &lt;p&gt;We don‚Äôt just report on phone security‚Äîwe provide it&lt;/p&gt;
    &lt;p&gt;Cybersecurity risks should never spread beyond a headline. Keep threats off your mobile devices by downloading Malwarebytes for iOS, and Malwarebytes for Android today.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46871504</guid><pubDate>Tue, 03 Feb 2026 14:38:26 +0000</pubDate></item><item><title>Data Brokers Can Fuel Violence Against Public Servants</title><link>https://www.wired.com/story/how-data-brokers-can-fuel-violence-against-public-servants/</link><description>&lt;doc fingerprint="e29891d9dc839717"&gt;
  &lt;main&gt;
    &lt;p&gt;A new report published Tuesday finds that while violent threats to public servants across the US have been increasing, ‚Äúcomprehensive‚Äù state-level consumer privacy laws do not provide adequate protections for those civil servants, creating a ‚Äúdata-to-violence pipeline.‚Äù&lt;/p&gt;
    &lt;p&gt;The report was published by researcher Justin Sherman of the Security Project at the Public Service Alliance, a platform that provides free and discounted security services to current and former public servants. While Trump officials have referred to documenting federal immigration agents‚Äô behavior on the job as ‚Äúviolence‚Äù and ‚Äúdoxing,‚Äù Sherman says the report focuses on the more traditional, widely accepted definition‚Äîthe publication of someone‚Äôs personal, private information, such as their home address, with the specific intent of harming them.&lt;/p&gt;
    &lt;p&gt;Sherman analyzed 19 different consumer privacy laws and found that while they all give consumers the right to stop data brokers from selling personal information obtained from private sources, none give ‚Äúpublic servants the right to legally compel state agencies to redact their personal data from public records,‚Äù and none prevent data brokers from selling data, including people‚Äôs home addresses, when they are obtained through public sources such as property records or court filings. Further, none include what is called a ‚Äúprivate right of action,‚Äù which would allow individuals to sue over violations of their respective state‚Äôs privacy law.&lt;/p&gt;
    &lt;p&gt;Together, this means that information about public employees is uniquely available and that they have uniquely few ways to prevent its dissemination.&lt;/p&gt;
    &lt;p&gt;Violent threats against public servants have been increasing, according to a separate analysis by PSA and the Impact Project of over 1,600 individual threats made against public servants between 2015 and 2025. That analysis found that violent threats against local public servants, including school board members and election workers, represented nearly a third of the reports reviewed. It also found that threatening statements occurred at nearly nine times the rate of physical attacks, and that one form of threat can escalate into another.&lt;/p&gt;
    &lt;p&gt;A 2024 report from the Brennan Center for Justice found that larger shares of women and Democrats reported increases in the severity of abuse since first taking public office, compared with men and Republicans.&lt;/p&gt;
    &lt;p&gt;Last year, a 57-year-old man was charged with assassinating Melissa Hortman, a Democratic state representative, along with her husband at their home in Minnesota. According to court records, the alleged shooter had handwritten lists of dozens of Minnesota state and federal public officials, including Hortman‚Äôs name and her home address, along with 11 ‚Äúpeople search engines‚Äù that allow anyone to find personal information about a person, including their home addresses, phone numbers, and names of relatives, often for a nominal fee.&lt;/p&gt;
    &lt;p&gt;The report advocates for legislation that would specifically address privacy concerns for all public servants, including public school educators and local elected officials, who are not necessarily covered by existing federal or state privacy laws. It suggests that lawmakers could try to balance First Amendment and privacy concerns by regulating the digitization of public records and how easy they are to access remotely, instead of limiting them completely.&lt;/p&gt;
    &lt;p&gt;Sherman, the author of the new report, said that while many public records can be useful to journalists and accountability watchdogs, repackaged public records sold by data brokers can make it too easy for abusive individuals to stalk and harass victims even when they move to a different state. In the past, people seeking out public records would already have to have an idea of where that public record was, and physically go to that location.&lt;/p&gt;
    &lt;p&gt;While residents of states with consumer privacy laws can request limits on data collected from private sources, it‚Äôs not always easy to do so. Only one state, California, offers a way for residents to limit what information data brokers collect and sell about them en masse and for free via its Delete Request and Opt-out Platform. People in other states, including public servants, must file deletion requests manually or pay for an opt-out service that promises to do so on their behalf.&lt;/p&gt;
    &lt;p&gt;Last year, dozens of data brokers were caught hiding data removal instructions from Google, making it difficult for consumers to find them. Even when consumers pay to use services that specialize in filing data deletion requests, the results aren‚Äôt perfect. In 2024, Consumer Reports studied the effectiveness of seven different data removal services, which ranged from $19.99 to $249 a year in cost, and found that at best they were only successful about two-thirds of the time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872190</guid><pubDate>Tue, 03 Feb 2026 15:28:59 +0000</pubDate></item><item><title>Anthropic is Down</title><link>https://updog.ai/status/anthropic</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872481</guid><pubDate>Tue, 03 Feb 2026 15:48:03 +0000</pubDate></item><item><title>New York Wants to Ctrl+Alt+Delete Your 3D Printer</title><link>https://blog.adafruit.com/2026/02/03/new-york-wants-to-ctrlaltdelete-your-3d-printer/</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872540</guid><pubDate>Tue, 03 Feb 2026 15:51:42 +0000</pubDate></item><item><title>Qwen3-Coder-Next</title><link>https://qwen.ai/blog?id=qwen3-coder-next</link><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872706</guid><pubDate>Tue, 03 Feb 2026 16:01:50 +0000</pubDate></item><item><title>Launch HN: Modelence (YC S25) ‚Äì App Builder with TypeScript / MongoDB Framework</title><link>https://news.ycombinator.com/item?id=46872733</link><description>&lt;doc fingerprint="bb22d77b01df145e"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi all, Aram and Eduard here - co-founders of Modelence (&lt;/p&gt;https://modelence.com&lt;p&gt;). After spending years on scaling our previous startup‚Äôs platform, we built an open-source full-stack TypeScript + MongoDB framework to stop solving the same auth / database / API / cron job implementations every time we created an app, and we didn‚Äôt like the idea of using multiple managed platforms for each of these to run our apps either.&lt;/p&gt;&lt;p&gt;(Here‚Äôs our prior Show HN post for reference: https://news.ycombinator.com/item?id=44902227)&lt;/p&gt;&lt;p&gt;At the same time, we were excited by the whole AI app builder boom and realized that the real challenge there is the platform rather than the tool itself. Now we‚Äôre making Modelence the first full-stack framework that‚Äôs built for coding agents and humans alike:&lt;/p&gt;&lt;p&gt;- TypeScript is already great for AI coding because it provides guardrails and catches many errors at build time, so agents can auto-correct&lt;/p&gt;&lt;p&gt;- MongoDB eliminates the schema management problem for agents, which is where they fail the most often otherwise (+ works great with TS/Node.js)&lt;/p&gt;&lt;p&gt;- Built-in auth, database, cron jobs and else that just works together out of the box means agents only focus on your product logic and don‚Äôt fail at trying to set these things up (+ less tokens spent on boilerplate).&lt;/p&gt;&lt;p&gt;You can now try the Modelence app builder (based on Claude Agent SDK) by just typing a prompt on our landing page ( https://modelence.com ) - watch a demo video here: https://youtu.be/BPsYvj_nGuE&lt;/p&gt;&lt;p&gt;Then you can check it out locally and continue working in your own IDE, while still using Modelence Cloud as your backend, with a dev cloud environment, and later deploy and run on Modelence Cloud with built-in observability around every operation running in your app.&lt;/p&gt;&lt;p&gt;We‚Äôre also going to add a built-in DevOps agent that lives in the same cloud, knows the framework end-to-end, and will use all this observability data to act on errors, alerts, and incidents - closing the loop, because running in production is much harder than just building.&lt;/p&gt;&lt;p&gt;We launched the app builder as a quick start for developers, to demonstrate the framework and Modelence Cloud without having to manually read docs and follow the steps to set up a new app. Our main focus is still the platform itself, since we believe the real challenge in AI coding is the framework and the platform rather than the builder tool itself.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46872733</guid><pubDate>Tue, 03 Feb 2026 16:03:21 +0000</pubDate></item></channel></rss>