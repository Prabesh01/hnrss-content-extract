<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 21 Sep 2025 02:24:58 +0000</lastBuildDate><item><title>After Babel Fish: The promise of cheap translations at the speed of the Web</title><link>https://hedgehogreview.com/issues/lessons-of-babel/articles/after-babel-fish</link><description>&lt;doc fingerprint="7e48db9f8bb08324"&gt;
  &lt;main&gt;
    &lt;quote&gt;&lt;p&gt;Far from a restrictive act of copying, a translator restores the meaning of a text by means of an elaborate process that requires imagination, ingenuity, and freedom.&lt;/p&gt;&lt;lb/&gt;—Jhumpa Lahiri, “In Praise of Echo”&lt;p&gt;[T]rust is a hard commodity to build, in any interpersonal communication, and all too easy to ruin. No one likes taking another person’s word, and yet in translation, that is literally what the reader is asked to do.&lt;/p&gt;&lt;lb/&gt;—Mark Polizzotti, Sympathy for the Traitor&lt;/quote&gt;
    &lt;p&gt;The project of machine translation was already in its fifth decade when the search engine AltaVista introduced Babel Fish, at the end of 1997. Named after the “leech-like” creature that functions as a universal translator in Douglas Adams’s The Hitchhiker’s Guide to the Galaxy (1979), it broke new ground by offering translation for free online. Previously, machine translation (MT) was something for which you had to pay and wait, since humans generally intervened to tidy up what the machine produced. AltaVista promised instant results—no human lag required—whether you wished to have an entire Webpage translated (without altering the graphics) or input an inscrutable chunk of foreign text. Here, in other words, was real-time translation of and on the Web. Digital Equipment Corporation, AltaVista’s parent company, declared that Babel Fish had “broken the Internet language barrier.”11xQuoted in Victoria Shannon, “The End User: The Power of Babel—Technology,” New York Times, May 3, 2006; https://www.nytimes.com/2006/05/03/technology/03iht-ptend04.1654790.html.&lt;/p&gt;
    &lt;p&gt;“Barely breached” would be more accurate. Initially, Babel Fish could translate English text only into German, French, Spanish, Italian, and Portuguese, and vice versa (but not, say, French to Spanish), though its capabilities would expand in the ensuing years. Even within that circumscribed domain, Babel Fish often stumbled, especially with names, technical terms, and idiomatic expressions. Its hold on grammar, too, was shaky. First-time users raved, but professional translators balked. Mischief-makers played a game—called “round-tripping”—in which a translated text is rendered back into its original tongue to see what distortions arise. In this regard, Babel Fish was very obliging.&lt;/p&gt;
    &lt;p&gt;Shortly after the service’s debut, Umberto Eco, the novelist, semiotician, and satirist, spotted the invitation on AltaVista’s homepage and took the bait, asking Babel Fish to translate English sites into his native Italian. His “first shock,” he reported a few months later in his “La Bustina di Minerva” column in the Italian newsmagazine L’Espresso, came when he saw a page titled “Gli impianti di Shakespeare”—or “Shakespeare’s Plants.”22xUmberto Eco, “La vera storia dei pali del Papa,” L’Espresso, January 15, 1998. The rules-based system that AltaVista employed (created by the Parisian company Systran) had latched on to the wrong sense of the English “works.” The Italian translation should have been opere, the “works” of an artist; instead, it selected impianti, the “works” of an industrialist. Eco noticed other errors: An author was credited with having many ventilatori (the whirring kind of “fans”); a publisher was referred to as Harcourt “Support” (i.e., “Brace”); the Polish people (i polacchi) were reduced to poles (i pali). In a subsequent column, Eco reported on round-tripping, using the opening lines of Dante’s Inferno as a test case. Round-trip Dante, he explained, and you get proof that the machine poses no threat to “il divin poeta.” Send Dante’s lines through several more permutations, and you get modern poetry.33xUmberto Eco, “Trionfante ritorno a Babele. Como giocare seriamente con Altavista,” L’Espresso, February 19, 1998. I am grateful to the good people at L’Espresso for responding promptly to my request for a scan of this column.&lt;/p&gt;
    &lt;p&gt;Eco kept playing with Babel Fish, and in Mouse or Rat?, his 2003 book on “translation as negotiation,” he again brought up its shortcomings to illustrate the qualities of effective translation. To begin with, Eco pointed out, translation does not consist of mechanical synonym-swapping. If that were the case, Babel Fish’s execution would have been flawless. The words we rely on most have multiple senses, and to determine the specific one invoked on any given occasion, the translator must decipher contextual clues. This Babel Fish could not do—even when given the larger window of multiple sentences. Inputting the opening verses of the Authorized Version’s Genesis, Eco was amused to find the English “spirit of God” transformed into the Spanish “el alcohol de dios.”44xUmberto Eco, Mouse or Rat? Translation as Negotiation (London, England: Phoenix Paperback 2004), 14. Moving between languages, furthermore, the translator needs to honor the grammatical and syntactic mores of both. No competent English user would say “divide waters of waters” (as Babel Fish rendered “aguas de aguas”) or begin a sentence, “In the God who began created heaven…” (as Babel Fish did in multiple languages). Even contextual and grammatical wherewithal could get the translator only so far, however. To decide whether “works” ought to be opere or impianti, the translator needed to know a simple fact that Babel Fish lacked—“that Shakespeare was a poet and a playwright and not an industrial tycoon.”55xIbid., 13.&lt;/p&gt;
    &lt;p&gt;The machine’s miscues clarified that translation depends on more than a large vocabulary and grammatical proficiency in two tongues. The translator must also possess extensive “world knowledge.”66xIbid., 18. Only one so equipped can undertake the multiple negotiations—with languages, with the author, with the imagined reader, with a very real publisher—that translation entails. Babel Fish might have its uses (and amusements), Eco granted, but it could never handle all that. Real-time machine translation was not ready for the world.&lt;/p&gt;
    &lt;head rend="h2"&gt;New Techniques, Old Ambitions&lt;/head&gt;
    &lt;p&gt;Is it now? Within a decade of its release, Babel Fish began to sink to the bottom of the Web, along with AltaVista, DEC, and its later owner, Yahoo, all doomed by the ascendance of Google. Google Translate (launched in 2006) demonstrated that a corpus-based statistical approach was superior to Babel Fish’s often cross-wired rules, though it too was prone to embarrassing gaffes, leading Google to implement a neural net upgrade in 2016. Generative AI has now shaken up the field again, initial results being so promising that some within the industry are speaking of machine translation as “almost a solved problem” (to echo a recent Economist headline).77xMachine Translation Is Almost a Solved Problem,” The Economist, December 11, 2024; https://www.economist.com/science-and-technology/2024/12/11/machine-translation-is-almost-a-solved-problem. Once again, we hear rumors of a forthcoming Babel fish. “Apple Is Turning Its AirPods Into the Babel Fish From Hitchhiker’s Guide to the Galaxy,” the news site Quartz reports.88xEce Yildirim, “Apple Is Turning Its AirPods Into the Babel Fish From Hitchhiker’s Guide to the Galaxy,” Quartz, March 14, 2025; https://qz.com/apple-airpods-translate-ios-19-1851770018. “Meta’s New Translation AI Is Nearly a Babel Fish,” the engineering site IEEE Spectrum declares.99xCharles Q. Choi, “Meta’s New Translation AI Is Nearly a Babel Fish,” IEEE Spectrum, January 15, 2025; https://spectrum.ieee.org/machine-translation Others promise that Star Trek’s universal translators will soon materialize in our palms.&lt;/p&gt;
    &lt;p&gt;Having now collectively ridden through several AI hype cycles, we know to be wary of such grandiose claims. For one, the world hosts more than seven thousand languages, and even the best of the current tools can handle only a tiny fraction of that total. The new Meta product SEAMLESSM4T (those four Ms standing for “Massively Multilingual &amp;amp; Multimodal Machine Translation”), for example, can take in speech and text from around one hundred languages, but its outputs fall to the thirties depending on what you ask it to do.1010xSeamless Communication et al., “SEAMLESSM4T: Massively Multilingual &amp;amp; Multimodal Machine Translation,” October 25, 2023; https://arxiv.org/pdf/2308.11596. That is still a remarkable achievement, especially given that the system works across modalities—from, say, Dutch text to Romanian speech. But you are out of luck if you wish to generate Serbian speech from Tamil speech or Xhosa text from any source. In thousands of cases, data is too scarce to make contemporary MT techniques feasible.&lt;/p&gt;
    &lt;p&gt;The “nearly solved problem” is not machine translation simpliciter, then, but the automatic, real-time translation of “high-resource” languages, meaning those for which training data has been generously provided by the Web, such as English and Spanish. To prove this point, researchers wave their systems’ scores on tests with acronyms like BLEU, MQM, and XCOMET in the air and proclaim that the machines are catching up to human translators. But the real test is the average user’s experience, yours and mine. While writing this article, I have run Italian, French, Spanish, Latin, and German passages through multiple machine translators, and while all made mistakes (more on that in a moment), their performance was consistently serviceable—at times, delightful—and undeniably convenient. The Belgian traveler who can’t read an apparently urgent Hindi sign, the Korean scientist writing an article in her third language, the Peruvian parent whose baby monitor comes with Chinese directions, the Saudi business owner arguing with a Norwegian contractor—all these parties, and many others, will find the new and improved MT a godsend.&lt;/p&gt;
    &lt;p&gt;Nor should we be surprised that machine translators can, in many everyday instances, rival their human counterparts. In 2011, as alarm bells sounded about the old Google Translate, the translator and academic David Bellos wisely noted, “Whatever a language may be in principle, in practice it is used most commonly to say the same things over and over again.”1111xDavid Bellos, Is That a Fish in Your Ear? Translation and the Meaning of Everything (New York, NY: Faber and Faber, 2011), 257. Professional translators are not constantly reinventing the wheel, Bellos stressed; rather, through daily practice and exposure to the conventions of their field, they develop “automatisms” that help them to make quick work of recurring issues. In this respect, human translators are not so different from Google Translate, Bellos argued, “scanning their own memories in double-quick time for the most probable solution to the issue at hand.”1212xIbid. Even human translation has its mechanical side.&lt;/p&gt;
    &lt;p&gt;Bellos was thus more than happy to cede routine tasks to computers. Doing so, he believed, would free up human translators to concentrate on the many tricky problems that seemed to defy statistical solutions. He imagined that demand for human translation services would grow as businesses and consumers around the globe came to “expect more and more communication between languages” and found MT inadequate on its own.1313x“What’s Lost (And Found) In Machine Translation,” interview with David Bellos; https://bigthink.com/videos/whats-lost-and-found-in-machine-translation/. Yet he also admitted to having worries that Google Translate and tools of its ilk might instigate a cultural shift in which translation would come to be seen as “a task fit only for machines.”1414xInterview with Translator David Bellos,” Gengo, February 2, 2012; https://gengo.com/business-insights/david-bellos/.&lt;/p&gt;
    &lt;p&gt;Bellos failed to see the enduring attraction of the Babel Fish formula: cheap translation at the speed of the Web. That project is now charging ahead with machine learning, and industry leaders are unsurprisingly eager to reduce their dependence on slow, expensive, break-taking humans, if not remove them from the equation entirely. Vasco Pedro, the outspoken CEO of Unbabel, has forecast exactly that: “It’s hard for me to see right now,” he told CNBC last year, “how three years from now, you will need humans to be translating anything.”1515xArjun Kharpal, “Startup CEO Says Humans Won’t Be Needed for Translation in 3 Years as It Launches AI App,” CNBC, November 13, 2024; https://www.cnbc.com/2024/11/13/unbabel-launches-ai-translation-app-looks-for-fresh-funding.html. Unbabel’s services are representative of the emerging paradigm for fully automated translation: Machines generate text, edit that text, and score the text for accuracy, length, coherence, and even more intangible qualities like fluidity and style. Clients are offered, in turn, not only rapid translation across a broad menu of languages but also “real-time quality scores” of the machine’s outputs. Human translators are pushed to the fringes, serving as a fail-safe mechanism for exceptionally difficult use cases and scorers in the development of gold-standard benchmarks. Several of the new MT companies present human editing as an optional upgrade.&lt;/p&gt;
    &lt;p&gt;In 2011, Bellos cautioned readers to use Google Translate only “to translate into a language in which you are sure you can recognize nonsense.”1616xBellos, Is That a Fish in Your Ear?, 256. Unbabel’s products are designed to surmount those inhibitions: Thanks to the company’s trusty internal metrics, you can allow the machines to churn away in ninety languages—from Afrikaans to Vietnamese—with the reassurance that line graphs and pie charts provide.&lt;/p&gt;
    &lt;head rend="h2"&gt;Minerva’s Mystery&lt;/head&gt;
    &lt;p&gt;Unsurprisingly, I have reservations about the drive to push humans out of the business of translation. In the first place, you don’t need to wade very deeply into the technical literature to grasp that, while the new MT has surpassed the old benchmarks by Olympic leaps and bounds, the machines are far from the “super polyglots” that Mr. Pedro has been peddling for smooth sailing in the metaverse. While adept at translating words, sentences, and paragraphs, their performance degrades as assignments lengthen; automatic book-length translation is still out of reach. The machines can forget previous renderings of a repeated term or phrase. They can slip into, and sometimes get mired in, “translationese”—clauses in which in the wrong places sit. They can be “verbose” (a semi-technical term), yielding more words than the prompter needs (say, for a headline) or fabricating additional verbiage beyond what the source text states. They sometimes refuse reasonable assignments. They make mistakes about (or fail to ask for context regarding) sensitive grammatical matters such as gender and person. They still garble idiomatic expressions, metaphors, and wordplay. And, of course, they hallucinate—which is to say, they make stuff up.&lt;/p&gt;
    &lt;p&gt;Eco provides a useful gauge of MT’s current capabilities and hazards. As expected, all the systems that I tested romped through the puzzles Eco posed to Babel Fish a quarter century ago. In fact, when round-tripping (immaculately) the opening words of Inferno, several of the machines earned bonus points for noting the lines are Dante’s. Yet when I submitted passages from the essays in which Eco related his Babel Fish experiments, results were mixed. The opening sentences of his piece “How to Play Seriously with Altavista” are illustrative. First, Eco’s Italian:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Tornare per la terza volta alle traduzioni via Internet potrebbe sembrare indisponente. Ma questa volta non voglio ironizzare sulla ottusità delle macchine, bensì vedere come sfruttarla a fini creativi. Devo il consiglio a Lee Marshall.1717xEco, “Trionfante ritorno a Babele. Como giocare seriamente con Altavista,” L’Espresso.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Claude 3.7 Sonnet came in dead last, though at a quick first glance you might not see why:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Returning for the third time to translations via Internet might seem indisposing. But this time I don’t want to focus on the senselessness of machines, but rather see how to use it for creative purposes. I gave the advice to Leo [sic] Marshall.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;There are two inexcusable blunders here. The first is the choice of “indisposing” for the Italian “indisponente.” In addition to being outdated English, “indisposing” is untrue to the author’s meaning. It suggests a lack of fit, or even illness, whereas Eco’s word choice was meant to anticipate the reader’s chagrin at finding another Eco column on Babel Fish. “Annoying” would work, as would “irritating,” “off-putting,” “exasperating,” and “irksome”—those words being the other machines’ proposals. The second issue is the verb in the last sentence. Claude got the gesture backwards: “devo” means not “I gave” but “I owe.” Now to be fair to Claude’s developers at Anthropic, I should acknowledge that when I tried the same prompt a few days later, the bot translated the verb correctly. Yet the fact that the machine translator can be right one day and wrong another is, as I’m sure you’ll agree, irritating.&lt;/p&gt;
    &lt;p&gt;The other responses were quite similar, structurally speaking, and while one might nitpick here or there, they all gave clear-enough windows into Eco’s thinking. One of Gemini 2.0 Flash’s outputs stood out for another reason. First, the translation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To return for the third time to internet translations might seem off-putting. But this time I don’t want to make fun of the machines’ obtuseness, but rather see how to exploit it for creative purposes. I owe the advice to Lee Marshall.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;After this, and without my prompting, Gemini proffered notes on key words in the passage, beginning with “indisponente.” “While ‘off-putting’ works,” the bot explained, “it can also mean ‘unpleasant’ or ‘reluctant.’ The idea is that it’s a bit annoying or tedious to keep going back to online translations.” While the second sentence is true, the first is not. “Unpleasant” is in the right neighborhood, although Italian lexicographers stress that indisponente signals a strong reaction that, to my ear, “unpleasant” does not convey. “Reluctant,” however, is simply incorrect. When I followed up to ask Gemini if “reluctant” would be an appropriate translation of indisponente, it replied, “No, ‘reluctant’ is not a direct or common translation of the Italian word,” and added that while a person who is “indisponente (annoying) might cause someone else to be ‘reluctant’ to interact with them, the words themselves describe different qualities or states.” Annoying.&lt;/p&gt;
    &lt;p&gt;The most troublesome phrase for the machines, though, was among the first that I input—the title of Eco’s column, “La Bustina di Minerva.” The most popular answer was “Minerva’s sachet.” Gemini suggested “Minerva’s little envelope” or “Minerva’s small pouch.” ChatGPT replied, “The Little Minerva’s Packet” or, more naturally, ‘Minerva’s Little Notebook,” and, on a subsequent trial, related, “It refers to the small pouch (or satchel) associated with Minerva, the Roman goddess of wisdom,” and then pointed out, “The phrase was used by the Italian writer and philosopher Umberto Eco as the title of a long-running column in L’Espresso magazine.” Despite all that bonus information, ChatGPT was, like the rest, mistaken.&lt;/p&gt;
    &lt;p&gt;“Bustina,” mind you, is applied to small envelopes, pouches, and packets. But our author was referring to a specific kind, the bustina di fiammiferi—the matchbook (or matchbox). In his inaugural column, in March 1985, Eco explained that he had chosen the name “not as a reference to the goddess of wisdom, but to the matchbooks that go by that brand name.”1818xEco, “Che Bell’Errore,” L’Espresso, March 31, 1985; https://lespresso.it/c/idee/2016/2/26/umberto-eco-che-bellerrore-ecco-la-sua-prima-storica-bustina-di-minerva/19016. Translation my own. He was recalling the old practice of using the blank inner flap of a matchbook to scribble an idea before it faded, the phone number of a potential love interest, or the title of a book to purchase or bypass. That’s what his column would offer—not the wisdom of the ages but thinking at its earliest stages.&lt;/p&gt;
    &lt;p&gt;To get the title—“Minerva’s Matchbook”—right, the translator needs to possess that “world knowledge” that Eco, having sampled Babel Fish, newly appreciated in translators of his own species. A translator who dwelled in Eco’s Italy—where people regularly needed a light—might catch the reference immediately. Yet even one remote from Eco’s world can easily glean the necessary information by starting in the obvious place: the debut column. And even that effort isn’t necessary. Googling will solve the mystery in a few clicks. The last two steps—searching the author’s writings or the Web—will happen, though, only if you first admit that Eco’s meaning eludes you, that if translated in the most straightforward fashion the title is odd. Humility here is an asset. ChatGPT went the other way: To support its version of Eco’s title, it invented a backstory, adding an accessory to Minerva’s traditional garb. Irksome.&lt;/p&gt;
    &lt;head rend="h2"&gt;Faithfulness, Trust—and Maybe a Little Humility?&lt;/head&gt;
    &lt;p&gt;It will get better, you say, whether in hope, fear, or fatigue. It may. By the time you read this, the machines may have sorted out their confusions about indisponente and devo and gotten a hint about the brand name behind Eco’s column title. On the other hand, due to the growing complexity of these systems, ironing out the current kinks may have ripple effects that give rise to other headaches, mild or severe. Some degree of duplicity and hallucination may just be part of the deal. Umberto Eco may always be a nuisance to translation machines.&lt;/p&gt;
    &lt;p&gt;Either way, we ought to be wary of the efforts of the proponents of MT automation to define translation as a purely technical activity, one whose success or failure can be unfailingly measured in real time, at all times, by metrics determined and administered by company machines. Translation is a technical activity, both in the more rarefied sense of dealing with specialized domains (e.g., scientific papers) and the basic one of depending on tekhnē, craft. But that craft is, and has always been, employed to mediate between those who otherwise would be reduced to pantomime or frustrated silence. Translation is thus, as translators themselves have been admitting with growing confidence in recent decades, a profoundly ethical pursuit.&lt;/p&gt;
    &lt;p&gt;That was what Eco was trying to get at with his notion of translation as “negotiation.” Translation does not happen in a vacuum; it is a social act that takes place at a given time and in a given milieu. It occurs on behalf of multiple parties—the author, who otherwise wouldn’t be read in the target language; the reader, who otherwise wouldn’t have access to the author’s questioning, imagining, reasoning, fact-finding, forecasting, declaiming, etc.; the publisher, who commissions the work and hopes to turn a buck; and perhaps to “culture” or “posterity” in some vague or certain sense. Accordingly, Eco portrayed the translator as the party who seeks a compromise between the several claimants in the exchange.&lt;/p&gt;
    &lt;p&gt;“World knowledge” helps. For only by having a thick understanding of the author, the author’s culture, the source language, the target language, the conventions of the genre in question, and the intended audience can the translator make wise linguistic choices. The process hinges, though, on faithfulness—not as a patented method but as a manner of approach. Faithfulness, on Eco’s telling, consists of faith in the possibility of translation in the first place, a wager on meaning despite obvious impediments. It extends to the translator’s interpretive excavations to grasp the text’s “deep sense” (which becomes the basis for subsequent decisions to be made about style, tone, rhythm, sentence length, word order, punctuation, and so on). It finds expression in “the goodwill that prods us to negotiate the best solution for every line.” “Among the synonyms of faithfulness,” Eco argued in 2003, “the word exactitude does not exist. Instead, there is loyalty, devotion, allegiance, piety.”1919xEco, Mouse or Rat?, 192.&lt;/p&gt;
    &lt;p&gt;Eco’s bar is, unquestionably, high. Others would place it lower, or stress other dimensions of translation. Even so, his account is valuable now because it brings to light the fact that the translator, being answerable to multiple parties, faces a series of ethical challenges as she works word by word, sentence by sentence, through her assignment.&lt;/p&gt;
    &lt;p&gt;Meanwhile, one is hard-pressed to find any mention of faithfulness, devotion, allegiance, or piety in the reports issuing daily on MT breakthroughs, though synonyms of exactitude abound. In industry and academic papers on MT, the “ethics” section (if there is one) often consists of nothing more than the details of how the team sought to tamp down bias, especially gender bias, and root out offensive language. Developers, for example, have been alarmed to note added “toxicity” in their outputs—meaning the machines sometimes introduce toxic language even though the original contained none. The favored solution is, of course, to build better diagnostics and add more safety protocols. Eco endeavored to renew faithfulness; Big Tech offers us “automatic toxicity detection.”&lt;/p&gt;
    &lt;p&gt;But the campaign to automate translation has its weightiest consequence not in the machine’s sphere but the user’s. As the translator Mark Polizzotti has observed, the “stale” Italian pun traduttore, traditore (“translator, traitor”) conveys a cultural truth: In most situations, we’d prefer not to trust the middleman.2020xMark Polizzotti, Sympathy for the Traitor: A Translation Manifesto (Cambridge, MA: MIT Press, 2018), 12. Translation is, for the audience, a vulnerable state: We must put our trust in a stranger who stands between us and the source that we cannot hear or read for ourselves. We must (to echo the second epigraph above) “take another person’s word for it.” Receiving a translation is an act of faith. Translation lays bare the grating fact of our finitude.&lt;/p&gt;
    &lt;p&gt;How much more appealing is the empowerment promised by the new MT systems. Now you are the controls. You can have your translation right now, tailored to your specifications. Which style would you prefer, DeepL Translate asks users—Simple? Business? Academic? Casual? What about tone? Friendly, enthusiastic, confident, or diplomatic? Or perhaps you’d like the text rendered as rhyming couplets? ChatGPT stands ready. And we have already seen a preview, thanks to Gemini, of the machines’ ability to supplement their renditions with commentary. With these tools at our fingertips and plugged into our ears, we may at last enjoy the linguistic freedom of our favorite sci-fi characters. We may go anywhere and never be lost for words.&lt;/p&gt;
    &lt;p&gt;Of course, as things currently stand, the new Babel Fish may prove riskier companions than today’s boisterous headlines admit. At our cultural moment in which a single ill-timed word or misplaced character can ignite a career-ending social-media storm, I suspect that some hard lessons await the most vociferous early adopters, especially those who pay no heed to Bellos’s warning against straying into languages in which you can’t spot rubbish (or excrement). We may find, moreover, that the ability to pontificate at any time, in scores of languages, creates new problems as words get out that we might, on second thought, rather not have shared or heard. More communication is not necessarily better communication. (Such was Douglas Adams’s lesson: “The poor Babel fish, by effectively removing all barriers to communication between different races and cultures, has caused more and bloodier wars than anything else in the history of creation.”2121xDouglas Adams, The Hitchhiker’s Guide to the Galaxy (London, England: Pan Books, 1979), 61.)&lt;/p&gt;
    &lt;p&gt;The old, slower-paced translation, meanwhile, offers those willing to attend a salutary disquiet. Where Babel Fish would render humanity’s diverse articulations on the user’s handpicked terms, the old translation reminds us that the whole world cannot be accounted for using the satchel of words that we ordinarily bear about with us. The old translation exposes the limitations of our language, even while gesturing toward the possibilities of others through shrewd incorporations. Translation, at its most human, tugs familiar words into foreign realms of meaning, renewing and extending them, and inviting us to follow there that we might sample the local flavors for ourselves. The developers of machine translation have achieved remarkable technical feats, and surely more are to come; their labors will release a torrent of words, and many of them will be good ones. But we ought to be apprehensive about what the Babel Fish whispers in our ears. Automatic machine translation is being marketed as a means to expand our little worlds. It may just as easily render the world back to us on ever more narrow terms.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45287838</guid><pubDate>Thu, 18 Sep 2025 10:16:54 +0000</pubDate></item><item><title>Teardown of Apple 40W dynamic power adapter with 60W max</title><link>https://www.chargerlab.com/teardown-of-apple-40w-dynamic-power-adapter-with-60w-max-a3365/</link><description>&lt;doc fingerprint="b55b1e21c132dd0a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;On September 10th, Apple held its 2025 Fall Event, unveiling the iPhone 17 lineup alongside a brand-new product category—iPhone Air. Among the announcements, one product that stood out was Apple’s new 40W Dynamic Power Adapter, which gained attention for its compact design and ability to dynamically deliver up to 60W of total output power.&lt;/p&gt;
    &lt;p&gt;The charger is now available on Apple’s official website, priced at $39 USD. According to Apple, when used with an iPhone 17 series device, the adapter can charge the phone to 50% in approximately 20 minutes—offering significantly faster charging performance compared to the previous generation. Despite the substantial power upgrade, the adapter maintains a highly compact form factor—roughly the same size as Apple’s standard 20W charger. It also features foldable prongs for improved portability and travel convenience. In the following teardown, we take a closer look at the internal design and power distribution architecture of Apple’s latest fast charger.&lt;/p&gt;
    &lt;head rend="h1"&gt;Product Appearance&lt;/head&gt;
    &lt;p&gt;The front of the packaging features the Apple logo, product name, and an image of the adapter.&lt;/p&gt;
    &lt;p&gt;The back of the packaging displays a simplified diagram of the adapter and its ports, along with CE certification and other information.&lt;/p&gt;
    &lt;p&gt;One side of the packaging has a specification label attached.&lt;/p&gt;
    &lt;p&gt;The opposite side features a label indicating the manufacturing date and "Made in China" origin.&lt;/p&gt;
    &lt;p&gt;The packaging includes the charger along with the user manual and other documentation.&lt;/p&gt;
    &lt;p&gt;The charger is wrapped in protective paper.&lt;/p&gt;
    &lt;p&gt;It features a design similar to the 35W dual USB-C charger (model A2579).&lt;/p&gt;
    &lt;p&gt;The small recessed areas on both sides of the body facilitate easy plugging and unplugging.&lt;/p&gt;
    &lt;p&gt;The output side features a single USB-C port with a white plastic insert.&lt;/p&gt;
    &lt;p&gt;The bottom is printed with specification details.&lt;/p&gt;
    &lt;p&gt;Model: A3365&lt;/p&gt;
    &lt;p&gt;Input: 100-240V\~ 50/60Hz 1.5A (USB PD)&lt;/p&gt;
    &lt;p&gt;Output: (AVS) 15-20V 2A \[3.0A DPS] or (AVS) 9-15V 2.67A \[3.0A DPS] or 9V 3A or 5V 3A&lt;/p&gt;
    &lt;p&gt;Maximum total output power: 60W LPS&lt;/p&gt;
    &lt;p&gt;The charger has passed CCC certification and Level VI energy efficiency certification.&lt;/p&gt;
    &lt;p&gt;It features foldable prongs.&lt;/p&gt;
    &lt;p&gt;The length of the charger is about 45.72 mm (1.8 inches).&lt;/p&gt;
    &lt;p&gt;The width is about 45.73 mm (1.8 inches).&lt;/p&gt;
    &lt;p&gt;The thickness is about 28.11 mm (1.11 inches).&lt;/p&gt;
    &lt;p&gt;Its size is nearly identical to that of the Apple 20W charger.&lt;/p&gt;
    &lt;p&gt;It is slightly smaller than the 35W dual USB-C charger.&lt;/p&gt;
    &lt;p&gt;That's how big it is in the hand.&lt;/p&gt;
    &lt;p&gt;The weight is about 80 g (2.82 oz).&lt;/p&gt;
    &lt;p&gt;ChargerLAB POWER-Z KM003C shows that it supports PD3.0 and DCP charging protocols.&lt;/p&gt;
    &lt;p&gt;And it has four fixed PDOs of 5V3A, 9V3A, 15V2.67A, and 20V2A.&lt;/p&gt;
    &lt;p&gt;When used to charge the iPhone 16 Pro Max, the charging power is about 27.23W.&lt;/p&gt;
    &lt;p&gt;When charging the MacBook Air M3 2024, the charging power is about 55.94W, successfully activating the 60W dynamic fast charging feature.&lt;/p&gt;
    &lt;head rend="h1"&gt;Teardown&lt;/head&gt;
    &lt;p&gt;Next, let's take it apart to see its internal components and structure.&lt;/p&gt;
    &lt;p&gt;Remove the bottom casing, and it is revealed that the enclosure uses a combination of snap-fit clips and ultrasonic welding for sealing.&lt;/p&gt;
    &lt;p&gt;The input side features a contact-based power delivery design. The inner side of the casing is lined with a graphite thermal pad and has been treated for insulation.&lt;/p&gt;
    &lt;p&gt;Remove the PCBA module.&lt;/p&gt;
    &lt;p&gt;The inner side of the other half of the casing is lined with the graphite thermal insulation pad and the protective rubber cushion.&lt;/p&gt;
    &lt;p&gt;High-temperature resistant insulating tape is also applied along the sides.&lt;/p&gt;
    &lt;p&gt;The length of the PCBA module is about 42.12 mm (1.66 inches).&lt;/p&gt;
    &lt;p&gt;The width is about 39.66 mm (1.56 inches).&lt;/p&gt;
    &lt;p&gt;The thickness is about 23.27 mm (0.92 inches).&lt;/p&gt;
    &lt;p&gt;One side of the PCBA module and the top of the output end are covered with protective foam pads.&lt;/p&gt;
    &lt;p&gt;A protective pad is also placed between the two high-voltage electrolytic filter capacitors on the other side.&lt;/p&gt;
    &lt;p&gt;The top-mounted high-voltage electrolytic filter capacitor and the transformer are secured with adhesive for added stability and insulation.&lt;/p&gt;
    &lt;p&gt;The solid capacitors for output filtering are also secured with adhesive, and an insulating sheet is attached to the left side of the plastic casing.&lt;/p&gt;
    &lt;p&gt;Remove the foam pads and black adhesive. The transformer is wrapped in copper foil, and the side near the secondary winding is reinforced and insulated with a plastic casing.&lt;/p&gt;
    &lt;p&gt;The PCBA module's input side features metal contact plates for power delivery along with a supporting plastic frame.&lt;/p&gt;
    &lt;p&gt;This side contains common mode chokes, a capacitor supplying power to the master control chip, and Y capacitors.&lt;/p&gt;
    &lt;p&gt;On the opposite side, two high-voltage electrolytic capacitors are mounted horizontally.&lt;/p&gt;
    &lt;p&gt;On both sides of the output, there are Y capacitors and solid capacitors, respectively.&lt;/p&gt;
    &lt;p&gt;Remove the capacitors, transformer, and other components. A plastic bracket is installed at the bottom to provide support and isolate the PCB.&lt;/p&gt;
    &lt;p&gt;The front side of the PCB features an SMD fuse and the master control chip.&lt;/p&gt;
    &lt;p&gt;The back side of the PCB contains the bridge rectifier, differential mode choke, synchronous rectifier, protocol chip, and output VBUS MOSFET.&lt;/p&gt;
    &lt;p&gt;Disassemble the capacitors, transformer, and other components. Let’s take a closer look at the specifications and functions of these individual components.&lt;/p&gt;
    &lt;p&gt;The SMD fuse is from WalterFuse with a rated current of 3.15A.&lt;/p&gt;
    &lt;p&gt;The two common mode chokes are arranged in a two-stage design to more effectively filter out EMI interference.&lt;/p&gt;
    &lt;p&gt;The safety X2 capacitor is wrapped with copper foil for shielding.&lt;/p&gt;
    &lt;p&gt;It has a specification of 0.1μF.&lt;/p&gt;
    &lt;p&gt;It is connected via soldered copper strips.&lt;/p&gt;
    &lt;p&gt;The input-side bridge rectifier is from DIODES, model RTT10KL, and uses a TTL package.&lt;/p&gt;
    &lt;p&gt;The high-voltage filter capacitors are from NCC, each rated at 400V 47μF, connected in parallel.&lt;/p&gt;
    &lt;p&gt;The differential mode choke has a specification of 13μH.&lt;/p&gt;
    &lt;p&gt;The master control chip is from PI, marked with ZN1612F, a custom model for Apple. It integrates the primary controller, high-voltage MOSFET, synchronous rectifier controller, and feedback functions, offering high integration and reduced external components. This simplifies fast charging power circuit design. The chip uses an InSOP-T28D package.&lt;/p&gt;
    &lt;p&gt;The capacitor supplying power to the master control chip is from Lelon.&lt;/p&gt;
    &lt;p&gt;It is rated at 50V, 22μF.&lt;/p&gt;
    &lt;p&gt;The transformer is manufactured by Sumida.&lt;/p&gt;
    &lt;p&gt;Close-up of three black Y capacitors.&lt;/p&gt;
    &lt;p&gt;The synchronous rectifier is from RECTRON, model RM85N100DF. It is an NMOS transistor with a voltage rating of 100V and an on-resistance of 4.6mΩ, packaged in a DFN 5x6-8L form factor.&lt;/p&gt;
    &lt;p&gt;The three solid capacitors for output filtering are from Nichicon, each rated at 25V 270μF.&lt;/p&gt;
    &lt;p&gt;The protocol chip is from Infineon, model CYPDC1185B2-32E, housed in a 32-pin QFN package.&lt;/p&gt;
    &lt;p&gt;The TI TLV9001 is a single-channel, 1MHz, rail-to-rail input and output operational amplifier with a voltage range of 1.8–5.5V, packaged in a SOT-23 (5) form factor.&lt;/p&gt;
    &lt;p&gt;The VBUS MOSFET is also from RECTRON, model RM80N30DN. It is an NMOS transistor rated for 30V with an on-resistance of 3.8mΩ, packaged in a DFN 3x3 form factor.&lt;/p&gt;
    &lt;p&gt;The thermistor monitors the internal temperature and dynamically adjusts the power level to reduce output power when the temperature rises.&lt;/p&gt;
    &lt;p&gt;Close-up of the sampling resistor used to detect the output current.&lt;/p&gt;
    &lt;p&gt;The pins of the USB-C socket are extended and soldered onto the PCBA.&lt;/p&gt;
    &lt;p&gt;Well, those are all components of the Apple 40W Dynamic Power Adapter with 60W Max.&lt;/p&gt;
    &lt;head rend="h1"&gt;Summary of ChargerLAB&lt;/head&gt;
    &lt;p&gt;Here is the component list of the Apple 40W Dynamic Power Adapter with 60W Max for your convenience.&lt;/p&gt;
    &lt;p&gt;It features a design similar to the 35W dual USB-C charger and comes with foldable prongs. The unique dynamic power delivery can be understood as "peak 60W, stable 40W," intelligently adjusting output power based on the device’s needs. This ensures it meets the charging requirements of the iPhone while also accommodating high-power charging scenarios for the MacBook. Given the increased charging power of the iPhone 17 series, this new adapter is definitely worth considering for new device users.&lt;/p&gt;
    &lt;p&gt;After taking it apart, we found that it uses the highly integrated PI power chip ZN1612F, paired with the RECTRON RM85N100DF synchronous rectifier. The output is controlled by an Infineon CYPDC1185B2-32E protocol chip, with filtering handled by capacitors from NCC and Nichicon.&lt;/p&gt;
    &lt;p&gt;The internal thermistor monitors the internal temperature to enable dynamic power switching. The charger’s casing remains robust as usual, with graphite thermal pads and foam cushions applied on the inside to assist with heat dissipation and protection. The PCBA module is further reinforced and insulated with foam pads and a plastic bracket, demonstrating reliable workmanship.&lt;/p&gt;
    &lt;p&gt;Related Articles：&lt;lb/&gt;1. Apple iPhone 17 Series Debuts With 40W Dynamic Power Adapter and PD 3.2 AVS Fast Charging&lt;lb/&gt;2. Hands-On Guide: ChargerLAB POWER-Z KM003C Load Test of Apple’s 40W Dynamic Power Adapter&lt;lb/&gt;3. What's Difference Between Two Apple 35W Charger (Compact and Traditional)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45289150</guid><pubDate>Thu, 18 Sep 2025 13:04:27 +0000</pubDate></item><item><title>Show HN: I Parallelized RNN Training from O(T) to O(log T) Using CUDA</title><link>https://dhruvmsheth.github.io/projects/gpu_pogramming_curnn/</link><description>&lt;doc fingerprint="e691829d45368af0"&gt;
  &lt;main&gt;&lt;p&gt;An implementation of parallelizable GRUs and LSTMs for CS179 in CUDA.&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Resource&lt;/cell&gt;&lt;cell role="head"&gt;Link&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Project Repository&lt;/cell&gt;&lt;cell&gt;GitHub&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;For my final project in CS179: GPU Programming, I decided to implement the paper “Were RNNs All We Needed?” by Feng et al. The paper’s core claim is that by making minor simplifications to LSTMs and GRUs, their recurrence can be expressed in a form amenable to the parallel scan algorithm. This changes their training and inference from an $O(T)$ sequential process into an $O(\log T)$ parallel one, which helps with GPU acceleration.&lt;/p&gt;&lt;p&gt;My goal was to verify this claim by building both the simplified models (minGRU and minLSTM) and a custom CUDA implementation of the parallel scan to see how much of a speedup was actually achievable. The focus was less on the machine learning application and more on the raw computational performance and the experience of parallelizing a traditionally sequential algorithm.&lt;/p&gt;&lt;p&gt;Recurrent Neural Networks, by their very nature, process sequences one step at a time. The hidden state at time step $t$, denoted $h_t$, is a function of the input $x_t$ and the previous hidden state, $h_{t-1}$. This dependency is the fundamental barrier to parallelization.&lt;/p&gt;&lt;p&gt;Let’s look at a standard GRU. The update equations are: \(r_t = \sigma(W_{ir}x_t + b_{ir} + W_{hr}h_{t-1} + b_{hr})\) \(z_t = \sigma(W_{iz}x_t + b_{iz} + W_{hz}h_{t-1} + b_{hz})\) \(n_t = \tanh(W_{in}x_t + b_{in} + r_t \odot (W_{hn}h_{t-1} + b_{hn}))\) \(h_t = (1 - z_t) \odot n_t + z_t \odot h_{t-1}\)&lt;/p&gt;&lt;p&gt;The reset gate ($r_t$) and update gate ($z_t$) both explicitly depend on $h_{t-1}$. You simply cannot compute the gates for the entire sequence in one shot, because each step requires the output from the one before it. This forces a sequential loop, which is notoriously inefficient on parallel hardware like GPUs.&lt;/p&gt;&lt;p&gt;The crux of the paper is to remove this direct dependency. The simplified models, minGRU and minLSTM, redefine the gates to depend only on the current input, $x_t$.&lt;/p&gt;&lt;p&gt;For minGRU, the gates are simplified to:&lt;/p&gt;&lt;p&gt;The recurrence then becomes: \(h_t = (1 - z_t) \odot h_{t-1} + z_t \odot \tilde{h}_t\)&lt;/p&gt;&lt;p&gt;This equation is now in the form $h_t = a_t \odot h_{t-1} + b_t$, where:&lt;/p&gt;&lt;p&gt;Crucially, because $z_t$ and $\tilde{h}_t$ only depend on $x_t$, we can compute the entire sequence of $(a_t, b_t)$ pairs in parallel with a single, large matrix multiplication. The problem has now shifted from a complex sequential dependency to resolving a linear recurrence relation. A similar simplification is applied to LSTMs to create minLSTM.&lt;/p&gt;&lt;p&gt;This linear recurrence is a classic computer science problem that can be solved efficiently with a parallel scan (also known as a prefix sum). The scan operation takes a sequence and an associative binary operator $\oplus$, and computes the prefix results. For our recurrence, the operator is slightly more complex than simple addition.&lt;/p&gt;&lt;p&gt;If we have a transformation $(A, B)$ representing $h_{out} = A \cdot h_{in} + B$, we can define an associative operator $\oplus$ to compose two such transformations: \((A_2, B_2) \oplus (A_1, B_1) = (A_2 A_1, A_2 B_1 + B_2)\)&lt;/p&gt;&lt;p&gt;With this operator, we can use an algorithm like Blelloch’s scan, which performs the computation in two phases (up-sweep and down-sweep) on a tree-like structure. This reduces the number of sequential steps from $O(T)$ to $O(\log T)$, making it a perfect fit for the GPU’s architecture. For numerical stability, the paper and my implementation use a log-space version of this scan.&lt;/p&gt;&lt;p&gt;To measure the real-world impact, I compared three implementation paths:&lt;/p&gt;&lt;code&gt;for t in range(T): h_t = cell(x_t, h_{t-1})&lt;/code&gt;. This represents the classic, non-parallelizable RNN.&lt;p&gt;I ran benchmarks on my personal machine (Intel i9-12900K, RTX 4090).&lt;/p&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;$T$&lt;/cell&gt;&lt;cell role="head"&gt;CPU-seq&lt;/cell&gt;&lt;cell role="head"&gt;CPU-scan&lt;/cell&gt;&lt;cell role="head"&gt;GPU-scan&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;256&lt;/cell&gt;&lt;cell&gt;634 ms&lt;/cell&gt;&lt;cell&gt;32.8 ms&lt;/cell&gt;&lt;cell&gt;25.8 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;1,024&lt;/cell&gt;&lt;cell&gt;2,395 ms&lt;/cell&gt;&lt;cell&gt;97.6 ms&lt;/cell&gt;&lt;cell&gt;92.1 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;4,096&lt;/cell&gt;&lt;cell&gt;5,493 ms&lt;/cell&gt;&lt;cell&gt;300 ms&lt;/cell&gt;&lt;cell&gt;340 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;16,384&lt;/cell&gt;&lt;cell&gt;–&lt;/cell&gt;&lt;cell&gt;2,683 ms&lt;/cell&gt;&lt;cell&gt;1,333 ms&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;65,536&lt;/cell&gt;&lt;cell&gt;–&lt;/cell&gt;&lt;cell&gt;10,989 ms&lt;/cell&gt;&lt;cell&gt;5,330 ms&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="4"&gt;&lt;cell role="head"&gt;T&lt;/cell&gt;&lt;cell role="head"&gt;CPU-seq&lt;/cell&gt;&lt;cell role="head"&gt;CPU-scan&lt;/cell&gt;&lt;cell role="head"&gt;GPU-scan&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;256&lt;/cell&gt;&lt;cell&gt;701.0 ms&lt;/cell&gt;&lt;cell&gt;37.0 ms&lt;/cell&gt;&lt;cell&gt;22.0 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;1,024&lt;/cell&gt;&lt;cell&gt;2,966.7 ms&lt;/cell&gt;&lt;cell&gt;96.8 ms&lt;/cell&gt;&lt;cell&gt;107.8 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;4,096&lt;/cell&gt;&lt;cell&gt;12,035.1 ms&lt;/cell&gt;&lt;cell&gt;416.5 ms&lt;/cell&gt;&lt;cell&gt;431.5 ms&lt;/cell&gt;&lt;/row&gt;&lt;row span="4"&gt;&lt;cell&gt;16,384&lt;/cell&gt;&lt;cell&gt;–&lt;/cell&gt;&lt;cell&gt;2,993.6 ms&lt;/cell&gt;&lt;cell&gt;1,693.9 ms&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;65,536&lt;/cell&gt;&lt;cell&gt;–&lt;/cell&gt;&lt;cell&gt;13,005.4 ms&lt;/cell&gt;&lt;cell&gt;6,709.8 ms&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Observations:&lt;/p&gt;&lt;code&gt;CPU-seq&lt;/code&gt; vs &lt;code&gt;CPU-scan&lt;/code&gt;) provides a massive, constant-factor speedup (around 10x), but the runtime still scales linearly, $O(T)$.&lt;p&gt;To understand the GPU performance better, I used NVIDIA’s Nsight Compute profiler. The initial implementation launched thousands of tiny kernels, one for each time step, which is a classic anti-pattern in GPU programming due to launch overhead.&lt;/p&gt;&lt;p&gt;My first major optimization was to fuse the gate computations for all time steps into a single, large kernel (&lt;code&gt;min_gru_extract_scan_params_kernel&lt;/code&gt;) that uses shared memory tiling to manage weights and inputs efficiently.&lt;/p&gt;&lt;p&gt;Here’s a snapshot of the kernel performance breakdown at $T=4096$ after this optimization:&lt;/p&gt;&lt;table&gt;&lt;row span="5"&gt;&lt;cell role="head"&gt;Rank&lt;/cell&gt;&lt;cell role="head"&gt;Kernel&lt;/cell&gt;&lt;cell role="head"&gt;Time/launch&lt;/cell&gt;&lt;cell role="head"&gt;Launches&lt;/cell&gt;&lt;cell role="head"&gt;% wall-time&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;min_gru_extract_scan_params_kernel&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;180 $\mu$s&lt;/cell&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;cell&gt;8 %&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;2–9&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;compose_offset_kernel&lt;/code&gt; (Scan Up-Sweep)&lt;/cell&gt;&lt;cell&gt;~3 $\mu$s&lt;/cell&gt;&lt;cell&gt;12&lt;/cell&gt;&lt;cell&gt;&amp;lt; 1 %&lt;/cell&gt;&lt;/row&gt;&lt;row span="5"&gt;&lt;cell&gt;10–&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;apply_scan_op_kernel&lt;/code&gt; (Scan Down-Sweep)&lt;/cell&gt;&lt;cell&gt;~2 $\mu$s&lt;/cell&gt;&lt;cell&gt;4096&lt;/cell&gt;&lt;cell&gt;10 %&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;11–&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;matvec_kernel&lt;/code&gt; (Output Projection)&lt;/cell&gt;&lt;cell&gt;~93 $\mu$s&lt;/cell&gt;&lt;cell&gt;4096&lt;/cell&gt;&lt;cell&gt;72 %&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The profiling revealed a few things:&lt;/p&gt;&lt;code&gt;matvec_kernel&lt;/code&gt;), which consumes 72% of the runtime. This is because I was still launching one kernel per time step (4096 launches!), leading to low occupancy and terrible memory bandwidth utilization (only 23 GB/s).&lt;code&gt;matvec&lt;/code&gt; launches with a single cuBLAS GEMM call ($C = A \cdot W^T$). This would eliminate the kernel launch overhead and leverage a highly optimized library routine, likely bringing the total latency down significantly.&lt;p&gt;I made this project as part of my final assignment for my GPU Programming course, CS 179 at Caltech. This project was a great hands-on lesson in parallel algorithms. The claims in “Were RNNs All We Needed?” did seem to hold up: by reformulating the recurrence, RNNs can indeed be parallelized, and the performance gains on GPUs are substantial for long sequences. One of the reasons why this paper gained criticism from the CS commmunity was because there weren’t many experiments to back the claim that miniRNNs performed any better than transformers - and from my rusty recollection of the paper - the only benchmarks the miniRNNs outperformed transformers were niche targetted datasets that did not transfer to real-world benchmarks. Sure, with the parallelization and ripping away unncessary complexity from RNNs, miniRNNs were much more efficient but it was never the end-all be-all.&lt;/p&gt;&lt;p&gt;I remember Francois’s quote on this paper from his X thread:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Interesting work on reviving RNNs. https://arxiv.org/abs/2410.01201 – in general the fact that there are many recent architectures coming from different directions that roughly match Transformers is proof that architectures aren’t fundamentally important in the curve-fitting paradigm (aka deep learning)&lt;/p&gt;&lt;p&gt;Curve-fitting is about embedding a dataset on a curve. The critical factor is the dataset, not the specific hard-coded bells and whistles that constrain the curve’s shape. As long as your curve is sufficiently expressive all architectures will converge to the same performance in the large-data regime.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;I have a different take on this. All progress in the language modelling in the last decade has come from changes in architectures to be able to generate rich, more expressive curves that fit the target dataset better. If we blindly apply the bitter lesson and throw enough compute to different architectures (reasonable ones), it would be a good signal to see which architecture hits the wall the fastest and which one continues generalizing rather than all converging in the same way eventually.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45291903</guid><pubDate>Thu, 18 Sep 2025 16:47:15 +0000</pubDate></item><item><title>MapSCII – World map in terminal</title><link>https://github.com/rastapasta/mapscii</link><description>&lt;doc fingerprint="ecc3b87ab9807886"&gt;
  &lt;main&gt;
    &lt;p&gt;A node.js based Vector Tile to Braille and ASCII renderer for xterm-compatible terminals.&lt;/p&gt;
    &lt;code&gt;$ telnet mapscii.me&lt;/code&gt;
    &lt;p&gt;If you're on Windows, use the open source telnet client PuTTY to connect.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use your mouse to drag and zoom in and out!&lt;/item&gt;
      &lt;item&gt;Discover Point-of-Interests around any given location&lt;/item&gt;
      &lt;item&gt;Highly customizable layer styling with Mapbox Styles support&lt;/item&gt;
      &lt;item&gt;Connect to any public or private vector tile server&lt;/item&gt;
      &lt;item&gt;Or just use the supplied and optimized OSM2VectorTiles based one&lt;/item&gt;
      &lt;item&gt;Work offline and discover local VectorTile/MBTiles&lt;/item&gt;
      &lt;item&gt;Compatible with most Linux and OSX terminals&lt;/item&gt;
      &lt;item&gt;Highly optimized algorithms for a smooth experience&lt;/item&gt;
      &lt;item&gt;100% pure JavaScript! 😎&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With a modern node installation available, just start it with&lt;/p&gt;
    &lt;code&gt;npx mapscii
&lt;/code&gt;
    &lt;p&gt;If you haven't already got Node.js &amp;gt;= version 10, then go get it.&lt;/p&gt;
    &lt;code&gt;npm install -g mapscii
&lt;/code&gt;
    &lt;p&gt;If you're on OSX, or get an error about file permissions, you may need to do &lt;code&gt;sudo npm install -g mapscii&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;In any of the supported Linux distros:&lt;/p&gt;
    &lt;code&gt;sudo snap install mapscii
&lt;/code&gt;
    &lt;p&gt;(This snap is maintained by @nathanhaines)&lt;/p&gt;
    &lt;p&gt;This is pretty simple too.&lt;/p&gt;
    &lt;code&gt;mapscii
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Arrows up, down, left, right to scroll around&lt;/item&gt;
      &lt;item&gt;Press a or z to zoom in and out&lt;/item&gt;
      &lt;item&gt;Press c to switch to block character mode&lt;/item&gt;
      &lt;item&gt;Press q to quit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If your terminal supports mouse events you can drag the map and use your scroll wheel to zoom in and out.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;x256&lt;/code&gt;for converting RGB values to closest xterm-256 color code&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;term-mouse&lt;/code&gt;for mouse handling&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;keypress&lt;/code&gt;for input handling&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;string-width&lt;/code&gt;to determine visual string lengths&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;vector-tile&lt;/code&gt;for VectorTile parsing&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;pbf&lt;/code&gt;for Protobuf decoding&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;mbtiles&lt;/code&gt;for MBTiles parsing&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;earcut&lt;/code&gt;for polygon triangulation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rbush&lt;/code&gt;for 2D spatial indexing of geo and label data&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bresenham&lt;/code&gt;for line point calculations&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;simplify-js&lt;/code&gt;for polyline simplifications&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;node-fetch&lt;/code&gt;for HTTP requests&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;env-paths&lt;/code&gt;to determine where to persist downloaded tiles&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;MapSCII&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;GeoJSON support via geojson-vt&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;CLI support&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;[-] startup parameters &lt;list rend="ul"&gt;&lt;item&gt;TileSource&lt;/item&gt;&lt;item&gt;Style&lt;/item&gt;&lt;item&gt;center position&lt;/item&gt;&lt;item&gt;zoom&lt;/item&gt;&lt;item&gt;demo mode?&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;[-] startup parameters &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;mouse control&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;hover POIs/labels&lt;/item&gt;
              &lt;item&gt;hover maybe even polygons/-lines?&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Styler&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;respect zoom based style ranges&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Renderer&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;TileSource&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;implement single vector-tile handling&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;lukasmartinelli &amp;amp; manuelroth for all their work on OSM2VectorTiles (global vector tiles from OSM Planet)&lt;/item&gt;
      &lt;item&gt;mourner for all his work on mindblowing GIS algorithms (like the used earcut, rbush, simplify-js, ..)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;OpenStreetMap is open data, licensed under the Open Data Commons Open Database License (ODbL) by the OpenStreetMap Foundation (OSMF).&lt;/p&gt;
    &lt;p&gt;You are free to copy, distribute, transmit and adapt our data, as long as you credit OpenStreetMap and its contributors. If you alter or build upon our data, you may distribute the result only under the same licence. The full legal code explains your rights and responsibilities.&lt;/p&gt;
    &lt;p&gt;The cartography in our map tiles, and our documentation, are licenced under the Creative Commons Attribution-ShareAlike 2.0 licence (CC BY-SA).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45293012</guid><pubDate>Thu, 18 Sep 2025 18:12:58 +0000</pubDate></item><item><title>PYREX vs. pyrex: What's the difference?</title><link>https://www.corning.com/worldwide/en/products/life-sciences/resources/stories/in-the-field/pyrex-vs-pyrex-whats-the-difference.html</link><description>&lt;doc fingerprint="bc309c5290c9256b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h2"&gt;PYREX vs pyrex Construction Differences&lt;/head&gt;
      &lt;p&gt;Corning used borosilicate to produce all Pyrex products. However, the company that purchased the cookware products switched to soda-lime glass, adopting the name pyrex (spelled with all lowercase letters).&lt;/p&gt;
      &lt;p&gt;Corning continued to make its lab tools with borosilicate, dubbing these products to be PYREX (spelled with all uppercase letters). Borosilicate glassware can sustain the large, sudden temperature changes that frequently occur in labs without shattering. These products are also less likely to react to chemicals.&lt;/p&gt;
      &lt;p&gt;Corning sold the consumer products or cookware business in 1998. The new owner, known as Borden at the time, later rebranding to World Kitchen in 2000, recognized that the cookware didn't need to be quite as strong, and — to make it accessible to the average customer — it needed to be more affordable. With this in mind, they switched the cookware to soda-lime glass, a less expensive component. Soda-lime glass, now called pyrex, isn't as resistant to thermal shock, but it is durable enough for everyday cooking.&lt;/p&gt;
      &lt;head rend="h2"&gt;Benefits of PYREX Labware&lt;/head&gt;
      &lt;p&gt;PYREX labware is designed to meet the rigorous demands of scientific experimentation. In fact, these scientific glassware products were integral in developing penicillin during World War II and the polio vaccine during the 1950s.&lt;/p&gt;
      &lt;p&gt;Corning laboratory glassware products have long been manufactured to meet the quality and reliability standards created by the American Society for Testing and Materials (ASTM). Corning advanced its quality control for accuracy and precision further by testing its volumetric glassware in an ISO/IEC 17025 accredited laboratory.&lt;/p&gt;
      &lt;p&gt;PYREX glass is well-suited for lab work because Corning uses borosilicate to produce beakers, flasks, test tubes, and other lab glassware. PYREX lab glassware made with borosilicate can withstand harsh, corrosive chemicals, handle extremely low and high temperatures, and it can survive rapid temperature changes without sustaining damage. PYREX beakers, Erlenmeyer flasks, and round- and flat-bottom boiling flasks can be repeatedly heated up to 230ºC. PYREX volumetric laboratory ware can be brought to 150ºC. Overall, PYREX laboratory glassware has a temperature shock limit — or allowable difference between the temperature of the glass and any medium in contact with the glass (air, liquid, or solid) — of 160ºC.&lt;/p&gt;
      &lt;p&gt;Always check laboratory glassware for any cracks, scratches, chips, or hazing — these damages can cause the product to break while in use. If properly cleaned and not damaged, PYREX laboratory glassware is reusable.&lt;/p&gt;
      &lt;head rend="h2"&gt;Unique Cleaning Procedures for PYREX Lab Glassware&lt;/head&gt;
      &lt;p&gt;Despite being made of a strong, durable material, PYREX lab glassware requires specific care and maintenance. Ignoring the specific cleaning differences of PYREX labware can undermine the glassware's integrity and stability. If handled improperly, these products could shatter when exposed to high temperatures.&lt;/p&gt;
      &lt;p&gt;Always clean PYREX products with a non-abrasive glassware detergent either by hand or in a dishwasher. Do not exceed temperatures above 110°C during the cleaning process. Do not use abrasive brushes or scrubbing pads that can scratch the glass or its coating. In addition, limit exposure to any aldehydes, ketones, chlorinated solvents, or concentrated acids, because they can damage the glassware.&lt;/p&gt;
      &lt;p&gt;For over 100 years, Corning has been a trailblazer in creating innovative glassware products that can reliably and repeatedly meet users' needs. These products have accelerated scientific discoveries and enhanced human health.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45310995</guid><pubDate>Sat, 20 Sep 2025 06:37:01 +0000</pubDate></item><item><title>FLX1s phone is launched</title><link>https://furilabs.com/flx1s-is-launched/</link><description>&lt;doc fingerprint="dfe351495ea32377"&gt;
  &lt;main&gt;
    &lt;p&gt;It is with great excitement that we can now release the FLX1s. Pre-sales are open and the phone is in production which is due to complete end of October 2025. Following that we can start shipping. Existing orders will be opted into the FLX1s or refunded.&lt;lb/&gt;To all our amazing FLX1 owners and those waiting patiently for their order, you have been the most wonderful and supportive community that we could ever have imagined.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Thank-you from the FuriLabs Team.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312326</guid><pubDate>Sat, 20 Sep 2025 11:20:04 +0000</pubDate></item><item><title>Images over DNS</title><link>https://dgl.cx/2025/09/images-over-dns</link><description>&lt;doc fingerprint="fec80dd7a0729493"&gt;
  &lt;main&gt;
    &lt;p&gt;What's the limit of what can be in a TXT record?&lt;/p&gt;
    &lt;p&gt;Some places say 255 bytes. They are wrong. Within a TXT record there are multiple character-strings (RFC 1035 section 3.3.14) and those are limited in length (because a single byte is used for their length), however there can be many of them.&lt;/p&gt;
    &lt;p&gt;The actual limit is limited by the size of the DNS payload, which for UDP is these days around 1232 bytes. That is obviously quite low. However if we use TCP, which doesn't require anything special, other than the normal fallback to TCP that DNS does, then we can serve up to 64KB.&lt;/p&gt;
    &lt;p&gt;I set out to demonstrate exactly that, by using Google Public DNS's JSON API and then serving large TXT responses over TCP, from a custom server.&lt;/p&gt;
    &lt;p&gt;This mostly just works, the main issue is not with the length, but with binary data, because JSON isn't really designed to handle binary data. Therefore there is some slightly custom JSON parsing. Using raw binary data in a TXT record avoids the overhead of Base64 or another encoding, meaning more data can be packed in.&lt;/p&gt;
    &lt;p&gt;👉 See it in action. For more read the comments in image.html.&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-browser&lt;/head&gt;
    &lt;p&gt;It is possible to query this via dig. Although turning it back into binary output is a bit tricky, as the presentation form of DNS responses is escaped for output.&lt;/p&gt;
    &lt;p&gt;You can retrieve the data with dig and a little Perl to unescape and combine the character sequences:&lt;/p&gt;
    &lt;code&gt;$ dig +short dog.log.battery.st TXT | perl -pe'chomp; s/" "//g; s/^"//; s/"$//; s/\\(\d{3})/chr $1/eg; s/\\([\\"])/$1/g' &amp;gt; dog.avif
$ sha256sum dog.avif
7058fbd20ef2af84d5efb0ae7d91f87ce7a912380636c468b32f2c759cbb9130  dog.avif
&lt;/code&gt;
    &lt;p&gt;(This is actually just a modified version of the Perl one liner from my Wikipedia over DNS from 2008, nothing changes.)&lt;/p&gt;
    &lt;p&gt;Because the web version uses Google's JSON resolver we know it doesn't have problems querying very large TXT records, however your local recursor may not support this. If it doesn't work you can add &lt;code&gt;@dns.google&lt;/code&gt; to the dig command
line to send the query to Google's Public DNS servers (or any other open
recursor, &lt;code&gt;@9.9.9.9&lt;/code&gt; seems to work too).&lt;/p&gt;
    &lt;head rend="h2"&gt;Why?&lt;/head&gt;
    &lt;p&gt;I thought it was a cute hack when I realised it was possible.&lt;/p&gt;
    &lt;p&gt;For those interested in security there is a consideration here, attackers have long tunnelled over DNS, but tunnelling large payloads to a browser is potentially something new. Because Google Public DNS has a certificate that includes &lt;code&gt;8.8.8.8&lt;/code&gt; and so on, HTTPS
traffic can go directly from a browser without a DNS lookup. This may be
unexpected in environments that use DNS filtering. This is something that will
become more common once Lets Encrypt fully rolls out IP address
certificates,
the difference here is piggybacking on an existing IP address certificate.&lt;/p&gt;
    &lt;p&gt;This deliberately uses a low TTL (10 seconds) to avoid filling DNS recursor's caches with useless content. It would be possible to increase this and therefore get caching from the recursors, a bit like a free distributed CDN (although I suspect if someone actually did this they would adaptively limit TTLs, if something like that isn't already done).&lt;/p&gt;
    &lt;head rend="h2"&gt;Server side&lt;/head&gt;
    &lt;p&gt;The server is a custom Go DNS server. To be honest it was written by ChatGPT because it's not that clever, the idea is what matters. (Although ChatGPT did get some details like truncation wrong so I fixed the code myself.)&lt;/p&gt;
    &lt;p&gt;All the code is here. AI was only used for the server component, this blog post and the client HTML code is my own work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45312515</guid><pubDate>Sat, 20 Sep 2025 11:50:15 +0000</pubDate></item><item><title>Vapor chamber tech keeps iPhone 17 Pro cool</title><link>https://spectrum.ieee.org/iphone-17-pro-vapor-chamber</link><description>&lt;doc fingerprint="9533a64f32e316ed"&gt;
  &lt;main&gt;
    &lt;p&gt;On 9 September, Apple introduced its newest lineup, including the iPhone 17 series. Much of the attention went to a new ultrathin model and a bright orange color option (a shade not dissimilar to that of the IEEE Spectrum logo). The new smartphones will also ship with the latest operating system and its “Liquid Glass” software design—but the liquid in these phones goes beyond software.&lt;/p&gt;
    &lt;p&gt;The iPhone 17 Pro and iPhone 17 Pro Max contain thin, hermetically sealed chambers with a drop of water inside that cycles between liquid and gas to help dissipate heat. Known as vapor chambers, the cooling system is becoming more common in smartphones built for sustained high performance. Some high-end Samsung Galaxy and Google Pixel models, among others, have introduced vapor-chamber cooling in the past few years. Now, Apple is following their lead.&lt;/p&gt;
    &lt;p&gt;“Cooling of smaller portables like phones must focus on spreading heat as widely as possible to the surface of the device, with particular attention to heat-generating components, like the chip,” says Kenneth Goodson, a professor of mechanical engineering at Stanford who specializes in heat transfer and energy conversion. To cool down those hot spots, the industry seems to be moving toward vapor chambers and other phase-change technology.&lt;/p&gt;
    &lt;head rend="h2"&gt;How vapor chambers keep phones cool&lt;/head&gt;
    &lt;p&gt;The standard approach to cooling smartphones uses a solid, highly conductive plate made from a material like copper to spread heat. This approach relies on having a surface where heat can spread. Sometimes, fins are added to extend that surface, but this can lead to a thicker device. Most companies, however, are intent on making thinner and thinner phones.&lt;/p&gt;
    &lt;p&gt;Phase-change technology—which has been used in laptops for decades, Goodson notes—achieves the same goal more effectively with fluid that boils and condenses to dissipate heat. These two-phase solutions include vapor chambers, like those used in the new iPhone, as well as narrow, fingerlike structures called heat pipes.&lt;/p&gt;
    &lt;p&gt;Phones have limited volume to work with, and “performance per volume is critical,” says Victor Chiriac, the CEO and cofounder of Global Cooling Technology Group, based in Phoenix. Thin and wide vapor chambers have a high heat-removal capacity and offer an effective solution. The cycle between liquid and vapor is “a powerful mechanism for absorbing heat,” he says.&lt;/p&gt;
    &lt;p&gt;Apple’s vapor chamber efficiently spreads heat across the phone’s body.Apple&lt;/p&gt;
    &lt;p&gt;In Apple’s version, a small amount of deionized water is sealed in the chamber. The water evaporates when near heat sources, then condenses back into a liquid when the heat dissipates into the phone’s surrounding aluminum body. Water is often used in vapor chambers, though sometimes other materials are mixed in to prevent it from freezing and cracking the seal, Chiriac says.&lt;/p&gt;
    &lt;head rend="h2"&gt;Vapor-chamber manufacturing faces challenges&lt;/head&gt;
    &lt;p&gt;As Apple, Samsung, and others push the boundaries of how thin phones can get, manufacturing vapor chambers may become a challenge. While solid materials can easily be shaved down, these chambers need to have enough space for coolant to travel through channels. The chambers have to be perfectly sealed in order to work properly, and “the thinner you make it, the less space you have for that secret sauce to do its thing,” Chiriac says.&lt;/p&gt;
    &lt;p&gt;It comes down to physics: “A big challenge in small devices like phones is that as you scale down the thickness of a vapor chamber, the fluid physics aggressively scale back their performance relative to copper and other solid heat conductors,” Goodson explains. (This is a problem that researchers, including his students, are working to address with new microstructures.) Plus, vapor chambers tend to be expensive to manufacture.&lt;/p&gt;
    &lt;p&gt;Still, Apple and other companies have decided to invest in this technology for their most powerful phone models. Goodson suspects part of that decision is to leverage the “wow” factor. But, he says, “with time this approach will likely become an industry standard.”&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All-Silicon “Fan-on-a-Chip” Keeps Thin Devices Cool ›&lt;/item&gt;
      &lt;item&gt;Superslim Liquid Loop Will Keep Future Smartphones Cool ›&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Gwendolyn Rak is an assistant editor at IEEE Spectrum covering consumer electronics and careers. She holds a master’s degree in science journalism from New York University and a bachelor’s degree in astrophysics and history from Swarthmore College.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313415</guid><pubDate>Sat, 20 Sep 2025 13:50:58 +0000</pubDate></item><item><title>Living microbial cement supercapacitors with reactivatable energy storage</title><link>https://www.cell.com/cell-reports-physical-science/fulltext/S2666-3864(25)00409-6</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313418</guid><pubDate>Sat, 20 Sep 2025 13:51:12 +0000</pubDate></item><item><title>Cormac McCarthy's tips on how to write a science paper (2019) [pdf]</title><link>https://gwern.net/doc/science/2019-savage.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45313557</guid><pubDate>Sat, 20 Sep 2025 14:08:24 +0000</pubDate></item><item><title>Ultrasonic Chef's Knife</title><link>https://seattleultrasonics.com/</link><description>&lt;doc fingerprint="c4ae7ddc24d05992"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;head rend="h2"&gt;The World's First&lt;/head&gt;&lt;lb/&gt;Ultrasonic Chef's Knife&lt;lb/&gt;For Home Cooks&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h2"&gt;Switch on the ultrasonics and feel the blade glide effortlessly through food. Clean cuts, minimal force, less sticking.&lt;/head&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Regular price $399.00 &lt;/p&gt;
    &lt;p&gt; Regular price &lt;del class="price-item price-item--regular" data-product-id="7320581177440" rend="overstrike"&gt; $399.00 &lt;/del&gt; Sale price $399.00 &lt;/p&gt;
    &lt;p&gt;Pre-Order now for estimated shipping by January, 2026 (Batch 1). Cancel anytime before your order ships. What is a Pre-Order?&lt;/p&gt;
    &lt;p&gt;Regular price $499.00 &lt;/p&gt;
    &lt;p&gt; Regular price &lt;del class="price-item price-item--regular" data-product-id="7497201942624" rend="overstrike"&gt; $548.00 &lt;/del&gt; Sale price $499.00 &lt;/p&gt;
    &lt;p&gt;Pre-Order now for estimated shipping by January 2026 (Batch 1). Cancel anytime before your order ships. What is a Pre-Order?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45314592</guid><pubDate>Sat, 20 Sep 2025 16:12:56 +0000</pubDate></item><item><title>Designing NotebookLM</title><link>https://jasonspielman.com/notebooklm</link><description>&lt;doc fingerprint="bf50da1b9d312eaa"&gt;
  &lt;main&gt;
    &lt;p&gt;User Journey â¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the productâs core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and Iâm incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadnât existed before. None of it wouldâve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;Podcast â¢ Sequoia&lt;/p&gt;
    &lt;p&gt;Raiza and I discuss the journey building NotebookLM.&lt;/p&gt;
    &lt;p&gt;NotebookLM â¢ Winner!&lt;/p&gt;
    &lt;p&gt;Recognized as one of TIMEâs Best Inventions of 2024.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;UI Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was âtab overwhelmâ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;â Inputs&lt;/p&gt;
    &lt;p&gt;Outputs â&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;â¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;â¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may seem obvious but it took After what felt like 1000 iterations to get there. Trying to put these blocks together in a way that allowed for a clear mental model and digstible UI. These early sketches are from a plane. I ran out of paper and ultimately found the final solution when drawing on a napkin.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs â Chat â Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;Itâs rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the userâs needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;A popular request, designed for users focused on drafting and iteration.&lt;/p&gt;
    &lt;p&gt;Ideal for composing while keeping source material in view.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Hereâs what that looks like:&lt;/p&gt;
    &lt;p&gt;User Journey â¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin â&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin â&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the productâs core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and Iâm incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadnât existed before. None of it wouldâve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Brand Identity&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Takeaways&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;UI Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was âtab overwhelmâ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;â Inputs&lt;/p&gt;
    &lt;p&gt;Outputs â&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;â¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;â¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may seem obvious but it took After what felt like 1000 iterations to get there. Trying to put these blocks together in a way that allowed for a clear mental model and digstible UI. These early sketches are from a plane. I ran out of paper and ultimately found the final solution when drawing on a napkin.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs â Chat â Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;Itâs rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the userâs needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;Standard&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Reading + Chat&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Hereâs what that looks like:&lt;/p&gt;
    &lt;p&gt;User Journey â¢ Annotated Overview&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin â&lt;/p&gt;
    &lt;p&gt;Wanda Wingleton&lt;/p&gt;
    &lt;p&gt;Linkedin â&lt;/p&gt;
    &lt;p&gt;Home&lt;/p&gt;
    &lt;p&gt;Next&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Design Lead&lt;/p&gt;
    &lt;p&gt;UX + Identity&lt;/p&gt;
    &lt;p&gt;2024&lt;/p&gt;
    &lt;p&gt;I led design for NotebookLM, shaping the productâs core user experience, brand identity, and visual system from experiment to launch.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;This remains one of my proudest projects, and Iâm incredibly grateful for the opportunity to design something entirely new from the ground up. It was a chance to explore fresh paradigms, invent new patterns, and bring a product to life that hadnât existed before. None of it wouldâve been possible without the tight-knit, cross-functional team I was fortunate to collaborate with.&lt;/p&gt;
    &lt;p&gt;Podcast â¢ Seqouia Training Data&lt;/p&gt;
    &lt;p&gt;Raiza and I discuss the journey building NotebookLM.&lt;/p&gt;
    &lt;p&gt;NotebookLM â¢ Winner!&lt;/p&gt;
    &lt;p&gt;Recognized as one of TIMEâs Best Inventions of 2024.&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;3 Panel&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Brand Identity&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Visual Assets&lt;/p&gt;
    &lt;p&gt;|&lt;/p&gt;
    &lt;p&gt;Takeaways&lt;/p&gt;
    &lt;p&gt;Architecture&lt;/p&gt;
    &lt;p&gt;Design Evolution&lt;/p&gt;
    &lt;p&gt;Early Prototype&lt;/p&gt;
    &lt;p&gt;This is what the UI looked like when I first joined the early project.&lt;/p&gt;
    &lt;p&gt;Notes driven UI&lt;/p&gt;
    &lt;p&gt;Exploratory chat UI introduced as an overlay on the note canvas.&lt;/p&gt;
    &lt;p&gt;3-Panel Structure&lt;/p&gt;
    &lt;p&gt;Synthesizes learnings into a scalable and adaptive layout.&lt;/p&gt;
    &lt;p&gt;One of the core problems we set out to solve with NotebookLM was âtab overwhelmâ the scattered, fractured experience of jumping between tools while trying to synthesize ideas. We wanted to create a space where every part of the creation journey could happen in one place.&lt;/p&gt;
    &lt;p&gt;â Inputs&lt;/p&gt;
    &lt;p&gt;Outputs â&lt;/p&gt;
    &lt;p&gt;Chat&lt;/p&gt;
    &lt;p&gt;â¢ Citations&lt;/p&gt;
    &lt;p&gt;Creation&lt;/p&gt;
    &lt;p&gt;â¢ Multiple entry points&lt;/p&gt;
    &lt;p&gt;This visual shows how the core building blocks came together.&lt;/p&gt;
    &lt;p&gt;The structure you see now may look obvious but it took what felt like a thousand iterations to get there. I was trying to arrange these blocks in a way that supported a clear mental model and a UI that felt intuitive and digestible.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;These sketches were done on a plane. I ran out of paper and ended up sketching the final solution across a few napkins.&lt;/p&gt;
    &lt;p&gt;The mental model of NotebookLM was built around the creation journey: starting with inputs, moving through conversation, and ending with outputs. Users bring in their sources (documents, notes, references), then interact with them through chat by asking questions, clarifying, and synthesizing before transforming those insights into structured outputs like notes, study guides, and Audio Overviews.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;By grounding the design in this linear but flexible flow (Inputs â Chat â Outputs) we gave users a clear sense of place within the product while keeping the complexity of new AI interactions digestible and intuitive.&lt;/p&gt;
    &lt;p&gt;Itâs rare to find a product that brings reading, writing, and creation together in a truly integrated way largely because juggling all three can be overwhelming. But with AI reducing friction, the opportunity emerged to design a space where every part of the creative process could coexist.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;To make that possible, I designed a responsive panel system that adapts to the userâs needs, scaling fluidly while preserving quick access to key elements like sources and notes, even at the smallest sizes.&lt;/p&gt;
    &lt;p&gt;Standard&lt;/p&gt;
    &lt;p&gt;The default layout, offering a balanced view of sources, chat, and notes.&lt;/p&gt;
    &lt;p&gt;Reading + Chat&lt;/p&gt;
    &lt;p&gt;Optimized for referencing sources and generating responses with citations.&lt;/p&gt;
    &lt;p&gt;Chat + Writing&lt;/p&gt;
    &lt;p&gt;A popular request, designed for users focused on drafting and iteration.&lt;/p&gt;
    &lt;p&gt;Reading + Writing&lt;/p&gt;
    &lt;p&gt;Ideal for composing while keeping source material in view.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;To optimize spatial utility, I created a set of responsive panels that scale based on user needs, retaining essential icons for sources and notes even at minimal widths.&lt;/p&gt;
    &lt;p&gt;Â&lt;/p&gt;
    &lt;p&gt;Scalability was a core principle. While the content within these panels can shift and evolve, the underlying system is built to support growth, accommodating new tools, modes, and workflows without breaking the structure.&lt;/p&gt;
    &lt;p&gt;Source Panel&lt;/p&gt;
    &lt;p&gt;Studio Panel&lt;/p&gt;
    &lt;p&gt;See how the team has continued to scale this system with the newest launch of flashcards, quizzes, professional reports.&lt;/p&gt;
    &lt;p&gt;Chat Panel&lt;/p&gt;
    &lt;p&gt;Hereâs what that looks like:&lt;/p&gt;
    &lt;p&gt;Read the full story&lt;/p&gt;
    &lt;p&gt;Defining the brand identity was a fast-paced effort, made possible by close collaboration with Google Labs and the central brand team. Shoutout Feel Hwang, Nick Mcginnis, Jennifer Leartanasan and team.&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin â&lt;/p&gt;
    &lt;p&gt;Jason Spielman&lt;/p&gt;
    &lt;p&gt;Linkedin â&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45315312</guid><pubDate>Sat, 20 Sep 2025 17:25:58 +0000</pubDate></item><item><title>A revolution in English bell ringing</title><link>https://harpers.org/archive/2025/10/a-change-of-tune-veronique-greenwood-bell-ringing/</link><description>&lt;doc fingerprint="f108bd6b5cc6fc83"&gt;
  &lt;main&gt;
    &lt;p&gt;October 2025 Issue [Annotation] A Change of Tune Download PDF Adjust Share A revolution in English bell ringing by Veronique Greenwood, Veronique Greenwood is a writer and bell ringer who lives in England. Tags Bell ringing England Adjust Share&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45316744</guid><pubDate>Sat, 20 Sep 2025 19:51:36 +0000</pubDate></item><item><title>Philips announces digital pathology scanner with native DICOM JPEG XL output</title><link>https://www.philips.com/a-w/about/news/archive/standard/news/articles/2025/philips-announces-digital-pathology-scanner-with-native-configurable-dicom-jpeg-and-jpeg-xl-output-in-world-first.html</link><description>&lt;doc fingerprint="1758be5a88b6ac93"&gt;
  &lt;main&gt;
    &lt;p&gt;Sep 08, 2025 | 2 minute read&lt;/p&gt;
    &lt;p&gt; Pathology plays a crucial role in the diagnosis of a variety of diseases, particularly cancer, through examination of patient tissue samples. With an estimated 70% of important medical decisions involving laboratory or pathology tests [2], the availability of digitally stored pathology images is especially important as it has a significant impact on patient care. The digital transformation of pathology also means there is a growing need for scalable storage to meet new data volumes and computing resources, which also allows full AI adoption in clinical and research environments. &lt;/p&gt;
    &lt;p&gt; DICOM (Digital Imaging and Communications in Medicine) is the international standard for medical images and related patient information. Because digital pathology is a relatively new imaging modality compared to radiology and others, there was no established DICOM standard in place. As a result, vendors created their own proprietary formats.&lt;lb/&gt; Today, Philips announced that it is expanding its SG300 and SG60 scanner offering with the Pathology Scanner SGi with configurable DICOM JPEG and DICOM JPEG XL output. As a result, it is the first in the world to offer native DICOM JPEG XL output. DICOM JPEG XL output files are up to 50% smaller while still providing the same high image quality [3], enabling pathology labs to store, manage, and analyze growing volumes of digital pathology data and enable more productive workflows in the cloud and on premise.&lt;lb/&gt; “The adoption of DICOM in pathology marks an important shift toward achieving scalable, interoperable imaging workflows, said Imogen Fitt, Principal Analyst at Signify Research. “As pathology labs face mounting data volumes and storage demands, the move to standardized formats helps reduce infrastructure costs and enables integration with a wider range of AI tools. Philips’ support for DICOM JPEG and DICOM JPEG XL as a native output from its scanners illustrates how vendors are aligning with these trends, intending to support capabilities such as centralized archiving, cross-modality diagnostics, and remote collaboration for customers.”&lt;/p&gt;
    &lt;p&gt; Sources [1] Pathology Scanner SGi is under development and is not CE marked and is not yet available for sale. [2] Report of the Second Phase of the Review of NHS Pathology Services in England, Lord Carter of Coles (2008). Results are specific to the institution where they were obtained and may not reflect the results achievable at other institutions. [3] Based on preliminary test data on diverse slide types. Data representative of a typical clinical mix is not yet available.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45316833</guid><pubDate>Sat, 20 Sep 2025 20:00:11 +0000</pubDate></item><item><title>A brief history of threads and threading</title><link>https://eclecticlight.co/2025/09/20/a-brief-history-of-threads-and-threading/</link><description>&lt;doc fingerprint="66748c770736d00a"&gt;
  &lt;main&gt;
    &lt;p&gt;The original 128K Mac from 1984 came with a single Motorola 68000 processor running at 8 MHz that could only run one app at a time. Yet today’s Macs come with multiple CPU cores that can comfortably run several substantial apps simultaneously, while running a Time Machine backup and other tasks in the background. This brief history outlines the journey between them.&lt;/p&gt;
    &lt;p&gt;A processor with a single core and no support for multi-tasking runs one sequence of instructions at a time. When those call for an operating system function to be performed, the running app is interrupted to hand control over to the system, and once that has completed, control is passed back to the app. That’s what the first Macs did until Andy Hertzfeld wrote Switcher, released by Apple in April 1985. This allowed the user to switch between running more than one app, but was still limited to running just one of them at a time.&lt;/p&gt;
    &lt;head rend="h4"&gt;Multitasking&lt;/head&gt;
    &lt;p&gt;Over the next couple of years, some third-party utilities were produced to go further than Switcher, but it wasn’t until 1987 that MultiFinder replaced Switcher, and was integrated into System 7 in 1991. Developed by Erich Ringewald and Phil Goldman, this brought cooperative multitasking, which was to become the mainstay of classic Mac OS.&lt;/p&gt;
    &lt;p&gt;In computers with a single processor core, multitasking is a way of cheating to give the impression that the processor is doing several things at once, when in fact all it’s doing is switching rapidly between two or more different programs. There are two fundamental models for doing that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;cooperative multitasking, in which individual tasks yield to give others processing time;&lt;/item&gt;
      &lt;item&gt;preemptive multitasking, in which a scheduler switches between tasks at regular intervals.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When a processor switches from one task to the next, the current task state must be saved so it can be resumed later. Once that’s complete, the next task is loaded to complete the context switch. That incurs overhead, both in terms of processing and in memory storage, which are less when switching between lightweight tasks. Different strategies have been adopted to determine the optimum size of tasks and overhead imposed by context switching, and terminology differs between them, variously using words such as processes, threads and even fibres, which can prove thoroughly confusing.&lt;/p&gt;
    &lt;p&gt;Classic Mac OS thus has a Process Manager that launches apps in cooperative multitasking. This works well much of the time, but lets badly behaved tasks hog the processor and block other tasks from getting their fair share. It’s greatly aided by the main event loop at the heart of Mac apps that waits for control input to direct the app to perform work for the user. But when an app charges off to spend many seconds tackling a demanding task without polling its main event loop, that app could lock the user out for what seems like an age.&lt;/p&gt;
    &lt;p&gt;In February 1988 Apple released the first Unix for Macintosh, A/UX, which came with preemptive multitasking. That was added to Mac OS in 1996 in System 7.5.3, in Multiprocessing Services, and further enhanced in Mac OS 8.6 three years later. Cooperative multitasking was also supported by the Thread Manager.&lt;/p&gt;
    &lt;head rend="h4"&gt;Threads&lt;/head&gt;
    &lt;p&gt;In 2000 Apple’s hardware and software changed radically. Its first Macs with dual processors came in PowerPC 7400 (G4) chips in Power Mac G4 desktop systems, and Mac OS X brought several types of thread that could be used to manage processing on multiple processors or CPU cores, together with preemptive multitasking. Thread types include low-level Mach threads, higher-level POSIX threads or Pthreads that replaced Multiprocessing Services, Java Threads, Cocoa’s NSThreads, and cooperatively scheduled threads using the Carbon Thread Manager. The following diagram summarises Apple’s current terminology.&lt;/p&gt;
    &lt;p&gt;In most cases, we’re considering applications with a GUI, normally run from a bundle structure. These can in turn run their own code, such as privileged helper apps used to perform work that requires elevated privileges. In recent years, there has been a proliferation of additional executable code associated with many apps.&lt;/p&gt;
    &lt;p&gt;When that app is run, there’s a single runtime instance created from its single executable code, and given its own virtual memory and access to system resources that it needs. This is a process, and listed as such in Activity Monitor, for example.&lt;/p&gt;
    &lt;p&gt;Each process has a main thread, a single flow of code execution, and may create additional threads, perhaps to run in the background. Threads don’t get their own virtual memory, but share that allocated to the process, although they have their own stack. On Apple silicon Macs they’re easy to tell apart as they can only run on a single core, although they may be moved between cores, sometimes rapidly.&lt;/p&gt;
    &lt;p&gt;Within each thread are individual tasks, each a quantity of work to be performed. These can be brief sections of code and are more interdependent than threads. They’re often divided into synchronous and asynchronous tasks, depending on whether they need to be run as part of a strict sequence.&lt;/p&gt;
    &lt;p&gt;In 2005 the Power Mac G5 was the first Mac to use dual-core PowerPC G5 processors, then the iMac 17-inch of the following year used Apple’s first Intel Core Duo processor with two cores.&lt;/p&gt;
    &lt;head rend="h4"&gt;Grand Central Dispatch&lt;/head&gt;
    &lt;p&gt;In 2009 Mac OS X 10.6 Snow Leopard introduced a new dispatcher, named Grand Central Dispatch (GCD) after Grand Central Terminal in New York City, and that was enhanced in macOS Sierra a decade later. More recently it has been referred to simply as Dispatch.&lt;/p&gt;
    &lt;p&gt;At its heart, GCD is a dispatcher managing queues of tasks, activating those that need most to be run, and leaving the less pressing to wait a bit longer. It has its own queues, as well as those assembled by apps. Some are run as simple queues with a first in first out rule, others using sophisticated heuristics to determine relative priorities. There’s a detailed account of GCD internals in Jonathan Levin’s book *OS Internals volume 1, and Apple’s current developer documentation is here.&lt;/p&gt;
    &lt;p&gt;GCD was introduced for Macs with multiple identical cores, to support their symmetric multiprocessing (SMP), and with the release of the first Apple silicon Macs in November 2020 it has managed queues of threads to be dispatched for execution on two CPU core types, Performance and Efficiency. Core allocation is now managed according to the Quality of Service (QoS) assigned to each thread. When used on SMP processors with no contention for core availability, QoS has limited effects on thread performance, but performance on P and E cores may differ by a factor of 10.&lt;/p&gt;
    &lt;p&gt;Over the last 41 years, macOS has gained thorough support for getting the best performance from multiple tasks, threads, and processes in chips that contain up to 32 CPU cores of two types – a far cry from that single 68000 processor.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45317526</guid><pubDate>Sat, 20 Sep 2025 21:04:38 +0000</pubDate></item><item><title>$2 WeAct Display FS adds a 0.96-inch USB information display to your computer</title><link>https://www.cnx-software.com/2025/09/18/2-weact-display-fs-adds-a-0-96-inch-usb-information-display-to-your-computer/</link><description>&lt;doc fingerprint="aa305d1c39dee0f3"&gt;
  &lt;main&gt;
    &lt;p&gt;WeAct Display FS is an inexpensive 0.96-inch USB display dongle designed to add an information display or a tiny secondary display to your computer or SBC.&lt;/p&gt;
    &lt;p&gt;We’ve seen this type of information display with products such as the Turing Smart Screen, a larger 3.5-inch color display, or small OLEDs integrated into cases such as the Pironman 5 Max to disable text. The WeAct Display FS V1 may be tiny, but it’s also a full-color 160×80 resolution display that can be customized with software provided by WeAct.&lt;/p&gt;
    &lt;p&gt;WeAct Display FS V1 specifications:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Display – 0.96-inch RGB565 display with 160×80 resolution&lt;/item&gt;
      &lt;item&gt;Host interface – “Reversible” USB 2.0 Type-A Full Speed (FS) port showing as a CDC device&lt;/item&gt;
      &lt;item&gt;Dimensions – 43 x 14.5 mm&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since you wouldn’t want to get a display only for it to face the wrong direction, for instance, the desk or the wall, the company made the USB-A port reversible, and the user only needs to install one of the two provided pads on the unused side of the port to avoid short circuits.&lt;/p&gt;
    &lt;p&gt;WeAct provides two programs for it. The first one is the WeAct Studio System Monitor based on a fork of Matthieu Houdebine’s Turing Smart Screen Python project. This allows users to create UIs/themes with text, images, weather, and other features… WeAct says the little device only works on Windows, but the open-source project is supposed to also work on macOS, Linux (including Raspberry Pi OS), and essentially any operating system with support for Python 3.9+.&lt;/p&gt;
    &lt;p&gt;The second program is called WeAct Studio Screen Projection, and as I understand it, it emulates an actual display, so you could move any window/program to the USB display. I’m just not sure how a desktop OS like Windows will handle a tiny 160×80 “monitor”… I suppose it could be used to play a full-screen YouTube video or display photos for whatever reason. That one only works on Windows, and there’s no source code.&lt;/p&gt;
    &lt;p&gt;You’ll find the WeAct Display FS V1 (0.96-inch) on AliExpress for about $2 plus shipping, but while looking for information, I also noticed a 3.5-inch variant with 480×320 resolution for about $11.&lt;/p&gt;
    &lt;p&gt;Jean-Luc started CNX Software in 2010 as a part-time endeavor, before quitting his job as a software engineering manager, and starting to write daily news, and reviews full time later in 2011.&lt;/p&gt;
    &lt;p&gt;Support CNX Software! Donate via cryptocurrencies, become a Patron on Patreon, or purchase goods on Amazon or Aliexpress. We also use affiliate links in articles to earn commissions if you make a purchase after clicking on those links.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45317527</guid><pubDate>Sat, 20 Sep 2025 21:04:47 +0000</pubDate></item><item><title>Why do some gamers invert their controls?</title><link>https://www.theguardian.com/games/2025/sep/18/why-do-some-gamers-invert-their-controls-scientists-now-have-answers-but-theyre-not-what-you-think</link><description>&lt;doc fingerprint="a63b909429620de9"&gt;
  &lt;main&gt;
    &lt;p&gt;Five years ago, on the verge of the first Covid lockdown, I wrote an article asking what seemed to be an extremely niche question: why do some people invert their controls when playing 3D games? A majority of players push down on the controller to make their onscreen character look down, and up to make them look up. But there is a sizeable minority who do the opposite, controlling their avatars like a pilot controls a plane, pulling back to go up. For most modern games, this requires going into the settings and reconfiguring the default controls. Why do they still persist?&lt;/p&gt;
    &lt;p&gt;I thought a few hardcore gamers would be interested in the question. Instead, more than one million people read the article, and the ensuing debate caught the attention of Dr Jennifer Corbett (quoted in the original piece) and Dr Jaap Munneke, then based at the Visual Perception and Attention Lab at Brunel University London.&lt;/p&gt;
    &lt;p&gt;At the time, the two were conducting research into vision science and cognitive neuroscience, but when the country locked down, they were no longer able to test volunteers in their laboratory. The question of controller inversion provided the perfect opportunity to study the neuroscience of human-computer interactions using remote subjects. They put out a call for gamers willing to help research the reasons behind controller inversion and received many hundreds of replies.&lt;/p&gt;
    &lt;p&gt;And it wasn’t just gamers who were interested. “Machinists, equipment operators, pilots, designers, surgeons – people from so many different backgrounds reached out,” says Corbett. “Because there were so many different answers, we realised we had a lot of scientific literature to review to design the best possible study. Readers’ responses turned this study into the first of its kind to try to figure out what actually are those factors that shape how users configure their controllers. Personal experiences, favourite games, different genres, age, consoles, which way you scroll with a mouse … all of these things could potentially be involved.”&lt;/p&gt;
    &lt;p&gt;This month the duo published their findings in a paper entitled “Why axis inversion? Optimising interactions between users, interfaces, and visual displays in 3D environments”. And the reason why some people invert their controls? It’s complicated.&lt;/p&gt;
    &lt;p&gt;The process started with participants completing a survey about their backgrounds and gaming experiences. “Many people told us that playing a flight simulator, using a certain type of console, or the first game they played were the reasons they preferred to invert or not,” says Corbett. “Many also said they switched preferences over time. We added a whole new section to the study based on all this feedback.”&lt;/p&gt;
    &lt;p&gt;But Corbett and Munneke, now based at MIT and Northeastern University respectively, were certain that there would also be important cognitive components to the inversion question that could be measured only through behavioural responses. So they devised a questionnaire and a series of four experiments that participants would take part in while being instructed and observed via Zoom. As Corbett explains: “They had to mentally rotate random shapes, take on the perspective of an ‘avatar’ object in a picture, determine which way something was tilted in differently tilted backgrounds, and overcome the typical ‘Simon effect’ where it’s harder to respond when a target is on the opposite v the same side of the screen as the response button. Then we used some machine-learning algorithms to help us sort through all this survey and experiment data and pick out what combination of all of these things best explained whether someone inverted.”&lt;/p&gt;
    &lt;p&gt;What they discovered through the cognitive testing was that a lot of assumptions being made around controller preferences were wrong. “None of the reasons people gave us [for inverting controls] had anything to do with whether they actually inverted,” says Corbett. “It turns out the most predictive out of all the factors we measured was how quickly gamers could mentally rotate things and overcome the Simon effect. The faster they were, the less likely they were to invert. People who said they sometimes inverted were by far the slowest on these tasks.” So does this mean non-inverters are better gamers? No, says Corbett. “Though they tended to be faster, they didn’t get the correct answer more than inverters who were actually slightly more accurate.”&lt;/p&gt;
    &lt;p&gt;In short, gamers think they are an inverter or a non-inverter because of how they were first exposed to game controls. Someone who played a lot of flight sims in the 1980s may have unconsciously taught themselves to invert and now they consider that their innate preference; alternatively a gamer who grew up in the 2000s, when non-inverted controls became prevalent may think they are naturally a non-inverter. However, cognitive tests suggest otherwise. It’s much more likely that you invert or don’t invert due to how your brain perceives objects in 3D space.&lt;/p&gt;
    &lt;p&gt;Consequently, Corbett says that it may improve you as a gamer to try the controller setup you are currently not using. “Non-inverters should give inversion a try – and inverters should give non-inversion another shot,” she says. “You might even want to force yourself to stick with it for a few hours. People have learned one way. That doesn’t mean they won’t learn another way even better. A good example is being left-handed. Until the mid-20th century, left-handed children were forced to write with their right hand, causing some people to have lifelong handwriting difficulties and learning problems. Many older adults still don’t realise they’re naturally left-handed and could write/draw much better if they switched back.”&lt;/p&gt;
    &lt;p&gt;Through this research, Corbett and Munneke have established that there are complex and often unconscious cognitive processes involved in how individuals use controllers, and that these may have important ramifications for not just game hardware but for any human-computer interfaces, from aircraft controls to surgical devices. They were able to design a framework for assessing how to best configure controls for any given individual and have now made that available via their research paper.&lt;/p&gt;
    &lt;p&gt;“This work opened our eyes to the huge potential that optimising inversion settings has for advancing human-machine teaming,” says Corbett. “So many technologies are pairing humans with AI and other machines to augment what we can do alone. Understanding how a given individual best performs with a certain setup (controller configuration, screen placement, whether they are trying to hit a target or avoid an obstacle) can allow for much smoother interactions between humans and machines in lots of scenarios from partnering with an AI player to defeat a boss, to preventing damage to delicate internal tissue while performing a complicated laparoscopic surgery.”&lt;/p&gt;
    &lt;p&gt;So what started as an idle, slightly nerdy question has now become a published cognitive research paper. One scientific publication has already cited it and interview requests are pouring in from podcasts and Youtubers. As for my takeaway? “The most surprising finding for gamers [who don’t invert] is that they might perform better if they practised with an inverted control scheme,” says Corbett. “Maybe not, but given our findings, it’s definitely worth a shot because it could dramatically improve competitive game play!”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45317870</guid><pubDate>Sat, 20 Sep 2025 21:46:11 +0000</pubDate></item><item><title>Bazel and Glibc Versions</title><link>https://blogsystem5.substack.com/p/glibc-versions-bazel</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45318140</guid><pubDate>Sat, 20 Sep 2025 22:22:03 +0000</pubDate></item><item><title>Teen Suspect Surrenders in 2023 Las Vegas Casino Cyberattack Case</title><link>https://www.casino.org/news/teen-suspect-surrenders-in-2023-las-vegas-strip-cyberattack-case/</link><description>&lt;doc fingerprint="2b94099be401d024"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Teen Suspect Surrenders in 2023 Las Vegas Casino Cyberattack Case&lt;/head&gt;
    &lt;p&gt;Posted on: September 19, 2025, 07:04h.&lt;/p&gt;
    &lt;p&gt;Last updated on: September 19, 2025, 07:04h.&lt;/p&gt;
    &lt;p&gt;A teenage boy suspected of involvement in the 2023 cyberattacks that disrupted the two largest Las Vegas casino companies has surrendered to authorities, according to the Las Vegas Metropolitan Police Department (LVMPD).&lt;/p&gt;
    &lt;p&gt;The suspect, whose name has not been released due to his status as a minor, is currently being held at the Clark County Juvenile Detention Center.&lt;/p&gt;
    &lt;p&gt;He faces six felony charges:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Three counts of obtaining and using personal identifying information to harm or impersonate another person&lt;/item&gt;
      &lt;item&gt;One count of extortion&lt;/item&gt;
      &lt;item&gt;One count of conspiracy to commit extortion&lt;/item&gt;
      &lt;item&gt;One count of unlawful acts regarding computers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;According to police, prosecutors from the Clark County District Attorney’s Office seek to transfer his case to the criminal division, where he would face the charges as an adult.&lt;/p&gt;
    &lt;p&gt;The arrest stems from a broader investigation led by the FBI’s Las Vegas Cyber Task Force, which includes LVMPD cyber investigators. In November 2024, federal prosecutors indicted four men, aged 20 to 23, in connection with similar cyber attacks, though those charges were not formally linked to the MGM and Caesars incidents.&lt;/p&gt;
    &lt;p&gt;LVMPD’s latest statement did not name MGM Resorts International or Caesars Entertainment directly, instead referring to “multiple Las Vegas casino properties” targeted between August and October 2023.&lt;/p&gt;
    &lt;p&gt;Cybersecurity experts have attributed the attacks to a loosely organized hacker group known as Scattered Spider, which also operates under aliases such as Octo Tempest, UNC3944 and 0ktapus3.&lt;/p&gt;
    &lt;p&gt;MGM reportedly refused to pay a ransom, resulting in an estimated $100 million in losses and roughly 10 days of system outages affecting reservations, slot machines, room keys and websites. Caesars, in contrast, was reported by the Wall street Journal to have paid $15 million of a $30 million ransom demand and experienced less operational disruption.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45318559</guid><pubDate>Sat, 20 Sep 2025 23:29:57 +0000</pubDate></item><item><title>AI and surveillance capitalism are undermining democracy</title><link>https://thebulletin.org/2025/08/how-ai-and-surveillance-capitalism-are-undermining-democracy/</link><description>&lt;doc fingerprint="ae9a115418e1159d"&gt;
  &lt;main&gt;
    &lt;p&gt;By Suresh Venkatasubramanian | August 21, 2025&lt;/p&gt;
    &lt;p&gt;On March 6, 2025, Axios reported that the State Department had launched a new social media surveillance program called “Catch and Revoke.” The intended goal of this program was to use artificial intelligence to assist in reviewing “tens of thousands of student visa holders’ social media footprints” to find “evidence of alleged terrorist sympathies expressed after Hamas’ attack on Israel.”&lt;/p&gt;
    &lt;p&gt;Whether you find this a horrifying development, an exciting application of AI, a flagrant violation of First Amendment rights, or even just a headscratcher, this incident captures the dynamics of how artificial intelligence, surveillance, and threats to democracy all come together. In a nutshell: AI’s promise of behavior prediction and control fuels a vicious cycle of surveillance which inevitably triggers abuses of power.&lt;/p&gt;
    &lt;p&gt;Throughout history, humans have always searched for ways to predict (and control) behavior, whether this constituted consulting an oracle, throwing bones, reading tea leaves, or even examining the shape of a person’s face and body to determine personality traits (which seems awfully contemporary if you start diving into the literature on “emotion AI”). As people became more adept at collecting data of various kinds, the field of statistics emerged to aid them in using data for prediction. (One of the amusing facts about AI research is that virtually every debate one encounters about the appropriate use of artificial intelligence in some social setting has parallels in history, often much earlier, which make it clear that efforts to predict and control behavior was never about AI at all.)&lt;/p&gt;
    &lt;p&gt;The problem with using data to make predictions is that the process can be used as a weapon against society, threatening democratic values. As the lines between private and public data are blurred in modern society, many won’t realize that their private lives are becoming data points used to make decisions about them. AI has supercharged these capabilities, smoothing out people’s individuality and instead placing each person into a group that’s deemed to behave a certain way. And while data and AI can be used for good, the only way these beneficial outcomes can be achieved is with restrictive, well-designed controls to prevent damage to democracy, much like humans did with nuclear energy.&lt;/p&gt;
    &lt;p&gt;The AI move. The statistics/big data/machine learning/data science move was to marry the core techniques for behavior prediction with computational magic and vast amounts of new kinds of data. This could all be translated into the high-dimensional vector representations that machine learning algorithms chewed up and spit out. These algorithms are masterful at finding patterns in data and using those patterns to make predictions about the future. As techniques for learning patterns from data became more complex, spawning an entire zoo of methods—supervised, unsupervised, semi-supervised, online, reinforced—the nature of the data and the kind of prediction being called for became less important than the magic box in the middle used to make the extrapolation. Humans had decontextualized the problem of prediction.&lt;/p&gt;
    &lt;p&gt;Finding patterns that purport to predict how people behave is only the first step. The “AI for good” impulse surfaces quickly here: If those in charge can predict how people behave in different circumstances, maybe they can help them be their best selves. If experts can predict who is likely to have bad financial habits, maybe they can direct more education their way, or nudge them into better practices. If educators can predict which students are going to struggle in school, maybe they can direct more resources to help them. A recent article on AI and wellness in Marie Claire exemplifies this sentiment: What if, with the aid of AI, “your watch could not only detect diseases and health issues before they arise but also communicate directly with our doctors to flag us for treatment? What if it could speak with the rest of your gadgets in real time, and optimize your environment so your bedroom was primed for your most restful sleep, keep your refrigerator full with the food your body actually needs and your home fitness equipment calibrated to give you the most effective workout for your energy level? What if, with the help of AI, your entire living environment could be so streamlined that you were immersed in the exact kind of wellness your body and mind needed at any given moment, without ever lifting a finger?”&lt;/p&gt;
    &lt;p&gt;What makes AI prediction both powerful and lucrative is being able to control what happens next. If a bank can claim to predict what people will do with a loan, it can use that to decide whether they should get one. If an admissions officer can claim to predict how students will perform in college, they can use that to decide which students to admit.&lt;/p&gt;
    &lt;p&gt;The data trade. Once people use AI to “know” something about themselves, someone will sell that information to someone else who not only wants to “know” something about a person or a group of people but to elicit a specific behavior from that person or those persons that can emerge from that knowledge.&lt;/p&gt;
    &lt;p&gt;Experts have commented copiously on this dynamic—of data collection for the sole purpose of fueling an entire economic enterprise of data trading—most prominently under the umbrella term “surveillance capitalism.” What AI does is make this a surveillance ratchet, a device that only goes in one direction, which goes something like this: To make the inferences I want to make to learn more about you, I must collect more data on you. For my AI tools to run, I need data about a lot of you. And once I’ve collected this data, I can monetize it by selling it to others who want to use AI to make other inferences about you. AI creates a demand for data but also becomes the result of collecting data.&lt;/p&gt;
    &lt;p&gt;Here’s the problem with being awash in data and inferences: It never stays limited to any innocent or well-intentioned purpose. It almost immediately becomes a tempting weapon for those who want to wield power over a society, with or without consent from the people in that society. And that’s where the biggest threats to democracy and democratic governance come from.&lt;/p&gt;
    &lt;p&gt;Blurred lines. I view democracy expansively. If society believes in government by, for, and of the people, its members must be comfortable expressing themselves in public, being themselves in private, and having clear lines between the two spheres of activity. As countless scholars have warned us, there are serious implications for society when these lines get blurred.&lt;/p&gt;
    &lt;p&gt;But this is exactly what AI-driven surveillance does. There are many spheres of life that people assumed were private or were promised to be private, but because of AI-driven surveillance have been thrust into the public sphere—with serious consequences. In a post-Dobbs regime, menstrual data trackers are now used for the legal pursuit of abortion seekers. In fact, earlier this month, a jury found that “Meta violated the California Invasion of Privacy Act when it intentionally recorded the sensitive health information of millions of women through the period tracking app Flo.” In their pursuit of deportation targets, ICE is now using people’s most private medical and financial information shared with the government with the promise of privacy protection. Amazon’s Echo devices have been subject to warrants for the audio recordings made by the device inside our homes—recordings that were made even when the people present weren’t talking directly to the device. (In my house we have loud and enthusiastic political discussions and have disconnected our Echo entirely for fear of our statements being misconstrued later on.)&lt;/p&gt;
    &lt;p&gt;Things people once thought were private are no longer kept in the private domain. In addition, there are the things people knew were public—sort of—but never imagined would be taken out of context and weaponized. Amazon’s Ring doorbells face outward, looking at our streets, our neighbors, and everyone who comes to our door. People may have no expectation of privacy out in public, but would they expect the police to commandeer the video feed from a neighbor’s doorbell to judge the degree of threateningness if they were to wave their hands wildly in an animated discussion about their lawn or an incident in our neighborhood? That’s what Ring’s new—and old—CEO wants to do with the now-ubiquitous doorbells.&lt;/p&gt;
    &lt;p&gt;Social media feeds are certainly not private. But people have their own style and personality in how they post, and the most common social media blowup is when someone re-sends another person’s post out of context and causes an internet pile on. Now what happens if that out-of-context post is processed by AI to determine if the person reposting is a terrorist sympathizer, as the State department is now proposing to do? And what if those posts are now combined with surveillance footage from a Ring camera as a person marches down the street as part of a protest that is now interpreted as being sympathetic to a terrorist organization? What is public is now surveilled, and what is private is now public.&lt;/p&gt;
    &lt;p&gt;Homogenizing behavior. There is an argument put forward to defend the use of AI in surveillance. It goes like this: “These systems of surveillance are bad because they are inaccurate, and AI will fix that.” This has been a common line of reasoning made in the facial recognition debates, where early criticism of these systems centered on their inability to recognize darker skin tones or facial characteristics that aren’t male and White. The problem is that AI won’t fix this. The predictions made by AI systems about our likely future behavior are by design built from patterns of behavior seen across many people. As such, any claims of accuracy don’t mean “we know how you, Suresh, are likely to behave in this scenario.” They mean “we have decided that you, Suresh, are a member of this class of individuals that on average behaves this way.”&lt;/p&gt;
    &lt;p&gt;This smoothing out of our individuality, our quirks, and our unique tendencies to react to stimuli around us is antithetical to the idea of democracy as a celebration of originality. It’s a chilling causal reversal. It’s not taking our individual expressions of freedom and finding some common ground; it’s removing all the things that make us unique and different for the purpose of prediction and control. And this is by design, and not an accident.&lt;/p&gt;
    &lt;p&gt;The desire to surveil is bipartisan. It’s about power, not party politics. This seems hard to accept eight months into the current administration, which has run roughshod over any and all protections against rampant surveillance, data collection, and AI (mis)use that it can find. But the temptation to collect data and then use it for surveillance is extremely strong, even more so inside government, where so much data is collected just as a matter of course, and people trust (or are forced to trust) government agencies to handle some of their most private financial and personal data.&lt;/p&gt;
    &lt;p&gt;Devising controls. This situation presents a very difficult conundrum for those of us (myself included) who want to hold out hope that society can in fact use AI and data for good and believe that people just need the right guardrails in place to do so. The ease with which the rule of law can be flouted, protections can be destroyed, and data can be abused in the service of power raises a huge question about the risk of any data collection and use, even if there was a benign purpose to begin with.&lt;/p&gt;
    &lt;p&gt;I don’t yet have a good answer to the question I have raised. But I will leave you, the readers of the Bulletin, with an image that harkens back to the founding of this publication. AI development is framed by countries around the world as an “arms race.” Good use cases of AI easily, and frequently do, turn to bad. The production of AI systems requires huge amounts of data collection and energy use. The inferences and insights generated by these AI systems can be downright dangerous in the wrong hands. All of this makes AI feel not a small bit like nuclear energy—radioactive, dangerous, and, yes, sometimes useful. The only way humans have been able to harness nuclear energy is with restrictive, well-designed controls, and while these might have limited some potential commercial opportunities, it has on balance helped keep the world safer and freer than without. I see no way for us to continue using AI without similarly restrictive, well-designed controls to prevent damage to our democracy and society and preserve its freedom and liberty.&lt;/p&gt;
    &lt;p&gt;Editor’s note: This piece was produced with support from the Future of Life Institute.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;The Bulletin elevates expert voices above the noise. But as an independent nonprofit organization, our operations depend on the support of readers like you. Help us continue to deliver quality journalism that holds leaders accountable. Your support of our work at any level is important. In return, we promise our coverage will be understandable, influential, vigilant, solution-oriented, and fair-minded. Together we can make a difference.&lt;/p&gt;
    &lt;p&gt;Keywords: AI, artificial intelligence, data, democracy, energy, nuclear energy, prediction, surveillance&lt;lb/&gt; Topics: Artificial Intelligence, Disruptive Technologies&lt;/p&gt;
    &lt;p&gt;The other thing ai can now start to do, is to de-anonymize our data.Things that you assume are not linkable to you personally are now increasingly within reach of being linked with high statistical probability in hundreds of ways.&lt;lb/&gt; So rules like Hipaa, designed to protect our health data, are now inadequate.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=45318863</guid><pubDate>Sun, 21 Sep 2025 00:18:14 +0000</pubDate></item></channel></rss>