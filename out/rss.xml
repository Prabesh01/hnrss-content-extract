<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Hacker News: Front Page</title><link>https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml</link><description>Hacker News RSS</description><atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 25 Dec 2025 16:13:33 +0000</lastBuildDate><item><title>Uplane (YC F25) Is Hiring Founding Engineers (Full-Stack and AI)</title><link>https://www.useparallel.com/uplane1/careers</link><description>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46355932</guid><pubDate>Mon, 22 Dec 2025 17:00:34 +0000</pubDate></item><item><title>Fabrice Bellard Releases MicroQuickJS</title><link>https://github.com/bellard/mquickjs/blob/main/README.md</link><description>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46367224</guid><pubDate>Tue, 23 Dec 2025 17:33:42 +0000</pubDate></item><item><title>Show HN: Vibium â€“ Browser automation for AI and humans, by Selenium's creator</title><link>https://github.com/VibiumDev/vibium</link><description>&lt;doc fingerprint="8d362e50e91db4ee"&gt;
  &lt;main&gt;
    &lt;p&gt;Browser automation without the drama.&lt;/p&gt;
    &lt;p&gt;Vibium is browser automation infrastructure built for AI agents. A single binary handles browser lifecycle, WebDriver BiDi protocol, and exposes an MCP server â€” so Claude Code (or any MCP client) can drive a browser with zero setup. Works great for AI agents, test automation, and anything else that needs a browser.&lt;/p&gt;
    &lt;p&gt;New here? Getting Started Tutorial â€” zero to hello world in 5 minutes.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Interface&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Clicker&lt;/cell&gt;
        &lt;cell&gt;Browser automation, BiDi proxy, MCP server&lt;/cell&gt;
        &lt;cell&gt;CLI / stdio / WebSocket :9515&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;JS Client&lt;/cell&gt;
        &lt;cell&gt;Developer-facing API&lt;/cell&gt;
        &lt;cell&gt;npm package&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LLM / Agent                         â”‚
â”‚          (Claude Code, Codex, Gemini, Local Models)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–²
                      â”‚ MCP Protocol (stdio)
                      â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         
           â”‚   Vibium Clicker    â”‚
           â”‚                     â”‚
           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
           â”‚  â”‚  MCP Server   â”‚  â”‚
           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚          â”‚          â”‚         â”‚                  â”‚
           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”‚WebSocketâ”‚                  â”‚
           â”‚  â”‚  BiDi Proxy   â”‚  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Chrome Browser  â”‚
           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  BiDi   â”‚                  â”‚
           â”‚                     â”‚         â”‚                  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–²
                      â”‚ WebSocket BiDi :9515
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        JS/TS Client                         â”‚
â”‚                     npm install vibium                      â”‚
â”‚                                                             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ Async API       â”‚               â”‚    Sync API     â”‚    â”‚
â”‚    â”‚ await vibe.go() â”‚               â”‚    vibe.go()    â”‚    â”‚
â”‚    â”‚                 â”‚               â”‚                 â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;p&gt;A single Go binary (~10MB) that does everything:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browser Management: Detects/launches Chrome with BiDi enabled&lt;/item&gt;
      &lt;item&gt;BiDi Proxy: WebSocket server that routes commands to browser&lt;/item&gt;
      &lt;item&gt;MCP Server: stdio interface for LLM agents&lt;/item&gt;
      &lt;item&gt;Auto-Wait: Polls for elements before interacting&lt;/item&gt;
      &lt;item&gt;Screenshots: Viewport capture as PNG&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Design goal: The binary is invisible. JS developers just &lt;code&gt;npm install vibium&lt;/code&gt; and it works.&lt;/p&gt;
    &lt;code&gt;// Option 1: require (REPL-friendly)
const { browserSync } = require('vibium')

// Option 2: dynamic import (REPL with --experimental-repl-await)
const { browser } = await import('vibium')

// Option 3: static import (in .mjs or .ts files)
import { browser, browserSync } from 'vibium'&lt;/code&gt;
    &lt;p&gt;Sync API:&lt;/p&gt;
    &lt;code&gt;const fs = require('fs')
const { browserSync } = require('vibium')

const vibe = browserSync.launch()
vibe.go('https://example.com')

const png = vibe.screenshot()
fs.writeFileSync('screenshot.png', png)

const link = vibe.find('a')
link.click()
vibe.quit()&lt;/code&gt;
    &lt;p&gt;Async API:&lt;/p&gt;
    &lt;code&gt;const fs = await import('fs/promises')
const { browser } = await import('vibium')

const vibe = await browser.launch()
await vibe.go('https://example.com')

const png = await vibe.screenshot()
await fs.writeFile('screenshot.png', png)

const link = await vibe.find('a')
await link.click()
await vibe.quit()&lt;/code&gt;
    &lt;p&gt;One command to add browser control to Claude Code:&lt;/p&gt;
    &lt;code&gt;claude mcp add vibium -- npx -y vibium&lt;/code&gt;
    &lt;p&gt;That's it. No manual steps needed. Chrome downloads automatically during setup.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_launch&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Start browser (visible by default)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_navigate&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Go to URL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_find&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Find element by CSS selector&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_click&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Click an element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_type&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Type text into an element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_screenshot&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Capture viewport (base64 or save to file with &lt;code&gt;--screenshot-dir&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;browser_quit&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Close browser&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;npm install vibium&lt;/code&gt;
    &lt;p&gt;This automatically:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Installs the Clicker binary for your platform&lt;/item&gt;
      &lt;item&gt;Downloads Chrome for Testing + chromedriver to platform cache: &lt;list rend="ul"&gt;&lt;item&gt;Linux: &lt;code&gt;~/.cache/vibium/&lt;/code&gt;&lt;/item&gt;&lt;item&gt;macOS: &lt;code&gt;~/Library/Caches/vibium/&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Windows: &lt;code&gt;%LOCALAPPDATA%\vibium\&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Linux: &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;No manual browser setup required.&lt;/p&gt;
    &lt;p&gt;Skip browser download (if you manage browsers separately):&lt;/p&gt;
    &lt;code&gt;VIBIUM_SKIP_BROWSER_DOWNLOAD=1 npm install vibium&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Architecture&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Linux&lt;/cell&gt;
        &lt;cell&gt;x64&lt;/cell&gt;
        &lt;cell&gt;âœ… Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;x64 (Intel)&lt;/cell&gt;
        &lt;cell&gt;âœ… Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;macOS&lt;/cell&gt;
        &lt;cell&gt;arm64 (Apple Silicon)&lt;/cell&gt;
        &lt;cell&gt;âœ… Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows&lt;/cell&gt;
        &lt;cell&gt;x64&lt;/cell&gt;
        &lt;cell&gt;âœ… Supported&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As a library:&lt;/p&gt;
    &lt;code&gt;import { browser } from "vibium";

const vibe = await browser.launch();
await vibe.go("https://example.com");
const el = await vibe.find("a");
await el.click();
await vibe.quit();&lt;/code&gt;
    &lt;p&gt;With Claude Code:&lt;/p&gt;
    &lt;p&gt;Once installed via &lt;code&gt;claude mcp add&lt;/code&gt;, just ask Claude to browse:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Go to example.com and click the first link"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;See CONTRIBUTING.md for development setup and guidelines.&lt;/p&gt;
    &lt;p&gt;V1 focuses on the core loop: browser control via MCP and JS client.&lt;/p&gt;
    &lt;p&gt;See V2-ROADMAP.md for planned features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python and Java clients&lt;/item&gt;
      &lt;item&gt;Cortex (memory/navigation layer)&lt;/item&gt;
      &lt;item&gt;Retina (recording extension)&lt;/item&gt;
      &lt;item&gt;Video recording&lt;/item&gt;
      &lt;item&gt;AI-powered locators&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2025-12-22: Day 12 - Published to npm&lt;/item&gt;
      &lt;item&gt;2025-12-21: Day 11 - Polish &amp;amp; Error Handling&lt;/item&gt;
      &lt;item&gt;2025-12-20: Day 10 - MCP Server&lt;/item&gt;
      &lt;item&gt;2025-12-19: Day 9 - Actionability&lt;/item&gt;
      &lt;item&gt;2025-12-19: Day 8 - Elements &amp;amp; Sync API&lt;/item&gt;
      &lt;item&gt;2025-12-17: Halfway There&lt;/item&gt;
      &lt;item&gt;2025-12-16: Week 1 Progress&lt;/item&gt;
      &lt;item&gt;2025-12-11: V1 Announcement&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Apache 2.0&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46377597</guid><pubDate>Wed, 24 Dec 2025 17:49:02 +0000</pubDate></item><item><title>Fabrice Bellard: Biography (2009) [pdf]</title><link>https://www.ipaidia.gr/wp-content/uploads/2020/12/117-2020-fabrice-bellard.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46377862</guid><pubDate>Wed, 24 Dec 2025 18:17:47 +0000</pubDate></item><item><title>Show HN: Minimalist editor that lives in browser, stores everything in the URL</title><link>https://github.com/antonmedv/textarea</link><description>&lt;doc fingerprint="2a34105e063698ad"&gt;
  &lt;main&gt;
    &lt;p&gt;A minimalist text editor that lives entirely in your browser and stores everything in the URL hash.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ“ It's a textarea! Actually not.&lt;/item&gt;
      &lt;item&gt;ğŸ—œï¸ Compression magic - Your text gets compressed with deflate because we're fancy like that&lt;/item&gt;
      &lt;item&gt;ğŸ”— URL storage - Share your notes by copying a 500-character URL. Your friends will love it!&lt;/item&gt;
      &lt;item&gt;ğŸŒ“ Dark mode - Respects your poor eyes and your color scheme preference&lt;/item&gt;
      &lt;item&gt;ğŸ’¾ Auto-save - Debounced to 500ms because we're not savages&lt;/item&gt;
      &lt;item&gt;ğŸ“± Mobile friendly - Type your manifesto on the go&lt;/item&gt;
      &lt;item&gt;ğŸ¯ No backend - Zero servers were harmed in the making of this app&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open textarea.my&lt;/item&gt;
      &lt;item&gt;Type stuff&lt;/item&gt;
      &lt;item&gt;Marvel at the URL getting longer&lt;/item&gt;
      &lt;item&gt;Try to share it&lt;/item&gt;
      &lt;item&gt;...&lt;/item&gt;
      &lt;item&gt;Profit&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start your document with &lt;code&gt;# Title&lt;/code&gt;to set a custom page title&lt;/item&gt;
      &lt;item&gt;Your data lives in localStorage AND the URL. Double the fun!&lt;/item&gt;
      &lt;item&gt;Feeling fancy? Add a &lt;code&gt;style&lt;/code&gt;attribute to the&lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt;tag via DevTools. It'll be saved in the URL too!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made with â¤ï¸ and JavaScript&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46378554</guid><pubDate>Wed, 24 Dec 2025 19:42:25 +0000</pubDate></item><item><title>Keystone (YC S25) is hiring engineer #1 to automate coding</title><link>https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer</link><description>&lt;doc fingerprint="a3b096f07e6fa468"&gt;
  &lt;main&gt;
    &lt;p&gt;Your team's on-call AI engineer&lt;/p&gt;
    &lt;p&gt;About Keystone&lt;/p&gt;
    &lt;p&gt;We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.&lt;/p&gt;
    &lt;p&gt;We're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.&lt;/p&gt;
    &lt;p&gt;We're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.&lt;/p&gt;
    &lt;p&gt;About the Role&lt;/p&gt;
    &lt;p&gt;You'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.&lt;/p&gt;
    &lt;p&gt;Example projects:&lt;/p&gt;
    &lt;p&gt;You might be a great fit if you:&lt;/p&gt;
    &lt;p&gt;Stack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS&lt;/p&gt;
    &lt;p&gt;Comp &amp;amp; benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget&lt;/p&gt;
    &lt;p&gt;If there appears to be a fit, we'll reach to schedule 2-3 short technicals. After, we'll schedule an onsite in our office, where you'll work on a small project, discuss ideas, and get a sense for our in-person culture.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46379173</guid><pubDate>Wed, 24 Dec 2025 21:01:05 +0000</pubDate></item><item><title>Nvidia to buy assets from Groq for $20B cash</title><link>https://www.cnbc.com/2025/12/24/nvidia-buying-ai-chip-startup-groq-for-about-20-billion-biggest-deal.html</link><description>&lt;doc fingerprint="22d081694f3ed1b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Nvidia has agreed to buy assets from Groq, a designer of high-performance artificial intelligence accelerator chips, for $20 billion in cash, according to Alex Davis, CEO of Disruptive, which led the startup's latest financing round in September.&lt;/p&gt;
    &lt;p&gt;Davis, whose firm has invested more than half a billion dollars in Groq since the company was founded in 2016, said the deal came together quickly. Groq raised $750 million at a valuation of about $6.9 billion three months ago. Investors in the round included Blackrock and Neuberger Berman, as well as Samsung, Cisco, Altimeter and 1789 Capital, where Donald Trump Jr. is a partner.&lt;/p&gt;
    &lt;p&gt;Groq said in a blog post on Wednesday that it's "entered into a non-exclusive licensing agreement with Nvidia for Groq's inference technology," without disclosing a price. With the deal, Groq founder and CEO Jonathan Ross along with Sunny Madra, the company's president, and other senior leaders "will join Nvidia to help advance and scale the licensed technology," the post said.&lt;/p&gt;
    &lt;p&gt;Groq added that it will continue as an "independent company," led by finance chief Simon Edwards as CEO.&lt;/p&gt;
    &lt;p&gt;Colette Kress, Nvidia's CFO, declined comment on the transaction.&lt;/p&gt;
    &lt;p&gt;Davis told CNBC that Nvidia is getting all of Groq's assets, though its nascent Groq cloud business is not part of the transaction. Groq said, "GroqCloud will continue to operate without interruption."&lt;/p&gt;
    &lt;p&gt;The deal represents by far Nvidia's largest purchase ever. The chipmaker's biggest acquisition to date came in 2019, when it bought Israeli chip designer Mellanox for close to $7 billion. At the end of October, Nvidia had $60.6 billion in cash and short-term investments, up from $13.3 billion in early 2023.&lt;/p&gt;
    &lt;p&gt;In an email to employees that was obtained by CNBC, Nvidia CEO Jensen Huang said the agreement will expand Nvidia's capabilities.&lt;/p&gt;
    &lt;p&gt;"We plan to integrate Groq's low-latency processors into the NVIDIA AI factory architecture, extending the platform to serve an even broader range of AI inference and real-time workloads," Huang wrote.&lt;/p&gt;
    &lt;p&gt;Huang added that, "While we are adding talented employees to our ranks and licensing Groq's IP, we are not acquiring Groq as a company."&lt;/p&gt;
    &lt;p&gt;Nvidia orchestrated a similar but smaller deal in September, when it shelled out over $900 million to hire Enfabrica CEO Rochan Sankar and other employees at the AI hardware startup, and to license the company's technology, CNBC reported at the time.&lt;/p&gt;
    &lt;p&gt;Other tech giants, including Meta, Google and Microsoft, have spent heavily over the last couple years to hire top AI talent through various types of licensing deals.&lt;/p&gt;
    &lt;p&gt;Nvidia has ramped up its investments in chip startups and the broader ecosystem as its cash pile has mounted. The company has backed AI and energy infrastructure company Crusoe, AI model developer Cohere, and boosted its investment in CoreWeave as the AI-centric cloud provider was getting ready to go public this year.&lt;/p&gt;
    &lt;p&gt;In September, Nvidia said it intended to invest up to $100 billion in OpenAI, with the startup committed to deploying at least 10 gigawatts of Nvidia products. The companies have yet to announce a formal deal. That same month, Nvidia said it would invest $5 billion in Intel as part of a partnership.&lt;/p&gt;
    &lt;p&gt;Groq has been targeting revenue of $500 million this year amid booming demand for AI accelerator chips used in speeding up the process for large language models to complete inference-related tasks. The company was not pursuing a sale when it was approached by Nvidia, Davis said.&lt;/p&gt;
    &lt;p&gt;Groq was founded in 2016 by a group of former engineers, including Ross. He was one of the creators of Google's tensor processing unit, or TPU, the search giant's custom chip that's being used by some companies as an alternative to Nvidia's graphics processing units.&lt;/p&gt;
    &lt;p&gt;In its initial filing with the SEC, announcing a $10.3 million fundraising in late 2016, Groq listed as principals Ross and Douglas Wightman, an entrepreneur and former engineer at the Google X "moonshot factory." Wightman left Groq in 2019, according to his LinkedIn profile.&lt;/p&gt;
    &lt;p&gt;Groq isn't the only chip startup that's gained traction during the AI boom.&lt;/p&gt;
    &lt;p&gt;AI chipmaker Cerebras Systems had planned to go public this year but withdrew its IPO filing in October after announcing that it raised over $1 billion in a fundraising round.&lt;/p&gt;
    &lt;p&gt;In a filing with the SEC, Cerebras said it does not intend to conduct a proposed offering "at this time," but didn't provide a reason. A spokesperson told CNBC at the time that the company still hopes to go public as soon as possible.&lt;/p&gt;
    &lt;p&gt;Cerebras filed for an IPO in late 2024, as it was ramping up to take on Nvidia in an effort to create processors for running generative AI models.&lt;/p&gt;
    &lt;p&gt;â€” CNBC's Jordan Novet contributed to this report.&lt;/p&gt;
    &lt;p&gt;WATCH: How the massive power draw of generative AI is overtaxing our grid&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46379183</guid><pubDate>Wed, 24 Dec 2025 21:02:15 +0000</pubDate></item><item><title>Phoenix: A modern X server written from scratch in Zig</title><link>https://git.dec05eba.com/phoenix/about/</link><description>&lt;doc fingerprint="d47bdcdd7826ad85"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Phoenix&lt;/head&gt;
    &lt;p&gt;Phoenix is a new X server, written from scratch in Zig (not a fork of Xorg server). This X server is designed to be a modern alternative to the Xorg server.&lt;/p&gt;
    &lt;head rend="h2"&gt;Current state&lt;/head&gt;
    &lt;p&gt;Phoenix is not ready to be used yet. At the moment it can render simple applications that do GLX, EGL or Vulkan graphics (fully hardware accelerated) nested in an existing X server. Running Phoenix nested will be the only supported mode until Phoenix has progressed more and can run real-world applications.&lt;/p&gt;
    &lt;head rend="h2"&gt;Goals&lt;/head&gt;
    &lt;head rend="h3"&gt;Simplicity&lt;/head&gt;
    &lt;p&gt;Be a simpler X server than the Xorg server by only supporting a subset of the X11 protocol, the features that are needed by relatively modern applications (applications written/updated in the last ~20 years).&lt;lb/&gt; This includes all software that you use, even old gtk2 applications.&lt;lb/&gt; Only relatively modern hardware (made/updated in the last ~15-20 years) which support linux drm and mesa gbm will be supported, and no server driver interface like the Xorg server. Just like how Wayland compositors work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Security&lt;/head&gt;
    &lt;p&gt;Be safer than the Xorg server by parsing protocol messages automatically. As it's written in Zig, it also automatically catches illegal behaviors (such as index out of array bounds) when building with the &lt;code&gt;ReleaseSafe&lt;/code&gt; option.&lt;/p&gt;
    &lt;p&gt;Applications will be isolated from each other by default and can only interact with other applications either through a GUI prompt asking for permission,&lt;lb/&gt; such as with screen recorders, where it will only be allowed to record the window specified or by explicitly giving the application permission before launched (such as a window manager or external compositor).&lt;lb/&gt; This will not break existing clients as clients wont receive errors when they try to access more than they need, they will instead receive dummy data.&lt;lb/&gt; Applications that rely on global hotkeys should work, as long as a modifier key is pressed (keys such as ctrl, shift, alt and super).&lt;lb/&gt; If an application needs global hotkeys without pressing a modifier key then it needs to be given permissions to do so (perhaps by adding a command to run a program with more X11 permissions).&lt;lb/&gt; There will be an option to disable this to make the X server behave like the Xorg server.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improvements for modern technology&lt;/head&gt;
    &lt;p&gt;Support modern hardware better than the Xorg server, such as proper support for multiple monitors (different refresh rates, VRR - not a single framebuffer for the whole collection of displays) and technology like HDR.&lt;/p&gt;
    &lt;head rend="h3"&gt;Improved graphics handling&lt;/head&gt;
    &lt;p&gt;No tearing by default and a built-in compositor. The compositor will get disabled if the user runs an external compositor (client application), such as picom or if the client runs a fullscreen application and disabled vsync in the application.&lt;lb/&gt; The goal is to also have lower vsync/compositor latency than the Xorg server.&lt;/p&gt;
    &lt;head rend="h3"&gt;New standards&lt;/head&gt;
    &lt;p&gt;New standards will be developed and documented, such as per-monitor DPI as randr properties. Applications can use this property to scale their content to the specified DPI for the monitor they are on.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extending the X11 protocol&lt;/head&gt;
    &lt;p&gt;If there is a need for new features (such as HDR) then the X11 protocol will be extended.&lt;/p&gt;
    &lt;head rend="h3"&gt;Wayland compatibility&lt;/head&gt;
    &lt;p&gt;Some applications might only run on Wayland in the future. Such applications should be supported by either Phoenix supporting Wayland natively or by running an external application that works as a bridge between Wayland and X11 (such as 12to11).&lt;/p&gt;
    &lt;head rend="h3"&gt;Nested display server&lt;/head&gt;
    &lt;p&gt;Being able to run Phoenix nested under X11 or Wayland with hardware acceleration. This is not only useful for debugging Phoenix but also for developers who want to test their window manager or compositor without restarting the display server they are running.&lt;lb/&gt; Being able to run Phoenix under Wayland as an alternative Xwayland server would be a good option.&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-goals&lt;/head&gt;
    &lt;head rend="h3"&gt;Replacing the Xorg server&lt;/head&gt;
    &lt;p&gt;The Xorg server will always support more features of the X11 protocol and wider range of hardware (especially older ones).&lt;/p&gt;
    &lt;head rend="h3"&gt;Multiple screens&lt;/head&gt;
    &lt;p&gt;Multiple displays (monitors) are going to be supported but not X11 screens.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exclusive access&lt;/head&gt;
    &lt;p&gt;GrabServer has no effect in Phoenix.&lt;/p&gt;
    &lt;head rend="h3"&gt;Endian-swapped client/server&lt;/head&gt;
    &lt;p&gt;This can be reconsidered if there is a reason.&lt;/p&gt;
    &lt;head rend="h3"&gt;Indirect (remote) GLX.&lt;/head&gt;
    &lt;p&gt;This is very complex as there are a lot of functions that would need to be implemented. These days remote streaming options are more efficient. Alternatively a proxy for glx could be implemented that does remote rendering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Differences between the X11 protocol and Phoenix&lt;/head&gt;
    &lt;head rend="h3"&gt;Core protocol&lt;/head&gt;
    &lt;p&gt;Several parts of the X11 protocol (core) are mandatory to be implemented by an X server, such as many font related operations.&lt;lb/&gt; However these are not going to be implemented in Phoenix, except for the simple ones that applications actually use (such as font operations used for cursors).&lt;lb/&gt; This will not affect applications that users actually use, even if they use old gtk2 applications.&lt;/p&gt;
    &lt;head rend="h3"&gt;Strings&lt;/head&gt;
    &lt;p&gt;Strings are in ISO Latin-1 encoding in the X11 protocol unless specified otherwise, however in Phoenix all strings are UTF-8 unless the protocol states that it's not an ISO Latin-1 string.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing&lt;/head&gt;
    &lt;p&gt;Run:&lt;/p&gt;
    &lt;code&gt;zig build -Doptimize=ReleaseSafe
sudo zig build install -p /usr/local -Doptimize=ReleaseSafe
&lt;/code&gt;
    &lt;head rend="h2"&gt;Uninstalling&lt;/head&gt;
    &lt;p&gt;Zig does currently not support the uninstall command so you have to remove files manually:&lt;/p&gt;
    &lt;code&gt;sudo rm /usr/local/bin/phoenix
&lt;/code&gt;
    &lt;head rend="h2"&gt;Building (for development)&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;zig build&lt;/code&gt;, which builds Phoenix in debug mode. The compiled binary will be available at &lt;code&gt;./zig-out/bin/phoenix&lt;/code&gt;. You can alternatively build and run with one command: &lt;code&gt;zig build run&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Generate x11 protocol documentation&lt;/head&gt;
    &lt;p&gt;Run &lt;code&gt;zig build -Dgenerate-docs=true&lt;/code&gt;. This will generate &lt;code&gt;.txt&lt;/code&gt; files in &lt;code&gt;./zig-out/protocol/&lt;/code&gt;. This generates x11 protocol documentation in the style of the official protocol documentation. The documentation is automatically generated from the protocol struct code.
Note that the generated documentation feature is a work-in-progress.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dependencies&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Zig 0.14.1&lt;/item&gt;
      &lt;item&gt;x11 (&lt;code&gt;xcb&lt;/code&gt;) - for nested mode under X11, when building Phoenix with&lt;code&gt;-Dbackends=x11&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;wayland (&lt;code&gt;wayland-client&lt;/code&gt;,&lt;code&gt;wayland-egl&lt;/code&gt;) - for nested mode under Wayland, when building Phoenix with&lt;code&gt;-Dbackends=wayland&lt;/code&gt;(not currently supported)&lt;/item&gt;
      &lt;item&gt;drm (&lt;code&gt;libdrm&lt;/code&gt;,&lt;code&gt;gbm&lt;/code&gt;) - for running Phoenix as a standalone X11 server, when building Phoenix with&lt;code&gt;-Dbackends=drm&lt;/code&gt;(not currently supported)&lt;/item&gt;
      &lt;item&gt;OpenGL (&lt;code&gt;libglvnd&lt;/code&gt;which provides both&lt;code&gt;gl&lt;/code&gt;and&lt;code&gt;egl&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;FAQ&lt;/head&gt;
    &lt;head rend="h3"&gt;Isn't it easier to write a Wayland compositor?&lt;/head&gt;
    &lt;p&gt;Despite popular belief, writing a simple X server that works in practice for a wide range of applications is easier to do than it is to write a Wayland compositor (+ related software).&lt;lb/&gt; Not many people have attempted to write an X server from scratch or have proper understanding of the protocol, but if you do you can see that it's quite simple.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380075</guid><pubDate>Wed, 24 Dec 2025 22:43:53 +0000</pubDate></item><item><title>Tell HN: Merry Christmas</title><link>https://news.ycombinator.com/item?id=46380168</link><description>&lt;doc fingerprint="3d2d13d459cf20bd"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Different cultures celebrate Christmas at different days and time zones are a thing. But it's Christmas here, so:&lt;/p&gt;
      &lt;p&gt;Merry Christmas to everyone. I hope you get some rest and can spend time with people who are dear to you and get to focus on what's important rather than getting lost in stressing about everything having to be perfect.&lt;/p&gt;
      &lt;p&gt;Also much love to everyone who cannot spend their Christmas with dear people.&lt;/p&gt;
      &lt;p&gt;To make sure this post meets the relevancy criteria, here is a Wikipedia article about some Christmas (more precisely advent) tradition which I personally really like: https://en.wikipedia.org/wiki/Christmas_market&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380168</guid><pubDate>Wed, 24 Dec 2025 22:56:00 +0000</pubDate></item><item><title>Asterisk AI Voice Agent</title><link>https://github.com/hkjarral/Asterisk-AI-Voice-Agent</link><description>&lt;doc fingerprint="2c0ef1107fb2aeaa"&gt;
  &lt;main&gt;
    &lt;p&gt;The most powerful, flexible open-source AI voice agent for Asterisk/FreePBX. Featuring a modular pipeline architecture that lets you mix and match STT, LLM, and TTS providers, plus 5 production-ready golden baselines validated for enterprise deployment.&lt;/p&gt;
    &lt;p&gt;Quick Start â€¢ Features â€¢ Demo â€¢ Documentation â€¢ Community&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸš€ Quick Start&lt;/item&gt;
      &lt;item&gt;ğŸ‰ What's New&lt;/item&gt;
      &lt;item&gt;ğŸŒŸ Why Asterisk AI Voice Agent?&lt;/item&gt;
      &lt;item&gt;âœ¨ Features&lt;/item&gt;
      &lt;item&gt;ğŸ¥ Demo&lt;/item&gt;
      &lt;item&gt;ğŸ› ï¸ AI-Powered Actions&lt;/item&gt;
      &lt;item&gt;ğŸ©º Agent CLI Tools&lt;/item&gt;
      &lt;item&gt;âš™ï¸ Configuration&lt;/item&gt;
      &lt;item&gt;ğŸ—ï¸ Project Architecture&lt;/item&gt;
      &lt;item&gt;ğŸ“Š Requirements&lt;/item&gt;
      &lt;item&gt;ğŸ—ºï¸ Documentation&lt;/item&gt;
      &lt;item&gt;ğŸ¤ Contributing&lt;/item&gt;
      &lt;item&gt;ğŸ’¬ Community&lt;/item&gt;
      &lt;item&gt;ğŸ“ License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get the Admin UI running in 2 minutes.&lt;/p&gt;
    &lt;p&gt;For a complete first successful call walkthrough (dialplan + transport selection + verification), see:&lt;/p&gt;
    &lt;code&gt;# Clone repository
git clone https://github.com/hkjarral/Asterisk-AI-Voice-Agent.git
cd Asterisk-AI-Voice-Agent

# Run preflight with auto-fix (creates .env, generates JWT_SECRET)
sudo ./preflight.sh --apply-fixes&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Important: Preflight creates your&lt;/p&gt;&lt;code&gt;.env&lt;/code&gt;file and generates a secure&lt;code&gt;JWT_SECRET&lt;/code&gt;. Always run this first!&lt;/quote&gt;
    &lt;code&gt;# Start the Admin UI container
docker compose up -d --build admin-ui&lt;/code&gt;
    &lt;p&gt;Open in your browser:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local: &lt;code&gt;http://localhost:3003&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Remote server: &lt;code&gt;http://&amp;lt;server-ip&amp;gt;:3003&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Default Login: &lt;code&gt;admin&lt;/code&gt; / &lt;code&gt;admin&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;Follow the Setup Wizard to configure your providers and make a test call.&lt;/p&gt;
    &lt;quote&gt;&lt;g-emoji&gt;âš ï¸&lt;/g-emoji&gt;Security: The Admin UI is accessible on the network. Change the default password immediately and restrict port 3003 via firewall, VPN, or reverse proxy for production use.&lt;/quote&gt;
    &lt;code&gt;# Start ai-engine (required for health checks)
docker compose up -d --build ai-engine

# Check ai-engine health
curl http://localhost:15000/health
# Expected: {"status":"healthy"}

# View logs for any errors
docker compose logs ai-engine | tail -20&lt;/code&gt;
    &lt;p&gt;The wizard will generate the necessary dialplan configuration for your Asterisk server.&lt;/p&gt;
    &lt;p&gt;Transport selection is configuration-dependent (not strictly â€œpipelines vs full agentsâ€). Use the validated matrix in:&lt;/p&gt;
    &lt;p&gt;For users who prefer the command line or need headless setup.&lt;/p&gt;
    &lt;code&gt;./install.sh
agent quickstart&lt;/code&gt;
    &lt;code&gt;# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Start services
docker compose up -d&lt;/code&gt;
    &lt;p&gt;Add this to your FreePBX (&lt;code&gt;extensions_custom.conf&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;[from-ai-agent]
exten =&amp;gt; s,1,NoOp(Asterisk AI Voice Agent v4.5.3)
 same =&amp;gt; n,Stasis(asterisk-ai-voice-agent)
 same =&amp;gt; n,Hangup()
&lt;/code&gt;
    &lt;p&gt;Health check:&lt;/p&gt;
    &lt;code&gt;agent doctor&lt;/code&gt;
    &lt;p&gt;View logs:&lt;/p&gt;
    &lt;code&gt;docker compose logs -f ai-engine&lt;/code&gt;
    &lt;head&gt;Latest Updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full Call Logging: Every call saved with conversation history, timing, and outcome&lt;/item&gt;
      &lt;item&gt;Per-Call Debugging: Review transcripts, tool executions, and errors from Admin UI&lt;/item&gt;
      &lt;item&gt;Search &amp;amp; Filter: Find calls by caller, provider, context, or date range&lt;/item&gt;
      &lt;item&gt;Export: Download call data as CSV or JSON&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Immediate Interruption: Agent audio stops instantly when caller speaks&lt;/item&gt;
      &lt;item&gt;Provider-Owned Turn-Taking: Full agents (Google, Deepgram, OpenAI, ElevenLabs) handle VAD natively&lt;/item&gt;
      &lt;item&gt;Platform Flush: Local playback clears immediately on interruption signal&lt;/item&gt;
      &lt;item&gt;Transport Parity: Works with both ExternalMedia RTP and AudioSocket&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Faster Whisper: High-accuracy STT backend with GPU acceleration&lt;/item&gt;
      &lt;item&gt;MeloTTS: New neural TTS option for local pipelines&lt;/item&gt;
      &lt;item&gt;Model Hot-Swap: Switch models via Dashboard without container restart&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;External Tools Framework: Connect AI agents to external services via Model Context Protocol&lt;/item&gt;
      &lt;item&gt;Admin UI Config: Configure MCP servers from the web interface&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Remote Endpoint Pinning: Lock RTP streams to prevent audio hijacking&lt;/item&gt;
      &lt;item&gt;Allowlist Support: Restrict allowed remote hosts for ExternalMedia&lt;/item&gt;
      &lt;item&gt;Cross-Talk Prevention: SSRC-based routing ensures call isolation&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;local_hybrid&lt;/code&gt;Default: Privacy-focused pipeline is now the out-of-box default&lt;/item&gt;
      &lt;item&gt;Pipeline-Aware Readiness: Health probes correctly reflect pipeline component status&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;Previous Versions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸŒ Pre-flight Script: System compatibility checker with auto-fix mode.&lt;/item&gt;
      &lt;item&gt;ğŸ”§ Admin UI Fixes: Models page, providers page, dashboard improvements.&lt;/item&gt;
      &lt;item&gt;ğŸ› ï¸ Developer Experience: Code splitting, ESLint + Prettier.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ¤ New STT Backends: Kroko ASR, Sherpa-ONNX.&lt;/item&gt;
      &lt;item&gt;ğŸ”Š Kokoro TTS: High-quality neural TTS.&lt;/item&gt;
      &lt;item&gt;ğŸ”„ Model Management: Dynamic backend switching from Dashboard.&lt;/item&gt;
      &lt;item&gt;ğŸ“š Documentation: LOCAL_ONLY_SETUP.md guide.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ–¥ï¸ Admin UI v1.0: Modern web interface (http://localhost:3003).&lt;/item&gt;
      &lt;item&gt;ğŸ™ï¸ ElevenLabs Conversational AI: Premium voice quality provider.&lt;/item&gt;
      &lt;item&gt;ğŸµ Background Music: Ambient music during AI calls.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ”§ Complete Tool Support: Works across ALL pipeline types.&lt;/item&gt;
      &lt;item&gt;ğŸ“š Documentation Overhaul: Reorganized structure.&lt;/item&gt;
      &lt;item&gt;ğŸ’¬ Discord Community: Official server integration.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ¤– Google Live API: Gemini 2.0 Flash integration.&lt;/item&gt;
      &lt;item&gt;ğŸš€ Interactive Setup: &lt;code&gt;agent quickstart&lt;/code&gt;wizard.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸ”§ Tool Calling System: Transfer calls, send emails.&lt;/item&gt;
      &lt;item&gt;ğŸ©º Agent CLI Tools: &lt;code&gt;doctor&lt;/code&gt;,&lt;code&gt;troubleshoot&lt;/code&gt;,&lt;code&gt;demo&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Benefit&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Asterisk-Native&lt;/cell&gt;
        &lt;cell&gt;Works directly with your existing Asterisk/FreePBX - no external telephony providers required.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Truly Open Source&lt;/cell&gt;
        &lt;cell&gt;MIT licensed with complete transparency and control.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Modular Architecture&lt;/cell&gt;
        &lt;cell&gt;Choose cloud, local, or hybrid - mix providers as needed.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Production-Ready&lt;/cell&gt;
        &lt;cell&gt;Battle-tested baselines with Call History-first debugging.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Cost-Effective&lt;/cell&gt;
        &lt;cell&gt;Local Hybrid costs ~$0.001-0.003/minute (LLM only).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Privacy-First&lt;/cell&gt;
        &lt;cell&gt;Keep audio local while using cloud intelligence.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;OpenAI Realtime (Recommended for Quick Start)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Modern cloud AI with natural conversations (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-openai.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Enterprise deployments, quick setup.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Deepgram Voice Agent (Enterprise Cloud)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Advanced Think stage for complex reasoning (&amp;lt;3s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-deepgram.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Deepgram ecosystem, advanced features.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Google Live API (Multimodal AI)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Gemini Live (Flash) with multimodal capabilities (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-google-live.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Google ecosystem, advanced AI features.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ElevenLabs Agent (Premium Voice Quality)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;ElevenLabs Conversational AI with premium voices (&amp;lt;2s response).&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-elevenlabs.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Voice quality priority, natural conversations.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Local Hybrid (Privacy-Focused)&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Local STT/TTS + Cloud LLM (OpenAI). Audio stays on-premises.&lt;/item&gt;
          &lt;item&gt;Config: &lt;code&gt;config/ai-agent.golden-local-hybrid.yaml&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Best for: Audio privacy, cost control, compliance.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run your own local LLM using Ollama - perfect for privacy-focused deployments:&lt;/p&gt;
    &lt;code&gt;# In ai-agent.yaml
active_pipeline: local_ollama&lt;/code&gt;
    &lt;p&gt;Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No API key required - fully self-hosted on your network&lt;/item&gt;
      &lt;item&gt;Tool calling support with compatible models (Llama 3.2, Mistral, Qwen)&lt;/item&gt;
      &lt;item&gt;Local Vosk STT + Your Ollama LLM + Local Piper TTS&lt;/item&gt;
      &lt;item&gt;Complete privacy - all processing stays on-premises&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mac Mini, gaming PC, or server with Ollama installed&lt;/item&gt;
      &lt;item&gt;8GB+ RAM (16GB+ recommended for larger models)&lt;/item&gt;
      &lt;item&gt;See docs/OLLAMA_SETUP.md for setup guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Recommended Models:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Tool Calling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;llama3.2&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2GB&lt;/cell&gt;
        &lt;cell&gt;âœ… Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;mistral&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GB&lt;/cell&gt;
        &lt;cell&gt;âœ… Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;qwen2.5&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4.7GB&lt;/cell&gt;
        &lt;cell&gt;âœ… Yes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tool Calling System: AI-powered actions (transfers, emails) work with any provider.&lt;/item&gt;
      &lt;item&gt;Agent CLI Tools: &lt;code&gt;doctor&lt;/code&gt;,&lt;code&gt;troubleshoot&lt;/code&gt;,&lt;code&gt;demo&lt;/code&gt;,&lt;code&gt;init&lt;/code&gt;commands.&lt;/item&gt;
      &lt;item&gt;Modular Pipeline System: Independent STT, LLM, and TTS provider selection.&lt;/item&gt;
      &lt;item&gt;Dual Transport Support: AudioSocket and ExternalMedia RTP (see Transport Compatibility matrix).&lt;/item&gt;
      &lt;item&gt;High-Performance Architecture: Separate &lt;code&gt;ai-engine&lt;/code&gt;and&lt;code&gt;local-ai-server&lt;/code&gt;containers.&lt;/item&gt;
      &lt;item&gt;Observability: Built-in Call History for per-call debugging + optional &lt;code&gt;/metrics&lt;/code&gt;scraping.&lt;/item&gt;
      &lt;item&gt;State Management: SessionStore for centralized, typed call state.&lt;/item&gt;
      &lt;item&gt;Barge-In Support: Interrupt handling with configurable gating.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Modern web interface for configuration and system management.&lt;/p&gt;
    &lt;p&gt;Quick Start:&lt;/p&gt;
    &lt;code&gt;docker compose up -d admin-ui
# Access at: http://localhost:3003
# Login: admin / admin (change immediately!)&lt;/code&gt;
    &lt;p&gt;Key Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Setup Wizard: Visual provider configuration.&lt;/item&gt;
      &lt;item&gt;Dashboard: Real-time system metrics and container status.&lt;/item&gt;
      &lt;item&gt;Live Logs: WebSocket-based log streaming.&lt;/item&gt;
      &lt;item&gt;YAML Editor: Monaco-based editor with validation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Experience our production-ready configurations with a single phone call:&lt;/p&gt;
    &lt;p&gt;Dial: (925) 736-6718&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Press 5 â†’ Google Live API (Multimodal AI with Gemini 2.0)&lt;/item&gt;
      &lt;item&gt;Press 6 â†’ Deepgram Voice Agent (Enterprise cloud with Think stage)&lt;/item&gt;
      &lt;item&gt;Press 7 â†’ OpenAI Realtime API (Modern cloud AI, most natural)&lt;/item&gt;
      &lt;item&gt;Press 8 â†’ Local Hybrid Pipeline (Privacy-focused, audio stays local)&lt;/item&gt;
      &lt;item&gt;Press 9 â†’ ElevenLabs Agent (Santa voice with background music)&lt;/item&gt;
      &lt;item&gt;Press 10 â†’ Fully Local Pipeline (100% on-premises, CPU-based)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Your AI agent can perform real-world telephony actions through tool calling.&lt;/p&gt;
    &lt;code&gt;Caller: "Transfer me to the sales team"
Agent: "I'll connect you to our sales team right away."
[Transfer to sales queue with queue music]
&lt;/code&gt;
    &lt;p&gt;Supported Destinations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extensions: Direct SIP/PJSIP endpoint transfers.&lt;/item&gt;
      &lt;item&gt;Queues: ACD queue transfers with position announcements.&lt;/item&gt;
      &lt;item&gt;Ring Groups: Multiple agents ring simultaneously.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cancel Transfer: "Actually, cancel that" (during ring).&lt;/item&gt;
      &lt;item&gt;Hangup Call: Ends call gracefully with farewell.&lt;/item&gt;
      &lt;item&gt;Voicemail: Routes to voicemail box.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic Call Summaries: Admins receive full transcripts and metadata.&lt;/item&gt;
      &lt;item&gt;Caller-Requested Transcripts: "Email me a transcript of this call."&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;transfer&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Transfer to extensions, queues, or ring groups&lt;/cell&gt;
        &lt;cell&gt;âœ…&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;cancel_transfer&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Cancel in-progress transfer (during ring)&lt;/cell&gt;
        &lt;cell&gt;âœ…&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;hangup_call&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;End call gracefully with farewell message&lt;/cell&gt;
        &lt;cell&gt;âœ…&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;leave_voicemail&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Route caller to voicemail extension&lt;/cell&gt;
        &lt;cell&gt;âœ…&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;send_email_summary&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Auto-send call summaries to admins&lt;/cell&gt;
        &lt;cell&gt;âœ…&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;request_transcript&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Caller-initiated email transcripts&lt;/cell&gt;
        &lt;cell&gt;âœ…&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Production-ready CLI for operations and setup.&lt;/p&gt;
    &lt;p&gt;Installation:&lt;/p&gt;
    &lt;code&gt;curl -sSL https://raw.githubusercontent.com/hkjarral/Asterisk-AI-Voice-Agent/main/scripts/install-cli.sh | bash&lt;/code&gt;
    &lt;p&gt;Commands:&lt;/p&gt;
    &lt;code&gt;agent quickstart          # Interactive setup wizard
agent dialplan            # Generate dialplan snippets
agent config validate     # Validate configuration
agent doctor --fix        # System health check
agent troubleshoot        # Analyze specific call
agent demo                # Demo features&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;config/ai-agent.yaml&lt;/code&gt;- Golden baseline configs.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;.env&lt;/code&gt;- Secrets and API keys (git-ignored).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example &lt;code&gt;.env&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;OPENAI_API_KEY=sk-your-key-here
DEEPGRAM_API_KEY=your-key-here
ASTERISK_ARI_USERNAME=asterisk
ASTERISK_ARI_PASSWORD=your-password&lt;/code&gt;
    &lt;p&gt;The engine exposes Prometheus-format metrics at &lt;code&gt;http://&amp;lt;engine-host&amp;gt;:15000/metrics&lt;/code&gt;.
Per-call debugging is handled via Admin UI â†’ Call History.&lt;/p&gt;
    &lt;p&gt;Two-container architecture for performance and scalability:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;ai-engine&lt;/code&gt;(Lightweight orchestrator): Connects to Asterisk via ARI, manages call lifecycle.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;local-ai-server&lt;/code&gt;(Optional): Runs local STT/LLM/TTS models (Vosk, Sherpa, Kroko, Piper, Kokoro, llama.cpp).&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;graph LR
    A[Asterisk Server] &amp;lt;--&amp;gt;|ARI, RTP| B[ai-engine]
    B &amp;lt;--&amp;gt;|API| C[AI Provider]
    B &amp;lt;--&amp;gt;|WS| D[local-ai-server]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#bbf,stroke:#333,stroke-width:2px
    style C fill:#bfb,stroke:#333,stroke-width:2px
    style D fill:#fbf,stroke:#333,stroke-width:2px
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Requirement&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Architecture&lt;/cell&gt;
        &lt;cell&gt;x86_64 (AMD64) only&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;OS&lt;/cell&gt;
        &lt;cell&gt;Linux with systemd&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Supported Distros&lt;/cell&gt;
        &lt;cell&gt;Ubuntu 20.04+, Debian 11+, RHEL/Rocky/Alma 8+, Fedora 38+, Sangoma Linux&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: ARM64 (Apple Silicon, Raspberry Pi) is not currently supported. See Supported Platforms for the full compatibility matrix.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;CPU&lt;/cell&gt;
        &lt;cell role="head"&gt;RAM&lt;/cell&gt;
        &lt;cell role="head"&gt;Disk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cloud (OpenAI/Deepgram)&lt;/cell&gt;
        &lt;cell&gt;2+ cores&lt;/cell&gt;
        &lt;cell&gt;4GB&lt;/cell&gt;
        &lt;cell&gt;1GB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Local Hybrid&lt;/cell&gt;
        &lt;cell&gt;4+ cores&lt;/cell&gt;
        &lt;cell&gt;8GB+&lt;/cell&gt;
        &lt;cell&gt;2GB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Docker + Docker Compose v2&lt;/item&gt;
      &lt;item&gt;Asterisk 18+ with ARI enabled&lt;/item&gt;
      &lt;item&gt;FreePBX (recommended) or vanilla Asterisk&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The &lt;code&gt;preflight.sh&lt;/code&gt; script handles initial setup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seeds &lt;code&gt;.env&lt;/code&gt;from&lt;code&gt;.env.example&lt;/code&gt;with your settings&lt;/item&gt;
      &lt;item&gt;Prompts for Asterisk config directory location&lt;/item&gt;
      &lt;item&gt;Sets &lt;code&gt;ASTERISK_UID&lt;/code&gt;/&lt;code&gt;ASTERISK_GID&lt;/code&gt;to match host permissions (fixes media access issues)&lt;/item&gt;
      &lt;item&gt;Re-running preflight often resolves permission problems&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configuration Reference&lt;/item&gt;
      &lt;item&gt;Transport Compatibility&lt;/item&gt;
      &lt;item&gt;Tuning Recipes&lt;/item&gt;
      &lt;item&gt;Supported Platforms&lt;/item&gt;
      &lt;item&gt;Local Profiles&lt;/item&gt;
      &lt;item&gt;Monitoring Guide&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Contributions are welcome! Please see our Contributing Guide.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord Server - Support and discussions&lt;/item&gt;
      &lt;item&gt;GitHub Issues - Bug reports&lt;/item&gt;
      &lt;item&gt;GitHub Discussions - General chat&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This project is licensed under the MIT License. See the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;If you find this project useful, please give it a â­ï¸ on GitHub!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380399</guid><pubDate>Wed, 24 Dec 2025 23:25:37 +0000</pubDate></item><item><title>Who Watches the Waymos? I do [video]</title><link>https://www.youtube.com/watch?v=oYU2hAbx_Fc</link><description>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket Â© 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380758</guid><pubDate>Thu, 25 Dec 2025 00:10:12 +0000</pubDate></item><item><title>The next-gen mainboard designed with amigaos4 and morphos in mind</title><link>https://mirari.vitasys.nl/our-story/</link><description>&lt;doc fingerprint="d4b2af7c4348b786"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;First things firstâ€¦&lt;/head&gt;
    &lt;p&gt;Letâ€™s take a moment to appreciate Trevor Dickinson and his incredible contributions to the Amiga world. His dedication and support have been instrumental in bringing us the next generation of Amiga computers, the ExecSG Kernel and the ongoing development of the Radeon Graphics drivers. Without having machines like the X1000, X5000 and A1222 this project would have never been born. Thank you Trevor, for keeping the Amiga spirit alive!&lt;/p&gt;
    &lt;head rend="h3"&gt;Rebooting The Next-Gen Amiga Dream&lt;/head&gt;
    &lt;p&gt;The Amiga, a once-dominant force in the personal computer world, continues to hold a special place in the hearts of many. But with limited next-gen hardware available and dwindling AmigaOS4 support, the future of this beloved platform seemed uncertain. That is, until a few Dutch passionate individuals decided to take matters into their own hands.&lt;/p&gt;
    &lt;p&gt;Driven by a shared love for the Amiga and a desire to see it thrive, they embarked on an ambitious project: to create a new, low-cost next-gen Amiga mainboard.&lt;/p&gt;
    &lt;p&gt;The Vision:&lt;/p&gt;
    &lt;p&gt;The goal was clear: to create a mainboard that would breathe new life into the next-gen Amiga platform. A board that would be affordable for hobbyists and enthusiasts, while offering the power and performance to run all AmigaOS software and games.&lt;/p&gt;
    &lt;p&gt;The Road Ahead:&lt;/p&gt;
    &lt;p&gt;The journey is filled with challenges, from overcoming technical hurdles to navigating the complexities of cheap production and logistics as for getting the needed software components up and running. But Dave and Harald fueled by their passion and the unwavering support of the Amiga community, remain committed to their vision.&lt;/p&gt;
    &lt;p&gt;A Testament to Community Spirit:&lt;/p&gt;
    &lt;p&gt;The story of Dave and Harald, is a testament to the power of community. It demonstrates how a shared love for technology and a collective effort can bring about remarkable achievements.&lt;/p&gt;
    &lt;p&gt;Stay Tuned:&lt;/p&gt;
    &lt;p&gt;As the project progresses, we will continue to provide updates on the development of the new Mirari Amiga mainboard. The progress can be found on The First Rebirth page.&lt;/p&gt;
    &lt;p&gt;The Future of the Amiga is in Our Hands.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46380953</guid><pubDate>Thu, 25 Dec 2025 00:38:09 +0000</pubDate></item><item><title>Project Dropstone: A Neuro-Symbolic Runtime for Long-Horizon Engineering [pdf]</title><link>https://archive.blankline.org/api/media/file/d3_engine_public_release%20(1)-1.pdf</link><description></description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46381620</guid><pubDate>Thu, 25 Dec 2025 02:47:48 +0000</pubDate></item><item><title>Ruby 4.0.0</title><link>https://www.ruby-lang.org/en/news/2025/12/25/ruby-4-0-0-released/</link><description>&lt;doc fingerprint="7e48a958082198f9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ruby 4.0.0 Released&lt;/head&gt;
    &lt;p&gt;Posted by naruse on 25 Dec 2025&lt;/p&gt;
    &lt;p&gt;We are pleased to announce the release of Ruby 4.0.0. Ruby 4.0 introduces â€œRuby Boxâ€ and â€œZJITâ€, and adds many improvements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ruby Box&lt;/head&gt;
    &lt;p&gt;Ruby Box is a new (experimental) feature to provide separation about definitions. Ruby Box is enabled when an environment variable &lt;code&gt;RUBY_BOX=1&lt;/code&gt; is specified. The class is &lt;code&gt;Ruby::Box&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Definitions loaded in a box are isolated in the box. Ruby Box can isolate/separate monkey patches, changes of global/class variables, class/module definitions, and loaded native/ruby libraries from other boxes.&lt;/p&gt;
    &lt;p&gt;Expected use cases are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Run test cases in box to protect other tests when the test case uses monkey patches to override something&lt;/item&gt;
      &lt;item&gt;Run web app boxes in parallel to execute blue-green deployment on an app server in a Ruby process&lt;/item&gt;
      &lt;item&gt;Run web app boxes in parallel to evaluate dependency updates for a certain period of time by checking response diff using Ruby code&lt;/item&gt;
      &lt;item&gt;Used as the foundation (low-level) API to implement kind of â€œpackageâ€ (high-level) API (it is not designed yet)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For the detail of â€œRuby Boxâ€, see Ruby::Box. [Feature #21311] [Misc #21385]&lt;/p&gt;
    &lt;head rend="h2"&gt;ZJIT&lt;/head&gt;
    &lt;p&gt;ZJIT is a new just-in-time (JIT) compiler, which is developed as the next generation of YJIT. You need Rust 1.85.0 or newer to build Ruby with ZJIT support, and ZJIT is enabled when &lt;code&gt;--zjit&lt;/code&gt; is specified.&lt;/p&gt;
    &lt;p&gt;Weâ€™re building a new compiler for Ruby because we want to both raise the performance ceiling (bigger compilation unit size and SSA IR) and encourage more outside contribution (by becoming a more traditional method compiler). See our blog post for more details.&lt;/p&gt;
    &lt;p&gt;ZJIT is faster than the interpreter, but not yet as fast as YJIT. We encourage you to experiment with ZJIT, but maybe hold off on deploying it in production for now. Stay tuned for Ruby 4.1 ZJIT.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ractor Improvements&lt;/head&gt;
    &lt;p&gt;Ractor, Rubyâ€™s parallel execution mechanism, has received several improvements. A new class, &lt;code&gt;Ractor::Port&lt;/code&gt;, was introduced to address issues related to message sending and receiving (see our blog post). Additionally, &lt;code&gt;Ractor.shareable_proc&lt;/code&gt; makes it easier to share &lt;code&gt;Proc&lt;/code&gt; objects between Ractors.&lt;/p&gt;
    &lt;p&gt;On the performance side, many internal data structures have been improved to significantly reduce contention on a global lock, unlocking better parallelism. Ractors also now share less internal data, resulting in less CPU cache contention when running in parallel.&lt;/p&gt;
    &lt;p&gt;Ractor was first introduced in Ruby 3.0 as an experimental feature. We aim to remove its â€œexperimentalâ€ status next year.&lt;/p&gt;
    &lt;head rend="h2"&gt;Language changes&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;*nil&lt;/code&gt;no longer calls&lt;code&gt;nil.to_a&lt;/code&gt;, similar to how&lt;code&gt;**nil&lt;/code&gt;does not call&lt;code&gt;nil.to_hash&lt;/code&gt;. [Feature #21047]&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Logical binary operators (&lt;/p&gt;&lt;code&gt;||&lt;/code&gt;,&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;,&lt;code&gt;and&lt;/code&gt;and&lt;code&gt;or&lt;/code&gt;) at the beginning of a line continue the previous line, like fluent dot. The following code examples are equal:&lt;code&gt;if condition1 &amp;amp;&amp;amp; condition2 ... end&lt;/code&gt;&lt;p&gt;Previously:&lt;/p&gt;&lt;code&gt;if condition1 &amp;amp;&amp;amp; condition2 ... end&lt;/code&gt;&lt;code&gt;if condition1 &amp;amp;&amp;amp; condition2 ... end&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Core classes updates&lt;/head&gt;
    &lt;p&gt;Note: Weâ€™re only listing outstanding class updates.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Array&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Array#rfind&lt;/code&gt;has been added as a more efficient alternative to&lt;code&gt;array.reverse_each.find&lt;/code&gt;[Feature #21678]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Array#find&lt;/code&gt;has been added as a more efficient override of&lt;code&gt;Enumerable#find&lt;/code&gt;[Feature #21678]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Binding&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Binding#local_variables&lt;/code&gt;does no longer include numbered parameters. Also,&lt;code&gt;Binding#local_variable_get&lt;/code&gt;,&lt;code&gt;Binding#local_variable_set&lt;/code&gt;, and&lt;code&gt;Binding#local_variable_defined?&lt;/code&gt;reject to handle numbered parameters. [Bug #21049]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Binding#implicit_parameters&lt;/code&gt;,&lt;code&gt;Binding#implicit_parameter_get&lt;/code&gt;, and&lt;code&gt;Binding#implicit_parameter_defined?&lt;/code&gt;have been added to access numbered parameters and â€œitâ€ parameter. [Bug #21049]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Enumerator&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Enumerator.produce&lt;/code&gt;now accepts an optional&lt;code&gt;size&lt;/code&gt;keyword argument to specify the size of the enumerator. It can be an integer,&lt;code&gt;Float::INFINITY&lt;/code&gt;, a callable object (such as a lambda), or&lt;code&gt;nil&lt;/code&gt;to indicate unknown size. When not specified, the size defaults to&lt;code&gt;Float::INFINITY&lt;/code&gt;.&lt;code&gt;# Infinite enumerator enum = Enumerator.produce(1, size: Float::INFINITY, &amp;amp;:succ) enum.size # =&amp;gt; Float::INFINITY # Finite enumerator with known/computable size abs_dir = File.expand_path("./baz") # =&amp;gt; "/foo/bar/baz" traverser = Enumerator.produce(abs_dir, size: -&amp;gt; { abs_dir.count("/") + 1 }) { raise StopIteration if it == "/" File.dirname(it) } traverser.size # =&amp;gt; 4&lt;/code&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ErrorHighlight&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;When an ArgumentError is raised, it now displays code snippets for both the method call (caller) and the method definition (callee). [Feature #21543]&lt;/p&gt;
            &lt;code&gt;test.rb:1:in 'Object#add': wrong number of arguments (given 1, expected 2) (ArgumentError) caller: test.rb:3 | add(1) ^^^ callee: test.rb:1 | def add(x, y) = x + y ^^^ from test.rb:3:in '&amp;lt;main&amp;gt;'&lt;/code&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fiber&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Introduce support for &lt;code&gt;Fiber#raise(cause:)&lt;/code&gt;argument similar to&lt;code&gt;Kernel#raise&lt;/code&gt;. [Feature #21360]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Introduce support for &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Fiber::Scheduler&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;p&gt;Introduce&lt;/p&gt;&lt;code&gt;Fiber::Scheduler#fiber_interrupt&lt;/code&gt;to interrupt a fiber with a given exception. The initial use case is to interrupt a fiber that is waiting on a blocking IO operation when the IO operation is closed. [Feature #21166]&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Introduce&lt;/p&gt;&lt;code&gt;Fiber::Scheduler#yield&lt;/code&gt;to allow the fiber scheduler to continue processing when signal exceptions are disabled. [Bug #21633]&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Reintroduce the&lt;/p&gt;&lt;code&gt;Fiber::Scheduler#io_close&lt;/code&gt;hook for asynchronous&lt;code&gt;IO#close&lt;/code&gt;.&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Invoke&lt;/p&gt;&lt;code&gt;Fiber::Scheduler#io_write&lt;/code&gt;when flushing the IO write buffer. [Bug #21789]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;File&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;File::Stat#birthtime&lt;/code&gt;is now available on Linux via the statx system call when supported by the kernel and filesystem. [Feature #21205]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;IO&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;IO.select&lt;/code&gt;accepts&lt;code&gt;Float::INFINITY&lt;/code&gt;as a timeout argument. [Feature #20610]&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;A deprecated behavior, process creation by&lt;/p&gt;&lt;code&gt;IO&lt;/code&gt;class methods with a leading&lt;code&gt;|&lt;/code&gt;, was removed. [Feature #19630]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kernel&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Kernel#inspect&lt;/code&gt;now checks for the existence of a&lt;code&gt;#instance_variables_to_inspect&lt;/code&gt;method, allowing control over which instance variables are displayed in the&lt;code&gt;#inspect&lt;/code&gt;string:&lt;code&gt;class DatabaseConfig def initialize(host, user, password) @host = host @user = user @password = password end private def instance_variables_to_inspect = [:@host, :@user] end conf = DatabaseConfig.new("localhost", "root", "hunter2") conf.inspect #=&amp;gt; #&amp;lt;DatabaseConfig:0x0000000104def350 @host="localhost", @user="root"&amp;gt;&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;A deprecated behavior, process creation by&lt;/p&gt;&lt;code&gt;Kernel#open&lt;/code&gt;with a leading&lt;code&gt;|&lt;/code&gt;, was removed. [Feature #19630]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Math&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Math.log1p&lt;/code&gt;and&lt;code&gt;Math.expm1&lt;/code&gt;are added. [Feature #21527]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Pathname&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Pathname has been promoted from a default gem to a core class of Ruby. [Feature #17473]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Proc&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Proc#parameters&lt;/code&gt;now shows anonymous optional parameters as&lt;code&gt;[:opt]&lt;/code&gt;instead of&lt;code&gt;[:opt, nil]&lt;/code&gt;, making the output consistent with when the anonymous parameter is required. [Bug #20974]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ractor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Ractor::Port&lt;/code&gt;class was added for a new synchronization mechanism to communicate between Ractors. [Feature #21262]&lt;code&gt;port1 = Ractor::Port.new port2 = Ractor::Port.new Ractor.new port1, port2 do |port1, port2| port1 &amp;lt;&amp;lt; 1 port2 &amp;lt;&amp;lt; 11 port1 &amp;lt;&amp;lt; 2 port2 &amp;lt;&amp;lt; 12 end 2.times{ p port1.receive } #=&amp;gt; 1, 2 2.times{ p port2.receive } #=&amp;gt; 11, 12&lt;/code&gt;&lt;code&gt;Ractor::Port&lt;/code&gt;provides the following methods:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;Ractor::Port#receive&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor::Port#send&lt;/code&gt;(or&lt;code&gt;Ractor::Port#&amp;lt;&amp;lt;&lt;/code&gt;)&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor::Port#close&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor::Port#closed?&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;As a result,&lt;/p&gt;&lt;code&gt;Ractor.yield&lt;/code&gt;and&lt;code&gt;Ractor#take&lt;/code&gt;were removed.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor#join&lt;/code&gt;and&lt;code&gt;Ractor#value&lt;/code&gt;were added to wait for the termination of a Ractor. These are similar to&lt;code&gt;Thread#join&lt;/code&gt;and&lt;code&gt;Thread#value&lt;/code&gt;.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor#monitor&lt;/code&gt;and&lt;code&gt;Ractor#unmonitor&lt;/code&gt;were added as low-level interfaces used internally to implement&lt;code&gt;Ractor#join&lt;/code&gt;.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor.select&lt;/code&gt;now only accepts Ractors and Ports. If Ractors are given, it returns when a Ractor terminates.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor#default_port&lt;/code&gt;was added. Each&lt;code&gt;Ractor&lt;/code&gt;has a default port, which is used by&lt;code&gt;Ractor.send&lt;/code&gt;,&lt;code&gt;Ractor.receive&lt;/code&gt;.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor#close_incoming&lt;/code&gt;and&lt;code&gt;Ractor#close_outgoing&lt;/code&gt;were removed.&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Ractor.shareable_proc&lt;/code&gt;and&lt;code&gt;Ractor.shareable_lambda&lt;/code&gt;are introduced to make shareable Proc or lambda. [Feature #21550], [Feature #21557]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Range&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Range#to_set&lt;/code&gt;now performs size checks to prevent issues with endless ranges. [Bug #21654]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Range#overlap?&lt;/code&gt;now correctly handles infinite (unbounded) ranges. [Bug #21185]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Range#max&lt;/code&gt;behavior on beginless integer ranges has been fixed. [Bug #21174] [Bug #21175]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ruby&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A new toplevel module &lt;code&gt;Ruby&lt;/code&gt;has been defined, which contains Ruby-related constants. This module was reserved in Ruby 3.4 and is now officially defined. [Feature #20884]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;A new toplevel module &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ruby::Box&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A new (experimental) feature to provide separation about definitions. For the detail of â€œRuby Boxâ€, see doc/language/box.md. [Feature #21311] [Misc #21385]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Set&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Set&lt;/code&gt;is now a core class, instead of an autoloaded stdlib class. [Feature #21216]&lt;/item&gt;
          &lt;item&gt;&lt;code&gt;Set#inspect&lt;/code&gt;now uses a simpler display, similar to literal arrays. (e.g.,&lt;code&gt;Set[1, 2, 3]&lt;/code&gt;instead of&lt;code&gt;#&amp;lt;Set: {1, 2, 3}&amp;gt;&lt;/code&gt;). [Feature #21389]&lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Passing arguments to&lt;/p&gt;&lt;code&gt;Set#to_set&lt;/code&gt;and&lt;code&gt;Enumerable#to_set&lt;/code&gt;is now deprecated. [Feature #21390]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Socket&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;Socket.tcp&lt;/code&gt;&amp;amp;&lt;code&gt;TCPSocket.new&lt;/code&gt;accepts an&lt;code&gt;open_timeout&lt;/code&gt;keyword argument to specify the timeout for the initial connection. [Feature #21347]&lt;/item&gt;
          &lt;item&gt;When a user-specified timeout occurred in &lt;code&gt;TCPSocket.new&lt;/code&gt;, either&lt;code&gt;Errno::ETIMEDOUT&lt;/code&gt;or&lt;code&gt;IO::TimeoutError&lt;/code&gt;could previously be raised depending on the situation. This behavior has been unified so that&lt;code&gt;IO::TimeoutError&lt;/code&gt;is now consistently raised. (Please note that, in&lt;code&gt;Socket.tcp&lt;/code&gt;, there are still cases where&lt;code&gt;Errno::ETIMEDOUT&lt;/code&gt;may be raised in similar situations, and that in both cases&lt;code&gt;Errno::ETIMEDOUT&lt;/code&gt;may be raised when the timeout occurs at the OS level.)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;String&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;Update Unicode to Version 17.0.0 and Emoji Version 17.0. [Feature #19908][Feature #20724][Feature #21275] (also applies to Regexp)&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;code&gt;String#strip&lt;/code&gt;,&lt;code&gt;strip!&lt;/code&gt;,&lt;code&gt;lstrip&lt;/code&gt;,&lt;code&gt;lstrip!&lt;/code&gt;,&lt;code&gt;rstrip&lt;/code&gt;, and&lt;code&gt;rstrip!&lt;/code&gt;are extended to accept&lt;code&gt;*selectors&lt;/code&gt;arguments. [Feature #21552]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Thread&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Introduce support for &lt;code&gt;Thread#raise(cause:)&lt;/code&gt;argument similar to&lt;code&gt;Kernel#raise&lt;/code&gt;. [Feature #21360]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Introduce support for &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Stdlib updates&lt;/head&gt;
    &lt;p&gt;We only list stdlib changes that are notable feature changes.&lt;/p&gt;
    &lt;p&gt;Other changes are listed in the following sections. We also listed release history from the previous bundled version that is Ruby 3.4.0 if it has GitHub releases.&lt;/p&gt;
    &lt;p&gt;The following bundled gems are promoted from default gems.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ostruct 0.6.3&lt;/item&gt;
      &lt;item&gt;pstore 0.2.0 &lt;list rend="ul"&gt;&lt;item&gt;0.1.4 to v0.2.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;benchmark 0.5.0&lt;/item&gt;
      &lt;item&gt;logger 1.7.0&lt;/item&gt;
      &lt;item&gt;rdoc 7.0.2&lt;/item&gt;
      &lt;item&gt;win32ole 1.9.2 &lt;list rend="ul"&gt;&lt;item&gt;1.9.1 to v1.9.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;irb 1.16.0&lt;/item&gt;
      &lt;item&gt;reline 0.6.3&lt;/item&gt;
      &lt;item&gt;readline 0.0.4&lt;/item&gt;
      &lt;item&gt;fiddle 1.1.8&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The following default gem is added.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;win32-registry 0.1.2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The following default gems are updated.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RubyGems 4.0.3&lt;/item&gt;
      &lt;item&gt;bundler 4.0.3&lt;/item&gt;
      &lt;item&gt;date 3.5.1&lt;/item&gt;
      &lt;item&gt;delegate 0.6.1&lt;/item&gt;
      &lt;item&gt;digest 3.2.1 &lt;list rend="ul"&gt;&lt;item&gt;3.2.0 to v3.2.1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;english 0.8.1 &lt;list rend="ul"&gt;&lt;item&gt;0.8.0 to v0.8.1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;erb 6.0.1&lt;/item&gt;
      &lt;item&gt;error_highlight 0.7.1&lt;/item&gt;
      &lt;item&gt;etc 1.4.6&lt;/item&gt;
      &lt;item&gt;fcntl 1.3.0 &lt;list rend="ul"&gt;&lt;item&gt;1.2.0 to v1.3.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;fileutils 1.8.0 &lt;list rend="ul"&gt;&lt;item&gt;1.7.3 to v1.8.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;forwardable 1.4.0 &lt;list rend="ul"&gt;&lt;item&gt;1.3.3 to v1.4.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;io-console 0.8.2 &lt;list rend="ul"&gt;&lt;item&gt;0.8.1 to v0.8.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;io-nonblock 0.3.2&lt;/item&gt;
      &lt;item&gt;io-wait 0.4.0 &lt;list rend="ul"&gt;&lt;item&gt;0.3.2 to v0.3.3, v0.3.5.test1, v0.3.5, v0.3.6, v0.4.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;ipaddr 1.2.8&lt;/item&gt;
      &lt;item&gt;json 2.18.0&lt;/item&gt;
      &lt;item&gt;net-http 0.9.1&lt;/item&gt;
      &lt;item&gt;openssl 4.0.0&lt;/item&gt;
      &lt;item&gt;optparse 0.8.1&lt;/item&gt;
      &lt;item&gt;pp 0.6.3 &lt;list rend="ul"&gt;&lt;item&gt;0.6.2 to v0.6.3&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;prism 1.7.0&lt;/item&gt;
      &lt;item&gt;psych 5.3.1&lt;/item&gt;
      &lt;item&gt;resolv 0.7.0&lt;/item&gt;
      &lt;item&gt;stringio 3.2.0&lt;/item&gt;
      &lt;item&gt;strscan 3.1.6&lt;/item&gt;
      &lt;item&gt;time 0.4.2 &lt;list rend="ul"&gt;&lt;item&gt;0.4.1 to v0.4.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;timeout 0.6.0&lt;/item&gt;
      &lt;item&gt;uri 1.1.1&lt;/item&gt;
      &lt;item&gt;weakref 0.1.4 &lt;list rend="ul"&gt;&lt;item&gt;0.1.3 to v0.1.4&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;zlib 3.2.2 &lt;list rend="ul"&gt;&lt;item&gt;3.2.1 to v3.2.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The following bundled gems are updated.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;minitest 6.0.0&lt;/item&gt;
      &lt;item&gt;power_assert 3.0.1&lt;/item&gt;
      &lt;item&gt;rake 13.3.1&lt;/item&gt;
      &lt;item&gt;test-unit 3.7.3&lt;/item&gt;
      &lt;item&gt;rexml 3.4.4&lt;/item&gt;
      &lt;item&gt;rss 0.3.2 &lt;list rend="ul"&gt;&lt;item&gt;0.3.1 to 0.3.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;net-ftp 0.3.9 &lt;list rend="ul"&gt;&lt;item&gt;0.3.8 to v0.3.9&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;net-imap 0.6.2&lt;/item&gt;
      &lt;item&gt;net-smtp 0.5.1 &lt;list rend="ul"&gt;&lt;item&gt;0.5.0 to v0.5.1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;matrix 0.4.3 &lt;list rend="ul"&gt;&lt;item&gt;0.4.2 to v0.4.3&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;prime 0.1.4 &lt;list rend="ul"&gt;&lt;item&gt;0.1.3 to v0.1.4&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;rbs 3.10.0 &lt;list rend="ul"&gt;&lt;item&gt;3.8.0 to v3.8.1, v3.9.0.dev.1, v3.9.0.pre.1, v3.9.0.pre.2, v3.9.0, v3.9.1, v3.9.2, v3.9.3, v3.9.4, v3.9.5, v3.10.0.pre.1, v3.10.0.pre.2, v3.10.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;typeprof 0.31.1&lt;/item&gt;
      &lt;item&gt;debug 1.11.1 &lt;list rend="ul"&gt;&lt;item&gt;1.11.0 to v1.11.1&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;base64 0.3.0 &lt;list rend="ul"&gt;&lt;item&gt;0.2.0 to v0.3.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;bigdecimal 4.0.1&lt;/item&gt;
      &lt;item&gt;drb 2.2.3 &lt;list rend="ul"&gt;&lt;item&gt;2.2.1 to v2.2.3&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;syslog 0.3.0 &lt;list rend="ul"&gt;&lt;item&gt;0.2.0 to v0.3.0&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;csv 3.3.5&lt;/item&gt;
      &lt;item&gt;repl_type_completor 0.1.12&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;RubyGems and Bundler&lt;/head&gt;
    &lt;p&gt;Ruby 4.0 bundled RubyGems and Bundler version 4. see the following links for details.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Upgrading to RubyGems/Bundler 4 - RubyGems Blog&lt;/item&gt;
      &lt;item&gt;4.0.0 Released - RubyGems Blog&lt;/item&gt;
      &lt;item&gt;4.0.1 Released - RubyGems Blog&lt;/item&gt;
      &lt;item&gt;4.0.2 Released - RubyGems Blog&lt;/item&gt;
      &lt;item&gt;4.0.3 Released - RubyGems Blog&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Supported platforms&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Windows&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Dropped support for MSVC versions older than 14.0 (_MSC_VER 1900). This means Visual Studio 2015 or later is now required.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Compatibility issues&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;The following methods were removed from Ractor due to the addition of&lt;/p&gt;&lt;code&gt;Ractor::Port&lt;/code&gt;:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;Ractor.yield&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor#take&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor#close_incoming&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;Ractor#close_outgoing&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ObjectSpace._id2ref&lt;/code&gt;is deprecated. [Feature #15408]&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Process::Status#&amp;amp;&lt;/code&gt;and&lt;code&gt;Process::Status#&amp;gt;&amp;gt;&lt;/code&gt;have been removed. They were deprecated in Ruby 3.3. [Bug #19868]&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;rb_path_check&lt;/code&gt;has been removed. This function was used for&lt;code&gt;$SAFE&lt;/code&gt;path checking which was removed in Ruby 2.7, and was already deprecated. [Feature #20971]&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;A backtrace for&lt;/p&gt;&lt;code&gt;ArgumentError&lt;/code&gt;of â€œwrong number of argumentsâ€ now include the receiverâ€™s class or module name (e.g., in&lt;code&gt;Foo#bar&lt;/code&gt;instead of in&lt;code&gt;bar&lt;/code&gt;). [Bug #21698]&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Backtraces no longer display&lt;/p&gt;&lt;code&gt;internal&lt;/code&gt;frames. These methods now appear as if it is in the Ruby source file, consistent with other C-implemented methods. [Bug #20968]&lt;p&gt;Before:&lt;/p&gt;&lt;code&gt;ruby -e '[1].fetch_values(42)' &amp;lt;internal:array&amp;gt;:211:in 'Array#fetch': index 42 outside of array bounds: -1...1 (IndexError) from &amp;lt;internal:array&amp;gt;:211:in 'block in Array#fetch_values' from &amp;lt;internal:array&amp;gt;:211:in 'Array#map!' from &amp;lt;internal:array&amp;gt;:211:in 'Array#fetch_values' from -e:1:in '&amp;lt;main&amp;gt;'&lt;/code&gt;&lt;p&gt;After:&lt;/p&gt;&lt;code&gt;$ ruby -e '[1].fetch_values(42)' -e:1:in 'Array#fetch_values': index 42 outside of array bounds: -1...1 (IndexError) from -e:1:in '&amp;lt;main&amp;gt;'&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Stdlib compatibility issues&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;CGI library is removed from the default gems. Now we only provide&lt;/p&gt;&lt;code&gt;cgi/escape&lt;/code&gt;for the following methods:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;CGI.escape&lt;/code&gt;and&lt;code&gt;CGI.unescape&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;CGI.escapeHTML&lt;/code&gt;and&lt;code&gt;CGI.unescapeHTML&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;CGI.escapeURIComponent&lt;/code&gt;and&lt;code&gt;CGI.unescapeURIComponent&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;CGI.escapeElement&lt;/code&gt;and&lt;code&gt;CGI.unescapeElement&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;With the move of&lt;/p&gt;&lt;code&gt;Set&lt;/code&gt;from stdlib to core class,&lt;code&gt;set/sorted_set.rb&lt;/code&gt;has been removed, and&lt;code&gt;SortedSet&lt;/code&gt;is no longer an autoloaded constant. Please install the&lt;code&gt;sorted_set&lt;/code&gt;gem and&lt;code&gt;require 'sorted_set'&lt;/code&gt;to use&lt;code&gt;SortedSet&lt;/code&gt;. [Feature #21287]&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Net::HTTP&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;The default behavior of automatically setting the &lt;code&gt;Content-Type&lt;/code&gt;header to&lt;code&gt;application/x-www-form-urlencoded&lt;/code&gt;for requests with a body (e.g.,&lt;code&gt;POST&lt;/code&gt;,&lt;code&gt;PUT&lt;/code&gt;) when the header was not explicitly set has been removed. If your application relied on this automatic default, your requests will now be sent without a Content-Type header, potentially breaking compatibility with certain servers. [GH-net-http #205]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;The default behavior of automatically setting the &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;C API updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;IO&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;rb_thread_fd_close&lt;/code&gt;is deprecated and now a no-op. If you need to expose file descriptors from C extensions to Ruby code, create an&lt;code&gt;IO&lt;/code&gt;instance using&lt;code&gt;RUBY_IO_MODE_EXTERNAL&lt;/code&gt;and use&lt;code&gt;rb_io_close(io)&lt;/code&gt;to close it (this also interrupts and waits for all pending operations on the&lt;code&gt;IO&lt;/code&gt;instance). Directly closing file descriptors does not interrupt pending operations, and may lead to undefined behaviour. In other words, if two&lt;code&gt;IO&lt;/code&gt;objects share the same file descriptor, closing one does not affect the other. [Feature #18455]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;GVL&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;code&gt;rb_thread_call_with_gvl&lt;/code&gt;now works with or without the GVL. This allows gems to avoid checking&lt;code&gt;ruby_thread_has_gvl_p&lt;/code&gt;. Please still be diligent about the GVL. [Feature #20750]&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Set&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;&lt;p&gt;A C API for&lt;/p&gt;&lt;code&gt;Set&lt;/code&gt;has been added. The following methods are supported: [Feature #21459]&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;rb_set_foreach&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_new&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_new_capa&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_lookup&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_add&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_clear&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_delete&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;rb_set_size&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Implementation improvements&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Class#new&lt;/code&gt;(ex.&lt;code&gt;Object.new&lt;/code&gt;) is faster in all cases, but especially when passing keyword arguments. This has also been integrated into YJIT and ZJIT. [Feature #21254]&lt;/item&gt;
      &lt;item&gt;GC heaps of different size pools now grow independently, reducing memory usage when only some pools contain long-lived objects&lt;/item&gt;
      &lt;item&gt;GC sweeping is faster on pages of large objects&lt;/item&gt;
      &lt;item&gt;â€œGeneric ivarâ€ objects (String, Array, &lt;code&gt;TypedData&lt;/code&gt;, etc.) now use a new internal â€œfieldsâ€ object for faster instance variable access&lt;/item&gt;
      &lt;item&gt;The GC avoids maintaining an internal &lt;code&gt;id2ref&lt;/code&gt;table until it is first used, making&lt;code&gt;object_id&lt;/code&gt;allocation and GC sweeping faster&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;object_id&lt;/code&gt;and&lt;code&gt;hash&lt;/code&gt;are faster on Class and Module objects&lt;/item&gt;
      &lt;item&gt;Larger bignum Integers can remain embedded using variable width allocation&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;Random&lt;/code&gt;,&lt;code&gt;Enumerator::Product&lt;/code&gt;,&lt;code&gt;Enumerator::Chain&lt;/code&gt;,&lt;code&gt;Addrinfo&lt;/code&gt;,&lt;code&gt;StringScanner&lt;/code&gt;, and some internal objects are now write-barrier protected, which reduces GC overhead.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Ractor&lt;/head&gt;
    &lt;p&gt;A lot of work has gone into making Ractors more stable, performant, and usable. These improvements bring Ractor implementation closer to leaving experimental status.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Performance improvements &lt;list rend="ul"&gt;&lt;item&gt;Frozen strings and the symbol table internally use a lock-free hash set [Feature #21268]&lt;/item&gt;&lt;item&gt;Method cache lookups avoid locking in most cases&lt;/item&gt;&lt;item&gt;Class (and generic ivar) instance variable access is faster and avoids locking&lt;/item&gt;&lt;item&gt;CPU cache contention is avoided in object allocation by using a per-ractor counter&lt;/item&gt;&lt;item&gt;CPU cache contention is avoided in xmalloc/xfree by using a thread-local counter&lt;/item&gt;&lt;item&gt;&lt;code&gt;object_id&lt;/code&gt;avoids locking in most cases&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Bug fixes and stability &lt;list rend="ul"&gt;&lt;item&gt;Fixed possible deadlocks when combining Ractors and Threads&lt;/item&gt;&lt;item&gt;Fixed issues with require and autoload in a Ractor&lt;/item&gt;&lt;item&gt;Fixed encoding/transcoding issues across Ractors&lt;/item&gt;&lt;item&gt;Fixed race conditions in GC operations and method invalidation&lt;/item&gt;&lt;item&gt;Fixed issues with processes forking after starting a Ractor&lt;/item&gt;&lt;item&gt;GC allocation counts are now accurate under Ractors&lt;/item&gt;&lt;item&gt;Fixed TracePoints not working after GC [Bug #19112]&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;JIT&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ZJIT &lt;list rend="ul"&gt;&lt;item&gt;Introduce an experimental method-based JIT compiler. Where available, ZJIT can be enabled at runtime with the &lt;code&gt;--zjit&lt;/code&gt;option or by calling&lt;code&gt;RubyVM::ZJIT.enable&lt;/code&gt;. When building Ruby, Rust 1.85.0 or later is required to include ZJIT support.&lt;/item&gt;&lt;item&gt;As of Ruby 4.0.0, ZJIT is faster than the interpreter, but not yet as fast as YJIT. We encourage experimentation with ZJIT, but advise against deploying it in production for now.&lt;/item&gt;&lt;item&gt;Our goal is to make ZJIT faster than YJIT and production-ready in Ruby 4.1.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Introduce an experimental method-based JIT compiler. Where available, ZJIT can be enabled at runtime with the &lt;/item&gt;
      &lt;item&gt;YJIT &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;RubyVM::YJIT.runtime_stats&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;ratio_in_yjit&lt;/code&gt;no longer works in the default build. Use&lt;code&gt;--enable-yjit=stats&lt;/code&gt;on&lt;code&gt;configure&lt;/code&gt;to enable it on&lt;code&gt;--yjit-stats&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;invalidate_everything&lt;/code&gt;to default stats, which is incremented when every code is invalidated by TracePoint.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;mem_size:&lt;/code&gt;and&lt;code&gt;call_threshold:&lt;/code&gt;options to&lt;code&gt;RubyVM::YJIT.enable&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;RJIT &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;--rjit&lt;/code&gt;is removed. We will move the implementation of the third-party JIT API to the ruby/rjit repository.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See NEWS or commit logs for more details.&lt;/p&gt;
    &lt;p&gt;With those changes, 3889 files changed, 230769 insertions(+), 297003 deletions(-) since Ruby 3.4.0!&lt;/p&gt;
    &lt;p&gt;Merry Christmas, a Happy New Year, and Happy Hacking with Ruby 4.0!&lt;/p&gt;
    &lt;head rend="h2"&gt;Download&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0.tar.gz&lt;/p&gt;
        &lt;code&gt;SIZE: 23955109 SHA1: 754e39e9ad122e1b6deaed860350bac133a35ed3 SHA256: 2e8389c8c072cb658c93a1372732d9eac84082c88b065750db1e52a5ac630271 SHA512: 688254e939b197d564e896fb951bc1abf07142f489e91c5ed0b11f68f52d6adb6b1f86616fe03f1f0bb434beeef7e75e158b9c616afb39bb34403b0b78d2ee19&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0.tar.xz&lt;/p&gt;
        &lt;code&gt;SIZE: 18008368 SHA1: 05ec670e86f84325c5353ef2f2888e53b6adc602 SHA256: a72bacee9de07283ebc19baa4ac243b193129f21aa4e168c7186fb1fe7d07fe1 SHA512: 2d5b2e566eaf70a5f3ea6ce6afc0611c0415de58a41336ef7a0b855c9a91eda9aa790a5f8b48e40a1eb9d50f8ea0f687216e617f16c8d040a08474f3116518a4&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://cache.ruby-lang.org/pub/ruby/4.0/ruby-4.0.0.zip&lt;/p&gt;
        &lt;code&gt;SIZE: 29253204 SHA1: 0b69f89d1d140157251c0d3a6032f6c45cdf81e8 SHA256: 70cb1bf89279b86ab9a975d504607c051fc05ee03e311d550a5541b65e373455 SHA512: a72e076ef618c0aeb9d20cf22e6fb12fda36809c0064ef0f98153b95a0bac257ef606342444a38f992c4594bf376a4d264686cf597463aa6f111220798784302&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What is Ruby&lt;/head&gt;
    &lt;p&gt;Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993, and is now developed as Open Source. It runs on multiple platforms and is used all over the world especially for web development.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recent News&lt;/head&gt;
    &lt;head rend="h3"&gt;A New Look for Ruby's Documentation&lt;/head&gt;
    &lt;p&gt;Following the ruby-lang.org redesign, we have more news to celebrate Rubyâ€™s 30th anniversary: docs.ruby-lang.org has a completely new look with Alikiâ€”RDocâ€™s new default theme.&lt;/p&gt;
    &lt;p&gt;Posted by Stan Lo on 23 Dec 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Redesign our Site Identity&lt;/head&gt;
    &lt;p&gt;We are excited to announce a comprehensive redesign of our site. The design for this update was created by Taeko Akatsuka.&lt;/p&gt;
    &lt;p&gt;Posted by Hiroshi SHIBATA on 22 Dec 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Ruby 4.0.0 preview3 Released&lt;/head&gt;
    &lt;p&gt;We are pleased to announce the release of Ruby 4.0.0-preview3. Ruby 4.0 introduces Ruby::Box and â€œZJITâ€, and adds many improvements.&lt;/p&gt;
    &lt;p&gt;Posted by naruse on 18 Dec 2025&lt;/p&gt;
    &lt;head rend="h3"&gt;Ruby 3.4.8 Released&lt;/head&gt;
    &lt;p&gt;Ruby 3.4.8 has been released.&lt;/p&gt;
    &lt;p&gt;Posted by k0kubun on 17 Dec 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46382011</guid><pubDate>Thu, 25 Dec 2025 04:13:00 +0000</pubDate></item><item><title>Self-referencing Page Tables for the x86-Architecture</title><link>https://0l.de/blog/2015/01/bachelor-thesis-abstract/</link><description>&lt;doc fingerprint="afb85c5647a1cb6d"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Bachelor Thesis: Extended Abstract&lt;/head&gt;&lt;p&gt;Almost fourteen months ago, I started working on my bachelor thesis. Although I finished it half a year ago, itÃ¢s still part of my work as a student research assistant.&lt;/p&gt;&lt;p&gt;During my initial work, most of the code was written for an internal research kernel. IÃ¢m now happy that we were able to port it to an open source kernel called eduOS: /RWTH-OS/eduOS ). This minimal operating system is used for practical demoÃ¢s and assignments during the OS course at my university. ThereÃ¢s much more I could write about. So this will probably be another separate blog post.&lt;/p&gt;&lt;p&gt;The motive for this article is an abstract I wrote for the student research competition of the ASPLOS conference which is held this year in Istanbul, Turkey. Unfortunately my submission got rejected. But as a nice side-effect, IÃ¢ve now the chance to present my work to an English audience as well:&lt;/p&gt;&lt;head rend="h2"&gt;Self-referencing Page Tables for the x86-Architecture&lt;/head&gt;Section titled Ã¢Self-referencing Page Tables for the x86-ArchitectureÃ¢&lt;head rend="h3"&gt;A simple Paging Implementation for a minimalistic Operating System&lt;/head&gt;Section titled Ã¢A simple Paging Implementation for a minimalistic Operating SystemÃ¢&lt;p&gt;Academic advisor: Dr. rer nat. Stefan Lankes Institute for Automation of Complex Power Systems E.ON Energy Research Center, RWTH Aachen University Mathieustr. 10, 52074 Aachen, Germany&lt;/p&gt;&lt;p&gt;This was a submission for ASPLOS Student Research Competition Ã¢15 Istanbul, Turkey1.&lt;/p&gt;&lt;head rend="h3"&gt;Abstract&lt;/head&gt;Section titled Ã¢AbstractÃ¢&lt;p&gt;The adoption of 64 bit architectures went along with an extension of the virtual address space (VAS). To cope with this growth, the memory management unit (MMU) had to be extended as well. For paging-based systems like IntelÃ¢s x86-architecture this was realized by adding more levels of indirection to the page table walk.&lt;/p&gt;&lt;p&gt;This walk translates virtual pages to physical page frames (PF) by performing look-ups in a radix / prefix tree in which every node represents a page table (Figure 1a). Since the tables are part of the translation process, they must be referenced by physical page frame numbers (PFN, blue line). As the operating system is only eligible to access the VAS, it cannot follow the path of a walk. In order to allow the manipulation of page tables, it must provide:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Access to the table entries, by mapping the tables themselves to the VAS.&lt;/item&gt;&lt;item&gt;A mapping between physical references to corresponding locations in the VAS.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Additionally, every level of the page table walk increases the complexity of managing these mappings. They also increase the memory consumption by occupying physical page frames. It is possible to avoid both drawbacks by the technique described in the following.&lt;/p&gt;&lt;p&gt;In my bachelor thesis, I presented an approach, which is compatible with both the 32 bit and 64 bit version of IntelÃ¢s x86-architecture. This allows for a replacement of two code bases, one for each architecture, by one supporting both. Thus, results in a shorter, easier comprehensible, and maintainable code. As foundation for this implementation our teaching OS called Ã¢eduOSÃ¢ was used2. Ã¢eduOSÃ¢ supports only the 32 bit protected mode whereas the 64 bit longmode is only implemented for an internal research kernel.&lt;/p&gt;&lt;p&gt;Thanks to the sophisticated design of IntelÃ¢s x86 MMU, it is possible to avoid most of the complexity and space requirements by using a little trick. Adding a self-reference in the root table (PML4 resp. PGD) automatically enables access to all page tables from the VAS without the need for manual mappings as described above (Figure 1b). The operating system does not need to manually follow the path of a page table walk, as this task is executed by the MMU for accessing individual tables instead of page frames.&lt;/p&gt;&lt;p&gt;An access to the VAS region covered by a self-reference causes the MMU to look up the root table twice (red line). Effectively, this shifts the whole page table walk by one level. Therefore, it stops with the PFN of page tables instead of page frames that are usually translated by the MMU. Here, both the PML4 and PDPT indexes are used to choose an entry out of the PML4 table. Therefore, it must be guaranteed that PML4 entries can be interpreted as PDPT entries, too. This demands for the following requirements:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Homogenous coding of paging flags across all paging levels.&lt;/item&gt;&lt;item&gt;Equal table sizes across all paging levels.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Fortunately, the x86-architecture complies with this prerequisites as shown in Figure 2. Green colored flags are coded consistently across all paging levels. Only PAT, size and global flags have a slightly different meaning for entries in the PGT. My bachelor thesis shows that these deviations still allow maintaining full control caching and memory protection properties of self-mapped tables. This includes for common system calls like fork() and kill().&lt;/p&gt;&lt;p&gt;By repeatedly addressing the self-reference, it is also possible to access tables of the upper levels (PGD to PML4). Table 1 shows the resulting virtual addresses of all page tables when using the last (512th) entry of the PML4 table for the self-reference3. This grants access to all possible page tables, including those which might not yet exist and may be allocated in the future. Hence, the self-reference reserves a fixed fraction of the VAS for the page tables. The size of this region is equal to 256 TiB / 512 = 512 GiB for 64 bit (resp. 4 GiB / 1024 = 4 MiB for 32 bit), which is negligible in comparison to the huge VAS of 248 byte.&lt;/p&gt;&lt;p&gt;For the manipulation of page table entries two approaches are feasible:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Top-down Use known tree traversals, starting at the root node, which corresponds to the PML4 respectively PGD.&lt;/item&gt;&lt;item&gt;Bottom-up Use the page fault handler to create new tables on-the-fly, when they are not yet present.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;But there are also other architectures which satisfy the prerequisites described above. One of these is the Alpha4 architecture, which suggests a similar approach in the reference manual. Intel and AMD do not mention the technique in their x86 manuals. In the field of operating systems, support is far more limited. There is only a single reference5 dated to 2010 indicating that Microsoft might use a similar approach for its NT kernel. Linux cannot profit because its paging implementation must support a broad selection of virtual memory architectures of which not all fulfill the requirements mentioned above.&lt;/p&gt;&lt;head rend="h2"&gt;Footnotes&lt;/head&gt;Section titled Ã¢FootnotesÃ¢&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;A full version of the thesis and slides are available in this post. Ã¢Â©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Description and source code at: www.os.rwth-aachen.de. Ã¢Â©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;This is an arbitrary choice. All other entries are feasible, too. Ã¢Â©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Compaq Computer Corporation: Alpha Architecture Reference Manual. January 2002. Ã¢Â©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Dave Probert, Microsoft: Windows Kernel Architecture Internals. April 2010. Ã¢Â©&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46383139</guid><pubDate>Thu, 25 Dec 2025 08:58:23 +0000</pubDate></item><item><title>Quantum Error Correction Goes FOOM</title><link>https://algassert.com/post/2503</link><description>&lt;doc fingerprint="4c1520f246a4eaee"&gt;
  &lt;main&gt;&lt;p&gt;In this post: why I expect the maximum achievable qubit quality to increase drastically in the next few years.&lt;/p&gt;&lt;p&gt;In 2014, the John Martinis group at UCSB performed an experiment where they stored a classical bit using their quantum computer. They protected the bit with a 9 qubit quantum repetition code. The protected bit had a half life of roughly 100 microseconds. Clearly thatâ€™s not competitive with classical storageâ€¦ but the goal of the experiment wasnâ€™t to hit a high number. The goal was to perform a demonstration of the fledgling power of quantum error correction. In particular, the 9 qubit rep code had a longer lifetime than the individual physical qubits, and also a longer lifetime than the 5 qubit rep code that they also tried. It hinted that qubit quality could be solved using qubit quantity.&lt;/p&gt;&lt;p&gt;Later experiments by the same group (now at Google) improved on this starting point. In 2021, it was a 21 qubit rep code with a half life of 3 milliseconds. Then, in 2023, it was a 51 qubit rep code with a half life of 300 milliseconds. Most recently, in 2024, it was a 59 qubit rep code with a half life of 2 hours.&lt;/p&gt;&lt;p&gt;Letâ€™s plot this data:&lt;/p&gt;&lt;p&gt;(view with semilog scale instead)&lt;/p&gt;&lt;p&gt;Thatâ€™s quite the plot, right? Thereâ€™s a huge lull and thenâ€¦ FOOM! It took nearly a decade for the half life to approach one second, and then one year later itâ€™s suddenly measured in hours?! I know why it happens, but I still find it surprising.&lt;/p&gt;&lt;p&gt;Hereâ€™s a simple model that explains the FOOM. The lifetime $L$ of a repetition code grows like $L = C \lambda^q$ (see equation 11 of â€œSurface codes: Towards practical large-scale quantum computationâ€). Here $q$ is the number of physical qubits, $\lambda$ is a measure of qubit quality, and $C$ is a starting constant. Suppose quality is held fixed at $\lambda = 2$ and qubit count doubles each year (meaning $q = 2^t$). Then $L$ grows superexponentially:&lt;/p&gt;\[L = C \lambda^q = C \lambda^{2^t}\]&lt;p&gt;The first stacked exponential is qubit count vs years, due to the assumed Mooreâ€™s-law-like growth. The second stacked exponential is error rate vs qubit count, due to technical details of how quantum error correction works that Iâ€™m not going to go into.&lt;/p&gt;&lt;p&gt;What do you get when you stack two exponentials? A lull followed by a FOOM.&lt;/p&gt;&lt;p&gt;In practice, things are a bit more complex than a superexponential. There are â€œhurdlesâ€ that place ceilings on the lifetime of error corrected objects. You discover these QEC hurdles due to the superexponential not holding, and you get mini FOOMs as you fix them. A mundane example of a QEC hurdle is, if you donâ€™t have backup generators, your qubits canâ€™t live longer than the time between power outages. Installing backup generators would allow the lifetime to increase, until it becomes limited by whatever the next QEC hurdle is (such as asteroid strikes).&lt;/p&gt;&lt;p&gt;An important QEC hurdle is leakage. During operation, superconducting transmons can get overexcited and â€œleakâ€ out of the qubit subspace. The proportion of leaked qubits will grow until they suffocate the computation. Fixing this requires some kind of leakage removal. Another important QEC hurdle is high energy events like cosmic rays. The 2023 lifetime of 300 milliseconds noticeably deviated from the $L = C \lambda^q$ idealization, due to high energy impacts intermittently disabling the entire chip. In 2024 this problem was mitigated using gap engineering, resulting in the sudden 10000x jump in lifetime. Without cosmic rays (or other QEC hurdles), the lifetime would have already been unmeasurably long in 2023.&lt;/p&gt;&lt;p&gt;QEC hurdles are extremely important to identify and fix. In fact, this is one of the major reasons the google team does rep code experiments. To clear the way for full quantum error correction.&lt;/p&gt;&lt;head rend="h1"&gt;Full Quantum Error Correction&lt;/head&gt;&lt;p&gt;So far Iâ€™ve only talked about protecting a classical bit on a quantum chip. That only requires correcting one type of error (bit flip errors). The real goal is, of course, to protect quantum bits. Protecting a qubit requires correcting a second type of error (phase flip errors, such as caused by unwanted measurements). Repetition codes protect against bit flips, but actually make phase flip errors worse. Correcting both simultaneously requires more complex codes, such as the surface code.&lt;/p&gt;&lt;p&gt;Although the process of protecting a qubit is more complex than protecting a bit, the same basic dynamics are present. Thereâ€™s a quality bar you must cross in order for it to work, and then you get exponential returns on error suppression by increasing qubit count. If your qubit count is also increasing exponentially, then you will achieve superexponential error suppression vs time (with ceilings as you encounter QEC hurdles).&lt;/p&gt;&lt;p&gt;In a surface code, quadrupling the number of physical qubits will square the logical error rate of the protected qubit. In 2024, the best surface code experiment had a logical error rate of 0.1% per round (corresponding to a half life of a ~300 microseconds). Holding quality constant, one qubit quadrupling would turn that 0.1% into 0.0001% (~300 milliseconds). The next quadrupling would reach 0.0000000001% (~3 days). And the one after that would reach 0.0000000000000000000001% (~30 billion years).&lt;/p&gt;&lt;p&gt;Quadrupling the number of physical qubits has technical challenges, like wiring complexity, which must be overcome in a way that doesnâ€™t degrade qubit quality. And, of course, there will be some QEC hurdle that places a ceiling stricter than 30 billion years (e.g. nuclear war). But ultimately the picture looks qualitatively similar to the rep code case. Lullâ€¦ then FOOM.&lt;/p&gt;&lt;p&gt;Because error corrected qubits recently begun to surpass physical qubits, I think the FOOM for logical qubits is near. I realize how ridiculous the hypotheticals look in this plot, but I legitimately think this is what will happen:&lt;/p&gt;&lt;head rend="h1"&gt;Summary&lt;/head&gt;&lt;p&gt;In my view, there are three long standing barriers to full scale quantum computation: qubit quality, qubit quantity, and qubit speed. I think the quality barrier will fall within the next five years. This is perhaps surprising, because the quality barrier has held strong over the three decades that weâ€™ve known about quantum error correction. But logical qubits have recently begun surpassing physical qubits, and QEC goes FOOM.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46383233</guid><pubDate>Thu, 25 Dec 2025 09:18:15 +0000</pubDate></item><item><title>We invited a man into our home at Christmas and he stayed with us for 45 years</title><link>https://www.bbc.co.uk/news/articles/cdxwllqz1l0o</link><description>&lt;doc fingerprint="76a191dce9279cf8"&gt;
  &lt;main&gt;
    &lt;p&gt;We invited a man into our home at Christmas and he stayed with us for 45 years&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Published&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Christmas is often regarded as a time for goodwill, but one young UK couple's act of kindness 50 years ago changed their lives forever.&lt;/p&gt;
    &lt;p&gt;On 23 December 1975, Rob Parsons and his wife Dianne were preparing for Christmas at their Cardiff home when they heard a knock at the door.&lt;/p&gt;
    &lt;p&gt;On their doorstep stood a man with a bin bag containing his possessions in his right hand and a frozen chicken in his left.&lt;/p&gt;
    &lt;p&gt;Rob studied the man's face and vaguely remembered him as Ronnie Lockwood, someone he would occasionally see at Sunday School as a boy and who he was told to be kind to as he was a "bit different".&lt;/p&gt;
    &lt;p&gt;"I said 'Ronnie, what's with the chicken?' He said 'somebody gave it to me for Christmas'. And then I said two words that changed all of our lives.&lt;/p&gt;
    &lt;p&gt;"And I'm not exactly sure why I said them. I said come in."&lt;/p&gt;
    &lt;p&gt;Aged just 27 and 26 years old at the time, the couple felt compelled to take Ronnie, who was autistic, under their wing.&lt;/p&gt;
    &lt;p&gt;They cooked his chicken, let him bathe and agreed to let him stay for Christmas.&lt;/p&gt;
    &lt;p&gt;What began as an act of compassion turned into an unique companionship of love and compromise that lasted 45 years, until the day Ronnie died.&lt;/p&gt;
    &lt;p&gt;Rob, now 77, and Dianne, now 76, had only been married for four years when they welcomed Ronnie into their home.&lt;/p&gt;
    &lt;p&gt;Ronnie was then almost 30 and had been without a home from the age of 15, living in and around Cardiff and moving from job to job - Rob would sometimes see him at a youth club he ran.&lt;/p&gt;
    &lt;p&gt;To make him feel as welcome as possible, they asked their family to bring him a gift for Christmas, anything from a pair of socks to some "smellies".&lt;/p&gt;
    &lt;p&gt;"I can remember him now. He was sat at the Christmas table and he had these presents and he cried because he'd never known that sort of feeling of love, you know," said Dianne.&lt;/p&gt;
    &lt;p&gt;"It was incredible, really, to watch."&lt;/p&gt;
    &lt;p&gt;The pair planned to let him stay until the day after Christmas, but when the day came, they couldn't bring themselves to cast Ronnie out and sought advice from the authorities.&lt;/p&gt;
    &lt;p&gt;The homeless centre told them Ronnie needed an address to get a job, Rob said, but "to get an address, you need a job".&lt;/p&gt;
    &lt;p&gt;"That's the Catch 22 that loads of homeless people are in."&lt;/p&gt;
    &lt;p&gt;Put in a care home when he was just eight years old, Ronnie disappeared from Cardiff aged 11, said Rob, and it was only when he was researching for his book, A Knock on the Door, did he discover what happened to him.&lt;/p&gt;
    &lt;p&gt;He had been sent 200 miles away to a school which was referred to in a report as a "school for subnormal boys" and he lived there for five years.&lt;/p&gt;
    &lt;p&gt;"He didn't have any friends there. He had no social worker that knew him. He had no teachers that knew him."&lt;/p&gt;
    &lt;p&gt;Rob said Ronnie would often ask "have I done a bad thing?" something which they believe he picked up from his time at the school.&lt;/p&gt;
    &lt;p&gt;"He was always worried he had offended you, or done something wrong."&lt;/p&gt;
    &lt;p&gt;Aged 15, Ronnie was sent back to Cardiff "to nothing" they said.&lt;/p&gt;
    &lt;p&gt;The couple said Ronnie was a bit awkward to begin with as he would struggle to make any eye contact and conversation was kept to a minimum.&lt;/p&gt;
    &lt;p&gt;"But then we got to know him and, in truth, we got to love him," they said.&lt;/p&gt;
    &lt;p&gt;They helped Ronnie get a job as a waste collector and took him to buy new clothes after finding out he wore the same clothes he was given as a teenager at the school.&lt;/p&gt;
    &lt;p&gt;"We didn't have kids of our own, it was like dressing your kids for school, we were proud parents," said Rob.&lt;/p&gt;
    &lt;p&gt;"As we came out of the shop, she [Dianne] said to me: 'He's got a job as a dustman, we've dressed him up as though he's the front man of the Dorchester Hotel'," Rob laughed.&lt;/p&gt;
    &lt;p&gt;Rob, who was a lawyer, would get up an extra hour early to drop Ronnie to work before going to work himself.&lt;/p&gt;
    &lt;p&gt;When he would get home, Rob said Ronnie would often be sitting there, just smiling, and one night he asked: "Ronnie, what's amusing you so much?"&lt;/p&gt;
    &lt;p&gt;Ronnie replied: "Rob, when you take me to work in the mornings, the other men say 'who is that who brings you to work in that car?' And I say 'oh that's my solicitor'.&lt;/p&gt;
    &lt;p&gt;"We don't think he was proud of being taken to work by a lawyer, but we think maybe he never had somebody take him on his first day of school," said Rob.&lt;/p&gt;
    &lt;p&gt;"And now he's almost 30... at last somebody is at the gate."&lt;/p&gt;
    &lt;p&gt;Ronnie had many rituals they became accustomed to, including emptying the dishwasher each morning, to which Rob would act surprised to avoid Ronnie's disappointment.&lt;/p&gt;
    &lt;p&gt;"It's hard to look surprised when you get the same question on Tuesday that you had on Monday, but that was Ronnie.&lt;/p&gt;
    &lt;p&gt;"We did that for 45 years," he laughed.&lt;/p&gt;
    &lt;p&gt;"He obviously struggled to read and write, but he would buy the South Wales Echo every day," Dianne added.&lt;/p&gt;
    &lt;p&gt;Ronnie would buy them the same Marks and Spencer gift cards every Christmas but each year he held the same excitement for their reaction.&lt;/p&gt;
    &lt;p&gt;Ronnie spent a lot of his spare time at their local church, gathering donations for the homeless and setting up for services, "meticulously" lining out the chairs.&lt;/p&gt;
    &lt;p&gt;Dianne recalled one day he came home with a different pair of shoes on, and she asked: "Ronnie, where are your shoes."&lt;/p&gt;
    &lt;p&gt;He told her a homeless man needed them.&lt;/p&gt;
    &lt;p&gt;"That's the type of person he was. He was amazing," they said.&lt;/p&gt;
    &lt;p&gt;One of their lowest times was when Dianne was ill with ME, also known as chronic fatigue syndrome, external, as she recalled there being days where she couldn't get out of bed.&lt;/p&gt;
    &lt;p&gt;"I had a little three-year-old daughter, Rob was away working," said Dianne.&lt;/p&gt;
    &lt;p&gt;But she said Ronnie was "remarkable" and came into his own, making milk bottles for their son Lloyd, helping out around the home and playing with their daughter Katie.&lt;/p&gt;
    &lt;p&gt;While they admitted the dynamic had its difficulties, including battling Ronnie's gambling addiction for 20 years, they couldn't imagine their lives without him.&lt;/p&gt;
    &lt;p&gt;"It's not something I would recommend as a strategy," said Rob, "but Ronnie enriched our lives in many ways".&lt;/p&gt;
    &lt;p&gt;"He had a great heart Ronnie. He was kind, he was frustrating," said Dianne.&lt;/p&gt;
    &lt;p&gt;"Sometimes I was his mother, sometimes I was his social worker and sometimes I was his carer.&lt;/p&gt;
    &lt;p&gt;"Somebody said to them [their children] one day, 'how did you cope with Ronnie when your friends came to the house' and they said 'well, we don't think about it really, it's just Ronnie'."&lt;/p&gt;
    &lt;p&gt;Rob added: "Our kids had never ever known life without Ronnie. He was there before they came and he was there when they were gone, with children of their own."&lt;/p&gt;
    &lt;p&gt;Only once did the couple consider supporting Ronnie to live independently, a few years after he moved in.&lt;/p&gt;
    &lt;p&gt;As their two children were growing older and space felt limited in their one-bathroom home, they approached Ronnie's room to suggest him getting a flat down the road from them.&lt;/p&gt;
    &lt;p&gt;But as they entered, he repeated that familiar question: "Have I done a bad thing?"&lt;/p&gt;
    &lt;p&gt;Rob said Dianne hushed him out of the room, burst into tears and said "I can't do it."&lt;/p&gt;
    &lt;p&gt;A few nights later, Ronnie entered their room and asked: "We three are firm friends, aren't we?"&lt;/p&gt;
    &lt;p&gt;"I said 'yes Ronnie, we three are firm friends'," said Rob.&lt;/p&gt;
    &lt;p&gt;"And we will be together forever won't we?" he asked.&lt;/p&gt;
    &lt;p&gt;"And there was a moment's pause, probably too long, I looked across to Di and I said 'yes Ronnie, we will be together forever'.&lt;/p&gt;
    &lt;p&gt;"And we were."&lt;/p&gt;
    &lt;p&gt;Ronnie died in 2020 at the age of 75 after suffering a stroke and the couple say they miss him terribly.&lt;/p&gt;
    &lt;p&gt;Only 50 people were allowed to go to his funeral due to Covid but "tickets were hotter than a Coldplay concert" Rob joked.&lt;/p&gt;
    &lt;p&gt;They received at least 100 sympathy cards, from "Oxford University professors, to politicians and the unemployed".&lt;/p&gt;
    &lt;p&gt;After his death, a new Ã‚Â£1.6m wellbeing centre attached to Glenwood Church in Cardiff was named Lockwood House, after Ronnie.&lt;/p&gt;
    &lt;p&gt;But the old building and the new building didn't quite match, and they needed extra funding to finish the renovation.&lt;/p&gt;
    &lt;p&gt;"But they needn't have worried," said Rob.&lt;/p&gt;
    &lt;p&gt;"Almost to the penny, it was the exact amount Ronnie had left in his will.&lt;/p&gt;
    &lt;p&gt;"In the end the homeless man put the roof over all of our heads."&lt;/p&gt;
    &lt;p&gt;"Isn't that amazing, I just think it's all meant to be," said Dianne.&lt;/p&gt;
    &lt;p&gt;"People say to us, how did it happen - 45 years - but the honest truth is, in some ways, it happened a day at a time.&lt;/p&gt;
    &lt;p&gt;"Ronnie brought a richness into our lives."&lt;/p&gt;
    &lt;p&gt;Additional reporting by Greg Davies&lt;/p&gt;
    &lt;head rend="h2"&gt;More top stories&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published2 days ago&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published2 days ago&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Published1 day ago&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46383552</guid><pubDate>Thu, 25 Dec 2025 10:35:34 +0000</pubDate></item><item><title>Mattermost restricted access to old messages after 10000 limit is reached</title><link>https://github.com/mattermost/mattermost/issues/34271</link><description>&lt;doc fingerprint="544ad3bcc9efe4be"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 8.2k&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Open&lt;/p&gt;
    &lt;p&gt;Labels&lt;/p&gt;
    &lt;p&gt;kind/licenseQuestion about Mattermost licenseQuestion about Mattermost license&lt;/p&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;We have a problem since the new upgrade.&lt;lb/&gt; "10.000-message limit reached. Messages sent before 26. September 2025 are hidden -Restore Access" appeared.&lt;lb/&gt; so the messages before that date can not be accessed anymore.&lt;lb/&gt; When was this hard restriction implemented. v11?&lt;/p&gt;
    &lt;p&gt;We are a school and have since corona this Mattermost instance with over 2000 active users and 470000 posts.&lt;/p&gt;
    &lt;p&gt;is the September 26 a calculated date with the 10000 messages or just access to the last months messages?&lt;/p&gt;
    &lt;p&gt;BayJay, movahhedi, irahog, mconsoir, zubozrout and 41 moreceberttylertechJWesorick and kinow&lt;/p&gt;
    &lt;head rend="h2"&gt;Metadata&lt;/head&gt;
    &lt;head rend="h2"&gt;Metadata&lt;/head&gt;
    &lt;head rend="h3"&gt;Assignees&lt;/head&gt;
    &lt;head rend="h3"&gt;Labels&lt;/head&gt;
    &lt;p&gt;kind/licenseQuestion about Mattermost licenseQuestion about Mattermost license&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46383675</guid><pubDate>Thu, 25 Dec 2025 11:03:59 +0000</pubDate></item><item><title>Python 3.15â€™s interpreter for Windows x86-64 should hopefully be 15% faster</title><link>https://fidget-spinner.github.io/posts/no-longer-sorry.html</link><description>&lt;doc fingerprint="2e609111f637a5d0"&gt;
  &lt;main&gt;
    &lt;p&gt;24 December 2025&lt;/p&gt;
    &lt;p&gt;Some time ago I posted an apology peice for Pythonâ€™s tail caling results. I apologized for communicating performance results without noticing a compiler bug had occured.&lt;/p&gt;
    &lt;p&gt;I can proudly say today that I am partially retracting that apology, but only for two platformsâ€”MacOs AArch64 (XCode Clang) and Windows x86-64 (MSVC).&lt;/p&gt;
    &lt;p&gt;In our own experiments, the tail calling interpreter for CPython was found to beat the computed goto interpreter by 5% on pyperformance on AArch64 macOS using XCode Clang, and roughly 15% on pyperformance on Windows on an experimental internal version of MSVC. The Windows build is against a switch-case interpreter, but this in theory shouldnâ€™t matter too much, more on that in the next section.&lt;/p&gt;
    &lt;p&gt;This is of course, a hopefully accurate result. I tried to be more diligent here, but I am of course not infallible. However, I have found that sharing early and making a fool of myself often works well, as it has led to people catching bugs in my code, so I shall continue doing so :).&lt;/p&gt;
    &lt;p&gt;Also this assumes the change doesnâ€™t get reverted later in Python 3.15â€™s development cycle.&lt;/p&gt;
    &lt;p&gt;Just a recap. There are two popular current ways of writing C-based interpreters.&lt;/p&gt;
    &lt;p&gt;Switch-cases:&lt;/p&gt;
    &lt;code&gt;switch (opcode) {
    case INST_1: ...
    case INST_2: ...
}
&lt;/code&gt;
    &lt;p&gt;Where we just switch-case to the correct instruction handler.&lt;/p&gt;
    &lt;p&gt;And the other popular way is a GCC/Clang extension called labels-as-values/computed gotos.&lt;/p&gt;
    &lt;code&gt;goto *dispatch_table[opcode];
INST_1: ...
INST_2: ...
&lt;/code&gt;
    &lt;p&gt;Which is basically the same idea, but to instead jump to the address of the next label. Traditionally, the key optimization here is that it needs only one jump to go to the next instruction, while in the switch-case interpreter, a naiive compiler would need two jumps.&lt;/p&gt;
    &lt;p&gt;With modern compilers however, the benefits of the computed gotos is a lot less, mainly because modern compilers have gotten better and modern hardware has also gotten better. In Nelson Elhageâ€™s excellent investigation on the next kind of interpreter, the speedup of computed gotos over switch case on modern Clang was only in the low single digits on pyperformance.&lt;/p&gt;
    &lt;p&gt;A 3rd way that was suggested decades ago, but not really entirely feasible is call/tail-call threaded interpreters. In this scheme, each bytecode handler is its own function, and we tail-call from one handler to the next in the instruction stream:&lt;/p&gt;
    &lt;code&gt;return dispatch_table[opcode];

PyObject *INST_1(...) {

}

PyObject *INST_2(...) {
}
&lt;/code&gt;
    &lt;p&gt;This wasnâ€™t too feasible in C for one main reasonâ€”tail call optimization was merely an optimization. Itâ€™s something the C compiler might do, or might not do. This means if youâ€™re unlucky and the C compiler chooses not to perform the tail call, your interpreter might stack overflow!&lt;/p&gt;
    &lt;p&gt;Some time ago, Clang introduced &lt;code&gt;__attribute__((musttail))&lt;/code&gt;, which allowed
for mandating that a call must be tail-called. Otherwise, the compilation
will fail. To my knowledge, the first time this was popularized for use
in a mainstream interpreter was in
Josh Habermanâ€™s Protobuf blog post.&lt;/p&gt;
    &lt;p&gt;Later on, Haoran Xu noticed that the GHC calling convention combined with tail calls produced efficient code. They used this for their baseline JIT in a paper and termed the technique Copy-and-Patch.&lt;/p&gt;
    &lt;p&gt;After using a fixed XCode Clang, our performance numbers on CPython 3.14/3.15 suggest that the tail calling interpreter does provide a modest speedup over computed gotos. Around the 5% geomean range on pyperformance.&lt;/p&gt;
    &lt;p&gt;To my understanding, &lt;code&gt;uv&lt;/code&gt; already ships Python 3.14 on macOS with tail calling,
which might be responsible for some of the speedups you see on there.
Weâ€™re planning to ship the official 3.15 macOS binaries on &lt;code&gt;python.org&lt;/code&gt; with
tail calling as well.&lt;/p&gt;
    &lt;p&gt;However, youâ€™re not here for that. The title of this blog post is clearly about MSVC Windows x86-64. So what about that?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[!CAUTION] The features for MSVC discussed below are to my knowledge, undocumented. They are not guaranteed to always be around unless the MSVC team decide to keep them. Use at your own risk!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;These are the preliminary pyperformance results for CPython on MSVC with tail-calling vs switch-case. Any number above 1.00x is a speedup (e.g. &lt;code&gt;1.01x == 1% speedup&lt;/code&gt;), anything below 1.00x is a slowdown.
The speedup is a geomtric mean of around 15-16%, with a
range of ~60% slowdown (one or two outliers) to 78% speedup.
However, the key thing is that the vast majority of benchmaarks sped up!&lt;/p&gt;
    &lt;p&gt;Chart credits to Michael Droettboom&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[!WARNING] These results are on an experimental internal MSVC compiler, public results below.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;To verify this and make sure I wasnâ€™t wrong yet again, I checked the results on my machine with Visual Studio 2026. These are the results from this issue.&lt;/p&gt;
    &lt;code&gt;Mean +- std dev: [spectralnorm_tc_no] 146 ms +- 1 ms -&amp;gt; [spectralnorm_tc] 98.3 ms +- 1.1 ms: 1.48x faster
Mean +- std dev: [nbody_tc_no] 145 ms +- 2 ms -&amp;gt; [nbody_tc] 107 ms +- 2 ms: 1.35x faster
Mean +- std dev: [bm_django_template_tc_no] 26.9 ms +- 0.5 ms -&amp;gt; [bm_django_template_tc] 22.8 ms +- 0.4 ms: 1.18x faster
Mean +- std dev: [xdsl_tc_no] 64.2 ms +- 1.6 ms -&amp;gt; [xdsl_tc] 56.1 ms +- 1.5 ms: 1.14x faster
&lt;/code&gt;
    &lt;p&gt;So yeah, the speedups are real! For a large-ish library like xDSL, we see a 14% speedup, while for smaller microbenchmarks like nbody and spectralnorm, the speedups are greater.&lt;/p&gt;
    &lt;p&gt;Thanks to Chris Eibl and Brandt Bucher, we managed to get the PR for this on MSVC over the finish line. I also want to sincerely thank the MSVC team. I canâ€™t say this enough: they have been a joy to work with and Iâ€™m very impressed by what theyâ€™ve done, and I want to congratulate them on releasing Visual Studio 2026.&lt;/p&gt;
    &lt;p&gt;This is now listed in the Whatâ€™s New for 3.15 notes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Builds using Visual Studio 2026 (MSVC 18) may now use the new tail-calling interpreter. Results on an early experimental MSVC compiler reported roughly 15% speedup on the geometric mean of pyperformance on Windows x86-64 over the switch-case interpreter. We have observed speedups ranging from 15% for large pure-Python libraries to 40% for long-running small pure-Python scripts on Windows. (Contributed by Chris Eibl, Ken Jin, and Brandt Bucher in gh-143068. Special thanks to the MSVC team including Hulon Jenkins.)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I used to believe the the tail calling interpreters get their speedup from better register use. While I still believe that now, I suspect that is not the main reason for speedups in CPython.&lt;/p&gt;
    &lt;p&gt;My main guess now is that tail calling resets compiler heuristics to sane levels, so that compilers can do their jobs.&lt;/p&gt;
    &lt;p&gt;Let me show an example, at the time of writing, CPython 3.15â€™s interpreter loop is around 12k lines of C code. Thatâ€™s 12k lines in a single function for the switch-case and computed goto interpreter.&lt;/p&gt;
    &lt;p&gt;This has caused many issues for compilers in the past, too many to list in fact. I have a EuroPython 2025 talk about this. In short, this overly large function breaks a lot of compiler heuristics.&lt;/p&gt;
    &lt;p&gt;One of the most beneficial optimisations is inlining. In the past, weâ€™ve found that compilers sometimes straight up refuse to inline even the simplest of functions in that 12k loc eval loop. I want to stress that this is not the fault of the compiler. Itâ€™s actually doing the correct thingâ€”you usually donâ€™t want to increase the code size of something already super large. Unfortunately, this doesâ€™t bode well for our interpreter.&lt;/p&gt;
    &lt;p&gt;You might say just write the interpreter in assembly! However, the whole point of this exercise is to not do that.&lt;/p&gt;
    &lt;p&gt;Ok enough talk, letâ€™s take a look at the code now. Taking a real example, we examine &lt;code&gt;BINARY_OP_ADD_INT&lt;/code&gt; which adds two Python integers.
Cleaning up the code so itâ€™s readable, things look like this:&lt;/p&gt;
    &lt;code&gt;TARGET(BINARY_OP_ADD_INT) {
    // Increment the instruction pointer.
    _Py_CODEUNIT* const this_instr = next_instr;
    frame-&amp;gt;instr_ptr = next_instr;
    next_instr += 6;
    _PyStackRef right = stack_pointer[-1];
    // Check that LHS is an int.
    PyObject *value_o = PyStackRef_AsPyObjectBorrow(left);
    if (!_PyLong_CheckExactAndCompact(value_o)) {
        JUMP_TO_PREDICTED(BINARY_OP);
    }
    // Check that RHS is an int.
    // ... (same code as above for LHS)

    // Add them together.
    PyObject *left_o = PyStackRef_AsPyObjectBorrow(left);
    PyObject *right_o = PyStackRef_AsPyObjectBorrow(right);
    res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);

    // If the addition fails, fall back to the generic instruction.
    if (PyStackRef_IsNull(res)) {
        JUMP_TO_PREDICTED(BINARY_OP);
    }

    // Close the references.
    PyStackRef_CLOSE_SPECIALIZED(left, _PyLong_ExactDealloc);
    PyStackRef_CLOSE_SPECIALIZED(right, _PyLong_ExactDealloc);

    // Write to the stack, and dispatch.
    stack_pointer[-2] = res;
    stack_pointer += -1;
    DISPATCH();
}
&lt;/code&gt;
    &lt;p&gt;Seems simple enough, letâ€™s take a look at the assembly for switch-case on VS 2026. Note again, this is a non-PGO build for easy source information, PGO generally makes some of these problems go away, but not all of them:&lt;/p&gt;
    &lt;code&gt;                if (!_PyLong_CheckExactAndCompact(value_o)) {
00007FFC4DE24DCE  mov         rcx,rbx  
00007FFC4DE24DD1  mov         qword ptr [rsp+58h],rax  
00007FFC4DE24DD6  call        _PyLong_CheckExactAndCompact (07FFC4DE227F0h)  
00007FFC4DE24DDB  test        eax,eax  
00007FFC4DE24DDD  je          _PyEval_EvalFrameDefault+10EFh (07FFC4DE258FFh)
...
                res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);
00007FFC4DE24DFF  mov         rdx,rbx  
00007FFC4DE24E02  mov         rcx,r15  
00007FFC4DE24E05  call        _PyCompactLong_Add (07FFC4DD34150h)  
00007FFC4DE24E0A  mov         rbx,rax  
...
                PyStackRef_CLOSE_SPECIALIZED(value, _PyLong_ExactDealloc);
00007FFC4DE24E17  lea         rdx,[_PyLong_ExactDealloc (07FFC4DD33BD0h)]  
00007FFC4DE24E1E  mov         rcx,rsi  
00007FFC4DE24E21  call        PyStackRef_CLOSE_SPECIALIZED (07FFC4DE222A0h) 
&lt;/code&gt;
    &lt;p&gt;Huhâ€¦ all our functions were not inlined. Surely that mustâ€™ve mean they were too big or something right? Letâ€™s look at &lt;code&gt;PyStackReF_CLOSE_SPECIALIZED&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;static inline void
PyStackRef_CLOSE_SPECIALIZED(_PyStackRef ref, destructor destruct)
{
    assert(!PyStackRef_IsNull(ref));
    if (PyStackRef_RefcountOnObject(ref)) {
        Py_DECREF_MORTAL_SPECIALIZED(BITS_TO_PTR(ref), destruct);
    }
}
&lt;/code&gt;
    &lt;p&gt;That looks â€¦ inlineable?&lt;/p&gt;
    &lt;p&gt;Hereâ€™s how &lt;code&gt;BINARY_OP_ADD_INT&lt;/code&gt; looks with tail calling on VS 2026 (again,
no PGO):&lt;/p&gt;
    &lt;code&gt;                if (!_PyLong_CheckExactAndCompact(left_o)) {
00007FFC67164785  cmp         qword ptr [rax+8],rdx  
00007FFC67164789  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+149h (07FFC67164879h)  
00007FFC6716478F  mov         r9,qword ptr [rax+10h]  
00007FFC67164793  cmp         r9,10h  
00007FFC67164797  jae         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+149h (07FFC67164879h) 
...
                res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);
00007FFC6716479D  mov         eax,dword ptr [rax+18h]  
00007FFC671647A0  and         r9d,3  
00007FFC671647A4  and         r8d,3  
00007FFC671647A8  mov         edx,1  
00007FFC671647AD  sub         rdx,r9  
00007FFC671647B0  mov         ecx,1  
00007FFC671647B5  imul        rdx,rax  
00007FFC671647B9  mov         eax,dword ptr [rbx+18h]  
00007FFC671647BC  sub         rcx,r8  
00007FFC671647BF  imul        rcx,rax  
00007FFC671647C3  add         rcx,rdx  
00007FFC671647C6  call        medium_from_stwodigits (07FFC6706E9E0h)  
00007FFC671647CB  mov         rbx,rax  
...
                PyStackRef_CLOSE_SPECIALIZED(value, _PyLong_ExactDealloc);
00007FFC671647EB  test        bpl,1  
00007FFC671647EF  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0ECh (07FFC6716481Ch)  
00007FFC671647F1  add         dword ptr [rbp],0FFFFFFFFh  
00007FFC671647F5  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0ECh (07FFC6716481Ch)  
00007FFC671647F7  mov         rax,qword ptr [_PyRuntime+25F8h (07FFC675C45F8h)]  
00007FFC671647FE  test        rax,rax  
00007FFC67164801  je          _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0E4h (07FFC67164814h)  
00007FFC67164803  mov         r8,qword ptr [_PyRuntime+2600h (07FFC675C4600h)]  
00007FFC6716480A  mov         edx,1  
00007FFC6716480F  mov         rcx,rbp  
00007FFC67164812  call        rax  
00007FFC67164814  mov         rcx,rbp  
00007FFC67164817  call        _PyLong_ExactDealloc (07FFC67073DA0h) 
&lt;/code&gt;
    &lt;p&gt;Would you look at that, suddenly our trivial functions get inlined :).&lt;/p&gt;
    &lt;p&gt;You might also say, surely this does not happen on PGO builds? Well the issue I linked above actually says it does! So yeah happy days.&lt;/p&gt;
    &lt;p&gt;Once again I want to stress, this is not the compilerâ€™s fault! Itâ€™s just that the CPython interpreter loop is not the best thing to optimize.&lt;/p&gt;
    &lt;p&gt;Unfortunately, for now, you will have to build from source.&lt;/p&gt;
    &lt;p&gt;With VS 2026, after cloning CPython, for a release build with PGO:&lt;/p&gt;
    &lt;code&gt;$env:PlatformToolset = "v145"
./PCbuild/build.bat --tail-call-interp -c Release -p x64 --pgo
&lt;/code&gt;
    &lt;p&gt;Hopefully, we can distribute this in an easier binary form in the future once Python 3.15â€™s development matures!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46384167</guid><pubDate>Thu, 25 Dec 2025 13:02:46 +0000</pubDate></item><item><title>Alzheimer's can be reversed to achieve full neurological recovery in animals</title><link>https://case.edu/news/new-study-shows-alzheimers-disease-can-be-reversed-achieve-full-neurological-recovery-not-just-prevented-or-slowed-animal-models</link><description>&lt;doc fingerprint="6f22933169f9f5e8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;New study shows Alzheimerâ€™s disease can be reversed to achieve full neurological recoveryâ€”not just prevented or slowedâ€”in animal models&lt;/head&gt;
    &lt;p&gt;Researchers from Case Western Reserve University, University Hospitals and the Cleveland VA showed restoring brainâ€™s energy balance led to both pathological and functional recovery&lt;/p&gt;
    &lt;p&gt;For more than a century, people have considered Alzheimer's disease (AD) an irreversible illness. Consequently, research has focused on preventing or slowing it, rather than recovery. Despite billions of dollars spent on decades of research, there has never been a clinical trial of any drug to reverse and recover from AD.&lt;/p&gt;
    &lt;p&gt;A research team from Case Western Reserve University, University Hospitals (UH) and the Louis Stokes Cleveland VA Medical Center has now challenged this long-held dogma in the field, testing whether brains already badly afflicted with advanced AD could recover.&lt;/p&gt;
    &lt;p&gt;The study, led by Kalyani Chaubey, from the Pieper Laboratory, was published online Dec. 22 in Cell Reports Medicine. Using diverse preclinical mouse models and analysis of human AD brains, the team showed that the brainâ€™s failure to maintain normal levels of a central cellular energy molecule, NAD+, is a major driver of AD, and that maintaining proper NAD+ balance can prevent and even reverse the disease.&lt;/p&gt;
    &lt;p&gt;NAD+ levels decline naturally across the body, including the brain, as people age. Without proper NAD+ balance, cells eventually become unable to execute many of the critical processes required for proper functioning and survival. In this study, the team showed that the decline in NAD+ is even more severe in the brains of people with AD, and that this same phenomenon also occurs in mouse models of the disease.&lt;/p&gt;
    &lt;p&gt;While AD is a uniquely human condition, it can be studied in the laboratory with mice that have been genetically engineered to express genetic mutations known to cause AD in people.&lt;/p&gt;
    &lt;p&gt;The researchers used two of these mouse models: One carried multiple human mutations in amyloid processing; the other carried a human mutation in the tau protein.&lt;/p&gt;
    &lt;p&gt;Amyloid and tau pathology are two of the major early events in AD. Both lines of mice develop brain pathology resembling AD, including blood-brain barrier deterioration, axonal degeneration, neuroinflammation, impaired hippocampal neurogenesis, reduced synaptic transmission and widespread accumulation of oxidative damage. These mice also develop the characteristics of severe cognitive impairments seen in people with AD.&lt;/p&gt;
    &lt;p&gt;After finding that NAD+ levels in the brain declined precipitously in both human and mouse AD, the research team tested whether preventing loss of brain NAD+ balance before disease onset or restoring brain NAD+ balance after significant disease progression could prevent or reverse AD, respectively.&lt;/p&gt;
    &lt;p&gt;The study was based on their previous work, published in Proceeding of the National Academy of Sciences USA, showing that restoring the brain's NAD+ balance achieved pathological and functional recovery after severe, long-lasting traumatic brain injury. They restored NAD+ balance by administering a now well-characterized pharmacologic agent known as P7C3-A20, developed in the Pieper lab.&lt;/p&gt;
    &lt;p&gt;Remarkably, not only did preserving NAD+ balance protect mice from developing AD, but delayed treatment in mice with advanced disease also enabled the brain to fix the major pathological events driven by the disease-causing genetic mutations.&lt;/p&gt;
    &lt;p&gt;Moreover, both lines of mice fully recovered cognitive function. This was accompanied by normalized blood levels of phosphorylated tau 217, a recently approved clinical biomarker of AD in people, providing confirmation of disease reversal and highlighting an objective biomarker that could be used in future clinical trials for AD recovery.&lt;/p&gt;
    &lt;p&gt;â€œWe were very excited and encouraged by our results,â€ said Andrew A. Pieper, the studyâ€™s senior author, a professor at the Case Western Reserve School of Medicine and director of the Brain Health Medicines Center, Harrington Discovery Institute at UH. â€œRestoring the brain's energy balance achieved pathological and functional recovery in both lines of mice with advanced Alzheimer's. Seeing this effect in two very different animal models, each driven by different genetic causes, strengthens the new idea that recovery from advanced disease might be possible in people with AD when the brain's NAD+ balance is restored.â€&lt;/p&gt;
    &lt;p&gt;Pieper also holds the Morley-Mather Chair in Neuropsychiatry at UH and the CWRU Rebecca E. Barchas, MD, DLFAPA, University Professorship in Translational Psychiatry. He serves as psychiatrist and investigator in the Louis Stokes VA Geriatric Research Education and Clinical Center.&lt;/p&gt;
    &lt;p&gt;The results prompt a paradigm shift in how researchers, clinicians and patients can think about treating AD in the future.&lt;/p&gt;
    &lt;p&gt;â€œThe key takeaway is a message of hopeâ€”the effects of Alzheimer's disease may not be inevitably permanent,â€ Pieper said. â€œThe damaged brain can, under some conditions, repair itself and regain function.â€&lt;/p&gt;
    &lt;p&gt;â€œThrough our study, we demonstrated one drug-based way to accomplish this in animal models, and also identified candidate proteins in the human AD brain that may relate to the ability to reverse AD,â€ Chaubey said.&lt;/p&gt;
    &lt;p&gt;Pieper emphasized that current over-the-counter NAD+-precursors have been shown in animal models to raise cellular NAD+ to dangerously high levels that promote cancer. The pharmacological approach in this study, however, uses a pharmacologic agent (P7C3-A20) that enables cells to maintain their proper balance of NAD+ under conditions of otherwise overwhelming stress, without elevating NAD+ to supraphysiologic levels.&lt;/p&gt;
    &lt;p&gt;â€œThis is an important factor when considering patient care, and clinicians should consider the possibility that therapeutic strategies aimed at restoring brain energy balance might offer a path to disease recovery,â€ Pieper said.&lt;/p&gt;
    &lt;p&gt;This work also encourages new research into complementary approaches and eventual testing in patients, and the technology is being commercialized by Cleveland-based company Glengary Brain Health, which Pieper co-founded.&lt;/p&gt;
    &lt;p&gt;â€œThis new therapeutic approach to recovery needs to be moved into carefully designed human clinical trials to determine whether the efficacy seen in animal models translates to human patients,â€ Pieper said. â€œAdditional next steps for the laboratory research include pinpointing which aspects of brain energy balance are most important for recovery, identifying and evaluating complementary approaches to Alzheimer's reversal, and investigating whether this recovery approach is also effective in other forms of chronic, age-related neurodegenerative disease.â€&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</description><guid isPermaLink="false">https://news.ycombinator.com/item?id=46384919</guid><pubDate>Thu, 25 Dec 2025 15:22:36 +0000</pubDate></item></channel></rss>